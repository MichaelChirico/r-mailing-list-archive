From lai at lindaspaces.com  Thu Sep  1 00:01:47 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Wed, 31 Aug 2005 18:01:47 -0400
Subject: [Rd] Build Portland Group Compiler
In-Reply-To: <43162853.6070902@lindaspaces.com>
References: <43162119.1010503@lindaspaces.com>
	<x2oe7d4vux.fsf@turmalin.kubism.ku.dk>
	<43162853.6070902@lindaspaces.com>
Message-ID: <431628CB.7080900@lindaspaces.com>

Forgot to mention, here are #define long and int value in config.log 
from second configure run (without --host argument)

| #define SIZEOF_INT 4
| #define INT_32_BITS 1
| #define SIZEOF_LONG 8
| #define SIZEOF_LONG_LONG 8
| #define SIZEOF_LONG_DOUBLE 16

Regards,
Jennifer

Jennifer Lai wrote:

> I can't duplicate the error message. After running "configure 
> --host=x86_64-unknow-linux-gnu" for the first time, I was able to run 
> configure without providing --host argument. Even start with a fresh 
> copy of R-devel didn't help me to get the original error. Is the host 
> info been cached somewhere in R?
>
> Regards,
> Jennifer
>
> Peter Dalgaard wrote:
>
>> Jennifer Lai <lai at lindaspaces.com> writes:
>>
>>  
>>
>>> Hi,
>>>    I built R with Portland Group compiler, but I noticed one thing 
>>> that when I ran configure for the first time on AMD machine, I got 
>>> the following error:
>>>
>>>
>>> checking whether the C compiler works... configure: error: cannot 
>>> run C compiled programs.
>>> If you meant to cross compile, use `--host'.
>>> See `config.log' for more details.
>>>
>>>
>>>
>>> so I tried to set host=x86_64-unknown-linux-gnu, which seems to 
>>> work, except what puzzles me is that there is warning messages 
>>> indicating C longs are 4 bytes.
>>>
>>> *******************************************
>>> % configure --host=x86_64-unknown-linux-gnu
>>> .
>>> .
>>> .
>>> R is now configured for x86_64-unknown-linux-gnu
>>>
>>>  Source directory:          .
>>>  Installation directory:    /usr/local/R.pgcc
>>>
>>>  C compiler:                /usr/pgi/linux86-64/6.0/bin/pgcc  -g -O2 
>>> -mieee-fp
>>>  C++ compiler:              /usr/pgi/linux86-64/6.0/bin/pgCC  -g
>>>  Fortran compiler:          /usr/pgi/linux86-64/6.0/bin/pgf77  -O2
>>>
>>>  Interfaces supported:      X11
>>>  External libraries:        readline
>>>  Additional capabilities:   PNG, JPEG, MBCS, NLS
>>>  Options enabled:           R profiling
>>>
>>>  Recommended packages:      yes
>>>
>>> configure: WARNING: assuming C ints are 4 byte on 
>>> x86_64-unknown-linux-gnu
>>> configure: WARNING: assuming C longs are 4 byte on 
>>> x86_64-unknown-linux-gnu
>>> configure: WARNING: you cannot build info or html versions of the R 
>>> manuals
>>>
>>>
>>> Am I defining a wrong host?
>>>   
>>
>>
>> You're not doing yourself a favour, anyway. 4-byte longs are
>> definitely not a good idea on Linux. What is worse, you are building a
>> cross-target, which means that configure is not even going to try
>> running any compiled programs, not that they work any better than
>> before.
>>
>> The thing to do is to look inside config.log and see what causes
>> configure to conclude that you cannot run C compiled programs.
>>
>>  
>>
>
>


From p.dalgaard at biostat.ku.dk  Thu Sep  1 00:07:53 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Sep 2005 00:07:53 +0200
Subject: [Rd] Build Portland Group Compiler
In-Reply-To: <43162853.6070902@lindaspaces.com>
References: <43162119.1010503@lindaspaces.com>
	<x2oe7d4vux.fsf@turmalin.kubism.ku.dk>
	<43162853.6070902@lindaspaces.com>
Message-ID: <x2k6i14v5y.fsf@turmalin.kubism.ku.dk>

Jennifer Lai <lai at lindaspaces.com> writes:

> I can't duplicate the error message. After running "configure
> --host=x86_64-unknow-linux-gnu" for the first time, I was able to run
> configure without providing --host argument. Even start with a fresh
> copy of R-devel didn't help me to get the original error. Is the host
> info been cached somewhere in R?

Not that I know of... Back in the old days we had config.cache playing
tricks on people, but it shouldn't be there anymore. 

If you're not already doing so, do yourself a favour and build in a
separate directory, keeping the sources untouched. It's much easier to
clean up and start over that way.

> >>Hi,
> >>    I built R with Portland Group compiler, but I noticed one thing
> >> that when I ran configure for the first time on AMD machine, I got
> >> the following error:
> >>
> >>
> >> checking whether the C compiler works... configure: error: cannot
> >> run C compiled programs.
> >>If you meant to cross compile, use `--host'.
> >>See `config.log' for more details.
> >>
> >>
> >>
> >> so I tried to set host=x86_64-unknown-linux-gnu, which seems to
> >> work, except what puzzles me is that there is warning messages
> >> indicating C longs are 4 bytes.
> >>
> >>*******************************************
> >>% configure --host=x86_64-unknown-linux-gnu
> >>.
> >>.
> >>.
> >>R is now configured for x86_64-unknown-linux-gnu
> >>
> >>  Source directory:          .
> >>  Installation directory:    /usr/local/R.pgcc
> >>
> >>  C compiler:                /usr/pgi/linux86-64/6.0/bin/pgcc  -g
> >> -O2 -mieee-fp
> >>  C++ compiler:              /usr/pgi/linux86-64/6.0/bin/pgCC  -g
> >>  Fortran compiler:          /usr/pgi/linux86-64/6.0/bin/pgf77  -O2
> >>
> >>  Interfaces supported:      X11
> >>  External libraries:        readline
> >>  Additional capabilities:   PNG, JPEG, MBCS, NLS
> >>  Options enabled:           R profiling
> >>
> >>  Recommended packages:      yes
> >>
> >>configure: WARNING: assuming C ints are 4 byte on x86_64-unknown-linux-gnu
> >>configure: WARNING: assuming C longs are 4 byte on x86_64-unknown-linux-gnu
> >>configure: WARNING: you cannot build info or html versions of the R manuals
> >>
> >>
> >>Am I defining a wrong host?
> >>
> >
> >You're not doing yourself a favour, anyway. 4-byte longs are
> >definitely not a good idea on Linux. What is worse, you are building a
> >cross-target, which means that configure is not even going to try
> >running any compiled programs, not that they work any better than
> >before.
> >
> >The thing to do is to look inside config.log and see what causes
> >configure to conclude that you cannot run C compiled programs.
> >
> >
> 
> 
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From mlopez at iattc.org  Thu Sep  1 00:11:18 2005
From: mlopez at iattc.org (Milton Lopez)
Date: Wed, 31 Aug 2005 15:11:18 -0700
Subject: [Rd] 64 bit R for Windows
Message-ID: <84B25EE9B4CB1A47A197E6AE76790D7801426D07@mail1.lajolla.iattc.org>

Duncan:

Thanks for your reply. Not being a part of the R world and having to assist with these purchases, I have to ask what "not yet" means. I realize that this is a difficult question to answer even for commercial software, but I am hoping you or someone else on the list may shed some additional light on the subject.

Thanks in advance.

Milton F. L?pez 
IT Guy
Inter-American Tuna Commission (IATTC)
8604 La Jolla Shores Drive 
La Jolla, CA 92037 
Tel: (858) 546-7041, Fax: (858) 546-7133 
mlopez at iattc.org 
http://www.iattc.org

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Tuesday, August 30, 2005 5:39 PM
To: Milton Lopez
Cc: r-devel at r-project.org
Subject: Re: [Rd] 64 bit R for Windows

Milton Lopez wrote:
> I am assisting in the purchase of 64-bit Windows XP system for researchers who run R. These systems will have AMD Opteron processors and at least 4GB of RAM. I'd appreciate advice on whether there is a working version of R that can take full advantage of such systems.

No, there are no 64 bit Windows versions yet.  You'll need to install 
some 64 bit version of Linux on those machines to take full advantage of 
the chips.

Duncan Murdoch


From lai at lindaspaces.com  Thu Sep  1 00:19:58 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Wed, 31 Aug 2005 18:19:58 -0400
Subject: [Rd] Build Portland Group Compiler
In-Reply-To: <x2k6i14v5y.fsf@turmalin.kubism.ku.dk>
References: <43162119.1010503@lindaspaces.com>	<x2oe7d4vux.fsf@turmalin.kubism.ku.dk>	<43162853.6070902@lindaspaces.com>
	<x2k6i14v5y.fsf@turmalin.kubism.ku.dk>
Message-ID: <43162D0E.5070003@lindaspaces.com>

My silly mistake. I didn't get the error message the second time is 
because I have set  LD_LIBRARY_PATH. If this value is unset, I would 
have gotten the same error message,

checking for C compiler default output file name... a.out
checking whether the C compiler works... configure: error: cannot run C 
compiled programs.
If you meant to cross compile, use `--host'.


Thank you for the help!

Sincerely,
Jennifer

Peter Dalgaard wrote:

>Jennifer Lai <lai at lindaspaces.com> writes:
>
>  
>
>>I can't duplicate the error message. After running "configure
>>--host=x86_64-unknow-linux-gnu" for the first time, I was able to run
>>configure without providing --host argument. Even start with a fresh
>>copy of R-devel didn't help me to get the original error. Is the host
>>info been cached somewhere in R?
>>    
>>
>
>Not that I know of... Back in the old days we had config.cache playing
>tricks on people, but it shouldn't be there anymore. 
>
>If you're not already doing so, do yourself a favour and build in a
>separate directory, keeping the sources untouched. It's much easier to
>clean up and start over that way.
>
>  
>
>>>>Hi,
>>>>   I built R with Portland Group compiler, but I noticed one thing
>>>>that when I ran configure for the first time on AMD machine, I got
>>>>the following error:
>>>>
>>>>
>>>>checking whether the C compiler works... configure: error: cannot
>>>>run C compiled programs.
>>>>If you meant to cross compile, use `--host'.
>>>>See `config.log' for more details.
>>>>
>>>>
>>>>
>>>>so I tried to set host=x86_64-unknown-linux-gnu, which seems to
>>>>work, except what puzzles me is that there is warning messages
>>>>indicating C longs are 4 bytes.
>>>>
>>>>*******************************************
>>>>% configure --host=x86_64-unknown-linux-gnu
>>>>.
>>>>.
>>>>.
>>>>R is now configured for x86_64-unknown-linux-gnu
>>>>
>>>> Source directory:          .
>>>> Installation directory:    /usr/local/R.pgcc
>>>>
>>>> C compiler:                /usr/pgi/linux86-64/6.0/bin/pgcc  -g
>>>>-O2 -mieee-fp
>>>> C++ compiler:              /usr/pgi/linux86-64/6.0/bin/pgCC  -g
>>>> Fortran compiler:          /usr/pgi/linux86-64/6.0/bin/pgf77  -O2
>>>>
>>>> Interfaces supported:      X11
>>>> External libraries:        readline
>>>> Additional capabilities:   PNG, JPEG, MBCS, NLS
>>>> Options enabled:           R profiling
>>>>
>>>> Recommended packages:      yes
>>>>
>>>>configure: WARNING: assuming C ints are 4 byte on x86_64-unknown-linux-gnu
>>>>configure: WARNING: assuming C longs are 4 byte on x86_64-unknown-linux-gnu
>>>>configure: WARNING: you cannot build info or html versions of the R manuals
>>>>
>>>>
>>>>Am I defining a wrong host?
>>>>
>>>>        
>>>>
>>>You're not doing yourself a favour, anyway. 4-byte longs are
>>>definitely not a good idea on Linux. What is worse, you are building a
>>>cross-target, which means that configure is not even going to try
>>>running any compiled programs, not that they work any better than
>>>before.
>>>
>>>The thing to do is to look inside config.log and see what causes
>>>configure to conclude that you cannot run C compiled programs.
>>>
>>>
>>>      
>>>
>>
>>    
>>
>
>  
>


From dhinds at sonic.net  Thu Sep  1 00:34:08 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Wed, 31 Aug 2005 22:34:08 +0000 (UTC)
Subject: [Rd] RFC: "loop connections"
References: <dedndn$daj$1@sea.gmane.org>
	<17168.15848.291481.473231@stat.math.ethz.ch>
Message-ID: <df5b90$1ba$1@sea.gmane.org>

Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> I think the main point of David's proposal is still worth
> consideration:  One way to see text connections is as a way to
> treat some kind of R objects as "generalized files" i.e., connections.

To summarize the motivation for the proposal, again:

- There are two modes of connections: text and binary.  The operations
  supported on text and binary connections are mostly disjoint.  Most
  connection classes (socket, file, etc) support both modes.

- textConnection() binds a character vector to a text connection.
  There is no equivalent for a binary connection.  there are
  workarounds (i.e. anonymous connections, equivalent to temporary
  files), but these have substantial performance penalties.

- Both connection modes have useful applications.  textConnection() is
  useful, or it would not exist.  Orthogonality is good, special cases
  are bad.

- Only about 50 lines of code are required to implement a binary form
  of textConnection() in the R core.  Implementing this functionality
  in a separate package requires substantially more code.

- I need it, and in at least one case, another R package developer has
  implemented it using temporary files (caTools).  I also just noticed
  that Duncon Murdoch recently proposed the EXACT SAME feature on
  r-help:

  https://stat.ethz.ch/pipermail/r-help/2005-April/067651.html

I think that just about sums it up.  I've attached a smaller patch
that makes fewer changes to R source, doesn't change any existing
function names, etc.  The feature adds 400 bytes to the size of R.dll.

-- Dave



--- src/main/connections.c.orig	2005-06-17 19:05:02.000000000 -0700
+++ src/main/connections.c	2005-08-31 15:26:19.947195100 -0700
@@ -1644,7 +1644,7 @@
     return ans;
 }
 
-/* ------------------- text connections --------------------- */
+/* ------------------- text and raw connections --------------------- */
 
 /* read a R character vector into a buffer */
 static void text_init(Rconnection con, SEXP text)
@@ -1668,6 +1668,22 @@
     this->cur = this->save = 0;
 }
 
+/* read a R raw vector into a buffer */
+static void raw_init(Rconnection con, SEXP raw)
+{
+    int nbytes = length(raw);
+    Rtextconn this = (Rtextconn)con->private;
+
+    this->data = (char *) malloc(nbytes);
+    if(!this->data) {
+	free(this); free(con->description); free(con->class); free(con);
+	error(_("cannot allocate memory for raw connection"));
+    }
+    memcpy(this->data, RAW(raw), nbytes);
+    this->nchars = nbytes;
+    this->cur = this->save = 0;
+}
+
 static Rboolean text_open(Rconnection con)
 {
     con->save = -1000;
@@ -1702,41 +1718,60 @@
 
 static double text_seek(Rconnection con, double where, int origin, int rw)
 {
-    if(where >= 0) error(_("seek is not relevant for text connection"));
+    if(where >= 0) error(_("seek is not relevant for this connection"));
     return 0; /* if just asking, always at the beginning */
 }
 
-static Rconnection newtext(char *description, SEXP text)
+static size_t raw_read(void *ptr, size_t size, size_t nitems,
+		       Rconnection con)
+{
+    Rtextconn this = (Rtextconn)con->private;
+    if (this->cur + size*nitems > this->nchars) {
+	nitems = (this->nchars - this->cur)/size;
+	memcpy(ptr, this->data+this->cur, size*nitems);
+	this->cur = this->nchars;
+    } else {
+	memcpy(ptr, this->data+this->cur, size*nitems);
+	this->cur += size*nitems;
+    }
+    return nitems;
+}
+
+static Rconnection newtext(char *description, SEXP data)
 {
     Rconnection new;
+    int isText = isString(data);
     new = (Rconnection) malloc(sizeof(struct Rconn));
-    if(!new) error(_("allocation of text connection failed"));
-    new->class = (char *) malloc(strlen("textConnection") + 1);
-    if(!new->class) {
-	free(new);
-	error(_("allocation of text connection failed"));
-    }
-    strcpy(new->class, "textConnection");
+    if(!new) goto f1;
+    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
+    if(!new->class) goto f2;
+    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
     new->description = (char *) malloc(strlen(description) + 1);
-    if(!new->description) {
-	free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->description) goto f3;
     init_con(new, description, "r");
     new->isopen = TRUE;
     new->canwrite = FALSE;
     new->open = &text_open;
     new->close = &text_close;
     new->destroy = &text_destroy;
-    new->fgetc = &text_fgetc;
     new->seek = &text_seek;
     new->private = (void*) malloc(sizeof(struct textconn));
-    if(!new->private) {
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
+    if(!new->private) goto f4;
+    new->text = isText;
+    if (new->text) {
+	new->fgetc = &text_fgetc;
+	text_init(new, data);
+    } else {
+	new->read = &raw_read;
+	raw_init(new, data);
     }
-    text_init(new, text);
     return new;
+
+f4: free(new->description);
+f3: free(new->class);
+f2: free(new);
+f1: error(_("allocation of %s connection failed"),
+	  isText ? "text" : "raw");
 }
 
 static void outtext_close(Rconnection con)
@@ -1830,24 +1865,42 @@
     return res;
 }
 
+static size_t raw_write(const void *ptr, size_t size, size_t nitems,
+			Rconnection con)
+{
+    Routtextconn this = (Routtextconn)con->private;
+    SEXP tmp;
+    int idx = ConnIndex(con);
+
+    PROTECT(tmp = lengthgets(this->data, this->len + size*nitems));
+    memcpy(RAW(tmp)+this->len, ptr, size*nitems);
+    this->len += size*nitems;
+    defineVar(this->namesymbol, tmp, VECTOR_ELT(OutTextData, idx));
+    this->data = tmp;
+    UNPROTECT(1);
+    return nitems;
+}
+
 static void outtext_init(Rconnection con, char *mode, int idx)
 {
     Routtextconn this = (Routtextconn)con->private;
+    int st = (con->text ? STRSXP : RAWSXP);
     SEXP val;
 
     this->namesymbol = install(con->description);
-    if(strcmp(mode, "w") == 0) {
+    if(strncmp(mode, "w", 1) == 0) {
 	/* create variable pointed to by con->description */
-	PROTECT(val = allocVector(STRSXP, 0));
+	PROTECT(val = allocVector(st, 0));
 	defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
 	UNPROTECT(1);
     } else {
 	/* take over existing variable */
 	val = findVar1(this->namesymbol, VECTOR_ELT(OutTextData, idx),
-		       STRSXP, FALSE);
+		       st, FALSE);
 	if(val == R_UnboundValue) {
-	    warning(_("text connection: appending to a non-existent char vector"));
-	    PROTECT(val = allocVector(STRSXP, 0));
+	    warning(_("%s connection: appending to a non-existent vector"),
+		    con->text ? "text" : "raw");
+	    PROTECT(val = allocVector(st, 0));
 	    defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
 	    UNPROTECT(1);
 	}
@@ -1862,43 +1915,43 @@
 static Rconnection newouttext(char *description, SEXP sfile, char *mode,
 			      int idx)
 {
+    int isText = (mode[1] != 'b');
     Rconnection new;
     void *tmp;
 
     new = (Rconnection) malloc(sizeof(struct Rconn));
-    if(!new) error(_("allocation of text connection failed"));
-    new->class = (char *) malloc(strlen("textConnection") + 1);
-    if(!new->class) {
-	free(new);
-	error(_("allocation of text connection failed"));
-    }
-    strcpy(new->class, "textConnection");
+    if(!new) goto f1;
+    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
+    if(!new->class) goto f2;
+    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
     new->description = (char *) malloc(strlen(description) + 1);
-    if(!new->description) {
-	free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->description) goto f3;
     init_con(new, description, mode);
+    new->text = isText;
     new->isopen = TRUE;
     new->canread = FALSE;
     new->open = &text_open;
     new->close = &outtext_close;
     new->destroy = &outtext_destroy;
-    new->vfprintf = &text_vfprintf;
     new->seek = &text_seek;
     new->private = (void*) malloc(sizeof(struct outtextconn));
-    if(!new->private) {
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->private) goto f4;
     ((Routtextconn)new->private)->lastline = tmp = malloc(LAST_LINE_LEN);
-    if(!tmp) {
-	free(new->private);
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
+    if(!tmp) goto f5;
+    if (isText) {
+	new->vfprintf = &text_vfprintf;
+    } else {
+	new->write = &raw_write;
     }
     outtext_init(new, mode, idx);
     return new;
+
+f5: free(new->private);
+f4: free(new->description);
+f3: free(new->class);
+f2: free(new);
+f1: error(_("allocation of %s connection failed"),
+	  isText ? "text" : "raw");
 }
 
 SEXP do_textconnection(SEXP call, SEXP op, SEXP args, SEXP env)
@@ -1914,8 +1967,6 @@
 	error(_("invalid 'description' argument"));
     desc = CHAR(STRING_ELT(sfile, 0));
     stext = CADR(args);
-    if(!isString(stext))
-	error(_("invalid 'text' argument"));
     sopen = CADDR(args);
     if(!isString(sopen) || length(sopen) != 1)
     error(_("invalid 'open' argument"));
@@ -1924,9 +1975,13 @@
     if (!isEnvironment(venv) && venv != R_NilValue)
 	error(_("invalid 'environment' argument"));
     ncon = NextConnection();
-    if(!strlen(open) || strncmp(open, "r", 1) == 0)
+    if(!strlen(open) || (open[0] == 'r')) {
+	if(!isString(stext) && (TYPEOF(stext) != RAWSXP))
+	    error(_("invalid 'object' argument"));
 	con = Connections[ncon] = newtext(desc, stext);
-    else if (strncmp(open, "w", 1) == 0 || strncmp(open, "a", 1) == 0) {
+    } else if ((open[0] == 'w') || (open[0] == 'a')) {
+	if(!isString(stext))
+	    error(_("invalid 'object' argument"));
 	if (OutTextData == NULL) {
 	    OutTextData = allocVector(VECSXP, NCONNECTIONS);
 	    R_PreserveObject(OutTextData);
@@ -1942,7 +1997,7 @@
     PROTECT(ans = allocVector(INTSXP, 1));
     INTEGER(ans)[0] = ncon;
     PROTECT(class = allocVector(STRSXP, 2));
-    SET_STRING_ELT(class, 0, mkChar("textConnection"));
+    SET_STRING_ELT(class, 0, mkChar(con->class));
     SET_STRING_ELT(class, 1, mkChar("connection"));
     classgets(ans, class);
     UNPROTECT(2);


From murdoch at stats.uwo.ca  Thu Sep  1 00:43:29 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 31 Aug 2005 18:43:29 -0400
Subject: [Rd] 64 bit R for Windows
In-Reply-To: <84B25EE9B4CB1A47A197E6AE76790D7801426D07@mail1.lajolla.iattc.org>
References: <84B25EE9B4CB1A47A197E6AE76790D7801426D07@mail1.lajolla.iattc.org>
Message-ID: <43163291.8020505@stats.uwo.ca>

Milton Lopez wrote:
> Duncan:
> 
> Thanks for your reply. Not being a part of the R world and having to assist with these purchases, I have to ask what "not yet" means. I realize that this is a difficult question to answer even for commercial software, but I am hoping you or someone else on the list may shed some additional light on the subject.

I would say it will be at least a year, and most likely longer.  The 
tools used to build R haven't been ported to 64 bit Windows yet.  After 
those are done (by the MinGW project, not us), we'll need someone with a 
64 bit Windows machine to handle builds there.

Duncan Murdoch

> Thanks in advance.
> 
> Milton F. L?pez 
> IT Guy
> Inter-American Tuna Commission (IATTC)
> 8604 La Jolla Shores Drive 
> La Jolla, CA 92037 
> Tel: (858) 546-7041, Fax: (858) 546-7133 
> mlopez at iattc.org 
> http://www.iattc.org
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
> Sent: Tuesday, August 30, 2005 5:39 PM
> To: Milton Lopez
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] 64 bit R for Windows
> 
> Milton Lopez wrote:
> 
>>I am assisting in the purchase of 64-bit Windows XP system for researchers who run R. These systems will have AMD Opteron processors and at least 4GB of RAM. I'd appreciate advice on whether there is a working version of R that can take full advantage of such systems.
> 
> 
> No, there are no 64 bit Windows versions yet.  You'll need to install 
> some 64 bit version of Linux on those machines to take full advantage of 
> the chips.
> 
> Duncan Murdoch


From luke at stat.uiowa.edu  Thu Sep  1 03:03:36 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Wed, 31 Aug 2005 20:03:36 -0500 (CDT)
Subject: [Rd] 64 bit R for Windows
In-Reply-To: <43163291.8020505@stats.uwo.ca>
References: <84B25EE9B4CB1A47A197E6AE76790D7801426D07@mail1.lajolla.iattc.org>
	<43163291.8020505@stats.uwo.ca>
Message-ID: <Pine.LNX.4.63.0508312000350.14940@itasca2.wildberry.org>

On Wed, 31 Aug 2005, Duncan Murdoch wrote:

> Milton Lopez wrote:
>> Duncan:
>>
>> Thanks for your reply. Not being a part of the R world and having to assist with these purchases, I have to ask what "not yet" means. I realize that this is a difficult question to answer even for commercial software, but I am hoping you or someone else on the list may shed some additional light on the subject.
>
> I would say it will be at least a year, and most likely longer.  The
> tools used to build R haven't been ported to 64 bit Windows yet.  After
> those are done (by the MinGW project, not us), we'll need someone with a
> 64 bit Windows machine to handle builds there.
>
> Duncan Murdoch

An additional factor is that MinGW will almost certainly follow the MS
idea that long's are 4 bytes even under Win64, unlike what every other
64-bit OS does.  It will take a fair bit of time and someonw with the
motivation to do so to sort out the consequences (which may not be
very great but even establishing that may be non-trivial).

luke


>
>> Thanks in advance.
>>
>> Milton F. L?pez
>> IT Guy
>> Inter-American Tuna Commission (IATTC)
>> 8604 La Jolla Shores Drive
>> La Jolla, CA 92037
>> Tel: (858) 546-7041, Fax: (858) 546-7133
>> mlopez at iattc.org
>> http://www.iattc.org
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
>> Sent: Tuesday, August 30, 2005 5:39 PM
>> To: Milton Lopez
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] 64 bit R for Windows
>>
>> Milton Lopez wrote:
>>
>>> I am assisting in the purchase of 64-bit Windows XP system for researchers who run R. These systems will have AMD Opteron processors and at least 4GB of RAM. I'd appreciate advice on whether there is a working version of R that can take full advantage of such systems.
>>
>>
>> No, there are no 64 bit Windows versions yet.  You'll need to install
>> some 64 bit version of Linux on those machines to take full advantage of
>> the chips.
>>
>> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From murdoch at stats.uwo.ca  Thu Sep  1 04:30:20 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 31 Aug 2005 22:30:20 -0400
Subject: [Rd] RFC: "loop connections"
In-Reply-To: <df5b90$1ba$1@sea.gmane.org>
References: <dedndn$daj$1@sea.gmane.org>	<17168.15848.291481.473231@stat.math.ethz.ch>
	<df5b90$1ba$1@sea.gmane.org>
Message-ID: <431667BC.7050906@stats.uwo.ca>

dhinds at sonic.net wrote:
> Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> 
>>I think the main point of David's proposal is still worth
>>consideration:  One way to see text connections is as a way to
>>treat some kind of R objects as "generalized files" i.e., connections.
> 
> 
> To summarize the motivation for the proposal, again:
> 
> - There are two modes of connections: text and binary.  The operations
>   supported on text and binary connections are mostly disjoint.  Most
>   connection classes (socket, file, etc) support both modes.
> 
> - textConnection() binds a character vector to a text connection.
>   There is no equivalent for a binary connection.  there are
>   workarounds (i.e. anonymous connections, equivalent to temporary
>   files), but these have substantial performance penalties.
> 
> - Both connection modes have useful applications.  textConnection() is
>   useful, or it would not exist.  Orthogonality is good, special cases
>   are bad.
> 
> - Only about 50 lines of code are required to implement a binary form
>   of textConnection() in the R core.  Implementing this functionality
>   in a separate package requires substantially more code.
> 
> - I need it, and in at least one case, another R package developer has
>   implemented it using temporary files (caTools).  I also just noticed
>   that Duncon Murdoch recently proposed the EXACT SAME feature on
>   r-help:
> 
>   https://stat.ethz.ch/pipermail/r-help/2005-April/067651.html

Since you quote me:

I would implement it differently from the way you did.  I'd call it a 
rawConnection, taking a raw variable (or converting something else using 
as.raw) as the input, and providing both text and binary read/write 
modes (using the same conventions for text mode as a file connection 
would).  It *should* support seek, at least in binary mode.

I would like an implementation that didn't necessarily duplicate the 
whole raw vector into a buffer (it might be big, and people who deal 
with big objects are always short of memory), but this isn't essential, 
it would just be a nice feature.

Now, it would be nice to have something like this, but I'm not likely to 
  have time to do it in the near future.  If you are interested in doing 
this (and documenting it), I'd be willing to take a look at your code 
and commit it when it looked okay.

The deadline for this to make it into 2.2.0 is that I'd want to commit 
it by Sept 6, so there's not a lot of time left.

Duncan Murdoch

> 
> I think that just about sums it up.  I've attached a smaller patch
> that makes fewer changes to R source, doesn't change any existing
> function names, etc.  The feature adds 400 bytes to the size of R.dll.
> 
> -- Dave
> 
> 
> 
> --- src/main/connections.c.orig	2005-06-17 19:05:02.000000000 -0700
> +++ src/main/connections.c	2005-08-31 15:26:19.947195100 -0700
> @@ -1644,7 +1644,7 @@
>      return ans;
>  }
>  
> -/* ------------------- text connections --------------------- */
> +/* ------------------- text and raw connections --------------------- */
>  
>  /* read a R character vector into a buffer */
>  static void text_init(Rconnection con, SEXP text)
> @@ -1668,6 +1668,22 @@
>      this->cur = this->save = 0;
>  }
>  
> +/* read a R raw vector into a buffer */
> +static void raw_init(Rconnection con, SEXP raw)
> +{
> +    int nbytes = length(raw);
> +    Rtextconn this = (Rtextconn)con->private;
> +
> +    this->data = (char *) malloc(nbytes);
> +    if(!this->data) {
> +	free(this); free(con->description); free(con->class); free(con);
> +	error(_("cannot allocate memory for raw connection"));
> +    }
> +    memcpy(this->data, RAW(raw), nbytes);
> +    this->nchars = nbytes;
> +    this->cur = this->save = 0;
> +}
> +
>  static Rboolean text_open(Rconnection con)
>  {
>      con->save = -1000;
> @@ -1702,41 +1718,60 @@
>  
>  static double text_seek(Rconnection con, double where, int origin, int rw)
>  {
> -    if(where >= 0) error(_("seek is not relevant for text connection"));
> +    if(where >= 0) error(_("seek is not relevant for this connection"));
>      return 0; /* if just asking, always at the beginning */
>  }
>  
> -static Rconnection newtext(char *description, SEXP text)
> +static size_t raw_read(void *ptr, size_t size, size_t nitems,
> +		       Rconnection con)
> +{
> +    Rtextconn this = (Rtextconn)con->private;
> +    if (this->cur + size*nitems > this->nchars) {
> +	nitems = (this->nchars - this->cur)/size;
> +	memcpy(ptr, this->data+this->cur, size*nitems);
> +	this->cur = this->nchars;
> +    } else {
> +	memcpy(ptr, this->data+this->cur, size*nitems);
> +	this->cur += size*nitems;
> +    }
> +    return nitems;
> +}
> +
> +static Rconnection newtext(char *description, SEXP data)
>  {
>      Rconnection new;
> +    int isText = isString(data);
>      new = (Rconnection) malloc(sizeof(struct Rconn));
> -    if(!new) error(_("allocation of text connection failed"));
> -    new->class = (char *) malloc(strlen("textConnection") + 1);
> -    if(!new->class) {
> -	free(new);
> -	error(_("allocation of text connection failed"));
> -    }
> -    strcpy(new->class, "textConnection");
> +    if(!new) goto f1;
> +    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
> +    if(!new->class) goto f2;
> +    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
>      new->description = (char *) malloc(strlen(description) + 1);
> -    if(!new->description) {
> -	free(new->class); free(new);
> -	error(_("allocation of text connection failed"));
> -    }
> +    if(!new->description) goto f3;
>      init_con(new, description, "r");
>      new->isopen = TRUE;
>      new->canwrite = FALSE;
>      new->open = &text_open;
>      new->close = &text_close;
>      new->destroy = &text_destroy;
> -    new->fgetc = &text_fgetc;
>      new->seek = &text_seek;
>      new->private = (void*) malloc(sizeof(struct textconn));
> -    if(!new->private) {
> -	free(new->description); free(new->class); free(new);
> -	error(_("allocation of text connection failed"));
> +    if(!new->private) goto f4;
> +    new->text = isText;
> +    if (new->text) {
> +	new->fgetc = &text_fgetc;
> +	text_init(new, data);
> +    } else {
> +	new->read = &raw_read;
> +	raw_init(new, data);
>      }
> -    text_init(new, text);
>      return new;
> +
> +f4: free(new->description);
> +f3: free(new->class);
> +f2: free(new);
> +f1: error(_("allocation of %s connection failed"),
> +	  isText ? "text" : "raw");
>  }
>  
>  static void outtext_close(Rconnection con)
> @@ -1830,24 +1865,42 @@
>      return res;
>  }
>  
> +static size_t raw_write(const void *ptr, size_t size, size_t nitems,
> +			Rconnection con)
> +{
> +    Routtextconn this = (Routtextconn)con->private;
> +    SEXP tmp;
> +    int idx = ConnIndex(con);
> +
> +    PROTECT(tmp = lengthgets(this->data, this->len + size*nitems));
> +    memcpy(RAW(tmp)+this->len, ptr, size*nitems);
> +    this->len += size*nitems;
> +    defineVar(this->namesymbol, tmp, VECTOR_ELT(OutTextData, idx));
> +    this->data = tmp;
> +    UNPROTECT(1);
> +    return nitems;
> +}
> +
>  static void outtext_init(Rconnection con, char *mode, int idx)
>  {
>      Routtextconn this = (Routtextconn)con->private;
> +    int st = (con->text ? STRSXP : RAWSXP);
>      SEXP val;
>  
>      this->namesymbol = install(con->description);
> -    if(strcmp(mode, "w") == 0) {
> +    if(strncmp(mode, "w", 1) == 0) {
>  	/* create variable pointed to by con->description */
> -	PROTECT(val = allocVector(STRSXP, 0));
> +	PROTECT(val = allocVector(st, 0));
>  	defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
>  	UNPROTECT(1);
>      } else {
>  	/* take over existing variable */
>  	val = findVar1(this->namesymbol, VECTOR_ELT(OutTextData, idx),
> -		       STRSXP, FALSE);
> +		       st, FALSE);
>  	if(val == R_UnboundValue) {
> -	    warning(_("text connection: appending to a non-existent char vector"));
> -	    PROTECT(val = allocVector(STRSXP, 0));
> +	    warning(_("%s connection: appending to a non-existent vector"),
> +		    con->text ? "text" : "raw");
> +	    PROTECT(val = allocVector(st, 0));
>  	    defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
>  	    UNPROTECT(1);
>  	}
> @@ -1862,43 +1915,43 @@
>  static Rconnection newouttext(char *description, SEXP sfile, char *mode,
>  			      int idx)
>  {
> +    int isText = (mode[1] != 'b');
>      Rconnection new;
>      void *tmp;
>  
>      new = (Rconnection) malloc(sizeof(struct Rconn));
> -    if(!new) error(_("allocation of text connection failed"));
> -    new->class = (char *) malloc(strlen("textConnection") + 1);
> -    if(!new->class) {
> -	free(new);
> -	error(_("allocation of text connection failed"));
> -    }
> -    strcpy(new->class, "textConnection");
> +    if(!new) goto f1;
> +    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
> +    if(!new->class) goto f2;
> +    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
>      new->description = (char *) malloc(strlen(description) + 1);
> -    if(!new->description) {
> -	free(new->class); free(new);
> -	error(_("allocation of text connection failed"));
> -    }
> +    if(!new->description) goto f3;
>      init_con(new, description, mode);
> +    new->text = isText;
>      new->isopen = TRUE;
>      new->canread = FALSE;
>      new->open = &text_open;
>      new->close = &outtext_close;
>      new->destroy = &outtext_destroy;
> -    new->vfprintf = &text_vfprintf;
>      new->seek = &text_seek;
>      new->private = (void*) malloc(sizeof(struct outtextconn));
> -    if(!new->private) {
> -	free(new->description); free(new->class); free(new);
> -	error(_("allocation of text connection failed"));
> -    }
> +    if(!new->private) goto f4;
>      ((Routtextconn)new->private)->lastline = tmp = malloc(LAST_LINE_LEN);
> -    if(!tmp) {
> -	free(new->private);
> -	free(new->description); free(new->class); free(new);
> -	error(_("allocation of text connection failed"));
> +    if(!tmp) goto f5;
> +    if (isText) {
> +	new->vfprintf = &text_vfprintf;
> +    } else {
> +	new->write = &raw_write;
>      }
>      outtext_init(new, mode, idx);
>      return new;
> +
> +f5: free(new->private);
> +f4: free(new->description);
> +f3: free(new->class);
> +f2: free(new);
> +f1: error(_("allocation of %s connection failed"),
> +	  isText ? "text" : "raw");
>  }
>  
>  SEXP do_textconnection(SEXP call, SEXP op, SEXP args, SEXP env)
> @@ -1914,8 +1967,6 @@
>  	error(_("invalid 'description' argument"));
>      desc = CHAR(STRING_ELT(sfile, 0));
>      stext = CADR(args);
> -    if(!isString(stext))
> -	error(_("invalid 'text' argument"));
>      sopen = CADDR(args);
>      if(!isString(sopen) || length(sopen) != 1)
>      error(_("invalid 'open' argument"));
> @@ -1924,9 +1975,13 @@
>      if (!isEnvironment(venv) && venv != R_NilValue)
>  	error(_("invalid 'environment' argument"));
>      ncon = NextConnection();
> -    if(!strlen(open) || strncmp(open, "r", 1) == 0)
> +    if(!strlen(open) || (open[0] == 'r')) {
> +	if(!isString(stext) && (TYPEOF(stext) != RAWSXP))
> +	    error(_("invalid 'object' argument"));
>  	con = Connections[ncon] = newtext(desc, stext);
> -    else if (strncmp(open, "w", 1) == 0 || strncmp(open, "a", 1) == 0) {
> +    } else if ((open[0] == 'w') || (open[0] == 'a')) {
> +	if(!isString(stext))
> +	    error(_("invalid 'object' argument"));
>  	if (OutTextData == NULL) {
>  	    OutTextData = allocVector(VECSXP, NCONNECTIONS);
>  	    R_PreserveObject(OutTextData);
> @@ -1942,7 +1997,7 @@
>      PROTECT(ans = allocVector(INTSXP, 1));
>      INTEGER(ans)[0] = ncon;
>      PROTECT(class = allocVector(STRSXP, 2));
> -    SET_STRING_ELT(class, 0, mkChar("textConnection"));
> +    SET_STRING_ELT(class, 0, mkChar(con->class));
>      SET_STRING_ELT(class, 1, mkChar("connection"));
>      classgets(ans, class);
>      UNPROTECT(2);
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dhinds at sonic.net  Thu Sep  1 07:09:48 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Thu, 1 Sep 2005 05:09:48 +0000 (UTC)
Subject: [Rd] RFC: rawConnection (was "loop connections")
References: <dedndn$daj$1@sea.gmane.org>
	<17168.15848.291481.473231@stat.math.ethz.ch>
	<df5b90$1ba$1@sea.gmane.org> <431667BC.7050906@stats.uwo.ca>
Message-ID: <df62er$jab$1@sea.gmane.org>

Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> I would implement it differently from the way you did.  I'd call it
> a rawConnection, taking a raw variable (or converting something else
> using as.raw) as the input, and providing both text and binary
> read/write modes (using the same conventions for text mode as a file
> connection would).  It *should* support seek, at least in binary
> mode.

I was trying to reuse as much of the textConnection semantics and
underlying code as possible...

Having a rawConnection() entry point is simple enough.  Seeking also
seems straightforward.  I'm not so sure about using as.raw().  I
wondered about that, but also thought that rather than coercing to
raw, it might make more sense to cast atomic vector types to raw,
byte-for-byte.

Can you given an example of where a text-mode raw connection would be
a useful thing?

-- Dave


From kkrueger at einthal.de  Thu Sep  1 11:07:52 2005
From: kkrueger at einthal.de (kkrueger@einthal.de)
Date: Thu,  1 Sep 2005 11:07:52 +0200 (CEST)
Subject: [Rd] whislist (PR#8117)
Message-ID: <20050901090752.7A2F010DDA@slim.kubism.ku.dk>

Full_Name: Knut Krueger
Version: 
OS: 
Submission from: (NULL) (217.250.214.33)


Maybe it is an idea to copy the hints f.e -> help.search("...") in the
commandline or in the memory to paste it into the commandline.
maybe you could build in an option entry to start the search with help.search
automatically if there is no entry with the ? function

?deviation
No documentation for 'deviation' in specified packages and libraries:
you could try 'help.search("deviation")'

Regards Knut


From p.dalgaard at biostat.ku.dk  Thu Sep  1 12:08:42 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Sep 2005 12:08:42 +0200
Subject: [Rd] R 2.2.0 slated for October 6
Message-ID: <x2acix5cd1.fsf@turmalin.kubism.ku.dk>


We plan to release R version 2.2.0 on October 6. Daily alpha releases
will be available after the "Grand feature" freeze on September 8 and
beta releases from September 22. The full schedule is available on
http://developer.r-project.org (pending propagation delay from
https://svn.r-project.org/R-dev-web/trunk/index.html).

As usual, it is strongly preferred if bugs are discovered prior to the
release and not immediately afterwards! Please do try the
alpha/beta releases and report back any errors.

        On behalf of the R Core Team
        Peter Dalgaard

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Thu Sep  1 12:32:19 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 01 Sep 2005 06:32:19 -0400
Subject: [Rd] RFC: rawConnection (was "loop connections")
In-Reply-To: <df62er$jab$1@sea.gmane.org>
References: <dedndn$daj$1@sea.gmane.org>	<17168.15848.291481.473231@stat.math.ethz.ch>	<df5b90$1ba$1@sea.gmane.org>
	<431667BC.7050906@stats.uwo.ca> <df62er$jab$1@sea.gmane.org>
Message-ID: <4316D8B3.3040504@stats.uwo.ca>

dhinds at sonic.net wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
> 
>>I would implement it differently from the way you did.  I'd call it
>>a rawConnection, taking a raw variable (or converting something else
>>using as.raw) as the input, and providing both text and binary
>>read/write modes (using the same conventions for text mode as a file
>>connection would).  It *should* support seek, at least in binary
>>mode.
> 
> 
> I was trying to reuse as much of the textConnection semantics and
> underlying code as possible...
> 
> Having a rawConnection() entry point is simple enough.  Seeking also
> seems straightforward.  I'm not so sure about using as.raw().  I
> wondered about that, but also thought that rather than coercing to
> raw, it might make more sense to cast atomic vector types to raw,
> byte-for-byte.

I'd prefer as.raw, so that we don't end up with two incompatible ways to 
convert other objects to raw objects.

> Can you given an example of where a text-mode raw connection would be
> a useful thing?

No, but someone else might.  Why unnecessarily let the source of the 
bytes determine the mode of the connection?  In the case of 
textConnection, there are natural line breaks, so a text mode connection 
makes sense.  A raw object can contain anything, so why wouldn't someone 
want to put text in it some day?

Duncan Murdoch


From S.J.Eglen at damtp.cam.ac.uk  Thu Sep  1 13:09:15 2005
From: S.J.Eglen at damtp.cam.ac.uk (Stephen Eglen)
Date: Thu, 1 Sep 2005 12:09:15 +0100
Subject: [Rd] R CMD BATCH on scripts without trailing newline
Message-ID: <17174.57691.868797.92193@notch.amtp.cam.ac.uk>


If the last line of an R script does not have a trailing newline, a
small errror is produced at the end of the script.

Small example.  If file eg.r contains one line:
getwd()
and there is no newline after the closing paren

$ R CMD BATCH eg.r

produces an error:
$ cat eg.r.Rout 

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.1 Patched (2005-09-01), ISBN 3-900051-07-0

...

> getwd()proc.time()
Error: syntax error
Execution halted
$ 

Is it worth changing the BATCH script so that it adds a newline before
adding the call to proc.time()?

Stephen


From maechler at stat.math.ethz.ch  Thu Sep  1 13:39:52 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Sep 2005 13:39:52 +0200
Subject: [Rd] R CMD BATCH on scripts without trailing newline
In-Reply-To: <17174.57691.868797.92193@notch.amtp.cam.ac.uk>
References: <17174.57691.868797.92193@notch.amtp.cam.ac.uk>
Message-ID: <17174.59528.327720.694835@stat.math.ethz.ch>

>>>>> "StEgl" == Stephen Eglen <S.J.Eglen at damtp.cam.ac.uk>
>>>>>     on Thu, 1 Sep 2005 12:09:15 +0100 writes:

    StEgl> If the last line of an R script does not have a
    StEgl> trailing newline, a small errror is produced at the
    StEgl> end of the script.

    StEgl> Small example.  If file eg.r contains one line:
    StEgl> getwd() and there is no newline after the closing
    StEgl> paren

    StEgl> $ R CMD BATCH eg.r

    StEgl> produces an error: $ cat eg.r.Rout

    StEgl> R : Copyright 2005, The R Foundation for Statistical
    StEgl> Computing Version 2.1.1 Patched (2005-09-01), ISBN
    StEgl> 3-900051-07-0

    StEgl> ...

    >> getwd()proc.time()
    StEgl> Error: syntax error Execution halted $

aahh, now I finally understand via some people append
those **ugly** unneeded ';' to the end of almost every line of R
code.  It would have helped here
:-) :-)

    StEgl> Is it worth changing the BATCH script so that it adds
    StEgl> a newline before adding the call to proc.time()?

Yes I think it would be.  This is trivial, at least for 
 <Rsrc>/src/scripts/BATCH
Slightly better but more tricky:  only append a newline "when needed".
Any idea for that?

You didn't tell us the *platform* you run R on
(and BATCH does depend on the platform),
but I know that it's a version of unix,  Linux I suppose?

BTW: The windows version of "R CMD BATCH" is actually
     *documented* do to work with files that don't end in newline.

Martin


From S.J.Eglen at damtp.cam.ac.uk  Thu Sep  1 13:43:05 2005
From: S.J.Eglen at damtp.cam.ac.uk (Stephen Eglen)
Date: Thu, 1 Sep 2005 12:43:05 +0100
Subject: [Rd] R CMD BATCH on scripts without trailing newline
In-Reply-To: <17174.59528.327720.694835@stat.math.ethz.ch>
References: <17174.57691.868797.92193@notch.amtp.cam.ac.uk>
	<17174.59528.327720.694835@stat.math.ethz.ch>
Message-ID: <17174.59721.921026.270236@notch.amtp.cam.ac.uk>


 > You didn't tell us the *platform* you run R on
 > (and BATCH does depend on the platform),
 > but I know that it's a version of unix,  Linux I suppose?

Thanks Martin.  Yes, linux - scientific linux 3 here.


From jtk at cmp.uea.ac.uk  Thu Sep  1 14:57:39 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Thu, 1 Sep 2005 13:57:39 +0100
Subject: [Rd] R CMD BATCH on scripts without trailing newline
In-Reply-To: <17174.59528.327720.694835@stat.math.ethz.ch>
References: <17174.57691.868797.92193@notch.amtp.cam.ac.uk>
	<17174.59528.327720.694835@stat.math.ethz.ch>
Message-ID: <20050901125739.GB5066@jtkpc.cmp.uea.ac.uk>

On Thu, Sep 01, 2005 at 01:39:52PM +0200, Martin Maechler wrote:

>     >> getwd()proc.time()
>     StEgl> Error: syntax error Execution halted $
> 
> aahh, now I finally understand via some people append
> those **ugly** unneeded ';' to the end of almost every line of R
> code.  It would have helped here
> :-) :-)

What is the problem with the semicolons? Ugliness is in the eye of
the beholder, evidently, but on a more objective level, terminating
statements by an explicit and visible separator seems like a very
reasonable idea to me.

>     StEgl> Is it worth changing the BATCH script so that it adds
>     StEgl> a newline before adding the call to proc.time()?
> 
> Yes I think it would be.  This is trivial, at least for 
>  <Rsrc>/src/scripts/BATCH
> Slightly better but more tricky:  only append a newline "when needed".
> Any idea for that?

I think this is a dangerous direction of thought. Having a "terminator
if apparently needed" semantics of newline has already brought us the
inconsistency of if / else parsing inside and outside of blocks. No more
of that, please.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk at cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From jh910 at juno.com  Thu Sep  1 15:46:19 2005
From: jh910 at juno.com (J. Hosking)
Date: Thu, 01 Sep 2005 09:46:19 -0400
Subject: [Rd] strwrap
Message-ID: <df70nd$iee$1@sea.gmane.org>

The maximum length of a character string returned by strwrap,
i.e. max(nchar(strwrap(x,width))), never in my experience exceeds
width-2 (unless x contains a word that is longer than this).
This is not exactly a bug -- width is described only as a "target
column for wrapping lines" -- but seems odd.

Though I don't understand everything that the code is doing,
I think that the first line in the "while" block,

   k <- max(sum(lens < maxLength), 1)

should be replaced by

   k <- max(sum(lens <= maxLength + 1), 1)

-- here lens[i] is the number of characters in the string
that consists of the first i words *with a trailing space*,
so there is no need to split unless this number exceeds
the target width plus one.

A code snippet for testing:

    x <- paste(sapply(sample(10, 100, rep=T),
      function(x) substring("aaaaaaaaaa", 1, x)), collapse=" ")
    sapply(10:40, function(m) c(requested.width=m,
      actual.width=max(nchar(strwrap(x, m)))))

Tested on:

   > R.version
          _
   platform i386-pc-mingw32
   arch     i386
   os       mingw32
   system   i386, mingw32
   status   Under development (unstable)
   major    2
   minor    2.0
   year     2005
   month    08
   day      29
   svn rev  35457
   language R



J. R. M. Hosking


From r.hankin at noc.soton.ac.uk  Thu Sep  1 15:57:01 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 1 Sep 2005 14:57:01 +0100
Subject: [Rd] generic function S3 consistency warning advice
Message-ID: <3128D6C1-B044-4CBF-8D7C-21A0B52D9904@soc.soton.ac.uk>

Hi

section 6.1 of R-exts suggests that a package  can take over a  
function in the base
package and make it generic.

I want to do this with Re() and have the following lines in my R code:



"Re" <- function(x){UseMethod("Re" )}
"Re.default" <- get("Re" ,pos=NULL,mode="function")
"Re.octonion" <- function(x){give.comp(x,1)}

This, however, generates the following warning from R CMD check:

* checking S3 generic/method consistency ... WARNING
Re:
   function(x)
Re.default:
   function()

See section 'Generic functions and methods' of the 'Writing R  
Extensions'
manual.



I can suppress the warning by commenting out the first line.  Is this a
sensible thing to do?




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From hb at maths.lth.se  Thu Sep  1 16:31:58 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 01 Sep 2005 16:31:58 +0200
Subject: [Rd] generic function S3 consistency warning advice
In-Reply-To: <3128D6C1-B044-4CBF-8D7C-21A0B52D9904@soc.soton.ac.uk>
References: <3128D6C1-B044-4CBF-8D7C-21A0B52D9904@soc.soton.ac.uk>
Message-ID: <431710DE.5060803@maths.lth.se>

This happens because you get a primitive function. However, I believe 
Re() is already an generic function ("too") internally, so you do not 
have to create your own and redefine the default one.  (I'm not sure if 
there is another way to tell if a primitive function is also a generic 
function than to look at the C source code or by trial-and-error).

Try:

% R --vanilla
 > Re.MyClass <- function(x) NA
 > x <- structure(3, class="MyClass")
 > Re(5+3i)
5
 > Re(x)
NA

/Henrik

Robin Hankin wrote:
> Hi
> 
> section 6.1 of R-exts suggests that a package  can take over a  
> function in the base
> package and make it generic.
> 
> I want to do this with Re() and have the following lines in my R code:
> 
> 
> 
> "Re" <- function(x){UseMethod("Re" )}
> "Re.default" <- get("Re" ,pos=NULL,mode="function")
> "Re.octonion" <- function(x){give.comp(x,1)}
> 
> This, however, generates the following warning from R CMD check:
> 
> * checking S3 generic/method consistency ... WARNING
> Re:
>    function(x)
> Re.default:
>    function()
> 
> See section 'Generic functions and methods' of the 'Writing R  
> Extensions'
> manual.
> 
> 
> 
> I can suppress the warning by commenting out the first line.  Is this a
> sensible thing to do?
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ligges at statistik.uni-dortmund.de  Thu Sep  1 18:23:05 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Thu,  1 Sep 2005 18:23:05 +0200 (CEST)
Subject: [Rd] R CMD check example problem (PR#8113)
Message-ID: <20050901162305.90E5B11353@slim.kubism.ku.dk>

[CCing to r-bugs to inform people that we have looked at it.]

Greg,

you sent me the example which can be reduced to an example.Rd file that 
contains the following Example section:


############################
\examples{
# \code{} \code{}
foo <- function()
{
}
}
############################

calling now
    R CMD Rdconv -t example example.Rd
results in:



############################
### ** Examples

# this-is-escaped-code{ this-is-escaped-codenormal-bracket9bracket-normal
foo <- function()
normal-bracket10bracket-normal
normal-bracket10bracket-normal
############################


I do not know whether this qualifies as a bug, but for simplicity let's say:
"Don't use \code{} in an Example section where it does not make sense 
anyway."

Best,
Uwe






Warnes, Gregory R wrote:

> 
>>-----Original Message-----
>>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
>>Sent: Thursday, September 01, 2005 8:57 AM
>>To: Warnes, Gregory R
>>Subject: Re: [Rd] R CMD check example problem (PR#8113)
>>
>>
>>Greg,
>>
>>the attachment is not appended on the forwarded message to 
>>R-devel, and 
>>I would like to take a look, can you send it in a private 
>>message, please?
>>
>>Best,
>>Uwe
>>
>>Warnes, Gregory R wrote:
>>
>>
>>>[Automatic forwarding from R-bugs failed.  This message has 
>>
>>been manually
>>
>>>forwarded.]
>>>
>>>Hi all!
>>>
>>>I'm trying to add Thomas Lumley's defmacro() function  Lumley T.
>>>"Programmer's Niche: Macros in {R}", R News, 2001, Vol 1,
>>>  No. 3, pp 11--13, 
>>
>>\url{http://CRAN.R-project.org/doc/Rnews/} to the gtools
>>
>>>package (provided that Thomas gives his OK). And I've 
>>
>>encountered an error
>>
>>>in how R CMD check is extracting the example code I have in 
>>
>>the .Rd file.
>>
>>>The example section contains the lines 
>>>
>>>  # An equivalent function is somewhat messier, since it must either
>>>explicitly
>>>  # construct the y axis label, duplicating some of the 
>>
>>work of the plot
>>
>>>  # function:
>>>  plotit <- function( df, var, col="red", title="" )
>>>  {
>>>      dname <- deparse(substitute(df))
>>>      vname <- deparse(substitute(var))
>>>      plot( df[[vname]] ~ df$Grp, type="b", col=col, title=title,
>>>            ylab=paste( dname, "$", vname, sep='' ) )
>>>  }
>>>  # or we explicitly construct the call and then call eval. 
>>
>> The code for
>>
>>>  # the latter approach is # omiited since this is quite messy and
>>>  # requires a lot of work.
>>>  
>>>which is getting extracted for testing into 
>>
>>gtools.Rcheck/gtools-Ex.R as
>>
>>>  # An equivalent function is somewhat messier, since it must either
>>>explicitly
>>>  # construct the y axis label, duplicating some of the 
>>
>>work of the plot
>>
>>>  # function:
>>>  plotit <- function( df, var, col="red", title=""
>>>)normal-bracket43bracket-normal
>>>      dname <- deparse(substitute(df))
>>>      vname <- deparse(substitute(var))
>>>      plot( df[[vname]] ~ df$Grp, type="b", col=col, title=title,
>>>            ylab=paste( dname, "$", vname, sep='' ) )
>>>  normal-bracket43bracket-normal
>>>  # or we explicitly construct the call and then call eval. 
>>
>> The code for
>>
>>>  # the latter approach is # omiited since this is quite messy and
>>>  # requires a lot of work.
>>>
>>>Note that the opening and closing curly brakkets are 
>>
>>converted to the string
>>
>>>"normal-bracket43bracket-normal".   [I assume that this is happeing
>>>somewhere to check for brace-matches, and isn't being 
>>
>>properly undone.]  As
>>
>>>a consequence, R CMD check is failing:
>>>
>>>  > # An equivalent function is somewhat messier, since it 
>>
>>must either
>>
>>>explicitly
>>>  > # construct the y axis label, duplicating some of the 
>>
>>work of the plot
>>
>>>  > # function:
>>>  > plotit <- function( df, var, col="red", title=""
>>>)normal-bracket43bracket-normal
>>>  >     dname <- deparse(substitute(df))
>>>  >     vname <- deparse(substitute(var))
>>>  >     plot( df[[vname]] ~ df$Grp, type="b", col=col, title=title,
>>>  +           ylab=paste( dname, "$", vname, sep='' ) )
>>>  Error in df[[vname]] : object is not subsettable
>>>  Execution halted
>>>
>>>I've checked, and this occurs under R-2.1.0, R-2.1.1, and today's
>>>R-2.2.0-devel on my
>>>
>>>  platform i686-pc-linux-gnu
>>>  arch     i686             
>>>  os       linux-gnu        
>>>  system   i686, linux-gnu  
>>>
>>>I'm attaching the probelmatic .Rd file to this email.  
>>>
>>>  <<defmacro.Rd>> 
>>>
>>>(For the record, I've simply enclosed the problematic 
>>
>>section in \dontrun as
>>
>>>a workaround.)
>>>
>>>-Greg
>>>
>>>
>>>
>>>Gregory R. Warnes, Ph.D.
>>>Associate Director, Non-Clinical Statistics
>>>Pfizer Global Research and Development
>>>
>>>
>>>
>>>LEGAL NOTICE
>>>Unless expressly stated otherwise, this message is 
>>
>>confidential and may be privileged. It is intended for the 
>>addressee(s) only. Access to this E-mail by anyone else is 
>>unauthorized. If you are not an addressee, any disclosure or 
>>copying of the contents of this E-mail or any action taken 
>>(or not taken) in reliance on it is unauthorized and may be 
>>unlawful. If you are not an addressee, please inform the 
>>sender immediately.
>>
>>>
>>>
>>--------------------------------------------------------------
>>----------
>>
>>>______________________________________________
>>>R-devel at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>


From gunter.berton at gene.com  Thu Sep  1 18:34:08 2005
From: gunter.berton at gene.com (gunter.berton@gene.com)
Date: Thu,  1 Sep 2005 18:34:08 +0200 (CEST)
Subject: [Rd] error in apply help file? (PR#8118)
Message-ID: <20050901163408.0002B15FE2@slim.kubism.ku.dk>

Gents: (alas, I think no ladies need to be included in the salutation)

The apply()  Help file says
"...
If the calls to FUN return vectors of different lengths, apply returns a
list of length dim(X)[MARGIN]. "

Shouldn't that be:

"If the calls to FUN return vectors of different lengths, apply returns a
list of length prod(dim(X)[MARGIN]). "

Also, might you wish to add:

"This list has a dim attribute of MARGIN. That is, if VALUE is the returned
list, dim(VALUE) = MARGIN and the values in VALUE can be accessed by the
usual array subscripting operations."

Further, it might also be useful to add the following to your Examples code:

## Example with different lengths for each call
z <- array(1:24,dim=2:4)
zseq <- apply(z,1:2,function(x)seq(length=max(x)))
zseq  ## displayed as a 2 x 3 matrix
typeof(zseq) ## list
dim(zseq) ## 2 3
zseq[1,]


Feel free to ignore these suggestions, of course. 

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA


From gregory.r.warnes at pfizer.com  Thu Sep  1 18:47:22 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Thu, 1 Sep 2005 12:47:22 -0400 
Subject: [Rd] R CMD check example problem (PR#8113)
Message-ID: <915D2D65A9986440A277AC5C98AA466F01863258@groamrexm02.amer.pfizer.com>

Ahh.  I didn't notice that my fingers had used \code() inside of the example
section.  I've removed them, and everything seems to be working properly
now.  

-G

> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org]On Behalf Of
> ligges at statistik.uni-dortmund.de
> Sent: Thursday, September 01, 2005 12:23 PM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: Re: [Rd] R CMD check example problem (PR#8113)
> 
> 
> [CCing to r-bugs to inform people that we have looked at it.]
> 
> Greg,
> 
> you sent me the example which can be reduced to an example.Rd 
> file that 
> contains the following Example section:
> 
> 
> ############################
> \examples{
> # \code{} \code{}
> foo <- function()
> {
> }
> }
> ############################
> 
> calling now
>     R CMD Rdconv -t example example.Rd
> results in:
> 
> 
> 
> ############################
> ### ** Examples
> 
> # this-is-escaped-code{ 
> this-is-escaped-codenormal-bracket9bracket-normal
> foo <- function()
> normal-bracket10bracket-normal
> normal-bracket10bracket-normal
> ############################
> 
> 
> I do not know whether this qualifies as a bug, but for 
> simplicity let's say:
> "Don't use \code{} in an Example section where it does not make sense 
> anyway."
> 
> Best,
> Uwe
> 
> 
> 
> 
> 
> 
> Warnes, Gregory R wrote:
> 
> > 
> >>-----Original Message-----
> >>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> >>Sent: Thursday, September 01, 2005 8:57 AM
> >>To: Warnes, Gregory R
> >>Subject: Re: [Rd] R CMD check example problem (PR#8113)
> >>
> >>
> >>Greg,
> >>
> >>the attachment is not appended on the forwarded message to 
> >>R-devel, and 
> >>I would like to take a look, can you send it in a private 
> >>message, please?
> >>
> >>Best,
> >>Uwe
> >>
> >>Warnes, Gregory R wrote:
> >>
> >>
> >>>[Automatic forwarding from R-bugs failed.  This message has 
> >>
> >>been manually
> >>
> >>>forwarded.]
> >>>
> >>>Hi all!
> >>>
> >>>I'm trying to add Thomas Lumley's defmacro() function  Lumley T.
> >>>"Programmer's Niche: Macros in {R}", R News, 2001, Vol 1,
> >>>  No. 3, pp 11--13, 
> >>
> >>\url{http://CRAN.R-project.org/doc/Rnews/} to the gtools
> >>
> >>>package (provided that Thomas gives his OK). And I've 
> >>
> >>encountered an error
> >>
> >>>in how R CMD check is extracting the example code I have in 
> >>
> >>the .Rd file.
> >>
> >>>The example section contains the lines 
> >>>
> >>>  # An equivalent function is somewhat messier, since it 
> must either
> >>>explicitly
> >>>  # construct the y axis label, duplicating some of the 
> >>
> >>work of the plot
> >>
> >>>  # function:
> >>>  plotit <- function( df, var, col="red", title="" )
> >>>  {
> >>>      dname <- deparse(substitute(df))
> >>>      vname <- deparse(substitute(var))
> >>>      plot( df[[vname]] ~ df$Grp, type="b", col=col, title=title,
> >>>            ylab=paste( dname, "$", vname, sep='' ) )
> >>>  }
> >>>  # or we explicitly construct the call and then call eval. 
> >>
> >> The code for
> >>
> >>>  # the latter approach is # omiited since this is quite messy and
> >>>  # requires a lot of work.
> >>>  
> >>>which is getting extracted for testing into 
> >>
> >>gtools.Rcheck/gtools-Ex.R as
> >>
> >>>  # An equivalent function is somewhat messier, since it 
> must either
> >>>explicitly
> >>>  # construct the y axis label, duplicating some of the 
> >>
> >>work of the plot
> >>
> >>>  # function:
> >>>  plotit <- function( df, var, col="red", title=""
> >>>)normal-bracket43bracket-normal
> >>>      dname <- deparse(substitute(df))
> >>>      vname <- deparse(substitute(var))
> >>>      plot( df[[vname]] ~ df$Grp, type="b", col=col, title=title,
> >>>            ylab=paste( dname, "$", vname, sep='' ) )
> >>>  normal-bracket43bracket-normal
> >>>  # or we explicitly construct the call and then call eval. 
> >>
> >> The code for
> >>
> >>>  # the latter approach is # omiited since this is quite messy and
> >>>  # requires a lot of work.
> >>>
> >>>Note that the opening and closing curly brakkets are 
> >>
> >>converted to the string
> >>
> >>>"normal-bracket43bracket-normal".   [I assume that this is happeing
> >>>somewhere to check for brace-matches, and isn't being 
> >>
> >>properly undone.]  As
> >>
> >>>a consequence, R CMD check is failing:
> >>>
> >>>  > # An equivalent function is somewhat messier, since it 
> >>
> >>must either
> >>
> >>>explicitly
> >>>  > # construct the y axis label, duplicating some of the 
> >>
> >>work of the plot
> >>
> >>>  > # function:
> >>>  > plotit <- function( df, var, col="red", title=""
> >>>)normal-bracket43bracket-normal
> >>>  >     dname <- deparse(substitute(df))
> >>>  >     vname <- deparse(substitute(var))
> >>>  >     plot( df[[vname]] ~ df$Grp, type="b", col=col, title=title,
> >>>  +           ylab=paste( dname, "$", vname, sep='' ) )
> >>>  Error in df[[vname]] : object is not subsettable
> >>>  Execution halted
> >>>
> >>>I've checked, and this occurs under R-2.1.0, R-2.1.1, and today's
> >>>R-2.2.0-devel on my
> >>>
> >>>  platform i686-pc-linux-gnu
> >>>  arch     i686             
> >>>  os       linux-gnu        
> >>>  system   i686, linux-gnu  
> >>>
> >>>I'm attaching the probelmatic .Rd file to this email.  
> >>>
> >>>  <<defmacro.Rd>> 
> >>>
> >>>(For the record, I've simply enclosed the problematic 
> >>
> >>section in \dontrun as
> >>
> >>>a workaround.)
> >>>
> >>>-Greg
> >>>
> >>>
> >>>
> >>>Gregory R. Warnes, Ph.D.
> >>>Associate Director, Non-Clinical Statistics
> >>>Pfizer Global Research and Development
> >>>
> >>>
> >>>
> >>>LEGAL NOTICE
> >>>Unless expressly stated otherwise, this message is 
> >>
> >>confidential and may be privileged. It is intended for the 
> >>addressee(s) only. Access to this E-mail by anyone else is 
> >>unauthorized. If you are not an addressee, any disclosure or 
> >>copying of the contents of this E-mail or any action taken 
> >>(or not taken) in reliance on it is unauthorized and may be 
> >>unlawful. If you are not an addressee, please inform the 
> >>sender immediately.
> >>
> >>>
> >>>
> >>--------------------------------------------------------------
> >>----------
> >>
> >>>______________________________________________
> >>>R-devel at r-project.org mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >>
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From dhinds at sonic.net  Thu Sep  1 18:58:44 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Thu, 1 Sep 2005 16:58:44 +0000 (UTC)
Subject: [Rd] RFC: rawConnection (was "loop connections")
References: <dedndn$daj$1@sea.gmane.org>
	<17168.15848.291481.473231@stat.math.ethz.ch>
	<df5b90$1ba$1@sea.gmane.org> <431667BC.7050906@stats.uwo.ca>
	<df62er$jab$1@sea.gmane.org> <4316D8B3.3040504@stats.uwo.ca>
Message-ID: <df7c03$s62$1@sea.gmane.org>

Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > 
> > Having a rawConnection() entry point is simple enough.  Seeking also
> > seems straightforward.  I'm not so sure about using as.raw().  I
> > wondered about that, but also thought that rather than coercing to
> > raw, it might make more sense to cast atomic vector types to raw,
> > byte-for-byte.

> I'd prefer as.raw, so that we don't end up with two incompatible ways to 
> convert other objects to raw objects.

An advantage of no as.raw() would be that you could create a raw
connection on an object without making an extra copy, which was
another of your requests.  But there would be a lack of symmetry,
because you could "r" from an arbitrary R object, but only "w" to raw,
unless there was also a way of specifying a type for the result
vector.

Having the backing store be an R object with no copy does seem tricky,
however.  Currently, textConnection() makes a copy for "r" connections
but writes directly to an R object for "w" connections.  The "w" case
is buggy; you can crash R by removing the target object while the
connection is being used.  I'm not familiar enough with R internals to
know how to fix that.  Maybe the object has to be searched for every
time the connection is used, to avoid potentially stale pointers?

> > Can you given an example of where a text-mode raw connection would be
> > a useful thing?

> No, but someone else might.  Why unnecessarily let the source of the 
> bytes determine the mode of the connection?  In the case of 
> textConnection, there are natural line breaks, so a text mode connection 
> makes sense.  A raw object can contain anything, so why wouldn't someone 
> want to put text in it some day?

It seems that that a text-mode raw connection would be equivalent to a
textConnection on the result of rawToChar(), no?

While some of these possibilities seem like they might be useful, I'm
not sure that all need to be implemented immediately.  If we can agree
on the basic interface and semantics, then we could implement a basic
version now, and relax restrictions on the arguments later as needed?

-- Dave


From ligges at statistik.uni-dortmund.de  Thu Sep  1 19:10:34 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 01 Sep 2005 19:10:34 +0200
Subject: [Rd] error in apply help file? (PR#8118)
In-Reply-To: <20050901163408.0002B15FE2@slim.kubism.ku.dk>
References: <20050901163408.0002B15FE2@slim.kubism.ku.dk>
Message-ID: <4317360A.4060408@statistik.uni-dortmund.de>

gunter.berton at gene.com wrote:

> Gents: (alas, I think no ladies need to be included in the salutation)


May I ask why you think R-devel (to which R-bugs stuff is forwarded) is 
only read by males?

Sounds a little bit discriminating ("Only males produce bugs, females 
simply produce perfect code and do not need to read R-devel mails."??!). 
Hence, I'd like to complain in this case.

Uwe Ligges



> The apply()  Help file says
> "...
> If the calls to FUN return vectors of different lengths, apply returns a
> list of length dim(X)[MARGIN]. "
> 
> Shouldn't that be:
> 
> "If the calls to FUN return vectors of different lengths, apply returns a
> list of length prod(dim(X)[MARGIN]). "
> 
> Also, might you wish to add:
> 
> "This list has a dim attribute of MARGIN. That is, if VALUE is the returned
> list, dim(VALUE) = MARGIN and the values in VALUE can be accessed by the
> usual array subscripting operations."
> 
> Further, it might also be useful to add the following to your Examples code:
> 
> ## Example with different lengths for each call
> z <- array(1:24,dim=2:4)
> zseq <- apply(z,1:2,function(x)seq(length=max(x)))
> zseq  ## displayed as a 2 x 3 matrix
> typeof(zseq) ## list
> dim(zseq) ## 2 3
> zseq[1,]
> 
> 
> Feel free to ignore these suggestions, of course. 
> 
> Cheers,
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From JAROSLAW.W.TUSZYNSKI at saic.com  Thu Sep  1 22:21:39 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Thu, 1 Sep 2005 16:21:39 -0400 
Subject: [Rd] Question about package's DESCRIPTION/Depends field
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD50357CAA8@us-arlington-0668.mail.saic.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050901/b5f64d0b/attachment.pl

From Kurt.Hornik at wu-wien.ac.at  Fri Sep  2 00:36:50 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 2 Sep 2005 00:36:50 +0200
Subject: [Rd] Question about package's DESCRIPTION/Depends field
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD50357CAA8@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD50357CAA8@us-arlington-0668.mail.saic.com>
Message-ID: <17175.33410.175138.239127@mithrandir.hornik.net>

>>>>> Tuszynski, Jaroslaw W writes:

> Hi,
> My package "caMassClass" depends on several other packages, one of them
> "PROcess" residing on "Bioconductor" website. Bioconductor repository is
> not, listed in default set of repositories in current version of R (Windows
> R 2.1.1). As a result people installing my package have to change that
> default, before installing the package.

> Is there a way of including that information in the DESCRIPTION file, that
> would spare the user from manual tinkering with the installation process?.
> Something along the lines of "Repositories: Bioconductor".

No.  The idea is that the 'repos' option is set appropriately.

Best
-k

> Jarek Tuszynski

 
 


> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From luke at stat.uiowa.edu  Fri Sep  2 03:36:16 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 1 Sep 2005 20:36:16 -0500 (CDT)
Subject: [Rd] Bug in copying of S4 objects (PR#8112)
In-Reply-To: <20050831184820.9612B1992B@slim.kubism.ku.dk>
References: <20050831184820.9612B1992B@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.63.0509012034570.15992@itasca2.wildberry.org>

Another variant of what is probably the same issue:

     > setClass("foo", representation(a = "numeric"))
     [1] "foo"
     > f <- function() x at a <<- 2
     > x <- new("foo",a=1)
     > y <- x
     > f()
     > x
     An object of class ???foo???
     Slot "a":
     [1] 2

     > y
     An object of class ???foo???
     Slot "a":
     [1] 2

luke

On Wed, 31 Aug 2005, murdoch at stats.uwo.ca wrote:

> If I have an S4 object, and I make a copy, changes to the original
> aren't reflected in the copy:
>
> > setClass("foo", representation(slot="numeric"))
> > x <- new("foo", slot=1)
> > y <- x
> > x at slot <- 2
> > y
> An object of class "foo"
> Slot "slot":
> [1] 1
>
> This is as it should be.  However, if I call the slot assignment
> function in a funny way, y *does* receive the changes:
>
> > x <- new("foo", slot=1)
> > y <- x
> > assign("x", "@<-"(x, "slot", 2))
> > y
> An object of class "foo"
> Slot "slot":
> [1] 2
>
> This happens in the current R-devel in Windows, and R-patched too.
>
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status   Under development (unstable)
> major    2
> minor    2.0
> year     2005
> month    08
> day      31
> svn rev  35467
> language R
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From murdoch at stats.uwo.ca  Fri Sep  2 04:19:33 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 01 Sep 2005 22:19:33 -0400
Subject: [Rd] RFC: rawConnection (was "loop connections")
In-Reply-To: <df7c03$s62$1@sea.gmane.org>
References: <dedndn$daj$1@sea.gmane.org>	<17168.15848.291481.473231@stat.math.ethz.ch>	<df5b90$1ba$1@sea.gmane.org>
	<431667BC.7050906@stats.uwo.ca>	<df62er$jab$1@sea.gmane.org>
	<4316D8B3.3040504@stats.uwo.ca> <df7c03$s62$1@sea.gmane.org>
Message-ID: <4317B6B5.30709@stats.uwo.ca>

dhinds at sonic.net wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>>Having a rawConnection() entry point is simple enough.  Seeking also
>>>seems straightforward.  I'm not so sure about using as.raw().  I
>>>wondered about that, but also thought that rather than coercing to
>>>raw, it might make more sense to cast atomic vector types to raw,
>>>byte-for-byte.
> 
> 
>>I'd prefer as.raw, so that we don't end up with two incompatible ways to 
>>convert other objects to raw objects.
> 
> 
> An advantage of no as.raw() would be that you could create a raw
> connection on an object without making an extra copy, which was
> another of your requests.  But there would be a lack of symmetry,
> because you could "r" from an arbitrary R object, but only "w" to raw,
> unless there was also a way of specifying a type for the result
> vector.

I think the cost of duplicating as.raw is worse than the cost of using 
extra memory.  If the lack of symmetry bothers you, a solution is to 
require a raw object as input.

> Having the backing store be an R object with no copy does seem tricky,
> however.  

In that case I wouldn't bother.  It's important to get it right; being 
maximally efficient is a second priority.

 > Currently, textConnection() makes a copy for "r" connections
> but writes directly to an R object for "w" connections.  The "w" case
> is buggy; you can crash R by removing the target object while the
> connection is being used.  I'm not familiar enough with R internals to
> know how to fix that.  Maybe the object has to be searched for every
> time the connection is used, to avoid potentially stale pointers?

I've been having an argument with some other people about something 
related to this.  I think they would say that the language doesn't 
support writing to a variable.

I don't know the right way to fix this.
> 
> 
>>>Can you given an example of where a text-mode raw connection would be
>>>a useful thing?
> 
> 
>>No, but someone else might.  Why unnecessarily let the source of the 
>>bytes determine the mode of the connection?  In the case of 
>>textConnection, there are natural line breaks, so a text mode connection 
>>makes sense.  A raw object can contain anything, so why wouldn't someone 
>>want to put text in it some day?
> 
> 
> It seems that that a text-mode raw connection would be equivalent to a
> textConnection on the result of rawToChar(), no?

If so, then a binary mode rawConnection (with mention of the way to 
convert in the Rd file) would be good enough for me.


> 
> While some of these possibilities seem like they might be useful, I'm
> not sure that all need to be implemented immediately.  If we can agree
> on the basic interface and semantics, then we could implement a basic
> version now, and relax restrictions on the arguments later as needed?

I'd rather get it right now, but that doesn't have to mean including 
every bell and whistle someone (even me!) has suggested.

Duncan Murdoch


From luke at stat.uiowa.edu  Fri Sep  2 05:33:26 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 1 Sep 2005 22:33:26 -0500 (CDT)
Subject: [Rd] Bug in copying of S4 objects (PR#8112)
In-Reply-To: <Pine.LNX.4.63.0509012034570.15992@itasca2.wildberry.org>
References: <20050831184820.9612B1992B@slim.kubism.ku.dk>
	<Pine.LNX.4.63.0509012034570.15992@itasca2.wildberry.org>
Message-ID: <Pine.LNX.4.63.0509012214180.15992@itasca2.wildberry.org>

I've poked in the source a bit.  Here are some notes in case someone
has time to look into this.

The main internal difference between <<- and <- for complex
assignments is that <- calls EnsureLocal which calls duplicate on the
value of the left hand side value if NAMED == 2.  In principle I don't
tink this should be necessary, but it means that assignment functions
called for <- assignments will not see NAMED == 2.  This protects
agains internal assignment functions that destructively modify without
looking at NAMED, which is what @<- and slot<- do.  But <<- does not
do this defensive duplicating, hence the problem with <<-.  Similar
problems occur if structures contain environments used to implement
reference behaviour since the copying stops at the environment.

The appropriate fix is to insure that @<- and slot<- respect NAMED and
duplicate when NAMED == 2, as attr<- does.  This will require either
making @<- and slot<- into SPECIALSXP's or some sort of
underhandedness to allow them to remain closures.  One possibility
might be to define a SPECIALSXP that looks at the NAMED value of the
object argument (by inspecting the promise before it is forced).  This
can then be passed into the internal R_set_slot function via .Call.

luke

On Thu, 1 Sep 2005, Luke Tierney wrote:

> Another variant of what is probably the same issue:
>
>    > setClass("foo", representation(a = "numeric"))
>    [1] "foo"
>    > f <- function() x at a <<- 2
>    > x <- new("foo",a=1)
>    > y <- x
>    > f()
>    > x
>    An object of class ???foo???
>    Slot "a":
>    [1] 2
>
>    > y
>    An object of class ???foo???
>    Slot "a":
>    [1] 2
>
> luke
>
> On Wed, 31 Aug 2005, murdoch at stats.uwo.ca wrote:
>
>> If I have an S4 object, and I make a copy, changes to the original
>> aren't reflected in the copy:
>> 
>> > setClass("foo", representation(slot="numeric"))
>> > x <- new("foo", slot=1)
>> > y <- x
>> > x at slot <- 2
>> > y
>> An object of class "foo"
>> Slot "slot":
>> [1] 1
>> 
>> This is as it should be.  However, if I call the slot assignment
>> function in a funny way, y *does* receive the changes:
>> 
>> > x <- new("foo", slot=1)
>> > y <- x
>> > assign("x", "@<-"(x, "slot", 2))
>> > y
>> An object of class "foo"
>> Slot "slot":
>> [1] 2
>> 
>> This happens in the current R-devel in Windows, and R-patched too.
>> 
>> > version
>>          _
>> platform i386-pc-mingw32
>> arch     i386
>> os       mingw32
>> system   i386, mingw32
>> status   Under development (unstable)
>> major    2
>> minor    2.0
>> year     2005
>> month    08
>> day      31
>> svn rev  35467
>> language R
>> 
>> Duncan Murdoch
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From dhinds at sonic.net  Fri Sep  2 06:12:15 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Fri, 2 Sep 2005 04:12:15 +0000 (UTC)
Subject: [Rd] RFC: rawConnection (was "loop connections")
References: <dedndn$daj$1@sea.gmane.org>
	<17168.15848.291481.473231@stat.math.ethz.ch>
	<df5b90$1ba$1@sea.gmane.org> <431667BC.7050906@stats.uwo.ca>
	<df62er$jab$1@sea.gmane.org> <4316D8B3.3040504@stats.uwo.ca>
	<df7c03$s62$1@sea.gmane.org> <4317B6B5.30709@stats.uwo.ca>
Message-ID: <df8jev$2l6$1@sea.gmane.org>

Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> I think the cost of duplicating as.raw is worse than the cost of using 
> extra memory.  If the lack of symmetry bothers you, a solution is to 
> require a raw object as input.

It wouldn't exactly be duplicating as.raw since this way of converting
to raw is actually to do nothing at all, just to treat the object as
if it is already raw.  But, I don't have a strong opinion.

>  > Currently, textConnection() makes a copy for "r" connections
> > but writes directly to an R object for "w" connections.  The "w" case
> > is buggy; you can crash R by removing the target object while the
> > connection is being used.  I'm not familiar enough with R internals to
> > know how to fix that.  Maybe the object has to be searched for every
> > time the connection is used, to avoid potentially stale pointers?

> I've been having an argument with some other people about something 
> related to this.  I think they would say that the language doesn't 
> support writing to a variable.

I tried changing textConnection output connections to look up the
destination object on every access and that seems to solve the problem
without being terribly expensive.

> If so, then a binary mode rawConnection (with mention of the way to 
> convert in the Rd file) would be good enough for me.

It seems we are coming back to something close to what I had
originally implemented?

-- Dave


From murdoch at stats.uwo.ca  Fri Sep  2 12:39:02 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 02 Sep 2005 06:39:02 -0400
Subject: [Rd] RFC: rawConnection (was "loop connections")
In-Reply-To: <df8jev$2l6$1@sea.gmane.org>
References: <dedndn$daj$1@sea.gmane.org>	<17168.15848.291481.473231@stat.math.ethz.ch>	<df5b90$1ba$1@sea.gmane.org>
	<431667BC.7050906@stats.uwo.ca>	<df62er$jab$1@sea.gmane.org>
	<4316D8B3.3040504@stats.uwo.ca>	<df7c03$s62$1@sea.gmane.org>
	<4317B6B5.30709@stats.uwo.ca> <df8jev$2l6$1@sea.gmane.org>
Message-ID: <43182BC6.5080700@stats.uwo.ca>

dhinds at sonic.net wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
> 
>>I think the cost of duplicating as.raw is worse than the cost of using 
>>extra memory.  If the lack of symmetry bothers you, a solution is to 
>>require a raw object as input.
> 
> 
> It wouldn't exactly be duplicating as.raw since this way of converting
> to raw is actually to do nothing at all, just to treat the object as
> if it is already raw.  But, I don't have a strong opinion.

I haven't looked at as.raw, but I think it does something other than 
that.  For example,

rawToChar(as.raw(1:10)) gives

"\001\002\003\004\005\006\a\b\t\n"

I don't know if there's a way to do exactly what you're proposing.  One 
argument against it is that the bytes for an object may vary from 
platform to platform (big versus little endian, maybe 32 vs 64 bit), 
whereas we try to make R code platform independent when we can.

>> > Currently, textConnection() makes a copy for "r" connections
>>
>>>but writes directly to an R object for "w" connections.  The "w" case
>>>is buggy; you can crash R by removing the target object while the
>>>connection is being used.  I'm not familiar enough with R internals to
>>>know how to fix that.  Maybe the object has to be searched for every
>>>time the connection is used, to avoid potentially stale pointers?
> 
> 
>>I've been having an argument with some other people about something 
>>related to this.  I think they would say that the language doesn't 
>>support writing to a variable.
> 
> 
> I tried changing textConnection output connections to look up the
> destination object on every access and that seems to solve the problem
> without being terribly expensive.
> 
> 
>>If so, then a binary mode rawConnection (with mention of the way to 
>>convert in the Rd file) would be good enough for me.
> 
> 
> It seems we are coming back to something close to what I had
> originally implemented?

Probably!  The differences I still know about are:

  - I'd like the name to reflect the data source, so rawConnection or 
something similar rather than overloading textConnection.

  - It needs a man page, or to be included on the textConnection man page.

Duncan


From lai at lindaspaces.com  Fri Sep  2 15:08:37 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Fri, 02 Sep 2005 09:08:37 -0400
Subject: [Rd] Build R with ATLAS
Message-ID: <43184ED5.1090607@lindaspaces.com>

Hi,
   I followed this message, 
https://stat.ethz.ch/pipermail/r-devel/2004-February/028942.html,  to 
compile ATLAS with gcc and g77 on AMD Opteron.  I then followed the 
instructions on this message, 
https://stat.ethz.ch/pipermail/r-devel/2004-February/028966.html, to 
convert static libraries to dynamic libraries.

However, when I tried to configure R-devel, I got the following error 
messages in config.log:

configure:33172: checking for sgemm_ in -lf77blas
configure:33210: /usr/pgi/linux86-64/6.0/bin/pgcc -o conftest -g -O2 
-mieee-fp  -I/usr/pgi/linux86-64/6.0/include -I/usr/pgi/l\
inux86-64/6.0/include/CC -L/usr/pgi/linux86-64/6.0/libso -L/usr/lib64 
-L/usr/local/lib64 conftest.c -lf77blas -latlas  -lpgftn\
rtl -lnspgc -lpgc -lm -ldl -lm  >&5
pgcc-Warning-Unknown switch: -mieee-fp
NOTE: your evaluation license will expire in 14 days, 0.426 hours.
For a permanent license, please read the order acknowledgement
that you received.  Connect to https://www.pgroup.com/License with
the username and password in the order acknowledgement.

        Name:   lai
        User:   lai
        Email:  lai at lindaspaces.com
        Hostid: PGI=00001AE0190CAB621CB217
/usr/local/lib64/libf77blas.so: undefined reference to `e_wsfe'
/usr/local/lib64/libf77blas.so: undefined reference to `do_fio'
/usr/local/lib64/libf77blas.so: undefined reference to `s_stop'
/usr/local/lib64/libf77blas.so: undefined reference to `s_wsfe'


My LD_LIBRARY_PATH=/usr/pgi/linux86-64/libso:/usr/local/lib64

Can anyone advise me on how to build R with ATLAS?


Thanks,
Jennifer


From charlie at stat.umn.edu  Fri Sep  2 17:30:38 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Fri, 2 Sep 2005 10:30:38 -0500
Subject: [Rd] lattice and for loop
Message-ID: <20050902153038.GA13664@stat.umn.edu>

----- Forwarded message from Sandy Weisberg <sandy at stat.umn.edu> -----

OK, here is my R bug:

library(lattice)
x <- rnorm(20)
y <- rnorm(20)
z <-rep(c(1,2),10)
xyplot(y~x|z)
# the above works fine.  Now try this:

for (j in 1:1) {xyplot(y~x|z)}

# no graph is produced.

-- 
Sanford Weisberg
University of Minnesota, School of Statistics
312 Ford Hall, Minneapolis, MN  55455
612-625-8355, FAX 612-624-8868
St. Paul office:  146 Classroom-Office Building, 612-625-8777
sandy at stat.umn.edu

----- End forwarded message -----

Sandy originally found this in

    R 2.1.1 (for Windows).

I have tried this in

    R 2.1.1 Patched (2005-08-04).
    R 2.1.1 Patched (2005-09-02).
    R 2.2.0 Under development (unstable) (2005-09-01).

all on

    Linux 2.6.11.4-21.7-smp i686 athlon i386 GNU/Linux
    Suse 9.3
    gcc (GCC) 3.3.5 20050117 (prerelease) (SUSE Linux)

So our question is: is this a bug or a feature?

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie at stat.umn.edu


From rpeng at jhsph.edu  Fri Sep  2 17:42:38 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 02 Sep 2005 11:42:38 -0400
Subject: [Rd] lattice and for loop
In-Reply-To: <20050902153038.GA13664@stat.umn.edu>
References: <20050902153038.GA13664@stat.umn.edu>
Message-ID: <431872EE.1060607@jhsph.edu>

See 
http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-do-lattice_002ftrellis-graphics-not-work_003f

-roger

Charles Geyer wrote:
> ----- Forwarded message from Sandy Weisberg <sandy at stat.umn.edu> -----
> 
> OK, here is my R bug:
> 
> library(lattice)
> x <- rnorm(20)
> y <- rnorm(20)
> z <-rep(c(1,2),10)
> xyplot(y~x|z)
> # the above works fine.  Now try this:
> 
> for (j in 1:1) {xyplot(y~x|z)}
> 
> # no graph is produced.
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/


From mlopez at iattc.org  Fri Sep  2 17:59:02 2005
From: mlopez at iattc.org (Milton Lopez)
Date: Fri, 2 Sep 2005 08:59:02 -0700
Subject: [Rd] 64 bit R for Windows
Message-ID: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>

I appreciate the update. We will consider using Linux, which leads me to
one more question: what is the maximum RAM that R can use on each
platform (Linux and Windows)?

Thanks again for your prompt responses.


M.

-----Original Message-----
From: Luke Tierney [mailto:luke at stat.uiowa.edu] 
Sent: Wednesday, August 31, 2005 6:04 PM
To: Duncan Murdoch
Cc: Milton Lopez; r-devel at r-project.org
Subject: Re: [Rd] 64 bit R for Windows

On Wed, 31 Aug 2005, Duncan Murdoch wrote:

> I would say it will be at least a year, and most likely longer.  The
> tools used to build R haven't been ported to 64 bit Windows yet.
After
> those are done (by the MinGW project, not us), we'll need someone with
a
> 64 bit Windows machine to handle builds there.
>
> Duncan Murdoch

An additional factor is that MinGW will almost certainly follow the MS
idea that long's are 4 bytes even under Win64, unlike what every other
64-bit OS does.  It will take a fair bit of time and someonw with the
motivation to do so to sort out the consequences (which may not be
very great but even establishing that may be non-trivial).

luke


From sfalcon at fhcrc.org  Fri Sep  2 18:08:06 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 02 Sep 2005 09:08:06 -0700
Subject: [Rd] R CMD check warning message "print.check_code_usage_in_package"
Message-ID: <m2oe7bpi55.fsf@macaroni.local>

We're seeing many warnings like this:

Warning: S3 method 'print.check_code_usage_in_package' was declared in
NAMESPACE but not found

But the package's NAMESPACE does not contain such a declaration.
Seeing this in many Bioconductor packages when running R CMD check on
Windows with R-devel built 1 Sept.

Below is a snip of the output from R CMD check.  Any ideas of what
this message is really trying to tell me?  

Thanks,

+ seth


* checking S3 generic/method consistency ... WARNING
Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
See section 'Generic functions and methods' of the 'Writing R Extensions'
manual.
* checking replacement functions ... WARNING
Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
In R, the argument of a replacement function which corresponds to the right
hand side must be named 'value'.
* checking foreign function calls ... WARNING
Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
See section 'System and foreign language interfaces' of the 'Writing R
Extensions' manual.
* checking Rd files ... WARNING
Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking for missing documentation entries ... WARNING
Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
All user-level objects in a package should have documentation entries.
See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking for code/documentation mismatches ... WARNING
Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found


From murdoch at stats.uwo.ca  Fri Sep  2 18:18:17 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 02 Sep 2005 12:18:17 -0400
Subject: [Rd] 64 bit R for Windows
In-Reply-To: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>
References: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>
Message-ID: <43187B49.7080307@stats.uwo.ca>

On 9/2/2005 11:59 AM, Milton Lopez wrote:
> I appreciate the update. We will consider using Linux, which leads me to
> one more question: what is the maximum RAM that R can use on each
> platform (Linux and Windows)?

On 32 bit Windows, I believe the limit is normally 2 G total for all 
user processes, but can be raised to 3 G with some work.  (If you have a 
4 G machine, the OS reserves 1 or 2 G for itself.)  R can use as much 
memory as Windows will give it, but may not be able to make large 
allocations if memory is fragmented, or reserved by other processes.

The limit under 64 bit Linux is much larger, but I don't know exactly 
what.

Duncan Murdoch
> 
> Thanks again for your prompt responses.
> 
> 
> M.
> 
> -----Original Message-----
> From: Luke Tierney [mailto:luke at stat.uiowa.edu] 
> Sent: Wednesday, August 31, 2005 6:04 PM
> To: Duncan Murdoch
> Cc: Milton Lopez; r-devel at r-project.org
> Subject: Re: [Rd] 64 bit R for Windows
> 
> On Wed, 31 Aug 2005, Duncan Murdoch wrote:
> 
>> I would say it will be at least a year, and most likely longer.  The
>> tools used to build R haven't been ported to 64 bit Windows yet.
> After
>> those are done (by the MinGW project, not us), we'll need someone with
> a
>> 64 bit Windows machine to handle builds there.
>>
>> Duncan Murdoch
> 
> An additional factor is that MinGW will almost certainly follow the MS
> idea that long's are 4 bytes even under Win64, unlike what every other
> 64-bit OS does.  It will take a fair bit of time and someonw with the
> motivation to do so to sort out the consequences (which may not be
> very great but even establishing that may be non-trivial).
> 
> luke
> 
> 
>


From p.dalgaard at biostat.ku.dk  Fri Sep  2 18:48:24 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Sep 2005 18:48:24 +0200
Subject: [Rd] 64 bit R for Windows
In-Reply-To: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>
References: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>
Message-ID: <x2u0h3wh47.fsf@turmalin.kubism.ku.dk>

"Milton Lopez" <mlopez at iattc.org> writes:

> I appreciate the update. We will consider using Linux, which leads me to
> one more question: what is the maximum RAM that R can use on each
> platform (Linux and Windows)?
> 
> Thanks again for your prompt responses.

On Win32, something like 3GB. Maybe a little more on Linux32, but
there's a physical limit at 4GB. 

On Linux 64, the motherboards set the limit in practice, 32GB systems
have been reported working and I think at least 64GB should be
possible. I seem to recall that the maximum _virtual_ memory is not
quite 2^64, but it will be pretty huge (2^48, 256TB)?.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Kurt.Hornik at wu-wien.ac.at  Fri Sep  2 22:00:35 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 2 Sep 2005 22:00:35 +0200
Subject: [Rd] R CMD check warning message
	"print.check_code_usage_in_package"
In-Reply-To: <m2oe7bpi55.fsf@macaroni.local>
References: <m2oe7bpi55.fsf@macaroni.local>
Message-ID: <17176.44899.58885.395083@mithrandir.hornik.net>

>>>>> Seth Falcon writes:

> We're seeing many warnings like this:
> Warning: S3 method 'print.check_code_usage_in_package' was declared in
> NAMESPACE but not found

> But the package's NAMESPACE does not contain such a declaration.
> Seeing this in many Bioconductor packages when running R CMD check on
> Windows with R-devel built 1 Sept.

My SVN checkout of the r-devel sources seems to have it:

$ grep print.check_code_usage_in_package *
QC.R:print.check_code_usage_in_package <-

and it also seems to be in the r-devel .tar.gz from ETHZ.

Are you sure you have a current version of r-devel's tools/R/QC.R?

Best
-k

> Below is a snip of the output from R CMD check.  Any ideas of what
> this message is really trying to tell me?  

> Thanks,

> + seth


> * checking S3 generic/method consistency ... WARNING
> Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
> See section 'Generic functions and methods' of the 'Writing R Extensions'
> manual.
> * checking replacement functions ... WARNING
> Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
> In R, the argument of a replacement function which corresponds to the right
> hand side must be named 'value'.
> * checking foreign function calls ... WARNING
> Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
> See section 'System and foreign language interfaces' of the 'Writing R
> Extensions' manual.
> * checking Rd files ... WARNING
> Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
> See chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking for missing documentation entries ... WARNING
> Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
> All user-level objects in a package should have documentation entries.
> See chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking for code/documentation mismatches ... WARNING
> Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found
> Warning: S3 method 'print.check_code_usage_in_package' was declared in NAMESPACE but not found

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Sep  2 22:06:25 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 2 Sep 2005 22:06:25 +0200
Subject: [Rd] 64 bit R for Windows
In-Reply-To: <x2u0h3wh47.fsf@turmalin.kubism.ku.dk>
References: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>
	<x2u0h3wh47.fsf@turmalin.kubism.ku.dk>
Message-ID: <17176.45249.954154.117268@stat.math.ethz.ch>

>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>     on 02 Sep 2005 18:48:24 +0200 writes:

    PD> "Milton Lopez" <mlopez at iattc.org> writes:

    >> I appreciate the update. We will consider using Linux,
    >> which leads me to one more question: what is the maximum
    >> RAM that R can use on each platform (Linux and Windows)?
    >> 
    >> Thanks again for your prompt responses.

    PD> On Win32, something like 3GB. Maybe a little more on
    PD> Linux32, but there's a physical limit at 4GB.

for a *single* object, yes.  However (and Peter knows this
probably better than me ..), R's workspace can be very much
larger which makes it realistically possible to start *using* R
functions on objects of around 4GB.
Someone (Venables & Ripley ?) have once stated the rule of thumb
that you need about 5--10 times the size of your "single" large
object for your "workspace", because of (intermediate) copies,
sometimes multiple ones are needed, or at least part of the
current implementations of many basic algorithms / functions.
In other words, if you got a 32 GB RAM, you could probably start
to work with objects of the size of (a little less than) 4GB
relatively comfortably.

Martin Maechler

    PD> On Linux 64, the motherboards set the limit in practice,
    PD> 32GB systems have been reported working and I think at
    PD> least 64GB should be possible. I seem to recall that the
    PD> maximum _virtual_ memory is not quite 2^64, but it will
    PD> be pretty huge (2^48, 256TB)?.


From tlumley at u.washington.edu  Fri Sep  2 22:29:16 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 2 Sep 2005 13:29:16 -0700 (PDT)
Subject: [Rd] 64 bit R for Windows
In-Reply-To: <17176.45249.954154.117268@stat.math.ethz.ch>
References: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>
	<x2u0h3wh47.fsf@turmalin.kubism.ku.dk>
	<17176.45249.954154.117268@stat.math.ethz.ch>
Message-ID: <Pine.A41.4.63a.0509021324540.217476@homer08.u.washington.edu>

On Fri, 2 Sep 2005, Martin Maechler wrote:

>>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>>     on 02 Sep 2005 18:48:24 +0200 writes:
>
>    PD> "Milton Lopez" <mlopez at iattc.org> writes:
>
>    >> I appreciate the update. We will consider using Linux,
>    >> which leads me to one more question: what is the maximum
>    >> RAM that R can use on each platform (Linux and Windows)?
>    >>
>    >> Thanks again for your prompt responses.
>
>    PD> On Win32, something like 3GB. Maybe a little more on
>    PD> Linux32, but there's a physical limit at 4GB.
>
> for a *single* object, yes.  However (and Peter knows this
> probably better than me ..), R's workspace can be very much
> larger which makes it realistically possible to start *using* R
> functions on objects of around 4GB.

No, no.  On *Windows* there is an address space limit of about 3Gb (and on 
other 32bit systems)

On a 64bit system the limit is that a vector can't have length greater 
than 2^31, but this would be 8Gb for integers or 16Gb for doubles and so 
represents larger objects than you would want to handle on most current 
64-bit systems.

 	-thomas


From p.dalgaard at biostat.ku.dk  Fri Sep  2 23:55:14 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Sep 2005 23:55:14 +0200
Subject: [Rd] 64 bit R for Windows
In-Reply-To: <17176.45249.954154.117268@stat.math.ethz.ch>
References: <84B25EE9B4CB1A47A197E6AE76790D7801426D9B@mail1.lajolla.iattc.org>
	<x2u0h3wh47.fsf@turmalin.kubism.ku.dk>
	<17176.45249.954154.117268@stat.math.ethz.ch>
Message-ID: <x2oe7bp22l.fsf@turmalin.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
> >>>>>     on 02 Sep 2005 18:48:24 +0200 writes:
> 
>     PD> "Milton Lopez" <mlopez at iattc.org> writes:
> 
>     >> I appreciate the update. We will consider using Linux,
>     >> which leads me to one more question: what is the maximum
>     >> RAM that R can use on each platform (Linux and Windows)?
>     >> 
>     >> Thanks again for your prompt responses.
> 
>     PD> On Win32, something like 3GB. Maybe a little more on
>     PD> Linux32, but there's a physical limit at 4GB.
> 
> for a *single* object, yes.  However (and Peter knows this
> probably better than me ..), R's workspace can be very much
> larger which makes it realistically possible to start *using* R
> functions on objects of around 4GB.

Notice that I said "Linux32" there.... The single-object size limit is
of course relevant on 64 bit systems, so thanks for the reminder.

<snip>

>     PD> On Linux 64, the motherboards set the limit in practice,
>     PD> 32GB systems have been reported working and I think at
>     PD> least 64GB should be possible. I seem to recall that the
>     PD> maximum _virtual_ memory is not quite 2^64, but it will
>     PD> be pretty huge (2^48, 256TB)?.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ggrothendieck at gmail.com  Sat Sep  3 06:46:16 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 3 Sep 2005 00:46:16 -0400
Subject: [Rd] R CMD check and interfacing packages
Message-ID: <971536df050902214612157859@mail.gmail.com>

For an R package whose purpose is to interface to other software,
since such other software is not necessarily being on CRAN how does one 
proceed so that the R package can pass 'R CMD check'?  None 
of the examples or demos in the package can run without the software 
being interfaced to.

Is there an example of such a package that could be used as a 
prototype?

Thanks.


From sfalcon at fhcrc.org  Sat Sep  3 07:25:31 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 02 Sep 2005 22:25:31 -0700
Subject: [Rd] R CMD check warning message
	"print.check_code_usage_in_package"
In-Reply-To: <17176.44899.58885.395083@mithrandir.hornik.net> (Kurt Hornik's
	message of "Fri, 2 Sep 2005 22:00:35 +0200")
References: <m2oe7bpi55.fsf@macaroni.local>
	<17176.44899.58885.395083@mithrandir.hornik.net>
Message-ID: <m2wtlyrad0.fsf@fhcrc.org>

On  2 Sep 2005, Kurt.Hornik at wu-wien.ac.at wrote:
> My SVN checkout of the r-devel sources seems to have it:
>
> $ grep print.check_code_usage_in_package *
> QC.R:print.check_code_usage_in_package <-
>
> and it also seems to be in the r-devel .tar.gz from ETHZ.
>
> Are you sure you have a current version of r-devel's tools/R/QC.R?

You were right, an svn update and rebuild seems to have resolved
things.  I guess I must have caught a bad revision.  Still seems like
a very odd message since it was refering to the tools package and not
the package being checked.

Thanks for the hint.

+ seth


From ligges at statistik.uni-dortmund.de  Sat Sep  3 12:59:56 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 03 Sep 2005 12:59:56 +0200
Subject: [Rd] R CMD check and interfacing packages
In-Reply-To: <971536df050902214612157859@mail.gmail.com>
References: <971536df050902214612157859@mail.gmail.com>
Message-ID: <4319822C.8090008@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:

> For an R package whose purpose is to interface to other software,
> since such other software is not necessarily being on CRAN how does one 
> proceed so that the R package can pass 'R CMD check'?  None 
> of the examples or demos in the package can run without the software 
> being interfaced to.

Yes, this is a problem.
For this reason, we have some exceptions on CRAN for packages that 
interface to other software products, e.g. for some we are doing only 
fake installations and for others, I am skipping automatical checks for 
Windows, if GUI interaction is required.


> Is there an example of such a package that could be used as a 
> prototype?

I don't think there is a globally perfect example.
It depends on the software you are going to interface to, on the 
Operating Systems this software is available on, and on the license and 
the requirements for linking against it etc....

Uwe Ligges


> Thanks.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat Sep  3 13:05:06 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 3 Sep 2005 07:05:06 -0400
Subject: [Rd] R CMD check and interfacing packages
In-Reply-To: <4319822C.8090008@statistik.uni-dortmund.de>
References: <971536df050902214612157859@mail.gmail.com>
	<4319822C.8090008@statistik.uni-dortmund.de>
Message-ID: <971536df05090304051184986e@mail.gmail.com>

On 9/3/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> Gabor Grothendieck wrote:
> 
> > For an R package whose purpose is to interface to other software,
> > since such other software is not necessarily being on CRAN how does one
> > proceed so that the R package can pass 'R CMD check'?  None
> > of the examples or demos in the package can run without the software
> > being interfaced to.
> 
> Yes, this is a problem.
> For this reason, we have some exceptions on CRAN for packages that
> interface to other software products, e.g. for some we are doing only
> fake installations and for others, I am skipping automatical checks for
> Windows, if GUI interaction is required.
> 
> 
> > Is there an example of such a package that could be used as a
> > prototype?
> 
> I don't think there is a globally perfect example.
> It depends on the software you are going to interface to, on the
> Operating Systems this software is available on, and on the license and
> the requirements for linking against it etc....

The interfaced software is GPL software available on all operating systems 
that R runs.   Currently the strategy is to include a Windows binary of the
interfaced software with the R package so that at least Windows users can use 
it without separately installing the package but users on other
operating systems
must separately install that package.  Communication with the package is 
currently via sockets so there is no linking.


From maechler at stat.math.ethz.ch  Sat Sep  3 13:56:03 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 3 Sep 2005 13:56:03 +0200
Subject: [Rd] R CMD BATCH on scripts without trailing newline
In-Reply-To: <17174.59528.327720.694835@stat.math.ethz.ch>
References: <17174.57691.868797.92193@notch.amtp.cam.ac.uk>
	<17174.59528.327720.694835@stat.math.ethz.ch>
Message-ID: <17177.36691.745673.940837@stat.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 1 Sep 2005 13:39:52 +0200 writes:

>>>>> "StEgl" == Stephen Eglen <S.J.Eglen at damtp.cam.ac.uk>
>>>>>     on Thu, 1 Sep 2005 12:09:15 +0100 writes:

    StEgl> If the last line of an R script does not have a
    StEgl> trailing newline, a small errror is produced at the
    StEgl> end of the script.

    StEgl> Small example.  If file eg.r contains one line:
    StEgl> getwd() and there is no newline after the closing
    StEgl> paren

    StEgl> $ R CMD BATCH eg.r

    StEgl> produces an error: $ cat eg.r.Rout

    StEgl> R : Copyright 2005, The R Foundation for Statistical
    StEgl> Computing Version 2.1.1 Patched (2005-09-01), ISBN
    StEgl> 3-900051-07-0

    StEgl> ...

    >>> getwd()proc.time()
    StEgl> Error: syntax error Execution halted $

    MM> aahh, now I finally understand via some people append
    MM> those **ugly** unneeded ';' to the end of almost every
    MM> line of R code.  It would have helped here :-) :-)

    StEgl> Is it worth changing the BATCH script so that it adds
    StEgl> a newline before adding the call to proc.time()?

    MM> Yes I think it would be.  This is trivial, at least for
    MM> <Rsrc>/src/scripts/BATCH Slightly better but more
    MM> tricky: only append a newline "when needed".  Any idea
    MM> for that?

It's probably not worth the extra effort (I agree with Jan on
*that); I've added the obvious to the BATCH script used on
unix-alike platforms, now adding a newline before 'proc.time()'
unconditionally.  I hope people can live with an extra byte in
the output files.

Martin

> BTW: The windows version of "R CMD BATCH" is actually
    MM> *documented* do to work with files that don't end in
    MM> newline.


From dhinds at sonic.net  Sat Sep  3 23:38:42 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Sat, 3 Sep 2005 21:38:42 +0000 (UTC)
Subject: [Rd] RFC: rawConnection (was "loop connections")
References: <dedndn$daj$1@sea.gmane.org>
	<17168.15848.291481.473231@stat.math.ethz.ch>
	<df5b90$1ba$1@sea.gmane.org> <431667BC.7050906@stats.uwo.ca>
	<df62er$jab$1@sea.gmane.org> <4316D8B3.3040504@stats.uwo.ca>
	<df7c03$s62$1@sea.gmane.org> <4317B6B5.30709@stats.uwo.ca>
	<df8jev$2l6$1@sea.gmane.org> <43182BC6.5080700@stats.uwo.ca>
Message-ID: <dfd551$sqe$1@sea.gmane.org>

Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> Probably!  The differences I still know about are:

>   - I'd like the name to reflect the data source, so rawConnection or 
> something similar rather than overloading textConnection.

>   - It needs a man page, or to be included on the textConnection man page.

Here is an updated patch, with the rawConnection() entry point, and a
man page, against today's R-devel snapshot.  This also fixes (text or
raw) output connections to verify that the target object still exists
before writing to that object.

-- Dave



--- src/main/connections.c.orig	2005-08-29 17:47:35.000000000 -0700
+++ src/main/connections.c	2005-09-03 13:34:25.098514900 -0700
@@ -1678,7 +1678,7 @@
     return ans;
 }
 
-/* ------------------- text connections --------------------- */
+/* ------------------- text and raw connections --------------------- */
 
 /* read a R character vector into a buffer */
 static void text_init(Rconnection con, SEXP text)
@@ -1702,6 +1702,22 @@
     this->cur = this->save = 0;
 }
 
+/* read a R raw vector into a buffer */
+static void raw_init(Rconnection con, SEXP raw)
+{
+    int nbytes = length(raw);
+    Rtextconn this = (Rtextconn)con->private;
+
+    this->data = (char *) malloc(nbytes);
+    if(!this->data) {
+	free(this); free(con->description); free(con->class); free(con);
+	error(_("cannot allocate memory for raw connection"));
+    }
+    memcpy(this->data, RAW(raw), nbytes);
+    this->nchars = nbytes;
+    this->cur = this->save = 0;
+}
+
 static Rboolean text_open(Rconnection con)
 {
     con->save = -1000;
@@ -1736,41 +1752,60 @@
 
 static double text_seek(Rconnection con, double where, int origin, int rw)
 {
-    if(where >= 0) error(_("seek is not relevant for text connection"));
+    if(where >= 0) error(_("seek is not relevant for this connection"));
     return 0; /* if just asking, always at the beginning */
 }
 
-static Rconnection newtext(char *description, SEXP text)
+static size_t raw_read(void *ptr, size_t size, size_t nitems,
+		       Rconnection con)
+{
+    Rtextconn this = (Rtextconn)con->private;
+    if (this->cur + size*nitems > this->nchars) {
+	nitems = (this->nchars - this->cur)/size;
+	memcpy(ptr, this->data+this->cur, size*nitems);
+	this->cur = this->nchars;
+    } else {
+	memcpy(ptr, this->data+this->cur, size*nitems);
+	this->cur += size*nitems;
+    }
+    return nitems;
+}
+
+static Rconnection newtext(char *description, SEXP data)
 {
     Rconnection new;
+    int isText = isString(data);
     new = (Rconnection) malloc(sizeof(struct Rconn));
-    if(!new) error(_("allocation of text connection failed"));
-    new->class = (char *) malloc(strlen("textConnection") + 1);
-    if(!new->class) {
-	free(new);
-	error(_("allocation of text connection failed"));
-    }
-    strcpy(new->class, "textConnection");
+    if(!new) goto f1;
+    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
+    if(!new->class) goto f2;
+    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
     new->description = (char *) malloc(strlen(description) + 1);
-    if(!new->description) {
-	free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->description) goto f3;
     init_con(new, description, "r");
     new->isopen = TRUE;
     new->canwrite = FALSE;
     new->open = &text_open;
     new->close = &text_close;
     new->destroy = &text_destroy;
-    new->fgetc = &text_fgetc;
     new->seek = &text_seek;
     new->private = (void*) malloc(sizeof(struct textconn));
-    if(!new->private) {
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
+    if(!new->private) goto f4;
+    new->text = isText;
+    if (new->text) {
+	new->fgetc = &text_fgetc;
+	text_init(new, data);
+    } else {
+	new->read = &raw_read;
+	raw_init(new, data);
     }
-    text_init(new, text);
     return new;
+
+f4: free(new->description);
+f3: free(new->class);
+f2: free(new);
+f1: error(_("allocation of %s connection failed"),
+	  isText ? "text" : "raw");
 }
 
 static void outtext_close(Rconnection con)
@@ -1780,10 +1815,13 @@
     int idx = ConnIndex(con);
 
     if(strlen(this->lastline) > 0) {
-	PROTECT(tmp = lengthgets(this->data, ++this->len));
+	tmp = findVar1(this->namesymbol, VECTOR_ELT(OutTextData, idx),
+		       STRSXP, FALSE);
+	if (tmp == R_UnboundValue)
+	    error(_("connection endpoint unbound"));
+	PROTECT(tmp = lengthgets(tmp, ++this->len));
 	SET_STRING_ELT(tmp, this->len - 1, mkChar(this->lastline));
 	defineVar(this->namesymbol, tmp, VECTOR_ELT(OutTextData, idx));
-	this->data = tmp;
 	UNPROTECT(1);
     }
     SET_VECTOR_ELT(OutTextData, idx, R_NilValue);
@@ -1843,10 +1881,13 @@
 	if(q) {
 	    int idx = ConnIndex(con);
 	    *q = '\0';
-	    PROTECT(tmp = lengthgets(this->data, ++this->len));
+	    tmp = findVar1(this->namesymbol, VECTOR_ELT(OutTextData, idx),
+			   STRSXP, FALSE);
+	    if (tmp == R_UnboundValue)
+		error(_("connection endpoint unbound"));
+	    PROTECT(tmp = lengthgets(tmp, ++this->len));
 	    SET_STRING_ELT(tmp, this->len - 1, mkChar(p));
 	    defineVar(this->namesymbol, tmp, VECTOR_ELT(OutTextData, idx));
-	    this->data = tmp;
 	    UNPROTECT(1);
 	} else {
 	    /* retain the last line */
@@ -1864,30 +1905,50 @@
     return res;
 }
 
+static size_t raw_write(const void *ptr, size_t size, size_t nitems,
+			Rconnection con)
+{
+    Routtextconn this = (Routtextconn)con->private;
+    SEXP tmp;
+    int idx = ConnIndex(con);
+
+    tmp = findVar1(this->namesymbol, VECTOR_ELT(OutTextData, idx),
+		   RAWSXP, FALSE);
+    if (tmp == R_UnboundValue)
+	error(_("connection endpoint unbound"));
+    PROTECT(tmp = lengthgets(tmp, this->len + size*nitems));
+    memcpy(RAW(tmp)+this->len, ptr, size*nitems);
+    this->len += size*nitems;
+    defineVar(this->namesymbol, tmp, VECTOR_ELT(OutTextData, idx));
+    UNPROTECT(1);
+    return nitems;
+}
+
 static void outtext_init(Rconnection con, char *mode, int idx)
 {
     Routtextconn this = (Routtextconn)con->private;
+    int st = (con->text ? STRSXP : RAWSXP);
     SEXP val;
 
     this->namesymbol = install(con->description);
-    if(strcmp(mode, "w") == 0) {
+    if(strncmp(mode, "w", 1) == 0) {
 	/* create variable pointed to by con->description */
-	PROTECT(val = allocVector(STRSXP, 0));
+	PROTECT(val = allocVector(st, 0));
 	defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
 	UNPROTECT(1);
     } else {
 	/* take over existing variable */
 	val = findVar1(this->namesymbol, VECTOR_ELT(OutTextData, idx),
-		       STRSXP, FALSE);
+		       st, FALSE);
 	if(val == R_UnboundValue) {
-	    warning(_("text connection: appending to a non-existent char vector"));
-	    PROTECT(val = allocVector(STRSXP, 0));
+	    warning(_("%s connection: appending to a non-existent vector"),
+		    con->text ? "text" : "raw");
+	    PROTECT(val = allocVector(st, 0));
 	    defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
 	    UNPROTECT(1);
 	}
     }
     this->len = LENGTH(val);
-    this->data = val;
     this->lastline[0] = '\0';
     this->lastlinelength = LAST_LINE_LEN;
 }
@@ -1896,43 +1957,43 @@
 static Rconnection newouttext(char *description, SEXP sfile, char *mode,
 			      int idx)
 {
+    int isText = (mode[1] != 'b');
     Rconnection new;
     void *tmp;
 
     new = (Rconnection) malloc(sizeof(struct Rconn));
-    if(!new) error(_("allocation of text connection failed"));
-    new->class = (char *) malloc(strlen("textConnection") + 1);
-    if(!new->class) {
-	free(new);
-	error(_("allocation of text connection failed"));
-    }
-    strcpy(new->class, "textConnection");
+    if(!new) goto f1;
+    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
+    if(!new->class) goto f2;
+    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
     new->description = (char *) malloc(strlen(description) + 1);
-    if(!new->description) {
-	free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->description) goto f3;
     init_con(new, description, mode);
+    new->text = isText;
     new->isopen = TRUE;
     new->canread = FALSE;
     new->open = &text_open;
     new->close = &outtext_close;
     new->destroy = &outtext_destroy;
-    new->vfprintf = &text_vfprintf;
     new->seek = &text_seek;
     new->private = (void*) malloc(sizeof(struct outtextconn));
-    if(!new->private) {
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->private) goto f4;
     ((Routtextconn)new->private)->lastline = tmp = malloc(LAST_LINE_LEN);
-    if(!tmp) {
-	free(new->private);
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
+    if(!tmp) goto f5;
+    if (isText) {
+	new->vfprintf = &text_vfprintf;
+    } else {
+	new->write = &raw_write;
     }
     outtext_init(new, mode, idx);
     return new;
+
+f5: free(new->private);
+f4: free(new->description);
+f3: free(new->class);
+f2: free(new);
+f1: error(_("allocation of %s connection failed"),
+	  isText ? "text" : "raw");
 }
 
 SEXP do_textconnection(SEXP call, SEXP op, SEXP args, SEXP env)
@@ -1948,19 +2009,22 @@
 	error(_("invalid '%s' argument"), "description");
     desc = CHAR(STRING_ELT(sfile, 0));
     stext = CADR(args);
-    if(!isString(stext))
-	error(_("invalid '%s' argument"), "text");
     sopen = CADDR(args);
     if(!isString(sopen) || length(sopen) != 1)
-    error(_("invalid '%s' argument"), "open");
+	error(_("invalid '%s' argument"), "open");
     open = CHAR(STRING_ELT(sopen, 0));
     venv = CADDDR(args);
     if (!isEnvironment(venv) && venv != R_BaseEnv)
 	error(_("invalid '%s' argument"), "environment");
     ncon = NextConnection();
-    if(!strlen(open) || strncmp(open, "r", 1) == 0)
+    if(!strlen(open) || (open[0] == 'r')) {
+ 	int isText = (!strlen(open) || (open[1] != 'b'));
+ 	if (TYPEOF(stext) != (isText ? STRSXP : RAWSXP))
+ 	    error(_("invalid '%s' argument"), "object");
 	con = Connections[ncon] = newtext(desc, stext);
-    else if (strncmp(open, "w", 1) == 0 || strncmp(open, "a", 1) == 0) {
+    } else if ((open[0] == 'w') || (open[0] == 'a')) {
+	if (!isString(stext))
+	    error(_("invalid '%s' argument"), "object");
 	if (OutTextData == NULL) {
 	    OutTextData = allocVector(VECSXP, NCONNECTIONS);
 	    R_PreserveObject(OutTextData);
@@ -1976,7 +2040,7 @@
     PROTECT(ans = allocVector(INTSXP, 1));
     INTEGER(ans)[0] = ncon;
     PROTECT(class = allocVector(STRSXP, 2));
-    SET_STRING_ELT(class, 0, mkChar("textConnection"));
+    SET_STRING_ELT(class, 0, mkChar(con->class));
     SET_STRING_ELT(class, 1, mkChar("connection"));
     classgets(ans, class);
     UNPROTECT(2);
--- src/include/Rconnections.h.orig	2005-08-03 08:50:36.000000000 -0700
+++ src/include/Rconnections.h	2005-09-03 12:52:22.790700000 -0700
@@ -95,7 +95,6 @@
 typedef struct outtextconn {
     int len;  /* number of lines */
     SEXP namesymbol;
-    SEXP data;
     char *lastline;
     int lastlinelength; /* buffer size */
 } *Routtextconn;
--- src/library/base/R/connections.R.orig	2005-04-18 04:34:17.000000000 -0700
+++ src/library/base/R/connections.R	2005-09-03 11:27:07.128227400 -0700
@@ -84,6 +84,17 @@
     .Internal(socketConnection(host, port, server, blocking, open, encoding))
 
 textConnection <- function(object, open = "r", local = FALSE) {
+    if (!(open %in% c("","r","a","w")))
+        stop('unsupported mode')
+    if (local) env <- parent.frame()
+    else env <- .GlobalEnv
+    .Internal(textConnection(deparse(substitute(object)), object, open, env))
+}
+
+rawConnection <- function(object, open = "rb", local = FALSE) {
+    if (open == "") open <- "rb"
+    if (!(open %in% c("rb","ab","wb")))
+        stop("unsupported mode")
     if (local) env <- parent.frame()
     else env <- .GlobalEnv
     .Internal(textConnection(deparse(substitute(object)), object, open, env))
--- src/library/base/man/textconnections.Rd.orig	2005-09-03 13:55:48.274305900 -0700
+++ src/library/base/man/textconnections.Rd	2005-09-03 13:55:48.821177400 -0700
@@ -45,8 +45,8 @@
 }
 
 \value{
-  A connection object of class \code{"textConnection"} which inherits
-  from class \code{"connection"}.
+  A text-mode connection object of class \code{"textConnection"} which
+  inherits from class \code{"connection"}.
 }
 
 \note{
@@ -69,7 +69,8 @@
 
 \seealso{
   \code{\link{connections}}, \code{\link{showConnections}},
-  \code{\link{pushBack}}, \code{\link{capture.output}}.
+  \code{\link{pushBack}}, \code{\link{capture.output}},
+  \code{\link{rawConnection}}.
 }
 
 \examples{
--- src/library/base/man/rawconnections.Rd.orig	1969-12-31 16:00:00.000000000 -0800
+++ src/library/base/man/rawconnections.Rd	2005-09-03 13:50:13.620197700 -0700
@@ -0,0 +1,78 @@
+\name{rawConnection}
+\alias{rawConnection}
+\title{Raw Connections}
+\description{
+  Input and output raw connections.
+}
+\usage{
+rawConnection(object, open = "r", local = FALSE)
+}
+\arguments{
+  \item{object}{raw or character.  A description of the connection. 
+    For an input this is an \R raw vector object, and for an output
+    connection the name for the \R raw vector to receive the
+    output.
+  }
+  \item{open}{character.  Either \code{"rb"} (or equivalently \code{""})
+    for an input connection or \code{"wb"} or \code{"ab"} for an output
+    connection.}
+  \item{local}{logical.  Used only for output connections.  If \code{TRUE},
+    output is assigned to a variable in the calling environment.  Otherwise
+    the global environment is used.}
+}
+\details{
+  An input raw connection is opened and the raw vector is copied
+  at time the connection object is created, and \code{close}
+  destroys the copy.
+
+  An output raw connection is opened and creates an \R raw vector of
+  the given name in the user's workspace or in the calling
+  environment, depending on the value of the \code{local} argument.
+  This object will at all times hold the accumulated output to the
+  connection.
+
+  Opening a raw connection with \code{mode = "ab"} will attempt to
+  append to an existing raw vector with the given name in the user's
+  workspace or the calling environment.  If none is found (even if an
+  object exists of the right name but the wrong type) a new raw vector
+  wil be created, with a warning.
+
+  You cannot \code{seek} on a raw connection, and \code{seek} will
+  always return zero as the position.
+}
+
+\value{
+  A binary-mode connection object of class \code{"rawConnection"}
+  which inherits from class \code{"connection"}.
+}
+
+\note{
+  As output raw connections update the result vector after every
+  operation, they can be relatively expensive to use, and it may be
+  better to use an anonymous \code{\link{file}()} connection to collect
+  output when a large amount of binary data needs to be assembled.
+}
+ 
+\seealso{
+  \code{\link{connections}}, \code{\link{showConnections}},
+  \code{\link{readBin}}, \code{\link{writeBin}},
+  \code{\link{textConnection}}.
+}
+
+\examples{
+zz <- rawConnection("foo", "wb")
+writeBin(1:2, zz)
+writeBin(1:8, zz, size=1)
+writeBin(pi, zz, size=4)
+close(zz)
+foo
+
+zz <- rawConnection(foo)
+readBin(zz, "integer", n=2)
+sprintf("\%04x", readBin(zz, "integer", n=2, size=2))
+sprintf("\%08x", readBin(zz, "integer", endian="swap"))
+readBin(zz, "numeric", n=1, size=4)
+close(zz)
+}
+\keyword{file}
+\keyword{connection}


From erich.neuwirth at univie.ac.at  Sun Sep  4 02:22:25 2005
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Sun, 04 Sep 2005 02:22:25 +0200
Subject: [Rd] tapply
Message-ID: <431A3E41.2030602@univie.ac.at>

compared to by tapply has the nice property that the output is a
multidimensional array. But in its standard form it only accepts one
vector, a list of factors, and a function of one argument.
Then it splits the vector according to the factor(s) and
applies the function to each of subsets created by the split.
Therefore, it can not be used to compute weighted means
with one vector containing the data and another vector containing
the weights.

There are other ways of computing groupwise weighted means,
but they do not return multidimensional arrays, but lists.

Therefore, I rewrote tapply to handle a list of vectors as its first
argument. If the list contains n vectors, the function argument has to
be a function of n arguments. Then, all the vectors are split according
to the factor list, and the function is applied to each of the subsets
defined this way.

Following is the code for mtapply doing this.
It could be used as a replacement for tapply, since it
handles vector arguments just like the current implementation of tapply
does.

Perhaps other list members are interested in testing this function,
and perhaps there is even interest in including this extended version of
tapply in the R distribution.



#######################################

mtapply<-function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
{
    FUN <- if (!is.null(FUN))
        match.fun(FUN)
    if (!is.list(INDEX))
        INDEX <- list(INDEX)
    nI <- length(INDEX)
    namelist <- vector("list", nI)
    names(namelist) <- names(INDEX)
    extent <- integer(nI)
    nx <- ifelse(is.list(X),length(X[[1]]),length(X))
    one <- as.integer(1)
    group <- rep.int(one, nx)
    ngroup <- one
    for (i in seq(INDEX)) {
        index <- as.factor(INDEX[[i]])
        if (length(index) != nx)
            stop("arguments must have same length")
        namelist[[i]] <- levels(index)
        extent[i] <- nlevels(index)
        group <- group + ngroup * (as.integer(index) - one)
        ngroup <- ngroup * nlevels(index)
    }
    if (is.null(FUN))
        return(group)
     if (!is.list(X)) {
    ans <- lapply(split(X, group), FUN, ...)
    index <- as.numeric(names(ans))
     }
     else {
    myargs<-vector("list",length(X)+1)
     for (i in 1:length(X)) myargs[[i+1]]<-split(X[[i]],group)
     myargs[[1]]<-FUN
     ans<-do.call(mapply,myargs)
     ansx <- lapply(myargs[[2]],length)
     index <- as.numeric(names(ansx))
     }
    if (simplify && all(unlist(lapply(ans,length)) == 1)) {
        ansmat <- array(dim = extent, dimnames = namelist)
        if (is.list(ans)) ans <- unlist(ans, recursive = FALSE)
    }
    else {
        ansmat <- array(vector("list", prod(extent)), dim = extent,
            dimnames = namelist)
    }
    names(ans) <- NULL
    ansmat[index] <- ans
    ansmat
}



###########################################

-- 
Erich Neuwirth, Didactic Center for Computer Science
University of Vienna
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39902 Fax: +43-1-4277-9399


From dhinds at sonic.net  Sun Sep  4 07:42:17 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Sun, 4 Sep 2005 05:42:17 +0000 (UTC)
Subject: [Rd] A memory management question
Message-ID: <dfe1fp$buj$1@sea.gmane.org>

Can someone explain the use of SETLENGTH() and SETTRUELENGTH()?

I would like to allocate a vector and reserve some space at the end,
so that it appears shorter than the allocated size.  So that I can
more efficiently append to the vector, without requiring a new copy
every time. So I'd like to use SETLENGTH() with a shorter apparent
length, and bump this up as needed until I've used the entire space.

There are only a couple users of SETLENGTH() in R, and they all appear
at first glance to be pointless: a few routines use allocVector() and
then call SETLENGTH() to set the vector length to the value that was
just allocated.  What are valid uses for SETLENGTH()?  And what are
the intended semantics for "truelength" as opposed to the regular
length?

If GC happens and an object is moved, and its apparent LENGTH()
differs from its allocated length, does GC preserve the allocated
length, or the updated LENGTH()?  Is there any way to get at the
original allocated length, given an SEXP?

-- Dave


From rabrantes82 at gmail.com  Sun Sep  4 21:32:01 2005
From: rabrantes82 at gmail.com (Ricardo Luiz Andrade Abrantes)
Date: Sun, 4 Sep 2005 16:32:01 -0300
Subject: [Rd] .Call and Segmentation Fault
In-Reply-To: <355C35514FEAC9458F75947F5270974D076CA3@usctmx1103.merck.com>
References: <355C35514FEAC9458F75947F5270974D076CA3@usctmx1103.merck.com>
Message-ID: <973080e105090412324891faa6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050904/7fd1fa6f/attachment.pl

From p.dalgaard at biostat.ku.dk  Sun Sep  4 21:54:20 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Sep 2005 21:54:20 +0200
Subject: [Rd] .Call and Segmentation Fault
In-Reply-To: <973080e105090412324891faa6@mail.gmail.com>
References: <355C35514FEAC9458F75947F5270974D076CA3@usctmx1103.merck.com>
	<973080e105090412324891faa6@mail.gmail.com>
Message-ID: <x27jdwlic3.fsf@turmalin.kubism.ku.dk>

Ricardo Luiz Andrade Abrantes <rabrantes82 at gmail.com> writes:

> Hello there!
> I almost don't deal with SEXPs. The function's name is main() it returns a 
> SEXP wich is R_NilValue, thats all I use of SEXPs. This function call an 
> optimization packge and the output goes all to a text file.
> Well, I followed Mr. Lumley's hint and used gdb with R and my program. 
> Together with a friend we could find the problem.
> Inside the Fortran optimization package there's a subroutine called cg(...), 
> and for some wierd reason this subroutine is never called (so, some 
> variables are not correctly initialized) and the program becomes crazy.
> I did this small example to show you what happens:
> 
> File: prog.f
> -------------
> subroutine cg()
> write(*,*) 'Just a simple test'
> end
> 
> subroutine program()
> write(*,*) 'Calling the function...'
> call cg()
> end
> 
> File test.h
> ------------
> #include "cfortran.h"
> 
> PROTOCCALLSFSUB0(PROGRAM,program)
> #define program() CCALLSFSUB0(PROGRAM,program)
> 
> 
> File test.c
> ------------
> #include <R.h>
> #include <Rdefines.h>
> #include <stdio.h>
> #include "test.h"
> 
> 
> SEXP simple_program(){
> program();
> return R_NilValue;
> }
> 
> 
> I compile the C and Fortran souces into a shared lib. I open R, do a 
> dyn.load("lib's name") and then a .Call("simple_program").
> What I got?
> Calling the function...
> Segmentation fault
> 
> What if I change the cg function's name to pp? My Fortran code is now:
> 
> File: prog.f
> -------------
> subroutine pp()
> write(*,*) 'Just a simple test'
> end
> 
> subroutine program()
> write(*,*) 'Calling the function...'
> call pp()
> end
> 
> And the output from R is:
> 
> Calling the function...
> Just a simple test
> NULL
> 
> Can anyone explain this? Is there a way to solve it? The optimization 
> package I use has the "cg" function, and I cannot change it's name!

Hmmmm.... Did you ever tell us

1) Exactly what your platform is
2) How you generated the shared library (R CMD SHLIB, or?)
3) What you did to load it into R

?

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From rabrantes82 at gmail.com  Sun Sep  4 21:54:44 2005
From: rabrantes82 at gmail.com (rabrantes82@gmail.com)
Date: Sun,  4 Sep 2005 21:54:44 +0200 (CEST)
Subject: [Rd] .Call with C and Fortran together (PR#8122)
Message-ID: <20050904195444.15D49CBFC@slim.kubism.ku.dk>

Full_Name: Ricardo Luiz de Andrade Abrantes
Version: 2.1.1
OS: Debian Linux, kernel 2.6.8
Submission from: (NULL) (201.6.83.153)


The problem can be well explained with the following example:
Suppose I made a program in fortran, and a C interfacece to it. Now I want to
use this C interface in R to call my fortran program. Then I modified my C file
to deal with SEXPs and compile it as a shared lib. Look at the files:

File: prog.f
-------------
      subroutine cg()
      write(*,*) 'Just a simple test'
      end

      subroutine program()
      write(*,*) 'Calling the function...'
      call cg()
      end

File test.h
------------
#include "cfortran.h"

PROTOCCALLSFSUB0(PROGRAM,program)
#define program() CCALLSFSUB0(PROGRAM,program)


File test.c
------------
#include <R.h>
#include <Rdefines.h>
#include <stdio.h>

SEXP simple_program(){
  program();
  return R_NilValue;
}


I compile the C and Fortran souces into a shared lib, open R, do a
dyn.load("lib's name") and then a .Call("simple_program").
What I got?
Calling the function...
Segmentation fault

What if I change the cg function's name to pp? My Fortran code is now:

File: prog.f
-------------
      subroutine pp()
      write(*,*) 'Just a simple test'
      end

      subroutine program()
      write(*,*) 'Calling the function...'
      call pp()
      end

And the output from R is:

 Calling the function...
 Just a simple test
NULL

In some machines I don't get the segmentation fault problem, but I don't get the
message "Just a simple test" either (when using "cg" as the subroutine's name).
I believe this is bug in R because if I change my C interface again to return a
0 instead of a R_NilValue, and then use it with another C program wich loads the
dynamic library amd call the function simple_program(), everything work
perfectly.


   Thanks,


         Ricardo


From rabrantes82 at gmail.com  Sun Sep  4 22:01:39 2005
From: rabrantes82 at gmail.com (Ricardo Luiz Andrade Abrantes)
Date: Sun, 4 Sep 2005 17:01:39 -0300
Subject: [Rd] .Call and Segmentation Fault
In-Reply-To: <x27jdwlic3.fsf@turmalin.kubism.ku.dk>
References: <355C35514FEAC9458F75947F5270974D076CA3@usctmx1103.merck.com>
	<973080e105090412324891faa6@mail.gmail.com>
	<x27jdwlic3.fsf@turmalin.kubism.ku.dk>
Message-ID: <973080e1050904130143511256@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050904/5d53c8ab/attachment.pl

From luke at stat.uiowa.edu  Mon Sep  5 01:26:28 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sun, 4 Sep 2005 18:26:28 -0500 (CDT)
Subject: [Rd] A memory management question
In-Reply-To: <dfe1fp$buj$1@sea.gmane.org>
References: <dfe1fp$buj$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.63.0509041814200.5751@itasca2.wildberry.org>


On Sun, 4 Sep 2005, dhinds at sonic.net wrote:

> Can someone explain the use of SETLENGTH() and SETTRUELENGTH()?
>
> I would like to allocate a vector and reserve some space at the end,
> so that it appears shorter than the allocated size.  So that I can
> more efficiently append to the vector, without requiring a new copy
> every time. So I'd like to use SETLENGTH() with a shorter apparent
> length, and bump this up as needed until I've used the entire space.

>
> There are only a couple users of SETLENGTH() in R, and they all appear
> at first glance to be pointless: a few routines use allocVector() and
> then call SETLENGTH() to set the vector length to the value that was
> just allocated.  What are valid uses for SETLENGTH()?  And what are
> the intended semantics for "truelength" as opposed to the regular
> length?
>

This is not supported by the memory manager.  Using SETLENGTH to
change the length would confuse the garbage collector--we should
probably remove SETLENGTH from the headers.

TRUELENGTH is unused except for something very different in envir.c.
Again we should probably remove or rename this to reflect how it is
currently used.  At one point, well before the current memory manager,
I believe there was thought that we might allow this sort of
over-allocation but I don't believe it was ever implemented.

The memory manager does over-allocate small vectors by rounding up to
convenient sizes, and the real size could be computed, but this is not
true for large allocations--these correspond to malloc calls for the
requested size--and in any case the memory manager relies on LENGTH
giving the correct amount (maybe not heavily but this could change).

> If GC happens and an object is moved, and its apparent LENGTH()
> differs from its allocated length, does GC preserve the allocated
> length, or the updated LENGTH()?  Is there any way to get at the
> original allocated length, given an SEXP?

A GC does not move objects.

Using R level vectors for the purpose you describe is in any case
tricky since it is hard to reliably prevent copying. You are better
off using something like an external pointer into an R-allocated
object that is only accessible through the external pointer.  Then you
can manage the filled length yourself.

luke


-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke at stat.uiowa.edu  Mon Sep  5 01:32:02 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sun, 4 Sep 2005 18:32:02 -0500 (CDT)
Subject: [Rd] Writing R-extensions
In-Reply-To: <Pine.LNX.4.61.0508271504001.4656@gannet.stats>
References: <17168.22195.533974.55934@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0508271504001.4656@gannet.stats>
Message-ID: <Pine.LNX.4.63.0509041830520.5751@itasca2.wildberry.org>

On Sat, 27 Aug 2005, Prof Brian Ripley wrote:

> On Sat, 27 Aug 2005, Berwin A Turlach wrote:

  ...

>> 3) The final sentence in the section on `Registering S3 methods' is:
>>
>>        Any methods for a generic defined in a package that does not
>>        use a name space should be exported, and the package defining
>>        and exporting the method should be attached to the search path
>>        if the methods are to be found.
>>
>>   I wonder whether this should actually be:
>>
>>        Any methods for a generic defined in a package that does not
>>        use a name space should be exported, and the package defining
>>        and exporting the generic should be attached to the search path
>>                          ^^^^^^^
>>        if the methods are to be found.
>>
>>   Or is the implication of that sentence that if I have a package
>>   with a name space which defines a method for a generic defined in
>>   another package that does not use a name space, then this method
>>   is only found if my package is attached to the search path and
>>   mere loading of the namespace is not sufficient?
>

There is no typo here and your reading in the paragraph above is
correct.

Best,

luke

> I think we need to check with the author (Luke, r23430).  If the generic
> is not visible there is no dispatch and so this would be irrelevant.
> Assuming a typo, your implication is what the svn log entry says and how I
> read the text.
>
> r23430 | luke | 2003-03-02 18:52:13 +0000 (Sun, 02 Mar 2003) | 3 lines
>
> Added wording to clarify that S3method registration should only be used if
> the generic is defined in a work space.
>                             name?
  ...

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From berwin at maths.uwa.edu.au  Mon Sep  5 03:17:07 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 5 Sep 2005 09:17:07 +0800
Subject: [Rd] Writing R-extensions
In-Reply-To: <Pine.LNX.4.63.0509041830520.5751@itasca2.wildberry.org>
References: <17168.22195.533974.55934@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0508271504001.4656@gannet.stats>
	<Pine.LNX.4.63.0509041830520.5751@itasca2.wildberry.org>
Message-ID: <17179.40083.1023.917759@bossiaea.maths.uwa.edu.au>

G'day Luke,

>>>>> "LT" == Luke Tierney <luke at stat.uiowa.edu> writes:

    >> On Sat, 27 Aug 2005, Berwin A Turlach wrote:

    >>> 3) The final sentence in the section on `Registering S3
    >>> methods' is:
    >>> 
    >>> Any methods for a generic defined in a package that does not
    >>> use a name space should be exported, and the package defining
    >>> and exporting the method should be attached to the search path
    >>> if the methods are to be found.
    >>> 
    >>> [...] is the implication of that sentence that if I have a
    >>> package with a name space which defines a method for a generic
    >>> defined in another package that does not use a name space,
    >>> then this method is only found if my package is attached to
    >>> the search path and mere loading of the namespace is not
    >>> sufficient?

    LT> There is no typo here and your reading in the paragraph above
    LT> is correct.
Thanks for the clarification.  

May I suggest that nevertheless there is a typo in this sentence and
it should be ".... the package defining and exporting the methods..."?
One reason why this sentence had me puzzled was that it uses twice
"methods" and once "method". :)

Cheers,

        Berwin


From dhinds at sonic.net  Mon Sep  5 09:25:38 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Mon, 5 Sep 2005 07:25:38 +0000 (UTC)
Subject: [Rd] A memory management question
References: <dfe1fp$buj$1@sea.gmane.org>
	<Pine.LNX.4.63.0509041814200.5751@itasca2.wildberry.org>
Message-ID: <dfgrti$6tn$1@sea.gmane.org>

Luke Tierney <luke at stat.uiowa.edu> wrote:

> This is not supported by the memory manager.  Using SETLENGTH to
> change the length would confuse the garbage collector--we should
> probably remove SETLENGTH from the headers.

> The memory manager does over-allocate small vectors by rounding up to
> convenient sizes, and the real size could be computed, but this is not
> true for large allocations--these correspond to malloc calls for the
> requested size--and in any case the memory manager relies on LENGTH
> giving the correct amount (maybe not heavily but this could change).

> A GC does not move objects.

> Using R level vectors for the purpose you describe is in any case
> tricky since it is hard to reliably prevent copying. You are better
> off using something like an external pointer into an R-allocated
> object that is only accessible through the external pointer.  Then you
> can manage the filled length yourself.

Ok... since GC does not move objects, and large vectors are allocated
using a regular malloc, and malloc/free manages space independent of
the LENGTH information, it seems that SETLENGTH would be "safe" if it
was possible to guarantee for an interval of time that this particular
value would not be moved or released due to any user activity?

What if I create the full-length vector, make it visible using
defineVar(), then protect the vector by creating a reference with
R_MakeExternalPtr(), and R_PreserveObject() this reference?  Then
shouldn't the vector be left alone until I release the reference?
And I could then play with SETLENGTH() on that vector safely, so long
as I restore it before releasing the reference, and so long as I only
perform operations that modify the vector in-place?

i.e., should something like this work:

static SEXP ptr;

do_init()
{
    SEXP s = PROTECT(allocVector(RAWSXP, 1000));
    defineVar("mystuff", s, R_BaseEnv);
    ptr = R_MakeExternalPtr(RAW(s), R_NilValue, s);
    R_PreserveObject(ptr);
    SETLENGTH(s, 0);
    UNPROTECT(1);
}

do_extend()
{
    SEXP s = R_ExternalPtrProtected(ptr);
    memcpy(RAW(s)+LENGTH(s), "xxxx", 4);
    SETLENGTH(s, LENGTH(s)+4);
}

do_finish()
{
    SEXP s = R_ExternalPtrProtected(ptr);
    SETLENGTH(s, 1000);
    R_ReleaseObject(ptr);
}

i.e., if the user tries to modify "mystuff", they'll end up with a
copy, but the value pointed to by ptr will hang around (no longer
accessible by the user) until do_finish() is called?

-- Dave


From f.hahne at dkfz-heidelberg.de  Mon Sep  5 09:51:18 2005
From: f.hahne at dkfz-heidelberg.de (Florian Hahne)
Date: Mon, 05 Sep 2005 09:51:18 +0200
Subject: [Rd] RODBC and 64 bit
Message-ID: <1125906678.7238.20.camel@snoopy.inet.dkfz-heidelberg.de>

Hi all,
I was quite succesfully working with the RODB package on a 32 bit linux
box to connect to a MSSQL Server via the freeTSL driver. After changing
to a 64 bit environment I ran into some segmentation faults using
function sqlUpdate on large database operations (the actual seg faults
occured in the call to the C function ODBCUpdate).
I just briefly looked into the code and found some extensive type
casting going on so I figured this might be a 64 bit problem with the
'SQL_C_SLONG' and 'SQL_C_DOUBLE' data types. However I can't rule out
the possibility that my TSL driver is messing up some things. I also
tried to reproduce the error with dummy data but here everything seems
to be fine (this might not be big eneugh). 
As a quick solution I tried using the option fast=FALSE, but again ran
into problems, this time R related:
The code lines

 cc <- grep("char", tolower(as.character(cdata[, 6])))
        if (length(cc))
            data[, cc] <- paste("'", data[, cc], "'", sep = "")

look up the columns with character data types from the database
specifications and includes parantheses that are later necessary for the
SQL query. This works fine as long as you are updating all database
columns. However if you only update a subset this will identify the
wrong columns in you data frame as being character. Something along the
lines of  

 cc <- grep("char", tolower(as.character(cdata[match(cnames,
            cdata[, 4]), 6])))
        if (length(cc))
            data[, cc] <- paste("'", data[, cc], "'", sep = "")

should fix that problem.
Hope anybody has an idea about the memory issue, since the fast=FALSE
option does exactly what its name suggests ;-)

Florian

     
-- 
Florian Hahne
Molecular Genome Analysis (B050)
German Cancer Research Center
Im Neuenheimer Feld 580
D-69120 Heidelberg
Germany
room TP3 2.204
phone ++49 6221 42-4764
email f.hahne at dkfz.de


From luke at stat.uiowa.edu  Mon Sep  5 13:35:27 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 5 Sep 2005 06:35:27 -0500 (CDT)
Subject: [Rd] A memory management question
In-Reply-To: <dfgrti$6tn$1@sea.gmane.org>
References: <dfe1fp$buj$1@sea.gmane.org>
	<Pine.LNX.4.63.0509041814200.5751@itasca2.wildberry.org>
	<dfgrti$6tn$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.63.0509050624390.5751@itasca2.wildberry.org>

On Mon, 5 Sep 2005, dhinds at sonic.net wrote:

> Luke Tierney <luke at stat.uiowa.edu> wrote:
>
>> This is not supported by the memory manager.  Using SETLENGTH to
>> change the length would confuse the garbage collector--we should
>> probably remove SETLENGTH from the headers.
>
>> The memory manager does over-allocate small vectors by rounding up to
>> convenient sizes, and the real size could be computed, but this is not
>> true for large allocations--these correspond to malloc calls for the
>> requested size--and in any case the memory manager relies on LENGTH
>> giving the correct amount (maybe not heavily but this could change).
>
>> A GC does not move objects.
>
>> Using R level vectors for the purpose you describe is in any case
>> tricky since it is hard to reliably prevent copying. You are better
>> off using something like an external pointer into an R-allocated
>> object that is only accessible through the external pointer.  Then you
>> can manage the filled length yourself.
>
> Ok... since GC does not move objects, and large vectors are allocated
> using a regular malloc, and malloc/free manages space independent of
> the LENGTH information, it seems that SETLENGTH would be "safe" if it
> was possible to guarantee for an interval of time that this particular
> value would not be moved or released due to any user activity?
>
> What if I create the full-length vector, make it visible using
> defineVar(), then protect the vector by creating a reference with
> R_MakeExternalPtr(), and R_PreserveObject() this reference?  Then
> shouldn't the vector be left alone until I release the reference?
> And I could then play with SETLENGTH() on that vector safely, so long
> as I restore it before releasing the reference, and so long as I only
> perform operations that modify the vector in-place?

It might or might not work now but is not guaranteed to do so reliably
in the future.  Seeing the risks of leaving SETLENGTH exposed, it is
very likely that SETLENGTH will be removed from the sources after the
2.2.0 release.

If you provide your own methods to read and write the external pointer
then you don' need this; this is safer than relying on undocumented
behavior of [ and [<- in any case.  You also then don't need to use
R_PreserveObject unless you really need to use it from the C level
outside of a context where an R reference exists.

luke



> i.e., should something like this work:
>
> static SEXP ptr;
>
> do_init()
> {
>    SEXP s = PROTECT(allocVector(RAWSXP, 1000));
>    defineVar("mystuff", s, R_BaseEnv);
>    ptr = R_MakeExternalPtr(RAW(s), R_NilValue, s);
>    R_PreserveObject(ptr);
>    SETLENGTH(s, 0);
>    UNPROTECT(1);
> }
>
> do_extend()
> {
>    SEXP s = R_ExternalPtrProtected(ptr);
>    memcpy(RAW(s)+LENGTH(s), "xxxx", 4);
>    SETLENGTH(s, LENGTH(s)+4);
> }
>
> do_finish()
> {
>    SEXP s = R_ExternalPtrProtected(ptr);
>    SETLENGTH(s, 1000);
>    R_ReleaseObject(ptr);
> }
>
> i.e., if the user tries to modify "mystuff", they'll end up with a
> copy, but the value pointed to by ptr will hang around (no longer
> accessible by the user) until do_finish() is called?
>
> -- Dave
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From f.hahne at dkfz-heidelberg.de  Mon Sep  5 13:41:54 2005
From: f.hahne at dkfz-heidelberg.de (Florian Hahne)
Date: Mon, 05 Sep 2005 13:41:54 +0200
Subject: [Rd] RODBC and 64 bit
Message-ID: <1125920514.7238.33.camel@snoopy.inet.dkfz-heidelberg.de>

I forgot to include some more information.

Here is my sessionInfo
R version 2.2.0, 2005-08-24, x86_64-unknown-linux-gnu

attached base packages:
[1] "grid"      "tools"     "methods"   "stats"     "graphics"
"grDevices"
[7] "utils"     "datasets"  "base"

other attached packages:
       RODBC        prada RColorBrewer      Biobase
     "1.1-4"      "1.4.7"      "0.2-3"      "1.6.6"

and I am running Suse 9.3 on Intel Pentium 650 3.4GHz CPU with EM64
technology.

The TDS driver is the latest release of freeTDS (version 0.64), the DSN
is configured using unixODBC and I am connecting to a MSSQL 2000 Server.

Hope this helps,
FLorian

-- 
Florian Hahne
Molecular Genome Analysis (B050)
German Cancer Research Center
Im Neuenheimer Feld 580
D-69120 Heidelberg
Germany
room TP3 2.204
phone ++49 6221 42-4764
email f.hahne at dkfz.de


From tlumley at u.washington.edu  Mon Sep  5 19:05:24 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 5 Sep 2005 10:05:24 -0700 (PDT)
Subject: [Rd] .Call with C and Fortran together (PR#8122)
In-Reply-To: <20050904195444.15D49CBFC@slim.kubism.ku.dk>
References: <20050904195444.15D49CBFC@slim.kubism.ku.dk>
Message-ID: <Pine.A41.4.63a.0509050929430.366298@homer04.u.washington.edu>


>
> In some machines I don't get the segmentation fault problem, but I don't get the
> message "Just a simple test" either (when using "cg" as the subroutine's name).
> I believe this is bug in R because if I change my C interface again to return a
> 0 instead of a R_NilValue, and then use it with another C program wich loads the
> dynamic library amd call the function simple_program(), everything work
> perfectly.
>

I don't think it is an R bug.  I think it is because there is already a 
Fortran function called cg in R. The fact that changing the name matters 
suggest that you have a linking problem, and this turns out to be the 
case.

When I try running your code under gdb in R as Peter Dalgaard suggested 
(after editing it to use R's macros for calling fortran from C instead of 
"cfortran.h" which I don't have), I get

> .Call("simple_program")
  Calling the function...

Program received signal SIGSEGV, Segmentation fault.
0x081604e5 in cg_ (nm=0x9e5dda4, n=0xbfefccfc, ar=0xbfefcce8, ai=0x89a826,
     wr=0x9e5dda4, wi=0x9790cc0, matz=0x56090a0, zr=0x80992d4, zi=0x0, 
fv1=0x0,
     fv2=0x9e745f8, fv3=0x89a810, ierr=0x706d6973) at eigen.f:3416
3416          IERR = 10 * N
Current language:  auto; currently fortran


That is, your program is calling the Fortran subroutine CG in eigen.f, 
rather than your CG.

There should be some set of linker flags that makes sure your definition 
of CG is used, but I don't know what it would be (and it's probably very 
platform dependent)

 	-thomas


From dhinds at sonic.net  Mon Sep  5 19:18:10 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Mon, 5 Sep 2005 17:18:10 +0000 (UTC)
Subject: [Rd] A memory management question
References: <dfe1fp$buj$1@sea.gmane.org>
	<Pine.LNX.4.63.0509041814200.5751@itasca2.wildberry.org>
	<dfgrti$6tn$1@sea.gmane.org>
	<Pine.LNX.4.63.0509050624390.5751@itasca2.wildberry.org>
Message-ID: <dfhuki$jvv$1@sea.gmane.org>

Luke Tierney <luke at stat.uiowa.edu> wrote:

> It might or might not work now but is not guaranteed to do so reliably
> in the future.  Seeing the risks of leaving SETLENGTH exposed, it is
> very likely that SETLENGTH will be removed from the sources after the
> 2.2.0 release.

> If you provide your own methods to read and write the external pointer
> then you don' need this; this is safer than relying on undocumented
> behavior of [ and [<- in any case.  You also then don't need to use
> R_PreserveObject unless you really need to use it from the C level
> outside of a context where an R reference exists.

I'm not sure I follow this.  Maybe I should explain the context for
the problem.

textConnection("xyz", "w") creates a connection, the output of which
is deposited in a char vector named "xyz", which is updated line by
line as output is sent to the connection.  The current code maintains
a pointer to "xyz" in the form of an unprotected SEXP.  Hence if the
user does rm(xyz), bad things happen.  A small bug, I admit.

I think the best fix is to use a protected reference to the result
vector.  I think this is safe and doesn't rely on any abuse of the
interfaces.

There's also a performance issue, that the result is updated after
every line of output, resulting in a vast amount of copying if a large
result is accumulated.  This is the part that could be fixed by using
SETLENGTH to manage the length of the protected result vector.

I'm not sure what you mean by undocumented behavior of [ and [<-.  I
think all I'm relying on is that as long as an outstanding reference
to the result vector exists, that R has to make sure the reference
remains valid, and hence can't change the memory allocation of the
result vector in any way.  I don't care what else happens to the
contents of the vector, as long as I get to control when it is
released.  It is ok with me if the user modifies the result vector
in-place, since my reference stays valid.  So I don't actually care
how [ and [<- work.

I think the only undocumented thing I'm relying on, is that the memory
manager doesn't pay attention to the LENGTH of objects that it isn't
actively doing anything to.  Currently, it actually only uses LENGTH
in one spot: for updating R_LargeVallocSize when a large vector is
released.  The true allocation sizes for individual objects are always
kept in another place (either by malloc, or in the node class of the
object).

It seems like in this limited usage, SETLENGTH does represent a useful
feature, by permitting safe over-allocation of a protected object, and
might be worth preserving (and documenting) for that purpose.  

Of course, the real problem here is the semantics of textConnection(),
which make life much more difficult and can't be changed because they
are specified outside of R.

-- Dave


From luke at stat.uiowa.edu  Mon Sep  5 21:02:14 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 5 Sep 2005 14:02:14 -0500 (CDT)
Subject: [Rd] A memory management question
In-Reply-To: <dfhuki$jvv$1@sea.gmane.org>
References: <dfe1fp$buj$1@sea.gmane.org>
	<Pine.LNX.4.63.0509041814200.5751@itasca2.wildberry.org>
	<dfgrti$6tn$1@sea.gmane.org>
	<Pine.LNX.4.63.0509050624390.5751@itasca2.wildberry.org>
	<dfhuki$jvv$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.63.0509051338000.5751@itasca2.wildberry.org>

On Mon, 5 Sep 2005, dhinds at sonic.net wrote:

> Luke Tierney <luke at stat.uiowa.edu> wrote:
>
>> It might or might not work now but is not guaranteed to do so reliably
>> in the future.  Seeing the risks of leaving SETLENGTH exposed, it is
>> very likely that SETLENGTH will be removed from the sources after the
>> 2.2.0 release.
>
>> If you provide your own methods to read and write the external pointer
>> then you don' need this; this is safer than relying on undocumented
>> behavior of [ and [<- in any case.  You also then don't need to use
>> R_PreserveObject unless you really need to use it from the C level
>> outside of a context where an R reference exists.
>
> I'm not sure I follow this.  Maybe I should explain the context for
> the problem.
>
> textConnection("xyz", "w") creates a connection, the output of which
> is deposited in a char vector named "xyz", which is updated line by
> line as output is sent to the connection.  The current code maintains
> a pointer to "xyz" in the form of an unprotected SEXP.  Hence if the
> user does rm(xyz), bad things happen.  A small bug, I admit.
>
> I think the best fix is to use a protected reference to the result
> vector.  I think this is safe and doesn't rely on any abuse of the
> interfaces.
> 
> There's also a performance issue, that the result is updated after
> every line of output, resulting in a vast amount of copying if a large
> result is accumulated.  This is the part that could be fixed by using
> SETLENGTH to manage the length of the protected result vector.
>
> I'm not sure what you mean by undocumented behavior of [ and [<-.  I
> think all I'm relying on is that as long as an outstanding reference
> to the result vector exists, that R has to make sure the reference
> remains valid, and hence can't change the memory allocation of the
> result vector in any way.  I don't care what else happens to the
> contents of the vector, as long as I get to control when it is
> released.  It is ok with me if the user modifies the result vector
> in-place, since my reference stays valid.  So I don't actually care
> how [ and [<- work.

It would have helped to explain what you are up to.  I had to guess
and guessed wrong, so forget the [ and [<- issue for now.

> I think the only undocumented thing I'm relying on, is that the memory
> manager doesn't pay attention to the LENGTH of objects that it isn't
> actively doing anything to.  Currently, it actually only uses LENGTH
> in one spot: for updating R_LargeVallocSize when a large vector is
> released.  The true allocation sizes for individual objects are always
> kept in another place (either by malloc, or in the node class of the
> object).
>
> It seems like in this limited usage, SETLENGTH does represent a useful
> feature, by permitting safe over-allocation of a protected object, and
> might be worth preserving (and documenting) for that purpose.

I am not comfortable making this available at this point.  It might be
useful to have but would need careful thought.  Without some way to
find out the true length there are potential problems.  Without some
way of making sure the fields in VECSXP and STRSXP that are added are
valid there are potential problems (not the first time but if the size
is shrunk and then increased).  Not that this can't be resolved but it
would take time that I don't have now, and this isn't high priority
enough to schedule in the near future.  So for now you should not use
SETLENGTH if you want your code to work beyond 2.2.0.

> Of course, the real problem here is the semantics of textConnection(),
> which make life much more difficult and can't be changed because they
> are specified outside of R.

It may be possible to expand the semantics by adding a logical
argument that controls whether the vector is to be over-allocated and
filled with zero length strings and truncated to the true length on
close.  Another variant would be to have a logical argument that says
to keep the input internally and provide a function, say
textConnectionOutput, to retrieve the internal output.  I would then
use a linked list internally.  The semantics of close complicate this
a bit; this function would probably need to optionally close the
connection to get a final complete line.

luke

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke at stat.uiowa.edu  Tue Sep  6 03:54:03 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 5 Sep 2005 20:54:03 -0500 (CDT)
Subject: [Rd] Writing R-extensions
In-Reply-To: <17179.40083.1023.917759@bossiaea.maths.uwa.edu.au>
References: <17168.22195.533974.55934@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0508271504001.4656@gannet.stats>
	<Pine.LNX.4.63.0509041830520.5751@itasca2.wildberry.org>
	<17179.40083.1023.917759@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.63.0509052053310.5751@itasca2.wildberry.org>

On Mon, 5 Sep 2005, Berwin A Turlach wrote:

> G'day Luke,
>
>>>>>> "LT" == Luke Tierney <luke at stat.uiowa.edu> writes:
>
>    >> On Sat, 27 Aug 2005, Berwin A Turlach wrote:
>
>    >>> 3) The final sentence in the section on `Registering S3
>    >>> methods' is:
>    >>>
>    >>> Any methods for a generic defined in a package that does not
>    >>> use a name space should be exported, and the package defining
>    >>> and exporting the method should be attached to the search path
>    >>> if the methods are to be found.
>    >>>
>    >>> [...] is the implication of that sentence that if I have a
>    >>> package with a name space which defines a method for a generic
>    >>> defined in another package that does not use a name space,
>    >>> then this method is only found if my package is attached to
>    >>> the search path and mere loading of the namespace is not
>    >>> sufficient?
>
>    LT> There is no typo here and your reading in the paragraph above
>    LT> is correct.
> Thanks for the clarification.
>
> May I suggest that nevertheless there is a typo in this sentence and
> it should be ".... the package defining and exporting the methods..."?
> One reason why this sentence had me puzzled was that it uses twice
> "methods" and once "method". :)

All three are now "methods"

Best,

luke

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ggrothendieck at gmail.com  Tue Sep  6 04:31:14 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 5 Sep 2005 22:31:14 -0400
Subject: [Rd] win.packages.html not found
Message-ID: <971536df05090519315e156c87@mail.gmail.com>

I am using Windows XP and

"R version 2.2.0, 2005-09-03"

and am getting the following message when I try to install or check a
package using
Rcmd check or Rcmd install:

Error in get(x, envir, mode, inherits) : variable "win.packages.html" was not fo
und

It seems to be looking for the indicated file but can't find it.  I
have not seen
this message before.  I am not sure if its related to 2.2.0 or something else.

Can anyone suggest how to proceed?

Thanks.


From ggrothendieck at gmail.com  Tue Sep  6 04:51:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 5 Sep 2005 22:51:01 -0400
Subject: [Rd] win.packages.html not found
In-Reply-To: <971536df05090519315e156c87@mail.gmail.com>
References: <971536df05090519315e156c87@mail.gmail.com>
Message-ID: <971536df05090519511da958cd@mail.gmail.com>

To answer my own question I had mixed up my library paths and
it seemed that it was using the tools package from R 2.1 due to
this error even though I was using R 2.2.  Once I corrected that the
error message goes away.

On 9/5/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> I am using Windows XP and
> 
> "R version 2.2.0, 2005-09-03"
> 
> and am getting the following message when I try to install or check a
> package using
> Rcmd check or Rcmd install:
> 
> Error in get(x, envir, mode, inherits) : variable "win.packages.html" was not fo
> und
> 
> It seems to be looking for the indicated file but can't find it.  I
> have not seen
> this message before.  I am not sure if its related to 2.2.0 or something else.
> 
> Can anyone suggest how to proceed?
> 
> Thanks.
>


From ggrothendieck at gmail.com  Tue Sep  6 05:48:42 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 5 Sep 2005 23:48:42 -0400
Subject: [Rd] Problem in R 2.2.0 with environments and [
Message-ID: <971536df05090520486999efd6@mail.gmail.com>

I have found a problem with R 2.2.0 under Windows XP.

Under R 2.1.1 patched I get the following result as expected.  First
we define a function f which displays the names of its arguments,
rather than their values.  We define a variable x whose value
is an environment and whose class is c("x", "environment").
f(x, x) then gives the expected result of "x" and "x".  If,
if we assign f to "[.x" then x[x] also gives "x" and "x" as 
expected under R 2.1.1 patched but _not_ under R 2.2.0.

First we show it under R 2.1.1 where everything works as expected:

> f <- function(x, y) { print(deparse(substitute(x))); print(deparse(substitute(y))) }
> x <- .GlobalEnv
> class(x) <- c("x", "environment")
> f(x, x)
[1] "x"
[1] "x"
> "[.x" <- f
> x[x]  ########## this is what we would have expected so its ok
[1] "x"
[1] "x"
> 
> R.version.string
[1] "R version 2.1.1, 2005-06-23"

Now lets repeat the above under R 2.2.0 and we see that f(x,x)
works as expected but not x[x] even though   "[.x" has set to equal f.
Unlike the situation in R 2.1.1 now f(x,x) and x[x] give
different results even though "[.x" was set to equal f.

> f <- function(x, y) { print(deparse(substitute(x))); print(deparse(substitute(y))) }
> x <- .GlobalEnv
> class(x) <- c("x", "environment")
> f(x, x)
[1] "x"
[1] "x"
> ################# now x[x] and f(x,x) should give same result
> "[.x" <- f
> x[x]  ####################### does not give the same as f(x,x) 
[1] "<environment>"
[1] "<environment>"
> 
> R.version.string
[1] "R version 2.2.0, 2005-09-03"


From dhinds at sonic.net  Tue Sep  6 07:48:26 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Tue, 6 Sep 2005 05:48:26 +0000 (UTC)
Subject: [Rd] A memory management question
References: <dfe1fp$buj$1@sea.gmane.org>
	<Pine.LNX.4.63.0509041814200.5751@itasca2.wildberry.org>
	<dfgrti$6tn$1@sea.gmane.org>
	<Pine.LNX.4.63.0509050624390.5751@itasca2.wildberry.org>
	<dfhuki$jvv$1@sea.gmane.org>
	<Pine.LNX.4.63.0509051338000.5751@itasca2.wildberry.org>
Message-ID: <dfjaja$or4$1@sea.gmane.org>

Luke Tierney <luke at stat.uiowa.edu> wrote:

> I am not comfortable making this available at this point.  It might be
> useful to have but would need careful thought.  Without some way to
> find out the true length there are potential problems.  Without some
> way of making sure the fields in VECSXP and STRSXP that are added are
> valid there are potential problems (not the first time but if the size
> is shrunk and then increased).  Not that this can't be resolved but it
> would take time that I don't have now, and this isn't high priority
> enough to schedule in the near future.  So for now you should not use
> SETLENGTH if you want your code to work beyond 2.2.0.

Ok, that's fine... given the lack of other valid uses of SETLENGTH, it
doesn't seem worth preserving it just for this one debatable usage.

> It may be possible to expand the semantics by adding a logical
> argument that controls whether the vector is to be over-allocated and
> filled with zero length strings and truncated to the true length on
> close.  Another variant would be to have a logical argument that says
> to keep the input internally and provide a function, say
> textConnectionOutput, to retrieve the internal output.

These are possible... or optionally just don't reveal the intermediate
output at all, and just make the final result visible on close...

-- Dave


From ggrothendieck at gmail.com  Tue Sep  6 07:52:36 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 6 Sep 2005 01:52:36 -0400
Subject: [Rd] Problem in R 2.2.0 with environments and [
In-Reply-To: <971536df05090520486999efd6@mail.gmail.com>
References: <971536df05090520486999efd6@mail.gmail.com>
Message-ID: <971536df05090522523ea9f109@mail.gmail.com>

Sorry. I think this "problem" was actually the same one as my previous
post where I set my library path wrong.  Once I set it correctly both
versions worked fine.

On 9/5/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> I have found a problem with R 2.2.0 under Windows XP.
> 
> Under R 2.1.1 patched I get the following result as expected.  First
> we define a function f which displays the names of its arguments,
> rather than their values.  We define a variable x whose value
> is an environment and whose class is c("x", "environment").
> f(x, x) then gives the expected result of "x" and "x".  If,
> if we assign f to "[.x" then x[x] also gives "x" and "x" as
> expected under R 2.1.1 patched but _not_ under R 2.2.0.
> 
> First we show it under R 2.1.1 where everything works as expected:
> 
> > f <- function(x, y) { print(deparse(substitute(x))); print(deparse(substitute(y))) }
> > x <- .GlobalEnv
> > class(x) <- c("x", "environment")
> > f(x, x)
> [1] "x"
> [1] "x"
> > "[.x" <- f
> > x[x]  ########## this is what we would have expected so its ok
> [1] "x"
> [1] "x"
> >
> > R.version.string
> [1] "R version 2.1.1, 2005-06-23"
> 
> Now lets repeat the above under R 2.2.0 and we see that f(x,x)
> works as expected but not x[x] even though   "[.x" has set to equal f.
> Unlike the situation in R 2.1.1 now f(x,x) and x[x] give
> different results even though "[.x" was set to equal f.
> 
> > f <- function(x, y) { print(deparse(substitute(x))); print(deparse(substitute(y))) }
> > x <- .GlobalEnv
> > class(x) <- c("x", "environment")
> > f(x, x)
> [1] "x"
> [1] "x"
> > ################# now x[x] and f(x,x) should give same result
> > "[.x" <- f
> > x[x]  ####################### does not give the same as f(x,x)
> [1] "<environment>"
> [1] "<environment>"
> >
> > R.version.string
> [1] "R version 2.2.0, 2005-09-03"
>


From rabrantes82 at gmail.com  Tue Sep  6 13:09:20 2005
From: rabrantes82 at gmail.com (Ricardo Luiz Andrade Abrantes)
Date: Tue, 6 Sep 2005 08:09:20 -0300
Subject: [Rd] .Call with C and Fortran together (PR#8122)
In-Reply-To: <Pine.A41.4.63a.0509050929430.366298@homer04.u.washington.edu>
References: <20050904195444.15D49CBFC@slim.kubism.ku.dk>
	<Pine.A41.4.63a.0509050929430.366298@homer04.u.washington.edu>
Message-ID: <973080e105090604093aeb72ab@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050906/1680120f/attachment.pl

From murdoch at stats.uwo.ca  Tue Sep  6 16:56:23 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 06 Sep 2005 10:56:23 -0400
Subject: [Rd] bash help please
Message-ID: <431DAE17.3070001@stats.uwo.ca>

I'd like to make MikTeX the default TeX package in 2.2.0, but we still 
need to let people use other packages.  The problem is that MikTeX wants 
a command line option --include-directory $R_HOME/share/texmf, while 
other packages specify includes via environment variables, and barf when 
they see the unexpected option.

The choice should be controlled by the user's settings in the MkRules 
file.  For example, I'll put something like this there:

ifneq ($(strip $(BUILD)),CROSS)
# Define to use MikTeX
#
PDFLATEX = pdflatex --include-directory=$(RHOME)/share/texmf
LATEX = latex --include-directory=$(RHOME)/share/texmf
PDFTEX = pdftex --include-directory=$(RHOME)/share/texmf
TEX = tex --include-directory=$(RHOME)/share/texmf
#
# Define to use other TeX
#
# PDFLATEX = pdflatex
# LATEX = latex
# PDFTEX = pdftex
# TEX = tex
else
PDFLATEX = pdflatex
LATEX = latex
PDFTEX = pdftex
TEX = tex
endif

My problem is that I don't know enough about Bourne shell scripting and 
GNU make to have this affect Rd2dvi (and possibly other Rcmd commands, I 
haven't looked yet).

Specifically, we need to have Rd2dvi.sh import these definitions from 
src/gnuwin32/MkRules, which may have been edited by the user since 
Rd2dvi.sh was built.  A complication is that if the user has already 
defined environment variables named PDFLATEX, LATEX, etc, we don't want 
to overwrite them.

One way would be to tell users to rebuild Rd2dvi.sh.  However, it would 
be easier if Rd2dvi.sh could import the changes automatically.

I was thinking of putting something like this into Rd2dvi.sh:

if test ${R_HOME}/src/gnuwin32/MkRules -nt ${R_HOME}/bin/setTeXenv.sh; then
   make -f ${R_HOME}/src/gnuwin32/Makefile ${R_HOME}/bin/setTeXenv.sh
fi
sh setTeXenv.sh

and then have the Makefile build the setTeXenv.sh script--but what 
should it contain?  Alternatively, can GNU make export environtment 
variables directly, and skip creating this new script?

Advice from shell hackers is welcomed!

Duncan Murdoch


From murdoch at stats.uwo.ca  Tue Sep  6 17:01:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 06 Sep 2005 11:01:31 -0400
Subject: [Rd] bash help please
In-Reply-To: <431DAE17.3070001@stats.uwo.ca>
References: <431DAE17.3070001@stats.uwo.ca>
Message-ID: <431DAF4B.3000805@stats.uwo.ca>

On 9/6/2005 10:56 AM, Duncan Murdoch wrote:
> I'd like to make MikTeX the default TeX package in 2.2.0, but we still 

I forgot to say "in Windows".  Sorry.

> need to let people use other packages.  The problem is that MikTeX wants 
> a command line option --include-directory $R_HOME/share/texmf, while 
> other packages specify includes via environment variables, and barf when 
> they see the unexpected option.
> 
> The choice should be controlled by the user's settings in the MkRules 
> file.  For example, I'll put something like this there:
> 
> ifneq ($(strip $(BUILD)),CROSS)
> # Define to use MikTeX
> #
> PDFLATEX = pdflatex --include-directory=$(RHOME)/share/texmf
> LATEX = latex --include-directory=$(RHOME)/share/texmf
> PDFTEX = pdftex --include-directory=$(RHOME)/share/texmf
> TEX = tex --include-directory=$(RHOME)/share/texmf
> #
> # Define to use other TeX
> #
> # PDFLATEX = pdflatex
> # LATEX = latex
> # PDFTEX = pdftex
> # TEX = tex
> else
> PDFLATEX = pdflatex
> LATEX = latex
> PDFTEX = pdftex
> TEX = tex
> endif
> 
> My problem is that I don't know enough about Bourne shell scripting and 
> GNU make to have this affect Rd2dvi (and possibly other Rcmd commands, I 
> haven't looked yet).
> 
> Specifically, we need to have Rd2dvi.sh import these definitions from 
> src/gnuwin32/MkRules, which may have been edited by the user since 
> Rd2dvi.sh was built.  A complication is that if the user has already 
> defined environment variables named PDFLATEX, LATEX, etc, we don't want 
> to overwrite them.
> 
> One way would be to tell users to rebuild Rd2dvi.sh.  However, it would 
> be easier if Rd2dvi.sh could import the changes automatically.
> 
> I was thinking of putting something like this into Rd2dvi.sh:
> 
> if test ${R_HOME}/src/gnuwin32/MkRules -nt ${R_HOME}/bin/setTeXenv.sh; then
>    make -f ${R_HOME}/src/gnuwin32/Makefile ${R_HOME}/bin/setTeXenv.sh
> fi
> sh setTeXenv.sh
> 
> and then have the Makefile build the setTeXenv.sh script--but what 
> should it contain?  Alternatively, can GNU make export environtment 
> variables directly, and skip creating this new script?
> 
> Advice from shell hackers is welcomed!
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lai at lindaspaces.com  Tue Sep  6 22:56:04 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Tue, 06 Sep 2005 16:56:04 -0400
Subject: [Rd] Build R with AMD pgi compiled ACML library
Message-ID: <431E0264.4090103@lindaspaces.com>

Hi,
     Has anyone had any luck in using portland group compiler to build 
R(-devel) with AMD's pgi compiled ACML library? I've downloaded the 
packages and set LD_LIBRARY_PATH, and run configuration script as follow:
% ./configure --prefix=/usr/local/R.pgcc --with-blas='-lacml'

However, it failed to pick up  double complex BLAS,

checking for sgemm_ in -lacml... yes
checking whether double complex BLAS can be used... no

Can anyone advise me on how to fix this problem?
Thank you in advance for your help!

Sincerely,
Jennifer


From ggrothendieck at gmail.com  Wed Sep  7 06:08:05 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 7 Sep 2005 00:08:05 -0400
Subject: [Rd] system on windows vs. unix
Message-ID: <971536df0509062108502a5b51@mail.gmail.com>

The R system command has different arguments on Windows and UNIX.
I hadn't realized that and I think it would be nice if the input=
argument available
on Windows were available on UNIX too and the ignore.stderr= argument
available on
UNIX were avaliable on Windows too.  

Even without that I could have saved some time if the help file had
pointed out that
the arguments vary from OS to OS or even better which are common and which 
are OS-specific.


From maechler at stat.math.ethz.ch  Wed Sep  7 14:03:33 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 7 Sep 2005 14:03:33 +0200
Subject: [Rd] system on windows vs. unix
In-Reply-To: <971536df0509062108502a5b51@mail.gmail.com>
References: <971536df0509062108502a5b51@mail.gmail.com>
Message-ID: <17182.55061.547573.537606@stat.math.ethz.ch>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Wed, 7 Sep 2005 00:08:05 -0400 writes:

    Gabor> The R system command has different arguments on Windows and UNIX.
    Gabor> I hadn't realized that and I think it would be nice if the input=
    Gabor> argument available
    Gabor> on Windows were available on UNIX too and the ignore.stderr= argument
    Gabor> available on
    Gabor> UNIX were avaliable on Windows too.  

    Gabor> Even without that I could have saved some time if the help file had
    Gabor> pointed out that
    Gabor> the arguments vary from OS to OS or even better which are common and which 
    Gabor> are OS-specific.

I very much agree.

Patches (against R-devel!) are very welcome.

Regards,
Martin


From andy_liaw at merck.com  Wed Sep  7 14:39:35 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 7 Sep 2005 08:39:35 -0400
Subject: [Rd] Build R with AMD pgi compiled ACML library
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED40C@usctmx1106.merck.com>

I can only say that the last time I tried linking ACML to R, it did quite a
bit worse than Goto's BLAS.  

Andy

> From: Jennifer Lai
> 
> Hi,
>      Has anyone had any luck in using portland group compiler 
> to build 
> R(-devel) with AMD's pgi compiled ACML library? I've downloaded the 
> packages and set LD_LIBRARY_PATH, and run configuration 
> script as follow:
> % ./configure --prefix=/usr/local/R.pgcc --with-blas='-lacml'
> 
> However, it failed to pick up  double complex BLAS,
> 
> checking for sgemm_ in -lacml... yes
> checking whether double complex BLAS can be used... no
> 
> Can anyone advise me on how to fix this problem?
> Thank you in advance for your help!
> 
> Sincerely,
> Jennifer
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
>


From hb at maths.lth.se  Wed Sep  7 19:14:37 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 07 Sep 2005 19:14:37 +0200
Subject: [Rd] Tracebacks with tryCatch() and withCallingHandlers()?
Message-ID: <431F1FFD.7080700@maths.lth.se>

When batch processing analysis, I use tryCatch() for failure handling 
and to prevent unwanted interrupts.  I write detailed progress to log 
file and conditions (warnings and errors) are written to the same log 
file immediately by using withCallingHandlers(..., condition=function(c) 
cat(c, file=logFile)).  However, I would also like to write the call 
stack to the log file to further simplify troubleshooting;  traceback() 
does unfortunately not work here. From ?traceback, we have

  "Errors which are caught _via_ 'try' or 'tryCatch' do not generate a 
traceback, so what is printed is the call sequence for the last uncaught 
error, and not necessarily the last error."

(and it seems to be case for withCallingHandlers() too).  Does anyone 
know of a workaround for this?   Is there a way to get the call stack 
within the condition handler?

Example:

foo <- function() stop("whoops");
pre <- function() foo();
bar <- function() pre();

yo <- function(fcn=tryCatch) {
   fcn(bar(),
     error = function(ex) {
       str(ex);
       traceback();   # I would like to access the call stack here!
     }
   )
   traceback();
}

Calling these gives:

 > rm(.Traceback)
 > yo()  # Using tryCatch()
List of 2
  $ message: chr "whoops"
  $ call   : language foo()
  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"
No traceback available
No traceback available
 > traceback()
No traceback available

The same, but now with withCallingHandlers(), which does not "prevent" 
the error from interrupting the code, gives similar results
 > rm(.Traceback)
 > yo(fcn=withCallingHandlers)
List of 2
  $ message: chr "whoops"
  $ call   : language foo()
  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"
No traceback available
Error in foo() : whoops
 > traceback()
5: stop("whoops")
4: foo()
3: bar()
2: fcn(bar(), error = function(ex) {
        str(ex)
        traceback()
    })
1: yo(fcn = withCallingHandlers)

Traceback() is available if the error is "let through".  I am also aware 
that the 'call' element of the condition object reports "foo()", (which 
is better than nothing).  However, I am missing information on the 
calling functions pre() and bar().

In addition to traceback(), I've also tried sys.calls(), sys.frames() 
and sys.status(), but none of these seems to "report" that the error 
occured inside foo(), instead you only get

$sys.calls
$sys.calls[[1]]
yo()

$sys.calls[[2]]
fcn(bar(), error = function(ex) {
     str(ex)
     traceback()
     print(sys.status())
     str(sys.calls())
     str(sys.frames())
})

$sys.calls[[3]]
tryCatchList(expr, classes, parentenv, handlers)

...

Am I looking for something that I can't get?  Would a solution be for R 
to internally record the call stack as soon as a condition occurs/is 
instanciated?

Thanks for enlightning me

Henrik


From ggrothendieck at gmail.com  Wed Sep  7 19:42:00 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 7 Sep 2005 13:42:00 -0400
Subject: [Rd] CRAN, Bioconductor and ctv package dependency questions
Message-ID: <971536df05090710422229e025@mail.gmail.com>

1. Can CRAN packages depend on Bioconductor packages and still pass
R CMD check?  That is can Suggests: and Depends: in the DESCRIPTION
file contain Bioconductor packages or only other CRAN packages?
Is there an example?

2. If a package depends on a Bioconductor package does one just list
the package its dependent on or also all packages that that package
recursively depends on?  Is this the same as for CRAN packages that
a package is dependent on?

3. Suppose that the output of package A is typically processed by
package B.  Thus strictly speaking no function in A depends on any
function in B; however, the output of A is not very usable without post 
processing it by B.   Would one list A as being dependent on B anyways?

4. Are there any considerations in the above cases related to 
CRAN Task Views (ctv package)?
http://cran.r-project.org/src/contrib/Views/

5. Are the above discussed anywhere?  I looked up the Depends and Suggests
field in 1.1 of the R Extensions manual but none of the above is addressed
there.

Thanks.


From deepayan.sarkar at gmail.com  Wed Sep  7 23:21:02 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 7 Sep 2005 16:21:02 -0500
Subject: [Rd] Fwd: segfault
In-Reply-To: <B2C92800-D422-45C5-B281-F597A7639FE6@stat.harvard.edu>
References: <p06230901bf3759687fd6@84.173.69.150>
	<AE67BE22-269F-4ED4-A6E3-D800A1F91496@mclink.it>
	<Pine.LNX.4.61.0508290930250.29579@gannet.stats>
	<90104E46-4CF0-48ED-9B75-C4C49D4D9540@mclink.it>
	<B2C92800-D422-45C5-B281-F597A7639FE6@stat.harvard.edu>
Message-ID: <eb555e6605090714213e3cd6c@mail.gmail.com>

On 8/31/05, Byron Ellis <ellis at stat.harvard.edu> wrote:
> There's definitely something a bit strange going on. The arguments as
> passed to wireframePanelCalculations from the code snippet show only
> 6060 elements for the z vector (51,101,16 respectively for x,y,rot)
> while the function routinely tries to access at positions in the z
> vector >20,000... until it eventually falls over (how long this takes
> seems to depend on circumstances, I can actually get it to complete a
> run while running in gdb).

Thanks for tracking this down. It's unlikely that I'll be able to fix
this before R 2.2.0, but at least I know where to look when I do
tackle this.

> On Aug 30, 2005, at 10:12 AM, stefano iacus wrote:
> 
> >
> > On 29/ago/05, at 10:35, Prof Brian Ripley wrote:
> >
> >
> >> It does not crash for me on either Windows or Linux, but it does
> >> take a
> >> long time and the plot is a mess, so there does seem to be a
> >> lattice-related problem (maybe a usage one).
> >>
> >> However, I think the crash is a Mac (presumably quartz()) problem.
> >>
> >>
> >
> > no, it also happens with the X11 device. BTW, it seems to be OS X
> > specific.
> > I'll try to debug
> > stefano
> >
> >
> >> On Mon, 29 Aug 2005, stefano iacus wrote:
> >>
> >>
> >>
> >>> This segfaults on OS X (10.4) on both X11 and quartz devices.
> >>> Seems a problem with lattice but I cannot test on other platforms
> >>> stefano
> >>>
> >>>
> >>> Begin forwarded message:
> >>>
> >>>
> >>>
> >>>> From: "G. Sawitzki" <gs at statlab.uni-heidelberg.de>
> >>>> Date: 28 agosto 2005 14:11:18 GMT+02:00
> >>>> To: jago at mclink.it
> >>>>
> >>>>
> >>>> Dear Stefano,
> >>>>
> >>>>  this small exaple leads to a crash of R. I did not try it on
> >>>> versions other than the Mac version. So I am sending it to you
> >>>> directly. If it is a littice problem, could you pass it to Deepayan
> >>>> Sarkar? Thank you.
> >>>>
> >>>>   g.
> >>>>
> >>>> ==
> >>>> #pbinom
> >>>> library(grid)
> >>>> library(lattice)
> >>>>
> >>>> n<-20
> >>>> psteps<-50
> >>>> binomtable<- function (n,psteps){
> >>>> x<-(0:(10*n))/10
> >>>> p<- (0:psteps)/psteps
> >>>> dd<-expand.grid(x=x,p=p)
> >>>> dd$F<- pbinom(dd$x,n,dd$p)
> >>>> dd$x0<-trunc(dd$x)
> >>>> dd
> >>>> }
> >>>>
> >>>> bt<-binomtable(n=5,psteps=100)
> >>>> bt[bt$x-bt$x0>=0.9,]$F<-NA
> >>>> wireframe(bt$F~bt$x*bt$p,bt,groups=bt$x0,shade=TRUE) # leads to R
> >>>> crash
> >>>> #wireframe(bt$F~bt$x*bt$p,bt,shade=TRUE) #ok
> >>>>
> >>>>
> >>
> >> --
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ---
> Byron Ellis (ellis at stat.harvard.edu)
> "Oook" -- The Librarian
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sebastien.durand at UMontreal.CA  Wed Sep  7 23:30:16 2005
From: sebastien.durand at UMontreal.CA (Sebastien Durand)
Date: Wed, 7 Sep 2005 17:30:16 -0400
Subject: [Rd] Month recognition issue
Message-ID: <p06230907bf450c2f1428@[192.168.0.11]>

Dear all,

I am running
R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
Under Mac os X, a french version!

I am preparing a package and I got the following issue

I am trying to read dates that are written in 
english and have them recognized by R using 
as.Date function.

I realized strangely that when I type
>  month.abb
  [1] "Jan" "Feb" "Mar" "Apr" "May" "Jun" "Jul" "Aug" "Sep" "Oct"
[11] "Nov" "Dec"

I get the abbreviated english version of every month

>  x <- c("1-jan-1960", "2-feb-1960", 
>"31-mar-1960", "30-apr-1960","2-may-1960", 
>"31-jun-1960", "30-jul-1960","2-aug-1960", 
>"31-sep-1960", "30-oct-1960", "30-nov-1960", 
>"30-dec-1960");
>  strptime(x, "%d-%b-%Y")
  [1] "1960-01-01" NA           "1960-03-31" NA
  [5] NA           NA           "1960-07-30" NA
  [9] "1960-10-01" "1960-10-30" "1960-11-30" NA

It is only once I have found through trial an 
error the french abbreviation, that I got a match 
for every month.

>  x <- c("1-jan-1960", "2-f?v-1960", 
>"31-mar-1960", "30-avr-1960","2-mai-1960", 
>"31-jui-1960", "30-jul-1960","2-ao?-1960", 
>"31-sep-1960", "30-oct-1960", "30-nov-1960", 
>"30-d?c-1960");
>  strptime(x, "%d-%b-%Y")
  [1] "1960-01-01" "1960-02-02" "1960-03-31" "1960-04-30"
  [5] "1960-05-02" "1960-07-01" "1960-07-30" "1960-08-02"
  [9] "1960-10-01" "1960-10-30" "1960-11-30" "1960-12-30"

I got simply two questions:

First, why since R was install on a french system 
the month.abb command didn't give me the french 
abbreviations.

Secondly, since I am producing a package, I would 
like to know how can I tell R  to momentairly use 
the english abbreviations instead of the french 
ones...

Thanks a lot

--


From Kurt.Hornik at wu-wien.ac.at  Thu Sep  8 08:42:46 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu, 8 Sep 2005 08:42:46 +0200
Subject: [Rd] Tracebacks with tryCatch() and withCallingHandlers()?
In-Reply-To: <431F1FFD.7080700@maths.lth.se>
References: <431F1FFD.7080700@maths.lth.se>
Message-ID: <17183.56678.727845.312867@mithrandir.hornik.net>

>>>>> Henrik Bengtsson writes:

> When batch processing analysis, I use tryCatch() for failure handling 
> and to prevent unwanted interrupts.  I write detailed progress to log 
> file and conditions (warnings and errors) are written to the same log 
> file immediately by using withCallingHandlers(..., condition=function(c) 
> cat(c, file=logFile)).  However, I would also like to write the call 
> stack to the log file to further simplify troubleshooting;  traceback() 
> does unfortunately not work here. From ?traceback, we have

>   "Errors which are caught _via_ 'try' or 'tryCatch' do not generate a 
> traceback, so what is printed is the call sequence for the last uncaught 
> error, and not necessarily the last error."

> (and it seems to be case for withCallingHandlers() too).  Does anyone 
> know of a workaround for this?   Is there a way to get the call stack 
> within the condition handler?

tools:::.try_quietly() tries doing something similar (catch errors and
print a traceback) [the code is not necessarily a thing of beauty ...].

Hth

Best
-k


From Kurt.Hornik at wu-wien.ac.at  Thu Sep  8 10:41:15 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu, 8 Sep 2005 10:41:15 +0200
Subject: [Rd] CRAN, Bioconductor and ctv package dependency questions
In-Reply-To: <971536df05090710422229e025@mail.gmail.com>
References: <971536df05090710422229e025@mail.gmail.com>
Message-ID: <17183.63787.468382.354659@mithrandir.hornik.net>

>>>>> Gabor Grothendieck writes:

> 1. Can CRAN packages depend on Bioconductor packages and still pass
> R CMD check?  That is can Suggests: and Depends: in the DESCRIPTION
> file contain Bioconductor packages or only other CRAN packages?
> Is there an example?

Yes, yes, yes.  (E.g., LMGene, limma, ...)

The only catch is that in the current setup of daily CRAN package
checking, packages with non-CRAN dependencies are checked using fake or
no installs.

> 2. If a package depends on a Bioconductor package does one just list
> the package its dependent on or also all packages that that package
> recursively depends on?  Is this the same as for CRAN packages that
> a package is dependent on?

Yes.  There is a difference between "CRAN style package repositories",
as handled by the base R Package Management system, and the main CRAN
repository (which of course happens to be a CRAN style one).

> 3. Suppose that the output of package A is typically processed by
> package B.  Thus strictly speaking no function in A depends on any
> function in B; however, the output of A is not very usable without
> post processing it by B.  Would one list A as being dependent on B
> anyways?

I think this would fall into a third "dependency" category which we
currently do not have.

> 4. Are there any considerations in the above cases related to 
> CRAN Task Views (ctv package)?
> http://cran.r-project.org/src/contrib/Views/

You would need to talk to the CRAN Task View (ctv) maintainer :-)

> 5. Are the above discussed anywhere?  I looked up the Depends and
> Suggests field in 1.1 of the R Extensions manual but none of the above
> is addressed there.

Re 1/2: This is because R-exts tells you what to do and not what not to
do.

Hth

-k


From Achim.Zeileis at wu-wien.ac.at  Thu Sep  8 11:21:17 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 8 Sep 2005 11:21:17 +0200
Subject: [Rd] CRAN, Bioconductor and ctv package dependency questions
In-Reply-To: <17183.63787.468382.354659@mithrandir.hornik.net>
References: <971536df05090710422229e025@mail.gmail.com>
	<17183.63787.468382.354659@mithrandir.hornik.net>
Message-ID: <20050908112117.444612da.Achim.Zeileis@wu-wien.ac.at>

On Thu, 8 Sep 2005 10:41:15 +0200 Kurt Hornik wrote:

> >>>>> Gabor Grothendieck writes:
> 
> > 1. Can CRAN packages depend on Bioconductor packages and still pass
> > R CMD check?  That is can Suggests: and Depends: in the DESCRIPTION
> > file contain Bioconductor packages or only other CRAN packages?
> > Is there an example?
> 
> Yes, yes, yes.  (E.g., LMGene, limma, ...)
> 
> The only catch is that in the current setup of daily CRAN package
> checking, packages with non-CRAN dependencies are checked using fake
> or no installs.
> 
> > 2. If a package depends on a Bioconductor package does one just list
> > the package its dependent on or also all packages that that package
> > recursively depends on?  Is this the same as for CRAN packages that
> > a package is dependent on?
> 
> Yes.  There is a difference between "CRAN style package repositories",
> as handled by the base R Package Management system, and the main CRAN
> repository (which of course happens to be a CRAN style one).
> 
> > 3. Suppose that the output of package A is typically processed by
> > package B.  Thus strictly speaking no function in A depends on any
> > function in B; however, the output of A is not very usable without
> > post processing it by B.  Would one list A as being dependent on B
> > anyways?
> 
> I think this would fall into a third "dependency" category which we
> currently do not have.
> 
> > 4. Are there any considerations in the above cases related to 
> > CRAN Task Views (ctv package)?
> > http://cran.r-project.org/src/contrib/Views/
> 
> You would need to talk to the CRAN Task View (ctv) maintainer :-)

Yes, there are considerations that I have discusses with several people
including Kurt :-)
We're thinking about a way that CRAN style repositories can know what
their name is (CRAN, BioConductor, etc.) and then we could query whether
the repositories in getOption("repos") include a CRAN or a BioC
repository and then have views that include packages from both CRAN and
BioC and potentially other repositories.

Best,
Z

> > 5. Are the above discussed anywhere?  I looked up the Depends and
> > Suggests field in 1.1 of the R Extensions manual but none of the
> > above is addressed there.
> 
> Re 1/2: This is because R-exts tells you what to do and not what not
> to do.
> 
> Hth
> 
> -k
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Kurt.Hornik at wu-wien.ac.at  Thu Sep  8 11:50:38 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu, 8 Sep 2005 11:50:38 +0200
Subject: [Rd] CRAN, Bioconductor and ctv package dependency questions
In-Reply-To: <20050908112117.444612da.Achim.Zeileis@wu-wien.ac.at>
References: <971536df05090710422229e025@mail.gmail.com>
	<17183.63787.468382.354659@mithrandir.hornik.net>
	<20050908112117.444612da.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <17184.2414.260320.121790@mithrandir.hornik.net>

>>>>> Achim Zeileis writes:

> On Thu, 8 Sep 2005 10:41:15 +0200 Kurt Hornik wrote:
>> >>>>> Gabor Grothendieck writes:
>> 
>> > 1. Can CRAN packages depend on Bioconductor packages and still pass
>> > R CMD check?  That is can Suggests: and Depends: in the DESCRIPTION
>> > file contain Bioconductor packages or only other CRAN packages?
>> > Is there an example?
>> 
>> Yes, yes, yes.  (E.g., LMGene, limma, ...)
>> 
>> The only catch is that in the current setup of daily CRAN package
>> checking, packages with non-CRAN dependencies are checked using fake
>> or no installs.
>> 
>> > 2. If a package depends on a Bioconductor package does one just list
>> > the package its dependent on or also all packages that that package
>> > recursively depends on?  Is this the same as for CRAN packages that
>> > a package is dependent on?
>> 
>> Yes.  There is a difference between "CRAN style package repositories",
>> as handled by the base R Package Management system, and the main CRAN
>> repository (which of course happens to be a CRAN style one).
>> 
>> > 3. Suppose that the output of package A is typically processed by
>> > package B.  Thus strictly speaking no function in A depends on any
>> > function in B; however, the output of A is not very usable without
>> > post processing it by B.  Would one list A as being dependent on B
>> > anyways?
>> 
>> I think this would fall into a third "dependency" category which we
>> currently do not have.
>> 
>> > 4. Are there any considerations in the above cases related to 
>> > CRAN Task Views (ctv package)?
>> > http://cran.r-project.org/src/contrib/Views/
>> 
>> You would need to talk to the CRAN Task View (ctv) maintainer :-)

> Yes, there are considerations that I have discusses with several
> people including Kurt :-) We're thinking about a way that CRAN style
> repositories can know what their name is (CRAN, BioConductor, etc.)
> and then we could query whether the repositories in getOption("repos")
> include a CRAN or a BioC repository and then have views that include
> packages from both CRAN and BioC and potentially other repositories.

Ah yes.  We want to provide repository-side metadata in the style of
Debian's 'Release' files, and take advantage of them.  Which has been on
my TODO pile for quite some time now ... how hard can it be to write a
DCF file containing three or four lines ...

-k


From sfalcon at fhcrc.org  Thu Sep  8 23:39:49 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 08 Sep 2005 14:39:49 -0700
Subject: [Rd] Install packages to non-default lib on Windows
Message-ID: <m2y867i6hm.fsf@macaroni.local>

We are trying to setup a Windows server that will allow any of our
users to build a binary R package given a source package.

The idea is to have a central R installation and allow users to
install packages to their own package library for the purposes of
binary package building.

It seems, however, that write access to $R_HOME is required as part of
the install step even when -l is used to specify an alternate package
library.

here's an example of what we're seeing:

C:\rlibdir\hpages>set R_LIBS=c:\rlibdir\hpages

C:\rlibdir\hpages>d:\biocbld\R-devel\bin\R CMD INSTALL -l=%R_LIBS% --build Biobase_1.6.7.tar.gz

Using auto-selected zip options 'Biobase-ZIPDATA=zip Biobase-HELP=ziponly'

---------- Making package Biobase ------------
  adding build stamp to DESCRIPTION
  installing NAMESPACE file and metadata
  making DLL ...
  ... DLL made
  installing DLL
  installing R files
  save image
Loading required package: tools
Creating a new generic function for 'ncol' in 'Biobase'

  installing inst files
  installing data files
  installing man source files
  installing indices
cannot create d:/biocbld/R-devel/doc/html/search/index.txt: permission denied
make[2]: *** [indices] Error 2
make[1]: *** [all] Error 2
make: *** [pkg-Biobase] Error 2
*** Installation of Biobase failed ***

Removing 'c:/rlibdir/hpages/Biobase'


Questions:

- Is it possible to build a binary package on Windows without write
  access to the $R_HOME tree?

- Is it still the case that a side-effect of building a binary package
  is having that package be installed?  My understanding is that R CMD
  INSTALL --build is the way to get zips on Windows, but maybe this
  changed?

Thanks,

+ seth


From dgrove at fhcrc.org  Fri Sep  9 00:33:02 2005
From: dgrove at fhcrc.org (Douglas Grove)
Date: Thu, 8 Sep 2005 15:33:02 -0700 (PDT)
Subject: [Rd] Wishlist: write.delim()
Message-ID: <Pine.LNX.4.61.0509081520540.10724@echidna.fhcrc.org>

Hi,

It would be great if someone would add write.delim() as an
adjunct to write.table(), just as with write.csv().

I store a lot of data in tab-delimited files and can read
it in easily with:  read.delim("text.txt", as.is=TRUE)
and would love to be able to write it out as easily when
I create these files.

The obvious setting needed for write.delim() is sep = "\t",
but in addition I would request the setting row.names = FALSE

i.e. 

write.delim(x, file) = write.table(x, file, sep = "\t", row.names=FALSE)

Thanks much,
Doug Grove


From murdoch at stats.uwo.ca  Fri Sep  9 01:26:52 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 08 Sep 2005 19:26:52 -0400
Subject: [Rd] Install packages to non-default lib on Windows
In-Reply-To: <m2y867i6hm.fsf@macaroni.local>
References: <m2y867i6hm.fsf@macaroni.local>
Message-ID: <4320C8BC.6020702@stats.uwo.ca>

Seth Falcon wrote:
> We are trying to setup a Windows server that will allow any of our
> users to build a binary R package given a source package.
> 
> The idea is to have a central R installation and allow users to
> install packages to their own package library for the purposes of
> binary package building.
> 
> It seems, however, that write access to $R_HOME is required as part of
> the install step even when -l is used to specify an alternate package
> library.
> 
> here's an example of what we're seeing:
> 
> C:\rlibdir\hpages>set R_LIBS=c:\rlibdir\hpages
> 
> C:\rlibdir\hpages>d:\biocbld\R-devel\bin\R CMD INSTALL -l=%R_LIBS% --build Biobase_1.6.7.tar.gz
> 
> Using auto-selected zip options 'Biobase-ZIPDATA=zip Biobase-HELP=ziponly'
> 
> ---------- Making package Biobase ------------
>   adding build stamp to DESCRIPTION
>   installing NAMESPACE file and metadata
>   making DLL ...
>   ... DLL made
>   installing DLL
>   installing R files
>   save image
> Loading required package: tools
> Creating a new generic function for 'ncol' in 'Biobase'
> 
>   installing inst files
>   installing data files
>   installing man source files
>   installing indices
> cannot create d:/biocbld/R-devel/doc/html/search/index.txt: permission denied
> make[2]: *** [indices] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-Biobase] Error 2
> *** Installation of Biobase failed ***
> 
> Removing 'c:/rlibdir/hpages/Biobase'
> 
> 
> Questions:
> 
> - Is it possible to build a binary package on Windows without write
>   access to the $R_HOME tree?
> 
> - Is it still the case that a side-effect of building a binary package
>   is having that package be installed?  My understanding is that R CMD
>   INSTALL --build is the way to get zips on Windows, but maybe this
>   changed?

There are two ways:  R CMD INSTALL --build, and R CMD build --binary. 
The latter doesn't do an install, so the links in help pages don't get 
generated properly, but it may do a good enough job for what you need.

Duncan Murdoch


From khawsith at maths.curtin.edu.au  Fri Sep  9 04:41:38 2005
From: khawsith at maths.curtin.edu.au (khawsith@maths.curtin.edu.au)
Date: Fri,  9 Sep 2005 04:41:38 +0200 (CEST)
Subject: [Rd] Rgui error (PR#8126)
Message-ID: <20050909024138.005D01995B@slim.kubism.ku.dk>

Full_Name: Pairoj Khawsithiwong
Version: 2.1.1
OS: Window xp
Submission from: (NULL) (134.7.248.137)


For Windows xp;
R for Wnidows GUI front-end has encountered a problem and needs to close.

For Windows Me;
Rgui caused an error in USER.EXE.


From khansen at stat.Berkeley.EDU  Fri Sep  9 06:50:29 2005
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Thu, 8 Sep 2005 21:50:29 -0700
Subject: [Rd] C macros and Makevars/package building
Message-ID: <5C1BDAE5-1DBF-45DB-B8D0-5A5AE2A2627C@stat.Berkeley.EDU>

Hi

We are currently embedding a rather large C++ library in R (BioC),  
and we want some comments on the portability of how we have approach  
this.

First of, we are not really able to do much about the portability of  
the basic library, which of course is the main question :) We have an  
approach which seems to work, I just want a bit of feedback on it....

The way we integrate it into R is simply by having a subdirectory  / 
src/sdk together with a Makevars file. This file basically looks like

PKG_CPPFLAGS+=\
   -imacros R_affx_constants.h\
   -Isdk/files\
    (... + a lot of other -I statements telling CPP to include  
subdirectories of src/sdk)

Then we have a

SOURCES.SDK = \
   sdk/files/FileIO.cpp \
   (... + a lot of other .cpp files)
SOURCES.OURS = \
   R_affx_cdf.cpp

and then finally a

OBJS=$(SOURCES.SDK:.cpp=.o) $(SOURCES.OURS:cpp:.o)

We seem to need the last statement since it seems that .cpp is not  
automatically a C++ suffix (but is it done the "right" way for  
portability?). We need the -imacro statement in order to include some  
macros from Rconfig.h (big endian checks) which are then translated  
from the WORDS_BIGENDIAN used in R to the IS_BIG_ENDIAN used in the  
library.

Comments on the portability?

Kasper


From p.dalgaard at biostat.ku.dk  Fri Sep  9 08:38:16 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Sep 2005 08:38:16 +0200
Subject: [Rd] C macros and Makevars/package building
In-Reply-To: <5C1BDAE5-1DBF-45DB-B8D0-5A5AE2A2627C@stat.Berkeley.EDU>
References: <5C1BDAE5-1DBF-45DB-B8D0-5A5AE2A2627C@stat.Berkeley.EDU>
Message-ID: <x2mzmmycdj.fsf@turmalin.kubism.ku.dk>

Kasper Daniel Hansen <khansen at stat.berkeley.edu> writes:

> Hi
> 
> We are currently embedding a rather large C++ library in R (BioC),  
> and we want some comments on the portability of how we have approach  
> this.
> 
> First of, we are not really able to do much about the portability of  
> the basic library, which of course is the main question :) We have an  
> approach which seems to work, I just want a bit of feedback on it....
> 
> The way we integrate it into R is simply by having a subdirectory  / 
> src/sdk together with a Makevars file. This file basically looks like
> 
> PKG_CPPFLAGS+=\
>    -imacros R_affx_constants.h\
>    -Isdk/files\
>     (... + a lot of other -I statements telling CPP to include  
> subdirectories of src/sdk)
> 
> Then we have a
> 
> SOURCES.SDK = \
>    sdk/files/FileIO.cpp \
>    (... + a lot of other .cpp files)
> SOURCES.OURS = \
>    R_affx_cdf.cpp
> 
> and then finally a
> 
> OBJS=$(SOURCES.SDK:.cpp=.o) $(SOURCES.OURS:cpp:.o)
> 
> We seem to need the last statement since it seems that .cpp is not  
> automatically a C++ suffix (but is it done the "right" way for  
> portability?). 

Er, I don't think it has to do with .cpp being a known suffix or not. 
If it wasn't, you would use SUFFIXES and a .cpp.o rule. The last line
comes from specifying sources, rather than objects.
Traditional make style would be

OBJS.SDK = \
   sdk/files/FileIO.o \
   (... + a lot of other .cpp files)
OBJS.OURS = \
    R_affx_cdf.o

OBJS = $(OBJS.SDK) $(OBJS.OURS)

from which the suffix rules would deduce the source files.

> We need the -imacro statement in order to include some  
> macros from Rconfig.h (big endian checks) which are then translated  
> from the WORDS_BIGENDIAN used in R to the IS_BIG_ENDIAN used in the  
> library.
> 
> Comments on the portability?
> 
> Kasper
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Fri Sep  9 08:41:11 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 09 Sep 2005 08:41:11 +0200
Subject: [Rd] Install packages to non-default lib on Windows
In-Reply-To: <4320C8BC.6020702@stats.uwo.ca>
References: <m2y867i6hm.fsf@macaroni.local> <4320C8BC.6020702@stats.uwo.ca>
Message-ID: <43212E87.5030804@statistik.uni-dortmund.de>

Duncan Murdoch wrote:

> Seth Falcon wrote:
> 
>>We are trying to setup a Windows server that will allow any of our
>>users to build a binary R package given a source package.
>>
>>The idea is to have a central R installation and allow users to
>>install packages to their own package library for the purposes of
>>binary package building.
>>
>>It seems, however, that write access to $R_HOME is required as part of
>>the install step even when -l is used to specify an alternate package
>>library.
>>
>>here's an example of what we're seeing:
>>
>>C:\rlibdir\hpages>set R_LIBS=c:\rlibdir\hpages
>>
>>C:\rlibdir\hpages>d:\biocbld\R-devel\bin\R CMD INSTALL -l=%R_LIBS% --build Biobase_1.6.7.tar.gz
>>
>>Using auto-selected zip options 'Biobase-ZIPDATA=zip Biobase-HELP=ziponly'
>>
>>---------- Making package Biobase ------------
>>  adding build stamp to DESCRIPTION
>>  installing NAMESPACE file and metadata
>>  making DLL ...
>>  ... DLL made
>>  installing DLL
>>  installing R files
>>  save image
>>Loading required package: tools
>>Creating a new generic function for 'ncol' in 'Biobase'
>>
>>  installing inst files
>>  installing data files
>>  installing man source files
>>  installing indices
>>cannot create d:/biocbld/R-devel/doc/html/search/index.txt: permission denied

I was also annoyed about this point a couple of times. But what are 
possible solutions?

- not updating indices at all?
- provide a switch such as --no-indices for the R CMD tools?
- ...?

short time workaround: simply give users write access to the few files 
that have to write to.


Uwe Ligges



>>make[2]: *** [indices] Error 2
>>make[1]: *** [all] Error 2
>>make: *** [pkg-Biobase] Error 2
>>*** Installation of Biobase failed ***
>>
>>Removing 'c:/rlibdir/hpages/Biobase'
>>
>>
>>Questions:
>>
>>- Is it possible to build a binary package on Windows without write
>>  access to the $R_HOME tree?
>>
>>- Is it still the case that a side-effect of building a binary package
>>  is having that package be installed?  My understanding is that R CMD
>>  INSTALL --build is the way to get zips on Windows, but maybe this
>>  changed?
> 
> 
> There are two ways:  R CMD INSTALL --build, and R CMD build --binary. 
> The latter doesn't do an install, so the links in help pages don't get 
> generated properly, but it may do a good enough job for what you need.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.uni-dortmund.de  Fri Sep  9 08:43:53 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Fri,  9 Sep 2005 08:43:53 +0200 (CEST)
Subject: [Rd] Rgui error (PR#8126)
Message-ID: <20050909064353.3168B1CCEA@slim.kubism.ku.dk>

khawsith at maths.curtin.edu.au wrote:

> Full_Name: Pairoj Khawsithiwong
> Version: 2.1.1
> OS: Window xp
> Submission from: (NULL) (134.7.248.137)
> 
> 
> For Windows xp;
> R for Wnidows GUI front-end has encountered a problem and needs to close.
> 
> For Windows Me;
> Rgui caused an error in USER.EXE.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


Unfortunately, this bug report is completely useless.
Please tell us exactly how you managed to produce this crash.

Please read the Section "R Bugs" in the R FAQ.

Uwe Ligges


From Carsten.Urbach at physik.fu-berlin.de  Fri Sep  9 11:32:02 2005
From: Carsten.Urbach at physik.fu-berlin.de (Carsten.Urbach@physik.fu-berlin.de)
Date: Fri,  9 Sep 2005 11:32:02 +0200 (CEST)
Subject: [Rd] nls fails to return correlation matrix (PR#8127)
Message-ID: <20050909093202.40C241C519@slim.kubism.ku.dk>

Full_Name: Carsten Urbach
Version: 2.1.1  (2005-06-20)
OS: Linux
Submission from: (NULL) (141.34.5.241)


I observed one case where nls failed to return the correlation matrix, while the
parameter estimates were computed correctly. In the follwing I include all the
commands leading to this problem. R was started with 'R --vanilla':

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    1.1
year     2005
month    06
day      20
language R
> data <- read.table(file="zp.dat", header=F)
> data
  V1     V2      V3      V4
1  4 5.6791 0.80709 0.00094
2  6 5.8636 0.71202 0.00083
3  8 6.0219 0.67844 0.00139
4 10 6.1628 0.65797 0.00130
5 12 6.2885 0.64604 0.00119
6 16 6.4956 0.63047 0.00112
> df <- data.frame(x=data$V2-6, y=data$V3)
> df
        x       y
1 -0.3209 0.80709
2 -0.1364 0.71202
3  0.0219 0.67844
4  0.1628 0.65797
5  0.2885 0.64604
6  0.4956 0.63047
> fit4 <- nls(y ~ a+b*x+c*x^2+d*x^3+e*x^4, data = df, start = list(a = 1., b =
-1., c = 1., d=-1., e=1.))
> summary(fit4)
Formula: y ~ a + b * x + c * x^2 + d * x^3 + e * x^4

Parameters:
   Estimate Std. Error t value Pr(>|t|)
a  0.680936   0.001327 513.002  0.00124 **
b -0.168167   0.010660 -15.775  0.04030 *
c  0.325593   0.047433   6.864  0.09210 .
d -0.860767   0.117710  -7.313  0.08652 .
e  0.957177   0.319101   3.000  0.20486
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.001722 on 1 degrees of freedom

Correlation of Parameter Estimates:
  a b c d
b   1
c , , 1
d   * , 1 
e . , * *
attr(,"legend")
[1] 0 ? ? 0.3 ?.? 0.6 ?,? 0.8 ?+? 0.9 ?*? 0.95 ?B? 1

> fit4
Nonlinear regression model
  model:  y ~ a + b * x + c * x^2 + d * x^3 + e * x^4
   data:  df
         a          b          c          d          e
 0.6809363 -0.1681674  0.3255929 -0.8607670  0.9571768
 residual sum-of-squares:  2.966569e-06


From maechler at stat.math.ethz.ch  Fri Sep  9 11:52:14 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Sep 2005 11:52:14 +0200
Subject: [Rd] Wishlist: write.delim()
In-Reply-To: <Pine.LNX.4.61.0509081520540.10724@echidna.fhcrc.org>
References: <Pine.LNX.4.61.0509081520540.10724@echidna.fhcrc.org>
Message-ID: <17185.23374.210672.553854@stat.math.ethz.ch>

>>>>> "Douglas" == Douglas Grove <dgrove at fhcrc.org>
>>>>>     on Thu, 8 Sep 2005 15:33:02 -0700 (PDT) writes:

    Douglas> Hi,
    Douglas> It would be great if someone would add write.delim() as an
    Douglas> adjunct to write.table(), just as with write.csv().

    Douglas> I store a lot of data in tab-delimited files and can read
    Douglas> it in easily with:  read.delim("text.txt", as.is=TRUE)
    Douglas> and would love to be able to write it out as easily when
    Douglas> I create these files.

    Douglas> The obvious setting needed for write.delim() is sep = "\t",
    Douglas> but in addition I would request the setting row.names = FALSE

    Douglas> i.e. 

    Douglas> write.delim(x, file) = write.table(x, file, sep = "\t", row.names=FALSE)

i.e.,
   write.delim <- function(x, file, ...) 
		    write.table(x, file, sep = "\t", row.names=FALSE, ...)

So, why don't you just add that one line to your .Rprofile ?

In general, I don't think that it's worth to introduce a whole
new function just because of some frequent argument use of an
already existing function  {{and I have wondered if it was worth
to provide write.csv() at all - although, there the difference to default
write.table() is quite a bit larger}}

Martin


From p.dalgaard at biostat.ku.dk  Fri Sep  9 11:55:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Sep 2005 11:55:49 +0200
Subject: [Rd] nls fails to return correlation matrix (PR#8127)
In-Reply-To: <20050909093202.40C241C519@slim.kubism.ku.dk>
References: <20050909093202.40C241C519@slim.kubism.ku.dk>
Message-ID: <x2psrid0pm.fsf@turmalin.kubism.ku.dk>

Carsten.Urbach at physik.fu-berlin.de writes:

> Full_Name: Carsten Urbach
> Version: 2.1.1  (2005-06-20)
> OS: Linux
> Submission from: (NULL) (141.34.5.241)
> 
> 
> I observed one case where nls failed to return the correlation matrix, while the
> parameter estimates were computed correctly. In the follwing I include all the
> commands leading to this problem. R was started with 'R --vanilla':


.............................
> 
> Residual standard error: 0.001722 on 1 degrees of freedom
> 
> Correlation of Parameter Estimates:
>   a b c d
> b   1
> c , , 1
> d   * , 1 
> e . , * *
> attr(,"legend")
> [1] 0 ? ? 0.3 ?.? 0.6 ?,? 0.8 ?+? 0.9 ?*? 0.95 ?B? 1


And the problem was??? 

You may not like the graphical representation, but it is not a bug.

Just use

print(summary(fit),symbolic.cor=FALSE)

to get rid of it.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Fri Sep  9 12:39:30 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 09 Sep 2005 06:39:30 -0400
Subject: [Rd] [R] Debugging R/Fortran in Windows
In-Reply-To: <3095.192.168.65.113.1126245320.squirrel@homebase.wehi.edu.au>
References: <3095.192.168.65.113.1126245320.squirrel@homebase.wehi.edu.au>
Message-ID: <43216662.7010802@stats.uwo.ca>

[Moved from R-help]

James Wettenhall wrote:
> Hi,
> 
> I'm trying to debug an R interface to a Fortran subroutine from Windows. 
> (Yes, I know I should try Unix/Linux as well, but a quick attempt
> suggested that the (MinGW g77) Fortran compiler I have installed on my
> Windows laptop works better on this Fortran code.)
> 
> I'm trying to follow the instructions in the "Writing R Extensions" Manual:
> 
> Start R under the debugger after setting a breakpoint for WinMain.
>           gdb .../bin/Rgui.exe
>           (gdb) break WinMain
>           (gdb) run
> 
> But when I run gdb on Rgui.exe, I get the message:
> "no debugging symbols found"
> and then when I try "break WinMain", I get:
> "No symbol table is loaded.  use the 'file' command."

You can also start R normally, load your dll by attaching the package, 
then click on Misc | Break to debugger.

This assumes you have debugging symbols in your DLL, and have gdb set up 
properly; see

http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR

for more details.

Duncan Murdoch
> 
> I'm using R 2.1.1 on Windows 2000 and gdb 5.2.1 from MSys's MinGW.
> 
> I'm calling a Fortran function (several times) from R.  And I seem to have
> the basic two-way data communication working - I appear to have
> succesfully passed all required data types (integer, real, double
> precision) to and from Fortran with sensible results both from within R
> and from using WRITE(FILENUM,*) from within Fortran.  But unfortunately
> there is still evidence of memory leakage.
> 
> Any suggestions would be greatly appreciated.
> 
> Regards,
> James
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


From Kurt.Hornik at wu-wien.ac.at  Fri Sep  9 09:34:15 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 9 Sep 2005 09:34:15 +0200
Subject: [Rd] C macros and Makevars/package building
In-Reply-To: <5C1BDAE5-1DBF-45DB-B8D0-5A5AE2A2627C@stat.Berkeley.EDU>
References: <5C1BDAE5-1DBF-45DB-B8D0-5A5AE2A2627C@stat.Berkeley.EDU>
Message-ID: <17185.15095.523359.87884@mithrandir.hornik.net>

>>>>> Kasper Daniel Hansen writes:

> Hi
> We are currently embedding a rather large C++ library in R (BioC),  
> and we want some comments on the portability of how we have approach  
> this.

> First of, we are not really able to do much about the portability of  
> the basic library, which of course is the main question :) We have an  
> approach which seems to work, I just want a bit of feedback on it....

> The way we integrate it into R is simply by having a subdirectory  / 
> src/sdk together with a Makevars file. This file basically looks like

> PKG_CPPFLAGS+=\
>    -imacros R_affx_constants.h\
>    -Isdk/files\
>     (... + a lot of other -I statements telling CPP to include  
> subdirectories of src/sdk)

> Then we have a

> SOURCES.SDK = \
>    sdk/files/FileIO.cpp \
>    (... + a lot of other .cpp files)
> SOURCES.OURS = \
>    R_affx_cdf.cpp

> and then finally a

> OBJS=$(SOURCES.SDK:.cpp=.o) $(SOURCES.OURS:cpp:.o)

> We seem to need the last statement since it seems that .cpp is not  
> automatically a C++ suffix (but is it done the "right" way for  
> portability?). We need the -imacro statement in order to include some  
> macros from Rconfig.h (big endian checks) which are then translated  
> from the WORDS_BIGENDIAN used in R to the IS_BIG_ENDIAN used in the  
> library.

> Comments on the portability?

THings like

  OBJS=$(SOURCES.SDK:.cpp=.o)

are portable.  Not sure about the .cpp not being a C++ suffix part; the
generated Makeconf files should contain a rule for

.cpp.o:
        $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) -c $< -o $@

and the appropriate .SUFFIXES settings.  (Maybe you manipulate
.SUFFIXES?)

Using FOO += something in Make files is not portable.

best
-k


From r.hankin at noc.soton.ac.uk  Fri Sep  9 13:09:58 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 9 Sep 2005 12:09:58 +0100
Subject: [Rd] two almost identical packages: best practice
Message-ID: <8B2D83C0-69CF-48DA-BF80-98ECC67AF55B@soc.soton.ac.uk>

Hi

I have written a whole bunch of methods for objects of class "octonion".

[
an octonion is a single column of an eight-row matrix.  Octonions have
their own multiplication rules and are a generalization of quaternions,
which are columns of a four-row matrix.
]

So far I've done about a dozen generic functions such as seq.octonion(),
rep.octonion(), [<-.octonion(),  and so on and so on.

Very nearly all  of these functions are applicable to objects of  
class "quaternion".
So, for example, I have a generic function Im.octonion():

R> Im.octonion
function (x)
{
     Re(x) <- 0
     return(x)
}

The definition of Im.quaternion() is exactly the same.
Sometimes the return value is an octonion:

  Conj.octonion
function (x)
{
     x <- as.matrix(x)
     x[-1, ] <- -x[-1, ]
     return(as.octonion(x))
}

So the last line of Conj.quaternion() would be "return(as.quaternion 
(x))"
but would be otherwise identical.
A similar story holds for each of maybe twenty generic functions.
Nearly all the Rd files are similarly identical:  the word "octonion"
replaces the word  "octonion".  I suppose "A" changes to "An" as well.

There is a small number of functions and datasets that are specific  
to octonions.

What is Best Practice in this situation?  I don't want to edit two  
separate
packages in tandem.   Is there a mechanism for doing what I want
in the context of a bundle?




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From ggrothendieck at gmail.com  Fri Sep  9 15:08:12 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 09:08:12 -0400
Subject: [Rd] two almost identical packages: best practice
In-Reply-To: <8B2D83C0-69CF-48DA-BF80-98ECC67AF55B@soc.soton.ac.uk>
References: <8B2D83C0-69CF-48DA-BF80-98ECC67AF55B@soc.soton.ac.uk>
Message-ID: <971536df05090906082f9d59d0@mail.gmail.com>

On 9/9/05, Robin Hankin <r.hankin at noc.soton.ac.uk> wrote:
> Hi
> 
> I have written a whole bunch of methods for objects of class "octonion".
> 
> [
> an octonion is a single column of an eight-row matrix.  Octonions have
> their own multiplication rules and are a generalization of quaternions,
> which are columns of a four-row matrix.
> ]
> 
> So far I've done about a dozen generic functions such as seq.octonion(),
> rep.octonion(), [<-.octonion(),  and so on and so on.
> 
> Very nearly all  of these functions are applicable to objects of
> class "quaternion".
> So, for example, I have a generic function Im.octonion():
> 
> R> Im.octonion
> function (x)
> {
>     Re(x) <- 0
>     return(x)
> }
> 
> The definition of Im.quaternion() is exactly the same.
> Sometimes the return value is an octonion:
> 
>  Conj.octonion
> function (x)
> {
>     x <- as.matrix(x)
>     x[-1, ] <- -x[-1, ]
>     return(as.octonion(x))
> }
> 
> So the last line of Conj.quaternion() would be "return(as.quaternion
> (x))"
> but would be otherwise identical.
> A similar story holds for each of maybe twenty generic functions.
> Nearly all the Rd files are similarly identical:  the word "octonion"
> replaces the word  "octonion".  I suppose "A" changes to "An" as well.
> 
> There is a small number of functions and datasets that are specific
> to octonions.
> 
> What is Best Practice in this situation?  I don't want to edit two
> separate
> packages in tandem.   Is there a mechanism for doing what I want
> in the context of a bundle?

Not sure what is best but some possibilities are to:
- create a third S3 class and make your two classes  subclasses of that or 
- make one of your classes a subclass of the other or
- in some cases, you may be able to use the .default method for common code.  
You can also make use of NextMethod if you like though I am not sure if it will
buy you much in this situation (see the dyn package for examples of the use 
of NextMethod).


From dgrove at fhcrc.org  Fri Sep  9 17:02:22 2005
From: dgrove at fhcrc.org (Douglas Grove)
Date: Fri, 9 Sep 2005 08:02:22 -0700 (PDT)
Subject: [Rd] Wishlist: write.delim()
In-Reply-To: <17185.23374.210672.553854@stat.math.ethz.ch>
References: <Pine.LNX.4.61.0509081520540.10724@echidna.fhcrc.org>
	<17185.23374.210672.553854@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0509090741030.31023@echidna.fhcrc.org>

On Fri, 9 Sep 2005, Martin Maechler wrote:

> >>>>> "Douglas" == Douglas Grove <dgrove at fhcrc.org>
> >>>>>     on Thu, 8 Sep 2005 15:33:02 -0700 (PDT) writes:
> 
>     Douglas> Hi,
>     Douglas> It would be great if someone would add write.delim() as an
>     Douglas> adjunct to write.table(), just as with write.csv().
> 
>     Douglas> I store a lot of data in tab-delimited files and can read
>     Douglas> it in easily with:  read.delim("text.txt", as.is=TRUE)
>     Douglas> and would love to be able to write it out as easily when
>     Douglas> I create these files.
> 
>     Douglas> The obvious setting needed for write.delim() is sep = "\t",
>     Douglas> but in addition I would request the setting row.names = FALSE
> 
>     Douglas> i.e. 
> 
>     Douglas> write.delim(x, file) = write.table(x, file, sep = "\t", row.names=FALSE)
> 
> i.e.,
>    write.delim <- function(x, file, ...) 
> 		    write.table(x, file, sep = "\t", row.names=FALSE, ...)
> 
> So, why don't you just add that one line to your .Rprofile ?
 
I would love to do this, but I have to distribute code to people who
are not only R illiterate, but also fairly computer illiterate as well.
So for simplicity I can't use a lot of little convenience functions 
that I'd prefer to use.  


> In general, I don't think that it's worth to introduce a whole
> new function just because of some frequent argument use of an
> already existing function  {{and I have wondered if it was worth
> to provide write.csv() at all - although, there the difference to default
> write.table() is quite a bit larger}}

I agree that it's not a good idea in general.  I suggested this since
there's plenty of precedent in the read and write table functions. 
On the "read" sinde there's read.csv, read.csv2, read.delim and read.delim2
and on the 'write" side there are write.csv and write.csv2.  So it seems
obvious (from a simplistic point of view) to balance these out and offer
write.delim and write.delim2. 

Probably one would want to use the same 'qmethod' setting too, as 
write.csv and write.csv2 use.  So that would bring the number of changed
arguments to 3, the same as write.csv has...

Doug


From sgiannerini at gmail.com  Fri Sep  9 19:04:38 2005
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Fri, 9 Sep 2005 19:04:38 +0200
Subject: [Rd] A question on R memory management in .Fortran() calls under
	Windows
Message-ID: <3c12769c0509091004555400f@mail.gmail.com>

Dear R community,

I have a question on how R manages memory allocation in .Fortran()
calls under Windows.
In brief, apparently, it is not possible to allocate large matrices
inside a Fortran subroutine
  unless you pass them as arguments. If you do not act in this way
RGUI crashes with a stack overflow error and acting  on memory through
vsize nsize ppsize and memory.limit does not help at all.

****************************************************************************************
Details of the configurations on which I performed testing follow:
R 2.1.1 on WinXP Pro SP2 ITA 
PC1: AMD 64 3700+ 1GB RAM 
PC2: AMD AthlonXP 2400+ 512Mb RAM
Compaq Visual Fortran pro 6.6C
****************************************************************************************

To give an idea I attach a brief example on how to reproduce this:
Create two simple subroutines 'foo' and 'foobis' that, say, give the
sum of the elements of a matrix:

*** file foo.f90 starts
***********************************************************************
SUBROUTINE foo(X,M,N,S)
!DEC$ ATTRIBUTES DLLEXPORT,C,REFERENCE,ALIAS:'foo_' :: FOO

    IMPLICIT NONE
    integer:: M,N
    real*8:: X(M,N),S

    S  = sum(X);

END SUBROUTINE foo

SUBROUTINE foobis(M,N,S)
!DEC$ ATTRIBUTES DLLEXPORT,C,REFERENCE,ALIAS:'foobis_' :: FOOBIS

    IMPLICIT NONE
    integer:: M,N
    real*8:: X(M,N),S
    X = 1;
    S  = sum(X);

END SUBROUTINE foobis

*** file foo.f90 ends
***********************************************************************

Notice that the matrix X is an input argument in foo and an internal
variable in foobis.
After compiling and linking turn to R:
**************************************************************************
> dyn.load("foo.dll");
> is.loaded(symbol.For("foo"));
[1] TRUE
> is.loaded(symbol.For("foobis"));
[1] TRUE
> M <- 10;
> N <- 10;
> X <- matrix(1,M,N);
> .Fortran("foo",X,as.integer(M),as.integer(N),S=as.double(0))$S;
[1] 100 
> .Fortran("foobis",as.integer(M),as.integer(N),S=as.double(0))$S;
[1] 100

## no problem here with small matrices, let's increase the size

> M <- 3000;
> N <- 100;
> X <- matrix(1,M,N);
> .Fortran("foo",X,as.integer(M),as.integer(N),S=as.double(0))$S;
[1] 3e+05  ## OK


.Fortran("foobis",as.integer(M),as.integer(N),S=as.double(0))$S;
##  *** R GUI CRASHES WITH A STACK OVERFLOW ERROR ***
****************************************************************************
Any suggestion would be greatly appreciated, I apologize if this
problem has already been addressed previously,  I did not notice it.
 Many thanks in advance,
 
 Simone
______________________________________________________ 

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From ggrothendieck at gmail.com  Fri Sep  9 19:21:41 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 13:21:41 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in read.spss,
	package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
Message-ID: <971536df05090910211d639ed1@mail.gmail.com>

On 9/9/05, Thomas Lumley <tlumley at u.washington.edu> wrote:
> 
> Many packages have a NEWS or ChangeLog file describing changes.  You would
> typically have to look at the source package to find them, since by Unix
> tradition they are usually in the top-level directory and so are not
> included in the binary build.
> 
> The foreign package is on svn.r-project.org, so you can see its Changelog
> there. There have been suggestions to extract these files and put them in
> the CRAN listing, but one obstacle is the lack of standardisation.

Of course this has been discussed a number of times but since its being
brought up again let me just add that there is a substantial need for something
here (i.e. something to address the lack of a standard way of communicating 
issues in packages including changes, outstanding bugs, wishlist items, etc.)  

I personally put NEWS, WISHLIST and THANKS files in the 'inst'
directory of all my source packages.  This has the effect of copying them to the
top level of the built version so that they are accessible from R via:

   system.file("NEWS", package = "mypackage"))

without the burden of having the user retrieve the source and I think we 
need something like that, in general.

If someone wanted to set it up it would really be nice to have sourceforge-like
facilities made available for package developers providing groupware
facilities such as svn for each package, Trac issue tracking for each package, 
home page for each package, email list for each package, etc.  Its probably
too much ongoing work to provide this on a package by package basis but 
an automated system that made it easy for package developers to access this 
all in a standard way on a self-serve basis similar to OpenSVN would
be feasible
if someone wanted to do it.


From tlumley at u.washington.edu  Fri Sep  9 19:33:03 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 9 Sep 2005 10:33:03 -0700 (PDT)
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <971536df05090910211d639ed1@mail.gmail.com>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
Message-ID: <Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>

On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
>
> I personally put NEWS, WISHLIST and THANKS files in the 'inst'
> directory of all my source packages.  This has the effect of copying them to the
> top level of the built version so that they are accessible from R via:
>

I'm not sure that WISHLIST and THANKS need to be available to people who 
haven't installed the package.   NEWS, on the other hand, really does.

One option (if it doesn't turn out to be too much work for the CRAN 
maintainers) would be to have an optional Changelog field in the 
DESCRIPTION file giving the relative path to the file. This would mean 
that maintainers would not all have to switch to the same format.
eg for foreign
   Changelog: ChangeLog
and for survey
   Changelog: inst/NEWS

This might be enough to make it easy for CRAN to display these when the 
maintainer provides them.

 	-thomas


From ggrothendieck at gmail.com  Fri Sep  9 19:44:00 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 13:44:00 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
	read.spss, package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
Message-ID: <971536df05090910442796d89d@mail.gmail.com>

On 9/9/05, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
> >
> > I personally put NEWS, WISHLIST and THANKS files in the 'inst'
> > directory of all my source packages.  This has the effect of copying them to the
> > top level of the built version so that they are accessible from R via:
> >
> 
> I'm not sure that WISHLIST and THANKS need to be available to people who
> haven't installed the package.   NEWS, on the other hand, really does.
> 
> One option (if it doesn't turn out to be too much work for the CRAN
> maintainers) would be to have an optional Changelog field in the
> DESCRIPTION file giving the relative path to the file. This would mean
> that maintainers would not all have to switch to the same format.
> eg for foreign
>   Changelog: ChangeLog
> and for survey
>   Changelog: inst/NEWS
> 
> This might be enough to make it easy for CRAN to display these when the
> maintainer provides them.

How about if there were just a standard location and name such as inst/NEWS,
inst/WISHLIST, inst/THANKS (which has the advantage that they are automatically
made available in the built package under the current way packages are
built) and
then CRAN could just check if its there or not -- no need to change
and document
the DESCRIPTION file.  The only thing package developers who want to provide
these have to do is to use the indicated names and location.  It would still be 
possible as step 2 to provide your idea since its upwardly compatible.  

In fact, even with no software at all there would be an advantage to this since
users would definitively know where to look and would not have to download
the source package just to read this.


From murdoch at stats.uwo.ca  Fri Sep  9 19:51:48 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 09 Sep 2005 13:51:48 -0400
Subject: [Rd] A question on R memory management in .Fortran() calls
 under Windows
In-Reply-To: <3c12769c0509091004555400f@mail.gmail.com>
References: <3c12769c0509091004555400f@mail.gmail.com>
Message-ID: <4321CBB4.3090805@stats.uwo.ca>

On 9/9/2005 1:04 PM, Simone Giannerini wrote:
> Dear R community,
> 
> I have a question on how R manages memory allocation in .Fortran()
> calls under Windows.
> In brief, apparently, it is not possible to allocate large matrices
> inside a Fortran subroutine
>   unless you pass them as arguments. If you do not act in this way
> RGUI crashes with a stack overflow error and acting  on memory through
> vsize nsize ppsize and memory.limit does not help at all.

It looks as though your Fortran compiler is allocating the new matrix on 
the stack.  R doesn't give you a huge stack, and that's causing the 
overflow.  When you get R to do the allocation, it does it on the heap, 
which has no artificial limits.  Only a pointer to the object ends up on 
the stack.

I'd say your only reasonable workarounds are to tell your compiler to 
use the heap for the local matrix allocation (if that's possible), or do 
your allocations in R.

There might be some utility somewhere which can modify Rgui.exe to tell 
it to start with a larger stack, and there is probably some linker 
option to put one in place, but it's not really reasonable to increase 
R's stack, because in almost all other situations, writing that much 
data to the stack is a sign of an infinite recursion.

Duncan Murdoch

> 
> ****************************************************************************************
> Details of the configurations on which I performed testing follow:
> R 2.1.1 on WinXP Pro SP2 ITA 
> PC1: AMD 64 3700+ 1GB RAM 
> PC2: AMD AthlonXP 2400+ 512Mb RAM
> Compaq Visual Fortran pro 6.6C
> ****************************************************************************************
> 
> To give an idea I attach a brief example on how to reproduce this:
> Create two simple subroutines 'foo' and 'foobis' that, say, give the
> sum of the elements of a matrix:
> 
> *** file foo.f90 starts
> ***********************************************************************
> SUBROUTINE foo(X,M,N,S)
> !DEC$ ATTRIBUTES DLLEXPORT,C,REFERENCE,ALIAS:'foo_' :: FOO
> 
>     IMPLICIT NONE
>     integer:: M,N
>     real*8:: X(M,N),S
> 
>     S  = sum(X);
> 
> END SUBROUTINE foo
> 
> SUBROUTINE foobis(M,N,S)
> !DEC$ ATTRIBUTES DLLEXPORT,C,REFERENCE,ALIAS:'foobis_' :: FOOBIS
> 
>     IMPLICIT NONE
>     integer:: M,N
>     real*8:: X(M,N),S
>     X = 1;
>     S  = sum(X);
> 
> END SUBROUTINE foobis
> 
> *** file foo.f90 ends
> ***********************************************************************
> 
> Notice that the matrix X is an input argument in foo and an internal
> variable in foobis.
> After compiling and linking turn to R:
> **************************************************************************
>> dyn.load("foo.dll");
>> is.loaded(symbol.For("foo"));
> [1] TRUE
>> is.loaded(symbol.For("foobis"));
> [1] TRUE
>> M <- 10;
>> N <- 10;
>> X <- matrix(1,M,N);
>> .Fortran("foo",X,as.integer(M),as.integer(N),S=as.double(0))$S;
> [1] 100 
>> .Fortran("foobis",as.integer(M),as.integer(N),S=as.double(0))$S;
> [1] 100
> 
> ## no problem here with small matrices, let's increase the size
> 
>> M <- 3000;
>> N <- 100;
>> X <- matrix(1,M,N);
>> .Fortran("foo",X,as.integer(M),as.integer(N),S=as.double(0))$S;
> [1] 3e+05  ## OK
> 
> 
> .Fortran("foobis",as.integer(M),as.integer(N),S=as.double(0))$S;
> ##  *** R GUI CRASHES WITH A STACK OVERFLOW ERROR ***
> ****************************************************************************
> Any suggestion would be greatly appreciated, I apologize if this
> problem has already been addressed previously,  I did not notice it.
>  Many thanks in advance,
>  
>  Simone
> ______________________________________________________ 
> 
> Simone Giannerini
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Universita' di Bologna
> Via delle belle arti 41 - 40126  Bologna,  ITALY
> Tel: +39 051 2098248  Fax: +39 051 232153
> E-mail: giannerini at stat.unibo.it
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Sep  9 20:00:05 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 9 Sep 2005 14:00:05 -0400
Subject: [Rd] A question on R memory management in .Fortran() calls
	under Windows
In-Reply-To: <3c12769c0509091004555400f@mail.gmail.com>
References: <3c12769c0509091004555400f@mail.gmail.com>
Message-ID: <9F60C50B-7195-4F83-9048-54F0A3B66063@r-project.org>

Simone,

On Sep 9, 2005, at 1:04 PM, Simone Giannerini wrote:

> Dear R community,
>
> I have a question on how R manages memory allocation in .Fortran()  
> calls under Windows.
> In brief, apparently, it is not possible to allocate large matrices  
> inside a Fortran subroutine

I suspect that this is a problem of your compiler, not R, because it  
works without problems for me:

 > dyn.load("foo.so")
 > M=10
 > N=10
 > X=matrix(1,M,N)
 > .Fortran("foo",X,as.integer(M),as.integer(N),S=as.double(0))$S
[1] 100
 > .Fortran("foobis",as.integer(M),as.integer(N),S=as.double(0))$S
[1] 100
 > M=3000
 > N=100
 > X=matrix(1,M,N)
 > .Fortran("foo",X,as.integer(M),as.integer(N),S=as.double(0))$S
[1] 3e+05
 > .Fortran("foobis",as.integer(M),as.integer(N),S=as.double(0))$S
[1] 3e+05
 > M=10000
 > N=10000
 > X=matrix(1,M,N)
 > .Fortran("foo",X,as.integer(M),as.integer(N),S=as.double(0))$S
[1] 1e+08
 > .Fortran("foobis",as.integer(M),as.integer(N),S=as.double(0))$S
[1] 1e+08

Tested on
PC1: Win XP SP2, AMD64 3000+, 1GB RAM, gfortran 4.1.0 (20050902)
PC2: OS X, G5 1.8, 1GB RAM, gfortran 4.0.1

Cheers,
Simon


From tlumley at u.washington.edu  Fri Sep  9 21:53:35 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 9 Sep 2005 12:53:35 -0700 (PDT)
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <971536df05090910442796d89d@mail.gmail.com>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net> 
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net> 
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu> 
	<971536df05090910211d639ed1@mail.gmail.com> 
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
Message-ID: <Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>

On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
> How about if there were just a standard location and name such as inst/NEWS,
> inst/WISHLIST, inst/THANKS (which has the advantage that they are automatically
> made available in the built package under the current way packages are
> built)

The problem is that there *isn't* a standard location. As Robert Gentleman 
has pointed out, if you only maintain two or three packages it isn't too 
bad to change them to some new layout, but if you are the bioconductor 
project it gets painful quite quickly.

Also, there are good reasons for having NEWS in the top level directory. 
Nearly everything that isn't an R package does this, because it's a useful 
standard.

 	-thomas


From ggrothendieck at gmail.com  Fri Sep  9 22:06:58 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 16:06:58 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
	read.spss, package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
Message-ID: <971536df050909130651e99366@mail.gmail.com>

On 9/9/05, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
> > How about if there were just a standard location and name such as inst/NEWS,
> > inst/WISHLIST, inst/THANKS (which has the advantage that they are automatically
> > made available in the built package under the current way packages are
> > built)
> 
> The problem is that there *isn't* a standard location. As Robert Gentleman

Yes, I know.  That was the point of my post -- declare a standard location
that everyone would use (or not but if they don't then people will have a hard
time finding their info but no worse than now).

> has pointed out, if you only maintain two or three packages it isn't too
> bad to change them to some new layout, but if you are the bioconductor
> project it gets painful quite quickly.

Surely there are only a few possibilities that are used and a simple script
could fix that all up.  Its the same problem if you have to modify every 
DESCRIPTION file.

At any rate I don't think this should be driven by compatibility with what
is there now since its not a difficult one-time transition.

> 
> Also, there are good reasons for having NEWS in the top level directory.
> Nearly everything that isn't an R package does this, because it's a useful
> standard.

This could be handled by having the build procedure
copy NEWS, WISHLIST and THANKS
files at the top level to the build rather than not copying them.  That way one 
would not have to put them in the inst directory -- although unlike my previous 
suggestion this would require modifying the build software though its
presumably
not a big change.  I agree that this would be worth it.


From sethfalcon at gmail.com  Fri Sep  9 23:08:53 2005
From: sethfalcon at gmail.com (Seth Falcon)
Date: Fri, 09 Sep 2005 14:08:53 -0700
Subject: [Rd] two almost identical packages: best practice
References: <8B2D83C0-69CF-48DA-BF80-98ECC67AF55B@soc.soton.ac.uk>
Message-ID: <m24q8udk4a.fsf@macaroni.local>

On  9 Sep 2005, r.hankin at noc.soton.ac.uk wrote:
> I have written a whole bunch of methods for objects of class
> "octonion".
>
> So far I've done about a dozen generic functions such as
> seq.octonion(), rep.octonion(), [<-.octonion(), and so on and so on.
>
> Very nearly all  of these functions are applicable to objects of  
> class "quaternion".

One solution would be to define a common base class (perhaps nionBase? ;-)
and put the common methods there.

So in S3 I guess you'd have an Im.nionBase function and your octonions
and quaternions would be subclasses of nionBase.

> (x))" but would be otherwise identical.  A similar story holds for
> each of maybe twenty generic functions.  Nearly all the Rd files are
> similarly identical: the word "octonion" replaces the word
> "octonion".  I suppose "A" changes to "An" as well.

If you document the generics for the base class, I think that would
work.  Otherwise, find/replace.

> There is a small number of functions and datasets that are specific
> to octonions.
>
> What is Best Practice in this situation?  I don't want to edit two  
> separate
> packages in tandem.   Is there a mechanism for doing what I want
> in the context of a bundle?

If they need to be in separate packages, perhaps you have three
packages:

nionBase
quaternion (depends on nionBase)
etc.

HTH,

+ seth


From sethfalcon at gmail.com  Fri Sep  9 23:09:02 2005
From: sethfalcon at gmail.com (Seth Falcon)
Date: Fri, 09 Sep 2005 14:09:02 -0700
Subject: [Rd] Install packages to non-default lib on Windows
References: <m2y867i6hm.fsf@macaroni.local> <4320C8BC.6020702@stats.uwo.ca>
	<43212E87.5030804@statistik.uni-dortmund.de>
Message-ID: <m2u0guc5jl.fsf@macaroni.local>

On  8 Sep 2005, ligges at statistik.uni-dortmund.de wrote:
>>> installing inst files installing data files installing man source
>>> files installing indices cannot create
>>> d:/biocbld/R-devel/doc/html/search/index.txt: permission denied
>
> I was also annoyed about this point a couple of times. But what are 
> possible solutions?
>
> - not updating indices at all?

No idea how difficult this would be but...  Perhaps there could be a
system and local help indices (defined by R_LIBS).  If a package is
installed in a local package library, I don't really see the point of
adding an entry in a global index.

> - provide a switch such as --no-indices for the R CMD tools?

Or perhaps making the failure to write into the index a warning and
not a fatal error?  Not updating the help index seems unfatal to me.

> short time workaround: simply give users write access to the few
> files that have to write to.

Yep.

Thanks,

+ seth


From murdoch at stats.uwo.ca  Sat Sep 10 03:34:01 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 09 Sep 2005 21:34:01 -0400
Subject: [Rd] MikTeX will be assumed in R 2.2.0 in Windows
Message-ID: <43223809.7000306@stats.uwo.ca>

I've just committed some changes to allow R to be built and to use 
MikTeX without needing the Rd.sty files to be installed to localtexmf. 
Unfortunately, the changes are not compatible with other TeX packages, 
so if you're not using MikTeX you'll need to edit a couple of the config 
files (or set an environment variable).

I'd appreciate hearing of any problems during the alpha or beta test period.

A binary build containing the changes should be on CRAN tomorrow or the 
next day.  Look for revision 35546 or higher.

Duncan Murdoch


From ggrothendieck at gmail.com  Sat Sep 10 03:43:20 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 21:43:20 -0400
Subject: [Rd] MikTeX will be assumed in R 2.2.0 in Windows
In-Reply-To: <43223809.7000306@stats.uwo.ca>
References: <43223809.7000306@stats.uwo.ca>
Message-ID: <971536df050909184358485557@mail.gmail.com>

Great.  What specifically is the change?

On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I've just committed some changes to allow R to be built and to use
> MikTeX without needing the Rd.sty files to be installed to localtexmf.
> Unfortunately, the changes are not compatible with other TeX packages,
> so if you're not using MikTeX you'll need to edit a couple of the config
> files (or set an environment variable).
> 
> I'd appreciate hearing of any problems during the alpha or beta test period.
> 
> A binary build containing the changes should be on CRAN tomorrow or the
> next day.  Look for revision 35546 or higher.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Sat Sep 10 03:54:14 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 09 Sep 2005 21:54:14 -0400
Subject: [Rd] MikTeX will be assumed in R 2.2.0 in Windows
In-Reply-To: <971536df050909184358485557@mail.gmail.com>
References: <43223809.7000306@stats.uwo.ca>
	<971536df050909184358485557@mail.gmail.com>
Message-ID: <43223CC6.8010109@stats.uwo.ca>

Gabor Grothendieck wrote:
> Great.  What specifically is the change?

There are a number of changes to make use of the --include-directory 
command line option that Miktex supports.  It needed to be done in 
several places because tex is called from makefiles, Perl and shell scripts.

Duncan Murdoch

> 
> On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>I've just committed some changes to allow R to be built and to use
>>MikTeX without needing the Rd.sty files to be installed to localtexmf.
>>Unfortunately, the changes are not compatible with other TeX packages,
>>so if you're not using MikTeX you'll need to edit a couple of the config
>>files (or set an environment variable).
>>
>>I'd appreciate hearing of any problems during the alpha or beta test period.
>>
>>A binary build containing the changes should be on CRAN tomorrow or the
>>next day.  Look for revision 35546 or higher.
>>
>>Duncan Murdoch
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From ggrothendieck at gmail.com  Sat Sep 10 04:02:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 22:02:33 -0400
Subject: [Rd] \dontshow
Message-ID: <971536df05090919025bc98fce@mail.gmail.com>

In R 2.2.0 I find that even if I use \dontshow in the examples section
of an .Rd file that the code still shows.  

Has anyone else seen this?   

Are there any packages that use this facility that I could
try in order to check this?

I am using 

> R.version.string # XP
"R version 2.2.0, 2005-09-03"


From ggrothendieck at gmail.com  Sat Sep 10 04:04:37 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 22:04:37 -0400
Subject: [Rd] R.version.string (Re: MikTeX will be assumed in R 2.2.0 in
	Windows)
In-Reply-To: <43223809.7000306@stats.uwo.ca>
References: <43223809.7000306@stats.uwo.ca>
Message-ID: <971536df050909190441a98acb@mail.gmail.com>

On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I've just committed some changes to allow R to be built and to use
> MikTeX without needing the Rd.sty files to be installed to localtexmf.
> Unfortunately, the changes are not compatible with other TeX packages,
> so if you're not using MikTeX you'll need to edit a couple of the config
> files (or set an environment variable).
> 
> I'd appreciate hearing of any problems during the alpha or beta test period.
> 
> A binary build containing the changes should be on CRAN tomorrow or the
> next day.  Look for revision 35546 or higher.

Note that R.version.string in R 2.2.0 2005-09-03 does not give
this sort of version information.  If we are going to use this style
I suggest we modify R.version.string accordingly.


From ggrothendieck at gmail.com  Sat Sep 10 04:11:42 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 22:11:42 -0400
Subject: [Rd] Copying libraries from one version of R to another (was Re:
	MikTeX will be assumed in R 2.2.0 in Windows)
In-Reply-To: <43223809.7000306@stats.uwo.ca>
References: <43223809.7000306@stats.uwo.ca>
Message-ID: <971536df050909191141274448@mail.gmail.com>

On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I've just committed some changes to allow R to be built and to use
> MikTeX without needing the Rd.sty files to be installed to localtexmf.
> Unfortunately, the changes are not compatible with other TeX packages,
> so if you're not using MikTeX you'll need to edit a couple of the config
> files (or set an environment variable).
> 
> I'd appreciate hearing of any problems during the alpha or beta test period.
> 
> A binary build containing the changes should be on CRAN tomorrow or the
> next day.  Look for revision 35546 or higher.

The above improvement was one of the key things one had to look out
for in installing R that was not already covered in the R setup procedure.

The other one is to copy the libraries from your old R version to your
new one (unless you want to share libraries among versions).  I have
a batch file in the devel version of batchfiles to do that but if this were
made part of the installation procedure I could eliminate it or if it
were included it would be much less necessary.


From ggrothendieck at gmail.com  Sat Sep 10 04:17:07 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Sep 2005 22:17:07 -0400
Subject: [Rd] \dontshow
In-Reply-To: <971536df05090919025bc98fce@mail.gmail.com>
References: <971536df05090919025bc98fce@mail.gmail.com>
Message-ID: <971536df050909191772cf7127@mail.gmail.com>

On 9/9/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> In R 2.2.0 I find that even if I use \dontshow in the examples section
> of an .Rd file that the code still shows.
> 
> Has anyone else seen this?
> 
> Are there any packages that use this facility that I could
> try in order to check this?
> 
> I am using
> 
> > R.version.string # XP
> "R version 2.2.0, 2005-09-03"
> 

I realize that this description was not clear enough.  It does not
show in the help file but when you run the example it shows
and it was that part I was concerned about.  Is that the way its
supposed to work?


From wettenhall at wehi.EDU.AU  Sat Sep 10 08:11:25 2005
From: wettenhall at wehi.EDU.AU (James Wettenhall)
Date: Sat, 10 Sep 2005 16:11:25 +1000 (EST)
Subject: [Rd] [R] Debugging R/Fortran in Windows
In-Reply-To: <43216662.7010802@stats.uwo.ca>
References: <3095.192.168.65.113.1126245320.squirrel@homebase.wehi.edu.au>
	<43216662.7010802@stats.uwo.ca>
Message-ID: <1999.138.217.40.71.1126332685.squirrel@homebase.wehi.edu.au>

Thanks very much to Uwe, Duncan and Seth (who replied off the list).

Uwe - That section of the R for Windows FAQ was very useful - thanks! 
Sorry I posted a question involving C/Fortran to R-Help.

Duncan - Thanks for all the useful info.  I've bookmarked the pages you
sent me.

Seth - Thanks for suggesting valgrind.  I tried it out, and it correctly
told me that memory leakage was not the problem (although I didn't believe
it at first).

It turned out that the reason my variables were being overwritten was not
because of memory leakage, but because of my own stupidity - using the
same variable name for a function I was estimating and for my current
estimate of that function.  Sorry I didn't spend more time checking this
myself!

Thanks again for your help,
James


From ligges at statistik.uni-dortmund.de  Sat Sep 10 12:08:07 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 10 Sep 2005 12:08:07 +0200
Subject: [Rd] \dontshow
In-Reply-To: <971536df050909191772cf7127@mail.gmail.com>
References: <971536df05090919025bc98fce@mail.gmail.com>
	<971536df050909191772cf7127@mail.gmail.com>
Message-ID: <4322B087.5050400@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:

> On 9/9/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> 
>>In R 2.2.0 I find that even if I use \dontshow in the examples section
>>of an .Rd file that the code still shows.
>>
>>Has anyone else seen this?
>>
>>Are there any packages that use this facility that I could
>>try in order to check this?
>>
>>I am using
>>
>>
>>>R.version.string # XP
>>
>>"R version 2.2.0, 2005-09-03"
>>
> 
> 
> I realize that this description was not clear enough.  It does not
> show in the help file but when you run the example it shows
> and it was that part I was concerned about.  Is that the way its
> supposed to work?

Yes:

Examples displayed and executed during checks/example runs:
   as is
Examples displayed but NOT executed during checks/example runs:
   \dontrun{}
Examples NOT displayed but executed during checks/example runs:
  \dontshow{}
Examples NOT displayed and NOT executed during checks/example runs:
  simply don't type them anywhere ;-)


Best,
Uwe Ligges



> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rhurlin at gwdg.de  Sat Sep 10 12:37:26 2005
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 10 Sep 2005 12:37:26 +0200
Subject: [Rd] FreeBSD 7.0-CURRENT and R-2.2.0 alpha
Message-ID: <4322B766.10803@gwdg.de>

The configure script runs fine, but when I compile todays alpha version
of R-2.2.0 (R-alpha_2005-09-10_r35546.tar.gz) under FreeBSD 7.0-CURRENT
from Sept. 4th I get the following output:


========================================================
[...]
gcc -I../../src/extra/zlib -I../../src/extra/bzip2
-I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
-I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -O2 -c
version.c -o version.o
gcc -I../../src/extra/zlib -I../../src/extra/bzip2
-I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
-I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -O2 -c
vfonts.c -o vfonts.o
f77   -g -O2 -c xxxpr.f -o xxxpr.o
gcc -export-dynamic -L/usr/local/lib -o R.bin  Rmain.o  CConverters.o
CommandLineArgs.o Rdynload.o Renviron.o RNG.o apply.o arithmetic.o
apse.o array.o attrib.o base.o bind.o builtin.o character.o coerce.o
colors.o complex.o connections.o context.o cov.o cum.o dcf.o datetime.o
debug.o deparse.o deriv.o dotcode.o dounzip.o dstruct.o duplicate.o
engine.o envir.o errors.o eval.o format.o fourier.o gevents.o gram.o
gram-ex.o graphics.o identical.o internet.o iosupport.o lapack.o list.o
logic.o main.o mapply.o match.o memory.o model.o names.o objects.o
optim.o optimize.o options.o par.o paste.o pcre.o platform.o plot.o
plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o
qsort.o random.o regex.o registration.o relop.o saveload.o scan.o seq.o
serialize.o size.o sort.o source.o split.o sprintf.o startup.o
subassign.o subscript.o subset.o summary.o sysutils.o unique.o util.o
version.o vfonts.o xxxpr.o ../unix/libunix.a ../appl/libappl.a
../nmath/libnmath.a  -lf77blas -latlas -lg2c -lm  ../extra/zlib/libz.a
../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a
/usr/local/lib/libintl.so -Wl,-rpath -Wl,/usr/local/lib -lreadline -lm
-liconv
complex.o(.text+0x106): In function `mycpow':
/usr/local/R-alpha/src/main/complex.c:170: undefined reference to `cpow'
complex.o(.text+0x6f9): In function `do_cmathfuns':
/usr/local/R-alpha/src/main/complex.c:323: undefined reference to `carg'
complex.o(.text+0xb4b): In function `z_log':
/usr/local/R-alpha/src/main/complex.c:423: undefined reference to `clog'
complex.o(.text+0xb86): In function `z_logbase':
/usr/local/R-alpha/src/main/complex.c:429: undefined reference to `clog'
complex.o(.text+0xb98):/usr/local/R-alpha/src/main/complex.c:429:
undefined reference to `clog'
complex.o(.text+0xbd8): In function `z_exp':
/usr/local/R-alpha/src/main/complex.c:434: undefined reference to `cexp'
complex.o(.text+0xbf8): In function `z_sqrt':
/usr/local/R-alpha/src/main/complex.c:439: undefined reference to `csqrt'
complex.o(.text+0xc18): In function `z_cos':
/usr/local/R-alpha/src/main/complex.c:486: undefined reference to `ccos'
complex.o(.text+0xc38): In function `z_sin':
/usr/local/R-alpha/src/main/complex.c:491: undefined reference to `csin'
complex.o(.text+0xc5e): In function `z_tan':
/usr/local/R-alpha/src/main/complex.c:497: undefined reference to `ctan'
complex.o(.text+0xd26): In function `z_atan2':
/usr/local/R-alpha/src/main/complex.c:523: undefined reference to `catan'
complex.o(.text+0xe18): In function `z_asin':
/usr/local/R-alpha/src/main/complex.c:541: undefined reference to `casin'
complex.o(.text+0xe38): In function `z_acos':
/usr/local/R-alpha/src/main/complex.c:553: undefined reference to `cacos'
complex.o(.text+0xe58): In function `z_atan':
/usr/local/R-alpha/src/main/complex.c:559: undefined reference to `catan'
complex.o(.text+0xe78): In function `z_acosh':
/usr/local/R-alpha/src/main/complex.c:564: undefined reference to `cacosh'
complex.o(.text+0xe98): In function `z_asinh':
/usr/local/R-alpha/src/main/complex.c:569: undefined reference to `casinh'
complex.o(.text+0xeb8): In function `z_atanh':
/usr/local/R-alpha/src/main/complex.c:574: undefined reference to `catanh'
complex.o(.text+0xed8): In function `z_cosh':
/usr/local/R-alpha/src/main/complex.c:579: undefined reference to `ccosh'
complex.o(.text+0xef8): In function `z_sinh':
/usr/local/R-alpha/src/main/complex.c:584: undefined reference to `csinh'
complex.o(.text+0xf18): In function `z_tanh':
/usr/local/R-alpha/src/main/complex.c:589: undefined reference to `ctanh'
*** Error code 1
Stop in /usr/local/R-alpha/src/main.
*** Error code 1
Stop in /usr/local/R-alpha/src/main.
*** Error code 1
Stop in /usr/local/R-alpha/src.
*** Error code 1
Stop in /usr/local/R-alpha.
========================================================

Am I missing something?

Thank you,
Rainer Hurling


From murdoch at stats.uwo.ca  Sat Sep 10 13:35:51 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 10 Sep 2005 07:35:51 -0400
Subject: [Rd] R.version.string (Re: MikTeX will be assumed in R 2.2.0 in
 Windows)
In-Reply-To: <971536df050909190441a98acb@mail.gmail.com>
References: <43223809.7000306@stats.uwo.ca>
	<971536df050909190441a98acb@mail.gmail.com>
Message-ID: <4322C517.4020806@stats.uwo.ca>

Gabor Grothendieck wrote:
> On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>I've just committed some changes to allow R to be built and to use
>>MikTeX without needing the Rd.sty files to be installed to localtexmf.
>>Unfortunately, the changes are not compatible with other TeX packages,
>>so if you're not using MikTeX you'll need to edit a couple of the config
>>files (or set an environment variable).
>>
>>I'd appreciate hearing of any problems during the alpha or beta test period.
>>
>>A binary build containing the changes should be on CRAN tomorrow or the
>>next day.  Look for revision 35546 or higher.
> 
> 
> Note that R.version.string in R 2.2.0 2005-09-03 does not give
> this sort of version information.  If we are going to use this style
> I suggest we modify R.version.string accordingly.

You can get the revision number from the startup banner if you download 
a binary build.

Duncan Murdoch


From murdoch at stats.uwo.ca  Sat Sep 10 13:44:51 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 10 Sep 2005 07:44:51 -0400
Subject: [Rd] [R] Debugging R/Fortran in Windows
In-Reply-To: <1999.138.217.40.71.1126332685.squirrel@homebase.wehi.edu.au>
References: <3095.192.168.65.113.1126245320.squirrel@homebase.wehi.edu.au>	<43216662.7010802@stats.uwo.ca>
	<1999.138.217.40.71.1126332685.squirrel@homebase.wehi.edu.au>
Message-ID: <4322C733.4070104@stats.uwo.ca>

James Wettenhall wrote:
> Thanks very much to Uwe, Duncan and Seth (who replied off the list).
> 
> Uwe - That section of the R for Windows FAQ was very useful - thanks! 
> Sorry I posted a question involving C/Fortran to R-Help.
> 
> Duncan - Thanks for all the useful info.  I've bookmarked the pages you
> sent me.
> 
> Seth - Thanks for suggesting valgrind.  I tried it out, and it correctly
> told me that memory leakage was not the problem (although I didn't believe
> it at first).

Is there a version of valgrind that works in Windows now, or did you do 
this test somewhere else?

Duncan Murdoch

> 
> It turned out that the reason my variables were being overwritten was not
> because of memory leakage, but because of my own stupidity - using the
> same variable name for a function I was estimating and for my current
> estimate of that function.  Sorry I didn't spend more time checking this
> myself!
> 
> Thanks again for your help,
> James
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Friedrich.Leisch at tuwien.ac.at  Sat Sep 10 10:31:29 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Sat, 10 Sep 2005 10:31:29 +0200
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
Message-ID: <17186.39393.136602.297141@celebrian.ci.tuwien.ac.at>

>>>>> On Fri, 9 Sep 2005 10:33:03 -0700 (PDT),
>>>>> Thomas Lumley (TL) wrote:

  > On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
  >> 
  >> I personally put NEWS, WISHLIST and THANKS files in the 'inst'
  >> directory of all my source packages.  This has the effect of copying them to the
  >> top level of the built version so that they are accessible from R via:
  >> 

  > I'm not sure that WISHLIST and THANKS need to be available to people who 
  > haven't installed the package.   NEWS, on the other hand, really does.

  > One option (if it doesn't turn out to be too much work for the CRAN 
  > maintainers) would be to have an optional Changelog field in the 
  > DESCRIPTION file giving the relative path to the file. This would mean 
  > that maintainers would not all have to switch to the same format.
  > eg for foreign
  >    Changelog: ChangeLog
  > and for survey
  >    Changelog: inst/NEWS

  > This might be enough to make it easy for CRAN to display these when the 
  > maintainer provides them.

Standard location or a mechachanism like the one you describe are both
similar amount of work (and not much at all), the HTML pages are
generated by perl and I have the parsed DESCRIPTION file there, i.e.,
using a fixed name or the value of the Changelog field is basically
the same.

.f


From Kurt.Hornik at wu-wien.ac.at  Sat Sep 10 12:01:47 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Sat, 10 Sep 2005 12:01:47 +0200
Subject: [Rd] \dontshow
In-Reply-To: <971536df050909191772cf7127@mail.gmail.com>
References: <971536df05090919025bc98fce@mail.gmail.com>
	<971536df050909191772cf7127@mail.gmail.com>
Message-ID: <17186.44811.377236.677233@mithrandir.hornik.net>

>>>>> Gabor Grothendieck writes:

> On 9/9/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>> In R 2.2.0 I find that even if I use \dontshow in the examples section
>> of an .Rd file that the code still shows.
>> 
>> Has anyone else seen this?
>> 
>> Are there any packages that use this facility that I could
>> try in order to check this?
>> 
>> I am using
>> 
>> > R.version.string # XP
>> "R version 2.2.0, 2005-09-03"
>> 

> I realize that this description was not clear enough.  It does not
> show in the help file but when you run the example it shows
> and it was that part I was concerned about.  Is that the way its
> supposed to work?

According to the docs, yes.  R-exts has

     For example,

          x <- runif(10)       # Shown and run.
          \dontrun{plot(x)}    # Only shown.
          \dontshow{log(x)}    # Only run.

-k


From Kurt.Hornik at wu-wien.ac.at  Sat Sep 10 12:22:13 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Sat, 10 Sep 2005 12:22:13 +0200
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
Message-ID: <17186.46037.468981.530188@mithrandir.hornik.net>

>>>>> Thomas Lumley writes:

> On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
>> How about if there were just a standard location and name such as inst/NEWS,
>> inst/WISHLIST, inst/THANKS (which has the advantage that they are automatically
>> made available in the built package under the current way packages are
>> built)

> The problem is that there *isn't* a standard location. As Robert
> Gentleman has pointed out, if you only maintain two or three packages
> it isn't too bad to change them to some new layout, but if you are the
> bioconductor project it gets painful quite quickly.

> Also, there are good reasons for having NEWS in the top level
> directory.  Nearly everything that isn't an R package does this,
> because it's a useful standard.

And similar things could be said about Emacs users with ChangeLog files
in top-level package directories ...

I like the suggestion about using a Changelog (or whatever it would be
called) field in the package DESCRIPTION meta-data.  If we have that, we
could not only use this for repository-side presentation of the package,
but also install such info and have a simple show_package_change_log()
function ...

-k

>  	-thomas

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat Sep 10 14:34:22 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 08:34:22 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
	read.spss, package foreign?]
In-Reply-To: <17186.39393.136602.297141@celebrian.ci.tuwien.ac.at>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<17186.39393.136602.297141@celebrian.ci.tuwien.ac.at>
Message-ID: <971536df05091005344c05d5db@mail.gmail.com>

On 9/10/05, Friedrich.Leisch at tuwien.ac.at <Friedrich.Leisch at tuwien.ac.at> wrote:
> >>>>> On Fri, 9 Sep 2005 10:33:03 -0700 (PDT),
> >>>>> Thomas Lumley (TL) wrote:
> 
>  > On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
>  >>
>  >> I personally put NEWS, WISHLIST and THANKS files in the 'inst'
>  >> directory of all my source packages.  This has the effect of copying them to the
>  >> top level of the built version so that they are accessible from R via:
>  >>
> 
>  > I'm not sure that WISHLIST and THANKS need to be available to people who
>  > haven't installed the package.   NEWS, on the other hand, really does.
> 
>  > One option (if it doesn't turn out to be too much work for the CRAN
>  > maintainers) would be to have an optional Changelog field in the
>  > DESCRIPTION file giving the relative path to the file. This would mean
>  > that maintainers would not all have to switch to the same format.
>  > eg for foreign
>  >    Changelog: ChangeLog
>  > and for survey
>  >    Changelog: inst/NEWS
> 
>  > This might be enough to make it easy for CRAN to display these when the
>  > maintainer provides them.
> 
> Standard location or a mechachanism like the one you describe are both
> similar amount of work (and not much at all), the HTML pages are
> generated by perl and I have the parsed DESCRIPTION file there, i.e.,
> using a fixed name or the value of the Changelog field is basically
> the same.
> 
> .f
> 

Regarding the two possibilities I think there is an advantage in a fixed
name in a fixed location since one always knows where to look.  The 
extra level of indirection in the DESCRIPTION file just means that one 
has to fill out yet another field and the user can't know where to look
directly, for sure, but must first look it up in the DESCRIPTION file.

I think the DESCRIPTION file idea was motivated by making it easier
for existing packages but in fact I think its no harder to rename and
move a file, and maybe easier, than to add a line to the DESCRIPTION
file.   Also I think this should apply not only to NEWS/ChangeLog but
also to THANKS and WISHLIST and that would mean 3 more lines in the
DESCRIPTION file so it could rapidly get out of hand.


From ggrothendieck at gmail.com  Sat Sep 10 14:48:30 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 08:48:30 -0400
Subject: [Rd] \dontshow
In-Reply-To: <17186.44811.377236.677233@mithrandir.hornik.net>
References: <971536df05090919025bc98fce@mail.gmail.com>
	<971536df050909191772cf7127@mail.gmail.com>
	<17186.44811.377236.677233@mithrandir.hornik.net>
Message-ID: <971536df050910054851d74efd@mail.gmail.com>

On 9/10/05, Kurt Hornik <Kurt.Hornik at wu-wien.ac.at> wrote:
> >>>>> Gabor Grothendieck writes:
> 
> > On 9/9/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >> In R 2.2.0 I find that even if I use \dontshow in the examples section
> >> of an .Rd file that the code still shows.
> >>
> >> Has anyone else seen this?
> >>
> >> Are there any packages that use this facility that I could
> >> try in order to check this?
> >>
> >> I am using
> >>
> >> > R.version.string # XP
> >> "R version 2.2.0, 2005-09-03"
> >>
> 
> > I realize that this description was not clear enough.  It does not
> > show in the help file but when you run the example it shows
> > and it was that part I was concerned about.  Is that the way its
> > supposed to work?
> 
> According to the docs, yes.  R-exts has
> 
>     For example,
> 
>          x <- runif(10)       # Shown and run.
>          \dontrun{plot(x)}    # Only shown.
>          \dontshow{log(x)}    # Only run.
> 
> -k
> 

A bit of background.   My package depends on external software that 
would not be on CRAN.

In order to pass R CMD check on a system that does not contain the
external software, what I am currently doing is to add an if statement at 
the beginning and end of each example section in each help file and in the 
demo that checks if the external software is present.  This check is done 
within a \dontrun{...} in the case of the help files.  

The if statement at the top simply checks for the availability of the external
software on the system and if not found then replaces f, the function
which would otherwise access that software, with a dummy function.
The if statement at the bottom removes the dummy function.

For example, 

\dontrun{  if (!software.found()) f <- function(...) cat("*** software
not present\n") }
...body of example...
\dontrun{ if (!software.found()) rm(f) }

Now this is quite kludgy but I currently know of no better alternative.
The help file looks ok but when you run it it does show the if statements
at the beginning and end which may be a bit disconcerting.

I had previously placed the entire body of the example section or demo
in an if but that had the disadvantage of not interleaving input and output
but rather showing all input and then all output.


From ggrothendieck at gmail.com  Sat Sep 10 14:51:07 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 08:51:07 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
	read.spss, package foreign?]
In-Reply-To: <17186.46037.468981.530188@mithrandir.hornik.net>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
	<17186.46037.468981.530188@mithrandir.hornik.net>
Message-ID: <971536df050910055166ae0a14@mail.gmail.com>

On 9/10/05, Kurt Hornik <Kurt.Hornik at wu-wien.ac.at> wrote:
> >>>>> Thomas Lumley writes:
> 
> > On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
> >> How about if there were just a standard location and name such as inst/NEWS,
> >> inst/WISHLIST, inst/THANKS (which has the advantage that they are automatically
> >> made available in the built package under the current way packages are
> >> built)
> 
> > The problem is that there *isn't* a standard location. As Robert
> > Gentleman has pointed out, if you only maintain two or three packages
> > it isn't too bad to change them to some new layout, but if you are the
> > bioconductor project it gets painful quite quickly.
> 
> > Also, there are good reasons for having NEWS in the top level
> > directory.  Nearly everything that isn't an R package does this,
> > because it's a useful standard.
> 
> And similar things could be said about Emacs users with ChangeLog files
> in top-level package directories ...
> 
> I like the suggestion about using a Changelog (or whatever it would be
> called) field in the package DESCRIPTION meta-data.  If we have that, we
> could not only use this for repository-side presentation of the package,
> but also install such info and have a simple show_package_change_log()
> function ...

One could have that without this meta data.  show_package_change_log
could just check if the file is present.


From ggrothendieck at gmail.com  Sat Sep 10 15:02:55 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 09:02:55 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
	read.spss, package foreign?]
In-Reply-To: <971536df050910055166ae0a14@mail.gmail.com>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
	<17186.46037.468981.530188@mithrandir.hornik.net>
	<971536df050910055166ae0a14@mail.gmail.com>
Message-ID: <971536df0509100602238abe70@mail.gmail.com>

On 9/10/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 9/10/05, Kurt Hornik <Kurt.Hornik at wu-wien.ac.at> wrote:
> > >>>>> Thomas Lumley writes:
> >
> > > On Fri, 9 Sep 2005, Gabor Grothendieck wrote:
> > >> How about if there were just a standard location and name such as inst/NEWS,
> > >> inst/WISHLIST, inst/THANKS (which has the advantage that they are automatically
> > >> made available in the built package under the current way packages are
> > >> built)
> >
> > > The problem is that there *isn't* a standard location. As Robert
> > > Gentleman has pointed out, if you only maintain two or three packages
> > > it isn't too bad to change them to some new layout, but if you are the
> > > bioconductor project it gets painful quite quickly.
> >
> > > Also, there are good reasons for having NEWS in the top level
> > > directory.  Nearly everything that isn't an R package does this,
> > > because it's a useful standard.
> >
> > And similar things could be said about Emacs users with ChangeLog files
> > in top-level package directories ...
> >
> > I like the suggestion about using a Changelog (or whatever it would be
> > called) field in the package DESCRIPTION meta-data.  If we have that, we
> > could not only use this for repository-side presentation of the package,
> > but also install such info and have a simple show_package_change_log()
> > function ...
> 
> One could have that without this meta data.  show_package_change_log
> could just check if the file is present.
> 

And one more comment.   The DESCRIPTION file does not record the
location or existence of the various subdirectories such as R, man, 
exec, etc. If NEWS is to be recorded as a meta data line item in 
DESCRIPTION then surely all of these should be too so its symmetric
and they are all on an equal footing (or else none of them
should be, which in fact I think is preferable).


From ggrothendieck at gmail.com  Sat Sep 10 15:04:57 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 09:04:57 -0400
Subject: [Rd] \dontshow
In-Reply-To: <971536df050910054851d74efd@mail.gmail.com>
References: <971536df05090919025bc98fce@mail.gmail.com>
	<971536df050909191772cf7127@mail.gmail.com>
	<17186.44811.377236.677233@mithrandir.hornik.net>
	<971536df050910054851d74efd@mail.gmail.com>
Message-ID: <971536df05091006042db0e5f1@mail.gmail.com>

On 9/10/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 9/10/05, Kurt Hornik <Kurt.Hornik at wu-wien.ac.at> wrote:
> > >>>>> Gabor Grothendieck writes:
> >
> > > On 9/9/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > >> In R 2.2.0 I find that even if I use \dontshow in the examples section
> > >> of an .Rd file that the code still shows.
> > >>
> > >> Has anyone else seen this?
> > >>
> > >> Are there any packages that use this facility that I could
> > >> try in order to check this?
> > >>
> > >> I am using
> > >>
> > >> > R.version.string # XP
> > >> "R version 2.2.0, 2005-09-03"
> > >>
> >
> > > I realize that this description was not clear enough.  It does not
> > > show in the help file but when you run the example it shows
> > > and it was that part I was concerned about.  Is that the way its
> > > supposed to work?
> >
> > According to the docs, yes.  R-exts has
> >
> >     For example,
> >
> >          x <- runif(10)       # Shown and run.
> >          \dontrun{plot(x)}    # Only shown.
> >          \dontshow{log(x)}    # Only run.
> >
> > -k
> >
> 
> A bit of background.   My package depends on external software that
> would not be on CRAN.
> 
> In order to pass R CMD check on a system that does not contain the
> external software, what I am currently doing is to add an if statement at
> the beginning and end of each example section in each help file and in the
> demo that checks if the external software is present.  This check is done
> within a \dontrun{...} in the case of the help files.
> 
> The if statement at the top simply checks for the availability of the external
> software on the system and if not found then replaces f, the function
> which would otherwise access that software, with a dummy function.
> The if statement at the bottom removes the dummy function.
> 
> For example,
> 
> \dontrun{  if (!software.found()) f <- function(...) cat("*** software
> not present\n") }
> ...body of example...
> \dontrun{ if (!software.found()) rm(f) }

Sorry, those should have been dontshow, not dontrun.

> 
> Now this is quite kludgy but I currently know of no better alternative.
> The help file looks ok but when you run it it does show the if statements
> at the beginning and end which may be a bit disconcerting.
> 
> I had previously placed the entire body of the example section or demo
> in an if but that had the disadvantage of not interleaving input and output
> but rather showing all input and then all output.
>


From ggrothendieck at gmail.com  Sat Sep 10 15:19:08 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 09:19:08 -0400
Subject: [Rd] R.version.string (Re: MikTeX will be assumed in R 2.2.0 in
	Windows)
In-Reply-To: <4322C517.4020806@stats.uwo.ca>
References: <43223809.7000306@stats.uwo.ca>
	<971536df050909190441a98acb@mail.gmail.com>
	<4322C517.4020806@stats.uwo.ca>
Message-ID: <971536df050910061939711dab@mail.gmail.com>

On 9/10/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> Gabor Grothendieck wrote:
> > On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >
> >>I've just committed some changes to allow R to be built and to use
> >>MikTeX without needing the Rd.sty files to be installed to localtexmf.
> >>Unfortunately, the changes are not compatible with other TeX packages,
> >>so if you're not using MikTeX you'll need to edit a couple of the config
> >>files (or set an environment variable).
> >>
> >>I'd appreciate hearing of any problems during the alpha or beta test period.
> >>
> >>A binary build containing the changes should be on CRAN tomorrow or the
> >>next day.  Look for revision 35546 or higher.
> >
> >
> > Note that R.version.string in R 2.2.0 2005-09-03 does not give
> > this sort of version information.  If we are going to use this style
> > I suggest we modify R.version.string accordingly.
> 
> You can get the revision number from the startup banner if you download
> a binary build.
> 
> Duncan Murdoch
> 
> 

I normally document what version I am using by displaying R.version.string.
If R.version.string is no longer definitive under 2.2.0 then it either needs to
be modified so that it is or we need some other way of getting that
capability.


From ligges at statistik.uni-dortmund.de  Sat Sep 10 15:39:22 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 10 Sep 2005 15:39:22 +0200
Subject: [Rd] R.version.string (Re: MikTeX will be assumed in R 2.2.0
 in	Windows)
In-Reply-To: <971536df050910061939711dab@mail.gmail.com>
References: <43223809.7000306@stats.uwo.ca>	<971536df050909190441a98acb@mail.gmail.com>	<4322C517.4020806@stats.uwo.ca>
	<971536df050910061939711dab@mail.gmail.com>
Message-ID: <4322E20A.8060003@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:
> On 9/10/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>Gabor Grothendieck wrote:
>>
>>>On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>
>>>
>>>>I've just committed some changes to allow R to be built and to use
>>>>MikTeX without needing the Rd.sty files to be installed to localtexmf.
>>>>Unfortunately, the changes are not compatible with other TeX packages,
>>>>so if you're not using MikTeX you'll need to edit a couple of the config
>>>>files (or set an environment variable).
>>>>
>>>>I'd appreciate hearing of any problems during the alpha or beta test period.
>>>>
>>>>A binary build containing the changes should be on CRAN tomorrow or the
>>>>next day.  Look for revision 35546 or higher.
>>>
>>>
>>>Note that R.version.string in R 2.2.0 2005-09-03 does not give
>>>this sort of version information.  If we are going to use this style
>>>I suggest we modify R.version.string accordingly.
>>
>>You can get the revision number from the startup banner if you download
>>a binary build.
>>
>>Duncan Murdoch
>>
>>
> 
> 
> I normally document what version I am using by displaying R.version.string.
> If R.version.string is no longer definitive
                          ^^^^^^^^^
It never was for non-released versions checked out from svn (or cvs in 
the older days) ...

Uwe Ligges


 > under 2.2.0 then it either needs to
> be modified so that it is or we need some other way of getting that
> capability.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From f.harrell at vanderbilt.edu  Sat Sep 10 15:58:30 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 10 Sep 2005 08:58:30 -0500
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in,
 read.spss, package foreign?]
Message-ID: <4322E686.8020603@vanderbilt.edu>

I would vote for allowing a URL or external file name in in DESCRIPTION, 
whose contents could be automatically displayed for the user when 
needed.  Our changelogs are automatically generated by CVS and are on 
the web.
-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ligges at statistik.uni-dortmund.de  Sat Sep 10 16:09:31 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 10 Sep 2005 16:09:31 +0200
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in,
 read.spss, package foreign?]
In-Reply-To: <4322E686.8020603@vanderbilt.edu>
References: <4322E686.8020603@vanderbilt.edu>
Message-ID: <4322E91B.3040900@statistik.uni-dortmund.de>

Frank E Harrell Jr wrote:

> I would vote for allowing a URL or external file name in in DESCRIPTION, 
> whose contents could be automatically displayed for the user when 
> needed.  Our changelogs are automatically generated by CVS and are on 
> the web.

 From a repositoriy maintainer's point of view:
Yes, if people really want it, then please something in a DESCRIPTION 
file. Lookup whether a file exists takes a lot of time, in particular if 
you do not have the source package in an extracted form.

Note that CRAN does not have to handle one or two packages, but 
processes 600 for each repository...

Uwe Ligges


From ggrothendieck at gmail.com  Sat Sep 10 16:23:13 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 10:23:13 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in,
	read.spss, package foreign?]
In-Reply-To: <4322E686.8020603@vanderbilt.edu>
References: <4322E686.8020603@vanderbilt.edu>
Message-ID: <971536df05091007231dfb275a@mail.gmail.com>

On 9/10/05, Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> I would vote for allowing a URL or external file name in in DESCRIPTION,
> whose contents could be automatically displayed for the user when
> needed.  Our changelogs are automatically generated by CVS and are on
> the web.

Normally I would have expected a NEWS file to contain information
similar to the R NEWS file 

   https://svn.r-project.org/R/trunk/NEWS

which is a less granular summary of the cvs or svn logs.  

   http://developer.r-project.org/R.svnlog.2005

For those of my packages that use svn I also have a NEWS
file.  The NEWS and log files are not the same.

If the DESCRIPTION file were to pull in log files off the net or
otherwise then I think it should be done at build time and incorporated 
into the distribution.

Perhaps we need the capability to reference both the NEWS file 
and the cvs/svn logs.


From wettenhall at wehi.EDU.AU  Sat Sep 10 17:15:49 2005
From: wettenhall at wehi.EDU.AU (James Wettenhall)
Date: Sun, 11 Sep 2005 01:15:49 +1000 (EST)
Subject: [Rd] [R] Debugging R/Fortran in Windows
In-Reply-To: <4322C733.4070104@stats.uwo.ca>
References: <3095.192.168.65.113.1126245320.squirrel@homebase.wehi.edu.au>	<43216662.7010802@stats.uwo.ca>
	<1999.138.217.40.71.1126332685.squirrel@homebase.wehi.edu.au>
	<4322C733.4070104@stats.uwo.ca>
Message-ID: <1088.138.217.40.71.1126365349.squirrel@homebase.wehi.edu.au>

Duncan,

>> Seth - Thanks for suggesting valgrind.  I tried it out, and it correctly
>> told me that memory leakage was not the problem (although I didn't
>> believe it at first).
>
> Is there a version of valgrind that works in Windows now, or did you do
> this test somewhere else?
>
> Duncan Murdoch

No, I didn't find a version of valgrind that works on Windows.  I used it
on Linux.

Best wishes,
James


From sethfalcon at gmail.com  Sat Sep 10 17:32:11 2005
From: sethfalcon at gmail.com (Seth Falcon)
Date: Sat, 10 Sep 2005 08:32:11 -0700
Subject: [Rd] Issue tracking in packages
In-Reply-To: <17186.46037.468981.530188@mithrandir.hornik.net> (Kurt Hornik's
	message of "Sat, 10 Sep 2005 12:22:13 +0200")
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
	<17186.46037.468981.530188@mithrandir.hornik.net>
Message-ID: <m2mzml2b2c.fsf@macaroni.gateway.2wire.net>

On 10 Sep 2005, Kurt.Hornik at wu-wien.ac.at wrote:
> I like the suggestion about using a Changelog (or whatever it would
> be called) field in the package DESCRIPTION meta-data.  If we have
> that, we could not only use this for repository-side presentation of
> the package, but also install such info and have a simple
> show_package_change_log() function ...

For what its worth, I don't like this idea of adding a ChangeLog field
to the DESCRIPTION file.

Agreeing upon a standard location for NEWS or CHANGES or some such
seems a more simple solution.  As long as the presence of such a file
is *optional*.  And if the location really needs to be at the top,
then the build tools could grab it from there as they do the
DESCRIPTION file.

+ seth


From tlumley at u.washington.edu  Sat Sep 10 18:32:29 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 10 Sep 2005 09:32:29 -0700 (PDT)
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <17186.39393.136602.297141@celebrian.ci.tuwien.ac.at>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<17186.39393.136602.297141@celebrian.ci.tuwien.ac.at>
Message-ID: <Pine.LNX.4.63a.0509100931060.17336@homer24.u.washington.edu>

>
> Standard location or a mechachanism like the one you describe are both
> similar amount of work (and not much at all), the HTML pages are
> generated by perl and I have the parsed DESCRIPTION file there, i.e.,
> using a fixed name or the value of the Changelog field is basically
> the same.
>

In which case a Changlog entry in DESCRIPTION would be a very nice 
addition, and would have the advantage of not requiring changes to 
packages.

 	-thomas


From tlumley at u.washington.edu  Sat Sep 10 18:40:20 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 10 Sep 2005 09:40:20 -0700 (PDT)
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <971536df0509100602238abe70@mail.gmail.com>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net> 
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net> 
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu> 
	<971536df05090910211d639ed1@mail.gmail.com> 
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu> 
	<971536df05090910442796d89d@mail.gmail.com> 
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu> 
	<17186.46037.468981.530188@mithrandir.hornik.net>
	<971536df050910055166ae0a14@mail.gmail.com>
	<971536df0509100602238abe70@mail.gmail.com>
Message-ID: <Pine.LNX.4.63a.0509100933520.17336@homer24.u.washington.edu>

On Sat, 10 Sep 2005, Gabor Grothendieck wrote:
>
> And one more comment.   The DESCRIPTION file does not record the
> location or existence of the various subdirectories such as R, man,
> exec, etc. If NEWS is to be recorded as a meta data line item in
> DESCRIPTION then surely all of these should be too so its symmetric
> and they are all on an equal footing (or else none of them
> should be, which in fact I think is preferable).
>

I don't see any advantage in symmetry.  The locations of these 
subdirectories are fixed and I can't see why someone trying to decide 
whether to install an upgrade needs to know if it has an exec 
subdirectory before they download the package.

I also don't see why THANKS and WISHLIST should need to be visible before 
you download the package.  CRAN does display a URL if one is given, and if 
these are important they could be at that URL.

The changelog, on the other hand, is one piece of information that is 
really valuable in deciding whether or not to update a package, so it 
would be worth having it visible on CRAN.  Since other coding standards 
suggest different things for the name and location of this file, a path in 
DESCRIPTION seems a minimal change.

 	-thomas


From tlumley at u.washington.edu  Sat Sep 10 18:44:41 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 10 Sep 2005 09:44:41 -0700 (PDT)
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in,
 read.spss, package foreign?]
In-Reply-To: <4322E686.8020603@vanderbilt.edu>
References: <4322E686.8020603@vanderbilt.edu>
Message-ID: <Pine.LNX.4.63a.0509100941130.17336@homer24.u.washington.edu>

On Sat, 10 Sep 2005, Frank E Harrell Jr wrote:

> I would vote for allowing a URL or external file name in in DESCRIPTION,
> whose contents could be automatically displayed for the user when
> needed.  Our changelogs are automatically generated by CVS and are on
> the web.

Yes, this would be nice.

However, a URL facility is already present (and you already use it, and 
link changelogs to the URL, as do I).

 	-thomas


From tlumley at u.washington.edu  Sat Sep 10 18:48:10 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 10 Sep 2005 09:48:10 -0700 (PDT)
Subject: [Rd] Issue tracking in packages
In-Reply-To: <m2mzml2b2c.fsf@macaroni.gateway.2wire.net>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
	<17186.46037.468981.530188@mithrandir.hornik.net>
	<m2mzml2b2c.fsf@macaroni.gateway.2wire.net>
Message-ID: <Pine.LNX.4.63a.0509100946190.17336@homer24.u.washington.edu>

On Sat, 10 Sep 2005, Seth Falcon wrote:
> For what its worth, I don't like this idea of adding a ChangeLog field
> to the DESCRIPTION file.
>
> Agreeing upon a standard location for NEWS or CHANGES or some such
> seems a more simple solution.  As long as the presence of such a file
> is *optional*.  And if the location really needs to be at the top,
> then the build tools could grab it from there as they do the
> DESCRIPTION file.

We're certainly agreed on its being optional.

 	-thomas


From f.harrell at vanderbilt.edu  Sat Sep 10 18:50:26 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 10 Sep 2005 11:50:26 -0500
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in,
 read.spss, package foreign?]
In-Reply-To: <971536df05091007231dfb275a@mail.gmail.com>
References: <4322E686.8020603@vanderbilt.edu>
	<971536df05091007231dfb275a@mail.gmail.com>
Message-ID: <43230ED2.1080906@vanderbilt.edu>

Gabor Grothendieck wrote:
> On 9/10/05, Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> 
>>I would vote for allowing a URL or external file name in in DESCRIPTION,
>>whose contents could be automatically displayed for the user when
>>needed.  Our changelogs are automatically generated by CVS and are on
>>the web.
> 
> 
> Normally I would have expected a NEWS file to contain information
> similar to the R NEWS file 
> 
>    https://svn.r-project.org/R/trunk/NEWS
> 
> which is a less granular summary of the cvs or svn logs.  
> 
>    http://developer.r-project.org/R.svnlog.2005
> 
> For those of my packages that use svn I also have a NEWS
> file.  The NEWS and log files are not the same.
> 
> If the DESCRIPTION file were to pull in log files off the net or
> otherwise then I think it should be done at build time and incorporated 
> into the distribution.

I would not vote for pulling files off the net.  It is useful to see 
change log entries dated after when the package was built, so the users 
can get a sense of the value of updating or can bother the maintainer to 
create a new version.

Frank

> 
> Perhaps we need the capability to reference both the NEWS file 
> and the cvs/svn logs.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From maechler at stat.math.ethz.ch  Sat Sep 10 19:06:51 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 10 Sep 2005 19:06:51 +0200
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509100931060.17336@homer24.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<17186.39393.136602.297141@celebrian.ci.tuwien.ac.at>
	<Pine.LNX.4.63a.0509100931060.17336@homer24.u.washington.edu>
Message-ID: <17187.4779.96104.903626@stat.math.ethz.ch>

>>>>> "TL" == Thomas Lumley <tlumley at u.washington.edu>
>>>>>     on Sat, 10 Sep 2005 09:32:29 -0700 (PDT) writes:

    >>  Standard location or a mechachanism like the one you
    >> describe are both similar amount of work (and not much at
    >> all), the HTML pages are generated by perl and I have the
    >> parsed DESCRIPTION file there, i.e., using a fixed name
    >> or the value of the Changelog field is basically the
    >> same.
    >> 

    TL> In which case a Changlog entry in DESCRIPTION would be a
    TL> very nice addition, and would have the advantage of not
    TL> requiring changes to packages.

yes *and* does allow slightly more flexibility with almost
no cost, as Fritz confirmed.

And, BTW, Gabor,  NEWS and ChangeLog are not at all the same
thing and it would be silly to urge users to one of them.
At least 'ChangeLog' is a well defined format for emacs users
that can very quickly be updated semi-automagically
("C-x 4 a" when you're in file  foo.R with function myfun(.)
 autogenerates a neat entry in a ChangeLog file);
but then really people should be allowed to use other formats
for good reasons.

Martin


From ggrothendieck at gmail.com  Sat Sep 10 20:42:12 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 10 Sep 2005 14:42:12 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
	read.spss, package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509100933520.17336@homer24.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
	<17186.46037.468981.530188@mithrandir.hornik.net>
	<971536df050910055166ae0a14@mail.gmail.com>
	<971536df0509100602238abe70@mail.gmail.com>
	<Pine.LNX.4.63a.0509100933520.17336@homer24.u.washington.edu>
Message-ID: <971536df050910114251a8cce6@mail.gmail.com>

On 9/10/05, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Sat, 10 Sep 2005, Gabor Grothendieck wrote:
> >
> > And one more comment.   The DESCRIPTION file does not record the
> > location or existence of the various subdirectories such as R, man,
> > exec, etc. If NEWS is to be recorded as a meta data line item in
> > DESCRIPTION then surely all of these should be too so its symmetric
> > and they are all on an equal footing (or else none of them
> > should be, which in fact I think is preferable).
> >
> 
> I don't see any advantage in symmetry.  The locations of these

The present discussion is where the change information may be located
but that is also true of the source and other information.    We could
just as easily have a field in the DESCRIPTION that tells the build
where to find the R source.
Its really the same issue.  

> subdirectories are fixed and I can't see why someone trying to decide
> whether to install an upgrade needs to know if it has an exec
> subdirectory before they download the package.
> 

That is a different issue which has not been discussed up to now.
I agree that that would be desirable.  It does seem independent
of the other issues discussed.  If CRAN processing speed can be
enhanced then I see no reason other than work involved to have the
build automatically enter a DESCRIPTION field of News: Yes
However, to make the user fill out another field and to burden
the user with having to look at DESCRIPTION first seems 
to add complexity without benefit.

I can think of one intermediate situation.  The source DESCRIPTION
has the path to the NEWS which the build grabs and puts it in
a standard place in the built package.  However, if we allow that for 
the NEWS then we should allow it for all components rather than
an inconsistent approach.

> I also don't see why THANKS and WISHLIST should need to be visible before
> you download the package.  CRAN does display a URL if one is given, and if

Either way would be ok in my opinion.

> these are important they could be at that URL.
> 
> The changelog, on the other hand, is one piece of information that is
> really valuable in deciding whether or not to update a package, so it
> would be worth having it visible on CRAN.  Since other coding standards
> suggest different things for the name and location of this file, a path in
> DESCRIPTION seems a minimal change.

There is no current standard. This is our chance to make it the same
for all packages and therefore easier for all users.


In short, how about we have a standard name and location for
the NEWS, cvs/svn log, WISHLIST, THANKS in the source
package.  The build would maintain their locations and, in
the case of NEWS and the svn/cvs log enter lines in the
DESCRIPTION file such as:

NEWS: Yes
ChangeLog: Yes

for sake of CRAN processing speed (if it turns out that
this does make a material difference which it may not).

This would seem to satisfy all requirements.  Its simple,
its easy to move to since one just renames or renames
and moves one's files (without the need for modifying the
DESCRIPTION file in every package or having yet more fields
in the DESCRIPTION file) and its easy for the 
user since they know where everything is supposed to be 
located without a complicating level of indirection.


From murdoch at stats.uwo.ca  Sat Sep 10 21:09:51 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 10 Sep 2005 15:09:51 -0400
Subject: [Rd] R.version.string (Re: MikTeX will be assumed in R 2.2.0 in
 Windows)
In-Reply-To: <971536df050910061939711dab@mail.gmail.com>
References: <43223809.7000306@stats.uwo.ca>	
	<971536df050909190441a98acb@mail.gmail.com>	
	<4322C517.4020806@stats.uwo.ca>
	<971536df050910061939711dab@mail.gmail.com>
Message-ID: <43232F7F.8030104@stats.uwo.ca>

Gabor Grothendieck wrote:
> On 9/10/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>Gabor Grothendieck wrote:
>>
>>>On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>
>>>
>>>>I've just committed some changes to allow R to be built and to use
>>>>MikTeX without needing the Rd.sty files to be installed to localtexmf.
>>>>Unfortunately, the changes are not compatible with other TeX packages,
>>>>so if you're not using MikTeX you'll need to edit a couple of the config
>>>>files (or set an environment variable).
>>>>
>>>>I'd appreciate hearing of any problems during the alpha or beta test period.
>>>>
>>>>A binary build containing the changes should be on CRAN tomorrow or the
>>>>next day.  Look for revision 35546 or higher.
>>>
>>>
>>>Note that R.version.string in R 2.2.0 2005-09-03 does not give
>>>this sort of version information.  If we are going to use this style
>>>I suggest we modify R.version.string accordingly.
>>
>>You can get the revision number from the startup banner if you download
>>a binary build.
>>
>>Duncan Murdoch
>>
>>
> 
> 
> I normally document what version I am using by displaying R.version.string.
> If R.version.string is no longer definitive under 2.2.0 then it either needs to
> be modified so that it is or we need some other way of getting that
> capability.

R.version$"svn rev" will give you the svn revision in 2.2.0 and up. 
Normally you won't need this; there is only one release of R per x.y.z 
version number.  You only need to go to svn revision when you are 
looking at unreleased snapshot builds.

Duncan Murdoch


From tlumley at u.washington.edu  Sat Sep 10 23:26:14 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 10 Sep 2005 14:26:14 -0700 (PDT)
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <971536df050910114251a8cce6@mail.gmail.com>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
	<17186.46037.468981.530188@mithrandir.hornik.net>
	<971536df050910055166ae0a14@mail.gmail.com>
	<971536df0509100602238abe70@mail.gmail.com>
	<Pine.LNX.4.63a.0509100933520.17336@homer24.u.washington.edu>
	<971536df050910114251a8cce6@mail.gmail.com>
Message-ID: <Pine.LNX.4.63a.0509101421200.7379@homer23.u.washington.edu>

On Sat, 10 Sep 2005, Gabor Grothendieck wrote:

> On 9/10/05, Thomas Lumley <tlumley at u.washington.edu> wrote:
>> On Sat, 10 Sep 2005, Gabor Grothendieck wrote:
>>>
>>> And one more comment.   The DESCRIPTION file does not record the
>>> location or existence of the various subdirectories such as R, man,
>>> exec, etc. If NEWS is to be recorded as a meta data line item in
>>> DESCRIPTION then surely all of these should be too so its symmetric
>>> and they are all on an equal footing (or else none of them
>>> should be, which in fact I think is preferable).
>>>
>>
>> I don't see any advantage in symmetry.  The locations of these
>
> The present discussion is where the change information may be located
> but that is also true of the source and other information.    We could
> just as easily have a field in the DESCRIPTION that tells the build
> where to find the R source.
> Its really the same issue.
>

There are two important differences

1/ No existing package has its source anywhere other than in the R 
subdirectory. Existing packages have their change logs in different places 
and different formats.

2/ Having source code where it will not be found must be an error -- 
making the source code available to R *cannot* be optional.  Making a 
change log available *must* be optional.


 	-thomas


From ggrothendieck at gmail.com  Sun Sep 11 08:04:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 11 Sep 2005 02:04:33 -0400
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
	read.spss, package foreign?]
In-Reply-To: <Pine.LNX.4.63a.0509101421200.7379@homer23.u.washington.edu>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<971536df05090910442796d89d@mail.gmail.com>
	<Pine.LNX.4.63a.0509091250220.5570@homer23.u.washington.edu>
	<17186.46037.468981.530188@mithrandir.hornik.net>
	<971536df050910055166ae0a14@mail.gmail.com>
	<971536df0509100602238abe70@mail.gmail.com>
	<Pine.LNX.4.63a.0509100933520.17336@homer24.u.washington.edu>
	<971536df050910114251a8cce6@mail.gmail.com>
	<Pine.LNX.4.63a.0509101421200.7379@homer23.u.washington.edu>
Message-ID: <971536df05091023045505489f@mail.gmail.com>

On 9/10/05, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Sat, 10 Sep 2005, Gabor Grothendieck wrote:
> 
> > On 9/10/05, Thomas Lumley <tlumley at u.washington.edu> wrote:
> >> On Sat, 10 Sep 2005, Gabor Grothendieck wrote:
> >>>
> >>> And one more comment.   The DESCRIPTION file does not record the
> >>> location or existence of the various subdirectories such as R, man,
> >>> exec, etc. If NEWS is to be recorded as a meta data line item in
> >>> DESCRIPTION then surely all of these should be too so its symmetric
> >>> and they are all on an equal footing (or else none of them
> >>> should be, which in fact I think is preferable).
> >>>
> >>
> >> I don't see any advantage in symmetry.  The locations of these
> >
> > The present discussion is where the change information may be located
> > but that is also true of the source and other information.    We could
> > just as easily have a field in the DESCRIPTION that tells the build
> > where to find the R source.
> > Its really the same issue.
> >
> 
> There are two important differences
> 
> 1/ No existing package has it source anywhere other than in the R
> subdirectory. Existing packages have their change logs in different places
> and different formats.

In terms of the source package the source code is in the R
subdirectory because its been standardized that way and the
R CMD tools support it.  It could, in principle be anywhere and brought
into the built package at build time had it not been designed that
way.  The same is true of the change information.  The point is
that there is really no difference in principle between the two.

Furthermore, what existing packages do is not important since its no harder
and probably easier to adapt to the standard scheme.  Even if that
were not the case I don't think that that should drive the design.

> 2/ Having source code where it will not be found must be an error --
> making the source code available to R *cannot* be optional.  Making a
> change log available *must* be optional.

Source code is optional too.  One can create a package with no
R subdirectory.  In fact the only thing you cannot leave out and
still pass R CMD check is the DESCRIPTION file.


There really is no difference between change information and the
source.  Both could be in the source package or not in the source
package and just brought into the built package at
build time depending on how the build process is designed.

Also in both cases the advantage of having everything in the
source package is that the built package can be guaranteed
to be built from the source package.


From ripley at stats.ox.ac.uk  Sun Sep 11 08:57:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 Sep 2005 07:57:49 +0100 (BST)
Subject: [Rd] FreeBSD 7.0-CURRENT and R-2.2.0 alpha
In-Reply-To: <4322B766.10803@gwdg.de>
References: <4322B766.10803@gwdg.de>
Message-ID: <Pine.LNX.4.61.0509110749100.24002@gannet.stats>

These were found by AC_CHECK_FUNCS (please confirm what configure said) so 
most likely some macro needs to be set or header included.

Could you please find out how configure managed to find cpow etc when they 
appear not to be in libc/libm?

On Sat, 10 Sep 2005, Rainer Hurling wrote:

> The configure script runs fine, but when I compile todays alpha version
> of R-2.2.0 (R-alpha_2005-09-10_r35546.tar.gz) under FreeBSD 7.0-CURRENT
> from Sept. 4th I get the following output:
>
>
> ========================================================
> [...]
> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -O2 -c
> version.c -o version.o
> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -O2 -c
> vfonts.c -o vfonts.o
> f77   -g -O2 -c xxxpr.f -o xxxpr.o
> gcc -export-dynamic -L/usr/local/lib -o R.bin  Rmain.o  CConverters.o
> CommandLineArgs.o Rdynload.o Renviron.o RNG.o apply.o arithmetic.o
> apse.o array.o attrib.o base.o bind.o builtin.o character.o coerce.o
> colors.o complex.o connections.o context.o cov.o cum.o dcf.o datetime.o
> debug.o deparse.o deriv.o dotcode.o dounzip.o dstruct.o duplicate.o
> engine.o envir.o errors.o eval.o format.o fourier.o gevents.o gram.o
> gram-ex.o graphics.o identical.o internet.o iosupport.o lapack.o list.o
> logic.o main.o mapply.o match.o memory.o model.o names.o objects.o
> optim.o optimize.o options.o par.o paste.o pcre.o platform.o plot.o
> plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o
> qsort.o random.o regex.o registration.o relop.o saveload.o scan.o seq.o
> serialize.o size.o sort.o source.o split.o sprintf.o startup.o
> subassign.o subscript.o subset.o summary.o sysutils.o unique.o util.o
> version.o vfonts.o xxxpr.o ../unix/libunix.a ../appl/libappl.a
> ../nmath/libnmath.a  -lf77blas -latlas -lg2c -lm  ../extra/zlib/libz.a
> ../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a
> /usr/local/lib/libintl.so -Wl,-rpath -Wl,/usr/local/lib -lreadline -lm
> -liconv
> complex.o(.text+0x106): In function `mycpow':
> /usr/local/R-alpha/src/main/complex.c:170: undefined reference to `cpow'
> complex.o(.text+0x6f9): In function `do_cmathfuns':
> /usr/local/R-alpha/src/main/complex.c:323: undefined reference to `carg'
> complex.o(.text+0xb4b): In function `z_log':
> /usr/local/R-alpha/src/main/complex.c:423: undefined reference to `clog'
> complex.o(.text+0xb86): In function `z_logbase':
> /usr/local/R-alpha/src/main/complex.c:429: undefined reference to `clog'
> complex.o(.text+0xb98):/usr/local/R-alpha/src/main/complex.c:429:
> undefined reference to `clog'
> complex.o(.text+0xbd8): In function `z_exp':
> /usr/local/R-alpha/src/main/complex.c:434: undefined reference to `cexp'
> complex.o(.text+0xbf8): In function `z_sqrt':
> /usr/local/R-alpha/src/main/complex.c:439: undefined reference to `csqrt'
> complex.o(.text+0xc18): In function `z_cos':
> /usr/local/R-alpha/src/main/complex.c:486: undefined reference to `ccos'
> complex.o(.text+0xc38): In function `z_sin':
> /usr/local/R-alpha/src/main/complex.c:491: undefined reference to `csin'
> complex.o(.text+0xc5e): In function `z_tan':
> /usr/local/R-alpha/src/main/complex.c:497: undefined reference to `ctan'
> complex.o(.text+0xd26): In function `z_atan2':
> /usr/local/R-alpha/src/main/complex.c:523: undefined reference to `catan'
> complex.o(.text+0xe18): In function `z_asin':
> /usr/local/R-alpha/src/main/complex.c:541: undefined reference to `casin'
> complex.o(.text+0xe38): In function `z_acos':
> /usr/local/R-alpha/src/main/complex.c:553: undefined reference to `cacos'
> complex.o(.text+0xe58): In function `z_atan':
> /usr/local/R-alpha/src/main/complex.c:559: undefined reference to `catan'
> complex.o(.text+0xe78): In function `z_acosh':
> /usr/local/R-alpha/src/main/complex.c:564: undefined reference to `cacosh'
> complex.o(.text+0xe98): In function `z_asinh':
> /usr/local/R-alpha/src/main/complex.c:569: undefined reference to `casinh'
> complex.o(.text+0xeb8): In function `z_atanh':
> /usr/local/R-alpha/src/main/complex.c:574: undefined reference to `catanh'
> complex.o(.text+0xed8): In function `z_cosh':
> /usr/local/R-alpha/src/main/complex.c:579: undefined reference to `ccosh'
> complex.o(.text+0xef8): In function `z_sinh':
> /usr/local/R-alpha/src/main/complex.c:584: undefined reference to `csinh'
> complex.o(.text+0xf18): In function `z_tanh':
> /usr/local/R-alpha/src/main/complex.c:589: undefined reference to `ctanh'
> *** Error code 1
> Stop in /usr/local/R-alpha/src/main.
> *** Error code 1
> Stop in /usr/local/R-alpha/src/main.
> *** Error code 1
> Stop in /usr/local/R-alpha/src.
> *** Error code 1
> Stop in /usr/local/R-alpha.
> ========================================================
>
> Am I missing something?
>
> Thank you,
> Rainer Hurling
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Friedrich.Leisch at tuwien.ac.at  Sun Sep 11 11:17:28 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Sun, 11 Sep 2005 11:17:28 +0200
Subject: [Rd] Issue tracking in packages [was: Re: [R] change in
 read.spss, package foreign?]
In-Reply-To: <17187.4779.96104.903626@stat.math.ethz.ch>
References: <3.0.6.32.20050909015829.007bed60@pop.gmx.net>
	<3.0.6.32.20050909145010.007c2a70@pop.gmx.net>
	<Pine.LNX.4.63a.0509090845050.619@homer23.u.washington.edu>
	<971536df05090910211d639ed1@mail.gmail.com>
	<Pine.LNX.4.63a.0509091029550.5570@homer23.u.washington.edu>
	<17186.39393.136602.297141@celebrian.ci.tuwien.ac.at>
	<Pine.LNX.4.63a.0509100931060.17336@homer24.u.washington.edu>
	<17187.4779.96104.903626@stat.math.ethz.ch>
Message-ID: <17187.63016.726744.91386@celebrian.ci.tuwien.ac.at>

>>>>> On Sat, 10 Sep 2005 19:06:51 +0200,
>>>>> Martin Maechler (MM) wrote:

>>>>> "TL" == Thomas Lumley <tlumley at u.washington.edu>
>>>>>     on Sat, 10 Sep 2005 09:32:29 -0700 (PDT) writes:

  >>> Standard location or a mechachanism like the one you
  >>> describe are both similar amount of work (and not much at
  >>> all), the HTML pages are generated by perl and I have the
  >>> parsed DESCRIPTION file there, i.e., using a fixed name
  >>> or the value of the Changelog field is basically the
  >>> same.
  >>> 

  TL> In which case a Changlog entry in DESCRIPTION would be a
  TL> very nice addition, and would have the advantage of not
  TL> requiring changes to packages.

  > yes *and* does allow slightly more flexibility with almost
  > no cost, as Fritz confirmed.

Well, as Kurt pointed out in another (?) thread "CRAN is not the R
universe", and, e.g., Seth might have another opinion when it comes to
BioC administration. But I don't think you can (or should) do too much
sensible computations on packages without having parsed the
DESCRIPTION file, so the "almost no cost" statement should be pretty
safe.


  > And, BTW, Gabor,  NEWS and ChangeLog are not at all the same
  > thing and it would be silly to urge users to one of them.
  > At least 'ChangeLog' is a well defined format for emacs users
  > that can very quickly be updated semi-automagically
  > ("C-x 4 a" when you're in file  foo.R with function myfun(.)
  >  autogenerates a neat entry in a ChangeLog file);
  > but then really people should be allowed to use other formats
  > for good reasons.

I fully agree.

.f


From W.E.Wolski at newcastle.ac.uk  Sun Sep 11 17:32:05 2005
From: W.E.Wolski at newcastle.ac.uk (nwew)
Date: Sun, 11 Sep 2005 16:32:05 +0100
Subject: [Rd] dyn.load error -- undefined symbol: ...
Message-ID: <4314EAF1@webmail.ncl.ac.uk>

Dear R-developers,

I am working on an C interface to some c functions.
I compiled the c file using R CMD SHLIB without any compilation errors. All 
libs used are added to the LD_LIBRARY_PATH.

However dyn.load("interface.so")
produces  undefined symbol: N_VNew_Serial;

which is defined in one of the libs I link against.
Where, and how to start searching for the error?

Eryk


From duncan at wald.ucdavis.edu  Sun Sep 11 22:13:32 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Sun, 11 Sep 2005 13:13:32 -0700
Subject: [Rd] dyn.load error -- undefined symbol: ...
In-Reply-To: <4314EAF1@webmail.ncl.ac.uk>
References: <4314EAF1@webmail.ncl.ac.uk>
Message-ID: <43248FEC.4080008@wald.ucdavis.edu>



You should tell us what operating system you are working on.

If it is a Unix variant, you can use the command ldd:

    ldd interface.so

and see if and where it finds all the libraries against which you link.

(otool -L  on Mac OS X will give you similar information.)

Then make certain that the symbol N_VNew_Serial is defined in
one of those. You can find which symbols are available from
a library, etc. using the command nm -g


If you don't find your problem, you should post the
output from R CMD SHLIB ...  so that we can see
the link command and give you some suggestions as
to where to look.

   D.

nwew wrote:
> Dear R-developers,
> 
> I am working on an C interface to some c functions.
> I compiled the c file using R CMD SHLIB without any compilation errors. All 
> libs used are added to the LD_LIBRARY_PATH.
> 
> However dyn.load("interface.so")
> produces  undefined symbol: N_VNew_Serial;
> 
> which is defined in one of the libs I link against.
> Where, and how to start searching for the error?
> 
> Eryk
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dragan_sestovic at yahoo.com  Mon Sep 12 03:48:20 2005
From: dragan_sestovic at yahoo.com (dragan_sestovic@yahoo.com)
Date: Mon, 12 Sep 2005 03:48:20 +0200 (CEST)
Subject: [Rd] chron on windows (PR#8130)
Message-ID: <20050912014820.9D8581CFA4@slim.kubism.ku.dk>

Full_Name: Dragan Sestovic
Version: 2.0.1
OS: windows XP
Submission from: (NULL) (216.80.117.146)


Function dates() does not work correctly on the windows system for years after
2000. On unix system it is OK. Here are the examples I got on my R 2.0.1. on
Windows XP:

> dates("02/10/2002")
[1] 02/10/92
> dates("02/10/2003")
[1] 02/09/93
> dates("02/10/2010")
[1] 02/10/00
>


Regards

Dragan Sestovic


From ligges at statistik.uni-dortmund.de  Mon Sep 12 09:34:46 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Mon, 12 Sep 2005 09:34:46 +0200 (CEST)
Subject: [Rd] chron on windows (PR#8130)
Message-ID: <20050912073446.6AD0CDB92@slim.kubism.ku.dk>

dragan_sestovic at yahoo.com wrote:

> Full_Name: Dragan Sestovic
> Version: 2.0.1
> OS: windows XP
> Submission from: (NULL) (216.80.117.146)
> 
> 
> Function dates() does not work correctly on the windows system for years after
> 2000. On unix system it is OK. Here are the examples I got on my R 2.0.1. on
> Windows XP:
> 
> 
>>dates("02/10/2002")
> 
> [1] 02/10/92


Please upgrade both R and chron. It works perfectly with recent versions.

Please read the FAQs and learn to check against recent versions of R (at 
least released version, these days in particular the alpha versions of R!)

Uwe Ligges


>>dates("02/10/2003")
> 
> [1] 02/09/93
> 
>>dates("02/10/2010")
> 
> [1] 02/10/00
> 
> 
> 
> Regards
> 
> Dragan Sestovic
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sgiannerini at gmail.com  Mon Sep 12 10:30:05 2005
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 12 Sep 2005 10:30:05 +0200
Subject: [Rd] A question on R memory management in .Fortran() calls
	under Windows
In-Reply-To: <4321CBB4.3090805@stats.uwo.ca>
References: <3c12769c0509091004555400f@mail.gmail.com>
	<4321CBB4.3090805@stats.uwo.ca>
Message-ID: <3c12769c05091201305a31f10f@mail.gmail.com>

Dear Duncan and Simon,

many thanks for your helpful reply.

> Duncan Murdoch wrote:
> It looks as though your Fortran compiler is allocating the new matrix on
> the stack.  R doesn't give you a huge stack, and that's causing the
> overflow.  When you get R to do the allocation, it does it on the heap,
> which has no artificial limits.  Only a pointer to the object ends up on
> the stack.
 
yes, CVF allocates automatic objects on the stack and apparently there
is no way of changing it. By the way, increasing the stack of the
fortran process when linking does not solve the problem

> I'd say your only reasonable workarounds are to tell your compiler to
> use the heap for the local matrix allocation (if that's possible), or do
> your allocations in R.

I might follow the second way, in any case, I am considering switching
to Linux, I have also  considered changing compiler under Win,  any
suggestions on the choice would be welcomed.
 
Many thanks again,
kind regards,

Simone Giannerini


From murdoch at stats.uwo.ca  Mon Sep 12 13:40:14 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 12 Sep 2005 07:40:14 -0400
Subject: [Rd] A question on R memory management in .Fortran() calls
 under Windows
In-Reply-To: <3c12769c05091201305a31f10f@mail.gmail.com>
References: <3c12769c0509091004555400f@mail.gmail.com>	
	<4321CBB4.3090805@stats.uwo.ca>
	<3c12769c05091201305a31f10f@mail.gmail.com>
Message-ID: <4325691E.7020509@stats.uwo.ca>

Simone Giannerini wrote:
> Dear Duncan and Simon,
> 
> many thanks for your helpful reply.
> 
> 
>>Duncan Murdoch wrote:
>>It looks as though your Fortran compiler is allocating the new matrix on
>>the stack.  R doesn't give you a huge stack, and that's causing the
>>overflow.  When you get R to do the allocation, it does it on the heap,
>>which has no artificial limits.  Only a pointer to the object ends up on
>>the stack.
> 
>  
> yes, CVF allocates automatic objects on the stack and apparently there
> is no way of changing it. By the way, increasing the stack of the
> fortran process when linking does not solve the problem
> 
> 
>>I'd say your only reasonable workarounds are to tell your compiler to
>>use the heap for the local matrix allocation (if that's possible), or do
>>your allocations in R.
> 
> 
> I might follow the second way, in any case, I am considering switching
> to Linux, I have also  considered changing compiler under Win,  any
> suggestions on the choice would be welcomed.

I think it's far from the best optimizing compiler, but the Fortran that 
comes with MinGW (g77 currently in Windows) is the one used to build R, 
so it's the one that will is most likely to work with it without 
fiddling.  But I don't use Fortran, so I don't know what else is available.

Duncan Murdoch


From simon.urbanek at r-project.org  Mon Sep 12 15:02:14 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 12 Sep 2005 09:02:14 -0400
Subject: [Rd] A question on R memory management in .Fortran() calls
	under Windows
In-Reply-To: <3c12769c05091201305a31f10f@mail.gmail.com>
References: <3c12769c0509091004555400f@mail.gmail.com>
	<4321CBB4.3090805@stats.uwo.ca>
	<3c12769c05091201305a31f10f@mail.gmail.com>
Message-ID: <2B95FE9B-2106-4226-A9AE-395C070994BD@r-project.org>

Simone,

On Sep 12, 2005, at 4:30 AM, Simone Giannerini wrote:

> yes, CVF allocates automatic objects on the stack and apparently  
> there is no way of changing it.

Yes, that's bad news.

> By the way, increasing the stack of the fortran process when  
> linking does not solve the problem

In general the stack size is also governed by the system limits so  
you may need to increase those as well, but still, that won't really  
solve your problem.

>> I'd say your only reasonable workarounds are to tell your compiler to
>> use the heap for the local matrix allocation (if that's possible),  
>> or do
>> your allocations in R.
>>
>
> I might follow the second way, in any case, I am considering  
> switching to Linux, I have also  considered changing compiler under  
> Win,  any suggestions on the choice would be welcomed.

As Duncan was mentioning g77 is your friend if you can convert your  
code to f77. If you don't have that option, you're partially on your  
own. GNU Fortran 95 (gfortran) may be an option as it exists both for  
unix and Windows (although not as a part of MinGW), but R currently  
doesn't provide .f90 target so you'll need to add your own small  
Makevars.

Cheers,
Simon


From sgiannerini at gmail.com  Mon Sep 12 15:03:47 2005
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 12 Sep 2005 15:03:47 +0200
Subject: [Rd] A question on R memory management in .Fortran() calls
	under Windows
In-Reply-To: <4325691E.7020509@stats.uwo.ca>
References: <3c12769c0509091004555400f@mail.gmail.com>
	<4321CBB4.3090805@stats.uwo.ca>
	<3c12769c05091201305a31f10f@mail.gmail.com>
	<4325691E.7020509@stats.uwo.ca>
Message-ID: <3c12769c05091206037ec06e3f@mail.gmail.com>

> I think it's far from the best optimizing compiler, but the Fortran that
> comes with MinGW (g77 currently in Windows) is the one used to build R,
> so it's the one that will is most likely to work with it without
> fiddling.  But I don't use Fortran, so I don't know what else is available.
> 
> Duncan Murdoch
> 

Thanks a lot anyway,
 in a comparative review I've come through recently 
(http://www.polyhedron.co.uk/compare.html)
 the Salford compiler seems to be one of the most protected against
errors but also one of the slowest. Intel compiler seems to be one of
the fastest but not the best on protection.

Simone Giannerini


From sgiannerini at gmail.com  Mon Sep 12 15:11:34 2005
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 12 Sep 2005 15:11:34 +0200
Subject: [Rd] A question on R memory management in .Fortran() calls
	under Windows
In-Reply-To: <2B95FE9B-2106-4226-A9AE-395C070994BD@r-project.org>
References: <3c12769c0509091004555400f@mail.gmail.com>
	<4321CBB4.3090805@stats.uwo.ca>
	<3c12769c05091201305a31f10f@mail.gmail.com>
	<2B95FE9B-2106-4226-A9AE-395C070994BD@r-project.org>
Message-ID: <3c12769c05091206113df83eb1@mail.gmail.com>

On 9/12/05, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Simone,
> 
> On Sep 12, 2005, at 4:30 AM, Simone Giannerini wrote:
> 
> > yes, CVF allocates automatic objects on the stack and apparently
> > there is no way of changing it.
> 
> Yes, that's bad news.
> 
> > By the way, increasing the stack of the fortran process when
> > linking does not solve the problem
> 
> In general the stack size is also governed by the system limits so
> you may need to increase those as well, but still, that won't really
> solve your problem.
> 
> >> I'd say your only reasonable workarounds are to tell your compiler to
> >> use the heap for the local matrix allocation (if that's possible),
> >> or do
> >> your allocations in R.
> >>
> >
> > I might follow the second way, in any case, I am considering
> > switching to Linux, I have also  considered changing compiler under
> > Win,  any suggestions on the choice would be welcomed.
> 
> As Duncan was mentioning g77 is your friend if you can convert your
> code to f77. If you don't have that option, you're partially on your
> own. GNU Fortran 95 (gfortran) may be an option as it exists both for
> unix and Windows (although not as a part of MinGW), but R currently
> doesn't provide .f90 target so you'll need to add your own small
> Makevars.
> 
> Cheers,
> Simon
> 
> 

Many thanks, I did not know about gfortran for Windows, I will have a
look at it.

Kind regards,
Simone

-- 
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From ligges at statistik.uni-dortmund.de  Mon Sep 12 17:41:18 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 Sep 2005 17:41:18 +0200
Subject: [Rd] contributed Windows binary packages for R-2.2.0 alpha
Message-ID: <4325A19E.3060703@statistik.uni-dortmund.de>

Dear package developers,

contributed Windows binary packages for R-devel are available for some 
time now and should have propagated through CRAN.

I have re-compiled and re-checked all packages under R-2.2.0 alpha again 
today. Results will propagate through CRAN within a couple of days (on 
CRAN master in a few hours).
Maintainers of packages that produce an ERROR now and have not produced 
an ERROR before have just been notified by automatical generated 
messages. All others might want to check whether there is a WARNING for 
their packages.

Best,
Uwe Ligges


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Mon Sep 12 18:02:39 2005
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Mon, 12 Sep 2005 18:02:39 +0200
Subject: [Rd] ptr_R_EditFile, R_WriteConsole, and R_ShowMessage
Message-ID: <200509121802.40246.thomas.friedrichsmeier@ruhr-uni-bochum.de>

Hi!

I have an application embedding R. For that of course, it is great, that since 
R 2.1.0 the pointers in Rinterface.h allow me to override some callbacks, 
easily. However, after implementing/overriding a couple of those, I'm a bit 
confused about when exactly they get called. So, here are a few specific 
questions:

ptr_R_EditFile:
I can find exactly one point in the R-sources where ptr_R_EditFile acutally 
seems to be used (at least if non-NULL). By default the pointer is set to 
NULL with the comment "for futur expansion".
I wonder:
1) Why is this needed at all? Shouldn't the more generic R_EditFiles 
(ptr_R_EditFiles) suffice for the more specific case of editing a single 
file?
2) Why is ptr_R_EditFiles only available on aqua? Ok, it says on other 
platforms this does not currently work. But if I'd be able to create a 
working implementation in my application, why shouldn't I be allowed to 
override it (ok, I still can by just declaring it extern, but it's not 
exported in rinterface.h)? R could still check ptr_R_EditFiles for NULL 
before using it.
3) Am I correct in assuming that the parameter char* buf is supposed to keep 
the filename?

R_ShowMessage (ptr_R_ShowMessage):
This one, too, seems to have very few use-cases (but at least some). Most seem 
to be for errors during startup.
I wonder:
1) If this callback is most useful during startR (...), can it even be used in 
a meaningful way? After all, startR () also initializes all the callbacks to 
the standard values.
2) That aside, what is the policy for R_ShowMessage? Can I assume all messages 
being shown this way are errors of some sort? Or could there also be mere 
informational messages (which in a GUI would be presented in slightly 
different ways)?

R_WriteConsole (ptr_R_WriteConsole):
This is a great callback. It will allow me to get rid of my hacky sinks 
(currently I use a sink to a file to retrieve the output). Even better would 
be an additional callback ptr_R_WriteErr. Is there any particular reason, why 
this does not exist? Could it be added?

Thanks!
Thomas


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Mon Sep 12 18:37:35 2005
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Mon, 12 Sep 2005 18:37:35 +0200
Subject: [Rd] ptr_R_EditFile, R_WriteConsole, and R_ShowMessage
In-Reply-To: <200509121802.40246.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <200509121802.40246.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <200509121837.35750.thomas.friedrichsmeier@ruhr-uni-bochum.de>

> R_ShowMessage (ptr_R_ShowMessage):
> This one, too, seems to have very few use-cases (but at least some). Most
> seem to be for errors during startup.
> I wonder:
> 1) If this callback is most useful during startR (...), can it even be used
> in a meaningful way? After all, startR () also initializes all the
> callbacks to the standard values.

Sorry, of course I meant to write Rf_initEmbeddedR (...). I got confused as I 
have this and a few other initialization calls in a functions called startR 
(...).


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Sep 13 02:27:54 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 13 Sep 2005 02:27:54 +0200 (CEST)
Subject: [Rd] R news: Call for Papers
Message-ID: <Pine.LNX.4.51.0509130226290.16273@artemis.imbe.med.uni-erlangen.de>


Dear useRs and developeRs,

the next issue of `R news' is scheduled for the beginning of November
and we are now  accepting submissions for this last issue in 2005.
For more information see

      http://cran.r-project.org/doc/Rnews/

If you are the author of a package on CRAN and you would like to promote
it a little bit, or if you simply have an interesting application using
R, we hope you can find some time to write a short article on it. We
suggest that it be approximately 3 pages or less. The idea of the
newsletter is that it be interesting to R users without being too
technical. For example an article describing a package could begin by
briefly outlining the statistical background and go on to demonstrate
the usage on some typical data set. Of course graphics are more than
welcome!

Bill Venables <Bill.Venables at csiro.au> is also encouraging submissions
to the more specialist Programmer's Niche column. In this case the
technical level could be a little higher, of course, but not necessarily:
ingeniousness is the key.

The R Help Desk column is intended to present answers to frequently
asked questions as well as tricks that are useful to the majority of
useRs. Please send submissions to Uwe Ligges <Uwe.Ligges at R-project.org>.

The deadline for submissions is

	October, 8th, 2005

Keep the contributions rolling in!

The Editorial Board,

Doug Bates, Paul Murrell and Torsten Hothorn


From maechler at stat.math.ethz.ch  Tue Sep 13 16:17:45 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 13 Sep 2005 16:17:45 +0200
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
Message-ID: <17190.57225.254938.977464@stat.math.ethz.ch>

As some of you R-devel readers may know, the plot() method for
"lm" objects is based in large parts on contributions by John
Maindonald, subsequently "massaged" by me and other R-core
members.

In the statistics litterature on applied regression, people have
had  diverse oppinions on what (and how many!) plots should be
used for goodness-of-fit / residual diagnostics, and to my
knowledge most people have agreed to want to see one (or more)
version of a Tukey-Anscombe plot {Residuals ~ Fitted} and a QQ
normal plot.
Another consideration was to be somewhat close to what S
(S-plus) was doing.  So we have two versions of residuals vs
fitted, one for checking  E[error] = 0, the other for checking 
Var[error] = constant.  So we got to the first three plots of
plot.lm() about which I don't want to debate at the moment
{though, there's room for improvement even there: e.g., I know of at
 least one case where plot(<lm>) wasn't used because the user
 was missing the qqline() she was so used to in the QQ plot}

The topic of this e-mail is the (default) 4th plot which I had
changed; really prompted by the following:
More than three months ago, John wrote
  http://tolstoy.newcastle.edu.au/R/devel/05/04/0594.html
    (which became a thread of about 20 messages, from Apr.23 -- 29, 2005)

and currently, 
NEWS for R 2.2.0 alpha contains

>> USER-VISIBLE CHANGES
>> 
>>    o plot(<lm object>) uses a new default for the fourth panel when
>>      'which' is not specified.
>>      ___ may change before release ___

and the header is

plot.lm <- 
function (x, which = c(1:3, 5), 
          caption = c("Residuals vs Fitted", 
	              "Normal Q-Q", "Scale-Location", 
		      "Cook's distance", "Residuals vs Leverage", 
		      "Cook's distance vs Leverage"), 
	   ......... ) {..............}

So we now have 6 possible plots, where 1,2,3 and 5 are the
defaults (and 1,2,3,4 where the old defaults).

For the influential points and combination of 'influential' and 'outlier'
there have been quite a few more proposals in the past. R <= 2.1.x
has been plotting the  Cook's distances vs. observation number, whereas
quite a few people in the past have noted that all influence
measures being more or less complicated functions of residuals
and "hat values" aka "leverages", (R_i, h_{ii}), it would really
make sense and fit more to the other plots
to plot residuals vs. Leverages --- with the additional idea of
adding *contours* of (equal) Cook's distances to that plot, in
case one would really want to seem them.

In the mean time, this has been *active* in R-devel for quite a
while, and we haven't received any new comments.

One remaining problem I'd like to address is the "balanced AOV"
situation, something probably pretty rare nowadays in real
practice, but common of course in teaching ANOVA.
As you may remember, in a balanced design, all observations have
the same leverages h_{ii}, and the plot  R_i  vs  h_ii is really
not so useful.  In that case,  the cook distances CD_i = c *  R_i ^2
and so  CD_i  vs  i {the old "4-th plot in plot.lm"} is
graphically identical to   R_i^2 vs i.
Now in that case (of identical h_ii's), I think one would really
want  "R_i  vs  i".

Question to the interested parties:

  Should there be an automatism
	 ``when h_ii == const''  {"==" with a bit of numerical fuzz}
  plot a)  R_i   vs i
  or   b)  CD_i  vs i

or should users have to manually use
    plot(<lm>,  which=1:4, ...)
in such a case?

Feedback very welcome, 
particularly, you first look at the examples in help(plot.lm) 
in *R-devel* aka R-2.2.0 alpha.

Martin Maechler, ETH Zurich


From murdoch at stats.uwo.ca  Tue Sep 13 19:28:52 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 13 Sep 2005 13:28:52 -0400
Subject: [Rd] Copying libraries from one version of R to another (was
 Re: MikTeX will be assumed in R 2.2.0 in Windows)
In-Reply-To: <971536df050909191141274448@mail.gmail.com>
References: <43223809.7000306@stats.uwo.ca>
	<971536df050909191141274448@mail.gmail.com>
Message-ID: <43270C54.9070303@stats.uwo.ca>

On 9/9/2005 10:11 PM, Gabor Grothendieck wrote:
> On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> I've just committed some changes to allow R to be built and to use
>> MikTeX without needing the Rd.sty files to be installed to localtexmf.
>> Unfortunately, the changes are not compatible with other TeX packages,
>> so if you're not using MikTeX you'll need to edit a couple of the config
>> files (or set an environment variable).
>> 
>> I'd appreciate hearing of any problems during the alpha or beta test period.
>> 
>> A binary build containing the changes should be on CRAN tomorrow or the
>> next day.  Look for revision 35546 or higher.
> 
> The above improvement was one of the key things one had to look out
> for in installing R that was not already covered in the R setup procedure.
> 
> The other one is to copy the libraries from your old R version to your
> new one (unless you want to share libraries among versions).  I have
> a batch file in the devel version of batchfiles to do that but if this were
> made part of the installation procedure I could eliminate it or if it
> were included it would be much less necessary.

I've just committed a change to the installer that partially addresses 
this.  Now, when a user does an install, the installer records the 
version number and path in the registry.  This way you can have multiple 
versions installed at once and there's a well-defined way to find them. 
  (Well, there will be as soon as we've had time to release multiple 
versions that do this.)

There's also a bit more help for non-admins to do
installs.  So an admin who installs just one copy of R will have
something like this in their registry:

[HKEY_LOCAL_MACHINE\SOFTWARE\R-core]

[HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R]
"InstallPath"="F:\\R\\R-2.2.0alpha"
"Current Version"="2.2.0 alpha"

[HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R\2.2.0 alpha]
"InstallPath"="F:\\R\\R-2.2.0alpha"

while a non-admin will get just this:

[HKEY_CURRENT_USER\Software\R-core]

[HKEY_CURRENT_USER\Software\R-core\R]

[HKEY_CURRENT_USER\Software\R-core\R\2.2.0 alpha]
"InstallPath"="C:\\Documents and Settings\\test\\My
Documents\\R\\R-2.2.0alpha"

If you want to see previously installed versions, you should search 
through HKEY_CURRENT_USER\Software\R-core\R and 
HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R to see what's there.

This went in to revision 35562 a few minutes ago; I'm not sure how long 
it will take to propagate to the alpha tarball and to the build on CRAN.

Duncan Murdoch


From ggrothendieck at gmail.com  Tue Sep 13 19:55:19 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 13 Sep 2005 13:55:19 -0400
Subject: [Rd] Copying libraries from one version of R to another (was
	Re: MikTeX will be assumed in R 2.2.0 in Windows)
In-Reply-To: <43270C54.9070303@stats.uwo.ca>
References: <43223809.7000306@stats.uwo.ca>
	<971536df050909191141274448@mail.gmail.com>
	<43270C54.9070303@stats.uwo.ca>
Message-ID: <971536df0509131055675fe24d@mail.gmail.com>

Thanks. That's great.  If I understand correctly, versions that
are as of the one you just uploaded will have this facility and for older
versions I need to search in the old, existing, way.  Thus once 2.3, say,
comes out we will have 2.2. and 2.3 in the registry.

That means that as of 2.3 it will be possible to have an R program
that checks for the older versions via the registry and redownloads everything
from CRAN to the new version.  It would be important that that
program is distributed with R and possibly invoked automatically
as part of the installation process since its best not to have
to install a package in order to install package.  I assume you
will be doing that by that time so I can probably don't need to
provide anything in batchfiles.  Maybe I
should just hold off on this area since it hardly seems worthwihle to do 
development whose lifespan is just one version.

By the way I did find a tool, sigcheck.exe, on sysinternals.com
that will find the file and product versions and running it on RGui.exe
it does work.  I am considering whether to use that or not to
Rversions.hta.

Regards.


On 9/13/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 9/9/2005 10:11 PM, Gabor Grothendieck wrote:
> > On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> I've just committed some changes to allow R to be built and to use
> >> MikTeX without needing the Rd.sty files to be installed to localtexmf.
> >> Unfortunately, the changes are not compatible with other TeX packages,
> >> so if you're not using MikTeX you'll need to edit a couple of the config
> >> files (or set an environment variable).
> >>
> >> I'd appreciate hearing of any problems during the alpha or beta test period.
> >>
> >> A binary build containing the changes should be on CRAN tomorrow or the
> >> next day.  Look for revision 35546 or higher.
> >
> > The above improvement was one of the key things one had to look out
> > for in installing R that was not already covered in the R setup procedure.
> >
> > The other one is to copy the libraries from your old R version to your
> > new one (unless you want to share libraries among versions).  I have
> > a batch file in the devel version of batchfiles to do that but if this were
> > made part of the installation procedure I could eliminate it or if it
> > were included it would be much less necessary.
> 
> I've just committed a change to the installer that partially addresses
> this.  Now, when a user does an install, the installer records the
> version number and path in the registry.  This way you can have multiple
> versions installed at once and there's a well-defined way to find them.
>  (Well, there will be as soon as we've had time to release multiple
> versions that do this.)
> 
> There's also a bit more help for non-admins to do
> installs.  So an admin who installs just one copy of R will have
> something like this in their registry:
> 
> [HKEY_LOCAL_MACHINE\SOFTWARE\R-core]
> 
> [HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R]
> "InstallPath"="F:\\R\\R-2.2.0alpha"
> "Current Version"="2.2.0 alpha"
> 
> [HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R\2.2.0 alpha]
> "InstallPath"="F:\\R\\R-2.2.0alpha"
> 
> while a non-admin will get just this:
> 
> [HKEY_CURRENT_USER\Software\R-core]
> 
> [HKEY_CURRENT_USER\Software\R-core\R]
> 
> [HKEY_CURRENT_USER\Software\R-core\R\2.2.0 alpha]
> "InstallPath"="C:\\Documents and Settings\\test\\My
> Documents\\R\\R-2.2.0alpha"
> 
> If you want to see previously installed versions, you should search
> through HKEY_CURRENT_USER\Software\R-core\R and
> HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R to see what's there.
> 
> This went in to revision 35562 a few minutes ago; I'm not sure how long
> it will take to propagate to the alpha tarball and to the build on CRAN.
> 
> Duncan Murdoch
>


From W.E.Wolski at newcastle.ac.uk  Tue Sep 13 20:26:18 2005
From: W.E.Wolski at newcastle.ac.uk (nwew)
Date: Tue, 13 Sep 2005 19:26:18 +0100
Subject: [Rd] NUMERIC_POINTER question
Message-ID: <43161F2B@webmail.ncl.ac.uk>

Dear R-developers,

Using .Call I pass a S4 class with e.g. the following class definition:

setClass("mmatrix",representation(
   data="matrix")
)

On the "C side" i do
mat = GET_SLOT(vs,install("data"));
and then:
printf("%f\n",NUMERIC_POINTER(mat)[1]);


The above print statement produces the correct output if 
xx<- new("mmatrix")
xx at data<-matrix(1:12+0.1,3,4). (data is double)

However it prints 
0.0000 
if xx at data are integers ( xx at data<-matrix(1:12,3,4) ).

Can anyone explain it to me why? 
I thought that NUMERIC_POINTER makes it clear that i expect datatype numeric.
(Why otherwise the distinction with INTEGER_POINTER)


cheers
Eryk


From murdoch at stats.uwo.ca  Tue Sep 13 20:26:22 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 13 Sep 2005 14:26:22 -0400
Subject: [Rd] Copying libraries from one version of R to another (was
 Re: MikTeX will be assumed in R 2.2.0 in Windows)
In-Reply-To: <971536df0509131055675fe24d@mail.gmail.com>
References: <43223809.7000306@stats.uwo.ca>	
	<971536df050909191141274448@mail.gmail.com>	
	<43270C54.9070303@stats.uwo.ca>
	<971536df0509131055675fe24d@mail.gmail.com>
Message-ID: <432719CE.9020005@stats.uwo.ca>

On 9/13/2005 1:55 PM, Gabor Grothendieck wrote:
> Thanks. That's great.  If I understand correctly, versions that
> are as of the one you just uploaded will have this facility and for older
> versions I need to search in the old, existing, way.  Thus once 2.3, say,
> comes out we will have 2.2. and 2.3 in the registry.
> 
> That means that as of 2.3 it will be possible to have an R program
> that checks for the older versions via the registry and redownloads everything
> from CRAN to the new version.  

Probably even sooner than that -- 2.2.1 will be recorded as a different 
version than 2.2.0.

> It would be important that that
> program is distributed with R and possibly invoked automatically
> as part of the installation process since its best not to have
> to install a package in order to install package.  I assume you
> will be doing that by that time so I can probably don't need to
> provide anything in batchfiles.  Maybe I
> should just hold off on this area since it hardly seems worthwihle to do 
> development whose lifespan is just one version.

It's probably not a good idea to assume that I'll do it :-).  Putting 
together a simple package that does this would be nice, and would be 
available sooner than 2.3.0.

Duncan Murdoch

> By the way I did find a tool, sigcheck.exe, on sysinternals.com
> that will find the file and product versions and running it on RGui.exe
> it does work.  I am considering whether to use that or not to
> Rversions.hta.
> 
> Regards.
> 
> 
> On 9/13/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 9/9/2005 10:11 PM, Gabor Grothendieck wrote:
>> > On 9/9/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> >> I've just committed some changes to allow R to be built and to use
>> >> MikTeX without needing the Rd.sty files to be installed to localtexmf.
>> >> Unfortunately, the changes are not compatible with other TeX packages,
>> >> so if you're not using MikTeX you'll need to edit a couple of the config
>> >> files (or set an environment variable).
>> >>
>> >> I'd appreciate hearing of any problems during the alpha or beta test period.
>> >>
>> >> A binary build containing the changes should be on CRAN tomorrow or the
>> >> next day.  Look for revision 35546 or higher.
>> >
>> > The above improvement was one of the key things one had to look out
>> > for in installing R that was not already covered in the R setup procedure.
>> >
>> > The other one is to copy the libraries from your old R version to your
>> > new one (unless you want to share libraries among versions).  I have
>> > a batch file in the devel version of batchfiles to do that but if this were
>> > made part of the installation procedure I could eliminate it or if it
>> > were included it would be much less necessary.
>> 
>> I've just committed a change to the installer that partially addresses
>> this.  Now, when a user does an install, the installer records the
>> version number and path in the registry.  This way you can have multiple
>> versions installed at once and there's a well-defined way to find them.
>>  (Well, there will be as soon as we've had time to release multiple
>> versions that do this.)
>> 
>> There's also a bit more help for non-admins to do
>> installs.  So an admin who installs just one copy of R will have
>> something like this in their registry:
>> 
>> [HKEY_LOCAL_MACHINE\SOFTWARE\R-core]
>> 
>> [HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R]
>> "InstallPath"="F:\\R\\R-2.2.0alpha"
>> "Current Version"="2.2.0 alpha"
>> 
>> [HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R\2.2.0 alpha]
>> "InstallPath"="F:\\R\\R-2.2.0alpha"
>> 
>> while a non-admin will get just this:
>> 
>> [HKEY_CURRENT_USER\Software\R-core]
>> 
>> [HKEY_CURRENT_USER\Software\R-core\R]
>> 
>> [HKEY_CURRENT_USER\Software\R-core\R\2.2.0 alpha]
>> "InstallPath"="C:\\Documents and Settings\\test\\My
>> Documents\\R\\R-2.2.0alpha"
>> 
>> If you want to see previously installed versions, you should search
>> through HKEY_CURRENT_USER\Software\R-core\R and
>> HKEY_LOCAL_MACHINE\SOFTWARE\R-core\R to see what's there.
>> 
>> This went in to revision 35562 a few minutes ago; I'm not sure how long
>> it will take to propagate to the alpha tarball and to the build on CRAN.
>> 
>> Duncan Murdoch
>>


From Roger.Bivand at nhh.no  Tue Sep 13 20:37:40 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 13 Sep 2005 20:37:40 +0200 (CEST)
Subject: [Rd] NUMERIC_POINTER question
In-Reply-To: <43161F2B@webmail.ncl.ac.uk>
Message-ID: <Pine.LNX.4.44.0509132033420.28550-100000@reclus.nhh.no>

On Tue, 13 Sep 2005, nwew wrote:

> Dear R-developers,
> 
> Using .Call I pass a S4 class with e.g. the following class definition:
> 
> setClass("mmatrix",representation(
>    data="matrix")
> )
> 
> On the "C side" i do
> mat = GET_SLOT(vs,install("data"));
> and then:
> printf("%f\n",NUMERIC_POINTER(mat)[1]);
> 
> 
> The above print statement produces the correct output if 
> xx<- new("mmatrix")
> xx at data<-matrix(1:12+0.1,3,4). (data is double)
> 
> However it prints 
> 0.0000 
> if xx at data are integers ( xx at data<-matrix(1:12,3,4) ).
> 
> Can anyone explain it to me why? 
> I thought that NUMERIC_POINTER makes it clear that i expect datatype numeric.
> (Why otherwise the distinction with INTEGER_POINTER)

No, I think you have to make sure that the bits are in the correct mode. 
Could you use validation at the new() to do it? A matrix could be double, 
integer, logical or character at least, but on the C side you only want 
double. I don't think expectations come into it.

Roger

> 
> 
> cheers
> Eryk
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From simon.urbanek at r-project.org  Tue Sep 13 20:44:13 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 13 Sep 2005 14:44:13 -0400
Subject: [Rd] NUMERIC_POINTER question
In-Reply-To: <43161F2B@webmail.ncl.ac.uk>
References: <43161F2B@webmail.ncl.ac.uk>
Message-ID: <3D7CA27B-5BD2-41AD-BBF8-151D33E00486@r-project.org>

Eryk,

On Sep 13, 2005, at 2:26 PM, nwew wrote:

> printf("%f\n",NUMERIC_POINTER(mat)[1]);
> [...]
> However it prints
> 0.0000
> if xx at data are integers ( xx at data<-matrix(1:12,3,4) ).
>
> Can anyone explain it to me why?
> I thought that NUMERIC_POINTER makes it clear that i expect  
> datatype numeric.
> (Why otherwise the distinction with INTEGER_POINTER)

You answered your own question - NUMERIC_POINTER expects that the  
SEXP you pass to it is numeric=double. When you use it, it's your  
responsibility to make sure that the SEXP is numeric and not integer  
or anything else. Probably you may want to use AS_NUMERIC to ensure  
that. [btw: NUMERIC_POINTER() is a compatibility macro for REAL() and  
AS_NUMERIC(x) for coerceVector(x,REALSXP)].

Also you should be aware that C uses 0-based indices so  
NUMERIC_POINTER(mat)[1] accesses the 2nd element of the vector.

Cheers,
Simon


From reid_huntsinger at merck.com  Tue Sep 13 20:43:33 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 13 Sep 2005 14:43:33 -0400
Subject: [Rd] NUMERIC_POINTER question
Message-ID: <355C35514FEAC9458F75947F5270974D076CC7@usctmx1103.merck.com>

You have to coerce to numeric yourself if that's what you want. Eg in the R
code, as.numeric(1:12) rather than 1:12. Or check the type first in C with
TYPEOF before doing NUMERIC_POINTER or INTEGER_POINTER (the difference is
that the two do different casts; they both point a fixed offset into the R
data structure and I'm not sure if there's a guarantee that this offset
needs to be the same, so perhaps the two don't even point to the same
location...).

Reid Huntsinger

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of nwew
Sent: Tuesday, September 13, 2005 2:26 PM
To: r-devel
Subject: [Rd] NUMERIC_POINTER question


Dear R-developers,

Using .Call I pass a S4 class with e.g. the following class definition:

setClass("mmatrix",representation(
   data="matrix")
)

On the "C side" i do
mat = GET_SLOT(vs,install("data"));
and then:
printf("%f\n",NUMERIC_POINTER(mat)[1]);


The above print statement produces the correct output if 
xx<- new("mmatrix")
xx at data<-matrix(1:12+0.1,3,4). (data is double)

However it prints 
0.0000 
if xx at data are integers ( xx at data<-matrix(1:12,3,4) ).

Can anyone explain it to me why? 
I thought that NUMERIC_POINTER makes it clear that i expect datatype
numeric.
(Why otherwise the distinction with INTEGER_POINTER)


cheers
Eryk

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From whit at twinfieldscapital.com  Tue Sep 13 21:55:22 2005
From: whit at twinfieldscapital.com (Whit Armstrong)
Date: Tue, 13 Sep 2005 15:55:22 -0400
Subject: [Rd] possible bug in model.matrix
Message-ID: <726FC6DD09DE1046AF81B499D70C3BCE2C8623@twinfields02.CORP.TWINFIELDSCAPITAL.COM>

Is this a bug, or have I misunderstood the proper use of lm?

Thanks,
Whit


code:
x <- rnorm(50)
y <- matrix(as.logical(round(runif(100),0)),ncol=2)
NROW(x)==NROW(y)
lm(x~y)



> x <- rnorm(50)
> y <- matrix(as.logical(round(runif(100),0)),ncol=2)
> NROW(x)==NROW(y)
[1] TRUE
> lm(x~y)
Error in "[[<-.data.frame"(`*tmp*`, nn, value = c(2, 1, 2, 1, 1, 1, 2,
:
        replacement has 100 rows, data has 50
>


However, the call to lm works if the matrix is a numeric instead of
logical:
x <- rnorm(50)
y <- matrix(runif(100),ncol=2)
NROW(x)==NROW(y)
lm(x~y)


Seems to be a problem in model.matrix.default:

debug: for (nn in namD[isF]) if (is.null(attr(data[[nn]], "contrasts")))
contrasts(data[[nn]]) <- contr.funs[1 +
    isOF[nn]]
Browse[1]>
Error in "[[<-.data.frame"(`*tmp*`, nn, value = c(1, 2, 2, 2, 2, 2, 2,
:
        replacement has 100 rows, data has 50
>


> R.Version()
$platform
[1] "i686-pc-linux-gnu"

$arch
[1] "i686"

$os
[1] "linux-gnu"

$system
[1] "i686, linux-gnu"

$status
[1] "alpha"

$major
[1] "2"

$minor
[1] "2.0"

$year
[1] "2005"

$month
[1] "09"

$day
[1] "12"

$"svn rev"
[1] "35558"

$language
[1] "R"

>


From p.dalgaard at biostat.ku.dk  Tue Sep 13 22:37:10 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Sep 2005 22:37:10 +0200
Subject: [Rd] possible bug in model.matrix
In-Reply-To: <726FC6DD09DE1046AF81B499D70C3BCE2C8623@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
References: <726FC6DD09DE1046AF81B499D70C3BCE2C8623@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
Message-ID: <x2y860puvd.fsf@turmalin.kubism.ku.dk>

"Whit Armstrong" <whit at twinfieldscapital.com> writes:

> Is this a bug, or have I misunderstood the proper use of lm?

Dunno. It appears that logicals like factors are not supposed to have
matrix structure. What actually happens is that setting contrasts
strips dimension attributes
 
Browse[1]>
debug: for (nn in namD[isF]) if (is.null(attr(data[[nn]], "contrasts"))) contrasts(data[[nn]]) <- contr.funs[1 +
    isOF[nn]]
Browse[1]> zz <- data[["y"]]
Browse[1]> contrasts(zz) <-  contrasts(zz)
Browse[1]> zz
  [1] TRUE  TRUE  TRUE  FALSE TRUE  TRUE  TRUE  TRUE  TRUE  FALSE TRUE FALSE
 [13] FALSE TRUE  TRUE  TRUE  FALSE TRUE  FALSE TRUE  TRUE  FALSE FALSE TRUE
 [25] TRUE  TRUE  FALSE FALSE FALSE FALSE TRUE  FALSE FALSE TRUE  TRUE FALSE
 [37] FALSE FALSE FALSE TRUE  TRUE  TRUE  TRUE  FALSE FALSE FALSE TRUE
..
 [85] TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  FALSE TRUE  TRUE  TRUE  TRUE
 [97] TRUE  TRUE  TRUE  FALSE
Levels: FALSE TRUE
 
which in turn comes from

if (is.logical(x)) x <- factor(x, levels = c(FALSE, TRUE))

and the fact that factor() throws away dimensions.

*If* it's a bug, I don't think it is easily fixable....

> Thanks,
> Whit
> 
> 
> code:
> x <- rnorm(50)
> y <- matrix(as.logical(round(runif(100),0)),ncol=2)
> NROW(x)==NROW(y)
> lm(x~y)
> 
> 
> 
> > x <- rnorm(50)
> > y <- matrix(as.logical(round(runif(100),0)),ncol=2)
> > NROW(x)==NROW(y)
> [1] TRUE
> > lm(x~y)
> Error in "[[<-.data.frame"(`*tmp*`, nn, value = c(2, 1, 2, 1, 1, 1, 2,
> :
>         replacement has 100 rows, data has 50
> >
> 
> 
> However, the call to lm works if the matrix is a numeric instead of
> logical:
> x <- rnorm(50)
> y <- matrix(runif(100),ncol=2)
> NROW(x)==NROW(y)
> lm(x~y)
> 
> 
> Seems to be a problem in model.matrix.default:
> 
> debug: for (nn in namD[isF]) if (is.null(attr(data[[nn]], "contrasts")))
> contrasts(data[[nn]]) <- contr.funs[1 +
>     isOF[nn]]
> Browse[1]>
> Error in "[[<-.data.frame"(`*tmp*`, nn, value = c(1, 2, 2, 2, 2, 2, 2,
> :
>         replacement has 100 rows, data has 50
> >
> 
> 
> > R.Version()
> $platform
> [1] "i686-pc-linux-gnu"
> 
> $arch
> [1] "i686"
> 
> $os
> [1] "linux-gnu"
> 
> $system
> [1] "i686, linux-gnu"
> 
> $status
> [1] "alpha"
> 
> $major
> [1] "2"
> 
> $minor
> [1] "2.0"
> 
> $year
> [1] "2005"
> 
> $month
> [1] "09"
> 
> $day
> [1] "12"
> 
> $"svn rev"
> [1] "35558"
> 
> $language
> [1] "R"
> 
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jfox at mcmaster.ca  Tue Sep 13 22:41:28 2005
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 13 Sep 2005 16:41:28 -0400
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <17190.57225.254938.977464@stat.math.ethz.ch>
Message-ID: <20050913204127.HZDY26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Martin,

A couple of comments on the new plots (numbers 5 and 6): Perhaps some more
thought could be given to the plotted contours for Cook's D (which are 0.5
and 1.0 in the example -- large Cook's Ds). A rule-of-thumb cut-off for this
example is 4/(n - p) = 4/(50 - 5) = 0.089, and the discrepancy will grow
with n. I'm not terribly fond of number 6, since it seems natural to me to
think of the relationship among these quantities as influence on
coefficients = leverage * outlyingness (which corresponds to 5); also note
how in the example, the labels for large residuals overplot. Finally, your
remarks about balanced data are cogent and suggest going with 1:3 in this
case (since R_i vs. i is pretty redundant with the QQ plot). 

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
> Sent: Tuesday, September 13, 2005 9:18 AM
> To: R-devel at stat.math.ethz.ch
> Cc: John Maindonald; Werner Stahel; John Fox
> Subject: plot(<lm>): new behavior in R-2.2.0 alpha
> 
> As some of you R-devel readers may know, the plot() method 
> for "lm" objects is based in large parts on contributions by 
> John Maindonald, subsequently "massaged" by me and other 
> R-core members.
> 
> In the statistics litterature on applied regression, people 
> have had  diverse oppinions on what (and how many!) plots 
> should be used for goodness-of-fit / residual diagnostics, 
> and to my knowledge most people have agreed to want to see 
> one (or more) version of a Tukey-Anscombe plot {Residuals ~ 
> Fitted} and a QQ normal plot.
> Another consideration was to be somewhat close to what S
> (S-plus) was doing.  So we have two versions of residuals vs 
> fitted, one for checking  E[error] = 0, the other for 
> checking Var[error] = constant.  So we got to the first three plots of
> plot.lm() about which I don't want to debate at the moment 
> {though, there's room for improvement even there: e.g., I 
> know of at  least one case where plot(<lm>) wasn't used 
> because the user  was missing the qqline() she was so used to 
> in the QQ plot}
> 
> The topic of this e-mail is the (default) 4th plot which I 
> had changed; really prompted by the following:
> More than three months ago, John wrote
>   http://tolstoy.newcastle.edu.au/R/devel/05/04/0594.html
>     (which became a thread of about 20 messages, from Apr.23 
> -- 29, 2005)
> 
> and currently,
> NEWS for R 2.2.0 alpha contains
> 
> >> USER-VISIBLE CHANGES
> >> 
> >>    o plot(<lm object>) uses a new default for the fourth panel when
> >>      'which' is not specified.
> >>      ___ may change before release ___
> 
> and the header is
> 
> plot.lm <-
> function (x, which = c(1:3, 5), 
>           caption = c("Residuals vs Fitted", 
> 	              "Normal Q-Q", "Scale-Location", 
> 		      "Cook's distance", "Residuals vs Leverage", 
> 		      "Cook's distance vs Leverage"), 
> 	   ......... ) {..............}
> 
> So we now have 6 possible plots, where 1,2,3 and 5 are the 
> defaults (and 1,2,3,4 where the old defaults).
> 
> For the influential points and combination of 'influential' 
> and 'outlier'
> there have been quite a few more proposals in the past. R <= 
> 2.1.x has been plotting the  Cook's distances vs. observation 
> number, whereas quite a few people in the past have noted 
> that all influence measures being more or less complicated 
> functions of residuals and "hat values" aka "leverages", 
> (R_i, h_{ii}), it would really make sense and fit more to the 
> other plots to plot residuals vs. Leverages --- with the 
> additional idea of adding *contours* of (equal) Cook's 
> distances to that plot, in case one would really want to seem them.
> 
> In the mean time, this has been *active* in R-devel for quite 
> a while, and we haven't received any new comments.
> 
> One remaining problem I'd like to address is the "balanced AOV"
> situation, something probably pretty rare nowadays in real 
> practice, but common of course in teaching ANOVA.
> As you may remember, in a balanced design, all observations 
> have the same leverages h_{ii}, and the plot  R_i  vs  h_ii 
> is really not so useful.  In that case,  the cook distances 
> CD_i = c *  R_i ^2 and so  CD_i  vs  i {the old "4-th plot in 
> plot.lm"} is
> graphically identical to   R_i^2 vs i.
> Now in that case (of identical h_ii's), I think one would 
> really want  "R_i  vs  i".
> 
> Question to the interested parties:
> 
>   Should there be an automatism
> 	 ``when h_ii == const''  {"==" with a bit of numerical fuzz}
>   plot a)  R_i   vs i
>   or   b)  CD_i  vs i
> 
> or should users have to manually use
>     plot(<lm>,  which=1:4, ...)
> in such a case?
> 
> Feedback very welcome,
> particularly, you first look at the examples in help(plot.lm) 
> in *R-devel* aka R-2.2.0 alpha.
> 
> Martin Maechler, ETH Zurich
> 
>


From ben.bob at gmail.com  Wed Sep 14 03:38:01 2005
From: ben.bob at gmail.com (Bo Peng)
Date: Tue, 13 Sep 2005 18:38:01 -0700
Subject: [Rd] as.Date() , feature or bug?
Message-ID: <6ea7b543050913183858e052f4@mail.gmail.com>

Under linux and windows,

> as.Date("6666-06-06")
[1] "6666-06-06"
> as.Date("7777-07-07")
[1] "1970-01-01"
> 

Feature? Bug? help(as.Date) does not mention this case.

Bo.


From john.maindonald at anu.edu.au  Wed Sep 14 08:09:06 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 14 Sep 2005 16:09:06 +1000
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <17190.57225.254938.977464@stat.math.ethz.ch>
References: <17190.57225.254938.977464@stat.math.ethz.ch>
Message-ID: <81A1F734-F502-4D4E-9C73-D59CB11EF010@anu.edu.au>

Following the >20 messages that Martin mentioned, I had
private discussion with John Fox, which in part lies behind
following questions:

(1) In plot 5, should we have, maybe as an option, vertical
lines at 2hbar and 3hbar, as in the plots produced by the
function that John Fox sent me.  I think this would be a useful
addition, but made no move to add it at that time, considering
it best to put that on a toThink About list.

(2) John also sent code for a plot that place contours of the
covratio on the points that are shown in plot 5.  This could
be added as an option to plot 5.
(The covratio statistic is a measure of the effect of omitting a
point on the variance-covariance matrix.  It is a function of
the residual and the leverage.)  Also there is the possibility
(I am not keen on this) to show Bonferroni critical values for
studentized residuals.

(3) My reaction to the new plot 6 (David Firth's proposal) is
sufficiently similar to John Fox's that I would not use it as a
matter of course.  I think it useful however, precisely because
it does offer a perspective on the information in plot 5 that
is, at first look, startlingly different.

(4) Are there other diagnostics that ought to be included in
stats? (perhaps in a function other than plot.lm(), which risks
being overloaded).  One strong claiment is vif() (variance
inflation factor), of which there are versions both in car and
(written by myself) in DAAG.  John Fox's function does more
than mine.  Thus, assuming that he is willing for it to be taken
across, that should go into stats.

(5) termplot() provides partial residual (component + residual)
plots, which I think extraordinarily useful.  They deserve to be
widely used.
Should partial regression plots also be available?

(6) It should be fairly easy to construct a function that would
examine the distribution of statistics of interest under repeated
bootstrap sampling or simulation.  This can be useful when
with small samples, when it is easy to over-interpret diagnostic
statistics.

(7) There are special issues, not just for aov models, but also
for glm() and (extending the discussion quite a lot) the models
that are fitted by lme()/lmer() [nlme/lme4].

(8) Are there special issues that require attention for large
datasets? [I'm sure there are, but regression diagnostics may
not be the best point of entry into the discussion.]

(9) How about a help(Diagnostics) entry?

(10) Maybe it would be useful to form a (small?) group to look at
what should go into:
  (a) stats
  (b) a specialist diagnostics package
Even if this idea is taken up, some preliminary wider canvassing
of the opinions of members of this list seems desirable.

John Maindonald.


On 14 Sep 2005, at 12:17 AM, Martin Maechler wrote:

> As some of you R-devel readers may know, the plot() method for
> "lm" objects is based in large parts on contributions by John
> Maindonald, subsequently "massaged" by me and other R-core
> members.
>
> In the statistics litterature on applied regression, people have
> had  diverse oppinions on what (and how many!) plots should be
> used for goodness-of-fit / residual diagnostics, and to my
> knowledge most people have agreed to want to see one (or more)
> version of a Tukey-Anscombe plot {Residuals ~ Fitted} and a QQ
> normal plot.
> Another consideration was to be somewhat close to what S
> (S-plus) was doing.  So we have two versions of residuals vs
> fitted, one for checking  E[error] = 0, the other for checking
> Var[error] = constant.  So we got to the first three plots of
> plot.lm() about which I don't want to debate at the moment
> {though, there's room for improvement even there: e.g., I know of at
>  least one case where plot(<lm>) wasn't used because the user
>  was missing the qqline() she was so used to in the QQ plot}
>
> The topic of this e-mail is the (default) 4th plot which I had
> changed; really prompted by the following:
> More than three months ago, John wrote
>   http://tolstoy.newcastle.edu.au/R/devel/05/04/0594.html
>     (which became a thread of about 20 messages, from Apr.23 -- 29,  
> 2005)
>
> and currently,
> NEWS for R 2.2.0 alpha contains
>
>
>>> USER-VISIBLE CHANGES
>>>
>>>    o plot(<lm object>) uses a new default for the fourth panel when
>>>      'which' is not specified.
>>>      ___ may change before release ___
>>>
>
> and the header is
>
> plot.lm <-
> function (x, which = c(1:3, 5),
>           caption = c("Residuals vs Fitted",
>                   "Normal Q-Q", "Scale-Location",
>               "Cook's distance", "Residuals vs Leverage",
>               "Cook's distance vs Leverage"),
>        ......... ) {..............}
>
> So we now have 6 possible plots, where 1,2,3 and 5 are the
> defaults (and 1,2,3,4 where the old defaults).
>
> For the influential points and combination of 'influential' and  
> 'outlier'
> there have been quite a few more proposals in the past. R <= 2.1.x
> has been plotting the  Cook's distances vs. observation number,  
> whereas
> quite a few people in the past have noted that all influence
> measures being more or less complicated functions of residuals
> and "hat values" aka "leverages", (R_i, h_{ii}), it would really
> make sense and fit more to the other plots
> to plot residuals vs. Leverages --- with the additional idea of
> adding *contours* of (equal) Cook's distances to that plot, in
> case one would really want to seem them.
>
> In the mean time, this has been *active* in R-devel for quite a
> while, and we haven't received any new comments.
>
> One remaining problem I'd like to address is the "balanced AOV"
> situation, something probably pretty rare nowadays in real
> practice, but common of course in teaching ANOVA.
> As you may remember, in a balanced design, all observations have
> the same leverages h_{ii}, and the plot  R_i  vs  h_ii is really
> not so useful.  In that case,  the cook distances CD_i = c *  R_i ^2
> and so  CD_i  vs  i {the old "4-th plot in plot.lm"} is
> graphically identical to   R_i^2 vs i.
> Now in that case (of identical h_ii's), I think one would really
> want  "R_i  vs  i".
>
> Question to the interested parties:
>
>   Should there be an automatism
>      ``when h_ii == const''  {"==" with a bit of numerical fuzz}
>   plot a)  R_i   vs i
>   or   b)  CD_i  vs i
>
> or should users have to manually use
>     plot(<lm>,  which=1:4, ...)
> in such a case?
>
> Feedback very welcome,
> particularly, you first look at the examples in help(plot.lm)
> in *R-devel* aka R-2.2.0 alpha.
>
> Martin Maechler, ETH Zurich
>
>

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From jinghuazhao at hotmail.com  Wed Sep 14 10:42:12 2005
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Wed, 14 Sep 2005 08:42:12 +0000
Subject: [Rd] R CMD check
Message-ID: <BAY108-F1811543DA96E6B0E84A85A59F0@phx.gbl>

Dear r-devel members,

I tried to build R packages on a PC running Windows XP but experience 
problems. However, it is ok when there is no inst directory in a package.

Any help would be appreciated.

The following is an example,

C:\work>R CMD check VR_7.2-19.tar.gz
* checking for working latex ... OK
* using log directory 'C:/work/VR.Rcheck'
* using R version 2.1.1, 2005-06-20
* checking for file 'VR/DESCRIPTION' ... OK
* looks like 'VR' is a package bundle
* this is bundle 'VR' version '7.2-19'
* checking if this is a source bundle ... OK

installing R.css in C:/work/VR.Rcheck

Looks like `C:/work/VR.Rcheck/00_pkg_src/VR' is a package bundle


---------- Making package MASS ------------
  adding build stamp to DESCRIPTION
  installing NAMESPACE file and metadata
  making DLL ...
making MASS.d from MASS.c
making lqs.d from lqs.c
gcc   -Ic:/PROGRA~1/r/rw2011/include -Wall -O2   -c MASS.c -o MASS.o
gcc   -Ic:/PROGRA~1/r/rw2011/include -Wall -O2   -c lqs.c -o lqs.o
ar cr MASS.a MASS.o lqs.o
ranlib MASS.a
windres --include-dir c:/PROGRA~1/r/rw2011/include  -i MASS_res.rc -o 
MASS_res.

gcc  --shared -s  -o MASS.dll MASS.def MASS.a MASS_res.o  
-c:/PROGRA~1/r/rw201/src/gnuwin32   -lg2c -lR
  ... DLL made
  installing DLL
  installing R files
  installing inst files
FIND: Parameter format not correct
make[2]: *** [C:/work/VR.Rcheck/MASS/inst] Error 2
make[1]: *** [all] Error 2
make: *** [pkg-MASS] Error 2
*** Installation of MASS failed ***

ERROR
Installation failed.

C:\work> path

PATH=C:\texmf\miktex\bin;C:\Perl\bin\;C:\Program 
Files\Insightful\splus62\;C:\WI
NDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program 
Files\Hummingbird\
Connectivity\9.00\Accessories\;C:\Program Files\Common 
Files\GTK\2.0\bin;C:\Prog
ram Files\WinSCP3\;C:\Program Files\PC-Pine



Jing Hua Zhao


From maechler at stat.math.ethz.ch  Wed Sep 14 10:55:48 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Sep 2005 10:55:48 +0200
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <20050913204127.HZDY26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <17190.57225.254938.977464@stat.math.ethz.ch>
	<20050913204127.HZDY26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <17191.58772.984424.580765@stat.math.ethz.ch>

Thank you, John, for
Dear 
>>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
>>>>>     on Tue, 13 Sep 2005 16:41:28 -0400 writes:

    JohnF> A couple of comments on the new plots (numbers 5 and 6):
    JohnF> Perhaps some more thought could be given to the
    JohnF> plotted contours for Cook's D (which are 0.5 and 1.0
    JohnF> in the example -- large Cook's Ds). A rule-of-thumb
    JohnF> cut-off for this example is 4/(n - p) = 4/(50 - 5) =
    JohnF> 0.089, and the discrepancy will grow with n.

That's an interesting suggestion.  Where does the 4/(n-p) come
from? or put differently, should I better read in of your books? ;-)

Honestly, I'm so much a fan of R_i / h_ii that I didn't even
know that.

    JohnF> I'm not terribly fond of number 6, since it seems
    JohnF> natural to me to think of the relationship among
    JohnF> these quantities as influence on coefficients =
    JohnF> leverage * outlyingness (which corresponds to 5);
    JohnF> also note how in the example, the labels for large
    JohnF> residuals overplot.

I think John mainly proposed '6' because other proposed it as another
good alternative.  From the few examples I've looked at, I
haven't got fond at all either.

    JohnF> Finally, your remarks about balanced data are cogent
    JohnF> and suggest going with 1:3 in this case (since R_i
    JohnF> vs. i is pretty redundant with the QQ plot).

Ah, that's another, maybe better alternative to my proposal.

One drawback of it is for situations where people do something
like   	par(mfrow=c(2,2))
before calling  plot(<lm>) for several fitted lm models,
assuming to fill one page for each of the plots.
and I think that's something I would have done always in such
situations where several different models are fitted and compared.

Maybe plot.lm() should "advance an empty frame" as soon as
 prod(par("mfrow")) >= 4 
in that case?

Martin

    JohnF> --------------------------------
    JohnF> John Fox
    JohnF> Department of Sociology
    JohnF> McMaster University
    JohnF> Hamilton, Ontario
    JohnF> Canada L8S 4M4
    JohnF> 905-525-9140x23604
    JohnF> http://socserv.mcmaster.ca/jfox 
    JohnF> -------------------------------- 

    >> -----Original Message-----
    >> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
    >> Sent: Tuesday, September 13, 2005 9:18 AM
    >> To: R-devel at stat.math.ethz.ch
    >> Cc: John Maindonald; Werner Stahel; John Fox
    >> Subject: plot(<lm>): new behavior in R-2.2.0 alpha
    >> 
    >> As some of you R-devel readers may know, the plot() method 
    >> for "lm" objects is based in large parts on contributions by 
    >> John Maindonald, subsequently "massaged" by me and other 
    >> R-core members.
    >> 
    >> In the statistics litterature on applied regression, people 
    >> have had  diverse oppinions on what (and how many!) plots 
    >> should be used for goodness-of-fit / residual diagnostics, 
    >> and to my knowledge most people have agreed to want to see 
    >> one (or more) version of a Tukey-Anscombe plot {Residuals ~ 
    >> Fitted} and a QQ normal plot.
    >> Another consideration was to be somewhat close to what S
    >> (S-plus) was doing.  So we have two versions of residuals vs 
    >> fitted, one for checking  E[error] = 0, the other for 
    >> checking Var[error] = constant.  So we got to the first three plots of
    >> plot.lm() about which I don't want to debate at the moment 
    >> {though, there's room for improvement even there: e.g., I 
    >> know of at  least one case where plot(<lm>) wasn't used 
    >> because the user  was missing the qqline() she was so used to 
    >> in the QQ plot}
    >> 
    >> The topic of this e-mail is the (default) 4th plot which I 
    >> had changed; really prompted by the following:
    >> More than three months ago, John wrote
    >> http://tolstoy.newcastle.edu.au/R/devel/05/04/0594.html
    >> (which became a thread of about 20 messages, from Apr.23 
    >> -- 29, 2005)
    >> 
    >> and currently,
    >> NEWS for R 2.2.0 alpha contains
    >> 
    >> >> USER-VISIBLE CHANGES
    >> >> 
    >> >>    o plot(<lm object>) uses a new default for the fourth panel when
    >> >>      'which' is not specified.
    >> >>      ___ may change before release ___
    >> 
    >> and the header is
    >> 
    >> plot.lm <-
    >> function (x, which = c(1:3, 5), 
    >> caption = c("Residuals vs Fitted", 
    >> "Normal Q-Q", "Scale-Location", 
    >> "Cook's distance", "Residuals vs Leverage", 
    >> "Cook's distance vs Leverage"), 
    >> ......... ) {..............}
    >> 
    >> So we now have 6 possible plots, where 1,2,3 and 5 are the 
    >> defaults (and 1,2,3,4 where the old defaults).
    >> 
    >> For the influential points and combination of 'influential' 
    >> and 'outlier'
    >> there have been quite a few more proposals in the past. R <= 
    >> 2.1.x has been plotting the  Cook's distances vs. observation 
    >> number, whereas quite a few people in the past have noted 
    >> that all influence measures being more or less complicated 
    >> functions of residuals and "hat values" aka "leverages", 
    >> (R_i, h_{ii}), it would really make sense and fit more to the 
    >> other plots to plot residuals vs. Leverages --- with the 
    >> additional idea of adding *contours* of (equal) Cook's 
    >> distances to that plot, in case one would really want to seem them.
    >> 
    >> In the mean time, this has been *active* in R-devel for quite 
    >> a while, and we haven't received any new comments.
    >> 
    >> One remaining problem I'd like to address is the "balanced AOV"
    >> situation, something probably pretty rare nowadays in real 
    >> practice, but common of course in teaching ANOVA.
    >> As you may remember, in a balanced design, all observations 
    >> have the same leverages h_{ii}, and the plot  R_i  vs  h_ii 
    >> is really not so useful.  In that case,  the cook distances 
    >> CD_i = c *  R_i ^2 and so  CD_i  vs  i {the old "4-th plot in 
    >> plot.lm"} is
    >> graphically identical to   R_i^2 vs i.
    >> Now in that case (of identical h_ii's), I think one would 
    >> really want  "R_i  vs  i".
    >> 
    >> Question to the interested parties:
    >> 
    >> Should there be an automatism
    >> ``when h_ii == const''  {"==" with a bit of numerical fuzz}
    >> plot a)  R_i   vs i
    >> or   b)  CD_i  vs i
    >> 
    >> or should users have to manually use
    >> plot(<lm>,  which=1:4, ...)
    >> in such a case?
    >> 
    >> Feedback very welcome,
    >> particularly, you first look at the examples in help(plot.lm) 
    >> in *R-devel* aka R-2.2.0 alpha.
    >> 
    >> Martin Maechler, ETH Zurich


From murdoch at stats.uwo.ca  Wed Sep 14 13:04:57 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 14 Sep 2005 07:04:57 -0400
Subject: [Rd] R CMD check
In-Reply-To: <BAY108-F1811543DA96E6B0E84A85A59F0@phx.gbl>
References: <BAY108-F1811543DA96E6B0E84A85A59F0@phx.gbl>
Message-ID: <432803D9.3080103@stats.uwo.ca>

jing hua zhao wrote:
> Dear r-devel members,
> 
> I tried to build R packages on a PC running Windows XP but experience 
> problems. However, it is ok when there is no inst directory in a package.
> 
> Any help would be appreciated.
> 
> The following is an example,
> 
> C:\work>R CMD check VR_7.2-19.tar.gz
> * checking for working latex ... OK
> * using log directory 'C:/work/VR.Rcheck'
> * using R version 2.1.1, 2005-06-20
> * checking for file 'VR/DESCRIPTION' ... OK
> * looks like 'VR' is a package bundle
> * this is bundle 'VR' version '7.2-19'
> * checking if this is a source bundle ... OK
> 
> installing R.css in C:/work/VR.Rcheck
> 
> Looks like `C:/work/VR.Rcheck/00_pkg_src/VR' is a package bundle
> 
> 
> ---------- Making package MASS ------------
>   adding build stamp to DESCRIPTION
>   installing NAMESPACE file and metadata
>   making DLL ...
> making MASS.d from MASS.c
> making lqs.d from lqs.c
> gcc   -Ic:/PROGRA~1/r/rw2011/include -Wall -O2   -c MASS.c -o MASS.o
> gcc   -Ic:/PROGRA~1/r/rw2011/include -Wall -O2   -c lqs.c -o lqs.o
> ar cr MASS.a MASS.o lqs.o
> ranlib MASS.a
> windres --include-dir c:/PROGRA~1/r/rw2011/include  -i MASS_res.rc -o 
> MASS_res.
> 
> gcc  --shared -s  -o MASS.dll MASS.def MASS.a MASS_res.o  
> -c:/PROGRA~1/r/rw201/src/gnuwin32   -lg2c -lR
>   ... DLL made
>   installing DLL
>   installing R files
>   installing inst files
> FIND: Parameter format not correct

Looks like a path problem.  There's a find command in the R tools, and a 
completely different one in Windows.  You need to set your path to find 
the R one first.

Duncan Murdoch

> make[2]: *** [C:/work/VR.Rcheck/MASS/inst] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-MASS] Error 2
> *** Installation of MASS failed ***
> 
> ERROR
> Installation failed.
> 
> C:\work> path
> 
> PATH=C:\texmf\miktex\bin;C:\Perl\bin\;C:\Program 
> Files\Insightful\splus62\;C:\WI
> NDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program 
> Files\Hummingbird\
> Connectivity\9.00\Accessories\;C:\Program Files\Common 
> Files\GTK\2.0\bin;C:\Prog
> ram Files\WinSCP3\;C:\Program Files\PC-Pine
> 
> 
> 
> Jing Hua Zhao
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.uni-dortmund.de  Wed Sep 14 14:18:55 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Sep 2005 14:18:55 +0200
Subject: [Rd] as.Date() , feature or bug?
In-Reply-To: <6ea7b543050913183858e052f4@mail.gmail.com>
References: <6ea7b543050913183858e052f4@mail.gmail.com>
Message-ID: <4328152F.9060705@statistik.uni-dortmund.de>

Bo Peng wrote:

> Under linux and windows,
> 
> 
>>as.Date("6666-06-06")
> 
> [1] "6666-06-06"
> 
>>as.Date("7777-07-07")
> 
> [1] "1970-01-01"
> 
> 
> Feature? Bug? help(as.Date) does not mention this case.

Well, bug, if you really want to call it a bug that you cannot represent 
the year 6666. ;-)

I guess this is some overflow in do_POSIXlt2D that is not protected 
against misuse. Don't see the point right now, I have to admit.


 > as.Date("6970-12-31")
[1] "6970-12-31"
 > as.Date("6971-01-01")
[1] "1970-01-01"


So we cannot represent more than 5000 years into the future, roughly 
speaking. *Guess* the problem is that we need more than 4 digits for +/- 
5000 years (sum=10000).

Uwe Ligges


> Bo.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jfox at mcmaster.ca  Wed Sep 14 14:42:50 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 14 Sep 2005 08:42:50 -0400
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <81A1F734-F502-4D4E-9C73-D59CB11EF010@anu.edu.au>
Message-ID: <20050914124249.QNHY16985.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear John,


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of John Maindonald
> Sent: Wednesday, September 14, 2005 1:09 AM
> To: Martin Maechler
> Cc: Werner Stahel; R-devel at stat.math.ethz.ch; John Fox
> Subject: Re: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
> 
> Following the >20 messages that Martin mentioned, I had 
> private discussion with John Fox, which in part lies behind 
> following questions:
> 
> (1) In plot 5, should we have, maybe as an option, vertical 
> lines at 2hbar and 3hbar, as in the plots produced by the 
> function that John Fox sent me.  I think this would be a 
> useful addition, but made no move to add it at that time, 
> considering it best to put that on a toThink About list.
> 
> (2) John also sent code for a plot that place contours of the 
> covratio on the points that are shown in plot 5.  This could 
> be added as an option to plot 5.
> (The covratio statistic is a measure of the effect of 
> omitting a point on the variance-covariance matrix.  It is a 
> function of the residual and the leverage.)  Also there is 
> the possibility (I am not keen on this) to show Bonferroni 
> critical values for studentized residuals.
> 
> (3) My reaction to the new plot 6 (David Firth's proposal) is 
> sufficiently similar to John Fox's that I would not use it as 
> a matter of course.  I think it useful however, precisely 
> because it does offer a perspective on the information in 
> plot 5 that is, at first look, startlingly different.
> 
> (4) Are there other diagnostics that ought to be included in 
> stats? (perhaps in a function other than plot.lm(), which 
> risks being overloaded).  One strong claiment is vif() 
> (variance inflation factor), of which there are versions both 
> in car and (written by myself) in DAAG.  John Fox's function 
> does more than mine.  Thus, assuming that he is willing for 
> it to be taken across, that should go into stats.
> 

Fine with me, but the latest version of this function (in the car package)
was rewritten by Henric Nilsson, so he should be asked as well (but see
comments at the end).

> (5) termplot() provides partial residual (component + 
> residual) plots, which I think extraordinarily useful.  They 
> deserve to be widely used.

If I remember right, the cr.plots() function in the car package is a bit
more general.

> Should partial regression plots also be available?
> 

They're implemented in the av.plots() function in the car package.

> (6) It should be fairly easy to construct a function that 
> would examine the distribution of statistics of interest 
> under repeated bootstrap sampling or simulation.  This can be 
> useful when with small samples, when it is easy to 
> over-interpret diagnostic statistics.
> 

I think that this is particularly useful for QQ plots of residuals (as
suggested by Atkinson). The .glm and .lm methods for qq.plot in the car
package do this.

> (7) There are special issues, not just for aov models, but 
> also for glm() and (extending the discussion quite a lot) the 
> models that are fitted by lme()/lmer() [nlme/lme4].
> 
> (8) Are there special issues that require attention for large 
> datasets? [I'm sure there are, but regression diagnostics may 
> not be the best point of entry into the discussion.]
> 
> (9) How about a help(Diagnostics) entry?
> 
> (10) Maybe it would be useful to form a (small?) group to 
> look at what should go into:
>   (a) stats
>   (b) a specialist diagnostics package

This seems to me a good idea, before making changes to stats. Certainly it's
not a great idea to try to cram everything into plot.lm (not that you're
recommending that).

Regards,
 John

> Even if this idea is taken up, some preliminary wider 
> canvassing of the opinions of members of this list seems desirable.
> 
> John Maindonald.
> 
> 
> On 14 Sep 2005, at 12:17 AM, Martin Maechler wrote:
> 
> > As some of you R-devel readers may know, the plot() method for "lm" 
> > objects is based in large parts on contributions by John 
> Maindonald, 
> > subsequently "massaged" by me and other R-core members.
> >
> > In the statistics litterature on applied regression, people 
> have had  
> > diverse oppinions on what (and how many!) plots should be used for 
> > goodness-of-fit / residual diagnostics, and to my knowledge most 
> > people have agreed to want to see one (or more) version of a 
> > Tukey-Anscombe plot {Residuals ~ Fitted} and a QQ normal plot.
> > Another consideration was to be somewhat close to what S
> > (S-plus) was doing.  So we have two versions of residuals 
> vs fitted, 
> > one for checking  E[error] = 0, the other for checking Var[error] = 
> > constant.  So we got to the first three plots of
> > plot.lm() about which I don't want to debate at the moment {though, 
> > there's room for improvement even there: e.g., I know of at 
>  least one 
> > case where plot(<lm>) wasn't used because the user  was missing the 
> > qqline() she was so used to in the QQ plot}
> >
> > The topic of this e-mail is the (default) 4th plot which I had 
> > changed; really prompted by the following:
> > More than three months ago, John wrote
> >   http://tolstoy.newcastle.edu.au/R/devel/05/04/0594.html
> >     (which became a thread of about 20 messages, from Apr.23 -- 29,
> > 2005)
> >
> > and currently,
> > NEWS for R 2.2.0 alpha contains
> >
> >
> >>> USER-VISIBLE CHANGES
> >>>
> >>>    o plot(<lm object>) uses a new default for the fourth 
> panel when
> >>>      'which' is not specified.
> >>>      ___ may change before release ___
> >>>
> >
> > and the header is
> >
> > plot.lm <-
> > function (x, which = c(1:3, 5),
> >           caption = c("Residuals vs Fitted",
> >                   "Normal Q-Q", "Scale-Location",
> >               "Cook's distance", "Residuals vs Leverage",
> >               "Cook's distance vs Leverage"),
> >        ......... ) {..............}
> >
> > So we now have 6 possible plots, where 1,2,3 and 5 are the defaults 
> > (and 1,2,3,4 where the old defaults).
> >
> > For the influential points and combination of 'influential' and 
> > 'outlier'
> > there have been quite a few more proposals in the past. R 
> <= 2.1.x has 
> > been plotting the  Cook's distances vs. observation number, whereas 
> > quite a few people in the past have noted that all 
> influence measures 
> > being more or less complicated functions of residuals and 
> "hat values" 
> > aka "leverages", (R_i, h_{ii}), it would really make sense and fit 
> > more to the other plots to plot residuals vs. Leverages --- 
> with the 
> > additional idea of adding *contours* of (equal) Cook's distances to 
> > that plot, in case one would really want to seem them.
> >
> > In the mean time, this has been *active* in R-devel for 
> quite a while, 
> > and we haven't received any new comments.
> >
> > One remaining problem I'd like to address is the "balanced AOV"
> > situation, something probably pretty rare nowadays in real 
> practice, 
> > but common of course in teaching ANOVA.
> > As you may remember, in a balanced design, all observations 
> have the 
> > same leverages h_{ii}, and the plot  R_i  vs  h_ii is really not so 
> > useful.  In that case,  the cook distances CD_i = c *  R_i 
> ^2 and so  
> > CD_i  vs  i {the old "4-th plot in plot.lm"} is
> > graphically identical to   R_i^2 vs i.
> > Now in that case (of identical h_ii's), I think one would 
> really want  
> > "R_i  vs  i".
> >
> > Question to the interested parties:
> >
> >   Should there be an automatism
> >      ``when h_ii == const''  {"==" with a bit of numerical fuzz}
> >   plot a)  R_i   vs i
> >   or   b)  CD_i  vs i
> >
> > or should users have to manually use
> >     plot(<lm>,  which=1:4, ...)
> > in such a case?
> >
> > Feedback very welcome,
> > particularly, you first look at the examples in help(plot.lm) in 
> > *R-devel* aka R-2.2.0 alpha.
> >
> > Martin Maechler, ETH Zurich
> >
> >
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194, John Dedman 
> Mathematical Sciences Building (Building 27) Australian 
> National University, Canberra ACT 0200.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jfox at mcmaster.ca  Wed Sep 14 14:48:21 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 14 Sep 2005 08:48:21 -0400
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <17191.58772.984424.580765@stat.math.ethz.ch>
Message-ID: <20050914124819.NFVT26967.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Martin,

> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
> Sent: Wednesday, September 14, 2005 3:56 AM
> To: John Fox
> Cc: 'Martin Maechler'; 'Werner Stahel'; 'John Maindonald'; 
> R-devel at stat.math.ethz.ch
> Subject: Re: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
> 
> Thank you, John, for
> Dear 
> >>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
> >>>>>     on Tue, 13 Sep 2005 16:41:28 -0400 writes:
> 
>     JohnF> A couple of comments on the new plots (numbers 5 and 6):
>     JohnF> Perhaps some more thought could be given to the
>     JohnF> plotted contours for Cook's D (which are 0.5 and 1.0
>     JohnF> in the example -- large Cook's Ds). A rule-of-thumb
>     JohnF> cut-off for this example is 4/(n - p) = 4/(50 - 5) =
>     JohnF> 0.089, and the discrepancy will grow with n.
> 
> That's an interesting suggestion.  Where does the 4/(n-p) 
> come from? or put differently, should I better read in of 
> your books? ;-)

I believe that I got this by transforming a cutoff suggested by Chatterjee
and Hadi for dffits to the Cook's D scale.

> 
> Honestly, I'm so much a fan of R_i / h_ii that I didn't even 
> know that.
> 
>     JohnF> I'm not terribly fond of number 6, since it seems
>     JohnF> natural to me to think of the relationship among
>     JohnF> these quantities as influence on coefficients =
>     JohnF> leverage * outlyingness (which corresponds to 5);
>     JohnF> also note how in the example, the labels for large
>     JohnF> residuals overplot.
> 
> I think John mainly proposed '6' because other proposed it as 
> another good alternative.  From the few examples I've looked 
> at, I haven't got fond at all either.
> 
>     JohnF> Finally, your remarks about balanced data are cogent
>     JohnF> and suggest going with 1:3 in this case (since R_i
>     JohnF> vs. i is pretty redundant with the QQ plot).
> 
> Ah, that's another, maybe better alternative to my proposal.
> 
> One drawback of it is for situations where people do something
> like   	par(mfrow=c(2,2))
> before calling  plot(<lm>) for several fitted lm models, 
> assuming to fill one page for each of the plots.

Good point -- I do that myself in the Rcmdr package.

> and I think that's something I would have done always in such 
> situations where several different models are fitted and compared.
> 
> Maybe plot.lm() should "advance an empty frame" as soon as
>  prod(par("mfrow")) >= 4
> in that case?
> 

That seems a good idea, at least for the default behaviour. An unlikely
complication would occur if the user wanted to put the plots generated by
plot.lm() on a page along with other plots.

Regards,
 John

> Martin
> 
>     JohnF> --------------------------------
>     JohnF> John Fox
>     JohnF> Department of Sociology
>     JohnF> McMaster University
>     JohnF> Hamilton, Ontario
>     JohnF> Canada L8S 4M4
>     JohnF> 905-525-9140x23604
>     JohnF> http://socserv.mcmaster.ca/jfox 
>     JohnF> -------------------------------- 
> 
>     >> -----Original Message-----
>     >> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
>     >> Sent: Tuesday, September 13, 2005 9:18 AM
>     >> To: R-devel at stat.math.ethz.ch
>     >> Cc: John Maindonald; Werner Stahel; John Fox
>     >> Subject: plot(<lm>): new behavior in R-2.2.0 alpha
>     >> 
>     >> As some of you R-devel readers may know, the plot() method 
>     >> for "lm" objects is based in large parts on contributions by 
>     >> John Maindonald, subsequently "massaged" by me and other 
>     >> R-core members.
>     >> 
>     >> In the statistics litterature on applied regression, people 
>     >> have had  diverse oppinions on what (and how many!) plots 
>     >> should be used for goodness-of-fit / residual diagnostics, 
>     >> and to my knowledge most people have agreed to want to see 
>     >> one (or more) version of a Tukey-Anscombe plot {Residuals ~ 
>     >> Fitted} and a QQ normal plot.
>     >> Another consideration was to be somewhat close to what S
>     >> (S-plus) was doing.  So we have two versions of residuals vs 
>     >> fitted, one for checking  E[error] = 0, the other for 
>     >> checking Var[error] = constant.  So we got to the 
> first three plots of
>     >> plot.lm() about which I don't want to debate at the moment 
>     >> {though, there's room for improvement even there: e.g., I 
>     >> know of at  least one case where plot(<lm>) wasn't used 
>     >> because the user  was missing the qqline() she was so used to 
>     >> in the QQ plot}
>     >> 
>     >> The topic of this e-mail is the (default) 4th plot which I 
>     >> had changed; really prompted by the following:
>     >> More than three months ago, John wrote
>     >> http://tolstoy.newcastle.edu.au/R/devel/05/04/0594.html
>     >> (which became a thread of about 20 messages, from Apr.23 
>     >> -- 29, 2005)
>     >> 
>     >> and currently,
>     >> NEWS for R 2.2.0 alpha contains
>     >> 
>     >> >> USER-VISIBLE CHANGES
>     >> >> 
>     >> >>    o plot(<lm object>) uses a new default for the 
> fourth panel when
>     >> >>      'which' is not specified.
>     >> >>      ___ may change before release ___
>     >> 
>     >> and the header is
>     >> 
>     >> plot.lm <-
>     >> function (x, which = c(1:3, 5), 
>     >> caption = c("Residuals vs Fitted", 
>     >> "Normal Q-Q", "Scale-Location", 
>     >> "Cook's distance", "Residuals vs Leverage", 
>     >> "Cook's distance vs Leverage"), 
>     >> ......... ) {..............}
>     >> 
>     >> So we now have 6 possible plots, where 1,2,3 and 5 are the 
>     >> defaults (and 1,2,3,4 where the old defaults).
>     >> 
>     >> For the influential points and combination of 'influential' 
>     >> and 'outlier'
>     >> there have been quite a few more proposals in the past. R <= 
>     >> 2.1.x has been plotting the  Cook's distances vs. observation 
>     >> number, whereas quite a few people in the past have noted 
>     >> that all influence measures being more or less complicated 
>     >> functions of residuals and "hat values" aka "leverages", 
>     >> (R_i, h_{ii}), it would really make sense and fit more to the 
>     >> other plots to plot residuals vs. Leverages --- with the 
>     >> additional idea of adding *contours* of (equal) Cook's 
>     >> distances to that plot, in case one would really want 
> to seem them.
>     >> 
>     >> In the mean time, this has been *active* in R-devel for quite 
>     >> a while, and we haven't received any new comments.
>     >> 
>     >> One remaining problem I'd like to address is the "balanced AOV"
>     >> situation, something probably pretty rare nowadays in real 
>     >> practice, but common of course in teaching ANOVA.
>     >> As you may remember, in a balanced design, all observations 
>     >> have the same leverages h_{ii}, and the plot  R_i  vs  h_ii 
>     >> is really not so useful.  In that case,  the cook distances 
>     >> CD_i = c *  R_i ^2 and so  CD_i  vs  i {the old "4-th plot in 
>     >> plot.lm"} is
>     >> graphically identical to   R_i^2 vs i.
>     >> Now in that case (of identical h_ii's), I think one would 
>     >> really want  "R_i  vs  i".
>     >> 
>     >> Question to the interested parties:
>     >> 
>     >> Should there be an automatism
>     >> ``when h_ii == const''  {"==" with a bit of numerical fuzz}
>     >> plot a)  R_i   vs i
>     >> or   b)  CD_i  vs i
>     >> 
>     >> or should users have to manually use
>     >> plot(<lm>,  which=1:4, ...)
>     >> in such a case?
>     >> 
>     >> Feedback very welcome,
>     >> particularly, you first look at the examples in help(plot.lm) 
>     >> in *R-devel* aka R-2.2.0 alpha.
>     >> 
>     >> Martin Maechler, ETH Zurich


From jinghuazhao at hotmail.com  Wed Sep 14 16:21:16 2005
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Wed, 14 Sep 2005 14:21:16 +0000
Subject: [Rd] R CMD check
In-Reply-To: <432803D9.3080103@stats.uwo.ca>
Message-ID: <BAY108-F29A18230936386D96FDE91A59F0@phx.gbl>

yes, it does work now by putting the R environments in front of the original 
%path%.


>From: Duncan Murdoch <murdoch at stats.uwo.ca>
>To: jing hua zhao <jinghuazhao at hotmail.com>
>CC: r-devel at r-project.org
>Subject: Re: [Rd] R CMD check
>Date: Wed, 14 Sep 2005 07:04:57 -0400
>
>jing hua zhao wrote:
>>Dear r-devel members,
>>
>>I tried to build R packages on a PC running Windows XP but experience 
>>problems. However, it is ok when there is no inst directory in a package.
>>
>>Any help would be appreciated.
>>
>>The following is an example,
>>
>>C:\work>R CMD check VR_7.2-19.tar.gz
>>* checking for working latex ... OK
>>* using log directory 'C:/work/VR.Rcheck'
>>* using R version 2.1.1, 2005-06-20
>>* checking for file 'VR/DESCRIPTION' ... OK
>>* looks like 'VR' is a package bundle
>>* this is bundle 'VR' version '7.2-19'
>>* checking if this is a source bundle ... OK
>>
>>installing R.css in C:/work/VR.Rcheck
>>
>>Looks like `C:/work/VR.Rcheck/00_pkg_src/VR' is a package bundle
>>
>>
>>---------- Making package MASS ------------
>>   adding build stamp to DESCRIPTION
>>   installing NAMESPACE file and metadata
>>   making DLL ...
>>making MASS.d from MASS.c
>>making lqs.d from lqs.c
>>gcc   -Ic:/PROGRA~1/r/rw2011/include -Wall -O2   -c MASS.c -o MASS.o
>>gcc   -Ic:/PROGRA~1/r/rw2011/include -Wall -O2   -c lqs.c -o lqs.o
>>ar cr MASS.a MASS.o lqs.o
>>ranlib MASS.a
>>windres --include-dir c:/PROGRA~1/r/rw2011/include  -i MASS_res.rc -o 
>>MASS_res.
>>
>>gcc  --shared -s  -o MASS.dll MASS.def MASS.a MASS_res.o  
>>-c:/PROGRA~1/r/rw201/src/gnuwin32   -lg2c -lR
>>   ... DLL made
>>   installing DLL
>>   installing R files
>>   installing inst files
>>FIND: Parameter format not correct
>
>Looks like a path problem.  There's a find command in the R tools, and a 
>completely different one in Windows.  You need to set your path to find the 
>R one first.
>
>Duncan Murdoch
>
>>make[2]: *** [C:/work/VR.Rcheck/MASS/inst] Error 2
>>make[1]: *** [all] Error 2
>>make: *** [pkg-MASS] Error 2
>>*** Installation of MASS failed ***
>>
>>ERROR
>>Installation failed.
>>
>>C:\work> path
>>
>>PATH=C:\texmf\miktex\bin;C:\Perl\bin\;C:\Program 
>>Files\Insightful\splus62\;C:\WI
>>NDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program 
>>Files\Hummingbird\
>>Connectivity\9.00\Accessories\;C:\Program Files\Common 
>>Files\GTK\2.0\bin;C:\Prog
>>ram Files\WinSCP3\;C:\Program Files\PC-Pine
>>
>>
>>
>>Jing Hua Zhao
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ben.bob at gmail.com  Wed Sep 14 17:27:27 2005
From: ben.bob at gmail.com (Bo Peng)
Date: Wed, 14 Sep 2005 08:27:27 -0700
Subject: [Rd] as.Date() , feature or bug?
In-Reply-To: <4328152F.9060705@statistik.uni-dortmund.de>
References: <6ea7b543050913183858e052f4@mail.gmail.com>
	<4328152F.9060705@statistik.uni-dortmund.de>
Message-ID: <6ea7b54305091408275ad633d3@mail.gmail.com>

> Well, bug, if you really want to call it a bug that you cannot represent
> the year 6666. ;-)

So I guess we need a warning message and a line in help(as.Date)?

Bo


From W.E.Wolski at ncl.ac.uk  Wed Sep 14 17:45:34 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Wed, 14 Sep 2005 17:45:34 +0200
Subject: [Rd] NUMERIC_POINTER question
In-Reply-To: <3D7CA27B-5BD2-41AD-BBF8-151D33E00486@r-project.org>
References: <43161F2B@webmail.ncl.ac.uk>
	<3D7CA27B-5BD2-41AD-BBF8-151D33E00486@r-project.org>
Message-ID: <4328459E.6040702@ncl.ac.uk>

Thanks Roger, Simon, Reid,


It's indeed trivial, if you stop to believe that S4 provides any type of 
type safety. However, having in mind all the arguments why S4, and that 
it  was designed in order to incorporate type safety on both the R and C 
side I was not expecting that when trying for the *first* time, the 
get_slot and set_slot "stuff" I will run in exactly the problems which 
S4 is supposed to solve.

Of course I knew that "matrix" is not S4 and it is therefore even not a 
proper class. But this complexity sometimes blows your mind.

Cheers
Eryk.


Simon Urbanek wrote:
> Eryk,
> 
> On Sep 13, 2005, at 2:26 PM, nwew wrote:
> 
>> printf("%f\n",NUMERIC_POINTER(mat)[1]);
>> [...]
>> However it prints
>> 0.0000
>> if xx at data are integers ( xx at data<-matrix(1:12,3,4) ).
>>
>> Can anyone explain it to me why?
>> I thought that NUMERIC_POINTER makes it clear that i expect  datatype 
>> numeric.
>> (Why otherwise the distinction with INTEGER_POINTER)
> 
> 
> You answered your own question - NUMERIC_POINTER expects that the  SEXP 
> you pass to it is numeric=double. When you use it, it's your  
> responsibility to make sure that the SEXP is numeric and not integer  or 
> anything else. Probably you may want to use AS_NUMERIC to ensure  that. 
> [btw: NUMERIC_POINTER() is a compatibility macro for REAL() and  
> AS_NUMERIC(x) for coerceVector(x,REALSXP)].
> 
> Also you should be aware that C uses 0-based indices so  
> NUMERIC_POINTER(mat)[1] accesses the 2nd element of the vector.
> 
> Cheers,
> Simon
> 
> 

From ligges at statistik.uni-dortmund.de  Wed Sep 14 17:48:36 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Sep 2005 17:48:36 +0200
Subject: [Rd] as.Date() , feature or bug?
In-Reply-To: <6ea7b54305091408275ad633d3@mail.gmail.com>
References: <6ea7b543050913183858e052f4@mail.gmail.com>	<4328152F.9060705@statistik.uni-dortmund.de>
	<6ea7b54305091408275ad633d3@mail.gmail.com>
Message-ID: <43284654.1010400@statistik.uni-dortmund.de>

Bo Peng wrote:

>>Well, bug, if you really want to call it a bug that you cannot represent
>>the year 6666. ;-)
> 
> 
> So I guess we need a warning message and a line in help(as.Date)?

Even better a fix (than an *error* message), since the POSIX classes can 
handle the date and I do not (yet) see the reason why Date cannot. But I 
have no time to dig deeper (at least not this week).


Uwe Ligges


> Bo
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pgilbert at bank-banque-canada.ca  Wed Sep 14 21:45:25 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 14 Sep 2005 15:45:25 -0400
Subject: [Rd] simulate in stats
Message-ID: <43287DD5.4080104@bank-banque-canada.ca>

Can the arguments nsim and seed be passed as part of ... in the new 
simulate generic in R-2.2.0alpha package stats?

This would potentially allow me to use the stats generic rather than the 
one I define in dse. There are contexts where nsim and seed do not make 
sense. I realize that the default arguments could be ignored, but it 
does not really make sense to introduce a new generic with that in mind. 
(I would also prefer that the "object" argument was called "model" but 
this is less important.)

Paul Gilbert


From pgilbert at bank-banque-canada.ca  Thu Sep 15 02:50:00 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 14 Sep 2005 20:50:00 -0400
Subject: [Rd] simulate in stats
Message-ID: <4328C538.40509@bank-banque-canada.ca>

(Sorry if this was posted twice. I seem to be having some email issues.)

Can the arguments nsim and seed be passed as part of ... in the new 
simulate generic in R-2.2.0alpha package stats?

This would potentially allow me to use the stats generic rather than the 
one I define in dse. There are contexts where nsim and seed do not make 
sense. I realize that the default arguments could be ignored, but it 
does not really make sense to introduce a new generic with that in mind. 
(I would also prefer that the "object" argument was called "model" but 
this is less important.)

Paul Gilbert


From pgilbert at bank-banque-canada.ca  Thu Sep 15 18:07:48 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 15 Sep 2005 12:07:48 -0400
Subject: [Rd] simulate in stats
In-Reply-To: <43287DD5.4080104@bank-banque-canada.ca>
References: <43287DD5.4080104@bank-banque-canada.ca>
Message-ID: <43299C54.1080100@bank-banque-canada.ca>

BTW, I think there is a problem with the way the argument "seed" is used 
in the new simulate in stats.  The problem is that repeated calls to 
simulate using the default argument will introduce a new pattern into 
the RNG:

 > stats:::simulate
function (object, nsim = 1, seed = as.integer(runif(1, 0, 
.Machine$integer.max)),   ...)
UseMethod("simulate")
<environment: namespace:stats>


 > stats:::simulate.lm
function (object, nsim = 1, seed = as.integer(runif(1, 0, 
.Machine$integer.max)),    ...)
{
    if (!exists(".Random.seed", envir = .GlobalEnv))
        runif(1)
    RNGstate <- .Random.seed
    set.seed(seed)
  ...

This should not be done, as the resulting RNG has not been studied or 
proven. A better mechanism is  to have a default argument equal NULL, 
and not touch the seed in that case. There are several examples of this 
in the package dse1 (in bundle dse),  see for example simulate.ARMA and 
simulate.SS. They also use the utilities in the setRNG package to save 
more of the information necessary to reproduce simulations. Roughly it 
is done like this:
 
simulate.x <- function (model, rng = NULL,  ...)
  {if (is.null(rng)) rng <- setRNG() #returns the RNG setting to be 
saved with the result
    else {
        old.rng <- setRNG(rng)
        on.exit(setRNG(old.rng))
        }
   ...


The seed by itself is not very useful if the purpose is to be able to 
reproduce things, and I think it would be a good idea to incorporate the 
few small functions setRNG into stats (especially if the simulate 
mechanism is being introduced).

The argument "nsim" presumably alleviates to some extent the above 
concern about changing the RNG pattern. However, in my fairly extensive 
experience it is not very workable to produce all the simulations and 
then do the analysis of them. In a Monte Carlo experiment the generated 
data set is just too big. A better approach is to do the analysis and 
save only necessary information after each simulation. That is the 
approach, for example, in dse2:::EstEval.

Paul

Paul Gilbert wrote:

> Can the arguments nsim and seed be passed as part of ... in the new 
> simulate generic in R-2.2.0alpha package stats?
>
> This would potentially allow me to use the stats generic rather than 
> the one I define in dse. There are contexts where nsim and seed do not 
> make sense. I realize that the default arguments could be ignored, but 
> it does not really make sense to introduce a new generic with that in 
> mind. (I would also prefer that the "object" argument was called 
> "model" but this is less important.)
>
> Paul Gilbert


From ripley at stats.ox.ac.uk  Thu Sep 15 18:24:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Sep 2005 17:24:38 +0100 (BST)
Subject: [Rd] as.Date() , feature or bug?
In-Reply-To: <43284654.1010400@statistik.uni-dortmund.de>
References: <6ea7b543050913183858e052f4@mail.gmail.com>
	<4328152F.9060705@statistik.uni-dortmund.de>
	<6ea7b54305091408275ad633d3@mail.gmail.com>
	<43284654.1010400@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0509151720570.11051@gannet.stats>

On Wed, 14 Sep 2005, Uwe Ligges wrote:

> Bo Peng wrote:
>
>>> Well, bug, if you really want to call it a bug that you cannot represent
>>> the year 6666. ;-)
>>
>>
>> So I guess we need a warning message and a line in help(as.Date)?
>
> Even better a fix (than an *error* message), since the POSIX classes can
> handle the date and I do not (yet) see the reason why Date cannot. But I
> have no time to dig deeper (at least not this week).

Well, actually they cannot.  There is a limit of dates +/- 5000 years from 
the epoch (1970-01-01).  This should have returned NA, and now does.

What does anyone want such dates for?  I hope there was an extremely good 
reason to spend other people's time on this, and look forward to an 
extremely convincing explanation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From B.Rowlingson at lancaster.ac.uk  Thu Sep 15 18:46:29 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 15 Sep 2005 17:46:29 +0100
Subject: [Rd] as.Date() , feature or bug?
In-Reply-To: <Pine.LNX.4.61.0509151720570.11051@gannet.stats>
References: <6ea7b543050913183858e052f4@mail.gmail.com>	<4328152F.9060705@statistik.uni-dortmund.de>	<6ea7b54305091408275ad633d3@mail.gmail.com>	<43284654.1010400@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0509151720570.11051@gannet.stats>
Message-ID: <4329A565.4030905@lancaster.ac.uk>

Prof Brian Ripley wrote:
>
> What does anyone want such dates for?  I hope there was an extremely good 
> reason to spend other people's time on this, and look forward to an 
> extremely convincing explanation.
> 

I can think of one case where I've seen exact dates that far in the 
future used: astronomical calculations. You may have something like "And 
the next chance you'll get to see Jupiter this close to Venus will be on 
December 12th 8766CE. Just after lunchtime in whatever remains of London 
then.".

Is there an R package for astronomical calculations?

Baz


From pgilbert at bank-banque-canada.ca  Thu Sep 15 19:53:08 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 15 Sep 2005 13:53:08 -0400
Subject: [Rd] loadings()   generic in R alpha
Message-ID: <4329B504.3020209@bank-banque-canada.ca>

Could loadings()  in R-2.2.0  please be made generic?

Thanks,
Paul Gilbert


From pgilbert at bank-banque-canada.ca  Thu Sep 15 19:53:15 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 15 Sep 2005 13:53:15 -0400
Subject: [Rd] acf()  generic in R alpha
Message-ID: <4329B50B.20400@bank-banque-canada.ca>

Could acf()  in R-2.2.0  please be made generic?

Thanks,
Paul Gilbert


From khansen at stat.Berkeley.EDU  Thu Sep 15 22:18:28 2005
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Thu, 15 Sep 2005 13:18:28 -0700
Subject: [Rd] simulate in stats
In-Reply-To: <43299C54.1080100@bank-banque-canada.ca>
References: <43287DD5.4080104@bank-banque-canada.ca>
	<43299C54.1080100@bank-banque-canada.ca>
Message-ID: <690DC58C-C035-4A5D-A95B-E529325AF5FD@stat.berkeley.edu>

I agree: no function should per default touch the random number  
stream. Otherwise this will undoubtedly lead to misuse. And while one  
may want to include a seed argument in case a user wants to set it  
explicitly, I would argue that the preferred usage is to do
   set.seed(SOMETHING)
   someFunction()
and then educate users that this is the way to go.

Kasper


On Sep 15, 2005, at 9:07 AM, Paul Gilbert wrote:

> BTW, I think there is a problem with the way the argument "seed" is  
> used
> in the new simulate in stats.  The problem is that repeated calls to
> simulate using the default argument will introduce a new pattern into
> the RNG:
>
>
>> stats:::simulate
>>
> function (object, nsim = 1, seed = as.integer(runif(1, 0,
> .Machine$integer.max)),   ...)
> UseMethod("simulate")
> <environment: namespace:stats>
>
>
>
>> stats:::simulate.lm
>>
> function (object, nsim = 1, seed = as.integer(runif(1, 0,
> .Machine$integer.max)),    ...)
> {
>     if (!exists(".Random.seed", envir = .GlobalEnv))
>         runif(1)
>     RNGstate <- .Random.seed
>     set.seed(seed)
>   ...
>
> This should not be done, as the resulting RNG has not been studied or
> proven. A better mechanism is  to have a default argument equal NULL,
> and not touch the seed in that case. There are several examples of  
> this
> in the package dse1 (in bundle dse),  see for example simulate.ARMA  
> and
> simulate.SS. They also use the utilities in the setRNG package to save
> more of the information necessary to reproduce simulations. Roughly it
> is done like this
> simulate.x <- function (model, rng = NULL,  ...)
>   {if (is.null(rng)) rng <- setRNG() #returns the RNG setting to be
> saved with the result
>     else {
>         old.rng <- setRNG(rng)
>         on.exit(setRNG(old.rng))
>         }
>    ...
>
>
> The seed by itself is not very useful if the purpose is to be able to
> reproduce things, and I think it would be a good idea to  
> incorporate the
> few small functions setRNG into stats (especially if the simulate
> mechanism is being introduced).
>
> The argument "nsim" presumably alleviates to some extent the above
> concern about changing the RNG pattern. However, in my fairly  
> extensive
> experience it is not very workable to produce all the simulations and
> then do the analysis of them. In a Monte Carlo experiment the  
> generated
> data set is just too big. A better approach is to do the analysis and
> save only necessary information after each simulation. That is the
> approach, for example, in dse2:::EstEval.
>
> Paul
>
> Paul Gilbert wrote:
>
>
>> Can the arguments nsim and seed be passed as part of ... in the new
>> simulate generic in R-2.2.0alpha package stats?
>>
>> This would potentially allow me to use the stats generic rather than
>> the one I define in dse. There are contexts where nsim and seed do  
>> not
>> make sense. I realize that the default arguments could be ignored,  
>> but
>> it does not really make sense to introduce a new generic with that in
>> mind. (I would also prefer that the "object" argument was called
>> "model" but this is less important.)
>>
>> Paul Gilbert
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ben.bob at gmail.com  Thu Sep 15 22:21:41 2005
From: ben.bob at gmail.com (Bo Peng)
Date: Thu, 15 Sep 2005 13:21:41 -0700
Subject: [Rd] as.Date() , feature or bug?
In-Reply-To: <4329A565.4030905@lancaster.ac.uk>
References: <6ea7b543050913183858e052f4@mail.gmail.com>
	<4328152F.9060705@statistik.uni-dortmund.de>
	<6ea7b54305091408275ad633d3@mail.gmail.com>
	<43284654.1010400@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0509151720570.11051@gannet.stats>
	<4329A565.4030905@lancaster.ac.uk>
Message-ID: <6ea7b543050915132176214f25@mail.gmail.com>

This problem was brought up by Xu Neng <neng.xu at umontreal.ca> in the rpy-list. 

<Quote>
Remember the old times when computer guys thought the year 2000 was
too far away to be worried? In my case, the dates like "6666-06-6" and
"9999-09-09" are used as special missing codings for dates.

If R cannot handle dates later than the year 5000, it is fine. Please
just let the world knows about it. What is really annoying is the fact
that the default date "1970-01-01" is silently used instead of raising
exception. If you are not very careful, you may not even notice this
trick. This is the bug I'm referring to.

Hopefully, the R experts can handle this bug seriously.
</Quote>

Bo


From Mark.Bravington at csiro.au  Fri Sep 16 01:51:15 2005
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Fri, 16 Sep 2005 09:51:15 +1000
Subject: [Rd] Rd and guillemots
Message-ID: <D79013E40FEF254AAF0D72DFC94F274803D8C4@extas4-hba.tas.csiro.au>

First of all, thanks to those who've set up R to work so smoothly with
Miktex-- even a total Latex bunny like me got it to work instantly, so
that for the first time I'm able to run my Rd files through the Latex
side of RCMD CHECK.

Now the question/buglet. One of my Rd files contains the following:

\code{mlazy( <<objname1>>, <<objname2>>, <<etc>>)}

When I run the file through RCMD (either RCMD CHECK or Rcmd Rd2dvi
--pdf) the first << and >> are left alone, but the second and third
pairs are converted to single guillemot characters (i.e. European
quotation marks). This inconsistency seems a bit odd.

Also, is there any way of getting RCMD to leave << and >> alone-- i.e.
not to guillemotize them? They cause unrecognized characters on my
(Windows XP, newly-installed Miktex, R-alpha of 10/9/2005) system when I
run the dvi files through dvips.

Thanks

Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623


From jfox at mcmaster.ca  Fri Sep 16 03:47:40 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Sep 2005 21:47:40 -0400
Subject: [Rd] Rprofile not executed in R 2.2.0 alpha for Windows
Message-ID: <20050916014739.UISK21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear list members (esp. Duncan),

I've run into the following curious problem with Version 2.2.0 alpha for
Windows: Options in the Profile file in R's etc directory don't appear to be
set. (I habitually uncomment options(chmhelp=TRUE), to no effect in this
case.)  As far as I can see, the only thing non-standard about my
installation is that I put R 2.2.0 alpha under c:\R rather than under
c:\Program Files.

Regards,
 John

-----------------------

Bug report info:

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = alpha
 major = 2
 minor = 2.0
 year = 2005
 month = 09
 day = 14
 svn rev = 35574
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads, package:base

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox


From ripley at stats.ox.ac.uk  Fri Sep 16 09:06:52 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Sep 2005 08:06:52 +0100 (BST)
Subject: [Rd] Rprofile not executed in R 2.2.0 alpha for Windows
In-Reply-To: <20050916014739.UISK21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>
References: <20050916014739.UISK21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.61.0509160802440.21343@gannet.stats>

Do you mean R_HOME/etc/Rprofile (not Profile)?  That is not supposed to be 
executed: see ?Startup.  See the NEWS item

     o   R_HOME/etc/Rprofile is no longer looked for if
         R_HOME/etc/Rprofile.site does not exist.  (This has been
         undocumented since R 1.4.0.)

We will rename the file to Rprofile.site (and update it).

On Thu, 15 Sep 2005, John Fox wrote:

> Dear list members (esp. Duncan),
>
> I've run into the following curious problem with Version 2.2.0 alpha for
> Windows: Options in the Profile file in R's etc directory don't appear to be
> set. (I habitually uncomment options(chmhelp=TRUE), to no effect in this
> case.)  As far as I can see, the only thing non-standard about my
> installation is that I put R 2.2.0 alpha under c:\R rather than under
> c:\Program Files.
>
> Regards,
> John
>
> -----------------------
>
> Bug report info:
>
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status = alpha
> major = 2
> minor = 2.0
> year = 2005
> month = 09
> day = 14
> svn rev = 35574
> language = R
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics,
> package:grDevices, package:utils, package:datasets, Autoloads, package:base
>
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Sep 16 10:06:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Sep 2005 09:06:33 +0100 (BST)
Subject: [Rd] loadings()   generic in R alpha
In-Reply-To: <4329B504.3020209@bank-banque-canada.ca>
References: <4329B504.3020209@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.61.0509160855171.31294@gannet.stats>

On Thu, 15 Sep 2005, Paul Gilbert wrote (in two separate messages)

> Could loadings()  in R-2.2.0  please be made generic?

> Could acf()  in R-2.2.0  please be made generic?

I think it is too late in the process for this (and especially for acf). 
In particular, it could have knock-on consequences for packages and 
recommended packages are scheduled to be all fixed in stone by next Weds.

To consider making such functions generic we would need

- a case
- discussion of what the arguments of the generic should be and what is
   to be specified about the return value.

Perhaps you could raise these again with specific proposals early in the 
developement cycle for 2.3.0.

(We have been a little too casual about speciying what generic functions 
should return in the past, and have got bitten as a result.  For example, 
can it be assumed that loadings() returns a matrix?)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From stahel at stat.math.ethz.ch  Fri Sep 16 09:37:02 2005
From: stahel at stat.math.ethz.ch (Werner Stahel)
Date: Fri, 16 Sep 2005 09:37:02 +0200
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <17190.57225.254938.977464@stat.math.ethz.ch>
References: <17190.57225.254938.977464@stat.math.ethz.ch>
Message-ID: <17194.30238.436418.752419@stat.math.ethz.ch>

Dear Martin, dear Johns

Thanks for including me into your discussion. 

I am a strong supporter of "Residuals vs. Hii"

>> One remaining problem I'd like to address is the "balanced AOV"
>> situation, ...

In order to keep the plots consistent, I suggest to draw a
histogram. Other alternatives will or can be interesting in the 
general case and therefore are not a suitable substitute for
this plot. 

A plot to be developed may be the following:
Define a distance in the subspace of x-space that is in some way
orthogonal (eg, with respect to the covariance matrix of the x's)
to the fit. Then plot residuals vs. this distance, with
different symbols for small, medium and large fit.
... but this is still a project.

A related project: Daniel (and Wood) introduced a term WSSD, a
distance in x-space. He then studied, for pairs of points, 
difference in residuals as a function of WSSD. If the function
increases, this indicates a lack of fit.

Back to currently available methods:

John Maindonald discusses different contours. I like the
implementation I get currently in R-devel: contours of Cook's
distances, since they are popular and we can then argue that the
plot of D_i vs. i is no more needed.

For most plots, I like to see a smoother along with the points.
I suggest to add the option to include smoothers, not only as an
argument to plot.lm, but even as an option().
I have heared of the intense discussions about options().
With Martin, we arrived at the conclusion that options() should
never influence calculations and results, but is suitable to
adjust outputs (numerical: digits=, graphical: smooth=) to the
user's taste.

>> (4) Are there other diagnostics that ought to be included in
>> stats? (perhaps in a function other than plot.lm(), which risks
>> being overloaded).  One strong claiment is vif() (variance
>> inflation factor),

I clearly support to add either vif or -- equivalent and more
intuitive to me -- R^2_j, the coefficient of determination of 
lm(X_j~.) However
-- this should be included in the coefficient table of print.lm
-- this adds another useless and misleading quantity for dummy
x-variables 
It is therefore quite a different question.

I have my own version of print for my own version of a function
regr(...) that calls lm, glm and other regression functions. 
If you are interested, I can send these functions within a few weeks.

>> (5) termplot() provides partial residual (component + residual)
>> plots, which I think extraordinarily useful.  They deserve to be
>> widely used.
>> Should partial regression plots also be available?

The plot method for my regr objects includes termplots.
I prefer residuals without component effects, but add a
reference line that allows for assessing the component effects.

>> (6) It should be fairly easy to construct a function that would
>> examine the distribution of statistics of interest under repeated
>> bootstrap sampling or simulation.  This can be useful when
>> with small samples, when it is easy to over-interpret diagnostic
>> statistics.

As we focus on plots, my plot method includes the option
(default) to add smooths for 20 simulated datasets (according to
the fitted model). 

>> (8) Are there special issues that require attention for large
>> datasets? [I'm sure there are, but regression diagnostics may
>> not be the best point of entry into the discussion.]

A cynical remark that I like to make about the state of
statistics: 
There is no program that is able to produce a scatterplot of two
variables adequately. 
The functions that I have seen work only for textbook
situations.
Large sample is one situation where they fail, others being
-- multiple points (due to rounding or classification)
-- outliers

This seems to be enough for one message ...

Cheers,

Werner 
----------------- This message was sent by ---------------------------
Werner Stahel                              http://stat.ethz.ch/~stahel
Seminar fuer Statistik                     phone  :    +41 1 632 34 30
ETH-Zentrum, LEO D8                        fax    :    +41 1 632 12 28
CH-8092 Zurich, Switzerland                meet me: Leonhardstr.27, D8


From thomas.petzoldt at tu-dresden.de  Fri Sep 16 10:45:19 2005
From: thomas.petzoldt at tu-dresden.de (thomas.petzoldt@tu-dresden.de)
Date: Fri, 16 Sep 2005 10:45:19 +0200 (CEST)
Subject: [Rd] incomplete make clean for grDevices ( Windows only) (PR#8137)
Message-ID: <20050916084519.114D71C690@slim.kubism.ku.dk>

Full_Name: Thomas Petzoldt
Version: R 2.2.0 alpha
OS: Windows
Submission from: (NULL) (141.30.20.2)


Symptom:

If one moves a source tree to another drive letter, a following compile will
fail when compiling grDevices.

The bug is found on Windows only.

Reason:

When performing a "make clean" for the complete installation, several files (in
particular *.d are not cleaned up.

Suggested solution: 

modify Makefile.win that "clean" deletes *.rd (and possibly some others??)

clean:
	$(RM) $(DLLNAME).dll *.a $(OBJS) $(DLLNAME).def grDevices_res.rc *.d


From jfox at mcmaster.ca  Fri Sep 16 14:38:45 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 16 Sep 2005 08:38:45 -0400
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <17194.30238.436418.752419@stat.math.ethz.ch>
Message-ID: <20050916123844.KCAL28424.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Werner,


> -----Original Message-----
> From: Werner Stahel [mailto:stahel at stat.math.ethz.ch] 
> Sent: Friday, September 16, 2005 2:37 AM
> To: Martin Maechler
> Cc: R-devel at stat.math.ethz.ch; John Maindonald; Werner 
> Stahel; John Fox
> Subject: Re: plot(<lm>): new behavior in R-2.2.0 alpha
> 

. . .

> 
> For most plots, I like to see a smoother along with the points.
> I suggest to add the option to include smoothers, not only as 
> an argument to plot.lm, but even as an option().

I agree that smoothers are useful.

. . .

> I clearly support to add either vif or -- equivalent and more 
> intuitive to me -- R^2_j, the coefficient of determination of
> lm(X_j~.) However
> -- this should be included in the coefficient table of print.lm
> -- this adds another useless and misleading quantity for 
> dummy x-variables It is therefore quite a different question.
> 

Generalized variance inflation factors (as computed by the vif function in
car) apply to sets of related regressors in a term, such as dummy
regressors.


. . .

Regards,
 John


From ripley at stats.ox.ac.uk  Fri Sep 16 14:55:17 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Sep 2005 13:55:17 +0100 (BST)
Subject: [Rd] Month recognition issue
In-Reply-To: <p06230907bf450c2f1428@[192.168.0.11]>
References: <p06230907bf450c2f1428@[192.168.0.11]>
Message-ID: <Pine.LNX.4.61.0509161351430.26021@gannet.stats>

On Wed, 7 Sep 2005, Sebastien Durand wrote:

> Dear all,
>
> I am running
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
> Under Mac os X, a french version!

There is no `french version', but you may be in a French locale.

> I am preparing a package and I got the following issue
>
> I am trying to read dates that are written in
> english and have them recognized by R using
> as.Date function.
>
> I realized strangely that when I type
>>  month.abb
>  [1] "Jan" "Feb" "Mar" "Apr" "May" "Jun" "Jul" "Aug" "Sep" "Oct"
> [11] "Nov" "Dec"
>
> I get the abbreviated english version of every month
>
>>  x <- c("1-jan-1960", "2-feb-1960",
>> "31-mar-1960", "30-apr-1960","2-may-1960",
>> "31-jun-1960", "30-jul-1960","2-aug-1960",
>> "31-sep-1960", "30-oct-1960", "30-nov-1960",
>> "30-dec-1960");
>>  strptime(x, "%d-%b-%Y")
>  [1] "1960-01-01" NA           "1960-03-31" NA
>  [5] NA           NA           "1960-07-30" NA
>  [9] "1960-10-01" "1960-10-30" "1960-11-30" NA
>
> It is only once I have found through trial an
> error the french abbreviation, that I got a match
> for every month.
>
>>  x <- c("1-jan-1960", "2-f?v-1960",
>> "31-mar-1960", "30-avr-1960","2-mai-1960",
>> "31-jui-1960", "30-jul-1960","2-ao?-1960",
>> "31-sep-1960", "30-oct-1960", "30-nov-1960",
>> "30-d?c-1960");
>>  strptime(x, "%d-%b-%Y")
>  [1] "1960-01-01" "1960-02-02" "1960-03-31" "1960-04-30"
>  [5] "1960-05-02" "1960-07-01" "1960-07-30" "1960-08-02"
>  [9] "1960-10-01" "1960-10-30" "1960-11-30" "1960-12-30"
>
> I got simply two questions:
>
> First, why since R was install on a french system
> the month.abb command didn't give me the french
> abbreviations.

Did you read the help page, as we do ask?

         *  'month.abb': the three-letter abbreviations for the English
            month names;

         *  'month.name': the English names for the months of the year;

> Secondly, since I am producing a package, I would
> like to know how can I tell R  to momentairly use
> the english abbreviations instead of the french
> ones...

To use them for what?  If you mean in strptime, set the locale you want.
There is an example on the help page!

Please do remember to read the help pages before posting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ggrothendieck at gmail.com  Fri Sep 16 15:06:45 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 16 Sep 2005 09:06:45 -0400
Subject: [Rd] Month recognition issue
In-Reply-To: <p06230907bf450c2f1428@192.168.0.11>
References: <p06230907bf450c2f1428@192.168.0.11>
Message-ID: <971536df050916060653e607c6@mail.gmail.com>

month.abb is hard coded English but I don't think its used by the
routines you are interested in anyways.  To momentarily set locale 
try this:

Sys.setlocale("LC_ALL","EN")

and

Sys.setlocale("LC_ALL","FR")


On 9/7/05, Sebastien Durand <sebastien.durand at umontreal.ca> wrote:
> Dear all,
> 
> I am running
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
> Under Mac os X, a french version!
> 
> I am preparing a package and I got the following issue
> 
> I am trying to read dates that are written in
> english and have them recognized by R using
> as.Date function.
> 
> I realized strangely that when I type
> >  month.abb
>  [1] "Jan" "Feb" "Mar" "Apr" "May" "Jun" "Jul" "Aug" "Sep" "Oct"
> [11] "Nov" "Dec"
> 
> I get the abbreviated english version of every month
> 
> >  x <- c("1-jan-1960", "2-feb-1960",
> >"31-mar-1960", "30-apr-1960","2-may-1960",
> >"31-jun-1960", "30-jul-1960","2-aug-1960",
> >"31-sep-1960", "30-oct-1960", "30-nov-1960",
> >"30-dec-1960");
> >  strptime(x, "%d-%b-%Y")
>  [1] "1960-01-01" NA           "1960-03-31" NA
>  [5] NA           NA           "1960-07-30" NA
>  [9] "1960-10-01" "1960-10-30" "1960-11-30" NA
> 
> It is only once I have found through trial an
> error the french abbreviation, that I got a match
> for every month.
> 
> >  x <- c("1-jan-1960", "2-f?v-1960",
> >"31-mar-1960", "30-avr-1960","2-mai-1960",
> >"31-jui-1960", "30-jul-1960","2-ao?-1960",
> >"31-sep-1960", "30-oct-1960", "30-nov-1960",
> >"30-d?c-1960");
> >  strptime(x, "%d-%b-%Y")
>  [1] "1960-01-01" "1960-02-02" "1960-03-31" "1960-04-30"
>  [5] "1960-05-02" "1960-07-01" "1960-07-30" "1960-08-02"
>  [9] "1960-10-01" "1960-10-30" "1960-11-30" "1960-12-30"
> 
> I got simply two questions:
> 
> First, why since R was install on a french system
> the month.abb command didn't give me the french
> abbreviations.
> 
> Secondly, since I am producing a package, I would
> like to know how can I tell R  to momentairly use
> the english abbreviations instead of the french
> ones...
> 
> Thanks a lot


From ripley at stats.ox.ac.uk  Fri Sep 16 15:17:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Sep 2005 14:17:18 +0100 (BST)
Subject: [Rd] MikTeX will be assumed in R 2.2.0 in Windows
In-Reply-To: <43223809.7000306@stats.uwo.ca>
References: <43223809.7000306@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0509161414420.31661@gannet.stats>

We've made some further changes that enable the scripts to figure out if 
MiKTeX or some more standard latex is being used, so hopefully it should 
work for everyone out-of-the-box.

On Fri, 9 Sep 2005, Duncan Murdoch wrote:

> I've just committed some changes to allow R to be built and to use
> MikTeX without needing the Rd.sty files to be installed to localtexmf.
> Unfortunately, the changes are not compatible with other TeX packages,
> so if you're not using MikTeX you'll need to edit a couple of the config
> files (or set an environment variable).
>
> I'd appreciate hearing of any problems during the alpha or beta test period.

Again, please let us know of any problems.  I have tested both MiKTeX and 
fptex, but on a machine that had both installed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert at bank-banque-canada.ca  Fri Sep 16 18:52:16 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 16 Sep 2005 12:52:16 -0400
Subject: [Rd] loadings()   generic in R alpha
In-Reply-To: <Pine.LNX.4.61.0509160855171.31294@gannet.stats>
References: <4329B504.3020209@bank-banque-canada.ca>
	<Pine.LNX.4.61.0509160855171.31294@gannet.stats>
Message-ID: <432AF840.2030403@bank-banque-canada.ca>

Brian

It would help if I understood general principles. I thought one would 
want a case for NOT making functions generic, rather than a case for 
making them generic. Hopefully a case for why generics and methods are 
useful will not be necessary.

The situation with loadings() is that I construct objects where the 
loadings are in a list within a list, so the simple definition in stats 
does not work:

loadings
function (x)
x$loadings
<environment: namespace:stats>

Basically this definition restricts the way in which objects can be 
constructed, so I would like it replaced by

loadings <- function (x) UseMethod("loadings")
loadings.default <- function (x) x$loadings

There may be a reason for adding a ... argument, but I have been using 
this generic and methods for it in my own work for a fairly long time 
now and have not discovered one.  The change seems rather trivial, I 
have tested it extensively with my own code, and there is a fairly 
complete test suite in place for checking changes to R,  so it seems 
reasonable to me that this should be considered as a change that is 
possible in an alpha release. It would also be fairly easy to back out 
of if there are problems.

The reason for needing  acf generic is the same, so that it can be use 
with more complicated objects that I construct. However, I see here that 
there are potentially more difficult problems, because the ... argument 
to the current acf (which one would want as the default method) is 
passed to plot.acf.  Here I can clearly see the reason for wanting to 
start consideration of this at an earlier point in the development cycle.

Best,
Paul

Prof Brian Ripley wrote:

> On Thu, 15 Sep 2005, Paul Gilbert wrote (in two separate messages)
>
>> Could loadings()  in R-2.2.0  please be made generic?
>
>
>> Could acf()  in R-2.2.0  please be made generic?
>
>
> I think it is too late in the process for this (and especially for 
> acf). In particular, it could have knock-on consequences for packages 
> and recommended packages are scheduled to be all fixed in stone by 
> next Weds.
>
> To consider making such functions generic we would need
>
> - a case
> - discussion of what the arguments of the generic should be and what is
>   to be specified about the return value.
>
> Perhaps you could raise these again with specific proposals early in 
> the developement cycle for 2.3.0.
>
> (We have been a little too casual about speciying what generic 
> functions should return in the past, and have got bitten as a result.  
> For example, can it be assumed that loadings() returns a matrix?)
>


From gavin.simpson at ucl.ac.uk  Fri Sep 16 19:20:29 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 16 Sep 2005 18:20:29 +0100
Subject: [Rd] loadings()   generic in R alpha
In-Reply-To: <432AF840.2030403@bank-banque-canada.ca>
References: <4329B504.3020209@bank-banque-canada.ca>
	<Pine.LNX.4.61.0509160855171.31294@gannet.stats>
	<432AF840.2030403@bank-banque-canada.ca>
Message-ID: <1126891229.29827.61.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2005-09-16 at 12:52 -0400, Paul Gilbert wrote:
> Brian
> 
> It would help if I understood general principles. I thought one would 
> want a case for NOT making functions generic, rather than a case for 
> making them generic. Hopefully a case for why generics and methods are 
> useful will not be necessary.
> 
> The situation with loadings() is that I construct objects where the 
> loadings are in a list within a list, so the simple definition in stats 
> does not work:
> 
> loadings
> function (x)
> x$loadings
> <environment: namespace:stats>
> 
> Basically this definition restricts the way in which objects can be 
> constructed, so I would like it replaced by
> 
> loadings <- function (x) UseMethod("loadings")
> loadings.default <- function (x) x$loadings

Paul,

The writing R extensions manual suggests the following way of hi-jacking
a function and making it generic:

loadings.default <- stats::loadings

As long as your function had argument x this should work, no?

Are there problems with this approach? - I'm interested as I've used
that method in a package I am currently finishing up, which seems to
work fine in my particular case.

One reason that same manual states for preferring not to make everything
generic is that it incurs a small performance cost

I'd be interested in hearing other people's views on this approach -
it's still not too late to change things in my package if I am blindly
teetering on the brink of impending disaster...

G

> 
> There may be a reason for adding a ... argument, but I have been using 
> this generic and methods for it in my own work for a fairly long time 
> now and have not discovered one.  The change seems rather trivial, I 
> have tested it extensively with my own code, and there is a fairly 
> complete test suite in place for checking changes to R,  so it seems 
> reasonable to me that this should be considered as a change that is 
> possible in an alpha release. It would also be fairly easy to back out 
> of if there are problems.
> 
> The reason for needing  acf generic is the same, so that it can be use 
> with more complicated objects that I construct. However, I see here that 
> there are potentially more difficult problems, because the ... argument 
> to the current acf (which one would want as the default method) is 
> passed to plot.acf.  Here I can clearly see the reason for wanting to 
> start consideration of this at an earlier point in the development cycle.
> 
> Best,
> Paul
> 
> Prof Brian Ripley wrote:
> 
> > On Thu, 15 Sep 2005, Paul Gilbert wrote (in two separate messages)
> >
> >> Could loadings()  in R-2.2.0  please be made generic?
> >
> >
> >> Could acf()  in R-2.2.0  please be made generic?
> >
> >
> > I think it is too late in the process for this (and especially for 
> > acf). In particular, it could have knock-on consequences for packages 
> > and recommended packages are scheduled to be all fixed in stone by 
> > next Weds.
> >
> > To consider making such functions generic we would need
> >
> > - a case
> > - discussion of what the arguments of the generic should be and what is
> >   to be specified about the return value.
> >
> > Perhaps you could raise these again with specific proposals early in 
> > the developement cycle for 2.3.0.
> >
> > (We have been a little too casual about speciying what generic 
> > functions should return in the past, and have got bitten as a result.  
> > For example, can it be assumed that loadings() returns a matrix?)
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ripley at stats.ox.ac.uk  Fri Sep 16 19:28:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 16 Sep 2005 18:28:38 +0100 (GMT Standard Time)
Subject: [Rd] loadings()   generic in R alpha
In-Reply-To: <432AF840.2030403@bank-banque-canada.ca>
References: <4329B504.3020209@bank-banque-canada.ca>
	<Pine.LNX.4.61.0509160855171.31294@gannet.stats>
	<432AF840.2030403@bank-banque-canada.ca>
Message-ID: <Pine.WNT.4.58.0509161800290.1472@Petrel>

On Fri, 16 Sep 2005, Paul Gilbert wrote:

> Brian
>
> It would help if I understood general principles. I thought one would
> want a case for NOT making functions generic, rather than a case for
> making them generic. Hopefully a case for why generics and methods are
> useful will not be necessary.

Making things generic

1) adds runtime cost

2) essentially fixes the signature for all time

3) needs the return value sufficiently well defined that all current uses
will not be broken by a new method.  (This was not a problem with e.g.
as.ts as everone knows the result should be a "ts" object.  But I think it
is a problem with acf and loadings.)

I would for example be unhappy with your definition of loadings() as it has
no ... argument (and S-PLUS has one in its loadings() generic).

So cases are necessary.  I am pretty sure that we have in the past agreed
that making a function generic is a Grand Feature, and we are in GFF.


> The situation with loadings() is that I construct objects where the
> loadings are in a list within a list, so the simple definition in stats
> does not work:
>
> loadings
> function (x)
> x$loadings
> <environment: namespace:stats>
>
> Basically this definition restricts the way in which objects can be
> constructed, so I would like it replaced by
>
> loadings <- function (x) UseMethod("loadings")
> loadings.default <- function (x) x$loadings
>
> There may be a reason for adding a ... argument, but I have been using
> this generic and methods for it in my own work for a fairly long time
> now and have not discovered one.  The change seems rather trivial, I
> have tested it extensively with my own code, and there is a fairly
> complete test suite in place for checking changes to R,  so it seems
> reasonable to me that this should be considered as a change that is
> possible in an alpha release. It would also be fairly easy to back out
> of if there are problems.
>
> The reason for needing  acf generic is the same, so that it can be use
> with more complicated objects that I construct. However, I see here that
> there are potentially more difficult problems, because the ... argument
> to the current acf (which one would want as the default method) is
> passed to plot.acf.  Here I can clearly see the reason for wanting to
> start consideration of this at an earlier point in the development cycle.
>
> Best,
> Paul
>
> Prof Brian Ripley wrote:
>
> > On Thu, 15 Sep 2005, Paul Gilbert wrote (in two separate messages)
> >
> >> Could loadings()  in R-2.2.0  please be made generic?
> >
> >
> >> Could acf()  in R-2.2.0  please be made generic?
> >
> >
> > I think it is too late in the process for this (and especially for
> > acf). In particular, it could have knock-on consequences for packages
> > and recommended packages are scheduled to be all fixed in stone by
> > next Weds.
> >
> > To consider making such functions generic we would need
> >
> > - a case
> > - discussion of what the arguments of the generic should be and what is
> >   to be specified about the return value.
> >
> > Perhaps you could raise these again with specific proposals early in
> > the developement cycle for 2.3.0.
> >
> > (We have been a little too casual about speciying what generic
> > functions should return in the past, and have got bitten as a result.
> > For example, can it be assumed that loadings() returns a matrix?)


From pgilbert at bank-banque-canada.ca  Fri Sep 16 20:00:09 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 16 Sep 2005 14:00:09 -0400
Subject: [Rd] loadings()   generic in R alpha
In-Reply-To: <1126891229.29827.61.camel@gsimpson.geog.ucl.ac.uk>
References: <4329B504.3020209@bank-banque-canada.ca>	
	<Pine.LNX.4.61.0509160855171.31294@gannet.stats>	
	<432AF840.2030403@bank-banque-canada.ca>
	<1126891229.29827.61.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <432B0829.3040308@bank-banque-canada.ca>

Gavin Simpson wrote:

>On Fri, 2005-09-16 at 12:52 -0400, Paul Gilbert wrote:
>  
>
>>Brian
>>
>>It would help if I understood general principles. I thought one would 
>>want a case for NOT making functions generic, rather than a case for 
>>making them generic. Hopefully a case for why generics and methods are 
>>useful will not be necessary.
>>
>>The situation with loadings() is that I construct objects where the 
>>loadings are in a list within a list, so the simple definition in stats 
>>does not work:
>>
>>loadings
>>function (x)
>>x$loadings
>><environment: namespace:stats>
>>
>>Basically this definition restricts the way in which objects can be 
>>constructed, so I would like it replaced by
>>
>>loadings <- function (x) UseMethod("loadings")
>>loadings.default <- function (x) x$loadings
>>    
>>
>
>Paul,
>
>The writing R extensions manual suggests the following way of hi-jacking
>a function and making it generic:
>
>loadings.default <- stats::loadings
>
>As long as your function had argument x this should work, no?
>
>Are there problems with this approach? - I'm interested as I've used
>that method in a package I am currently finishing up, which seems to
>work fine in my particular case.
>
Gavin

Hi-jacking works, at least as long as only one package does it. I've 
been doing that for several years now. I'm not sure what happens when 
two packages try to hi-jack the same function, and especially if they 
define the generic differently. I think with namespaces there is 
protection within your own package code, but not protection for anything 
a user might define. I am especially worried about loadings(), as that 
seems like something lots of packages may want to hi-jack.

There are also some additional considerations when namespaces are used. 
For example, to hi-jack loadings one would typically want to put 
something like this in the package code:

if (!exists("loadings.default", mode="function")){
  loadings.default  <- stats::loadings
  loadings <- function(x)UseMethod("loadings")
  }

The if statement is so that the package continues to work if it is 
decided to make loadings generic in  a new version of stats. But exists 
does not work since stats has namespaces (at least not in R-2.1.1, but 
it may be fixed in R-2.2.0). If it is broken then there is no easy way I 
know about to protect against everything in my package getting broken by 
a new release of R.  (Now you may think this last is wishful thinking, 
but so far I have been fairly lucky.)

Paul

>
>One reason that same manual states for preferring not to make everything
>generic is that it incurs a small performance cost
>
>I'd be interested in hearing other people's views on this approach -
>it's still not too late to change things in my package if I am blindly
>teetering on the brink of impending disaster...
>
>G
>
>  
>
>>There may be a reason for adding a ... argument, but I have been using 
>>this generic and methods for it in my own work for a fairly long time 
>>now and have not discovered one.  The change seems rather trivial, I 
>>have tested it extensively with my own code, and there is a fairly 
>>complete test suite in place for checking changes to R,  so it seems 
>>reasonable to me that this should be considered as a change that is 
>>possible in an alpha release. It would also be fairly easy to back out 
>>of if there are problems.
>>
>>The reason for needing  acf generic is the same, so that it can be use 
>>with more complicated objects that I construct. However, I see here that 
>>there are potentially more difficult problems, because the ... argument 
>>to the current acf (which one would want as the default method) is 
>>passed to plot.acf.  Here I can clearly see the reason for wanting to 
>>start consideration of this at an earlier point in the development cycle.
>>
>>Best,
>>Paul
>>
>>Prof Brian Ripley wrote:
>>
>>    
>>
>>>On Thu, 15 Sep 2005, Paul Gilbert wrote (in two separate messages)
>>>
>>>      
>>>
>>>>Could loadings()  in R-2.2.0  please be made generic?
>>>>        
>>>>
>>>      
>>>
>>>>Could acf()  in R-2.2.0  please be made generic?
>>>>        
>>>>
>>>I think it is too late in the process for this (and especially for 
>>>acf). In particular, it could have knock-on consequences for packages 
>>>and recommended packages are scheduled to be all fixed in stone by 
>>>next Weds.
>>>
>>>To consider making such functions generic we would need
>>>
>>>- a case
>>>- discussion of what the arguments of the generic should be and what is
>>>  to be specified about the return value.
>>>
>>>Perhaps you could raise these again with specific proposals early in 
>>>the developement cycle for 2.3.0.
>>>
>>>(We have been a little too casual about speciying what generic 
>>>functions should return in the past, and have got bitten as a result.  
>>>For example, can it be assumed that loadings() returns a matrix?)
>>>
>>>      
>>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>    
>>


From pgilbert at bank-banque-canada.ca  Fri Sep 16 20:04:37 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 16 Sep 2005 14:04:37 -0400
Subject: [Rd] loadings()   generic in R alpha
In-Reply-To: <Pine.WNT.4.58.0509161800290.1472@Petrel>
References: <4329B504.3020209@bank-banque-canada.ca>
	<Pine.LNX.4.61.0509160855171.31294@gannet.stats>
	<432AF840.2030403@bank-banque-canada.ca>
	<Pine.WNT.4.58.0509161800290.1472@Petrel>
Message-ID: <432B0935.5090208@bank-banque-canada.ca>

Brian

Ok, lets leave this for now. When does the development cycle start for 
the next version that would allow making a function generic?

Paul

Prof Brian D Ripley wrote:

>On Fri, 16 Sep 2005, Paul Gilbert wrote:
>
>  
>
>>Brian
>>
>>It would help if I understood general principles. I thought one would
>>want a case for NOT making functions generic, rather than a case for
>>making them generic. Hopefully a case for why generics and methods are
>>useful will not be necessary.
>>    
>>
>
>Making things generic
>
>1) adds runtime cost
>
>2) essentially fixes the signature for all time
>
>3) needs the return value sufficiently well defined that all current uses
>will not be broken by a new method.  (This was not a problem with e.g.
>as.ts as everone knows the result should be a "ts" object.  But I think it
>is a problem with acf and loadings.)
>
>I would for example be unhappy with your definition of loadings() as it has
>no ... argument (and S-PLUS has one in its loadings() generic).
>
>So cases are necessary.  I am pretty sure that we have in the past agreed
>that making a function generic is a Grand Feature, and we are in GFF.
>
>
>  
>
>>The situation with loadings() is that I construct objects where the
>>loadings are in a list within a list, so the simple definition in stats
>>does not work:
>>
>>loadings
>>function (x)
>>x$loadings
>><environment: namespace:stats>
>>
>>Basically this definition restricts the way in which objects can be
>>constructed, so I would like it replaced by
>>
>>loadings <- function (x) UseMethod("loadings")
>>loadings.default <- function (x) x$loadings
>>
>>There may be a reason for adding a ... argument, but I have been using
>>this generic and methods for it in my own work for a fairly long time
>>now and have not discovered one.  The change seems rather trivial, I
>>have tested it extensively with my own code, and there is a fairly
>>complete test suite in place for checking changes to R,  so it seems
>>reasonable to me that this should be considered as a change that is
>>possible in an alpha release. It would also be fairly easy to back out
>>of if there are problems.
>>
>>The reason for needing  acf generic is the same, so that it can be use
>>with more complicated objects that I construct. However, I see here that
>>there are potentially more difficult problems, because the ... argument
>>to the current acf (which one would want as the default method) is
>>passed to plot.acf.  Here I can clearly see the reason for wanting to
>>start consideration of this at an earlier point in the development cycle.
>>
>>Best,
>>Paul
>>
>>Prof Brian Ripley wrote:
>>
>>    
>>
>>>On Thu, 15 Sep 2005, Paul Gilbert wrote (in two separate messages)
>>>
>>>      
>>>
>>>>Could loadings()  in R-2.2.0  please be made generic?
>>>>        
>>>>
>>>      
>>>
>>>>Could acf()  in R-2.2.0  please be made generic?
>>>>        
>>>>
>>>I think it is too late in the process for this (and especially for
>>>acf). In particular, it could have knock-on consequences for packages
>>>and recommended packages are scheduled to be all fixed in stone by
>>>next Weds.
>>>
>>>To consider making such functions generic we would need
>>>
>>>- a case
>>>- discussion of what the arguments of the generic should be and what is
>>>  to be specified about the return value.
>>>
>>>Perhaps you could raise these again with specific proposals early in
>>>the developement cycle for 2.3.0.
>>>
>>>(We have been a little too casual about speciying what generic
>>>functions should return in the past, and have got bitten as a result.
>>>For example, can it be assumed that loadings() returns a matrix?)
>>>      
>>>


From murdoch at stats.uwo.ca  Fri Sep 16 20:06:24 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 16 Sep 2005 14:06:24 -0400
Subject: [Rd] Rd and guillemots
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F274803D8C4@extas4-hba.tas.csiro.au>
References: <D79013E40FEF254AAF0D72DFC94F274803D8C4@extas4-hba.tas.csiro.au>
Message-ID: <432B09A0.1090607@stats.uwo.ca>

On 9/15/2005 7:51 PM, Mark.Bravington at csiro.au wrote:
> First of all, thanks to those who've set up R to work so smoothly with
> Miktex-- even a total Latex bunny like me got it to work instantly, so
> that for the first time I'm able to run my Rd files through the Latex
> side of RCMD CHECK.
> 
> Now the question/buglet. One of my Rd files contains the following:
> 
> \code{mlazy( <<objname1>>, <<objname2>>, <<etc>>)}
> 
> When I run the file through RCMD (either RCMD CHECK or Rcmd Rd2dvi
> --pdf) the first << and >> are left alone, but the second and third
> pairs are converted to single guillemot characters (i.e. European
> quotation marks). This inconsistency seems a bit odd.

Yes, this is the tex that gets output:

\code{mlazy( <{}<objname1>{}>, <<objname2>>, <<etc>>)}

This seems to happen in Rdconv.pm, around here:

     ## avoid conversion to guillemots
     $c =~ s/<</<\{\}</;
     $c =~ s/>>/>\{\}>/;


But I don't know enough Perl syntax to tell it to replace all << by 
<{}<, instead of just the first.  (I would have guessed appending a g 
would work, but didn't in a quick test, i.e. $c =~ s/<</<\{\}</g; didn't 
work.)

Duncan Murdoch

> 
> Also, is there any way of getting RCMD to leave << and >> alone-- i.e.
> not to guillemotize them? They cause unrecognized characters on my
> (Windows XP, newly-installed Miktex, R-alpha of 10/9/2005) system when I
> run the dvi files through dvips.
> 
> Thanks
> 
> Mark Bravington
> CSIRO Mathematical & Information Sciences
> Marine Laboratory
> Castray Esplanade
> Hobart 7001
> TAS
> 
> ph (+61) 3 6232 5118
> fax (+61) 3 6232 5012
> mob (+61) 438 315 623
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Ted.Harding at nessie.mcc.ac.uk  Fri Sep 16 21:34:38 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 16 Sep 2005 20:34:38 +0100 (BST)
Subject: [Rd] Rd and guillemots
In-Reply-To: <432B09A0.1090607@stats.uwo.ca>
Message-ID: <XFMail.050916203438.Ted.Harding@nessie.mcc.ac.uk>

On 16-Sep-05 Duncan Murdoch wrote:
> On 9/15/2005 7:51 PM, Mark.Bravington at csiro.au wrote:
>> First of all, thanks to those who've set up R to work so smoothly with
>> Miktex-- even a total Latex bunny like me got it to work instantly, so
>> that for the first time I'm able to run my Rd files through the Latex
>> side of RCMD CHECK.
>> 
>> Now the question/buglet. One of my Rd files contains the following:
>> 
>> \code{mlazy( <<objname1>>, <<objname2>>, <<etc>>)}
>> 
>> When I run the file through RCMD (either RCMD CHECK or Rcmd Rd2dvi
>> --pdf) the first << and >> are left alone, but the second and third
>> pairs are converted to single guillemot characters (i.e. European
>> quotation marks). This inconsistency seems a bit odd.
> 
> Yes, this is the tex that gets output:
> 
> \code{mlazy( <{}<objname1>{}>, <<objname2>>, <<etc>>)}
> 
> This seems to happen in Rdconv.pm, around here:
> 
>      ## avoid conversion to guillemots
>      $c =~ s/<</<\{\}</;
>      $c =~ s/>>/>\{\}>/;
> 
> 
> But I don't know enough Perl syntax to tell it to replace all << by 
> <{}<, instead of just the first.  (I would have guessed appending a g 
> would work, but didn't in a quick test, i.e. $c =~ s/<</<\{\}</g;
> didn't 
> work.)
> 
> Duncan Murdoch

Perl is overkill -- by a long way!

echo "{mlazy( <<objname1>>, <<objname2>>, <<etc>>)}" |
  sed 's/<</<{}</g;s/>>/>{}>/g'

{mlazy( <{}<objname1>{}>, <{}<objname2>{}>, <{}<etc>{}>)}

Cheers,
Ted.



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Sep-05                                       Time: 20:33:40
------------------------------ XFMail ------------------------------


From Ted.Harding at nessie.mcc.ac.uk  Fri Sep 16 22:04:03 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 16 Sep 2005 21:04:03 +0100 (BST)
Subject: [Rd] Rd and guillemots
In-Reply-To: <XFMail.050916203438.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.050916210403.Ted.Harding@nessie.mcc.ac.uk>

On 16-Sep-05 Ted Harding wrote:
> On 16-Sep-05 Duncan Murdoch wrote:
>> Yes, this is the tex that gets output:
>> 
>> \code{mlazy( <{}<objname1>{}>, <<objname2>>, <<etc>>)}
>> 
>> This seems to happen in Rdconv.pm, around here:
>> 
>>      ## avoid conversion to guillemots
>>      $c =~ s/<</<\{\}</;
>>      $c =~ s/>>/>\{\}>/;
>> 
>> 
>> But I don't know enough Perl syntax to tell it to replace all << by 
>> <{}<, instead of just the first.  (I would have guessed appending a g 
>> would work, but didn't in a quick test, i.e. $c =~ s/<</<\{\}</g;
>> didn't work.)
>> 
>> Duncan Murdoch
> 
> Perl is overkill -- by a long way!
> 
> echo "{mlazy( <<objname1>>, <<objname2>>, <<etc>>)}" |
>   sed 's/<</<{}</g;s/>>/>{}>/g'
> 
> {mlazy( <{}<objname1>{}>, <{}<objname2>{}>, <{}<etc>{}>)}
> 
> Cheers,
> Ted.

Sorry, Duncan -- I misread the role of Perl in your mail.

But the substitution string might also work in Perl ... ?

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Sep-05                                       Time: 21:03:58
------------------------------ XFMail ------------------------------


From ripley at stats.ox.ac.uk  Fri Sep 16 22:16:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Sep 2005 21:16:49 +0100 (BST)
Subject: [Rd] Rd and guillemots
In-Reply-To: <432B09A0.1090607@stats.uwo.ca>
References: <D79013E40FEF254AAF0D72DFC94F274803D8C4@extas4-hba.tas.csiro.au>
	<432B09A0.1090607@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0509162115380.6756@gannet.stats>

There are two instances of this.  If I add 'go' to both it works for me.
I guess you only had the first one (the second is used here).

On Fri, 16 Sep 2005, Duncan Murdoch wrote:

> On 9/15/2005 7:51 PM, Mark.Bravington at csiro.au wrote:
>> First of all, thanks to those who've set up R to work so smoothly with
>> Miktex-- even a total Latex bunny like me got it to work instantly, so
>> that for the first time I'm able to run my Rd files through the Latex
>> side of RCMD CHECK.
>>
>> Now the question/buglet. One of my Rd files contains the following:
>>
>> \code{mlazy( <<objname1>>, <<objname2>>, <<etc>>)}
>>
>> When I run the file through RCMD (either RCMD CHECK or Rcmd Rd2dvi
>> --pdf) the first << and >> are left alone, but the second and third
>> pairs are converted to single guillemot characters (i.e. European
>> quotation marks). This inconsistency seems a bit odd.
>
> Yes, this is the tex that gets output:
>
> \code{mlazy( <{}<objname1>{}>, <<objname2>>, <<etc>>)}
>
> This seems to happen in Rdconv.pm, around here:
>
>     ## avoid conversion to guillemots
>     $c =~ s/<</<\{\}</;
>     $c =~ s/>>/>\{\}>/;
>
>
> But I don't know enough Perl syntax to tell it to replace all << by
> <{}<, instead of just the first.  (I would have guessed appending a g
> would work, but didn't in a quick test, i.e. $c =~ s/<</<\{\}</g; didn't
> work.)
>
> Duncan Murdoch
>
>>
>> Also, is there any way of getting RCMD to leave << and >> alone-- i.e.
>> not to guillemotize them? They cause unrecognized characters on my
>> (Windows XP, newly-installed Miktex, R-alpha of 10/9/2005) system when I
>> run the dvi files through dvips.
>>
>> Thanks
>>
>> Mark Bravington
>> CSIRO Mathematical & Information Sciences
>> Marine Laboratory
>> Castray Esplanade
>> Hobart 7001
>> TAS
>>
>> ph (+61) 3 6232 5118
>> fax (+61) 3 6232 5012
>> mob (+61) 438 315 623
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Fri Sep 16 22:33:19 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 16 Sep 2005 16:33:19 -0400
Subject: [Rd] Rd and guillemots
In-Reply-To: <Pine.LNX.4.61.0509162115380.6756@gannet.stats>
References: <D79013E40FEF254AAF0D72DFC94F274803D8C4@extas4-hba.tas.csiro.au>	<432B09A0.1090607@stats.uwo.ca>
	<Pine.LNX.4.61.0509162115380.6756@gannet.stats>
Message-ID: <432B2C0F.2050006@stats.uwo.ca>

On 9/16/2005 4:16 PM, Prof Brian Ripley wrote:
> There are two instances of this.  If I add 'go' to both it works for me.
> I guess you only had the first one (the second is used here).

Yes, that's it.  Thanks!

Duncan Murdoch

> 
> On Fri, 16 Sep 2005, Duncan Murdoch wrote:
> 
>> On 9/15/2005 7:51 PM, Mark.Bravington at csiro.au wrote:
>>> First of all, thanks to those who've set up R to work so smoothly with
>>> Miktex-- even a total Latex bunny like me got it to work instantly, so
>>> that for the first time I'm able to run my Rd files through the Latex
>>> side of RCMD CHECK.
>>>
>>> Now the question/buglet. One of my Rd files contains the following:
>>>
>>> \code{mlazy( <<objname1>>, <<objname2>>, <<etc>>)}
>>>
>>> When I run the file through RCMD (either RCMD CHECK or Rcmd Rd2dvi
>>> --pdf) the first << and >> are left alone, but the second and third
>>> pairs are converted to single guillemot characters (i.e. European
>>> quotation marks). This inconsistency seems a bit odd.
>>
>> Yes, this is the tex that gets output:
>>
>> \code{mlazy( <{}<objname1>{}>, <<objname2>>, <<etc>>)}
>>
>> This seems to happen in Rdconv.pm, around here:
>>
>>     ## avoid conversion to guillemots
>>     $c =~ s/<</<\{\}</;
>>     $c =~ s/>>/>\{\}>/;
>>
>>
>> But I don't know enough Perl syntax to tell it to replace all << by
>> <{}<, instead of just the first.  (I would have guessed appending a g
>> would work, but didn't in a quick test, i.e. $c =~ s/<</<\{\}</g; didn't
>> work.)
>>
>> Duncan Murdoch
>>
>>>
>>> Also, is there any way of getting RCMD to leave << and >> alone-- i.e.
>>> not to guillemotize them? They cause unrecognized characters on my
>>> (Windows XP, newly-installed Miktex, R-alpha of 10/9/2005) system when I
>>> run the dvi files through dvips.
>>>
>>> Thanks
>>>
>>> Mark Bravington
>>> CSIRO Mathematical & Information Sciences
>>> Marine Laboratory
>>> Castray Esplanade
>>> Hobart 7001
>>> TAS
>>>
>>> ph (+61) 3 6232 5118
>>> fax (+61) 3 6232 5012
>>> mob (+61) 438 315 623
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From Ted.Harding at nessie.mcc.ac.uk  Fri Sep 16 23:51:24 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 16 Sep 2005 22:51:24 +0100 (BST)
Subject: [Rd] Typo [Was:  Rd and guillemots]
In-Reply-To: <432B09A0.1090607@stats.uwo.ca>
Message-ID: <XFMail.050916225124.Ted.Harding@nessie.mcc.ac.uk>

On 16-Sep-05 Duncan Murdoch wrote:
> [...]
> This seems to happen in Rdconv.pm, around here:
> 
>      ## avoid conversion to guillemots
>      $c =~ s/<</<\{\}</;
>      $c =~ s/>>/>\{\}>/;

The name of the "continental" quotation mark ? is "guillemet".

The R Development Core Team must have had some bird on the brain
at the time ...

Ted.



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Sep-05                                       Time: 22:51:19
------------------------------ XFMail ------------------------------


From tlumley at u.washington.edu  Sat Sep 17 01:16:51 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 16 Sep 2005 16:16:51 -0700 (PDT)
Subject: [Rd] Typo [Was:  Rd and guillemots]
In-Reply-To: <XFMail.050916225124.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050916225124.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.63a.0509161611310.6007@homer24.u.washington.edu>

On Fri, 16 Sep 2005, Ted.Harding at nessie.mcc.ac.uk wrote:
>
> The name of the "continental" quotation mark ? is "guillemet".
>

For anyone who is still confused:

Left pointing guillemet (U+00BB)
http://www.mathmlcentral.com/characters/glyphs/LeftGuillemet.html

Left pointing guillemot (Uria aalge)
http://www.rspb.org.uk/scotland/action/disaster/index.asp

Right pointing guillemet: (Unicode U+00AB)
http://www.mathmlcentral.com/characters/glyphs/RightGuillemet.html

Right pointing guillemot: (Uria aalge)
http://www.yptenc.org.uk/docs/factsheets/animal_facts/guillemot.html


 	-thomas

From tlumley at u.washington.edu  Sat Sep 17 01:25:15 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 16 Sep 2005 16:25:15 -0700 (PDT)
Subject: [Rd] Typo [Was:  Rd and guillemots]
In-Reply-To: <Pine.LNX.4.63a.0509161611310.6007@homer24.u.washington.edu>
References: <XFMail.050916225124.Ted.Harding@nessie.mcc.ac.uk>
	<Pine.LNX.4.63a.0509161611310.6007@homer24.u.washington.edu>
Message-ID: <Pine.LNX.4.63a.0509161621490.6007@homer24.u.washington.edu>

On Fri, 16 Sep 2005, Thomas Lumley wrote:

> On Fri, 16 Sep 2005, Ted.Harding at nessie.mcc.ac.uk wrote:
>> 
>> The name of the "continental" quotation mark  is "guillemet".
>> 
>
> For anyone who is still confused:

It should perhaps be noted that the Postscript name for the Unicode "Left 
pointing guillemet" is guillemotleft, which explains some of the 
confusion.  There does not seem to be a Postscript name for "Left pointing 
guillemot"

 	-thomas

From ripley at stats.ox.ac.uk  Sat Sep 17 09:47:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Sep 2005 08:47:34 +0100 (BST)
Subject: [Rd] Typo [Was:  Rd and guillemots]
In-Reply-To: <XFMail.050916225124.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050916225124.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.61.0509170836490.13510@gannet.stats>

On Fri, 16 Sep 2005 Ted.Harding at nessie.mcc.ac.uk wrote:

> On 16-Sep-05 Duncan Murdoch wrote:
>> [...]
>> This seems to happen in Rdconv.pm, around here:
>>
>>      ## avoid conversion to guillemots
>>      $c =~ s/<</<\{\}</;
>>      $c =~ s/>>/>\{\}>/;
>
> The name of the "continental" quotation mark ? is "guillemet".
>
> The R Development Core Team must have had some bird on the brain
> at the time ...

I don't think any authority agrees with Ted here. There are two 
characters, left and right.  Collectively it seems agreed they are called 
guillemets, but the issue is over the names of the single characters, and 
the character shown is the left guillem[eo]t.

Adobe says these are left and right guillemot.  It seems that the 
majority opinion does not agree, but there is a substantial usage 
following Adobe.

I had already changed the R source code, so please Ted and others follow 
the advice in the posting guide and

*** check the current sources before posting alleged bugs ***

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Ted.Harding at nessie.mcc.ac.uk  Sat Sep 17 12:02:03 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 17 Sep 2005 11:02:03 +0100 (BST)
Subject: [Rd] Typo [Was:  Rd and guillemots]
In-Reply-To: <Pine.LNX.4.61.0509170836490.13510@gannet.stats>
Message-ID: <XFMail.050917110203.Ted.Harding@nessie.mcc.ac.uk>

On 17-Sep-05 Prof Brian Ripley wrote:
> On Fri, 16 Sep 2005 Ted.Harding at nessie.mcc.ac.uk wrote:
> 
>> On 16-Sep-05 Duncan Murdoch wrote:
>>> [...]
>>> This seems to happen in Rdconv.pm, around here:
>>>
>>>      ## avoid conversion to guillemots
>>>      $c =~ s/<</<\{\}</;
>>>      $c =~ s/>>/>\{\}>/;
>>
>> The name of the "continental" quotation mark ? is "guillemet".
>>
>> The R Development Core Team must have had some bird on the brain
>> at the time ...
> 
> I don't think any authority agrees with Ted here. There are two 
> characters, left and right.

Agreed I only gave one instance. Either ? or ? is a guillemet.

As to "any authority", it depends what you mean by "authority".

1. Take any good French dictionary (e.g. Collins "Robert").
   Look up [Fr]"guillemet": --> [En]"quotation mark, inverted comma".
   Look up [En]"quotation mark": --> [Fr]"guillemet".

   There is a phrase "entre guillemets": --> "in quotation marks"
   or "in quotes", and vice versa.

   Look up [Fr]"guillemot": --> [En]"guillemot" and vice versa.

2. Take a good book on printing/typographical matters, e.g. "The
   Chicago Manual of Style" which is very comprehensive.

   Index: "guillemets" [the entry is in the plural]: -> 9.22-26
   "Small angle marks called guillemets (??) are used for quotation
   marks ..."

   Index: "guillemot": --> nothing found.

It's not as straightforward as that, however! In French, "guillemet"
is in fact used generically for "quotation mark" and, typographically,
includes not only the marks ? and ? we are talking bout, but also
the marks used for similar purposes in "non-continental" typography.

So the opening double quote `` (e.g. in Times Roman) and closing ''
(sorry, can't make these marks in email) are also "guillemets".
Indeed we have [note the singular] "guillemet anglais ouvrant" (``),
"guillemet anglais fermant" (''), as well as "guillemet fran?ais
ouvrant" (?), "guillemet fran?ais fermant (?); not to mention the
fact that a "guillemet fran?ais" e.g. ? consists of two "chevrons"
and one can also have a "chevron ouvrant" consisting of just one
of these (can't do this either) which is also called a "guillemet
fran?ais simple ouvrant" (in PostScript "guilsingleft"), etc. And
there is (as in Courier font) the guillemet dactylographique
= typewriter quotation mark ("). And lots of other variants.

Rather than sink in the morass of French-speaking usage, we might
be better off referring to an authority closer to the sort of usage
that concerns us, So I've had a look at the Unicode Standard,
specifically

  http://www.unicode.org/Public/UNIDATA/NamesList.txt

where one can find

  00AB    LEFT-POINTING DOUBLE ANGLE QUOTATION MARK
          = LEFT POINTING GUILLEMET
          = chevrons (in typography)
          * usually opening, sometimes closing

  00BB    RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK
          = RIGHT POINTING GUILLEMET
          * usually closing, sometimes opening

  2039    SINGLE LEFT-POINTING ANGLE QUOTATION MARK
          = LEFT POINTING SINGLE GUILLEMET
          * usually opening, sometimes closing

  203A    SINGLE RIGHT-POINTING ANGLE QUOTATION MARK
          = RIGHT POINTING SINGLE GUILLEMET
          * usually closing, sometimes opening

but no guillemots!

> Collectively it seems agreed they are called guillemets, but the
> issue is over the names of the single characters, and the character
> shown is the left guillem[eo]t.

See above ...

> Adobe says these are left and right guillemot.  It seems that the 
> majority opinion does not agree, but there is a substantial usage 
> following Adobe.

That is certainly a matter of fact! And it is certainly thus in
Adobe's PostScript Language Reference Manual (see e.g. Standard
Roman Character Set in Appendix E, "Standard Character Sets and
Encoding Vectors"). So that is what must be used when invoking
them in PostScript. However, I am firmly of the view that Adobe
made an error when they gave these things the names "guillemotleft"
and "guillemotright".

> I had already changed the R source code, so please Ted and others
> follow the advice in the posting guide and
> 
> *** check the current sources before posting alleged bugs ***

Easier said than done ... However, I apologise!

Nevertheless, apart from the issue of a possible "R bug", I think
it is worth putting the record straight on the general issue of
nomenclature.

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 17-Sep-05                                       Time: 10:51:17
------------------------------ XFMail ------------------------------


From Ted.Harding at nessie.mcc.ac.uk  Sat Sep 17 12:02:03 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 17 Sep 2005 11:02:03 +0100 (BST)
Subject: [Rd] Typo [Was:  Rd and guillemots]
In-Reply-To: <Pine.LNX.4.63a.0509161611310.6007@homer24.u.washington.edu>
Message-ID: <XFMail.050917110203.Ted.Harding@nessie.mcc.ac.uk>

On 16-Sep-05 Thomas Lumley wrote:
> On Fri, 16 Sep 2005, Ted.Harding at nessie.mcc.ac.uk wrote:
>>
>> The name of the "continental" quotation mark ? is "guillemet".
>>
> 
> For anyone who is still confused:
> 
> Left pointing guillemet (U+00BB)
> http://www.mathmlcentral.com/characters/glyphs/LeftGuillemet.html
> 
> Left pointing guillemot (Uria aalge)
> http://www.rspb.org.uk/scotland/action/disaster/index.asp
> 
> Right pointing guillemet: (Unicode U+00AB)
> http://www.mathmlcentral.com/characters/glyphs/RightGuillemet.html
> 
> Right pointing guillemot: (Uria aalge)
> http://www.yptenc.org.uk/docs/factsheets/animal_facts/guillemot.html
> 
> 
>       -thomas

Very nice one, Thomas! Also your follow-up. Nice pictures too.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 17-Sep-05                                       Time: 11:01:57
------------------------------ XFMail ------------------------------


From maechler at stat.math.ethz.ch  Sat Sep 17 17:37:32 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 17 Sep 2005 17:37:32 +0200
Subject: [Rd] loadings()   generic in R alpha
In-Reply-To: <432B0935.5090208@bank-banque-canada.ca>
References: <4329B504.3020209@bank-banque-canada.ca>
	<Pine.LNX.4.61.0509160855171.31294@gannet.stats>
	<432AF840.2030403@bank-banque-canada.ca>
	<Pine.WNT.4.58.0509161800290.1472@Petrel>
	<432B0935.5090208@bank-banque-canada.ca>
Message-ID: <17196.14396.218418.507492@deb8.math.ethz.ch>


>>>>> "PaulG" == Paul Gilbert <pgilbert at bank-banque-canada.ca>
>>>>>     on Fri, 16 Sep 2005 14:04:37 -0400 writes:

    PaulG> Brian Ok, lets leave this for now. When does the
    PaulG> development cycle start for the next version that
    PaulG> would allow making a function generic?

Almost immediately after 2.2.0 is released.

    PaulG> Paul

    PaulG> Prof Brian D Ripley wrote:

    >> On Fri, 16 Sep 2005, Paul Gilbert wrote:
    >> 
    >> 
    >> 
    >>> Brian
    >>> 
    >>> It would help if I understood general principles. I
    >>> thought one would want a case for NOT making functions
    >>> generic, rather than a case for making them
    >>> generic. Hopefully a case for why generics and methods
    >>> are useful will not be necessary.
    >>> 
    >>> 
    >>  Making things generic
    >> 
    >> 1) adds runtime cost
    >> 
    >> 2) essentially fixes the signature for all time
    >> 
    >> 3) needs the return value sufficiently well defined that
    >> all current uses will not be broken by a new method.
    >> (This was not a problem with e.g.  as.ts as everone knows
    >> the result should be a "ts" object.  But I think it is a
    >> problem with acf and loadings.)
    >> 
    >> I would for example be unhappy with your definition of
    >> loadings() as it has no ... argument (and S-PLUS has one
    >> in its loadings() generic).
    >> 
    >> So cases are necessary.  I am pretty sure that we have in
    >> the past agreed that making a function generic is a Grand
    >> Feature, and we are in GFF.
    >> 
    >> 
    >> 
    >> 
    >>> The situation with loadings() is that I construct
    >>> objects where the loadings are in a list within a list,
    >>> so the simple definition in stats does not work:
    >>> 
    >>> loadings function (x) x$loadings <environment:
    >>> namespace:stats>
    >>> 
    >>> Basically this definition restricts the way in which
    >>> objects can be constructed, so I would like it replaced
    >>> by
    >>> 
    >>> loadings <- function (x) UseMethod("loadings")
    >>> loadings.default <- function (x) x$loadings
    >>> 
    >>> There may be a reason for adding a ... argument, but I
    >>> have been using this generic and methods for it in my
    >>> own work for a fairly long time now and have not
    >>> discovered one.  The change seems rather trivial, I have
    >>> tested it extensively with my own code, and there is a
    >>> fairly complete test suite in place for checking changes
    >>> to R, so it seems reasonable to me that this should be
    >>> considered as a change that is possible in an alpha
    >>> release. It would also be fairly easy to back out of if
    >>> there are problems.
    >>> 
    >>> The reason for needing acf generic is the same, so that
    >>> it can be use with more complicated objects that I
    >>> construct. However, I see here that there are
    >>> potentially more difficult problems, because the
    >>> ... argument to the current acf (which one would want as
    >>> the default method) is passed to plot.acf.  Here I can
    >>> clearly see the reason for wanting to start
    >>> consideration of this at an earlier point in the
    >>> development cycle.
    >>> 
    >>> Best, Paul
    >>> 
    >>> Prof Brian Ripley wrote:
    >>> 
    >>> 
    >>> 
    >>>> On Thu, 15 Sep 2005, Paul Gilbert wrote (in two
    >>>> separate messages)
    >>>> 
    >>>> 
    >>>> 
    >>>>> Could loadings() in R-2.2.0 please be made generic?
    >>>>> 
    >>>>> 
    >>>>
    >>>>> Could acf() in R-2.2.0 please be made generic?
    >>>>> 
    >>>>> 
    >>>> I think it is too late in the process for this (and
    >>>> especially for acf). In particular, it could have
    >>>> knock-on consequences for packages and recommended
    >>>> packages are scheduled to be all fixed in stone by next
    >>>> Weds.
    >>>> 
    >>>> To consider making such functions generic we would need
    >>>> 
    >>>> - a case - discussion of what the arguments of the
    >>>> generic should be and what is to be specified about the
    >>>> return value.
    >>>> 
    >>>> Perhaps you could raise these again with specific
    >>>> proposals early in the developement cycle for 2.3.0.
    >>>> 
    >>>> (We have been a little too casual about speciying what
    >>>> generic functions should return in the past, and have
    >>>> got bitten as a result.  For example, can it be assumed
    >>>> that loadings() returns a matrix?)
    >>>> 
    >>>> 

    PaulG> ______________________________________________
    PaulG> R-devel at r-project.org mailing list
    PaulG> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat Sep 17 17:29:20 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 17 Sep 2005 17:29:20 +0200
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <17194.30238.436418.752419@stat.math.ethz.ch>
References: <17190.57225.254938.977464@stat.math.ethz.ch>
	<17194.30238.436418.752419@stat.math.ethz.ch>
Message-ID: <17196.13904.78468.758438@deb8.math.ethz.ch>


>>>>> "Wst" == Werner Stahel <stahel at stat.math.ethz.ch>
>>>>>     on Fri, 16 Sep 2005 09:37:02 +0200 writes:

    Wst> Dear Martin, dear Johns Thanks for including me into
    Wst> your discussion.

    Wst> I am a strong supporter of "Residuals vs. Hii"

    >>> One remaining problem I'd like to address is the
    >>> "balanced AOV" situation, ...

    Wst> In order to keep the plots consistent, I suggest to
    Wst> draw a histogram. Other alternatives will or can be
    Wst> interesting in the general case and therefore are not a
    Wst> suitable substitute for this plot.

hmm, but all other 3 default plots have
 (standardized / sqrt) residuals  on the y-axis.
I'd very much like to keep that for any forth plot.
So would we want a horizontal histogram?  And do we really want
a histogram when we've already got the QQ plot?

We need a decent proposal for a 4th plot 
{instead of  R_i vs h_ii  , when  h_ii are constant}
REAL SOON NOW  since it's feature
freeze on Monday. 
Of course the current state can be declared a bug and still be
fixed but that was not the intention...

Also, there are now at least 2 book authors among R-core (and
more book authors more generally!) in whose books there are
pictures with the "old-default" 4th plot. 
So I'd like to have convincing reasons for ``deprecating'' all 
the plot.lm() pictures in the published books.

At the moment, I'd still  go for
 
         R_i  vs i
or  sqrt|R_i| vs i  -- possibly with type = 'h' 

which could be used to "check" an important kind of "temporal" 
auto-correlation.

the latter, because in a 2 x 2 plot arrangement, this gives the
same y-axis as default plot 3.

    Wst> ........................

    Wst> Back to currently available methods:

    Wst> John Maindonald discusses different contours. I like
    Wst> the implementation I get currently in R-devel: contours
    Wst> of Cook's distances, since they are popular and we can
    Wst> then argue that the plot of D_i vs. i is no more
    Wst> needed.

what about John's proposal of different contour levels than
c(0.5, 1)  -- note that these *have* been added as arguments to
plot.lm() a user could modify.

    Wst> For most plots, I like to see a smoother along with the
    Wst> points.  I suggest to add the option to include
    Wst> smoothers, not only as an argument to plot.lm, but even
    Wst> as an option().  I have heared of the intense
    Wst> discussions about options().  With Martin, we arrived
    Wst> at the conclusion that options() should never influence
    Wst> calculations and results, but is suitable to adjust
    Wst> outputs (numerical: digits=, graphical: smooth=) to the
    Wst> user's taste.

{and John Fox agreed, `in general'}

That could be a possibility, for 2.2.0  only applied to
plot.lm() in any case, where plot.lm() would get a new argument

    add.smooth = getOption("plot.add.smooth")

What do people think about the name? 
it would ``stick with us'' -- so we better choose it well..

    >>> (4) Are there other diagnostics that ought to be
    >>> included in stats? (perhaps in a function other than
    >>> plot.lm(), which risks being overloaded).  One strong
    >>> claiment is vif() (variance inflation factor),

   ...................
   ...................
   ...................


    Wst> As we focus on plots, my plot method includes the
    Wst> option (default) to add smooths for 20 simulated
    Wst> datasets (according to the fitted model).

this and others are really nice.

However not for R 2.2.x in any case.

I agree that one should rather provide `single-plot'
functions and have plot.lm() just call a few of them; instead of
having things all part of plot.lm().
There's the slight advantage that you can guarantee some
consistence (e.g. in the definition of "standardized residuals")
and save some computations when have everything in one function,
but consistency should be possible otherwise as well...
Anyway this is for 2.3.0 or later.

Martin


From charlie at stat.umn.edu  Sun Sep 18 00:19:02 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Sat, 17 Sep 2005 17:19:02 -0500
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <mailman.9.1126951201.11292.r-devel@r-project.org>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
Message-ID: <20050917221902.GA10806@stat.umn.edu>

I can't compile R-alpha on AMD 64.  Rather than include a 1400 line script
I have put it on the web

    http://www.stat.umn.edu/~charlie/typescript.txt

way down near the bottom it fails building lapack.so

    gcc -shared -L/usr/local/lib64 -o lapack.so  Lapack.lo    -llapack -lblas -lg2c -lm -lgcc_s
    /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../x86_64-suse-linux/bin/ld: /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a(dgecon.i): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
    /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a: could not read symbols: Bad value

The 'recompile with -fPIC' is bullsh*t.  The problem is that is is looking
in /usr/lib64/liblapack.a rather than /usr/lib64/liblapack.so.3 both of which
exist.  Some searching for this error message on Google shows a lot of
questions about this problem but no solution that I found other than

    rm /usr/lib64/liblapack.a

which I don't consider a solution.  It will link with the .so as the bottom
of the script shows

    snowbank$ cd src/modules/lapack
    snowbank$ gcc -shared -o lapack.so Lapack.lo -llapack -lblas -lg2c -lm -lgcc_s
    /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../x86_64-suse-linux/bin/ld: /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a(dgecon.i): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
    /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a: could not read symbols: Bad value
    collect2: ld returned 1 exit status
    snowbank$ gcc -shared -o lapack.so Lapack.lo /usr/lib64/liblapack.so.3 -lblas -l g2c -lm -lgcc_s

No problems with the second link.

So what do I do?  liblapack.so is there.  I've linked other (non-R) programs
to it.  So it SHOULD work with R.

Either I can't read (possible) or the solution to this isn't in the gcc info
pages.

System (more info in typescript).

   AMD 64
   SuSE linux 9.3
   GCC 3.3.5

I also observed the same problem with R-2.1.1 but didn't get around to
debugging it until today.

It occurred to me that /usr/local/lib/liblapack.so.3 which is 32 bit
(because right now we are running only one R on both 32 and 64 bit and
that's where the 32 bit R finds it's shared libraries), but I don't
think that's the problem.  Well maybe it is.  How do I tell configure
NOT to add /user/local ?
-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie at stat.umn.edu


From john.maindonald at anu.edu.au  Sun Sep 18 04:28:41 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 18 Sep 2005 12:28:41 +1000
Subject: [Rd] plot(<lm>): new behavior in R-2.2.0 alpha
In-Reply-To: <17196.13904.78468.758438@deb8.math.ethz.ch>
References: <17190.57225.254938.977464@stat.math.ethz.ch>
	<17194.30238.436418.752419@stat.math.ethz.ch>
	<17196.13904.78468.758438@deb8.math.ethz.ch>
Message-ID: <A6A9F6A1-5E67-4D50-9DF9-DCBD429739C4@anu.edu.au>

Martin -
Thanks for your efforts in initiating and managing this
discussion.

As for the issue of deprecating the plot.lm() pictures in
the published books, surely this will have great benefits
for the authors. It will help them to sell the new editions
of their books that will in due course appear replete with
the new plots!

For 2.2.0, I have nothing more to add to the comments
others have made,  I hope we can in due course agree,
as a minimum, to put some version of John Fox's vif(),
and something akin to Werner Stahl's smooths for up to
20 simulated data sets, into 2.3.0
John Maindonald.

On 18 Sep 2005, at 1:29 AM, Martin Maechler wrote:

>>>>>> "Wst" == Werner Stahel <stahel at stat.math.ethz.ch>
>>>>>>     on Fri, 16 Sep 2005 09:37:02 +0200 writes:
>>>>>>
>
>     Wst> Dear Martin, dear Johns Thanks for including me into
>     Wst> your discussion.
>
>     Wst> I am a strong supporter of "Residuals vs. Hii"
>
>
>>>> One remaining problem I'd like to address is the
>>>> "balanced AOV" situation, ...
>>>>
>
>     Wst> In order to keep the plots consistent, I suggest to
>     Wst> draw a histogram. Other alternatives will or can be
>     Wst> interesting in the general case and therefore are not a
>     Wst> suitable substitute for this plot.
>
> hmm, but all other 3 default plots have
>  (standardized / sqrt) residuals  on the y-axis.
> I'd very much like to keep that for any forth plot.
> So would we want a horizontal histogram?  And do we really want
> a histogram when we've already got the QQ plot?
>
> We need a decent proposal for a 4th plot
> {instead of  R_i vs h_ii  , when  h_ii are constant}
> REAL SOON NOW  since it's feature
> freeze on Monday.
> Of course the current state can be declared a bug and still be
> fixed but that was not the intention...
>
> Also, there are now at least 2 book authors among R-core (and
> more book authors more generally!) in whose books there are
> pictures with the "old-default" 4th plot.
> So I'd like to have convincing reasons for ``deprecating'' all
> the plot.lm() pictures in the published books.
>
> At the moment, I'd still  go for
>
>          R_i  vs i
> or  sqrt|R_i| vs i  -- possibly with type = 'h'
>
> which could be used to "check" an important kind of "temporal"
> auto-correlation.
>
> the latter, because in a 2 x 2 plot arrangement, this gives the
> same y-axis as default plot 3.
>
>     Wst> ........................
>
>     Wst> Back to currently available methods:
>
>     Wst> John Maindonald discusses different contours. I like
>     Wst> the implementation I get currently in R-devel: contours
>     Wst> of Cook's distances, since they are popular and we can
>     Wst> then argue that the plot of D_i vs. i is no more
>     Wst> needed.
>
> what about John's proposal of different contour levels than
> c(0.5, 1)  -- note that these *have* been added as arguments to
> plot.lm() a user could modify.
>
>     Wst> For most plots, I like to see a smoother along with the
>     Wst> points.  I suggest to add the option to include
>     Wst> smoothers, not only as an argument to plot.lm, but even
>     Wst> as an option().  I have heared of the intense
>     Wst> discussions about options().  With Martin, we arrived
>     Wst> at the conclusion that options() should never influence
>     Wst> calculations and results, but is suitable to adjust
>     Wst> outputs (numerical: digits=, graphical: smooth=) to the
>     Wst> user's taste.
>
> {and John Fox agreed, `in general'}
>
> That could be a possibility, for 2.2.0  only applied to
> plot.lm() in any case, where plot.lm() would get a new argument
>
>     add.smooth = getOption("plot.add.smooth")
>
> What do people think about the name?
> it would ``stick with us'' -- so we better choose it well..
>
>
>>>> (4) Are there other diagnostics that ought to be
>>>> included in stats? (perhaps in a function other than
>>>> plot.lm(), which risks being overloaded).  One strong
>>>> claiment is vif() (variance inflation factor),
>>>>
>
>    ...................
>    ...................
>    ...................
>
>
>     Wst> As we focus on plots, my plot method includes the
>     Wst> option (default) to add smooths for 20 simulated
>     Wst> datasets (according to the fitted model).
>
> this and others are really nice.
>
> However not for R 2.2.x in any case.
>
> I agree that one should rather provide `single-plot'
> functions and have plot.lm() just call a few of them; instead of
> having things all part of plot.lm().
> There's the slight advantage that you can guarantee some
> consistence (e.g. in the definition of "standardized residuals")
> and save some computations when have everything in one function,
> but consistency should be possible otherwise as well...
> Anyway this is for 2.3.0 or later.
>
> Martin
>


From briaskan at boafans.com  Sun Sep 18 09:24:13 2005
From: briaskan at boafans.com (briaskan@boafans.com)
Date: Sun, 18 Sep 2005 09:24:13 +0200 (CEST)
Subject: [Rd] Be given a significant markdown on your RX-Meds (PR#8140)
Message-ID: <20050918072413.683D41C697@slim.kubism.ku.dk>


Take delivery of a great concession on your Meds-RX
Name brands, Finest quality.
Vast  variety,  including Difficult to find drugs
0 RX needed.
Private with No waiting quarters or appointments required
Shipped within 21 hours or under, discrete boxing
Purchase in bulk and Save! Still additional

http://uk.geocities.com/hanho_keeffes/?ms=05No prescription needed.


Have you ze luggage? No; but I'll pay in advance, said Rob, and began
counting out his dimes and nickles and pennies, to the unbounded amazement
of the waiter, who looked as if he had never seen such coins before. He
carried the money to the fat gentleman, who examined the pieces curiously,
and there was a long conference between them before it was decided to accept
them in payment for a room for a day
But at this season the hotel was almost empty, and when Rob protested that
he had no other money the fat gentleman put the coins into his cash box with
a resigned sigh and the waiter showed the boy to a little room at the very
top of the building


From ulrich.poetter at ruhr-uni-bochum.de  Sun Sep 18 17:37:44 2005
From: ulrich.poetter at ruhr-uni-bochum.de (ulrich.poetter@ruhr-uni-bochum.de)
Date: Sun, 18 Sep 2005 17:37:44 +0200 (CEST)
Subject: [Rd] as.data.frame segfaults on large lists (PR#8141)
Message-ID: <20050918153744.AB3C0CC03@slim.kubism.ku.dk>

Full_Name: Ulrich Poetter
Version: 2.1.1
OS: i686-pc-linux-gnu FC2
Submission from: (NULL) (134.147.95.187)


as.data.frame() segfaults on lists with very many elements:

> dfn <- rep(list(rep(0,2)),198000)
> test <- as.data.frame.list(dfn)

Process R segmentation fault at Sun Sep 18 17:06:02 2005


From p.dalgaard at biostat.ku.dk  Sun Sep 18 18:50:47 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Sep 2005 18:50:47 +0200
Subject: [Rd] as.data.frame segfaults on large lists (PR#8141)
In-Reply-To: <20050918153744.AB3C0CC03@slim.kubism.ku.dk>
References: <20050918153744.AB3C0CC03@slim.kubism.ku.dk>
Message-ID: <x2ll1u48wo.fsf@turmalin.kubism.ku.dk>

ulrich.poetter at ruhr-uni-bochum.de writes:

> Full_Name: Ulrich Poetter
> Version: 2.1.1
> OS: i686-pc-linux-gnu FC2
> Submission from: (NULL) (134.147.95.187)
> 
> 
> as.data.frame() segfaults on lists with very many elements:
> 
> > dfn <- rep(list(rep(0,2)),198000)
> > test <- as.data.frame.list(dfn)
> 
> Process R segmentation fault at Sun Sep 18 17:06:02 2005

Not for me on FC4. The process size grows to about 180M and the system
thrashes badly, but the calculation runs to completion.

It's not unlikely that we are ignoring a failed allocation somewhere,
but there's not much hope of finding it from the available
information. You could try running under gdb and see where things go
wrong for you.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ulrich.poetter at ruhr-uni-bochum.de  Sun Sep 18 19:54:37 2005
From: ulrich.poetter at ruhr-uni-bochum.de (Ulrich Poetter)
Date: Sun, 18 Sep 2005 19:54:37 +0200
Subject: [Rd] as.data.frame segfaults on large lists (PR#8141)
In-Reply-To: <x2ll1u48wo.fsf@turmalin.kubism.ku.dk>
References: <20050918153744.AB3C0CC03@slim.kubism.ku.dk>
	<x2ll1u48wo.fsf@turmalin.kubism.ku.dk>
Message-ID: <17197.43485.477171.842775@borel.stat.ruhr-uni-bochum.de>

Peter Dalgaard writes:
 > ulrich.poetter at ruhr-uni-bochum.de writes:
 > 
 > > Full_Name: Ulrich Poetter
 > > Version: 2.1.1
 > > OS: i686-pc-linux-gnu FC2
 > > Submission from: (NULL) (134.147.95.187)
 > > 
 > > 
 > > as.data.frame() segfaults on lists with very many elements:
 > > 
 > > > dfn <- rep(list(rep(0,2)),198000)
 > > > test <- as.data.frame.list(dfn)
 > > 
 > > Process R segmentation fault at Sun Sep 18 17:06:02 2005
 > 
 > Not for me on FC4. The process size grows to about 180M and the system
 > thrashes badly, but the calculation runs to completion.
 > 
 > It's not unlikely that we are ignoring a failed allocation somewhere,
 > but there's not much hope of finding it from the available
 > information. You could try running under gdb and see where things go
 > wrong for you.
gdb says:

 dfn <- rep(list(rep(0,2)),198000)
 test <- as.data.frame.list(dfn)

Program received signal SIGSEGV, Segmentation fault.
0x08082416 in Rf_substituteList (el=0xa1c5634, rho=0x83ea668)
    at coerce.c:1973
1973	coerce.c: No such file or directory.
	in coerce.c
(gdb) bt
#0  0x08082416 in Rf_substituteList (el=0xa1c5634, rho=0x83ea668)
    at coerce.c:1973
[snip]
(I don't have the source handy). I have forgotten to say that R was
compiled with gcc 3.3.3.

All the best,
Ulrich Poetter


From waldo at parspage.com  Sun Sep 18 20:17:16 2005
From: waldo at parspage.com (waldo@parspage.com)
Date: Sun, 18 Sep 2005 20:17:16 +0200 (CEST)
Subject: [Rd] Receive a significant discount on your medications (PR#8142)
Message-ID: <20050918181716.B21571C698@slim.kubism.ku.dk>


Obtain a great deduction on your prescriptions
Name brands, Finest quality.
Big  range,  including challenging to find drugs
No previous doctors direction needed.
Secret with No waiting rooms or appointmnets required
Shipped within 24 hours or less, discrete packaging
Acquire in bulk and Save! Even more

http://uk.geocities.com/janise_chlick/?w=021186No prescription needed.


A big battle was being fought in the Philippines, and so fiercely was it
contested that Rob watched its progress for hours, with rapt attention.
Finally a brave rally by the Americans sent their foes to the cover of the
woods, where they scattered in every direction, only to form again in a deep
valley hidden by high hills
If only I was there, thought Rob, I could show that captain where to find
the rebels and capture them


From dhinds at sonic.net  Sun Sep 18 22:18:39 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Sun, 18 Sep 2005 20:18:39 +0000 (UTC)
Subject: [Rd] Updated rawConnection() patch
Message-ID: <dgki2u$6ba$1@sea.gmane.org>

Here's an update of my rawConnection() implementation.  In addition to
providing a raw version of textConnection(), this fixes two existing
issues with textConnection(): one is that the current textConnection()
implementation carries around unprotected SEXP pointers, the other is
a performance problem due to prolific copying of the output buffer as
output is accumulated line by line.

This new version uses a separate buffer for connection output, which
is extended in larger chunks, so that resize operations are less
frequent.  And the buffer is hidden behind an active binding, so that
the user can't corrupt it.

My original need for this is largely addressed by Brian Ripley's
recent extension of readBin/writeBin to operate on raw vectors as well
as connections, in the latest development tree.  But I think having a
raw version of textConnection is still a bit more orthogonal and
flexible, and requires very little code.

-- Dave


--- ./src/include/Internal.h.orig	2005-08-29 17:47:27.000000000 -0700
+++ ./src/include/Internal.h	2005-09-18 00:32:08.196336200 -0700
@@ -525,6 +525,7 @@
 SEXP do_pushbacklength(SEXP, SEXP, SEXP, SEXP);
 SEXP do_clearpushback(SEXP, SEXP, SEXP, SEXP);
 SEXP do_textconnection(SEXP, SEXP, SEXP, SEXP);
+SEXP do_graboutput(SEXP, SEXP, SEXP, SEXP);
 SEXP do_getallconnections(SEXP, SEXP, SEXP, SEXP);
 SEXP do_sumconnection(SEXP, SEXP, SEXP, SEXP);
 SEXP do_download(SEXP, SEXP, SEXP, SEXP);
--- ./src/include/Rconnections.h.orig	2005-08-03 08:50:36.000000000 -0700
+++ ./src/include/Rconnections.h	2005-09-17 23:56:01.875475000 -0700
@@ -94,8 +94,7 @@
 
 typedef struct outtextconn {
     int len;  /* number of lines */
-    SEXP namesymbol;
-    SEXP data;
+    SEXP namesymbol, data, venv;
     char *lastline;
     int lastlinelength; /* buffer size */
 } *Routtextconn;
--- ./src/library/base/man/rawconnections.Rd.orig	2005-09-18 11:37:18.004405000 -0700
+++ ./src/library/base/man/rawconnections.Rd	2005-09-18 11:37:00.535655300 -0700
@@ -0,0 +1,71 @@
+\name{rawConnection}
+\alias{rawConnection}
+\title{Raw Connections}
+\description{
+  Input and output raw connections.
+}
+\usage{
+rawConnection(object, open = "r", local = FALSE)
+}
+\arguments{
+  \item{object}{raw or character.  A description of the connection. 
+    For an input this is an \R raw vector object, and for an output
+    connection the name for the \R raw vector to receive the
+    output.
+  }
+  \item{open}{character.  Either \code{"rb"} (or equivalently \code{""})
+    for an input connection or \code{"wb"} or \code{"ab"} for an output
+    connection.}
+  \item{local}{logical.  Used only for output connections.  If \code{TRUE},
+    output is assigned to a variable in the calling environment.  Otherwise
+    the global environment is used.}
+}
+\details{
+  An input raw connection is opened and the raw vector is copied
+  at time the connection object is created, and \code{close}
+  destroys the copy.
+
+  An output raw connection is opened and creates an \R raw vector of
+  the given name in the user's workspace or in the calling
+  environment, depending on the value of the \code{local} argument.
+  This object will at all times hold the accumulated output to the
+  connection.
+
+  Opening a raw connection with \code{mode = "ab"} will attempt to
+  append to an existing raw vector with the given name in the user's
+  workspace or the calling environment.  If none is found (even if an
+  object exists of the right name but the wrong type) a new raw vector
+  wil be created, with a warning.
+
+  You cannot \code{seek} on a raw connection, and \code{seek} will
+  always return zero as the position.
+}
+
+\value{
+  A binary-mode connection object of class \code{"rawConnection"}
+  which inherits from class \code{"connection"}.
+}
+
+\seealso{
+  \code{\link{connections}}, \code{\link{showConnections}},
+  \code{\link{readBin}}, \code{\link{writeBin}},
+  \code{\link{textConnection}}.
+}
+
+\examples{
+zz <- rawConnection("foo", "wb")
+writeBin(1:2, zz)
+writeBin(1:8, zz, size=1)
+writeBin(pi, zz, size=4)
+close(zz)
+foo
+
+zz <- rawConnection(foo)
+readBin(zz, "integer", n=2)
+sprintf("\%04x", readBin(zz, "integer", n=2, size=2))
+sprintf("\%08x", readBin(zz, "integer", endian="swap"))
+readBin(zz, "numeric", n=1, size=4)
+close(zz)
+}
+\keyword{file}
+\keyword{connection}
--- ./src/library/base/man/textconnections.Rd.orig	2005-09-03 13:55:48.274305900 -0700
+++ ./src/library/base/man/textconnections.Rd	2005-09-18 11:37:03.457530300 -0700
@@ -45,16 +45,11 @@
 }
 
 \value{
-  A connection object of class \code{"textConnection"} which inherits
-  from class \code{"connection"}.
+  A text-mode connection object of class \code{"textConnection"} which
+  inherits from class \code{"connection"}.
 }
 
 \note{
-  As output text connections keep the character vector up to date
-  line-by-line, they are relatively expensive to use, and it is often
-  better to use an anonymous \code{\link{file}()} connection to collect
-  output.
-
   On platforms where \code{vsnprintf} does not return the needed length
   of output (e.g., Windows) there is a 100,000 character limit on the
   length of line for output connections: longer lines will be truncated
@@ -69,7 +64,8 @@
 
 \seealso{
   \code{\link{connections}}, \code{\link{showConnections}},
-  \code{\link{pushBack}}, \code{\link{capture.output}}.
+  \code{\link{pushBack}}, \code{\link{capture.output}},
+  \code{\link{rawConnection}}.
 }
 
 \examples{
--- ./src/library/base/R/connections.R.orig	2005-09-18 12:03:25.854437000 -0700
+++ ./src/library/base/R/connections.R	2005-09-18 11:18:50.479582300 -0700
@@ -84,9 +84,32 @@
     .Internal(socketConnection(host, port, server, blocking, open, encoding))
 
 textConnection <- function(object, open = "r", local = FALSE) {
+    if (!(open %in% c("","r","a","w")))
+        stop('unsupported mode')
     if (local) env <- parent.frame()
     else env <- .GlobalEnv
-    .Internal(textConnection(deparse(substitute(object)), object, open, env))
+    con <- .Internal(textConnection(deparse(substitute(object)),
+                                    object, open, env))
+    if (open %in% c("a", "w")) {
+        suppressWarnings(rm(list=object, envir=env))
+        makeActiveBinding(object, function(v) .Internal(grabOutput(con)), env)
+    }
+    con
+}
+
+rawConnection <- function(object, open = "rb", local = FALSE) {
+    if (open == "") open <- "rb"
+    if (!(open %in% c("rb","ab","wb")))
+        stop("unsupported mode")
+    if (local) env <- parent.frame()
+    else env <- .GlobalEnv
+    con <- .Internal(textConnection(deparse(substitute(object)),
+                                    object, open, env))
+    if (open %in% c("ab", "wb")) {
+        suppressWarnings(rm(list=object, envir=env))
+        makeActiveBinding(object, function(v) .Internal(grabOutput(con)), env)
+    }
+    con
 }
 
 seek <- function(con, ...)
--- ./src/main/connections.c.orig	2005-08-29 17:47:35.000000000 -0700
+++ ./src/main/connections.c	2005-09-18 11:54:49.752647400 -0700
@@ -59,7 +59,6 @@
 #define NSINKS 21
 
 static Rconnection Connections[NCONNECTIONS];
-static SEXP OutTextData;
 
 static int R_SinkNumber;
 static int SinkCons[NSINKS], SinkConsClose[NSINKS], R_SinkSplit[NSINKS];
@@ -76,16 +75,6 @@
     return i;
 }
 
-static int ConnIndex(Rconnection con)
-{
-    int i;
-    for(i = 0; i < NCONNECTIONS; i++)
-	if(Connections[i] == con) break;
-    if(i >= NCONNECTIONS)
-	error(_("connection not found"));
-    return i;
-}
-
 /* internal, not the same as R function getConnection */
 Rconnection getConnection(int n)
 {
@@ -1678,7 +1667,7 @@
     return ans;
 }
 
-/* ------------------- text connections --------------------- */
+/* ------------------- text and raw connections --------------------- */
 
 /* read a R character vector into a buffer */
 static void text_init(Rconnection con, SEXP text)
@@ -1702,6 +1691,22 @@
     this->cur = this->save = 0;
 }
 
+/* read a R raw vector into a buffer */
+static void raw_init(Rconnection con, SEXP raw)
+{
+    int nbytes = length(raw);
+    Rtextconn this = (Rtextconn)con->private;
+
+    this->data = (char *) malloc(nbytes);
+    if(!this->data) {
+	free(this); free(con->description); free(con->class); free(con);
+	error(_("cannot allocate memory for raw connection"));
+    }
+    memcpy(this->data, RAW(raw), nbytes);
+    this->nchars = nbytes;
+    this->cur = this->save = 0;
+}
+
 static Rboolean text_open(Rconnection con)
 {
     con->save = -1000;
@@ -1736,57 +1741,79 @@
 
 static double text_seek(Rconnection con, double where, int origin, int rw)
 {
-    if(where >= 0) error(_("seek is not relevant for text connection"));
+    if(where >= 0) error(_("seek is not relevant for this connection"));
     return 0; /* if just asking, always at the beginning */
 }
 
-static Rconnection newtext(char *description, SEXP text)
+static size_t raw_read(void *ptr, size_t size, size_t nitems,
+		       Rconnection con)
+{
+    Rtextconn this = (Rtextconn)con->private;
+    if (this->cur + size*nitems > this->nchars)
+	nitems = (this->nchars - this->cur)/size;
+    memcpy(ptr, this->data+this->cur, size*nitems);
+    this->cur += size*nitems;
+    return nitems;
+}
+
+static Rconnection newtext(char *description, SEXP data)
 {
     Rconnection new;
+    int isText = isString(data);
     new = (Rconnection) malloc(sizeof(struct Rconn));
-    if(!new) error(_("allocation of text connection failed"));
-    new->class = (char *) malloc(strlen("textConnection") + 1);
-    if(!new->class) {
-	free(new);
-	error(_("allocation of text connection failed"));
-    }
-    strcpy(new->class, "textConnection");
+    if(!new) goto f1;
+    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
+    if(!new->class) goto f2;
+    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
     new->description = (char *) malloc(strlen(description) + 1);
-    if(!new->description) {
-	free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->description) goto f3;
     init_con(new, description, "r");
     new->isopen = TRUE;
     new->canwrite = FALSE;
     new->open = &text_open;
     new->close = &text_close;
     new->destroy = &text_destroy;
-    new->fgetc = &text_fgetc;
     new->seek = &text_seek;
     new->private = (void*) malloc(sizeof(struct textconn));
-    if(!new->private) {
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
+    if(!new->private) goto f4;
+    new->text = isText;
+    if (new->text) {
+	new->fgetc = &text_fgetc;
+	text_init(new, data);
+    } else {
+	new->read = &raw_read;
+	raw_init(new, data);
     }
-    text_init(new, text);
     return new;
+
+f4: free(new->description);
+f3: free(new->class);
+f2: free(new);
+f1: error(_("allocation of %s connection failed"),
+	  isText ? "text" : "raw");
 }
 
 static void outtext_close(Rconnection con)
 {
     Routtextconn this = (Routtextconn)con->private;
-    SEXP tmp;
-    int idx = ConnIndex(con);
+    SEXP tmp, rm;
 
     if(strlen(this->lastline) > 0) {
-	PROTECT(tmp = lengthgets(this->data, ++this->len));
-	SET_STRING_ELT(tmp, this->len - 1, mkChar(this->lastline));
-	defineVar(this->namesymbol, tmp, VECTOR_ELT(OutTextData, idx));
-	this->data = tmp;
+	PROTECT(tmp = lengthgets(this->data, this->len+1));
+	SET_STRING_ELT(tmp, this->len, mkChar(this->lastline));
+    } else {
+	PROTECT(tmp = lengthgets(this->data, this->len));
+    }
+    /* remove current binding, then install result */
+    if (R_BindingIsActive(this->namesymbol, this->venv)) {
+	PROTECT(rm = lang2(install("rm"), this->namesymbol));
+	eval(rm, this->venv);
 	UNPROTECT(1);
     }
-    SET_VECTOR_ELT(OutTextData, idx, R_NilValue);
+    defineVar(this->namesymbol, tmp, this->venv);
+    UNPROTECT(1);
+    R_ReleaseObject(this->venv);
+    R_ReleaseObject(this->data);
 }
 
 static void outtext_destroy(Rconnection con)
@@ -1795,6 +1822,17 @@
     free(this->lastline); free(this);
 }
 
+static void outtext_grow(Routtextconn this, int need)
+{
+    SEXP tmp = this->data;
+    int len = length(tmp);
+    if (this->len + need > len) {
+	this->data = lengthgets(tmp, len + need + (len>>3) + 16);
+	R_PreserveObject(this->data);
+	R_ReleaseObject(tmp);
+    }
+}
+
 #define LAST_LINE_LEN 256
 
 static int text_vfprintf(Rconnection con, const char *format, va_list ap)
@@ -1803,7 +1841,6 @@
     char buf[BUFSIZE], *b = buf, *p, *q, *vmax = vmaxget();
     int res = 0, usedRalloc = FALSE, buffree,
 	already = strlen(this->lastline);
-    SEXP tmp;
 
     if(already >= BUFSIZE) {
 	/* This will fail so just call vsnprintf to get the length of
@@ -1841,13 +1878,9 @@
     for(p = b; ; p = q+1) {
 	q = Rf_strchr(p, '\n');
 	if(q) {
-	    int idx = ConnIndex(con);
 	    *q = '\0';
-	    PROTECT(tmp = lengthgets(this->data, ++this->len));
-	    SET_STRING_ELT(tmp, this->len - 1, mkChar(p));
-	    defineVar(this->namesymbol, tmp, VECTOR_ELT(OutTextData, idx));
-	    this->data = tmp;
-	    UNPROTECT(1);
+	    outtext_grow(this, 1);
+	    SET_STRING_ELT(this->data, this->len++, mkChar(p));
 	} else {
 	    /* retain the last line */
 	    if(strlen(p) >= this->lastlinelength) {
@@ -1864,75 +1897,94 @@
     return res;
 }
 
-static void outtext_init(Rconnection con, char *mode, int idx)
+static size_t raw_write(const void *ptr, size_t size, size_t nitems,
+			Rconnection con)
+{
+    Routtextconn this = (Routtextconn)con->private;
+    outtext_grow(this, size*nitems);
+    memcpy(RAW(this->data)+this->len, ptr, size*nitems);
+    this->len += size*nitems;
+    return nitems;
+}
+
+static void outtext_init(Rconnection con, SEXP venv, char *mode)
 {
     Routtextconn this = (Routtextconn)con->private;
     SEXP val;
+    int st = (con->text ? STRSXP : RAWSXP);
 
     this->namesymbol = install(con->description);
-    if(strcmp(mode, "w") == 0) {
+    R_PreserveObject(this->venv = venv);
+    if(strncmp(mode, "w", 1) == 0) {
 	/* create variable pointed to by con->description */
-	PROTECT(val = allocVector(STRSXP, 0));
-	defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
-	UNPROTECT(1);
+	val = allocVector(st, 0);
     } else {
 	/* take over existing variable */
-	val = findVar1(this->namesymbol, VECTOR_ELT(OutTextData, idx),
-		       STRSXP, FALSE);
+	val = findVar1(this->namesymbol, venv, st, FALSE);
 	if(val == R_UnboundValue) {
-	    warning(_("text connection: appending to a non-existent char vector"));
-	    PROTECT(val = allocVector(STRSXP, 0));
-	    defineVar(this->namesymbol, val, VECTOR_ELT(OutTextData, idx));
-	    UNPROTECT(1);
+	    warning(_("%s connection: appending to a non-existent vector"),
+		    con->text ? "text" : "raw");
+	    val = allocVector(st, 0);
 	}
     }
-    this->len = LENGTH(val);
-    this->data = val;
+    R_PreserveObject(this->data = val);
+    this->len = length(val);
     this->lastline[0] = '\0';
     this->lastlinelength = LAST_LINE_LEN;
 }
 
 
-static Rconnection newouttext(char *description, SEXP sfile, char *mode,
-			      int idx)
+static Rconnection newouttext(char *description, SEXP venv,
+			      SEXP sfile, char *mode)
 {
+    int isText = (mode[1] != 'b');
     Rconnection new;
     void *tmp;
 
     new = (Rconnection) malloc(sizeof(struct Rconn));
-    if(!new) error(_("allocation of text connection failed"));
-    new->class = (char *) malloc(strlen("textConnection") + 1);
-    if(!new->class) {
-	free(new);
-	error(_("allocation of text connection failed"));
-    }
-    strcpy(new->class, "textConnection");
+    if(!new) goto f1;
+    new->class = (char *) malloc(strlen("xxxxConnection") + 1);
+    if(!new->class) goto f2;
+    sprintf(new->class, "%sConnection", isText ? "text" : "raw");
     new->description = (char *) malloc(strlen(description) + 1);
-    if(!new->description) {
-	free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->description) goto f3;
     init_con(new, description, mode);
+    new->text = isText;
     new->isopen = TRUE;
     new->canread = FALSE;
     new->open = &text_open;
     new->close = &outtext_close;
     new->destroy = &outtext_destroy;
-    new->vfprintf = &text_vfprintf;
     new->seek = &text_seek;
     new->private = (void*) malloc(sizeof(struct outtextconn));
-    if(!new->private) {
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
-    }
+    if(!new->private) goto f4;
     ((Routtextconn)new->private)->lastline = tmp = malloc(LAST_LINE_LEN);
-    if(!tmp) {
-	free(new->private);
-	free(new->description); free(new->class); free(new);
-	error(_("allocation of text connection failed"));
+    if(!tmp) goto f5;
+    if (isText) {
+	new->vfprintf = &text_vfprintf;
+    } else {
+	new->write = &raw_write;
     }
-    outtext_init(new, mode, idx);
+    outtext_init(new, venv, mode);
     return new;
+
+f5: free(new->private);
+f4: free(new->description);
+f3: free(new->class);
+f2: free(new);
+f1: error(_("allocation of %s connection failed"),
+	  isText ? "text" : "raw");
+}
+
+SEXP do_graboutput(SEXP call, SEXP op, SEXP args, SEXP env)
+{
+    Routtextconn this;
+    checkArity(op, args);
+    if(!inherits(CAR(args), "textConnection") &&
+       !inherits(CAR(args), "rawConnection"))
+	errorcall(call, _("not a text or raw connection"));
+    this = getConnection(asInteger(CAR(args)))->private;
+    return lengthgets(this->data, this->len);
 }
 
 SEXP do_textconnection(SEXP call, SEXP op, SEXP args, SEXP env)
@@ -1948,26 +2000,24 @@
 	error(_("invalid '%s' argument"), "description");
     desc = CHAR(STRING_ELT(sfile, 0));
     stext = CADR(args);
-    if(!isString(stext))
-	error(_("invalid '%s' argument"), "text");
     sopen = CADDR(args);
     if(!isString(sopen) || length(sopen) != 1)
-    error(_("invalid '%s' argument"), "open");
+	error(_("invalid '%s' argument"), "open");
     open = CHAR(STRING_ELT(sopen, 0));
     venv = CADDDR(args);
     if (!isEnvironment(venv) && venv != R_BaseEnv)
 	error(_("invalid '%s' argument"), "environment");
     ncon = NextConnection();
-    if(!strlen(open) || strncmp(open, "r", 1) == 0)
+    if(!strlen(open) || (open[0] == 'r')) {
+ 	int isText = (!strlen(open) || (open[1] != 'b'));
+ 	if (TYPEOF(stext) != (isText ? STRSXP : RAWSXP))
+ 	    error(_("invalid '%s' argument"), "object");
 	con = Connections[ncon] = newtext(desc, stext);
-    else if (strncmp(open, "w", 1) == 0 || strncmp(open, "a", 1) == 0) {
-	if (OutTextData == NULL) {
-	    OutTextData = allocVector(VECSXP, NCONNECTIONS);
-	    R_PreserveObject(OutTextData);
-	}
-	SET_VECTOR_ELT(OutTextData, ncon, venv);
+    } else if ((open[0] == 'w') || (open[0] == 'a')) {
+	if (!isString(stext))
+	    error(_("invalid '%s' argument"), "object");
 	con = Connections[ncon] =
-	    newouttext(CHAR(STRING_ELT(stext, 0)), sfile, open, ncon);
+	    newouttext(CHAR(STRING_ELT(stext, 0)), venv, sfile, open);
     }
     else
 	errorcall(call, _("unsupported mode"));
@@ -1976,7 +2026,7 @@
     PROTECT(ans = allocVector(INTSXP, 1));
     INTEGER(ans)[0] = ncon;
     PROTECT(class = allocVector(STRSXP, 2));
-    SET_STRING_ELT(class, 0, mkChar("textConnection"));
+    SET_STRING_ELT(class, 0, mkChar(con->class));
     SET_STRING_ELT(class, 1, mkChar("connection"));
     classgets(ans, class);
     UNPROTECT(2);
--- ./src/main/names.c.orig	2005-08-29 17:47:35.000000000 -0700
+++ ./src/main/names.c	2005-09-18 00:29:48.089651300 -0700
@@ -870,6 +870,7 @@
 {"clearPushBack",do_clearpushback,0,  11,     1,      {PP_FUNCALL, PREC_FN,	0}},
 {"pushBackLength",do_pushbacklength,0,  11,     1,      {PP_FUNCALL, PREC_FN,	0}},
 {"textConnection",do_textconnection,0,	11,     4,      {PP_FUNCALL, PREC_FN,	0}},
+{"grabOutput",do_graboutput,0,	11,     1,      {PP_FUNCALL, PREC_FN,	0}},
 {"socketConnection",do_sockconn,0,	11,     6,      {PP_FUNCALL, PREC_FN,	0}},
 {"sockSelect",do_sockselect,0,	11,     3,      {PP_FUNCALL, PREC_FN,	0}},
 {"getAllConnections",do_getallconnections,0,11, 0,      {PP_FUNCALL, PREC_FN,	0}},


From ggrothendieck at gmail.com  Mon Sep 19 06:56:47 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 19 Sep 2005 00:56:47 -0400
Subject: [Rd] List of languages supported
Message-ID: <971536df05091821562ed3f7f7@mail.gmail.com>

Is there a list of languges supported by R:

- languages for which one can get various screen text in that language
- languages into which the manuals have been translated

I assume that locale support is OS-specific but that the above
are not.

Thanks.


From ligges at statistik.uni-dortmund.de  Mon Sep 19 08:20:53 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 19 Sep 2005 08:20:53 +0200
Subject: [Rd] List of languages supported
In-Reply-To: <971536df05091821562ed3f7f7@mail.gmail.com>
References: <971536df05091821562ed3f7f7@mail.gmail.com>
Message-ID: <432E58C5.20107@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:
> Is there a list of languges supported by R:
> 
> - languages for which one can get various screen text in that language

Simply look into file .../po/Linguas
For R-2.2.0 alpha it has:

en
en_GB
fr
de
it
ja
ko
pt_BR
ru
zh_CN
en at quot




> - languages into which the manuals have been translated

The corresponding web page is CRAN/other-docs.html
It contains links to the Japanese translations. I do not know of other 
translations.



> I assume that locale support is OS-specific but that the above
> are not.

Yes.

Uwe Ligges

> Thanks.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From antonio.fabio at gmail.com  Mon Sep 19 09:37:36 2005
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Mon, 19 Sep 2005 00:37:36 -0700
Subject: [Rd] (no subject)
Message-ID: <b0808fdc050919003759056967@mail.gmail.com>

Is it planned to 'officially' support F95 code in R-2.2.0?
If not, by now, how is it possible to 'smothly' use F95 code in a
package (i mean, using gfortran)?
Something like stopping compilation if a non-f95 compiler is found. My
idea by now is to search for the gfortran executable, and set the F77
variable to this in the configure script...

Any suggestion will be appreciated!
Antonio, Fabio Di Narzo.

From antonio.fabio at gmail.com  Mon Sep 19 09:46:42 2005
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Mon, 19 Sep 2005 00:46:42 -0700
Subject: [Rd] using F95 code in package src (was: (no subject))
In-Reply-To: <b0808fdc050919003759056967@mail.gmail.com>
References: <b0808fdc050919003759056967@mail.gmail.com>
Message-ID: <b0808fdc050919004661592bce@mail.gmail.com>

sorry: wrote 'subject' as 'attachments'!

On 9/19/05, Antonio, Fabio Di Narzo <antonio.fabio at gmail.com> wrote:
> Is it planned to 'officially' support F95 code in R-2.2.0?
> If not, by now, how is it possible to 'smothly' use F95 code in a
> package (i mean, using gfortran)?
> Something like stopping compilation if a non-f95 compiler is found. My
> idea by now is to search for the gfortran executable, and set the F77
> variable to this in the configure script...
> 
> Any suggestion will be appreciated!
> Antonio, Fabio Di Narzo.
> 
>


From ripley at stats.ox.ac.uk  Mon Sep 19 10:02:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Sep 2005 09:02:25 +0100 (BST)
Subject: [Rd] using F95 code in package src (was: (no subject))
In-Reply-To: <b0808fdc050919004661592bce@mail.gmail.com>
References: <b0808fdc050919003759056967@mail.gmail.com>
	<b0808fdc050919004661592bce@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0509190851580.21782@gannet.stats>

On Mon, 19 Sep 2005, Antonio, Fabio Di Narzo wrote:

> sorry: wrote 'subject' as 'attachments'!
>
> On 9/19/05, Antonio, Fabio Di Narzo <antonio.fabio at gmail.com> wrote:
>> Is it planned to 'officially' support F95 code in R-2.2.0?

Do you mean in a contributed package to be installed in R?  There are no 
plans to use F95 in R itself.

If so, perhaps by 2.3.0, but there are a lot of issues to resolve.  For 
example, how do you indicate that the source file is F95?  Some compilers 
accept a .f95 extension, but not all (and it is not ever clean which do).

>> If not, by now, how is it possible to 'smothly' use F95 code in a
>> package (i mean, using gfortran)?

It is not. The largest R platform, Windows, does not have a supported F95 
compiler.  (g95 works with MinGW, but R has no support for it as yet, nor 
can one expect people to have installed it.)

>> Something like stopping compilation if a non-f95 compiler is found. My
>> idea by now is to search for the gfortran executable, and set the F77
>> variable to this in the configure script...

Why do you think gfortran is a F95 compiler? (It has considerable support 
for F95, but not complete support AFAICS.)  And that it is the only F95 
compiler?   How do you propose to tell if you have a F95 compiler?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Mon Sep 19 10:11:35 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 19 Sep 2005 04:11:35 -0400
Subject: [Rd] Contacting RDCOMClient Maintainer
Message-ID: <971536df05091901112ac89f71@mail.gmail.com>

I tried to contact the maintainer of RDCOMClient as per the DESCRIPTION file 
to report a bug but my mail bounced.  Is there more recent contact information?

The original message was received at Mon, 19 Sep 2005 03:03:21 -0500 (CDT)
from hoemail2.lucent.com [192.11.226.163]

  ----- The following addresses had permanent fatal errors -----
<duncan at research.bell-labs.com>
   (reason: 550 5.1.1 <duncan at research.bell-labs.com>... User unknown)

  ----- Transcript of session follows -----
... while talking to grubby.research.bell-labs.com.:
>>> DATA
<<< 550 5.1.1 <duncan at research.bell-labs.com>... User unknown
550 5.1.1 <duncan at research.bell-labs.com>... User unknown
<<< 503 5.0.0 Need RCPT (recipient)


Final-Recipient: RFC822; duncan at research.bell-labs.com
Action: failed
Status: 5.1.1
Remote-MTA: DNS; grubby.research.bell-labs.com
Diagnostic-Code: SMTP; 550 5.1.1 <duncan at research.bell-labs.com>... User unknown
Last-Attempt-Date: Mon, 19 Sep 2005 03:03:22 -0500 (CDT)


From Kurt.Hornik at wu-wien.ac.at  Mon Sep 19 10:19:31 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Mon, 19 Sep 2005 10:19:31 +0200
Subject: [Rd] Contacting RDCOMClient Maintainer
In-Reply-To: <971536df05091901112ac89f71@mail.gmail.com>
References: <971536df05091901112ac89f71@mail.gmail.com>
Message-ID: <17198.29843.455468.386092@mithrandir.hornik.net>

>>>>> Gabor Grothendieck writes:

> I tried to contact the maintainer of RDCOMClient as per the
> DESCRIPTION file to report a bug but my mail bounced.  Is there more
> recent contact information?

Yes.  In case you want to have it .....

  Duncan Temple Lang <duncan at wald.ucdavis.edu>

-k

> The original message was received at Mon, 19 Sep 2005 03:03:21 -0500 (CDT)
> from hoemail2.lucent.com [192.11.226.163]

>   ----- The following addresses had permanent fatal errors -----
> <duncan at research.bell-labs.com>
>    (reason: 550 5.1.1 <duncan at research.bell-labs.com>... User unknown)

>   ----- Transcript of session follows -----
> ... while talking to grubby.research.bell-labs.com.:
>>>> DATA
> <<< 550 5.1.1 <duncan at research.bell-labs.com>... User unknown
> 550 5.1.1 <duncan at research.bell-labs.com>... User unknown
> <<< 503 5.0.0 Need RCPT (recipient)


> Final-Recipient: RFC822; duncan at research.bell-labs.com
> Action: failed
> Status: 5.1.1
> Remote-MTA: DNS; grubby.research.bell-labs.com
> Diagnostic-Code: SMTP; 550 5.1.1 <duncan at research.bell-labs.com>... User unknown
> Last-Attempt-Date: Mon, 19 Sep 2005 03:03:22 -0500 (CDT)

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From plummer at iarc.fr  Mon Sep 19 10:44:00 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Mon, 19 Sep 2005 10:44:00 +0200
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <20050917221902.GA10806@stat.umn.edu>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
Message-ID: <1127119440.3624.5.camel@seurat>

On Sat, 2005-09-17 at 17:19 -0500, Charles Geyer wrote:
> I can't compile R-alpha on AMD 64.  Rather than include a 1400 line script
> I have put it on the web
> 
>     http://www.stat.umn.edu/~charlie/typescript.txt
> 
> way down near the bottom it fails building lapack.so
> 
>     gcc -shared -L/usr/local/lib64 -o lapack.so  Lapack.lo    -llapack -lblas -lg2c -lm -lgcc_s
>     /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../x86_64-suse-linux/bin/ld: /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a(dgecon.i): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
>     /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a: could not read symbols: Bad value
> 
> The 'recompile with -fPIC' is bullsh*t.  The problem is that is is looking
> in /usr/lib64/liblapack.a rather than /usr/lib64/liblapack.so.3 both of which
> exist.  Some searching for this error message on Google shows a lot of
> questions about this problem but no solution that I found other than
> 
>     rm /usr/lib64/liblapack.a
> 
> which I don't consider a solution.  It will link with the .so as the bottom
> of the script shows
> 
>     snowbank$ cd src/modules/lapack
>     snowbank$ gcc -shared -o lapack.so Lapack.lo -llapack -lblas -lg2c -lm -lgcc_s
>     /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../x86_64-suse-linux/bin/ld: /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a(dgecon.i): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
>     /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../lib64/liblapack.a: could not read symbols: Bad value
>     collect2: ld returned 1 exit status
>     snowbank$ gcc -shared -o lapack.so Lapack.lo /usr/lib64/liblapack.so.3 -lblas -l g2c -lm -lgcc_s
> 
> No problems with the second link.
> 
> So what do I do?  liblapack.so is there.  I've linked other (non-R) programs
> to it.  So it SHOULD work with R.
> 
> Either I can't read (possible) or the solution to this isn't in the gcc info
> pages.
> 
> System (more info in typescript).
> 
>    AMD 64
>    SuSE linux 9.3
>    GCC 3.3.5
> 
> I also observed the same problem with R-2.1.1 but didn't get around to
> debugging it until today.
> 
> It occurred to me that /usr/local/lib/liblapack.so.3 which is 32 bit
> (because right now we are running only one R on both 32 and 64 bit and
> that's where the 32 bit R finds it's shared libraries), but I don't
> think that's the problem.  Well maybe it is.  How do I tell configure
> NOT to add /user/local ?

You would need to modify the LDFLAGS and CPPFLAGS environment variables,
as these default to -L/usr/local/lib and -I/usr/local/include
respectively.  See Appendix B.3.3 of the R Installation and
Administration manual, which gives a warning about 64-bit systems.

You can also use the --with-readline configure flag to specify the exact
location of the readline library you wish to use.

I hope this helps.
Martyn


-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}


From maechler at stat.math.ethz.ch  Mon Sep 19 14:18:07 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Sep 2005 14:18:07 +0200
Subject: [Rd] automatically adding smooth to plot: options("plot.add.smooth")
In-Reply-To: <17196.13904.78468.758438@deb8.math.ethz.ch>
References: <17190.57225.254938.977464@stat.math.ethz.ch>
	<17194.30238.436418.752419@stat.math.ethz.ch>
	<17196.13904.78468.758438@deb8.math.ethz.ch>
Message-ID: <17198.44159.670311.662705@stat.math.ethz.ch>

I've changed the subject in the hope some more people would
voice an opinion...

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Sat, 17 Sep 2005 17:29:20 +0200 writes:

>>>>> "Wst" == Werner Stahel <stahel at stat.math.ethz.ch>
>>>>>     on Fri, 16 Sep 2005 09:37:02 +0200 writes:


    Wst> ........................
    Wst> ........................
    Wst> ........................

    Wst> For most plots, I like to see a smoother along with the
    Wst> points.  I suggest to add the option to include
    Wst> smoothers, not only as an argument to plot.lm, but even
    Wst> as an option().  I have heared of the intense
    Wst> discussions about options().  With Martin, we arrived
    Wst> at the conclusion that options() should never influence
    Wst> calculations and results, but is suitable to adjust
    Wst> outputs (numerical: digits=, graphical: smooth=) to the
    Wst> user's taste.

    MM> {and John Fox agreed, `in general'}

    MM> That could be a possibility, for 2.2.0 only applied to
    MM> plot.lm() in any case, where plot.lm() would get a new
    MM> argument

    MM>     add.smooth = getOption("plot.add.smooth")

    MM> What do people think about the name?  it would ``stick
    MM> with us'' -- so we better choose it well..

No reaction so far.... 


I've realized that I can introduce this very easily into
plot.lm():

Instead of the former argument    

	 panel = points

I use the new ones

	 panel = if(add.smooth) panel.smooth else points,

         add.smooth = isTRUE(getOption("plot.add.smooth")),

- - - 

Now I even propose to have
      
	options(add.smooth = TRUE)

as a new default.....

Do I get a reaction now?
Martin


From murdoch at stats.uwo.ca  Mon Sep 19 14:47:01 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 19 Sep 2005 08:47:01 -0400
Subject: [Rd] automatically adding smooth to plot:
	options("plot.add.smooth")
In-Reply-To: <17198.44159.670311.662705@stat.math.ethz.ch>
References: <17190.57225.254938.977464@stat.math.ethz.ch>	<17194.30238.436418.752419@stat.math.ethz.ch>	<17196.13904.78468.758438@deb8.math.ethz.ch>
	<17198.44159.670311.662705@stat.math.ethz.ch>
Message-ID: <432EB345.801@stats.uwo.ca>

On 9/19/2005 8:18 AM, Martin Maechler wrote:
> I've changed the subject in the hope some more people would
> voice an opinion...
> 
>>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>     on Sat, 17 Sep 2005 17:29:20 +0200 writes:
> 
>>>>>> "Wst" == Werner Stahel <stahel at stat.math.ethz.ch>
>>>>>>     on Fri, 16 Sep 2005 09:37:02 +0200 writes:
> 
> 
>     Wst> ........................
>     Wst> ........................
>     Wst> ........................
> 
>     Wst> For most plots, I like to see a smoother along with the
>     Wst> points.  I suggest to add the option to include
>     Wst> smoothers, not only as an argument to plot.lm, but even
>     Wst> as an option().  I have heared of the intense
>     Wst> discussions about options().  With Martin, we arrived
>     Wst> at the conclusion that options() should never influence
>     Wst> calculations and results, but is suitable to adjust
>     Wst> outputs (numerical: digits=, graphical: smooth=) to the
>     Wst> user's taste.
> 
>     MM> {and John Fox agreed, `in general'}
> 
>     MM> That could be a possibility, for 2.2.0 only applied to
>     MM> plot.lm() in any case, where plot.lm() would get a new
>     MM> argument
> 
>     MM>     add.smooth = getOption("plot.add.smooth")
> 
>     MM> What do people think about the name?  it would ``stick
>     MM> with us'' -- so we better choose it well..
> 
> No reaction so far.... 
> 
> 
> I've realized that I can introduce this very easily into
> plot.lm():
> 
> Instead of the former argument    
> 
> 	 panel = points
> 
> I use the new ones
> 
> 	 panel = if(add.smooth) panel.smooth else points,
> 
>          add.smooth = isTRUE(getOption("plot.add.smooth")),
> 
> - - - 
> 
> Now I even propose to have
>       
> 	options(add.smooth = TRUE)
> 
> as a new default.....
> 
> Do I get a reaction now?

I like the name "add.smooth" (as used at the bottom) better than 
"plot.add.smooth" (as used a few lines up).

With that choice, I think it's a good idea.

Duncan Murdoch


From jfox at mcmaster.ca  Mon Sep 19 15:17:44 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 19 Sep 2005 09:17:44 -0400
Subject: [Rd] automatically adding smooth to
	plot:options("plot.add.smooth")
In-Reply-To: <432EB345.801@stats.uwo.ca>
Message-ID: <20050919131743.EMPT25800.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Duncan and Martin,


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Monday, September 19, 2005 7:47 AM
> To: Martin Maechler
> Cc: Werner Stahel; R-devel at stat.math.ethz.ch
> Subject: Re: [Rd] automatically adding smooth to 
> plot:options("plot.add.smooth")
> 
> On 9/19/2005 8:18 AM, Martin Maechler wrote:
> > I've changed the subject in the hope some more people would 
> voice an 
> > opinion...
> > 
> >>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
> >>>>>>     on Sat, 17 Sep 2005 17:29:20 +0200 writes:
> > 
> >>>>>> "Wst" == Werner Stahel <stahel at stat.math.ethz.ch>
> >>>>>>     on Fri, 16 Sep 2005 09:37:02 +0200 writes:
> > 
> > 
> >     Wst> ........................
> >     Wst> ........................
> >     Wst> ........................
> > 
> >     Wst> For most plots, I like to see a smoother along with the
> >     Wst> points.  I suggest to add the option to include
> >     Wst> smoothers, not only as an argument to plot.lm, but even
> >     Wst> as an option().  I have heared of the intense
> >     Wst> discussions about options().  With Martin, we arrived
> >     Wst> at the conclusion that options() should never influence
> >     Wst> calculations and results, but is suitable to adjust
> >     Wst> outputs (numerical: digits=, graphical: smooth=) to the
> >     Wst> user's taste.
> > 
> >     MM> {and John Fox agreed, `in general'}
> > 
> >     MM> That could be a possibility, for 2.2.0 only applied to
> >     MM> plot.lm() in any case, where plot.lm() would get a new
> >     MM> argument
> > 
> >     MM>     add.smooth = getOption("plot.add.smooth")
> > 
> >     MM> What do people think about the name?  it would ``stick
> >     MM> with us'' -- so we better choose it well..
> > 
> > No reaction so far.... 
> > 
> > 
> > I've realized that I can introduce this very easily into
> > plot.lm():
> > 
> > Instead of the former argument    
> > 
> > 	 panel = points
> > 
> > I use the new ones
> > 
> > 	 panel = if(add.smooth) panel.smooth else points,
> > 
> >          add.smooth = isTRUE(getOption("plot.add.smooth")),
> > 
> > - - -
> > 
> > Now I even propose to have
> >       
> > 	options(add.smooth = TRUE)
> > 
> > as a new default.....
> > 
> > Do I get a reaction now?
> 
> I like the name "add.smooth" (as used at the bottom) better 
> than "plot.add.smooth" (as used a few lines up).
> 
> With that choice, I think it's a good idea.
> 
> Duncan Murdoch

I agree.

Regards,
 John


From fwagner at fh-lausitz.de  Mon Sep 19 15:34:05 2005
From: fwagner at fh-lausitz.de (fwagner@fh-lausitz.de)
Date: Mon, 19 Sep 2005 15:34:05 +0200 (CEST)
Subject: [Rd] Lists and data frames (PR#8143)
Message-ID: <20050919133405.D29FD1C6B0@slim.kubism.ku.dk>

Full_Name: Frank Wagner
Version: R 2.1.1
OS: Windows
Submission from: (NULL) (193.174.73.34)


Hi,
The pdf file R-intro descripe on page 27 that lists can be extended by adding
numbers.
Unfortunately, it's not working 
## example :

# if i did not declare the variable an error occurs : object not found
mylist <- list() 
mylist[1] <- list(value1=3, value2=5)
## Error

Can you please help me
Thank you

Regards
Frank Wagner


From andy_liaw at merck.com  Mon Sep 19 15:43:38 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Sep 2005 09:43:38 -0400
Subject: [Rd] Lists and data frames (PR#8143)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED44D@usctmx1106.merck.com>

> From: r-devel
> 
> Full_Name: Frank Wagner
> Version: R 2.1.1
> OS: Windows
> Submission from: (NULL) (193.174.73.34)
> 
> 
> Hi,
> The pdf file R-intro descripe on page 27 that lists can be 
> extended by adding
> numbers.
> Unfortunately, it's not working 
> ## example :
> 
> # if i did not declare the variable an error occurs : object not found
> mylist <- list() 
> mylist[1] <- list(value1=3, value2=5)
> ## Error

I don't get that (with R-2.1.1-patched on WinXPPro):

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.1 Patched (2005-07-13), ISBN 3-900051-07-0

[...]

> mylist <- list() 
> mylist[1] <- list(value1=3, value2=5)
Warning message:
number of items to replace is not a multiple of replacement length 


Andy 

 
> Can you please help me
> Thank you
> 
> Regards
> Frank Wagner
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
>


From ligges at statistik.uni-dortmund.de  Mon Sep 19 15:58:17 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Mon, 19 Sep 2005 15:58:17 +0200 (CEST)
Subject: [Rd] Lists and data frames (PR#8143)
Message-ID: <20050919135817.A9EF41C6B7@slim.kubism.ku.dk>

fwagner at fh-lausitz.de wrote:

> Full_Name: Frank Wagner
> Version: R 2.1.1
> OS: Windows
> Submission from: (NULL) (193.174.73.34)
> 
> 
> Hi,
> The pdf file R-intro descripe on page 27 that lists can be extended by adding
> numbers.
> Unfortunately, it's not working 
> ## example :
> 
> # if i did not declare the variable an error occurs : object not found
> mylist <- list() 
> mylist[1] <- list(value1=3, value2=5)
> ## Error

NO!

1. No, this is not a bug!
2. No, this was not an error but a *warning* which tells you that the 
length does not match.
Each Element of *vector* mylist must be a list of length one, hence you 
cannot assign one of length two. Instead you can say:

mylist[1:2] <- list(value1=3, value2=5)

This is a question that might go to R-help, if you do not understand 
what is described in the docs. The manual is correct, hence this is not 
a bug.
Please read the docs on how to post bugs and how a bug is defined ...

Uwe Ligges



> 
> Can you please help me
> Thank you
> 
> Regards
> Frank Wagner
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pgilbert at bank-banque-canada.ca  Mon Sep 19 16:01:57 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 19 Sep 2005 10:01:57 -0400
Subject: [Rd] automatically adding smooth to plot:
	options("plot.add.smooth")
In-Reply-To: <17198.44159.670311.662705@stat.math.ethz.ch>
References: <17190.57225.254938.977464@stat.math.ethz.ch>	<17194.30238.436418.752419@stat.math.ethz.ch>	<17196.13904.78468.758438@deb8.math.ethz.ch>
	<17198.44159.670311.662705@stat.math.ethz.ch>
Message-ID: <432EC4D5.7090609@bank-banque-canada.ca>

Martin Maechler wrote:

> I've changed the subject in the hope some more people would
> voice an opinion...

...

> Now I even propose to have
>       
> 	options(add.smooth = TRUE)
> 
> as a new default.....
> 
> Do I get a reaction now?
> Martin

I think you may break a lot of things if you make this the default for 
plot. Plot gets used by other things (like matplot) where this default 
may not make much sense. (But I may have missed too much of the earlier 
discussion under some other subject.)

Paul
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gavin.simpson at ucl.ac.uk  Mon Sep 19 16:03:44 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 19 Sep 2005 15:03:44 +0100
Subject: [Rd] Lists and data frames (PR#8143)
In-Reply-To: <20050919133405.D29FD1C6B0@slim.kubism.ku.dk>
References: <20050919133405.D29FD1C6B0@slim.kubism.ku.dk>
Message-ID: <1127138624.31636.6.camel@gsimpson.geog.ucl.ac.uk>

On Mon, 2005-09-19 at 15:34 +0200, fwagner at fh-lausitz.de wrote:
> Full_Name: Frank Wagner
> Version: R 2.1.1
> OS: Windows
> Submission from: (NULL) (193.174.73.34)
> 
> 
> Hi,
> The pdf file R-intro descripe on page 27 that lists can be extended by adding
> numbers.
> Unfortunately, it's not working 
> ## example :
> 
> # if i did not declare the variable an error occurs : object not found
> mylist <- list() 
> mylist[1] <- list(value1=3, value2=5)
> ## Error

You need to use [[x]] to subset a list:

> mylist <- list()
> mylist[[1]] <- list(value1=3, value2=5)
> mylist
[[1]]
[[1]]$value1
[1] 3

[[1]]$value2
[1] 5

> str(mylist)
List of 1
 $ :List of 2
  ..$ value1: num 3
  ..$ value2: num 5

I don't know whether there is a typo on page 27 or not: [x] is valid, it
just means something different to [[x]] - as explained on page 26 of
said manual. If it was intentional, then IMHO it is not the most clear
example of extending a list - the [[x]] notation is what I would expect
to have to use - after reading page 26 of course...

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From murdoch at stats.uwo.ca  Mon Sep 19 16:31:56 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 19 Sep 2005 10:31:56 -0400
Subject: [Rd] automatically adding smooth to
	plot:	options("plot.add.smooth")
In-Reply-To: <432EC4D5.7090609@bank-banque-canada.ca>
References: <17190.57225.254938.977464@stat.math.ethz.ch>	<17194.30238.436418.752419@stat.math.ethz.ch>	<17196.13904.78468.758438@deb8.math.ethz.ch>	<17198.44159.670311.662705@stat.math.ethz.ch>
	<432EC4D5.7090609@bank-banque-canada.ca>
Message-ID: <432ECBDC.4080308@stats.uwo.ca>

On 9/19/2005 10:01 AM, Paul Gilbert wrote:
> Martin Maechler wrote:
> 
>> I've changed the subject in the hope some more people would
>> voice an opinion...
> 
> ...
> 
>> Now I even propose to have
>>       
>> 	options(add.smooth = TRUE)
>> 
>> as a new default.....
>> 
>> Do I get a reaction now?
>> Martin
> 
> I think you may break a lot of things if you make this the default for 
> plot. Plot gets used by other things (like matplot) where this default 
> may not make much sense. (But I may have missed too much of the earlier 
> discussion under some other subject.)

This was going to affect only plot.lm, as far as I know.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Mon Sep 19 16:38:31 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Sep 2005 16:38:31 +0200
Subject: [Rd] automatically adding smooth to
	plot:	options("plot.add.smooth")
In-Reply-To: <432EC4D5.7090609@bank-banque-canada.ca>
References: <17190.57225.254938.977464@stat.math.ethz.ch>
	<17194.30238.436418.752419@stat.math.ethz.ch>
	<17196.13904.78468.758438@deb8.math.ethz.ch>
	<17198.44159.670311.662705@stat.math.ethz.ch>
	<432EC4D5.7090609@bank-banque-canada.ca>
Message-ID: <17198.52583.8400.669027@stat.math.ethz.ch>

>>>>> "PaulG" == Paul Gilbert <pgilbert at bank-banque-canada.ca>
>>>>>     on Mon, 19 Sep 2005 10:01:57 -0400 writes:

    PaulG> Martin Maechler wrote:
    >> I've changed the subject in the hope some more people
    >> would voice an opinion...

    PaulG> ...

    >> Now I even propose to have
    >> 
    >> options(add.smooth = TRUE)
    >> 
    >> as a new default.....
    >> 
    >> Do I get a reaction now?  Martin

    PaulG> I think you may break a lot of things if you make
    PaulG> this the default for plot. 

You mean plot.default().
Yes, that would be quite dangerous to do and you give a good example:

    PaulG> this the default for plot. Plot gets used by other
    PaulG> things (like matplot) where this default may not make
    PaulG> much sense. (But I may have missed too much of the
    PaulG> earlier discussion under some other subject.)

or I was not clear enough:
For R 2.2.0, the option would only be used in plot.lm().
Since I'd set its default to TRUE,  plot.lm()'s panels would use
panel.smooth(x,y,...) rather than points(x,y,...), 
and this actually does look quite useful.

Martin


From ligges at statistik.uni-dortmund.de  Mon Sep 19 16:39:57 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 19 Sep 2005 16:39:57 +0200
Subject: [Rd] Lists and data frames (PR#8143)
In-Reply-To: <1127138624.31636.6.camel@gsimpson.geog.ucl.ac.uk>
References: <20050919133405.D29FD1C6B0@slim.kubism.ku.dk>
	<1127138624.31636.6.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <432ECDBD.4060303@statistik.uni-dortmund.de>

Gavin Simpson wrote:

> On Mon, 2005-09-19 at 15:34 +0200, fwagner at fh-lausitz.de wrote:
> 
>>Full_Name: Frank Wagner
>>Version: R 2.1.1
>>OS: Windows
>>Submission from: (NULL) (193.174.73.34)
>>
>>
>>Hi,
>>The pdf file R-intro descripe on page 27 that lists can be extended by adding
>>numbers.
>>Unfortunately, it's not working 
>>## example :
>>
>># if i did not declare the variable an error occurs : object not found
>>mylist <- list() 
>>mylist[1] <- list(value1=3, value2=5)
>>## Error
> 
> 
> You need to use [[x]] to subset a list:
> 
> 
>>mylist <- list()
>>mylist[[1]] <- list(value1=3, value2=5)
>>mylist
> 
> [[1]]
> [[1]]$value1
> [1] 3
> 
> [[1]]$value2
> [1] 5


This is a list of a list, but that is not the same as the stuff we are 
discussing here. See below.


> 
>>str(mylist)
> 
> List of 1
>  $ :List of 2
>   ..$ value1: num 3
>   ..$ value2: num 5
> 
> I don't know whether there is a typo on page 27 or not: [x] is valid, it
> just means something different to [[x]] - as explained on page 26 of
> said manual. If it was intentional, then IMHO it is not the most clear
> example of extending a list - the [[x]] notation is what I would expect
> to have to use - after reading page 26 of course...

Folks, please specify which version of the manual you are speaking 
about, e.g. by giving a chapter's/section's name.

The statement on what is referred to page 27 in this thread is completly 
correct.

Note that a list is nothing else than a vector of mode list which 
contains in each element a list of length one.

Hence you *can* say
mylist[1:2] <- list(value1=3, value2=5)
or
c(mylist, list(value1=3, value2=5))
or whatever.


Uwe Ligges



> HTH
> 
> G


From pgilbert at bank-banque-canada.ca  Mon Sep 19 16:38:54 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 19 Sep 2005 10:38:54 -0400
Subject: [Rd] automatically adding smooth to
	plot:	options("plot.add.smooth")
In-Reply-To: <432ECBDC.4080308@stats.uwo.ca>
References: <17190.57225.254938.977464@stat.math.ethz.ch>	<17194.30238.436418.752419@stat.math.ethz.ch>	<17196.13904.78468.758438@deb8.math.ethz.ch>	<17198.44159.670311.662705@stat.math.ethz.ch>
	<432EC4D5.7090609@bank-banque-canada.ca>
	<432ECBDC.4080308@stats.uwo.ca>
Message-ID: <432ECD7E.1050400@bank-banque-canada.ca>



Duncan Murdoch wrote:

> On 9/19/2005 10:01 AM, Paul Gilbert wrote:
> 
>> Martin Maechler wrote:
>>
>>> I've changed the subject in the hope some more people would
>>> voice an opinion...
>>
>>
>> ...
>>
>>> Now I even propose to have
>>>           options(add.smooth = TRUE)
>>>
>>> as a new default.....
>>>
>>> Do I get a reaction now?
>>> Martin
>>
>>
>> I think you may break a lot of things if you make this the default for 
>> plot. Plot gets used by other things (like matplot) where this default 
>> may not make much sense. (But I may have missed too much of the 
>> earlier discussion under some other subject.)
> 
> 
> This was going to affect only plot.lm, as far as I know.

 From the earlier discussion I thought so, but it was not really clear 
in the new subject line.

Paul
> 
> Duncan Murdoch


From p.dalgaard at biostat.ku.dk  Mon Sep 19 17:10:16 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Sep 2005 17:10:16 +0200
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <1127119440.3624.5.camel@seurat>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
Message-ID: <x23bo15c13.fsf@turmalin.kubism.ku.dk>

Martyn Plummer <plummer at iarc.fr> writes:

> > The 'recompile with -fPIC' is bullsh*t.  The problem is that is is looking
> > in /usr/lib64/liblapack.a rather than /usr/lib64/liblapack.so.3 both of which
> > exist.  Some searching for this error message on Google shows a lot of
> > questions about this problem but no solution that I found other than
> > 
> >     rm /usr/lib64/liblapack.a
> > 
> > which I don't consider a solution.  It will link with the .so as the bottom
> > of the script shows
....
> You would need to modify the LDFLAGS and CPPFLAGS environment variables,
> as these default to -L/usr/local/lib and -I/usr/local/include
> respectively.  See Appendix B.3.3 of the R Installation and
> Administration manual, which gives a warning about 64-bit systems.
> 
> You can also use the --with-readline configure flag to specify the exact
> location of the readline library you wish to use.

How did _readline_ get into this?

As a curiosity, I tried looking at what Fedora Core 4 does with this.
So I looked for liblapack.a with locate, and it found one in /usr/lib
(on a 32bit system). Then I went to have a closer look at the library
and it turned out not to be there -- apparently the recent update to
lapack had wiped it out, but the locate database was not yet
rebuilt...

This sort of suggests to me that removing the .a file might actually
be a sensible thing to do on SuSE as well. 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From plummer at iarc.fr  Mon Sep 19 17:40:43 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Mon, 19 Sep 2005 17:40:43 +0200
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <x23bo15c13.fsf@turmalin.kubism.ku.dk>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
Message-ID: <1127144443.18426.14.camel@seurat>

On Mon, 2005-09-19 at 17:10 +0200, Peter Dalgaard wrote:
> Martyn Plummer <plummer at iarc.fr> writes:
> 
> > > The 'recompile with -fPIC' is bullsh*t.  The problem is that is is looking
> > > in /usr/lib64/liblapack.a rather than /usr/lib64/liblapack.so.3 both of which
> > > exist.  Some searching for this error message on Google shows a lot of
> > > questions about this problem but no solution that I found other than
> > > 
> > >     rm /usr/lib64/liblapack.a
> > > 
> > > which I don't consider a solution.  It will link with the .so as the bottom
> > > of the script shows
> ....
> > You would need to modify the LDFLAGS and CPPFLAGS environment variables,
> > as these default to -L/usr/local/lib and -I/usr/local/include
> > respectively.  See Appendix B.3.3 of the R Installation and
> > Administration manual, which gives a warning about 64-bit systems.
> > 
> > You can also use the --with-readline configure flag to specify the exact
> > location of the readline library you wish to use.
> 
> How did _readline_ get into this?

I meant --with-lapack.  My fingers have their very own autocomplete
feature, which is a little buggy.  

> As a curiosity, I tried looking at what Fedora Core 4 does with this.
> So I looked for liblapack.a with locate, and it found one in /usr/lib
> (on a 32bit system). Then I went to have a closer look at the library
> and it turned out not to be there -- apparently the recent update to
> lapack had wiped it out, but the locate database was not yet
> rebuilt...

Fedora have just split off a separate lapack-devel package containing
the static library and the symlink liblapack.so.  (Mandrake/Mandriva has
been doing this for some time. I don't know about SuSE).  The up2date
service will recognize that it needs to update lapack, but I guess that
it won't install lapack-devel, as it doesn't know you need it.

It might have been better to do this in the next release, rather than as
an update to FC4, but there you go. Better install lapack-devel
manually.

> This sort of suggests to me that removing the .a file might actually
> be a sensible thing to do on SuSE as well. 

M.

-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}


From gavin.simpson at ucl.ac.uk  Mon Sep 19 18:05:07 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 19 Sep 2005 17:05:07 +0100
Subject: [Rd] Lists and data frames (PR#8143)
In-Reply-To: <432ECDBD.4060303@statistik.uni-dortmund.de>
References: <20050919133405.D29FD1C6B0@slim.kubism.ku.dk>
	<1127138624.31636.6.camel@gsimpson.geog.ucl.ac.uk>
	<432ECDBD.4060303@statistik.uni-dortmund.de>
Message-ID: <1127145907.8144.14.camel@gsimpson.geog.ucl.ac.uk>

On Mon, 2005-09-19 at 16:39 +0200, Uwe Ligges wrote: 
> Gavin Simpson wrote:
> 
> > On Mon, 2005-09-19 at 15:34 +0200, fwagner at fh-lausitz.de wrote:
> > 
> >>Full_Name: Frank Wagner
> >>Version: R 2.1.1
> >>OS: Windows
> >>Submission from: (NULL) (193.174.73.34)
> >>
> >>
> >>Hi,
> >>The pdf file R-intro descripe on page 27 that lists can be extended by adding
> >>numbers.
> >>Unfortunately, it's not working 
> >>## example :
> >>
> >># if i did not declare the variable an error occurs : object not found
> >>mylist <- list() 
> >>mylist[1] <- list(value1=3, value2=5)
> >>## Error
> > 
> > 
> > You need to use [[x]] to subset a list:
> > 
> > 
> >>mylist <- list()
> >>mylist[[1]] <- list(value1=3, value2=5)
> >>mylist
> > 
> > [[1]]
> > [[1]]$value1
> > [1] 3
> > 
> > [[1]]$value2
> > [1] 5
> 
> 
> This is a list of a list, but that is not the same as the stuff we are 
> discussing here. See below.
> 
> 
> > 
> >>str(mylist)
> > 
> > List of 1
> >  $ :List of 2
> >   ..$ value1: num 3
> >   ..$ value2: num 5
> > 
> > I don't know whether there is a typo on page 27 or not: [x] is valid, it
> > just means something different to [[x]] - as explained on page 26 of
> > said manual. If it was intentional, then IMHO it is not the most clear
> > example of extending a list - the [[x]] notation is what I would expect
> > to have to use - after reading page 26 of course...
> 
> Folks, please specify which version of the manual you are speaking 
> about, e.g. by giving a chapter's/section's name.

R-patched Section 6.1 and 6.2 - (pdf version). Which was stated in
Frank's original email which I included, as was R version info.

> 
> The statement on what is referred to page 27 in this thread is completly 
> correct.

I would say what we are discussing here is a matter of interpreting what
the OP was intending to do. If the OP wanted to replace the first
component of mylist then [[1]] is needed. If it was the first sublist of
mylist then [1] is called for.

I interpreted the OP as the former; wanting to put a list in the first
component of mylist - because that is what the example on page 27 states
it is doing (depending on what "component" means - see below).

Confusion arises, because it depends on what you take "components" to
mean in para 2, page 27. In the paragraph above para 2 on page 27, a
list is defined and "components" refers to the bits extracted by [[ ]].
[x] extracts a list containing the xth component. So when para 2 states
that if you wish to add more components to the list you use [ ], isn't
this contradicting the previous paragraph?

mylist <- list(comp1 = 1, comp2 = matrix(1:10, ncol = 2), comp3 =
"comp3")
> mylist
$comp1
[1] 1

$comp2
     [,1] [,2]
[1,]    1    6
[2,]    2    7
[3,]    3    8
[4,]    4    9
[5,]    5   10

$comp3
[1] "comp3"

> mylist[[2]]
     [,1] [,2]
[1,]    1    6
[2,]    2    7
[3,]    3    8
[4,]    4    9
[5,]    5   10

> mylist[1] <- list(comp5 = 1:10, comp6 = 1:10)
Warning message:
number of items to replace is not a multiple of replacement length
> mylist[[1]] <- list(comp5 = 1:10, comp6 = 1:10) ## or
> mylist[1] <- list(list(comp5 = 1:10, comp6 = 1:10))

And here I *do* want to replace the first component with a list (itself
with two components)

Which is because [[ ]] extracts the "component", whereas [ ] extracts a
[sub]list:

> class(mylist[[2]])
[1] "matrix"
> class(mylist[2])
[1] "list"

So, it depends what you mean by a "component".

At the very least, the use of "component" in the first two paragraphs of
page 27 (pdf version) is confusing as the two uses do not correspond to
the same "thing". I would go as far as saying contradictory - but that
might be nit-picking and depends on your definition of "extracts" ;-)

Wouldn't the following be better:

Lists, like any subscripted object, can be extended by specifying
additional components. To add new /components/ you could:

> Mat <- matrix(1:100, ncol = 10) ## not defined previously
> ## add Mat to component 5 of Lst
> Lst[[5]] <- Mat
> ## or
> Lst[5] <- list(Matrix = Mat)
> ## or, replace Lst[[5]] with a list with 2 components
> Lst[[5]] <- list(Matrix1 = Mat, Matrix2 = Mat)

See Section 6.1 for the differences.

Personally, I find Lst[[5]] <- Mat more intuitive than having to wrap it
in list().

Just my USD1.50 worth (judging by the length of this email)

G

> 
> Note that a list is nothing else than a vector of mode list which 
> contains in each element a list of length one.
> 
> Hence you *can* say
> mylist[1:2] <- list(value1=3, value2=5)
> or
> c(mylist, list(value1=3, value2=5))
> or whatever.
> 
> 
> Uwe Ligges
> 
> 
> 
> > HTH
> > 
> > G
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From gavin.simpson at ucl.ac.uk  Mon Sep 19 18:18:14 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 19 Sep 2005 17:18:14 +0100
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <1127144443.18426.14.camel@seurat>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat>
Message-ID: <1127146694.8144.23.camel@gsimpson.geog.ucl.ac.uk>

On Mon, 2005-09-19 at 17:40 +0200, Martyn Plummer wrote:
> On Mon, 2005-09-19 at 17:10 +0200, Peter Dalgaard wrote:
> > Martyn Plummer <plummer at iarc.fr> writes:
> > 
> > > > The 'recompile with -fPIC' is bullsh*t.  The problem is that is is looking
> > > > in /usr/lib64/liblapack.a rather than /usr/lib64/liblapack.so.3 both of which
> > > > exist.  Some searching for this error message on Google shows a lot of
> > > > questions about this problem but no solution that I found other than
> > > > 
> > > >     rm /usr/lib64/liblapack.a
> > > > 
> > > > which I don't consider a solution.  It will link with the .so as the bottom
> > > > of the script shows
> > ....
> > > You would need to modify the LDFLAGS and CPPFLAGS environment variables,
> > > as these default to -L/usr/local/lib and -I/usr/local/include
> > > respectively.  See Appendix B.3.3 of the R Installation and
> > > Administration manual, which gives a warning about 64-bit systems.
> > > 
> > > You can also use the --with-readline configure flag to specify the exact
> > > location of the readline library you wish to use.
> > 
> > How did _readline_ get into this?
> 
> I meant --with-lapack.  My fingers have their very own autocomplete
> feature, which is a little buggy.  
> 
> > As a curiosity, I tried looking at what Fedora Core 4 does with this.
> > So I looked for liblapack.a with locate, and it found one in /usr/lib
> > (on a 32bit system). Then I went to have a closer look at the library
> > and it turned out not to be there -- apparently the recent update to
> > lapack had wiped it out, but the locate database was not yet
> > rebuilt...
> 
> Fedora have just split off a separate lapack-devel package containing
> the static library and the symlink liblapack.so.  (Mandrake/Mandriva has
> been doing this for some time. I don't know about SuSE).  The up2date
> service will recognize that it needs to update lapack, but I guess that
> it won't install lapack-devel, as it doesn't know you need it.
> 
> It might have been better to do this in the next release, rather than as
> an update to FC4, but there you go. Better install lapack-devel
> manually.

Yep, and the same with BLAS - which just caused me to spend half a day
wondering why R wasn't being configured with BLAS(generic) anymore when
trying out R2.2.0 alpha at home...

G

> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From tts_boopathy at yahoo.com  Mon Sep 19 21:30:10 2005
From: tts_boopathy at yahoo.com (shanmuha boopathy)
Date: Mon, 19 Sep 2005 12:30:10 -0700 (PDT)
Subject: [Rd] how to extract the column name or value from the numerical
	value of the matrix
Message-ID: <20050919193010.91321.qmail@web33810.mail.mud.yahoo.com>

Dear sir,
 i have a matrix like
 x<-c(1:20)
A<-matrix(x,4,5)
> A
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    5    9   13   17
[2,]    2    6   10   14   18
[3,]    3    7   11   15   19
[4,]    4    8   12   16   20

I want to extract the column value for the matrix
value 11...

or the row value for 14..
how it is possible?

thanks for your help....

with regards,
boopathy.

Thirumalai Shanmuha Boopathy, 
Zimmer no : 07-15,
R?tscher strasse 165, 
52072  Aachen . 
Germany.
 
Home zone   :  0049 - 241 - 9813409
Mobile zone :  0049 - 176 - 23567867


From greg.snow at ihc.com  Mon Sep 19 21:56:02 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Mon, 19 Sep 2005 13:56:02 -0600
Subject: [Rd] [R] how to extract the column name or value from the
 numerical value of the matrix
Message-ID: <s32ec37c.088@lp-msg1.co.ihc.com>

look at ?col and ?row.  One way to use them is:

col(A)[A==11]
row(A)[A==14]

hope this helps,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> shanmuha boopathy <tts_boopathy at yahoo.com> 09/19/05 01:30PM >>>
Dear sir,
 i have a matrix like
 x<-c(1:20)
A<-matrix(x,4,5)
> A
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    5    9   13   17
[2,]    2    6   10   14   18
[3,]    3    7   11   15   19
[4,]    4    8   12   16   20

I want to extract the column value for the matrix
value 11...

or the row value for 14..
how it is possible?

thanks for your help....

with regards,
boopathy.

Thirumalai Shanmuha Boopathy, 
Zimmer no : 07-15,
R?tscher strasse 165, 
52072  Aachen . 
Germany.
 
Home zone   :  0049 - 241 - 9813409
Mobile zone :  0049 - 176 - 23567867

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


From paltr at bio.uio.no  Tue Sep 20 11:24:18 2005
From: paltr at bio.uio.no (paltr@bio.uio.no)
Date: Tue, 20 Sep 2005 11:24:18 +0200 (CEST)
Subject: [Rd] Error report upon using the help.search( ) command (PR#8144)
Message-ID: <20050920092418.CFA1F1DAA6@slim.kubism.ku.dk>

Full_Name: P?l Trosvik
Version: 2.0.1
OS: Windows XP
Submission from: (NULL) (129.240.91.220)


Hi

Upon entering the command: help.search("linear") .I get the following error
report:
Error in rbind(...) : number of columns of matrices must match (see arg 8)

I get the same error message whichever search term I enter between the quotation
marks. This function was working fine just a few weeks ago, and in the mean time
I haven't done anything unusual. All I have done is download a few packages from
CRAN, namely 'pls' and 'splines', as well as 'gplots','gtools' and 'gdata'. I
have no idea what is causing this problem, but I guess it might be a bug. 

I shold perhaps mention that I saw an almost identical bug report entered in the
'not-repoducible' directory of previous bug reports by one Sabyasaschi Ray on
020805.

His problem remains unsolved.

Best regards

P?l Trosvik
Ph.D. student
University of Oslo - Department of Biology/Norwegian Food Research Institute


From maechler at stat.math.ethz.ch  Tue Sep 20 11:40:18 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue, 20 Sep 2005 11:40:18 +0200 (CEST)
Subject: [Rd] Error report upon using the help.search( ) command
	(PR#8144)
Message-ID: <20050920094018.76EF01DAA7@slim.kubism.ku.dk>

>>>>> "paltr" == paltr  <paltr at bio.uio.no>
>>>>>     on Tue, 20 Sep 2005 11:24:18 +0200 (CEST) writes:

    paltr> Full_Name: P?l Trosvik Version: 2.0.1 
    paltr> OS: Windows XP Submission from: (NULL) (129.240.91.220)


    paltr> Upon entering the command: help.search("linear") 
    paltr> I get the following error report: Error in rbind(...) :
    paltr> number of columns of matrices must match (see arg 8)

    paltr> I get the same error message whichever search term I
    paltr> enter between the quotation marks. This function was
    paltr> working fine just a few weeks ago, and in the mean
    paltr> time I haven't done anything unusual. All I have done
    paltr> is download a few packages from CRAN, namely 'pls'
    paltr> and 'splines', as well as 'gplots','gtools' and
    paltr> 'gdata'. I have no idea what is causing this problem,
    paltr> but I guess it might be a bug.

it's a broken package in your library; i.e., one of the packages
you have added to your library is not properly installed.
Something which should not have happened if you installed
packages via the GUI or  install.packages() -- unless you have
interrupted the installation.
It also can happen very well if you use manual unzipping and
other non-supported ways of "putting packages in your library".

If you upgrade your version of R, the problem also goes away:
help.search() will produce warnings and continue searching
instead of producing an error when encountering incorrectly
installed packages.  So, please do upgrade.


    paltr> I shold perhaps mention that I saw an almost
    paltr> identical bug report entered in the 'not-repoducible'
    paltr> directory of previous bug reports by one Sabyasaschi
    paltr> Ray on 020805.

    paltr> His problem remains unsolved.

Well, I think this is about 3rd or 4th time the topic has come up.

Note that you are *NOT* supposed to send bug reports to R-bugs
when you use outdated versions of R.
It's fine to ask about it on R-help or R-devel if appropriate,
but sending a bug report for an outdated version is "no no!"

Regards,
Martin Maechler, ETH Zurich

    paltr> Best regards

    paltr> P?l Trosvik Ph.D. student University of Oslo -
    paltr> Department of Biology/Norwegian Food Research
    paltr> Institute


From ripley at stats.ox.ac.uk  Tue Sep 20 11:46:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Sep 2005 10:46:48 +0100 (BST)
Subject: [Rd] (PR#8144) Error report upon using the help.search( )
	command
In-Reply-To: <20050920092418.CFA1F1DAA6@slim.kubism.ku.dk>
References: <20050920092418.CFA1F1DAA6@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0509201035530.13700@gannet.stats>

Please do not send a bug report on an obselete version of R.  2.1.1 is 
current and 2.2.0 is in alpha-testing.  (This is covered in the posting 
guide and the FAQ.)

It has been the case that a broken package DESCRIPTION could cause this, 
but as the comment on PR#8144 says, that has already been fixed.

If you use R's debugging tools you can find out which package is causing 
the problem and remove it.


On Tue, 20 Sep 2005 paltr at bio.uio.no wrote:

> Full_Name: P?l Trosvik
> Version: 2.0.1
> OS: Windows XP
> Submission from: (NULL) (129.240.91.220)
>
>
> Hi
>
> Upon entering the command: help.search("linear") .I get the following error
> report:
> Error in rbind(...) : number of columns of matrices must match (see arg 8)
>
> I get the same error message whichever search term I enter between the quotation
> marks. This function was working fine just a few weeks ago, and in the mean time
> I haven't done anything unusual. All I have done is download a few packages from
> CRAN, namely 'pls' and 'splines', as well as 'gplots','gtools' and 'gdata'. I
> have no idea what is causing this problem, but I guess it might be a bug.
>
> I shold perhaps mention that I saw an almost identical bug report entered in the
> 'not-repoducible' directory of previous bug reports by one Sabyasaschi Ray on
> 020805.

2002-08-05 or 2005-08-05 or what?

> His problem remains unsolved.

I don't think so. If this is PR#8044, please do read the comment:

   No R version given, not reproducible.
   This is probably due to a broken package, and if so already fixed.
                                                 ^^^^^^^^^^^^^^^^^^^

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From W.E.Wolski at ncl.ac.uk  Tue Sep 20 12:15:38 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Tue, 20 Sep 2005 12:15:38 +0200
Subject: [Rd] configuration and installation of R packages with C/C++
	library dependencies.
Message-ID: <432FE14A.3020206@ncl.ac.uk>

Dear R-developers, Bioc-developers,

I am working on an R package which provides a R binding to a C library, 
which again depends on two other "non-standard" C++ libraries.
I have this libraries installed on my box of course and I specified the 
library location in the Makevars file.

However I thinking about to make the package available to other users 
and wonder

a) Where I should provide the information which C++ libraries must be 
installed on the computer? README/ DESCRIPTION file?
b) The library location on other users computers will be in a different 
place than specified by me in the Makevars file.  What mechanism of 
finding out the library locations, or prompting the user to specify them 
are integrated in the package installation procedure?
c) Which packages available on CRAN or BioConductor are *good* practice 
examples?


Thanks
Eryk




From ripley at stats.ox.ac.uk  Tue Sep 20 12:36:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Sep 2005 11:36:33 +0100 (BST)
Subject: [Rd] configuration and installation of R packages with C/C++
 library dependencies.
In-Reply-To: <432FE14A.3020206@ncl.ac.uk>
References: <432FE14A.3020206@ncl.ac.uk>
Message-ID: <Pine.LNX.4.61.0509201129540.18833@gannet.stats>

On Tue, 20 Sep 2005, Witold Eryk Wolski wrote:

Please ask R development questions on the R list and not cross-post.

> Dear R-developers, Bioc-developers,
>
> I am working on an R package which provides a R binding to a C library, which 
> again depends on two other "non-standard" C++ libraries.
> I have this libraries installed on my box of course and I specified the 
> library location in the Makevars file.
>
> However I thinking about to make the package available to other users and 
> wonder
>
> a) Where I should provide the information which C++ libraries must be 
> installed on the computer? README/ DESCRIPTION file?

As stated in `Writing R Extensions': the SystemRequirements field in 
DESCRIPTION or a README file.

> b) The library location on other users computers will be in a different place 
> than specified by me in the Makevars file.  What mechanism of finding out the 
> library locations, or prompting the user to specify them are integrated in 
> the package installation procedure?

As stated in `Writing R Extensions' section 1.2: use a configure file.

> c) Which packages available on CRAN or BioConductor are *good* practice 
> examples?

Several, e.g. RODBC (which is used as an example in `Writing R 
Extensions', section 1.2).


Did we mention this was all in `Writing R Extensions'?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jarioksa at sun3.oulu.fi  Tue Sep 20 15:25:28 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue, 20 Sep 2005 16:25:28 +0300
Subject: [Rd] Shy Suggestion?
Message-ID: <1127222728.21824.15.camel@biol102145.oulu.fi>

The R-exts manual says about 'Suggests' field in package DESCRIPTION:

"The optional `Suggests' field uses the same syntax as `Depends' and
lists packages that are not necessarily needed."

However, this seems to be a suggestion you cannot refuse. If you suggest
packages:

(a line from DESCRIPTION):
Suggests: MASS, ellipse, rgl, mgcv, akima, lattice

This is what happens:

$ /tmp/R-alpha/bin/R CMD check vegan
* checking for working latex ... OK
* using log directory '/home/jarioksa/devel/R/vegan.Rcheck'
* using R version 2.2.0, 2005-09-19
* checking for file 'vegan/DESCRIPTION' ... OK
* this is package 'vegan' version '1.7-75'
... clip ...
* checking package dependencies ... ERROR
Packages required but not available:
  ellipse rgl akima

In my cultural context suggesting a package means that it is not
necessarily needed and the check should not fail, although some
functionality would be unavailable without those packages.  I want the
package to pass the tests in a clean standard environment without
forcing anybody to load any extra packages. Is there a possibility to be
modest and shy in suggestions so that it would be up to the user to get
those extra packages needed without requiring them in R CMD check?

I stumbled on this with earlier versions of R, and then my solution was
to suggest nothing. 

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/


From tlumley at u.washington.edu  Tue Sep 20 15:27:49 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 20 Sep 2005 06:27:49 -0700 (PDT)
Subject: [Rd] as.data.frame segfaults on large lists (PR#8141)
In-Reply-To: <x2ll1u48wo.fsf@turmalin.kubism.ku.dk>
References: <20050918153744.AB3C0CC03@slim.kubism.ku.dk>
	<x2ll1u48wo.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.63a.0509200627170.28721@homer21.u.washington.edu>


Under Valgrind on x86_64 I get
==27405==  Access not within mapped region at address 0x33FFEFD8
==27405==    at 0x447045: Rf_substituteList (coerce.c:2003)
==27405== Stack overflow in thread 1: can't grow stack to 0x33FFEF98


 	-thomas

On Sun, 18 Sep 2005, Peter Dalgaard wrote:

> ulrich.poetter at ruhr-uni-bochum.de writes:
>
>> Full_Name: Ulrich Poetter
>> Version: 2.1.1
>> OS: i686-pc-linux-gnu FC2
>> Submission from: (NULL) (134.147.95.187)
>>
>>
>> as.data.frame() segfaults on lists with very many elements:
>>
>>> dfn <- rep(list(rep(0,2)),198000)
>>> test <- as.data.frame.list(dfn)
>>
>> Process R segmentation fault at Sun Sep 18 17:06:02 2005
>
> Not for me on FC4. The process size grows to about 180M and the system
> thrashes badly, but the calculation runs to completion.
>
> It's not unlikely that we are ignoring a failed allocation somewhere,
> but there's not much hope of finding it from the available
> information. You could try running under gdb and see where things go
> wrong for you.
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From tlumley at u.washington.edu  Tue Sep 20 15:28:07 2005
From: tlumley at u.washington.edu (tlumley@u.washington.edu)
Date: Tue, 20 Sep 2005 15:28:07 +0200 (CEST)
Subject: [Rd] as.data.frame segfaults on large lists (PR#8141)
Message-ID: <20050920132807.320D41DAA5@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

---1903393524-540054921-1127222869=:28721
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE


Under Valgrind on x86_64 I get
=3D=3D27405=3D=3D  Access not within mapped region at address 0x33FFEFD8
=3D=3D27405=3D=3D    at 0x447045: Rf_substituteList (coerce.c:2003)
=3D=3D27405=3D=3D Stack overflow in thread 1: can't grow stack to 0x33FFEF9=
8


 =09-thomas

On Sun, 18 Sep 2005, Peter Dalgaard wrote:

> ulrich.poetter at ruhr-uni-bochum.de writes:
>
>> Full_Name: Ulrich Poetter
>> Version: 2.1.1
>> OS: i686-pc-linux-gnu FC2
>> Submission from: (NULL) (134.147.95.187)
>>
>>
>> as.data.frame() segfaults on lists with very many elements:
>>
>>> dfn <- rep(list(rep(0,2)),198000)
>>> test <- as.data.frame.list(dfn)
>>
>> Process R segmentation fault at Sun Sep 18 17:06:02 2005
>
> Not for me on FC4. The process size grows to about 180M and the system
> thrashes badly, but the calculation runs to completion.
>
> It's not unlikely that we are ignoring a failed allocation somewhere,
> but there's not much hope of finding it from the available
> information. You could try running under gdb and see where things go
> wrong for you.
>
> --
>   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 353279=
18
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327=
907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley=09=09=09Assoc. Professor, Biostatistics
tlumley at u.washington.edu=09University of Washington, Seattle
---1903393524-540054921-1127222869=:28721--


From rpeng at jhsph.edu  Tue Sep 20 15:42:22 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 20 Sep 2005 09:42:22 -0400
Subject: [Rd] Shy Suggestion?
In-Reply-To: <1127222728.21824.15.camel@biol102145.oulu.fi>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
Message-ID: <433011BE.8090007@jhsph.edu>

I think this needs to fail because packages listed in 'Suggests:' may, for 
example, be needed in the examples.  How can 'R CMD check' run the examples and 
verify that they are executable if those packages are not available?  I suppose 
you could put the examples in a \dontrun{}.

-roger

Jari Oksanen wrote:
> The R-exts manual says about 'Suggests' field in package DESCRIPTION:
> 
> "The optional `Suggests' field uses the same syntax as `Depends' and
> lists packages that are not necessarily needed."
> 
> However, this seems to be a suggestion you cannot refuse. If you suggest
> packages:
> 
> (a line from DESCRIPTION):
> Suggests: MASS, ellipse, rgl, mgcv, akima, lattice
> 
> This is what happens:
> 
> $ /tmp/R-alpha/bin/R CMD check vegan
> * checking for working latex ... OK
> * using log directory '/home/jarioksa/devel/R/vegan.Rcheck'
> * using R version 2.2.0, 2005-09-19
> * checking for file 'vegan/DESCRIPTION' ... OK
> * this is package 'vegan' version '1.7-75'
> ... clip ...
> * checking package dependencies ... ERROR
> Packages required but not available:
>   ellipse rgl akima
> 
> In my cultural context suggesting a package means that it is not
> necessarily needed and the check should not fail, although some
> functionality would be unavailable without those packages.  I want the
> package to pass the tests in a clean standard environment without
> forcing anybody to load any extra packages. Is there a possibility to be
> modest and shy in suggestions so that it would be up to the user to get
> those extra packages needed without requiring them in R CMD check?
> 
> I stumbled on this with earlier versions of R, and then my solution was
> to suggest nothing. 
> 
> cheers, jari oksanen

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/


From jarioksa at sun3.oulu.fi  Tue Sep 20 15:48:12 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue, 20 Sep 2005 16:48:12 +0300
Subject: [Rd] Shy Suggestion?
In-Reply-To: <433011BE.8090007@jhsph.edu>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
	<433011BE.8090007@jhsph.edu>
Message-ID: <1127224092.21824.20.camel@biol102145.oulu.fi>

On Tue, 2005-09-20 at 09:42 -0400, Roger D. Peng wrote:
> I think this needs to fail because packages listed in 'Suggests:' may, for 
> example, be needed in the examples.  How can 'R CMD check' run the examples and 
> verify that they are executable if those packages are not available?  I suppose 
> you could put the examples in a \dontrun{}.
> 
Yes, that's what I do, and exactly for that reason: if something is not
necessarily needed (= 'suggestion' in this culture), it should not be
required in tests. However, if I don't use \dontrun{} for a
non-recommended package, the check would fail and I would get the needed
information: so why should the check fail already when checking
DESCRIPTION?

cheers, jari oksanen


From ripley at stats.ox.ac.uk  Tue Sep 20 16:03:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Sep 2005 15:03:45 +0100 (BST)
Subject: [Rd] Shy Suggestion?
In-Reply-To: <1127224092.21824.20.camel@biol102145.oulu.fi>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
	<433011BE.8090007@jhsph.edu>
	<1127224092.21824.20.camel@biol102145.oulu.fi>
Message-ID: <Pine.LNX.4.61.0509201459490.7077@gannet.stats>

On Tue, 20 Sep 2005, Jari Oksanen wrote:

> On Tue, 2005-09-20 at 09:42 -0400, Roger D. Peng wrote:
>> I think this needs to fail because packages listed in 'Suggests:' may, for
>> example, be needed in the examples.  How can 'R CMD check' run the examples and
>> verify that they are executable if those packages are not available?  I suppose
>> you could put the examples in a \dontrun{}.
>>
> Yes, that's what I do, and exactly for that reason: if something is not
> necessarily needed (= 'suggestion' in this culture), it should not be
> required in tests. However, if I don't use \dontrun{} for a
> non-recommended package, the check would fail and I would get the needed
> information: so why should the check fail already when checking
> DESCRIPTION?

Because it is a `check', and it assembles all the information needed at 
the beginning.  I'd certainly prefer to know at the beginning rather than 
20 minutes into running the tests.

R CMD check is not really for end users: it is for package writers, 
repository maintainers and for people checking proposed R changes.  Those 
people want all the checks possible to be done.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rpeng at jhsph.edu  Tue Sep 20 16:03:50 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 20 Sep 2005 10:03:50 -0400
Subject: [Rd] Shy Suggestion?
In-Reply-To: <1127224092.21824.20.camel@biol102145.oulu.fi>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>	
	<433011BE.8090007@jhsph.edu>
	<1127224092.21824.20.camel@biol102145.oulu.fi>
Message-ID: <433016C6.3090100@jhsph.edu>

I think the reason is that the standard for 'R CMD check' is that examples in 
help pages are guaranteed to be executable by the user (as long as the 
requirements are met).  There is no way to guarantee this without having the 
packages installed.  So strictly speaking, the 'Suggested' packages are not 
needed by the *user*, but are needed by the *maintainer*.

Perhaps, you differ with the standard itself, but I personally think it's a good 
one.

-roger

Jari Oksanen wrote:
> On Tue, 2005-09-20 at 09:42 -0400, Roger D. Peng wrote:
> 
>>I think this needs to fail because packages listed in 'Suggests:' may, for 
>>example, be needed in the examples.  How can 'R CMD check' run the examples and 
>>verify that they are executable if those packages are not available?  I suppose 
>>you could put the examples in a \dontrun{}.
>>
> 
> Yes, that's what I do, and exactly for that reason: if something is not
> necessarily needed (= 'suggestion' in this culture), it should not be
> required in tests. However, if I don't use \dontrun{} for a
> non-recommended package, the check would fail and I would get the needed
> information: so why should the check fail already when checking
> DESCRIPTION?
> 
> cheers, jari oksanen
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/


From ggrothendieck at gmail.com  Tue Sep 20 16:06:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 20 Sep 2005 10:06:33 -0400
Subject: [Rd] Shy Suggestion?
In-Reply-To: <1127224092.21824.20.camel@biol102145.oulu.fi>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
	<433011BE.8090007@jhsph.edu>
	<1127224092.21824.20.camel@biol102145.oulu.fi>
Message-ID: <971536df0509200706171c26d@mail.gmail.com>

On 9/20/05, Jari Oksanen <jarioksa at sun3.oulu.fi> wrote:
> On Tue, 2005-09-20 at 09:42 -0400, Roger D. Peng wrote:
> > I think this needs to fail because packages listed in 'Suggests:' may, for
> > example, be needed in the examples.  How can 'R CMD check' run the examples and
> > verify that they are executable if those packages are not available?  I suppose
> > you could put the examples in a \dontrun{}.
> >
> Yes, that's what I do, and exactly for that reason: if something is not
> necessarily needed (= 'suggestion' in this culture), it should not be
> required in tests. However, if I don't use \dontrun{} for a
> non-recommended package, the check would fail and I would get the needed
> information: so why should the check fail already when checking
> DESCRIPTION?
> 

Also one could not have any demos that depend on the missing
packages nor vignettes.

1. Note that you can use:

if (require(mypackage)) {
  myfunction1()
  myfunction2()
}

which will only run my function if mypackage is accessible.
The main downside is that you don't interspersed input and
output but rather it shows the above all at once since its
one statement and then one sees all the output.

2. One could do:

if (require(mypackage)) myfunction1()
if (require(mypackage)) myfunction2()

but that is quite ugly.

3. Another possibility is:

if (!require(mypackage)) myfunction1 <- myfunction2 <- dummyfunction
myfunction1()
myfunction2()
if (!require(mypackage)) myfunction1 <- get("myfunction1", "package:mypackage")
if (!require(mypackage)) myfunction2 <- get("myfunction2", "package:mypackage")

None of these is really entirely satisfactory and I think we need some
better mechanism/solution for situations like this.

Note that this comes up not only in the situation you mention but also 
if you are working on a package whose purpose is to interface to 
external code since that external code may not be available but you
still want it to pass R CMD check.


From Achim.Zeileis at wu-wien.ac.at  Tue Sep 20 16:14:09 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 20 Sep 2005 16:14:09 +0200 (CEST)
Subject: [Rd] Shy Suggestion?
In-Reply-To: <1127224092.21824.20.camel@biol102145.oulu.fi>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
	<433011BE.8090007@jhsph.edu>
	<1127224092.21824.20.camel@biol102145.oulu.fi>
Message-ID: <Pine.LNX.4.58.0509201608150.13157@thorin.ci.tuwien.ac.at>

On Tue, 20 Sep 2005, Jari Oksanen wrote:

> On Tue, 2005-09-20 at 09:42 -0400, Roger D. Peng wrote:
> > I think this needs to fail because packages listed in 'Suggests:' may, for
> > example, be needed in the examples.  How can 'R CMD check' run the examples and
> > verify that they are executable if those packages are not available?  I suppose
> > you could put the examples in a \dontrun{}.
> >
> Yes, that's what I do, and exactly for that reason: if something is not
> necessarily needed (= 'suggestion' in this culture), it should not be
> required in tests. However, if I don't use \dontrun{} for a
> non-recommended package, the check would fail and I would get the needed
> information: so why should the check fail already when checking
> DESCRIPTION?

My understanding is that `suggests' only gives suggestions for the user
not the developer. This means that if you as the developer run R CMD check
you need to have the suggested packages available (in order to check all
code in the examples/vignettes/etc.) but the user does not have to have
them for installing/attaching the package.

For example, in my packages if frequently have examples of type

  if(require(foo)) {
    x <- foo(...)
    bar(x)
  }

where foo is a suggested package. This code would never be R CMD checked
if I just don't install the package myself.

Best,
Z

> cheers, jari oksanen
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rgentlem at fhcrc.org  Tue Sep 20 16:21:37 2005
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Tue, 20 Sep 2005 07:21:37 -0700
Subject: [Rd] Shy Suggestion?
In-Reply-To: <Pine.LNX.4.61.0509201459490.7077@gannet.stats>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>	<433011BE.8090007@jhsph.edu>	<1127224092.21824.20.camel@biol102145.oulu.fi>
	<Pine.LNX.4.61.0509201459490.7077@gannet.stats>
Message-ID: <43301AF1.9080902@fhcrc.org>



Prof Brian Ripley wrote:
> On Tue, 20 Sep 2005, Jari Oksanen wrote:
> 
> 
>>On Tue, 2005-09-20 at 09:42 -0400, Roger D. Peng wrote:
>>
>>>I think this needs to fail because packages listed in 'Suggests:' may, for
>>>example, be needed in the examples.  How can 'R CMD check' run the examples and
>>>verify that they are executable if those packages are not available?  I suppose
>>>you could put the examples in a \dontrun{}.
>>>
>>
>>Yes, that's what I do, and exactly for that reason: if something is not
>>necessarily needed (= 'suggestion' in this culture), it should not be
>>required in tests. However, if I don't use \dontrun{} for a
>>non-recommended package, the check would fail and I would get the needed
>>information: so why should the check fail already when checking
>>DESCRIPTION?
> 
> 
> Because it is a `check', and it assembles all the information needed at 
> the beginning.  I'd certainly prefer to know at the beginning rather than 
> 20 minutes into running the tests.
> 
> R CMD check is not really for end users: it is for package writers, 
> repository maintainers and for people checking proposed R changes.  Those 
> people want all the checks possible to be done.
> 

   Some of us also want a mechanism similar to this proposal. There are 
situations where the usage is of a minimal nature, the package may not 
be available on all architectures and the package developer is perfectly 
capable of setting up their tests to deal with the presence or lack 
there of. What happens now is that in these sorts of situations 
developers are tending to simply not list the dependency anywhere, and 
that is not a particularly good solution either. I would also point out, 
to those who believe that forcing all dependencies to be declared and 
enforced that name spaces provide a rather large hole.

My understanding of the original intent of Suggests was that it not be 
quite so rigid, but as that has not been how others interpreted it, it 
seems we should have another level of dependency (Uses has been bandied 
about).

  As I recall the discussion it was something like
  Depends:  major functionality in the package will not
      work without other packages listed here

  Suggests:  minor functionality (eg. some functions and or options will 
fail) if these packages are not available

  Uses: package is used for an example, or the current package provides 
an interface to the other package (where else do I put that code?) which
  will be used by anyone wanting to use both

  As I said above, and will try to emphasize, I really do not want R CMD 
check to do any checking of Uses (unless asked to do so). Developers 
that use Uses need to make sure that their package works and passes R 
CMD check whether the package is there or not.

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From sfalcon at fhcrc.org  Tue Sep 20 17:11:51 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 20 Sep 2005 08:11:51 -0700
Subject: [Rd] Shy Suggestion?
In-Reply-To: <43301AF1.9080902@fhcrc.org> (Robert Gentleman's message of "Tue, 
	20 Sep 2005 07:21:37 -0700")
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
	<433011BE.8090007@jhsph.edu>
	<1127224092.21824.20.camel@biol102145.oulu.fi>
	<Pine.LNX.4.61.0509201459490.7077@gannet.stats>
	<43301AF1.9080902@fhcrc.org>
Message-ID: <m2d5n3hiyw.fsf@macaroni.local>

On 20 Sep 2005, rgentlem at fhcrc.org wrote:
> As I said above, and will try to emphasize, I really do not want R
> CMD check to do any checking of Uses (unless asked to do
> so). Developers that use Uses need to make sure that their package
> works and passes R CMD check whether the package is there or not.

One of the potential gotchas with the current Suggests and R CMD check
setup is that developers cannot easily test whether or not their package
behaves well (e.g. the examples fail gracefully) when packages listed
in Suggests are not available.

As a package developer, I'd like easy ways to check my package under
the "everything is there" scenario and under the "only the minimum
requirements are available" scenario.

+ seth


From pgilbert at bank-banque-canada.ca  Tue Sep 20 17:30:10 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 20 Sep 2005 11:30:10 -0400
Subject: [Rd] Shy Suggestion?
In-Reply-To: <m2d5n3hiyw.fsf@macaroni.local>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>	<433011BE.8090007@jhsph.edu>	<1127224092.21824.20.camel@biol102145.oulu.fi>	<Pine.LNX.4.61.0509201459490.7077@gannet.stats>	<43301AF1.9080902@fhcrc.org>
	<m2d5n3hiyw.fsf@macaroni.local>
Message-ID: <43302B02.5030201@bank-banque-canada.ca>

Seth Falcon wrote:

>On 20 Sep 2005, rgentlem at fhcrc.org wrote:
>  
>
>>As I said above, and will try to emphasize, I really do not want R
>>CMD check to do any checking of Uses (unless asked to do
>>so). Developers that use Uses need to make sure that their package
>>works and passes R CMD check whether the package is there or not.
>>    
>>
>
>One of the potential gotchas with the current Suggests and R CMD check
>setup is that developers cannot easily test whether or not their package
>behaves well (e.g. the examples fail gracefully) when packages listed
>in Suggests are not available.
>
>As a package developer, I'd like easy ways to check my package under
>the "everything is there" scenario and under the "only the minimum
>requirements are available" scenario.
>
I suspect a lot of us are doing this by using

>Achim Zeileis wrote:
>  if(require(foo)) {
>    x <- foo(...)
>    bar(x)
>  }
>  
>
and not putting foo in "Suggests."  Robert's solution will solve this by 
having us put foo in "Uses," but then will "Suggests" still have a 
purpose?  Perhaps it would be better just to return to what many of us 
thought was the original meaning of "Suggests."

I related problem is that if there are circular "Suggests" I think there 
is a problem.

Paul

>
>+ seth
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>  
>


From jamatos at fc.up.pt  Tue Sep 20 17:45:54 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Tue, 20 Sep 2005 16:45:54 +0100
Subject: [Rd] looks in liblapack.a not liblapack.so
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat>
Message-ID: <dgpari$a96$1@sea.gmane.org>

Martyn Plummer wrote:

> Fedora have just split off a separate lapack-devel package containing
> the static library and the symlink liblapack.so.  (Mandrake/Mandriva has
> been doing this for some time. I don't know about SuSE).  The up2date
> service will recognize that it needs to update lapack, but I guess that
> it won't install lapack-devel, as it doesn't know you need it.

  You are right.

> It might have been better to do this in the next release, rather than as
> an update to FC4, but there you go. Better install lapack-devel
> manually.

  lapack belongs to Extras and not to Core. Extras is a rolling release.

  The change was necessary to allow atlas to compile and interact with
lapack.

  atlas is on the queue to Fedora Extras, it is in the review phase now.

-- 
Jos? Ab?lio


From cpaulse at aecom.yu.edu  Tue Sep 20 20:00:06 2005
From: cpaulse at aecom.yu.edu (Chris Paulse)
Date: Tue, 20 Sep 2005 14:00:06 -0400
Subject: [Rd] indicating progress in RGui from a c function
Message-ID: <20050920180014.BA49D2FCB@post.aecom.yu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050920/414caca5/attachment.pl

From ripley at stats.ox.ac.uk  Tue Sep 20 20:27:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Sep 2005 19:27:40 +0100 (BST)
Subject: [Rd] indicating progress in RGui from a c function
In-Reply-To: <20050920180014.BA49D2FCB@post.aecom.yu.edu>
References: <20050920180014.BA49D2FCB@post.aecom.yu.edu>
Message-ID: <Pine.LNX.4.61.0509201921180.23942@gannet.stats>

On Tue, 20 Sep 2005, Chris Paulse wrote:

> I'm sure this issue has come up before, but searching the archives didn't
> lead me to a solution or resolution of the issue.

It is documented in the rw-FAQ: Q8.8 in the R-2.2.0-alpha version.

> I'd like to indicate progress of a calculation from within a C shared
> library to the R GUI.  The apparent function call is flush.console() after
> RPrintf, but it isn't clear to me what the easiest way to do this is.  Would
> it be possible to add a flag to RPrintf to have this done implicitly?

No.  It's a varargs function and we cannot go round changing the API.

> 	[[alternative HTML version deleted]]

Please don't send HTML mail as we do ask in the posting guide.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Tue Sep 20 20:58:21 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 20 Sep 2005 11:58:21 -0700
Subject: [Rd] indicating progress in RGui from a c function
In-Reply-To: <20050920180014.BA49D2FCB@post.aecom.yu.edu> (Chris Paulse's
	message of "Tue, 20 Sep 2005 14:00:06 -0400")
References: <20050920180014.BA49D2FCB@post.aecom.yu.edu>
Message-ID: <m2oe6nefci.fsf@macaroni.local>

On 20 Sep 2005, cpaulse at aecom.yu.edu wrote:
> I'd like to indicate progress of a calculation from within a C
> shared library to the R GUI.  The apparent function call is
> flush.console() after RPrintf, but it isn't clear to me what the
> easiest way to do this is.  Would it be possible to add a flag to
> RPrintf to have this done implicitly?

When you do get this sorted out, you may want to consider a verbose
option that toggles such updating of the GUI.  When users want to run
code in a non-interactive mode, such output can get in the way.

You could use interactive() to determine a default value for the
verbose option.

Best,

+ seth


From Kurt.Hornik at wu-wien.ac.at  Tue Sep 20 18:00:08 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Tue, 20 Sep 2005 18:00:08 +0200
Subject: [Rd] Shy Suggestion?
In-Reply-To: <433016C6.3090100@jhsph.edu>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
	<433011BE.8090007@jhsph.edu>
	<1127224092.21824.20.camel@biol102145.oulu.fi>
	<433016C6.3090100@jhsph.edu>
Message-ID: <17200.12808.872332.67431@mithrandir.hornik.net>

>>>>> Roger D Peng writes:

> I think the reason is that the standard for 'R CMD check' is that
> examples in help pages are guaranteed to be executable by the user (as
> long as the requirements are met).  There is no way to guarantee this
> without having the packages installed.  So strictly speaking, the
> 'Suggested' packages are not needed by the *user*, but are needed by
> the *maintainer*.

> Perhaps, you differ with the standard itself, but I personally think
> it's a good one.

Those who really want to run R CMD check without forcing the suggestions
can do so via setting the "internal" environment variable
_R_CHECK_FORCE_SUGGESTS_ to something "false", the test is via

  if(!identical(as.logical(Sys.getenv("_R_CHECK_FORCE_SUGGESTS_")),
                FALSE))

If people feel very strongly about this, we could turn this into a check
profile variable to be set in ~/.R/check.conf.  Personally, both as a
developer and a CRAN maintainer I see little need in not forcing the
suggested packages at check time, as in both scenarios I prefer to act
as defensively as possible.

-k


From mwtoews at sfu.ca  Tue Sep 20 22:51:18 2005
From: mwtoews at sfu.ca (mwtoews@sfu.ca)
Date: Tue, 20 Sep 2005 22:51:18 +0200 (CEST)
Subject: [Rd] coplot using Date object (PR#8147)
Message-ID: <20050920205118.106081C6B3@slim.kubism.ku.dk>

Full_Name: Michael Toews
Version: 2.1.1
OS: WinXP (SP2)
Submission from: (NULL) (142.58.206.114)


This is a simple feature request concerning the display of the axis in the
coplot function.
Consider an arbritrary set of values from 1990-1999:

date <- as.Date(paste(rep(1990:1999,each=365),1:365),"%Y %j")
mon <- factor(months(date,T),levels=month.abb)
value <- runif(3650)

# Now create coplot for each month:
coplot(value ~ date | mon)

# The resulting date on the x-axis is not like the axis produced from:
plot(value ~ date)


From ripley at stats.ox.ac.uk  Tue Sep 20 23:10:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Sep 2005 22:10:39 +0100 (BST)
Subject: [Rd] coplot using Date object (PR#8147)
In-Reply-To: <20050920205118.106081C6B3@slim.kubism.ku.dk>
References: <20050920205118.106081C6B3@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0509202201280.4109@gannet.stats>

On Tue, 20 Sep 2005 mwtoews at sfu.ca wrote:

> Full_Name: Michael Toews
> Version: 2.1.1
> OS: WinXP (SP2)
> Submission from: (NULL) (142.58.206.114)
>
>
> This is a simple feature request concerning the display of the axis in the
> coplot function.
> Consider an arbritrary set of values from 1990-1999:
>
> date <- as.Date(paste(rep(1990:1999,each=365),1:365),"%Y %j")
> mon <- factor(months(date,T),levels=month.abb)
> value <- runif(3650)
>
> # Now create coplot for each month:
> coplot(value ~ date | mon)
>
> # The resulting date on the x-axis is not like the axis produced from:
> plot(value ~ date)

Why do you expect it to be?  plot() is generic, and coplot() is not: 
plot(value ~ date) is just a round-the-houses way to generate the call 
plot(date, value) (and that is why it happens to work with Date objects).

Think of coplot() as a limited predecessor of lattice graphics, which also 
precedes class "Date".  Lattice currently handles POSIXct date-times, and 
it would be nice if it handled Date too.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From charlie at stat.umn.edu  Wed Sep 21 03:19:41 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Tue, 20 Sep 2005 20:19:41 -0500
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <1127119440.3624.5.camel@seurat>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
Message-ID: <20050921011941.GA22326@stat.umn.edu>

On Mon, Sep 19, 2005 at 10:44:00AM +0200, Martyn Plummer wrote:
> On Sat, 2005-09-17 at 17:19 -0500, Charles Geyer wrote:
> > I can't compile R-alpha on AMD 64 ...
> 
> You would need to modify the LDFLAGS and CPPFLAGS environment variables,
> as these default to -L/usr/local/lib and -I/usr/local/include
> respectively.  See Appendix B.3.3 of the R Installation and
> Administration manual, which gives a warning about 64-bit systems.

That does not help.  The problem has (apparently) nothing to do
with /usr/local (and the 32 bit compatibility libraries we have there).

> You can also use the --with-readline configure flag to specify the exact
> location of the readline library you wish to use.

That's it.  I need

./configure --prefix=/APPS/Foo/Alpha64 --with-lapack=/usr/lib64/liblapack.so.3

> I hope this helps.

Yes it does.  Everything seems to work except the rpvm and rcdd contributed
packages did not install.  Looking at the problem with rcdd, I see what the
main problem was all along.  On 32 bit you can extract a .o out of a .a to
put in a .so.  On 64 bit, you can't.  It's pickier apparently.  The makefile
for cddlib doesn't make shared libraries, so I'm out of luck for rcdd on AMD64
until I get that fixed.

Now this problem makes a lot more sense.

Sorry to be so stupid.  I knew you could do --with-lapack=something but forgot
(meaning I have a vague recollection of reading about this once, now that I'm
reminded of it).

Anyway we now have R-2.2.0 alpha on AMD64 on SuSE 9.3 with

> dim(installed.packages())
[1] 80 10

Thanks for the help.

I still don't understand why gcc -shared even bothers to look in *.a
(on AMD64) when it won't do the slightest bit of good.  Maybe I'm still
ignorant of some important technical issue (maybe? more like with very
high probability!)

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie at stat.umn.edu


From luke at stat.uiowa.edu  Wed Sep 21 04:43:51 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Sep 2005 21:43:51 -0500 (CDT)
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <20050921011941.GA22326@stat.umn.edu>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<20050921011941.GA22326@stat.umn.edu>
Message-ID: <Pine.LNX.4.63.0509202124040.9741@itasca2.wildberry.org>

On Tue, 20 Sep 2005, Charles Geyer wrote:

> On Mon, Sep 19, 2005 at 10:44:00AM +0200, Martyn Plummer wrote:
>> On Sat, 2005-09-17 at 17:19 -0500, Charles Geyer wrote:
>>> I can't compile R-alpha on AMD 64 ...
>>
>> You would need to modify the LDFLAGS and CPPFLAGS environment variables,
>> as these default to -L/usr/local/lib and -I/usr/local/include
>> respectively.  See Appendix B.3.3 of the R Installation and
>> Administration manual, which gives a warning about 64-bit systems.
>
> That does not help.  The problem has (apparently) nothing to do
> with /usr/local (and the 32 bit compatibility libraries we have there).
>
>> You can also use the --with-readline configure flag to specify the exact
>> location of the readline library you wish to use.
>
> That's it.  I need
>
> ./configure --prefix=/APPS/Foo/Alpha64 --with-lapack=/usr/lib64/liblapack.so.3
>
>> I hope this helps.
>
> Yes it does.  Everything seems to work except the rpvm and rcdd contributed
> packages did not install.  Looking at the problem with rcdd, I see what the
> main problem was all along.  On 32 bit you can extract a .o out of a .a to
> put in a .so.  On 64 bit, you can't.  It's pickier apparently.  The makefile
> for cddlib doesn't make shared libraries, so I'm out of luck for rcdd on AMD64
> until I get that fixed.
>
> Now this problem makes a lot more sense.
>
> Sorry to be so stupid.  I knew you could do --with-lapack=something but forgot
> (meaning I have a vague recollection of reading about this once, now that I'm
> reminded of it).
>
> Anyway we now have R-2.2.0 alpha on AMD64 on SuSE 9.3 with
>
>> dim(installed.packages())
> [1] 80 10
>
> Thanks for the help.
>
> I still don't understand why gcc -shared even bothers to look in *.a
> (on AMD64) when it won't do the slightest bit of good.  Maybe I'm still
> ignorant of some important technical issue (maybe? more like with very
> high probability!)
>

The issue is not the library but whether the code is compiled as
position-independent code (PIC) or not.  Many .a libraries are built
as PIC and they can be used to create shared objects, you just get
copies of the modules you use linked in.  PIC code can be slower,
which is why some prefer to build .a libraries as non-PIC.

I'm not sure why one rarely runs into non-PIC issues on i386--it may
be that gcc at least is always producing PIC code there.  It does come
up on other architectures though, in particular on x86_64.  It seems
that most Linux distros that provide pvm only provide .a libraries,
but some build these with PIC some don't.  Red Hat Enterprise WS4
seems to be non-PIC, FC3 and FC4 seem to be PIC.  If your distro is
non-PIC you will need to build your own PIC version of pvm and tell
rpvm where to find it.

luke


-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jarioksa at sun3.oulu.fi  Wed Sep 21 09:23:30 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 21 Sep 2005 10:23:30 +0300
Subject: [Rd] Shy Suggestion?
In-Reply-To: <433016C6.3090100@jhsph.edu>
References: <1127222728.21824.15.camel@biol102145.oulu.fi>
	<433011BE.8090007@jhsph.edu>
	<1127224092.21824.20.camel@biol102145.oulu.fi>
	<433016C6.3090100@jhsph.edu>
Message-ID: <1127287410.11424.15.camel@biol102145.oulu.fi>

On Tue, 2005-09-20 at 10:03 -0400, Roger D. Peng wrote:
> I think the reason is that the standard for 'R CMD check' is that examples in 
> help pages are guaranteed to be executable by the user (as long as the 
> requirements are met).  There is no way to guarantee this without having the 
> packages installed.  So strictly speaking, the 'Suggested' packages are not 
> needed by the *user*, but are needed by the *maintainer*.
> 
> Perhaps, you differ with the standard itself, but I personally think it's a good 
> one.
> 
I am not sure this is a standard by design, but it rather seems to be an
"industrial standard" or a "de facto" standard because of the way its
check is implemented. However, I've learnt that my assumption about the
meaning of 'Suggests' was wrong, and I'll correct my beliefs and work
accordingly.

This was what I assumed: I have 203 functions, and five of these need
non-recommended packages. Many a user never notices any of these
functions, but I thought it might be polite to hint (or "suggest") that
they may (but need not) download some extra packages. Obviously
'Suggests' field can be used for this, but it seems to be used to so
many other and different purposes that using it for hinting is hardly
sensible.  To summarize the responses, 'Suggests' has following uses:

1. It actually is meant for maintainers instead of the users, and
therefore it should list all packages that the package depends on. It is
not 'Depends', though, since those packages are not attach'ed. There for
missing 'Suggests' packages is an ERROR.

2. 'Suggests' also should be used for 'BuildRequires' (since there in no
field of that name). Both the R-exts manual and several responders said
that 'Suggests' should contain those packages that are needed to, say,
build the package vignettes. After building these vignettes, those
packages are never needed, and won't be needed by users of binary
packages. Therefore agian the ERROR.

This was not a complaint nor a suggestion to change the tools, but only
an observation. I'm quite willing to work with this set of rules and
I'll comply with them. Again, the grammar confused me, since I didn't
know that suggestions are so absolute (even though I'm married).

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/


From webmaster at se-ed.net  Wed Sep 21 18:57:15 2005
From: webmaster at se-ed.net (se-ed.net PostMaster)
Date: Wed, 21 Sep 2005 23:57:15 +0700
Subject: [Rd] Error sending message [1127321785032.6308.ae2d3.www4] from
	[se-ed.net]
Message-ID: <200509212357264.SM05504@smtp.se-ed.net>

[<00>] XMail bounce: Rcpt=[maria at se-ed.net];Error=[550 Requested action aborted: Message may contain a virus.]


[<01>] Error sending message [1127321785032.6308.ae2d3.www4] from [se-ed.net].

ID:        <S5F7715>
Mail From: <r-devel at r-project.org>
Rcpt To:   <maria at se-ed.net>
Server:    <www4.se-ed.web> [10.18.3.165]


[<02>] The reason of the delivery failure was:

550 Requested action aborted: Message may contain a virus.


[<05>] Here is listed the initial part of the message:

Received: from r-project.org ([202.29.18.254]:2360)
	by se-ed.net with [XMail 1.21 ESMTP Server]
	id <S5F7715> for <maria at se-ed.net> from <r-devel at r-project.org>;
	Wed, 21 Sep 2005 23:57:14 +0700
From: r-devel at r-project.org
To: maria at se-ed.net
Subject: HELLO
Date: Mon, 19 Sep 2005 23:56:55 +0700
MIME-Version: 1.0
Content-Type: multipart/mixed;
	boundary="----=_NextPart_000_0002_59EA1E47.3F96F459"
X-Priority: 3
X-MSMail-Priority: Normal


From p.dalgaard at biostat.ku.dk  Thu Sep 22 10:56:58 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Sep 2005 10:56:58 +0200
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <dgpari$a96$1@sea.gmane.org>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
Message-ID: <x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>

Jos? Matos <jamatos at fc.up.pt> writes:

> Martyn Plummer wrote:
> 
> > Fedora have just split off a separate lapack-devel package containing
> > the static library and the symlink liblapack.so.  (Mandrake/Mandriva has
> > been doing this for some time. I don't know about SuSE).  The up2date
> > service will recognize that it needs to update lapack, but I guess that
> > it won't install lapack-devel, as it doesn't know you need it.
> 
>   You are right.
> 
> > It might have been better to do this in the next release, rather than as
> > an update to FC4, but there you go. Better install lapack-devel
> > manually.
> 
>   lapack belongs to Extras and not to Core. Extras is a rolling release.
> 
>   The change was necessary to allow atlas to compile and interact with
> lapack.
> 
>   atlas is on the queue to Fedora Extras, it is in the review phase now.

Hmm. Doesn't look like it is actually working, though. Install
lapack-devel, configure --with-lapack, and make check dies with

running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
make[4]: Leaving directory `/home/pd/r-devel/BUILD/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
....
[pd at titmouse BUILD]$ tail tests/Examples/base-Ex.Rout.fail
> kappa(x2 <- cbind(x1,2:11))# high! [x2 is singular!]
[1] 8.351867e+16
>
> hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
> sv9 <- svd(h9 <- hilbert(9))$ d
> kappa(h9)# pretty high!
[1] 728289254735
> kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
Error in La.svd(x, nu, nv) : BLAS/LAPACK routine 'DGEBRD' gave error code -10
Execution halted

This happens on both x86_64 and x86 installs of FC4.

I have a strong sense of deja vu regarding this error.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Thu Sep 22 11:27:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Sep 2005 10:27:11 +0100 (BST)
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat>
	<dgpari$a96$1@sea.gmane.org> <x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0509221013230.14847@gannet.stats>

Which confirms the wisdom of our advice not to use --with-lapack unless 
you have to (a few systems do).  (Quote from the R-admin manual

 	this is definitely *not* recommended

. Perhaps this needs to say `use at your own risk and do not report 
problems with it'!)

There are far too many rogue LAPACK builds out there in distros.

BTW, I don't understand how a Linux distro can supply ATLAS tuned to my 
CPU/FPU.  Dr Goto has had about ten versions of his optimized BLAS 
covering just a small subset of i686 CPUs.  So although a distro's ATLAS 
may be better than a generic BLAS, it seems that it is likely to be 
suboptimal, and perhaps disastrous (I've seen that with mobile Pentium 
chips using ATLAS tuned on desktop machines).  So the recommendation must 
remain to tune ATLAS on your specific hardware.


On Thu, 22 Sep 2005, Peter Dalgaard wrote:

> Jos? Matos <jamatos at fc.up.pt> writes:
>
>> Martyn Plummer wrote:
>>
>>> Fedora have just split off a separate lapack-devel package containing
>>> the static library and the symlink liblapack.so.  (Mandrake/Mandriva has
>>> been doing this for some time. I don't know about SuSE).  The up2date
>>> service will recognize that it needs to update lapack, but I guess that
>>> it won't install lapack-devel, as it doesn't know you need it.
>>
>>   You are right.
>>
>>> It might have been better to do this in the next release, rather than as
>>> an update to FC4, but there you go. Better install lapack-devel
>>> manually.
>>
>>   lapack belongs to Extras and not to Core. Extras is a rolling release.
>>
>>   The change was necessary to allow atlas to compile and interact with
>> lapack.
>>
>>   atlas is on the queue to Fedora Extras, it is in the review phase now.
>
> Hmm. Doesn't look like it is actually working, though. Install
> lapack-devel, configure --with-lapack, and make check dies with
>
> running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
> make[4]: Leaving directory `/home/pd/r-devel/BUILD/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> ....
> [pd at titmouse BUILD]$ tail tests/Examples/base-Ex.Rout.fail
>> kappa(x2 <- cbind(x1,2:11))# high! [x2 is singular!]
> [1] 8.351867e+16
>>
>> hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
>> sv9 <- svd(h9 <- hilbert(9))$ d
>> kappa(h9)# pretty high!
> [1] 728289254735
>> kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
> Error in La.svd(x, nu, nv) : BLAS/LAPACK routine 'DGEBRD' gave error code -10
> Execution halted
>
> This happens on both x86_64 and x86 installs of FC4.
>
> I have a strong sense of deja vu regarding this error.
>
> -- 
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Sep 22 11:36:29 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Sep 2005 10:36:29 +0100 (BST)
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat>
	<dgpari$a96$1@sea.gmane.org> <x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0509221034170.15750@gannet.stats>

On Thu, 22 Sep 2005, Peter Dalgaard wrote:

> running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
> make[4]: Leaving directory `/home/pd/r-devel/BUILD/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> ....
> [pd at titmouse BUILD]$ tail tests/Examples/base-Ex.Rout.fail
>> kappa(x2 <- cbind(x1,2:11))# high! [x2 is singular!]
> [1] 8.351867e+16
>>
>> hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
>> sv9 <- svd(h9 <- hilbert(9))$ d
>> kappa(h9)# pretty high!
> [1] 728289254735
>> kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
> Error in La.svd(x, nu, nv) : BLAS/LAPACK routine 'DGEBRD' gave error code -10
> Execution halted
>
> This happens on both x86_64 and x86 installs of FC4.
>
> I have a strong sense of deja vu regarding this error.

Probably because it is discussed in the R-admin manual as having 
previously appeared in Debian and being traced to an erroneous patch to 
the Lapack 3.0 sources.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Thu Sep 22 15:12:27 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Sep 2005 15:12:27 +0200
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <Pine.LNX.4.61.0509221013230.14847@gannet.stats>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
	<x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.61.0509221013230.14847@gannet.stats>
Message-ID: <x2aci5l004.fsf@turmalin.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Which confirms the wisdom of our advice not to use --with-lapack
> unless you have to (a few systems do).  (Quote from the R-admin manual
> 
>  	this is definitely *not* recommended
> 
> . Perhaps this needs to say `use at your own risk and do not report
> problems with it'!)
> 
> There are far too many rogue LAPACK builds out there in distros.

Right, and I did of course know about the warning and the reason for
it. I just thought that when yet another distro saw fit to put a
liblapack out, the least we could do was to test it...
 
> BTW, I don't understand how a Linux distro can supply ATLAS tuned to
> my CPU/FPU.  Dr Goto has had about ten versions of his optimized BLAS
> covering just a small subset of i686 CPUs.  So although a distro's
> ATLAS may be better than a generic BLAS, it seems that it is likely to
> be suboptimal, and perhaps disastrous (I've seen that with mobile
> Pentium chips using ATLAS tuned on desktop machines).  So the
> recommendation must remain to tune ATLAS on your specific hardware.

I don't think an RPM is restricted to contain only one version of the
binaries, so in principle, the post-installer could adapt the
installed version to your hardware, if it could narrow the choice down
to a dozen versions or so. It's not easy though, since not only the
CPU/FPU types factor in, but also cache sizes and memory speeds.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tlumley at u.washington.edu  Thu Sep 22 16:26:09 2005
From: tlumley at u.washington.edu (tlumley@u.washington.edu)
Date: Thu, 22 Sep 2005 16:26:09 +0200 (CEST)
Subject: [Rd] as.data.frame segfaults on large lists (PR#8141)
Message-ID: <20050922142609.970811C90A@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

---1903393524-2062424977-1127399140=:32170
Content-Type: TEXT/PLAIN; charset=X-UNKNOWN; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE


The problem is a deep recursion in substituteList, presumably from=20
substitute(list(...)) in data.frame().  This overflows the stack for large=
=20
enough lists.  Presumably the only solution is to rewrite substituteList=20
iteratively.

 =09-thomas

On Tue, 20 Sep 2005, Thomas Lumley wrote:

>
> Under Valgrind on x86_64 I get
> =3D=3D27405=3D=3D  Access not within mapped region at address 0x33FFEFD8
> =3D=3D27405=3D=3D    at 0x447045: Rf_substituteList (coerce.c:2003)
> =3D=3D27405=3D=3D Stack overflow in thread 1: can't grow stack to 0x33FFE=
F98
>
>
> =09-thomas
>
> On Sun, 18 Sep 2005, Peter Dalgaard wrote:
>
>> ulrich.poetter at ruhr-uni-bochum.de writes:
>>=20
>>> Full_Name: Ulrich Poetter
>>> Version: 2.1.1
>>> OS: i686-pc-linux-gnu FC2
>>> Submission from: (NULL) (134.147.95.187)
>>>=20
>>>=20
>>> as.data.frame() segfaults on lists with very many elements:
>>>=20
>>>> dfn <- rep(list(rep(0,2)),198000)
>>>> test <- as.data.frame.list(dfn)
>>>=20
>>> Process R segmentation fault at Sun Sep 18 17:06:02 2005
>>=20
>> Not for me on FC4. The process size grows to about 180M and the system
>> thrashes badly, but the calculation runs to completion.
>>=20
>> It's not unlikely that we are ignoring a failed allocation somewhere,
>> but there's not much hope of finding it from the available
>> information. You could try running under gdb and see where things go
>> wrong for you.
>>=20
>> --
>>   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
>>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327=
918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)=20
>> 35327907
>>=20
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>=20
>
> Thomas Lumley=09=09=09Assoc. Professor, Biostatistics
> tlumley at u.washington.edu=09University of Washington, Seattle

Thomas Lumley=09=09=09Assoc. Professor, Biostatistics
tlumley at u.washington.edu=09University of Washington, Seattle
---1903393524-2062424977-1127399140=:32170--


From ggrothendieck at gmail.com  Thu Sep 22 17:13:14 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Sep 2005 11:13:14 -0400
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
Message-ID: <971536df05092208135b7ff57d@mail.gmail.com>

Just wanted to post this wishlist item.

Currently one can read text from the Windows clipboard but the Windows
clipboard can hold all sorts of objects, not just text, and it can
hold them simultaneously.  For example, if one selects some cells in
Excel and then copies them to the clipboard, the clipboard will have
all the cell boundary information but R can only read the text and
will have to figure it out if it can.

It would be nice if the user could use R to access all the information on
the clipboard, not just the text.


From murdoch at stats.uwo.ca  Thu Sep 22 18:42:18 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 22 Sep 2005 12:42:18 -0400
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <971536df05092208135b7ff57d@mail.gmail.com>
References: <971536df05092208135b7ff57d@mail.gmail.com>
Message-ID: <4332DEEA.8090705@stats.uwo.ca>

On 9/22/2005 11:13 AM, Gabor Grothendieck wrote:
> Just wanted to post this wishlist item.
> 
> Currently one can read text from the Windows clipboard but the Windows
> clipboard can hold all sorts of objects, not just text, and it can
> hold them simultaneously.  For example, if one selects some cells in
> Excel and then copies them to the clipboard, the clipboard will have
> all the cell boundary information but R can only read the text and
> will have to figure it out if it can.
> 
> It would be nice if the user could use R to access all the information on
> the clipboard, not just the text.

This looks like something someone should write a package to do.  It 
needs lots of support (e.g. what do all the possible clipboard format 
constants mean, what binary format corresponds to each, etc.), but it 
would only be useful on the Windows platform.

Duncan Murdoch


From ggrothendieck at gmail.com  Thu Sep 22 19:12:29 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Sep 2005 13:12:29 -0400
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <4332DEEA.8090705@stats.uwo.ca>
References: <971536df05092208135b7ff57d@mail.gmail.com>
	<4332DEEA.8090705@stats.uwo.ca>
Message-ID: <971536df050922101246bf8667@mail.gmail.com>

There is an open source clipboard extender CLCL that handles all
clipboard formats.  I think this code could be leveraged to simplify
it substantially.  Run CLCL and copy something from IE or Excel,
say, so that you have a complex object in the clipboard.
Now expand Clipboard in the left pane and the various components
in the clipboard are shown in the tree as children.  You can right click
and save any of them.

If this code could be followed it might be simple to just have a new
argument to clipboard() which specified which component to return
or one could optionally return a list of all of them.

On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 9/22/2005 11:13 AM, Gabor Grothendieck wrote:
> > Just wanted to post this wishlist item.
> >
> > Currently one can read text from the Windows clipboard but the Windows
> > clipboard can hold all sorts of objects, not just text, and it can
> > hold them simultaneously.  For example, if one selects some cells in
> > Excel and then copies them to the clipboard, the clipboard will have
> > all the cell boundary information but R can only read the text and
> > will have to figure it out if it can.
> >
> > It would be nice if the user could use R to access all the information on
> > the clipboard, not just the text.
>
> This looks like something someone should write a package to do.  It
> needs lots of support (e.g. what do all the possible clipboard format
> constants mean, what binary format corresponds to each, etc.), but it
> would only be useful on the Windows platform.
>
> Duncan Murdoch
>


From murdoch at stats.uwo.ca  Thu Sep 22 20:07:15 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 22 Sep 2005 14:07:15 -0400
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <971536df050922101246bf8667@mail.gmail.com>
References: <971536df05092208135b7ff57d@mail.gmail.com>	<4332DEEA.8090705@stats.uwo.ca>
	<971536df050922101246bf8667@mail.gmail.com>
Message-ID: <4332F2D3.6000807@stats.uwo.ca>

On 9/22/2005 1:12 PM, Gabor Grothendieck wrote:
> There is an open source clipboard extender CLCL that handles all
> clipboard formats.  I think this code could be leveraged to simplify
> it substantially.  Run CLCL and copy something from IE or Excel,
> say, so that you have a complex object in the clipboard.
> Now expand Clipboard in the left pane and the various components
> in the clipboard are shown in the tree as children.  You can right click
> and save any of them.
> 
> If this code could be followed it might be simple to just have a new
> argument to clipboard() which specified which component to return
> or one could optionally return a list of all of them.

We'd need to write clipboard() first.  This might be a good idea, but 
it's not at the top of my priority list.

I think a better thing for R to do is to make sure it's easy for package 
writers to write connections.  Then a package writer could write 
clipboard(), and it would fit into the rest of the R machinery.

Duncan Murdoch

> 
> On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 9/22/2005 11:13 AM, Gabor Grothendieck wrote:
>> > Just wanted to post this wishlist item.
>> >
>> > Currently one can read text from the Windows clipboard but the Windows
>> > clipboard can hold all sorts of objects, not just text, and it can
>> > hold them simultaneously.  For example, if one selects some cells in
>> > Excel and then copies them to the clipboard, the clipboard will have
>> > all the cell boundary information but R can only read the text and
>> > will have to figure it out if it can.
>> >
>> > It would be nice if the user could use R to access all the information on
>> > the clipboard, not just the text.
>>
>> This looks like something someone should write a package to do.  It
>> needs lots of support (e.g. what do all the possible clipboard format
>> constants mean, what binary format corresponds to each, etc.), but it
>> would only be useful on the Windows platform.
>>
>> Duncan Murdoch
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From charlie at stat.umn.edu  Thu Sep 22 20:23:57 2005
From: charlie at stat.umn.edu (Charles Geyer)
Date: Thu, 22 Sep 2005 13:23:57 -0500
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <Pine.LNX.4.63.0509202124040.9741@itasca2.wildberry.org>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
	<20050921011941.GA22326@stat.umn.edu>
	<Pine.LNX.4.63.0509202124040.9741@itasca2.wildberry.org>
Message-ID: <20050922182357.GA10196@stat.umn.edu>

On Tue, Sep 20, 2005 at 09:43:51PM -0500, Luke Tierney wrote:
> On Tue, 20 Sep 2005, Charles Geyer wrote:
> >
> >I still don't understand why gcc -shared even bothers to look in *.a
> >(on AMD64) when it won't do the slightest bit of good.  Maybe I'm still
> >ignorant of some important technical issue (maybe? more like with very
> >high probability!)
> >
> 
> The issue is not the library but whether the code is compiled as
> position-independent code (PIC) or not.  Many .a libraries are built
> as PIC and they can be used to create shared objects, you just get
> copies of the modules you use linked in.  PIC code can be slower,
> which is why some prefer to build .a libraries as non-PIC.

Oh.  Thanks.  That makes it all clear.  If I compile cddlib with

    export CXX=gcc
    export CFLAGS="-O -fPIC"
    ./configure --prefix=/APPS/64/

then I can build rcdd and it works!  (And, you're right, the fact that
cddlib builds libcddgmp.a instead of libcddgmp.so is irrelevant, it's
the -fPIC that matters.)

> I'm not sure why one rarely runs into non-PIC issues on i386--it may
> be that gcc at least is always producing PIC code there.  It does come
> up on other architectures though, in particular on x86_64.  It seems
> that most Linux distros that provide pvm only provide .a libraries,
> but some build these with PIC some don't.  Red Hat Enterprise WS4
> seems to be non-PIC, FC3 and FC4 seem to be PIC.  If your distro is
> non-PIC you will need to build your own PIC version of pvm and tell
> rpvm where to find it.

    snowbank$ locate pvm | grep -E '\.so|\.a$'
    /usr/lib/pvm3/lib/LINUX64/libfpvm3.a
    /usr/lib/pvm3/lib/LINUX64/libgpvm3.a
    /usr/lib/pvm3/lib/LINUX64/libpvm3.a
    /usr/lib/pvm3/lib/LINUX64/libpvmtrc.a
    /usr/lib64/libpvm3.so
    /usr/lib64/libpvm3.so.3
    /usr/lib64/libpvm3.so.3.4

I think I've got the libraries, so

  > install.packages("rpvm", repos = "http://www.biometrics.mtu.edu/CRAN/")
  trying URL 'http://www.biometrics.mtu.edu/CRAN/src/contrib/rpvm_0.6-5.tar.gz'

  [lots of blather deleted]

  gcc -shared -L/usr/local/lib64 -o rpvm.so rpvm_core.o rpvm_ser.o utils.o -L/usr/lib/pvm3/lib/LINUX64 -lpvm3 -lgpvm3 -lreadline -lncurses
  /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../x86_64-suse-linux/bin/ld: /usr/lib/pvm3/lib/LINUX64/libpvm3.a(lpvmgen.o): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC

same problem, I have a .so (presumably PIC), but it's picked another library.
Reading the help for install.packages, I don't find anything about how to
make it link against /usr/lib64/libpvm3.so instead
of /usr/lib/pvm3/lib/LINUX64/libpvm3.a so I guess that means do it by hand.

I'm a little puzzled by that too.  Apparently the configure in rpvm wants
to use PVM_ROOT which for this (SuSE 9.3 AMD64) box is /usr/lib/pvm3 (which
is the default) to find the libraries it wants to link to, but that won't
work.  The appropriate library is /usr/lib64/libpvm3.so -- maybe.
I just noticed the -lpvm3 -lgpvm3 in the link that failed.  I'm not
sure /usr/lib64/libpvm3.so contains everything rpvm needs.

This just isn't going to work with the SuSE provided pvm stuff right?

I untarred the rpvm package and did R CMD check on it and it really
doesn't give any way to link to a library in an odd place -- at least
not that I can see.

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie at stat.umn.edu


From ggrothendieck at gmail.com  Thu Sep 22 20:50:54 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Sep 2005 14:50:54 -0400
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <4332F2D3.6000807@stats.uwo.ca>
References: <971536df05092208135b7ff57d@mail.gmail.com>
	<4332DEEA.8090705@stats.uwo.ca>
	<971536df050922101246bf8667@mail.gmail.com>
	<4332F2D3.6000807@stats.uwo.ca>
Message-ID: <971536df050922115057416498@mail.gmail.com>

On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 9/22/2005 1:12 PM, Gabor Grothendieck wrote:
> > There is an open source clipboard extender CLCL that handles all
> > clipboard formats.  I think this code could be leveraged to simplify
> > it substantially.  Run CLCL and copy something from IE or Excel,
> > say, so that you have a complex object in the clipboard.
> > Now expand Clipboard in the left pane and the various components
> > in the clipboard are shown in the tree as children.  You can right click
> > and save any of them.
> >
> > If this code could be followed it might be simple to just have a new
> > argument to clipboard() which specified which component to return
> > or one could optionally return a list of all of them.
>
> We'd need to write clipboard() first.  This might be a good idea, but
> it's not at the top of my priority list.

Sorry, its readClipboard() rather than clipboard().  See ?readClipboard

>
> I think a better thing for R to do is to make sure it's easy for package
> writers to write connections.  Then a package writer could write
> clipboard(), and it would fit into the rest of the R machinery.
>
> Duncan Murdoch
>
> >
> > On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 9/22/2005 11:13 AM, Gabor Grothendieck wrote:
> >> > Just wanted to post this wishlist item.
> >> >
> >> > Currently one can read text from the Windows clipboard but the Windows
> >> > clipboard can hold all sorts of objects, not just text, and it can
> >> > hold them simultaneously.  For example, if one selects some cells in
> >> > Excel and then copies them to the clipboard, the clipboard will have
> >> > all the cell boundary information but R can only read the text and
> >> > will have to figure it out if it can.
> >> >
> >> > It would be nice if the user could use R to access all the information on
> >> > the clipboard, not just the text.
> >>
> >> This looks like something someone should write a package to do.  It
> >> needs lots of support (e.g. what do all the possible clipboard format
> >> constants mean, what binary format corresponds to each, etc.), but it
> >> would only be useful on the Windows platform.
> >>
> >> Duncan Murdoch
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch at stats.uwo.ca  Thu Sep 22 21:13:58 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 22 Sep 2005 15:13:58 -0400
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <971536df050922115057416498@mail.gmail.com>
References: <971536df05092208135b7ff57d@mail.gmail.com>	<4332DEEA.8090705@stats.uwo.ca>	<971536df050922101246bf8667@mail.gmail.com>	<4332F2D3.6000807@stats.uwo.ca>
	<971536df050922115057416498@mail.gmail.com>
Message-ID: <43330276.7070709@stats.uwo.ca>

On 9/22/2005 2:50 PM, Gabor Grothendieck wrote:
> On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 9/22/2005 1:12 PM, Gabor Grothendieck wrote:
>> > There is an open source clipboard extender CLCL that handles all
>> > clipboard formats.  I think this code could be leveraged to simplify
>> > it substantially.  Run CLCL and copy something from IE or Excel,
>> > say, so that you have a complex object in the clipboard.
>> > Now expand Clipboard in the left pane and the various components
>> > in the clipboard are shown in the tree as children.  You can right click
>> > and save any of them.
>> >
>> > If this code could be followed it might be simple to just have a new
>> > argument to clipboard() which specified which component to return
>> > or one could optionally return a list of all of them.
>>
>> We'd need to write clipboard() first.  This might be a good idea, but
>> it's not at the top of my priority list.
> 
> Sorry, its readClipboard() rather than clipboard().  See ?readClipboard

I don't think I ever noticed that function.  It looks tricky to 
determine how much data is there.  For text it goes to the first NULL 
character, but what do you do for other formats?  Can you see how the 
package you mentioned does it?

Duncan Murdoch
> 
>>
>> I think a better thing for R to do is to make sure it's easy for package
>> writers to write connections.  Then a package writer could write
>> clipboard(), and it would fit into the rest of the R machinery.
>>
>> Duncan Murdoch
>>
>> >
>> > On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> >> On 9/22/2005 11:13 AM, Gabor Grothendieck wrote:
>> >> > Just wanted to post this wishlist item.
>> >> >
>> >> > Currently one can read text from the Windows clipboard but the Windows
>> >> > clipboard can hold all sorts of objects, not just text, and it can
>> >> > hold them simultaneously.  For example, if one selects some cells in
>> >> > Excel and then copies them to the clipboard, the clipboard will have
>> >> > all the cell boundary information but R can only read the text and
>> >> > will have to figure it out if it can.
>> >> >
>> >> > It would be nice if the user could use R to access all the information on
>> >> > the clipboard, not just the text.
>> >>
>> >> This looks like something someone should write a package to do.  It
>> >> needs lots of support (e.g. what do all the possible clipboard format
>> >> constants mean, what binary format corresponds to each, etc.), but it
>> >> would only be useful on the Windows platform.
>> >>
>> >> Duncan Murdoch
>> >>
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Thu Sep 22 21:33:05 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Sep 2005 15:33:05 -0400
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <43330276.7070709@stats.uwo.ca>
References: <971536df05092208135b7ff57d@mail.gmail.com>
	<4332DEEA.8090705@stats.uwo.ca>
	<971536df050922101246bf8667@mail.gmail.com>
	<4332F2D3.6000807@stats.uwo.ca>
	<971536df050922115057416498@mail.gmail.com>
	<43330276.7070709@stats.uwo.ca>
Message-ID: <971536df0509221233175aea58@mail.gmail.com>

On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 9/22/2005 2:50 PM, Gabor Grothendieck wrote:
> > On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 9/22/2005 1:12 PM, Gabor Grothendieck wrote:
> >> > There is an open source clipboard extender CLCL that handles all
> >> > clipboard formats.  I think this code could be leveraged to simplify
> >> > it substantially.  Run CLCL and copy something from IE or Excel,
> >> > say, so that you have a complex object in the clipboard.
> >> > Now expand Clipboard in the left pane and the various components
> >> > in the clipboard are shown in the tree as children.  You can right click
> >> > and save any of them.
> >> >
> >> > If this code could be followed it might be simple to just have a new
> >> > argument to clipboard() which specified which component to return
> >> > or one could optionally return a list of all of them.
> >>
> >> We'd need to write clipboard() first.  This might be a good idea, but
> >> it's not at the top of my priority list.
> >
> > Sorry, its readClipboard() rather than clipboard().  See ?readClipboard
>
> I don't think I ever noticed that function.  It looks tricky to
> determine how much data is there.  For text it goes to the first NULL
> character, but what do you do for other formats?  Can you see how the
> package you mentioned does it?
>
> Duncan Murdoch
> >
> >>
> >> I think a better thing for R to do is to make sure it's easy for package
> >> writers to write connections.  Then a package writer could write
> >> clipboard(), and it would fit into the rest of the R machinery.
> >>
> >> Duncan Murdoch
> >>
> >> >
> >> > On 9/22/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> >> On 9/22/2005 11:13 AM, Gabor Grothendieck wrote:
> >> >> > Just wanted to post this wishlist item.
> >> >> >
> >> >> > Currently one can read text from the Windows clipboard but the Windows
> >> >> > clipboard can hold all sorts of objects, not just text, and it can
> >> >> > hold them simultaneously.  For example, if one selects some cells in
> >> >> > Excel and then copies them to the clipboard, the clipboard will have
> >> >> > all the cell boundary information but R can only read the text and
> >> >> > will have to figure it out if it can.
> >> >> >
> >> >> > It would be nice if the user could use R to access all the information on
> >> >> > the clipboard, not just the text.
> >> >>
> >> >> This looks like something someone should write a package to do.  It
> >> >> needs lots of support (e.g. what do all the possible clipboard format
> >> >> constants mean, what binary format corresponds to each, etc.), but it
> >> >> would only be useful on the Windows platform.
> >> >>
> >> >> Duncan Murdoch

Look in clipboard.c in the source. It seems to use GetClipboardData.
See Microsoft's site:

http://msdn.microsoft.com/library/default.asp?url=/library/en-us/winui/winui/windowsuserinterface/dataexchange/clipboard/clipboardreference/clipboardfunctions/getclipboarddata.asp

or just google for GetClipboardData .  Its the first hit.


From luke at stat.uiowa.edu  Thu Sep 22 22:24:41 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 22 Sep 2005 15:24:41 -0500 (CDT)
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <20050922182357.GA10196@stat.umn.edu>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<20050921011941.GA22326@stat.umn.edu>
	<Pine.LNX.4.63.0509202124040.9741@itasca2.wildberry.org>
	<20050922182357.GA10196@stat.umn.edu>
Message-ID: <Pine.LNX.4.63.0509221516070.3838@nokomis.stat.uiowa.edu>

On Thu, 22 Sep 2005, Charles Geyer wrote:

> On Tue, Sep 20, 2005 at 09:43:51PM -0500, Luke Tierney wrote:
>> On Tue, 20 Sep 2005, Charles Geyer wrote:
>>>
>>> I still don't understand why gcc -shared even bothers to look in *.a
>>> (on AMD64) when it won't do the slightest bit of good.  Maybe I'm still
>>> ignorant of some important technical issue (maybe? more like with very
>>> high probability!)
>>>
>>
>> The issue is not the library but whether the code is compiled as
>> position-independent code (PIC) or not.  Many .a libraries are built
>> as PIC and they can be used to create shared objects, you just get
>> copies of the modules you use linked in.  PIC code can be slower,
>> which is why some prefer to build .a libraries as non-PIC.
>
> Oh.  Thanks.  That makes it all clear.  If I compile cddlib with
>
>    export CXX=gcc
>    export CFLAGS="-O -fPIC"
>    ./configure --prefix=/APPS/64/
>
> then I can build rcdd and it works!  (And, you're right, the fact that
> cddlib builds libcddgmp.a instead of libcddgmp.so is irrelevant, it's
> the -fPIC that matters.)
>
>> I'm not sure why one rarely runs into non-PIC issues on i386--it may
>> be that gcc at least is always producing PIC code there.  It does come
>> up on other architectures though, in particular on x86_64.  It seems
>> that most Linux distros that provide pvm only provide .a libraries,
>> but some build these with PIC some don't.  Red Hat Enterprise WS4
>> seems to be non-PIC, FC3 and FC4 seem to be PIC.  If your distro is
>> non-PIC you will need to build your own PIC version of pvm and tell
>> rpvm where to find it.
>
>    snowbank$ locate pvm | grep -E '\.so|\.a$'
>    /usr/lib/pvm3/lib/LINUX64/libfpvm3.a
>    /usr/lib/pvm3/lib/LINUX64/libgpvm3.a
>    /usr/lib/pvm3/lib/LINUX64/libpvm3.a
>    /usr/lib/pvm3/lib/LINUX64/libpvmtrc.a
>    /usr/lib64/libpvm3.so
>    /usr/lib64/libpvm3.so.3
>    /usr/lib64/libpvm3.so.3.4
>
> I think I've got the libraries, so
>
>  > install.packages("rpvm", repos = "http://www.biometrics.mtu.edu/CRAN/")
>  trying URL 'http://www.biometrics.mtu.edu/CRAN/src/contrib/rpvm_0.6-5.tar.gz'
>
>  [lots of blather deleted]
>
>  gcc -shared -L/usr/local/lib64 -o rpvm.so rpvm_core.o rpvm_ser.o utils.o -L/usr/lib/pvm3/lib/LINUX64 -lpvm3 -lgpvm3 -lreadline -lncurses
>  /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.5/../../../../x86_64-suse-linux/bin/ld: /usr/lib/pvm3/lib/LINUX64/libpvm3.a(lpvmgen.o): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
>
> same problem, I have a .so (presumably PIC), but it's picked another library.
> Reading the help for install.packages, I don't find anything about how to
> make it link against /usr/lib64/libpvm3.so instead
> of /usr/lib/pvm3/lib/LINUX64/libpvm3.a so I guess that means do it by hand.
>
> I'm a little puzzled by that too.  Apparently the configure in rpvm wants
> to use PVM_ROOT which for this (SuSE 9.3 AMD64) box is /usr/lib/pvm3 (which
> is the default) to find the libraries it wants to link to, but that won't
> work.  The appropriate library is /usr/lib64/libpvm3.so -- maybe.
> I just noticed the -lpvm3 -lgpvm3 in the link that failed.  I'm not
> sure /usr/lib64/libpvm3.so contains everything rpvm needs.
> This just isn't going to work with the SuSE provided pvm stuff right?
>
> I untarred the rpvm package and did R CMD check on it and it really
> doesn't give any way to link to a library in an odd place -- at least
> not that I can see.

I would run configure in the untarred package then edit src/Makevars
to remove the -L bit and the -lgpvm and see if that works.  If not,
I'd get the pvm source, build libpvm.a and liggpvm.a with -fPIC files,
and fix src/Makevars to use them.  I'm sure there are more elegant
alternatives, but ...

luke

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From murdoch at stats.uwo.ca  Fri Sep 23 14:58:39 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 23 Sep 2005 08:58:39 -0400
Subject: [Rd] [R] warning.expression?
In-Reply-To: <4333E8C8.7000509@lancaster.ac.uk>
References: <200509221814.12666.thomas.friedrichsmeier@ruhr-uni-bochum.de>	<4332DF91.8040607@jhsph.edu>	<200509221900.56739.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4333E8C8.7000509@lancaster.ac.uk>
Message-ID: <4333FBFF.2020508@stats.uwo.ca>

I'm sending this reply to r-devel instead of r-help, since it has moved 
into talking about changes to R internals now.

On 9/23/2005 7:36 AM, Barry Rowlingson wrote:
> Thomas Friedrichsmeier wrote:
> 
>> Yes, thanks for pointing it out. However, I'm actually looking for a way to 
>> catch all warnings in a whole (interactive) session. Can warning.expression 
>> be used for that?
> 
>   I've just been nosing around the source code in errors.c, and it 
> doesn't look good.
> 
> In this function:
> 
> static void vwarningcall_dflt(SEXP call, const char *format, va_list ap)
> 
> the warning.expression 's' is called here:
> 
>         cptr = R_GlobalContext;
>          while ( !(cptr->callflag & CTXT_FUNCTION) && cptr->callflag )
>              cptr = cptr->nextcontext;
>          eval(s, cptr->cloenv);
> 	return;
> 
> but when the expression is null/nil the code goes on to the default 
> case, in which it gets the warning message from the 'call' parameter:
> 
> 
>   dcall = CHAR(STRING_ELT(deparse1(call, 0, SIMPLEDEPARSE), 0));
>   REprintf(_("Warning in %s : "), dcall);
> 
>   So I don't see how this parameter can be available to the 
> warning.expression call. There may be a way, but I don't see it.
> 
>   It seems a bit dumb that warning.expression functions can only say 
> "Hey, something a bit iffy may have ocurred, but I dont know what and I 
> dont know where!". Maybe there's something in that cptr->cloenv that can 
> tell you...
> 
>   Otherwise it requires patching.

That's old code (mostly from 1999/2000), and that method of handling 
warnings is not used in any of the base code, which may explain why it 
isn't all that useful.  I don't know of any GUIs that do what Thomas is 
attempting (which I think is to have his GUI divert warnings and errors 
from the output stream to some other display), so there might not 
currently be a good way to do what he wants other than pattern matching 
on the output.

It would probably be a good idea to deprecate warning.expression in the 
next release, rather than beefing it up.  If we don't have a good method 
to do what Thomas wants, we should add it, but warning.expression 
doesn't look like the right way to do it.

Does anyone know of any uses of it in current code on CRAN, 
Bioconductor, or elsewhere?

Duncan Murdoch


From sfalcon at fhcrc.org  Fri Sep 23 15:59:13 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 23 Sep 2005 06:59:13 -0700
Subject: [Rd] [R] warning.expression?
In-Reply-To: <4333FBFF.2020508@stats.uwo.ca> (Duncan Murdoch's message of
	"Fri, 23 Sep 2005 08:58:39 -0400")
References: <200509221814.12666.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4332DF91.8040607@jhsph.edu>
	<200509221900.56739.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4333E8C8.7000509@lancaster.ac.uk> <4333FBFF.2020508@stats.uwo.ca>
Message-ID: <m2d5mzga1a.fsf@macaroni.local>

On 23 Sep 2005, murdoch at stats.uwo.ca wrote:
> It would probably be a good idea to deprecate warning.expression in
> the next release, rather than beefing it up.  If we don't have a
> good method to do what Thomas wants, we should add it, but
> warning.expression doesn't look like the right way to do it.
>
> Does anyone know of any uses of it in current code on CRAN, 
> Bioconductor, or elsewhere?

I don't see any use of it grep'ing through the BioC package sources.

+ seth


From andy_liaw at merck.com  Fri Sep 23 16:10:01 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 23 Sep 2005 10:10:01 -0400
Subject: [Rd] undocumented objects in a package
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED48F@usctmx1106.merck.com>

Dear R-devel,

I recall that there used to be a mechanism to get around the requirement
that all objects in a package have associated documentation; i.e., a way to
specify a list of objects (mostly functions) that are not considered as part
of the package API.  Is this still available?  I cannot find any mention in
R-exts.

I realize that the way to go is to have a name space, and eventually that's
what I will do, but for now I rather spend the time doing other necessary
clean-ups first.  

Any pointer much appreciated!

Best,
Andy

Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw at merck.com        732-594-0820


From ligges at statistik.uni-dortmund.de  Fri Sep 23 16:34:34 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 23 Sep 2005 16:34:34 +0200
Subject: [Rd] undocumented objects in a package
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED48F@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED48F@usctmx1106.merck.com>
Message-ID: <4334127A.2060208@statistik.uni-dortmund.de>

Liaw, Andy wrote:

> Dear R-devel,
> 
> I recall that there used to be a mechanism to get around the requirement
> that all objects in a package have associated documentation; i.e., a way to
> specify a list of objects (mostly functions) that are not considered as part
> of the package API.  Is this still available?  I cannot find any mention in
> R-exts.
> 
> I realize that the way to go is to have a name space, and eventually that's
> what I will do, but for now I rather spend the time doing other necessary
> clean-ups first.  
> 
> Any pointer much appreciated!


E.g. just make one simple help page with keyword "internal" with aliases 
for all the functions. You do not need to write exact documentation in 
this case.

Uwe Ligges

> Best,
> Andy
> 
> Andy Liaw, PhD
> Biometrics Research      PO Box 2000, RY33-300     
> Merck Research Labs           Rahway, NJ 07065
> mailto:andy_liaw at merck.com        732-594-0820
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jamatos at fc.up.pt  Fri Sep 23 19:42:34 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Fri, 23 Sep 2005 18:42:34 +0100
Subject: [Rd] looks in liblapack.a not liblapack.so
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
	<x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
Message-ID: <dh1eqa$690$1@sea.gmane.org>

Peter Dalgaard wrote:

> Jos? Matos <jamatos at fc.up.pt> writes:
> 
>>   The change was necessary to allow atlas to compile and interact with
>> lapack.
>> 
>>   atlas is on the queue to Fedora Extras, it is in the review phase now.
> 
> Hmm. Doesn't look like it is actually working, though. Install
> lapack-devel, configure --with-lapack, and make check dies with
> 
> running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
> make[4]: Leaving directory `/home/pd/r-devel/BUILD/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> ....
> [pd at titmouse BUILD]$ tail tests/Examples/base-Ex.Rout.fail
>> kappa(x2 <- cbind(x1,2:11))# high! [x2 is singular!]
> [1] 8.351867e+16
>>
>> hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
>> sv9 <- svd(h9 <- hilbert(9))$ d
>> kappa(h9)# pretty high!
> [1] 728289254735
>> kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
> Error in La.svd(x, nu, nv) : BLAS/LAPACK routine 'DGEBRD' gave error code
> -10 Execution halted
> 
> This happens on both x86_64 and x86 installs of FC4.

  I will report it to lapack maintainer, he is very responsive and
competent. :-)

> I have a strong sense of deja vu regarding this error.

  I don't think that the Fedora packages derives from Debian, but sometimes
patches cross distributions, even the wrong ones. :-)

-- 
Jos? Ab?lio


From jamatos at fc.up.pt  Fri Sep 23 20:24:29 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Fri, 23 Sep 2005 19:24:29 +0100
Subject: [Rd] looks in liblapack.a not liblapack.so
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
	<x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.61.0509221013230.14847@gannet.stats>
	<x2aci5l004.fsf@turmalin.kubism.ku.dk>
Message-ID: <dh1h8u$dvg$1@sea.gmane.org>

Peter Dalgaard wrote:
> Prof Brian Ripley wrote:
>> BTW, I don't understand how a Linux distro can supply ATLAS tuned to
>> my CPU/FPU.  Dr Goto has had about ten versions of his optimized BLAS
>> covering just a small subset of i686 CPUs.  So although a distro's
>> ATLAS may be better than a generic BLAS, it seems that it is likely to
>> be suboptimal, and perhaps disastrous (I've seen that with mobile
>> Pentium chips using ATLAS tuned on desktop machines).  So the
>> recommendation must remain to tune ATLAS on your specific hardware.
> 
> I don't think an RPM is restricted to contain only one version of the
> binaries, so in principle, the post-installer could adapt the
> installed version to your hardware, if it could narrow the choice down
> to a dozen versions or so. It's not easy though, since not only the
> CPU/FPU types factor in, but also cache sizes and memory speeds.

  Peter is right here. We can have rpms for i386, i486, i586, i686,
athlon, ...

  One example of this kind of package is the kernel, but most applications
the optimizations does not matter. The few packages shipped in Fedora Core
who follow this scheme (and just for few subarchitecture, not for all) are:

- kernel related
- glibc
- openssl

  The other possibility (orthogonal with the previous) is to ship the
libraries optimized for different cpu features, like gmp (GNU arbitrary
precision library) does:

$ rpm -ql gmp-4.1.4-6.i386
/usr/lib/libgmp.so.3
/usr/lib/libgmp.so.3.3.3
/usr/lib/libgmpxx.so.3
/usr/lib/libgmpxx.so.3.0.5
/usr/lib/libmp.so.3
/usr/lib/libmp.so.3.1.7
/usr/lib/sse2/libgmp.so.3
/usr/lib/sse2/libgmp.so.3.3.3
/usr/lib/sse2/libgmpxx.so.3
/usr/lib/sse2/libgmpxx.so.3.0.5
/usr/lib/sse2/libmp.so.3
/usr/lib/sse2/libmp.so.3.1.7

and for 64 bits:
$ rpm -ql gmp-4.1.4-6.x86_64
/usr/lib64/libgmp.so.3
/usr/lib64/libgmp.so.3.3.3
/usr/lib64/libgmpxx.so.3
/usr/lib64/libgmpxx.so.3.0.5
/usr/lib64/libmp.so.3
/usr/lib64/libmp.so.3.1.7

  As I have told above usually this only applies to very few packages where
performance is really important. Clearly this description fits to
atlas. :-)

-- 
Jos? Ab?lio


From jamatos at fc.up.pt  Fri Sep 23 20:27:15 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Fri, 23 Sep 2005 19:27:15 +0100
Subject: [Rd] looks in liblapack.a not liblapack.so
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
	<x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.61.0509221013230.14847@gannet.stats>
Message-ID: <dh1he3$eg3$1@sea.gmane.org>

Prof Brian Ripley wrote:

> I've seen that with mobile Pentium chips using ATLAS tuned on desktop
> machines 

  In the future (not now), since Intel plans to sell those chips to desktop
machines, that will not be a bad thing. ;-)

  And yes, I do understand your point. :-)
-- 
Jos? Ab?lio


From aniko.szabo at hci.utah.edu  Fri Sep 23 21:54:39 2005
From: aniko.szabo at hci.utah.edu (aniko.szabo@hci.utah.edu)
Date: Fri, 23 Sep 2005 21:54:39 +0200 (CEST)
Subject: [Rd] reshape direction="long" does not drop temporary ID (PR#8152)
Message-ID: <20050923195439.40D9E1C68D@slim.kubism.ku.dk>

Full_Name: Aniko Szabo
Version: 2.1.0
OS: Windows XP
Submission from: (NULL) (155.100.234.96)


When using reshape with direction="long", multiple id variables and only one
column of varying data, the resulting data frame has a temporary ID variable.
Here is an example:

a <- data.frame(G=LETTERS[1:3], H=letters[1:3], x=1:3)
reshape(a, direction="long", varying=list(c("x")), idvar=c("G","H"))

  G H tempID29457 time x
1 A a         A.a    1 1
2 B b         B.b    1 2
3 C c         C.c    1 3

While I understand that there was not much point to reshaping, I think it is
still a bug.


From mschwartz at mn.rr.com  Fri Sep 23 22:37:02 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 23 Sep 2005 15:37:02 -0500
Subject: [Rd] R's parsing of command line arguments using commandArgs()
Message-ID: <1127507823.4947.52.camel@localhost.localdomain>

Hi all,

I am setting up some R program files for use by our DB programmers to
enable them to utilize some R functions which will be called from within
TCL code. R has been installed on an RHEL server and R will process the
results of SQL queries against an Oracle database.

In some cases, they will generate a data file to be read in and
processed by R, in others they will simply make the tabulated results
available.

I know that I could do the SQL queries from within R, however, this is
the approach that has been defined for now for various reasons.

I wanted to provide some flexibility for them, by passing some of the
tabulated results via command line arguments to R functions, rather than
via environment variables, which is easier for them to do in TCL it
would seem. They would create these values at run time, based upon specs
that I give them.

Using the following as an example:

$ R --slave --vanilla --args "c(5,5)" "c(.5,.5)" < RScript.R

I can then process "c(5,5)" and "c(.5,.5)" as two arguments, via:

Args <- commandArgs()

where the two arguments are Args[5] and Args[6], respectively. I can
then of course pass these as "eval(parse(text = Args[5]))" to other R
functions.


However, if there is any whitespace in the two arguments, such as:

R --slave --vanilla --args "c(5, 5)" "c(.5, .5)" < RScript.R

even though surrounded by double quotes (or single quotes or
backquotes), the two arguments are parsed as four.

Is this behavior expected? I was under the impression, from other C
based programs and bash shell scripts for example, that the use of the
double quotes would wrap such text and thus be parsed as a single
argument.

This is using:

Version 2.1.1 Patched (2005-09-22) on FC4.

Thanks for any guidance.

Marc Schwartz


From arnima at u.washington.edu  Sat Sep 24 02:54:26 2005
From: arnima at u.washington.edu (arnima@u.washington.edu)
Date: Sat, 24 Sep 2005 02:54:26 +0200 (CEST)
Subject: [Rd] bxp.Rd typo (PR#8153)
Message-ID: <20050924005426.E15A41C916@slim.kubism.ku.dk>

Hi. There's a minor typo in bxp.Rd:

whiskco:l
  should be
whiskcol:

Cheers,
Arni

R 2.1.1pat on WinXP


From rhurlin at gwdg.de  Sat Sep 24 14:02:57 2005
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 24 Sep 2005 14:02:57 +0200
Subject: [Rd] FreeBSD 7.0-CURRENT and R-2.2.0 alpha
In-Reply-To: <Pine.LNX.4.61.0509110749100.24002@gannet.stats>
References: <4322B766.10803@gwdg.de>
	<Pine.LNX.4.61.0509110749100.24002@gannet.stats>
Message-ID: <43354071.3090704@gwdg.de>

Sorry for my very late answer. On Sept. 12th I got an unexpected 
business trip until yesterday evening, so I had no chance to try out.


Thank you for the hints. But I am afraid I have no idea how to extract 
the needed information.

With R-2.2.0 (R-beta_2005-09-22_r35658.tar.gz) I tried the following:

nm /usr/lib/libc.a | grep cpow
nm /usr/lib/libm.a | grep cpow

In both cases without any result.

Where I have to look? Or what else can I do to find out where the libs 
with these procedures are?

Rainer Hurling


Prof Brian Ripley wrote:
> These were found by AC_CHECK_FUNCS (please confirm what configure said) 
> so most likely some macro needs to be set or header included.
> 
> Could you please find out how configure managed to find cpow etc when 
> they appear not to be in libc/libm?
> 
> On Sat, 10 Sep 2005, Rainer Hurling wrote:
> 
>> The configure script runs fine, but when I compile todays alpha version
>> of R-2.2.0 (R-alpha_2005-09-10_r35546.tar.gz) under FreeBSD 7.0-CURRENT
>> from Sept. 4th I get the following output:
>>
>>
>> ========================================================
>> [...]
>> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
>> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
>> -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -O2 -c
>> version.c -o version.o
>> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
>> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
>> -I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES  -g -O2 -c
>> vfonts.c -o vfonts.o
>> f77   -g -O2 -c xxxpr.f -o xxxpr.o
>> gcc -export-dynamic -L/usr/local/lib -o R.bin  Rmain.o  CConverters.o
>> CommandLineArgs.o Rdynload.o Renviron.o RNG.o apply.o arithmetic.o
>> apse.o array.o attrib.o base.o bind.o builtin.o character.o coerce.o
>> colors.o complex.o connections.o context.o cov.o cum.o dcf.o datetime.o
>> debug.o deparse.o deriv.o dotcode.o dounzip.o dstruct.o duplicate.o
>> engine.o envir.o errors.o eval.o format.o fourier.o gevents.o gram.o
>> gram-ex.o graphics.o identical.o internet.o iosupport.o lapack.o list.o
>> logic.o main.o mapply.o match.o memory.o model.o names.o objects.o
>> optim.o optimize.o options.o par.o paste.o pcre.o platform.o plot.o
>> plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o
>> qsort.o random.o regex.o registration.o relop.o saveload.o scan.o seq.o
>> serialize.o size.o sort.o source.o split.o sprintf.o startup.o
>> subassign.o subscript.o subset.o summary.o sysutils.o unique.o util.o
>> version.o vfonts.o xxxpr.o ../unix/libunix.a ../appl/libappl.a
>> ../nmath/libnmath.a  -lf77blas -latlas -lg2c -lm  ../extra/zlib/libz.a
>> ../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a
>> /usr/local/lib/libintl.so -Wl,-rpath -Wl,/usr/local/lib -lreadline -lm
>> -liconv
>> complex.o(.text+0x106): In function `mycpow':
>> /usr/local/R-alpha/src/main/complex.c:170: undefined reference to `cpow'
>> complex.o(.text+0x6f9): In function `do_cmathfuns':
>> /usr/local/R-alpha/src/main/complex.c:323: undefined reference to `carg'
>> complex.o(.text+0xb4b): In function `z_log':
>> /usr/local/R-alpha/src/main/complex.c:423: undefined reference to `clog'
>> complex.o(.text+0xb86): In function `z_logbase':
>> /usr/local/R-alpha/src/main/complex.c:429: undefined reference to `clog'
>> complex.o(.text+0xb98):/usr/local/R-alpha/src/main/complex.c:429:
>> undefined reference to `clog'
>> complex.o(.text+0xbd8): In function `z_exp':
>> /usr/local/R-alpha/src/main/complex.c:434: undefined reference to `cexp'
>> complex.o(.text+0xbf8): In function `z_sqrt':
>> /usr/local/R-alpha/src/main/complex.c:439: undefined reference to `csqrt'
>> complex.o(.text+0xc18): In function `z_cos':
>> /usr/local/R-alpha/src/main/complex.c:486: undefined reference to `ccos'
>> complex.o(.text+0xc38): In function `z_sin':
>> /usr/local/R-alpha/src/main/complex.c:491: undefined reference to `csin'
>> complex.o(.text+0xc5e): In function `z_tan':
>> /usr/local/R-alpha/src/main/complex.c:497: undefined reference to `ctan'
>> complex.o(.text+0xd26): In function `z_atan2':
>> /usr/local/R-alpha/src/main/complex.c:523: undefined reference to `catan'
>> complex.o(.text+0xe18): In function `z_asin':
>> /usr/local/R-alpha/src/main/complex.c:541: undefined reference to `casin'
>> complex.o(.text+0xe38): In function `z_acos':
>> /usr/local/R-alpha/src/main/complex.c:553: undefined reference to `cacos'
>> complex.o(.text+0xe58): In function `z_atan':
>> /usr/local/R-alpha/src/main/complex.c:559: undefined reference to `catan'
>> complex.o(.text+0xe78): In function `z_acosh':
>> /usr/local/R-alpha/src/main/complex.c:564: undefined reference to 
>> `cacosh'
>> complex.o(.text+0xe98): In function `z_asinh':
>> /usr/local/R-alpha/src/main/complex.c:569: undefined reference to 
>> `casinh'
>> complex.o(.text+0xeb8): In function `z_atanh':
>> /usr/local/R-alpha/src/main/complex.c:574: undefined reference to 
>> `catanh'
>> complex.o(.text+0xed8): In function `z_cosh':
>> /usr/local/R-alpha/src/main/complex.c:579: undefined reference to `ccosh'
>> complex.o(.text+0xef8): In function `z_sinh':
>> /usr/local/R-alpha/src/main/complex.c:584: undefined reference to `csinh'
>> complex.o(.text+0xf18): In function `z_tanh':
>> /usr/local/R-alpha/src/main/complex.c:589: undefined reference to `ctanh'
>> *** Error code 1
>> Stop in /usr/local/R-alpha/src/main.
>> *** Error code 1
>> Stop in /usr/local/R-alpha/src/main.
>> *** Error code 1
>> Stop in /usr/local/R-alpha/src.
>> *** Error code 1
>> Stop in /usr/local/R-alpha.
>> ========================================================
>>
>> Am I missing something?
>>
>> Thank you,
>> Rainer Hurling


From ggrothendieck at gmail.com  Sat Sep 24 17:48:53 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Sep 2005 11:48:53 -0400
Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
Message-ID: <971536df05092408483b1f2d7d@mail.gmail.com>

I noticed, what seened to me, to be odd.  These produce
a boxplot in the first case and a spineplot in the second
case in R .2.2.0:

plot(Sepal.Length ~ Species, iris)
plot(Species ~ Sepal.Length, iris)

What if one wants to exchange axes?  Does the fact that
this seemingly innocuous change result in completely
different graphics make sense?  Is it desirable?


From lai at lindaspaces.com  Sat Sep 24 21:03:06 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Sat, 24 Sep 2005 15:03:06 -0400
Subject: [Rd] complex.h in R
Message-ID: <4335A2EA.1050000@lindaspaces.com>

Hi,
    How does complex.h used in R? Whether a compiler support complex.h 
or not, does it affect R's performance? I used PGI compiler to build 
R-devel on AMD Opteron, but the configuration file failed to link BLAS 
library despite the fact it is located in the usual location, 
/usr/lib64.  PGI said they don't support complex.h. R configuration 
script printed out that doublecomplex is not supported. Are "supporting 
complex.h" and "linking BLAS library" related?
any comments on this issue?

note: I can ignore linking BLAS and proceed to compile R with PGI 
compiler successfully.

Regards,
Jennifer


From ggrothendieck at gmail.com  Sat Sep 24 19:40:50 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Sep 2005 13:40:50 -0400
Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
In-Reply-To: <20050924172102.DBZZ21470.tomts22-srv.bellnexxia.net@JohnDesktop8300>
References: <971536df05092408483b1f2d7d@mail.gmail.com>
	<20050924172102.DBZZ21470.tomts22-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <971536df05092410407260a0ce@mail.gmail.com>

I agree that I was mixing up the two issues.

On 9/24/05, John Fox <jfox at mcmaster.ca> wrote:
> Dear Gabor,
>
> This behaviour makes sense to me, since in the first case the response is
> quantitative and the explanatory variable a factor (hence, parallel
> boxplots), while in the second it's vice-versa (hence parallel stacked
> bars). That is, the primary distinction, I think, isn't the orientation of
> the axes but the nature of the variables.
>
> Regards,
>  John
>
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> --------------------------------
>
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Gabor Grothendieck
> > Sent: Saturday, September 24, 2005 10:49 AM
> > To: R-devel
> > Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
> >
> > I noticed, what seened to me, to be odd.  These produce a
> > boxplot in the first case and a spineplot in the second case
> > in R .2.2.0:
> >
> > plot(Sepal.Length ~ Species, iris)
> > plot(Species ~ Sepal.Length, iris)
> >
> > What if one wants to exchange axes?  Does the fact that this
> > seemingly innocuous change result in completely different
> > graphics make sense?  Is it desirable?
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ggrothendieck at gmail.com  Sat Sep 24 19:40:15 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Sep 2005 13:40:15 -0400
Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
In-Reply-To: <1127581202.4108.18.camel@localhost.localdomain>
References: <971536df05092408483b1f2d7d@mail.gmail.com>
	<1127581202.4108.18.camel@localhost.localdomain>
Message-ID: <971536df050924104061e849df@mail.gmail.com>

On 9/24/05, Marc Schwartz <MSchwartz at mn.rr.com> wrote:
> On Sat, 2005-09-24 at 11:48 -0400, Gabor Grothendieck wrote:
> > I noticed, what seened to me, to be odd.  These produce
> > a boxplot in the first case and a spineplot in the second
> > case in R .2.2.0:
> >
> > plot(Sepal.Length ~ Species, iris)
> > plot(Species ~ Sepal.Length, iris)
> >
> > What if one wants to exchange axes?  Does the fact that
> > this seemingly innocuous change result in completely
> > different graphics make sense?  Is it desirable?
>
> Gabor,
>
> Did you try:
>
> plot(Sepal.Length ~ Species, iris, horizontal = TRUE)

I had tried horiz= which did not have any effect but I should
have written it all out since it comes after a ... .  In any
case it works as you have shown but not if I interchange
the variables.

>
> This will rotate the boxplot by 90 degrees, as expected.
>
> The plot method is dispatched based upon (from ?plot.formula):
>
> If y is an object (i.e. has a class attribute) then plot.formula looks
> for a plot method for that class first. Otherwise, the class of x will
> determine the type of the plot. For factors this will be a parallel
> boxplot, and argument horizontal = TRUE can be used (see boxplot).
>
>
> Since there is no plot.numeric(), plot.factor() will be used.
>
> This is unchanged from 2.1.1.
>
> What is changed is the plot that is created in your second case. In
> 2.1.1, this was a barplot, rather than a spineplot. From
> 2.1.1 ?plot.factor:
>
> This functions implements a "scatterplot" method for factor arguments of
> the generic plot function. Actually, boxplot or barplot are used when
> appropriate.
>
>
> >From 2.0.0 beta ?plot.factor:
>
> This functions implements a "scatterplot" method for factor arguments of
> the generic plot function. Actually, boxplot is used when y is numeric
> and a spineplot when y is a factor. For a single factor x (i.e., with y
> missing) a simple barplot is produced.
>
>
>
> HTH,
>
> Marc Schwartz
>
>
>

OK. Thanks.


From jfox at mcmaster.ca  Sat Sep 24 19:21:03 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 24 Sep 2005 13:21:03 -0400
Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
In-Reply-To: <971536df05092408483b1f2d7d@mail.gmail.com>
Message-ID: <20050924172102.DBZZ21470.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Gabor,

This behaviour makes sense to me, since in the first case the response is
quantitative and the explanatory variable a factor (hence, parallel
boxplots), while in the second it's vice-versa (hence parallel stacked
bars). That is, the primary distinction, I think, isn't the orientation of
the axes but the nature of the variables.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Gabor Grothendieck
> Sent: Saturday, September 24, 2005 10:49 AM
> To: R-devel
> Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
> 
> I noticed, what seened to me, to be odd.  These produce a 
> boxplot in the first case and a spineplot in the second case 
> in R .2.2.0:
> 
> plot(Sepal.Length ~ Species, iris)
> plot(Species ~ Sepal.Length, iris)
> 
> What if one wants to exchange axes?  Does the fact that this 
> seemingly innocuous change result in completely different 
> graphics make sense?  Is it desirable?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From MSchwartz at mn.rr.com  Sat Sep 24 19:19:20 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 24 Sep 2005 12:19:20 -0500
Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
In-Reply-To: <1127581202.4108.18.camel@localhost.localdomain>
References: <971536df05092408483b1f2d7d@mail.gmail.com>
	<1127581202.4108.18.camel@localhost.localdomain>
Message-ID: <1127582360.4108.21.camel@localhost.localdomain>

On Sat, 2005-09-24 at 12:00 -0500, Marc Schwartz wrote:
> >From 2.0.0 beta ?plot.factor:

Ack...That should be 2.2.0 beta.

Sorry for the typo.

Marc


From MSchwartz at mn.rr.com  Sat Sep 24 19:00:01 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 24 Sep 2005 12:00:01 -0500
Subject: [Rd] plot, spineplot, boxplot in R 2.2.0
In-Reply-To: <971536df05092408483b1f2d7d@mail.gmail.com>
References: <971536df05092408483b1f2d7d@mail.gmail.com>
Message-ID: <1127581202.4108.18.camel@localhost.localdomain>

On Sat, 2005-09-24 at 11:48 -0400, Gabor Grothendieck wrote:
> I noticed, what seened to me, to be odd.  These produce
> a boxplot in the first case and a spineplot in the second
> case in R .2.2.0:
> 
> plot(Sepal.Length ~ Species, iris)
> plot(Species ~ Sepal.Length, iris)
> 
> What if one wants to exchange axes?  Does the fact that
> this seemingly innocuous change result in completely
> different graphics make sense?  Is it desirable?

Gabor,

Did you try:

plot(Sepal.Length ~ Species, iris, horizontal = TRUE)

This will rotate the boxplot by 90 degrees, as expected.

The plot method is dispatched based upon (from ?plot.formula):

If y is an object (i.e. has a class attribute) then plot.formula looks
for a plot method for that class first. Otherwise, the class of x will
determine the type of the plot. For factors this will be a parallel
boxplot, and argument horizontal = TRUE can be used (see boxplot).


Since there is no plot.numeric(), plot.factor() will be used.

This is unchanged from 2.1.1.

What is changed is the plot that is created in your second case. In
2.1.1, this was a barplot, rather than a spineplot. From
2.1.1 ?plot.factor:

This functions implements a ?scatterplot? method for factor arguments of
the generic plot function. Actually, boxplot or barplot are used when
appropriate.


>From 2.0.0 beta ?plot.factor:

This functions implements a ?scatterplot? method for factor arguments of
the generic plot function. Actually, boxplot is used when y is numeric
and a spineplot when y is a factor. For a single factor x (i.e., with y
missing) a simple barplot is produced.



HTH,

Marc Schwartz


From ripley at stats.ox.ac.uk  Sat Sep 24 22:36:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Sep 2005 21:36:38 +0100 (BST)
Subject: [Rd] complex.h in R
In-Reply-To: <4335A2EA.1050000@lindaspaces.com>
Message-ID: <Pine.GSO.4.31.0509242129110.17364-100000@toucan.stats>

On Sat, 24 Sep 2005, Jennifer Lai wrote:

> Hi,
>     How does complex.h used in R? Whether a compiler support complex.h
> or not, does it affect R's performance?

complex.h will only used in future (2.2.0-to-be) versions of R, and only
if configure finds enough C99 support. Otherwise R's own C-level complex
support is used, as it always was.  One would expect the OS's support to
be faster and more accurate (but one could be disappointed, we have
found).

> I used PGI compiler to build
> R-devel on AMD Opteron, but the configuration file failed to link BLAS
> library despite the fact it is located in the usual location,
> /usr/lib64.

Look in config.log to find out why.

> PGI said they don't support complex.h. R configuration
> script printed out that doublecomplex is not supported.

That is *FORTRAN* DOUBLE COMPLEX, and that does affect the operation of R,
as without it you will not have complex linear algebra support.

> Are "supporting
> complex.h" and "linking BLAS library" related?

No.  They are completely orthoogonal concepts.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rhurlin at gwdg.de  Sun Sep 25 12:08:25 2005
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 25 Sep 2005 12:08:25 +0200
Subject: [Rd] FreeBSD 7.0-CURRENT and R-2.2.0 alpha
In-Reply-To: <Pine.LNX.4.61.0509110749100.24002@gannet.stats>
References: <4322B766.10803@gwdg.de>
	<Pine.LNX.4.61.0509110749100.24002@gannet.stats>
Message-ID: <43367719.6010403@gwdg.de>

As I said before I experience difficulties to evaluate what configure 
has found.

The place in R's config.log, where 'cpow' fails, sais:

------------------------
configure:32656: checking for cpow
configure:32721: gcc -o conftest -g -O2 -D__NO_MATH_INLINES 
-I/usr/local/include -L/usr/local/lib conftest.c -lm  >&5
conftest.c:165: warning: conflicting types for built-in function 'cpow'
/var/tmp//cc4mUk2D.o(.text+0x14): In function `main':
/usr/local/R-beta/conftest.c:189: undefined reference to `cpow'
/var/tmp//cc4mUk2D.o(.data+0x0):/usr/local/R-beta/conftest.c:188: 
undefined reference to `cpow'
configure:32727: $? = 1
configure: failed program was:
| /* confdefs.h.  */
[...]
------------------------

It is almost the same for the other references. If desired, I can send 
config.log.



In FreeBSD's '/usr/include' I found the header-file 'tgmath.h' which 
defines the following:

#define	pow(x, y)	__tg_impl_full(x, x, y, pow, powf, powl,\
			    cpow, cpowf, cpowl, x, y)
#define	carg(x)		__tg_simple(x, carg)

Up to now I have no idea, where the rest (clog, cexp, csqrt ...) is 
defined in FreeBSD.


I am not familiar with configure scripts, autoconf and automake. So I am 
afraid I need more guidance to progress.

Rainer Hurling



 > Prof Brian Ripley wrote:

 > These were found by AC_CHECK_FUNCS (please confirm what configure said)
 > so most likely some macro needs to be set or header included.
 >
 > Could you please find out how configure managed to find cpow etc when
 > they appear not to be in libc/libm?


From jussi.jousimo at ktl.fi  Mon Sep 26 13:34:23 2005
From: jussi.jousimo at ktl.fi (jussi.jousimo@ktl.fi)
Date: Mon, 26 Sep 2005 13:34:23 +0200 (CEST)
Subject: [Rd] Assigning a zero length vector to a list (PR#8157)
Message-ID: <20050926113423.E6A291C699@slim.kubism.ku.dk>

Full_Name: Jussi Jousimo
Version: 2.2.0 beta
OS: Windows XP
Submission from: (NULL) (193.167.195.60)


I'm trying to assign a zero length vector to a list:

x<-numeric()
length(x)
foo<-list()
foo$bar[[1]]<-x
length(foo$bar[[1]])
foo

But in the list this vector turns out to be length one with random content.
x<-character() makes R to crash.


From murdoch at stats.uwo.ca  Mon Sep 26 15:05:47 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 26 Sep 2005 09:05:47 -0400
Subject: [Rd] Assigning a zero length vector to a list (PR#8157)
In-Reply-To: <20050926113423.E6A291C699@slim.kubism.ku.dk>
References: <20050926113423.E6A291C699@slim.kubism.ku.dk>
Message-ID: <4337F22B.3070905@stats.uwo.ca>

On 9/26/2005 7:34 AM, jussi.jousimo at ktl.fi wrote:
> Full_Name: Jussi Jousimo
> Version: 2.2.0 beta
> OS: Windows XP
> Submission from: (NULL) (193.167.195.60)
> 
> 
> I'm trying to assign a zero length vector to a list:
> 
> x<-numeric()
> length(x)
> foo<-list()
> foo$bar[[1]]<-x
> length(foo$bar[[1]])
> foo
> 
> But in the list this vector turns out to be length one with random content.
> x<-character() makes R to crash.

After foo<-list(), foo$bar is NULL, so we can simplify this.

Here's a simpler version:

# These work, which is a bit of a surprise, but there is some 
inconsistency:   one x becomes a list, the other is numeric:
 > x <- NULL
 > x[[1]] <- 1:10
 > x
[[1]]
  [1]  1  2  3  4  5  6  7  8  9 10

 > x <- NULL
 > x[[1]] <- 1
 > x
[1] 1


# This generates the same bug as the above:
 > x <- NULL
 > x[[1]] <- numeric(0)
 > x
[1] 4.250083e-314

It looks like we're trying to be too clever with handling assignments to 
components of NULL.  Wouldn't it make more sense for those to generate 
an error?

Duncan Murdoch


From p.dalgaard at biostat.ku.dk  Mon Sep 26 16:29:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Sep 2005 16:29:49 +0200
Subject: [Rd] Assigning a zero length vector to a list (PR#8157)
In-Reply-To: <4337F22B.3070905@stats.uwo.ca>
References: <20050926113423.E6A291C699@slim.kubism.ku.dk>
	<4337F22B.3070905@stats.uwo.ca>
Message-ID: <x28xxjewbm.fsf@turmalin.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> After foo<-list(), foo$bar is NULL, so we can simplify this.
> 
> Here's a simpler version:
> 
> # These work, which is a bit of a surprise, but there is some 
> inconsistency:   one x becomes a list, the other is numeric:
>  > x <- NULL
>  > x[[1]] <- 1:10
>  > x
> [[1]]
>   [1]  1  2  3  4  5  6  7  8  9 10
> 
>  > x <- NULL
>  > x[[1]] <- 1
>  > x
> [1] 1
> 
> 
> # This generates the same bug as the above:
>  > x <- NULL
>  > x[[1]] <- numeric(0)
>  > x
> [1] 4.250083e-314
> 
> It looks like we're trying to be too clever with handling assignments to 
> components of NULL.  Wouldn't it make more sense for those to generate 
> an error?

Once upon a time, we had pairlists, and NULL was the empty list. This
looks like it might be a relic. If so, it likely also predates
consistent handling of zero-length vectors, so something is getting
confused. I think it would be reasonable to expect similar results to
this: 

> x<-list()
> x[[1]] <- numeric(0)
> x
[[1]]
numeric(0)

 

S-PLUS also tries to handle NULL as a zero length list, with some
anomalies:

> x <- NULL
> x[[1]] <- numeric(0)
> x
$value:
numeric(0)


> x <- list()
> x[[1]] <- numeric(0)
> x
[[1]]:
numeric(0)


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Mon Sep 26 16:29:59 2005
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Mon, 26 Sep 2005 16:29:59 +0200 (CEST)
Subject: [Rd] Assigning a zero length vector to a list (PR#8157)
Message-ID: <20050926142959.0E5591C9C3@slim.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> After foo<-list(), foo$bar is NULL, so we can simplify this.
> 
> Here's a simpler version:
> 
> # These work, which is a bit of a surprise, but there is some 
> inconsistency:   one x becomes a list, the other is numeric:
>  > x <- NULL
>  > x[[1]] <- 1:10
>  > x
> [[1]]
>   [1]  1  2  3  4  5  6  7  8  9 10
> 
>  > x <- NULL
>  > x[[1]] <- 1
>  > x
> [1] 1
> 
> 
> # This generates the same bug as the above:
>  > x <- NULL
>  > x[[1]] <- numeric(0)
>  > x
> [1] 4.250083e-314
> 
> It looks like we're trying to be too clever with handling assignments to 
> components of NULL.  Wouldn't it make more sense for those to generate 
> an error?

Once upon a time, we had pairlists, and NULL was the empty list. This
looks like it might be a relic. If so, it likely also predates
consistent handling of zero-length vectors, so something is getting
confused. I think it would be reasonable to expect similar results to
this: 

> x<-list()
> x[[1]] <- numeric(0)
> x
[[1]]
numeric(0)

 

S-PLUS also tries to handle NULL as a zero length list, with some
anomalies:

> x <- NULL
> x[[1]] <- numeric(0)
> x
$value:
numeric(0)


> x <- list()
> x[[1]] <- numeric(0)
> x
[[1]]:
numeric(0)


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From charles.dupont at vanderbilt.edu  Mon Sep 26 17:34:19 2005
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Mon, 26 Sep 2005 10:34:19 -0500
Subject: [Rd] is.Date function question
Message-ID: <433814FB.30904@vanderbilt.edu>

Why is there no is.Date function in R?  I am running 2.1.1 does it exist 
in newer version?  If there is a reasoning behind the lack of a is.Date 
function what is it?

Thanks

Charles


-- 
Charles Dupont         Computer System Analyst      School of Medicine
Phone: (615) 936-6510  Department of Biostatistics   Vanderbilt University


From ggrothendieck at gmail.com  Mon Sep 26 17:43:57 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 26 Sep 2005 11:43:57 -0400
Subject: [Rd] is.Date function question
In-Reply-To: <433814FB.30904@vanderbilt.edu>
References: <433814FB.30904@vanderbilt.edu>
Message-ID: <971536df05092608437ede3eb0@mail.gmail.com>

Try this:

> is(Sys.Date(), "Date")
[1] TRUE
> is(33, "Date")
[1] FALSE

> inherits(Sys.Date(), "Date")
[1] TRUE
> inherits(33, "Date")
[1] FALSE

> R.version.string
[1] "R version 2.2.0, 2005-09-20"


On 9/26/05, Charles Dupont <charles.dupont at vanderbilt.edu> wrote:
> Why is there no is.Date function in R?  I am running 2.1.1 does it exist
> in newer version?  If there is a reasoning behind the lack of a is.Date
> function what is it?
>
> Thanks
>
> Charles
>
>
> --
> Charles Dupont         Computer System Analyst      School of Medicine
> Phone: (615) 936-6510  Department of Biostatistics   Vanderbilt University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mschwartz at mn.rr.com  Mon Sep 26 17:51:00 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 26 Sep 2005 10:51:00 -0500
Subject: [Rd] R's parsing of command line arguments using commandArgs()
In-Reply-To: <1127507823.4947.52.camel@localhost.localdomain>
References: <1127507823.4947.52.camel@localhost.localdomain>
Message-ID: <1127749860.4288.18.camel@localhost.localdomain>

On Fri, 2005-09-23 at 15:37 -0500, Marc Schwartz (via MN) wrote:
> Hi all,
> 
> I am setting up some R program files for use by our DB programmers to
> enable them to utilize some R functions which will be called from within
> TCL code. R has been installed on an RHEL server and R will process the
> results of SQL queries against an Oracle database.
> 
> In some cases, they will generate a data file to be read in and
> processed by R, in others they will simply make the tabulated results
> available.
> 
> I know that I could do the SQL queries from within R, however, this is
> the approach that has been defined for now for various reasons.
> 
> I wanted to provide some flexibility for them, by passing some of the
> tabulated results via command line arguments to R functions, rather than
> via environment variables, which is easier for them to do in TCL it
> would seem. They would create these values at run time, based upon specs
> that I give them.
> 
> Using the following as an example:
> 
> $ R --slave --vanilla --args "c(5,5)" "c(.5,.5)" < RScript.R
> 
> I can then process "c(5,5)" and "c(.5,.5)" as two arguments, via:
> 
> Args <- commandArgs()
> 
> where the two arguments are Args[5] and Args[6], respectively. I can
> then of course pass these as "eval(parse(text = Args[5]))" to other R
> functions.
> 
> 
> However, if there is any whitespace in the two arguments, such as:
> 
> R --slave --vanilla --args "c(5, 5)" "c(.5, .5)" < RScript.R
> 
> even though surrounded by double quotes (or single quotes or
> backquotes), the two arguments are parsed as four.
> 
> Is this behavior expected? I was under the impression, from other C
> based programs and bash shell scripts for example, that the use of the
> double quotes would wrap such text and thus be parsed as a single
> argument.
> 
> This is using:
> 
> Version 2.1.1 Patched (2005-09-22) on FC4.


Apologies for replying to my own post here, but I wanted to follow up
with a solution provided by Robert McGehee, which works here.

The solution is as follows:

echo "a <- c(5, 5); b <- c(0.5, 0.5)" | cat - RScript.R | R --slave \
--vanilla


This uses echo and cat to pre-pend the 'a' and 'b' vector assignments to
the R program file, before passing the whole thing to R.

This then allows for arguments with embedded whitespace to be passed as
required at run time.

Thanks Robert!

Marc


From ripley at stats.ox.ac.uk  Mon Sep 26 17:54:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Sep 2005 16:54:08 +0100 (BST)
Subject: [Rd] is.Date function question
In-Reply-To: <433814FB.30904@vanderbilt.edu>
References: <433814FB.30904@vanderbilt.edu>
Message-ID: <Pine.LNX.4.61.0509261653180.23625@gannet.stats>

inherits(object, "Date") is all that is required.

We don't need to complicate R with such simple functions.

On Mon, 26 Sep 2005, Charles Dupont wrote:

> Why is there no is.Date function in R?  I am running 2.1.1 does it exist
> in newer version?  If there is a reasoning behind the lack of a is.Date
> function what is it?
>
> Thanks
>
> Charles
>
>
> -- 
> Charles Dupont         Computer System Analyst      School of Medicine
> Phone: (615) 936-6510  Department of Biostatistics   Vanderbilt University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Sep 26 18:12:23 2005
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 26 Sep 2005 17:12:23 +0100 (GMT Daylight Time)
Subject: [Rd] R's parsing of command line arguments using commandArgs()
In-Reply-To: <1127749860.4288.18.camel@localhost.localdomain>
References: <1127507823.4947.52.camel@localhost.localdomain>
	<1127749860.4288.18.camel@localhost.localdomain>
Message-ID: <Pine.WNT.4.58.0509261703070.3800@auk>

On Mon, 26 Sep 2005, Marc Schwartz (via MN) wrote:

> On Fri, 2005-09-23 at 15:37 -0500, Marc Schwartz (via MN) wrote:
> > Hi all,
> >
> > I am setting up some R program files for use by our DB programmers to
> > enable them to utilize some R functions which will be called from within
> > TCL code. R has been installed on an RHEL server and R will process the
> > results of SQL queries against an Oracle database.
> >
> > In some cases, they will generate a data file to be read in and
> > processed by R, in others they will simply make the tabulated results
> > available.
> >
> > I know that I could do the SQL queries from within R, however, this is
> > the approach that has been defined for now for various reasons.
> >
> > I wanted to provide some flexibility for them, by passing some of the
> > tabulated results via command line arguments to R functions, rather than
> > via environment variables, which is easier for them to do in TCL it
> > would seem. They would create these values at run time, based upon specs
> > that I give them.
> >
> > Using the following as an example:
> >
> > $ R --slave --vanilla --args "c(5,5)" "c(.5,.5)" < RScript.R
> >
> > I can then process "c(5,5)" and "c(.5,.5)" as two arguments, via:
> >
> > Args <- commandArgs()
> >
> > where the two arguments are Args[5] and Args[6], respectively. I can
> > then of course pass these as "eval(parse(text = Args[5]))" to other R
> > functions.
> >
> >
> > However, if there is any whitespace in the two arguments, such as:
> >
> > R --slave --vanilla --args "c(5, 5)" "c(.5, .5)" < RScript.R
> >
> > even though surrounded by double quotes (or single quotes or
> > backquotes), the two arguments are parsed as four.
> >
> > Is this behavior expected? I was under the impression, from other C
> > based programs and bash shell scripts for example, that the use of the
> > double quotes would wrap such text and thus be parsed as a single
> > argument.

Sort of.  Unfortunately both the R front-end script and the R executable
get to play here, so once the front-end has parsed the args the quoting
gets lost.  You might hope that double quoting would help, but it does not.

> >
> > This is using:
> >
> > Version 2.1.1 Patched (2005-09-22) on FC4.
>
>
> Apologies for replying to my own post here, but I wanted to follow up
> with a solution provided by Robert McGehee, which works here.
>
> The solution is as follows:
>
> echo "a <- c(5, 5); b <- c(0.5, 0.5)" | cat - RScript.R | R --slave \
> --vanilla
>
>
> This uses echo and cat to pre-pend the 'a' and 'b' vector assignments to
> the R program file, before passing the whole thing to R.
>
> This then allows for arguments with embedded whitespace to be passed as
> required at run time.
>
> Thanks Robert!
>
> Marc
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lai at lindaspaces.com  Mon Sep 26 19:05:50 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Mon, 26 Sep 2005 13:05:50 -0400
Subject: [Rd] complex.h in R
In-Reply-To: <Pine.GSO.4.31.0509242129110.17364-100000@toucan.stats>
References: <Pine.GSO.4.31.0509242129110.17364-100000@toucan.stats>
Message-ID: <43382A6E.8020109@lindaspaces.com>

Hi,
I checked config.log and BLAS_LIBS was not set. However, I have set 
BLAS_LIBS='-L/usr/lib64 -lblas' in config.site file.
I can't figure out why BLAS_LIBS is not set, when PGI compiler is used. 
When gcc is used, BLAS_LIBS need not be set in config.site and 
automatically get picked up by the configuration script.

Here is a snapshot of the configuration script output (for buidling R 
with PGI compiler):
checking for complex.h... yes
checking for double complex... no
checking for sgemm_ in -L/usr/lib64 -lblas... yes
checking whether double complex BLAS can be used... no

Is there other thing I should look into in the config.log?
Your help is very much appreicated.


Thanks,
Jennifer


Prof Brian Ripley wrote:

>On Sat, 24 Sep 2005, Jennifer Lai wrote:
>
>  
>
>>Hi,
>>    How does complex.h used in R? Whether a compiler support complex.h
>>or not, does it affect R's performance?
>>    
>>
>
>complex.h will only used in future (2.2.0-to-be) versions of R, and only
>if configure finds enough C99 support. Otherwise R's own C-level complex
>support is used, as it always was.  One would expect the OS's support to
>be faster and more accurate (but one could be disappointed, we have
>found).
>
>  
>
>>I used PGI compiler to build
>>R-devel on AMD Opteron, but the configuration file failed to link BLAS
>>library despite the fact it is located in the usual location,
>>/usr/lib64.
>>    
>>
>
>Look in config.log to find out why.
>
>  
>
>>PGI said they don't support complex.h. R configuration
>>script printed out that doublecomplex is not supported.
>>    
>>
>
>That is *FORTRAN* DOUBLE COMPLEX, and that does affect the operation of R,
>as without it you will not have complex linear algebra support.
>
>  
>
>>Are "supporting
>>complex.h" and "linking BLAS library" related?
>>    
>>
>
>No.  They are completely orthoogonal concepts.
>
>  
>


From ripley at stats.ox.ac.uk  Mon Sep 26 19:12:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Sep 2005 18:12:50 +0100 (BST)
Subject: [Rd] complex.h in R
In-Reply-To: <43382A6E.8020109@lindaspaces.com>
References: <Pine.GSO.4.31.0509242129110.17364-100000@toucan.stats>
	<43382A6E.8020109@lindaspaces.com>
Message-ID: <Pine.LNX.4.61.0509261808270.27900@gannet.stats>

On Mon, 26 Sep 2005, Jennifer Lai wrote:

> Hi,
> I checked config.log and BLAS_LIBS was not set. However, I have set 
> BLAS_LIBS='-L/usr/lib64 -lblas' in config.site file.
> I can't figure out why BLAS_LIBS is not set, when PGI compiler is used. When 
> gcc is used, BLAS_LIBS need not be set in config.site and automatically get 
> picked up by the configuration script.
>
> Here is a snapshot of the configuration script output (for buidling R with 
> PGI compiler):
> checking for complex.h... yes
> checking for double complex... no
> checking for sgemm_ in -L/usr/lib64 -lblas... yes
> checking whether double complex BLAS can be used... no
>
> Is there other thing I should look into in the config.log?

You need to look for the evidence for the line

> checking for sgemm_ in -L/usr/lib64 -lblas... yes

in config.log.  I very much doubt that -L/usr/lib64 helps you: surely that 
should be in your library path.  But you will probably find you cannot mix 
code compiled under different compilers, especially as -lblas is likely to 
be Fortran compiled with g77.  (You may need -lblas -lg2c, but you would 
be better off using the BLAS built into R.)


> Your help is very much appreicated.
>
>
> Thanks,
> Jennifer
>
>
> Prof Brian Ripley wrote:
>
>> On Sat, 24 Sep 2005, Jennifer Lai wrote:
>> 
>> 
>>> Hi,
>>>    How does complex.h used in R? Whether a compiler support complex.h
>>> or not, does it affect R's performance?
>>> 
>> 
>> complex.h will only used in future (2.2.0-to-be) versions of R, and only
>> if configure finds enough C99 support. Otherwise R's own C-level complex
>> support is used, as it always was.  One would expect the OS's support to
>> be faster and more accurate (but one could be disappointed, we have
>> found).
>> 
>> 
>>> I used PGI compiler to build
>>> R-devel on AMD Opteron, but the configuration file failed to link BLAS
>>> library despite the fact it is located in the usual location,
>>> /usr/lib64.
>>> 
>> 
>> Look in config.log to find out why.
>> 
>> 
>>> PGI said they don't support complex.h. R configuration
>>> script printed out that doublecomplex is not supported.
>>> 
>> 
>> That is *FORTRAN* DOUBLE COMPLEX, and that does affect the operation of R,
>> as without it you will not have complex linear algebra support.
>> 
>> 
>>> Are "supporting
>>> complex.h" and "linking BLAS library" related?
>>> 
>> 
>> No.  They are completely orthoogonal concepts.
>> 
>> 
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lai at lindaspaces.com  Mon Sep 26 19:31:42 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Mon, 26 Sep 2005 13:31:42 -0400
Subject: [Rd] complex.h in R
In-Reply-To: <Pine.LNX.4.61.0509261808270.27900@gannet.stats>
References: <Pine.GSO.4.31.0509242129110.17364-100000@toucan.stats>
	<43382A6E.8020109@lindaspaces.com>
	<Pine.LNX.4.61.0509261808270.27900@gannet.stats>
Message-ID: <4338307E.6020307@lindaspaces.com>

Hi,

Prof Brian Ripley wrote:

> On Mon, 26 Sep 2005, Jennifer Lai wrote:
>
>> Hi,
>> I checked config.log and BLAS_LIBS was not set. However, I have set 
>> BLAS_LIBS='-L/usr/lib64 -lblas' in config.site file.
>> I can't figure out why BLAS_LIBS is not set, when PGI compiler is 
>> used. When gcc is used, BLAS_LIBS need not be set in config.site and 
>> automatically get picked up by the configuration script.
>>
>> Here is a snapshot of the configuration script output (for buidling R 
>> with PGI compiler):
>> checking for complex.h... yes
>> checking for double complex... no
>> checking for sgemm_ in -L/usr/lib64 -lblas... yes
>> checking whether double complex BLAS can be used... no
>>
>> Is there other thing I should look into in the config.log?
>
>
> You need to look for the evidence for the line
>
>> checking for sgemm_ in -L/usr/lib64 -lblas... yes
>
>
> in config.log.  I very much doubt that -L/usr/lib64 helps you: surely 
> that should be in your library path.  But you will probably find you 
> cannot mix code compiled under different compilers, especially as 
> -lblas is likely to be Fortran compiled with g77.  (You may need 
> -lblas -lg2c, but you would be better off using the BLAS built into R.)
>

"-lg2c -lblas" didn't work.  I am not sure if mixing code compiled under 
different compilers is the problem, because I built R with ACML library 
(PGI compiled), and config.log still shows that BLAS_LIBS is not set.
Sorry for being ignorant, but where is the BLAS built into R? Is 
configuring R with "--without-blas" option pick up the BLAS built into 
R? I thought it's to build R with BLAS package.

Your help is very much appreciated.

Thanks,
Jennifer


From ripley at stats.ox.ac.uk  Mon Sep 26 19:51:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Sep 2005 18:51:48 +0100 (BST)
Subject: [Rd] complex.h in R
In-Reply-To: <4338307E.6020307@lindaspaces.com>
References: <Pine.GSO.4.31.0509242129110.17364-100000@toucan.stats>
	<43382A6E.8020109@lindaspaces.com>
	<Pine.LNX.4.61.0509261808270.27900@gannet.stats>
	<4338307E.6020307@lindaspaces.com>
Message-ID: <Pine.LNX.4.61.0509261851050.17272@gannet.stats>

On Mon, 26 Sep 2005, Jennifer Lai wrote:

> Hi,
>
> Prof Brian Ripley wrote:
>
>> On Mon, 26 Sep 2005, Jennifer Lai wrote:
>> 
>>> Hi,
>>> I checked config.log and BLAS_LIBS was not set. However, I have set 
>>> BLAS_LIBS='-L/usr/lib64 -lblas' in config.site file.
>>> I can't figure out why BLAS_LIBS is not set, when PGI compiler is used. 
>>> When gcc is used, BLAS_LIBS need not be set in config.site and 
>>> automatically get picked up by the configuration script.
>>> 
>>> Here is a snapshot of the configuration script output (for buidling R with 
>>> PGI compiler):
>>> checking for complex.h... yes
>>> checking for double complex... no
>>> checking for sgemm_ in -L/usr/lib64 -lblas... yes
>>> checking whether double complex BLAS can be used... no
>>> 
>>> Is there other thing I should look into in the config.log?
>> 
>> 
>> You need to look for the evidence for the line
>> 
>>> checking for sgemm_ in -L/usr/lib64 -lblas... yes
>> 
>> 
>> in config.log.

Where is it?

> I very much doubt that -L/usr/lib64 helps you: surely that 
>> should be in your library path.  But you will probably find you cannot mix 
>> code compiled under different compilers, especially as -lblas is likely to 
>> be Fortran compiled with g77.  (You may need -lblas -lg2c, but you would be 
>> better off using the BLAS built into R.)
>> 
>
> "-lg2c -lblas" didn't work.  I am not sure if mixing code compiled under 
> different compilers is the problem, because I built R with ACML library (PGI 
> compiled), and config.log still shows that BLAS_LIBS is not set.
> Sorry for being ignorant, but where is the BLAS built into R? Is configuring 
> R with "--without-blas" option pick up the BLAS built into R? I thought it's 
> to build R with BLAS package.

No, and please

1) Do read the relevant manual

2) Do answer the question.


>
> Your help is very much appreciated.
>
> Thanks,
> Jennifer
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mschwartz at mn.rr.com  Mon Sep 26 21:09:23 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 26 Sep 2005 14:09:23 -0500
Subject: [Rd] R's parsing of command line arguments using commandArgs()
In-Reply-To: <Pine.WNT.4.58.0509261703070.3800@auk>
References: <1127507823.4947.52.camel@localhost.localdomain>
	<1127749860.4288.18.camel@localhost.localdomain>
	<Pine.WNT.4.58.0509261703070.3800@auk>
Message-ID: <1127761763.4288.54.camel@localhost.localdomain>

On Mon, 2005-09-26 at 17:12 +0100, Prof Brian D Ripley wrote:
> On Mon, 26 Sep 2005, Marc Schwartz (via MN) wrote:
> 
> > On Fri, 2005-09-23 at 15:37 -0500, Marc Schwartz (via MN) wrote:

[snip]

> > > However, if there is any whitespace in the two arguments, such as:
> > >
> > > R --slave --vanilla --args "c(5, 5)" "c(.5, .5)" < RScript.R
> > >
> > > even though surrounded by double quotes (or single quotes or
> > > backquotes), the two arguments are parsed as four.
> > >
> > > Is this behavior expected? I was under the impression, from other C
> > > based programs and bash shell scripts for example, that the use of the
> > > double quotes would wrap such text and thus be parsed as a single
> > > argument.
> 
> Sort of.  Unfortunately both the R front-end script and the R executable
> get to play here, so once the front-end has parsed the args the quoting
> gets lost.  You might hope that double quoting would help, but it does not.

Prof. Ripley,

Thanks kindly for your reply. I suspected that there might be something
going on in the startup script and/or the executable, but did not
consider that the quoting gets stripped before being passed on to the
binary. That makes sense of course.

Given that 2.2.0 is imminent, I know timing on this is bad, but is there
any logic in considering something along the lines of the following for
a future enhancement to the startup script relative to the processing of
arguments after '--args'?

This generic script takes the arguments from the command line, parses
them and adds double quotes back to the arguments as an array, before
passing them to the binary executable command line:

#!/bin/sh

declare -i index
declare -a QuotedArgs

index=1

for Args in "$@"
do
  echo "Arg $index = $Args"
  # Arrays are 0 index based
  QuotedArgs[index-1]=\"$Args\"
  index=index+1
done

echo "R Exec Command: /usr/local/lib/bin/exec/R ${QuotedArgs[@]}"



Thus, from the command line, you get the following:

$ ./QuoteArgs one two three
Arg 1 = one
Arg 2 = two
Arg 3 = three
R Exec Command: /usr/local/lib/bin/exec/R "one" "two" "three"


$ ./QuoteArgs "one two" three
Arg 1 = one two
Arg 2 = three
R Exec Command: /usr/local/lib/bin/exec/R "one two" "three"


$ ./QuoteArgs "one two three"
Arg 1 = one two three
R Exec Command: /usr/local/lib/bin/exec/R "one two three"



Let me know your thoughts, especially any gotchas on this approach.

Best regards,

Marc


From murdoch at stats.uwo.ca  Mon Sep 26 21:12:49 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 26 Sep 2005 15:12:49 -0400
Subject: [Rd] Assigning a zero length vector to a list (PR#8157)
In-Reply-To: <x28xxjewbm.fsf@turmalin.kubism.ku.dk>
References: <20050926113423.E6A291C699@slim.kubism.ku.dk>	<4337F22B.3070905@stats.uwo.ca>
	<x28xxjewbm.fsf@turmalin.kubism.ku.dk>
Message-ID: <43384831.9060000@stats.uwo.ca>

On 9/26/2005 10:29 AM, Peter Dalgaard wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> 
>> After foo<-list(), foo$bar is NULL, so we can simplify this.
>> 
>> Here's a simpler version:
>> 
>> # These work, which is a bit of a surprise, but there is some 
>> inconsistency:   one x becomes a list, the other is numeric:
>>  > x <- NULL
>>  > x[[1]] <- 1:10
>>  > x
>> [[1]]
>>   [1]  1  2  3  4  5  6  7  8  9 10
>> 
>>  > x <- NULL
>>  > x[[1]] <- 1
>>  > x
>> [1] 1
>> 
>> 
>> # This generates the same bug as the above:
>>  > x <- NULL
>>  > x[[1]] <- numeric(0)
>>  > x
>> [1] 4.250083e-314
>> 
>> It looks like we're trying to be too clever with handling assignments to 
>> components of NULL.  Wouldn't it make more sense for those to generate 
>> an error?
> 
> Once upon a time, we had pairlists, and NULL was the empty list. This
> looks like it might be a relic. If so, it likely also predates
> consistent handling of zero-length vectors, so something is getting
> confused. I think it would be reasonable to expect similar results to
> this: 
> 
>> x<-list()
>> x[[1]] <- numeric(0)
>> x
> [[1]]
> numeric(0)

I agree.  I think I see where the problem is (a test "length(y) <= 1" in 
do_subassign2_dflt in subassign.c should be "length(y) == 1"; I'll try 
to fix it.

Duncan Murdoch
> 
>  
> 
> S-PLUS also tries to handle NULL as a zero length list, with some
> anomalies:
> 
>> x <- NULL
>> x[[1]] <- numeric(0)
>> x
> $value:
> numeric(0)
> 
> 
>> x <- list()
>> x[[1]] <- numeric(0)
>> x
> [[1]]:
> numeric(0)
> 
>


From murdoch at stats.uwo.ca  Mon Sep 26 21:13:56 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Mon, 26 Sep 2005 21:13:56 +0200 (CEST)
Subject: [Rd] Assigning a zero length vector to a list (PR#8157)
Message-ID: <20050926191356.644711C8D2@slim.kubism.ku.dk>

On 9/26/2005 10:29 AM, Peter Dalgaard wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> 
>> After foo<-list(), foo$bar is NULL, so we can simplify this.
>> 
>> Here's a simpler version:
>> 
>> # These work, which is a bit of a surprise, but there is some 
>> inconsistency:   one x becomes a list, the other is numeric:
>>  > x <- NULL
>>  > x[[1]] <- 1:10
>>  > x
>> [[1]]
>>   [1]  1  2  3  4  5  6  7  8  9 10
>> 
>>  > x <- NULL
>>  > x[[1]] <- 1
>>  > x
>> [1] 1
>> 
>> 
>> # This generates the same bug as the above:
>>  > x <- NULL
>>  > x[[1]] <- numeric(0)
>>  > x
>> [1] 4.250083e-314
>> 
>> It looks like we're trying to be too clever with handling assignments to 
>> components of NULL.  Wouldn't it make more sense for those to generate 
>> an error?
> 
> Once upon a time, we had pairlists, and NULL was the empty list. This
> looks like it might be a relic. If so, it likely also predates
> consistent handling of zero-length vectors, so something is getting
> confused. I think it would be reasonable to expect similar results to
> this: 
> 
>> x<-list()
>> x[[1]] <- numeric(0)
>> x
> [[1]]
> numeric(0)

I agree.  I think I see where the problem is (a test "length(y) <= 1" in 
do_subassign2_dflt in subassign.c should be "length(y) == 1"; I'll try 
to fix it.

Duncan Murdoch
> 
>  
> 
> S-PLUS also tries to handle NULL as a zero length list, with some
> anomalies:
> 
>> x <- NULL
>> x[[1]] <- numeric(0)
>> x
> $value:
> numeric(0)
> 
> 
>> x <- list()
>> x[[1]] <- numeric(0)
>> x
> [[1]]:
> numeric(0)
> 
>


From hbren at stat.tamu.edu  Tue Sep 27 00:19:14 2005
From: hbren at stat.tamu.edu (hbren@stat.tamu.edu)
Date: Tue, 27 Sep 2005 00:19:14 +0200 (CEST)
Subject: [Rd] constrOptim (PR#8158)
Message-ID: <20050926221914.201E31C913@slim.kubism.ku.dk>

Full_Name: Haobo Ren
Version: 2.1.1
OS: Windows 2000
Submission from: (NULL) (192.11.226.116)


When running constrOptim, there is error message

Error: subscript out of bounds


From murdoch at stats.uwo.ca  Tue Sep 27 01:14:28 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 26 Sep 2005 19:14:28 -0400
Subject: [Rd] constrOptim (PR#8158)
In-Reply-To: <20050926221914.201E31C913@slim.kubism.ku.dk>
References: <20050926221914.201E31C913@slim.kubism.ku.dk>
Message-ID: <433880D4.1040204@stats.uwo.ca>

On 9/26/2005 6:19 PM, hbren at stat.tamu.edu wrote:
> Full_Name: Haobo Ren
> Version: 2.1.1
> OS: Windows 2000
> Submission from: (NULL) (192.11.226.116)
> 
> 
> When running constrOptim, there is error message
> 
> Error: subscript out of bounds
> 

Please test this in the latest beta version, (available from 
http://cran.r-project.org/bin/windows/base/rdevel.html) and if you still 
see the problem, put together a reproducible example.  (If you are 
unable to install the beta, please do post the example.)

Make it as simple as you can, so you're sure it's not an error in your 
own code.  If you need to use simulated data, call set.seed() first so 
we can reproduce the results.

Thursday is code freeze; if you can post the relevant information enough 
before that there's a good chance this could be fixed before the next 
release.

Duncan Murdoch


From ggrothendieck at gmail.com  Tue Sep 27 07:36:20 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 27 Sep 2005 01:36:20 -0400
Subject: [Rd] R 2.2.0 tooltips
Message-ID: <971536df05092622363ab648bf@mail.gmail.com>

On R 2.2.0 (and maybe earlier ones too) the tooltips on the
icons at the top include "load image" and "save image".
I find the use of the word image possibly confusing.  I
had just been editing some graphics images and
moved over to R and my first thought was that these
would allow me to insert a background image.


From murdoch at stats.uwo.ca  Tue Sep 27 18:44:30 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Tue, 27 Sep 2005 18:44:30 +0200 (CEST)
Subject: [Rd] constrOptim (PR#8158)
Message-ID: <20050927164430.393E515A83@slim.kubism.ku.dk>

On 9/27/2005 12:20 PM, hbren at stat.tamu.edu wrote:
> I tested both 2.2.0 Beta and 2.1.1 Patched. The problem I reported is
> still there. I gurantee that there is no error in my codes. I identified
> there is something wrong in "optim" or the accociated internal function.
> It turns out that the error message
> 
> Error: subscript out of bounds
> 
> shows up when the dimension of parameter is high. Also it happens even
> when the dimension is low but if you run it more times.
> 
> Attached please find the R program with the data file I used for the
> optimization objective function.

When I try your code I get this:

 > 
a=constrOptim(points,target3,NULL,ui=con1,ci=con2,control=list(fnscale=-1), 
value=value,at=at)
Error: subscript out of bounds
 > traceback()
6: f(theta, ...)
5: R(theta, theta.old, ...)
4: fn(par, ...)
3: function (par)
    fn(par, ...)(c(1995, 2253.7, 2057))
2: optim(theta.old, fun, gradient, control = control, method = method,
        ...)
1: constrOptim(points, target3, NULL, ui = con1, ci = con2, control = 
list(fnscale = -1),
        value = value, at = at)

This says that the error occurs in your target3 function (which is 
called f at this point).

So despite your guarantee, I think the bug is in your code, not in R.

Duncan Murdoch

> Thanks,
> 
> 
>> On 9/26/2005 6:19 PM, hbren at stat.tamu.edu wrote:
>>> Full_Name: Haobo Ren
>>> Version: 2.1.1
>>> OS: Windows 2000
>>> Submission from: (NULL) (192.11.226.116)
>>>
>>>
>>> When running constrOptim, there is error message
>>>
>>> Error: subscript out of bounds
>>>
>>
>> Please test this in the latest beta version, (available from
>> http://cran.r-project.org/bin/windows/base/rdevel.html) and if you still
>> see the problem, put together a reproducible example.  (If you are
>> unable to install the beta, please do post the example.)
>>
>> Make it as simple as you can, so you're sure it's not an error in your
>> own code.  If you need to use simulated data, call set.seed() first so
>> we can reproduce the results.
>>
>> Thursday is code freeze; if you can post the relevant information enough
>> before that there's a good chance this could be fixed before the next
>> release.
>>
>> Duncan Murdoch
>>


From leif at reflectivity.com  Tue Sep 27 20:37:27 2005
From: leif at reflectivity.com (Leif Kirschenbaum)
Date: Tue, 27 Sep 2005 11:37:27 -0700
Subject: [Rd] RODBC and utils:object.size
Message-ID: <200509271837.j8RIbYAN024422@hypatia.math.ethz.ch>

I would like to note that utils::object.size fails on RODBC connection objects.
> DB<-RODBC::odbcConnect("internal")
> utils::object.size(DB)
Error in utils::object.size(DB) : object.size: unknown type 22
> 


I took a brief look at do_objectsize in the source code, and could not figure out how it dealt with new classes of objects. i.e. if someone defines a new class (such as "RODBC") are they supposed to define a size method for the class?


My current workaround for listing object sizes is to drop RODBC objects from Petr Pikal's original ls.objects() function:

ls.objects<-function (pos = 1, order.by,...)
{
    napply <- function(names, fn) sapply(names, function(x) fn(get(x,pos=pos)))
    names <- ls(pos = pos,...)
    obj.class <- napply(names, function(x) as.character(class(x))[1])
    obj.drop <- match("RODBC",obj.class)
    obj.class <- obj.class[-obj.drop]
    names <- names[-obj.drop]
    obj.mode <- napply(names, mode)
    obj.type <- ifelse(is.na(obj.class), obj.mode, obj.class)
    obj.size <- napply(names, object.size)
    obj.dim <- t(napply(names, function(x) as.numeric(dim(x))[1:2]))
    vec <- is.na(obj.dim)[, 1] & (obj.type != "function")
    obj.dim[vec, 1] <- napply(names, length)[vec]
    out <- data.frame(obj.type, obj.size, obj.dim)
    names(out) <- c("Type", "Size", "Rows", "Columns")
    if (!missing(order.by)) out <- out[order(out[[order.by]]), ]
    out
} 



Leif S. Kirschenbaum, Ph.D.
Senior Yield Engineer
Reflectivity, Inc.


From dhinds at sonic.net  Tue Sep 27 21:45:54 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Tue, 27 Sep 2005 19:45:54 +0000 (UTC)
Subject: [Rd] Future plans for raw data type?
Message-ID: <dhc7hi$gqj$1@sea.gmane.org>

I've been working with raw vectors quite a bit and was wondering if
the R team might comment on where they see raw vector support going in
the long run.  Is the intent that 'raw' will eventually become a first
class data type on the same level as 'integer'?  Or should 'raw' have 
more limited support, by design?

For example, with very minor changes to subassign.c to implement some
automatic coercions, raw vectors can become arguments to ifelse() and
can be members of data frames.  Would this be desirable?

-- David Hinds


From LI at nsabp.pitt.edu  Tue Sep 27 23:30:40 2005
From: LI at nsabp.pitt.edu (Li, Jia)
Date: Tue, 27 Sep 2005 17:30:40 -0400
Subject: [Rd] Help: A application error and failed just-in-debugging.
Message-ID: <D70CBC108DFBD446862A6E1F6F0B4A150F0867@nsabpmail>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050927/36926d5a/attachment.pl

From jross at openvistas.net  Wed Sep 28 00:48:33 2005
From: jross at openvistas.net (Jeff Ross)
Date: Tue, 27 Sep 2005 16:48:33 -0600 (MDT)
Subject: [Rd] Make test fails in d-p-q-r-tests...
Message-ID: <Pine.BSO.4.63.0509271638560.9423@heinlein.openvistas.net>

Hi,

R-2.1.1, R-patched, and the latest R-beta--all fail with same error

OS:  OpenBSD-current (3.8) on i386
Compiler:gcc version 3.3.5 (propolice)
Thread model: single

configure \
    --with-readline \
    --with-tcltk \
    --with-tcl-config=/usr/local/lib/tcl8.4/tclConfig.sh \
    --with-tk-config=/usr/local/lib/tk8.4/tkConfig.sh \
    --with-libpng \
    --with-jpeglib \
    --with-zlib \
    --with-bzlib \
    --with-pcre \
    --with-libiconv-prefix=/usr/local/

Here's the last bit what make check FORCE=FORCE outputs:

running code in 'grDevices-Ex.R' ... OK
comparing 'grDevices-Ex.Rout' to 'grDevices-Ex.Rout.prev' ... OK
running code in 'graphics-Ex.R' ... OK
comparing 'graphics-Ex.Rout' to 'graphics-Ex.Rout.prev' ... OK
running code in 'stats-Ex.R' ... OK
comparing 'stats-Ex.Rout' to 'stats-Ex.Rout.prev' ... OK
running code in 'datasets-Ex.R' ... OK
comparing 'datasets-Ex.Rout' to 'datasets-Ex.Rout.prev' ... OK
running code in 'methods-Ex.R' ... OK
comparing 'methods-Ex.Rout' to 'methods-Ex.Rout.prev' ... OK
running code in 'grid-Ex.R' ... OK
comparing 'grid-Ex.Rout' to 'grid-Ex.Rout.prev' ... OK
running code in 'splines-Ex.R' ... OK
comparing 'splines-Ex.Rout' to 'splines-Ex.Rout.prev' ... OK
running code in 'stats4-Ex.R' ... OK
comparing 'stats4-Ex.Rout' to 'stats4-Ex.Rout.prev' ... OK
running code in 'tcltk-Ex.R' ... OK
comparing 'tcltk-Ex.Rout' to 'tcltk-Ex.Rout.prev' ... OK
updating test dependencies
`Makedeps' is up to date.
running strict specific tests
running code in 'eval-etc.R' ... OK
comparing 'eval-etc.Rout' to './eval-etc.Rout.save' ... OK
running code in 'simple-true.R' ... OK
comparing 'simple-true.Rout' to './simple-true.Rout.save' ... OK
running code in 'arith-true.R' ... OK
comparing 'arith-true.Rout' to './arith-true.Rout.save' ... OK
running code in 'arith.R' ... OK
comparing 'arith.Rout' to './arith.Rout.save' ... OK
running code in 'lm-tests.R' ... OK
comparing 'lm-tests.Rout' to './lm-tests.Rout.save' ... OK
running code in 'primitive-funs.R' ... OK
comparing 'primitive-funs.Rout' to './primitive-funs.Rout.save' ... OK
running code in 'ok-errors.R' ... OK
comparing 'ok-errors.Rout' to './ok-errors.Rout.save' ... OK
running code in 'method-dispatch.R' ... OK
comparing 'method-dispatch.Rout' to './method-dispatch.Rout.save' ... OK
running code in 'd-p-q-r-tests.R' ...*** Error code 1
Stop in /usr/local/src/R-2.1.1/tests.
*** Error code 1

Here is the tail of d-p-q-r-tests.Rout.fail:

> ## for PR#7902:
> ex <- -c(rev(1/x), ex)
> All.eq(-x, qcauchy(pcauchy(-x)))
[1] TRUE
> All.eq(+x, qcauchy(pcauchy(+x, log=TRUE), log=TRUE))
[1] TRUE
> All.eq(1/x, pcauchy(qcauchy(1/x)))
[1] TRUE
> All.eq(ex,  pcauchy(qcauchy(ex, log=TRUE), log=TRUE))
[1] "`is.NA' value mismatches: 1 in current, 0  in target"
Warning message:
NaNs produced in: qcauchy(p, location, scale, lower.tail, log.p) 
> II <- c(-Inf,Inf)
> stopifnot(pcauchy(II) == 0:1, ## qcauchy(0:1) == II,
+           pcauchy(II, log=TRUE) == c(-Inf,0),
+           qcauchy(c(-Inf,0), log=TRUE) == II)
Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) stop(paste(deparse(mc[[i +  :
  	missing value where TRUE/FALSE needed
In addition: Warning message:
NaNs produced in: qcauchy(p, location, scale, lower.tail, log.p) 
Execution halted

It was suggested to me over on the r-help list

On Tue, 27 Sep 2005, Prof Brian Ripley wrote:

> I am afraid this does look like a real problem, if a minor one. We have
for
> the first problem
>
> x <- 10^(ex <- c(1,2,5*(1:5),50,100,200,300,Inf))
> ex <- -c(rev(1/x), ex)
> qcauchy(ex, log=TRUE)
>
> The first entry of the result should be Inf and the last -Inf.  From the
> output you have shown us I would guess the last is NaN.
>
> If this is what is going on, it is a problem but a somewhat esoteric one
that
> probably reflects a lack of IEC60559 (aka IEEE754) conformance.  It 
needs
> more hands-on debugging than we can provide on a help list.


Anything I can do to help debug this?  I am not a C programmer, but I do 
have an interest in getting R running.


Jeff Ross


From joel3000 at gmail.com  Wed Sep 28 09:17:10 2005
From: joel3000 at gmail.com (Joel Bremson)
Date: Wed, 28 Sep 2005 00:17:10 -0700
Subject: [Rd] gfortran Makefile for windows
Message-ID: <1253d67a05092800173c7138b3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050928/3a4e228a/attachment.pl

From ripley at stats.ox.ac.uk  Wed Sep 28 11:43:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Sep 2005 10:43:55 +0100 (BST)
Subject: [Rd] gfortran Makefile for windows
In-Reply-To: <1253d67a05092800173c7138b3@mail.gmail.com>
References: <1253d67a05092800173c7138b3@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0509281018250.6137@gannet.stats>

I am unaware that gfortran or gcc4 exist as a MinGW binary for Windows.
You mention Cygwin, but that is not a supported platform for R.

There is a g95 binary for Windows.

You can find how to link on Windows from the sources: most of the rules 
are in src/gnuwin32/MkRules.   I suspect all you need is to set 
pkgname-DLLLIBS appropriately.


I don't see that you need a Makefile: a Makevars file would suffice and 
avoid your hardcoding so many OS-specific features.  In any case it seems 
to me that in general you need to link against the Fortran libraries: you 
may get away with it on MacOS, but you will not on Windows.

Support for F95 files is planned for R 2.3.0, but depends on being able to 
differentiate F77 and F95 sources where needed (most platforms). 
Meanwhile we will try to add an example to the R-admin manual for 2.2.0.


On Wed, 28 Sep 2005, Joel Bremson wrote:

> Hi all,
>
> (Originally posted to r-help)

Congratulations: you have now read the posting guide and selected an 
appropriate list!  Perhaps soon you will get the part about not sending 
HTML mail?

Seriously, there is a posting guide, and it asks you to do your homework 
before posting.  Please show us the courtesy of doing so.

> I'm porting a package that I've worked on for OS X to Windows.
> The package is written in F95 so I need to compile it with gfortran
> and link it with gcc4.
>
> I've been trying to build an R with gcc4 without luck so far. If there is
> a binary of such a thing info would be appreciated.
>
> This package requires a Makefile. My question is, how can I find out
> (or what is), the link command?
>
> Here is the OS X Makefile:
>
>
> RLIB_LOC=${R_HOME}
>
> F90_FILES=\
> class_data_frame.f90 \
> class_old_dbest.f90 \
> class_cm_data.f90 \
> class_cm.f90 \
> class_bgw.f90 \
> class_cm_mle.f90 \
> cme.f90
>
>
> FORTRAN_FILES=\
> dgletc.f \
> dglfgb.f\
> dglfg.f\
> dmdc.f\
> mecdf.f
>
>
> %.o: %.f90
> gfortran -c -g $<
>
> %.o: %.f
> gfortran -c -g $<
>
> bpkg.so: $(F90_FILES:%.f90=%.o) $(FORTRAN_FILES:%.f=%.o)
> gcc -Wall -bundle -flat_namespace -undefined suppress -L/sw/lib
> -L/usr/local/lib -o $@ $^ \
> -L$(RLIB_LOC)/lib -lR
>
> ###EOF####
>
> The -L lib dirs are not correct. On a *nix platform I would do something
> like this
>
> sh -x R CMD SHLIB ...
>
> to get at the R internal link information but I can't get that to work on
> Cygwin.
>
> Regards,
>
> Joel
>
> --
> Joel Bremson
> Graduate Student
> Institute for Transportation Studies - UC Davis
> http://etrans.blogspot.com
>
> 	[[alternative HTML version deleted]]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Sep 28 11:59:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Sep 2005 10:59:39 +0100 (BST)
Subject: [Rd] Future plans for raw data type?
In-Reply-To: <dhc7hi$gqj$1@sea.gmane.org>
References: <dhc7hi$gqj$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.61.0509272140280.17878@gannet.stats>

On Tue, 27 Sep 2005 dhinds at sonic.net wrote:

> I've been working with raw vectors quite a bit and was wondering if
> the R team might comment on where they see raw vector support going in
> the long run.  Is the intent that 'raw' will eventually become a first
> class data type on the same level as 'integer'?  Or should 'raw' have
> more limited support, by design?

They _are_ `first class data types', atomic vectors, just like integers. 
The intent remains that their contents should not be interpreted, just as 
in the Green Book.  One comsequential difference from other atomic vectors 
is that there is no notion of NA for raw elements.

This means that there are basically no plans to add support for 
manipulation of raw vectors.  We have already gone quite a lot further 
than S does, and quite a few things have been considered undesirable (see 
below).

> For example, with very minor changes to subassign.c to implement some
> automatic coercions, raw vectors can become arguments to ifelse() and
> can be members of data frames.  Would this be desirable?

It is desirable that they can be members of data frames, which is why they 
_can_ be:

> y <- charToRaw("test")
> z <- data.frame(y)

format() was not handling raw until recently, but now does.  Thus z can 
now be printed.  (Again, it is somewhat dubious that one should be able to 
format/print raw vectors as that imposes an interpretation, but it is 
convenient.)

ifelse() is coded in a peculiar way that needs logical to be coercible 
(for some values of 'test') to a common mode for 'yes' and 'no'. 
Alternatives are given on its help page.

Given that you cannot interpret raw elements, you cannot unambiguously 
coerce logical to raw.  In particular there is no way to coerce logical NA 
to raw.  So what should ifelse(NA, yes, no) be?  There is no good answer, 
which is why the status quo is desirable.  (as.raw warns if you attempt 
this.)

You are vague as to which `automatic coercions' you think could be added, 
but at least this one was deliberately not added.

Digging around I did find one unanticipated problem.  If z is a list z$a 
<- raw_vector works but z[["a"]] <- raw_vector does not.  The reason is 
that for atomic vectors the latter first coerces the rhs to a list and 
then extracts the first element.  Which is clearly wasteful (and not 
documented), and I will take a closer look at it for 2.3.0, but I've added 
sticking plaster for 2.2.0.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Sep 28 14:43:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Sep 2005 13:43:46 +0100 (BST)
Subject: [Rd] gfortran Makefile for windows
In-Reply-To: <Pine.LNX.4.61.0509281018250.6137@gannet.stats>
References: <1253d67a05092800173c7138b3@mail.gmail.com>
	<Pine.LNX.4.61.0509281018250.6137@gannet.stats>
Message-ID: <Pine.LNX.4.61.0509281324250.9384@gannet.stats>

On Wed, 28 Sep 2005, Prof Brian Ripley wrote:

> I am unaware that gfortran or gcc4 exist as a MinGW binary for Windows.
> You mention Cygwin, but that is not a supported platform for R.
>
> There is a g95 binary for Windows.

At www.g95.org, but I found no installation instructions relevant to 
Windows.  Some comments at the end of this message.

[...]

> Support for F95 files is planned for R 2.3.0, but depends on being able to
> differentiate F77 and F95 sources where needed (most platforms).
> Meanwhile we will try to add an example to the R-admin manual for 2.2.0.

Here is an example src/Makefile.win for a package called testf95 that uses 
F95/F90 only.

% cat testf95/src/Makefile.win

DLLNAME=testf95 # will not be needed in 2.2.0

include $(RHOME)/src/gnuwin32/MkRules

F90SOURCES=$(wildcard -f *.f90)
F95SOURCES=$(wildcard -f *.f95)
OBJS=$(F90SOURCES:.f90=.o) $(F95SOURCES:.f95=.o)

G95=c:/packages/g95/bin/g95
MINGW=c:/packages/gcc-3.4.4/

.SUFFIXES: .f90 .f95
.f90.o:
 	$(G95) -c $< -o $@
.f95.o:
 	$(G95) -c $< -o $@

## at least on my setup, G95 is not searching MinGW libs.
DLL=$(G95) -L$(MINGW)/lib

all: $(DLLNAME).dll

## Rules copied from MakeDll

RCNAME=${DLLNAME}_res
RCOBJ=$(RCNAME).o
RESFLAGS=--include-dir $(RHOME)/include
$(DLLNAME)_res.rc:
 	@PERL5LIB=$(RHOME)/share/perl perl 
$(RHOME)/src/gnuwin32/makeDllRes.pl $(DLLNAME) > $@
$(DLLNAME)_res.o: $(DLLNAME)_res.rc $(RHOME)/include/Rversion.h
$(DLLNAME).a: $(OBJS)
$(DLLNAME).dll : $(DLLNAME).a $(RCOBJ)


It works for me, but do be aware that it will depend on the
fine details of how your MinGW/G95 tools are installed.  I had to copy
dllcrt2.o from MINGW/lib to
C:/packages/g95/lib/gcc-lib/i686-pc-mingw32/4.0.1 since the paths are
processed after that file.  It is probably better to fiddle with the specs 
file.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jamatos at fc.up.pt  Wed Sep 28 16:12:42 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Wed, 28 Sep 2005 15:12:42 +0100
Subject: [Rd] looks in liblapack.a not liblapack.so
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
	<x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
Message-ID: <dhe8cr$tbm$1@sea.gmane.org>

Peter Dalgaard wrote:

> Hmm. Doesn't look like it is actually working, though. Install
> lapack-devel, configure --with-lapack, and make check dies with
> 
> running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
> make[4]: Leaving directory `/home/pd/r-devel/BUILD/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> ....
> [pd at titmouse BUILD]$ tail tests/Examples/base-Ex.Rout.fail
>> kappa(x2 <- cbind(x1,2:11))# high! [x2 is singular!]
> [1] 8.351867e+16
>>
>> hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
>> sv9 <- svd(h9 <- hilbert(9))$ d
>> kappa(h9)# pretty high!
> [1] 728289254735
>> kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
> Error in La.svd(x, nu, nv) : BLAS/LAPACK routine 'DGEBRD' gave error code
> -10 Execution halted
> 
> This happens on both x86_64 and x86 installs of FC4.

  I am sorry Peter, I am trying really hard to replicate this bug but I have
not been able to see the same result, no matter what I try.

  I have download the latest tar ball and then I run:

$ ./configure --with-lapack="-llapack -lblas"
...
R is now configured for x86_64-unknown-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc  -g -O2
  C++ compiler:              g++  -g -O2
  Fortran compiler:          gfortran  -g -O2

  Interfaces supported:      X11
  External libraries:        readline
  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes

$ make -j8
$ make check

  It works.

  OTOH I am not sure that configure is accepting my options. Looking into
config.log I don't see that value being used, and I noticed that the lapack
module it is still being built.

  I read docs/manual/R-admin.html but without any difference. I have tried
different forms:

--with-lapack
--with-lapack="-llapack -lcblas"
--with-lapack="-llapack -lblas"

  What am I missing?

> I have a strong sense of deja vu regarding this error.

  Thanks,
-- 
Jos? Ab?lio


From p.dalgaard at biostat.ku.dk  Wed Sep 28 16:53:43 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Sep 2005 16:53:43 +0200
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <dhe8cr$tbm$1@sea.gmane.org>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
	<x2mzm5lbtx.fsf@turmalin.kubism.ku.dk> <dhe8cr$tbm$1@sea.gmane.org>
Message-ID: <x2k6h1451k.fsf@viggo.kubism.ku.dk>

Jos? Matos <jamatos at fc.up.pt> writes:

> Peter Dalgaard wrote:
> 
> > Hmm. Doesn't look like it is actually working, though. Install
> > lapack-devel, configure --with-lapack, and make check dies with
> > 
> > running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
> > make[4]: Leaving directory `/home/pd/r-devel/BUILD/tests/Examples'
> > make[3]: *** [test-Examples-Base] Error 2
> > ....
> > [pd at titmouse BUILD]$ tail tests/Examples/base-Ex.Rout.fail
> >> kappa(x2 <- cbind(x1,2:11))# high! [x2 is singular!]
> > [1] 8.351867e+16
> >>
> >> hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
> >> sv9 <- svd(h9 <- hilbert(9))$ d
> >> kappa(h9)# pretty high!
> > [1] 728289254735
> >> kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
> > Error in La.svd(x, nu, nv) : BLAS/LAPACK routine 'DGEBRD' gave error code
> > -10 Execution halted
> > 
> > This happens on both x86_64 and x86 installs of FC4.
> 
>   I am sorry Peter, I am trying really hard to replicate this bug but I have
> not been able to see the same result, no matter what I try.
> 
>   I have download the latest tar ball and then I run:
> 
> $ ./configure --with-lapack="-llapack -lblas"
> ...
> R is now configured for x86_64-unknown-linux-gnu
> 
>   Source directory:          .
>   Installation directory:    /usr/local
> 
>   C compiler:                gcc  -g -O2
>   C++ compiler:              g++  -g -O2
>   Fortran compiler:          gfortran  -g -O2
> 
>   Interfaces supported:      X11
>   External libraries:        readline
>   Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>   Options enabled:           R profiling
> 
>   Recommended packages:      yes
> 
> $ make -j8
> $ make check
> 
>   It works.
> 
>   OTOH I am not sure that configure is accepting my options. Looking into
> config.log I don't see that value being used, and I noticed that the lapack
> module it is still being built.
> 
>   I read docs/manual/R-admin.html but without any difference. I have tried
> different forms:
> 
> --with-lapack
> --with-lapack="-llapack -lcblas"
> --with-lapack="-llapack -lblas"
> 
>   What am I missing?

-L/usr/lib64  I think. I have 

#LAPACK_LIBS="-L/usr/lib64 -llapack"

(commented out now) in config.site.

../R/configure --with-lapack="-L/usr/lib64 -llapack"

seems to work with FC4/Opteron (even with the configure line, you
still need to have at least "--with-lapack" on the command line, which
is a bit of a bug -- or will be one, once we stop advising against
using external lapack libs in the first place...).

A line like

External libraries:        readline, BLAS(ATLAS), LAPACK(generic)

shows that R is not using the internal versions of BLAS/LAPACK. (Of
course, the ATLAS bit required more work...)

The latest updates to lapack seem not to have worked.
 
> > I have a strong sense of deja vu regarding this error.
> 
>   Thanks,
> -- 
> Jos?? Ab??lio
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From dhinds at sonic.net  Wed Sep 28 18:27:40 2005
From: dhinds at sonic.net (David Hinds)
Date: Wed, 28 Sep 2005 09:27:40 -0700
Subject: [Rd] Future plans for raw data type?
In-Reply-To: <Pine.LNX.4.61.0509272140280.17878@gannet.stats>
References: <dhc7hi$gqj$1@sea.gmane.org>
	<Pine.LNX.4.61.0509272140280.17878@gannet.stats>
Message-ID: <20050928162740.GA26776@sonic.net>

On Wed, Sep 28, 2005 at 10:59:39AM +0100, Prof Brian Ripley wrote:
> 
> They _are_ `first class data types', atomic vectors, just like integers. 
> The intent remains that their contents should not be interpreted, just as 
> in the Green Book.  One comsequential difference from other atomic vectors 
> is that there is no notion of NA for raw elements.

That's reasonable.  I should have known to be more specific in saying
what I meant by "first class data type", but drawing the line at
interpreting the contents of a raw seems fine.

> It is desirable that they can be members of data frames, which is why they 
> _can_ be:
> 
> >y <- charToRaw("test")
> >z <- data.frame(y)

Hmmm, that's interesting; I wonder how I missed the fact that this
worked.  Somehow I managed to only try things that didn't, even though
the obvious case does work.  Here are some things that are broken:

  x <- data.frame(a=1:10)
  x$b <- as.raw(1:10)
  x[[2]] <- as.raw(1:10)
  x <- data.frame(as.raw(1:10))
  x[1,]
  x[1,1]

> Given that you cannot interpret raw elements, you cannot unambiguously 
> coerce logical to raw.  In particular there is no way to coerce logical NA 
> to raw.  So what should ifelse(NA, yes, no) be?  There is no good answer, 
> which is why the status quo is desirable.  (as.raw warns if you attempt 
> this.)
>
> You are vague as to which `automatic coercions' you think could be added, 
> but at least this one was deliberately not added.

Because of how ifelse() is implemented, for type 'X', it requires both
'X' <- logical and logical <- 'X' coercions.  The 'X' <- logical
coercion is used for handling NA elements in 'test' even if there are
none.  The logical <- 'X' coercion is required due to how ifelse()
constructs the result vector from 'yes' and 'no'.  The logical <- raw
coercion seems unambiguous.  Arguably, ifelse() should not care about
the ability to represent NA if there are no NA values in 'test', and
could do:

    if (any(nas)) ans[nas] <- NA

instead of:

    ans[nas] <- NA

I think this is a little bit more consistent with how ifelse() handles
the 'yes' and 'no' arguments, as well (they are only evaluated if they
are actually used).  But as you say, ifelse() is pretty easily to work
around.

> Digging around I did find one unanticipated problem.  If z is a list z$a 
> <- raw_vector works but z[["a"]] <- raw_vector does not.  The reason is 
> that for atomic vectors the latter first coerces the rhs to a list and 
> then extracts the first element.  Which is clearly wasteful (and not 
> documented), and I will take a closer look at it for 2.3.0, but I've added 
> sticking plaster for 2.2.0.

I think this is related to the problems I described above, and I
suspect that your fix is the same as mine (i.e. handle "case 1924" in
subassign.c).

-- Dave


From jamatos at fc.up.pt  Wed Sep 28 20:30:08 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Wed, 28 Sep 2005 19:30:08 +0100
Subject: [Rd] looks in liblapack.a not liblapack.so
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu>
	<1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat> <dgpari$a96$1@sea.gmane.org>
	<x2mzm5lbtx.fsf@turmalin.kubism.ku.dk> <dhe8cr$tbm$1@sea.gmane.org>
	<x2k6h1451k.fsf@viggo.kubism.ku.dk>
Message-ID: <dhenfh$klr$1@sea.gmane.org>

Peter Dalgaard wrote:

> -L/usr/lib64  I think. I have
> 
> #LAPACK_LIBS="-L/usr/lib64 -llapack"
> 
> (commented out now) in config.site.

  I'm sorry, it was my mistake. I forgot to install blas-devel where
libblas.so is defined as a symbolic link to the correct library version.

  Since the configure script could not find the blas library it would
immediately disallow the lapack usage. This is not obvious from configure's
output... maybe an explicit message saying this would help here.

  So now it is enough
../R/configure --with-lapack

  :-)

> ../R/configure --with-lapack="-L/usr/lib64 -llapack"
> 
> seems to work with FC4/Opteron (even with the configure line, you
> still need to have at least "--with-lapack" on the command line, which
> is a bit of a bug -- or will be one, once we stop advising against
> using external lapack libs in the first place...).
> 
> A line like
> 
> External libraries:        readline, BLAS(ATLAS), LAPACK(generic)

  Yes, I get this. For now I have BLAS(generic).

> shows that R is not using the internal versions of BLAS/LAPACK. (Of
> course, the ATLAS bit required more work...)
> 
> The latest updates to lapack seem not to have worked.

  You are right, I am able to reproduce the bug. I will report it and report
back when a solution is available.

> 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
>  35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> 35327907
> 

  Thanks,
-- 
Jos? Ab?lio


From tcallawa at redhat.com  Thu Sep 29 01:25:34 2005
From: tcallawa at redhat.com (Tom 'spot' Callaway)
Date: Wed, 28 Sep 2005 18:25:34 -0500
Subject: [Rd] looks in liblapack.a not liblapack.so
In-Reply-To: <Pine.LNX.4.61.0509221034170.15750@gannet.stats>
References: <mailman.9.1126951201.11292.r-devel@r-project.org>
	<20050917221902.GA10806@stat.umn.edu> <1127119440.3624.5.camel@seurat>
	<x23bo15c13.fsf@turmalin.kubism.ku.dk>
	<1127144443.18426.14.camel@seurat>
	<dgpari$a96$1@sea.gmane.org> <x2mzm5lbtx.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.61.0509221034170.15750@gannet.stats>
Message-ID: <1127949934.5391.6.camel@localhost.localdomain>

On Thu, 2005-09-22 at 10:36 +0100, Prof Brian Ripley wrote:

> Probably because it is discussed in the R-admin manual as having 
> previously appeared in Debian and being traced to an erroneous patch to 
> the Lapack 3.0 sources.

You wouldn't happen to have more specific details on this, would you? :)

I know there is a fair amount of cruft in the Fedora lapack package, and
I'd like to clean it out, but I want to make sure I don't remove any
legitimate bug-fixes in the process.

(See: https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=169399 for
some semi-related discussion of lapack and its patching)

Thanks,

~spot
-- 
Tom "spot" Callaway: Red Hat Senior Sales Engineer || GPG ID: 93054260
Fedora Extras Steering Committee Member (RPM Standards and Practices)
Aurora Linux Project Leader: http://auroralinux.org
Lemurs, llamas, and sparcs, oh my!


From feferraz at ime.usp.br  Thu Sep 29 05:50:16 2005
From: feferraz at ime.usp.br (Fernando Henrique Ferraz P. da Rosa)
Date: Thu, 29 Sep 2005 00:50:16 -0300
Subject: [Rd] Summary of translation status
Message-ID: <20050929035016.GA16165@ime.usp.br>

        Dear R-devel & Translation Teams,

        In order to monitor the progress of the translation for the
pt_BR team I wrote a script to summarize the status of the translations.
It wasn't difficult to extend it to the other languages so I decided to
set up a page with the summaries of the translation for all languages
for which currently exist a translation. 

        http://www.ime.usp.br/~feferraz/en/rtransstat.html

        If any of you find it useful I can keep it updated on a regular basis
(daily or weekly). 

        
        Thank you,


(PS: I'm resending this message because it didn't get through the
filter the first time. Sorry for the inconvenience for those that
are receiving it more than one time).

--
Fernando Henrique Ferraz P. da Rosa
http://www.feferraz.net


From ggrothendieck at gmail.com  Thu Sep 29 06:11:20 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 29 Sep 2005 00:11:20 -0400
Subject: [Rd] Summary of translation status
In-Reply-To: <20050929035016.GA16165@ime.usp.br>
References: <20050929035016.GA16165@ime.usp.br>
Message-ID: <971536df05092821114056be8e@mail.gmail.com>

Could you enlarge this to include translations of the help files
and documentation too so there is a single location that one
can refer to?  If this is already tracked somewhere else then
just a link at the top would be enough.

On 9/28/05, Fernando Henrique Ferraz P. da Rosa <feferraz at ime.usp.br> wrote:
>        Dear R-devel & Translation Teams,
>
>        In order to monitor the progress of the translation for the
> pt_BR team I wrote a script to summarize the status of the translations.
> It wasn't difficult to extend it to the other languages so I decided to
> set up a page with the summaries of the translation for all languages
> for which currently exist a translation.
>
>        http://www.ime.usp.br/~feferraz/en/rtransstat.html
>
>        If any of you find it useful I can keep it updated on a regular basis
> (daily or weekly).
>
>
>        Thank you,
>
>
> (PS: I'm resending this message because it didn't get through the
> filter the first time. Sorry for the inconvenience for those that
> are receiving it more than one time).
>
> --
> Fernando Henrique Ferraz P. da Rosa
> http://www.feferraz.net
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From feferraz at ime.usp.br  Thu Sep 29 06:48:53 2005
From: feferraz at ime.usp.br (Fernando Henrique Ferraz P. da Rosa)
Date: Thu, 29 Sep 2005 01:48:53 -0300
Subject: [Rd] Summary of translation status
In-Reply-To: <971536df05092821114056be8e@mail.gmail.com>
References: <20050929035016.GA16165@ime.usp.br>
	<971536df05092821114056be8e@mail.gmail.com>
Message-ID: <20050929044853.GA17161@ime.usp.br>

Gabor Grothendieck writes:
> Could you enlarge this to include translations of the help files
> and documentation too so there is a single location that one
> can refer to?  If this is already tracked somewhere else then
> just a link at the top would be enough.
> 

        As far as I know this kind of information is not centralized, as
today there exists no standard procedure for providing translated
versions of the help files and documentation (as exists for the message
files, at least).

        We have the contributed documentation page:
http://cran.r-project.org/other-docs.html , where links can be found to
(some of the) translated documentation available.

         As far as the help files go I never read or heard anything about.
 Is there any effort going on to translate them?

        The idea to have a single location to refer to when it comes to
the translation efforts sounds good though. We just have to consider a
way to centralize information on the translation of documentation and
help files.

       

--
Fernando Henrique Ferraz P. da Rosa
http://www.feferraz.net


From blindglobe at gmail.com  Thu Sep 29 09:16:52 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu, 29 Sep 2005 09:16:52 +0200
Subject: [Rd] Does the "installWithVers=TRUE" setting for the
	install.packages/update.packages flag updates?
Message-ID: <1abe3fa90509290016d8cc371@mail.gmail.com>

It might be my settings or improper use -- but if I use the
"installWithVers=TRUE" flag for update.packages(), I don't seem to get
updates;
and if I use "install.packages(new.packages(),installWithVers=TRUE)",
it seems to (re-)install identical versions of what I have.

(this is with Rdevel from subversion from yesterday)

best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).


From feferraz at ime.usp.br  Wed Sep 28 22:12:22 2005
From: feferraz at ime.usp.br (Fernando Henrique Ferraz P. da Rosa)
Date: Wed, 28 Sep 2005 17:12:22 -0300
Subject: [Rd] Summary of translation status
Message-ID: <20050928201222.GA1722@ime.usp.br>

        Dear R-devel & Translation Teams,

        In order to monitor the progress of the translation for the
pt_BR team I wrote a script to summarize the status of the translations.
It wasn't difficult to extend it to the other languages so I decided to
set up a page with the summaries of the translation for all languages
for which currently exist a translation. 

        http://www.ime.usp.br/~feferraz/en/rtransstat.html

        If any of you find it useful I can keep it updated on a regular basis
(daily or weekly). 

        
        Thank you,

--
Fernando Henrique Ferraz P. da Rosa
http://www.feferraz.net


From phgrosjean at sciviews.org  Wed Sep 28 22:44:32 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 28 Sep 2005 22:44:32 +0200
Subject: [Rd] Summary of translation status
In-Reply-To: <20050928201222.GA1722@ime.usp.br>
References: <20050928201222.GA1722@ime.usp.br>
Message-ID: <433B00B0.70104@sciviews.org>

Hell Fernando Henrique,

Many thanks for this... very nice picture of the translation process of R.
Best,

Philippe

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Fernando Henrique Ferraz P. da Rosa wrote:
>         Dear R-devel & Translation Teams,
> 
>         In order to monitor the progress of the translation for the
> pt_BR team I wrote a script to summarize the status of the translations.
> It wasn't difficult to extend it to the other languages so I decided to
> set up a page with the summaries of the translation for all languages
> for which currently exist a translation. 
> 
>         http://www.ime.usp.br/~feferraz/en/rtransstat.html
> 
>         If any of you find it useful I can keep it updated on a regular basis
> (daily or weekly). 
> 
>         
>         Thank you,
> 
> --
> Fernando Henrique Ferraz P. da Rosa
> http://www.feferraz.net
> 
> 
>


From maechler at stat.math.ethz.ch  Thu Sep 29 12:08:05 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Sep 2005 12:08:05 +0200
Subject: [Rd] simulate in stats
In-Reply-To: <43299C54.1080100@bank-banque-canada.ca>
References: <43287DD5.4080104@bank-banque-canada.ca>
	<43299C54.1080100@bank-banque-canada.ca>
Message-ID: <17211.48389.817189.650413@stat.math.ethz.ch>

>>>>> "PaulG" == Paul Gilbert <pgilbert at bank-banque-canada.ca>
>>>>>     on Thu, 15 Sep 2005 12:07:48 -0400 writes:

    PaulG> BTW, I think there is a problem with the way the
    PaulG> argument "seed" is used in the new simulate in stats.
    PaulG> The problem is that repeated calls to simulate using
    PaulG> the default argument will introduce a new pattern
    PaulG> into the RNG:

    >> stats:::simulate
    PaulG> function (object, nsim = 1, seed = as.integer(runif(1, 0, 
    PaulG> .Machine$integer.max)),   ...)
    PaulG> UseMethod("simulate")
    PaulG> <environment: namespace:stats>


    >> stats:::simulate.lm
    PaulG> function (object, nsim = 1, seed = as.integer(runif(1, 0, 
    PaulG> .Machine$integer.max)),    ...)
    PaulG> {
    PaulG> if (!exists(".Random.seed", envir = .GlobalEnv))
    PaulG> runif(1)
    PaulG> RNGstate <- .Random.seed
    PaulG> set.seed(seed)
    PaulG> ...

    PaulG> This should not be done, as the resulting RNG has not
    PaulG> been studied or proven. A better mechanism is to have
    PaulG> a default argument equal NULL, and not touch the seed
    PaulG> in that case.

I agree so far.  I think the default seed should really be NULL
(with your semantic!) rather than a random number.


    PaulG>  There are several examples of this in
    PaulG> the package dse1 (in bundle dse), see for example
    PaulG> simulate.ARMA and simulate.SS. They also use the
    PaulG> utilities in the setRNG package to save more of the
    PaulG> information necessary to reproduce
    PaulG> simulations. Roughly it is done like this:
 
    PaulG> simulate.x <- function (model, rng = NULL,  ...)
    PaulG>   {if (is.null(rng)) rng <- setRNG() 
    PaulG>     ## returns the RNG setting to be  saved with the result
    PaulG>   else {
    PaulG>     old.rng <- setRNG(rng)
    PaulG>     on.exit(setRNG(old.rng))
    PaulG>   }
    PaulG> ...

as nobody has further delved into this in the mean time,
this is definitely too late for R 2.2.0, even if it was desired.

But I also think you should be able to live with interpreting
'seed' as 'rng' if you want, shouldn't you?

    PaulG> The seed by itself is not very useful if the purpose
    PaulG> is to be able to reproduce things, and I think it
    PaulG> would be a good idea to incorporate the few small
    PaulG> functions setRNG into stats (especially if the
    PaulG> simulate mechanism is being introduced).

maybe we should reopen this topic {adopting ideas or even exact
implementations from your 'setRNG' into stats} in a few weeks,
when R 2.2.0 is released.

    PaulG> The argument "nsim" presumably alleviates to some
    PaulG> extent the above concern about changing the RNG
    PaulG> pattern. However, in my fairly extensive experience
    PaulG> it is not very workable to produce all the
    PaulG> simulations and then do the analysis of them. 
    PaulG> In a Monte Carlo experiment the generated data set is just
    PaulG> too big.

I believe this depends very much on the topic.  The simulate()
uses that we had envisaged with simulate() don't save all the
models and then analyze them.  
But maybe I'm misunderstanding your point completely here.

    PaulG>  A better approach is to do the analysis and save
    PaulG> only necessary information after each
    PaulG> simulation. That is the approach, for example, in
    PaulG> dse2:::EstEval.

    PaulG> Paul

    PaulG> Paul Gilbert wrote:

    >> Can the arguments nsim and seed be passed as part of ... in the new 
    >> simulate generic in R-2.2.0alpha package stats?

    >> This would potentially allow me to use the stats generic rather than 
    >> the one I define in dse. There are contexts where nsim and seed do not 
    >> make sense.

Well, the current specification for simulate() has been different
explicitly.

I agree that there are situations where both 'nsim' and 'seed'
(or a generalization, say 'RNGstate') wouldn't make sense and
one still would like to use something like "simulate" in the
function name. 

    >> I realize that the default arguments could be ignored, but 
    >> it does not really make sense to introduce a new generic with that in 
    >> mind. 

I think it would depend on the exaxt context if I would rather
use a (slightly) different function name, or just ignore the
ignorable arguments as you mention.


    >> (I would also prefer that the "object" argument was called 
    >>  "model" but this is less important.)

I'd personally agree with that;  the argument was that
'object' is very generally used in such situations.

Martin Maechler


From sfalcon at fhcrc.org  Thu Sep 29 16:40:30 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 29 Sep 2005 07:40:30 -0700
Subject: [Rd] Does the "installWithVers=TRUE" setting for the
	install.packages/update.packages flag updates?
In-Reply-To: <1abe3fa90509290016d8cc371@mail.gmail.com> (A. J. Rossini's
	message of "Thu, 29 Sep 2005 09:16:52 +0200")
References: <1abe3fa90509290016d8cc371@mail.gmail.com>
Message-ID: <m2achwey3l.fsf@macaroni.local>

On 29 Sep 2005, blindglobe at gmail.com wrote:

> It might be my settings or improper use -- but if I use the
> "installWithVers=TRUE" flag for update.packages(), I don't seem to
> get updates; and if I use
> "install.packages(new.packages(),installWithVers=TRUE)", it seems to
> (re-)install identical versions of what I have.
>
> (this is with Rdevel from subversion from yesterday)

For the install.packages part, I'm pretty certain that
install.packages is never smart enough not to reinstall already
installed packages at the same version.  That could be a bandwidth
saving enhacement :-)

No experience with the installWithVers arg. 

Best,

+ seth


From blindglobe at gmail.com  Fri Sep 30 10:51:04 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Fri, 30 Sep 2005 10:51:04 +0200
Subject: [Rd] Option "installWithVers" seems to impact new.packages() badly?
Message-ID: <1abe3fa90509300151i641e4408y9e74f728fe681785@mail.gmail.com>

In Rdevel, SVN version built this morning around 10am central european
time, it looks like

   install.packages(new.packages(),installWithVers=TRUE)

seem to ignore the version information -- that is, it reinstalls
current versions of packages.

This did not happen before I used "installWithVers=TRUE" option, that is
I could use

   update.packages()
 and
   install.packages(new.packages())

to keep a current, platform-complete, installed base of CRAN.

best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).


From Richard.Mott at well.ox.ac.uk  Fri Sep 30 11:33:35 2005
From: Richard.Mott at well.ox.ac.uk (Richard.Mott@well.ox.ac.uk)
Date: Fri, 30 Sep 2005 11:33:35 +0200 (CEST)
Subject: [Rd] bug in gsub with perl=TRUE (PR#8164)
Message-ID: <20050930093335.B84DA1C915@slim.kubism.ku.dk>

Full_Name: Richard Mott
Version: 2.0.1
OS: Linux toad 2.6.9 #4 SMP Mon Feb 21 16:20:16 GMT 2005 x86_64 AMD Opteron(tm) Processor 848 AuthenticAMD GNU/Linux
Submission from: (NULL) (129.67.46.247)


gsub with perl=TRUE does not work properly. It pads/truncates the resulting
string to
the length of the input string: 

my.formula <- "log10(Biochem.ALP)^2+1 ~ Family + GENDER"

> gsub("^.+~", "transformed.y ~", my.formula )
[1] "transformed.y ~ Family + GENDER"

> gsub("^.+~", "transformed.y ~", my.formula, perl=TRUE )
[1] "transformed.y ~ Family + GENDER\0\006\0\0\r\377\0\0\0"  # padded

 my.formula <- "Biochem.ALP ~ Family + GENDER"
> gsub("^.+~", "transformed.y ~", my.formula, perl=TRUE )
[1] "transformed.y ~ Family + GEND"  # truncated
> gsub("^.+~", "transformed.y ~", my.formula )
[1] "transformed.y ~ Family + GENDER"


From ligges at statistik.uni-dortmund.de  Fri Sep 30 13:51:58 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Sep 2005 13:51:58 +0200
Subject: [Rd] bug in gsub with perl=TRUE (PR#8164)
In-Reply-To: <20050930093335.B84DA1C915@slim.kubism.ku.dk>
References: <20050930093335.B84DA1C915@slim.kubism.ku.dk>
Message-ID: <433D26DE.5060203@statistik.uni-dortmund.de>

Richard.Mott at well.ox.ac.uk wrote:

> Full_Name: Richard Mott
> Version: 2.0.1

This version is completely outdated.
Please try with a *recent* version of R when reporting bugs, in this 
case R-2.2.0 beta (or in worst case R-2.1.1, the current release).

The bug reported below has been fixed some months ago ...

Uwe Ligges

> OS: Linux toad 2.6.9 #4 SMP Mon Feb 21 16:20:16 GMT 2005 x86_64 AMD Opteron(tm) Processor 848 AuthenticAMD GNU/Linux
> Submission from: (NULL) (129.67.46.247)
> 
> 
> gsub with perl=TRUE does not work properly. It pads/truncates the resulting
> string to
> the length of the input string: 
> 
> my.formula <- "log10(Biochem.ALP)^2+1 ~ Family + GENDER"
> 
> 
>>gsub("^.+~", "transformed.y ~", my.formula )
> 
> [1] "transformed.y ~ Family + GENDER"
> 
> 
>>gsub("^.+~", "transformed.y ~", my.formula, perl=TRUE )
> 
> [1] "transformed.y ~ Family + GENDER\0\006\0\0\r\377\0\0\0"  # padded
> 
>  my.formula <- "Biochem.ALP ~ Family + GENDER"
> 
>>gsub("^.+~", "transformed.y ~", my.formula, perl=TRUE )
> 
> [1] "transformed.y ~ Family + GEND"  # truncated
> 
>>gsub("^.+~", "transformed.y ~", my.formula )
> 
> [1] "transformed.y ~ Family + GENDER"
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From oehl_list at gmx.de  Fri Sep 30 15:12:40 2005
From: oehl_list at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Fri, 30 Sep 2005 15:12:40 +0200 (MEST)
Subject: [Rd] Subscripting fails if name of element is "" (PR#8161)
Message-ID: <14134.1128085960@www76.gmx.net>

Dear all,

I resend this mail because it was blocked: I submitted a bug from the r-bug
webpage and hypatia seems to block mail that is send from a different IP
than that usually associated with the email. Looks like it is currently
impossible to correctly submit bugs from the website. However, here is the
original bug report:

(PR#8161)

Dear all,

The following shows cases where accessing elements via their name fails (if
the
name is a string of length zero). 

Best regards


Jens Oehlschl?gel


> p <- 1:3
> names(p) <- c("a","", as.character(NA))
> p
   a      <NA> 
   1    2    3 
> 
> for (i in names(p))
+ print(p[[i]])
[1] 1
[1] 2
[1] 3
> 
> # error 1: vector subsripting with "" fails in second element
> for (i in names(p))
+ print(p[i])
a 
1 
<NA> 
  NA 
<NA> 
   3 
> 
> # error 2: print method for list shows no name for second element
> p <- as.list(p)
> 
> 
> for (i in names(p))
+ print(p[[i]])
[1] 1
[1] 2
[1] 3
> 
> # error 3: list subsripting with "" fails in second element
> for (i in names(p))
+ print(p[i])
$a
[1] 1

$"NA"
NULL

$"NA"
[1] 3

> 
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    1.1            
year     2005           
month    06             
day      20             
language R




# -- replication code ----------------------------------

p <- 1:3
names(p) <- c("a","", as.character(NA))
p

for (i in names(p))
		 print(p[[i]])
		 
# error 1: vector subsripting with "" fails in second element
for (i in names(p))
		 print(p[i])

# error 2: print method for list shows no name for second element
p <- as.list(p)


for (i in names(p))
		 print(p[[i]])
		 
# error 3: list subsripting with "" fails in second element
for (i in names(p))
		 print(p[i])




--


From murdoch at stats.uwo.ca  Fri Sep 30 16:03:46 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 30 Sep 2005 10:03:46 -0400
Subject: [Rd] Summary of translation status
In-Reply-To: <20050929035016.GA16165@ime.usp.br>
References: <20050929035016.GA16165@ime.usp.br>
Message-ID: <433D45C2.9070508@stats.uwo.ca>

On 9/28/2005 11:50 PM, Fernando Henrique Ferraz P. da Rosa wrote:
>         Dear R-devel & Translation Teams,
> 
>         In order to monitor the progress of the translation for the
> pt_BR team I wrote a script to summarize the status of the translations.
> It wasn't difficult to extend it to the other languages so I decided to
> set up a page with the summaries of the translation for all languages
> for which currently exist a translation. 
> 
>         http://www.ime.usp.br/~feferraz/en/rtransstat.html
> 
>         If any of you find it useful I can keep it updated on a regular basis
> (daily or weekly). 
> 
>         
>         Thank you,
> 
> 
> (PS: I'm resending this message because it didn't get through the
> filter the first time. Sorry for the inconvenience for those that
> are receiving it more than one time).

Hi Fernando.  That's a nice page.  I'd add an explicit statement about 
which branch the statistics apply to.  You say "Statistics based on SVN: 
35706", presumably on the trunk, but soon interest will shift to the 
R-2-2-patches branch.  (If this is automated and you have the disk space 
for both, perhaps both trunk and the current patch branch could be 
listed, but I expect the statistics will be very similar.)

Duncan Murdoch


From tlumley at u.washington.edu  Fri Sep 30 17:47:20 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 30 Sep 2005 08:47:20 -0700 (PDT)
Subject: [Rd] Subscripting fails if name of element is "" (PR#8161)
In-Reply-To: <14134.1128085960@www76.gmx.net>
References: <14134.1128085960@www76.gmx.net>
Message-ID: <Pine.LNX.4.63a.0509300844400.29284@homer23.u.washington.edu>

On Fri, 30 Sep 2005, "Jens Oehlschl?gel" wrote:
> Dear all,
>
> The following shows cases where accessing elements via their name fails (if
> the
> name is a string of length zero).


This looks deliberate (there is a function NonNullStringMatch that does 
the matching).  I assume this is because there is no other way to 
indicate that an element has no name.

If so, it is a documentation bug -- help(names) and FAQ 7.14 should 
specify this behaviour.  Too late for 2.2.0, unfortunately.

 	-thomas




>
> Best regards
>
>
> Jens Oehlschl?gel
>
>
>> p <- 1:3
>> names(p) <- c("a","", as.character(NA))
>> p
>   a      <NA>
>   1    2    3
>>
>> for (i in names(p))
> + print(p[[i]])
> [1] 1
> [1] 2
> [1] 3
>>
>> # error 1: vector subsripting with "" fails in second element
>> for (i in names(p))
> + print(p[i])
> a
> 1
> <NA>
>  NA
> <NA>
>   3
>>
>> # error 2: print method for list shows no name for second element
>> p <- as.list(p)
>>
>>
>> for (i in names(p))
> + print(p[[i]])
> [1] 1
> [1] 2
> [1] 3
>>
>> # error 3: list subsripting with "" fails in second element
>> for (i in names(p))
> + print(p[i])
> $a
> [1] 1
>
> $"NA"
> NULL
>
> $"NA"
> [1] 3
>
>>
>> version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
>
>
>
>
> # -- replication code ----------------------------------
>
> p <- 1:3
> names(p) <- c("a","", as.character(NA))
> p
>
> for (i in names(p))
> 		 print(p[[i]])
>
> # error 1: vector subsripting with "" fails in second element
> for (i in names(p))
> 		 print(p[i])
>
> # error 2: print method for list shows no name for second element
> p <- as.list(p)
>
>
> for (i in names(p))
> 		 print(p[[i]])
>
> # error 3: list subsripting with "" fails in second element
> for (i in names(p))
> 		 print(p[i])
>
>
>
>
> --
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From vkwyau at gmail.com  Fri Sep 30 19:16:11 2005
From: vkwyau at gmail.com (Vincent Yau)
Date: Fri, 30 Sep 2005 10:16:11 -0700
Subject: [Rd] Compiling R on OpenSolaris
Message-ID: <f20482fc0509301016s17caa6dbvd83dad5efda1f58a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050930/eaa98ff1/attachment.pl

From murdoch at stats.uwo.ca  Fri Sep 30 19:22:21 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 30 Sep 2005 13:22:21 -0400
Subject: [Rd] by() processing on a dataframe
Message-ID: <433D744D.3030603@stats.uwo.ca>

I want to calculate a statistic on a number of subgroups of a dataframe, 
then put the results into a dataframe.  (What SAS PROC MEANS does, I 
think, though it's been years since I used it.)

This is possible using by(), but it seems cumbersome and fragile.  Is 
there a more straightforward way than this?

Here's a simple example showing my current strategy:

 > dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4, 
c(2,2,2,2)), value = rnorm(8))
 > dataset
   gp1 gp2      value
1   1   1  0.9493232
2   1   1 -0.0474712
3   1   2 -0.6808021
4   1   2  1.9894999
5   2   3  2.0154786
6   2   3  0.4333056
7   2   4 -0.4746228
8   2   4  0.6017522
 >
 > handleonegroup <- function(subset) data.frame(gp1 = subset$gp1[1],
+ gp2 = subset$gp2[1], statistic = mean(subset$value))
 >
 > bylist <- by(dataset, list(dataset$gp1, dataset$gp2), handleonegroup)
 >
 > result <- do.call('rbind', bylist)
 > result
    gp1 gp2  statistic
1    1   1 0.45092598
11   1   2 0.65434890
12   2   3 1.22439210
13   2   4 0.06356469

tapply() is inappropriate because I don't have all possible combinations 
of gp1 and gp2 values, only some of them:

 > tapply(dataset$value, list(dataset$gp1, dataset$gp2), mean)
          1         2        3          4
1 0.450926 0.6543489       NA         NA
2       NA        NA 1.224392 0.06356469



In the real case, I only have a very sparse subset of all the 
combinations, and tapply() and by() both die for lack of memory.

Any suggestions on how to do what I want, without using SAS?

Duncan Murdoch


From h.wickham at gmail.com  Fri Sep 30 19:41:04 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 30 Sep 2005 12:41:04 -0500
Subject: [Rd] by() processing on a dataframe
In-Reply-To: <433D744D.3030603@stats.uwo.ca>
References: <433D744D.3030603@stats.uwo.ca>
Message-ID: <f8e6ff050509301041g772977f0w8b624170394ff81b@mail.gmail.com>

I'm not entirely sure what you want, but maybe this does the trick?

data.frame.by <- function(data, variables, fun, ...) {
	if (length(variables) == 0 ) {
		df <- data.frame(results = 0)
		df$results <- list(fun(data$value, ...))
		return(df)
	}

	sorted <- sort.df(data, variables)[,c(variables), drop=FALSE]
	duplicates <- duplicated(sorted[,variables, drop=FALSE])
	index <- cumsum(!duplicates)

	results <- by(data, index, fun, ...)

	cols <- sorted[!duplicates,variables, drop=FALSE]
	cols$results <- array(results)
	cols
}


sort.df <- function(data, vars) {
	data[do.call("order", data[,vars, drop=FALSE]), ,drop=FALSE]
}


dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4,
c(2,2,2,2)), value = rnorm(8))

data.frame.by(dataset, c("gp1", "gp2"), function(data) mean(data$value))
data.frame.by(dataset, "gp1", function(data) tapply(data$value, data$gp2, mean))
data.frame.by(dataset, "gp1", function(data) lm(gp2 ~ value, data)) #
doesn't print, but everything is there ok

(note that the results column will be a list if necessary - this may
be a serious abuse of data frames, but I'm not sure and no one replied
when I queried the list)

Hadley


From p.dalgaard at biostat.ku.dk  Fri Sep 30 19:41:52 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Sep 2005 19:41:52 +0200
Subject: [Rd] by() processing on a dataframe
In-Reply-To: <433D744D.3030603@stats.uwo.ca>
References: <433D744D.3030603@stats.uwo.ca>
Message-ID: <x23bnmjvvj.fsf@turmalin.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> I want to calculate a statistic on a number of subgroups of a dataframe, 
> then put the results into a dataframe.  (What SAS PROC MEANS does, I 
> think, though it's been years since I used it.)
> 
> This is possible using by(), but it seems cumbersome and fragile.  Is 
> there a more straightforward way than this?
> 
> Here's a simple example showing my current strategy:
> 
>  > dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4, 
> c(2,2,2,2)), value = rnorm(8))
>  > dataset
>    gp1 gp2      value
> 1   1   1  0.9493232
> 2   1   1 -0.0474712
> 3   1   2 -0.6808021
> 4   1   2  1.9894999
> 5   2   3  2.0154786
> 6   2   3  0.4333056
> 7   2   4 -0.4746228
> 8   2   4  0.6017522
>  >
>  > handleonegroup <- function(subset) data.frame(gp1 = subset$gp1[1],
> + gp2 = subset$gp2[1], statistic = mean(subset$value))
>  >
>  > bylist <- by(dataset, list(dataset$gp1, dataset$gp2), handleonegroup)
>  >
>  > result <- do.call('rbind', bylist)
>  > result
>     gp1 gp2  statistic
> 1    1   1 0.45092598
> 11   1   2 0.65434890
> 12   2   3 1.22439210
> 13   2   4 0.06356469
> 
> tapply() is inappropriate because I don't have all possible combinations 
> of gp1 and gp2 values, only some of them:
> 
>  > tapply(dataset$value, list(dataset$gp1, dataset$gp2), mean)
>           1         2        3          4
> 1 0.450926 0.6543489       NA         NA
> 2       NA        NA 1.224392 0.06356469
> 
> 
> 
> In the real case, I only have a very sparse subset of all the 
> combinations, and tapply() and by() both die for lack of memory.
> 
> Any suggestions on how to do what I want, without using SAS?

Have you tried aggregate()?

Alternatively, you migth split on interaction(...., drop=TRUE)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ggrothendieck at gmail.com  Fri Sep 30 19:45:58 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Sep 2005 13:45:58 -0400
Subject: [Rd] by() processing on a dataframe
In-Reply-To: <433D744D.3030603@stats.uwo.ca>
References: <433D744D.3030603@stats.uwo.ca>
Message-ID: <971536df0509301045t31328ba6tff2685e811c5a6fb@mail.gmail.com>

Check out summaryBy in the doBy package at:

   http://genetics.agrsci.dk/~sorenh/misc

e.g.

   summaryBy(value ~ gp1 + gp2, data = dataset)



On 9/30/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I want to calculate a statistic on a number of subgroups of a dataframe,
> then put the results into a dataframe.  (What SAS PROC MEANS does, I
> think, though it's been years since I used it.)
>
> This is possible using by(), but it seems cumbersome and fragile.  Is
> there a more straightforward way than this?
>
> Here's a simple example showing my current strategy:
>
>  > dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4,
> c(2,2,2,2)), value = rnorm(8))
>  > dataset
>   gp1 gp2      value
> 1   1   1  0.9493232
> 2   1   1 -0.0474712
> 3   1   2 -0.6808021
> 4   1   2  1.9894999
> 5   2   3  2.0154786
> 6   2   3  0.4333056
> 7   2   4 -0.4746228
> 8   2   4  0.6017522
>  >
>  > handleonegroup <- function(subset) data.frame(gp1 = subset$gp1[1],
> + gp2 = subset$gp2[1], statistic = mean(subset$value))
>  >
>  > bylist <- by(dataset, list(dataset$gp1, dataset$gp2), handleonegroup)
>  >
>  > result <- do.call('rbind', bylist)
>  > result
>    gp1 gp2  statistic
> 1    1   1 0.45092598
> 11   1   2 0.65434890
> 12   2   3 1.22439210
> 13   2   4 0.06356469
>
> tapply() is inappropriate because I don't have all possible combinations
> of gp1 and gp2 values, only some of them:
>
>  > tapply(dataset$value, list(dataset$gp1, dataset$gp2), mean)
>          1         2        3          4
> 1 0.450926 0.6543489       NA         NA
> 2       NA        NA 1.224392 0.06356469
>
>
>
> In the real case, I only have a very sparse subset of all the
> combinations, and tapply() and by() both die for lack of memory.
>
> Any suggestions on how to do what I want, without using SAS?
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mschwartz at mn.rr.com  Fri Sep 30 19:48:07 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 30 Sep 2005 12:48:07 -0500
Subject: [Rd] by() processing on a dataframe
In-Reply-To: <433D744D.3030603@stats.uwo.ca>
References: <433D744D.3030603@stats.uwo.ca>
Message-ID: <1128102487.4202.13.camel@localhost.localdomain>

On Fri, 2005-09-30 at 13:22 -0400, Duncan Murdoch wrote:
> I want to calculate a statistic on a number of subgroups of a dataframe, 
> then put the results into a dataframe.  (What SAS PROC MEANS does, I 
> think, though it's been years since I used it.)
> 
> This is possible using by(), but it seems cumbersome and fragile.  Is 
> there a more straightforward way than this?
> 
> Here's a simple example showing my current strategy:
> 
>  > dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4, 
> c(2,2,2,2)), value = rnorm(8))
>  > dataset
>    gp1 gp2      value
> 1   1   1  0.9493232
> 2   1   1 -0.0474712
> 3   1   2 -0.6808021
> 4   1   2  1.9894999
> 5   2   3  2.0154786
> 6   2   3  0.4333056
> 7   2   4 -0.4746228
> 8   2   4  0.6017522
>  >
>  > handleonegroup <- function(subset) data.frame(gp1 = subset$gp1[1],
> + gp2 = subset$gp2[1], statistic = mean(subset$value))
>  >
>  > bylist <- by(dataset, list(dataset$gp1, dataset$gp2), handleonegroup)
>  >
>  > result <- do.call('rbind', bylist)
>  > result
>     gp1 gp2  statistic
> 1    1   1 0.45092598
> 11   1   2 0.65434890
> 12   2   3 1.22439210
> 13   2   4 0.06356469
> 
> tapply() is inappropriate because I don't have all possible combinations 
> of gp1 and gp2 values, only some of them:
> 
>  > tapply(dataset$value, list(dataset$gp1, dataset$gp2), mean)
>           1         2        3          4
> 1 0.450926 0.6543489       NA         NA
> 2       NA        NA 1.224392 0.06356469
> 
> 
> 
> In the real case, I only have a very sparse subset of all the 
> combinations, and tapply() and by() both die for lack of memory.
> 
> Any suggestions on how to do what I want, without using SAS?
> 
> Duncan Murdoch

Duncan,

Does this do what you want?

> set.seed(1)
 
> df <- data.frame(gp1 = rep(1:2, c(4,4)), 
                   gp2 = rep(1:4, c(2,2,2,2)), 
                   value = rnorm(8))
 
> df
  gp1 gp2      value
1   1   1 -0.6264538
2   1   1  0.1836433
3   1   2 -0.8356286
4   1   2  1.5952808
5   2   3  0.3295078
6   2   3 -0.8204684
7   2   4  0.4874291
8   2   4  0.7383247

> means <- aggregate(df$value, list(gp1 = df$gp1, gp2 = df$gp2), mean)
 
> means
  gp1 gp2          x
1   1   1 -0.2214052
2   1   2  0.3798261
3   2   3 -0.2454803
4   2   4  0.6128769


> merge(df, means, by = c("gp1", "gp2"))
  gp1 gp2      value          x
1   1   1 -0.6264538 -0.2214052
2   1   1  0.1836433 -0.2214052
3   1   2 -0.8356286  0.3798261
4   1   2  1.5952808  0.3798261
5   2   3  0.3295078 -0.2454803
6   2   3 -0.8204684 -0.2454803
7   2   4  0.4874291  0.6128769
8   2   4  0.7383247  0.6128769


HTH,

Marc Schwartz


From murdoch at stats.uwo.ca  Fri Sep 30 20:35:38 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 30 Sep 2005 14:35:38 -0400
Subject: [Rd] by() processing on a dataframe
In-Reply-To: <x23bnmjvvj.fsf@turmalin.kubism.ku.dk>
References: <433D744D.3030603@stats.uwo.ca>
	<x23bnmjvvj.fsf@turmalin.kubism.ku.dk>
Message-ID: <433D857A.9030805@stats.uwo.ca>

On 9/30/2005 1:41 PM, Peter Dalgaard wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> 
>> I want to calculate a statistic on a number of subgroups of a dataframe, 
>> then put the results into a dataframe.  (What SAS PROC MEANS does, I 
>> think, though it's been years since I used it.)
>> 
>> This is possible using by(), but it seems cumbersome and fragile.  Is 
>> there a more straightforward way than this?
>> 
>> Here's a simple example showing my current strategy:
>> 
>>  > dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4, 
>> c(2,2,2,2)), value = rnorm(8))
>>  > dataset
>>    gp1 gp2      value
>> 1   1   1  0.9493232
>> 2   1   1 -0.0474712
>> 3   1   2 -0.6808021
>> 4   1   2  1.9894999
>> 5   2   3  2.0154786
>> 6   2   3  0.4333056
>> 7   2   4 -0.4746228
>> 8   2   4  0.6017522
>>  >
>>  > handleonegroup <- function(subset) data.frame(gp1 = subset$gp1[1],
>> + gp2 = subset$gp2[1], statistic = mean(subset$value))
>>  >
>>  > bylist <- by(dataset, list(dataset$gp1, dataset$gp2), handleonegroup)
>>  >
>>  > result <- do.call('rbind', bylist)
>>  > result
>>     gp1 gp2  statistic
>> 1    1   1 0.45092598
>> 11   1   2 0.65434890
>> 12   2   3 1.22439210
>> 13   2   4 0.06356469
>> 
>> tapply() is inappropriate because I don't have all possible combinations 
>> of gp1 and gp2 values, only some of them:
>> 
>>  > tapply(dataset$value, list(dataset$gp1, dataset$gp2), mean)
>>           1         2        3          4
>> 1 0.450926 0.6543489       NA         NA
>> 2       NA        NA 1.224392 0.06356469
>> 
>> 
>> 
>> In the real case, I only have a very sparse subset of all the 
>> combinations, and tapply() and by() both die for lack of memory.
>> 
>> Any suggestions on how to do what I want, without using SAS?
> 
> Have you tried aggregate()?

aggregate() has a few problems:

  - it applies the function to every column in the dataframe.  In my 
case it only makes sense to apply it to some of them.  (This may not be 
a killer, but it certainly makes things inefficient and tricky.)
  - I'd like to look at the whole subset to figure out the function (but 
I can probably work around this)
  - It uses too much memory.  E.g. try

 > df <- data.frame(x=rnorm(1000), y=rnorm(1000), z=rnorm(1000), 
w=rnorm(1000))
 > aggregate(df, list(df$x,df$y,df$z), mean)
Error: cannot allocate vector of size 3906250 Kb
In addition: Warning messages:
1: Reached total allocation of 1007Mb: see help(memory.size)
2: Reached total allocation of 1007Mb: see help(memory.size)

This should have returned the same dataframe (there are 1000 subsets), 
but it tried to construct a billion of them.

On 9/30/2005 1:48 PM, Don MacQueen wrote:
 > Look at the summarize() function in the Hmisc package.

It seems to want a matrix, not a data.frame.  The real situation has 
mixed types (character, factors, numeric) so it can't be a matrix.

 > (and I this is an r-help question, not an r-devel question, I would 
think)

Yes, that's where I should have posted.  Sorry.  However, this is 
starting to look like a development problem...

Peter again:

> Alternatively, you migth split on interaction(...., drop=TRUE)

Looking at the code, it appears that will construct the full product 
interaction, then subset to the non-empty cases... Yes, it does that.

Looks like I'll have to write my own.

Duncan


From murdoch at stats.uwo.ca  Fri Sep 30 20:39:15 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 30 Sep 2005 14:39:15 -0400
Subject: [Rd] by() processing on a dataframe
In-Reply-To: <f8e6ff050509301041g772977f0w8b624170394ff81b@mail.gmail.com>
References: <433D744D.3030603@stats.uwo.ca>
	<f8e6ff050509301041g772977f0w8b624170394ff81b@mail.gmail.com>
Message-ID: <433D8653.4020208@stats.uwo.ca>

On 9/30/2005 1:41 PM, hadley wickham wrote:
> I'm not entirely sure what you want, but maybe this does the trick?
> 
> data.frame.by <- function(data, variables, fun, ...) {
> 	if (length(variables) == 0 ) {
> 		df <- data.frame(results = 0)
> 		df$results <- list(fun(data$value, ...))
> 		return(df)
> 	}
> 
> 	sorted <- sort.df(data, variables)[,c(variables), drop=FALSE]
> 	duplicates <- duplicated(sorted[,variables, drop=FALSE])
> 	index <- cumsum(!duplicates)
> 
> 	results <- by(data, index, fun, ...)
> 
> 	cols <- sorted[!duplicates,variables, drop=FALSE]
> 	cols$results <- array(results)
> 	cols
> }
> 
> 
> sort.df <- function(data, vars) {
> 	data[do.call("order", data[,vars, drop=FALSE]), ,drop=FALSE]
> }
> 
> 
> dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4,
> c(2,2,2,2)), value = rnorm(8))
> 
> data.frame.by(dataset, c("gp1", "gp2"), function(data) mean(data$value))
> data.frame.by(dataset, "gp1", function(data) tapply(data$value, data$gp2, mean))
> data.frame.by(dataset, "gp1", function(data) lm(gp2 ~ value, data)) #
> doesn't print, but everything is there ok
> 
> (note that the results column will be a list if necessary - this may
> be a serious abuse of data frames, but I'm not sure and no one replied
> when I queried the list)

I think this should work.  Thanks!

Duncan Murdoch


From ggrothendieck at gmail.com  Fri Sep 30 20:47:37 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Sep 2005 14:47:37 -0400
Subject: [Rd] by() processing on a dataframe
In-Reply-To: <971536df0509301045t31328ba6tff2685e811c5a6fb@mail.gmail.com>
References: <433D744D.3030603@stats.uwo.ca>
	<971536df0509301045t31328ba6tff2685e811c5a6fb@mail.gmail.com>
Message-ID: <971536df0509301147j54d1c9fdm6525b16eeda380cb@mail.gmail.com>

And here is one more approach using the reshape package:

library(reshape)

dataset.d <- melt(dataset, id = 1:2)
cast(dataset.d, gp1 + gp2 ~ variable, mean)


On 9/30/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Check out summaryBy in the doBy package at:
>
>   http://genetics.agrsci.dk/~sorenh/misc
>
> e.g.
>
>   summaryBy(value ~ gp1 + gp2, data = dataset)
>
>
>
> On 9/30/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > I want to calculate a statistic on a number of subgroups of a dataframe,
> > then put the results into a dataframe.  (What SAS PROC MEANS does, I
> > think, though it's been years since I used it.)
> >
> > This is possible using by(), but it seems cumbersome and fragile.  Is
> > there a more straightforward way than this?
> >
> > Here's a simple example showing my current strategy:
> >
> >  > dataset <- data.frame(gp1 = rep(1:2, c(4,4)), gp2 = rep(1:4,
> > c(2,2,2,2)), value = rnorm(8))
> >  > dataset
> >   gp1 gp2      value
> > 1   1   1  0.9493232
> > 2   1   1 -0.0474712
> > 3   1   2 -0.6808021
> > 4   1   2  1.9894999
> > 5   2   3  2.0154786
> > 6   2   3  0.4333056
> > 7   2   4 -0.4746228
> > 8   2   4  0.6017522
> >  >
> >  > handleonegroup <- function(subset) data.frame(gp1 = subset$gp1[1],
> > + gp2 = subset$gp2[1], statistic = mean(subset$value))
> >  >
> >  > bylist <- by(dataset, list(dataset$gp1, dataset$gp2), handleonegroup)
> >  >
> >  > result <- do.call('rbind', bylist)
> >  > result
> >    gp1 gp2  statistic
> > 1    1   1 0.45092598
> > 11   1   2 0.65434890
> > 12   2   3 1.22439210
> > 13   2   4 0.06356469
> >
> > tapply() is inappropriate because I don't have all possible combinations
> > of gp1 and gp2 values, only some of them:
> >
> >  > tapply(dataset$value, list(dataset$gp1, dataset$gp2), mean)
> >          1         2        3          4
> > 1 0.450926 0.6543489       NA         NA
> > 2       NA        NA 1.224392 0.06356469
> >
> >
> >
> > In the real case, I only have a very sparse subset of all the
> > combinations, and tapply() and by() both die for lack of memory.
> >
> > Any suggestions on how to do what I want, without using SAS?
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


