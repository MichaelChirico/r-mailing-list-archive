From ross at biostat.ucsf.edu  Wed Feb  1 00:21:32 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 31 Jan 2006 15:21:32 -0800
Subject: [Rd] an unpleasant interaction of environments and generic functions
Message-ID: <1138749692.27733.250.camel@iron.psg.net>

I've run into an unpleasant oddity involving the interaction of
environments and generic functions.  I want to check my diagnosis, and
see if there is a good way to avoid the problem.

Problem:
A library defines
"foo" <- function(object) 1
setMethod("foo", c("matrix"), function(object) 30)

After loading the library
foo(0) is 1
foo(matrix()) is 30
foo is a generic

The source the file with the code given above.
Now 
foo(matrix()) is 1
foo is a function
(Also, there is no "creating generic function" message).

Diagnosis:
The library creates foo and related generics in package:libname.
The source for the initial definition puts the name and function
definition in .GlobalEnv.
The source'd setMethod finds the existing generic in package:libname and
updates it (I'm not sure about this last step).
foo then discovers the foo in .GlobalEnv, not the generic, so the
generic and the alternate methods are hidden.

In case you're wondering, I found this out because I was experimenting
with a library, changing the R and not the C code.  I get sick of doing
R CMD INSTALL with each iteration, but needed to load the library to get
the .so file.

So, is my diagnosis correct?

Any suggestions about how to avoid this problem?
Maybe sys.source("file", 2)... Seems to work!
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From ross at biostat.ucsf.edu  Wed Feb  1 01:46:11 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 31 Jan 2006 16:46:11 -0800
Subject: [Rd] an unpleasant interaction of environments and generic
	functions
In-Reply-To: <1138749692.27733.250.camel@iron.psg.net>
References: <1138749692.27733.250.camel@iron.psg.net>
Message-ID: <1138754771.27735.255.camel@iron.psg.net>

On Tue, 2006-01-31 at 15:21 -0800, Ross Boylan wrote:

> Any suggestions about how to avoid this problem?
> Maybe sys.source("file", 2)... Seems to work!
Not quite.  The original versions of some stuff from the library hung
around, and my efforts to delete them led to more difficulties.

Specifically, after loading the library I deleted the names of the
generics and classes from the library's frame.  Then I read the source
files into the frame.  This time it complained there was no function by
the appropriate name when I tried to do setMethod, even though the
previous file should have created it.


From murdoch at stats.uwo.ca  Wed Feb  1 01:57:53 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 31 Jan 2006 19:57:53 -0500
Subject: [Rd] [R] Help! What does this R command mean?
In-Reply-To: <971536df0601311355g7a4e9337iab7e356e533bcfee@mail.gmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED79A@usctmx1106.merck.com>
	<971536df0601311355g7a4e9337iab7e356e533bcfee@mail.gmail.com>
Message-ID: <43E00791.7030506@stats.uwo.ca>

On 1/31/2006 4:55 PM, Gabor Grothendieck wrote:
> I think that a pointer to ?formula needs to be added to ?":"

Good suggestion; I'll do it.

Duncan Murdoch
> 
> 
> On 1/31/06, Liaw, Andy <andy_liaw at merck.com> wrote:
>> ":" in a formula is not the same as ":" otherwise!
>>
>> Andy
>>
>> From: Ionut Florescu
>>> a:b means - all the element in the vector from a to b
>>> a[,-1] means for the matrix a keep all the rows but not the last or
>>> first -can't remember column.
>>> When in doubt do what I do make a small matrix and apply the
>>> command see
>>> what it does.
>>> After this:
>>>  > a=matrix(c(1:9),3,3)
>>>  > a[,-1]
>>>      [,1] [,2]
>>> [1,]    4    7
>>> [2,]    5    8
>>> [3,]    6    9
>>>
>>> you see that -1 eliminates the first column.
>>> I found the R manual useless myself.
>>> The only thing useful is the search function in the html
>>> help. That has
>>> examples.
>>>
>>> Ionut Florescu
>>>
>>> Michael wrote:
>>>> Hi all,
>>>>
>>>> R is so difficult. I am so desperate.
>>>>
>>>> What does the ":" mean in the following statement?
>>>>
>>>> What does the "[, -1]" mean?
>>>>
>>>>
>>>>> # Leaps takes a design matrix as argument: throw away the intercept
>>>>> # column or leaps will complain
>>>>>
>>>>> X <- model.matrix(lm(V ~ I + D + W +G:I + P + N,
>>> election.table))[,-1]
>>>> Thanks a lot!
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From KjetilBrinchmannHalvorsen at gmail.com  Wed Feb  1 02:07:28 2006
From: KjetilBrinchmannHalvorsen at gmail.com (KjetilBrinchmannHalvorsen@gmail.com)
Date: Wed,  1 Feb 2006 02:07:28 +0100 (CET)
Subject: [Rd] window()   problem (PR#8545)
Message-ID: <20060201010728.C3C4A3D5BB@slim.kubism.ku.dk>

window() does not work correctly when called with extend=TRUE  and
the new time range intersect null with the old time range! Maybe this is 
really a feature request, but the documentation does not say what to 
expect in this case.

This case does occur in programming!

This is R2.2.1 on windows, latest compiled from CRAN.

Look at the excerps below:

 > test <- ts(1:144, start=c(1,1), frequency=12)
 > tsp(test)
[1]  1.00000 12.91667 12.00000
 > test2 <- window(test, start=c(5,1), end=c(16,4), extend=TRUE)
 > test2
    Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
5   49  50  51  52  53  54  55  56  57  58  59  60
6   61  62  63  64  65  66  67  68  69  70  71  72
7   73  74  75  76  77  78  79  80  81  82  83  84
8   85  86  87  88  89  90  91  92  93  94  95  96
9   97  98  99 100 101 102 103 104 105 106 107 108
10 109 110 111 112 113 114 115 116 117 118 119 120
11 121 122 123 124 125 126 127 128 129 130 131 132
12 133 134 135 136 137 138 139 140 141 142 143 144
13  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
14  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
15  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
16  NA  NA  NA  NA
 > tsp(test2)
[1]  5.00 16.25 12.00
 > test3 <- window(test, start=c(15,1), end=c(17,1), extend=TRUE)
Error in window.default(x, ...) : invalid time series parameters specified

Enter a frame number, or 0 to exit

1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
3: as.ts(window.default(x, ...))
4: window.default(x, ...)

Selection: 4
Called from: eval(expr, envir, enclos)
Browse[1]> x
    Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1    1   2   3   4   5   6   7   8   9  10  11  12
2   13  14  15  16  17  18  19  20  21  22  23  24
3   25  26  27  28  29  30  31  32  33  34  35  36
4   37  38  39  40  41  42  43  44  45  46  47  48
5   49  50  51  52  53  54  55  56  57  58  59  60
6   61  62  63  64  65  66  67  68  69  70  71  72
7   73  74  75  76  77  78  79  80  81  82  83  84
8   85  86  87  88  89  90  91  92  93  94  95  96
9   97  98  99 100 101 102 103 104 105 106 107 108
10 109 110 111 112 113 114 115 116 117 118 119 120
11 121 122 123 124 125 126 127 128 129 130 131 132
12 133 134 135 136 137 138 139 140 141 142 143 144
Browse[1]> tsp(x)
[1]  1.00000 12.91667 12.00000
Browse[1]> y
  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 
NA NA NA NA NA NA NA NA NA
[32] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
Browse[1]> tsp(y)
NULL
Browse[1]>

As one can see from the above, the calculated answer y does not have a
tsp attribute.

Kjetil


From KjetilBrinchmannHalvorsen at gmail.com  Wed Feb  1 02:14:21 2006
From: KjetilBrinchmannHalvorsen at gmail.com (KjetilBrinchmannHalvorsen@gmail.com)
Date: Wed,  1 Feb 2006 02:14:21 +0100 (CET)
Subject: [Rd] recover() (PR#8546)
Message-ID: <20060201011421.E59BD28FE7@slim.kubism.ku.dk>

After using options(error=recover),
it takes a long time (too long) to get back
to the prompt. Look at:

Browse[1]> recover()

Enter a frame number, or 0 to exit

1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
3: as.ts(window.default(x, ...))
4: window.default(x, ...)
5: function ()
6: eval(quote(browser()), envir = sys.frame(which))
7: eval(expr, envir, enclos)

Selection: recover()
Enter an item from the menu, or 0 to exit
Selection: 0
Browse[1]> recover()

Enter a frame number, or 0 to exit

1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
3: as.ts(window.default(x, ...))
4: window.default(x, ...)
5: function ()
6: eval(quote(browser()), envir = sys.frame(which))
7: eval(expr, envir, enclos)

Selection: 0
Browse[1]> recover()

Enter a frame number, or 0 to exit

1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
3: as.ts(window.default(x, ...))
4: window.default(x, ...)
5: function ()
6: eval(quote(browser()), envir = sys.frame(which))
7: eval(expr, envir, enclos)

Selection: 0
Browse[1]> recover()

Enter a frame number, or 0 to exit

1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
3: as.ts(window.default(x, ...))
4: window.default(x, ...)
5: function ()
6: eval(quote(browser()), envir = sys.frame(which))
7: eval(expr, envir, enclos)

Selection: 0
Browse[1]> recover()

Enter a frame number, or 0 to exit

1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
3: as.ts(window.default(x, ...))
4: window.default(x, ...)
5: function ()
6: eval(quote(browser()), envir = sys.frame(which))
7: eval(expr, envir, enclos)

Selection: 0
Browse[1]>

Enter a frame number, or 0 to exit

1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
3: as.ts(window.default(x, ...))
4: window.default(x, ...)

Selection: 0
 >

I had to type 0 [to exit] 6 times to actually
exit!


Kjetil

(windows, R2.2.1 from CRAN)


From stgries at linguistics.ucsb.edu  Wed Feb  1 02:37:42 2006
From: stgries at linguistics.ucsb.edu (stgries@linguistics.ucsb.edu)
Date: Wed,  1 Feb 2006 02:37:42 +0100 (CET)
Subject: [Rd] Word boundaries and gregexpr in R 2.2.1 (PR#8547)
Message-ID: <20060201013742.E7B663D5BB@slim.kubism.ku.dk>

Full_Name: Stefan Th. Gries
Version: 2.2.1
OS: Windows XP (Home and Professional)
Submission from: (NULL) (68.6.34.104)


The problem is this: I have a vector of two character strings.

> text<-c("This is a first example sentence.", "And this is a second example    
 sentence.")

If I now look for word boundaries with regexpr, this is what I get:
> regexpr("\\b", text, perl=TRUE)
[1] 1 1
attr(,"match.length")
[1] 0 0

So far, so good. But with gregexpr I get:

> gregexpr("\\b", text, perl=TRUE)
Error: cannot allocate vector of size 524288 Kb
In addition: Warning messages:
1: Reached total allocation of 1015Mb: see help(memory.size)
2: Reached total allocation of 1015Mb: see help(memory.size)

Why don't I get the locations and extensions of all word boundaries?

I am using R 2.2.1 on a machine running Windows XP:
> R.version
        _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R


From ripley at stats.ox.ac.uk  Wed Feb  1 08:24:06 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed,  1 Feb 2006 08:24:06 +0100 (CET)
Subject: [Rd] recover() (PR#8546)
Message-ID: <20060201072406.311903ED72@slim.kubism.ku.dk>

Why are you calling recover() at the browse() prompt? What the help page 
says is

      When finished browsing in this call, type 'c' to return to
      'recover' from the browser.  Type another frame number to browse
      some more, or type '0' to exit 'recover'.

You can also type Q in the browser.

You seem never to have typed 'c' as instructed.

On Wed, 1 Feb 2006 KjetilBrinchmannHalvorsen at gmail.com wrote:

> After using options(error=recover),
> it takes a long time (too long) to get back
> to the prompt. Look at:
>
> Browse[1]> recover()
>
> Enter a frame number, or 0 to exit
>
> 1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 3: as.ts(window.default(x, ...))
> 4: window.default(x, ...)
> 5: function ()
> 6: eval(quote(browser()), envir = sys.frame(which))
> 7: eval(expr, envir, enclos)
>
> Selection: recover()
> Enter an item from the menu, or 0 to exit
> Selection: 0
> Browse[1]> recover()
>
> Enter a frame number, or 0 to exit
>
> 1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 3: as.ts(window.default(x, ...))
> 4: window.default(x, ...)
> 5: function ()
> 6: eval(quote(browser()), envir = sys.frame(which))
> 7: eval(expr, envir, enclos)
>
> Selection: 0
> Browse[1]> recover()
>
> Enter a frame number, or 0 to exit
>
> 1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 3: as.ts(window.default(x, ...))
> 4: window.default(x, ...)
> 5: function ()
> 6: eval(quote(browser()), envir = sys.frame(which))
> 7: eval(expr, envir, enclos)
>
> Selection: 0
> Browse[1]> recover()
>
> Enter a frame number, or 0 to exit
>
> 1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 3: as.ts(window.default(x, ...))
> 4: window.default(x, ...)
> 5: function ()
> 6: eval(quote(browser()), envir = sys.frame(which))
> 7: eval(expr, envir, enclos)
>
> Selection: 0
> Browse[1]> recover()
>
> Enter a frame number, or 0 to exit
>
> 1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 3: as.ts(window.default(x, ...))
> 4: window.default(x, ...)
> 5: function ()
> 6: eval(quote(browser()), envir = sys.frame(which))
> 7: eval(expr, envir, enclos)
>
> Selection: 0
> Browse[1]>
>
> Enter a frame number, or 0 to exit
>
> 1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 3: as.ts(window.default(x, ...))
> 4: window.default(x, ...)
>
> Selection: 0
> >
>
> I had to type 0 [to exit] 6 times to actually
> exit!
>
>
> Kjetil
>
> (windows, R2.2.1 from CRAN)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Feb  1 08:49:51 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 01 Feb 2006 08:49:51 +0100
Subject: [Rd] an unpleasant interaction of environments and generic
	functions
In-Reply-To: <1138749692.27733.250.camel@iron.psg.net>
References: <1138749692.27733.250.camel@iron.psg.net>
Message-ID: <43E0681F.9030207@statistik.uni-dortmund.de>

Ross Boylan wrote:

> I've run into an unpleasant oddity involving the interaction of
> environments and generic functions.  I want to check my diagnosis, and
> see if there is a good way to avoid the problem.
> 
> Problem:
> A library defines
> "foo" <- function(object) 1
> setMethod("foo", c("matrix"), function(object) 30)
> 
> After loading the library
> foo(0) is 1
> foo(matrix()) is 30
> foo is a generic
> 
> The source the file with the code given above.
> Now 
> foo(matrix()) is 1
> foo is a function
> (Also, there is no "creating generic function" message).
> 
> Diagnosis:
> The library creates foo and related generics in package:libname.
> The source for the initial definition puts the name and function
> definition in .GlobalEnv.
> The source'd setMethod finds the existing generic in package:libname and
> updates it (I'm not sure about this last step).
> foo then discovers the foo in .GlobalEnv, not the generic, so the
> generic and the alternate methods are hidden.
> 
> In case you're wondering, I found this out because I was experimenting
> with a library, changing the R and not the C code.  I get sick of doing
> R CMD INSTALL with each iteration, but needed to load the library to get
> the .so file.
> 
> So, is my diagnosis correct?
> 
> Any suggestions about how to avoid this problem?
> Maybe sys.source("file", 2)... Seems to work!


I'd suggest to dyn.load() the .so and source() the code during early 
development. So you do not need to R CMD INSTALL the _*package*_ into a 
library.

Uwe Ligges


From ripley at stats.ox.ac.uk  Wed Feb  1 09:35:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 08:35:05 +0000 (GMT)
Subject: [Rd] The install.R and R_PROFILE.R files
Message-ID: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>

R-exts says

   Both install.R and R_PROFILE.R should be viewed as experimental; the
   mechanism to execute code before attaching or installing the package may
   change in the near future. With the other facilities available as from R
   2.0.0 they should be removed if possible.

Every usage of these on CRAN is unnecessary. If you want to save the 
image, say so in the SaveImage field in DESCRIPTION (but why not LazyLoad 
instead?).  If you require methods, say so in Depends in DESCRIPTION.

I propose that we deprecate/remove this mechanism (as it makes 
installation a lot convoluted than it needs to be).  Does any one know of

(a) A usage that requires one of these files to do something which cannot 
now be done more simply via fields in DESCRIPTION, or

(b) A package that requires a saved image (and lazy loading is 
insufficient)?

If so, please let us know.

I am also minded to deprecate/remove the following command-line flags to 
INSTALL

   -s, --save[=ARGS]     save the package source as an image file, and
                         arrange for this file to be loaded when the
                         package is attached; if given, ARGS are passed
                         to R when creating the save image
       --no-save         do not save the package source as an image file
       --lazy            use lazy loading
       --no-lazy         do not use lazy loading
       --lazy-data       use lazy loading for data
       --no-lazy-data    do not use lazy loading for data (current default)

since these have been superseded by the DESCRIPTION fields (and Windows 
does not support --save=ARGS).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From albrecht.gebhardt at uni-klu.ac.at  Wed Feb  1 11:31:17 2006
From: albrecht.gebhardt at uni-klu.ac.at (Albrecht Gebhardt)
Date: Wed, 01 Feb 2006 11:31:17 +0100
Subject: [Rd] akima 0.4-5, interpp() bug = COMMON block problem
In-Reply-To: <17375.16702.18714.169754@stat.math.ethz.ch>
References: <4cba05650512081124w4f869416u64a5189c9a35feeb@mail.gmail.com>
	<4cba05650512081208p1f75ebcehedb3cfe85084cd9@mail.gmail.com>
	<4cba05650512090812g2b9b1d2dk4881088e31ae01b5@mail.gmail.com>
	<17305.47217.562656.398575@stat.math.ethz.ch>
	<1134510976.2543.13.camel@localhost.localdomain>
	<17311.53905.682042.837386@stat.math.ethz.ch>
	<4cba05650601301526l4e7254fajd9d37ff92475bae8@mail.gmail.com>
	<1138695939.9842.16.camel@pc28-math.math.uni-klu.ac.at>
	<17375.16702.18714.169754@stat.math.ethz.ch>
Message-ID: <1138789878.670.27.camel@pc28-math.math.uni-klu.ac.at>

Hi,

I'm currently hunting a bug in the akima library, especially in the code
behind the interpp.old function (bi-variate linear interpolation).
It is based on a triangulation algorithm, interpolation at a given point
needs to know the triangle which contains this point, then the
interpolation is a straightforward calculation based on the three
vertexes.

The problem is: Sometimes the triangle indices are not given back
correctly, they just default to 1 leading to wrong results.

The following lines can be used to visualize it using the rgl library.
If the error occurs (may be architecture depending) the interpolation
"steepest" part of the interp() surface will not be hit by the interpp()
interpolation points.

library(akima)
library(rgl)
data(akima)
# data
rgl.spheres(akima$x,akima$z , akima$y,0.5,color="red")
rgl.bbox()
# interp:
akima.li <- interp(akima$x, akima$y, akima$z, 
                   xo=seq(min(akima$x), max(akima$x), length = 200),
                   yo=seq(min(akima$y), max(akima$y), length = 200))
# interp surface:
rgl.surface(akima.li$x,akima.li$y,akima.li$z,color="green",alpha=c(0.5))
# interpp:
akima.p <- interpp(akima$x, akima$y, akima$z,
                    runif(2000,0,25),
                    runif(2000,0,20))
# interpp (partially wrong) points:
rgl.points(akima.p$x,akima.p$z , akima.p$y,size=4,color="yellow")

The errors occurs at least with R 2.1.1 on a i386 Ubuntu Breezy system.
If I compile without "-O2" in FFLAGS the error vanishes. 

Meanwhile I could track down the bug to the use of COMMON blocks in the
underlying Fortran code:

During the interpp() call a Fortran routine (IDLCTN called from IDBVIP)
is called several times. Only during the first call a COMMON block is
initialized, subsequent calls rely on the values initialized by the
first call. But these values just vanish after the first call.

I already have workaround: I call the initialization on every entry,
this fixes the problem.

===================================================================
RCS file: /home/cvs/math/stat/R/akima/src/idlctn.f,v
retrieving revision 1.2
diff -u -r1.2 idlctn.f
--- idlctn.f    19 Aug 1998 21:54:17 -0000      1.2
+++ idlctn.f    1 Feb 2006 10:28:53 -0000
@@ -49,7 +49,7 @@
       X0 = XII
       Y0 = YII
 C PROCESSING FOR A NEW SET OF DATA POINTS
-      IF (NIT.NE.0) GO TO 80
+C      IF (NIT.NE.0) GO TO 80
       NIT = 1
 C - DIVIDES THE X-Y PLANE INTO NINE RECTANGULAR SECTIONS.
       XMN = XD(1)


I guess, using COMMON blocks is generally a bad idea when using Fortran
code within R? Shall I leave it with my workaround or should I search
for more details of the COMMON block misuse?



Best regards

Albrecht Gebhardt


-- 
// Albrecht Gebhardt          Tel.: (++43 463) 2700/3118
// Institut fuer Mathematik   Fax : (++43 463) 2700/3198
// Universitaet Klagenfurt    mailto:albrecht.gebhardt at uni-klu.ac.at
// Universitaetsstr. 65       http://www.math.uni-klu.ac.at/~agebhard
// A-9020 Klagenfurt, Austria
// GPG PK: http://www.math.uni-klu.ac.at/~agebhard/agebhard.asc
// GPG FP: F46F 656E E83C 9323 CE30  FF8F 9DBA D1A3 B55A 78A6
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Dies ist ein digital signierter Nachrichtenteil
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20060201/c0671038/attachment.bin

From albrecht.gebhardt at uni-klu.ac.at  Wed Feb  1 12:32:15 2006
From: albrecht.gebhardt at uni-klu.ac.at (Albrecht Gebhardt)
Date: Wed, 01 Feb 2006 12:32:15 +0100
Subject: [Rd] akima 0.4-5, interpp() bug = COMMON block problem
In-Reply-To: <1138789878.670.27.camel@pc28-math.math.uni-klu.ac.at>
References: <4cba05650512081124w4f869416u64a5189c9a35feeb@mail.gmail.com>
	<4cba05650512081208p1f75ebcehedb3cfe85084cd9@mail.gmail.com>
	<4cba05650512090812g2b9b1d2dk4881088e31ae01b5@mail.gmail.com>
	<17305.47217.562656.398575@stat.math.ethz.ch>
	<1134510976.2543.13.camel@localhost.localdomain>
	<17311.53905.682042.837386@stat.math.ethz.ch>
	<4cba05650601301526l4e7254fajd9d37ff92475bae8@mail.gmail.com>
	<1138695939.9842.16.camel@pc28-math.math.uni-klu.ac.at>
	<17375.16702.18714.169754@stat.math.ethz.ch>
	<1138789878.670.27.camel@pc28-math.math.uni-klu.ac.at>
Message-ID: <1138793535.670.40.camel@pc28-math.math.uni-klu.ac.at>

After reading my own question once again, I think I can answer it
myself:

The code had too _few_ COMMON blocks. It seems the code relied on that, 
that several local variables would carry their values after being
initialised in the first subroutine call until the second call. This is
not the case. I introduced a new COMMON block containing (at least) all
these variables and this fixes it.

After I have done some more checks, you should expect a new version of
akima soon.


Best wishes

Albrecht


Am Mittwoch, den 01.02.2006, 11:31 +0100 schrieb Albrecht Gebhardt:
> Hi,
> 
> I'm currently hunting a bug in the akima package, especially in the code
> behind the interpp.old function (bi-variate linear interpolation).
> It is based on a triangulation algorithm, interpolation at a given point
> needs to know the triangle which contains this point, then the
> interpolation is a straightforward calculation based on the three
> vertexes.
> 
> The problem is: Sometimes the triangle indices are not given back
> correctly, they just default to 1 leading to wrong results.
> 
> The following lines can be used to visualize it using the rgl package.
> If the error occurs (may be architecture depending) the interpolation
> "steepest" part of the interp() surface will not be hit by the interpp()
> interpolation points.
> 
> library(akima)
> library(rgl)
> data(akima)
> # data
> rgl.spheres(akima$x,akima$z , akima$y,0.5,color="red")
> rgl.bbox()
> # interp:
> akima.li <- interp(akima$x, akima$y, akima$z, 
>                    xo=seq(min(akima$x), max(akima$x), length = 200),
>                    yo=seq(min(akima$y), max(akima$y), length = 200))
> # interp surface:
> rgl.surface(akima.li$x,akima.li$y,akima.li$z,color="green",alpha=c(0.5))
> # interpp:
> akima.p <- interpp(akima$x, akima$y, akima$z,
>                     runif(2000,0,25),
>                     runif(2000,0,20))
> # interpp (partially wrong) points:
> rgl.points(akima.p$x,akima.p$z , akima.p$y,size=4,color="yellow")
> 
> The errors occurs at least with R 2.1.1 on a i386 Ubuntu Breezy system.
> If I compile without "-O2" in FFLAGS the error vanishes. 
> 
> Meanwhile I could track down the bug to the use of COMMON blocks in the
> underlying Fortran code:
> 
> During the interpp() call a Fortran routine (IDLCTN called from IDBVIP)
> is called several times. Only during the first call a COMMON block is
> initialized, subsequent calls rely on the values initialized by the
> first call. But these values just vanish after the first call.
> 
> I already have workaround: I call the initialization on every entry,
> this fixes the problem.
> 
> ===================================================================
> RCS file: /home/cvs/math/stat/R/akima/src/idlctn.f,v
> retrieving revision 1.2
> diff -u -r1.2 idlctn.f
> --- idlctn.f    19 Aug 1998 21:54:17 -0000      1.2
> +++ idlctn.f    1 Feb 2006 10:28:53 -0000
> @@ -49,7 +49,7 @@
>        X0 = XII
>        Y0 = YII
>  C PROCESSING FOR A NEW SET OF DATA POINTS
> -      IF (NIT.NE.0) GO TO 80
> +C      IF (NIT.NE.0) GO TO 80
>        NIT = 1
>  C - DIVIDES THE X-Y PLANE INTO NINE RECTANGULAR SECTIONS.
>        XMN = XD(1)
> 
> 
> I guess, using COMMON blocks is generally a bad idea when using Fortran
> code within R? Shall I leave it with my workaround or should I search
> for more details of the COMMON block misuse?
> 
> 
> 
> Best regards
> 
> Albrecht Gebhardt
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
// Albrecht Gebhardt          Tel.: (++43 463) 2700/3118
// Institut fuer Mathematik   Fax : (++43 463) 2700/3198
// Universitaet Klagenfurt    mailto:albrecht.gebhardt at uni-klu.ac.at
// Universitaetsstr. 65       http://www.math.uni-klu.ac.at/~agebhard
// A-9020 Klagenfurt, Austria
// GPG PK: http://www.math.uni-klu.ac.at/~agebhard/agebhard.asc
// GPG FP: F46F 656E E83C 9323 CE30  FF8F 9DBA D1A3 B55A 78A6
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Dies ist ein digital signierter Nachrichtenteil
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20060201/97346a22/attachment.bin

From ripley at stats.ox.ac.uk  Wed Feb  1 14:06:29 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed,  1 Feb 2006 14:06:29 +0100 (CET)
Subject: [Rd] window()   problem (PR#8545)
Message-ID: <20060201130629.8A7773EFEF@slim.kubism.ku.dk>

This was never intended to work, but can easily be programmed in.
I have done so for R-devel.

On Wed, 1 Feb 2006 KjetilBrinchmannHalvorsen at gmail.com wrote:

> window() does not work correctly when called with extend=TRUE  and
> the new time range intersect null with the old time range! Maybe this is
> really a feature request, but the documentation does not say what to
> expect in this case.
>
> This case does occur in programming!

It is hard to see that it would not be known about in advance.

> This is R2.2.1 on windows, latest compiled from CRAN.
>
> Look at the excerps below:
>
> > test <- ts(1:144, start=c(1,1), frequency=12)
> > tsp(test)
> [1]  1.00000 12.91667 12.00000
> > test2 <- window(test, start=c(5,1), end=c(16,4), extend=TRUE)
> > test2
>    Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
> 5   49  50  51  52  53  54  55  56  57  58  59  60
> 6   61  62  63  64  65  66  67  68  69  70  71  72
> 7   73  74  75  76  77  78  79  80  81  82  83  84
> 8   85  86  87  88  89  90  91  92  93  94  95  96
> 9   97  98  99 100 101 102 103 104 105 106 107 108
> 10 109 110 111 112 113 114 115 116 117 118 119 120
> 11 121 122 123 124 125 126 127 128 129 130 131 132
> 12 133 134 135 136 137 138 139 140 141 142 143 144
> 13  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
> 14  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
> 15  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
> 16  NA  NA  NA  NA
> > tsp(test2)
> [1]  5.00 16.25 12.00
> > test3 <- window(test, start=c(15,1), end=c(17,1), extend=TRUE)
> Error in window.default(x, ...) : invalid time series parameters specified
>
> Enter a frame number, or 0 to exit
>
> 1: window(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 2: window.ts(test, start = c(15, 1), end = c(17, 1), extend = TRUE)
> 3: as.ts(window.default(x, ...))
> 4: window.default(x, ...)
>
> Selection: 4
> Called from: eval(expr, envir, enclos)
> Browse[1]> x
>    Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
> 1    1   2   3   4   5   6   7   8   9  10  11  12
> 2   13  14  15  16  17  18  19  20  21  22  23  24
> 3   25  26  27  28  29  30  31  32  33  34  35  36
> 4   37  38  39  40  41  42  43  44  45  46  47  48
> 5   49  50  51  52  53  54  55  56  57  58  59  60
> 6   61  62  63  64  65  66  67  68  69  70  71  72
> 7   73  74  75  76  77  78  79  80  81  82  83  84
> 8   85  86  87  88  89  90  91  92  93  94  95  96
> 9   97  98  99 100 101 102 103 104 105 106 107 108
> 10 109 110 111 112 113 114 115 116 117 118 119 120
> 11 121 122 123 124 125 126 127 128 129 130 131 132
> 12 133 134 135 136 137 138 139 140 141 142 143 144
> Browse[1]> tsp(x)
> [1]  1.00000 12.91667 12.00000
> Browse[1]> y
>  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> NA NA NA NA NA NA NA NA NA
> [32] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> Browse[1]> tsp(y)
> NULL
> Browse[1]>
>
> As one can see from the above, the calculated answer y does not have a
> tsp attribute.
>
> Kjetil
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rgentlem at fhcrc.org  Wed Feb  1 15:16:35 2006
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Wed, 01 Feb 2006 06:16:35 -0800
Subject: [Rd] Word boundaries and gregexpr in R 2.2.1 (PR#8547)
In-Reply-To: <20060201013742.E7B663D5BB@slim.kubism.ku.dk>
References: <20060201013742.E7B663D5BB@slim.kubism.ku.dk>
Message-ID: <43E0C2C3.2@fhcrc.org>

Should be patched in R-devel, will be available shortly

stgries at linguistics.ucsb.edu wrote:
> Full_Name: Stefan Th. Gries
> Version: 2.2.1
> OS: Windows XP (Home and Professional)
> Submission from: (NULL) (68.6.34.104)
> 
> 
> The problem is this: I have a vector of two character strings.
> 
> 
>>text<-c("This is a first example sentence.", "And this is a second example    
> 
>  sentence.")
> 
> If I now look for word boundaries with regexpr, this is what I get:
> 
>>regexpr("\\b", text, perl=TRUE)
> 
> [1] 1 1
> attr(,"match.length")
> [1] 0 0
> 
> So far, so good. But with gregexpr I get:
> 
> 
>>gregexpr("\\b", text, perl=TRUE)
> 
> Error: cannot allocate vector of size 524288 Kb
> In addition: Warning messages:
> 1: Reached total allocation of 1015Mb: see help(memory.size)
> 2: Reached total allocation of 1015Mb: see help(memory.size)
> 
> Why don't I get the locations and extensions of all word boundaries?
> 
> I am using R 2.2.1 on a machine running Windows XP:
> 
>>R.version
> 
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From pgilbert at bank-banque-canada.ca  Wed Feb  1 17:54:20 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 01 Feb 2006 11:54:20 -0500
Subject: [Rd] package introductions
Message-ID: <43E0E7BC.6000601@bank-banque-canada.ca>

I have been experimenting with different possibilities for an 
"introduction" page for my packages. That is, a good place to tell users 
about the most important things in a package, and where to start.

Recently there was a discussion about this, and a suggestion to use 
<foo>-package.Rd, and also a function that generates a skeleton 
document. My problem with this suggestion is that <foo>-package may not 
be high in the sort order, so users will not find this unless they know 
to look for it (and so there is difficulty establishing the convention). 
A second problem is that the skeleton document has information that may 
be useful, but is not really what I am looking for. (It has all the 
methods in the package, but what I want is to tell users the most 
important ones to look at first. It also has "high maintenance" 
information, like version numbers. I want something that is either 
completely automatic, or manual but low maintenance.) Another related 
problem is that the information put in the skeleton  <foo>-package.Rd 
possibly should be in a man page somewhere, so if this does happen, that 
naming convention will likely be used and would then conflict with my 
introduction.

I now think I have found something that works fairly well. I put the 
introduction in a file 00.foo.Intro.Rd and in that file have

/name{00.foo.Intro}
/alias{00.foo.Intro}
/alias{foo.Intro}

Then sorting puts the 00 version at the beginning of the table of 
contents in both the pdf version with all the help pages, and in the 
html version for the help.start() system. Also, ?foo.Intro works. 
(?"00.foo.Intro" works too, but the quote marks are necessary and this 
seems likely to cause problems for beginners.)

It is also helpful to put something like "See ?foo.Intro for more 
details" in the "Description:" line of the DESCRIPTION file, so users 
see this with help(package="foo"). (I don't think users of the 
help.start() system ever see this, but perhaps someone can correct me.)

I also would like to put in my vote for a DESCRIPTION file tag
   GettingStarted: foo.Intro
probably as an optional tag to begin.

Of course, the biggest simplification happens when things like this are 
done in a similar way by everyone. ( "configure ; make" is not 
intuitively simple, but everyone now knows the incantation.)

Paul Gilbert
-------------- next part --------------
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email message from the Bank of Canada is given in good faith, and shall not be
binding or construed as constituting any obligation on the part of the Bank.

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

Recipients are advised to apply their own virus checks to this message upon receipt.

------------------------------------------------------------------------------------

L'information communiqu?e dans les courriels en provenance de la Banque du Canada
est soumise de bonne foi, mais elle ne saurait lier la Banque et ne doit aucunement
?tre interpr?t?e comme constituant une obligation de sa part.

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

D?s la r?ception du pr?sent message, le ou les destinataires doivent activer leur
programme de d?tection de virus pour ?viter toute contamination possible.

From jago at mclink.it  Wed Feb  1 18:25:10 2006
From: jago at mclink.it (stefano iacus)
Date: Wed, 1 Feb 2006 18:25:10 +0100
Subject: [Rd] (no subject)
Message-ID: <6279E7D6-B12B-46B8-ADD2-D41570489753@mclink.it>

Suppose X is a data.frame with n obs and k vars, all variables are  
factors.

tab <- table(X)

containes a k-dim array

I would like to get a list from tab. This list is such that, each  
element contain the indexes corresponding to the observations which  
are in the same cell of this k-dim array. Of course, only for non  
empty cell.

E.g.

 > set.seed(123)
 > X <- as.data.frame(matrix(rnorm(5000),100,5))
 > X$V1 <- cut(X$V1, br=5)
 > X$V2 <- cut(X$V2, br=5)
 > X$V3 <- cut(X$V3, br=5)
 > X$V4 <- cut(X$V4, br=5)
 > X$V5 <- cut(X$V5, br=5)
 > tab <- table(X)
 > which(tab>0) -> cells
 > length(cells)
[1] 94

thus, of course, 94 cells over 5^5 = 3125 are non empty.
I would like a smart way (without reimplementing table/tabulate) to  
get the list of length 94 which contains the indexes of the obs in  
each cell
Or, viceversa, a vector of length n which tells, observation by  
observation,  which cell (out of the 3125) the observation is in.
stefano


From ripley at stats.ox.ac.uk  Wed Feb  1 19:00:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 18:00:05 +0000 (GMT)
Subject: [Rd] Cutting up a k-D space (no subject)
In-Reply-To: <6279E7D6-B12B-46B8-ADD2-D41570489753@mclink.it>
References: <6279E7D6-B12B-46B8-ADD2-D41570489753@mclink.it>
Message-ID: <Pine.LNX.4.61.0602011750570.24823@gannet.stats>

Stefano,

Try this

XX <- as.numeric(X[[1]])
for (i in 2:length(X)) XX <- 10*XX + as.numeric(X[[i]])
split(seq(along=XX), XX)

You can read off the cell from the decimal expansion of the label.
And XX goes from observations to cells.

The hard work is done by unique() under the skin (split makes XX into a 
factor).

Brian

On Wed, 1 Feb 2006, stefano iacus wrote:

> Suppose X is a data.frame with n obs and k vars, all variables are
> factors.
>
> tab <- table(X)
>
> containes a k-dim array
>
> I would like to get a list from tab. This list is such that, each
> element contain the indexes corresponding to the observations which
> are in the same cell of this k-dim array. Of course, only for non
> empty cell.
>
> E.g.
>
> > set.seed(123)
> > X <- as.data.frame(matrix(rnorm(5000),100,5))
> > X$V1 <- cut(X$V1, br=5)
> > X$V2 <- cut(X$V2, br=5)
> > X$V3 <- cut(X$V3, br=5)
> > X$V4 <- cut(X$V4, br=5)
> > X$V5 <- cut(X$V5, br=5)
> > tab <- table(X)
> > which(tab>0) -> cells
> > length(cells)
> [1] 94
>
> thus, of course, 94 cells over 5^5 = 3125 are non empty.
> I would like a smart way (without reimplementing table/tabulate) to
> get the list of length 94 which contains the indexes of the obs in
> each cell
> Or, viceversa, a vector of length n which tells, observation by
> observation,  which cell (out of the 3125) the observation is in.
> stefano
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jago at mclink.it  Wed Feb  1 19:00:38 2006
From: jago at mclink.it (stefano iacus)
Date: Wed, 1 Feb 2006 19:00:38 +0100
Subject: [Rd] (no subject)
In-Reply-To: <6279E7D6-B12B-46B8-ADD2-D41570489753@mclink.it>
References: <6279E7D6-B12B-46B8-ADD2-D41570489753@mclink.it>
Message-ID: <8D52A513-21B4-44C1-AD3E-1D41E789C04B@mclink.it>

Apologizies, I forgot the subject.
Btw, I found it
stefano

Il giorno 01/feb/06, alle ore 18:25, stefano iacus ha scritto:

> Suppose X is a data.frame with n obs and k vars, all variables are
> factors.
>
> tab <- table(X)
>
> containes a k-dim array
>
> I would like to get a list from tab. This list is such that, each
> element contain the indexes corresponding to the observations which
> are in the same cell of this k-dim array. Of course, only for non
> empty cell.
>
> E.g.
>
>> set.seed(123)
>> X <- as.data.frame(matrix(rnorm(5000),100,5))
>> X$V1 <- cut(X$V1, br=5)
>> X$V2 <- cut(X$V2, br=5)
>> X$V3 <- cut(X$V3, br=5)
>> X$V4 <- cut(X$V4, br=5)
>> X$V5 <- cut(X$V5, br=5)
>> tab <- table(X)
>> which(tab>0) -> cells
>> length(cells)
> [1] 94
>
> thus, of course, 94 cells over 5^5 = 3125 are non empty.
> I would like a smart way (without reimplementing table/tabulate) to
> get the list of length 94 which contains the indexes of the obs in
> each cell
> Or, viceversa, a vector of length n which tells, observation by
> observation,  which cell (out of the 3125) the observation is in.
> stefano
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jago at mclink.it  Wed Feb  1 19:05:06 2006
From: jago at mclink.it (stefano iacus)
Date: Wed, 1 Feb 2006 19:05:06 +0100
Subject: [Rd] Cutting up a k-D space (no subject)
In-Reply-To: <Pine.LNX.4.61.0602011750570.24823@gannet.stats>
References: <6279E7D6-B12B-46B8-ADD2-D41570489753@mclink.it>
	<Pine.LNX.4.61.0602011750570.24823@gannet.stats>
Message-ID: <DE5D70D8-4F50-41C8-98EA-C20B4C899D70@mclink.it>

Thanks Brian,
stefano
Il giorno 01/feb/06, alle ore 19:00, Prof Brian Ripley ha scritto:

> Stefano,
>
> Try this
>
> XX <- as.numeric(X[[1]])
> for (i in 2:length(X)) XX <- 10*XX + as.numeric(X[[i]])
> split(seq(along=XX), XX)
>
> You can read off the cell from the decimal expansion of the label.
> And XX goes from observations to cells.
>
> The hard work is done by unique() under the skin (split makes XX  
> into a factor).
>
> Brian
>
> On Wed, 1 Feb 2006, stefano iacus wrote:
>
>> Suppose X is a data.frame with n obs and k vars, all variables are
>> factors.
>>
>> tab <- table(X)
>>
>> containes a k-dim array
>>
>> I would like to get a list from tab. This list is such that, each
>> element contain the indexes corresponding to the observations which
>> are in the same cell of this k-dim array. Of course, only for non
>> empty cell.
>>
>> E.g.
>>
>> > set.seed(123)
>> > X <- as.data.frame(matrix(rnorm(5000),100,5))
>> > X$V1 <- cut(X$V1, br=5)
>> > X$V2 <- cut(X$V2, br=5)
>> > X$V3 <- cut(X$V3, br=5)
>> > X$V4 <- cut(X$V4, br=5)
>> > X$V5 <- cut(X$V5, br=5)
>> > tab <- table(X)
>> > which(tab>0) -> cells
>> > length(cells)
>> [1] 94
>>
>> thus, of course, 94 cells over 5^5 = 3125 are non empty.
>> I would like a smart way (without reimplementing table/tabulate) to
>> get the list of length 94 which contains the indexes of the obs in
>> each cell
>> Or, viceversa, a vector of length n which tells, observation by
>> observation,  which cell (out of the 3125) the observation is in.
>> stefano
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From sfalcon at fhcrc.org  Wed Feb  1 20:21:37 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 01 Feb 2006 11:21:37 -0800
Subject: [Rd] The install.R and R_PROFILE.R files
In-Reply-To: <Pine.LNX.4.61.0601311817010.20339@gannet.stats> (Brian Ripley's
	message of "Wed, 1 Feb 2006 08:35:05 +0000 (GMT)")
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
Message-ID: <m2ek2mdgvy.fsf@fhcrc.org>

On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
> Every usage of these on CRAN is unnecessary. If you want to save the
> image, say so in the SaveImage field in DESCRIPTION (but why not
> LazyLoad instead?).  If you require methods, say so in Depends in
> DESCRIPTION.

I've looked over the packages in the Bioconductor repository and I
believe that every usage of R_PROFILE.R and install.R is also
unnecessary.

> (b) A package that requires a saved image (and lazy loading is 
> insufficient)?

Many Bioc packages use SaveImage in their DESCRIPTION file.

Could someone provide more detail on the difference between SaveImage
and LazyLoad.  It is possible that LazyLoad would do just as well.

Thanks,

+ seth


From hpages at fhcrc.org  Wed Feb  1 20:30:08 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 01 Feb 2006 11:30:08 -0800
Subject: [Rd] Rd files with unknown sections
Message-ID: <43E10C40.8030105@fhcrc.org>

Hi,


With recent versions of R-devel, "R CMD check" complains about
some "Rd files with unknown sections".

hpages at gladstone:~> R CMD check multtest_1.9.4.tar.gz
...
...
* checking Rd files ... WARNING
Rd files with unknown sections:
  /home/hpages/multtest.Rcheck/00_pkg_src/multtest/man/boot.resample.Rd:
    notes
  /home/hpages/multtest.Rcheck/00_pkg_src/multtest/man/MTP.Rd: notes
 
See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
...
...
 
WARNING: There was 1 warning, see
  /home/hpages/multtest.Rcheck/00check.log
for details
 
I've tried with other Bioconductor packages and "R CMD check" complains
that "alias", "warning", "detail", etc... are "unknown sections".

I get these warnings with R-devel built from a snapshot tarball
from 2006-01-23 (r37152) and 2006-01-31 (r37220).
I don't get it with R-devel tarball from 2006-01-04 (r36984).

Regards,


H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From ripley at stats.ox.ac.uk  Wed Feb  1 21:00:22 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 20:00:22 +0000 (GMT)
Subject: [Rd] Rd files with unknown sections
In-Reply-To: <43E10C40.8030105@fhcrc.org>
References: <43E10C40.8030105@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0602011953260.29877@gannet.stats>

On Wed, 1 Feb 2006, Herve Pages wrote:

> Hi,
>
>
> With recent versions of R-devel, "R CMD check" complains about
> some "Rd files with unknown sections".
>
> hpages at gladstone:~> R CMD check multtest_1.9.4.tar.gz
> ...
> ...
> * checking Rd files ... WARNING
> Rd files with unknown sections:
>  /home/hpages/multtest.Rcheck/00_pkg_src/multtest/man/boot.resample.Rd:
>    notes
>  /home/hpages/multtest.Rcheck/00_pkg_src/multtest/man/MTP.Rd: notes
>
> See chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> ...
> ...
>
> WARNING: There was 1 warning, see
>  /home/hpages/multtest.Rcheck/00check.log
> for details
>
> I've tried with other Bioconductor packages and "R CMD check" complains
> that "alias", "warning", "detail", etc... are "unknown sections".
>
> I get these warnings with R-devel built from a snapshot tarball
> from 2006-01-23 (r37152) and 2006-01-31 (r37220).
> I don't get it with R-devel tarball from 2006-01-04 (r36984).

It is new test (thanks to Kurt Hornik).  Those are all incorrect, and 
will result in incorrect output (or at least, not the intended output). 
It is

\note
\alias  (the warning I see is \alais)
\details

and there is no \warning (etc), you need \section(Warning}{...}

Previously (as Rd is not a defined format with e.g. a DTD), almost all 
errors were silently ignored.

All the reports I have looked at are genuine user errors.  (The same 
applies to the recent subdirectory checks.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hpages at fhcrc.org  Wed Feb  1 21:35:19 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 01 Feb 2006 12:35:19 -0800
Subject: [Rd] Rd files with unknown sections
In-Reply-To: <Pine.LNX.4.61.0602011953260.29877@gannet.stats>
References: <43E10C40.8030105@fhcrc.org>
	<Pine.LNX.4.61.0602011953260.29877@gannet.stats>
Message-ID: <43E11B87.9090308@fhcrc.org>

That's a nice improvement. Thanks!

H.

Prof Brian Ripley wrote:

> On Wed, 1 Feb 2006, Herve Pages wrote:
>
>> With recent versions of R-devel, "R CMD check" complains about
>> some "Rd files with unknown sections".
>
>
> It is new test (thanks to Kurt Hornik).  Those are all incorrect, and 
> will result in incorrect output (or at least, not the intended output).


-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From h.wickham at gmail.com  Wed Feb  1 23:01:52 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 1 Feb 2006 16:01:52 -0600
Subject: [Rd] Retrieving an unevaluated argument
Message-ID: <f8e6ff050602011401m29afd061v3cd1cdae48a83d4f@mail.gmail.com>

I'm trying to retrieve an unevalated argument (a list in particular). 
I can do this easily when I call the function directly:

a1 <- function(x) match.call()$x

> a1(list(y=x^2))
list(y = x^2)

But when the function is called by another function, it gets trickier

b <- function(x, f) f(x)

> b(list(x^2), a1)
x

The best I've been able to do is:

a2 <- function(x) parse(text=deparse(substitute(x, parent.frame())))[[1]]

> b(list(x^2), a2)
list(x^2)

But I'm sure there must be a better way!

Hadley


From andy_liaw at merck.com  Wed Feb  1 23:10:46 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 1 Feb 2006 17:10:46 -0500
Subject: [Rd] Retrieving an unevaluated argument
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7AC@usctmx1106.merck.com>

Why isn't substitute(x, parent.frame()) enough?  parse(deparse()) seems
redundant...

Andy

From: hadley wickham
> 
> I'm trying to retrieve an unevalated argument (a list in particular). 
> I can do this easily when I call the function directly:
> 
> a1 <- function(x) match.call()$x
> 
> > a1(list(y=x^2))
> list(y = x^2)
> 
> But when the function is called by another function, it gets trickier
> 
> b <- function(x, f) f(x)
> 
> > b(list(x^2), a1)
> x
> 
> The best I've been able to do is:
> 
> a2 <- function(x) parse(text=deparse(substitute(x, 
> parent.frame())))[[1]]
> 
> > b(list(x^2), a2)
> list(x^2)
> 
> But I'm sure there must be a better way!
> 
> Hadley
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From h.wickham at gmail.com  Thu Feb  2 01:16:11 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 1 Feb 2006 18:16:11 -0600
Subject: [Rd] Converting an unevaluted list to list of unevaluted elements
Message-ID: <f8e6ff050602011616k412fdba6r77082ee4d463ccd3@mail.gmail.com>

Thanks to Andy Liaw, I have realised my problem isn't getting an
unevaluated argument, my problem really is converting an unevaluted
list to list of unevaluted elements.  That is, how can I go from

substitute(list(a=x, b=c))

to

list(a=substitute(x), b=substitute(c))


(I am also interested in a general means of getting the "correct"
unevaluated argument. ie, what should a be to always return list(x=1)
for these functions:
b <- function(x) a(x)
c <- function(x) b(x)
d <- function(x) c(x)

a(list(x=1))
b(list(x=1))
c(list(x=1))
d(list(x=1))
)

Thanks, as always, for your help

Hadley


From ripley at stats.ox.ac.uk  Thu Feb  2 08:45:55 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 07:45:55 +0000 (GMT)
Subject: [Rd] The install.R and R_PROFILE.R files
In-Reply-To: <m2ek2mdgvy.fsf@fhcrc.org>
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0602020703420.9210@gannet.stats>

On Wed, 1 Feb 2006, Seth Falcon wrote:

> On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
>> Every usage of these on CRAN is unnecessary. If you want to save the
>> image, say so in the SaveImage field in DESCRIPTION (but why not
>> LazyLoad instead?).  If you require methods, say so in Depends in
>> DESCRIPTION.
>
> I've looked over the packages in the Bioconductor repository and I
> believe that every usage of R_PROFILE.R and install.R is also
> unnecessary.

Thanks for that.

>> (b) A package that requires a saved image (and lazy loading is
>> insufficient)?
>
> Many Bioc packages use SaveImage in their DESCRIPTION file.
>
> Could someone provide more detail on the difference between SaveImage
> and LazyLoad.  It is possible that LazyLoad would do just as well.

When an R package is installed, a file is prepared which is the 
concatenation of the (valid) files in the R directory.

With SaveImage, that file is loaded into an environment, and the 
environment dumped as a all.rda file.  The R code is then replaced by 
a loader whose sole job is to load the all.rda file.

With LazyLoad, the R file is loaded into an environment, and the objects 
in the environment are dumped individually into a simple database. The R 
code is then replaced by a loader whose sole job is to create an 
environment of promises to load the objects from the database.
(There is an article in R-news about lazy-loading.)

Lazy-loading is the norm for all but packages with very small amounts of R 
code.

I don't know when saving an image might be needed in preference to 
lazy-loading.  The differences in space (and hence time) when the package 
is used can be considerable, in favour of lazy-loading.  Since saving the 
objects in an environment and saving an environment are not quite the same 
thing there are potential differences.  (I have forgotten, if I ever knew, 
what happens with lazy-loading when you have an object whose environment 
is another namespace, for example.)

There have been packages ('aod' and 'gamlss' are two) which have both 
SaveImage and LazyLoad true. That works but is wasteful.

I just looked at the 12 non-Windows CRAN packages with SaveImage: yes and 
replaced this by LazyLoad: yes.  All passed R CMD check after the change. 
This included 'debug' and 'mvbutils' which had SaveImage: yes, LazyLoad: 
no which suggests the author thought otherwise.

There is no intention to withdraw SaveImage: yes.  Rather, if lazy-loading 
is not doing a complete job, we could see if it could be improved.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Feb  2 14:38:54 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 13:38:54 +0000 (GMT)
Subject: [Rd] [R] readline detection problems
In-Reply-To: <NOEOKKCPBGIAIPPDONMGAEGICBAA.b.otto@uke.uni-hamburg.de>
References: <NOEOKKCPBGIAIPPDONMGAEGICBAA.b.otto@uke.uni-hamburg.de>
Message-ID: <Pine.LNX.4.61.0602021319510.11238@gannet.stats>

Moved to R-devel: please see the posting guide.  This WAY off topic for 
R-help.

Please do read the installation manual:  configure --help says

   --with-readline         use readline library (if available) [yes]

and note, no path can be specified.  The installation manual says

   If you have libraries and header files, e.g., for GNU readline, in
   non-system directories, use the variables LDFLAGS (for libraries, using
   `-L' flags to be passed to the linker) and CPPFLAGS (for header files,
   using `-I' flags to be passed to the C/C++ preprocessors), respectively,
   to specify these locations. These default to LDFLAGS=-L/usr/local/lib
   (/usr/local/lib64 on most 64-bit Linux OSes) and
   CPPFLAGS=-I/usr/local/include to catch the most common cases.

My guess is that you need something like

CPPFLAGS=-I/usr/local/include -I/home3/fa/faga001/vol/readline-5.1/include
LDFLAGS=-L/usr/local/lib -L/home3/fa/faga001/vol/readline-5.1/lib

If this really is readline-5.1, don't use it.  It needs a patch (I believe 
the one found on the GNU mirror suffices) or it is badly broken, enough to 
crash the calling application.


On Thu, 2 Feb 2006, Benjamin Otto wrote:

> Dear community,
>
> I'm trying to install R-2.2.1 on an IRIX 6.2 (Unix System V Release 4)
> system without root access. Unfortunately readline is not installed in
> default, so I installed it locally in my home directory, more precisely in:
> $HOME/vol/readline-5.1, where $HOME is "/home3/fa/faga001". Afterwards I
> appended the path to the library with several $PATH variable, which now
> looks like:
>
> PATH=:/usr/sbin:/usr/bsd:/sbin:/usr/bin:/bin:/usr/bin/X11:/usr/local/bin:/us
> r/freeware/bin:/usr/local/bin:.:/home3/fa/faga001/vol:/home3/fa/faga001/vol/
> readline-5.1:/home3/fa/faga001/vol/readline-5.1/lib
>
> Still, readline is not detected by the configure script. I tried the
> commands:
>
> ./configure --with-readline="-L/$HOME/vol/readline"
> ./configure --with-readline="/$HOME/vol/readline"
> ./configure --with-readline=/$HOME/vol/readline
> ./configure --x-includes="-L/$HOME/vol/readline"
> ./configure --x-includes="/$HOME/vol/readline"
> ./configure --x-libraries="-L/$HOME/vol/readline"
> ./configure --x-libraries="/$HOME/vol/readline"
>
> trying out the different path variants which I previously included in the
> $PATH variable. Nothing helps yet. According to printenv there is currently
> no kind of $LIBRARY or sth. like that defined, but maybe the path should
> rather be included in such an env. variable, I didn't find any hint in the
> documentation.
>
> Has someone an idea how I should link my local readline correctly, so that
> the library is found not only during installtion but afterwards too?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From no228 at cam.ac.uk  Thu Feb  2 16:28:25 2006
From: no228 at cam.ac.uk (no228@cam.ac.uk)
Date: Thu,  2 Feb 2006 16:28:25 +0100 (CET)
Subject: [Rd] crossvalidation in svm regression in e1071 gives incorrect
	results (PR#8554)
Message-ID: <20060202152825.0CE023F065@slim.kubism.ku.dk>

Full_Name: Noel O'Boyle
Version: 2.1.0
OS: Debian GNU/Linux Sarge
Submission from: (NULL) (131.111.8.96)


(1) Description of error

The 10-fold CV option for the svm function in e1071 appears to give incorrect
results for the rmse.

The example code in (3) uses the example regression data in the svm
documentation. The rmse for internal prediction is 0.24. It is expected the
10-fold CV rmse should be bigger, but the result obtained using the "cross=10"
option is 0.07. When the 10-fold CV is conducted either 'by hand' (not shown
below) or using the errorest function in ipred (shown below) the answer is
closer to 0.27, a more reasonable value.

(2) Description of system

I'm using the Debian Sarge version of R:
   R : Copyright 2005, The R Foundation for Statistical Computing
   Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0

svm is in the e1071 package from CRAN:
   Version: 1.5-11
   Date: 2005-09-19

(3) Example code illustrating the problem

library(e1071)

set.seed(42)
# create data
x <- seq(0.1, 5, by = 0.05)
y <- log(x) + rnorm(x, sd = 0.2)
data <- as.data.frame(cbind(y,x))

# estimate model and predict input values
mysvm   <- svm(y ~ x,data)
result <- predict(mysvm, data)
(rmse <- sqrt(mean((result-data[,1])**2)))
# 0.2390489

# built-in 10-fold CV estimate of prediction error
spread <- rep(0,20)
for (i in 1:20) {
    mysvm <- svm(y ~ x,data,cross=10)
    spread[i] <- mean(mysvm$MSE)
    }
summary(spread)
#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 0.06789 0.07089 0.07236 0.07310 0.07411 0.08434 (or something similar)

# 10-fold CV using errorest
library(ipred)
mysvm <- function(formula,data) {
  model <- svm(formula,data)
  function(newdata) predict(model,newdata)
  }
spread <- rep(0,20)
for (i in 1:20) {
  spread[i] <- errorest(y ~ x, data, model=mysvm)$error
}
summary(spread)
#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
#  0.2601  0.2649  0.2673  0.2696  0.2741  0.2927


Regards,
 Noel O'Boyle.


From andy_liaw at merck.com  Thu Feb  2 17:28:40 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 2 Feb 2006 11:28:40 -0500
Subject: [Rd] crossvalidation in svm regression in e1071 gives incorre
 ct results (PR#8554)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7B6@usctmx1106.merck.com>

1. This is _not_ a bug in R itself.  Please don't use R's bug reporting
system for contributed packages.

2. This is _not_ a bug in svm() in `e1071'.  I believe you forgot to take
sqrt.

3.  You really should use the `tot.MSE' component rather than the mean of
the `MSE' component, but this is only a very small difference.

So, instead of spread[i] <- mean(mysvm$MSE), you should have spread[i] <-
sqrt(mysvm$tot.MSE).  I get:

> spread <- rep(0,20)
> for (i in 1:20) {
+     spread[i] <- svm(y ~ x,data, cross=10)$tot.MSE
+ }
> summary(sqrt(spread[i]))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.2679  0.2679  0.2679  0.2679  0.2679  0.2679 


Andy 

From: no228 at cam.ac.uk
> 
> Full_Name: Noel O'Boyle
> Version: 2.1.0
> OS: Debian GNU/Linux Sarge
> Submission from: (NULL) (131.111.8.96)
> 
> 
> (1) Description of error
> 
> The 10-fold CV option for the svm function in e1071 appears 
> to give incorrect
> results for the rmse.
> 
> The example code in (3) uses the example regression data in the svm
> documentation. The rmse for internal prediction is 0.24. It 
> is expected the
> 10-fold CV rmse should be bigger, but the result obtained 
> using the "cross=10"
> option is 0.07. When the 10-fold CV is conducted either 'by 
> hand' (not shown
> below) or using the errorest function in ipred (shown below) 
> the answer is
> closer to 0.27, a more reasonable value.
> 
> (2) Description of system
> 
> I'm using the Debian Sarge version of R:
>    R : Copyright 2005, The R Foundation for Statistical Computing
>    Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0
> 
> svm is in the e1071 package from CRAN:
>    Version: 1.5-11
>    Date: 2005-09-19
> 
> (3) Example code illustrating the problem
> 
> library(e1071)
> 
> set.seed(42)
> # create data
> x <- seq(0.1, 5, by = 0.05)
> y <- log(x) + rnorm(x, sd = 0.2)
> data <- as.data.frame(cbind(y,x))
> 
> # estimate model and predict input values
> mysvm   <- svm(y ~ x,data)
> result <- predict(mysvm, data)
> (rmse <- sqrt(mean((result-data[,1])**2)))
> # 0.2390489
> 
> # built-in 10-fold CV estimate of prediction error
> spread <- rep(0,20)
> for (i in 1:20) {
>     mysvm <- svm(y ~ x,data,cross=10)
>     spread[i] <- mean(mysvm$MSE)
>     }
> summary(spread)
> #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> # 0.06789 0.07089 0.07236 0.07310 0.07411 0.08434 (or 
> something similar)
> 
> # 10-fold CV using errorest
> library(ipred)
> mysvm <- function(formula,data) {
>   model <- svm(formula,data)
>   function(newdata) predict(model,newdata)
>   }
> spread <- rep(0,20)
> for (i in 1:20) {
>   spread[i] <- errorest(y ~ x, data, model=mysvm)$error
> }
> summary(spread)
> #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> #  0.2601  0.2649  0.2673  0.2696  0.2741  0.2927
> 
> 
> Regards,
>  Noel O'Boyle.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From sfalcon at fhcrc.org  Thu Feb  2 20:32:42 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 02 Feb 2006 11:32:42 -0800
Subject: [Rd] The install.R and R_PROFILE.R files
In-Reply-To: <Pine.LNX.4.61.0602020703420.9210@gannet.stats> (Brian Ripley's
	message of "Thu, 2 Feb 2006 07:45:55 +0000 (GMT)")
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>
Message-ID: <m2lkwta751.fsf@ziti.local>

Thanks for the explaination of LazyLoad, that's very helpful.

On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
> There is no intention to withdraw SaveImage: yes.  Rather, if
> lazy-loading is not doing a complete job, we could see if it could
> be improved.

It seems to me that LazyLoad does something different with respect to
packages listed in Depends and/or how it interacts with namespaces.

I'm testing using the Bioconductor package graph and find that if I
change SaveImage to LazyLoad I get the following:

   ** preparing package for lazy loading
   Error in makeClassRepresentation(Class, properties, superClasses, prototype,  : 
           couldn't find function "getuuid"              

Looking at the NAMESPACE for the graph package, it looks like it is
missing some imports.  I added lines:
  import(Ruuid)
  exportClasses(Ruuid)

Aside: am I correct in my reading of the extension manual that if one
uses S4 classes from another package with a namespace, one
must import the classes and *also* export them?

Now I see this:

    ** preparing package for lazy loading
    Error in getClass("Ruuid") : "Ruuid" is not a defined class
    Error: unable to load R code in package 'graph'
    Execution halted   

But Ruuid _is_ defined and exported in the Ruuid package.

Is there a known difference in how dependencies and imports are
handled with LazyLoad as opposed to SaveImage?  

Thanks,

+ seth


From charlie at stat.umn.edu  Thu Feb  2 23:26:28 2006
From: charlie at stat.umn.edu (charlie@stat.umn.edu)
Date: Thu,  2 Feb 2006 23:26:28 +0100 (CET)
Subject: [Rd] achieved.alpha calculated wrong in wilcox.test (PR#8557)
Message-ID: <20060202222628.901CE3F069@slim.kubism.ku.dk>

In R-2.2.1 stable the file wilcox.test.R line 86 has

    achieved.alpha<-2*psignrank(trunc(qu),n)

and should have

    achieved.alpha<-2*psignrank(trunc(qu)-1,n)

this is apparently a thinko not a typo so similar statements are probably
wrong too (line 97, line 109, line 293, line 304, line 316).

Reference: Hollander and Wolfe or

    http://www.stat.umn.edu/geyer/5601/examp/signrank.html
    http://www.stat.umn.edu/geyer/5601/examp/ranksum.html

If the signed rank c. i. is diffs[k] to diffs[length(diffs) + 1 - k],
then the probability of failure to cover for a two-sided interval is

    2 * Pr(T < k)

where T is a random variable having the null distribution of the test
statistic.  It is easy to check this is true in the k = 1 case.  The
confidence interval fails to cover if and only if ALL of the data points
are to one side of the true unknown parameter value, and the probability
of this happening is Pr(T = 0), not Pr(T <= 1) as the code on line 86 has it.

This leads to bizarre behavior.  Consider the following homework problem.

---------- begin R output ----------
> X <- read.table(url("http://www.stat.umn.edu/geyer/5601/hwdata/t3-3.txt"),
+     header = TRUE)
> attach(X)
> wilcox.test(y, x, paired = TRUE, conf.int = TRUE)

        Wilcoxon signed rank test

data:  y and x
V = 24, p-value = 0.1094
alternative hypothesis: true mu is not equal to 0
92.2 percent confidence interval:
 -25 605
sample estimates:
(pseudo)median
            80

Warning message:
Requested conf.level not achievable in: switch(alternative, two.sided = {
----------- end R output -----------

when the correct behavior is given by the code on

    http://www.stat.umn.edu/geyer/5601/examp/signrank.html#conf

---------- begin R output ----------
> conf.level <- 0.95
> z <- sort(y - x)
> n <- length(z)
> walsh <- outer(z, z, "+") / 2
> walsh <- sort(walsh[lower.tri(walsh, diag = TRUE)])
> m <- length(walsh)
> alpha <- 1 - conf.level
> k <- qsignrank(alpha / 2, n)
> if (k == 0) k <- k + 1
> print(k)
[1] 3
> cat("achieved confidence level:", 1 - 2 * psignrank(k - 1, n), "\n")
achieved confidence level: 0.953125
> c(walsh[k], walsh[m + 1 - k])
[1] -25 605
----------- end R output -----------

Note that wilcox.test reports the correct interval, which
is diffs[k] to diffs[length(diffs) + 1 - k] with k == 3.
Its mistake is to claim that this is only
a 92.2 percent confidence interval when it is
actually a 95.3125 percent confidence interval.

IMHO it is also a bug to give no option to get the actual achieved confidence
level unless the level requested is not achievable and then only in the text
of a warning.  But that is debatable.

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie at stat.umn.edu


From Mergers_N_Acquisitions_mallard at gmail.com  Fri Feb  3 01:43:39 2006
From: Mergers_N_Acquisitions_mallard at gmail.com (Lucille Abel)
Date: Thu, 02 Feb 2006 18:43:39 -0600
Subject: [Rd] IAWK  iAsiaWorks
Message-ID: <182510350459.XAA13898Mergers_N_Acquisitions_mallard@gmail.com>

Orville,

IAWK  iAsiaWorks - http://geocities.yahoo.com.br/vituperator30086

Lucille Abel, Acct. Rep. wa794223


From didier.renard at ensmp.fr  Fri Feb  3 08:25:00 2006
From: didier.renard at ensmp.fr (Renard Didier)
Date: Fri, 03 Feb 2006 08:25:00 +0100
Subject: [Rd] Interfacing C-code (gets and printf) under WINDOWS (Visual C++)
Message-ID: <43E3054C.5020600@ensmp.fr>

Hi

I try to develop a R interface to a set of C routines, in order to 
produce a R-package on Geostatistics.
My C-code uses interaction with the user as I use printf and gets 
statements.
I develop the code in a LINUX environment and do not face any problem 
having the questions and answers routed on my current Terminal.
When I tried to port the package on Windows, the problems began. No 
message was routed to the Console and I could not enter any answer. Let 
me first admit that I am not a specialist of the WINDOWS environment.
I started looking for an answer on the WEB and intercepted some pieces 
of answers ... but I did not succeed in getting a workable solution. 
This is the reason why I put this open question here today.

I did not find lots of information about the gets solution. Finally, I 
have chosen to use R_WriteConsole and R_ReadConsole which seemed to be 
promising solutions. I discovered an information saying that starting 
R-2.0.1, the include file R-interface.h could help me. This is the 
reason why I downloaded the latest version available on the R site 
(R-2.2.1). Unfortunately, I did not find such a file in the include 
directory. Moreover, in Visual C++ that I am using for building my DLL, 
I need to find the LIBRARY containing the objects of these two routines.
Did I do something wrong. Do I need to download other contributions 
first. Do I use incorrect routines ?

Thank you for your help.

Didier RENARD


From ripley at stats.ox.ac.uk  Fri Feb  3 09:49:20 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 08:49:20 +0000 (GMT)
Subject: [Rd] Interfacing C-code (gets and printf) under WINDOWS (Visual
 C++)
In-Reply-To: <43E3054C.5020600@ensmp.fr>
References: <43E3054C.5020600@ensmp.fr>
Message-ID: <Pine.LNX.4.61.0602030742200.4544@gannet.stats>

Please do study the `Writing R Extensions' manual.

The `information' you have that

> starting R-2.0.1, the include file R-interface.h could help me.

is misinformation: it is for writing alternative front ends under 
Unix-alikes and not included in the Windows binary distribution. 
R_WriteConsole and R_ReadConsole are not part of the R API (and not 
defined in that file).

The distinction is not between Linux and Windows, but between a 
command-line and a console (GUI) environment.  Rterm.exe on Windows works 
as you expect.  OTOH, there are several GUI consoles on Unix-alikes, most 
notably the MacOS X GUI.

For output, the manual clearly describes the problem and the solution 
(Rprintf/REprintf).  This is used by hundreds of packages.

For input, you can read from the stdin() connection.  However, it is 
confusing to the users to mix up input to your functions with input to R, 
and in a GUI context it is normal for a function to use a dialog box for 
input.  For example, the R/Windows equivalent of gets is 
winDialogString().

With very few exceptions (scan(), readline(), menu(), ...) the 
user expects to use console input only for R commands.  If your 
interaction is like those R commands, you can execute them from your C 
code (via eval).

If your code needs frequent interactions with the user an alternative 
approach is to use its own GUI.  Quite a few packages do that, using the 
tcltk package to build a GUI in Tcl/Tk, with the analysis functions 
programmed as callbacks.

[I should add that Visual C++ is not supported, and that you will need to 
make your own import library - this is described in file README.packages. 
For a Linux programmer it would be much easier to use the supported 
MinGW environment.]

On Fri, 3 Feb 2006, Renard Didier wrote:

> Hi
>
> I try to develop a R interface to a set of C routines, in order to
> produce a R-package on Geostatistics.
> My C-code uses interaction with the user as I use printf and gets
> statements.
> I develop the code in a LINUX environment and do not face any problem
> having the questions and answers routed on my current Terminal.
> When I tried to port the package on Windows, the problems began. No
> message was routed to the Console and I could not enter any answer. Let
> me first admit that I am not a specialist of the WINDOWS environment.
> I started looking for an answer on the WEB and intercepted some pieces
> of answers ... but I did not succeed in getting a workable solution.
> This is the reason why I put this open question here today.
>
> I did not find lots of information about the gets solution. Finally, I
> have chosen to use R_WriteConsole and R_ReadConsole which seemed to be
> promising solutions. I discovered an information saying that starting
> R-2.0.1, the include file R-interface.h could help me. This is the
> reason why I downloaded the latest version available on the R site
> (R-2.2.1). Unfortunately, I did not find such a file in the include
> directory. Moreover, in Visual C++ that I am using for building my DLL,
> I need to find the LIBRARY containing the objects of these two routines.
> Did I do something wrong. Do I need to download other contributions
> first. Do I use incorrect routines ?
>
> Thank you for your help.
>
> Didier RENARD


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Feb  3 10:41:25 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 3 Feb 2006 10:41:25 +0100
Subject: [Rd] SaveImage, LazyLoad,
	S4 and all that {was "install.R ... files"}
In-Reply-To: <m2lkwta751.fsf@ziti.local>
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>
	<m2lkwta751.fsf@ziti.local>
Message-ID: <17379.9541.58029.774861@stat.math.ethz.ch>

>>>>> "Seth" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>     on Thu, 02 Feb 2006 11:32:42 -0800 writes:

    Seth> Thanks for the explaination of LazyLoad, that's very helpful.
    Seth> On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
    >> There is no intention to withdraw SaveImage: yes.  Rather, if
    >> lazy-loading is not doing a complete job, we could see if it could
    >> be improved.

    Seth> It seems to me that LazyLoad does something different with respect to
    Seth> packages listed in Depends and/or how it interacts with namespaces.

    Seth> I'm testing using the Bioconductor package graph and find that if I
    Seth> change SaveImage to LazyLoad I get the following:

Interesting.

I had also the vague feeling that  saveImage  was said to be
important when using  S4 classes and methods; particularly when
some methods are for generics from a different package/Namespace
and other methods for `base' classes (or other classes defined
elsewhere).
This is the case of 'Matrix', my primary experience here.
OTOH, we now only use 'LazyLoad: yes' , not (any more?)
'SaveImage: yes' -- and honestly I don't know / remember why.

Martin


    Seth> ** preparing package for lazy loading
    Seth> Error in makeClassRepresentation(Class, properties, superClasses, prototype,  : 
    Seth> couldn't find function "getuuid"              

    Seth> Looking at the NAMESPACE for the graph package, it looks like it is
    Seth> missing some imports.  I added lines:
    Seth> import(Ruuid)
    Seth> exportClasses(Ruuid)

    Seth> Aside: am I correct in my reading of the extension manual that if one
    Seth> uses S4 classes from another package with a namespace, one
    Seth> must import the classes and *also* export them?

    Seth> Now I see this:

    Seth> ** preparing package for lazy loading
    Seth> Error in getClass("Ruuid") : "Ruuid" is not a defined class
    Seth> Error: unable to load R code in package 'graph'
    Seth> Execution halted   

    Seth> But Ruuid _is_ defined and exported in the Ruuid package.

    Seth> Is there a known difference in how dependencies and imports are
    Seth> handled with LazyLoad as opposed to SaveImage?  

    Seth> Thanks,

    Seth> + seth


From ripley at stats.ox.ac.uk  Fri Feb  3 11:28:48 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 10:28:48 +0000 (GMT)
Subject: [Rd] SaveImage, LazyLoad,
	S4 and all that {was "install.R ... files"}
In-Reply-To: <17379.9541.58029.774861@stat.math.ethz.ch>
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>
	<m2lkwta751.fsf@ziti.local>
	<17379.9541.58029.774861@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0602031023460.18275@gannet.stats>

The short answer is that there are no known (i.e. documented) differences, 
and no examples on CRAN which do not work with lazy-loading (except party, 
which loads the saved image in a test).  And that includes examples of 
packages which share S4 classes.  But my question was to tease things like 
this out.

You do need either SaveImage or LazyLoad in a package that defines S4 
classes and methods, since SetClass etc break the `rules' for R files in 
packages in `Writing R Extensions'.

When I have time I will take a closer look at this example.


On Fri, 3 Feb 2006, Martin Maechler wrote:

>>>>>> "Seth" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>>     on Thu, 02 Feb 2006 11:32:42 -0800 writes:
>
>    Seth> Thanks for the explaination of LazyLoad, that's very helpful.
>    Seth> On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
>    >> There is no intention to withdraw SaveImage: yes.  Rather, if
>    >> lazy-loading is not doing a complete job, we could see if it could
>    >> be improved.
>
>    Seth> It seems to me that LazyLoad does something different with respect to
>    Seth> packages listed in Depends and/or how it interacts with namespaces.
>
>    Seth> I'm testing using the Bioconductor package graph and find that if I
>    Seth> change SaveImage to LazyLoad I get the following:
>
> Interesting.
>
> I had also the vague feeling that  saveImage  was said to be
> important when using  S4 classes and methods; particularly when
> some methods are for generics from a different package/Namespace
> and other methods for `base' classes (or other classes defined
> elsewhere).
> This is the case of 'Matrix', my primary experience here.
> OTOH, we now only use 'LazyLoad: yes' , not (any more?)
> 'SaveImage: yes' -- and honestly I don't know / remember why.
>
> Martin
>
>
>    Seth> ** preparing package for lazy loading
>    Seth> Error in makeClassRepresentation(Class, properties, superClasses, prototype,  :
>    Seth> couldn't find function "getuuid"
>
>    Seth> Looking at the NAMESPACE for the graph package, it looks like it is
>    Seth> missing some imports.  I added lines:
>    Seth> import(Ruuid)
>    Seth> exportClasses(Ruuid)
>
>    Seth> Aside: am I correct in my reading of the extension manual that if one
>    Seth> uses S4 classes from another package with a namespace, one
>    Seth> must import the classes and *also* export them?
>
>    Seth> Now I see this:
>
>    Seth> ** preparing package for lazy loading
>    Seth> Error in getClass("Ruuid") : "Ruuid" is not a defined class
>    Seth> Error: unable to load R code in package 'graph'
>    Seth> Execution halted
>
>    Seth> But Ruuid _is_ defined and exported in the Ruuid package.
>
>    Seth> Is there a known difference in how dependencies and imports are
>    Seth> handled with LazyLoad as opposed to SaveImage?
>
>    Seth> Thanks,
>
>    Seth> + seth
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Fri Feb  3 12:08:10 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 03 Feb 2006 11:08:10 +0000
Subject: [Rd] Interfacing C-code (gets and printf) under WINDOWS (Visual
 C++)
In-Reply-To: <Pine.LNX.4.61.0602030742200.4544@gannet.stats>
References: <43E3054C.5020600@ensmp.fr>
	<Pine.LNX.4.61.0602030742200.4544@gannet.stats>
Message-ID: <43E3399A.2000907@cimr.cam.ac.uk>

In addition to everything Prof Ripley wrote, I'd just like to add that
win32 R does run under wine (in fact I am currently doing a test
loading a 150MB Rdata file into win32 R under 32-bit wine under
64-bit opteron to see how slow it might be - it takes about 2 minutes 
natively), and I believe that the usual way of building win32 R
is either mingw or cross-compile from linux. So besides mingw, one might
consider setting up a cross-compiling environment.

(and mingw also seems to install and run fine under wine, and it is my 
intention to see if I can compile and build some C code for win32 R
with mingw/wine which I wrote and have got working under linux).

HTL

Prof Brian Ripley wrote:
> Please do study the `Writing R Extensions' manual.
> 
> The `information' you have that
> 
> 
>>starting R-2.0.1, the include file R-interface.h could help me.
> 
> 
> is misinformation: it is for writing alternative front ends under 
> Unix-alikes and not included in the Windows binary distribution. 
> R_WriteConsole and R_ReadConsole are not part of the R API (and not 
> defined in that file).
> 
> The distinction is not between Linux and Windows, but between a 
> command-line and a console (GUI) environment.  Rterm.exe on Windows works 
> as you expect.  OTOH, there are several GUI consoles on Unix-alikes, most 
> notably the MacOS X GUI.
> 
> For output, the manual clearly describes the problem and the solution 
> (Rprintf/REprintf).  This is used by hundreds of packages.
> 
> For input, you can read from the stdin() connection.  However, it is 
> confusing to the users to mix up input to your functions with input to R, 
> and in a GUI context it is normal for a function to use a dialog box for 
> input.  For example, the R/Windows equivalent of gets is 
> winDialogString().
> 
> With very few exceptions (scan(), readline(), menu(), ...) the 
> user expects to use console input only for R commands.  If your 
> interaction is like those R commands, you can execute them from your C 
> code (via eval).
> 
> If your code needs frequent interactions with the user an alternative 
> approach is to use its own GUI.  Quite a few packages do that, using the 
> tcltk package to build a GUI in Tcl/Tk, with the analysis functions 
> programmed as callbacks.
> 
> [I should add that Visual C++ is not supported, and that you will need to 
> make your own import library - this is described in file README.packages. 
> For a Linux programmer it would be much easier to use the supported 
> MinGW environment.]
> 
> On Fri, 3 Feb 2006, Renard Didier wrote:
> 
> 
>>Hi
>>
>>I try to develop a R interface to a set of C routines, in order to
>>produce a R-package on Geostatistics.
>>My C-code uses interaction with the user as I use printf and gets
>>statements.
>>I develop the code in a LINUX environment and do not face any problem
>>having the questions and answers routed on my current Terminal.
>>When I tried to port the package on Windows, the problems began. No
>>message was routed to the Console and I could not enter any answer. Let
>>me first admit that I am not a specialist of the WINDOWS environment.
>>I started looking for an answer on the WEB and intercepted some pieces
>>of answers ... but I did not succeed in getting a workable solution.
>>This is the reason why I put this open question here today.
>>
>>I did not find lots of information about the gets solution. Finally, I
>>have chosen to use R_WriteConsole and R_ReadConsole which seemed to be
>>promising solutions. I discovered an information saying that starting
>>R-2.0.1, the include file R-interface.h could help me. This is the
>>reason why I downloaded the latest version available on the R site
>>(R-2.2.1). Unfortunately, I did not find such a file in the include
>>directory. Moreover, in Visual C++ that I am using for building my DLL,
>>I need to find the LIBRARY containing the objects of these two routines.
>>Did I do something wrong. Do I need to download other contributions
>>first. Do I use incorrect routines ?
>>
>>Thank you for your help.
>>
>>Didier RENARD
> 
> 
>


From uht at dfu.min.dk  Fri Feb  3 12:55:36 2006
From: uht at dfu.min.dk (uht@dfu.min.dk)
Date: Fri,  3 Feb 2006 12:55:36 +0100 (CET)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
Message-ID: <20060203115536.699413F06E@slim.kubism.ku.dk>

Full_Name: Uffe H?gsbro Thygesen
Version: 2.2.0
OS: linux
Submission from: (NULL) (130.226.135.250)


Hello all.

  pbinom(q=0,size=0,prob=0.5)

returns the value NaN. I had expected the result 1. In fact any value for q
seems to give an NaN. Note that

  dbinom(x=0,size=0,prob=0.5)

returns the value 1.

Cheers,

Uffe


From b.otto at uke.uni-hamburg.de  Fri Feb  3 13:44:31 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Fri, 3 Feb 2006 13:44:31 +0100
Subject: [Rd] [R] readline detection problems
In-Reply-To: <Pine.LNX.4.61.0602021319510.11238@gannet.stats>
Message-ID: <NOEOKKCPBGIAIPPDONMGEEGOCBAA.b.otto@uke.uni-hamburg.de>

Dear Mr. Ripley,

thanks for the quick reply. I set these flags now, however there still seem
to be some problems with readline. The corresponding cofigure output is:

checking readline/history.h usability... yes
checking readline/history.h presence... yes
checking for readline/history.h... yes
checking readline/readline.h usability... yes
checking readline/readline.h presence... yes
checking for readline/readline.h... yes
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... no
checking for main in -ltermcap... yes
checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and headers/libs are not
available

The existing compiler is gcc version 2.8.1 and the linker editor used by gcc
is an IRIX ld version 7.30. By the way I had read the installation manual
and already patched readline 5.1.

>> --with-readline         use readline library (if available) [yes]

The lpack linking

--with-lapack="-L/path/to/libs -llapack -lcblas"

was the reason why I thought I could at least give it a try with the command

--with-readline="-L/$HOME/vol/readline"

However, I admit I missed the passage about the LDFLAGS and should have
search more thoroughly in the docu. Still I'm a little bit confused where
the current remaining problem is. I gave it a try with readline 5.0, which
seem to me to be the newest version not needing any patches, same problem.
Is this some compiler and linker problem?

regards,
benjamin


 which was the reason why I thought I could give it


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: 02 February 2006 14:39
> To: Benjamin Otto
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [R] readline detection problems
>
>
> Moved to R-devel: please see the posting guide.  This WAY off topic for
> R-help.
>
> Please do read the installation manual:  configure --help says
>
>    --with-readline         use readline library (if available) [yes]
>
> and note, no path can be specified.  The installation manual says
>
>    If you have libraries and header files, e.g., for GNU readline, in
>    non-system directories, use the variables LDFLAGS (for libraries, using
>    `-L' flags to be passed to the linker) and CPPFLAGS (for header files,
>    using `-I' flags to be passed to the C/C++ preprocessors),
> respectively,
>    to specify these locations. These default to LDFLAGS=-L/usr/local/lib
>    (/usr/local/lib64 on most 64-bit Linux OSes) and
>    CPPFLAGS=-I/usr/local/include to catch the most common cases.
>
> My guess is that you need something like
>
> CPPFLAGS=-I/usr/local/include -I/home3/fa/faga001/vol/readline-5.1/include
> LDFLAGS=-L/usr/local/lib -L/home3/fa/faga001/vol/readline-5.1/lib
>
> If this really is readline-5.1, don't use it.  It needs a patch
> (I believe
> the one found on the GNU mirror suffices) or it is badly broken,
> enough to
> crash the calling application.
>
>
> On Thu, 2 Feb 2006, Benjamin Otto wrote:
>
> > Dear community,
> >
> > I'm trying to install R-2.2.1 on an IRIX 6.2 (Unix System V Release 4)
> > system without root access. Unfortunately readline is not installed in
> > default, so I installed it locally in my home directory, more
> precisely in:
> > $HOME/vol/readline-5.1, where $HOME is "/home3/fa/faga001". Afterwards I
> > appended the path to the library with several $PATH variable, which now
> > looks like:
> >
> >
> PATH=:/usr/sbin:/usr/bsd:/sbin:/usr/bin:/bin:/usr/bin/X11:/usr/loc
> al/bin:/us
> >
> r/freeware/bin:/usr/local/bin:.:/home3/fa/faga001/vol:/home3/fa/fa
> ga001/vol/
> > readline-5.1:/home3/fa/faga001/vol/readline-5.1/lib
> >
> > Still, readline is not detected by the configure script. I tried the
> > commands:
> >
> > ./configure --with-readline="-L/$HOME/vol/readline"
> > ./configure --with-readline="/$HOME/vol/readline"
> > ./configure --with-readline=/$HOME/vol/readline
> > ./configure --x-includes="-L/$HOME/vol/readline"
> > ./configure --x-includes="/$HOME/vol/readline"
> > ./configure --x-libraries="-L/$HOME/vol/readline"
> > ./configure --x-libraries="/$HOME/vol/readline"
> >
> > trying out the different path variants which I previously
> included in the
> > $PATH variable. Nothing helps yet. According to printenv there
> is currently
> > no kind of $LIBRARY or sth. like that defined, but maybe the path should
> > rather be included in such an env. variable, I didn't find any
> hint in the
> > documentation.
> >
> > Has someone an idea how I should link my local readline
> correctly, so that
> > the library is found not only during installtion but afterwards too?
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From hin-tak.leung at cimr.cam.ac.uk  Fri Feb  3 14:07:39 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 03 Feb 2006 13:07:39 +0000
Subject: [Rd] [R] readline detection problems
In-Reply-To: <NOEOKKCPBGIAIPPDONMGEEGOCBAA.b.otto@uke.uni-hamburg.de>
References: <NOEOKKCPBGIAIPPDONMGEEGOCBAA.b.otto@uke.uni-hamburg.de>
Message-ID: <43E3559B.8040507@cimr.cam.ac.uk>

look into config.log towards the end - it gives you the details of what
happened during the failed configure. (the file is created by configure
as it runs).

As for consistency of what --someopt should take, it is all part of
the mess of autoconf. You could read it up at http://www.gnu.org/ and 
look for autoconf docs there.

Prof Ripley had already give you CPPFLAGS and LDFLAGS ; if in doubt, 
stick the -I<readline_include_loc> and -L<readlne_lib_loc>  into CFLAGS 
  FFLAGS and CXXFLAGS as well, like

CFLAGS= -I/home3/fa/faga001/vol/readline-5.1/include \
-L/home3/fa/faga001/vol/readline-5.1/lib

I suspect what you needed was CFLAGS, rather than CPPFLAGS .
This is barbaric, but the alternative is that you'll need to understand
how autoconf works, which is not a easy task.

Good luck.

HTL

Benjamin Otto wrote:
> Dear Mr. Ripley,
> 
> thanks for the quick reply. I set these flags now, however there still seem
> to be some problems with readline. The corresponding cofigure output is:
> 
> checking readline/history.h usability... yes
> checking readline/history.h presence... yes
> checking for readline/history.h... yes
> checking readline/readline.h usability... yes
> checking readline/readline.h presence... yes
> checking for readline/readline.h... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... no
> checking for main in -ltermcap... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and headers/libs are not
> available
> 
> The existing compiler is gcc version 2.8.1 and the linker editor used by gcc
> is an IRIX ld version 7.30. By the way I had read the installation manual
> and already patched readline 5.1.
> 
> 
>>>--with-readline         use readline library (if available) [yes]
> 
> 
> The lpack linking
> 
> --with-lapack="-L/path/to/libs -llapack -lcblas"
> 
> was the reason why I thought I could at least give it a try with the command
> 
> --with-readline="-L/$HOME/vol/readline"
> 
> However, I admit I missed the passage about the LDFLAGS and should have
> search more thoroughly in the docu. Still I'm a little bit confused where
> the current remaining problem is. I gave it a try with readline 5.0, which
> seem to me to be the newest version not needing any patches, same problem.
> Is this some compiler and linker problem?
> 
> regards,
> benjamin
> 
> 
>  which was the reason why I thought I could give it
> 
> 
> 
>>-----Original Message-----
>>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>>Sent: 02 February 2006 14:39
>>To: Benjamin Otto
>>Cc: r-devel at stat.math.ethz.ch
>>Subject: Re: [R] readline detection problems
>>
>>
>>Moved to R-devel: please see the posting guide.  This WAY off topic for
>>R-help.
>>
>>Please do read the installation manual:  configure --help says
>>
>>   --with-readline         use readline library (if available) [yes]
>>
>>and note, no path can be specified.  The installation manual says
>>
>>   If you have libraries and header files, e.g., for GNU readline, in
>>   non-system directories, use the variables LDFLAGS (for libraries, using
>>   `-L' flags to be passed to the linker) and CPPFLAGS (for header files,
>>   using `-I' flags to be passed to the C/C++ preprocessors),
>>respectively,
>>   to specify these locations. These default to LDFLAGS=-L/usr/local/lib
>>   (/usr/local/lib64 on most 64-bit Linux OSes) and
>>   CPPFLAGS=-I/usr/local/include to catch the most common cases.
>>
>>My guess is that you need something like
>>
>>CPPFLAGS=-I/usr/local/include -I/home3/fa/faga001/vol/readline-5.1/include
>>LDFLAGS=-L/usr/local/lib -L/home3/fa/faga001/vol/readline-5.1/lib
>>
>>If this really is readline-5.1, don't use it.  It needs a patch
>>(I believe
>>the one found on the GNU mirror suffices) or it is badly broken,
>>enough to
>>crash the calling application.
>>
>>
>>On Thu, 2 Feb 2006, Benjamin Otto wrote:
>>
>>
>>>Dear community,
>>>
>>>I'm trying to install R-2.2.1 on an IRIX 6.2 (Unix System V Release 4)
>>>system without root access. Unfortunately readline is not installed in
>>>default, so I installed it locally in my home directory, more
>>
>>precisely in:
>>
>>>$HOME/vol/readline-5.1, where $HOME is "/home3/fa/faga001". Afterwards I
>>>appended the path to the library with several $PATH variable, which now
>>>looks like:
>>>
>>>
>>
>>PATH=:/usr/sbin:/usr/bsd:/sbin:/usr/bin:/bin:/usr/bin/X11:/usr/loc
>>al/bin:/us
>>
>>r/freeware/bin:/usr/local/bin:.:/home3/fa/faga001/vol:/home3/fa/fa
>>ga001/vol/
>>
>>>readline-5.1:/home3/fa/faga001/vol/readline-5.1/lib
>>>
>>>Still, readline is not detected by the configure script. I tried the
>>>commands:
>>>
>>>./configure --with-readline="-L/$HOME/vol/readline"
>>>./configure --with-readline="/$HOME/vol/readline"
>>>./configure --with-readline=/$HOME/vol/readline
>>>./configure --x-includes="-L/$HOME/vol/readline"
>>>./configure --x-includes="/$HOME/vol/readline"
>>>./configure --x-libraries="-L/$HOME/vol/readline"
>>>./configure --x-libraries="/$HOME/vol/readline"
>>>
>>>trying out the different path variants which I previously
>>
>>included in the
>>
>>>$PATH variable. Nothing helps yet. According to printenv there
>>
>>is currently
>>
>>>no kind of $LIBRARY or sth. like that defined, but maybe the path should
>>>rather be included in such an env. variable, I didn't find any
>>
>>hint in the
>>
>>>documentation.
>>>
>>>Has someone an idea how I should link my local readline
>>
>>correctly, so that
>>
>>>the library is found not only during installtion but afterwards too?
>>
>>--
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Fri Feb  3 14:06:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 13:06:07 +0000 (GMT)
Subject: [Rd] [R] readline detection problems
In-Reply-To: <NOEOKKCPBGIAIPPDONMGEEGOCBAA.b.otto@uke.uni-hamburg.de>
References: <NOEOKKCPBGIAIPPDONMGEEGOCBAA.b.otto@uke.uni-hamburg.de>
Message-ID: <Pine.LNX.4.61.0602031304320.23095@gannet.stats>

On Fri, 3 Feb 2006, Benjamin Otto wrote:

> Dear Mr. Ripley,
>
> thanks for the quick reply. I set these flags now, however there still seem
> to be some problems with readline. The corresponding cofigure output is:
>
> checking readline/history.h usability... yes
> checking readline/history.h presence... yes
> checking for readline/history.h... yes
> checking readline/readline.h usability... yes
> checking readline/readline.h presence... yes
> checking for readline/readline.h... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... no
> checking for main in -ltermcap... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and headers/libs are not
> available

What does config.log say?  It looks like it is not finding libreadline.so.
You may need LD_LIBRARY_PATH set to include where it is.

> The existing compiler is gcc version 2.8.1 and the linker editor used by gcc

Wow, that is really old!

> is an IRIX ld version 7.30. By the way I had read the installation manual
> and already patched readline 5.1.
>
>>> --with-readline         use readline library (if available) [yes]
>
> The lpack linking
>
> --with-lapack="-L/path/to/libs -llapack -lcblas"
>
> was the reason why I thought I could at least give it a try with the command
>
> --with-readline="-L/$HOME/vol/readline"
>
> However, I admit I missed the passage about the LDFLAGS and should have
> search more thoroughly in the docu. Still I'm a little bit confused where
> the current remaining problem is. I gave it a try with readline 5.0, which
> seem to me to be the newest version not needing any patches, same problem.
> Is this some compiler and linker problem?
>
> regards,
> benjamin
>
>
> which was the reason why I thought I could give it
>
>
>> -----Original Message-----
>> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>> Sent: 02 February 2006 14:39
>> To: Benjamin Otto
>> Cc: r-devel at stat.math.ethz.ch
>> Subject: Re: [R] readline detection problems
>>
>>
>> Moved to R-devel: please see the posting guide.  This WAY off topic for
>> R-help.
>>
>> Please do read the installation manual:  configure --help says
>>
>>    --with-readline         use readline library (if available) [yes]
>>
>> and note, no path can be specified.  The installation manual says
>>
>>    If you have libraries and header files, e.g., for GNU readline, in
>>    non-system directories, use the variables LDFLAGS (for libraries, using
>>    `-L' flags to be passed to the linker) and CPPFLAGS (for header files,
>>    using `-I' flags to be passed to the C/C++ preprocessors),
>> respectively,
>>    to specify these locations. These default to LDFLAGS=-L/usr/local/lib
>>    (/usr/local/lib64 on most 64-bit Linux OSes) and
>>    CPPFLAGS=-I/usr/local/include to catch the most common cases.
>>
>> My guess is that you need something like
>>
>> CPPFLAGS=-I/usr/local/include -I/home3/fa/faga001/vol/readline-5.1/include
>> LDFLAGS=-L/usr/local/lib -L/home3/fa/faga001/vol/readline-5.1/lib
>>
>> If this really is readline-5.1, don't use it.  It needs a patch
>> (I believe
>> the one found on the GNU mirror suffices) or it is badly broken,
>> enough to
>> crash the calling application.
>>
>>
>> On Thu, 2 Feb 2006, Benjamin Otto wrote:
>>
>>> Dear community,
>>>
>>> I'm trying to install R-2.2.1 on an IRIX 6.2 (Unix System V Release 4)
>>> system without root access. Unfortunately readline is not installed in
>>> default, so I installed it locally in my home directory, more
>> precisely in:
>>> $HOME/vol/readline-5.1, where $HOME is "/home3/fa/faga001". Afterwards I
>>> appended the path to the library with several $PATH variable, which now
>>> looks like:
>>>
>>>
>> PATH=:/usr/sbin:/usr/bsd:/sbin:/usr/bin:/bin:/usr/bin/X11:/usr/loc
>> al/bin:/us
>>>
>> r/freeware/bin:/usr/local/bin:.:/home3/fa/faga001/vol:/home3/fa/fa
>> ga001/vol/
>>> readline-5.1:/home3/fa/faga001/vol/readline-5.1/lib
>>>
>>> Still, readline is not detected by the configure script. I tried the
>>> commands:
>>>
>>> ./configure --with-readline="-L/$HOME/vol/readline"
>>> ./configure --with-readline="/$HOME/vol/readline"
>>> ./configure --with-readline=/$HOME/vol/readline
>>> ./configure --x-includes="-L/$HOME/vol/readline"
>>> ./configure --x-includes="/$HOME/vol/readline"
>>> ./configure --x-libraries="-L/$HOME/vol/readline"
>>> ./configure --x-libraries="/$HOME/vol/readline"
>>>
>>> trying out the different path variants which I previously
>> included in the
>>> $PATH variable. Nothing helps yet. According to printenv there
>> is currently
>>> no kind of $LIBRARY or sth. like that defined, but maybe the path should
>>> rather be included in such an env. variable, I didn't find any
>> hint in the
>>> documentation.
>>>
>>> Has someone an idea how I should link my local readline
>> correctly, so that
>>> the library is found not only during installtion but afterwards too?
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Fri Feb  3 14:33:40 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 03 Feb 2006 13:33:40 +0000
Subject: [Rd] [R] readline detection problems
In-Reply-To: <Pine.LNX.4.61.0602031304320.23095@gannet.stats>
References: <NOEOKKCPBGIAIPPDONMGEEGOCBAA.b.otto@uke.uni-hamburg.de>
	<Pine.LNX.4.61.0602031304320.23095@gannet.stats>
Message-ID: <43E35BB4.9070207@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> On Fri, 3 Feb 2006, Benjamin Otto wrote:
> 
> 
>>Dear Mr. Ripley,
>>
>>thanks for the quick reply. I set these flags now, however there still seem
>>to be some problems with readline. The corresponding cofigure output is:
>>
>>checking readline/history.h usability... yes
>>checking readline/history.h presence... yes
>>checking for readline/history.h... yes
>>checking readline/readline.h usability... yes
>>checking readline/readline.h presence... yes
>>checking for readline/readline.h... yes
>>checking for rl_callback_read_char in -lreadline... no
>>checking for main in -lncurses... no
>>checking for main in -ltermcap... yes
>>checking for rl_callback_read_char in -lreadline... no
>>checking for history_truncate_file... no
>>configure: error: --with-readline=yes (default) and headers/libs are not
>>available
> 
> 
> What does config.log say?  It looks like it is not finding libreadline.so.
> You may need LD_LIBRARY_PATH set to include where it is.

LD_LIBRARY_PATH affects the dynamic link loader, which is probably not
the issue here. the barbaric manipulation of CFLAGS (=-I and -L)
is needed.

>>The existing compiler is gcc version 2.8.1 and the linker editor used by gcc
> 
> 
> Wow, that is really old!

2.8.1 would be pre-cygnus/egcs , 1997-1998 ... should breath down the 
sys-admin's neck to get it upgraded - ncurse, termcap, tcltk, etc
would be rather old as well...


From Ted.Harding at nessie.mcc.ac.uk  Fri Feb  3 15:34:32 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 03 Feb 2006 14:34:32 -0000 (GMT)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
In-Reply-To: <20060203115536.699413F06E@slim.kubism.ku.dk>
Message-ID: <XFMail.060203143432.Ted.Harding@nessie.mcc.ac.uk>

On 03-Feb-06 uht at dfu.min.dk wrote:
> Full_Name: Uffe H?gsbro Thygesen
> Version: 2.2.0
> OS: linux
> Submission from: (NULL) (130.226.135.250)
> 
> 
> Hello all.
> 
>   pbinom(q=0,size=0,prob=0.5)
> 
> returns the value NaN. I had expected the result 1. In fact any
> value for q seems to give an NaN.

Well, "NaN" can make sense since "q=0" refers to a single sampled
value, and there is no value which you can sample from "size=0";
i.e. sampling from "size=0" is a non-event. I think the probability
of a non-event should be NaN, not 1! (But maybe others might argue
that if you try to sample from an empty urn you necessarily get
zero "successes", so p should be 1; but I would counter that you
also necessarily get zero "failures" so q should be 1. I suppose
it may be a matter of whether you regard the "r" of the binomial
distribution as referring to the "identities" of the outcomes
rather than to how many you get of a particular type. Hmmm.)

> Note that
> 
>   dbinom(x=0,size=0,prob=0.5)
> 
> returns the value 1.

That is probably because the .Internal code for pbinom may do
a preliminary test for "x >= size". This also makes sense, for
the cumulative p<dist> for any <dist> with a finite range,
since the answer must then be 1 and a lot of computation would
be saved (likewise returning 0 when x < 0). However, it would
make even more sense to have a preceding test for "size<=0"
and return NaN in that case since, for the same reasons as
above, the result is the probability of a non-event.

(But it depends on your point of view, as above ... However,
surely the two  should be consistent with each other.)

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 03-Feb-06                                       Time: 14:34:28
------------------------------ XFMail ------------------------------


From p.dalgaard at biostat.ku.dk  Fri Feb  3 15:47:07 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Feb 2006 15:47:07 +0100
Subject: [Rd] pbinom with size argument 0 (PR#8560)
In-Reply-To: <XFMail.060203143432.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.060203143432.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <x2psm4v6s4.fsf@viggo.kubism.ku.dk>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> On 03-Feb-06 uht at dfu.min.dk wrote:
> > Full_Name: Uffe H?gsbro Thygesen
> > Version: 2.2.0
> > OS: linux
> > Submission from: (NULL) (130.226.135.250)
> > 
> > 
> > Hello all.
> > 
> >   pbinom(q=0,size=0,prob=0.5)
> > 
> > returns the value NaN. I had expected the result 1. In fact any
> > value for q seems to give an NaN.
> 
> Well, "NaN" can make sense since "q=0" refers to a single sampled
> value, and there is no value which you can sample from "size=0";
> i.e. sampling from "size=0" is a non-event. I think the probability
> of a non-event should be NaN, not 1! (But maybe others might argue
> that if you try to sample from an empty urn you necessarily get
> zero "successes", so p should be 1; but I would counter that you
> also necessarily get zero "failures" so q should be 1. I suppose
> it may be a matter of whether you regard the "r" of the binomial
> distribution as referring to the "identities" of the outcomes
> rather than to how many you get of a particular type. Hmmm.)
> 
> > Note that
> > 
> >   dbinom(x=0,size=0,prob=0.5)
> > 
> > returns the value 1.
> 
> That is probably because the .Internal code for pbinom may do
> a preliminary test for "x >= size". This also makes sense, for
> the cumulative p<dist> for any <dist> with a finite range,
> since the answer must then be 1 and a lot of computation would
> be saved (likewise returning 0 when x < 0). However, it would
> make even more sense to have a preceding test for "size<=0"
> and return NaN in that case since, for the same reasons as
> above, the result is the probability of a non-event.

Once you get your coffee, you'll likely realize that you got your p's
and d's mixed up...

I think Uffe is perfectly right: The result of zero experiments will
be zero successes (and zero failures) with probability 1, so the
cumulative distribution function is a step function with one step at
zero ( == as.numeric(x>=0) ).

 
> (But it depends on your point of view, as above ... However,
> surely the two  should be consistent with each other.)
> 
> Best wishes,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 03-Feb-06                                       Time: 14:34:28
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Ted.Harding at nessie.mcc.ac.uk  Fri Feb  3 16:07:52 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 03 Feb 2006 15:07:52 -0000 (GMT)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
In-Reply-To: <x2psm4v6s4.fsf@viggo.kubism.ku.dk>
Message-ID: <XFMail.060203150752.Ted.Harding@nessie.mcc.ac.uk>

On 03-Feb-06 Peter Dalgaard wrote:
> (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
> 
>> On 03-Feb-06 uht at dfu.min.dk wrote:
>> > Full_Name: Uffe H?gsbro Thygesen
>> > Version: 2.2.0
>> > OS: linux
>> > Submission from: (NULL) (130.226.135.250)
>> > 
>> > 
>> > Hello all.
>> > 
>> >   pbinom(q=0,size=0,prob=0.5)
>> > 
>> > returns the value NaN. I had expected the result 1. In fact any
>> > value for q seems to give an NaN.
>> 
>> Well, "NaN" can make sense since "q=0" refers to a single sampled
>> value, and there is no value which you can sample from "size=0";
>> i.e. sampling from "size=0" is a non-event. I think the probability
>> of a non-event should be NaN, not 1! (But maybe others might argue
>> that if you try to sample from an empty urn you necessarily get
>> zero "successes", so p should be 1; but I would counter that you
>> also necessarily get zero "failures" so q should be 1. I suppose
>> it may be a matter of whether you regard the "r" of the binomial
>> distribution as referring to the "identities" of the outcomes
>> rather than to how many you get of a particular type. Hmmm.)
>> 
>> > Note that
>> > 
>> >   dbinom(x=0,size=0,prob=0.5)
>> > 
>> > returns the value 1.
>> 
>> That is probably because the .Internal code for pbinom may do
>> a preliminary test for "x >= size". This also makes sense, for
>> the cumulative p<dist> for any <dist> with a finite range,
>> since the answer must then be 1 and a lot of computation would
>> be saved (likewise returning 0 when x < 0). However, it would
>> make even more sense to have a preceding test for "size<=0"
>> and return NaN in that case since, for the same reasons as
>> above, the result is the probability of a non-event.
> 
> Once you get your coffee, you'll likely realize that you got
> your p's and d's mixed up...

You're right about the mix-up! (I must mend the pipeline.)

> I think Uffe is perfectly right: The result of zero experiments will
> be zero successes (and zero failures) with probability 1, so the
> cumulative distribution function is a step function with one step at
> zero ( == as.numeric(x>=0) ).

I'm perfectly happy with this argument so long as it leads to
dbinom(x=0,size=0,prob=p)=1 and also pbinom(q=0,size=0,prob=p)=1
(which seems to be what you are arguing too). And I think there
are no traps if p=0 or p=1.

>> (But it depends on your point of view, as above ... However,
>> surely the two  should be consistent with each other.)

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 03-Feb-06                                       Time: 15:07:49
------------------------------ XFMail ------------------------------


From rgentlem at fhcrc.org  Fri Feb  3 17:00:41 2006
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Fri, 03 Feb 2006 08:00:41 -0800
Subject: [Rd] SaveImage, LazyLoad,
 S4 and all that {was "install.R ... files"}
In-Reply-To: <Pine.LNX.4.61.0602031023460.18275@gannet.stats>
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>	<m2ek2mdgvy.fsf@fhcrc.org>	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>	<m2lkwta751.fsf@ziti.local>	<17379.9541.58029.774861@stat.math.ethz.ch>
	<Pine.LNX.4.61.0602031023460.18275@gannet.stats>
Message-ID: <43E37E29.5090905@fhcrc.org>

My understanding, and John or others may correct that, is that you need 
SaveImage if you want to have the class hierarchy and generic functions, 
plus associated methods all created and saved at build time. This is 
basically a sort of compilation step, and IMHO, should always be done 
since it only needs to be done once, rather than every time a package is 
loaded. Note that attaching your methods to other people's generics has 
to happen at load time, since you won't necessarily know where they are 
or even what they are until then (using an import directive may 
alleviate some of those issues but I have not tested just what does and 
does not work currently).

I hope that LazyLoad does what it says it does, that is dissociates the 
value from the symbol in such a way that the value lives on disk until 
it is wanted, but the symbol is available at package load time. I do not 
see how this relates to precomputing an image, and would not be very 
happy if the two ideas became one, they really are different and can be 
used to solve very different problems.

best wishes
  Robert




Prof Brian Ripley wrote:
> The short answer is that there are no known (i.e. documented) differences, 
> and no examples on CRAN which do not work with lazy-loading (except party, 
> which loads the saved image in a test).  And that includes examples of 
> packages which share S4 classes.  But my question was to tease things like 
> this out.
> 
> You do need either SaveImage or LazyLoad in a package that defines S4 
> classes and methods, since SetClass etc break the `rules' for R files in 
> packages in `Writing R Extensions'.
> 
> When I have time I will take a closer look at this example.
> 
> 
> On Fri, 3 Feb 2006, Martin Maechler wrote:
> 
> 
>>>>>>>"Seth" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>>>    on Thu, 02 Feb 2006 11:32:42 -0800 writes:
>>
>>   Seth> Thanks for the explaination of LazyLoad, that's very helpful.
>>   Seth> On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
>>   >> There is no intention to withdraw SaveImage: yes.  Rather, if
>>   >> lazy-loading is not doing a complete job, we could see if it could
>>   >> be improved.
>>
>>   Seth> It seems to me that LazyLoad does something different with respect to
>>   Seth> packages listed in Depends and/or how it interacts with namespaces.
>>
>>   Seth> I'm testing using the Bioconductor package graph and find that if I
>>   Seth> change SaveImage to LazyLoad I get the following:
>>
>>Interesting.
>>
>>I had also the vague feeling that  saveImage  was said to be
>>important when using  S4 classes and methods; particularly when
>>some methods are for generics from a different package/Namespace
>>and other methods for `base' classes (or other classes defined
>>elsewhere).
>>This is the case of 'Matrix', my primary experience here.
>>OTOH, we now only use 'LazyLoad: yes' , not (any more?)
>>'SaveImage: yes' -- and honestly I don't know / remember why.
>>
>>Martin
>>
>>
>>   Seth> ** preparing package for lazy loading
>>   Seth> Error in makeClassRepresentation(Class, properties, superClasses, prototype,  :
>>   Seth> couldn't find function "getuuid"
>>
>>   Seth> Looking at the NAMESPACE for the graph package, it looks like it is
>>   Seth> missing some imports.  I added lines:
>>   Seth> import(Ruuid)
>>   Seth> exportClasses(Ruuid)
>>
>>   Seth> Aside: am I correct in my reading of the extension manual that if one
>>   Seth> uses S4 classes from another package with a namespace, one
>>   Seth> must import the classes and *also* export them?
>>
>>   Seth> Now I see this:
>>
>>   Seth> ** preparing package for lazy loading
>>   Seth> Error in getClass("Ruuid") : "Ruuid" is not a defined class
>>   Seth> Error: unable to load R code in package 'graph'
>>   Seth> Execution halted
>>
>>   Seth> But Ruuid _is_ defined and exported in the Ruuid package.
>>
>>   Seth> Is there a known difference in how dependencies and imports are
>>   Seth> handled with LazyLoad as opposed to SaveImage?
>>
>>   Seth> Thanks,
>>
>>   Seth> + seth
>>
>>
> 
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From sfalcon at fhcrc.org  Fri Feb  3 17:42:44 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 03 Feb 2006 08:42:44 -0800
Subject: [Rd] SaveImage, LazyLoad,
	S4 and all that {was "install.R ... files"}
In-Reply-To: <Pine.LNX.4.61.0602031023460.18275@gannet.stats> (Brian Ripley's
	message of "Fri, 3 Feb 2006 10:28:48 +0000 (GMT)")
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>
	<m2lkwta751.fsf@ziti.local>
	<17379.9541.58029.774861@stat.math.ethz.ch>
	<Pine.LNX.4.61.0602031023460.18275@gannet.stats>
Message-ID: <m2lkws8kcb.fsf@ziti.local>

On  3 Feb 2006, ripley at stats.ox.ac.uk wrote:
> The short answer is that there are no known (i.e. documented)
> differences, and no examples on CRAN which do not work with
> lazy-loading (except party, which loads the saved image in a test).
> And that includes examples of packages which share S4 classes.  But
> my question was to tease things like this out.

The issue I was seeing with the graph packge is caused by the Ruuid
package creating class instances at the C level using MAKE_CLASS.
MAKE_CLASS doesn't know about namespaces and if it gets called when a
package is loaded via an import, the class def will not be found.

With SaveImage *and* listing Ruuid in Depends, the Ruuid package ends
up in the right place for the class def to be found.  If one uses
LazyLoad, the Ruuid package does not end up in the same place.
Similarly, if one only specifies Ruuid in Imports, then both SaveImage
and LazyLoad fail.

I did a quick test of adding R_do_MAKE_CLASS_NS (see below) to allow
one to get class definitions from a specified namespace.  This seems
to work: I can use LazyLoad on a package (graph) that imports a
package that creates class instances in C code (Ruuid).


/* in src/main/objects.c */
SEXP R_do_MAKE_CLASS_NS(char *what, char *where)
{
    static SEXP s_getClass = NULL;
    SEXP val, call, namespace, force;
    if(!what)
	error(_("C level MAKE_CLASS macro called with NULL string pointer"));
    if(!s_getClass)
	s_getClass = Rf_install("getClass");
    PROTECT(force = allocVector(LGLSXP, 1));
    LOGICAL(force)[0] = 0;
    PROTECT(namespace = R_FindNamespace(mkString(where)));
    PROTECT(call = allocVector(LANGSXP, 4));
    SETCAR(call, s_getClass);
    val = CDR(call);
    SETCAR(val, mkString(what));
    val = CDR(val);
    SETCAR(val, force);
    val = CDR(val);
    SETCAR(val, namespace);
    val = eval(call, R_GlobalEnv);
    UNPROTECT(3);
    return(val);
}


+ seth


From helen.mills at yale.edu  Sat Feb  4 14:03:47 2006
From: helen.mills at yale.edu (helen.mills@yale.edu)
Date: Sat,  4 Feb 2006 14:03:47 +0100 (CET)
Subject: [Rd] script window fails to load script (PR#8564)
Message-ID: <20060204130347.15B353EFF9@slim.kubism.ku.dk>

Full_Name: helen mills poulos
Version: 2.2.1
OS: windows
Submission from: (NULL) (68.9.235.48)


When using the randomForest package, I have had problems when running scripts
after r has been open for some time, and after running multiple iterations of
random forest. After about the 4th or 5th time I run a randomForest script from
the script window in r, r just runs an old script that I ran before, rather than
the one I just edited. This happens regardles of whether I send the script using
ctrl r from the script window or I type in the script manually. I end up having
to shut down r and start over again.


From francoisromain at free.fr  Sat Feb  4 15:30:13 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sat, 04 Feb 2006 15:30:13 +0100
Subject: [Rd] javascript device for R
Message-ID: <43E4BA75.20201@free.fr>

Hi,

Has anyone started a javascript device for R.
I don't see something like that googling or at on 
http://www.stat.auckland.ac.nz/~paul/R/devices.html
For example, using that graphics library : 
http://www.walterzorn.com/jsgraphics/jsgraphics_e.htm
(I cc that message to the author.)

ps : this is not a feature request, i will do it. But if someone has 
started that, let me know.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From Friedrich.Leisch at tuwien.ac.at  Sat Feb  4 16:27:33 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Sat, 4 Feb 2006 16:27:33 +0100
Subject: [Rd] Citation of R packages
In-Reply-To: <1578.202.89.153.187.1138576012.squirrel@sqmail.anu.edu.au>
References: <1578.202.89.153.187.1138576012.squirrel@sqmail.anu.edu.au>
Message-ID: <17380.51173.64968.956060@celebrian.ci.tuwien.ac.at>

>>>>> On Mon, 30 Jan 2006 10:06:52 +1100 (EST),
>>>>> John Maindonald (JM) wrote:

  > The bibtex citations provided by citation() do not
  > work all that well in cases where there is no printed
  > document to reference:

That's why there is a warning at the end that they will need manual
editing ... IMHO they at least save you some typing effort in many
cases.

  > (1) A version field is needed, as the note field is
  > required for other purposes, currently trying to
  > sort out nuances that cannot be sorted out in the
  > author list (author, compiler, implementor of R version,
  > contributor, ...) and maybe giving a cross-reference
  > to a book or paper that is somehow relevant.

Why should a reference cross-reference another reference? Could you
give an example?

  > (2) Maybe the author field should be more nuanced, or
  > maybe ...

author fields of bibtex entries have a strict format (names separated
by "and"), what do you mean by "more nuanced"?

  > (3) In compiling a list of packages, name order seems
  > preferable, and one wants the title first (achieved by
  > relocating the format.title field in the manual FUNCTION
  > in the .bst file
  > (4) manual seems not an ideal name for the class, if
  > there is no manual.

A package always has a "reference manual", the concatenated help pages
certainly qualify as such and can be downloaded in PDF format from
CRAN. The ISBN rules even allow to assign an ISBN number to the online
help of a software package which also can serve as the ISBN number of
the *software itself* (which we did for base R).

  > Maybe what is needed is a package or suchlike class,
  > and several alternative .bst files that handle the needed
  > listings.

  > I know at least one other person who is wrestling with
  > this, and others on this list must be wrestling with it.

I am certainly open for discussions and any suggestions for
improvements, but it must be within the standard bibtex entry types,
we cannot write our own entry types and .bst files. Many journals
require the usage of their own (or standard) bibtex styles, and the
entries we produce must work with those. If R creates nonstandard
bibtex entries even more manual work will be necessary in many
cases.

I have no definitive bibtex reference at hand, but the natbib style
files (a very popular collection of bibtex styles, at least I
definitely want to be compatible with those) define

 article
 book
 booklet
 conference  (= alias for inproceedings)
 inbook
 incollection
 inproceedings
 manual
 mastersthesis
 misc
 phdthesis
 proceedings
 techreport
 unpublished

which coincide with the choices the emacs bibtex mode offers. Out of
these only "manual", "misc" and "unpublished" seem appropriate for
packages, and the description suggests to use manual for citing
software manuals, but the definitions of those three are very similar
anyway.

Maybe you could give an example what your candidate for a bibtex entry
for packages should look like?

Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch


From Friedrich.Leisch at tuwien.ac.at  Sat Feb  4 16:57:13 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Sat, 4 Feb 2006 16:57:13 +0100
Subject: [Rd] What about a bib file
In-Reply-To: <Pine.GSO.4.58.0601301729090.20387@capecod.bwh.harvard.edu>
References: <Pine.GSO.4.58.0601301729090.20387@capecod.bwh.harvard.edu>
Message-ID: <17380.52953.532020.941402@celebrian.ci.tuwien.ac.at>

>>>>> On Mon, 30 Jan 2006 17:49:37 -0500 (EST),
>>>>> Vincent Carey 525-2265 (VC5) wrote:

  > Romain Francois suggests that a central bibliographic database
  > (possibly in bibtex format) might be useful for reference inclusion
  > in R package man pages.  This has been discussed by a small
  > group, with one proposal presented for a package-specific bibtex database
  > placed in a dedicated package subdirectory.  Man page references would
  > then cite the sources enumerated in the database using their bibtex
  > tags.  This approach could encourage better annotation and should
  > confer greater accuracy on package:literature referencing.

  > This does not rule out a central archive that might include all the
  > references cited in base man pages.

  > We are doing some work on harvesting the bibliographic citations
  > in man pages in an R distribution, and converting them to a regular
  > format.  The \references section is free form, so the conversion
  > is not trivial, but progress has been made.

  > The infrastructure required to use this approach to propagate
  > (e.g., bibtex-formatted) bibliographic data into the man pages that
  > cite the sources is not yet available, but we hope to have some
  > prototypes in the next month.

Sounds great! The "hardest" parts are probably

1) a bibtex parser in R
2) at least one function converting arbitrary bibtex entries to text,
   i.e., the R equivalent of a .bst file.

(I'm only guessing what such a system would involve).

After looking into it when writing the citation() infrastructure I
decided I don't want to do it and went straight to S objects written
by the package author. All those string replacements and possible LaTeX
markup simply looked like too much effort for just 1-2 entries per
package ;-)

But it would be great to have the above functionality in R, of
course, and "all references" in a package are certainly a larger set
then what citation() should report, making the effort worthwhile.

My only wish is that the bibtex parser returns objects compatible to
class "citation" (either the same class or simple coercion). I
modelled the class after bibtex entries anyway, so that shouldn't be a
restriction (I hope). If we need to modify class "citation" to be
accomodate your needs, please let me know.

Once we can suck bibtex files into R it would be trivial to give users
a choice between writing

 CITATION files in the current form (with the benefit of headers and
 footers)

or

 mark certain entries in the PACKAGE.bib file (whatever its name may be) 
 that they should be reported by citation().

Best,
Fritz

PS: Of course I volunteer to alpha-test any prototypes you have,


From afinley at stat.umn.edu  Sat Feb  4 19:14:34 2006
From: afinley at stat.umn.edu (Andrew Finley)
Date: Sat, 04 Feb 2006 12:14:34 CST
Subject: [Rd] Rprintf loop status does not print under windows
Message-ID: <200602041814.k14IEYSR012282@badlands.software.umn.edu>

Hello,
I am writing a c/c++ extension package that does some mcmc sampling, and
periodically writes the sampling status to the terminal via Rprintf.  So in
my sampling loop I have:

if(status == 100){
  Rprintf("%i...", s);
  status = 0;
}
status++;

Under linux/unix this works fine, but under windows the status is not
printed.  Am I missing something?

Thanks-
Andy

-- 
Andrew Finley, Research Fellow
Department of Forest Resources
College of Natural Resources
University of Minnesota
305 Green Hall
1530 Cleveland Avenue N.
St. Paul, MN 55108

Ph 612-624-1714 office
http://blue.fr.umn.edu/home


From murdoch at stats.uwo.ca  Sat Feb  4 19:22:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Feb 2006 13:22:36 -0500
Subject: [Rd] Rprintf loop status does not print under windows
In-Reply-To: <200602041814.k14IEYSR012282@badlands.software.umn.edu>
References: <200602041814.k14IEYSR012282@badlands.software.umn.edu>
Message-ID: <43E4F0EC.9060108@stats.uwo.ca>

On 2/4/2006 1:14 PM, Andrew Finley wrote:
> Hello,
> I am writing a c/c++ extension package that does some mcmc sampling, and
> periodically writes the sampling status to the terminal via Rprintf.  So in
> my sampling loop I have:
> 
> if(status == 100){
>   Rprintf("%i...", s);
>   status = 0;
> }
> status++;
> 
> Under linux/unix this works fine, but under windows the status is not
> printed.  Am I missing something?

Looks like you have buffering enabled (the default).  In the Misc menu 
item, uncheck "buffered output" and you should see things sooner (but 
slower).

Duncan Murdoch


From andy_liaw at merck.com  Sat Feb  4 19:45:59 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 4 Feb 2006 13:45:59 -0500
Subject: [Rd] Rprintf loop status does not print under windows
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7C7@usctmx1106.merck.com>



> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Saturday, February 04, 2006 1:23 PM
> To: Andrew Finley
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Rprintf loop status does not print under windows
> 
> 
> On 2/4/2006 1:14 PM, Andrew Finley wrote:
> > Hello,
> > I am writing a c/c++ extension package that does some mcmc 
> sampling, and
> > periodically writes the sampling status to the terminal via 
> Rprintf.  So in
> > my sampling loop I have:
> > 
> > if(status == 100){
> >   Rprintf("%i...", s);
> >   status = 0;
> > }
> > status++;
> > 
> > Under linux/unix this works fine, but under windows the 
> status is not
> > printed.  Am I missing something?
> 
> Looks like you have buffering enabled (the default).  In the 
> Misc menu 
> item, uncheck "buffered output" and you should see things sooner (but 
> slower).

... or add something like this in your C code:

#ifdef win32
	    R_FlushConsole();
#endif

Andy
 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ehlers at math.ucalgary.ca  Sat Feb  4 23:05:36 2006
From: ehlers at math.ucalgary.ca (ehlers@math.ucalgary.ca)
Date: Sat,  4 Feb 2006 23:05:36 +0100 (CET)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
Message-ID: <20060204220536.F2C7C33585@slim.kubism.ku.dk>



(Ted Harding) wrote:
> On 03-Feb-06 Peter Dalgaard wrote:
> 
>>(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
>>
>>
>>>On 03-Feb-06 uht at dfu.min.dk wrote:
>>>
>>>>Full_Name: Uffe H?gsbro Thygesen
>>>>Version: 2.2.0
>>>>OS: linux
>>>>Submission from: (NULL) (130.226.135.250)
>>>>
>>>>
>>>>Hello all.
>>>>
>>>>  pbinom(q=0,size=0,prob=0.5)
>>>>
>>>>returns the value NaN. I had expected the result 1. In fact any
>>>>value for q seems to give an NaN.
>>>
>>>Well, "NaN" can make sense since "q=0" refers to a single sampled
>>>value, and there is no value which you can sample from "size=0";
>>>i.e. sampling from "size=0" is a non-event. I think the probability
>>>of a non-event should be NaN, not 1! (But maybe others might argue
>>>that if you try to sample from an empty urn you necessarily get
>>>zero "successes", so p should be 1; but I would counter that you
>>>also necessarily get zero "failures" so q should be 1. I suppose
>>>it may be a matter of whether you regard the "r" of the binomial
>>>distribution as referring to the "identities" of the outcomes
>>>rather than to how many you get of a particular type. Hmmm.)
>>>
>>>
>>>>Note that
>>>>
>>>>  dbinom(x=0,size=0,prob=0.5)
>>>>
>>>>returns the value 1.
>>>
>>>That is probably because the .Internal code for pbinom may do
>>>a preliminary test for "x >= size". This also makes sense, for
>>>the cumulative p<dist> for any <dist> with a finite range,
>>>since the answer must then be 1 and a lot of computation would
>>>be saved (likewise returning 0 when x < 0). However, it would
>>>make even more sense to have a preceding test for "size<=0"
>>>and return NaN in that case since, for the same reasons as
>>>above, the result is the probability of a non-event.
>>
>>Once you get your coffee, you'll likely realize that you got
>>your p's and d's mixed up...
> 
> 
> You're right about the mix-up! (I must mend the pipeline.)
> 
> 
>>I think Uffe is perfectly right: The result of zero experiments will
>>be zero successes (and zero failures) with probability 1, so the
>>cumulative distribution function is a step function with one step at
>>zero ( == as.numeric(x>=0) ).
> 
> 
> I'm perfectly happy with this argument so long as it leads to
> dbinom(x=0,size=0,prob=p)=1 and also pbinom(q=0,size=0,prob=p)=1
> (which seems to be what you are arguing too). And I think there
> are no traps if p=0 or p=1.
> 
> 
>>>(But it depends on your point of view, as above ... However,
>>>surely the two  should be consistent with each other.)
> 
> 
> Ted.

I prefer a (consistent) NaN. What happens to our notion of a
Binomial RV as a sequence of Bernoulli RVs if we permit n=0?
I have never seen (nor contemplated, I confess) the definition
of a Bernoulli RV as anything other than some dichotomous-outcome
one-trial random experiment. Not n trials, where n might equal zero,
but _one_ trial. I can't see what would be gained by permitting a
zero-trial experiment. If we assign probability 1 to each outcome,
we have a problem with the sum of the probabilities.

Peter Ehlers
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 03-Feb-06                                       Time: 15:07:49
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ehlers at math.ucalgary.ca  Sat Feb  4 23:04:58 2006
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Sat, 04 Feb 2006 15:04:58 -0700
Subject: [Rd] pbinom with size argument 0 (PR#8560)
In-Reply-To: <XFMail.060203150752.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.060203150752.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <43E5250A.6080706@math.ucalgary.ca>



(Ted Harding) wrote:
> On 03-Feb-06 Peter Dalgaard wrote:
> 
>>(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
>>
>>
>>>On 03-Feb-06 uht at dfu.min.dk wrote:
>>>
>>>>Full_Name: Uffe H?gsbro Thygesen
>>>>Version: 2.2.0
>>>>OS: linux
>>>>Submission from: (NULL) (130.226.135.250)
>>>>
>>>>
>>>>Hello all.
>>>>
>>>>  pbinom(q=0,size=0,prob=0.5)
>>>>
>>>>returns the value NaN. I had expected the result 1. In fact any
>>>>value for q seems to give an NaN.
>>>
>>>Well, "NaN" can make sense since "q=0" refers to a single sampled
>>>value, and there is no value which you can sample from "size=0";
>>>i.e. sampling from "size=0" is a non-event. I think the probability
>>>of a non-event should be NaN, not 1! (But maybe others might argue
>>>that if you try to sample from an empty urn you necessarily get
>>>zero "successes", so p should be 1; but I would counter that you
>>>also necessarily get zero "failures" so q should be 1. I suppose
>>>it may be a matter of whether you regard the "r" of the binomial
>>>distribution as referring to the "identities" of the outcomes
>>>rather than to how many you get of a particular type. Hmmm.)
>>>
>>>
>>>>Note that
>>>>
>>>>  dbinom(x=0,size=0,prob=0.5)
>>>>
>>>>returns the value 1.
>>>
>>>That is probably because the .Internal code for pbinom may do
>>>a preliminary test for "x >= size". This also makes sense, for
>>>the cumulative p<dist> for any <dist> with a finite range,
>>>since the answer must then be 1 and a lot of computation would
>>>be saved (likewise returning 0 when x < 0). However, it would
>>>make even more sense to have a preceding test for "size<=0"
>>>and return NaN in that case since, for the same reasons as
>>>above, the result is the probability of a non-event.
>>
>>Once you get your coffee, you'll likely realize that you got
>>your p's and d's mixed up...
> 
> 
> You're right about the mix-up! (I must mend the pipeline.)
> 
> 
>>I think Uffe is perfectly right: The result of zero experiments will
>>be zero successes (and zero failures) with probability 1, so the
>>cumulative distribution function is a step function with one step at
>>zero ( == as.numeric(x>=0) ).
> 
> 
> I'm perfectly happy with this argument so long as it leads to
> dbinom(x=0,size=0,prob=p)=1 and also pbinom(q=0,size=0,prob=p)=1
> (which seems to be what you are arguing too). And I think there
> are no traps if p=0 or p=1.
> 
> 
>>>(But it depends on your point of view, as above ... However,
>>>surely the two  should be consistent with each other.)
> 
> 
> Ted.

I prefer a (consistent) NaN. What happens to our notion of a
Binomial RV as a sequence of Bernoulli RVs if we permit n=0?
I have never seen (nor contemplated, I confess) the definition
of a Bernoulli RV as anything other than some dichotomous-outcome
one-trial random experiment. Not n trials, where n might equal zero,
but _one_ trial. I can't see what would be gained by permitting a
zero-trial experiment. If we assign probability 1 to each outcome,
we have a problem with the sum of the probabilities.

Peter Ehlers
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 03-Feb-06                                       Time: 15:07:49
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jfox at mcmaster.ca  Sun Feb  5 00:28:42 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 4 Feb 2006 18:28:42 -0500
Subject: [Rd] Using the lazy data mechanism
Message-ID: <20060204232842.TYLX17035.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear list members,

I'm trying to use the lazy data mechanism with the car package, so far
without success. The data sets are in the source package's data subdirectory
in the form of compressed .rda files, and I added the directive LazyData:
yes to the package's DESCRIPTION file.

I suspect that the problem is that the package has no namespace, but I've
been unable to find a reference in the Writing R Extensions manual (nor
elsewhere) that suggests that this is necessary. Is there a place that I've
missed that describes the lazy data mechanism?

My system info:

----- snip -----

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:MASS, package:car, package:methods, package:stats,
package:graphics, package:grDevices, package:utils, package:datasets,
package:svIO, package:R2HTML, package:svMisc, package:svSocket,
package:svIDE, package:tcltk, Autoloads, package:base

----- snip -----

Thanks,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox


From p.dalgaard at biostat.ku.dk  Sun Feb  5 01:33:31 2006
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Sun,  5 Feb 2006 01:33:31 +0100 (CET)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
Message-ID: <20060205003331.A5F6B33585@slim.kubism.ku.dk>

P Ehlers <ehlers at math.ucalgary.ca> writes:

> I prefer a (consistent) NaN. What happens to our notion of a
> Binomial RV as a sequence of Bernoulli RVs if we permit n=0?
> I have never seen (nor contemplated, I confess) the definition
> of a Bernoulli RV as anything other than some dichotomous-outcome
> one-trial random experiment. 

What's the problem ??

An n=0 binomial is the sum of an empty set of Bernoulli RV's, and the
sum over an empty set is identically 0.

> Not n trials, where n might equal zero,
> but _one_ trial. I can't see what would be gained by permitting a
> zero-trial experiment. If we assign probability 1 to each outcome,
> we have a problem with the sum of the probabilities.

Consistency is what you gain. E.g. 

 binom(.,n=n1+n2,p) == binom(.,n=n1,p) * binom(.,n=n2,p)

where * denotes convolution. This will also hold for n1=0 or n2=0 if
the binomial in that case is defined as a one-point distribution at
zero. Same thing as any(logical(0)) etc., really.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Bill.Venables at csiro.au  Sun Feb  5 07:41:03 2006
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sun, 5 Feb 2006 17:41:03 +1100
Subject: [Rd] a generic 'attach'?
Message-ID: <B998A44C8986644EA8029CFE6396A924546A56@exqld2-bne.qld.csiro.au>

Is there any reason why 'attach' is not generic in R?

I notice that it is in another system, for example, and I can see some
applications if it were so in R.

Bill Venables.


Bill Venables, 
CMIS, CSIRO Laboratories, 
PO Box 120, Cleveland, Qld. 4163 
AUSTRALIA


From ripley at stats.ox.ac.uk  Sun Feb  5 09:23:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 5 Feb 2006 08:23:39 +0000 (GMT)
Subject: [Rd] Using the lazy data mechanism
In-Reply-To: <20060204232842.TYLX17035.tomts5-srv.bellnexxia.net@JohnDesktop8300>
References: <20060204232842.TYLX17035.tomts5-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.61.0602050754070.29538@gannet.stats>

John,

There are lots of examples without a namespace on CRAN.  The first in the 
alphabet (in the C locale) is DAAG.  Another example (but handled 
specially) is package 'datasets'.

Taking the version on CRAN (car_1.0-18) and adding

LazyData: yes
LazyLoad: yes

worked for me (and you don't actually need the second, as it works whether 
or not the R code is lazy-loaded).

Perhaps you can let me know offline what the problems are?

Brian

On Sat, 4 Feb 2006, John Fox wrote:

> Dear list members,
>
> I'm trying to use the lazy data mechanism with the car package, so far
> without success. The data sets are in the source package's data subdirectory
> in the form of compressed .rda files, and I added the directive LazyData:
> yes to the package's DESCRIPTION file.
>
> I suspect that the problem is that the package has no namespace, but I've
> been unable to find a reference in the Writing R Extensions manual (nor
> elsewhere) that suggests that this is necessary. Is there a place that I've
> missed that describes the lazy data mechanism?

There's are article in R-news, but that describes the mechanism per se. 
How to use it is in `Writing R Extensions'.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Sun Feb  5 11:35:27 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Feb 2006 11:35:27 +0100
Subject: [Rd] a generic 'attach'?
In-Reply-To: <B998A44C8986644EA8029CFE6396A924546A56@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A924546A56@exqld2-bne.qld.csiro.au>
Message-ID: <x264nuks9c.fsf@turmalin.kubism.ku.dk>

<Bill.Venables at csiro.au> writes:

> Is there any reason why 'attach' is not generic in R?
> 
> I notice that it is in another system, for example,

I wonder which one? ;-)

> and I can see some
> applications if it were so in R.

I suppose there is no particular reason, except that it was probably
"good enough for now" at some point in time. 

Apropos attach(), and apologies in advance for the lengthy rant that
follows:

There are a couple of other annoyances with the attach/detach
mechanism that could do with a review. In particular, detach() is not
behaving according to documentation (return value is really NULL). I
feel that sensible semantics for editing an attached database and
storing it back would be useful. The current semantics tend to get
people in trouble, and some of the stuff you need to explain really
feels quite odd:

attach(airquality)
airquality$Month <- factor(airquality$Month)
# oops, that's not going to work. You need:
detach(airquality)
attach(airquality)

(notice in particular that this tends to keep two copies of the data
in memory at a time).

You can actually modify a database after attaching it (I'm
deliberately not saying "data frame", because it will not be one at
that stage), but it leads to contorsions like

assign("Month", factor(Month), "airquality")

or

with(pos.to.env(2), Month <- factor(Month))

(or even with(pos.to.env(match("airquality",search())),....))

I've been thinking on and off about these matters. It is a bit tricky
because we'd rather not break codes (and books!) all over the place,
but suppose we 

(a) allowed with() to have its first argument interpreted like the 3rd
    argument in assign()

(b) made detach() do what it claims: return the (possibly modified)
    database. This requires that more metadata are kept around than
    currently. Also, the semantics of 

    attach(airquality)
    assign("foo", function(bar)baz, "airquality") 
    aq <- detach(airquality)

    would need to be sorted out. Presumably "foo" needs to be dropped
    with a warning.

Potentially, one could then also devise mechanisms for load/store
directly to/from the search path.

Alternative ideas include changing the search path itself to be an
actual list of objects (rather than a nesting of environments), but
that leads to the same sort of issues.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Bill.Venables at csiro.au  Sun Feb  5 13:23:17 2006
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sun, 5 Feb 2006 23:23:17 +1100
Subject: [Rd] a generic 'attach'?
Message-ID: <B998A44C8986644EA8029CFE6396A924546A5A@exqld2-bne.qld.csiro.au>

What have I started?  I had nothing anywhere near as radical as that in mind, Peter...

One argument against making 'attach' generic might be that such a move would slow it down a bit, but I can't really see why speed would be much of an issue with 'attach'.

I've noticed that David Brahm's package, g.data, for example really has a method for attach as part of it, (well almost), but he has to calls it g.data.attach.

Another package that has an obvious application for a method for attach is the filehash package of Roger Peng.

And as it happens I have another, but for now I call it 'Attach', which is pretty unsatisfying from an aesthetic point of view.

I think I'll just sew the seed for now.  The thing about generic functions is that if they exist people sometimes find quite innovative uses for them, and if they come at minimal cost, and break no existing code, I suggest we thik about implementing them.

(Notice I have had no need to use a 'compatibility with another system' argument at any stage...)

---

Another, even more minor issue I've wondered about is giving rm() the return value the object, or list of objects, that are removed.  Thus

newName <- rm(object)

would become essentially a renaming of an object in memory.

For some reason I seem to recall that this was indeed a feature of a very early version of the S language, but dropped out (I think) when S3 was introduced.  Have I got that completely wrong?  (I seem to recall a lot of code had to be scrapped at that stage, including something rather reminiscent of the R with(), but I digress...)

Bill.


-----Original Message-----
From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter Dalgaard
Sent: Sunday, 5 February 2006 8:35 PM
To: Venables, Bill (CMIS, Cleveland)
Cc: r-devel at lists.r-project.org
Subject: Re: [Rd] a generic 'attach'?


<Bill.Venables at csiro.au> writes:

> Is there any reason why 'attach' is not generic in R?
> 
> I notice that it is in another system, for example,

I wonder which one? ;-)

> and I can see some
> applications if it were so in R.

I suppose there is no particular reason, except that it was probably
"good enough for now" at some point in time. 

Apropos attach(), and apologies in advance for the lengthy rant that
follows:

There are a couple of other annoyances with the attach/detach
mechanism that could do with a review. In particular, detach() is not
behaving according to documentation (return value is really NULL). I
feel that sensible semantics for editing an attached database and
storing it back would be useful. The current semantics tend to get
people in trouble, and some of the stuff you need to explain really
feels quite odd:

attach(airquality)
airquality$Month <- factor(airquality$Month)
# oops, that's not going to work. You need:
detach(airquality)
attach(airquality)

(notice in particular that this tends to keep two copies of the data
in memory at a time).

You can actually modify a database after attaching it (I'm
deliberately not saying "data frame", because it will not be one at
that stage), but it leads to contorsions like

assign("Month", factor(Month), "airquality")

or

with(pos.to.env(2), Month <- factor(Month))

(or even with(pos.to.env(match("airquality",search())),....))

I've been thinking on and off about these matters. It is a bit tricky
because we'd rather not break codes (and books!) all over the place,
but suppose we 

(a) allowed with() to have its first argument interpreted like the 3rd
    argument in assign()

(b) made detach() do what it claims: return the (possibly modified)
    database. This requires that more metadata are kept around than
    currently. Also, the semantics of 

    attach(airquality)
    assign("foo", function(bar)baz, "airquality") 
    aq <- detach(airquality)

    would need to be sorted out. Presumably "foo" needs to be dropped
    with a warning.

Potentially, one could then also devise mechanisms for load/store
directly to/from the search path.

Alternative ideas include changing the search path itself to be an
actual list of objects (rather than a nesting of environments), but
that leads to the same sort of issues.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Sun Feb  5 14:12:33 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 5 Feb 2006 13:12:33 +0000 (GMT)
Subject: [Rd] a generic 'attach'?
In-Reply-To: <B998A44C8986644EA8029CFE6396A924546A5A@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A924546A5A@exqld2-bne.qld.csiro.au>
Message-ID: <Pine.LNX.4.61.0602051238100.3459@gannet.stats>

What are you proposing the generic be, and how should it be described?

Most of the currrent attach seems to be general, the only parts which are 
specific to save() images and lists are

         value <- .Internal(attach(NULL, pos, name))
         load(what, envir = as.environment(pos))
     }
     else value <- .Internal(attach(what, pos, name))

So maybe it is not attach() but some internal version of it (which 
populates a frame on the search list) which needs to be generic.  Indeed. 
dbLoad() in pkg filehash looks just what one wants here.

[That code is a bit strange: is not 'value' the environment into which you 
want to load things?  So why go via as.environment?]

The devil is in the `well almost'.

On Sun, 5 Feb 2006 Bill.Venables at csiro.au wrote:

> What have I started?  I had nothing anywhere near as radical as that in 
> mind, Peter...
>
> One argument against making 'attach' generic might be that such a move 
> would slow it down a bit, but I can't really see why speed would be much 
> of an issue with 'attach'.

Speed is not an issue.  The major issue in making a function generic is 
describing what a generic function is required to do (including what it is 
required to return), and thereby ensuring that you do not break existing 
code without unduly limiting future uses.

> I've noticed that David Brahm's package, g.data, for example really has 
> a method for attach as part of it, (well almost), but he has to calls it 
> g.data.attach.

Another candidate is lazyload/lazydata databases.

> Another package that has an obvious application for a method for attach 
> is the filehash package of Roger Peng.
>
> And as it happens I have another, but for now I call it 'Attach', which 
> is pretty unsatisfying from an aesthetic point of view.
>
> I think I'll just sew the seed for now.  The thing about generic 
> functions is that if they exist people sometimes find quite innovative 
> uses for them, and if they come at minimal cost, and break no existing 
> code, I suggest we thik about implementing them.
>
> (Notice I have had no need to use a 'compatibility with another system' 
> argument at any stage...)

A good point, as it is not actually documented to be generic under that 
systems, as far as I can see.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rpeng at jhsph.edu  Sun Feb  5 15:17:27 2006
From: rpeng at jhsph.edu (Roger Peng)
Date: Sun, 05 Feb 2006 09:17:27 -0500
Subject: [Rd] a generic 'attach'?
In-Reply-To: <B998A44C8986644EA8029CFE6396A924546A5A@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A924546A5A@exqld2-bne.qld.csiro.au>
Message-ID: <43E608F7.4010303@jhsph.edu>

I think having a generic attach might be useful in the end.  But I agree 
that some more thought needs to go into how such a generic would behave. 
  I've always avoided using `attach()' precisely because I didn't fully 
understand the semantics.

One related possibility would be to create a method for `with()' (which 
is already generic) which would work on (in my case) "filehash" 
databases.  It still wouldn't be quite as nice as `attach()' for 
interactive work but it could serve some purposes.

-roger

Bill.Venables at csiro.au wrote:
> What have I started?  I had nothing anywhere near as radical as that
> in mind, Peter...
> 
> One argument against making 'attach' generic might be that such a
> move would slow it down a bit, but I can't really see why speed would
> be much of an issue with 'attach'.
> 
> I've noticed that David Brahm's package, g.data, for example really
> has a method for attach as part of it, (well almost), but he has to
> calls it g.data.attach.
> 
> Another package that has an obvious application for a method for
> attach is the filehash package of Roger Peng.
> 
> And as it happens I have another, but for now I call it 'Attach',
> which is pretty unsatisfying from an aesthetic point of view.
> 
> I think I'll just sew the seed for now.  The thing about generic
> functions is that if they exist people sometimes find quite
> innovative uses for them, and if they come at minimal cost, and break
> no existing code, I suggest we thik about implementing them.
> 
> (Notice I have had no need to use a 'compatibility with another
> system' argument at any stage...)
> 
> ---
> 
> Another, even more minor issue I've wondered about is giving rm() the
> return value the object, or list of objects, that are removed.  Thus
> 
> newName <- rm(object)
> 
> would become essentially a renaming of an object in memory.
> 
> For some reason I seem to recall that this was indeed a feature of a
> very early version of the S language, but dropped out (I think) when
> S3 was introduced.  Have I got that completely wrong?  (I seem to
> recall a lot of code had to be scrapped at that stage, including
> something rather reminiscent of the R with(), but I digress...)
> 
> Bill.
> 
> 
> -----Original Message----- From: pd at pubhealth.ku.dk
> [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter Dalgaard Sent: Sunday,
> 5 February 2006 8:35 PM To: Venables, Bill (CMIS, Cleveland) Cc:
> r-devel at lists.r-project.org Subject: Re: [Rd] a generic 'attach'?
> 
> 
> <Bill.Venables at csiro.au> writes:
> 
> 
>> Is there any reason why 'attach' is not generic in R?
>> 
>> I notice that it is in another system, for example,
> 
> 
> I wonder which one? ;-)
> 
> 
>> and I can see some applications if it were so in R.
> 
> 
> I suppose there is no particular reason, except that it was probably 
> "good enough for now" at some point in time.
> 
> Apropos attach(), and apologies in advance for the lengthy rant that 
> follows:
> 
> There are a couple of other annoyances with the attach/detach 
> mechanism that could do with a review. In particular, detach() is not
>  behaving according to documentation (return value is really NULL). I
>  feel that sensible semantics for editing an attached database and 
> storing it back would be useful. The current semantics tend to get 
> people in trouble, and some of the stuff you need to explain really 
> feels quite odd:
> 
> attach(airquality) airquality$Month <- factor(airquality$Month) #
> oops, that's not going to work. You need: detach(airquality) 
> attach(airquality)
> 
> (notice in particular that this tends to keep two copies of the data 
> in memory at a time).
> 
> You can actually modify a database after attaching it (I'm 
> deliberately not saying "data frame", because it will not be one at 
> that stage), but it leads to contorsions like
> 
> assign("Month", factor(Month), "airquality")
> 
> or
> 
> with(pos.to.env(2), Month <- factor(Month))
> 
> (or even with(pos.to.env(match("airquality",search())),....))
> 
> I've been thinking on and off about these matters. It is a bit tricky
>  because we'd rather not break codes (and books!) all over the place,
>  but suppose we
> 
> (a) allowed with() to have its first argument interpreted like the
> 3rd argument in assign()
> 
> (b) made detach() do what it claims: return the (possibly modified) 
> database. This requires that more metadata are kept around than 
> currently. Also, the semantics of
> 
> attach(airquality) assign("foo", function(bar)baz, "airquality") aq
> <- detach(airquality)
> 
> would need to be sorted out. Presumably "foo" needs to be dropped 
> with a warning.
> 
> Potentially, one could then also devise mechanisms for load/store 
> directly to/from the search path.
> 
> Alternative ideas include changing the search path itself to be an 
> actual list of objects (rather than a nesting of environments), but 
> that leads to the same sort of issues.
> 
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Sun Feb  5 16:50:30 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 5 Feb 2006 15:50:30 +0000 (GMT)
Subject: [Rd] SaveImage, LazyLoad,
 S4 and all that {was "install.R ... files"}
In-Reply-To: <43E37E29.5090905@fhcrc.org>
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>
	<m2lkwta751.fsf@ziti.local>
	<17379.9541.58029.774861@stat.math.ethz.ch>
	<Pine.LNX.4.61.0602031023460.18275@gannet.stats>
	<43E37E29.5090905@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0602031637550.25945@gannet.stats>

On Fri, 3 Feb 2006, Robert Gentleman wrote:

> My understanding, and John or others may correct that, is that you need 
> SaveImage if you want to have the class hierarchy and generic functions, plus 
> associated methods all created and saved at build time.

That meaning the time of using R CMD INSTALL rather than using R CMD 
build, I guess?  (We do have an unfortunate ambiguity.)

> This is basically a sort of compilation step, and IMHO, should always be 
> done since it only needs to be done once, rather than every time a 
> package is loaded. Note that attaching your methods to other people's 
> generics has to happen at load time, since you won't necessarily know 
> where they are or even what they are until then (using an import 
> directive may alleviate some of those issues but I have not tested just 
> what does and does not work currently).

My understanding is that `compilation step' creates objects which are then 
saved in the image.  Such objects would also be saved if the image is 
converted into a lazyload database.

> I hope that LazyLoad does what it says it does, that is dissociates the value 
> from the symbol in such a way that the value lives on disk until it is 
> wanted, but the symbol is available at package load time. I do not see how 
> this relates to precomputing an image,

You obviously have this defined a different way to me: I believe (and so 
does my dictionary) that the image is what I save in my camera, not the 
real world scene.  I understand 'save' to save an image of an environment, 
that is to make a representation on a connection that can be used to 
recreate the environment at a later date.

> and would not be very happy if the two ideas became one, they really are 
> different and can be used to solve very different problems.

To create a lazyload database you first need an environment to save. On 
loading the package it then recreates not the environment but symbols 
linked to promises that will recreate the values at a later date.  So both 
mechanisms create an environment which they `image' in different ways.

The difference here is an inadvertent difference in the Unix INSTALL 
script, which I have now corrected.


> Prof Brian Ripley wrote:
>> The short answer is that there are no known (i.e. documented) differences, 
>> and no examples on CRAN which do not work with lazy-loading (except party, 
>> which loads the saved image in a test).  And that includes examples of 
>> packages which share S4 classes.  But my question was to tease things like 
>> this out.
>> 
>> You do need either SaveImage or LazyLoad in a package that defines S4 
>> classes and methods, since SetClass etc break the `rules' for R files in 
>> packages in `Writing R Extensions'.
>> 
>> When I have time I will take a closer look at this example.
>> 
>> 
>> On Fri, 3 Feb 2006, Martin Maechler wrote:
>> 
>> 
>>>>>>>> "Seth" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>>>>    on Thu, 02 Feb 2006 11:32:42 -0800 writes:
>>> 
>>>   Seth> Thanks for the explaination of LazyLoad, that's very helpful.
>>>   Seth> On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
>>>   >> There is no intention to withdraw SaveImage: yes.  Rather, if
>>>   >> lazy-loading is not doing a complete job, we could see if it could
>>>   >> be improved.
>>> 
>>>   Seth> It seems to me that LazyLoad does something different with respect 
>>> to
>>>   Seth> packages listed in Depends and/or how it interacts with 
>>> namespaces.
>>> 
>>>   Seth> I'm testing using the Bioconductor package graph and find that if 
>>> I
>>>   Seth> change SaveImage to LazyLoad I get the following:
>>> 
>>> Interesting.
>>> 
>>> I had also the vague feeling that  saveImage  was said to be
>>> important when using  S4 classes and methods; particularly when
>>> some methods are for generics from a different package/Namespace
>>> and other methods for `base' classes (or other classes defined
>>> elsewhere).
>>> This is the case of 'Matrix', my primary experience here.
>>> OTOH, we now only use 'LazyLoad: yes' , not (any more?)
>>> 'SaveImage: yes' -- and honestly I don't know / remember why.
>>> 
>>> Martin
>>> 
>>> 
>>>   Seth> ** preparing package for lazy loading
>>>   Seth> Error in makeClassRepresentation(Class, properties, superClasses, 
>>> prototype,  :
>>>   Seth> couldn't find function "getuuid"
>>> 
>>>   Seth> Looking at the NAMESPACE for the graph package, it looks like it 
>>> is
>>>   Seth> missing some imports.  I added lines:
>>>   Seth> import(Ruuid)
>>>   Seth> exportClasses(Ruuid)
>>> 
>>>   Seth> Aside: am I correct in my reading of the extension manual that if 
>>> one
>>>   Seth> uses S4 classes from another package with a namespace, one
>>>   Seth> must import the classes and *also* export them?
>>> 
>>>   Seth> Now I see this:
>>> 
>>>   Seth> ** preparing package for lazy loading
>>>   Seth> Error in getClass("Ruuid") : "Ruuid" is not a defined class
>>>   Seth> Error: unable to load R code in package 'graph'
>>>   Seth> Execution halted
>>> 
>>>   Seth> But Ruuid _is_ defined and exported in the Ruuid package.
>>> 
>>>   Seth> Is there a known difference in how dependencies and imports are
>>>   Seth> handled with LazyLoad as opposed to SaveImage?
>>> 
>>>   Seth> Thanks,
>>> 
>>>   Seth> + seth

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Feb  5 17:01:27 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 5 Feb 2006 16:01:27 +0000 (GMT)
Subject: [Rd] The install.R and R_PROFILE.R files
In-Reply-To: <m2lkwta751.fsf@ziti.local>
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>
	<m2lkwta751.fsf@ziti.local>
Message-ID: <Pine.LNX.4.61.0602051557200.24093@gannet.stats>

I had a bumpy ride with this one.

Ruuid/src/Makefile.win refers to src/include, which is not in a binary 
distribution so cannot be installed from an installed version of R 2.2.1. 
(That's a bug report.)

graph throws an S4 signature error in R-devel.

After fixing those, it works with LazyLoad on Windows but not in Unix 
where there is an error in the INSTALL script which I have now fixed.


On Thu, 2 Feb 2006, Seth Falcon wrote:

> Thanks for the explaination of LazyLoad, that's very helpful.
>
> On  1 Feb 2006, ripley at stats.ox.ac.uk wrote:
>> There is no intention to withdraw SaveImage: yes.  Rather, if
>> lazy-loading is not doing a complete job, we could see if it could
>> be improved.
>
> It seems to me that LazyLoad does something different with respect to
> packages listed in Depends and/or how it interacts with namespaces.
>
> I'm testing using the Bioconductor package graph and find that if I
> change SaveImage to LazyLoad I get the following:
>
>   ** preparing package for lazy loading
>   Error in makeClassRepresentation(Class, properties, superClasses, prototype,  :
>           couldn't find function "getuuid"
>
> Looking at the NAMESPACE for the graph package, it looks like it is
> missing some imports.  I added lines:
>  import(Ruuid)
>  exportClasses(Ruuid)
>
> Aside: am I correct in my reading of the extension manual that if one
> uses S4 classes from another package with a namespace, one
> must import the classes and *also* export them?
>
> Now I see this:
>
>    ** preparing package for lazy loading
>    Error in getClass("Ruuid") : "Ruuid" is not a defined class
>    Error: unable to load R code in package 'graph'
>    Execution halted
>
> But Ruuid _is_ defined and exported in the Ruuid package.
>
> Is there a known difference in how dependencies and imports are
> handled with LazyLoad as opposed to SaveImage?
>
> Thanks,
>
> + seth
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From uht at dfu.min.dk  Sun Feb  5 21:39:36 2006
From: uht at dfu.min.dk (=?iso-8859-1?Q?Uffe_H=F8gsbro_Thygesen?=)
Date: Sun, 5 Feb 2006 21:39:36 +0100
Subject: [Rd] pbinom with size argument 0 (PR#8560)
Message-ID: <8CDDBB8CAC32F34B809EB4A677952B4BA54E8A@ch-mail01.dfu.local>

Hello all

A pragmatic argument for allowing size==0 is the situation where the size is in itself a random variable (that's how I stumbled over the inconsistency, by the way).

For example, in textbooks on probability it is stated that:

  If X is Poisson(lambda), and the conditional 
  distribution of Y given X is Binomial(X,p), then 
  Y is Poisson(lambda*p).

(cf eg Pitman's "Probability", p. 400)

Clearly this statement requires Binomial(0,p) to be a well-defined distribution.

Such statements would be quite convoluted if we did not define Binomial(0,p) as a legal (but degenerate) distribution. The same applies to codes where the size parameter may attain the value 0.

Just my 2 cents.

Cheers,

Uffe


-----Oprindelig meddelelse-----
Fra: pd at pubhealth.ku.dk p? vegne af Peter Dalgaard
Sendt: s? 05-02-2006 01:33
Til: P Ehlers
Cc: ted.harding at nessie.mcc.ac.uk; Peter Dalgaard; R-bugs at biostat.ku.dk; r-devel at stat.math.ethz.ch; Uffe H?gsbro Thygesen
Emne: Re: [Rd] pbinom with size argument 0 (PR#8560)
 
P Ehlers <ehlers at math.ucalgary.ca> writes:

> I prefer a (consistent) NaN. What happens to our notion of a
> Binomial RV as a sequence of Bernoulli RVs if we permit n=0?
> I have never seen (nor contemplated, I confess) the definition
> of a Bernoulli RV as anything other than some dichotomous-outcome
> one-trial random experiment. 

What's the problem ??

An n=0 binomial is the sum of an empty set of Bernoulli RV's, and the
sum over an empty set is identically 0.

> Not n trials, where n might equal zero,
> but _one_ trial. I can't see what would be gained by permitting a
> zero-trial experiment. If we assign probability 1 to each outcome,
> we have a problem with the sum of the probabilities.

Consistency is what you gain. E.g. 

 binom(.,n=n1+n2,p) == binom(.,n=n1,p) * binom(.,n=n2,p)

where * denotes convolution. This will also hold for n1=0 or n2=0 if
the binomial in that case is defined as a one-point distribution at
zero. Same thing as any(logical(0)) etc., really.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From uht at dfu.min.dk  Sun Feb  5 21:40:20 2006
From: uht at dfu.min.dk (uht@dfu.min.dk)
Date: Sun,  5 Feb 2006 21:40:20 +0100 (CET)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
Message-ID: <20060205204020.D68EE3EFFD@slim.kubism.ku.dk>

Hello all

A pragmatic argument for allowing size=3D=3D0 is the situation where the =
size is in itself a random variable (that's how I stumbled over the =
inconsistency, by the way).

For example, in textbooks on probability it is stated that:

  If X is Poisson(lambda), and the conditional=20
  distribution of Y given X is Binomial(X,p), then=20
  Y is Poisson(lambda*p).

(cf eg Pitman's "Probability", p. 400)

Clearly this statement requires Binomial(0,p) to be a well-defined =
distribution.

Such statements would be quite convoluted if we did not define =
Binomial(0,p) as a legal (but degenerate) distribution. The same applies =
to codes where the size parameter may attain the value 0.

Just my 2 cents.

Cheers,

Uffe


-----Oprindelig meddelelse-----
Fra: pd at pubhealth.ku.dk p=E5 vegne af Peter Dalgaard
Sendt: s=F8 05-02-2006 01:33
Til: P Ehlers
Cc: ted.harding at nessie.mcc.ac.uk; Peter Dalgaard; R-bugs at biostat.ku.dk; =
r-devel at stat.math.ethz.ch; Uffe H=F8gsbro Thygesen
Emne: Re: [Rd] pbinom with size argument 0 (PR#8560)
=20
P Ehlers <ehlers at math.ucalgary.ca> writes:

> I prefer a (consistent) NaN. What happens to our notion of a
> Binomial RV as a sequence of Bernoulli RVs if we permit n=3D0?
> I have never seen (nor contemplated, I confess) the definition
> of a Bernoulli RV as anything other than some dichotomous-outcome
> one-trial random experiment.=20

What's the problem ??

An n=3D0 binomial is the sum of an empty set of Bernoulli RV's, and the
sum over an empty set is identically 0.

> Not n trials, where n might equal zero,
> but _one_ trial. I can't see what would be gained by permitting a
> zero-trial experiment. If we assign probability 1 to each outcome,
> we have a problem with the sum of the probabilities.

Consistency is what you gain. E.g.=20

 binom(.,n=3Dn1+n2,p) =3D=3D binom(.,n=3Dn1,p) * binom(.,n=3Dn2,p)

where * denotes convolution. This will also hold for n1=3D0 or n2=3D0 if
the binomial in that case is defined as a one-point distribution at
zero. Same thing as any(logical(0)) etc., really.

--=20
   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) =
35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) =
35327907


From tshort at eprisolutions.com  Sun Feb  5 21:31:00 2006
From: tshort at eprisolutions.com (Tom Short)
Date: Sun, 5 Feb 2006 20:31:00 +0000 (UTC)
Subject: [Rd] javascript device for R
References: <43E4BA75.20201@free.fr>
Message-ID: <loom.20060205T212400-654@post.gmane.org>

Romain Francois <francoisromain <at> free.fr> writes:

> 
> Hi,
> 
> Has anyone started a javascript device for R.
> I don't see something like that googling or at on 
> http://www.stat.auckland.ac.nz/~paul/R/devices.html
> For example, using that graphics library : 
> http://www.walterzorn.com/jsgraphics/jsgraphics_e.htm
> (I cc that message to the author.)
> 
> ps : this is not a feature request, i will do it. But if someone has 
> started that, let me know.
> 
> Romain
> 

Not that I know of, but here are some pointers that might get you started.
Here's an example of a graph in SVG done in the Dojo javascript toolkit:

http://archive.dojotoolkit.org/nightly/tests/widget/test_Chart.html

The idea is that it generates SVG for SVG-capable browsers and VML for Internet
Explorer (although I don't think they finished the IE part yet).

Another option is to use the canvas tag available in Firefox and Safari. You can
use this to emulate the canvas tag in IE:

http://me.eae.net/archive/2005/12/29/canvas-in-ie/

- Tom


From david.meyer at wu-wien.ac.at  Mon Feb  6 00:53:14 2006
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Mon, 6 Feb 2006 00:53:14 +0100
Subject: [Rd] e1071: using svm with sparse matrices (PR#8527)
Message-ID: <20060206005314.6836e132.david.meyer@wu-wien.ac.at>

> 
> First: this is not a bug, more a feature request.

[not in R as correctly pointed out, so just for the records:]

It _is_ a bug (in e1071), since svm() is indeed supposed to support
sparse data. The bug was introduced in 1.5-9 I think when support for
correct na-handling was added. The bug will be fixed in 1.5-13.

Thanks for pointing this out!

David.

> 
> Secondly, even if it was a bug, it is _not_ a bug in R, please read  
> the posting rules for bugs. Now a member of R-core has to use  
> valuable time to clean up after your bug report.
> 
> Correspondence such as this such really be sent to the package  
> maintainers (and - perhaps - a cc to R-devel).
> 
> Having said all of this, of course it would be nice if svn supported  
> sparse matrices.

> Libsvm, the `engine' underneath svm() in `e1071', uses a sparse
> representation of the data.  I vaguely recall seeing Chih-Jen Lin's code
> that uses the SparseM package to pass sparse data to svm()...  David would
> know best, of course.

> Andy

 
> /Kasper
> 
> 
> On Jan 27, 2006, at 2:02 AM, julien.gagneur at embl.de wrote:
> 
> > Full_Name: Julien Gagneur
> > Version: 2.2.1
> > OS: Linux (Suse 9.3)
> > Submission from: (NULL) (194.94.44.4)
> >
> >
> > Using the SparseM library (SparseM_0.66)
> > and the e1071 library (e1071_1.5-12)
> >
> >
> > I fail using svm method with a sparse matrix. Here is a sample  
> > example.
> >
> > I experienced the same problem under Windows.
> >
> >
> >
> >> library(SparseM)
> > [1] "SparseM library loaded"
> >> library("e1071")
> > Loading required package: class
> >> data(iris)
> >> attach(iris)
> >> M=as.matrix(iris[,1:4])
> >> Msparse=as.matrix.csr(M)
> >> Species=iris[,5]
> >> mod=svm(Msparse,Species)
> > Error in svm.default(Msparse, Species) : object "nac" not found
> >


From p.dalgaard at biostat.ku.dk  Sun Feb  5 01:33:05 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Feb 2006 01:33:05 +0100
Subject: [Rd] pbinom with size argument 0 (PR#8560)
In-Reply-To: <43E5250A.6080706@math.ucalgary.ca>
References: <XFMail.060203150752.Ted.Harding@nessie.mcc.ac.uk>
	<43E5250A.6080706@math.ucalgary.ca>
Message-ID: <x2u0bey79a.fsf@turmalin.kubism.ku.dk>

P Ehlers <ehlers at math.ucalgary.ca> writes:

> I prefer a (consistent) NaN. What happens to our notion of a
> Binomial RV as a sequence of Bernoulli RVs if we permit n=0?
> I have never seen (nor contemplated, I confess) the definition
> of a Bernoulli RV as anything other than some dichotomous-outcome
> one-trial random experiment. 

What's the problem ??

An n=0 binomial is the sum of an empty set of Bernoulli RV's, and the
sum over an empty set is identically 0.

> Not n trials, where n might equal zero,
> but _one_ trial. I can't see what would be gained by permitting a
> zero-trial experiment. If we assign probability 1 to each outcome,
> we have a problem with the sum of the probabilities.

Consistency is what you gain. E.g. 

 binom(.,n=n1+n2,p) == binom(.,n=n1,p) * binom(.,n=n2,p)

where * denotes convolution. This will also hold for n1=0 or n2=0 if
the binomial in that case is defined as a one-point distribution at
zero. Same thing as any(logical(0)) etc., really.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Ancelet at engref.fr  Mon Feb  6 10:50:36 2006
From: Ancelet at engref.fr (Sophie Ancelet)
Date: Mon, 06 Feb 2006 10:50:36 +0100
Subject: [Rd] Troubles with Fortran and C (was with the function
 rmultinom.c of the R's Random Number Generator)
In-Reply-To: <Pine.LNX.4.61.0601201653420.23380@gannet.stats>
References: <3.0.6.32.20060120164501.007c4c90@Tilia.engref.fr>
	<3.0.6.32.20060120164501.007c4c90@Tilia.engref.fr>
Message-ID: <3.0.6.32.20060206105036.007d53e0@Tilia.engref.fr>



Thank you for the answer. However, I sought in Doc. Writing R
extensions, in particular in the paragraph 5.6 "Calling C from FORTRAN
and vice versa" (page 67) but I did not find anything which could help me to
correct my code. Indeed, rmultinom.c is a particular function
since arrays are passed in arguments. Has somebody ever
written a wrapper for this function?

Thanks in advance,
Sophie. 



At 17:06 20/01/06 +0000, Prof Brian Ripley wrote:
>All arguments to functions called from C by Fortran are pointers
>(or should be: yours are not).  The error is within your own code.
>
>You don't want to call rndstart and rndend around every call, only before 
>the first and after the last.
>
>This is not the list for advice om mixed Fortran/C programming, though.




>On Fri, 20 Jan 2006, Sophie Ancelet wrote:
>
>>
>> Hi,
>>
>> I'm simulating a Markov chain in Fortran interfaced with R-2.2.1 in order
>> to generate data according to a Markov Random Field called the Potts model.
>>
>> R Version:
>> platform i686-pc-linux-gnu
>> arch     i686
>> os       linux-gnu
>> system   i686, linux-gnu
>> status
>> major    2
>> minor    2.1
>> year     2005
>> month    12
>> day      20
>> svn rev  36812
>>
>>
>>
>>
>> Each loop of my Fortran calls the function rmultinom.c of the R's Random
>> Number Generator through the wrapper:
>>
>> #include <R.h>
>> #include <Rmath.h>
>> void F77_SUB(sarmultinom)(int n,
>>                          double* prob,
>>                          int K,
>>                          int* rN){
>> rmultinom(n, prob, K, rN);}
>>
>>
>>
>> My fortran program is:
>>
>> subroutine testsarmultinom(n,prob,K,rN)
>> implicit none
>> integer n,K,rN(K)
>> double precision prob(K)
>>
>> call rndstart()
>> call sarmultinom(n,prob,K,rN)
>> call rndend()
>> end
>>
>>
>> In order to understand better how the function rmultinom.c works, I have
>> written an R code which calls this fortran subroutine as follows:
>>
>> system("R CMD SHLIB test-multinom.f wrapper.c")
>> dyn.load("~/Package/test/test-multinom.so")
>>
>> n=1
>> prob=c(0.6,0.1,0.3)
>> K=3
>> rN=c(1,0,0)
>> res<- .Fortran("testsarmultinom",
>>               as.integer(n),
>>               as.double(prob),
>>               as.integer(K),
>>               as.integer(rN))
>>
>>
>> Unfortunately, I have some trouble with the results. First, this command
>> always returns 0 values. In other words, I always get:
>>
>>> res[[4]]
>> [1] 0 0 0
>>
>>
>> Moreover, if I run this R code a second time, an error message appears:
>> Segmentation fault.
>>
>> Has somebody ever used rmultinom.c and encountered these problems? My code
>> must be wrong but I don't know where. In this case, what is the correct way
>> to call the C function rmultinom.c?
>>
>> Thanks in advance,
>>
>> Sophie.


From ripley at stats.ox.ac.uk  Mon Feb  6 10:51:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Feb 2006 09:51:36 +0000 (GMT)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
In-Reply-To: <x2u0bey79a.fsf@turmalin.kubism.ku.dk>
References: <XFMail.060203150752.Ted.Harding@nessie.mcc.ac.uk>
	<43E5250A.6080706@math.ucalgary.ca>
	<x2u0bey79a.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0602060939040.11949@gannet.stats>

On Sun, 5 Feb 2006, Peter Dalgaard wrote:

> P Ehlers <ehlers at math.ucalgary.ca> writes:
>
>> I prefer a (consistent) NaN. What happens to our notion of a
>> Binomial RV as a sequence of Bernoulli RVs if we permit n=0?
>> I have never seen (nor contemplated, I confess) the definition
>> of a Bernoulli RV as anything other than some dichotomous-outcome
>> one-trial random experiment.
>
> What's the problem ??
>
> An n=0 binomial is the sum of an empty set of Bernoulli RV's, and the
> sum over an empty set is identically 0.
>
>> Not n trials, where n might equal zero,
>> but _one_ trial. I can't see what would be gained by permitting a
>> zero-trial experiment. If we assign probability 1 to each outcome,
>> we have a problem with the sum of the probabilities.
>
> Consistency is what you gain. E.g.
>
> binom(.,n=n1+n2,p) == binom(.,n=n1,p) * binom(.,n=n2,p)
>
> where * denotes convolution. This will also hold for n1=0 or n2=0 if
> the binomial in that case is defined as a one-point distribution at
> zero. Same thing as any(logical(0)) etc., really.

Consistency is a Good Thing, and I had already altered the codebase to 
consistently allow size=0 as a discrete distribution concentrated at 0.

There were other inconsistencies, e.g. whether the geometric/negative 
binomial functions allow prob=0 or prob=1.  I have no problem with prob=1 
(it is a discrete distribution concentrated on one point) and this was 
addressed for rnbinom before (PR#1218) but subsequently broken (which is 
why we like regression tests ...).  However prob=0 does not correspond to 
a proper distribution unless Inf is allowed as a value, and it was not so 
documented (nor implemented).  Indeed we had

> dgeom(2, prob=0)
[1] 0
> dgeom(Inf, prob=0)
[1] 0
> pgeom(Inf, prob=0)
[1] 0

and in fact dgeom gave zero for every allowed value.  So I cannot accept 
that as being right (and we even have a d-p-q-r test with prob=0).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Ted.Harding at nessie.mcc.ac.uk  Mon Feb  6 11:10:22 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 06 Feb 2006 10:10:22 -0000 (GMT)
Subject: [Rd] pbinom with size argument 0 (PR#8560)
In-Reply-To: <20060205204020.D68EE3EFFD@slim.kubism.ku.dk>
Message-ID: <XFMail.060206101022.Ted.Harding@nessie.mcc.ac.uk>

On 05-Feb-06 uht at dfu.min.dk wrote:
> Hello all
> 
> A pragmatic argument for allowing size=3D=3D0 is the situation where
> the size is in itself a random variable (that's how I stumbled over
> the inconsistency, by the way).
> 
> For example, in textbooks on probability it is stated that:
> 
>   If X is Poisson(lambda), and the conditional=20
>   distribution of Y given X is Binomial(X,p), then=20
>   Y is Poisson(lambda*p).
> 
> (cf eg Pitman's "Probability", p. 400)
> 
> Clearly this statement requires Binomial(0,p) to be a well-defined
> distribution.
> 
> Such statements would be quite convoluted if we did not define
> Binomial(0,p) as a legal (but degenerate) distribution. The same
> applies to codes where the size parameter may attain the value 0.
> 
> Just my 2 cents.
> 
> Cheers,
> 
> Uffe

Uffe's pragmatic argument is of course convincing at least in
the circumstances he refers to. However, Peter Ehlers' posting
has re-stimulated the underlying ambiguity I feel about this
issue (intially, that the probability of a "non-event" should
be undefined).

Thus I can envisage different circumatances in which one or the
other view could be appropriate.

Uffe observes a Poisson-distributed number of Bernoulli trials
and records the number of "successes", with zero if the Poisson
distribution says "zero trials". In that case no Bernoulli trial
has been carried out, so the issue of what the distribution over
its empty set of outcomes should be is irrelevant. However, he
can encapsulate this process mathematically by assigning P=1
to the outcome r=0 when n=0, and this may well lead to a more
straightforward R program, for instance (which, reading between
the lines, may well be what really happened in his case).

On the other hand, suppose I (and maybe Peter Ehlers too) am
simulating a study in which random numbers (according to some
distribution) of subjects become available, in each "sweep" of the
study, for questionnaire, and the outcome of interest is the
number in the "sweep" answering "Yes" to a question. Part of this
simulation is to create a database of responses along with concomitant
variables. It is possible (and under some circumstances perhaps more
likely) that the number of available subjects in a "sweep" is zero --
these people cannot be contacted, say.

Maybe I'm studying a "missing data" situation.

In that case it would be natural to enter "r=NA" in the
database for those sweeps which produces no responses. This
would denote "missing data". And natural also to (initially,
before embarking on say an imputation exercise) to attribute
"P=NA" to the probability of "Yes" for such a group since
we do not have any direct information (though may be able to
exploit associations between other variables to obtain indirect
information, under certain assumptions).

So maybe one could need implementations of pbinom and dbinom
which work differently in different circumstances. But what
remains important is that, whichever way they work in given
circumstances, they should be consistent with each other.

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 06-Feb-06                                       Time: 10:10:19
------------------------------ XFMail ------------------------------


From Ancelet at engref.fr  Mon Feb  6 11:30:29 2006
From: Ancelet at engref.fr (Sophie Ancelet)
Date: Mon, 06 Feb 2006 11:30:29 +0100
Subject: [Rd] Troubles with the function rmultinom.c of the R's Random
 Number Generator
Message-ID: <3.0.6.32.20060206113029.007c2d70@Tilia.engref.fr>


Thank you for the answer. However, I sought in Doc. Writing R
extensions, in particular in the paragraph 5.6 "Calling C from FORTRAN
and vice versa" (page 67) but I did not find anything which could help me to
correct my code. Indeed, rmultinom.c is a particular function
since arrays are passed in arguments. Has somebody ever
written a wrapper for this function?

Thanks in advance,
Sophie. 



At 17:06 20/01/06 +0000, Prof Brian Ripley wrote:
>All arguments to functions called from C by Fortran are pointers
>(or should be: yours are not).  The error is within your own code.
>
>You don't want to call rndstart and rndend around every call, only before 
>the first and after the last.
>
>This is not the list for advice om mixed Fortran/C programming, though.




>On Fri, 20 Jan 2006, Sophie Ancelet wrote:
>
>>
>> Hi,
>>
>> I'm simulating a Markov chain in Fortran interfaced with R-2.2.1 in order
>> to generate data according to a Markov Random Field called the Potts model.
>>
>> R Version:
>> platform i686-pc-linux-gnu
>> arch     i686
>> os       linux-gnu
>> system   i686, linux-gnu
>> status
>> major    2
>> minor    2.1
>> year     2005
>> month    12
>> day      20
>> svn rev  36812
>>
>>
>>
>>
>> Each loop of my Fortran calls the function rmultinom.c of the R's Random
>> Number Generator through the wrapper:
>>
>> #include <R.h>
>> #include <Rmath.h>
>> void F77_SUB(sarmultinom)(int n,
>>                          double* prob,
>>                          int K,
>>                          int* rN){
>> rmultinom(n, prob, K, rN);}
>>
>>
>>
>> My fortran program is:
>>
>> subroutine testsarmultinom(n,prob,K,rN)
>> implicit none
>> integer n,K,rN(K)
>> double precision prob(K)
>>
>> call rndstart()
>> call sarmultinom(n,prob,K,rN)
>> call rndend()
>> end
>>
>>
>> In order to understand better how the function rmultinom.c works, I have
>> written an R code which calls this fortran subroutine as follows:
>>
>> system("R CMD SHLIB test-multinom.f wrapper.c")
>> dyn.load("~/Package/test/test-multinom.so")
>>
>> n=1
>> prob=c(0.6,0.1,0.3)
>> K=3
>> rN=c(1,0,0)
>> res<- .Fortran("testsarmultinom",
>>               as.integer(n),
>>               as.double(prob),
>>               as.integer(K),
>>               as.integer(rN))
>>
>>
>> Unfortunately, I have some trouble with the results. First, this command
>> always returns 0 values. In other words, I always get:
>>
>>> res[[4]]
>> [1] 0 0 0
>>
>>
>> Moreover, if I run this R code a second time, an error message appears:
>> Segmentation fault.
>>
>> Has somebody ever used rmultinom.c and encountered these problems? My code
>> must be wrong but I don't know where. In this case, what is the correct way
>> to call the C function rmultinom.c?
>>
>> Thanks in advance,
>>
>> Sophie.


From hin-tak.leung at cimr.cam.ac.uk  Mon Feb  6 12:08:39 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 06 Feb 2006 11:08:39 +0000
Subject: [Rd] Troubles with the function rmultinom.c of the R's Random
 Number Generator
In-Reply-To: <3.0.6.32.20060206113029.007c2d70@Tilia.engref.fr>
References: <3.0.6.32.20060206113029.007c2d70@Tilia.engref.fr>
Message-ID: <43E72E37.7040701@cimr.cam.ac.uk>

Sophie Ancelet wrote:
> Thank you for the answer. However, I sought in Doc. Writing R
> extensions, in particular in the paragraph 5.6 "Calling C from FORTRAN
> and vice versa" (page 67) but I did not find anything which could help me to
> correct my code. Indeed, rmultinom.c is a particular function
> since arrays are passed in arguments. Has somebody ever
> written a wrapper for this function?

You probably haven't managed to digest what Prof Ripley was writing: 
"All arguments to functions called from C by Fortran are pointers
(or should be: yours are not)" - here is a more hand-holding kind
of answer, which is exactly the same advice, really - you need to
be doing something like this (note the pointers) instead:

 >>>void F77_SUB(sarmultinom)(int *n,
 >>>                         double** prob,
 >>>                         int *K,
 >>>                         int** rN){
 >>>rmultinom(n, prob, K, rN);}

I'll be interested to see what breaks - do you mind sending me
both of test-multinom.f wrapper.c direct for me to have a look?

HTL

> At 17:06 20/01/06 +0000, Prof Brian Ripley wrote:
> 
>>All arguments to functions called from C by Fortran are pointers
>>(or should be: yours are not).  The error is within your own code.
>>
>>You don't want to call rndstart and rndend around every call, only before 
>>the first and after the last.
>>
>>This is not the list for advice om mixed Fortran/C programming, though.
> 
> 
> 
> 
> 
>>On Fri, 20 Jan 2006, Sophie Ancelet wrote:
>>
>>
>>>Hi,
>>>
>>>I'm simulating a Markov chain in Fortran interfaced with R-2.2.1 in order
>>>to generate data according to a Markov Random Field called the Potts model.
>>>
>>>R Version:
>>>platform i686-pc-linux-gnu
>>>arch     i686
>>>os       linux-gnu
>>>system   i686, linux-gnu
>>>status
>>>major    2
>>>minor    2.1
>>>year     2005
>>>month    12
>>>day      20
>>>svn rev  36812
>>>
>>>
>>>
>>>
>>>Each loop of my Fortran calls the function rmultinom.c of the R's Random
>>>Number Generator through the wrapper:
>>>
>>>#include <R.h>
>>>#include <Rmath.h>
>>>void F77_SUB(sarmultinom)(int n,
>>>                         double* prob,
>>>                         int K,
>>>                         int* rN){
>>>rmultinom(n, prob, K, rN);}
>>>
>>>
>>>
>>>My fortran program is:
>>>
>>>subroutine testsarmultinom(n,prob,K,rN)
>>>implicit none
>>>integer n,K,rN(K)
>>>double precision prob(K)
>>>
>>>call rndstart()
>>>call sarmultinom(n,prob,K,rN)
>>>call rndend()
>>>end
>>>
>>>
>>>In order to understand better how the function rmultinom.c works, I have
>>>written an R code which calls this fortran subroutine as follows:
>>>
>>>system("R CMD SHLIB test-multinom.f wrapper.c")
>>>dyn.load("~/Package/test/test-multinom.so")
>>>
>>>n=1
>>>prob=c(0.6,0.1,0.3)
>>>K=3
>>>rN=c(1,0,0)
>>>res<- .Fortran("testsarmultinom",
>>>              as.integer(n),
>>>              as.double(prob),
>>>              as.integer(K),
>>>              as.integer(rN))
>>>
>>>
>>>Unfortunately, I have some trouble with the results. First, this command
>>>always returns 0 values. In other words, I always get:
>>>
>>>
>>>>res[[4]]
>>>
>>>[1] 0 0 0
>>>
>>>
>>>Moreover, if I run this R code a second time, an error message appears:
>>>Segmentation fault.
>>>
>>>Has somebody ever used rmultinom.c and encountered these problems? My code
>>>must be wrong but I don't know where. In this case, what is the correct way
>>>to call the C function rmultinom.c?
>>>
>>>Thanks in advance,
>>>
>>>Sophie.
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From stvjc at channing.harvard.edu  Mon Feb  6 18:04:27 2006
From: stvjc at channing.harvard.edu (Vincent Carey 525-2265)
Date: Mon, 6 Feb 2006 12:04:27 -0500 (EST)
Subject: [Rd] extending "list" in S4: loss of element names
Message-ID: <Pine.GSO.4.58.0602061149260.7709@capecod.bwh.harvard.edu>


using R 2.3 of 1/31/06

> new("list")
list()
> new("list", list(a=1))
$a
[1] 1

> setClass("listlike", contains="list")
[1] "listlike"
> new("listlike", list(a=1))
An object of class "listlike"
[[1]]
[1] 1

Why does the list in the second construction lose
the element name?  A workaround is to endow the
listlike class with a names slot, but it would
be nice for the names to be propagated from the
data to the object.

Loss of names in a numeric construction does
not require extension:
> new("numeric", c(a=1))
[1] 1

But coercion can allow names to persist.
> as(c(a=1), "numeric")
a
1


From sfalcon at fhcrc.org  Mon Feb  6 18:14:49 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 06 Feb 2006 09:14:49 -0800
Subject: [Rd] The install.R and R_PROFILE.R files
In-Reply-To: <Pine.LNX.4.61.0602051557200.24093@gannet.stats> (Brian Ripley's
	message of "Sun, 5 Feb 2006 16:01:27 +0000 (GMT)")
References: <Pine.LNX.4.61.0601311817010.20339@gannet.stats>
	<m2ek2mdgvy.fsf@fhcrc.org>
	<Pine.LNX.4.61.0602020703420.9210@gannet.stats>
	<m2lkwta751.fsf@ziti.local>
	<Pine.LNX.4.61.0602051557200.24093@gannet.stats>
Message-ID: <m2wtg8l88m.fsf@ziti.local>

On  5 Feb 2006, ripley at stats.ox.ac.uk wrote:
> I had a bumpy ride with this one.
>
> Ruuid/src/Makefile.win refers to src/include, which is not in a
> binary distribution so cannot be installed from an installed version
> of R 2.2.1. (That's a bug report.)

Thanks for the report, this has been fixed in the devel version of
Ruuid.

> graph throws an S4 signature error in R-devel.

Also fixed in devel, thanks.

> After fixing those, it works with LazyLoad on Windows but not in
> Unix where there is an error in the INSTALL script which I have now
> fixed.

Excellent, thanks.  

+ seth


From Alexander.Holzbach at ifr.uni-karlsruhe.de  Mon Feb  6 19:11:19 2006
From: Alexander.Holzbach at ifr.uni-karlsruhe.de (Alexander.Holzbach@ifr.uni-karlsruhe.de)
Date: Mon,  6 Feb 2006 19:11:19 +0100 (CET)
Subject: [Rd] saving PDF with multiple diagrams results in crash (PR#8569)
Message-ID: <20060206181119.B9978398DC@slim.kubism.ku.dk>

Full_Name: Alexander Holzbach
Version: 2.2.0
OS: Mac OS X 10.3.9
Submission from: (NULL) (129.13.186.1)


when i build an area with multiple diagrams (par(mfrow=c(1,3)) ) and try to save
this to a pdf via "save as.." or by setting pdf("filename") r crashes
reproducable.


From simon.urbanek at r-project.org  Mon Feb  6 19:30:22 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 6 Feb 2006 13:30:22 -0500
Subject: [Rd] saving PDF with multiple diagrams results in crash
	(PR#8569)
In-Reply-To: <20060206181119.B9978398DC@slim.kubism.ku.dk>
References: <20060206181119.B9978398DC@slim.kubism.ku.dk>
Message-ID: <3FC73F3E-3B64-4F34-9196-42F8A9127E3B@r-project.org>


On Feb 6, 2006, at 1:11 PM, Alexander.Holzbach at ifr.uni-karlsruhe.de  
wrote:

> Full_Name: Alexander Holzbach
> Version: 2.2.0
> OS: Mac OS X 10.3.9
> Submission from: (NULL) (129.13.186.1)
>
>
> when i build an area with multiple diagrams (par(mfrow=c(1,3)) )  
> and try to save
> this to a pdf via "save as.." or by setting pdf("filename") r crashes
> reproducable.

Firstly, please update at least to R 2.2.1 before reporting bugs  
(preferably to R-patched). Secondly, can you, please, send us exactly  
the code you use (and/or exactly the steps you take)? I'm not able to  
reproduce it in R 2.2.1 from your brief description.

Thanks,
Simon


From sfalcon at fhcrc.org  Mon Feb  6 20:21:53 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 06 Feb 2006 11:21:53 -0800
Subject: [Rd] match gets confused by S4 objects
Message-ID: <m2hd7cjnse.fsf@ziti.local>

If one accidentally calls match(x, obj), where obj is any S4 instance,
the result is NA.  

I was expecting an error because, in general, if a match method is not
defined for a particular S4 class, I don't know what a reasonable
default could be.  Specifically, here's what I see

setClass("FOO", representation(a="numeric"))
foo <- new("FOO", a=10)
match("a", foo)
[1] NA

And my thinking is that this should be an error, along the lines of
match("a", function(x) x)

Unless, of course, a specific method for match, table="FOO" has been
defined.

+ seth


From ripley at stats.ox.ac.uk  Mon Feb  6 20:44:50 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Feb 2006 19:44:50 +0000 (GMT)
Subject: [Rd] match gets confused by S4 objects
In-Reply-To: <m2hd7cjnse.fsf@ziti.local>
References: <m2hd7cjnse.fsf@ziti.local>
Message-ID: <Pine.LNX.4.61.0602061925190.4469@gannet.stats>

An S4 object is just a list with attributes, so a vector type.  match() 
works with all vector types including lists, as you found out (or could 
have read).

If in the future those proposing it do re-implement an S4 object as an new 
SEXP then this will change, but for now the cost of detecting objects 
which might have an S4 class defined somewhere is just too high (and would 
fall on those who do not use S4 classes).

On Mon, 6 Feb 2006, Seth Falcon wrote:

> If one accidentally calls match(x, obj), where obj is any S4 instance,
> the result is NA.
>
> I was expecting an error because, in general, if a match method is not
> defined for a particular S4 class, I don't know what a reasonable
> default could be.  Specifically, here's what I see
>
> setClass("FOO", representation(a="numeric"))
> foo <- new("FOO", a=10)
> match("a", foo)
> [1] NA
>
> And my thinking is that this should be an error, along the lines of
> match("a", function(x) x)
>
> Unless, of course, a specific method for match, table="FOO" has been
> defined.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Tue Feb  7 00:12:23 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 6 Feb 2006 18:12:23 -0500
Subject: [Rd] invalid graphics state using dev.print
In-Reply-To: <02575270-8477-48E4-97AD-03BC127B0FBE@houston.rr.com>
References: <02575270-8477-48E4-97AD-03BC127B0FBE@houston.rr.com>
Message-ID: <24E8DC10-8C07-4E1A-93F6-E462CB1E96BB@r-project.org>

Paul,

On Feb 6, 2006, at 5:24 PM, Paul Roebuck wrote:

> Tried on R-Sig-Mac with no responses, but I need some kind of answer.
> [...]
> Does the following work on your system?

Interesting, no, it doesn't either. For png and pdf I use Quartz +  
quartz.save (it produces much nicer results) so I didn't really  
notice, but you're right. First I thought those graphics state issues  
are specific to the Quartz device, but you have proven that it's not.  
It's in fact not even Mac-specific - I have just reproduced it on a  
Linux box - that's why I'm moving this to R-devel.

Here is a small reproducible example:
x11()
plot(rnorm(10))
dev.print(png)

I'll try to have a look at it later today, but I can't promise anything.

Cheers,
Simon


From mbeason at harrahs.com  Tue Feb  7 01:41:52 2006
From: mbeason at harrahs.com (Matthew Beason)
Date: Mon, 6 Feb 2006 16:41:52 -0800
Subject: [Rd] [R] R compile on AIX 5.2
Message-ID: <E153C65077E0034E97A981C6CE26F1BD03A9D94E@ENTWMAIL1A.harrahs.org>

Professor Ripley,

	Following your advice, I am now using an updated version of gcc
(4.0.2 to be exact) as well as a true fortran compiler (XL Fortran
Compiler v10.1.0.0 from IBM). I am still experiencing difficulty in
running "make" after a successful "configure". Any additional insight
you could provide would be greatly appreciated. Output of make is as
follows:

 Running Make R-2.2.1:

/home/mbeason/work/R-2.2.1/src/main
        /usr/local/bin/gcc -Wl,-brtl -Wl,-bdynamic
-Wl,-bE:../../etc/R.exp -Wl,-bM:SRE -L/usr/local/lib -o R.bin  Rmain.o
CConverters.o CommandLineArgs.o Rdynload.o Renviron.o RNG.o apply.o
arithmetic.o apse.o array.o attrib.o base.o bind.o builtin.o character.o
coerce.o colors.o complex.o connections.o context.o cov.o cum.o dcf.o
datetime.o debug.o deparse.o deriv.o dotcode.o dounzip.o dstruct.o
duplicate.o engine.o envir.o errors.o eval.o format.o fourier.o
gevents.o gram.o gram-ex.o graphics.o identical.o internet.o iosupport.o
lapack.o list.o logic.o main.o mapply.o match.o memory.o model.o names.o
objects.o optim.o optimize.o options.o par.o paste.o pcre.o platform.o
plot.o plot3d.o plotmath.o print.o printarray.o printvector.o
printutils.o qsort.o random.o regex.o registration.o relop.o saveload.o
scan.o seq.o serialize.o size.o sort.o source.o split.o sprintf.o
startup.o subassign.o subscript.o subset.o summary.o sysutils.o unique.o
util.o version.o vfonts.o xxxpr.o ../unix/libunix.a ../appl/libappl.a
../nmath/libnmath.a   -lg -lxlf90 -L/usr/lpp/xlf/lib -lxlopt -lxlf
-lxlomp_ser -lm /lib/crt0.o ../extra/zlib/libz.a ../extra/bzip2/libbz2.a
../extra/pcre/libpcre.a -lintl -lreadline  -ldl -lm -lc -liconv
ld: 0711-317 ERROR: Undefined symbol: ch2inv
ld: 0711-317 ERROR: Undefined symbol: chol
ld: 0711-317 ERROR: Undefined symbol: cg
ld: 0711-317 ERROR: Undefined symbol: ch
ld: 0711-317 ERROR: Undefined symbol: rg
ld: 0711-317 ERROR: Undefined symbol: rs
ld: 0711-317 ERROR: Undefined symbol: dchdc
ld: 0711-317 ERROR: Undefined symbol: dpbfa
ld: 0711-317 ERROR: Undefined symbol: dpbsl
ld: 0711-317 ERROR: Undefined symbol: dpoco
ld: 0711-317 ERROR: Undefined symbol: dpodi
ld: 0711-317 ERROR: Undefined symbol: dpofa
ld: 0711-317 ERROR: Undefined symbol: dposl
ld: 0711-317 ERROR: Undefined symbol: dqrcf
ld: 0711-317 ERROR: Undefined symbol: dqrdc
ld: 0711-317 ERROR: Undefined symbol: dqrdc2
ld: 0711-317 ERROR: Undefined symbol: dqrls
ld: 0711-317 ERROR: Undefined symbol: dqrsl
ld: 0711-317 ERROR: Undefined symbol: dqrqty
ld: 0711-317 ERROR: Undefined symbol: dqrqy
ld: 0711-317 ERROR: Undefined symbol: dqrrsd
ld: 0711-317 ERROR: Undefined symbol: dqrxb
ld: 0711-317 ERROR: Undefined symbol: dsvdc
ld: 0711-317 ERROR: Undefined symbol: dtrsl
ld: 0711-317 ERROR: Undefined symbol: dtrco
ld: 0711-317 ERROR: Undefined symbol: lminfl
ld: 0711-317 ERROR: Undefined symbol: .zgemm
ld: 0711-317 ERROR: Undefined symbol: .dsyrk
ld: 0711-317 ERROR: Undefined symbol: .dtrsm
ld: 0711-317 ERROR: Undefined symbol: .dcopy
ld: 0711-317 ERROR: Undefined symbol: .dtrsl
ld: 0711-317 ERROR: Undefined symbol: .ddot
ld: 0711-317 ERROR: Undefined symbol: .dnrm2
ld: 0711-317 ERROR: Undefined symbol: .dscal
ld: 0711-317 ERROR: Undefined symbol: .daxpy
ld: 0711-317 ERROR: Undefined symbol: .dpofa
ld: 0711-317 ERROR: Undefined symbol: .intpr0_
ld: 0711-317 ERROR: Undefined symbol: .i_len
ld: 0711-317 ERROR: Undefined symbol: .realp0_
ld: 0711-317 ERROR: Undefined symbol: .dblep0_
ld: 0711-317 ERROR: Undefined symbol: .rexitc_
ld: 0711-317 ERROR: Undefined symbol: .rwarnc_
ld: 0711-317 ERROR: Undefined symbol: .xerbla_
ld: 0711-317 ERROR: Undefined symbol: .d_sign
ld: 0711-317 ERROR: Undefined symbol: .d_cnjg
ld: 0711-345 Use the -bloadmap or -bnoquiet option to obtain more
information.
collect2: ld returned 8 exit status
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 2.


Stop.
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 1.


Stop.

Running make with R-devel_2006-02-05:

/home/mbeason/work/R-devel/src/appl
        f95   -g -c ch2inv.f -o ch2inv.o
"ch2inv.f", line 1.2: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 2.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 3.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 4.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 5.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 6.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 7.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 7.39: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 8.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 9.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 9.41: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 10.8: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 11.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 12.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 13.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 13.38: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 14.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 15.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 16.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 17.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 18.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 18.32: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 19.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 20.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 21.2: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 22.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 23.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 24.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 25.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 26.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 27.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 28.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 29.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 30.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 30.30: 1515-018 (S) Incorrect character found in source
at line 30 in column 30.  Hexadecimal value of character is 7B.
"ch2inv.f", line 30.39: 1515-018 (S) Incorrect character found in source
at line 30 in column 39.  Hexadecimal value of character is 7D.
"ch2inv.f", line 31.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 32.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 33.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 34.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 35.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 36.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 37.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 38.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 39.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 40.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 41.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 42.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 43.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 44.0: 1515-010 (S) String is missing a closing
delimiter.  Closing delimiter assumed at end of line.
"ch2inv.f", line 44.4: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 45.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 46.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 47.3: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 48.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", 1515-002 (S) END card is missing.  One is assumed.
** _main   === End of Compilation 1 ===
"ch2inv.f", line 50.7: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 51.6: 1514-050 (S) Specification statement is out of
order.  Statement is ignored.
"ch2inv.f", line 52.6: 1514-050 (S) Specification statement is out of
order.  Statement is ignored.
"ch2inv.f", line 53.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 54.6: 1514-050 (S) Specification statement is out of
order.  Statement is ignored.
"ch2inv.f", line 55.6: 1514-050 (S) Specification statement is out of
order.  Statement is ignored.
"ch2inv.f", line 56.1: 1515-019 (S) Syntax is incorrect.
"ch2inv.f", line 63.11: 1515-025 (S) Only a name of a variable, array
element, or character substring is permitted on the left hand side of an
assignment statement.
"ch2inv.f", line 66.18: 1516-040 (S) Item has not been defined with the
EXTERNAL or INTRINSIC attribute.
"ch2inv.f", line 70.11: 1515-025 (S) Only a name of a variable, array
element, or character substring is permitted on the left hand side of an
assignment statement.
** ch2inv   === End of Compilation 2 ===
1501-511  Compilation failed for file ch2inv.f.
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 2.


Stop.
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 1.


Matthew Beason
Analyst - Capacity Planning
Harrah's Entertainment, Inc.
One Harrah's Court, Las Vegas, NV 89119-4312
Office: 702-494-4097
Mobile: 702-622-6902
mbeason at harrahs.com
The information contained in this email may be legally privileged and
confidential. It is intended to be read only by the person to whom it is
addressed. If you have received this in error or are not the intended
recipient, please immediately notify the sender and delete all copies of
this message. Thank you.


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Thursday, January 26, 2006 11:35 PM
To: Matthew Beason
Cc: r-devel at stat.math.ethz.ch; Ron Kaminski
Subject: Re: [R] R compile on AIX 5.2

[Moved to a more appropriate list.]

This is a problem with your f2c.  R-2.2.1 (of which you used a beta from
more than a month ago) has been compiled using f2c, and I just checked
that my f2c (compiled from the current netlib sources) does not produce
anything like that or near on line 296.

Why not use a real Fortran compiler?  (Your gcc is rather old, as well.)

On Thu, 26 Jan 2006, Matthew Beason wrote:

> Fellow R Enthusiasts..
>
> 	I'm trying to compile R on AIX 5.2 32bit with gcc 3.3.2-5. I've
tried 
> both the development bundle R-devel_2006-01-25.tar.gz and the 
> R-beta.tar.gz from about a month ago. In each instance, I'm using the 
> following options prior to running "./configure
--prefix=/usr/local/R":
>
> 	OBJECT_MODE=32
> 	MAIN_LDFLAGS=-Wl,-brtl
> 	SHLIB_LDFLAGS=-Wl,-G
> 	F2C=/usr/local/bin/f2c

But R-devel_2006-01-25 does not support F2C, and its R-admin manual says
so quite explicitly!

> 	The "R-beta" bundle successfully completes the "configure" stage
but 
> comes up with the following error during "make":
>
> gcc -Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall 
> -Wl,-bI:../../../etc/R.exp -L/usr/local/lib -o internet.so  Rsock.lo 
> internet.lo nanoftp.lo nanohttp.lo sock.lo sockconn.lo 
> /home/mbeason/work/R-beta/src/modules/lapack
> making Lapack.d from Lapack.c
>        /usr/local/bin/f2c  < dlamc.f > c_dlamc.c
>   dlamch:
>   dlamc1:
> Error on line 296: p1_addr:  unknown uname_tag '537090960'
>   dlamc2:
>   dlamc3:
>   dlamc4:
>   dlamc5:
> make: The error code from the last command is 1.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Feb  7 09:52:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Feb 2006 08:52:43 +0000 (GMT)
Subject: [Rd] Problems in d-p-q-r functions (was PR#8528, but unrelated)
In-Reply-To: <20060128084351.090CD2070C@slim.kubism.ku.dk>
References: <20060128084351.090CD2070C@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0602061350550.31143@gannet.stats>

For the record, some of these claims are untrue:

> df(0, 2, 2)
[1] 1
> df(0, 1.3, 2)
[1] Inf
> x <- 1e-170
> pbeta(x, x, x)
[1] 0.5

qnbinom(1e-10,1e3,1e-7,TRUE,FALSE) is an error, and so is 
qnbinom(1E-300,0.000002,10000000000)

Here we can guess at what you meant, maybe correctly.  There were comments 
in the source code about needing a better search, and I have recently 
implemented one.  So

> qnbinom(1e-10, 1e3, 1e-7) # instant
[1] 8117986721
> qnbinom(0.5, 10000000000, 0.000000002)
[1] 5e+18
> qnbinom(1e-300, 10000000000, 0.000002)
[1] 4.998138e+15

seem to be solved.

There were two problems with dbeta, one easily overcome (f underflows) the 
other fundamental to the way dbinom_raw is computed (n*p can underflow). 
What I cannot see is why a formula which worked correctly in this region 
was replaced by one that did not.  It is precisely in order not to 
generate such errors that I used TOMS 708 only in the area where the 
existing algorithm is problematic.  (It may be better elswehere, but I did 
not have the time to do the requisite analysis.  It seems neither do some 
other people: I would prefer not to spend the time to clear up after such 
unneeded changes.)

On pt, thank you for the report.  pt(x, df=1) is not interesting for
|x| > 1e150, but it is for smaller values of df and those were 
underflowing.  It is easy to use an asymptotic formula to regain the 
accuracy.

R was potentially generating reports of lack of convergence and loss of 
accuracy in quite a number of its algorithms, but for reasons unknown to 
me these were being buried (ML_ERROR did nothing, and has not for a very 
long time). It's a matter of debate whether in some of these it would be 
better to return NaN as well, but warnings should have been generated (and 
now are).

As for `panic' (your word: why is it 'panic' to submit a correct bug 
report?), a major platform returning +Inf for a log probability is very 
bad news, as is another failing a regression test by getting NaN for a 
probability which is 0.5.

On Sat, 28 Jan 2006 IandJMSmith at aol.com wrote:

> On 23/02/05 I suggested that given R had included TOMS 708 to correct for t=
> he=20
> poor performance of pbeta, TOMS 654 should be included to fix all the pgamm=
> a=20
> problems. I was slightly surprised to find Morten's code had been included=
> =20
> instead 2 days later. I noticed but did not worry that the reference to me =
> had=20
> been removed.=20
>
> The derivation of the asymptotic expansion for the gamma distribution used =
> by=20
> Morten can be found at http://members.aol.com/iandjmsmith/PoissonApprox.htm=
> =20
> It is fairly easy to understand and find error bounds for and hence include=
> =20
> sensibly in an algorithm to calculate pgamma.
>
> The basis and accuracy of the some of the algorithms I use is discussed in=
> =20
> http://members.aol.com/iandjmsmith/Accuracy.htm In this case, the absolute =
> error=20
> in the log of the probability gives a good indication of the accuracy of yo=
> ur=20
> answer. In the least extreme example you consider=20
> (pgamma(0.9*1e25,1e25,log=3DT)the absolute error would be about 5360515 and=
> if you exponentiated the result=20
> the relative error would be about 10 to the power 2328042. So the answer yo=
> u=20
> wish to calculate is K times 10 to the power -2.32804237034994E+22, where K=
> is=20
> somewhere between 10 to the power plus or minus 2328042. In other words whe=
> n=20
> you make the changes to correct this problem, your calculation will still=
> =20
> return values with no real meaning but at least users might be aware of thi=
> s which=20
> would be no bad thing! For me this answer is possibly so meaningless that N=
> an=20
> would be preferable.
>
> I did mention to Morten that I had updated my code but I believed that for=
> =20
> Gnumeric he was quite satisfied with what he had. If you look at the VBA co=
> de at=20
> http://members.aol.com/iandjmsmith/Examples.txt you can see the changes I=
> =20
> made to stop the overflow problems you seem to be worried about. My code fo=
> r the=20
> pdf of the gamma distribution still fails for shape parameters > 2e307 due =
> to=20
> multiplication of the shap parameter by 2pi. The code for dgamma will have =
> the=20
> same problem unless it is hidden by use of an 80 or more bit floating point=
> =20
> processor. The code for the asymptotic expansion for the gamma distribution=
> =20
> seems to be fine for any number, excluding silly ones like Nan and Inf. Ind=
> eed it=20
> takes the difference from the mean as a parameter and if you supply an=20
> accurate value you get a sensible answer as mentioned in=20
> http://members.aol.com/iandjmsmith/Accuracy.htm
>
> I do not share your apparent sense of panic on this matter. I have no=20
> problems with error signals like NaNs because it is obvious to the user tha=
> t things=20
> have gone wrong. Inaccurate answers when the user has no reason to expect t=
> hem=20
> are usually far more difficult to spot and in many cases the results are ju=
> st=20
> believed. That for me is a serious problem. I think you will find that the=
> =20
> pgamma code of 2.0.0 did not work for small shape parameters (similar to th=
> e=20
> problems exhibited by pbeta still for small parameters see PR#2894), was=20
> inaccurate for large shape parameters (> 1e5) when it resorted to the norma=
> l=20
> approximation and was pretty slow in between. Indeed, the normal approximat=
> ion was the=20
> cause of PR#7307.
>
>
> I don't understand your comments about=20
> "pt_ =3D -x * (log(1 + (lambda-x)/x) - (lambda-x)/x) =3D -x * log((lambda-x=
> )/x) -=20
> (lambda-x)=20
> and naively assumes that this is small enough to use a power series expansi=
> on=20
> in 1/x with coefficients as powers of pt_. To make matters worse, consider =
> =E2=80=A6"
> In the example you go on to discuss, |(lambda-x)/x| is 0.1 and I don't thin=
> k=20
> it can be bigger than 0.2. Calculating log(1+x)-x is done several ways. If =
> |x|=20
> < .01 it is evaluated by a power series, if x < -0.8 or x > 1 it uses=20
> log1p(1+x)-x and for other values it uses a continued fraction which essent=
> ially=20
> evaluates more of the same series used when |x| < .01.
>
> Your comments about replacing logspace_add with logspace_sub with simpler=
> =20
> code which works at first sight to be a very sensible improvement. However,=
> I=20
> would be a bit nervous that lnd-lnp could be very large and the exp of it c=
> ould=20
> return infinity. I'm sure this can be accounted for in the code and lnp +=
> =20
> log1p(f*exp(lnd-lnp))evaluated as lnp or log(f)+lnd accordingly.
>
> I am not responsible for the code for calculating the logs of probabilities=
> =20
> but I seem to remember that the extremely poor performance of the algorithm=
> s in=20
> R2.0.0 with logged probabilities was one of the reasons Morten became=20
> interested in changing the pgamma code (see PR#7307). I have had a quick lo=
> ok and=20
> once the corections mentioned above are made it should be giving nonsense a=
> nswers=20
> with no difficulty.
>
>
> Unfortunately there are still a few examples of sloppy coding and accuracy=
> =20
> errors remaining in R.
>
> The non-central distribution functions have horrible 1- cancellation errors=
> =20
> associated with them (see PR#7099) and separate code is required for the tw=
> o=20
> tails of the distributions to get round the problem.
>
> The fix for PR#8251 is a kludge and just moves the inaccuracies to examples=
> =20
> with higher non-centrality parameters.
>
> pt(x,1) will overflow or return 0 for values < -2e154 for 64-bit=20
> implementations. pcauchy works but I believe the pt function is also suppos=
> ed to work for=20
> non integral degrees of freedom so making it work one degree of freedom via=
> =20
> pcauchy is hardly much use.
>
> qnbinom(1e-10,1e3,1e-7,TRUE,FALSE) is slow and by varying the 
parameters,=
> =20
> qnbinom can be made very slow indeed. I do not think there is anything wron=
> g with=20
> the Cornish-Fisher expansion. It just seems that it is not always very good=
> =20
> for the Negative Binomial distribution. In the example above, the initial=
> =20
> approximation is out by 2e6.
>
> A slightly different problem which can cause qnbinom and qbinom to go into=
> =20
> infinite loops is when the q-value is too big. For example=20
> qnbinom(1E-300,0.000002,10000000000) should return 4.99813787561159E+15 app=
> rox but the code works=20
> with values where one of the statements y :=3D y +1 or y =3D y - 1; is exec=
> uted but=20
> does not alter the value of y.
>
> df(0,2,2,FALSE) should be 1 not 0
> df(0,df,2,FALSE) should be infinity for df < 2 not 0
> dbeta(1e-162,1e-162,1e-162,FALSE) should be 0.5 not 0
>
> Presumably R also has similar problems with the pbeta function. As I recall=
> =20
> the TOMS 708 code was pretty much included without edits and therefore didn=
> 't=20
> calculate logs of probabilities except by calculating the probability and t=
> hen=20
> logging it. I assumed this was why it was not used for small shape paramete=
> rs=20
> where the current code does not work, although it did not seem logical to m=
> e.=20
> Of course, my memory is not what it was but if that is the case and there a=
> re=20
> problems with modifying the TOMS code, you could try an 
asymptotic expansio=
> n=20
> based on http://members.aol.com/iandjmsmith/BinomialApprox.htm
>
> This response has been very rushed. I do not write well when I have plenty =
> of=20
> time and I felt I had so many different things to say so I apologise if it =
> is=20
> all a bit of a jumble.=20
>
> Ian Smith
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Feb  7 11:04:16 2006
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue,  7 Feb 2006 11:04:16 +0100 (CET)
Subject: [Rd] Problems in d-p-q-r functions (was PR#8528, but unrelated)
Message-ID: <20060207100416.88F423F13C@slim.kubism.ku.dk>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Tue, 7 Feb 2006 08:52:43 +0000 (GMT) writes:

    BDR> For the record, some of these claims are untrue:
    >> df(0, 2, 2)
    BDR> [1] 1
    >> df(0, 1.3, 2)
    BDR> [1] Inf

Well, these first two I had fixed in the mean time.
So Ian was right about reporting them.

    >> x <- 1e-170
    >> pbeta(x, x, x)
    BDR> [1] 0.5

( but Ian only explicitly mentioned dbeta(x,x,x)  for x = 1e-162 
  and that *did* need to be fixed -- and I see you did fix it; 
  thanks a lot! )

Martin

 BDR> ............................
 BDR> ............................


From maechler at stat.math.ethz.ch  Tue Feb  7 14:07:57 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Feb 2006 14:07:57 +0100
Subject: [Rd] match gets confused by S4 objects
In-Reply-To: <Pine.LNX.4.61.0602061925190.4469@gannet.stats>
References: <m2hd7cjnse.fsf@ziti.local>
	<Pine.LNX.4.61.0602061925190.4469@gannet.stats>
Message-ID: <17384.39853.165572.356541@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Mon, 6 Feb 2006 19:44:50 +0000 (GMT) writes:

    BDR> An S4 object is just a list with attributes, so a
    BDR> vector type.  match() works with all vector types
    BDR> including lists, as you found out (or could have read).

yes, the internal representation of S4 objects is such -- seen
from a non-S4 perspective.

    BDR> If in the future those proposing it do re-implement an
    BDR> S4 object as an new SEXP then this will change, but for
    BDR> now the cost of detecting objects which might have an
    BDR> S4 class defined somewhere is just too high (and would
    BDR> fall on those who do not use S4 classes).

Just for further explanation, put into other words and a
slightly changed point of view: 

Yes, many R functions get confused by S4 objects, 
most notably,  c()  (!)

 - because they only look at the "internal representation"

 - and because it's expensive to always ``look twice'';
   particularly from the internal C code.
   There's a relatively simple check from R code which we've
   using for str() :

   >> if(has.class <- !is.null(cl <- attr(object, "class"))) { # S3 or S4 class
   >>    ## FIXME: a kludge
   >>    S4 <- !is.null(attr(cl, "package")) || cl == "classRepresentation"
   >>    ## better, but needs 'methods':   length(methods::getSlots(cl)) > 0
   >> }

   which --- when only testing for S4-presence --- you could collapse to

      if(!is.null(cl <- attr(object, "class")) &&
	 (!is.null(attr(cl, "package")) || 
	  cl == "classRepresentation"))     {

	  ...have.S4.object... 

      }

  but note the comment  >>>>   ## FIXME: a kludge   <<<

The solution has been agreed to be changing the internal
representation of S4 objects making them a new SEXP (basic R
"type"); and as Brian alludes to, the problem is that those in
R-core that want to and are able to do this didn't have the time
for that till now.

Martin Maechler, ETH Zurich


    BDR> On Mon, 6 Feb 2006, Seth Falcon wrote:

    >> If one accidentally calls match(x, obj), where obj is any S4 instance,
    >> the result is NA.
    >> 
    >> I was expecting an error because, in general, if a match method is not
    >> defined for a particular S4 class, I don't know what a reasonable
    >> default could be.  Specifically, here's what I see
    >> 
    >> setClass("FOO", representation(a="numeric"))
    >> foo <- new("FOO", a=10)
    >> match("a", foo)
    >> [1] NA
    >> 
    >> And my thinking is that this should be an error, along the lines of
    >> match("a", function(x) x)
    >> 
    >> Unless, of course, a specific method for match, table="FOO" has been
    >> defined.


    BDR> -- 
    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

    BDR> ______________________________________________
    BDR> R-devel at r-project.org mailing list
    BDR> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Tue Feb  7 16:20:17 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Feb 2006 07:20:17 -0800
Subject: [Rd] match gets confused by S4 objects
In-Reply-To: <17384.39853.165572.356541@stat.math.ethz.ch> (Martin Maechler's
	message of "Tue, 7 Feb 2006 14:07:57 +0100")
References: <m2hd7cjnse.fsf@ziti.local>
	<Pine.LNX.4.61.0602061925190.4469@gannet.stats>
	<17384.39853.165572.356541@stat.math.ethz.ch>
Message-ID: <m2wtg7gpqm.fsf@ziti.local>

On  7 Feb 2006, maechler at stat.math.ethz.ch wrote:
> The solution has been agreed to be changing the internal
> representation of S4 objects making them a new SEXP (basic R
> "type"); and as Brian alludes to, the problem is that those in
> R-core that want to and are able to do this didn't have the time
> for that till now.

The explanations from you are Brian are helpful, thanks.  I was aware
that the issue is the internal representation of S4 objects and was
hoping there might be a cheap work around until a new SEXP comes
around.

It seems that S4 instances are less trivial to detect than one might
expect before actually trying it.  

I suppose one work around is to have an S4Basic class that defines
methods for match(), c(), etc and raises an error.  Then extending
this class gives you some protection.

+ seth


From jmc at r-project.org  Tue Feb  7 17:48:10 2006
From: jmc at r-project.org (John Chambers)
Date: Tue, 07 Feb 2006 08:48:10 -0800
Subject: [Rd] match gets confused by S4 objects
In-Reply-To: <m2wtg7gpqm.fsf@ziti.local>
References: <m2hd7cjnse.fsf@ziti.local>
	<Pine.LNX.4.61.0602061925190.4469@gannet.stats>
	<17384.39853.165572.356541@stat.math.ethz.ch>
	<m2wtg7gpqm.fsf@ziti.local>
Message-ID: <43E8CF4A.6080804@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060207/3abe9f0f/attachment.pl

From maechler at stat.math.ethz.ch  Tue Feb  7 17:49:38 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Feb 2006 17:49:38 +0100
Subject: [Rd] match gets confused by S4 objects
In-Reply-To: <m2wtg7gpqm.fsf@ziti.local>
References: <m2hd7cjnse.fsf@ziti.local>
	<Pine.LNX.4.61.0602061925190.4469@gannet.stats>
	<17384.39853.165572.356541@stat.math.ethz.ch>
	<m2wtg7gpqm.fsf@ziti.local>
Message-ID: <17384.53154.997657.517346@stat.math.ethz.ch>

>>>>> "Seth" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>     on Tue, 07 Feb 2006 07:20:17 -0800 writes:

    Seth> On  7 Feb 2006, maechler at stat.math.ethz.ch wrote:
    >> The solution has been agreed to be changing the internal
    >> representation of S4 objects making them a new SEXP (basic R
    >> "type"); and as Brian alludes to, the problem is that those in
    >> R-core that want to and are able to do this didn't have the time
    >> for that till now.

    Seth> The explanations from you are Brian are helpful, thanks.  I was aware
    Seth> that the issue is the internal representation of S4 objects and was
    Seth> hoping there might be a cheap work around until a new SEXP comes
    Seth> around.

    Seth> It seems that S4 instances are less trivial to detect than one might
    Seth> expect before actually trying it.  

    Seth> I suppose one work around is to have an S4Basic class that defines
    Seth> methods for match(), c(), etc and raises an error.  Then extending
    Seth> this class gives you some protection.

well; not so easy for c() !! {see the hoops we had to jump through to do
this for cbind() / rbind() (used in 'Matrix')}.

But it might be interesting; particularly since some have said
they'd expect a considerable performance penalty when all these basic
functions would become S4 generics...

Martin


From ross at biostat.ucsf.edu  Tue Feb  7 22:30:03 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 07 Feb 2006 13:30:03 -0800
Subject: [Rd] S4 documentation
Message-ID: <1139347803.13030.48.camel@iron.psg.net>

1. promptClass generated a file that included
\section{Methods}{
No methods defined with class "mspathDistributedCalculator" in the
signature.
}
Yet there are such methods.  Is this a not-working yet feature, or is
something funny going on (maybe I have definitions in the library and in
the global workspace...)?

2. Is the \code{\link{myS4class-class}} the proper way to
cross-reference a class?  \code{\link{myS4method-method}} the right way
to refer to a method?  I looked for something like \class or \method to
correspond to \code, but didn't see anything.

3.  This question goes beyond documentation.  I have been approaching
things like this:
setClass("A", ....)
foo <- function(a) ....
setClass("B", ...)
setMethod("foo", "B", ....)
so the first foo turns into the default function for the generic.

This was primarily motivated by discovering that
setMethod("foo", "A") where I have the first function definition
produced an error.

Is this a reasonable way to proceed?

Then do I document the generic with standard function documentation for
foo?  Are there some examples I could look at?  When I want to refer to
the function generically, how do I do that?

I'm using R 2.2.1, and I've found the documentation on documenting S4 a
bit too brief (even after looking at the recommended links, which in
some cases don't have much on documentation).  Since the docs say it's a
work in progress, I'm hoping to get the latest word here.

Thanks.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From sfalcon at fhcrc.org  Wed Feb  8 02:48:11 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Feb 2006 17:48:11 -0800
Subject: [Rd] NAMESPACE Q: does import as exist?
Message-ID: <m2slquei3o.fsf@ziti.local>

Is there a way to rename a function when importing it?  I want to say,
"import yourFunc from Foo as myFunc" in the NAMESPACE file.  

Does this exist and I've missed it?  If it doesn't exist, would others
think it useful (and possible)?


Best,

+ seth


From murdoch at stats.uwo.ca  Wed Feb  8 03:10:52 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Feb 2006 21:10:52 -0500
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <m2slquei3o.fsf@ziti.local>
References: <m2slquei3o.fsf@ziti.local>
Message-ID: <43E9532C.5010505@stats.uwo.ca>

On 2/7/2006 8:48 PM, Seth Falcon wrote:
> Is there a way to rename a function when importing it?  I want to say,
> "import yourFunc from Foo as myFunc" in the NAMESPACE file.  
> 
> Does this exist and I've missed it?  If it doesn't exist, would others
> think it useful (and possible)?

I don't know if that exists, but importing it and then copying it should 
work.  That is, in your namespace import foo, and export bar, and in one 
of your R source files have

bar <- foo


From Mark.Bravington at csiro.au  Wed Feb  8 04:14:15 2006
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Wed, 8 Feb 2006 14:14:15 +1100
Subject: [Rd] NAMESPACE Q: does import as exist?
Message-ID: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>

> On 2/7/2006 8:48 PM, Seth Falcon wrote:
> > Is there a way to rename a function when importing it?  I 
> want to say, 
> > "import yourFunc from Foo as myFunc" in the NAMESPACE file.
> 

I don't think Seth's facility exists yet, but it has occurred to me
previously that it would be useful when you need to import two different
functions with the same name from two different packages. (Rare but does
happen.) Duncan's solution won't get around that. So it would be nice to
be able to do this

ImportFromAs( 'pack1', 'funca', 'pack1.funca')
ImportFromAs( 'pack2', 'funca', 'different.name.altogether')

in a NAMESPACE file. Useful-- yes. Possible-- I don't know!

Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Wednesday, 8 February 2006 1:11 PM
> To: Seth Falcon
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] NAMESPACE Q: does import as exist?
> 
> On 2/7/2006 8:48 PM, Seth Falcon wrote:
> > Is there a way to rename a function when importing it?  I 
> want to say, 
> > "import yourFunc from Foo as myFunc" in the NAMESPACE file.
> > 
> > Does this exist and I've missed it?  If it doesn't exist, 
> would others 
> > think it useful (and possible)?
> 
> I don't know if that exists, but importing it and then 
> copying it should work.  That is, in your namespace import 
> foo, and export bar, and in one of your R source files have
> 
> bar <- foo
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From sfalcon at fhcrc.org  Wed Feb  8 04:26:33 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Feb 2006 19:26:33 -0800
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	(Mark Bravington's message of "Wed, 8 Feb 2006 14:14:15 +1100")
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
Message-ID: <m2mzh2edjq.fsf@ziti.local>

On  7 Feb 2006, Mark.Bravington at csiro.au wrote:

>> On 2/7/2006 8:48 PM, Seth Falcon wrote:
>>> Is there a way to rename a function when importing it?  I 
>> want to say, 
>>> "import yourFunc from Foo as myFunc" in the NAMESPACE file.
>>
>
> I don't think Seth's facility exists yet, but it has occurred to me
> previously that it would be useful when you need to import two
> different functions with the same name from two different
> packages. (Rare but does happen.) Duncan's solution won't get around
> that. So it would be nice to be able to do this
>
> ImportFromAs( 'pack1', 'funca', 'pack1.funca')
> ImportFromAs( 'pack2', 'funca', 'different.name.altogether')
>
> in a NAMESPACE file. Useful-- yes. Possible-- I don't know!

Yes, this is along the lines of what I was thinking.  

An unpleasant work around would be to create a translation package
that does something along the lines of Duncan M.'s suggestion,
importing, renaming, exporting.


From sfalcon at fhcrc.org  Wed Feb  8 07:24:11 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Feb 2006 22:24:11 -0800
Subject: [Rd] Improve error message for bad NAMESPACE file?
Message-ID: <m2ek2ee5bo.fsf@ziti.local>

If a user mis-types a directive in the NAMESPACE file, the error
message is quite cryptic.  If it was possible to report the offending
line/text that would likely give a valuable clue to the user.

Try putting the following line in NAMESPACE

foo("bar")

Then R CMD INSTALL says,

* Installing *source* package 'goodbye' ...
** R
** preparing package for lazy loading
Error in gettext(domain, unlist(args)) : invalid 'domain' value
Execution halted
ERROR: lazy loading failed for package 'goodbye'





platform       powerpc-apple-darwin8.4.0                                     
arch           powerpc                                                       
os             darwin8.4.0                                                   
system         powerpc, darwin8.4.0                                          
status         Under development (unstable)                                  
major          2                                                             
minor          3.0                                                           
year           2006                                                          
month          02                                                            
day            05                                                            
svn rev        37270                                                         
language       R                                                             
version.string Version 2.3.0 Under development (unstable) (2006-02-05 r37270) 



--
 + seth


From ripley at stats.ox.ac.uk  Wed Feb  8 08:21:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 07:21:35 +0000 (GMT)
Subject: [Rd] Improve error message for bad NAMESPACE file?
In-Reply-To: <m2ek2ee5bo.fsf@ziti.local>
References: <m2ek2ee5bo.fsf@ziti.local>
Message-ID: <Pine.LNX.4.61.0602080720310.2578@gannet.stats>

On Tue, 7 Feb 2006, Seth Falcon wrote:

> If a user mis-types a directive in the NAMESPACE file, the error
> message is quite cryptic.  If it was possible to report the offending
> line/text that would likely give a valuable clue to the user.
>
> Try putting the following line in NAMESPACE
>
> foo("bar")
>
> Then R CMD INSTALL says,
>
> * Installing *source* package 'goodbye' ...
> ** R
> ** preparing package for lazy loading
> Error in gettext(domain, unlist(args)) : invalid 'domain' value
> Execution halted
> ERROR: lazy loading failed for package 'goodbye'

I suspect this line in namespace.R:

                }
                stop(gettextf("unknown namespace directive: %s", deparse(e)),
                     call. = FALSE, domain = FALSE)

Does domain=NA solve this?

>
>
>
>
>
> platform       powerpc-apple-darwin8.4.0
> arch           powerpc
> os             darwin8.4.0
> system         powerpc, darwin8.4.0
> status         Under development (unstable)
> major          2
> minor          3.0
> year           2006
> month          02
> day            05
> svn rev        37270
> language       R
> version.string Version 2.3.0 Under development (unstable) (2006-02-05 r37270)
>
>
>
> --
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Wed Feb  8 08:37:42 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Feb 2006 23:37:42 -0800
Subject: [Rd] Improve error message for bad NAMESPACE file?
In-Reply-To: <Pine.LNX.4.61.0602080720310.2578@gannet.stats> (Brian Ripley's
	message of "Wed, 8 Feb 2006 07:21:35 +0000 (GMT)")
References: <m2ek2ee5bo.fsf@ziti.local>
	<Pine.LNX.4.61.0602080720310.2578@gannet.stats>
Message-ID: <m2zml2cncp.fsf@ziti.local>

On  7 Feb 2006, ripley at stats.ox.ac.uk wrote:
> I suspect this line in namespace.R:
>
> }
> stop(gettextf("unknown namespace directive: %s", deparse(e)),
> call. = FALSE, domain = FALSE)
>
> Does domain=NA solve this?

Seems to me for me.  I now see an error message like:

   * Installing *source* package 'goodbye' ...
   ** R
   ** save image
   Error: unknown namespace directive: foo("foo")
   Execution halted                                   

which is quite helpful.

Thanks,

+ seth


From francoisromain at free.fr  Wed Feb  8 09:33:50 2006
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 08 Feb 2006 09:33:50 +0100
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <m2mzh2edjq.fsf@ziti.local>
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local>
Message-ID: <43E9ACEE.9060909@free.fr>

Le 08.02.2006 04:26, Seth Falcon a ?crit :

>On  7 Feb 2006, Mark.Bravington at csiro.au wrote:
>
>  
>
>>>On 2/7/2006 8:48 PM, Seth Falcon wrote:
>>>      
>>>
>>>>Is there a way to rename a function when importing it?  I 
>>>>        
>>>>
>>>want to say, 
>>>      
>>>
>>>>"import yourFunc from Foo as myFunc" in the NAMESPACE file.
>>>>        
>>>>
>>I don't think Seth's facility exists yet, but it has occurred to me
>>previously that it would be useful when you need to import two
>>different functions with the same name from two different
>>packages. (Rare but does happen.) Duncan's solution won't get around
>>that. So it would be nice to be able to do this
>>
>>ImportFromAs( 'pack1', 'funca', 'pack1.funca')
>>ImportFromAs( 'pack2', 'funca', 'different.name.altogether')
>>
>>in a NAMESPACE file. Useful-- yes. Possible-- I don't know!
>>    
>>
>
>Yes, this is along the lines of what I was thinking.  
>
>An unpleasant work around would be to create a translation package
>that does something along the lines of Duncan M.'s suggestion,
>importing, renaming, exporting.
>  
>
What about :

bar <- pack::foo
kok <- otherpack::foo


Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From atossava at cc.helsinki.fi  Wed Feb  8 09:37:19 2006
From: atossava at cc.helsinki.fi (Atro Tossavainen)
Date: Wed, 8 Feb 2006 10:37:19 +0200 (EET)
Subject: [Rd] R 2.2.1 installation trouble on SGI/Sun
In-Reply-To: <16435.55491.810396.856921@mithrandir.hornik.net>
Message-ID: <200602080837.k188bJHd013101@kruuna.helsinki.fi>

Hi,

I'm upgrading to R 2.2.1 and have bumped into some problems.

I have been successful with installing on x86 and PPC Linux, but am
unable to install R on Solaris 7 and on IRIX 6.5.  Configuration
and compilation go through just fine, but "make install" fails:

gmake[1]: Entering directory `/scratch/atossava/R-2.2.1/doc'
installing doc ...
../tools/install-sh: no destination specified.
../tools/install-sh: no destination specified.
../tools/install-sh: no destination specified.
gmake[1]: *** [install-sources] Error 1
gmake[1]: Leaving directory `/scratch/atossava/R-2.2.1/doc'
gmake: *** [install] Error 1

Running "gmake -n install" reveals this is because:

echo "installing doc ..."
/bin/ksh ../src/scripts/mkinstalldirs ""
/bin/ksh ../src/scripts/mkinstalldirs /afs/bi/v/sun4x_57/apps/stats/R/2.2.1/man/man1
for f in CRAN_mirrors.csv KEYWORDS KEYWORDS.db; do \
  ../tools/install-sh -c -m 644 ./${f} ""; \
done

Any ideas what might be causing "" to appear as the destination directory?

-- 
Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
+358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
< URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS


From Atro.Tossavainen at helsinki.fi  Wed Feb  8 09:37:49 2006
From: Atro.Tossavainen at helsinki.fi (Atro.Tossavainen@helsinki.fi)
Date: Wed,  8 Feb 2006 09:37:49 +0100 (CET)
Subject: [Rd] R 2.2.1 installation trouble on SGI/Sun (PR#8575)
Message-ID: <20060208083749.82B083F0D3@slim.kubism.ku.dk>

Hi,

I'm upgrading to R 2.2.1 and have bumped into some problems.

I have been successful with installing on x86 and PPC Linux, but am
unable to install R on Solaris 7 and on IRIX 6.5.  Configuration
and compilation go through just fine, but "make install" fails:

gmake[1]: Entering directory `/scratch/atossava/R-2.2.1/doc'
installing doc ...
../tools/install-sh: no destination specified.
../tools/install-sh: no destination specified.
../tools/install-sh: no destination specified.
gmake[1]: *** [install-sources] Error 1
gmake[1]: Leaving directory `/scratch/atossava/R-2.2.1/doc'
gmake: *** [install] Error 1

Running "gmake -n install" reveals this is because:

echo "installing doc ..."
/bin/ksh ../src/scripts/mkinstalldirs ""
/bin/ksh ../src/scripts/mkinstalldirs /afs/bi/v/sun4x_57/apps/stats/R/2.2.1/man/man1
for f in CRAN_mirrors.csv KEYWORDS KEYWORDS.db; do \
  ../tools/install-sh -c -m 644 ./${f} ""; \
done

Any ideas what might be causing "" to appear as the destination directory?

-- 
Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
+358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
< URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS


From ripley at stats.ox.ac.uk  Wed Feb  8 10:08:47 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed,  8 Feb 2006 10:08:47 +0100 (CET)
Subject: [Rd] R 2.2.1 installation trouble on SGI/Sun (PR#8575)
Message-ID: <20060208090847.147313F208@slim.kubism.ku.dk>

Please do not send questions to R-bugs (especially as well as to R-devel).

The thing you are getting as "" is from (see doc/Makefile)
           $(INSTALL_DATA) $(srcdir)/$${f} "$(rdocdir)"; \

What is rdocdir set to in Makeconf?  It (and related quantities) should be

rhome = ${libdir}/R
rsharedir = ${rhome}/share
rincludedir = ${rhome}/include
rdocdir = ${rhome}/doc

unless you set something non-standard during configure.  (If you did not, 
the code is very simple and anything else here would seem to indicate a 
bug in the shell used, but please debug it.)

Solaris 7 is very old: this does work on Solaris 8 (from where I copied 
the above).  You can always specify it on the make install line (as 
described in the R-admin manual you were pointed to).


On Wed, 8 Feb 2006 Atro.Tossavainen at helsinki.fi wrote:

> Hi,
>
> I'm upgrading to R 2.2.1 and have bumped into some problems.
>
> I have been successful with installing on x86 and PPC Linux, but am
> unable to install R on Solaris 7 and on IRIX 6.5.  Configuration
> and compilation go through just fine, but "make install" fails:
>
> gmake[1]: Entering directory `/scratch/atossava/R-2.2.1/doc'
> installing doc ...
> ../tools/install-sh: no destination specified.
> ../tools/install-sh: no destination specified.
> ../tools/install-sh: no destination specified.
> gmake[1]: *** [install-sources] Error 1
> gmake[1]: Leaving directory `/scratch/atossava/R-2.2.1/doc'
> gmake: *** [install] Error 1
>
> Running "gmake -n install" reveals this is because:
>
> echo "installing doc ..."
> /bin/ksh ../src/scripts/mkinstalldirs ""
> /bin/ksh ../src/scripts/mkinstalldirs /afs/bi/v/sun4x_57/apps/stats/R/2.2.1/man/man1
> for f in CRAN_mirrors.csv KEYWORDS KEYWORDS.db; do \
>  ../tools/install-sh -c -m 644 ./${f} ""; \
> done
>
> Any ideas what might be causing "" to appear as the destination directory?
>
> -- 
> Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
> Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
> +358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
> < URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From atossava at cc.helsinki.fi  Wed Feb  8 11:00:58 2006
From: atossava at cc.helsinki.fi (Atro Tossavainen)
Date: Wed, 8 Feb 2006 12:00:58 +0200 (EET)
Subject: [Rd] R 2.2.1 installation trouble on SGI/Sun (PR#8575)
In-Reply-To: <Pine.LNX.4.61.0602080857100.3820@gannet.stats>
Message-ID: <200602081000.k18A0wQ2015794@kruuna.helsinki.fi>

Dear Prof Ripley,

Thank you for your quick response!

> Please do not send questions to R-bugs (especially as well as to R-devel).

Sorry.  I took the addresses from a response to an older question that
I had received from Kurt Hornik.  That message had been cc'd to both.

> The thing you are getting as "" is from (see doc/Makefile)
>            $(INSTALL_DATA) $(srcdir)/$${f} "$(rdocdir)"; \
> 
> What is rdocdir set to in Makeconf?  It (and related quantities) should be
> 
> rhome = ${libdir}/R
> rsharedir = ${rhome}/share
> rincludedir = ${rhome}/include
> rdocdir = ${rhome}/doc

rhome = ${libdir}/R
rsharedir = 
rincludedir = 
rdocdir = 

(I find this is the case both on Solaris 7 and on IRIX 6.5.)

> unless you set something non-standard during configure.  (If you did not, 
> the code is very simple and anything else here would seem to indicate a 
> bug in the shell used, but please debug it.)

The only changes to "./configure" that I made were to set the relevant
environment variables to pick the native compilers instead of gcc, and
--prefix=/afs/bi/v/{systemtype}/apps/stats/R/2.2.1 (for literal values
of system type; sgi_65, sun4x_57).

The shell I performed "configure" under is bash 2.05, which is
admittedly old too.  It hasn't caused any such problems before, though,
and I have built a very large amount of autoconfigured software for
these platforms with it.

> Solaris 7 is very old: this does work on Solaris 8 (from where I copied 
> the above).

IRIX 6.5 is current and displays the same issue.

Thank you for your help and suggestions.  If there is anything I can
do to help debug the problem further, please let me know.

-- 
Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
+358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
< URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS


From Kurt.Hornik at wu-wien.ac.at  Wed Feb  8 11:27:19 2006
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed, 8 Feb 2006 11:27:19 +0100
Subject: [Rd] chron library: format.times, parse.format and h:m (PR#8507)
In-Reply-To: <20060119202902.9382428FB5@slim.kubism.ku.dk>
References: <20060119202902.9382428FB5@slim.kubism.ku.dk>
Message-ID: <17385.51079.962784.151654@mithrandir.hornik.net>

>>>>> spector  writes:

> Due to the following lines in parse.format:
> else if (nf == 3) {
>         sep <- ""
>         fmt <- substring(format, first = 1:3, last = 1:3)
>     }

> If a format code has 3 characters, it will not use a separator:

>> library(chron)
>> mytime = times('7:15:00')
>> format(mytime,'h:m')
> [1] "0715"
>                                        - Phil Spector
> 					 Statistical Computing Facility
> 					 Department of Statistics
> 					 UC Berkeley
> 					 spector at stat.berkeley.edu

The docs say

          The times format can be any permutation of '"h"', '"m"', and
          '"s"' separated by any one non-special character.  The
          default is '"h:m:s"'.

and I would read *permutation* as to include each of h m s, so that
incomplete representations like the one you gave are ruled out.

(In any case, it seems we should teach the docs about the no-separator
case.)

-k


From ripley at stats.ox.ac.uk  Wed Feb  8 11:29:51 2006
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Wed, 8 Feb 2006 10:29:51 +0000 (GMT)
Subject: [Rd] R 2.2.1 installation trouble on SGI/Sun (PR#8575)
In-Reply-To: <200602081000.k18A0wQ2015794@kruuna.helsinki.fi>
Message-ID: <Pine.GSO.4.31.0602081022130.24227-100000@markov.stats>

Thank you for the reply.  Setting these variables explicitly on the make
install line should help.

I have a guess at the shell problem.  Configure contains

if test -z ${rdocdir}; then
  rdocdir='${rhome}/doc'
fi

and maybe test -z is broken.  Does it help to add quotes as in

if test -z "${rdocdir}"; then

?  (I have a recollection of such problems under Solaris 7 when we ran
it, and a recollection that autoconf picks ksh as its shell on Solaris.)

On Wed, 8 Feb 2006, Atro Tossavainen wrote:

> Dear Prof Ripley,
>
> Thank you for your quick response!
>
> > Please do not send questions to R-bugs (especially as well as to R-devel).
>
> Sorry.  I took the addresses from a response to an older question that
> I had received from Kurt Hornik.  That message had been cc'd to both.
>
> > The thing you are getting as "" is from (see doc/Makefile)
> >            $(INSTALL_DATA) $(srcdir)/$${f} "$(rdocdir)"; \
> >
> > What is rdocdir set to in Makeconf?  It (and related quantities) should be
> >
> > rhome = ${libdir}/R
> > rsharedir = ${rhome}/share
> > rincludedir = ${rhome}/include
> > rdocdir = ${rhome}/doc
>
> rhome = ${libdir}/R
> rsharedir =
> rincludedir =
> rdocdir =
>
> (I find this is the case both on Solaris 7 and on IRIX 6.5.)
>
> > unless you set something non-standard during configure.  (If you did not,
> > the code is very simple and anything else here would seem to indicate a
> > bug in the shell used, but please debug it.)
>
> The only changes to "./configure" that I made were to set the relevant
> environment variables to pick the native compilers instead of gcc, and
> --prefix=/afs/bi/v/{systemtype}/apps/stats/R/2.2.1 (for literal values
> of system type; sgi_65, sun4x_57).
>
> The shell I performed "configure" under is bash 2.05, which is
> admittedly old too.  It hasn't caused any such problems before, though,
> and I have built a very large amount of autoconfigured software for
> these platforms with it.
>
> > Solaris 7 is very old: this does work on Solaris 8 (from where I copied
> > the above).
>
> IRIX 6.5 is current and displays the same issue.
>
> Thank you for your help and suggestions.  If there is anything I can
> do to help debug the problem further, please let me know.
>
> --
> Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
> Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
> +358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
> < URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From arsenije at ist.utl.pt  Wed Feb  8 12:06:55 2006
From: arsenije at ist.utl.pt (arsenije@ist.utl.pt)
Date: Wed,  8 Feb 2006 12:06:55 +0100 (CET)
Subject: [Rd] identify() bug (PR#8576)
Message-ID: <20060208110655.E6C9F3F215@slim.kubism.ku.dk>

Full_Name: Vladan Arsenijevic
Version: 2.2.1
OS: linux/gentoo
Submission from: (NULL) (193.136.128.14)


I have a vector of floats that I want to assign to a set of the points in the
plot with identify(). When I print the vector, it appears with a certain
precision (let's say 2 decimal places), while in the plot it gets 12 more.
For example 8.97 turns to 8.97000000000025. Any hint?
Regards!


From ripley at stats.ox.ac.uk  Wed Feb  8 12:35:57 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed,  8 Feb 2006 12:35:57 +0100 (CET)
Subject: [Rd] identify() bug (PR#8576)
Message-ID: <20060208113557.ACB243F0D6@slim.kubism.ku.dk>

Please do not use R-bugs to ask questions.  Well under half the traffic on
R-bugs is related to actual bug reports.

On Wed, 8 Feb 2006 arsenije at ist.utl.pt wrote:

> Full_Name: Vladan Arsenijevic
> Version: 2.2.1
> OS: linux/gentoo
> Submission from: (NULL) (193.136.128.14)
>
>
> I have a vector of floats that I want to assign to a set of the points in the
> plot with identify(). When I print the vector, it appears with a certain
> precision (let's say 2 decimal places), while in the plot it gets 12 more.
> For example 8.97 turns to 8.97000000000025. Any hint?

The 'labels' are character strings and as.character is using the full
precision of your numbers.  If you do not want what you asked for, ask
for something else, e.g. via round() or format().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Wed Feb  8 13:08:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Feb 2006 07:08:23 -0500
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <43E9532C.5010505@stats.uwo.ca>
References: <m2slquei3o.fsf@ziti.local> <43E9532C.5010505@stats.uwo.ca>
Message-ID: <43E9DF37.2040805@stats.uwo.ca>

On 2/7/2006 9:10 PM, Duncan Murdoch wrote:
> On 2/7/2006 8:48 PM, Seth Falcon wrote:
>> Is there a way to rename a function when importing it?  I want to say,
>> "import yourFunc from Foo as myFunc" in the NAMESPACE file.  
>>
>> Does this exist and I've missed it?  If it doesn't exist, would others
>> think it useful (and possible)?
> 
> I don't know if that exists, but importing it and then copying it should 
> work.  That is, in your namespace import foo, and export bar, and in one 
> of your R source files have
> 
> bar <- foo

There may be a disadvantage to this if you have a saved image of the 
function -- the current one will be saved, not the one that gets a bug 
fixed next week.  Or maybe it's okay, I don't know.  I think a way 
around that problem would be

delayedAssign("bar", foo)

which won't actually do the copying until the first use of bar.

As Romain said, if there are multiple foo functions around, just qualify 
the name before importing.

Duncan Murdoch


From murdoch at stats.uwo.ca  Wed Feb  8 13:10:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Feb 2006 07:10:36 -0500
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <m2mzh2edjq.fsf@ziti.local>
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local>
Message-ID: <43E9DFBC.4090704@stats.uwo.ca>

On 2/7/2006 10:26 PM, Seth Falcon wrote:
> On  7 Feb 2006, Mark.Bravington at csiro.au wrote:
> 
>>> On 2/7/2006 8:48 PM, Seth Falcon wrote:
>>>> Is there a way to rename a function when importing it?  I 
>>> want to say, 
>>>> "import yourFunc from Foo as myFunc" in the NAMESPACE file.
>> I don't think Seth's facility exists yet, but it has occurred to me
>> previously that it would be useful when you need to import two
>> different functions with the same name from two different
>> packages. (Rare but does happen.) Duncan's solution won't get around
>> that. So it would be nice to be able to do this
>>
>> ImportFromAs( 'pack1', 'funca', 'pack1.funca')
>> ImportFromAs( 'pack2', 'funca', 'different.name.altogether')
>>
>> in a NAMESPACE file. Useful-- yes. Possible-- I don't know!
> 
> Yes, this is along the lines of what I was thinking.  
> 
> An unpleasant work around would be to create a translation package
> that does something along the lines of Duncan M.'s suggestion,
> importing, renaming, exporting.

Why do you call it unpleasant?  With the current mechanisms in R, that's 
probably what your ImportFromAs function would have to do.  There's no 
way to have two names referring to the same function.

Duncan Murdoch


From atossava at cc.helsinki.fi  Wed Feb  8 13:55:35 2006
From: atossava at cc.helsinki.fi (Atro Tossavainen)
Date: Wed, 8 Feb 2006 14:55:35 +0200 (EET)
Subject: [Rd] R 2.2.1 installation trouble on SGI/Sun (PR#8575)
In-Reply-To: <Pine.GSO.4.31.0602081022130.24227-100000@markov.stats>
Message-ID: <200602081255.k18CtZvD021523@kruuna.helsinki.fi>

Dear Prof Ripley,

> Thank you for the reply.  Setting these variables explicitly on the make
> install line should help.

I just fixed them in Makeconf explicitly and it's OK now.

> I have a guess at the shell problem.  Configure contains
> 
> if test -z ${rdocdir}; then
>   rdocdir='${rhome}/doc'
> fi
> 
> and maybe test -z is broken.  Does it help to add quotes as in
> 
> if test -z "${rdocdir}"; then

Yes, that's the trick.

-- 
Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
+358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
< URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS


From ripley at stats.ox.ac.uk  Wed Feb  8 15:34:54 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 14:34:54 +0000 (GMT)
Subject: [Rd] R 2.2.1 installation trouble on SGI/Sun (PR#8575)
In-Reply-To: <200602081255.k18CtZvD021523@kruuna.helsinki.fi>
Message-ID: <Pine.GSO.4.31.0602081433590.10930-100000@toucan.stats>

On Wed, 8 Feb 2006, Atro Tossavainen wrote:

> Dear Prof Ripley,
>
> > Thank you for the reply.  Setting these variables explicitly on the make
> > install line should help.
>
> I just fixed them in Makeconf explicitly and it's OK now.
>
> > I have a guess at the shell problem.  Configure contains
> >
> > if test -z ${rdocdir}; then
> >   rdocdir='${rhome}/doc'
> > fi
> >
> > and maybe test -z is broken.  Does it help to add quotes as in
> >
> > if test -z "${rdocdir}"; then
>
> Yes, that's the trick.

We'll alter the script in that case.  Thanks for testing the fix.

>
> --
> Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
> Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
> +358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
> < URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Wed Feb  8 15:41:17 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 08 Feb 2006 06:41:17 -0800
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <43E9ACEE.9060909@free.fr> (Romain Francois's message of "Wed,
	08 Feb 2006 09:33:50 +0100")
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local> <43E9ACEE.9060909@free.fr>
Message-ID: <m2r76ddib6.fsf@ziti.local>

On  8 Feb 2006, francoisromain at free.fr wrote:
> What about :
>
> bar <- pack::foo
> kok <- otherpack::foo

This is a solution, thanks for the suggestion.  The downside is that
it doesn't let one be particularly specific about what one is using in
the NAMESPACE file.  In fact, if one only wanted to use pack::foo and
otherpack::foo, then I believe one would have to _not_ mention them at
all in NAMESPACE.

+ seth


From sfalcon at fhcrc.org  Wed Feb  8 16:18:27 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 08 Feb 2006 07:18:27 -0800
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <43E9DFBC.4090704@stats.uwo.ca> (Duncan Murdoch's message of "Wed,
	08 Feb 2006 07:10:36 -0500")
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local> <43E9DFBC.4090704@stats.uwo.ca>
Message-ID: <m2lkwldgl8.fsf@ziti.local>

On  8 Feb 2006, murdoch at stats.uwo.ca wrote:
>>> in a NAMESPACE file. Useful-- yes. Possible-- I don't know!
>> Yes, this is along the lines of what I was thinking.  An unpleasant
>> work around would be to create a translation package
>> that does something along the lines of Duncan M.'s suggestion,
>> importing, renaming, exporting.
>
> Why do you call it unpleasant?  

Because other languages do this without defining an extra "package".
I don't think users should have to go to that length to resolve such
name issues.

> With the current mechanisms in R, that's probably what your
> ImportFromAs function would have to do.  There's no way to have two
> names referring to the same function.

Do you mean: there's no way to have one name referring to two
different functions?  

After looking over some of the namespace code, I think what I'm asking
for is possible (without creating extra packages).  E.g., attaching a
package with a NAMESPACE file looks like it will call
attachNamespace(), which creates an empty env on the search path and
then calls importIntoEnv() to fill it.  ImportIntoEnv() ends up in
do_importIntoEnv in envir.c.  The comment there is encouraging:

    /* This function copies values of variables from one environment
       to another environment, possibly with different names.
       Promises are not forced and active bindings are preserved. */

Am I on track here that this implies that it is possible to have an
importFromAs directive without change to the current underlying
mechanism and that only higher level additions would be needed (not to
say it would be easy).

Best,

+ seth


From murdoch at stats.uwo.ca  Wed Feb  8 17:16:10 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Feb 2006 11:16:10 -0500
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <m2lkwldgl8.fsf@ziti.local>
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>	<m2mzh2edjq.fsf@ziti.local>
	<43E9DFBC.4090704@stats.uwo.ca> <m2lkwldgl8.fsf@ziti.local>
Message-ID: <43EA194A.1060905@stats.uwo.ca>

On 2/8/2006 10:18 AM, Seth Falcon wrote:
> On  8 Feb 2006, murdoch at stats.uwo.ca wrote:
>>>> in a NAMESPACE file. Useful-- yes. Possible-- I don't know!
>>> Yes, this is along the lines of what I was thinking.  An unpleasant
>>> work around would be to create a translation package
>>> that does something along the lines of Duncan M.'s suggestion,
>>> importing, renaming, exporting.
>>
>> Why do you call it unpleasant?  
> 
> Because other languages do this without defining an extra "package".
> I don't think users should have to go to that length to resolve such
> name issues.

I don't see a need for an additional package here -- it could all be 
done in the package doing the importing.

> 
>> With the current mechanisms in R, that's probably what your
>> ImportFromAs function would have to do.  There's no way to have two
>> names referring to the same function.
> 
> Do you mean: there's no way to have one name referring to two
> different functions?  

No, but that's true too, if you're talking within an environment.  It's 
certainly possible to use the same name in different environments to 
refer to different things.

What I meant was that I can't define "foo" to refer to function "bar". 
I can make a copy of "bar", but not a reference.

Duncan Murdoch

> 
> After looking over some of the namespace code, I think what I'm asking
> for is possible (without creating extra packages).  E.g., attaching a
> package with a NAMESPACE file looks like it will call
> attachNamespace(), which creates an empty env on the search path and
> then calls importIntoEnv() to fill it.  ImportIntoEnv() ends up in
> do_importIntoEnv in envir.c.  The comment there is encouraging:
> 
>     /* This function copies values of variables from one environment
>        to another environment, possibly with different names.
>        Promises are not forced and active bindings are preserved. */
> 
> Am I on track here that this implies that it is possible to have an
> importFromAs directive without change to the current underlying
> mechanism and that only higher level additions would be needed (not to
> say it would be easy).
> 
> Best,
> 
> + seth
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmacdon at med.umich.edu  Wed Feb  8 17:37:38 2006
From: jmacdon at med.umich.edu (James MacDonald)
Date: Wed, 08 Feb 2006 11:37:38 -0500
Subject: [Rd] Using .onUnload() to unload compiled code
Message-ID: <s3e9d80e.049@med-gwia-02a.med.umich.edu>

If one wants to unload compiled code for a package containing a namespace, my understanding is that .onUnload() should be used, with a call to library.dynam.unload(). This is used in e.g., the stats and methods packages, but it appears to me that the compiled code is not being unloaded when the package is detached(). Am I misunderstanding something?

Best,

Jim

> search()
[1] ".GlobalEnv"        "package:methods"   "package:stats"     "package:graphics" 
[5] "package:grDevices" "package:utils"     "package:datasets"  "Autoloads"        
[9] "package:base"     

> stats:::.onUnload
function (libpath) 
library.dynam.unload("stats", libpath)
<environment: namespace:stats>

> getLoadedDLLs()
                                                   Filename Dynamic.Lookup
base                                                   base          FALSE
iconv                        C:/rw2030dev/modules/iconv.dll           TRUE
grDevices C:/rw2030dev/library/grDevices/libs/grDevices.dll          FALSE
stats             C:/rw2030dev/library/stats/libs/stats.dll          FALSE
methods       C:/rw2030dev/library/methods/libs/methods.dll          FALSE

> detach(3)

> search()
[1] ".GlobalEnv"        "package:methods"   "package:graphics"  "package:grDevices"
[5] "package:utils"     "package:datasets"  "Autoloads"         "package:base"  
   
> getLoadedDLLs()
                                                   Filename Dynamic.Lookup
base                                                   base          FALSE
iconv                        C:/rw2030dev/modules/iconv.dll           TRUE
grDevices C:/rw2030dev/library/grDevices/libs/grDevices.dll          FALSE
stats             C:/rw2030dev/library/stats/libs/stats.dll          FALSE
methods       C:/rw2030dev/library/methods/libs/methods.dll          FALSE

> R.version
               _                                                             
platform       i386-pc-mingw32                                               
arch           i386                                                          
os             mingw32                                                       
system         i386, mingw32                                                 
status         Under development (unstable)                                  
major          2                                                             
minor          3.0                                                           
year           2006                                                          
month          01                                                            
day            01                                                            
svn rev        36947                                                         
language       R                                                             
version.string Version 2.3.0 Under development (unstable) (2006-01-01 r36947)


James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623



**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.


From sfalcon at fhcrc.org  Wed Feb  8 18:07:25 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 08 Feb 2006 09:07:25 -0800
Subject: [Rd] How to change names when importing with a NAMESPACE (was:
	NAMESPACE Q: does import as exist?)
In-Reply-To: <m2lkwldgl8.fsf@ziti.local> (Seth Falcon's message of "Wed,
	08 Feb 2006 07:18:27 -0800")
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local> <43E9DFBC.4090704@stats.uwo.ca>
	<m2lkwldgl8.fsf@ziti.local>
Message-ID: <m23bitdbjm.fsf_-_@ziti.local>

Well, it seems that the following does what I want.  In the NAMESPACE
file, one can do:

  importFrom("pkgA", foo=bar)

Which will allow you to use the symbol 'foo' to refer to pkgA::bar.
This is exactly what I wanted.

Despite the lack of documentation, this seems an intentional feature.
Is there a reason not to document it and allow it as part of the
NAMESPACE feature set?

Best,

+ seth


From gchappi at gmail.com  Wed Feb  8 18:07:56 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Wed, 8 Feb 2006 18:07:56 +0100
Subject: [Rd] Rf_protect in Rinternals.h
Message-ID: <47fce0650602080907q39738247w@mail.gmail.com>

Hello!

I'd like to ask you a question about c (macros):

In Rinternals.h are defined:
a)   SEXP Rf_protect(SEXP);
b)   #define protect Rf_protect
c)   #define PROTECT(s)	protect(s)

As far as I understand the calls Rf_protect( x ), protect( x ) and
PROTECT( x ) are all equalent.

So whats the reason that there are 2 macros defined? Why 3 times the
same when 1 distinct function would be enough?

Thanks for some enlightenment...

--
Regards,
Hans-Peter


From luke at stat.uiowa.edu  Wed Feb  8 19:11:36 2006
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Wed, 8 Feb 2006 12:11:36 -0600 (CST)
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <m2lkwldgl8.fsf@ziti.local>
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local> <43E9DFBC.4090704@stats.uwo.ca>
	<m2lkwldgl8.fsf@ziti.local>
Message-ID: <Pine.LNX.4.63.0602081136340.21301@nokomis.stat.uiowa.edu>

We anticipated this issue when the name space mechanism was designed,
and the design allows for this, but we deliberately did not formally
document this at the time.  As with most things like this there are
trade-offs.  Allowing for renaming complicates the code; it also may
prevent, or at least significantly complicate, changes in the
implementation we might want to make.  On the other hand this might be
quite useful in some settings.  We had some disagrements about how
useful, so the compromise was to leave the facility in but not
officially document it, and wait and see what the need looks like.
This is the first request I recall in almost three years since the
mechanism was introduced, so it is not a major issue.

The support for renaming on import allows you to use the directive

 	importFrom(bar, hh = g)

to import bar::g as hh in your package.

Since this mechanism is not officially documented and has not been
used or tested, changes that have occurred in the code over time may
have broken things, or things may have been added that did not take
renaming into account.  For example, the parallel facility for
renaming on export seems to have been broken somewhere along the way.
So if you want to use this do so with caution.  If we see substantial
usage we may need to think about formally documenting and testing
this; but only after carefully considering whether it does impose
limits on other things we would like to do.

Some of the throughts on this are described in
http://www.stat.uiowa.edu/~luke/R/namespaces/morenames.html, also
available off the developer page developer.r-project.org.

Best,

luke




On Wed, 8 Feb 2006, Seth Falcon wrote:

> On  8 Feb 2006, murdoch at stats.uwo.ca wrote:
>>>> in a NAMESPACE file. Useful-- yes. Possible-- I don't know!
>>> Yes, this is along the lines of what I was thinking.  An unpleasant
>>> work around would be to create a translation package
>>> that does something along the lines of Duncan M.'s suggestion,
>>> importing, renaming, exporting.
>>
>> Why do you call it unpleasant?
>
> Because other languages do this without defining an extra "package".
> I don't think users should have to go to that length to resolve such
> name issues.
>
>> With the current mechanisms in R, that's probably what your
>> ImportFromAs function would have to do.  There's no way to have two
>> names referring to the same function.
>
> Do you mean: there's no way to have one name referring to two
> different functions?
>
> After looking over some of the namespace code, I think what I'm asking
> for is possible (without creating extra packages).  E.g., attaching a
> package with a NAMESPACE file looks like it will call
> attachNamespace(), which creates an empty env on the search path and
> then calls importIntoEnv() to fill it.  ImportIntoEnv() ends up in
> do_importIntoEnv in envir.c.  The comment there is encouraging:
>
>    /* This function copies values of variables from one environment
>       to another environment, possibly with different names.
>       Promises are not forced and active bindings are preserved. */
>
> Am I on track here that this implies that it is possible to have an
> importFromAs directive without change to the current underlying
> mechanism and that only higher level additions would be needed (not to
> say it would be easy).
>
> Best,
>
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From sfalcon at fhcrc.org  Wed Feb  8 19:13:01 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 08 Feb 2006 10:13:01 -0800
Subject: [Rd] Using .onUnload() to unload compiled code
In-Reply-To: <s3e9d80e.049@med-gwia-02a.med.umich.edu> (James MacDonald's
	message of "Wed, 08 Feb 2006 11:37:38 -0500")
References: <s3e9d80e.049@med-gwia-02a.med.umich.edu>
Message-ID: <m2slqtbtxu.fsf@ziti.local>

Hi Jim,

On  8 Feb 2006, jmacdon at med.umich.edu wrote:
> If one wants to unload compiled code for a package containing a
> namespace, my understanding is that .onUnload() should be used, with
> a call to library.dynam.unload(). This is used in e.g., the stats
> and methods packages, but it appears to me that the compiled code is
> not being unloaded when the package is detached(). Am I
> misunderstanding something?

A package with a namespace can be loaded and not attached or loaded
and attached.

Use loadedNamespaces() to see what is loaded, and search() to see
what is attached.

.Last.lib() gets called by detach() is called.  .onUnload() is called
by unloadNamespace().  I'm pretty sure you can have both .Last.lib and
.onUnload in a package with a namespace.

hth,

+ seth


From ripley at stats.ox.ac.uk  Wed Feb  8 19:30:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 18:30:46 +0000 (GMT)
Subject: [Rd] Using .onUnload() to unload compiled code
In-Reply-To: <s3e9d80e.049@med-gwia-02a.med.umich.edu>
References: <s3e9d80e.049@med-gwia-02a.med.umich.edu>
Message-ID: <Pine.LNX.4.64.0602081828280.27091@gannet.stats.ox.ac.uk>

On Wed, 8 Feb 2006, James MacDonald wrote:

> If one wants to unload compiled code for a package containing a 
> namespace, my understanding is that .onUnload() should be used, with a 
> call to library.dynam.unload(). This is used in e.g., the stats and 
> methods packages, but it appears to me that the compiled code is not 
> being unloaded when the package is detached(). Am I misunderstanding 
> something?

No. It is still needed whilst the namespace is loaded.  .onUnload is not 
run by detach(), but by unloadNamespace


>
> Best,
>
> Jim
>
>> search()
> [1] ".GlobalEnv"        "package:methods"   "package:stats"     "package:graphics"
> [5] "package:grDevices" "package:utils"     "package:datasets"  "Autoloads"
> [9] "package:base"
>
>> stats:::.onUnload
> function (libpath)
> library.dynam.unload("stats", libpath)
> <environment: namespace:stats>
>
>> getLoadedDLLs()
>                                                   Filename Dynamic.Lookup
> base                                                   base          FALSE
> iconv                        C:/rw2030dev/modules/iconv.dll           TRUE
> grDevices C:/rw2030dev/library/grDevices/libs/grDevices.dll          FALSE
> stats             C:/rw2030dev/library/stats/libs/stats.dll          FALSE
> methods       C:/rw2030dev/library/methods/libs/methods.dll          FALSE
>
>> detach(3)
>
>> search()
> [1] ".GlobalEnv"        "package:methods"   "package:graphics"  "package:grDevices"
> [5] "package:utils"     "package:datasets"  "Autoloads"         "package:base"
>
>> getLoadedDLLs()
>                                                   Filename Dynamic.Lookup
> base                                                   base          FALSE
> iconv                        C:/rw2030dev/modules/iconv.dll           TRUE
> grDevices C:/rw2030dev/library/grDevices/libs/grDevices.dll          FALSE
> stats             C:/rw2030dev/library/stats/libs/stats.dll          FALSE
> methods       C:/rw2030dev/library/methods/libs/methods.dll          FALSE
>
>> R.version
>               _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status         Under development (unstable)
> major          2
> minor          3.0
> year           2006
> month          01
> day            01
> svn rev        36947
> language       R
> version.string Version 2.3.0 Under development (unstable) (2006-01-01 r36947)
>
>
> James W. MacDonald
> Affymetrix and cDNA Microarray Core
> University of Michigan Cancer Center
> 1500 E. Medical Center Drive
> 7410 CCGC
> Ann Arbor MI 48109
> 734-647-5623
>
>
>
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Feb  8 20:08:04 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 19:08:04 +0000 (GMT)
Subject: [Rd] How to change names when importing with a NAMESPACE (was:
 NAMESPACE Q: does import as exist?)
In-Reply-To: <m23bitdbjm.fsf_-_@ziti.local>
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local> <43E9DFBC.4090704@stats.uwo.ca>
	<m2lkwldgl8.fsf@ziti.local> <m23bitdbjm.fsf_-_@ziti.local>
Message-ID: <Pine.LNX.4.64.0602081904310.28253@gannet.stats.ox.ac.uk>

This is indeed described in

http://www.stat.uiowa.edu/~luke/R/namespaces/morenames.html

linked from developer.r-project.org.

with the comment

   The purpose of baz is to import some of the exports of foo and bar and
   re-export them, using renaming in one case: bar's export g is imported
   under the internal name hh, and the internal variable hh is exported
   under the name gg. [Renaming seems like a useful option, but it may
   turn out to create too many complications and need to be dropped.]

It's been there since 1.7.0 and not yet been dropped.  (I would also 
suggest checking the R-News article on namespaces, which I have not done.
But checking the developer site is always worthwhile.)

It would be nice to have more end-user documentation on namespaces, and I 
have suggested it in the past.  A project for you, perhaps?


On Wed, 8 Feb 2006, Seth Falcon wrote:

> Well, it seems that the following does what I want.  In the NAMESPACE
> file, one can do:
>
>  importFrom("pkgA", foo=bar)
>
> Which will allow you to use the symbol 'foo' to refer to pkgA::bar.
> This is exactly what I wanted.
>
> Despite the lack of documentation, this seems an intentional feature.
> Is there a reason not to document it and allow it as part of the
> NAMESPACE feature set?
>
> Best,
>
> + seth

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Feb  8 20:09:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 19:09:46 +0000 (GMT)
Subject: [Rd] Rf_protect in Rinternals.h
In-Reply-To: <47fce0650602080907q39738247w@mail.gmail.com>
References: <47fce0650602080907q39738247w@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602081831110.27091@gannet.stats.ox.ac.uk>

On Wed, 8 Feb 2006, Hans-Peter wrote:

> Hello!
>
> I'd like to ask you a question about c (macros):
>
> In Rinternals.h are defined:
> a)   SEXP Rf_protect(SEXP);
> b)   #define protect Rf_protect
> c)   #define PROTECT(s)	protect(s)
>
> As far as I understand the calls Rf_protect( x ), protect( x ) and
> PROTECT( x ) are all equalent.
>
> So whats the reason that there are 2 macros defined? Why 3 times the
> same when 1 distinct function would be enough?

History.  People do not like writing 'Rf_protect', so PROTECT is used 
instead.  And the code is written as 'protect' for the same reason, and to 
allow future changes under the skin.  (Several macros are in fact used 
differently inside R, and Rinternals.h was an attempt to extract a 
reasonable subset of the internal code, not an ab initio design).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Wed Feb  8 21:05:35 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 08 Feb 2006 12:05:35 -0800
Subject: [Rd] Another NAMESPACE question, imports and S4
Message-ID: <m2k6c5boq8.fsf@ziti.local>

One more namespaces thread and then I will be quiet for a while ;-)

Should S4 methods be attached to the appropriate generic when a
package is loaded, but not attached?

For example, suppose package 'hello' defines an S4 class Speaker and a
defines a method for the show generic defined in the methods package.
Then package 'goodbye' imports hello and defines a function that
creates a Speaker instance and calls show on it.  

The only way I've found thus far to get the show method defined in
'hello' to get attached to the generic is to exportMethods("show")
from 'goodbye'.  But I don't think I should have to export in order to
import.

I've posted packages hello and goodbye here:
http://bioconductor.fhcrc.org/developers/examples/

To see an example, install both then do:

    > library(goodbye)
    > goodbye()
    An object of class "Speaker"
    Slot "words":
    [1] "Goodbye, world"   

Thanks,

+ seth


From roebuck at mdanderson.org  Wed Feb  8 22:33:11 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Wed, 8 Feb 2006 15:33:11 -0600 (CST)
Subject: [Rd]  invalid graphics state using dev.print (fwd)
Message-ID: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>

On Mon, 6 Feb 2006 18:12, Simon Urbanek wrote:

> On Feb 6, 2006, at 5:24 PM, Paul Roebuck wrote:
>
>> Tried on R-Sig-Mac with no responses, but I need some kind
>> of answer.
>> [...]
>> Does the following work on your system?
>
> Interesting, no, it doesn't either. For png and pdf I use
> Quartz + quartz.save (it produces much nicer results) so
> I didn't really notice, but you're right. First I thought
> those graphics state issues are specific to the Quartz
> device, but you have proven that it's not. It's in fact
> not even Mac-specific - I have just reproduced it on a
> Linux box - that's why I'm moving this to R-devel.

It's been several workdays now with no responses. Could
someone try the last three lines of code and see if they
get the following error message?

> x11()
> plot(rnorm(10))
> dev.print(png)

Error in dev.copy(device = function (filename = "Rplot%03d.png", width =
480,  :
	invalid graphics state

> traceback()
6: dev.copy(device = function (filename = "Rplot%03d.png", width = 480,
       height = 480, pointsize = 12, gamma = 1, colortype =
getOption("X11colortype"),
       maxcubesize = 256, bg = "white", fonts = getOption("X11fonts"),
       res = NA)
   .Internal(X11(paste("png::", filename, sep = ""), width, height,
       pointsize, gamma, colortype, maxcubesize, bg, bg, fonts,
       res)), width = 6.98715785526809, height = 6.99452568428947)
5: eval(expr, envir, enclos)
4: eval(expr, p)
3: eval.parent(oc)
2: dev.off(eval.parent(oc))
1: dev.print(png)

I noticed it on OS X, and Simon on Linux. Other platforms?
WFM?

TIA

> version
         _
platform powerpc-apple-darwin7.9.0
arch     powerpc
os       darwin7.9.0
system   powerpc, darwin7.9.0
status   Patched
major    2
minor    2.1
year     2006
month    02
day      01
svn rev  37245
language R

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From rpeng at jhsph.edu  Wed Feb  8 23:45:54 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 08 Feb 2006 17:45:54 -0500
Subject: [Rd] corruption of data with serialize(ascii=TRUE)
Message-ID: <43EA74A2.2000607@jhsph.edu>

I noticed the following peculiarity with `serialize()' when `ascii = TRUE' is 
used.  In today's (svn r37299) R-devel, I get

 > set.seed(10)
 > x <- rnorm(10)
 >
 > a <- serialize(x, con = NULL, ascii = TRUE)
 > b <- unserialize(a)
 >
 > identical(x, b)  ## FALSE
[1] FALSE
 > x - b
  [1] -3.469447e-18  2.775558e-17 -4.440892e-16  0.000000e+00  5.551115e-17
  [6] -5.551115e-17 -4.440892e-16  0.000000e+00  2.220446e-16 -5.551115e-17


I expected `x' and `b' to be identical, which is what I get when `ascii = FALSE':

 > a <- serialize(x, con = NULL, ascii = FALSE)
 > b <- unserialize(a)
 >
 > identical(x, b)  ## TRUE
[1] TRUE


The same phenomenon occurs with `.saveRDS(ascii = TRUE)',

 > .saveRDS(x, file = "asdf", ascii = TRUE)
 > d <- .readRDS("asdf")
 >
 > identical(x, d)  ## FALSE
[1] FALSE
 >

Has anyone noticed this before?  I didn't see anything in the docs for 
`serialize()' that would indicate this behavior should be expected.

I'm on Linux Fedora Core 4.

-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Thu Feb  9 08:18:52 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 07:18:52 +0000 (GMT)
Subject: [Rd] corruption of data with serialize(ascii=TRUE)
In-Reply-To: <43EA74A2.2000607@jhsph.edu>
References: <43EA74A2.2000607@jhsph.edu>
Message-ID: <Pine.LNX.4.64.0602090707440.26108@gannet.stats.ox.ac.uk>

It is known (happens with save() too and did in earlier save formats). 
Nothing particularly clever is done (the format is "%.16g\n") and 
similarly as.character/parse are not inverses.

Perhaps more relevant is

> b/x -1
  [1]  0.000000e+00 -1.110223e-16  2.220446e-16  0.000000e+00  0.000000e+00
  [6]  2.220446e-16  4.440892e-16  0.000000e+00  2.220446e-16  0.000000e+00

so the error (on my system) is about what you would expect from 
floating-point computations.

There is a comment in serialize.c

 	    /* 16: full precision; 17 gives 999, 000 &c */

which suggests that the format is optimized for size not maximal possible 
accuracy.

Really all you have said is `floating point operations are subject to 
rounding error'.


On Wed, 8 Feb 2006, Roger D. Peng wrote:

> I noticed the following peculiarity with `serialize()' when `ascii = TRUE' is
> used.  In today's (svn r37299) R-devel, I get
>
> > set.seed(10)
> > x <- rnorm(10)
> >
> > a <- serialize(x, con = NULL, ascii = TRUE)
> > b <- unserialize(a)
> >
> > identical(x, b)  ## FALSE
> [1] FALSE
> > x - b
>  [1] -3.469447e-18  2.775558e-17 -4.440892e-16  0.000000e+00  5.551115e-17
>  [6] -5.551115e-17 -4.440892e-16  0.000000e+00  2.220446e-16 -5.551115e-17
>
>
> I expected `x' and `b' to be identical, which is what I get when `ascii = FALSE':
>
> > a <- serialize(x, con = NULL, ascii = FALSE)
> > b <- unserialize(a)
> >
> > identical(x, b)  ## TRUE
> [1] TRUE
>
>
> The same phenomenon occurs with `.saveRDS(ascii = TRUE)',
>
> > .saveRDS(x, file = "asdf", ascii = TRUE)
> > d <- .readRDS("asdf")
> >
> > identical(x, d)  ## FALSE
> [1] FALSE
> >
>
> Has anyone noticed this before?  I didn't see anything in the docs for
> `serialize()' that would indicate this behavior should be expected.
>
> I'm on Linux Fedora Core 4.
>
> -roger
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Thu Feb  9 10:33:36 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 9 Feb 2006 17:33:36 +0800
Subject: [Rd] Question on help system under windows
Message-ID: <17387.3184.995825.81172@bossiaea.maths.uwa.edu.au>

G'day all,

I spend today sometime playing around with R under Windows since our
lecturing starts in 2 weeks again and our IT guys want to know which
version to put onto our lab machines.

I noticed the following:

Under R-2.2.1, I obtain the following output:
      > R.home()
      [1] "C:\\PROGRA~1\\R\\R-22~1.1"
and if I run "help.start()" under R, I obtain a file "fixedHTMLlinks"
in packages that are not installed in the standard library with entry:
      file:///C:/PROGRA~1/R/R-22~1.1
And the index help page of such a package is updated such that it has
links like: 
      file:///C:/PROGRA~1/R/R-22~1.1/doc/html/logo.jpg
in it.  So this seems all to be fine.

However, when I install R-2.2.1 patched, I get the following output:
      > R.home()
      [1] "C:\\PROGRA~1\\R\\R-22~1.1PA"
and if I run "help.start()" under R, I obtain a file "fixedHTMLlinks"
(needless to say, I deleted the previous file before running
help.start) in packages that are not installed in the standard library
with entry: 
      file:///C:/PROGRA~1/R/R-22~1.1PA
Which seems also correct.  However, the index help page of such a
package, although its modification time was the time help.start() was
run, still has links like:
      file:///C:/PROGRA~1/R/R-22~1.1/doc/html/logo.jpg
in it.  This, of course, stopped working when I un-installed R-2.2.1
and only kept R-2.2.1 patched.  

Do I have a misconception of what help.start() is doing?  Or is this a
bug?

Moreover, these machines still have R-2.2.0 installed, when I started
R-2.2.0, I got the output:
      > R.home()
      [1] "C:\\PROGRA~1\\R\\R-22~1.0"
and running help.start() creates "fixedHTMLlinks" with entry:
      file:///C:/PROGRA~1/R/R-22~1.0
Also, during my test the index help page of such a package was changed
to have links like:
      file:///C:/PROGRA~1/R/R-22~1.0/doc/html/logo.jpg

However, when I wanted to discuss these findings with our IT person
(at which time I had deinstalled R-2.2.1 and R-2.2.1 patched),
everytime we run help.start() from R-2.2.0, the modification dates of
the html files changed, but the links were still of the type:
     file:///C:/PROGRA~1/R/R-22~1.1/doc/html/logo.jpg
So we were completely baffled why R-2.2.0 would write an R-2.2.1 link
into these files. (???)

To make things more complicated, those packages are not only not in
the standard library, but the library they are in is on another drive
(the network drive).  We couldn't get compiled html help working for
such packages at all under any of the recent versions of R.  I looked
into the manuals, FAQ, RSiteSearch() &c for information about compiled
help, but couldn't find anything that described how to get compiled
help working for packages in a library that is on another drive than R
is.  So our question is also whether this is possible?

Thanks for any advice that you might be able to offer.

Cheers,

        Berwin


From ligges at statistik.uni-dortmund.de  Thu Feb  9 10:49:21 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 09 Feb 2006 10:49:21 +0100
Subject: [Rd] Question on help system under windows
In-Reply-To: <17387.3184.995825.81172@bossiaea.maths.uwa.edu.au>
References: <17387.3184.995825.81172@bossiaea.maths.uwa.edu.au>
Message-ID: <43EB1021.3080400@statistik.uni-dortmund.de>

Berwin A Turlach wrote:

> G'day all,
> 
> I spend today sometime playing around with R under Windows since our
> lecturing starts in 2 weeks again and our IT guys want to know which
> version to put onto our lab machines.
> 
> I noticed the following:
> 
> Under R-2.2.1, I obtain the following output:
>       > R.home()
>       [1] "C:\\PROGRA~1\\R\\R-22~1.1"
> and if I run "help.start()" under R, I obtain a file "fixedHTMLlinks"
> in packages that are not installed in the standard library with entry:
>       file:///C:/PROGRA~1/R/R-22~1.1
> And the index help page of such a package is updated such that it has
> links like: 
>       file:///C:/PROGRA~1/R/R-22~1.1/doc/html/logo.jpg
> in it.  So this seems all to be fine.
> 
> However, when I install R-2.2.1 patched, I get the following output:
>       > R.home()
>       [1] "C:\\PROGRA~1\\R\\R-22~1.1PA"
> and if I run "help.start()" under R, I obtain a file "fixedHTMLlinks"
> (needless to say, I deleted the previous file before running
> help.start) in packages that are not installed in the standard library
> with entry: 
>       file:///C:/PROGRA~1/R/R-22~1.1PA
> Which seems also correct.  However, the index help page of such a
> package, although its modification time was the time help.start() was
> run, still has links like:
>       file:///C:/PROGRA~1/R/R-22~1.1/doc/html/logo.jpg
> in it.  This, of course, stopped working when I un-installed R-2.2.1
> and only kept R-2.2.1 patched.  
> 
> Do I have a misconception of what help.start() is doing?  Or is this a
> bug?
> 
> Moreover, these machines still have R-2.2.0 installed, when I started
> R-2.2.0, I got the output:
>       > R.home()
>       [1] "C:\\PROGRA~1\\R\\R-22~1.0"
> and running help.start() creates "fixedHTMLlinks" with entry:
>       file:///C:/PROGRA~1/R/R-22~1.0
> Also, during my test the index help page of such a package was changed
> to have links like:
>       file:///C:/PROGRA~1/R/R-22~1.0/doc/html/logo.jpg
> 
> However, when I wanted to discuss these findings with our IT person
> (at which time I had deinstalled R-2.2.1 and R-2.2.1 patched),
> everytime we run help.start() from R-2.2.0, the modification dates of
> the html files changed, but the links were still of the type:
>      file:///C:/PROGRA~1/R/R-22~1.1/doc/html/logo.jpg
> So we were completely baffled why R-2.2.0 would write an R-2.2.1 link
> into these files. (???)
> 
> To make things more complicated, those packages are not only not in
> the standard library, but the library they are in is on another drive
> (the network drive).  We couldn't get compiled html help working for
> such packages at all under any of the recent versions of R.  I looked
> into the manuals, FAQ, RSiteSearch() &c for information about compiled
> help, but couldn't find anything that described how to get compiled
> help working for packages in a library that is on another drive than R
> is.  So our question is also whether this is possible?


For the latter, a recent patch from Microsoft has disabled the feature 
to display *framed* compiled html located on network drives.
According to Microsoft documentation you can re-enable it using the 
following registry setting - note that this a security issue!

[HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\HTMLHelp\1.x\HHRestrictions]
"EnableFrameNavigationInSafeMode"=dword:00000001


Uwe Ligges



> Thanks for any advice that you might be able to offer.
> 
> Cheers,
> 
>         Berwin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From b.otto at uke.uni-hamburg.de  Thu Feb  9 13:45:17 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Thu, 9 Feb 2006 13:45:17 +0100
Subject: [Rd] [R] readline detection problems
In-Reply-To: <43E35BB4.9070207@cimr.cam.ac.uk>
Message-ID: <NOEOKKCPBGIAIPPDONMGEEJBCBAA.b.otto@uke.uni-hamburg.de>

Dear Mr. Ripley, Mr. Leung, Mrs. Hawkins,

many thanks for the intensive help you provided me concerning the readline
problem although I should have looked in the installation manual more
thoroughly. It turned out as you already suspected that the problem with
getting the configure script detecting the new readline library could be
easily solved by setting the CFLGAS. In fact, setting the CPPFLGAS and
LDFLAGS alone results in detection of the header files but not the library
files.

On the other hand setting the CFLAGS alone seems to be enough for the
detection of both library and header files thus solving the problem without
necessity of the previous two flags. However that seems to apply only for
the configure script. Under native conditions with the flags set the make
command fails in locating the -lreadline flag during compilation. I suppose
that should be solved with linking the library via ldconfig in a personal
local cache file. I'm working on that.


regards,
Benjamin Otto


> -----Original Message-----
> From: Hin-Tak Leung [mailto:hin-tak.leung at cimr.cam.ac.uk]
> Sent: 03 February 2006 14:34
> Cc: Benjamin Otto; r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] [R] readline detection problems
>
>
> Prof Brian Ripley wrote:
> > On Fri, 3 Feb 2006, Benjamin Otto wrote:
> >
> >
> >>Dear Mr. Ripley,
> >>
> >>thanks for the quick reply. I set these flags now, however
> there still seem
> >>to be some problems with readline. The corresponding cofigure output is:
> >>
> >>checking readline/history.h usability... yes
> >>checking readline/history.h presence... yes
> >>checking for readline/history.h... yes
> >>checking readline/readline.h usability... yes
> >>checking readline/readline.h presence... yes
> >>checking for readline/readline.h... yes
> >>checking for rl_callback_read_char in -lreadline... no
> >>checking for main in -lncurses... no
> >>checking for main in -ltermcap... yes
> >>checking for rl_callback_read_char in -lreadline... no
> >>checking for history_truncate_file... no
> >>configure: error: --with-readline=yes (default) and headers/libs are not
> >>available
> >
> >
> > What does config.log say?  It looks like it is not finding
> libreadline.so.
> > You may need LD_LIBRARY_PATH set to include where it is.
>
> LD_LIBRARY_PATH affects the dynamic link loader, which is probably not
> the issue here. the barbaric manipulation of CFLAGS (=-I and -L)
> is needed.
>
> >>The existing compiler is gcc version 2.8.1 and the linker
> editor used by gcc
> >
> >
> > Wow, that is really old!
>
> 2.8.1 would be pre-cygnus/egcs , 1997-1998 ... should breath down the
> sys-admin's neck to get it upgraded - ncurse, termcap, tcltk, etc
> would be rather old as well...
>


From rpeng at jhsph.edu  Thu Feb  9 14:10:55 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 09 Feb 2006 08:10:55 -0500
Subject: [Rd] corruption of data with serialize(ascii=TRUE)
In-Reply-To: <Pine.LNX.4.64.0602090707440.26108@gannet.stats.ox.ac.uk>
References: <43EA74A2.2000607@jhsph.edu>
	<Pine.LNX.4.64.0602090707440.26108@gannet.stats.ox.ac.uk>
Message-ID: <43EB3F5F.2050904@jhsph.edu>

Okay, I just wasn't sure of the source of the changes.  In retrospect, character 
and other vectors did serialize/unserialize to the original objects.

-roger

Prof Brian Ripley wrote:
> It is known (happens with save() too and did in earlier save formats). 
> Nothing particularly clever is done (the format is "%.16g\n") and 
> similarly as.character/parse are not inverses.
> 
> Perhaps more relevant is
> 
>> b/x -1
>  [1]  0.000000e+00 -1.110223e-16  2.220446e-16  0.000000e+00  0.000000e+00
>  [6]  2.220446e-16  4.440892e-16  0.000000e+00  2.220446e-16  0.000000e+00
> 
> so the error (on my system) is about what you would expect from 
> floating-point computations.
> 
> There is a comment in serialize.c
> 
>         /* 16: full precision; 17 gives 999, 000 &c */
> 
> which suggests that the format is optimized for size not maximal 
> possible accuracy.
> 
> Really all you have said is `floating point operations are subject to 
> rounding error'.
> 
> 
> On Wed, 8 Feb 2006, Roger D. Peng wrote:
> 
>> I noticed the following peculiarity with `serialize()' when `ascii = 
>> TRUE' is
>> used.  In today's (svn r37299) R-devel, I get
>>
>> > set.seed(10)
>> > x <- rnorm(10)
>> >
>> > a <- serialize(x, con = NULL, ascii = TRUE)
>> > b <- unserialize(a)
>> >
>> > identical(x, b)  ## FALSE
>> [1] FALSE
>> > x - b
>>  [1] -3.469447e-18  2.775558e-17 -4.440892e-16  0.000000e+00  
>> 5.551115e-17
>>  [6] -5.551115e-17 -4.440892e-16  0.000000e+00  2.220446e-16 
>> -5.551115e-17
>>
>>
>> I expected `x' and `b' to be identical, which is what I get when 
>> `ascii = FALSE':
>>
>> > a <- serialize(x, con = NULL, ascii = FALSE)
>> > b <- unserialize(a)
>> >
>> > identical(x, b)  ## TRUE
>> [1] TRUE
>>
>>
>> The same phenomenon occurs with `.saveRDS(ascii = TRUE)',
>>
>> > .saveRDS(x, file = "asdf", ascii = TRUE)
>> > d <- .readRDS("asdf")
>> >
>> > identical(x, d)  ## FALSE
>> [1] FALSE
>> >
>>
>> Has anyone noticed this before?  I didn't see anything in the docs for
>> `serialize()' that would indicate this behavior should be expected.
>>
>> I'm on Linux Fedora Core 4.
>>
>> -roger
>>
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From parker at quartz.gly.fsu.edu  Thu Feb  9 15:02:52 2006
From: parker at quartz.gly.fsu.edu (parker@quartz.gly.fsu.edu)
Date: Thu,  9 Feb 2006 15:02:52 +0100 (CET)
Subject: [Rd] R, Rcmdr crash on WinXP PRO laptop (PR#8583)
Message-ID: <20060209140252.BEE8D3F229@slim.kubism.ku.dk>

My system is a Dell laptop running Win XP Pro with SP2 and all current 
updates. R is version 2.2.1, Rcmdr is version 1.1-6 (also happens with 1.1-5).

First attempt to import data from text file (in Rcmdr) works correctly with 
no errors or warnings. Second, third or fourth attempt to load same data or 
a similar dataset will cause all R windows, including Rcmdr and R console 
windows, to disappear when cursor is placed over data file icon in file 
selection window. Although R appears to have crashed and exited, use of the 
Windows taskmanager reveals that Rgui is still an active process consuming 
99% of cpu. Each subsequent reload and crash of R will yield another Rgui 
process, until the system slows to a halt (or I manually delete the Rgui 
processes). System and Application event viewers show no errors or warnings.

Same R and Rcmdr installed on a Dell Dimension desktop with Windows 2000, 
SP4, all current updates, does not exhibit this problem.

Any help or suggestions will be appreciated.

Thankyou

Bill Parker


From murdoch at stats.uwo.ca  Thu Feb  9 17:18:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 09 Feb 2006 11:18:36 -0500
Subject: [Rd] R, Rcmdr crash on WinXP PRO laptop (PR#8583)
In-Reply-To: <20060209140252.BEE8D3F229@slim.kubism.ku.dk>
References: <20060209140252.BEE8D3F229@slim.kubism.ku.dk>
Message-ID: <43EB6B5C.6070003@stats.uwo.ca>

On 2/9/2006 9:02 AM, parker at quartz.gly.fsu.edu wrote:
> My system is a Dell laptop running Win XP Pro with SP2 and all current 
> updates. R is version 2.2.1, Rcmdr is version 1.1-6 (also happens with 1.1-5).
> 
> First attempt to import data from text file (in Rcmdr) works correctly with 
> no errors or warnings. Second, third or fourth attempt to load same data or 
> a similar dataset will cause all R windows, including Rcmdr and R console 
> windows, to disappear when cursor is placed over data file icon in file 
> selection window. Although R appears to have crashed and exited, use of the 
> Windows taskmanager reveals that Rgui is still an active process consuming 
> 99% of cpu. Each subsequent reload and crash of R will yield another Rgui 
> process, until the system slows to a halt (or I manually delete the Rgui 
> processes). System and Application event viewers show no errors or warnings.
> 
> Same R and Rcmdr installed on a Dell Dimension desktop with Windows 2000, 
> SP4, all current updates, does not exhibit this problem.
> 
> Any help or suggestions will be appreciated.

This might be an R bug, but it may also be some other software that you 
have installed that's integrated into Explorer, e.g. an anti-virus 
program.  When you open a file dialog all sorts of DLLs run, depending 
on what you've got installed.  It sounds as though one of them is 
incompatible with R/Rcmdr.

If you can give specific instructions for reproducing the crash, I'll 
try it, but I just tried a version of your description above and saw no 
problems.  I'm using the same version of XP, R, and Rcmdr as you, so I 
suspect that I was either doing something different than you, or you 
have something installed that I don't.

Duncan Murdoch


From sfalcon at fhcrc.org  Thu Feb  9 17:19:35 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 09 Feb 2006 08:19:35 -0800
Subject: [Rd] NAMESPACE Q: does import as exist?
In-Reply-To: <Pine.LNX.4.63.0602081136340.21301@nokomis.stat.uiowa.edu> (Luke
	Tierney's message of "Wed, 8 Feb 2006 12:11:36 -0600 (CST)")
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local> <43E9DFBC.4090704@stats.uwo.ca>
	<m2lkwldgl8.fsf@ziti.local>
	<Pine.LNX.4.63.0602081136340.21301@nokomis.stat.uiowa.edu>
Message-ID: <m2irro7be0.fsf@ziti.local>

Hi Luke,

Thanks very much for the explanation.

On  8 Feb 2006, luke at stat.uiowa.edu wrote:
> Allowing for renaming complicates the code; it also may prevent, or
> at least significantly complicate, changes in the implementation we
> might want to make.

Makes sense that this feature is not of highest priority.  Renaming
will always be available as newFoo <- somePkg::foo.  The ability to do
the renaming in the NAMESPACE file has the added advantage of being
declarative.  That has value, but certainly one can get by without
it.  

Given that newFoo <- somePkg::foo will always work, I would think that
getting it to work in the NAMESPACE file shouldn't add too much
complexity, but I recognize this is a naive view.

> On the other hand this might be quite useful in some settings.  We
> had some disagrements about how useful, so the compromise was to
> leave the facility in but not officially document it, and wait and
> see what the need looks like.  This is the first request I recall in
> almost three years since the mechanism was introduced, so it is not
> a major issue.

My bias is obvious from this thread; I think this is a valuable
feature and I'm not sure the count of requests in the past 3 yrs is a
fair measure.  There is, perhaps, a feedback loop: 

  more doc (plus beating with sticks)  => more use of namespaces
                                       => more feature requests

In the end, I would like to see more packages use namespaces and I
think this would be helped by more doc and examples.

> So if you want to use this do so with caution.  If we see
> substantial usage we may need to think about formally documenting
> and testing this; but only after carefully considering whether it
> does impose limits on other things we would like to do.

That is clear.  One last thought that I didn't see mentioned in the
namespace notes on your website:

Is there a way to say in the NAMESPACE file: 

  I'm going to use pkgFoo, please load the package, but don't import
  anything because I will access via pkgFoo::

I realize that '::' will load pkgFoo on demand.  My reservation about
using :: is that it is easy to lose track of the fact that my package
needs pkgFoo.  I like the idea that all of my package's dependencies
are easily parsable by the system.

Having written that, I realize that the Imports field in DESCRIPTION
gives me a way to do this --- but in an ideal world I would need to
duplicate info from NAMESPACE in DESCRIPTION.

Best Wishes,

+ seth


From sfalcon at fhcrc.org  Thu Feb  9 17:23:36 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 09 Feb 2006 08:23:36 -0800
Subject: [Rd] How to change names when importing with a NAMESPACE
In-Reply-To: <Pine.LNX.4.64.0602081904310.28253@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Wed, 8 Feb 2006 19:08:04 +0000 (GMT)")
References: <D79013E40FEF254AAF0D72DFC94F274816B00B@extas4-hba.tas.csiro.au>
	<m2mzh2edjq.fsf@ziti.local> <43E9DFBC.4090704@stats.uwo.ca>
	<m2lkwldgl8.fsf@ziti.local> <m23bitdbjm.fsf_-_@ziti.local>
	<Pine.LNX.4.64.0602081904310.28253@gannet.stats.ox.ac.uk>
Message-ID: <m2acd07b7b.fsf@ziti.local>

On  8 Feb 2006, ripley at stats.ox.ac.uk wrote:
> This is indeed described in
>
> http://www.stat.uiowa.edu/~luke/R/namespaces/morenames.html
>
> linked from developer.r-project.org.
>
> with the comment
>
> The purpose of baz is to import some of the exports of foo and bar
> and re-export them, using renaming in one case: bar's export g is
> imported under the internal name hh, and the internal variable hh is
> exported under the name gg. [Renaming seems like a useful option,
> but it may turn out to create too many complications and need to be
> dropped.]
>
> It's been there since 1.7.0 and not yet been dropped.

I'd like to interpret that as an endorsement that this feature is
likely to stay around.  Luke's comments indicates that at least in his
opinion the provisional nature is just as much provisional as now.

> It would be nice to have more end-user documentation on namespaces,
> and I have suggested it in the past.  A project for you, perhaps?

:-)

I will very likely write something up, at least as a summary of
lessons learned from this email exchange.  

+ seth


From cadet at odd.bio.sunysb.edu  Thu Feb  9 18:39:56 2006
From: cadet at odd.bio.sunysb.edu (cadet@odd.bio.sunysb.edu)
Date: Thu,  9 Feb 2006 18:39:56 +0100 (CET)
Subject: [Rd] make: Target `all' not remade because of errors. (PR#8585)
Message-ID: <20060209173956.5553C3F225@slim.kubism.ku.dk>

Full_Name: Je Cade
Version: R-2.2.1
OS: RedHat 9
Submission from: (NULL) (129.49.108.173)



I followed the instructions. tar -xvf, configure, then make.
I get these error messages at the end of make and with make check. 
==================================================================
==================================================================
In file included from rbitmap.c:45:
/usr/include/png.h:318:18: zlib.h: No such file or directory
In file included from /usr/include/png.h:321,
                 from rbitmap.c:45:
/usr/include/pngconf.h:1091: error: parse error before '*' token
/usr/include/pngconf.h:1092: error: parse error before '*' token
/usr/include/pngconf.h:1093: error: parse error before '*' token
In file included from rbitmap.c:45:
/usr/include/png.h:1034: error: parse error before "z_stream"
/usr/include/png.h:1262: error: parse error before '}' token
/usr/include/png.h:1821: error: parse error before "png_zalloc"
/usr/include/png.h:1821: error: parse error before "png_ptr"
/usr/include/png.h:1825: error: parse error before "png_ptr"
rbitmap.c: In function `my_png_error':
rbitmap.c:72: error: dereferencing pointer to incomplete type
rbitmap.c: In function `R_SaveAsPng':
rbitmap.c:121: error: dereferencing pointer to incomplete type
make[4]: *** [rbitmap.lo] Error 1
make[4]: Target `R_X11.so' not remade because of errors.
make[4]: Leaving directory `/users/cadet/R-2.2.1/src/modules/X11'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/users/cadet/R-2.2.1/src/modules/X11'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/users/cadet/R-2.2.1/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/users/cadet/R-2.2.1/src'
make: *** [R] Error 1
make: Target `all' not remade because of errors.
giant {122} make check
make[1]: Entering directory `/users/cadet/R-2.2.1/tests'
make[2]: Entering directory `/users/cadet/R-2.2.1/tests'
make[3]: Entering directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: Entering directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: `Makedeps' is up to date.
make[4]: Leaving directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: Entering directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: *** No rule to make target `../../src/library/base/all.R', needed by
`base-Ex.Rout'.  Stop.
make[4]: Leaving directory `/users/cadet/R-2.2.1/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory `/users/cadet/R-2.2.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/users/cadet/R-2.2.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/users/cadet/R-2.2.1/tests'
make: *** [check] Error 2


From ripley at stats.ox.ac.uk  Thu Feb  9 20:40:29 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu,  9 Feb 2006 20:40:29 +0100 (CET)
Subject: [Rd] make: Target `all' not remade because of errors. (PR#8585)
Message-ID: <20060209194029.F38E5103EC@slim.kubism.ku.dk>

Why did you think this was an error in R?  This is an error from a 
*system* header file about a missing *system* header file.

It look like on your system libpng-devel has been installed without its 
dependency zlib-devel. In all the years this has been in R we have never 
encountered such a system, and RPM management is supposed to prevent it 
happening (see below).

You can work around this by altering src/include/config.h to not define 
HAVE_PNG.

Please seek help elsewhere about fixing your OS (which is no longer 
supported by RedHat, of course).

On an FC3 box

gannet% rpm -q --whatprovides /usr/include/png.h
libpng-devel-1.2.8-1.fc3
gannet% rpm -q --whatprovides /usr/include/zlib.h
zlib-devel-1.2.1.2-3.fc3
gannet% rpm -q -R libpng-devel-1.2.8-1.fc3
/bin/sh
libpng = 2:1.2.8
rpmlib(CompressedFileNames) <= 3.0.4-1
rpmlib(PayloadFilesHavePrefix) <= 4.0-1
zlib-devel
^^^^^^^^^^

On Thu, 9 Feb 2006, cadet at odd.bio.sunysb.edu wrote:

> Full_Name: Je Cade
> Version: R-2.2.1
> OS: RedHat 9
> Submission from: (NULL) (129.49.108.173)
>
>
>
> I followed the instructions. tar -xvf, configure, then make.
> I get these error messages at the end of make and with make check.
> ==================================================================
> ==================================================================
> In file included from rbitmap.c:45:
> /usr/include/png.h:318:18: zlib.h: No such file or directory

This is the problem.

> In file included from /usr/include/png.h:321,
>                 from rbitmap.c:45:
> /usr/include/pngconf.h:1091: error: parse error before '*' token
> /usr/include/pngconf.h:1092: error: parse error before '*' token
> /usr/include/pngconf.h:1093: error: parse error before '*' token
> In file included from rbitmap.c:45:
> /usr/include/png.h:1034: error: parse error before "z_stream"
> /usr/include/png.h:1262: error: parse error before '}' token
> /usr/include/png.h:1821: error: parse error before "png_zalloc"
> /usr/include/png.h:1821: error: parse error before "png_ptr"
> /usr/include/png.h:1825: error: parse error before "png_ptr"
> rbitmap.c: In function `my_png_error':
> rbitmap.c:72: error: dereferencing pointer to incomplete type
> rbitmap.c: In function `R_SaveAsPng':
> rbitmap.c:121: error: dereferencing pointer to incomplete type
> make[4]: *** [rbitmap.lo] Error 1
> make[4]: Target `R_X11.so' not remade because of errors.

[...]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Fri Feb 10 02:57:51 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 9 Feb 2006 20:57:51 -0500
Subject: [Rd] ?bquote
Message-ID: <971536df0602091757hd69d838l5c58166e714a790e@mail.gmail.com>

?bquote says it returns an expression but, in fact, it typically
(though not always) returns a call object:

> class(bquote(a+b))
[1] "call"

> class(bquote(1))
[1] "numeric"


From john.maindonald at anu.edu.au  Fri Feb 10 11:01:44 2006
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 10 Feb 2006 21:01:44 +1100
Subject: [Rd] Citation of R packages
In-Reply-To: <17380.51173.64968.956060@celebrian.ci.tuwien.ac.at>
References: <1578.202.89.153.187.1138576012.squirrel@sqmail.anu.edu.au>
	<17380.51173.64968.956060@celebrian.ci.tuwien.ac.at>
Message-ID: <511271C5-05FF-4B0A-8776-51D13DE9F043@anu.edu.au>

On 5 Feb 2006, at 2:27 AM, Friedrich.Leisch at tuwien.ac.at wrote:

>>>>>> On Mon, 30 Jan 2006 10:06:52 +1100 (EST),
>>>>>> John Maindonald (JM) wrote:
>
>> The bibtex citations provided by citation() do not
>> work all that well in cases where there is no printed
>> document to reference:
>
> That's why there is a warning at the end that they will need manual
> editing ... IMHO they at least save you some typing effort in many
> cases.

They are certainly a useful start.

>> (1) A version field is needed, as the note field is
>> required for other purposes, currently trying to
>> sort out nuances that cannot be sorted out in the
>> author list (author, compiler, implementor of R version,
>> contributor, ...) and maybe giving a cross-reference
>> to a book or paper that is somehow relevant.
>
> Why should a reference cross-reference another reference? Could you
> give an example?

Where there is a published paper or a book (such as MASS), or a manual
for which a url can be given, my decision was to include that in the  
main
list of references, but not to include references there that were  
references
to the package itself, which as you suggest below can be a reference to
the concatenated help pages.

It seemed anyway useful to have a separate list of packages.  For
consistency, these were always references to the package, with a
cross-reference to any relevant document in the references to papers.

>> (2) Maybe the author field should be more nuanced, or
>> maybe ...
>
> author fields of bibtex entries have a strict format (names separated
> by "and"), what do you mean by "more nuanced"?

Those named in the list of authors may be any combination of: the  
authors
of an R package, the authors of an original S version, the person or  
persons
responsible for an R port, the authors of the Fortran code, compiler 
(s), and
contributors of ideas.

For John Fox's car, citation() gives the following:
     author = {John Fox. I am grateful to Douglas Bates and David  
Firth and Michael Friendly and Gregor Gorjanc and Georges Monette and  
Henric Nilsson and Brian Ripley and Sanford Weisberg and and Achim  
Zeleis for various suggestions and contributions.},

For Rcmdr:
     author = {John Fox and with contributions from Michael Ash and  
Philippe Grosjean and Martin Maechler and Dan Putler and and Peter  
Wolf.},

For car, maybe John Fox should be identified as author.  For Rcmdr,  
maybe the other persons that are named should be added?

For leaps:
     author = {Thomas Lumley using Fortran code by Alan Miller},

It seems reasonable to cite Lumley and Miller as authors.  Should  
there be a note that identifies Miller as the contributor of the  
Fortran code?

Should the name(s) of porters (usually from S) be included as author 
(s)?  Or should their contribution be acknowledged in the note field?  
Or ...

Possibilities are to cite all those individuals as author, or to cite  
John Fox only,
with any combination of no additional information in the note field,  
or using the
note field to explain who did what.  The citation() function leaves  
it unclear who
are to be acknowledged as authors, and in fact

>> (3) In compiling a list of packages, name order seems
>> preferable, and one wants the title first (achieved by
>> relocating the format.title field in the manual FUNCTION
>> in the .bst file
>> (4) manual seems not an ideal name for the class, if
>> there is no manual.
>
> A package always has a "reference manual", the concatenated help pages
> certainly qualify as such and can be downloaded in PDF format from
> CRAN. The ISBN rules even allow to assign an ISBN number to the online
> help of a software package which also can serve as the ISBN number of
> the *software itself* (which we did for base R).

I'd prefer some consistency in the way that R packages are referenced.
Thus, if reference for one package is to the concatenated help pages,
do it that way for all of them.

>> Maybe what is needed is a package or suchlike class,
>> and several alternative .bst files that handle the needed
>> listings.
>
>> I know at least one other person who is wrestling with
>> this, and others on this list must be wrestling with it.
>
> I am certainly open for discussions and any suggestions for
> improvements, but it must be within the standard bibtex entry types,
> we cannot write our own entry types and .bst files. Many journals
> require the usage of their own (or standard) bibtex styles, and the
> entries we produce must work with those. If R creates nonstandard
> bibtex entries even more manual work will be necessary in many
> cases.
>
> I have no definitive bibtex reference at hand, but the natbib style
> files (a very popular collection of bibtex styles, at least I
> definitely want to be compatible with those) define
>
>  article
>  book
>  booklet
>  conference  (= alias for inproceedings)
>  inbook
>  incollection
>  inproceedings
>  manual
>  mastersthesis
>  misc
>  phdthesis
>  proceedings
>  techreport
>  unpublished
>
> which coincide with the choices the emacs bibtex mode offers. Out of
> these only "manual", "misc" and "unpublished" seem appropriate for
> packages, and the description suggests to use manual for citing
> software manuals, but the definitions of those three are very similar
> anyway.
>
> Maybe you could give an example what your candidate for a bibtex entry
> for packages should look like?

It will depend on context.  The requirement for a paper will be  
different
from that for a book.

Here's what I've done for boot:

@Manual{boot-package,
     title = {boot: Bootstrap R (S-Plus) Functions (Canty)},
     author = "{\noopsort{boot}}{Canty, A. and Ripley, B.}",
     key  = {boot},
     year = {2005},
     note = {(Version 1.2-24). S original by A.~Canty; R port by  
B.~Ripley.
See further \citet{Canty}}
   }

Maybe I should either omit the version number or include it along
with the title.

John


> Best,
> Fritz
>
> -- 
> -------------------------------------------------------------------
>                         Friedrich Leisch
> Institut f?r Statistik                     Tel: (+43 1) 58801 10715
> Technische Universit?t Wien                Fax: (+43 1) 58801 10798
> Wiedner Hauptstra?e 8-10/1071
> A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
> -------------------------------------------------------------------

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Mathematical Sciences Institute, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From hb at maths.lth.se  Fri Feb 10 11:27:14 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 10 Feb 2006 11:27:14 +0100
Subject: [Rd] R CMD build: "Subdirectory 'R' contains invalid file names"
Message-ID: <59d7961d0602100227s5e1d3dbahbfcca5dd386b02d3@mail.gmail.com>

Hi, I get

* excluding invalid files from 'R.oo'
Subdirectory 'R' contains invalid file names:
  attachLocally.Object.Rex Exception.Rex extend.default.Rex
  InternalErrorException.reportBug.Rex Package.Rex Person.Rex Rdoc.Rex
  setMethodS3.Rex StaticFields.Rex

when running R CMD build in R v2.3.0 devel.  I do understand what is
going on.  In my *.R files I keep so called Rdoc comments which in
their simplest form are Rd code wrapped up in plain comments.  These
are compiled into Rd files written to ../man/ (I do this prior to
building packages).  Rdoc also supports inclusion of other files, e.g.
@include "Person.Rex" to include example code.

With this structure I can, when I develop/maintain a package, have
<pkg>/R/ as the working directory, modify my *.R files and re-source
them from within R.  Since I keep all my Rd example code in separate
*.Rex files, I can easily rerun/test these by sourcing them too.  I
find this very convenient.

In previous versions, the *.Rex files was included when building a
source distribution of a package.  In R v2.3.0 they are excluded. 
However, I would like to distribute the *.Rex files with my
source-code package too (so I do not have to keep another type of
source distribution).  Note that these files are only needed for
further development of the package, but *not* to install the package
from source (since their contents is already incorporated in the Rd
files).  They are also not of interest to the end-user.

My question is how to incorporate the *.Rex files?  Here are some
ideas, that I would like to have some feedback on:

1) Put them in <pkg>/R/Rex/*.Rex.  However, Section 1.1.4 in Writing R
Extensions suggest that subdirectories of R/ may only(?) be named
'windows' or 'unix'.

2) Rename them to <pkg>/R/*.in, cf. Section 1.1.4.  Is this the
purpose of *.in files?  Will it have side effects?

3) Put the in <pkg>/inst/<dir>/*.Rex.  This will work, but then they
will also be install and available in system.file("<dir>",
package="<pkg>").  Not a big problem, but not what I want.

4) To avoid (3), put the in <pkg>/<dir>/*.Rex, i.e. at the top level
directory.  Is this allowed?  Section 1.1.4 says "Note that [...]
information files at the top level of the package will not be
installed". Does this mean that they will be included in the source
distribution and what about top level directories?

5) Put the in <pkg>/src/*.Rex.  Can src/ be used this way too?

6) Ask R-core to revert back to pre-R v2.3.0 and allow other files in
the R/ directory too.  Are more people than I interested in this?

I realize I can test the above by trial and error, but I will still
not be sure what is the right approach here.  Comments/feedback is
appreciated.

Thanks

Henrik


From aronovitch at gmail.com  Fri Feb 10 11:29:39 2006
From: aronovitch at gmail.com (Amit Aronovitch)
Date: Fri, 10 Feb 2006 12:29:39 +0200
Subject: [Rd]  ATLAS threaded 64 bit Opteron build for R: need -fPIC
References: <x2u11dew8v.fsf@biostat.ku.dk>
Message-ID: <43EC6B13.1040203@gmail.com>

Hi,

 Sorry for sending such a late reply, and for being abit OT.

  I've been trying to compile 64 bit ATLAS for numpy
(http://numeric.scipy.org/ ),
and so far this thread is the most useful one I could google up - thanks!.
  I encountered similiar problems, and so far could not get a .a
linkable to numpy
(comparing to your post - it seems I might have forgotten to add the
-fPIC for the
F77FLAGS or MMFLAGS).

 Also, I'm having trouble with the ATLAS lapack. To get a usable lib,
one has to
merge it with a full lapack implementation (as described in the ATLAS
errata).
 However, I'm using RHEL4, and their installed liblapack.a seems to have
been compiled
without -fPIC, so the merged library is unlinkable to numpy's .so. Is
there a way to use Redhat's
installed liblapack.so?

 Few questions about your compiler flags:

1) Is there a reason to compile with -O rather than -O3?
 (did you try and encounter some problem, or found no major performance
difference)
2) I see you use -mfpmath=387 - does this work better than sse2 (which
seems to be
 the default)? How about the "sse,387" option - should I try that?
 
Martin Maechler wrote:

>>>>>/ "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk <https://www.stat.math.ethz.ch/mailman/listinfo/r-devel>>
/>>>>>/  >>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>>     on 26 Feb 2004 15:44:16 +0100 writes:
>
>    PD> Douglas Bates <bates at stat.wisc.edu> writes:
>    >> Have you tried configuring R with Goto's BLAS
>    >> http://www.cs.utexas.edu/users/kgoto/
>    >> 
>    >> I haven't worked with Opteron or Athlon64 computers but I understand
>    >> that Goto's BLAS are very effective on those machines.  Furthermore
>    >> Goto's BLAS are (only) available as .so libraries so you don't need to
>    >> mess with creating the .so version.
>
>    PD> I tried it, yes. Somewhat to my surprise, it seemed to be not quite as
>    PD> fast as the threaded ATLAS, but I wasn't very systematic about the
>    PD> benchmarking.
>
>    PD> (and the Goto items have license issues, which get in the way for
>    PD> binary distributions.)
>
>Thanks a lot, Peter, Brian, Doug, for your feedbacks!
>In the mean time, I have three running versions of R(-devel) on
>the 64-Opteron
>- "plain"
>- linked against threaded GOTO
>- linked against threaded (static) ATLAS  (using -fPIC for compilation;
>					   "large" Rlapack)
>and I find that GOTO is faster than ATLAS
>consistently (between ~ 5-20%) for several tests
>(square matrices; %*% and solve).
>ATLAS is still an order of magnitude faster than "plain" for
>3000x3000 matrices.
>
>Here are somewhat repeatable "ATLAS for R" build instructions:
>
> 1. get ATLAS source; unpack
> 2. make : use defaults and "express" installation
> 3. Before "make install ...", edit the  Make.<ARCHITECTURE> file:
>    add "-fPIC" to three places, namely  F77FLAGS, CCFLAG0, and MMFLAGS:
>    which in case of the "threaded Opteron" architecture, leads to
>    the three new lines
>       F77FLAGS = -fPIC -fomit-frame-pointer -O -m64
>
>	CCFLAG0 = -fPIC -fomit-frame-pointer -O -mfpmath=387 -m64
>
>	MMFLAGS = -fPIC -fomit-frame-pointer -O -mfpmath=387 -m64
>    in the file   Make.Linux_HAMMER64SSE2_2
>
> 4. make install arch=Linux_HAMMER64SSE2_2
>
> 5. Sym.link the ATLAS libraries into /usr/local/lib:
>
>    cd /usr/local/lib
>    ln -s <ATLAS_build_dir>/lib/Linux_HAMMER64SSE2_2/lib* .
>
> 6. (needed for runtime!):
>    Use environment variable LD_LIBRARY_PATH=/usr/local/lib
>
>
>Note that I haven't built *.so (shared) libraries yet.
 /


From Kurt.Hornik at wu-wien.ac.at  Fri Feb 10 11:46:53 2006
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 10 Feb 2006 11:46:53 +0100
Subject: [Rd] R CMD build: "Subdirectory 'R' contains invalid file names"
In-Reply-To: <59d7961d0602100227s5e1d3dbahbfcca5dd386b02d3@mail.gmail.com>
References: <59d7961d0602100227s5e1d3dbahbfcca5dd386b02d3@mail.gmail.com>
Message-ID: <17388.28445.832529.327685@mithrandir.hornik.net>

>>>>> Henrik Bengtsson writes:

> Hi, I get
> * excluding invalid files from 'R.oo'
> Subdirectory 'R' contains invalid file names:
>   attachLocally.Object.Rex Exception.Rex extend.default.Rex
>   InternalErrorException.reportBug.Rex Package.Rex Person.Rex Rdoc.Rex
>   setMethodS3.Rex StaticFields.Rex

> when running R CMD build in R v2.3.0 devel.  I do understand what is
> going on.  In my *.R files I keep so called Rdoc comments which in
> their simplest form are Rd code wrapped up in plain comments.  These
> are compiled into Rd files written to ../man/ (I do this prior to
> building packages).  Rdoc also supports inclusion of other files, e.g.
> @include "Person.Rex" to include example code.

> With this structure I can, when I develop/maintain a package, have
> <pkg>/R/ as the working directory, modify my *.R files and re-source
> them from within R.  Since I keep all my Rd example code in separate
> *.Rex files, I can easily rerun/test these by sourcing them too.  I
> find this very convenient.

> In previous versions, the *.Rex files was included when building a
> source distribution of a package.  In R v2.3.0 they are excluded. 
> However, I would like to distribute the *.Rex files with my
> source-code package too (so I do not have to keep another type of
> source distribution).  Note that these files are only needed for
> further development of the package, but *not* to install the package
> from source (since their contents is already incorporated in the Rd
> files).  They are also not of interest to the end-user.

Henrik,

I am not sure I fully understand the issue.

The 

   Note that these files are only needed for further development of the
   package

suggests that these files are only needed for your local master sources,
but not in the source package created by R CMD build.  If this is the
case, then you really don't have to do anything, because R CMD build
will happily exclude these files, and R CMD check on the .tar.gz will no
longer find them.

Best
-k

> My question is how to incorporate the *.Rex files?  Here are some
> ideas, that I would like to have some feedback on:

> 1) Put them in <pkg>/R/Rex/*.Rex.  However, Section 1.1.4 in Writing R
> Extensions suggest that subdirectories of R/ may only(?) be named
> 'windows' or 'unix'.

> 2) Rename them to <pkg>/R/*.in, cf. Section 1.1.4.  Is this the
> purpose of *.in files?  Will it have side effects?

> 3) Put the in <pkg>/inst/<dir>/*.Rex.  This will work, but then they
> will also be install and available in system.file("<dir>",
> package="<pkg>").  Not a big problem, but not what I want.

> 4) To avoid (3), put the in <pkg>/<dir>/*.Rex, i.e. at the top level
> directory.  Is this allowed?  Section 1.1.4 says "Note that [...]
> information files at the top level of the package will not be
> installed". Does this mean that they will be included in the source
> distribution and what about top level directories?

> 5) Put the in <pkg>/src/*.Rex.  Can src/ be used this way too?

> 6) Ask R-core to revert back to pre-R v2.3.0 and allow other files in
> the R/ directory too.  Are more people than I interested in this?

> I realize I can test the above by trial and error, but I will still
> not be sure what is the right approach here.  Comments/feedback is
> appreciated.

> Thanks

> Henrik

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at maths.lth.se  Fri Feb 10 12:08:04 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 10 Feb 2006 12:08:04 +0100
Subject: [Rd] R CMD build: "Subdirectory 'R' contains invalid file names"
In-Reply-To: <17388.28445.832529.327685@mithrandir.hornik.net>
References: <59d7961d0602100227s5e1d3dbahbfcca5dd386b02d3@mail.gmail.com>
	<17388.28445.832529.327685@mithrandir.hornik.net>
Message-ID: <59d7961d0602100308nafeec66n4ce873d1e44db565@mail.gmail.com>

Hi,

On 2/10/06, Kurt Hornik <Kurt.Hornik at wu-wien.ac.at> wrote:
> >>>>> Henrik Bengtsson writes:
>
> > Hi, I get
> > * excluding invalid files from 'R.oo'
> > Subdirectory 'R' contains invalid file names:
> >   attachLocally.Object.Rex Exception.Rex extend.default.Rex
> >   InternalErrorException.reportBug.Rex Package.Rex Person.Rex Rdoc.Rex
> >   setMethodS3.Rex StaticFields.Rex
>
> > when running R CMD build in R v2.3.0 devel.  I do understand what is
> > going on.  In my *.R files I keep so called Rdoc comments which in
> > their simplest form are Rd code wrapped up in plain comments.  These
> > are compiled into Rd files written to ../man/ (I do this prior to
> > building packages).  Rdoc also supports inclusion of other files, e.g.
> > @include "Person.Rex" to include example code.
>
> > With this structure I can, when I develop/maintain a package, have
> > <pkg>/R/ as the working directory, modify my *.R files and re-source
> > them from within R.  Since I keep all my Rd example code in separate
> > *.Rex files, I can easily rerun/test these by sourcing them too.  I
> > find this very convenient.
>
> > In previous versions, the *.Rex files was included when building a
> > source distribution of a package.  In R v2.3.0 they are excluded.
> > However, I would like to distribute the *.Rex files with my
> > source-code package too (so I do not have to keep another type of
> > source distribution).  Note that these files are only needed for
> > further development of the package, but *not* to install the package
> > from source (since their contents is already incorporated in the Rd
> > files).  They are also not of interest to the end-user.
>
> Henrik,
>
> I am not sure I fully understand the issue.
>
> The
>
>    Note that these files are only needed for further development of the
>    package
>
> suggests that these files are only needed for your local master sources,
> but not in the source package created by R CMD build.  If this is the
> case, then you really don't have to do anything, because R CMD build
> will happily exclude these files, and R CMD check on the .tar.gz will no
> longer find them.

Yes.  However, I would like to avoid to keep a version of "local
master sources".  Until now, all necessary code in my packages are
available in the *.tar.gz files build by R CMD build.  This is
convenient if someone else wants to contribute/add to my package, the
*.tar.gz is all that is needed and it is available on the web.  I can
also update my package on request, say, when I travel, without having
access to my "local master sources".  Kind of a poor man's
subversion/cvs.

Thanks

Henrik

> Best
> -k
>
> > My question is how to incorporate the *.Rex files?  Here are some
> > ideas, that I would like to have some feedback on:
>
> > 1) Put them in <pkg>/R/Rex/*.Rex.  However, Section 1.1.4 in Writing R
> > Extensions suggest that subdirectories of R/ may only(?) be named
> > 'windows' or 'unix'.
>
> > 2) Rename them to <pkg>/R/*.in, cf. Section 1.1.4.  Is this the
> > purpose of *.in files?  Will it have side effects?
>
> > 3) Put the in <pkg>/inst/<dir>/*.Rex.  This will work, but then they
> > will also be install and available in system.file("<dir>",
> > package="<pkg>").  Not a big problem, but not what I want.
>
> > 4) To avoid (3), put the in <pkg>/<dir>/*.Rex, i.e. at the top level
> > directory.  Is this allowed?  Section 1.1.4 says "Note that [...]
> > information files at the top level of the package will not be
> > installed". Does this mean that they will be included in the source
> > distribution and what about top level directories?
>
> > 5) Put the in <pkg>/src/*.Rex.  Can src/ be used this way too?
>
> > 6) Ask R-core to revert back to pre-R v2.3.0 and allow other files in
> > the R/ directory too.  Are more people than I interested in this?
>
> > I realize I can test the above by trial and error, but I will still
> > not be sure what is the right approach here.  Comments/feedback is
> > appreciated.
>
> > Thanks
>
> > Henrik
>
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


--
Henrik Bengtsson
Mobile: +46 708 909208 (+1h UTC)


From ripley at stats.ox.ac.uk  Fri Feb 10 12:14:17 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Feb 2006 11:14:17 +0000 (GMT)
Subject: [Rd] ATLAS threaded 64 bit Opteron build for R: need -fPIC
In-Reply-To: <43EC6B13.1040203@gmail.com>
References: <x2u11dew8v.fsf@biostat.ku.dk> <43EC6B13.1040203@gmail.com>
Message-ID: <Pine.LNX.4.64.0602101036590.7843@gannet.stats.ox.ac.uk>

On Fri, 10 Feb 2006, Amit Aronovitch wrote:

You set the reply address to Martin Maechler!  That's antisocial.

> Hi,
>
> Sorry for sending such a late reply, and for being abit OT.
>
>  I've been trying to compile 64 bit ATLAS for numpy 
> (http://numeric.scipy.org/ ), and so far this thread is the most useful 
> one I could google up - thanks!.
>  I encountered similiar problems, and so far could not get a .a linkable 
> to numpy (comparing to your post - it seems I might have forgotten to 
> add the -fPIC for the F77FLAGS or MMFLAGS).

Yes, that _is_ in the R-admin manual.  I guess you have not read that - it 
describes how to install R.  You can get it in the R tarball from

ftp://ftp.stat.math.ethz.ch/Software/R/R-devel.tar.bz2


> Also, I'm having trouble with the ATLAS lapack. To get a usable lib, one 
> has to merge it with a full lapack implementation (as described in the 
> ATLAS errata). However, I'm using RHEL4, and their installed liblapack.a 
> seems to have been compiled without -fPIC, so the merged library is 
> unlinkable to numpy's .so. Is there a way to use Redhat's installed 
> liblapack.so?

No, nor should you want to.  If RHEL4 is like FC3/4 watch out, as RH have 
managed to get BLAS routines in liblapack and not liblas, and use 
incorrect patches to LAPACK 3.0.  (Again, see the latest R-admin manual.)

> Few questions about your compiler flags:
>
> 1) Is there a reason to compile with -O rather than -O3?
> (did you try and encounter some problem, or found no major performance
> difference)

ATLAS chose that.  Since the real work is done by hand-tuned assembler 
code it should not matter.

> 2) I see you use -mfpmath=387 - does this work better than sse2 (which
> seems to be
> the default)? How about the "sse,387" option - should I try that?

Depends on your ATLAS version.  Again, ATLAS chose those.

As it happens, I have been trying to build ATLAS on my new dual Opteron 
box this morning.  The latest devel version (3.7.11) does not build, as at 
some point it says it expects the GNU x86-32 assembler.  If it did it 
would use SSE3 and so be faster.

Both 3.6.0 and 3.7.11 fail because my machine is too fast, and I had to 
increase the number of replications (1000) in make/Make.{mv,r1}tune and in 
tune/blas/level1/*.c.  Even then I do not entirely trust the results (and 
the two versions report different L1 caches sizes ...).

I got pretty exasperated with this (it needed about ten builds to get one 
that succeeded).  Both ACML and the Goto BLAS work well out of the box on 
Opterons, but do have licence issues. (Again, see the R-admin manual for 
details.)


> Martin Maechler wrote:
>
>>>>>> / "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk <https://www.stat.math.ethz.ch/mailman/listinfo/r-devel>>
> />>>>>/  >>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>>>     on 26 Feb 2004 15:44:16 +0100 writes:
>>
>>    PD> Douglas Bates <bates at stat.wisc.edu> writes:
>>   >> Have you tried configuring R with Goto's BLAS
>>   >> http://www.cs.utexas.edu/users/kgoto/
>>   >>
>>   >> I haven't worked with Opteron or Athlon64 computers but I understand
>>   >> that Goto's BLAS are very effective on those machines.  Furthermore
>>   >> Goto's BLAS are (only) available as .so libraries so you don't need to
>>   >> mess with creating the .so version.
>>
>>    PD> I tried it, yes. Somewhat to my surprise, it seemed to be not quite as
>>    PD> fast as the threaded ATLAS, but I wasn't very systematic about the
>>    PD> benchmarking.
>>
>>    PD> (and the Goto items have license issues, which get in the way for
>>    PD> binary distributions.)
>>
>> Thanks a lot, Peter, Brian, Doug, for your feedbacks!
>> In the mean time, I have three running versions of R(-devel) on
>> the 64-Opteron
>> - "plain"
>> - linked against threaded GOTO
>> - linked against threaded (static) ATLAS  (using -fPIC for compilation;
>> 					   "large" Rlapack)
>> and I find that GOTO is faster than ATLAS
>> consistently (between ~ 5-20%) for several tests
>> (square matrices; %*% and solve).
>> ATLAS is still an order of magnitude faster than "plain" for
>> 3000x3000 matrices.
>>
>> Here are somewhat repeatable "ATLAS for R" build instructions:
>>
>> 1. get ATLAS source; unpack
>> 2. make : use defaults and "express" installation
>> 3. Before "make install ...", edit the  Make.<ARCHITECTURE> file:
>>    add "-fPIC" to three places, namely  F77FLAGS, CCFLAG0, and MMFLAGS:
>>    which in case of the "threaded Opteron" architecture, leads to
>>    the three new lines
>>       F77FLAGS = -fPIC -fomit-frame-pointer -O -m64
>>
>> 	CCFLAG0 = -fPIC -fomit-frame-pointer -O -mfpmath=387 -m64
>>
>> 	MMFLAGS = -fPIC -fomit-frame-pointer -O -mfpmath=387 -m64
>>    in the file   Make.Linux_HAMMER64SSE2_2
>>
>> 4. make install arch=Linux_HAMMER64SSE2_2
>>
>> 5. Sym.link the ATLAS libraries into /usr/local/lib:
>>
>>    cd /usr/local/lib
>>    ln -s <ATLAS_build_dir>/lib/Linux_HAMMER64SSE2_2/lib* .
>>
>> 6. (needed for runtime!):
>>    Use environment variable LD_LIBRARY_PATH=/usr/local/lib
>>
>>
>> Note that I haven't built *.so (shared) libraries yet.
> /

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri Feb 10 12:15:10 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Feb 2006 12:15:10 +0100
Subject: [Rd] ?bquote
In-Reply-To: <971536df0602091757hd69d838l5c58166e714a790e@mail.gmail.com>
References: <971536df0602091757hd69d838l5c58166e714a790e@mail.gmail.com>
Message-ID: <x2lkwj31oh.fsf@viggo.kubism.ku.dk>

Gabor Grothendieck <ggrothendieck at gmail.com> writes:

> ?bquote says it returns an expression but, in fact, it typically
> (though not always) returns a call object:
> 
> > class(bquote(a+b))
> [1] "call"
> 
> > class(bquote(1))
> [1] "numeric"

Unevaluated expressions and objects of mode "expression" are not the
same thing. The latter is effectively a list wrapping one or more of
the former.

Unevaluated expressions are generally mode "call", except when they
are constants. They do, however, correspond to expressions as
syntactic element (look for "expr" inside gram.y in the sources). 

The terminology does not seem completely rationalised, see also the
help pages for expression() and substitute()/quote(), and it might be
worth cleaning it up at some point. Just requires someone with a
sufficiently clear mind to decide on issues like whether constants
qualify as "unevaluated calls"... (my hunch is that they don't, and
that "unevaluated expressions" should be used throughout, but my mind
is definitely not clear these days.)

Another question is whether it would be desirable for bquote to return
an "expression" object. I realized recently that 

> boxplot(rnorm(99),ylab=quote(a[1]))
Error in title(ylab = a[1]) : object "a" not found

and that you need expression(a[1]) instead. I think this implies that
you'd have to use as.expression(bquote(....)) which is a bit nasty.
I'm not sure this isn't a bug in boxplot, though.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Fri Feb 10 12:42:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Feb 2006 11:42:46 +0000 (GMT)
Subject: [Rd] R CMD build: "Subdirectory 'R' contains invalid file names"
In-Reply-To: <59d7961d0602100308nafeec66n4ce873d1e44db565@mail.gmail.com>
References: <59d7961d0602100227s5e1d3dbahbfcca5dd386b02d3@mail.gmail.com>
	<17388.28445.832529.327685@mithrandir.hornik.net>
	<59d7961d0602100308nafeec66n4ce873d1e44db565@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602101141150.4273@gannet.stats.ox.ac.uk>

On Fri, 10 Feb 2006, Henrik Bengtsson wrote:

> Hi,
>
> On 2/10/06, Kurt Hornik <Kurt.Hornik at wu-wien.ac.at> wrote:
>>>>>>> Henrik Bengtsson writes:
>>
>>> Hi, I get
>>> * excluding invalid files from 'R.oo'
>>> Subdirectory 'R' contains invalid file names:
>>>   attachLocally.Object.Rex Exception.Rex extend.default.Rex
>>>   InternalErrorException.reportBug.Rex Package.Rex Person.Rex Rdoc.Rex
>>>   setMethodS3.Rex StaticFields.Rex
>>
>>> when running R CMD build in R v2.3.0 devel.  I do understand what is
>>> going on.  In my *.R files I keep so called Rdoc comments which in
>>> their simplest form are Rd code wrapped up in plain comments.  These
>>> are compiled into Rd files written to ../man/ (I do this prior to
>>> building packages).  Rdoc also supports inclusion of other files, e.g.
>>> @include "Person.Rex" to include example code.
>>
>>> With this structure I can, when I develop/maintain a package, have
>>> <pkg>/R/ as the working directory, modify my *.R files and re-source
>>> them from within R.  Since I keep all my Rd example code in separate
>>> *.Rex files, I can easily rerun/test these by sourcing them too.  I
>>> find this very convenient.
>>
>>> In previous versions, the *.Rex files was included when building a
>>> source distribution of a package.  In R v2.3.0 they are excluded.
>>> However, I would like to distribute the *.Rex files with my
>>> source-code package too (so I do not have to keep another type of
>>> source distribution).  Note that these files are only needed for
>>> further development of the package, but *not* to install the package
>>> from source (since their contents is already incorporated in the Rd
>>> files).  They are also not of interest to the end-user.
>>
>> Henrik,
>>
>> I am not sure I fully understand the issue.
>>
>> The
>>
>>    Note that these files are only needed for further development of the
>>    package
>>
>> suggests that these files are only needed for your local master sources,
>> but not in the source package created by R CMD build.  If this is the
>> case, then you really don't have to do anything, because R CMD build
>> will happily exclude these files, and R CMD check on the .tar.gz will no
>> longer find them.
>
> Yes.  However, I would like to avoid to keep a version of "local
> master sources".  Until now, all necessary code in my packages are
> available in the *.tar.gz files build by R CMD build.  This is
> convenient if someone else wants to contribute/add to my package, the
> *.tar.gz is all that is needed and it is available on the web.  I can
> also update my package on request, say, when I travel, without having
> access to my "local master sources".  Kind of a poor man's
> subversion/cvs.

And inconvenient to everyone who has to pay to download your development 
files that they do not need.

Can you not put your master sources on your own web site.

>
> Thanks
>
> Henrik
>
>> Best
>> -k
>>
>>> My question is how to incorporate the *.Rex files?  Here are some
>>> ideas, that I would like to have some feedback on:
>>
>>> 1) Put them in <pkg>/R/Rex/*.Rex.  However, Section 1.1.4 in Writing R
>>> Extensions suggest that subdirectories of R/ may only(?) be named
>>> 'windows' or 'unix'.
>>
>>> 2) Rename them to <pkg>/R/*.in, cf. Section 1.1.4.  Is this the
>>> purpose of *.in files?  Will it have side effects?
>>
>>> 3) Put the in <pkg>/inst/<dir>/*.Rex.  This will work, but then they
>>> will also be install and available in system.file("<dir>",
>>> package="<pkg>").  Not a big problem, but not what I want.
>>
>>> 4) To avoid (3), put the in <pkg>/<dir>/*.Rex, i.e. at the top level
>>> directory.  Is this allowed?  Section 1.1.4 says "Note that [...]
>>> information files at the top level of the package will not be
>>> installed". Does this mean that they will be included in the source
>>> distribution and what about top level directories?
>>
>>> 5) Put the in <pkg>/src/*.Rex.  Can src/ be used this way too?
>>
>>> 6) Ask R-core to revert back to pre-R v2.3.0 and allow other files in
>>> the R/ directory too.  Are more people than I interested in this?
>>
>>> I realize I can test the above by trial and error, but I will still
>>> not be sure what is the right approach here.  Comments/feedback is
>>> appreciated.
>>
>>> Thanks
>>
>>> Henrik
>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>
> --
> Henrik Bengtsson
> Mobile: +46 708 909208 (+1h UTC)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marco.vezzoli at st.com  Fri Feb 10 14:01:47 2006
From: marco.vezzoli at st.com (marco.vezzoli@st.com)
Date: Fri, 10 Feb 2006 14:01:47 +0100 (CET)
Subject: [Rd] Accuracy of dnorm (PR#8586)
Message-ID: <20060210130147.808AE121AE@slim.kubism.ku.dk>

Full_Name: Marco Vezzoli
Version: 2.2.0 2.1.0 2.0.0
OS: Solaris, Windows, Linux
Submission from: (NULL) (57.78.11.38)


The dnorm functions yield a wrong value when the standard deviation is near to
1e-1
e.g.
> dnorm(0,mean=0.04,sd=0.3)
[1] 1.318039

this error is consistent in various version and os.


From ripley at stats.ox.ac.uk  Fri Feb 10 14:20:29 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Feb 2006 13:20:29 +0000 (GMT)
Subject: [Rd] Accuracy of dnorm (PR#8586)
In-Reply-To: <20060210130147.808AE121AE@slim.kubism.ku.dk>
References: <20060210130147.808AE121AE@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0602101313560.5396@gannet.stats.ox.ac.uk>

On Fri, 10 Feb 2006, marco.vezzoli at st.com wrote:

> Full_Name: Marco Vezzoli
> Version: 2.2.0 2.1.0 2.0.0
> OS: Solaris, Windows, Linux
> Submission from: (NULL) (57.78.11.38)
>
>
> The dnorm functions yield a wrong value when the standard deviation is near to
> 1e-1
> e.g.
>> dnorm(0,mean=0.04,sd=0.3)
> [1] 1.318039

What is wrong here?  Try the textbook formula

> x <- 0
> m <- 0.04
> sd <- 0.3
> 1/(sqrt(2*pi)*sd) * exp(-0.5*(x-m)^2/sd^2)
[1] 1.318039

> this error is consistent in various version and os.

It _is_ good that R is consistent.

I don't think we are going to believe you unless you give your credentials 
and state your `correct value' and your reasoning.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From B.Rowlingson at lancaster.ac.uk  Fri Feb 10 14:33:09 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 10 Feb 2006 13:33:09 +0000
Subject: [Rd] Accuracy of dnorm (PR#8586)
In-Reply-To: <Pine.LNX.4.64.0602101313560.5396@gannet.stats.ox.ac.uk>
References: <20060210130147.808AE121AE@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0602101313560.5396@gannet.stats.ox.ac.uk>
Message-ID: <43EC9615.8090905@lancaster.ac.uk>

Prof Brian Ripley wrote:

>>The dnorm functions yield a wrong value when the standard deviation is near to
>>1e-1

> What is wrong here?  Try the textbook formula
> 
> 
>>x <- 0
>>m <- 0.04
>>sd <- 0.3
>>1/(sqrt(2*pi)*sd) * exp(-0.5*(x-m)^2/sd^2)
> 
> [1] 1.318039
> 

Even MS Excel gets this one right:

=NORMDIST(0,0.04,0.3,FALSE)

1.31803947

Barry


From p.dalgaard at biostat.ku.dk  Fri Feb 10 14:44:03 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Feb 2006 14:44:03 +0100
Subject: [Rd] Accuracy of dnorm (PR#8586)
In-Reply-To: <20060210130147.808AE121AE@slim.kubism.ku.dk>
References: <20060210130147.808AE121AE@slim.kubism.ku.dk>
Message-ID: <x21wyb2usc.fsf@viggo.kubism.ku.dk>

marco.vezzoli at st.com writes:

> Full_Name: Marco Vezzoli
> Version: 2.2.0 2.1.0 2.0.0
> OS: Solaris, Windows, Linux
> Submission from: (NULL) (57.78.11.38)
> 
> 
> The dnorm functions yield a wrong value when the standard deviation is near to
> 1e-1
> e.g.
> > dnorm(0,mean=0.04,sd=0.3)
> [1] 1.318039
> 
> this error is consistent in various version and os.

What's wrong with it???

> (pnorm(0.000001,mean=0.04,sd=0.3) - pnorm(0,mean=0.04,sd=0.3))/.000001
[1] 1.318040


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From marco.vezzoli at st.com  Fri Feb 10 14:55:19 2006
From: marco.vezzoli at st.com (Marco VEZZOLI)
Date: Fri, 10 Feb 2006 14:55:19 +0100
Subject: [Rd] Accuracy of dnorm (PR#8586)
References: <20060210130147.808AE121AE@slim.kubism.ku.dk>
	<x21wyb2usc.fsf@viggo.kubism.ku.dk>
Message-ID: <43EC9B47.F17000C2@st.com>

I'm very sorry for the error.
I confused probability density with the distribution.
Thank you for your answer.
	Marco


From aronovitch at gmail.com  Fri Feb 10 16:53:47 2006
From: aronovitch at gmail.com (Amit Aronovitch)
Date: Fri, 10 Feb 2006 17:53:47 +0200
Subject: [Rd] ATLAS threaded 64 bit Opteron build for R: need -fPIC
In-Reply-To: <Pine.LNX.4.64.0602101036590.7843@gannet.stats.ox.ac.uk>
References: <x2u11dew8v.fsf@biostat.ku.dk> <43EC6B13.1040203@gmail.com>
	<Pine.LNX.4.64.0602101036590.7843@gannet.stats.ox.ac.uk>
Message-ID: <43ECB70B.8000302@gmail.com>

Prof Brian Ripley wrote:

> On Fri, 10 Feb 2006, Amit Aronovitch wrote:
>
> You set the reply address to Martin Maechler!  That's antisocial.
>
Sincere apologies. I certainly didn't intend to!
(I probably misclicked while trying to put him on Cc: )

   Please ignore that header.

>> Hi,
>>
>> Sorry for sending such a late reply, and for being abit OT.
>>
>>  I've been trying to compile 64 bit ATLAS for numpy
>> (http://numeric.scipy.org/ ), and so far this thread is the most
>> useful one I could google up - thanks!.
>>  I encountered similiar problems, and so far could not get a .a
>> linkable to numpy (comparing to your post - it seems I might have
>> forgotten to add the -fPIC for the F77FLAGS or MMFLAGS).
>
>
> Yes, that _is_ in the R-admin manual.  I guess you have not read that
> - it describes how to install R.  You can get it in the R tarball from
>
> ftp://ftp.stat.math.ethz.ch/Software/R/R-devel.tar.bz2
>
>
>> Also, I'm having trouble with the ATLAS lapack. To get a usable lib,
>> one has to merge it with a full lapack implementation (as described
>> in the ATLAS errata). However, I'm using RHEL4, and their installed
>> liblapack.a seems to have been compiled without -fPIC, so the merged
>> library is unlinkable to numpy's .so. Is there a way to use Redhat's
>> installed liblapack.so?
>
>
> No, nor should you want to.  If RHEL4 is like FC3/4 watch out, as RH
> have managed to get BLAS routines in liblapack and not liblas, and use
> incorrect patches to LAPACK 3.0.  (Again, see the latest R-admin manual.)

Thanks for the tip - guess that means I'll have to compile my own lapack...

>
>> Few questions about your compiler flags:
>>
>> 1) Is there a reason to compile with -O rather than -O3?
>> (did you try and encounter some problem, or found no major performance
>> difference)
>
>
> ATLAS chose that.  Since the real work is done by hand-tuned assembler
> code it should not matter.
>
>> 2) I see you use -mfpmath=387 - does this work better than sse2 (which
>> seems to be
>> the default)? How about the "sse,387" option - should I try that?
>
>
> Depends on your ATLAS version.  Again, ATLAS chose those.
>
> As it happens, I have been trying to build ATLAS on my new dual
> Opteron box this morning.  The latest devel version (3.7.11) does not
> build, as at some point it says it expects the GNU x86-32 assembler. 
> If it did it would use SSE3 and so be faster.
>
> Both 3.6.0 and 3.7.11 fail because my machine is too fast, and I had
> to increase the number of replications (1000) in make/Make.{mv,r1}tune
> and in tune/blas/level1/*.c.  Even then I do not entirely trust the
> results (and the two versions report different L1 caches sizes ...).
>
> I got pretty exasperated with this (it needed about ten builds to get
> one that succeeded).  Both ACML and the Goto BLAS work well out of the
> box on Opterons, but do have licence issues. (Again, see the R-admin
> manual for details.)
>
I'll certainly have to read the R-admin manual.
Once I manage to get a working lib I'll try posting some of that info to
ATLAS lists (should prbly be included in atlas errata or something).

  thanks alot,
      Amit A.


From maechler at stat.math.ethz.ch  Fri Feb 10 18:18:18 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 10 Feb 2006 18:18:18 +0100
Subject: [Rd] invalid graphics state using dev.print (fwd)
In-Reply-To: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>
Message-ID: <17388.51930.273876.336070@stat.math.ethz.ch>

>>>>> "Paul" == Paul Roebuck <roebuck at mdanderson.org>
>>>>>     on Wed, 8 Feb 2006 15:33:11 -0600 (CST) writes:

    Paul> On Mon, 6 Feb 2006 18:12, Simon Urbanek wrote:
    >> On Feb 6, 2006, at 5:24 PM, Paul Roebuck wrote:
    >> 
    >>> Tried on R-Sig-Mac with no responses, but I need some kind
    >>> of answer.
    >>> [...]
    >>> Does the following work on your system?
    >> 
    >> Interesting, no, it doesn't either. For png and pdf I use
    >> Quartz + quartz.save (it produces much nicer results) so
    >> I didn't really notice, but you're right. First I thought
    >> those graphics state issues are specific to the Quartz
    >> device, but you have proven that it's not. It's in fact
    >> not even Mac-specific - I have just reproduced it on a
    >> Linux box - that's why I'm moving this to R-devel.

    Paul> It's been several workdays now with no responses. Could
    Paul> someone try the last three lines of code and see if they
    Paul> get the following error message?

    >> x11()
    >> plot(rnorm(10))
    >> dev.print(png)

    Paul> Error in dev.copy(device = function (filename = "Rplot%03d.png", width =
    Paul> 480,  :
    Paul> invalid graphics state

    >> traceback()
    Paul> 6: dev.copy(device = function (filename = "Rplot%03d.png", width = 480,
    Paul> height = 480, pointsize = 12, gamma = 1, colortype =
    Paul> getOption("X11colortype"),
    Paul> maxcubesize = 256, bg = "white", fonts = getOption("X11fonts"),
    Paul> res = NA)
    Paul> .Internal(X11(paste("png::", filename, sep = ""), width, height,
    Paul> pointsize, gamma, colortype, maxcubesize, bg, bg, fonts,
    Paul> res)), width = 6.98715785526809, height = 6.99452568428947)
    Paul> 5: eval(expr, envir, enclos)
    Paul> 4: eval(expr, p)
    Paul> 3: eval.parent(oc)
    Paul> 2: dev.off(eval.parent(oc))
    Paul> 1: dev.print(png)

    Paul> I noticed it on OS X, and Simon on Linux. 

Yes, I can confim getting the same.
Just on Linux though (as Simon)

I'd say this should make a ``nice little''  bug.report() 

Interestingly, replacing

    dev.print(png)

by  dev.copy(png) ; dev.off()  

which is about equivalent,  *does* work and so is a workaround
to your problem.

Regards,
Martin

    Paul> Other platforms?  WFM?

    Paul> TIA

    >> version
    Paul> _
    Paul> platform powerpc-apple-darwin7.9.0
    Paul> arch     powerpc
    Paul> os       darwin7.9.0
    Paul> system   powerpc, darwin7.9.0
    Paul> status   Patched
    Paul> major    2
    Paul> minor    2.1
    Paul> year     2006
    Paul> month    02
    Paul> day      01
    Paul> svn rev  37245
    Paul> language R

    Paul> ----------------------------------------------------------
    Paul> SIGSIG -- signature too long (core dumped)


From Friedrich.Leisch at tuwien.ac.at  Fri Feb 10 19:36:28 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Fri, 10 Feb 2006 19:36:28 +0100
Subject: [Rd] Citation of R packages
In-Reply-To: <511271C5-05FF-4B0A-8776-51D13DE9F043@anu.edu.au>
References: <1578.202.89.153.187.1138576012.squirrel@sqmail.anu.edu.au>
	<17380.51173.64968.956060@celebrian.ci.tuwien.ac.at>
	<511271C5-05FF-4B0A-8776-51D13DE9F043@anu.edu.au>
Message-ID: <17388.56620.256649.781994@celebrian.ci.tuwien.ac.at>

>>>>> On Fri, 10 Feb 2006 21:01:44 +1100,
>>>>> John Maindonald (JM) wrote:

[...]

  > Where there is a published paper or a book (such as MASS), or a
  > manual for which a url can be given, my decision was to include
  > that in the main list of references, but not to include references
  > there that were references to the package itself, which as you
  > suggest below can be a reference to the concatenated help pages.

The CITATION file of a package may contain as many entries as the
author wants, including both a reference to the help pages and to the
book (or whatever).


  > It seemed anyway useful to have a separate list of packages.  For
  > consistency, these were always references to the package, with a
  > cross-reference to any relevant document in the references to papers.

  >>> (2) Maybe the author field should be more nuanced, or
  >>> maybe ...
  >> 
  >> author fields of bibtex entries have a strict format (names separated
  >> by "and"), what do you mean by "more nuanced"?

  > Those named in the list of authors may be any combination of: the  
  > authors
  > of an R package, the authors of an original S version, the person or  
  > persons
  > responsible for an R port, the authors of the Fortran code, compiler 
  > (s), and
  > contributors of ideas.

  > For John Fox's car, citation() gives the following:
  >      author = {John Fox. I am grateful to Douglas Bates and David  
  > Firth and Michael Friendly and Gregor Gorjanc and Georges Monette and  
  > Henric Nilsson and Brian Ripley and Sanford Weisberg and and Achim  
  > Zeleis for various suggestions and contributions.},

  > For Rcmdr:
  >      author = {John Fox and with contributions from Michael Ash and  
  > Philippe Grosjean and Martin Maechler and Dan Putler and and Peter  
  > Wolf.},

  > For car, maybe John Fox should be identified as author.  For Rcmdr,  
  > maybe the other persons that are named should be added?

  > For leaps:
  >      author = {Thomas Lumley using Fortran code by Alan Miller},

  > It seems reasonable to cite Lumley and Miller as authors.  Should  
  > there be a note that identifies Miller as the contributor of the  
  > Fortran code?

  > Should the name(s) of porters (usually from S) be included as author 
  > (s)?  Or should their contribution be acknowledged in the note field?  
  > Or ...

  > Possibilities are to cite all those individuals as author, or to cite  
  > John Fox only,
  > with any combination of no additional information in the note field,  
  > or using the
  > note field to explain who did what.  The citation() function leaves  
  > it unclear who
  > are to be acknowledged as authors, and in fact


Umm, the problem there is not the citation() function, but that the
authors of all those packages obviously have not included a CITATION
file in their package which overrides the default (extracted from the
DESCRIPTION file).

E.g., package flexclust has DESCRIPTION

Package: flexclust
Version: 0.8-1
Date: 2006-01-11
Author: Friedrich Leisch, parts based on code by Evgenia Dimitriadou

but

****
R> citation("flexclust")

To cite package flexclust in publications use:

  Friedrich Leisch. A Toolbox for K-Centroids Cluster Analysis.
  Computational Statistics and Data Analysis, 2006. Accepted for
  publication.

A BibTeX entry for LaTeX users is

  @Article{,
    author = {Friedrich Leisch},
    title = {A Toolbox for K-Centroids Cluster Analysis},
    journal = {Computational Statistics and Data Analysis},
    year = {2006},
    note = {Accepted for publication},
  }
****

because the CITATION file overrides the DESCRIPTION file. Writing a
CITATION file is of course also intended for those cases where a
proper reference cannot be auto-generated from the DESCRIPTION file.


  >>> (3) In compiling a list of packages, name order seems
  >>> preferable, and one wants the title first (achieved by
  >>> relocating the format.title field in the manual FUNCTION
  >>> in the .bst file
  >>> (4) manual seems not an ideal name for the class, if
  >>> there is no manual.
  >> 
  >> A package always has a "reference manual", the concatenated help pages
  >> certainly qualify as such and can be downloaded in PDF format from
  >> CRAN. The ISBN rules even allow to assign an ISBN number to the online
  >> help of a software package which also can serve as the ISBN number of
  >> the *software itself* (which we did for base R).

  > I'd prefer some consistency in the way that R packages are referenced.
  > Thus, if reference for one package is to the concatenated help pages,
  > do it that way for all of them.

But we recommend that package authors should (try to) get their work
into reviewed journals like JSS, JCGS, or CSDA, and then package
authors usually prefer if the article gets cited. Unfortunately, many
academic institutions value paper publications higher than software.
Citing the help pages is mainly intended as a substitute if no journal
article is available.

Best,
Fritz


From john.maindonald at anu.edu.au  Sat Feb 11 00:32:17 2006
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 11 Feb 2006 10:32:17 +1100
Subject: [Rd] Citation of R packages
In-Reply-To: <17388.56620.256649.781994@celebrian.ci.tuwien.ac.at>
References: <1578.202.89.153.187.1138576012.squirrel@sqmail.anu.edu.au>
	<17380.51173.64968.956060@celebrian.ci.tuwien.ac.at>
	<511271C5-05FF-4B0A-8776-51D13DE9F043@anu.edu.au>
	<17388.56620.256649.781994@celebrian.ci.tuwien.ac.at>
Message-ID: <C832DAEC-22F7-4406-B124-6DBE7AB98293@anu.edu.au>

Even if a CITATION file is included, there is an issue of what to put  
in it.
Authorship of a book or paper is not always the simple matter that might
appear.  With an R package, it can be a far from simple matter.  We are
trying to adapt a tool, surely, that was designed for different  
purposes.

1. I'd like to see the definition of a new BibTeX entry type that has  
fields for
additional author details and version number. There is surely some
mechanism for getting agreement on a new entry type.

2. In any case, there's a message for maintainers of packages to include
CITATION files that reflect what they want to appear in any citation,  
with
citation("lattice") as maybe a suitable model?

John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Mathematical Sciences Institute, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 11 Feb 2006, at 5:36 AM, Friedrich.Leisch at tuwien.ac.at wrote:

>>>>>> On Fri, 10 Feb 2006 21:01:44 +1100,
>>>>>> John Maindonald (JM) wrote:
>
> [...]
>
>> Where there is a published paper or a book (such as MASS), or a
>> manual for which a url can be given, my decision was to include
>> that in the main list of references, but not to include references
>> there that were references to the package itself, which as you
>> suggest below can be a reference to the concatenated help pages.
>
> The CITATION file of a package may contain as many entries as the
> author wants, including both a reference to the help pages and to the
> book (or whatever).
>
>
>> It seemed anyway useful to have a separate list of packages.  For
>> consistency, these were always references to the package, with a
>> cross-reference to any relevant document in the references to papers.
>
>>>> (2) Maybe the author field should be more nuanced, or
>>>> maybe ...
>>>
>>> author fields of bibtex entries have a strict format (names  
>>> separated
>>> by "and"), what do you mean by "more nuanced"?
>
>> Those named in the list of authors may be any combination of: the
>> authors
>> of an R package, the authors of an original S version, the person or
>> persons
>> responsible for an R port, the authors of the Fortran code, compiler
>> (s), and
>> contributors of ideas.
>
>> For John Fox's car, citation() gives the following:
>>      author = {John Fox. I am grateful to Douglas Bates and David
>> Firth and Michael Friendly and Gregor Gorjanc and Georges Monette and
>> Henric Nilsson and Brian Ripley and Sanford Weisberg and and Achim
>> Zeleis for various suggestions and contributions.},
>
>> For Rcmdr:
>>      author = {John Fox and with contributions from Michael Ash and
>> Philippe Grosjean and Martin Maechler and Dan Putler and and Peter
>> Wolf.},
>
>> For car, maybe John Fox should be identified as author.  For Rcmdr,
>> maybe the other persons that are named should be added?
>
>> For leaps:
>>      author = {Thomas Lumley using Fortran code by Alan Miller},
>
>> It seems reasonable to cite Lumley and Miller as authors.  Should
>> there be a note that identifies Miller as the contributor of the
>> Fortran code?
>
>> Should the name(s) of porters (usually from S) be included as author
>> (s)?  Or should their contribution be acknowledged in the note field?
>> Or ...
>
>> Possibilities are to cite all those individuals as author, or to cite
>> John Fox only,
>> with any combination of no additional information in the note field,
>> or using the
>> note field to explain who did what.  The citation() function leaves
>> it unclear who
>> are to be acknowledged as authors, and in fact
>
>
> Umm, the problem there is not the citation() function, but that the
> authors of all those packages obviously have not included a CITATION
> file in their package which overrides the default (extracted from the
> DESCRIPTION file).
>
> E.g., package flexclust has DESCRIPTION
>
> Package: flexclust
> Version: 0.8-1
> Date: 2006-01-11
> Author: Friedrich Leisch, parts based on code by Evgenia Dimitriadou
>
> but
>
> ****
> R> citation("flexclust")
>
> To cite package flexclust in publications use:
>
>   Friedrich Leisch. A Toolbox for K-Centroids Cluster Analysis.
>   Computational Statistics and Data Analysis, 2006. Accepted for
>   publication.
>
> A BibTeX entry for LaTeX users is
>
>   @Article{,
>     author = {Friedrich Leisch},
>     title = {A Toolbox for K-Centroids Cluster Analysis},
>     journal = {Computational Statistics and Data Analysis},
>     year = {2006},
>     note = {Accepted for publication},
>   }
> ****
>
> because the CITATION file overrides the DESCRIPTION file. Writing a
> CITATION file is of course also intended for those cases where a
> proper reference cannot be auto-generated from the DESCRIPTION file.
>
>
>>>> (3) In compiling a list of packages, name order seems
>>>> preferable, and one wants the title first (achieved by
>>>> relocating the format.title field in the manual FUNCTION
>>>> in the .bst file
>>>> (4) manual seems not an ideal name for the class, if
>>>> there is no manual.
>>>
>>> A package always has a "reference manual", the concatenated help  
>>> pages
>>> certainly qualify as such and can be downloaded in PDF format from
>>> CRAN. The ISBN rules even allow to assign an ISBN number to the  
>>> online
>>> help of a software package which also can serve as the ISBN  
>>> number of
>>> the *software itself* (which we did for base R).
>
>> I'd prefer some consistency in the way that R packages are  
>> referenced.
>> Thus, if reference for one package is to the concatenated help pages,
>> do it that way for all of them.
>
> But we recommend that package authors should (try to) get their work
> into reviewed journals like JSS, JCGS, or CSDA, and then package
> authors usually prefer if the article gets cited. Unfortunately, many
> academic institutions value paper publications higher than software.
> Citing the help pages is mainly intended as a substitute if no journal
> article is available.
>
> Best,
> Fritz


From Bill.Venables at csiro.au  Sat Feb 11 02:46:33 2006
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sat, 11 Feb 2006 12:46:33 +1100
Subject: [Rd] Arguments of 'transform'
Message-ID: <B998A44C8986644EA8029CFE6396A924546AF5@exqld2-bne.qld.csiro.au>

If you would like a 10 second R puzzle, you might like to think about
this one:


> g <- expand.grid(long = 130:140, lat = -(10:25))
> gp <- transform(g, x = long, y = lat)
Error in transform(g, x = long, y = lat) : 
        object "long" not found


I don't expect this hasn't come up before, but I can't find mention of
it.  I suggest that to minimise this little stumbling block for
beginners (and others) we either

	change the name of the principal argument in transform from 'x'
to, say '.x' (or even 'data' as it is in 'with' for example)  OR

	at least put a note in the help file for 'transform' in the
'Detalis' section to say
     
	*** NOTE: The only tag name unavailable to be used is 'x'. ***

Just another little seed.

Bill.

Bill Venables, 
CMIS, CSIRO Laboratories, 
PO Box 120, Cleveland, Qld. 4163 
AUSTRALIA 
Office Phone (email preferred): +61 7 3826 7251 
Fax (if absolutely necessary):    +61 7 3826 7304 
Mobile (rarely used):                +61 4 1963 4642 
Home Phone:                          +61 7 3286 7700 
mailto:Bill.Venables at csiro.au 
http://www.cmis.csiro.au/bill.venables/


From ggrothendieck at gmail.com  Sat Feb 11 03:05:39 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 10 Feb 2006 21:05:39 -0500
Subject: [Rd] ?bquote
In-Reply-To: <x2lkwj31oh.fsf@viggo.kubism.ku.dk>
References: <971536df0602091757hd69d838l5c58166e714a790e@mail.gmail.com>
	<x2lkwj31oh.fsf@viggo.kubism.ku.dk>
Message-ID: <971536df0602101805x3a968d85k46363480265c6bd@mail.gmail.com>

On 10 Feb 2006 12:15:10 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>
> > ?bquote says it returns an expression but, in fact, it typically
> > (though not always) returns a call object:
> >
> > > class(bquote(a+b))
> > [1] "call"
> >
> > > class(bquote(1))
> > [1] "numeric"
>
> Unevaluated expressions and objects of mode "expression" are not the
> same thing. The latter is effectively a list wrapping one or more of
> the former.
>
> Unevaluated expressions are generally mode "call", except when they
> are constants. They do, however, correspond to expressions as
> syntactic element (look for "expr" inside gram.y in the sources).
>
> The terminology does not seem completely rationalised, see also the
> help pages for expression() and substitute()/quote(), and it might be
> worth cleaning it up at some point. Just requires someone with a
> sufficiently clear mind to decide on issues like whether constants
> qualify as "unevaluated calls"... (my hunch is that they don't, and
> that "unevaluated expressions" should be used throughout, but my mind
> is definitely not clear these days.)
>
> Another question is whether it would be desirable for bquote to return
> an "expression" object. I realized recently that
>
> > boxplot(rnorm(99),ylab=quote(a[1]))
> Error in title(ylab = a[1]) : object "a" not found
>
> and that you need expression(a[1]) instead. I think this implies that
> you'd have to use as.expression(bquote(....)) which is a bit nasty.
> I'm not sure this isn't a bug in boxplot, though.

I think this is the same issue that Berton Gunter brought up on r-help
recently with

   x <- y <- 1:10
   plot(y ~ x, main=quote(abc))

which gives an error message even though

   plot(x,y,main=quote(abc))

does not.

The first case seems to be stripping off one layer so that

   plot(y ~ x, quote(quote(abc)))

is ok but just one quote is not.


From p.dalgaard at biostat.ku.dk  Sat Feb 11 10:43:21 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Feb 2006 10:43:21 +0100
Subject: [Rd] Arguments of 'transform'
In-Reply-To: <B998A44C8986644EA8029CFE6396A924546AF5@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A924546AF5@exqld2-bne.qld.csiro.au>
Message-ID: <x2pslucjt2.fsf@turmalin.kubism.ku.dk>

<Bill.Venables at csiro.au> writes:

> If you would like a 10 second R puzzle, you might like to think about
> this one:
> 
> 
> > g <- expand.grid(long = 130:140, lat = -(10:25))
> > gp <- transform(g, x = long, y = lat)
> Error in transform(g, x = long, y = lat) : 
>         object "long" not found
> 
> 
> I don't expect this hasn't come up before, but I can't find mention of
> it.  I suggest that to minimise this little stumbling block for
> beginners (and others) we either
> 
> 	change the name of the principal argument in transform from 'x'
> to, say '.x' (or even 'data' as it is in 'with' for example)  OR
> 
> 	at least put a note in the help file for 'transform' in the
> 'Detalis' section to say
>      
> 	*** NOTE: The only tag name unavailable to be used is 'x'. ***

Yes it has come up before (surprisingly rarely though), and you're
probably right although changing argument names of functions should
never be taken lightly as there could be people using the current
ones. 

> 
> Just another little seed.

...which is connected to my grievances with attach() &c the other day.
Something about transform() just isn't The Right Way.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From dasnicht at mac.com  Sat Feb 11 15:51:37 2006
From: dasnicht at mac.com (dasnicht@mac.com)
Date: Sat, 11 Feb 2006 15:51:37 +0100 (CET)
Subject: [Rd] heatmap.2 in gplots (PR#8587)
Message-ID: <20060211145137.7F94221EED@slim.kubism.ku.dk>

Full_Name: Shane Neph
Version: 2.2.1
OS: mac os x
Submission from: (NULL) (71.113.43.247)


While I found the names of the package authors and maintainer, I was
unsuccessful in finding any contact information.

The preliminary documentation for heatmap.2 is inconsistent in at least a couple
of places when discussing the suppression of one or more dendrograms (and
column/row ordering in general).
In the Details section, in regards to the Rowv and Colv parameters, "If either
is NULL, no reordering will be done for the corresponding side."  The default
value for these parameters is NULL.  With NULL, the dendrograms are computed
(and hence reordering is done).
In the Arguments section, Rowv shows "determines if and how the row dendrogram
should be reordered.  Either a dendrogram or a vector of values to reorder the
row dendrogram of FALSE to suppres reordering or by default, NULL, ...".  In
particular, the portion about FALSE should be contrasted with the portion about
NULL in the Details section.

Finally, it is my belief that part of the intention or using FALSE (or whatever
is supposed to suppress the reordering) is to suppress the actual dendrogram
drawing as well.  This is similar to how NA works for the same argument names in
the heatmap function.  Achieving this behavior is straightforward.  Assuming
FALSE is the argument for suppression, the column dendrogram/reordering can be
achieved by modifying heatmap.2 near line 78-80:

FROM:
    else {
        colInd <- order(Colv)
    }

TO:
    else if ( isTRUE(Colv) ) {
        colInd <- order(Colv)
    } 
    else
        colInd <- 1:nc

This does suppress the automatic column ordering/dendrogram as desired.  Similar
fixes for the Rowv argument are needed.

R is great - keep up the work.
Shane


From jfox at mcmaster.ca  Sat Feb 11 16:38:39 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 11 Feb 2006 10:38:39 -0500
Subject: [Rd] Arguments of 'transform'
In-Reply-To: <x2pslucjt2.fsf@turmalin.kubism.ku.dk>
Message-ID: <20060211153839.NIYJ27612.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter and Bill,

How about changing the current "x argument to something like "x."? That
should make the problem that Bill points out less likely and still be
backwards compatible with using "x" in the call to transform().

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> Sent: Saturday, February 11, 2006 4:43 AM
> To: Bill.Venables at csiro.au
> Cc: r-devel at stat.math.ethz.ch; p.dalgaard at biostat.ku.dk
> Subject: Re: [Rd] Arguments of 'transform'
> 
> <Bill.Venables at csiro.au> writes:
> 
> > If you would like a 10 second R puzzle, you might like to 
> think about 
> > this one:
> > 
> > 
> > > g <- expand.grid(long = 130:140, lat = -(10:25)) gp <- 
> transform(g, 
> > > x = long, y = lat)
> > Error in transform(g, x = long, y = lat) : 
> >         object "long" not found
> > 
> > 
> > I don't expect this hasn't come up before, but I can't find 
> mention of 
> > it.  I suggest that to minimise this little stumbling block for 
> > beginners (and others) we either
> > 
> > 	change the name of the principal argument in transform from 'x'
> > to, say '.x' (or even 'data' as it is in 'with' for example)  OR
> > 
> > 	at least put a note in the help file for 'transform' in 
> the 'Detalis' 
> > section to say
> >      
> > 	*** NOTE: The only tag name unavailable to be used is 'x'. ***
> 
> Yes it has come up before (surprisingly rarely though), and 
> you're probably right although changing argument names of 
> functions should never be taken lightly as there could be 
> people using the current ones. 
> 
> > 
> > Just another little seed.
> 
> ...which is connected to my grievances with attach() &c the other day.
> Something about transform() just isn't The Right Way.
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Bill.Venables at csiro.au  Sat Feb 11 17:06:38 2006
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sun, 12 Feb 2006 03:06:38 +1100
Subject: [Rd] Arguments of 'transform'
Message-ID: <B998A44C8986644EA8029CFE6396A924546AF7@exqld2-bne.qld.csiro.au>

Hi John,

Unfortunately I don't think that will fix it because of partial matching.

(That would be OK if the argument sequence were reversed to:

	function(..., x.)

since partial matching does not occur with arguments coming after ..., but it would break ALL existing code.)

Bill.

-----Original Message-----
From: John Fox [mailto:jfox at mcmaster.ca] 
Sent: Sunday, 12 February 2006 1:39 AM
To: 'Peter Dalgaard'; Venables, Bill (CMIS, Cleveland)
Cc: r-devel at stat.math.ethz.ch
Subject: RE: [Rd] Arguments of 'transform'


Dear Peter and Bill,

How about changing the current "x argument to something like "x."? That
should make the problem that Bill points out less likely and still be
backwards compatible with using "x" in the call to transform().

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> Sent: Saturday, February 11, 2006 4:43 AM
> To: Bill.Venables at csiro.au
> Cc: r-devel at stat.math.ethz.ch; p.dalgaard at biostat.ku.dk
> Subject: Re: [Rd] Arguments of 'transform'
> 
> <Bill.Venables at csiro.au> writes:
> 
> > If you would like a 10 second R puzzle, you might like to 
> think about 
> > this one:
> > 
> > 
> > > g <- expand.grid(long = 130:140, lat = -(10:25)) gp <- 
> transform(g, 
> > > x = long, y = lat)
> > Error in transform(g, x = long, y = lat) : 
> >         object "long" not found
> > 
> > 
> > I don't expect this hasn't come up before, but I can't find 
> mention of 
> > it.  I suggest that to minimise this little stumbling block for 
> > beginners (and others) we either
> > 
> > 	change the name of the principal argument in transform from 'x'
> > to, say '.x' (or even 'data' as it is in 'with' for example)  OR
> > 
> > 	at least put a note in the help file for 'transform' in 
> the 'Detalis' 
> > section to say
> >      
> > 	*** NOTE: The only tag name unavailable to be used is 'x'. ***
> 
> Yes it has come up before (surprisingly rarely though), and 
> you're probably right although changing argument names of 
> functions should never be taken lightly as there could be 
> people using the current ones. 
> 
> > 
> > Just another little seed.
> 
> ...which is connected to my grievances with attach() &c the other day.
> Something about transform() just isn't The Right Way.
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jfox at mcmaster.ca  Sat Feb 11 17:39:41 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 11 Feb 2006 11:39:41 -0500
Subject: [Rd] Arguments of 'transform'
In-Reply-To: <B998A44C8986644EA8029CFE6396A924546AF7@exqld2-bne.qld.csiro.au>
Message-ID: <20060211163941.OAAM10262.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Bill,

I didn't realize that "x." would be partially matched by "x" when there was
a first (unnamed) argument in the function call -- but I see the error now.

Thanks,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> Bill.Venables at csiro.au
> Sent: Saturday, February 11, 2006 11:07 AM
> To: jfox at mcmaster.ca; p.dalgaard at biostat.ku.dk
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] Arguments of 'transform'
> 
> Hi John,
> 
> Unfortunately I don't think that will fix it because of 
> partial matching.
> 
> (That would be OK if the argument sequence were reversed to:
> 
> 	function(..., x.)
> 
> since partial matching does not occur with arguments coming 
> after ..., but it would break ALL existing code.)
> 
> Bill.
> 
> -----Original Message-----
> From: John Fox [mailto:jfox at mcmaster.ca]
> Sent: Sunday, 12 February 2006 1:39 AM
> To: 'Peter Dalgaard'; Venables, Bill (CMIS, Cleveland)
> Cc: r-devel at stat.math.ethz.ch
> Subject: RE: [Rd] Arguments of 'transform'
> 
> 
> Dear Peter and Bill,
> 
> How about changing the current "x argument to something like 
> "x."? That
> should make the problem that Bill points out less likely and still be
> backwards compatible with using "x" in the call to transform().
> 
> Regards,
>  John
> 
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox 
> -------------------------------- 
> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org 
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> > Sent: Saturday, February 11, 2006 4:43 AM
> > To: Bill.Venables at csiro.au
> > Cc: r-devel at stat.math.ethz.ch; p.dalgaard at biostat.ku.dk
> > Subject: Re: [Rd] Arguments of 'transform'
> > 
> > <Bill.Venables at csiro.au> writes:
> > 
> > > If you would like a 10 second R puzzle, you might like to 
> > think about 
> > > this one:
> > > 
> > > 
> > > > g <- expand.grid(long = 130:140, lat = -(10:25)) gp <- 
> > transform(g, 
> > > > x = long, y = lat)
> > > Error in transform(g, x = long, y = lat) : 
> > >         object "long" not found
> > > 
> > > 
> > > I don't expect this hasn't come up before, but I can't find 
> > mention of 
> > > it.  I suggest that to minimise this little stumbling block for 
> > > beginners (and others) we either
> > > 
> > > 	change the name of the principal argument in transform from 'x'
> > > to, say '.x' (or even 'data' as it is in 'with' for example)  OR
> > > 
> > > 	at least put a note in the help file for 'transform' in 
> > the 'Detalis' 
> > > section to say
> > >      
> > > 	*** NOTE: The only tag name unavailable to be used is 'x'. ***
> > 
> > Yes it has come up before (surprisingly rarely though), and 
> > you're probably right although changing argument names of 
> > functions should never be taken lightly as there could be 
> > people using the current ones. 
> > 
> > > 
> > > Just another little seed.
> > 
> > ...which is connected to my grievances with attach() &c the 
> other day.
> > Something about transform() just isn't The Right Way.
> > 
> > -- 
> >    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >  (*) \(*) -- University of Copenhagen   Denmark          Ph:  
> > (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: 
> > (+45) 35327907
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.uni-dortmund.de  Sun Feb 12 12:02:08 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 12 Feb 2006 12:02:08 +0100
Subject: [Rd] heatmap.2 in gplots (PR#8587)
In-Reply-To: <20060211145137.7F94221EED@slim.kubism.ku.dk>
References: <20060211145137.7F94221EED@slim.kubism.ku.dk>
Message-ID: <43EF15B0.2050300@statistik.uni-dortmund.de>

dasnicht at mac.com wrote:

> Full_Name: Shane Neph
> Version: 2.2.1
> OS: mac os x
> Submission from: (NULL) (71.113.43.247)
> 
> 
> While I found the names of the package authors and maintainer, I was
> unsuccessful in finding any contact information.

This is not a bug in R, hence please do not post it to R-bugs, R-devel 
would have been much more appropriate.
You will get contact information of the maintainer by typing, e.g.:

  library(help=gplots)

Uwe Ligges



> The preliminary documentation for heatmap.2 is inconsistent in at least a couple
> of places when discussing the suppression of one or more dendrograms (and
> column/row ordering in general).
> In the Details section, in regards to the Rowv and Colv parameters, "If either
> is NULL, no reordering will be done for the corresponding side."  The default
> value for these parameters is NULL.  With NULL, the dendrograms are computed
> (and hence reordering is done).
> In the Arguments section, Rowv shows "determines if and how the row dendrogram
> should be reordered.  Either a dendrogram or a vector of values to reorder the
> row dendrogram of FALSE to suppres reordering or by default, NULL, ...".  In
> particular, the portion about FALSE should be contrasted with the portion about
> NULL in the Details section.
> 
> Finally, it is my belief that part of the intention or using FALSE (or whatever
> is supposed to suppress the reordering) is to suppress the actual dendrogram
> drawing as well.  This is similar to how NA works for the same argument names in
> the heatmap function.  Achieving this behavior is straightforward.  Assuming
> FALSE is the argument for suppression, the column dendrogram/reordering can be
> achieved by modifying heatmap.2 near line 78-80:
> 
> FROM:
>     else {
>         colInd <- order(Colv)
>     }
> 
> TO:
>     else if ( isTRUE(Colv) ) {
>         colInd <- order(Colv)
>     } 
>     else
>         colInd <- 1:nc
> 
> This does suppress the automatic column ordering/dendrogram as desired.  Similar
> fixes for the Rowv argument are needed.
> 
> R is great - keep up the work.
> Shane
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From benphalan at gmail.com  Sun Feb 12 16:05:25 2006
From: benphalan at gmail.com (benphalan@gmail.com)
Date: Sun, 12 Feb 2006 16:05:25 +0100 (CET)
Subject: [Rd] floor and ceiling can't handle more than 15 decimal places
	(PR#8590)
Message-ID: <20060212150525.D1D0FCD4E@slim.kubism.ku.dk>

Full_Name: Ben Phalan
Version: 2.2.1
OS: Win XP
Submission from: (NULL) (131.111.111.231)


I have noticed that floor returns the wrong number when there are more than 15
decimal places:

> floor(6.999999999999999)
[1] 6
> floor(6.9999999999999999)
[1] 7

There is a similar problem with ceiling, so this may apply to all/most rounding
functions?

> ceiling (2.000000000000001)
[1] 3
> ceiling (2.0000000000000001)
[1] 2


From Ted.Harding at nessie.mcc.ac.uk  Sun Feb 12 16:37:57 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 12 Feb 2006 15:37:57 -0000 (GMT)
Subject: [Rd] floor and ceiling can't handle more than 15 decimal pla
In-Reply-To: <20060212150525.D1D0FCD4E@slim.kubism.ku.dk>
Message-ID: <XFMail.060212153757.Ted.Harding@nessie.mcc.ac.uk>

On 12-Feb-06 benphalan at gmail.com wrote:
> Full_Name: Ben Phalan
> Version: 2.2.1
> OS: Win XP
> Submission from: (NULL) (131.111.111.231)
> 
> 
> I have noticed that floor returns the wrong number when there are more
> than 15
> decimal places:
> 
>> floor(6.999999999999999)
> [1] 6
>> floor(6.9999999999999999)
> [1] 7
> 
> There is a similar problem with ceiling, so this may apply to all/most
> rounding functions?
> 
>> ceiling (2.000000000000001)
> [1] 3
>> ceiling (2.0000000000000001)
> [1] 2

This is not a problem (nor a bug) with 'floor' or 'ceiling'.
The "problem" (in quotes because the real problem is the user's)
is in R, intrinsic to the finite-length floating-point arithmetic
which is used. See:

  > 6.999999999999999 - 7
  [1] -8.881784e-16
  > 6.9999999999999999 - 7
  [1] 0
  > 2.000000000000001 - 2
  [1] 8.881784e-16
  > 2.0000000000000001 - 2
  [1] 0

so, in fact, R cannot "see" the 16th decimal place when you enter
a number to that precision -- it is simply lost. Exactly the same
"problem" would arise at some point whatever the finite precision
to which a floating-point number is stored. The effect is not
confined to functions 'floor' and 'ceiling' or any similar
"rounding" functions. It applies to all functions; it is simply
more obvious with the rounding functions.

Enter

  .Machine

and the first two items in the output are:

  $double.eps
  [1] 2.220446e-16

  $double.neg.eps
  [1] 1.110223e-16

showing that the smallest difference which can be "seen" by R
is greater than 1-^(-16).

So, when you type it in, you *think* you have entered

    2.0000000000000001

into R, but you have not. So the user has to face the problem of
how to cope with the finite-length representation in any situation
where the distinction between 2 and 2.0000000000000001 really
matters.

Hoping this helps,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 12-Feb-06                                       Time: 15:37:53
------------------------------ XFMail ------------------------------


From ted.harding at nessie.mcc.ac.uk  Sun Feb 12 16:38:07 2006
From: ted.harding at nessie.mcc.ac.uk (ted.harding@nessie.mcc.ac.uk)
Date: Sun, 12 Feb 2006 16:38:07 +0100 (CET)
Subject: [Rd] floor and ceiling can't handle more than 15 decimal pla
	(PR#8591)
Message-ID: <20060212153807.7CC8B121AE@slim.kubism.ku.dk>

On 12-Feb-06 benphalan at gmail.com wrote:
> Full_Name: Ben Phalan
> Version: 2.2.1
> OS: Win XP
> Submission from: (NULL) (131.111.111.231)
> 
> 
> I have noticed that floor returns the wrong number when there are more
> than 15
> decimal places:
> 
>> floor(6.999999999999999)
> [1] 6
>> floor(6.9999999999999999)
> [1] 7
> 
> There is a similar problem with ceiling, so this may apply to all/most
> rounding functions?
> 
>> ceiling (2.000000000000001)
> [1] 3
>> ceiling (2.0000000000000001)
> [1] 2

This is not a problem (nor a bug) with 'floor' or 'ceiling'.
The "problem" (in quotes because the real problem is the user's)
is in R, intrinsic to the finite-length floating-point arithmetic
which is used. See:

  > 6.999999999999999 - 7
  [1] -8.881784e-16
  > 6.9999999999999999 - 7
  [1] 0
  > 2.000000000000001 - 2
  [1] 8.881784e-16
  > 2.0000000000000001 - 2
  [1] 0

so, in fact, R cannot "see" the 16th decimal place when you enter
a number to that precision -- it is simply lost. Exactly the same
"problem" would arise at some point whatever the finite precision
to which a floating-point number is stored. The effect is not
confined to functions 'floor' and 'ceiling' or any similar
"rounding" functions. It applies to all functions; it is simply
more obvious with the rounding functions.

Enter

  .Machine

and the first two items in the output are:

  $double.eps
  [1] 2.220446e-16

  $double.neg.eps
  [1] 1.110223e-16

showing that the smallest difference which can be "seen" by R
is greater than 1-^(-16).

So, when you type it in, you *think* you have entered

    2.0000000000000001

into R, but you have not. So the user has to face the problem of
how to cope with the finite-length representation in any situation
where the distinction between 2 and 2.0000000000000001 really
matters.

Hoping this helps,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 12-Feb-06                                       Time: 15:37:53
------------------------------ XFMail ------------------------------


From hb at maths.lth.se  Mon Feb 13 15:48:19 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 13 Feb 2006 15:48:19 +0100
Subject: [Rd] MinGW and the ld bug
Message-ID: <59d7961d0602130648i782671cmb5e782e8334b4138@mail.gmail.com>

Hi.

I noticed that Brian Ripley found and corrected a bug in MinGW's
ld.exe, see http://www.murdoch-sutherland.com/Rtools/.  Thanks for
this.  I wonder if this is the same bug that cause my problems.  I
have tiny toy package with C code that installs perfectly on R Version
2.2.1 beta (2005-12-18 r36792) [this version was mislabelled "beta"
the first few hours on CRAN when the stable 2.2.1 version first came
out].  However, when I try to install the same on R Version 2.2.1
Patched (2006-02-09 r37305) as well as R Version 2.3.0 Under
development (unstable) (2006-02-02 r37243), I get the following error:

C:\Documents and Settings\hb\braju.com.R\R.native\build>Rcmd install R.native

---------- Making package R.native ------------
  adding build stamp to DESCRIPTION
  making DLL ...
making rowMedians.d from rowMedians.c
gcc   -IC:/PROGRA~1/R/R-2.2.1pat/include -Wall -O2   -c rowMedians.c -o rowMedia
ns.o
ar cr R.native.a rowMedians.o
ranlib R.native.a
windres --include-dir C:/PROGRA~1/R/R-2.2.1pat/include  -i R.native_res.rc -o R.
native_res.o
gcc  --shared -s  -o R.native.dll R.native.def R.native.a R.native_res.o  -LC:/P
ROGRA~1/R/R-2.2.1pat/src/gnuwin32   -lg2c -lR
c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe: R.native.d
ef:1: syntax error
c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe:R.native.de
f: file format not recognized; treating as linker script
c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe:R.native.de
f:1: syntax error
collect2: ld returned 1 exit status
make[3]: *** [R.native.dll] Error 1
make[2]: *** [srcDynlib] Error 2
make[1]: *** [all] Error 2
make: *** [pkg-R.native] Error 2
*** Installation of R.native failed ***

Removing 'C:/PROGRA~1/R/R-2.2.1pat/library/R.native'
Restoring previous 'C:/PROGRA~1/R/R-2.2.1pat/library/R.native'

My R.native.def looks like this:

LIBRARY R.native.dll
EXPORTS
 rowMedians
 rowMediansInteger
 rowMediansReal

I've tried to replace the two occurances of ld.exe in MINGW with BR's
patch, but I get the same error.  The ld of the patch and the original
one show the same version string;
patch: GNU ld version 2.16.91 20050827 and original: GNU ld version
2.16.91 20050827. I've tried to use both MINGW v5.0.0 and v5.0.2 with
both "current" (v3.4.2) and "candidate" (v3.4.4) packages.

Is this related to the bug BR found?  Any suggestions what might go
wrong between R v2.2.1 and v2.2.1 patched?

Thanks

Henrik


From gregory.r.warnes at pfizer.com  Mon Feb 13 16:35:25 2006
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Mon, 13 Feb 2006 10:35:25 -0500
Subject: [Rd] heatmap.2 in gplots (PR#8587)
Message-ID: <915D2D65A9986440A277AC5C98AA466F018638F4@groamrexm02.amer.pfizer.com>

Nitin Jain and I are the maintainers of gplots.  We'll look over the details of this bug report and correspond with Shane directly.

-G

> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org]On Behalf Of dasnicht at mac.com
> Sent: Saturday, February 11, 2006 9:52 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: [Rd] heatmap.2 in gplots (PR#8587)
> 
> 
> Full_Name: Shane Neph
> Version: 2.2.1
> OS: mac os x
> Submission from: (NULL) (71.113.43.247)
> 
> 
> While I found the names of the package authors and maintainer, I was
> unsuccessful in finding any contact information.
> 
> The preliminary documentation for heatmap.2 is inconsistent 
> in at least a couple
> of places when discussing the suppression of one or more 
> dendrograms (and
> column/row ordering in general).
> In the Details section, in regards to the Rowv and Colv 
> parameters, "If either
> is NULL, no reordering will be done for the corresponding 
> side."  The default
> value for these parameters is NULL.  With NULL, the 
> dendrograms are computed
> (and hence reordering is done).
> In the Arguments section, Rowv shows "determines if and how 
> the row dendrogram
> should be reordered.  Either a dendrogram or a vector of 
> values to reorder the
> row dendrogram of FALSE to suppres reordering or by default, 
> NULL, ...".  In
> particular, the portion about FALSE should be contrasted with 
> the portion about
> NULL in the Details section.
> 
> Finally, it is my belief that part of the intention or using 
> FALSE (or whatever
> is supposed to suppress the reordering) is to suppress the 
> actual dendrogram
> drawing as well.  This is similar to how NA works for the 
> same argument names in
> the heatmap function.  Achieving this behavior is 
> straightforward.  Assuming
> FALSE is the argument for suppression, the column 
> dendrogram/reordering can be
> achieved by modifying heatmap.2 near line 78-80:
> 
> FROM:
>     else {
>         colInd <- order(Colv)
>     }
> 
> TO:
>     else if ( isTRUE(Colv) ) {
>         colInd <- order(Colv)
>     } 
>     else
>         colInd <- 1:nc
> 
> This does suppress the automatic column ordering/dendrogram 
> as desired.  Similar
> fixes for the Rowv argument are needed.
> 
> R is great - keep up the work.
> Shane
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From ripley at stats.ox.ac.uk  Mon Feb 13 18:22:56 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Feb 2006 17:22:56 +0000 (GMT)
Subject: [Rd] MinGW and the ld bug
In-Reply-To: <59d7961d0602130648i782671cmb5e782e8334b4138@mail.gmail.com>
References: <59d7961d0602130648i782671cmb5e782e8334b4138@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602131516150.11319@gannet.stats.ox.ac.uk>

I believe the bug is triggered by the fairly unusual event you have a '.' 
in the package name, and the change in 2.2.1 to 2.2.1 patched was to add

> LIBRARY R.native.dll
                   ^^^^
(which is what my workaround in ld.exe was doing another way).

Since we are told that is the correct form and we were using it 
incorrectly before, I don't really know how to work around this.  For you, 
just delete .dll in the following line in src/gnuwin32/MkRules

%.dll:
 	@$(ECHO) LIBRARY $*.dll > $*.def

but that is not a general solution.


On Mon, 13 Feb 2006, Henrik Bengtsson wrote:

> Hi.
>
> I noticed that Brian Ripley found and corrected a bug in MinGW's
> ld.exe, see http://www.murdoch-sutherland.com/Rtools/.  Thanks for
> this.  I wonder if this is the same bug that cause my problems.  I
> have tiny toy package with C code that installs perfectly on R Version
> 2.2.1 beta (2005-12-18 r36792) [this version was mislabelled "beta"
> the first few hours on CRAN when the stable 2.2.1 version first came
> out].  However, when I try to install the same on R Version 2.2.1
> Patched (2006-02-09 r37305) as well as R Version 2.3.0 Under
> development (unstable) (2006-02-02 r37243), I get the following error:
>
> C:\Documents and Settings\hb\braju.com.R\R.native\build>Rcmd install R.native
>
> ---------- Making package R.native ------------
>  adding build stamp to DESCRIPTION
>  making DLL ...
> making rowMedians.d from rowMedians.c
> gcc   -IC:/PROGRA~1/R/R-2.2.1pat/include -Wall -O2   -c rowMedians.c -o rowMedia
> ns.o
> ar cr R.native.a rowMedians.o
> ranlib R.native.a
> windres --include-dir C:/PROGRA~1/R/R-2.2.1pat/include  -i R.native_res.rc -o R.
> native_res.o
> gcc  --shared -s  -o R.native.dll R.native.def R.native.a R.native_res.o  -LC:/P
> ROGRA~1/R/R-2.2.1pat/src/gnuwin32   -lg2c -lR
> c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe: R.native.d
> ef:1: syntax error
> c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe:R.native.de
> f: file format not recognized; treating as linker script
> c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe:R.native.de
> f:1: syntax error
> collect2: ld returned 1 exit status
> make[3]: *** [R.native.dll] Error 1
> make[2]: *** [srcDynlib] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-R.native] Error 2
> *** Installation of R.native failed ***
>
> Removing 'C:/PROGRA~1/R/R-2.2.1pat/library/R.native'
> Restoring previous 'C:/PROGRA~1/R/R-2.2.1pat/library/R.native'
>
> My R.native.def looks like this:
>
> LIBRARY R.native.dll
> EXPORTS
> rowMedians
> rowMediansInteger
> rowMediansReal
>
> I've tried to replace the two occurances of ld.exe in MINGW with BR's
> patch, but I get the same error.  The ld of the patch and the original
> one show the same version string;
> patch: GNU ld version 2.16.91 20050827 and original: GNU ld version
> 2.16.91 20050827. I've tried to use both MINGW v5.0.0 and v5.0.2 with
> both "current" (v3.4.2) and "candidate" (v3.4.4) packages.

Hmm, only 3.4.5 is there as a candidate.

> Is this related to the bug BR found?  Any suggestions what might go
> wrong between R v2.2.1 and v2.2.1 patched?
>
> Thanks
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From vincent.goulet at act.ulaval.ca  Mon Feb 13 21:57:43 2006
From: vincent.goulet at act.ulaval.ca (vincent.goulet@act.ulaval.ca)
Date: Mon, 13 Feb 2006 21:57:43 +0100 (CET)
Subject: [Rd] Typo in polygon.Rd (PR#8605)
Message-ID: <20060213205743.F351E3F24E@slim.kubism.ku.dk>

Hi,

Small typo in the description of argument 'col' of function polygon(): "(For 
back-compatibiility, ..." should obviously be "(For back-compatibility...".

The mistake was still there in 2.3.0 minutes ago...

Best,

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca


From murdoch at stats.uwo.ca  Mon Feb 13 23:27:45 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 13 Feb 2006 17:27:45 -0500
Subject: [Rd] Typo in polygon.Rd (PR#8605)
In-Reply-To: <20060213205743.F351E3F24E@slim.kubism.ku.dk>
References: <20060213205743.F351E3F24E@slim.kubism.ku.dk>
Message-ID: <43F107E1.4040907@stats.uwo.ca>

On 2/13/2006 3:57 PM, vincent.goulet at act.ulaval.ca wrote:
> Hi,
> 
> Small typo in the description of argument 'col' of function polygon(): "(For 
> back-compatibiility, ..." should obviously be "(For back-compatibility...".
> 
> The mistake was still there in 2.3.0 minutes ago...

Fixed now.

In general, typos like this don't really deserve full bug reports:  it's 
simpler just to collect a few, and post them to R-devel.  If nobody 
picks them up, then maybe a bug report would be justified.

Duncan Murdoch


From jh910 at juno.com  Tue Feb 14 03:39:41 2006
From: jh910 at juno.com (J. Hosking)
Date: Mon, 13 Feb 2006 21:39:41 -0500
Subject: [Rd] addmargins
Message-ID: <dsrftd$9t$1@sea.gmane.org>

 > addmargins(UCBAdmissions, FUN = list(Total=sum))

works with no problems, but consider:

 > myFUN <- list(Total=sum)
 > addmargins(UCBAdmissions, FUN = myFUN)
Error in "names<-.default"(`*tmp*`, value = "") :
         names() applied to a non-vector

Is this a bug?


 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R


J. R. M. Hosking


From hb at maths.lth.se  Tue Feb 14 14:02:19 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 14 Feb 2006 14:02:19 +0100
Subject: [Rd] MinGW and the ld bug
In-Reply-To: <Pine.LNX.4.64.0602131516150.11319@gannet.stats.ox.ac.uk>
References: <59d7961d0602130648i782671cmb5e782e8334b4138@mail.gmail.com>
	<Pine.LNX.4.64.0602131516150.11319@gannet.stats.ox.ac.uk>
Message-ID: <59d7961d0602140502y2342156evf2b6631c25efcf2@mail.gmail.com>

On 2/13/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> I believe the bug is triggered by the fairly unusual event you have a '.'
> in the package name, and the change in 2.2.1 to 2.2.1 patched was to add
>
> > LIBRARY R.native.dll
>                    ^^^^
> (which is what my workaround in ld.exe was doing another way).
>
> Since we are told that is the correct form and we were using it
> incorrectly before, I don't really know how to work around this.  For you,
> just delete .dll in the following line in src/gnuwin32/MkRules
>
> %.dll:
>         @$(ECHO) LIBRARY $*.dll > $*.def

Thanks. With "@$(ECHO) LIBRARY $ > $*.def" it works again.

All the best,

Henrik


> but that is not a general solution.
>
>
> On Mon, 13 Feb 2006, Henrik Bengtsson wrote:
>
> > Hi.
> >
> > I noticed that Brian Ripley found and corrected a bug in MinGW's
> > ld.exe, see http://www.murdoch-sutherland.com/Rtools/.  Thanks for
> > this.  I wonder if this is the same bug that cause my problems.  I
> > have tiny toy package with C code that installs perfectly on R Version
> > 2.2.1 beta (2005-12-18 r36792) [this version was mislabelled "beta"
> > the first few hours on CRAN when the stable 2.2.1 version first came
> > out].  However, when I try to install the same on R Version 2.2.1
> > Patched (2006-02-09 r37305) as well as R Version 2.3.0 Under
> > development (unstable) (2006-02-02 r37243), I get the following error:
> >
> > C:\Documents and Settings\hb\braju.com.R\R.native\build>Rcmd install R.native
> >
> > ---------- Making package R.native ------------
> >  adding build stamp to DESCRIPTION
> >  making DLL ...
> > making rowMedians.d from rowMedians.c
> > gcc   -IC:/PROGRA~1/R/R-2.2.1pat/include -Wall -O2   -c rowMedians.c -o rowMedia
> > ns.o
> > ar cr R.native.a rowMedians.o
> > ranlib R.native.a
> > windres --include-dir C:/PROGRA~1/R/R-2.2.1pat/include  -i R.native_res.rc -o R.
> > native_res.o
> > gcc  --shared -s  -o R.native.dll R.native.def R.native.a R.native_res.o  -LC:/P
> > ROGRA~1/R/R-2.2.1pat/src/gnuwin32   -lg2c -lR
> > c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe: R.native.d
> > ef:1: syntax error
> > c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe:R.native.de
> > f: file format not recognized; treating as linker script
> > c:\MinGW\bin\..\lib\gcc\mingw32\3.4.4\..\..\..\..\mingw32\bin\ld.exe:R.native.de
> > f:1: syntax error
> > collect2: ld returned 1 exit status
> > make[3]: *** [R.native.dll] Error 1
> > make[2]: *** [srcDynlib] Error 2
> > make[1]: *** [all] Error 2
> > make: *** [pkg-R.native] Error 2
> > *** Installation of R.native failed ***
> >
> > Removing 'C:/PROGRA~1/R/R-2.2.1pat/library/R.native'
> > Restoring previous 'C:/PROGRA~1/R/R-2.2.1pat/library/R.native'
> >
> > My R.native.def looks like this:
> >
> > LIBRARY R.native.dll
> > EXPORTS
> > rowMedians
> > rowMediansInteger
> > rowMediansReal
> >
> > I've tried to replace the two occurances of ld.exe in MINGW with BR's
> > patch, but I get the same error.  The ld of the patch and the original
> > one show the same version string;
> > patch: GNU ld version 2.16.91 20050827 and original: GNU ld version
> > 2.16.91 20050827. I've tried to use both MINGW v5.0.0 and v5.0.2 with
> > both "current" (v3.4.2) and "candidate" (v3.4.4) packages.
>
> Hmm, only 3.4.5 is there as a candidate.
>
> > Is this related to the bug BR found?  Any suggestions what might go
> > wrong between R v2.2.1 and v2.2.1 patched?
> >
> > Thanks
> >
> > Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Feb 14 16:19:34 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 15:19:34 +0000 (GMT)
Subject: [Rd] addmargins
In-Reply-To: <dsrftd$9t$1@sea.gmane.org>
References: <dsrftd$9t$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.64.0602140812150.27036@gannet.stats.ox.ac.uk>

On Mon, 13 Feb 2006, J. Hosking wrote:

> > addmargins(UCBAdmissions, FUN = list(Total=sum))
>
> works with no problems, but consider:
>
> > myFUN <- list(Total=sum)
> > addmargins(UCBAdmissions, FUN = myFUN)
> Error in "names<-.default"(`*tmp*`, value = "") :
>         names() applied to a non-vector
>
> Is this a bug?

I believe so.  addmargins contains

FUN <- eval(add.names(substitute(FUN)))

and that only makes sense if FUN is a call and not a symbol.  I've made 
the appropriate change to R-devel.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From leydold at statistik.wu-wien.ac.at  Tue Feb 14 16:44:23 2006
From: leydold at statistik.wu-wien.ac.at (Josef Leydold)
Date: Tue, 14 Feb 2006 16:44:23 +0100
Subject: [Rd] S4 classes and methods with optional arguments
In-Reply-To: <mailman.7.1139914801.6090.r-devel@r-project.org>
References: <mailman.7.1139914801.6090.r-devel@r-project.org>
Message-ID: <20060214154423.GA6722@essek.stat-math.wu-wien.ac.at>

Hi,

i have used S4 classes to implement a unified access to random number generators
(package rstream on CRAN).

I have used a construct to allow optional arguments:

if(!isGeneric("rstream.sample"))
        setGeneric("rstream.sample", function(stream,...) standardGeneric("rstream.sample"))

setMethod("rstream.sample", c("rstream","numeric"), 
          function(stream,n=1) { ... [ code ] ... } )

Thus if rs is an instance of an rstream object one can a random
sample of size 10 using 

rstream.sample(rs, 10)

for a sample of size 1 one can use equivalently

rstream.sample(rs,1) 
rstream.sample(rs) 

however, with R-devel the above construct does not work any more, due to
more stringent checkings. It can be fixed by replacing it by

if(!isGeneric("rstream.sample"))
        setGeneric("rstream.sample", function(stream,n) standardGeneric("rstream.sample"))

setMethod("rstream.sample", c("rstream","numeric"), 
          function(stream,n=1) { ... [ code ] ... } )

then rstream.sample(rs) does not work any more.

Is there still a way to allow optional arguments for methods of
S4 classes?

Josef


From sfalcon at fhcrc.org  Tue Feb 14 17:22:04 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 14 Feb 2006 08:22:04 -0800
Subject: [Rd] S4 classes and methods with optional arguments
In-Reply-To: <20060214154423.GA6722@essek.stat-math.wu-wien.ac.at> (Josef
	Leydold's message of "Tue, 14 Feb 2006 16:44:23 +0100")
References: <mailman.7.1139914801.6090.r-devel@r-project.org>
	<20060214154423.GA6722@essek.stat-math.wu-wien.ac.at>
Message-ID: <m2u0b152s3.fsf@ziti.local>

Hi Josef,

On 14 Feb 2006, leydold at statistik.wu-wien.ac.at wrote:
> I have used a construct to allow optional arguments:
>
> if(!isGeneric("rstream.sample")) setGeneric("rstream.sample",
> function(stream,...) standardGeneric("rstream.sample"))

First, a question:
  Is this idiom of testing for the generic before defining it still
  "recommended"?  It seems to me that one should either define one's
  own generic in the package namespace or define a method for a
  *particular* generic defined elsewhere.  Otherwise, one could end up
  defining a method for the wrong generic.

> setMethod("rstream.sample", c("rstream","numeric"),
> function(stream,n=1) { ... [ code ] ... } )

This will work if you remove the second arg in the signature.  That
is,

  setMethod("rstream.sample", signature(stream="rstream"),
            function(strea, n=1) { ... })

Putting an arg in the signature means dispatching on that arg.  You
cannot dispatch on an arg that is not named in the definition of the
generic.

> however, with R-devel the above construct does not work any more,
> due to more stringent checkings. It can be fixed by replacing it by
>
> if(!isGeneric("rstream.sample")) setGeneric("rstream.sample",
> function(stream,n) standardGeneric("rstream.sample"))
>
> setMethod("rstream.sample", c("rstream","numeric"),
> function(stream,n=1) { ... [ code ] ... } )
>
> then rstream.sample(rs) does not work any more.
>
> Is there still a way to allow optional arguments for methods of S4
> classes?

Here's an approach that works for me:

1. You have to specify a default value to args *in the generic*.  This
   doesn't make a whole lot of sense to me, but it does seem to be
   needed.

   setGeneric("rstream.sample", 
              function(stream, n=0) standardGeneric("rstream.sample"))

2. Then define a method with a signature that matches the default
   case:

   setMethod("rstream.sample", signature(stream="rstream", n="missing"),
             function(stream, n=1) { ... })

   Note that you could also use signature(stream="rstream"), but then
   a call like rstream.sample(s, "foo") could match... Leaving out the
   arg is like saying n="ANY".

HTH,

+ seth


From ripley at stats.ox.ac.uk  Tue Feb 14 17:37:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 16:37:15 +0000 (GMT)
Subject: [Rd] S4 classes and methods with optional arguments
In-Reply-To: <20060214154423.GA6722@essek.stat-math.wu-wien.ac.at>
References: <mailman.7.1139914801.6090.r-devel@r-project.org>
	<20060214154423.GA6722@essek.stat-math.wu-wien.ac.at>
Message-ID: <Pine.LNX.4.64.0602141613550.12182@gannet.stats.ox.ac.uk>

The problem is not the optional argument, but the attempt to dispatch on 
an argument not in the generic.

setGeneric("rstream.sample", function(stream, ...)
            standardGeneric("rstream.sample"))
setMethod("rstream.sample", "rstream", function(stream,n=1) { print(n) } )
rstream.sample(rs, 10)
[1] 10
rstream.sample(rs)
[1] 1

works, and seems to work as you intended.

On Tue, 14 Feb 2006, Josef Leydold wrote:

> Hi,
>
> i have used S4 classes to implement a unified access to random number generators
> (package rstream on CRAN).
>
> I have used a construct to allow optional arguments:
>
> if(!isGeneric("rstream.sample"))
>        setGeneric("rstream.sample", function(stream,...) standardGeneric("rstream.sample"))
>
> setMethod("rstream.sample", c("rstream","numeric"),
>          function(stream,n=1) { ... [ code ] ... } )
>
> Thus if rs is an instance of an rstream object one can a random
> sample of size 10 using
>
> rstream.sample(rs, 10)
>
> for a sample of size 1 one can use equivalently
>
> rstream.sample(rs,1)
> rstream.sample(rs)
>
> however, with R-devel the above construct does not work any more, due to
> more stringent checkings. It can be fixed by replacing it by
>
> if(!isGeneric("rstream.sample"))
>        setGeneric("rstream.sample", function(stream,n) standardGeneric("rstream.sample"))
>
> setMethod("rstream.sample", c("rstream","numeric"),
>          function(stream,n=1) { ... [ code ] ... } )
>
> then rstream.sample(rs) does not work any more.
>
> Is there still a way to allow optional arguments for methods of
> S4 classes?
>
> Josef
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Tue Feb 14 19:02:35 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 14 Feb 2006 10:02:35 -0800
Subject: [Rd] S4 classes and methods with optional arguments
In-Reply-To: <20060214154423.GA6722@essek.stat-math.wu-wien.ac.at> (Josef
	Leydold's message of "Tue, 14 Feb 2006 16:44:23 +0100")
References: <mailman.7.1139914801.6090.r-devel@r-project.org>
	<20060214154423.GA6722@essek.stat-math.wu-wien.ac.at>
Message-ID: <6ph4q31n7ic.fsf@wellington.fhcrc.org>

Echoing similar suggestions, but with a bit of philosophy... How about:

setGeneric("rstream.sample",
           function( stream, ... ) standardGeneric("rstream.sample"))

setMethod("rstream.sample", c( "numeric" ),
          function( stream, n = 1, ... ) { code }  )

It seems to me like the generic should (always?) just have arguments
used for dispatch -- stream, in this case -- and that methods then
specify default values. To also dispatch on the second argument, one
might

setGeneric("rstream.sample",
           function( stream, n, ... ) standardGeneric("rstream.sample"))

setMethod("rstream.sample", c( "rstream.sample", "numeric" ),
          function( stream, n, ... ) { code } )

setMethod("rstream.sample", c( "rstream.sample", "missing" ),
          function( stream, n, ... ) rstream.sample( stream, n = 1 ))

setMethod("rstream.sample", c( "rstream.sample", "otherclass" ),
          function( stream, n, ... ) n )

Martin

"Josef Leydold" <leydold at statistik.wu-wien.ac.at> writes:

> Hi,
>
> i have used S4 classes to implement a unified access to random number generators
> (package rstream on CRAN).
>
> I have used a construct to allow optional arguments:
>
> if(!isGeneric("rstream.sample"))
>         setGeneric("rstream.sample", function(stream,...) standardGeneric("rstream.sample"))
>
> setMethod("rstream.sample", c("rstream","numeric"), 
>           function(stream,n=1) { ... [ code ] ... } )
>
> Thus if rs is an instance of an rstream object one can a random
> sample of size 10 using 
>
> rstream.sample(rs, 10)
>
> for a sample of size 1 one can use equivalently
>
> rstream.sample(rs,1) 
> rstream.sample(rs) 
>
> however, with R-devel the above construct does not work any more, due to
> more stringent checkings. It can be fixed by replacing it by
>
> if(!isGeneric("rstream.sample"))
>         setGeneric("rstream.sample", function(stream,n) standardGeneric("rstream.sample"))
>
> setMethod("rstream.sample", c("rstream","numeric"), 
>           function(stream,n=1) { ... [ code ] ... } )
>
> then rstream.sample(rs) does not work any more.
>
> Is there still a way to allow optional arguments for methods of
> S4 classes?
>
> Josef
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Tue Feb 14 19:42:52 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 14 Feb 2006 10:42:52 -0800
Subject: [Rd] S4 classes and methods with optional arguments
In-Reply-To: <6ph4q31n7ic.fsf@wellington.fhcrc.org> (Martin Morgan's message
	of "Tue, 14 Feb 2006 10:02:35 -0800")
References: <mailman.7.1139914801.6090.r-devel@r-project.org>
	<20060214154423.GA6722@essek.stat-math.wu-wien.ac.at>
	<6ph4q31n7ic.fsf@wellington.fhcrc.org>
Message-ID: <m2zmkt3hoz.fsf@ziti.local>

On 14 Feb 2006, mtmorgan at fhcrc.org wrote:

> It seems to me like the generic should (always?) just have arguments
> used for dispatch -- stream, in this case -- and that methods then
> specify default values. 

There are advantages to adding named arguments to a generic to define
the expected interface.  These 'extra' args may not be *needed* for
dispatch in the sense that the first arg may be enough to decide what
method you want.

So IMO, there are two reasons to put an arg in a generic:

1. You really want to dispatch on it.
2. You want to define an interface and can handle the fact that you
   will have to also dispatch on it.

I guess my point is that for downstream developers extending your
generic and for the sake of documentation, relying too much on '...'
can make things difficult.

> To also dispatch on the second argument, one
> might
>
> setGeneric("rstream.sample",
> function( stream, n, ... ) standardGeneric("rstream.sample"))
>
> setMethod("rstream.sample", c( "rstream.sample", "numeric" ),
> function( stream, n, ... ) { code } )
>
> setMethod("rstream.sample", c( "rstream.sample", "missing" ),
> function( stream, n, ... ) rstream.sample( stream, n = 1 ))

And here I might offer a slight improvement.  Putting the default
value in the signature of the function will give automated tools a
chance to document:

  setMethod("rstream.sample", c("rstream.sample", "missing"),
            function( stream, n=1, ...) rstream.sample(stream, n))

+ seth


From vasu.akkineni at gmail.com  Tue Feb 14 21:10:34 2006
From: vasu.akkineni at gmail.com (Vasundhara Akkineni)
Date: Tue, 14 Feb 2006 15:10:34 -0500
Subject: [Rd] Legend to a heatmap
Message-ID: <3b67376c0602141210o4a9a0cb3sc0477528d9d70885@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060214/3f05836d/attachment.pl

From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 15 10:16:18 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 15 Feb 2006 10:16:18 +0100 (CET)
Subject: [Rd] S3 generics without NS and cleanEx()
Message-ID: <Pine.LNX.4.64.0602150954340.20143@artemis.imbe.med.uni-erlangen.de>


Good morning,

we recently observed a problem with importing S3 generics from a foreign 
package (without namespace), defining a S3 method in a package _with_ 
namespace and the `cleanEx()' function which is automatically generated 
and executed before examples are run by R CMD check.

To be more precise. Package `strucchange' defines a S3 generic

     sctest <- function(x, ...) UseMethod("sctest")

and the development version of `party' defines

     sctest.mob <- function(x, node = NULL, ...) {
         ...

which is exported in party's namespace

     S3method(sctest, mob)

Creating a `mob' object and running `sctest' on it works fine.

However, when we attach `party' and run `cleanEx()', the `sctest' method 
for `mob' is no longer found. Before `cleanEx()' we get

R> methods(sctest)
[1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp 
sctest.mob*

and afterwards

R> methods(sctest)
[1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp

is missing.

Debugging `cleanEx()' shows that those objects are removed from the 
global environment:

ls(envir = env, all.names = TRUE)
[1] ".Random.seed"         ".__S3MethodsTable__." "GCtorture"
[4] "a"                    "euro"

where the second one looks very suspicious.

`party_0.4-0.tar.gz' is available from

     http://www.imbe.med.uni-erlangen.de/~hothorn/party_0.4-0.tar.gz

and

     http://www.imbe.med.uni-erlangen.de/~hothorn/modeltools_0.2-3.tar.gz

is required.

The example below can be reproduced with both R-2.2.1 and R-2.3.0.

Best wishes,

Torsten



R> invisible(options(echo = TRUE))
R> ### * <HEADER>
R> ###
R> attach(NULL, name = "CheckExEnv")
R> assign(".CheckExEnv", as.environment(2), pos = length(search())) # base
R> ## add some hooks to label plot pages for base and grid graphics
R> setHook("plot.new", ".newplot.hook")
R> setHook("persp", ".newplot.hook")
R> setHook("grid.newpage", ".gridplot.hook")
R> 
R> assign("cleanEx",
+        function(env = .GlobalEnv) {
+ 	   rm(list = ls(envir = env, all.names = TRUE), envir = env)
+            RNGkind("default", "default")
+ 	   set.seed(1)
+    	   options(warn = 1)
+ 	   delayedAssign("T", stop("T used instead of TRUE"),
+ 		  assign.env = .CheckExEnv)
+ 	   delayedAssign("F", stop("F used instead of FALSE"),
+ 		  assign.env = .CheckExEnv)
+ 	   sch <- search()
+ 	   newitems <- sch[! sch %in% .oldSearch]
+ 	   for(item in rev(newitems))
+                eval(substitute(detach(item), list(item=item)))
+ 	   missitems <- .oldSearch[! .oldSearch %in% sch]
+ 	   if(length(missitems))
+ 	       warning("items ", paste(missitems, collapse=", "),
+ 		       " have been removed from the search path")
+        },
+        env = .CheckExEnv)
R> assign("..nameEx", "__{must remake R-ex/*.R}__", env = .CheckExEnv) # for now
R> assign("ptime", proc.time(), env = .CheckExEnv)
R> grDevices::postscript("party-Ex.ps")
R> assign("par.postscript", graphics::par(no.readonly = TRUE), env = .CheckExEnv)
R> options(contrasts = c(unordered = "contr.treatment", ordered = "contr.poly"))
R> options(warn = 1) 
R> library('party')
Loading required package: survival
Loading required package: splines
Loading required package: grid
Loading required package: modeltools
Loading required package: coin
Loading required package: mvtnorm
Loading required package: zoo
Loading required package: sandwich
Loading required package: strucchange
R> 
R> methods(sctest)
[1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp    sctest.mob*

    Non-visible functions are asterisked
R> 
R> assign(".oldSearch", search(), env = .CheckExEnv)
R> assign(".oldNS", loadedNamespaces(), env = .CheckExEnv)
R> cleanEx(); ..nameEx <- "BinaryTree-class"
R> 
R> methods(sctest)
[1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp 
R> 
R> 
R> proc.time()
[1] 1.77 0.01 1.97 0.00 0.00
R>


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 15 10:26:55 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 15 Feb 2006 10:26:55 +0100 (CET)
Subject: [Rd] conflicting S4 generics
Message-ID: <Pine.LNX.4.64.0602151020400.20143@artemis.imbe.med.uni-erlangen.de>


Good morning again,

there is a second problem which keeps us from finishing new releases.

Package `kernlab' defines a `fit' S4 generic and `modeltools' does as 
well (so this is kind of an internal communication problem). `party' and 
`kernlab' define methods for `fit' and export them in their namespaces.

Now, when I attach `party' I get

R> library("party")
R> getMethods(fit)
model = "StatModel", data = "ModelEnv":
structure(function (model, data, ...)
model at fit(data, ...), class = structure("MethodDefinition", package = 
"methods"), target = structure(c("StatModel",
"ModelEnv"), .Names = c("model", "data"), class = structure("signature", 
package = "methods")), defined = structure(c("StatModel",
"ModelEnv"), .Names = c("model", "data"), class = structure("signature", 
package = "methods")))

model = "StatModel", data = "LearningSample":
structure(function (model, data, ...)
model at fit(data, ...), class = structure("MethodDefinition", package = 
"methods"), target = structure(c("StatModel",
"LearningSample"), .Names = c("model", "data"), class = 
structure("signature", package = "methods")), defined = 
structure(c("StatModel",
"LearningSample"), .Names = c("model", "data"), class = 
structure("signature", package = "methods")))

Now, when I additionally attach `kernlab', only the `kernlab' definitions 
remain active

R> getMethods(fit)
object = "ksvm":
structure(function (object)
object at fit, class = structure("MethodDefinition", package = "methods"), 
target = structure("ksvm", .Names = "object", class = 
structure("signature", package = "methods")), defined = structure("ksvm", 
.Names = "object", class = structure("signature", package = "methods")))

object = "gausspr":
structure(function (object)
object at fit, class = structure("MethodDefinition", package = "methods"), 
target = structure("gausspr", .Names = "object", class = 
structure("signature", package = "methods")), defined = 
structure("gausspr", .Names = "object", class = structure("signature", 
package = "methods")))

object = "rvm":
structure(function (object)
object at fit, class = structure("MethodDefinition", package = "methods"), 
target = structure("rvm", .Names = "object", class = 
structure("signature", package = "methods")), defined = structure("rvm", 
.Names = "object", class = structure("signature", package = "methods")))

object = "onlearn":
structure(function (object)
object at fit, class = structure("MethodDefinition", package = "methods"), 
target = structure("onlearn", .Names = "object", class = 
structure("signature", package = "methods")), defined = 
structure("onlearn", .Names = "object", class = structure("signature", 
package = "methods")))


and the `party' is over. Is there anything (except agreeing on a common 
signature) one can do about it?

Best wishes,

Torsten


From ripley at stats.ox.ac.uk  Wed Feb 15 10:33:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Feb 2006 09:33:35 +0000 (GMT)
Subject: [Rd] S3 generics without NS and cleanEx()
In-Reply-To: <Pine.LNX.4.64.0602150954340.20143@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.64.0602150954340.20143@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.LNX.4.64.0602150929130.19834@gannet.stats.ox.ac.uk>

Torsten,

The error is that .__S3MethodsTable__. ends up in the global environment.
Are you importing sctest (I can't see it)?  I think that's the problem.

>From R-exts:

The standard method for S3-style @code{UseMethod} dispatching might fail
to locate methods defined in a package that is imported but not attached
to the search path.  To ensure that these methods are available the
packages defining the methods should ensure that the generics are
imported and register the methods using @code{S3method} directives.
^^^^^^^^

Brian

On Wed, 15 Feb 2006, Torsten Hothorn wrote:

>
> Good morning,
>
> we recently observed a problem with importing S3 generics from a foreign
> package (without namespace), defining a S3 method in a package _with_
> namespace and the `cleanEx()' function which is automatically generated
> and executed before examples are run by R CMD check.
>
> To be more precise. Package `strucchange' defines a S3 generic
>
>     sctest <- function(x, ...) UseMethod("sctest")
>
> and the development version of `party' defines
>
>     sctest.mob <- function(x, node = NULL, ...) {
>         ...
>
> which is exported in party's namespace
>
>     S3method(sctest, mob)
>
> Creating a `mob' object and running `sctest' on it works fine.
>
> However, when we attach `party' and run `cleanEx()', the `sctest' method
> for `mob' is no longer found. Before `cleanEx()' we get
>
> R> methods(sctest)
> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
> sctest.mob*
>
> and afterwards
>
> R> methods(sctest)
> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>
> is missing.
>
> Debugging `cleanEx()' shows that those objects are removed from the
> global environment:
>
> ls(envir = env, all.names = TRUE)
> [1] ".Random.seed"         ".__S3MethodsTable__." "GCtorture"
> [4] "a"                    "euro"
>
> where the second one looks very suspicious.
>
> `party_0.4-0.tar.gz' is available from
>
>     http://www.imbe.med.uni-erlangen.de/~hothorn/party_0.4-0.tar.gz
>
> and
>
>     http://www.imbe.med.uni-erlangen.de/~hothorn/modeltools_0.2-3.tar.gz
>
> is required.
>
> The example below can be reproduced with both R-2.2.1 and R-2.3.0.
>
> Best wishes,
>
> Torsten
>
>
>
> R> invisible(options(echo = TRUE))
> R> ### * <HEADER>
> R> ###
> R> attach(NULL, name = "CheckExEnv")
> R> assign(".CheckExEnv", as.environment(2), pos = length(search())) # base
> R> ## add some hooks to label plot pages for base and grid graphics
> R> setHook("plot.new", ".newplot.hook")
> R> setHook("persp", ".newplot.hook")
> R> setHook("grid.newpage", ".gridplot.hook")
> R>
> R> assign("cleanEx",
> +        function(env = .GlobalEnv) {
> + 	   rm(list = ls(envir = env, all.names = TRUE), envir = env)
> +            RNGkind("default", "default")
> + 	   set.seed(1)
> +    	   options(warn = 1)
> + 	   delayedAssign("T", stop("T used instead of TRUE"),
> + 		  assign.env = .CheckExEnv)
> + 	   delayedAssign("F", stop("F used instead of FALSE"),
> + 		  assign.env = .CheckExEnv)
> + 	   sch <- search()
> + 	   newitems <- sch[! sch %in% .oldSearch]
> + 	   for(item in rev(newitems))
> +                eval(substitute(detach(item), list(item=item)))
> + 	   missitems <- .oldSearch[! .oldSearch %in% sch]
> + 	   if(length(missitems))
> + 	       warning("items ", paste(missitems, collapse=", "),
> + 		       " have been removed from the search path")
> +        },
> +        env = .CheckExEnv)
> R> assign("..nameEx", "__{must remake R-ex/*.R}__", env = .CheckExEnv) # for now
> R> assign("ptime", proc.time(), env = .CheckExEnv)
> R> grDevices::postscript("party-Ex.ps")
> R> assign("par.postscript", graphics::par(no.readonly = TRUE), env = .CheckExEnv)
> R> options(contrasts = c(unordered = "contr.treatment", ordered = "contr.poly"))
> R> options(warn = 1)
> R> library('party')
> Loading required package: survival
> Loading required package: splines
> Loading required package: grid
> Loading required package: modeltools
> Loading required package: coin
> Loading required package: mvtnorm
> Loading required package: zoo
> Loading required package: sandwich
> Loading required package: strucchange
> R>
> R> methods(sctest)
> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp    sctest.mob*
>
>    Non-visible functions are asterisked
> R>
> R> assign(".oldSearch", search(), env = .CheckExEnv)
> R> assign(".oldNS", loadedNamespaces(), env = .CheckExEnv)
> R> cleanEx(); ..nameEx <- "BinaryTree-class"
> R>
> R> methods(sctest)
> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
> R>
> R>
> R> proc.time()
> [1] 1.77 0.01 1.97 0.00 0.00
> R>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 15 10:38:42 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 15 Feb 2006 10:38:42 +0100 (CET)
Subject: [Rd] S3 generics without NS and cleanEx()
In-Reply-To: <Pine.LNX.4.64.0602150929130.19834@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0602150954340.20143@artemis.imbe.med.uni-erlangen.de>
	<Pine.LNX.4.64.0602150929130.19834@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602151036530.26571@artemis.imbe.med.uni-erlangen.de>


On Wed, 15 Feb 2006, Prof Brian Ripley wrote:

> Torsten,
>
> The error is that .__S3MethodsTable__. ends up in the global environment.
> Are you importing sctest (I can't see it)?  I think that's the problem.
>

yes. But `strucchange' has no namespace and so I can't import `sctest' in 
the NAMESPACE file. Or am I missing something?

Thanks!

Torsten

>> From R-exts:
>
> The standard method for S3-style @code{UseMethod} dispatching might fail
> to locate methods defined in a package that is imported but not attached
> to the search path.  To ensure that these methods are available the
> packages defining the methods should ensure that the generics are
> imported and register the methods using @code{S3method} directives.
> ^^^^^^^^
>
> Brian
>
> On Wed, 15 Feb 2006, Torsten Hothorn wrote:
>
>>
>> Good morning,
>>
>> we recently observed a problem with importing S3 generics from a foreign
>> package (without namespace), defining a S3 method in a package _with_
>> namespace and the `cleanEx()' function which is automatically generated
>> and executed before examples are run by R CMD check.
>>
>> To be more precise. Package `strucchange' defines a S3 generic
>>
>>     sctest <- function(x, ...) UseMethod("sctest")
>>
>> and the development version of `party' defines
>>
>>     sctest.mob <- function(x, node = NULL, ...) {
>>         ...
>>
>> which is exported in party's namespace
>>
>>     S3method(sctest, mob)
>>
>> Creating a `mob' object and running `sctest' on it works fine.
>>
>> However, when we attach `party' and run `cleanEx()', the `sctest' method
>> for `mob' is no longer found. Before `cleanEx()' we get
>>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>> sctest.mob*
>>
>> and afterwards
>>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>>
>> is missing.
>>
>> Debugging `cleanEx()' shows that those objects are removed from the
>> global environment:
>>
>> ls(envir = env, all.names = TRUE)
>> [1] ".Random.seed"         ".__S3MethodsTable__." "GCtorture"
>> [4] "a"                    "euro"
>>
>> where the second one looks very suspicious.
>>
>> `party_0.4-0.tar.gz' is available from
>>
>>     http://www.imbe.med.uni-erlangen.de/~hothorn/party_0.4-0.tar.gz
>>
>> and
>>
>>     http://www.imbe.med.uni-erlangen.de/~hothorn/modeltools_0.2-3.tar.gz
>>
>> is required.
>>
>> The example below can be reproduced with both R-2.2.1 and R-2.3.0.
>>
>> Best wishes,
>>
>> Torsten
>>
>>
>>
>> R> invisible(options(echo = TRUE))
>> R> ### * <HEADER>
>> R> ###
>> R> attach(NULL, name = "CheckExEnv")
>> R> assign(".CheckExEnv", as.environment(2), pos = length(search())) # base
>> R> ## add some hooks to label plot pages for base and grid graphics
>> R> setHook("plot.new", ".newplot.hook")
>> R> setHook("persp", ".newplot.hook")
>> R> setHook("grid.newpage", ".gridplot.hook")
>> R>
>> R> assign("cleanEx",
>> +        function(env = .GlobalEnv) {
>> + 	   rm(list = ls(envir = env, all.names = TRUE), envir = env)
>> +            RNGkind("default", "default")
>> + 	   set.seed(1)
>> +    	   options(warn = 1)
>> + 	   delayedAssign("T", stop("T used instead of TRUE"),
>> + 		  assign.env = .CheckExEnv)
>> + 	   delayedAssign("F", stop("F used instead of FALSE"),
>> + 		  assign.env = .CheckExEnv)
>> + 	   sch <- search()
>> + 	   newitems <- sch[! sch %in% .oldSearch]
>> + 	   for(item in rev(newitems))
>> +                eval(substitute(detach(item), list(item=item)))
>> + 	   missitems <- .oldSearch[! .oldSearch %in% sch]
>> + 	   if(length(missitems))
>> + 	       warning("items ", paste(missitems, collapse=", "),
>> + 		       " have been removed from the search path")
>> +        },
>> +        env = .CheckExEnv)
>> R> assign("..nameEx", "__{must remake R-ex/*.R}__", env = .CheckExEnv) # for now
>> R> assign("ptime", proc.time(), env = .CheckExEnv)
>> R> grDevices::postscript("party-Ex.ps")
>> R> assign("par.postscript", graphics::par(no.readonly = TRUE), env = .CheckExEnv)
>> R> options(contrasts = c(unordered = "contr.treatment", ordered = "contr.poly"))
>> R> options(warn = 1)
>> R> library('party')
>> Loading required package: survival
>> Loading required package: splines
>> Loading required package: grid
>> Loading required package: modeltools
>> Loading required package: coin
>> Loading required package: mvtnorm
>> Loading required package: zoo
>> Loading required package: sandwich
>> Loading required package: strucchange
>> R>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp    sctest.mob*
>>
>>    Non-visible functions are asterisked
>> R>
>> R> assign(".oldSearch", search(), env = .CheckExEnv)
>> R> assign(".oldNS", loadedNamespaces(), env = .CheckExEnv)
>> R> cleanEx(); ..nameEx <- "BinaryTree-class"
>> R>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>> R>
>> R>
>> R> proc.time()
>> [1] 1.77 0.01 1.97 0.00 0.00
>> R>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Wed Feb 15 10:41:30 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Feb 2006 09:41:30 +0000 (GMT)
Subject: [Rd] S3 generics without NS and cleanEx()
In-Reply-To: <Pine.LNX.4.64.0602150929130.19834@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0602150954340.20143@artemis.imbe.med.uni-erlangen.de>
	<Pine.LNX.4.64.0602150929130.19834@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602150939260.19834@gannet.stats.ox.ac.uk>

Follow up:

You said

>> which is exported in party's namespace
>>
>>     S3method(sctest, mob)

but that's not true: it is registered not exported.  You need to export it 
as strucchange does not have a namespace.


On Wed, 15 Feb 2006, Prof Brian Ripley wrote:

> Torsten,
>
> The error is that .__S3MethodsTable__. ends up in the global environment.
> Are you importing sctest (I can't see it)?  I think that's the problem.
>
>> From R-exts:
>
> The standard method for S3-style @code{UseMethod} dispatching might fail
> to locate methods defined in a package that is imported but not attached
> to the search path.  To ensure that these methods are available the
> packages defining the methods should ensure that the generics are
> imported and register the methods using @code{S3method} directives.
> ^^^^^^^^
>
> Brian
>
> On Wed, 15 Feb 2006, Torsten Hothorn wrote:
>
>>
>> Good morning,
>>
>> we recently observed a problem with importing S3 generics from a foreign
>> package (without namespace), defining a S3 method in a package _with_
>> namespace and the `cleanEx()' function which is automatically generated
>> and executed before examples are run by R CMD check.
>>
>> To be more precise. Package `strucchange' defines a S3 generic
>>
>>     sctest <- function(x, ...) UseMethod("sctest")
>>
>> and the development version of `party' defines
>>
>>     sctest.mob <- function(x, node = NULL, ...) {
>>         ...
>>
>> which is exported in party's namespace
>>
>>     S3method(sctest, mob)
>>
>> Creating a `mob' object and running `sctest' on it works fine.
>>
>> However, when we attach `party' and run `cleanEx()', the `sctest' method
>> for `mob' is no longer found. Before `cleanEx()' we get
>>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>> sctest.mob*
>>
>> and afterwards
>>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>>
>> is missing.
>>
>> Debugging `cleanEx()' shows that those objects are removed from the
>> global environment:
>>
>> ls(envir = env, all.names = TRUE)
>> [1] ".Random.seed"         ".__S3MethodsTable__." "GCtorture"
>> [4] "a"                    "euro"
>>
>> where the second one looks very suspicious.
>>
>> `party_0.4-0.tar.gz' is available from
>>
>>     http://www.imbe.med.uni-erlangen.de/~hothorn/party_0.4-0.tar.gz
>>
>> and
>>
>>     http://www.imbe.med.uni-erlangen.de/~hothorn/modeltools_0.2-3.tar.gz
>>
>> is required.
>>
>> The example below can be reproduced with both R-2.2.1 and R-2.3.0.
>>
>> Best wishes,
>>
>> Torsten
>>
>>
>>
>> R> invisible(options(echo = TRUE))
>> R> ### * <HEADER>
>> R> ###
>> R> attach(NULL, name = "CheckExEnv")
>> R> assign(".CheckExEnv", as.environment(2), pos = length(search())) # base
>> R> ## add some hooks to label plot pages for base and grid graphics
>> R> setHook("plot.new", ".newplot.hook")
>> R> setHook("persp", ".newplot.hook")
>> R> setHook("grid.newpage", ".gridplot.hook")
>> R>
>> R> assign("cleanEx",
>> +        function(env = .GlobalEnv) {
>> + 	   rm(list = ls(envir = env, all.names = TRUE), envir = env)
>> +            RNGkind("default", "default")
>> + 	   set.seed(1)
>> +    	   options(warn = 1)
>> + 	   delayedAssign("T", stop("T used instead of TRUE"),
>> + 		  assign.env = .CheckExEnv)
>> + 	   delayedAssign("F", stop("F used instead of FALSE"),
>> + 		  assign.env = .CheckExEnv)
>> + 	   sch <- search()
>> + 	   newitems <- sch[! sch %in% .oldSearch]
>> + 	   for(item in rev(newitems))
>> +                eval(substitute(detach(item), list(item=item)))
>> + 	   missitems <- .oldSearch[! .oldSearch %in% sch]
>> + 	   if(length(missitems))
>> + 	       warning("items ", paste(missitems, collapse=", "),
>> + 		       " have been removed from the search path")
>> +        },
>> +        env = .CheckExEnv)
>> R> assign("..nameEx", "__{must remake R-ex/*.R}__", env = .CheckExEnv) # for now
>> R> assign("ptime", proc.time(), env = .CheckExEnv)
>> R> grDevices::postscript("party-Ex.ps")
>> R> assign("par.postscript", graphics::par(no.readonly = TRUE), env = .CheckExEnv)
>> R> options(contrasts = c(unordered = "contr.treatment", ordered = "contr.poly"))
>> R> options(warn = 1)
>> R> library('party')
>> Loading required package: survival
>> Loading required package: splines
>> Loading required package: grid
>> Loading required package: modeltools
>> Loading required package: coin
>> Loading required package: mvtnorm
>> Loading required package: zoo
>> Loading required package: sandwich
>> Loading required package: strucchange
>> R>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp    sctest.mob*
>>
>>    Non-visible functions are asterisked
>> R>
>> R> assign(".oldSearch", search(), env = .CheckExEnv)
>> R> assign(".oldNS", loadedNamespaces(), env = .CheckExEnv)
>> R> cleanEx(); ..nameEx <- "BinaryTree-class"
>> R>
>> R> methods(sctest)
>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>> R>
>> R>
>> R> proc.time()
>> [1] 1.77 0.01 1.97 0.00 0.00
>> R>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 15 10:52:29 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 15 Feb 2006 10:52:29 +0100 (CET)
Subject: [Rd] S3 generics without NS and cleanEx()
In-Reply-To: <Pine.LNX.4.64.0602150939260.19834@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0602150954340.20143@artemis.imbe.med.uni-erlangen.de>
	<Pine.LNX.4.64.0602150929130.19834@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602150939260.19834@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602151051200.26571@artemis.imbe.med.uni-erlangen.de>


On Wed, 15 Feb 2006, Prof Brian Ripley wrote:

> Follow up:
>
> You said
>
>>> which is exported in party's namespace
>>>
>>>     S3method(sctest, mob)
>
> but that's not true: it is registered not exported.  You need to export it
> as strucchange does not have a namespace.
>

 	export(sctest.mob)

instead of

 	S3method(sctest, mob)

fixes the problem. Thanks!

Torsten

>
> On Wed, 15 Feb 2006, Prof Brian Ripley wrote:
>
>> Torsten,
>>
>> The error is that .__S3MethodsTable__. ends up in the global environment.
>> Are you importing sctest (I can't see it)?  I think that's the problem.
>>
>>> From R-exts:
>>
>> The standard method for S3-style @code{UseMethod} dispatching might fail
>> to locate methods defined in a package that is imported but not attached
>> to the search path.  To ensure that these methods are available the
>> packages defining the methods should ensure that the generics are
>> imported and register the methods using @code{S3method} directives.
>> ^^^^^^^^
>>
>> Brian
>>
>> On Wed, 15 Feb 2006, Torsten Hothorn wrote:
>>
>>>
>>> Good morning,
>>>
>>> we recently observed a problem with importing S3 generics from a foreign
>>> package (without namespace), defining a S3 method in a package _with_
>>> namespace and the `cleanEx()' function which is automatically generated
>>> and executed before examples are run by R CMD check.
>>>
>>> To be more precise. Package `strucchange' defines a S3 generic
>>>
>>>     sctest <- function(x, ...) UseMethod("sctest")
>>>
>>> and the development version of `party' defines
>>>
>>>     sctest.mob <- function(x, node = NULL, ...) {
>>>         ...
>>>
>>> which is exported in party's namespace
>>>
>>>     S3method(sctest, mob)
>>>
>>> Creating a `mob' object and running `sctest' on it works fine.
>>>
>>> However, when we attach `party' and run `cleanEx()', the `sctest' method
>>> for `mob' is no longer found. Before `cleanEx()' we get
>>>
>>> R> methods(sctest)
>>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>>> sctest.mob*
>>>
>>> and afterwards
>>>
>>> R> methods(sctest)
>>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>>>
>>> is missing.
>>>
>>> Debugging `cleanEx()' shows that those objects are removed from the
>>> global environment:
>>>
>>> ls(envir = env, all.names = TRUE)
>>> [1] ".Random.seed"         ".__S3MethodsTable__." "GCtorture"
>>> [4] "a"                    "euro"
>>>
>>> where the second one looks very suspicious.
>>>
>>> `party_0.4-0.tar.gz' is available from
>>>
>>>     http://www.imbe.med.uni-erlangen.de/~hothorn/party_0.4-0.tar.gz
>>>
>>> and
>>>
>>>     http://www.imbe.med.uni-erlangen.de/~hothorn/modeltools_0.2-3.tar.gz
>>>
>>> is required.
>>>
>>> The example below can be reproduced with both R-2.2.1 and R-2.3.0.
>>>
>>> Best wishes,
>>>
>>> Torsten
>>>
>>>
>>>
>>> R> invisible(options(echo = TRUE))
>>> R> ### * <HEADER>
>>> R> ###
>>> R> attach(NULL, name = "CheckExEnv")
>>> R> assign(".CheckExEnv", as.environment(2), pos = length(search())) # base
>>> R> ## add some hooks to label plot pages for base and grid graphics
>>> R> setHook("plot.new", ".newplot.hook")
>>> R> setHook("persp", ".newplot.hook")
>>> R> setHook("grid.newpage", ".gridplot.hook")
>>> R>
>>> R> assign("cleanEx",
>>> +        function(env = .GlobalEnv) {
>>> + 	   rm(list = ls(envir = env, all.names = TRUE), envir = env)
>>> +            RNGkind("default", "default")
>>> + 	   set.seed(1)
>>> +    	   options(warn = 1)
>>> + 	   delayedAssign("T", stop("T used instead of TRUE"),
>>> + 		  assign.env = .CheckExEnv)
>>> + 	   delayedAssign("F", stop("F used instead of FALSE"),
>>> + 		  assign.env = .CheckExEnv)
>>> + 	   sch <- search()
>>> + 	   newitems <- sch[! sch %in% .oldSearch]
>>> + 	   for(item in rev(newitems))
>>> +                eval(substitute(detach(item), list(item=item)))
>>> + 	   missitems <- .oldSearch[! .oldSearch %in% sch]
>>> + 	   if(length(missitems))
>>> + 	       warning("items ", paste(missitems, collapse=", "),
>>> + 		       " have been removed from the search path")
>>> +        },
>>> +        env = .CheckExEnv)
>>> R> assign("..nameEx", "__{must remake R-ex/*.R}__", env = .CheckExEnv) # for now
>>> R> assign("ptime", proc.time(), env = .CheckExEnv)
>>> R> grDevices::postscript("party-Ex.ps")
>>> R> assign("par.postscript", graphics::par(no.readonly = TRUE), env = .CheckExEnv)
>>> R> options(contrasts = c(unordered = "contr.treatment", ordered = "contr.poly"))
>>> R> options(warn = 1)
>>> R> library('party')
>>> Loading required package: survival
>>> Loading required package: splines
>>> Loading required package: grid
>>> Loading required package: modeltools
>>> Loading required package: coin
>>> Loading required package: mvtnorm
>>> Loading required package: zoo
>>> Loading required package: sandwich
>>> Loading required package: strucchange
>>> R>
>>> R> methods(sctest)
>>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp    sctest.mob*
>>>
>>>    Non-visible functions are asterisked
>>> R>
>>> R> assign(".oldSearch", search(), env = .CheckExEnv)
>>> R> assign(".oldNS", loadedNamespaces(), env = .CheckExEnv)
>>> R> cleanEx(); ..nameEx <- "BinaryTree-class"
>>> R>
>>> R> methods(sctest)
>>> [1] sctest.Fstats  sctest.efp     sctest.formula sctest.gefp
>>> R>
>>> R>
>>> R> proc.time()
>>> [1] 1.77 0.01 1.97 0.00 0.00
>>> R>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From jonvaz at stud.ibg.uit.no  Wed Feb 15 12:04:16 2006
From: jonvaz at stud.ibg.uit.no (jonvaz@stud.ibg.uit.no)
Date: Wed, 15 Feb 2006 11:04:16 GMT
Subject: [Rd] [R] repeated measurements and lme
Message-ID: <200602151100.k1FB0I9d001870@morgan.ibg.uit.no>

I am trying to do a repeated measurement anova using an lme. I have the
    following variables:
    -ID, the identification of the individual
    -trail, with 2 levels
    -treatment, with 3
    -time, measure 5 times the same individual
    -VCL, the response variable
    I tried the following in R,
    within.gr<-groupedData(VCL~time|ID/treatment/time,data=within)
    summary(lme(fixed=VCL~time*treatment,random=~1,data=within.gr))
    I am not sure if it is correct at all. Can anyone help me? It will be very
    helpful.
    Sincerely,
    Jonathan
   
Vaz

---------------------------------------------
This message was sent using Endymion MailMan.
http://www.endymion.com/products/mailman/


From ripley at stats.ox.ac.uk  Wed Feb 15 13:05:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Feb 2006 12:05:35 +0000 (GMT)
Subject: [Rd] [R] repeated measurements and lme
In-Reply-To: <200602151100.k1FB0I9d001870@morgan.ibg.uit.no>
References: <200602151100.k1FB0I9d001870@morgan.ibg.uit.no>
Message-ID: <Pine.LNX.4.64.0602151202270.22746@gannet.stats.ox.ac.uk>

Please do not post to multiple lists.  In this case R-help was more 
appropriate, but studying the posting guide was even more appropriate 
since you have not given enough information and the question is really 
statistical consulting not R.

On Wed, 15 Feb 2006, jonvaz at stud.ibg.uit.no wrote:

> I am trying to do a repeated measurement anova using an lme. I have the
>    following variables:
>    -ID, the identification of the individual
>    -trail, with 2 levels
>    -treatment, with 3
>    -time, measure 5 times the same individual
>    -VCL, the response variable
>    I tried the following in R,
>    within.gr<-groupedData(VCL~time|ID/treatment/time,data=within)
>    summary(lme(fixed=VCL~time*treatment,random=~1,data=within.gr))
>    I am not sure if it is correct at all. Can anyone help me? It will be very
>    helpful.
>    Sincerely,
>    Jonathan
>
> Vaz

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From drego.student at manhattan.edu  Thu Feb 16 02:46:34 2006
From: drego.student at manhattan.edu (drego.student@manhattan.edu)
Date: Thu, 16 Feb 2006 02:46:34 +0100 (CET)
Subject: [Rd] Not working with intel macs (PR#8608)
Message-ID: <20060216014634.130A5364C3@slim.kubism.ku.dk>

Full_Name: Dina Rego
Version: R Cocoa GUI 1.14
OS: Intel Mac 10.4.4
Submission from: (NULL) (24.199.98.228)


I recently bought the new intel imac and every program I had on my old computer
(shareware and all) works on my new computer except R.  When you double click
it, it seems like it's going to launch (it does that box rushing to the screen
thing) but nothing happens.  I need this program for class!! Please update
soon!!!


From khansen at stat.Berkeley.EDU  Thu Feb 16 02:58:05 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Wed, 15 Feb 2006 17:58:05 -0800
Subject: [Rd] Not working with intel macs (PR#8608)
In-Reply-To: <20060216014634.130A5364C3@slim.kubism.ku.dk>
References: <20060216014634.130A5364C3@slim.kubism.ku.dk>
Message-ID: <167671E4-FF38-4E3A-997C-32742857A0BA@stat.berkeley.edu>

Please read the R-sig-mac list (the list for special interest in R on  
Macs) for a discussion of universal binaries on the Mac Intel platform.

/Kasper

On Feb 15, 2006, at 5:46 PM, drego.student at manhattan.edu wrote:

> Full_Name: Dina Rego
> Version: R Cocoa GUI 1.14
> OS: Intel Mac 10.4.4
> Submission from: (NULL) (24.199.98.228)
>
>
> I recently bought the new intel imac and every program I had on my  
> old computer
> (shareware and all) works on my new computer except R.  When you  
> double click
> it, it seems like it's going to launch (it does that box rushing to  
> the screen
> thing) but nothing happens.  I need this program for class!! Please  
> update
> soon!!!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jago at mclink.it  Thu Feb 16 09:39:47 2006
From: jago at mclink.it (stefano iacus)
Date: Thu, 16 Feb 2006 09:39:47 +0100
Subject: [Rd] Not working with intel macs (PR#8608)
In-Reply-To: <20060216014634.130A5364C3@slim.kubism.ku.dk>
References: <20060216014634.130A5364C3@slim.kubism.ku.dk>
Message-ID: <1181A084-FE23-4CF7-9C62-5AC62EB508A5@mclink.it>

Please send the output of the crash.log (you can find it via  
console.app).
R.app is supposed to run under rosetta as well.
Btw, we are about to release a Universal Binary of R.app.
Please read R-Sig-Mac and don't send msgs to R-bugs.
stefano

Il giorno 16/feb/06, alle ore 02:46, drego.student at manhattan.edu ha  
scritto:

> Full_Name: Dina Rego
> Version: R Cocoa GUI 1.14
> OS: Intel Mac 10.4.4
> Submission from: (NULL) (24.199.98.228)
>
>
> I recently bought the new intel imac and every program I had on my  
> old computer
> (shareware and all) works on my new computer except R.  When you  
> double click
> it, it seems like it's going to launch (it does that box rushing to  
> the screen
> thing) but nothing happens.  I need this program for class!! Please  
> update
> soon!!!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gchappi at gmail.com  Thu Feb 16 09:55:57 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Thu, 16 Feb 2006 09:55:57 +0100
Subject: [Rd] Rf_errorcall - translate to Pascal
Message-ID: <47fce0650602160055y33a4c253r@mail.gmail.com>

Hello!

I (try to) convert the external R header files to Pascal (Delphi). At
one place I stumbled over a macro that uses a method that is not
declared in a LGPL header file:

In Rinternals.h:
   #define error_return(msg)	{ Rf_error(msg); return R_NilValue; }
   #define errorcall_return(cl,msg){ Rf_errorcall(cl, msg); return R_NilValue; }
                                                  ~~~~~~~~
In Error.h:
    void Rf_error(const char *, ...);
    [Rf_errorcall is not declared here, would be something like:
     void Rf_errorcall(SEXP, const char *,...)]

Is this by purpose or would it be possible to pull the Rf_errorcall
declaration to the error.h file? It's not that I need the Rf_errorcall
function, it's more that I am a bit pedantic and like to translate the
complete thing (based on LGPL (which is more convenient in the Delphi
world) - well you might not care about this).

How is this handled in general, I mean, there might be other spots
like this. Is it appropriate to ask such questions here?

--
Regards,
Hans-Peter


From murdoch at stats.uwo.ca  Thu Feb 16 11:44:26 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 16 Feb 2006 05:44:26 -0500
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <47fce0650602160055y33a4c253r@mail.gmail.com>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
Message-ID: <43F4578A.3030201@stats.uwo.ca>

On 2/16/2006 3:55 AM, Hans-Peter wrote:
> Hello!
> 
> I (try to) convert the external R header files to Pascal (Delphi). At
> one place I stumbled over a macro that uses a method that is not
> declared in a LGPL header file:
> 
> In Rinternals.h:
>    #define error_return(msg)	{ Rf_error(msg); return R_NilValue; }
>    #define errorcall_return(cl,msg){ Rf_errorcall(cl, msg); return R_NilValue; }
>                                                   ~~~~~~~~
> In Error.h:
>     void Rf_error(const char *, ...);
>     [Rf_errorcall is not declared here, would be something like:
>      void Rf_errorcall(SEXP, const char *,...)]
> 
> Is this by purpose or would it be possible to pull the Rf_errorcall
> declaration to the error.h file? It's not that I need the Rf_errorcall
> function, it's more that I am a bit pedantic and like to translate the
> complete thing (based on LGPL (which is more convenient in the Delphi
> world) - well you might not care about this).

Just to be clear:  this is a licensing issue, not a technical issue. 
Error.h is licensed under the LGPL, but Defn.h (where Rf_errorcall is 
declared) is under the more restrictive GPL.

> How is this handled in general, I mean, there might be other spots
> like this. Is it appropriate to ask such questions here?

I think this is a reasonable forum.

My feeling would be that this is probably an oversight; the public API 
for R should be self-contained.  But I don't know if the fix is to 
change errorcall_return or to move the Rf_errorcall declaration. 
Generally things are not put in the public API if there's a feeling that 
we'd like to change them; we are much more conservative about API changes.

I think it would be helpful to know the scope of the problem.  Could you 
collect together a complete list of examples like this?

Duncan Murdoch


From gchappi at gmail.com  Thu Feb 16 11:47:43 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Thu, 16 Feb 2006 11:47:43 +0100
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <47fce0650602160055y33a4c253r@mail.gmail.com>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
Message-ID: <47fce0650602160247w58a5f770s@mail.gmail.com>

2006/2/16, Hans-Peter <gchappi at gmail.com>:
>     [Rf_errorcall is not declared here, would be something like:
>      void Rf_errorcall(SEXP, const char *,...)]
>
> ... would it be possible to pull the Rf_errorcall
> declaration to the error.h file?

error.h doesn't look like a good place as the SEXP type is not known
there. Sorry, I am quite unfluent with this c headers...

As a sidenote: in Defn.h are two macrogroups:

  /* Promise Access Macros */
  /* Hashing Macros */

which aren't declared in Rinternals.h. This is different from e.g. the groups:

  /* General Cons Cell Attributes */
  /* Primitive Access Macros */
  ...

--
Regards,
Hans-Peter


From rkrug at sun.ac.za  Thu Feb 16 11:54:24 2006
From: rkrug at sun.ac.za (Rainer M Krug)
Date: Thu, 16 Feb 2006 12:54:24 +0200
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <47fce0650602160055y33a4c253r@mail.gmail.com>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
Message-ID: <43F459E0.7060207@sun.ac.za>

Hans-Peter wrote:
> Hello!
> 
> I (try to) convert the external R header files to Pascal (Delphi). At
> one place I stumbled over a macro that uses a method that is not
.
.
.
Sounds interesting - Could you keep me updated about your progress? I 
would be interested in the header files to use them in the analysis of 
simulations from Delphi.

Rainer


-- 
--
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa

email:    RMK at krugs.de


From ripley at stats.ox.ac.uk  Thu Feb 16 13:58:37 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 12:58:37 +0000 (GMT)
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <47fce0650602160247w58a5f770s@mail.gmail.com>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
	<47fce0650602160247w58a5f770s@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602161235070.12709@gannet.stats.ox.ac.uk>

On Thu, 16 Feb 2006, Hans-Peter wrote:

> 2006/2/16, Hans-Peter <gchappi at gmail.com>:
>>     [Rf_errorcall is not declared here, would be something like:
>>      void Rf_errorcall(SEXP, const char *,...)]
>>
>> ... would it be possible to pull the Rf_errorcall
>> declaration to the error.h file?
>
> error.h doesn't look like a good place as the SEXP type is not known
> there. Sorry, I am quite unfluent with this c headers...

Yes, and their names are case-sensitive too.  So it is intentional that 
errorcall is not in R_Ext/Error.h.  Since it is needed for writing 
front-ends and now mentioned in Writing R Extensions it should probably be 
in Rinternals.h.  But note that is basically the only way that a non-core 
programmer is going to be writing code that gets passed 'call' objects.

> As a sidenote: in Defn.h are two macrogroups:
>
>  /* Promise Access Macros */
>  /* Hashing Macros */
>
> which aren't declared in Rinternals.h. This is different from e.g. the groups:
>
>  /* General Cons Cell Attributes */
>  /* Primitive Access Macros */
>  ...

This is intentional.  Both Defn.h and Rinternals.h have these in a section 
protected by

#ifdef USE_RINTERNALS
#endif

and that section should not be regarded as public.  There _are_ 
(mis-titled) sections

/* Promise Access Macros */
/* Hashing Macros */

in Rinternals.h, and those are the function equivalents defined for 
external use.

All that is public is what is documented in `Writing R Extensions': other 
things are in the header files but you should not assume that they will 
even be exported in future versions of R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From afinley at stat.umn.edu  Thu Feb 16 14:59:08 2006
From: afinley at stat.umn.edu (Andrew Finley)
Date: Thu, 16 Feb 2006 07:59:08 CST
Subject: [Rd] Calling R functions from C and setting function's formal list
	values
Message-ID: <200602161359.k1GDx8wB014854@vanguard.software.umn.edu>

Hello,
I am writing an extension that requires the user to pass a function into
the C code. The function returns a covariance matrix. The user defines an
arbitrary set of parameters as the function's arguments, which are used to
construct this covariance matrix.  Within the C code these parameters and
hence covariance matrix are iteratively updated.

The user's function might look like this:

cov.function <- function(sigmasq, tausq, phi){
  sigmasq*exp(-phi*D) + tausq*diag(n)
}

The way my C code is now, the iteratively proposed values for the cov.fun
parameters are in the same order as the parameters used in the cov.fun
function (i.e., same order as the formal list).  So what I'd like to do is
just set the value portion of the tags in the cov.fun formal list, then
just call the function using its newly set defaults at the values to be
passed in.

This way might look is:

for(i = 0; i < iters; i++){
  //proposed new values for cov.fun parameters and set them as the
function's
  //default arg. values

  //call the function and collect the returned matrix
  PROTECT(RFnCall = lang1(CovFn));
  PROTECT(fnCov = eval(RFnCall, env));

}

My question is, does this seem reasonable?  And if so, how do I set the
value portion of the formal's list tags.  Also, is the formal list a
LISTSXP.  I have read the sections on 'Evaluating R expression from C' in
the docs. But the idea of setting the argument defaults then just calling
the function is a bit different.

Thanks for your time-
Andy


Research Fellow
Department of Forest Resources
University of Minnesota
Office: 305 Green Hall
Phone: (612) 624-1714
Fax: (612) 625-5212
web: http://blue.fr.umn.edu


From gchappi at gmail.com  Thu Feb 16 17:37:56 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Thu, 16 Feb 2006 17:37:56 +0100
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <Pine.LNX.4.64.0602161235070.12709@gannet.stats.ox.ac.uk>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
	<47fce0650602160247w58a5f770s@mail.gmail.com>
	<Pine.LNX.4.64.0602161235070.12709@gannet.stats.ox.ac.uk>
Message-ID: <47fce0650602160837g259799ar@mail.gmail.com>

Hello!

Thanks for your answers!

---
2006/2/16, Duncan Murdoch <murdoch at stats.uwo.ca>:
> I think it would be helpful to know the scope of the problem.  Could you
> collect together a complete list of examples like this?

yes, I will do that. Until now it's only the one function mentioned
and the 2 macro groups.
Btw: your Delphi notes were great to get me started !!!

---
2006/2/16, Rainer M Krug <rkrug at sun.ac.za>:
> Hans-Peter wrote:
> > I (try to) convert the external R header files to Pascal (Delphi). At
> Sounds interesting - Could you keep me updated about your progress? I
> would be interested in the header files to use them in the analysis of
> simulations from Delphi.

Sure, but I cannot promise anything. I did the same for Matlab but
it's much more difficult with R.

---
2006/2/16, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> Yes, and their names are case-sensitive too.  So it is intentional that
> errorcall is not in R_Ext/Error.h.  Since it is needed for writing
> front-ends and now mentioned in Writing R Extensions it should probably be
> in Rinternals.h.

that would be great!

>But note that is basically the only way that a non-core
> programmer is going to be writing code that gets passed 'call' objects.

ok, thanks

> > As a sidenote: in Defn.h are two macrogroups:
> This is intentional.  Both Defn.h and Rinternals.h have these in a section
> protected by
> #ifdef USE_RINTERNALS
> #endif
> and that section should not be regarded as public.

I know that USE_RINTERNALS is ...internal and can change. But I had to
translate it nevertheless, because I need at least the type definition
"SEXP". And e.g. in chapter "4.8.2 Calling .External" there are code
samples with the macros CADR, TYPEOF, CHAR, STRING_ELT, ... which
AFAIK can run in Pascal only if they are redefined as pascal
functions. Regarding the possible changes I have to think about DUnit
tests to catch them.

>There _are_ (mis-titled) sections
> /* Promise Access Macros */
> /* Hashing Macros */
> in Rinternals.h, and those are the function equivalents defined for
> external use.

Sorry, I don't understand. Eg. in Rinternals.h the first entry in /*
Promise Access Macros */ is:   SEXP (PRCODE)(SEXP x);
                 ~~~~~~~
Do you now mean, that the macro PRCODE is defined for external use? 
On the other hand, it's nowhere in the "writing R extensions
documentation". But it's e.g. used in the library methods (in the
function: methods-List_dispatch.c).

If its meant for external use, then AFAIK the only way to use this
macro in Pascal code is to translate it as a function, like e.g.:

  function rhPrcode( _x: pSexp ): pSexp;
    begin
      result:= _x.promsxp.expr;
    end;

<license related>
And now it's a bit unnice, that "_x.promsxp.expr" is defined in Defn.h
[as: ((x)->u.promsxp.expr)] and not in Rinternal.h. With almost all
other macros, e.g. FORMALS this is different, they are defined in
Rinternal.h [e.g.: ((x)->u.closxp.formals)]. In this macro case I
think its also for strict license interpretations irrelevant, because
SEXPREC and promsxp_struct are fully declared in Rinternal.h. But it's
not nice and maybe I just skip it.
</license related>


--
Regards,
Hans-Peter


From ripley at stats.ox.ac.uk  Thu Feb 16 18:20:47 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 17:20:47 +0000 (GMT)
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <47fce0650602160837g259799ar@mail.gmail.com>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
	<47fce0650602160247w58a5f770s@mail.gmail.com>
	<Pine.LNX.4.64.0602161235070.12709@gannet.stats.ox.ac.uk>
	<47fce0650602160837g259799ar@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602161708580.16122@gannet.stats.ox.ac.uk>

On Thu, 16 Feb 2006, Hans-Peter wrote:

> Hello!
>
> Thanks for your answers!
>
> ---
> 2006/2/16, Duncan Murdoch <murdoch at stats.uwo.ca>:
>> I think it would be helpful to know the scope of the problem.  Could you
>> collect together a complete list of examples like this?
>
> yes, I will do that. Until now it's only the one function mentioned
> and the 2 macro groups.
> Btw: your Delphi notes were great to get me started !!!
>
> ---
> 2006/2/16, Rainer M Krug <rkrug at sun.ac.za>:
>> Hans-Peter wrote:
>>> I (try to) convert the external R header files to Pascal (Delphi). At
>> Sounds interesting - Could you keep me updated about your progress? I
>> would be interested in the header files to use them in the analysis of
>> simulations from Delphi.
>
> Sure, but I cannot promise anything. I did the same for Matlab but
> it's much more difficult with R.
>
> ---
> 2006/2/16, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>> Yes, and their names are case-sensitive too.  So it is intentional that
>> errorcall is not in R_Ext/Error.h.  Since it is needed for writing
>> front-ends and now mentioned in Writing R Extensions it should probably be
>> in Rinternals.h.
>
> that would be great!
>
>> But note that is basically the only way that a non-core
>> programmer is going to be writing code that gets passed 'call' objects.
>
> ok, thanks
>
>>> As a sidenote: in Defn.h are two macrogroups:
>> This is intentional.  Both Defn.h and Rinternals.h have these in a section
>> protected by
>> #ifdef USE_RINTERNALS
>> #endif
>> and that section should not be regarded as public.
>
> I know that USE_RINTERNALS is ...internal and can change.

It is for use only inside R itself: see the comments in Defn.h.

> But I had to translate it nevertheless, because I need at least the type 
> definition "SEXP".

Which is not inside #ifdef USE_RINTERNALS.

> And e.g. in chapter "4.8.2 Calling .External" there are code
> samples with the macros CADR, TYPEOF, CHAR, STRING_ELT, ... which

Those are not macros, but function calls.

> AFAIK can run in Pascal only if they are redefined as pascal
> functions. Regarding the possible changes I have to think about DUnit
> tests to catch them.
>
>> There _are_ (mis-titled) sections
>> /* Promise Access Macros */
>> /* Hashing Macros */
>> in Rinternals.h, and those are the function equivalents defined for
>> external use.
>
> Sorry, I don't understand. Eg. in Rinternals.h the first entry in /*
> Promise Access Macros */ is:   SEXP (PRCODE)(SEXP x);

That's not a macro (macros in C start #define).  It is a definition of a 
function call.  And R.dll exports a function entry point PRCODE.

> Do you now mean, that the macro PRCODE is defined for external use?
> On the other hand, it's nowhere in the "writing R extensions
> documentation". But it's e.g. used in the library methods (in the
> function: methods-List_dispatch.c).

It is not part of the API, and the methods package imports the PRCODE 
function.  It does not use the PRCODE macro.  However, do note that the 
standard packages which ship with R are regarded as part of R and have 
privileges other packages do not have.  (One is to use Defn.h.)

I realize you may be unfamiliar with C terminology, but you do definitely 
seem to be misreadling Rinternals.h.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gchappi at gmail.com  Thu Feb 16 19:38:56 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Thu, 16 Feb 2006 19:38:56 +0100
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <Pine.LNX.4.64.0602161708580.16122@gannet.stats.ox.ac.uk>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
	<47fce0650602160247w58a5f770s@mail.gmail.com>
	<Pine.LNX.4.64.0602161235070.12709@gannet.stats.ox.ac.uk>
	<47fce0650602160837g259799ar@mail.gmail.com>
	<Pine.LNX.4.64.0602161708580.16122@gannet.stats.ox.ac.uk>
Message-ID: <47fce0650602161038r783d84bfp@mail.gmail.com>

2006/2/16, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> I realize you may be unfamiliar with C terminology, but you do definitely
> seem to be misreadling Rinternals.h.

Thanks for your helpful comments, I think I have understood now.

I won't use the internal structures (but it's nevertheless nice to be
able to and I've seen in the debugger the correct information is
there).

--
Regards,
Hans-Peter


From kwright68 at gmail.com  Thu Feb 16 22:25:57 2006
From: kwright68 at gmail.com (Kevin Wright)
Date: Thu, 16 Feb 2006 15:25:57 -0600
Subject: [Rd] Could heatmap default to scale="none" ?
Message-ID: <adf71a630602161325p17a92220p4774012ac5e7a33d@mail.gmail.com>

(I have searched the email archives for discussions on this topic but
have found nothing.)

The help page for heatmap says:
By default (scale = "row") the rows are scaled to have mean zero and
standard deviation one. There is some empirical evidence from genomic
plotting that this is useful.

I offer two comments on that.

1. Since the heatmap function is general-purpose (that is, not in a
genomics package), wouldn't it be better to just use no scaling?

2. Why assume that the rows should be scaled instead of the columns? 
There appears to be an assumption on the structure of the data.  Is
this assumption really warranted for a general-purpose function?

For the data I'm analyzing, scaling has hidden a great deal of
structure and I've just had to re-do many hours of work because I
didn't thoroughly read the help page and was not expecting the
scaling.  Further, given the structure of my data I did try (manually)
centering (not scaling) the COLUMNS, not the rows.

The heatmap.2 function in the gplots package defaults to scale="none"
and I argue that it would be better for the heatmap function to do the
same.

Kevin Wright


From kwright68 at gmail.com  Fri Feb 17 00:04:49 2006
From: kwright68 at gmail.com (kwright68@gmail.com)
Date: Fri, 17 Feb 2006 00:04:49 +0100 (CET)
Subject: [Rd] Heatmap documentation (scale argument) (PR#8614)
Message-ID: <20060216230449.142E2C76D@slim.kubism.ku.dk>

Full_Name: Kevin Wright
Version: 2.2.1
OS: Windows 2000
Submission from: (NULL) (170.54.58.4)



The help page for heatmap says this about the scale argument:

scale 	character indicating if the values should be centered and scaled in
either the row direction or the column direction, or none. The default is "row"
if symm false, and "none" otherwise.

This is true, but not completely accurate IMHO.  In particular, 'scale' has no
effect on the dendrograms, since the dendrograms are calculated before any
scaling is done.  The scale argument only affects the colors used in the 'image'
part of the heatmap.

Consider:
  x  <- as.matrix(mtcars)
  heatmap(x, scale="column")
  heatmap(scale(x), scale="none")
Those two plots give different dendrograms.

It would be nice for the documentation to make this more clear.  For example:

"scaling affects only the 'image' part of the heatmap and has no effect on the
dendgrograms".


From aorchid at mac.com  Fri Feb 17 01:41:52 2006
From: aorchid at mac.com (Aric Gregson)
Date: Thu, 16 Feb 2006 16:41:52 -0800
Subject: [Rd] Unable to configure R 2.2.1 on Solaris 5.10 x86_64
Message-ID: <20060216164152.00005dc5@unknown>

Hello,

Apologies for the post here. I have read the R-Admin (learned
a lot!) and searched the web for days, but still fail at compiling R on
my machine. This is the tail of './configure' output:
.....
checking for dlopen in -ldl... yes
checking readline/history.h usability... no
checking readline/history.h presence... no
checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... no
checking for main in -ltermcap... yes
checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and headers/libs are
not available 

My R-2.2.1/config.site has the following changes from default:

CC="cc -xtarget=opteron -xarch=amd64"
CFLAGS="-xO5 -xlibmil -dalign"
CPPFLAGS=-I/opt/sfw/include -I/opt/sfw/include/readline \
-I/opt/csw/include -I/opt/SUNWspro/include -I/opt/csw/include/readline
F77="f95 -xarch=amd64 -xtarget=opteron"
FFLAGS="-xO5 -xlibmil -dalign"
LDFLAGS=-L/opt/SUNWspro/lib/amd64/ -L/opt/sfw/lib -L/opt/csw/lib
CXX="CC -xarch=amd64 -xtarget=opteron"
CXXFLAGS="-xO5 -xlibmil -dalign"
R_BROWSER=mozilla
MAKE=gmake

My .zshrc file has the following (as I saw that some of the LDFLAGS
should match my LD_LIBRARY_PATH and CONFIG_SHELL=/bin/ksh):

LD_LIBRARY_PATH=/opt/sfw/include:/opt/sfw/include/readline:/usr/local/lib:/usr/X/lib:/usr/lib:/usr/ucblib:/lib:/usr/ccs/lib:/etc/lib:/usr/dt/lib:/opt/SUNWspro/lib/amd64/:/opt/sfw/lib:/opt/csw/lib

Readline (version 4.2 from the Sun Companion CD) is located
in /opt/sfw/include/readline. Both the readline.h and history.h files
are there. Version 5.0 is located in /opt/csw/include/readline (from
Blastwave). As you can see, I am new at compiling in generally and
solaris specifically. Any help would be greatly appreciated.

System information:

System = SunOS
Node = unknown
Release = 5.10
KernelID = Generic_118844-26
Machine = i86pc
OEM# = 0
Origin# = 1
NumCPU = 1

thanks,

aric


From ripley at stats.ox.ac.uk  Fri Feb 17 18:23:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Feb 2006 17:23:40 +0000 (GMT)
Subject: [Rd] Rf_errorcall - translate to Pascal
In-Reply-To: <47fce0650602161038r783d84bfp@mail.gmail.com>
References: <47fce0650602160055y33a4c253r@mail.gmail.com>
	<47fce0650602160247w58a5f770s@mail.gmail.com>
	<Pine.LNX.4.64.0602161235070.12709@gannet.stats.ox.ac.uk>
	<47fce0650602160837g259799ar@mail.gmail.com>
	<Pine.LNX.4.64.0602161708580.16122@gannet.stats.ox.ac.uk>
	<47fce0650602161038r783d84bfp@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602171719360.31301@gannet.stats.ox.ac.uk>

I've made some changes in R-devel, so errorcall is now defined there and 
it is clear what is a macro and what is a function and which are both.

I looked in the 'primitive access' functions/macros.  It is clear that all 
these could be used for was to access the internal table of builtins, and 
that is no longer exported (and was never intended to be used outside base 
R), so I've moved those back to Defn.h.

On Thu, 16 Feb 2006, Hans-Peter wrote:

> 2006/2/16, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>> I realize you may be unfamiliar with C terminology, but you do definitely
>> seem to be misreadling Rinternals.h.
>
> Thanks for your helpful comments, I think I have understood now.
>
> I won't use the internal structures (but it's nevertheless nice to be
> able to and I've seen in the debugger the correct information is
> there).
>
> --
> Regards,
> Hans-Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From efg at stowers-institute.org  Fri Feb 17 20:34:15 2006
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Fri, 17 Feb 2006 13:34:15 -0600
Subject: [Rd] Could heatmap default to scale="none" ?
References: <adf71a630602161325p17a92220p4774012ac5e7a33d@mail.gmail.com>
Message-ID: <dt58fr$3fn$1@sea.gmane.org>

"Kevin Wright" <kwright68 at gmail.com> wrote in message
news:adf71a630602161325p17a92220p4774012ac5e7a33d at mail.gmail.com...
> (I have searched the email archives for discussions on this topic but
> have found nothing.)
> 1. Since the heatmap function is general-purpose (that is, not in a
> genomics package), wouldn't it be better to just use no scaling?
>
> 2. Why assume that the rows should be scaled instead of the columns?
> There appears to be an assumption on the structure of the data.  Is
> this assumption really warranted for a general-purpose function?
. . .
> The heatmap.2 function in the gplots package defaults to scale="none"
> and I argue that it would be better for the heatmap function to do the
> same.

I second this recommendation for exactly the same reasons.
Last week I spent an hour or so trying to figure out why the heatmap colors
for the same number were different across several related heatmaps. Turning
the scaling off removed the surprise color differences.  I will always want
scale="none" as my default and now must remember to always specify it.

If the default is not changed, I think a WARNING should be included in the
documentation about this.

efg


From murdoch at stats.uwo.ca  Sat Feb 18 16:41:06 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 18 Feb 2006 10:41:06 -0500
Subject: [Rd] Floating point control (was: [R] Variance for Vector of
 Constants is STILL Not Zero)
In-Reply-To: <43F69D1E.6070107@stats.uwo.ca>
References: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
	<43F69D1E.6070107@stats.uwo.ca>
Message-ID: <43F74012.3090106@stats.uwo.ca>

Over on R-help, the old problem of floating point precision has come up 
again (see my example below, where calling RSiteSearch can change the 
results of the var() function).

The problem here is that on Windows many DLLs set the precision of the 
fpu to 53 bit mantissas, whereas R normally uses 64 bit mantissas. 
(Some Microsoft docs refer to these as 64 bit and 80 bit precision 
respectively, because they count the sign and exponent bits too).

When R calls out to the system, if one of these DLLs gets control, it 
may change the precision and not change it back.  This can happen for 
example in calls to display a file dialog or anything else where a DLL 
can set a hook; it's very hard to predict.

I consider this to be very poor programming; DLLs shouldn't 
unnecessarily change the operating environment of their caller. 
However, it's something we've got to live with.

Currently R itself sets the FPU precision to 64 bit mantissas when it 
starts and preserves it across dyn.load calls.  I think we need to be 
more aggressive about protecting the precision.  Specifically, in any 
case where we know we are directly calling an external function we 
should protect the precision across the call.

A problem is that the C runtime library also makes calls to system 
functions, so some of those calls are probably risky too.  It's not 
reasonable to protect all C library calls, but I think we should fairly 
aggressively test for changes, fix them, and optionally report them.

Another problem is that R itself is used as a DLL.  Should it set the 
precision to 64 bit mantissas, or try to maintain whatever precision the 
caller gave it?  I'd lean towards documenting a requirement for 64 bit 
precision on entry and documenting that we may change the precision to 
64 bits.

Yet another problem is that Microsoft's .NET only supports 53 bit 
precision, according to some documentation I've read.  Do we need to 
interoperate with .NET?

I don't know if this is a Windows-only problem, or if it occurs on any 
other systems, but I think the only way to know is to add the tests on 
all systems.

I'd like to suggest the following:

  - We add R level functions to get and set the floating point control bits.

  - We save the value that is set, and work aggressively to make sure it 
doesn't get changed by other mechanisms, with debugging options to 
report all unexpected changes.

I don't know how portable any of this will be.  Is the _controlfp() 
function standard C, or is it only available on some of our platforms?

Duncan Murdoch

On 2/17/2006 11:05 PM, Duncan Murdoch wrote:

> My guess is that you've got a video driver or some other software that's 
> messing with your floating point processor, reducing the precision from 
> 64 bit to 53 or less.  I can reproduce the error after running 
> RSiteSearch, which messes with my fpu in that way:
> 
>  > var(rep(0.2, 100))
> [1] 0
>  > RSiteSearch('fpu')
> A search query has been submitted to http://search.r-project.org
> The results page should open in your browser shortly
>  > var(rep(0.2, 100))
> [1] 1.525181e-31
> 
> (I'm not blaming RSiteSearch for doing something bad, it's the system 
> DLLs that it calls that are at fault.)
> 
> I think this is something we should address, but it's not easy.


From ripley at stats.ox.ac.uk  Sat Feb 18 16:53:41 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 18 Feb 2006 15:53:41 +0000 (GMT)
Subject: [Rd] Floating point control (was: [R] Variance for Vector of
 Constants is STILL Not Zero)
In-Reply-To: <43F74012.3090106@stats.uwo.ca>
References: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
	<43F69D1E.6070107@stats.uwo.ca> <43F74012.3090106@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0602181544270.4244@gannet.stats.ox.ac.uk>

I believe this to be a Windows-only problem.  Setting the FPU control is 
OS x CPU specific (e.g. Solaris and FreeBSD do it differently on Sparc and 
ix86), and may well not be allowed for user processes.

But we should be more aggressive about combating it on Windows.

On Sat, 18 Feb 2006, Duncan Murdoch wrote:

> Over on R-help, the old problem of floating point precision has come up
> again (see my example below, where calling RSiteSearch can change the
> results of the var() function).
>
> The problem here is that on Windows many DLLs set the precision of the
> fpu to 53 bit mantissas, whereas R normally uses 64 bit mantissas.
> (Some Microsoft docs refer to these as 64 bit and 80 bit precision
> respectively, because they count the sign and exponent bits too).

(I have a solution to that in place in R-devel.  As some other chips, e.g. 
Sparc, are more strictly IEC60559 compliant, we should and now do achieve 
full accuracy on chips with an effective 53-bit mantissa ('effective' 
since the top bit is not actually stored).)

> When R calls out to the system, if one of these DLLs gets control, it
> may change the precision and not change it back.  This can happen for
> example in calls to display a file dialog or anything else where a DLL
> can set a hook; it's very hard to predict.
>
> I consider this to be very poor programming; DLLs shouldn't
> unnecessarily change the operating environment of their caller.
> However, it's something we've got to live with.
>
> Currently R itself sets the FPU precision to 64 bit mantissas when it
> starts and preserves it across dyn.load calls.  I think we need to be
> more aggressive about protecting the precision.  Specifically, in any
> case where we know we are directly calling an external function we
> should protect the precision across the call.
>
> A problem is that the C runtime library also makes calls to system
> functions, so some of those calls are probably risky too.  It's not
> reasonable to protect all C library calls, but I think we should fairly
> aggressively test for changes, fix them, and optionally report them.
>
> Another problem is that R itself is used as a DLL.  Should it set the
> precision to 64 bit mantissas, or try to maintain whatever precision the
> caller gave it?  I'd lean towards documenting a requirement for 64 bit
> precision on entry and documenting that we may change the precision to
> 64 bits.
>
> Yet another problem is that Microsoft's .NET only supports 53 bit
> precision, according to some documentation I've read.  Do we need to
> interoperate with .NET?
>
> I don't know if this is a Windows-only problem, or if it occurs on any
> other systems, but I think the only way to know is to add the tests on
> all systems.
>
> I'd like to suggest the following:
>
>  - We add R level functions to get and set the floating point control bits.
>
>  - We save the value that is set, and work aggressively to make sure it
> doesn't get changed by other mechanisms, with debugging options to
> report all unexpected changes.
>
> I don't know how portable any of this will be.  Is the _controlfp()
> function standard C, or is it only available on some of our platforms?
>
> Duncan Murdoch
>
> On 2/17/2006 11:05 PM, Duncan Murdoch wrote:
>
>> My guess is that you've got a video driver or some other software that's
>> messing with your floating point processor, reducing the precision from
>> 64 bit to 53 or less.  I can reproduce the error after running
>> RSiteSearch, which messes with my fpu in that way:
>>
>> > var(rep(0.2, 100))
>> [1] 0
>> > RSiteSearch('fpu')
>> A search query has been submitted to http://search.r-project.org
>> The results page should open in your browser shortly
>> > var(rep(0.2, 100))
>> [1] 1.525181e-31
>>
>> (I'm not blaming RSiteSearch for doing something bad, it's the system
>> DLLs that it calls that are at fault.)
>>
>> I think this is something we should address, but it's not easy.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at maths.lth.se  Sat Feb 18 20:33:49 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 18 Feb 2006 20:33:49 +0100
Subject: [Rd] file.info() on WinXP/NTFS > 2Gb
Message-ID: <59d7961d0602181133r2e22ccechdafb31aaf8e85b47@mail.gmail.com>

Hi,

on WinXP Pro SP2 with NTFS, I noticed that file.info() under
Rv2.2.1pat (2006-02-09) does not report the correct file size if the
file is >= 2^31 bytes (2GB).   Is this problem known?  Is this related
to the note in ?file.info:

"Some (broken) systems allow files of more than 2Gb to be created but
not accessed by the 'stat' system call.  Such files will show up as
non-readable (and very likely not be readable by any of R's input
functions)."

Example:

# Create a 2Gb(!) file, report file.info()$size, and remove the file.

fname <- "tmp.Rbin";
con <- file(fname, open="w+b");
size <- 2^31-1; # OK
size <- 2^31;    # Not OK
seek(con, where=size-1, rw="write");
writeBin(con=con, as.integer(0), size=1);
close(con);
print(file.info(fname)$size);
file.remove(fname);

With size = c(2^31-1,2^31), file.info() reports file size
c(2147483647,-2147483648).  This looks to me like a non-signed to
signed integer case.

Note that the above code does indeed create files >2Gb on WinXP with
NTFS; I've created files about 6Gb this way.

BTW, about seek() on Windows:  I noticed the warning about using
seek() on Windows (see ?seek): "We have found so many errors in the
Windows implementation of file positioning that users are advised to
use it only at their own risk, and asked not to waste the R
developers' time with bug reports on Windows' deficiencies.".  Not
going to bug report, but I haven't noticed any problems this far. 
What errors/symptoms are expected? Is regardless of file system used,
e.g. FAT, NTFS?

Thanks

Henrik


From murdoch at stats.uwo.ca  Sat Feb 18 20:41:37 2006
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Sat, 18 Feb 2006 20:41:37 +0100 (CET)
Subject: [Rd] Bug in Sweave? -- scoping problem? (PR#8615)
Message-ID: <20060218194137.913123F23C@slim.kubism.ku.dk>

I have found a strange scoping problem in Sweave.  The following Rnw
file doesn't produce the same output in Sweave as it does if I produce
an R file using Stangle and execute that:

\documentclass[12pt]{article}
\begin{document}
<<R>>=
election <- data.frame(A=1:3, B=9:7, C=rep(0,3))
partytotal <- rep(0, ncol(election))
for (i in 1:ncol(election)) {
      partytotal[i] <- sum(election[,i], na.rm=TRUE)
}
@

<<fig=true,width=12,height=6,echo=true>>=
names(partytotal) <- names(election)
partytotal <- sort(partytotal)
partytotal
dotchart(partytotal)
@
\end{document}

The data.frame "election" contains columns which are vote counts for 3
parties, with rows being 3 electoral districts.   The column totals are
6 for A, 24 for B, and 0 for C.  I calculate those totals in a vector
partytotal, assign the names to its entries, and then sort it.

The strange thing is that while the value in partytotal is output 
correctly as

\begin{Sinput}
  > names(partytotal) <- names(election)
  > partytotal <- sort(partytotal)
  > partytotal
\end{Sinput}
\begin{Soutput}
   C  A  B
   0  6 24
\end{Soutput}
\begin{Sinput}
  > dotchart(partytotal)
\end{Sinput}

but the dotchart contains the wrong values:  it shows sorted
values, but not sorted names, which is also what is left over in my
workspace after the Sweave call:

  > partytotal
   A  B  C
   0  6 24

These tests were run in R 2.2.1, but I see the same thing in today's 
R-devel.

Duncan Murdoch


From ArresrSpam at bellsouth.net  Sat Feb 18 21:07:30 2006
From: ArresrSpam at bellsouth.net (ArresrSpam@bellsouth.net)
Date: Sat, 18 Feb 2006 21:07:30 +0100 (CET)
Subject: [Rd] Error message while installing quatreg in ox s (PR#8616)
Message-ID: <20060218200730.7A2343F239@slim.kubism.ku.dk>

Full_Name: Alok Krishen
Version: 2.2.1
OS: OS X
Submission from: (NULL) (68.221.92.169)


When install.packages("quantreg") produces the following error message
cannot create HTML package index in: make.packages.html()


From ripley at stats.ox.ac.uk  Sat Feb 18 21:15:47 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 18 Feb 2006 20:15:47 +0000 (GMT)
Subject: [Rd] file.info() on WinXP/NTFS > 2Gb
In-Reply-To: <59d7961d0602181133r2e22ccechdafb31aaf8e85b47@mail.gmail.com>
References: <59d7961d0602181133r2e22ccechdafb31aaf8e85b47@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602181946230.10789@gannet.stats.ox.ac.uk>

On Sat, 18 Feb 2006, Henrik Bengtsson wrote:

> Hi,
>
> on WinXP Pro SP2 with NTFS, I noticed that file.info() under
> Rv2.2.1pat (2006-02-09) does not report the correct file size if the
> file is >= 2^31 bytes (2GB).   Is this problem known?  Is this related
> to the note in ?file.info:
>
> "Some (broken) systems allow files of more than 2Gb to be created but
> not accessed by the 'stat' system call.  Such files will show up as
> non-readable (and very likely not be readable by any of R's input
> functions)."

Yes, no (although I have forgotten which file system that was).  The code 
relies on the stat call.  On a modern OS this comes from POSIX and says

                   off_t         st_size;     /* total size, in bytes */

It looks the corresponding MinGW/MSVCRT type is _off_t which is long, and 
on Windows that is a 32-bit type.  This can be avoided by 
calling stati64 rather than stat: that is incorrectly documented in my 
copy of MSDN library, but I have been able to find the correct 
incantation so this will be fixed in R-devel soon.

> Example:
>
> # Create a 2Gb(!) file, report file.info()$size, and remove the file.
>
> fname <- "tmp.Rbin";
> con <- file(fname, open="w+b");
> size <- 2^31-1; # OK
> size <- 2^31;    # Not OK
> seek(con, where=size-1, rw="write");
> writeBin(con=con, as.integer(0), size=1);
> close(con);
> print(file.info(fname)$size);
> file.remove(fname);
>
> With size = c(2^31-1,2^31), file.info() reports file size
> c(2147483647,-2147483648).  This looks to me like a non-signed to
> signed integer case.
>
> Note that the above code does indeed create files >2Gb on WinXP with
> NTFS; I've created files about 6Gb this way.
>
> BTW, about seek() on Windows:  I noticed the warning about using
> seek() on Windows (see ?seek): "We have found so many errors in the
> Windows implementation of file positioning that users are advised to
> use it only at their own risk, and asked not to waste the R
> developers' time with bug reports on Windows' deficiencies.".  Not
> going to bug report, but I haven't noticed any problems this far.
> What errors/symptoms are expected? Is regardless of file system used,
> e.g. FAT, NTFS?

Look in the bug repository.  There have been issues with text files and 
with files > 2Gb, and others.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at maths.lth.se  Sat Feb 18 22:10:39 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 18 Feb 2006 22:10:39 +0100
Subject: [Rd] file.info() on WinXP/NTFS > 2Gb
In-Reply-To: <Pine.LNX.4.64.0602181946230.10789@gannet.stats.ox.ac.uk>
References: <59d7961d0602181133r2e22ccechdafb31aaf8e85b47@mail.gmail.com>
	<Pine.LNX.4.64.0602181946230.10789@gannet.stats.ox.ac.uk>
Message-ID: <59d7961d0602181310g22870577m7d16eb0ac68dc610@mail.gmail.com>

On 2/18/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Sat, 18 Feb 2006, Henrik Bengtsson wrote:
>
> > Hi,
> >
> > on WinXP Pro SP2 with NTFS, I noticed that file.info() under
> > Rv2.2.1pat (2006-02-09) does not report the correct file size if the
> > file is >= 2^31 bytes (2GB).   Is this problem known?  Is this related
> > to the note in ?file.info:
> >
> > "Some (broken) systems allow files of more than 2Gb to be created but
> > not accessed by the 'stat' system call.  Such files will show up as
> > non-readable (and very likely not be readable by any of R's input
> > functions)."
>
> Yes, no (although I have forgotten which file system that was).  The code
> relies on the stat call.  On a modern OS this comes from POSIX and says
>
>                    off_t         st_size;     /* total size, in bytes */
>
> It looks the corresponding MinGW/MSVCRT type is _off_t which is long, and
> on Windows that is a 32-bit type.  This can be avoided by
> calling stati64 rather than stat: that is incorrectly documented in my
> copy of MSDN library, but I have been able to find the correct
> incantation so this will be fixed in R-devel soon.

Thank you very much for this.

Regards,

Henrik

> > Example:
> >
> > # Create a 2Gb(!) file, report file.info()$size, and remove the file.
> >
> > fname <- "tmp.Rbin";
> > con <- file(fname, open="w+b");
> > size <- 2^31-1; # OK
> > size <- 2^31;    # Not OK
> > seek(con, where=size-1, rw="write");
> > writeBin(con=con, as.integer(0), size=1);
> > close(con);
> > print(file.info(fname)$size);
> > file.remove(fname);
> >
> > With size = c(2^31-1,2^31), file.info() reports file size
> > c(2147483647,-2147483648).  This looks to me like a non-signed to
> > signed integer case.
> >
> > Note that the above code does indeed create files >2Gb on WinXP with
> > NTFS; I've created files about 6Gb this way.
> >
> > BTW, about seek() on Windows:  I noticed the warning about using
> > seek() on Windows (see ?seek): "We have found so many errors in the
> > Windows implementation of file positioning that users are advised to
> > use it only at their own risk, and asked not to waste the R
> > developers' time with bug reports on Windows' deficiencies.".  Not
> > going to bug report, but I haven't noticed any problems this far.
> > What errors/symptoms are expected? Is regardless of file system used,
> > e.g. FAT, NTFS?
>
> Look in the bug repository.  There have been issues with text files and
> with files > 2Gb, and others.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>


--
Henrik Bengtsson
Mobile: +46 708 909208 (+1h UTC)


From ripley at stats.ox.ac.uk  Sun Feb 19 11:58:56 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Feb 2006 10:58:56 +0000 (GMT)
Subject: [Rd] Computing means, variances and sums
Message-ID: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>

There has been a recent thread on R-help on this, which resurrected 
concepts from bug reports PR#1228 and PR#6743.  Since the discussion has 
included a lot of erroneous 'information' based on misunderstandings of 
floating-point computations, this is an attempt to set the record straight 
and explain the solutions adopted.

The problem was that var(rep(0.02, 10)) was observed to be (on some 
machines) about 1e-35.  This can easily be explained.

0.02 is not an exactly repesented binary fraction.  Repeatedly adding the 
represented quantity makes increasing rounding errors relative to the 
exact computation, so (on Sparc Solaris)

> var(rep(0.02, 10))
[1] 1.337451e-35
> options(digits=18)
> sum(rep(0.02, 10))
[1] 0.19999999999999998
> sum(rep(0.02, 10)) -0.2
[1] -2.775557561562891e-17
> sum(rep(0.02, 10))/10 -0.02
[1] -3.469446951953614e-18
> z <- sum(rep(0.02, 10))/10 -0.02
> 10*z^2/9
[1] 1.3374513502689138e-35

and so the non-zero variance is arising from (x[i] - mean) being non-zero.
(I did check that was what was happening at C level.)

There has been talk of other ways to arrange these computations, for 
example Kahan summation and Welford's algorithm (see Chan & Lewis, 1979, 
CACM 22, 526-531 and references therein).  However, R already used the 
two-pass algorithm which is the most accurate (in terms of error bounds) 
in that reference.

Why are most people seeing 0?  Because the way computation is done in 
modern FPUs is not the computation analysed in early numerical analysis 
papers, including in Chan & Lewis.  First, all FPUs that I am aware of 
allow the use of guard digits, effectively doing intermediate computations 
to one more bit than required.  And many use extended precision registers 
for computations which they can keep in FP registers, thereby keeping 
another 10 or more bits.  (This includes R on most OSes on ix86 CPUs, the 
exception being on Windows where the FPU has been reset by some other 
software. Typically it is not the case for RISC CPUs, e.g. Sparc.)

The use of extended precision registers invalidates the textbook 
comparisons of accuracy in at least two ways.  First, the error analysis 
is different if all intermediate results are stored in extended precision. 
Second, the simpler the algorithm, the more intermediate results which 
will remain in extended precision.  This means that (for example) Kahan 
summation is usually less accurate than direct summation on real-world 
FPUs.

There are at least two steps which can be done to improve accuracy.
One is to ensure that intermediate results are stored in extended 
precision.  Every R platform of which I am aware has a 'long double' type 
which can be used.  On ix86 this is the extended precision type used 
internally in the FPU and so the cost is zero or close to zero, whereas on 
a Sparc the extra precision is more but there is some cost.  The second 
step is to use iterative refinement, so the final part of mean.default 
currently is

     ## sum(int) can overflow, so convert here.
     if(is.integer(x)) x <- as.numeric(x)
     ## use one round of iterative refinement
     res <- sum(x)/n
     if(is.finite(res)) res + sum(x-res)/n else res

This is a well-known technique in numerical linear algebra, and improves 
the accuracy whilst doubling the cost.  (This is about to be replaced by 
an internal function to allow the intermediate result to be stored in a 
long double.)

Note the is.finite(res) there.  R works with the extended IEC60059 (aka 
IEEE754) quantities of Inf, -Inf and NaN (NA being a special NaN).  The 
rearranged computations do not work correctly for those quantities.  So 
although they can be more 'efficient' (in terms of flops), they have to be 
supplemented by some other calculation to ensure that the specials are 
handled correctly.  Remember once again that we get both speed and 
accuracy advantages by keeping computations in FPU registers, so 
complicating the code has considerable cost.

R-devel will shortly use long doubles for critical intermediate results 
and iterative refinement for calculations of means.  This may be slower 
but it would be an extreme case in which the speed difference was 
detectable.  Higher accuracy has a cost too: there are several packages 
(dprep and mclust are two) whose results are critically dependent on fine 
details of computations and will for example infinite-loop if an optimized 
BLAS is used on AMD64.


The choice of algorithms in R is an eclectic mixture of accuracy and 
speed.  When (some of) R-core decided to make use of a BLAS for e.g. 
matrix products this produced a large speed increase for those with 
optimized BLAS (and a small speed decrease for others), but it did result 
in lower accuracy and problems with NAs etc (and the alternative 
algorithms have since been added back to cover such cases).  But it seems 
that nowadays few R users understand the notion of rounding error, and it 
is easier to make the computations maximally accurate than to keep 
explaining basic numerical analysis on R-help.  (The problem is thereby 
just pushed farther down the line, because for example linear regression 
is not maximally accurate.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Sun Feb 19 04:48:49 2006
From: berwin at maths.uwa.edu.au (berwin@maths.uwa.edu.au)
Date: Sun, 19 Feb 2006 04:48:49 +0100 (CET)
Subject: [Rd] Bug in Sweave? -- scoping problem? (PR#8615)
Message-ID: <20060219034849.1280C121AE@slim.kubism.ku.dk>

G'day Duncan,

>>>>> "DM" == murdoch  <murdoch at stats.uwo.ca> writes:

    DM> I have found a strange scoping problem in Sweave.  [...]

    DM> The strange thing is that while the value in partytotal is
    DM> output correctly as [...]

    DM> but the dotchart contains the wrong values: it shows sorted
    DM> values, but not sorted names, [...]
No bug, but a feature. :)
(But then, a well known software producer seems to use `feature' as a
euphemism for `bug', so perhaps I shouldn't call it a feature.)

There was recently a discussion on r-help (?) about Sweave producing
different output in the text and plot when random numbers were
generated, and it seems as if you have run into the same trap:

      Code in chunks that produce pictures is executed several times.
      First, to produce the output in the text.  And then once more
      for *each* format in which the figure has to be produced.  I.e.,
      if you want a PDF and a PostScript version of the figure, the
      code is executed a total of three times.

All instances of this feature reported so far involved commands that
produced random numbers and the poster was surprised that the output
in the text and the figures differed (and that the two figures were
different).

In your case the first execution of the code assigns the names to
partytotal, sorts partytotal and produces the data.  On the next
execution, when the picture is produced, partytotal is already sorted
but you reassign the names.  Then the partytotal is sorted again and
the plot is produced.  But that re-assigning of names lead to the
disconnect between values and names.

Hope this helps.

Cheers,

        Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin


From murdoch at stats.uwo.ca  Sun Feb 19 14:41:18 2006
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Sun, 19 Feb 2006 14:41:18 +0100 (CET)
Subject: [Rd] Bug in Sweave? -- scoping problem? (PR#8615)
Message-ID: <20060219134118.D7326A6C8@slim.kubism.ku.dk>

Berwin A Turlach wrote:
> G'day Duncan,
> 
> 
>>>>>>"DM" == murdoch  <murdoch at stats.uwo.ca> writes:
> 
> 
>     DM> I have found a strange scoping problem in Sweave.  [...]
> 
>     DM> The strange thing is that while the value in partytotal is
>     DM> output correctly as [...]
> 
>     DM> but the dotchart contains the wrong values: it shows sorted
>     DM> values, but not sorted names, [...]
> No bug, but a feature. :)
> (But then, a well known software producer seems to use `feature' as a
> euphemism for `bug', so perhaps I shouldn't call it a feature.)
> 
> There was recently a discussion on r-help (?) about Sweave producing
> different output in the text and plot when random numbers were
> generated, and it seems as if you have run into the same trap:
> 
>       Code in chunks that produce pictures is executed several times.
>       First, to produce the output in the text.  And then once more
>       for *each* format in which the figure has to be produced.  I.e.,
>       if you want a PDF and a PostScript version of the figure, the
>       code is executed a total of three times.

Thanks, that's what caught me.  Is that a quote from the discussion, or 
from the docs somewhere?  It makes sense in hindsight, but it's not 
obvious ahead of time, so it should be stated fairly prominently in the 
docs.

Duncan Murdoch
> 
> All instances of this feature reported so far involved commands that
> produced random numbers and the poster was surprised that the output
> in the text and the figures differed (and that the two figures were
> different).
> 
> In your case the first execution of the code assigns the names to
> partytotal, sorts partytotal and produces the data.  On the next
> execution, when the picture is produced, partytotal is already sorted
> but you reassign the names.  Then the partytotal is sorted again and
> the plot is produced.  But that re-assigning of names lead to the
> disconnect between values and names.
> 
> Hope this helps.
> 
> Cheers,
> 
>         Berwin
> 
> ========================== Full address ============================
> Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
> School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
> The University of Western Australia   FAX : +61 (8) 6488 1028
> 35 Stirling Highway                   
> Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
> Australia                        http://www.maths.uwa.edu.au/~berwin


From jago at mclink.it  Sun Feb 19 17:30:22 2006
From: jago at mclink.it (stefano iacus)
Date: Sun, 19 Feb 2006 17:30:22 +0100
Subject: [Rd] Error message while installing quatreg in ox s (PR#8616)
In-Reply-To: <20060218200730.7A2343F239@slim.kubism.ku.dk>
References: <20060218200730.7A2343F239@slim.kubism.ku.dk>
Message-ID: <A14EB72D-ABC3-462D-9451-4BF93D71062F@mclink.it>

This is not an R bug, nor it realtes to quantreg. It is not even an  
error but a warning.
It is due to the fact that you don't have enough writing permission  
and it is related the R.app way of handling package installation.
stefano

Il giorno 18/feb/06, alle ore 21:07, ArresrSpam at bellsouth.net ha  
scritto:

> Full_Name: Alok Krishen
> Version: 2.2.1
> OS: OS X
> Submission from: (NULL) (68.221.92.169)
>
>
> When install.packages("quantreg") produces the following error message
> cannot create HTML package index in: make.packages.html()
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From spencer.graves at pdf.com  Sun Feb 19 20:02:41 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 19 Feb 2006 11:02:41 -0800
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
Message-ID: <43F8C0D1.6000907@pdf.com>

Dear Professors Ripley & Murdoch, & others:

	  If this were just an issue of computations like var(rep(0.02, 10)) 
producing something other than 0 on certain platforms (e.g., 
combinations of operating systems and microprocessors), then I would 
suggest it be documented as an FAQ and left as a tool to help explain 
finite precision arithmetic and rounding issues to people who don't yet 
understand those concepts.

	  However, Duncan's comment shows that it is more than that, namely 
that certain DLLs change the precision of the fpu (floating point unit?) 
from 64 to 53 bit matissas AND DON'T RESET THEM.  When this is not 
detected, it could make the difference between a useable answer and 
nonsense in poorly conditioned applications where those 9 bits might be 
important.  For me, that problem is NOT that one occasionally gets 
nonsense from a poorly conditioned compution.  Rather it is that the 
SAME computation could give a useful answer in one case and nonsense a 
few seconds later ON THE SAME COMPUTER, operating system, etc.

	  To test my understanding, I simplified Barry Zajdik's example further:

 > var(rep(.2, 3))
[1] 0
 > RSiteSearch("convert to binary")
A search query has been submitted to http://search.r-project.org
The results page should open in your browser shortly
 > var(rep(.2, 3))
[1] 1.155558e-33
 > sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

	  This indicates there is a problem that perhaps should eventually be 
fixed.  However, please do NOT spend time on this because I suggested it 
was an issue.  The conditions under which this would create problems for 
anyone are still so rare that I would not want to alter anyone's work 
priorities for it.

	  spencer graves
p.s.  If my computations are correct, 0.2 = 0*/2 + 0/4 + 1/8 + 1/16 + 
0/32 + 0/64 + 1/128 + 1/256 + 0/512 + 0/1024 + 1/2048 + 1/4096 + ... = 
0.3333333333333h.  Perhaps someone can extend this to an FAQ to help 
explain finite precision arithmetic and rounding issues.
	
Prof Brian Ripley wrote:
> There has been a recent thread on R-help on this, which resurrected 
> concepts from bug reports PR#1228 and PR#6743.  Since the discussion has 
> included a lot of erroneous 'information' based on misunderstandings of 
> floating-point computations, this is an attempt to set the record 
> straight and explain the solutions adopted.
> 
> The problem was that var(rep(0.02, 10)) was observed to be (on some 
> machines) about 1e-35.  This can easily be explained.
> 
> 0.02 is not an exactly repesented binary fraction.  Repeatedly adding 
> the represented quantity makes increasing rounding errors relative to 
> the exact computation, so (on Sparc Solaris)
> 
>> var(rep(0.02, 10))
> 
> [1] 1.337451e-35
> 
>> options(digits=18)
>> sum(rep(0.02, 10))
> 
> [1] 0.19999999999999998
> 
>> sum(rep(0.02, 10)) -0.2
> 
> [1] -2.775557561562891e-17
> 
>> sum(rep(0.02, 10))/10 -0.02
> 
> [1] -3.469446951953614e-18
> 
>> z <- sum(rep(0.02, 10))/10 -0.02
>> 10*z^2/9
> 
> [1] 1.3374513502689138e-35
> 
> and so the non-zero variance is arising from (x[i] - mean) being non-zero.
> (I did check that was what was happening at C level.)
> 
> There has been talk of other ways to arrange these computations, for 
> example Kahan summation and Welford's algorithm (see Chan & Lewis, 1979, 
> CACM 22, 526-531 and references therein).  However, R already used the 
> two-pass algorithm which is the most accurate (in terms of error bounds) 
> in that reference.
> 
> Why are most people seeing 0?  Because the way computation is done in 
> modern FPUs is not the computation analysed in early numerical analysis 
> papers, including in Chan & Lewis.  First, all FPUs that I am aware of 
> allow the use of guard digits, effectively doing intermediate 
> computations to one more bit than required.  And many use extended 
> precision registers for computations which they can keep in FP 
> registers, thereby keeping another 10 or more bits.  (This includes R on 
> most OSes on ix86 CPUs, the exception being on Windows where the FPU has 
> been reset by some other software. Typically it is not the case for RISC 
> CPUs, e.g. Sparc.)
> 
> The use of extended precision registers invalidates the textbook 
> comparisons of accuracy in at least two ways.  First, the error analysis 
> is different if all intermediate results are stored in extended 
> precision. Second, the simpler the algorithm, the more intermediate 
> results which will remain in extended precision.  This means that (for 
> example) Kahan summation is usually less accurate than direct summation 
> on real-world FPUs.
> 
> There are at least two steps which can be done to improve accuracy.
> One is to ensure that intermediate results are stored in extended 
> precision.  Every R platform of which I am aware has a 'long double' 
> type which can be used.  On ix86 this is the extended precision type 
> used internally in the FPU and so the cost is zero or close to zero, 
> whereas on a Sparc the extra precision is more but there is some cost.  
> The second step is to use iterative refinement, so the final part of 
> mean.default currently is
> 
>     ## sum(int) can overflow, so convert here.
>     if(is.integer(x)) x <- as.numeric(x)
>     ## use one round of iterative refinement
>     res <- sum(x)/n
>     if(is.finite(res)) res + sum(x-res)/n else res
> 
> This is a well-known technique in numerical linear algebra, and improves 
> the accuracy whilst doubling the cost.  (This is about to be replaced by 
> an internal function to allow the intermediate result to be stored in a 
> long double.)
> 
> Note the is.finite(res) there.  R works with the extended IEC60059 (aka 
> IEEE754) quantities of Inf, -Inf and NaN (NA being a special NaN).  The 
> rearranged computations do not work correctly for those quantities.  So 
> although they can be more 'efficient' (in terms of flops), they have to 
> be supplemented by some other calculation to ensure that the specials 
> are handled correctly.  Remember once again that we get both speed and 
> accuracy advantages by keeping computations in FPU registers, so 
> complicating the code has considerable cost.
> 
> R-devel will shortly use long doubles for critical intermediate results 
> and iterative refinement for calculations of means.  This may be slower 
> but it would be an extreme case in which the speed difference was 
> detectable.  Higher accuracy has a cost too: there are several packages 
> (dprep and mclust are two) whose results are critically dependent on 
> fine details of computations and will for example infinite-loop if an 
> optimized BLAS is used on AMD64.
> 
> 
> The choice of algorithms in R is an eclectic mixture of accuracy and 
> speed.  When (some of) R-core decided to make use of a BLAS for e.g. 
> matrix products this produced a large speed increase for those with 
> optimized BLAS (and a small speed decrease for others), but it did 
> result in lower accuracy and problems with NAs etc (and the alternative 
> algorithms have since been added back to cover such cases).  But it 
> seems that nowadays few R users understand the notion of rounding error, 
> and it is easier to make the computations maximally accurate than to 
> keep explaining basic numerical analysis on R-help.  (The problem is 
> thereby just pushed farther down the line, because for example linear 
> regression is not maximally accurate.)
>


From h.wickham at gmail.com  Sun Feb 19 20:42:04 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 19 Feb 2006 13:42:04 -0600
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <43F8C0D1.6000907@pdf.com>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
	<43F8C0D1.6000907@pdf.com>
Message-ID: <f8e6ff050602191142x6a7c1359v768980d0f8842bf2@mail.gmail.com>

> p.s.  If my computations are correct, 0.2 = 0*/2 + 0/4 + 1/8 + 1/16 +
> 0/32 + 0/64 + 1/128 + 1/256 + 0/512 + 0/1024 + 1/2048 + 1/4096 + ... =
> 0.3333333333333h.  Perhaps someone can extend this to an FAQ to help
> explain finite precision arithmetic and rounding issues.

This is drifting a bit off topic, but the other day I discovered this
rather nice illustration of the perils of finite precision arithmetic
while creating a contrast matrix:

> n <- 13
> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
> rowSums(a)
 [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
 [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
[11]  1.110223e-16  1.665335e-16  2.220446e-16

Not only do most of the rows not sum to 0, they do not even sum to the
same number!  It is hard to remember the familiar rules of arithmetic
do not always apply.

Hadley


From ripley at stats.ox.ac.uk  Sun Feb 19 21:13:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Feb 2006 20:13:36 +0000 (GMT)
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <43F8C0D1.6000907@pdf.com>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
	<43F8C0D1.6000907@pdf.com>
Message-ID: <Pine.LNX.4.64.0602192009410.28769@gannet.stats.ox.ac.uk>

As I have said before on R-help, it is _already_ fixed in this (and 
related cases) and the reasons it is fixed were explained here.  If you 
read carefully, you will have noticed that some platforms (such as Sparc) 
only use 53 bits (+ a guard bit).

Not that I accept that the 53-bit calculation is `nonsense', or anything 
close to it.

On Sun, 19 Feb 2006, Spencer Graves wrote:

> Dear Professors Ripley & Murdoch, & others:
>
> 	  If this were just an issue of computations like var(rep(0.02, 10)) 
> producing something other than 0 on certain platforms (e.g., combinations of 
> operating systems and microprocessors), then I would suggest it be documented 
> as an FAQ and left as a tool to help explain finite precision arithmetic and 
> rounding issues to people who don't yet understand those concepts.
>
> 	  However, Duncan's comment shows that it is more than that, namely 
> that certain DLLs change the precision of the fpu (floating point unit?) from 
> 64 to 53 bit matissas AND DON'T RESET THEM.  When this is not detected, it 
> could make the difference between a useable answer and nonsense in poorly 
> conditioned applications where those 9 bits might be important.  For me, that 
> problem is NOT that one occasionally gets nonsense from a poorly conditioned 
> compution.  Rather it is that the SAME computation could give a useful answer 
> in one case and nonsense a few seconds later ON THE SAME COMPUTER, operating 
> system, etc.
>
> 	  To test my understanding, I simplified Barry Zajdik's example 
> further:
>
>> var(rep(.2, 3))
> [1] 0
>> RSiteSearch("convert to binary")
> A search query has been submitted to http://search.r-project.org
> The results page should open in your browser shortly
>> var(rep(.2, 3))
> [1] 1.155558e-33
>> sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"
>
> 	  This indicates there is a problem that perhaps should eventually be 
> fixed.  However, please do NOT spend time on this because I suggested it was 
> an issue.  The conditions under which this would create problems for anyone 
> are still so rare that I would not want to alter anyone's work priorities for 
> it.
>
> 	  spencer graves
> p.s.  If my computations are correct, 0.2 = 0*/2 + 0/4 + 1/8 + 1/16 + 0/32 + 
> 0/64 + 1/128 + 1/256 + 0/512 + 0/1024 + 1/2048 + 1/4096 + ... = 
> 0.3333333333333h.  Perhaps someone can extend this to an FAQ to help explain 
> finite precision arithmetic and rounding issues.
> 	Prof Brian Ripley wrote:
>> There has been a recent thread on R-help on this, which resurrected 
>> concepts from bug reports PR#1228 and PR#6743.  Since the discussion has 
>> included a lot of erroneous 'information' based on misunderstandings of 
>> floating-point computations, this is an attempt to set the record straight 
>> and explain the solutions adopted.
>> 
>> The problem was that var(rep(0.02, 10)) was observed to be (on some 
>> machines) about 1e-35.  This can easily be explained.
>> 
>> 0.02 is not an exactly repesented binary fraction.  Repeatedly adding the 
>> represented quantity makes increasing rounding errors relative to the exact 
>> computation, so (on Sparc Solaris)
>> 
>>> var(rep(0.02, 10))
>> 
>> [1] 1.337451e-35
>> 
>>> options(digits=18)
>>> sum(rep(0.02, 10))
>> 
>> [1] 0.19999999999999998
>> 
>>> sum(rep(0.02, 10)) -0.2
>> 
>> [1] -2.775557561562891e-17
>> 
>>> sum(rep(0.02, 10))/10 -0.02
>> 
>> [1] -3.469446951953614e-18
>> 
>>> z <- sum(rep(0.02, 10))/10 -0.02
>>> 10*z^2/9
>> 
>> [1] 1.3374513502689138e-35
>> 
>> and so the non-zero variance is arising from (x[i] - mean) being non-zero.
>> (I did check that was what was happening at C level.)
>> 
>> There has been talk of other ways to arrange these computations, for 
>> example Kahan summation and Welford's algorithm (see Chan & Lewis, 1979, 
>> CACM 22, 526-531 and references therein).  However, R already used the 
>> two-pass algorithm which is the most accurate (in terms of error bounds) in 
>> that reference.
>> 
>> Why are most people seeing 0?  Because the way computation is done in 
>> modern FPUs is not the computation analysed in early numerical analysis 
>> papers, including in Chan & Lewis.  First, all FPUs that I am aware of 
>> allow the use of guard digits, effectively doing intermediate computations 
>> to one more bit than required.  And many use extended precision registers 
>> for computations which they can keep in FP registers, thereby keeping 
>> another 10 or more bits.  (This includes R on most OSes on ix86 CPUs, the 
>> exception being on Windows where the FPU has been reset by some other 
>> software. Typically it is not the case for RISC CPUs, e.g. Sparc.)
>> 
>> The use of extended precision registers invalidates the textbook 
>> comparisons of accuracy in at least two ways.  First, the error analysis is 
>> different if all intermediate results are stored in extended precision. 
>> Second, the simpler the algorithm, the more intermediate results which will 
>> remain in extended precision.  This means that (for example) Kahan 
>> summation is usually less accurate than direct summation on real-world 
>> FPUs.
>> 
>> There are at least two steps which can be done to improve accuracy.
>> One is to ensure that intermediate results are stored in extended 
>> precision.  Every R platform of which I am aware has a 'long double' type 
>> which can be used.  On ix86 this is the extended precision type used 
>> internally in the FPU and so the cost is zero or close to zero, whereas on 
>> a Sparc the extra precision is more but there is some cost.  The second 
>> step is to use iterative refinement, so the final part of mean.default 
>> currently is
>>
>>     ## sum(int) can overflow, so convert here.
>>     if(is.integer(x)) x <- as.numeric(x)
>>     ## use one round of iterative refinement
>>     res <- sum(x)/n
>>     if(is.finite(res)) res + sum(x-res)/n else res
>> 
>> This is a well-known technique in numerical linear algebra, and improves 
>> the accuracy whilst doubling the cost.  (This is about to be replaced by an 
>> internal function to allow the intermediate result to be stored in a long 
>> double.)
>> 
>> Note the is.finite(res) there.  R works with the extended IEC60059 (aka 
>> IEEE754) quantities of Inf, -Inf and NaN (NA being a special NaN).  The 
>> rearranged computations do not work correctly for those quantities.  So 
>> although they can be more 'efficient' (in terms of flops), they have to be 
>> supplemented by some other calculation to ensure that the specials are 
>> handled correctly.  Remember once again that we get both speed and accuracy 
>> advantages by keeping computations in FPU registers, so complicating the 
>> code has considerable cost.
>> 
>> R-devel will shortly use long doubles for critical intermediate results and 
>> iterative refinement for calculations of means.  This may be slower but it 
>> would be an extreme case in which the speed difference was detectable. 
>> Higher accuracy has a cost too: there are several packages (dprep and 
>> mclust are two) whose results are critically dependent on fine details of 
>> computations and will for example infinite-loop if an optimized BLAS is 
>> used on AMD64.
>> 
>> 
>> The choice of algorithms in R is an eclectic mixture of accuracy and speed. 
>> When (some of) R-core decided to make use of a BLAS for e.g. matrix 
>> products this produced a large speed increase for those with optimized BLAS 
>> (and a small speed decrease for others), but it did result in lower 
>> accuracy and problems with NAs etc (and the alternative algorithms have 
>> since been added back to cover such cases).  But it seems that nowadays few 
>> R users understand the notion of rounding error, and it is easier to make 
>> the computations maximally accurate than to keep explaining basic numerical 
>> analysis on R-help.  (The problem is thereby just pushed farther down the 
>> line, because for example linear regression is not maximally accurate.)
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Feb 19 21:18:13 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Feb 2006 20:18:13 +0000 (GMT)
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <f8e6ff050602191142x6a7c1359v768980d0f8842bf2@mail.gmail.com>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
	<43F8C0D1.6000907@pdf.com>
	<f8e6ff050602191142x6a7c1359v768980d0f8842bf2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602192014300.28769@gannet.stats.ox.ac.uk>

On Sun, 19 Feb 2006, hadley wickham wrote:

>> p.s.  If my computations are correct, 0.2 = 0*/2 + 0/4 + 1/8 + 1/16 +
>> 0/32 + 0/64 + 1/128 + 1/256 + 0/512 + 0/1024 + 1/2048 + 1/4096 + ... =
>> 0.3333333333333h.  Perhaps someone can extend this to an FAQ to help
>> explain finite precision arithmetic and rounding issues.
>
> This is drifting a bit off topic, but the other day I discovered this
> rather nice illustration of the perils of finite precision arithmetic
> while creating a contrast matrix:
>
>> n <- 13
>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>> rowSums(a)
> [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
> [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
> [11]  1.110223e-16  1.665335e-16  2.220446e-16
>
> Not only do most of the rows not sum to 0, they do not even sum to the
> same number!  It is hard to remember the familiar rules of arithmetic
> do not always apply.

I think you will find this example does give all 0's in R-devel, even 
on platforms like Sparc.  But users do need to remember that computer 
arithmetic is inexact except in rather narrowly delimited cases.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Sun Feb 19 22:58:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 19 Feb 2006 16:58:23 -0500
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <Pine.LNX.4.64.0602192014300.28769@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>	<43F8C0D1.6000907@pdf.com>	<f8e6ff050602191142x6a7c1359v768980d0f8842bf2@mail.gmail.com>
	<Pine.LNX.4.64.0602192014300.28769@gannet.stats.ox.ac.uk>
Message-ID: <43F8E9FF.9080304@stats.uwo.ca>

On 2/19/2006 3:18 PM, Prof Brian Ripley wrote:
> On Sun, 19 Feb 2006, hadley wickham wrote:
> 
>>> p.s.  If my computations are correct, 0.2 = 0*/2 + 0/4 + 1/8 + 1/16 +
>>> 0/32 + 0/64 + 1/128 + 1/256 + 0/512 + 0/1024 + 1/2048 + 1/4096 + ... =
>>> 0.3333333333333h.  Perhaps someone can extend this to an FAQ to help
>>> explain finite precision arithmetic and rounding issues.
>> This is drifting a bit off topic, but the other day I discovered this
>> rather nice illustration of the perils of finite precision arithmetic
>> while creating a contrast matrix:
>>
>>> n <- 13
>>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>>> rowSums(a)
>> [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
>> [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
>> [11]  1.110223e-16  1.665335e-16  2.220446e-16
>>
>> Not only do most of the rows not sum to 0, they do not even sum to the
>> same number!  It is hard to remember the familiar rules of arithmetic
>> do not always apply.
> 
> I think you will find this example does give all 0's in R-devel, even 
> on platforms like Sparc.  

Only until the fpu precision gets changed:

 > n <- 13
 > a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
 > rowSums(a)
  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0
 > RSiteSearch('junk')
A search query has been submitted to http://search.r-project.org
The results page should open in your browser shortly

 > n <- 13
 > a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
 > rowSums(a)
  [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
  [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
[11]  1.110223e-16  1.665335e-16  2.220446e-16

We still need to protect against these changes.  I'll put something 
together, unless you're already working on it.

The approach I'm thinking of is to define a macro to be called in risky 
situations.  On platforms where this isn't an issue, the macro would be 
null; on Windows, it would reset the fpu to full precision.

For example, RSiteSearch causes damage in the ShellExecute call in 
do_shellexec called from browseURL, so I'd add protection there.  I 
think we should also add detection code somewhere in the evaluation loop 
to help in diagnosing these problems.

> But users do need to remember that computer 
> arithmetic is inexact except in rather narrowly delimited cases.

Yes, that too.

Duncan Murdoch


From p.murrell at auckland.ac.nz  Mon Feb 20 03:06:24 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 20 Feb 2006 15:06:24 +1300
Subject: [Rd] invalid graphics state using dev.print (fwd)
In-Reply-To: <17388.51930.273876.336070@stat.math.ethz.ch>
References: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>
	<17388.51930.273876.336070@stat.math.ethz.ch>
Message-ID: <43F92420.4070706@stat.auckland.ac.nz>

Hi


Martin Maechler wrote:
>>>>>>"Paul" == Paul Roebuck <roebuck at mdanderson.org>
>>>>>>    on Wed, 8 Feb 2006 15:33:11 -0600 (CST) writes:
> 
> 
>     Paul> On Mon, 6 Feb 2006 18:12, Simon Urbanek wrote:
>     >> On Feb 6, 2006, at 5:24 PM, Paul Roebuck wrote:
>     >> 
>     >>> Tried on R-Sig-Mac with no responses, but I need some kind
>     >>> of answer.
>     >>> [...]
>     >>> Does the following work on your system?
>     >> 
>     >> Interesting, no, it doesn't either. For png and pdf I use
>     >> Quartz + quartz.save (it produces much nicer results) so
>     >> I didn't really notice, but you're right. First I thought
>     >> those graphics state issues are specific to the Quartz
>     >> device, but you have proven that it's not. It's in fact
>     >> not even Mac-specific - I have just reproduced it on a
>     >> Linux box - that's why I'm moving this to R-devel.
> 
>     Paul> It's been several workdays now with no responses. Could
>     Paul> someone try the last three lines of code and see if they
>     Paul> get the following error message?
> 
>     >> x11()
>     >> plot(rnorm(10))
>     >> dev.print(png)
> 
>     Paul> Error in dev.copy(device = function (filename = "Rplot%03d.png", width =
>     Paul> 480,  :
>     Paul> invalid graphics state
> 
>     >> traceback()
>     Paul> 6: dev.copy(device = function (filename = "Rplot%03d.png", width = 480,
>     Paul> height = 480, pointsize = 12, gamma = 1, colortype =
>     Paul> getOption("X11colortype"),
>     Paul> maxcubesize = 256, bg = "white", fonts = getOption("X11fonts"),
>     Paul> res = NA)
>     Paul> .Internal(X11(paste("png::", filename, sep = ""), width, height,
>     Paul> pointsize, gamma, colortype, maxcubesize, bg, bg, fonts,
>     Paul> res)), width = 6.98715785526809, height = 6.99452568428947)
>     Paul> 5: eval(expr, envir, enclos)
>     Paul> 4: eval(expr, p)
>     Paul> 3: eval.parent(oc)
>     Paul> 2: dev.off(eval.parent(oc))
>     Paul> 1: dev.print(png)
> 
>     Paul> I noticed it on OS X, and Simon on Linux. 
> 
> Yes, I can confim getting the same.
> Just on Linux though (as Simon)
> 
> I'd say this should make a ``nice little''  bug.report() 
> 
> Interestingly, replacing
> 
>     dev.print(png)
> 
> by  dev.copy(png) ; dev.off()  
> 
> which is about equivalent,  *does* work and so is a workaround
> to your problem.


I think the problem is that the width and height of the PNG device is 
being taken (without regard for units) from the X11 device.  So 
approximately 7 inches square screen window gets drawn into 
approximately 7 *pixel* square PNG file and (understandably) R complains 
that there is not enough room for the plot.  Another workaround is 
something like ...

dev.print(png, width=480, height=480)

... and a fix requires making dev.print() smarter so that it figures out 
that it needs to convert width/height from inches to pixels.

Paul


>     Paul> Other platforms?  WFM?
> 
>     Paul> TIA
> 
>     >> version
>     Paul> _
>     Paul> platform powerpc-apple-darwin7.9.0
>     Paul> arch     powerpc
>     Paul> os       darwin7.9.0
>     Paul> system   powerpc, darwin7.9.0
>     Paul> status   Patched
>     Paul> major    2
>     Paul> minor    2.1
>     Paul> year     2006
>     Paul> month    02
>     Paul> day      01
>     Paul> svn rev  37245
>     Paul> language R
> 
>     Paul> ----------------------------------------------------------
>     Paul> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ripley at stats.ox.ac.uk  Mon Feb 20 08:56:57 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 07:56:57 +0000 (GMT)
Subject: [Rd] invalid graphics state using dev.print (fwd)
In-Reply-To: <43F92420.4070706@stat.auckland.ac.nz>
References: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>
	<17388.51930.273876.336070@stat.math.ethz.ch>
	<43F92420.4070706@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0602200714030.3798@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Paul Murrell wrote:

[...]

>>    >> x11()
>>    >> plot(rnorm(10))
>>    >> dev.print(png)

>>     Paul> Error in dev.copy(device = function (filename = "Rplot%03d.png", width =
>>     Paul> 480,  :
>>     Paul> invalid graphics state

> I think the problem is that the width and height of the PNG device is
> being taken (without regard for units) from the X11 device.  So
> approximately 7 inches square screen window gets drawn into
> approximately 7 *pixel* square PNG file and (understandably) R complains
> that there is not enough room for the plot.

Yes, that it how it is documented to work.

> Another workaround is something like ...
>
> dev.print(png, width=480, height=480)

(Just one will do if you want to preserve the aspect ratio.)

> ... and a fix requires making dev.print() smarter so that it figures out
> that it needs to convert width/height from inches to pixels.

I don't think there is a way to do that unambiguously (there is no 
standard way to do the conversion), and in any case dev.print() was passed 
a function, not the name of a function, and so does not in general know 
how it behaves (and your 'png' need not be R's png()).

All we can do is to re-emphasize this on the help page, and add a warning 
if a known bitmap device is detected (possibly inaccurately) by name.

BTW, I think it was perverse to call dev.print() except to do printing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Friedrich.Leisch at tuwien.ac.at  Mon Feb 20 09:37:40 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon, 20 Feb 2006 09:37:40 +0100 (CET)
Subject: [Rd] Bug in Sweave? -- scoping problem? (PR#8615)
Message-ID: <20060220083740.97779A6CD@slim.kubism.ku.dk>


I will add it to the FAQ.

fritz

>>>>> On Sun, 19 Feb 2006 08:42:09 -0500,
>>>>> Duncan Murdoch (DM) wrote:

[...]

>       Code in chunks that produce pictures is executed several times.
>       First, to produce the output in the text.  And then once more
>       for *each* format in which the figure has to be produced.  I.e.,
>       if you want a PDF and a PostScript version of the figure, the
>       code is executed a total of three times.

  > Thanks, that's what caught me.  Is that a quote from the discussion, or 
  > from the docs somewhere?  It makes sense in hindsight, but it's not 
  > obvious ahead of time, so it should be stated fairly prominently in the 
  > docs.


  > Duncan Murdoch
  >> 
  >> All instances of this feature reported so far involved commands that
  >> produced random numbers and the poster was surprised that the output
  >> in the text and the figures differed (and that the two figures were
  >> different).
  >> 
  >> In your case the first execution of the code assigns the names to
  >> partytotal, sorts partytotal and produces the data.  On the next
  >> execution, when the picture is produced, partytotal is already sorted
  >> but you reassign the names.  Then the partytotal is sorted again and
  >> the plot is produced.  But that re-assigning of names lead to the
  >> disconnect between values and names.
  >> 
  >> Hope this helps.
  >> 
  >> Cheers,
  >> 
  >> Berwin
  >> 
  >> ========================== Full address ============================
  >> Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
  >> School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
  >> The University of Western Australia   FAX : +61 (8) 6488 1028
  >> 35 Stirling Highway                   
  >> Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
  >> Australia                        http://www.maths.uwa.edu.au/~berwin


From ripley at stats.ox.ac.uk  Mon Feb 20 09:37:47 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 08:37:47 +0000 (GMT)
Subject: [Rd] invalid graphics state using dev.print (fwd)
In-Reply-To: <Pine.LNX.4.64.0602200714030.3798@gannet.stats.ox.ac.uk>
References: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>
	<17388.51930.273876.336070@stat.math.ethz.ch>
	<43F92420.4070706@stat.auckland.ac.nz>
	<Pine.LNX.4.64.0602200714030.3798@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602200833030.4588@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Prof Brian Ripley wrote:

> On Mon, 20 Feb 2006, Paul Murrell wrote:
>
> [...]
>
>>>   >> x11()
>>>   >> plot(rnorm(10))
>>>   >> dev.print(png)
>
>>>     Paul> Error in dev.copy(device = function (filename = "Rplot%03d.png", width =
>>>     Paul> 480,  :
>>>     Paul> invalid graphics state
>
>> I think the problem is that the width and height of the PNG device is
>> being taken (without regard for units) from the X11 device.  So
>> approximately 7 inches square screen window gets drawn into
>> approximately 7 *pixel* square PNG file and (understandably) R complains
>> that there is not enough room for the plot.
>
> Yes, that it how it is documented to work.
>
>> Another workaround is something like ...
>>
>> dev.print(png, width=480, height=480)
>
> (Just one will do if you want to preserve the aspect ratio.)
>
>> ... and a fix requires making dev.print() smarter so that it figures out
>> that it needs to convert width/height from inches to pixels.
>
> I don't think there is a way to do that unambiguously (there is no
> standard way to do the conversion), and in any case dev.print() was passed
> a function, not the name of a function, and so does not in general know
> how it behaves (and your 'png' need not be R's png()).
>
> All we can do is to re-emphasize this on the help page, and add a warning
> if a known bitmap device is detected (possibly inaccurately) by name.

One more thing we can do is to get the devices to issue a warning if the 
'width' and 'height' arguments appear inappropriate.  Since one might want 
to produce long thin plots, I've decided to do so if
width < 20 && height < 20.   Even those are just about plausible if you 
were trying to produce a small icon.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dpleydel at univ-fcomte.fr  Mon Feb 20 14:54:53 2006
From: dpleydel at univ-fcomte.fr (dpleydel@univ-fcomte.fr)
Date: Mon, 20 Feb 2006 14:54:53 +0100 (CET)
Subject: [Rd] Matrix / SparseM conflict (PR#8618)
Message-ID: <20060220135453.F08793F201@slim.kubism.ku.dk>

Full_Name: David Pleydell
Version: 2.2.1
OS: Debian Etch
Submission from: (NULL) (193.55.70.206)


There appears to be a conflict between the chol functions from the Matrix and
the SparseM packages. chol() can only be applied to a matrix of class dspMatrix
if SparseM is not in the path.

with gratitude
David


> library(Matrix)
> sm <- as(as(Matrix(diag(5) + 1), "dsyMatrix"), "dspMatrix")
> chol(sm)
5 x 5 Matrix of class "pCholesky"
     [,1]      [,2]      [,3]      [,4]      [,5]     
[1,] 1.4142136 0.7071068 0.7071068 0.7071068 0.7071068
[2,]         . 1.2247449 0.4082483 0.4082483 0.4082483
[3,]         .         . 1.1547005 0.2886751 0.2886751
[4,]         .         .         . 1.1180340 0.2236068
[5,]         .         .         .         . 1.0954451
> 
> library(SparseM)
[1] "SparseM library loaded"
> chol(sm)
Error in chol(sm) : no applicable method for "chol"
> 
> detach("package:SparseM")
> chol(sm)
5 x 5 Matrix of class "pCholesky"
     [,1]      [,2]      [,3]      [,4]      [,5]     
[1,] 1.4142136 0.7071068 0.7071068 0.7071068 0.7071068
[2,]         . 1.2247449 0.4082483 0.4082483 0.4082483
[3,]         .         . 1.1547005 0.2886751 0.2886751
[4,]         .         .         . 1.1180340 0.2236068
[5,]         .         .         .         . 1.0954451
>


From murdoch at stats.uwo.ca  Mon Feb 20 15:05:44 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 20 Feb 2006 09:05:44 -0500
Subject: [Rd] Matrix / SparseM conflict (PR#8618)
In-Reply-To: <20060220135453.F08793F201@slim.kubism.ku.dk>
References: <20060220135453.F08793F201@slim.kubism.ku.dk>
Message-ID: <43F9CCB8.9030808@stats.uwo.ca>

On 2/20/2006 8:54 AM, dpleydel at univ-fcomte.fr wrote:
> Full_Name: David Pleydell
> Version: 2.2.1
> OS: Debian Etch
> Submission from: (NULL) (193.55.70.206)
> 
> 
> There appears to be a conflict between the chol functions from the Matrix and
> the SparseM packages. chol() can only be applied to a matrix of class dspMatrix
> if SparseM is not in the path.

This isn't a bug, it's simply that both Matrix and SparseM define a 
generic for chol (though Matrix actually gets it by converting the 
function in base).

If you want access to the version in Matrix after attaching SparseM 
ahead of it in the search path, use Matrix::chol.

 > library(Matrix)
 > sm <- as(as(Matrix(diag(5) + 1), "dsyMatrix"), "dspMatrix")
 > library(SparseM)
[1] "SparseM library loaded"
 > chol(sm)
Error in chol(sm) : no applicable method for "chol"
 > Matrix::chol(sm)
5 x 5 Matrix of class "pCholesky"
      [,1]      [,2]      [,3]      [,4]      [,5]
[1,] 1.4142136 0.7071068 0.7071068 0.7071068 0.7071068
[2,]         . 1.2247449 0.4082483 0.4082483 0.4082483
[3,]         .         . 1.1547005 0.2886751 0.2886751
[4,]         .         .         . 1.1180340 0.2236068
[5,]         .         .         .         . 1.0954451

You might want to discuss this with the SparseM package maintainers; 
perhaps they don't really need to define their own generic.

Duncan Murdoch

> 
> with gratitude
> David
> 
> 
>> library(Matrix)
>> sm <- as(as(Matrix(diag(5) + 1), "dsyMatrix"), "dspMatrix")
>> chol(sm)
> 5 x 5 Matrix of class "pCholesky"
>      [,1]      [,2]      [,3]      [,4]      [,5]     
> [1,] 1.4142136 0.7071068 0.7071068 0.7071068 0.7071068
> [2,]         . 1.2247449 0.4082483 0.4082483 0.4082483
> [3,]         .         . 1.1547005 0.2886751 0.2886751
> [4,]         .         .         . 1.1180340 0.2236068
> [5,]         .         .         .         . 1.0954451
>> 
>> library(SparseM)
> [1] "SparseM library loaded"
>> chol(sm)
> Error in chol(sm) : no applicable method for "chol"
>> 
>> detach("package:SparseM")
>> chol(sm)
> 5 x 5 Matrix of class "pCholesky"
>      [,1]      [,2]      [,3]      [,4]      [,5]     
> [1,] 1.4142136 0.7071068 0.7071068 0.7071068 0.7071068
> [2,]         . 1.2247449 0.4082483 0.4082483 0.4082483
> [3,]         .         . 1.1547005 0.2886751 0.2886751
> [4,]         .         .         . 1.1180340 0.2236068
> [5,]         .         .         .         . 1.0954451
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Feb 20 15:07:54 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 20 Feb 2006 15:07:54 +0100 (CET)
Subject: [Rd] Matrix / SparseM conflict (PR#8618)
Message-ID: <20060220140754.B2BAE3F201@slim.kubism.ku.dk>

Both are contributed packages. The R-bugs repository is for bugs in R, not 
for contributed packages, as clearly stated in the R FAQ.

   Finally, check carefully whether the bug is with R, or a contributed
   package.  Bug reports on contributed packages should be sent first to
   the  package maintainer, and only submitted to the R-bugs repository by
   package maintainers, mentioning the package in the subject line.

Please contact the maintainers.  (It looks to me as if the problem is in 
SparseM, so you could try loading it first.)

On Mon, 20 Feb 2006, dpleydel at univ-fcomte.fr wrote:

> Full_Name: David Pleydell
> Version: 2.2.1
> OS: Debian Etch
> Submission from: (NULL) (193.55.70.206)
>
>
> There appears to be a conflict between the chol functions from the Matrix and
> the SparseM packages. chol() can only be applied to a matrix of class dspMatrix
> if SparseM is not in the path.
>
> with gratitude
> David
>
>
>> library(Matrix)
>> sm <- as(as(Matrix(diag(5) + 1), "dsyMatrix"), "dspMatrix")
>> chol(sm)
> 5 x 5 Matrix of class "pCholesky"
>     [,1]      [,2]      [,3]      [,4]      [,5]
> [1,] 1.4142136 0.7071068 0.7071068 0.7071068 0.7071068
> [2,]         . 1.2247449 0.4082483 0.4082483 0.4082483
> [3,]         .         . 1.1547005 0.2886751 0.2886751
> [4,]         .         .         . 1.1180340 0.2236068
> [5,]         .         .         .         . 1.0954451
>>
>> library(SparseM)
> [1] "SparseM library loaded"
>> chol(sm)
> Error in chol(sm) : no applicable method for "chol"
>>
>> detach("package:SparseM")
>> chol(sm)
> 5 x 5 Matrix of class "pCholesky"
>     [,1]      [,2]      [,3]      [,4]      [,5]
> [1,] 1.4142136 0.7071068 0.7071068 0.7071068 0.7071068
> [2,]         . 1.2247449 0.4082483 0.4082483 0.4082483
> [3,]         .         . 1.1547005 0.2886751 0.2886751
> [4,]         .         .         . 1.1180340 0.2236068
> [5,]         .         .         .         . 1.0954451
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Mon Feb 20 15:23:30 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 20 Feb 2006 08:23:30 -0600
Subject: [Rd] R CMD config --cppflags buglet
Message-ID: <17401.53474.442624.424119@basebud.nulle.part>


As you may recall, a Debian user complained last year about how R is out of
line with respect to the filesystem standards (where, in essence,
architecture independent files should be in /usr/share, not /usr/lib).  While
I more or less just told him to get lost, I think it was mostly BDR who
actually added support for this over the summer -- so a public Thanks!
first.  As of a few weeks ago, I now activate this in the Debian builds so
that we get

	edd at basebud:~> ls -F /usr/share/R
	doc/  include/  share/

The downside of this that the maintained assumption of 
	$R_HOME/share
	$R_HOME/include
no longer works. 

I was updated a number of packages for Quantian yesterday and noticed that
(at least) two packages had hard-coded links to $R_HOME/include in their
Makefiles. I was just about to mail their maintainers suggesting an
alternative when I noticed that that R (2.2.1) has it wrong too:

	edd at basebud:~> R CMD config --cppflags
	-I/usr/lib/R/include

Should I patch this at my end with a softlink

	/usr/share/R/include -> /usr/lib/R/include

or should that be fixed in R? For the record, I configure'd with

	--datadir=/usr/share/R/share	\
	--includedir=/usr/share/R/include	\

so that I get told about '-I/usr/lib/R/include' is probably a bug. Indeed,
src/script/config has an unconditional

    --cppflags)
      if test -z "${LIBR}"; then
        echo "R was not built as a shared library" >&2
      else
        echo "-I${R_HOME}/include"
      fi
      exit 0

so this should probably get autoconf'ed as well.  R.sh.in may be in the same
boat.

I apologise in advance for not checking with R-devel which I don't have handy
at home right now...

Regards, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ripley at stats.ox.ac.uk  Mon Feb 20 15:29:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 14:29:10 +0000 (GMT)
Subject: [Rd] Matrix / SparseM conflict (PR#8618)
In-Reply-To: <43F9CCB8.9030808@stats.uwo.ca>
References: <20060220135453.F08793F201@slim.kubism.ku.dk>
	<43F9CCB8.9030808@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0602201409480.28459@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Duncan Murdoch wrote:

> On 2/20/2006 8:54 AM, dpleydel at univ-fcomte.fr wrote:
>> Full_Name: David Pleydell
>> Version: 2.2.1
>> OS: Debian Etch
>> Submission from: (NULL) (193.55.70.206)
>>
>>
>> There appears to be a conflict between the chol functions from the Matrix and
>> the SparseM packages. chol() can only be applied to a matrix of class dspMatrix
>> if SparseM is not in the path.
>
> This isn't a bug, it's simply that both Matrix and SparseM define a
> generic for chol (though Matrix actually gets it by converting the
> function in base).

The problem appears to be that SparseM first redefines chol as an S3 
generic and then defines S4 methods on it.  As no new S3 methods are then 
defined the S3 step would seem unnecessary, but it is used to allow the 
package to define S4 methods on a different signature from R's chol().
(That seems to me to be asking for trouble.)

Only the package maintainer of SparseM can do anything about this.

Beyond, that I guess it is a consequence of namespaces that Matrix 
defines methods via a derived generic on base::chol and not on the generic 
chol in SparseM.  That needs further thought by someone (JMC?) who 
understands the S4 internals.

> If you want access to the version in Matrix after attaching SparseM
> ahead of it in the search path, use Matrix::chol.

But the whole point of generic functions is to allow one to write generic 
code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Feb 20 15:45:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 14:45:05 +0000 (GMT)
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <17401.53474.442624.424119@basebud.nulle.part>
References: <17401.53474.442624.424119@basebud.nulle.part>
Message-ID: <Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>

Dirk,

It was even more wrong in R-devel, for there we have sub-architectures and 
it needs to be "-I${R_INCLUDE_DIR} -I${R_INCLUDE_DIR}${R_ARCH}".
Fixed now, thanks.

I don't think there is any problem in R.sh.in.

Brian

On Mon, 20 Feb 2006, Dirk Eddelbuettel wrote:

>
> As you may recall, a Debian user complained last year about how R is out of
> line with respect to the filesystem standards (where, in essence,
> architecture independent files should be in /usr/share, not /usr/lib).  While
> I more or less just told him to get lost, I think it was mostly BDR who
> actually added support for this over the summer -- so a public Thanks!
> first.  As of a few weeks ago, I now activate this in the Debian builds so
> that we get
>
> 	edd at basebud:~> ls -F /usr/share/R
> 	doc/  include/  share/
>
> The downside of this that the maintained assumption of
> 	$R_HOME/share
> 	$R_HOME/include
> no longer works.
>
> I was updated a number of packages for Quantian yesterday and noticed that
> (at least) two packages had hard-coded links to $R_HOME/include in their

Well, only 5 CRAN packages have a src/Makefile, and one other has 
src/Makefile.in.  Of those only ROracle appears to have $R_HOME/include.
So I'm missing something.

When 2.3.0 is nearer release this will need to go into the update notes.

> Makefiles. I was just about to mail their maintainers suggesting an
> alternative when I noticed that that R (2.2.1) has it wrong too:
>
> 	edd at basebud:~> R CMD config --cppflags
> 	-I/usr/lib/R/include
>
> Should I patch this at my end with a softlink
>
> 	/usr/share/R/include -> /usr/lib/R/include
>
> or should that be fixed in R? For the record, I configure'd with
>
> 	--datadir=/usr/share/R/share	\
> 	--includedir=/usr/share/R/include	\
>
> so that I get told about '-I/usr/lib/R/include' is probably a bug. Indeed,
> src/script/config has an unconditional
>
>    --cppflags)
>      if test -z "${LIBR}"; then
>        echo "R was not built as a shared library" >&2
>      else
>        echo "-I${R_HOME}/include"
>      fi
>      exit 0
>
> so this should probably get autoconf'ed as well.

It should just need the right environment variables.

>  R.sh.in may be in the same
> boat.
>
> I apologise in advance for not checking with R-devel which I don't have handy
> at home right now...
>
> Regards, Dirk
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Mon Feb 20 15:53:43 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 20 Feb 2006 09:53:43 -0500
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
Message-ID: <DE3E9FD7-2AC8-4864-99E3-E6C7D504190D@r-project.org>


On Feb 20, 2006, at 9:45 AM, Prof Brian Ripley wrote:

> Dirk,
>
> It was even more wrong in R-devel, for there we have sub- 
> architectures and
> it needs to be "-I${R_INCLUDE_DIR} -I${R_INCLUDE_DIR}${R_ARCH}".
> Fixed now, thanks.
>
> I don't think there is any problem in R.sh.in.
>
> Brian
>
> On Mon, 20 Feb 2006, Dirk Eddelbuettel wrote:
>
>>
>> As you may recall, a Debian user complained last year about how R  
>> is out of
>> line with respect to the filesystem standards (where, in essence,
>> architecture independent files should be in /usr/share, not /usr/ 
>> lib).

Just curious - does that mean that ${R_INCLUDE_DIR}${R_ARCH} should  
actually be somewhere else than in ${R_INCLUDE_DIR}, because strictly  
speaking it is not architecture independent? It seems to me that  
would just make things even more messy, and I'm wondering what Debian  
does in that case ... In fact I can't even find examples for either  
on my Debian machines (except for Sun's Java which seems to use /usr/ 
lib as R used to) ...

Cheers,
Simon


From rkoenker at uiuc.edu  Mon Feb 20 16:45:22 2006
From: rkoenker at uiuc.edu (roger koenker)
Date: Mon, 20 Feb 2006 09:45:22 -0600
Subject: [Rd] Matrix / SparseM conflict (PR#8618)
In-Reply-To: <Pine.LNX.4.64.0602201409480.28459@gannet.stats.ox.ac.uk>
References: <20060220135453.F08793F201@slim.kubism.ku.dk>
	<43F9CCB8.9030808@stats.uwo.ca>
	<Pine.LNX.4.64.0602201409480.28459@gannet.stats.ox.ac.uk>
Message-ID: <2EECC209-3A37-44E7-9518-69CAFD48D6CC@uiuc.edu>

On Feb 20, 2006, at 8:29 AM, Prof Brian Ripley wrote:

> On Mon, 20 Feb 2006, Duncan Murdoch wrote:
>
>> On 2/20/2006 8:54 AM, dpleydel at univ-fcomte.fr wrote:
>>> Full_Name: David Pleydell
>>> Version: 2.2.1
>>> OS: Debian Etch
>>> Submission from: (NULL) (193.55.70.206)
>>>
>>>
>>> There appears to be a conflict between the chol functions from  
>>> the Matrix and
>>> the SparseM packages. chol() can only be applied to a matrix of  
>>> class dspMatrix
>>> if SparseM is not in the path.
>>
>> This isn't a bug, it's simply that both Matrix and SparseM define a
>> generic for chol (though Matrix actually gets it by converting the
>> function in base).
>
> The problem appears to be that SparseM first redefines chol as an  
> S3 generic and then defines S4 methods on it.  As no new S3 methods  
> are then defined the S3 step would seem unnecessary, but it is used  
> to allow the package to define S4 methods on a different signature  
> from R's chol().
> (That seems to me to be asking for trouble.)
>
> Only the package maintainer of SparseM can do anything about this.

I'm happy to modify this, but would welcome advice.  The current  
snafu is a consequence of writing a first
version of SparseM with S3 methods and then converting (evidently  
incompletely) to S4.
>
> Beyond, that I guess it is a consequence of namespaces that Matrix  
> defines methods via a derived generic on base::chol and not on the  
> generic chol in SparseM.  That needs further thought by someone  
> (JMC?) who understands the S4 internals.
>
>> If you want access to the version in Matrix after attaching SparseM
>> ahead of it in the search path, use Matrix::chol.
>
> But the whole point of generic functions is to allow one to write  
> generic code.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Mon Feb 20 17:22:04 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 20 Feb 2006 10:22:04 -0600
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
Message-ID: <17401.60588.104174.467342@basebud.nulle.part>


		(resending, had the CC header foobar'ed. My bad --Dirk)

Brian, Simon,

On 20 February 2006 at 14:45, Prof Brian Ripley wrote:
| Dirk,
| 
| It was even more wrong in R-devel, for there we have sub-architectures and 
| it needs to be "-I${R_INCLUDE_DIR} -I${R_INCLUDE_DIR}${R_ARCH}".
| Fixed now, thanks.

Excellent, thanks.

| I don't think there is any problem in R.sh.in.

Possibly a false alert, I was just grepping for R_HOME_DIR/include. Sorry
about that.

| > I was updated a number of packages for Quantian yesterday and noticed that
| > (at least) two packages had hard-coded links to $R_HOME/include in their
| 
| Well, only 5 CRAN packages have a src/Makefile, and one other has 
| src/Makefile.in.  Of those only ROracle appears to have $R_HOME/include.
| So I'm missing something.

As you asked, the two failure were gnomeGUI which has a hardcoded
$R_HOME/include which could get fixed, and JGR which isn't even on CRAN....
I didn't rebuild everything, and I never touch ROracle for lack of Oracle
headers and backends here at home.

JGR also calls out to /usr/lib/R/share/sh/help-links.sh which is probably not
a good idea given that we have that in /usr/share/R/share/sh/help-links.sh
instead.  Given the trouble we had in Debian from calling its sibbling
/usr/share/R/share/perl/build-help.pl, I put in a kludge for that, but maybe
we should work how JGR can get this functionality via actually exported calls
(as you rightly told me that never that /usr/share/R/share/perl/build-help.pl
was not meant to be called directly).

That said, having JGR in Quantian is very nice ==:-)

| When 2.3.0 is nearer release this will need to go into the update notes.

Ok.

Thanks, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From simon.urbanek at r-project.org  Mon Feb 20 17:31:46 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 20 Feb 2006 11:31:46 -0500
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <17401.60588.104174.467342@basebud.nulle.part>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
	<17401.60588.104174.467342@basebud.nulle.part>
Message-ID: <3999B172-8A10-442E-B924-0D291CFB0C15@r-project.org>

Dirk,

On Feb 20, 2006, at 11:22 AM, Dirk Eddelbuettel wrote:

> As you asked, the two failure were gnomeGUI which has a hardcoded  
> $R_HOME/include which could get fixed, and JGR which isn't even on  
> CRAN....

Thanks for pointing this out. JGR is a completely different beast and  
unfortunately it has to hard-code things, because it is not started  
via R CMD, so it doesn't know the right paths. For non-framework  
unix, however, we can do better, because JRI now uses autoconf, so it  
can pull the paths from R at configure time.  I'll fix JRI  
correspondingly.

> JGR also calls out to /usr/lib/R/share/sh/help-links.sh which is  
> probably not a good idea given that we have that in /usr/share/R/ 
> share/sh/help-links.sh instead.  Given the trouble we had in Debian  
> from calling its sibbling /usr/share/R/share/perl/build-help.pl, I  
> put in a kludge for that, but maybe we should work how JGR can get  
> this functionality via actually exported calls (as you rightly told  
> me that never that /usr/share/R/share/perl/build-help.pl was not  
> meant to be called directly).
>

Another hack I suspect, but I'll have to ask Markus about this one.

Thanks,
Simon


From ripley at stats.ox.ac.uk  Mon Feb 20 17:56:47 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 16:56:47 +0000 (GMT)
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <17401.59202.174654.582346@basebud.nulle.part>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
	<17401.59202.174654.582346@basebud.nulle.part>
Message-ID: <Pine.LNX.4.64.0602201654260.11837@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Dirk Eddelbuettel wrote:

>
> Brian, Simon,
>
> On 20 February 2006 at 14:45, Prof Brian Ripley wrote:
> | Dirk,
> |
> | It was even more wrong in R-devel, for there we have sub-architectures and
> | it needs to be "-I${R_INCLUDE_DIR} -I${R_INCLUDE_DIR}${R_ARCH}".
> | Fixed now, thanks.
>
> Excellent, thanks.
>
> | I don't think there is any problem in R.sh.in.
>
> Possibly a false alert, I was just grepping for R_HOME_DIR/include. Sorry
> about that.
>
> | > I was updated a number of packages for Quantian yesterday and noticed that
> | > (at least) two packages had hard-coded links to $R_HOME/include in their
> |
> | Well, only 5 CRAN packages have a src/Makefile, and one other has
> | src/Makefile.in.  Of those only ROracle appears to have $R_HOME/include.
> | So I'm missing something.
>
> As you asked, the two failure were gnomeGUI which has a hardcoded
> $R_HOME/include which could get fixed, and JGR which isn't even on CRAN....
> I didn't rebuild everything, and I never touch ROracle for lack of Oracle
> headers and backends here at home.

gnomeGUI is under revision.  There is one version in 2.3.0/Other on CRAN, 
but there will be another before release.  As you may have noticed, there 
never was a 2.2.0 version so it is still on -2.1.0.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Mon Feb 20 18:01:24 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 20 Feb 2006 11:01:24 -0600
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <3999B172-8A10-442E-B924-0D291CFB0C15@r-project.org>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
	<17401.60588.104174.467342@basebud.nulle.part>
	<3999B172-8A10-442E-B924-0D291CFB0C15@r-project.org>
Message-ID: <17401.62948.818551.564413@basebud.nulle.part>


Simon, Markus,

On 20 February 2006 at 11:31, Simon Urbanek wrote:
| Dirk,
| 
| On Feb 20, 2006, at 11:22 AM, Dirk Eddelbuettel wrote:
| 
| > As you asked, the two failure were gnomeGUI which has a hardcoded  
| > $R_HOME/include which could get fixed, and JGR which isn't even on  
| > CRAN....
| 
| Thanks for pointing this out. JGR is a completely different beast and  
| unfortunately it has to hard-code things, because it is not started  
| via R CMD, so it doesn't know the right paths. For non-framework  

Good point.

| unix, however, we can do better, because JRI now uses autoconf, so it  
| can pull the paths from R at configure time.  I'll fix JRI  
| correspondingly.

Right. Generally speaking, it built like a charm, very impressive. There is
other small gotcha. I used the .deb packages sun-j2se5.0-jdk-binary and
sun-j2se5.0-jre-binary which may do things differently from other JRE/JDK. In
any event JGR came with 
  /usr/lib/j2se5.0-sun//bin/java -cp JGR.jar:. -Xmx512m org.rosuda.JGR.JGR $*
but the path ought to be /usr/lib/j2se5.0-sun/jre/bin/java (with an added
jre).  Not sure if this is worth worrying about.
| 
| > JGR also calls out to /usr/lib/R/share/sh/help-links.sh which is  
| > probably not a good idea given that we have that in /usr/share/R/ 
| > share/sh/help-links.sh instead.  Given the trouble we had in Debian  
| > from calling its sibbling /usr/share/R/share/perl/build-help.pl, I  
| > put in a kludge for that, but maybe we should work how JGR can get  
| > this functionality via actually exported calls (as you rightly told  
| > me that never that /usr/share/R/share/perl/build-help.pl was not  
| > meant to be called directly).
| >
| 
| Another hack I suspect, but I'll have to ask Markus about this one.

Can you let R's code from help.start() do the work for you?  Would be cleaner
than trying to guess where the scripts are hiding. And to Brian's point, they
shouldn't get called directly in the first place...

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ripley at stats.ox.ac.uk  Mon Feb 20 18:09:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 17:09:08 +0000 (GMT)
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <DE3E9FD7-2AC8-4864-99E3-E6C7D504190D@r-project.org>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
	<DE3E9FD7-2AC8-4864-99E3-E6C7D504190D@r-project.org>
Message-ID: <Pine.LNX.4.64.0602201458300.18227@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Simon Urbanek wrote:

>
> On Feb 20, 2006, at 9:45 AM, Prof Brian Ripley wrote:
>
>> Dirk,
>> 
>> It was even more wrong in R-devel, for there we have sub-architectures and
>> it needs to be "-I${R_INCLUDE_DIR} -I${R_INCLUDE_DIR}${R_ARCH}".
>> Fixed now, thanks.
>> 
>> I don't think there is any problem in R.sh.in.
>> 
>> Brian
>> 
>> On Mon, 20 Feb 2006, Dirk Eddelbuettel wrote:
>> 
>>> 
>>> As you may recall, a Debian user complained last year about how R is out 
>>> of
>>> line with respect to the filesystem standards (where, in essence,
>>> architecture independent files should be in /usr/share, not /usr/lib).

/usr/share is for `architecture independent _data_' according to the 
self-styled Filesystem Hierarchy Standard.  It mentions using include for 
header files, but not that they should be `architecture independent'.

> Just curious - does that mean that ${R_INCLUDE_DIR}${R_ARCH} should actually 
> be somewhere else than in ${R_INCLUDE_DIR}, because strictly speaking it is 
> not architecture independent? It seems to me that would just make things even 
> more messy, and I'm wondering what Debian does in that case ... In fact I 
> can't even find examples for either on my Debian machines (except for Sun's 
> Java which seems to use /usr/lib as R used to) ...

I suspect on Debian the R include files actually are arch-independent. 
(The main reason that they might not be is different configuration 
options.  Suppose for a real example that you only had a 32-bit libintl on 
Sparc: then the system libintl.h is only relevant to a 32- and not a 
64-bit build, and so libintl.h needs to get installed in include/sparcv9, 
only.)  But I think the point is that /usr/share and /usr/doc may get 
shared, whereas /usr/include will not. As I recall, using R_INCLUDE_DIR 
was our idea.

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Mon Feb 20 19:15:18 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 20 Feb 2006 13:15:18 -0500
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <17401.62948.818551.564413@basebud.nulle.part>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
	<17401.60588.104174.467342@basebud.nulle.part>
	<3999B172-8A10-442E-B924-0D291CFB0C15@r-project.org>
	<17401.62948.818551.564413@basebud.nulle.part>
Message-ID: <12229378-F4A0-43ED-81CE-0B1B7AB6D790@r-project.org>


On Feb 20, 2006, at 12:01 PM, Dirk Eddelbuettel wrote:

> There is other small gotcha. I used the .deb packages sun-j2se5.0- 
> jdk-binary and sun-j2se5.0-jre-binary which may do things  
> differently from other JRE/JDK. In any event JGR came with
>   /usr/lib/j2se5.0-sun//bin/java -cp JGR.jar:. -Xmx512m  
> org.rosuda.JGR.JGR $*
> but the path ought to be /usr/lib/j2se5.0-sun/jre/bin/java (with an  
> added jre).  Not sure if this is worth worrying about.


This is determined from the system, so the jre package should make  
sure its "java" is picked first, otherwise you're creating a  
dependency on jdk - i.e. make sure your jre/bin comes before jdk's  
bin in PATH and everything should be fine.

A special case is when JAVA_HOME is set - I have updated JRI such  
that it will try ${JAVA_HOME}/jre/bin before ${JAVA_HOME}/bin in such  
case.

> | Another hack I suspect, but I'll have to ask Markus about this one.
>
> Can you let R's code from help.start() do the work for you?

Maybe - Markus, can you have a look or should I do it? I didn't see  
the JGR help code for a while, but I remember some overhaul was due -  
switching to help objects should possibly solve the whole issue,  
because R will handle all the paths then.

Cheers,
Simon


From edd at debian.org  Mon Feb 20 20:07:58 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 20 Feb 2006 13:07:58 -0600
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <12229378-F4A0-43ED-81CE-0B1B7AB6D790@r-project.org>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
	<17401.60588.104174.467342@basebud.nulle.part>
	<3999B172-8A10-442E-B924-0D291CFB0C15@r-project.org>
	<17401.62948.818551.564413@basebud.nulle.part>
	<12229378-F4A0-43ED-81CE-0B1B7AB6D790@r-project.org>
Message-ID: <17402.5006.879696.341356@basebud.nulle.part>


On 20 February 2006 at 13:15, Simon Urbanek wrote:
| 
| On Feb 20, 2006, at 12:01 PM, Dirk Eddelbuettel wrote:
| 
| > There is other small gotcha. I used the .deb packages sun-j2se5.0- 
| > jdk-binary and sun-j2se5.0-jre-binary which may do things  
| > differently from other JRE/JDK. In any event JGR came with
| >   /usr/lib/j2se5.0-sun//bin/java -cp JGR.jar:. -Xmx512m  
| > org.rosuda.JGR.JGR $*
| > but the path ought to be /usr/lib/j2se5.0-sun/jre/bin/java (with an  
| > added jre).  Not sure if this is worth worrying about.
| 
| 
| This is determined from the system, so the jre package should make  
| sure its "java" is picked first, otherwise you're creating a  
| dependency on jdk - i.e. make sure your jre/bin comes before jdk's  
| bin in PATH and everything should be fine.

Precisely -- The trivial shell script I wrote actually calls

    cd /opt/JGR-1.3 && java -cp JGR.jar:. -Xmx512m org.rosuda.JGR.JGR $*

as 'java' is handled The Right Way (TM) by Debian's update-alternatives(8). 
However, your Makefile doesn't know that and I was merely pointing out that 
it pasted together a wrong path using the information it otherwise used
rather successfully to build the beast.

| A special case is when JAVA_HOME is set - I have updated JRI such  
| that it will try ${JAVA_HOME}/jre/bin before ${JAVA_HOME}/bin in such  
| case.

Exactly, that would do it !

Thanks,  Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From roebuck at mdanderson.org  Mon Feb 20 20:46:42 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 20 Feb 2006 13:46:42 -0600 (CST)
Subject: [Rd] invalid graphics state using dev.print (fwd)
In-Reply-To: <Pine.LNX.4.64.0602200714030.3798@gannet.stats.ox.ac.uk>
References: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>
	<17388.51930.273876.336070@stat.math.ethz.ch>
	<43F92420.4070706@stat.auckland.ac.nz>
	<Pine.LNX.4.64.0602200714030.3798@gannet.stats.ox.ac.uk>
Message-ID: <Pine.OSF.4.58.0602201205190.67951@wotan.mdacc.tmc.edu>

On Mon, 20 Feb 2006, Prof Brian Ripley wrote:

> On Mon, 20 Feb 2006, Paul Murrell wrote:
>
> [...]
>
> >>    >> x11()
> >>    >> plot(rnorm(10))
> >>    >> dev.print(png)
>
> >>     Paul> Error in dev.copy(device = function (filename = "Rplot%03d.png", width =
> >>     Paul> 480,  :
> >>     Paul> invalid graphics state
>
> > I think the problem is that the width and height of the PNG device is
> > being taken (without regard for units) from the X11 device.  So
> > approximately 7 inches square screen window gets drawn into
> > approximately 7 *pixel* square PNG file and (understandably) R complains
> > that there is not enough room for the plot.
>
> Yes, that it how it is documented to work.

Might have snapped to this if the error message had said something
less vague.

> > Another workaround is something like ...
> >
> > dev.print(png, width=480, height=480)
>
> (Just one will do if you want to preserve the aspect ratio.)
>
> > ... and a fix requires making dev.print() smarter so that it figures out
> > that it needs to convert width/height from inches to pixels.
>
> I don't think there is a way to do that unambiguously (there is no
> standard way to do the conversion)

What is the recommended method of converting width/height
from inches to pixels (preserving aspect ratio), even if
ambiguous?

> ..., and in any case dev.print() was passed
> a function, not the name of a function, and so does not in general know
> how it behaves (and your 'png' need not be R's png()).
>
> All we can do is to re-emphasize this on the help page, and add a warning
> if a known bitmap device is detected (possibly inaccurately) by name.

Perhaps an extra attribute could be added to each device
where attr("type") = c("bitmap", "vector")

> str(dev.cur())
 Named int 2
 - attr(*, "names")= chr "quartz"
 - attr(*, "type")= chr "vector"

> BTW, I think it was perverse to call dev.print() except to do printing.

I was making a hardcopy of my plot which IMO would seem
a legitimate usage. Don't understand your "perverse"
comment here. Alternative recommendation?

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From edd at debian.org  Mon Feb 20 22:04:08 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 20 Feb 2006 15:04:08 -0600
Subject: [Rd] R CMD config --cppflags buglet
In-Reply-To: <17402.5006.879696.341356@basebud.nulle.part>
References: <17401.53474.442624.424119@basebud.nulle.part>
	<Pine.LNX.4.64.0602201431330.28459@gannet.stats.ox.ac.uk>
	<17401.60588.104174.467342@basebud.nulle.part>
	<3999B172-8A10-442E-B924-0D291CFB0C15@r-project.org>
	<17401.62948.818551.564413@basebud.nulle.part>
	<12229378-F4A0-43ED-81CE-0B1B7AB6D790@r-project.org>
	<17402.5006.879696.341356@basebud.nulle.part>
Message-ID: <17402.11976.86597.521460@basebud.nulle.part>


On 20 February 2006 at 13:07, Dirk Eddelbuettel wrote:
| Precisely -- The trivial shell script I wrote actually calls
| 
|     cd /opt/JGR-1.3 && java -cp JGR.jar:. -Xmx512m org.rosuda.JGR.JGR $*
| 
| as 'java' is handled The Right Way (TM) by Debian's update-alternatives(8). 

That came out wrong. I meant to say something like 

	"the trivial addition I made to your run script to create a
	 /usr/local/bin/jgr as the following last line instead:"

The script is otherwise unaltered. Sorry for not being clearer in the first
place. 

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From jmc at r-project.org  Mon Feb 20 23:03:32 2006
From: jmc at r-project.org (John Chambers)
Date: Mon, 20 Feb 2006 14:03:32 -0800
Subject: [Rd] changes in r-devel for S3/S4 objects
Message-ID: <43FA3CB4.5020705@r-project.org>

Two recent changes have been committed to r-devel, related to 
discussions on this list earlier:

1.  setOldClass() has an argument prototype= to specify the default 
object for the class.  If provided, the S3 class can be a slot in an S4 
class, with a valid default object.

(It's still not going to work well to have an S3 non-virtual class as a 
superclass of an S4 class.  See the setOldClass help page.)

2.  There is a heuristic test for S4 objects, seemsS4Object(), and a 
corresponding C-level test, R_seemsS4Object(object), both using the 
existence of a "package" attribute on  class(object) as a test.

The test is called seemsS4Object() rather than isS4Object() 
deliberately, but it should be fairly accurate.

It will mistakenly identify an S3 object as S4 if the package attribute 
is there (possible, but hard to see why anyone would do this).
It can make the opposite mistake, though, UNLESS the package generating 
the object is reinstalled with the current version of R, because older 
versions failed to put the attribute on some of the basic S4 classes 
(esp. classRepresentation).

This is not by itself the right test for intercepting S3 code for 
certain primitives (c(), match(), [, for example), as was being 
discussed earlier.  Only S4 objects that do not inherit from "vector" 
should be blocked.  So the suitable test, in R code, is something like:
  if(seemsS4Object(x) && !is(x, "vector"))


From roebuck at mdanderson.org  Tue Feb 21 00:13:24 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 20 Feb 2006 17:13:24 -0600 (CST)
Subject: [Rd] [REQ] Add Title Argument for Interactive Devices
Message-ID: <Pine.OSF.4.58.0602201636140.79424@wotan.mdacc.tmc.edu>

As a generic capability, would it be possible for all
known interactive devices (x11, windows, quartz) to have
a title argument that could be displayed in their titlebar
when invoked?

Sounds like a roundabout means of doing so for x11() may
be possible in R-2.3 via X resources.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From ross at biostat.ucsf.edu  Tue Feb 21 01:18:18 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 20 Feb 2006 16:18:18 -0800
Subject: [Rd] profiling C code
Message-ID: <20060221001818.GA12976@wheat.betterworld.us>

Does anyone have any advice about profiling C/C++ code in a package
under R?  Does R need to be built specially for this to work?

The FAQ has some entries about profiling but they cover R level
profiling; I'm try to get at the C++ code I've written that is called
from R.

Primary target is Mac OS X.

Thanks.

Ross Boylan


From andy_liaw at merck.com  Tue Feb 21 04:23:47 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 20 Feb 2006 22:23:47 -0500
Subject: [Rd] profiling C code
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>

The last time I tried I didn't have much luck.  The gprof manual I could
find seems to indicate that it can not profile code that are dynamically
loaded.  (I was trying on Linux.)  The R source seems to hint otherwise.
I'd very much appreciate pointers as well.

Andy

From: Ross Boylan
> 
> Does anyone have any advice about profiling C/C++ code in a package
> under R?  Does R need to be built specially for this to work?
> 
> The FAQ has some entries about profiling but they cover R level
> profiling; I'm try to get at the C++ code I've written that is called
> from R.
> 
> Primary target is Mac OS X.
> 
> Thanks.
> 
> Ross Boylan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From kriegstn at yahoo.de  Tue Feb 21 05:42:45 2006
From: kriegstn at yahoo.de (Bernd Kriegstein)
Date: Tue, 21 Feb 2006 05:42:45 +0100 (CET)
Subject: [Rd] simple C function segfaults
Message-ID: <20060221044245.33844.qmail@web27412.mail.ukl.yahoo.com>

Hello,

I use the simplest of examples that somebody can think
of in order to generate a matrix of random numbers
from within C, calling appropriate R functions. The
concrete example is below:

--- file pico.c

#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <R.h>
#include <Rmath.h>

#define COLM( i, j, m ) ( m*j + i)

void pico ( double *y, int n, int m ) {
        int i, j;
        GetRNGstate();
        for ( i=0; i<n; i++ ) {
                for ( j=0; j<m; j++ ) {
                        y[ COLM( i,j,m ) ] = rnorm( 0,
1 );
                }
        }
        PutRNGstate();
}
---------


--- file pico.R

dyn.load("pico.so");
if( is.loaded( symbol.C( "pico" ) ) )
n<-10; m<-5;
y<-matrix( 0, n, m );
a<- .C( "pico", as.double(y), as.integer(n),
as.integer(m) );

-----

The code, when executed within R, gives a segmentation
fault. I looked at the writing R extensions, but not
much can be inferred from there on the subject. In
fact, I would be indebted if I could have a pointer to
a beginnner's guide to the R API.

Thank you for any answers,

- b.

PS. if this is not the appropriate section of R
maillists that this post should be in, I apologise in advance.


From berwin at maths.uwa.edu.au  Tue Feb 21 06:03:08 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 21 Feb 2006 13:03:08 +0800
Subject: [Rd] simple C function segfaults
In-Reply-To: <20060221044245.33844.qmail@web27412.mail.ukl.yahoo.com>
References: <20060221044245.33844.qmail@web27412.mail.ukl.yahoo.com>
Message-ID: <17402.40716.876104.217975@bossiaea.maths.uwa.edu.au>

>>>>> "BK" == Bernd Kriegstein <kriegstn at yahoo.de> writes:

    BK> void pico ( double *y, int n, int m )
                               ^^^^^^^^^^^^^
Everything is passed from R to C as pointer, so these should be
pointers.

Hope this helps.

Cheers,

        Berwin


From kriegstn at yahoo.de  Tue Feb 21 06:08:54 2006
From: kriegstn at yahoo.de (Bernd Kriegstein)
Date: Tue, 21 Feb 2006 06:08:54 +0100 (CET)
Subject: [Rd] simple C function segfaults
In-Reply-To: <17402.40716.876104.217975@bossiaea.maths.uwa.edu.au>
Message-ID: <20060221050854.34720.qmail@web27410.mail.ukl.yahoo.com>

Berwin thanks, I tried that, but it didn't work. There
is a conflict in using a pointer for the operation
defined in the #define. The error message is:

pico.c:17: warning: comparison between pointer and
integer

Suppose that I use pointers for n and m. What should I
alter in the program in order for the column-major
mode index in the #define to work?

Thanks,

- b.

--- Berwin A Turlach <berwin at maths.uwa.edu.au>
schrieb:

> >>>>> "BK" == Bernd Kriegstein <kriegstn at yahoo.de>
> writes:
> 
>     BK> void pico ( double *y, int n, int m )
>                                ^^^^^^^^^^^^^
> Everything is passed from R to C as pointer, so
> these should be
> pointers.
> 
> Hope this helps.
> 
> Cheers,
> 
>         Berwin
> 
>


From roebuck at mdanderson.org  Tue Feb 21 07:14:37 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Tue, 21 Feb 2006 00:14:37 -0600 (CST)
Subject: [Rd] simple C function segfaults
In-Reply-To: <20060221044245.33844.qmail@web27412.mail.ukl.yahoo.com>
References: <20060221044245.33844.qmail@web27412.mail.ukl.yahoo.com>
Message-ID: <Pine.OSF.4.58.0602202348210.91966@wotan.mdacc.tmc.edu>

On Tue, 21 Feb 2006, Bernd Kriegstein wrote:

> I use the simplest of examples that somebody can think
> of in order to generate a matrix of random numbers
> from within C, calling appropriate R functions. The
> concrete example is below:
> [SNIP]

------ pico.c --------
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <R.h>
#include <Rmath.h>

#define COLM(i,j,m) ((m * j) + i)

void pico(double *y, int *n, int *m) {
    register int i;

    GetRNGstate();
    for (i = 0; i < *n; i++) {
        register int j;

        for (j = 0; j < *m; j++) {
            y[COLM(i,j,*m)] = rnorm(0.0, 1.0);
        }
    }
    PutRNGstate();
}

------ pico.R --------
dyn.load("pico.so")
n <- 10
m <- 5
ans <- .C("pico",
          as.double(matrix(0, n, m)),
          as.integer(n),
          as.integer(m))
str(ans[[1]])

----------------------

$ R CMD SHLIB pico.c
$ R --vanilla < pico.R

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Feb 21 08:28:32 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 21 Feb 2006 08:28:32 +0100 (CET)
Subject: [Rd] profiling C code
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.64.0602210825150.29020@artemis.imbe.med.uni-erlangen.de>


On Mon, 20 Feb 2006, Liaw, Andy wrote:

> The last time I tried I didn't have much luck.  The gprof manual I could
> find seems to indicate that it can not profile code that are dynamically
> loaded.  (I was trying on Linux.)  The R source seems to hint otherwise.
> I'd very much appreciate pointers as well.
>

I happily use `oprofile' (web page at http://oprofile.sourceforge.net/) 
for profiling shared libs. You simply start a daemon, run your R code, 
and get the results. `opannotate' labels lines in C source files with the 
corresponding systime, very very cute.

Best,

Torsten

> Andy
>
> From: Ross Boylan
>>
>> Does anyone have any advice about profiling C/C++ code in a package
>> under R?  Does R need to be built specially for this to work?
>>
>> The FAQ has some entries about profiling but they cover R level
>> profiling; I'm try to get at the C++ code I've written that is called
>> from R.
>>
>> Primary target is Mac OS X.
>>
>> Thanks.
>>
>> Ross Boylan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Tue Feb 21 08:40:06 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 07:40:06 +0000 (GMT)
Subject: [Rd] profiling C code
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.64.0602210720001.30643@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Liaw, Andy wrote:

> The last time I tried I didn't have much luck.  The gprof manual I could
> find seems to indicate that it can not profile code that are dynamically
> loaded.  (I was trying on Linux.)  The R source seems to hint otherwise.

grof is not mentioned in any of the R manuals, so what are your referring 
to?  (R-admin talks about `to compile a profiling version of R', not of 
shared libraries.)

> I'd very much appreciate pointers as well.

You need to use sprof rather than gprof.  Here's one relevant thread:

http://tolstoy.newcastle.edu.au/~rking/R/devel/05/02/2351.html

and I am pretty sure there have been others.

Linux has very sketchy info on sprof.  However,

http://people.redhat.com/drepper/dsohowto.pdf

has some.  I've thought about putting something about this in the
R-exts manual


>
> Andy
>
> From: Ross Boylan
>>
>> Does anyone have any advice about profiling C/C++ code in a package
>> under R?  Does R need to be built specially for this to work?
>>
>> The FAQ has some entries about profiling but they cover R level
>> profiling; I'm try to get at the C++ code I've written that is called
>> from R.
>>
>> Primary target is Mac OS X.
>>
>> Thanks.
>>
>> Ross Boylan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Tue Feb 21 15:51:06 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 21 Feb 2006 14:51:06 +0000
Subject: [Rd] invalid graphics state using dev.print (fwd)
In-Reply-To: <Pine.LNX.4.64.0602200833030.4588@gannet.stats.ox.ac.uk>
References: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>	<17388.51930.273876.336070@stat.math.ethz.ch>	<43F92420.4070706@stat.auckland.ac.nz>	<Pine.LNX.4.64.0602200714030.3798@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602200833030.4588@gannet.stats.ox.ac.uk>
Message-ID: <43FB28DA.4080708@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> On Mon, 20 Feb 2006, Prof Brian Ripley wrote:
> 
>>On Mon, 20 Feb 2006, Paul Murrell wrote:
<snipped>
>>>>  >> x11()
>>>>  >> plot(rnorm(10))
>>>>  >> dev.print(png)
<snipped>
>>I don't think there is a way to do that unambiguously (there is no
>>standard way to do the conversion), and in any case dev.print() was passed
>>a function, not the name of a function, and so does not in general know
>>how it behaves (and your 'png' need not be R's png()).

There is a "standard" way of querying the X display directly about
the size each pixel supposedly represents - well, an X display can
be configured wrongly, etc, but you get what you ask for...

$ xdpyinfo |grep 'resolution'
   resolution:    75x75 dots per inch

(this 75x75 seems to be a default value as I did not set it anywhere,
but I believe it is configurable)

I am not sure about png files, but tiff files also have internal data
claiming x pixels corresponds to y inches. (and I am fairly sure jpeg
does *not* have this feature).

HTL


From ripley at stats.ox.ac.uk  Tue Feb 21 15:55:04 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 14:55:04 +0000 (GMT)
Subject: [Rd] invalid graphics state using dev.print (fwd)
In-Reply-To: <43FB28DA.4080708@cimr.cam.ac.uk>
References: <Pine.OSF.4.58.0602081515590.512812@wotan.mdacc.tmc.edu>
	<17388.51930.273876.336070@stat.math.ethz.ch>
	<43F92420.4070706@stat.auckland.ac.nz>
	<Pine.LNX.4.64.0602200714030.3798@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602200833030.4588@gannet.stats.ox.ac.uk>
	<43FB28DA.4080708@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0602211447310.9240@gannet.stats.ox.ac.uk>

On Tue, 21 Feb 2006, Hin-Tak Leung wrote:

> Prof Brian Ripley wrote:
>> On Mon, 20 Feb 2006, Prof Brian Ripley wrote:
>> 
>>> On Mon, 20 Feb 2006, Paul Murrell wrote:
> <snipped>
>>>>>  >> x11()
>>>>>  >> plot(rnorm(10))
>>>>>  >> dev.print(png)
> <snipped>
>>> I don't think there is a way to do that unambiguously (there is no
>>> standard way to do the conversion), and in any case dev.print() was passed
>>> a function, not the name of a function, and so does not in general know
>>> how it behaves (and your 'png' need not be R's png()).
>
> There is a "standard" way of querying the X display directly about
> the size each pixel supposedly represents - well, an X display can
> be configured wrongly, etc, but you get what you ask for...
>
> $ xdpyinfo |grep 'resolution'
>  resolution:    75x75 dots per inch
>
> (this 75x75 seems to be a default value as I did not set it anywhere,
> but I believe it is configurable)

Yes, but this is png, not X11.  The resolution of your X11 screen is 
unrelated to a .png file you might produce.

> I am not sure about png files, but tiff files also have internal data
> claiming x pixels corresponds to y inches. (and I am fairly sure jpeg
> does *not* have this feature).

Reading the help page for the R devices will enlighten you.  (Really, you 
should do so before posting as we do ask.)  An assumption of 72ppi is 
quite common, but so are 180 and 300.

The png/jpeg devices now tell careless users that small width/height 
values are probably a mistake.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Tue Feb 21 16:50:39 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 21 Feb 2006 07:50:39 -0800 (PST)
Subject: [Rd] profiling C code
In-Reply-To: <20060221001818.GA12976@wheat.betterworld.us>
References: <20060221001818.GA12976@wheat.betterworld.us>
Message-ID: <Pine.LNX.4.64.0602210748540.1702@homer24.u.washington.edu>

On Mon, 20 Feb 2006, Ross Boylan wrote:

> Does anyone have any advice about profiling C/C++ code in a package
> under R?  Does R need to be built specially for this to work?
>
> The FAQ has some entries about profiling but they cover R level
> profiling; I'm try to get at the C++ code I've written that is called
> from R.
>
> Primary target is Mac OS X.

Under OS X I use 'sample', which doesn't require any recompiling (or 
Sampler.app, which is a GUI version)

 	-thomas

>
> Thanks.
>
> Ross Boylan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ripley at stats.ox.ac.uk  Tue Feb 21 18:40:19 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 17:40:19 +0000 (GMT)
Subject: [Rd] profiling C code
In-Reply-To: <Pine.LNX.4.64.0602210720001.30643@gannet.stats.ox.ac.uk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>
	<Pine.LNX.4.64.0602210720001.30643@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602211551440.11480@gannet.stats.ox.ac.uk>

Some more information.

1) Whether gprof works is system-specific.  Solaris says in man gprof

   64-bit profiling
      64-bit profiling may be used freely with dynamically  linked
      executables,  and profiling information is collected for the
      shared objects if the objects are  compiled  for  profiling.

   32-bit profiling
      32-bit profiling may be used with dynamically linked execut-
      ables, but care must be applied. In 32-bit profiling, shared
      objects cannot be profiled with gprof.

As usual, Linux seems not to give such details (or if it does, please 
point me at them).

2) Here is an example of using sprof.  I needed to be root to create 
some directories:

% mkdir -p /var/tmp//users/ripley/R/R-devel/library/stats/libs
% chown -R ripley:bdr /var/tmp//users/ripley
% setenv LD_PROFILE /users/ripley/R/R-devel/library/stats/libs/stats.so

% R
> example(smooth.spline)
> q()

% sprof /users/ripley/R/R-devel/library/stats/libs/stats.so \
/var/tmp/users/ripley/R/R-devel/library/stats/libs/stats.so.profile

Flat profile:

Each sample counts as 0.01 seconds.
   %   cumulative   self              self     total
  time   seconds   seconds    calls  us/call  us/call  name
100.00      0.01     0.01     2914     3.43           bsplvb_
   0.00      0.01     0.00     2261     0.00           bvalue_
   0.00      0.01     0.00     2186     0.00           bsplvd_
   0.00      0.01     0.00       91     0.00           sinerp_
   0.00      0.01     0.00       91     0.00           sslvrg_
   0.00      0.01     0.00        9     0.00           sbart_
   0.00      0.01     0.00        9     0.00           sgram_
   0.00      0.01     0.00        9     0.00           stxwx_
...

If you are running Linux, Torsten's suggestion of oprofile is a good one, 
provided you have root access (it seems to need it).  So I used in a root 
terminal (running the same example in another window in the middle)

% opcontrol --no-vmlinux
% opcontrol --start
.... run things ...
% opreport -l /users/ripley/R/R-devel/bin/exec/R
% opreport -l /users/ripley/R/R-devel/library/stats/libs/stats.so
...
(No unit mask) count 100000
samples  %        symbol name
6        31.5789  bvalue_
4        21.0526  bsplvb_
3        15.7895  bsplvd_
2        10.5263  sbart_
2        10.5263  sslvrg_
1         5.2632  anonymous symbol from section .plt
1         5.2632  stxwx_
% opannotate -s /users/ripley/R/R-devel/library/stats/libs/stats.so
[Problem, root cannot read my source files]
% opcontrol --shutdown

If there is a way to use this without root access I would like to know it, 
as only a few very privileged users get that here, and I am not going to 
open up root access to my private file server.

Since it does look worthwhile collecting this sort of information together 
for R-exts, please add further contributions (to the list or direct to 
me).


On Tue, 21 Feb 2006, Prof Brian Ripley wrote:

> On Mon, 20 Feb 2006, Liaw, Andy wrote:
>
>> The last time I tried I didn't have much luck.  The gprof manual I could
>> find seems to indicate that it can not profile code that are dynamically
>> loaded.  (I was trying on Linux.)  The R source seems to hint otherwise.
>
> grof is not mentioned in any of the R manuals, so what are your referring
> to?  (R-admin talks about `to compile a profiling version of R', not of
> shared libraries.)
>
>> I'd very much appreciate pointers as well.
>
> You need to use sprof rather than gprof.  Here's one relevant thread:
>
> http://tolstoy.newcastle.edu.au/~rking/R/devel/05/02/2351.html
>
> and I am pretty sure there have been others.
>
> Linux has very sketchy info on sprof.  However,
>
> http://people.redhat.com/drepper/dsohowto.pdf
>
> has some.  I've thought about putting something about this in the
> R-exts manual
>
>
>>
>> Andy
>>
>> From: Ross Boylan
>>>
>>> Does anyone have any advice about profiling C/C++ code in a package
>>> under R?  Does R need to be built specially for this to work?
>>>
>>> The FAQ has some entries about profiling but they cover R level
>>> profiling; I'm try to get at the C++ code I've written that is called
>>> from R.
>>>
>>> Primary target is Mac OS X.
>>>
>>> Thanks.
>>>
>>> Ross Boylan
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Tue Feb 21 20:14:41 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 21 Feb 2006 14:14:41 -0500
Subject: [Rd] profiling C code
In-Reply-To: <20060221001818.GA12976@wheat.betterworld.us>
References: <20060221001818.GA12976@wheat.betterworld.us>
Message-ID: <AA763BA4-622B-4D50-BFFF-B7D6ABCB4ADD@r-project.org>


On Feb 20, 2006, at 7:18 PM, Ross Boylan wrote:

> Does anyone have any advice about profiling C/C++ code in a package  
> under R?  Does R need to be built specially for this to work?
>
> The FAQ has some entries about profiling but they cover R level  
> profiling; I'm try to get at the C++ code I've written that is  
> called from R.
>
> Primary target is Mac OS X.
>

If you have an OS X box to work on, then you have a handful of really  
excellent tools. Have a look at Shark from the CHUD tools (in / 
Developer/Applications/Performance Tools) Although it's sampling- 
based (.i.e. no need to gprof - just run sample running R), it is  
remarkably accurate and has ton of features for what they call 'data  
mining' of the profile data - including drill-down to source code and  
even assembly level. You can read a bit at
http://developer.apple.com/tools/sharkoptimize.html
It proves to be really useful and very flexible.

Cheers,
Simon


From kriegstn at yahoo.de  Tue Feb 21 20:48:10 2006
From: kriegstn at yahoo.de (Bernd Kriegstein)
Date: Tue, 21 Feb 2006 20:48:10 +0100 (CET)
Subject: [Rd] simple C function segfaults
In-Reply-To: <Pine.OSF.4.58.0602202348210.91966@wotan.mdacc.tmc.edu>
Message-ID: <20060221194810.46878.qmail@web27414.mail.ukl.yahoo.com>

Thank you very much for the answer. As a general
principle, when and why should I register the
counters? Should I do the same in matrices or other
parameters that I pass and alter in the main body of
the C function?

Thanks again,

- b.

--- Paul Roebuck <roebuck at mdanderson.org> schrieb:

> On Tue, 21 Feb 2006, Bernd Kriegstein wrote:
> 
> > I use the simplest of examples that somebody can
> think
> > of in order to generate a matrix of random numbers
> > from within C, calling appropriate R functions.
> The
> > concrete example is below:
> > [SNIP]
> 
> ------ pico.c --------
> #include <stdio.h>
> #include <stdlib.h>
> #include <math.h>
> #include <R.h>
> #include <Rmath.h>
> 
> #define COLM(i,j,m) ((m * j) + i)
> 
> void pico(double *y, int *n, int *m) {
>     register int i;
> 
>     GetRNGstate();
>     for (i = 0; i < *n; i++) {
>         register int j;
> 
>         for (j = 0; j < *m; j++) {
>             y[COLM(i,j,*m)] = rnorm(0.0, 1.0);
>         }
>     }
>     PutRNGstate();
> }
> 
> ------ pico.R --------
> dyn.load("pico.so")
> n <- 10
> m <- 5
> ans <- .C("pico",
>           as.double(matrix(0, n, m)),
>           as.integer(n),
>           as.integer(m))
> str(ans[[1]])
> 
> ----------------------
> 
> $ R CMD SHLIB pico.c
> $ R --vanilla < pico.R
> 
>
----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Tue Feb 21 21:16:08 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 21 Feb 2006 15:16:08 -0500
Subject: [Rd] simple C function segfaults
In-Reply-To: <20060221194810.46878.qmail@web27414.mail.ukl.yahoo.com>
References: <20060221194810.46878.qmail@web27414.mail.ukl.yahoo.com>
Message-ID: <1AF14F32-B953-4D58-A02B-A5ED0F3FA8CA@r-project.org>


On Feb 21, 2006, at 2:48 PM, Bernd Kriegstein wrote:

> Thank you very much for the answer. As a general principle, when  
> and why should I register the counters?

"register int i" is merely an optimization, you can safely use "int  
i" instead. The "register" keyword only tells the compiler to store  
the variable in a CPU register where possible - it is not necessary  
at all (most modern compiler will optimize it correctly anyway).  
Crucial mistake in your example was the improper use of function  
parameters and pointers.

Cheers,
Simon


From ripley at stats.ox.ac.uk  Tue Feb 21 22:11:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 21 Feb 2006 21:11:46 +0000 (GMT Standard Time)
Subject: [Rd] simple C function segfaults
In-Reply-To: <1AF14F32-B953-4D58-A02B-A5ED0F3FA8CA@r-project.org>
References: <20060221194810.46878.qmail@web27414.mail.ukl.yahoo.com>
	<1AF14F32-B953-4D58-A02B-A5ED0F3FA8CA@r-project.org>
Message-ID: <Pine.WNT.4.64.0602212106490.4076@auk>

On Tue, 21 Feb 2006, Simon Urbanek wrote:

>
> On Feb 21, 2006, at 2:48 PM, Bernd Kriegstein wrote:
>
>> Thank you very much for the answer. As a general principle, when
>> and why should I register the counters?
>
> "register int i" is merely an optimization, you can safely use "int
> i" instead. The "register" keyword only tells the compiler to store
> the variable in a CPU register where possible - it is not necessary
> at all (most modern compiler will optimize it correctly anyway).

I actually think you should leave this off with an optimizing compiler. 
They are better at optimizing register use than humans!  I believe there 
are only a few dozen `register' statements in the R code base, almost all 
of which are in code borrowed or generated (e.g. gram.c).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Feb 22 09:52:13 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 08:52:13 +0000 (GMT)
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <43F8E9FF.9080304@stats.uwo.ca>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
	<43F8C0D1.6000907@pdf.com>
	<f8e6ff050602191142x6a7c1359v768980d0f8842bf2@mail.gmail.com>
	<Pine.LNX.4.64.0602192014300.28769@gannet.stats.ox.ac.uk>
	<43F8E9FF.9080304@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0602220838280.19147@gannet.stats.ox.ac.uk>

I've managed to track this down.  The setting of the FPU control word on a 
ix86 machine changes the precision of (gcc) long double calculations in 
the FPU, as well as those of double.  So if it gets changed to PC_53, long 
doubles lose accuracy even though 10 bytes are carried around.

For some discussion of extended-precision issues, see Priest's annex to
Goldberg's paper at http://www.validlab.com/goldberg/paper.pdf.

Many other OSes other than Windows on ix86 do consider the FPU control 
word when doing context-switching.  There is (often heated) debate as to 
what the correct default should be, see e.g. the thread begining

http://gcc.gnu.org/ml/gcc/1998-12/msg00473.html

Whereas Linux has selected extended precision, apparently FreeBSD selected 
53-bit mantissa, and Solaris x86 used the equivalent of -ffloat-store to
ensure stricter compliant to the IEEE754 'double' model (and cynics say, 
to make the Sparc Solaris performance look good).

It will be interesting to see what MacIntel has selected (I suspect the 
FreeBSD solution).

This does mean that using long doubles for accumulators is not necessarily 
always a win although the potential loss is likely to be small.


On Sun, 19 Feb 2006, Duncan Murdoch wrote:

> On 2/19/2006 3:18 PM, Prof Brian Ripley wrote:
>> On Sun, 19 Feb 2006, hadley wickham wrote:
>> 
>>>> p.s.  If my computations are correct, 0.2 = 0*/2 + 0/4 + 1/8 + 1/16 +
>>>> 0/32 + 0/64 + 1/128 + 1/256 + 0/512 + 0/1024 + 1/2048 + 1/4096 + ... =
>>>> 0.3333333333333h.  Perhaps someone can extend this to an FAQ to help
>>>> explain finite precision arithmetic and rounding issues.
>>> This is drifting a bit off topic, but the other day I discovered this
>>> rather nice illustration of the perils of finite precision arithmetic
>>> while creating a contrast matrix:
>>> 
>>>> n <- 13
>>>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>>>> rowSums(a)
>>> [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
>>> [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
>>> [11]  1.110223e-16  1.665335e-16  2.220446e-16
>>> 
>>> Not only do most of the rows not sum to 0, they do not even sum to the
>>> same number!  It is hard to remember the familiar rules of arithmetic
>>> do not always apply.
>> 
>> I think you will find this example does give all 0's in R-devel, even on 
>> platforms like Sparc. 
>
> Only until the fpu precision gets changed:
>
>> n <- 13
>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>> rowSums(a)
> [1] 0 0 0 0 0 0 0 0 0 0 0 0 0
>> RSiteSearch('junk')
> A search query has been submitted to http://search.r-project.org
> The results page should open in your browser shortly
>
>> n <- 13
>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>> rowSums(a)
> [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
> [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
> [11]  1.110223e-16  1.665335e-16  2.220446e-16
>
> We still need to protect against these changes.  I'll put something together, 
> unless you're already working on it.
>
> The approach I'm thinking of is to define a macro to be called in risky 
> situations.  On platforms where this isn't an issue, the macro would be null; 
> on Windows, it would reset the fpu to full precision.
>
> For example, RSiteSearch causes damage in the ShellExecute call in 
> do_shellexec called from browseURL, so I'd add protection there.  I think we 
> should also add detection code somewhere in the evaluation loop to help in 
> diagnosing these problems.
>
>> But users do need to remember that computer arithmetic is inexact except in 
>> rather narrowly delimited cases.
>
> Yes, that too.
>
> Duncan Murdoch
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 22 11:39:33 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 22 Feb 2006 11:39:33 +0100 (CET)
Subject: [Rd] profiling C code
In-Reply-To: <Pine.LNX.4.64.0602211551440.11480@gannet.stats.ox.ac.uk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>
	<Pine.LNX.4.64.0602210720001.30643@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602211551440.11480@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602221135290.23956@artemis.imbe.med.uni-erlangen.de>


>
> If you are running Linux, Torsten's suggestion of oprofile is a good one,
> provided you have root access (it seems to need it).  So I used in a root
> terminal (running the same example in another window in the middle)
>
> % opcontrol --no-vmlinux
> % opcontrol --start
> .... run things ...

opcontrol --dump

doesn't require root privileges on my system and

> % opreport -l /users/ripley/R/R-devel/bin/exec/R
> % opreport -l /users/ripley/R/R-devel/library/stats/libs/stats.so

should be allowed for `normal users', too.

> ...
> (No unit mask) count 100000
> samples  %        symbol name
> 6        31.5789  bvalue_
> 4        21.0526  bsplvb_
> 3        15.7895  bsplvd_
> 2        10.5263  sbart_
> 2        10.5263  sslvrg_
> 1         5.2632  anonymous symbol from section .plt
> 1         5.2632  stxwx_
> % opannotate -s /users/ripley/R/R-devel/library/stats/libs/stats.so
> [Problem, root cannot read my source files]

for me, opannotate did not ask about running as `root'.

> % opcontrol --shutdown
>
> If there is a way to use this without root access I would like to know it,
> as only a few very privileged users get that here, and I am not going to
> open up root access to my private file server.

root needs to start the daemon via

opcontrol --start-daemon

and normal users can dump the output. But I don't know how a normal user 
would clean up and start new.

Best,

Torsten


From ripley at stats.ox.ac.uk  Wed Feb 22 12:56:45 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 11:56:45 +0000 (GMT)
Subject: [Rd] profiling C code
In-Reply-To: <Pine.LNX.4.64.0602221135290.23956@artemis.imbe.med.uni-erlangen.de>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82C@usctmx1106.merck.com>
	<Pine.LNX.4.64.0602210720001.30643@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602211551440.11480@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602221135290.23956@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.LNX.4.64.0602221130020.28960@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, Torsten Hothorn wrote:

>
>>
>> If you are running Linux, Torsten's suggestion of oprofile is a good one,
>> provided you have root access (it seems to need it).  So I used in a root
>> terminal (running the same example in another window in the middle)
>>
>> % opcontrol --no-vmlinux
>> % opcontrol --start
>> .... run things ...
>
> opcontrol --dump
>
> doesn't require root privileges on my system and

Yes, true, but not much use unless you can start a daemon.

>> % opreport -l /users/ripley/R/R-devel/bin/exec/R
>> % opreport -l /users/ripley/R/R-devel/library/stats/libs/stats.so
>
> should be allowed for `normal users', too.

Interesting.  It seems to be allowed unless the daemon is running and has 
undumped data on the file.  So the advice seems to need to be to dump and 
then run opreport.

>> ...
>> (No unit mask) count 100000
>> samples  %        symbol name
>> 6        31.5789  bvalue_
>> 4        21.0526  bsplvb_
>> 3        15.7895  bsplvd_
>> 2        10.5263  sbart_
>> 2        10.5263  sslvrg_
>> 1         5.2632  anonymous symbol from section .plt
>> 1         5.2632  stxwx_
>> % opannotate -s /users/ripley/R/R-devel/library/stats/libs/stats.so
>> [Problem, root cannot read my source files]
>
> for me, opannotate did not ask about running as `root'.

The issue is that that my source files are on a private file server to 
which the root account has no access.  That should be common for any 
secure system with remote-mounted file systems.  However, once I dump the 
data I can run opannotate as a normal user.

>
>> % opcontrol --shutdown
>>
>> If there is a way to use this without root access I would like to know it,
>> as only a few very privileged users get that here, and I am not going to
>> open up root access to my private file server.
>
> root needs to start the daemon via
>
> opcontrol --start-daemon
>
> and normal users can dump the output. But I don't know how a normal user
> would clean up and start new.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Wed Feb 22 13:11:44 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 22 Feb 2006 07:11:44 -0500
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <Pine.LNX.4.64.0602220838280.19147@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
	<43F8C0D1.6000907@pdf.com>
	<f8e6ff050602191142x6a7c1359v768980d0f8842bf2@mail.gmail.com>
	<Pine.LNX.4.64.0602192014300.28769@gannet.stats.ox.ac.uk>
	<43F8E9FF.9080304@stats.uwo.ca>
	<Pine.LNX.4.64.0602220838280.19147@gannet.stats.ox.ac.uk>
Message-ID: <43FC5500.9010500@stats.uwo.ca>

On 2/22/2006 3:52 AM, Prof Brian Ripley wrote:
> I've managed to track this down.  The setting of the FPU control word on a 
> ix86 machine changes the precision of (gcc) long double calculations in 
> the FPU, as well as those of double.  So if it gets changed to PC_53, long 
> doubles lose accuracy even though 10 bytes are carried around.
> 
> For some discussion of extended-precision issues, see Priest's annex to
> Goldberg's paper at http://www.validlab.com/goldberg/paper.pdf.
> 
> Many other OSes other than Windows on ix86 do consider the FPU control 
> word when doing context-switching.  There is (often heated) debate as to 
> what the correct default should be, see e.g. the thread begining

I think Windows also preserves the FPU control word across context 
switches.  The problem is that it doesn't do a context switch when you 
make a call into the system.  In particular, the shell services (file 
dialogs, URL recognition, etc.) involve a large number of DLLs, all 
running within the same context.  MSVC++ normally chooses 53 bit 
precision as the default, and will set that when a DLL starts up, or 
whenever a function in it asks to reset the FPU.

Duncan Murdoch
> 
> http://gcc.gnu.org/ml/gcc/1998-12/msg00473.html
> 
> Whereas Linux has selected extended precision, apparently FreeBSD selected 
> 53-bit mantissa, and Solaris x86 used the equivalent of -ffloat-store to
> ensure stricter compliant to the IEEE754 'double' model (and cynics say, 
> to make the Sparc Solaris performance look good).
> 
> It will be interesting to see what MacIntel has selected (I suspect the 
> FreeBSD solution).
> 
> This does mean that using long doubles for accumulators is not necessarily 
> always a win although the potential loss is likely to be small.
> 
> 
> On Sun, 19 Feb 2006, Duncan Murdoch wrote:
> 
>> On 2/19/2006 3:18 PM, Prof Brian Ripley wrote:
>>> On Sun, 19 Feb 2006, hadley wickham wrote:
>>>
>>>>> p.s.  If my computations are correct, 0.2 = 0*/2 + 0/4 + 1/8 + 1/16 +
>>>>> 0/32 + 0/64 + 1/128 + 1/256 + 0/512 + 0/1024 + 1/2048 + 1/4096 + ... =
>>>>> 0.3333333333333h.  Perhaps someone can extend this to an FAQ to help
>>>>> explain finite precision arithmetic and rounding issues.
>>>> This is drifting a bit off topic, but the other day I discovered this
>>>> rather nice illustration of the perils of finite precision arithmetic
>>>> while creating a contrast matrix:
>>>>
>>>>> n <- 13
>>>>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>>>>> rowSums(a)
>>>> [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
>>>> [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
>>>> [11]  1.110223e-16  1.665335e-16  2.220446e-16
>>>>
>>>> Not only do most of the rows not sum to 0, they do not even sum to the
>>>> same number!  It is hard to remember the familiar rules of arithmetic
>>>> do not always apply.
>>> I think you will find this example does give all 0's in R-devel, even on 
>>> platforms like Sparc. 
>> Only until the fpu precision gets changed:
>>
>>> n <- 13
>>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>>> rowSums(a)
>> [1] 0 0 0 0 0 0 0 0 0 0 0 0 0
>>> RSiteSearch('junk')
>> A search query has been submitted to http://search.r-project.org
>> The results page should open in your browser shortly
>>
>>> n <- 13
>>> a <- matrix(-1/n, ncol=n, nrow=n) + diag(n)
>>> rowSums(a)
>> [1]  2.775558e-16  2.775558e-16  5.551115e-17  5.551115e-17  5.551115e-17
>> [6]  5.551115e-17  0.000000e+00 -5.551115e-17  0.000000e+00  5.551115e-17
>> [11]  1.110223e-16  1.665335e-16  2.220446e-16
>>
>> We still need to protect against these changes.  I'll put something together, 
>> unless you're already working on it.
>>
>> The approach I'm thinking of is to define a macro to be called in risky 
>> situations.  On platforms where this isn't an issue, the macro would be null; 
>> on Windows, it would reset the fpu to full precision.
>>
>> For example, RSiteSearch causes damage in the ShellExecute call in 
>> do_shellexec called from browseURL, so I'd add protection there.  I think we 
>> should also add detection code somewhere in the evaluation loop to help in 
>> diagnosing these problems.
>>
>>> But users do need to remember that computer arithmetic is inexact except in 
>>> rather narrowly delimited cases.
>> Yes, that too.
>>
>> Duncan Murdoch
>>
>>
>


From ripley at stats.ox.ac.uk  Wed Feb 22 13:27:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 12:27:10 +0000 (GMT)
Subject: [Rd] Computing means, variances and sums
In-Reply-To: <43FC5500.9010500@stats.uwo.ca>
References: <Pine.LNX.4.64.0602190957290.4741@gannet.stats.ox.ac.uk>
	<43F8C0D1.6000907@pdf.com>
	<f8e6ff050602191142x6a7c1359v768980d0f8842bf2@mail.gmail.com>
	<Pine.LNX.4.64.0602192014300.28769@gannet.stats.ox.ac.uk>
	<43F8E9FF.9080304@stats.uwo.ca>
	<Pine.LNX.4.64.0602220838280.19147@gannet.stats.ox.ac.uk>
	<43FC5500.9010500@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0602221217150.30614@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, Duncan Murdoch wrote:

> On 2/22/2006 3:52 AM, Prof Brian Ripley wrote:
>> I've managed to track this down.  The setting of the FPU control word on a 
>> ix86 machine changes the precision of (gcc) long double calculations in the 
>> FPU, as well as those of double.  So if it gets changed to PC_53, long 
>> doubles lose accuracy even though 10 bytes are carried around.
>> 
>> For some discussion of extended-precision issues, see Priest's annex to
>> Goldberg's paper at http://www.validlab.com/goldberg/paper.pdf.
>> 
>> Many other OSes other than Windows on ix86 do consider the FPU control word 
>> when doing context-switching.  There is (often heated) debate as to what 
>> the correct default should be, see e.g. the thread begining
>
> I think Windows also preserves the FPU control word across context switches. 
> The problem is that it doesn't do a context switch when you make a call into 
> the system.  In particular, the shell services (file dialogs, URL 
> recognition, etc.) involve a large number of DLLs, all running within the 
> same context.  MSVC++ normally chooses 53 bit precision as the default, and 
> will set that when a DLL starts up, or whenever a function in it asks to 
> reset the FPU.

Yes, I think you are correct. In that case the difference is that it is 
considered legitimate for a shared resource (a DLL) to change the control 
word in the context that initializes it.

Since as I understand it Win64 does not have a working controlfp nor the 
ability to change precision (from 
http://msdn2.microsoft.com/en-us/library/e9b52ceh.aspx) in its native 
mode, maybe one day this will go away.

Brian Ripley

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gchappi at gmail.com  Wed Feb 22 14:06:23 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Wed, 22 Feb 2006 14:06:23 +0100
Subject: [Rd] translating eventloop.h
Message-ID: <47fce0650602220506k55c365efp@mail.gmail.com>

Hi,

I don't know much about "eventloop.h" (yet) but according to the
manual statement "for add-on front-ends and for packages that need to
share in the R event loops (on all platforms)" I thought it might make
sense to translate this to Pascal too.

But I have a couple of questions:

- no function declarations show up in the export tables of the R.dll
(or in any other dll)
- what good is this header file declaration when I don't have any entry points?
- why are all functions declared with the "extern" keyword. According
to my C++ information this would mean that the functions would have to
be declared somwhere else, but the only reference I could find was in
devX11.c and \unit\Sys-std.c. I don't understand this.

- is eventloop.h (maybe) a unix-only-thing?


Thanks!

--
Regards,
Hans-Peter


From pinard at progiciels-bpi.ca  Wed Feb 22 19:41:13 2006
From: pinard at progiciels-bpi.ca (pinard@progiciels-bpi.ca)
Date: Wed, 22 Feb 2006 19:41:13 +0100 (CET)
Subject: [Rd] Spurious output white line in R script (PR#8631)
Message-ID: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>


I noticed that R scripts produce a spurious white line after output.
For example, the following shell script,


#!/bin/sh
R --slave --vanilla <<EOF

cat("Hello\n")

EOF


when made executable under the name ``hello`` along the search path, behaves
like this:


$ hello | od -bc
0000000 110 145 154 154 157 012 012
          H   e   l   l   o  \n  \n
0000007



The second newline is not wanted, and I would like if R was not
producing it.



--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:utils, package:datasets, fp.etc, package:grDevices, Autoloads, package:base


From davidhughjones at gmail.com  Wed Feb 22 19:47:41 2006
From: davidhughjones at gmail.com (davidhughjones@gmail.com)
Date: Wed, 22 Feb 2006 19:47:41 +0100 (CET)
Subject: [Rd] PR#6614
Message-ID: <20060222184741.5EFB93F705@slim.kubism.ku.dk>

I agree with the submitter that this needs some kind of solution.
Although data.frame[,-12] works, how do I drop a named column (the
most common use case)? (I found this bug while searching for an
answer.)

cheers
David


From ggrothendieck at gmail.com  Wed Feb 22 20:13:54 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 22 Feb 2006 14:13:54 -0500
Subject: [Rd] PR#6614
In-Reply-To: <20060222184741.5EFB93F705@slim.kubism.ku.dk>
References: <20060222184741.5EFB93F705@slim.kubism.ku.dk>
Message-ID: <971536df0602221113g18fa674doa0deb0febae49bd9@mail.gmail.com>

Try this:

 subset(iris, select = - Species)


On 2/22/06, davidhughjones at gmail.com <davidhughjones at gmail.com> wrote:
> I agree with the submitter that this needs some kind of solution.
> Although data.frame[,-12] works, how do I drop a named column (the
> most common use case)? (I found this bug while searching for an
> answer.)
>
> cheers
> David
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Wed Feb 22 20:19:04 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 22 Feb 2006 14:19:04 -0500
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
Message-ID: <20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>

I don't see the bug here ... you may want to explain how this  
behavior conflicts with the documentation. As of your problem, see  
below.

On Feb 22, 2006, at 1:41 PM, pinard at progiciels-bpi.ca wrote:

> I noticed that R scripts produce a spurious white line after output.
> For example, the following shell script,
>
>
> #!/bin/sh
> R --slave --vanilla <<EOF
>
> cat("Hello\n")
>
> EOF
>
>
> when made executable under the name ``hello`` along the search  
> path, behaves
> like this:
>
>
> $ hello | od -bc
> 0000000 110 145 154 154 157 012 012
>           H   e   l   l   o  \n  \n
> 0000007
>
>
>
> The second newline is not wanted, and I would like if R was not
> producing it.
>

If you don't want it, tell R to explicitly terminate in your script,  
e.g. with quit("no",0) - then there will be no new line.

Cheers,
Simon


From pinard at iro.umontreal.ca  Thu Feb 23 00:10:22 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 22 Feb 2006 18:10:22 -0500
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
Message-ID: <20060222231022.GA24313@phenix.sram.qc.ca>

[Simon Urbanek]

>I don't see the bug here ... you may want to explain how this  behavior 
>conflicts with the documentation.

Oh, sorry.  I merely surmised that R developers were aware of the 
meaning of "--slave" option.  Within the output resulting of command 
"man R", one reads:

       --slave
              Make R run as quietly as possible

So, I was not expecting R, running with that option activated, to 
"volunteer" white lines. :-)

>If you don't want it, tell R to explicitly terminate in your script,
>e.g. with quit("no",0) - then there will be no new line.

Thanks for this work-around, which solves the problem of the spurious 
white line at end of script.  I did not need arguments on the q() call, 
first because the "no" is already implied through "default" from the 
"--vanilla" option and second because 0 is also the default exit status.

Yet, it sounds reasonable to suggest (or hope) that R interprets an 
end-of-file as meaning that R should cleanly quit.  I naively thought 
that it does this already, from the fact that interactively at least, 
R seems to behave on a Ctrl-D as if q() has been called.

This is either right or wrong using an end-of-file instead of calling 
q().  If it is right to use end-of-file instead of an explicit q() call,
I'm reporting a bug.  If it is wrong to use end-of-file instead of an 
explicit q() call, I'm rather making a suggestion. :-)

If you consider that the user is definitely wrong by not calling q() 
explicitly, and that various unexpected things may then happen, R would 
be friendlier if it produced a diagnostic, hitting an end-of-file while 
expecting a statement.  Interactively, it could even go further, and 
nicely remind the user, at the time the user types Ctrl-D, that calling 
q() is the only proper way for cleanly terminating an R session.

>On Feb 22, 2006, at 1:41 PM, pinard at progiciels-bpi.ca wrote:

>>I noticed that R scripts produce a spurious white line after output.
>>For example, the following shell script,


>>#!/bin/sh
>>R --slave --vanilla <<EOF

>>cat("Hello\n")

>>EOF


>>when made executable under the name ``hello`` along the search  
>>path, behaves
>>like this:


>>$ hello | od -bc
>>0000000 110 145 154 154 157 012 012
>>           H   e   l   l   o  \n  \n
>>0000007



>>The second newline is not wanted, and I would like if R was not
>>producing it.


>Cheers,
>Simon


-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From p.dalgaard at biostat.ku.dk  Thu Feb 23 00:23:59 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Feb 2006 00:23:59 +0100
Subject: [Rd] PR#6614
In-Reply-To: <971536df0602221113g18fa674doa0deb0febae49bd9@mail.gmail.com>
References: <20060222184741.5EFB93F705@slim.kubism.ku.dk>
	<971536df0602221113g18fa674doa0deb0febae49bd9@mail.gmail.com>
Message-ID: <x2fymbrn8w.fsf@turmalin.kubism.ku.dk>

"Gabor Grothendieck" <ggrothendieck at gmail.com> writes:

> Try this:
> 
>  subset(iris, select = - Species)

Or, canonically,

nm <- names(iris)
iris[, nm != "Species" ]

iris[, -match("Species", nm)]
 
> 
> On 2/22/06, davidhughjones at gmail.com <davidhughjones at gmail.com> wrote:
> > I agree with the submitter that this needs some kind of solution.
> > Although data.frame[,-12] works, how do I drop a named column (the
> > most common use case)? (I found this bug while searching for an
> > answer.)
> >
> > cheers
> > David
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From pinard at progiciels-bpi.ca  Thu Feb 23 04:26:50 2006
From: pinard at progiciels-bpi.ca (pinard@progiciels-bpi.ca)
Date: Thu, 23 Feb 2006 04:26:50 +0100 (CET)
Subject: [Rd] Tiny documentation error for ?options (PR#8633)
Message-ID: <20060223032650.A6103A260@slim.kubism.ku.dk>


Hi, people.  The output produced by "?options" contains:

     'expressions': sets a limit on the number of nested expressions
          that will be evaluated.  Valid values are 25...500000 with
          default 1000.  [...]

and a bit further down:

     The 'factory-fresh' default settings of some of these options are
       [...]
       'expressions'          '5000'

Is there a distinction between "default" and "factory-fresh default"?  
If not, then 1000 might be the correct value instead of 5000, as 1000 is 
contained in the list returned by R when given "options('expressions')".

--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:utils, package:datasets, fp.etc, package:grDevices, Autoloads, package:base


From ripley at stats.ox.ac.uk  Thu Feb 23 06:58:51 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 05:58:51 +0000 (GMT)
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <20060222231022.GA24313@phenix.sram.qc.ca>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
	<20060222231022.GA24313@phenix.sram.qc.ca>
Message-ID: <Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, Fran?ois Pinard wrote:

> [Simon Urbanek]
>
>> I don't see the bug here ... you may want to explain how this  behavior
>> conflicts with the documentation.
>
> Oh, sorry.  I merely surmised that R developers were aware of the
> meaning of "--slave" option.

We are.

> Within the output resulting of command
> "man R", one reads:
>
>       --slave
>              Make R run as quietly as possible
>
> So, I was not expecting R, running with that option activated, to
> "volunteer" white lines. :-)

But Simon said `with the documentation'.  Not doing what you expected is
not a bug.  Can you please point us to documentation which says that
end-of-file produces no output?

This does appear to be deliberate behaviour from

void end_Rmainloop(void)
{
     Rprintf("\n");
     /* run the .Last function. If it gives an error, will drop back to 
main
        loop. */
     R_CleanUp(SA_DEFAULT, 0, 1);
}

and I think it is necessary, as R might well have a partial line of output 
queued up for the console.  So this is probably `as quietly as possible'.

[...]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Feb 23 07:08:34 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 06:08:34 +0000 (GMT)
Subject: [Rd] Tiny documentation error for ?options (PR#8633)
In-Reply-To: <20060223032650.A6103A260@slim.kubism.ku.dk>
References: <20060223032650.A6103A260@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0602230604170.24547@gannet.stats.ox.ac.uk>

This is already corrected in the the development version of R: see

https://svn.r-project.org/R/trunk/src/library/base/man/options.Rd

(The FAQ does suggest you check there before sending a bug report.)

It is a question of defaults being changed frequently (because C stack 
overflow was occuring on some platforms) and the documentation being 
behind.

On Thu, 23 Feb 2006, pinard at progiciels-bpi.ca wrote:

>
> Hi, people.  The output produced by "?options" contains:
>
>     'expressions': sets a limit on the number of nested expressions
>          that will be evaluated.  Valid values are 25...500000 with
>          default 1000.  [...]
>
> and a bit further down:
>
>     The 'factory-fresh' default settings of some of these options are
>       [...]
>       'expressions'          '5000'
>
> Is there a distinction between "default" and "factory-fresh default"?
> If not, then 1000 might be the correct value instead of 5000, as 1000 is
> contained in the list returned by R when given "options('expressions')".
>
> --please do not edit the information below--
>
> Version:
> platform = i686-pc-linux-gnu
> arch = i686
> os = linux-gnu
> system = i686, linux-gnu
> status =
> major = 2
> minor = 2.1
> year = 2005
> month = 12
> day = 20
> svn rev = 36812
> language = R
>
> Locale:
> LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics, package:utils, package:datasets, fp.etc, package:grDevices, Autoloads, package:base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Bernhard_Pfaff at fra.invesco.com  Thu Feb 23 10:01:47 2006
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Thu, 23 Feb 2006 09:01:47 -0000
Subject: [Rd] Minor typo in optim.Rd (in details section)
Message-ID: <25D1C2585277D311B9A20000F6CCC71B077C0430@DEFRAEX02>


Dear R-Core member,

I spotted the following minor typo in:
https://svn.r-project.org/R/trunk/src/library/stats/man/optim.Rd


currently:
==========
\details{
[...]Conjugate gradient methods will generally be more fragile that the BFGS
method, [...]
}


Should read:
============
\details{
[...]Conjugate gradient methods will generally be more fragile than the BFGS
method, [...]
}                                                              ^^^^

Cheers,
Bernhard

Dr. Bernhard Pfaff
Global Structured Products Group
(Europe)

Invesco Asset Management Deutschland GmbH
Bleichstrasse 60-62
D-60313 Frankfurt am Main

Tel: +49(0)69 298 07230
Fax: +49(0)69 298 07178
Email: bernhard_pfaff at fra.invesco.com 
*****************************************************************
Confidentiality Note: The information contained in this mess...{{dropped}}


From ripley at stats.ox.ac.uk  Thu Feb 23 10:36:29 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 09:36:29 +0000 (GMT)
Subject: [Rd] Minor typo in optim.Rd (in details section)
In-Reply-To: <25D1C2585277D311B9A20000F6CCC71B077C0430@DEFRAEX02>
References: <25D1C2585277D311B9A20000F6CCC71B077C0430@DEFRAEX02>
Message-ID: <Pine.LNX.4.64.0602230936230.30922@gannet.stats.ox.ac.uk>

Fixed, thanks.

On Thu, 23 Feb 2006, Pfaff, Bernhard Dr. wrote:

>
> Dear R-Core member,
>
> I spotted the following minor typo in:
> https://svn.r-project.org/R/trunk/src/library/stats/man/optim.Rd
>
>
> currently:
> ==========
> \details{
> [...]Conjugate gradient methods will generally be more fragile that the BFGS
> method, [...]
> }
>
>
> Should read:
> ============
> \details{
> [...]Conjugate gradient methods will generally be more fragile than the BFGS
> method, [...]
> }                                                              ^^^^
>
> Cheers,
> Bernhard
>
> Dr. Bernhard Pfaff
> Global Structured Products Group
> (Europe)
>
> Invesco Asset Management Deutschland GmbH
> Bleichstrasse 60-62
> D-60313 Frankfurt am Main
>
> Tel: +49(0)69 298 07230
> Fax: +49(0)69 298 07178
> Email: bernhard_pfaff at fra.invesco.com
> *****************************************************************
> Confidentiality Note: The information contained in this mess...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From penel at biomserv.univ-lyon1.fr  Thu Feb 23 15:03:02 2006
From: penel at biomserv.univ-lyon1.fr (Simon Penel)
Date: Thu, 23 Feb 2006 15:03:02 +0100
Subject: [Rd] Problem during "make" with the devel version R-2.3.0 under Sun
	OS
Message-ID: <43FDC096.8010503@biomserv.univ-lyon1.fr>

Hello R users and developers,

I had a problem when I tried to install  the last version of R-devel.
I know that this R version is an unstable version and that this problem 
may be irrelevant.
I am  maintaining a R package  thus I check if this package can be 
installed with the development version.
( Everinthing is fine with the R-patched)

The details are the following:

My machine:
System:  SunOS 
Release: 5.9
Kernel ID : Generic_117171-07
Machine : sun4u
Processor :sparc
Platform : SUNW Sun-Fire-880

R version
 2.3.0 Under development (unstable)

SVN:
Revision: 37414
Last Changed Date: 2006-02-22

Results    affer configure:

R is now configured for sparc-sun-solaris2.9

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc  -g -O2 -std=gnu99
  Fortran 77 compiler:       g77  -g -O2

  C++ compiler:              g++  -g -O2
  Fortran 90/95 compiler:    f90

  Interfaces supported:      X11, tcltk
  External libraries:        readline
  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
  Options enabled:           R profiling


The problem during make:


gcc -I../../src/extra/zlib -I../../src/extra/bzip2 
-I../../src/extra/pcre  -I. -I../../src/include -I../../src/include 
-I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -std=gnu99 -c plot.c -o plot.o
gcc -I../../src/extra/zlib -I../../src/extra/bzip2 
-I../../src/extra/pcre  -I. -I../../src/include -I../../src/include 
-I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -std=gnu99 -c plot3d.c -o 
plot3d.o
/usr/ccs/bin/as: "/tmp/ccYv732b.s", line 7057: error: constant value 
must be between -4096 and 4095
make[3]: *** [plot3d.o] Error 1
make[3]: Leaving directory `/bge/penel/R-devel/src/main'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/bge/penel/R-devel/src/main'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/bge/penel/R-devel/src'
make: *** [R] Error 1

I did not found any report about this problem in the R-devel archives . 
Should I wait and try a next version of R-devel?

thanks for your help, I hope this mail is not irrelevant

Simon


From tlumley at u.washington.edu  Thu Feb 23 17:14:56 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 23 Feb 2006 08:14:56 -0800 (PST)
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
	<20060222231022.GA24313@phenix.sram.qc.ca>
	<Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602230809280.23263@homer21.u.washington.edu>

On Thu, 23 Feb 2006, Prof Brian Ripley wrote:

> On Wed, 22 Feb 2006, Franois Pinard wrote:
[...]
>> 
>> So, I was not expecting R, running with that option activated, to
>> "volunteer" white lines. :-)
>
> But Simon said `with the documentation'.  Not doing what you expected is
> not a bug.  Can you please point us to documentation which says that
> end-of-file produces no output?
>
> This does appear to be deliberate behaviour from
>
> void end_Rmainloop(void)
> {
>    Rprintf("\n");
>    /* run the .Last function. If it gives an error, will drop back to main
>       loop. */
>    R_CleanUp(SA_DEFAULT, 0, 1);
> }
>
> and I think it is necessary, as R might well have a partial line of output 
> queued up for the console.  So this is probably `as quietly as possible'.

(While agreeing entirely on the "bug" issue), couldn't we have 
fflush() instead of sending a newline?

 	-thomas

From ripley at stats.ox.ac.uk  Thu Feb 23 17:53:19 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 16:53:19 +0000 (GMT)
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <Pine.LNX.4.64.0602230809280.23263@homer21.u.washington.edu>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
	<20060222231022.GA24313@phenix.sram.qc.ca>
	<Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602230809280.23263@homer21.u.washington.edu>
Message-ID: <Pine.LNX.4.64.0602231629260.11945@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, Thomas Lumley wrote:

> On Thu, 23 Feb 2006, Prof Brian Ripley wrote:
>
>> On Wed, 22 Feb 2006, Fran?ois Pinard wrote:
> [...]
>>> 
>>> So, I was not expecting R, running with that option activated, to
>>> "volunteer" white lines. :-)
>> 
>> But Simon said `with the documentation'.  Not doing what you expected is
>> not a bug.  Can you please point us to documentation which says that
>> end-of-file produces no output?
>> 
>> This does appear to be deliberate behaviour from
>> 
>> void end_Rmainloop(void)
>> {
>>    Rprintf("\n");
>>    /* run the .Last function. If it gives an error, will drop back to main
>>       loop. */
>>    R_CleanUp(SA_DEFAULT, 0, 1);
>> }
>> 
>> and I think it is necessary, as R might well have a partial line of output 
>> queued up for the console.  So this is probably `as quietly as possible'.
>
> (While agreeing entirely on the "bug" issue), couldn't we have fflush() 
> instead of sending a newline?

Well, we might not be outputting to a file ... (I did say console), and 
.Last() might well produce output so we need to leave the console in a 
suitable state.  I do think we need a \n unless we can be sure that we are 
currently at the left margin of the console (and I am not sure we can be 
unless we assume all output went through R[E]printf, and even in that 
case we do not currently collect the information).

Consider the script

gannet% cat foo
#!/bin/sh
R --slave --vanilla <<EOF

.Last <- function() cat("goodbye\n")
cat("Hello")
EOF

which produces

gannet% foo.R
Hello
goodbye
gannet%

We do not want

gannet% foo.R
Hellogoodbye
gannet%

or at least, I do not want that.


Beyond that, there must be hundreds or more reference results of test runs 
against which comparisons are made, and this might well affect a lot of 
testing code, although perhaps we could conditionalize on --slave.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From h.wickham at gmail.com  Thu Feb 23 17:53:28 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Feb 2006 10:53:28 -0600
Subject: [Rd] Links to non-vignette documentation
Message-ID: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>

Section 1.4 of Writing R Extensions says:

In addition to the help files in Rd format, R packages allow the
inclusion of documents in arbitrary other formats. The standard
location for these is subdirectory inst/doc of a source package, the
contents will be copied to subdirectory doc when the package is
installed. Pointers from package help indices to the installed
documents are automatically created. Documents in inst/doc can be in
arbitrary format, however we strongly recommend to provide them in PDF
format, such that users on all platforms can easily read them.

Where are these pointers created?  I have a package with a pdf file
(introduction.pdf) in inst/doc but I can't find a link to it from the
documentation (eg. from help.start() or help(package=...)

Is there anyway to have my pdf documentation listed under vignettes
other than making it a sweave file?

Hadley


From jeff.horner at vanderbilt.edu  Thu Feb 23 18:07:55 2006
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Thu, 23 Feb 2006 11:07:55 -0600
Subject: [Rd] Utilizing the internet module
Message-ID: <43FDEBEB.4040104@vanderbilt.edu>

Hello all,

I'd like to utilize the R_Sock* functions from R_ext/R-ftp-http.h in my 
R package. The intent is to use these in conjunction with R_serialize() 
  to store R objects in a remote data store. I'm aware that version 
2.2.1 of "Writing R extensions" explains that these may be undocumented 
and unstable, but I have a couple of questions:

1) are they platform independent? I presume they are...

2) What's the appropriate way to link against them? On Linux x86, I can 
do this with the Makevars:

PKG_LIBS=$(R_HOME)/modules/internet$(SHLIB_EXT)

but that doesn't work on Mac OS X 10.3.9 powerpc G4:

gcc -bundle -flat_namespace -undefined suppress -L/sw/lib 
-L/usr/local/lib -o rmemcache.so rmemcache.o 
/Users/hornerjr/src/R-2.2.1/modules/internet.so -lcc_dynamic 
-L/Users/hornerjr/src/R-2.2.1/lib -lR
ld: /Users/hornerjr/src/R-2.2.1/modules/internet.so is input for the 
dynamic link editor, is not relocatable by the static link editor again

Thanks in advance,
-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University


From simon.urbanek at r-project.org  Thu Feb 23 18:20:48 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 23 Feb 2006 12:20:48 -0500
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <Pine.LNX.4.64.0602230809280.23263@homer21.u.washington.edu>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
	<20060222231022.GA24313@phenix.sram.qc.ca>
	<Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602230809280.23263@homer21.u.washington.edu>
Message-ID: <E02C3C2E-38B3-4FEF-B90A-8DBA4FF09939@r-project.org>


On Feb 23, 2006, at 11:14 AM, Thomas Lumley wrote:

> On Thu, 23 Feb 2006, Prof Brian Ripley wrote:
>
>> On Wed, 22 Feb 2006, Fran?ois Pinard wrote:
> [...]
>>> So, I was not expecting R, running with that option activated, to
>>> "volunteer" white lines. :-)
>>
>> But Simon said `with the documentation'.  Not doing what you  
>> expected is
>> not a bug.  Can you please point us to documentation which says that
>> end-of-file produces no output?
>>
>> This does appear to be deliberate behaviour from
>>
>> void end_Rmainloop(void)
>> {
>>    Rprintf("\n");
>>    /* run the .Last function. If it gives an error, will drop back  
>> to main
>>       loop. */
>>    R_CleanUp(SA_DEFAULT, 0, 1);
>> }
>>
>> and I think it is necessary, as R might well have a partial line  
>> of output queued up for the console.  So this is probably `as  
>> quietly as possible'.
>
> (While agreeing entirely on the "bug" issue), couldn't we have  
> fflush() instead of sending a newline?
>

It's not really about fflush - the rationale is to not leave non- 
terminated lines on the output before quitting via EOF, which has its  
merits. If you remove it, you get this:
...
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

 > caladan:Rdev$

instead of

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

 >
caladan:Rdev$

fflush won't change this.

Cheers,
Simon


From jjmcnutt at gmail.com  Thu Feb 23 19:04:49 2006
From: jjmcnutt at gmail.com (jjmcnutt@gmail.com)
Date: Thu, 23 Feb 2006 19:04:49 +0100 (CET)
Subject: [Rd] rnorm returning NA's (PR#8635)
Message-ID: <20060223180449.7B5733F6C4@slim.kubism.ku.dk>

Full_Name: Josh McNutt
Version: 2.2.1
OS: Win XP
Submission from: (NULL) (192.88.209.232)


> which(is.na(rnorm(20000000)))
[1] 15242377

> which(is.na(rnorm(10000000)))
[1] 3692029

> which(is.na(rnorm(40000000)))
[1]  5560337  5938719 33888822

> which(is.na(rnorm(50000000)))
[1] 25231754 42397181 45085564 45363557


From tlumley at u.washington.edu  Thu Feb 23 19:28:15 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 23 Feb 2006 10:28:15 -0800 (PST)
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <E02C3C2E-38B3-4FEF-B90A-8DBA4FF09939@r-project.org>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
	<20060222231022.GA24313@phenix.sram.qc.ca>
	<Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0602230809280.23263@homer21.u.washington.edu>
	<E02C3C2E-38B3-4FEF-B90A-8DBA4FF09939@r-project.org>
Message-ID: <Pine.LNX.4.64.0602231026070.23263@homer21.u.washington.edu>

On Thu, 23 Feb 2006, Simon Urbanek wrote:

>
> On Feb 23, 2006, at 11:14 AM, Thomas Lumley wrote:
>
>> On Thu, 23 Feb 2006, Prof Brian Ripley wrote:
>> 
>>> On Wed, 22 Feb 2006, Fran?ois Pinard wrote:
>> [...]
>>>> So, I was not expecting R, running with that option activated, to
>>>> "volunteer" white lines. :-)
>>> 
>>> But Simon said `with the documentation'.  Not doing what you expected is
>>> not a bug.  Can you please point us to documentation which says that
>>> end-of-file produces no output?
>>> 
>>> This does appear to be deliberate behaviour from
>>> 
>>> void end_Rmainloop(void)
>>> {
>>>   Rprintf("\n");
>>>   /* run the .Last function. If it gives an error, will drop back to main
>>>      loop. */
>>>   R_CleanUp(SA_DEFAULT, 0, 1);
>>> }
>>> 
>>> and I think it is necessary, as R might well have a partial line of output 
>>> queued up for the console.  So this is probably `as quietly as possible'.
>> 
>> (While agreeing entirely on the "bug" issue), couldn't we have fflush() 
>> instead of sending a newline?
>> 
>
> It's not really about fflush - the rationale is to not leave non-terminated 
> lines on the output before quitting via EOF, which has its merits.

I would have thought that, at least with --slave, you might want the 
ability to produce output that didn't end with any newline (in contrast to 
the original question, which was about one vs two newlines, which is easy 
to fix).

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From murdoch at stats.uwo.ca  Thu Feb 23 19:51:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 13:51:23 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
Message-ID: <43FE042B.4080601@stats.uwo.ca>

On 2/23/2006 11:53 AM, hadley wickham wrote:
> Section 1.4 of Writing R Extensions says:
> 
> In addition to the help files in Rd format, R packages allow the
> inclusion of documents in arbitrary other formats. The standard
> location for these is subdirectory inst/doc of a source package, the
> contents will be copied to subdirectory doc when the package is
> installed. Pointers from package help indices to the installed
> documents are automatically created. Documents in inst/doc can be in
> arbitrary format, however we strongly recommend to provide them in PDF
> format, such that users on all platforms can easily read them.
> 
> Where are these pointers created?  I have a package with a pdf file
> (introduction.pdf) in inst/doc but I can't find a link to it from the
> documentation (eg. from help.start() or help(package=...)
> 
> Is there anyway to have my pdf documentation listed under vignettes
> other than making it a sweave file?

A manually written inst/doc/index.html file will be linked into the help 
system.

I don't know if the sentence about pointers being created is true otherwise.

Duncan Murdoch


From pinard at iro.umontreal.ca  Thu Feb 23 20:20:17 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Thu, 23 Feb 2006 14:20:17 -0500
Subject: [Rd] Tiny documentation error for ?options (PR#8633)
In-Reply-To: <Pine.LNX.4.64.0602230604170.24547@gannet.stats.ox.ac.uk>
References: <20060223032650.A6103A260@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0602230604170.24547@gannet.stats.ox.ac.uk>
Message-ID: <20060223192017.GA24528@alcyon.progiciels-bpi.ca>

[Brian Ripley]
>This is already corrected in the the development version of R:

Good, thanks!

P.S. - More generally, huge thanks to all developers of this impressive 
R system.  I have an idea of the constant courage and long dedication it 
takes for reaching the usability and maturity R already has.

>(The FAQ does suggest you check there before sending a bug report.)

Yes, I know (and even checked the FAQ first, as I could quickly do it).  
I had to choose between putting more time in research that I had at my 
disposal, and not sending a report.  If I did the wrong choice, just 
tell me, and I'll merely refrain in similar circumstances.

I may be a very patient nit-picker, and while this is advantageous for 
a system, it is sometimes irritating for those maintaining it.


[Reminder of original message follows]

>It is a question of defaults being changed frequently (because C stack 
>overflow was occuring on some platforms) and the documentation being 
>behind.

>On Thu, 23 Feb 2006, pinard at progiciels-bpi.ca wrote:


>>Hi, people.  The output produced by "?options" contains:

>>     'expressions': sets a limit on the number of nested expressions
>>          that will be evaluated.  Valid values are 25...500000 with
>>          default 1000.  [...]

>>and a bit further down:

>>     The 'factory-fresh' default settings of some of these options are
>>       [...]
>>       'expressions'          '5000'

>>Is there a distinction between "default" and "factory-fresh default"?
>>If not, then 1000 might be the correct value instead of 5000, as 1000 is
>>contained in the list returned by R when given "options('expressions')".

>>--please do not edit the information below--

>>Version:
>>platform = i686-pc-linux-gnu
>>arch = i686
>>os = linux-gnu
>>system = i686, linux-gnu
>>status =
>>major = 2
>>minor = 2.1
>>year = 2005
>>month = 12
>>day = 20
>>svn rev = 36812
>>language = R

>>Locale:
>>LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

>>Search Path:
>>.GlobalEnv, package:methods, package:stats, package:graphics, 
>>package:utils, package:datasets, fp.etc, package:grDevices, Autoloads, 
>>package:base

>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel



>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From ripley at stats.ox.ac.uk  Thu Feb 23 20:23:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 19:23:43 +0000 (GMT)
Subject: [Rd] Utilizing the internet module
In-Reply-To: <43FDEBEB.4040104@vanderbilt.edu>
References: <43FDEBEB.4040104@vanderbilt.edu>
Message-ID: <Pine.LNX.4.64.0602231904380.10209@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, Jeffrey Horner wrote:

> Hello all,
>
> I'd like to utilize the R_Sock* functions from R_ext/R-ftp-http.h in my
> R package. The intent is to use these in conjunction with R_serialize()
>  to store R objects in a remote data store. I'm aware that version
> 2.2.1 of "Writing R extensions" explains that these may be undocumented
> and unstable, but I have a couple of questions:
>
> 1) are they platform independent? I presume they are...

Only in sense that they have a common interface.

> 2) What's the appropriate way to link against them? On Linux x86, I can
> do this with the Makevars:

You can, but that is a module and not a library and so it does not work on 
MacOS X and may well not work on Windows (you would be lucky prior to R 
2.3.0).

I wonder why you need a C interface at all.  There is serialize() and 
socket connections are available at R level.  Below that, Rsockopen etc 
are exported from R itself and underly make.socket etc.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Feb 23 21:08:12 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 23 Feb 2006 21:08:12 +0100 (CET)
Subject: [Rd] rnorm returning NA's (PR#8635)
Message-ID: <20060223200812.C82C019A53@slim.kubism.ku.dk>

This is not reproducible, and you have not told us the seed you used which 
is what is needed to make random results reproducible.

Please supply a reproducible example (if you can).  I ran the first line 
100 times (about 15 minutes) without encountering any NAs.  If you found 
these fairly easily it indicates a bug in your Windows installation, not 
one in R.  Further, if it were at all common then other people would have 
encountered it and surely mentioned it.

On Thu, 23 Feb 2006, jjmcnutt at gmail.com wrote:

> Full_Name: Josh McNutt
> Version: 2.2.1
> OS: Win XP
> Submission from: (NULL) (192.88.209.232)
>
>
>> which(is.na(rnorm(20000000)))
> [1] 15242377
>
>> which(is.na(rnorm(10000000)))
> [1] 3692029
>
>> which(is.na(rnorm(40000000)))
> [1]  5560337  5938719 33888822
>
>> which(is.na(rnorm(50000000)))
> [1] 25231754 42397181 45085564 45363557
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Feb 23 21:16:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 20:16:40 +0000 (GMT)
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <43FE042B.4080601@stats.uwo.ca>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, Duncan Murdoch wrote:

> On 2/23/2006 11:53 AM, hadley wickham wrote:
>> Section 1.4 of Writing R Extensions says:
>>
>> In addition to the help files in Rd format, R packages allow the
>> inclusion of documents in arbitrary other formats. The standard
>> location for these is subdirectory inst/doc of a source package, the
>> contents will be copied to subdirectory doc when the package is
>> installed. Pointers from package help indices to the installed
>> documents are automatically created. Documents in inst/doc can be in
>> arbitrary format, however we strongly recommend to provide them in PDF
>> format, such that users on all platforms can easily read them.
>>
>> Where are these pointers created?  I have a package with a pdf file
>> (introduction.pdf) in inst/doc but I can't find a link to it from the
>> documentation (eg. from help.start() or help(package=...)
>>
>> Is there anyway to have my pdf documentation listed under vignettes
>> other than making it a sweave file?

No, a vignette is regarded as an Sweave file.

> A manually written inst/doc/index.html file will be linked into the help
> system.

.install_package_vignette_index does create an index, and info does get 
put on the packages html page.

I just tried this by adding inst/doc/foo.pdf to windlgs.  If there is an 
pdf file but no .[RS]nw vignettes, the index is fairly useless but 
browsing is available.

> I don't know if the sentence about pointers being created is true otherwise.

It seems to be.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Feb 23 21:22:09 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 15:22:09 -0500
Subject: [Rd] rnorm returning NA's (PR#8635)
In-Reply-To: <20060223180449.7B5733F6C4@slim.kubism.ku.dk>
References: <20060223180449.7B5733F6C4@slim.kubism.ku.dk>
Message-ID: <43FE1971.3030507@stats.uwo.ca>

On 2/23/2006 1:04 PM, jjmcnutt at gmail.com wrote:
> Full_Name: Josh McNutt
> Version: 2.2.1
> OS: Win XP
> Submission from: (NULL) (192.88.209.232)
> 
> 
>> which(is.na(rnorm(20000000)))
> [1] 15242377
> 
>> which(is.na(rnorm(10000000)))
> [1] 3692029
> 
>> which(is.na(rnorm(40000000)))
> [1]  5560337  5938719 33888822
> 
>> which(is.na(rnorm(50000000)))
> [1] 25231754 42397181 45085564 45363557
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

I don't see these.  Could you use set.seed() to put the RNG in a 
reproducible state, and show us the results then?

Duncan Murdoch


From h.wickham at gmail.com  Thu Feb 23 21:37:15 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Feb 2006 14:37:15 -0600
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>

> >> Is there anyway to have my pdf documentation listed under vignettes
> >> other than making it a sweave file?
>
> No, a vignette is regarded as an Sweave file.

It would be useful if there was a mechanism to allow arbitrary pdf
files to be included as vignettes.  There are many other ways to
include R code/output in pdf files other than through Sweave.

> I just tried this by adding inst/doc/foo.pdf to windlgs.  If there is an
> pdf file but no .[RS]nw vignettes, the index is fairly useless but
> browsing is available.
>
> > I don't know if the sentence about pointers being created is true otherwise.
>
> It seems to be.

A link to the directory where the pdf is located, only available in
the html version of help, rather stretches the definition of a
pointer.

Hadley


From ripley at stats.ox.ac.uk  Thu Feb 23 21:50:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 20:50:23 +0000 (GMT)
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com> 
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, hadley wickham wrote:

>>>> Is there anyway to have my pdf documentation listed under vignettes
>>>> other than making it a sweave file?
>>
>> No, a vignette is regarded as an Sweave file.
>
> It would be useful if there was a mechanism to allow arbitrary pdf
> files to be included as vignettes.  There are many other ways to
> include R code/output in pdf files other than through Sweave.

I think you need to define `vignette'.  I understand the usage to mean an
Sweave file.  There are ways to include other PDF files, and you can write 
your own index file.  R can't do that for you as it cannot read PDF (it 
can read Sweave).

>> I just tried this by adding inst/doc/foo.pdf to windlgs.  If there is an
>> pdf file but no .[RS]nw vignettes, the index is fairly useless but
>> browsing is available.
>>
>>> I don't know if the sentence about pointers being created is true otherwise.
>>
>> It seems to be.
>
> A link to the directory where the pdf is located, only available in
> the html version of help, rather stretches the definition of a
> pointer.

What is a link if not a pointer?  What it actually says is

    Pointers from package help indices to the installed
    documents are automatically created.

I am not aware of any other sort of `package help index', although one 
could arge the toss about Compiled HTML.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Feb 23 21:57:34 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 20:57:34 +0000 (GMT)
Subject: [Rd] Problem during "make" with the devel version R-2.3.0 under
 Sun OS
In-Reply-To: <43FDC096.8010503@biomserv.univ-lyon1.fr>
References: <43FDC096.8010503@biomserv.univ-lyon1.fr>
Message-ID: <Pine.LNX.4.64.0602232050570.25797@gannet.stats.ox.ac.uk>

This is a compiler error (generating invalid assembler), not an R error. 
What compiler version is this?

I have no problem compiling the current R-devel (37422) on Solaris with 
gcc-3.4.5 or gcc-4.0.2 (and using the Sun assembler as you are).  I have 
seen problems with plot3d with earlier versions of gcc-4.


On Thu, 23 Feb 2006, Simon Penel wrote:

> Hello R users and developers,
>
> I had a problem when I tried to install  the last version of R-devel.
> I know that this R version is an unstable version and that this problem
> may be irrelevant.
> I am  maintaining a R package  thus I check if this package can be
> installed with the development version.
> ( Everinthing is fine with the R-patched)
>
> The details are the following:
>
> My machine:
> System:  SunOS
> Release: 5.9
> Kernel ID : Generic_117171-07
> Machine : sun4u
> Processor :sparc
> Platform : SUNW Sun-Fire-880
>
> R version
> 2.3.0 Under development (unstable)
>
> SVN:
> Revision: 37414
> Last Changed Date: 2006-02-22
>
> Results    affer configure:
>
> R is now configured for sparc-sun-solaris2.9
>
>  Source directory:          .
>  Installation directory:    /usr/local
>
>  C compiler:                gcc  -g -O2 -std=gnu99
>  Fortran 77 compiler:       g77  -g -O2
>
>  C++ compiler:              g++  -g -O2
>  Fortran 90/95 compiler:    f90
>
>  Interfaces supported:      X11, tcltk
>  External libraries:        readline
>  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>  Options enabled:           R profiling
>
>
> The problem during make:
>
>
> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre  -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -std=gnu99 -c plot.c -o plot.o
> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre  -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -std=gnu99 -c plot3d.c -o
> plot3d.o
> /usr/ccs/bin/as: "/tmp/ccYv732b.s", line 7057: error: constant value
> must be between -4096 and 4095
> make[3]: *** [plot3d.o] Error 1
> make[3]: Leaving directory `/bge/penel/R-devel/src/main'
> make[2]: *** [R] Error 2
> make[2]: Leaving directory `/bge/penel/R-devel/src/main'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/bge/penel/R-devel/src'
> make: *** [R] Error 1
>
> I did not found any report about this problem in the R-devel archives .
> Should I wait and try a next version of R-devel?
>
> thanks for your help, I hope this mail is not irrelevant
>
> Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Thu Feb 23 22:10:25 2006
From: h.wickham at gmail.com (h.wickham@gmail.com)
Date: Thu, 23 Feb 2006 22:10:25 +0100 (CET)
Subject: [Rd] Wishlist: browser and traceback should trim callstack when
	printing (PR#8638)
Message-ID: <20060223211025.48CBAE0B8@slim.kubism.ku.dk>

Full_Name: Hadley Wickham
Version: 2.2.0
OS: OS X
Submission from: (NULL) (129.186.195.213)


Example: 

f <- function(...) browser()
do.call(f, mtcars)

Entire contents of mtcars is printed on callstack.  

When you are using do.call with large data.frames this is a frustrating as it
easily wipes out your entire buffer.  While it is useful to be able to see all
the arguments when looking for the cause of the bug, manual inspection is
impractical when dealing with very long arguments.


From h.wickham at gmail.com  Thu Feb 23 22:23:59 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Feb 2006 15:23:59 -0600
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>

> I think you need to define `vignette'.  I understand the usage to mean an
> Sweave file.  There are ways to include other PDF files, and you can write
> your own index file.  R can't do that for you as it cannot read PDF (it
> can read Sweave).

How can I write an index file with a pointer to my pdf?  Should I
provide a code snippet to run system(paste(getOption("pdfviewer"),
system.file("doc/my.pdf", package="mypackage"), "&"))?

Perhaps my problem is thinking of a vignette as a "A brief verbal
description of a person, place, etc.; a short descriptive or evocative
episode in a play, etc." rather than a Sweave document.

> I am not aware of any other sort of `package help index', although one
> could arge the toss about Compiled HTML.

What about (eg.) help(package=grid)?  This is where vignettes are
listed by name (and location).  I would like to be able put my pdf
into a similar list.

Hadley


From ripley at stats.ox.ac.uk  Thu Feb 23 22:37:58 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 21:37:58 +0000 (GMT)
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com> 
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com> 
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602232127250.26309@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, hadley wickham wrote:

>> I think you need to define `vignette'.  I understand the usage to mean an
>> Sweave file.  There are ways to include other PDF files, and you can write
>> your own index file.  R can't do that for you as it cannot read PDF (it
>> can read Sweave).
>
> How can I write an index file with a pointer to my pdf?  Should I
> provide a code snippet to run system(paste(getOption("pdfviewer"),
> system.file("doc/my.pdf", package="mypackage"), "&"))?

Just add a hyperlink in inst/doc/index.html to foo.pdf and let the browser 
do the rest.  The grid/doc/index.html is a suitable template.

> Perhaps my problem is thinking of a vignette as a "A brief verbal
> description of a person, place, etc.; a short descriptive or evocative
> episode in a play, etc." rather than a Sweave document.
>
>> I am not aware of any other sort of `package help index', although one
>> could arge the toss about Compiled HTML.
>
> What about (eg.) help(package=grid)?  This is where vignettes are
> listed by name (and location).  I would like to be able put my pdf
> into a similar list.

Which is really library(help=grid).  Vignettes there are a recent 
addition, and we need the author to tell us.  It looks to me as if that 
means strict-sense vignettes (it gets the info from the vignette 
metadata).  If there were a mechanism for authors to list PDF docs and 
titles in a two-column format in some file in inst/docs, the installation 
tools could provide more support.  (I think this is Kurt's area.)

[I am not arguing that this could not be better documented, but I think 
most things are possible by digging around.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Feb 23 23:16:51 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 17:16:51 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	
	<43FE042B.4080601@stats.uwo.ca>	
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>	
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
Message-ID: <43FE3453.6020405@stats.uwo.ca>

On 2/23/2006 4:23 PM, hadley wickham wrote:
>> I think you need to define `vignette'.  I understand the usage to mean an
>> Sweave file.  There are ways to include other PDF files, and you can write
>> your own index file.  R can't do that for you as it cannot read PDF (it
>> can read Sweave).
> 
> How can I write an index file with a pointer to my pdf?  Should I
> provide a code snippet to run system(paste(getOption("pdfviewer"),
> system.file("doc/my.pdf", package="mypackage"), "&"))?

We were referring to an HTML index file.  If you want to have a 
reference from your package man page (foo-package.Rd) or some other man 
page, you can use \url{../doc/my.pdf} and the link will work in HTML 
versions of help, and won't be too misleading in other versions 
(especially if you explain how to use it).

> Perhaps my problem is thinking of a vignette as a "A brief verbal
> description of a person, place, etc.; a short descriptive or evocative
> episode in a play, etc." rather than a Sweave document.
> 
>> I am not aware of any other sort of `package help index', although one
>> could arge the toss about Compiled HTML.
> 
> What about (eg.) help(package=grid)?  This is where vignettes are
> listed by name (and location).  I would like to be able put my pdf
> into a similar list.

I don't think you can do that, but you should be using a package man 
page anyway.

Duncan Murdoch


From h.wickham at gmail.com  Thu Feb 23 23:49:32 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Feb 2006 16:49:32 -0600
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <43FE3453.6020405@stats.uwo.ca>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
	<43FE3453.6020405@stats.uwo.ca>
Message-ID: <f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>

> We were referring to an HTML index file.  If you want to have a
> reference from your package man page (foo-package.Rd) or some other man
> page, you can use \url{../doc/my.pdf} and the link will work in HTML
> versions of help, and won't be too misleading in other versions
> (especially if you explain how to use it).

Ok, I'll give that a go.

> I don't think you can do that, but you should be using a package man
> page anyway.

Can you suggest a good example of a package man page?  I've tried a
few packages and haven't been able to find one.  The example generated
by promptPackage suggests I need to duplicate the contents of
DESCRIPTION and INDEX.

Hadley


From jeff.horner at vanderbilt.edu  Fri Feb 24 00:07:29 2006
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Thu, 23 Feb 2006 17:07:29 -0600
Subject: [Rd] Utilizing the internet module
In-Reply-To: <Pine.LNX.4.64.0602231904380.10209@gannet.stats.ox.ac.uk>
References: <43FDEBEB.4040104@vanderbilt.edu>
	<Pine.LNX.4.64.0602231904380.10209@gannet.stats.ox.ac.uk>
Message-ID: <43FE4031.1080503@vanderbilt.edu>

Prof Brian Ripley wrote:
> On Thu, 23 Feb 2006, Jeffrey Horner wrote:
> 
>> Hello all,
>>
>> I'd like to utilize the R_Sock* functions from R_ext/R-ftp-http.h in my
>> R package. The intent is to use these in conjunction with R_serialize()
>>  to store R objects in a remote data store. I'm aware that version
>> 2.2.1 of "Writing R extensions" explains that these may be undocumented
>> and unstable, but I have a couple of questions:
>>
>> 1) are they platform independent? I presume they are...
> 
> 
> Only in sense that they have a common interface.
> 
>> 2) What's the appropriate way to link against them? On Linux x86, I can
>> do this with the Makevars:
> 
> 
> You can, but that is a module and not a library and so it does not work 
> on MacOS X and may well not work on Windows (you would be lucky prior to 
> R 2.3.0).
> 
> I wonder why you need a C interface at all.  There is serialize() and 
> socket connections are available at R level.  Below that, Rsockopen etc 
> are exported from R itself and underly make.socket etc.

I may not need it (or get to use it portably), but as far as using 
Rsockopen, etc. am I right in assuming that a package writer would have 
to copy the declarations from src/main/basedecl.h into his/her own code 
in order to utilize them? This seems odd when there's already an exposed 
(although undocumented) interface with R_Sock*, so what's the point of 
having R_ext/R-ftp-http.h? Is it just for some xml package?

On a related note, how do I serialize() an R object to a database table 
column of type BLOB? I've tried using RODBC but was unsuccessfully (see 
R-sig-DB in Feb archive). I've also looked into RMySQL/DBI but I don't 
think it's supported yet.



-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University


From pinard at iro.umontreal.ca  Fri Feb 24 00:14:54 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Thu, 23 Feb 2006 18:14:54 -0500
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
	<20060222231022.GA24313@phenix.sram.qc.ca>
	<Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
Message-ID: <20060223231454.GA29213@alcyon.progiciels-bpi.ca>

[Brian Ripley]
>[Fran?ois Pinard]

>>Within the output resulting of command "man R", one reads:

>>       --slave
>>              Make R run as quietly as possible

>>So, I was not expecting R, running with that option activated, to
>>"volunteer" white lines. :-)

>Can you please point us to documentation which says that end-of-file 
>produces no output?

I just did.  However, you state that "as quietly as possible" should not 
be interpreted as "no output".  Our interpretations differ.

>This does appear to be deliberate behaviour from

>void end_Rmainloop(void)
>{
>     Rprintf("\n");
>     /* run the .Last function. If it gives an error, will drop back to 
>main
>        loop. */
>     R_CleanUp(SA_DEFAULT, 0, 1);
>}

>and I think it is necessary, as R might well have a partial line of output 
>queued up for the console.  So this is probably `as quietly as possible'.

I do not doubt that it is deliberate, and I suspected as much even 
before submitting my initial report on this topic, as I do the same in 
some interactive programs I wrote, so the shell prompt shows at the 
left.  However, I'm careful at not doing it outside human-interactive 
contexts.

It is likely unusual that R users starts an R session with "--slave",
when that session is really meant to be human-interactive.  Whatever the 
documentation says or does not say, the spurious '\n' kludge has no good 
reason to apply with "--slave".  Let's both be trying to have 
a reasonable and intelligent conversation here, keeping in mind that the 
documentation is not necessarily perfect either, and not the last word 
of everything.

The argument that it is necessary to write a '\n' because a partial line 
of output may be queued up for the console, does not fully hold.  Proof 
is, following Simon Urbanek's suggestion, that the following valid 
R script:


#!/bin/sh
R --slave --vanilla <<EOF

cat("Hello")
q()

EOF


produces such a partial line.  I see no problem there: when using 
"--slave", a script writer should feel in good control of the produced 
output, and s/he will recognise a missing newline as a bug in the 
script, not as a bug in R.

If the newline is a way to flush out the output buffer before quitting, 
the suggestion made by others to use `fflush()', or anything similar, is 
wise.  Adding a newline when "--slave" has not been selected, and 
whenever the output is connected to a tty, is also wise, regardless if 
termination is effected through q() or through hitting end-of-file.

Not adding a newline in other circumstances is debatable, but wise.

It is also reasonable (whether documented or not) expecting that q() and 
hitting end-of-file act similarly.  Some developers (or maybe none) 
might even recognise they attempted it already.  Let me suggest that 
this similarity is aimed, and even documented.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From pinard at iro.umontreal.ca  Fri Feb 24 00:24:30 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Thu, 23 Feb 2006 18:24:30 -0500
Subject: [Rd] Spurious output white line in R script (PR#8631)
In-Reply-To: <20060223231454.GA29213@alcyon.progiciels-bpi.ca>
References: <20060222184113.A6F1B3F70C@slim.kubism.ku.dk>
	<20A69DDC-E571-4DD1-9047-0073F47FA7CF@r-project.org>
	<20060222231022.GA24313@phenix.sram.qc.ca>
	<Pine.LNX.4.64.0602230552410.24547@gannet.stats.ox.ac.uk>
	<20060223231454.GA29213@alcyon.progiciels-bpi.ca>
Message-ID: <20060223232430.GA29792@alcyon.progiciels-bpi.ca>

[Fran?ois Pinard, clarifying himself]

>Adding a newline when "--slave" has not been selected, and whenever the 
>output is connected to a tty, is also wise, regardless if termination 
>is effected through q() or through hitting end-of-file.

Just to make sure I'm not misinterpreted, the "and" of the first line 
above should be read as a logical conjunction.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From berwin at maths.uwa.edu.au  Fri Feb 24 01:26:56 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 24 Feb 2006 08:26:56 +0800
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <Pine.LNX.4.64.0602232127250.26309@gannet.stats.ox.ac.uk>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
	<Pine.LNX.4.64.0602232127250.26309@gannet.stats.ox.ac.uk>
Message-ID: <17406.21200.539725.925232@bossiaea.maths.uwa.edu.au>

G'day all,

seems as if I must have slept through most of this most interesting
discussion. :)

>>>>> "BR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

    BR> On Thu, 23 Feb 2006, hadley wickham wrote:
    >> How can I write an index file with a pointer to my pdf?  Should
    >> I provide a code snippet to run
    >> system(paste(getOption("pdfviewer"), system.file("doc/my.pdf",
    >> package="mypackage"), "&"))?
    BR> Just add a hyperlink in inst/doc/index.html to foo.pdf and let
    BR> the browser do the rest.  The grid/doc/index.html is a
    BR> suitable template.
Editing this file by hand is certainly an option, but one more think
to remember while maintaining a package.  Thus, I think it is
preferable to automate process as much as possible.  I ran into a
similar problem as Hadley with a package that I am currently developing
(since some time) and offer my solution below.

>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca> writes:

    DM> On 2/23/2006 4:23 PM, hadley wickham wrote:
    >> What about (eg.) help(package=grid)?  This is where vignettes
    >> are listed by name (and location).  I would like to be able put
    >> my pdf into a similar list.
    DM> I don't think you can do that, but you should be using a
    DM> package man page anyway.
I believe this can be done, albeit not directly.

In my case, I wanted to include a PDF, whose source is not in Sweave
format, with the documentation of the package and have the links to
this documentation created automatically.  My solution, in the end was
to create a "dummy" Rnw vignette which has a link to the pdf file.  I
include that dummy vignette below.  Hence, in the directory inst/doc
of my package there are the following files:
    interface96.pdf             The PDF file I actually want to include
                                as part of the documentation
    interface96-vignette.Rnw    The dummy vignette file
Using hyperref with a "file:" url, the dummy vignette file links to
the actual files.

For the user, this means that she/he sees the dummy vignette and
access it first and then has to click once more on a link to get to
the actual document.  Slightly inconvenient for the user, but I
believe it is a fair price to pay to make my life as developer
easier. ;-))

If you want to distribute binary copies (e.g. for the various version
of Windows that exists) of your package, then you need of course all
the tools that are necessary to handle vignettes.

Cheers,

        Berwin

------------------------- Source of dummy vignette -------------------------
\documentclass[a4paper]{article}
%\VignetteIndexEntry{Interface '96 paper by Marron et al. (1997)}
%\VignettePackage{clps}

\usepackage{hyperref}
\usepackage{natbib}

\title{Interface '96 paper by \cite{mar:tur:wan:96}}
\author{Berwin A Turlach}
\date{September 25, 2004}

\begin{document}
\maketitle

This is just a dummy vignette with a link to the 
\href{file:interface96.pdf}{PDF file} of \cite{mar:tur:wan:96} which
is part of the \textit{CLPS} package.  The dummy vignette should
appear in the automatically generated index, but I did not succeed in
getting the actual paper to appear in that index.

\bibliographystyle{dcunsp}
\bibliography{clps}

\end{document}


From murdoch at stats.uwo.ca  Fri Feb 24 02:51:33 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 20:51:33 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	
	<43FE042B.4080601@stats.uwo.ca>	
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>	
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>	
	<43FE3453.6020405@stats.uwo.ca>
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>
Message-ID: <43FE66A5.3090103@stats.uwo.ca>

On 2/23/2006 5:49 PM, hadley wickham wrote:
>> We were referring to an HTML index file.  If you want to have a
>> reference from your package man page (foo-package.Rd) or some other man
>> page, you can use \url{../doc/my.pdf} and the link will work in HTML
>> versions of help, and won't be too misleading in other versions
>> (especially if you explain how to use it).
> 
> Ok, I'll give that a go.
> 
>> I don't think you can do that, but you should be using a package man
>> page anyway.
> 
> Can you suggest a good example of a package man page?  I've tried a
> few packages and haven't been able to find one.  The example generated
> by promptPackage suggests I need to duplicate the contents of
> DESCRIPTION and INDEX.

All of the base packages have them; some contain more than others.  I 
don't know which ones I'd consider to be "good".

They are meant to replace the INDEX, which you shouldn't need to create 
any more.  The DESCRIPTION file is still needed, but it contains more 
structured information meant for mechanical reading and processing; the 
package man page is meant to be the place to put things intended for 
people to read.

Duncan Murdoch


From h.wickham at gmail.com  Fri Feb 24 04:02:52 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Feb 2006 21:02:52 -0600
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <43FE66A5.3090103@stats.uwo.ca>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
	<43FE3453.6020405@stats.uwo.ca>
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>
	<43FE66A5.3090103@stats.uwo.ca>
Message-ID: <f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>

> They are meant to replace the INDEX, which you shouldn't need to create
> any more.  The DESCRIPTION file is still needed, but it contains more
> structured information meant for mechanical reading and processing; the
> package man page is meant to be the place to put things intended for
> people to read.

Do I need to keep the list of functions on the package man page in
sync myself, or will they be automatically rebuilt?  Is the intention
to eventually change help(package=XXX) to point to the package man
page?

Hadley


From ggrothendieck at gmail.com  Fri Feb 24 04:40:48 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Feb 2006 22:40:48 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
	<43FE3453.6020405@stats.uwo.ca>
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>
	<43FE66A5.3090103@stats.uwo.ca>
	<f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>
Message-ID: <971536df0602231940g169821cal766dd924531383a3@mail.gmail.com>

I haven't followed this whole thread but note that if your
package is called mypkg then you can create an .Rd
file called mypkg-package.Rd which will be called up
when the user issues:

package?mypkg

and that can contain links to whatever you are
interested in.

Try

library(dyn)
package?dyn

for an example.  The R command, promptPackage, can be
used to facilitate the creation of the -package.Rd file.


On 2/23/06, hadley wickham <h.wickham at gmail.com> wrote:
> > They are meant to replace the INDEX, which you shouldn't need to create
> > any more.  The DESCRIPTION file is still needed, but it contains more
> > structured information meant for mechanical reading and processing; the
> > package man page is meant to be the place to put things intended for
> > people to read.
>
> Do I need to keep the list of functions on the package man page in
> sync myself, or will they be automatically rebuilt?  Is the intention
> to eventually change help(package=XXX) to point to the package man
> page?
>
> Hadley
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Fri Feb 24 08:13:33 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 07:13:33 +0000 (GMT)
Subject: [Rd] Utilizing the internet module
In-Reply-To: <43FE4031.1080503@vanderbilt.edu>
References: <43FDEBEB.4040104@vanderbilt.edu>
	<Pine.LNX.4.64.0602231904380.10209@gannet.stats.ox.ac.uk>
	<43FE4031.1080503@vanderbilt.edu>
Message-ID: <Pine.LNX.4.64.0602240711150.2370@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, Jeffrey Horner wrote:

> Prof Brian Ripley wrote:
>> On Thu, 23 Feb 2006, Jeffrey Horner wrote:
>> 
>>> Hello all,
>>> 
>>> I'd like to utilize the R_Sock* functions from R_ext/R-ftp-http.h in my
>>> R package. The intent is to use these in conjunction with R_serialize()
>>>  to store R objects in a remote data store. I'm aware that version
>>> 2.2.1 of "Writing R extensions" explains that these may be undocumented
>>> and unstable, but I have a couple of questions:
>>> 
>>> 1) are they platform independent? I presume they are...
>> 
>> 
>> Only in sense that they have a common interface.
>> 
>>> 2) What's the appropriate way to link against them? On Linux x86, I can
>>> do this with the Makevars:
>> 
>> 
>> You can, but that is a module and not a library and so it does not work on 
>> MacOS X and may well not work on Windows (you would be lucky prior to R 
>> 2.3.0).
>> 
>> I wonder why you need a C interface at all.  There is serialize() and 
>> socket connections are available at R level.  Below that, Rsockopen etc are 
>> exported from R itself and underly make.socket etc.
>
> I may not need it (or get to use it portably), but as far as using Rsockopen, 
> etc. am I right in assuming that a package writer would have to copy the 
> declarations from src/main/basedecl.h into his/her own code in order to 
> utilize them? This seems odd when there's already an exposed (although 
> undocumented) interface with R_Sock*, so what's the point of having 
> R_ext/R-ftp-http.h? Is it just for some xml package?

Yes.  It was written as an internal header.  As you have discovered, the 
interface is not actually exposed.

> On a related note, how do I serialize() an R object to a database table 
> column of type BLOB? I've tried using RODBC but was unsuccessfully (see 
> R-sig-DB in Feb archive). I've also looked into RMySQL/DBI but I don't think 
> it's supported yet.

Since BLOB is not a standard SQL type (AFAIK), ODBC seems not to support 
it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From penel at biomserv.univ-lyon1.fr  Fri Feb 24 09:42:18 2006
From: penel at biomserv.univ-lyon1.fr (Simon Penel)
Date: Fri, 24 Feb 2006 09:42:18 +0100
Subject: [Rd] Problem during "make" with the devel version R-2.3.0 under
 Sun OS
References: <43FDC096.8010503@biomserv.univ-lyon1.fr>
	<Pine.LNX.4.64.0602232050570.25797@gannet.stats.ox.ac.uk>
Message-ID: <43FEC6EA.6050606@biomserv.univ-lyon1.fr>

Thank you very much for your help, and sorry for any inconvevience.
Your are rigth my current compiler version is  too old : 3.3.2.
I will upgrade it  immediately.
All the best and thanks again

Simon



Prof Brian Ripley wrote:

> This is a compiler error (generating invalid assembler), not an R 
> error. What compiler version is this?
>
> I have no problem compiling the current R-devel (37422) on Solaris 
> with gcc-3.4.5 or gcc-4.0.2 (and using the Sun assembler as you are).  
> I have seen problems with plot3d with earlier versions of gcc-4.
>
>
> On Thu, 23 Feb 2006, Simon Penel wrote:
>
>> Hello R users and developers,
>>
>> I had a problem when I tried to install  the last version of R-devel.
>> I know that this R version is an unstable version and that this problem
>> may be irrelevant.
>> I am  maintaining a R package  thus I check if this package can be
>> installed with the development version.
>> ( Everinthing is fine with the R-patched)
>>
>> The details are the following:
>>
>> My machine:
>> System:  SunOS
>> Release: 5.9
>> Kernel ID : Generic_117171-07
>> Machine : sun4u
>> Processor :sparc
>> Platform : SUNW Sun-Fire-880
>>
>> R version
>> 2.3.0 Under development (unstable)
>>
>> SVN:
>> Revision: 37414
>> Last Changed Date: 2006-02-22
>>
>> Results    affer configure:
>>
>> R is now configured for sparc-sun-solaris2.9
>>
>>  Source directory:          .
>>  Installation directory:    /usr/local
>>
>>  C compiler:                gcc  -g -O2 -std=gnu99
>>  Fortran 77 compiler:       g77  -g -O2
>>
>>  C++ compiler:              g++  -g -O2
>>  Fortran 90/95 compiler:    f90
>>
>>  Interfaces supported:      X11, tcltk
>>  External libraries:        readline
>>  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>>  Options enabled:           R profiling
>>
>>
>> The problem during make:
>>
>>
>> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
>> -I../../src/extra/pcre  -I. -I../../src/include -I../../src/include
>> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -std=gnu99 -c plot.c -o 
>> plot.o
>> gcc -I../../src/extra/zlib -I../../src/extra/bzip2
>> -I../../src/extra/pcre  -I. -I../../src/include -I../../src/include
>> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -std=gnu99 -c plot3d.c -o
>> plot3d.o
>> /usr/ccs/bin/as: "/tmp/ccYv732b.s", line 7057: error: constant value
>> must be between -4096 and 4095
>> make[3]: *** [plot3d.o] Error 1
>> make[3]: Leaving directory `/bge/penel/R-devel/src/main'
>> make[2]: *** [R] Error 2
>> make[2]: Leaving directory `/bge/penel/R-devel/src/main'
>> make[1]: *** [R] Error 1
>> make[1]: Leaving directory `/bge/penel/R-devel/src'
>> make: *** [R] Error 1
>>
>> I did not found any report about this problem in the R-devel archives .
>> Should I wait and try a next version of R-devel?
>>
>> thanks for your help, I hope this mail is not irrelevant
>>
>> Simon
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>

-- 
Simon Penel
Laboratoire de Biometrie et Biologie Evolutive           
Bat 711  -   CNRS UMR 5558  -    Universite Lyon 1              
43 bd du 11 novembre 1918 69622 Villeurbanne Cedex       
Tel:   04 72 43 12 87      Fax:  04 72 43 13 88
http://pbil.univ-lyon1.fr/members/penel


From ripley at stats.ox.ac.uk  Fri Feb 24 09:49:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 08:49:43 +0000 (GMT)
Subject: [Rd] Utilizing the internet module
In-Reply-To: <Pine.LNX.4.64.0602231904380.10209@gannet.stats.ox.ac.uk>
References: <43FDEBEB.4040104@vanderbilt.edu>
	<Pine.LNX.4.64.0602231904380.10209@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602240832060.3665@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, Prof Brian Ripley wrote:

> On Thu, 23 Feb 2006, Jeffrey Horner wrote:
>
>> Hello all,
>>
>> I'd like to utilize the R_Sock* functions from R_ext/R-ftp-http.h in my
>> R package. The intent is to use these in conjunction with R_serialize()
>>  to store R objects in a remote data store. I'm aware that version
>> 2.2.1 of "Writing R extensions" explains that these may be undocumented
>> and unstable, but I have a couple of questions:
>>
>> 1) are they platform independent? I presume they are...
>
> Only in sense that they have a common interface.
>
>> 2) What's the appropriate way to link against them? On Linux x86, I can
>> do this with the Makevars:
>
> You can, but that is a module and not a library and so it does not work on
> MacOS X and may well not work on Windows (you would be lucky prior to R
> 2.3.0).

It also does not work in R-devel on any system that supports visibility 
attributes, for example Linux systems with gcc4, and some RedHat systems 
with gcc 3.4.4.  I am removing the declarations from R_exts/R-ftp-http.c 
for R 2.3.0.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From roebuck at mdanderson.org  Fri Feb 24 10:12:02 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Fri, 24 Feb 2006 03:12:02 -0600 (CST)
Subject: [Rd] Minor Typo in image.Rd
Message-ID: <Pine.OSF.4.58.0602240304410.257724@wotan.mdacc.tmc.edu>

<https://svn.r-project.org/R/trunk/src/library/graphics/man/image.Rd>


Currently:
==========
\arguments{
[...]
  \item{xlab, ylab}{
[...]
Default to the \sQuote{call names} of \code{x} or \code{y},
or to \code{""} if these where unspecified.}
                         ^^^^^

Should read:
============
\arguments{
[...]
  \item{xlab, ylab}{
[...]
Default to the \sQuote{call names} of \code{x} or \code{y},
or to \code{""} if these were unspecified.}

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From murdoch at stats.uwo.ca  Fri Feb 24 12:49:55 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Feb 2006 06:49:55 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	
	<43FE042B.4080601@stats.uwo.ca>	
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>	
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>	
	<43FE3453.6020405@stats.uwo.ca>	
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>	
	<43FE66A5.3090103@stats.uwo.ca>
	<f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>
Message-ID: <43FEF2E3.3070609@stats.uwo.ca>

On 2/23/2006 10:02 PM, hadley wickham wrote:
>> They are meant to replace the INDEX, which you shouldn't need to create
>> any more.  The DESCRIPTION file is still needed, but it contains more
>> structured information meant for mechanical reading and processing; the
>> package man page is meant to be the place to put things intended for
>> people to read.
> 
> Do I need to keep the list of functions on the package man page in
> sync myself, or will they be automatically rebuilt?  Is the intention
> to eventually change help(package=XXX) to point to the package man
> page?

No, there's no automatic building after the promptPackage call.  It's up 
to you to decide which functions need to be mentioned to users.  In 
large packages it usually doesn't make sense to list all the functions, 
so the package writer needs to use judgement here.  There are other 
mechanisms (e.g. ls("package:XXX") for a list of names, the help index 
generation for a list of names and titles) to get a list of everything.

There aren't any immediate plans to change help(package=XXX), but I 
think in the long run, if package?XXX receives wider support than it has 
now, it would make sense to make that change.

Duncan Murdoch


From murdoch at stats.uwo.ca  Fri Feb 24 13:21:51 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Feb 2006 07:21:51 -0500
Subject: [Rd] Minor Typo in image.Rd
In-Reply-To: <Pine.OSF.4.58.0602240304410.257724@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0602240304410.257724@wotan.mdacc.tmc.edu>
Message-ID: <43FEFA5F.3010702@stats.uwo.ca>

Thanks, I'll fix this.

Duncan Murdoch

On 2/24/2006 4:12 AM, Paul Roebuck wrote:
> <https://svn.r-project.org/R/trunk/src/library/graphics/man/image.Rd>
> 
> 
> Currently:
> ==========
> \arguments{
> [...]
>   \item{xlab, ylab}{
> [...]
> Default to the \sQuote{call names} of \code{x} or \code{y},
> or to \code{""} if these where unspecified.}
>                          ^^^^^
> 
> Should read:
> ============
> \arguments{
> [...]
>   \item{xlab, ylab}{
> [...]
> Default to the \sQuote{call names} of \code{x} or \code{y},
> or to \code{""} if these were unspecified.}
> 
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From francoisromain at free.fr  Fri Feb 24 13:27:10 2006
From: francoisromain at free.fr (Romain Francois)
Date: Fri, 24 Feb 2006 13:27:10 +0100
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <17406.21200.539725.925232@bossiaea.maths.uwa.edu.au>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	<43FE042B.4080601@stats.uwo.ca>	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>	<Pine.LNX.4.64.0602232127250.26309@gannet.stats.ox.ac.uk>
	<17406.21200.539725.925232@bossiaea.maths.uwa.edu.au>
Message-ID: <43FEFB9E.5020700@free.fr>

Le 24.02.2006 01:26, Berwin A Turlach a ?crit :
> G'day all,
>
> seems as if I must have slept through most of this most interesting
> discussion. :)
>
>   
>>>>>> "BR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>>>>>>             
>
>     BR> On Thu, 23 Feb 2006, hadley wickham wrote:
>     >> How can I write an index file with a pointer to my pdf?  Should
>     >> I provide a code snippet to run
>     >> system(paste(getOption("pdfviewer"), system.file("doc/my.pdf",
>     >> package="mypackage"), "&"))?
>     BR> Just add a hyperlink in inst/doc/index.html to foo.pdf and let
>     BR> the browser do the rest.  The grid/doc/index.html is a
>     BR> suitable template.
> Editing this file by hand is certainly an option, but one more think
> to remember while maintaining a package.  Thus, I think it is
> preferable to automate process as much as possible.  I ran into a
> similar problem as Hadley with a package that I am currently developing
> (since some time) and offer my solution below.
>
>   
>>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>>>>>>             
>
>     DM> On 2/23/2006 4:23 PM, hadley wickham wrote:
>     >> What about (eg.) help(package=grid)?  This is where vignettes
>     >> are listed by name (and location).  I would like to be able put
>     >> my pdf into a similar list.
>     DM> I don't think you can do that, but you should be using a
>     DM> package man page anyway.
> I believe this can be done, albeit not directly.
>
> In my case, I wanted to include a PDF, whose source is not in Sweave
> format, with the documentation of the package and have the links to
> this documentation created automatically.  My solution, in the end was
> to create a "dummy" Rnw vignette which has a link to the pdf file.  I
> include that dummy vignette below.  Hence, in the directory inst/doc
> of my package there are the following files:
>     interface96.pdf             The PDF file I actually want to include
>                                 as part of the documentation
>     interface96-vignette.Rnw    The dummy vignette file
> Using hyperref with a "file:" url, the dummy vignette file links to
> the actual files.
>
> For the user, this means that she/he sees the dummy vignette and
> access it first and then has to click once more on a link to get to
> the actual document.  Slightly inconvenient for the user, but I
> believe it is a fair price to pay to make my life as developer
> easier. ;-))
>
> If you want to distribute binary copies (e.g. for the various version
> of Windows that exists) of your package, then you need of course all
> the tools that are necessary to handle vignettes.
>
> Cheers,
>
>         Berwin
>
> ------------------------- Source of dummy vignette -------------------------
> \documentclass[a4paper]{article}
> %\VignetteIndexEntry{Interface '96 paper by Marron et al. (1997)}
> %\VignettePackage{clps}
>
> \usepackage{hyperref}
> \usepackage{natbib}
>
> \title{Interface '96 paper by \cite{mar:tur:wan:96}}
> \author{Berwin A Turlach}
> \date{September 25, 2004}
>
> \begin{document}
> \maketitle
>
> This is just a dummy vignette with a link to the 
> \href{file:interface96.pdf}{PDF file} of \cite{mar:tur:wan:96} which
> is part of the \textit{CLPS} package.  The dummy vignette should
> appear in the automatically generated index, but I did not succeed in
> getting the actual paper to appear in that index.
>
> \bibliographystyle{dcunsp}
> \bibliography{clps}
>
> \end{document}
>   
Hi,

What about using the latex package pdfpages to copy the pages from your 
PDF file `interface96.pdf` to your Sweave file. (I don't know if it is 
compatible with Sweave).

Not tested :

\documentclass[a4paper]{article}
%\VignetteIndexEntry{Interface '96 paper by Marron et al. (1997)}
%\VignettePackage{clps}

\usepackage{hyperref}
\usepackage{natbib}
\usepackage{pdfpages}

\title{Interface '96 paper by \cite{mar:tur:wan:96}}
\author{Berwin A Turlach}
\date{September 25, 2004}

\begin{document}
\maketitle

\newpage

\includepdf{interface96.pdf}


\bibliographystyle{dcunsp}
\bibliography{clps}

\end{document}


Romain
 

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
Discover the R Movies Gallery : http://addictedtor.free.fr/movies
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From murdoch at stats.uwo.ca  Fri Feb 24 15:11:44 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Feb 2006 09:11:44 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <43FEFB9E.5020700@free.fr>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	<43FE042B.4080601@stats.uwo.ca>	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>	<Pine.LNX.4.64.0602232127250.26309@gannet.stats.ox.ac.uk>	<17406.21200.539725.925232@bossiaea.maths.uwa.edu.au>
	<43FEFB9E.5020700@free.fr>
Message-ID: <43FF1420.2030604@stats.uwo.ca>

On 2/24/2006 7:27 AM, Romain Francois wrote:
> 
> What about using the latex package pdfpages to copy the pages from your 
> PDF file `interface96.pdf` to your Sweave file. (I don't know if it is 
> compatible with Sweave).
> 
> Not tested :
> 
> \documentclass[a4paper]{article}
> %\VignetteIndexEntry{Interface '96 paper by Marron et al. (1997)}
> %\VignettePackage{clps}
> 
> \usepackage{hyperref}
> \usepackage{natbib}
> \usepackage{pdfpages}
> 
> \title{Interface '96 paper by \cite{mar:tur:wan:96}}
> \author{Berwin A Turlach}
> \date{September 25, 2004}
> 
> \begin{document}
> \maketitle
> 
> \newpage
> 
> \includepdf{interface96.pdf}
> 
> 
> \bibliographystyle{dcunsp}
> \bibliography{clps}
> 
> \end{document}

That's a nice hack.  You probably want the "fitpaper" option on the 
\includepdf command, so that you don't get an extra border around the 
page.  For example, this file test.Rnw

\documentclass{article}
%\VignetteIndexEntry{test include of pdf}
%\VignettePackage{ellipse}

\usepackage{pdfpages}

\begin{document}

\includepdf[fitpaper=true]{response.pdf}

\end{document}

produces an output that looks pretty much exactly like the 
"response.pdf" file I used as test input in a viewer.

The only disadvantages I see are that both the test.pdf and response.pdf 
files got built into the package (but only test.pdf shows up in the 
index), and that test.pdf is a lot larger than response.pdf.  (This may 
be because response.pdf was small; I haven't checked if the increase is 
additive or multiplicative).

For a non-hack solution:

A change to the R package build process would be to add support for a 
command like

%\VignetteExists

to the test.Rnw file, telling R not to bother trying to build the pdf, 
because it had already been built by other means.  Then I'd just have 
test.Rnw containing

%\VignetteIndexEntry{test include of pdf}
%\VignettePackage{ellipse}
%\VignetteExists

and solve both of the problems with Romain's workaround.

Duncan Murdoch


From h.wickham at gmail.com  Fri Feb 24 15:29:25 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 24 Feb 2006 08:29:25 -0600
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <43FEF2E3.3070609@stats.uwo.ca>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
	<43FE3453.6020405@stats.uwo.ca>
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>
	<43FE66A5.3090103@stats.uwo.ca>
	<f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>
	<43FEF2E3.3070609@stats.uwo.ca>
Message-ID: <f8e6ff050602240629j2f31d4e7g23dd726472010114@mail.gmail.com>

> No, there's no automatic building after the promptPackage call.  It's up
> to you to decide which functions need to be mentioned to users.  In
> large packages it usually doesn't make sense to list all the functions,
> so the package writer needs to use judgement here.  There are other
> mechanisms (e.g. ls("package:XXX") for a list of names, the help index
> generation for a list of names and titles) to get a list of everything.

Ok, that seems reasonable, but perhaps promptPackage (or
documentation) could make this more clear.

> There aren't any immediate plans to change help(package=XXX), but I
> think in the long run, if package?XXX receives wider support than it has
> now, it would make sense to make that change.

When was this form of package documentation created?  How are users
supposed to know it exists?  I couldn't find any pointers to it from
?help, ?library or from help(package=XXX).

Hadley


From hin-tak.leung at cimr.cam.ac.uk  Fri Feb 24 15:47:00 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 24 Feb 2006 14:47:00 +0000
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <43FF1420.2030604@stats.uwo.ca>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	<43FE042B.4080601@stats.uwo.ca>	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>	<Pine.LNX.4.64.0602232127250.26309@gannet.stats.ox.ac.uk>	<17406.21200.539725.925232@bossiaea.maths.uwa.edu.au>	<43FEFB9E.5020700@free.fr>
	<43FF1420.2030604@stats.uwo.ca>
Message-ID: <43FF1C64.4010303@cimr.cam.ac.uk>

Duncan Murdoch wrote:
<snipped>
>>\usepackage{pdfpages}
<snipped>
> That's a nice hack.  You probably want the "fitpaper" option on the 
> \includepdf command, so that you don't get an extra border around the 
> page.  For example, this file test.Rnw
<snipped>
> The only disadvantages I see are that both the test.pdf and response.pdf 
> files got built into the package (but only test.pdf shows up in the 
> index), and that test.pdf is a lot larger than response.pdf.  (This may 
> be because response.pdf was small; I haven't checked if the increase is 
> additive or multiplicative).
<snipped>

I like pdfpages and do use it from time to time (as frequently as
every couple of weeks for filling expense/travel/claim forms) -
but in fact it isn't shipped with tetex 1.0 and is not in the
site-wise LaTeX installation in my work location.
(and luckily I am not using the site-wise one...). I checked and
pdfpages was added to tetex in Oct 2001 and is in tetex 2.0 which
was released in feb 2003; but sites could be slow in upgrading...
so such constructions would break on sites which hasn't upgraded
their LaTeX installation in the last 3 years.

HTL


From jeff.horner at vanderbilt.edu  Fri Feb 24 17:05:00 2006
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri, 24 Feb 2006 10:05:00 -0600
Subject: [Rd] Utilizing the internet module
In-Reply-To: <Pine.LNX.4.64.0602240711150.2370@gannet.stats.ox.ac.uk>
References: <43FDEBEB.4040104@vanderbilt.edu>
	<Pine.LNX.4.64.0602231904380.10209@gannet.stats.ox.ac.uk>
	<43FE4031.1080503@vanderbilt.edu>
	<Pine.LNX.4.64.0602240711150.2370@gannet.stats.ox.ac.uk>
Message-ID: <43FF2EAC.3070804@vanderbilt.edu>

Prof Brian Ripley wrote:
> On Thu, 23 Feb 2006, Jeffrey Horner wrote:
[...]
>> On a related note, how do I serialize() an R object to a database 
>> table column of type BLOB? I've tried using RODBC but was 
>> unsuccessfully (see R-sig-DB in Feb archive). I've also looked into 
>> RMySQL/DBI but I don't think it's supported yet.
> 
> 
> Since BLOB is not a standard SQL type (AFAIK), ODBC seems not to support 
> it.
> 

It's not standard, per se, but many ODBC drivers and many databases 
(Oracle, MS SQL Server, MySQL, Postgresql, Access, ...) support such a 
type. In fact, the structured query language standards SQL92 and SQL99 
define the type BIT and BIT VARYING to hold arbitrary bit strings, which 
I think is some sort of endorsement for this type.

-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University


From murdoch at stats.uwo.ca  Fri Feb 24 17:38:10 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Feb 2006 11:38:10 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602240629j2f31d4e7g23dd726472010114@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>	
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>	
	<43FE3453.6020405@stats.uwo.ca>	
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>	
	<43FE66A5.3090103@stats.uwo.ca>	
	<f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>	
	<43FEF2E3.3070609@stats.uwo.ca>
	<f8e6ff050602240629j2f31d4e7g23dd726472010114@mail.gmail.com>
Message-ID: <43FF3672.70801@stats.uwo.ca>

On 2/24/2006 9:29 AM, hadley wickham wrote:
>> No, there's no automatic building after the promptPackage call.  It's up
>> to you to decide which functions need to be mentioned to users.  In
>> large packages it usually doesn't make sense to list all the functions,
>> so the package writer needs to use judgement here.  There are other
>> mechanisms (e.g. ls("package:XXX") for a list of names, the help index
>> generation for a list of names and titles) to get a list of everything.
> 
> Ok, that seems reasonable, but perhaps promptPackage (or
> documentation) could make this more clear.
> 
>> There aren't any immediate plans to change help(package=XXX), but I
>> think in the long run, if package?XXX receives wider support than it has
>> now, it would make sense to make that change.
> 
> When was this form of package documentation created?  How are users
> supposed to know it exists?  I couldn't find any pointers to it from
> ?help, ?library or from help(package=XXX).

It's described in the Writing R Extensions Manual, in Writing R 
Documentation Files, Rd Format, Documenting Packages (section 2.1.4 in 
the PDF).

There probably should be more pointers to it...

Duncan Murdoch


From murdoch at stats.uwo.ca  Fri Feb 24 20:11:13 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Feb 2006 14:11:13 -0500
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602240842i6781e882mcfad6a7961e64dcb@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>	
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>	
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>	
	<43FE3453.6020405@stats.uwo.ca>	
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>	
	<43FE66A5.3090103@stats.uwo.ca>	
	<f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>	
	<43FEF2E3.3070609@stats.uwo.ca>	
	<f8e6ff050602240629j2f31d4e7g23dd726472010114@mail.gmail.com>	
	<43FF3672.70801@stats.uwo.ca>
	<f8e6ff050602240842i6781e882mcfad6a7961e64dcb@mail.gmail.com>
Message-ID: <43FF5A51.7030700@stats.uwo.ca>

On 2/24/2006 11:42 AM, hadley wickham wrote:
>> > When was this form of package documentation created?  How are users
>> > supposed to know it exists?  I couldn't find any pointers to it from
>> > ?help, ?library or from help(package=XXX).
>>
>> It's described in the Writing R Extensions Manual, in Writing R
>> Documentation Files, Rd Format, Documenting Packages (section 2.1.4 in
>> the PDF).
> 
> That's great for developers, but how are users supposed to find out?

I think users would be disappointed if they tried using package?foo 
right now, because mostly it tells you there's no such man page.  First 
you need a few more developers to follow the recommendations, before it 
really makes sense to advertise the feature.

An alternative approach would be for R CMD check to warn developers who 
don't have such a man page.  That would encourage adoption of this 
convention, but there were quite a few objections when I suggested it. 
It does put a load on package authors.

Another alternative would be for a default package man page to be built 
if the developer didn't supply one; that's probably a good idea, but not 
one I have time to act on before 2.3.x, so it's not coming soon.

If you feel like writing some patches to the documentation in the 
appropriate places, and it looks as though they won't mislead readers, 
please do so, and I'll review and commit them.  If you want to revise 
the package build scripts, you're going to need to find someone else to 
commit them; I will not have enough time to review things that could 
cause that much trouble if you get it wrong.

Duncan Murdoch


From agarbutt at systemsbiology.org  Fri Feb 24 22:11:20 2006
From: agarbutt at systemsbiology.org (Andrew Garbutt)
Date: Fri, 24 Feb 2006 13:11:20 -0800
Subject: [Rd] Rcpp, best method for linking to
Message-ID: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1C60@exchange.systemsbiology.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060224/aa7635ad/attachment.pl

From afinley at stat.umn.edu  Fri Feb 24 23:03:10 2006
From: afinley at stat.umn.edu (Andrew Finley)
Date: Fri, 24 Feb 2006 16:03:10 -0600
Subject: [Rd] Rcpp, best method for linking to
In-Reply-To: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1C60@exchange.systemsbiology.net>
References: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1C60@exchange.systemsbiology.net>
Message-ID: <1140818590.30443.8.camel@populus.fr.umn.edu>

Hi Andy,
Follow the suggestions for c++ in the Writing R Extensions document.
Wrap your c++ code in extern "C"{}, include your classes in the includes
(e.g., #include "myclass.h") and put the myclass.h and myclass.cpp in
the src directory along with your other code. Then R CMD build ... and R
CMD INSTALL ...  This works for me. 
-Andy


On Fri, 2006-02-24 at 13:11 -0800, Andrew Garbutt wrote:
> Dear all,
> 
>  
> 
> After a bit of reading I came across the Rcpp example package.  There
> are a few classes that I would like to use and I am not sure how best to
> include them in my own package.  Is it best to compile it as an
> independent library and link to it? Or is there some way to `require` it
> for my own package?  Re-write using the code as an example (unsure how
> best to do this at this moment, as the Rcpp package is licensed under
> the GPL v2 and I am unsure of the license that I wish to use for my own
> package.)  Any thoughts or ideas would be appreciated.
> 
>  
> 
> Thanks,
> 
> Andy 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Research Fellow
Department of Forest Resources
University of Minnesota
Office: 305 Green Hall
Phone: (612) 624-1714
Fax: (612) 625-5212
web: http://blue.fr.umn.edu


From dsamperi at DecisionSynergy.com  Fri Feb 24 23:30:22 2006
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Fri, 24 Feb 2006 17:30:22 -0500
Subject: [Rd] Rcpp, best method for linking to
In-Reply-To: <1140818590.30443.8.camel@populus.fr.umn.edu>
References: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1C60@exchange.systemsbiology.net>
	<1140818590.30443.8.camel@populus.fr.umn.edu>
Message-ID: <43FF88FE.2020605@DecisionSynergy.com>


Hi Andy (and Andy),

I'm not sure why there should be any licensing issues. R itself is GPL-ed,
so I just followed this convention.

Of course, you can do it yourself with extern "C" and all that. The
purpose of Rcpp.{cpp,hpp} is to enable you to write
readable code (for a C++ programmer) while hiding the error-prone
macro gymnastics that is required to fetch R parameters when using
the .Call interface. There is also a fair amount of type checking done
in the Rcpp package that relieves you of the trouble of putting many
checks in your R code.

If you are using the older, simpler .C interface this may not be
important to you. But note that the same functionality is available
through Rcpp, with the added convenience that list item names
are not dropped like they are when you use the .C interface.

Dominick

Andrew Finley wrote:
> Hi Andy,
> Follow the suggestions for c++ in the Writing R Extensions document.
> Wrap your c++ code in extern "C"{}, include your classes in the includes
> (e.g., #include "myclass.h") and put the myclass.h and myclass.cpp in
> the src directory along with your other code. Then R CMD build ... and R
> CMD INSTALL ...  This works for me. 
> -Andy
>
>
> On Fri, 2006-02-24 at 13:11 -0800, Andrew Garbutt wrote:
>   
>> Dear all,
>>
>>  
>>
>> After a bit of reading I came across the Rcpp example package.  There
>> are a few classes that I would like to use and I am not sure how best to
>> include them in my own package.  Is it best to compile it as an
>> independent library and link to it? Or is there some way to `require` it
>> for my own package?  Re-write using the code as an example (unsure how
>> best to do this at this moment, as the Rcpp package is licensed under
>> the GPL v2 and I am unsure of the license that I wish to use for my own
>> package.)  Any thoughts or ideas would be appreciated.
>>
>>  
>>
>> Thanks,
>>
>> Andy 
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From agarbutt at systemsbiology.org  Sat Feb 25 00:00:17 2006
From: agarbutt at systemsbiology.org (Andrew Garbutt)
Date: Fri, 24 Feb 2006 15:00:17 -0800
Subject: [Rd] Rcpp, best method for linking to
Message-ID: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>

Dominick,

Sorry, that's not quite what I was asking.  I was asking more of a "best
practice" kind of question. My own C++ codes compile fine and are
accessible to R with some great #define magic.  I was noting that the
Rcpp package has some generic classes to handle conversion of SEXP
structures to STL and back again. As I far as I can see, using them
would require that I compile the C++ code into a library and link to
that library. Or copy the code into my own code base, but doing would
restrict myself to the GPL, as it would be a derivative work?? (IANAL)
At this point I do not want to commit to any particular licensure for my
package.  

So, to sum up my "actual" question... 
Is it better to create a libRcpp.a and link to that? Have a copy of the
Rcpp.cpp/.hpp files in my own code base compiling them directly?
Require that any particular R installation have the requirement that the
Rcpp package be installed prior?

Thanks for your time,
Andy

-----Original Message-----
From: Dominick Samperi [mailto:dsamperi at DecisionSynergy.com] 
Sent: Friday, February 24, 2006 2:30 PM
To: Andrew Finley
Cc: Andrew Garbutt; r-devel at r-project.org
Subject: Re: [Rd] Rcpp, best method for linking to


Hi Andy (and Andy),

I'm not sure why there should be any licensing issues. R itself is
GPL-ed,
so I just followed this convention.

Of course, you can do it yourself with extern "C" and all that. The
purpose of Rcpp.{cpp,hpp} is to enable you to write
readable code (for a C++ programmer) while hiding the error-prone
macro gymnastics that is required to fetch R parameters when using
the .Call interface. There is also a fair amount of type checking done
in the Rcpp package that relieves you of the trouble of putting many
checks in your R code.

If you are using the older, simpler .C interface this may not be
important to you. But note that the same functionality is available
through Rcpp, with the added convenience that list item names
are not dropped like they are when you use the .C interface.

Dominick

Andrew Finley wrote:
> Hi Andy,
> Follow the suggestions for c++ in the Writing R Extensions document.
> Wrap your c++ code in extern "C"{}, include your classes in the
includes
> (e.g., #include "myclass.h") and put the myclass.h and myclass.cpp in
> the src directory along with your other code. Then R CMD build ... and
R
> CMD INSTALL ...  This works for me. 
> -Andy
>
>
> On Fri, 2006-02-24 at 13:11 -0800, Andrew Garbutt wrote:
>   
>> Dear all,
>>
>>  
>>
>> After a bit of reading I came across the Rcpp example package.  There
>> are a few classes that I would like to use and I am not sure how best
to
>> include them in my own package.  Is it best to compile it as an
>> independent library and link to it? Or is there some way to `require`
it
>> for my own package?  Re-write using the code as an example (unsure
how
>> best to do this at this moment, as the Rcpp package is licensed under
>> the GPL v2 and I am unsure of the license that I wish to use for my
own
>> package.)  Any thoughts or ideas would be appreciated.
>>
>>  
>>
>> Thanks,
>>
>> Andy 
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From dsamperi at DecisionSynergy.com  Sat Feb 25 00:13:02 2006
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Fri, 24 Feb 2006 18:13:02 -0500
Subject: [Rd] Rcpp, best method for linking to
In-Reply-To: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>
References: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>
Message-ID: <43FF92FE.1060208@DecisionSynergy.com>

Andy,

Any of the options you mentioned (libRcpp.a, source, etc.) sound fine
to me. If the GPL is a problem I am happy to change this to some other
open source license (I'm not entirely comfortable with GPL, and used
it because R uses it). I'm open to suggestions.

Dominick

Andrew Garbutt wrote:
> Dominick,
>
> Sorry, that's not quite what I was asking.  I was asking more of a "best
> practice" kind of question. My own C++ codes compile fine and are
> accessible to R with some great #define magic.  I was noting that the
> Rcpp package has some generic classes to handle conversion of SEXP
> structures to STL and back again. As I far as I can see, using them
> would require that I compile the C++ code into a library and link to
> that library. Or copy the code into my own code base, but doing would
> restrict myself to the GPL, as it would be a derivative work?? (IANAL)
> At this point I do not want to commit to any particular licensure for my
> package.  
>
> So, to sum up my "actual" question... 
> Is it better to create a libRcpp.a and link to that? Have a copy of the
> Rcpp.cpp/.hpp files in my own code base compiling them directly?
> Require that any particular R installation have the requirement that the
> Rcpp package be installed prior?
>
> Thanks for your time,
> Andy
>
> -----Original Message-----
> From: Dominick Samperi [mailto:dsamperi at DecisionSynergy.com] 
> Sent: Friday, February 24, 2006 2:30 PM
> To: Andrew Finley
> Cc: Andrew Garbutt; r-devel at r-project.org
> Subject: Re: [Rd] Rcpp, best method for linking to
>
>
> Hi Andy (and Andy),
>
> I'm not sure why there should be any licensing issues. R itself is
> GPL-ed,
> so I just followed this convention.
>
> Of course, you can do it yourself with extern "C" and all that. The
> purpose of Rcpp.{cpp,hpp} is to enable you to write
> readable code (for a C++ programmer) while hiding the error-prone
> macro gymnastics that is required to fetch R parameters when using
> the .Call interface. There is also a fair amount of type checking done
> in the Rcpp package that relieves you of the trouble of putting many
> checks in your R code.
>
> If you are using the older, simpler .C interface this may not be
> important to you. But note that the same functionality is available
> through Rcpp, with the added convenience that list item names
> are not dropped like they are when you use the .C interface.
>
> Dominick
>
> Andrew Finley wrote:
>   
>> Hi Andy,
>> Follow the suggestions for c++ in the Writing R Extensions document.
>> Wrap your c++ code in extern "C"{}, include your classes in the
>>     
> includes
>   
>> (e.g., #include "myclass.h") and put the myclass.h and myclass.cpp in
>> the src directory along with your other code. Then R CMD build ... and
>>     
> R
>   
>> CMD INSTALL ...  This works for me. 
>> -Andy
>>
>>
>> On Fri, 2006-02-24 at 13:11 -0800, Andrew Garbutt wrote:
>>   
>>     
>>> Dear all,
>>>
>>>  
>>>
>>> After a bit of reading I came across the Rcpp example package.  There
>>> are a few classes that I would like to use and I am not sure how best
>>>       
> to
>   
>>> include them in my own package.  Is it best to compile it as an
>>> independent library and link to it? Or is there some way to `require`
>>>       
> it
>   
>>> for my own package?  Re-write using the code as an example (unsure
>>>       
> how
>   
>>> best to do this at this moment, as the Rcpp package is licensed under
>>> the GPL v2 and I am unsure of the license that I wish to use for my
>>>       
> own
>   
>>> package.)  Any thoughts or ideas would be appreciated.
>>>
>>>  
>>>
>>> Thanks,
>>>
>>> Andy 
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>     
>>>


From edd at debian.org  Sat Feb 25 04:13:51 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 24 Feb 2006 21:13:51 -0600
Subject: [Rd] Rcpp, best method for linking to
In-Reply-To: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>
References: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>
Message-ID: <17407.52079.241833.854793@basebud.nulle.part>


Andrew, 

On 24 February 2006 at 15:00, Andrew Garbutt wrote:
| Sorry, that's not quite what I was asking.  I was asking more of a "best
| practice" kind of question. My own C++ codes compile fine and are
| accessible to R with some great #define magic.  I was noting that the
| Rcpp package has some generic classes to handle conversion of SEXP
| structures to STL and back again. As I far as I can see, using them
| would require that I compile the C++ code into a library and link to
| that library. Or copy the code into my own code base, but doing would
| restrict myself to the GPL, as it would be a derivative work?? (IANAL)
| At this point I do not want to commit to any particular licensure for my
| package.  

I may be misunderstanding you but here it goes: if you are using Rcpp as a
means to get to R, you still end up linking with R itself.  It is my
understanding that this implies the GPL -- or a suitable GPL-compatible
license -- for your code.

I do not see any _additional restriction_ coming in via the addition of
Rcpp. You already use GPL'ed object files / libraries via R itself. Plus
you're presumably building with R toolchain via 'R CMD INSTALL ....'

Hth, Dirk
 
-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From berwin at maths.uwa.edu.au  Sat Feb 25 08:41:13 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 25 Feb 2006 15:41:13 +0800
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <43FF1420.2030604@stats.uwo.ca>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<43FE042B.4080601@stats.uwo.ca>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
	<Pine.LNX.4.64.0602232127250.26309@gannet.stats.ox.ac.uk>
	<17406.21200.539725.925232@bossiaea.maths.uwa.edu.au>
	<43FEFB9E.5020700@free.fr> <43FF1420.2030604@stats.uwo.ca>
Message-ID: <17408.2585.367987.53173@bossiaea.maths.uwa.edu.au>

G'day all,

>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca> writes:

    DM> On 2/24/2006 7:27 AM, Romain Francois wrote:
    >> 
    >> What about using the latex package pdfpages to copy the pages from your 
    >> PDF file `interface96.pdf` to your Sweave file. 
Merci beaucoup, I wasn't aware that this style file exists, it
definitely seems to be useful.

    DM> That's a nice hack.  You probably want the "fitpaper" option on the 
    DM> \includepdf command, so that you don't get an extra border around the 
    DM> page.  For example, this file test.Rnw [...]

    DM> \includepdf[fitpaper=true]{response.pdf}
Additionally, if response.pdf has several pages and you want to
include them all, you should also include a "pages" options, such as:

        \includepdf[fitpaper=true,pages=-]{interface96.pdf}

More details can be found in the pdfpages documentation, but by
default only the first page is included.

    DM> produces an output that looks pretty much exactly like the 
    DM> "response.pdf" file I used as test input in a viewer.
Perhaps interface96.pdf was created too long ago (it says PDF 1.2 at
the top of that file), but the result looks strange in xpdf (the
included pages are quite small and in the upper left corner, selecting
"fit to page" creates an acceptable viewing results); no problem with
acroread.  This is on a linux box.

    DM> The only disadvantages I see are that both the test.pdf and
    DM> response.pdf files got built into the package (but only
    DM> test.pdf shows up in the index),
That is a potential disadvantage as it duplicates material.  But I
guess .Rbuildignore in the main directory of the package can help in
this case.  I have put the line "inst/doc/interface96.pdf" into the
.Rbuildignore file of that package.

    DM> and that test.pdf is a lot larger than response.pdf.  (This
    DM> may be because response.pdf was small; I haven't checked if
    DM> the increase is additive or multiplicative).
I didn't check this either, but here are some results on including a 6
page pdf file (extracts from looking at the .tar.gz file produced by
the build process).  First, the old solution with a separate PDF file
and a dummy vignette:

 drwxr-xr-x  berwin/berwin        0 clps/inst/
 drwxr-xr-x  berwin/berwin        0 clps/inst/doc/
 -rw-r--r--  berwin/berwin      649 clps/inst/doc/clps.bib
 -rw-r--r--  berwin/berwin      670 clps/inst/doc/interface96-vignette.Rnw
 -rw-r--r--  berwin/berwin   105035 clps/inst/doc/interface96.pdf
 -rw-r--r--  berwin/berwin    49242 clps/inst/doc/interface96-vignette.pdf
 
Second, with \includepdf and .Rbuildignore:

 drwxr-xr-x  berwin/berwin        0 clps/inst/
 drwxr-xr-x  berwin/berwin        0 clps/inst/doc/
 -rw-r--r--  berwin/berwin      649 clps/inst/doc/clps.bib
 -rw-r--r--  berwin/berwin      440 clps/inst/doc/interface96-vignette.Rnw
 -rw-r--r--  berwin/berwin   191589 clps/inst/doc/interface96-vignette.pdf

Looks like an increase of about 40 kB to me which I would find acceptable.

    DM> A change to the R package build process would be to add support for a 
    DM> command like

    DM> %\VignetteExists

    DM> to the test.Rnw file, telling R not to bother trying to build the pdf, 
    DM> because it had already been built by other means.  Then I'd just have 
    DM> test.Rnw containing
Searching the "Writing R Extensions" manual for vignette, I noticed
the following:

      Unless @kbd{R CMD build} is invoked with the
      @option{--no-vignettes} option, it will attempt to rebuild the
      vignettes (@pxref{Writing package vignettes}) in the package.
      To do so it installs the current package/bundle into a temporary
      library tree, but any dependent packages need to be installed in
      an available library tree (see the Note: below).

Thus there is already a mechanism to avoid (automatic) rebuilding of
vignettes.  But it seems to be a "all-or-nothing" solution and I could
imagine that some packages might have "real" vignettes that the
maintainer would like to have rebuild automatically and "dummy"
vignettes that should not be rebuild.  So a fine-grained control,
along the way that you suggest, would be a nice way.

>>>>> "HT" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk> writes:

    HT> I like pdfpages and do use it from time to time [...]  so such
    HT> constructions would break on sites which hasn't upgraded their
    HT> LaTeX installation in the last 3 years.
The "Writing R Extensions" manual states on page 15:

      @code{R CMD build} will automatically create PDF versions of the
      vignettes for distribution with the package sources.  By
      including the PDF version in the package sources it is not
      necessary that the vignettes can be compiled at install time,
      i.e., the package author can use private @LaTeX{} extensions
      which are only available on his machine.  Only the @R{} code
      inside the vignettes is part of the checking procedure,
      typesetting manuals is not part of the package QC.

Thus, only the (La)TeX installation of the maintainer of a package has
to be on a reasonably up-to-date level to use such a construction.  

Thanks everybody for their input and comments.

Cheers,

        Berwin


From claudio at gnu.org  Sat Feb 25 09:11:26 2006
From: claudio at gnu.org (Claudio Fontana)
Date: Sat, 25 Feb 2006 03:11:26 -0500
Subject: [Rd] R-Project build system: DESTDIR support
Message-ID: <20060225081126.GB14754@fencepost>

Hello,

I am writing you about the GNU R-Project,
as part of by effort to help GNU projects provide a better, more
consistent build system.

Currently, your project does not support the DESTDIR variable in
generated Makefiles (marked as optional in the GNU coding policies, make and
automake manual).

In my opinion, DESTDIR support can be very helpful for the user, the
distribution-specific packagers and third-party programs, because it
offers a consistent and portable way to perform staged installations.

In each case, please contact me at this address <claudio at gnu.org>
to provide your feedback about this issue _in any case_, should you
want to support DESTDIR or not.

I am ready to offer you information, help and support.

Thank you for your help in making GNU projects build systems better.

Claudio Fontana


From berwin at maths.uwa.edu.au  Sat Feb 25 09:34:47 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 25 Feb 2006 16:34:47 +0800
Subject: [Rd] Links to non-vignette documentation
In-Reply-To: <f8e6ff050602240629j2f31d4e7g23dd726472010114@mail.gmail.com>
References: <f8e6ff050602230853l7eb9cfe6n7458e718ce7934b3@mail.gmail.com>
	<Pine.LNX.4.64.0602232010470.17594@gannet.stats.ox.ac.uk>
	<f8e6ff050602231237j12689b32i511425b6948766a1@mail.gmail.com>
	<Pine.LNX.4.64.0602232044190.25797@gannet.stats.ox.ac.uk>
	<f8e6ff050602231323m7a0779bdrb694f85758df6f3d@mail.gmail.com>
	<43FE3453.6020405@stats.uwo.ca>
	<f8e6ff050602231449l187478f1mcb166915b02c4f3e@mail.gmail.com>
	<43FE66A5.3090103@stats.uwo.ca>
	<f8e6ff050602231902i6b999b8m952a58ff459e6914@mail.gmail.com>
	<43FEF2E3.3070609@stats.uwo.ca>
	<f8e6ff050602240629j2f31d4e7g23dd726472010114@mail.gmail.com>
Message-ID: <17408.5799.865648.376306@bossiaea.maths.uwa.edu.au>

G'day all,

>>>>> "HW" == hadley wickham <h.wickham at gmail.com> writes:

    >> There aren't any immediate plans to change help(package=XXX), but I
    >> think in the long run, if package?XXX receives wider support than it has
    >> now, it would make sense to make that change.
    HW> When was this form of package documentation created?
Well, the section in "Writing R extensions" on "Documenting packages"
appeared first in the version for R 2.2.0.  My impression is that this
form of package documentation was created in response to the following
discussion:
        http://tolstoy.newcastle.edu.au/R/devel/05/06/index.html#1141
In particular, look at message :
        http://tolstoy.newcastle.edu.au/R/devel/05/06/1161.html
in that thread.

    HW> How are users supposed to know it exists?
By asking questions (or following the discussions) on r-help and r-devel? ;-))

More seriously, as Duncan pointed out in his reply, this is a
relatively new feature and few packages support it.  But I guess
sooner or later this feature will be advertised more widely, if only
because of it being again and again mentioned in discussions on r-help
and r-devel.

Cheers,

        Berwin


From ripley at stats.ox.ac.uk  Sat Feb 25 11:07:12 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 25 Feb 2006 10:07:12 +0000 (GMT)
Subject: [Rd] Rcpp, best method for linking to
In-Reply-To: <17407.52079.241833.854793@basebud.nulle.part>
References: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>
	<17407.52079.241833.854793@basebud.nulle.part>
Message-ID: <Pine.LNX.4.64.0602250756140.18071@gannet.stats.ox.ac.uk>

On Fri, 24 Feb 2006, Dirk Eddelbuettel wrote:

> On 24 February 2006 at 15:00, Andrew Garbutt wrote:
> | Sorry, that's not quite what I was asking.  I was asking more of a "best
> | practice" kind of question. My own C++ codes compile fine and are
> | accessible to R with some great #define magic.  I was noting that the
> | Rcpp package has some generic classes to handle conversion of SEXP
> | structures to STL and back again. As I far as I can see, using them
> | would require that I compile the C++ code into a library and link to
> | that library. Or copy the code into my own code base, but doing would
> | restrict myself to the GPL, as it would be a derivative work?? (IANAL)
> | At this point I do not want to commit to any particular licensure for my
> | package.
>
> I may be misunderstanding you but here it goes: if you are using Rcpp as a
> means to get to R, you still end up linking with R itself.  It is my
> understanding that this implies the GPL -- or a suitable GPL-compatible
> license -- for your code.

As you know, what constitutes 'linking' and 'using' is controversial (and 
legal experts do not agree except perhaps that it would need to be tested 
in court and the interpretation may differ by country).  See e.g.

http://www.gnu.org/licenses/gpl-faq.html#MereAggregation

for one (extremal) viewpoint which might appear to disqualify the 
distribution of any non-GPL R package.

But there are statements in the R codebase which could be taken to be more 
liberal (and in the UK would be considered to have a legal bearing).

R's COPYRIGHTS file says (in connection of declaring certain header files 
to be under LGPL).

     It came to our attention that some projects are interpreting GPL to
     mean that compiling against the header files or linking against a
     Windows import library brings the compiled code under the scope of
     GPL.  This would mean it would be impossible to distribute binary
     versions of non-GPL packages with compiled code which called entry
     points in the R executable or DLL, of which there are many on CRAN.

     We encourage packages to be distributed under Open Source conditions,
     but accept that this is not possible for some contributions.  Our
     intention is that export files and import libraries be `accessors'
     under clause 5 of the LGPL, so that in most cases no (additional)
     restrictions are imposed by compiling a package using the LGPL-ed
     components of R.

> I do not see any _additional restriction_ coming in via the addition of
> Rcpp. You already use GPL'ed object files / libraries via R itself. Plus
> you're presumably building with R toolchain via 'R CMD INSTALL ....'

Building with a GPLed compiler does not impose license conditions on the 
executable, and similarly with the R toolchain on built packages, as far 
as I am aware.

We do not currently have a mechanism for one R package to make use of the 
compiled code of another.  When we do, the licence condition on the 
exporting package becomes relevant.  That is already relevant for 
rproxy.dll, where the author chose to use LGPL.  So I think there are 
grounds for suggesting the Rcpp might be more usable under LGPL in some 
circumstances.

[All I am trying to do here is to point out that there are multiple 
viewpoints.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Sat Feb 25 20:43:20 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 25 Feb 2006 13:43:20 -0600
Subject: [Rd] R-Project build system: DESTDIR support
In-Reply-To: <20060225081126.GB14754@fencepost>
References: <20060225081126.GB14754@fencepost>
Message-ID: <17408.45912.247893.86191@basebud.nulle.part>


Hi Claudio,

On 25 February 2006 at 03:11, Claudio Fontana wrote:
| Hello,
| 
| I am writing you about the GNU R-Project,
| as part of by effort to help GNU projects provide a better, more
| consistent build system.
| 
| Currently, your project does not support the DESTDIR variable in
| generated Makefiles (marked as optional in the GNU coding policies, make and
| automake manual).
| 
| In my opinion, DESTDIR support can be very helpful for the user, the
| distribution-specific packagers and third-party programs, because it
| offers a consistent and portable way to perform staged installations.

I'm confused. We've been maintaining R in Debian quite merrily even with the
exisiting standards. To the best of my knowledge things seem to work without
DESTDIR. 

In a nutshell, what we do -- and this is, or at least used to be, pretty
canonical across GNU-style packages and has been in effect for probably a
dozen years.  Now, I may miss something newer happening elsewhere...

The key is that configure details the _final_ location on the installed
system, whereas 'make install' pivots off to a subdirectory in the archive of
the currently built package is 'installed' before being tarred:

	./configure --prefix=/usr			\
		    --with-system-bzlib			\
[...]
		    --build $(buildarch)

[...]

	$(MAKE)		CFLAGS="$(compilerflags)"		\
			CXXFLAGS="$(compilerflags)"		\
			FFLAGS="$(compilerflags)"		\
			CC=${compiler}				\
			CXX=${cxxcompiler}			\
			${fortrancompiler}			\
			R

[...]

	$(MAKE) prefix=$(debtmp)/usr				\
		mandir=$(debtmp)/usr/share/man			\
		rsharedir=$(debtmp)/usr/share/R/share		\
		rincludedir=$(debtmp)/usr/share/R/include	\
		rdocdir=$(debtmp)/usr/share/R/doc		\
		install

So could you detail how using DESTDIR makes this (or, for that matter,
another) use case any easier or better?
 
| In each case, please contact me at this address <claudio at gnu.org>
| to provide your feedback about this issue _in any case_, should you
| want to support DESTDIR or not.
|
| I am ready to offer you information, help and support.

You may want to talk to Kurt Hornik who covers the autoconf et al build
process for R.  Whenever I had little gripes or needs, he reflected these
and typically with much better solutions than I could have proposed :)
 
| Thank you for your help in making GNU projects build systems better.

Thanks for this initiative. It could indeed makes things better

Cheers, Dirk


-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From dsamperi at DecisionSynergy.com  Sat Feb 25 20:50:37 2006
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Sat, 25 Feb 2006 14:50:37 -0500
Subject: [Rd] Rcpp -> RcppTemplate package with L-GPL
In-Reply-To: <Pine.LNX.4.64.0602250756140.18071@gannet.stats.ox.ac.uk>
References: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>
	<17407.52079.241833.854793@basebud.nulle.part>
	<Pine.LNX.4.64.0602250756140.18071@gannet.stats.ox.ac.uk>
Message-ID: <4400B50D.8010806@DecisionSynergy.com>

The R package previously named Rcpp has been renamed to
RcppTemplate (version 1.4), and it is on its way to CRAN.

This is clearer because now RcppTemplate is an R package,
RcppExample is a sample R function, and Rcpp is a C++
class library.

The new package contains the Rcpp class library released
under L-GPL instead of the more restrictive GPL, and it has
been reorganized so that it can be used like a template for
creating R packages that use C++ libraries.

In particular, the Rcpp source files have been moved from src to
inst/lib, and the static library libRcpp.a is built as part of the package
install process. It is linked against when building the package
shared library and then deleted.

See the latest RcppAPI.pdf file for more information. To view it
use vignette("RcppAPI"), or simply fetch the PDF file from
RHOME/lib/RcppTemplate/doc/RcppAPI.pdf.

Be sure to remove the old package named Rcpp if present, because
otherwise there will be two vignettes named RcppAPI, and this
confuses vignette() (chokes under Windows).

Dominick


From edd at debian.org  Sat Feb 25 21:05:29 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 25 Feb 2006 14:05:29 -0600
Subject: [Rd] Rcpp, best method for linking to
In-Reply-To: <Pine.LNX.4.64.0602250756140.18071@gannet.stats.ox.ac.uk>
References: <BFBA7186C5B3CB4C8EA0B509FA9090B3035B1CBF@exchange.systemsbiology.net>
	<17407.52079.241833.854793@basebud.nulle.part>
	<Pine.LNX.4.64.0602250756140.18071@gannet.stats.ox.ac.uk>
Message-ID: <17408.47241.996603.803343@basebud.nulle.part>


Brian,

On 25 February 2006 at 10:07, Prof Brian Ripley wrote:
| > I may be misunderstanding you but here it goes: if you are using Rcpp as a
| > means to get to R, you still end up linking with R itself.  It is my
| > understanding that this implies the GPL -- or a suitable GPL-compatible
| > license -- for your code.
| 
| As you know, what constitutes 'linking' and 'using' is controversial (and 
| legal experts do not agree except perhaps that it would need to be tested 
| in court and the interpretation may differ by country).  See e.g.
[...]
| [All I am trying to do here is to point out that there are multiple 
| viewpoints.]

I appreciate the follow-up and clarification because it is indeed difficult
and not fully mapped territory.  But now that Dominick has released the RCpp
/ RCppTemplate code under LGPL, things should be easier for Andrew.

It will be interesting to see what happens with GPLv3. As I understand, the
murkiness with respect to linking, and things like webservice interface is
said to be one of several drivers behind the license update.  

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From sick_soul at yahoo.it  Mon Feb 27 02:11:37 2006
From: sick_soul at yahoo.it (Claudio Fontana)
Date: Sun, 26 Feb 2006 17:11:37 -0800 (PST)
Subject: [Rd] R-Project build system: DESTDIR support
In-Reply-To: <17408.45912.247893.86191@basebud.nulle.part>
Message-ID: <20060227011137.66822.qmail@web26012.mail.ukl.yahoo.com>


Hello Dirk,
thanks for your answer.

--- Dirk Eddelbuettel <edd at debian.org> wrote:

> 
> Hi Claudio,
> 
> On 25 February 2006 at 03:11, Claudio Fontana wrote:
> | Hello,
> | 
> | I am writing you about the GNU R-Project,
> | as part of by effort to help GNU projects provide
> a better, more
> | consistent build system.
> | 
> | Currently, your project does not support the
> DESTDIR variable in
> | generated Makefiles (marked as optional in the GNU
> coding policies, make and
> | automake manual).
> | 
> | In my opinion, DESTDIR support can be very helpful
> for the user, the
> | distribution-specific packagers and third-party
> programs, because it
> | offers a consistent and portable way to perform
> staged installations.
> 
> I'm confused. We've been maintaining R in Debian
> quite merrily even with the
> exisiting standards. To the best of my knowledge
> things seem to work without
> DESTDIR. 

No need to be confused. DESTDIR is not required to be
able to maintain your project in Debian or in other
GNU/Linux distributions or other Unix-likes.

> In a nutshell, what we do -- and this is, or at
> least used to be, pretty
> canonical across GNU-style packages and has been in
> effect for probably a
> dozen years.  Now, I may miss something newer
> happening elsewhere...

AFAIK widespread DESTDIR use has begun with the
support in Automake, about 6-7 years ago.
DESTDIR dates back to the older INSTALL_ROOT, which is
still in use in the tcl community. 

> The key is that configure details the _final_
> location on the installed
> system, whereas 'make install' pivots off to a
> subdirectory in the archive of
> the currently built package is 'installed' before
> being tarred [cut]
>
> So could you detail how using DESTDIR makes this
> (or, for that matter,
> another) use case any easier or better?

(
 I got your example screwed up by this mail service 
 and was difficult to read - care to send a possibly 
 more verbose version as attachment?
)

What you describe is conceptually very similar to
DESTDIR, if I understand you correctly.

A difference is that DESTDIR is written in the
Makefile.in, for each installation or uninstallation
rule, without altering the primaries. [...]

It only applies to the install/uninstall phase, so
hard-coded paths, and other location-dependant stuff
determined at build time remains valid for the final
destination.

DESTDIR is widely known and portable, and users and
programs can rely on it for running commands on the
to-be-installed files for different goals.

simple usage:
./configure --prefix=/my/final/prefix
make
make install DESTDIR=/staged/directory

simple rule example:
$(INSTALL_DATA) $(srcdir)/file.dat
$(pkgdatadir)/file.dat

becomes

$(INSTALL_DATA) $(srcdir)/file.dat
$(DESTDIR)$(pkgdatadir)/file.dat

Automake generates DESTDIR support automatically (with
some caution required in custom installation hooks).

Probably many sources can provide you more information
about DESTDIR that I can. 

More info is available in the GNU coding standards
(Makefile conventions), GNU make and GNU automake
manuals, and it is probably topical in the autotools
lists too. Google gives me some good hits for DESTDIR
too.

> | In each case, please contact me at this address
> <claudio at gnu.org>
> | to provide your feedback about this issue _in any
> case_, should you
> | want to support DESTDIR or not.
> |
> | I am ready to offer you information, help and
> support.
> 
> You may want to talk to Kurt Hornik who covers the
> autoconf et al build
> process for R.  Whenever I had little gripes or
> needs, he reflected these
> and typically with much better solutions than I
> could have proposed :)

Great, maybe you can forward our conversation?
  
> | Thank you for your help in making GNU projects
> build systems better.
> 
> Thanks for this initiative. It could indeed makes
> things better

I hope so, as I am putting a lot of effort in this.

> Cheers, Dirk

Best,

CLaudio


From hin-tak.leung at cimr.cam.ac.uk  Mon Feb 27 12:06:16 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 27 Feb 2006 11:06:16 +0000
Subject: [Rd] R-Project build system: DESTDIR support
In-Reply-To: <17408.45912.247893.86191@basebud.nulle.part>
References: <20060225081126.GB14754@fencepost>
	<17408.45912.247893.86191@basebud.nulle.part>
Message-ID: <4402DD28.3030305@cimr.cam.ac.uk>

Dirk Eddelbuettel wrote:
> Hi Claudio,
> 
> On 25 February 2006 at 03:11, Claudio Fontana wrote:
<snipped>
> | Currently, your project does not support the DESTDIR variable in
> | generated Makefiles (marked as optional in the GNU coding policies, make and
> | automake manual).
<snipped>
> I'm confused. We've been maintaining R in Debian quite merrily even with the
> exisiting standards. To the best of my knowledge things seem to work without
> DESTDIR. 
<snipped>

You are both right - R currently does not use DESDIR, and also R seems 
to work without it. What happens is that R is *almost* completely 
re-locatable based on one environment variable R_HOME . There is one
wrapper script (/usr/bin/R) which contains the location of R_HOME,
and it is "massaged" with the intended R_HOME location just before
"make install". The "make install" process essentially just copy
all the files into the intended R_HOME, edit the wrapper script
with the location of R_HOME and copy it also.

Change to DESTDIR should be quite simple. I think it is mostly one
line change in R/Makeconf.in,
where
        rhome = ${libdir}/R
to
        rhome = ${DESTDIR}/${libdir}/R
and maybe one or two other places, concerning that wrapper script.
(some volunteers?)

HTL


From hin-tak.leung at cimr.cam.ac.uk  Mon Feb 27 13:28:23 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 27 Feb 2006 12:28:23 +0000
Subject: [Rd] method dispatch and in-place modification? - unclass,
 RemoveClass, getDataPart, method dispatch
Message-ID: <4402F067.7030608@cimr.cam.ac.uk>

I have a little problem about method dispatch and "unnessary" copying.
Basically what I would like to do is:

`[.myclass` <- function(x, i,j, extraopt=TRUE/FALSE, drop=TRUE) {
   ...do stuff depending on extraopt...
    value <- Nextmethod("[", x, i,j, drop=TRUE)
   ... do more stuff depending on extraopt...
}

I have two general problems:
(1) NextMethod() really doesn't like having "extraopt" around.
(2) I can do "unclass" or "class<-" (they seems to do exactly the
same thing with R_set_class()), but it makes a new copy of the object.
The object in my case is very large - (about 80MB, and will be 10x
higher if I can get away with it) and the copying itself accounts
for 97% of the total CPU time consumed - which basically makes it
about 30 times slower than it should be.
In fact R_set_class says:

> /* set the class to value, and return the modified object.  This is
>    NOT a primitive assignment operator , because there is no code in R
>    that changes type in place. See the definition of "class<-" in 
>    the methods package for the use of this code. */


I came upon "RemoveClass()" in R/src/main/object.c which says it is 
__unused__ but seems to do what I would like it to do.

So I tried a S4 method dispatch mechanism, but it is 3 times *slower*
than unclass, and it seems to be due to the switch() statement inside
  getDataPart() (in R/src/library/methods/R/RClassUtils.R)
which typically copies the object three times? (I think 
"attributes(value) <- NULL" also copies)

> getDataPart <- 
> function (object)
> {
>     ...
>     switch(dataPart, 
       ...
>  array = {
>             value <- object
>             attributes(value) <- NULL
>             attr(value, "dim") <- attr(object, "dim")
>             attr(value, "dimnames") <- attr(object, "dimnames")
>             object <- value
>         }, 
>     ...
>     object
> }

The basic question is - is there a way of implementing a method which 
has extra arguments compared to generic? The other question concerns
the "there is no code in R that changes type in place" statement -
how can one avoid excessive copying in these two cases? Is it alright to 
invoke the "RemoveClass()" routine to do a unclass_in_place()?
(I did think about doing my own unclass(), but it just seems exactly 
like what RemoveClass() is!).

Hin-Tak Leung


From getpaidprograms at streamyx.com  Mon Feb 27 17:30:06 2006
From: getpaidprograms at streamyx.com (Neil Getpaid program)
Date: Tue, 28 Feb 2006 00:30:06 +0800
Subject: [Rd] Egold earn $ while surfing
Message-ID: <0IVC00HSETV5LMH0@av5.tm.net.my>


Double your money now
http://www.autumnfund.com/?own=neilgomes




e-gold account is required
Visit E-gold.com


From bill at insightful.com  Mon Feb 27 18:57:57 2006
From: bill at insightful.com (Bill Dunlap)
Date: Mon, 27 Feb 2006 09:57:57 -0800 (PST)
Subject: [Rd] PR#6614
In-Reply-To: <x2fymbrn8w.fsf@turmalin.kubism.ku.dk>
References: <20060222184741.5EFB93F705@slim.kubism.ku.dk>
	<971536df0602221113g18fa674doa0deb0febae49bd9@mail.gmail.com>
	<x2fymbrn8w.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.GSO.4.56.0602270937030.14562@octopus>

On Wed, 23 Feb 2006, Peter Dalgaard wrote:

> "Gabor Grothendieck" <ggrothendieck at gmail.com> writes:
>
> > Try this:
> >
> >  subset(iris, select = - Species)
>
> Or, canonically,
>
> nm <- names(iris)
> iris[, nm != "Species" ]
>
> iris[, -match("Species", nm)]
>
> >
> > On 2/22/06, davidhughjones at gmail.com <davidhughjones at gmail.com> wrote:
> > > I agree with the submitter that this needs some kind of solution.
> > > Although data.frame[,-12] works, how do I drop a named column (the
> > > most common use case)? (I found this bug while searching for an
> > > answer.)

That code with match only works if "Species" is actually
a column of iris.  If not, your result depends on whether
you have a data.frame (an error) or a matrix (a column
of NA's).

I found some mail in a 15 year old sent-mail file that suggested
allowing the tag 'except=' on any of the arguments to "[" to
replace/extend the limited negative integer convention.  The idea was
that
    iris[ except=c(10:20), except=c("Petal.Width","Petal.Length")) ]
would return all rows except 10:20 and all columns except
the ones named.
    iris[ except=integer(0), ]
would return all rows of iris, while iris[-integer(0), ] returns
no rows of iris.

This abuses the tag= notation, but the "[" function doesn't
really support the i= and j= tags that some people expect.

This would take care of the problem that subset(data.frame,select=-name)
only lets you omit columns.

The mail had a version of [.data.frame (for Splus 2.1?) that
implemented this, although, if it is to be used it should be
implemented in the most primitive [ code so all methods use it.

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From davidhughjones at gmail.com  Mon Feb 27 19:35:46 2006
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Mon, 27 Feb 2006 18:35:46 +0000
Subject: [Rd] PR#6614
In-Reply-To: <Pine.GSO.4.56.0602270937030.14562@octopus>
References: <20060222184741.5EFB93F705@slim.kubism.ku.dk>
	<971536df0602221113g18fa674doa0deb0febae49bd9@mail.gmail.com>
	<x2fymbrn8w.fsf@turmalin.kubism.ku.dk>
	<Pine.GSO.4.56.0602270937030.14562@octopus>
Message-ID: <f5d848060602271035y2c511414x@mail.gmail.com>

One thing I notice is that after using subset() on a data frame
imported from SPSS, my variable.names attribute disappeared. I guess
what I would expect is for a subset() method always to preserve
everything but the omitted column.

Cheers
David

On 27/02/06, Bill Dunlap <bill at insightful.com> wrote:
> On Wed, 23 Feb 2006, Peter Dalgaard wrote:
>
> > "Gabor Grothendieck" <ggrothendieck at gmail.com> writes:
> >
> > > Try this:
> > >
> > >  subset(iris, select = - Species)
> >
> > Or, canonically,
> >
> > nm <- names(iris)
> > iris[, nm != "Species" ]
> >
> > iris[, -match("Species", nm)]
> >
> > >
> > > On 2/22/06, davidhughjones at gmail.com <davidhughjones at gmail.com> wrote:
> > > > I agree with the submitter that this needs some kind of solution.
> > > > Although data.frame[,-12] works, how do I drop a named column (the
> > > > most common use case)? (I found this bug while searching for an
> > > > answer.)
>
> That code with match only works if "Species" is actually
> a column of iris.  If not, your result depends on whether
> you have a data.frame (an error) or a matrix (a column
> of NA's).
>
> I found some mail in a 15 year old sent-mail file that suggested
> allowing the tag 'except=' on any of the arguments to "[" to
> replace/extend the limited negative integer convention.  The idea was
> that
>     iris[ except=c(10:20), except=c("Petal.Width","Petal.Length")) ]
> would return all rows except 10:20 and all columns except
> the ones named.
>     iris[ except=integer(0), ]
> would return all rows of iris, while iris[-integer(0), ] returns
> no rows of iris.
>
> This abuses the tag= notation, but the "[" function doesn't
> really support the i= and j= tags that some people expect.
>
> This would take care of the problem that subset(data.frame,select=-name)
> only lets you omit columns.
>
> The mail had a version of [.data.frame (for Splus 2.1?) that
> implemented this, although, if it is to be used it should be
> implemented in the most primitive [ code so all methods use it.
>
> ----------------------------------------------------------------------------
> Bill Dunlap
> Insightful Corporation
> bill at insightful dot com
> 360-428-8146
>
>  "All statements in this message represent the opinions of the author and do
>  not necessarily reflect Insightful Corporation policy or position."
>


From mmorales at williams.edu  Mon Feb 27 21:15:38 2006
From: mmorales at williams.edu (mmorales@williams.edu)
Date: Mon, 27 Feb 2006 21:15:38 +0100 (CET)
Subject: [Rd] readline and/or lme crashes R (PR#8646)
Message-ID: <20060227201538.560592A361@slim.kubism.ku.dk>

Full_Name: Manuel Morales
Version: 2.2.1
OS: Linux (Fedora Core 4)
Submission from: (NULL) (137.165.200.32)


I've noticed that using readline after an lme analysis results in a crash.

E.g.
library(nlme)
fm1 <- lme(distance ~ age, data = Orthodont)
Crashes after typing the "up arrow", sometimes with the error message:

/usr/local/lib/R/bin/exec/R: symbol lookup error: /usr/lib/libreadline.so.5:
undefined symbol: tputs

Details:
nlme 3.1-68.1
readline-5.0-3

> R.version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R

I tried to get a backtrace using gd, but bt gave the output, "no stack"

Manuel


From p.dalgaard at biostat.ku.dk  Mon Feb 27 21:55:53 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Feb 2006 21:55:53 +0100
Subject: [Rd] PR#6614
In-Reply-To: <Pine.GSO.4.56.0602270937030.14562@octopus>
References: <20060222184741.5EFB93F705@slim.kubism.ku.dk>
	<971536df0602221113g18fa674doa0deb0febae49bd9@mail.gmail.com>
	<x2fymbrn8w.fsf@turmalin.kubism.ku.dk>
	<Pine.GSO.4.56.0602270937030.14562@octopus>
Message-ID: <x2ek1osequ.fsf@turmalin.kubism.ku.dk>

Bill Dunlap <bill at insightful.com> writes:

> On Wed, 23 Feb 2006, Peter Dalgaard wrote:
> 
> > "Gabor Grothendieck" <ggrothendieck at gmail.com> writes:
> >
> > > Try this:
> > >
> > >  subset(iris, select = - Species)
> >
> > Or, canonically,
> >
> > nm <- names(iris)
> > iris[, nm != "Species" ]
> >
> > iris[, -match("Species", nm)]
> >
> > >
> > > On 2/22/06, davidhughjones at gmail.com <davidhughjones at gmail.com> wrote:
> > > > I agree with the submitter that this needs some kind of solution.
> > > > Although data.frame[,-12] works, how do I drop a named column (the
> > > > most common use case)? (I found this bug while searching for an
> > > > answer.)
> 
> That code with match only works if "Species" is actually
> a column of iris.  If not, your result depends on whether
> you have a data.frame (an error) or a matrix (a column
> of NA's).
> 
> I found some mail in a 15 year old sent-mail file that suggested
> allowing the tag 'except=' on any of the arguments to "[" to
> replace/extend the limited negative integer convention.  The idea was
> that
>     iris[ except=c(10:20), except=c("Petal.Width","Petal.Length")) ]
> would return all rows except 10:20 and all columns except
> the ones named.
>     iris[ except=integer(0), ]
> would return all rows of iris, while iris[-integer(0), ] returns
> no rows of iris.
> 
> This abuses the tag= notation, but the "[" function doesn't
> really support the i= and j= tags that some people expect.
> 
> This would take care of the problem that subset(data.frame,select=-name)
> only lets you omit columns.
> 
> The mail had a version of [.data.frame (for Splus 2.1?) that
> implemented this, although, if it is to be used it should be
> implemented in the most primitive [ code so all methods use it.

>From the language viewpoint, I think that using the same tag multiple
times and mixing up tagged and positional argument matching would be
quite nasty. I actually suspect that the argument matching rules will
make it impossible in R (except possibly from C and .Primitive). 

However, it could be possible to have an omit() function, as in

iris[ omit(c(10:20)), omit(c("Petal.Width","Petal.Length")) ]  

all this needs to do is to tack an attribute onto the index which the
indexing code can look for. 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From leif at reflectivity.com  Mon Feb 27 22:41:14 2006
From: leif at reflectivity.com (Leif Kirschenbaum)
Date: Mon, 27 Feb 2006 13:41:14 -0800
Subject: [Rd] Request for showWarnings parameter for write.table
Message-ID: <200602272141.k1RLfJ6r027586@hypatia.math.ethz.ch>

Madams & Sirs,
  I use write.table to write CSV files to generate reports for my colleagues to open in their spreadsheet application of choice.  I often append data of dissimilar structure to the same file, i.e. a few summary lines and then additional data of some number of columns.

Normally write.table produces:
> write.table(etest[,writevars],file=fname,row.names=FALSE,col.names=TRUE,
	append=TRUE,sep=",")
Warning message:
appending column names to file in: write.table(etest[, writevars], file = fname, row.names = FALSE,  


Therefore I resort to:

> options(warn=-1)
> write.table(etest[,writevars],file=fname,row.names=FALSE,col.names=TRUE,append=TRUE,sep=",")
> options(warn=0)


However I thought that perhaps a parameter such as included for dir.create would be more elegant:
> write.table(etest[,writevars],file=fname,row.names=FALSE,col.names=TRUE,
	append=TRUE,sep=",",showWarnings=FALSE)


where showWarnings would default to TRUE.

Please cc: replies to leif at reflectivity.com

Thank you.


Leif Kirschenbaum
Senior Yield Engineer
Reflectivity, Inc.
(408) 737-8100 x307
leif at reflectivity.com


From ggrothendieck at gmail.com  Mon Feb 27 22:46:12 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 27 Feb 2006 16:46:12 -0500
Subject: [Rd] Request for showWarnings parameter for write.table
In-Reply-To: <200602272141.k1RLfJ6r027586@hypatia.math.ethz.ch>
References: <200602272141.k1RLfJ6r027586@hypatia.math.ethz.ch>
Message-ID: <971536df0602271346v2ecd07e3ie6efe378145bd689@mail.gmail.com>

You might also check out suppressWarnings, e.g.

suppressWarnings(write.table(...whatevever...))



On 2/27/06, Leif Kirschenbaum <leif at reflectivity.com> wrote:
> Madams & Sirs,
>  I use write.table to write CSV files to generate reports for my colleagues to open in their spreadsheet application of choice.  I often append data of dissimilar structure to the same file, i.e. a few summary lines and then additional data of some number of columns.
>
> Normally write.table produces:
> > write.table(etest[,writevars],file=fname,row.names=FALSE,col.names=TRUE,
>        append=TRUE,sep=",")
> Warning message:
> appending column names to file in: write.table(etest[, writevars], file = fname, row.names = FALSE,
>
>
> Therefore I resort to:
>
> > options(warn=-1)
> > write.table(etest[,writevars],file=fname,row.names=FALSE,col.names=TRUE,append=TRUE,sep=",")
> > options(warn=0)
>
>
> However I thought that perhaps a parameter such as included for dir.create would be more elegant:
> > write.table(etest[,writevars],file=fname,row.names=FALSE,col.names=TRUE,
>        append=TRUE,sep=",",showWarnings=FALSE)
>
>
> where showWarnings would default to TRUE.
>
> Please cc: replies to leif at reflectivity.com
>
> Thank you.
>
>
> Leif Kirschenbaum
> Senior Yield Engineer
> Reflectivity, Inc.
> (408) 737-8100 x307
> leif at reflectivity.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jcygnaro at gmail.com  Tue Feb 28 01:27:22 2006
From: jcygnaro at gmail.com (j. signorovitch)
Date: Mon, 27 Feb 2006 19:27:22 -0500
Subject: [Rd] trouble with R CMD SHLIB on winXP
Message-ID: <7dc006e80602271627x3e54c772w2cf31979d375869d@mail.gmail.com>

Hi,

Has anyone come across this difficulty using R-2.2.1 in Windows XP:

when I try to run

R CMD SHLIB mycode.c

I get the response:

"The system cannot execute the specified program."

I've tried installing all windows updates, reinstalling R and putting
"R-2.2.1\bin" at the head of my path.

Googling that error message leads to lots of stuff about *.manifest
files.  The Rgui.exe.manifest etc. files are in my /bin directory.

Funny thing is I have been using SHLIB for ~2 years on this system, up
to several month ago, without difficulty.

Any suggestions would be greatly appreciated!

Thanks,

Jacob


From weigand.stephen at gmail.com  Tue Feb 28 05:25:29 2006
From: weigand.stephen at gmail.com (Stephen D. Weigand)
Date: Mon, 27 Feb 2006 22:25:29 -0600
Subject: [Rd] Typos in writeLines.Rd, readLines.Rd, and data.matrix.Rd
Message-ID: <67ff476e32330f987dca67e6b0252503@gmail.com>

Hello,

The diffs below are based on revision 37445 and show
some typo corrections for writeLines.Rd, readLines.Rd,
and data.matrix.Rd that I'd like to bring to the list's
attention.

Sincerely,

Stephen Weigand
Rochester, Minnesota, USA



--- ./src/library/base/man/writeLines.Rd        Sun Feb 26 13:46:06 2006
+++ /tmp/writeLines.Rd  Sun Feb 26 20:53:44 2006
@@ -14,8 +14,8 @@
      each line of text.}
  }
  \details{
-  If the \code{con} is a character string, the functions call
-  \code{\link{file}} to obtain an file connection which is opened for
+  If the \code{con} is a character string, the function calls
+  \code{\link{file}} to obtain a file connection which is opened for
    the duration of the function call.

    If the connection is open it is written from its current position.


--- ./src/library/base/man/readLines.Rd Sun Feb 26 13:46:28 2006
+++ /tmp/readLines.Rd   Sun Feb 26 21:08:30 2006
@@ -16,8 +16,8 @@
      \code{n > 0} lines are read? If not, an error will be generated.}
  }
  \details{
-  If the \code{con} is a character string, the functions call
-  \code{\link{file}} to obtain an file connection which is opened for
+  If the \code{con} is a character string, the function calls
+  \code{\link{file}} to obtain a file connection which is opened for
    the duration of the function call.

    If the connection is open it is read from its current position.


--- ./src/library/base/man/data.matrix.Rd       Sun Feb 26 13:46:15 2006
+++ /tmp/data.matrix.Rd Sun Feb 26 21:14:33 2006
@@ -15,7 +15,7 @@
      factors or numeric vectors.}
  }
  \details{
-  Suppling a data frame with columns which are not numeric, factor or 
logical
+  Supplying a data frame with columns which are not numeric, factor or 
logical
    is an error.  A warning is given if any non-factor column has a 
class,
    as then information can be lost.
  }


From ripley at stats.ox.ac.uk  Tue Feb 28 07:15:30 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 06:15:30 +0000 (GMT)
Subject: [Rd] Typos in writeLines.Rd, readLines.Rd, and data.matrix.Rd
In-Reply-To: <67ff476e32330f987dca67e6b0252503@gmail.com>
References: <67ff476e32330f987dca67e6b0252503@gmail.com>
Message-ID: <Pine.LNX.4.64.0602280612510.22632@gannet.stats.ox.ac.uk>

Fixed now, thanks.

BTW, supplying patches inline almost always does not work as lines get 
wrapped, tabs converted ....  A text attachment should be better.

On Mon, 27 Feb 2006, Stephen D. Weigand wrote:

> Hello,
>
> The diffs below are based on revision 37445 and show
> some typo corrections for writeLines.Rd, readLines.Rd,
> and data.matrix.Rd that I'd like to bring to the list's
> attention.
>
> Sincerely,
>
> Stephen Weigand
> Rochester, Minnesota, USA
>
>
>
> --- ./src/library/base/man/writeLines.Rd        Sun Feb 26 13:46:06 2006
> +++ /tmp/writeLines.Rd  Sun Feb 26 20:53:44 2006
> @@ -14,8 +14,8 @@
>      each line of text.}
>  }
>  \details{
> -  If the \code{con} is a character string, the functions call
> -  \code{\link{file}} to obtain an file connection which is opened for
> +  If the \code{con} is a character string, the function calls
> +  \code{\link{file}} to obtain a file connection which is opened for
>    the duration of the function call.
>
>    If the connection is open it is written from its current position.
>
>
> --- ./src/library/base/man/readLines.Rd Sun Feb 26 13:46:28 2006
> +++ /tmp/readLines.Rd   Sun Feb 26 21:08:30 2006
> @@ -16,8 +16,8 @@
>      \code{n > 0} lines are read? If not, an error will be generated.}
>  }
>  \details{
> -  If the \code{con} is a character string, the functions call
> -  \code{\link{file}} to obtain an file connection which is opened for
> +  If the \code{con} is a character string, the function calls
> +  \code{\link{file}} to obtain a file connection which is opened for
>    the duration of the function call.
>
>    If the connection is open it is read from its current position.
>
>
> --- ./src/library/base/man/data.matrix.Rd       Sun Feb 26 13:46:15 2006
> +++ /tmp/data.matrix.Rd Sun Feb 26 21:14:33 2006
> @@ -15,7 +15,7 @@
>      factors or numeric vectors.}
>  }
>  \details{
> -  Suppling a data frame with columns which are not numeric, factor or
> logical
> +  Supplying a data frame with columns which are not numeric, factor or
> logical
>    is an error.  A warning is given if any non-factor column has a
> class,
>    as then information can be lost.
>  }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Feb 28 07:26:48 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 06:26:48 +0000 (GMT)
Subject: [Rd] trouble with R CMD SHLIB on winXP
In-Reply-To: <7dc006e80602271627x3e54c772w2cf31979d375869d@mail.gmail.com>
References: <7dc006e80602271627x3e54c772w2cf31979d375869d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602280453090.21783@gannet.stats.ox.ac.uk>

We don't know from this what the `specified program' is, but it probably 
means that a DLL cannot be found on your path.

It is probable that your PATH is set up incorrectly, so please check with 
the R-admin manual extremely carefully.  In particular, that you really do 
have a complete unpacked tools.zip at the head of your path and that you 
do not also have Cygwin on your path.

On Mon, 27 Feb 2006, j. signorovitch wrote:

> Hi,
>
> Has anyone come across this difficulty using R-2.2.1 in Windows XP:
>
> when I try to run
>
> R CMD SHLIB mycode.c
>
> I get the response:
>
> "The system cannot execute the specified program."
>
> I've tried installing all windows updates, reinstalling R and putting
> "R-2.2.1\bin" at the head of my path.
>
> Googling that error message leads to lots of stuff about *.manifest
> files.  The Rgui.exe.manifest etc. files are in my /bin directory.

Really?  *.manifest files need to be in the same directory as the 
executables they refer to, that's all.  I think you have found hits
related to Visual .NET, which is not in use.

> Funny thing is I have been using SHLIB for ~2 years on this system, up
> to several month ago, without difficulty.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bibiko at eva.mpg.de  Tue Feb 28 10:19:01 2006
From: bibiko at eva.mpg.de (bibiko@eva.mpg.de)
Date: Tue, 28 Feb 2006 10:19:01 +0100 (CET)
Subject: [Rd] Workspace Browser - No Refresh of Deleted Objects (PR#8647)
Message-ID: <20060228091901.94D422A360@slim.kubism.ku.dk>

Full_Name: Hans-Joerg Bibiko
Version: 2.2.0
OS: Mac OSX 10.4.5
Submission from: (NULL) (194.94.96.198)


Bug Reproduction:

- open R
- go to Workspace Browser -> it is empty

enter:
>a<-100
>b<-200

- go to Workspace Browser -> you see a and b

enter:
>rm(a)
>rm(b)

- go to Workspace Browser
!! BUG you still see a and b although these objects are deleted physically!!
Refresh-Button doesn't help.

enter:
>c<-300

- go to Workspace Browser, press Refresh -> you see only the new object c!!

> sessionInfo()
R version 2.2.0, 2005-10-06, powerpc-apple-darwin7.9.0 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
"base"


From hin-tak.leung at cimr.cam.ac.uk  Tue Feb 28 11:09:24 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 28 Feb 2006 10:09:24 +0000
Subject: [Rd] R-Project build system: DESTDIR support
In-Reply-To: <20060227222842.57696.qmail@web26006.mail.ukl.yahoo.com>
References: <20060227222842.57696.qmail@web26006.mail.ukl.yahoo.com>
Message-ID: <44042154.2070504@cimr.cam.ac.uk>

Claudio Fontana wrote:
> Hello,
> 
> --- Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
<snipped>
>>Change to DESTDIR should be quite simple. I think it
>>is mostly one
>>line change in R/Makeconf.in,
>>where
>>        rhome = ${libdir}/R
>>to
>>        rhome = ${DESTDIR}/${libdir}/R
>>and maybe one or two other places, concerning that
>>wrapper script.
> 
> 
> Please DON'T. If I understood your idea correctly,
> this is not the meaning of DESTDIR,
> and placing DESTDIR there is harmful since its meaning
> is overloaded. The staged installation does _not_ need
> to be functional. Its hard coded paths must refer to
> the _final destination_ which is determined by prefix
> only.
<snipped>
> Then try this (replace user with your user name):
> 
> $ tar -zxvf bc-1.06.tar.gz
> $ cd bc-1.06
> $ ./configure --prefix=/home/user/tmp
> $ make
> $ make install DESTDIR=/home/user/install-destdir
> $ ls /home/user/tmp
> ls: /home/user/tmp: No such file or directory
> $ find /home/user/install-destdir
> [study the output of this command]

I don't think you understand me correctly.
Doing the insertion as I wrote, (Makeconf.in is
included by R's top-level Makefile as far as I understand it),
would make "make install DESTDIR=/someotherroot/" work.
You probably mean this construction:

DESTDIR ?=${libdir}/R
rhome = ${DESTDIR}

instead. Either way, please study what Makeconf.in does.

HTL


From sick_soul at yahoo.it  Tue Feb 28 12:09:34 2006
From: sick_soul at yahoo.it (Claudio Fontana)
Date: Tue, 28 Feb 2006 03:09:34 -0800 (PST)
Subject: [Rd] R-Project build system: DESTDIR support
In-Reply-To: <44042154.2070504@cimr.cam.ac.uk>
Message-ID: <20060228110934.17216.qmail@web26015.mail.ukl.yahoo.com>


--- Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
wrote:

> Claudio Fontana wrote:
> > Hello,
> > 
> > --- Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
> <snipped>
> >>Change to DESTDIR should be quite simple. I think
> it
> >>is mostly one
> >>line change in R/Makeconf.in,
> >>where
> >>        rhome = ${libdir}/R
> >>to
> >>        rhome = ${DESTDIR}/${libdir}/R
> >>and maybe one or two other places, concerning that
> >>wrapper script.
> > 
> > 
> > Please DON'T. If I understood your idea correctly,
> > this is not the meaning of DESTDIR,
> > and placing DESTDIR there is harmful since its
> meaning
> > is overloaded. The staged installation does _not_
> need
> > to be functional. Its hard coded paths must refer
> to
> > the _final destination_ which is determined by
> prefix
> > only.
> <snipped>
> > Then try this (replace user with your user name):
> > 
> > $ tar -zxvf bc-1.06.tar.gz
> > $ cd bc-1.06
> > $ ./configure --prefix=/home/user/tmp
> > $ make
> > $ make install DESTDIR=/home/user/install-destdir
> > $ ls /home/user/tmp
> > ls: /home/user/tmp: No such file or directory
> > $ find /home/user/install-destdir
> > [study the output of this command]
> 
> I don't think you understand me correctly.

I am now pretty sure I did.

> Doing the insertion as I wrote, (Makeconf.in is
> included by R's top-level Makefile as far as I
> understand it),
> would make "make install DESTDIR=/someotherroot/"
> work.

It works, but not in the way its intended.

> Either way, please study what Makeconf.in
> does.
> 
> HTL

I did, and does not seem ok.
Look:

- make the change in Makeconf.in:
  rhome = $(DESTDIR)${libdir}/R

now I do:

$ ./configure --prefix=/home/claudio/tmp
$ make
$ make install DESTDIR=/home/claudio/install-destdir

$ find /home/claudio/tmp
/home/claudio/tmp
/home/claudio/tmp/man
/home/claudio/tmp/man/man1
/home/claudio/tmp/man/man1/R.1
/home/claudio/tmp/bin
/home/claudio/tmp/bin/R

[not ok, should return: /home/claudio/tmp: No such
file or directory. ]

Now for the more important thing:

$ cat /home/claudio/tmp/bin/R
#!/bin/sh
# Shell wrapper for R executable.

R_HOME_DIR=/home/claudio/install-destdir/home/claudio/tmp/lib/R
if test -n "${R_HOME}" && \
   test "${R_HOME}" != "${R_HOME_DIR}"; then
  echo "WARNING: ignoring environment value of R_HOME"
fi
R_HOME="${R_HOME_DIR}"
export R_HOME
R_SHARE_DIR=/home/claudio/install-destdir/home/claudio/tmp/lib/R/share
export R_SHARE_DIR
R_INCLUDE_DIR=/home/claudio/install-destdir/home/claudio/tmp/lib/R/include
export R_INCLUDE_DIR
R_DOC_DIR=/home/claudio/install-destdir/home/claudio/tmp/lib/R/doc
export R_DOC_DIR

 [
  not ok: the software itself must be DESTDIR unaware.
  Those paths should read for example:
  R_SHARE_DIR=/home/claudio/tmp/lib/R/share

  The binaries, the datafiles, and the content of
  everything else that gets installed should be 
  indistinguishable from a non-DESTDIR installation.
  Moving the staged installation to the
  final place should be (more or less[...]) a matter
  of one mv command.
 ]

Do you see the difference in meaning between your
concept and the DESTDIR concept?

CLaudio


From agarbutt at systemsbiology.org  Tue Feb 28 20:57:18 2006
From: agarbutt at systemsbiology.org (Andrew Garbutt)
Date: Tue, 28 Feb 2006 11:57:18 -0800
Subject: [Rd] Rcpp -> RcppTemplate package with L-GPL
Message-ID: <BFBA7186C5B3CB4C8EA0B509FA9090B30375BDAB@exchange.systemsbiology.net>

Thank you all for your input and ideas.  It seems this discussion has
clarified the purpose of the Rcpp/RcppTemplate package and further
demonstrated both creating and linking with an external library as well
as utilizing C++ for creating R packages.  Moving the Rcpp code base to
a separate library encourages using its variable parsing in other
packages.  Thank you again.

-Andy


-----Original Message-----
From: Dominick Samperi [mailto:dsamperi at DecisionSynergy.com] 
Sent: Saturday, February 25, 2006 11:51 AM
To: Prof Brian Ripley; Andrew Finley
Cc: Dirk Eddelbuettel; Andrew Garbutt; r-devel at r-project.org
Subject: Rcpp -> RcppTemplate package with L-GPL

The R package previously named Rcpp has been renamed to
RcppTemplate (version 1.4), and it is on its way to CRAN.

This is clearer because now RcppTemplate is an R package,
RcppExample is a sample R function, and Rcpp is a C++
class library.

The new package contains the Rcpp class library released
under L-GPL instead of the more restrictive GPL, and it has
been reorganized so that it can be used like a template for
creating R packages that use C++ libraries.

In particular, the Rcpp source files have been moved from src to
inst/lib, and the static library libRcpp.a is built as part of the
package
install process. It is linked against when building the package
shared library and then deleted.

See the latest RcppAPI.pdf file for more information. To view it
use vignette("RcppAPI"), or simply fetch the PDF file from
RHOME/lib/RcppTemplate/doc/RcppAPI.pdf.

Be sure to remove the old package named Rcpp if present, because
otherwise there will be two vignettes named RcppAPI, and this
confuses vignette() (chokes under Windows).

Dominick


