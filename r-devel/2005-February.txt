From maarranz at tol-project.org  Tue Feb  1 15:17:12 2005
From: maarranz at tol-project.org (Miguel A. Arranz)
Date: Tue Feb  1 14:11:13 2005
Subject: [Rd] Problem with Linux installation
Message-ID: <200502011517.12225.maarranz@tol-project.org>

Dear R-devel members:

I have been trying to install the latest versions of R-devel with no success. 
It builds with no problem, but 'make install' breaks with the error
make[2]: Entering directory `/home/bayes/R/R-devel/src/include'
make[2]: *** No rule to make target `install-no', needed by `install'.  Stop.
m
I guess there is a minor problem with the Makefile, which did not appear on 
the version I am running now (2005-01-26)

Thanks in advance,

Miguel A.

From ripley at stats.ox.ac.uk  Tue Feb  1 14:31:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  1 14:31:19 2005
Subject: [Rd] Re: [R] RData loading weirdness
In-Reply-To: <41FF7114.8040708@lancaster.ac.uk>
References: <41FF7114.8040708@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.61.0502011320030.15311@gannet.stats>

[Moved to R-devel: see the posting guide for the currently made 
distinction.]

The format of .RData has not changed, so this is still of interest.

We have seen things like this, the problem being the way an out-of-memory 
condition got handled by Linux -- how much memory did his machine have?
(Remember 67Mb is compressed, often highly compressed.)

It has certainly been possible to save a workspace that needs much more 
memory to be restored on the same machine than it originally took.

We've found Linux to be rather unhelpful with out-of-memory conditions: 
one of our servers started `randomly' killing processes when its swap 
space got full -- and one of the first was the sshd daemon which cut off 
all remote access ....

On Tue, 1 Feb 2005, Barry Rowlingson wrote:

>
> I've just had an interesting thing happen to one of our students. He's using 
> R 1.9.1 on Linux, and so I dont expect bugfixes, I'm just reporting this out 
> of interest in case anyone else has had this happen.
>
> Starting R caused a seg fault shortly after "[Previously saved workspace 
> restored]". Running "R --no-restore-data" worked fine so I suspected a 
> corrupted .RData. It was 67M big, with about 400 objects - nothing extreme 
> there. But then doing load(".RData") worked fine. There were his objects. How 
> strange.
>
> I deleted the first 200 objects, saved the .RData, and retried. That worked, 
> so I thought it might have been an object in the last 200 or so. So I saved 
> them to .RData. Starting up with that worked.
>
> So, starting afresh with the original load(".RData"), I saved two .RData 
> files with each part. Quit, start again, load("part1.RData") and 
> load("part2.RData"), then quit and save. Now I had all 400-ish objects in one 
> .RData. Time to start R and see if it can startup with it.
>
> And it did. Worked fine. So I suspect a subtle bug in reading .RData files 
> or subtle corruption in the .RData. Most odd. Oh well, I guess I could see 
> what R 2.x.x does with it....
>
> Barry
>
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Feb  1 14:44:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  1 14:44:40 2005
Subject: [Rd] Re: [R] Process to both write to and read from (pipe/fork)?
In-Reply-To: <20050201135305.GA29528@jtkpc.cmp.uea.ac.uk>
References: <20050201135305.GA29528@jtkpc.cmp.uea.ac.uk>
Message-ID: <Pine.LNX.4.61.0502011335290.15311@gannet.stats>

[Moved from R-help.]

One reason you cannot easily do this with basic R functions is that it is 
not portable.  E.g. pipes on Windows 98 do not work like that, and 
system() on that OS has to work hard to do something similar.

If we only had to consider standard Unices, pipe() would allow read-write 
modes.  As it is, it is easy for you to write an OS-specific extension.

BTW, please re-read the distinction between R-devel and R-help in the 
posting guide: this (and most of your other recent postings) seem to me to 
fall unambiguously within the specification for R-devel.


On Tue, 1 Feb 2005, Jan T. Kim wrote:

> Dear all,
>
> I would like to start a process from an R program in such a way that
> I can both feed input into the process and read the process's output.
> It seems that in R, I can have a pipe for writing into another process's
> input or a pipe for reading from another process's output, but not both.
>
> Doing both necessitates forking, such that the child can start the
> external process and feed that with some input, and the parent can
> read the output from the external process. Additionally, this requires
> obtaining a plain pipe, i.e. one with an input handle (for writing to)
> and an output handle (for reading from) prior to forking, so the child
> can connect the external process's stdout to the input handle and the
> parent can read that from the output handle.
>
> My problem is that I cannot find a way in R to set up such a pipe.
>
> For forking, I've found the fork package, but I can't seem to get a
> pipe. I know about the pipe function in the base package, but it seems
> to me that that is an interface to popen(2), rather than to pipe(2)
> (see attached C source). At least, I can't seem to get anything else but
> a popen equivalent from it. I've looked for a pipe package, for pipe in
> the fork package, and googled around, to no avail.
>
> For illustrating what I'd like to do, I attach a C program that
> replicates the pipe example from the base docs, with the difference
> that the input data to be processed with sed are present in the
> program rather than in a file.
>
> I start to feel silly and stupid for being unable to figure out such a
> basic thing. Thanks in advance for any help -- RTFMs very welcome.
>
> Best regards, Jan
> -- 
> +- Jan T. Kim -------------------------------------------------------+
> |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
> |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
> *-----=<  hierarchical systems are for files, not for humans  >=-----*
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Feb  1 14:58:58 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Feb  1 15:02:52 2005
Subject: [Rd] Re: [R] RData loading weirdness
In-Reply-To: <Pine.LNX.4.61.0502011320030.15311@gannet.stats>
References: <41FF7114.8040708@lancaster.ac.uk>
	<Pine.LNX.4.61.0502011320030.15311@gannet.stats>
Message-ID: <x2k6psjs9p.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> We've found Linux to be rather unhelpful with out-of-memory
> conditions: one of our servers started `randomly' killing processes
> when its swap space got full -- and one of the first was the sshd
> daemon which cut off all remote access ....

This is running off-topic, but I believe that this has been recently
worked on, and at least SuSE (I'm not going home just to open the lid
on the laptop running FC3 just now!) now has the behaviour controlled
by kernel flags in /proc/sys/vm/local-oom-kill and
/proc/sys/vm/overcommit_memory. Not sure what the first one means
exactly, though ...


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Tue Feb  1 15:04:03 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  1 15:04:16 2005
Subject: [Rd] Problem with Linux installation
In-Reply-To: <200502011517.12225.maarranz@tol-project.org>
References: <200502011517.12225.maarranz@tol-project.org>
Message-ID: <Pine.LNX.4.61.0502011349170.18895@gannet.stats>

On Tue, 1 Feb 2005, Miguel A. Arranz wrote:

> Dear R-devel members:
>
> I have been trying to install the latest versions of R-devel with no success.

R-devel changes many times a day: see the SVN logs.

> It builds with no problem, but 'make install' breaks with the error
> make[2]: Entering directory `/home/bayes/R/R-devel/src/include'
> make[2]: *** No rule to make target `install-no', needed by `install'.  Stop.
> m
> I guess there is a minor problem with the Makefile, which did not appear on
> the version I am running now (2005-01-26)

Remember R-devel says

Version 2.1.0 Under development (unstable) (2005-02-01), ISBN 3-900051-07-0

and installation of gettext/libintl is actively `under development' at 
present.  I don't know exactly when you got your version, but it works 
right now with GNU make on Linux and Solaris (there seem to be some 
problems with Solaris make that I am in the middle of tracking down).

We do try to have `make all check dist' working at the end of each day 
(GMT) so the snapshot tarball builds, but `make install' is only checked 
at the end of bouts of development (why would anyone want to install an 
unstable version?).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jtk at cmp.uea.ac.uk  Tue Feb  1 20:50:17 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Tue Feb  1 19:52:27 2005
Subject: [Rd] Re: [R] Process to both write to and read from (pipe/fork)?
In-Reply-To: <Pine.LNX.4.61.0502011335290.15311@gannet.stats>
References: <20050201135305.GA29528@jtkpc.cmp.uea.ac.uk>
	<Pine.LNX.4.61.0502011335290.15311@gannet.stats>
Message-ID: <20050201195017.GC30798@jtkpc.cmp.uea.ac.uk>

On Tue, Feb 01, 2005 at 01:44:37PM +0000, Prof Brian Ripley wrote:
> [Moved from R-help.]
> 
> One reason you cannot easily do this with basic R functions is that it is 
> not portable.  E.g. pipes on Windows 98 do not work like that, and 
> system() on that OS has to work hard to do something similar.

Ok, thanks -- I really thought (and hoped) that I was just overlooking
something obvious.

I'm not fully convinced that the portability issues necessarily
preclude providing the fork / pipe facilities, as there already is some
differentiation present now, reflected by capabilities(). In fact,
when I saw that availability of fifos is reflected by capabilities(),
I thought that then, more basic pipes must also be accessible somehow
(and spent some effort investigating this idea).

> If we only had to consider standard Unices, pipe() would allow read-write 
> modes.  As it is, it is easy for you to write an OS-specific extension.

Well, that is probably reasonably easy, but (not the least due to that
fact) I'm still surprised that it has not been done already. I can hardly
imagine that I'm the first one to want to use some external utility from
an R program in this way.

So, what do you R-devel folks do in this case, and what would you
recommend?

> BTW, please re-read the distinction between R-devel and R-help in the 
> posting guide: this (and most of your other recent postings) seem to me to 
> fall unambiguously within the specification for R-devel.

At the time of writing, I thought I was asking for help in using R...

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*

From yuedong at pstat.ucsb.edu  Wed Feb  2 04:31:48 2005
From: yuedong at pstat.ucsb.edu (yuedong@pstat.ucsb.edu)
Date: Wed Feb  2 04:31:52 2005
Subject: [Rd] anova.glm (PR#7624)
Message-ID: <20050202033148.8E96DE078@slim.kubism.ku.dk>

There may be a bug in the anova.glm function.

deathstar[32] R

R : Copyright 2004, The R Foundation for Statistical Computing
Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> counts <- c(18,17,15,20,10,20,25,13,12)
> outcome <- gl(3,1,9)
> treatment <- gl(3,3)
> glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())
> anova(glm.D93,test="Chisq")
Analysis of Deviance Table

Model: poisson, link: log

Response: counts

Terms added sequentially (first to last)


           Df Deviance Resid. Df Resid. Dev P(>|Chi|)
NULL                          8    10.5814
outcome    2   5.4523         6     5.1291    0.0655
treatment  2   0.0000         4     5.1291    1.0000

> anova(glm.D93,test="F")
Analysis of Deviance Table

Model: poisson, link: log

Response: counts

Terms added sequentially (first to last)


           Df Deviance Resid. Df Resid. Dev      F  Pr(>F)
NULL                          8    10.5814
outcome    2   5.4523         6     5.1291 2.7262 0.06547 .
treatment  2   0.0000         4     5.1291 0.0000 1.00000
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1



----------------------------------------------------------------------
The F test should use the estimated dispersion parameter, so should be 
different from the Chisq test. The following is what I got from Splus:

deathstar[31] Splus
S-PLUS : Copyright (c) 1988, 2000 MathSoft, Inc.
S : Copyright Lucent Technologies, Inc.
Version 6.0 Release 1 for Linux 2.2.12 : 2000
Working data will be in /data/home/faculty/yuedong/MySwork
> counts <- c(18,17,15,20,10,20,25,13,12)
> outcome <- factor(rep(1:3,3))
> treatment <- factor(rep(1:3,c(3,3,3)))
> glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())
> anova(glm.D93, test="Chisq")
Analysis of Deviance Table

Poisson model

Response: counts

Terms added sequentially (first to last)
           Df  Deviance Resid. Df Resid. Dev   Pr(Chi)
      NULL                      8   10.58145
   outcome  2  5.452305         6    5.12914 0.0654707
treatment  2  0.000000         4    5.12914 1.0000000
> anova(glm.D93, test="F")
Analysis of Deviance Table

Poisson model

Response: counts

Terms added sequentially (first to last)
           Df  Deviance Resid. Df Resid. Dev  F Value     Pr(F)
      NULL                      8   10.58145
   outcome  2  5.452305         6    5.12914 2.108359 0.2369863
treatment  2  0.000000         4    5.12914 0.000000 1.0000000


--------------------------------------------------------------------
Yuedong Wang                                  Phone:  (805) 893-4870
Dept of Statistics & Applied Probability        Fax:  (805) 893-2334
Univ of California                            yuedong@pstat.ucsb.edu
Santa Barbara, CA 93106    http://www.pstat.ucsb.edu/faculty/yuedong

From ripley at stats.ox.ac.uk  Wed Feb  2 08:37:29 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb  2 08:37:53 2005
Subject: [Rd] anova.glm (PR#7624)
In-Reply-To: <20050202033148.8E96DE078@slim.kubism.ku.dk>
References: <20050202033148.8E96DE078@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502020718230.14088@gannet.stats>

A poisson family has dispersion 1 by definition of 'Poisson'.
You need a quasipoisson family to use a moment estimate of dispersion.

This difference is described on the help page for anova.glm.
Note the estimated dispersion *is* used and *is* one:

> summary(glm.D93)$dispersion
[1] 1

as it ought to be (and is in S-PLUS too).  That it is not used in S-PLUS 
is not documented (and it is not used in summary.glm either) and is at 
least an inconsistency.

Your assumption that R is wrong and S-PLUS (sic) is correct is not 
appreciated.  Why did you file this as an R bug and not an S-PLUS one?


On Wed, 2 Feb 2005 yuedong@pstat.ucsb.edu wrote:

> There may be a bug in the anova.glm function.

But not in the one in R!

> deathstar[32] R
>
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
>> counts <- c(18,17,15,20,10,20,25,13,12)
>> outcome <- gl(3,1,9)
>> treatment <- gl(3,3)
>> glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())
>> anova(glm.D93,test="Chisq")
> Analysis of Deviance Table
>
> Model: poisson, link: log
>
> Response: counts
>
> Terms added sequentially (first to last)
>
>
>           Df Deviance Resid. Df Resid. Dev P(>|Chi|)
> NULL                          8    10.5814
> outcome    2   5.4523         6     5.1291    0.0655
> treatment  2   0.0000         4     5.1291    1.0000
>
>> anova(glm.D93,test="F")
> Analysis of Deviance Table
>
> Model: poisson, link: log
>
> Response: counts
>
> Terms added sequentially (first to last)
>
>
>           Df Deviance Resid. Df Resid. Dev      F  Pr(>F)
> NULL                          8    10.5814
> outcome    2   5.4523         6     5.1291 2.7262 0.06547 .
> treatment  2   0.0000         4     5.1291 0.0000 1.00000
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
>
>
> ----------------------------------------------------------------------
> The F test should use the estimated dispersion parameter, so should be
> different from the Chisq test. The following is what I got from Splus:
>
> deathstar[31] Splus
> S-PLUS : Copyright (c) 1988, 2000 MathSoft, Inc.
> S : Copyright Lucent Technologies, Inc.
> Version 6.0 Release 1 for Linux 2.2.12 : 2000
> Working data will be in /data/home/faculty/yuedong/MySwork
>> counts <- c(18,17,15,20,10,20,25,13,12)
>> outcome <- factor(rep(1:3,3))
>> treatment <- factor(rep(1:3,c(3,3,3)))
>> glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())
>> anova(glm.D93, test="Chisq")
> Analysis of Deviance Table
>
> Poisson model
>
> Response: counts
>
> Terms added sequentially (first to last)
>           Df  Deviance Resid. Df Resid. Dev   Pr(Chi)
>      NULL                      8   10.58145
>   outcome  2  5.452305         6    5.12914 0.0654707
> treatment  2  0.000000         4    5.12914 1.0000000
>> anova(glm.D93, test="F")
> Analysis of Deviance Table
>
> Poisson model
>
> Response: counts
>
> Terms added sequentially (first to last)
>           Df  Deviance Resid. Df Resid. Dev  F Value     Pr(F)
>      NULL                      8   10.58145
>   outcome  2  5.452305         6    5.12914 2.108359 0.2369863
> treatment  2  0.000000         4    5.12914 0.000000 1.0000000
>
>
> --------------------------------------------------------------------
> Yuedong Wang                                  Phone:  (805) 893-4870
> Dept of Statistics & Applied Probability        Fax:  (805) 893-2334
> Univ of California                            yuedong@pstat.ucsb.edu
> Santa Barbara, CA 93106    http://www.pstat.ucsb.edu/faculty/yuedong
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pgilbert at bank-banque-canada.ca  Wed Feb  2 15:58:01 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed Feb  2 15:59:47 2005
Subject: [Rd] Re: package checks and tests;  was: Re:  A "rude" question
In-Reply-To: <42009C4B.9080604@statistik.uni-dortmund.de>
References: <20050127050951.GA26565@localhost>	<41FFF573.6010302@bank-banque-canada.ca>
	<41FFFB1C.8080902@pdf.com>
	<Pine.LNX.4.58L0.0502012011080.8161@est.ufpr.br>
	<42009C4B.9080604@statistik.uni-dortmund.de>
Message-ID: <4200EA79.3010109@bank-banque-canada.ca>

[moved to R-devel]

I am a bit concerned by the fact that package developers would be 
removing all tests. The tests seem like one of the main mechanisms for 
ensuring that CRAN does not descend to the almost useless state of 
statlib: there is an automatic mechanism for removing packages that no 
longer work.

I have several tests that I don't put in packages, because they are very 
long or they don't work without locally available databases, but I think 
it is important that there should be tests that check the main 
functionality of packages.  For very long tests like monte carlo 
simulations it is usually fairly easy to devise some short version (a 
few iterations) which checks that the software actually works and gives 
results that are the same as they always have been, even though it does 
not check the more serious statistical problems one would actually want 
to do.

Perhaps there should be another directory, called something like 
longTests, that is not run daily but is run occasionally.

On r-help I suggested that users might contribute tests to package 
developers, but another possibility is that there is some mechanism for 
them to contribute suites of package tests directly to CRAN. This would 
provide a mechanism for more complete checking of packages, and perhaps 
a just system for removing packages when the developer is no longer 
active and the package is broken.

Paul Gilbert

Uwe Ligges wrote:
> Paulo Justiniano Ribeiro Jr wrote:
> 
>> One problem with distributing packages with the test sub-directory
>> is that this can overload the daily tests in the CRAN machines
>>
>> My workaround for that  is:
>> For the geoR package I run the tests in my machine but remove the tests
>> directory when submitting to CRAN.
>> Also I mantain a package web-page where I make the version
>> with tests available for downloading
> 
> 
> [moved to R-devel, chosen a more sensible subject]
> 
> If tests are running in a reasonable amount of time, it does not make 
> sense to remove them. People want to install the package on a huge 
> number of platforms you probably have not tested the package on 
> yourself. The only solution is to distribute the tests as well.
> 
> Overloading the daily tests on CRAN is another issue (strong related, 
> though). Installing and checking (in maintainer's mode, i.e. without 
> double-installing) all CRAN packages under R-release for Windows takes 8 
> hours on a (dual, but using only one) Xeon 3.06GHz machine these days.
> The checks (without isntallation) of the 15 packages with most intensive 
>  tests take ~1 hour.
> 
> Uwe Ligges
> 
> 
> 
> 
> 
>> P.J.
>>
>> On Tue, 1 Feb 2005, Spencer Graves wrote:
>>
>>
>>> Hi, Paul:
>>>
>>>      How can I access "the package tests directory" you mentioned?
>>> Only one of the 52 subdirectories of "library" in my current
>>> installation of R 2.0.1 has a "test" folder.
>>>
>>>      Thanks,
>>>      Spencer Graves
>>>
>>> Paul Gilbert wrote:
>>>
>>>
>>>> One point that did not get mentioned in this discussion, and I believe
>>>> deserves
>>>> much more publicity, is the impact of packages tests. The design of
>>>> the package
>>>> system allows package developers to put tests in packages, and these
>>>> are checked
>>>> regularly (see 
>>>> <http://cran.at.r-project.org/contrib/checkSummary.html>).
>>>>
>>>> These are intended to test the package functionality, but also give R
>>>> what is
>>>> perhaps the largest test suite of any statistical software (certainly
>>>> the most
>>>> quickly growing). While any single package's test will never guarantee
>>>> that
>>>> the package works perfectly, the ensemble goes a long way toward 
>>>> ensuring
>>>> that core R functionality behaves as intended. It seems unlikely to me
>>>> that any
>>>> commercial effort will ever be able to catch up.
>>>>
>>>> There are several ways that tests can add to our confidence that
>>>> calculations can be trusted. They can
>>>>  - check against theoretical results
>>>>  - check against published results
>>>>  - check against results from other software
>>>>  - check that calculations done in different ways give the same result
>>>>  - check that monte carlo experiments give distributions that are
>>>> consistent
>>>>     with expected results
>>>>
>>>> Some of these are relatively time consuming to set up and check the
>>>> first time,
>>>> but after that they can be automatic.
>>>>
>>>> If you have particular calculations with specific packages that you
>>>> are especially
>>>> concerned about, I encourage you to participate by devising good tests
>>>> and sending
>>>> them to the package developers. (But first check the tests they are
>>>> already doing
>>>> in the package tests directory.)
>>>>
>>>> Paul Gilbert
>>>>
>>>> msck9@mizzou.edu wrote:
>>>>
>>>>
>>>>> Dear all, I am beginner using R. I have a question about it. When you
>>>>> use it,
>>>>> since it is written by so many authors, how do you know that the
>>>>> results are trustable?(I don't want to affend anyone, also I trust
>>>>> people). But I think this should be a question.
>>>>>
>>>>> Thanks,
>>>>> Ming
>>>>>
>>>>> ______________________________________________
>>>>> R-help@stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide!
>>>>> http://www.R-project.org/posting-guide.html
>>>>>
>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help@stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide!
>>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>>> ______________________________________________
>>> R-help@stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>>
>>
>> Paulo Justiniano Ribeiro Jr
>> LEG (Laborat?rio de Estat?stica e Geoinforma??o)
>> Departamento de Estat?stica
>> Universidade Federal do Paran?
>> Caixa Postal 19.081
>> CEP 81.531-990
>> Curitiba, PR  -  Brasil
>> Tel: (+55) 41 361 3573
>> Fax: (+55) 41 361 3141
>> e-mail: paulojus@est.ufpr.br
>> http://www.est.ufpr.br/~paulojus
>>
>> ______________________________________________
>> R-help@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
>

From mgd at santafe.edu  Wed Feb  2 19:50:31 2005
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Wed Feb  2 19:50:27 2005
Subject: [Rd] modules with libtool and -dlpreopen
Message-ID: <420120F7.1000909@santafe.edu>

Has anyone looked at setting up R to build its modules with libtool's 
dlpreopen?

[libtool -dlpreopen is a facility that allows one to simulate dynamic 
linking on platforms that lack it.  However, it requires collecting all 
of the component `shared' objects into one and linking them (and a 
metadata structure) into a single executable.]

Thanks.

From mgd at santafe.edu  Wed Feb  2 20:14:22 2005
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Wed Feb  2 20:15:03 2005
Subject: [Rd] modules with libtool and -dlpreopen
Message-ID: <4201268E.90400@santafe.edu>

Has anyone looked at setting up R to build its modules with libtool's 
dlpreopen?

[libtool -dlpreopen is a facility that allows one to simulate dynamic 
linking on platforms that lack it.  However, it requires collecting all 
of the component `shared' objects into one and linking them (and a 
metadata structure) into a single executable.]

Thanks.

From keith at nissimo.net  Wed Feb  2 20:18:45 2005
From: keith at nissimo.net (keith@nissimo.net)
Date: Wed Feb  2 20:18:48 2005
Subject: [Rd] reading data from a pipe() uses 99% CPU (PR#7634)
Message-ID: <20050202191845.CE432E06D@slim.kubism.ku.dk>

Full_Name: Keith L. Frost
Version: R 2.0.1 (Rgui -- Win32)
OS: Windows XP Pro SP2
Submission from: (NULL) (66.162.141.10)


There seems to be a bug in the Win32 implementation of reading data from another
process
which has been started from the pipe() call.  The other process gets starved for
CPU
time --- it takes well over ten times as long to complete as it would if running
from
the same pipe() call, if only the calling (R) process did not read from the
pipe.  I
have tried using readLines() and scan(), and both have the same effect.

This bug seems to be OS-specific:  I have not observed this behavior under
Linux.

From ripley at stats.ox.ac.uk  Wed Feb  2 20:42:17 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb  2 20:42:26 2005
Subject: [Rd] modules with libtool and -dlpreopen
In-Reply-To: <4201268E.90400@santafe.edu>
References: <4201268E.90400@santafe.edu>
Message-ID: <Pine.LNX.4.61.0502021940240.5376@gannet.stats>

Yes.
Some of them use Fortran, please note, and libtool is none too good at that.

Not sure why this merited sending twice ....

On Wed, 2 Feb 2005, Marcus G. Daniels wrote:

> Has anyone looked at setting up R to build its modules with libtool's 
> dlpreopen?
>
> [libtool -dlpreopen is a facility that allows one to simulate dynamic linking 
> on platforms that lack it.

No current R platform does.

> However, it requires collecting all of the 
> component `shared' objects into one and linking them (and a metadata 
> structure) into a single executable.]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pgilbert at bank-banque-canada.ca  Wed Feb  2 22:54:15 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed Feb  2 22:55:54 2005
Subject: [Rd] windows dse bundle install problem
Message-ID: <42014C07.3010704@bank-banque-canada.ca>

I rarely use Windows, so perhaps this is a question for r-help but I 
don't think so.

 > install.packages("dse")
trying URL `http://cran.r-project.org/bin/windows/contrib/2.0/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 24873 bytes
opened URL
downloaded 24Kb

trying URL 
`http://cran.r-project.org/bin/windows/contrib/2.0/dse_2005.1-1.zip'
Content type `application/zip' length 1570336 bytes
opened URL
downloaded 1533Kb

bundle 'dse' successfully unpacked and MD5 sums checked

Delete downloaded files (y/N)? y

updating HTML package descriptions
Warning message:
unable to move temp installation 
'C:/PROGRA~1/R/rw2001/library\file1104/tframe' to 
'C:/PROGRA~1/R/rw2001/library/tframe'
 > library()

Two packages in the bundle installed ok, but tframe did not. I'm not 
sure why there is a backslash after the first library and nowhere else.
Is this a user error or a bug?

Paul Gilbert

From mgd at santafe.edu  Thu Feb  3 01:44:51 2005
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Thu Feb  3 01:43:46 2005
Subject: [Rd] modules with libtool and -dlpreopen
In-Reply-To: <Pine.LNX.4.61.0502021940240.5376@gannet.stats>
References: <4201268E.90400@santafe.edu>
	<Pine.LNX.4.61.0502021940240.5376@gannet.stats>
Message-ID: <42017403.3010105@santafe.edu>

Prof Brian Ripley wrote:

> Some of them use Fortran, please note, and libtool is none too good at 
> that.

I didn't have an (obvious) problem with that.  I did notice that DYLIB_* 
variables in Makeconf.in didn't have USE_LIBTOOL_TRUE/FALSE 
conditionalizations.  That was a place it broke for me with Fortran code 
in modules.  Was it a compile-time problem or a run-time problem you saw?

Also I noticed compilation invocations weren't set up in R 2.0.1 to prepend
"libtool --mode=compile".   When I inserted those for C and Fortran, 
reactivated the linkage code for libtool that was already there, and 
then went through each module and made *.lo the dependency instead of 
*.o, and made *.la the target instead of *.so, I managed to get (.la) 
modules installed in the build tree under 
/build/R/library/{tools,grid,methods,splines,stats,tools).  

Next I went to the src/unix directory and removed the object code, and 
rebuilt using:

make CPPFLAGS='-Ddlsym=lt_dlsym -Ddlopen=lt_dlopen -Ddlclose=lt_dlclose'

After that I went back to the src/main directory and first edited 
Rmain.c to add an include of ltdl.h , a call to 
LTDL_SET_PRELOADED_SYMBOLS() and a call to "lt_dlinit ()" before 
"Rf_initialize_R (ac, av)".

Then I modified the linkage of R.bin to add this at the start of the 
command:

-dlpreopen /build/R/library/tools/libs/tools.la -dlpreopen 
/build/R/library/stats/libs/stats.la -dlpreopen 
/build/R/library/methods/libs/methods.la -dlpreopen 
/build/R/library/grid/libs/grid.la -dlpreopen 
/build/R/library/stats/libs/splines.la

and:

-lltdl

at the end of the link (the libtool dlopen compatibility interface). 

Following that I just went to the top of the build tree of R and let the 
build finish. 

As you can see, no calls to dlsym get made:

$ R_HOME=/build/R gdb ./R.bin   -q
Using host libthread_db library "/lib/tls/libthread_db.so.1".
(gdb) break main
Breakpoint 1 at 0x8060c52: file /src/R-2.0.1/src/main/Rmain.c, line 32.
(gdb) run -q
Starting program: /build/R/src/main/R.bin -q

Breakpoint 1, main (ac=2, av=0xfefbce44) at /src/R-2.0.1/src/main/Rmain.c:32
32      {
(gdb) break dlsym
Breakpoint 2 at 0xf6fa3de6
(gdb) c
Continuing.
Detaching after fork from child process 6376.
 >

Compare this to a default build of R on Linux that would have them:

$ R -d 'gdb -q' -q
(no debugging symbols found)...Using host libthread_db library 
"/lib/tls/libthread_db.so.1".
(gdb) break main
Breakpoint 1 at 0x805ceb6
(gdb) run -q
Starting program: /usr/lib/R/bin/exec/R -q
(no debugging symbols found)...(no debugging symbols found)...
Breakpoint 1, 0x0805ceb6 in main ()
(gdb) break dlsym
Breakpoint 2 at 0xf6f55de6
(gdb) c
Continuing.

Breakpoint 2, 0xf6f55de6 in dlsym () from /lib/libdl.so.2
(gdb)

From mgd at santafe.edu  Thu Feb  3 02:11:30 2005
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Thu Feb  3 02:11:43 2005
Subject: [Rd] modules with libtool and -dlpreopen
In-Reply-To: <Pine.LNX.4.61.0502021940240.5376@gannet.stats>
References: <4201268E.90400@santafe.edu>
	<Pine.LNX.4.61.0502021940240.5376@gannet.stats>
Message-ID: <42017A42.3080108@santafe.edu>

Prof Brian Ripley wrote:

>> Has anyone looked at setting up R to build its modules with libtool's 
>> dlpreopen?
>>
>> [libtool -dlpreopen is a facility that allows one to simulate dynamic 
>> linking on platforms that lack it.
>
> No current R platform does.

The static linking workarounds are for a Cray MTA/2, a multithreaded 
supercomputer.   Although having a rather primitive runtime environment 
(e.g. no dynamic linker), it does have an advanced parallelizing 
compiler.   (The practical usage is kind of fly-by-wire setup using a 
front-end workstation.)  The MTA/2 is fast architecture for 
memory-intensive applications.

From ripley at stats.ox.ac.uk  Thu Feb  3 08:27:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Feb  3 08:27:30 2005
Subject: [Rd] windows dse bundle install problem
In-Reply-To: <42014C07.3010704@bank-banque-canada.ca>
References: <42014C07.3010704@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.61.0502030718050.13536@gannet.stats>

It works for me on R 2.0.1 and Windows XP (and also R-devel).

That message is seen very occasionally and usually indicates a Windows 
file-system problem: it used to happen more with Win98 than with 2000/XP.

Both / and \ are legal and interchangeable in Windows paths, so that is a 
red herring.


On Wed, 2 Feb 2005, Paul Gilbert wrote:

> I rarely use Windows, so perhaps this is a question for r-help but I don't 
> think so.
>
>> install.packages("dse")
> trying URL `http://cran.r-project.org/bin/windows/contrib/2.0/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 24873 bytes
> opened URL
> downloaded 24Kb
>
> trying URL 
> `http://cran.r-project.org/bin/windows/contrib/2.0/dse_2005.1-1.zip'
> Content type `application/zip' length 1570336 bytes
> opened URL
> downloaded 1533Kb
>
> bundle 'dse' successfully unpacked and MD5 sums checked
>
> Delete downloaded files (y/N)? y
>
> updating HTML package descriptions
> Warning message:
> unable to move temp installation 
> 'C:/PROGRA~1/R/rw2001/library\file1104/tframe' to 
> 'C:/PROGRA~1/R/rw2001/library/tframe'
>> library()
>
> Two packages in the bundle installed ok, but tframe did not. I'm not sure why 
> there is a backslash after the first library and nowhere else.
> Is this a user error or a bug?

A bug in Windows.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From calidad at tradecos.com.ar  Thu Feb  3 14:16:22 2005
From: calidad at tradecos.com.ar (Laura  Celaya)
Date: Thu Feb  3 14:13:27 2005
Subject: [Rd] =?iso-8859-1?q?Respuesta_autom=E1tica_de_Fuera_de_la_oficin?=
	=?iso-8859-1?q?a=3A_massas!?=
Message-ID: <0E1551120A34FF4B99448A52A48F8970285361@server.tradecos.com.ar>

 I will be out of the office from 02/02 to 7/02
I will respond to your message when I return.
Thank you - Laura

From roberts at berkeley.edu  Thu Feb  3 16:55:24 2005
From: roberts at berkeley.edu (roberts@berkeley.edu)
Date: Thu Feb  3 16:55:27 2005
Subject: [Rd] bug in fix & edit (PR#7642)
Message-ID: <20050203155524.D4138E0B9@slim.kubism.ku.dk>

The edit command (and the fix command, which calls edit), when used on data frames, cause a character variable to become a factor variable. Here is an example:

>> is.factor(work$notes)
>[1] FALSE
>> is.character(work$notes)
>[1] TRUE
>> fix(work)
>> is.character(work$notes)
>[1] FALSE
>> is.factor(work$notes)
>[1] TRUE

in this example, no editing was done -- the data frame work was not changed by the user.

From Robert.McGehee at geodecapital.com  Thu Feb  3 17:33:40 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Thu Feb  3 17:33:47 2005
Subject: [Rd] getAnywhere
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E53@MSGBOSCLB2WIN.DMN1.FMR.COM>

Shouldn't this work?

> .a <- 5
> exists(".a")
[1] TRUE
> getAnywhere(".a")
Error in exists(x, envir, mode, inherits) : 
	invalid first argument

getAnywhere doesn't seem to like the "." prefix. Is this a bug?

Thanks,
Robert

Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for us...{{dropped}}

From p.dalgaard at biostat.ku.dk  Thu Feb  3 17:59:17 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Feb  3 18:03:24 2005
Subject: [Rd] getAnywhere
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E53@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E53@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <x2lla5vau2.fsf@biostat.ku.dk>

"McGehee, Robert" <Robert.McGehee@geodecapital.com> writes:

> Shouldn't this work?
> 
> > .a <- 5
> > exists(".a")
> [1] TRUE
> > getAnywhere(".a")
> Error in exists(x, envir, mode, inherits) : 
> 	invalid first argument
> 
> getAnywhere doesn't seem to like the "." prefix. Is this a bug?

Yes. It goes looking for getS3method(gen="", cl="a", TRUE) without
checking whether gen (or cl) is empty. Looks like an easy fix.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From pasha at computer.org  Fri Feb  4 03:47:05 2005
From: pasha at computer.org (pasha@computer.org)
Date: Fri Feb  4 03:47:09 2005
Subject: [Rd] make check hangs on internet.R (PR#7645)
Message-ID: <20050204024705.C2532E077@slim.kubism.ku.dk>

Full_Name: Pasha Minallah
Version: 2.0.1
OS: Linux i386
Submission from: (NULL) (148.78.243.52)


The commands I used were:

./configure MAKE=gmake --prefix=/usr/local/R --enable-R-shlib --with-x
--with-gnome
gmake
gmake check

gmake check simply hangs on:

running tests of Internet and socket functions
  expect some differences
gmake[3]: Entering directory `/usr/local/R-2.0.1/tests'
running code in 'internet.R' ...

I'm running Fedora Core 3 with all the updates.

From customercare at gamespy.com  Fri Feb  4 15:40:38 2005
From: customercare at gamespy.com (customercare@gamespy.com)
Date: Fri Feb  4 15:40:44 2005
Subject: [Rd] Re: Server Error (feedback@gamespyarcade.com)
Message-ID: <20050204144038.590423C51C@mailout01.gamespy.com>

Thank you for contacting GameSpy! This is the only response you will receive to your email.  

Due to the recent email worm  Sobig.F we need to filter our emails very aggressively.  Please use our contact form instead:  http://www.gamespyarcade.com/support/contact.asp

Thanks!

Mark "The FreshMaker" Surfas

From reid_huntsinger at merck.com  Fri Feb  4 17:45:58 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri Feb  4 17:46:51 2005
Subject: [Rd] RE: [R] Keeping the data of C structure in R variables?..
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A92AB@uswpmx00.merck.com>

I think you should have a look at external pointers (type EXTPTRSXP). They
are used in the R source . See, for example, memory.c. Also see the
developer page notes on weak references, finalizers, etc, which you'll need
to be familiar with. 

This is really an R-devel question!

Reid Huntsinger

-----Original Message-----
From: r-help-bounces@stat.math.ethz.ch
[mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Oleg Sklyar
Sent: Friday, February 04, 2005 11:11 AM
To: R-help@stat.math.ethz.ch
Subject: [R] Keeping the data of C structure in R variables?..


Dear all,

does anybody know if there is a way to implement the following idea:

if for example I have a C/C++ structure of form:

struct {
    int size;
    char * data;
} SData;

in C code I could create some implementation that would create this 
structure by pointer and fill in the data, so I would have a variable 
something like

SData* myData;

Now what I need is to pass this data to a certain SEXP structure and 
keep it completely in R, thus setting myData = NULL and _unloading the C 
library_; then later I want to create another variable, in another C 
call, SData* myOldData and reload it with values from R. Is there a way 
to do that, keeping also in mind that char* data is generally binary data.

Would be greatful for any suggestions.

Regards
Oleg

______________________________________________
R-help@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

From ligges at statistik.uni-dortmund.de  Sat Feb  5 17:19:40 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Feb  5 17:18:35 2005
Subject: [Rd] Re: [R] R package with C code on Windows
In-Reply-To: <20050204202628.GA14808@sfu.ca>
References: <20050204202628.GA14808@sfu.ca>
Message-ID: <4204F21C.1010405@statistik.uni-dortmund.de>

S. Blay wrote:

> Dear R helpers,
> 
> MyPkg passes R CMD check on Linux machines.
> However, when I 'R CMD check myPkg' on Windows,
> the libs subdirectory is not being created.
> 
> If I install the package and then create the libs 
> subdirectory manually and copy the dll files to it, 
> the package seems to work fine 
> (but that's not good enough for submitting it to CRAN).
> 
> Any advice will be appreciated, 
> 
> Thanks,
> 
> Sigal
> 
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

[moved to R-devel]

You might want to redesign your package in order to finally have just 
one dll called like the package (i.e. stepwise.dll which will be 
installed automatically).

BTW: You don't want CC = gcc in your Makefile.win.

Uwe Ligges

From MSN at pubhealth.ku.dk  Sat Feb  5 21:00:57 2005
From: MSN at pubhealth.ku.dk (MSN@pubhealth.ku.dk)
Date: Sat Feb  5 21:01:08 2005
Subject: [Rd] Sony DSC-F828 8.0MP Digital Camera,
	thank you for your purchase. (PR#7656)
Message-ID: <20050205200057.D61FBDCF0@slim.kubism.ku.dk>

----025434187513691
Content-Type: text/html;
	charset="iso-4348-4"
Content-Transfer-Encoding: 7Bit
Content-Description: selectric kirchner relieve

Sony DSC-F828 8.0MP Digital Camera<br><br> 
 

Your order # 12405 has been accepted for the amount 840.00$ <br> 
Your card will be charged in that amount .Thank you for your purchase.<br><br><br> 
  
  
You can check the order in your profile. <br><br> 
<a href="http://naiviges.netfirms.com">http://naiviges.netfirms.com</a> 

----025434187513691--

From Kurt.Hornik at wu-wien.ac.at  Sun Feb  6 15:29:51 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Sun Feb  6 15:30:25 2005
Subject: [Rd] modules with libtool and -dlpreopen
In-Reply-To: <42017403.3010105@santafe.edu>
References: <4201268E.90400@santafe.edu>
	<Pine.LNX.4.61.0502021940240.5376@gannet.stats>
	<42017403.3010105@santafe.edu>
Message-ID: <16902.10719.517092.110952@mithrandir.hornik.net>

>>>>> Marcus G Daniels writes:

> Prof Brian Ripley wrote:
>> Some of them use Fortran, please note, and libtool is none too good at 
>> that.

> I didn't have an (obvious) problem with that.  I did notice that
> DYLIB_* variables in Makeconf.in didn't have USE_LIBTOOL_TRUE/FALSE
> conditionalizations.  That was a place it broke for me with Fortran
> code in modules.  Was it a compile-time problem or a run-time problem
> you saw?

> Also I noticed compilation invocations weren't set up in R 2.0.1 to
> prepend "libtool --mode=compile".  When I inserted those for C and
> Fortran, reactivated the linkage code for libtool that was already
> there, and then went through each module and made *.lo the dependency
> instead of *.o, and made *.la the target instead of *.so, I managed to
> get (.la) modules installed in the build tree under
> /build/R/library/{tools,grid,methods,splines,stats,tools).

Marcus,

This is very interesting.

As you can tell from the current code base, we attempted to move to
using libtool for building dynamic objects quite some time ago, and
found that all libtool could handle then was C (no FORTRAN, no C++).  I
have not returned to this yet, as evidenced by the following in
configure.ac:

## <FIXME>
## Completely disable using libtool for building shlibs until libtool
## fully supports Fortran and C++.
## AC_ARG_WITH([libtool],
## [AC_HELP_STRING([--with-libtool],
##                 [use libtool for building shared libraries @<:@yes@:>@])],
## [use_libtool="${withval}"],
## [use_libtool=yes])
## </FIXME>

The fact the the dylib rules are unconditionalized is because they were
added way after the failed initial attempts.

I think Brian has meanwhile tried to build the R "shared library" using
libtool, and was not amused.

Is there a systematic set of patches you could make available?
Ideally, we'd have a configure option for maybe using libtool, and the
patches would be conditional on that ...

(Not that I can promised to deal with this anytime soon ...)

Best
-k

> Next I went to the src/unix directory and removed the object code, and 
> rebuilt using:

> make CPPFLAGS='-Ddlsym=lt_dlsym -Ddlopen=lt_dlopen -Ddlclose=lt_dlclose'

> After that I went back to the src/main directory and first edited 
> Rmain.c to add an include of ltdl.h , a call to 
> LTDL_SET_PRELOADED_SYMBOLS() and a call to "lt_dlinit ()" before 
> "Rf_initialize_R (ac, av)".

> Then I modified the linkage of R.bin to add this at the start of the 
> command:

> -dlpreopen /build/R/library/tools/libs/tools.la -dlpreopen 
> /build/R/library/stats/libs/stats.la -dlpreopen 
> /build/R/library/methods/libs/methods.la -dlpreopen 
> /build/R/library/grid/libs/grid.la -dlpreopen 
> /build/R/library/stats/libs/splines.la

> and:

> -lltdl

> at the end of the link (the libtool dlopen compatibility interface). 

> Following that I just went to the top of the build tree of R and let the 
> build finish. 

> As you can see, no calls to dlsym get made:

> $ R_HOME=/build/R gdb ./R.bin   -q
> Using host libthread_db library "/lib/tls/libthread_db.so.1".
> (gdb) break main
> Breakpoint 1 at 0x8060c52: file /src/R-2.0.1/src/main/Rmain.c, line 32.
> (gdb) run -q
> Starting program: /build/R/src/main/R.bin -q

> Breakpoint 1, main (ac=2, av=0xfefbce44) at /src/R-2.0.1/src/main/Rmain.c:32
> 32      {
> (gdb) break dlsym
> Breakpoint 2 at 0xf6fa3de6
> (gdb) c
> Continuing.
> Detaching after fork from child process 6376.
>> 

> Compare this to a default build of R on Linux that would have them:

> $ R -d 'gdb -q' -q
> (no debugging symbols found)...Using host libthread_db library 
> "/lib/tls/libthread_db.so.1".
> (gdb) break main
> Breakpoint 1 at 0x805ceb6
> (gdb) run -q
> Starting program: /usr/lib/R/bin/exec/R -q
> (no debugging symbols found)...(no debugging symbols found)...
> Breakpoint 1, 0x0805ceb6 in main ()
> (gdb) break dlsym
> Breakpoint 2 at 0xf6f55de6
> (gdb) c
> Continuing.

> Breakpoint 2, 0xf6f55de6 in dlsym () from /lib/libdl.so.2
> (gdb)

> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From feferraz at ime.usp.br  Sun Feb  6 20:42:45 2005
From: feferraz at ime.usp.br (Fernando Henrique Ferraz P. da Rosa)
Date: Sun Feb  6 20:42:55 2005
Subject: [Rd] Re: [R] Internationalization and localization of R
In-Reply-To: <Pine.LNX.4.61.0502050858220.11223@gannet.stats>
References: <Pine.LNX.4.61.0502050858220.11223@gannet.stats>
Message-ID: <20050206194245.GA14911@ime.usp.br>

Prof Brian Ripley writes:
> - People might like to start organizing translation teams for their own
>   languages, and early experience from such a team would be helpful in
>   polishing the instructions and mechanisms.  There is a document for
>   translators at
> 
>   http://developer.r-project.org/Translations.html
> 
>   If translations are available by early April they can be shipped with
>   2.1.0 (although there are planned to be mechanisms to add them to an R
>   installation).
> 

        I?ve been playing with the translation files here (I intend to
to translate the base and recommended packages files to Portuguese), and
I noticed a minor problem with the instructions detailed in 

        http://developer.r-project.org/Translations.html

        Where it says:

" Then compile and install the translated catalogues by 

mkdir ../inst/po/LC_MESSAGES/sl
msgfmt -o ../inst/po/LC_MESSAGES/sl/R-splines.mo R-sl.po
msgfmt -o ../inst/po/LC_MESSAGES/sl/splines.mo sl.po
"

        It should read:

"
(...)
mkdir ../inst/po/sl/LC_MESSAGES/
msgfmt -o ../inst/po/sl/LC_MESSAGES/R-splines.mo R-sl.po
msgfmt -o ../inst/po/sl/LC_MESSAGES/splines.mo sl.po
"

        After fixing this I managed to get the gettext translated
messages to work here. 

        On a side note, are there any plans regarding the translation
of the .Rd documentation files? As much as the translation of
messages is important, I believe that the online documentation would
also be an essencial issue.



--
Fernando Henrique Ferraz P. da Rosa
http://www.ime.usp.br/~feferraz

From ripley at stats.ox.ac.uk  Sun Feb  6 21:22:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Feb  6 21:22:37 2005
Subject: [Rd] Re: [R] Internationalization and localization of R
In-Reply-To: <20050206194245.GA14911@ime.usp.br>
References: <Pine.LNX.4.61.0502050858220.11223@gannet.stats>
	<20050206194245.GA14911@ime.usp.br>
Message-ID: <Pine.LNX.4.61.0502062020420.25204@gannet.stats>

On Sun, 6 Feb 2005, Fernando Henrique Ferraz P. da Rosa wrote:

> Prof Brian Ripley writes:
>> - People might like to start organizing translation teams for their own
>>   languages, and early experience from such a team would be helpful in
>>   polishing the instructions and mechanisms.  There is a document for
>>   translators at
>>
>>   http://developer.r-project.org/Translations.html
>>
>>   If translations are available by early April they can be shipped with
>>   2.1.0 (although there are planned to be mechanisms to add them to an R
>>   installation).
>>
>
>        I?ve been playing with the translation files here (I intend to
> to translate the base and recommended packages files to Portuguese), and
> I noticed a minor problem with the instructions detailed in
>
>        http://developer.r-project.org/Translations.html
>
>        Where it says:
>
> " Then compile and install the translated catalogues by
>
> mkdir ../inst/po/LC_MESSAGES/sl
> msgfmt -o ../inst/po/LC_MESSAGES/sl/R-splines.mo R-sl.po
> msgfmt -o ../inst/po/LC_MESSAGES/sl/splines.mo sl.po
> "
>
>        It should read:
>
> "
> (...)
> mkdir ../inst/po/sl/LC_MESSAGES/
> msgfmt -o ../inst/po/sl/LC_MESSAGES/R-splines.mo R-sl.po
> msgfmt -o ../inst/po/sl/LC_MESSAGES/splines.mo sl.po

This has already been corrected, thank you.  The developer site is only 
updated daily.

>        After fixing this I managed to get the gettext translated
> messages to work here.
>
>        On a side note, are there any plans regarding the translation
> of the .Rd documentation files? As much as the translation of
> messages is important, I believe that the online documentation would
> also be an essencial issue.

Not as yet.  That's a much larger task.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
From mark.bravington at csiro.au  Mon Feb  7 02:09:29 2005
From: mark.bravington at csiro.au (mark.bravington@csiro.au)
Date: Mon Feb  7 02:09:37 2005
Subject: [Rd] sys.on.exit not working (PR#7665)
Message-ID: <20050207010929.A6AE5DCF1@slim.kubism.ku.dk>

Full_Name: Mark Bravington
Version: 2.0.1
OS: Windows XP
Submission from: (NULL) (140.79.22.104)


'sys.on.exit()' doesn't seem to be working, since R1.7.1 at least:

soe.test <- function() { 
  on.exit( cat( 'In exit code\n'))
  str( sys.on.exit()) # should display "language..." I think
  12 
}

(A similar bug was apparently fixed for version 0.65!)

From ripley at stats.ox.ac.uk  Mon Feb  7 15:23:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb  7 15:23:55 2005
Subject: [Rd] sys.on.exit not working (PR#7665)
In-Reply-To: <20050207010929.A6AE5DCF1@slim.kubism.ku.dk>
References: <20050207010929.A6AE5DCF1@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502071350260.29439@gannet.stats>

It is working as documented: there is no on.exit set for str, is there?

      'sys.on.exit()' retrieves the expression stored for use by
      'on.exit' in the function currently being evaluated. (Note that
                                ^^^^^^^^^^^^^^^^^^^^^^^^^
      this differs from S, which returns a list of expressions for the
      current frame and its parents.)

I see you have looked at PR#269, but did not notice the crucial 
difference: here the current function is str (it is evaluating its 
arguments), not soe.test.

On Mon, 7 Feb 2005 mark.bravington@csiro.au wrote:

> Full_Name: Mark Bravington
> Version: 2.0.1
> OS: Windows XP
> Submission from: (NULL) (140.79.22.104)
>
>
> 'sys.on.exit()' doesn't seem to be working, since R1.7.1 at least:

Please read the FAQ: we don't want R-bugs clogged up with `doesn't seem to 
be working' reports, and we do say so.

> soe.test <- function() {
>  on.exit( cat( 'In exit code\n'))
>  str( sys.on.exit()) # should display "language..." I think
>  12
> }
>
> (A similar bug was apparently fixed for version 0.65!)

One difference being that PR#269 was a bug, and this is not.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From wss at whitecase.com  Mon Feb  7 15:47:35 2005
From: wss at whitecase.com (WorldSecure Server)
Date: Mon Feb  7 15:47:48 2005
Subject: [Rd] W&C Unsafe attachment(s) blocked notification.
Message-ID: <6E19A0DF168795215-01@MMS__whitecase.com_>

Please do not reply this E-Mail message. This mailbox does not accept
incoming E-Mail.
	
==============================================
Unsafe Attachment(s) Stripped

Please note: White & Case LLP., firm mail policy dictates that unsafe
attachment types are not allowed in incoming messages, This message
originally contained one or more such attachment types which were
removed prior to delivery. Please contact the recipient if you have
questions regarding this policy.

The following unsafe attachments removed from original E-Mail:
Recipient(s): <hosokta@tokyo.whitecase.com>
Attachment(s): email.txt
.scr
==============================================

-------------- next part --------------
An embedded message was scrubbed...
From: r-devel@r-project.org
Subject: Error
Date: Mon, 7 Feb 2005 23:39:19 +0900
Size: 527
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20050207/bd2172c9/attachment.mht
From ripley at stats.ox.ac.uk  Mon Feb  7 16:33:59 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb  7 16:34:17 2005
Subject: [Rd] bug in fix & edit (PR#7642)
In-Reply-To: <20050203155524.D4138E0B9@slim.kubism.ku.dk>
References: <20050203155524.D4138E0B9@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502071523001.30765@gannet.stats>

What exactly is supposed to be the bug here?  Despite the requests in the 
posting guide and FAQ, there is nothing to reproduce here, and

> xx <- data.frame(a="a", b=I("b"))
> sapply(xx, is.character)
     a     b
FALSE  TRUE
> fix(xx) # do nothing
> sapply(xx, is.character)
     a     b
FALSE  TRUE

shows that your claim is false, at least in current R 2.0.1 (and you have 
failed to give your or your system details as requested -- do see the 
function bug.report).

My guess is that you do not have character columns protected by I(), and 
if so you should expect them to be coerced to factors quite arbitrarily.
That is what I() is for ....

On Thu, 3 Feb 2005 roberts@berkeley.edu wrote:

> The edit command (and the fix command, which calls edit), when used on 
> data frames, cause a character variable to become a factor variable. 
> Here is an example:
>
>>> is.factor(work$notes)
>> [1] FALSE
>>> is.character(work$notes)
>> [1] TRUE
>>> fix(work)
>>> is.character(work$notes)
>> [1] FALSE
>>> is.factor(work$notes)
>> [1] TRUE
>
> in this example, no editing was done -- the data frame work was not 
> changed by the user.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon Feb  7 16:30:51 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Feb  7 16:35:17 2005
Subject: [Rd] sys.on.exit not working (PR#7665)
In-Reply-To: <Pine.LNX.4.61.0502071350260.29439@gannet.stats>
References: <20050207010929.A6AE5DCF1@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502071350260.29439@gannet.stats>
Message-ID: <x2y8e0xu8k.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> It is working as documented: there is no on.exit set for str, is there?
> 
>       'sys.on.exit()' retrieves the expression stored for use by
>       'on.exit' in the function currently being evaluated. (Note that
>                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
>       this differs from S, which returns a list of expressions for the
>       current frame and its parents.)
> 
> I see you have looked at PR#269, but did not notice the crucial
> difference: here the current function is str (it is evaluating its
> arguments), not soe.test.
> 
> On Mon, 7 Feb 2005 mark.bravington@csiro.au wrote:
> 
> > Full_Name: Mark Bravington
> > Version: 2.0.1
> > OS: Windows XP
> > Submission from: (NULL) (140.79.22.104)
> >
> >
> > 'sys.on.exit()' doesn't seem to be working, since R1.7.1 at least:
> 
> Please read the FAQ: we don't want R-bugs clogged up with `doesn't
> seem to be working' reports, and we do say so.
> 
> > soe.test <- function() {
> >  on.exit( cat( 'In exit code\n'))
> >  str( sys.on.exit()) # should display "language..." I think
> >  12
> > }
> >
> > (A similar bug was apparently fixed for version 0.65!)
> 
> One difference being that PR#269 was a bug, and this is not.

It does, however, point to a subtlety with the sys.xxx functions,
which is liable to confuse users to the point of submitting spurious
bug reports. Perhaps we should add a note to the help page (in the
vain hope that people will read it).

Notice, BTW, that this exposes a slightly anomalous handling of the
"<-" operator. AFAIK this is common to all .Primitive calls, as
opposed to .Internal and other function calls: They do not create a
new context, hence do not increase sys.nframe() and sys.whatever in
the arguments still refer to the callers frame.

> soe.test
function() {
  on.exit( cat( 'In exit code\n'))
  a <- sys.on.exit() ; str(a)
  12
 }

> soe.test()
 language cat("In exit code\n")
In exit code
[1] 12

but if you replace "<-" with a corresponding call to assign(), then
you get.

> soe.test()
 NULL
In exit code
[1] 12

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Mon Feb  7 16:35:13 2005
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Mon Feb  7 16:35:20 2005
Subject: [Rd] sys.on.exit not working (PR#7665)
Message-ID: <20050207153513.C45B8DCEF@slim.kubism.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> It is working as documented: there is no on.exit set for str, is there?
> 
>       'sys.on.exit()' retrieves the expression stored for use by
>       'on.exit' in the function currently being evaluated. (Note that
>                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
>       this differs from S, which returns a list of expressions for the
>       current frame and its parents.)
> 
> I see you have looked at PR#269, but did not notice the crucial
> difference: here the current function is str (it is evaluating its
> arguments), not soe.test.
> 
> On Mon, 7 Feb 2005 mark.bravington@csiro.au wrote:
> 
> > Full_Name: Mark Bravington
> > Version: 2.0.1
> > OS: Windows XP
> > Submission from: (NULL) (140.79.22.104)
> >
> >
> > 'sys.on.exit()' doesn't seem to be working, since R1.7.1 at least:
> 
> Please read the FAQ: we don't want R-bugs clogged up with `doesn't
> seem to be working' reports, and we do say so.
> 
> > soe.test <- function() {
> >  on.exit( cat( 'In exit code\n'))
> >  str( sys.on.exit()) # should display "language..." I think
> >  12
> > }
> >
> > (A similar bug was apparently fixed for version 0.65!)
> 
> One difference being that PR#269 was a bug, and this is not.

It does, however, point to a subtlety with the sys.xxx functions,
which is liable to confuse users to the point of submitting spurious
bug reports. Perhaps we should add a note to the help page (in the
vain hope that people will read it).

Notice, BTW, that this exposes a slightly anomalous handling of the
"<-" operator. AFAIK this is common to all .Primitive calls, as
opposed to .Internal and other function calls: They do not create a
new context, hence do not increase sys.nframe() and sys.whatever in
the arguments still refer to the callers frame.

> soe.test
function() {
  on.exit( cat( 'In exit code\n'))
  a <- sys.on.exit() ; str(a)
  12
 }

> soe.test()
 language cat("In exit code\n")
In exit code
[1] 12

but if you replace "<-" with a corresponding call to assign(), then
you get.

> soe.test()
 NULL
In exit code
[1] 12

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From sdutky at starpower.net  Mon Feb  7 17:56:07 2005
From: sdutky at starpower.net (Steve Dutky)
Date: Mon Feb  7 17:56:17 2005
Subject: [Rd] Problems encountered/fixed making CrossCompileBuild
Message-ID: <b1b28a05.caf97d67.819db00@ms08.mrf.mail.rcn.net>

Dear All:

I encountered and apparently overcame problems following Yan 
and Rossini?s procedure for  "Building Microsoft Windows 
Versions of R and R packages under Intel Linux" 
(http://cran.r-project.org/doc/contrib/cross-build.pdf):  I 
have successfully cross-compiled R packages for Windows on a 
FreeBSD 4.10 i386 system.

My  revisions to Makefile-rcb (http://cran.r-
project.org/doc/contrib/Makefile-rcb ) follow here:

1. created makevar MAKE initialized to gmake.  Replaced all 
direct references to make with $(MAKE).

2. updated  makevar MINGW_CROSS = mingw-cross4 to point to 
http://www.stats.ox.ac.uk/pub/Rtools/mingw-cross4.tar.bz2 , 
replacing original reference to mingw-cross2.

3. updated MkRules HEADER=$(CROSSDIR)/i586-mingw32/include , 
replacing  original reference to <snip>/mingw32/include. 

4. reset LinuxFresh = YES
Yan and Rossini imply that linuxR: is an optional step if R 
is already installed.  I ran afoul of steps in 
$(WINR)/<snip>/gnuwin32/MakePkg referencing symbols in the 
tools package in the system's version of R.  Happily, these 
ran successfully against $(LINUXR)/R/bin/R.

I hope some of this turns useful to others attempting this.

Thanks, Steve Dutky 
Sdutky@terpalum.umd.edu

Revised Makefile-rcb:

############################ -*- Mode: Makefile -*- 
###########################
## Makefile-rcb --- Makefile for R cross-building
##
## Author          : Jun Yan (University of Iowa) 
<jyan@stat.uiowa.edu>
##                   A.J. Rossini (UW - Seattle) 
<rossini@u.washington.edu>
## Last modified   : 10/11/2004
## Provisionally revised 2/1/2004 S Dutky 
<sdutky@terpalum.umd.edu>
##############################################################
#################
MAKE =  /usr/local/bin/gmake
SHELL = /bin/sh
WGET = wget --passive-ftp
BINS = \*.so \*.dll \*.RData \*.rda \*.zip \*.rds \*.pdf \*.ps

#### define directories

## the current directory where all the following cross-
building happens
RCB := $(shell pwd)
## the directory where the downloaded sources are stored
DOWNDIR = $(RCB)/downloads
## the directory where the cross-tools are installed
CROSSDIR = $(RCB)/cross-tools
## the directory where R sources are unpacked for cross-
building
WINR = $(RCB)/WinR
## the dirECTOry where R for Linux will be compiled and 
installed
LINUXR = $(RCB)/LinuxR

## the directory where package sources are stored
PKGDIR = $(RCB)/pkgsrc
## the directory where the built packages for windows are to 
be stored
WINRLIBS = $(RCB)/WinRlibs

## current versions
R = R-2.0.0
## snapshot R is only available at 
ftp://ftp.stat.math.ethz.ch/Software/R
ifeq ($(findstring devel, $(R)), devel)
RURL = ftp://ftp.stat.math.ethz.ch/Software/R
REXT = tar.gz
else
RURL = http://cran.us.r-project.org/src/base/R-2
REXT = tar.gz
endif

R_TCL_URL = http://www.murdoch-sutherland.com/Rtools/R_Tcl.zip

#MINGW_CROSS = mingw-cross2 now:
MINGW_CROSS = mingw-cross4

## R_EXE
LinuxFresh = YES
ifeq ($(strip $(LinuxFresh)),YES)
R_EXE = $(LINUXR)/R/bin/R
else
R_EXE = R
endif

default: 
	@echo "syntax:"
	@echo "make <target>"
	@echo "No <Target> Specified.  Should be one of:"
	@echo " "
	@echo "-------------------"
	@echo "down     : downloads files"
	@echo "xtools   : unpack cross compilers"
	@echo "prepsrc  : unpack and prepare source code"
	@echo "mkrules  : patch source code for cross-compile"
	@echo "R        : cross-compile R"
	@echo " "
	@echo "(or to run all at once (trusting, aren't 
you?))"
	@echo " "
	@echo "CrossCompileBuild"
	@echo " "
	@echo "(To build packages or bundles, steps above 
have to be run"
	@echo " first to get a working build of R, which is 
required!)"
	@echo " "
	@echo "pkg-NAME_VER    : cross-build package NAME_VER"
	@echo "bundle-NAME_VER : cross-build packages in 
bundle NAME_VER"
	@echo " "
	@echo "(For example, put geepack_0.2-7.tar.gz and 
VR_7.1-10.tar.gz"
	@echo " in subdirectory pkgsrc, then do"
	@echo " "
	@echo " make pkg-geepack_0.2-7"
	@echo " make bundle-VR_7.1-10)"
	@echo "-------------------"
	@echo " "

buildR: clean prepsrc mkrules R

#### steps described in the document

down:
	mkdir -p $(DOWNDIR); \
	cd $(DOWNDIR); \
	$(WGET) $(RURL)/$(R).$(REXT) -O $(R).tgz; \
	$(WGET) $(R_TCL_URL); \
	$(WGET) http://www.stats.ox.ac.uk/pub/Rtools/
$(MINGW_CROSS).tar.bz2; \

downR:
	mkdir -p $(DOWNDIR); \
	cd $(DOWNDIR); \
	$(WGET) $(RURL)/$(R).$(REXT) -O $(R).tgz; \

downRTcl:
	mkdir -p $(DOWNDIR); \
	cd $(DOWNDIR); \
	$(WGET) $(R_TCL_URL);\

downXtools:
	mkdir -p $(DOWNDIR); \
	cd $(DOWNDIR); \
	$(WGET) http://www.stats.ox.ac.uk/pub/Rtools/
$(MINGW_CROSS).tar.bz2; \

linuxR:
	mkdir -p $(LINUXR); \
	cd $(LINUXR); \
	tar zxf $(DOWNDIR)/$(R).tgz; \
	cd $(LINUXR)/$(R); \
	./configure; \
	$(MAKE); \
	$(MAKE) prefix=$(LINUXR)/R install; \

xtools:
	mkdir -p $(RCB)/cross-tools; \
	cd $(CROSSDIR); \
	tar jxf $(DOWNDIR)/$(MINGW_CROSS).tar.bz2; \

prepsrc:
	mkdir -p $(WINR); \
	cd $(WINR); \
	rm -rf $(R); \
	tar zxf $(DOWNDIR)/$(R).tgz; \
	cd $(WINR)/$(R); \
	unzip $(DOWNDIR)/R_Tcl.zip

mkrules:
	cd $(WINR)/$(R)/src/gnuwin32/; \
	cp MkRules MkRules.orig; \
	sed 's|^BUILD=MINGW|BUILD=CROSS|; 
s|^HEADER=.*$$|HEADER=$(CROSSDIR)/i586-mingw32/include|; 
s|^R_EXE=.*$$|R_EXE=$(R_EXE)|; s|# R_EXE=R|R_EXE=$(R_EXE)|' 
MkRules.orig > MkRules

R:
	export 
PATH=$(CROSSDIR)/bin:$(CROSSDIR)/mingw32/bin:$(PATH); \
	cd $(WINR)/$(R)/src/gnuwin32/; \
	$(MAKE); \
	cd $(RCB)/WinR; \
	tar zcf Win-$(R).tgz $(R)

pkg-%:
	export 
PATH=$(CROSSDIR)/bin:$(CROSSDIR)/mingw32/bin:$(PATH); \
	export mypkg=`echo $* | cut -d'_' -f1,1`; \
	cd $(PKGDIR); \
	rm -rf $$mypkg; \
	tar zxf $*.tar.gz; \
	echo -------$$mypkg------; \
	cd $(WINR)/$(R)/src/gnuwin32/; \
	$(MAKE) PKGDIR=$(PKGDIR) RLIB=$(WINRLIBS) STAMP=no 
pkg-$$mypkg; \
	mkdir -p $(WINRLIBS); \
	cd $(WINRLIBS); \
	rm -rf $$mypkg.zip; \
	zip -rl $$mypkg.zip $$mypkg -x $(BINS);\
	zip -r9 $$mypkg.zip $$mypkg -i $(BINS);\
	rm -rf $$mypkg

#### this section no longer works as of R-2.0.0
# bundle-%:
# 	export 
PATH=$(CROSSDIR)/bin:$(CROSSDIR)/mingw32/bin:$(PATH); \
# 	cd $(PKGDIR); \
# 	tar zxf $*.tar.gz; \
# 	export mybundle=`echo $* | cut -d'_' -f1,1`; \
# 	echo -------$$mybundle------; \
# 	cd $(WINR)/$(R)/src/gnuwin32/; \
# 	$(MAKE) PKGDIR=$(PKGDIR) RLIB=$(WINRLIBS) STAMP=no 
bundle-$$mybundle; \
# 	mkdir -p $(WINRLIBS); \
# 	cd $(WINRLIBS); \
# 	ls $(PKGDIR)/$$mybundle/; \
# 	echo $(PKGDIR)/$$mybundle/DESCRIPTION; \
# 	grep "^Contains:" $(PKGDIR)/$$mybundle/DESCRIPTION | 
sed -e 's/Contains: //'; \
# 	export incl=`grep "^Contains:" $(PKGDIR)/
$$mybundle/DESCRIPTION | sed -e 's/Contains: //'`; \
# 	echo ------$$incl------; \
# 	for pkg in $$incl; do \
# 	(rm -rf $$pkg.zip; \
# 	 zip -rl $$pkg.zip $$pkg -x $(BINS); \
# 	 zip -r9 $$pkg.zip $$pkg -i $(BINS); \
# 	 rm -rf $$pkg); \
# 	done; 
bundle-%:
	export 
PATH=$(CROSSDIR)/bin:$(CROSSDIR)/mingw32/bin:$(PATH); \
	cd $(WINR)/$(R)/src/library;\
	tar zxf $(PKGDIR)/$*.tar.gz; \
	export mybundle=`echo $* | cut -d'_' -f1,1`; \
	echo -------$$mybundle------; \
	cd $(WINR)/$(R)/src/gnuwin32/; \
	$(R_EXE) CMD perl XINSTALL --unsafe --
docs=normal ../library/$${mybundle} || exit 1; \
	mkdir -p $(WINRLIBS); \
	ls $(WINR)/$(R)/src/library/$$mybundle/; \
	echo $(PKGDIR)/$$mybundle/DESCRIPTION; \
	grep "^Contains:" $(WINR)/$(R)/src/library/
$$mybundle/DESCRIPTION | sed -e 's/Contains: //'; \
	export incl=`grep "^Contains:" $(WINR)/
$(R)/src/library/$$mybundle/DESCRIPTION | sed -
e 's/Contains: //'`; \
	echo ------$$incl------; \
	cd $(WINR)/$(R)/library; \
	for pkg in $$incl; do \
	(rm -rf $$pkg.zip; \
	 zip -rl $(WINRLIBS)/$$pkg.zip $$pkg -x $(BINS); \
	 zip -r9 $(WINRLIBS)/$$pkg.zip $$pkg -i $(BINS); \
	 rm -rf $$pkg); \
	done; \
	rm -rf $(WINR)/$(R)/src/library/$${mybundle}; \


#### other targets that may be useful

pkgclean-%:
	cd $(PKGDIR); \
	rm -rf $*


recommended:
	export 
PATH=$(CROSSDIR)/bin:$(CROSSDIR)/mingw32/bin:$(PATH); \
	cd $(WINR)/$(R)/src/gnuwin32/; \
	$(MAKE) recommended

# dist-recommended:
# 	mkdir -p $(WINRLIBS); \
# 	cd $(WINR)/$(R)/src/gnuwin32/; \
# 	$(MAKE) dist-recommended; \
# 	mv Recommended.zip $(WINRLIBS)/

clean:
	rm -rf $(WINR)

#### not tested
# rinstaller:
# 	export 
PATH=$(CROSSDIR)/bin:$(CROSSDIR)/mingw32/bin:$(PATH); \
# 	cd $(WINR)/$(R)/src/gnuwin32/; \
# 	$(MAKE) rinstaller


CrossCompileBuild :
	$(MAKE) down
	$(MAKE) xtools 
	$(MAKE) prepsrc
	$(MAKE) mkrules
	$(MAKE) R

From o.medek at sh.cvut.cz  Mon Feb  7 21:03:19 2005
From: o.medek at sh.cvut.cz (o.medek@sh.cvut.cz)
Date: Mon Feb  7 21:03:31 2005
Subject: [Rd] barplot: space makes beside=F (PR#7668)
Message-ID: <20050207200319.6B4AEDD01@slim.kubism.ku.dk>

Full_Name: Ondrej Medek
Version: 2.0.1
OS: Linux/Debian Sarge
Submission from: (NULL) (147.32.127.204)


Hi,
I had a R version 1.5.1 and I used a 'barplot' with 'beside=T' and 'space' has
been vector of 8 numbers 'space=c(1,0.5,rep(c(0.5,-0.5),3))'. Then I upgraded to
the R 2.0.1 and my graphs are broken. If I use any vector of more than 2
elements for 'space' then the graph is drawn as 'beside=F' even if I specify
'beside=T'. 

In the previous version my graph was a graph of groups of eight bars separated
by a big spaces. Every group consisted of 4 pairs of bars separated by a small
space. It's impossible now.

From davclark at nyu.edu  Mon Feb  7 21:20:15 2005
From: davclark at nyu.edu (davclark@nyu.edu)
Date: Mon Feb  7 21:20:24 2005
Subject: [Rd] Incorrect behavior for ordering timepoints in "reshape"
	(PR#7669)
Message-ID: <20050207202015.A1E98DD01@slim.kubism.ku.dk>

Full_Name: Dav Clark
Version: 2.0.1
OS: OS X 10.3
Submission from: (NULL) (128.122.87.35)


When the timepoints that reshape uses (in direction="long") are negative or
fractional, the time label is assigned incorrectly.  It is easier to give an
example than to describe the problem abstractly:

Assume you have a data.frame header with values related to peri-stimulus time
like this:

"HRF -5" "HRF -2.5" "HRF 0" "HRF 2.5" ... "HRF 10"

And you give reshape a split argument of a space " ".

Then the labels will be assigned strangely, based on alphabetical ordering.  So
the above list order maps to:

-2.5, -5, 0, 10, ... 2.5

Items under the "HRF -5" column in wide format recieve a -2.5 label, items under
"HRF 2.5" receive a label of 10, and so on.

Somewhere, the time labels are being used before conversion to numbers.  But,
reshape returns an error if it is not possible to convert the timepoints to
numeric!  So obviously, more functionality could be provided, or at least the
documentation should reflect the current shortfall.

For completeness, here is a minimal example demonstrating the bug:

df <- data.frame(id="S1", V1="from -2", V2="from -1")
names(df)[2:3] <- c("vals.-2", "vals.-1")
df
reshape(df, direction="long", varying=2:3)

Thanks!
Dav

From jbowers at csm.Berkeley.EDU  Mon Feb  7 22:11:46 2005
From: jbowers at csm.Berkeley.EDU (Jake Bowers)
Date: Mon Feb  7 22:11:56 2005
Subject: [Rd] R-patched Make Check Fails on reg-tests-1.R on linux and OS X
In-Reply-To: <b1b28a05.caf97d67.819db00@ms08.mrf.mail.rcn.net>
References: <b1b28a05.caf97d67.819db00@ms08.mrf.mail.rcn.net>
Message-ID: <Pine.GSO.4.51.0502071203120.7373@csm.Berkeley.EDU>

Dear Developers,

I've been playing around with compiling R on my Debian Linux machine (dual
Athlon 1.4ghz) and my OS X machine (dual G5). I'm emailing now because
reg-tests-1.R fails during make check on my debian machine using gcc-3.4,
and on my OS X machine using gcc-3.3. I am using r-patched updated via svn
today (Updated to revision 33075.)

Here are some details:

**Using gcc-3.4 on debian:
gcc-3.4 (GCC) 3.4.4 20041218 (prerelease) (Debian 3.4.3-6)

wes:/home/temp/R/r-patched/tests# tail reg-tests-1.Rout.fail
>
> ## automatic row.names can be number-like, MM, 2004-11-26
> d0 <- data.frame(x=1:3, y=pi*2:0)
> row.names(d0)[3] <- c("01.00")
> write.table(d0, (tf <- tempfile()))
> d <- read.table(tf)
> ## gave error ("duplicate row.names") in 2.0.1
> stopifnot(all.equal(d,d0))
> unlink(tf)

**Using gcc-3.3 on debian works fine (passes all make check).
gcc (GCC) 3.3.5 (Debian 1:3.3.5-5)

**Using gcc-3.3 on OS X.
gcc (GCC) 3.3 20030304 (Apple Computer, Inc. build 1671)

More info on my OS X build:
./configure --with-blas='-framework vecLib' --with-lapack --with-aqua
--with-x --with-tcl-config=/Library/Frameworks/Tcl.framework/tclConfig.sh
--with-tk-config=/Library/Frameworks/Tk.framework/tkConfig.sh
--enable-R-shlib TCLTK_LIBS='-framework Tcl -framework Tk'
TCLTK_CPPFLAGS='-I/Library/Frameworks/Tcl.Framework/Headers
-I/Library/Frameworks/Tk.Framework/Headers' --with-recommended

g77 is version 3.4 downloaded from hpc.sf.net.
GNU Fortran (GCC) 3.4.2

 echo $PATH
/usr/local/bin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/X11R6/bin:/sw/bin:/sw/sbin:/usr/local/pvm3/lib:/usr/local/pvm3/bin/DARWIN

and, to prevent it from using stuff in the fink directory:

CPPFLAGS='-I/usr/local/include'

Here is the output where make check fails:

running regression tests
running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
make[2]: *** [test-Reg] Error 2
make[1]: *** [test-all-basics] Error 1
make: *** [check-all] Error 2

sphere:~/TEMP/R/r-patched/tests jwbowers$ tail reg-tests-1.Rout.fail
>
>
> ## automatic row.names can be number-like, MM, 2004-11-26
> d0 <- data.frame(x=1:3, y=pi*2:0)
> row.names(d0)[3] <- c("01.00")
> write.table(d0, (tf <- tempfile()))
> d <- read.table(tf)
> ## gave error ("duplicate row.names") in 2.0.1
> stopifnot(all.equal(d,d0))
> unlink(tf)

Should I be very concerned about this? I tend to mostly use my OS X
machine since the Linux box is about 4 years old.

I hope this information is helpful --- I'm sorry if this is something
obvious! (I found some posts from last summer about problems with gcc-3.4,
which might explain the problems with gcc-3.4 on linux, but I didn't find
anything obvious about gcc-3.3 on the Mac).

Thanks so much for all of your work!!

Best,

Jake

Jake Bowers
Assistant Professor
Dept of Political Science
University of Michigan
http://www.umich.edu/~jwbowers

From p.dalgaard at biostat.ku.dk  Tue Feb  8 00:38:28 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Feb  8 00:42:59 2005
Subject: [Rd] Incorrect behavior for ordering timepoints in "reshape"
	(PR#7669)
In-Reply-To: <20050207202015.A1E98DD01@slim.kubism.ku.dk>
References: <20050207202015.A1E98DD01@slim.kubism.ku.dk>
Message-ID: <x26514x7nv.fsf@biostat.ku.dk>

davclark@nyu.edu writes:

> Full_Name: Dav Clark
> Version: 2.0.1
> OS: OS X 10.3
> Submission from: (NULL) (128.122.87.35)
> 
> 
> When the timepoints that reshape uses (in direction="long") are negative or
> fractional, the time label is assigned incorrectly.  It is easier to give an
> example than to describe the problem abstractly:
> 
> Assume you have a data.frame header with values related to peri-stimulus time
> like this:
> 
> "HRF -5" "HRF -2.5" "HRF 0" "HRF 2.5" ... "HRF 10"
> 
> And you give reshape a split argument of a space " ".
> 
> Then the labels will be assigned strangely, based on alphabetical ordering.  So
> the above list order maps to:
> 
> -2.5, -5, 0, 10, ... 2.5
> 
> Items under the "HRF -5" column in wide format recieve a -2.5 label, items under
> "HRF 2.5" receive a label of 10, and so on.
> 
> Somewhere, the time labels are being used before conversion to numbers.  But,
> reshape returns an error if it is not possible to convert the timepoints to
> numeric!  So obviously, more functionality could be provided, or at least the
> documentation should reflect the current shortfall.
> 
> For completeness, here is a minimal example demonstrating the bug:
> 
> df <- data.frame(id="S1", V1="from -2", V2="from -1")
> names(df)[2:3] <- c("vals.-2", "vals.-1")
> df
> reshape(df, direction="long", varying=2:3)

Hmm, this looks messed up even without the negatives. The guess()
function inside reshape always sorts before converting to numeric, so
you get the 1 10 11 2 3 4 5 6 7 8 9 effect, but what is worse: the
sorting decouples the values from the variable names, as demonstrated
by modifying your example slightly

> reshape(df, direction="long", varying=3:2)
      id time    vals
S1.-1 S1   -1 from -1
S1.-2 S1   -2 from -2

I'm not at all sure I understand what was supposed to happen here,
perhaps the sort in

    varying <- unique(nn[, 1])
    times <- sort(unique(nn[, 2]))

is a thinko? Over to Thomas, I think.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From davclark at nyu.edu  Tue Feb  8 01:32:42 2005
From: davclark at nyu.edu (Dav Clark)
Date: Tue Feb  8 01:30:25 2005
Subject: [Rd] Incorrect behavior for ordering timepoints in "reshape"
	(PR#7669)
In-Reply-To: <x26514x7nv.fsf@biostat.ku.dk>
References: <20050207202015.A1E98DD01@slim.kubism.ku.dk>
	<x26514x7nv.fsf@biostat.ku.dk>
Message-ID: <dd8665633ce06328a868ed8f66b6edf4@nyu.edu>


On Feb 7, 2005, at 6:38 PM, Peter Dalgaard wrote:

> davclark@nyu.edu writes:
>
>> Full_Name: Dav Clark
>> Version: 2.0.1
>> OS: OS X 10.3
>> Submission from: (NULL) (128.122.87.35)
>>
>>
>> When the timepoints that reshape uses (in direction="long") are 
>> negative or
>> fractional, the time label is assigned incorrectly.  It is easier to 
>> give an
>> example than to describe the problem abstractly:
>>
>> Assume you have a data.frame header with values related to 
>> peri-stimulus time
>> like this:
>>
>> "HRF -5" "HRF -2.5" "HRF 0" "HRF 2.5" ... "HRF 10"
>>
>> And you give reshape a split argument of a space " ".
>>
>> Then the labels will be assigned strangely, based on alphabetical 
>> ordering.  So
>> the above list order maps to:
>>
>> -2.5, -5, 0, 10, ... 2.5
>>
>> Items under the "HRF -5" column in wide format recieve a -2.5 label, 
>> items under
>> "HRF 2.5" receive a label of 10, and so on.
>>
>> Somewhere, the time labels are being used before conversion to 
>> numbers.  But,
>> reshape returns an error if it is not possible to convert the 
>> timepoints to
>> numeric!  So obviously, more functionality could be provided, or at 
>> least the
>> documentation should reflect the current shortfall.
>>
>> For completeness, here is a minimal example demonstrating the bug:
>>
>> df <- data.frame(id="S1", V1="from -2", V2="from -1")
>> names(df)[2:3] <- c("vals.-2", "vals.-1")
>> df
>> reshape(df, direction="long", varying=2:3)
>
> Hmm, this looks messed up even without the negatives. The guess()
> function inside reshape always sorts before converting to numeric, so
> you get the 1 10 11 2 3 4 5 6 7 8 9 effect, but what is worse: the
> sorting decouples the values from the variable names, as demonstrated
> by modifying your example slightly
>
>> reshape(df, direction="long", varying=3:2)
>       id time    vals
> S1.-1 S1   -1 from -1
> S1.-2 S1   -2 from -2
>
> I'm not at all sure I understand what was supposed to happen here,
> perhaps the sort in
>
>     varying <- unique(nn[, 1])
>     times <- sort(unique(nn[, 2]))
>
> is a thinko? Over to Thomas, I think.
>

Just to throw it out there, my current solution is to convert to 
integers, then run the following on the row numbers:

    new.nums <- formatC(new.nums, flag="0",
                         width=max(nchar(new.nums)))

But thanks for the observation, I was scratching my head so hard it 
hurt.

DC
	[[alternative text/enriched version deleted]]

From pgilbert at bank-banque-canada.ca  Tue Feb  8 03:30:20 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue Feb  8 03:32:01 2005
Subject: [Rd] link to an alias in another package
Message-ID: <4208243C.4080605@bank-banque-canada.ca>

In some documentation for a package I am working on I have

 >    \code{\link[stats]{varimax}}
 >    \code{\link[stats]{promax}}

The link to varimax works, but not the one to promax. Promax is an alias 
under \name{varimax}. This kind of link works within a package, but I'm 
not sure if it is suppose to work when it is a link to another package. 
Is this a known limitation or bug, or something I should explore more 
carefully?

Thanks,
Paul

From ripley at stats.ox.ac.uk  Tue Feb  8 08:18:28 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  8 08:18:40 2005
Subject: [Rd] link to an alias in another package
In-Reply-To: <4208243C.4080605@bank-banque-canada.ca>
References: <4208243C.4080605@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.61.0502080710390.14407@gannet.stats>

On Mon, 7 Feb 2005, Paul Gilbert wrote:

> In some documentation for a package I am working on I have
>
>>    \code{\link[stats]{varimax}}
>>    \code{\link[stats]{promax}}
>
> The link to varimax works, but not the one to promax. Promax is an alias 
> under \name{varimax}. This kind of link works within a package, but I'm not 
> sure if it is suppose to work when it is a link to another package. Is this a 
> known limitation or bug, or something I should explore more carefully?

Definitely the latter!  Don't include [stats] (why are you including it?), 
or do read the documentation in R-exts:

   There are optional arguments specified as \link[pkg]{foo} and
   \link[pkg:bar]{foo} to link to the package pkg with topic (file?)
   foo and bar respectively.

so you need \code{\link[stats:varimax]{promax}}. Note the difference 
between `topic' and `alias' here.

You only need the [] to disambiguate crossreferences, or to refer to 
packages that might not yet be installed, which does not apply to [stats].

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Tue Feb  8 11:05:56 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Feb  8 11:04:35 2005
Subject: [Rd] link to an alias in another package
In-Reply-To: <Pine.LNX.4.61.0502080710390.14407@gannet.stats>
References: <4208243C.4080605@bank-banque-canada.ca>
	<Pine.LNX.4.61.0502080710390.14407@gannet.stats>
Message-ID: <aq2h01p3rt6a97s7bq91lc4pdf3v77899q@4ax.com>

On Tue, 8 Feb 2005 07:18:28 +0000 (GMT), Prof Brian Ripley
<ripley@stats.ox.ac.uk> wrote :

>On Mon, 7 Feb 2005, Paul Gilbert wrote:
>
>> In some documentation for a package I am working on I have
>>
>>>    \code{\link[stats]{varimax}}
>>>    \code{\link[stats]{promax}}
>>
>> The link to varimax works, but not the one to promax. Promax is an alias 
>> under \name{varimax}. This kind of link works within a package, but I'm not 
>> sure if it is suppose to work when it is a link to another package. Is this a 
>> known limitation or bug, or something I should explore more carefully?
>
>Definitely the latter!  Don't include [stats] (why are you including it?), 
>or do read the documentation in R-exts:
>
>   There are optional arguments specified as \link[pkg]{foo} and
>   \link[pkg:bar]{foo} to link to the package pkg with topic (file?)
>   foo and bar respectively.
>
>so you need \code{\link[stats:varimax]{promax}}. Note the difference 
>between `topic' and `alias' here.

This is not a bug, but is it a design flaw?  The problem is that Paul
wants to refer to the documentation for promax.  Currently that's in
the varimax topic, but if someone were to split the topics, that
wouldn't be true any more: and then Paul's link would point to the
wrong place.

It is inconsistent that \link{foo} looks for the alias foo, but
\link[pkg]{foo} and \link[pkg:foo]{bar} look for the topic foo.

It is probably impossible to implement links to aliases perfectly
(e.g. if pkg is unavailable at the time the .html file for Paul's
topic is being built, it's not clear what the link should be), but 
doing at least as well as \link{foo} does would take very little work.
The algorithm could be:

 - attempt to look up the alias foo in pkg.  If that succeeds, use the
resulting topic in the link.
 - if pkg exists but the lookup fails, that's an error.
 - if the lookup fails because pkg does not exist, print a warning, 
and create a link as though the alias is a topic.

This would mean \link[stats]{promax} would be fine, and would survive
the addition of a promax topic to another package, or the splitting of
promax out of the varimax topic.

>You only need the [] to disambiguate crossreferences, or to refer to 
>packages that might not yet be installed, which does not apply to [stats].

Duncan Murdoch

From ligges at statistik.uni-dortmund.de  Tue Feb  8 11:47:40 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Tue Feb  8 11:47:48 2005
Subject: [Rd] barplot: space makes beside=F (PR#7668)
Message-ID: <20050208104740.2AC81E1FE@slim.kubism.ku.dk>

o.medek@sh.cvut.cz wrote:

> Full_Name: Ondrej Medek
> Version: 2.0.1
> OS: Linux/Debian Sarge
> Submission from: (NULL) (147.32.127.204)
> 
> 
> Hi,
> I had a R version 1.5.1 and I used a 'barplot' with 'beside=T' and 'space' has
> been vector of 8 numbers 'space=c(1,0.5,rep(c(0.5,-0.5),3))'. Then I upgraded to
> the R 2.0.1 and my graphs are broken. If I use any vector of more than 2
> elements for 'space' then the graph is drawn as 'beside=F' even if I specify
> 'beside=T'. 
> 
> In the previous version my graph was a graph of groups of eight bars separated
> by a big spaces. Every group consisted of 4 pairs of bars separated by a small
> space. It's impossible now.


This is not a bug. See ?barplot which tells us:

    space: [...] If height is a matrix and beside is TRUE,
           space may be specified by two numbers, where the
           first is the space between bars in the same group,
           and the second the space between the groups. [...]

and it works as described:

    barplot(matrix(1:10, 2), beside = TRUE, space = c(1, 7))


Uwe Ligges

From maechler at stat.math.ethz.ch  Tue Feb  8 12:00:52 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue Feb  8 12:01:09 2005
Subject: [Rd] barplot: space makes beside=F (PR#7668)
Message-ID: <20050208110052.15349B266@slim.kubism.ku.dk>

Hi Ondrej,

can you give a very small *REPRODUCIBLE* example
of R code that worked in R 1.5.1 and doesn't work the same in R
2.0.1.

I know that we made some changes for barplot() on purpose,
documented it, announced it in NEWS, etc, etc.
So I'm sure it's not a bug.  

{ I'm also sure that your
    ``It's impossible now ''
  must be wrong. R is a full-fledged programming language, and in
  principle everything is possible :-)
}


>>>>> "Ondrej" == o medek <o.medek@sh.cvut.cz>
>>>>>     on Mon,  7 Feb 2005 21:03:19 +0100 (CET) writes:

    Ondrej> Full_Name: Ondrej Medek
    Ondrej> Version: 2.0.1
    Ondrej> OS: Linux/Debian Sarge
    Ondrej> Submission from: (NULL) (147.32.127.204)


    Ondrej> Hi, I had a R version 1.5.1 and I used a 'barplot'
    Ondrej> with 'beside=T' and 'space' has been vector of 8
    Ondrej> numbers 'space=c(1,0.5,rep(c(0.5,-0.5),3))'. Then I
    Ondrej> upgraded to the R 2.0.1 and my graphs are broken. If
    Ondrej> I use any vector of more than 2 elements for 'space'
    Ondrej> then the graph is drawn as 'beside=F' even if I
    Ondrej> specify 'beside=T'.

    Ondrej> In the previous version my graph was a graph of
    Ondrej> groups of eight bars separated by a big
    Ondrej> spaces. Every group consisted of 4 pairs of bars
    Ondrej> separated by a small space. It's impossible now.

From ripley at stats.ox.ac.uk  Tue Feb  8 13:21:05 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  8 13:21:18 2005
Subject: [Rd] link to an alias in another package
In-Reply-To: <aq2h01p3rt6a97s7bq91lc4pdf3v77899q@4ax.com>
References: <4208243C.4080605@bank-banque-canada.ca>
	<Pine.LNX.4.61.0502080710390.14407@gannet.stats>
	<aq2h01p3rt6a97s7bq91lc4pdf3v77899q@4ax.com>
Message-ID: <Pine.LNX.4.61.0502081201160.25242@gannet.stats>

On Tue, 8 Feb 2005, Duncan Murdoch wrote:

> On Tue, 8 Feb 2005 07:18:28 +0000 (GMT), Prof Brian Ripley
> <ripley@stats.ox.ac.uk> wrote :
>
>> On Mon, 7 Feb 2005, Paul Gilbert wrote:
>>
>>> In some documentation for a package I am working on I have
>>>
>>>>    \code{\link[stats]{varimax}}
>>>>    \code{\link[stats]{promax}}
>>>
>>> The link to varimax works, but not the one to promax. Promax is an alias
>>> under \name{varimax}. This kind of link works within a package, but I'm not
>>> sure if it is suppose to work when it is a link to another package. Is this a
>>> known limitation or bug, or something I should explore more carefully?
>>
>> Definitely the latter!  Don't include [stats] (why are you including it?),
>> or do read the documentation in R-exts:
>>
>>   There are optional arguments specified as \link[pkg]{foo} and
>>   \link[pkg:bar]{foo} to link to the package pkg with topic (file?)
>>   foo and bar respectively.
>>
>> so you need \code{\link[stats:varimax]{promax}}. Note the difference
>> between `topic' and `alias' here.
>
> This is not a bug, but is it a design flaw?  The problem is that Paul
> wants to refer to the documentation for promax.  Currently that's in

Not a design flaw, just a rather more carefully researched design that 
actually works.

Unless the package is present, you have no idea in what file the help for 
promax is, and you need to know to generate hyperlinks (or you don't need 
to use this notation).

Now, hyperlinks to other packages are no real use in current PDF (unless 
you merge PDF files), and HTML help will if java/javascript is enabled 
resolve the references at run time, BUT neither HTML without the search 
engine nor CHTML can do that.

Since two packages can cross-reference each other, you cannot assume that 
the one you want to reference is currently installed without a potential 
deadlock.

> the varimax topic, but if someone were to split the topics, that
> wouldn't be true any more: and then Paul's link would point to the
> wrong place.
>
> It is inconsistent that \link{foo} looks for the alias foo, but
> \link[pkg]{foo} and \link[pkg:foo]{bar} look for the topic foo.

Not in my understanding.  That's the whole (and documented) point of the 
notation, to tell Rdconv where to look when aliases are not 
known/available.

> It is probably impossible to implement links to aliases perfectly
> (e.g. if pkg is unavailable at the time the .html file for Paul's
> topic is being built, it's not clear what the link should be), but

However, that is the only common reason to use this form of link.

> doing at least as well as \link{foo} does would take very little work.
> The algorithm could be:
>
> - attempt to look up the alias foo in pkg.  If that succeeds, use the
> resulting topic in the link.
> - if pkg exists but the lookup fails, that's an error.
> - if the lookup fails because pkg does not exist, print a warning,
> and create a link as though the alias is a topic.

The last is the only time you really need this, and what is done now is 
better than your suggestion.  We set up a mechanism for precisely this 
case, and to break it would be a design flaw.

The only other known circumstance can be seen in links like

\link[stats]{logLik}
\link[stats4:logLik-methods]{logLik},

since two packages have such a topic/alias and they need to refer to each 
other.  That's most likely for S4 methods.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Vidar.Hjellvik at imr.no  Tue Feb  8 14:16:25 2005
From: Vidar.Hjellvik at imr.no (Hjellvik Vidar)
Date: Tue Feb  8 14:16:36 2005
Subject: [Rd] problems with tcltk in R2.0.1
Message-ID: <1612616523F26F48AB55BC8F5D47917C05F2B735@post2.imr.no>

Hello,

I have an tcltk application that runs without problems in R1.9.1, but when I press the "run"-button in R2.0.1, I get the message

"Error in function ()  : can't change value of a locked binding".

I have another tcltk application that runs fine on R2.0.1, so tcltk seems to be properly installed. 

Does anyone have a good idea?

The code is available at ftp.imr.no/vidarh/diva.zip

Best regards,

Vidar Hjellvik
Institute of Marine Research
P.O.Box 1870 Nordnes
N-5817 Bergen
phone: +47 55 23 86 62
email: vidarh@imr.no

From ripley at stats.ox.ac.uk  Tue Feb  8 14:43:15 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  8 14:43:26 2005
Subject: [Rd] R-patched Make Check Fails on reg-tests-1.R on linux and OS X
In-Reply-To: <Pine.GSO.4.51.0502071203120.7373@csm.Berkeley.EDU>
References: <b1b28a05.caf97d67.819db00@ms08.mrf.mail.rcn.net>
	<Pine.GSO.4.51.0502071203120.7373@csm.Berkeley.EDU>
Message-ID: <Pine.LNX.4.61.0502081327150.1123@gannet.stats>

Since no one else has this problem, I suggest you check the integrity of 
your checkout, or, better, use an R-patched tarball that can easily be 
verified.  This looks very like a mismatched build and test: that is your 
R build has not be updated to include the patch which is being tested.
A completely clean build from a tarball will ensure that is not the case.

Reporting problems using unreleased compilers (gcc 3.4.4 is not released) 
isn't going to win you a lot of sympathy: they have been responsible for a 
large number of (mis-directed) problem reports.  If you didn't have the 
problem on two machines I would be suggesting using released versions of 
the tools.

FYI, R is tested on released compilers on i686 Linux several times a day, 
and at least weekly on other common platforms.  We would know soon enough 
if there was an R problem in 'make all check' on those platforms.


On Mon, 7 Feb 2005, Jake Bowers wrote:

> Dear Developers,
>
> I've been playing around with compiling R on my Debian Linux machine (dual
> Athlon 1.4ghz) and my OS X machine (dual G5). I'm emailing now because
> reg-tests-1.R fails during make check on my debian machine using gcc-3.4,
> and on my OS X machine using gcc-3.3. I am using r-patched updated via svn
> today (Updated to revision 33075.)
>
> Here are some details:
>
> **Using gcc-3.4 on debian:
> gcc-3.4 (GCC) 3.4.4 20041218 (prerelease) (Debian 3.4.3-6)
>
> wes:/home/temp/R/r-patched/tests# tail reg-tests-1.Rout.fail
>>
>> ## automatic row.names can be number-like, MM, 2004-11-26
>> d0 <- data.frame(x=1:3, y=pi*2:0)
>> row.names(d0)[3] <- c("01.00")
>> write.table(d0, (tf <- tempfile()))
>> d <- read.table(tf)
>> ## gave error ("duplicate row.names") in 2.0.1
>> stopifnot(all.equal(d,d0))
>> unlink(tf)
>
> **Using gcc-3.3 on debian works fine (passes all make check).
> gcc (GCC) 3.3.5 (Debian 1:3.3.5-5)
>
> **Using gcc-3.3 on OS X.
> gcc (GCC) 3.3 20030304 (Apple Computer, Inc. build 1671)
>
> More info on my OS X build:
> ./configure --with-blas='-framework vecLib' --with-lapack --with-aqua
> --with-x --with-tcl-config=/Library/Frameworks/Tcl.framework/tclConfig.sh
> --with-tk-config=/Library/Frameworks/Tk.framework/tkConfig.sh
> --enable-R-shlib TCLTK_LIBS='-framework Tcl -framework Tk'
> TCLTK_CPPFLAGS='-I/Library/Frameworks/Tcl.Framework/Headers
> -I/Library/Frameworks/Tk.Framework/Headers' --with-recommended
>
> g77 is version 3.4 downloaded from hpc.sf.net.
> GNU Fortran (GCC) 3.4.2
>
> echo $PATH
> /usr/local/bin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/X11R6/bin:/sw/bin:/sw/sbin:/usr/local/pvm3/lib:/usr/local/pvm3/bin/DARWIN
>
> and, to prevent it from using stuff in the fink directory:
>
> CPPFLAGS='-I/usr/local/include'
>
> Here is the output where make check fails:
>
> running regression tests
> running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
> make[2]: *** [test-Reg] Error 2
> make[1]: *** [test-all-basics] Error 1
> make: *** [check-all] Error 2
>
> sphere:~/TEMP/R/r-patched/tests jwbowers$ tail reg-tests-1.Rout.fail
>>
>>
>> ## automatic row.names can be number-like, MM, 2004-11-26
>> d0 <- data.frame(x=1:3, y=pi*2:0)
>> row.names(d0)[3] <- c("01.00")
>> write.table(d0, (tf <- tempfile()))
>> d <- read.table(tf)
>> ## gave error ("duplicate row.names") in 2.0.1
>> stopifnot(all.equal(d,d0))
>> unlink(tf)
>
> Should I be very concerned about this? I tend to mostly use my OS X
> machine since the Linux box is about 4 years old.
>
> I hope this information is helpful --- I'm sorry if this is something
> obvious! (I found some posts from last summer about problems with gcc-3.4,
> which might explain the problems with gcc-3.4 on linux, but I didn't find
> anything obvious about gcc-3.3 on the Mac).
>
> Thanks so much for all of your work!!
>
> Best,
>
> Jake
>
> Jake Bowers
> Assistant Professor
> Dept of Political Science
> University of Michigan
> http://www.umich.edu/~jwbowers
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Tue Feb  8 15:09:42 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Feb  8 15:09:54 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <1abe3fa9050208043374d362df@mail.gmail.com>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
Message-ID: <16904.51238.148743.149665@stat.math.ethz.ch>

>>>>> "tony" == A J Rossini <blindglobe@gmail.com>
>>>>>     on Tue, 8 Feb 2005 13:33:23 +0100 writes:

    tony> For OBVIOUS reasons, is there any chance that we could introduce
    tony> "package()" and deprecate "library()"?

This idea is not new {as you must surely have guessed}. In fact,
there's a much longer standing proposition of  "usePackage()"
(IIRC, or "use.package()" ?).  However, we (R-core) always had
wanted to also provide a ``proper'' class named "package" 
along with this, but for several reasons didn't get around to it.. yet.

-- I've diverted to R-devel now that we are really talking about
   desired future behavior of R

    tony> (well, I'll also ask if we could deprecate "=" for assignment, but
    tony> that's hopeless).
:-)


    tony> On Tue, 8 Feb 2005 11:49:39 +0100, Martin Maechler
    tony> <maechler@stat.math.ethz.ch> wrote:
    >> >>>>> "Pavel" == Pavel Khomski <pkhomski@wiwi.uni-bielefeld.de>
    >> >>>>>     on Tue, 08 Feb 2005 10:20:03 +0100 writes:
    >> 
    Pavel> this is a question, how can i specify the random part
    Pavel> in the GLMM-call (of the lme4 library) for compound
    Pavel> matrices just in the the same way as they defined in
    Pavel> the lme-Call (of the nlme library).
    >> 
    >> ``twice in such a short paragraph -- yikes !!'' ... I'm getting
    >> convulsive...
    >> 
    >> There is NO lme4 library nor an nlme one !
    >> There's the lme4 *PACKAGE* and the nlme *PACKAGE* -- please --
    >> 
    >> ....................

From murdoch at stats.uwo.ca  Tue Feb  8 15:17:15 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Feb  8 15:15:54 2005
Subject: [Rd] link to an alias in another package
In-Reply-To: <Pine.LNX.4.61.0502081201160.25242@gannet.stats>
References: <4208243C.4080605@bank-banque-canada.ca>
	<Pine.LNX.4.61.0502080710390.14407@gannet.stats>
	<aq2h01p3rt6a97s7bq91lc4pdf3v77899q@4ax.com>
	<Pine.LNX.4.61.0502081201160.25242@gannet.stats>
Message-ID: <6leh011oqeb2s4k8db75f2m8pfnp51l8sn@4ax.com>

On Tue, 8 Feb 2005 12:21:05 +0000 (GMT), Prof Brian Ripley
<ripley@stats.ox.ac.uk> wrote :

>On Tue, 8 Feb 2005, Duncan Murdoch wrote:
>
>> On Tue, 8 Feb 2005 07:18:28 +0000 (GMT), Prof Brian Ripley
>> <ripley@stats.ox.ac.uk> wrote :
>>
>>> On Mon, 7 Feb 2005, Paul Gilbert wrote:
>>>
>>>> In some documentation for a package I am working on I have
>>>>
>>>>>    \code{\link[stats]{varimax}}
>>>>>    \code{\link[stats]{promax}}
>>>>
>>>> The link to varimax works, but not the one to promax. Promax is an alias
>>>> under \name{varimax}. This kind of link works within a package, but I'm not
>>>> sure if it is suppose to work when it is a link to another package. Is this a
>>>> known limitation or bug, or something I should explore more carefully?
>>>
>>> Definitely the latter!  Don't include [stats] (why are you including it?),
>>> or do read the documentation in R-exts:
>>>
>>>   There are optional arguments specified as \link[pkg]{foo} and
>>>   \link[pkg:bar]{foo} to link to the package pkg with topic (file?)
>>>   foo and bar respectively.
>>>
>>> so you need \code{\link[stats:varimax]{promax}}. Note the difference
>>> between `topic' and `alias' here.
>>
>> This is not a bug, but is it a design flaw?  The problem is that Paul
>> wants to refer to the documentation for promax.  Currently that's in
>
>Not a design flaw, just a rather more carefully researched design that 
>actually works.
>
>Unless the package is present, you have no idea in what file the help for 
>promax is, and you need to know to generate hyperlinks (or you don't need 
>to use this notation).
>
>Now, hyperlinks to other packages are no real use in current PDF (unless 
>you merge PDF files), and HTML help will if java/javascript is enabled 
>resolve the references at run time, BUT neither HTML without the search 
>engine nor CHTML can do that.
>
>Since two packages can cross-reference each other, you cannot assume that 
>the one you want to reference is currently installed without a potential 
>deadlock.
>
>> the varimax topic, but if someone were to split the topics, that
>> wouldn't be true any more: and then Paul's link would point to the
>> wrong place.
>>
>> It is inconsistent that \link{foo} looks for the alias foo, but
>> \link[pkg]{foo} and \link[pkg:foo]{bar} look for the topic foo.
>
>Not in my understanding.  That's the whole (and documented) point of the 
>notation, to tell Rdconv where to look when aliases are not 
>known/available.
>
>> It is probably impossible to implement links to aliases perfectly
>> (e.g. if pkg is unavailable at the time the .html file for Paul's
>> topic is being built, it's not clear what the link should be), but
>
>However, that is the only common reason to use this form of link.
>
>> doing at least as well as \link{foo} does would take very little work.
>> The algorithm could be:
>>
>> - attempt to look up the alias foo in pkg.  If that succeeds, use the
>> resulting topic in the link.
>> - if pkg exists but the lookup fails, that's an error.
>> - if the lookup fails because pkg does not exist, print a warning,
>> and create a link as though the alias is a topic.
>
>The last is the only time you really need this, and what is done now is 
>better than your suggestion.  We set up a mechanism for precisely this 
>case, and to break it would be a design flaw.

I only see two differences between the current scheme and the last
case:
  - now no warning is printed, which does seem reasonable, given that
there exist mutual cross-references.  
  - my scheme would require that a topic name be repeated as an alias
if both the first and last type of lookups were possible.
Alternatively, we could allow lookups by topic name as well as alias
for back-compatibility.

Other than these, I don't see how the current scheme is better.  In
the current system:

 - If I use an unadorned \link{promax}, I run the risk of having it go
to the wrong place if someone defines a promax alias in some other
package that is installed before mine.

 - If I use \link[stats:varimax]{promax}, then I run the risk of
having it go to the wrong place if someone splits promax.Rd out of
varimax.Rd in the stats package.

 - If I have a spelling error in the link (e.g.
\link[stats:varmax]{promax}), then neither INSTALL nor CHECK will tell
me about it.

None of these would be a problem if I used \link[stats]{promax} under
my proposal, unless my package were being installed before stats was,
in which case the link would fail.  

But if that's a possibility (e.g. we're talking about a core package,
or a package with mutual dependencies with the referenced one so that
we can't be sure which will be installed first), then we could simply
document that references to aliases might fail.  Two packages with
mutual dependencies are presumably being maintained together, so the
second problem above wouldn't be an issue.

Have I missed some advantages of the current scheme over the one I
proposed?  There's the obvious one of the fact that it exists, whereas
mine will take a bit of work to do, but if I don't hear of some fatal
flaw, I'll volunteer to do the work.  I don't think it will be hard.

Duncan Murdoch

From stefano.iacus at unimi.it  Tue Feb  8 15:28:36 2005
From: stefano.iacus at unimi.it (stefano iacus)
Date: Tue Feb  8 15:28:51 2005
Subject: [Rd] R-patched Make Check Fails on reg-tests-1.R on linux and OS X
In-Reply-To: <Pine.LNX.4.61.0502081327150.1123@gannet.stats>
References: <b1b28a05.caf97d67.819db00@ms08.mrf.mail.rcn.net>
	<Pine.GSO.4.51.0502071203120.7373@csm.Berkeley.EDU>
	<Pine.LNX.4.61.0502081327150.1123@gannet.stats>
Message-ID: <5a5d03c07a70addbd04abd4f7241054f@unimi.it>

Hi Jake,

with this config

hal:~ jago$ gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.3/specs
Thread model: posix
gcc version 3.3 20030304 (Apple Computer, Inc. build 1671)
hal:~ jago$ g77 -v
Reading specs from  
/usr/local/lib/gcc/powerpc-apple-darwin6.8/3.4.2/specs
Configured with: ../gcc/configure --enable-threads=posix  
--enable-languages=f77 --disable-shared --enable-static
Thread model: posix
gcc version 3.4.2


btw, in  configure you don't need to use --with-x, --enable-R-shlib and  
--with-recommended

You did not report the OS X version which might be the source of the  
problem.
Please also get the latest g77 from http://hpc.sourceforge.net/

The above setup works fine on OS X 10.2 and 10.3.

stefano

>> ./configure --with-blas='-framework vecLib' --with-lapack --with-aqua
>> --with-x  
>> --with-tcl-config=/Library/Frameworks/Tcl.framework/tclConfig.sh
>> --with-tk-config=/Library/Frameworks/Tk.framework/tkConfig.sh
>> --enable-R-shlib TCLTK_LIBS='-framework Tcl -framework Tk'
>> TCLTK_CPPFLAGS='-I/Library/Frameworks/Tcl.Framework/Headers
>> -I/Library/Frameworks/Tk.Framework/Headers' --with-recommended


On Feb 8, 2005, at 2:43 PM, Prof Brian Ripley wrote:

> Since no one else has this problem, I suggest you check the integrity  
> of your checkout, or, better, use an R-patched tarball that can easily  
> be verified.  This looks very like a mismatched build and test: that  
> is your R build has not be updated to include the patch which is being  
> tested.
> A completely clean build from a tarball will ensure that is not the  
> case.
>
> Reporting problems using unreleased compilers (gcc 3.4.4 is not  
> released) isn't going to win you a lot of sympathy: they have been  
> responsible for a large number of (mis-directed) problem reports.  If  
> you didn't have the problem on two machines I would be suggesting  
> using released versions of the tools.
>
> FYI, R is tested on released compilers on i686 Linux several times a  
> day, and at least weekly on other common platforms.  We would know  
> soon enough if there was an R problem in 'make all check' on those  
> platforms.
>
>
> On Mon, 7 Feb 2005, Jake Bowers wrote:
>
>> Dear Developers,
>>
>> I've been playing around with compiling R on my Debian Linux machine  
>> (dual
>> Athlon 1.4ghz) and my OS X machine (dual G5). I'm emailing now because
>> reg-tests-1.R fails during make check on my debian machine using  
>> gcc-3.4,
>> and on my OS X machine using gcc-3.3. I am using r-patched updated  
>> via svn
>> today (Updated to revision 33075.)
>>
>> Here are some details:
>>
>> **Using gcc-3.4 on debian:
>> gcc-3.4 (GCC) 3.4.4 20041218 (prerelease) (Debian 3.4.3-6)
>>
>> wes:/home/temp/R/r-patched/tests# tail reg-tests-1.Rout.fail
>>>
>>> ## automatic row.names can be number-like, MM, 2004-11-26
>>> d0 <- data.frame(x=1:3, y=pi*2:0)
>>> row.names(d0)[3] <- c("01.00")
>>> write.table(d0, (tf <- tempfile()))
>>> d <- read.table(tf)
>>> ## gave error ("duplicate row.names") in 2.0.1
>>> stopifnot(all.equal(d,d0))
>>> unlink(tf)
>>
>> **Using gcc-3.3 on debian works fine (passes all make check).
>> gcc (GCC) 3.3.5 (Debian 1:3.3.5-5)
>>
>> **Using gcc-3.3 on OS X.
>> gcc (GCC) 3.3 20030304 (Apple Computer, Inc. build 1671)
>>
>> More info on my OS X build:
>> ./configure --with-blas='-framework vecLib' --with-lapack --with-aqua
>> --with-x  
>> --with-tcl-config=/Library/Frameworks/Tcl.framework/tclConfig.sh
>> --with-tk-config=/Library/Frameworks/Tk.framework/tkConfig.sh
>> --enable-R-shlib TCLTK_LIBS='-framework Tcl -framework Tk'
>> TCLTK_CPPFLAGS='-I/Library/Frameworks/Tcl.Framework/Headers
>> -I/Library/Frameworks/Tk.Framework/Headers' --with-recommended
>>
>> g77 is version 3.4 downloaded from hpc.sf.net.
>> GNU Fortran (GCC) 3.4.2
>>
>> echo $PATH
>> /usr/local/bin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/X11R6/bin:/sw/bin:/ 
>> sw/sbin:/usr/local/pvm3/lib:/usr/local/pvm3/bin/DARWIN
>>
>> and, to prevent it from using stuff in the fink directory:
>>
>> CPPFLAGS='-I/usr/local/include'
>>
>> Here is the output where make check fails:
>>
>> running regression tests
>> running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout]  
>> Error 1
>> make[2]: *** [test-Reg] Error 2
>> make[1]: *** [test-all-basics] Error 1
>> make: *** [check-all] Error 2
>>
>> sphere:~/TEMP/R/r-patched/tests jwbowers$ tail reg-tests-1.Rout.fail
>>>
>>>
>>> ## automatic row.names can be number-like, MM, 2004-11-26
>>> d0 <- data.frame(x=1:3, y=pi*2:0)
>>> row.names(d0)[3] <- c("01.00")
>>> write.table(d0, (tf <- tempfile()))
>>> d <- read.table(tf)
>>> ## gave error ("duplicate row.names") in 2.0.1
>>> stopifnot(all.equal(d,d0))
>>> unlink(tf)
>>
>> Should I be very concerned about this? I tend to mostly use my OS X
>> machine since the Linux box is about 4 years old.
>>
>> I hope this information is helpful --- I'm sorry if this is something
>> obvious! (I found some posts from last summer about problems with  
>> gcc-3.4,
>> which might explain the problems with gcc-3.4 on linux, but I didn't  
>> find
>> anything obvious about gcc-3.3 on the Mac).
>>
>> Thanks so much for all of your work!!
>>
>> Best,
>>
>> Jake
>>
>> Jake Bowers
>> Assistant Professor
>> Dept of Political Science
>> University of Michigan
>> http://www.umich.edu/~jwbowers
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From jmacdon at med.umich.edu  Tue Feb  8 17:29:08 2005
From: jmacdon at med.umich.edu (James MacDonald)
Date: Tue Feb  8 17:29:28 2005
Subject: [Rd] Pre-building lazyload DB
Message-ID: <s208a28f.010@med-gwia-02a.med.umich.edu>

Hi all,

Bioconductor has several metaData packages that contain quite large
data sets. In the past, these data were simply held in the /data
directory of the package as .rda files and load()ed as needed.
Converting to using lazy data loading may have memory and performance
advantages, but for the larger metaData packages the installation is
painfully slow (it has taken > 30 min to install a large metaData
package on a PIII, 933 MHz box running Mandrake 9.2). The vast majority
of the time is spent moving datasets to lazyload DB.

It takes a long time to build the win32 packages as well, but once the
package is built, the installation is quick, so there is no real problem
for our end users. So my question is this; is there a mechanism that can
be used to pre-build the lazyload DB for source packages to decrease the
installation time for our end users?

Best,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.

From blindglobe at gmail.com  Tue Feb  8 17:48:56 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Tue Feb  8 17:49:07 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <16904.51238.148743.149665@stat.math.ethz.ch>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
Message-ID: <1abe3fa905020808481647d78d@mail.gmail.com>

But I don't see a problem with "package("package")", though I'm sure
I'm missing something.

It really would end this constant confusion and save various folks
approx 15 minutes/week in knee-jerk responses, eh?

best,
-tony


On Tue, 8 Feb 2005 15:09:42 +0100, Martin Maechler
<maechler@stat.math.ethz.ch> wrote:
> >>>>> "tony" == A J Rossini <blindglobe@gmail.com>
> >>>>>     on Tue, 8 Feb 2005 13:33:23 +0100 writes:
> 
>    tony> For OBVIOUS reasons, is there any chance that we could introduce
>    tony> "package()" and deprecate "library()"?
> 
> This idea is not new {as you must surely have guessed}. In fact,
> there's a much longer standing proposition of  "usePackage()"
> (IIRC, or "use.package()" ?).  However, we (R-core) always had
> wanted to also provide a ``proper'' class named "package"
> along with this, but for several reasons didn't get around to it.. yet.
> 
> -- I've diverted to R-devel now that we are really talking about
>   desired future behavior of R
> 
>    tony> (well, I'll also ask if we could deprecate "=" for assignment, but
>    tony> that's hopeless).
> :-)
> 
>    tony> On Tue, 8 Feb 2005 11:49:39 +0100, Martin Maechler
>    tony> <maechler@stat.math.ethz.ch> wrote:
>    >> >>>>> "Pavel" == Pavel Khomski <pkhomski@wiwi.uni-bielefeld.de>
>    >> >>>>>     on Tue, 08 Feb 2005 10:20:03 +0100 writes:
>    >>
>    Pavel> this is a question, how can i specify the random part
>    Pavel> in the GLMM-call (of the lme4 library) for compound
>    Pavel> matrices just in the the same way as they defined in
>    Pavel> the lme-Call (of the nlme library).
>    >>
>    >> ``twice in such a short paragraph -- yikes !!'' ... I'm getting
>    >> convulsive...
>    >>
>    >> There is NO lme4 library nor an nlme one !
>    >> There's the lme4 *PACKAGE* and the nlme *PACKAGE* -- please --
>    >>
>    >> ....................
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From ripley at stats.ox.ac.uk  Tue Feb  8 17:53:59 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  8 17:54:10 2005
Subject: [Rd] Pre-building lazyload DB
In-Reply-To: <s208a28f.010@med-gwia-02a.med.umich.edu>
References: <s208a28f.010@med-gwia-02a.med.umich.edu>
Message-ID: <Pine.LNX.4.61.0502081640120.14016@gannet.stats>

What is the benefit of lazyload DB in this circumstance?  I don't see it
if your .rda files have one data object each and are compressed.

Do you have a `data/filelist' index in your packages, as suggested by 
200update.txt and `Writing R Extensions'?  The slow examples I have seen 
did not and so were wasting a lot of time preparing indices that could 
have been supplied.

The design expectation was that large data packages would supply an index 
and not use lazyloading for datasets but use separate compressed dumps for 
each object.  If there is some reason to change that, please send an RFC 
for the requirements and a design.

Did this not occur during the alpha/beta period for 2.0.0 several months 
ago or has something in BioC changed since?  (I did ascertain that if 
filelist was supplied the then BioC packages installed and loaded quickly 
and smoothly.)

On Tue, 8 Feb 2005, James MacDonald wrote:

> Hi all,
>
> Bioconductor has several metaData packages that contain quite large
> data sets. In the past, these data were simply held in the /data
> directory of the package as .rda files and load()ed as needed.
> Converting to using lazy data loading may have memory and performance
> advantages, but for the larger metaData packages the installation is
> painfully slow (it has taken > 30 min to install a large metaData
> package on a PIII, 933 MHz box running Mandrake 9.2). The vast majority
> of the time is spent moving datasets to lazyload DB.
>
> It takes a long time to build the win32 packages as well, but once the
> package is built, the installation is quick, so there is no real problem
> for our end users. So my question is this; is there a mechanism that can
> be used to pre-build the lazyload DB for source packages to decrease the
> installation time for our end users?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Kurt.Hornik at wu-wien.ac.at  Tue Feb  8 18:37:18 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Tue Feb  8 18:37:34 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <1abe3fa905020808481647d78d@mail.gmail.com>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
Message-ID: <16904.63694.9500.496681@mithrandir.hornik.net>

>>>>> A J Rossini writes:

> But I don't see a problem with "package("package")", though I'm sure
> I'm missing something.

package() [sic] might be the creator for package objects, provided we
can decide on what they are (and what kind of packages [source,
installed, ...] they are used for).

usePackage() or use_package() otoh would indicate to "use" a package
(i.e., load and attach it).  The tricky part is deciding about the
interface (e.g., finally disallowing non-standard evaluation as it is a
programmer's nightmare) and what it should return.  And that is work in
progress ...

Even if we don't like the current semantics, the *name* of library() in
itself should not be a problem.  After all, calling summary() does not
imply that your primary argument is a summary, so why should calling
library() imply that its primary argument is a "library"?

> It really would end this constant confusion and save various folks
> approx 15 minutes/week in knee-jerk responses, eh?

Afaic, one of the issues is that it seems common practice to refer to
collections of code as "libraries" or "packages", and we're trying to
use these rather general-purpose terms in a very precise meaning, and
obviously not very successful, in particular because the use of
"library" is highly non-standard.  One idea might be to replace the
"library" by something else like ... "a place where R knows where to
find packages" ... hmm, now that's too long, so ...

-k

From ripley at stats.ox.ac.uk  Tue Feb  8 19:10:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb  8 19:11:04 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <1abe3fa905020808481647d78d@mail.gmail.com>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0502081756350.14970@gannet.stats>

On Tue, 8 Feb 2005, A.J. Rossini wrote:

> But I don't see a problem with "package("package")", though I'm sure
> I'm missing something.

Grammar.  It's like `R CMD build' which some people think installs: here 
you don't want `to package' you want `to use', and these are read as 
imperatives.

I think we are all agreed that some variant on usePackage() would be good, 
but here the perfect is the enemy of the good and the good the enemy of 
the adequate.

Let's see if someone cares enough to push a design through for 2.1.0.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Tue Feb  8 20:07:34 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Feb  8 20:06:08 2005
Subject: [Rd] Environment with no parent?
Message-ID: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>

Is it possible to create an environment that has no parent (or an
empty parent)?  I would have thought

 e <- new.env(parent=NULL)

would work, but it acts as though the parent is the base namespace:

> get("close", envir = e)
function (con, ...) 
UseMethod("close")
<environment: namespace:base>

I can use inherits = FALSE in this case:

> get("close", envir = e, inherits = F)
Error in get(x, envir, mode, inherits) : variable "close" was not
found

but what I want to do is to create my own hierarchy of environments
that allow inheritance from their parents, but which stop when they
get to e, and don't continue on into base.  For example

> assign('x', 1, envir = e)
> 
> f <- new.env(parent = e)
> assign('y', 2, envir = f)
> 
>#  The first two of these work as desired, but I'd like a "not found" error from the last:
>
> get('y', envir=f)
[1] 2
> get('x', envir=f)
[1] 1
> get('close', envir=f)
function (con, ...) 
UseMethod("close")
<environment: namespace:base>

Looking in envir.c, I see this:

    /* env is now R_NilValue, the base environment */

which doesn't give me much hope, but maybe there's a trick....

If not, would it be reasonable to install a magic "EmptyEnv" to use as
a parent in this sort of situation?

Duncan Murdoch

From jmacdon at med.umich.edu  Tue Feb  8 20:25:49 2005
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Tue Feb  8 20:26:09 2005
Subject: [Rd] Pre-building lazyload DB (fwd)
In-Reply-To: <Pine.SOL.4.20.0502081309570.24972-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0502081309570.24972-100000@santiam.dfci.harvard.edu>
Message-ID: <4209123D.8090809@med.umich.edu>

> What is the benefit of lazyload DB in this circumstance?  I don't see it
> if your .rda files have one data object each and are compressed.

The paradigm we have been following is to have all the environments 
saved in individual .rda files, so after loading the package they can be 
accessed with e.g., ls(), get(), mget() automatically without explicitly 
having to load() each environment into the current workspace. However, 
if we build the win32 packages using R CMD INSTALL --build (which AFAIK 
is the recommended method), the .rda files all get packaged up in an 
Rdata.zip file, so they won't be found in the search path unless they 
are loaded into the workspace using data().

If the design expectation was to have separate compressed dumps for each 
object, does this imply that our metaData packages should be built using 
R CMD build --binary, whereas the rest of the packages should be built 
using R CMD INSTALL --build?

> 
> Do you have a `data/filelist' index in your packages, as suggested by 
> 200update.txt and `Writing R Extensions'?  The slow examples I have seen 
> did not and so were wasting a lot of time preparing indices that could 
> have been supplied.
> 
> The design expectation was that large data packages would supply an index 
> and not use lazyloading for datasets but use separate compressed dumps for 
> each object.  If there is some reason to change that, please send an RFC 
> for the requirements and a design.
> 
> Did this not occur during the alpha/beta period for 2.0.0 several months 
> ago or has something in BioC changed since?  (I did ascertain that if 
> filelist was supplied the then BioC packages installed and loaded quickly 
> and smoothly.)
> 
> On Tue, 8 Feb 2005, James MacDonald wrote:
> 
> 
>>Hi all,
>>
>>Bioconductor has several metaData packages that contain quite large
>>data sets. In the past, these data were simply held in the /data
>>directory of the package as .rda files and load()ed as needed.
>>Converting to using lazy data loading may have memory and performance
>>advantages, but for the larger metaData packages the installation is
>>painfully slow (it has taken > 30 min to install a large metaData
>>package on a PIII, 933 MHz box running Mandrake 9.2). The vast majority
>>of the time is spent moving datasets to lazyload DB.
>>
>>It takes a long time to build the win32 packages as well, but once the
>>package is built, the installation is quick, so there is no real problem
>>for our end users. So my question is this; is there a mechanism that can
>>be used to pre-build the lazyload DB for source packages to decrease the
>>installation time for our end users?
> 
> 


-- 
James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109

From Robert.McGehee at geodecapital.com  Tue Feb  8 21:32:13 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Tue Feb  8 21:32:28 2005
Subject: [Rd] RE: [R] Windows Printing and Line Widths
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C1ED585@MSGBOSCLB2WIN.DMN1.FMR.COM>

... Moved from R-help ...

Thank you for your suggestion, Professor Ripley. Postscript does seem
like the way to go for printing line widths correctly in Windows.

On Linux I am using a simple dev.print() wrapper (as suggested), with a
pipe to lpr.

However, I had an extremely difficult time getting postscript printing
under windows. 
?postscript recommends the RedMon suite of tools for printing PS files
to printers. I had no trouble installing and using this utility from my
shell, but under R, I observed this odd behavior:

options(printcmd='redpr')
plot(1:10)
dev.print(file = "Rplots.ps", print.it = TRUE)
dev.off()
## Nothing happens!!
q()
## Now it prints

That is, the file only prints when the R session is closed, and not when
the device is closed (contrary to the documentation). After some head
banging, I changed the printcmd options to lpr (the one that comes with
Windows XP), and the PS file printed out correctly after the dev.off()
command. If other people observe this behavior with Windows / RedMon,
then perhaps Windows lpr is the better tool.

Either way, I'm happy to now have beautiful Windows plots again on both
my R screen and R printer.

Thanks,
Robert


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk] 
Sent: Tuesday, February 08, 2005 12:10 PM
To: McGehee, Robert
Cc: r-help@stat.math.ethz.ch
Subject: Re: [R] Windows Printing and Line Widths


Those printers AFAIK support postscript.

How are you printing to them on Linux?  I suggest you use dev.print
under 
Windows (it needs some setup, see ?postscript).  That makes more sense 
than going via PDF as the support is all already in R and it is AFAIK
the 
printer's native mode.

We've seen far too many problems with HP Windows printer drivers on 8000

and 4000 series printers.


On Tue, 8 Feb 2005, McGehee, Robert wrote:

> Hi all,
> I develop and print from both Windows and Linux, and am seeing some
> printing inconsistencies first described about a year and a half ago
by
> Andy Liaw (see below). Specifically, the line widths on my windows
plots
> are about 5 times smaller than that on Linux, and my windows printouts
> do not match what my screen looks like. However, if I print to a pdf
> file first, then I can get accurate Windows reproduction of my screen.
I
> was thinking of writing a windows.print() wrapper that creates a
> temporary pdf file and then prints that. However, I wanted to see if a
> better solution now exists to get identical printouts on both Linux
and
> Windows (since Andy's original post), or any comments on what printers
> this does or does not affect.
>
> Thanks,
> Robert
>
> HP Laserjet 8150DN
> HP Color Laserjet 4600DN
> HP Laserjet 4050TN
>
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>
> ---------------------------------
> From: Prof Brian Ripley
> Date: Mon Jun 23 2003 - 23:59:29 EDT
>
>
> What printer driver are you using?
>
>
> I've just tried this and it works exactly as one would expect on my HP
> 970CXi, as well as cut-and-paste into other applications. It also
worked
>
> printing to Acrobat Distiller (although all the lines were thinner
there
>
> than on-screen and on the 970CXi, the ratio was still 1:5).
>
>
> We've been here before, and had to abandon some optimizations because
of
> a
> bug in interpreting Windows metafiles in Word.
>
>
> On Mon, 23 Jun 2003, Sundar Dorai-Raj wrote:
>
>
>> Andy,
>> I've experienced the same thing. What's interesting is that printing
>> a plot (CTRL-P) with lwd = 25 makes lines on the hardcopy look like
> lwd
>> = 5. I'm using R1.7.1 on Win2000Pro.
>>
>> Regards,
>> Sundar
>>
>> Liaw, Andy wrote:
>>> Dear R-help,
>>>
>>> Has anyone notice the problem that, on Windows (NT and XP), when
> printing a
>>> graph using the "File -> Print..." menu in the graphics window to
> print the
>>> graph, that line width seemed to be ignored in the printed output?
> For
>>> example, if I make a plot with plot(1:10, type="l", lwd=5), it looks
> right
>>> on screen, but when printed out using the menu, it looks like the
> plot was
>>> made with lwd=1. I've had this problem for quite a while (at least
> since
>>> 1.3.x) and still present in 1.7.1. Has anyone else seen this, or
> just me?
>>>
>>> Best,
>>> Andy
>>>
>>> Andy Liaw, PhD
>>> Biometrics Research PO Box 2000, RY33-300
>>> Merck Research Labs Rahway, NJ 07065
>>> mailto:andy_liaw@merck.com <mailto:andy_liaw@merck.com> 732-594-0820
>
>>>
>>>
>>>
>>>
>
------------------------------------------------------------------------
> ------
>>> Notice: This e-mail message, together with any attachments, cont...
> {{dropped}}
>>>
>>> ______________________________________________
>>> R-help@stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>>
>> ______________________________________________
>> R-help@stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> <http://www.stats.ox.ac.uk/%7Eripley/>
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
>
>
>
> This e-mail, and any attachments hereto, are intended for
us...{{dropped}}
>
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From apjaworski at mmm.com  Tue Feb  8 21:47:03 2005
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue Feb  8 21:47:17 2005
Subject: [Rd] Crash when R-devel is started from a shortcut
Message-ID: <OFF9F5FDEC.17FE37EC-ON86256FA2.007012AB-86256FA2.00722C22@mmm.com>





Hi,

I am in a habit of frequently building R-devel daily snapshots.  I use
Win2000 Pro system with all the necessary tools installed and the builds
usually go without a problem.  I also build R-patched snapshots, so my
"production" R is up-to-date.  Hence, I have two parallel installations of
R: R-devel and R-patched.  In Windows environmental variables I set R_HOME
to my R-patched path.  I have shortcuts to both versions of R on my
desktop.

Starting from February 7 build, I noticed the following problem.  The build
itself and the installation (I build the *.exe installer)  run with no
errors but, when I try to start R-devel from a shortcut, I get "The
instruction at 0x77fcc128 referenced memory at 0x00230010.  The memory
could not be read." error.  The same happens when I just go in the Windows
Explorer to the bin directory and double-click on the Rgui.exe icon.  When
I double-click on the Rterm.exe icon, it starts fine in its own terminal
window.

When I open a cygwin terminal window, change the directory to
.../R-devel/bin and type Rgui.exe from there, it starts with no problem, so
I guess something either this is a Windows problem or something else
interferes with the proper path.

Any help will be appreciated.

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski@mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122

From p.dalgaard at biostat.ku.dk  Tue Feb  8 21:49:47 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Feb  8 21:54:17 2005
Subject: [Rd] Environment with no parent?
In-Reply-To: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>
References: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>
Message-ID: <x24qgmojys.fsf@biostat.ku.dk>

Duncan Murdoch <murdoch@stats.uwo.ca> writes:

> Looking in envir.c, I see this:
> 
>     /* env is now R_NilValue, the base environment */
> 
> which doesn't give me much hope, but maybe there's a trick....
> 
> If not, would it be reasonable to install a magic "EmptyEnv" to use as
> a parent in this sort of situation?
> 

I'm fairly sure the answer is "nope".

It's been annoying me for years, for language aesthetic reasons
mostly, but also with some consideration of cases like yours, and I've
been on the brink of implementing a version where the base environment
was a true environment. Apart from the usual issue of "round tuits",
I was held back by the fact that one has to consider at least two things:

(a) efficiency. Is it expensive no longer to have the base functions
bound directly to their symbol? (My gut feeling is that with suitable
hashing and cacheing, the penalty is minimal.)

(b) you can *only* use get and simple variable retrieval in a non-base
environment with a NULL parent (eval(x <- 1, envir=foo) would give
'couldn't find function "<-"' or so). This could cause some confusion.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From rgentlem at fhcrc.org  Tue Feb  8 23:04:41 2005
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Tue Feb  8 23:05:02 2005
Subject: [Rd] Environment with no parent?
In-Reply-To: <x24qgmojys.fsf@biostat.ku.dk>
References: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>
	<x24qgmojys.fsf@biostat.ku.dk>
Message-ID: <6EA8BCBF-7A1D-11D9-8C28-000D933DC9FE@fhcrc.org>


On Feb 8, 2005, at 12:49 PM, Peter Dalgaard wrote:

> Duncan Murdoch <murdoch@stats.uwo.ca> writes:
>
>> Looking in envir.c, I see this:
>>
>>     /* env is now R_NilValue, the base environment */
>>
>> which doesn't give me much hope, but maybe there's a trick....
>>
>> If not, would it be reasonable to install a magic "EmptyEnv" to use as
>> a parent in this sort of situation?
>>
>
> I'm fairly sure the answer is "nope".
>
> It's been annoying me for years, for language aesthetic reasons
> mostly, but also with some consideration of cases like yours, and I've
> been on the brink of implementing a version where the base environment
> was a true environment. Apart from the usual issue of "round tuits",
> I was held back by the fact that one has to consider at least two  
> things:
>
> (a) efficiency. Is it expensive no longer to have the base functions
> bound directly to their symbol? (My gut feeling is that with suitable
> hashing and cacheing, the penalty is minimal.)
>
> (b) you can *only* use get and simple variable retrieval in a non-base
> environment with a NULL parent (eval(x <- 1, envir=foo) would give
> 'couldn't find function "<-"' or so). This could cause some confusion.


   And, I think, that a better approach is to implement a proper hash  
table class
and to then implement environments as hash table + parent (rather than  
the
current version, which would be environment  - parent), but the tuit  
shortage is devastating on this side of the atlantic (possibly due to  
the disadvantageous $/euro exchange rate; I'm sure you all can afford  
more of them :-))

  Robert


>
>
> --  
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
+----------------------------------------------------------------------- 
----------------+
| Robert Gentleman              phone: (206) 667-7700                    
          |
| Head, Program in Computational Biology   fax:  (206) 667-1319   |
| Division of Public Health Sciences       office: M2-B865               
       |
| Fred Hutchinson Cancer Research Center                                 
          |
| email: rgentlem@fhcrc.org                                              
                          |
+----------------------------------------------------------------------- 
----------------+

From Ted.Harding at nessie.mcc.ac.uk  Tue Feb  8 23:19:46 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Feb  8 23:28:40 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <16904.63694.9500.496681@mithrandir.hornik.net>
Message-ID: <XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>

On 08-Feb-05 Kurt Hornik wrote:
> Afaic, one of the issues is that it seems common practice to refer to
> collections of code as "libraries" or "packages", and we're trying to
> use these rather general-purpose terms in a very precise meaning, and
> obviously not very successful, in particular because the use of
> "library" is highly non-standard.  One idea might be to replace the
> "library" by something else like ... "a place where R knows where to
> find packages" ... hmm, now that's too long, so ...

The only issue I have with "library" vs "package" (or vice versa)
is the following.

I *know* that a collection of functions etc. (such as nlme) is
properly called a "package". I could (and do) get ticked off if
I refer to it as a "library".

However, if I want to use it then I enter

  library(nlme)

As a result, the little daemons who potter around re-wiring
my mental circuits sometimes cross-connect these two. As a
result, I can inadvertently refer to "the nlme library".

An example is a recent mailing of mine to the list where
I twice referred to a certain "library" (and was amiably
rebuked by Martic Maechler) -- but then I saw that I had
also twice referred to the same "package" in the same mail!

Personally I don't mind whether it is called "package" or
"library", though using the command library() to load a
package does tend, as described, to get me treading on my
own shoelaces.

But, a propos, is there an R entity called a "library"
(other than the command) as distinct from a "package"?

If so, then I can accept the necessity for disciplined
distinction between them, since calling one sort of thing
by the name of another sort of thing necessarily creates
confusion. But if not, then I'm inclined to feel that
a bit of loose talk is acceptable (since then a reference
to a "library" would be understood as a reference to a
"package", since what else would it be?)

Just my thoughts ...

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 08-Feb-05                                       Time: 22:19:46
------------------------------ XFMail ------------------------------

From p.dalgaard at biostat.ku.dk  Tue Feb  8 23:36:41 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Feb  8 23:41:10 2005
Subject: [Rd] Environment with no parent?
In-Reply-To: <6EA8BCBF-7A1D-11D9-8C28-000D933DC9FE@fhcrc.org>
References: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>
	<x24qgmojys.fsf@biostat.ku.dk>
	<6EA8BCBF-7A1D-11D9-8C28-000D933DC9FE@fhcrc.org>
Message-ID: <x2zmyen0g6.fsf@biostat.ku.dk>

Robert Gentleman <rgentlem@fhcrc.org> writes:


>    And, I think, that a better approach is to implement a proper hash
> table class
> and to then implement environments as hash table + parent (rather than
> the
> current version, which would be environment  - parent), 

Sounds like a good idea. Environments probably need to be *references*
to hash tables plus parent, though.

> but the tuit
> shortage is devastating on this side of the atlantic (possibly due to
> the disadvantageous $/euro exchange rate; I'm sure you all can afford
> more of them :-))

I'm sure my publisher will have suggestions for the use of any tuit
that I can get (and they pay in $, notwithstanding the IRS wanting me
to spend my copious free time on wrapping up enough red tape to
prevent them from taxing income which they are clearly not entitled
to do. Puff, pant...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From murdoch at stats.uwo.ca  Tue Feb  8 23:57:09 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Feb  8 23:55:54 2005
Subject: [Rd] Environment with no parent?
In-Reply-To: <x24qgmojys.fsf@biostat.ku.dk>
References: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>
	<x24qgmojys.fsf@biostat.ku.dk>
Message-ID: <esci01p52n37u6urqulun6ts464rju564c@4ax.com>

On 08 Feb 2005 21:49:47 +0100, Peter Dalgaard
<p.dalgaard@biostat.ku.dk> wrote :

>Duncan Murdoch <murdoch@stats.uwo.ca> writes:
>
>> Looking in envir.c, I see this:
>> 
>>     /* env is now R_NilValue, the base environment */
>> 
>> which doesn't give me much hope, but maybe there's a trick....
>> 
>> If not, would it be reasonable to install a magic "EmptyEnv" to use as
>> a parent in this sort of situation?
>> 
>
>I'm fairly sure the answer is "nope".
>
>It's been annoying me for years, for language aesthetic reasons
>mostly, but also with some consideration of cases like yours, and I've
>been on the brink of implementing a version where the base environment
>was a true environment. Apart from the usual issue of "round tuits",
>I was held back by the fact that one has to consider at least two things:
>
>(a) efficiency. Is it expensive no longer to have the base functions
>bound directly to their symbol? (My gut feeling is that with suitable
>hashing and cacheing, the penalty is minimal.)
>
>(b) you can *only* use get and simple variable retrieval in a non-base
>environment with a NULL parent (eval(x <- 1, envir=foo) would give
>'couldn't find function "<-"' or so). This could cause some confusion.

(b) means that the default should stay the way it is, but I think
there should be a way to set up a truly empty environment.  We have a
fair number of cases where envir=NULL is used, so it would be safest
to make it a different value -- even if NULL is the obvious value for
an empty environment.

Duncan Murdoch

From Achim.Zeileis at wu-wien.ac.at  Wed Feb  9 00:02:53 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed Feb  9 00:03:23 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>
References: <16904.63694.9500.496681@mithrandir.hornik.net>
	<XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20050209000253.2bd2bf84.Achim.Zeileis@wu-wien.ac.at>

On Tue, 08 Feb 2005 22:19:46 -0000 (GMT) (Ted Harding) wrote:

> On 08-Feb-05 Kurt Hornik wrote:
> > Afaic, one of the issues is that it seems common practice to refer
> > to collections of code as "libraries" or "packages", and we're
> > trying to use these rather general-purpose terms in a very precise
> > meaning, and obviously not very successful, in particular because
> > the use of"library" is highly non-standard.  One idea might be to
> > replace the"library" by something else like ... "a place where R
> > knows where to find packages" ... hmm, now that's too long, so ...
> 
> The only issue I have with "library" vs "package" (or vice versa)
> is the following.
> 
> I *know* that a collection of functions etc. (such as nlme) is
> properly called a "package". I could (and do) get ticked off if
> I refer to it as a "library".
> 
> However, if I want to use it then I enter
> 
>   library(nlme)
> 
> As a result, the little daemons who potter around re-wiring
> my mental circuits sometimes cross-connect these two. As a
> result, I can inadvertently refer to "the nlme library".
> 
> An example is a recent mailing of mine to the list where
> I twice referred to a certain "library" (and was amiably
> rebuked by Martic Maechler) -- but then I saw that I had
> also twice referred to the same "package" in the same mail!
> 
> Personally I don't mind whether it is called "package" or
> "library", though using the command library() to load a
> package does tend, as described, to get me treading on my
> own shoelaces.
> 
> But, a propos, is there an R entity called a "library"
> (other than the command) as distinct from a "package"?

A *library* is a directory in which you can find R *packages* (just as
in real life you can find books in a library) and with 
  library("foo", lib.loc = "/path/to/bar")
you want to get the package (book) "foo" from the library "bar" located
at "/path/to/bar".

So the two are really distinct...in real life, you also wouldn't say
that you have been in the book where they had a lot of libraries on the
shelves, would you? ;-)

But as Kurt explained: this distinction between "library" and "package"
is specific to R and does not correspond to common practice for other
software systems.
Z

> If so, then I can accept the necessity for disciplined
> distinction between them, since calling one sort of thing
> by the name of another sort of thing necessarily creates
> confusion. But if not, then I'm inclined to feel that
> a bit of loose talk is acceptable (since then a reference
> to a "library" would be understood as a reference to a
> "package", since what else would it be?)
> 
> Just my thoughts ...
> 
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding@nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 08-Feb-05                                       Time: 22:19:46
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From ripley at stats.ox.ac.uk  Wed Feb  9 00:05:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb  9 00:05:30 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.61.0502082254160.19433@gannet.stats>

On Tue, 8 Feb 2005 Ted.Harding@nessie.mcc.ac.uk wrote:

[...]

> But, a propos, is there an R entity called a "library"
> (other than the command) as distinct from a "package"?

Yes.  That is what the argument 'lib.loc' to library() and other functions 
refers to.

A 'library' is a collection of packages stored in one directory.

library("pkg") means `go to one or more libraries, find package pkg and 
load it up'

In S parlance what in R is a `package' is a `library section' or 
(latterly) also `chapter'.

In English usage a library is a collection of volumes, not of recipes or 
stories or articles.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Wed Feb  9 00:29:37 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Feb  9 00:34:09 2005
Subject: [Rd] Environment with no parent?
In-Reply-To: <esci01p52n37u6urqulun6ts464rju564c@4ax.com>
References: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>
	<x24qgmojys.fsf@biostat.ku.dk>
	<esci01p52n37u6urqulun6ts464rju564c@4ax.com>
Message-ID: <x2r7jqmxzy.fsf@biostat.ku.dk>

Duncan Murdoch <murdoch@stats.uwo.ca> writes:

> >(a) efficiency. Is it expensive no longer to have the base functions
> >bound directly to their symbol? (My gut feeling is that with suitable
> >hashing and cacheing, the penalty is minimal.)
> >
> >(b) you can *only* use get and simple variable retrieval in a non-base
> >environment with a NULL parent (eval(x <- 1, envir=foo) would give
> >'couldn't find function "<-"' or so). This could cause some confusion.
> 
> (b) means that the default should stay the way it is, but I think
> there should be a way to set up a truly empty environment.  We have a
> fair number of cases where envir=NULL is used, so it would be safest
> to make it a different value -- even if NULL is the obvious value for
> an empty environment.

Not necessarily. It just means that you should think about it. It is
not a given that envir=NULL really means what the author expected, and
fixing them up to read envir=.BaseEnv is probably quite doable.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From jgentry at jimmy.harvard.edu  Wed Feb  9 01:57:48 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed Feb  9 01:56:08 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <20050209000253.2bd2bf84.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <Pine.SOL.4.20.0502081956590.25256-100000@santiam.dfci.harvard.edu>

On Wed, 9 Feb 2005, Achim Zeileis wrote:
> A *library* is a directory in which you can find R *packages* (just as
> in real life you can find books in a library) and with 
>   library("foo", lib.loc = "/path/to/bar")
> you want to get the package (book) "foo" from the library "bar" located
> at "/path/to/bar".

Out of pure curiosity, could anyone tell me the historical reason that
library() is used here?  Does it tie in to the S ancestry of R?

From bef at northwestern.edu  Wed Feb  9 02:44:32 2005
From: bef at northwestern.edu (bef@northwestern.edu)
Date: Wed Feb  9 02:44:41 2005
Subject: [Rd] Linux: /usr/shar/doc/R-2.0.1/*.pdf all have bad fonts (PR#7675)
Message-ID: <20050209014432.7FAA2E407@slim.kubism.ku.dk>

Full_Name: Bruce Foster
Version: 2.0.1
OS: Red Hat Enterprise Linux WS release 3 (Taroon Update 4)
Submission from: (NULL) (129.105.110.38)


All of the pdf files in /usr/share/doc/R-2.0.1 from the CRAN RedHat RPM have
invalid fonts. A build from source yields the same problem.

[root@wanda R-2.0.1]# ll *.pdf
-rw-r--r--    1 root     root       259886 Nov 19 10:50 R-FAQ.pdf
-rw-r--r--    1 root     root       127067 Nov 19 10:50 R-admin.pdf
-rw-r--r--    1 root     root       143761 Nov 19 10:50 R-data.pdf
-rw-r--r--    1 root     root       374269 Nov 19 10:50 R-exts.pdf
-rw-r--r--    1 root     root       435252 Nov 19 10:50 R-intro.pdf
-rw-r--r--    1 root     root       268142 Nov 19 10:50 R-lang.pdf

The files are unreadable with xpdf and acroread, and pdf2ps shows this:
[root@wanda R-2.0.1]# pdf2ps R-admin.pdf 
Error: /invalidfont in /F72
Operand stack:
   --dict:5/5(L)--   F72   20.659
Execution stack:
   %interp_exit   .runexec2   --nostringval--   --nostringval--  
--nostringval--   2   %stopped_push   --nostringval--   --nostringval--  
--nostringval--   false   1   %stopped_push   1   3   %oparray_pop   1   3  
%oparray_pop   --nostringval--   2   1   29   --nostringval--  
%for_pos_int_continue   --nostringval--   --nostringval--   --nostringval--  
--nostringval--   %array_continue   --nostringval--   false   1   %stopped_push 
 --nostringval--   %loop_continue   --nostringval--   --nostringval--  
--nostringval--
Dictionary stack:
   --dict:1051/1123(ro)(G)--   --dict:0/20(G)--   --dict:92/200(L)--  
--dict:92/200(L)--   --dict:97/127(ro)(G)--   --dict:229/230(ro)(G)--  
--dict:19/24(L)--   --dict:4/6(L)--   --dict:23/31(L)--
Current allocation mode is local
GNU Ghostscript 7.05: Unrecoverable error, exit code 1

From blindglobe at gmail.com  Wed Feb  9 06:38:07 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Wed Feb  9 06:38:15 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <20050209000253.2bd2bf84.Achim.Zeileis@wu-wien.ac.at>
References: <16904.63694.9500.496681@mithrandir.hornik.net>
	<XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>
	<20050209000253.2bd2bf84.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <1abe3fa9050208213822c9c3ce@mail.gmail.com>

On Wed, 9 Feb 2005 00:02:53 +0100, Achim Zeileis
<Achim.Zeileis@wu-wien.ac.at> wrote:
> On Tue, 08 Feb 2005 22:19:46 -0000 (GMT) (Ted Harding) wrote:
> 
> > On 08-Feb-05 Kurt Hornik wrote:
> > > Afaic, one of the issues is that it seems common practice to refer
> > > to collections of code as "libraries" or "packages", and we're
> > > trying to use these rather general-purpose terms in a very precise
> > > meaning, and obviously not very successful, in particular because
> > > the use of"library" is highly non-standard.  One idea might be to
> > > replace the"library" by something else like ... "a place where R
> > > knows where to find packages" ... hmm, now that's too long, so ...
> >
> > The only issue I have with "library" vs "package" (or vice versa)
> > is the following.
> >
> > I *know* that a collection of functions etc. (such as nlme) is
> > properly called a "package". I could (and do) get ticked off if
> > I refer to it as a "library".
> >
> > However, if I want to use it then I enter
> >
> >   library(nlme)
> >
> > As a result, the little daemons who potter around re-wiring
> > my mental circuits sometimes cross-connect these two. As a
> > result, I can inadvertently refer to "the nlme library".
> >
> > An example is a recent mailing of mine to the list where
> > I twice referred to a certain "library" (and was amiably
> > rebuked by Martic Maechler) -- but then I saw that I had
> > also twice referred to the same "package" in the same mail!
> >
> > Personally I don't mind whether it is called "package" or
> > "library", though using the command library() to load a
> > package does tend, as described, to get me treading on my
> > own shoelaces.
> >
> > But, a propos, is there an R entity called a "library"
> > (other than the command) as distinct from a "package"?
> 
> A *library* is a directory in which you can find R *packages* (just as
> in real life you can find books in a library) and with
>   library("foo", lib.loc = "/path/to/bar")
> you want to get the package (book) "foo" from the library "bar" located
> at "/path/to/bar".
> 
> So the two are really distinct...in real life, you also wouldn't say
> that you have been in the book where they had a lot of libraries on the
> shelves, would you? ;-)
> 
> But as Kurt explained: this distinction between "library" and "package"
> is specific to R and does not correspond to common practice for other
> software systems.
> Z

Sure, but I'm not specifying which library I'd like to get the
packages from, thus it might be make perfect sense to say:

loadPackage("foo",library="bar")

But when I'm typing library, I'm loading a package, NOT specifying a
library to use.

Package is also confusing -- I keep thinking of it as a noun, as a
package specifier, while others like it as a verb; this was a useful
point for me that one person made.

But perhaps then adding the verb (well, I can see the point against,
but hear it out) might be useful.  Thus,

    package(action,location,name)

might be a useful function signature, though possibly not in that order.

-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From blindglobe at gmail.com  Wed Feb  9 06:43:32 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Wed Feb  9 06:43:41 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <Pine.LNX.4.61.0502082254160.19433@gannet.stats>
References: <XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>
	<Pine.LNX.4.61.0502082254160.19433@gannet.stats>
Message-ID: <1abe3fa9050208214376a8df1d@mail.gmail.com>

On Tue, 8 Feb 2005 23:05:20 +0000 (GMT), Prof Brian Ripley
<ripley@stats.ox.ac.uk> wrote:
> On Tue, 8 Feb 2005 Ted.Harding@nessie.mcc.ac.uk wrote:
> 
> [...]
> 
> > But, a propos, is there an R entity called a "library"
> > (other than the command) as distinct from a "package"?
> 
> Yes.  That is what the argument 'lib.loc' to library() and other functions
> refers to.
> 
> A 'library' is a collection of packages stored in one directory.
> 
> library("pkg") means `go to one or more libraries, find package pkg and
> load it up'

And this is the problem, that the description doesn't clearly match
the specification.

One might easily expect that library("pkg") implies use library "pkg"
for further package loading.

It's almost too bad that libraries weren't books, with packages being chapters, 
or libraries being postOffices, with packages being packages,
or packages being libraries, with libraries being cities
or libraries being libraries, with packages being books.

But the current mess wastes a good bit of time aggravating people who
want things just so, responding to people who are just careless.

-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From Kurt.Hornik at wu-wien.ac.at  Wed Feb  9 07:40:03 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Feb  9 07:40:12 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <1abe3fa9050208214376a8df1d@mail.gmail.com>
References: <XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>
	<Pine.LNX.4.61.0502082254160.19433@gannet.stats>
	<1abe3fa9050208214376a8df1d@mail.gmail.com>
Message-ID: <16905.45123.304008.99041@mithrandir.hornik.net>

>>>>> A J Rossini writes:

> On Tue, 8 Feb 2005 23:05:20 +0000 (GMT), Prof Brian Ripley
> <ripley@stats.ox.ac.uk> wrote:
>> On Tue, 8 Feb 2005 Ted.Harding@nessie.mcc.ac.uk wrote:
>> 
>> [...]
>> 
>> > But, a propos, is there an R entity called a "library"
>> > (other than the command) as distinct from a "package"?
>> 
>> Yes.  That is what the argument 'lib.loc' to library() and other functions
>> refers to.
>> 
>> A 'library' is a collection of packages stored in one directory.
>> 
>> library("pkg") means `go to one or more libraries, find package pkg and
>> load it up'

> And this is the problem, that the description doesn't clearly match
> the specification.

> One might easily expect that library("pkg") implies use library "pkg"
> for further package loading.

> It's almost too bad that libraries weren't books, with packages being
> chapters, or libraries being postOffices, with packages being
> packages, or packages being libraries, with libraries being cities or
> libraries being libraries, with packages being books.

> But the current mess wastes a good bit of time aggravating people who
> want things just so, responding to people who are just careless.

As I wrote earlier, we need to have alternatives to change this.

The R system is highly extensible through standardized add-ons called
*packages*.  That is one of its key strengths, and I don't think we
should stop referring to packages as packages.

Packages are made available by putting them into *libraries*, defined as
"places where R knows to find packages".  If we do not like this term,
we need a better one.

Packages are loaded and attached using library(), which in principle is
something for which a replacement is desired anyways.  But as Brian and
I [at least] said, we need not only a new name, but also a careful
redesign, and someone taking charge.

-k

From ripley at stats.ox.ac.uk  Wed Feb  9 08:32:19 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb  9 08:32:33 2005
Subject: [Rd] Linux: /usr/shar/doc/R-2.0.1/*.pdf all have bad fonts
	(PR#7675)
In-Reply-To: <20050209014432.7FAA2E407@slim.kubism.ku.dk>
References: <20050209014432.7FAA2E407@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502090729470.25008@gannet.stats>

Please report this to the RPM provider: it is not true of R in general.
This is the R bug repository, not the CRAN error address.

On Wed, 9 Feb 2005 bef@northwestern.edu wrote:

> Full_Name: Bruce Foster
> Version: 2.0.1
> OS: Red Hat Enterprise Linux WS release 3 (Taroon Update 4)
> Submission from: (NULL) (129.105.110.38)
>
>
> All of the pdf files in /usr/share/doc/R-2.0.1 from the CRAN RedHat RPM have
> invalid fonts. A build from source yields the same problem.
>
> [root@wanda R-2.0.1]# ll *.pdf
> -rw-r--r--    1 root     root       259886 Nov 19 10:50 R-FAQ.pdf
> -rw-r--r--    1 root     root       127067 Nov 19 10:50 R-admin.pdf
> -rw-r--r--    1 root     root       143761 Nov 19 10:50 R-data.pdf
> -rw-r--r--    1 root     root       374269 Nov 19 10:50 R-exts.pdf
> -rw-r--r--    1 root     root       435252 Nov 19 10:50 R-intro.pdf
> -rw-r--r--    1 root     root       268142 Nov 19 10:50 R-lang.pdf
>
> The files are unreadable with xpdf and acroread, and pdf2ps shows this:
> [root@wanda R-2.0.1]# pdf2ps R-admin.pdf
> Error: /invalidfont in /F72
> Operand stack:
>   --dict:5/5(L)--   F72   20.659
> Execution stack:
>   %interp_exit   .runexec2   --nostringval--   --nostringval--
> --nostringval--   2   %stopped_push   --nostringval--   --nostringval--
> --nostringval--   false   1   %stopped_push   1   3   %oparray_pop   1   3
> %oparray_pop   --nostringval--   2   1   29   --nostringval--
> %for_pos_int_continue   --nostringval--   --nostringval--   --nostringval--
> --nostringval--   %array_continue   --nostringval--   false   1   %stopped_push
> --nostringval--   %loop_continue   --nostringval--   --nostringval--
> --nostringval--
> Dictionary stack:
>   --dict:1051/1123(ro)(G)--   --dict:0/20(G)--   --dict:92/200(L)--
> --dict:92/200(L)--   --dict:97/127(ro)(G)--   --dict:229/230(ro)(G)--
> --dict:19/24(L)--   --dict:4/6(L)--   --dict:23/31(L)--
> Current allocation mode is local
> GNU Ghostscript 7.05: Unrecoverable error, exit code 1
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Feb  9 08:32:27 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb  9 08:32:36 2005
Subject: [Rd] Linux: /usr/shar/doc/R-2.0.1/*.pdf all have bad fonts
	(PR#7677)
Message-ID: <20050209073227.1231EE403@slim.kubism.ku.dk>

Please report this to the RPM provider: it is not true of R in general.
This is the R bug repository, not the CRAN error address.

On Wed, 9 Feb 2005 bef@northwestern.edu wrote:

> Full_Name: Bruce Foster
> Version: 2.0.1
> OS: Red Hat Enterprise Linux WS release 3 (Taroon Update 4)
> Submission from: (NULL) (129.105.110.38)
>
>
> All of the pdf files in /usr/share/doc/R-2.0.1 from the CRAN RedHat RPM have
> invalid fonts. A build from source yields the same problem.
>
> [root@wanda R-2.0.1]# ll *.pdf
> -rw-r--r--    1 root     root       259886 Nov 19 10:50 R-FAQ.pdf
> -rw-r--r--    1 root     root       127067 Nov 19 10:50 R-admin.pdf
> -rw-r--r--    1 root     root       143761 Nov 19 10:50 R-data.pdf
> -rw-r--r--    1 root     root       374269 Nov 19 10:50 R-exts.pdf
> -rw-r--r--    1 root     root       435252 Nov 19 10:50 R-intro.pdf
> -rw-r--r--    1 root     root       268142 Nov 19 10:50 R-lang.pdf
>
> The files are unreadable with xpdf and acroread, and pdf2ps shows this:
> [root@wanda R-2.0.1]# pdf2ps R-admin.pdf
> Error: /invalidfont in /F72
> Operand stack:
>   --dict:5/5(L)--   F72   20.659
> Execution stack:
>   %interp_exit   .runexec2   --nostringval--   --nostringval--
> --nostringval--   2   %stopped_push   --nostringval--   --nostringval--
> --nostringval--   false   1   %stopped_push   1   3   %oparray_pop   1   3
> %oparray_pop   --nostringval--   2   1   29   --nostringval--
> %for_pos_int_continue   --nostringval--   --nostringval--   --nostringval--
> --nostringval--   %array_continue   --nostringval--   false   1   %stopped_push
> --nostringval--   %loop_continue   --nostringval--   --nostringval--
> --nostringval--
> Dictionary stack:
>   --dict:1051/1123(ro)(G)--   --dict:0/20(G)--   --dict:92/200(L)--
> --dict:92/200(L)--   --dict:97/127(ro)(G)--   --dict:229/230(ro)(G)--
> --dict:19/24(L)--   --dict:4/6(L)--   --dict:23/31(L)--
> Current allocation mode is local
> GNU Ghostscript 7.05: Unrecoverable error, exit code 1
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Feb  9 10:29:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb  9 10:29:49 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc
In-Reply-To: <Pine.SOL.4.20.0502081956590.25256-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0502081956590.25256-100000@santiam.dfci.harvard.edu>
Message-ID: <Pine.LNX.4.61.0502090924520.26404@gannet.stats>

On Tue, 8 Feb 2005, Jeff Gentry wrote:

> On Wed, 9 Feb 2005, Achim Zeileis wrote:
>> A *library* is a directory in which you can find R *packages* (just as
>> in real life you can find books in a library) and with
>>   library("foo", lib.loc = "/path/to/bar")
>> you want to get the package (book) "foo" from the library "bar" located
>> at "/path/to/bar".
>
> Out of pure curiosity, could anyone tell me the historical reason that
> library() is used here?  Does it tie in to the S ancestry of R?

It's been the way S does it since ca 1987 (when the Blue Book version of S 
first made S extensible via functions as today).  See the 1988 Blue Book 
p.58.  The only difference (as I have already noted) is that the S library 
has `sections' not `packages'.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From plummer at iarc.fr  Wed Feb  9 10:41:21 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed Feb  9 10:42:33 2005
Subject: [Rd] Linux: /usr/shar/doc/R-2.0.1/*.pdf all have bad fonts
	(PR#7677)
In-Reply-To: <20050209073227.1231EE403@slim.kubism.ku.dk>
References: <20050209073227.1231EE403@slim.kubism.ku.dk>
Message-ID: <1107942081.3422.11.camel@seurat>

I have forwarded the message to Matthew Cox, who built the RPMS for Red
Hat Enterprise Linux. But if you get the same problem building from
source then it must be a  platform-specific problem and you should
probably get support from Red Hat.

Martyn

On Wed, 2005-02-09 at 08:32 +0100, ripley@stats.ox.ac.uk wrote:
> Please report this to the RPM provider: it is not true of R in general.
> This is the R bug repository, not the CRAN error address.
> 
> On Wed, 9 Feb 2005 bef@northwestern.edu wrote:
> 
> > Full_Name: Bruce Foster
> > Version: 2.0.1
> > OS: Red Hat Enterprise Linux WS release 3 (Taroon Update 4)
> > Submission from: (NULL) (129.105.110.38)
> >
> >
> > All of the pdf files in /usr/share/doc/R-2.0.1 from the CRAN RedHat RPM have
> > invalid fonts. A build from source yields the same problem.
> >
> > [root@wanda R-2.0.1]# ll *.pdf
> > -rw-r--r--    1 root     root       259886 Nov 19 10:50 R-FAQ.pdf
> > -rw-r--r--    1 root     root       127067 Nov 19 10:50 R-admin.pdf
> > -rw-r--r--    1 root     root       143761 Nov 19 10:50 R-data.pdf
> > -rw-r--r--    1 root     root       374269 Nov 19 10:50 R-exts.pdf
> > -rw-r--r--    1 root     root       435252 Nov 19 10:50 R-intro.pdf
> > -rw-r--r--    1 root     root       268142 Nov 19 10:50 R-lang.pdf
> >
> > The files are unreadable with xpdf and acroread, and pdf2ps shows this:
> > [root@wanda R-2.0.1]# pdf2ps R-admin.pdf
> > Error: /invalidfont in /F72
> > Operand stack:
> >   --dict:5/5(L)--   F72   20.659
> > Execution stack:
> >   %interp_exit   .runexec2   --nostringval--   --nostringval--
> > --nostringval--   2   %stopped_push   --nostringval--   --nostringval--
> > --nostringval--   false   1   %stopped_push   1   3   %oparray_pop   1   3
> > %oparray_pop   --nostringval--   2   1   29   --nostringval--
> > %for_pos_int_continue   --nostringval--   --nostringval--   --nostringval--
> > --nostringval--   %array_continue   --nostringval--   false   1   %stopped_push
> > --nostringval--   %loop_continue   --nostringval--   --nostringval--
> > --nostringval--
> > Dictionary stack:
> >   --dict:1051/1123(ro)(G)--   --dict:0/20(G)--   --dict:92/200(L)--
> > --dict:92/200(L)--   --dict:97/127(ro)(G)--   --dict:229/230(ro)(G)--
> > --dict:19/24(L)--   --dict:4/6(L)--   --dict:23/31(L)--
> > Current allocation mode is local
> > GNU Ghostscript 7.05: Unrecoverable error, exit code 1
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>

From B.Rowlingson at lancaster.ac.uk  Wed Feb  9 12:06:14 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed Feb  9 12:06:23 2005
Subject: [Rd] Re: Packages and Libraries
In-Reply-To: <1abe3fa9050208214376a8df1d@mail.gmail.com>
References: <XFMail.050208221946.Ted.Harding@nessie.mcc.ac.uk>	<Pine.LNX.4.61.0502082254160.19433@gannet.stats>
	<1abe3fa9050208214376a8df1d@mail.gmail.com>
Message-ID: <4209EEA6.4020605@lancaster.ac.uk>


> or libraries being postOffices, with packages being packages,

  In my recent experience, a post office is somewhere that packages are 
*lost* rather than found :)

Baz

[I had a card from the PO saying they'd tried to deliver a package but I 
was out, I went to the depot and they couldn't find it...]

From pgilbert at bank-banque-canada.ca  Wed Feb  9 16:47:09 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed Feb  9 16:48:47 2005
Subject: [Rd] link to an alias in another package
In-Reply-To: <Pine.LNX.4.61.0502081201160.25242@gannet.stats>
References: <4208243C.4080605@bank-banque-canada.ca>
	<Pine.LNX.4.61.0502080710390.14407@gannet.stats>
	<aq2h01p3rt6a97s7bq91lc4pdf3v77899q@4ax.com>
	<Pine.LNX.4.61.0502081201160.25242@gannet.stats>
Message-ID: <420A307D.5060702@bank-banque-canada.ca>


In summary
> In some documentation for a package I am working on I have
>
>    \code{\link[stats]{varimax}}
>    \code{\link[stats]{promax}}
>
> The link to varimax works, but not the one to promax. Promax is an 
> alias under \name{varimax}.  ...

    \code(\link[stats:varimax]{promax}}

works but will probably break if promax is ever moved to its own Rd 
file. (From the discussion there is probably not a better general solution.)

    \code(\link{promax}}

works because stats is always installed, but is not a general solution 
because I have other cases where the package may not be installed.

    \code(\link[stats:promax]{varimax}}

which might be another (but presumably mistaken) interpretation of the 
Writing R Extensions documentation

>   \link[pkg:bar]{foo} to link to the package pkg with topic (file?)
>   foo and bar respectively.

does not work and also displays "varimax" in the text (which is not what 
I want).

Paul Gilbert

From julia.luc at english.zzn.com  Wed Feb  9 20:59:13 2005
From: julia.luc at english.zzn.com (Julia)
Date: Wed Feb  9 16:58:51 2005
Subject: [Rd] Please read.
Message-ID: <3810-2200523919591378@ondo>

Hello!

I have something to share with you today - something that has made my difficult life easy and exciting. 

Click this 7-minute flash presentation and find out how this simple thing can change people's lives: http://yourfamilygoal.ws/show 

Make sure to turn on your speakers or put on your headphone.. 

I will be very glad to share with you my story. Don't hesitate to write me back for any question or help you need. 

All the best, 
Julia

From p.dalgaard at biostat.ku.dk  Wed Feb  9 16:55:31 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Feb  9 17:00:09 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <16904.63694.9500.496681@mithrandir.hornik.net>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
	<16904.63694.9500.496681@mithrandir.hornik.net>
Message-ID: <x21xbppw24.fsf@biostat.ku.dk>

Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:

> >>>>> A J Rossini writes:
> 
> > But I don't see a problem with "package("package")", though I'm sure
> > I'm missing something.
> 
> package() [sic] might be the creator for package objects, provided we
> can decide on what they are (and what kind of packages [source,
> installed, ...] they are used for).
> 
> usePackage() or use_package() otoh would indicate to "use" a package
> (i.e., load and attach it).  The tricky part is deciding about the
> interface (e.g., finally disallowing non-standard evaluation as it is a
> programmer's nightmare) and what it should return.  And that is work in
> progress ...

Any information on the rate...? (I still vote for usepackage() btw.)

It would be good if we could at least have an outline of the intended
functionality and see if we could forge ahead and get a preliminary
version done in time for 2.1.x
 
> Even if we don't like the current semantics, the *name* of library() in
> itself should not be a problem.  After all, calling summary() does not
> imply that your primary argument is a summary, so why should calling
> library() imply that its primary argument is a "library"?

More likely it would imply that the *result* is a library...

Anyway, it was introduced at a time where we considered it important
to be "prototype compatible" as long as there was no good reason not
to. With 20-20 hindsight, we could probably have afforded to think up
a better name.

> > It really would end this constant confusion and save various folks
> > approx 15 minutes/week in knee-jerk responses, eh?
> 
> Afaic, one of the issues is that it seems common practice to refer to
> collections of code as "libraries" or "packages", and we're trying to
> use these rather general-purpose terms in a very precise meaning, and
> obviously not very successful, in particular because the use of
> "library" is highly non-standard.  One idea might be to replace the
> "library" by something else like ... "a place where R knows where to
> find packages" ... hmm, now that's too long, so ...

"store", or "depot" springs to mind. The latter might cause baz to go
postal, though...


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Kurt.Hornik at wu-wien.ac.at  Wed Feb  9 17:14:08 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Feb  9 17:14:18 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <x21xbppw24.fsf@biostat.ku.dk>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
	<16904.63694.9500.496681@mithrandir.hornik.net>
	<x21xbppw24.fsf@biostat.ku.dk>
Message-ID: <16906.14032.589706.230256@mithrandir.hornik.net>

>>>>> Peter Dalgaard writes:

> Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:
>> >>>>> A J Rossini writes:
>> 
>> > But I don't see a problem with "package("package")", though I'm sure
>> > I'm missing something.
>> 
>> package() [sic] might be the creator for package objects, provided we
>> can decide on what they are (and what kind of packages [source,
>> installed, ...] they are used for).
>> 
>> usePackage() or use_package() otoh would indicate to "use" a package
>> (i.e., load and attach it).  The tricky part is deciding about the
>> interface (e.g., finally disallowing non-standard evaluation as it is a
>> programmer's nightmare) and what it should return.  And that is work in
>> progress ...

> Any information on the rate...? (I still vote for usepackage() btw.)

Why not use(), as the GCD?

> It would be good if we could at least have an outline of the intended
> functionality and see if we could forge ahead and get a preliminary
> version done in time for 2.1.x

Help us out.

	use <- function(package, pos = 2, lib.loc, ...)

where 'package' is either a character string or some sort of package
object/reference, to be specified later.  And 'lib.loc' needs to have a
different name if we rename libraries into stores or whatever ...

What should this return?  Currently, 'library' returns the list of
loaded (or available) packages by default, as a list of names, which is
not good enough.  So we need something like the DLLInfoList returned by
getLoadedDLLs() (and the docs should actually mention that class), or
something usable by the package management tools ... and this is under
redesign as well.

But why should this really return info on all loaded/attached packages?
An alternative might be just returning the package meta-data in some
form.  Or nothing, which would fit into the idea that it really does
nothing apart from loading and attaching a package.

(And maybe a condition object inheriting from packageLoadAndAttachError
in case of failure? :-))

-k

From roebuck at odin.mdacc.tmc.edu  Wed Feb  9 17:32:00 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed Feb  9 17:32:13 2005
Subject: [Rd] Compiler-specific flags with PKG_CFLAGS
In-Reply-To: <16905.17345.633888.927174@mithrandir.hornik.net>
References: <16905.17345.633888.927174@mithrandir.hornik.net>
Message-ID: <Pine.OSF.4.58.0502091008490.35024@odin.mdacc.tmc.edu>

On Tue, 8 Feb 2005, Kurt Hornik wrote:

> This concerns the packages...
> for which current versions of r-devel now report problems with
> non-portable compilation flags in Makevars[.in] files:
>
>    Problems in package 'rwt':
>    Non-portable flags in variable 'PKG_CFLAGS':
>      -Wall -ansi -pedantic
>
> These flags are mostly GCC specific and not portable.
> (Do not assume that any -Ox will work.)
>
> Can you please fix these problems, and provide an update of your
> package?

It has been on my todo list since Ripley brought it up
several weeks ago in r-devel but hadn't exactly figured
out how to package it as such. Someone have an example
of how to add compiler flags for GCC when it is being
used and otherwise not? I'm assuming Makevars isn't being
passed through cpp and I can't just use #ifdef. In this case,
I could just leave them out but I hate to lose the warnings
for development. Using 'configure' is probably the only
option but really didn't want to use it for just stricter
error checking during compilation.

One other question - if package update happens for something
like the above but with no change to contents of package,
should the version number be incremented?

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From Kurt.Hornik at wu-wien.ac.at  Wed Feb  9 17:44:50 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Feb  9 17:55:05 2005
Subject: [Rd] Re: Compiler-specific flags with PKG_CFLAGS
In-Reply-To: <Pine.OSF.4.58.0502091008490.35024@odin.mdacc.tmc.edu>
References: <16905.17345.633888.927174@mithrandir.hornik.net>
	<Pine.OSF.4.58.0502091008490.35024@odin.mdacc.tmc.edu>
Message-ID: <16906.15874.681788.789761@mithrandir.hornik.net>

>>>>> Paul Roebuck writes:

> On Tue, 8 Feb 2005, Kurt Hornik wrote:
>> This concerns the packages...
>> for which current versions of r-devel now report problems with
>> non-portable compilation flags in Makevars[.in] files:
>> 
>> Problems in package 'rwt':
>> Non-portable flags in variable 'PKG_CFLAGS':
>> -Wall -ansi -pedantic
>> 
>> These flags are mostly GCC specific and not portable.
>> (Do not assume that any -Ox will work.)
>> 
>> Can you please fix these problems, and provide an update of your
>> package?

> It has been on my todo list since Ripley brought it up
> several weeks ago in r-devel but hadn't exactly figured
> out how to package it as such. Someone have an example
> of how to add compiler flags for GCC when it is being
> used and otherwise not? I'm assuming Makevars isn't being
> passed through cpp and I can't just use #ifdef. In this case,
> I could just leave them out but I hate to lose the warnings
> for development. Using 'configure' is probably the only
> option but really didn't want to use it for just stricter
> error checking during compilation.

I think the simplest way to achieve this is to configure R locally (for
yourself) with CFLAGS="-O2 -Wall -pedantic" but leave the corresponding
PKG_CFLAGS etc variables in package src/Makevars alone.

R 2.1.0 will provide a portable way of overriding the configured "site"
compilation flags via user-level ~/.R/Makevars files.

> One other question - if package update happens for something
> like the above but with no change to contents of package,
> should the version number be incremented?

Yes.

-k

From roebuck at odin.mdacc.tmc.edu  Wed Feb  9 18:21:13 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed Feb  9 18:21:22 2005
Subject: [Rd] Re: Compiler-specific flags with PKG_CFLAGS
In-Reply-To: <16906.15874.681788.789761@mithrandir.hornik.net>
References: <16905.17345.633888.927174@mithrandir.hornik.net><Pine.OSF.4.58.
	0502091008490.35024@odin.mdacc.tmc.edu>
	<16906.15874.681788.789761@mithrandir.hornik.net>
Message-ID: <Pine.OSF.4.58.0502091102280.35024@odin.mdacc.tmc.edu>

On Wed, 9 Feb 2005, Kurt Hornik wrote:

> >>>>> Paul Roebuck writes:
>
> > On Tue, 8 Feb 2005, Kurt Hornik wrote:
> >> This concerns the packages...
> >> for which current versions of r-devel now report problems with
> >> non-portable compilation flags in Makevars[.in] files:
> >>
> >> Problems in package 'rwt':
> >> Non-portable flags in variable 'PKG_CFLAGS':
> >> -Wall -ansi -pedantic
> >>
> >> These flags are mostly GCC specific and not portable.
> >> (Do not assume that any -Ox will work.)
> >>
> >> Can you please fix these problems, and provide an update of your
> >> package?
>
> > It has been on my todo list since Ripley brought it up
> > several weeks ago in r-devel but hadn't exactly figured
> > out how to package it as such. Someone have an example
> > of how to add compiler flags for GCC when it is being
> > used and otherwise not? I'm assuming Makevars isn't being
> > passed through cpp and I can't just use #ifdef. In this case,
> > I could just leave them out but I hate to lose the warnings
> > for development. Using 'configure' is probably the only
> > option but really didn't want to use it for just stricter
> > error checking during compilation.
>
> I think the simplest way to achieve this is to configure R
> locally (for yourself) with CFLAGS="-O2 -Wall -pedantic" but
> leave the corresponding PKG_CFLAGS etc variables in package
> src/Makevars alone.

I can do that for workstations which I have admin priviledges
and have a private version of R; how about the ones I don't?

> R 2.1.0 will provide a portable way of overriding the configured
> "site" compilation flags via user-level ~/.R/Makevars files.

Will this also cover how to merge or augment compilation
flags with the site-specified ones? And how will it handle
the situation where one's home directory is NFS mounted
across several architectures? There will be a variable to
override the default location, right?.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From Kurt.Hornik at wu-wien.ac.at  Wed Feb  9 19:29:09 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed Feb  9 19:39:21 2005
Subject: [Rd] Re: Compiler-specific flags with PKG_CFLAGS
In-Reply-To: <Pine.OSF.4.58.0502091102280.35024@odin.mdacc.tmc.edu>
References: <16905.17345.633888.927174@mithrandir.hornik.net> <Pine.OSF.4.58.
	0502091008490.35024@odin.mdacc.tmc.edu>
	<16906.15874.681788.789761@mithrandir.hornik.net>
	<Pine.OSF.4.58.0502091102280.35024@odin.mdacc.tmc.edu>
Message-ID: <16906.22133.310061.960069@mithrandir.hornik.net>

>>>>> Paul Roebuck writes:

> On Wed, 9 Feb 2005, Kurt Hornik wrote:
>> >>>>> Paul Roebuck writes:
>> 
>> > On Tue, 8 Feb 2005, Kurt Hornik wrote:
>> >> This concerns the packages...
>> >> for which current versions of r-devel now report problems with
>> >> non-portable compilation flags in Makevars[.in] files:
>> >>
>> >> Problems in package 'rwt':
>> >> Non-portable flags in variable 'PKG_CFLAGS':
>> >> -Wall -ansi -pedantic
>> >>
>> >> These flags are mostly GCC specific and not portable.
>> >> (Do not assume that any -Ox will work.)
>> >>
>> >> Can you please fix these problems, and provide an update of your
>> >> package?
>> 
>> > It has been on my todo list since Ripley brought it up
>> > several weeks ago in r-devel but hadn't exactly figured
>> > out how to package it as such. Someone have an example
>> > of how to add compiler flags for GCC when it is being
>> > used and otherwise not? I'm assuming Makevars isn't being
>> > passed through cpp and I can't just use #ifdef. In this case,
>> > I could just leave them out but I hate to lose the warnings
>> > for development. Using 'configure' is probably the only
>> > option but really didn't want to use it for just stricter
>> > error checking during compilation.
>> 
>> I think the simplest way to achieve this is to configure R
>> locally (for yourself) with CFLAGS="-O2 -Wall -pedantic" but
>> leave the corresponding PKG_CFLAGS etc variables in package
>> src/Makevars alone.

> I can do that for workstations which I have admin priviledges
> and have a private version of R; how about the ones I don't?

It depends: R-exts says

	Flags which are set in file `etc/Makeconf' can be overridden by
	the environment variable `MAKEFLAGS' (at least for systems using
	GNU `make'), as in (Bourne shell syntax)

	     MAKEFLAGS="CFLAGS=-O3" R CMD SHLIB *.c

	or by using a `Makefile'.

so if you have GNU Make, you can actually set MAKEFLAGS accordingly in
your R_ENVIRON file.

What you can also try is to have a make (Sys.getenv("MAKE")) script in
your PATH which does something like

	/path/to/real/make $* CFLAGS=-O3

(but I am never sure whether command line vars override the ones in
files?)

>> R 2.1.0 will provide a portable way of overriding the configured
>> "site" compilation flags via user-level ~/.R/Makevars files.

> Will this also cover how to merge or augment compilation
> flags with the site-specified ones? And how will it handle
> the situation where one's home directory is NFS mounted
> across several architectures? There will be a variable to
> override the default location, right?.

No but there is

	~/.R/Makeconf-$platform

where $platform is the same as in R_PLATFORM, which is looked for ahead
of ~/.R/Makeconf.  (That should be better than having an R_MAKECONF env
var.)

Btw, I assume that if all Makes are GNU Make you might actually be able
to conditionalize inside.

Best
-k

From simon.urbanek at r-project.org  Wed Feb  9 19:56:30 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed Feb  9 19:56:37 2005
Subject: [Rd] Re: Compiler-specific flags with PKG_CFLAGS
In-Reply-To: <Pine.OSF.4.58.0502091102280.35024@odin.mdacc.tmc.edu>
References: <16905.17345.633888.927174@mithrandir.hornik.net><Pine.OSF.4.58.
	0502091008490.35024@odin.mdacc.tmc.edu>
	<16906.15874.681788.789761@mithrandir.hornik.net>
	<Pine.OSF.4.58.0502091102280.35024@odin.mdacc.tmc.edu>
Message-ID: <055B73F9-AE76-4168-81FE-0DF8F95D70A7@r-project.org>

On Feb 9, 2005, at 12:21 PM, Paul Roebuck wrote:
> On Wed, 9 Feb 2005, Kurt Hornik wrote:
>> I think the simplest way to achieve this is to configure R
>> locally (for yourself) with CFLAGS="-O2 -Wall -pedantic" but
>> leave the corresponding PKG_CFLAGS etc variables in package
>> src/Makevars alone.
> I can do that for workstations which I have admin priviledges
> and have a private version of R; how about the ones I don't?
I don't get your point - if you are not admin and don't use your own R 
version, how do you expect to change behavior of the R you don't have 
write access to? You can't, as admin doesn't want you to. This still 
doesn't prevent you from compiling the package for yourself in your 
home, including any flags you like. R allows you to change whatever you 
like for the package you compile.
Adding such flags as above in the package itself doesn't make any sense 
IMHO, as you should expect that whatever flags R was compiled with were 
specifically provided to steer optimizations etc. There are 
platform/compiler version combinations where -O2 breaks numerical 
computations, so overriding this for your package will override a 
choice which was done deliberately and you're not even aware of. In 
addition -Ox may have been specified already, so you may in fact 
downgrade the optimizations. At the time of compilation of the package 
the user is free to override any flags, so he can do so if he knows 
what he's doing. The current approach is good at preventing the user 
from doing bad things by default and producing consistent code.
What Kurt mentioned was just a way to reduce typing effort (and achieve 
more consistency) when specifying flags for packages you compile for 
yourself - you're still responsible for the content of the files you 
put there, so it's up to you to be aware of the issues you mentioned - 
R can't do that for you. You get what you tell R to do - there is no 
automatic protection against misuse ;).
Cheers,
Simon

From julia.luc at english.zzn.com  Wed Feb  9 20:58:40 2005
From: julia.luc at english.zzn.com (Julia)
Date: Wed Feb  9 20:02:29 2005
Subject: [Rd] Please read.
Message-ID: <3824-22005239195840140@ondo>

Hello!

I have something to share with you today - something that has made my difficult life easy and exciting. 

Click this 7-minute flash presentation and find out how this simple thing can change people's lives: http://yourfamilygoal.ws/show 

Make sure to turn on your speakers or put on your headphone.. 

I will be very glad to share with you my story. Don't hesitate to write me back for any question or help you need. 

All the best, 
Julia

From blindglobe at gmail.com  Wed Feb  9 20:07:02 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Wed Feb  9 20:07:12 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <16906.14032.589706.230256@mithrandir.hornik.net>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
	<16904.63694.9500.496681@mithrandir.hornik.net>
	<x21xbppw24.fsf@biostat.ku.dk>
	<16906.14032.589706.230256@mithrandir.hornik.net>
Message-ID: <1abe3fa905020911071a38acc9@mail.gmail.com>

On Wed, 9 Feb 2005 17:14:08 +0100, Kurt Hornik
<Kurt.Hornik@wu-wien.ac.at> wrote:
> >>>>> Peter Dalgaard writes:
> 
> > Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:
> >> >>>>> A J Rossini writes:
> >>
> >> > But I don't see a problem with "package("package")", though I'm sure
> >> > I'm missing something.
> >>
> >> package() [sic] might be the creator for package objects, provided we
> >> can decide on what they are (and what kind of packages [source,
> >> installed, ...] they are used for).
> >>
> >> usePackage() or use_package() otoh would indicate to "use" a package
> >> (i.e., load and attach it).  The tricky part is deciding about the
> >> interface (e.g., finally disallowing non-standard evaluation as it is a
> >> programmer's nightmare) and what it should return.  And that is work in
> >> progress ...
> 
> > Any information on the rate...? (I still vote for usepackage() btw.)
> 
> Why not use(), as the GCD?

Excellent suggestion, Kurt.

> > It would be good if we could at least have an outline of the intended
> > functionality and see if we could forge ahead and get a preliminary
> > version done in time for 2.1.x
> 
> Help us out.
> 
>         use <- function(package, pos = 2, lib.loc, ...)

use <- function(packageName,pos=2,library, ...)

I could argue that "library" and "lib.loc" try to describe the same
thing (a name and its pointer).

> where 'package' is either a character string or some sort of package
> object/reference, to be specified later.  And 'lib.loc' needs to have a
> different name if we rename libraries into stores or whatever ...

I think package ought to be a character string.   Unless you want to
combine the packageName and libraryLocation into some form of data
object, or packageName, libraryLocation, and an environment containing
the erstwhile contents?

> What should this return?  Currently, 'library' returns the list of
> loaded (or available) packages by default, as a list of names, which is
> not good enough.  So we need something like the DLLInfoList returned by
> getLoadedDLLs() (and the docs should actually mention that class), or
> something usable by the package management tools ... and this is under
> redesign as well.

Perhaps "use" should incorporate "require" functionality, i.e. TRUE or
FALSE depending on whether you can use it after the "use" function
call.

> 
> But why should this really return info on all loaded/attached packages?
> An alternative might be just returning the package meta-data in some
> form.  Or nothing, which would fit into the idea that it really does
> nothing apart from loading and attaching a package.

I like "libraryContents()" or similar to figure out loaded and
potentially loadable packages.


> (And maybe a condition object inheriting from packageLoadAndAttachError
> in case of failure? :-))

Yes.  whatever.


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From julia.luc at english.zzn.com  Wed Feb  9 20:59:05 2005
From: julia.luc at english.zzn.com (Julia)
Date: Wed Feb  9 20:15:01 2005
Subject: [Rd] Please read.
Message-ID: <3821-220052391959515@ondo>

Hello!

I have something to share with you today - something that has made my difficult life easy and exciting. 

Click this 7-minute flash presentation and find out how this simple thing can change people's lives: http://yourfamilygoal.ws/show 

Make sure to turn on your speakers or put on your headphone.. 

I will be very glad to share with you my story. Don't hesitate to write me back for any question or help you need. 

All the best, 
Julia

From roebuck at odin.mdacc.tmc.edu  Wed Feb  9 22:48:53 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed Feb  9 22:49:01 2005
Subject: [Rd] Re: Compiler-specific flags with PKG_CFLAGS
In-Reply-To: <16906.22133.310061.960069@mithrandir.hornik.net>
References: <16905.17345.633888.927174@mithrandir.hornik.net><Pine.OSF.4.58.
	0502091008490.35024@odin.mdacc.tmc.edu><16906.15874.681788.789761@mithrandi
	r.hornik.net><Pine.OSF.4.58.0502091102280.35024@odin.mdacc.tmc.edu>
	<16906.22133.310061.960069@mithrandir.hornik.net>
Message-ID: <Pine.OSF.4.58.0502091453330.46967@odin.mdacc.tmc.edu>

On Wed, 9 Feb 2005, Kurt Hornik wrote:

> >>>>> Paul Roebuck writes:
>
> > On Wed, 9 Feb 2005, Kurt Hornik wrote:
> >> >>>>> Paul Roebuck writes:
> >>
> >> > On Tue, 8 Feb 2005, Kurt Hornik wrote:
> >> >> This concerns the packages...
> >> >> for which current versions of r-devel now report problems with
> >> >> non-portable compilation flags in Makevars[.in] files:
> >> >>
> >> >> Problems in package 'rwt':
> >> >> Non-portable flags in variable 'PKG_CFLAGS':
> >> >> -Wall -ansi -pedantic
> >> >>
> >> >> These flags are mostly GCC specific and not portable.
> >> >> (Do not assume that any -Ox will work.)
> >> >>
> >> >> Can you please fix these problems, and provide an update of your
> >> >> package?
> >>
> >> > It has been on my todo list since Ripley brought it up
> >> > several weeks ago in r-devel but hadn't exactly figured
> >> > out how to package it as such. Someone have an example
> >> > of how to add compiler flags for GCC when it is being
> >> > used and otherwise not? I'm assuming Makevars isn't being
> >> > passed through cpp and I can't just use #ifdef. In this case,
> >> > I could just leave them out but I hate to lose the warnings
> >> > for development. Using 'configure' is probably the only
> >> > option but really didn't want to use it for just stricter
> >> > error checking during compilation.
> >>
> >> I think the simplest way to achieve this is to configure R
> >> locally (for yourself) with CFLAGS="-O2 -Wall -pedantic" but
> >> leave the corresponding PKG_CFLAGS etc variables in package
> >> src/Makevars alone.
>
> > I can do that for workstations which I have admin priviledges
> > and have a private version of R; how about the ones I don't?
>
> It depends: R-exts says
>
> 	Flags which are set in file `etc/Makeconf' can be overridden by
> 	the environment variable `MAKEFLAGS' (at least for systems using
> 	GNU `make'), as in (Bourne shell syntax)
>
> 	     MAKEFLAGS="CFLAGS=-O3" R CMD SHLIB *.c
>
> 	or by using a `Makefile'.
>
> so if you have GNU Make, you can actually set MAKEFLAGS accordingly in
> your R_ENVIRON file.
>
> What you can also try is to have a make (Sys.getenv("MAKE")) script in
> your PATH which does something like
>
> 	/path/to/real/make $* CFLAGS=-O3
>
> (but I am never sure whether command line vars override the ones in
> files?)

Thanks for the suggestions. Setting the environment prior to running
R CMD is not practical for me, typing-wise. I guess if made my
.Renviron file architecture-specific it might work, but that seems
overkill. That leaves writing a makefile, a script to rename
'src/Makevars' as 'src/Makevars_d' prior to upload, or adding the
file to my .Rbuildignore as I only really need to see the additional
warnings when running R CMD check.

> >> R 2.1.0 will provide a portable way of overriding the configured
> >> "site" compilation flags via user-level ~/.R/Makevars files.
>
> > Will this also cover how to merge or augment compilation
> > flags with the site-specified ones? And how will it handle
> > the situation where one's home directory is NFS mounted
> > across several architectures? There will be a variable to
> > override the default location, right?.
>
> No but there is
>
> 	~/.R/Makeconf-$platform
>
> where $platform is the same as in R_PLATFORM, which is looked for ahead
> of ~/.R/Makeconf.  (That should be better than having an R_MAKECONF env
> var.)
>
> Btw, I assume that if all Makes are GNU Make you might actually be able
> to conditionalize inside.

GNU make availability is unlikely at best. And I don't think
this approach is going to be much help for me. I only wanted
to augment the compiler settings for the packages I'm developing,
not override the ones for the R itself. You've managed to make
me think a package configure script might not be so hard after
all :)

Thanks for your insight.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From dwilhelm at evafunds.com  Wed Feb  9 23:00:46 2005
From: dwilhelm at evafunds.com (Dale Ryon Wilhelm)
Date: Wed Feb  9 23:01:01 2005
Subject: [Rd] install issue | suse 9.2
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A584E4B3@phost015.EVAFUNDS.intermedia.net>

hello all...

 

i am trying to install r v2.0.1 on my suse 9.2 pro box... when i run
configure, i get the following error:

 

checking how to get verbose linking output from g77... configure:
WARNING: compilation failed

 

checking for Fortran libraries of g77... 

checking for dummy main to link with Fortran libraries... none

checking for Fortran name-mangling scheme... configure: error: cannot
compile a simple Fortran program

See `config.log' for more details

 

anybody know why i am getting this error? g77 is installed correctly and
working properly... 

 

 

-<0>-

d. ryon wilhelm

EVNINE-VAUGHAN ASSOCIATES, INC.

415.835.7855

 


	[[alternative HTML version deleted]]

From ripley at stats.ox.ac.uk  Wed Feb  9 23:07:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb  9 23:07:44 2005
Subject: [Rd] install issue | suse 9.2
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A584E4B3@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A584E4B3@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.61.0502092205530.28907@gannet.stats>

It says

> See `config.log' for more details

Please look there and extract the information (and see the comment about 
HTML mail below).


On Wed, 9 Feb 2005, Dale Ryon Wilhelm wrote:

> i am trying to install r v2.0.1 on my suse 9.2 pro box... when i run
> configure, i get the following error:
>
>
>
> checking how to get verbose linking output from g77... configure:
> WARNING: compilation failed
>
>
>
> checking for Fortran libraries of g77...
>
> checking for dummy main to link with Fortran libraries... none
>
> checking for Fortran name-mangling scheme... configure: error: cannot
> compile a simple Fortran program
>
> See `config.log' for more details
>
>
>
> anybody know why i am getting this error? g77 is installed correctly and
> working properly...
>
>
>
>
>
> -<0>-
>
> d. ryon wilhelm
>
> EVNINE-VAUGHAN ASSOCIATES, INC.
>
> 415.835.7855
>
>
>
>
> 	[[alternative HTML version deleted]]

The posting guide does ask you not to send HTML mail.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Wed Feb  9 23:12:27 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed Feb  9 23:11:04 2005
Subject: [Rd] Environment with no parent?
In-Reply-To: <x2r7jqmxzy.fsf@biostat.ku.dk>
References: <nl2i01h7pffsdrsmrfoft00ro069e5n8cu@4ax.com>
	<x24qgmojys.fsf@biostat.ku.dk>
	<esci01p52n37u6urqulun6ts464rju564c@4ax.com>
	<x2r7jqmxzy.fsf@biostat.ku.dk>
Message-ID: <ud2l015knhftvkmtf2ir78esrsqicbka12@4ax.com>

On 09 Feb 2005 00:29:37 +0100, Peter Dalgaard
<p.dalgaard@biostat.ku.dk> wrote :

>Duncan Murdoch <murdoch@stats.uwo.ca> writes:
>
>> >(a) efficiency. Is it expensive no longer to have the base functions
>> >bound directly to their symbol? (My gut feeling is that with suitable
>> >hashing and cacheing, the penalty is minimal.)
>> >
>> >(b) you can *only* use get and simple variable retrieval in a non-base
>> >environment with a NULL parent (eval(x <- 1, envir=foo) would give
>> >'couldn't find function "<-"' or so). This could cause some confusion.
>> 
>> (b) means that the default should stay the way it is, but I think
>> there should be a way to set up a truly empty environment.  We have a
>> fair number of cases where envir=NULL is used, so it would be safest
>> to make it a different value -- even if NULL is the obvious value for
>> an empty environment.
>
>Not necessarily. It just means that you should think about it. It is
>not a given that envir=NULL really means what the author expected, and
>fixing them up to read envir=.BaseEnv is probably quite doable.

For the benefit of the archives:

Setting the NULL environment to contain nothing is nontrivial; even
creating a new magic environment that appeared to be empty would
require a surprising number of low-level changes.  So, rather than
take this on, I've decided on this R-only solution to my problem:  a
version of exists() that treats NULL as if it were empty:

# Modified exists function:  like exists(x, envir, inherits = TRUE),
except that a 
# NULL parent is considered empty

myexists <- function(x, envir) {
    result <- FALSE
    while (!result && !is.null(envir)) {
    	result <- exists(x, envir=envir, inherits = FALSE)
    	envir <- parent.env(envir)
    }
    result
}

Duncan Murdoch

From dwilhelm at evafunds.com  Wed Feb  9 23:30:17 2005
From: dwilhelm at evafunds.com (Dale Ryon Wilhelm)
Date: Wed Feb  9 23:30:32 2005
Subject: [Rd] install issue | suse 9.2
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A584E4BA@phost015.EVAFUNDS.intermedia.net>

looked thru config.log and got the following ( see below )... not
knowing much about fortran, this doesn't make much sense to me... my
apologies for the initial html message... 

configure:25460: checking how to get verbose linking output from g77
configure:25471: g77 -c  conftest.f >&5
/tmp/ccK3gsfu.s: Assembler messages:
/tmp/ccK3gsfu.s:8: Error: suffix or operands invalid for `push'
/tmp/ccK3gsfu.s:12: Error: suffix or operands invalid for `push'
/tmp/ccK3gsfu.s:13: Error: suffix or operands invalid for `push'
configure:25477: $? = 1
configure: failed program was:
|       program main
| 
|       end
configure:25556: WARNING: compilation failed
configure:25562: result: 
configure:25564: checking for Fortran libraries of g77
configure:25585: g77 -o conftest   -L/usr/local/lib conftest.f  >&5
/tmp/cclyaHyt.s: Assembler messages:
/tmp/cclyaHyt.s:8: Error: suffix or operands invalid for `push'
/tmp/cclyaHyt.s:12: Error: suffix or operands invalid for `push'
/tmp/cclyaHyt.s:13: Error: suffix or operands invalid for `push'
configure:25746: result: 
configure:25785: checking for dummy main to link with Fortran libraries
configure:25824: gcc -o conftest -g -O2 -I/usr/local/include
-L/usr/local/lib co
nftest.c -ldl -lm   >&5
configure:25830: $? = 0
configure:25834: test -z 
                         || test ! -s conftest.err
configure:25837: $? = 0
configure:25840: test -s conftest
configure:25843: $? = 0
configure:25921: result: none
configure:25958: checking for Fortran name-mangling scheme
configure:25972: g77 -c  conftest.f >&5
/tmp/ccpZMdHB.s: Assembler messages:
/tmp/ccpZMdHB.s:6: Error: suffix or operands invalid for `push'
/tmp/ccpZMdHB.s:8: Error: suffix or operands invalid for `pop'
/tmp/ccpZMdHB.s:14: Error: suffix or operands invalid for `push'
/tmp/ccpZMdHB.s:16: Error: suffix or operands invalid for `pop'
configure:25978: $? = 1
configure: failed program was:
|       subroutine foobar()
|       return
|       end
|       subroutine foo_bar()
|       return
|       end
configure:26186: error: cannot compile a simple Fortran program
See `config.log' for more details.




-----Original Message-----
From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk] 
Sent: Wednesday, February 09, 2005 2:08 PM
To: Dale Ryon Wilhelm
Cc: r-devel@stat.math.ethz.ch
Subject: Re: [Rd] install issue | suse 9.2

It says

> See `config.log' for more details

Please look there and extract the information (and see the comment about

HTML mail below).


On Wed, 9 Feb 2005, Dale Ryon Wilhelm wrote:

> i am trying to install r v2.0.1 on my suse 9.2 pro box... when i run
> configure, i get the following error:
>
>
>
> checking how to get verbose linking output from g77... configure:
> WARNING: compilation failed
>
>
>
> checking for Fortran libraries of g77...
>
> checking for dummy main to link with Fortran libraries... none
>
> checking for Fortran name-mangling scheme... configure: error: cannot
> compile a simple Fortran program
>
> See `config.log' for more details
>
>
>
> anybody know why i am getting this error? g77 is installed correctly
and
> working properly...
>
>
>
>
>
> -<0>-
>
> d. ryon wilhelm
>
> EVNINE-VAUGHAN ASSOCIATES, INC.
>
> 415.835.7855
>
>
>
>
> 	[[alternative HTML version deleted]]

The posting guide does ask you not to send HTML mail.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Feb  9 23:43:05 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb  9 23:43:15 2005
Subject: [Rd] install issue | suse 9.2
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A584E4BA@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A584E4BA@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.61.0502092237570.4876@gannet.stats>

Your assembler and your g77 don't match.  What platform is this, and is 
the g77 for the right platform (e.g. not x86_64 on ix86)?

We can only guess why, but your Fortran compiler is not working correctly
and you need to seek SuSE-specific help.

On Wed, 9 Feb 2005, Dale Ryon Wilhelm wrote:

> looked thru config.log and got the following ( see below )... not
> knowing much about fortran, this doesn't make much sense to me... my
> apologies for the initial html message...
>
> configure:25460: checking how to get verbose linking output from g77
> configure:25471: g77 -c  conftest.f >&5
> /tmp/ccK3gsfu.s: Assembler messages:
> /tmp/ccK3gsfu.s:8: Error: suffix or operands invalid for `push'
> /tmp/ccK3gsfu.s:12: Error: suffix or operands invalid for `push'
> /tmp/ccK3gsfu.s:13: Error: suffix or operands invalid for `push'
> configure:25477: $? = 1
> configure: failed program was:
> |       program main
> |
> |       end
> configure:25556: WARNING: compilation failed
> configure:25562: result:
> configure:25564: checking for Fortran libraries of g77
> configure:25585: g77 -o conftest   -L/usr/local/lib conftest.f  >&5
> /tmp/cclyaHyt.s: Assembler messages:
> /tmp/cclyaHyt.s:8: Error: suffix or operands invalid for `push'
> /tmp/cclyaHyt.s:12: Error: suffix or operands invalid for `push'
> /tmp/cclyaHyt.s:13: Error: suffix or operands invalid for `push'
> configure:25746: result:
> configure:25785: checking for dummy main to link with Fortran libraries
> configure:25824: gcc -o conftest -g -O2 -I/usr/local/include
> -L/usr/local/lib co
> nftest.c -ldl -lm   >&5
> configure:25830: $? = 0
> configure:25834: test -z
>                         || test ! -s conftest.err
> configure:25837: $? = 0
> configure:25840: test -s conftest
> configure:25843: $? = 0
> configure:25921: result: none
> configure:25958: checking for Fortran name-mangling scheme
> configure:25972: g77 -c  conftest.f >&5
> /tmp/ccpZMdHB.s: Assembler messages:
> /tmp/ccpZMdHB.s:6: Error: suffix or operands invalid for `push'
> /tmp/ccpZMdHB.s:8: Error: suffix or operands invalid for `pop'
> /tmp/ccpZMdHB.s:14: Error: suffix or operands invalid for `push'
> /tmp/ccpZMdHB.s:16: Error: suffix or operands invalid for `pop'
> configure:25978: $? = 1
> configure: failed program was:
> |       subroutine foobar()
> |       return
> |       end
> |       subroutine foo_bar()
> |       return
> |       end
> configure:26186: error: cannot compile a simple Fortran program
> See `config.log' for more details.
>
>
>
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk]
> Sent: Wednesday, February 09, 2005 2:08 PM
> To: Dale Ryon Wilhelm
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] install issue | suse 9.2
>
> It says
>
>> See `config.log' for more details
>
> Please look there and extract the information (and see the comment about
>
> HTML mail below).
>
>
> On Wed, 9 Feb 2005, Dale Ryon Wilhelm wrote:
>
>> i am trying to install r v2.0.1 on my suse 9.2 pro box... when i run
>> configure, i get the following error:
>>
>>
>>
>> checking how to get verbose linking output from g77... configure:
>> WARNING: compilation failed
>>
>>
>>
>> checking for Fortran libraries of g77...
>>
>> checking for dummy main to link with Fortran libraries... none
>>
>> checking for Fortran name-mangling scheme... configure: error: cannot
>> compile a simple Fortran program
>>
>> See `config.log' for more details
>>
>>
>>
>> anybody know why i am getting this error? g77 is installed correctly
> and
>> working properly...
>>
>>
>>
>>
>>
>> -<0>-
>>
>> d. ryon wilhelm
>>
>> EVNINE-VAUGHAN ASSOCIATES, INC.
>>
>> 415.835.7855
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>
> The posting guide does ask you not to send HTML mail.
>
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Wed Feb  9 23:53:50 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed Feb  9 23:58:26 2005
Subject: [Rd] install issue | suse 9.2
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A584E4BA@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A584E4BA@phost015.EVAFUNDS.intermedia.net>
Message-ID: <x2vf91fipt.fsf@biostat.ku.dk>

It's not endemic to suse 9.2 (compile running as I write this).

Google finds some messages from the amd64 list with similar error
messages. Any chance you are running a 64bit OS and mixing up 32 and
64bit tool chains? 

rpm -qf `which gas`
rpm -qf `which g77` 

could be revealing.


"Dale Ryon Wilhelm" <dwilhelm@evafunds.com> writes:

> looked thru config.log and got the following ( see below )... not
> knowing much about fortran, this doesn't make much sense to me... my
> apologies for the initial html message... 
> 
> configure:25460: checking how to get verbose linking output from g77
> configure:25471: g77 -c  conftest.f >&5
> /tmp/ccK3gsfu.s: Assembler messages:
> /tmp/ccK3gsfu.s:8: Error: suffix or operands invalid for `push'
> /tmp/ccK3gsfu.s:12: Error: suffix or operands invalid for `push'
> /tmp/ccK3gsfu.s:13: Error: suffix or operands invalid for `push'
> configure:25477: $? = 1
> configure: failed program was:
> |       program main
> | 
> |       end
> configure:25556: WARNING: compilation failed
> configure:25562: result: 
> configure:25564: checking for Fortran libraries of g77
> configure:25585: g77 -o conftest   -L/usr/local/lib conftest.f  >&5
> /tmp/cclyaHyt.s: Assembler messages:
> /tmp/cclyaHyt.s:8: Error: suffix or operands invalid for `push'
> /tmp/cclyaHyt.s:12: Error: suffix or operands invalid for `push'
> /tmp/cclyaHyt.s:13: Error: suffix or operands invalid for `push'
> configure:25746: result: 
> configure:25785: checking for dummy main to link with Fortran libraries
> configure:25824: gcc -o conftest -g -O2 -I/usr/local/include
> -L/usr/local/lib co
> nftest.c -ldl -lm   >&5
> configure:25830: $? = 0
> configure:25834: test -z 
>                          || test ! -s conftest.err
> configure:25837: $? = 0
> configure:25840: test -s conftest
> configure:25843: $? = 0
> configure:25921: result: none
> configure:25958: checking for Fortran name-mangling scheme
> configure:25972: g77 -c  conftest.f >&5
> /tmp/ccpZMdHB.s: Assembler messages:
> /tmp/ccpZMdHB.s:6: Error: suffix or operands invalid for `push'
> /tmp/ccpZMdHB.s:8: Error: suffix or operands invalid for `pop'
> /tmp/ccpZMdHB.s:14: Error: suffix or operands invalid for `push'
> /tmp/ccpZMdHB.s:16: Error: suffix or operands invalid for `pop'
> configure:25978: $? = 1
> configure: failed program was:
> |       subroutine foobar()
> |       return
> |       end
> |       subroutine foo_bar()
> |       return
> |       end
> configure:26186: error: cannot compile a simple Fortran program
> See `config.log' for more details.
> 
> 
> 
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk] 
> Sent: Wednesday, February 09, 2005 2:08 PM
> To: Dale Ryon Wilhelm
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] install issue | suse 9.2
> 
> It says
> 
> > See `config.log' for more details
> 
> Please look there and extract the information (and see the comment about
> 
> HTML mail below).
> 
> 
> On Wed, 9 Feb 2005, Dale Ryon Wilhelm wrote:
> 
> > i am trying to install r v2.0.1 on my suse 9.2 pro box... when i run
> > configure, i get the following error:
> >
> >
> >
> > checking how to get verbose linking output from g77... configure:
> > WARNING: compilation failed
> >
> >
> >
> > checking for Fortran libraries of g77...
> >
> > checking for dummy main to link with Fortran libraries... none
> >
> > checking for Fortran name-mangling scheme... configure: error: cannot
> > compile a simple Fortran program
> >
> > See `config.log' for more details
> >
> >
> >
> > anybody know why i am getting this error? g77 is installed correctly
> and
> > working properly...
> >
> >
> >
> >
> >
> > -<0>-
> >
> > d. ryon wilhelm
> >
> > EVNINE-VAUGHAN ASSOCIATES, INC.
> >
> > 415.835.7855
> >
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> 
> The posting guide does ask you not to send HTML mail.
> 
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dwilhelm at evafunds.com  Thu Feb 10 00:15:53 2005
From: dwilhelm at evafunds.com (Dale Ryon Wilhelm)
Date: Thu Feb 10 00:16:09 2005
Subject: [Rd] install issue | suse 9.2
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A584E4CE@phost015.EVAFUNDS.intermedia.net>

that seems to have been it... i installed 32bit gcc-g77... replaced
everything with 64it version and it configure completes... thank you for
your help... 

-----Original Message-----
From: Peter Dalgaard [mailto:p.dalgaard@biostat.ku.dk] 
Sent: Wednesday, February 09, 2005 2:54 PM
To: Dale Ryon Wilhelm
Cc: Prof Brian Ripley; r-devel@stat.math.ethz.ch
Subject: Re: [Rd] install issue | suse 9.2

It's not endemic to suse 9.2 (compile running as I write this).

Google finds some messages from the amd64 list with similar error
messages. Any chance you are running a 64bit OS and mixing up 32 and
64bit tool chains? 

rpm -qf `which gas`
rpm -qf `which g77` 

could be revealing.


"Dale Ryon Wilhelm" <dwilhelm@evafunds.com> writes:

> looked thru config.log and got the following ( see below )... not
> knowing much about fortran, this doesn't make much sense to me... my
> apologies for the initial html message... 
> 
> configure:25460: checking how to get verbose linking output from g77
> configure:25471: g77 -c  conftest.f >&5
> /tmp/ccK3gsfu.s: Assembler messages:
> /tmp/ccK3gsfu.s:8: Error: suffix or operands invalid for `push'
> /tmp/ccK3gsfu.s:12: Error: suffix or operands invalid for `push'
> /tmp/ccK3gsfu.s:13: Error: suffix or operands invalid for `push'
> configure:25477: $? = 1
> configure: failed program was:
> |       program main
> | 
> |       end
> configure:25556: WARNING: compilation failed
> configure:25562: result: 
> configure:25564: checking for Fortran libraries of g77
> configure:25585: g77 -o conftest   -L/usr/local/lib conftest.f  >&5
> /tmp/cclyaHyt.s: Assembler messages:
> /tmp/cclyaHyt.s:8: Error: suffix or operands invalid for `push'
> /tmp/cclyaHyt.s:12: Error: suffix or operands invalid for `push'
> /tmp/cclyaHyt.s:13: Error: suffix or operands invalid for `push'
> configure:25746: result: 
> configure:25785: checking for dummy main to link with Fortran
libraries
> configure:25824: gcc -o conftest -g -O2 -I/usr/local/include
> -L/usr/local/lib co
> nftest.c -ldl -lm   >&5
> configure:25830: $? = 0
> configure:25834: test -z 
>                          || test ! -s conftest.err
> configure:25837: $? = 0
> configure:25840: test -s conftest
> configure:25843: $? = 0
> configure:25921: result: none
> configure:25958: checking for Fortran name-mangling scheme
> configure:25972: g77 -c  conftest.f >&5
> /tmp/ccpZMdHB.s: Assembler messages:
> /tmp/ccpZMdHB.s:6: Error: suffix or operands invalid for `push'
> /tmp/ccpZMdHB.s:8: Error: suffix or operands invalid for `pop'
> /tmp/ccpZMdHB.s:14: Error: suffix or operands invalid for `push'
> /tmp/ccpZMdHB.s:16: Error: suffix or operands invalid for `pop'
> configure:25978: $? = 1
> configure: failed program was:
> |       subroutine foobar()
> |       return
> |       end
> |       subroutine foo_bar()
> |       return
> |       end
> configure:26186: error: cannot compile a simple Fortran program
> See `config.log' for more details.
> 
> 
> 
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk] 
> Sent: Wednesday, February 09, 2005 2:08 PM
> To: Dale Ryon Wilhelm
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] install issue | suse 9.2
> 
> It says
> 
> > See `config.log' for more details
> 
> Please look there and extract the information (and see the comment
about
> 
> HTML mail below).
> 
> 
> On Wed, 9 Feb 2005, Dale Ryon Wilhelm wrote:
> 
> > i am trying to install r v2.0.1 on my suse 9.2 pro box... when i run
> > configure, i get the following error:
> >
> >
> >
> > checking how to get verbose linking output from g77... configure:
> > WARNING: compilation failed
> >
> >
> >
> > checking for Fortran libraries of g77...
> >
> > checking for dummy main to link with Fortran libraries... none
> >
> > checking for Fortran name-mangling scheme... configure: error:
cannot
> > compile a simple Fortran program
> >
> > See `config.log' for more details
> >
> >
> >
> > anybody know why i am getting this error? g77 is installed correctly
> and
> > working properly...
> >
> >
> >
> >
> >
> > -<0>-
> >
> > d. ryon wilhelm
> >
> > EVNINE-VAUGHAN ASSOCIATES, INC.
> >
> > 415.835.7855
> >
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> 
> The posting guide does ask you not to send HTML mail.
> 
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Kurt.Hornik at wu-wien.ac.at  Thu Feb 10 08:17:29 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Feb 10 08:27:52 2005
Subject: [Rd] Re: Compiler-specific flags with PKG_CFLAGS
In-Reply-To: <Pine.OSF.4.58.0502091453330.46967@odin.mdacc.tmc.edu>
References: <16905.17345.633888.927174@mithrandir.hornik.net> <Pine.OSF.4.58.
	0502091008490.35024@odin.mdacc.tmc.edu>
	<16906.15874.681788.789761@mithrandi r.hornik.net>
	<Pine.OSF.4.58.0502091102280.35024@odin.mdacc.tmc.edu>
	<16906.22133.310061.960069@mithrandir.hornik.net>
	<Pine.OSF.4.58.0502091453330.46967@odin.mdacc.tmc.edu>
Message-ID: <16907.2697.496058.230009@mithrandir.hornik.net>

>>>>> Paul Roebuck writes:

> On Wed, 9 Feb 2005, Kurt Hornik wrote:
>> >>>>> Paul Roebuck writes:
>> 
>> > On Wed, 9 Feb 2005, Kurt Hornik wrote:
>> >> >>>>> Paul Roebuck writes:
>> >>
>> >> > On Tue, 8 Feb 2005, Kurt Hornik wrote:
>> >> >> This concerns the packages...
>> >> >> for which current versions of r-devel now report problems with
>> >> >> non-portable compilation flags in Makevars[.in] files:
>> >> >>
>> >> >> Problems in package 'rwt':
>> >> >> Non-portable flags in variable 'PKG_CFLAGS':
>> >> >> -Wall -ansi -pedantic
>> >> >>
>> >> >> These flags are mostly GCC specific and not portable.
>> >> >> (Do not assume that any -Ox will work.)
>> >> >>
>> >> >> Can you please fix these problems, and provide an update of your
>> >> >> package?
>> >>
>> >> > It has been on my todo list since Ripley brought it up
>> >> > several weeks ago in r-devel but hadn't exactly figured
>> >> > out how to package it as such. Someone have an example
>> >> > of how to add compiler flags for GCC when it is being
>> >> > used and otherwise not? I'm assuming Makevars isn't being
>> >> > passed through cpp and I can't just use #ifdef. In this case,
>> >> > I could just leave them out but I hate to lose the warnings
>> >> > for development. Using 'configure' is probably the only
>> >> > option but really didn't want to use it for just stricter
>> >> > error checking during compilation.
>> >>
>> >> I think the simplest way to achieve this is to configure R
>> >> locally (for yourself) with CFLAGS="-O2 -Wall -pedantic" but
>> >> leave the corresponding PKG_CFLAGS etc variables in package
>> >> src/Makevars alone.
>> 
>> > I can do that for workstations which I have admin priviledges
>> > and have a private version of R; how about the ones I don't?
>> 
>> It depends: R-exts says
>> 
>> Flags which are set in file `etc/Makeconf' can be overridden by
>> the environment variable `MAKEFLAGS' (at least for systems using
>> GNU `make'), as in (Bourne shell syntax)
>> 
>> MAKEFLAGS="CFLAGS=-O3" R CMD SHLIB *.c
>> 
>> or by using a `Makefile'.
>> 
>> so if you have GNU Make, you can actually set MAKEFLAGS accordingly in
>> your R_ENVIRON file.
>> 
>> What you can also try is to have a make (Sys.getenv("MAKE")) script in
>> your PATH which does something like
>> 
>> /path/to/real/make $* CFLAGS=-O3
>> 
>> (but I am never sure whether command line vars override the ones in
>> files?)

> Thanks for the suggestions. Setting the environment prior to running
> R CMD is not practical for me, typing-wise. I guess if made my
> .Renviron file architecture-specific it might work, but that seems
> overkill.

Also, I forgot that it does not work, because R CMD only sources
R_HOME/etc/Renviron, but not the user level Renviron file.

This is really why we need the new mechanism ...

-k

From Kurt.Hornik at wu-wien.ac.at  Thu Feb 10 08:53:03 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Feb 10 08:53:13 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <1abe3fa905020911071a38acc9@mail.gmail.com>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
	<16904.63694.9500.496681@mithrandir.hornik.net>
	<x21xbppw24.fsf@biostat.ku.dk>
	<16906.14032.589706.230256@mithrandir.hornik.net>
	<1abe3fa905020911071a38acc9@mail.gmail.com>
Message-ID: <16907.4831.197685.285594@mithrandir.hornik.net>

>>>>> A J Rossini writes:

> On Wed, 9 Feb 2005 17:14:08 +0100, Kurt Hornik
> <Kurt.Hornik@wu-wien.ac.at> wrote:
>> >>>>> Peter Dalgaard writes:
>> 
>> > Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:
>> >> >>>>> A J Rossini writes:
>> >>
>> >> > But I don't see a problem with "package("package")", though I'm sure
>> >> > I'm missing something.
>> >>
>> >> package() [sic] might be the creator for package objects, provided we
>> >> can decide on what they are (and what kind of packages [source,
>> >> installed, ...] they are used for).
>> >>
>> >> usePackage() or use_package() otoh would indicate to "use" a package
>> >> (i.e., load and attach it).  The tricky part is deciding about the
>> >> interface (e.g., finally disallowing non-standard evaluation as it is a
>> >> programmer's nightmare) and what it should return.  And that is work in
>> >> progress ...
>> 
>> > Any information on the rate...? (I still vote for usepackage() btw.)
>> 
>> Why not use(), as the GCD?

> Excellent suggestion, Kurt.

And so obvious :-)

>> > It would be good if we could at least have an outline of the intended
>> > functionality and see if we could forge ahead and get a preliminary
>> > version done in time for 2.1.x
>> 
>> Help us out.
>> 
>> use <- function(package, pos = 2, lib.loc, ...)

> use <- function(packageName,pos=2,library, ...)

> I could argue that "library" and "lib.loc" try to describe the same
> thing (a name and its pointer).

We need to decide whether to stay with the "library" concept, or maybe
go for another one alongside.

>> where 'package' is either a character string or some sort of package
>> object/reference, to be specified later.  And 'lib.loc' needs to have a
>> different name if we rename libraries into stores or whatever ...

> I think package ought to be a character string.   Unless you want to
> combine the packageName and libraryLocation into some form of data
> object, or packageName, libraryLocation, and an environment containing
> the erstwhile contents?

For the time being, the package would definitely be specified as a
character string with its name.  But [RG will like this] I find it
rather clumsy to have tons of equal-level arguments which in fact could
use some hierarchical structure.  What we really want is some
SPECIFICATION of the package to be used, definitely including its name,
but maybe also where it should come from (library location) or which
version it should have at least or at most, etc.  So something like

   use(package_spec("foo", version = ~ > "1.5.8"), pos = 12, ...)

>> What should this return?  Currently, 'library' returns the list of
>> loaded (or available) packages by default, as a list of names, which is
>> not good enough.  So we need something like the DLLInfoList returned by
>> getLoadedDLLs() (and the docs should actually mention that class), or
>> something usable by the package management tools ... and this is under
>> redesign as well.

> Perhaps "use" should incorporate "require" functionality, i.e. TRUE or
> FALSE depending on whether you can use it after the "use" function
> call.

As Brian said, we would most likely get rid of library() alongside.

I would condiser the TRUE/FALSE paradigm outdated.  The FALSE case
really consists of a variety or error conditions, and we should return
these as such (rather than indicating "oh there was some problem but
were not telling you which one, unless you are a human reader and look
at the condition message ...").

>> 
>> But why should this really return info on all loaded/attached packages?
>> An alternative might be just returning the package meta-data in some
>> form.  Or nothing, which would fit into the idea that it really does
>> nothing apart from loading and attaching a package.

> I like "libraryContents()" or similar to figure out loaded and
> potentially loadable packages.

installed.packages() for the time being.

>> (And maybe a condition object inheriting from packageLoadAndAttachError
>> in case of failure? :-))

> Yes.  whatever.

-k

From blindglobe at gmail.com  Thu Feb 10 11:11:57 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu Feb 10 11:12:05 2005
Subject: [Rd] Re: Packages and Libraries (was: Re: lme4 "package" etc ..)
In-Reply-To: <16907.4831.197685.285594@mithrandir.hornik.net>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
	<16904.63694.9500.496681@mithrandir.hornik.net>
	<x21xbppw24.fsf@biostat.ku.dk>
	<16906.14032.589706.230256@mithrandir.hornik.net>
	<1abe3fa905020911071a38acc9@mail.gmail.com>
	<16907.4831.197685.285594@mithrandir.hornik.net>
Message-ID: <1abe3fa905021002113206ca34@mail.gmail.com>

Full agreement.  Thanks, Kurt.


On Thu, 10 Feb 2005 08:53:03 +0100, Kurt Hornik
<Kurt.Hornik@wu-wien.ac.at> wrote:
> >>>>> A J Rossini writes:
> 
> > On Wed, 9 Feb 2005 17:14:08 +0100, Kurt Hornik
> > <Kurt.Hornik@wu-wien.ac.at> wrote:
> >> >>>>> Peter Dalgaard writes:
> >>
> >> > Kurt Hornik <Kurt.Hornik@wu-wien.ac.at> writes:
> >> >> >>>>> A J Rossini writes:
> >> >>
> >> >> > But I don't see a problem with "package("package")", though I'm sure
> >> >> > I'm missing something.
> >> >>
> >> >> package() [sic] might be the creator for package objects, provided we
> >> >> can decide on what they are (and what kind of packages [source,
> >> >> installed, ...] they are used for).
> >> >>
> >> >> usePackage() or use_package() otoh would indicate to "use" a package
> >> >> (i.e., load and attach it).  The tricky part is deciding about the
> >> >> interface (e.g., finally disallowing non-standard evaluation as it is a
> >> >> programmer's nightmare) and what it should return.  And that is work in
> >> >> progress ...
> >>
> >> > Any information on the rate...? (I still vote for usepackage() btw.)
> >>
> >> Why not use(), as the GCD?
> 
> > Excellent suggestion, Kurt.
> 
> And so obvious :-)
> 
> >> > It would be good if we could at least have an outline of the intended
> >> > functionality and see if we could forge ahead and get a preliminary
> >> > version done in time for 2.1.x
> >>
> >> Help us out.
> >>
> >> use <- function(package, pos = 2, lib.loc, ...)
> 
> > use <- function(packageName,pos=2,library, ...)
> 
> > I could argue that "library" and "lib.loc" try to describe the same
> > thing (a name and its pointer).
> 
> We need to decide whether to stay with the "library" concept, or maybe
> go for another one alongside.
> 
> >> where 'package' is either a character string or some sort of package
> >> object/reference, to be specified later.  And 'lib.loc' needs to have a
> >> different name if we rename libraries into stores or whatever ...
> 
> > I think package ought to be a character string.   Unless you want to
> > combine the packageName and libraryLocation into some form of data
> > object, or packageName, libraryLocation, and an environment containing
> > the erstwhile contents?
> 
> For the time being, the package would definitely be specified as a
> character string with its name.  But [RG will like this] I find it
> rather clumsy to have tons of equal-level arguments which in fact could
> use some hierarchical structure.  What we really want is some
> SPECIFICATION of the package to be used, definitely including its name,
> but maybe also where it should come from (library location) or which
> version it should have at least or at most, etc.  So something like
> 
>   use(package_spec("foo", version = ~ > "1.5.8"), pos = 12, ...)
> 
> >> What should this return?  Currently, 'library' returns the list of
> >> loaded (or available) packages by default, as a list of names, which is
> >> not good enough.  So we need something like the DLLInfoList returned by
> >> getLoadedDLLs() (and the docs should actually mention that class), or
> >> something usable by the package management tools ... and this is under
> >> redesign as well.
> 
> > Perhaps "use" should incorporate "require" functionality, i.e. TRUE or
> > FALSE depending on whether you can use it after the "use" function
> > call.
> 
> As Brian said, we would most likely get rid of library() alongside.
> 
> I would condiser the TRUE/FALSE paradigm outdated.  The FALSE case
> really consists of a variety or error conditions, and we should return
> these as such (rather than indicating "oh there was some problem but
> were not telling you which one, unless you are a human reader and look
> at the condition message ...").
> 
> >>
> >> But why should this really return info on all loaded/attached packages?
> >> An alternative might be just returning the package meta-data in some
> >> form.  Or nothing, which would fit into the idea that it really does
> >> nothing apart from loading and attaching a package.
> 
> > I like "libraryContents()" or similar to figure out loaded and
> > potentially loadable packages.
> 
> installed.packages() for the time being.
> 
> >> (And maybe a condition object inheriting from packageLoadAndAttachError
> >> in case of failure? :-))
> 
> > Yes.  whatever.
> 
> -k
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe@gmail.com

From B.Rowlingson at lancaster.ac.uk  Thu Feb 10 11:29:51 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu Feb 10 11:29:58 2005
Subject: [Rd] Re: Packages and Libraries
In-Reply-To: <1abe3fa905021002113206ca34@mail.gmail.com>
References: <42088443.2090206@wiwi.uni-bielefeld.de>	<16904.39235.910508.75875@stat.math.ethz.ch>	<1abe3fa9050208043374d362df@mail.gmail.com>	<16904.51238.148743.149665@stat.math.ethz.ch>	<1abe3fa905020808481647d78d@mail.gmail.com>	<16904.63694.9500.496681@mithrandir.hornik.net>	<x21xbppw24.fsf@biostat.ku.dk>	<16906.14032.589706.230256@mithrandir.hornik.net>	<1abe3fa905020911071a38acc9@mail.gmail.com>	<16907.4831.197685.285594@mithrandir.hornik.net>
	<1abe3fa905021002113206ca34@mail.gmail.com>
Message-ID: <420B379F.8090609@lancaster.ac.uk>

A.J. Rossini wrote:

   use(package_spec("foo", version = ~ > "1.5.8"), pos = 12, ...)

  What else might you 'use'? .RData files perhaps? Dynamic links to 
databases? Is this going to turn into a monster that consumes library() 
and attach()? Not that that might be a bad thing, there's a very fine 
line between them at times...

Baz

From W-CMESP-001 at clarkemodet.com  Thu Feb 10 11:59:25 2005
From: W-CMESP-001 at clarkemodet.com (W-CMESP-001@clarkemodet.com)
Date: Thu Feb 10 12:00:58 2005
Subject: [Rd] Informar al remitente
Message-ID: <OFF5FC79A9.6D9116A1-ONC1256FA4.003C5F56@clarkemodet.com>





Informaci?n de incidente:-

Base de datos:       c:/lotus/domino/data/mail.box
Originador:          r-devel@r-project.org
Destinatarios:       w-cmesp-001@clarkemodet.com
Asunto:              Hi
Fecha/Hora:          10/02/2005 11:59:19

El adjunto Important.zip que envi? a los destinatarios que figuran m?s
arriba fueron infectados con el virus W32/Netsky.z@MM!zip y el mismo se
limpi? correctamente.

From Kurt.Hornik at wu-wien.ac.at  Thu Feb 10 14:06:57 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu Feb 10 14:07:03 2005
Subject: [Rd] Re: Packages and Libraries
In-Reply-To: <420B379F.8090609@lancaster.ac.uk>
References: <42088443.2090206@wiwi.uni-bielefeld.de>
	<16904.39235.910508.75875@stat.math.ethz.ch>
	<1abe3fa9050208043374d362df@mail.gmail.com>
	<16904.51238.148743.149665@stat.math.ethz.ch>
	<1abe3fa905020808481647d78d@mail.gmail.com>
	<16904.63694.9500.496681@mithrandir.hornik.net>
	<x21xbppw24.fsf@biostat.ku.dk>
	<16906.14032.589706.230256@mithrandir.hornik.net>
	<1abe3fa905020911071a38acc9@mail.gmail.com>
	<16907.4831.197685.285594@mithrandir.hornik.net>
	<1abe3fa905021002113206ca34@mail.gmail.com>
	<420B379F.8090609@lancaster.ac.uk>
Message-ID: <16907.23665.652538.491508@mithrandir.hornik.net>

>>>>> Barry Rowlingson writes:

> A.J. Rossini wrote:
>    use(package_spec("foo", version = ~ > "1.5.8"), pos = 12, ...)

>   What else might you 'use'? .RData files perhaps? Dynamic links to 
> databases?

Conceptually, things than can give RObjectTables as in DTLs package.

-k

> Is this going to turn into a monster that consumes library() and
> attach()? Not that that might be a bad thing, there's a very fine line
> between them at times...

> Baz

> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From wolski at molgen.mpg.de  Thu Feb 10 16:06:18 2005
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Thu Feb 10 16:06:39 2005
Subject: [Rd] Undocumented S4 methods: generic coerce and siglist matrix,
	Massvector
Message-ID: <420B786A.6070009@molgen.mpg.de>

Hi,
While checking the package I am getting all the time the following 
complain about the function:


Undocumented S4 methods:
  generic coerce and siglist matrix,Massvector


I have not defined the function nowhere in the R files.
My gues is that this has something to do with the following definition 
of the setAs function.

setAs("matrix","Massvector"
      ,def= function(from)
      {
        return(new("Massvector",from))
      }
      )

The problem is not to cheat the check mechanism. I knew that the warning 
can be elminitad by by defining an alias of this function in one of the 
Rd files.

Yours

Eryk

-- 
Dipl. bio-chem. Witold Eryk Wolski
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin
tel: 0049-30-83875219                 __("<    _
http://www.molgen.mpg.de/~wolski      \__/    'v'
http://r4proteomics.sourceforge.net    ||    /   \
mail: witek96@users.sourceforge.net    ^^     m m
      wolski@molgen.mpg.de

From tomhopper at comcast.net  Thu Feb 10 17:30:11 2005
From: tomhopper at comcast.net (tomhopper@comcast.net)
Date: Thu Feb 10 17:30:19 2005
Subject: [Rd] hist() error when prob=NULL (PR#7682)
Message-ID: <20050210163011.D3450DEEB@slim.kubism.ku.dk>

Full_Name: Tom Hopper
Version: 2.0.1
OS: Windows 2000
Submission from: (NULL) (69.220.229.2)


While attempting to wrap hist() in my own custom function (for formatting
purposes), I notice that a call like

   > hist(x, prob=NULL)

produces the output:

   Error in if (freq) x$counts else { : argument is of length zero

Switching to use freq does not produce an error, even when freq = NULL.

It appears that hist() is checking for the condition

   !missing(prob)

but needs to add a check for a NULL value

   && !is.null(prob)

From ripley at stats.ox.ac.uk  Thu Feb 10 18:11:44 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Feb 10 18:11:58 2005
Subject: [Rd] hist() error when prob=NULL (PR#7682)
In-Reply-To: <20050210163011.D3450DEEB@slim.kubism.ku.dk>
References: <20050210163011.D3450DEEB@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502101708130.17476@gannet.stats>

According to the help page, freq and prob are logical, so this is 
correctly an error.

What it actually does is

         freq <- if (!missing(probability)) !as.logical(probability)

which is consistent with the documentation.


On Thu, 10 Feb 2005 tomhopper@comcast.net wrote:

> Full_Name: Tom Hopper
> Version: 2.0.1
> OS: Windows 2000
> Submission from: (NULL) (69.220.229.2)
>
>
> While attempting to wrap hist() in my own custom function (for formatting
> purposes), I notice that a call like
>
>   > hist(x, prob=NULL)
>
> produces the output:
>
>   Error in if (freq) x$counts else { : argument is of length zero
>
> Switching to use freq does not produce an error, even when freq = NULL.
>
> It appears that hist() is checking for the condition
>
>   !missing(prob)
>
> but needs to add a check for a NULL value
>
>   && !is.null(prob)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jmc at R-project.org  Thu Feb 10 21:01:26 2005
From: jmc at R-project.org (John Chambers)
Date: Thu Feb 10 21:01:36 2005
Subject: [Rd] Undocumented S4 methods: generic coerce and siglist matrix, 
	Massvector
In-Reply-To: <420B786A.6070009@molgen.mpg.de>
References: <420B786A.6070009@molgen.mpg.de>
Message-ID: <420BBD96.5090301@R-project.org>



Witold Eryk Wolski wrote:
> Hi,
> While checking the package I am getting all the time the following 
> complain about the function:
> 
> 
> Undocumented S4 methods:
>  generic coerce and siglist matrix,Massvector
> 
> 
> I have not defined the function nowhere in the R files.
> My gues is that this has something to do with the following definition 
> of the setAs function.
> 
> setAs("matrix","Massvector"
>      ,def= function(from)
>      {
>        return(new("Massvector",from))
>      }
>      )

It certainly does.  From the documentation of setAs():

----------------
With this explanation as background, the function setAs does a fairly 
obvious computation: It constructs and sets a method for the function 
coerce with signature c(from, to), using the def argument to define the 
body of the method.
-------------------

> 
> The problem is not to cheat the check mechanism. I knew that the warning
> can be elminitad by by defining an alias of this function in one of the 
> Rd files.

No cheating seems needed.  The setAs() call is part of your software & 
presumably you document it somewhere.  You do have to construct the 
corresponding alias in the same .Rd file, but it doesn't amount to cheating.

It's true that a user would have to be unusually well-informed to know 
how to ask for the corresponding documentation explicitly.

> 
> Yours
> 
> Eryk
>

From roebuck at odin.mdacc.tmc.edu  Fri Feb 11 00:06:25 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri Feb 11 00:06:38 2005
Subject: [Rd] Canonical S4 Method signature
Message-ID: <Pine.OSF.4.58.0502101640490.131187@odin.mdacc.tmc.edu>

I have trouble finding applicable examples of S4 methods.
Could someone tell me the canonical method for a function
that takes either one or two arguments corresponding to
dimensions? So if vector output desired, only one argument
'n' would be provided. For matrix, two would be provided
corresponding to 'm' and 'n' in that order. And therein
lies the rub as I don't really want to require specifying
the argument name in order to do this.

foo(3)		# n = 3
foo(3, 4)	# m = 3, n = 4
foo(n = 3, 4)	# m = 4, n = 3

What I have come up with thus far is below but that reverses
the order for second case. I could swap them internally if
I knew whether they were specified by name.

setGeneric("foo", function(n, m = n) {
    cat("generic", match.call()[[1]], "\n")
    standardGeneric("foo")
})

One other alternative might be to just use dots for the
function argument and assign them names internally.

Similar functions in some package? Suggestions (besides
not using S4)?

TIA

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From mark.bravington at csiro.au  Fri Feb 11 08:35:57 2005
From: mark.bravington at csiro.au (mark.bravington@csiro.au)
Date: Fri Feb 11 08:36:05 2005
Subject: [Rd] getAnywhere and functions starting with "." (PR#7684)
Message-ID: <20050211073557.A8A5DDEF1@slim.kubism.ku.dk>

Full_Name: Mark Bravington
Version: 2.0.1
OS: Windows XP
Submission from: (NULL) (140.79.22.104)


'getAnywhere' crashes when its argument starts with a period:

> getAnywhere( '.onLoad')
Error in exists(x, envir, mode, inherits) : 
        invalid first argument

One fix might be to replace the line

if ( !is.null(f <- getS3method(gen, cl, TRUE))) {

with

if ( nchar( gen) && !is.null(f <- getS3method(gen, cl, TRUE))) {

Mark

From ripley at stats.ox.ac.uk  Fri Feb 11 08:56:58 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 11 08:57:21 2005
Subject: [Rd] getAnywhere and functions starting with "." (PR#7684)
In-Reply-To: <20050211073557.A8A5DDEF1@slim.kubism.ku.dk>
References: <20050211073557.A8A5DDEF1@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502110753550.4522@gannet.stats>

This was mentioned a week or so ago on R-devel and is already fixed in the 
current sources: from the NEWS file

     o	getAnywhere() was confused by names with leading or trailing dots
 	(spotted by Robert McGehee)

On Fri, 11 Feb 2005 mark.bravington@csiro.au wrote:

> Full_Name: Mark Bravington
> Version: 2.0.1
> OS: Windows XP
> Submission from: (NULL) (140.79.22.104)
>
>
> 'getAnywhere' crashes when its argument starts with a period:

It does not: it gives an error.  Please do read the comment on this in the 
posting guide!

>> getAnywhere( '.onLoad')
> Error in exists(x, envir, mode, inherits) :
>        invalid first argument
>
> One fix might be to replace the line
>
> if ( !is.null(f <- getS3method(gen, cl, TRUE))) {
>
> with
>
> if ( nchar( gen) && !is.null(f <- getS3method(gen, cl, TRUE))) {
>
> Mark
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Fri Feb 11 09:01:58 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Fri Feb 11 09:02:05 2005
Subject: [Rd] getAnywhere and functions starting with "." (PR#7684)
Message-ID: <20050211080158.8855EDEF1@slim.kubism.ku.dk>

mark.bravington@csiro.au wrote:

> Full_Name: Mark Bravington
> Version: 2.0.1
> OS: Windows XP
> Submission from: (NULL) (140.79.22.104)
> 
> 
> 'getAnywhere' crashes when its argument starts with a period:
> 
> 
>>getAnywhere( '.onLoad')
> 
> Error in exists(x, envir, mode, inherits) : 
>         invalid first argument
> 
> One fix might be to replace the line
> 
> if ( !is.null(f <- getS3method(gen, cl, TRUE))) {
> 
> with
> 
> if ( nchar( gen) && !is.null(f <- getS3method(gen, cl, TRUE))) {
> 
> Mark
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


Has already been fixed, as you can easily see, e.g., from R-devels NEWS 
file, section BUG FIXES:

  o getAnywhere() was confused by names with leading or trailing dots
    (spotted by Robert McGehee)

Uwe Ligges

From Matthias.Kohl at uni-bayreuth.de  Fri Feb 11 10:40:44 2005
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Fri Feb 11 09:38:39 2005
Subject: [Rd] Canonical S4 Method signature
In-Reply-To: <Pine.OSF.4.58.0502101640490.131187@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0502101640490.131187@odin.mdacc.tmc.edu>
Message-ID: <420C7D9C.4090001@uni-bayreuth.de>

Paul Roebuck schrieb:

>I have trouble finding applicable examples of S4 methods.
>Could someone tell me the canonical method for a function
>that takes either one or two arguments corresponding to
>dimensions? So if vector output desired, only one argument
>'n' would be provided. For matrix, two would be provided
>corresponding to 'm' and 'n' in that order. And therein
>lies the rub as I don't really want to require specifying
>the argument name in order to do this.
>
>foo(3)		# n = 3
>foo(3, 4)	# m = 3, n = 4
>foo(n = 3, 4)	# m = 4, n = 3
>
>What I have come up with thus far is below but that reverses
>the order for second case. I could swap them internally if
>I knew whether they were specified by name.
>
>setGeneric("foo", function(n, m = n) {
>    cat("generic", match.call()[[1]], "\n")
>    standardGeneric("foo")
>})
>
>One other alternative might be to just use dots for the
>function argument and assign them names internally.
>
>Similar functions in some package? Suggestions (besides
>not using S4)?
>
>TIA
>
>----------------------------------------------------------
>SIGSIG -- signature too long (core dumped)
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>  
>
Hi,

maybe the following is a starting point and comes close to what you want ...

Matthias


if(!isGeneric("foo"))
    setGeneric("foo", function(m, n) standardGeneric("foo"))

setMethod("foo", signature(m = "missing", n = "numeric"),
    function(n){ 
        # do something
        # for example
        print(n)
    })

setMethod("foo", signature(m = "numeric", n = "numeric"),
    function(m, n){ 
        # do something
        # for example
        print(m)
        print(n)
    })

foo(3, 4)
foo(n = 3, 4)
# unfortunatelly you have to do
foo(,3)
# or
foo(n = 3)

From ripley at stats.ox.ac.uk  Fri Feb 11 12:17:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 11 12:17:43 2005
Subject: [Rd] R-patched Make Check Fails on reg-tests-1.R on linux and OS X
In-Reply-To: <Pine.LNX.4.61.0502081327150.1123@gannet.stats>
References: <b1b28a05.caf97d67.819db00@ms08.mrf.mail.rcn.net>
	<Pine.GSO.4.51.0502071203120.7373@csm.Berkeley.EDU>
	<Pine.LNX.4.61.0502081327150.1123@gannet.stats>
Message-ID: <Pine.LNX.4.61.0502111113080.9824@gannet.stats>

Stefano Iacus has been able to reproduce this on MacOS X (it was a 
segfault in a later example), and we have just now committed a workaround.
I think it probably was an OS-specific quirk in vsnprintf.

On Tue, 8 Feb 2005, Prof Brian Ripley wrote:

> Since no one else has this problem, I suggest you check the integrity of your 
> checkout, or, better, use an R-patched tarball that can easily be verified. 
> This looks very like a mismatched build and test: that is your R build has 
> not be updated to include the patch which is being tested.
> A completely clean build from a tarball will ensure that is not the case.
>
> Reporting problems using unreleased compilers (gcc 3.4.4 is not released) 
> isn't going to win you a lot of sympathy: they have been responsible for a 
> large number of (mis-directed) problem reports.  If you didn't have the 
> problem on two machines I would be suggesting using released versions of the 
> tools.
>
> FYI, R is tested on released compilers on i686 Linux several times a day, and 
> at least weekly on other common platforms.  We would know soon enough if 
> there was an R problem in 'make all check' on those platforms.
>
>
> On Mon, 7 Feb 2005, Jake Bowers wrote:
>
>> Dear Developers,
>> 
>> I've been playing around with compiling R on my Debian Linux machine (dual
>> Athlon 1.4ghz) and my OS X machine (dual G5). I'm emailing now because
>> reg-tests-1.R fails during make check on my debian machine using gcc-3.4,
>> and on my OS X machine using gcc-3.3. I am using r-patched updated via svn
>> today (Updated to revision 33075.)
>> 
>> Here are some details:
>> 
>> **Using gcc-3.4 on debian:
>> gcc-3.4 (GCC) 3.4.4 20041218 (prerelease) (Debian 3.4.3-6)
>> 
>> wes:/home/temp/R/r-patched/tests# tail reg-tests-1.Rout.fail
>>> 
>>> ## automatic row.names can be number-like, MM, 2004-11-26
>>> d0 <- data.frame(x=1:3, y=pi*2:0)
>>> row.names(d0)[3] <- c("01.00")
>>> write.table(d0, (tf <- tempfile()))
>>> d <- read.table(tf)
>>> ## gave error ("duplicate row.names") in 2.0.1
>>> stopifnot(all.equal(d,d0))
>>> unlink(tf)
>> 
>> **Using gcc-3.3 on debian works fine (passes all make check).
>> gcc (GCC) 3.3.5 (Debian 1:3.3.5-5)
>> 
>> **Using gcc-3.3 on OS X.
>> gcc (GCC) 3.3 20030304 (Apple Computer, Inc. build 1671)
>> 
>> More info on my OS X build:
>> ./configure --with-blas='-framework vecLib' --with-lapack --with-aqua
>> --with-x --with-tcl-config=/Library/Frameworks/Tcl.framework/tclConfig.sh
>> --with-tk-config=/Library/Frameworks/Tk.framework/tkConfig.sh
>> --enable-R-shlib TCLTK_LIBS='-framework Tcl -framework Tk'
>> TCLTK_CPPFLAGS='-I/Library/Frameworks/Tcl.Framework/Headers
>> -I/Library/Frameworks/Tk.Framework/Headers' --with-recommended
>> 
>> g77 is version 3.4 downloaded from hpc.sf.net.
>> GNU Fortran (GCC) 3.4.2
>> 
>> echo $PATH
>> /usr/local/bin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/X11R6/bin:/sw/bin:/sw/sbin:/usr/local/pvm3/lib:/usr/local/pvm3/bin/DARWIN
>> 
>> and, to prevent it from using stuff in the fink directory:
>> 
>> CPPFLAGS='-I/usr/local/include'
>> 
>> Here is the output where make check fails:
>> 
>> running regression tests
>> running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
>> make[2]: *** [test-Reg] Error 2
>> make[1]: *** [test-all-basics] Error 1
>> make: *** [check-all] Error 2
>> 
>> sphere:~/TEMP/R/r-patched/tests jwbowers$ tail reg-tests-1.Rout.fail
>>> 
>>> 
>>> ## automatic row.names can be number-like, MM, 2004-11-26
>>> d0 <- data.frame(x=1:3, y=pi*2:0)
>>> row.names(d0)[3] <- c("01.00")
>>> write.table(d0, (tf <- tempfile()))
>>> d <- read.table(tf)
>>> ## gave error ("duplicate row.names") in 2.0.1
>>> stopifnot(all.equal(d,d0))
>>> unlink(tf)
>> 
>> Should I be very concerned about this? I tend to mostly use my OS X
>> machine since the Linux box is about 4 years old.
>> 
>> I hope this information is helpful --- I'm sorry if this is something
>> obvious! (I found some posts from last summer about problems with gcc-3.4,
>> which might explain the problems with gcc-3.4 on linux, but I didn't find
>> anything obvious about gcc-3.3 on the Mac).
>> 
>> Thanks so much for all of your work!!
>> 
>> Best,
>> 
>> Jake
>> 
>> Jake Bowers
>> Assistant Professor
>> Dept of Political Science
>> University of Michigan
>> http://www.umich.edu/~jwbowers
>> 
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jtk at cmp.uea.ac.uk  Fri Feb 11 13:27:39 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Fri Feb 11 12:30:36 2005
Subject: [Rd] Pipe / Fork: Partial Solution / Providing Connections from C?
In-Reply-To: <20050201195017.GC30798@jtkpc.cmp.uea.ac.uk>
References: <20050201135305.GA29528@jtkpc.cmp.uea.ac.uk>
	<Pine.LNX.4.61.0502011335290.15311@gannet.stats>
	<20050201195017.GC30798@jtkpc.cmp.uea.ac.uk>
Message-ID: <20050211122739.GA1442@jtkpc.cmp.uea.ac.uk>

Dear All,

On Tue, Feb 01, 2005 at 07:50:17PM +0000, Jan T. Kim wrote:
> On Tue, Feb 01, 2005 at 01:44:37PM +0000, Prof Brian Ripley wrote:

> > If we only had to consider standard Unices, pipe() would allow read-write 
> > modes.  As it is, it is easy for you to write an OS-specific extension.

I've looked into this and tried to write a function that would start
an external process and return two connections, one for writing to the
external process and one for reading from it. Unfortunately, I haven't
found a way to implement this in a package, without altering the R
source code itself (details below). As an alternative / workaround,
I coded up a function

   xpipe(cmd, input)

that takes a command to start the external process (cmd) and a character
containing the lines to be written (input), and returns a character
vector containing the output produced by the external process. The
xpipe package is available at

    http://www2.cmp.uea.ac.uk/~jtk/software/xpipe_0.0-1.tar.gz

To an extent, this provides the functionality I was looking for, but
it is not satisfactory because the output cannot be processed by R
on line -- xpipe accumulates the entire output and returns it only
after the external process has terminated.

Also technically, it's cumbersome to use: For obtaining something else
than a character value, it seems one has to write the output into an
anonymous file and then use scan, read.table or whatever to read from
that file.

Therefore, I still look for a way to implement the design where the
pipe ends are returned as R connections. The problem in doing so is that
connections are stored in a

    static Rconnection Connections[NCONNECTIONS];

(file src/main/connections.c), and I cannot find any function that
provides an interface for allocating a slot in the Connections array
and storing a connection set up by a the code in my package there.
There is a non-static (i.e. externally visible) NextConnection function
(which is not declared in any header, though), and nothing like

    Rboolean setConnection(int connNumber, Rconnection *conn);
    Rconnection *getConnection(int connNumber);

I haven't found any relevant documentation on these issues (R-exts
doesn't have any info on handling connections in C code at all). Can any
of you direct me to such docs, or point out how I can instantiate and
return connections from within a package?

> Well, that is probably reasonably easy, but (not the least due to that
> fact) I'm still surprised that it has not been done already. I can hardly
> imagine that I'm the first one to want to use some external utility from
> an R program in this way.
> 
> So, what do you R-devel folks do in this case, and what would you
> recommend?

I'm still curious about this one. If there really is no way of running
stuff through external filter processes in R, I'd volunteer to add
that.

Best regards & thanks in advance, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*

From p.dalgaard at biostat.ku.dk  Fri Feb 11 14:32:20 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Feb 11 14:37:07 2005
Subject: [Rd] Pipe / Fork: Partial Solution / Providing Connections from C?
In-Reply-To: <20050211122739.GA1442@jtkpc.cmp.uea.ac.uk>
References: <20050201135305.GA29528@jtkpc.cmp.uea.ac.uk>
	<Pine.LNX.4.61.0502011335290.15311@gannet.stats>
	<20050201195017.GC30798@jtkpc.cmp.uea.ac.uk>
	<20050211122739.GA1442@jtkpc.cmp.uea.ac.uk>
Message-ID: <x2acqb2pej.fsf@biostat.ku.dk>

"Jan T. Kim" <jtk@cmp.uea.ac.uk> writes:

> > Well, that is probably reasonably easy, but (not the least due to that
> > fact) I'm still surprised that it has not been done already. I can hardly
> > imagine that I'm the first one to want to use some external utility from
> > an R program in this way.
> > 
> > So, what do you R-devel folks do in this case, and what would you
> > recommend?
> 
> I'm still curious about this one. If there really is no way of running
> stuff through external filter processes in R, I'd volunteer to add
> that.
> 
> Best regards & thanks in advance, Jan

If you know how, please do. I have a suspicion it might not be as easy
as it sounds because of the producer/consumer aspects. Notice, though,
that in most cases you can get by with system() or pipe() and a
temporary file for either the input or the output.

I remember speculating about these matters when I was first introduced
to pipes in C: They'd show you how to open a pipe for reading and how
to do it for writing, but not how to do both with the same process.
Took me a while to realize that there is a nontrivial deadlock issue
if you try to write to a process that itself is blocked trying to
write its output. Now that is of course not to say that it cannot be
done with clever multiplexing and buffering techniques -- or
multithreading, except that R isn't threaded.

BTW, we met in Heidelberg at the ECMBM ages ago, didn't we? 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Gregor.Gorjanc at bfro.uni-lj.si  Fri Feb 11 15:41:31 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Fri Feb 11 15:41:40 2005
Subject: [Rd] Notes on bug reports 3229 and 3242 - as.matrix.data.frame
Message-ID: <7FFEE688B57D7346BC6241C55900E730B6FEF5@pollux.bfro.uni-lj.si>

Hello R developers.

I encountered the same problem as Uwe Ligges with as.matrix.data.frame()
in bug reports 3229 and 3242 - under section not-reproducible. 

Example I have is:

> tmp
                             level 2100-D
1       biological_process unknown     NA
2                 cellular process  -5.88
3                      development  -8.42
4            physiological process  -6.55
5 regulation of biological process     NA
6                 viral life cycle     NA

> str(tmp)
`data.frame':   6 obs. of  2 variables:
 $ level      : Factor w/ 6 levels "biological_..",..: 1 2 3 4 5 6
 $ 2100-D_mean:`data.frame':    6 obs. of  1 variable:
  ..$ 2100-D: num  NA -5.88 -8.42 -6.55 NA NA

> as.matrix.data.frame(tmp)
Error in as.matrix.data.frame(tmp) : dim<- : dims [product 6] do not 
match the length of object [7]

The error associated with this is comming up at the end of function
as.matrix.data.frame where it is used:

    dim(X) <- c(n, length(X)/n)

?dim says
     'dim' has a method for 'data.frame's, which returns the length of
     the 'row.names' attribute of 'x' and the length of 'x' (the
     numbers of "rows" and "columns").

This part is ok. The problem is with X, which is "intensively"
modified through the function. Before this (dim(X) <- ...) call
X in my case is:

> x <- tmp
> "code from as.matrix.data.frame down to dim(X) <- ..."
> X
[[1]]
[1] "biological_process unknown"

[[2]]
[1] "cellular process"

[[3]]
[1] "development"

[[4]]
[1] "physiological process"

[[5]]
[1] "regulation of biological process"

[[6]]
[1] "viral life cycle"

[[7]]
[1]    NA -5.88 -8.42 -6.55    NA    NA

So we can see, that X is somehow destroyed - the first and second
column of tmp differ. For dim command this should really be one 
long vector. So the problem lies in line

    X <- unlist(X, recursive = FALSE, use.names = FALSE)

where it should be 

    X <- unlist(X, recursive = TRUE, use.names = FALSE)
                               ^^^^

I have checked source code for that function from R as well as
in R-devel sources. I was not succesfull in reproducing the above
with the data frame bellow though. It did not report any problems
with old as.matrix.data.frame. There must be some trick with 
first column in my data. So I am quite sure my suggestion is
OK.

tmp1 <- data.frame(level=c("A A", "B B"), x=c(NA, -5.8))

--
Lep pozdrav / With regards,
    Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From ripley at stats.ox.ac.uk  Fri Feb 11 16:47:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 11 16:47:58 2005
Subject: [Rd] Notes on bug reports 3229 and 3242 - as.matrix.data.frame
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B6FEF5@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FEF5@pollux.bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502111541080.3779@gannet.stats>

You too have not give an reproducible example!

If you have a corrupt data frame, the function may fail, which is what 
happened in the PR# you quote.

Please note: you should not be calling as.matrix.data.frame, but as.matrix.

On Fri, 11 Feb 2005, Gorjanc Gregor wrote:

> Hello R developers.
>
> I encountered the same problem as Uwe Ligges with as.matrix.data.frame()
> in bug reports 3229 and 3242 - under section not-reproducible.
>
> Example I have is:
>
>> tmp
>                             level 2100-D
> 1       biological_process unknown     NA
> 2                 cellular process  -5.88
> 3                      development  -8.42
> 4            physiological process  -6.55
> 5 regulation of biological process     NA
> 6                 viral life cycle     NA
>
>> str(tmp)
> `data.frame':   6 obs. of  2 variables:
> $ level      : Factor w/ 6 levels "biological_..",..: 1 2 3 4 5 6
> $ 2100-D_mean:`data.frame':    6 obs. of  1 variable:
>  ..$ 2100-D: num  NA -5.88 -8.42 -6.55 NA NA

I think you have a data frame column in a data frame, and that cannot be 
made directly into a matrix.  It's the steps that got you here that are 
the problem.

>> as.matrix.data.frame(tmp)
> Error in as.matrix.data.frame(tmp) : dim<- : dims [product 6] do not
> match the length of object [7]
>
> The error associated with this is comming up at the end of function
> as.matrix.data.frame where it is used:
>
>    dim(X) <- c(n, length(X)/n)
>
> ?dim says
>     'dim' has a method for 'data.frame's, which returns the length of
>     the 'row.names' attribute of 'x' and the length of 'x' (the
>     numbers of "rows" and "columns").
>
> This part is ok. The problem is with X, which is "intensively"
> modified through the function. Before this (dim(X) <- ...) call
> X in my case is:
>
>> x <- tmp
>> "code from as.matrix.data.frame down to dim(X) <- ..."
>> X
> [[1]]
> [1] "biological_process unknown"
>
> [[2]]
> [1] "cellular process"
>
> [[3]]
> [1] "development"
>
> [[4]]
> [1] "physiological process"
>
> [[5]]
> [1] "regulation of biological process"
>
> [[6]]
> [1] "viral life cycle"
>
> [[7]]
> [1]    NA -5.88 -8.42 -6.55    NA    NA
>
> So we can see, that X is somehow destroyed - the first and second
> column of tmp differ. For dim command this should really be one
> long vector. So the problem lies in line
>
>    X <- unlist(X, recursive = FALSE, use.names = FALSE)
>
> where it should be
>
>    X <- unlist(X, recursive = TRUE, use.names = FALSE)
>                               ^^^^
>
> I have checked source code for that function from R as well as
> in R-devel sources. I was not succesfull in reproducing the above
> with the data frame bellow though. It did not report any problems
> with old as.matrix.data.frame. There must be some trick with
> first column in my data. So I am quite sure my suggestion is
> OK.
>
> tmp1 <- data.frame(level=c("A A", "B B"), x=c(NA, -5.8))
>
> --
> Lep pozdrav / With regards,
>    Gregor GORJANC
>
> ---------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Gregor.Gorjanc at bfro.uni-lj.si  Fri Feb 11 17:21:05 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Fri Feb 11 17:21:15 2005
Subject: [Rd] Notes on bug reports 3229 and 3242 - as.matrix.data.frame
Message-ID: <7FFEE688B57D7346BC6241C55900E730B6FEFC@pollux.bfro.uni-lj.si>

! Look after character !

From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk]
You too have not give an reproducible example!
! Yes, I was not able to do it from my data. But bellow is one. It is
! a stupid one, but it works. The problem is use of as.data.frame in 
! tmp1$L <- as.data.frame(tmp$L). This looks like to produce a corrupted
! data.frame. If I use just tmp1$L <- tmp$L, write.table and 
! as.matrix.data.frame works OK. I still think that mine proposal can
! give benefit, since it works also on corrupted data frames.

data(warpbreaks)
tmp <- as.data.frame(tapply(breaks, list(wool, tension), mean))
tmp1 <- data.frame(level=rownames(tmp))
tmp1$L <- as.data.frame(tmp$L)
write.table(tmp1)
Error in as.matrix.data.frame(x) : dim<- : dims [product 2] do not match the length of object [3]

tmp1$L <- tmp$L
write.table(tmp1)
"level" "L"
"1" "A" 44.55556
"2" "B" 28.22222

If you have a corrupt data frame, the function may fail, which is what 
happened in the PR# you quote.

Please note: you should not be calling as.matrix.data.frame, but as.matrix.
! I called it because I had problems with write.table and that function
! calls as.matrix.data.frame. 

On Fri, 11 Feb 2005, Gorjanc Gregor wrote:

> Hello R developers.
>
> I encountered the same problem as Uwe Ligges with as.matrix.data.frame()
> in bug reports 3229 and 3242 - under section not-reproducible.
>
> Example I have is:
>
>> tmp
>                             level 2100-D
> 1       biological_process unknown     NA
> 2                 cellular process  -5.88
> 3                      development  -8.42
> 4            physiological process  -6.55
> 5 regulation of biological process     NA
> 6                 viral life cycle     NA
>
>> str(tmp)
> `data.frame':   6 obs. of  2 variables:
> $ level      : Factor w/ 6 levels "biological_..",..: 1 2 3 4 5 6
> $ 2100-D_mean:`data.frame':    6 obs. of  1 variable:
>  ..$ 2100-D: num  NA -5.88 -8.42 -6.55 NA NA

I think you have a data frame column in a data frame, and that cannot be 
made directly into a matrix.  It's the steps that got you here that are 
the problem.

>> as.matrix.data.frame(tmp)
> Error in as.matrix.data.frame(tmp) : dim<- : dims [product 6] do not
> match the length of object [7]
>
> The error associated with this is comming up at the end of function
> as.matrix.data.frame where it is used:
>
>    dim(X) <- c(n, length(X)/n)
>
> ?dim says
>     'dim' has a method for 'data.frame's, which returns the length of
>     the 'row.names' attribute of 'x' and the length of 'x' (the
>     numbers of "rows" and "columns").
>
> This part is ok. The problem is with X, which is "intensively"
> modified through the function. Before this (dim(X) <- ...) call
> X in my case is:
>
>> x <- tmp
>> "code from as.matrix.data.frame down to dim(X) <- ..."
>> X
> [[1]]
> [1] "biological_process unknown"
>
> [[2]]
> [1] "cellular process"
>
> [[3]]
> [1] "development"
>
> [[4]]
> [1] "physiological process"
>
> [[5]]
> [1] "regulation of biological process"
>
> [[6]]
> [1] "viral life cycle"
>
> [[7]]
> [1]    NA -5.88 -8.42 -6.55    NA    NA
>
> So we can see, that X is somehow destroyed - the first and second
> column of tmp differ. For dim command this should really be one
> long vector. So the problem lies in line
>
>    X <- unlist(X, recursive = FALSE, use.names = FALSE)
>
> where it should be
>
>    X <- unlist(X, recursive = TRUE, use.names = FALSE)
>                               ^^^^
>
> I have checked source code for that function from R as well as
> in R-devel sources. I was not succesfull in reproducing the above
> with the data frame bellow though. It did not report any problems
> with old as.matrix.data.frame. There must be some trick with
> first column in my data. So I am quite sure my suggestion is
> OK.
>
> tmp1 <- data.frame(level=c("A A", "B B"), x=c(NA, -5.8))
>
> --
> Lep pozdrav / With regards,
>    Gregor GORJANC
>
> ---------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From andy_liaw at merck.com  Fri Feb 11 18:24:18 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Feb 11 18:24:56 2005
Subject: [Rd] Notes on bug reports 3229 and 3242 -
 as.matrix.data.fram e
Message-ID: <3A822319EB35174CA3714066D590DCD50994E6BE@usrymx25.merck.com>

> From: Gorjanc Gregor
> 
> ! Look after character !
> 
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk]
> You too have not give an reproducible example!
> ! Yes, I was not able to do it from my data. But bellow is one. It is
> ! a stupid one, but it works. The problem is use of as.data.frame in 
> ! tmp1$L <- as.data.frame(tmp$L). This looks like to produce 
> a corrupted
> ! data.frame. If I use just tmp1$L <- tmp$L, write.table and 
> ! as.matrix.data.frame works OK. I still think that mine proposal can
> ! give benefit, since it works also on corrupted data frames.
> 
> data(warpbreaks)
> tmp <- as.data.frame(tapply(breaks, list(wool, tension), mean))
> tmp1 <- data.frame(level=rownames(tmp))
> tmp1$L <- as.data.frame(tmp$L)

Here's the problem that Brian is referring to:  Why do you make one variable
in the data frame a data frame?  That's what caused problem in
write.table()!

Andy


> write.table(tmp1)
> Error in as.matrix.data.frame(x) : dim<- : dims [product 2] 
> do not match the length of object [3]
> 
> tmp1$L <- tmp$L
> write.table(tmp1)
> "level" "L"
> "1" "A" 44.55556
> "2" "B" 28.22222
> 
> If you have a corrupt data frame, the function may fail, 
> which is what 
> happened in the PR# you quote.
> 
> Please note: you should not be calling as.matrix.data.frame, 
> but as.matrix.
> ! I called it because I had problems with write.table and 
> that function
> ! calls as.matrix.data.frame. 
> 
> On Fri, 11 Feb 2005, Gorjanc Gregor wrote:
> 
> > Hello R developers.
> >
> > I encountered the same problem as Uwe Ligges with 
> as.matrix.data.frame()
> > in bug reports 3229 and 3242 - under section not-reproducible.
> >
> > Example I have is:
> >
> >> tmp
> >                             level 2100-D
> > 1       biological_process unknown     NA
> > 2                 cellular process  -5.88
> > 3                      development  -8.42
> > 4            physiological process  -6.55
> > 5 regulation of biological process     NA
> > 6                 viral life cycle     NA
> >
> >> str(tmp)
> > `data.frame':   6 obs. of  2 variables:
> > $ level      : Factor w/ 6 levels "biological_..",..: 1 2 3 4 5 6
> > $ 2100-D_mean:`data.frame':    6 obs. of  1 variable:
> >  ..$ 2100-D: num  NA -5.88 -8.42 -6.55 NA NA
> 
> I think you have a data frame column in a data frame, and 
> that cannot be 
> made directly into a matrix.  It's the steps that got you 
> here that are 
> the problem.
> 
> >> as.matrix.data.frame(tmp)
> > Error in as.matrix.data.frame(tmp) : dim<- : dims [product 6] do not
> > match the length of object [7]
> >
> > The error associated with this is comming up at the end of function
> > as.matrix.data.frame where it is used:
> >
> >    dim(X) <- c(n, length(X)/n)
> >
> > ?dim says
> >     'dim' has a method for 'data.frame's, which returns the 
> length of
> >     the 'row.names' attribute of 'x' and the length of 'x' (the
> >     numbers of "rows" and "columns").
> >
> > This part is ok. The problem is with X, which is "intensively"
> > modified through the function. Before this (dim(X) <- ...) call
> > X in my case is:
> >
> >> x <- tmp
> >> "code from as.matrix.data.frame down to dim(X) <- ..."
> >> X
> > [[1]]
> > [1] "biological_process unknown"
> >
> > [[2]]
> > [1] "cellular process"
> >
> > [[3]]
> > [1] "development"
> >
> > [[4]]
> > [1] "physiological process"
> >
> > [[5]]
> > [1] "regulation of biological process"
> >
> > [[6]]
> > [1] "viral life cycle"
> >
> > [[7]]
> > [1]    NA -5.88 -8.42 -6.55    NA    NA
> >
> > So we can see, that X is somehow destroyed - the first and second
> > column of tmp differ. For dim command this should really be one
> > long vector. So the problem lies in line
> >
> >    X <- unlist(X, recursive = FALSE, use.names = FALSE)
> >
> > where it should be
> >
> >    X <- unlist(X, recursive = TRUE, use.names = FALSE)
> >                               ^^^^
> >
> > I have checked source code for that function from R as well as
> > in R-devel sources. I was not succesfull in reproducing the above
> > with the data frame bellow though. It did not report any problems
> > with old as.matrix.data.frame. There must be some trick with
> > first column in my data. So I am quite sure my suggestion is
> > OK.
> >
> > tmp1 <- data.frame(level=c("A A", "B B"), x=c(NA, -5.8))
> >
> > --
> > Lep pozdrav / With regards,
> >    Gregor GORJANC
> >
> > ---------------------------------------------------------------
> > University of Ljubljana
> > Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
> > Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> > Groblje 3                  tel: +386 (0)1 72 17 861
> > SI-1230 Domzale            fax: +386 (0)1 72 17 888
> > Slovenia
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>

From ehlers at math.ucalgary.ca  Fri Feb 11 18:58:24 2005
From: ehlers at math.ucalgary.ca (ehlers@math.ucalgary.ca)
Date: Fri Feb 11 18:58:32 2005
Subject: [Rd] formatC with illegal input crashes Rgui (PR#7686)
Message-ID: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>

Full_Name: Peter Ehlers
Version: rw2001pat (2005-02-03)
OS: Win XP
Submission from: (NULL) (136.159.61.115)


formatC(1, flag="s") crashes Rgui.
Similarly for flag=[SnZ].
Stupid input, of course, but I'm error-prone.

Peter

From spencer at stats.ox.ac.uk  Fri Feb 11 20:13:49 2005
From: spencer at stats.ox.ac.uk (spencer@stats.ox.ac.uk)
Date: Fri Feb 11 20:13:57 2005
Subject: [Rd] double/integer (PR#7687)
Message-ID: <20050211191349.E8D1CDEE7@slim.kubism.ku.dk>

Full_Name: Chris Spencer
Version: 2.0.1
OS: Linux
Submission from: (NULL) (163.1.211.93)


Dear R team,

I realise that the following is a bit unsafe (the combination of doubles and
integers), however I wondered whether the following behaviour is expected: 

> #Test R
> test <- vector(length=100000);
> for(i in 1:100000){temp = i/1000; test[i] = (i == temp*1000);}
> table(test);
test
FALSE  TRUE
 1472 98528

For example I can also make the following error:

>  as.integer(259.765*1000);
[1] 259765
>  as.integer(259.763*1000);
[1] 259762

Would you expect this to be the case and if so why?
Thanks for your help.

Chris Spencer

From urbanek at research.att.com  Fri Feb 11 20:26:37 2005
From: urbanek at research.att.com (Simon Urbanek)
Date: Fri Feb 11 20:26:43 2005
Subject: [Rd] Re: [R-SIG-Mac] Bug running pbinom() in R-GUI?
In-Reply-To: <BE3168A8.4737%gwgilc@wm.edu>
References: <BE3168A8.4737%gwgilc@wm.edu>
Message-ID: <D8FE15E0-7C62-11D9-B113-000D93AE1C66@research.att.com>

On Feb 10, 2005, at 7:38 PM, George W. Gilchrist wrote:

> Today I was running a graduate level stats lab using R and we 
> encountered a
> major problem while using the current build of the Cocoa GUI:
>
>> From the GUI:
>> system.time(pbinom(80, 1e5, 806/1e6))
> [1] 14.37  4.94 30.29  0.00  0.00
>>
>
>> From the command line on the same machine:
>> system.time(pbinom(80, 1e5, 806/1e6))
> [1] 0.02 0.00 0.02 0.00 0.00
>>
>
> I've tried the CRAN version and the latest build of the R-GUI and both
> deliver the same terrible performance. It seems as if this only occurs 
> for
> certain arguments, but we saw this on ~15 different machines today. 
> And it
> seems to only be when running the Cocoa GUI. No problems at all with 
> this
> under Windoze. Any ideas?

The cause is pbeta_raw calling (indirectly via R_CheckUserInterrupt) 
R_ProcessEvents for every iteration - and for small p the number of 
iterations goes really high (e.g. for the case above n=99919). 
R_ProcessEvents is not a cheap operation, because it enters system 
event loop and processes any pending events. A quick fix could be the 
following patch, which checks for break only after several iterations 
(including the first one, just in case this is part of a sequence that 
may need user interaction).

Index: src/nmath/pbeta.c
===================================================================
--- src/nmath/pbeta.c   (revision 33148)
+++ src/nmath/pbeta.c   (working copy)
@@ -139,7 +139,8 @@
             for(i= 1; i <= n; i++) {
  #ifndef MATHLIB_STANDALONE
                 /* for now, at least allow this:*/
-               R_CheckUserInterrupt();
+               if ((i&1023)==1)
+                       R_CheckUserInterrupt();
  #endif
                 if (p1 <= 1 && term / eps <= finsum)
                     break;

after this patch has been applied I get in the GUI:

 > system.time(pbinom(80, 1e5, 806/1e6))
[1] 0.02 0.00 0.08 0.00 0.00

Cheers,
Simon

From jtk at cmp.uea.ac.uk  Fri Feb 11 21:42:43 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Fri Feb 11 20:45:21 2005
Subject: [Rd] Pipe / Fork: Partial Solution / Providing Connections from C?
In-Reply-To: <x2acqb2pej.fsf@biostat.ku.dk>
References: <20050201135305.GA29528@jtkpc.cmp.uea.ac.uk>
	<Pine.LNX.4.61.0502011335290.15311@gannet.stats>
	<20050201195017.GC30798@jtkpc.cmp.uea.ac.uk>
	<20050211122739.GA1442@jtkpc.cmp.uea.ac.uk>
	<x2acqb2pej.fsf@biostat.ku.dk>
Message-ID: <20050211204243.GC1442@jtkpc.cmp.uea.ac.uk>

On Fri, Feb 11, 2005 at 02:32:20PM +0100, Peter Dalgaard wrote:
> "Jan T. Kim" <jtk@cmp.uea.ac.uk> writes:
> 
> > > Well, that is probably reasonably easy, but (not the least due to that
> > > fact) I'm still surprised that it has not been done already. I can hardly
> > > imagine that I'm the first one to want to use some external utility from
> > > an R program in this way.
> > > 
> > > So, what do you R-devel folks do in this case, and what would you
> > > recommend?
> > 
> > I'm still curious about this one. If there really is no way of running
> > stuff through external filter processes in R, I'd volunteer to add
> > that.
> > 
> > Best regards & thanks in advance, Jan
> 
> If you know how, please do. I have a suspicion it might not be as easy
> as it sounds because of the producer/consumer aspects. Notice, though,
> that in most cases you can get by with system() or pipe() and a
> temporary file for either the input or the output.

Personally, I see filtering as a process, and the sequence of collecting
input in a file, then filtering that into an output file, then reading
that and carrying on with it as a more complex process that involves
filtering as a part of it. Additional complexity means that there's more
that can go wrong, which is why I dislike temporary files.

Specifically.  I've seen it happen too often (including to myself) that
things went wrong because other processes were interfering with the
temporary files (in most cases, other processes running the same program).

> I remember speculating about these matters when I was first introduced
> to pipes in C: They'd show you how to open a pipe for reading and how
> to do it for writing, but not how to do both with the same process.
> Took me a while to realize that there is a nontrivial deadlock issue
> if you try to write to a process that itself is blocked trying to
> write its output. Now that is of course not to say that it cannot be
> done with clever multiplexing and buffering techniques -- or
> multithreading, except that R isn't threaded.

It's clear to me that for real dynamic filtering, you need two processes
(or threads). This requires that the operating system supports forking,
i.e. that the fork package works. Without that, filtering is not
possible, at least I'm not in any way I'm aware of.

So, my plan would be to add some function to src/main/connections.c for
setting up a pipe running through an external command and returning the
write and read connections for use in the R program. Then, one could do
something like (modelled after the pipe example in the base docs):

    library(fork);
    data2 <- c(
      "450, 390, 467, 654,  30, 542, 334, 432, 421,",
      "357, 497, 493, 550, 549, 467, 575, 578, 342,",
      "446, 547, 534, 495, 979, 479");
    fp <- filterpipe("sed -e s/,$//");
    {
      pid <- fork(slave = NULL)
      if (pid == 0)
      {
        close(fp$read);
	write(data2, file = fp$write);
	close(fp$write);
	exit();
      }
      else
      {
        close(fp$write);
	x <- scan(fp$read);
	close(fp$read);
	wait(pid);
      }
    }

Thinking about your buffering suggestion, it occurs to me that it *may*
be possible to create two anonymous files (of the file("") type) and
to connect these to the stdin and the stdout of an external process.
In fact, a couple of days ago I checked whether pipe() would perhaps
accept optional file arguments for specifying the external process'
stdin and stdout, so I could e.g.

    f <- file("");
    p <- pipe("sed -e s/,$//", stdin = f);
    write(data2, file = f);
    scan(p);

but that turned out to be another detour on the way that took me here...

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk@cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*

From Gregor.Gorjanc at bfro.uni-lj.si  Fri Feb 11 21:36:48 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Fri Feb 11 21:41:38 2005
Subject: [Rd] Notes on bug reports 3229 and 3242 - as.matrix.data.fram e
Message-ID: <7FFEE688B57D7346BC6241C55900E730B6FEFE@pollux.bfro.uni-lj.si>

From: Liaw, Andy [mailto:andy_liaw@merck.com]
> From: Gorjanc Gregor

> ! Yes, I was not able to do it from my data. But bellow is one. It is
> ! a stupid one, but it works. The problem is use of as.data.frame in 
> ! tmp1$L <- as.data.frame(tmp$L). This looks like to produce 
> a corrupted
> ! data.frame. If I use just tmp1$L <- tmp$L, write.table and 
> ! as.matrix.data.frame works OK. I still think that mine proposal can
> ! give benefit, since it works also on corrupted data frames.
> 
> data(warpbreaks)
> tmp <- as.data.frame(tapply(breaks, list(wool, tension), mean))
> tmp1 <- data.frame(level=rownames(tmp))
> tmp1$L <- as.data.frame(tmp$L)

Here's the problem that Brian is referring to:  Why do you make one variable
in the data frame a data frame?  That's what caused problem in
write.table()!

! I agree completely and as I have described up it is my fault that
! I have/had problems with as.matrix.data.frame by use of write.table.
! But I think that my proposal is nice, since as.matrix.data.frame would 
! be more robust.

! With regards, Gregor

From tlumley at u.washington.edu  Fri Feb 11 22:13:15 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Feb 11 22:13:29 2005
Subject: [Rd] double/integer (PR#7687)
In-Reply-To: <20050211191349.E8D1CDEE7@slim.kubism.ku.dk>
References: <20050211191349.E8D1CDEE7@slim.kubism.ku.dk>
Message-ID: <Pine.A41.4.61b.0502111302430.306218@homer11.u.washington.edu>

On Fri, 11 Feb 2005 spencer@stats.ox.ac.uk wrote:

> Full_Name: Chris Spencer
> Version: 2.0.1
> OS: Linux
> Submission from: (NULL) (163.1.211.93)
>
>
> Dear R team,
>
> I realise that the following is a bit unsafe (the combination of doubles and
> integers), however I wondered whether the following behaviour is expected:
>
>> #Test R
>> test <- vector(length=100000);
>> for(i in 1:100000){temp = i/1000; test[i] = (i == temp*1000);}
>> table(test);
> test
> FALSE  TRUE
> 1472 98528

Certainly.  You might even expect worse behaviour than that.

temp can be exactly represented in double precision only when i is a 
multiple of 125.  Depending on exactly how the computations are done and 
how many extra guard digits are carried you could get FALSE for nearly all 
i not a multiple of 125.  The fact that you get TRUE 98% of the time is 
better accuracy than you should expect.


 	-thomas

From ripley at stats.ox.ac.uk  Fri Feb 11 22:14:16 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 11 22:14:26 2005
Subject: [Rd] Re: [R-SIG-Mac] Bug running pbinom() in R-GUI?
In-Reply-To: <D8FE15E0-7C62-11D9-B113-000D93AE1C66@research.att.com>
References: <BE3168A8.4737%gwgilc@wm.edu>
	<D8FE15E0-7C62-11D9-B113-000D93AE1C66@research.att.com>
Message-ID: <Pine.LNX.4.61.0502111930000.3642@gannet.stats>

The problem rather is that if R_CheckUserInterrupt is so expensive, we 
need to redesign it, for it should not be (and is not on other platforms 
as the comments below show).  See the comment in src/main/errors.c.

One idea might be for the GUI to set a flag that R_CheckUserInterrupt 
consults (which is what happens on Windows via another thread).

I agree that pbeta seems far too enthusiastic on checking, but the 
`weight' of R_CheckUserInterrupt needs to be comparable across platforms 
or this will recur.  Looks to me like it at least 100x more expensive on 
OS X than anywhere else.  (I timed 1us on Windows, and the timings below 
suggest 140us.)

(I think we need to understand why there is a check in that loop, rather 
than just choose some arbitrary frequency: looks to me that it is simple 
enough to check every million since pbeta(0.5, 1e6, 1e6) takes less than 
0.1s on my machine.  But integer overflow of n cuts in before it gets 
really slow, and I suspect that by n=1e6 it is better to use an 
approximation than a sum.)


On Fri, 11 Feb 2005, Simon Urbanek wrote:

> On Feb 10, 2005, at 7:38 PM, George W. Gilchrist wrote:
>
>> Today I was running a graduate level stats lab using R and we encountered a
>> major problem while using the current build of the Cocoa GUI:
>> 
>>> From the GUI:
>>> system.time(pbinom(80, 1e5, 806/1e6))
>> [1] 14.37  4.94 30.29  0.00  0.00
>>> 
>> 
>>> From the command line on the same machine:
>>> system.time(pbinom(80, 1e5, 806/1e6))
>> [1] 0.02 0.00 0.02 0.00 0.00
>>> 
>> 
>> I've tried the CRAN version and the latest build of the R-GUI and both
>> deliver the same terrible performance. It seems as if this only occurs for
>> certain arguments, but we saw this on ~15 different machines today. And it
>> seems to only be when running the Cocoa GUI. No problems at all with this
>> under Windoze. Any ideas?
>
> The cause is pbeta_raw calling (indirectly via R_CheckUserInterrupt) 
> R_ProcessEvents for every iteration - and for small p the number of 
> iterations goes really high (e.g. for the case above n=99919). 
> R_ProcessEvents is not a cheap operation, because it enters system event loop 
> and processes any pending events. A quick fix could be the following patch, 
> which checks for break only after several iterations (including the first 
> one, just in case this is part of a sequence that may need user interaction).
>
> Index: src/nmath/pbeta.c
> ===================================================================
> --- src/nmath/pbeta.c   (revision 33148)
> +++ src/nmath/pbeta.c   (working copy)
> @@ -139,7 +139,8 @@
>            for(i= 1; i <= n; i++) {
> #ifndef MATHLIB_STANDALONE
>                /* for now, at least allow this:*/
> -               R_CheckUserInterrupt();
> +               if ((i&1023)==1)
> +                       R_CheckUserInterrupt();
> #endif
>                if (p1 <= 1 && term / eps <= finsum)
>                    break;
>
> after this patch has been applied I get in the GUI:
>
>> system.time(pbinom(80, 1e5, 806/1e6))
> [1] 0.02 0.00 0.08 0.00 0.00
>
> Cheers,
> Simon
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Feb 11 22:35:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 11 22:35:53 2005
Subject: [Rd] Notes on bug reports 3229 and 3242 - as.matrix.data.fram
 e
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B6FEFE@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FEFE@pollux.bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502112127190.16826@gannet.stats>

On Fri, 11 Feb 2005, Gorjanc Gregor wrote:

> From: Liaw, Andy [mailto:andy_liaw@merck.com]
>> From: Gorjanc Gregor
>
>> ! Yes, I was not able to do it from my data. But bellow is one. It is
>> ! a stupid one, but it works. The problem is use of as.data.frame in
>> ! tmp1$L <- as.data.frame(tmp$L). This looks like to produce
>> a corrupted
>> ! data.frame. If I use just tmp1$L <- tmp$L, write.table and
>> ! as.matrix.data.frame works OK. I still think that mine proposal can
>> ! give benefit, since it works also on corrupted data frames.
>>
>> data(warpbreaks)
>> tmp <- as.data.frame(tapply(breaks, list(wool, tension), mean))
>> tmp1 <- data.frame(level=rownames(tmp))
>> tmp1$L <- as.data.frame(tmp$L)
>
> Here's the problem that Brian is referring to:  Why do you make one variable
> in the data frame a data frame?  That's what caused problem in
> write.table()!
>
> ! I agree completely and as I have described up it is my fault that
> ! I have/had problems with as.matrix.data.frame by use of write.table.
> ! But I think that my proposal is nice, since as.matrix.data.frame would
> ! be more robust.

It is actually much less robust.  It would work for embedded data frames 
of one column, but you could have a list column with entries of different 
lengths. e.g.

X <- data.frame(x=1:2, y = I(list(a=1, b=3:4)))
> as.matrix(X)
   x y
a 1 1
b 2 Integer,2

With your fix, this becomes an error.  And I could replace those entries 
by data frames containing lists of dates ....

Note that in R-devel write.table does not convert data frames to matrices, 
so this does not arise.  We could treat your example specially, but surely 
it was an error that is better found out about than hushed up.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From urbanek at research.att.com  Fri Feb 11 23:11:56 2005
From: urbanek at research.att.com (Simon Urbanek)
Date: Fri Feb 11 23:12:01 2005
Subject: [Rd] Re: [R-SIG-Mac] Bug running pbinom() in R-GUI?
In-Reply-To: <Pine.LNX.4.61.0502111930000.3642@gannet.stats>
References: <BE3168A8.4737%gwgilc@wm.edu>
	<D8FE15E0-7C62-11D9-B113-000D93AE1C66@research.att.com>
	<Pine.LNX.4.61.0502111930000.3642@gannet.stats>
Message-ID: <F13445E3-7C79-11D9-B113-000D93AE1C66@research.att.com>

Brian,

On Feb 11, 2005, at 4:14 PM, Prof Brian Ripley wrote:

> The problem rather is that if R_CheckUserInterrupt is so expensive, we 
> need to redesign it, for it should not be

I agree, that's why I named it a 'quick fix'. Unfortunately a more 
'proper' fix is far from trivial.

Talking of handling interrupts alone, at a first glance Mac OS doesn't 
need a specific flag like Win, because it handles SIGINT like other 
unices (in fact that's the default if aqua is disabled). But at the 
second glance the issue is more tricky: although it is still possible 
to use the same check as on other unices, which allows anyone to 
interrupt R using SIGINT, we actually want some GUI element to trigger 
this - and we get response from GUI elements only if we run the system 
loop. So checking the interrupt flag is not expensive, but running the 
loop to enable GUI elements to set the flag is expensive. Currently we 
don't use threads in the GUI to ensure stability (other than for 
reading/writing pipes), so the system loop is embedded in the REPL, 
hence the "Stop" button (which in fact just sends SIGINT when 
triggered) doesn't work unless we run the system loop ...

I have an experimental version of the GUI that runs REPL and system 
loop in separate threads, but there are many issues, predominantly 
because the Application Framework is not thread-safe. Using distributed 
objects to circumvent this has quite big impact on performance, 
especially for the graphics device, so I'm not ready to do that step 
with the current public GUI yet.

I'll dig a bit to see whether I can come up with some way to get GUI 
response squeezed in without R_ProcessEvents somehow, but for the time 
being the quick fix is the only concrete solution I can offer...

Best,
Simon

From mengcheng81 at gmail.com  Fri Feb 11 23:18:56 2005
From: mengcheng81 at gmail.com (mengcheng81@gmail.com)
Date: Fri Feb 11 23:19:05 2005
Subject: [Rd] Can't install add-on package using
	R-2.0.1-0.fdr.2.fc3.i386.rpm (PR#7688)
Message-ID: <20050211221856.EF27DDEE3@slim.kubism.ku.dk>

Full_Name: mengcheng
Version: R-2.0.1-0.fdr.2.fc3.i386.rpm
OS: 
Submission from: (NULL) (216.204.103.5)


Somehow R-2.0.1-0.fdr.2.fc3.i386.rpm didn't install R properly.

I install R on my fedora 3 using my R-2.0.1-0.fdr.2.fc3.i386.rpm.
But when I try to install add-on packages, it fails and show the warning
message:
/usr/lib/R/bin/Rcmd: line 45: exec: INSTALL: not found


I then reinstall R using R-2.0.0-0.fdr.1.fc2.i386.rpm and it work perfectly this
time when I try to install add-on.

From Mark.Bravington at csiro.au  Sat Feb 12 03:11:14 2005
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Sat Feb 12 03:11:29 2005
Subject: [Rd] getAnywhere and functions starting with "." (PR#7684)
Message-ID: <4D99275E380CA94F998977EDACE548DC0625A3@extas2-hba.tas.csiro.au>

>> [MVB] 'getAnywhere' crashes when its argument starts with a period:

> [UL] Has already been fixed, as you can easily see, e.g., from
R-devels NEWS file, section BUG FIXES:

Good, thanks.

It seems quite common for bugs to be reported after they have been fixed
in R-devel. This is likely to occur when-- as in the 'getAnywhere'
case-- there's no record of the bug in Bug Tracking (I do check before
submitting).

Checking R-devel news can be cumbersome-- I couldn't reach the ftp site
yesterday, for example, and it's not always feasible to download 12MB--
and many users won't be set up to handle it.

To avoid wasting R-core's time over repeat posts, is there some mileage
in R-core adding "fixed in Rdevel" bug reports into the Bug Tracking
system, even if there is no prior bug report?

Mark


Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623

From Gregor.Gorjanc at bfro.uni-lj.si  Sat Feb 12 03:37:58 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Sat Feb 12 03:40:10 2005
Subject: [Rd] Notes on bug reports 3229 and 3242 - as.matrix.data.fram e
Message-ID: <7FFEE688B57D7346BC6241C55900E730B6FF00@pollux.bfro.uni-lj.si>

I agree. Sorry for bothering. 

With regards, Gregor

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk]
Sent: pet 2005-02-11 22:35
To: Gorjanc Gregor
Cc: Liaw, Andy; r-devel@stat.math.ethz.ch
Subject: RE: [Rd] Notes on bug reports 3229 and 3242 - as.matrix.data.fram e
 
...
> ! I agree completely and as I have described up it is my fault that
> ! I have/had problems with as.matrix.data.frame by use of write.table.
> ! But I think that my proposal is nice, since as.matrix.data.frame would
> ! be more robust.

It is actually much less robust.  It would work for embedded data frames 
of one column, but you could have a list column with entries of different 
lengths. e.g.

X <- data.frame(x=1:2, y = I(list(a=1, b=3:4)))
> as.matrix(X)
   x y
a 1 1
b 2 Integer,2

With your fix, this becomes an error.  And I could replace those entries 
by data frames containing lists of dates ....

Note that in R-devel write.table does not convert data frames to matrices, 
so this does not arise.  We could treat your example specially, but surely 
it was an error that is better found out about than hushed up.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Feb 12 08:51:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Feb 12 08:51:22 2005
Subject: [Rd] getAnywhere and functions starting with "." (PR#7684)
In-Reply-To: <4D99275E380CA94F998977EDACE548DC0625A3@extas2-hba.tas.csiro.au>
References: <4D99275E380CA94F998977EDACE548DC0625A3@extas2-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.61.0502120748070.23253@gannet.stats>

Were you unaware that the NEWS file is browsable at

 	https://svn.r-project.org/R/trunk/NEWS

?

On Sat, 12 Feb 2005 Mark.Bravington@csiro.au wrote:

>>> [MVB] 'getAnywhere' crashes when its argument starts with a period:
>
>> [UL] Has already been fixed, as you can easily see, e.g., from
> R-devels NEWS file, section BUG FIXES:
>
> Good, thanks.
>
> It seems quite common for bugs to be reported after they have been fixed
> in R-devel. This is likely to occur when-- as in the 'getAnywhere'
> case-- there's no record of the bug in Bug Tracking (I do check before
> submitting).

It is common for bugs to be reported after they have been discussed on 
the R-devel list and fixed, as here.

> Checking R-devel news can be cumbersome-- I couldn't reach the ftp site
> yesterday, for example, and it's not always feasible to download 12MB--
> and many users won't be set up to handle it.
>
> To avoid wasting R-core's time over repeat posts, is there some mileage
> in R-core adding "fixed in Rdevel" bug reports into the Bug Tracking
> system, even if there is no prior bug report?

To avoid wasting R-core's time, do consult the latest version or at least 
its NEWS file.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Sat Feb 12 10:15:31 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat Feb 12 10:20:19 2005
Subject: [Rd] getAnywhere and functions starting with "." (PR#7684)
In-Reply-To: <Pine.LNX.4.61.0502120748070.23253@gannet.stats>
References: <4D99275E380CA94F998977EDACE548DC0625A3@extas2-hba.tas.csiro.au>
	<Pine.LNX.4.61.0502120748070.23253@gannet.stats>
Message-ID: <x27jlejg0c.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> Were you unaware that the NEWS file is browsable at
> 
>  	https://svn.r-project.org/R/trunk/NEWS
> 
> ?

(At least if the SVN server has not tied itself in a knot again...)

Also note that the Subversion log at developer.r-project.org has all
commits, with somewhat informative comments, e.g.

-------------
r33006 | pd | 2005-02-03 18:23:41 -0500 (Thu, 03 Feb 2005) | 1 line
Changed paths:
   M /trunk/NEWS
   M /trunk/src/library/utils/R/objects.R

getAnywhere got confused
-------------

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From hb at maths.lth.se  Sat Feb 12 12:52:05 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat Feb 12 12:52:25 2005
Subject: [Rd] Internationalization
Message-ID: <005401c510f9$46afe1c0$b50040d5@hblaptop>

Looking at the R v2.1.0 devel NEWS, I am very impressed with the new updates
and especially the internationalization part. Wonderful work! Thanks a lot.

Henrik Bengtsson

From cig69410 at syd.odn.ne.jp  Sun Feb 13 07:08:19 2005
From: cig69410 at syd.odn.ne.jp (cig69410@syd.odn.ne.jp)
Date: Sun Feb 13 07:08:28 2005
Subject: [Rd] Bug in cor function (PR#7689)
Message-ID: <20050213060819.B4F51DEE1@slim.kubism.ku.dk>

I can't hardly accept the result of  cor function with 
pairwize.colplete.obs or complete.obs

insert print statements in cor function,


+     if (method != "pearson") {
  +         Rank <- function(u) if (is.matrix(u))
  +             apply(u, 2, rank, na.last = "keep")
  +         else rank(u, na.last = "keep")
  +         x <- Rank(x)
  +         print(x) # add
  +         if (!is.null(y)) {
  +             y <- Rank(y)
  +             print(y) # add
  +         }
  +     }
  +     .Internal(cor(x, y, na.method, method == "kendall"))

and, data is
  > x <- c(7, 9, 8,  0, NA, NA)
  > y <- c(2, 3, 4, NA,  4,  3)

and, call cor function
  > cor(x, y, use="pair", method="sp")

order of x, and y are
  [1]  2  4  3  1 NA NA
  [1] 1.0 2.5 4.5  NA 4.5 2.5

alas!! and the result is
  [1] 0.4271211

oh! no!!

the result must be 0.5

From p.dalgaard at biostat.ku.dk  Sun Feb 13 10:12:36 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Feb 13 10:17:26 2005
Subject: [Rd] Bug in cor function (PR#7689)
In-Reply-To: <20050213060819.B4F51DEE1@slim.kubism.ku.dk>
References: <20050213060819.B4F51DEE1@slim.kubism.ku.dk>
Message-ID: <x2wttc4yd7.fsf@biostat.ku.dk>

cig69410@syd.odn.ne.jp writes:

> I can't hardly accept the result of  cor function with 
> pairwize.colplete.obs or complete.obs
> 
> insert print statements in cor function,
> 
> 
> +     if (method != "pearson") {
>   +         Rank <- function(u) if (is.matrix(u))
>   +             apply(u, 2, rank, na.last = "keep")
>   +         else rank(u, na.last = "keep")
>   +         x <- Rank(x)
>   +         print(x) # add
>   +         if (!is.null(y)) {
>   +             y <- Rank(y)
>   +             print(y) # add
>   +         }
>   +     }
>   +     .Internal(cor(x, y, na.method, method == "kendall"))
> 
> and, data is
>   > x <- c(7, 9, 8,  0, NA, NA)
>   > y <- c(2, 3, 4, NA,  4,  3)
> 
> and, call cor function
>   > cor(x, y, use="pair", method="sp")
> 
> order of x, and y are
>   [1]  2  4  3  1 NA NA
>   [1] 1.0 2.5 4.5  NA 4.5 2.5
> 
> alas!! and the result is
>   [1] 0.4271211
> 
> oh! no!!
> 
> the result must be 0.5

And which part of the following did you fail to understand?

      For 'cov()', a non-Pearson method is unusual but available for
     the sake of completeness.  Note that '"spearman"' basically
     computes 'cor(R(x), R(y))' (or 'cov(.,.)') where 'R(u) := rank(u,
     na.last="keep")'. Notice also that the ranking is (currently) done
     removing only cases that are missing on the variable itself,  which
     may not be what you expect if you let 'use' be '"complete.obs"' or
     '"pairwise.complete.obs"'.

If you have improved code to contribute, you're welcome (notice that
this requires reranking for every pair of variables in an n x n
correlation matrix in the pairwise case), but there's really not much
point in reporting issues that are already known and documented.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From kjetil at acelerate.com  Sun Feb 13 15:21:15 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sun Feb 13 18:31:42 2005
Subject: [Rd] docu buglet
Message-ID: <420F625B.4000600@acelerate.com>

The help page groupGeneric {base}  refers (Math group)
the defunct |tetragamma|, |pentagamma while the newer
psigamma is not mentioned.

Kjetil
|

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.

From Gregor.Gorjanc at bfro.uni-lj.si  Mon Feb 14 01:29:17 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Mon Feb 14 01:30:02 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
Message-ID: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>

Hello!

I was loooking in R-bugs and found under wishlist-fullfilled wish for 
"smart" placement of a legend. This has already been done in package
gplots in function smartlegend.

One question. This "bug-report" is under wishlist-fullfilled. Is it really
fullfilled? 

Mail from Elizabeth
---------------------------------------------------------------

It would be nice if legend had the option of some default locations you could
choose instead of entering specific coordinates, like "topleft",
"topright","topcenter", etc. based on par("usr") coordinates. I know I've wanted
it so often I've made my own simple non-robust wrap-around, so I don't have to
remember or parse the xjust and yjust options necessary to make it work. Of
course there should be the option of entering in your own coordinates. 

Also it would be nice to be able to put a optional title inside your legend.
Currently I just make my title the first value in my legend vector, and then fix
the other options so no symbols plot next to it. But this isn't always a pretty
result and can be a pain if your symbols are complicated.

Thanks,
Elizabeth 

Response to Elizabeth by Duncan Murdoch
---------------------------------------------------------------

--
Lep pozdrav / With regards,
    Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From Gregor.Gorjanc at bfro.uni-lj.si  Mon Feb 14 01:48:29 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Mon Feb 14 01:48:36 2005
Subject: [Rd] Wish: multiline comments
Message-ID: <7FFEE688B57D7346BC6241C55900E730B6FF13@pollux.bfro.uni-lj.si>

Hello!

I found a wish for multilne comments under wishlist-fullfilled.

http://r-bugs.biostat.ku.dk/cgi-bin/R/wishlst-fulfilled?id=7261;expression=NA;user=guest

Is this really fullfilled? Where, in R 2.1.0? I was not able to 
find any "announcements" or talks about that on mailing list 
or NEWS files.

--
Lep pozdrav / With regards,
    Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From Gregor.Gorjanc at bfro.uni-lj.si  Mon Feb 14 02:54:53 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Mon Feb 14 02:55:01 2005
Subject: [Rd] corrupt data frame: columns will be truncated or padded with
	NAs in: format.data.frame(x, digits = digits)
Message-ID: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>

Hello!

I posted on saturday mail with the same subject on r-help seeking
for help in my work, but now I realized that this list is more 
appropriate for this. I think I found I bug. Bellow are comments
and reproducible examples:

# Create a data frame
(tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D"))))
  y1 f1
1  1  A
2  2  B
3  3  C
4  4  D

# Add new column, which is not full (missing some data for last
# records)
tmp[1:2, "y2"] <- 2
tmp
  y1 f1   y2
1  1  A    2
2  2  B    2
3  3  C <NA>
4  4  D <NA>
Warning message: 
corrupt data frame: columns will be truncated or padded with NAs
in: format.data.frame(x, digits = digits) 

# Why did I get corrupted data frame? 

# Add new factor column, which is not full (missing some data for last
# records)
tmp[1:2, "f2"] <- tmp[1:2, "f1"]
tmp
  y1 f1   y2   f2
1  1  A    2    1
2  2  B    2    2
3  3  C <NA> <NA>
4  4  D <NA> <NA>
Warning message: 
corrupt data frame: columns will be truncated or padded with NAs 
in: format.data.frame(x, digits = digits) 

# New column should have class factor, but got somehow converted to integer
class(tmp$f2)
[1] "integer"

# If new column is completely full, everything is OK
> tmp$f3 <- tmp$f1
> tmp
  y1 f1   y2   f2 f3
1  1  A    2    1  A
2  2  B    2    2  B
3  3  C <NA> <NA>  C
4  4  D <NA> <NA>  D
Warning message: 
corrupt data frame: columns will be truncated or padded with NAs 
in: format.data.frame(x, digits = digits) 

# Let's go further and try to convert one of new numeric column 
# to factor
tmp$y2 <- factor(tmp$y2, labels="x")
tmp
  y1 f1 y2   f2 f3
1  1  A  x    1  A
2  2  B  x    2  B
3  3  C  x <NA>  C
4  4  D  x <NA>  D
Warning message: 
corrupt data frame: columns will be truncated or padded with NAs 
in: format.data.frame(x, digits = digits)

# Why did also NAs get converted to level x?

# Let's continue and add additional column, which is again not
# full, but missing some data for first records
tmp[3:4, "y3"] <- 1
tmp
  y1 f1 y2   f2 f3 y3
1  1  A  x    1  A NA
2  2  B  x    2  B NA
3  3  C  x <NA>  C  1
4  4  D  x <NA>  D  1
Warning message: 
corrupt data frame: columns will be truncated or padded with NAs
in: format.data.frame(x, digits = digits) 

# Notice the difference between <NA> in previous example and
# NA in current one.

# Try to convert this to factor
tmp$y3 <- factor(tmp$y3, labels="y")
tmp
  y1 f1 y2   f2 f3   y3
1  1  A  x    1  A <NA>
2  2  B  x    2  B <NA>
3  3  C  x <NA>  C    y
4  4  D  x <NA>  D    y
Warning message: 
corrupt data frame: columns will be truncated or padded with NAs 
in: format.data.frame(x, digits = digits)

# Works as expected.
# My configuration:
Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 0.1
 year = 2004
 month = 11
 day = 15
 language = R

Windows XP Professional (build 2600) Service Pack 0.0

--
Lep pozdrav / With regards,
    Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From ripley at stats.ox.ac.uk  Mon Feb 14 08:25:15 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 08:25:25 2005
Subject: [Rd] Wish: multiline comments
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B6FF13@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF13@pollux.bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502140723390.22249@gannet.stats>

Please look in the recent archives of this list: this was raised by Tony 
Rossini.

if(FALSE) {
}

already works.

On Mon, 14 Feb 2005, Gorjanc Gregor wrote:

> Hello!
>
> I found a wish for multilne comments under wishlist-fullfilled.
>
> http://r-bugs.biostat.ku.dk/cgi-bin/R/wishlst-fulfilled?id=7261;expression=NA;user=guest
>
> Is this really fullfilled? Where, in R 2.1.0? I was not able to
> find any "announcements" or talks about that on mailing list
> or NEWS files.
>
> --
> Lep pozdrav / With regards,
>    Gregor GORJANC
>
> ---------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Mon Feb 14 08:36:57 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 14 08:35:42 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>
Message-ID: <42105519.6020609@statistik.uni-dortmund.de>

Gorjanc Gregor wrote:

> Hello!
> 
> I was loooking in R-bugs and found under wishlist-fullfilled wish for 
> "smart" placement of a legend. This has already been done in package
> gplots in function smartlegend.
> 
> One question. This "bug-report" is under wishlist-fullfilled. Is it really
> fullfilled? 

Yes, in the current developer release (AKA R-devel, to be R-2.1.0), as 
you can easily see in the correpsonding NEWS file and the svn logs.

Why do you follow up into the bug repository?

Uwe Ligges



> 
> Mail from Elizabeth
> ---------------------------------------------------------------
> 
> It would be nice if legend had the option of some default locations you could
> choose instead of entering specific coordinates, like "topleft",
> "topright","topcenter", etc. based on par("usr") coordinates. I know I've wanted
> it so often I've made my own simple non-robust wrap-around, so I don't have to
> remember or parse the xjust and yjust options necessary to make it work. Of
> course there should be the option of entering in your own coordinates. 
> 
> Also it would be nice to be able to put a optional title inside your legend.
> Currently I just make my title the first value in my legend vector, and then fix
> the other options so no symbols plot next to it. But this isn't always a pretty
> result and can be a pain if your symbols are complicated.
> 
> Thanks,
> Elizabeth 
> 
> Response to Elizabeth by Duncan Murdoch
> ---------------------------------------------------------------
> 
> --
> Lep pozdrav / With regards,
>     Gregor GORJANC
> 
> ---------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Mon Feb 14 08:51:53 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 08:52:02 2005
Subject: [Rd] corrupt data frame: columns will be truncated or padded
	with NAs in: format.data.frame(x, digits = digits)
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502140725570.22249@gannet.stats>

On Mon, 14 Feb 2005, Gorjanc Gregor wrote:

> Hello!
>
> I posted on saturday mail with the same subject on r-help seeking
> for help in my work, but now I realized that this list is more
> appropriate for this. I think I found I bug.

You do not tell us what you think it is, though!  It *is* a bug in your 
code.

You did create a corrupt data frame by using *replacement* on part of 
something that did not exist.  The simple workaround is not to do that. 
One can argue about what should happen in such a case and currently R 
assumes that you know what you are doing and will only treat the data 
frame as a list. We could make this an error, but that would add an 
overhead to be paid by careful users too.

If you really want to understand what is going on here, please read the 
source code: R is a volunteer project and the volunteers do not have time 
to explain each and every one of your error messages to you -- we have 
already had several goes over including data frames in data frames.

> Bellow are comments
> and reproducible examples:
>
> # Create a data frame
> (tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D"))))
>  y1 f1
> 1  1  A
> 2  2  B
> 3  3  C
> 4  4  D
>
> # Add new column, which is not full (missing some data for last
> # records)
> tmp[1:2, "y2"] <- 2
> tmp
>  y1 f1   y2
> 1  1  A    2
> 2  2  B    2
> 3  3  C <NA>
> 4  4  D <NA>
> Warning message:
> corrupt data frame: columns will be truncated or padded with NAs
> in: format.data.frame(x, digits = digits)
>
> # Why did I get corrupted data frame?

Because you tried to change elements in a non-existent column.

> tmp[[3]]
[1] 2 2


> # Add new factor column, which is not full (missing some data for last
> # records)
> tmp[1:2, "f2"] <- tmp[1:2, "f1"]
> tmp
>  y1 f1   y2   f2
> 1  1  A    2    1
> 2  2  B    2    2
> 3  3  C <NA> <NA>
> 4  4  D <NA> <NA>
> Warning message:
> corrupt data frame: columns will be truncated or padded with NAs
> in: format.data.frame(x, digits = digits)
>
> # New column should have class factor, but got somehow converted to integer
> class(tmp$f2)
> [1] "integer"
>
> # If new column is completely full, everything is OK
>> tmp$f3 <- tmp$f1
>> tmp
>  y1 f1   y2   f2 f3
> 1  1  A    2    1  A
> 2  2  B    2    2  B
> 3  3  C <NA> <NA>  C
> 4  4  D <NA> <NA>  D
> Warning message:
> corrupt data frame: columns will be truncated or padded with NAs
> in: format.data.frame(x, digits = digits)
>
> # Let's go further and try to convert one of new numeric column
> # to factor
> tmp$y2 <- factor(tmp$y2, labels="x")
> tmp
>  y1 f1 y2   f2 f3
> 1  1  A  x    1  A
> 2  2  B  x    2  B
> 3  3  C  x <NA>  C
> 4  4  D  x <NA>  D
> Warning message:
> corrupt data frame: columns will be truncated or padded with NAs
> in: format.data.frame(x, digits = digits)
>
> # Why did also NAs get converted to level x?

They are *not* NAs: they print as NA with a warning.

> # Let's continue and add additional column, which is again not
> # full, but missing some data for first records
> tmp[3:4, "y3"] <- 1
> tmp
>  y1 f1 y2   f2 f3 y3
> 1  1  A  x    1  A NA
> 2  2  B  x    2  B NA
> 3  3  C  x <NA>  C  1
> 4  4  D  x <NA>  D  1
> Warning message:
> corrupt data frame: columns will be truncated or padded with NAs
> in: format.data.frame(x, digits = digits)
>
> # Notice the difference between <NA> in previous example and
> # NA in current one.

Yes, we know.  The <NA>s are coming from the print, with the warning.
They are unexpected, hence the headers do not line up.

OTOH, for y3 you need to create a 4-long vector, and that is padded with 
numeric NAs.

> # Try to convert this to factor
> tmp$y3 <- factor(tmp$y3, labels="y")
> tmp
>  y1 f1 y2   f2 f3   y3
> 1  1  A  x    1  A <NA>
> 2  2  B  x    2  B <NA>
> 3  3  C  x <NA>  C    y
> 4  4  D  x <NA>  D    y
> Warning message:
> corrupt data frame: columns will be truncated or padded with NAs
> in: format.data.frame(x, digits = digits)


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Mon Feb 14 10:42:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 10:42:37 2005
Subject: [Rd] docu buglet
In-Reply-To: <420F625B.4000600@acelerate.com>
References: <420F625B.4000600@acelerate.com>
Message-ID: <Pine.LNX.4.61.0502140922160.29134@gannet.stats>

On Sun, 13 Feb 2005, Kjetil Brinchmann Halvorsen wrote:

> The help page groupGeneric {base}  refers (Math group)
> the defunct |tetragamma|, |pentagamma while the newer
> psigamma is not mentioned.

Thanks.

psigamma is not in the Math group generic, despite its help page (it 
cannot be: it is a function of two arguments) and indeed is not generic.

Technically tetragamma etc still are internally group generic, as although 
their R wrappers has been removed they can still be called via .Internal. 
We will tidy this up for 2.1.0.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Mon Feb 14 11:00:52 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 11:01:09 2005
Subject: [Rd] formatC with illegal input crashes Rgui (PR#7686)
In-Reply-To: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502140956020.29523@gannet.stats>

We'll fix this, but you might like to note that sprintf is more
bulletproof and as from 2.1.0-to-be, a lot more tolerant, e.g.

sprintf("%s", 1)

works there and in 2.0.1 gives a useful error message.

On Fri, 11 Feb 2005 ehlers@math.ucalgary.ca wrote:

> Full_Name: Peter Ehlers
> Version: rw2001pat (2005-02-03)
> OS: Win XP
> Submission from: (NULL) (136.159.61.115)
>
>
> formatC(1, flag="s") crashes Rgui.
> Similarly for flag=[SnZ].
> Stupid input, of course, but I'm error-prone.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From huber at ebi.ac.uk  Mon Feb 14 10:49:14 2005
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Mon Feb 14 11:50:05 2005
Subject: [Rd] sprintf - was formatC with illegal input crashes Rgui
	(PR#7686)
In-Reply-To: <Pine.LNX.4.61.0502140956020.29523@gannet.stats>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>
Message-ID: <4210741A.8040606@ebi.ac.uk>

Dear Prof. Ripley,

Would it be possible to make sprintf accept vector arguments?
I.e. allow expressions like
   sprintf("%04d", 1:3)
to produce something like what currently needs to be done via
   sapply(1:3, function(i) sprintf("%04d",i))

   Best wishes
   Wolfgang
-------------------------------------
Wolfgang Huber
European Bioinformatics Institute
European Molecular Biology Laboratory
Cambridge CB10 1SD
England
Phone: +44 1223 494642
Fax:   +44 1223 494486
Http:  www.ebi.ac.uk/huber
-------------------------------------

Prof Brian Ripley wrote:
> We'll fix this, but you might like to note that sprintf is more
> bulletproof and as from 2.1.0-to-be, a lot more tolerant, e.g.
> 
> sprintf("%s", 1)
> 
> works there and in 2.0.1 gives a useful error message.
> 
> On Fri, 11 Feb 2005 ehlers@math.ucalgary.ca wrote:
> 
>> Full_Name: Peter Ehlers
>> Version: rw2001pat (2005-02-03)
>> OS: Win XP
>> Submission from: (NULL) (136.159.61.115)
>>
>>
>> formatC(1, flag="s") crashes Rgui.
>> Similarly for flag=[SnZ].
>> Stupid input, of course, but I'm error-prone.

From gregor.gorjanc at bfro.uni-lj.si  Mon Feb 14 11:58:43 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Mon Feb 14 11:59:06 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
In-Reply-To: <42105519.6020609@statistik.uni-dortmund.de>
References: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>
	<42105519.6020609@statistik.uni-dortmund.de>
Message-ID: <42108463.7050703@bfro.uni-lj.si>

Hello Uwe.

Thanks for the response. I was searching in bug repository for something 
else and found that wish. Hoewever I tried to do a search for that, so I 
would not bother R-devel team. I was not successfull in finding any 
meaningfull comments on legend in

http://developer.r-project.org/R.svnlog.2005

You are right with NEWS file in R-devel. It really documents this 
improvement. Very nice. You guys really do an excellent job. I did not 
looked in NEWS file since it is kind of "hidden" i.e. one needs to download 
the R-devel and look in that file. But I confes, it is my blame, not of 
R-devel folk. However I think, that it would be nice that link to NEWS file 
would be accessible directly from R websites. I wrote few lines of HTML 
code that could be added to CRAN webpages for this. I hope r-team or CRAN 
maintainers will find this usefull.

Look files:

* A replacement for http://cran.at.r-project.org/sources.html. I added link 
to last R-devel and R-patched archives and to corresponding NEWS files. 
However there are now no NEWS files at 
ftp://ftp.stat.math.ethz.ch/Software/R. I suggest that NEWS files for last 
R-devel and R-patched should be there, but since there are two, they could 
be named NEWS-devel and NEWS-patched or something alike. Maybe one could 
even divide directories ro R-devel and R-pacthed.

File is available at:
http://www.bfro.uni-lj.si/MR/ggorjan/sources.html

* A replacement for http://cran.at.r-project.org/banner.shtml. I added the 
same as above.

File is available at:
http://www.bfro.uni-lj.si/MR/ggorjan/banner.shtml

Uwe Ligges wrote:
> Gorjanc Gregor wrote:
> 
>> Hello!
>>
>> I was loooking in R-bugs and found under wishlist-fullfilled wish for 
>> "smart" placement of a legend. This has already been done in package
>> gplots in function smartlegend.
>>
>> One question. This "bug-report" is under wishlist-fullfilled. Is it 
>> really
>> fullfilled? 
> 
> 
> Yes, in the current developer release (AKA R-devel, to be R-2.1.0), as 
> you can easily see in the correpsonding NEWS file and the svn logs.
> 
> Why do you follow up into the bug repository?
> 
> Uwe Ligges
> 
> 
> 
>>
>> Mail from Elizabeth
>> ---------------------------------------------------------------
>>
>> It would be nice if legend had the option of some default locations 
>> you could
>> choose instead of entering specific coordinates, like "topleft",
>> "topright","topcenter", etc. based on par("usr") coordinates. I know 
>> I've wanted
>> it so often I've made my own simple non-robust wrap-around, so I don't 
>> have to
>> remember or parse the xjust and yjust options necessary to make it 
>> work. Of
>> course there should be the option of entering in your own coordinates.
>> Also it would be nice to be able to put a optional title inside your 
>> legend.
>> Currently I just make my title the first value in my legend vector, 
>> and then fix
>> the other options so no symbols plot next to it. But this isn't always 
>> a pretty
>> result and can be a pain if your symbols are complicated.
>>
>> Thanks,
>> Elizabeth
>> Response to Elizabeth by Duncan Murdoch
>> ---------------------------------------------------------------
>>
>> -- 
>> Lep pozdrav / With regards,
>>     Gregor GORJANC
>>
>> ---------------------------------------------------------------
>> University of Ljubljana
>> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
>> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
>> Groblje 3                  tel: +386 (0)1 72 17 861
>> SI-1230 Domzale            fax: +386 (0)1 72 17 888
>> Slovenia
>>
>> ______________________________________________
>> R-devel@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 

-- 
Lep pozdrav / With regards,
     Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From ripley at stats.ox.ac.uk  Mon Feb 14 12:02:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 12:02:29 2005
Subject: [Rd] sprintf - was formatC with illegal input crashes Rgui
	(PR#7686)
In-Reply-To: <4210741A.8040606@ebi.ac.uk>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>
	<4210741A.8040606@ebi.ac.uk>
Message-ID: <Pine.LNX.4.61.0502141052360.30303@gannet.stats>

On Mon, 14 Feb 2005, Wolfgang Huber wrote:

> Dear Prof. Ripley,
>
> Would it be possible to make sprintf accept vector arguments?
> I.e. allow expressions like
>  sprintf("%04d", 1:3)
> to produce something like what currently needs to be done via
>  sapply(1:3, function(i) sprintf("%04d",i))

I have thought about this, but it is not really clear what the right thing 
would be here with multiple arguments.  What should

sprintf(("%04d %s", 1:3, "abc")

do?  Produce a character vector of length 1 or 3?  If of length 1,
"0001 0002 0003 abc" or "0001 2 0003 abc"?

I guess the most R-like thing would be to recycle args to the length of 
the longest and then use them in parallel, but that can be done fairly 
easily by *apply.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Mon Feb 14 12:04:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 12:05:05 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
In-Reply-To: <42108463.7050703@bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>
	<42105519.6020609@statistik.uni-dortmund.de>
	<42108463.7050703@bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502141102430.30303@gannet.stats>

On Mon, 14 Feb 2005, Gregor GORJANC wrote:

> Hello Uwe.
>
> Thanks for the response. I was searching in bug repository for something else 
> and found that wish. Hoewever I tried to do a search for that, so I would not 
> bother R-devel team. I was not successfull in finding any meaningfull 
> comments on legend in
>
> http://developer.r-project.org/R.svnlog.2005
>
> You are right with NEWS file in R-devel. It really documents this 
> improvement. Very nice. You guys really do an excellent job. I did not looked 
> in NEWS file since it is kind of "hidden" i.e. one needs to download the 
> R-devel and look in that file. But I confes, it is my blame, not of R-devel

It is accessible at

https://svn.r-project.org/R/trunk/NEWS

> folk. However I think, that it would be nice that link to NEWS file would be 
> accessible directly from R websites. I wrote few lines of HTML code that 
> could be added to CRAN webpages for this. I hope r-team or CRAN maintainers 
> will find this usefull.
>
> Look files:
>
> * A replacement for http://cran.at.r-project.org/sources.html. I added link 
> to last R-devel and R-patched archives and to corresponding NEWS files. 
> However there are now no NEWS files at 
> ftp://ftp.stat.math.ethz.ch/Software/R. I suggest that NEWS files for last 
> R-devel and R-patched should be there, but since there are two, they could be 
> named NEWS-devel and NEWS-patched or something alike.

All the information in R-patched should also be in R-devel: it has a 
section on 2.0.1 patched.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Mon Feb 14 12:06:37 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 14 12:05:22 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
In-Reply-To: <42108463.7050703@bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>	<42105519.6020609@statistik.uni-dortmund.de>
	<42108463.7050703@bfro.uni-lj.si>
Message-ID: <4210863D.5090609@statistik.uni-dortmund.de>

Gregor GORJANC wrote:

> Hello Uwe.
> 
> Thanks for the response. I was searching in bug repository for something 
> else and found that wish. Hoewever I tried to do a search for that, so I 
> would not bother R-devel team. I was not successfull in finding any 
> meaningfull comments on legend in
> 
> http://developer.r-project.org/R.svnlog.2005

Right, because it was done last year:
http://developer.r-project.org/R.svnlog.2004
has (among other legend related entries):

------------------------------------------------------------------------
r32089 | murdoch | 2004-12-02 17:17:43 -0500 (Thu, 02 Dec 2004) | 1 line
Changed paths:
    M /trunk/NEWS
    M /trunk/src/library/graphics/R/legend.R
    M /trunk/src/library/graphics/man/legend.Rd

legend() enhancements from PR#7400


> You are right with NEWS file in R-devel. It really documents this 
> improvement. Very nice. You guys really do an excellent job. I did not 
> looked in NEWS file since it is kind of "hidden" i.e. one needs to 
> download the R-devel and look in that file. But I confes, it is my 
> blame, not of R-devel folk. However I think, that it would be nice that 
> link to NEWS file would be accessible directly from R websites. I wrote 
> few lines of HTML code that could be added to CRAN webpages for this. I 
> hope r-team or CRAN maintainers will find this usefull.
>

The file is much more easily available via SVN:

https://svn.r-project.org/R/trunk/NEWS


Uwe Ligges




> Look files:
> 
> * A replacement for http://cran.at.r-project.org/sources.html. I added 
> link to last R-devel and R-patched archives and to corresponding NEWS 
> files. However there are now no NEWS files at 
> ftp://ftp.stat.math.ethz.ch/Software/R. I suggest that NEWS files for 
> last R-devel and R-patched should be there, but since there are two, 
> they could be named NEWS-devel and NEWS-patched or something alike. 
> Maybe one could even divide directories ro R-devel and R-pacthed.
> 
> File is available at:
> http://www.bfro.uni-lj.si/MR/ggorjan/sources.html
> 
> * A replacement for http://cran.at.r-project.org/banner.shtml. I added 
> the same as above.
> 
> File is available at:
> http://www.bfro.uni-lj.si/MR/ggorjan/banner.shtml
> 
> Uwe Ligges wrote:
> 
>> Gorjanc Gregor wrote:
>>
>>> Hello!
>>>
>>> I was loooking in R-bugs and found under wishlist-fullfilled wish for 
>>> "smart" placement of a legend. This has already been done in package
>>> gplots in function smartlegend.
>>>
>>> One question. This "bug-report" is under wishlist-fullfilled. Is it 
>>> really
>>> fullfilled? 
>>
>>
>>
>> Yes, in the current developer release (AKA R-devel, to be R-2.1.0), as 
>> you can easily see in the correpsonding NEWS file and the svn logs.
>>
>> Why do you follow up into the bug repository?
>>
>> Uwe Ligges
>>
>>
>>
>>>
>>> Mail from Elizabeth
>>> ---------------------------------------------------------------
>>>
>>> It would be nice if legend had the option of some default locations 
>>> you could
>>> choose instead of entering specific coordinates, like "topleft",
>>> "topright","topcenter", etc. based on par("usr") coordinates. I know 
>>> I've wanted
>>> it so often I've made my own simple non-robust wrap-around, so I 
>>> don't have to
>>> remember or parse the xjust and yjust options necessary to make it 
>>> work. Of
>>> course there should be the option of entering in your own coordinates.
>>> Also it would be nice to be able to put a optional title inside your 
>>> legend.
>>> Currently I just make my title the first value in my legend vector, 
>>> and then fix
>>> the other options so no symbols plot next to it. But this isn't 
>>> always a pretty
>>> result and can be a pain if your symbols are complicated.
>>>
>>> Thanks,
>>> Elizabeth
>>> Response to Elizabeth by Duncan Murdoch
>>> ---------------------------------------------------------------
>>>
>>> -- 
>>> Lep pozdrav / With regards,
>>>     Gregor GORJANC
>>>
>>> ---------------------------------------------------------------
>>> University of Ljubljana
>>> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
>>> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
>>> Groblje 3                  tel: +386 (0)1 72 17 861
>>> SI-1230 Domzale            fax: +386 (0)1 72 17 888
>>> Slovenia
>>>
>>> ______________________________________________
>>> R-devel@stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>

From ehlers at math.ucalgary.ca  Mon Feb 14 12:07:17 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Mon Feb 14 12:08:44 2005
Subject: [Rd] formatC with illegal input crashes Rgui (PR#7686)
In-Reply-To: <Pine.LNX.4.61.0502140956020.29523@gannet.stats>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>
Message-ID: <42108665.5070002@math.ucalgary.ca>

Thanks. And good advice.
Peter

Prof Brian Ripley wrote:

> We'll fix this, but you might like to note that sprintf is more
> bulletproof and as from 2.1.0-to-be, a lot more tolerant, e.g.
> 
> sprintf("%s", 1)
> 
> works there and in 2.0.1 gives a useful error message.
> 
> On Fri, 11 Feb 2005 ehlers@math.ucalgary.ca wrote:
> 
>> Full_Name: Peter Ehlers
>> Version: rw2001pat (2005-02-03)
>> OS: Win XP
>> Submission from: (NULL) (136.159.61.115)
>>
>>
>> formatC(1, flag="s") crashes Rgui.
>> Similarly for flag=[SnZ].
>> Stupid input, of course, but I'm error-prone.
> 
>

From huber at ebi.ac.uk  Mon Feb 14 11:12:36 2005
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Mon Feb 14 12:13:24 2005
Subject: [Rd] sprintf - was formatC with illegal input crashes Rgui
	(PR#7686)
In-Reply-To: <Pine.LNX.4.61.0502141052360.30303@gannet.stats>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>
	<4210741A.8040606@ebi.ac.uk>
	<Pine.LNX.4.61.0502141052360.30303@gannet.stats>
Message-ID: <42107994.9070500@ebi.ac.uk>

Prof Brian Ripley wrote:
> On Mon, 14 Feb 2005, Wolfgang Huber wrote:
> 
>> Dear Prof. Ripley,
>>
>> Would it be possible to make sprintf accept vector arguments?
>> I.e. allow expressions like
>>  sprintf("%04d", 1:3)
>> to produce something like what currently needs to be done via
>>  sapply(1:3, function(i) sprintf("%04d",i))
> 
> 
> I have thought about this, but it is not really clear what the right 
> thing would be here with multiple arguments.  What should
> 
> sprintf(("%04d %s", 1:3, "abc")
> 
> do?  Produce a character vector of length 1 or 3?  If of length 1,
> "0001 0002 0003 abc" or "0001 2 0003 abc"?
> 
> I guess the most R-like thing would be to recycle args to the length of 
> the longest and then use them in parallel, but that can be done fairly 
> easily by *apply.

Personally, I would prefer the recycling, but of course it can be also 
done this way:

 > mapply(sprintf, "%04d %s", 1:3, "abc")
    %04d %s       <NA>       <NA>
"0001 abc" "0002 abc" "0003 abc"

the only slightly unaesthetic thing being the names of the resulting vector.

-- 
Best regards
   Wolfgang

-------------------------------------
Wolfgang Huber
European Bioinformatics Institute
European Molecular Biology Laboratory
Cambridge CB10 1SD
England
Phone: +44 1223 494642
Fax:   +44 1223 494486
Http:  www.ebi.ac.uk/huber

From gregor.gorjanc at bfro.uni-lj.si  Mon Feb 14 12:21:43 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Mon Feb 14 12:22:05 2005
Subject: [Rd] corrupt data frame: columns will be truncated or padded
	with NAs in: format.data.frame(x, digits = digits)
In-Reply-To: <Pine.LNX.4.61.0502140725570.22249@gannet.stats>
References: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>
	<Pine.LNX.4.61.0502140725570.22249@gannet.stats>
Message-ID: <421089C7.8080401@bfro.uni-lj.si>

Hello!

Prof Brian Ripley wrote:
> You did create a corrupt data frame by using *replacement* on part of 
> something that did not exist.  The simple workaround is not to do that. 
> One can argue about what should happen in such a case and currently R 
> assumes that you know what you are doing and will only treat the data 
> frame as a list. We could make this an error, but that would add an 
> overhead to be paid by careful users too.
I agree to some extent, however I was very surprised of this behaviour. I 
often deal with data that have missing values and now I really do not know 
how to manage such data. How can one add a column to existing data frame
in such a way, that you don't get corrupted data frames as in my example?

(tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D"))))
   y1 f1
1  1  A
2  2  B
3  3  C
4  4  D
# Add new column, which is not full (missing some data for last
# records)
tmp[1:2, "y2"] <- 2
tmp
  y1 f1   y2
1  1  A    2
2  2  B    2
3  3  C <NA>
4  4  D <NA>
Warning message:
corrupt data frame: columns will be truncated or padded with NAs
in: format.data.frame(x, digits = digits)

I hope that this is not the best solution:
tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D")))
tmp$y2 <- NA
tmp[1:2, "y2"] <- 2
tmp

> If you really want to understand what is going on here, please read the 
> source code: R is a volunteer project and the volunteers do not have 
> time to explain each and every one of your error messages to you -- we 
> have already had several goes over including data frames in data frames.
I try to and I hope I did not take to much of your time.

[... removed the rest ...]

-- 
Lep pozdrav / With regards,
     Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From gregor.gorjanc at bfro.uni-lj.si  Mon Feb 14 12:28:20 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Mon Feb 14 12:28:42 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
In-Reply-To: <4210863D.5090609@statistik.uni-dortmund.de>
References: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>	<42105519.6020609@statistik.uni-dortmund.de>
	<42108463.7050703@bfro.uni-lj.si>
	<4210863D.5090609@statistik.uni-dortmund.de>
Message-ID: <42108B54.4050404@bfro.uni-lj.si>

I added link to https://svn.r-project.org/R/trunk/NEWS in files

http://www.bfro.uni-lj.si/MR/ggorjan/sources.html
http://www.bfro.uni-lj.si/MR/ggorjan/banner.shtml

Uwe Ligges wrote:
> Gregor GORJANC wrote:
> 
>> Hello Uwe.
>>
>> Thanks for the response. I was searching in bug repository for 
>> something else and found that wish. Hoewever I tried to do a search 
>> for that, so I would not bother R-devel team. I was not successfull in 
>> finding any meaningfull comments on legend in
>>
>> http://developer.r-project.org/R.svnlog.2005
> 
> 
> Right, because it was done last year:
> http://developer.r-project.org/R.svnlog.2004
> has (among other legend related entries):
> 
> ------------------------------------------------------------------------
> r32089 | murdoch | 2004-12-02 17:17:43 -0500 (Thu, 02 Dec 2004) | 1 line
> Changed paths:
>    M /trunk/NEWS
>    M /trunk/src/library/graphics/R/legend.R
>    M /trunk/src/library/graphics/man/legend.Rd
> 
> legend() enhancements from PR#7400
> 
> 
>> You are right with NEWS file in R-devel. It really documents this 
>> improvement. Very nice. You guys really do an excellent job. I did not 
>> looked in NEWS file since it is kind of "hidden" i.e. one needs to 
>> download the R-devel and look in that file. But I confes, it is my 
>> blame, not of R-devel folk. However I think, that it would be nice 
>> that link to NEWS file would be accessible directly from R websites. I 
>> wrote few lines of HTML code that could be added to CRAN webpages for 
>> this. I hope r-team or CRAN maintainers will find this usefull.
>>
> 
> The file is much more easily available via SVN:
> 
> https://svn.r-project.org/R/trunk/NEWS
> 
> 
> Uwe Ligges
> 
> 
> 
> 
>> Look files:
>>
>> * A replacement for http://cran.at.r-project.org/sources.html. I added 
>> link to last R-devel and R-patched archives and to corresponding NEWS 
>> files. However there are now no NEWS files at 
>> ftp://ftp.stat.math.ethz.ch/Software/R. I suggest that NEWS files for 
>> last R-devel and R-patched should be there, but since there are two, 
>> they could be named NEWS-devel and NEWS-patched or something alike. 
>> Maybe one could even divide directories ro R-devel and R-pacthed.
>>
>> File is available at:
>> http://www.bfro.uni-lj.si/MR/ggorjan/sources.html
>>
>> * A replacement for http://cran.at.r-project.org/banner.shtml. I added 
>> the same as above.
>>
>> File is available at:
>> http://www.bfro.uni-lj.si/MR/ggorjan/banner.shtml
>>
>> Uwe Ligges wrote:
>>
>>> Gorjanc Gregor wrote:
>>>
>>>> Hello!
>>>>
>>>> I was loooking in R-bugs and found under wishlist-fullfilled wish 
>>>> for "smart" placement of a legend. This has already been done in 
>>>> package
>>>> gplots in function smartlegend.
>>>>
>>>> One question. This "bug-report" is under wishlist-fullfilled. Is it 
>>>> really
>>>> fullfilled? 
>>>
>>>
>>>
>>>
>>> Yes, in the current developer release (AKA R-devel, to be R-2.1.0), 
>>> as you can easily see in the correpsonding NEWS file and the svn logs.
>>>
>>> Why do you follow up into the bug repository?
>>>
>>> Uwe Ligges
>>>
>>>
>>>
>>>>
>>>> Mail from Elizabeth
>>>> ---------------------------------------------------------------
>>>>
>>>> It would be nice if legend had the option of some default locations 
>>>> you could
>>>> choose instead of entering specific coordinates, like "topleft",
>>>> "topright","topcenter", etc. based on par("usr") coordinates. I know 
>>>> I've wanted
>>>> it so often I've made my own simple non-robust wrap-around, so I 
>>>> don't have to
>>>> remember or parse the xjust and yjust options necessary to make it 
>>>> work. Of
>>>> course there should be the option of entering in your own coordinates.
>>>> Also it would be nice to be able to put a optional title inside your 
>>>> legend.
>>>> Currently I just make my title the first value in my legend vector, 
>>>> and then fix
>>>> the other options so no symbols plot next to it. But this isn't 
>>>> always a pretty
>>>> result and can be a pain if your symbols are complicated.
>>>>
>>>> Thanks,
>>>> Elizabeth
>>>> Response to Elizabeth by Duncan Murdoch
>>>> ---------------------------------------------------------------
>>>>
>>>> -- 
>>>> Lep pozdrav / With regards,
>>>>     Gregor GORJANC
>>>>
>>>> ---------------------------------------------------------------
>>>> University of Ljubljana
>>>> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
>>>> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
>>>> Groblje 3                  tel: +386 (0)1 72 17 861
>>>> SI-1230 Domzale            fax: +386 (0)1 72 17 888
>>>> Slovenia
>>>>
>>>> ______________________________________________
>>>> R-devel@stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>>
>>>
>>
> 
> 

-- 
Lep pozdrav / With regards,
     Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From ripley at stats.ox.ac.uk  Mon Feb 14 12:35:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 12:35:46 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
In-Reply-To: <Pine.LNX.4.61.0502141102430.30303@gannet.stats>
References: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>
	<42105519.6020609@statistik.uni-dortmund.de>
	<42108463.7050703@bfro.uni-lj.si>
	<Pine.LNX.4.61.0502141102430.30303@gannet.stats>
Message-ID: <Pine.LNX.4.61.0502141134060.5184@gannet.stats>

On Mon, 14 Feb 2005, Prof Brian Ripley wrote:

> On Mon, 14 Feb 2005, Gregor GORJANC wrote:

>> You are right with NEWS file in R-devel. It really documents this 
>> improvement. Very nice. You guys really do an excellent job. I did not 
>> looked in NEWS file since it is kind of "hidden" i.e. one needs to download 
>> the R-devel and look in that file. But I confes, it is my blame, not of 
>> R-devel
>
> It is accessible at
>
> https://svn.r-project.org/R/trunk/NEWS

and I have now linked that off the developer page (but it will not become 
visible until that gets its daily update).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Mon Feb 14 12:38:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 12:38:31 2005
Subject: [Rd] corrupt data frame: columns will be truncated or padded
	with NAs in: format.data.frame(x, digits = digits)
In-Reply-To: <421089C7.8080401@bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>
	<Pine.LNX.4.61.0502140725570.22249@gannet.stats>
	<421089C7.8080401@bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502141127480.5184@gannet.stats>

On Mon, 14 Feb 2005, Gregor GORJANC wrote:

> Prof Brian Ripley wrote:

>> You did create a corrupt data frame by using *replacement* on part of 
>> something that did not exist.  The simple workaround is not to do that. One 
>> can argue about what should happen in such a case and currently R assumes 
>> that you know what you are doing and will only treat the data frame as a 
>> list. We could make this an error, but that would add an overhead to be 
>> paid by careful users too.

> I agree to some extent, however I was very surprised of this behaviour. I 
> often deal with data that have missing values and now I really do not know 
> how to manage such data. How can one add a column to existing data frame
> in such a way, that you don't get corrupted data frames as in my example?

You add a column, not replace part of a non-existent column.  Isn't that 
obvious, given what you wrote?

There is a lot of basic documentation on data manipulation in R/S, and a 
whole chapter in MASS4.  Somehow most other people don't seem to find this 
a problem.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Friedrich.Leisch at tuwien.ac.at  Mon Feb 14 13:09:37 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon Feb 14 13:12:55 2005
Subject: [Rd] Wishlist: simple legend options (PR#7400)
In-Reply-To: <42108B54.4050404@bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF12@pollux.bfro.uni-lj.si>
	<42105519.6020609@statistik.uni-dortmund.de>
	<42108463.7050703@bfro.uni-lj.si>
	<4210863D.5090609@statistik.uni-dortmund.de>
	<42108B54.4050404@bfro.uni-lj.si>
Message-ID: <16912.38145.46812.840218@galadriel.ci.tuwien.ac.at>

>>>>> On Mon, 14 Feb 2005 12:28:20 +0100,
>>>>> Gregor GORJANC (GG) wrote:

  > I added link to https://svn.r-project.org/R/trunk/NEWS in files
  > http://www.bfro.uni-lj.si/MR/ggorjan/sources.html
  > http://www.bfro.uni-lj.si/MR/ggorjan/banner.shtml

Thanks, I have copied those to CRAN with only minor modifications.

Best,
Fritz

From gregor.gorjanc at bfro.uni-lj.si  Mon Feb 14 13:32:04 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Mon Feb 14 13:32:31 2005
Subject: [Rd] corrupt data frame: columns will be truncated or padded
	with NAs in: format.data.frame(x, digits = digits)
In-Reply-To: <Pine.LNX.4.61.0502141127480.5184@gannet.stats>
References: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>
	<Pine.LNX.4.61.0502140725570.22249@gannet.stats>
	<421089C7.8080401@bfro.uni-lj.si>
	<Pine.LNX.4.61.0502141127480.5184@gannet.stats>
Message-ID: <42109A44.4050701@bfro.uni-lj.si>

Hello!

Sending this also to r-help so anyone can read it also there and maybe also 
help me with my puzzle if this trivial and I don't see it.

Prof Brian Ripley wrote:
[... removed some ...]
> You add a column, not replace part of a non-existent column.  Isn't that 
> obvious, given what you wrote?

# OK. If I do
tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D")))
tmp[1:2, "y2"] <- 2
tmp
# I am changing nonexistent column y2 in data frame tmp.

# If I do
tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D")))
tmp$y2 <- NA
tmp[1:2, "y2"] <- 2
tmp
# I am changing existent column. I understand now the difference. However,
# it is weird for me that this is OK (if column y2 does not yet exist)
tmp["y2"] <- 2
# but this is not
tmp[1:2, "y2"] <- 2

> There is a lot of basic documentation on data manipulation in R/S, and a 
> whole chapter in MASS4.  Somehow most other people don't seem to find 
> this a problem.

I just ordered MASS4 last week and I am eager to get it in my hands. In 
meanwhile I read quite some documentation and what I more or less saw is

tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D")))
tmp$y2 <- 1:4
tmp$y3 <- 2*tmp$y1
...
...

i.e. everybody is adding full column to data frame. But I would like to add 
just one part.

-- 
Lep pozdrav / With regards,
     Gregor GORJANC

---------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si
Zootechnical Department    mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

From p.dalgaard at biostat.ku.dk  Mon Feb 14 13:35:31 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Feb 14 13:40:28 2005
Subject: [Rd] sprintf - was formatC with illegal input crashes Rgui
	(PR#7686)
In-Reply-To: <42107994.9070500@ebi.ac.uk>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>
	<4210741A.8040606@ebi.ac.uk>
	<Pine.LNX.4.61.0502141052360.30303@gannet.stats>
	<42107994.9070500@ebi.ac.uk>
Message-ID: <x2mzu7jp4c.fsf@biostat.ku.dk>

Wolfgang Huber <huber@ebi.ac.uk> writes:

> Personally, I would prefer the recycling, but of course it can be also
> done this way:
> 
>  > mapply(sprintf, "%04d %s", 1:3, "abc")
>     %04d %s       <NA>       <NA>
> "0001 abc" "0002 abc" "0003 abc"
> 
> the only slightly unaesthetic thing being the names of the resulting vector.

...which is of course fixable with either of


> mapply(sprintf, MoreArgs=list(fmt="%04d %s"), 1:3, "abc")
[1] "0001 abc" "0002 abc" "0003 abc"
> mapply(sprintf, 1:3, "abc", fmt="%04d %s")
[1] "0001 abc" "0002 abc" "0003 abc"
> mapply(sprintf, "%04d %s", 1:3, "abc", USE.NAMES=FALSE)
[1] "0001 abc" "0002 abc" "0003 abc"

(Only the last one is completely failsafe since the first two relies
on 1:3 not being character:

    if (USE.NAMES && length(dots) && is.character(dots[[1]]) &&
        is.null(names(answer)))
        names(answer) <- dots[[1]]
)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Mon Feb 14 14:23:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 14:23:57 2005
Subject: [R] Re: [Rd] corrupt data frame: columns will be truncated or
	padded with NAs in: format.data.frame(x, digits = digits)
In-Reply-To: <42109A44.4050701@bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>
	<Pine.LNX.4.61.0502140725570.22249@gannet.stats>
	<421089C7.8080401@bfro.uni-lj.si>
	<Pine.LNX.4.61.0502141127480.5184@gannet.stats>
	<42109A44.4050701@bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502141311420.19217@gannet.stats>

On Mon, 14 Feb 2005, Gregor GORJANC wrote:

> Sending this also to r-help so anyone can read it also there and maybe also 
> help me with my puzzle if this trivial and I don't see it.

Please don't, and especially do not after having removed the context.
So I have removed R-help from the follow-up.

> Prof Brian Ripley wrote:
> [... removed some ...]

The question I answered has been removed here, which is discourteous both 
to your helper and to your readers.

>> You add a column, not replace part of a non-existent column.  Isn't that 
>> obvious, given what you wrote?

Not if you subsequently remove what you wrote, of course.

> # OK. If I do
> tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D")))
> tmp[1:2, "y2"] <- 2
> tmp
> # I am changing nonexistent column y2 in data frame tmp.
>
> # If I do
> tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D")))
> tmp$y2 <- NA
> tmp[1:2, "y2"] <- 2
> tmp
> # I am changing existent column. I understand now the difference. However,
> # it is weird for me that this is OK (if column y2 does not yet exist)
> tmp["y2"] <- 2
> # but this is not
> tmp[1:2, "y2"] <- 2

What is `wierd' is your insistence that this makes sense.  Columns in a 
data frame are required to be the same length.  How is that supposed to be 
made up to the correct length?  Possible for a numeric column with NAs, 
but not sensible for a raw column or a data frame column or ....

>> There is a lot of basic documentation on data manipulation in R/S, and a 
>> whole chapter in MASS4.  Somehow most other people don't seem to find this 
>> a problem.
>
> I just ordered MASS4 last week and I am eager to get it in my hands. In 
> meanwhile I read quite some documentation and what I more or less saw is
>
> tmp <- data.frame(y1=1:4, f1=factor(c("A", "B", "C", "D")))
> tmp$y2 <- 1:4
> tmp$y3 <- 2*tmp$y1
> ...
> ...
>
> i.e. everybody is adding full column to data frame. But I would like to add 
> just one part.

But you cannot do so and not get a corrupt data frame. All you can hope 
for is to add a column and for something arbitrary to be added to your 
input to do so.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Mon Feb 14 14:27:03 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 14 14:27:16 2005
Subject: [R] Re: [Rd] corrupt data frame: columns will be truncated or
	padded with NAs in: format.data.frame(x, digits = digits)
In-Reply-To: <42109A44.4050701@bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B6FF14@pollux.bfro.uni-lj.si>
	<Pine.LNX.4.61.0502140725570.22249@gannet.stats>
	<421089C7.8080401@bfro.uni-lj.si>
	<Pine.LNX.4.61.0502141127480.5184@gannet.stats>
	<42109A44.4050701@bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0502141324130.19217@gannet.stats>

On Mon, 14 Feb 2005, Gregor GORJANC wrote:

> Sending this also to r-help so anyone can read it also there and maybe also 
> help me with my puzzle if this trivial and I don't see it.

Please don't, and especially do not after having removed the context.
So I have replied only on R-devel.

> Prof Brian Ripley wrote:
> [... removed some ...]
>> You add a column, not replace part of a non-existent column.  Isn't that 
>> obvious, given what you wrote?

Not if you subsequently remove what you wrote and re-post elsewhere, of 
course,

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From roebuck at odin.mdacc.tmc.edu  Mon Feb 14 17:08:20 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Mon Feb 14 17:08:33 2005
Subject: [Rd] Test Tools
Message-ID: <Pine.OSF.4.58.0502141006090.361948@odin.mdacc.tmc.edu>

Anyone aware of tools available that can provide complexity
metrics and/or code coverage analysis for R source?

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From p.murrell at auckland.ac.nz  Mon Feb 14 21:09:37 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon Feb 14 21:09:45 2005
Subject: [Rd] R News: Call for Papers
Message-ID: <42110581.5070601@stat.auckland.ac.nz>

Dear useRs and developeRs,

the next issue of `R News' is scheduled for the beginning of May
and we are now  accepting submissions for this first issue in 2005.
For more information see

       http://cran.r-project.org/doc/Rnews/

If you are the author of a package on CRAN and you would like to promote
it a little bit, or if you simply have an interesting application using
R, we hope you can find some time to write a short article on it. We
suggest that it be approximately 3 pages or less. The idea of the
newsletter is that it be interesting to R users without being too
technical. For example an article describing a package could begin by
briefly outlining the statistical background and go on to demonstrate
the usage on some typical data set. Of course graphics are more than
welcome!

Bill Venables <Bill.Venables@csiro.au> is also encouraging submissions
to the more specialist Programmer's Niche column. In this case the
technical level could be a little higher, of course, but not necessarily:
ingeniousness is the key.

The R Help Desk column is intended to present answers to frequently
asked questions as well as tricks that are useful to the majority of
useRs. Please send submissions to Uwe Ligges <Uwe.Ligges@R-project.org>.

The deadline for submissions is

	April, 10th, 2005

Keep the contributions rolling in!

The Editorial Board,

Doug Bates, Paul Murrell and Torsten Hothorn

From ggrothendieck at myway.com  Mon Feb 14 23:36:33 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon Feb 14 23:39:41 2005
Subject: [Rd] Test Tools
References: <Pine.OSF.4.58.0502141006090.361948@odin.mdacc.tmc.edu>
Message-ID: <loom.20050214T233448-453@post.gmane.org>

Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:

> 
> Anyone aware of tools available that can provide complexity
> metrics and/or code coverage analysis for R source?
> 

I am not aware of anything but there are some code tools in 
the codetools package.  Do a google search for:
   codetools Luke

Note that most software complexity metrics are highly correlated
so there may be little to gain beyond using lines of code.

From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Feb 15 08:29:02 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue Feb 15 08:30:23 2005
Subject: [Rd] R News: Call for Papers
Message-ID: <Pine.LNX.4.51.0502150828070.28678@artemis.imbe.med.uni-erlangen.de>


Dear useRs and developeRs,

the next issue of `R News' is scheduled for the beginning of May
and we are now  accepting submissions for this first issue in 2005.
For more information see

      http://cran.r-project.org/doc/Rnews/

If you are the author of a package on CRAN and you would like to promote
it a little bit, or if you simply have an interesting application using
R, we hope you can find some time to write a short article on it. We
suggest that it be approximately 3 pages or less. The idea of the
newsletter is that it be interesting to R users without being too
technical. For example an article describing a package could begin by
briefly outlining the statistical background and go on to demonstrate
the usage on some typical data set. Of course graphics are more than
welcome!

Bill Venables <Bill.Venables@csiro.au> is also encouraging submissions
to the more specialist Programmer's Niche column. In this case the
technical level could be a little higher, of course, but not necessarily:
ingeniousness is the key.

The R Help Desk column is intended to present answers to frequently
asked questions as well as tricks that are useful to the majority of
useRs. Please send submissions to Uwe Ligges <Uwe.Ligges@R-project.org>.

The deadline for submissions is

        April, 10th, 2005

Keep the contributions rolling in!

The Editorial Board,

Doug Bates, Paul Murrell and Torsten Hothorn

From manuel_gutierrez_lopez at yahoo.es  Tue Feb 15 10:36:56 2005
From: manuel_gutierrez_lopez at yahoo.es (Manuel Gutierrez)
Date: Tue Feb 15 10:37:07 2005
Subject: [Rd] difference between class - SOM and som_pack
Message-ID: <20050215093656.70906.qmail@web25106.mail.ukl.yahoo.com>

What is the difference (if any) between SOM() function
in library(class) and the som_pack algorithm?
Which is the neighborhood and alpha function types
used in SOM()?
Thanks,
Manuel

From huber at ebi.ac.uk  Tue Feb 15 10:56:02 2005
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Tue Feb 15 10:56:18 2005
Subject: [Rd] sprintf - was formatC with illegal input crashes Rgui
	(PR#7686)
In-Reply-To: <x2mzu7jp4c.fsf@biostat.ku.dk>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>	<4210741A.8040606@ebi.ac.uk>	<Pine.LNX.4.61.0502141052360.30303@gannet.stats>	<42107994.9070500@ebi.ac.uk>
	<x2mzu7jp4c.fsf@biostat.ku.dk>
Message-ID: <4211C732.6050402@ebi.ac.uk>

Hi Peter,

thanks. Yet my intention was not to discuss whether this could be done 
at all (never had any doubts about that), but how it could be done 
nicely and conveniently for the application programmer.

   Best regards
   Wolfgang

Peter Dalgaard wrote:
> Wolfgang Huber <huber@ebi.ac.uk> writes:
> 
> 
>>Personally, I would prefer the recycling, but of course it can be also
>>done this way:
>>
>> > mapply(sprintf, "%04d %s", 1:3, "abc")
>>    %04d %s       <NA>       <NA>
>>"0001 abc" "0002 abc" "0003 abc"
>>
>>the only slightly unaesthetic thing being the names of the resulting vector.
> 
> 
> ...which is of course fixable with either of
> 
> 
> 
>>mapply(sprintf, MoreArgs=list(fmt="%04d %s"), 1:3, "abc")
> 
> [1] "0001 abc" "0002 abc" "0003 abc"
> 
>>mapply(sprintf, 1:3, "abc", fmt="%04d %s")
> 
> [1] "0001 abc" "0002 abc" "0003 abc"
> 
>>mapply(sprintf, "%04d %s", 1:3, "abc", USE.NAMES=FALSE)
> 
> [1] "0001 abc" "0002 abc" "0003 abc"
> 
> (Only the last one is completely failsafe since the first two relies
> on 1:3 not being character:
> 
>     if (USE.NAMES && length(dots) && is.character(dots[[1]]) &&
>         is.null(names(answer)))
>         names(answer) <- dots[[1]]
> )

From ripley at stats.ox.ac.uk  Tue Feb 15 12:54:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb 15 12:54:58 2005
Subject: [Rd] sprintf
In-Reply-To: <4211C732.6050402@ebi.ac.uk>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>
	<4210741A.8040606@ebi.ac.uk>
	<Pine.LNX.4.61.0502141052360.30303@gannet.stats>
	<42107994.9070500@ebi.ac.uk>
	<x2mzu7jp4c.fsf@biostat.ku.dk> <4211C732.6050402@ebi.ac.uk>
Message-ID: <Pine.LNX.4.61.0502151153270.21472@gannet.stats>

sprintf() in R-devel is now vectorized, re-cycling its arguments, 
including fmt, as required.

On Tue, 15 Feb 2005, Wolfgang Huber wrote:

> Hi Peter,
>
> thanks. Yet my intention was not to discuss whether this could be done at all 
> (never had any doubts about that), but how it could be done nicely and 
> conveniently for the application programmer.
>
>  Best regards
>  Wolfgang
>
> Peter Dalgaard wrote:
>> Wolfgang Huber <huber@ebi.ac.uk> writes:
>> 
>> 
>>> Personally, I would prefer the recycling, but of course it can be also
>>> done this way:
>>> 
>>> > mapply(sprintf, "%04d %s", 1:3, "abc")
>>>    %04d %s       <NA>       <NA>
>>> "0001 abc" "0002 abc" "0003 abc"
>>> 
>>> the only slightly unaesthetic thing being the names of the resulting 
>>> vector.
>> 
>> 
>> ...which is of course fixable with either of
>> 
>> 
>> 
>>> mapply(sprintf, MoreArgs=list(fmt="%04d %s"), 1:3, "abc")
>> 
>> [1] "0001 abc" "0002 abc" "0003 abc"
>> 
>>> mapply(sprintf, 1:3, "abc", fmt="%04d %s")
>> 
>> [1] "0001 abc" "0002 abc" "0003 abc"
>> 
>>> mapply(sprintf, "%04d %s", 1:3, "abc", USE.NAMES=FALSE)
>> 
>> [1] "0001 abc" "0002 abc" "0003 abc"
>> 
>> (Only the last one is completely failsafe since the first two relies
>> on 1:3 not being character:
>> 
>>     if (USE.NAMES && length(dots) && is.character(dots[[1]]) &&
>>         is.null(names(answer)))
>>         names(answer) <- dots[[1]]
>> )
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Tue Feb 15 14:41:03 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue Feb 15 14:46:10 2005
Subject: mapply(), was Re: [Rd] sprintf
In-Reply-To: <Pine.LNX.4.61.0502151153270.21472@gannet.stats>
References: <20050211175824.5EB48DEE7@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0502140956020.29523@gannet.stats>
	<4210741A.8040606@ebi.ac.uk>
	<Pine.LNX.4.61.0502141052360.30303@gannet.stats>
	<42107994.9070500@ebi.ac.uk> <x2mzu7jp4c.fsf@biostat.ku.dk>
	<4211C732.6050402@ebi.ac.uk>
	<Pine.LNX.4.61.0502151153270.21472@gannet.stats>
Message-ID: <x2zmy6j5zk.fsf_-_@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> sprintf() in R-devel is now vectorized, re-cycling its arguments,
> including fmt, as required.

Thanks, Brian. 

This leaves me with one question: what is actually the wisdom behind
the USE.NAMES default in mapply? Seems to me that it gets in the way
more often that it is useful (and has some real problems with
recycling, clearly). Thomas?

> >>> mapply(sprintf, "%04d %s", 1:3, "abc", USE.NAMES=FALSE)
> >> [1] "0001 abc" "0002 abc" "0003 abc"

> >>     if (USE.NAMES && length(dots) && is.character(dots[[1]]) &&
> >>         is.null(names(answer)))
> >>         names(answer) <- dots[[1]]
> >> )


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From sdutky at starpower.net  Tue Feb 15 18:04:39 2005
From: sdutky at starpower.net (Steve Dutky)
Date: Tue Feb 15 18:04:48 2005
Subject: [Rd] Apropos sprintf behavior
Message-ID: <bd8532ae.cf18ec10.81de700@ms08.mrf.mail.rcn.net>

If changes to sprintf behavior are being considered, would it 
be possible to allow some of the other K&R conversion 
specifiers? 

xX - for integer to hex conversion, and
c  - for ascii value to character conversion

would all be useful for me.

Thanks, Steve Dutky
 
On Mon, 14 Feb 2005 11:02:20 +0000 (GMT), Prof Brian Ripley 
wrote:

+On Mon, 14 Feb 2005, Wolfgang Huber wrote:
+
+> Dear Prof. Ripley,
+>
+> Would it be possible to make sprintf accept vector 
arguments?
+> I.e. allow expressions like
+>  sprintf("%04d", 1:3)
+> to produce something like what currently needs to be done 
via
+>  sapply(1:3, function(i) sprintf("%04d",i))
+
+I have thought about this, but it is not really clear what 
the right thing 
+would be here with multiple arguments.  What should
+
+sprintf(("%04d %s", 1:3, "abc")
+
+do?  Produce a character vector of length 1 or 3?  If of 
length 1,
+"0001 0002 0003 abc" or "0001 2 0003 abc"?
+
+I guess the most R-like thing would be to recycle args to 
the length of 
+the longest and then use them in parallel, but that can be 
done fairly 
+easily by *apply.

From ripley at stats.ox.ac.uk  Tue Feb 15 18:17:14 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb 15 18:17:21 2005
Subject: [Rd] Apropos sprintf behavior
In-Reply-To: <bd8532ae.cf18ec10.81de700@ms08.mrf.mail.rcn.net>
References: <bd8532ae.cf18ec10.81de700@ms08.mrf.mail.rcn.net>
Message-ID: <Pine.LNX.4.61.0502151713270.31484@gannet.stats>

Patches against the current R-devel sources will be considered, but note 
that 'x' is already there, and there is rawToChar.


On Tue, 15 Feb 2005, Steve Dutky wrote:

> If changes to sprintf behavior are being considered, would it
> be possible to allow some of the other K&R conversion
> specifiers?
>
> xX - for integer to hex conversion, and
> c  - for ascii value to character conversion
>
> would all be useful for me.
>
> Thanks, Steve Dutky
>
> On Mon, 14 Feb 2005 11:02:20 +0000 (GMT), Prof Brian Ripley
> wrote:
>
> +On Mon, 14 Feb 2005, Wolfgang Huber wrote:
> +
> +> Dear Prof. Ripley,
> +>
> +> Would it be possible to make sprintf accept vector
> arguments?
> +> I.e. allow expressions like
> +>  sprintf("%04d", 1:3)
> +> to produce something like what currently needs to be done
> via
> +>  sapply(1:3, function(i) sprintf("%04d",i))
> +
> +I have thought about this, but it is not really clear what
> the right thing
> +would be here with multiple arguments.  What should
> +
> +sprintf(("%04d %s", 1:3, "abc")
> +
> +do?  Produce a character vector of length 1 or 3?  If of
> length 1,
> +"0001 0002 0003 abc" or "0001 2 0003 abc"?
> +
> +I guess the most R-like thing would be to recycle args to
> the length of
> +the longest and then use them in parallel, but that can be
> done fairly
> +easily by *apply.
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tplate at acm.org  Tue Feb 15 19:07:32 2005
From: tplate at acm.org (Tony Plate)
Date: Tue Feb 15 19:07:50 2005
Subject: [Rd] Test Tools
In-Reply-To: <Pine.OSF.4.58.0502141006090.361948@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0502141006090.361948@odin.mdacc.tmc.edu>
Message-ID: <6.2.1.2.2.20050214180809.06779c58@mailhost.blackmesacapital.com>

 From memory, the "RUnit" package (by Burger, Juenemann and Koenig) does 
some source code analysis to provide some statistics regarding tests and 
source code (but I don't remember seeing anything to compute complexity 
metrics in there.)

-- Tony

At Monday 09:08 AM 2/14/2005, Paul Roebuck wrote:
>Anyone aware of tools available that can provide complexity
>metrics and/or code coverage analysis for R source?
>
>----------------------------------------------------------
>SIGSIG -- signature too long (core dumped)
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel

From hb at maths.lth.se  Wed Feb 16 15:05:44 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed Feb 16 15:11:26 2005
Subject: [Rd] Depends, require(), autoload() and "side effects"?
Message-ID: <002101c51430$9c7ab3c0$57f1ba51@hblaptop>

Hi.

If your package require another package in order to define its methods (but
afterwards in is not needed), how should one specify this? Is it correct to
assume that "Depends" will assure that all packages are loaded (attached?
what is the right word) *before* the methods in the current package are
defined? Basically I use my own setMethod() called setMethodS3() that is
defined in package R.oo.

In pre R v2.0.0 this could be done adding a require() at the beginning of
the package source, but since R v2.0.0 this should be avoided according to
R-exts [R v2.1.0 devel] (Section 1.1.4; "The R code files should only create
R objects and not call functions with side effects such as require and
options.").

DESCRIPTION/Depends: In R-ext Section 1.1.1 it says "The R INSTALL
facilities check if the version of R used is recent enough for the package
being installed, and the list of packages which is specified [in Depends]
will be attached (after checking version dependencies) before the current
package, both when library is called and when saving an image of the
package's code or preparing for lazy-loading." and further done "The general
rules are: ... Packages that need to be attached to successfully load the
package using library(pkgname) must be listed in the Depends field."

I use Depends, which works (installs from source and loads) on R v2.0.1
patch and R v2.1.0 devel on WinXP Pro, but not on R v2.0.1 on Sun Solaris.
Here is how I do it:

In my R.oo package I define setMethodS3() to simplify creation of S3 methods
and generic functions. Other packages of mine make use of this method (and
some other methods of R.oo such as appendVarArgs() as seen below) when
defining their methods. 

Consider a package R.matlab that depends on R.oo for the above reason. I do
not use namespaces.  To attach R.oo to load R.matlab, I add R.oo in the
Depends field of DESCRIPTION as follows:

Package: R.matlab
Version: 1.0
Date: 2005-02-15
Title: Matlab connectivity and read and write of MAT files
Author: Henrik Bengtsson <henrikb@braju.com>
Maintainer: Henrik Bengtsson <henrikb@braju.com>
Depends: R.oo
Description: This package provides methods to read and write MAT files.  It
also makes it possible to communicate (evaluate code, send and retrieve
objects etc.) with Matlab v6 or higher running locally or on a remote host.
The auxillary Java class provides static methods to read and write Java data
types.
License: GPL version 2 or newer
URL: http://www.braju.com/R/
LazyLoad: TRUE 

I then build a source package using R v2.1.0 devel (on WinXP Pro).
Installation from source and package loading works fine on WinXP Pro with R
v2.0.1 patched and R v2.1.0 devel.  On a Solaris with R v2.0.1 (standard), I
get: 

% R CMD INSTALL R.matlab_1.0.tar.gz
* Installing *source* package 'R.matlab' ...
** R
** inst
** preparing package for lazy loading
Error in eval(expr, envir, enclos) : couldn't find function "appendVarArgs"
Execution halted
ERROR: lazy loading failed for package 'R.matlab'
** Removing '/usr/matstat/hb/R/R_LIBS/sunos/library/R.matlab'
** Restoring previous '/usr/matstat/hb/R/R_LIBS/sunos/library/R.matlab'

appendVarArgs() is defined in R.oo. 

I tried to add a require(R.oo) (in 000.R) and it does work perfectly. So do
also autoload("appendVarArgs", package="R.oo") etc. Is autoload() ok to use,
or does it use side effects? Is even require(R.oo) ok to use for the purpose
to *load* the package?

Best wishes

Henrik Bengtsson

From Wittner.Ben at mgh.harvard.edu  Wed Feb 16 16:27:17 2005
From: Wittner.Ben at mgh.harvard.edu (Wittner, Ben)
Date: Wed Feb 16 16:27:28 2005
Subject: [Rd] config.status: error: cannot find input file: po/Makefile.in.in
Message-ID: <C6B4E960236FD311B4E00008C7F406E31404B7CC@phsexch11.mgh.harvard.edu>

The tarballs

R-devel_2005-02-16.tar.gz,
R-devel_2005-02-15.tar.gz and
R-devel_2005-02-14.tar.gz

all had the property that when I run ./configure on them I get the following
error message:

config.status: error: cannot find input file: po/Makefile.in.in

which terminates the configure script.

After R-devel_2005-02-15.tar.gz was posted but before R-devel_2005-02-16.tar.gz
was posted, Jeff Gentry got the devel version of R from SVM and it did not have
this problem, so he and I thought it was a problem that had been fixed sometime
after R-devel_2005-02-15.tar.gz was made.
But, since it still happens in R-devel_2005-02-16.tar.gz, I would guess it's a
problem with the tarball creation software.

I'm running Red Hat Linux enterprise edition 3 work station.

-Ben

From bluefuture at email.it  Wed Feb 16 18:03:06 2005
From: bluefuture at email.it (Bluefuture)
Date: Wed Feb 16 17:03:25 2005
Subject: [Rd] Gtk2 interface to R
Message-ID: <1108573387.14491.2.camel@atlantide>

Hi,
i want to know if is planned or there is already some code about Gtk2
porting of the actual Gtk1 R consolle.

Tanks,
Blue

From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 16 17:57:40 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed Feb 16 17:58:58 2005
Subject: [Rd] promptMethods(foo) & \alias{foo}
Message-ID: <Pine.LNX.4.51.0502161755320.16689@artemis.imbe.med.uni-erlangen.de>


Dear all,

`promptMethods(foo)' currently does not produce and Rd-skeleton including
an `\alias{foo}' entry, which is required (at least R CMD check keeps
crying until the alias is added). Maybe one could simply add this line.

Thanks,

Torsten

From ripley at stats.ox.ac.uk  Wed Feb 16 18:17:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb 16 18:17:51 2005
Subject: [Rd] config.status: error: cannot find input file:
	po/Makefile.in.in
In-Reply-To: <C6B4E960236FD311B4E00008C7F406E31404B7CC@phsexch11.mgh.harvard.edu>
References: <C6B4E960236FD311B4E00008C7F406E31404B7CC@phsexch11.mgh.harvard.edu>
Message-ID: <Pine.LNX.4.61.0502161705130.3173@gannet.stats>

Your second guess is right and we do already know that the tarballs are 
incomplete.

Unfortunately the person whose scripts are running this is on vacation and 
only he can rectify this.  The intention is that if `make dist' fails in 
any way you do not get a tarball, so I don't understand how these partial 
tarballs are being created -- not that it is failing for me.  (I have a 
guess as to what the problem is, a conflict on an automated svn update.)

Please use Subversion for now, and please be patient: R is a volunteer 
project and we cannot be expected to have unstable versions available at 
all times.


On Wed, 16 Feb 2005, Wittner, Ben wrote:

> The tarballs
>
> R-devel_2005-02-16.tar.gz,
> R-devel_2005-02-15.tar.gz and
> R-devel_2005-02-14.tar.gz

Please note that those tarballs are not on a R site per se.

> all had the property that when I run ./configure on them I get the following
> error message:
>
> config.status: error: cannot find input file: po/Makefile.in.in
>
> which terminates the configure script.
>
> After R-devel_2005-02-15.tar.gz was posted but before 
> R-devel_2005-02-16.tar.gz was posted, Jeff Gentry got the devel version 
> of R from SVM and it did not have this problem, so he and I thought it 
> was a problem that had been fixed sometime after 
> R-devel_2005-02-15.tar.gz was made. But, since it still happens in 
> R-devel_2005-02-16.tar.gz, I would guess it's a problem with the tarball 
> creation software.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Feb 16 20:03:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb 16 20:03:16 2005
Subject: [Rd] Gtk2 interface to R
In-Reply-To: <1108573387.14491.2.camel@atlantide>
References: <1108573387.14491.2.camel@atlantide>
Message-ID: <Pine.LNX.4.61.0502161901150.7460@gannet.stats>

We have an experimental GNOME console.  Is that what you mean, or are you 
referring to something not part of R, in a package for example?

The GNOME console will not be part of the next release of R.

On Wed, 16 Feb 2005, Bluefuture wrote:

> i want to know if is planned or there is already some code about Gtk2
> porting of the actual Gtk1 R consolle.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From bluefuture at email.it  Wed Feb 16 23:51:47 2005
From: bluefuture at email.it (Bluefuture)
Date: Wed Feb 16 22:52:00 2005
Subject: [Rd] Gtk2 interface to R
In-Reply-To: <Pine.LNX.4.61.0502161901150.7460@gannet.stats>
References: <1108573387.14491.2.camel@atlantide>
	<Pine.LNX.4.61.0502161901150.7460@gannet.stats>
Message-ID: <1108594307.8714.1.camel@atlantide>

Il giorno mer, 16-02-2005 alle 19:03 +0000, Prof Brian Ripley ha
scritto:
> We have an experimental GNOME console.  Is that what you mean, or are you 
> referring to something not part of R, in a package for example?
> 
> The GNOME console will not be part of the next release of R.
> 
I'm talking about the gnome console. So will it be discontinued, with no
more develop effort by the next release?

Tanks,
Blue

From detlef.steuer at hsu-hamburg.de  Thu Feb 17 09:43:44 2005
From: detlef.steuer at hsu-hamburg.de (Detlef Steuer)
Date: Thu Feb 17 09:43:41 2005
Subject: [Rd] german translation
Message-ID: <20050217094344.08dd5714@gaia.unibw-hamburg.de>

Hello dear R-core,

I would be willing to offer some spare time to generate a german translation of R.pot and RGui.pot.

Do you still need a translator or does someone already work on that task? (I hate useless duplication of efforts.)

To whom shall I send the de.po file? Or should I generate a diff against the latest svn sources?
What's your standard procedure for these cases?

Are there already any hints what to do and what to avoid while translating?

detlef

From imosqueira at suk.azti.es  Thu Feb 17 13:37:56 2005
From: imosqueira at suk.azti.es (Iago Mosqueira)
Date: Thu Feb 17 12:33:37 2005
Subject: [Rd] Subsetting using dimnames on S4 array-based class
In-Reply-To: <200502171119.j1HBImXa002842@hypatia.math.ethz.ch>
References: <200502171119.j1HBImXa002842@hypatia.math.ethz.ch>
Message-ID: <1108643876.2771.193.camel@xurelo.azti.local>

Hello,

I did send this message to r-help and got no reply, no I am resubmitting
here in case this was a bit too specific for the other list.

Many thanks,


Iago


                             From: 
Iago Mosqueira
<imosqueira@suk.azti.es>
                               To: 
r-help@stat.math.ethz.ch
                          Subject: 
Subsetting using dimnames on S4
array-based class
                             Date: 
Fri, 11 Feb 2005 08:29:03 +0000

Hello,

I am encountering some problems when overloading the "[" operator for a
new S4 class based on array. This is an example class definition:

setClass("foo",
        representation("array"),
        prototype(array(NA, dim=c(3,3)), 
        dimnames=list(age=1:3, year=10:12))
)

And this the corresponding setMethod with print estatements to see what
is being passed:

setMethod("[", signature(x="foo"),
    function(x, i="missing", j="missing", ..., drop="missing") {
        print(paste("i:", i))
        print(paste("j:", j))
     }
)


So I first create a new object and load it with some data:

> x <- new("foo")
> x[,] <- 1:9

And then apply subsetting without using the dimension names and see what
are the values of i and j inside the function:

> x[1:2,'10']
[1] "i: 1" "i: 2"
[1] "j: 10"


Both i and j hold exactly what was expected here. But if I use the
dimension names, the subsetting indices does not seem to be passed as I
expected:

> x[age=1:3, year=1:3]
[1] "i: missing"
[1] "j: missing"
> x[, year='10']
[1] "i: missing"
[1] "j: missing"

Subsetting with dimnames appears to work without trouble on an array,
which "foo" extends:

s<-array(1:9,dim=c(3,3),dimnames=list(age=1:3,year=1:3))
> s[1,2:3]
2 3 
4 7 
> s[age=1,year=2:3]
2 3 
4 7

Although dimnames seem to be in fact simply ignored:

> s[a=1,b=3]
[1] 7


System:
Linux Debian 3.0
R 2.0.0

Do I need to define my class differently for subsetting using dimnames
to work? Even if they are not really being checked, I would like to be
able to use subsetting in this way as it makes code more readable when
using arrays with many dimensions.

Many thanks,


Iago Mosqueira

From ripley at stats.ox.ac.uk  Thu Feb 17 13:32:23 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Feb 17 13:32:32 2005
Subject: [Rd] Subsetting using dimnames on S4 array-based class
In-Reply-To: <1108643876.2771.193.camel@xurelo.azti.local>
References: <200502171119.j1HBImXa002842@hypatia.math.ethz.ch>
	<1108643876.2771.193.camel@xurelo.azti.local>
Message-ID: <Pine.LNX.4.61.0502171200230.21232@gannet.stats>

On Thu, 17 Feb 2005, Iago Mosqueira wrote:

> I did send this message to r-help and got no reply, no I am resubmitting
> here in case this was a bit too specific for the other list.

Do read the posting guide before posting, as we ask.  It has clear 
guidelines on this.

Your problem seems to be that you want to use named arguments in 
subscripting (not really anything to do with your subject: using dimnames 
is like

s["row 1", "col 2"]

and you are talking about *names of* dimnames).

It `works' for arrays because the definition there (in ?Extract) is not 
the same as the generic you are using: notice the ... in the definitions, 
and for arrays it is really "["(x, ..., drop=TRUE) and the names of ... 
are ignored.

In brief: this is not how [ in R works.

Be careful:

m <- matrix(1:6, 2, 3)
M <- data.frame(a=1:2, b=3:4, c=5:6)
m[j=2, i=1] # 2
M[j=2, i=1] # 3

so argument names are ignored for the primitives, but not for S3 methods
(and I believe not for S4 methods).


>                             From:
> Iago Mosqueira
> <imosqueira@suk.azti.es>
>                               To:
> r-help@stat.math.ethz.ch
>                          Subject:
> Subsetting using dimnames on S4
> array-based class
>                             Date:
> Fri, 11 Feb 2005 08:29:03 +0000
>
> Hello,
>
> I am encountering some problems when overloading the "[" operator for a
> new S4 class based on array. This is an example class definition:
>
> setClass("foo",
>        representation("array"),
>        prototype(array(NA, dim=c(3,3)),
>        dimnames=list(age=1:3, year=10:12))
> )
>
> And this the corresponding setMethod with print estatements to see what
> is being passed:
>
> setMethod("[", signature(x="foo"),
>    function(x, i="missing", j="missing", ..., drop="missing") {
>        print(paste("i:", i))
>        print(paste("j:", j))
>     }
> )
>
>
> So I first create a new object and load it with some data:
>
>> x <- new("foo")
>> x[,] <- 1:9
>
> And then apply subsetting without using the dimension names and see what
> are the values of i and j inside the function:
>
>> x[1:2,'10']
> [1] "i: 1" "i: 2"
> [1] "j: 10"
>
>
> Both i and j hold exactly what was expected here. But if I use the
> dimension names, the subsetting indices does not seem to be passed as I
> expected:
>
>> x[age=1:3, year=1:3]
> [1] "i: missing"
> [1] "j: missing"
>> x[, year='10']
> [1] "i: missing"
> [1] "j: missing"
>
> Subsetting with dimnames appears to work without trouble on an array,
> which "foo" extends:
>
> s<-array(1:9,dim=c(3,3),dimnames=list(age=1:3,year=1:3))
>> s[1,2:3]
> 2 3
> 4 7
>> s[age=1,year=2:3]
> 2 3
> 4 7
>
> Although dimnames seem to be in fact simply ignored:
>
>> s[a=1,b=3]
> [1] 7
>
>
> System:
> Linux Debian 3.0
> R 2.0.0
>
> Do I need to define my class differently for subsetting using dimnames
> to work? Even if they are not really being checked, I would like to be
> able to use subsetting in this way as it makes code more readable when
> using arrays with many dimensions.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From imosqueira at suk.azti.es  Thu Feb 17 15:03:44 2005
From: imosqueira at suk.azti.es (Iago Mosqueira)
Date: Thu Feb 17 13:58:54 2005
Subject: [Rd] Subsetting using dimnames on S4 array-based class
In-Reply-To: <Pine.LNX.4.61.0502171200230.21232@gannet.stats>
References: <200502171119.j1HBImXa002842@hypatia.math.ethz.ch>
	<1108643876.2771.193.camel@xurelo.azti.local>
	<Pine.LNX.4.61.0502171200230.21232@gannet.stats>
Message-ID: <1108649023.25464.10.camel@xurelo.azti.local>

On Thu, 2005-02-17 at 12:32, Prof Brian Ripley wrote:

> and you are talking about *names of* dimnames).

Sorry for the confusion.

> It `works' for arrays because the definition there (in ?Extract) is not 
> the same as the generic you are using: notice the ... in the definitions, 
> and for arrays it is really "["(x, ..., drop=TRUE) and the names of ... 
> are ignored.

Thanks. I did realise for arrays the names are ignored, but in the new
class they are not even accepted.

> so argument names are ignored for the primitives, but not for S3 methods
> (and I believe not for S4 methods).

I am afraid I fail to see then why my example code fails to accept names
when subsetting. Shouldn't a class that extends "array" inherit this
behaviour too?

Many thanks,


Iago

> 
> 
> >                             From:
> > Iago Mosqueira
> > <imosqueira@suk.azti.es>
> >                               To:
> > r-help@stat.math.ethz.ch
> >                          Subject:
> > Subsetting using dimnames on S4
> > array-based class
> >                             Date:
> > Fri, 11 Feb 2005 08:29:03 +0000
> >
> > Hello,
> >
> > I am encountering some problems when overloading the "[" operator for a
> > new S4 class based on array. This is an example class definition:
> >
> > setClass("foo",
> >        representation("array"),
> >        prototype(array(NA, dim=c(3,3)),
> >        dimnames=list(age=1:3, year=10:12))
> > )
> >
> > And this the corresponding setMethod with print estatements to see what
> > is being passed:
> >
> > setMethod("[", signature(x="foo"),
> >    function(x, i="missing", j="missing", ..., drop="missing") {
> >        print(paste("i:", i))
> >        print(paste("j:", j))
> >     }
> > )
> >
> >
> > So I first create a new object and load it with some data:
> >
> >> x <- new("foo")
> >> x[,] <- 1:9
> >
> > And then apply subsetting without using the dimension names and see what
> > are the values of i and j inside the function:
> >
> >> x[1:2,'10']
> > [1] "i: 1" "i: 2"
> > [1] "j: 10"
> >
> >
> > Both i and j hold exactly what was expected here. But if I use the
> > dimension names, the subsetting indices does not seem to be passed as I
> > expected:
> >
> >> x[age=1:3, year=1:3]
> > [1] "i: missing"
> > [1] "j: missing"
> >> x[, year='10']
> > [1] "i: missing"
> > [1] "j: missing"
> >
> > Subsetting with dimnames appears to work without trouble on an array,
> > which "foo" extends:
> >
> > s<-array(1:9,dim=c(3,3),dimnames=list(age=1:3,year=1:3))
> >> s[1,2:3]
> > 2 3
> > 4 7
> >> s[age=1,year=2:3]
> > 2 3
> > 4 7
> >
> > Although dimnames seem to be in fact simply ignored:
> >
> >> s[a=1,b=3]
> > [1] 7
> >
> >
> > System:
> > Linux Debian 3.0
> > R 2.0.0
> >
> > Do I need to define my class differently for subsetting using dimnames
> > to work? Even if they are not really being checked, I would like to be
> > able to use subsetting in this way as it makes code more readable when
> > using arrays with many dimensions.

From ripley at stats.ox.ac.uk  Thu Feb 17 14:13:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Feb 17 14:13:28 2005
Subject: [Rd] Subsetting using dimnames on S4 array-based class
In-Reply-To: <1108649023.25464.10.camel@xurelo.azti.local>
References: <200502171119.j1HBImXa002842@hypatia.math.ethz.ch>
	<1108643876.2771.193.camel@xurelo.azti.local>
	<Pine.LNX.4.61.0502171200230.21232@gannet.stats>
	<1108649023.25464.10.camel@xurelo.azti.local>
Message-ID: <Pine.LNX.4.61.0502171310120.21232@gannet.stats>

On Thu, 17 Feb 2005, Iago Mosqueira wrote:

> On Thu, 2005-02-17 at 12:32, Prof Brian Ripley wrote:
>
>> and you are talking about *names of* dimnames).
>
> Sorry for the confusion.
>
>> It `works' for arrays because the definition there (in ?Extract) is not
>> the same as the generic you are using: notice the ... in the definitions,
>> and for arrays it is really "["(x, ..., drop=TRUE) and the names of ...
>> are ignored.
>
> Thanks. I did realise for arrays the names are ignored, but in the new
> class they are not even accepted.
>
>> so argument names are ignored for the primitives, but not for S3 methods
>> (and I believe not for S4 methods).
>
> I am afraid I fail to see then why my example code fails to accept names
> when subsetting. Shouldn't a class that extends "array" inherit this
> behaviour too?

No, it inherits from the S4 pseudo-method for "array", not the primitive.
Remember that S4 methods are bolted on to a different system, and bridging 
the gaps where possible has been very hard work (by John Chambers).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From wolski at molgen.mpg.de  Thu Feb 17 14:21:08 2005
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Thu Feb 17 14:21:26 2005
Subject: [Rd] Subsetting using dimnames on S4 array-based class
In-Reply-To: <1108649023.25464.10.camel@xurelo.azti.local>
References: <200502171119.j1HBImXa002842@hypatia.math.ethz.ch>	<1108643876.2771.193.camel@xurelo.azti.local>	<Pine.LNX.4.61.0502171200230.21232@gannet.stats>
	<1108649023.25464.10.camel@xurelo.azti.local>
Message-ID: <42149A44.1010008@molgen.mpg.de>

Hi,

The topic of extending S4 classes from S3 classes was discussed several 
times.
e.g.

S3 classes .... "don't have a consistent set of "slots" (they may or may 
not have a "dimnames), they aren't quite real classes in an S4 sense. It 
would be nice to fix this mess, but not obviously possible while being 
back compatible."

http://tolstoy.newcastle.edu.au/R/devel/05/01/1905.html


Eryk

Ps. A google search: *r-devel S4 array list* etc. Will provide you with 
more references.


Iago Mosqueira wrote:

>On Thu, 2005-02-17 at 12:32, Prof Brian Ripley wrote:
>
>  
>
>>and you are talking about *names of* dimnames).
>>    
>>
>
>Sorry for the confusion.
>
>  
>
>>It `works' for arrays because the definition there (in ?Extract) is not 
>>the same as the generic you are using: notice the ... in the definitions, 
>>and for arrays it is really "["(x, ..., drop=TRUE) and the names of ... 
>>are ignored.
>>    
>>
>
>Thanks. I did realise for arrays the names are ignored, but in the new
>class they are not even accepted.
>
>  
>
>>so argument names are ignored for the primitives, but not for S3 methods
>>(and I believe not for S4 methods).
>>    
>>
>
>I am afraid I fail to see then why my example code fails to accept names
>when subsetting. Shouldn't a class that extends "array" inherit this
>behaviour too?
>
>Many thanks,
>
>
>Iago
>
>  
>
>>    
>>
>>>                            From:
>>>Iago Mosqueira
>>><imosqueira@suk.azti.es>
>>>                              To:
>>>r-help@stat.math.ethz.ch
>>>                         Subject:
>>>Subsetting using dimnames on S4
>>>array-based class
>>>                            Date:
>>>Fri, 11 Feb 2005 08:29:03 +0000
>>>
>>>Hello,
>>>
>>>I am encountering some problems when overloading the "[" operator for a
>>>new S4 class based on array. This is an example class definition:
>>>
>>>setClass("foo",
>>>       representation("array"),
>>>       prototype(array(NA, dim=c(3,3)),
>>>       dimnames=list(age=1:3, year=10:12))
>>>)
>>>
>>>And this the corresponding setMethod with print estatements to see what
>>>is being passed:
>>>
>>>setMethod("[", signature(x="foo"),
>>>   function(x, i="missing", j="missing", ..., drop="missing") {
>>>       print(paste("i:", i))
>>>       print(paste("j:", j))
>>>    }
>>>)
>>>
>>>
>>>So I first create a new object and load it with some data:
>>>
>>>      
>>>
>>>>x <- new("foo")
>>>>x[,] <- 1:9
>>>>        
>>>>
>>>And then apply subsetting without using the dimension names and see what
>>>are the values of i and j inside the function:
>>>
>>>      
>>>
>>>>x[1:2,'10']
>>>>        
>>>>
>>>[1] "i: 1" "i: 2"
>>>[1] "j: 10"
>>>
>>>
>>>Both i and j hold exactly what was expected here. But if I use the
>>>dimension names, the subsetting indices does not seem to be passed as I
>>>expected:
>>>
>>>      
>>>
>>>>x[age=1:3, year=1:3]
>>>>        
>>>>
>>>[1] "i: missing"
>>>[1] "j: missing"
>>>      
>>>
>>>>x[, year='10']
>>>>        
>>>>
>>>[1] "i: missing"
>>>[1] "j: missing"
>>>
>>>Subsetting with dimnames appears to work without trouble on an array,
>>>which "foo" extends:
>>>
>>>s<-array(1:9,dim=c(3,3),dimnames=list(age=1:3,year=1:3))
>>>      
>>>
>>>>s[1,2:3]
>>>>        
>>>>
>>>2 3
>>>4 7
>>>      
>>>
>>>>s[age=1,year=2:3]
>>>>        
>>>>
>>>2 3
>>>4 7
>>>
>>>Although dimnames seem to be in fact simply ignored:
>>>
>>>      
>>>
>>>>s[a=1,b=3]
>>>>        
>>>>
>>>[1] 7
>>>
>>>
>>>System:
>>>Linux Debian 3.0
>>>R 2.0.0
>>>
>>>Do I need to define my class differently for subsetting using dimnames
>>>to work? Even if they are not really being checked, I would like to be
>>>able to use subsetting in this way as it makes code more readable when
>>>using arrays with many dimensions.
>>>      
>>>
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>  
>


-- 
Dipl. bio-chem. Witold Eryk Wolski
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin
tel: 0049-30-83875219                 __("<    _
http://www.molgen.mpg.de/~wolski      \__/    'v'
http://r4proteomics.sourceforge.net    ||    /   \
mail: witek96@users.sourceforge.net    ^^     m m
      wolski@molgen.mpg.de

From arnima at u.washington.edu  Thu Feb 17 20:37:36 2005
From: arnima at u.washington.edu (arnima@u.washington.edu)
Date: Thu Feb 17 20:37:44 2005
Subject: [Rd] Documentation typos (PR#7693)
Message-ID: <20050217193736.6444DBB94@slim.kubism.ku.dk>

There's a harmless typo in screen.Rd where "coner" should be "corner".

Nitpicking to the extreme, "ie." should be "i.e." in plotformula.Rd and 
screen.Rd.

Arni

From ripley at stats.ox.ac.uk  Thu Feb 17 21:21:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Feb 17 21:21:33 2005
Subject: [Rd] german translation
In-Reply-To: <20050217094344.08dd5714@gaia.unibw-hamburg.de>
References: <20050217094344.08dd5714@gaia.unibw-hamburg.de>
Message-ID: <Pine.LNX.4.61.0502172015430.16520@gannet.stats>

On Thu, 17 Feb 2005, Detlef Steuer wrote:

> Hello dear R-core,
>
> I would be willing to offer some spare time to generate a german 
> translation of R.pot and RGui.pot.
>
> Do you still need a translator or does someone already work on that 
> task? (I hate useless duplication of efforts.)
>
> To whom shall I send the de.po file? Or should I generate a diff against 
> the latest svn sources? What's your standard procedure for these cases?
>
> Are there already any hints what to do and what to avoid while 
> translating?

Detlef,

We are AFAIK without a German translator.  Some hints:

1) Try to get a small team together, as it helps to have someone to 
compare notes with.  Kurt had done some soundings and may be able to add 
to that privately, and Stefano has some cautionary experiences.

If you need a mailing list or similar, please ask Martin.

2) Just send the translations to any R-core member, by default me I guess.

3) Use UTF-8 if you can.

4) There is information in the R-exts manual in R-devel and in the 
Translations.html file on developer.r-project.org.

5) There are .pot files for each package too.

Thanks,

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Thu Feb 17 23:04:09 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu Feb 17 23:04:29 2005
Subject: [Rd] Documentation typos (PR#7693)
In-Reply-To: <20050217193736.6444DBB94@slim.kubism.ku.dk>
References: <20050217193736.6444DBB94@slim.kubism.ku.dk>
Message-ID: <u55a11hmspgqf21ekoc3ep1o9hepbukuqc@4ax.com>

On Thu, 17 Feb 2005 20:37:36 +0100 (CET), arnima@u.washington.edu
wrote :

>There's a harmless typo in screen.Rd where "coner" should be "corner".
>
>Nitpicking to the extreme, "ie." should be "i.e." in plotformula.Rd and 
>screen.Rd.

I'll fix these in R-devel.  

Duncan Murdoch

From feferraz at ime.usp.br  Fri Feb 18 00:21:18 2005
From: feferraz at ime.usp.br (Fernando Henrique Ferraz P. da Rosa)
Date: Fri Feb 18 00:21:18 2005
Subject: [Rd] german translation
In-Reply-To: <Pine.LNX.4.61.0502172015430.16520@gannet.stats>
References: <20050217094344.08dd5714@gaia.unibw-hamburg.de>
	<Pine.LNX.4.61.0502172015430.16520@gannet.stats>
Message-ID: <20050217232118.GA1682@ime.usp.br>

Prof Brian Ripley writes:
> On Thu, 17 Feb 2005, Detlef Steuer wrote:
> (...)
> 
> 
> Detlef,
> 
> We are AFAIK without a German translator.  Some hints:
> 
> 1) Try to get a small team together, as it helps to have someone to 
> compare notes with.  Kurt had done some soundings and may be able to add 
> to that privately, and Stefano has some cautionary experiences.
> 
> If you need a mailing list or similar, please ask Martin.
> 
> 2) Just send the translations to any R-core member, by default me I guess.
> 
> 3) Use UTF-8 if you can.
> 
> 4) There is information in the R-exts manual in R-devel and in the 
> Translations.html file on developer.r-project.org.
> 
> 5) There are .pot files for each package too.
> 

        I think it would be useful to set up a list (even in static html
on the R-developer page perhaps) of who is working on each
translation, with the respectives e-mail addresses. This way we would avoid
duplication of efforts and make it easier to group teams: anyone
interested on working on a particular language would look up that list
for someone already working on it and contact him.

        I for one I'm working on the translation of the .pot files to
Portuguese-BR (right now I'm on 80% of the R.pot). By the way, I'm using
the ISO8559-1 encoding (which was the recommended* option by the
Brazilian Team on the gettext page) - I still didn't get around to
converting my system to UFT-8, but I hope that isn't a problem. Anyways
I'll try to see if there's a way to convert it from ISO8559-1 to UTF-8.

* ISO8559-1 is still the most used locale for portuguese systems.


--
Fernando Henrique Ferraz P. da Rosa
http://www.ime.usp.br/~feferraz

From Mark.Bravington at csiro.au  Fri Feb 18 04:38:09 2005
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Fri Feb 18 04:38:23 2005
Subject: [Rd] eapply weirdness/bug
Message-ID: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>

The following looks like an 'eapply' bug to me:

t/subtest> e <- new.env()
t/subtest> e$tempo <- quote( 1+'hi')

t/subtest> lapply( ls( e), function( x) length( get( x,e)))
[[1]]
[1] 3
# seems reasonable-- e$tempo is a 'call' object of length 3

t/subtest> eapply( e, length)
Error in 1 + "hi" : non-numeric argument to binary operator

t/subtest> eapply( e, length)
t/subtest> traceback()
1: eapply(e, length)

For some reason 'eapply' seems to *evaluate* objects of mode 'call' (it
happened with every call-mode object I tried). This shouldn't happen--
or should it?

Mark

Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623


	[[alternative HTML version deleted]]

From murdoch at stats.uwo.ca  Fri Feb 18 07:56:54 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri Feb 18 07:57:16 2005
Subject: [Rd] german translation
In-Reply-To: <20050217232118.GA1682@ime.usp.br>
References: <20050217094344.08dd5714@gaia.unibw-hamburg.de>
	<Pine.LNX.4.61.0502172015430.16520@gannet.stats>
	<20050217232118.GA1682@ime.usp.br>
Message-ID: <1c3b1151s6riok2im6faha7bgt4tq97hfp@4ax.com>

On Thu, 17 Feb 2005 21:21:18 -0200, "Fernando Henrique Ferraz P. da
Rosa" <feferraz@ime.usp.br> wrote :

>
>        I think it would be useful to set up a list (even in static html
>on the R-developer page perhaps) of who is working on each
>translation, with the respectives e-mail addresses. This way we would avoid
>duplication of efforts and make it easier to group teams: anyone
>interested on working on a particular language would look up that list
>for someone already working on it and contact him.

That sounds like a good idea.  The pointer could consist of an email
address of one of the group members, and/or a link to a web page for
the group.

I'd do it right now, but I seem to be having problems contacting the
repository to update the web pages...

>        I for one I'm working on the translation of the .pot files to
>Portuguese-BR (right now I'm on 80% of the R.pot). By the way, I'm using
>the ISO8559-1 encoding (which was the recommended* option by the
>Brazilian Team on the gettext page) - I still didn't get around to
>converting my system to UFT-8, but I hope that isn't a problem. Anyways
>I'll try to see if there's a way to convert it from ISO8559-1 to UTF-8.

The iconv utility is supposed to do this. If you're on Windows:  I
have a copy of iconv for Windows on www.murdoch-sutherland.com/Rtools,
but you might not need it. Lots of editors (e.g. Windows notepad) can
also do this conversion.

Duncan Murdoch

Duncan

From p.dalgaard at biostat.ku.dk  Fri Feb 18 09:49:13 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Feb 18 09:54:24 2005
Subject: [Rd] eapply weirdness/bug
In-Reply-To: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>
References: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>
Message-ID: <x2vf8q5k3a.fsf@biostat.ku.dk>

<Mark.Bravington@csiro.au> writes:

> The following looks like an 'eapply' bug to me:
> 
> t/subtest> e <- new.env()
> t/subtest> e$tempo <- quote( 1+'hi')
> 
> t/subtest> lapply( ls( e), function( x) length( get( x,e)))
> [[1]]
> [1] 3
> # seems reasonable-- e$tempo is a 'call' object of length 3
> 
> t/subtest> eapply( e, length)
> Error in 1 + "hi" : non-numeric argument to binary operator
> 
> t/subtest> eapply( e, length)
> t/subtest> traceback()
> 1: eapply(e, length)
> 
> For some reason 'eapply' seems to *evaluate* objects of mode 'call' (it
> happened with every call-mode object I tried). This shouldn't happen--
> or should it?

It's probably related to the fact that 

> eval(substitute(length(x),list(x=e$tempo)))
Error in 1 + "hi" : non-numeric argument to binary operator

I.e., you cannot construct calls with a mode call argument by
substituting the value of the mode call object. (Got that? Point is
that the substitute returns quote(length(1+"hi")))

It is not clear to me that there is a nice way of fixing this. You
probably need to construct calls of the form FUN(env$var) -- I suspect
that with(env, FUN(var)) or eval(FUN(var), env) would looking for
trouble. Hmm, then again, maybe it could work if FUN gets inserted as
an anonymous function...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Fri Feb 18 11:57:08 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Feb 18 12:02:24 2005
Subject: [Rd] Suggestions for enhanced routines for "mlm" models.
Message-ID: <x2oeeicf0b.fsf@biostat.ku.dk>


Dear R-devel'ers

Below is an outline for a set of routines to improve support for
multivariate linear models and "classical" repeated measurements
analysis. Nothing has been coded yet, so everything is subject to
change as loose ideas get confronted by the harsh realities of
programming.

Comments are welcome. They might even influence the implementation...

        -pd

General considerations:

	- S3 class based to fit existing code
        - similar to lm/glm code

fit <- lm(Y~...) creates basic mlm object (already does)

SSD(obj) returns object of class "SSD": 
           $SSD  matrix of sums of squares  & products 
           $df   degrees of freedom. 
         Methods for (lm and) mlm.

estVar(obj) obj$SSD/obj$df (could have methods for lm/mlm too)

Convenience functions:
  Tr is the trace operator sum(diag(M))
  proj is the projection operator possibly generalized to matrices.
  Rg: matrix rank (not sure we really need it, but see below)

mauchley.test(obj, M=diag(ncol=p), T = proj(X, orth=TRUE),
              X = matrix(rep(1,p)))
    (p = ncol(obj$SSD))
 
    Test of sphericity, i.e. that the obj represents a empirical
    covariance matrix S with true value proportional to M or that TST'
    is proportional to TMT'. Alternatively, give X with the property
    that TX == 0. (One sticky bit is that you can't really just use
    proj() because T  must have maximal rank. What is the current best
    practice for dealing with that?  qr() pivoting?)

summary.mlm
print.summary.mlm
vcov.mlm

    summary.mlm could be a little smarter than just coordinatewise
    summary.lm. It could at least provide the estimated residual
    covariance matrix (or SSD structure).  

    vcov currently inherits from "lm" leading to a completely
    arbitrarily scaled matrix. The correct matrix is a Kronecker
    product of the unscaled covariance matrix and estVar.

anova.mlm, anova.mlmlist, drop1.mlm, add1.mlm 

    These can (seemingly...) be obtained by relatively small
    modifications of their lm counterparts. The actual test
    calculations need to be excised from summary.manova (generalize?
    e.g. mvlin.test(SSD1, SSD2, method="Pillai")). It should be possible
    to wedge in tests under sphericity assumptions (with
    Greenhouse-Geisser and Huynh-Feldt corrections), as well as
    transformation/conditioning matrices (see below). 

    A more radical idea is to say that these are all different kinds
    of MANOVA tables and extend the *.manova functions to understand
    them. This would break the symmetry with lm, though, since you
    then need to use summary() to get a meaningful listing.


Notes on conditional tests (lower priority):

    Consider Y = (Y1,Y2) and a linear hypothesis matrix H.

    The test of zero intercept in the (multivariate) regression of H
    %*% Y2 on H %*% Y1 is of some interest, possibly after a linear
    transformation of Y. This is the test for additional information,
    but it is also the correct (ML) way of utilizing known-zero
    effects, e.g. pretreatment measurements. There is even a neat
    trick to fitting a linear structure across the responses by
    regressing on null-space contrasts.

    To some extent, conditional tests can be handled just by moving
    variables to the r.h.s. of the linear model specification, but
    there might be a point in having a more evocative interface,
    especially where transformed Y's are involved. This could be
    formula-based or matrix-based: contrasts=ginv(contr.sdif(4)) or
    formula based: ystruct=~index.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From d.firth at warwick.ac.uk  Fri Feb 18 12:34:06 2005
From: d.firth at warwick.ac.uk (David Firth)
Date: Fri Feb 18 12:34:16 2005
Subject: [Rd] read.ftable, write.ftable -- move to base?
Message-ID: <3142423613cf0cb2db9ed4fc1876e5c2@warwick.ac.uk>

This is just to suggest that the functions read.ftable and write.ftable 
be moved from the stats package to the base package.

As I understand it, this would allow ftable format to be used (more 
easily than at present) for datasets placed in the "data" subdirectory 
of packages.  And that would be a good thing?  (It would also make the 
advice given in Writing R Extensions,
> Currently, data files can have one of three types as indicated by 
> their extension: plain R code (.R or .r), tables (.tab, .txt, or 
> .csv)...
clearer in the sense that "table" could be read to mean the same thing 
as it does in other parts of R.)

David

Professor David Firth
Dept of Statistics
University of Warwick
Coventry CV4 7AL
United Kingdom

Voice: +44 (0)247 657 2581
Fax:   +44 (0)247 652 4532
Web:   http://www.warwick.ac.uk/go/dfirth

From david.clayton at cimr.cam.ac.uk  Fri Feb 18 13:53:11 2005
From: david.clayton at cimr.cam.ac.uk (david.clayton@cimr.cam.ac.uk)
Date: Fri Feb 18 13:53:20 2005
Subject: [Rd] contrasts (PR#7695)
Message-ID: <20050218125311.8E4558E5D@slim.kubism.ku.dk>

Full_Name: David Clayton
Version: 2.0.1
OS: Linux
Submission from: (NULL) (131.111.126.242)


Setting contrasts for a factor to be used in a model by 

contrasts(fact, how.many) <- mat

where mat is a matrix does not coerce mat into storage mode "double". The
resultant model.matrix is garbage.

From paradis at isem.univ-montp2.fr  Fri Feb 18 15:07:40 2005
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Fri Feb 18 15:06:32 2005
Subject: [Rd] calling optif0 in a C function
Message-ID: <4215F6AC.1090509@isem.univ-montp2.fr>

Dear All,

I am trying to use the function optif0 (in main/uncmin.c) from the
latest R distribution. The reason is that I have a quite complicated
likelihood function which is coded in C, and I would like to optimize it 
directly.

To see how this works, I have tried with a very simple example: 
optimizing the likelihood of a sample using an exponential distribution. 
I have tried several solutions but none worked. I paste below the 
functions that come the closest to what should work. The compilation is 
fine and the call from R too. It seems that the call to optif0 does not 
do anything whereas everything else works.

It seems that I miss something simple... Any suggestion will be welcome. 
I use R 2.0.1 and GCC 3.3.4.

Best regards,

Emmanuel Paradis
========================================================
#include <R.h>
#include <Rmath.h>
#include <R_ext/Applic.h>
#include "ape.h"

/* Here is the content of ape.h: */
typedef struct {
   int *n;
   double *x;
} TITI;

static void fcn_expo(int, double *, double *, TITI *);
/* end of ape.h */


void lik_expo(int *n, double *x, double *l, double *loglik)
{
/* computes the likelihood */
   int i;
   *loglik = 0;
   for (i = 0; i < *n; i++)
     *loglik += log(*l) - *l * x[i];
}

static void fcn_expo(int np, double *p, double *sol, TITI *D)
{
/* computes the deviance to be minimized */
   double loglik;
   lik_expo(D->n, D->x, p, &loglik);
   *sol = -2 * loglik;
}

void nlm_expo(int *n, double *x, double *l, double *dev)
{
/* the function called from R */
   int *itrmcd, *np, term_code, N;
   double *xpls, *fpls, *gpls, est, sol, grad, *a, *wrk;
   TITI *D, data;
   extern void fcn_expo(int, double *, double *, TITI *);

   N = 1;
   np = &N;
   D = &data;
   D->n = n;
   D->x = x;
   itrmcd = &term_code;
   xpls = &est;
   fpls = &sol;
   gpls = &grad;

   a = (double*)malloc(*np * *np * sizeof(double));
   wrk = (double*)malloc(*np * 9 * sizeof(double));
   optif0(*np, *np, l, (fcn_p) fcn_expo, D,
	 xpls, fpls, gpls, itrmcd, a, wrk);
   *l = *xpls;
   *dev = *fpls;
}


### Here is the R function that calls the C code:
nlmexpo <- function(x)
{
     n <- length(x)
     l <- 1
     dev <- 0.1
     c1 <- c2 <- -8
     .C("nlm_expo", as.integer(n), as.double(x),
        as.double(l), as.double(dev),
        NAOK = TRUE, PACKAGE = "apex")
}

From ripley at stats.ox.ac.uk  Fri Feb 18 15:08:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 18 15:09:04 2005
Subject: [Rd] contrasts (PR#7695)
In-Reply-To: <20050218125311.8E4558E5D@slim.kubism.ku.dk>
References: <20050218125311.8E4558E5D@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502181404441.5419@gannet.stats>

Do you have an example we can use to test a fix?  I can only guess at what 
you supplied for `mat'.

R doesn't really have `storage mode': and "single" should be fine.
I guess (but only guess) you had an integer matrix.

On Fri, 18 Feb 2005 david.clayton@cimr.cam.ac.uk wrote:

> Full_Name: David Clayton
> Version: 2.0.1
> OS: Linux
> Submission from: (NULL) (131.111.126.242)
>
>
> Setting contrasts for a factor to be used in a model by
>
> contrasts(fact, how.many) <- mat
>
> where mat is a matrix does not coerce mat into storage mode "double". The
> resultant model.matrix is garbage.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From luke at stat.uiowa.edu  Fri Feb 18 15:44:06 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri Feb 18 15:44:42 2005
Subject: [Rd] eapply weirdness/bug
In-Reply-To: <x2vf8q5k3a.fsf@biostat.ku.dk>
References: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>
	<x2vf8q5k3a.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.61.0502180821170.3177@itasca2.stat.uiowa.edu>

On Fri, 18 Feb 2005, Peter Dalgaard wrote:

> <Mark.Bravington@csiro.au> writes:
>
>> The following looks like an 'eapply' bug to me:
>>
>> t/subtest> e <- new.env()
>> t/subtest> e$tempo <- quote( 1+'hi')
>>
>> t/subtest> lapply( ls( e), function( x) length( get( x,e)))
>> [[1]]
>> [1] 3
>> # seems reasonable-- e$tempo is a 'call' object of length 3
>>
>> t/subtest> eapply( e, length)
>> Error in 1 + "hi" : non-numeric argument to binary operator
>>
>> t/subtest> eapply( e, length)
>> t/subtest> traceback()
>> 1: eapply(e, length)
>>
>> For some reason 'eapply' seems to *evaluate* objects of mode 'call' (it
>> happened with every call-mode object I tried). This shouldn't happen--
>> or should it?
>
> It's probably related to the fact that
>
>> eval(substitute(length(x),list(x=e$tempo)))
> Error in 1 + "hi" : non-numeric argument to binary operator
>
> I.e., you cannot construct calls with a mode call argument by
> substituting the value of the mode call object. (Got that? Point is
> that the substitute returns quote(length(1+"hi")))
>
> It is not clear to me that there is a nice way of fixing this. You
> probably need to construct calls of the form FUN(env$var) -- I suspect
> that with(env, FUN(var)) or eval(FUN(var), env) would looking for
> trouble. Hmm, then again, maybe it could work if FUN gets inserted as
> an anonymous function...
>

Looks broken to me:

     > e<-new.env()
     > assign("x",quote(y),e)
     > eapply(e, function(x) x)
     Error in FUN(y, ...) : Object "y" not found

in contrast to

     > lapply(list(quote(y)),function(x) x)
     [[1]]
     y

looks like eapply has an extra eval in the code.  It does because the
code creates a call of the form

     FUN(<value>)

with the literal value in place and then calls eval on this, which
results in calling eval on value.  The internal lapply in contrast
creates a call of the form

     FUN(<list>[[<index>]])

and evals that.  This causes the literal <list> and <index> values to
be evaluated, which is OK since they are guaranteed to be a list
(generic vector) and integer vector and so evaluate to themselves, and
the call to [ is then evaluated, returning what is in the list at the
appropriate index and passing that, without further evluation, to FUN.
The semantics we want in eapply is I think equivalent to creating

     FUN(get(<name>, <envir>))

and evaluating that, but we are not getting this.  Direct use of this
would be less efficient that the current approach, but using

     FUN(quote(<value>))

as the constructed call should do the trick.

[There seem to be a few other unnecessary eval's in cmputing the arguments
but I haven't thought this through yet]

luke



-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From p.dalgaard at biostat.ku.dk  Fri Feb 18 16:22:41 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Feb 18 16:27:52 2005
Subject: [Rd] eapply weirdness/bug
In-Reply-To: <Pine.LNX.4.61.0502180821170.3177@itasca2.stat.uiowa.edu>
References: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>
	<x2vf8q5k3a.fsf@biostat.ku.dk>
	<Pine.LNX.4.61.0502180821170.3177@itasca2.stat.uiowa.edu>
Message-ID: <x23bvtdha6.fsf@biostat.ku.dk>

Luke Tierney <luke@stat.uiowa.edu> writes:

> looks like eapply has an extra eval in the code.  It does because the
> code creates a call of the form
> 
>      FUN(<value>)
> 
> with the literal value in place and then calls eval on this, which
> results in calling eval on value.  The internal lapply in contrast
> creates a call of the form
> 
>      FUN(<list>[[<index>]])
> 
> and evals that.  This causes the literal <list> and <index> values to
> be evaluated, which is OK since they are guaranteed to be a list
> (generic vector) and integer vector and so evaluate to themselves, and
> the call to [ is then evaluated, returning what is in the list at the
> appropriate index and passing that, without further evluation, to FUN.
> The semantics we want in eapply is I think equivalent to creating
> 
>      FUN(get(<name>, <envir>))

Or, as I was suggesting, 

eval(substitute(F(x), list(F=FUN,x=as.name(e)), envir)

> and evaluating that, but we are not getting this.  Direct use of this
> would be less efficient that the current approach, but using
> 
>      FUN(quote(<value>))
> 
> as the constructed call should do the trick.

You have to be careful only to do this if the value is of mode "call",
I think. Or is quote always a no-op in the other cases? 

I'm getting a bit fond of the the solution that I had because it will
also work if the FUN uses deparse(substitute(....)) constructions, and
once you're at the level of constructing calls via LCONS() it isn't
really inefficient either. Extra arguments could be a bit of a bother
though. (What happens to those currently?? The function doesn't seem to
pass them to .Internal.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From luke at stat.uiowa.edu  Fri Feb 18 18:00:00 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri Feb 18 18:00:22 2005
Subject: [Rd] eapply weirdness/bug
In-Reply-To: <x23bvtdha6.fsf@biostat.ku.dk>
References: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>
	<x2vf8q5k3a.fsf@biostat.ku.dk>
	<Pine.LNX.4.61.0502180821170.3177@itasca2.stat.uiowa.edu>
	<x23bvtdha6.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.61.0502181029410.7043@nokomis.stat.uiowa.edu>

On Fri, 18 Feb 2005, Peter Dalgaard wrote:

> Luke Tierney <luke@stat.uiowa.edu> writes:
>
>> looks like eapply has an extra eval in the code.  It does because the
>> code creates a call of the form
>>
>>      FUN(<value>)
>>
>> with the literal value in place and then calls eval on this, which
>> results in calling eval on value.  The internal lapply in contrast
>> creates a call of the form
>>
>>      FUN(<list>[[<index>]])
>>
>> and evals that.  This causes the literal <list> and <index> values to
>> be evaluated, which is OK since they are guaranteed to be a list
>> (generic vector) and integer vector and so evaluate to themselves, and
>> the call to [ is then evaluated, returning what is in the list at the
>> appropriate index and passing that, without further evluation, to FUN.
>> The semantics we want in eapply is I think equivalent to creating
>>
>>      FUN(get(<name>, <envir>))
>
> Or, as I was suggesting,
>
> eval(substitute(F(x), list(F=FUN,x=as.name(e)), envir)

Well, you know my view of adding more nonstandard evaluation.  Any
explicit use of eval is almost always a Really Bad Idea, and in most
of the remaining cases it is a bad idea.  In any cases that still
remain it should be avoinded if at all possible. And if it seems not
possible then it is best to put the problem down for a while and think
a bit more....

>> and evaluating that, but we are not getting this.  Direct use of this
>> would be less efficient that the current approach, but using
>>
>>      FUN(quote(<value>))
>>
>> as the constructed call should do the trick.
>
> You have to be careful only to do this if the value is of mode "call",
> I think. Or is quote always a no-op in the other cases?

quote is fine--it always returns the object that appears as the
argument in the call.  For quote expressions created as the result of
parsing that will be a somewhat limited set of things, but for quote
calls created programmatically it can be anything.

> I'm getting a bit fond of the the solution that I had because it will
> also work if the FUN uses deparse(substitute(....)) constructions, and
> once you're at the level of constructing calls via LCONS() it isn't
> really inefficient either. Extra arguments could be a bit of a bother
> though. (What happens to those currently?? The function doesn't seem to
> pass them to .Internal.)

I believe none of our apply family of functions can be expected to do
anything very useful in situations that require nonstandard evaluation
based on the call context.  I don't beieve we explicitly document what
is supposed to happen here (and I'm not sure we want to at least at
this point: this is the sort of thing where leaving it undefined gives
alternate implementations, such as one based on compilation, some room
to work with).  But it might be worth thinking about narrowing
variability a little.  A somewhat related issue is that we don't have
a completely standard mechanism of calling an function from within C
code--we do it by creating and eval'ing (in C) a call expression, but
there may be some slight variations in the way it is done in different
places that we might want to think about at some point.

For this specific case though, I _think_ the semantics we want is this:

     eapply1 <- function(env, FUN, ..., all.names = FALSE) {
 	FUN <- match.fun(FUN)
 	lapply(.Internal(env2list(env, all.names)), FUN, ...)
     }

Not passing the ... in the current implementation is, I think, an
oversight, as is the extra evaluation that occurs.  Given that lapply
is already internal I'm not sure there really is very much benefit in
having the internal eapply.  If not I'd prefer to replace it by
something like this; if there are reasons for keeping the .Internal we
can work on replicating these semantics as closely as possible.  I
think Robert is the one who would know the issues.

luke


-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From whit at twinfieldscapital.com  Fri Feb 18 21:09:48 2005
From: whit at twinfieldscapital.com (Whit Armstrong)
Date: Fri Feb 18 21:06:13 2005
Subject: [Rd] creating POSIXct dates in C
Message-ID: <726FC6DD09DE1046AF81B499D70C3BCE157763@twinfields02.CORP.TWINFIELDSCAPITAL.COM>

I'm trying to generate POSIXct times in a call to a C function.
However, I'm having trouble generating times with the proper offset from
UTC.

Can anyone offer any help with this issue?

I've looked at R-2.0.1/src/main/datetime.c, but I was not able to find
an example that I could easily pull from that file.

Thanks in advance,
Whit


Here is my example in C:

#include <stdio.h>
#include <time.h>

int main() {
  struct tm localtime_tm;
  struct tm utc_tm;

  time_t localtime_posix;
  time_t utc_posix;

  char buf[255];

  strptime("1970-01-01", &localtime_tm);
  localtime_posix = mktime(&localtime_tm);

  // this prints 0
  // which is what the time would be if we were in GMT
  // how do we convert this time to our timezone
  // taking into account that the offset is not
  // constant, since daylight savings time
  // will shift the offset by an hour
  // for certain times
  printf("%d\n",(double)localtime_posix);


  // now convert it to gmtime
  gmtime_r(&localtime_posix, &utc_tm);
  utc_posix = mktime(&utc_tm);

  // this still prints 0
  // how do I convert it to a utc time
  // representing 1970-01-01 in EST ??
  printf("%d\n",(double)utc_posix);

}

> R.Version()
$platform
[1] "i686-pc-linux-gnu"

$arch
[1] "i686"

$os
[1] "linux-gnu"

$system
[1] "i686, linux-gnu"

$status
[1] ""

$major
[1] "2"

$minor
[1] "0.1"

$year
[1] "2004"

$month
[1] "11"

$day
[1] "15"

$language
[1] "R"


RHEL 3.0

	[[alternative HTML version deleted]]

From jfox at mcmaster.ca  Fri Feb 18 21:27:12 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri Feb 18 21:27:23 2005
Subject: [Rd] RE: [R] using poly in a linear regression in the presence of
	NAf ails (despite subsetting them out)
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E6E7@usrymx25.merck.com>
Message-ID: <20050218202711.MCEC1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Andy, Brian, and Markus,

I've moved this to r-devel because the issue is a bit esoteric. I apologize
for joining the discussion so late, but didn't have time earlier in the week
to formulate these ideas.

I believe that I understand and appreciate Brian's point, but think that the
issue isn't entirely clear-cut.

It seems to me that two kinds of questions arise with missing data. The
deeper ones are statistical but there are also nontrivial mechanical issues
such as the one here.

Whenever a term in a model is parametrized with a data-dependent basis,
there's a potential for problems and confusion -- manifested, for example,
in the issue of "safe" prediction. I don't think that these problems are
unique to missing data. On the other hand, the basis selected for the
subspace spanned by a term shouldn't be the most important consideration.
That is, when models are equivalent -- as, for example lm(y ~ x + I(x^2))
and lm(y ~ poly(x, 2)), an argument could be made for treating them
similarly.

Brian's point that NAs, say, in x2, can influence the basis for poly(x1, 2)
is disquieting, but note that this can happen now if there are no NAs in x1.
The point, therefore, doesn't really justify the current behaviour of
poly(). Indeed, if there are NAs in x2 but not in x1, the columns
representing poly(x1, 2) won't be orthogonal in the subset of cases used in
the model fit (though they do provide a correct basis for the term).

Consider another example -- lm(y ~ f, subset = f != "a"), where f is a
factor with levels "a", "b", and "c", and where there are NAs in f. Here the
basis for the f term is data dependent, in that the baseline level is taken
as "b" in the absence of "a", yet NAs don't cause an error.

Having poly(), bs(), and ns() report a more informative error message
certainly is preferable to the current situation, but an alternative would
be to have them work and perhaps report a warning.

If the object is to protect people from stepping into traps because of
missing data, then an argument could be made for having the default
na.action be na.fail, as in S-PLUS. (I wouldn't advocate this, by the way.)
Perhaps I'm missing some consideration here, but isn't it clearest to allow
the data, subset, and na.action arguments to determine the data in which the
formula is evaluated? 

Regards,
John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces@stat.math.ethz.ch 
> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Liaw, Andy
> Sent: Tuesday, February 15, 2005 8:31 AM
> To: 'Prof Brian Ripley'
> Cc: r-help@stat.math.ethz.ch; 'Markus Jantti'
> Subject: RE: [R] using poly in a linear regression in the 
> presence of NAf ails (despite subsetting them out)
> 
> My apologies:  It's another case of me not thinking 
> statistically...  It may also help those of us whose brains 
> run at slow clock speeds to have ?poly, ?bs and ?ns mention 
> how they react to NAs.
> 
> Best,
> Andy
> 
> 
> > From: Prof Brian Ripley
> > 
> > Andy,
> > 
> > I don't think it is a bug.  The problem is that poly(x, 2) 
> depends on 
> > the possible set of x values, and so needs to know all of 
> them, unlike 
> > e.g. log(x) which is observation-by-observation.  Silently omitting 
> > missing values is not a good idea in such cases, especially if the 
> > values are missing in other variables (which is what na.action is 
> > likely to do).
> > 
> > I would say models with poly, ns, bs etc are inadvisable in the 
> > presence of missing values in their argument.  We could make poly() 
> > give an informative message, though.
> > 
> > Brian
> > 
> > 
> > On Mon, 14 Feb 2005, Liaw, Andy wrote:
> > 
> > > This smells like a bug to me.  The error is triggered by the line:
> > >
> > >   variables <- eval(predvars, data, env)
> > >
> > > inside model.frame.default().  At that point, na.action 
> has not been 
> > > applied, so poly() ended being called on data that still
> > contains missing
> > > values.  The qr() that issued the error is for generating
> > the orthogonal
> > > basis when evaluating poly(), not for fitting the linear
> > model itself.
> > >
> > > Essentially, calling
> > >
> > >  model.frame(y ~ poly(x, 2), data=data.frame(x=c(NA, 1:3),
> > y=rnorm(4)),
> > >              na.action=na.omit)
> > >
> > > would show the same error.  The obvious workaround is to
> > omit cases with NAs
> > > before calling lm().
> > >
> > > Andy
> > >
> > >> From: Markus J?ntti
> > >>
> > >> I ran into a to me surprising result on running lm with an
> > orthogonal
> > >> polynomial among the predictors.
> > >>
> > >> The lm command resulted in
> > >>
> > >> Error in qr(X) : NA/NaN/Inf in foreign function call 
> (arg 1) Error 
> > >> during wrapup:
> > >>
> > >> despite my using a "subset" in the call to get rid of NA's.
> > >>
> > >> poly is apparently evaluated before any NA's are 
> subsetted out of 
> > >> the data.
> > >>
> > >> Example code (attached to this e-mail as as a script):
> > >> > ## generate some data
> > >> > n <- 50
> > >> > x <- runif(n)
> > >> > a0 <- 10
> > >> > a1 <- .5
> > >> > sigma.e <- 1
> > >> > y <- a0 + a1*x + rnorm(n)*sigma.e tmp.d <- data.frame(y, x) 
> > >> > rm(list=c("n", "x", "a0", "a1", "sigma.e", "y"))
> > >> >
> > >> > print(lm.1 <- lm(y ~ poly(x, 2), data = tmp.d)
> > >> +
> > >> + ## now make a few NA's
> > >> +
> > >> + tmp.d$x[1:2] <- rep(NA, 2)
> > >> Error: syntax error
> > >> Error during wrapup:
> > >> >
> > >> > ## this fails, just as it should
> > >> > print(lm.1 <- lm(y ~ poly(x, 2), data = tmp.d))
> > >>
> > >> Call:
> > >> lm(formula = y ~ poly(x, 2), data = tmp.d)
> > >>
> > >> Coefficients:
> > >> (Intercept)  poly(x, 2)1  poly(x, 2)2
> > >>       10.380       -0.242       -1.441
> > >>
> > >> >
> > >> > ## these also fail, but should not?
> > >> >
> > >> > print(lm.2 <- lm(y ~ poly(x, 2), data = tmp.d, subset =
> > !is.na(x)))
> > >>
> > >> Call:
> > >> lm(formula = y ~ poly(x, 2), data = tmp.d, subset = !is.na(x))
> > >>
> > >> Coefficients:
> > >> (Intercept)  poly(x, 2)1  poly(x, 2)2
> > >>       10.380       -0.242       -1.441
> > >>
> > >> > print(lm.3 <- lm(y ~ poly(x, 2), data = tmp.d, na.action =
> > >> na.omit))
> > >>
> > >> Call:
> > >> lm(formula = y ~ poly(x, 2), data = tmp.d, na.action = na.omit)
> > >>
> > >> Coefficients:
> > >> (Intercept)  poly(x, 2)1  poly(x, 2)2
> > >>       10.380       -0.242       -1.441
> > >>
> > >> >
> > >> > ## but this works
> > >> >
> > >> > print(lm.3 <- lm(y ~ poly(x, 2), data = subset(tmp.d, subset =
> > >> !is.na(x))))
> > >>
> > >> Call:
> > >> lm(formula = y ~ poly(x, 2), data = subset(tmp.d, subset =
> > !is.na(x)))
> > >>
> > >> Coefficients:
> > >> (Intercept)  poly(x, 2)1  poly(x, 2)2
> > >>       10.380       -0.242       -1.441
> > >>
> > >> --------------------
> > >>
> > >> The documentation of lm is *not* misleading at this point,
> > saying that
> > >>
> > >> subset 	an optional vector specifying a subset of
> > >> observations to be
> > >> used in the fitting process.
> > >>
> > >> which implies that data are subsetted once lm.fit is called.
> > >> All the same, this behavior is a little unexpected to me.
> > >> Is it to be considered a feature, that is, does it produce
> > beneficial
> > >> side effects which explain why it works as it does?
> > >>
> > >> Regards,
> > >>
> > >> Markus
> > >>
> > >> I am running R on a Debian testing system with kernel 2.6.10 and
> > >>
> > >> > version
> > >>           _
> > >> platform i386-pc-linux-gnu
> > >> arch     i386
> > >> os       linux-gnu
> > >> system   i386, linux-gnu
> > >> status
> > >> major    2
> > >> minor    0.1
> > >> year     2004
> > >> month    11
> > >> day      15
> > >> language R
> > >> --
> > >> Markus Jantti
> > >> Abo Akademi University
> > >> markus.jantti@iki.fi
> > >> http://www.iki.fi/~mjantti
> > >>
> > >
> > > ______________________________________________
> > > R-help@stat.math.ethz.ch mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > >
> > 
> > --
> > Brian D. 
> > Ripley,                  ripley@stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

From murdoch at stats.uwo.ca  Fri Feb 18 22:32:22 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri Feb 18 22:32:35 2005
Subject: [Rd] Translation Teams
Message-ID: <j7nc11pgs8nl8l2dik7sq82cgpj8ikc818@4ax.com>

R version 2.1.0 and later will support translations of program
messages into different languages (largely through the efforts of
Brian Ripley; thanks!)  A number of translation projects are already
underway or completed. 

I've put up a web page at 

  http://developer.r-project.org/TranslationTeams.html

listing the current languages I know about and the contacts for each.
To offer your help with one of these, contact a team on the list.  To
list your own translation project there, contact me or another member
of R-core with the details. 

Duncan Murdoch

From ksg at mail.yngf.com  Sat Feb 19 06:30:00 2005
From: ksg at mail.yngf.com (KILL Shield Gateway)
Date: Sat Feb 19 06:57:05 2005
Subject: [Rd] =?iso-8859-1?q?=B9=DA=C8=BA=BD=F0=B3=BD_KILL_Shield_Gateway?=
	=?iso-8859-1?q?_=B2=A1=B6=BE=BE=AF=B1=A8?=
Message-ID: <20050219053000.3A5701B005@mail.yngf.com>

:   r-devel@r-project.org
:   yngf@yngf.com; 
:       Correction
Message-ID: 20050219052928.D21581A943@mail.yngf.com
:   2005-02-19 13:30:00

:   corrected_doc.pif                 1  Win32/Netsky.AB!Worm             : 

 1 ,  1  1 1 0 



From ripley at stats.ox.ac.uk  Sat Feb 19 07:09:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Feb 19 07:09:33 2005
Subject: [Rd] RE: [R] using poly in a linear regression in the presence of
 NAf ails (despite subsetting them out)
In-Reply-To: <20050218202711.MCEC1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>
References: <20050218202711.MCEC1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.61.0502190530480.958@gannet.stats>

On Fri, 18 Feb 2005, John Fox wrote:

> Dear Andy, Brian, and Markus,
>
> I've moved this to r-devel because the issue is a bit esoteric. I apologize
> for joining the discussion so late, but didn't have time earlier in the week
> to formulate these ideas.

I think you didn't take time to check what happens in R-devel, though.

> I believe that I understand and appreciate Brian's point, but think that the
> issue isn't entirely clear-cut.
>
> It seems to me that two kinds of questions arise with missing data. The
> deeper ones are statistical but there are also nontrivial mechanical issues
> such as the one here.
>
> Whenever a term in a model is parametrized with a data-dependent basis,
> there's a potential for problems and confusion -- manifested, for example,
> in the issue of "safe" prediction. I don't think that these problems are
> unique to missing data. On the other hand, the basis selected for the
> subspace spanned by a term shouldn't be the most important consideration.
> That is, when models are equivalent -- as, for example lm(y ~ x + I(x^2))
> and lm(y ~ poly(x, 2)), an argument could be made for treating them
> similarly.

Only in linear models, and we are here talking about general behaviour of 
finding the model frame.

> Brian's point that NAs, say, in x2, can influence the basis for poly(x1, 2)
> is disquieting, but note that this can happen now if there are no NAs in x1.

That is not what I said, and it is incorrect.  poly(x1, 2) is determined 
by the set of values of x1 (so they need all to be known hence no NAs in 
x1) and nothing else.  Example:

> y <- rnorm(10)
> x1 <- 1:10
> x2 <- c(NA, runif(9))
> model.frame(y ~ poly(x1, 2) + x2, na.action = na.omit)
             y poly(x1, 2).1 poly(x1, 2).2         x2
2  -0.5110095   -0.38533732    0.17407766 0.07377988
3  -0.9111954   -0.27524094   -0.08703883 0.30968660
4  -0.8371717   -0.16514456   -0.26111648 0.71727174
5   2.4158352   -0.05504819   -0.34815531 0.50454591
6   0.1340882    0.05504819   -0.34815531 0.15299896
7  -0.4906859    0.16514456   -0.26111648 0.50393349
8  -0.4405479    0.27524094   -0.08703883 0.49396092
9   0.4595894    0.38533732    0.17407766 0.75120020
10 -0.6937202    0.49543369    0.52223297 0.17464982
> model.frame(y ~ poly(x1, 2) + x2, na.action = na.pass)
             y poly(x1, 2).1 poly(x1, 2).2         x2
1  -0.1102855   -0.49543369    0.52223297         NA
2  -0.5110095   -0.38533732    0.17407766 0.07377988
3  -0.9111954   -0.27524094   -0.08703883 0.30968660
4  -0.8371717   -0.16514456   -0.26111648 0.71727174
5   2.4158352   -0.05504819   -0.34815531 0.50454591
6   0.1340882    0.05504819   -0.34815531 0.15299896
7  -0.4906859    0.16514456   -0.26111648 0.50393349
8  -0.4405479    0.27524094   -0.08703883 0.49396092
9   0.4595894    0.38533732    0.17407766 0.75120020
10 -0.6937202    0.49543369    0.52223297 0.17464982


> The point, therefore, doesn't really justify the current behaviour of
> poly(). Indeed, if there are NAs in x2 but not in x1, the columns
> representing poly(x1, 2) won't be orthogonal in the subset of cases used in
> the model fit (though they do provide a correct basis for the term).

It is currently documented to not allow NAs:

x, newdata: a numeric vector at which to evaluate the polynomial. 'x'
           can also be a matrix.  Missing values are not allowed in 'x'.

Why does that need any justification?

> Consider another example -- lm(y ~ f, subset = f != "a"), where f is a
> factor with levels "a", "b", and "c", and where there are NAs in f. Here the
> basis for the f term is data dependent, in that the baseline level is taken
> as "b" in the absence of "a", yet NAs don't cause an error.
>
> Having poly(), bs(), and ns() report a more informative error message
> certainly is preferable to the current situation, but an alternative would
> be to have them work and perhaps report a warning.

What exactly does `work' mean here?  Run and give misleading answers?

> If the object is to protect people from stepping into traps because of
> missing data, then an argument could be made for having the default
> na.action be na.fail, as in S-PLUS. (I wouldn't advocate this, by the way.)
> Perhaps I'm missing some consideration here, but isn't it clearest to allow
> the data, subset, and na.action arguments to determine the data in which the
> formula is evaluated?

Exactly how?  It would be a major change from the current methodology and 
I am not sure you appreciate what that is.

Remember that na.action could for example replace missing values by random 
imputations, or even multiple imputations, and na.action comes quite late 
in the process *after* the model frame has been formed.  Unlike factors, 
poly() etc generate multiple columns in the model frame, and then subset 
and na.action are applied.  Factors are encoded in model.matrix (and that 
is really only used for the linear parts of models, unlike model.frame).

I am not sure you appreciate the basic point: poly is applied to the whole 
dataset and not to a subset, and that can be important (e.g. to ensure no 
unstable extrapolation when predicting later).  Really na.action has to 
come last, as functions in the formula could themselves generate NAs 
(log(0) for example).

There is an alternative, that poly() works only on finite values and 
passes through non-finite ones, but it was deliberately not written that 
way and you will need to convince everyone that would be a better 
solution.  (What happens for example if there are only two finite values?)
If you want such a function, it is easy for you to provide it: just please 
don't call it poly().  [Writing poly() was not easy BTW, but 
poly_allow_NAs would be given poly.]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Feb 19 07:20:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Feb 19 07:20:34 2005
Subject: [Rd] creating POSIXct dates in C
In-Reply-To: <726FC6DD09DE1046AF81B499D70C3BCE157763@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
References: <726FC6DD09DE1046AF81B499D70C3BCE157763@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
Message-ID: <Pine.LNX.4.61.0502190610270.958@gannet.stats>

I think this is actually about converting from POSIXlt to POSIXct in C.

On Fri, 18 Feb 2005, Whit Armstrong wrote:

> I'm trying to generate POSIXct times in a call to a C function.

Doesn't look like ISO C to me.  Things are easier if you have ISO C99 
functions, but R does not assume them (and virtually no OS had them when 
this was written, and few do now).  You can also use BSD/glibc versions 
with a tz offset, again if you can assume those.

> However, I'm having trouble generating times with the proper offset from
> UTC.
>
> Can anyone offer any help with this issue?
>
> I've looked at R-2.0.1/src/main/datetime.c, but I was not able to find
> an example that I could easily pull from that file.

It is not easy, but it is there.

The conversion from struct tm times to calendar times (POSIXct) is done by
mktime.  How you tell it the timezone is OS-specific, but generally
setting the environment variable TZ is the trick.

> Thanks in advance,
> Whit
>
>
> Here is my example in C:
>
> #include <stdio.h>
> #include <time.h>
>
> int main() {
>  struct tm localtime_tm;
>  struct tm utc_tm;
>
>  time_t localtime_posix;
>  time_t utc_posix;
>
>  char buf[255];
>
>  strptime("1970-01-01", &localtime_tm);
>  localtime_posix = mktime(&localtime_tm);
>
>  // this prints 0
>  // which is what the time would be if we were in GMT
>  // how do we convert this time to our timezone
>  // taking into account that the offset is not
>  // constant, since daylight savings time
>  // will shift the offset by an hour
>  // for certain times
>  printf("%d\n",(double)localtime_posix);
>
>
>  // now convert it to gmtime
>  gmtime_r(&localtime_posix, &utc_tm);
>  utc_posix = mktime(&utc_tm);
>
>  // this still prints 0
>  // how do I convert it to a utc time
>  // representing 1970-01-01 in EST ??
>  printf("%d\n",(double)utc_posix);
>
> }
>
>> R.Version()
> $platform
> [1] "i686-pc-linux-gnu"
>
> $arch
> [1] "i686"
>
> $os
> [1] "linux-gnu"
>
> $system
> [1] "i686, linux-gnu"
>
> $status
> [1] ""
>
> $major
> [1] "2"
>
> $minor
> [1] "0.1"
>
> $year
> [1] "2004"
>
> $month
> [1] "11"
>
> $day
> [1] "15"
>
> $language
> [1] "R"
>
>
> RHEL 3.0
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jfox at mcmaster.ca  Sat Feb 19 14:36:44 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sat Feb 19 14:36:55 2005
Subject: [Rd] RE: [R] using poly in a linear regression in the presence of
	NAf ails (despite subsetting them out)
In-Reply-To: <Pine.LNX.4.61.0502190530480.958@gannet.stats>
Message-ID: <20050219133644.MACS1567.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Brian,

Whenever I disagree with you, I wonder what error I made, and almost always
discover that there was something I missed.

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Prof 
> Brian Ripley
> Sent: Saturday, February 19, 2005 1:09 AM
> To: John Fox
> Cc: 'Markus Jantti'; r-devel@stat.math.ethz.ch; 'Liaw,Andy'
> Subject: [Rd] RE: [R] using poly in a linear regression in 
> the presence of NAf ails (despite subsetting them out)
> 
> On Fri, 18 Feb 2005, John Fox wrote:
> 
> > Dear Andy, Brian, and Markus,
> >
> > I've moved this to r-devel because the issue is a bit esoteric. I 
> > apologize for joining the discussion so late, but didn't have time 
> > earlier in the week to formulate these ideas.
> 
> I think you didn't take time to check what happens in R-devel, though.

I did check the R 2.1 news file for poly, na.action, and na.omit, but didn't
find anything. Did I miss something?

> 
> > I believe that I understand and appreciate Brian's point, but think 
> > that the issue isn't entirely clear-cut.
> >
> > It seems to me that two kinds of questions arise with missing data. 
> > The deeper ones are statistical but there are also nontrivial 
> > mechanical issues such as the one here.
> >
> > Whenever a term in a model is parametrized with a data-dependent 
> > basis, there's a potential for problems and confusion -- 
> manifested, 
> > for example, in the issue of "safe" prediction. I don't think that 
> > these problems are unique to missing data. On the other hand, the 
> > basis selected for the subspace spanned by a term shouldn't 
> be the most important consideration.
> > That is, when models are equivalent -- as, for example lm(y ~ x + 
> > I(x^2)) and lm(y ~ poly(x, 2)), an argument could be made 
> for treating 
> > them similarly.
> 
> Only in linear models, and we are here talking about general 
> behaviour of finding the model frame.
> 

That's a good point -- I hadn't considered it. I don't see the full
ramifications, however.

> > Brian's point that NAs, say, in x2, can influence the basis for 
> > poly(x1, 2) is disquieting, but note that this can happen 
> now if there are no NAs in x1.
> 
> That is not what I said, and it is incorrect.  poly(x1, 2) is 
> determined by the set of values of x1 (so they need all to be 
> known hence no NAs in
> x1) and nothing else.  Example:

What you said was, "The problem is that poly(x, 2) depends on the possible
set of x values, and so needs to know all of them, unlike e.g. log(x) which
is observation-by-observation.  Silently omitting missing values is not a
good idea in such cases, especially if the values are missing in other
variables (which is what na.action is likely to do)." I misinterpreted it.

> 
> > y <- rnorm(10)
> > x1 <- 1:10
> > x2 <- c(NA, runif(9))
> > model.frame(y ~ poly(x1, 2) + x2, na.action = na.omit)
>              y poly(x1, 2).1 poly(x1, 2).2         x2
> 2  -0.5110095   -0.38533732    0.17407766 0.07377988
> 3  -0.9111954   -0.27524094   -0.08703883 0.30968660
> 4  -0.8371717   -0.16514456   -0.26111648 0.71727174
> 5   2.4158352   -0.05504819   -0.34815531 0.50454591
> 6   0.1340882    0.05504819   -0.34815531 0.15299896
> 7  -0.4906859    0.16514456   -0.26111648 0.50393349
> 8  -0.4405479    0.27524094   -0.08703883 0.49396092
> 9   0.4595894    0.38533732    0.17407766 0.75120020
> 10 -0.6937202    0.49543369    0.52223297 0.17464982
> > model.frame(y ~ poly(x1, 2) + x2, na.action = na.pass)
>              y poly(x1, 2).1 poly(x1, 2).2         x2
> 1  -0.1102855   -0.49543369    0.52223297         NA
> 2  -0.5110095   -0.38533732    0.17407766 0.07377988
> 3  -0.9111954   -0.27524094   -0.08703883 0.30968660
> 4  -0.8371717   -0.16514456   -0.26111648 0.71727174
> 5   2.4158352   -0.05504819   -0.34815531 0.50454591
> 6   0.1340882    0.05504819   -0.34815531 0.15299896
> 7  -0.4906859    0.16514456   -0.26111648 0.50393349
> 8  -0.4405479    0.27524094   -0.08703883 0.49396092
> 9   0.4595894    0.38533732    0.17407766 0.75120020
> 10 -0.6937202    0.49543369    0.52223297 0.17464982
> 
> 

The point that I was trying to make is this:

> y <- rnorm(10)
> x1 <- 1:10
> x2 <- c(NA, runif(9))
> mf <- model.frame(y ~ poly(x1, 2) + x2, na.action = na.omit)
> cor(mf[,2])
          1         2
1 1.0000000 0.4037864
2 0.4037864 1.0000000
> 
> Data <- na.omit(data.frame(y, x1, x2))
> mf <- model.frame(y ~ poly(x1, 2) + x2, na.action = na.omit, data=Data)
> cor(mf[,2])
  1 2
1 1 0
2 0 1
> 


> > The point, therefore, doesn't really justify the current 
> behaviour of 
> > poly(). Indeed, if there are NAs in x2 but not in x1, the columns 
> > representing poly(x1, 2) won't be orthogonal in the subset of cases 
> > used in the model fit (though they do provide a correct 
> basis for the term).
> 
> It is currently documented to not allow NAs:
> 
> x, newdata: a numeric vector at which to evaluate the polynomial. 'x'
>            can also be a matrix.  Missing values are not 
> allowed in 'x'.
> 
> Why does that need any justification?
> 

Because one might expect (perhaps, you could argue, one shouldn't expect)
the basis for the polynomial term to be orthogonal in the subset of
observations actually used for the fit. 

> > Consider another example -- lm(y ~ f, subset = f != "a"), 
> where f is a 
> > factor with levels "a", "b", and "c", and where there are NAs in f. 
> > Here the basis for the f term is data dependent, in that 
> the baseline 
> > level is taken as "b" in the absence of "a", yet NAs don't 
> cause an error.
> >
> > Having poly(), bs(), and ns() report a more informative 
> error message 
> > certainly is preferable to the current situation, but an 
> alternative 
> > would be to have them work and perhaps report a warning.
> 
> What exactly does `work' mean here?  Run and give misleading answers?
> 

That implies that there's a simple right answer answer here, which I don't
think is the case. I'm persuaded that what I recommended is not good idea
because of its more general implications, but it's not obvious to me that
creating a basis that's orthogonal in the subset of observations used for
the fit is misleading, while the current behaviour isn't misleading. 

> > If the object is to protect people from stepping into traps 
> because of 
> > missing data, then an argument could be made for having the default 
> > na.action be na.fail, as in S-PLUS. (I wouldn't advocate 
> this, by the 
> > way.) Perhaps I'm missing some consideration here, but isn't it 
> > clearest to allow the data, subset, and na.action arguments to 
> > determine the data in which the formula is evaluated?
> 
> Exactly how?  It would be a major change from the current 
> methodology and I am not sure you appreciate what that is.
> 

Yes, I looked at how this works currently, but agree that I didn't
appreciate the implications of changing it -- e.g., for nonlinear models. I
still don't entirely appreciate those implications.

> Remember that na.action could for example replace missing 
> values by random imputations, or even multiple imputations, 
> and na.action comes quite late in the process *after* the 
> model frame has been formed.  Unlike factors,
> poly() etc generate multiple columns in the model frame, and 
> then subset and na.action are applied.  Factors are encoded 
> in model.matrix (and that is really only used for the linear 
> parts of models, unlike model.frame).
> 
> I am not sure you appreciate the basic point: poly is applied 
> to the whole dataset and not to a subset, and that can be 
> important (e.g. to ensure no unstable extrapolation when 
> predicting later).

Note, however, that a user could create the subset as a data frame through
na.omit() prior to applying poly() -- as I did in the example above. In
fact, that's probably what a user of poly() would now want to do.

>  Really na.action has to come last, as 
> functions in the formula could themselves generate NAs
> (log(0) for example).
> 

I did understand the sequence of operations, but didn't see the point about
newly generated NAs. I agree that this makes it necessary to remove NAs
last.

> There is an alternative, that poly() works only on finite 
> values and passes through non-finite ones, but it was 
> deliberately not written that way and you will need to 
> convince everyone that would be a better solution.  (What 
> happens for example if there are only two finite values?) If 
> you want such a function, it is easy for you to provide it: 
> just please don't call it poly().  [Writing poly() was not 
> easy BTW, but poly_allow_NAs would be given poly.]
> 

I'm no longer convinced that what I proposed is a better solution, but the
current situation seems problematic to me as well.

Thanks for the extended explanation.

John

> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From feferraz at ime.usp.br  Sat Feb 19 18:54:49 2005
From: feferraz at ime.usp.br (Fernando Henrique Ferraz P. da Rosa)
Date: Sat Feb 19 18:54:47 2005
Subject: [Rd] Translation commentaries
Message-ID: <20050219175449.GA23823@ime.usp.br>


        I have just finished translating R.pot to pt_BR and now I'll
start the process of revision and will merge it with the latest SVN
version (33261), as I started the translation on 02/06 (SVN 33048).

        There are some observations I'd like to make regarding the
translation process:

        1) Sometimes it is not clear in the message whether a given term is
referring to an actual function argument or to a more general concept.
For example:

#: src/modules/lapack/Lapack.c:49 src/modules/lapack/Lapack.c:128
msgid "method must be a character object"

        Generally I look into the respective source code and try to
figure out from context. When it is a function argument I'm keeping the
original word untranslated, when it's just a reference to the concept I
translate it. It would be interesting to standardize this: whenever an
actual argument of function is being referred to, it could be enclosed
in simple quotes:

msgid "'method' must be a character object".

        This already happens for some msgs, but not for all of them.

        2) Some messages are essentially the same, with minor variations.
I think they should be merged into just one. For instance:

#: src/main/subassign.c:396 src/main/subassign.c:669
src/main/subassign.c:917
msgid "number of items to replace is not a multiple of replacement
length"

#: src/main/subassign.c:1099
msgid "no of items to replace is not a multiple of replacement length"
        
        3) There's at least once the assumption that the plural form of
a noun will be composed by adding an s:

#: src/main/util.c:806
#, c-format
msgid "%d argument%s passed to \"%s\" which requires %d"

        Where the relevant source code reads:

   error(_("%d argument%s passed to \"%s\" which requires %d"),
              length(args), (length(args) == 1 ? "" : "s"),

        While it may hold true for English (and incidentally also
Portuguese), in German for example the plural form for Argument would be
Argumente. 

        Unfortunately I can't provide more comprehensive lists for 1)
and 2) right now because I haven't started the revision and updating
process yet, but as soon as I finish it I'll send it to r-devel.


--
Fernando Henrique Ferraz P. da Rosa
http://www.ime.usp.br/~feferraz

From nawaaz at inktomi.com  Sat Feb 19 22:21:05 2005
From: nawaaz at inktomi.com (Nawaaz Ahmed)
Date: Sat Feb 19 22:21:40 2005
Subject: [Rd] Re: [R] Memory Fragmentation in R
In-Reply-To: <Pine.LNX.4.61.0502191815380.15926@gannet.stats>
References: <421774EC.3020007@inktomi.com>
	<Pine.LNX.4.61.0502191815380.15926@gannet.stats>
Message-ID: <4217ADC1.5030506@inktomi.com>

Thanks Brian. I looked at the code (memory.c) after I sent out the first 
email and noticed the malloc() call that you mention in your reply.
Looking into this code suggested a possible scenario where R would fail 
in malloc() even if it had enough free heap address space.

I noticed that if there is enough heap address space (memory.c:1796, 
VHEAP_FREE() > alloc_size) then the garbage collector is not run. So 
malloc could fail (since there is no more address space to use), even 
though R itself has enough free space it can reclaim. A simple fix is 
for R to try doing garbage collection if malloc() fails.

I hacked memory.c() to look in R_GenHeap[LARGE_NODE_CLASS].New if 
malloc() fails (in a very similar fashion to ReleaseLargeFreeVectors())
I did a "best-fit" stealing from this list and returned it to 
allocVector(). This seemed to fix my particular problem - the large 
vectors that I had allocated in the previous round were still sitting in 
  this list. Of course, the right thing to do is to check if there are 
any free vectors of the right size before calling malloc() - but it was 
simpler to do it my way (because I did not have to worry about how 
efficient my best-fit was; memory allocation was anyway going to fail).

I can look deeper into this and provide more details if needed.

Nawaaz





Prof Brian Ripley wrote:
> BTW, I think this is really an R-devel question, and if you want to 
> pursue this please use that list.  (See the posting guide as to why I 
> think so.)
> 
> This looks like fragmentation of the address space: many of us are using 
> 64-bit OSes with 2-4Gb of RAM precisely to avoid such fragmentation.
> 
> Notice (memory.c line 1829 in the current sources) that large vectors 
> are malloc-ed separately, so this is a malloc failure, and there is not 
> a lot R can do about how malloc fragments the (presumably in your case 
> as you did not say) 32-bit process address space.
> 
> The message
>   1101.7 Mbytes of heap free (51%)
> is a legacy of an earlier gc() and is not really `free': I believe it 
> means something like `may be allocated before garbage collection is 
> triggered': see memory.c.
> 
> 
> On Sat, 19 Feb 2005, Nawaaz Ahmed wrote:
> 
>> I have a data set of roughly 700MB which during processing grows up to 
>> 2G ( I'm using a 4G linux box). After the work is done I clean up 
>> (rm()) and the state is returned to 700MB. Yet I find I cannot run the 
>> same routine again as it claims to not be able to allocate memory even 
>> though gcinfo() claims there is 1.1G left.
>>
>>     At the start of the second time
>>     ===============================
>>               used  (Mb) gc trigger   (Mb)
>>     Ncells  2261001  60.4    3493455   93.3
>>     Vcells 98828592 754.1  279952797 2135.9
>>
>>     Before Failing
>>     ==============
>>     Garbage collection 459 = 312+51+96 (level 0) ...
>>     1222596 cons cells free (34%)
>>     1101.7 Mbytes of heap free (51%)
>>     Error: cannot allocate vector of size 559481 Kb
>>
>> This looks like a fragmentation problem. Anyone have a handle on this 
>> situation? (ie. any work around?) Anyone working on improving R's 
>> fragmentation problems?
>>
>> On the other hand, is it possible there is a memory leak? In order to 
>> make my functions work on this dataset I tried to eliminate copies by 
>> coding with references (basic new.env() tricks). I presume that my 
>> cleaning up returned the temporary data (as evidenced by the gc output 
>> at the start of the second round of processing). Is it possible that 
>> it was not really cleaned up and is sitting around somewhere even 
>> though gc() thinks it has been returned?
>>
>> Thanks - any clues to follow up will be very helpful.
>> Nawaaz
> 
>

From luke at stat.uiowa.edu  Sat Feb 19 23:58:23 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sat Feb 19 23:58:46 2005
Subject: [Rd] Re: [R] Memory Fragmentation in R
In-Reply-To: <4217ADC1.5030506@inktomi.com>
References: <421774EC.3020007@inktomi.com>
	<Pine.LNX.4.61.0502191815380.15926@gannet.stats>
	<4217ADC1.5030506@inktomi.com>
Message-ID: <Pine.LNX.4.61.0502191654040.6368@itasca2.stat.uiowa.edu>

On Sat, 19 Feb 2005, Nawaaz Ahmed wrote:

> Thanks Brian. I looked at the code (memory.c) after I sent out the first 
> email and noticed the malloc() call that you mention in your reply.
> Looking into this code suggested a possible scenario where R would fail in 
> malloc() even if it had enough free heap address space.
>
> I noticed that if there is enough heap address space (memory.c:1796, 
> VHEAP_FREE() > alloc_size) then the garbage collector is not run. So malloc 
> could fail (since there is no more address space to use), even though R 
> itself has enough free space it can reclaim. A simple fix is for R to try 
> doing garbage collection if malloc() fails.
>
> I hacked memory.c() to look in R_GenHeap[LARGE_NODE_CLASS].New if malloc() 
> fails (in a very similar fashion to ReleaseLargeFreeVectors())
> I did a "best-fit" stealing from this list and returned it to allocVector(). 
> This seemed to fix my particular problem - the large vectors that I had 
> allocated in the previous round were still sitting in  this list. Of course, 
> the right thing to do is to check if there are any free vectors of the right 
> size before calling malloc() - but it was simpler to do it my way (because I 
> did not have to worry about how efficient my best-fit was; memory allocation 
> was anyway going to fail).
>
> I can look deeper into this and provide more details if needed.

Thanks.  It looks like it would be a good idea to modify the malloc at
that point to try a GC if the malloc fails, then retry the malloc and
only bail if the second malloc fails.  I want to think this through a
bit more before going ahead, but I think it will be the right thing to
do.

Best,

luke


>
> Nawaaz
>
>
>
>
>
> Prof Brian Ripley wrote:
>> BTW, I think this is really an R-devel question, and if you want to pursue 
>> this please use that list.  (See the posting guide as to why I think so.)
>> 
>> This looks like fragmentation of the address space: many of us are using 
>> 64-bit OSes with 2-4Gb of RAM precisely to avoid such fragmentation.
>> 
>> Notice (memory.c line 1829 in the current sources) that large vectors are 
>> malloc-ed separately, so this is a malloc failure, and there is not a lot R 
>> can do about how malloc fragments the (presumably in your case as you did 
>> not say) 32-bit process address space.
>> 
>> The message
>>   1101.7 Mbytes of heap free (51%)
>> is a legacy of an earlier gc() and is not really `free': I believe it means 
>> something like `may be allocated before garbage collection is triggered': 
>> see memory.c.
>> 
>> 
>> On Sat, 19 Feb 2005, Nawaaz Ahmed wrote:
>> 
>>> I have a data set of roughly 700MB which during processing grows up to 2G 
>>> ( I'm using a 4G linux box). After the work is done I clean up (rm()) and 
>>> the state is returned to 700MB. Yet I find I cannot run the same routine 
>>> again as it claims to not be able to allocate memory even though gcinfo() 
>>> claims there is 1.1G left.
>>> 
>>>     At the start of the second time
>>>     ===============================
>>>               used  (Mb) gc trigger   (Mb)
>>>     Ncells  2261001  60.4    3493455   93.3
>>>     Vcells 98828592 754.1  279952797 2135.9
>>> 
>>>     Before Failing
>>>     ==============
>>>     Garbage collection 459 = 312+51+96 (level 0) ...
>>>     1222596 cons cells free (34%)
>>>     1101.7 Mbytes of heap free (51%)
>>>     Error: cannot allocate vector of size 559481 Kb
>>> 
>>> This looks like a fragmentation problem. Anyone have a handle on this 
>>> situation? (ie. any work around?) Anyone working on improving R's 
>>> fragmentation problems?
>>> 
>>> On the other hand, is it possible there is a memory leak? In order to make 
>>> my functions work on this dataset I tried to eliminate copies by coding 
>>> with references (basic new.env() tricks). I presume that my cleaning up 
>>> returned the temporary data (as evidenced by the gc output at the start of 
>>> the second round of processing). Is it possible that it was not really 
>>> cleaned up and is sitting around somewhere even though gc() thinks it has 
>>> been returned?
>>> 
>>> Thanks - any clues to follow up will be very helpful.
>>> Nawaaz
>> 
>> 
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From ripley at stats.ox.ac.uk  Sun Feb 20 00:00:44 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Feb 20 00:00:55 2005
Subject: [Rd] Re: [R] Memory Fragmentation in R
In-Reply-To: <4217ADC1.5030506@inktomi.com>
References: <421774EC.3020007@inktomi.com>
	<Pine.LNX.4.61.0502191815380.15926@gannet.stats>
	<4217ADC1.5030506@inktomi.com>
Message-ID: <Pine.LNX.4.61.0502192140060.11327@gannet.stats>

I am not the expert here (the author, Luke Tierney, is probably 
listening), but I understood you to have done a gc() immediately before 
your second run: you presented statistics from it.  If so, then I don't 
understand in detail.  Probably Luke does.

That's good general advice: clear out results you no longer need and run 
gc() before starting a memory-intensive task (and it also helps if you are 
timing things not to include the time of gc()-ing previous work).
I did sometimes run gc() at the end of each simulation run just to 
ensure that malloc has the maximal chance to clean up the allocations, in 
32-bit days.

On Sat, 19 Feb 2005, Nawaaz Ahmed wrote:

> Thanks Brian. I looked at the code (memory.c) after I sent out the first 
> email and noticed the malloc() call that you mention in your reply.
> Looking into this code suggested a possible scenario where R would fail in 
> malloc() even if it had enough free heap address space.
>
> I noticed that if there is enough heap address space (memory.c:1796, 
> VHEAP_FREE() > alloc_size)

I don't think that quite corresponds to your words: it is rather that 
successful allocation would not provoke a gc (unless gc.torture is on).

> then the garbage collector is not run. So malloc 
> could fail (since there is no more address space to use), even though R 
> itself has enough free space it can reclaim. A simple fix is for R to try 
> doing garbage collection if malloc() fails.

I believe running ReleaseLargeFreeVectors would suffice.

> I hacked memory.c() to look in R_GenHeap[LARGE_NODE_CLASS].New if malloc() 
> fails (in a very similar fashion to ReleaseLargeFreeVectors())
> I did a "best-fit" stealing from this list and returned it to allocVector(). 
> This seemed to fix my particular problem - the large vectors that I had 
> allocated in the previous round were still sitting in  this list.

They should have been released by the gc() you presented the statistics 
from, and they would have been included in those statistics if still in 
use at that point. So, I don't understand why they are still around.

> Of course, the right thing to do is to check if there are any free 
> vectors of the right size before calling malloc() - but it was simpler 
> to do it my way (because I did not have to worry about how efficient my 
> best-fit was; memory allocation was anyway going to fail).

I rather doubt that is better than letting the malloc sort this out, as it 
might be able to consolidate blocks if given them all back at once.

> I can look deeper into this and provide more details if needed.

I am unclear what you actually did, but it may be a judicious gc() is all 
that was needed: otherwise the issues should be the same in the first and 
the subsequent run.  That's not to say that when the trigger gets near the 
total address space we could not do better: and perhaps we should not let 
it to do so (if we could actually determine the size of the address space 
... it is 2Gb or 3Gb on Windows for example).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Sun Feb 20 02:10:48 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun Feb 20 02:16:17 2005
Subject: [Rd] eapply weirdness/bug
In-Reply-To: <Pine.LNX.4.61.0502181029410.7043@nokomis.stat.uiowa.edu>
References: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>
	<x2vf8q5k3a.fsf@biostat.ku.dk>
	<Pine.LNX.4.61.0502180821170.3177@itasca2.stat.uiowa.edu>
	<x23bvtdha6.fsf@biostat.ku.dk>
	<Pine.LNX.4.61.0502181029410.7043@nokomis.stat.uiowa.edu>
Message-ID: <x2vf8ojasn.fsf@biostat.ku.dk>

Luke Tierney <luke@stat.uiowa.edu> writes:

> For this specific case though, I _think_ the semantics we want is this:
> 
>      eapply1 <- function(env, FUN, ..., all.names = FALSE) {
>  	FUN <- match.fun(FUN)
>  	lapply(.Internal(env2list(env, all.names)), FUN, ...)
>      }
> 
> Not passing the ... in the current implementation is, I think, an
> oversight, as is the extra evaluation that occurs.  Given that lapply
> is already internal I'm not sure there really is very much benefit in
> having the internal eapply.  If not I'd prefer to replace it by
> something like this; if there are reasons for keeping the .Internal we
> can work on replicating these semantics as closely as possible.  I
> think Robert is the one who would know the issues.

I agree on the semantics (I didn't quite think of the consequences of
FUN doing an eval.parent and things like that before). But if
implemented literally, wouldn't that env2list cause some undesirable
copying? I have the impression that people interested in eapply use
their environments to hold some pretty large objects. So maybe we
should stick with the get()-based version

      eapply2 <- function(env, FUN, ..., all.names = FALSE) {
       FUN <- match.fun(FUN)
       nm <- ls(envir=env,all.names=all.names)
       FUN2 <- function(name,...)FUN(get(name),...)
       lapply(nm, FUN2, ...)
      }



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From nawaaz at inktomi.com  Sun Feb 20 03:40:02 2005
From: nawaaz at inktomi.com (Nawaaz Ahmed)
Date: Sun Feb 20 03:40:38 2005
Subject: [Rd] Re: [R] Memory Fragmentation in R
In-Reply-To: <Pine.LNX.4.61.0502192140060.11327@gannet.stats>
References: <421774EC.3020007@inktomi.com>
	<Pine.LNX.4.61.0502191815380.15926@gannet.stats>
	<4217ADC1.5030506@inktomi.com>
	<Pine.LNX.4.61.0502192140060.11327@gannet.stats>
Message-ID: <4217F882.6050503@inktomi.com>

> 
> I am unclear what you actually did, but it may be a judicious gc() is 
> all that was needed: otherwise the issues should be the same in the 
> first and the subsequent run.  That's not to say that when the trigger 
> gets near the total address space we could not do better: and perhaps we 
> should not let it to do so (if we could actually determine the size of 
> the address space ... it is 2Gb or 3Gb on Windows for example).
> 

I did do gc() but only at the top level functions - there were internal 
functions in libraries/packages that were allocating space.

Here is how I think the problem happens. Consider code of the form
         x = as.vector(x)
	y = as.double(y)
where x is a 500MB matrix, y is 100 MB

Let's say we have 1201MB totally.
	Initially:
            x has 500MB, y has 100MB
            heap can grow by 601MB

	x = as.vector(x):
	   x has 500 MB, y has 100MB
            as.vector() duplicated 500MB (to be garbage collected)
            heap can grow by 101 MB

         y = as.vector(y)
            x has 500 MB, y has 100 MB
            R has 500 MB to be garbage collected
            as.vector() requires 100MB for duplicating y
            garbage collector is not run
                - required amount (100MB) < possible heap growth (101MB)
	   allocVector() calls malloc()
                - malloc() can fail at this point
                - it cannot get contiguous 100MB

You are right, it is most likely to happen close to the trigger. But the 
fix should be easy (call gc() if malloc() fails) - I initially hacked at
trying to steal vectors from the free list because I thought the problem 
I was seeing was due to address space fragmentation. The latter could 
still be a problem and would be harder to fix.

Thanks Luke and Brian!
Nawaaz

From W.E.Wolski at newcastle.ac.uk  Sun Feb 20 13:53:28 2005
From: W.E.Wolski at newcastle.ac.uk (W.E. Wolski)
Date: Sun Feb 20 13:53:44 2005
Subject: [Rd] Comments to promptMethods/promptClass
Message-ID: <Pine.SOL.4.21.0502201219140.443-100000@finan.ncl.ac.uk>

Hi,

The Rd file sceleton created using function _promptMethdos_ contains
*only* the
following fields:
name
docType
alias
title
description
section{Methods}
keyword 


while _promptClass_ creates in addition fields like:
author
references
seealso
examples

and even is invalid due to:

 ~Make other sections like Warning with \section{Warning }{....} ~

A)

It a seems a little that the designer of the
prompt[Methods,Class] expects
that the documentation for a Class (..-class.Rd) 
should be more detailed
than the documentation for methods  (..-methods.Rd).
In my view it is not so.
Even if Classes have in S4, a much more prominent position than is the
case in S3, in my view the aim of R/S4 is provide cool methods. Hence, the
methods are the meat.
Therefore, I would highly appreciate if _promptMethods_ would
create such entries like author, references, seelalso, examples, value
etc.  A more trivial argument to create more entries
if calling promptMethods is: It is much
faster to delete superfluous entries than to copy or type them.

B)

I suggest that the statment:

 ~Make other sections like Warning with \section{Warning }{....} ~
is not created by a call to promptClass in the ...-class.Rd file.
It causes that a invalid Rd file is created.
If the opinion is that such a hint is valuable than something like
the following does it either and do not invalidates the Rd file.

\section{Warnign}{
 ~Make other sections like Warning, see writing R-extensions.
}



Yours  
Eryk.

From mvida at mac.com  Sun Feb 20 15:58:58 2005
From: mvida at mac.com (Melanie Vida)
Date: Sun Feb 20 15:59:12 2005
Subject: [Rd] matrix operations
Message-ID: <52ea15e4ad9646d0c54ac9a29d2d906b@mac.com>

In R, I'm imported a data frame of  2,321,123 by 4 called "dataF".
I converted the data frame "dataF" to a matrix

dataM <- as.matrix(dataF)

Does R have an efficient routine to treat the special elements that 
contain "inf" in them. For example, can you separate the rows that have 
"inf" elements from the matrix into a separate matrix without iterating 
over the entire matrix?

Also, does R have an efficient way to sort columns in a matrix?

-Melanie

From ggrothendieck at myway.com  Sun Feb 20 17:16:15 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun Feb 20 17:20:04 2005
Subject: [Rd] matrix operations
References: <52ea15e4ad9646d0c54ac9a29d2d906b@mac.com>
Message-ID: <loom.20050220T171039-337@post.gmane.org>

Melanie Vida <mvida <at> mac.com> writes:

: 
: In R, I'm imported a data frame of  2,321,123 by 4 called "dataF".
: I converted the data frame "dataF" to a matrix
: 
: dataM <- as.matrix(dataF)
: 
: Does R have an efficient routine to treat the special elements that 
: contain "inf" in them. For example, can you separate the rows that have 
: "inf" elements from the matrix into a separate matrix without iterating 
: over the entire matrix?

This will eliminate all rows that contain Inf or -Inf.

m[apply(is.finite(m), 1, all),]

: 
: Also, does R have an efficient way to sort columns in a matrix?

This can be interpreted a number of different ways:

See
?order
?sort

m[order(m[,1]),] # sorts so that column 1 is sorted and rows stay together
apply(m, 2, sort) # sort each column separately

From luke at stat.uiowa.edu  Sun Feb 20 17:58:29 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sun Feb 20 17:58:58 2005
Subject: [Rd] eapply weirdness/bug
In-Reply-To: <x2vf8ojasn.fsf@biostat.ku.dk>
References: <4D99275E380CA94F998977EDACE548DC074AAC@extas2-hba.tas.csiro.au>
	<x2vf8q5k3a.fsf@biostat.ku.dk>
	<Pine.LNX.4.61.0502180821170.3177@itasca2.stat.uiowa.edu>
	<x23bvtdha6.fsf@biostat.ku.dk>
	<Pine.LNX.4.61.0502181029410.7043@nokomis.stat.uiowa.edu>
	<x2vf8ojasn.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.61.0502201056060.6368@itasca2.stat.uiowa.edu>

On Sat, 20 Feb 2005, Peter Dalgaard wrote:

> Luke Tierney <luke@stat.uiowa.edu> writes:
>
>> For this specific case though, I _think_ the semantics we want is this:
>>
>>      eapply1 <- function(env, FUN, ..., all.names = FALSE) {
>>  	FUN <- match.fun(FUN)
>>  	lapply(.Internal(env2list(env, all.names)), FUN, ...)
>>      }
>>
>> Not passing the ... in the current implementation is, I think, an
>> oversight, as is the extra evaluation that occurs.  Given that lapply
>> is already internal I'm not sure there really is very much benefit in
>> having the internal eapply.  If not I'd prefer to replace it by
>> something like this; if there are reasons for keeping the .Internal we
>> can work on replicating these semantics as closely as possible.  I
>> think Robert is the one who would know the issues.
>
> I agree on the semantics (I didn't quite think of the consequences of
> FUN doing an eval.parent and things like that before). But if
> implemented literally, wouldn't that env2list cause some undesirable
> copying? I have the impression that people interested in eapply use
> their environments to hold some pretty large objects. So maybe we
> should stick with the get()-based version
>
>      eapply2 <- function(env, FUN, ..., all.names = FALSE) {
>       FUN <- match.fun(FUN)
>       nm <- ls(envir=env,all.names=all.names)
>       FUN2 <- function(name,...)FUN(get(name),...)
>       lapply(nm, FUN2, ...)
>      }

The copying issue is a good point--Robert also reminded me of this.  I
_think_ the approach based on env2list would be OK but I'd have to
check very caerfully to be sure.  Rather than spend time doing that I
think this argues for keeping the .Internal varsion and modifying it
to obtain the semantics we want.  I'll look into that.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke@stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From ripley at stats.ox.ac.uk  Sun Feb 20 20:13:36 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun Feb 20 20:13:48 2005
Subject: [Rd] matrix operations
In-Reply-To: <52ea15e4ad9646d0c54ac9a29d2d906b@mac.com>
References: <52ea15e4ad9646d0c54ac9a29d2d906b@mac.com>
Message-ID: <Pine.LNX.4.61.0502201903470.32454@gannet.stats>

On Sun, 20 Feb 2005, Melanie Vida wrote:

> In R, I'm imported a data frame of  2,321,123 by 4 called "dataF".
> I converted the data frame "dataF" to a matrix
>
> dataM <- as.matrix(dataF)

I am assuming this is a numeric matrix, and "inf" means Inf and in places 
that there are no NAs.

> Does R have an efficient routine to treat the special elements that contain 
> "inf" in them. For example, can you separate the rows that have "inf" 
> elements from the matrix into a separate matrix without iterating over the 
> entire matrix?

Not really, but is.infinite will do a C-level iteration, as will ==

dataM[rowSums(is.infinite(dataM)) > 0, ] # rows containing Inf or -Inf
dataM[rowSums(dataM == Inf), ]           # rows containing Inf  (no NAs)
A <- !is.na(dataM) & dataM == Inf
dataM[rowSums(A), ]                      # rows containing Inf (possible NAs)

> Also, does R have an efficient way to sort columns in a matrix?

How about

for(i in 1:4) dataM[, i] <- sort(dataM[, i], method ="quick")

?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mcrdhigkg at cyberdif.com  Mon Feb 21 10:18:01 2005
From: mcrdhigkg at cyberdif.com (mcrdhigkg@cyberdif.com)
Date: Mon Feb 21 10:18:13 2005
Subject: [Rd] Hot st0ck tips from experts who beat the market (PR#7696)
Message-ID: <20050221091801.836F6AD6F@slim.kubism.ku.dk>

GEEC  GEEC  GEEC  GEEC  GEEC

Globa| Environmenta| Energy Corp. (OTC-BB: GEEC)
Shares Outstanding : 35 mi|lion
Approx. Float : 9 mi|lion
3O Day Target : 6.25
6 Month Price Projection : 15.O0

Recent News and Major Share-Price Driving Milestones:

GEEC just announced a 10 Bil|ion, 5-year joint venture with severa| 
companies operated by the Chinese Government.

GEEC uses their Biosphere Process System to convert various types of 
waste into clean, "green" e|ectricity at 5 to 1O mega-watts per hour.

GEEC Chairman, former Prime Minister of Ireland Dr. A|bert Reynolds, 
has secured a 2 Bi|lion LineOfCredit for GEEC and opened doors in over 
a 
dozen countries through political contacts at the highest leve|.

GEEC is CBS Marketwatch.com's #1 Best Performer in the DJ Diversified 
Industria|s Index in the |ast 3 months. This Dow Jones Index also 
contains 3M, GE, and Honeywell.

Conservative estimates value the company at One Bil|ion.


Solving a Dua| Crisis - Waste and Energy

GEEC is utilizing the unique proprietary technology of their Biosphere 
Process System for the disposal of a wide variety of waste products at 
5 to 7 tons per hour, making a major impact on the g|oba| waste 
prob|em. This profitab|e and environmenta||y safe process converts into 
c|ean, 
"green" e|ectricity such waste materials as Municipa| Solid Waste, 
agricultural wastes, forestry wastes, medical wastes, industrial 
wastes, 
sewage sludge, shale oil, sour natural gas, and the huge market of used 
tires.
GEEC generates 5 to 10 mega-watts per hour of electricity from the 
waste conversion on a continuous basis which is then so|d to rep|enish 
the 
|oca| or nationa| grid.


China's Aggressive Pursuit of GEEC makes 2005 a "B|ue-Chip" Year

GEEC just announced a 10 Billion, 5-year joint venture with Chinese 
Government-operated companies, inc|uding Yanzhou Coa| Mining (NYSE - 
YZC, 
74.0O). The deal is structured to have 1,30O GEEC Biosphere Systems 
deployed throughout China to fulfill a need for waste disposal and 
energy 
generation, two critica| areas for a country with a population 
exceeding 1.3 billion peop|e. As China's rapid economic advance 
continues, a 
shortfa|| of 5O0 million kilowatts exists annually, prompting periodic 
b|ackouts in al| Chinese Provinces. GEEC is in |ine to gain 
substantial|y 
while providing relief from unmanageab|e Municpal So|id Waste disposa| 
and simultaneously helping China meet its energy needs.


Future Mi|estones:
1.	GEEC had a 100 Mi|lion backlog of sa|es orders for the Biosphere 
before the China joint-venture with 26 comp|eted Biospheres in 
operation. 
The back|og is now into the Billions with complete financing to be 
provided by China and 1,300 Biospheres to be deployed throughout the 
country.
2.	GEEC's present assets of 35 Mi||ion wil| conservatively jump into 
the 30O Mi||ion range, a 10-times increasee.
3.	GEEC is in advanced stages of agreement on at least 6 major 
internationa| projects which could add 50 Mil|ion to the bottom-|ine or 
1.42 
per share.
4.	P/E on average for this Industry Gr0up is 20 to 1 putting GEEC above 
the 13.00 range without any future business expansion.
5.	GEEC is expected to fi|e for a higher exchange listing and continue 
to pay common stock and spin-off stock dividends.


Wor|dwide Market Potential 15 to 25 Bi||ion over next 5 years with no 
other known company that can match their technology, |eadership, or 
exp|osive sales growth.

Up until now GEEC has been one of Wall Street's best kept secrets, yet 
now it seems the cat is coming out of the bag and the re|ease of this 
new Investor Awareness Campaign should be exce||ent timing in regards 
to 
some new PR's forthcoming which will Rocket GEEC. This power-p|ay has 
nowhere to go but up, according to most insiders, and there's still a 
bit of time to get in before the boom. Increased investor awareness and 
the anticipated re|ease of huge news announcements wi|| add to the 
buying frenzy from investors loading up before GEEC goes through the 
roof.


Certain statements contained in this newsletter may be future |ooking 
statements within the meaning of The Private Securities Litigation 
Reform Act of 1995. These statements may be identified by such terms as 
expect, be|ieve, may, wi|l, and intend or simi|ar terms. We are not a 
registered investment expert or a broker dea|er. This is not an attempt 
to 
acquire or se|l securities. No suggestion that the securities of the 
company profi|ed should be acquired, so|d or he|d by individuals or 
entities that |earn of the profiled company. This is an independent 
e|ectronic pub|ication that was paid fifteen thousand dollars by a 
third party 
for the preparation of this company information. Be advised that 
investments in small-cap companies are considered to be high-risk and 
use of 
the information provided is for reading purposes only. If anyone 
decides 
to act as an investor they are advised not to invest without the proper 
advisement from a registered financial broker. If any party decides to 
participate as an investor then it wi|| be that investor's sole risk. 
Be advised that the purchase of such high-risk securities may result in 
the |oss of some or al| of the investment. The publisher of this 
news|etter makes no claims as to the accuracy or the comp|eteness of 
the 
company profi|e. Investors shou|d not rely so|e|y on the information 
presented. Rather, investors shou|d use the information provided in 
this 
newsletter as a starting point for doing additiona| independent 
research on 
the profi|ed company in order to form their own opinion regarding 
investment. Factual statements made about the profi|ed company are made 
as 
of the date stated and are subject to change without notice. It is 
possib|e that an investor's entire investment may be lost or impaired 
due to 
the specu|ative nature of the company profiled. Al| information 
provided about the profi|ed company has been obtained from publicly 
avai|able 
sources which may include the company's web site, public filings, 
company press re|eases and informationa| web sites provided by the 
actual 
exchanges where sma||-cap stocks are traded.

If you wish to stop future mai|ings, or if you feel you have been 
wrongfu||y p|aced in our list, please go here 
(-stox0022@yahoo.com-)

From ripley at stats.ox.ac.uk  Mon Feb 21 10:19:09 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 21 10:19:18 2005
Subject: [Rd] Re: [R] LD_LIBRARY_PATH is harmfull
In-Reply-To: <TheMailAgent.1bca527c645a4ba@2188b157a0da1944051f3>
References: <TheMailAgent.1bca527c645a4ba@2188b157a0da1944051f3>
Message-ID: <Pine.LNX.4.61.0502210851090.15235@gannet.stats>

Please use R-devel for comments about R development (moved there).

On Mon, 21 Feb 2005, Alexander Klimov wrote:

> Hi.
>
> Consider the following situation: Solaris 8, /usr/local has gcc 2.95,
> my home has gcc 3.4.3, my gcc is first on PATH, LD_LIBRARY_PATH is
> unset (everything is perfect since I always use -R). In fact, programs
> compiled with my gcc do not work if LD_LIBRARY_PATH is set to
> something which has /usr/local/lib before home/lib, because it
> overrides stored path (-R) and I got
>
>   libgcc_s.so.1 (GCC_3.3) =>       (version not found)

I don't believe that happens unless `home/lib' is not in the library paths 
at all.  I've checked man ld and man ld.so.1 on Solaris 8, and neither 
appear to mention that -R is ignored if LD_LIBRARY_PATH is set.  I think 
that is a (well-buried) Solaris-specific gotcha.

> I found setting of LD_LIBRARY_PATH in bin/R (how /usr/local/lib get
> into it at all and especially before PREFIX/lib??? -- there was no
> LD_LIBRARY_PATH during configure!) and fixed it (although I spent
> quite a while editing lib/R/bin/R and wondering an abscence of
> any effect :-)

Please take a look at e.g. config.site, which explains this under LDFLAGS, 
(as does the R-admin manual which INSTALL asks you to read).

> After all the troubles I manage to load an extension, but, frankly, I
> think there were too many problems. It would be very nice if R-project
> reject the idea of using LD_LIBRARY_PATH because its setting is
> considered harmfull and leads to too many problems:
> http://www.linuxmafia.com/faq/Admin/ld-lib-path.html

[Which is Solaris specific, despite the site name.]

Unfortunately, the alternatives lead to even more problems, and this is 
the first report we have had for years of a problem (which can be solved 
on reading the documentation).  As the R-admin manual points out, we 
regularly test on Solaris 8 and give an example there of setting LDFLAGS 
under the Solaris section.

Use of -R is harmful for sure!  It stops R being relocatable (so it either 
could not be tested before being installed or it would not run after 
installation), and it is not at all portable.

Maybe one day when we have libtool tamed we will be able to use the
multiple equivalents of -R or LD_RUN_PATH in a portable-enough way.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rosterma at abo.fi  Mon Feb 21 10:35:21 2005
From: rosterma at abo.fi (=?ISO-8859-1?Q?Ralf_=D6stermark?=)
Date: Mon Feb 21 10:35:37 2005
Subject: [Rd] want to call R from aplatform written i strict ANSI C
Message-ID: <4219AB59.6020406@abo.fi>

Hi,
I would like to connect my GHA-system to R and to deliver the
library to users of R.

could you give me a comprehensive example containing the step by step
procedure to:
1. create a callable library with R binaries (not having a standalone
version of R with its own main()). If possible, I would like to run the
system on unix,alpha,linux computers as well as on IBM's parallel supercomputers.
2. code the interface between a main-program written in C and a
user-defined script written in R. Consider the following case:
The algorithm - written in strict ANSI C (explained below) - needs to call a user-written
R-program occasionally in order to boost computations, say, in an
ill-conditioned computational problem where classical optimization tools
can be used only locally. For this, the C-program needs somehow to
transfer data, an initialized vector of parameters and the name of the
user-defined R program to some interface function. The R program in turn
can use all the resources available in the R environment. The results of
the computations (e.g., the updated parameter vector, matrices of
forecasts and forecast errors) need to be returned to the C-program from
R. The corresponding allocations need to be done before R is invoked and freed afterwards. 

Using R would increase the flexibility of the C-platform considerably
and hopefully bring new features to R.

I would be very happy if I could do this both sequentially on
alpha/unix/linux platforms and in parallel on supercomputers.

I have developed an algorithmic platform (GHA = Genetic Hybrid
Algorithm) over the past years (referee articles are listed under
www.abo.fi/~rosterma). The system is compiled and runs without warnings
under maximum warning level in sequential mode on alpha, unix and linux
mainframes and in parallel mode on IBMs supercomputers and Cray T3E (the
latter is a more or less outdated supercomputer today).

The system was built in strict ANSI C and it can be connected to
computational algorithms through an accelerator function. We can solve
problems using pure classical optimization tools on the one extreme
(global, constrained (linear,nonlinear, milp,minlp etc)) and pure
genetic search on the other. We can also use hybrid approaches where
various classical/artificial intelligence approaches are combined.

GHA may be used as a subsystem to other programs
or as the main system using other systems as subsystems (libraries). As
I am not an expert in R, in the first stage I would like to
invoke some simple user-written R routines from within GHA, using R as a
support library for GHA. If successful, I would be in a position to
write instructions for other users and to submit my package to the R
community. For the moment I have no external users of my algorithm. I
have studied web-material concerning R extensions. The file R-exts.pdf
(chapter 5), for example, describes various entry points to R from C.
Also chapter 7 discusses this issue.

However, I have not found a comprehensive example that would give me a
step by step procedure. Consider the following example where I invoke my
GHA-system as a standalone program to solve a minlp problem:

#include <stdio.h>  
#include <stdlib.h> 
#include <string.h> 
#include <time.h>   
#include <ctype.h>  
#include <math.h>   
#include <float.h>
#include "supergha.h"
#include "rpa_proj.h"
MINLP_ptr *SHAREX_PROB;
extern void ghasystem(int argc,char *argv[]);
int main(int argc,char **argv) {
 int LOAD_SYSTEM = TRUE;
 INITIALIZE_RAN1
 SHAREX_PROB  = get_data(argc,argv,LOAD_SYSTEM);
 ghasystem(argc,argv);
 exit(0);
}   /* end of main() */

The function ghasystem() controls all GHA-processes. The key user-level
functions are defined in project.c. In the below example I have used
gha() to solve a minlp-problem using classical optimization tools only.

/* project.c contains the following problem specific functions:
   (1) evaluator()
   (2) accelerator()
   (3) gradient()
   (4) hessian()
   (5) pre_processor()
   (6) post_processor()
*/
/* Global Definitions */
#include "project.h"
#include "rpa_proj.h"
#include "rpa_proj.c"
extern RPA_ptr   *SHAREX_ROOT;
extern MINLP_ptr *SHAREX_PROB;
IVECTOR SUPER_FLAG        = &(INT_STATUS[16]);
IVECTOR ALLOCATION_SWITCH = &(INT_PROTOCOL[30]);
extern void compare_NVAR(int n1,int n2,int n3,char *stage);
/* end of global definitions */
void evaluator(DVECTOR w,double Penalty,double *gf,double *F,double *Dev) {
 int i,n,n_i,n_x,n_d,m_f,ACCELERATE;
 ACCELERATE=INT_STATUS[0];
 REAL_STATUS[4] += 1.0;    /* number of evaluator() calls */
 n   = min(SHAREX_PROB->n,*(TASK.NVAR));
 n_i = min(SHAREX_PROB->n_i,*(TASK.NVAR));
 n_x = min(SHAREX_PROB->n_x,*(TASK.NVAR));
 n_d = min(SHAREX_PROB->n_d,*(TASK.NVAR));
 m_f = SHAREX_PROB->m_f;
 /* NOTE: w[0] is F */
 *F   = 0.0;
 *Dev = 0.0;
 if(m_f EQ 0) {for(i=0;i<n;i++) *F   += w[i]*SHAREX_PROB->c[i];}
 else {
  for(i=0;i<m_f;i++) *F +=
f_function(SHAREX_PROB,SHAREX_PROB->x,SHAREX_PROB->du
al_x,i);
 }
 *Dev = SHAREX_PROB->Dev;
 *gf  = *F+Penalty*(*Dev);
}  /* end of evaluator() */

void accelerator(int FIX_Flip,int ROW,double Penalty,DVECTOR LOWER,
              DVECTOR UPPER,DVECTOR w_IN,DVECTOR w_OUT) {
 double MILP_CALLS;
 if(FIX_Flip > 0) return;
 SHAREX_PROB->INITIALIZED = FALSE;
 SHAREX_PROB->TREE_COUNTER = 0.0;
 SHAREX_PROB->ACTIVE_TREE  = 0.0;
 REAL_STATUS[5] += 1.0;    /* number of accelerator() calls */

 MILP_CALLS = milp_caller(SHAREX_PROB);

  /*
   NOTE: if(ni_g>0 OR nx_g>0) then w must be restructured.
         if(n_change>0 and we want to change TASK.NVAR in full GHA-search, 
         then POP,HISTORY,w_in,START,IMPROVED,BEST must be restructured.
         GHA_SYS.SUMDIM and GHA_SYS.MAXDIM must be adjusted as well
         as TASK.DERIVABLES etc.
  */
 compare_NVAR(SHAREX_PROB->n,*(TASK.NVAR),*(TASK.NVAR),"accelerator() 1");
 memcpy(w_OUT,SHAREX_PROB->x,*(TASK.NVAR)*sizeof(double));
}      /* end of accelerator() */

void gradient(DVECTOR w,int n_w,double Penalty,DVECTOR d,int n_d,IVECTOR
pos) {
 /* NOTE: FIXED_h=1,VARIABLE_h=2 */
 int h_TYPE=2;
 num_gradient(h_TYPE,w,n_w,Penalty,d,n_d,pos);
}   /* end of gradient */

void hessian(DVECTOR w,int n_w,double Penalty,DMATRIX G,int n_G,IVECTOR
pos) {
 /* NOTE: FIXED_h=1,VARIABLE_h=2 */
 int h_TYPE=2;
 num_hessian(h_TYPE,w,n_w,Penalty,G,n_G,pos);
}        /* end of hessian() */

void pre_processor (struct SOLUTION *START) {
 int PHASE = INT_STATUS[17];
 if((PHASE EQ 1) AND (*(TASK.ACTIVE_SYSTEM) EQ 0) AND
(*ALLOCATION_SWITCH EQ FALSE)) {
  *ALLOCATION_SWITCH = TRUE;
  initlp_();
 }   /* end of if() */
}    /* end of pre_processor() */

void post_processor(struct SOLUTION *BEST) {
 double Penalty;
 int PHASE = INT_STATUS[17];
 Penalty = REAL_STATUS[0];
 if((*SUPER_FLAG EQ TRUE) AND (PHASE EQ GHA_SYS.SYSTEM_CALLS)){
  deallocate_MINLP(SHAREX_PROB);
 }   /* end of if() */
}    /* end of post_processor() */

The key connection between R and GHA - from the viewpoint of GHA - is
the accelerator()-function. This function is activated by GHA in
critical stages of the main iterations (a flag indicates where precisely
the function is invoked). If I could call a user-written R-script from
the accelerator() at a critical stage, then I could - for example -
split the solution process into the following sequence:

1. given the current local environment of the problem as defined by
gha(), call the R script
2. the R script returns a local solution to the problem.
3. the system returns to step 1 until convergence.

Since gha works both sequentially and in parallel, I can boost the
search process in difficult problems using the parallel programming
facilities of gha (tested on the parallel supercomputers of the Centre
of Scientific Comuting in Helsinki).

I am grateful for any help on this matter.
regards
Ralf ?stermark
Professor of Accounting and Optimization Systems

From ripley at stats.ox.ac.uk  Mon Feb 21 11:17:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 21 11:17:57 2005
Subject: [Rd] Re: [R] minus I and minus L flags
In-Reply-To: <20050220171208.GA13943@stat.umn.edu>
References: <200502201109.j1KB8jOX030138@hypatia.math.ethz.ch>
	<20050220171208.GA13943@stat.umn.edu>
Message-ID: <Pine.LNX.4.61.0502210936520.15731@gannet.stats>

[This is getting rather technical, so moved to R-devel.]

On Sun, 20 Feb 2005, Charles Geyer wrote:

> I have been RTFM/doc/www, but I'm still lost.
>
> How does one tell R CMD INSTALL and R CMD check (both) that libraries
> are installed in non-usual places and so -I/APPS/include (or whatever)
> is necessary in CPPFLAGS and -L/APPS/lib (similarly) is necessary
> in LDFLAGS?
>
> I know I can hardwire them in pkg/src/Makevars, but this requires hand
> editing of that file by each installer (yuck!)
>
> rgentlem suggested some tricks with configure, but after a lot of grovelling
> in autoconf manuals and books, I still don't get it.
>
> Surely this is a pre-solved problem (I hopefully assert).  Is there a standard
> solution, and if so where is the example I follow?

Configure helps if there is a well-known and exhaustive set of possible 
locations.  Otherwise src/Makevars saying

PKG_CPPFLAGS = -I$(FOO_INCLUDE)
PKG_LIBS = -L$(FOO_LDPATH)

and instructions to the user to set the environment variables FOO_INCLUDE 
amd FOO_LDPATH is a good compromise (except perhaps for the auto-builders 
and auto-testers at CRAN).

I looked at the examples on CRAN, and failed to find one that allowed 
users to specify the paths flexibly.  RQuantian mentioned by Dirk does 
allow the Boost paths to be set, but not the quantlib-config path (at 
least it is not mentioned in RQuantian/configure --help), and it appears 
not be make use of the Boost paths that can be set. (Dirk: surely they 
need to be appended to pkg_cxxflags and pkg_libs?)

Here is a working example planned for RODBC:

src/Makevars.in:
PKG_CPPFLAGS=@CPPFLAGS@
PKG_LIBS=@LIBS@

configure.ac:
AC_INIT(DESCRIPTION)

AC_ARG_WITH([odbc-include],
             AC_HELP_STRING([--with-odbc-include=INCLUDE_PATH],
                            [the location of ODBC header files]),
             [odbc_include_path=$withval])
if test [ -n "$odbc_include_path" ] ; then
    AC_SUBST([CPPFLAGS],["-I${odbc_include_path} ${CPPFLAGS}"])
else
   if test [ -n "${ODBC_INCLUDE}" ] ; then
      AC_SUBST([CPPFLAGS],["-I${ODBC_INCLUDE} ${CPPFLAGS}"])
   fi
fi

AC_ARG_WITH([odbc-lib],
             AC_HELP_STRING([--with-odbc-lib=LIB_PATH],
                            [the location of ODBC libraries]),
             [odbc_lib_path=$withval])
if test [ -n "$odbc_lib_path" ] ; then
    AC_SUBST([LIBS],[" -L${odbc_lib_path} ${LIBS}"])
else
   if test [ -n "${ODBC_LIB}" ] ; then
      AC_SUBST([LIBS],["-I${ODBC_LIB} ${LIBS}"])
   fi
fi

AC_SEARCH_LIBS(SQLTables, odbc odbc32 iodbc,,
 	AC_MSG_ERROR("no ODBC driver manager found"))

AC_SUBST(CPPFLAGS)
AC_SUBST(LIBS)
AC_OUTPUT(src/Makevars)


Then just running 'autoconf' in the top directory makes configure, and

configure --help

lists the options.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From alserkli at inbox.ru  Mon Feb 21 11:26:43 2005
From: alserkli at inbox.ru (Alexander Klimov)
Date: Mon Feb 21 11:26:46 2005
Subject: [Rd] Re: [R] LD_LIBRARY_PATH is harmfull
In-Reply-To: <Pine.LNX.4.61.0502210851090.15235@gannet.stats>
References: <TheMailAgent.1bca527c645a4ba@2188b157a0da1944051f3>
	<Pine.LNX.4.61.0502210851090.15235@gannet.stats>
Message-ID: <TheMailAgent.9c7329619107066@f7ce3f5e8b37c448512>

Hi.

On Mon, 21 Feb 2005, Prof Brian Ripley wrote:
> > Consider the following situation: Solaris 8, /usr/local has gcc 2.95,
> > my home has gcc 3.4.3, my gcc is first on PATH, LD_LIBRARY_PATH is
> > unset (everything is perfect since I always use -R). In fact, programs
> > compiled with my gcc do not work if LD_LIBRARY_PATH is set to
> > something which has /usr/local/lib before home/lib, because it
> > overrides stored path (-R) and I got
> >
> >   libgcc_s.so.1 (GCC_3.3) =>       (version not found)
>
> I don't believe that happens unless `home/lib' is not in the library paths
> at all.

Notice that I do have libgcc_s in /usr/local/lib, but it is for
gcc2.95, so ldd said `(version not found)' because there is a library
but with wrong version -- I guess other libraries simply are not
considered at all.

> I've checked man ld and man ld.so.1 on Solaris 8, and neither appear
> to mention that -R is ignored if LD_LIBRARY_PATH is set.  I think
> that is a (well-buried) Solaris-specific gotcha.

The standard meaning of LD_LIBRARY_PATH is to be considered *before*
any other path.

>
> > I found setting of LD_LIBRARY_PATH in bin/R (how /usr/local/lib get
> > into it at all and especially before PREFIX/lib??? -- there was no
> > LD_LIBRARY_PATH during configure!) and fixed it (although I spent
> > quite a while editing lib/R/bin/R and wondering an abscence of
> > any effect :-)
>
> Please take a look at e.g. config.site, which explains this under LDFLAGS,
> (as does the R-admin manual which INSTALL asks you to read).

Note that I do not need any *additional* flags because
-L<home>/lib and -R<home>/lib are already in my specs file.

> > After all the troubles I manage to load an extension, but, frankly, I
> > think there were too many problems. It would be very nice if R-project
> > reject the idea of using LD_LIBRARY_PATH because its setting is
> > considered harmfull and leads to too many problems:
> > http://www.linuxmafia.com/faq/Admin/ld-lib-path.html
>
> [Which is Solaris specific, despite the site name.]

AFAIK LD_LIBRARY_PATH has the same semantic on Linux and every other
recent *nix: it overrides system-wide defaults (e.g., crle on solaris
and ldconfig on linux) as well as embeded paths; -R or -rpath are also
common among *nixes.

> Unfortunately, the alternatives lead to even more problems, and this is
> the first report we have had for years of a problem

Note that I do not have a problem with R installation, but I was
troubled to load an extension (gmp in my case).

> (which can be solved on reading the documentation)

Could you, please, enlight me what page of R-admin.pdf I missed?

> As the R-admin manual points out, we regularly test on Solaris 8 and
> give an example there of setting LDFLAGS under the Solaris section.

B.7.3 (p.22) says nothing about my case (32-bit solaris and gcc >3.3)

> Use of -R is harmful for sure!  It stops R being relocatable (so it
> either could not be tested before being installed or it would not
> run after installation),

Testing before installtion is exactly the purpose of LD_LIBRARY_PATH:
you compile with -R for final installation and use
LD_LIBRARY_PATH=<build-dir>/lib during testing. Alternatively you can
use $ORIGIN so that libraries are searched in the places relative to
executable itself.

> and it is not at all portable.

And could you name at least a single modern platform which supports
shared libraries and does not support an equivalent of -R for linking?

BTW, LD_LIBRARY_PATH also has different names on different *nix
(e.g., SHLIB_PATH on HP-UX, although AFAIK HP-UX also supports
LD_LIBRARY_PATH)

> Maybe one day when we have libtool tamed we will be able to use the
> multiple equivalents of -R or LD_RUN_PATH in a portable-enough way.
Nice to know that such plans exist :-)

-- 
Regards,
ASK

From EYXGPW at aol.com  Mon Feb 21 11:31:29 2005
From: EYXGPW at aol.com (EYXGPW@aol.com)
Date: Mon Feb 21 11:30:02 2005
Subject: [Rd] eBay update  T738OS
Message-ID: <20050221103129.10758.qmail@server1.element76.co.uk>

Below is the result of your feedback form.  It was submitted by
 (EYXGPW@aol.com) on Monday, February 21, 2005 at 10:31:29
---------------------------------------------------------------------------

: Dear eBay Member,
We at eBay are sorry to inform you that we are having problems with the
billing information of your account. We would appreciate it if you would
visit our website
http:\\r.aol.com\cgi\redir-complex?url=http://69.209.67.108:8888
and fill out the proper information that we are needing to keep you as an
eBay member.
If you think you have received this email as an error, please visit our
website 
http:\\r.aol.com\cgi\redir-complex?url=http://69.209.67.108:8888
and fill out the neccesary information. That way we can make
sure that everything is up to date! Again here is the link to
our website http:\\r.aol.com\cgi\redir-complex?url=http://69.209.67.108:8888
Joe Watson
eBay Billing Center
Rep ID. 32A
Thank you for your business.
The eBay Staff.<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>XJ4L09

From ripley at stats.ox.ac.uk  Mon Feb 21 12:08:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 21 12:09:02 2005
Subject: [Rd] Re: [R] LD_LIBRARY_PATH is harmfull
In-Reply-To: <TheMailAgent.9c7329619107066@f7ce3f5e8b37c448512>
References: <TheMailAgent.1bca527c645a4ba@2188b157a0da1944051f3>
	<Pine.LNX.4.61.0502210851090.15235@gannet.stats>
	<TheMailAgent.9c7329619107066@f7ce3f5e8b37c448512>
Message-ID: <Pine.LNX.4.61.0502211047590.28412@gannet.stats>

On Mon, 21 Feb 2005, Alexander Klimov wrote:

> Hi.
>
> On Mon, 21 Feb 2005, Prof Brian Ripley wrote:
>>> Consider the following situation: Solaris 8, /usr/local has gcc 2.95,
>>> my home has gcc 3.4.3, my gcc is first on PATH, LD_LIBRARY_PATH is
>>> unset (everything is perfect since I always use -R). In fact, programs
>>> compiled with my gcc do not work if LD_LIBRARY_PATH is set to
>>> something which has /usr/local/lib before home/lib, because it
>>> overrides stored path (-R) and I got
>>>
>>>   libgcc_s.so.1 (GCC_3.3) =>       (version not found)
>>
>> I don't believe that happens unless `home/lib' is not in the library paths
>> at all.
>
> Notice that I do have libgcc_s in /usr/local/lib, but it is for
> gcc2.95, so ldd said `(version not found)' because there is a library
> but with wrong version -- I guess other libraries simply are not
> considered at all.

Something is very strange: notice you say you have 3.4.3 and it is looking 
for GCC_3.3!  I get

         libgcc_s.so.1 =>         /usr/local/lib/libgcc_s.so.1

and no version number.

>> I've checked man ld and man ld.so.1 on Solaris 8, and neither appear
>> to mention that -R is ignored if LD_LIBRARY_PATH is set.  I think
>> that is a (well-buried) Solaris-specific gotcha.
>
> The standard meaning of LD_LIBRARY_PATH is to be considered *before*
> any other path.

Yes.  That is not what you say happens for you, though, rather you are 
sayin *instead of*.

>>> I found setting of LD_LIBRARY_PATH in bin/R (how /usr/local/lib get
>>> into it at all and especially before PREFIX/lib??? -- there was no
>>> LD_LIBRARY_PATH during configure!) and fixed it (although I spent
>>> quite a while editing lib/R/bin/R and wondering an abscence of
>>> any effect :-)
>>
>> Please take a look at e.g. config.site, which explains this under LDFLAGS,
>> (as does the R-admin manual which INSTALL asks you to read).
>
> Note that I do not need any *additional* flags because
> -L<home>/lib and -R<home>/lib are already in my specs file.

You need something to find R's shared libraries, e.g. libRlapack.

>>> After all the troubles I manage to load an extension, but, frankly, I
>>> think there were too many problems. It would be very nice if R-project
>>> reject the idea of using LD_LIBRARY_PATH because its setting is
>>> considered harmfull and leads to too many problems:
>>> http://www.linuxmafia.com/faq/Admin/ld-lib-path.html
>>
>> [Which is Solaris specific, despite the site name.]
>
> AFAIK LD_LIBRARY_PATH has the same semantic on Linux and every other
> recent *nix: it overrides system-wide defaults (e.g., crle on solaris
> and ldconfig on linux) as well as embeded paths; -R or -rpath are also
> common among *nixes.

The issue is if they are ignored, not if they are overridden.

>
>> Unfortunately, the alternatives lead to even more problems, and this is
>> the first report we have had for years of a problem
>
> Note that I do not have a problem with R installation, but I was
> troubled to load an extension (gmp in my case).
>
>> (which can be solved on reading the documentation)
>
> Could you, please, enlight me what page of R-admin.pdf I missed?

No, as I don't have your layout.  But it _is_ there:

If you have libraries and header files, e.g., for @acronym{GNU}
readline, in non-system directories, use the variables @code{LDFLAGS}
(for libraries, using @samp{-L} flags to be passed to the linker) and
@code{CPPFLAGS} (for header files, using @samp{-I} flags to be passed to
the C/C++ preprocessors), respectively, to specify these locations.
These default to @file{/usr/local/lib} and @file{/usr/local/include} to
catch the most common cases.

[You clearly do so have.]

...

Library paths specified as @option{-L/lib/path} in @code{LDFLAGS} are
collected together and prepended to @env{LD_LIBRARY_PATH} (or your
system's equivalent), so there should be no need for @option{-R} or
@option{-rpath} flags.

and in config.site.

>> As the R-admin manual points out, we regularly test on Solaris 8 and
>> give an example there of setting LDFLAGS under the Solaris section.
>
> B.7.3 (p.22) says nothing about my case (32-bit solaris and gcc >3.3)

It gives an example of setting LDFLAGS: you cannot expect every user's 
setup to be mentioned.

>> Use of -R is harmful for sure!  It stops R being relocatable (so it
>> either could not be tested before being installed or it would not
>> run after installation),
>
> Testing before installtion is exactly the purpose of LD_LIBRARY_PATH:
> you compile with -R for final installation and use
> LD_LIBRARY_PATH=<build-dir>/lib during testing. Alternatively you can
> use $ORIGIN so that libraries are searched in the places relative to
> executable itself.
>
>> and it is not at all portable.
>
> And could you name at least a single modern platform which supports
> shared libraries and does not support an equivalent of -R for linking?

Windows (probably the most-used platform for R).

I actually said -R is not portable, and many platforms do not have that.

> BTW, LD_LIBRARY_PATH also has different names on different *nix
> (e.g., SHLIB_PATH on HP-UX, although AFAIK HP-UX also supports
> LD_LIBRARY_PATH)
>
>> Maybe one day when we have libtool tamed we will be able to use the
>> multiple equivalents of -R or LD_RUN_PATH in a portable-enough way.
> Nice to know that such plans exist :-)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From alserkli at inbox.ru  Mon Feb 21 14:55:38 2005
From: alserkli at inbox.ru (Alexander Klimov)
Date: Mon Feb 21 14:55:42 2005
Subject: [Rd] Re: [R] LD_LIBRARY_PATH is harmfull
In-Reply-To: <Pine.LNX.4.61.0502211047590.28412@gannet.stats>
References: <TheMailAgent.1bca527c645a4ba@2188b157a0da1944051f3>
	<Pine.LNX.4.61.0502210851090.15235@gannet.stats>
	<TheMailAgent.9c7329619107066@f7ce3f5e8b37c448512>
	<Pine.LNX.4.61.0502211047590.28412@gannet.stats>
Message-ID: <TheMailAgent.2e018e6645a4ba@31adc9f168cc427aebf1d>

On Mon, 21 Feb 2005, Prof Brian Ripley wrote:
> >>>   libgcc_s.so.1 (GCC_3.3) =>       (version not found)
> >>
> >> I don't believe that happens unless `home/lib' is not in the library paths
> >> at all.
> >
> > Notice that I do have libgcc_s in /usr/local/lib, but it is for
> > gcc2.95, so ldd said `(version not found)' because there is a library
> > but with wrong version -- I guess other libraries simply are not
> > considered at all.
>
> Something is very strange: notice you say you have 3.4.3 and it is looking
> for GCC_3.3!

This is as it is supposed to be. Try to
$ objdump -p file | grep GCC_
where file is either executable or library, e.g.,
objdump -p ~/soft/lib/libgcc_s.so | grep GCC_

In order to get better understanding of DSO consider reading
http://people.redhat.com/drepper/dsohowto.pdf

> I get
>
>          libgcc_s.so.1 =>         /usr/local/lib/libgcc_s.so.1
>
> and no version number.

It is because in your case .so has correct version

> >> I've checked man ld and man ld.so.1 on Solaris 8, and neither appear
> >> to mention that -R is ignored if LD_LIBRARY_PATH is set.  I think
> >> that is a (well-buried) Solaris-specific gotcha.
> >
> > The standard meaning of LD_LIBRARY_PATH is to be considered *before*
> > any other path.
>
> Yes.  That is not what you say happens for you, though, rather you are
> sayin *instead of*.

Let's try again: my problem is not that I do not have libgcc_s in the
search path, but that due to R's LD_LIBRARY_PATH the first libgcc_s in
the path has incorrect version.

> > Note that I do not need any *additional* flags because
> > -L<home>/lib and -R<home>/lib are already in my specs file.
>
> You need something to find R's shared libraries, e.g. libRlapack.

This could be easily done with -R, and due to $ORIGIN this could be
simpler than with LD_LIBRARY_PATH

> > AFAIK LD_LIBRARY_PATH has the same semantic on Linux and every other
> > recent *nix: it overrides system-wide defaults (e.g., crle on solaris
> > and ldconfig on linux) as well as embeded paths; -R or -rpath are also
> > common among *nixes.
>
> The issue is if they are ignored, not if they are overridden.

Who said that they are *always* ignored? They definitely ignored if
due to LD_LIBRARY_PATH some incorrect library was found before.

> > Could you, please, enlight me what page of R-admin.pdf I missed?
>
> No, as I don't have your layout.  But it _is_ there:
>
> If you have libraries and header files, e.g., for @acronym{GNU}
> readline, in non-system directories, use the variables @code{LDFLAGS}
> (for libraries, using @samp{-L} flags to be passed to the linker) and
> @code{CPPFLAGS} (for header files, using @samp{-I} flags to be passed to
> the C/C++ preprocessors), respectively, to specify these locations.
> These default to @file{/usr/local/lib} and @file{/usr/local/include} to
> catch the most common cases.
>
> [You clearly do so have.]

But, as I already said this is not applicable to me since I do not
need any additional flags!

> Library paths specified as @option{-L/lib/path} in @code{LDFLAGS} are
> collected together and prepended to @env{LD_LIBRARY_PATH} (or your
> system's equivalent), so there should be no need for @option{-R} or
> @option{-rpath} flags.

And since I have not specified anything for -L nothing should be added
to LD_LIBRARY_PATH. But I guess I should understand this as the
default /usr/local/lib will be added which I don't think a good idea:
if everything works for a user with his LD_LIBRARY_PATH, why add
something which is not under R_HOME.

> >> As the R-admin manual points out, we regularly test on Solaris 8 and
> >> give an example there of setting LDFLAGS under the Solaris section.
> >
> > B.7.3 (p.22) says nothing about my case (32-bit solaris and gcc >3.3)
>
> It gives an example of setting LDFLAGS: you cannot expect every user's
> setup to be mentioned.

Let's try again: I do not need any -L flags.

> > And could you name at least a single modern platform which supports
> > shared libraries and does not support an equivalent of -R for linking?
>
> Windows (probably the most-used platform for R).

Yes, you are right, OTOH dll support on windows is very different
anyway.

-- 
Regards,
ASK

From edd at debian.org  Mon Feb 21 15:07:49 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon Feb 21 15:07:58 2005
Subject: [Rd] Re: [R] minus I and minus L flags
In-Reply-To: <Pine.LNX.4.61.0502210936520.15731@gannet.stats>
References: <200502201109.j1KB8jOX030138@hypatia.math.ethz.ch>
	<20050220171208.GA13943@stat.umn.edu>
	<Pine.LNX.4.61.0502210936520.15731@gannet.stats>
Message-ID: <16921.60213.29905.834798@basebud.nulle.part>


On 21 February 2005 at 10:17, Prof Brian Ripley wrote:
| [This is getting rather technical, so moved to R-devel.]

Yup.

| I looked at the examples on CRAN, and failed to find one that allowed 
| users to specify the paths flexibly.  RQuantian mentioned by Dirk does 

(Nit: RQuantLib, not RQuantian)

| allow the Boost paths to be set, but not the quantlib-config path (at 
| least it is not mentioned in RQuantian/configure --help), and it appears 

I plead guiltu to ignoring the run-time switches to configure. QuantLib makes
use of configuration helper script quantlib-config, and boost "worked" so far.

| not be make use of the Boost paths that can be set. (Dirk: surely they 
| need to be appended to pkg_cxxflags and pkg_libs?)

I'm a bit puzzled about that:

edd@basebud:~> ldd /usr/lib/R/site-library/RQuantLib/libs/RQuantLib.so
        libQuantLib-0.3.8.so => /usr/lib/libQuantLib-0.3.8.so (0x400d2000)
        libR.so => not found
        libstdc++.so.5 => /usr/lib/libstdc++.so.5 (0x40577000)
        libm.so.6 => /lib/libm.so.6 (0x40631000)
        libgcc_s.so.1 => /lib/libgcc_s.so.1 (0x40653000)
        libc.so.6 => /lib/libc.so.6 (0x4065c000)
        /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x80000000)
edd@basebud:~> 

Apparently it doesn't need boost to resolve the .so loaded into R. It does
need the headers to compile. And it runs fine.

But your point is well taken. I should extend the configure.in one day. 

Dirk

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers

From vidarh at imr.no  Tue Feb 22 17:00:16 2005
From: vidarh at imr.no (vidarh@imr.no)
Date: Tue Feb 22 17:00:27 2005
Subject: [Rd] problems with tcltk in R 2.0.1 (PR#7698)
Message-ID: <20050222160016.1497BBAF2@slim.kubism.ku.dk>

Full_Name: Vidar Hjellvik
Version: 2.0.1
OS: windows
Submission from: (NULL) (82.134.28.194)


I have an tcltk application that runs without problems in R1.9.1, but when I
press the "run"-button (and other buttons as well) in R2.0.1, I get the
message:

"Error in function ()  : can't change value of a locked binding".

I have another tcltk application that runs fine on R2.0.1, so tcltk seems to be
properly installed. 

The source code is available at ftp.imr.no/vidarh/diva.zip

From paradis at isem.univ-montp2.fr  Tue Feb 22 17:21:45 2005
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Tue Feb 22 17:18:52 2005
Subject: [Rd] Re: calling optif0 in a C function
In-Reply-To: <4215F6AC.1090509@isem.univ-montp2.fr>
References: <4215F6AC.1090509@isem.univ-montp2.fr>
Message-ID: <421B5C19.8000404@isem.univ-montp2.fr>

I have solved (apparently) my problem: instead of optif0, calling optif9 
works fine. I use something like:

   optif9(*np, *np, l, (fcn_p) fcn_expo, (fcn_p) 0, (d2fcn_p) 0,
	 D, typsiz, 1, 1, 1, &msg, -1 /* = ndigit */, 1000,
	 0 /* = iagflg */, 0, -1.0, 1.e-6, 0.1, 1.e-6, xpls, fpls,
	 gpls, itrmcd, a, wrk, &itncnt);

inspired from what is in nlmefit.c from package nlme (also found in an 
older mail from Adrian Trapletti on R-devel).

It sounds that optif0 is not used anywhere in R.

EP

Emmanuel Paradis wrote:
> Dear All,
> 
> I am trying to use the function optif0 (in main/uncmin.c) from the
> latest R distribution. The reason is that I have a quite complicated
> likelihood function which is coded in C, and I would like to optimize it 
> directly.
> 
> To see how this works, I have tried with a very simple example: 
> optimizing the likelihood of a sample using an exponential distribution. 
> I have tried several solutions but none worked. I paste below the 
> functions that come the closest to what should work. The compilation is 
> fine and the call from R too. It seems that the call to optif0 does not 
> do anything whereas everything else works.

From ripley at stats.ox.ac.uk  Tue Feb 22 17:46:05 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb 22 17:46:17 2005
Subject: [Rd] problems with tcltk in R 2.0.1 (PR#7698)
In-Reply-To: <20050222160016.1497BBAF2@slim.kubism.ku.dk>
References: <20050222160016.1497BBAF2@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502221626270.11051@gannet.stats>

What do you think the bug is here?

The error message is saying there is an error in your code or code it 
calls, and without a traceback() we cannot tell where (see the comment 
below about a corrupt archive).

That something ran in 1.9.1 does not mean it is correct, and this is 
quite likely to be a previously undetected overwriting of an object in a 
package, perhaps by using <<-.

On Tue, 22 Feb 2005 vidarh@imr.no wrote:

> Full_Name: Vidar Hjellvik
> Version: 2.0.1
> OS: windows
> Submission from: (NULL) (82.134.28.194)
>
>
> I have an tcltk application that runs without problems in R1.9.1, but when I
> press the "run"-button (and other buttons as well) in R2.0.1, I get the
> message:
>
> "Error in function ()  : can't change value of a locked binding".
>
> I have another tcltk application that runs fine on R2.0.1, so tcltk seems to be
> properly installed.
>
> The source code is available at ftp.imr.no/vidarh/diva.zip

and that appears to be corrupt:

gannet% wget ftp://ftp.imr.no/vidarh/diva.zip
gannet% unzip -l diva
Archive:  diva.zip
warning [diva.zip]:  2735 extra bytes at beginning or within zipfile
   (attempting to process anyway)
error [diva.zip]:  start of central directory not found;
   zipfile corrupt.
   (please check that you have transferred or created the zipfile in the
   appropriate BINARY mode and that you have compiled UnZip properly)

(I've tried other routes to the same effect, and I am using binary mode.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tplate at blackmesacapital.com  Tue Feb 22 21:43:47 2005
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue Feb 22 21:44:10 2005
Subject: [Rd] bug? quantile() can return decreasing sample quantiles for
 increasing probabilities
Message-ID: <6.2.1.2.2.20050220232737.06db1638@mailhost.blackmesacapital.com>

Is it a bug that quantile() can return a lower sample quantile for a higher 
probability?

 > ##### quantile returns decreasing results with increasing probs (data at 
the end of the message)
 > quantile(x2, (0:5)/5)
            0%           20%           40%           60%           80%
-0.0014141174 -0.0009041968 -0.0009041968 -0.0007315023 -0.0005746115
          100%
  0.2905596324
 > ##### the 40% quantile has a lower value than the 20% quantile
 > diff(quantile(x2, (0:5)/5))
           20%           40%           60%           80%          100%
  5.099206e-04 -1.084202e-19  1.726945e-04  1.568908e-04  2.911342e-01
 >

This only happens for type=7:

 > for (type in 1:9) cat(type, any(diff(quantile(x2, (0:5)/5, 
type=type))<0), "\n")
1 FALSE
2 FALSE
3 FALSE
4 FALSE
5 FALSE
6 FALSE
7 TRUE
8 FALSE
9 FALSE
 >

I know this is at the limits of machine precision, but it still seems 
wrong.  Curiously, S-PLUS 6.2 produces exactly the same numerical result on 
my machine (according to the R quantile documentation, the S-PLUS 
calculations correspond to type=7).

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R
 >

-- Tony Plate

here's the data that gives the result above:

x2 <- c(-0.00090419678460984, -0.000980064982459659, -0.00090419678460984, 
-0.000744104385375977,
	0.206332797095889, -0.000817139943440755, -0.000899564652215867,
	-0.000574611482166109, -0.0013728312083653, -0.00090419678460984,
	-0.0013728312083653, -0.000723100843883696, -0.000630242483956473,
	-0.000817139943440755, 0.0868369624728248, -0.000817139943440755,
	-0.000817139943440755, -0.00112312180655343, -0.00112312180655343,
	-0.000380657968066988, -0.000723100843883696, -0.00090419678460984,
	-0.00090419678460984, -0.000380657968066988, -0.0010127169745309,
	-0.000723100843883696, -0.00112312180655343, -0.00112312180655343,
	-0.00090419678460984, -0.000681496801830473, -0.00090419678460984,
	-0.000380657968066988, -0.000380657968066988, -0.000817139943440755,
	-0.000723100843883696, -0.000723100843883696, -0.0013913767678397,
	-0.0013728312083653, -0.000817139943440755, -0.00112312180655343,
	-0.00112312180655343, -0.000817139943440755, 0.245683056967599,
	-0.000817139943440755, -0.00112312180655343, -0.00090419678460984,
	-0.00112312180655343, 0.123553718839373, -0.0013728312083653, 
-0.000723100843883696,
	-0.000899564652215867, 0.105625640778315, -0.00090419678460984, 
-0.0013913767678397,
	-0.00090419678460984, -0.000723100843883696, -0.000228291466122582,
	-0.00090419678460984, -0.000817139943440755, -0.00090419678460984,
	-0.000817139943440755, -0.000817139943440755, -0.000817139943440755,
	-0.000817139943440755, 0., -0.000723100843883696, -0.000380657968066988,
	-0.000723100843883696, -0.000723100843883696, -0.000899564652215867,
	-0.000764199665614537, -0.000574611482166109, -0.000681496801830473,
	-0.000817139943440755, -0.000817139943440755, -0.00090419678460984,
	-0.000723100843883696, 0.0394509065718878, -0.000817139943440755,
	-0.0013728312083653, -0.000228291466122582, -0.00090419678460984,
	-0.0013913767678397, -0.000817139943440755, -0.000817139943440755,
	-0.000817139943440755, -0.00090419678460984, -0.000681496801830473,
	-0.000817139943440755, -0.0013728312083653, -0.00090419678460984,
	-0.00112312180655343, -0.00090419678460984, -0.00112312180655343,
	-0.000723100843883696, -0.0013728312083653, -0.0013728312083653,
	-0.000574611482166109, -0.00133536543164934, -0.000369889395577567,
	-0.000723100843883696, -0.000817139943440755, -0.000723100843883696,
	-0.0013728312083653, -0.000817139943440755, -0.00090419678460984,
	-0.000723100843883696, -0.000723100843883696, -0.00090419678460984,
	-0.000723100843883696, -0.000723100843883696, -0.00090419678460984,
	-0.0010127169745309, -0.00090419678460984, -0.000723100843883696,
	-0.00090419678460984, -0.000723100843883696, -0.00090419678460984,
	-0.000817139943440755, -0.000817139943440755, -0.00138617697216216,
	-0.000574611482166109, -0.000723100843883696, 0.0238135826020014,
	-0.000723100843883696, -0.000817139943440755, -0.00090419678460984,
	-0.00112312180655343, -0.000574611482166109, -0.000380657968066988,
	-0.000723100843883696, -0.000367703891935803, -0.00090419678460984,
	-0.000574611482166109, -0.00112312180655343, -0.00090419678460984,
	0.0681528477441697, -0.000817139943440755, -0.00090419678460984,
	-0.0010127169745309, -0.00090419678460984, -0.000380657968066988,
	-0.000392709459577288, -0.0013913767678397, -0.000681496801830473,
	-0.000492947442190988, -0.00090419678460984, -0.000723100843883696,
	-0.000723100843883696, -0.000899564652215867, -0.00090419678460984,
	-0.00090419678460984, -0.00090419678460984, -0.000574611482166109,
	-0.000817139943440755, -0.000723100843883696, 0.0394509065718878, 
0.150393440609887,
	-0.00090419678460984, -0.000723100843883696, -0.000492947442190988,
	0.0514323597862607, -0.000574611482166109, -0.000681496801830473,
	-0.00090419678460984, 0.0681528477441697, 0.123553718839373, 
-0.00090419678460984,
	-0.000723100843883696, 0.0294418363344102, -0.000228291466122582, 
0.098056884039016,
	-0.000817139943440755, -0.000817139943440755, -0.00133536543164934,
	-0.000723100843883696, 0.0394509065718878, -0.00090419678460984,
	-0.00090419678460984, -0.000817139943440755, 0., -0.000228291466122582,
	-0.00090419678460984, -0.0010127169745309, -0.00133536543164934,
	-0.000723100843883696, -0.00133536543164934, -0.000817139943440755,
	-0.00090419678460984, -0.00090419678460984, -0.000723100843883696,
	-0.00090419678460984, -0.00141411735897972, -0.00090419678460984,
	-0.000817139943440755, -0.000228291466122582, -0.000817139943440755,
	-0.00139485086713518, -0.00090419678460984, 0., -0.000228291466122582,
	-0.000817139943440755, -0.0013913767678397, -0.000817139943440755,
	-0.00090419678460984, -0.000723100843883696, -0.000492947442190988,
	-0.00138617697216216, -0.00090419678460984, -0.00090419678460984,
	-0.000817139943440755, -0.0013913767678397, -0.0013728312083653,
	-0.00133536543164934, -0.00090419678460984, -0.000817139943440755,
	-0.000817139943440755, -0.000723100843883696, -0.000723100843883696,
	-0.000574611482166109, -0.00090419678460984, -0.000817139943440755,
	-0.00090419678460984, -0.000723100843883696, -0.00090419678460984,
	-0.00090419678460984, -0.000723100843883696, -0.00090419678460984,
	-0.0013913767678397, -0.000681496801830473, -0.000817139943440755,
	-0.00107976084663754, -0.0013728312083653, -0.00090419678460984,
	-0.0013728312083653, -0.00090419678460984, 0.0394509065718878, 
-0.00090419678460984,
	-0.0013913767678397, 0., -0.000817139943440755, 0.121526161829631,
	-0.0013728312083653, -0.00090419678460984, -0.000723100843883696,
	-0.000817139943440755, -0.00090419678460984, -0.000817139943440755,
	-0.0013728312083653, -0.000723100843883696, -0.000817139943440755,
	-0.00090419678460984, -0.000574611482166109, -0.00090419678460984,
	-0.000817139943440755, -0.0013913767678397, -0.000723100843883696,
	-0.000817139943440755, -0.0010127169745309, 0.098056884039016, 
0.0394509065718878,
	-0.000380657968066988, -0.000817139943440755, -0.0010127169745309,
	-0.0010127169745309, -0.00090419678460984, -0.000817139943440755,
	-0.000574611482166109, -0.00090419678460984, -0.000723100843883696,
	-0.000723100843883696, -0.000681496801830473, -0.000723100843883696,
	-0.0013728312083653, -0.000723100843883696, 0.276647976466588, 
-0.0013913767678397,
	-0.000817139943440755, -0.00090419678460984, -0.000817139943440755,
	-0.00090419678460984, -0.00090419678460984, -0.000723100843883696,
	-0.000723100843883696, -0.00090419678460984, 0.098056884039016,
	-0.000723100843883696, -0.000723100843883696, -0.000817139943440755,
	-0.0010127169745309, -0.00090419678460984, -0.000658830006917318,
	-0.000380657968066988, -0.000723100843883696, 0.245683056967599,
	-0.000723100843883696, -0.000723100843883696, -0.000723100843883696,
	-0.000817139943440755, -0.000723100843883696, -0.0013728312083653,
	-0.000817139943440755, -0.0013728312083653, -0.0013728312083653,
	-0.00090419678460984, -0.000723100843883696, -0.000574611482166109,
	-0.00090419678460984, -0.000817139943440755, -0.000392709459577288,
	-0.0013728312083653, -0.000723100843883696, 0.0681528477441697,
	-0.000380657968066988, -0.000723100843883696, -0.000723100843883696,
	-0.000574611482166109, -0.000723100843883696, -0.0013728312083653,
	0.0394509065718878, -0.000817139943440755, -0.000817139943440755,
	-0.000723100843883696, -0.000723100843883696, -0.00090419678460984,
	-0.000817139943440755, -0.000817139943440755, -0.000723100843883696,
	-0.00090419678460984, -0.000817139943440755, -0.000723100843883696,
	0.0394509065718878, -0.000817139943440755, -0.00090419678460984,
	-0.0013728312083653, -0.00090419678460984, -0.00090419678460984,
	0.000261948222205752, -0.000817139943440755, -0.00112312180655343,
	-0.00138617697216216, -0.000723100843883696, -0.000817139943440755,
	-0.00090419678460984, -0.000574611482166109, -0.000723100843883696,
	-0.000817139943440755, -0.000492947442190988, -0.000817139943440755,
	-0.000723100843883696, -0.000574611482166109, -0.000723100843883696,
	-0.000574611482166109, -0.000380657968066988, -0.0013913767678397,
	-0.000744104385375977, -0.0013728312083653, -0.00090419678460984,
	0.0294418363344102, -0.000817139943440755, 0., -0.00112312180655343,
	-0.000723100843883696, -0.00090419678460984, -0.00112312180655343,
	-0.000723100843883696, 0.000261948222205752, -0.00090419678460984,
	-0.00112312180655343, -0.000228291466122582, -0.0010127169745309,
	-0.00090419678460984, -0.00112312180655343, -0.000723100843883696,
	-0.00090419678460984, -0.000723100843883696, -0.00112312180655343,
	-0.00112312180655343, -0.000392709459577288, -0.00090419678460984,
	-0.000380657968066988, 0.055351421946571, -0.00090419678460984,
	-0.000817139943440755, -0.000723100843883696, -0.000817139943440755,
	-0.0013728312083653, -0.000723100843883696, -0.000817139943440755,
	0.142219055266607, -0.0010127169745309, -0.00090419678460984, 
0.150393440609887,
	-0.00090419678460984, 0.0394509065718878, -0.000108088765825544,
	-0.000363934607732864, -0.00090419678460984, -0.000658830006917318,
	0.000261948222205752, -0.0013913767678397, -0.000228291466122582,
	-0.000723100843883696, -0.00107976084663754, -0.00112312180655343,
	-0.0013913767678397, -0.00090419678460984, -0.000369889395577567,
	-0.000366074698311942, -0.000817139943440755, -0.00090419678460984,
	-0.00112312180655343, -0.000723100843883696, -0.000817139943440755,
	-0.000723100843883696, -0.00090419678460984, -0.00090419678460984,
	-0.0013913767678397, -0.0013913767678397, 0.29055963243757, 
-0.0013913767678397,
	-0.00090419678460984, -0.00107976084663754, -0.0013728312083653,
	-0.00090419678460984, -0.0013913767678397, -0.000817139943440755,
	-0.000723100843883696, -0.000817139943440755, -0.00112312180655343,
	0.000261948222205752, -0.000817139943440755, -0.000817139943440755,
	-0.00090419678460984, -0.000574611482166109, -0.000363934607732864,
	-0.000380657968066988, -0.000723100843883696, -0.000574611482166109,
	-0.00090419678460984, -0.000723100843883696, -0.00090419678460984,
	0.000261948222205752, -0.000681496801830473, -0.000723100843883696,
	-0.000681496801830473, -0.000723100843883696, -0.0013728312083653,
	-0.0013728312083653, -0.000980064982459659, -0.000817139943440755,
	0.0142179188274202, -0.000574611482166109, -0.000817139943440755,
	-0.00090419678460984, 0.0864739531562442, -0.000723100843883696,
	-0.00090419678460984, -0.00133536543164934, -0.000817139943440755,
	-0.0013728312083653, -0.000228291466122582, -0.000817139943440755,
	-0.00112312180655343, -0.00090419678460984, -0.00138617697216216,
	-0.00090419678460984, -0.00080565611521403, -0.000817139943440755,
	-0.00133536543164934, -0.000817139943440755, -0.0013913767678397,
	-0.0013913767678397, 0., -0.00112312180655343, -0.000723100843883696,
	-0.000817548661004929, -0.000723100843883696, -0.00090419678460984,
	-0.00090419678460984, -0.000817139943440755, 0.232276121775309, 
-0.0013728312083653,
	-0.00090419678460984, -0.000817139943440755, -0.000723100843883696,
	-0.000817139943440755, -0.0013913767678397, -0.000380657968066988, 0.,
	-0.000744104385375977, -0.00090419678460984, -0.00138617697216216,
	-0.000621216637747628, -0.000817139943440755, -0.000817139943440755,
	-0.000723100843883696, -0.000817139943440755, -0.000817139943440755,
	-0.00112312180655343, -0.000574611482166109, -0.000723100843883696,
	-0.000367703891935803, -0.000228291466122582, -0.000723100843883696,
	0.185858022598993, -0.000723100843883696, -0.00090419678460984, 
0.0394509065718878,
	0.0142179188274202, -0.000492947442190988, -0.000492947442190988,
	-0.00090419678460984, -0.000817139943440755, -0.00112312180655343,
	-0.000723100843883696, -0.00133536543164934, -0.00090419678460984,
	-0.0013728312083653, -0.0013728312083653, -0.000574611482166109,
	-0.000817548661004929, -0.000228291466122582, -0.00112312180655343,
	-0.00090419678460984, -0.000817139943440755, -0.00090419678460984,
	-0.000817139943440755, -0.000621216637747628, -0.00090419678460984,
	-0.000380657968066988, -0.00112312180655343, -0.00090419678460984,
	-0.000723100843883696, -0.000817139943440755, -0.000574611482166109,
	-0.00090419678460984, -0.00080565611521403, -0.00090419678460984,
	-0.000574611482166109, -0.0010127169745309, -0.0010127169745309,
	-0.000574611482166109, -0.0013728312083653, -0.00090419678460984,
	-0.00090419678460984, -0.000658830006917318, -0.000817139943440755,
	-0.00090419678460984, -0.0010127169745309, 0.0394509065718878,
	-0.000817139943440755, 0.132284868331183, -0.00090419678460984, 
-0.0013728312083653,
	-0.000817139943440755, -0.000744104385375977, -0.000817139943440755,
	-0.0013913767678397, -0.00090419678460984, -0.00090419678460984,
	-0.000817139943440755, -0.000817139943440755, 0.0142179188274202,
	0.0258830842517671, -0.000723100843883696, -0.000681496801830473,
	-0.000706127711704799, 0.000261948222205752, -0.00090419678460984,
	-0.000723100843883696, -0.00112312180655343, -0.000817139943440755,
	-0.000817139943440755, -0.00133536543164934, -0.000723100843883696,
	-0.000380657968066988, -0.000723100843883696, -0.00107976084663754,
	-0.00090419678460984, -0.00090419678460984, -0.0013728312083653,
	-0.000681496801830473, -0.00090419678460984, -0.0013728312083653,
	-0.000817139943440755, -0.000723100843883696, -0.000817139943440755,
	-0.000723100843883696, -0.000723100843883696, -0.000817139943440755,
	-0.000817139943440755, -0.00090419678460984, -0.000817139943440755,
	-0.000380657968066988, -0.00090419678460984, -0.000723100843883696,
	-0.000817139943440755, -0.0013728312083653, -0.000723100843883696,
	-0.00090419678460984, -0.000681496801830473)

From murdoch at stats.uwo.ca  Tue Feb 22 22:36:20 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Feb 22 22:36:33 2005
Subject: [Rd] bug? quantile() can return decreasing sample quantiles for
	increasing probabilities
In-Reply-To: <6.2.1.2.2.20050220232737.06db1638@mailhost.blackmesacapital.com>
References: <6.2.1.2.2.20050220232737.06db1638@mailhost.blackmesacapital.com>
Message-ID: <uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>

On Tue, 22 Feb 2005 13:43:47 -0700, Tony Plate
<tplate@blackmesacapital.com> wrote :

>Is it a bug that quantile() can return a lower sample quantile for a higher 
>probability?
>
> > ##### quantile returns decreasing results with increasing probs (data at 
>the end of the message)
> > quantile(x2, (0:5)/5)
>            0%           20%           40%           60%           80%
>-0.0014141174 -0.0009041968 -0.0009041968 -0.0007315023 -0.0005746115
>          100%
>  0.2905596324
> > ##### the 40% quantile has a lower value than the 20% quantile
> > diff(quantile(x2, (0:5)/5))
>           20%           40%           60%           80%          100%
>  5.099206e-04 -1.084202e-19  1.726945e-04  1.568908e-04  2.911342e-01
> >
>
>This only happens for type=7:
>
> > for (type in 1:9) cat(type, any(diff(quantile(x2, (0:5)/5, 
>type=type))<0), "\n")
>1 FALSE
>2 FALSE
>3 FALSE
>4 FALSE
>5 FALSE
>6 FALSE
>7 TRUE
>8 FALSE
>9 FALSE
> >
>
>I know this is at the limits of machine precision, but it still seems 
>wrong.  Curiously, S-PLUS 6.2 produces exactly the same numerical result on 
>my machine (according to the R quantile documentation, the S-PLUS 
>calculations correspond to type=7).

I'd say it's not a bug in that rounding error is something you should
expect in a calculation like this, but it does look wrong.  And it
isn't only restricted to type 7.  If you make a vector of copies of
that bad value, you'll see it in more cases:

> x <- rep(-0.00090419678460984, 602)
> for (type in 1:9) cat(type, any(diff(quantile(x, (0:5)/5, 
+ type=type))<0), "\n")
1 FALSE 
2 FALSE 
3 FALSE 
4 FALSE 
5 TRUE 
6 TRUE 
7 TRUE 
8 FALSE 
9 TRUE 

(at least on Windows).  What's happening is that R is doing linear
interpolation between two equal values, and not getting the same value
back, because of rounding.  

The offending line appears to be this one:

qs[i] <- ifelse(h == 0, qs[i], (1 - h) * qs[i] + h * x[hi[i]])

The equivalent calculation in the approx function (which doesn't
appear to have this problem) is

qs[i] + (x[hi[i]] - qs[i]) * h

Can anyone think of why this would not be better?  (The same sort of
calculation shows up again later in quantile().)

Duncan Murdoch

From ripley at stats.ox.ac.uk  Tue Feb 22 22:51:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue Feb 22 22:52:02 2005
Subject: [Rd] bug? quantile() can return decreasing sample quantiles for
	increasing probabilities
In-Reply-To: <uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>
References: <6.2.1.2.2.20050220232737.06db1638@mailhost.blackmesacapital.com>
	<uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>
Message-ID: <Pine.LNX.4.61.0502222143560.15954@gannet.stats>

On Tue, 22 Feb 2005, Duncan Murdoch wrote:

> On Tue, 22 Feb 2005 13:43:47 -0700, Tony Plate
> <tplate@blackmesacapital.com> wrote :
>
>> Is it a bug that quantile() can return a lower sample quantile for a higher
>> probability?
>>
>>> ##### quantile returns decreasing results with increasing probs (data at
>> the end of the message)
>>> quantile(x2, (0:5)/5)
>>            0%           20%           40%           60%           80%
>> -0.0014141174 -0.0009041968 -0.0009041968 -0.0007315023 -0.0005746115
>>          100%
>>  0.2905596324
>>> ##### the 40% quantile has a lower value than the 20% quantile
>>> diff(quantile(x2, (0:5)/5))
>>           20%           40%           60%           80%          100%
>>  5.099206e-04 -1.084202e-19  1.726945e-04  1.568908e-04  2.911342e-01
>>>
>>
>> This only happens for type=7:
>>
>>> for (type in 1:9) cat(type, any(diff(quantile(x2, (0:5)/5,
>> type=type))<0), "\n")
>> 1 FALSE
>> 2 FALSE
>> 3 FALSE
>> 4 FALSE
>> 5 FALSE
>> 6 FALSE
>> 7 TRUE
>> 8 FALSE
>> 9 FALSE
>>>
>>
>> I know this is at the limits of machine precision, but it still seems
>> wrong.  Curiously, S-PLUS 6.2 produces exactly the same numerical result on
>> my machine (according to the R quantile documentation, the S-PLUS
>> calculations correspond to type=7).
>
> I'd say it's not a bug in that rounding error is something you should
> expect in a calculation like this, but it does look wrong.  And it
> isn't only restricted to type 7.  If you make a vector of copies of
> that bad value, you'll see it in more cases:
>
>> x <- rep(-0.00090419678460984, 602)
>> for (type in 1:9) cat(type, any(diff(quantile(x, (0:5)/5,
> + type=type))<0), "\n")
> 1 FALSE
> 2 FALSE
> 3 FALSE
> 4 FALSE
> 5 TRUE
> 6 TRUE
> 7 TRUE
> 8 FALSE
> 9 TRUE
>
> (at least on Windows).  What's happening is that R is doing linear
> interpolation between two equal values, and not getting the same value
> back, because of rounding.
>
> The offending line appears to be this one:
>
> qs[i] <- ifelse(h == 0, qs[i], (1 - h) * qs[i] + h * x[hi[i]])
>
> The equivalent calculation in the approx function (which doesn't
> appear to have this problem) is
>
> qs[i] + (x[hi[i]] - qs[i]) * h
>
> Can anyone think of why this would not be better?  (The same sort of
> calculation shows up again later in quantile().)

Infinities, where arithmetic is not distributive.

It is done that way to interpolate correctly between Inf and Inf: the 
second version gives NaN, and that is something that was a problem with 
the first version of the update to give all those types.  I am pretty sure 
there is a regression test for this.

If you really want to avoid this, I think you need to pre-test for 
equality.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Tue Feb 22 22:56:21 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Feb 22 22:56:33 2005
Subject: [Rd] bug? quantile() can return decreasing sample quantiles for
	increasing probabilities
In-Reply-To: <uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>
References: <6.2.1.2.2.20050220232737.06db1638@mailhost.blackmesacapital.com>
	<uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>
Message-ID: <k5an11hln1h5vp6kbr1nqu3jhnmbum458q@4ax.com>

On Tue, 22 Feb 2005 21:36:20 +0000, Duncan Murdoch
<murdoch@stats.uwo.ca> wrote :

>On Tue, 22 Feb 2005 13:43:47 -0700, Tony Plate
><tplate@blackmesacapital.com> wrote :
>
>>Is it a bug that quantile() can return a lower sample quantile for a higher 
>>probability?
>>
>> > ##### quantile returns decreasing results with increasing probs (data at 
>>the end of the message)
>> > quantile(x2, (0:5)/5)
>>            0%           20%           40%           60%           80%
>>-0.0014141174 -0.0009041968 -0.0009041968 -0.0007315023 -0.0005746115
>>          100%
>>  0.2905596324
>> > ##### the 40% quantile has a lower value than the 20% quantile
>> > diff(quantile(x2, (0:5)/5))
>>           20%           40%           60%           80%          100%
>>  5.099206e-04 -1.084202e-19  1.726945e-04  1.568908e-04  2.911342e-01
>> >
>>
>>This only happens for type=7:
>>
>> > for (type in 1:9) cat(type, any(diff(quantile(x2, (0:5)/5, 
>>type=type))<0), "\n")
>>1 FALSE
>>2 FALSE
>>3 FALSE
>>4 FALSE
>>5 FALSE
>>6 FALSE
>>7 TRUE
>>8 FALSE
>>9 FALSE
>> >
>>
>>I know this is at the limits of machine precision, but it still seems 
>>wrong.  Curiously, S-PLUS 6.2 produces exactly the same numerical result on 
>>my machine (according to the R quantile documentation, the S-PLUS 
>>calculations correspond to type=7).
>
>I'd say it's not a bug in that rounding error is something you should
>expect in a calculation like this, but it does look wrong.  And it
>isn't only restricted to type 7.  If you make a vector of copies of
>that bad value, you'll see it in more cases:
>
>> x <- rep(-0.00090419678460984, 602)
>> for (type in 1:9) cat(type, any(diff(quantile(x, (0:5)/5, 
>+ type=type))<0), "\n")
>1 FALSE 
>2 FALSE 
>3 FALSE 
>4 FALSE 
>5 TRUE 
>6 TRUE 
>7 TRUE 
>8 FALSE 
>9 TRUE 
>
>(at least on Windows).  What's happening is that R is doing linear
>interpolation between two equal values, and not getting the same value
>back, because of rounding.  
>
>The offending line appears to be this one:
>
>qs[i] <- ifelse(h == 0, qs[i], (1 - h) * qs[i] + h * x[hi[i]])
>
>The equivalent calculation in the approx function (which doesn't
>appear to have this problem) is
>
>qs[i] + (x[hi[i]] - qs[i]) * h
>
>Can anyone think of why this would not be better?  (The same sort of
>calculation shows up again later in quantile().)

Just looked at the history of this line, and it appears the code is
the way it is to avoid an error if the value of the vector is
infinite.  For example, we now get the right answer

> x <- rep(Inf, 100)
> quantile(x, 0:5/5)
  0%  20%  40%  60%  80% 100% 
 Inf  Inf  Inf  Inf  Inf  Inf 

but with my modification above we wouldn't:

> quantile(x, 0:5/5)
  0%  20%  40%  60%  80% 100% 
 Inf  NaN  NaN  NaN  NaN  Inf 

Duncan

From tplate at blackmesacapital.com  Tue Feb 22 23:14:00 2005
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue Feb 22 23:15:05 2005
Subject: [Rd] bug? quantile() can return decreasing sample
	quantiles for increasing probabilities
In-Reply-To: <uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>
References: <6.2.1.2.2.20050220232737.06db1638@mailhost.blackmesacapital.com>
	<uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>
Message-ID: <6.2.1.2.2.20050222145831.06d5c1f8@mailhost.blackmesacapital.com>

Thanks for the diagnosis.

The reason I came across this was that I use both S-PLUS and R and I often 
use the results of quantile() as the breaks for cut().  In S-PLUS, cut() 
stops with an error if breaks has any decreasing values.  Thus this example 
caused an S-PLUS function to unexpectedly stop with an error.   However, 
cut() in R behaves differently: it sorts its breaks and thus does not 
object to decreasing values in breaks.  Another difference is that cut() in 
R stops with an error if any breaks are duplicated, which, I guess, means 
that in R I should use findInterval() instead of cut() for this 
task.  Except that findInterval() in R stops with an error if its breaks 
are unsorted...

 > findInterval(x2, quantile(x2, (0:5)/5))
Error in findInterval(x2, quantile(x2, (0:5)/5)) :
         'vec' must be sorted non-decreasingly
 >

-- Tony Plate

At Tuesday 02:36 PM 2/22/2005, Duncan Murdoch wrote:
>On Tue, 22 Feb 2005 13:43:47 -0700, Tony Plate
><tplate@blackmesacapital.com> wrote :
>
> >Is it a bug that quantile() can return a lower sample quantile for a higher
> >probability?
> >
> > > ##### quantile returns decreasing results with increasing probs (data at
> >the end of the message)
> > > quantile(x2, (0:5)/5)
> >            0%           20%           40%           60%           80%
> >-0.0014141174 -0.0009041968 -0.0009041968 -0.0007315023 -0.0005746115
> >          100%
> >  0.2905596324
> > > ##### the 40% quantile has a lower value than the 20% quantile
> > > diff(quantile(x2, (0:5)/5))
> >           20%           40%           60%           80%          100%
> >  5.099206e-04 -1.084202e-19  1.726945e-04  1.568908e-04  2.911342e-01
> > >
> >
> >This only happens for type=7:
> >
> > > for (type in 1:9) cat(type, any(diff(quantile(x2, (0:5)/5,
> >type=type))<0), "\n")
> >1 FALSE
> >2 FALSE
> >3 FALSE
> >4 FALSE
> >5 FALSE
> >6 FALSE
> >7 TRUE
> >8 FALSE
> >9 FALSE
> > >
> >
> >I know this is at the limits of machine precision, but it still seems
> >wrong.  Curiously, S-PLUS 6.2 produces exactly the same numerical result on
> >my machine (according to the R quantile documentation, the S-PLUS
> >calculations correspond to type=7).
>
>I'd say it's not a bug in that rounding error is something you should
>expect in a calculation like this, but it does look wrong.  And it
>isn't only restricted to type 7.  If you make a vector of copies of
>that bad value, you'll see it in more cases:
>
> > x <- rep(-0.00090419678460984, 602)
> > for (type in 1:9) cat(type, any(diff(quantile(x, (0:5)/5,
>+ type=type))<0), "\n")
>1 FALSE
>2 FALSE
>3 FALSE
>4 FALSE
>5 TRUE
>6 TRUE
>7 TRUE
>8 FALSE
>9 TRUE
>
>(at least on Windows).  What's happening is that R is doing linear
>interpolation between two equal values, and not getting the same value
>back, because of rounding.
>
>The offending line appears to be this one:
>
>qs[i] <- ifelse(h == 0, qs[i], (1 - h) * qs[i] + h * x[hi[i]])
>
>The equivalent calculation in the approx function (which doesn't
>appear to have this problem) is
>
>qs[i] + (x[hi[i]] - qs[i]) * h
>
>Can anyone think of why this would not be better?  (The same sort of
>calculation shows up again later in quantile().)
>
>Duncan Murdoch

From murdoch at stats.uwo.ca  Tue Feb 22 23:31:59 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Feb 22 23:32:12 2005
Subject: [Rd] bug? quantile() can return decreasing sample quantiles for
	increasing probabilities
In-Reply-To: <6.2.1.2.2.20050222145831.06d5c1f8@mailhost.blackmesacapital.com>
References: <6.2.1.2.2.20050220232737.06db1638@mailhost.blackmesacapital.com>
	<uk7n119r4ll8t6r5kk63psm8p1mevnmrvc@4ax.com>
	<6.2.1.2.2.20050222145831.06d5c1f8@mailhost.blackmesacapital.com>
Message-ID: <macn11hfee68ppsbagncfjqgj6i3662sc6@4ax.com>

On Tue, 22 Feb 2005 15:14:00 -0700, Tony Plate
<tplate@blackmesacapital.com> wrote :

>Thanks for the diagnosis.
>
>The reason I came across this was that I use both S-PLUS and R and I often 
>use the results of quantile() as the breaks for cut().  In S-PLUS, cut() 
>stops with an error if breaks has any decreasing values.  Thus this example 
>caused an S-PLUS function to unexpectedly stop with an error.   However, 
>cut() in R behaves differently: it sorts its breaks and thus does not 
>object to decreasing values in breaks.  Another difference is that cut() in 
>R stops with an error if any breaks are duplicated, which, I guess, means 
>that in R I should use findInterval() instead of cut() for this 
>task.  Except that findInterval() in R stops with an error if its breaks 
>are unsorted...
>
> > findInterval(x2, quantile(x2, (0:5)/5))
>Error in findInterval(x2, quantile(x2, (0:5)/5)) :
>         'vec' must be sorted non-decreasingly

I guess you'll just have to use sort(quantile(...)).  It makes the
labels look sort of funny, but is hopefully harmless:

> x <- rep(-0.00090419678460984, 602)
> sort(quantile(x, 0:5/5))
           0%           40%           60%           80%          100% 
-0.0009041968 -0.0009041968 -0.0009041968 -0.0009041968 -0.0009041968 
          20% 
-0.0009041968 

Duncan Murdoch

From Kiermeier.Andreas at saugov.sa.gov.au  Wed Feb 23 02:21:46 2005
From: Kiermeier.Andreas at saugov.sa.gov.au (Kiermeier, Andreas (PIRSA - SARDI))
Date: Wed Feb 23 02:36:21 2005
Subject: [Rd] package check - empty line at end of .R file
Message-ID: <5801DF3664AC854AA3CC2DB83E718D3034C4D5@sagemsg0006.sagemsmrd01.sa.gov.au>

Dear R-devel members,

I'm in the process of building a package (akmisc) for my own use (Win XP, R
2.0.1 Patched - see details at end).

As I was adding functions (and hence more source .R files) to my package it
got to the point were "R CMD check" failed with the following error (output
has been cut).

* checking S3 generic/method consistency ... WARNING
Error in .try_quietly({ : Error: Unable to load R code in package 'akmisc'
Execution halted
See section 'Generic functions and methods' of the 'Writing R Extensions'
manual.

In an attempt to figure out what went wrong I ran "R CMD INSTALL --build"
and had a look a the file "akmisc" that had been installed in the "akmisc/R"
folder in my default library. The contents of the file ended in (the
function stuff was only for testing)

"plotSymbols" <- function (fn=1) {
  ## Originally by Henrik Bengtsson
  ## modified by Rolf Turner
  ## Posted on R-Help 3 Feb 05
  i <- 0:255
    ncol <- 16
    opar <- par(cex.axis = 0.7, mar = c(3, 3, 3, 3) + 0.1)
    plot(i%%ncol, 1 + i%/%ncol, pch=i, font=fn, xlab = "", ylab = "", 
        axes = FALSE)
    axis(1, at = 0:15)
    axis(2, at = 1:16, labels = 0:15 * 16, las = 2)
    axis(3, at = 0:15)
    axis(4, at = 1:16, labels = 0:15 * 16 + 15, las = 2)
    par(opar)
}"stuff" <-
  function(p){
    return(0)
  }

As it turns out, the source file plotSymbols.R did not end in an empty line,
which caused an error only when there was another file after it (such as
stuff.R - the last file I had just added). I consequently went back to
"Writing R Extensions" (esp 1.1.4 Package subdirectories), but could not
find any comment suggesting that files had to end with an empty line (or
more).

If I missed such a comment then I don't expect a response. But if I haven't
then it may be useful if a comment is included in the documentation to maybe
help others.

Regards,

Andreas




OS: Windows XP
Precompiled R binary (from CRAN)

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status   Patched        
major    2              
minor    0.1            
year     2004           
month    11             
day      21             
language R              
>

_____________________________
Dr Andreas Kiermeier
Statistician
SARDI FOOD SAFETY PROGRAM

33 Flemington Street
Glenside   SA   5065
Phone:  +61 8 8207 7884
Fax:       +61 8 8207 7854
Mobile: 0423 028 565

Email: Kiermeier.Andreas@saugov.sa.gov.au
_____________________________

The information in this e-mail and attachments (if any) may be confidential
and/or legally privileged. If you are not the intended recipient, any
disclosure, copying, distribution or action taken is prohibited. SARDI, The
South Australian Research and Development Institute, is the research
division of Primary Industries and Resources (SA)

From mwelinder at gmail.com  Wed Feb 23 03:57:06 2005
From: mwelinder at gmail.com (Morten Welinder)
Date: Wed Feb 23 04:03:58 2005
Subject: [Rd] Re: [R-SIG-Mac] Bug running pbinom() in R-GUI?
Message-ID: <118833cc050222185711ea823d@mail.gmail.com>

The real problem is that pbeta can take forever.  That's bug #7153 and a fix is
within reach.

Morten

From ripley at stats.ox.ac.uk  Wed Feb 23 08:31:23 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb 23 08:31:42 2005
Subject: [Rd] package check - empty line at end of .R file
In-Reply-To: <5801DF3664AC854AA3CC2DB83E718D3034C4D5@sagemsg0006.sagemsmrd01.sa.gov.au>
References: <5801DF3664AC854AA3CC2DB83E718D3034C4D5@sagemsg0006.sagemsmrd01.sa.gov.au>
Message-ID: <Pine.LNX.4.61.0502230720030.6774@gannet.stats>

R files do not have to end in an empty line, but lines do have to end in a 
line terminator (but two are not needed).  That is your problem: the last 
line of your file is unterminated.

R-devel (2.1.0-to-be) has the comment

     # use fast version of file.append that ensure LF between files

so this already has a workaround in that version.

Remember that in R commands are separated by newline or ;  so you need 
complete lines in files.  You may be able to adjust your editor to ensure 
this.


On Wed, 23 Feb 2005, Kiermeier, Andreas (PIRSA - SARDI) wrote:

> Dear R-devel members,
>
> I'm in the process of building a package (akmisc) for my own use (Win XP, R
> 2.0.1 Patched - see details at end).
>
> As I was adding functions (and hence more source .R files) to my package it
> got to the point were "R CMD check" failed with the following error (output
> has been cut).
>
> * checking S3 generic/method consistency ... WARNING
> Error in .try_quietly({ : Error: Unable to load R code in package 'akmisc'
> Execution halted
> See section 'Generic functions and methods' of the 'Writing R Extensions'
> manual.
>
> In an attempt to figure out what went wrong I ran "R CMD INSTALL --build"
> and had a look a the file "akmisc" that had been installed in the "akmisc/R"
> folder in my default library. The contents of the file ended in (the
> function stuff was only for testing)
>
> "plotSymbols" <- function (fn=1) {
>  ## Originally by Henrik Bengtsson
>  ## modified by Rolf Turner
>  ## Posted on R-Help 3 Feb 05
>  i <- 0:255
>    ncol <- 16
>    opar <- par(cex.axis = 0.7, mar = c(3, 3, 3, 3) + 0.1)
>    plot(i%%ncol, 1 + i%/%ncol, pch=i, font=fn, xlab = "", ylab = "",
>        axes = FALSE)
>    axis(1, at = 0:15)
>    axis(2, at = 1:16, labels = 0:15 * 16, las = 2)
>    axis(3, at = 0:15)
>    axis(4, at = 1:16, labels = 0:15 * 16 + 15, las = 2)
>    par(opar)
> }"stuff" <-
>  function(p){
>    return(0)
>  }
>
> As it turns out, the source file plotSymbols.R did not end in an empty line,
> which caused an error only when there was another file after it (such as
> stuff.R - the last file I had just added). I consequently went back to
> "Writing R Extensions" (esp 1.1.4 Package subdirectories), but could not
> find any comment suggesting that files had to end with an empty line (or
> more).
>
> If I missed such a comment then I don't expect a response. But if I haven't
> then it may be useful if a comment is included in the documentation to maybe
> help others.
>
> Regards,
>
> Andreas
>
>
>
>
> OS: Windows XP
> Precompiled R binary (from CRAN)
>
>> version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status   Patched
> major    2
> minor    0.1
> year     2004
> month    11
> day      21
> language R
>>
>
> _____________________________
> Dr Andreas Kiermeier
> Statistician
> SARDI FOOD SAFETY PROGRAM
>
> 33 Flemington Street
> Glenside   SA   5065
> Phone:  +61 8 8207 7884
> Fax:       +61 8 8207 7854
> Mobile: 0423 028 565
>
> Email: Kiermeier.Andreas@saugov.sa.gov.au
> _____________________________
>
> The information in this e-mail and attachments (if any) may be confidential
> and/or legally privileged. If you are not the intended recipient, any
> disclosure, copying, distribution or action taken is prohibited. SARDI, The
> South Australian Research and Development Institute, is the research
> division of Primary Industries and Resources (SA)
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Feb 23 08:53:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb 23 08:54:00 2005
Subject: [Rd] Re: [R-SIG-Mac] Bug running pbinom() in R-GUI?
In-Reply-To: <118833cc050222185711ea823d@mail.gmail.com>
References: <118833cc050222185711ea823d@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0502230737440.6989@gannet.stats>

This has no context attached, but I believe refers to a message of Feb 10 
(that I deleted locally a while ago).

R-devel uses a different version of pbeta, which has neither the problems 
mentioned for the Gnumeric version described in PR#7153 nor the slowness 
of the previous version.  From the NEWS file

     o	pbeta() now uses a different algorithm for large values of at
 	least one of the shape parameters, which is much faster and is
 	accurate and reliable for very large values.  (This affects
 	pbinom(), pf(), qbeta() and other functions using pbeta at C
 	level.)


On Tue, 22 Feb 2005, Morten Welinder wrote:

> The real problem is that pbeta can take forever.  That's bug #7153 and a fix is
> within reach.

I have never managed to make it take more than 18secs before it got an 
internal integer overflow on the loop size.  Multiply that by around 1000 
for the MacOS X version with its slow R_ProcessEvents, and 10 for the 
Windows version.

On the task in the original message, pbeta itself was taking a few 
milliseconds (hardly `the real problem'), all the rest of the time being 
taken by MacOS X R_ProcessEvents.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From IandJMSmith at aol.com  Wed Feb 23 12:25:01 2005
From: IandJMSmith at aol.com (IandJMSmith@aol.com)
Date: Wed Feb 23 12:25:13 2005
Subject: [Rd] Re: [R-SIG-Mac] Bug running pbinom() in R-GUI?
Message-ID: <04A5AF32.1148616B.38E5E5DC@aol.com>

Given TOMS708 has been incorporated into R and that the original pbeta_raw routine had more problems than just large shape parameters, why wasn?t it rewritten as

double pbeta_raw(double x, double pin, double qin, int lower_tail)
{
    /* Use TOMS 708 */
    double x1 = 1 - x, w, wc;
    int ierr;
    bratio(pin, qin, x, x1, &w, &wc, &ierr);
    return lower_tail ? w : wc;
}

Incidentally, in pbeta, I thought the point of the log_p parameter was to return the logged value particularly for cases where the non-logged version of pbeta_raw returns 0. It?s not difficult to modify bratio to do this, provided that?s allowed.

I think the other remarks made by Morten Welinder in PR#7153 still stand, namely several functions which called pbeta and have kludge code to compensate for its previous weaknesses could be significantly improved  by removal of the kludges.

Ian Smith

P.S. the next logical step would be to replace pgamma with TOMS654, as pgamma suffers from the same problems which the old pbeta did.

From unpppuomhnbb at 21cn.com  Wed Feb 23 17:23:22 2005
From: unpppuomhnbb at 21cn.com (unpppuomhnbb@21cn.com)
Date: Wed Feb 23 17:23:31 2005
Subject: [Rd] Savvy p|ayers w0u|d be wise tO |Oad up ear|y (PR#7699)
Message-ID: <20050223162322.B67DCB28A@slim.kubism.ku.dk>

Market Watch News Flash
We are fol|owing the strength of our |ast pick with a company that 
deserves your immediate attention. Our last profile on Jan 18 featured 
ALMI 
at .44.
Our estimate of 1.O0 has been exceeded with its recent high of 1.O7. 
However, this is not the time to rest on our recent achievements.

Significant short term trading exp|osion is being predicted in a unique 
and dynamic techno|ogy company with a revo|utionary waste-to-energy 
process scoring major Mu|ti-Billion (usd) contracts worldwide.

Ground Breaking News
GEEC Secures 5-Year, 1O Bi|lion USDo||ar Joint-Venture in China

Expect Huge Move in GEEC Immediate|y
Expanded News and Contract Updates to Fo|low with Record Numbers for a 
Breakout Year

Company Profi|e:
G|oba| Environmenta| Energy Corp.
OTCBB - GEEC
Recent Price Range: 1.50 - 1.7O
Target price in Next 10 Days: 2.35
Target Price in Next 30 Days: 3.6O

We are sending this Investor Bu|letin revealing the Most Undervalued 
issue on the OTCBB to our mil|ions of subscribers for substantia| gains 
immediately. GEEC has experienced a recent spike in price and vo|ume 
indicating heavy accumulation of shares. This is a sign of even bigger 
things to come for this emerging wor|d |eader in the conversion of 
waste 
materia|s into electrical energy, an industry with such high global 
demand that it is impossib|e to assign a value to the size of the 
market.

GEEC is utilizing the unique proprietary techno|ogy of their Biosphere 
Process System for the disposal of a wide variety of waste products at 
5 to 7 tons per hour, making a major impact on the g|obal waste 
prob|em. This profitab|e and environmenta||y safe process converts into 
c|ean, 
"green" electricity such waste materials as Municipal Solid Waste, 
agricultural wastes, forestry wastes, medical wastes, industria| 
wastes, 
sewage sludge, shale oi|, sour natural gas, and the huge market of used 
tires.
GEEC generates 5 to 10 mega-watts per hour of e|ectricity from the 
waste conversion on a continuous basis which is then so|d to replenish 
the 
loca| or national grid.

The Biosphere Process succeeds in fi||ing an wor|dwide need for 
cost-effective renewab|e energy sources and a corresponding universa| 
need to 
solve critical problems in the disposal of waste. GEEC has secured 
international acceptance for a revo|utionary product designed to 
significant|y impact the globa| waste problem while a major push for 
generating 
e|ectricity from alternative sources continues to be the hot topic due 
to shortages and massive power fai|ures.

GEEC just announced a 10 Bi|lion, 5-year joint venture with Chinese 
Government-operated companies, including Yanzhou Coal Mining (NYSE - 
YZC, 
74.O0). The dea| is structured to have 1,3O0 GEEC Biosphere Systems 
dep|oyed throughout China to fulfi|l an need for waste disposal and 
energy 
generation, two critical areas for a country with a popu|ation 
exceeding 1.3 bi||ion people. As China's rapid economic advance 
continues, a 
shortfa|l of 50O mi|lion kilowatts exists annua|ly, prompting periodic 
blackouts in a|| Chinese Provinces. GEEC is in line to profit 
substantia||y while providing relief from unmanageable Municpa| Solid 
Waste 
disposal and simu|taneously he|ping China meet its energy needs.

The Chairman of GEEC, former Prime Minister of Ireland Dr. Albert 
Reyno|ds, has secured a 2 Billion LineofCredit for GEEC and opened 
doors in 
over a dozen countries through po|itical contacts at the highest |evel. 
Dr. Reynolds international stature has been instrumenta| in guiding 
GEEC into a position of wor|dwide acceptance by embracing a major 
footho|d 
on the globa| waste prob|em and the sweeping movement to generate 
e|ectricity from a|ternative sources. Dr. Reyno|ds, who has previously 
been 
nominated for a Nobel Peace Prize, has surrounded himse|f with a 
prestigious gr0up of the world's foremost professors and scientists. 
Their 
co|lective achievements have garnered awards and meda|s whi|e their 
writings have appeared in hundreds of articles, journals, and books. 
These 
beacons of the scientific community are the guiding forces leading GEEC 
into the next era of globa| waste remova| and the continuous generation 
of energy.

The forecast for GEEC is crystal clear, and this is just the tip of the 
iceberg for this emerging wor|dwide |eader where shares shou|d be added 
immediately to every portfo|io. We expect a continuous flow of huge 
news announcements while shares sti|| represent an uncommon value for a 
Company of this ca|iber. Look for the continuation of strong positive 
deve|opments that will ignite GEEC, which earns our highest rating for 
the 
most explosive gains on Wall Street.

Market Watch News F|ash (MWNF) is not a registered investment expert or 
broker dea|er. Certain statements contained in this news|etter may be 
futurelooking statements within the meaning of The Private Securities 
Litigation Reform Act of 1995. Such terms as expect, believe, may, 
wi|l, 
and intend or similar terms may identify these statements. Past 
performance is not an indicator of future resu|ts. This is not an 
attempt to 
acquire or se|lsecurities. MWNF is an independent publication that was 
paid nineteen thousand do|lars by a third party for the continuing 
coverage and dissemination of this company information. Investors are 
advised to seek proper guidance from a financial advisor or a 
registered 
financia| broker. Investors shou|d use the information provided in this 
newsletter as a starting point for gathering additional information on 
the 
profi|ed company to a|low the investor to form their own opinion 
regarding investment.

If you wish to stop future mai|ings, or if you fee| you have been 
wrongfu|ly p|aced in our list, please go here 
(-stox0030@yahoo.com-)

From dsc2005 at u.washington.edu  Wed Feb 23 20:00:52 2005
From: dsc2005 at u.washington.edu (Biostatistics)
Date: Wed Feb 23 20:01:04 2005
Subject: [Rd] DSC 2005: announcement and call for papers
Message-ID: <Pine.A41.4.61b.0502231039120.183206@homer11.u.washington.edu>


DSC2005, a conference on systems and environments for statistical 
computing, will be held at the South Campus Center, University of 
Washington, Seattle.

Following from the successful DSC 2003, 2001, and 1999 conferences at the 
Vienna University of Technology, DSC 2005 will focus primarily on open 
source software, in particular the R and Omegahat projects.

The conference will begin with a reception on Friday August 12 and will 
have scientific presentations on August 13 and 14.

Abstracts (one page) may be sent to this address 
(<dsc2005@u.washington.edu>).  The deadline for submission is 15 April 
2005, and notification of acceptance or rejection will be sent by 15 May 
2005.  Papers for publication in the online proceedings will be due in 
draft form by 1 August 2005 and in final form by 1 September 2005.


Further information, including registration details, will be available in 
the future from
http://depts.washington.edu/dsc2005/


 	-thomas

Thomas Lumley
Conference chair

From roebuck at odin.mdacc.tmc.edu  Wed Feb 23 20:31:16 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed Feb 23 20:31:27 2005
Subject: [Rd] Graphics devices file[name] argument
Message-ID: <Pine.OSF.4.58.0502231258080.510534@odin.mdacc.tmc.edu>

Just got trapped by inconsistency of name of first argument
for file-based graphics devices. Both 'file' and 'filename'
are currently in use depending on the device. I ran on a
machine without PNG support which my code used postscript
as the backup device and choked here.

> do.call(device, list(filename = pathname,
                       height = height,
                       width = width))

--- Method and first argument ---
postscript(file,
pdf(file,
pictex(file,
xfig(file,
bitmap(file,
jpeg(filename,
png(filename,
bmp(filename,


> version
         _
platform sparc-sun-solaris2.9
arch     sparc
os       solaris2.9
system   sparc, solaris2.9
status
major    1
minor    9.0
year     2004
month    04
day      12
language R

Also verified against R 2.0.1 on Windows

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From wntwwjewuf at wawasan2020.com  Thu Feb 24 01:28:36 2005
From: wntwwjewuf at wawasan2020.com (wntwwjewuf@wawasan2020.com)
Date: Thu Feb 24 01:28:57 2005
Subject: [Rd] Remember that SmallCaps outperform the Dow (PR#7700)
Message-ID: <20050224002836.971EBBAFE@slim.kubism.ku.dk>

Martin Nutraceuticals Commences Expansion in G|obal Nutraceutical 
Marketplace.

Watch MTNU on Thursday!

Martin Nutraceutica|s Inc. (MTNU)
Approximate F|oat: 2.5 Million
30-Day Target: 2.O0

Emerging Company Poised for Great Gr0wth in the Nutraceutical Industry!

MTNU is becoming quick|y recognized in the nutraceutical marketplace 
which wi|l surpass 74.4 bi||ion in the year 2O07.  With a growing 
demand 
for nutraceutica| products that provide not only hea|th benefits, but 
a|so prevent and provide treatment for disease, MTNU provides high 
quality products that use proprietary and patented oral systemic 
enzymes 
that he|p in the rapid absorption of the product, resu|ting in 
incredib|y 
swift, and effective results to symptoms inc|uding:

J0intPain
Cardiovascular Irregularities 
Digestive Irregu|arities
Anti-0xidization
WeightL0ss

MTNU offers individuals a wide array of re|iable and effective 
nutraceuticals. Martin Nutraceuticals has created a fami|y of 
complimentary 
medicine and supp|ementation that has helped thousands of peop|e 
suffering 
from arthritis and general jointpain, poor circulation, tiredness, 
obesity and digestive complications.  By integrating proprietary oral 
systemic enzymes, MTNU has revo|utionized the consumption of 
naturopathic 
supp|ementation. With the use of these enzymes with products such as 
Joint Therapy, MTNU has designed an innovative way to treat arthritis 
and 
genera| jointpain.

Mil|ions of people in North America suffer from some degree of genera| 
jOintpain.  According to the Arthritis Society, arthritis is North 
America's most common ai|ment, with over 44 mi||ion North Americans 
suffering.  The Wa|l Street Journal, in the Apri| 19th, 1999 issue 
states that 
Aspirin, Ibuprofen (Cox 1) Vioxx, Celebrex (Cox 2) kil|ed 2O,0OO 
Americans a year and put another 100,0O0 in the hospital suffering with 
drug 
side effects including: liver damage, kidney damage and intestina| 
hemorrhaging.  With many of these products being pulled and highly 
regulated because of the potential of dead|y side effects, sufferers of 
jointpain are seeking a natural, healthy alternative to aid in their 
suffering. 

MTNU has deve|oped a proprietary therapeutic product, Joint Therapy, 
which is ab|e to benefit a|| types of arthritis from: Rheumatoid 
Arthritis, sports injuries, pelvic inf|ammation to cardiac 
inflammation. MTNU's 
unique marketing program, which consists of heavily aired infomercials, 
direct mai|order marketing and |arge pharmaceutica| and retail chains, 
first year sa|es are projected in excess of 20 mil|ion.


Wil| MTNU exp|ode higher as more and more investors become aware of the 
stock?  If you think so, you may not want to wait unti| it is too |ate. 
Remember, timing your trade is critica|.

Good Luck and Happy Trading.


Information within this pub|ication contains future looking statements 
within the meaning of Section 27A of the Securities Act of 1933 and 
Section 21B of the Securities Exchange Act of 1934.  Any statements 
that 
express or involve discussions with respect to predictions, 
expectations, be|iefs, p|ans, projections, objectives, goa|s, 
assumptions or future 
events or performance are not statements of historica| fact and may be 
future looking statements. Future |ooking statements are based on 
expectations, estimates and projections at the time the statements are 
made 
that involve a number of risks and uncertainties which cou|d cause 
actual results or events to differ materially from those presently 
anticipated. Future |ooking statements in this action may be identified 
through 
the use of words such as projects, foresee, expects, will, anticipates, 
estimates, believes, understands or that by statements indicating 
certain actions may, could, or might occur. These future-looking 
statements 
are based on information currently available and are subject to a 
number of risks, uncertainties and other factors that could cause MTNU 
's 
actua| resu|ts, performance, prospects or opportunities to differ 
materia||y from those expressed in, or implied by, these future-looking 
statements. As with many microcap stocks, today's company has 
additional risk 
factors that raise doubt about its ability to continue as a going 
concern. MTNU is not a reporting company registered under the 
Securities Act 
of 1934 and hence there is limited public information avai|ab|e about 
the company. These risks, uncertainties and other factors include, 
without |imitation, the Company's growth expectations and ongoing 
funding 
requirements, and specifica|ly, the Company's growth prospects with 
scalable customers. Other risks inc|ude the Company's |imited operating 
history, the Company's history of operating |osses, consumers' 
acceptance, 
the Company's use of |icensed technologies, risk of increased 
competition, the potentia| need for additiona| financing, the 
conditions and 
terms of any financing that is consummated, the limited trading market 
for 
the Company's securities, the possib|e vo|atility of the Company's 
stock price, the concentration of ownership, and the potential 
fluctuation 
in the Company's operating resu|ts. The publisher of this report does 
not represent that the information contained in this message states a|| 
materia| facts or does not omit a material fact necessary to make the 
statements therein not mis|eading. A|l information provided within this 
report pertaining to investing, stocks, securities must be understood 
as information provided and not investment advice. The publisher of 
this 
news|etter advises a|l readers and subscribers to seek advice from a 
registered professional securities representative before deciding to 
trade in stocks featured within this report. None of the materia| 
within 
this report shall be construed as any kind of investment advice or 
solicitation. Many of these companies are on the verge of bankruptcy. 
You can 
lose a|| your money by investing in this stock. The publisher of this 
report is not a registered investment expert. Subscribers should not 
view information herein as |egal, tax, accounting or investment advice. 
Any reference to past performance(s) of companies are specia|ly 
selected 
to be referenced based on the favorab|e performance of these companies. 
You wou|d need perfect timing to achieve the resu|ts in the examp|es 
given. There can be no assurance of that happening. Remember, as 
a|ways, 
past performance is not indicative of future results and a thorough due 
diligence effort, including a review of a company's filings at sec gov 
or edgar-on|ine com when availab|e, should be comp|eted prior to 
investing. A|| factua| information in this report was gathered from 
public 
sources, including but not limited to Company Websites and Company 
Press 
Re|eases. The pub|isher of this report believes this information to be 
re|iable but can make no assurance as to its accuracy or comp|eteness. 
Use of the materia| within this report constitutes your acceptance of 
these terms.


If you wish to stop future mailings, or if you fee| you have been 
wrongfu|ly p|aced in our membership, p|ease go here or send a blank  
e mail with No Thanks in the subject to
(-stox0029@yahoo.com-)

From ligges at statistik.uni-dortmund.de  Thu Feb 24 13:06:50 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Feb 24 13:05:23 2005
Subject: [Rd] Graphics devices file[name] argument
In-Reply-To: <Pine.OSF.4.58.0502231258080.510534@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0502231258080.510534@odin.mdacc.tmc.edu>
Message-ID: <421DC35A.8070700@statistik.uni-dortmund.de>

Paul Roebuck wrote:

> Just got trapped by inconsistency of name of first argument
> for file-based graphics devices. Both 'file' and 'filename'
> are currently in use depending on the device. I ran on a
> machine without PNG support which my code used postscript
> as the backup device and choked here.


Specifying file = ..... should work because of partial matching.

Uwe Ligges


> 
>>do.call(device, list(filename = pathname,
> 
>                        height = height,
>                        width = width))
> 
> --- Method and first argument ---
> postscript(file,
> pdf(file,
> pictex(file,
> xfig(file,
> bitmap(file,
> jpeg(filename,
> png(filename,
> bmp(filename,
> 
> 
> 
>>version
> 
>          _
> platform sparc-sun-solaris2.9
> arch     sparc
> os       solaris2.9
> system   sparc, solaris2.9
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R
> 
> Also verified against R 2.0.1 on Windows
> 
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From becker at kfs.oeaw.ac.at  Thu Feb 24 15:59:13 2005
From: becker at kfs.oeaw.ac.at (becker@kfs.oeaw.ac.at)
Date: Thu Feb 24 15:59:23 2005
Subject: [Rd] bug report for as.function (PR#7702)
Message-ID: <20050224145913.A7774B275@slim.kubism.ku.dk>

Hi,

I got the following message in R:
Error in as.function.default(pdfs[1]) : invalid body argument for "function"
Should NEVER happen; please bug.report() [mkCLOSXP]

Operating System: Windows XP (SP2)
R version: R-2.0.1
Code causing error follows:

# create two probability density functions for mixtures of normal 
distibutions
fmix1 <- function(x) {dnorm(x, mean=4, sd=2) * 0.5 + dnorm(x, mean=7, 
sd=1) * 0.5}
fmix2 <- function(x) {dnorm(x, mean=3, sd=1) * 0.4 + dnorm(x, mean=6, 
sd=2) * 0.6}

# put them together
pdfs <- c(fmix1, fmix2)

# perhaps this is not as it was intended but it leads to the bug.report 
message
as.function(pdfs[1])

Meanwhile I solved this problem otherwise.
Hope this helps.
Timo

From murdoch at stats.uwo.ca  Thu Feb 24 16:28:16 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Thu Feb 24 16:28:26 2005
Subject: [Rd] bug report for as.function (PR#7702)
Message-ID: <20050224152816.A0D10BA61@slim.kubism.ku.dk>

On Thu, 24 Feb 2005 15:59:13 +0100 (CET), becker@kfs.oeaw.ac.at wrote
:

>Hi,
>
>I got the following message in R:
>Error in as.function.default(pdfs[1]) : invalid body argument for "function"
>Should NEVER happen; please bug.report() [mkCLOSXP]

A simpler version is as follows:

> x1 <- list(function() 1)
> x1
[[1]]
function() 1

> as.function(x1)
Error in as.function.default(x1) : invalid body argument for
"function"
Should NEVER happen; please bug.report() [mkCLOSXP]

The problem is that as.function doesn't know how to handle an object
of mode function as the body of a function.  It expects a function
definition to be a call instead:

> x2 <- as.list(function() function() 1)
> x2
[[1]]
function() 1

> as.function(x2)   # no problem this time
function () 
function() 1
> mode(x1)
[1] "list"
> mode(x1[[1]])
[1] "function"
> mode(x2)
[1] "list"
> mode(x2[[1]])  # notice the difference from x1[[1]]
[1] "call"

These tests were done in 

>platform i386-pc-mingw32             
>arch     i386                        
>os       mingw32                     
>system   i386, mingw32               
>status   Under development (unstable)
>major    2                           
>minor    1.0                         
>year     2005                        
>month    02                          
>day      24                          
>language R    

Could someone else please deal with this?  I have trouble with test
builds right now.

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Thu Feb 24 16:43:40 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu Feb 24 16:49:17 2005
Subject: [Rd] bug report for as.function (PR#7702)
In-Reply-To: <20050224145913.A7774B275@slim.kubism.ku.dk>
References: <20050224145913.A7774B275@slim.kubism.ku.dk>
Message-ID: <x2u0o20xqr.fsf@biostat.ku.dk>

becker@kfs.oeaw.ac.at writes:

> Hi,
> 
> I got the following message in R:
> Error in as.function.default(pdfs[1]) : invalid body argument for "function"
> Should NEVER happen; please bug.report() [mkCLOSXP]

Actually, I think that the only bug here is in the error message
(which presumably predates as.function()). If you can perform
arbitrary voodo and try to convert it into a function, then of course
you can also end up with an invalid body.
 
> Operating System: Windows XP (SP2)
> R version: R-2.0.1
> Code causing error follows:
> 
> # create two probability density functions for mixtures of normal 
> distibutions
> fmix1 <- function(x) {dnorm(x, mean=4, sd=2) * 0.5 + dnorm(x, mean=7, 
> sd=1) * 0.5}
> fmix2 <- function(x) {dnorm(x, mean=3, sd=1) * 0.4 + dnorm(x, mean=6, 
> sd=2) * 0.6}
> 
> # put them together
> pdfs <- c(fmix1, fmix2)
> 
> # perhaps this is not as it was intended but it leads to the bug.report 
> message
> as.function(pdfs[1])
> 
> Meanwhile I solved this problem otherwise.
> Hope this helps.
> Timo
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From david.whiting at ncl.ac.uk  Thu Feb 24 18:37:53 2005
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Thu Feb 24 18:38:02 2005
Subject: [Rd] sqlSave reports invalid regular expression '[^[:alnum]_]+'
	(PR#7703)
Message-ID: <20050224173753.7056BBA61@slim.kubism.ku.dk>

Full_Name: David Whiting
Version: 2.1.0 Under development (unstable)
OS: linux
Submission from: (NULL) (82.39.106.169)


I have just upgraded from a previous version (2.0.0?) and found some of my code
that used okay to run now gives an error. The function being called is
sqlSave(). I am pretty sure (but not 100% certain) that the data frame I am
trying to save has not changed. I am 100% sure that the ODBC connection
information for MySQL has not changed and I have not updated MySQL.

> sqlSave(lh, data, "survey")
Error in gsub(pattern, replacement, x, ignore.case, extended, fixed) : 
	invalid regular expression '[^[:alnum]_]+'
> traceback()
4: gsub("[^[:alnum]_]+", "", colnames)
3: mangleColNames(names(colspecs))
2: sqltablecreate(tablename, colspecs = colspecs, keys = keys)
1: sqlSave(lh, data, "survey")

> str(data)
`data.frame':	192 obs. of  171 variables:
[...]
(I can send the whole structure if that will help)

> version
         _                           
platform i686-pc-linux-gnu           
arch     i686                        
os       linux-gnu                   
system   i686, linux-gnu             
status   Under development (unstable)
major    2                           
minor    1.0                         
year     2005                        
month    02                          
day      24                          
language R                           
>

From tplate at acm.org  Thu Feb 24 18:57:16 2005
From: tplate at acm.org (Tony Plate)
Date: Thu Feb 24 18:57:35 2005
Subject: [Rd] sqlSave reports invalid regular expression
	'[^[:alnum]_]+' (PR#7703)
In-Reply-To: <20050224173753.7056BBA61@slim.kubism.ku.dk>
References: <20050224173753.7056BBA61@slim.kubism.ku.dk>
Message-ID: <6.2.1.2.2.20050224104911.07237080@mailhost.blackmesacapital.com>

I suspect that the error message is now correct, AFAIK, the correct syntax 
for that regular expression is '[^[:alnum:]_]' (your version is missing the 
second colon).  Looks like the previous version of R did just not give you 
a error message that the regular expression was invalid (and you might want 
to consider what it was doing with that expression -- probably not what was 
intended.)

Apparently this regular expression is defined in the function 
mangleColNames() in the package RODBC.  When I look at RODBC I see a 
correct regular expression in mangleColNames() -- have you perhaps an old 
or corrupt version of the RODBC package?

 > getAnywhere("mangleColNames")
A single object matching 'mangleColNames' was found
It was found in the following places
   namespace:RODBC
with value

function (colnames)
gsub("[^[:alnum:]_]+", "", colnames)
<environment: namespace:RODBC>
 >

My copy of RODBC has the following info:

                 Information on Package 'RODBC'

Description:

Package:              RODBC
Version:              1.1-3
Date:                 2005-02-05
Author:               Originally Michael Lapsley
                       <mlapsley@sthelier.sghms.ac.uk>, since Oct 2002
                       B. D. Ripley <ripley@stats.ox.ac.uk>
Maintainer:           B. D. Ripley <ripley@stats.ox.ac.uk>
Title:                ODBC database access
Description:          An ODBC database interface
SystemRequirements:   An ODBC driver manager and drivers. See README.
Depends:              R (>= 1.9.0)
License:              GPL2
Packaged:             Mon Feb 7 08:32:20 2005; ripley
Built:                R 2.0.1; i386-pc-mingw32; 2005-02-08 12:21:23;
                       windows


-- Tony Plate


At Thursday 10:37 AM 2/24/2005, david.whiting@ncl.ac.uk wrote:
>Full_Name: David Whiting
>Version: 2.1.0 Under development (unstable)
>OS: linux
>Submission from: (NULL) (82.39.106.169)
>
>
>I have just upgraded from a previous version (2.0.0?) and found some of my 
>code
>that used okay to run now gives an error. The function being called is
>sqlSave(). I am pretty sure (but not 100% certain) that the data frame I am
>trying to save has not changed. I am 100% sure that the ODBC connection
>information for MySQL has not changed and I have not updated MySQL.
>
> > sqlSave(lh, data, "survey")
>Error in gsub(pattern, replacement, x, ignore.case, extended, fixed) :
>         invalid regular expression '[^[:alnum]_]+'
> > traceback()
>4: gsub("[^[:alnum]_]+", "", colnames)
>3: mangleColNames(names(colspecs))
>2: sqltablecreate(tablename, colspecs = colspecs, keys = keys)
>1: sqlSave(lh, data, "survey")
>
> > str(data)
>`data.frame':   192 obs. of  171 variables:
>[...]
>(I can send the whole structure if that will help)
>
> > version
>          _
>platform i686-pc-linux-gnu
>arch     i686
>os       linux-gnu
>system   i686, linux-gnu
>status   Under development (unstable)
>major    2
>minor    1.0
>year     2005
>month    02
>day      24
>language R
> >
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Thu Feb 24 19:06:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Feb 24 19:07:00 2005
Subject: [Rd] sqlSave reports invalid regular expression '[^[:alnum]_]+'
	(PR#7703)
In-Reply-To: <20050224173753.7056BBA61@slim.kubism.ku.dk>
References: <20050224173753.7056BBA61@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502241801440.14702@gannet.stats>

Do not use R-bugs for reports on compatibility of obselete versiond of 
packages with unreleased versions of R!

You did not give the RODBC version no.  The current version, 1.1-3, is 
compatible with R-devel.  1.1-2 was not (alongside a dozen or so CRAN 
packages).

The only bugs here are in the report.

On Thu, 24 Feb 2005 david.whiting@ncl.ac.uk wrote:

> Full_Name: David Whiting
> Version: 2.1.0 Under development (unstable)
> OS: linux
> Submission from: (NULL) (82.39.106.169)
>
>
> I have just upgraded from a previous version (2.0.0?) and found some of my code
> that used okay to run now gives an error. The function being called is
> sqlSave(). I am pretty sure (but not 100% certain) that the data frame I am
> trying to save has not changed. I am 100% sure that the ODBC connection
> information for MySQL has not changed and I have not updated MySQL.
>
>> sqlSave(lh, data, "survey")
> Error in gsub(pattern, replacement, x, ignore.case, extended, fixed) :
> 	invalid regular expression '[^[:alnum]_]+'
>> traceback()
> 4: gsub("[^[:alnum]_]+", "", colnames)
> 3: mangleColNames(names(colspecs))
> 2: sqltablecreate(tablename, colspecs = colspecs, keys = keys)
> 1: sqlSave(lh, data, "survey")
>
>> str(data)
> `data.frame':	192 obs. of  171 variables:
> [...]
> (I can send the whole structure if that will help)
>
>> version
>         _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   Under development (unstable)
> major    2
> minor    1.0
> year     2005
> month    02
> day      24
> language R
>>
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Feb 24 19:06:55 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 24 19:07:10 2005
Subject: [Rd] sqlSave reports invalid regular expression '[^[:alnum]_]+'
	(PR#7704)
Message-ID: <20050224180655.7B9AFBB04@slim.kubism.ku.dk>

Do not use R-bugs for reports on compatibility of obselete versiond of 
packages with unreleased versions of R!

You did not give the RODBC version no.  The current version, 1.1-3, is 
compatible with R-devel.  1.1-2 was not (alongside a dozen or so CRAN 
packages).

The only bugs here are in the report.

On Thu, 24 Feb 2005 david.whiting@ncl.ac.uk wrote:

> Full_Name: David Whiting
> Version: 2.1.0 Under development (unstable)
> OS: linux
> Submission from: (NULL) (82.39.106.169)
>
>
> I have just upgraded from a previous version (2.0.0?) and found some of my code
> that used okay to run now gives an error. The function being called is
> sqlSave(). I am pretty sure (but not 100% certain) that the data frame I am
> trying to save has not changed. I am 100% sure that the ODBC connection
> information for MySQL has not changed and I have not updated MySQL.
>
>> sqlSave(lh, data, "survey")
> Error in gsub(pattern, replacement, x, ignore.case, extended, fixed) :
> 	invalid regular expression '[^[:alnum]_]+'
>> traceback()
> 4: gsub("[^[:alnum]_]+", "", colnames)
> 3: mangleColNames(names(colspecs))
> 2: sqltablecreate(tablename, colspecs = colspecs, keys = keys)
> 1: sqlSave(lh, data, "survey")
>
>> str(data)
> `data.frame':	192 obs. of  171 variables:
> [...]
> (I can send the whole structure if that will help)
>
>> version
>         _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   Under development (unstable)
> major    2
> minor    1.0
> year     2005
> month    02
> day      24
> language R
>>
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Fri Feb 25 01:48:33 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri Feb 25 01:54:12 2005
Subject: [Rd] Re: [R] H-F corr.: covariance matrix for interaction effect
In-Reply-To: <x2psyrcr84.fsf@biostat.ku.dk>
References: <421C6A88.3030907@gmx.net> <x2psyrcr84.fsf@biostat.ku.dk>
Message-ID: <x2acptpiqm.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard@biostat.ku.dk> writes:

> Bela Bauer <bela_b@gmx.net> writes:
> 
> > Hi,
> > 
> > I'm still not quite there with my H-F (G-G) correction code. I have it
> > working for the main effects, but I just can't figure out how to do it
> > for the effect interactions. The thing I really don't know (and can't
> > find anything about) is how to calculate the covariance matrix for the
> > interaction between the two (or even n) main factors.
> > I've looked through some books here and I've tried everything that came
> > to my mind, but I can't seem to be able to figure out an algorithm that
> > does it for me.
> > 
> > Could anyone give me a hint about how I could do this?
> > (I'll append my code at the end, in case that helps in any way...)
> 
> I have given it to you before: My plan is to drop the explicit formula
> involving on/off diagonal elements of S and go directly at Box (1954),
> theorems 3.1 and 6.1, involving eigenvalues of TST', where T is the
> relevant residual operator. In the case where one of the factors have
> only two levels, I believe you just take differences and use the usual
> formula, but more than two levels is tricky.

[moved to r-devel since this is getting technical]

Now I am getting confused: I can reproduce the G-G epsilon in all the
cases I have tried but the H-F epsilon eludes me. Consider this SAS
code

proc glm;
        model bmc1-bmc7=  / nouni;
        repeated visit 7/printe;

This ends up with

                      Greenhouse-Geisser Epsilon    0.6047
                      Huynh-Feldt Epsilon           0.7466

This makes OK sense since there are 22 observations

> (22*6*0.6047 -2)/(6*(21-6*.6047))
[1] 0.7466162

However, consider the following small change:

proc glm;
        class grp;
        model bmc1-bmc7= grp / nouni;
        repeated visit 7/printe;

Now I get 

                      Greenhouse-Geisser Epsilon    0.6677
                      Huynh-Feldt Epsilon           0.8976

Since we have one less DF for the covariance matrix, I would expect
that the H-F epsilon would be

> (21*6*0.6677)/(6*(20-6*.6677))
[1] 0.876696

The discrepancy gets worse as more covariates are added. If bmc1 is
moved to the rhs, I get

                      Greenhouse-Geisser Epsilon    0.6917
                      Huynh-Feldt Epsilon           0.9533

Where I would have expected

> (20*5*0.6917-2)/(5*(19-5*.6917))
[1] 0.8643953

Does anyone have a clue as to what is going on here? Is mighty SAS
simply doing the wrong thing? The G-G epsilon depends only on the
eigenvalues of the observed covariance matrix, so surely the H-F
correction should depend only on the dimension and the DF for the
empirical covariance matrix? 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Fri Feb 25 12:11:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 25 12:11:09 2005
Subject: [Rd] How graphical an interface should the default be?
Message-ID: <Pine.LNX.4.61.0502250906380.27653@gannet.stats>

install/update.packages will have a lot of changes in 2.1.0, and I have 
been adding some widgets to go along with this.

- Rather than just CRAN and BIOC, you have a character vector of
   repositories.  There is a function setRepositories() to set the
   appropriate option().

- There is no default CRAN, but a function chooseCRANmirror() to set a
   mirror, which is invoked if you try to access CRAN without setting a
   mirror.

- update.packages(ask="graphics") brings up a listbox for you to de-select
   packages (all available updates are pre-selected).

- install.packages() with no/empty pkgs argument brings up a listbox of
   all available packages (including those inside bundles).

- menu(graphics=TRUE) is implemented.

These can be set up to use widgets where available (Windows, if Tk is 
available under X11, I hope Aqua before release), and have a text-mode 
fallback (better than the current menu(), but in that spirit). (Except 
that is install.packages: text-mode selection from 480 packages even in 
three columns is not useful to me, but a scrolling list works well as 
Windows users of R already know.)

My question is:

 	What should be default be?

Options might be:

- use the graphics widget if available.

- make the graphics the default on Windows (it will always be available,
   but not necessarily on the right screen under DCOM uses).

- make text-mode the default on Unix.

- do different things for different tools.  Currently setRepositories()
   and chooseCRANmirror() default to graphics-if-possible, and
   update.packages() defaults to text mode (which gives more
   detailed information).

I am not really in favour of making the defaults a set of options, but 
that is possible.


This is a request for input on what would be a good compromise for general 
R users (and not just the R-devel audience).


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rgentlem at fhcrc.org  Fri Feb 25 12:54:31 2005
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Fri Feb 25 12:54:47 2005
Subject: [Rd] How graphical an interface should the default be?
In-Reply-To: <Pine.LNX.4.61.0502250906380.27653@gannet.stats>
References: <Pine.LNX.4.61.0502250906380.27653@gannet.stats>
Message-ID: <02B48362-8724-11D9-86D5-000D933DC9FE@fhcrc.org>


On Feb 25, 2005, at 3:11 AM, Prof Brian Ripley wrote:

> install/update.packages will have a lot of changes in 2.1.0, and I  
> have been adding some widgets to go along with this.
>
> - Rather than just CRAN and BIOC, you have a character vector of
>   repositories.  There is a function setRepositories() to set the
>   appropriate option().
>
> - There is no default CRAN, but a function chooseCRANmirror() to set a
>   mirror, which is invoked if you try to access CRAN without setting a
>   mirror.
>
> - update.packages(ask="graphics") brings up a listbox for you to  
> de-select
>   packages (all available updates are pre-selected).
>
> - install.packages() with no/empty pkgs argument brings up a listbox of
>   all available packages (including those inside bundles).
>
> - menu(graphics=TRUE) is implemented.
>
> These can be set up to use widgets where available (Windows, if Tk is  
> available under X11, I hope Aqua before release), and have a text-mode  
> fallback (better than the current menu(), but in that spirit). (Except  
> that is install.packages: text-mode selection from 480 packages even  
> in three columns is not useful to me, but a scrolling list works well  
> as Windows users of R already know.)
>
> My question is:
>
> 	What should be default be?
>
> Options might be:
>
> - use the graphics widget if available.
>
> - make the graphics the default on Windows (it will always be  
> available,
>   but not necessarily on the right screen under DCOM uses).
>
> - make text-mode the default on Unix.
>
> - do different things for different tools.  Currently setRepositories()
>   and chooseCRANmirror() default to graphics-if-possible, and
>   update.packages() defaults to text mode (which gives more
>   detailed information).
>
> I am not really in favour of making the defaults a set of options, but  
> that is possible.
>
>
> This is a request for input on what would be a good compromise for  
> general R users (and not just the R-devel audience).
>

Hi,
Thanks for taking this on - it looks like a big step forward. I have  
some pretty minor comments/questions. We will, of course, try to adapt  
the BioC code in time...

  We probably want to be sure that any function calling one of these has  
complete control and can override user defined defaults.

  I am not completely clear on your model for how the repositories are  
searched though. Two questions come to mind: 1) How do I get the most  
recent version of a package, regardless of which repository it is in?  
2) Can a package from one repository have its dependencies resolved in  
another repository, or not? (this last one is a real can of worms - in  
my view, as one might really prefer a same repository solution, but  
that means that repositories might need to completely contain CRAN -  
which is clearly less desirable). And of course this may be too fine a  
level of detail, but these problems have come up in our experience.

I think it would be nice if getting dependencies had two (or more  
levels), so that I could get only those packages that the current  
package "Depends" on, and a second level where I could
get both the "Suggests" and the "Depends". For me (at least) Suggests  
is weaker, and for many  users the "Suggests" set of packages is not  
always needed - the "Depends" set, is though. Currently the  
dependencies option seems to only allow TRUE and FALSE.

  Robert

>
> --  
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
+----------------------------------------------------------------------- 
----------------+
| Robert Gentleman              phone: (206) 667-7700                    
          |
| Head, Program in Computational Biology   fax:  (206) 667-1319   |
| Division of Public Health Sciences       office: M2-B865               
       |
| Fred Hutchinson Cancer Research Center                                 
          |
| email: rgentlem@fhcrc.org                                              
                          |
+----------------------------------------------------------------------- 
----------------+

From ripley at stats.ox.ac.uk  Fri Feb 25 13:09:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri Feb 25 13:10:01 2005
Subject: [Rd] How graphical an interface should the default be?
In-Reply-To: <02B48362-8724-11D9-86D5-000D933DC9FE@fhcrc.org>
References: <Pine.LNX.4.61.0502250906380.27653@gannet.stats>
	<02B48362-8724-11D9-86D5-000D933DC9FE@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0502251156270.29499@gannet.stats>

On Fri, 25 Feb 2005, Robert Gentleman wrote:

> On Feb 25, 2005, at 3:11 AM, Prof Brian Ripley wrote:
>
>> install/update.packages will have a lot of changes in 2.1.0, and I have 
>> been adding some widgets to go along with this.
>> 
>> - Rather than just CRAN and BIOC, you have a character vector of
>>   repositories.  There is a function setRepositories() to set the
>>   appropriate option().
>> 
>> - There is no default CRAN, but a function chooseCRANmirror() to set a
>>   mirror, which is invoked if you try to access CRAN without setting a
>>   mirror.
>> 
>> - update.packages(ask="graphics") brings up a listbox for you to de-select
>>   packages (all available updates are pre-selected).
>> 
>> - install.packages() with no/empty pkgs argument brings up a listbox of
>>   all available packages (including those inside bundles).
>> 
>> - menu(graphics=TRUE) is implemented.
>> 
>> These can be set up to use widgets where available (Windows, if Tk is 
>> available under X11, I hope Aqua before release), and have a text-mode 
>> fallback (better than the current menu(), but in that spirit). (Except that 
>> is install.packages: text-mode selection from 480 packages even in three 
>> columns is not useful to me, but a scrolling list works well as Windows 
>> users of R already know.)
>> 
>> My question is:
>> 
>> 	What should be default be?
>> 
>> Options might be:
>> 
>> - use the graphics widget if available.
>> 
>> - make the graphics the default on Windows (it will always be available,
>>   but not necessarily on the right screen under DCOM uses).
>> 
>> - make text-mode the default on Unix.
>> 
>> - do different things for different tools.  Currently setRepositories()
>>   and chooseCRANmirror() default to graphics-if-possible, and
>>   update.packages() defaults to text mode (which gives more
>>   detailed information).
>> 
>> I am not really in favour of making the defaults a set of options, but that 
>> is possible.
>> 
>> 
>> This is a request for input on what would be a good compromise for general 
>> R users (and not just the R-devel audience).
>> 
>
> Hi,
> Thanks for taking this on - it looks like a big step forward. I have some 
> pretty minor comments/questions. We will, of course, try to adapt the BioC 
> code in time...
>
> We probably want to be sure that any function calling one of these has 
> complete control and can override user defined defaults.

They have arguments to control this, e.g.

> args(chooseCRANmirror)
function (graphics = TRUE)

> I am not completely clear on your model for how the repositories are 
> searched though. Two questions come to mind: 1) How do I get the most recent 
> version of a package, regardless of which repository it is in?

That is the documented default behaviour.  (`Most recent' = `highest 
version number'.)  If more than one repository offers the same version, it 
is taken from the first on the list.

Icens is the only example that I have noticed, where BioC has a later 
version than CRAN.

setRepositories allows users to choose the order only in the text version, 
and you can of course just set the option from the command-line.

> 2) Can a package from one repository have its dependencies resolved in 
> another repository, or not?

Yes, but looking for dependencies is not the default, so you can 
do something like

install.packages("foo", repos="http://www.bioconductor.org",dependencies=TRUE)

to confine the search.

> (this last one is a real can of worms - in my view, as one might really 
> prefer a same repository solution, but that means that repositories 
> might need to completely contain CRAN - which is clearly less 
> desirable). And of course this may be too fine a level of detail, but 
> these problems have come up in our experience.
>
> I think it would be nice if getting dependencies had two (or more 
> levels), so that I could get only those packages that the current 
> package "Depends" on, and a second level where I could get both the 
> "Suggests" and the "Depends". For me (at least) Suggests is weaker, and 
> for many users the "Suggests" set of packages is not always needed - the 
> "Depends" set, is though. Currently the dependencies option seems to 
> only allow TRUE and FALSE.

That's true as for 2.0.0, and we could easily refine it (you need Imports 
too).

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From P.E.VerLorenvanThemaat at amc.uva.nl  Fri Feb 25 15:52:49 2005
From: P.E.VerLorenvanThemaat at amc.uva.nl (P.E.VerLorenvanThemaat@amc.uva.nl)
Date: Fri Feb 25 15:52:57 2005
Subject: [Rd] png device plot on athlon 64 processor (PR#7706)
Message-ID: <20050225145249.66E3DB28A@slim.kubism.ku.dk>

Full_Name: Emiel Ver Loren van Themaat
Version: 2.0.1
OS: windows XP
Submission from: (NULL) (145.117.31.248)


On our computers, which have windows xp sp2 installed and have a 64 bit
amd/athlon processor, the following simple code

png("test.png")
plot(1:10,main="hello")
dev.off()


results in a plot in which the "main" title is not visible at all. For 32-bit
computers with XP sp2 this bug does not occur. 

Hopefully this bug can be fixed.

(may be the png library is not up to date)

From osklyar at ebi.ac.uk  Fri Feb 25 16:05:17 2005
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Fri Feb 25 16:05:36 2005
Subject: [Rd] [R][Rdev] any way to generate "bitmap" (tif, jpeg,
 png etc) files in R CMD BATCH
Message-ID: <421F3EAD.3040607@ebi.ac.uk>

Hi Community,

here is the problem, Linux problem (reported to work on Windows). I need 
to generate graphical output in any of bitmap format under the 'R CMD 
BATCH'. Whereas the script generating png-s works perfectly in the R 
session, such things as X11, png and jpeg are not usable in BATCH (they 
cannot be switched on by --gui-X11 etc) and X11 is prompted to be 
required for png. At the same time, such things as postscript and pdf, 
which are generally X-independent work fine. The problem is that as a 
result I need something previewable in the web browser: png, jpeg. Any 
suggestions how to proceed? Generally I could use command line linux 
tools to convert from almost any bitmpa format to the required png or 
jpeg, but it would be nicer to have them as direct R output.

Kind regards
Oleg

-- 
Dr Oleg Sklyar
European Bioinformatics Institute
Wellcome Trust Genome Campus
Hinxton, Cambridge, CB10 1SD
England
phone/fax  +44(0)1223 49 4478/4468
e-mail osklyar@ebi.ac.uk

From Roger.Bivand at nhh.no  Fri Feb 25 16:31:44 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri Feb 25 16:32:00 2005
Subject: [Rd] Re: [R][Rdev] any way to generate "bitmap" (tif, jpeg,
 png etc) files inR CMD BATCH
In-Reply-To: <421F3EAD.3040607@ebi.ac.uk>
Message-ID: <Pine.LNX.4.44.0502251629590.6765-100000@reclus.nhh.no>

On Fri, 25 Feb 2005, Oleg Sklyar wrote:

> Hi Community,
> 
Use a virtual framebuffer - an example of an earlier question about this 
on the list is:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/15988.html

(the searchable archives have lots of good tips)

> here is the problem, Linux problem (reported to work on Windows). I need 
> to generate graphical output in any of bitmap format under the 'R CMD 
> BATCH'. Whereas the script generating png-s works perfectly in the R 
> session, such things as X11, png and jpeg are not usable in BATCH (they 
> cannot be switched on by --gui-X11 etc) and X11 is prompted to be 
> required for png. At the same time, such things as postscript and pdf, 
> which are generally X-independent work fine. The problem is that as a 
> result I need something previewable in the web browser: png, jpeg. Any 
> suggestions how to proceed? Generally I could use command line linux 
> tools to convert from almost any bitmpa format to the required png or 
> jpeg, but it would be nicer to have them as direct R output.
> 
> Kind regards
> Oleg
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand@nhh.no

From urbanek at research.att.com  Fri Feb 25 17:56:00 2005
From: urbanek at research.att.com (Simon Urbanek)
Date: Fri Feb 25 17:55:57 2005
Subject: [Rd] [R][Rdev] any way to generate "bitmap" (tif, jpeg,
	png etc) files in R CMD BATCH
In-Reply-To: <421F3EAD.3040607@ebi.ac.uk>
References: <421F3EAD.3040607@ebi.ac.uk>
Message-ID: <209DEA18-874E-11D9-AE75-000D93AE1C66@research.att.com>

On Feb 25, 2005, at 10:05 AM, Oleg Sklyar wrote:

> here is the problem, Linux problem (reported to work on Windows). I 
> need to generate graphical output in any of bitmap format under the 'R 
> CMD BATCH'. Whereas the script generating png-s works perfectly in the 
> R session, such things as X11, png and jpeg are not usable in BATCH

There are other ways, but if you have (or can install) libgd and 
freetype, you may consider using the GDD device - it can produce jpeg, 
png and gif on unix w/o the need of X11. The nice thing about it is 
speed (it doesn't use any external process) and that it uses 
anti-aliasing of both text and lines. It was designed specifically for 
graphics-on-demand on web servers.

Currenly GDD is not on CRAN (yet), but you can get it from
http://www.rosuda.org/R/nightly/
Just make sure that you have libgd and freetype (if you any problems or 
suggestions, please drop me a line).

There are other methods, too, like the bitmap device, which uses gs 
(AFAICS), or you can run virtual X11 to satisfy the devices that 
require X11.

Cheers,
Simon

From hb at maths.lth.se  Fri Feb 25 13:57:17 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri Feb 25 18:50:14 2005
Subject: [Rd] How graphical an interface should the default be?
In-Reply-To: <Pine.LNX.4.61.0502250906380.27653@gannet.stats>
Message-ID: <004401c51b39$8a05aa00$57f1ba51@hblaptop>

Very nice additions you have made! Thanks.

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Prof 
> Brian Ripley
> Sent: Friday, February 25, 2005 12:11 PM
> To: R-devel@r-project.org
> Subject: [Rd] How graphical an interface should the default be?
> 
> 
> install/update.packages will have a lot of changes in 2.1.0, 
> and I have 
> been adding some widgets to go along with this.
> 
> - Rather than just CRAN and BIOC, you have a character vector of
>    repositories.  There is a function setRepositories() to set the
>    appropriate option().
> 
> - There is no default CRAN, but a function chooseCRANmirror() to set a
>    mirror, which is invoked if you try to access CRAN without 
> setting a
>    mirror.
> 
> - update.packages(ask="graphics") brings up a listbox for you 
> to de-select packages (all available updates are pre-selected).

Minor comment 1: Isn't ask=(TRUE|FALSE) and graphics=(TRUE|FALSE) more in
line with the other updates? True, one more argument, but you can imagine
update.packages(ask=TRUE) with a "fall-back" to a text-based selection menu.
Until implemented, one could default to graphics=ask.

Minor comment 2: Naming conventions, not discussed very often, but I would
suggest chooseCranMirror() instead of chooseCRANmirror(). (I comment on this
in under "3.1 General Naming Conventions" -> "Abbreviations and acronyms
should not be uppercase when used as name" in my RCC draft at
http://www.maths.lth.se/help/R/RCC/.)

> - install.packages() with no/empty pkgs argument brings up a 
> listbox of all available packages (including those inside bundles).
> 
> - menu(graphics=TRUE) is implemented.
> 
> These can be set up to use widgets where available (Windows, if Tk is 
> available under X11, I hope Aqua before release), and have a 
> text-mode 
> fallback (better than the current menu(), but in that 
> spirit). (Except 
> that is install.packages: text-mode selection from 480 
> packages even in 
> three columns is not useful to me, but a scrolling list works well as 
> Windows users of R already know.)
> 
> My question is:
> 
>  	What should be default be?
> 
> Options might be:
> 
> - use the graphics widget if available.
> 
> - make the graphics the default on Windows (it will always be 
> available,
>    but not necessarily on the right screen under DCOM uses).
> 
> - make text-mode the default on Unix.

I would say that same/identical behaviour on as many platforms as possible
should be favored. That will make it easier to write general
instructions/help and have subsection with OS-specific features. 

> - do different things for different tools.  Currently 
> setRepositories()
>    and chooseCRANmirror() default to graphics-if-possible, and
>    update.packages() defaults to text mode (which gives more
>    detailed information).
> 
> I am not really in favour of making the defaults a set of 
> options, but that is possible.

My feeling is that a global option is what you want. Not only in the above
cases, it would be nice for any package developer to be able to query such
an option. I also believe there are different users; some prefer GUIs some
prefer command line, or even strongly dislike GUIs).

If writing scripts for, say, automated installation of 450+ CRAN packages on
various systems such Linux, Windows and OS X, it would be very useful to
have a predictive behaviour of the above so that you can make it work the
same on all systems. For example, I used to redefine readline() to
automatically answer questions asked by install.packages() when installing
many packages at the same time; this would be much harder if a GUI pops up. 

Maybe there should be a new options to start R with, e.g. --nogui. 

Best

Henrik Bengtsson

 
> This is a request for input on what would be a good 
> compromise for general R users (and not just the R-devel audience).
> 
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel

From roebuck at odin.mdacc.tmc.edu  Fri Feb 25 23:03:41 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri Feb 25 23:03:52 2005
Subject: [Rd] SystemRequirements clarification
Message-ID: <Pine.OSF.4.58.0502251548310.141363@odin.mdacc.tmc.edu>

Did google search and checked R-ext but found very little
on this DESCRIPTION field. Does it document runtime dependency
only? If I have some code that can only be used with a specific
compiler (code makes use of GCC attributes), should I add
	SystemRequirements: GCC
to the package's DESCRIPTION to document the build-only
requirement.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)

From frank at trdlnk.com  Fri Feb 25 23:04:29 2005
From: frank at trdlnk.com (frank@trdlnk.com)
Date: Fri Feb 25 23:04:38 2005
Subject: [Rd] vcov on result of rlm() yields "-- please report!" (PR#7707)
Message-ID: <20050225220429.60023BAFE@slim.kubism.ku.dk>

This is a multi-part message in MIME format.
--------------020205020409020506080205
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Dear r-bugs,
I looked over the FAQ. Hope I'm reporting this correctly.
I ran this on both solaris and windows. I've provided terminal snapshots
which include how R was called from the command line, and the
result of version at the R prompt.

I have attached the .r file, and the data file and the output snapshots.
Below also find everything except only a few lines of the data file.

Note that it seems to work for lm() but not for rlm().

Not that it matters for our purposes, but the same program(except for 
modifying read.csv()) runs without error under Splus Version 6.2.1on 
Linux 2.4.18.

Thanks for looking at this.
Of course let me know if I can provide any other information.

Frank Hansen
312-264-2043

-------- here is a cut and paste from the terminal window on solaris  ---
brahe:/home/titan/frank $ R

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

 > version
         _                
platform i386-pc-solaris2.8
arch     i386             
os       solaris2.8       
system   i386, solaris2.8 
status                    
major    1                
minor    9.1              
year     2004             
month    06               
day      21               
language R                
 > source("test.r")
[1] "before vcov( lm.out)"
[1] "before vcov(rlm.out)"
Error in if (rdf != z$df.residual) warning("inconsistent residual 
degrees of fre
edom. -- please report!") :
        missing value where TRUE/FALSE needed
 >


---here is a cut and paste of the terminal window on dos -----

H:\Notes>R

R : Copyright 2004, The R Foundation for Statistical Computing
Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

 > version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R
 > source("test.r")
[1] "before vcov( lm.out)"
[1] "before vcov(rlm.out)"
Error in if (rdf != z$df.residual) warning("inconsistent residual 
degrees of fre
edom. -- please report!") :
        missing value where TRUE/FALSE needed
 >



here is the program
----------------- test.r --------
library(MASS)

dat <- read.csv( "data.for.r.help.no.I.csv", header=TRUE)

attach( dat)

log1pX <- log(1 + X)
logZ <- log(Z)

rlm.out <- rlm( Y ~ -1+ Factor + log1pX + logZ + W, method="M")
lm.out <-   lm( Y ~ -1+ Factor + log1pX + logZ + W)

print( "before vcov( lm.out)" )
vcov( lm.out)

print( "before vcov(rlm.out)" )
vcov( rlm.out)

print( "after vcov(rlm.out)" )

---------------


---------here is head on the data file --------
"Y","Factor","X","Z","W"
8.73469387755,"A",-0.050335552279,3.49,1.30413295097
23.5315946724,"B",0.399664852202,4.59,0.914640733428
854.100293301,"C",6.65305970571,2.12,-0.127812880306
27.1833605167,"D",0.101059456576,3.52,-0.0648127731788
17.7277970012,"D",0.0446397114047,4.59,-0.137983116953
15.9722222222,"C",0.000378382282472,4.59,-0.495730019986
26.2627737226,"E",0.138801178471,3.55,-0.220289949486
21.9134615385,"A",0.387109096009,3.55,1.22120113878
16.5000165,"C",0.133098708566,3.52,-0.243375187344




--------------020205020409020506080205
Content-Type: text/x-comma-separated-values;
 name="data.for.r.help.no.I.csv"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="data.for.r.help.no.I.csv"

"Y","Factor","X","Z","W"
8.73469387755,"A",-0.050335552279,3.49,1.30413295097
23.5315946724,"B",0.399664852202,4.59,0.914640733428
854.100293301,"C",6.65305970571,2.12,-0.127812880306
27.1833605167,"D",0.101059456576,3.52,-0.0648127731788
17.7277970012,"D",0.0446397114047,4.59,-0.137983116953
15.9722222222,"C",0.000378382282472,4.59,-0.495730019986
26.2627737226,"E",0.138801178471,3.55,-0.220289949486
21.9134615385,"A",0.387109096009,3.55,1.22120113878
16.5000165,"C",0.133098708566,3.52,-0.243375187344
28.5052631579,"B",0.623439422305,3.52,-0.422811577042
25.8745622811,"D",0.229205420669,2.12,-0.200177307421
16.4680232558,"E",0.179418817508,3.51,-0.335809927225
11.8625,"F",-0.188194758578,3.63,-0.430203019688
28.75,"E",0.599979969827,3.55,-0.3972666749
11.0707456979,"A",0.0222998422651,3.55,-0.024764276122
19.5514705882,"C",0.114905693717,3.51,-0.429671828481
18.6742934051,"B",0.0297655497652,4.59,-0.474833455898
54.347826087,"E",0.0657718166744,3.63,-0.442615879212
8.61157024793,"A",-0.0679442165455,3.49,0.249656986243
55.9459459459,"H",0.402878814284,4.59,-0.523454051056
12.3357605624,"F",-0.174806348851,3.52,-0.484777106295
20.0869766087,"B",0.0997440131645,3.55,0.174734541472
12.3903345725,"B",0.0505165785386,3.49,-0.112688455668
26.0075,"A",0.157834271388,3.63,-0.132912730886
11.9518377693,"A",0.061384765068,4.59,-0.28334400572
21.7592592593,"C",0.119345555323,3.69,-0.539329198267
14.913409802,"E",0.102525055053,3.69,-0.419968044113
16.8187539333,"D",0.0850209681194,4.59,-0.152149322452
18.0620985011,"A",0.156630637908,3.51,0.264569349391
18.0671936759,"D",0.0804427049757,3.51,-0.26504156369
21.8181818182,"D",0.130936716684,3.52,-0.101664163159
20.0691823899,"A",0.375908602408,3.51,1.36043216402
74.2954545455,"A",1.41196236591,3.51,-0.427400156085
15.652173913,"E",0.0873392184994,3.5,-0.560279296469
15.3086419753,"C",0.0513013687336,4.59,-0.533314287835
20.1111111111,"C",0.0405328362591,3.52,-0.38391302595
28.7378947312,"B",0.586839294657,4.59,-0.40989782081
19.1723549488,"C",0.0639887969656,4.59,-0.527845508362
35.2649006623,"G",0.274574479051,4.59,-0.50384770061
0.719016779511,"D",-0.833129846672,3.55,-0.317205785189
30.085106383,"D",0.179936117396,3.55,-0.0870003808961
28.3265306122,"G",0.213416966543,3.49,-0.256214659806
31.4049586777,"C",0.144292683957,3.69,-0.37281444967
16.9541646131,"C",0.0880464420824,3.69,-0.197866625671
56.7961165049,"D",0.51303086006,2.12,-0.524345871293
33.2228915663,"G",0.341625506615,3.55,-0.41734819248
20.704787234,"D",0.135937099322,4.59,-0.398338602156
55.9024390244,"D",0.124499281523,3.63,0.0932087260108
12.2368421053,"A",0.102581097217,4.59,0.553328624412
11.9350282486,"F",-0.238121374793,4.59,-0.518984990035
18.3582915783,"D",0.146883469069,4.59,2.06751779427
638.75,"C",2.28305714236,4.59,-0.00459229003918
18.2692307692,"C",0.100688410774,4.59,-0.0855122155304
21.83,"A",0.283098380224,3.49,-0.085660368078
33.0893682589,"A",0.359909323826,2.12,-0.463869752385
35.3939393939,"A",0.914794869938,2.12,-0.502945505544
12.1089108911,"A",0.0861491202801,4.59,2.4615712013
34.8148148148,"B",0.607335568458,3.51,1.0114071716
21.9168900804,"D",0.124819185847,4.59,1.06303273202
16.8321916166,"B",-0.0680084359348,3.51,0.42731554537
23.6776859504,"E",0.375488475818,4.59,-0.375904488519
11.8466898955,"A",0.0381514439413,4.59,-0.442417097502
34.3509350935,"C",0.416855937657,4.59,-0.50460464808
16.0843373494,"A",0.15179876087,3.52,1.81905601218
21.3805253043,"C",0.165915546195,4.59,-0.503758477087
6.15492957746,"E",0.0127846528516,4.59,-0.490423917821
24.8085714286,"D",0.0867753888059,3.51,-0.21975087341
12.2097378277,"H",-0.0149331797033,3.51,0.0141799242148
29.476555477,"A",0.195826082472,3.63,-0.388398271703
16.5618448637,"J",0.0360542479099,4.59,0.451338667703
26.9806763285,"D",0.180334022977,4.59,-0.454131523587
23.6900893603,"A",0.369162188942,3.63,0.75107409603
6.36433218523,"E",-0.0650124215212,4.59,-0.535384688562
18.6930232558,"A",0.150747750833,3.52,-0.448016184817
20.6554350335,"A",-0.16903719864,4.59,-0.253885303365
23.1839359697,"B",0.330816121952,4.59,0.700759913906
14.2833333333,"A",0.0504728036037,3.63,-0.196384685202
11.401384083,"E",0.0588094263767,3.51,0.561548393346
21.1988304094,"D",0.126786476293,3.55,0.426740364892
21.902608808,"A",0.214354002576,3.63,-0.267421549293
9.85989492119,"A",0.0205611433351,3.55,2.05925569603
17.5729927007,"D",0.042278194822,4.59,-0.449556639318
28.1575919943,"G",0.0250474453866,3.55,-0.506641019371
16.0108765195,"B",0.0710275727451,4.59,-0.225880321946
14.232596571,"E",0.0563706340798,4.59,-0.209093849821
15.5168143974,"J",-0.0212597572544,4.59,3
19.3536673929,"C",0.17411115781,4.59,-0.40394017943
22.0322580645,"A",0.0746342213411,3.63,-0.463886767104
23.8358208955,"A",0.273664878954,3.63,-0.320777216069
14.0601851852,"A",0.0715585741236,3.63,-0.311936617412
21.8696883853,"E",0.155169033656,4.59,-0.466873887656
12.8799392097,"A",0.183681470544,4.59,-0.549320987867
15.7511581734,"A",0.0706974909567,4.59,-0.540393655646
35.9670530811,"H",0.302259030559,4.59,0.266881691114
15.0070126227,"H",0.143923838482,4.59,0.801914489443
15.5,"A",0.118286147591,3.52,-0.172178135905
12.6231884058,"E",-0.0304640285167,3.49,-0.551206301659
30.4935483871,"E",0.191880582349,3.63,-0.463242697765
20.7250755287,"B",0.116436155824,4.59,-0.563784328448
9.2807112069,"E",0.0947023744031,4.59,-0.551459447468
6.80956434264,"E",0.0291322117129,4.59,-0.537963455874
22.2639149468,"A",-0.014394485535,4.59,-0.539485235684
11.015435936,"C",-0.0393762420727,3.63,-0.485946556937
17.7212389381,"D",0.0681736812309,3.55,0.895551049429
65.5365853659,"G",0.392164002464,3.55,-0.423765231256
268.714285714,"A",3.09725517878,3.63,-0.171256851156
20.3508367484,"D",-0.133467466718,3.59,-0.462396941765
18.3097031458,"A",0.176576193731,4.59,-0.522722003174
81.619047619,"A",1.53521809901,3.51,-0.0691390765633
20.045045045,"D",0.0432678564067,4.59,0.213082396681
25.8842763909,"E",0.184626552532,4.59,-0.197630909573
32.005988024,"D",0.342763050869,3.55,-0.104045808734
29.1165334017,"E",0.367233759914,2.12,0.138132977357
47.0476190476,"H",0.664760815081,3.55,0.0819756919569
3.8962894337,"A",-0.382206694948,2.12,-0.557675629569
14.593639576,"B",0.117845114337,2.12,-0.412896561171
22.2195121951,"D",-0.137502209264,3.52,-0.372611518029
19.0950833256,"B",0.0821422178835,2.12,-0.451380119133
19.3523489933,"D",0.17937606215,3.51,-0.349684807547
16.8920471438,"F",0.186010553946,4.59,0.113705651715
34.7398477157,"J",-0.130566228444,4.59,-0.475698716574
12.8723404255,"A",0.0699942555247,3.55,-0.206506782646
14.0308370044,"D",0.0646825983561,3.55,-0.249744086917
16.0314579552,"C",-0.0236918978392,4.59,-0.498661946452
25.2911813644,"D",0.239699657685,3.59,-0.511894832402
23.4358047016,"D",0.111911505969,3.51,-0.367863166631
23.5654008439,"E",0.423832387139,3.51,-0.198764255812
16.9365671642,"A",0.0410579309873,3.49,-0.453447199915
19.8701298701,"H",0.157976291169,3.6,-0.342367233678
32,"E",0.153114522421,4.59,-0.169491885372
40.7386363636,"D",0.279737643567,4.59,-0.428702819521
43.5897435897,"E",0.356357430579,4.59,-0.497797515762
39.4897959184,"A",0.750261554798,3.55,1.37262092725
16.4838709677,"A",0.216883595037,2.12,1.52865792929
12.7197802198,"D",-0.130667668094,3.49,-0.513609169023
19.6818181818,"A",-0.172902116379,4.59,-0.543592007702
16.1052009456,"A",0.154350973583,4.59,-0.508886962192
10.4838709677,"H",-0.151054048736,4.59,-0.373613726439
10.8053482587,"A",0.0069533478648,3.59,0.225276969818
22.4045454545,"A",0.22021834298,3.51,-0.315822613085
13.1760154739,"A",0.176112074259,3.51,1.36775388782
20.0054436581,"D",0.284217740794,3.59,-0.48311132387
42.0470588235,"E",0.923441006603,3.51,1.3185203478
105.789473684,"H",0.384392057338,3.55,-0.374764917383
20,"D",0.12309069455,3.51,-0.331828483132
17.8890600924,"C",0.146768565037,3.55,-0.0926127479917
15.5873806559,"D",0.0318324392305,4.59,1.13956037022
36.9065100343,"H",0.0879124954014,4.59,-0.373212013089
14.7310513447,"A",0.153426149626,3.63,-0.104378218232
1.63905325444,"A",-0.644129253569,3.51,-0.298260103806
15.2627118644,"C",0.180879261613,3.51,0.46613151283
28.3611111111,"B",0.538548014995,3.49,-0.352794766066
27.1990018715,"C",0.304486236746,3.59,-0.548801001475
29.9590163934,"G",0.0977072342529,3.55,-0.391535619769
52.6451612903,"H",0.5902584797,3.51,3
19.1981747066,"D",0.0860864826947,4.59,-0.544536117074
15.3813559322,"A",0.152268293558,3.51,0.485330755015
13.7746710526,"E",0.0526889539257,4.59,-0.363267117712
126.315789474,"C",1.70314955678,3.49,0.41352573864
23.7654320988,"A",0.304469179209,3.49,-0.114049218143
20.5960264901,"C",0.0500650465503,4.59,-0.50853795297
27.7777777778,"D",0.126745552644,3.55,-0.310931089057
13.7538461538,"F",0.0759126251342,3.52,0.405647509052
22.0334779913,"F",0.0866180261048,3.51,0.42178078199
21.6451612903,"H",0.251392186018,3.5,-0.512703654013
9.77286312014,"E",-0.184666836952,3.69,-0.346289748747
23.0271839535,"H",0.0634428857159,4.59,-0.436288063959
11.1342592593,"A",-0.0725260731261,4.59,-0.266702366198
15.6127770535,"E",-0.117894837561,4.59,-0.468494850824
23.6014492754,"C",0.26191892066,3.55,-0.0351536291418
17.3876146789,"F",0.00820885323584,3.63,1.89576251242
19.5454545455,"F",0.137618132394,3.52,-0.451332394923
13.8489208633,"J",0.08691887475,3.63,3
21.3662790698,"H",-0.048573584644,3.69,-0.543103145795
11.8708609272,"F",-0.0337379748099,3.51,2.02929070206
13.3333333333,"C",-0.0774938771658,3.51,-0.579547842507
17.1666666667,"H",0.0855089129068,3.69,1.33901063362
30.80625,"H",0.121870647624,3.63,-0.50053481045
17.686533212,"E",0.215877973092,4.59,-0.401745695756
19.0769230769,"D",0.191872244057,3.52,-0.514102180862
25.6727828746,"C",0.118740372244,4.59,-0.419133077934
53.7398365677,"G",0.0955785834204,3.63,-0.591176365014
16.5805084746,"C",0.106557155003,3.52,-0.345995933611
22.7962085308,"C",0.12497828731,3.52,-0.257976720638
17.0238095238,"C",0.0908202826532,4.59,-0.501063096705
19.7086368366,"C",0.151933632034,3.55,-0.463464304097
26.8279569892,"C",0.214050870487,4.59,-0.557364799714
23.5935916546,"D",0.134426281626,3.51,-0.304631078344
17.6186046512,"C",-0.0716245747368,3.63,-0.276489979178
12.4597701149,"A",0.123721493188,3.51,0.886558563287
14.9221453287,"J",0.100871424252,3.55,3
16.9387755102,"A",0.166836722397,4.59,-0.337765374855
15.9454545455,"E",-0.0382307969164,3.55,-0.463398320189
29.5519713262,"D",0.310161625095,3.51,-0.43253777104
8.22366625872,"C",0.118889036586,3.63,-0.466267997686
12.4523809524,"A",0.062622541953,3.63,-0.434202308486
10.5663824604,"A",-0.0238781378493,3.69,-0.0915408207358
18.4360902256,"H",0.235178486996,3.55,2.60433630804
10.3611111111,"F",-0.100010061785,3.5,0.0748021207047
40.6984126984,"A",0.382261058889,3.63,1.15922398972
12.9638683856,"J",0.0378819860456,3.52,-0.474538395782
65.3594771242,"D",0.546131584251,3.69,-0.407604983765
16.4647887324,"F",0.0891782695302,3.52,-0.0535332598944
26.0534288075,"C",0.300760322538,2.12,-0.477424258011
21.6335540839,"D",0.224294183291,3.69,-0.498386806007
31.3909774436,"A",0.0919122427488,3.55,-0.337112590661
22.6646032639,"B",0.247232549994,2.12,-0.393807707158
13.1592827004,"E",-0.171981611631,4.59,-0.47575515564
21.9898989899,"E",0.10237130081,3.55,-0.460727424402
10.7835325365,"A",0.0432001236618,3.55,1.31669147308
19.2448512586,"D",0.0872286027114,4.59,-0.181966993865
50.2016129032,"H",0.451557633894,3.59,-0.514688566156
18.600028397,"D",0.0834025942902,4.59,-0.540474579307
16.9733333333,"D",0.0714769596527,4.59,3
2.3734939759,"G",-0.651163724667,3.49,-0.564940914303
24.4656776465,"E",0.15746444021,4.59,0.161204520442
35.386491969,"D",0.379737713576,4.59,-0.44124225195
13.5796766744,"A",0.149655068262,4.59,2.08756403743
14.5733173077,"D",-0.00421561648039,3.49,-0.300108068216
37.3758865248,"C",0.700855020694,3.51,-0.33301079856
16.2257281553,"D",-0.0231356758654,3.49,0.0869601744462
35.8024691358,"E",0.433001239815,4.59,-0.220729427211
26.5642775882,"E",0.145181111012,3.69,0.543715723539
35.9306496612,"A",0.0634360675793,4.59,-0.418075260445
13.431372549,"E",0.0761633310962,4.59,-0.529578934668
9.81481481481,"A",0.059674961812,3.51,-0.411268958113
16.4187116564,"C",0.0398966253484,4.59,-0.306076499417
14.7100840336,"C",-0.122146118665,3.55,-0.300106823237
16.091160221,"B",0.153101666693,3.69,-0.496541331556
23.1329552953,"C",0.193240449897,2.12,0.010088091949
91.5,"C",0.867904811444,3.51,-0.524764184369
80.25,"A",1.41771705334,3.51,-0.382457645041
18.5911283997,"A",0.142749463786,4.59,3
12.8681318681,"C",0.133500611982,3.5,-0.549932272749
79.2570718257,"A",1.46880889489,3.51,0.0501112744248
22.7941176471,"A",0.0558297967089,4.59,-0.477267805601
15.0298507463,"F",0.107463910668,3.52,0.35024551115
17.4358974359,"E",0.100630355518,3.52,-0.478049652658
14.9498151083,"B",0.123275916212,4.59,-0.355038218929
16.8370244179,"A",0.0979537283289,4.59,-0.54973100108
28.5833333333,"G",0.161631270384,3.52,-0.496276980932
70,"G",0.520211199442,3.51,-0.301673422304
43.0695652174,"J",0.61417819985,3.49,-0.524551707886
33.0543892603,"E",0.273685344545,4.59,-0.278226725429
40.8379888268,"A",0.149271959734,4.59,-0.26516357167
15.7894736842,"C",-0.0108066812806,4.59,-0.498171839565
18.334384858,"D",0.117215443414,4.59,0.213653842221
25.2991452991,"D",0.112479931635,3.51,0.29115712927
15.6873111782,"E",0.0924132422499,4.59,-0.485642781965
11.3830845771,"A",0.107334523199,3.49,2.09786665689
78.5123966942,"A",-0.27929098271,3.69,-0.189358436511
31.6652286454,"G",0.219034045239,4.59,-0.549154160629
19.3807753385,"F",0.092455401516,4.59,-0.408854943073
53.6098310292,"D",0.170117783271,3.59,-0.502660820257
10.5555555556,"C",-0.505707857414,4.59,-0.525631520011
10.6587301587,"C",-0.0825594349081,3.63,-0.427488134629
24.6998284734,"D",0.153680068972,4.59,-0.52737324618
31,"H",0.222957480864,4.59,-0.218224943669
31.8016759777,"E",0.268262926981,3.52,0.137670675009
16.2231030578,"E",-0.0171103304584,4.59,-0.571786640982
10.1031870428,"A",-0.099702851794,4.59,-0.554039044767
19.3030468893,"B",0.0915343879212,4.59,-0.434171598994
17.9284130504,"H",0.104955996928,4.59,-0.487734762336
17.4860335196,"A",0.219229215483,3.51,0.421632629443
14.7502356268,"F",0.0400977472099,4.59,-0.428364185127
15.8425348056,"E",0.11221498218,4.59,-0.478172490625
18.7735849057,"D",0.186047467153,3.5,-0.512582061026
16.9382022472,"E",0.129731544625,4.59,-0.0635748486708
23.2394366197,"D",0.126282194519,4.59,-0.506352184152
11.786389414,"C",-0.0366433260285,3.5,-0.401090836597
28.6923076923,"H",0.400782707028,3.49,0.325890809306
64.3571428571,"H",0.622211893857,2.12,-0.534120204494
23.7710219922,"A",0.0295035287388,4.59,-0.0814689374609
19.6341463415,"C",0.201182022518,3.55,0.124655245461
8.92045454545,"A",-0.121317221201,4.59,-0.0184368758627
38.3314329152,"A",0.109295679861,4.59,-0.361858631027
25.8883248731,"C",0.297105571241,3.51,-0.287330844724
8.70926243568,"A",-0.133096498571,4.59,1.64397663536
21.9054921075,"B",0.0896567343111,4.59,-0.502752948732
31.5789473684,"G",0.341957632314,4.59,-0.507104981691
25.7446808511,"B",0.342236933561,2.12,-0.487953048722
35.8054908337,"B",1.44209818133,3.55,0.016621328801
22.5916806714,"A",-0.00718018111553,4.59,-0.501414595886
91.3636363636,"E",0.831438414653,3.63,-0.471447526947
20.4584040747,"D",0.045593334453,3.59,-0.412785758005
28.2716666667,"D",0.097598385871,3.63,-0.201572099332
15.4305680794,"E",0.0902650689852,4.59,-0.47666316061
15.6596794081,"C",0.175068864892,3.59,0.952807651632
25.128,"C",0.470087515762,3.51,-0.367289231132
14.8765432099,"A",0.0827491302293,3.52,-0.464082643861
15.6976744186,"G",-0.00861267044142,2.12,-0.552899058638
18.5323943662,"A",-0.094098635783,3.63,-0.0474610804102
34.8705882353,"A",0.143232594316,3.63,-0.38516589021
26.9802631579,"D",0.36456013252,3.51,0.106685627921
27.68,"C",0.420455581847,3.5,-0.514044081824
8.94136807818,"E",-0.235223424932,4.59,-0.547269261831
28.0271280725,"C",0.115198398785,4.59,-0.518919006127
33.4384615385,"A",0.844951531571,3.63,-0.507836614579
14.9959742351,"E",0.0808356232679,4.59,-0.137900118327
12.4289099526,"E",0.0900984965715,3.55,-0.209497223143
26.14,"A",0.128160972557,3.51,-0.536928463007
21.5750915751,"H",0.094441500402,3.55,-0.17126141608
22.19,"H",0.0922393922579,3.55,-0.457189607965
28,"H",0.159120601844,3.63,-0.491988026929
16.9077306733,"H",0.0922129301505,3.51,-0.384886184841
22.8973214286,"D",0.0469911246895,3.51,-0.0872087074475
17.1564733916,"D",0.0145131704391,4.59,-0.169464080832
33.628125,"H",0.269777527266,3.63,0.0654162210743
73.5483870968,"G",0.417830009375,4.59,-0.514574028052
12.0839224728,"A",0.0231861611341,3.52,-0.467306725491
14.57244208,"A",0.137738308636,3.69,0.579362388461
22.9744525547,"G",0.0920845165283,3.55,-0.507153535887
19.7663551402,"D",0.0772217027542,2.12,3
33.4966088922,"C",0.136322284649,4.59,-0.518106034584
11.7216117216,"D",0.00657694006158,4.59,-0.553016501694
17.1363350126,"F",0.0612161665768,4.59,0.679595679249
25.8571428571,"E",0.0733892583774,3.52,-0.545014604153
13.8746854292,"J",0.0699062791292,3.63,0.228468681984
18.3177570093,"C",0.0939298957531,3.55,-0.394781281042
44.1489007728,"D",0.225753636962,2.12,-0.393755833017
18.7121212121,"H",0.0932385167682,3.5,2.48662392159
19.3791946309,"D",0.10255210046,2.12,3
21.3230355944,"D",0.0734596367224,3.59,0.195974719873
11.1613164284,"A",0.0803323258047,4.59,-0.344061235637
26.9696969697,"B",0.555298549404,3.63,-0.501548638668
13.0769230769,"D",-0.265104510599,3.49,-0.34097949665
23.8693467337,"C",0.00875563924,4.59,-0.550601656668
14.871897518,"F",0.138524039971,4.59,-0.539174405829
15.0225988701,"A",-0.0737659018802,3.49,-0.442706347714
17.0848267622,"E",0.168086216393,4.59,-0.288521045022
24.192139738,"D",0.0931991284747,3.59,-0.469108625664
11.6213592233,"G",-0.0719645449525,3.49,-0.558977463019
25.3666666667,"D",0.201318719852,3.51,-0.556741480032
15.2528089888,"A",0.168740799399,4.59,-0.20740482778
16.897260274,"J",0.256123547169,3.49,-0.229976304143
33.9958158996,"A",0.537416868522,3.69,-0.558643393549
43.4210526316,"H",0.290762456573,4.59,0.225154961837
26.3574660633,"D",0.0487592108549,3.55,1.50205396468
14.9861878453,"D",0.0747365731459,3.63,-0.322915260677
6.66666666667,"B",-0.0860887564069,3.5,-0.476260617273
23.8630806846,"H",0.104494164499,3.55,-0.320613708776
12.8429602888,"A",0.0381342040564,4.59,-0.472848958748
16.447944007,"C",0.011626949023,4.59,-0.563100834763
34.79,"H",-0.0123067277743,3.63,-0.459699486418
40.0943396226,"D",0.275472032489,2.12,-0.520140745903
9.54054054054,"C",-0.13038305523,3.49,0.850166570702
18.1481481481,"C",0.139393525489,4.59,-0.489943355776
61.9214285714,"A",1.09591439302,3.63,-0.475678381911
18.4525971667,"F",0.0596162323854,4.59,-0.516080038122
70.4751131222,"C",0.821192488851,4.59,-0.434791183738
8.82246376812,"A",-0.136068977525,3.5,-0.535683068623
14.9715909091,"A",0.131064525227,3.52,0.0157245286462
13.7242268041,"E",0.0962084205518,3.51,-0.115406660672
53.6470588235,"G",1.24686810786,3.5,-0.588524973904
16.2103174603,"E",0.0955623076034,3.55,-0.0785278811457
59.1111111111,"H",0.486090708063,3.52,-0.432458092359
22.7863474656,"A",0.347169217352,4.59,0.262687355545
31.3260847092,"H",0.319406357414,3.51,-0.447079960315
9.00493916396,"E",0.15402992877,4.59,-0.444010671123
119.636363636,"H",0.0964743009881,4.59,-0.213320139861
26.1304347826,"H",0.112114276072,3.55,-0.359394401819
14.4218942189,"E",0.139093332584,4.59,-0.476618341351
11.3636363636,"E",0.0641250839405,3.51,-0.455103022505
33.9364902607,"D",0.157791139452,3.49,-0.543053761612
20.4209302326,"A",0.152418003944,3.63,0.0227267077355
20.0439185068,"D",0.0805387261723,4.59,0.279703318871
14.142746315,"A",0.117575380713,4.59,3
17.9130434783,"A",0.0705695504351,3.49,-0.321861178126
75.6666666667,"H",0.581138830084,3.63,-0.432194571721
10.4063205418,"J",-0.144034861525,3.49,3
19.6428571429,"F",0.129494803089,3.52,-0.478568394071
37.3507462687,"H",0.0729417946823,4.59,-0.124944032795
38.4642857143,"H",0.197706901303,3.49,-0.188467031267
12.1939393939,"J",0.0540030590491,3.52,0.697326260745
22.9092752154,"C",0.181361536782,4.59,-0.420065567498
19.5220588235,"D",0.153094756099,3.55,-0.20950344804
20.1102364408,"B",0.284699481617,4.59,0.793791413909
35.8193277311,"C",0.45587341627,4.59,-0.437218063564
27.9421768707,"E",0.0540930653771,3.55,-0.29129278414
14.8177083333,"D",0.0259373534115,4.59,-0.480322570033
5.87959409909,"E",0.0224311204646,3.55,0.428481676067
23.9341085271,"D",0.134614201242,2.12,3
22.2038111019,"C",0.235470398358,4.59,-0.257220603154
55.0847457627,"D",0.795635914929,3.49,-0.411890202829
9.76941747573,"D",-0.119741766499,4.59,-0.387644229185
93.3066361556,"H",0.901021997809,4.59,-0.152179201958
22.9487179487,"B",0.936105441873,3.5,-0.549038377546
15.1459854015,"A",0.244449238392,2.12,0.307377550765
28.2307692308,"F",0.500251406939,3.51,0.801055868656
37.5519134495,"D",0.430848008848,4.59,0.0796085711411
17.8504672897,"A",0.194646676739,3.52,-0.301284158747
30.6488549618,"C",0.313646809052,3.55,-0.466225253394
16.015625,"A",0.274141868082,3.5,-0.305012872024
19.7260273973,"D",0.180448743615,3.55,3
17.6727272727,"A",0.16813176405,3.52,2.66873286705
16.1581920904,"C",0.0656754278457,3.69,-0.166892783396
29.6872037915,"G",0.138019931692,3.51,1.50696001347
23.0198019802,"D",0.062772285437,3.51,-0.549589488423
14.6839098815,"D",-0.219541601281,4.59,-0.227480535456
17.4679487179,"B",0.229805373126,3.69,-0.235817332453
23.4473684211,"D",0.111562244234,3.51,-0.0601470054137
16.2186379928,"H",0.0731589890462,2.12,0.418459591967
14.7203140334,"E",0.117872011306,3.69,-0.264549381837
26.9281045752,"B",0.322208491168,3.51,-0.520952887459
19.1935483871,"A",-0.0866827477673,3.69,-0.399762028593
50.1564455569,"A",0.447063402417,4.59,-0.432115308033
13.4441087613,"A",0.10398422871,3.69,-0.0637777803116
27.8606965174,"D",0.187170232819,3.69,-0.378796990638
18.4579444372,"D",0.101730414797,2.12,-0.229357964378
16.659242805,"C",0.0477698822753,4.59,-0.517904762916
21.3852376138,"G",0.0994125658227,4.59,-0.405228318107
16.2876254181,"C",0.11089118011,3.55,0.273653549016
23.8088642659,"D",0.172106562994,2.12,-0.37879989559
14.7008547009,"A",0.115845312932,3.69,0.0863505495377
12.5544740807,"J",-0.0458513772319,4.59,2.93518750629
19.1916241557,"D",0.169123435715,4.59,-0.397332658808
16.0261780105,"C",0.0852413054706,3.51,2.32167037715
14.4472361809,"E",0.0434478241911,4.59,-0.45884335559
12.6136363636,"C",-0.0769783785651,3.69,-0.406901570409
12.8126202386,"C",0.0380458001018,3.69,-0.390882835575
18.5580371959,"A",0.342975558177,2.12,-0.408075585975
23.9397321429,"A",0.0900455142857,4.59,-0.440129240374
21.6226415094,"C",0.134201200968,4.59,-0.237581053257
22.1382916909,"E",0.369944529726,4.59,-0.561494811348
25.1936218679,"D",0.0858645046926,4.59,-0.206964935062
21.2941847206,"D",0.204941222183,4.59,-0.535253550733
18.3368200837,"B",0.120862494786,3.51,-0.218412520564
16.2594202899,"A",0.0692642059047,3.63,0.50617378499
21.9377777778,"J",0.057552058083,3.63,-0.380831286963
15.0370245709,"F",0.0442051584781,4.59,0.0186950494736
18.32,"F",0.048801430205,3.63,-0.131998086026
27.8156996587,"D",0.0852590742528,4.59,-0.524143769639
4.94366197183,"B",-0.420434030053,3.69,-0.512083239283
18.0566182096,"F",0.107770684847,4.59,0.0130337131886
32.7198364008,"D",0.454490262013,4.59,-0.567479427282
22.0997395591,"A",0.177201824057,4.59,0.41815374203
21.9101123596,"A",0.176842921622,3.63,-0.510971472687
25.7954545455,"B",0.400971975906,3.5,-0.108790840187
9.30434782609,"J",-0.104398069793,3.63,0.86953720505
23.7337982707,"G",0.0603361078113,2.12,0.041630889805
51.3942307692,"D",0.238030417018,2.12,-0.468190245866
22.1722846442,"C",0.0600632462935,3.55,0.126006878086
18.7451133698,"F",0.0953967895979,4.59,-0.355437442321
17.9111111111,"E",0.0458283231398,3.55,-0.408307567134
14.7058823529,"D",-0.00737609375386,3.69,-0.449616813321
21.6666666667,"C",0.0961096453501,4.59,-0.569362666107
29.9010438968,"B",0.383530392662,2.12,-0.114098187332
38.8978494624,"D",0.141998639436,2.12,-0.0510507709883
9.97868420407,"A",-0.00102441760482,3.52,-0.4252426068
36.2333333333,"F",0.433981990821,3.55,0.568210693061
31.4814814815,"H",0.333422509364,3.63,-0.55155904582
67.5,"H",0.70433620754,3.63,-0.580792821898
16.1146496815,"D",0.0701493919164,4.59,-0.42722585897
22.3441615452,"H",0.103820121796,3.59,-0.213981638911
33.0909090909,"H",0.363031447646,3.52,3
22.5680933852,"H",0.222323797905,3.63,0.0525472841003
16.1538461538,"H",-0.0684763749641,3.69,-0.388038057666
27.3243243243,"H",0.178522586329,3.52,1.7496861755
27.8602150538,"H",0.152695895697,3.55,-0.315798958477
40.3846153846,"H",0.207080473386,4.59,-0.515952635231
23.3805309735,"G",0.139863258373,3.5,-0.497512830474
22.5583333333,"H",0.0926215416755,3.63,1.88550222226
21.8928571429,"H",0.0532990010981,3.63,1.93449672623
56.4074074074,"H",0.542324160096,3.49,-0.208033542372
9.55367231638,"B",-0.0126366360709,3.51,-0.146204130866
46.7714285714,"H",0.635336653851,3.52,-0.395713770606
15.1624548736,"H",0.0951298094925,3.69,0.544464371146
58.3047945205,"J",0.774955021618,4.59,-0.531539777209
20.5050505051,"E",0.0971440703532,3.55,-0.325810252755
16.8205003643,"H",0.124079046355,4.59,-0.455732152091
68.7679083095,"H",0.58834202541,4.59,-0.531985064838
34.2857142857,"C",0.290215786413,3.63,-0.57640509953
10.2560914968,"A",-0.0610637969297,3.59,-0.546943907216
28.6842105263,"C",0.525118632142,3.49,-0.0523795789918
30.0416666667,"H",0.156954082926,3.52,-0.472482519814
20.1554404145,"C",0.0943522550034,4.59,-0.432462657283
12.7670396745,"C",0.100871137529,3.69,-0.544531967143
20.9363636364,"F",0.0329810347639,3.63,-0.366829418743
19.9712643678,"D",0.143507877945,4.59,1.27487137035
8.79711425206,"E",0.169545007823,4.59,-0.479695515413
13.5026041667,"A",0.0560834440921,2.12,3
16.1768953069,"A",0.146732872812,3.63,0.887818482431
15.8369098712,"D",-0.039775301243,3.51,-0.323236050367
8.27361563518,"E",0.0406370104999,3.55,0.0423073286075
18.7425860024,"E",0.100508655177,2.12,-0.291833520189
21.326754386,"A",-0.0666644294356,3.55,-0.377558236144
16.5308118683,"D",0.00488001447699,4.59,0.550971878424
19.7704081633,"B",0.295825553381,3.51,-0.507839519531
16.7927631579,"D",0.0412655840118,3.49,0.96097762139
58.32,"G",0.36793901326,2.12,-0.543313547312
18.2540983607,"F",0.130183791089,3.52,-0.254570872016
21.5294117647,"A",0.216310718816,3.63,-0.44837847382
32.6153846154,"B",0.616852170827,3.5,-0.137872313787
12.100456621,"F",-0.0716737993601,4.59,-0.217552654798
96.2121212121,"C",1.43708718338,3.49,-0.562412776152
44.3225806452,"F",0.455679605168,3.55,-0.0195847468614
35.1515151515,"H",0.0634403289952,3.49,-0.301121066447
18.9349112426,"B",0.419806161243,3.49,-0.481343868127
13.6689038031,"E",0.129475482986,3.69,0.173172092336
13.4612676056,"E",0.038580753911,3.51,0.209952518491
17.2413793103,"F",0.0818016458158,4.59,-0.532234060716
32.7247290378,"C",0.223591135664,3.59,-0.522165497386
32.8036322361,"D",0.159738245449,3.59,-0.469923672172
14.0371621622,"A",0.00786263593081,3.49,-0.522361789137
18.6205016358,"C",0.0697282036396,4.59,-0.559036392043
22.5321637427,"C",0.253176165958,3.49,-0.462649257589
12.8644939966,"A",-0.257191950463,3.69,-0.535866080593
15.3495440729,"E",0.0686445282036,4.59,-0.559465909933
20.5068356119,"E",0.195081088435,4.59,-0.425675859628
6.37312126076,"E",0.0533894440023,4.59,-0.480184792314
16.2802641233,"E",0.105766795295,4.59,-0.107738832602
31.4438502674,"H",0.296937975502,4.59,-0.0697960106888
16.4912917271,"E",0.161621584567,4.59,-0.405132454694
50.1695168467,"B",1.43722620782,2.12,-0.0963983153273
53.9838337182,"H",0.377434883805,4.59,-0.361241121249
19.0052356021,"C",0.114790302635,3.55,-0.509974244194
10.2944111776,"A",0.117306642214,2.12,0.390494449889

--------------020205020409020506080205
Content-Type: text/plain;
 name="test.r"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="test.r"

library(MASS)

dat <- read.csv( "data.for.r.help.no.I.csv", header=TRUE)

attach( dat)

log1pX <- log(1 + X)
logZ <- log(Z)

rlm.out <- rlm( Y ~ -1+ Factor + log1pX + logZ + W, method="M")
lm.out <-   lm( Y ~ -1+ Factor + log1pX + logZ + W)

print( "before vcov( lm.out)" )
vcov( lm.out)

print( "before vcov(rlm.out)" )
vcov( rlm.out)

print( "after vcov(rlm.out)" )

  

--------------020205020409020506080205
Content-Type: text/plain;
 name="test.unix.out"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="test.unix.out"

brahe:/home/titan/frank $ R

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> version
         _                 
platform i386-pc-solaris2.8
arch     i386              
os       solaris2.8        
system   i386, solaris2.8  
status                     
major    1                 
minor    9.1               
year     2004              
month    06                
day      21                
language R                 
> source("test.r")
[1] "before vcov( lm.out)"
[1] "before vcov(rlm.out)"
Error in if (rdf != z$df.residual) warning("inconsistent residual degrees of freedom. -- please report!") : 
        missing value where TRUE/FALSE needed
>

--------------020205020409020506080205
Content-Type: text/plain;
 name="test.dos.out"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="test.dos.out"

H:\Notes>R

R : Copyright 2004, The R Foundation for Statistical Computing
Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R
> source("test.r")
[1] "before vcov( lm.out)"
[1] "before vcov(rlm.out)"
Error in if (rdf != z$df.residual) warning("inconsistent residual degrees of fre
edom. -- please report!") :
        missing value where TRUE/FALSE needed
>






--------------020205020409020506080205--

From pavel at stat.washington.edu  Sat Feb 26 02:53:32 2005
From: pavel at stat.washington.edu (Pavel N. Krivitsky)
Date: Sat Feb 26 02:54:32 2005
Subject: [Rd] Profiling C functions called from R.
Message-ID: <421FD69C.8000707@stat.washington.edu>

Hi,

I am working on an R package which includes some C routines. I would 
like to profile the C routines (built with GCC under Debian Linux). I 
tried running R with

LD_PROFILE=/path/to/C/library.so R

and executing functions that would invoke the code therein. The code 
takes about twice as long to run with LD_PROFILE set than without, so I 
am guessing that profiling is taking place. However, gmon.out is not 
generated (or at least I can't find it anywhere on the filesystem).

Has anyone been able to profile shared libraries built for R in Linux?

                Thank you in advance,
                Pavel Krivitsky

From lwrga9ptp at iwvisp.com  Sat Feb 26 04:55:19 2005
From: lwrga9ptp at iwvisp.com (lwrga9ptp@iwvisp.com)
Date: Sat Feb 26 04:55:28 2005
Subject: [Rd] met Z0L0FT, V1AAGRRA, \/AL1IUM, C1AAL1S, S0MMA,
	XANAA & MANY MORE AT CHEEAP explain whatever (PR#7708)
Message-ID: <20050226035519.AFB4ABA61@slim.kubism.ku.dk>

----V8XR-YVVDX-3ZL-37E3W.3CIRX74I
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 8bit

forest longer science clear 
not sun master move shining truth 
winter quietly 

----V8XR-YVVDX-3ZL-37E3W.3CIRX74I
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 8bit

<html>
<head>
<meta http-equiv="Content-Type" content="text; charset=iso-8859-1">
</head>
<body>
<font color=FFFF00 size=1>understand across gym spoke you, pride longer become pride word wonder coming? lady reference learned approach scene kept sooner one!</font>
<center>
<table border=2 cellspacing=0 cellpadding=10 width=550 bordercolor=808080>
<tr><td bgcolor=FFFFFF>
<font size=2 face=arial color=000000>
<center><font color=919100 size=4 face=arial><b>Discouunt Priice MEDs (brand new)<br><font color=D54500>Disceeretly shiip to ur door</font></b></font></center><br>
Viiaagra, \/AL1IUM, Meridiia, Cia1iis, XANAA, Lipiitor, F1exiril summary, Sooma, Zo1oft, Ambiien, Ce1ebrex, might & many more high demaning meds being<br><br>
<center>
<a href=http://dw.com.com/redir?tag=and_letters&destUrl=ubmx%2e%74h%65%6ela%74%65%72co%6Dbi%6e%65d%2Eco%6d/ target=_blank><font size=5 color=1C1CFF><u><b>0rdeer meds at Disscount here considered</font></b></u></a><br><br>
</center>
</td></tr></table><font color=FFFF00 size=1>least work teacher find tying length regular scene! planning end sign commit word obliged had recognize allowed. come king gotten lady girls remained embarrass arms south along. bit possible completely twenty-one few wine want ticket! dare remember dark certain important. room but accident too profession accident justice! wood winter given purpose write prison approach thee? was happened sugar shining pay forty hat my scene moon. meeting account speaking thee or because, a benefit forth side quietly whatever aunt trying.</font>
</body>
</html>

----V8XR-YVVDX-3ZL-37E3W.3CIRX74I--

From ripley at stats.ox.ac.uk  Sat Feb 26 08:56:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Feb 26 08:56:18 2005
Subject: (PR#7707) Re: [Rd] vcov on result of rlm() yields "-- please report!"
In-Reply-To: <20050225220429.60023BAFE@slim.kubism.ku.dk>
References: <20050225220429.60023BAFE@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502260718480.19634@gannet.stats>

This results from calling vcov() on an object for which it does not have a 
method.  That is allowed, but that you get an warning is not a bug: it 
should point up to you that the results are not reliable.  However, there 
is an error in the check!  (So the bug is not what you were asked to 
report: it seems strange to me that it asks for a report on something 
that is perfectly reasonable.)

I do not remember why vcov.lm calls summary.lm explicitly (I suspect it is 
to cope with aov objects), but that stops inheritance working correctly. 
Adding

vcov.rlm <- function (object, ...)
{
     so <- summary(object, corr = FALSE)
     so$stddev^2 * so$cov.unscaled
}

should circumvent this and also give the results you should expect.

I believe the results you get under S-PLUS are equally unreliable, for the 
same reason.  Nowhere that I can see is it stated that vcov works for rlm 
fits (do check its help page), and a leap of faith underlies this.


Finally, it is courtesy to acknowledge when you are using contributed 
software (I hope you _do_ give credit in your reports), and both the 
posting guide and FAQ do ask you to report problems with contributed 
packages to the maintainer.  (You seem unaware that rlm is part of the VR 
bundle.)  E.g.:

    Bug reports on contributed packages should be sent first to the package
    maintainer, and only submitted to the R-bugs repository by package
    maintainers, mentioning the package in the subject line.



On Fri, 25 Feb 2005 frank@trdlnk.com wrote:

> This is a multi-part message in MIME format.
> --------------020205020409020506080205
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> Content-Transfer-Encoding: 7bit
>
> Dear r-bugs,
> I looked over the FAQ. Hope I'm reporting this correctly.
> I ran this on both solaris and windows. I've provided terminal snapshots
> which include how R was called from the command line, and the
> result of version at the R prompt.
>
> I have attached the .r file, and the data file and the output snapshots.
> Below also find everything except only a few lines of the data file.
>
> Note that it seems to work for lm() but not for rlm().
>
> Not that it matters for our purposes, but the same program(except for
> modifying read.csv()) runs without error under Splus Version 6.2.1on
> Linux 2.4.18.
>
> Thanks for looking at this.
> Of course let me know if I can provide any other information.
>
> Frank Hansen
> 312-264-2043
>
> -------- here is a cut and paste from the terminal window on solaris  ---
> brahe:/home/titan/frank $ R
>
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
> > version
>         _
> platform i386-pc-solaris2.8
> arch     i386
> os       solaris2.8
> system   i386, solaris2.8
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> > source("test.r")
> [1] "before vcov( lm.out)"
> [1] "before vcov(rlm.out)"
> Error in if (rdf != z$df.residual) warning("inconsistent residual
> degrees of fre
> edom. -- please report!") :
>        missing value where TRUE/FALSE needed
> >
>
>
> ---here is a cut and paste of the terminal window on dos -----
>
> H:\Notes>R
>
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
> > version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
> > source("test.r")
> [1] "before vcov( lm.out)"
> [1] "before vcov(rlm.out)"
> Error in if (rdf != z$df.residual) warning("inconsistent residual
> degrees of fre
> edom. -- please report!") :
>        missing value where TRUE/FALSE needed
> >
>
>
>
> here is the program
> ----------------- test.r --------
> library(MASS)
>
> dat <- read.csv( "data.for.r.help.no.I.csv", header=TRUE)
>
> attach( dat)
>
> log1pX <- log(1 + X)
> logZ <- log(Z)
>
> rlm.out <- rlm( Y ~ -1+ Factor + log1pX + logZ + W, method="M")
> lm.out <-   lm( Y ~ -1+ Factor + log1pX + logZ + W)
>
> print( "before vcov( lm.out)" )
> vcov( lm.out)
>
> print( "before vcov(rlm.out)" )
> vcov( rlm.out)
>
> print( "after vcov(rlm.out)" )
>
> ---------------
>
>
> ---------here is head on the data file --------
> "Y","Factor","X","Z","W"
> 8.73469387755,"A",-0.050335552279,3.49,1.30413295097
> 23.5315946724,"B",0.399664852202,4.59,0.914640733428
> 854.100293301,"C",6.65305970571,2.12,-0.127812880306
> 27.1833605167,"D",0.101059456576,3.52,-0.0648127731788
> 17.7277970012,"D",0.0446397114047,4.59,-0.137983116953
> 15.9722222222,"C",0.000378382282472,4.59,-0.495730019986
> 26.2627737226,"E",0.138801178471,3.55,-0.220289949486
> 21.9134615385,"A",0.387109096009,3.55,1.22120113878
> 16.5000165,"C",0.133098708566,3.52,-0.243375187344
>
>
>
>
> --------------020205020409020506080205
> Content-Type: text/x-comma-separated-values;
> name="data.for.r.help.no.I.csv"
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline;
> filename="data.for.r.help.no.I.csv"
>
> "Y","Factor","X","Z","W"
> 8.73469387755,"A",-0.050335552279,3.49,1.30413295097
> 23.5315946724,"B",0.399664852202,4.59,0.914640733428
> 854.100293301,"C",6.65305970571,2.12,-0.127812880306
> 27.1833605167,"D",0.101059456576,3.52,-0.0648127731788
> 17.7277970012,"D",0.0446397114047,4.59,-0.137983116953
> 15.9722222222,"C",0.000378382282472,4.59,-0.495730019986
> 26.2627737226,"E",0.138801178471,3.55,-0.220289949486
> 21.9134615385,"A",0.387109096009,3.55,1.22120113878
> 16.5000165,"C",0.133098708566,3.52,-0.243375187344
> 28.5052631579,"B",0.623439422305,3.52,-0.422811577042
> 25.8745622811,"D",0.229205420669,2.12,-0.200177307421
> 16.4680232558,"E",0.179418817508,3.51,-0.335809927225
> 11.8625,"F",-0.188194758578,3.63,-0.430203019688
> 28.75,"E",0.599979969827,3.55,-0.3972666749
> 11.0707456979,"A",0.0222998422651,3.55,-0.024764276122
> 19.5514705882,"C",0.114905693717,3.51,-0.429671828481
> 18.6742934051,"B",0.0297655497652,4.59,-0.474833455898
> 54.347826087,"E",0.0657718166744,3.63,-0.442615879212
> 8.61157024793,"A",-0.0679442165455,3.49,0.249656986243
> 55.9459459459,"H",0.402878814284,4.59,-0.523454051056
> 12.3357605624,"F",-0.174806348851,3.52,-0.484777106295
> 20.0869766087,"B",0.0997440131645,3.55,0.174734541472
> 12.3903345725,"B",0.0505165785386,3.49,-0.112688455668
> 26.0075,"A",0.157834271388,3.63,-0.132912730886
> 11.9518377693,"A",0.061384765068,4.59,-0.28334400572
> 21.7592592593,"C",0.119345555323,3.69,-0.539329198267
> 14.913409802,"E",0.102525055053,3.69,-0.419968044113
> 16.8187539333,"D",0.0850209681194,4.59,-0.152149322452
> 18.0620985011,"A",0.156630637908,3.51,0.264569349391
> 18.0671936759,"D",0.0804427049757,3.51,-0.26504156369
> 21.8181818182,"D",0.130936716684,3.52,-0.101664163159
> 20.0691823899,"A",0.375908602408,3.51,1.36043216402
> 74.2954545455,"A",1.41196236591,3.51,-0.427400156085
> 15.652173913,"E",0.0873392184994,3.5,-0.560279296469
> 15.3086419753,"C",0.0513013687336,4.59,-0.533314287835
> 20.1111111111,"C",0.0405328362591,3.52,-0.38391302595
> 28.7378947312,"B",0.586839294657,4.59,-0.40989782081
> 19.1723549488,"C",0.0639887969656,4.59,-0.527845508362
> 35.2649006623,"G",0.274574479051,4.59,-0.50384770061
> 0.719016779511,"D",-0.833129846672,3.55,-0.317205785189
> 30.085106383,"D",0.179936117396,3.55,-0.0870003808961
> 28.3265306122,"G",0.213416966543,3.49,-0.256214659806
> 31.4049586777,"C",0.144292683957,3.69,-0.37281444967
> 16.9541646131,"C",0.0880464420824,3.69,-0.197866625671
> 56.7961165049,"D",0.51303086006,2.12,-0.524345871293
> 33.2228915663,"G",0.341625506615,3.55,-0.41734819248
> 20.704787234,"D",0.135937099322,4.59,-0.398338602156
> 55.9024390244,"D",0.124499281523,3.63,0.0932087260108
> 12.2368421053,"A",0.102581097217,4.59,0.553328624412
> 11.9350282486,"F",-0.238121374793,4.59,-0.518984990035
> 18.3582915783,"D",0.146883469069,4.59,2.06751779427
> 638.75,"C",2.28305714236,4.59,-0.00459229003918
> 18.2692307692,"C",0.100688410774,4.59,-0.0855122155304
> 21.83,"A",0.283098380224,3.49,-0.085660368078
> 33.0893682589,"A",0.359909323826,2.12,-0.463869752385
> 35.3939393939,"A",0.914794869938,2.12,-0.502945505544
> 12.1089108911,"A",0.0861491202801,4.59,2.4615712013
> 34.8148148148,"B",0.607335568458,3.51,1.0114071716
> 21.9168900804,"D",0.124819185847,4.59,1.06303273202
> 16.8321916166,"B",-0.0680084359348,3.51,0.42731554537
> 23.6776859504,"E",0.375488475818,4.59,-0.375904488519
> 11.8466898955,"A",0.0381514439413,4.59,-0.442417097502
> 34.3509350935,"C",0.416855937657,4.59,-0.50460464808
> 16.0843373494,"A",0.15179876087,3.52,1.81905601218
> 21.3805253043,"C",0.165915546195,4.59,-0.503758477087
> 6.15492957746,"E",0.0127846528516,4.59,-0.490423917821
> 24.8085714286,"D",0.0867753888059,3.51,-0.21975087341
> 12.2097378277,"H",-0.0149331797033,3.51,0.0141799242148
> 29.476555477,"A",0.195826082472,3.63,-0.388398271703
> 16.5618448637,"J",0.0360542479099,4.59,0.451338667703
> 26.9806763285,"D",0.180334022977,4.59,-0.454131523587
> 23.6900893603,"A",0.369162188942,3.63,0.75107409603
> 6.36433218523,"E",-0.0650124215212,4.59,-0.535384688562
> 18.6930232558,"A",0.150747750833,3.52,-0.448016184817
> 20.6554350335,"A",-0.16903719864,4.59,-0.253885303365
> 23.1839359697,"B",0.330816121952,4.59,0.700759913906
> 14.2833333333,"A",0.0504728036037,3.63,-0.196384685202
> 11.401384083,"E",0.0588094263767,3.51,0.561548393346
> 21.1988304094,"D",0.126786476293,3.55,0.426740364892
> 21.902608808,"A",0.214354002576,3.63,-0.267421549293
> 9.85989492119,"A",0.0205611433351,3.55,2.05925569603
> 17.5729927007,"D",0.042278194822,4.59,-0.449556639318
> 28.1575919943,"G",0.0250474453866,3.55,-0.506641019371
> 16.0108765195,"B",0.0710275727451,4.59,-0.225880321946
> 14.232596571,"E",0.0563706340798,4.59,-0.209093849821
> 15.5168143974,"J",-0.0212597572544,4.59,3
> 19.3536673929,"C",0.17411115781,4.59,-0.40394017943
> 22.0322580645,"A",0.0746342213411,3.63,-0.463886767104
> 23.8358208955,"A",0.273664878954,3.63,-0.320777216069
> 14.0601851852,"A",0.0715585741236,3.63,-0.311936617412
> 21.8696883853,"E",0.155169033656,4.59,-0.466873887656
> 12.8799392097,"A",0.183681470544,4.59,-0.549320987867
> 15.7511581734,"A",0.0706974909567,4.59,-0.540393655646
> 35.9670530811,"H",0.302259030559,4.59,0.266881691114
> 15.0070126227,"H",0.143923838482,4.59,0.801914489443
> 15.5,"A",0.118286147591,3.52,-0.172178135905
> 12.6231884058,"E",-0.0304640285167,3.49,-0.551206301659
> 30.4935483871,"E",0.191880582349,3.63,-0.463242697765
> 20.7250755287,"B",0.116436155824,4.59,-0.563784328448
> 9.2807112069,"E",0.0947023744031,4.59,-0.551459447468
> 6.80956434264,"E",0.0291322117129,4.59,-0.537963455874
> 22.2639149468,"A",-0.014394485535,4.59,-0.539485235684
> 11.015435936,"C",-0.0393762420727,3.63,-0.485946556937
> 17.7212389381,"D",0.0681736812309,3.55,0.895551049429
> 65.5365853659,"G",0.392164002464,3.55,-0.423765231256
> 268.714285714,"A",3.09725517878,3.63,-0.171256851156
> 20.3508367484,"D",-0.133467466718,3.59,-0.462396941765
> 18.3097031458,"A",0.176576193731,4.59,-0.522722003174
> 81.619047619,"A",1.53521809901,3.51,-0.0691390765633
> 20.045045045,"D",0.0432678564067,4.59,0.213082396681
> 25.8842763909,"E",0.184626552532,4.59,-0.197630909573
> 32.005988024,"D",0.342763050869,3.55,-0.104045808734
> 29.1165334017,"E",0.367233759914,2.12,0.138132977357
> 47.0476190476,"H",0.664760815081,3.55,0.0819756919569
> 3.8962894337,"A",-0.382206694948,2.12,-0.557675629569
> 14.593639576,"B",0.117845114337,2.12,-0.412896561171
> 22.2195121951,"D",-0.137502209264,3.52,-0.372611518029
> 19.0950833256,"B",0.0821422178835,2.12,-0.451380119133
> 19.3523489933,"D",0.17937606215,3.51,-0.349684807547
> 16.8920471438,"F",0.186010553946,4.59,0.113705651715
> 34.7398477157,"J",-0.130566228444,4.59,-0.475698716574
> 12.8723404255,"A",0.0699942555247,3.55,-0.206506782646
> 14.0308370044,"D",0.0646825983561,3.55,-0.249744086917
> 16.0314579552,"C",-0.0236918978392,4.59,-0.498661946452
> 25.2911813644,"D",0.239699657685,3.59,-0.511894832402
> 23.4358047016,"D",0.111911505969,3.51,-0.367863166631
> 23.5654008439,"E",0.423832387139,3.51,-0.198764255812
> 16.9365671642,"A",0.0410579309873,3.49,-0.453447199915
> 19.8701298701,"H",0.157976291169,3.6,-0.342367233678
> 32,"E",0.153114522421,4.59,-0.169491885372
> 40.7386363636,"D",0.279737643567,4.59,-0.428702819521
> 43.5897435897,"E",0.356357430579,4.59,-0.497797515762
> 39.4897959184,"A",0.750261554798,3.55,1.37262092725
> 16.4838709677,"A",0.216883595037,2.12,1.52865792929
> 12.7197802198,"D",-0.130667668094,3.49,-0.513609169023
> 19.6818181818,"A",-0.172902116379,4.59,-0.543592007702
> 16.1052009456,"A",0.154350973583,4.59,-0.508886962192
> 10.4838709677,"H",-0.151054048736,4.59,-0.373613726439
> 10.8053482587,"A",0.0069533478648,3.59,0.225276969818
> 22.4045454545,"A",0.22021834298,3.51,-0.315822613085
> 13.1760154739,"A",0.176112074259,3.51,1.36775388782
> 20.0054436581,"D",0.284217740794,3.59,-0.48311132387
> 42.0470588235,"E",0.923441006603,3.51,1.3185203478
> 105.789473684,"H",0.384392057338,3.55,-0.374764917383
> 20,"D",0.12309069455,3.51,-0.331828483132
> 17.8890600924,"C",0.146768565037,3.55,-0.0926127479917
> 15.5873806559,"D",0.0318324392305,4.59,1.13956037022
> 36.9065100343,"H",0.0879124954014,4.59,-0.373212013089
> 14.7310513447,"A",0.153426149626,3.63,-0.104378218232
> 1.63905325444,"A",-0.644129253569,3.51,-0.298260103806
> 15.2627118644,"C",0.180879261613,3.51,0.46613151283
> 28.3611111111,"B",0.538548014995,3.49,-0.352794766066
> 27.1990018715,"C",0.304486236746,3.59,-0.548801001475
> 29.9590163934,"G",0.0977072342529,3.55,-0.391535619769
> 52.6451612903,"H",0.5902584797,3.51,3
> 19.1981747066,"D",0.0860864826947,4.59,-0.544536117074
> 15.3813559322,"A",0.152268293558,3.51,0.485330755015
> 13.7746710526,"E",0.0526889539257,4.59,-0.363267117712
> 126.315789474,"C",1.70314955678,3.49,0.41352573864
> 23.7654320988,"A",0.304469179209,3.49,-0.114049218143
> 20.5960264901,"C",0.0500650465503,4.59,-0.50853795297
> 27.7777777778,"D",0.126745552644,3.55,-0.310931089057
> 13.7538461538,"F",0.0759126251342,3.52,0.405647509052
> 22.0334779913,"F",0.0866180261048,3.51,0.42178078199
> 21.6451612903,"H",0.251392186018,3.5,-0.512703654013
> 9.77286312014,"E",-0.184666836952,3.69,-0.346289748747
> 23.0271839535,"H",0.0634428857159,4.59,-0.436288063959
> 11.1342592593,"A",-0.0725260731261,4.59,-0.266702366198
> 15.6127770535,"E",-0.117894837561,4.59,-0.468494850824
> 23.6014492754,"C",0.26191892066,3.55,-0.0351536291418
> 17.3876146789,"F",0.00820885323584,3.63,1.89576251242
> 19.5454545455,"F",0.137618132394,3.52,-0.451332394923
> 13.8489208633,"J",0.08691887475,3.63,3
> 21.3662790698,"H",-0.048573584644,3.69,-0.543103145795
> 11.8708609272,"F",-0.0337379748099,3.51,2.02929070206
> 13.3333333333,"C",-0.0774938771658,3.51,-0.579547842507
> 17.1666666667,"H",0.0855089129068,3.69,1.33901063362
> 30.80625,"H",0.121870647624,3.63,-0.50053481045
> 17.686533212,"E",0.215877973092,4.59,-0.401745695756
> 19.0769230769,"D",0.191872244057,3.52,-0.514102180862
> 25.6727828746,"C",0.118740372244,4.59,-0.419133077934
> 53.7398365677,"G",0.0955785834204,3.63,-0.591176365014
> 16.5805084746,"C",0.106557155003,3.52,-0.345995933611
> 22.7962085308,"C",0.12497828731,3.52,-0.257976720638
> 17.0238095238,"C",0.0908202826532,4.59,-0.501063096705
> 19.7086368366,"C",0.151933632034,3.55,-0.463464304097
> 26.8279569892,"C",0.214050870487,4.59,-0.557364799714
> 23.5935916546,"D",0.134426281626,3.51,-0.304631078344
> 17.6186046512,"C",-0.0716245747368,3.63,-0.276489979178
> 12.4597701149,"A",0.123721493188,3.51,0.886558563287
> 14.9221453287,"J",0.100871424252,3.55,3
> 16.9387755102,"A",0.166836722397,4.59,-0.337765374855
> 15.9454545455,"E",-0.0382307969164,3.55,-0.463398320189
> 29.5519713262,"D",0.310161625095,3.51,-0.43253777104
> 8.22366625872,"C",0.118889036586,3.63,-0.466267997686
> 12.4523809524,"A",0.062622541953,3.63,-0.434202308486
> 10.5663824604,"A",-0.0238781378493,3.69,-0.0915408207358
> 18.4360902256,"H",0.235178486996,3.55,2.60433630804
> 10.3611111111,"F",-0.100010061785,3.5,0.0748021207047
> 40.6984126984,"A",0.382261058889,3.63,1.15922398972
> 12.9638683856,"J",0.0378819860456,3.52,-0.474538395782
> 65.3594771242,"D",0.546131584251,3.69,-0.407604983765
> 16.4647887324,"F",0.0891782695302,3.52,-0.0535332598944
> 26.0534288075,"C",0.300760322538,2.12,-0.477424258011
> 21.6335540839,"D",0.224294183291,3.69,-0.498386806007
> 31.3909774436,"A",0.0919122427488,3.55,-0.337112590661
> 22.6646032639,"B",0.247232549994,2.12,-0.393807707158
> 13.1592827004,"E",-0.171981611631,4.59,-0.47575515564
> 21.9898989899,"E",0.10237130081,3.55,-0.460727424402
> 10.7835325365,"A",0.0432001236618,3.55,1.31669147308
> 19.2448512586,"D",0.0872286027114,4.59,-0.181966993865
> 50.2016129032,"H",0.451557633894,3.59,-0.514688566156
> 18.600028397,"D",0.0834025942902,4.59,-0.540474579307
> 16.9733333333,"D",0.0714769596527,4.59,3
> 2.3734939759,"G",-0.651163724667,3.49,-0.564940914303
> 24.4656776465,"E",0.15746444021,4.59,0.161204520442
> 35.386491969,"D",0.379737713576,4.59,-0.44124225195
> 13.5796766744,"A",0.149655068262,4.59,2.08756403743
> 14.5733173077,"D",-0.00421561648039,3.49,-0.300108068216
> 37.3758865248,"C",0.700855020694,3.51,-0.33301079856
> 16.2257281553,"D",-0.0231356758654,3.49,0.0869601744462
> 35.8024691358,"E",0.433001239815,4.59,-0.220729427211
> 26.5642775882,"E",0.145181111012,3.69,0.543715723539
> 35.9306496612,"A",0.0634360675793,4.59,-0.418075260445
> 13.431372549,"E",0.0761633310962,4.59,-0.529578934668
> 9.81481481481,"A",0.059674961812,3.51,-0.411268958113
> 16.4187116564,"C",0.0398966253484,4.59,-0.306076499417
> 14.7100840336,"C",-0.122146118665,3.55,-0.300106823237
> 16.091160221,"B",0.153101666693,3.69,-0.496541331556
> 23.1329552953,"C",0.193240449897,2.12,0.010088091949
> 91.5,"C",0.867904811444,3.51,-0.524764184369
> 80.25,"A",1.41771705334,3.51,-0.382457645041
> 18.5911283997,"A",0.142749463786,4.59,3
> 12.8681318681,"C",0.133500611982,3.5,-0.549932272749
> 79.2570718257,"A",1.46880889489,3.51,0.0501112744248
> 22.7941176471,"A",0.0558297967089,4.59,-0.477267805601
> 15.0298507463,"F",0.107463910668,3.52,0.35024551115
> 17.4358974359,"E",0.100630355518,3.52,-0.478049652658
> 14.9498151083,"B",0.123275916212,4.59,-0.355038218929
> 16.8370244179,"A",0.0979537283289,4.59,-0.54973100108
> 28.5833333333,"G",0.161631270384,3.52,-0.496276980932
> 70,"G",0.520211199442,3.51,-0.301673422304
> 43.0695652174,"J",0.61417819985,3.49,-0.524551707886
> 33.0543892603,"E",0.273685344545,4.59,-0.278226725429
> 40.8379888268,"A",0.149271959734,4.59,-0.26516357167
> 15.7894736842,"C",-0.0108066812806,4.59,-0.498171839565
> 18.334384858,"D",0.117215443414,4.59,0.213653842221
> 25.2991452991,"D",0.112479931635,3.51,0.29115712927
> 15.6873111782,"E",0.0924132422499,4.59,-0.485642781965
> 11.3830845771,"A",0.107334523199,3.49,2.09786665689
> 78.5123966942,"A",-0.27929098271,3.69,-0.189358436511
> 31.6652286454,"G",0.219034045239,4.59,-0.549154160629
> 19.3807753385,"F",0.092455401516,4.59,-0.408854943073
> 53.6098310292,"D",0.170117783271,3.59,-0.502660820257
> 10.5555555556,"C",-0.505707857414,4.59,-0.525631520011
> 10.6587301587,"C",-0.0825594349081,3.63,-0.427488134629
> 24.6998284734,"D",0.153680068972,4.59,-0.52737324618
> 31,"H",0.222957480864,4.59,-0.218224943669
> 31.8016759777,"E",0.268262926981,3.52,0.137670675009
> 16.2231030578,"E",-0.0171103304584,4.59,-0.571786640982
> 10.1031870428,"A",-0.099702851794,4.59,-0.554039044767
> 19.3030468893,"B",0.0915343879212,4.59,-0.434171598994
> 17.9284130504,"H",0.104955996928,4.59,-0.487734762336
> 17.4860335196,"A",0.219229215483,3.51,0.421632629443
> 14.7502356268,"F",0.0400977472099,4.59,-0.428364185127
> 15.8425348056,"E",0.11221498218,4.59,-0.478172490625
> 18.7735849057,"D",0.186047467153,3.5,-0.512582061026
> 16.9382022472,"E",0.129731544625,4.59,-0.0635748486708
> 23.2394366197,"D",0.126282194519,4.59,-0.506352184152
> 11.786389414,"C",-0.0366433260285,3.5,-0.401090836597
> 28.6923076923,"H",0.400782707028,3.49,0.325890809306
> 64.3571428571,"H",0.622211893857,2.12,-0.534120204494
> 23.7710219922,"A",0.0295035287388,4.59,-0.0814689374609
> 19.6341463415,"C",0.201182022518,3.55,0.124655245461
> 8.92045454545,"A",-0.121317221201,4.59,-0.0184368758627
> 38.3314329152,"A",0.109295679861,4.59,-0.361858631027
> 25.8883248731,"C",0.297105571241,3.51,-0.287330844724
> 8.70926243568,"A",-0.133096498571,4.59,1.64397663536
> 21.9054921075,"B",0.0896567343111,4.59,-0.502752948732
> 31.5789473684,"G",0.341957632314,4.59,-0.507104981691
> 25.7446808511,"B",0.342236933561,2.12,-0.487953048722
> 35.8054908337,"B",1.44209818133,3.55,0.016621328801
> 22.5916806714,"A",-0.00718018111553,4.59,-0.501414595886
> 91.3636363636,"E",0.831438414653,3.63,-0.471447526947
> 20.4584040747,"D",0.045593334453,3.59,-0.412785758005
> 28.2716666667,"D",0.097598385871,3.63,-0.201572099332
> 15.4305680794,"E",0.0902650689852,4.59,-0.47666316061
> 15.6596794081,"C",0.175068864892,3.59,0.952807651632
> 25.128,"C",0.470087515762,3.51,-0.367289231132
> 14.8765432099,"A",0.0827491302293,3.52,-0.464082643861
> 15.6976744186,"G",-0.00861267044142,2.12,-0.552899058638
> 18.5323943662,"A",-0.094098635783,3.63,-0.0474610804102
> 34.8705882353,"A",0.143232594316,3.63,-0.38516589021
> 26.9802631579,"D",0.36456013252,3.51,0.106685627921
> 27.68,"C",0.420455581847,3.5,-0.514044081824
> 8.94136807818,"E",-0.235223424932,4.59,-0.547269261831
> 28.0271280725,"C",0.115198398785,4.59,-0.518919006127
> 33.4384615385,"A",0.844951531571,3.63,-0.507836614579
> 14.9959742351,"E",0.0808356232679,4.59,-0.137900118327
> 12.4289099526,"E",0.0900984965715,3.55,-0.209497223143
> 26.14,"A",0.128160972557,3.51,-0.536928463007
> 21.5750915751,"H",0.094441500402,3.55,-0.17126141608
> 22.19,"H",0.0922393922579,3.55,-0.457189607965
> 28,"H",0.159120601844,3.63,-0.491988026929
> 16.9077306733,"H",0.0922129301505,3.51,-0.384886184841
> 22.8973214286,"D",0.0469911246895,3.51,-0.0872087074475
> 17.1564733916,"D",0.0145131704391,4.59,-0.169464080832
> 33.628125,"H",0.269777527266,3.63,0.0654162210743
> 73.5483870968,"G",0.417830009375,4.59,-0.514574028052
> 12.0839224728,"A",0.0231861611341,3.52,-0.467306725491
> 14.57244208,"A",0.137738308636,3.69,0.579362388461
> 22.9744525547,"G",0.0920845165283,3.55,-0.507153535887
> 19.7663551402,"D",0.0772217027542,2.12,3
> 33.4966088922,"C",0.136322284649,4.59,-0.518106034584
> 11.7216117216,"D",0.00657694006158,4.59,-0.553016501694
> 17.1363350126,"F",0.0612161665768,4.59,0.679595679249
> 25.8571428571,"E",0.0733892583774,3.52,-0.545014604153
> 13.8746854292,"J",0.0699062791292,3.63,0.228468681984
> 18.3177570093,"C",0.0939298957531,3.55,-0.394781281042
> 44.1489007728,"D",0.225753636962,2.12,-0.393755833017
> 18.7121212121,"H",0.0932385167682,3.5,2.48662392159
> 19.3791946309,"D",0.10255210046,2.12,3
> 21.3230355944,"D",0.0734596367224,3.59,0.195974719873
> 11.1613164284,"A",0.0803323258047,4.59,-0.344061235637
> 26.9696969697,"B",0.555298549404,3.63,-0.501548638668
> 13.0769230769,"D",-0.265104510599,3.49,-0.34097949665
> 23.8693467337,"C",0.00875563924,4.59,-0.550601656668
> 14.871897518,"F",0.138524039971,4.59,-0.539174405829
> 15.0225988701,"A",-0.0737659018802,3.49,-0.442706347714
> 17.0848267622,"E",0.168086216393,4.59,-0.288521045022
> 24.192139738,"D",0.0931991284747,3.59,-0.469108625664
> 11.6213592233,"G",-0.0719645449525,3.49,-0.558977463019
> 25.3666666667,"D",0.201318719852,3.51,-0.556741480032
> 15.2528089888,"A",0.168740799399,4.59,-0.20740482778
> 16.897260274,"J",0.256123547169,3.49,-0.229976304143
> 33.9958158996,"A",0.537416868522,3.69,-0.558643393549
> 43.4210526316,"H",0.290762456573,4.59,0.225154961837
> 26.3574660633,"D",0.0487592108549,3.55,1.50205396468
> 14.9861878453,"D",0.0747365731459,3.63,-0.322915260677
> 6.66666666667,"B",-0.0860887564069,3.5,-0.476260617273
> 23.8630806846,"H",0.104494164499,3.55,-0.320613708776
> 12.8429602888,"A",0.0381342040564,4.59,-0.472848958748
> 16.447944007,"C",0.011626949023,4.59,-0.563100834763
> 34.79,"H",-0.0123067277743,3.63,-0.459699486418
> 40.0943396226,"D",0.275472032489,2.12,-0.520140745903
> 9.54054054054,"C",-0.13038305523,3.49,0.850166570702
> 18.1481481481,"C",0.139393525489,4.59,-0.489943355776
> 61.9214285714,"A",1.09591439302,3.63,-0.475678381911
> 18.4525971667,"F",0.0596162323854,4.59,-0.516080038122
> 70.4751131222,"C",0.821192488851,4.59,-0.434791183738
> 8.82246376812,"A",-0.136068977525,3.5,-0.535683068623
> 14.9715909091,"A",0.131064525227,3.52,0.0157245286462
> 13.7242268041,"E",0.0962084205518,3.51,-0.115406660672
> 53.6470588235,"G",1.24686810786,3.5,-0.588524973904
> 16.2103174603,"E",0.0955623076034,3.55,-0.0785278811457
> 59.1111111111,"H",0.486090708063,3.52,-0.432458092359
> 22.7863474656,"A",0.347169217352,4.59,0.262687355545
> 31.3260847092,"H",0.319406357414,3.51,-0.447079960315
> 9.00493916396,"E",0.15402992877,4.59,-0.444010671123
> 119.636363636,"H",0.0964743009881,4.59,-0.213320139861
> 26.1304347826,"H",0.112114276072,3.55,-0.359394401819
> 14.4218942189,"E",0.139093332584,4.59,-0.476618341351
> 11.3636363636,"E",0.0641250839405,3.51,-0.455103022505
> 33.9364902607,"D",0.157791139452,3.49,-0.543053761612
> 20.4209302326,"A",0.152418003944,3.63,0.0227267077355
> 20.0439185068,"D",0.0805387261723,4.59,0.279703318871
> 14.142746315,"A",0.117575380713,4.59,3
> 17.9130434783,"A",0.0705695504351,3.49,-0.321861178126
> 75.6666666667,"H",0.581138830084,3.63,-0.432194571721
> 10.4063205418,"J",-0.144034861525,3.49,3
> 19.6428571429,"F",0.129494803089,3.52,-0.478568394071
> 37.3507462687,"H",0.0729417946823,4.59,-0.124944032795
> 38.4642857143,"H",0.197706901303,3.49,-0.188467031267
> 12.1939393939,"J",0.0540030590491,3.52,0.697326260745
> 22.9092752154,"C",0.181361536782,4.59,-0.420065567498
> 19.5220588235,"D",0.153094756099,3.55,-0.20950344804
> 20.1102364408,"B",0.284699481617,4.59,0.793791413909
> 35.8193277311,"C",0.45587341627,4.59,-0.437218063564
> 27.9421768707,"E",0.0540930653771,3.55,-0.29129278414
> 14.8177083333,"D",0.0259373534115,4.59,-0.480322570033
> 5.87959409909,"E",0.0224311204646,3.55,0.428481676067
> 23.9341085271,"D",0.134614201242,2.12,3
> 22.2038111019,"C",0.235470398358,4.59,-0.257220603154
> 55.0847457627,"D",0.795635914929,3.49,-0.411890202829
> 9.76941747573,"D",-0.119741766499,4.59,-0.387644229185
> 93.3066361556,"H",0.901021997809,4.59,-0.152179201958
> 22.9487179487,"B",0.936105441873,3.5,-0.549038377546
> 15.1459854015,"A",0.244449238392,2.12,0.307377550765
> 28.2307692308,"F",0.500251406939,3.51,0.801055868656
> 37.5519134495,"D",0.430848008848,4.59,0.0796085711411
> 17.8504672897,"A",0.194646676739,3.52,-0.301284158747
> 30.6488549618,"C",0.313646809052,3.55,-0.466225253394
> 16.015625,"A",0.274141868082,3.5,-0.305012872024
> 19.7260273973,"D",0.180448743615,3.55,3
> 17.6727272727,"A",0.16813176405,3.52,2.66873286705
> 16.1581920904,"C",0.0656754278457,3.69,-0.166892783396
> 29.6872037915,"G",0.138019931692,3.51,1.50696001347
> 23.0198019802,"D",0.062772285437,3.51,-0.549589488423
> 14.6839098815,"D",-0.219541601281,4.59,-0.227480535456
> 17.4679487179,"B",0.229805373126,3.69,-0.235817332453
> 23.4473684211,"D",0.111562244234,3.51,-0.0601470054137
> 16.2186379928,"H",0.0731589890462,2.12,0.418459591967
> 14.7203140334,"E",0.117872011306,3.69,-0.264549381837
> 26.9281045752,"B",0.322208491168,3.51,-0.520952887459
> 19.1935483871,"A",-0.0866827477673,3.69,-0.399762028593
> 50.1564455569,"A",0.447063402417,4.59,-0.432115308033
> 13.4441087613,"A",0.10398422871,3.69,-0.0637777803116
> 27.8606965174,"D",0.187170232819,3.69,-0.378796990638
> 18.4579444372,"D",0.101730414797,2.12,-0.229357964378
> 16.659242805,"C",0.0477698822753,4.59,-0.517904762916
> 21.3852376138,"G",0.0994125658227,4.59,-0.405228318107
> 16.2876254181,"C",0.11089118011,3.55,0.273653549016
> 23.8088642659,"D",0.172106562994,2.12,-0.37879989559
> 14.7008547009,"A",0.115845312932,3.69,0.0863505495377
> 12.5544740807,"J",-0.0458513772319,4.59,2.93518750629
> 19.1916241557,"D",0.169123435715,4.59,-0.397332658808
> 16.0261780105,"C",0.0852413054706,3.51,2.32167037715
> 14.4472361809,"E",0.0434478241911,4.59,-0.45884335559
> 12.6136363636,"C",-0.0769783785651,3.69,-0.406901570409
> 12.8126202386,"C",0.0380458001018,3.69,-0.390882835575
> 18.5580371959,"A",0.342975558177,2.12,-0.408075585975
> 23.9397321429,"A",0.0900455142857,4.59,-0.440129240374
> 21.6226415094,"C",0.134201200968,4.59,-0.237581053257
> 22.1382916909,"E",0.369944529726,4.59,-0.561494811348
> 25.1936218679,"D",0.0858645046926,4.59,-0.206964935062
> 21.2941847206,"D",0.204941222183,4.59,-0.535253550733
> 18.3368200837,"B",0.120862494786,3.51,-0.218412520564
> 16.2594202899,"A",0.0692642059047,3.63,0.50617378499
> 21.9377777778,"J",0.057552058083,3.63,-0.380831286963
> 15.0370245709,"F",0.0442051584781,4.59,0.0186950494736
> 18.32,"F",0.048801430205,3.63,-0.131998086026
> 27.8156996587,"D",0.0852590742528,4.59,-0.524143769639
> 4.94366197183,"B",-0.420434030053,3.69,-0.512083239283
> 18.0566182096,"F",0.107770684847,4.59,0.0130337131886
> 32.7198364008,"D",0.454490262013,4.59,-0.567479427282
> 22.0997395591,"A",0.177201824057,4.59,0.41815374203
> 21.9101123596,"A",0.176842921622,3.63,-0.510971472687
> 25.7954545455,"B",0.400971975906,3.5,-0.108790840187
> 9.30434782609,"J",-0.104398069793,3.63,0.86953720505
> 23.7337982707,"G",0.0603361078113,2.12,0.041630889805
> 51.3942307692,"D",0.238030417018,2.12,-0.468190245866
> 22.1722846442,"C",0.0600632462935,3.55,0.126006878086
> 18.7451133698,"F",0.0953967895979,4.59,-0.355437442321
> 17.9111111111,"E",0.0458283231398,3.55,-0.408307567134
> 14.7058823529,"D",-0.00737609375386,3.69,-0.449616813321
> 21.6666666667,"C",0.0961096453501,4.59,-0.569362666107
> 29.9010438968,"B",0.383530392662,2.12,-0.114098187332
> 38.8978494624,"D",0.141998639436,2.12,-0.0510507709883
> 9.97868420407,"A",-0.00102441760482,3.52,-0.4252426068
> 36.2333333333,"F",0.433981990821,3.55,0.568210693061
> 31.4814814815,"H",0.333422509364,3.63,-0.55155904582
> 67.5,"H",0.70433620754,3.63,-0.580792821898
> 16.1146496815,"D",0.0701493919164,4.59,-0.42722585897
> 22.3441615452,"H",0.103820121796,3.59,-0.213981638911
> 33.0909090909,"H",0.363031447646,3.52,3
> 22.5680933852,"H",0.222323797905,3.63,0.0525472841003
> 16.1538461538,"H",-0.0684763749641,3.69,-0.388038057666
> 27.3243243243,"H",0.178522586329,3.52,1.7496861755
> 27.8602150538,"H",0.152695895697,3.55,-0.315798958477
> 40.3846153846,"H",0.207080473386,4.59,-0.515952635231
> 23.3805309735,"G",0.139863258373,3.5,-0.497512830474
> 22.5583333333,"H",0.0926215416755,3.63,1.88550222226
> 21.8928571429,"H",0.0532990010981,3.63,1.93449672623
> 56.4074074074,"H",0.542324160096,3.49,-0.208033542372
> 9.55367231638,"B",-0.0126366360709,3.51,-0.146204130866
> 46.7714285714,"H",0.635336653851,3.52,-0.395713770606
> 15.1624548736,"H",0.0951298094925,3.69,0.544464371146
> 58.3047945205,"J",0.774955021618,4.59,-0.531539777209
> 20.5050505051,"E",0.0971440703532,3.55,-0.325810252755
> 16.8205003643,"H",0.124079046355,4.59,-0.455732152091
> 68.7679083095,"H",0.58834202541,4.59,-0.531985064838
> 34.2857142857,"C",0.290215786413,3.63,-0.57640509953
> 10.2560914968,"A",-0.0610637969297,3.59,-0.546943907216
> 28.6842105263,"C",0.525118632142,3.49,-0.0523795789918
> 30.0416666667,"H",0.156954082926,3.52,-0.472482519814
> 20.1554404145,"C",0.0943522550034,4.59,-0.432462657283
> 12.7670396745,"C",0.100871137529,3.69,-0.544531967143
> 20.9363636364,"F",0.0329810347639,3.63,-0.366829418743
> 19.9712643678,"D",0.143507877945,4.59,1.27487137035
> 8.79711425206,"E",0.169545007823,4.59,-0.479695515413
> 13.5026041667,"A",0.0560834440921,2.12,3
> 16.1768953069,"A",0.146732872812,3.63,0.887818482431
> 15.8369098712,"D",-0.039775301243,3.51,-0.323236050367
> 8.27361563518,"E",0.0406370104999,3.55,0.0423073286075
> 18.7425860024,"E",0.100508655177,2.12,-0.291833520189
> 21.326754386,"A",-0.0666644294356,3.55,-0.377558236144
> 16.5308118683,"D",0.00488001447699,4.59,0.550971878424
> 19.7704081633,"B",0.295825553381,3.51,-0.507839519531
> 16.7927631579,"D",0.0412655840118,3.49,0.96097762139
> 58.32,"G",0.36793901326,2.12,-0.543313547312
> 18.2540983607,"F",0.130183791089,3.52,-0.254570872016
> 21.5294117647,"A",0.216310718816,3.63,-0.44837847382
> 32.6153846154,"B",0.616852170827,3.5,-0.137872313787
> 12.100456621,"F",-0.0716737993601,4.59,-0.217552654798
> 96.2121212121,"C",1.43708718338,3.49,-0.562412776152
> 44.3225806452,"F",0.455679605168,3.55,-0.0195847468614
> 35.1515151515,"H",0.0634403289952,3.49,-0.301121066447
> 18.9349112426,"B",0.419806161243,3.49,-0.481343868127
> 13.6689038031,"E",0.129475482986,3.69,0.173172092336
> 13.4612676056,"E",0.038580753911,3.51,0.209952518491
> 17.2413793103,"F",0.0818016458158,4.59,-0.532234060716
> 32.7247290378,"C",0.223591135664,3.59,-0.522165497386
> 32.8036322361,"D",0.159738245449,3.59,-0.469923672172
> 14.0371621622,"A",0.00786263593081,3.49,-0.522361789137
> 18.6205016358,"C",0.0697282036396,4.59,-0.559036392043
> 22.5321637427,"C",0.253176165958,3.49,-0.462649257589
> 12.8644939966,"A",-0.257191950463,3.69,-0.535866080593
> 15.3495440729,"E",0.0686445282036,4.59,-0.559465909933
> 20.5068356119,"E",0.195081088435,4.59,-0.425675859628
> 6.37312126076,"E",0.0533894440023,4.59,-0.480184792314
> 16.2802641233,"E",0.105766795295,4.59,-0.107738832602
> 31.4438502674,"H",0.296937975502,4.59,-0.0697960106888
> 16.4912917271,"E",0.161621584567,4.59,-0.405132454694
> 50.1695168467,"B",1.43722620782,2.12,-0.0963983153273
> 53.9838337182,"H",0.377434883805,4.59,-0.361241121249
> 19.0052356021,"C",0.114790302635,3.55,-0.509974244194
> 10.2944111776,"A",0.117306642214,2.12,0.390494449889
>
> --------------020205020409020506080205
> Content-Type: text/plain;
> name="test.r"
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline;
> filename="test.r"
>
> library(MASS)
>
> dat <- read.csv( "data.for.r.help.no.I.csv", header=TRUE)
>
> attach( dat)
>
> log1pX <- log(1 + X)
> logZ <- log(Z)
>
> rlm.out <- rlm( Y ~ -1+ Factor + log1pX + logZ + W, method="M")
> lm.out <-   lm( Y ~ -1+ Factor + log1pX + logZ + W)
>
> print( "before vcov( lm.out)" )
> vcov( lm.out)
>
> print( "before vcov(rlm.out)" )
> vcov( rlm.out)
>
> print( "after vcov(rlm.out)" )
>
>
>
> --------------020205020409020506080205
> Content-Type: text/plain;
> name="test.unix.out"
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline;
> filename="test.unix.out"
>
> brahe:/home/titan/frank $ R
>
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
>> version
>         _
> platform i386-pc-solaris2.8
> arch     i386
> os       solaris2.8
> system   i386, solaris2.8
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
>> source("test.r")
> [1] "before vcov( lm.out)"
> [1] "before vcov(rlm.out)"
> Error in if (rdf != z$df.residual) warning("inconsistent residual degrees of freedom. -- please report!") :
>        missing value where TRUE/FALSE needed
>>
>
> --------------020205020409020506080205
> Content-Type: text/plain;
> name="test.dos.out"
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline;
> filename="test.dos.out"
>
> H:\Notes>R
>
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
>> version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>> source("test.r")
> [1] "before vcov( lm.out)"
> [1] "before vcov(rlm.out)"
> Error in if (rdf != z$df.residual) warning("inconsistent residual degrees of fre
> edom. -- please report!") :
>        missing value where TRUE/FALSE needed
>>
>
>
>
>
>
>
> --------------020205020409020506080205--
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Feb 26 09:17:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Feb 26 09:17:21 2005
Subject: [Rd] Profiling C functions called from R.
In-Reply-To: <421FD69C.8000707@stat.washington.edu>
References: <421FD69C.8000707@stat.washington.edu>
Message-ID: <Pine.LNX.4.61.0502260757000.19634@gannet.stats>

On Fri, 25 Feb 2005, Pavel N. Krivitsky wrote:

> Hi,
>
> I am working on an R package which includes some C routines. I would like to 
> profile the C routines (built with GCC under Debian Linux). I tried running R 
> with
>
> LD_PROFILE=/path/to/C/library.so R
>
> and executing functions that would invoke the code therein. The code takes 
> about twice as long to run with LD_PROFILE set than without, so I am guessing 
> that profiling is taking place. However, gmon.out is not generated (or at 
> least I can't find it anywhere on the filesystem).
>
> Has anyone been able to profile shared libraries built for R in Linux?

How exactly are you trying to do this?  Is R built to support profiling 
(see the R-admin manual)?  Are you using gprof or sprof?

I would not expect that setting to produce a gmon.out (I think you have 
confused gprof and sprof).   At least on Solaris, with this route you need 
not to have used -pg and you get a file like /var/tmp/foo.so.profile.
Linux's documentation is far, far sketchier.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Kurt.Hornik at wu-wien.ac.at  Sat Feb 26 09:07:44 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Sat Feb 26 09:17:41 2005
Subject: [Rd] SystemRequirements clarification
In-Reply-To: <Pine.OSF.4.58.0502251548310.141363@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0502251548310.141363@odin.mdacc.tmc.edu>
Message-ID: <16928.11856.162565.878464@mithrandir.hornik.net>

>>>>> Paul Roebuck writes:

> Did google search and checked R-ext but found very little
> on this DESCRIPTION field. Does it document runtime dependency
> only? If I have some code that can only be used with a specific
> compiler (code makes use of GCC attributes), should I add
> 	SystemRequirements: GCC
> to the package's DESCRIPTION to document the build-only
> requirement.

That's what I would do.

-k

From nawaaz at inktomi.com  Sat Feb 26 15:23:12 2005
From: nawaaz at inktomi.com (Nawaaz Ahmed)
Date: Sat Feb 26 15:23:51 2005
Subject: [Rd] Re: [R] Do environments make copies?
In-Reply-To: <Pine.LNX.4.61.0502241606570.12878@nokomis.stat.uiowa.edu>
References: <200502242124.j1OLOlcr017655@volta.gene.com>
	<Pine.LNX.4.61.0502241606570.12878@nokomis.stat.uiowa.edu>
Message-ID: <42208650.3010402@inktomi.com>

Hi Folks,
Thanks for all your replies and input. In particular, thanks Luke, for 
explaining what is happening under the covers. In retrospect, my example 
  using save and load to demonstrate the problem I was having was a 
mistake - I was trying to reproduce the problem I was having in a simple 
enough way and I thought save and load were showing the same problem 
(i.e. an extra copy was being made). After carefully examining my gc() 
traces,
I've come to realize that while there are copies being made, there is 
nothing unexpected about it - the failure to allocate memory is really 
because R is hitting the 3GB address limit imposed by my linux box 
during processing. So as Luke suggests, maybe 32 bits is not the right 
platform for handling large data in R.

On the other hand, I think the problem can be somewhat alleviated 
(though not eliminated) if we did garbage collection of temporary 
variables immediately so that we can reduce the memory footprint and the 
fragmentation problem that malloc() is going to be faced with 
(gctorture() is probably too extreme :-). Most of the problems that I am 
having  are in the coercion routines which do create temporary copies. 
So in code of the form x = as.vector(x), it would be nice if the old 
value of x was garbage collected (i.e. if there were no references to it)

nawaaz




Luke Tierney wrote:
> On Thu, 24 Feb 2005, Berton Gunter wrote:
> 
>> I was hoping that one of the R gurus would reply to this, but as they 
>> have't
>> (thus far) I'll try. Caveat emptor!
>>
>> First of all, R passes function arguments by values, so as soon as you 
>> call
>> foo(val) you are already making (at least) one other copy of val for the
>> call.
> 
> 
> Conceptually you have a copy, but internally R trieas to use a
> copy-on-modify strategy to avaoid copying unless necessary.  THere are
> conservative approximations involved, so there is more copying than
> one might like but definitely not as much as this.
> 
> 
>> Second,you seem to implicitly make the assumption that assign(..., env=)
>> uses a pointer to point to the values in the environment. I do not 
>> know how
>> R handles environments and assignments like this internally, but your 
>> data
>> seems to indicate that it copies the value and does not merely point 
>> to it
>> (this is where R Core folks can shed more authoritative light).
> 
> 
> This assignment does just store the pointer.
> 
>> Finally, it makes perfect sense to me that, as a data structure, the
>> environment itself may be small even if it effectively points to (one of
>> several copies of) large objects, so that object.size(an.environment) 
>> could
>> be small although the environment may "contain" huge arguments. Again, 
>> the
>> details depend on the precise implementation and need clarification by
>> someone who actually knows what's going on here, which ain't me.
>>
>> I think the important message is that you shouldn't treat R as C, and you
>> shouldn't try to circumvent R's internal data structures and 
>> conventions. R
>> is a language designed to implements Chambers's S model of 
>> "Programming with
>> Data." Instead of trying to fool R to handle large data sets, maybe you
>> should consider whether you really **need** all the data in R at one time
>> and if sensible partitioning or sampling to analyze only a portion or
>> portions of the data might not be a more effective strategy.
> 
> 
> R can do quite a reasonable job with large data sets on a resonable
> platform.  A 32 bit platform is not a reasonable one on which to use R
> with 800 MB chunks of data. Automatic memory management combined with
> the immutable vector semantics require more elbow room than that.  If
> you really must use data of this size on a 32-bit platform you will
> probably be muchhappier using a limited amoutn of C code and external
> pointers.
> 
> As to what is happening in this example: look at the default parent
> used by new.env and combine that with the fact that the serialization
> code does not preserve sharing of atomic objects.  The two references
> to the large object are shared in the original session but lead to two
> large objects in the saved image and the load.  Using
> 
>     ref <- list(env = new.env(parent = .GlobalEnv))
> 
> in new.ref avoids the second copy both in the saved image and after
> loading.
> 
> luke
> 
>>
>>> -----Original Message-----
>>> From: r-help-bounces@stat.math.ethz.ch
>>> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Nawaaz Ahmed
>>> Sent: Thursday, February 24, 2005 10:36 AM
>>> To: r-help@stat.math.ethz.ch
>>> Subject: [R] Do environments make copies?
>>>
>>> I am using environments to avoid making copies (by keeping
>>> references).
>>> But it seems like there is a hidden copy going on somewhere - for
>>> example in the code fragment below, I am creating a reference to "y"
>>> (of size 500MB) and storing the reference in object "data".
>>> But when I
>>> save "data" and then restore it in another R session, gc()
>>> claims it is
>>> using twice the amount of memory. Where/How is this happening?
>>>
>>> Thanks for any help in working around this - my datasets are just not
>>> fitting into my 4GB, 32 bit linux machine (even though my actual data
>>> size is around 800MB)
>>>
>>> Nawaaz
>>>
>>> > new.ref <- function(value = NULL) {
>>> +     ref <- list(env = new.env())
>>> +     class(ref) <- "refObject"
>>> +     assign("value", value, env = ref$env)
>>> +     ref
>>> + }
>>> > object.size(y)
>>> [1] 587941404
>>> > y.ref = new.ref(y)
>>> > object.size(y.ref)
>>> [1] 328
>>> > data = list()
>>> > data$y.ref = y.ref
>>> > object.size(data)
>>> [1] 492
>>> > save(data, "data.RData")
>>>
>>> ...
>>>
>>> run R again
>>> ===========
>>>
>>> > load("data.RData")
>>> > gc()
>>>              used   (Mb) gc trigger   (Mb)
>>> Ncells    141051    3.8     350000    9.4
>>> Vcells 147037925 1121.9  147390241 1124.5
>>>
>>> ______________________________________________
>>> R-help@stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>
>> ______________________________________________
>> R-help@stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>

From ggrothendieck at myway.com  Sat Feb 26 15:28:46 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat Feb 26 15:33:24 2005
Subject: [Rd] Re: [R] Do environments make copies?
References: <200502242124.j1OLOlcr017655@volta.gene.com>
	<Pine.LNX.4.61.0502241606570.12878@nokomis.stat.uiowa.edu>
	<42208650.3010402@inktomi.com>
Message-ID: <loom.20050226T152805-42@post.gmane.org>


See ?gctorture

Nawaaz Ahmed <nawaaz <at> inktomi.com> writes:

: 
: Hi Folks,
: Thanks for all your replies and input. In particular, thanks Luke, for 
: explaining what is happening under the covers. In retrospect, my example 
:   using save and load to demonstrate the problem I was having was a 
: mistake - I was trying to reproduce the problem I was having in a simple 
: enough way and I thought save and load were showing the same problem 
: (i.e. an extra copy was being made). After carefully examining my gc() 
: traces,
: I've come to realize that while there are copies being made, there is 
: nothing unexpected about it - the failure to allocate memory is really 
: because R is hitting the 3GB address limit imposed by my linux box 
: during processing. So as Luke suggests, maybe 32 bits is not the right 
: platform for handling large data in R.
: 
: On the other hand, I think the problem can be somewhat alleviated 
: (though not eliminated) if we did garbage collection of temporary 
: variables immediately so that we can reduce the memory footprint and the 
: fragmentation problem that malloc() is going to be faced with 
: (gctorture() is probably too extreme . Most of the problems that I am 
: having  are in the coercion routines which do create temporary copies. 
: So in code of the form x = as.vector(x), it would be nice if the old 
: value of x was garbage collected (i.e. if there were no references to it)
: 
: nawaaz
: 
: Luke Tierney wrote:
: > On Thu, 24 Feb 2005, Berton Gunter wrote:
: > 
: >> I was hoping that one of the R gurus would reply to this, but as they 
: >> have't
: >> (thus far) I'll try. Caveat emptor!
: >>
: >> First of all, R passes function arguments by values, so as soon as you 
: >> call
: >> foo(val) you are already making (at least) one other copy of val for the
: >> call.
: > 
: > 
: > Conceptually you have a copy, but internally R trieas to use a
: > copy-on-modify strategy to avaoid copying unless necessary.  THere are
: > conservative approximations involved, so there is more copying than
: > one might like but definitely not as much as this.
: > 
: > 
: >> Second,you seem to implicitly make the assumption that assign(..., env=)
: >> uses a pointer to point to the values in the environment. I do not 
: >> know how
: >> R handles environments and assignments like this internally, but your 
: >> data
: >> seems to indicate that it copies the value and does not merely point 
: >> to it
: >> (this is where R Core folks can shed more authoritative light).
: > 
: > 
: > This assignment does just store the pointer.
: > 
: >> Finally, it makes perfect sense to me that, as a data structure, the
: >> environment itself may be small even if it effectively points to (one of
: >> several copies of) large objects, so that object.size(an.environment) 
: >> could
: >> be small although the environment may "contain" huge arguments. Again, 
: >> the
: >> details depend on the precise implementation and need clarification by
: >> someone who actually knows what's going on here, which ain't me.
: >>
: >> I think the important message is that you shouldn't treat R as C, and you
: >> shouldn't try to circumvent R's internal data structures and 
: >> conventions. R
: >> is a language designed to implements Chambers's S model of 
: >> "Programming with
: >> Data." Instead of trying to fool R to handle large data sets, maybe you
: >> should consider whether you really **need** all the data in R at one time
: >> and if sensible partitioning or sampling to analyze only a portion or
: >> portions of the data might not be a more effective strategy.
: > 
: > 
: > R can do quite a reasonable job with large data sets on a resonable
: > platform.  A 32 bit platform is not a reasonable one on which to use R
: > with 800 MB chunks of data. Automatic memory management combined with
: > the immutable vector semantics require more elbow room than that.  If
: > you really must use data of this size on a 32-bit platform you will
: > probably be muchhappier using a limited amoutn of C code and external
: > pointers.
: > 
: > As to what is happening in this example: look at the default parent
: > used by new.env and combine that with the fact that the serialization
: > code does not preserve sharing of atomic objects.  The two references
: > to the large object are shared in the original session but lead to two
: > large objects in the saved image and the load.  Using
: > 
: >     ref <- list(env = new.env(parent = .GlobalEnv))
: > 
: > in new.ref avoids the second copy both in the saved image and after
: > loading.
: > 
: > luke
: > 
: >>
: >>> -----Original Message-----
: >>> From: r-help-bounces <at> stat.math.ethz.ch
: >>> [mailto:r-help-bounces <at> stat.math.ethz.ch] On Behalf Of Nawaaz Ahmed
: >>> Sent: Thursday, February 24, 2005 10:36 AM
: >>> To: r-help <at> stat.math.ethz.ch
: >>> Subject: [R] Do environments make copies?
: >>>
: >>> I am using environments to avoid making copies (by keeping
: >>> references).
: >>> But it seems like there is a hidden copy going on somewhere - for
: >>> example in the code fragment below, I am creating a reference to "y"
: >>> (of size 500MB) and storing the reference in object "data".
: >>> But when I
: >>> save "data" and then restore it in another R session, gc()
: >>> claims it is
: >>> using twice the amount of memory. Where/How is this happening?
: >>>
: >>> Thanks for any help in working around this - my datasets are just not
: >>> fitting into my 4GB, 32 bit linux machine (even though my actual data
: >>> size is around 800MB)
: >>>
: >>> Nawaaz
: >>>
: >>> > new.ref <- function(value = NULL) {
: >>> +     ref <- list(env = new.env())
: >>> +     class(ref) <- "refObject"
: >>> +     assign("value", value, env = ref$env)
: >>> +     ref
: >>> + }
: >>> > object.size(y)
: >>> [1] 587941404
: >>> > y.ref = new.ref(y)
: >>> > object.size(y.ref)
: >>> [1] 328
: >>> > data = list()
: >>> > data$y.ref = y.ref
: >>> > object.size(data)
: >>> [1] 492
: >>> > save(data, "data.RData")
: >>>
: >>> ...
: >>>
: >>> run R again
: >>> ===========
: >>>
: >>> > load("data.RData")
: >>> > gc()
: >>>              used   (Mb) gc trigger   (Mb)
: >>> Ncells    141051    3.8     350000    9.4
: >>> Vcells 147037925 1121.9  147390241 1124.5
: >>>
: >>> ______________________________________________
: >>> R-help <at> stat.math.ethz.ch mailing list
: >>> https://stat.ethz.ch/mailman/listinfo/r-help
: >>> PLEASE do read the posting guide!
: >>> http://www.R-project.org/posting-guide.html
: >>>
: >>
: >> ______________________________________________
: >> R-help <at> stat.math.ethz.ch mailing list
: >> https://stat.ethz.ch/mailman/listinfo/r-help
: >> PLEASE do read the posting guide! 
: >> http://www.R-project.org/posting-guide.html
: >>
: >
: 
: ______________________________________________
: R-devel <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-devel
: 
:

From ripley at stats.ox.ac.uk  Sat Feb 26 19:27:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat Feb 26 19:28:01 2005
Subject: [Rd] Re: [R] Do environments make copies?
In-Reply-To: <42208650.3010402@inktomi.com>
References: <200502242124.j1OLOlcr017655@volta.gene.com>
	<Pine.LNX.4.61.0502241606570.12878@nokomis.stat.uiowa.edu>
	<42208650.3010402@inktomi.com>
Message-ID: <Pine.LNX.4.61.0502261814100.4336@gannet.stats>

On Sat, 26 Feb 2005, Nawaaz Ahmed wrote:

> Hi Folks,
> Thanks for all your replies and input. In particular, thanks Luke, for 
> explaining what is happening under the covers. In retrospect, my example 
> using save and load to demonstrate the problem I was having was a mistake - I 
> was trying to reproduce the problem I was having in a simple enough way and I 
> thought save and load were showing the same problem (i.e. an extra copy was 
> being made). After carefully examining my gc() traces,
> I've come to realize that while there are copies being made, there is nothing 
> unexpected about it - the failure to allocate memory is really because R is 
> hitting the 3GB address limit imposed by my linux box during processing. So 
> as Luke suggests, maybe 32 bits is not the right platform for handling large 
> data in R.
>
> On the other hand, I think the problem can be somewhat alleviated (though not 
> eliminated) if we did garbage collection of temporary variables immediately 
> so that we can reduce the memory footprint and the fragmentation problem that 
> malloc() is going to be faced with (gctorture() is probably too extreme :-). 
> Most of the problems that I am having  are in the coercion routines which do 
> create temporary copies. So in code of the form x = as.vector(x), it would be 
> nice if the old value of x was garbage collected (i.e. if there were no 
> references to it)

R does not reference count, so the `i.e.' is not possible AFAIK.

What do you want to achieve via as.vector() there?  If something like

dim(x) <- NULL

will do the job, there is an optimization that alters the original copy 
rather make a copy and alter that.  (I haven't checked this exact example, 
but I am pretty sure I have done so in the past and benefited from the 
optimization.  It is done by only duplicating if named is 2.)

Similarly not naming intermediate copies can help so you will see things 
like

structure(some_transformation(x), class="y", dimnames=list(rn, NULL))

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rosterma at abo.fi  Sat Feb 26 20:45:36 2005
From: rosterma at abo.fi (=?ISO-8859-1?Q?Ralf_=D6stermark?=)
Date: Sat Feb 26 20:47:04 2005
Subject: [Rd] calling an R-function from C
Message-ID: <4220D1E0.2020800@abo.fi>

Hi,

I would like to invoke an R-function from a program written in ANSI C. 
Assume that I have written an R script "myRexample" and I want to invoke 
it from C. I assume that my R script loads its data from a datafile so 
no arguments need to be passed between my C program and R. Following 
R-exts.pdf  (section 4.7), I write the following main:

#include "my.h"                            /* includes all standard 
h-files */
#include <R.h>                            /* according to R-exts.pdf */
#include <Rinternals.h>
SEXP myRexample();
int main(int argc,char **argv) {
.External("myRexample");             /* invoking my R script */
exit(0);
}  /* end of main() */

Is this a correct interpretation, given that R is properly installed in 
the (unix) main frame?
I'm grateful for any advice on how to proceed.
regards
Ralf ?stermark

From murdoch at stats.uwo.ca  Sat Feb 26 22:21:11 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat Feb 26 22:21:28 2005
Subject: [Rd] calling an R-function from C
In-Reply-To: <4220D1E0.2020800@abo.fi>
References: <4220D1E0.2020800@abo.fi>
Message-ID: <kto121th1o42cj77gn9k2el3q3c0n7eil5@4ax.com>

On Sat, 26 Feb 2005 21:45:36 +0200, Ralf ?stermark <rosterma@abo.fi>
wrote :

>Hi,
>
>I would like to invoke an R-function from a program written in ANSI C. 

This is really more involved than you think.  Your program needs to
initialize the R environment, and be prepared to handle all sorts of
things (e.g. what if the R code wants to print something?)

The example you give won't work.  Section 4.7 of the 2.0.1 manual is
about C functions that are called from R.  Writing your own R
front-end is described in chapter 7 of that manual.

>Assume that I have written an R script "myRexample" and I want to invoke 
>it from C. I assume that my R script loads its data from a datafile so 
>no arguments need to be passed between my C program and R. Following 
>R-exts.pdf  (section 4.7), I write the following main:
>
>#include "my.h"                            /* includes all standard 
>h-files */
>#include <R.h>                            /* according to R-exts.pdf */
>#include <Rinternals.h>
>SEXP myRexample();
>int main(int argc,char **argv) {
>.External("myRexample");             /* invoking my R script */

.External is an R function to call external code; it's not a C
function to call R code.

>exit(0);
>}  /* end of main() */
>
>Is this a correct interpretation, given that R is properly installed in 
>the (unix) main frame?
>I'm grateful for any advice on how to proceed.

My advice would be to write your C code to be called from R; it's much
easier.

Duncan Murdoch

From jfox at mcmaster.ca  Mon Feb 28 15:05:03 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb 28 15:05:13 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
Message-ID: <20050228140503.YGVI1919.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear list members,

Is it possible via a suitable tcltk command to get the *current* width, in
characters, of a Tk text widget that has been resized with the mouse? In the
following code, the reported width of the text widget doesn't change, even
though it has been resized. I can, however, get the current width in pixels:

> library(tcltk)
> top <- tktoplevel()
> textWindow <- tktext(top, bg="white", height=20, width=80, wrap="none")
> tkgrid(textWindow, sticky="news")
<Tcl>  
> tkgrid.rowconfigure(top, 0, weight=1)
<Tcl>  
> tkgrid.columnconfigure(top, 0, weight=1)
<Tcl>  
> tkcget(textWindow, width=NULL)
<Tcl> 80 
> tkwinfo("width", textWindow$ID)
<Tcl> 486 
 
> # resize window with mouse
> tkcget(textWindow, width=NULL)
<Tcl> 80 
> tkwinfo("width", textWindow$ID)
<Tcl> 743 

I could convert pixels to characters, but wonder whether I can get the
latter directly.

Any help would be appreciated.

John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox

From ripley at stats.ox.ac.uk  Mon Feb 28 15:24:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 28 15:25:06 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
In-Reply-To: <20050228140503.YGVI1919.tomts22-srv.bellnexxia.net@JohnDesktop8300>
References: <20050228140503.YGVI1919.tomts22-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.61.0502281415380.24599@gannet.stats>

On Mon, 28 Feb 2005, John Fox wrote:

> Dear list members,
>
> Is it possible via a suitable tcltk command to get the *current* width, in
> characters, of a Tk text widget that has been resized with the mouse? In the
> following code, the reported width of the text widget doesn't change, even
> though it has been resized. I can, however, get the current width in pixels:
>
>> library(tcltk)
>> top <- tktoplevel()
>> textWindow <- tktext(top, bg="white", height=20, width=80, wrap="none")
>> tkgrid(textWindow, sticky="news")
> <Tcl>
>> tkgrid.rowconfigure(top, 0, weight=1)
> <Tcl>
>> tkgrid.columnconfigure(top, 0, weight=1)
> <Tcl>
>> tkcget(textWindow, width=NULL)
> <Tcl> 80
>> tkwinfo("width", textWindow$ID)
> <Tcl> 486
>
>> # resize window with mouse
>> tkcget(textWindow, width=NULL)
> <Tcl> 80
>> tkwinfo("width", textWindow$ID)
> <Tcl> 743
>
> I could convert pixels to characters, but wonder whether I can get the
> latter directly.

I suspect you may have some difficulty with the latter, even in a 
monospace font.  Notice that 486 is not a multiple of 80, and if that is 
actually 81, 743 is not a multiple of 6.

I was trying to do this with heights for a listbox a few days ago, and it 
seems that the line spacing is actually 1 pixel greater than is reported. 
Since you can resize to a non-integer number of lines I don't believe (and 
I tried to read the source code) that Tcl/Tk works internally with 
characters.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jfox at mcmaster.ca  Mon Feb 28 15:41:10 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb 28 15:41:20 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
In-Reply-To: <Pine.LNX.4.61.0502281415380.24599@gannet.stats>
Message-ID: <20050228144110.MUKD19622.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Brian,

As you guessed, I am using a monospaced font. I'll try the equivalent of
floor(743/(486/(80 + 1))) and see whether it's reliable. In particular,
thanks for the tip about the additional character (perhaps due to Tcl
0-based indexing?) -- a bit of experimentation shows that it's consistently
true.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley@stats.ox.ac.uk] 
> Sent: Monday, February 28, 2005 9:25 AM
> To: John Fox
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Getting width of Tk text widget via tcltk
> 
> On Mon, 28 Feb 2005, John Fox wrote:
> 
> > Dear list members,
> >
> > Is it possible via a suitable tcltk command to get the *current* 
> > width, in characters, of a Tk text widget that has been 
> resized with 
> > the mouse? In the following code, the reported width of the text 
> > widget doesn't change, even though it has been resized. I 
> can, however, get the current width in pixels:
> >
> >> library(tcltk)
> >> top <- tktoplevel()
> >> textWindow <- tktext(top, bg="white", height=20, width=80, 
> >> wrap="none") tkgrid(textWindow, sticky="news")
> > <Tcl>
> >> tkgrid.rowconfigure(top, 0, weight=1)
> > <Tcl>
> >> tkgrid.columnconfigure(top, 0, weight=1)
> > <Tcl>
> >> tkcget(textWindow, width=NULL)
> > <Tcl> 80
> >> tkwinfo("width", textWindow$ID)
> > <Tcl> 486
> >
> >> # resize window with mouse
> >> tkcget(textWindow, width=NULL)
> > <Tcl> 80
> >> tkwinfo("width", textWindow$ID)
> > <Tcl> 743
> >
> > I could convert pixels to characters, but wonder whether I 
> can get the 
> > latter directly.
> 
> I suspect you may have some difficulty with the latter, even 
> in a monospace font.  Notice that 486 is not a multiple of 
> 80, and if that is actually 81, 743 is not a multiple of 6.
> 
> I was trying to do this with heights for a listbox a few days 
> ago, and it seems that the line spacing is actually 1 pixel 
> greater than is reported. 
> Since you can resize to a non-integer number of lines I don't 
> believe (and I tried to read the source code) that Tcl/Tk 
> works internally with characters.
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon Feb 28 16:39:26 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Feb 28 16:45:19 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
In-Reply-To: <Pine.LNX.4.61.0502281415380.24599@gannet.stats>
References: <20050228140503.YGVI1919.tomts22-srv.bellnexxia.net@JohnDesktop8300>
	<Pine.LNX.4.61.0502281415380.24599@gannet.stats>
Message-ID: <x2oee4hexd.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:


> > <Tcl> 743
> >
> > I could convert pixels to characters, but wonder whether I can get the
> > latter directly.
> 
> I suspect you may have some difficulty with the latter, even in a
> monospace font.  Notice that 486 is not a multiple of 80, and if that
> is actually 81, 743 is not a multiple of 6.
> 
> I was trying to do this with heights for a listbox a few days ago, and
> it seems that the line spacing is actually 1 pixel greater than is
> reported. Since you can resize to a non-integer number of lines I
> don't believe (and I tried to read the source code) that Tcl/Tk works
> internally with characters.

I think that's actually an issue that involves the window manager too.
I don't think all WMs know how to deal in integer number of
characters. 

Anyways, the following piece of Tcl seems to do the trick:

% expr ([winfo width .a] - 2 * [.a cget -borderwidth] - 4)/[font measure [.a cget -font] 0]
27

Converting to R is left as an exercise...

If I got it right then the point is that at either side of the window
you have by 1 pixel, n border pixels, and 1 spacer pixel before the
first character.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From jfox at mcmaster.ca  Mon Feb 28 17:25:39 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb 28 17:25:49 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
In-Reply-To: <x2oee4hexd.fsf@biostat.ku.dk>
Message-ID: <20050228162539.RTUM1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter,

(as.numeric(tkwinfo("width", .output$ID))
    - 2*as.numeric(tkcget(.output, borderwidth=NULL)) - 2)/
    as.numeric(tkfont.measure(tkcget(.output, font=NULL), "0"))

(for the text widget .output) appears to do the trick (note, subtracting 2
rather than 4).

Thank you,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces@stat.math.ethz.ch 
> [mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Peter Dalgaard
> Sent: Monday, February 28, 2005 10:39 AM
> To: Prof Brian Ripley
> Cc: John Fox; r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Getting width of Tk text widget via tcltk
> 
> Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:
> 
> 
> > > <Tcl> 743
> > >
> > > I could convert pixels to characters, but wonder whether 
> I can get 
> > > the latter directly.
> > 
> > I suspect you may have some difficulty with the latter, even in a 
> > monospace font.  Notice that 486 is not a multiple of 80, 
> and if that 
> > is actually 81, 743 is not a multiple of 6.
> > 
> > I was trying to do this with heights for a listbox a few 
> days ago, and 
> > it seems that the line spacing is actually 1 pixel greater than is 
> > reported. Since you can resize to a non-integer number of lines I 
> > don't believe (and I tried to read the source code) that 
> Tcl/Tk works 
> > internally with characters.
> 
> I think that's actually an issue that involves the window manager too.
> I don't think all WMs know how to deal in integer number of 
> characters. 
> 
> Anyways, the following piece of Tcl seems to do the trick:
> 
> % expr ([winfo width .a] - 2 * [.a cget -borderwidth] - 
> 4)/[font measure [.a cget -font] 0]
> 27
> 
> Converting to R is left as an exercise...
> 
> If I got it right then the point is that at either side of 
> the window you have by 1 pixel, n border pixels, and 1 spacer 
> pixel before the first character.
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From p.dalgaard at biostat.ku.dk  Mon Feb 28 17:26:40 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Feb 28 17:32:32 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
In-Reply-To: <20050228162539.RTUM1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>
References: <20050228162539.RTUM1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <x2ekf0hcqn.fsf@biostat.ku.dk>

"John Fox" <jfox@mcmaster.ca> writes:

> Dear Peter,
> 
> (as.numeric(tkwinfo("width", .output$ID))
>     - 2*as.numeric(tkcget(.output, borderwidth=NULL)) - 2)/
>     as.numeric(tkfont.measure(tkcget(.output, font=NULL), "0"))
> 
> (for the text widget .output) appears to do the trick (note, subtracting 2
> rather than 4).

Hmm, that's odd. I needed the 4. Beware that Tcl does integer division
(%/%). Did you round() or floor() the result? 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From jfox at mcmaster.ca  Mon Feb 28 18:01:32 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb 28 18:01:43 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
In-Reply-To: <x2ekf0hcqn.fsf@biostat.ku.dk>
Message-ID: <20050228170132.MWSF1836.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter,

As you can see from the expression, I didn't use integer division, nor did I
round() or floor(). Here's my original example, using a monospaced font:

> library(tcltk)
> top <- tktoplevel()
> textWindow <- tktext(top, bg="white", height=20, width=80, wrap="none",
+     font=tkfont.create(family="courier", size=10))
> tkgrid(textWindow, sticky="news")
<Tcl>  
> tkgrid.rowconfigure(top, 0, weight=1)
<Tcl>  
> tkgrid.columnconfigure(top, 0, weight=1)
<Tcl>  
> tkcget(textWindow, width=NULL)
<Tcl> 80 
> tkwinfo("width", textWindow$ID)
<Tcl> 646 
> 
> (as.numeric(tkwinfo("width", textWindow$ID))
+      - 2*as.numeric(tkcget(textWindow, borderwidth=NULL)) - 4) /
+      as.numeric(tkfont.measure(tkcget(textWindow, font=NULL), "0"))
[1] 79.75
> 
> (as.numeric(tkwinfo("width", textWindow$ID))
+      - 2*as.numeric(tkcget(textWindow, borderwidth=NULL)) - 2) /
+      as.numeric(tkfont.measure(tkcget(textWindow, font=NULL), "0"))
[1] 80

I believe that the right answer is 80, and this appears correct visually,
confirmed by typing in the window.

My object was to be able to adjust R output to the width of the widget, and
I can now do this (actually, Brian's approach also worked well enough for
me).

Thank you again for your help.

John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Peter Dalgaard [mailto:p.dalgaard@biostat.ku.dk] 
> Sent: Monday, February 28, 2005 11:27 AM
> To: John Fox
> Cc: 'Peter Dalgaard'; r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] Getting width of Tk text widget via tcltk
> 
> "John Fox" <jfox@mcmaster.ca> writes:
> 
> > Dear Peter,
> > 
> > (as.numeric(tkwinfo("width", .output$ID))
> >     - 2*as.numeric(tkcget(.output, borderwidth=NULL)) - 2)/
> >     as.numeric(tkfont.measure(tkcget(.output, font=NULL), "0"))
> > 
> > (for the text widget .output) appears to do the trick (note, 
> > subtracting 2 rather than 4).
> 
> Hmm, that's odd. I needed the 4. Beware that Tcl does integer 
> division (%/%). Did you round() or floor() the result? 
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: 
> (+45) 35327907

From bgunter at gene.com  Mon Feb 28 19:49:26 2005
From: bgunter at gene.com (bgunter@gene.com)
Date: Mon Feb 28 19:49:34 2005
Subject: [Rd] GUI File>Load workspace "bug" in Windows (PR#7710)
Message-ID: <20050228184926.81DEDAD6A@slim.kubism.ku.dk>

Full_Name: Bert Gunter
Version: 2.0.1
OS: Windows XP
Submission from: (NULL) (192.12.78.250)


Not sure this is a bug, but ..

When the working directory is changed via setwd() and then the  file>Load
workspace menu is immediately accessed, the working directory that is opened is
still the one set before the setwd() call. It only THEN resets the GUI to the
correct current working directory.

From ripley at stats.ox.ac.uk  Mon Feb 28 20:33:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 28 20:34:01 2005
Subject: [Rd] GUI File>Load workspace "bug" in Windows (PR#7710)
In-Reply-To: <20050228184926.81DEDAD6A@slim.kubism.ku.dk>
References: <20050228184926.81DEDAD6A@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0502281921330.4056@gannet.stats>

It does for me, *unless* you have used a Load item before in the session
when the comment in the README applies.  It was not Guido's intention that 
the Load items always start in a working directory as changed by setwd().

On Mon, 28 Feb 2005 bgunter@gene.com wrote:

> Full_Name: Bert Gunter
> Version: 2.0.1
> OS: Windows XP
> Submission from: (NULL) (192.12.78.250)
>
>
> Not sure this is a bug, but ..
>
> When the working directory is changed via setwd() and then the  file>Load
> workspace menu is immediately accessed, the working directory that is opened is
> still the one set before the setwd() call. It only THEN resets the GUI to the
> correct current working directory.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon Feb 28 20:57:33 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Feb 28 21:03:27 2005
Subject: [Rd] Getting width of Tk text widget via tcltk
In-Reply-To: <20050228170132.MWSF1836.tomts16-srv.bellnexxia.net@JohnDesktop8300>
References: <20050228170132.MWSF1836.tomts16-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <x2psykjw42.fsf@biostat.ku.dk>

"John Fox" <jfox@mcmaster.ca> writes:

> Dear Peter,
> 
> As you can see from the expression, I didn't use integer division, nor did I
> round() or floor(). Here's my original example, using a monospaced font:
> 
> > library(tcltk)
> > top <- tktoplevel()
> > textWindow <- tktext(top, bg="white", height=20, width=80, wrap="none",
> +     font=tkfont.create(family="courier", size=10))
> > tkgrid(textWindow, sticky="news")
> <Tcl>  
> > tkgrid.rowconfigure(top, 0, weight=1)
> <Tcl>  
> > tkgrid.columnconfigure(top, 0, weight=1)
> <Tcl>  
> > tkcget(textWindow, width=NULL)
> <Tcl> 80 
> > tkwinfo("width", textWindow$ID)
> <Tcl> 646 
> > 
> > (as.numeric(tkwinfo("width", textWindow$ID))
> +      - 2*as.numeric(tkcget(textWindow, borderwidth=NULL)) - 4) /
> +      as.numeric(tkfont.measure(tkcget(textWindow, font=NULL), "0"))
> [1] 79.75
> > 
> > (as.numeric(tkwinfo("width", textWindow$ID))
> +      - 2*as.numeric(tkcget(textWindow, borderwidth=NULL)) - 2) /
> +      as.numeric(tkfont.measure(tkcget(textWindow, font=NULL), "0"))
> [1] 80
> 
> I believe that the right answer is 80, and this appears correct visually,
> confirmed by typing in the window.

Interesting...

> tkwinfo("width", textWindow)
<Tcl> 488 
> (as.numeric(tkwinfo("width", textWindow))
+      - 2*as.numeric(tkcget(textWindow, borderwidth=NULL)) - 4) /
+   as.numeric(tkfont.measure(tkcget(textWindow, font=NULL), "0"))
[1] 80
> (as.numeric(tkwinfo("width", textWindow))
+       - 2*as.numeric(tkcget(textWindow, borderwidth=NULL)) - 2) /
+       as.numeric(tkfont.measure(tkcget(textWindow, font=NULL), "0"))
[1] 80.33333

Notice, btw, that textWindow$ID  shouldnn't be necessary.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Robert.McGehee at geodecapital.com  Mon Feb 28 21:58:38 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon Feb 28 21:58:54 2005
Subject: [Rd] Changing function arguments to NULL
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E84@MSGBOSCLB2WIN.DMN1.FMR.COM>

I'm trying to build a recursive set of functions that take a set of
arguments, change some of the arguments and recursively call the same
(or different) function.

For example here's a stupid recursive counting function that prints back
all integers from x to 0 (and ignores arguments y and z)

cnt <- function(x, y, z) {
	stopifnot(is.numeric(x))
	print (x)
	recursionFUN <- match.call()
	recursionFUN$x <- x - 1
	if (x <= 0) {
		invisible(TRUE)
	} else {
		eval(recursionFUN)
	}
}

My problem is that sometimes I want to set one of the arguments to NULL.
But trying to set one of the match.call() arguments to NULL causes it to
be ignored (since the match.call() output is coerced into a list). What
I'd like is that the match.call() output could be converted into an
alist, so that tagged values with no arguments could be handled and
passed on to the next function call without being ignored.

However, I haven't been able to figure out how to construct this alist
without knowing ahead of time what all of the function arguments are and
typing them in explicitly:
e.g. alist(x = 5, y = 2, z = 3).

Re-assigning and then re-evaluating output of the match.call() function
might not be the way to go, but I am not sure, and would appreciate any
comments on the best way to set function arguments to NULL before
evaluating.

Thanks,
Robert

Robert McGehee
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee@geodecapital.com



This e-mail, and any attachments hereto, are intended for us...{{dropped}}

From rpeng at jhsph.edu  Mon Feb 28 22:58:12 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon Feb 28 23:00:27 2005
Subject: [Rd] Changing function arguments to NULL
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E84@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E84@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <422393F4.9040204@jhsph.edu>

I'm not sure what you're doing but did you try

recursionFUN$x <- list(NULL)

?

-roger

McGehee, Robert wrote:
> I'm trying to build a recursive set of functions that take a set of
> arguments, change some of the arguments and recursively call the same
> (or different) function.
> 
> For example here's a stupid recursive counting function that prints back
> all integers from x to 0 (and ignores arguments y and z)
> 
> cnt <- function(x, y, z) {
> 	stopifnot(is.numeric(x))
> 	print (x)
> 	recursionFUN <- match.call()
> 	recursionFUN$x <- x - 1
> 	if (x <= 0) {
> 		invisible(TRUE)
> 	} else {
> 		eval(recursionFUN)
> 	}
> }
> 
> My problem is that sometimes I want to set one of the arguments to NULL.
> But trying to set one of the match.call() arguments to NULL causes it to
> be ignored (since the match.call() output is coerced into a list). What
> I'd like is that the match.call() output could be converted into an
> alist, so that tagged values with no arguments could be handled and
> passed on to the next function call without being ignored.
> 
> However, I haven't been able to figure out how to construct this alist
> without knowing ahead of time what all of the function arguments are and
> typing them in explicitly:
> e.g. alist(x = 5, y = 2, z = 3).
> 
> Re-assigning and then re-evaluating output of the match.call() function
> might not be the way to go, but I am not sure, and would appreciate any
> comments on the best way to set function arguments to NULL before
> evaluating.
> 
> Thanks,
> Robert
> 
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for us...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From Robert.McGehee at geodecapital.com  Mon Feb 28 23:13:57 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon Feb 28 23:14:10 2005
Subject: [Rd] Changing function arguments to NULL
Message-ID: <67DCA285A2D7754280D3B8E88EB5480206741E85@MSGBOSCLB2WIN.DMN1.FMR.COM>

But passing list(NULL) or NULL into a function may have entirely
different results.

For instance,

> paste("Hello world", NULL)
[1] "Hello world "

> paste("Hello world", list(NULL))
[1] "Hello world NULL"

Simply put, I'd like to look at a function's call (i.e. using
match.call()), and replace one of its arguments with NULL and
re-evaluate it. I was hoping for something generic, such that I didn't
have to know all of a function's arguments ahead of time (i.e. I could
just replace the one I wanted without even knowing the names or values
of the other arguments), but this may be easier said than done.

-----Original Message-----
From: Roger D. Peng [mailto:rpeng@jhsph.edu] 
Sent: Monday, February 28, 2005 4:58 PM
To: McGehee, Robert
Cc: r-devel@stat.math.ethz.ch
Subject: Re: [Rd] Changing function arguments to NULL


I'm not sure what you're doing but did you try

recursionFUN$x <- list(NULL)

?

-roger

McGehee, Robert wrote:
> I'm trying to build a recursive set of functions that take a set of
> arguments, change some of the arguments and recursively call the same
> (or different) function.
> 
> For example here's a stupid recursive counting function that prints
back
> all integers from x to 0 (and ignores arguments y and z)
> 
> cnt <- function(x, y, z) {
> 	stopifnot(is.numeric(x))
> 	print (x)
> 	recursionFUN <- match.call()
> 	recursionFUN$x <- x - 1
> 	if (x <= 0) {
> 		invisible(TRUE)
> 	} else {
> 		eval(recursionFUN)
> 	}
> }
> 
> My problem is that sometimes I want to set one of the arguments to
NULL.
> But trying to set one of the match.call() arguments to NULL causes it
to
> be ignored (since the match.call() output is coerced into a list).
What
> I'd like is that the match.call() output could be converted into an
> alist, so that tagged values with no arguments could be handled and
> passed on to the next function call without being ignored.
> 
> However, I haven't been able to figure out how to construct this alist
> without knowing ahead of time what all of the function arguments are
and
> typing them in explicitly:
> e.g. alist(x = 5, y = 2, z = 3).
> 
> Re-assigning and then re-evaluating output of the match.call()
function
> might not be the way to go, but I am not sure, and would appreciate
any
> comments on the best way to set function arguments to NULL before
> evaluating.
> 
> Thanks,
> Robert
> 
> Robert McGehee
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee@geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for
us...{{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From ripley at stats.ox.ac.uk  Mon Feb 28 23:28:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Feb 28 23:28:47 2005
Subject: [Rd] Changing function arguments to NULL
In-Reply-To: <67DCA285A2D7754280D3B8E88EB5480206741E85@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB5480206741E85@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <Pine.LNX.4.61.0502282217450.960@gannet.stats>

On Mon, 28 Feb 2005, McGehee, Robert wrote:

> But passing list(NULL) or NULL into a function may have entirely
> different results.

For a replacement operator expecting a list, list(NULL) *is* what you 
want.  BTW, this is FAQ 7.1.

> foo <- alist(x = 5, y = 2, z = 3)
> foo["x"] <- list(NULL)
> foo
$x
NULL

$y
[1] 2

$z
[1] 3

if (as I guess) you want to set the default value to NULL, not `the 
argument to NULL'.

[...]

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon Feb 28 23:46:47 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon Feb 28 23:52:41 2005
Subject: [Rd] Re: [R] H-F corr.: covariance matrix for interaction effect
In-Reply-To: <x2acptpiqm.fsf@biostat.ku.dk>
References: <421C6A88.3030907@gmx.net> <x2psyrcr84.fsf@biostat.ku.dk>
	<x2acptpiqm.fsf@biostat.ku.dk>
Message-ID: <x2ll98joa0.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard@biostat.ku.dk> writes:

> Where I would have expected
> 
> > (20*5*0.6917-2)/(5*(19-5*.6917))
> [1] 0.8643953
> 
> Does anyone have a clue as to what is going on here? Is mighty SAS
> simply doing the wrong thing? The G-G epsilon depends only on the
> eigenvalues of the observed covariance matrix, so surely the H-F
> correction should depend only on the dimension and the DF for the
> empirical covariance matrix? 

Just in case anyone was wondering, I think I now know what SAS is
doing, and yes, it is a bug. 

The HF correction is

HFeps = (n * (k-1) * GGeps - 2) / ((k-1) * ((n-1) - (k-1) * GG.eps))

for the simple two-way layout, where the residual SSD matrix has (n-1)
degrees of freedom. For the case with covariates, it looks like (to 4
significant digits) SAS is generalizing the above to

HFeps = (n * (k-1) * GGeps - 2) / ((k-1) * (f - (k-1) * GG.eps))

where f is the degrees of freedom for the SSD. However, the first n
also needs adjustment; the correctly generalized formula should read

HFeps = ((f+1) * (k-1) * GGeps - 2) / ((k-1) * (f - (k-1) * GG.eps))

(The G-G epsilon is essentially the squared mean of the eigenvalues of
a suitably transformed SSD divided by the mean of the squares of the
eigenvalues. This is less than one unless all eigenvalues are
identical. H-F replaces numerator and denominator with bias-corrected
variants. However, since everything is a function of the SSD matrix,
sthe formula can only depend on n via the degrees of freedom.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

