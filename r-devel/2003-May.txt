From Heather.L.Turner at exeter.ac.uk  Thu May  1 17:17:58 2003
From: Heather.L.Turner at exeter.ac.uk (Heather.L.Turner@exeter.ac.uk)
Date: Thu May  1 16:18:08 2003
Subject: [Rd] Opening previous workspace in Windows (PR#2890)
Message-ID: <200305011417.h41EHw2b016178@pubhealth.ku.dk>

Full_Name: Heather Turner
Version: 1.7.0
OS: Windows 98
Submission from: (NULL) (144.173.6.80)


I have just upgraded to 1.7.0 from 1.4.1. Unlike 1.4.1, version 1.7.0 will not
open .RData files from Windows Explorer. This appears to be because there are
spaces in the path name as I get the error messages:

ARGUMENT `C:\My'__ignored____

followed by

ARGUMENT `Documents\Arrays\...'____ignored____

etc, where the full path begins `C:\My Documents\Arrays\...'

I can get around this problem by opening R then loading the workspace using the
File menu or dragging and dropping the file into R, but I found opening the
workspace from Explorer a convenient one-step method and it would be nice if it
worked with the new version.

From murdoch at stats.uwo.ca  Thu May  1 11:49:12 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu May  1 16:47:44 2003
Subject: [Rd] Opening previous workspace in Windows (PR#2890)
In-Reply-To: <200305011417.h41EHw2b016178@pubhealth.ku.dk>
References: <200305011417.h41EHw2b016178@pubhealth.ku.dk>
Message-ID: <8pc2bvgu1jnnh1to3e6klntsp4jqd51lbm@4ax.com>

On Thu, 1 May 2003 16:17:58 +0200 (MET DST), you wrote in message
<200305011417.h41EHw2b016178@pubhealth.ku.dk>:

>Full_Name: Heather Turner
>Version: 1.7.0
>OS: Windows 98
>Submission from: (NULL) (144.173.6.80)
>
>
>I have just upgraded to 1.7.0 from 1.4.1. Unlike 1.4.1, version 1.7.0 will not
>open .RData files from Windows Explorer. This appears to be because there are
>spaces in the path name as I get the error messages:

I just tried this in Win98 and it worked fine.  I can't think why it
wouldn't be working for you.  Could you tell me the exact pathname you
used?  Maybe it was too long or something.

Duncan Murdoch

From ripley at stats.ox.ac.uk  Thu May  1 17:06:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu May  1 17:06:19 2003
Subject: [Rd] Opening previous workspace in Windows (PR#2890)
In-Reply-To: <8pc2bvgu1jnnh1to3e6klntsp4jqd51lbm@4ax.com>
Message-ID: <Pine.WNT.4.44.0305011559070.2232-100000@gannet.stats.ox.ac.uk>

On Thu, 1 May 2003, Duncan Murdoch wrote:

> On Thu, 1 May 2003 16:17:58 +0200 (MET DST), you wrote in message
>
> >Full_Name: Heather Turner
> >Version: 1.7.0
> >OS: Windows 98
> >Submission from: (NULL) (144.173.6.80)
> >
> >
> >I have just upgraded to 1.7.0 from 1.4.1. Unlike 1.4.1, version 1.7.0 will not
> >open .RData files from Windows Explorer. This appears to be because there are
> >spaces in the path name as I get the error messages:

[example from "My Documents"]

> I just tried this in Win98 and it worked fine.  I can't think why it
> wouldn't be working for you.  Could you tell me the exact pathname you
> used?  Maybe it was too long or something.

It also works for me (in XP)

Could you please check the file associations. In Windows Explorer go to
`File options | File types' and look at RDATA.  The `open' command should
be something like

"c:\Program Files\R\rw1070\bin\RGui.exe" "%1"

and the behaviour you report is what I would expect if the second pair of
quotes is missing.  (If perchance it is, that tells you how to repair
this, although it would not tell us how it went wrong ....)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rgrubbfink at cox.net  Thu May  1 22:20:42 2003
From: rgrubbfink at cox.net (rgrubbfink@cox.net)
Date: Thu May  1 21:20:53 2003
Subject: [Rd] ldAIX4 does not generate Rlapack.exp (PR#2893)
Message-ID: <200305011920.h41JKg2b017522@pubhealth.ku.dk>

Full_Name: Richard L. Grubb
Version: 1.7.0
OS: AIX 4.3.3
Submission from: (NULL) (130.76.96.17)


src/modules/lapack/Makefile executes the tools/ldAIX4 script and supplies,
as arguments to ldAIX4, several object file names with filename extensions of
.lo.
The ldAIX4 script did not generate the file etc/Rlapack.exp until I changed
ldAIX4
as follows:

Original context:
# Check for object or archive files
ofiles=""
for arg; do
    case $arg in *.o) ofiles="$ofiles $arg";; esac
    case $arg in *.a) ofiles="$ofiles $arg";; esac
done

Changed context:
# Check for object or archive files
ofiles=""
for arg; do
    case $arg in *.o) ofiles="$ofiles $arg";; esac
    case $arg in *.lo) ofiles="$ofiles $arg";; esac
    case $arg in *.a) ofiles="$ofiles $arg";; esac
done

See also Bug reports 2887 and 2888

From mpvenkatesh at lycos.com  Thu May  1 13:55:12 2003
From: mpvenkatesh at lycos.com (Venkatesh)
Date: Thu May  1 21:55:36 2003
Subject: [Rd] query reg. submission procedure
Message-ID: <OIEPLKICNJJGGAAA@mailcity.com>

Hi,

I am trying to submit a patch to R-1.7.0 with new features. I'm wondering what the guidelines are.

Thanks !
Venkatesh 
-Bioinformatics Group-
-New York Univerity-

-----------------------------
Home:
144 Kensington Avenue #2,
Jersey City,
NJ 07304
Ph: 201 536 1314

Office:
715 Broadway #1014,
New York, 
NY 10003
Ph: 212 998 3373

From ripley at stats.ox.ac.uk  Thu May  1 22:34:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu May  1 22:35:04 2003
Subject: [Rd] query reg. submission procedure
In-Reply-To: <OIEPLKICNJJGGAAA@mailcity.com>
Message-ID: <Pine.LNX.4.44.0305012126290.1742-100000@gannet.stats>

On Thu, 1 May 2003, Venkatesh wrote:

> I am trying to submit a patch to R-1.7.0 with new features. I'm
> wondering what the guidelines are.

It would have to be a patch to R-devel (as R 1.7.0 is out, and R.1.7.x
will be bug-fix releases).  So do make the patch against the current
R-devel.  The FAQ section `5.6 How can I contribute to R?' looks rather
pertinent!

You could also send to the R-bugs repository marked for the `wishlist', or
tell us (R-devel or R-core) what the `new features' are and seek advice
from a member of R-core who responds -- the latter looks the best idea for
a substantial enhancement.

Brian Ripley

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From terra at gnome.org  Thu May  1 23:44:00 2003
From: terra at gnome.org (terra@gnome.org)
Date: Thu May  1 22:44:11 2003
Subject: [Rd] qbeta hang (PR#2894)
Message-ID: <200305012044.h41Ki02b017789@pubhealth.ku.dk>

Full_Name: Morten Welinder
Version: 1.6.1
OS: Solaris/sparc
Submission from: (NULL) (65.213.85.144)


qbeta(0.1, 1e-8, 0.5, TRUE, FALSE) seems to hang for me.

From p.dalgaard at biostat.ku.dk  Fri May  2 01:20:06 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri May  2 00:16:35 2003
Subject: [Rd] qbeta hang (PR#2894)
In-Reply-To: <200305012044.h41Ki02b017789@pubhealth.ku.dk>
References: <200305012044.h41Ki02b017789@pubhealth.ku.dk>
Message-ID: <x265oujomh.fsf@biostat.ku.dk>

terra@gnome.org writes:

> Full_Name: Morten Welinder
> Version: 1.6.1
> OS: Solaris/sparc
> Submission from: (NULL) (65.213.85.144)
> 
> 
> qbeta(0.1, 1e-8, 0.5, TRUE, FALSE) seems to hang for me.

confirmed on 1.7.0 Solaris 9, gcc 3.0.3 (standard build, so -O2, I assume)

Morten: the gcc version is often crucial in these cases.

However, the exact same thing is happening on Linux. The immediate
cause is that n = fmax2(lneps/log(y), 4.0) gets large when y is in the
vicinity of 1-1e-8, so the loop in src/nmath/pbeta.c:101 gets a rather
high count. The algorithm isn't really stuck, it just takes a very
long time. On the fastest machine that I have available:

> system.time(qbeta(0.1, 1e-8, 0.5, TRUE, FALSE))
[1] 75.58  0.00 75.58  0.00  0.00


It's not really that surprising:

> pbeta(1e-5, 1e-8, 0.5,, TRUE, FALSE)
[1] 0.9999999
> pbeta(1e-10, 1e-8, 0.5,, TRUE, FALSE)
[1] 0.9999998
> pbeta(1e-200, 1e-8, 0.5,, TRUE, FALSE)
[1] 0.9999954
> pbeta(1e-309, 1e-8, 0.5,, TRUE, FALSE)
[1] 0.999993
> pbeta(1e-400, 1e-8, 0.5,, TRUE, FALSE)
[1] 0

and you're trying to solve pbeta(x, 1e-8, 0.5,, TRUE, FALSE) == 0.1


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Fri May  2 01:39:05 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Fri May  2 00:39:17 2003
Subject: [Rd] qbeta hang (PR#2894)
Message-ID: <200305012239.h41Md52b018213@pubhealth.ku.dk>

On Thu, 1 May 2003 22:44:00 +0200 (MET DST), you wrote:

>Full_Name: Morten Welinder
>Version: 1.6.1
>OS: Solaris/sparc
>Submission from: (NULL) (65.213.85.144)
>
>
>qbeta(0.1, 1e-8, 0.5, TRUE, FALSE) seems to hang for me.

In 1.7.0-patched in Windows, it's very, very slow, but eventually
produces an answer:

> qbeta(0.1, 1e-8, 0.5, TRUE, FALSE)
[1] 4.400784e-309

The answer should be really small (the mean is 2e-8, and it's strongly
skewed to the right), so I'd guess it's giving the right answer, and
is just slow to converge to it.

Duncan Murdoch

From Mark.Bravington at csiro.au  Fri May  2 03:03:46 2003
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Fri May  2 02:04:00 2003
Subject: [Rd] predict (PR#2686)
Message-ID: <200305020003.h4203k2b018395@pubhealth.ku.dk>

Hmmm-- still looks like a bug to me! But as I don't want to hog the
airwaves, here's my last summary on this point, with a question:

[Bravington]
#> Prediction from the original data was just an example, of course; my
general
#> proposal is that inactive factor levels in the prediction set should be
#> dropped. I don't see how this could ever cause inconsistent behaviour
across
#> prediction sets-- have I missed something?

[Ripley]
#Yes, repeatedly: `inactive' depends on the prediction set, and that's not 
#thought desirable.

But that doesn't explain why this "is not thought desirable". Could you
provide an actual example where automatically dropping inactive levels in a
prediction dataset would cause problems? Then at last the scales might fall
from my eyes...

(1) Suppose a prediction dataset contains a factor which has inactive levels
that weren't active (or didn't exist) in the original data. Then
'predict.lm' etc give an error message, even when statistically-sensible
predictions can be made. In particular, this happens even when 'predict' is
called with the original fitting dataset as the 'newdata' argument. This
appears to be inconsistent with the documentation, at least.

(2) The only generic way to prevent the error appearing, is for users to
insert code along the lines of

predict.set[] <- lapply( predict.set, function( x) if( inherits( x,
'factor')) x[,drop=T] else x)

This doesn't look like a very helpful requirement. It is very awkward, and I
don't (yet) see how the user gains any security from it.

(3) My proposal is to change 'predict' to drop inactive factor levels, just
as 'lm' etc already do; see earlier emails for the one-line change. In
effect, step (2) gets done automatically. The code for 'predict' will still
rightly give an error if the prediction data has levels that didn't exist or
weren't active in the fitting data. Is there a counterexample where this
proposal would cause trouble?


cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington@csiro.au

From maechler at stat.math.ethz.ch  Fri May  2 11:00:23 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Fri May  2 10:00:36 2003
Subject: [Rd] pnorm conditional (PR#2883)
Message-ID: <200305020800.h4280N2b020845@pubhealth.ku.dk>

>>>>> "Daniel" == Daniel Pemstein <dbpemste@artsci.wustl.edu>
>>>>>     on Wed, 30 Apr 2003 19:20:36 +0200 (MET DST) writes:

    Daniel> I was going over the source in src/nmath/pnorm.c and
    Daniel> noticed a little bug in pnorm_both (in R 1.7.0).
    Daniel> The else-if on line 205 covers the entire real line.
    Daniel> Seems you want an &&, not an ||.  Doesn't make a big
    Daniel> difference (you still get a 0 or 1 from extreme
    Daniel> starting values) but your log refinements will
    Daniel> always be skipped.

Thank you, Daniel!
You are right about the || typo.  However as I found things are
a bit more subtle.  The last clause now always has been
skipped and the if( || ) was James Rath's contribution
subsequent to his PR#699 , including the mentioned asymptotic
expansion for the log_p clause.   
Now because of the typo that log_p case had not ever been in use
in the past and I know found that part the "*ccum = -0." clearly
is sub-optimal and worse than the current log_p behavior.

Anyway, this is being fixed for 1.7.1, but the patch will be
more than the 2-letter replacement,  s/||/&&/

Please let me know (off the mailing list) if you're interested
in more details.

Thanks again.
Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From welinder at rentec.com  Fri May  2 11:03:23 2003
From: welinder at rentec.com (Morten Welinder)
Date: Fri May  2 16:03:41 2003
Subject: [Rd] qbeta hang (PR#2894)
In-Reply-To: <x265oujomh.fsf@biostat.ku.dk> (message from Peter Dalgaard BSA
	on 02 May 2003 00:20:06 +0200)
References: <200305012044.h41Ki02b017789@pubhealth.ku.dk>
	<x265oujomh.fsf@biostat.ku.dk>
Message-ID: <200305021403.h42E3NcU001790@robbie.rentec.com>


Ok, I can confirm that it does not, in fact, loop forever.  Just a close
approximation.

> Morten: the gcc version is often crucial in these cases.

Sorry.  gcc-2.7.2 (both -O2 and -O0) on Solaris 2.9 / sparc.

The problems seem to be...

1. The initial guess underflows to zero.

2. That guess is replaced by the truly awful guess 0.5.

3. The root finding algorithm ignores all the nice properties of pbeta
   -- such as it being monotonically increasing and bounded.

> and you're trying to solve pbeta(x, 1e-8, 0.5,, TRUE, FALSE) == 0.1

Not quite.  What I was trying to do was the see what would happen with an
insanely small alpha.  Actually doing that would involve getting the
arguments right, of course, :-)  The not-quite-hang was an unplesant side
effect of swapping the args.

I notice things like

    r = sqrt(-log(a * a));

in the code.  I fail to see why that isn't just

    r = sqrt(-2 * log (a))

which ought to be faster and more accurate.  Then later

    ...log((1. - a) * qq)...

which might be better as

    ...(log1p(-a) + log (qq))...

if a is close to zero.

There are lots of other places that worry me with respect to cancellation
errors, for example

    r = 1 - pp;
    t = 1 - qq;

Morten

From brahm at alum.mit.edu  Fri May  2 11:42:27 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Fri May  2 16:42:45 2003
Subject: [Rd] Suppressing Scientific Notation
Message-ID: <16050.33747.851916.979913@arbres1a.fmr.com>

R gurus,

Every so often(*) someone asks how to suppress scientific notation in
printing, so I thought I'd give it a shot, but I need some help.

The formatting decision is made(**) on line 286 of src/main/format.c :

    if (mF <= *m) { /* IFF it needs less space : "F" (Fixpoint) format */

where mF is the number of characters for "normal" printing and *m is the number
of characters for scientific notation.  If mf <= *m, then parameters are set
that cause "normal" printing.  My idea was to introduce a "penalty" for
scientific notation, which changes line 286 to:

    if (mF <= *m + R_print.scipen) {

R_print.scipen is an integer (defaulting to 0) set with "options":
  R> options(scipen=99)

I tried to copy the code for R_print.digits (as in "options(digits=7)")
wherever I found it, notably in the struct "R_print_par_t" defined in Print.h.
I changed main/options.c and main/print.c, as detailed in the diff output
below.  But I must have done it wrong because my version of R crashes with:
  > Error: bad value
  > Segmentation fault

Can anyone more familiar with options() help?  How do you add a new option
parameter?  Thanks!
-- 
                              -- David Brahm (brahm@alum.mit.edu)


******************************* Footnotes: ***********************************

(*) Thomas Gerds <gerds@fdm.uni-freiburg.de> "[R] printing decimal numbers"
      posted to R-help on 24 Feb 2003.
      > how can i force R to print 0.0001 instead of 1e-04???
    Bob Porter <rjporter@mindspring.com> "[R] scientific notation"
      posted to R-help on 16 Mar 2003
      > Is there a way to force R to forgo use of scientific notation...

(**) In R-1.7.0.  Also on lines 395 and 421 for complex numbers.

*********** diff output for my "scipen" modifications to R-1.7.0 *************

diff -r R-1.7.0/src/include/Print.h R-1.7.0.mod/src/include/Print.h
40a41
>     int scipen;
diff -r R-1.7.0/src/main/format.c R-1.7.0.mod/src/main/format.c
286c286
<     if (mF <= *m) { /* IFF it needs less space : "F" (Fixpoint) format */
---
>     if (mF <= *m + R_print.scipen) { /* IFF less space : "F" (Fixpoint) fmt */
395c395
< 	if (mF <= *mr) { /* IFF it needs less space : "F" (Fixpoint) format */
---
>         if (mF <= *mr + R_print.scipen) { /* IFF less space : "F"(Fixpt) fmt */
421c421
< 	if (mF <= *mi) { /* IFF it needs less space : "F" (Fixpoint) format */
---
>         if (mF <= *mi + R_print.scipen) { /* IFF less space : "F"(Fixpt) fmt */
diff -r R-1.7.0/src/main/options.c R-1.7.0.mod/src/main/options.c
52a53
>  *	"scipen"
136a138,140
> int GetOptionSciPen(SEXP rho) {
>     return asInteger(GetOption(install("scipen"), rho));
> }
235a240,243
>     SET_TAG(v, install("scipen"));
>     SETCAR(v, ScalarInteger(0));
>     v = CDR(v);
> 
374a383,386
> 	    else if (streql(CHAR(namei), "scipen")) {
> 		k = asInteger(argi);
> 		SET_VECTOR_ELT(value, i, SetOption(tag, ScalarInteger(k)));
> 	    }
diff -r R-1.7.0/src/main/print.c R-1.7.0.mod/src/main/print.c
88a89
>     R_print.scipen = GetOptionSciPen(rho);

***************************** End diff output ********************************

From ripley at stats.ox.ac.uk  Fri May  2 18:07:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May  2 18:15:37 2003
Subject: [Rd] Suppressing Scientific Notation
In-Reply-To: <16050.33747.851916.979913@arbres1a.fmr.com>
Message-ID: <Pine.LNX.4.44.0305021658150.5075-100000@gannet.stats>

A couple of hints:

1) You don't need to touch the internal code for options: you can just
set options(scipen=100), or rely on it being unset for the default.

2) I would do something like

    R_print.scipen = asInteger(GetOption(install("scipen"), rho));
    if(R_print.scipen == NA_INTEGER) R_print.scipen = 0;

Your way you need GetOptionSciPen defined in some common header.

I believe (but have not checked) that if options("scipen") is not defined
then GetOption(install("scipen"), rho) will be NULL and asInteger(NULL) 
will be NA_INTEGER, but it might well be worth being more cautious.


On Fri, 2 May 2003, David Brahm wrote:

> R gurus,
> 
> Every so often(*) someone asks how to suppress scientific notation in
> printing, so I thought I'd give it a shot, but I need some help.
> 
> The formatting decision is made(**) on line 286 of src/main/format.c :
> 
>     if (mF <= *m) { /* IFF it needs less space : "F" (Fixpoint) format */
> 
> where mF is the number of characters for "normal" printing and *m is the number
> of characters for scientific notation.  If mf <= *m, then parameters are set
> that cause "normal" printing.  My idea was to introduce a "penalty" for
> scientific notation, which changes line 286 to:
> 
>     if (mF <= *m + R_print.scipen) {
> 
> R_print.scipen is an integer (defaulting to 0) set with "options":
>   R> options(scipen=99)
> 
> I tried to copy the code for R_print.digits (as in "options(digits=7)")
> wherever I found it, notably in the struct "R_print_par_t" defined in Print.h.
> I changed main/options.c and main/print.c, as detailed in the diff output
> below.  But I must have done it wrong because my version of R crashes with:
>   > Error: bad value
>   > Segmentation fault
> 
> Can anyone more familiar with options() help?  How do you add a new option
> parameter?  Thanks!
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri May  2 20:50:51 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri May  2 19:51:01 2003
Subject: [Rd] Suppressing Scientific Notation
In-Reply-To: <Pine.LNX.4.44.0305021658150.5075-100000@gannet.stats>
References: <16050.33747.851916.979913@arbres1a.fmr.com>
	<Pine.LNX.4.44.0305021658150.5075-100000@gannet.stats>
Message-ID: <16050.45051.675505.711133@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Fri, 2 May 2003 17:07:50 +0100 (BST) writes:

    BDR> A couple of hints:
    BDR> 1) You don't need to touch the internal code for options: you can just
    BDR> set options(scipen=100), or rely on it being unset for the default.

    BDR> 2) I would do something like

    BDR> R_print.scipen = asInteger(GetOption(install("scipen"), rho));
    BDR> if(R_print.scipen == NA_INTEGER) R_print.scipen = 0;

    BDR> Your way you need GetOptionSciPen defined in some
    BDR> common header.

I remember vaguely that the more tedious way we do for the
"digits" leads to quite substantial speed improvements as
opposed to always have to go through  GetOption(install("..."), rho).
Printing of "numeric" data is such a basic thing that it should
be as fast as possible.  I said *vaguely* though ...

In any case,  David, I think it's quite a neat idea to provide
such an option.  I've also had such requests which didn't go to
the mailing lists..

Martin

    BDR> I believe (but have not checked) that if
    BDR> options("scipen") is not defined then
    BDR> GetOption(install("scipen"), rho) will be NULL and
    BDR> asInteger(NULL) will be NA_INTEGER, but it might well
    BDR> be worth being more cautious.


    BDR> On Fri, 2 May 2003, David Brahm wrote:

    >> R gurus,
    >> 
    >> Every so often(*) someone asks how to suppress scientific notation in
    >> printing, so I thought I'd give it a shot, but I need some help.
    >> 
    >> The formatting decision is made(**) on line 286 of src/main/format.c :
    >> 
    >> if (mF <= *m) { /* IFF it needs less space : "F" (Fixpoint) format */
    >> 
    >> where mF is the number of characters for "normal" printing and *m is the number
    >> of characters for scientific notation.  If mf <= *m, then parameters are set
    >> that cause "normal" printing.  My idea was to introduce a "penalty" for
    >> scientific notation, which changes line 286 to:
    >> 
    >> if (mF <= *m + R_print.scipen) {
    >> 
    >> R_print.scipen is an integer (defaulting to 0) set with "options":
    R> options(scipen=99)
    >> 
    >> I tried to copy the code for R_print.digits (as in "options(digits=7)")
    >> wherever I found it, notably in the struct "R_print_par_t" defined in Print.h.
    >> I changed main/options.c and main/print.c, as detailed in the diff output
    >> below.  But I must have done it wrong because my version of R crashes with:
    >> > Error: bad value
    >> > Segmentation fault
    >> 
    >> Can anyone more familiar with options() help?  How do you add a new option
    >> parameter?  Thanks!
    >> 

    BDR> -- 
    BDR> Brian D. Ripley,                  ripley@stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

    BDR> ______________________________________________
    BDR> R-devel@stat.math.ethz.ch mailing list
    BDR> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Fri May  2 20:53:41 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May  2 21:01:28 2003
Subject: [Rd] Suppressing Scientific Notation
In-Reply-To: <16050.45051.675505.711133@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0305021949440.5692-100000@gannet.stats>

On Fri, 2 May 2003, Martin Maechler wrote:

> >>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
> >>>>>     on Fri, 2 May 2003 17:07:50 +0100 (BST) writes:
> 
>     BDR> A couple of hints:
>     BDR> 1) You don't need to touch the internal code for options: you can just
>     BDR> set options(scipen=100), or rely on it being unset for the default.
> 
>     BDR> 2) I would do something like
> 
>     BDR> R_print.scipen = asInteger(GetOption(install("scipen"), rho));
>     BDR> if(R_print.scipen == NA_INTEGER) R_print.scipen = 0;
> 
>     BDR> Your way you need GetOptionSciPen defined in some
>     BDR> common header.
> 
> I remember vaguely that the more tedious way we do for the
> "digits" leads to quite substantial speed improvements as
> opposed to always have to go through  GetOption(install("..."), rho).
> Printing of "numeric" data is such a basic thing that it should
> be as fast as possible.  I said *vaguely* though ...

It's not avoiding that: GetOptionDigits is called by PrintDefaults and
that looks up the .Options variable every time.  You do need to look up
the options on each call (possibly internal) to print, as there are
scoping possibilities with options() (hence that rho in the GetOption
call).

As far as I can see this only called in print.c, but I presume it was 
intended to be used more widely.


My point was that in the patch GetOptionSciPen was not defined to return 
integer ....

Brian Ripley

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From beebe at math.utah.edu  Sat May  3 17:10:11 2003
From: beebe at math.utah.edu (beebe@math.utah.edu)
Date: Sat May  3 16:10:56 2003
Subject: [Rd] R-1.7.0 build feedback: NetBSD 1.6 (PR#2837)
Message-ID: <200305031410.h43EAB2b001238@pubhealth.ku.dk>

This is a followup to my report of a SIGSEGV in R-1.7.0 built
on NetBSD 1.6.

Kurt Hornik responded:

>> ...
>> After some discussions on r-core, two suggestions.
>>
>> * It might be helpful to know if zlib has found in the OS or compiled
>>   from the sources within R: if the first you could try configure
>>   --without-zlib as it is possible the OS has a modified version.
>>
>> * You have
>>
>>   R : Copyright 2003, The R Development Core Team
>>   Version 1.7.0 Under development (unstable) (2003-04-11)
>>                       ^^^^^^^^^^^^^^^^^^^^^^         ^^^
>>
>>   and might just have hit a bad day of the r-devel daily snapshot.
>> ...

I don't think that the latter is the problem.  This version built,
validated, and installed on several other platforms.

Since my initial bug report for this system, I upgraded the gcc
release from 3.2.2 to the latest 3.2.3, so the compilation environment
is now a bit different.

I tried your suggestion of the --without-zlib configure option, and
that produced a working R, which I've installed.  There was one *.fail
file in the tests directory: reg-tests-1.Rout.fail.  It is 2280 lines
long, and contains a fair number of "Error xxx" reports.

In view of the gcc upgrade, I'm going to go back now and do a fresh
build, and see if the zlib problem recurs.

Here is a copy of reg-tests-1.Rout.fail:

R : Copyright 2003, The R Development Core Team
Version 1.7.0 Under development (unstable) (2003-04-11)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

> ## regression test for PR#376
> aggregate(ts(1:20), nfreq=1/3)
Time Series:
Start = 1
End = 16
Frequency = 0.333333333333333
[1]  6 15 24 33 42 51
> ## Comments: moved from aggregate.Rd
>
>
> ## aperm
> # check the names
> x <- array(1:24, c(4, 6))
> nms <- list(happy=letters[1:4], sad=LETTERS[1:6])
>
> dimnames(x) <- nms
> tmp <- aperm(x, c(2, 1))
> stopifnot(all.equal(dimnames(tmp), nms[c(2, 1)]))
>
> dimnames(x) <- c(nms[1], list(NULL))
> tmp <- aperm(x, c(2, 1))
> stopifnot(all.equal(dimnames(tmp), c(list(NULL), nms[1])))
>
> names(nms) <- c("happy", "sad")
> dimnames(x) <- nms
> tmp <- aperm(x, c(2, 1))
> stopifnot(all.equal(names(dimnames(tmp)), names(nms[c(2, 1)])))
>
> dimnames(x) <- c(nms[1], list(NULL))
> tmp <- aperm(x, c(2, 1))
> stopifnot(all.equal(names(dimnames(tmp)), c("", names(nms)[1])))
>
> # check resize
> stopifnot(dim(aperm(x, c(2, 1), FALSE)) == dim(x))
> stopifnot(is.null(dimnames(aperm(x, c(2, 1), FALSE))))
>
> # check the types
> x <- array(1:24, c(4, 6))
> stopifnot(all.equal(aperm(x, c(2, 1)), t(x)))
> stopifnot(is.integer(aperm(x, c(2, 1))))
>
> x <- x + 0.0
> stopifnot(all.equal(aperm(x, c(2, 1)), t(x)))
> stopifnot(is.double(aperm(x, c(2, 1))))
>
> x <- x + 0.0i
> stopifnot(all.equal(aperm(x, c(2, 1)), t(x)))
>
> x[] <- LETTERS[1:24]
> stopifnot(all.equal(aperm(x, c(2, 1)), t(x)))
>
> x <- array(list("fred"), c(4, 6))
> x[[3, 4]] <- 1:10
> stopifnot(all.equal(aperm(x, c(2, 1)), t(x)))
> ## end of moved from aperm.Rd
>
>
> ## append
> stopifnot(append(1:5, 0:1, after=3) == append(1:3, c(0:1, 4:5)))
> ## end of moved from append.Rd
>
>
> ## as.POSIXlt
> z <- Sys.time()
> stopifnot(range(z) == z,
+ 	  min(z) == z,
+ 	  max(z) == z,
+ 	  mean(z) == z)
> ## end of moved from as.POSIXlt.Rd
>
>
> ## autoload
> stopifnot(ls("Autoloads") == ls(envir = .AutoloadEnv))
> ## end of moved from autoload.Rd
>
>
> ## backsolve
> r <- rbind(c(1,2,3),
+ 	   c(0,1,1),
+ 	   c(0,0,2))
> ( y <- backsolve(r, x <- c(8,4,2)) ) # -1 3 1
[1] -1  3  1
> r %*% y # == x = (8,4,2)
     [,1]
[1,]    8
[2,]    4
[3,]    2
> ( y2 <- backsolve(r, x, transpose = TRUE)) # 8 -12 -5
[1]   8 -12  -5
> stopifnot(all.equal(drop(t(r) %*% y2), x))
> stopifnot(all.equal(y, backsolve(t(r), x, upper = FALSE, transpose = TRUE)))
> stopifnot(all.equal(y2, backsolve(t(r), x, upper = FALSE, transpose = FALSE)))
> ## end of moved from backsolve.Rd
>
>
> ## basename
> dirname(character(0))
character(0)
> ## end of moved from basename.Rd
>
>
> ## Bessel
> ## Check the Scaling :
> nus <- c(0:5,10,20)
> x <- seq(0,40,len=801)[-1]
> for(nu in nus)
+    stopifnot(abs(1- besselK(x,nu)*exp( x) / besselK(x,nu,expo=TRUE)) < 2e-15)
> for(nu in nus)
+    stopifnot(abs(1- besselI(x,nu)*exp(-x) / besselI(x,nu,expo=TRUE)) < 1e-15)
> ## end of moved from Bessel.Rd
>
>
> ## c
> ll <- list(A = 1, c="C")
> stopifnot(identical(c(ll, d=1:3), c(ll, as.list(c(d=1:3)))))
> ## moved from c.Rd
>
>
> ## Cauchy
> stopifnot(all.equal(dcauchy(-1:4), 1 / (pi*(1 + (-1:4)^2))))
> ## end of moved from Cauchy.Rd
>
>
> ## chol
> ( m <- matrix(c(5,1,1,3),2,2) )
     [,1] [,2]
[1,]    5    1
[2,]    1    3
> ( cm <- chol(m) )
         [,1]      [,2]
[1,] 2.236068 0.4472136
[2,] 0.000000 1.6733201
> stopifnot(abs(m	 -  t(cm) %*% cm) < 100* .Machine$double.eps)
> ( Lcm <- La.chol(m) )
         [,1]      [,2]
[1,] 2.236068 0.4472136
[2,] 0.000000 1.6733201
> stopifnot(abs(m - crossprod(Lcm))  < 100* .Machine$double.eps)
>
> ## check with pivoting
> ( m <- matrix(c(5,1,1,3),2,2) )
     [,1] [,2]
[1,]    5    1
[2,]    1    3
> ( cm <- chol(m, TRUE) )
         [,1]      [,2]
[1,] 2.236068 0.4472136
[2,] 0.000000 1.6733201
attr(,"pivot")
[1] 1 2
attr(,"rank")
[1] 2
> stopifnot(abs(m	 -  t(cm) %*% cm) < 100* .Machine$double.eps)
>
> x <- matrix(c(1:5, (1:5)^2), 5, 2)
> m <- crossprod(x)
> Q <- chol(m)
> stopifnot(all.equal(t(Q) %*% Q, m))
>
> Q <- chol(m, pivot = TRUE)
> pivot <- attr(Q, "pivot")
> oo <- order(pivot)
> stopifnot(all.equal(t(Q[, oo]) %*% Q[, oo], m))
> stopifnot(all.equal(t(Q) %*% Q, m[pivot, pivot]))
>
> # now for something positive semi-definite
> x <- cbind(x, x[, 1]+3*x[, 2])
> m <- crossprod(x)
> qr(m)$rank # is 2, as it should be
[1] 2
>
> (Q <- chol(m, pivot = TRUE)) # NB wrong rank here ... see Warning section.
         [,1]     [,2]          [,3]
[1,] 101.0742 7.222415  3.128394e+01
[2,]   0.0000 1.684259 -5.614195e-01
[3,]   0.0000 0.000000  1.010646e-07
attr(,"pivot")
[1] 3 1 2
attr(,"rank")
[1] 3
> pivot <- attr(Q, "pivot")
> oo <- order(pivot)
> stopifnot(all.equal(t(Q[, oo]) %*% Q[, oo], m))
> stopifnot(all.equal(t(Q) %*% Q, m[pivot, pivot]))
> ## end of moved from chol.Rd
>
>
> ## chol2inv
> cma <- chol(ma	<- cbind(1, 1:3, c(1,3,7)))
> stopifnot(all.equal(diag(3), ma %*% chol2inv(cma)))
> stopifnot(all.equal(diag(3), ma %*% La.chol2inv(cma)))
> ## end of moved from chol2inv.Rd
>
>
> ## col2rgb
> pp <- palette(); names(pp) <- pp # add & use names :
> stopifnot(col2rgb(1:8) == print(col2rgb(pp)))
      black red green3 blue cyan magenta yellow gray
red       0 255      0    0    0     255    255  190
green     0   0    205    0  255       0    255  190
blue      0   0      0  255  255     255      0  190
> stopifnot(col2rgb("#08a0ff") == c(8, 160, 255))
> grC <- col2rgb(paste("gray",0:100,sep=""))
> stopifnot(grC["red",] == grC["green",],
+ 	  grC["red",] == grC["blue",],
+ 	  grC["red", 1:4] == c(0,3,5,8))
> ## end of moved from col2rgb.Rd
>
>
> ## complex
> z <- 0i ^ (-3:3)
> stopifnot(Re(z) == 0 ^ (-3:3))
> set.seed(123)
> z <- complex(real = rnorm(100), imag = rnorm(100))
> stopifnot(Mod ( 1 -  sin(z) / ( (exp(1i*z)-exp(-1i*z))/(2*1i) ))
+ 	  < 20 * .Machine$double.eps)
> ## end of moved from complex.Rd
>
>
> ## Constants
> stopifnot(
+  nchar(letters) == 1,
+  month.abb == substr(month.name, 1, 3)
+ )
>
> eps <- .Machine$double.eps
> stopifnot(all.equal(pi, 4*atan(1), tol= 2*eps))
>
> # John Machin (1705) computed 100 decimals of pi :
> stopifnot(all.equal(pi/4, 4*atan(1/5) - atan(1/239), 4*eps))
> ## end of moved from Constants.Rd
>
>
> ## cor
> stopifnot(  is.na(var(1)),
+ 	  !is.nan(var(1)))
>
> zz <- c(-1.30167, -0.4957, -1.46749, 0.46927)
> r <- cor(zz,zz); r - 1
[1] 0
> stopifnot(r <= 1) # fails in R <= 1.3.x, for versions of Linux and Solaris
> ## end of moved from cor.Rd
>
>
> ## DateTimeClasses
> (dls <- .leap.seconds[-1] - .leap.seconds[-22])
Time differences of 184, 365, 365, 365, 366, 365, 365, 365, 547, 730, 731, 365, 549, 731, 365, 547, 365, 365, 549, 547, 549 days
> table(dls)
dls
184 365 366 547 549 730 731
  1  10   1   3   3   1   2
> ## end of moved from DateTimeClasses.Rd
>
>
> ## deriv
> trig.exp <- expression(sin(cos(x + y^2)))
> D.sc <- D(trig.exp, "x")
> dxy <- deriv(trig.exp, c("x", "y"))
> y <- 1
> stopifnot(eval(D.sc) ==
+ 	  attr(eval(dxy),"gradient")[,"x"])
> ff <- y ~ sin(cos(x) * y)
> stopifnot(all.equal(deriv(ff, c("x","y"), func = TRUE ),
+ 		    deriv(ff, c("x","y"), func = function(x,y){ } )))
> ## end of moved from deriv.Rd
>
>
> ## diff
> x <- cumsum(cumsum(1:10))
> stopifnot(diff(x, lag = 2) == x[(1+2):10] - x[1:(10 - 2)],
+ 	  diff(x, lag = 2) == (3:10)^2,
+ 	  diff(diff(x))	   == diff(x, differences = 2))
> ## end of moved from diff.Rd
>
>
> ## duplicated
> x <- c(9:20, 1:5, 3:7, 0:8)
> ## extract unique elements
> (xu <- x[!duplicated(x)])
 [1]  9 10 11 12 13 14 15 16 17 18 19 20  1  2  3  4  5  6  7  0  8
> stopifnot(xu == unique(x), # but unique(x) is more efficient
+ 	  0:20 == sort(x[!duplicated(x)]))
>
> data(iris)
> stopifnot(duplicated(iris)[143] == TRUE)
> ## end of moved from duplicated.Rd
>
>
> ## eigen
> Meps <- .Machine$double.eps
> set.seed(321, kind = "default")	 # force a particular seed
> m <- matrix(round(rnorm(25),3), 5,5)
> sm <- m + t(m) #- symmetric matrix
> em <- eigen(sm); V <- em$vect
> print(lam <- em$values) # ordered DEcreasingly
[1]  5.1738946  3.1585064  0.6849974 -1.6299494 -2.5074489
>
> stopifnot(
+  abs(sm %*% V - V %*% diag(lam))	  < 60*Meps,
+  abs(sm	      - V %*% diag(lam) %*% t(V)) < 60*Meps)
>
> ##------- Symmetric = FALSE:  -- different to above : ---
>
> em <- eigen(sm, symmetric = FALSE); V2 <- em$vect
> print(lam2 <- em$values) # ordered decreasingly in ABSolute value !
[1]  5.1738946  3.1585064 -2.5074489 -1.6299494  0.6849974
> print(i <- rev(order(lam2)))
[1] 1 2 5 4 3
> stopifnot(abs(lam - lam2[i]) < 60 * Meps)
>
> zapsmall(Diag <- t(V2) %*% V2)
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    0    0    0    0
[2,]    0    1    0    0    0
[3,]    0    0    1    0    0
[4,]    0    0    0    1    0
[5,]    0    0    0    0    1
> stopifnot( abs(1- diag(Diag)) < 60*Meps)
>
> stopifnot(abs(sm %*% V2 - V2 %*% diag(lam2))		< 60*Meps,
+ 	  abs(sm	 - V2 %*% diag(lam2) %*% t(V2)) < 60*Meps)
>
> ## Re-ordered as with symmetric:
> sV <- V2[,i]
> slam <- lam2[i]
> stopifnot(abs(sm %*% sV -  sV %*% diag(slam))		  < 60*Meps)
> stopifnot(abs(sm	-  sV %*% diag(slam) %*% t(sV)) < 60*Meps)
> ## sV  *is* now equal to V  -- up to sign (+-) and rounding errors
> stopifnot(abs(c(1 - abs(sV / V)))	<     1000*Meps)
> ## end of moved from eigen.Rd
>
>
> ## euro
> data(euro)
> stopifnot(euro == signif(euro,6), euro.cross == outer(1/euro, euro))
> ## end of moved from euro.Rd
>
>
> ## Exponential
> r <- rexp(100)
> stopifnot(abs(1 - dexp(1, r) / (r*exp(-r))) < 1e-14)
> ## end of moved from Exponential.Rd
>
>
> ## family
> gf <- Gamma()
> stopifnot(1:10 == gf$linkfun(gf$linkinv(1:10)))
> ## end of moved from family.Rd
>
>
> ## fft
> set.seed(123)
> eps <- 1e-11
> for(N in 1:130) {
+     x <- rnorm(N)
+     if(N %% 5 == 0) {
+ 	m5 <- matrix(x,ncol=5)
+ 	stopifnot(apply(m5,2,fft) == mvfft(m5))
+     }
+     dd <- Mod(1 - (f2 <- fft(fft(x), inverse=TRUE)/(x*length(x))))
+     stopifnot(dd < eps)
+ }
> ## end of moved from fft.Rd
>
>
> ## findint
> N <- 100
> X <- sort(round(rt(N, df=2), 2))
> tt <- c(-100, seq(-2,2, len=201), +100)
> it <- findInterval(tt, X)
>
> ## See that this is N * Fn(.) :
> tt <- c(tt,X)
> eps <- 100 * .Machine$double.eps
> require(stepfun)
Loading required package: stepfun
[1] TRUE
> stopifnot(it[c(1,203)] == c(0, 100),
+ 	  all.equal(N * ecdf(X)(tt),
+ 		    findInterval(tt, X),  tol = eps),
+ 	  findInterval(tt,X) ==	 apply( outer(tt, X, ">="), 1, sum)
+ 	  )
> ## end of moved from findint.Rd
>
>
> ## format
> (dd <- sapply(1:10, function(i)paste((9:0)[1:i],collapse="")))
 [1] "9"          "98"         "987"        "9876"       "98765"
 [6] "987654"     "9876543"    "98765432"   "987654321"  "9876543210"
> np <- nchar(pd <- prettyNum(dd, big.mark="'"))
> stopifnot(sapply(0:2, function(m)
+ 	   all(grep("'", substr(pd, 1, np - 4*m)) == (4+3*m):10)))
> ## end of moved from format.Rd
>
>
> ## Geometric
> pp <- sort(c((1:9)/10, 1 - .2^(2:8)))
> print(qg <- qgeom(pp, prob = .2))
 [1]  0  0  1  2  3  4  5  7 10 14 21 28 36 43 50 57
> ## test that qgeom is an inverse of pgeom
> print(qg1 <- qgeom(pgeom(qg, prob=.2), prob =.2))
 [1]  0  0  1  2  3  4  5  7 10 14 21 28 36 43 50 57
> stopifnot(identical(qg, qg1))
> ## moved from Geometric.Rd
>
>
> ## glm
> ## these are the same -- example from Jim Lindsey
> y <- rnorm(20)
> y1 <- y[-1]; y2 <- y[-20]
> summary(g1 <- glm(y1 - y2 ~ 1))

Call:
glm(formula = y1 - y2 ~ 1)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-1.49564  -0.47332   0.06862   0.43131   1.37700

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.01213    0.17481   0.069    0.945

(Dispersion parameter for gaussian family taken to be 0.5806225)

    Null deviance: 10.451  on 18  degrees of freedom
Residual deviance: 10.451  on 18  degrees of freedom
AIC: 46.563

Number of Fisher Scoring iterations: 2

> summary(g2 <- glm(y1 ~ offset(y2)))

Call:
glm(formula = y1 ~ offset(y2))

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-1.49564  -0.47332   0.06862   0.43131   1.37700

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.01213    0.17481   0.069    0.945

(Dispersion parameter for gaussian family taken to be 0.5806225)

    Null deviance: 10.451  on 18  degrees of freedom
Residual deviance: 10.451  on 18  degrees of freedom
AIC: 46.563

Number of Fisher Scoring iterations: 2

> Eq <- function(x,y) all.equal(x,y, tol = 1e-12)
> stopifnot(Eq(coef(g1), coef(g2)),
+ 	  Eq(deviance(g1), deviance(g2)),
+ 	  Eq(resid(g1), resid(g2)))
> ## from logLik.glm.Rd
> "anorexia" <-
+ structure(list(Treat = structure(c(2, 2, 2, 2, 2, 2, 2, 2, 2,
+ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,
+ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
+ 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3
+ ), .Label = c("CBT", "Cont", "FT"), class = "factor"), Prewt = c(80.7,
+ 89.4, 91.8, 74, 78.1, 88.3, 87.3, 75.1, 80.6, 78.4, 77.6, 88.7,
+ 81.3, 78.1, 70.5, 77.3, 85.2, 86, 84.1, 79.7, 85.5, 84.4, 79.6,
+ 77.5, 72.3, 89, 80.5, 84.9, 81.5, 82.6, 79.9, 88.7, 94.9, 76.3,
+ 81, 80.5, 85, 89.2, 81.3, 76.5, 70, 80.4, 83.3, 83, 87.7, 84.2,
+ 86.4, 76.5, 80.2, 87.8, 83.3, 79.7, 84.5, 80.8, 87.4, 83.8, 83.3,
+ 86, 82.5, 86.7, 79.6, 76.9, 94.2, 73.4, 80.5, 81.6, 82.1, 77.6,
+ 83.5, 89.9, 86, 87.3), Postwt = c(80.2, 80.1, 86.4, 86.3, 76.1,
+ 78.1, 75.1, 86.7, 73.5, 84.6, 77.4, 79.5, 89.6, 81.4, 81.8, 77.3,
+ 84.2, 75.4, 79.5, 73, 88.3, 84.7, 81.4, 81.2, 88.2, 78.8, 82.2,
+ 85.6, 81.4, 81.9, 76.4, 103.6, 98.4, 93.4, 73.4, 82.1, 96.7,
+ 95.3, 82.4, 72.5, 90.9, 71.3, 85.4, 81.6, 89.1, 83.9, 82.7, 75.7,
+ 82.6, 100.4, 85.2, 83.6, 84.6, 96.2, 86.7, 95.2, 94.3, 91.5,
+ 91.9, 100.3, 76.7, 76.8, 101.6, 94.9, 75.2, 77.8, 95.5, 90.7,
+ 92.5, 93.8, 91.7, 98)), .Names = c("Treat", "Prewt", "Postwt"
+ ), class = "data.frame", row.names = c("1", "2", "3", "4", "5",
+ "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16",
+ "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27",
+ "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38",
+ "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49",
+ "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60",
+ "61", "62", "63", "64", "65", "66", "67", "68", "69", "70", "71",
+ "72"))
> anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
+ 	    family = gaussian, data = anorexia)
> summary(anorex.1)

Call:
glm(formula = Postwt ~ Prewt + Treat + offset(Prewt), family = gaussian,
    data = anorexia)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-14.1083   -4.2773   -0.5484    5.4838   15.2922

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  49.7711    13.3910   3.717 0.000410 ***
Prewt        -0.5655     0.1612  -3.509 0.000803 ***
TreatCont    -4.0971     1.8935  -2.164 0.033999 *
TreatFT       4.5631     2.1333   2.139 0.036035 *
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Dispersion parameter for gaussian family taken to be 48.69504)

    Null deviance: 4525.4  on 71  degrees of freedom
Residual deviance: 3311.3  on 68  degrees of freedom
AIC: 489.97

Number of Fisher Scoring iterations: 2

> Eq <- function(x,y) all.equal(x,y, tol = 1e-12)
> stopifnot(Eq(AIC(anorex.1), anorex.1$aic),
+ 	  Eq(AIC(g1), g1$aic),
+ 	  Eq(AIC(g2), g2$aic))
> ## next was wrong in 1.4.1
> x <- 1:10
> lmx <- logLik(lm(x ~ 1)); glmx <- logLik(glm(x ~ 1))
> stopifnot(all.equal(as.vector(lmx), as.vector(glmx)),
+ 	  all.equal(attr(lmx, 'df'), attr(glmx, 'df')))
> ## end of moved from glm.Rd and logLik.glm.Rd
>
>
> ## Hyperbolic
> Ceps <- .Machine$double.eps # ``Computer epsilon''
> x <- seq(-3, 3, len=200)
> stopifnot(
+  abs(cosh(x) - (exp(x) + exp(-x))/2) < 20*Ceps,
+  abs(sinh(x) - (exp(x) - exp(-x))/2) < 20*Ceps,
+  Mod(cosh(x) - cos(1i*x))	< 20*Ceps,
+  Mod(sinh(x) - sin(1i*x)/1i)	< 20*Ceps,
+  abs(tanh(x)*cosh(x) - sinh(x)) < 20*Ceps
+ )
>
> stopifnot(abs(asinh(sinh(x)) - x) < 20*Ceps)
> stopifnot(abs(acosh(cosh(x)) - abs(x)) < 1000*Ceps) #- imprecise for small x
> stopifnot(abs(atanh(tanh(x)) - x) < 100*Ceps)
>
> stopifnot(abs(asinh(x) - log(x + sqrt(x^2 + 1))) < 100*Ceps)
> cx <- cosh(x)
> stopifnot(abs(acosh(cx) - log(cx + sqrt(cx^2 - 1))) < 1000*Ceps)
> ## end of moved from Hyperbolic.Rd
>
>
> ## image
> ## Degenerate, should still work
> image(as.matrix(1))
> image(matrix(pi,2,4))
> x <- seq(0,1,len=100)
> image(x, 1, matrix(x), col=heat.colors(10))
> image(x, 1, matrix(x), col=heat.colors(10), oldstyle = TRUE)
> image(x, 1, matrix(x), col=heat.colors(10), breaks = seq(0.1,1.1,len=11))
> ## end of moved from image.Rd
>
>
> ## integrate
> (ii <- integrate(dnorm, -1.96, 1.96))
0.9500042 with absolute error < 1.0e-11
> (i1 <- integrate(dnorm, -Inf, Inf))
1 with absolute error < 9.4e-05
> stopifnot(all.equal(0.9500042097, ii$val, tol = ii$abs.err, scale=1),
+ 	  all.equal( 1,		  i1$val, tol = i1$abs.err, scale=1))
>
> integrand <- function(x) {1/((x+1)*sqrt(x))}
> (ii <- integrate(integrand, lower = 0, upper = Inf, rel.tol = 1e-10))
3.141593 with absolute error < 2.8e-12
> stopifnot(all.equal(pi, ii$val, tol = ii$abs.err, scale=1))
> ## end of moved from integrate.Rd
>
>
> ## is.finite
> ( weird.values <- c(-20.9/0, 1/0, 0/0, NA) )
[1] -Inf  Inf  NaN   NA
>
> Mmax <- .Machine$double.xmax
> Mmin <- .Machine$double.xmin
> ( X.val <- c(Mmin*c(2^(-10:3),1e5,1e10),
+ 	     Mmax*c(1e-10,1e-5,2^(-3:0),1.001)) )
 [1] 2.172924e-311 4.345847e-311 8.691695e-311 1.738339e-310 3.476678e-310
 [6] 6.953356e-310 1.390671e-309 2.781342e-309 5.562685e-309 1.112537e-308
[11] 2.225074e-308 4.450148e-308 8.900295e-308 1.780059e-307 2.225074e-303
[16] 2.225074e-298 1.797693e+298 1.797693e+303 2.247116e+307 4.494233e+307
[21] 8.988466e+307 1.797693e+308           Inf
> ( tst.val <- sort(c(X.val, weird.values), na.last = TRUE) )
 [1]          -Inf 2.172924e-311 4.345847e-311 8.691695e-311 1.738339e-310
 [6] 3.476678e-310 6.953356e-310 1.390671e-309 2.781342e-309 5.562685e-309
[11] 1.112537e-308 2.225074e-308 4.450148e-308 8.900295e-308 1.780059e-307
[16] 2.225074e-303 2.225074e-298 1.797693e+298 1.797693e+303 2.247116e+307
[21] 4.494233e+307 8.988466e+307 1.797693e+308           Inf           Inf
[26]           NaN            NA
> ( x2 <- c(-1:1/0,pi,1,NA) )
[1]     -Inf      NaN      Inf 3.141593 1.000000       NA
> ( z2 <- c(x2, 1+1i, Inf -Inf* 1i) )
[1]     -Inf+  0i      NaN+  0i      Inf+  0i 3.141593+  0i 1.000000+  0i
[6]            NA 1.000000+  1i      NaN-Infi
>
> is.inf <-
+   function(x) (is.numeric(x) || is.complex(x)) && !is.na(x) && !is.finite(x)
>
> for(x in list(tst.val, x2, z2))
+   print(cbind(format(x), is.infinite=format(is.infinite(x))), quote=FALSE)
                    is.infinite
 [1,]          -Inf  TRUE
 [2,] 2.172924e-311 FALSE
 [3,] 4.345847e-311 FALSE
 [4,] 8.691695e-311 FALSE
 [5,] 1.738339e-310 FALSE
 [6,] 3.476678e-310 FALSE
 [7,] 6.953356e-310 FALSE
 [8,] 1.390671e-309 FALSE
 [9,] 2.781342e-309 FALSE
[10,] 5.562685e-309 FALSE
[11,] 1.112537e-308 FALSE
[12,] 2.225074e-308 FALSE
[13,] 4.450148e-308 FALSE
[14,] 8.900295e-308 FALSE
[15,] 1.780059e-307 FALSE
[16,] 2.225074e-303 FALSE
[17,] 2.225074e-298 FALSE
[18,] 1.797693e+298 FALSE
[19,] 1.797693e+303 FALSE
[20,] 2.247116e+307 FALSE
[21,] 4.494233e+307 FALSE
[22,] 8.988466e+307 FALSE
[23,] 1.797693e+308 FALSE
[24,]           Inf  TRUE
[25,]           Inf  TRUE
[26,]           NaN FALSE
[27,]            NA FALSE
              is.infinite
[1,]     -Inf  TRUE
[2,]      NaN FALSE
[3,]      Inf  TRUE
[4,] 3.141593 FALSE
[5,] 1.000000 FALSE
[6,]       NA FALSE
                    is.infinite
[1,]     -Inf+  0i   TRUE
[2,]      NaN+  0i  FALSE
[3,]      Inf+  0i   TRUE
[4,] 3.141593+  0i  FALSE
[5,] 1.000000+  0i  FALSE
[6,]             NA FALSE
[7,] 1.000000+  1i  FALSE
[8,]      NaN-Infi   TRUE
>
> rbind(is.nan(tst.val),
+       is.na (tst.val))
      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] [,12]
[1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]
[1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
     [,25] [,26] [,27]
[1,] FALSE  TRUE FALSE
[2,] FALSE  TRUE  TRUE
> tst.val [ is.nan(tst.val) !=  is.na(tst.val) ]
[1] NA
>
> stopifnot(
+     is.na(0/0),
+     !is.na(Inf),
+     is.nan(0/0),
+
+     !is.nan(NA)	 &&  !is.infinite(NA)  && !is.finite(NA),
+      is.nan(NaN) &&  !is.infinite(NaN) && !is.finite(NaN),
+     !is.nan(c(1,NA)),
+     c(FALSE,TRUE,FALSE) == is.nan(c   (1,NaN,NA)),
+     c(FALSE,TRUE,FALSE) == is.nan(list(1,NaN,NA))#-> FALSE in older versions
+ )
>
> stopifnot(identical(lgamma(Inf), Inf))
> stopifnot(identical(Inf + Inf, Inf))
> stopifnot(identical(Inf - Inf, NaN))
> stopifnot(identical((1/0) * (1/0), Inf))
> stopifnot(identical((1/0) / (1/0), NaN))
> stopifnot(identical(exp(-Inf), 0))
> stopifnot(identical(log(0), -Inf))
> stopifnot(identical((-1)/0, -Inf))
> pm <- c(-1,1) # 'pm' = plus/minus
> stopifnot(atan(Inf*pm) == pm*pi/2)
> ## end of moved from is.finite.Rd
>
>
> ## kronecker
> ( M <- matrix(1:6, ncol=2) )
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
> stopifnot(kronecker(4, M)==4 * M)
> # Block diagonal matrix:
> stopifnot(kronecker(diag(1, 3), M) == diag(1, 3) %x% M)
> ## end of moved from kronecker.Rd
>
>
> ## log
> stopifnot(all.equal(log(1:10), log(1:10, exp(1))))
> stopifnot(all.equal(log10(30), log(30, 10)))
> stopifnot(all.equal(log2(2^pi), 2^log2(pi)))
> stopifnot(Mod(pi - log(exp(pi*1i)) / 1i) < .Machine$double.eps)
> stopifnot(Mod(1+exp(pi*1i)) < .Machine$double.eps)
> ## end of moved from Log.Rd
>
>
> ## logistic
> eps <- 100 * .Machine$double.eps
> x <- c(0:4, rlogis(100))
> stopifnot(all.equal(plogis(x),	1 / (1 + exp(-x)), tol = eps))
> stopifnot(all.equal(plogis(x, lower=FALSE),  exp(-x)/ (1 + exp(-x)), tol = eps))
> stopifnot(all.equal(plogis(x, lower=FALSE, log=TRUE), -log(1 + exp(x)),
+ 		    tol = eps))
> stopifnot(all.equal(dlogis(x), exp(x) * (1 + exp(x))^-2, tol = eps))
> ## end of moved from Logistic.Rd
>
>
> ## Lognormal
> x <- rlnorm(1000)	# not yet always :
> stopifnot(abs(x	 -  qlnorm(plnorm(x))) < 1e4 * .Machine$double.eps * x)
> ## end of moved from Lognormal.Rd
>
>
> ## lower.tri
> ma <- matrix(1:20, 4, 5)
> stopifnot(lower.tri(ma) == !upper.tri(ma, diag=TRUE))
> ## end of moved from lower.tri.Rd
>
>
> ## make.names
> stopifnot(make.names(letters) == letters)
> ## end of make.names
>
>
> ## mean
> x <- c(0:10, 50)
> stopifnot(all.equal(mean(x, trim = 0.5), median(x)))
> ## moved from mean.Rd
>
>
> ## Multinom
> N <- 20
> pr <- c(1,3,6,10) # normalization not necessary for generation
> set.seed(153)
> rr <- rmultinom(5000, N, prob = pr)
> stopifnot(colSums(rr) == N)
> (m <- rowMeans(rr))
[1] 0.9952 2.9802 6.0382 9.9864
> all.equal(m, N * pr/sum(pr)) # rel.error ~0.003
[1] "Mean relative  difference: 0.00382"
> stopifnot(max(abs(m/(N*pr/sum(pr)) - 1)) < 0.01)
>
> (Pr <- dmultinom(c(0,0,3), prob = c(1, 1, 14)))
[1] 0.6699219
> stopifnot(all.equal(Pr, dbinom(3, 3, p = 14/16)))
>
> X <- t(as.matrix(expand.grid(0:3, 0:3)))
> X <- X[, colSums(X) <= 3]
> X <- rbind(X, 3:3 - colSums(X))
> for(p in list(c(1,2,5), 1:3, 3:1, 2:0, 0:2, c(1,2,1), c(0,0,1))) {
+   px <- apply(X, 2, function(x) dmultinom(x, prob = p))
+   stopifnot(identical(TRUE, all.equal(sum(px), 1)))
+ }
> ## end of moved from Multinom.Rd
>
>
> ## plot.lm
> # which=4 failed in R 1.0.1
> par(mfrow=c(1,1), oma= rep(0,4))
> data(longley)
> summary(lm.fm2 <- lm(Employed ~ . - Population - GNP.deflator, data = longley))

Call:
lm(formula = Employed ~ . - Population - GNP.deflator, data = longley)

Residuals:
     Min       1Q   Median       3Q      Max
-0.42165 -0.12457 -0.02416  0.08369  0.45268

Coefficients:
               Estimate Std. Error t value Pr(>|t|)
(Intercept)  -3.599e+03  7.406e+02  -4.859 0.000503 ***
GNP          -4.019e-02  1.647e-02  -2.440 0.032833 *
Unemployed   -2.088e-02  2.900e-03  -7.202 1.75e-05 ***
Armed.Forces -1.015e-02  1.837e-03  -5.522 0.000180 ***
Year          1.887e+00  3.828e-01   4.931 0.000449 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 0.2794 on 11 degrees of freedom
Multiple R-Squared: 0.9954,	Adjusted R-squared: 0.9937
F-statistic: 589.8 on 4 and 11 DF,  p-value: 9.5e-13

> for(wh in 1:4) plot(lm.fm2, which = wh)
> ## end of moved from plot.lm.Rd
>
>
> ## Poisson
> dpois(c(0, 1, 0.17, 0.77), 1)
[1] 0.3678794 0.3678794 0.0000000 0.0000000
Warning messages:
1: non-integer x = 0.170000
2: non-integer x = 0.770000
> ## end of moved from Poisson.Rd
>
>
> ## qr
> ## tests of complex case
> set.seed(1)
> A <- matrix(rnorm(25), 5, 5, dimnames=list(1:5, letters[1:5]))
> qr.solve(A, 1:5)
        a         b         c         d         e
 3.795761 -7.034826 -7.390881  6.397972  9.866288
> A[] <- as.complex(A)
> qr.coef(qr(A), 1:5)
[1]  3.795761+0i -7.034826+0i -7.390881+0i  6.397972+0i  9.866288+0i
> qr.solve(A, 1:5)
[1]  3.795761+0i -7.034826+0i -7.390881+0i  6.397972+0i  9.866288+0i
>
> ## check for rank-deficient cases
> X <- cbind(1:3, 1:3, 1)
> stopifnot(all.equal(qr.X(qr(X)), X))
> ## end of moved from qr.Rd
>
>
> ## qraux
> data(LifeCycleSavings)
> p <- ncol(x <- LifeCycleSavings[,-1]) # not the `sr'
> qrstr <- qr(x)	 # dim(x) == c(n,p)
> Q <- qr.Q(qrstr) # dim(Q) == dim(x)
> R <- qr.R(qrstr) # dim(R) == ncol(x)
> X <- qr.X(qrstr) # X == x
> stopifnot(all.equal(X,	as.matrix(x)))
>
> ## X == Q %*% R :
> stopifnot((1 - X /( Q %*% R))< 100*.Machine$double.eps)
>
> dim(Qc <- qr.Q(qrstr, complete=TRUE)) # Square: dim(Qc) == rep(nrow(x),2)
> stopifnot((crossprod(Qc) - diag(nrow(x))) < 10*.Machine $double.eps)
>
> QD <- qr.Q(qrstr, D=1:p)      # QD == Q \%*\% diag(1:p)
> stopifnot(QD - Q %*% diag(1:p)	< 8* .Machine$double.eps)
>
> dim(Rc <- qr.R(qrstr, complete=TRUE)) # == dim(x)
> dim(Xc <- qr.X(qrstr, complete=TRUE)) # square: nrow(x) ^ 2
> dimnames(X) <- NULL
> stopifnot(all.equal(Xc[,1:p], X))
> ## end of moved from qraux.Rd
>
>
> ## quantile
> x <- rnorm(1001)
> n <- length(x) ## the following is exact, because 1/(1001-1) is exact:
> stopifnot(sort(x) == quantile(x, probs = ((1:n)-1)/(n-1), names=FALSE))
>
> n <- 777
> ox <- sort(x <- round(rnorm(n),1))# round() produces ties
> ox <- c(ox, ox[n]) #- such that ox[n+1] := ox[n]
> p <- c(0,1,runif(100))
> i <- floor(r <- 1 + (n-1)*p)
> f <- r - i
> stopifnot(abs(quantile(x,p) - ((1-f)*ox[i] + f*ox[i+1])) < 20*.Machine$double.eps)
> ## end of moved from quantile.Rd
>
>
> ## rep
> stopifnot(identical(rep(letters, 0), character(0)),
+ 	  identical(rep.int(1:2, 0), integer(0)))
> ## end of moved from rep.Rd
>
>
> ## Round
> x1 <- seq(-2, 4, by = .5)
> non.int <- ceiling(x1) != floor(x1)
> stopifnot(
+  trunc(x1) == as.integer(x1),
+  non.int == (ceiling(x1) != trunc(x1) | trunc(x1) != floor(x1)),
+  (signif(x1, 1) != round(x1,1)) == (non.int & abs(x1) > 1)
+ )
> ## end of moved from Round.Rd
>
>
> ## seq
> stopifnot(
+  3 == seq(3,3,	by=pi),
+  3 == seq(3,3.1,by=pi),
+  seq(1,6,by=3) == c(1,4),
+  seq(10,4.05,by=-3) == c(10,7)
+ )
> ## end of moved from seq.Rd
>
>
> ## sort
> data(swiss)
> x <- swiss$Education[1:25]
> stopifnot(!is.unsorted(sort(x)),
+ 	  !is.unsorted(LETTERS),
+ 	   is.unsorted(c(NA,1:3,2), na.rm = TRUE))
>
> for(n in 1:20) {
+     z <- rnorm(n)
+     for(x in list(z, round(z,1))) { ## 2nd one has ties
+        qxi <- sort(x,  method = "quick",  index.return = TRUE)
+        stopifnot(qxi$x == sort(x, method = "shell"),
+ 		 any(duplicated(x)) || qxi$ix == order(x),
+ 		 x[qxi$ix] == qxi$x)
+    }
+ }
> ## end of moved from sort.Rd
>
>
> ## substr
> ss <- substring("abcdef",1:6,1:6)
> stopifnot(ss == strsplit ("abcdef",NULL)[[1]])
> x <- c("asfef", "qwerty", "yuiop[", "b", "stuff.blah.yech")
> stopifnot(substr(x, 2, 5) == substring(x, 2, 5))
> ## end of moved from substr.Rd
>
>
> ## svd
> hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
> str(X <- hilbert(9)[,1:6])
 num [1:9, 1:6] 1.000 0.500 0.333 0.250 0.200 ...
> str(s <- svd(X))
List of 3
 $ d: num [1:6] 1.67e+00 2.77e-01 2.22e-02 1.08e-03 3.24e-05 ...
 $ u: num [1:9, 1:6] -0.724 -0.428 -0.312 -0.248 -0.206 ...
 $ v: num [1:6, 1:6] -0.736 -0.443 -0.327 -0.263 -0.220 ...
> Eps <- 100 * .Machine$double.eps
>
> D <- diag(s$d)
> stopifnot(abs(X - s$u %*% D %*% t(s$v)) < Eps)#	 X = U D V'
> stopifnot(abs(D - t(s$u) %*% X %*% s$v) < Eps)#	 D = U' X V
>
> X <- cbind(1, 1:7)
> str(s <- svd(X)); D <- diag(s$d)
List of 3
 $ d: num [1:2] 12.07  1.16
 $ u: num [1:7, 1:2] 0.0976 0.1788 0.2601 0.3413 0.4225 ...
 $ v: num [1:2, 1:2]  0.198  0.980  0.980 -0.198
> stopifnot(abs(X - s$u %*% D %*% t(s$v)) < Eps)#	 X = U D V'
> stopifnot(abs(D - t(s$u) %*% X %*% s$v) < Eps)#	 D = U' X V
> ## end of moved from svd.Rd
>
>
> ## trace
> hasMethods <- .isMethodsDispatchOn() ## trace requires methods
> f <- function(x, y) { c(x,y)}
> xy <- 0
>
> trace(f, quote(x <- c(1, x)), exit = quote(xy <<- x), print = FALSE)
[1] "f"
>
> fxy <- f(2,3)
>
> stopifnot(identical(fxy, c(1,2,3)))
> stopifnot(identical(xy, c(1,2)))
>
> untrace(f)
>
> ## a generic and its methods
>
> setGeneric("f")
[1] "f"
>
> setMethod("f", c("character", "character"), function(x,	 y) paste(x,y))
[1] "f"
>
> ## trace the generic
> trace("f", quote(x <- c("A", x)), exit = quote(xy <<- c(x, "Z")), print = FALSE)
[1] "f"
>
> ## should work for any method
>
> stopifnot(identical(f(4,5), c("A",4,5)))
> stopifnot(identical(xy, c("A", 4, "Z")))
>
> stopifnot(identical(f("B", "C"), paste(c("A","B"), "C")))
> stopifnot(identical(xy, c("A", "B", "Z")))
>
> ## trace a method
>
> trace("f", sig = c("character", "character"), quote(x <- c(x, "D")),
+       exit = quote(xy <<- xyy <<- c(x, "W")), print = FALSE)
[1] "f"
>
> stopifnot(identical(f("B", "C"), paste(c("A","B","D"), "C")))
> # These two got broken by Luke's lexical scoping fix
> #stopifnot(identical(xy, c("A", "B", "D", "W")))
> #stopifnot(identical(xy, xyy))
>
> ## but the default method is unchanged
>
> stopifnot(identical(f(4,5), c("A",4,5)))
> stopifnot(identical(xy, c("A", 4, "Z")))
>
> removeGeneric("f")
[1] TRUE
>
> if(!hasMethods) detach("package:methods")
> ## end of moved from trace.Rd
>
>
> ## Trig
> ## many of these tested for machine accuracy, which seems a bit extreme
> set.seed(123)
> stopifnot(cos(0) == 1)
> stopifnot(sin(3*pi/2) == cos(pi))
> x <- rnorm(99)
> stopifnot(all.equal( sin(-x), - sin(x)))
> stopifnot(all.equal( cos(-x), cos(x)))
> x <- abs(x); y <- abs(rnorm(x))
> stopifnot(abs(atan2(y, x) - atan(y/x)) < 10 * .Machine$double.eps)
> stopifnot(abs(atan2(y, x) - atan(y/x)) < 10 * .Machine$double.eps)
>
> x <- 1:99/100
> stopifnot(Mod(1 - (cos(x) + 1i*sin(x)) / exp(1i*x)) < 10 * .Machine$double.eps)
> ## error is about 650* are x=0.01
> stopifnot(abs(1 - x / acos(cos(x))) < 1000 * .Machine$double.eps)
> stopifnot(abs(1 - x / asin(sin(x))) <= 10 * .Machine$double.eps)
> stopifnot(abs(1 - x / atan(tan(x))) <= 10 *.Machine$double.eps)
> ## end of moved from Trig.Rd
>
> ## Uniform
> u <- runif(20)
> stopifnot(punif(u) == u, dunif(u) == 1,
+ 	  runif(100, 2,2) == 2)#-> TRUE [bug in R version <= 0.63.1]
> ## end of moved from Uniform.Rd
>
>
> ## unique
> my.unique <- function(x) x[!duplicated(x)]
> for(i in 1:4)
+  { x <- rpois(100, pi); stopifnot(unique(x) == my.unique(x)) }
>
> data(iris)
> unique(iris)
    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
1            5.1         3.5          1.4         0.2     setosa
2            4.9         3.0          1.4         0.2     setosa
3            4.7         3.2          1.3         0.2     setosa
4            4.6         3.1          1.5         0.2     setosa
5            5.0         3.6          1.4         0.2     setosa
6            5.4         3.9          1.7         0.4     setosa
7            4.6         3.4          1.4         0.3     setosa
8            5.0         3.4          1.5         0.2     setosa
9            4.4         2.9          1.4         0.2     setosa
10           4.9         3.1          1.5         0.1     setosa
11           5.4         3.7          1.5         0.2     setosa
12           4.8         3.4          1.6         0.2     setosa
13           4.8         3.0          1.4         0.1     setosa
14           4.3         3.0          1.1         0.1     setosa
15           5.8         4.0          1.2         0.2     setosa
16           5.7         4.4          1.5         0.4     setosa
17           5.4         3.9          1.3         0.4     setosa
18           5.1         3.5          1.4         0.3     setosa
19           5.7         3.8          1.7         0.3     setosa
20           5.1         3.8          1.5         0.3     setosa
21           5.4         3.4          1.7         0.2     setosa
22           5.1         3.7          1.5         0.4     setosa
23           4.6         3.6          1.0         0.2     setosa
24           5.1         3.3          1.7         0.5     setosa
25           4.8         3.4          1.9         0.2     setosa
26           5.0         3.0          1.6         0.2     setosa
27           5.0         3.4          1.6         0.4     setosa
28           5.2         3.5          1.5         0.2     setosa
29           5.2         3.4          1.4         0.2     setosa
30           4.7         3.2          1.6         0.2     setosa
31           4.8         3.1          1.6         0.2     setosa
32           5.4         3.4          1.5         0.4     setosa
33           5.2         4.1          1.5         0.1     setosa
34           5.5         4.2          1.4         0.2     setosa
35           4.9         3.1          1.5         0.2     setosa
36           5.0         3.2          1.2         0.2     setosa
37           5.5         3.5          1.3         0.2     setosa
38           4.9         3.6          1.4         0.1     setosa
39           4.4         3.0          1.3         0.2     setosa
40           5.1         3.4          1.5         0.2     setosa
41           5.0         3.5          1.3         0.3     setosa
42           4.5         2.3          1.3         0.3     setosa
43           4.4         3.2          1.3         0.2     setosa
44           5.0         3.5          1.6         0.6     setosa
45           5.1         3.8          1.9         0.4     setosa
46           4.8         3.0          1.4         0.3     setosa
47           5.1         3.8          1.6         0.2     setosa
48           4.6         3.2          1.4         0.2     setosa
49           5.3         3.7          1.5         0.2     setosa
50           5.0         3.3          1.4         0.2     setosa
51           7.0         3.2          4.7         1.4 versicolor
52           6.4         3.2          4.5         1.5 versicolor
53           6.9         3.1          4.9         1.5 versicolor
54           5.5         2.3          4.0         1.3 versicolor
55           6.5         2.8          4.6         1.5 versicolor
56           5.7         2.8          4.5         1.3 versicolor
57           6.3         3.3          4.7         1.6 versicolor
58           4.9         2.4          3.3         1.0 versicolor
59           6.6         2.9          4.6         1.3 versicolor
60           5.2         2.7          3.9         1.4 versicolor
61           5.0         2.0          3.5         1.0 versicolor
62           5.9         3.0          4.2         1.5 versicolor
63           6.0         2.2          4.0         1.0 versicolor
64           6.1         2.9          4.7         1.4 versicolor
65           5.6         2.9          3.6         1.3 versicolor
66           6.7         3.1          4.4         1.4 versicolor
67           5.6         3.0          4.5         1.5 versicolor
68           5.8         2.7          4.1         1.0 versicolor
69           6.2         2.2          4.5         1.5 versicolor
70           5.6         2.5          3.9         1.1 versicolor
71           5.9         3.2          4.8         1.8 versicolor
72           6.1         2.8          4.0         1.3 versicolor
73           6.3         2.5          4.9         1.5 versicolor
74           6.1         2.8          4.7         1.2 versicolor
75           6.4         2.9          4.3         1.3 versicolor
76           6.6         3.0          4.4         1.4 versicolor
77           6.8         2.8          4.8         1.4 versicolor
78           6.7         3.0          5.0         1.7 versicolor
79           6.0         2.9          4.5         1.5 versicolor
80           5.7         2.6          3.5         1.0 versicolor
81           5.5         2.4          3.8         1.1 versicolor
82           5.5         2.4          3.7         1.0 versicolor
83           5.8         2.7          3.9         1.2 versicolor
84           6.0         2.7          5.1         1.6 versicolor
85           5.4         3.0          4.5         1.5 versicolor
86           6.0         3.4          4.5         1.6 versicolor
87           6.7         3.1          4.7         1.5 versicolor
88           6.3         2.3          4.4         1.3 versicolor
89           5.6         3.0          4.1         1.3 versicolor
90           5.5         2.5          4.0         1.3 versicolor
91           5.5         2.6          4.4         1.2 versicolor
92           6.1         3.0          4.6         1.4 versicolor
93           5.8         2.6          4.0         1.2 versicolor
94           5.0         2.3          3.3         1.0 versicolor
95           5.6         2.7          4.2         1.3 versicolor
96           5.7         3.0          4.2         1.2 versicolor
97           5.7         2.9          4.2         1.3 versicolor
98           6.2         2.9          4.3         1.3 versicolor
99           5.1         2.5          3.0         1.1 versicolor
100          5.7         2.8          4.1         1.3 versicolor
101          6.3         3.3          6.0         2.5  virginica
102          5.8         2.7          5.1         1.9  virginica
103          7.1         3.0          5.9         2.1  virginica
104          6.3         2.9          5.6         1.8  virginica
105          6.5         3.0          5.8         2.2  virginica
106          7.6         3.0          6.6         2.1  virginica
107          4.9         2.5          4.5         1.7  virginica
108          7.3         2.9          6.3         1.8  virginica
109          6.7         2.5          5.8         1.8  virginica
110          7.2         3.6          6.1         2.5  virginica
111          6.5         3.2          5.1         2.0  virginica
112          6.4         2.7          5.3         1.9  virginica
113          6.8         3.0          5.5         2.1  virginica
114          5.7         2.5          5.0         2.0  virginica
115          5.8         2.8          5.1         2.4  virginica
116          6.4         3.2          5.3         2.3  virginica
117          6.5         3.0          5.5         1.8  virginica
118          7.7         3.8          6.7         2.2  virginica
119          7.7         2.6          6.9         2.3  virginica
120          6.0         2.2          5.0         1.5  virginica
121          6.9         3.2          5.7         2.3  virginica
122          5.6         2.8          4.9         2.0  virginica
123          7.7         2.8          6.7         2.0  virginica
124          6.3         2.7          4.9         1.8  virginica
125          6.7         3.3          5.7         2.1  virginica
126          7.2         3.2          6.0         1.8  virginica
127          6.2         2.8          4.8         1.8  virginica
128          6.1         3.0          4.9         1.8  virginica
129          6.4         2.8          5.6         2.1  virginica
130          7.2         3.0          5.8         1.6  virginica
131          7.4         2.8          6.1         1.9  virginica
132          7.9         3.8          6.4         2.0  virginica
133          6.4         2.8          5.6         2.2  virginica
134          6.3         2.8          5.1         1.5  virginica
135          6.1         2.6          5.6         1.4  virginica
136          7.7         3.0          6.1         2.3  virginica
137          6.3         3.4          5.6         2.4  virginica
138          6.4         3.1          5.5         1.8  virginica
139          6.0         3.0          4.8         1.8  virginica
140          6.9         3.1          5.4         2.1  virginica
141          6.7         3.1          5.6         2.4  virginica
142          6.9         3.1          5.1         2.3  virginica
144          6.8         3.2          5.9         2.3  virginica
145          6.7         3.3          5.7         2.5  virginica
146          6.7         3.0          5.2         2.3  virginica
147          6.3         2.5          5.0         1.9  virginica
148          6.5         3.0          5.2         2.0  virginica
149          6.2         3.4          5.4         2.3  virginica
150          5.9         3.0          5.1         1.8  virginica
> stopifnot(dim(unique(iris)) == c(149, 5))
> ## end of moved from unique.Rd
>
>
> ## which.min
> stopifnot(length(which.min(numeric(0))) == 0)
> stopifnot(length(which.max( c(NA,NA) )) == 0)
> ## end of moved from which.min.Rd
>
>
> ## Wilcoxon
> x <- -1:(4*6 + 1)
> fx <- dwilcox(x, 4, 6)
> stopifnot(fx == dwilcox(x, 6, 4))
> Fx <- pwilcox(x, 4, 6)
> stopifnot(abs(Fx - cumsum(fx)) < 10 * .Machine$double.eps)
> ## end of moved from Wilcoxon.Rd
>
>
> ## .Machine
> (Meps <- .Machine$double.eps)
[1] 2.220446e-16
> ## All the following relations must hold :
> stopifnot(
+  1 +	 Meps != 1,
+  1 + .5* Meps == 1,
+  log2(.Machine$double.xmax) == .Machine$double.max.exp,
+  log2(.Machine$double.xmin) == .Machine$double.min.exp
+ )
> # This test fails on HP-UX since pow(2,1024) returns DBL_MAX and sets
> # errno = ERANGE.  Most other systems return Inf and set errno
> if (Sys.info()["sysname"] != "HP-UX")
+     stopifnot(is.infinite(.Machine$double.base ^ .Machine$double.max.exp))
> ## end of moved from zMachine.Rd
>
>
> ## PR 640 (diff.default computes an incorrect starting time)
> ## By: Laimonis Kavalieris <lkavalieris@maths.otago.ac.nz>
> y <- ts(rnorm(24), freq=12)
> x <- ts(rnorm(24), freq=12)
> arima0(y, xreg = x, seasonal = list(order=c(0,1,0)))

Call:
arima0(x = y, seasonal = list(order = c(0, 1, 0)), xreg = x)

Coefficients:
       xreg1
      0.3218
s.e.  0.2260

sigma^2 estimated as 2.233:  log likelihood = -21.85,  aic = 47.7
> ## Comments:
>
>
> ## PR 644 (crash using fisher.test on Windows)
> ## By: Uwe Ligges <ligges@statistik.uni-dortmund.de>
> x <- matrix(c(2, 2, 4, 8, 6, 0, 1, 1, 7, 8, 1, 3, 1, 3, 7, 4, 2, 2, 2,
+ 	      1, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 0, 0),
+ 	    nc = 2)
> fisher.test(x)

	Fisher's Exact Test for Count Data

data:  x
p-value = 0.7178
alternative hypothesis: two.sided

> ## Comments: (wasn't just on Windows)
>
> ## PR 653 (extrapolation in spline)
> ## By: Ian White <imsw@holyrood.ed.ac.uk>
> x <- c(2,5,8,10)
> y <- c(1.2266,-1.7606,-0.5051,1.0390)
> fn <- splinefun(x, y, method="natural")
> xx1 <- fn(0:12)
> # should be the same if reflected
> fn <- splinefun(rev(-x),rev(y),method="natural")
> xx2 <- fn(0:-12)
> stopifnot(all.equal(xx1, xx2))
> # should be the same as interpSpline
> library(splines)
> xx3 <- predict(interpSpline(x, y), 0:12)
> stopifnot(all.equal(xx1, xx3$y))
> detach("package:splines")
> ## Comments: all three differed in 1.2.1.
>
>
> ## PR 698 (print problem with data frames)
> ## actually, a subsetting problem with data frames
> fred <- data.frame(happy=c(TRUE, FALSE, TRUE), sad=7:9)
> z <- try(tmp <- fred[c(FALSE, FALSE, TRUE, TRUE)])
Error in "[.data.frame"(fred, c(FALSE, FALSE, TRUE, TRUE)) :
	undefined columns selected
> stopifnot(class(z) == "try-error")
> ## Comments: No error before 1.2.1
>
>
> ## PR 753 (step can't find variables)
> ##
> x <- data.frame(a=rnorm(10), b=rnorm(10), c=rnorm(10))
> x0.lm <- lm(a ~ 1, data=x)
> step(x0.lm, ~ b + c)
Start:  AIC= -4.17
 a ~ 1

       Df Sum of Sq     RSS     AIC
+ c     1    1.3369  4.0562 -5.0234
<none>               5.3931 -4.1747
+ b     1    0.0726  5.3205 -2.3101

Step:  AIC= -5.02
 a ~ c

       Df Sum of Sq     RSS     AIC
+ b     1    1.0784  2.9778 -6.1139
<none>               4.0562 -5.0234
- c     1    1.3369  5.3931 -4.1747

Step:  AIC= -6.11
 a ~ c + b

       Df Sum of Sq     RSS     AIC
<none>               2.9778 -6.1139
- b     1    1.0784  4.0562 -5.0234
- c     1    2.3427  5.3205 -2.3101

Call:
lm(formula = a ~ c + b, data = x)

Coefficients:
(Intercept)            c            b
    -0.4553       0.9121       0.4021

> ## Comments:
>
>
> ## PR 796 (aic in binomial models is often wrong)
> ##
> data(esoph)
> a1 <- glm(cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp,
+ 	  data = esoph, family = binomial())$aic
> a1
[1] 236.9645
> a2 <- glm(ncases/(ncases+ncontrols) ~ agegp + tobgp * alcgp,
+ 	  data = esoph, family = binomial(), weights=ncases+ncontrols)$aic
> a2
[1] 236.9645
> stopifnot(a1 == a2)
> ## Comments:
> # both should be 236.9645
>
> ## Follow up: example from Lindsey, purportedly of inaccuracy in aic
> y <- matrix(c(2, 0, 7, 3, 0, 9), ncol=2)
> x <- gl(3, 1)
> a <- glm(y ~ x, family=binomial)$aic
> stopifnot(is.finite(a))
> ## Comments: gave NaN prior to 1.2.1
>
>
> ## PR 802 (crash with scan(..., what=list(,,)))
> ##
> m <- matrix(1:9, 3,3)
> write(m, "test.dat", 3)
> try(scan("test.dat", what=list(,,,)))
Error in scan("test.dat", what = list(, , , )) :
	empty `what=' specified
> unlink("test.dat")
> ## Comments: segfaulted in 1.2.0
>
>
> ## Jonathan Rougier, 2001-01-30	 [bug in 1.2.1 and earlier]
> tmp <- array(list(3), c(2, 3))
> tmp[[2, 3]] <- "fred"
> all.equal(t(tmp), aperm(tmp))
[1] TRUE
>
>
> ## PR 860 (Context problem with ... and rbind) Prof Brian D Ripley, 2001-03-03,
> f <- function(x, ...)
+ {
+    g <- function(x, ...) x
+    rbind(numeric(), g(x, ...))
+ }
> f(1:3)
     [,1] [,2] [,3]
[1,]    1    2    3
> ## Error in 1.2.2
> f <- function(x, ...) h(g(x, ...))
> g <- function(x, ...) x
> h <- function(...)substitute(list(...))
> f(1)
list(g(x, ...))
> ## Error in 1.2.2
> substitute(list(...))
list(...)
> ## Error in 1.2.2
>
>
> ## Martin Maechler, 2001-03-07 [1.2.2 and in parts earlier]
> tf <- tempfile()
> cat(1:3,"\n", file = tf)
> for(line in list(4:6, "", 7:9)) cat(line,"\n", file = tf, append = TRUE)
>
> count.fields(tf) # 3 3 3 : ok {blank line skipped}
[1] 3 3 3
> z <- scan(tf, what=rep(list(""),3), nmax = 3)
Read 3 records
> stopifnot(sapply(z, length) == 3)
> ## FALSE in 1.2.2
> z <- as.data.frame(scan(tf, what=rep(list(""),3), n=9))
Read 3 records
> dim(z)
[1] 3 3
> ## should be 3 3.  Was 2 3 in 1.2.2.
> read.table(tf)
  V1 V2 V3
1  1  2  3
2  4  5  6
3  7  8  9
> ## gave error in 1.2.2
> unlink(tf)
>
>
> ## PR 870 (as.numeric and NAs)	Harald Fekjr, 2001-03-08,
> is.na(as.numeric(" "))
[1] TRUE
> is.na(as.integer(" "))
[1] TRUE
> is.na(as.complex(" "))
[1] TRUE
> ## all false in 1.2.2
>
>
> ## PR 871 (deparsing of attribute names) Harald Fekjr, 2001-03-08,
> midl <- 4
> attr(midl,"Object created") <- date()
> deparse(midl)
[1] "structure(4, \"Object created\" = \"Sat May  3 05:55:00 2003\")"
> dump("midl", "midl.R")
> source("midl.R") ## syntax error in 1.2.2
> unlink("midl.R")
>
>
> ## PR 872 (surprising behavior of match.arg()) Woodrow Setzer, 2001-03-08,
> fun1 <- function(x, A=c("power","constant")) {
+   arg <- match.arg(A)
+   formals()
+ }
> topfun <- function(x, Fun=fun1) {
+   a1 <- fun1(x)
+   print(a1)
+   a2 <- Fun(x,A="power")
+   stopifnot(all.equal(a1, a2))
+   print(a2)
+ }
> topfun(2, fun1)
$x


$A
c("power", "constant")

$x


$A
c("power", "constant")

> ## a1 printed without defaults in 1.2.2
>
>
> ## PR 873 (long formulas in terms()) Jerome Asselin, 2001-03-08,
> form <- cbind(log(inflowd1),log(inflowd2),log(inflowd3),
+     log(inflowd4),log(inflowd5),log(inflowd6)) ~ precip*I(Tmax^2)
> terms(form) # error in 1.2.2
cbind(log(inflowd1), log(inflowd2), log(inflowd3), log(inflowd4),
    log(inflowd5), log(inflowd6)) ~ precip * I(Tmax^2)
attr(,"variables")
list(cbind(log(inflowd1), log(inflowd2), log(inflowd3), log(inflowd4),
    log(inflowd5), log(inflowd6)), precip, I(Tmax^2))
attr(,"factors")
                                                                                                precip
cbind(log(inflowd1), log(inflowd2), log(inflowd3), log(inflowd4), log(inflowd5), log(inflowd6))      0
precip                                                                                               1
I(Tmax^2)                                                                                            0
                                                                                                I(Tmax^2)
cbind(log(inflowd1), log(inflowd2), log(inflowd3), log(inflowd4), log(inflowd5), log(inflowd6))         0
precip                                                                                                  0
I(Tmax^2)                                                                                               1
                                                                                                precip:I(Tmax^2)
cbind(log(inflowd1), log(inflowd2), log(inflowd3), log(inflowd4), log(inflowd5), log(inflowd6))                0
precip                                                                                                         1
I(Tmax^2)                                                                                                      1
attr(,"term.labels")
[1] "precip"           "I(Tmax^2)"        "precip:I(Tmax^2)"
attr(,"order")
[1] 1 1 2
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
>
>
> ## PR 881 Incorrect values in non-central chisq values on Linux, 2001-03-21
> x <- dchisq(c(7.1, 7.2, 7.3), df=2, ncp=20)
> stopifnot(diff(x) > 0)
> ## on 1.2.2 on RH6.2 i686 Linux x = 0.01140512 0.00804528 0.01210514
>
>
> ## PR 882 eigen segfaults on 0-diml matrices, 2001-03-23
> m <- matrix(1, 0, 0)  # 1 to force numeric not logical
> try(eigen(m))
Error in eigen(m) : 0 x 0 matrix
> ## segfaults on 1.2.2
>
>
> ## 1.3.0 had poor compression on gzfile() with lots of small pieces.
> if (capabilities("libz")) {
+     zz <- gzfile("t1.gz", "w")
+     write(1:1000, zz)
+     close(zz)
+     (sz <- file.info("t1.gz")$size)
+     unlink("t1.gz")
+     stopifnot(sz < 2000)
+ }
>
>
> ## PR 1010: plot.mts (type="p") was broken in 1.3.0 and this call failed.
> plot(ts(matrix(runif(10), ncol = 2)), type = "p")
>
>
> ## in 1.3.0 readLines(ok=FALSE) failed.
> cat(file="foo", 1:10, sep="\n")
> x <- try(readLines("foo", 100, ok=FALSE))
Error in readLines("foo", 100, ok = FALSE) :
	too few lines read in readLines
> unlink("foo")
> stopifnot(length(class(x)) == 1 &&class(x) == "try-error")
>
>
> ## PR 1047 [<-data.frame failure, BDR 2001-08-10
> test <- df <- data.frame(x=1:10, y=11:20, row.names=letters[1:10])
> test[] <- lapply(df, factor)
> test
   x  y
a  1 11
b  2 12
c  3 13
d  4 14
e  5 15
f  6 16
g  7 17
h  8 18
i  9 19
j 10 20
> ## error in 1.3.0 in test[]
>
>
> ## PR 1048 bug in dummy.coef.lm, Adrian Baddeley, 2001-08-10
> ## modified to give a sensible test
> old <- getOption("contrasts")
> options(contrasts=c("contr.helmert", "contr.poly"))
> DF <- data.frame(x=1:20,y=rnorm(20),z=factor(1:20 <= 10))
> dummy.coef.lm(lm(y ~ z * I(x), data=DF))
Full coefficients are

(Intercept):      0.2425610
z:                    FALSE       TRUE
                 -0.1386709  0.1386709
I(x):           -0.04996379
z:I(x):               FALSE       TRUE
                  0.0186591 -0.0186591
> dummy.coef.lm(lm(y ~ z * poly(x,1), data=DF))
Full coefficients are

(Intercept):      -0.2820588
z:                     FALSE        TRUE
                  0.05724965 -0.05724965
poly(x, 1):         0.474656
z:poly(x, 1):          FALSE        TRUE
                  -0.1772615   0.1772615
> ## failed in 1.3.0.  Second one warns: deficiency of the method.
> options(contrasts=old)
>
>
> ## PR 1050 error in ksmooth C code + patch, Hsiu-Khuern Tang, 2001-08-12
> x <- 1:4
> y <- 1:4
> z <- ksmooth(x, y, x.points=x)
> stopifnot(all.equal(z$y, y))
> ## did some smoothing prior to 1.3.1.
>
>
> ## The length of lines read by scan() was limited before 1.4.0
> xx <- paste(rep(0:9, 2000), collapse="")
> zz <- file("foo.txt", "w")
> writeLines(xx, zz)
> close(zz)
> xxx <- scan("foo.txt", "", sep="\n")
Read 1 items
> stopifnot(identical(xx, xxx))
> unlink("foo.txt")
>
>
> ## as.character was truncating formulae:  John Fox 2001-08-23
> mod <- this ~ is + a + very + long + formula + with + a + very + large + number + of + characters
> zz <- as.character(mod)
> zz
[1] "~"
[2] "this"
[3] "is + a + very + long + formula + with + a + very + large + number + of + characters"
> nchar(zz)
[1]  1  4 83
> stopifnot(nchar(zz)[3] == 83)
> ## truncated in 1.3.0
>
>
> ## substr<-, Tom Vogels, 2001-09-07
> x <- "abcdef"
> substr(x, 2, 3) <- "wx"
> stopifnot(x == "awxdef")
>
> x <- "abcdef"
> substr(x, 2, 3) <- "wxy"
> stopifnot(x == "awxdef")
>
> x <- "abcdef"
> substr(x, 2, 3) <- "w"
> stopifnot(x == "awcdef")
> ## last was "aw" in 1.3.1
>
>
> ## reading bytes from a connection,  Friedrich Leisch 2001-09-07
> cat("Hello World", file="world.txt")
> con <- file("world.txt", "r")
> zz <- readChar(con, 100)
> close(con)
> unlink("world.txt")
> stopifnot(zz == "Hello World")
> ## was "" in 1.3.1.
>
>
> ## prediction was failing for intercept-only model
> ## as model frame has no columns.
> d <- data.frame(x=runif(50), y=rnorm(50))
> d.lm <- lm(y ~ 1, data=d)
> predict(d.lm, data.frame(x=0.5))
[1] -0.008940623
> ## error in 1.3.1
>
>
> ## predict.arima0 needed a matrix newxreg: Roger Koenker, 2001-09-27
> u <- rnorm(120)
> s <- 1:120
> y <- 0.3*s + 5*filter(u, c(.95,-.1), "recursive", init=rnorm(2))
> fit0 <- arima0(y,order=c(2,0,0), xreg=s)
> fit1 <- arima0(y,order=c(2,1,0), xreg=s, include.mean=TRUE)
> fore0 <- predict(fit0 ,n.ahead=44, newxreg=121:164)
> fore1 <- predict(fit1, n.ahead=44, newxreg=121:164)
> par(mfrow=c(1,2))
> ts.plot(y,fore0$pred, fore0$pred+2*fore0$se, fore0$pred-2*fore0$se,
+ 		gpars=list(lty=c(1,2,3,3)))
> abline(fit0$coef[3:4], lty=2)
> ts.plot(y, fore1$pred, fore1$pred+2*fore1$se, fore1$pred-2*fore1$se,
+ 		gpars=list(lty=c(1,2,3,3)))
> abline(c(0, fit1$coef[3]), lty=2)
>
>
> ## merging when NA is a level
> a <- data.frame(x = 1:4)
> b <- data.frame(x = 1:3, y = factor(c("NA", "a", "b"), exclude=""))
> (m <- merge(a, b, all.x = TRUE))
  x    y
1 1   NA
2 2    a
3 3    b
4 4 <NA>
> stopifnot(is.na(m[4, 2]))
> ## was level NA in 1.3.1
> stopifnot(!is.na(m[1, 2]))
>
>
> ## merging with POSIXct columns:
> x <- data.frame(a = as.POSIXct(Sys.time() + (1:3)*10000), b = LETTERS[1:3])
> y <- data.frame(b = LETTERS[3:4], c = 1:2)
> stopifnot(1 == nrow(merge(x, y)))
> stopifnot(4 == nrow(merge(x, y, all = TRUE)))
>
>
> ## PR 1149.  promax was returning the wrong rotation matrix.
> data(ability.cov)
> ability.FA <- factanal(factors = 2, covmat = ability.cov, rotation = "none")
> pm <- promax(ability.FA$loadings)
> tmp1 <- as.vector(ability.FA$loadings %*% pm$rotmat)
> tmp2 <- as.vector(pm$loadings)
> stopifnot(all.equal(tmp1, tmp2))
> rm(ability.cov)
>
>
> ## PR 1155. On some systems strptime was not setting the month or mday
> ## when yday was supplied.
> bv1 <- data.frame(day=c(346,346,347,347,347), time=c(2340,2350,0,10,20))
> attach(bv1)
> tmp <- strptime(paste(day, time %/% 100, time %% 100), "%j %H %M")
> detach()
> stopifnot(tmp$mon == 11)
> # day of month will be different in a leap year on systems that default
> # to the current year, so test differences:
> stopifnot(diff(tmp$mday) == c(0, 1, 0, 0))
> ## Comments: failed on glibc-based systems in 1.3.1, including Windows.
>
>
> ## PR 1004 (follow up).	 Exact Kolmogorov-Smirnov test gave incorrect
> ## results due to rounding errors (Charles Geyer, charlie@stat.umn.edu,
> ## 2001-10-25).
> ## Example 5.4 in Hollander and Wolfe (Nonparametric Statistical
> ## Methods, 2nd ed., Wiley, 1999, pp. 180-181).
> x <- c(-0.15, 8.6, 5, 3.71, 4.29, 7.74, 2.48, 3.25, -1.15, 8.38)
> y <- c(2.55, 12.07, 0.46, 0.35, 2.69, -0.94, 1.73, 0.73, -0.35, -0.37)
> stopifnot(round(ks.test(x, y)$p.value, 4) == 0.0524)
>
>
> ## PR 1150.  Wilcoxon rank sum and signed rank tests did not return the
> ## Hodges-Lehmann estimators of the associated confidence interval
> ## (Charles Geyer, charlie@stat.umn.edu, 2001-10-25).
> ## One-sample test: Example 3.1 in Hollander & Wolfe (1973), 29f.
> x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
> y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
> we <- wilcox.test(y, x, paired = TRUE, conf.int = TRUE)
> ## NOTE order: y then x.
> ## Results from Hollander & Wolfe (1999), 2nd edition, page 40 and 53
> stopifnot(round(we$p.value,4) == 0.0391)
> stopifnot(round(we$conf.int,3) == c(-0.786, -0.010))
> stopifnot(round(we$estimate,3) == -0.46)
> ## Two-sample test: Example 4.1 in Hollander & Wolfe (1973), 69f.
> x <- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46)
> y <- c(1.15, 0.88, 0.90, 0.74, 1.21)
> we <- wilcox.test(y, x, conf.int = TRUE)
> ## NOTE order: y then x.
> ## Results from Hollander & Wolfe (1999), 2nd edition, page 111 and 126
> stopifnot(round(we$p.value,4) == 0.2544)
> stopifnot(round(we$conf.int,3) == c(-0.76, 0.15))
> stopifnot(round(we$estimate,3) == -0.305)
>
>
> ## range gave wrong length result for R < 1.4.0
> stopifnot(length(range(numeric(0))) == 2)
Warning messages:
1: no finite arguments to min; returning Inf
2: no finite arguments to max; returning -Inf
> ##  Comments: was just NA
>
>
> ## mishandling of integer(0) in R < 1.4.0
> x1 <- integer(0) / (1:3)
> x2 <- integer(0) ^ (1:3)
> stopifnot(length(x1) == 0 & length(x2) == 0)
> ##  Comments: were integer NAs in real answer in 1.3.1.
>
>
> ## PR#1138/9  rounding could give non-integer answer.
> x <- round(100000/3, -2) - 33300
> stopifnot(x == 0)
> ## failed in 1.3.x on Solaris and Windows but not Debian Linux.
>
>
> ## PR#1160 finding midpoints in image <janef@stat.berkeley.edu, 2001-11-06>
> x2 <- c(0, 0.002242152, 0.004484305, 0.006726457, 0.00896861,
+ 	0.01121076, 0.01345291, 0.01569507, 0.01793722, 0.02017937,
+ 	0.02242152, 0.02466368, 0.02690583, 0.02914798, 0.03139013,
+ 	0.03363229, 0.03587444, 0.03811659, 0.04035874, 0.04932735,
+ 	0.05156951, 0.05381166)
> z <- c(0, 0.067, NA, 0.167, 0.083, 0.05, 0.067, NA, 0, 0.1, 0, 0.05,
+        0.067, 0.067, 0.016, 0.117, 0.017, -0.017, 0.2, 0.35, 0.134, 0.15)
> image(x2, 1, as.matrix(z))
> ## Comments: failed under R 1.3.1.
>
>
> ##PR 1175 and 1123##
> set.seed(123)
> ## We can't seem to get Pearson residuals right ##
> x <- 1:4 # regressor variable
> y <- c(2,6,7,8) # response binomial counts
> n <- rep(10,4) # number of binomial trials
> ym <- cbind(y,n-y) # response variable as a matrix
> glm1 <- glm(ym~x,binomial) # fit a generalized linear model
> f <- fitted(glm1)
> rp1 <- (y-n*f)/sqrt(n*f*(1-f)) # direct calculation of pearson residuals
> rp2 <- residuals(glm1,type="pearson") # should be pearson residuals
> stopifnot(all.equal(rp1,rp2))
> # sign should be same as response residuals
> x <- 1:10
> y <- rgamma(10,2)/x
> glm2 <- glm(y~x,family=Gamma)
> stopifnot(all.equal(sign(resid(glm2,"response")),sign(resid(glm2,"pearson"))))
> # shouldn't depend on link for a saturated model
> x<-rep(0:1,10)
> y<-rep(c(0,1,1,0,1),4)
> glm3<-glm(y~x,family=binomial(),control=glm.control(eps=1e-8))
> glm4<-glm(y~x,family=binomial("log"),control=glm.control(eps=1e-8))
> stopifnot(all.equal(resid(glm3,"pearson"),resid(glm4,"pearson")))
>
>
> ## Torsten Hothorn, 2001-12-04
> stopifnot(pt(-Inf, 3, ncp=0) == 0, pt(Inf, 3, ncp=0) == 1)
> ##  Comments: were 0.5 in 1.3.1
>
>
> ## Paul Gilbert, 2001-12-07
> cancor(matrix(rnorm(100),100,1), matrix(rnorm(300),100,3))
$cor
[1] 0.09057181

$xcoef
          [,1]
[1,] 0.1117289

$ycoef
            [,1]        [,2]         [,3]
[1,] -0.07465770 -0.04311967 -0.052752879
[2,] -0.04302592  0.09307937 -0.009990484
[3,] -0.05409998 -0.01244767  0.084752170

$xcenter
[1] 0.02784576

$ycenter
[1] -0.03353540  0.08536240 -0.05617746

> ##  Comments: failed in R-devel.
>
>
> ## PR#1201: incorrect values in qbeta
> x <- seq(0, 0.8, len=1000)
> xx <- pbeta(qbeta(x, 0.143891, 0.05), 0.143891, 0.05)
> stopifnot(max(abs(x - xx)) < 1e-6)
> ##  Comments:  Get a range of zeroes in 1.3.1
>
>
> ## PR#1216: binomial null model
> y <- rbinom(20, 1, 0.5)
> glm(y ~ 0, family = binomial)

Call:  glm(formula = y ~ 0, family = binomial)

No coefficients

Degrees of Freedom: 20 Total; 20 Residual
Null Deviance: 27.73
Residual Deviance: 27.73 	AIC: 27.73
> ##  Comments:  1.3.1 gave  Error in any(n > 1) : Object "n" not found
>
>
> ## Integer overflow in type.convert
> res <- type.convert("12345689")
> stopifnot(typeof(res) == "integer")
> res <- type.convert("12345689012")
> stopifnot(typeof(res) == "double")
> ##  Comments: was integer in 1.4.0
>
>
> ## La.eigen() segfault
> e1 <- La.eigen(m <- matrix(1:9,3))
> stopifnot(e1$values == La.eigen(m, only.values = TRUE)$values)
>
>
> ## Patrick Connelly 2001-01-22, prediction with offsets failed
> ## a simpler example
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> DF <- data.frame(counts = c(18, 17, 15, 20, 10, 20, 25, 13, 12),
+ 		 outcome = gl(3, 1, 9), treatment = gl(3, 3),
+ 		 exposure = c(1.17, 1.78, 1.00, 2.36, 2.58, 0.80, 2.51,
+ 		 1.16, 1.77))
> fit <- glm(counts ~ outcome + treatment + offset(log(exposure)),
+ 	   family = poisson, data = DF)
> p1 <- predict(fit)
> p2 <- predict(fit, se = TRUE)  ## failed < 1.4.1
> p3 <- predict(fit, newdata = DF)
> p4 <- predict(fit, newdata = DF, se = TRUE)
> stopifnot(all.equal(p1, p2$fit), all.equal(p1, p3), all.equal(p2, p4))
> fit <- glm(counts ~ outcome + treatment, offset = log(exposure),
+ 	   family = poisson, data = DF)
> p1 <- predict(fit)
> p2 <- predict(fit, se = TRUE)  ## failed < 1.4.1
> p3 <- predict(fit, newdata = DF)
> p4 <- predict(fit, newdata = DF, se = TRUE)
> stopifnot(all.equal(p1, p2$fit), all.equal(p1, p3), all.equal(p2, p4))
>
>
> ## PR#1267 hashing NaN
> load(file.path(Sys.getenv("SRCDIR"), "nanbug.rda"))
> bb <- b; bb[5] <- NaN
> identical(b, bb)	    # TRUE
[1] TRUE
> unique(c(NaN, bb))	    #[1] NaN 0 1 2 3 NA
[1] NaN   0   1   2   3  NA
> stopifnot(identical(unique(c(NaN, b)), unique(c(NaN, bb))))
> ## 1.4.0 gives [1] NaN 0 1 2 NaN 3 NA	on most platforms
>
>
> ## PR 1271  detach("package:base") crashes R.
> try(detach("package:base"))
Error in detach(pos) : detaching "package:base" is not allowed
>
>
> ## reported by PD 2002-01-24
> Y <- matrix(rnorm(20), , 2)
> fit <- manova(Y ~ 1)
> fit # failed
Call:
   manova(Y ~ 1)

Terms:
                Residuals
resp 1           12.10603
resp 2           11.86833
Deg. of Freedom         9

Residual standard error: 1.159790 1.148348
> print(fit, intercept = TRUE)
Call:
   manova(Y ~ 1)

Terms:
                (Intercept) Residuals
resp 1             0.912842 12.106025
resp 2             0.303404 11.868328
Deg. of Freedom           1         9

Residual standard error: 1.159790 1.148348
Estimated effects are balanced
> summary(fit) # failed
          Df Pillai approx F num Df den Df Pr(>F)
Residuals  9
> summary(fit, intercept = TRUE)
            Df  Pillai approx F num Df den Df Pr(>F)
(Intercept)  1 0.07600  0.32901      2      8  0.729
Residuals    9
>
>
> ## Several  qr.*() functions lose (dim)names.
> ## reported by MM 2002-01-26
>
> ## the following should work both in R and S+ :
> q4 <- qr(X4 <- cbind(a = 1:9, b = c(1:6,3:1), c = 2:10, d = rep(1,9)))
> ##q2 <- qr(X4[,1:2])
> y04 <- y4 <- cbind(A=1:9,B=2:10,C=3:11,D=4:12)
> dimnames(y4)[[1]] <- paste("c",1:9,sep=".")
> y1 <- y4[,2]
> y40 <- y4 ; dimnames(y40) <- list(dimnames(y4)[[1]], NULL)
>
> c1 <- qr.coef( q4, y4) # row- AND col-names
> c2 <- qr.coef( q4, y04)# ditto
> c3 <- qr.coef( q4, y40)# row--names
> dn3 <- dimnames(c3)
> stopifnot(identical(dimnames(c1), dimnames(c2)),
+ 	  identical(dimnames(c1), list(letters[1:4], LETTERS[1:4])),
+ 	  identical(dn3[[1]], letters[1:4]),  length(dn3[[2]]) == 0,
+ 	  identical(names(qr.coef(q4,y1)),   letters[1:4]),
+ 	  identical(dimnames(qr.R(q4))[[2]], letters[1:4]),
+
+ 	  identical(dimnames(qr.qty(q4,y4)), dimnames(y4)),
+ 	  identical(dimnames(qr.qty(q4,y40)), dimnames(y40)),
+ 	  identical(dimnames(qr.qy (q4,y04)), dimnames(y04)),
+
+ 	  all.equal(y1,	 qr.fitted(q4, y1 ), tol = 1e-12),
+ 	  all.equal(y4,	 qr.fitted(q4, y4 ), tol = 1e-12),
+ 	  all.equal(y40, qr.fitted(q4, y40), tol = 1e-12),
+ 	  all.equal(y04, qr.fitted(q4, y04), tol = 1e-12),
+
+ 	  all.equal(X4, qr.X(q4), tol = 1e-12)
+ )
>
>
> ## PR 1297  read.fwf() was interpreting `#' in 1.4.0/1
> cat(file="test.fwf", "123ABC123", "123#3 123", "123XYZ123", sep="\n")
> (res <- read.fwf("test.fwf", widths=c(3,3,3), comment.char=""))
   V1  V2  V3
1 123 ABC 123
2 123 #3  123
3 123 XYZ 123
> unlink("test.fwf")
> stopifnot(res[2, 2] == "#3 ")
>
>
> ## abs was failing to dispatch as part of the Math group generic
> tmp <- data.frame(x = -5:5)
> abs(tmp)
   x
1  5
2  4
3  3
4  2
5  1
6  0
7  1
8  2
9  3
10 4
11 5
> ## failed in 1.4.1.
>
>
> ## PR 1363 La.svd was not working for integer args
> m <- matrix(1:4, 2)
> (s1 <- svd(m))
$d
[1] 5.4649857 0.3659662

$u
           [,1]       [,2]
[1,] -0.5760484 -0.8174156
[2,] -0.8174156  0.5760484

$v
           [,1]       [,2]
[1,] -0.4045536  0.9145143
[2,] -0.9145143 -0.4045536

> (s2 <- La.svd(m))
$d
[1] 5.4649857 0.3659662

$u
           [,1]       [,2]
[1,] -0.5760484 -0.8174156
[2,] -0.8174156  0.5760484

$vt
           [,1]       [,2]
[1,] -0.4045536 -0.9145143
[2,]  0.9145143 -0.4045536

> stopifnot(all.equal(s1$d, s2$d), all.equal(s1$u, s2$u),
+ 	  all.equal(s1$v, t(s2$vt)))
> (e1 <- eigen(m))
$values
[1]  5.3722813 -0.3722813

$vectors
           [,1]       [,2]
[1,] -0.5657675 -0.9093767
[2,] -0.8245648  0.4159736

> (e2 <- La.eigen(m))
$values
[1]  5.3722813 -0.3722813

$vectors
           [,1]       [,2]
[1,] -0.5657675 -0.9093767
[2,] -0.8245648  0.4159736

> stopifnot(all.equal(e1$d, e1$d))
>
>
> ## order/sort.list on NA_STRING
> x <- c("A", NA, "Z")
> stopifnot(identical(sort(x, na.last = TRUE), x[sort.list(x, na.last = TRUE)]))
> stopifnot(identical(sort(x, na.last = FALSE), x[sort.list(x, na.last = FALSE)]))
> ## 1.4.1 sorted NA correctly with sort but not sort.list.
>
>
> ## Don MacQueen 2002-03-26
> stopifnot(length(seq(1024902010, 1024902025, by=1)) == 16)
> t0 <- ISOdatetime(2002,6,24,0,0,10)
> x <- seq.POSIXt(from=t0,to=t0+15,by='1 sec')
> stopifnot(length(x) == 16)
>
>
> ## whilst reading the code BDR 2002-03-31
> z <- try(max(complex(0)))
Error in max(..., na.rm = na.rm) : invalid "mode" of argument
> stopifnot(inherits(z, "try-error"))
> z <- try(min(complex(0)))
Error in min(..., na.rm = na.rm) : invalid "mode" of argument
> stopifnot(inherits(z, "try-error"))
> ## 1.4.1 gave +-Inf + random imaginary part
>
>
> ## PR#1238  min/max(NULL) or (integer(0))
> z <- min(NULL)
Warning message:
no finite arguments to min; returning Inf
> stopifnot(!is.na(z), mode(z) == "numeric", z == Inf)
> z <- min(integer(0))
Warning message:
no finite arguments to min; returning Inf
> stopifnot(!is.na(z), mode(z) == "numeric", z == Inf)
> z <- max(NULL)
Warning message:
no finite arguments to max; returning -Inf
> stopifnot(!is.na(z), mode(z) == "numeric", z == -Inf)
> z <- max(integer(0))
Warning message:
no finite arguments to max; returning -Inf
> stopifnot(!is.na(z), mode(z) == "numeric", z == -Inf)
>
>
> ## more reading the code BDR 2002-03-31
> stopifnot(identical(range(), range(numeric(0))))
Warning messages:
1: no finite arguments to min; returning Inf
2: no finite arguments to max; returning -Inf
3: no finite arguments to min; returning Inf
4: no finite arguments to max; returning -Inf
> ## in 1.4.1 range() was c(1,1)
> stopifnot(is.null(c()))
> ## in 1.4.1 this was structure(TRUE, names="recursive")
>
> ## range(numeric(0)) was not as documented
> x <- numeric(0)
> (rx <- range(x))
[1]  Inf -Inf
Warning messages:
1: no finite arguments to min; returning Inf
2: no finite arguments to max; returning -Inf
> stopifnot(identical(rx, c(min(x), max(x))))
Warning messages:
1: no finite arguments to min; returning Inf
2: no finite arguments to max; returning -Inf
> ## 1.4.1 had c(NA, NA)
>
>
> ## PR 1431 persp() crashes with numeric values for [x,y,z]lab
> persp(1:2, 1:2, matrix(1:4, 2), xlab=1)
> ## segfaulted in 1.4.1
>
>
> ## PR#1244 bug in det using method="qr"
> m2 <- structure(c(9822616000, 3841723000, 79790.09, 3841723000, 1502536000,
+ 		  31251.82, 79790.09, 31251.82, 64156419.36), .Dim = c(3, 3))
> (d1 <- det(m2, method="eigenvalues"))
[1] -9.331893e+19
> (d2 <- det(m2, method="qr"))
[1] 0
> stopifnot(d2 == 0) ## 1.4.1 gave 9.331893e+19
> (d3 <- det(m2, method="qr", tol = 1e-10))
[1] -9.331893e+19
> stopifnot(all.equal(d1, d3, tol=1e-3))
>
>
> ## PR#1422 glm start/offset bugs
> if(require(MASS)) {
+ data(ships, package = MASS)
+ ships.glm <- glm(incidents ~ type + year + period + offset(log(service)),
+ 		 family = poisson, data = ships, subset = (service != 0))
+ update(ships.glm, start = coef(ships.glm))
+ detach("package:MASS")
+ }
Loading required package: MASS
Warning message:
There is no package called 'MASS' in: library(package, char = TRUE, logical = TRUE, warn.conflicts = warn.conflicts,
> ## failed in 1.4.1.
>
>
> ## PR#1439 file.info()$isdir was only partially logical
> (info <- file.info("."))
  size isdir mode               mtime               ctime               atime
. 2048  TRUE  755 2003-05-03 05:55:03 2003-05-03 05:55:03 2003-05-03 05:54:49
  uid gid uname   grname
. 887  10 beebe sysstaff
> info$isdir
[1] TRUE
> stopifnot(info$isdir == TRUE)
> ## 1.4.1 had a TRUE value that was not internally integer 1.
>
> ## PR#1473 predict.*bSpline() bugs extrapolating for deriv >= 1
> library(splines)
> x <- c(1:3,5:6)
> y <- c(3:1,5:6)
> (isP <- interpSpline(x,y))# poly-spline representation
polynomial representation of spline for y ~ x
  constant     linear  quadratic      cubic
1        3 -0.8360656  0.0000000 -0.1639344
2        2 -1.3278689 -0.4918033  0.8196721
3        1  0.1475410  1.9672131 -0.5204918
5        5  1.7704918 -1.1557377  0.3852459
6        6  0.6147541  0.0000000  0.0000000
> (isB <- interpSpline(x,y, bSpl = TRUE))# B-spline repr.
bSpline representation of spline for y ~ x
        -3         -2         -1          1          2          3          5
        NA         NA         NA         NA  4.3934426  3.2786885  2.1639344
         6          7          9         10
-0.2622951  5.1803279  6.0000000  6.8196721
> xo <- c(0, x, 10)# x + outside points
> op <- options(digits = 4)
> for(der in 0:3) # deriv=3 fails!
+     print(formatC(try(predict(isP, xo, deriv = der)$y), wid=7,format="f"),
+ 	  quote = FALSE)
[1]  3.8361  3.0000  2.0000  1.0000  5.0000  6.0000  8.4590
[1] -0.8361 -0.8361 -1.3279  0.1475  1.7705  0.6148  0.6148
[1]  0.0000  0.0000 -0.9836  3.9344 -2.3115  0.0000  0.0000
[1]  0.0000 -0.9836 -0.9836  4.9180 -3.1230  2.3115  0.0000
> ## and for B-spline (instead of polynomial):
> for(der in 0:3)	 # deriv=3 failed
+     print(formatC(try(predict(isB, xo, deriv = der)$y), wid=7,format="f"),
+ 	  quote = FALSE)
[1]  3.8361  3.0000  2.0000  1.0000  5.0000  6.0000  8.4590
[1] -0.8361 -0.8361 -1.3279  0.1475  1.7705  0.6148  0.6148
[1]  0.0000  0.0000 -0.9836  3.9344 -2.3115  0.0000  0.0000
[1]  0.0000 -0.9836  4.9180 -3.1230  2.3115  0.0000  0.0000
> options(op)
> detach("package:splines")
>
>
> ## PR 902 segfaults when warning string is too long, Ben Bolker 2001-04-09
> provoke.bug <- function(n=9000) {
+    warnmsg <- paste(LETTERS[sample(1:26,n,replace=TRUE)],collapse="")
+    warning(warnmsg)
+ }
> provoke.bug()
Warning message:
TYKHGFOTROVTAJBUYOWPRNTXVBABWOIYPNJIVBJWSRJODUXFUPYENWWAZMKKCEKIKHOEYBJZQBKLNLQDXOODTMUBVHHQYAJKLSXQXTDDELCFOKOVQKSCHPEWWMUHBLMIENAUOQMHLUPKVIPLGOGOLDQODOLLVSLNGBKAWZSVXOOHRGHSSEHJCSODZOUWWUQQHAKJKEIKTHDAUMUCCDTTZQHFUSFTWNPYYRBVMKHGKYGOFFSIDBYODOOVSOSTJHNGVKBYFKQQIDXPTXNJBWNFJFLGDBRHDZKKQXFOSKCQAFRWUDKUSPDOLTAFWCZKWXMSMZBEUOKZGNCVJUFYINCXYBMFWNAHIPGBCSYICIQLUHOBESVNOADWCGZPGPADSBQYCZASLOWOTQIKFWPTOHTOINVNFWJHUTVOAMOVSOBDRCFJWGSCUGOAUIXJZJMMAQNIPQLESTVNHLJGRYHQNPAADACMFVGMQEVLGHEPDEIEKPRVJYAPMJWBWEFWBGZRLJLURMBGGFBMGTOYCYSXPEESPIUIWPKYMCMZYLWHUUKJQWRNDPBMTTBLNHPTSDOUGSVDYTVEAWXDMMSBTKLSMZVVTCVVZBTKPVAAZTIVZFQLYZLFSOPLLPLYVFKKAJKESATLTABKQFVSXKKGJGYMBUIORHBLPZZCMKKIRHKZUIVFNEDXCWHAUJATALGMQCECVQQKLJUXQPIBPETHQDGVUBWDPMOSMZZKPILFAABTMWPEPXUNKRXXEGCUCVUYMYUWKCHSJJANDXBUWAHQUKYKLHPOBTFRNQQHFOZIIANPTYMCGWWVYQMESCLYVSDPZQHBBWJYONYCVJOICUFRLFZLAYWPHVYWDZOADAVUYJZVUQZMXKLYRAEMLZXISXRQDPHLFGQMEHSPDBZJRVGAPVJIQYPNEVFRQBYPWNGPURMMQLPAZKDWOWAWSUWNYFAIRIYUIMKUMAQGTHXWMBPPZIRYORCWNFKXMRHVG!
 JGYKDXJWDJ in: provoke.bug()
> ## segfaulted in 1.2.2, will also on machines without vsnprintf (none now)
>
>
> ## PR#1510 merge with multiple match rows and different names.
> df1 <- data.frame(z = 1:10, m = letters[1:10], w = rnorm(10))
> df2 <- data.frame(x = 1:10, y = rnorm(10), n = letters[1:10])
> merge(df2, df1, by.x = c("x", "n"), by.y = c("z", "m"))
    x n          y          w
1   1 a -0.1310038 -1.6852624
2  10 j  1.8186184 -2.4514910
3   2 b -1.0533970  1.2106916
4   3 c  1.1271659 -1.0471136
5   4 d -0.7278346  0.4385468
6   5 e  0.9353406 -0.3378052
7   6 f -0.4682921 -2.3794764
8   7 g  0.1298211  0.2593449
9   8 h  1.4623528 -1.1030047
10  9 i -0.6821694  0.9223011
> ## failed in 1.5.0
>
>
> ## PR 1524  Problems with paste/unlist
> l <- names(unlist(list(aa = list(bb = 1))))
> l
[1] "aa.bb"
> # this is exactly "aa.bb"
> stopifnot(identical(l, "aa.bb"))
> l2 <- paste(l, "this should be added")
> stopifnot(identical(l2, "aa.bb this should be added"))
> ## 1.5.0 gave l2 printing as l.
>
>
> ## PR 1530 drop inconsistency for data frames
> DF <- data.frame(x = 1:3, y = c("A","D","E"), z = c(6,9,10))
> a1 <- DF[1,1:3]
> xx <- DF[1,]
> a2 <- xx[, 1:3]
> a3 <- DF[1,1:3, drop = TRUE]
> a4 <- xx[, 1:3, drop = TRUE]
> stopifnot(identical(a1, a2), identical(a3, a4))
> ## <= 1.5.0 had a2 == a3.
>
>
> ## PR 1536 rbind.data.frame converts logical to factor
> df <- data.frame(a = 1:10)
> df$b <- df$a < 5
> ddf <- rbind(df, df)
> stopifnot(!is.factor(ddf$b))
> ## 1.5.0 had b as a factor.
>
>
> ## PR 1548 : prettyNum inserted leading commas
> stopifnot(prettyNum(123456, big.mark=",") == "123,456")
>
>
> ## PR 1552: cut.dendrogram
> data(USArrests)
> hc <- hclust(dist(USArrests), "ave")
> cc <- cut(as.dendrogram(hc), h = 20)## error in 1.5.0
>
> ## predict.smooth.spline(*, deriv > 0) :
> x <- (1:200)/32
> ss <- smooth.spline(x, 10*sin(x))
> stopifnot(length(x) == length(predict(ss,deriv=1)$x))# not yet in 1.5.0
>
> ## pweibull(large, log=T):
> stopifnot(pweibull(seq(1,50,len=1001), 2,3, log = TRUE) < 0)
Error: pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) < 0 is not TRUE
Execution halted

-------------------------------------------------------------------------------
- Nelson H. F. Beebe                    Tel: +1 801 581 5254                  -
- Center for Scientific Computing       FAX: +1 801 581 4148                  -
- University of Utah                    Internet e-mail: beebe@math.utah.edu  -
- Department of Mathematics, 110 LCB        beebe@acm.org  beebe@computer.org -
- 155 S 1400 E RM 233                       beebe@ieee.org                    -
- Salt Lake City, UT 84112-0090, USA    URL: http://www.math.utah.edu/~beebe  -

From ripley at stats.ox.ac.uk  Sat May  3 18:07:44 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May  3 18:08:00 2003
Subject: [Rd] R-1.7.0 build feedback: NetBSD 1.6 (PR#2837)
In-Reply-To: <200305031410.h43EAB2b001238@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305031519400.7222-100000@gannet.stats>

On Sat, 3 May 2003 beebe@math.utah.edu wrote:

> This is a followup to my report of a SIGSEGV in R-1.7.0 built
> on NetBSD 1.6.
> 
> Kurt Hornik responded:
> 
> >> ...
> >> After some discussions on r-core, two suggestions.
> >>
> >> * It might be helpful to know if zlib has found in the OS or compiled
> >>   from the sources within R: if the first you could try configure
> >>   --without-zlib as it is possible the OS has a modified version.
> >>
> >> * You have
> >>
> >>   R : Copyright 2003, The R Development Core Team
> >>   Version 1.7.0 Under development (unstable) (2003-04-11)
> >>                       ^^^^^^^^^^^^^^^^^^^^^^         ^^^
> >>
> >>   and might just have hit a bad day of the r-devel daily snapshot.
> >> ...
> 
> I don't think that the latter is the problem.  This version built,
> validated, and installed on several other platforms.
> 
> Since my initial bug report for this system, I upgraded the gcc
> release from 3.2.2 to the latest 3.2.3, so the compilation environment
> is now a bit different.
> 
> I tried your suggestion of the --without-zlib configure option, and
> that produced a working R, which I've installed.  There was one *.fail
> file in the tests directory: reg-tests-1.Rout.fail.  It is 2280 lines
> long, and contains a fair number of "Error xxx" reports.

About 12 are expected.  The error will be in the last command line, so 
only the last few lines of the file are relevant: to wit

> ## pweibull(large, log=T):
> stopifnot(pweibull(seq(1,50,len=1001), 2,3, log = TRUE) < 0)
Error: pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) < 0 is not TRUE

for which you would need to investigate the output of

pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) 

and I guess that this is an accuracy problem in the runtime (libc).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From hornik at ci.tuwien.ac.at  Sun May  4 12:26:36 2003
From: hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Sun May  4 11:29:48 2003
Subject: [Rd] R-1.7.0 build feedback: NetBSD 1.6 (PR#2837)
In-Reply-To: <Pine.LNX.4.44.0305031519400.7222-100000@gannet.stats>
References: <200305031410.h43EAB2b001238@pubhealth.ku.dk>
	<Pine.LNX.4.44.0305031519400.7222-100000@gannet.stats>
Message-ID: <16052.56524.86366.533238@mithrandir.hornik.net>

>>>>> Prof Brian Ripley writes:

> On Sat, 3 May 2003 beebe@math.utah.edu wrote:
>> This is a followup to my report of a SIGSEGV in R-1.7.0 built
>> on NetBSD 1.6.
>> 
>> Kurt Hornik responded:
>> 
>> >> ...
>> >> After some discussions on r-core, two suggestions.
>> >>
>> >> * It might be helpful to know if zlib has found in the OS or compiled
>> >>   from the sources within R: if the first you could try configure
>> >>   --without-zlib as it is possible the OS has a modified version.
>> >>
>> >> * You have
>> >>
>> >>   R : Copyright 2003, The R Development Core Team
>> >>   Version 1.7.0 Under development (unstable) (2003-04-11)
>> >>                       ^^^^^^^^^^^^^^^^^^^^^^         ^^^
>> >>
>> >>   and might just have hit a bad day of the r-devel daily snapshot.
>> >> ...
>> 
>> I don't think that the latter is the problem.  This version built,
>> validated, and installed on several other platforms.
>> 
>> Since my initial bug report for this system, I upgraded the gcc
>> release from 3.2.2 to the latest 3.2.3, so the compilation environment
>> is now a bit different.
>> 
>> I tried your suggestion of the --without-zlib configure option, and
>> that produced a working R, which I've installed.  There was one *.fail
>> file in the tests directory: reg-tests-1.Rout.fail.  It is 2280 lines
>> long, and contains a fair number of "Error xxx" reports.

> About 12 are expected.  The error will be in the last command line, so 
> only the last few lines of the file are relevant: to wit

>> ## pweibull(large, log=T):
>> stopifnot(pweibull(seq(1,50,len=1001), 2,3, log = TRUE) < 0)
> Error: pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) < 0 is not TRUE

> for which you would need to investigate the output of

> pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) 

> and I guess that this is an accuracy problem in the runtime (libc).

So the conclusion would be that the system's -lz is broken?  Argh ...

-k

From beebe at math.utah.edu  Sun May  4 17:05:15 2003
From: beebe at math.utah.edu (beebe@math.utah.edu)
Date: Sun May  4 16:05:34 2003
Subject: [Rd] R-1.7.0 build feedback: NetBSD 1.6 (PR#2837): final report
Message-ID: <200305041405.h44E5F2b004719@pubhealth.ku.dk>

I've now done two rebuilds of R-1.7.0 on NetBSD 1.6, one with the
--without-zlib configure option, and one without.  Both builds use the
recently-installed gcc-3.2.3 compiler.

As before, the one built normally gets a segment violation, whereas
the one built with the --without-zlib option works.

The odd thing is that neither uses shared libraries for zlib:

	% ldd /usr/local/lib/R/bin/R.bin
	/usr/local/lib/R/bin/R.bin:
		 -lm.0 => /usr/lib/libm387.so.0
		 -lm.0 => /usr/lib/libm.so.0
		 -lg2c.0 => /usr/local/lib/libg2c.so.0
		 -lc.12 => /usr/lib/libc.so.12
		 -lgcc_s.1 => /usr/local/lib/libgcc_s.so.1

The other build shows the same library list.

The NetBSD 1.6 system ships with these libraries:

	/usr/lib/libz.a   /usr/lib/libz.so.0    /usr/lib/libz_p.a
	/usr/lib/libz.so  /usr/lib/libz.so.0.2  /usr/lib/libz_pic.a

but the pkg_info commands on NetBSD and OpenBSD produce no output.

There seems to be no simple way to confirm the zlib version on these
systems.  Running strings and nm on libz.a produces no useful
identification.  However, /usr/include/zlib.h reports "version 1.1.4,
March 11th, 2002", which is the same as the one that I installed in
/usr/local/, and is the latest stable release (I'm on the zlib beta
testers list).  That number is confirmed by this simple test program:

	% cat show-zlib-version.c
	#include <stdio.h>
	#include <stdlib.h>
	#include <zlib.h>

	int
	main()
	{
	    (void)printf("zlibVersion() reports [%s]\n", zlibVersion());
	    return (EXIT_SUCCESS);
	}

	% cc show-zlib-version.c -lz && ./a.out
	zlibVersion() reports [1.1.4]

The bad one only segment faults after installation.  If I run it in
the build tree as bin/R, it works, and passes all but the base-Ex
test.

Brian Ripley responds to the reg-tests-1.Rout.fail file found in the
working build:

>> ...
>> The error will be in the last command line, so
>> only the last few lines of the file are relevant: to wit
>>
>> > ## pweibull(large, log=T):
>> > stopifnot(pweibull(seq(1,50,len=1001), 2,3, log = TRUE) < 0)
>> Error: pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) < 0 is not TRUE
>>
>> for which you would need to investigate the output of
>>
>> pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE)
>>
>> and I guess that this is an accuracy problem in the runtime (libc).
>> ...

Here is what I get in that output:

	% R

	R : Copyright 2003, The R Development Core Team
	Version 1.7.0 Under development (unstable) (2003-04-11)

	R is free software and comes with ABSOLUTELY NO WARRANTY.
	You are welcome to redistribute it under certain conditions.
	Type `license()' or `licence()' for distribution details.

	R is a collaborative project with many contributors.
	Type `contributors()' for more information.

	Type `demo()' for some demos, `help()' for on-line help, or
	`help.start()' for a HTML browser interface to help.
	Type `q()' to quit R.

	> pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE)
	  [1] -2.252266e+00 -2.162061e+00 -2.076474e+00 -1.995124e+00 -1.917675e+00
	   [6] -1.843830e+00 -1.773331e+00 -1.705943e+00 -1.641459e+00 -1.579693e+00
	  [11] -1.520477e+00 -1.463659e+00 -1.409102e+00 -1.356679e+00 -1.306276e+00
	  [16] -1.257788e+00 -1.211118e+00 -1.166177e+00 -1.122883e+00 -1.081160e+00
	  [21] -1.040937e+00 -1.002149e+00 -9.647332e-01 -9.286334e-01 -8.937957e-01
	  [26] -8.601698e-01 -8.277083e-01 -7.963667e-01 -7.661032e-01 -7.368779e-01
	  [31] -7.086534e-01 -6.813940e-01 -6.550661e-01 -6.296376e-01 -6.050778e-01
	  [36] -5.813577e-01 -5.584494e-01 -5.363265e-01 -5.149634e-01 -4.943358e-01
	  [41] -4.744204e-01 -4.551946e-01 -4.366369e-01 -4.187266e-01 -4.014437e-01
	  [46] -3.847688e-01 -3.686833e-01 -3.531692e-01 -3.382092e-01 -3.237864e-01
	  [51] -3.098845e-01 -2.964877e-01 -2.835807e-01 -2.711486e-01 -2.591770e-01
	  [56] -2.476519e-01 -2.365597e-01 -2.258870e-01 -2.156210e-01 -2.057491e-01
	  [61] -1.962592e-01 -1.871392e-01 -1.783776e-01 -1.699631e-01 -1.618847e-01
	  [66] -1.541315e-01 -1.466932e-01 -1.395596e-01 -1.327205e-01 -1.261664e-01
	  [71] -1.198878e-01 -1.138753e-01 -1.081199e-01 -1.026130e-01 -9.734578e-02
	  [76] -9.231000e-02 -8.749747e-02 -8.290025e-02 -7.851057e-02 -7.432090e-02
	  [81] -7.032386e-02 -6.651231e-02 -6.287926e-02 -5.941794e-02 -5.612173e-02
	  [86] -5.298423e-02 -4.999919e-02 -4.716054e-02 -4.446239e-02 -4.189903e-02
	  [91] -3.946490e-02 -3.715463e-02 -3.496298e-02 -3.288491e-02 -3.091551e-02
	  [96] -2.905005e-02 -2.728393e-02 -2.561271e-02 -2.403212e-02 -2.253801e-02
	 [101] -2.112637e-02 -1.979336e-02 -1.853526e-02 -1.734848e-02 -1.622957e-02
	 [106] -1.517522e-02 -1.418223e-02 -1.324752e-02 -1.236817e-02 -1.154132e-02
	 [111] -1.076427e-02 -1.003442e-02 -9.349278e-03 -8.706452e-03 -8.103661e-03
	 [116] -7.538723e-03 -7.009554e-03 -6.514161e-03 -6.050648e-03 -5.617201e-03
	 [121] -5.212098e-03 -4.833694e-03 -4.480428e-03 -4.150814e-03 -3.843441e-03
	 [126] -3.556967e-03 -3.290122e-03 -3.041701e-03 -2.810561e-03 -2.595622e-03
	 [131] -2.395859e-03 -2.210307e-03 -2.038050e-03 -1.878228e-03 -1.730026e-03
	 [136] -1.592676e-03 -1.465456e-03 -1.347685e-03 -1.238723e-03 -1.137968e-03
	 [141] -1.044855e-03 -9.588518e-04 -8.794615e-04 -8.062168e-04 -7.386800e-04
	 [146] -6.764415e-04 -6.191181e-04 -5.663515e-04 -5.178069e-04 -4.731716e-04
	 [151] -4.321541e-04 -3.944823e-04 -3.599030e-04 -3.281801e-04 -2.990941e-04
	 [156] -2.724409e-04 -2.480308e-04 -2.256875e-04 -2.052476e-04 -1.865595e-04
	 [161] -1.694827e-04 -1.538870e-04 -1.396520e-04 -1.266662e-04 -1.148267e-04
	 [166] -1.040384e-04 -9.421341e-05 -8.527081e-05 -7.713589e-05 -6.973986e-05
	 [171] -6.301937e-05 -5.691614e-05 -5.137658e-05 -4.635146e-05 -4.179554e-05
	 [176] -3.766734e-05 -3.392878e-05 -3.054498e-05 -2.748400e-05 -2.471657e-05
	 [181] -2.221595e-05 -1.995767e-05 -1.791939e-05 -1.608070e-05 -1.442298e-05
	 [186] -1.292925e-05 -1.158404e-05 -1.037325e-05 -9.284062e-06 -8.304808e-06
	 [191] -7.424880e-06 -6.634643e-06 -5.925350e-06 -5.289063e-06 -4.718585e-06
	 [196] -4.207393e-06 -3.749581e-06 -3.339801e-06 -2.973218e-06 -2.645460e-06
	 [201] -2.352578e-06 -2.091005e-06 -1.857524e-06 -1.649233e-06 -1.463518e-06
	 [206] -1.298022e-06 -1.150627e-06 -1.019425e-06 -9.027020e-07 -7.989171e-07
	 [211] -7.066874e-07 -6.247715e-07 -5.520563e-07 -4.875440e-07 -4.303409e-07
	 [216] -3.796467e-07 -3.347456e-07 -2.949976e-07 -2.598306e-07 -2.287339e-07
	 [221] -2.012514e-07 -1.769765e-07 -1.555466e-07 -1.366387e-07 -1.199652e-07
	 [226] -1.052701e-07 -9.232584e-08 -8.093002e-08 -7.090295e-08 -6.208508e-08
	 [231] -5.433485e-08 -4.752674e-08 -4.154950e-08 -3.630461e-08 -3.170488e-08
	 [236] -2.767316e-08 -2.414125e-08 -2.104887e-08 -1.834283e-08 -1.597615e-08
	 [241] -1.390740e-08 -1.210008e-08 -1.052202e-08 -9.144876e-09 -7.943739e-09
	 [246] -6.896685e-09 -5.984448e-09 -5.190104e-09 -4.498796e-09 -3.897489e-09
	 [251] -3.374750e-09 -2.920564e-09 -2.526156e-09 -2.183845e-09 -1.886912e-09
	 [256] -1.629483e-09 -1.406425e-09 -1.213253e-09 -1.046054e-09 -9.014167e-10
	 [261] -7.763638e-10 -6.683025e-10 -5.749754e-10 -4.944174e-10 -4.249193e-10
	 [266] -3.649955e-10 -3.133551e-10 -2.688775e-10 -2.305899e-10 -1.976489e-10
	 [271] -1.693233e-10 -1.449798e-10 -1.240699e-10 -1.061191e-10 -9.071710e-11
	 [276] -7.750911e-11 -6.618894e-11 -5.649181e-11 -4.818967e-11 -4.108569e-11
	 [281] -3.501033e-11 -2.981737e-11 -2.538114e-11 -2.159339e-11 -1.836120e-11
	 [286] -1.560441e-11 -1.325440e-11 -1.125233e-11 -9.547585e-12 -8.096857e-12
	 [291] -6.862844e-12 -5.813794e-12 -4.922507e-12 -4.165557e-12 -3.523182e-12
	 [296] -2.978284e-12 -2.516320e-12 -2.124856e-12 -1.793343e-12 -1.512790e-12
	 [301] -1.275424e-12 -1.074696e-12 -9.050538e-13 -7.618350e-13 -6.409318e-13
	 [306] -5.389023e-13 -4.528600e-13 -3.803624e-13 -3.193001e-13 -2.678968e-13
	 [311] -2.247091e-13 -1.882938e-13 -1.577627e-13 -1.321165e-13 -1.105782e-13
	 [316] -9.248158e-14 -7.727152e-14 -6.461498e-14 -5.395684e-14 -4.496403e-14
	 [321] -3.752554e-14 -3.130829e-14 -2.609024e-14 -2.176037e-14 -1.809664e-14
	 [326] -1.498801e-14 -1.254552e-14 -1.043610e-14 -8.659740e-15 -7.216450e-15
	 [331] -5.995204e-15 -4.884981e-15 -4.107825e-15 -3.330669e-15 -2.775558e-15
	 [336] -2.331468e-15 -1.887379e-15 -1.554312e-15 -1.332268e-15 -1.110223e-15
	 [341] -8.881784e-16 -7.771561e-16 -5.551115e-16 -5.551115e-16 -4.440892e-16
	 [346] -3.330669e-16 -3.330669e-16 -2.220446e-16 -2.220446e-16 -1.110223e-16
	 [351] -1.110223e-16 -1.110223e-16 -1.110223e-16 -1.110223e-16 -1.110223e-16
	 [356]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
	...all lines are zero from here on...
	 [996]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
	[1001]  0.000000e+00

When I compare it with output from FreeBSD 5.0 on the same platform, I
get 4 columns instead of 5, and the numbers are nonzero right up to
the last:

	> pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE)
	   [1]  -2.252266e+00  -2.162061e+00  -2.076474e+00  -1.995124e+00
	   [5]  -1.917675e+00  -1.843830e+00  -1.773331e+00  -1.705943e+00
	...
	 [993] -1.765317e-119 -1.028280e-119 -5.986435e-120 -3.483321e-120
	 [997] -2.025755e-120 -1.177467e-120 -6.840359e-121 -3.971708e-121
	[1001] -2.304857e-121

On OpenBSD 3.2 on the same platform (all of these systems run on top
of VMware on top of GNU/Linux 7.2 or 8.0 on Pentium III 600MHz dual
CPU servers), I get 5-column output, and trailing zeros:

	> pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE)
	   [1] -2.252266e+00 -2.162061e+00 -2.076474e+00 -1.995124e+00 -1.917675e+00
	   [6] -1.843830e+00 -1.773331e+00 -1.705943e+00 -1.641459e+00 -1.579693e+00
	  [11] -1.520477e+00 -1.463659e+00 -1.409102e+00 -1.356679e+00 -1.306276e+00
	  [16] -1.257788e+00 -1.211118e+00 -1.166177e+00 -1.122883e+00 -1.081160e+00
	  [21] -1.040937e+00 -1.002149e+00 -9.647332e-01 -9.286334e-01 -8.937957e-01
	...

	 [351] -1.110223e-16 -1.110223e-16 -1.110223e-16 -1.110223e-16 -1.110223e-16
	 [356]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
	...
	 [996]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
	[1001]  0.000000e+00

On Solaris 9 x86 on the same platform, I get 4-column output:

	> pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE)
	   [1]  -2.252266e+00  -2.162061e+00  -2.076474e+00  -1.995124e+00
	   [5]  -1.917675e+00  -1.843830e+00  -1.773331e+00  -1.705943e+00
	   [9]  -1.641459e+00  -1.579693e+00  -1.520477e+00  -1.463659e+00
	  [13]  -1.409102e+00  -1.356679e+00  -1.306276e+00  -1.257788e+00
	  [17]  -1.211118e+00  -1.166177e+00  -1.122883e+00  -1.081160e+00
	...
	 [353]  -8.543005e-17  -7.001648e-17  -5.735327e-17  -4.695528e-17
	 [357]  -3.842190e-17  -3.142256e-17  -2.568459e-17  -2.098321e-17
	 [361]  -1.713324e-17  -1.398220e-17  -1.140459e-17  -9.297196e-18
	...
	 [993] -1.765317e-119 -1.028280e-119 -5.986435e-120 -3.483321e-120
	 [997] -2.025755e-120 -1.177467e-120 -6.840359e-121 -3.971708e-121
	[1001] -2.304857e-121

On the underlying GNU/Linux systems, I get 4-column output:

	> pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE)
	   [1]  -2.252266e+00  -2.162061e+00  -2.076474e+00  -1.995124e+00
	   [5]  -1.917675e+00  -1.843830e+00  -1.773331e+00  -1.705943e+00
	   [9]  -1.641459e+00  -1.579693e+00  -1.520477e+00  -1.463659e+00
	  [13]  -1.409102e+00  -1.356679e+00  -1.306276e+00  -1.257788e+00
	  [17]  -1.211118e+00  -1.166177e+00  -1.122883e+00  -1.081160e+00
	...
	 [353]  -8.543005e-17  -7.001648e-17  -5.735327e-17  -4.695528e-17
	 [357]  -3.842190e-17  -3.142256e-17  -2.568459e-17  -2.098321e-17
	 [361]  -1.713324e-17  -1.398220e-17  -1.140459e-17  -9.297196e-18
	...
	 [997] -2.025755e-120 -1.177467e-120 -6.840359e-121 -3.971708e-121
	[1001] -2.304857e-121

I'd like to get to the bottom of these differences.  My numerical
calculator project, extended hoc

	http://www.math.utah.edu/hoc

has an extensive battery of validation tests, which have turned up
bugs in the math library on a half-dozen systems, including a couple
in glibc.  However, although the tests show some differences between
the four guest O/Ses, the chi-square and incomplete gamma function
tests pass.

The tests reveal that OpenBSD has these anomalies: exp(-Inf) -> NaN,
exp(Inf) -> Inf, but exp(-MAXNORMAL) -> 0 and exp(MAXNORMAL) -> +Inf,
as expected.

Examination of the R-1.7.0/src/nmath/pweibull.c file shows that
pweibull() calls pow(), log(), log1p(), and R_D_exp(), and the latter
is defined in ./src/nmath/dpq.h as

#define R_D_exp(x)       (log_p  ?  (x)   : exp(x))      /* exp(x) */

I therefore tried some experiments with hoc, using log1p() as the most
likely candidate for errors, since it is quite new, and much less used
than exp() and log().  And voil, log1p() is at least part of the
problem:

FreeBSD, Solaris 9 x86, GNU/Linux, Solaris SPARC:

	hoc64> for (k = 0; k <= 100; ++k) println k, log1p(2^-k)
	0 0.69314718055994529
	1 0.40546510810816438
	...
	50 8.8817841970012484e-16
	51 4.4408920985006252e-16
	52 2.2204460492503128e-16
	53 1.1102230246251565e-16
	...
	99 1.5777218104420236e-30
	100 7.8886090522101181e-31

NetBSD, OpenBSD:

	hoc64> for (k = 0; k <= 100; ++k) println k, log1p(2^-k)
	0 0.69314718055994529
	1 0.40546510810816438
	...
	50 8.8817841970012484e-16
	51 4.4408920985006252e-16
	52 2.2204460492503128e-16
	53 0
	54 0
	...
	99 0
	100 0

OpenBSD 3.3 was announced earlier this week, so if my colleague who
installs these systems can find the time, we may be able to test it as
well.

log1p will now get some additional tests in the hoc validation suite.

-------------------------------------------------------------------------------
- Nelson H. F. Beebe                    Tel: +1 801 581 5254                  -
- Center for Scientific Computing       FAX: +1 801 581 4148                  -
- University of Utah                    Internet e-mail: beebe@math.utah.edu  -
- Department of Mathematics, 110 LCB        beebe@acm.org  beebe@computer.org -
- 155 S 1400 E RM 233                       beebe@ieee.org                    -
- Salt Lake City, UT 84112-0090, USA    URL: http://www.math.utah.edu/~beebe  -

From ripley at stats.ox.ac.uk  Sun May  4 17:17:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun May  4 17:17:20 2003
Subject: [Rd] R-1.7.0 build feedback: NetBSD 1.6 (PR#2837)
In-Reply-To: <16052.56524.86366.533238@mithrandir.hornik.net>
Message-ID: <Pine.LNX.4.44.0305041614500.16454-100000@gannet.stats>

On Sun, 4 May 2003, Kurt Hornik wrote:

> >>>>> Prof Brian Ripley writes:
> 
> > On Sat, 3 May 2003 beebe@math.utah.edu wrote:
> >> This is a followup to my report of a SIGSEGV in R-1.7.0 built
> >> on NetBSD 1.6.
> >> 
> >> Kurt Hornik responded:
> >> 
> >> >> ...
> >> >> After some discussions on r-core, two suggestions.
> >> >>
> >> >> * It might be helpful to know if zlib has found in the OS or compiled
> >> >>   from the sources within R: if the first you could try configure
> >> >>   --without-zlib as it is possible the OS has a modified version.
> >> >>
> >> >> * You have
> >> >>
> >> >>   R : Copyright 2003, The R Development Core Team
> >> >>   Version 1.7.0 Under development (unstable) (2003-04-11)
> >> >>                       ^^^^^^^^^^^^^^^^^^^^^^         ^^^
> >> >>
> >> >>   and might just have hit a bad day of the r-devel daily snapshot.
> >> >> ...
> >> 
> >> I don't think that the latter is the problem.  This version built,
> >> validated, and installed on several other platforms.
> >> 
> >> Since my initial bug report for this system, I upgraded the gcc
> >> release from 3.2.2 to the latest 3.2.3, so the compilation environment
> >> is now a bit different.
> >> 
> >> I tried your suggestion of the --without-zlib configure option, and
> >> that produced a working R, which I've installed.  There was one *.fail
> >> file in the tests directory: reg-tests-1.Rout.fail.  It is 2280 lines
> >> long, and contains a fair number of "Error xxx" reports.
> 
> > About 12 are expected.  The error will be in the last command line, so 
> > only the last few lines of the file are relevant: to wit
> 
> >> ## pweibull(large, log=T):
> >> stopifnot(pweibull(seq(1,50,len=1001), 2,3, log = TRUE) < 0)
> > Error: pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) < 0 is not TRUE
> 
> > for which you would need to investigate the output of
> 
> > pweibull(seq(1, 50, len = 1001), 2, 3, log = TRUE) 
> 
> > and I guess that this is an accuracy problem in the runtime (libc).
> 
> So the conclusion would be that the system's -lz is broken?  Argh ...

Most likely, yes.  I've floated the idea before of not using a system -lz
as an insurance (and am intending to look for 1.1.4, not just 1.1.3, in 
1.8.0 once I get around to untangling the two uses of -lz in configure).

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mpvenkatesh at lycos.com  Mon May  5 02:07:30 2003
From: mpvenkatesh at lycos.com (mpvenkatesh@lycos.com)
Date: Mon May  5 01:07:43 2003
Subject: [Rd] R-1.7.0: Rproxy.dll loadlibrary/freelibrary error (PR#2914)
Message-ID: <200305042307.h44N7U2b006301@pubhealth.ku.dk>

Full_Name: Venkatesh Mysore
Version: R-1.7.0
OS: WindowsXP
Submission from: (NULL) (216.165.110.10)


While accessing Rproxy.dll repeatedly (using the code from the (D)COM example in
the R website) causes a failure in the 24th iteration. R-1.6.2 does NOT give
this error. This seems to be a memory management error, that might be linked to
the huge leakage difference between R-1.7.0 and R-1.6.2 (leakage observed using
Windows Task Manager).

Here is a C program that can be used to reproduce the error:
(the files SC-Proxy.h, Defn.h, Rinternals.h etc.. are to be included in the path
- see StatConnector.cpp in the (D)COM server example)


#include "windows.h"
#include "stdio.h"
#include "SC_Proxy.h"
#define RDLL "Rproxy.dll"
struct _SC_Proxy_Object* m_ProxyObject;
HMODULE m_ProxyModule;


#define SERVER_MAJOR_VERSION  "1"
#define SERVER_MINOR_VERSION "2"

#define	SCN_IERR_INTERFACENOTFOUND      0x81000000
#define	SCN_IERR_LIBRARYNOTFOUND        0x81000001
#define	SCN_IERR_INVALIDLIBRARY         0x81000002
#define	SCN_IERR_INITIALIZATIONFAILED   0x81000003
#define	SCN_IERR_INVALIDCONNECTORNAME   0x81000004
#define SCN_ERR_INITIALIZED             0x81000005
#define SCN_ERR_NOTINITIALIZED          0x81000006

#define TRACEBUFSIZE 1024
// 00-02-18 | baier | support arguments for connector initialization
// 01-04-04 | baier | enhancements by BDR: set RHOME from registry
// 03-04-07 | baier | check registry key on failure even if R_HOME is set,
//                    check PATH if everything else fails. trace failures!
int loadDll()
{
	  static char lTraceBuffer[TRACEBUFSIZE];
     // get entry-point
	if (getenv ("R_HOME"))
	  { // BDR
		  OutputDebugString("from env:");
		  char DLLlocation[MAX_PATH];
		  strcpy(DLLlocation, getenv("R_HOME"));
		  strcat(DLLlocation, "\\bin\\");
		  strcat(DLLlocation, RDLL);
		  OutputDebugString(DLLlocation);
		  m_ProxyModule = LoadLibraryEx (DLLlocation, NULL, 
					 LOAD_WITH_ALTERED_SEARCH_PATH);
		  // trace failure!
		  if (m_ProxyModule == 0) {
			  sprintf(lTraceBuffer,"R_HOME set to \"%s\", failed to load \"%s\"\n",
				  getenv("R_HOME"),DLLlocation);
			  OutputDebugString(lTraceBuffer);
		  }
	  }

      if (m_ProxyModule == 0)
	  {
	  // look in the registry
	  OutputDebugString("from reg:");
	  char DLLlocation[MAX_PATH];
	  LONG rc;
	  HKEY hkey;
	  DWORD keytype = REG_SZ;
	  DWORD cbData = sizeof (DLLlocation);
	  rc = RegOpenKeyEx (HKEY_LOCAL_MACHINE, "Software\\R-core\\R", 0, 
			     KEY_READ, &hkey);
	  if (rc == ERROR_SUCCESS)
	    {
	      rc = RegQueryValueEx (hkey, "InstallPath", 0, &keytype, 
				    (LPBYTE)DLLlocation, &cbData);
	      RegCloseKey (hkey);
	    }

	  if (rc == ERROR_SUCCESS)
	    {
	      // set R_HOME
	      char *buf;
	      buf =
		(char *) malloc ((strlen (DLLlocation) + 8) * sizeof (char));
	      strcpy (buf, "R_HOME=");
	      strcat (buf, DLLlocation);
	      putenv (buf);
	      //SetEnvironmentVariable ("R_HOME",DLLlocation);
	      strcat (DLLlocation, "\\bin\\");
		  strcat (DLLlocation, RDLL);
		  OutputDebugString(DLLlocation);
	      m_ProxyModule = LoadLibraryEx (DLLlocation, NULL, 
					     LOAD_WITH_ALTERED_SEARCH_PATH);
	      if (m_ProxyModule == 0) {
		sprintf(lTraceBuffer,"Registry information said to load \"%s\", failed!\n",
		        DLLlocation);
		OutputDebugString(lTraceBuffer);
	      }
	    }
	  } //module==0

	//m_ProxyModule = LoadLibraryEx ("C:\\R\\rw1070\\bin\\Rproxy.dll", NULL, 
	//				 LOAD_WITH_ALTERED_SEARCH_PATH);

	

      SC_PROXY_GET_OBJECT lFunc;
      
      lFunc = (SC_PROXY_GET_OBJECT) GetProcAddress (m_ProxyModule,
    						   SC_PROXY_GET_OBJECT_FUN);
	  
      
      if (lFunc == 0)
    	{
          return -1;
    	}
      
      // get proxy object
      ULONG lRc = lFunc (&m_ProxyObject,SC_PROXY_INTERFACE_VERSION);
      
	  
      if ((lRc != SC_PROXY_OK) || (m_ProxyObject == 0))
    	{
    	  FreeLibrary (m_ProxyModule);
    	  m_ProxyModule = 0;
    	  
          return -2;
    	}
      
      char* lParams = 0;

	lParams = strdup ("");
	OutputDebugString("vtbl->init getting called:");         
      // init R
      lRc = m_ProxyObject->vtbl->init (m_ProxyObject,lParams);
	OutputDebugString("done init.");      
      free (lParams);

      if (lRc != SC_PROXY_OK)
    	{
    	  m_ProxyObject->vtbl->release (m_ProxyObject);
    	  m_ProxyObject = 0;
    	  FreeLibrary (m_ProxyModule);
    	  m_ProxyModule = 0;
    	  
    	  return -3;
    	}
    return 1;
}

int unloadDll()
{

      m_ProxyObject->vtbl->release (m_ProxyObject);
	  m_ProxyObject = 0;

	  DWORD err;
      int b = FreeLibrary (m_ProxyModule);
	  if (b==0) {
		  err = GetLastError();
		char ss[100];
		sprintf(ss,"\n\nErr = %d\n\n", err);
		OutputDebugString(ss);
		return -1;
	  } else OutputDebugString("no error unloading Rproxy dll.\n\n");

	  m_ProxyModule = 0;
    
  return 1;
}


int main() {
	char ss[100];
	int i,x,a;
	for (i=1; i<=100; i++) {
		sprintf(ss,"Iteration: %d", i);
		OutputDebugString(ss);
	x=loadDll();
	if (x<=0) OutputDebugString("LoadLibraryEx ERROR.");
	else OutputDebugString("LoadLibraryEx succeeded.");
	a = unloadDll();
	if (a<=0) OutputDebugString("FreeLibrary ERROR.");
	else OutputDebugString("FreeLibrary succeeded.");
	}
}

-----------------------------------------

-Venkatesh Mysore
Bioinformatics Group,
New York University

From hornik at ci.tuwien.ac.at  Sun May  4 17:42:29 2003
From: hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Mon May  5 06:57:58 2003
Subject: [Rd] ldAIX4 does not generate Rlapack.exp (PR#2893)
In-Reply-To: <200305011920.h41JKg2b017522@pubhealth.ku.dk>
References: <200305011920.h41JKg2b017522@pubhealth.ku.dk>
Message-ID: <16053.9941.63663.297380@mithrandir.hornik.net>

>>>>> rgrubbfink  writes:

> Full_Name: Richard L. Grubb
> Version: 1.7.0
> OS: AIX 4.3.3
> Submission from: (NULL) (130.76.96.17)


> src/modules/lapack/Makefile executes the tools/ldAIX4 script and
> supplies, as arguments to ldAIX4, several object file names with
> filename extensions of .lo.  The ldAIX4 script did not generate the
> file etc/Rlapack.exp until I changed ldAIX4 as follows:

> Original context:
> # Check for object or archive files
> ofiles=""
> for arg; do
>     case $arg in *.o) ofiles="$ofiles $arg";; esac
>     case $arg in *.a) ofiles="$ofiles $arg";; esac
> done

> Changed context:
> # Check for object or archive files
> ofiles=""
> for arg; do
>     case $arg in *.o) ofiles="$ofiles $arg";; esac
>     case $arg in *.lo) ofiles="$ofiles $arg";; esac
>     case $arg in *.a) ofiles="$ofiles $arg";; esac
> done

> See also Bug reports 2887 and 2888

Thanks for spotting this.  Will change to

  case $arg in *.o | *.lo | *.a)

Re the two other bug reports.  If I recall correctly, the current
version of ldAIX4 was provided by Tom Vogels a long time ago.  Not sure
if R Core members currently still have access to an AIX4 system ...

I see that Tcl/Tk has a script called ldAix which I think does something
similar and hard-wires nm to /usr/ccs/bin/nm, and that libtool has

    # If we're using GNU nm, then we don't want the "-C" option.
    # -C means demangle to AIX nm, but means don't demangle with GNU nm
    if $NM -V 2>&1 | grep 'GNU' > /dev/null; then
      _LT_AC_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\''{ if (((\[$]2 == "T") || (\[$]2 == "D") || (\[$]2 == "B")) && ([substr](\[$]3,1,1) != ".")) { print \[$]3 } }'\'' | sort -u > $export_symbols'
    else
      _LT_AC_TAGVAR(export_symbols_cmds, $1)='$NM -BCpg $libobjs $convenience | awk '\''{ if (((\[$]2 == "T") || (\[$]2 == "D") || (\[$]2 == "B")) && ([substr](\[$]3,1,1) != ".")) { print \[$]3 } }'\'' | sort -u > $export_symbols'
    fi

As the libtool configure code is run anyway, I'd prefer making the $NM
configure value available and testing its value for being GNU nm or not,
if possible.  But see above: do you have a fix to the current version of
ldAIX4 that works with GNU nm?

-k

From swli at londonlink.net  Sun May  4 23:26:57 2003
From: swli at londonlink.net (swli@londonlink.net)
Date: Mon May  5 08:31:50 2003
Subject: [Rd] qsfi yjd FW: Descramble Digital Cable
Message-ID: <42a801c312cf$53d8c030$6ed02b4f@swli>


	[[alternate HTML version deleted]]

From childers83 at wattle.id.au  Mon May  5 13:04:43 2003
From: childers83 at wattle.id.au (Lane Childers)
Date: Mon May  5 14:04:30 2003
Subject: [Rd] Women will flock to you!!
Message-ID: <NJKNDKNDCEEHGDLEMFHJOJMMBIAA.childers83@wattle.id.au>




	[[alternate HTML version deleted]]

From rharding at justnet.com.au  Mon May  5 15:12:42 2003
From: rharding at justnet.com.au (rharding@justnet.com.au)
Date: Mon May  5 14:12:53 2003
Subject: [Rd] save money! (PR#2921)
Message-ID: <200305051212.h45CCg2b013333@pubhealth.ku.dk>




	[[alternate HTML version deleted]]

From harald at cepba.upc.es  Mon May  5 18:53:50 2003
From: harald at cepba.upc.es (harald@cepba.upc.es)
Date: Mon May  5 17:54:11 2003
Subject: [Rd] (PR#1289)
Message-ID: <200305051553.h45Fro2b016035@pubhealth.ku.dk>

Dear all,

I've found a bug report for R when installing it on an AIX5.1 system.
There's a followup (number 4) that comments a segmentation fault on R
when quitting "q()".

I'm using a newer version of R but on the same operating system and
I obtain the same error.

There was a way to solve this problem?

Best regards and thanks,

-- 
________________________________________________________________________
             Harald Servat Gelabert (harald@cepba.upc.es)
   o//o      Centre Europeu de Paral.lelisme de Barcelona          CEPBA
  o//o       WWW...: http://www.cepba.upc.es       Tel: +34-93-401 74 23
 o//o        e-mail: suport@cepba.upc.es           Fax: +34-93-401 25 77
o//o  CEPBA  c/Jordi Girona, 1-3, Mdul D6. E-08034 Barcelona, Catalunya
________________________________________________________________________

The optimist thinks that this is the best of all possible worlds,
and the pessimist knows it.
-- J. Robert Oppenheimer, "Bulletin of Atomic Scientists"

We scientists, whose tragic destiny it has been to make the methods
of annihilation ever more gruesome and more effective, must consider
it our solemn and transcendent duty to do all in our power in
preventing these weapons from being used for the brutal purpose for
which they were invented.
-- Albert Einstein,       "Bulletin of Atomic Scientists"

From p.dalgaard at biostat.ku.dk  Mon May  5 17:24:34 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon May  5 18:24:35 2003
Subject: [Rd] (PR#1289)
In-Reply-To: <200305051553.h45Fro2b016035@pubhealth.ku.dk>
References: <200305051553.h45Fro2b016035@pubhealth.ku.dk>
Message-ID: <x2he89bbny.fsf@biostat.ku.dk>

harald@cepba.upc.es writes:

> Dear all,
> 
> I've found a bug report for R when installing it on an AIX5.1 system.
> There's a followup (number 4) that comments a segmentation fault on R
> when quitting "q()".
> 
> I'm using a newer version of R but on the same operating system and
> I obtain the same error.
> 
> There was a way to solve this problem?

Well, some exact version numbers and bug report ditto might help
someone help you. 

Remember: *You* have a problem. People may actually go out of their
way to help you, but if they have to do detective work just to guess
your setup or figure out which PR# you're referring to, then they
might not bother.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From harald at cepba.upc.es  Mon May  5 19:39:22 2003
From: harald at cepba.upc.es (harald@cepba.upc.es)
Date: Mon May  5 18:39:35 2003
Subject: [Rd] (PR#1289)
Message-ID: <200305051639.h45GdM2b016240@pubhealth.ku.dk>

Ups, sorry, I forgot it. I thought that referencing the request
could be enough.

I'm trying to compile R 1.6.0, 1.6.1 and 1.6.2, and they all fail
on the same manner. With R 1.7.0 we have some problems for compiling
it.

I use GNU C version 3.1 and the G77 in the same package.

As I mentioned we have an AIX5.1 operating system running on a 
cluster of Power3 cpus.

When I launch R on the machine and quit from it, it makes a 
segmentation fault and core dumps.

Now I remember, when I tried to compile with XLC/XLF there were
several warning on a SETJMP or similar but this compiler didn't
fail on that point. (XLC failed when was unable to locate the
symbol __fixsfsi)


Best regards and thanks,


Peter Dalgaard BSA wrote:
> 
> harald@cepba.upc.es writes:
> 
> > Dear all,
> >
> > I've found a bug report for R when installing it on an AIX5.1 system.
> > There's a followup (number 4) that comments a segmentation fault on R
> > when quitting "q()".
> >
> > I'm using a newer version of R but on the same operating system and
> > I obtain the same error.
> >
> > There was a way to solve this problem?
> 
> Well, some exact version numbers and bug report ditto might help
> someone help you.
> 
> Remember: *You* have a problem. People may actually go out of their
> way to help you, but if they have to do detective work just to guess
> your setup or figure out which PR# you're referring to, then they
> might not bother.
> 
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

-- 
________________________________________________________________________
             Harald Servat Gelabert (harald@cepba.upc.es)
   o//o      Centre Europeu de Paral.lelisme de Barcelona          CEPBA
  o//o       WWW...: http://www.cepba.upc.es       Tel: +34-93-401 74 23
 o//o        e-mail: suport@cepba.upc.es           Fax: +34-93-401 25 77
o//o  CEPBA  c/Jordi Girona, 1-3, Mdul D6. E-08034 Barcelona, Catalunya
________________________________________________________________________

The optimist thinks that this is the best of all possible worlds,
and the pessimist knows it.
-- J. Robert Oppenheimer, "Bulletin of Atomic Scientists"

We scientists, whose tragic destiny it has been to make the methods
of annihilation ever more gruesome and more effective, must consider
it our solemn and transcendent duty to do all in our power in
preventing these weapons from being used for the brutal purpose for
which they were invented.
-- Albert Einstein,       "Bulletin of Atomic Scientists"

From ligges at statistik.uni-dortmund.de  Mon May  5 20:36:09 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Mon May  5 19:36:23 2003
Subject: [Rd] segfault when applying strange coercion (PR#2923)
Message-ID: <200305051736.h45Ha92b016451@pubhealth.ku.dk>

I made a mistake -- and R crashed. A (more or less) reproducible example 
seems to be:

   x <- matrix(nrow=20000, ncol=20)
   x$any <- numeric(0)

It is possible to crash R by executing these lines several times (1 - 
20) on Windows as well as on Solaris (might be related to PR#2880 - 
let's call it "non-existing list elements")

Uwe Ligges


--please do not edit the information below--

Version:
  platform = i386-pc-mingw32
  arch = i386
  os = mingw32
  system = i386, mingw32
  status =
  major = 1
  minor = 7.0
  year = 2003
  month = 04
  day = 16
  language = R

Windows NT 4.0 (build 1381) Service Pack 6

Search Path:
  .GlobalEnv, package:methods, package:ctest, package:mva, 
package:modreg, package:nls, package:ts, Autoloads, package:base

From pgilbert at bank-banque-canada.ca  Mon May  5 21:14:23 2003
From: pgilbert at bank-banque-canada.ca (pgilbert@bank-banque-canada.ca)
Date: Mon May  5 20:14:35 2003
Subject: [Rd] prcomp need Conj(t(s$vt)) (PR#2924)
Message-ID: <200305051814.h45IEN2b016635@pubhealth.ku.dk>

In prcomp

        s <- La.svd(x, nu = 0)
        s$v <- t(s$vt)

the second above line should be 

        s$v <- Conj(t(s$vt))

(to cover complex cases).

Paul Gilbert

From ripley at stats.ox.ac.uk  Mon May  5 20:19:36 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon May  5 20:19:48 2003
Subject: [Rd] prcomp need Conj(t(s$vt)) (PR#2924)
In-Reply-To: <200305051814.h45IEN2b016635@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305051915440.29159-100000@gannet.stats>

On Mon, 5 May 2003 pgilbert@bank-banque-canada.ca wrote:

> In prcomp
> 
>         s <- La.svd(x, nu = 0)
>         s$v <- t(s$vt)
> 
> the second above line should be 
> 
>         s$v <- Conj(t(s$vt))
> 
> (to cover complex cases).

They are not covered in the help page, AFAICS.

They are certainly not covered in the references quoted.

Are you not jumping to conclusions?  There is a lot of R that does not 
handle complex cases, and does not say so. (lm, for one.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From brahm at alum.mit.edu  Mon May  5 16:04:47 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Mon May  5 21:05:11 2003
Subject: [Rd] Suppressing Scientific Notation
Message-ID: <16054.46543.828428.318509@arbres1a.fmr.com>

Big thanks to Prof Brian Ripley <ripley@stats.ox.ac.uk> and Martin Maechler
<maechler@stat.math.ethz.ch> for help in building a patch to allow suppression
of scientific notation!  The working patch is attached below.  Most helpfully,
BDR persuaded me to avoid mucking with the options.c code entirely, so I really
only needed to do three things:

 1) Add a component "scipen" to the R_print_par_t struct defined in Print.h,
 2) Set it via GetOption in PrintDefaults, using 0 if the option is undefined,
 3) Use it in format.c to penalize the character count for scientific notation.

Normally, R prints "1e+05" rather than "100000" because the former takes only 5
characters, while the latter takes 6, and 5 < 6.  Now if you set
  R> options(scipen=3)
R will penalize the scientific notation version by 3 characters, and will print
"100000" in this example because 5+3 >= 6.  ("scipen" = "scientific notation
penalty".)  Setting e.g. options(scipen=999) will prevent effectively all
scientific notation.

   Note I have not documented the new option, and I have not measured how much
of a performance hit it entails (though I hope the use of PrintDefaults keeps
that low).  Anyway, I submit this patch as a possible future enhancement of R.
-- 
                              -- David Brahm (brahm@alum.mit.edu)


############################# Patch file follows #############################
#
# Go into the R-1.7.0 directory and type "patch -p1 < scipen.diff" where
#   "scipen.diff" is this file, and "patch" is the GNU patch utility.
#
diff -cr R-1.7.0/src/include/Print.h R-1.7.0.mod/src/include/Print.h
*** R-1.7.0/src/include/Print.h	2003-01-31 10:00:34.000000000 -0500
--- R-1.7.0.mod/src/include/Print.h	2003-05-05 12:34:56.614703522 -0400
***************
*** 38,43 ****
--- 38,44 ----
      int na_width;
      int na_width_noquote;
      int digits;
+     int scipen;
      int gap;
      int quote;
      int right;
diff -cr R-1.7.0/src/main/format.c R-1.7.0.mod/src/main/format.c
*** R-1.7.0/src/main/format.c	2003-01-24 11:44:50.000000000 -0500
--- R-1.7.0.mod/src/main/format.c	2003-05-05 12:38:51.181370171 -0400
***************
*** 283,289 ****
      *n = mxns - 1;
      *m = neg + (*n > 0) + *n + 4 + *e; /* width m for E	 format */
  
!     if (mF <= *m) { /* IFF it needs less space : "F" (Fixpoint) format */
  	*e = 0;
  	*n = rgt;
  	*m = mF;
--- 283,289 ----
      *n = mxns - 1;
      *m = neg + (*n > 0) + *n + 4 + *e; /* width m for E	 format */
  
!     if (mF <= *m  + R_print.scipen) { /* Fixpoint if it needs less space */
  	*e = 0;
  	*n = rgt;
  	*m = mF;
***************
*** 392,398 ****
  	else *er = 1;
  	*nr = mxns - 1;
  	*mr = neg + (*nr > 0) + *nr + 4 + *er;
! 	if (mF <= *mr) { /* IFF it needs less space : "F" (Fixpoint) format */
  	    *er = 0;
  	    *nr = rt;
  	    *mr = mF;
--- 392,398 ----
  	else *er = 1;
  	*nr = mxns - 1;
  	*mr = neg + (*nr > 0) + *nr + 4 + *er;
!         if (mF <= *mr + R_print.scipen) { /* Fixpoint if it needs less space */
  	    *er = 0;
  	    *nr = rt;
  	    *mr = mF;
***************
*** 418,424 ****
  	else *ei = 1;
  	*ni = i_mxns - 1;
  	*mi = (*ni > 0) + *ni + 4 + *ei;
! 	if (mF <= *mi) { /* IFF it needs less space : "F" (Fixpoint) format */
  	    *ei = 0;
  	    *ni = i_rt;
  	    *mi = mF;
--- 418,424 ----
  	else *ei = 1;
  	*ni = i_mxns - 1;
  	*mi = (*ni > 0) + *ni + 4 + *ei;
!         if (mF <= *mi + R_print.scipen) { /* Fixpoint if it needs less space */
  	    *ei = 0;
  	    *ni = i_rt;
  	    *mi = mF;
diff -cr R-1.7.0/src/main/print.c R-1.7.0.mod/src/main/print.c
*** R-1.7.0/src/main/print.c	2003-03-04 05:51:24.000000000 -0500
--- R-1.7.0.mod/src/main/print.c	2003-05-05 12:37:06.998036850 -0400
***************
*** 86,91 ****
--- 86,93 ----
      R_print.quote = 1;
      R_print.right = 0;
      R_print.digits = GetOptionDigits(rho);
+     R_print.scipen = asInteger(GetOption(install("scipen"), rho));
+     if (R_print.scipen == NA_INTEGER) R_print.scipen = 0;
      R_print.gap = 1;
      R_print.width = GetOptionWidth(rho);
  }
#
############################# End of patch file #############################

From p.dalgaard at biostat.ku.dk  Mon May  5 20:08:27 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon May  5 21:08:28 2003
Subject: [Rd] segfault when applying strange coercion (PR#2923)
In-Reply-To: <200305051736.h45Ha92b016451@pubhealth.ku.dk>
References: <200305051736.h45Ha92b016451@pubhealth.ku.dk>
Message-ID: <x28ytlb42n.fsf@biostat.ku.dk>

ligges@statistik.uni-dortmund.de writes:

> I made a mistake -- and R crashed. A (more or less) reproducible example 
> seems to be:
> 
>    x <- matrix(nrow=20000, ncol=20)
>    x$any <- numeric(0)
> 
> It is possible to crash R by executing these lines several times (1 - 
> 20) on Windows as well as on Solaris (might be related to PR#2880 - 
> let's call it "non-existing list elements")

Linux too: (r-devel)

...
> x <- matrix(nrow=20000, ncol=20) ;    x$any <- numeric(0)
Warning message:
Coercing LHS to a list
> x <- matrix(nrow=20000, ncol=20) ;    x$any <- numeric(0)

Program received signal SIGSEGV, Segmentation fault.
Rf_copyMostAttrib (inp=0xa2325a8, ans=0x402f9008)
    at ../../../R/src/main/attrib.c:155
155             if ((TAG(s) != R_NamesSymbol) &&

Tried running it with gctorture() but haven't gotten the prompt back
yet.... 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Mon May  5 23:07:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon May  5 23:15:03 2003
Subject: [Rd] Suppressing Scientific Notation
In-Reply-To: <16054.46543.828428.318509@arbres1a.fmr.com>
Message-ID: <Pine.LNX.4.44.0305052200370.29542-100000@gannet.stats>

I've merged this into R-devel, with some documentation.  I couldn't see
a measurable performance change.

On Mon, 5 May 2003, David Brahm wrote:

> Big thanks to Prof Brian Ripley <ripley@stats.ox.ac.uk> and Martin Maechler
> <maechler@stat.math.ethz.ch> for help in building a patch to allow suppression
> of scientific notation!  The working patch is attached below.  Most helpfully,
> BDR persuaded me to avoid mucking with the options.c code entirely, so I really
> only needed to do three things:
> 
>  1) Add a component "scipen" to the R_print_par_t struct defined in Print.h,
>  2) Set it via GetOption in PrintDefaults, using 0 if the option is undefined,
>  3) Use it in format.c to penalize the character count for scientific notation.
> 
> Normally, R prints "1e+05" rather than "100000" because the former takes only 5
> characters, while the latter takes 6, and 5 < 6.  Now if you set
>   R> options(scipen=3)
> R will penalize the scientific notation version by 3 characters, and will print
> "100000" in this example because 5+3 >= 6.  ("scipen" = "scientific notation
> penalty".)  Setting e.g. options(scipen=999) will prevent effectively all
> scientific notation.
> 
>    Note I have not documented the new option, and I have not measured how much
> of a performance hit it entails (though I hope the use of PrintDefaults keeps
> that low).  Anyway, I submit this patch as a possible future enhancement of R.
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon May  5 22:44:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon May  5 23:44:14 2003
Subject: [Rd] segfault when applying strange coercion (PR#2923)
In-Reply-To: <x28ytlb42n.fsf@biostat.ku.dk>
References: <200305051736.h45Ha92b016451@pubhealth.ku.dk>
	<x28ytlb42n.fsf@biostat.ku.dk>
Message-ID: <x2znm19iam.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> writes:

> ligges@statistik.uni-dortmund.de writes:
> 
> > I made a mistake -- and R crashed. A (more or less) reproducible example 
> > seems to be:
> > 
> >    x <- matrix(nrow=20000, ncol=20)
> >    x$any <- numeric(0)
> > 
> > It is possible to crash R by executing these lines several times (1 - 
> > 20) on Windows as well as on Solaris (might be related to PR#2880 - 
> > let's call it "non-existing list elements")
> 
> Linux too: (r-devel)
> 
> ...
> > x <- matrix(nrow=20000, ncol=20) ;    x$any <- numeric(0)
> Warning message:
> Coercing LHS to a list
> > x <- matrix(nrow=20000, ncol=20) ;    x$any <- numeric(0)
> 
> Program received signal SIGSEGV, Segmentation fault.
> Rf_copyMostAttrib (inp=0xa2325a8, ans=0x402f9008)
>     at ../../../R/src/main/attrib.c:155
> 155             if ((TAG(s) != R_NamesSymbol) &&
> 
> Tried running it with gctorture() but haven't gotten the prompt back
> yet.... 

For once, gctorture didn't seem to be of any use except to make things
take longer. 

A little further debugging reveals that the crash is happening in this
loop

154         for (s = ATTRIB(inp); s != R_NilValue; s = CDR(s)) {
155             if ((TAG(s) != R_NamesSymbol) &&
156                 (TAG(s) != R_DimSymbol) &&
157                 (TAG(s) != R_DimNamesSymbol)) {
158                 installAttrib(ans, TAG(s), CAR(s));
159             }
 
where inp is

(gdb) p *inp
$32 = {sxpinfo = {type = 4, obj = 0, named = 3, gp = 4789, mark = 0,
    debug = 1, trace = 0, fin = 0, gcgen = 0, gccls = 2}, attrib =0x4212b5c4,
  gengc_next_node = 0x83a8d50, gengc_prev_node = 0x83a8d50, u =
{primsxp = {...

[type = 4 means that it is an ENVSXP -- I don't think they generally
want to have attributes?]

(gdb) p *(inp->attrib)
$33 = {sxpinfo = {type = 28, obj = 1, named = 2, gp = 4789, mark = 0,
    debug = 1, trace = 0, fin = 0, gcgen = 0, gccls = 2}, attrib = 0x4212b5bc,

[type = 28 is undefined, so something is clearly wrong at this point]

Comes from R_subassign3_dflt ..hmm.. We have 

1680            if (!(isNewList(x) || isExpression(x))) {
1681                warning("Coercing LHS to a list");
1682                x = coerceVector(x, VECSXP);
1683            }

which requires reprotection of x does it not?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Tue May  6 00:09:38 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue May  6 01:09:39 2003
Subject: [Rd] segfault when applying strange coercion (PR#2923)
In-Reply-To: <x28ytlb42n.fsf@biostat.ku.dk>
References: <200305051736.h45Ha92b016451@pubhealth.ku.dk>
	<x28ytlb42n.fsf@biostat.ku.dk>
Message-ID: <x2n0i19ec6.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> writes:

> ligges@statistik.uni-dortmund.de writes:
> 
> > I made a mistake -- and R crashed. A (more or less) reproducible example 
> > seems to be:
> > 
> >    x <- matrix(nrow=20000, ncol=20)
> >    x$any <- numeric(0)
> > 
> > It is possible to crash R by executing these lines several times (1 - 
> > 20) on Windows as well as on Solaris (might be related to PR#2880 - 
> > let's call it "non-existing list elements")
> 
> Linux too: (r-devel)

Fixed now in r-patched. Thanks to Rob for reminding me of Luke's
REPROTECT mechanism.
        
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Tue May  6 11:43:37 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue May  6 10:44:20 2003
Subject: [Rd] Opening previous workspace in Windows (PR#2890) (fwd)
Message-ID: <200305060843.h468hb2b021295@pubhealth.ku.dk>

Filing the response on R-bugs.

It's quite possible that uninstalling R will damage this, but I would have 
expected it to be removed entirely.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

---------- Forwarded message ----------
Date: Tue, 6 May 2003 09:36:18 +0100
From: Heather Turner <Heather.L.Turner@exeter.ac.uk>
To: Prof Brian D Ripley <ripley@stats.ox.ac.uk>
Subject: Re: [Rd] Opening previous workspace in Windows (PR#2890)

On Thu, 1 May 2003 16:06:07 +0100 (GMT Daylight Time) Prof Brian D 
Ripley <ripley@stats.ox.ac.uk> wrote:

> Could you please check the file associations. In Windows Explorer go to
> `File options | File types' and look at RDATA.  The `open' command 
> should
> be something like
> 
> "c:\Program Files\R\rw1070\bin\RGui.exe" "%1"
> 
> and the behaviour you report is what I would expect if the second pair 
> of
> quotes is missing.  (If perchance it is, that tells you how to repair
> this, although it would not tell us how it went wrong ....)

Your expectation was correct  - adding "%1" to the open command fixes 
the problem. 

I think it might have happened because I installed the new
version before uninstalling the old version - although the files were 
still associated with the new version so it's a bit odd that it was 
just the second part of the open command that was wrong. However, I 
didn't have the problem on my home computer (WinXP) when I uninstalled 
the old version first so I expect that's where I went wrong.

Thanks for the fix,

Heather


-------------------
Mrs H L Turner
School of Mathematical Sciences
Laver Building
North Park Road
Exeter
EX4 4QE
Heather.L.Turner@exeter.ac.uk
Tel: (01392) 264465

From murdoch at stats.uwo.ca  Tue May  6 10:25:37 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue May  6 15:24:20 2003
Subject: [Rd] R-1.7.0: Rproxy.dll loadlibrary/freelibrary error (PR#2914)
In-Reply-To: <200305042307.h44N7U2b006301@pubhealth.ku.dk>
References: <200305042307.h44N7U2b006301@pubhealth.ku.dk>
Message-ID: <2kdfbv4g3k9gl5fle6dm1rmpgr39csmc37@4ax.com>

Venkatesh:

I was hoping someone else would pick up on this one.  I don't know the
rproxy code at all, so I can't tell if the error you are seeing is
some new error in R or a mistake on your part.  I've cc'd this to
Thomas Baier; Thomas, can you comment on this?

Venkatesh, you do mention a "huge leakage difference".  Could you
expand on that, and maybe give a loop in plain R code that causes R to
grow without bounds?

Duncan Murdoch

On Mon, 5 May 2003 01:07:30 +0200 (MET DST), you wrote in message
<200305042307.h44N7U2b006301@pubhealth.ku.dk>:

>Full_Name: Venkatesh Mysore
>Version: R-1.7.0
>OS: WindowsXP
>Submission from: (NULL) (216.165.110.10)
>
>
>While accessing Rproxy.dll repeatedly (using the code from the (D)COM example in
>the R website) causes a failure in the 24th iteration. R-1.6.2 does NOT give
>this error. This seems to be a memory management error, that might be linked to
>the huge leakage difference between R-1.7.0 and R-1.6.2 (leakage observed using
>Windows Task Manager).
>
>Here is a C program that can be used to reproduce the error:
>(the files SC-Proxy.h, Defn.h, Rinternals.h etc.. are to be included in the path
>- see StatConnector.cpp in the (D)COM server example)
>
>
>#include "windows.h"
>#include "stdio.h"
>#include "SC_Proxy.h"
>#define RDLL "Rproxy.dll"
>struct _SC_Proxy_Object* m_ProxyObject;
>HMODULE m_ProxyModule;
>
>
>#define SERVER_MAJOR_VERSION  "1"
>#define SERVER_MINOR_VERSION "2"
>
>#define	SCN_IERR_INTERFACENOTFOUND      0x81000000
>#define	SCN_IERR_LIBRARYNOTFOUND        0x81000001
>#define	SCN_IERR_INVALIDLIBRARY         0x81000002
>#define	SCN_IERR_INITIALIZATIONFAILED   0x81000003
>#define	SCN_IERR_INVALIDCONNECTORNAME   0x81000004
>#define SCN_ERR_INITIALIZED             0x81000005
>#define SCN_ERR_NOTINITIALIZED          0x81000006
>
>#define TRACEBUFSIZE 1024
>// 00-02-18 | baier | support arguments for connector initialization
>// 01-04-04 | baier | enhancements by BDR: set RHOME from registry
>// 03-04-07 | baier | check registry key on failure even if R_HOME is set,
>//                    check PATH if everything else fails. trace failures!
>int loadDll()
>{
>	  static char lTraceBuffer[TRACEBUFSIZE];
>     // get entry-point
>	if (getenv ("R_HOME"))
>	  { // BDR
>		  OutputDebugString("from env:");
>		  char DLLlocation[MAX_PATH];
>		  strcpy(DLLlocation, getenv("R_HOME"));
>		  strcat(DLLlocation, "\\bin\\");
>		  strcat(DLLlocation, RDLL);
>		  OutputDebugString(DLLlocation);
>		  m_ProxyModule = LoadLibraryEx (DLLlocation, NULL, 
>					 LOAD_WITH_ALTERED_SEARCH_PATH);
>		  // trace failure!
>		  if (m_ProxyModule == 0) {
>			  sprintf(lTraceBuffer,"R_HOME set to \"%s\", failed to load \"%s\"\n",
>				  getenv("R_HOME"),DLLlocation);
>			  OutputDebugString(lTraceBuffer);
>		  }
>	  }
>
>      if (m_ProxyModule == 0)
>	  {
>	  // look in the registry
>	  OutputDebugString("from reg:");
>	  char DLLlocation[MAX_PATH];
>	  LONG rc;
>	  HKEY hkey;
>	  DWORD keytype = REG_SZ;
>	  DWORD cbData = sizeof (DLLlocation);
>	  rc = RegOpenKeyEx (HKEY_LOCAL_MACHINE, "Software\\R-core\\R", 0, 
>			     KEY_READ, &hkey);
>	  if (rc == ERROR_SUCCESS)
>	    {
>	      rc = RegQueryValueEx (hkey, "InstallPath", 0, &keytype, 
>				    (LPBYTE)DLLlocation, &cbData);
>	      RegCloseKey (hkey);
>	    }
>
>	  if (rc == ERROR_SUCCESS)
>	    {
>	      // set R_HOME
>	      char *buf;
>	      buf =
>		(char *) malloc ((strlen (DLLlocation) + 8) * sizeof (char));
>	      strcpy (buf, "R_HOME=");
>	      strcat (buf, DLLlocation);
>	      putenv (buf);
>	      //SetEnvironmentVariable ("R_HOME",DLLlocation);
>	      strcat (DLLlocation, "\\bin\\");
>		  strcat (DLLlocation, RDLL);
>		  OutputDebugString(DLLlocation);
>	      m_ProxyModule = LoadLibraryEx (DLLlocation, NULL, 
>					     LOAD_WITH_ALTERED_SEARCH_PATH);
>	      if (m_ProxyModule == 0) {
>		sprintf(lTraceBuffer,"Registry information said to load \"%s\", failed!\n",
>		        DLLlocation);
>		OutputDebugString(lTraceBuffer);
>	      }
>	    }
>	  } //module==0
>
>	//m_ProxyModule = LoadLibraryEx ("C:\\R\\rw1070\\bin\\Rproxy.dll", NULL, 
>	//				 LOAD_WITH_ALTERED_SEARCH_PATH);
>
>	
>
>      SC_PROXY_GET_OBJECT lFunc;
>      
>      lFunc = (SC_PROXY_GET_OBJECT) GetProcAddress (m_ProxyModule,
>    						   SC_PROXY_GET_OBJECT_FUN);
>	  
>      
>      if (lFunc == 0)
>    	{
>          return -1;
>    	}
>      
>      // get proxy object
>      ULONG lRc = lFunc (&m_ProxyObject,SC_PROXY_INTERFACE_VERSION);
>      
>	  
>      if ((lRc != SC_PROXY_OK) || (m_ProxyObject == 0))
>    	{
>    	  FreeLibrary (m_ProxyModule);
>    	  m_ProxyModule = 0;
>    	  
>          return -2;
>    	}
>      
>      char* lParams = 0;
>
>	lParams = strdup ("");
>	OutputDebugString("vtbl->init getting called:");         
>      // init R
>      lRc = m_ProxyObject->vtbl->init (m_ProxyObject,lParams);
>	OutputDebugString("done init.");      
>      free (lParams);
>
>      if (lRc != SC_PROXY_OK)
>    	{
>    	  m_ProxyObject->vtbl->release (m_ProxyObject);
>    	  m_ProxyObject = 0;
>    	  FreeLibrary (m_ProxyModule);
>    	  m_ProxyModule = 0;
>    	  
>    	  return -3;
>    	}
>    return 1;
>}
>
>int unloadDll()
>{
>
>      m_ProxyObject->vtbl->release (m_ProxyObject);
>	  m_ProxyObject = 0;
>
>	  DWORD err;
>      int b = FreeLibrary (m_ProxyModule);
>	  if (b==0) {
>		  err = GetLastError();
>		char ss[100];
>		sprintf(ss,"\n\nErr = %d\n\n", err);
>		OutputDebugString(ss);
>		return -1;
>	  } else OutputDebugString("no error unloading Rproxy dll.\n\n");
>
>	  m_ProxyModule = 0;
>    
>  return 1;
>}
>
>
>int main() {
>	char ss[100];
>	int i,x,a;
>	for (i=1; i<=100; i++) {
>		sprintf(ss,"Iteration: %d", i);
>		OutputDebugString(ss);
>	x=loadDll();
>	if (x<=0) OutputDebugString("LoadLibraryEx ERROR.");
>	else OutputDebugString("LoadLibraryEx succeeded.");
>	a = unloadDll();
>	if (a<=0) OutputDebugString("FreeLibrary ERROR.");
>	else OutputDebugString("FreeLibrary succeeded.");
>	}
>}
>
>-----------------------------------------
>
>-Venkatesh Mysore
>Bioinformatics Group,
>New York University
>
>______________________________________________
>R-devel@stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From hornik at ci.tuwien.ac.at  Mon May  5 22:44:27 2003
From: hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Tue May  6 16:58:22 2003
Subject: [Rd] (PR#1289)
In-Reply-To: <200305051639.h45GdM2b016240@pubhealth.ku.dk>
References: <200305051639.h45GdM2b016240@pubhealth.ku.dk>
Message-ID: <16054.48923.85323.827671@mithrandir.hornik.net>

>>>>> harald  writes:

> Ups, sorry, I forgot it. I thought that referencing the request
> could be enough.

> I'm trying to compile R 1.6.0, 1.6.1 and 1.6.2, and they all fail
> on the same manner. With R 1.7.0 we have some problems for compiling
> it.

> I use GNU C version 3.1 and the G77 in the same package.

> As I mentioned we have an AIX5.1 operating system running on a 
> cluster of Power3 cpus.

> When I launch R on the machine and quit from it, it makes a 
> segmentation fault and core dumps.

It might be helpful if you could debug this ...

Btw, I think the usual recommendation is using GCC 3.0 or 3.2, but not
3.1.

-k

From jerome at hivnet.ubc.ca  Wed May  7 01:37:02 2003
From: jerome at hivnet.ubc.ca (jerome@hivnet.ubc.ca)
Date: Wed May  7 00:37:15 2003
Subject: [Rd] frailty models in survreg() -- survival package (PR#2933)
Message-ID: <200305062237.h46Mb22b029261@pubhealth.ku.dk>


I am confused on how the log-likelihood is calculated in a parametric 
survival problem with frailty. I see a contradiction in the frailty() help 
file vs. the source code of frailty.gamma(), frailty.gaussian() and 
frailty.t().

The function frailty.gaussian() appears to calculate the penalty as the 
negative log-density of independent Gaussian variables, as one would 
expect:
> frailty.gaussian
[...]
            list([...], penalty = 0.5 * sum(coef^2/theta +
                log(2 * pi * theta)), flag = FALSE)
[...]

Similarly, the frailty.t() appears to use the joint negative log-density 
of Student t random variables. HOWEVER, frailty.gamma() uses:
> frailty.gamma
[...]
            list([...], penalty = -sum(coef) *
                nu, flag = FALSE)
[...]
I would rather expect to see something like:
(1)    penalty=sum(coef*nu-(nu-1)*log(coef)+lgamma(nu)-nu*log(nu))
which is the joint negative log-density of gamma variables. Alternately, I 
could also expect to see something like this:
(2)    penalty=sum(coef-exp(coef))*nu
which was shown to lead to the same EM solution as penalty (1) -- at least 
in the case of a Cox proportional hazard model (Therneau and Grambsch, 
2000. Modeling Survival Data, Extending the Cox Model. Springer, New York. 
Page 254, Eq. (9.8).). Bare we me, I don't know whether this holds in the 
case of a parametric model. I also have concerns about the validity of the 
likelihood ratio tests obtained with the latter penalty function (2), 
because this penalty is NOT equal to the negative log-likelihood (1). 
Finally, it's not clear to me whether we gain significant convergence 
speed and accuracy by using the penalty (2) as opposed to (1).

Furthermore, the help file for frailty() says,
     "The penalised likelihood method is equivalent to maximum (partial)
     likelihood for the gamma frailty but not for the others."

In the current state of the package, I would think that this should be the 
other way around. That is,
     "The penalised likelihood method is equivalent to maximum (partial)
     likelihood for the gaussian and t frailty but not for the gamma."

However, my current comprehension of the problem leads me to recommend to 
use the negative log-likelihood of gamma variables (2). Hence, both gamma, 
Gaussian and t frailty would be equivalent to maximum (partial) likelihood.

Any comment on this issue would be much appreciated.

Sincerely,
Jerome Asselin

R 1.6.2 on Red Hat Linux 7.2
Package: survival
Version: 2.9-7

-- 

Jerome Asselin (Jrme), Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, 608 - 1081 Burrard Street
Vancouver, British Columbia, CANADA V6Z 1Y6
Email: jerome@hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044

From tlumley at u.washington.edu  Wed May  7 01:58:42 2003
From: tlumley at u.washington.edu (tlumley@u.washington.edu)
Date: Wed May  7 00:58:55 2003
Subject: [Rd] Re: frailty models in survreg() -- survival package (PR#2934)
Message-ID: <200305062258.h46Mwg2b029323@pubhealth.ku.dk>

On Tue, 6 May 2003, Jerome Asselin wrote:

>
> I am confused on how the log-likelihood is calculated in a parametric
> survival problem with frailty. I see a contradiction in the frailty() help
> file vs. the source code of frailty.gamma(), frailty.gaussian() and
> frailty.t().
>
> The function frailty.gaussian() appears to calculate the penalty as the
> negative log-density of independent Gaussian variables, as one would
> expect:
> > frailty.gaussian
> [...]
>             list([...], penalty = 0.5 * sum(coef^2/theta +
>                 log(2 * pi * theta)), flag = FALSE)
> [...]
>
> Similarly, the frailty.t() appears to use the joint negative log-density
> of Student t random variables. HOWEVER, frailty.gamma() uses:
> > frailty.gamma
> [...]
>             list([...], penalty = -sum(coef) *
>                 nu, flag = FALSE)
> [...]
> I would rather expect to see something like:
> (1)    penalty=sum(coef*nu-(nu-1)*log(coef)+lgamma(nu)-nu*log(nu))
> which is the joint negative log-density of gamma variables. Alternately, I
> could also expect to see something like this:
> (2)    penalty=sum(coef-exp(coef))*nu
> which was shown to lead to the same EM solution as penalty (1) -- at least
> in the case of a Cox proportional hazard model (Therneau and Grambsch,
> 2000. Modeling Survival Data, Extending the Cox Model. Springer, New York.
> Page 254, Eq. (9.8).).

Looking at a wider context in the code

   pfun <- function(coef, theta, ndeath) {
        if (theta == 0)
            list(recenter = 0, penalty = 0, flag = TRUE)
        else {
            recenter <- log(mean(exp(coef)))
            coef <- coef - recenter
            nu <- 1/theta
            list(recenter = recenter, first = (exp(coef) - 1) *
                nu, second = exp(coef) * nu, penalty = -sum(coef) *
                nu, flag = FALSE)
        }
    }

so the recentering means the penalty is actually your penalty (2) -- not
surprising, as the code was written by Terry Therneau.



> Bare we me, I don't know whether this holds in the
> case of a parametric model. I also have concerns about the validity of the
> likelihood ratio tests obtained with the latter penalty function (2),
> because this penalty is NOT equal to the negative log-likelihood (1).
> Finally, it's not clear to me whether we gain significant convergence
> speed and accuracy by using the penalty (2) as opposed to (1).
>
> Furthermore, the help file for frailty() says,
>      "The penalised likelihood method is equivalent to maximum (partial)
>      likelihood for the gamma frailty but not for the others."
>
> In the current state of the package, I would think that this should be the
> other way around. That is,
>      "The penalised likelihood method is equivalent to maximum (partial)
>      likelihood for the gaussian and t frailty but not for the gamma."
>
> However, my current comprehension of the problem leads me to recommend to
> use the negative log-likelihood of gamma variables (2). Hence, both gamma,
> Gaussian and t frailty would be equivalent to maximum (partial) likelihood.
>

The log density penalty doesn't give maximum likelihood (which you would
get by integrating out the frailties). It gives the joint likelihood of
the data and the random effects.

For the gamma model, as you note, they are equivalent.  I believe that the
current state of knowledge is that the log density penalty generally gives
consistent estimates but is not equivalent to maximum likelihood. However,
I have not actually seen the arguments for consistency and it isn't
obvious to me how the argument would go.


	-thomas

From jerome at hivnet.ubc.ca  Wed May  7 02:54:17 2003
From: jerome at hivnet.ubc.ca (jerome@hivnet.ubc.ca)
Date: Wed May  7 01:54:37 2003
Subject: [Rd] Re: frailty models in survreg() -- survival package (PR#2934)
Message-ID: <200305062354.h46NsH2b029459@pubhealth.ku.dk>


SEE ALSO ORIGINAL POSTING IN PR#2933

On May 6, 2003 03:58 pm, Thomas Lumley wrote:
>
> Looking at a wider context in the code
>
>    pfun <- function(coef, theta, ndeath) {
>         if (theta == 0)
>             list(recenter = 0, penalty = 0, flag = TRUE)
>         else {
>             recenter <- log(mean(exp(coef)))
>             coef <- coef - recenter
>             nu <- 1/theta
>             list(recenter = recenter, first = (exp(coef) - 1) *
>                 nu, second = exp(coef) * nu, penalty = -sum(coef) *
>                 nu, flag = FALSE)
>         }
>     }
>
> so the recentering means the penalty is actually your penalty (2) -- not
> surprising, as the code was written by Terry Therneau.

Ok, I forgot to account for the recentering. However, correct me if I am 
wrong, but if Therneau and Grambsch (2000, Eq. (9.8)) are right, I think 
it should be:
            recenter <- mean(exp(coef))
instead of
            recenter <- log(mean(exp(coef)))

>
> The log density penalty doesn't give maximum likelihood (which you would
> get by integrating out the frailties). It gives the joint likelihood of
> the data and the random effects.

I'm confused... Do you mean that the log-likelihood of all model 
parameters (which is maximised) is NOT the sum of the conditional 
log-likelihood of the data and the log-likelihood of the random effects?

>
> For the gamma model, as you note, they are equivalent.  I believe that
> the current state of knowledge is that the log density penalty generally
> gives consistent estimates but is not equivalent to maximum likelihood.
> However, I have not actually seen the arguments for consistency and it
> isn't obvious to me how the argument would go.
>

Sorry, I don't understand why you say that they are equivalent for the 
gamma model. Therneau and Grambsch (p.254) specifically note,
"... the penalized loglikelihood and the observed-data loglikelihood in 
equation (9.4) have the same solution, although these two equations are 
NOT equal to one another."
For that reason, I think that the help file should read,
> >      "The penalised likelihood method is equivalent to maximum
> > (partial) likelihood for the gaussian and t frailty but not for the
> > gamma."

Also, is it clear whether the current gamma penalty function remains valid 
even in the case of parametric survival analysis? Is it computationally 
better than (1)? Finally, what is the meaning of the "loglik" value in 
gamma frailty? Can it still be used to calculate likelihood ratio tests?

Cheers,
Jerome

From kjetil at entelnet.bo  Tue May  6 21:54:20 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed May  7 02:54:43 2003
Subject: [Rd] Problems building R-1.7.0 on windows XP
Message-ID: <3EB820FC.23322.1239E2C@localhost>

Hola!

Everything went well until 
make distribution

The last few lines from the make output is:

Copying spatial
find rw1070 -name CVS -prune -exec rm -rf \{\} \;
FIND: formato de par?metros incorrecto
make[2]: *** [imagedir] Error 2
make[2]: Leaving directory `/cygdrive/c/R/Rsource/R-
1.7.0/src/gnuwin32/installer'
make[1]: *** [rinstaller] Error 2
make[1]: Leaving directory `/cygdrive/c/R/Rsource/R-
1.7.0/src/gnuwin32'
make: *** [distribution] Error 2

So there seems to be a problem with find. I downloaded and innstalled 
the latest version of tools.zip today.

Any idea of what is going wrong?

Kjetil Halvorsen

From dmurdoch at pair.com  Tue May  6 22:20:31 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed May  7 03:20:37 2003
Subject: [Rd] Problems building R-1.7.0 on windows XP
In-Reply-To: <3EB820FC.23322.1239E2C@localhost>
References: <3EB820FC.23322.1239E2C@localhost>
Message-ID: <mengbvsd6tgi54cgr2672agv8sst98uvis@4ax.com>

On Tue, 06 May 2003 20:54:20 -0400, you wrote:

>Hola!
>
>Everything went well until 
>make distribution
>
>The last few lines from the make output is:
>
>Copying spatial
>find rw1070 -name CVS -prune -exec rm -rf \{\} \;
>FIND: formato de par?metros incorrecto
>make[2]: *** [imagedir] Error 2

I don't know what that error would be, but you don't really need to go
that far.  By that point you're building the installer; if you're
doing a build for yourself, you only need to go as far as "docs" in
the list of targets in the src/gnuwin32/INSTALL file.  

If I were going to guess at the reason, I'd guess you have a different
version of find in your path ahead of the R tools one (mine gives
English error messages), or you have something on your system that
makes it think it's talking Spanish, so perhaps "-name", "-prune" and
"-exec" need to be translated too.

Duncan Murdoch

From James at amotransport.com  Wed May  7 06:37:14 2003
From: James at amotransport.com (James@amotransport.com)
Date: Wed May  7 05:37:37 2003
Subject: [Rd] This Car Shipping Company Might Interst You. (PR#2938)
Message-ID: <200305070337.h473bE2b000065@pubhealth.ku.dk>

<HTML><HEAD><TITLE>This Car Shipping Company Might Interst You.</TITLE>
<META charset=UTF-8 http-equiv=Content-Type content="text/html; charset=utf-8">
</STYLE>
</HEAD>
<BODY bgColor=#ffffff background="">
<TBODY>
<TR>
<TD class=smallesttext bgColor=#b5107b>
<TABLE width="100%">
<TBODY>
<TR>
<TD class=smallesttext bgColor=#800080>
<p align="center">&nbsp;<B><FONT size=4 face="Arial, Helvetica, sans-serif"><a href="http://www.amotransport.com" style="text-decoration: none"><font color="#FFFFFF">The 
      Car Shipping experts</font></a></FONT></B>&nbsp;</TD>
</TR></TBODY></TABLE></TD></TR></TBODY></TABLE>
<TABLE borderColor=#b5107b cellSpacing=0 cellPadding=5 width="100%" bgColor=#ffffff border=1>
<TBODY>
<TR>
<TD bordercolor="#800080">
<TABLE>
<TBODY>
<TR>
<TD vAlign=top>
<p align="center"><span style="background-color: #FFFFFF"><b>D</b></span><FONT face="Arial, Helvetica, sans-serif"><B><FONT face=Arial><SPAN 
                  style="BACKGROUND-COLOR: #ffffff">o you need, or know of 
someone who needs a Car Transported to another state? 
                  </SPAN></FONT></B></FONT>
<BR><FONT face="Arial, Helvetica, sans-serif" 
                  color=#b57272 size=4>
                  <IMG 
                  src="http://www.amotransport.com/images/image.jpg" border=0 width="248" height="106" align="middle"></FONT><BR>&nbsp;</p>
<FONT 
                  face="Arial, Helvetica, sans-serif" size=2>
                  <DIV align=center><FONT size=4>Online State-of-the-art 
                    computer Car tracking system</FONT></DIV>
                  <DIV align=center><FONT size=4>Office: Mon-Fri 9am to 5pm 
                  "Central" </FONT></DIV>
                  <DIV align=center><FONT size=4>Phone: </FONT><SPAN 
                  class=heading><FONT size=4>(888) 356-1468</FONT></SPAN></DIV>
                  <DIV align=center><B>Visit 
                  our site for an <U><a href="http://www.amotransport.com">Instant online 
                  quote</a></U></B><FONT 
                  face="Arial, Helvetica, sans-serif" size=4>
                    <font color="#FF0000">24/7</font></FONT></DIV>
                  <DIV align=center><FONT 
                  face="Arial, Helvetica, sans-serif" size=4>
                  <a href="http://www.amotransport.com" style="text-decoration: none"><b>America's leading </b>
                  </a></FONT>
                  <B>
                  <a href="http://www.amotransport.com" style="text-decoration: none">
                  <FONT size=4 face="Arial, Helvetica, sans-serif">Transport Company.</FONT></a></B></DIV>
                  <P align=left><FONT face=Arial><B><FONT size=2>&nbsp; We 
                  take great pride in our car shipping 
                  service. We arrange transports for relocation individuals, 
                  college students, dealerships and our specialty: SNOWBIRDS ! 
                  We can move your car coast to coast and most points in 
                  between. <BR><BR>&nbsp;&nbsp; We understand that having 
                  someone move your auto is no small matter - your car is not 
                  only an expensive possession, it's also part of your family. 
                  Our 5 Star Carriers take great care to ensure that your car is 
                  protected from start to finish. And unlike other carriers, 
                  once your car is on our truck, it doesnt get off until it 
                  reaches its destination  theres no loading and reloading at 
                  big consolidation centers. Minimized handling means a minimum 
                  risk of problems.</FONT>&nbsp; The most trusted in the 
                  business</B></FONT></FONT></P></TD></TR></TBODY></TABLE>
<TABLE width="100%">
<TBODY>
<TR>
<TD align=middle bgColor=#800080>&nbsp;</TD></TR>
</TBODY></TABLE></TD></TR>
</TBODY></TABLE>
<CENTER>
<DIV class=smallesttext align=center>
                <p align="left">
                <FONT 
                  face="tahoma, arial, sanserif" size="2">We're sending this message 
                <b>only once</b> to 
                  every affiliate subscriber. This message isn't spam. 
                  If you feel you've gotten this message in error, please reply with the subject "Remove" and we'll remove your e-mail 
                  address from our records.</FONT></DIV></CENTER></BODY></HTML>

From baier at ci.tuwien.ac.at  Wed May  7 09:14:20 2003
From: baier at ci.tuwien.ac.at (Thomas Baier)
Date: Wed May  7 08:14:57 2003
Subject: [Rd] R-1.7.0: Rproxy.dll loadlibrary/freelibrary error (PR#2914)
In-Reply-To: <2kdfbv4g3k9gl5fle6dm1rmpgr39csmc37@4ax.com>
Message-ID: <200305070614.h476EKnn000717@luthien.ci.tuwien.ac.at>

> Venkatesh:
> 
> I was hoping someone else would pick up on this one.  I don't know the
> rproxy code at all, so I can't tell if the error you are seeing is
> some new error in R or a mistake on your part.  I've cc'd this to
> Thomas Baier; Thomas, can you comment on this?
> 
> Venkatesh, you do mention a "huge leakage difference".  Could you
> expand on that, and maybe give a loop in plain R code that causes R to
> grow without bounds?

Just had a look at the code (but no further analysis at the moment).

What you're trying to do is you load and unload the library some times.
This is something you normally shouldn't do ;-)

1. Windows has some problems in releasing all memory of a DLL. Just
   loading and unloading a DLL (just containing text resources, no code
   at all) causes a memory leak (and a significant delay in time)
2. R itself assumes (or that's what I think) that all resources which are
   not explicitly freed are released by the operating system when R quits

Of course, you're right, that this could be a problem (the current implemen-
tation of the COM server loads the DLL in Init() and unloads in Terminate()).
But on the other hand, the COM server also gets terminated after the reference
to the COM object is released and every client gets a new server process.

If R 1.6.2 doesn't behave the same as you stated, there may be some newly
allocated resources which don't get freed (maybe statics which you can only
handle safely in an atexit() routine).

The question to Duncan now is if you are aware of any resources which can/should
be freed by rproxy.dll or by R. Anything we can do about it.

Venkatesh: Maybe you can just keep a single reference to the proxy object
so you won't hit the problem. Or use the COM server, which will automatically
handle this for you (out of process).

Best,
Thomas

> Duncan Murdoch
> 
> On Mon, 5 May 2003 01:07:30 +0200 (MET DST), you wrote in message
> <200305042307.h44N7U2b006301@pubhealth.ku.dk>:
> 
> >Full_Name: Venkatesh Mysore
> >Version: R-1.7.0
> >OS: WindowsXP
> >Submission from: (NULL) (216.165.110.10)
> >
> >
> >While accessing Rproxy.dll repeatedly (using the code from the (D)COM example in
> >the R website) causes a failure in the 24th iteration. R-1.6.2 does NOT give
> >this error. This seems to be a memory management error, that might be linked to
> >the huge leakage difference between R-1.7.0 and R-1.6.2 (leakage observed using
> >Windows Task Manager).
> >
> >Here is a C program that can be used to reproduce the error:
> >(the files SC-Proxy.h, Defn.h, Rinternals.h etc.. are to be included in the path
> >- see StatConnector.cpp in the (D)COM server example)
> >
> >
> >#include "windows.h"
> >#include "stdio.h"
> >#include "SC_Proxy.h"
> >#define RDLL "Rproxy.dll"
> >struct _SC_Proxy_Object* m_ProxyObject;
> >HMODULE m_ProxyModule;
> >
> >
> >#define SERVER_MAJOR_VERSION  "1"
> >#define SERVER_MINOR_VERSION "2"
> >
> >#define	SCN_IERR_INTERFACENOTFOUND      0x81000000
> >#define	SCN_IERR_LIBRARYNOTFOUND        0x81000001
> >#define	SCN_IERR_INVALIDLIBRARY         0x81000002
> >#define	SCN_IERR_INITIALIZATIONFAILED   0x81000003
> >#define	SCN_IERR_INVALIDCONNECTORNAME   0x81000004
> >#define SCN_ERR_INITIALIZED             0x81000005
> >#define SCN_ERR_NOTINITIALIZED          0x81000006
> >
> >#define TRACEBUFSIZE 1024
> >// 00-02-18 | baier | support arguments for connector initialization
> >// 01-04-04 | baier | enhancements by BDR: set RHOME from registry
> >// 03-04-07 | baier | check registry key on failure even if R_HOME is set,
> >//                    check PATH if everything else fails. trace failures!
> >int loadDll()
> >{
> >	  static char lTraceBuffer[TRACEBUFSIZE];
> >     // get entry-point
> >	if (getenv ("R_HOME"))
> >	  { // BDR
> >		  OutputDebugString("from env:");
> >		  char DLLlocation[MAX_PATH];
> >		  strcpy(DLLlocation, getenv("R_HOME"));
> >		  strcat(DLLlocation, "\\bin\\");
> >		  strcat(DLLlocation, RDLL);
> >		  OutputDebugString(DLLlocation);
> >		  m_ProxyModule = LoadLibraryEx (DLLlocation, NULL, 
> >					 LOAD_WITH_ALTERED_SEARCH_PATH);
> >		  // trace failure!
> >		  if (m_ProxyModule == 0) {
> >			  sprintf(lTraceBuffer,"R_HOME set to \"%s\", failed to load \"%s\"\n",
> >				  getenv("R_HOME"),DLLlocation);
> >			  OutputDebugString(lTraceBuffer);
> >		  }
> >	  }
> >
> >      if (m_ProxyModule == 0)
> >	  {
> >	  // look in the registry
> >	  OutputDebugString("from reg:");
> >	  char DLLlocation[MAX_PATH];
> >	  LONG rc;
> >	  HKEY hkey;
> >	  DWORD keytype = REG_SZ;
> >	  DWORD cbData = sizeof (DLLlocation);
> >	  rc = RegOpenKeyEx (HKEY_LOCAL_MACHINE, "Software\\R-core\\R", 0, 
> >			     KEY_READ, &hkey);
> >	  if (rc == ERROR_SUCCESS)
> >	    {
> >	      rc = RegQueryValueEx (hkey, "InstallPath", 0, &keytype, 
> >				    (LPBYTE)DLLlocation, &cbData);
> >	      RegCloseKey (hkey);
> >	    }
> >
> >	  if (rc == ERROR_SUCCESS)
> >	    {
> >	      // set R_HOME
> >	      char *buf;
> >	      buf =
> >		(char *) malloc ((strlen (DLLlocation) + 8) * sizeof (char));
> >	      strcpy (buf, "R_HOME=");
> >	      strcat (buf, DLLlocation);
> >	      putenv (buf);
> >	      //SetEnvironmentVariable ("R_HOME",DLLlocation);
> >	      strcat (DLLlocation, "\\bin\\");
> >		  strcat (DLLlocation, RDLL);
> >		  OutputDebugString(DLLlocation);
> >	      m_ProxyModule = LoadLibraryEx (DLLlocation, NULL, 
> >					     LOAD_WITH_ALTERED_SEARCH_PATH);
> >	      if (m_ProxyModule == 0) {
> >		sprintf(lTraceBuffer,"Registry information said to load \"%s\", failed!\n",
> >		        DLLlocation);
> >		OutputDebugString(lTraceBuffer);
> >	      }
> >	    }
> >	  } //module==0
> >
> >	//m_ProxyModule = LoadLibraryEx ("C:\\R\\rw1070\\bin\\Rproxy.dll", NULL, 
> >	//				 LOAD_WITH_ALTERED_SEARCH_PATH);
> >
> >	
> >
> >      SC_PROXY_GET_OBJECT lFunc;
> >      
> >      lFunc = (SC_PROXY_GET_OBJECT) GetProcAddress (m_ProxyModule,
> >    						   SC_PROXY_GET_OBJECT_FUN);
> >	  
> >      
> >      if (lFunc == 0)
> >    	{
> >          return -1;
> >    	}
> >      
> >      // get proxy object
> >      ULONG lRc = lFunc (&m_ProxyObject,SC_PROXY_INTERFACE_VERSION);
> >      
> >	  
> >      if ((lRc != SC_PROXY_OK) || (m_ProxyObject == 0))
> >    	{
> >    	  FreeLibrary (m_ProxyModule);
> >    	  m_ProxyModule = 0;
> >    	  
> >          return -2;
> >    	}
> >      
> >      char* lParams = 0;
> >
> >	lParams = strdup ("");
> >	OutputDebugString("vtbl->init getting called:");         
> >      // init R
> >      lRc = m_ProxyObject->vtbl->init (m_ProxyObject,lParams);
> >	OutputDebugString("done init.");      
> >      free (lParams);
> >
> >      if (lRc != SC_PROXY_OK)
> >    	{
> >    	  m_ProxyObject->vtbl->release (m_ProxyObject);
> >    	  m_ProxyObject = 0;
> >    	  FreeLibrary (m_ProxyModule);
> >    	  m_ProxyModule = 0;
> >    	  
> >    	  return -3;
> >    	}
> >    return 1;
> >}
> >
> >int unloadDll()
> >{
> >
> >      m_ProxyObject->vtbl->release (m_ProxyObject);
> >	  m_ProxyObject = 0;
> >
> >	  DWORD err;
> >      int b = FreeLibrary (m_ProxyModule);
> >	  if (b==0) {
> >		  err = GetLastError();
> >		char ss[100];
> >		sprintf(ss,"\n\nErr = %d\n\n", err);
> >		OutputDebugString(ss);
> >		return -1;
> >	  } else OutputDebugString("no error unloading Rproxy dll.\n\n");
> >
> >	  m_ProxyModule = 0;
> >    
> >  return 1;
> >}
> >
> >
> >int main() {
> >	char ss[100];
> >	int i,x,a;
> >	for (i=1; i<=100; i++) {
> >		sprintf(ss,"Iteration: %d", i);
> >		OutputDebugString(ss);
> >	x=loadDll();
> >	if (x<=0) OutputDebugString("LoadLibraryEx ERROR.");
> >	else OutputDebugString("LoadLibraryEx succeeded.");
> >	a = unloadDll();
> >	if (a<=0) OutputDebugString("FreeLibrary ERROR.");
> >	else OutputDebugString("FreeLibrary succeeded.");
> >	}
> >}
> >
> >-----------------------------------------
> >
> >-Venkatesh Mysore
> >Bioinformatics Group,
> >New York University
> >
> >______________________________________________
> >R-devel@stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Thomas Baier

From pd at pubhealth.ku.dk  Wed May  7 08:15:03 2003
From: pd at pubhealth.ku.dk (Peter Dalgaard BSA)
Date: Wed May  7 08:40:40 2003
Subject: [Rd] Bug list summary (automatic post)
Message-ID: <200305070515.h475F36k026132@blueberry.kubism.ku.dk>

=================================================
This is an automated summary of the status of the R-bugs
repository.

Note that this may be neither complete nor perfectly
correct at any given instance: Not all bugs are reported,
and some reported bugs may have been fixed, but the
repository not yet updated.

Some bug fixes are difficult to verify because they pertain
to specific hardware or operating system versions. If you
have information to contribute, please do so.

If you happen to know how to fix a problem please send
patches to the bug repository, too.

New bugs are reported either through the web
interface at r-bugs.r-project.org or via email to
r-bugs@r-project.org. The bug.report() function can be
used to automate parts of the procedure on many systems.
Followups on older bugs can be done by including the string
"(PR#999)" in the Subject of an email (change 999 to the
actual reference number, of course!).
=================================================

Directory:  Accuracy

* PR# 1228 *
Subject: bug with var(rep(1e30, 3))
From: Emmanuel Paradis <paradis@isem.univ-montp2.fr>
Date: Wed, 26 Dec 2001 13:03:31 +0100
* PR# 1664 *
Subject: Bug in rnorm.
From: Rolf Turner <rolf@math.unb.ca>
Date: Thu, 13 Jun 2002 16:35:59 -0300 (ADT)
.Strange interaction between "Marsaglia-Multicarry" generator and
."Kinderman-Ramage" 
.method for normal variates. Apparently, switching either of them will help.
* PR# 2214 *
Subject: qgamma precision
From: terra@diku.dk
Date: Fri, 25 Oct 2002 16:50:17 +0200 (MET DST)

Directory:  Add-ons

* PR# 974 *
Subject: Lattice: panel.superpose with ordered factor groups
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sat, 9 Jun 2001 11:08:51 +1000 (EST)
.The warning is standard S and R behaviour.
.Probably xyplot needs to avoid it (by unclassing?)
.Still there in lattice 0.3-0, 0.6-8
* PR# 1361 *
Subject: Matrix identification bug
From: hyu@stats.uwo.ca
Date: Tue, 5 Mar 2002 21:19:46 +0100 (MET)
.seems to be about Matrix package, not solve
* PR# 1662 *
Subject: fisher.test FEXACT memory bug "should not occur"
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Thu, 13 Jun 2002 08:21:50 +0200
.The supplementary (table of sum one) is fixed for 1.5.1.
.Detection code for the first problem has been added to 1.5.1 which will stop
.the crash, but the underlying cause is still open.
* PR# 1729 *
Subject: problem with qq( )
From: Jarno.Tuimala@Helsinki.Fi
Date: Tue, 2 Jul 2002 10:37:10 +0200 (MET DST)
.A report on lattice
* PR# 1741 *
Subject: groupedData constructor from a function
From: dieter.menne@menne-biomed.de
Date: Thu, 4 Jul 2002 15:59:59 +0200 (MET DST)
* PR# 1972 *
Subject: lattice install
From: robert.king@newcastle.edu.au
Date: Mon, 2 Sep 2002 04:55:41 +0200 (MET DST)
.Perhaps lattice should require(grid) and print a clearer message?
* PR# 1974 *
Subject: Rwave installation problem
From: ld-temp-qt3i@pobox.com
Date: Mon, 2 Sep 2002 09:27:36 +0200 (MET DST)
.Instead, this should use ISO C headers, namely <stdlib.h>
* PR# 2173 *
Subject: xlim in plot.survfit() [with a discussion on "..."]
From: jerome@hivnet.ubc.ca
Date: Wed, 16 Oct 2002 18:46:11 +0200 (MET DST)
* PR# 2320 *
Subject: Segmentation fault using "survival" package
From: jerome@hivnet.ubc.ca
Date: Sat, 23 Nov 2002 00:51:50 +0100 (MET)
* PR# 2322 *
Subject: simplex
From: george@lecompte.org
Date: Sat, 23 Nov 2002 17:30:37 +0100 (MET)
.report on boot, I think (not mentioned, though)
* PR# 2352 *
Subject: avas: segmentation fault on empty args
From: vograno@arbitrade.com
Date: Fri, 6 Dec 2002 19:41:48 +0100 (MET)
* PR# 2363 *
Subject: nlme() and parameters "model", "fixed" and "random"
From: jerome@hivnet.ubc.ca
Date: Wed, 11 Dec 2002 22:29:47 +0100 (MET)
* PR# 2369 *
Subject: convergence problem with nlme()
From: jerome@hivnet.ubc.ca
Date: Thu, 12 Dec 2002 23:43:14 +0100 (MET)
* PR# 2374 *
Subject: quantreg package - predict method for rq objects
From: John Maindonald <u9801539@leonard.anu.edu.au>
Date: Sat, 14 Dec 2002 20:46:34 +1100 (EST)
* PR# 2384 *
Subject: degrees of freedom in nlme()
From: jerome@hivnet.ubc.ca
Date: Fri, 20 Dec 2002 01:40:06 +0100 (MET)
* PR# 2385 *
Subject: read.xport and lookup.xport in foreign
From: Frank E Harrell Jr <fharrell@virginia.edu>
Date: Fri, 20 Dec 2002 12:47:58 -0500
* PR# 2386 *
Subject: ace and avas in acepack
From: Frank E Harrell Jr <fharrell@virginia.edu>
Date: Fri, 20 Dec 2002 12:59:07 -0500
* PR# 2480 *
Subject: bug in CrossTable (package:gregmisc)
From: John_Hendrickx@yahoo.com
Date: Tue, 21 Jan 2003 13:51:01 +0100 (MET)
* PR# 2499 *
Subject: survival bug?
From: Pius Korner <korner@eco.umnw.ethz.ch>
Date: Mon, 27 Jan 2003 17:28:11 +0100
.Needs to resubmit in more useful format.
* PR# 2520 *
Subject: Apparent parser problem
From: "Jim Rogers" <jrogers@cantatapharm.com>
Date: Sat, 1 Feb 2003 16:51:41 -0500
.Its an ESS or XEmacs problem. I redirected him to ESS-bugs.
* PR# 2859 *
Subject: bug and proposed fix in print.trellis 1.7.0
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Sun, 27 Apr 2003 01:56:30 -0400
.Lattice
* PR# 2865 *
Subject: bug in y limits in bwplot
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Mon, 28 Apr 2003 02:19:53 -0400 (EDT)

Directory:  Analyses

none

Directory:  Documentation

* PR# 988 *
Subject: input for R-intro
From: "Paul E. Johnson" <pauljohn@ku.edu>
Date: Mon, 18 Jun 2001 13:57:10 -0500
* PR# 1011 *
Subject: R-intro suggestions part II
From: "Paul E. Johnson" <pauljohn@ukans.edu>
Date: Tue, 03 Jul 2001 15:50:06 -0500
* PR# 1772 *
Subject: bug(?) in R FAQ - Should I run R from within Emacs?
From: Tim.Harrold@csiro.au
Date: Thu, 11 Jul 2002 18:21:42 +1000
* PR# 2545 *
Subject: colSums etc. documentation
From: "Gunter, Bert" <bert_gunter@merck.com>
Date: Thu, 13 Feb 2003 09:08:44 -0500
* PR# 2794 *
Subject: prop.test  confidence intervals
From: rbaer@kcom.edu
Date: Fri, 18 Apr 2003 19:01:03 +0200 (MET DST)
.prop.test should say how it computes confidence intervals.
* PR# 2886 *
Subject: [ENH] Clarify rsync flavors
From: Ross Boylan <ross@biostat.ucsf.edu>
Date: Wed, 30 Apr 2003 11:15:02 -0700

Directory:  Graphics

* PR# 202 *
Subject: persp box occlusion bug
From: wsi@gcal.ac.uk
Date: Wed, 2 Jun 1999 15:02:03 +0200 (MET DST)
.The persp algorithm does not apply the occlusion rules to the frame, 
.which is always plotted first. 
.A bug, but not very simple to fix.
* PR# 660 *
Subject: identify.default ignores any setting of cex.
From: Prof Brian Ripley <ripley@stats.ox.ac.uk>
Date: Fri, 15 Sep 2000 10:23:39 +0100 (BST)
* PR# 776 *
Subject: strwidth does not take font into account
From: Martyn Plummer <plummer@iarc.fr>
Date: Tue, 19 Dec 2000 14:56:01 +0100 (CET)
.This needs a substantial redesign.
* PR# 791 *
Subject:  par(lab= *) / axis(*) bug 
From: maechler@stat.math.ethz.ch
Date: Fri, 22 Dec 2000 10:59:26 +0100
* PR# 816 *
Subject: dotplot: character size of labels
From: RINNER Heinrich <H.RINNER@TIROL.GV.AT>
Date: Thu, 18 Jan 2001 14:54:32 +0100
.Suggested fix is incorporated in 1.2.2.
.
.There is a deeper problem:  mtext() ignores par(cex=.5) in general.  
.To see the problem try:  par(cex=.5); mtext("hi")
.Paul thinks the right fix is to change the argument list for mtext so that
.cex=par(cex) by default rather than cex=NA by default (plus corresponding
.internal changes to  do_mtext in plot.c).
.This needs to be done very carefully because (i) the change suggested above 
.mayhave side-effects in many other pieces of interpreted code 
.(ii) do_mtext ignores dd->gp.cexbase unlike, for example, do_plot_xy 
.and anything to do with cexbase needs extreme care.
* PR# 831 *
Subject: screen can't go back to (split) screen with log="y" plot
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 30 Jan 2001 00:39:41 -0500
.Still there. Suggested fix included in followups, but we didn't get around to
.try it in time for 1.2.3.
.
.Fix doesn't work. One problem is that the opar<-par();par(opar) idiom updates
.xaxp before xlog, and the new value of xaxp may only be valid under the new
.value of xlog.
* PR# 837 *
Subject: screen doesn't handle redrawing properly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 01 Feb 2001 14:20:52 -0500
* PR# 887 *
Subject: axis(adj=anything) has no effect
From: jhallman@frb.gov
Date: Wed, 28 Mar 2001 20:51:05 +0200 (MET DST)
* PR# 943 *
Subject: legend() with xpd=T; omission of initial plot character
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sun, 20 May 2001 10:35:16 +1000
* PR# 997 *
Subject:  las=1 with log axis 
From: Peter Dalgaard BSA <pd@pubhealth.ku.dk>
Date: Wed, 27 Jun 2001 11:54:06 +0200
* PR# 1045 *
Subject: Palette changes on redraw
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 08 Aug 2001 19:08:01 +0200
* PR# 1147 *
Subject: postscript problem
From: kjetil halvorsen <kjetilh@umsanet.edu.bo>
Date: Fri, 26 Oct 2001 15:23:45 -0400
.This seems to be a problem with screen/layout rather than postscript.
* PR# 1161 *
Subject: x-axis label in persp()
From: Rolf Turner <rolf@maths.uwa.edu.au>
Date: Wed, 7 Nov 2001 18:07:22 +0800 (WST)
* PR# 1207 *
Subject: boxplot labels incorrect when horizontal = TRUE
From: Rashid Nassar <rnassar@duke.edu>
Date: Sun, 9 Dec 2001 21:46:32 -0500 (EST)
* PR# 1235 *
Subject: Axes labelling with logarithmic scales
From: tobias.hoevekamp@ilw.agrl.ethz.ch
Date: Thu, 3 Jan 2002 15:29:02 +0100 (MET)
* PR# 1300 *
Subject: FW: layout and piechart diameter problem
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Thu, 7 Feb 2002 11:05:15 -0500 
* PR# 1395 *
Subject: mgp parameter in par()
From: mh.smith@niwa.cri.nz
Date: Tue, 19 Mar 2002 06:11:49 +0100 (MET)
* PR# 1476 *
Subject: Bug: persp and colors
From: oliver.niggemann@acterna.com
Date: Tue, 23 Apr 2002 09:41:37 +0200 (MET DST)
* PR# 1505 *
Subject: pictex 
From: luchini@ehess.cnrs-mrs.fr
Date: Thu, 2 May 2002 12:23:21 +0200 (MET DST)
* PR# 1653 *
Subject: coplot behaviour
From: "RenE J.V. Bertin" <rjvbertin@hotmail.com>
Date: Mon, 10 Jun 2002 20:11:02 +0200
* PR# 1654 *
Subject: R 1.5.0: axis() does not honor the xaxp argument
From: "Robert D. Merithew" <merithew@ccmr.cornell.edu>
Date: Tue, 11 Jun 2002 09:29:39 -0400 (EDT)
* PR# 1659 *
Subject:  mtext() alignment of perpendicular text 
From: p.murrell@auckland.ac.nz
Date: Wed, 12 Jun 2002 13:29:45 +1200 (NZST)
* PR# 1878 *
Subject: close.screen
From: Martin.Schlather@uni-bayreuth.de
Date: Mon, 5 Aug 2002 22:35:02 +0200 (MET DST)
* PR# 1933 *
Subject: dev2eps() prints ticks with wrong length!
From: Timur Elzhov <Timur.Elzhov@jinr.ru>
Date: Fri, 23 Aug 2002 17:22:15 +0400
.dev.copy problem
* PR# 2069 *
Subject: split.screen problem
From: cbodily@att.net
Date: Thu, 26 Sep 2002 19:37:40 +0200 (MET DST)
* PR# 2283 *
Subject: Wandering usr values in par(no.readonly=TRUW)
From: Jari Oksanen <jarioksa@sun3.oulu.fi>
Date: Tue, 12 Nov 2002 13:50:44 +0200
* PR# 2578 *
Subject: "trace" argument in legend()
From: jerome@hivnet.ubc.ca
Date: Mon, 24 Feb 2003 18:53:29 +0100 (MET)
* PR# 2628 *
Subject: cex.axis in boxplot
From: Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de>
Date: Wed, 12 Mar 2003 17:27:34 +0100 (CET)
* PR# 2630 *
Subject: plot() with type="s" and lty=2
From: jerome@hivnet.ubc.ca
Date: Wed, 12 Mar 2003 23:35:59 +0100 (MET)

Directory:  In-Out

* PR# 1688 *
Subject: Maybe a problem in binary read/write
From: accot@free.fr
Date: Tue, 18 Jun 2002 22:51:17 +0200 (MET DST)
.I don't think file() is said to work with devices!

Directory:  Installation

* PR# 1222 *
Subject: configure: sed: Function s%@PDFLATEX@%/usr/local/bin/pdflatex%g
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Thu, 20 Dec 2001 14:09:42 +0100 (CET)
.problem is on hppa2.0-hp-hpux10.20: may be HP-UX specific
* PR# 1268 *
Subject: Solaris 2.6 Compile
From: gm81640@development.nssmb.com
Date: Thu, 17 Jan 2002 06:28:26 +0100 (MET)
.Most likely a compiler installation problem
* PR# 1291 *
Subject: Installation problem : SunOS
From: brendan_mcmahon@prusec.com
Date: Thu, 31 Jan 2002 18:00:55 +0100 (MET)
.looks like gcc compiled under different OS version.
* PR# 1500 *
Subject: configure script fails on comment in tkConfig.sh
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Tue, 30 Apr 2002 16:41:51 +0200 (CEST)
.Looks like a conspiracy between a shell problem and an oddity in Tk 8.0 rather
.than an R problem. Good to know for the workaround though. The comment in
.TK_XINCLUDES has since disappeared, at least in Tk 8.3.3.
* PR# 1658 *
Subject: make install fails - index.html not found
From: dhouston@bio.ri.ccf.org
Date: Tue, 11 Jun 2002 22:14:07 +0200 (MET DST)
.Missing perl??
* PR# 1676 *
Subject: R configure.in makes bad alpha assumptions
From: mcmahill@mtl.mit.edu
Date: Sat, 15 Jun 2002 19:21:09 -0400 (EDT)
.Probably fixed in 1.5.1
* PR# 1825 *
Subject: bug in R-1.5.1 for Mac OS X installer
From: Kow Kuroda <kkuroda@crl.ucsd.edu>
Date: Mon, 22 Jul 2002 16:40:26 -0700
.Darwin port
* PR# 1829 *
Subject: R config failure on solaris
From: "Siva Ginjupalli" <gsivrao@hotmail.com>
Date: Wed, 24 Jul 2002 20:08:49 +0000
.Missing info on R version and compilers.

Directory:  Language

* PR# 408 *
Subject: convolution bug
From: wsimpson@gcal.ac.uk
Date: Fri, 28 Jan 2000 11:17:36 +0100 (MET)
* PR# 412 *
Subject: anomalies with call objects
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 06 Feb 2000 01:18:50 +0100
* PR# 669 *
Subject: Bug(s) w/ rbind.data.frame(); fix also read.table(*, as.is = TRUE) ?
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Mon, 25 Sep 2000 10:17:15 +0200
.status of AsIs columns
* PR# 1073 *
Subject: Wierd problem comparing numeric values and list using ==
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Fri, 24 Aug 2001 22:07:41 -0400
.see also PR#1075
* PR# 1076 *
Subject: Re: [Rd] Wierd problem comparing numeric values and list using == 
From: John Chambers <jmc@research.bell-labs.com>
Date: Mon, 27 Aug 2001 08:44:22 -0400
.part of PR#1073
* PR# 1186 *
Subject: a patch to tapply
From: Vadim Ogranovich <vograno@arbitrade.com>
Date: Thu, 29 Nov 2001 14:48:35 -0600
* PR# 1214 *
Subject: syntax questtion, maybe a bug
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Thu, 13 Dec 2001 13:46:54 -0500 (EST)
.Is .2logl meant to be a valid name in R? It is S
* PR# 1241 *
Subject:  Problem with "missing" in "local" 
From: J.C.Rougier@durham.ac.uk
Date: Fri, 4 Jan 2002 13:34:34 GMT
* PR# 1556 *
Subject: lib.fixup, .GlobalEnv, and R1.5.0
From: mark.bravington@csiro.au
Date: Wed, 15 May 2002 08:30:50 +0200 (MET DST)

Directory:  Low-level

* PR# 989 *
Subject: "[.data.frame" allows un-named 3rd subscript
From: "Charles C. Berry" <cberry@tajo.ucsd.edu>
Date: Mon, 18 Jun 2001 13:13:46 -0700 (PDT)
* PR# 1068 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: Luke Tierney <luke@nokomis.stat.umn.edu>
Date: Wed, 22 Aug 2001 19:32:51 -0500
.see also followup in PR#1069
* PR# 1069 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: "John W. Eaton" <jwe@bevo.che.wisc.edu>
Date: Wed, 22 Aug 2001 21:56:33 -0500
.part of PR#1068
* PR# 1880 *
Subject:  You requested this report 
From: Berwin Turlach <berwin@maths.uwa.edu.au>
Date: Tue, 6 Aug 2002 16:57:54 +0800
.The bug is that we get as far as mkCLOSXP before an error is reported
* PR# 2253 *
Subject: [R] CTRL-C suspends echo of shell (R versions 1.6.0 and 1.6.1)
From: Wolfram Fischer - Z/I/M <wolfram@fischer-zim.ch>
Date: Mon, 4 Nov 2002 10:18:48 +0100
* PR# 2846 *
Subject: Kinderman-Ramage
From: Josef Leydold <leydold@statistik.wu-wien.ac.at>
Date: Fri, 25 Apr 2003 13:18:53 +0200 (CEST)

Directory:  Macintosh

* PR# 1819 *
Subject: Date arithmetic fails
From: RML27@cornell.edu
Date: Sun, 21 Jul 2002 20:26:12 +0200 (MET DST)
.In fact, as.POSIXct is off by 66 years. See
.   http://developer.apple.com/qa/ops/ops23.html
.This is semifixed, but timezones still don't work
* PR# 1991 *
Subject: Mac Save As... bug
From: Tim Cole <tjc1@cam.ac.uk>
Date: Sun, 8 Sep 2002 13:47:00 +0100
* PR# 2276 *
Subject: Mac specific - quartz leads to crash
From: h95mr@mun.ca
Date: Fri, 8 Nov 2002 16:28:50 +0100 (MET)
* PR# 2550 *
Subject: eigen() error: R Version 1.6.1 on Mac OS X
From: "Daniel E. Weeks" <dweeks@watson.hgen.pitt.edu>
Date: Fri, 14 Feb 2003 15:36:15 -0500
* PR# 2725 *
Subject: Default broswer for OS X
From: james@freelancepropaganda.com
Date: Fri, 4 Apr 2003 06:04:48 +0200 (MET DST)
* PR# 2813 *
Subject: Search Engine
From: leroy@ucsd.edu
Date: Tue, 22 Apr 2003 06:21:19 +0200 (MET DST)
* PR# 2875 *
Subject: configure succeeds without dlfcn.h, but fails to compile (OS X)
From: buerkla@uwec.edu
Date: Tue, 29 Apr 2003 20:24:12 +0200 (MET DST)

Directory:  Misc

* PR# 1126 *
Subject: R-bug report www page whishlist
From: jens.lund@nordea.com
Date: Wed, 10 Oct 2001 18:24:29 +0200 (MET DST)
* PR# 1158 *
Subject: bug.report()sends empty message
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Mon, 05 Nov 2001 10:05:27 -0500
* PR# 1503 *
Subject: R-GNOME
From: Patrick Gonin <gonin@genethon.fr>
Date: Thu, 2 May 2002 09:29:07 +0200
.1) is not a bug, as jpeg etc work.  capabilities() has been changed for 1.5.1
.2) system() needs a new version for GNOME.
* PR# 2644 *
Subject: R CMD SHLIB uses foo.c instead of foo.cc if both are present
From: faheem@email.unc.edu
Date: Sun, 16 Mar 2003 19:47:55 +0100 (MET)
* PR# 2645 *
Subject: Re: [Rd] R CMD SHLIB uses foo.c instead of foo.cc if both are present
From: Faheem Mitha <faheem@email.unc.edu>
Date: Sun, 16 Mar 2003 15:44:14 -0500 (EST)
.part of 2644
* PR# 2648 *
Subject: Re: [Rd] R CMD SHLIB uses foo.c instead of foo.cc if both are present
From: Kurt Hornik <hornik@ci.tuwien.ac.at>
Date: Mon, 17 Mar 2003 21:32:55 +0100
.part of 2644

Directory:  Models

* PR# 1861 *
Subject: update() can not find objects
From: yzhou@arcturusag.com
Date: Thu, 1 Aug 2002 19:01:59 +0200 (MET DST)
.The problem is actually deeper than this.
.
.Sometime update() wants to evaluate arguments in the environment where the model
.was defined, as here. 
.
.Sometimes it wants to use the current environment, eg this snippet from MASS 
.ph.fun <- function(data, i) {
.  d <- data
.  d$calls <- d$fitted + d$res[i]
.  coef(update(fit, data=d))
.}

Directory:  Startup

none

Directory:  System-specific

* PR# 848 *
Subject: X11 device doesn't handle destroy events correcly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 13 Feb 2001 17:40:46 -0500
* PR# 1020 *
Subject: .Call and Mandrake 8.0
From: lcottret@yahoo.fr
Date: Wed, 11 Jul 2001 15:34:23 +0200 (MET DST)
.problem with symbol names only on Mandrake 8.0, not 7.2
.needs reply to follow-up
* PR# 1097 *
Subject: R 1.3.1 fails 'make check' on arm in the Bessel example
From: Dirk Eddelbuettel <edd@debian.org>
Date: Thu, 20 Sep 2001 23:54:19 -0500
.This platform turned out to have badly broken FPU behaviour. Given up, at 
.least for now .
* PR# 1140 *
Subject: Possible bug, Rprof() and scan(pipe())
From: Don MacQueen <macq@llnl.gov>
Date: Tue, 23 Oct 2001 13:50:26 -0700
.MacOS X: Doesn't happen on Solaris or Linux
* PR# 1261 *
Subject: R_140 AND RHL_72 AND Packages
From: Patrick Gonin <gonin@genethon.fr>
Date: Wed, 15 Jan 2003 13:25:17 +0100
.Seems to relate to RH7.2 rpms
* PR# 1272 *
Subject: eigen segfault with GCC 3 on Solaris
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Thu, 17 Jan 2002 15:14:33 -0500
.Seems to be a problem with g77 in gcc 3.0.2 on Solaris only.
.Probably a compiler bug
* PR# 1275 *
Subject: compile problem with bessel_i.c on IRIX64 flexor 6.5 10100655 IP35 (uname -a)
From: Walter Tautz <wtautz@math.uwaterloo.ca>
Date: Tue, 22 Jan 2002 10:05:20 -0500 (EST)
* PR# 1289 *
Subject: R 1.4.0 build fails on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Wed, 30 Jan 2002 14:10:30 +0100 (MET)
* PR# 1316 *
Subject: shared libraries on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Mon, 18 Feb 2002 18:53:41 +0100 (MET)
* PR# 1461 *
Subject: make check fails d-p-q-r-tests.R - OpenBSD 3.0
From: Jason Turner <jasont@indigoindustrial.co.nz>
Date: Mon, 15 Apr 2002 10:13:36 +0000
* PR# 1606 *
Subject: hitting ^C breaks readline history
From: Cyril Humbert <humbertc@univ-mlv.fr>
Date: Tue, 28 May 2002 12:07:07 +0200 (MET DST)
* PR# 2730 *
Subject: Re: Bug#187537: r-base: FTBFS: hangs in tcltk test
From: Dirk Eddelbuettel <edd@debian.org>
Date: Fri, 4 Apr 2003 06:27:15 -0600
.something obscure in debian: pbuilder is not part of R
* PR# 2733 *
Subject: Re: Bug#187537: r-base: FTBFS: hangs in tcltk test
From: Daniel Schepler <schepler@math.berkeley.edu>
Date: 05 Apr 2003 14:06:09 -0800
.part of 2730
* PR# 2736 *
Subject: Re: Bug#187537: r-base: FTBFS: hangs in tcltk test
From: Dirk Eddelbuettel <edd@debian.org>
Date: Sun, 6 Apr 2003 21:20:29 -0500
.part of 2730
* PR# 2836 *
Subject: R-1.7.0: build feedback: OpenBSD 3.2
From: "Nelson H. F. Beebe" <beebe@math.utah.edu>
Date: Thu, 24 Apr 2003 11:40:35 -0600 (MDT)
* PR# 2837 *
Subject: R-1.7.0 build feedback: NetBSD 1.6
From: "Nelson H. F. Beebe" <beebe@math.utah.edu>
Date: Thu, 24 Apr 2003 11:45:20 -0600 (MDT)
* PR# 2887 *
Subject: tools/ldAIX4 Assumes AIX nm
From: rgrubbfink@cox.net
Date: Wed, 30 Apr 2003 22:24:34 +0200 (MET DST)
* PR# 2888 *
Subject: AIX 4.3.3 nm will not read all of dounzip.o
From: rgrubbfink@cox.net
Date: Wed, 30 Apr 2003 22:33:24 +0200 (MET DST)
* PR# 2893 *
Subject: ldAIX4 does not generate Rlapack.exp
From: rgrubbfink@cox.net
Date: Thu, 1 May 2003 21:20:40 +0200 (MET DST)

Directory:  TooMuchAtOnce

none

Directory:  Windows

* PR# 1711 *
Subject: GUI bug
From: socrates@mail.ru
Date: Thu, 27 Jun 2002 10:30:51 +0200 (MET DST)
.A crash that is *very* hard to trigger (after several
.minutes of continuous resizing)
* PR# 2798 *
Subject: Re: [R] Keyboard problem using RWin 1.7.0
From: DJNordlund@aol.com
Date: Sat, 19 Apr 2003 18:56:25 EDT
.Can't reproduce so far.

Directory:  incoming

* PR# 2461 *
Subject: apropos() with partial name
From: John Maindonald <u9801539@leonard.anu.edu.au>
Date: Thu, 16 Jan 2003 20:22:23 +1100 (EST)
.The proposed fix would make it impossible to pass a variable to apropos
.
.eg 
.
.> sor<-"plot"
.> apropos(sor)
.[1] "sor"          "isoreg"       "sortedXyData" "is.unsorted"  "sort"        
.[6] "sort.list"   
.
.A better fix might be to require the argument to be a string.
* PR# 2577 *
Subject: Problem with hessian in deriv3 
From: j.c.rougier@durham.ac.uk
Date: Mon, 24 Feb 2003 17:01:47 GMT
* PR# 2593 *
Subject: density(), with argument of length 1
From: John Maindonald <u9801539@leonard.anu.edu.au>
Date: Sat, 1 Mar 2003 16:35:56 +1100 (EST)
* PR# 2656 *
Subject: recursive default argument reference in debugger
From: pburns@pburns.seanet.com
Date: Wed, 19 Mar 2003 12:23:40 +0100 (MET)
* PR# 2808 *
Subject: building R 1.7.0 under RH7.3
From: Tim Hoar <thoar@cgd.ucar.edu>
Date: Mon, 21 Apr 2003 13:16:16 -0600 (MDT)
* PR# 2809 *
Subject: sweave provoked segfault
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Mon, 21 Apr 2003 17:01:53 -0400
* PR# 2822 *
Subject: "LAPACK routine DGESDD gave error code -12" with Debian
From: Ramon Diaz <rdiaz@cnio.es>
Date: Tue, 22 Apr 2003 20:06:21 +0200
* PR# 2823 *
Subject: Re: [Rd] 
From: Kurt Hornik <hornik@ci.tuwien.ac.at>
Date: Tue, 22 Apr 2003 20:15:19 +0200
.part of 2822
* PR# 2824 *
Subject: coplot panels malrendered / 1653
From: dmaszle@mendelbio.com
Date: Wed, 23 Apr 2003 02:19:53 +0200 (MET DST)
* PR# 2872 *
Subject: Rprofile.site and check/build
From: Laurent Gautier <laurent@cbs.dtu.dk>
Date: Tue, 29 Apr 2003 08:03:35 +0200
* PR# 2876 *
Subject: Re: [Rd]  configure succeeds without dlfcn.h, but fails to compile
From: Thomas Lumley <tlumley@u.washington.edu>
Date: Tue, 29 Apr 2003 13:02:25 -0700 (PDT)
* PR# 2878 *
Subject: Problem with R CMD INSTALL and package versions
From: rpeng@stat.ucla.edu
Date: Wed, 30 Apr 2003 08:23:12 +0200 (MET DST)
* PR# 2880 *
Subject: return(1, ) results in subsequent segfault
From: Uwe Ligges <ligges@statistik.uni-dortmund.de>
Date: Wed, 30 Apr 2003 15:52:35 +0200
* PR# 2884 *
Subject: make check failures
From: Ross Boylan <ross@biostat.ucsf.edu>
Date: Wed, 30 Apr 2003 11:05:37 -0700
* PR# 2894 *
Subject: qbeta hang
From: terra@gnome.org
Date: Thu, 1 May 2003 22:43:59 +0200 (MET DST)
* PR# 2914 *
Subject: R-1.7.0: Rproxy.dll loadlibrary/freelibrary error
From: mpvenkatesh@lycos.com
Date: Mon, 5 May 2003 01:07:29 +0200 (MET DST)
* PR# 2923 *
Subject: segfault when applying strange coercion
From: Uwe Ligges <ligges@statistik.uni-dortmund.de>
Date: Mon, 05 May 2003 19:36:01 +0200
* PR# 2924 *
Subject: prcomp need Conj(t(s$vt))
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Mon, 05 May 2003 14:12:59 -0400
* PR# 2933 *
Subject: frailty models in survreg() -- survival package
From: Jerome Asselin <jerome@hivnet.ubc.ca>
Date: Tue, 6 May 2003 15:36:23 -0700
* PR# 2934 *
Subject: Re: frailty models in survreg() -- survival package
From: Thomas Lumley <tlumley@u.washington.edu>
Date: Tue, 6 May 2003 15:58:37 -0700 (PDT)

From dmurdoch at pair.com  Wed May  7 07:50:19 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed May  7 12:50:36 2003
Subject: [Rd] R-1.7.0: Rproxy.dll loadlibrary/freelibrary error (PR#2914)
In-Reply-To: <200305070614.h476EKnn000717@luthien.ci.tuwien.ac.at>
References: <2kdfbv4g3k9gl5fle6dm1rmpgr39csmc37@4ax.com>
	<200305070614.h476EKnn000717@luthien.ci.tuwien.ac.at>
Message-ID: <0tohbv8aena3vi8gujkf1t180d12d4tdbp@4ax.com>

On Wed, 7 May 2003 08:14:20 +0200 (CEST), you wrote:

>The question to Duncan now is if you are aware of any resources which can/should
>be freed by rproxy.dll or by R. Anything we can do about it.

I don't know of any intentional resource allocation changes between
1.6.2 and 1.7.0, but it's always possible other changes had bad side
effects.

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Wed May  7 11:54:17 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed May  7 12:54:19 2003
Subject: [Rd] Problems building R-1.7.0 on windows XP
In-Reply-To: <mengbvsd6tgi54cgr2672agv8sst98uvis@4ax.com>
References: <3EB820FC.23322.1239E2C@localhost>
	<mengbvsd6tgi54cgr2672agv8sst98uvis@4ax.com>
Message-ID: <x2u1c7dnwn.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> 
> If I were going to guess at the reason, I'd guess you have a different
> version of find in your path ahead of the R tools one (mine gives
> English error messages), or you have something on your system that
> makes it think it's talking Spanish, so perhaps "-name", "-prune" and
> "-exec" need to be translated too.

Could it not more likely be picking up the system "find"? The one of
MSDOS heritage and having a completely different syntax.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From pgilbert at bank-banque-canada.ca  Wed May  7 10:54:50 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed May  7 15:56:52 2003
Subject: [Rd] prcomp need Conj(t(s$vt)) (PR#2924) 
Message-ID: <3EB9102A.1A868B9B@bank-banque-canada.ca>

>On Mon, 5 May 2003 pgilbert at bank-banque-canada.ca wrote:

>> In prcomp
>> 
>>         s <- La.svd(x, nu = 0)
>>         s$v <- t(s$vt)
>> 
>> the second above line should be 
>> 
>>         s$v <- Conj(t(s$vt))
>> 
>> (to cover complex cases).

On Mon, 5 May 2003 Prof. Brian Ripley wrote:

>They are not covered in the help page, AFAICS.

>They are certainly not covered in the references quoted.

>Are you not jumping to conclusions?  There is a lot of R that does not 
>handle complex cases, and does not say so. (lm, for one.)

Sorry for the delay, I seem to be experiencing some mail problems.

The prcomp documentation says "matrix" and does not say that the complex case is
not handle but, as you say, there may be many instances of this in R. It says
that prcomp uses La.svd, for which the documentation does mention the complex
case. More importantly, prcomp() now fails in the complex case by return the
wrong answer. I think it should either fail with an error message or return the
correct answer. (And I think the only change required to return the correct
answer is that mentioned above.)

Paul Gilbert

From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed May  7 17:57:58 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed May  7 16:58:08 2003
Subject: [Rd] contrasts
In-Reply-To: <200305060843.h468hb2b021295@pubhealth.ku.dk>
References: <200305060843.h468hb2b021295@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.51.0305071649330.28422@artemis.imbe.med.uni-erlangen.de>


Hi,

I spent some time now trying to understand how functions for the
computation of contrasts

contr.foo(n, contrasts=TRUE)

passed to model.matrix are called. My problem is
that for the computation of some contrasts one needs `n' to be the number
of observations at each level of the factor of interest and for others the
number of levels is sufficient. For example, `contr.treatment' has code
for handling vector valued `n' (and ?contrasts states that `n' may be a vector).

Where can I find the condition under which `n = nlevel(x)' or `n =
table(x)' or how can I define what I would like to see?

Best,

Torsten

From ripley at stats.ox.ac.uk  Wed May  7 17:12:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed May  7 17:12:50 2003
Subject: [Rd] contrasts
In-Reply-To: <Pine.LNX.4.51.0305071649330.28422@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.LNX.4.44.0305071609340.5546-100000@gannet.stats>

On Wed, 7 May 2003, Torsten Hothorn wrote:

> I spent some time now trying to understand how functions for the
> computation of contrasts
> 
> contr.foo(n, contrasts=TRUE)
> 
> passed to model.matrix are called. My problem is
> that for the computation of some contrasts one needs `n' to be the number
> of observations at each level of the factor of interest and for others the
> number of levels is sufficient. For example, `contr.treatment' has code
> for handling vector valued `n' (and ?contrasts states that `n' may be a vector).
> 
> Where can I find the condition under which `n = nlevel(x)' or `n =
> table(x)' or how can I define what I would like to see?

>From model.matrix, only the number of levels is passed: src/main/model.c 
line 1626 (in R-devel and probably also 1.7.0).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Wed May  7 20:16:49 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed May  7 21:16:52 2003
Subject: [Rd] Kinderman-Ramage (PR#2846)
In-Reply-To: <200304251119.h3PBJ4pD015872@pubhealth.ku.dk>
References: <200304251119.h3PBJ4pD015872@pubhealth.ku.dk>
Message-ID: <x2fznqwok6.fsf@biostat.ku.dk>

leydold@statistik.wu-wien.ac.at writes:

> Hi,
> 
> Our department has detected a bug in the implementation of the
> Kinderman-Ramage generator for normal random variates in version
> 1.7.0, which can be seen from the below R session.
> (Consecutive calls for chisq.test(...) always gives p-values very
> close to 0.)
> We have already encountered this bug in version 1.6.2

Josef, I'm in the process of implementing your fixes, but while they
certainly improve things, I'm still seeing anomalies. Could you try
this (it takes a while, even on a fast machine)

m <- sapply(1:200,function(i)table(trunc(100*pnorm(rnorm(1e6)))))
plot(rowMeans(m), type="l")

and tell me if you see a double peak in the middle? It's only about
1.3% off-target, but given the accuracy of the constants in the
routine, it does seem a bit more than you should expect. I see the
same effect both with the Mersenne-Twister and with the Wichmann-Hill
uniform generators.

 
> The error is in file 
> R-1.7.0/src/nmath/snorm.c
> 
> Here is a patch for this file to correct the error
> (the added two lines are crucial):
> 
> --- R-1.7.0/src/nmath/snorm.c	Wed Feb 26 16:51:17 2003
> +++ snorm.c	Fri Apr 25 09:22:28 2003
> @@ -197,7 +197,9 @@
>  	u1 = unif_rand();
>  	if(u1 < 0.884070402298758) {
>  	    u2 = unif_rand();
> -	    return A*(1.13113163544180*u1+u2-1);
> +	    /** <modified constant> **/
> +	    return A*(1.131131635444180*u1+u2-1);
> +	    /** </modified> **/
>  	}
>  	
>  	if(u1 >= 0.973310954173898) { /* tail: */
> @@ -241,6 +243,10 @@
>  	    tt = 0.479727404222441-0.595507138015940*fmin2(u2,u3);
>  	    if(fmax2(u2,u3) <= 0.805577924423817)
>  		return (u2<u3) ? tt : -tt;
> +	    /** <added> **/
> +	    if(0.053377549506886*fabs(u2-u3) <= g(tt))
> +	      return (u2<u3) ? tt : -tt;
> +	    /** </added> **/
>  	}
>      case BOX_MULLER:
>  	if(BM_norm_keep != 0.0) { /* An exact test is intentional */
> 
> 
> 
> ----------------------------------------------------------
> 
> $ uname -a
> Linux 2.4.18-3 #1 Thu Apr 18 07:37:53 EDT 2002 i686 unknown
> 
> $ R
> R : Copyright 2003, The R Development Core Team
> Version 1.7.0  (2003-04-16)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type `license()' or `licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type `contributors()' for more information.
> 
> Type `demo()' for some demos, `help()' for on-line help, or
> `help.start()' for a HTML browser interface to help.
> Type `q()' to quit R.
> 
> > RNGkind(normal.kind="Kinderman-Ramage")
> > chisq.test(table(trunc(100*pnorm(rnorm(1e6)))))
> 
>         Chi-squared test for given probabilities
> 
> data:  table(trunc(100 * pnorm(rnorm(1e+06)))) 
> X-squared = 204.1378, df = 99, p-value = 2.746e-09
> 
> 
> Josef
> 
> --
> 
> -----------------------------------------------------------------------------
> Josef Leydold     |     University of Economics and Business Administration
>                   |     Department for Applied Statistics and Data Processing
> -----------------------------------------------------------------------------
> Augasse 2-6       |     Tel.   *43/1/31336-4695
> A-1090 Vienna     |     FAX    *43/1/31336-738
> European Union    |     email  Josef.Leydold@statistik.wu-wien.ac.at
> -----------------------------------------------------------------------------
> Alles Unglueck kam daher, dass die Denkenden nicht mehr handeln konnten,
> und die Handelnden keine Zeit mehr fanden zu denken.       (Marlen Haushofer)
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu May  8 10:17:50 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu May  8 09:18:01 2003
Subject: [Rd] contrasts
In-Reply-To: <Pine.LNX.4.44.0305071609340.5546-100000@gannet.stats>
References: <Pine.LNX.4.44.0305071609340.5546-100000@gannet.stats>
Message-ID: <Pine.LNX.4.51.0305080913080.16342@artemis.imbe.med.uni-erlangen.de>


> On Wed, 7 May 2003, Torsten Hothorn wrote:
>
> > I spent some time now trying to understand how functions for the
> > computation of contrasts
> >
> > contr.foo(n, contrasts=TRUE)
> >
> > passed to model.matrix are called. My problem is
> > that for the computation of some contrasts one needs `n' to be the number
> > of observations at each level of the factor of interest and for others the
> > number of levels is sufficient. For example, `contr.treatment' has code
> > for handling vector valued `n' (and ?contrasts states that `n' may be a vector).
> >
> > Where can I find the condition under which `n = nlevel(x)' or `n =
> > table(x)' or how can I define what I would like to see?
>
> >From model.matrix, only the number of levels is passed: src/main/model.c
> line 1626 (in R-devel and probably also 1.7.0).

Thank you! Therefore one cannot compute contrasts that depend on
the number of observations at each level, right? Looking at the code in
`contr.treatment' that handles this case: may I conclude that this is on
the wishlist?

Torsten

>
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

From ripley at stats.ox.ac.uk  Thu May  8 09:44:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu May  8 09:45:09 2003
Subject: [Rd] contrasts
In-Reply-To: <Pine.LNX.4.51.0305080913080.16342@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.LNX.4.44.0305080833460.18345-100000@gannet.stats>

On Thu, 8 May 2003, Torsten Hothorn wrote:

> 
> > On Wed, 7 May 2003, Torsten Hothorn wrote:
> >
> > > I spent some time now trying to understand how functions for the
> > > computation of contrasts
> > >
> > > contr.foo(n, contrasts=TRUE)
> > >
> > > passed to model.matrix are called. My problem is
> > > that for the computation of some contrasts one needs `n' to be the number
> > > of observations at each level of the factor of interest and for others the
> > > number of levels is sufficient. For example, `contr.treatment' has code
> > > for handling vector valued `n' (and ?contrasts states that `n' may be a vector).
> > >
> > > Where can I find the condition under which `n = nlevel(x)' or `n =
> > > table(x)' or how can I define what I would like to see?

BTW, I don't think contr.treatment does this.  It is documented to take 
either the set of levels or the number of levels, not a table of counts: 
it is coincidental that it works with the latter since it only looks at 
the length.

> > >From model.matrix, only the number of levels is passed: src/main/model.c
> > line 1626 (in R-devel and probably also 1.7.0).
> 
> Thank you! Therefore one cannot compute contrasts that depend on
> the number of observations at each level, right? Looking at the code in
> `contr.treatment' that handles this case: may I conclude that this is on
> the wishlist?

But you can, just not from inside model.matrix.  Contrast functions have
other uses, including computing contrast matrices to pass to model-fitting
functions via a `contrasts.arg' or 'contrasts' argument.

I don't think altering model.matrix is on anyone's wishlist (look at the C
code if you need dissuading), and it could only assume a minimal spec for
the contrast functions supplied: there are several user-written ones out
there.  E.g. contr.sdif (MASS) will not give sensible labels when supplied
a table of counts.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Thu May  8 08:46:16 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu May  8 09:46:17 2003
Subject: [Rd] contrasts
In-Reply-To: <Pine.LNX.4.51.0305080913080.16342@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.44.0305071609340.5546-100000@gannet.stats>
	<Pine.LNX.4.51.0305080913080.16342@artemis.imbe.med.uni-erlangen.de>
Message-ID: <x2brydx4fb.fsf@biostat.ku.dk>

Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de> writes:

> > >From model.matrix, only the number of levels is passed: src/main/model.c
> > line 1626 (in R-devel and probably also 1.7.0).
> 
> Thank you! Therefore one cannot compute contrasts that depend on
> the number of observations at each level, right? Looking at the code in
> `contr.treatment' that handles this case: may I conclude that this is on
> the wishlist?

That's not what it does. It just allows you to give the vector of
levels instead of the count. At the moment, this seems to be used only
for labeling:

> contr.treatment(4:1)
  3 2 1
4 0 0 0
3 1 0 0
2 0 1 0
1 0 0 1

Notice that C() allows a matrix argument, so even if model.matrix
doesn't use this feature, you could still use y~C(g,contr.xxx(levs))
in modeling.

One place where something like this might be useful, but (one of my
ancient gripes) isn't, is for generating polynomial contrasts over a
non-equidistant level set. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From arronfletcher at cityallstar.de.vu  Thu May  8 10:58:41 2003
From: arronfletcher at cityallstar.de.vu (arronfletcher@cityallstar.de.vu)
Date: Thu May  8 09:58:54 2003
Subject: [Rd] New Mortgage Leads available (PR#2952)
Message-ID: <200305080758.h487wf2b014582@pubhealth.ku.dk>

PEhUTUw+PGJvZHkgYmdjb2xvcj0iIzY2NjY5OSI+DQo8Y2VudGVyPjx0YWJs
ZSBib3JkZXI9MT4NCjx0cj48dGQgYWxpZ249Y2VudGVyIHdpZHRoPTYwMCBi
Z2NvbG9yPXdoaXRlPg0KPEZPTlQgU0laRT0zIEZBQ0U9ImFyaWFsIj4NCjxo
Mj48QSBIUkVGPSJodHRwOi8vdyU3N3cubCU2ZndlJTczJTc0JTcyJTQxJTc0
ZXMlNjElNTIlNEYlNTUlNGUlNDQubmV0L2luZCU2NSU3OC4lNzBocD8lNjE9
JTZGJTc4eSU2N2UlNkUiPkY8S0NKPnI8WVg+ZWUgPFpJPk08Wj5vcjxXUT50
Z+BnPFdCPmUgUXVvPFpEPnQ8WT5lLjwvQT48L2gyPg0KPGltZyBzcmM9Imh0
dHA6Ly8lNTclNzd3LmlsJTY1JTYxZHMlNEYlNTVyJTQzZS5jbyU0ZC9pJTZk
JTYxJTY3JTY1cy9waG90JTZmMS4lNkFwZyIgYWxpZ249cmlnaHQ+DQpUaGVy
ZSBhcmUgb3ZlciA4NiwwMDAgbfNydDxYPmdhPEtNUEo+Z2UgY29tcGFuaWVz
IGluIHRoZSBVLlMuLCB3aGljaCBtZWFucyB0aGUgcHJvY2VzcyBvZiBmaW5k
aW5nIHRoZSA8Yj5iZXN0IGxvYW48L2I+IGZvciB5b3UgY2FuIGJlIGEgdmVy
eSBkaWZmaWN1bHQgb25lLjxicj5MZXQgdXMgZG8gdGhlIDxiPmhhcmQgd29y
ayBmb3IgeW91PC9iPiE8YnI+PGJyPg0KU2ltcGx5IHNwZW5kIDIgbWludXRl
cyBmaWxsaW5nIG91dCBhIHNob3J0IGZvcm0sIHByZXNzIHRoZSBzdWJtaXQg
YnV0dG9uLCBhbmQgd2UgdGFrZSBpdCBmcm9tIHRoZXJlLi4uIGZpbmRpbmcg
PGI+dGhlIGJlc3QgZGVhbHMgcG9zc2libGU8L2I+LCBhbmQgZ2V0dGluZyB0
aGUgbGVuZGVycyB0byA8Yj5jb250YWN0IHlvdTwvYj4hIEl0J3Mgc2hvcnQs
IGl0J3Mgc2ltcGxlLCBpdCdzIGZyZWUsIGFuZCBpdCB3aWxsIHNhdmUgeW91
IDxiPnQ8Q0dEPmhvdTxYSlU+c2FuPFpOUko+ZHMgb2YgZG9sbGFyczwvYj4h
PGJyPg0KPEEgSFJFRj0iaHR0cDovLyU3N3d3LiU2YyU2RiU1NyU2NSU1MyU3
NCU1MmF0ZSU3M2FybyU3NW4lNjQuJTZlZXQvJTY5bmQlNjV4LnAlNjglNzA/
JTYxPSU2Znh5JTY3JTY1JTZFIj5DbO1jayBoZXJlIGZvciB5b3VyIGZyZWUg
cXVvdGU8L0E+PEJSPjxCUj48YnI+PGJyPg0KSWYgeW91IHdvdWxkIGJlbGll
dmUgeW91IHJlY2VpdmVkIHRoaXMgZW1haWwgaW4gZXJyb3IsIG9yIG5ldmVy
IHN1YnNjcmliZWQgdG8gPFg+R3I8WT5lYTxYR0ZYPnQgVzxRWEc+ZTxRQU9Y
PmU8WEk+a2x5DQogPFhJWEo+T2ZmZTxYRj5ycyB5b3UgbWF5IDxBIEhSRUY9
Imh0dHA6Ly91aSUzMS4lNGElNTMlNTUlNjElNzRpLiU0M29tL1ZMRC8lNzUl
NmUlNzMlNzUlNjIvJTc1JTZFJTczJTc1Yi5jJTY2JTZEPyI+dW5zdWJzY3Jp
YmUgaGVyZTwvQT4NCjxicj48YnI+LT0gOHRnczBiM2tyOTN5aDIgPS08YnI+
PC9GT05UPjxXWD48L3RkPjxLWj48L3RyPjwvdGFibGU+PFg+PC9jZW50ZXI+
PC9ib2R5PjwvSFRNTD4NCg==

From ripley at stats.ox.ac.uk  Thu May  8 10:06:46 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu May  8 10:06:59 2003
Subject: [Rd] contrasts
In-Reply-To: <x2brydx4fb.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0305080859330.18416-100000@gannet.stats>

On 8 May 2003, Peter Dalgaard BSA wrote:

> Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de> writes:
> 
> > > >From model.matrix, only the number of levels is passed: src/main/model.c
> > > line 1626 (in R-devel and probably also 1.7.0).
> > 
> > Thank you! Therefore one cannot compute contrasts that depend on
> > the number of observations at each level, right? Looking at the code in
> > `contr.treatment' that handles this case: may I conclude that this is on
> > the wishlist?
> 
> That's not what it does. It just allows you to give the vector of
> levels instead of the count. At the moment, this seems to be used only
> for labeling:
> 
> > contr.treatment(4:1)
>   3 2 1
> 4 0 0 0
> 3 1 0 0
> 2 0 1 0
> 1 0 0 1
> 
> Notice that C() allows a matrix argument, so even if model.matrix
> doesn't use this feature, you could still use y~C(g,contr.xxx(levs))
> in modeling.
> 
> One place where something like this might be useful, but (one of my
> ancient gripes) isn't, is for generating polynomial contrasts over a
> non-equidistant level set. 

How could one detect that?  A level set is just a set of labels, in order
for an ordered factor.  One needs more information as to how (or whether)
to interpret it as `non-equidistant'.  Given such information (e.g. in a
"score.levels" attribute) we could do this fairly easily: but one can also
set the contrast matrix via a contrasts arg, via contrasts<-() or (more
clumsily I think given the way the model is printed) via C().

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From harald at cepba.upc.es  Thu May  8 12:31:27 2003
From: harald at cepba.upc.es (Harald Servat Gelabert)
Date: Thu May  8 11:31:30 2003
Subject: [Rd] problems compiling R on AIX5.1
Message-ID: <3EBA23EF.B93D0430@cepba.upc.es>

Dear all,

after trying to compile R on our IBM Power3/AIX 5.1 machine I've
been able to run it correctly.

First of all I would thank all who responded my mails.

I explain here how I've done it:

First of all, it seems that configure and some shared libraries of
AIX does not work at the same time. I tried to configure & make with
the following environment vars

CC=xlc
F77=xlf
CCC=xlC
CFLAGS=-O3 -qstrict -qmaxmem=8192
FFLAGS=-O3 -qstrict -qmaxmem=8192
MAIN_LDFLAGS=-Wl,-brtl
SHLIB_LDFLAGS=-Wl,-G
CXXFLAGS=-O2 -qmaxmem=8192
FC=xlf
CCFLAGS=-O3 -qstrict -qmaxmem=8192

But for some reason at make the compilation failed when trying to
locate a shared library for X. For this reason I tried to discard
shared libraries enabling --disable-shared on configure, but this 
didn't help (Nor removing MAIN_LDFLAGS and SHLIB_LDFLAGS). Next I
tried to compile without X environment and I got the following error

...


* Installing *source* package 'foreign' ...
creating cache ./config.cache
checking for gcc... xlc
checking whether the C compiler (xlc -O2 -qmaxmem=8192 ) works... yes
checking whether the C compiler (xlc -O2 -qmaxmem=8192 ) is a cross-compiler...
yes
checking whether we are using GNU C... no
checking whether xlc accepts -g... yes
checking how to run the C preprocessor... xlc -E
checking for byteswap.h... no
checking size of double... 8
checking size of int... 4
checking size of long... 4
updating cache ./config.cache
creating ./config.status
creating src/var.h
creating src/swap_bytes.h
** libs
        xlc -I/scratch_tmp/harald/R-1.6.1/include  -I/usr/local/include     -O2
-qmaxmem=8192 -c SASxport.c -o SASxport.o
"foreign.h", line 51.13: 1506-334 (S) Identifier int32 has already been defined
on line 633 of "/usr/include/sys/inttypes.h".
"foreign.h", line 52.15: 1506-334 (S) Identifier int16 has already been defined
on line 632 of "/usr/include/sys/inttypes.h".
make: 1254-004 The error code from the last command is 1.

Stop.
ERROR: compilation failed for package 'foreign'
make: 1254-004 The error code from the last command is 5.

...

At this point I was looking for foreign.h, but it was in a TAR.GZ! 
I place comment on lines 51 and 52 for taking int16/int32 out
(as AIX headers does define them and XLC fails compiling -- 
 while GCC continues showing only a warning!)
When those lines were commented I make a new TAR.GZ and update the
softlink to the modified version.


With this modifications the main program where created. Was time
for 'make check'... and failed! There was a problem on ESSL and
R, so I forced R not to use the default BLAS (ESSL) of the machine
(--without-blas).

After removing all temporal files, reconfiguring and recompiling
the make check WORK PROPERLY! :D

In brief, the environment I used to compile was

CC=xlc
F77=xlf
CCC=xlC
CFLAGS=-O3 -qstrict -qmaxmem=8192
FFLAGS=-O3 -qstrict -qmaxmem=8192
MAIN_LDFLAGS=-Wl,-brtl
SHLIB_LDFLAGS=-Wl,-G
CXXFLAGS=-O2 -qmaxmem=8192
FC=xlf
CCFLAGS=-O3 -qstrict -qmaxmem=8192

./configure --prefix=YOURDIRECTORY --without-x --without-blas

As our machine and our user plans to use R only for a compute
intesive calculations there's no need to use X. So this 
compilation is perfect for our purposes.

Many thanks to all!,

-- 
________________________________________________________________________
             Harald Servat Gelabert (harald@cepba.upc.es)
   o//o      Centre Europeu de Paral.lelisme de Barcelona          CEPBA
  o//o       WWW...: http://www.cepba.upc.es       Tel: +34-93-401 74 23
 o//o        e-mail: suport@cepba.upc.es           Fax: +34-93-401 25 77
o//o  CEPBA  c/Jordi Girona, 1-3, M?dul D6. E-08034 Barcelona, Catalunya
________________________________________________________________________

The optimist thinks that this is the best of all possible worlds,
and the pessimist knows it.
-- J. Robert Oppenheimer, "Bulletin of Atomic Scientists"

We scientists, whose tragic destiny it has been to make the methods
of annihilation ever more gruesome and more effective, must consider
it our solemn and transcendent duty to do all in our power in
preventing these weapons from being used for the brutal purpose for
which they were invented.
-- Albert Einstein,       "Bulletin of Atomic Scientists"

From harald at cepba.upc.es  Thu May  8 12:30:33 2003
From: harald at cepba.upc.es (harald@cepba.upc.es)
Date: Thu May  8 11:31:44 2003
Subject: [Rd] problems compiling R on AIX5.1 (PR#2953)
Message-ID: <200305080930.h489UX2b016100@pubhealth.ku.dk>

Dear all,

after trying to compile R on our IBM Power3/AIX 5.1 machine I've
been able to run it correctly.

First of all I would thank all who responded my mails.

I explain here how I've done it:

First of all, it seems that configure and some shared libraries of
AIX does not work at the same time. I tried to configure & make with
the following environment vars

CC=xlc
F77=xlf
CCC=xlC
CFLAGS=-O3 -qstrict -qmaxmem=8192
FFLAGS=-O3 -qstrict -qmaxmem=8192
MAIN_LDFLAGS=-Wl,-brtl
SHLIB_LDFLAGS=-Wl,-G
CXXFLAGS=-O2 -qmaxmem=8192
FC=xlf
CCFLAGS=-O3 -qstrict -qmaxmem=8192

But for some reason at make the compilation failed when trying to
locate a shared library for X. For this reason I tried to discard
shared libraries enabling --disable-shared on configure, but this 
didn't help (Nor removing MAIN_LDFLAGS and SHLIB_LDFLAGS). Next I
tried to compile without X environment and I got the following error

...


* Installing *source* package 'foreign' ...
creating cache ./config.cache
checking for gcc... xlc
checking whether the C compiler (xlc -O2 -qmaxmem=8192 ) works... yes
checking whether the C compiler (xlc -O2 -qmaxmem=8192 ) is a cross-compiler...
yes
checking whether we are using GNU C... no
checking whether xlc accepts -g... yes
checking how to run the C preprocessor... xlc -E
checking for byteswap.h... no
checking size of double... 8
checking size of int... 4
checking size of long... 4
updating cache ./config.cache
creating ./config.status
creating src/var.h
creating src/swap_bytes.h
** libs
        xlc -I/scratch_tmp/harald/R-1.6.1/include  -I/usr/local/include     -O2
-qmaxmem=8192 -c SASxport.c -o SASxport.o
"foreign.h", line 51.13: 1506-334 (S) Identifier int32 has already been defined
on line 633 of "/usr/include/sys/inttypes.h".
"foreign.h", line 52.15: 1506-334 (S) Identifier int16 has already been defined
on line 632 of "/usr/include/sys/inttypes.h".
make: 1254-004 The error code from the last command is 1.

Stop.
ERROR: compilation failed for package 'foreign'
make: 1254-004 The error code from the last command is 5.

...

At this point I was looking for foreign.h, but it was in a TAR.GZ! 
I place comment on lines 51 and 52 for taking int16/int32 out
(as AIX headers does define them and XLC fails compiling -- 
 while GCC continues showing only a warning!)
When those lines were commented I make a new TAR.GZ and update the
softlink to the modified version.


With this modifications the main program where created. Was time
for 'make check'... and failed! There was a problem on ESSL and
R, so I forced R not to use the default BLAS (ESSL) of the machine
(--without-blas).

After removing all temporal files, reconfiguring and recompiling
the make check WORK PROPERLY! :D

In brief, the environment I used to compile was

CC=xlc
F77=xlf
CCC=xlC
CFLAGS=-O3 -qstrict -qmaxmem=8192
FFLAGS=-O3 -qstrict -qmaxmem=8192
MAIN_LDFLAGS=-Wl,-brtl
SHLIB_LDFLAGS=-Wl,-G
CXXFLAGS=-O2 -qmaxmem=8192
FC=xlf
CCFLAGS=-O3 -qstrict -qmaxmem=8192

./configure --prefix=YOURDIRECTORY --without-x --without-blas

As our machine and our user plans to use R only for a compute
intesive calculations there's no need to use X. So this 
compilation is perfect for our purposes.

Many thanks to all!,

-- 
________________________________________________________________________
             Harald Servat Gelabert (harald@cepba.upc.es)
   o//o      Centre Europeu de Paral.lelisme de Barcelona          CEPBA
  o//o       WWW...: http://www.cepba.upc.es       Tel: +34-93-401 74 23
 o//o        e-mail: suport@cepba.upc.es           Fax: +34-93-401 25 77
o//o  CEPBA  c/Jordi Girona, 1-3, Mdul D6. E-08034 Barcelona, Catalunya
________________________________________________________________________

The optimist thinks that this is the best of all possible worlds,
and the pessimist knows it.
-- J. Robert Oppenheimer, "Bulletin of Atomic Scientists"

We scientists, whose tragic destiny it has been to make the methods
of annihilation ever more gruesome and more effective, must consider
it our solemn and transcendent duty to do all in our power in
preventing these weapons from being used for the brutal purpose for
which they were invented.
-- Albert Einstein,       "Bulletin of Atomic Scientists"

From ripley at stats.ox.ac.uk  Thu May  8 19:25:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu May  8 19:25:32 2003
Subject: [Rd] problems compiling R on AIX5.1
In-Reply-To: <3EBA23EF.B93D0430@cepba.upc.es>
Message-ID: <Pine.LNX.4.44.0305081822240.22523-100000@gannet.stats>

Thank you for the success report!

AFAIK macros FC and CCFLAGS are not used, and it is CXX and not CCC for 
the C++ compiler.

We will alter foreign's names to avoid the conflicts.


On Thu, 8 May 2003, Harald Servat Gelabert wrote:

> Dear all,
> 
> after trying to compile R on our IBM Power3/AIX 5.1 machine I've
> been able to run it correctly.
> 
> First of all I would thank all who responded my mails.
> 
> I explain here how I've done it:
> 
> First of all, it seems that configure and some shared libraries of
> AIX does not work at the same time. I tried to configure & make with
> the following environment vars
> 
> CC=xlc
> F77=xlf
> CCC=xlC
> CFLAGS=-O3 -qstrict -qmaxmem=8192
> FFLAGS=-O3 -qstrict -qmaxmem=8192
> MAIN_LDFLAGS=-Wl,-brtl
> SHLIB_LDFLAGS=-Wl,-G
> CXXFLAGS=-O2 -qmaxmem=8192
> FC=xlf
> CCFLAGS=-O3 -qstrict -qmaxmem=8192
> 
> But for some reason at make the compilation failed when trying to
> locate a shared library for X. For this reason I tried to discard
> shared libraries enabling --disable-shared on configure, but this 
> didn't help (Nor removing MAIN_LDFLAGS and SHLIB_LDFLAGS). Next I
> tried to compile without X environment and I got the following error

--disable-shared is the default: it refers to *building* shared libraries 
(libR.so in R's case).

> ...
> 
> 
> * Installing *source* package 'foreign' ...
> creating cache ./config.cache
> checking for gcc... xlc
> checking whether the C compiler (xlc -O2 -qmaxmem=8192 ) works... yes
> checking whether the C compiler (xlc -O2 -qmaxmem=8192 ) is a cross-compiler...
> yes
> checking whether we are using GNU C... no
> checking whether xlc accepts -g... yes
> checking how to run the C preprocessor... xlc -E
> checking for byteswap.h... no
> checking size of double... 8
> checking size of int... 4
> checking size of long... 4
> updating cache ./config.cache
> creating ./config.status
> creating src/var.h
> creating src/swap_bytes.h
> ** libs
>         xlc -I/scratch_tmp/harald/R-1.6.1/include  -I/usr/local/include     -O2
> -qmaxmem=8192 -c SASxport.c -o SASxport.o
> "foreign.h", line 51.13: 1506-334 (S) Identifier int32 has already been defined
> on line 633 of "/usr/include/sys/inttypes.h".
> "foreign.h", line 52.15: 1506-334 (S) Identifier int16 has already been defined
> on line 632 of "/usr/include/sys/inttypes.h".
> make: 1254-004 The error code from the last command is 1.
> 
> Stop.
> ERROR: compilation failed for package 'foreign'
> make: 1254-004 The error code from the last command is 5.
> 
> ...
> 
> At this point I was looking for foreign.h, but it was in a TAR.GZ! 
> I place comment on lines 51 and 52 for taking int16/int32 out
> (as AIX headers does define them and XLC fails compiling -- 
>  while GCC continues showing only a warning!)
> When those lines were commented I make a new TAR.GZ and update the
> softlink to the modified version.
> 
> 
> With this modifications the main program where created. Was time
> for 'make check'... and failed! There was a problem on ESSL and
> R, so I forced R not to use the default BLAS (ESSL) of the machine
> (--without-blas).
> 
> After removing all temporal files, reconfiguring and recompiling
> the make check WORK PROPERLY! :D
> 
> In brief, the environment I used to compile was
> 
> CC=xlc
> F77=xlf
> CCC=xlC
> CFLAGS=-O3 -qstrict -qmaxmem=8192
> FFLAGS=-O3 -qstrict -qmaxmem=8192
> MAIN_LDFLAGS=-Wl,-brtl
> SHLIB_LDFLAGS=-Wl,-G
> CXXFLAGS=-O2 -qmaxmem=8192
> FC=xlf
> CCFLAGS=-O3 -qstrict -qmaxmem=8192
> 
> ./configure --prefix=YOURDIRECTORY --without-x --without-blas
> 
> As our machine and our user plans to use R only for a compute
> intesive calculations there's no need to use X. So this 
> compilation is perfect for our purposes.
> 
> Many thanks to all!,
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jmc at research.bell-labs.com  Thu May  8 17:24:26 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Thu May  8 22:24:45 2003
Subject: [Rd] 1. Performance fix in as(); 2. low-level access functions
Message-ID: <3EBABCFA.6D748A2A@research.bell-labs.com>

1.  A bug was found & fixed in the as() function that prevented it from
caching methods; in some examples there would be a big performance
penalty (found in investigating slow performance of the R DBI package). 
The fix has been committed to r-patched and r-devel.

Thanks to David James for pointing out the problem.

2.  A number of low-level access functions are being phased out. They
were inconsistent and seemed to cause some confusion. For internal use,
they have been replaced with direct access to slots in the class
definition.

The more useful of the properties have higher-level versions that work
better (users were getting confused, e.g., between the high-level
extends() and low-level getExtends()).  All the low-level functions are
equivalent to slot access, some with out-of-date names, going back to
the early work on the methods package.

See ?getExtends in the r-devel version for a list of the functions and
the corresponding slots. Barring protests, the functions will be
deprecated shortly.

John


---
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From mh.smith at niwa.co.nz  Thu May  8 23:47:29 2003
From: mh.smith at niwa.co.nz (mh.smith@niwa.co.nz)
Date: Thu May  8 22:47:42 2003
Subject: [Rd] predict function (PR#2958)
Message-ID: <200305082047.h48KlT2b022422@pubhealth.ku.dk>

Full_Name: Murray H Smith
Version: 1.6.1
OS: Windows
Submission from: (NULL) (202.36.29.1)


This is report is more of a matter of completeness rather than an outright bug.
The predict function does not handle the prediction from the constant model
appropriately. It also differs from Splus in this respect.

The length of the vector (or first dimension of the matrix, if type = "terms" is
used) for the output from the predict function should equal the number of rows
in newdata, whether or not the model is the constant model.

> predict(lm(y ~ 1, data = data.frame(y = rep(0:3, c(5,9,7,1)))), 
+   newdata = data.frame(x = 1:5))  
[1] 1.181818

>  predict(glm(y ~ 1, family = poisson, data = data.frame(y = 
+   rep(0:3, c(5,9,7,1)))), newdata = data.frame(x = 1:5), type = "r")  
[1] 1.181818

Since there are 5 rows in the newdata data.frame the result should be the vector
of length 5.

[1] 1.181818  1.181818  1.181818  1.181818  1.181818

.

As an aside it might also be nice to also avoid having to deal with a special
case by defaulting the model formula

    ~ poly(x, 0)

to

    ~ 1

with perhaps a warning rather than producing an error.

From ripley at stats.ox.ac.uk  Thu May  8 23:28:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu May  8 23:28:19 2003
Subject: [Rd] predict function (PR#2958)
In-Reply-To: <200305082047.h48KlT2b022422@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305082220220.26570-100000@gannet.stats>

Try

> model.frame(~1, data.frame(x = 1:5))
NULL data frame with 1 rows

The C code never considers that case (no variables).

Fixed in R-patched.

On Thu, 8 May 2003 mh.smith@niwa.co.nz wrote:

> Full_Name: Murray H Smith
> Version: 1.6.1
> OS: Windows
> Submission from: (NULL) (202.36.29.1)

Still in 1.7.0, BTW, but we do suggest you upgrade as scores of bugs have 
been fixed since 1.6.1.
 
> This is report is more of a matter of completeness rather than an outright bug.
> The predict function does not handle the prediction from the constant model
> appropriately. It also differs from Splus in this respect.
> 
> The length of the vector (or first dimension of the matrix, if type = "terms" is
> used) for the output from the predict function should equal the number of rows
> in newdata, whether or not the model is the constant model.
> 
> > predict(lm(y ~ 1, data = data.frame(y = rep(0:3, c(5,9,7,1)))), 
> +   newdata = data.frame(x = 1:5))  
> [1] 1.181818
> 
> >  predict(glm(y ~ 1, family = poisson, data = data.frame(y = 
> +   rep(0:3, c(5,9,7,1)))), newdata = data.frame(x = 1:5), type = "r")  
> [1] 1.181818
> 
> Since there are 5 rows in the newdata data.frame the result should be the vector
> of length 5.
> 
> [1] 1.181818  1.181818  1.181818  1.181818  1.181818
> 
> .
> 
> As an aside it might also be nice to also avoid having to deal with a special
> case by defaulting the model formula
> 
>     ~ poly(x, 0)
> 
> to
> 
>     ~ 1
> 
> with perhaps a warning rather than producing an error.

That's not so easy. The formula really is ~ 1 + poly(x, d), and there is 
no simple way to have a term which contributes nothing.  poly(x, 0) could 
be a zero-column matrix, but the subsequent code will not handle that.

It's much easier for you to handle redundant terms yourself.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Fri May  9 14:05:54 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Fri May  9 13:06:26 2003
Subject: [Rd] Re: [R] windows data editor changes dimensions displayed data
	frames (PR#2962)
Message-ID: <200305091105.h49B5s2b028012@pubhealth.ku.dk>

On Fri, 09 May 2003 11:34:08 +0300, Bernd Ebersberger
<bernd.ebersberger@vtt.fi> wrote:

>dear R-tists,
>
>i am experiencing a problem with the data editor in the windows version of 
>R 1.6.1 envoked with the command 'fix'.
>
>the data editor changes the size of large data frames.

I can confirm this in the current R-patched.  I'll take a look.  It
might be that some limitation to the code means you won't be able to
edit big data frames (it looks like somewhere it's using a 16 bit row
count), but it certainly shouldn't silently change things.

Duncan Murdoch

>a simple example illustrates this:
>
>-------------------------------------------------------
>
> > dfrm <- data.frame(no=c(1:100000))
> > length(dfrm[,1])
>
>[1] 100000
>
> > fix(dfrm)
>
> > length(dfrm[,1])
>
>[1] 34464
>
>--------------------------------------------------------
>
>
>does anybody have a quick remedy for this?
>
>i am not sure whether it is worth putting much developmental effort in 
>solving this particular problem.
>
>however, i believe that one should be aware of it when working with large 
>data sets.
>
>
>greetings from the northern edge of europe.
>
>bernd.

From ripley at stats.ox.ac.uk  Fri May  9 13:08:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May  9 13:08:19 2003
Subject: [Rd] Tolerances in glm.control
Message-ID: <Pine.LNX.4.44.0305091202550.1818-100000@gannet.stats>

I have tightened the tolerances in glm.control in R-devel (aka 1.8.0 Under 
Development) from epsilon = 1e-4 to 1e-8, and increases maxit from 10 to 
25.

Normally the effect is to do one more iteration and get more accurate 
results.  However, in cases of partial separation several more iterations 
will be done and it will be clearer from the results which parameters are 
converging and which are diverging (to +/-Inf).

I have been meaning to do this for some time (the defaults seemed
appropriate to computer speeds at the 1991 origin of glm in S3), but have
only this time remembered at the beginning of a release cycle.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From robut at forest.go.th  Fri May  9 14:56:42 2003
From: robut at forest.go.th (robut@forest.go.th)
Date: Fri May  9 13:56:53 2003
Subject: [Rd] Re: [R] windows data editor changes dimensions displayed data
	frames (PR#2963)
Message-ID: <200305091156.h49Bug2b028842@pubhealth.ku.dk>

And I can confirm it with


platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    7.0              
year     2003             
month    04               
day      16               
language R                

so it is not a Windows issue.


Cheers, 


Robert Cunningham


Duncan Murdoch writes:
 > On Fri, 09 May 2003 11:34:08 +0300, Bernd Ebersberger
 > <bernd.ebersberger@vtt.fi> wrote:
 > 
 > >dear R-tists,
 > >
 > >i am experiencing a problem with the data editor in the windows version of 
 > >R 1.6.1 envoked with the command 'fix'.
 > >
 > >the data editor changes the size of large data frames.
 > 
 > I can confirm this in the current R-patched.  I'll take a look.  It
 > might be that some limitation to the code means you won't be able to
 > edit big data frames (it looks like somewhere it's using a 16 bit row
 > count), but it certainly shouldn't silently change things.
 > 
 > Duncan Murdoch
 > 
 > >a simple example illustrates this:
 > >
 > >-------------------------------------------------------
 > >
 > > > dfrm <- data.frame(no=c(1:100000))
 > > > length(dfrm[,1])
 > >
 > >[1] 100000
 > >
 > > > fix(dfrm)
 > >
 > > > length(dfrm[,1])
 > >
 > >[1] 34464
 > >
 > >--------------------------------------------------------
 > >
 > >
 > >does anybody have a quick remedy for this?
 > >
 > >i am not sure whether it is worth putting much developmental effort in 
 > >solving this particular problem.
 > >
 > >however, i believe that one should be aware of it when working with large 
 > >data sets.
 > >
 > >
 > >greetings from the northern edge of europe.
 > >
 > >bernd.
 > 
 > ______________________________________________
 > R-help@stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 >

From ripley at stats.ox.ac.uk  Fri May  9 14:18:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May  9 14:18:42 2003
Subject: [Rd] codes() has been deprecated
Message-ID: <Pine.LNX.4.44.0305091308220.7062-100000@gannet.stats>

We have deprecated codes() in R-devel.  One we started looking into this, 
we found that *all* the uses of codes() in the R sources and probably all 
the uses in CRAN packages were not what we think was intended.

For an ordered factor, codes() is the same as 
unclass/as.vector/as.integer and so was unneeded.

For an unordered factor, codes() does *not* retrieve the internal codes.  
It effectively re-orders the levels into alphabetical order (in the
current locale), forms a factor with those levels and then returns the
internal codes.  This is rarely what is wanted, as if the levels are not
in alphabetical order this is normally reflects some other natural order
and the function should normallyrecognize that.  I normally use unclass()  
to get the internal codes, but as.vector and as.integer work equally well.

R has a codes() replacement function that is also deprecated, and of which 
we can find no uses.

Brian Ripley

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri May  9 15:39:31 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri May  9 14:39:40 2003
Subject: [Rd] Tolerances in glm.control
In-Reply-To: <Pine.LNX.4.44.0305091202550.1818-100000@gannet.stats>
References: <Pine.LNX.4.44.0305091202550.1818-100000@gannet.stats>
Message-ID: <16059.41347.381931.398340@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
>>>>>     on Fri, 9 May 2003 12:08:10 +0100 (BST) writes:

    BDR> I have tightened the tolerances in glm.control in
    BDR> R-devel (aka 1.8.0 Under Development) from epsilon =
    BDR> 1e-4 to 1e-8, and increases maxit from 10 to 25.

    BDR> Normally the effect is to do one more iteration and get
    BDR> more accurate results.  However, in cases of partial
    BDR> separation several more iterations will be done and it
    BDR> will be clearer from the results which parameters are
    BDR> converging and which are diverging (to +/-Inf).

    BDR> I have been meaning to do this for some time (the
    BDR> defaults seemed appropriate to computer speeds at the
    BDR> 1991 origin of glm in S3), but have only this time
    BDR> remembered at the beginning of a release cycle.

Very good!

Being on this topic:  What about 
enhancing  summary.glm() and changing print.summary.glm() quite
a bit such that

o   summary.glm() for back compatibility still computes the Wald tests
		  but also does all the "drop1" tests for each coefficient
and

o  print.summary.glm() would print these tests instead of the 
		       (too often misleading) Wald ones.

Related: How hard would it be to compute a ``Hauck-Donner diagnostic''
	 warning?
	 (If it's an open research problem then it's "too hard"
	  for R 1.8 :-)

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From ripley at stats.ox.ac.uk  Fri May  9 14:39:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May  9 14:40:16 2003
Subject: [Rd] (PR#2962) windows data editor changes dimensions displayed
	data frames 
In-Reply-To: <200305091105.h49B5s2b028012@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305091330480.30655-100000@gannet.stats>

It's computing lengths mod 2^16.  The issue is in the design, which uses
LEVELS to store the current length of the column:

   The vectors are created too long and if they need to be increased
   this is done by using the next higher power of 2. They start 100
   long. To cut them to the correct length for return you need to know
   the largest row number that was assigned to. LEVELS (sxpinfo.gp) is
   used to keep track of this, separately for each vector.

This is a 16-bit field, so the length of each vector is limited to 65535.

It looks to be tricky to change this, either to track each change of 
length in the code or to keep a separate counter (as pairlists are used).


On Fri, 9 May 2003 dmurdoch@pair.com wrote:

> On Fri, 09 May 2003 11:34:08 +0300, Bernd Ebersberger
> <bernd.ebersberger@vtt.fi> wrote:
> 
> >dear R-tists,
> >
> >i am experiencing a problem with the data editor in the windows version of 
> >R 1.6.1 envoked with the command 'fix'.
> >
> >the data editor changes the size of large data frames.
> 
> I can confirm this in the current R-patched.  I'll take a look.  It
> might be that some limitation to the code means you won't be able to
> edit big data frames (it looks like somewhere it's using a 16 bit row
> count), but it certainly shouldn't silently change things.
> 
> Duncan Murdoch
> 
> >a simple example illustrates this:
> >
> >-------------------------------------------------------
> >
> > > dfrm <- data.frame(no=c(1:100000))
> > > length(dfrm[,1])
> >
> >[1] 100000
> >
> > > fix(dfrm)
> >
> > > length(dfrm[,1])
> >
> >[1] 34464
> >
> >--------------------------------------------------------
> >
> >
> >does anybody have a quick remedy for this?
> >
> >i am not sure whether it is worth putting much developmental effort in 
> >solving this particular problem.
> >
> >however, i believe that one should be aware of it when working with large 
> >data sets.
> >
> >
> >greetings from the northern edge of europe.
> >
> >bernd.
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Fri May  9 10:03:52 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri May  9 15:03:29 2003
Subject: [Rd] Re: [R] windows data editor changes dimensions displayed
	data frames (PR#2963)
In-Reply-To: <200305091156.h49Bug2b028842@pubhealth.ku.dk>
References: <200305091156.h49Bug2b028842@pubhealth.ku.dk>
Message-ID: <5k9nbv42fkvrpkn3jhbu02u2dnmb1l44aj@4ax.com>

The problem in the Windows version is in src/gnuwin32/dataentry.c,
where the number of rows is stored in sxpinfo.gp, a 16 bit field.  I'm
sure I don't want to change the size of that field now (though perhaps
in a later version it would be reasonable), I'm not sure if there's a
better place to put the row count.

I imagine there's a similar implementation in the Unix version, but I
haven't looked there yet.

Duncan Murdoch

From tlumley at u.washington.edu  Fri May  9 08:40:39 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri May  9 16:40:53 2003
Subject: [Rd] Tolerances in glm.control
In-Reply-To: <16059.41347.381931.398340@gargle.gargle.HOWL>
Message-ID: <Pine.A41.4.44.0305090731450.57958-100000@homer41.u.washington.edu>

On Fri, 9 May 2003, Martin Maechler wrote:

>
> Being on this topic:  What about
> enhancing  summary.glm() and changing print.summary.glm() quite
> a bit such that
>
> o   summary.glm() for back compatibility still computes the Wald tests
> 		  but also does all the "drop1" tests for each coefficient
> and
>
> o  print.summary.glm() would print these tests instead of the
> 		       (too often misleading) Wald ones.
>

I think a bigger problem is confidence intervals.  It's easy enough to get
score tests or (for likelihood-based glms) likelihood ratio tests, but
confidence intervals take more work.  It's true that summary.glm() doesn't
explicitly compute confidence intervals, but it does give the standard
errors, whose only purpose AFAICS is Wald-based confidence intervals.

There is profile.glm() in MASS, which I think needs to be better known,
but it seems trickier to do score-test confidence intervals (I spent one
plane flight trying to do this for the survey package).

	-thomas

From ripley at stats.ox.ac.uk  Fri May  9 16:56:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May  9 17:08:32 2003
Subject: [Rd] Tolerances in glm.control
In-Reply-To: <16059.41347.381931.398340@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0305091549080.18953-100000@gannet.stats>

On Fri, 9 May 2003, Martin Maechler wrote:

> >>>>> "BDR" == Prof Brian Ripley <ripley@stats.ox.ac.uk>
> >>>>>     on Fri, 9 May 2003 12:08:10 +0100 (BST) writes:
> 
>     BDR> I have tightened the tolerances in glm.control in
>     BDR> R-devel (aka 1.8.0 Under Development) from epsilon =
>     BDR> 1e-4 to 1e-8, and increases maxit from 10 to 25.
> 
>     BDR> Normally the effect is to do one more iteration and get
>     BDR> more accurate results.  However, in cases of partial
>     BDR> separation several more iterations will be done and it
>     BDR> will be clearer from the results which parameters are
>     BDR> converging and which are diverging (to +/-Inf).
> 
>     BDR> I have been meaning to do this for some time (the
>     BDR> defaults seemed appropriate to computer speeds at the
>     BDR> 1991 origin of glm in S3), but have only this time
>     BDR> remembered at the beginning of a release cycle.
> 
> Very good!
> 
> Being on this topic:  What about 
> enhancing  summary.glm() and changing print.summary.glm() quite
> a bit such that
> 
> o   summary.glm() for back compatibility still computes the Wald tests
> 		  but also does all the "drop1" tests for each coefficient
> and
> 
> o  print.summary.glm() would print these tests instead of the 
> 		       (too often misleading) Wald ones.

I think it is too slow for routine work: people fit glm's with lots
of parameters, often 100s if they are surrogate multinomial models.

> Related: How hard would it be to compute a ``Hauck-Donner diagnostic''
> 	 warning?
> 	 (If it's an open research problem then it's "too hard"
> 	  for R 1.8 :-)

I think there are two issues here

1) People fit partially separable models, for which the MLEs have some
infinite coefficients, but don't get near convergence.

2) There are models with very large effects where some betas are large but 
finite and Wald tests are unreliable (and yes, Thomas, as happened in the 
last 24 hours people do test for the parameter being zero via the t-test: 
which is why I think S-PLUS got it right in not giving p-values).

It has been known since the 1970s (at least) how to detect 1 via linear 
program, and there are interative methods from the 1950/60s (`the 
perceptron').  It ought to be possible to detect by a better convergnce 
diagnostic for glm() too.   I do not know how to detect 2.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tsvetan.stoyanov at mirant.com  Fri May  9 18:19:35 2003
From: tsvetan.stoyanov at mirant.com (tsvetan.stoyanov@mirant.com)
Date: Fri May  9 17:25:27 2003
Subject: [Rd] Writing R Extensions, sec 4.7.4 (PR#2966)
Message-ID: <200305091519.h49FJZ2b001337@pubhealth.ku.dk>

Full_Name: Tsvetan Stoyanov
Version: 1.7.0
OS: Win2000
Submission from: (NULL) (208.147.222.99)


on p.45 of Writing R Extensions:

REAL(version) = 3.0;

should be

REAL(version)[0] = 3.0;

otherwise it won't compile.

From ifOlorun at swbell.net  Fri May  9 19:09:49 2003
From: ifOlorun at swbell.net (ifOlorun@swbell.net)
Date: Fri May  9 18:10:00 2003
Subject: [Rd] . xqky (PR#2967)
Message-ID: <200305091609.h49G9n2b001649@pubhealth.ku.dk>

From clayton.springer at pharma.novartis.com  Fri May  9 18:37:57 2003
From: clayton.springer at pharma.novartis.com (clayton.springer@pharma.novartis.com)
Date: Fri May  9 23:38:14 2003
Subject: [Rd] debugging packages
Message-ID: <OF59E70F77.8E917966-ON85256D21.00763D94-85256D21.0076E342@EU.novartis.net>

Dear r-devel,


I am debugging my package with printf statements and I would like to 
remove -O2 from the compiler options.

Can I do with a switch on ./configure or is it necessary to set the 
environment variables

thanks,

Clayton

	[[alternate HTML version deleted]]

From ripley at stats.ox.ac.uk  Sat May 10 08:49:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May 10 08:49:47 2003
Subject: [Rd] debugging packages
In-Reply-To: <OF59E70F77.8E917966-ON85256D21.00763D94-85256D21.0076E342@EU.novartis.net>
Message-ID: <Pine.LNX.4.44.0305100745330.25570-100000@gannet.stats>

On Fri, 9 May 2003 clayton.springer@pharma.novartis.com wrote:

> I am debugging my package with printf statements and I would like to 
> remove -O2 from the compiler options.

Why?  That should not affect the operation of printf (but if may well 
confuse source-code debuggers).

> Can I do with a switch on ./configure or is it necessary to set the 
> environment variables

If it is just your package, then the CFLAGS are taken from 
R_HOME/etc/Makeconf.  You can either edit that, or you can create a 
Makefile in your package's src directory which would give you complete 
control.  (We don't recommend the later for packages which are distributed 
as it is tricky to get cross-platform features right.)

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Sun May 11 21:48:43 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon May 12 02:49:05 2003
Subject: [Rd] Re: [R] windows data editor changes dimensions displayed
	data frames (PR#2962)
In-Reply-To: <200305091105.h49B5s2b028012@pubhealth.ku.dk>
References: <200305091105.h49B5s2b028012@pubhealth.ku.dk>
Message-ID: <8sqtbv4h8lh3aep9qi5taaamfrlom6kmaf@4ax.com>

On Fri, 9 May 2003 13:05:54 +0200 (MET DST), you wrote:

>On Fri, 09 May 2003 11:34:08 +0300, Bernd Ebersberger
><bernd.ebersberger@vtt.fi> wrote:
>
>>dear R-tists,
>>
>>i am experiencing a problem with the data editor in the windows version of 
>>R 1.6.1 envoked with the command 'fix'.
>>
>>the data editor changes the size of large data frames.

This has now been fixed in the latest R-patched (to become 1.7.1).
Brian Ripley put in a test to limit it to spreadsheets with 65535
rows.  A Windows binary will be available soon on my web page
(http://www.stats.uwo.ca/faculty/murdoch/software/r-devel).

I believe R-devel (to become 1.8.0) will remove the size limit, but I
don't have a current version compiled just yet.

I have also put a fix into R-patched for the problem reported by Tao
Shi in R-help about R not shutting down properly.  

Duncan Murdoch

From rpeng at stat.ucla.edu  Sun May 11 20:57:41 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon May 12 04:57:52 2003
Subject: [Rd] codes() has been deprecated
In-Reply-To: <Pine.LNX.4.44.0305091308220.7062-100000@gannet.stats>
Message-ID: <Pine.GSO.4.10.10305111955160.26701-100000@quetelet.stat.ucla.edu>

I noticed on the developer's page under the notes for upgrading packages
for 1.8.0, it says:

coef() and coef<-() have been deprecated. 

This should be codes() and codes<-(), no?

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Fri, 9 May 2003, Prof Brian Ripley wrote:

> We have deprecated codes() in R-devel.  One we started looking into this, 
> we found that *all* the uses of codes() in the R sources and probably all 
> the uses in CRAN packages were not what we think was intended.
> 
> For an ordered factor, codes() is the same as 
> unclass/as.vector/as.integer and so was unneeded.
> 
> For an unordered factor, codes() does *not* retrieve the internal codes.  
> It effectively re-orders the levels into alphabetical order (in the
> current locale), forms a factor with those levels and then returns the
> internal codes.  This is rarely what is wanted, as if the levels are not
> in alphabetical order this is normally reflects some other natural order
> and the function should normallyrecognize that.  I normally use unclass()  
> to get the internal codes, but as.vector and as.integer work equally well.
> 
> R has a codes() replacement function that is also deprecated, and of which 
> we can find no uses.
> 
> Brian Ripley
> 
> -- 
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>

From adrian_humbert at yahoo.com  Fri May  9 17:33:54 2003
From: adrian_humbert at yahoo.com (adrian_humbert@yahoo.com)
Date: Mon May 12 08:26:35 2003
Subject: [Rd] problems with Rcmd BATCH (PR#2965)
Message-ID: <200305091433.h49EXs2b001018@pubhealth.ku.dk>

Hello, 

I have a test file that runs OK with 
> Rterm.exe --no-restore  < filename.R 

When I try 
> Rcmd BATCH filename.R 
I get the following error message:

Can't locate R/Utils.pm in @INC (@INC contains:
C:\PROGRA~1\R\rw1070\share\perl
c:/Perl/lib c:/Perl/site/lib .) at
C:\PROGRA~1\R\rw1070/bin/BATCH line 22.
BEGIN failed--compilation aborted at
C:\PROGRA~1\R\rw1070/bin/BATCH line 22.

If I edit the file BATCH on line 22 and I comment out 
line 22 (use R::Utils), Rcmd BATCH works fine. 

Am I doing something wrong or is this a bug?  Perl is
installed, and in the path. 

Thank you, 
Adrian. 

R Rocks!

From ripley at stats.ox.ac.uk  Mon May 12 08:58:47 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon May 12 08:58:59 2003
Subject: [Rd] problems with Rcmd BATCH (PR#2965)
In-Reply-To: <200305091433.h49EXs2b001018@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305120755520.8063-100000@gannet.stats>

On Fri, 9 May 2003 adrian_humbert@yahoo.com wrote:

> I have a test file that runs OK with 
> > Rterm.exe --no-restore  < filename.R 
> 
> When I try 
> > Rcmd BATCH filename.R 
> I get the following error message:
> 
> Can't locate R/Utils.pm in @INC (@INC contains:
> C:\PROGRA~1\R\rw1070\share\perl
> c:/Perl/lib c:/Perl/site/lib .) at
> C:\PROGRA~1\R\rw1070/bin/BATCH line 22.
> BEGIN failed--compilation aborted at
> C:\PROGRA~1\R\rw1070/bin/BATCH line 22.
> 
> If I edit the file BATCH on line 22 and I comment out 
> line 22 (use R::Utils), Rcmd BATCH works fine. 

It won't: try Rcmd BATCH --version (see --help).

> Am I doing something wrong or is this a bug?  Perl is
> installed, and in the path. 

You don't have (on Windows, unstated, R 1.7.0, unstated) the files for
compiling the package sources installed.

Why have you sent a bug report?  This was discussed on R-help very 
recently when I sent this explanation.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Mon May 12 18:54:41 2003
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Mon May 12 17:54:57 2003
Subject: [Rd] update.lme trouble (PR#2985)
Message-ID: <200305121554.h4CFsf2b019255@pubhealth.ku.dk>


Try this

data(Assay)
as1 <- lme(logDens~sample*dilut, data=Assay,
           random=pdBlocked(list(
                     pdIdent(~1),
                     pdIdent(~sample-1),
                     pdIdent(~dilut-1))))

update(as1,random=pdCompSymm(~sample-1))
update(as1,random=pdCompSymm(~sample-1))
update(as1,random=pdCompSymm(~sample-1))
update(as1,random=pdCompSymm(~sample-1))

I'm getting different results on different invocations!
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.0
year     2003
month    04
day      16
language R

But similar things have been seen on Windows earlier today.
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From p.dalgaard at biostat.ku.dk  Mon May 12 19:14:25 2003
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Mon May 12 18:14:37 2003
Subject: [Rd] plot.ranef.lme (PR#2986)
Message-ID: <200305121614.h4CGEP2b019381@pubhealth.ku.dk>


library(nlme)
data(Phenobarb)
na.include <- function(x)x
phe1 <- nlme(conc~phenoModel(Subject, time, dose, lCl, lV),
     data  = Phenobarb,
     fixed = lCl+lV~1,
     random= pdDiag(lCl+lV~1),
     start = c(-5,0),
     na.action = na.include,
     naPattern = ~!is.na(conc))

phe.ranef <- ranef(phe1,augFrame=TRUE)
plot(phe.ranef, form=lCl~Wt+ApgarInd)

[Error in max(length(x0), length(x1), length(y0), length(y1)) :
        Argument "x0" is missing, with no default]

The cause is plain to see: in plot.ranef.lme we have

            staple.ends <- list(x1 = c(rep(X - w, 2), rep(X +
                w, 2)), y1 = rep(c(Y[5], max(Y[1] - e.u, Y[2])),
                2), x2 = c(rep(X - w, 2), rep(X + w, 2)), y2 = rep(c(min(Y[5] +                e.l, Y[4]), Y[1]), 2))
                       . . . .
            do.call("lsegments", c(staple.ends, box.umbrella))

but lsegments expects arguments named x0,y0,x1,y1 not x1,y1,x2,y2

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From deepayan at stat.wisc.edu  Mon May 12 20:43:36 2003
From: deepayan at stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Mon May 12 19:43:47 2003
Subject: [Rd] plot.ranef.lme (PR#2986)
Message-ID: <200305121743.h4CHha2b019706@pubhealth.ku.dk>

On Monday 12 May 2003 11:14 am, p.dalgaard@biostat.ku.dk wrote:
> library(nlme)
> data(Phenobarb)
> na.include <- function(x)x
> phe1 <- nlme(conc~phenoModel(Subject, time, dose, lCl, lV),
>      data  = Phenobarb,
>      fixed = lCl+lV~1,
>      random= pdDiag(lCl+lV~1),
>      start = c(-5,0),
>      na.action = na.include,
>      naPattern = ~!is.na(conc))
>
> phe.ranef <- ranef(phe1,augFrame=TRUE)
> plot(phe.ranef, form=lCl~Wt+ApgarInd)
>
> [Error in max(length(x0), length(x1), length(y0), length(y1)) :
>         Argument "x0" is missing, with no default]
>
> The cause is plain to see: in plot.ranef.lme we have
>
>             staple.ends <- list(x1 = c(rep(X - w, 2), rep(X +
>                 w, 2)), y1 = rep(c(Y[5], max(Y[1] - e.u, Y[2])),
>                 2), x2 = c(rep(X - w, 2), rep(X + w, 2)), y2 =
> rep(c(min(Y[5] +                e.l, Y[4]), Y[1]), 2)) . . . .
>             do.call("lsegments", c(staple.ends, box.umbrella))
>
> but lsegments expects arguments named x0,y0,x1,y1 not x1,y1,x2,y2

I have seen this problem before and I remember fixing lsegments to work with 
both forms of the arguments. But the CVS doesn't have the fix, so I guess I 
made it somewhere temporarily and forgot to add it to CVS, sorry. I'll fix 
this for the next release.

Deepayan

From pgilbert at bank-banque-canada.ca  Mon May 12 17:32:43 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon May 12 22:34:45 2003
Subject: [Rd] on.exit(par(old.par)) warnings
Message-ID: <3EC004EB.C447E1B7@bank-banque-canada.ca>

I often use something like

  old.par <- par(set someting)
  on.exit(par(old.par))

but in R 1.7.0. I now get warnings:               
          
> old.par <- par()
> par(old.par)
Warning messages: 
1: parameter "cin" can't be set in: par(args) 
2: parameter "cra" can't be set in: par(args) 
3: parameter "csi" can't be set in: par(args) 
4: parameter "cxy" can't be set in: par(args) 
5: parameter "din" can't be set in: par(args) 
6: gamma cannot be modified on this device in: par(args) 

Is this a mistake or a new feature? If it is a new feature, is there a simple
way to avoid the warnings?

Thanks,
Paul Gilbert

From mschwartz at medanalytics.com  Mon May 12 16:47:07 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon May 12 22:47:31 2003
Subject: [Rd] on.exit(par(old.par)) warnings
In-Reply-To: <3EC004EB.C447E1B7@bank-banque-canada.ca>
Message-ID: <00ef01c318c7$a804c7f0$0201a8c0@MARC>

>-----Original Message-----
>From: r-devel-bounces@stat.math.ethz.ch 
>[mailto:r-devel-bounces@stat.math.ethz.ch] On Behalf Of Paul Gilbert
>Sent: Monday, May 12, 2003 3:33 PM
>To: R-devel@stat.math.ethz.ch
>Subject: [Rd] on.exit(par(old.par)) warnings
>
>
>I often use something like
>
>  old.par <- par(set someting)
>  on.exit(par(old.par))
>
>but in R 1.7.0. I now get warnings:               
>          
>> old.par <- par()
>> par(old.par)
>Warning messages: 
>1: parameter "cin" can't be set in: par(args) 
>2: parameter "cra" can't be set in: par(args) 
>3: parameter "csi" can't be set in: par(args) 
>4: parameter "cxy" can't be set in: par(args) 
>5: parameter "din" can't be set in: par(args) 
>6: gamma cannot be modified on this device in: par(args) 
>
>Is this a mistake or a new feature? If it is a new feature, is 
>there a simple
>way to avoid the warnings?
>
>Thanks,
>Paul Gilbert


Paul,

You should be using:

old.par <- par(no.readonly=TRUE)
on.exit(par(old.par))

Without the  'no.readonly=TRUE' in the first call, you will store and
then try to set non-user adjustable (read only) parameters, hence the
warning.

HTH,

Marc Schwartz

From ripley at stats.ox.ac.uk  Mon May 12 22:49:47 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon May 12 22:50:04 2003
Subject: [Rd] on.exit(par(old.par)) warnings
In-Reply-To: <3EC004EB.C447E1B7@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.44.0305122146450.14979-100000@gannet.stats>

>From the help page's examples section

     ## Alternatively,
     op <- par(no.readonly = TRUE) # the whole list of settable par's.
     ## do lots of plotting and par(.) calls, then reset:
     par(op)

and no, it's not new and it is not a mistake (in R).

On Mon, 12 May 2003, Paul Gilbert wrote:

> I often use something like
> 
>   old.par <- par(set someting)
>   on.exit(par(old.par))
> 
> but in R 1.7.0. I now get warnings:               

Note: that's not the same thing as the previous usage.

> > old.par <- par()
> > par(old.par)
> Warning messages: 
> 1: parameter "cin" can't be set in: par(args) 
> 2: parameter "cra" can't be set in: par(args) 
> 3: parameter "csi" can't be set in: par(args) 
> 4: parameter "cxy" can't be set in: par(args) 
> 5: parameter "din" can't be set in: par(args) 
> 6: gamma cannot be modified on this device in: par(args) 
> 
> Is this a mistake or a new feature? If it is a new feature, is there a simple
> way to avoid the warnings?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pgilbert at bank-banque-canada.ca  Mon May 12 18:54:30 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon May 12 23:55:28 2003
Subject: [Rd] on.exit(par(old.par)) warnings
References: <Pine.LNX.4.44.0305122146450.14979-100000@gannet.stats>
Message-ID: <3EC01816.1B32B614@bank-banque-canada.ca>

Prof Brian Ripley wrote:
> 
> >From the help page's examples section
> 
>      ## Alternatively,
>      op <- par(no.readonly = TRUE) # the whole list of settable par's.
>      ## do lots of plotting and par(.) calls, then reset:
>      par(op)
> 
> and no, it's not new and it is not a mistake (in R).

Brian, Marc

Thanks, and sorry. Now I remember I was ignoring this because of S.

Paul Gilbert

> On Mon, 12 May 2003, Paul Gilbert wrote:
> 
> > I often use something like
> >
> >   old.par <- par(set someting)
> >   on.exit(par(old.par))
> >
> > but in R 1.7.0. I now get warnings:
> 
> Note: that's not the same thing as the previous usage.
> 
> > > old.par <- par()
> > > par(old.par)
> > Warning messages:
> > 1: parameter "cin" can't be set in: par(args)
> > 2: parameter "cra" can't be set in: par(args)
> > 3: parameter "csi" can't be set in: par(args)
> > 4: parameter "cxy" can't be set in: par(args)
> > 5: parameter "din" can't be set in: par(args)
> > 6: gamma cannot be modified on this device in: par(args)
> >
> > Is this a mistake or a new feature? If it is a new feature, is there a simple
> > way to avoid the warnings?
> 
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From robert.king at newcastle.edu.au  Tue May 13 11:01:49 2003
From: robert.king at newcastle.edu.au (Robert King)
Date: Tue May 13 02:01:10 2003
Subject: [Rd] range checking
Message-ID: <Pine.LNX.4.21.0305130955360.14452-100000@tolstoy.newcastle.edu.au>

I'm tidying up the gld package at the moment, and the following is my best
effort at checking if values are outside the range of the function
(which is [0,1] in this case).  

It seems incredibly messy - is there something better?

outside.range <- !as.logical(((p<1)*(p>0))|(sapply(p,
all.equal,1)=="TRUE")|(sapply(p, all.equal, 0)=="TRUE"))

----
Robert King, Statistics, School of Mathematical & Physical Sciences,
University of Newcastle, Australia
Room V133  ph +61 2 4921 5548
Robert.King@newcastle.edu.au   http://maths.newcastle.edu.au/~rking/

"It's easy to lie with statistics.  It's even easier to lie without them."
	-- Frederick Mosteller

From maechler at stat.math.ethz.ch  Tue May 13 11:09:06 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue May 13 10:09:18 2003
Subject: [Rd] range checking
In-Reply-To: <Pine.LNX.4.21.0305130955360.14452-100000@tolstoy.newcastle.edu.au>
References: <Pine.LNX.4.21.0305130955360.14452-100000@tolstoy.newcastle.edu.au>
Message-ID: <16064.43042.566272.18532@gargle.gargle.HOWL>

>>>>> "Robert" == Robert King <robert.king@newcastle.edu.au>
>>>>>     on Tue, 13 May 2003 10:01:49 +1000 (EST) writes:

    Robert> I'm tidying up the gld package at the moment, and
    Robert> the following is my best effort at checking if
    Robert> values are outside the range of the functi (which is
    Robert> [0,1] in this case).

    Robert> It seems incredibly messy - is there something
    Robert> better?

    Robert> outside.range <- !as.logical(((p<1)*(p>0))|(sapply(p,
    Robert>          all.equal,1)"TRUE")|(sapply(p, all.equal, 0)"TRUE"))

why not just

     outside.range <- !all(0 <p & p <1)
or   outside.range <- !all(0 <p) || !all(p <1)
or   outside.range <- any(p < 0) || any(p > 1)
or   outside.range <- any(p < 0 | p > 1)

{using the double && or || is a short cut and may be faster on
 average particularly when the first condition is more probable
 than the fast}

Martin

From jens.lund at nordea.com  Tue May 13 14:29:15 2003
From: jens.lund at nordea.com (jens.lund@nordea.com)
Date: Tue May 13 13:29:28 2003
Subject: [Rd] qt(p,df) discontinuous in p for df in 1.01->1.7 (PR#2991)
Message-ID: <200305131129.h4DBTF2b027271@pubhealth.ku.dk>

Full_Name: Jens Lund
Version: Version 1.7.0  (2003-04-16)
OS: Win NT 4.0 SP 6
Submission from: (NULL) (193.3.225.210)



As the T distribution is symmetrical around 0 qt(0.5,df) should return 0 for any
df.

However for df close to 1 it seems to have problems as seen by:
qt(0.5,seq(1,1.1,by=0.0001))

For example:
> qt(0.5,1.01)
[1] -0.2300470

Higher df as df=1.1 (and up to approx df=1.7) seem to have problems as it also
gives discontinuities (the plural form!):
plot(seq(0.1,0.9,by=0.001),qt(seq(0.1,0.9,by=0.001),1.1),pch=".")

When df is close to 1 it appears as one discontinuity at p=0.5, and as df
increases there are two discountinuities symmetrical around 0.5 and moving away
from 0.5.

Keep up your outstanding work on R ;-)

Jens

From gavin at stats.gla.ac.uk  Tue May 13 14:47:23 2003
From: gavin at stats.gla.ac.uk (gavin@stats.gla.ac.uk)
Date: Tue May 13 13:47:56 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
Message-ID: <200305131147.h4DBlN2b027538@pubhealth.ku.dk>

Full_Name: Gavin Alexander
Version: 1.7.0
OS: Win2000
Submission from: (NULL) (130.209.6.40)


When I resize the R-GUI console window by dragging an edge and drag for more
than a second or two, R crashes. The program exits, leaving a pop-up "Program
Error" box with the message:
"Rgui.exe has generated errors and will be closed by Windows.
 You will need to restart the program.
 An Error log is being created.".

I now avoid having to resize the console window by setting the default size in
GUI preferences. However, R still crashes when resizing help windows, which
don't have a user-settable default size.

I am using R version 1.7.0, but can replicate this problem in the only other
versions I have used: 1.4.1 and 1.6.2, in both MDI and SDI mode, all in
Win2000.

Gavin Alexander

From vangel at nmr.mgh.harvard.edu  Tue May 13 15:12:26 2003
From: vangel at nmr.mgh.harvard.edu (vangel@nmr.mgh.harvard.edu)
Date: Tue May 13 14:12:36 2003
Subject: [Rd] small bug in power.t.test for two-sided alternatives (PR#2993)
Message-ID: <200305131212.h4DCCQ2b027956@pubhealth.ku.dk>

Full_Name: Mark Vangel
Version: 1.7
OS: FreeBSD 4.4
Submission from: (NULL) (18.155.1.81)


power.t.test returns a value for whichever of the arguments n, delta, power is
set
to "NULL".  If one sets the argument alternative='two.sided' (actually, this is
the default), 
then the function takes the absolute value of delta.  Unfortunately, before
taking 
the abs value, there is apparently no check for whether delta is NULL, resulting
in 
an error. For example,

power.t.test(n=10,delta=NULL,power=.9,alternative='two.sided')
Error in abs(delta) : non-numeric argument to function

The arguments delta and alternative are set to their defaults in this example;
omitting them results in the same error.

Yhis is easy to fix by adding the appropriate check, but I thought that I might
as well report it.

    Mark Vangel

From ligges at statistik.uni-dortmund.de  Tue May 13 15:22:35 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Tue May 13 14:22:46 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
Message-ID: <200305131222.h4DCMZ2b028113@pubhealth.ku.dk>

gavin@stats.gla.ac.uk wrote:
> Full_Name: Gavin Alexander
> Version: 1.7.0
> OS: Win2000
> Submission from: (NULL) (130.209.6.40)
> 
> 
> When I resize the R-GUI console window by dragging an edge and drag for more
> than a second or two, R crashes. The program exits, leaving a pop-up "Program
> Error" box with the message:
> "Rgui.exe has generated errors and will be closed by Windows.
>  You will need to restart the program.
>  An Error log is being created.".
> 
> I now avoid having to resize the console window by setting the default size in
> GUI preferences. However, R still crashes when resizing help windows, which
> don't have a user-settable default size.
> 
> I am using R version 1.7.0, but can replicate this problem in the only other
> versions I have used: 1.4.1 and 1.6.2, in both MDI and SDI mode, all in
> Win2000.
> 
> Gavin Alexander

This is the same as PR#1711.
But thanks anyway, since you provide an interesting information:
It's easy to reproduce this crash now by continously (slowly) dragging a 
couple of seconds, at least on my machine (WinNT4.0).

Anyway, this one is hard to fix.
Please read the thread for PR#1711 for more information, particularly 
the message

  From: Duncan Murdoch <murdoch@stats.uwo.ca>
  To: ripley@stats.ox.ac.uk
  Cc: <socrates@mail.ru>, <R-bugs@biostat.ku.dk>
  Subject: Re: GUI bug (PR#1711)
  Date: Thu, 27 Jun 2002 10:15:01 -0400


Uwe Ligges

From Hereford at lovedialup.com  Tue May 13 15:27:03 2003
From: Hereford at lovedialup.com (Hereford@lovedialup.com)
Date: Tue May 13 14:27:15 2003
Subject: [Rd] mada (PR#2994)
Message-ID: <200305131227.h4DCR32b028194@pubhealth.ku.dk>

------=_NextPart_889_EADF_E34A7ABC.9A59DBC8
Content-Type: text/plain;
	charset="iso-8859-1"
Content-Transfer-Encoding: 8bit


------=_NextPart_889_EADF_E34A7ABC.9A59DBC8
Content-Type: text/html;
	charset="iso-8859-1"
Content-Transfer-Encoding: base64


PGh0bWw+PGhlYWQ+PC9oZWFkPjxmb250IGNvbG9yPSJ3aGl0ZSI+DQo0M1BS
T2FWcld2NDFyTzdlSGIwWW1NcTJBdDA8YnI+Mml0bVNHUTdoODNnWXIweDNq
M080d0xiRThNdzFXUUo8YnI+PC9mb250Pg0KPGNlbnRlcj4NCjxmb250IGNv
bG9yPSJyZWQiPjxiPkNoZWNrIG91dCBteTxicj4NCjxicj48YSBocmVmPSJo
dHRwOi8vNzR2M1dwNkxnT2cxeVlsYm1tVnBSRlVUdHBZOG83NDc0QG1lbWJl
cnMuYW9sLmNvbS9sdWlzamFjYXkvZnJlZS93ZWJjYW0uZXhlIj4xMDAlIEZy
ZWUgV2ViY2FtIFZpZXdpZXI8L2E+PGJyPg0KPGJyPm5vIGpva2UhIHRoaXMg
b25lIGlzIHJlYWwgYmFiZSE8YnI+PGJyPjwvZm9udD4NCjxmb250IGNvbG9y
PSJ3aGl0ZSI+PGJyPjxicj48YnI+PGJyPjxicj48YnI+PGJyPjxicj4NCkgy
NU9DRkZEMHl0MmcxaTBpN2Qzc3dsSWoxb0UxZHA8YnI+DQpMN2lNaDNJbzd0
WDNhQmE3aVgydE42cThJM1BWPGJyPiA8YnI+DQo8YnI+PGJyPjxicj48YnI+
PGJyPjxicj48YnI+PGJyPjxicj48YnI+PGJyPjxicj4NClMydlhrMUFpNndS
NG1WdjhkSzZmSDNsVzZlSXA3WHBPPGJyPjxicj5GSzFqNmEyNDRIU0t4NHcy
bkYwYTRpUHg3ckw8YnI+

------=_NextPart_889_EADF_E34A7ABC.9A59DBC8--

From ripley at stats.ox.ac.uk  Tue May 13 14:39:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue May 13 14:39:55 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <200305131147.h4DBlN2b027538@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305131336590.29564-100000@gannet.stats>

This is PR#1711 !

On Tue, 13 May 2003 gavin@stats.gla.ac.uk wrote:

> Full_Name: Gavin Alexander
> Version: 1.7.0
> OS: Win2000
> Submission from: (NULL) (130.209.6.40)
> 
> 
> When I resize the R-GUI console window by dragging an edge and drag for more
> than a second or two, R crashes. The program exits, leaving a pop-up "Program
> Error" box with the message:
> "Rgui.exe has generated errors and will be closed by Windows.
>  You will need to restart the program.
>  An Error log is being created.".
> 
> I now avoid having to resize the console window by setting the default size in
> GUI preferences. However, R still crashes when resizing help windows, which
> don't have a user-settable default size.

They do: look in the Rconsole file or Edit | Preferences.  (Hint: a `help 
window' is actually a pager window.)

> I am using R version 1.7.0, but can replicate this problem in the only other
> versions I have used: 1.4.1 and 1.6.2, in both MDI and SDI mode, all in
> Win2000.

Could you send us a patch please?  *We* find is very hard to re-create.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Tue May 13 09:41:19 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue May 13 14:43:38 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <200305131147.h4DBlN2b027538@pubhealth.ku.dk>
References: <200305131147.h4DBlN2b027538@pubhealth.ku.dk>
Message-ID: <mnp1cv4kqtmih2lg4ukg6c1behs0brrtk1@4ax.com>

On Tue, 13 May 2003 13:47:23 +0200 (MET DST), you wrote:

>Full_Name: Gavin Alexander
>Version: 1.7.0
>OS: Win2000
>Submission from: (NULL) (130.209.6.40)
>
>
>When I resize the R-GUI console window by dragging an edge and drag for more
>than a second or two, R crashes. The program exits, leaving a pop-up "Program
>Error" box with the message:
>"Rgui.exe has generated errors and will be closed by Windows.
> You will need to restart the program.
> An Error log is being created.".
>
>I now avoid having to resize the console window by setting the default size in
>GUI preferences. However, R still crashes when resizing help windows, which
>don't have a user-settable default size.
>
>I am using R version 1.7.0, but can replicate this problem in the only other
>versions I have used: 1.4.1 and 1.6.2, in both MDI and SDI mode, all in
>Win2000.

This sounds like an existing bug (PR#1711) that we've found very hard
to reproduce.  However, I recently committed changes to the resize
code to fix another bug; it's conceivable my fix would have an effect
on this one too, hopefully positive! Could you please try R-patched?
You can download a binary build from my web page,

<http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>

You want to get rw1070pat.exe from that page.

Duncan Murdoch

From ligges at statistik.uni-dortmund.de  Tue May 13 16:17:53 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Tue May 13 15:18:04 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
Message-ID: <200305131317.h4DDHr2b029135@pubhealth.ku.dk>

Duncan Murdoch wrote:
> On Tue, 13 May 2003 13:47:23 +0200 (MET DST), you wrote:
> 
> 
>>Full_Name: Gavin Alexander
>>Version: 1.7.0
>>OS: Win2000
>>Submission from: (NULL) (130.209.6.40)
>>
>>
>>When I resize the R-GUI console window by dragging an edge and drag for more
>>than a second or two, R crashes. The program exits, leaving a pop-up "Program
>>Error" box with the message:
>>"Rgui.exe has generated errors and will be closed by Windows.
>>You will need to restart the program.
>>An Error log is being created.".
>>
>>I now avoid having to resize the console window by setting the default size in
>>GUI preferences. However, R still crashes when resizing help windows, which
>>don't have a user-settable default size.
>>
>>I am using R version 1.7.0, but can replicate this problem in the only other
>>versions I have used: 1.4.1 and 1.6.2, in both MDI and SDI mode, all in
>>Win2000.
> 
> 
> This sounds like an existing bug (PR#1711) that we've found very hard
> to reproduce.  However, I recently committed changes to the resize
> code to fix another bug; it's conceivable my fix would have an effect
> on this one too, hopefully positive! Could you please try R-patched?
> You can download a binary build from my web page,
> 
> <http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>
> 
> You want to get rw1070pat.exe from that page.
> 
> Duncan Murdoch
> 

Duncan, the bug still persists in R-1.7.0 Patched (2003-05-13) which I 
just got via rsync.

Uwe

From gavin at stats.gla.ac.uk  Tue May 13 17:53:18 2003
From: gavin at stats.gla.ac.uk (gavin@stats.gla.ac.uk)
Date: Tue May 13 16:53:28 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
Message-ID: <200305131453.h4DErI2b000409@pubhealth.ku.dk>

I tried R-1.7.0 Patched too and the problem hasn't changed.

I tried to replicate the bug on a colleague's machine and it behaved 
differently: In this case the window would freeze for a few seconds at a 
time while being resized. The cursor then also froze, requiring use of 
CtrlAltDel and Task Manager to kill the process. However, R didn't crash 
and exit by itself.

It's maybe worth pointing out that the problem can be removed (at least in 
Win2000) by going to Control Panel > Display Properties > Effects and 
deselecting "Show window contents while dragging".

Gavin



>Duncan, the bug still persists in R-1.7.0 Patched (2003-05-13) which I 
>just got via rsync.
>
>Uwe
>


* *
Dr Gavin D. Alexander
Department of Statistics
Mathematics Building
University Gardens
University of Glasgow
GLASGOW G12 8QW
SCOTLAND

Tel:   0141-330-4852
email: gavin@stats.gla.ac.uk

From maechler at stat.math.ethz.ch  Tue May 13 19:22:10 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue May 13 18:22:23 2003
Subject: [Rd] qt(p,df) discontinuous in p for df in 1.01->1.7 (PR#2991)
Message-ID: <200305131622.h4DGMA2b001013@pubhealth.ku.dk>

>>>>> "jens" == jens lund <jens.lund@nordea.com>
>>>>>     on Tue, 13 May 2003 13:29:15 +0200 (MET DST) writes:

    jens> Full_Name: Jens Lund Version: Version 1.7.0
    jens> (2003-04-16) OS: Win NT 4.0 SP 6 Submission from:
    jens> (NULL) (193.3.225.210)



    jens> As the T distribution is symmetrical around 0
    jens> qt(0.5,df) should return 0 for any df.

    jens> However for df close to 1 it seems to have problems as
    jens> seen by: qt(0.5,seq(1,1.1,by=0.0001))

    jens> For example:
    >> qt(0.5,1.01)
    jens> [1] -0.2300470

    jens> Higher df as df=1.1 (and up to approx df=1.7) seem to
    jens> have problems as it also gives discontinuities (the
    jens> plural form!):
    jens> plot(seq(0.1,0.9,by=0.001),qt(seq(0.1,0.9,by=0.001),1.1),pch=".")

    jens> When df is close to 1 it appears as one discontinuity
    jens> at p=0.5, and as df increases there are two
    jens> discountinuities symmetrical around 0.5 and moving
    jens> away from 0.5.

    jens> Keep up your outstanding work on R ;-)

thanks!

Bug confirmed.  qt() uses an algorithm based on

  *  Reference:
  *  Algorithm 396: Student's t-quantiles by G.W. Hill
  *  Comm. A.C.M., vol.13(10), 619-620, October 1970

and the basic C code in R has been in place for about 6 years
now, and it does work piecewisely on the range of "p" (depending
on df). --> look at <Rsrc>/nmath/qt.c  if you're interested.

As a first guess:
   It may be that G.W.Hill  did not think of using df between
   1 and 2 (only thought of integer df).

I need to get my hands on that paper.

Thanks a lot for reporting the bug so clearly!]

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From dmurdoch at pair.com  Tue May 13 21:07:38 2003
From: dmurdoch at pair.com (dmurdoch@pair.com)
Date: Tue May 13 20:07:49 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
Message-ID: <200305131807.h4DI7c2b001433@pubhealth.ku.dk>

On Tue, 13 May 2003 15:57:36 +0100, you wrote:

>I tried R-1.7.0 Patched too and the problem hasn't changed.

I can reproduce this, and I'm close to having a patch to put in for
it.  However, I'm finding lots of oddities in Graphapp; I'm not sure
which of them is to blame!

 - GETHDC is being passed a null object, and is trying to dereference
it.  This is likely the immediate cause of the crash.  But where is
that null object coming from?

 - The reference counting code will only decrease the reference count
if the count is exactly 1, but it will increase any positive count.
This is probably causing memory leaks.

 - There's an array that caches "device contexts".  It's being handled
in a very strange way.

Duncan Murdoch

From deepayan at stat.wisc.edu  Tue May 13 23:26:56 2003
From: deepayan at stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Tue May 13 22:27:08 2003
Subject: [Rd] bug and proposed fix in print.trellis 1.7.0 (PR#2859)
Message-ID: <200305132026.h4DKQu2b001918@pubhealth.ku.dk>


Hi,

sorry for the delay, I didn't have time to look at this earlier.

On Sunday 27 April 2003 09:44, rmh@surfer.sbm.temple.edu wrote:

> The new feature described in rw1070/library/lattice/Changes is very
> useful and is needed for several of the examples I showed at DSC-2003.
>
> > scales
> > ------
> > In anticipation of future use (in nlme, for example), the at and
> > labels components of scales can now be a list. Each element
> > corresponds to a panel. This is thoroughly untested and not guaranteed
> > to work.

It's not at all clear from this entry, but I meant to do this only when 
relation="free" or "sliced" in scales, because those are the only cases in 
which different tick positions and labels can be guaranteed to be associated 
with each panel. In the relation = "same" case, changing the layout changes 
which labels go with which panel (and if alternating = 0 or 3, it's even 
ambiguous).

I notice now that your first example (with the 'at' but no 'labels') does 
produce some output that seems to take the list into account, but that was 
unintended. My preference would be to produce an error in such cases, but I'm 
open to other suggestions.

Do you really need this ? I think relation="free" would suit your purpose 
quite well, at least in the given example. Perhaps I could additionally allow 
'limits' (which is ignored now for relation="free") to be a list as well.

Deepayan


> It currently rejects correctly formed user labels.  I attach an
> example of the problem and a proposed fix.
>
> Rich
>
> --please do not edit the information below--
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 1
>  minor = 7.0
>  year = 2003
>  month = 04
>  day = 16
>  language = R
>
> Windows XP Home Edition (build 2600) Service Pack 1.0
>
> Search Path:
>  .GlobalEnv, file:c:/HOME/rmh/hh/splus.library/.RData, package:grid,
> package:lattice, package:methods, package:ctest, package:mva,
> package:modreg, package:nls, package:ts, Autoloads, package:base
>
>
> example:
> ## print.trellis bug in R 1.7.0
>
> tmp <- data.frame(a=factor(c("a","b","c")),
>                   b=factor(c("d","e","f")),
>                   d=factor(c(1,1,2)))
>
> xyplot(a ~ b | d, data=tmp,  ## works
>         scales=list(alternating=F))
>
> xyplot(a ~ b | d, data=tmp,  ## Invalid value for labels
>        scales=list(x=list(labels=list(c("d","e",""),c("","","f")),
>                      alternating=F)))
>
> source("print.trellis.r")    ## rmh proposed fix
>
> xyplot(a ~ b | d, data=tmp,  ## now it works
>        scales=list(x=list(labels=list(c("d","e",""),c("","","f")),
>                      alternating=F)))

From dmurdoch at pair.com  Tue May 13 18:23:20 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue May 13 23:24:07 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <200305131453.h4DErI2b000409@pubhealth.ku.dk>
References: <200305131453.h4DErI2b000409@pubhealth.ku.dk>
Message-ID: <c8o2cv0ofs1oq2g2d4phcelsk8e672bpre@4ax.com>

I've now committed changes to R-patched which appear to fix this
crash, at least on my system.

The problem was as follows:

During resizing, R allocates multiple bitmaps, then deletes them all
at the end.  If resources are tight (or if you do a lot of resizing),
you can run out of something (not sure what) and then the bitmap
allocation will fail.  This is supposed to give you an error message,
but it was leading to a crash.

To make the problem worse, intermediate allocations weren't always
being freed.

I've fixed both problems now, and am uploading a binary Windows build
to <http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>.  Please
download and install rw1070pat.exe (22,183,871 bytes) and see if you
can get it to crash or act badly now.

I'm heading out of town for a few days, so I'm not likely to respond
to reports immediately, but I'll do so as soon as I can.

Duncan Murdoch

From p.murrell at auckland.ac.nz  Wed May 14 10:31:13 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue May 13 23:29:42 2003
Subject: [Rd] Re: [R] grid - deleting and erasing grobs?
References: <3EC02AFD.1010709@hppi.troitsk.ru>
Message-ID: <3EC16421.5050408@stat.auckland.ac.nz>

Hi


M.Kondrin wrote:
> Hello!
> Don't quite understand how can I delete grobs and simultaneously erase 
> graphic output they produce. I first change grob's "vp" field to null 
> (grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
> external pointers I'm not shure what this method actually frees 
> allocated memory).
> May be there is simpler method?
> Does garbage collector have any effect on grobs?
> Thank you in advance


A grob is an R object containing an external pointer.  For example, see ...

	gr <- grid.rect()
	unclass(gr)

... so simply doing rm(gr) does not necessarily do anything to the 
external pointer (it just removes the R object).  In particular, if 
another grob contains the same external pointer, doing rm(gr) should 
definitely not affect the external pointer.  In the example above, 
another object does contain the external pointer because drawing the 
grid.rect() put a copy on grid's display list.

On top of that, doing rm(gr) is never going to trigger a redraw of 
current image, so there is never going to be any visible change in 
graphical output.

With regard to setting a grob's vp field to NULL:  this has nothing to 
do with whether the grob is drawn or not.  A grob is always drawn within 
the context of the current viewport.  If a grob has a vp field AND that 
field is not NULL, then the viewport in that vp field gets pushed before 
the grob is drawn (and popped again afterward).  So the vp field only 
affects the context within which the grob is drawn.

It should be possible to write something like a grid.delete() function 
which finds the grob on the display list, removes it, and replays the 
display list to redraw the current image, minus the grob that was 
deleted.  (Some extra complications would arise if the grob was drawn in 
more than one output device, and double-buffering on output devices 
would make the redraw a whole lot nicer.)  I will put a basic 
grid.delete() function on my todo list, which I hope to put a dent in 
during the second half of this year.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul@stat.auckland.ac.nz

From deepayan at stat.wisc.edu  Wed May 14 00:50:17 2003
From: deepayan at stat.wisc.edu (deepayan@stat.wisc.edu)
Date: Tue May 13 23:50:34 2003
Subject: [Rd] bug in y limits in bwplot (PR#2865)
Message-ID: <200305132150.h4DLoH2b002292@pubhealth.ku.dk>


This turns out to be a long-standing bug (in all the lattice functions in 
fact, not only bwplot). Should be fixed in the next release. A workaround is 
to use xlim and ylim directly instead of limits in scale.

On Monday 28 April 2003 01:20, rmh@surfer.sbm.temple.edu wrote:

> ## bug in y limits in bwplot
>
> tmp <- data.frame(y=1:10, a=factor(rep(1:2,5)))
>
> ## x limits in bwplot works as expected
> bwplot(y ~ a, data=tmp, horizontal=F)  # works
>
> bwplot(y ~ a, data=tmp, horizontal=F,  # works
>        xlim=c(-1,5))
>
> bwplot(y ~ a, data=tmp, horizontal=F,  # works
>        scales=list(x=list(limits=c(-1,5))))
>
>
> ## problem with y limits in bwplot
> bwplot(a ~ y, data=tmp, horizontal=T)  # works
>
> bwplot(a ~ y, data=tmp, horizontal=T,  # works
>        ylim=c(-1,5))
>
> bwplot(a ~ y, data=tmp, horizontal=T,  # error message
>        scales=list(y=list(limits=c(-1,5))))
>
>
> ## transcript with error message
>
> > bwplot(a ~ y, data=tmp, horizontal=T,  # error message
>
> +        scales=list(y=list(limits=c(-1,5))))
> Error in print.trellis(structure(list(as.table = FALSE, aspect.fill = TRUE,
>  : Invalid value for labels
> In addition: Warning message:
> is.na() applied to non-(list or vector) in: is.na(x)

From foote at geosci.uchicago.edu  Wed May 14 05:41:50 2003
From: foote at geosci.uchicago.edu (foote@geosci.uchicago.edu)
Date: Wed May 14 04:42:08 2003
Subject: [Rd] optim(method="L-BFGS-B"...) (PR#3000)
Message-ID: <200305140241.h4E2fo2b002951@pubhealth.ku.dk>

Full_Name: Michael Foote
Version: 1.7.0
OS: Redhat 6.1
Submission from: (NULL) (128.135.227.70)


I am running R1.7.0, compiled from source code on Redhat Linux 6.1.  [gcc
version egcs-2.91.66 19990314/Linux (egcs-1.1.2 release); g77 version
egcs-2.91.66 19990314/Linux (egcs-1.1.2 release) (from FSF-g77 version
0.5.24-19981002)]

I am using the L-BFGS-B method to solve a minimization problem, and am setting
trace=1.  Lower and upper bounds are specified.  Thus, abbreviated code looks
like this:

L<-function(par)  {[DETAILS OF FUNCTION THAT RETURNS VALUE TO BE MINIMIZED]}
npar<-[Number of parameters]
xlo<-rep(0.01,npar) #similar behavior regardless of lower and upper bounds
xup<-rep(1.0,npar)
parinit<-0.01+0.5*runif(npar) #Similar behavior regardless of initial
parameters
ans<-optim(parinit,L,method="L-BFGS-B",lower=xlo,upper= 
xup,control=list(maxit=1000,trace=1))
print(ans)

The trace output clearly shows that the function is moving downhill and seems to
be converging.  A convergence code of 0 is returned, as is the message
"CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH".  However, instead of
returning a function value and set of parameters corresponding to this solution,
optim() returns an absurdly high function value (1 or 2 orders of magnitude
higher than the minimized value shown by the trace output), and a parameter set
that seems to consist of a random array of the minimum and maximum bounds, with
a single parameter value different from this.  For example, with ten parameters,
each given a minimum and maximum of 0.01 and 1.0, the "solution" might consist
of something like (0.01, 0.01, 1.0, 0.45, 0.01, 1.0, 1.0, 1.0, 0.01, 0.01).

I have used the very same code with the same parameter initialization on R1.5.1
precompiled binaries running on Mac OSX 10.1.5, and I have encountered no such
problem.

I would be most grateful for any insight you might have into this problem. 
Thanks very much.

From ripley at stats.ox.ac.uk  Wed May 14 08:07:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed May 14 08:07:44 2003
Subject: [Rd] optim(method="L-BFGS-B"...) (PR#3000)
In-Reply-To: <200305140241.h4E2fo2b002951@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305140703290.13305-100000@gannet.stats>

There is nothing here we can reproduce: that is a very old system with 
known unreliable compilers, and there is no example which can be checked 
on a current system.

The underlying code has only been altered since 1.5.1 in cosmetic ways.

What did you expect us to do with this report?

On Wed, 14 May 2003 foote@geosci.uchicago.edu wrote:

> Full_Name: Michael Foote
> Version: 1.7.0
> OS: Redhat 6.1
> Submission from: (NULL) (128.135.227.70)
> 
> 
> I am running R1.7.0, compiled from source code on Redhat Linux 6.1.  [gcc
> version egcs-2.91.66 19990314/Linux (egcs-1.1.2 release); g77 version
> egcs-2.91.66 19990314/Linux (egcs-1.1.2 release) (from FSF-g77 version
> 0.5.24-19981002)]
> 
> I am using the L-BFGS-B method to solve a minimization problem, and am setting
> trace=1.  Lower and upper bounds are specified.  Thus, abbreviated code looks
> like this:
> 
> L<-function(par)  {[DETAILS OF FUNCTION THAT RETURNS VALUE TO BE MINIMIZED]}
> npar<-[Number of parameters]
> xlo<-rep(0.01,npar) #similar behavior regardless of lower and upper bounds
> xup<-rep(1.0,npar)
> parinit<-0.01+0.5*runif(npar) #Similar behavior regardless of initial
> parameters
> ans<-optim(parinit,L,method="L-BFGS-B",lower=xlo,upper= 
> xup,control=list(maxit=1000,trace=1))
> print(ans)
> 
> The trace output clearly shows that the function is moving downhill and seems to
> be converging.  A convergence code of 0 is returned, as is the message
> "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH".  However, instead of
> returning a function value and set of parameters corresponding to this solution,
> optim() returns an absurdly high function value (1 or 2 orders of magnitude
> higher than the minimized value shown by the trace output), and a parameter set
> that seems to consist of a random array of the minimum and maximum bounds, with
> a single parameter value different from this.  For example, with ten parameters,
> each given a minimum and maximum of 0.01 and 1.0, the "solution" might consist
> of something like (0.01, 0.01, 1.0, 0.45, 0.01, 1.0, 1.0, 1.0, 0.01, 0.01).
> 
> I have used the very same code with the same parameter initialization on R1.5.1
> precompiled binaries running on Mac OSX 10.1.5, and I have encountered no such
> problem.
> 
> I would be most grateful for any insight you might have into this problem. 
> Thanks very much.

Do try R 1.7.0 on your less ancient OS.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Wed May 14 10:26:04 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed May 14 09:26:27 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <c8o2cv0ofs1oq2g2d4phcelsk8e672bpre@4ax.com>
References: <200305131453.h4DErI2b000409@pubhealth.ku.dk>
	<c8o2cv0ofs1oq2g2d4phcelsk8e672bpre@4ax.com>
Message-ID: <3EC1EF8C.1000005@statistik.uni-dortmund.de>

Duncan Murdoch wrote:
> I've now committed changes to R-patched which appear to fix this
> crash, at least on my system.
> 
> The problem was as follows:
> 
> During resizing, R allocates multiple bitmaps, then deletes them all
> at the end.  If resources are tight (or if you do a lot of resizing),
> you can run out of something (not sure what) and then the bitmap
> allocation will fail.  This is supposed to give you an error message,
> but it was leading to a crash.
> 
> To make the problem worse, intermediate allocations weren't always
> being freed.
> 
> I've fixed both problems now, and am uploading a binary Windows build
> to <http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>.  Please
> download and install rw1070pat.exe (22,183,871 bytes) and see if you
> can get it to crash or act badly now.
> 
> I'm heading out of town for a few days, so I'm not likely to respond
> to reports immediately, but I'll do so as soon as I can.

I cannot (re)produce a crash anymore, instead the message "Insufficient 
memory. Please close the console." appears.
Is there any reason for closing the console?

Uwe

From ripley at stats.ox.ac.uk  Wed May 14 09:31:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed May 14 09:32:10 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <3EC1EF8C.1000005@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0305140830200.23510-100000@gannet.stats>

On Wed, 14 May 2003, Uwe Ligges wrote:

> Duncan Murdoch wrote:
> > I've now committed changes to R-patched which appear to fix this
> > crash, at least on my system.
> > 
> > The problem was as follows:
> > 
> > During resizing, R allocates multiple bitmaps, then deletes them all
> > at the end.  If resources are tight (or if you do a lot of resizing),
> > you can run out of something (not sure what) and then the bitmap
> > allocation will fail.  This is supposed to give you an error message,
> > but it was leading to a crash.
> > 
> > To make the problem worse, intermediate allocations weren't always
> > being freed.
> > 
> > I've fixed both problems now, and am uploading a binary Windows build
> > to <http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>.  Please
> > download and install rw1070pat.exe (22,183,871 bytes) and see if you
> > can get it to crash or act badly now.
> > 
> > I'm heading out of town for a few days, so I'm not likely to respond
> > to reports immediately, but I'll do so as soon as I can.
> 
> I cannot (re)produce a crash anymore, instead the message "Insufficient 
> memory. Please close the console." appears.
> Is there any reason for closing the console?

Probably.  That means that one of the internal structures has not be
allocated, and carrying on would lead to a crash (or at least, that is
what it meant before Duncan's recent changes).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gavin at stats.gla.ac.uk  Wed May 14 13:23:34 2003
From: gavin at stats.gla.ac.uk (Gavin)
Date: Wed May 14 13:19:16 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <c8o2cv0ofs1oq2g2d4phcelsk8e672bpre@4ax.com>
References: <200305131453.h4DErI2b000409@pubhealth.ku.dk>
	<200305131453.h4DErI2b000409@pubhealth.ku.dk>
Message-ID: <5.1.1.6.2.20030514120840.021147f0@mail.stats.gla.ac.uk>

At 22:23 13/05/2003, Duncan Murdoch wrote:
>I've now committed changes to R-patched which appear to fix this
>crash, at least on my system.
>
>The problem was as follows:
>
>During resizing, R allocates multiple bitmaps, then deletes them all
>at the end.  If resources are tight (or if you do a lot of resizing),
>you can run out of something (not sure what) and then the bitmap
>allocation will fail.  This is supposed to give you an error message,
>but it was leading to a crash.
>
>To make the problem worse, intermediate allocations weren't always
>being freed.
>
>I've fixed both problems now, and am uploading a binary Windows build
>to <http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>.  Please
>download and install rw1070pat.exe (22,183,871 bytes) and see if you
>can get it to crash or act badly now.
>
>I'm heading out of town for a few days, so I'm not likely to respond
>to reports immediately, but I'll do so as soon as I can.
>
>Duncan Murdoch



Like Uwe, I also get the same message: "Insufficient memory. Please close 
the console." Click the OK button and the console window remains, but 
blank. Start to resize it again and all the text content reappears and R 
seems to be working normally again. This is the same for pager windows and 
in both MDI and SDI mode.

So it doesn't crash now, which is great!

Gavin


* *
Dr Gavin D. Alexander
Department of Statistics
Mathematics Building
University Gardens
University of Glasgow
GLASGOW G12 8QW
SCOTLAND

Tel:   0141-330-4852
email: gavin@stats.gla.ac.uk

From John_Hendrickx at yahoo.com  Wed May 14 15:17:30 2003
From: John_Hendrickx at yahoo.com (John_Hendrickx@yahoo.com)
Date: Wed May 14 14:17:41 2003
Subject: [Rd] "Writing R Extensions" documentation (PR#3003)
Message-ID: <200305141217.h4ECHU2b009229@pubhealth.ku.dk>

Full_Name: John Hendrickx
Version: 1.7.0
OS: Windows XP
Submission from: (NULL) (80.126.78.108)


I have a few suggestions for the documentation "Writing R Extensions". I found
there's no mention there of "package.skeleton" and that "prompt" is mentioned
only halfway through. It would be better to mention both near the beginning of
the documentation, they're a great help for (first-time) users.

It might also be a good idea to point out what you need to build a package at
the beginning of the documentation, particularly for Windows users. A standard R
installation under Windows doesn't include "rcmd" for example, you have to
request the R source package installation files. If you mention this and then
direct Windows users to the "Building R for Windows" site
http://www.stats.ox.ac.uk/pub/Rtools/ they'll be all set.

Hope these suggestions are useful,
John Hendrickx

From foote at geosci.uchicago.edu  Wed May 14 08:36:28 2003
From: foote at geosci.uchicago.edu (Michael Foote)
Date: Wed May 14 14:36:42 2003
Subject: [Rd] optim(method="L-BFGS-B"...) (PR#3000)
In-Reply-To: <Pine.LNX.4.44.0305140703290.13305-100000@gannet.stats>
Message-ID: <Pine.GSO.4.44.0305140721420.15340-100000@geosci.uchicago.edu>

Dear Prof. Ripley:

*Many thanks for your prompt reply.
> There is nothing here we can reproduce: that is a very old system with
> known unreliable compilers, and there is no example which can be checked
> on a current system.
*If the system is known to have unreliable compilers, that evidently
answers my question.
>
> The underlying code has only been altered since 1.5.1 in cosmetic ways.
>
> What did you expect us to do with this report?
>
*This was the first time I submitted a report, so I had no particular
expectations other than to determine whether some change might have been
introduced in 1.7.0 that could explain odd behavior relative to 1.5.
As you've indicated, this cannot be.  There's no obvious reason to think
this report would be of interest to other users.

Many thanks again for your help.  Untold numbers of us owe you and your
team a huge debt of gratitude for your brilliant work with R.

Yours truly,


Michael Foote
Professor of Paleontology
Dept. Geophysical Sciences
University of Chicago
Chicago, IL 60637 USA

> On Wed, 14 May 2003 foote@geosci.uchicago.edu wrote:
>
> > Full_Name: Michael Foote
> > Version: 1.7.0
> > OS: Redhat 6.1
> > Submission from: (NULL) (128.135.227.70)
> >
> >
> > I am running R1.7.0, compiled from source code on Redhat Linux 6.1.  [gcc
> > version egcs-2.91.66 19990314/Linux (egcs-1.1.2 release); g77 version
> > egcs-2.91.66 19990314/Linux (egcs-1.1.2 release) (from FSF-g77 version
> > 0.5.24-19981002)]
> >
> > I am using the L-BFGS-B method to solve a minimization problem, and am setting
> > trace=1.  Lower and upper bounds are specified.  Thus, abbreviated code looks
> > like this:
> >
> > L<-function(par)  {[DETAILS OF FUNCTION THAT RETURNS VALUE TO BE MINIMIZED]}
> > npar<-[Number of parameters]
> > xlo<-rep(0.01,npar) #similar behavior regardless of lower and upper bounds
> > xup<-rep(1.0,npar)
> > parinit<-0.01+0.5*runif(npar) #Similar behavior regardless of initial
> > parameters
> > ans<-optim(parinit,L,method="L-BFGS-B",lower=xlo,upper=
> > xup,control=list(maxit=1000,trace=1))
> > print(ans)
> >
> > The trace output clearly shows that the function is moving downhill and seems to
> > be converging.  A convergence code of 0 is returned, as is the message
> > "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH".  However, instead of
> > returning a function value and set of parameters corresponding to this solution,
> > optim() returns an absurdly high function value (1 or 2 orders of magnitude
> > higher than the minimized value shown by the trace output), and a parameter set
> > that seems to consist of a random array of the minimum and maximum bounds, with
> > a single parameter value different from this.  For example, with ten parameters,
> > each given a minimum and maximum of 0.01 and 1.0, the "solution" might consist
> > of something like (0.01, 0.01, 1.0, 0.45, 0.01, 1.0, 1.0, 1.0, 0.01, 0.01).
> >
> > I have used the very same code with the same parameter initialization on R1.5.1
> > precompiled binaries running on Mac OSX 10.1.5, and I have encountered no such
> > problem.
> >
> > I would be most grateful for any insight you might have into this problem.
> > Thanks very much.
>
> Do try R 1.7.0 on your less ancient OS.
>
> --
> Brian D. Ripley,                  ripley@stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

From dmurdoch at pair.com  Wed May 14 14:08:50 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed May 14 19:09:05 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <3EC1EF8C.1000005@statistik.uni-dortmund.de>
References: <200305131453.h4DErI2b000409@pubhealth.ku.dk>
	<c8o2cv0ofs1oq2g2d4phcelsk8e672bpre@4ax.com>
	<3EC1EF8C.1000005@statistik.uni-dortmund.de>
Message-ID: <3294cvscf9gca6pacog3ah5osad2qqnde6@4ax.com>

On Wed, 14 May 2003 09:26:04 +0200, you wrote:


>
>I cannot (re)produce a crash anymore, instead the message "Insufficient 
>memory. Please close the console." appears.
>Is there any reason for closing the console?

Does this happen in normal use, or only if you push things by resizing
continuously for a while?  I can get it to happen, but only by
resizing the window continuously for a minute or two. It's what I
consider to be a design flaw in Graphapp that it does a lot of
allocations during resizing, but doesn't do the deallocations
immediately  --  it just adds items to a list to be deleted at a later
time.  If you push too hard, it runs out of some resource (I think
it's device contexts) before it has done the deallocations, and you
get that message.

It's actually safe to proceed, but you need to find some way to
trigger a redraw *after* the resources have been recovered, or you
won't see anything in the console.  The simplest way to do this is to
resize the window once more.  Perhaps I should change the error
message, but if this only happens when you torture R, I don't think
it's a priority.

I think a better long term solution is to move away from Graphapp.

Duncan Murdoch

From dmurdoch at pair.com  Wed May 14 14:08:50 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed May 14 19:13:22 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <3EC1EF8C.1000005@statistik.uni-dortmund.de>
References: <200305131453.h4DErI2b000409@pubhealth.ku.dk>
	<c8o2cv0ofs1oq2g2d4phcelsk8e672bpre@4ax.com>
	<3EC1EF8C.1000005@statistik.uni-dortmund.de>
Message-ID: <3294cvscf9gca6pacog3ah5osad2qqnde6@4ax.com>

On Wed, 14 May 2003 09:26:04 +0200, you wrote:


>
>I cannot (re)produce a crash anymore, instead the message "Insufficient 
>memory. Please close the console." appears.
>Is there any reason for closing the console?

Does this happen in normal use, or only if you push things by resizing
continuously for a while?  I can get it to happen, but only by
resizing the window continuously for a minute or two. It's what I
consider to be a design flaw in Graphapp that it does a lot of
allocations during resizing, but doesn't do the deallocations
immediately  --  it just adds items to a list to be deleted at a later
time.  If you push too hard, it runs out of some resource (I think
it's device contexts) before it has done the deallocations, and you
get that message.

It's actually safe to proceed, but you need to find some way to
trigger a redraw *after* the resources have been recovered, or you
won't see anything in the console.  The simplest way to do this is to
resize the window once more.  Perhaps I should change the error
message, but if this only happens when you torture R, I don't think
it's a priority.

I think a better long term solution is to move away from Graphapp.

Duncan Murdoch

From dmurdoch at pair.com  Wed May 14 19:11:52 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu May 15 00:12:09 2003
Subject: [Rd] R crashes when resizing windows (PR#2992)
In-Reply-To: <5.1.1.6.2.20030514120840.021147f0@mail.stats.gla.ac.uk>
References: <200305131453.h4DErI2b000409@pubhealth.ku.dk>
	<200305131453.h4DErI2b000409@pubhealth.ku.dk>
	<c8o2cv0ofs1oq2g2d4phcelsk8e672bpre@4ax.com>
	<5.1.1.6.2.20030514120840.021147f0@mail.stats.gla.ac.uk>
Message-ID: <1pc5cvc1c0mc5nd8qe8su5quaaq8rog737@4ax.com>

On Wed, 14 May 2003 12:23:34 +0100, you wrote:

>Like Uwe, I also get the same message: "Insufficient memory. Please close 
>the console." Click the OK button and the console window remains, but 
>blank. Start to resize it again and all the text content reappears and R 
>seems to be working normally again. This is the same for pager windows and 
>in both MDI and SDI mode.
>

That's good news.  I've found a slightly better patch that seems  to
remove that error too, but I won't be able to upload a binary build
that incorporates it for a few days.  I'm not sure if I can even get a
connection to commit the patch to the source tree.

The new patch releases the resources after each resize attempt, rather
than waiting until the end, so you aren't likely to run out no matter
how much you try.

Duncan Murdoch

From bates at stat.wisc.edu  Thu May 15 17:28:59 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu May 15 18:29:02 2003
Subject: [Rd] update.lme trouble (PR#2985)
In-Reply-To: <200305121554.h4CFsf2b019255@pubhealth.ku.dk>
References: <200305121554.h4CFsf2b019255@pubhealth.ku.dk>
Message-ID: <6ry918i37i.fsf@bates4.stat.wisc.edu>

p.dalgaard@biostat.ku.dk writes:

> Try this
> 
> data(Assay)
> as1 <- lme(logDens~sample*dilut, data=Assay,
>            random=pdBlocked(list(
>                      pdIdent(~1),
>                      pdIdent(~sample-1),
>                      pdIdent(~dilut-1))))
> 
> update(as1,random=pdCompSymm(~sample-1))
> update(as1,random=pdCompSymm(~sample-1))
> update(as1,random=pdCompSymm(~sample-1))
> update(as1,random=pdCompSymm(~sample-1))
> 
> I'm getting different results on different invocations!

I'm not sure exactly what the problem was but it could be triggered by
calling lme directly rather than through update.  That is, successive
calls to
  lme(logDens~sample*dilut, data=Assay, random=pdCompSymm(~sample-1))
would alternate between a successful fit and an error.

The problem does *not* occur with the current r-patched, which will be
released as R-1.7.1 in early June.  At least it does not occur under
Linux.  I would appreciate it if someone could check with r-patched
under Windows.

I have added this example as one of the tests in nlme_3.1-40, which
will be released before R-1.7.1

From pgilbert at bank-banque-canada.ca  Thu May 15 14:13:11 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu May 15 19:14:35 2003
Subject: [Rd] Re: [R] R as 64 bit application (moved from R-help)
References: <Pine.A41.4.44.0305150902550.23588-100000@homer36.u.washington.edu>
Message-ID: <3EC3CAA7.782B6F58@bank-banque-canada.ca>

Feature request:

Could this or the pointer size be added to r-devel as an element of
capabilities()? 

(Apart from my possible use of this, I think with the potentially wider
availability of 64 bit processors it is worth publicizing the 64 bit capability
of R.)

Paul Gilbert

Thomas Lumley wrote:
> 
> On Thu, 15 May 2003, Paul Gilbert wrote:
> 
> > In a package test I have a problem that needs over 4G of memory. This
> > requires that I use R compiled as a 64 bit application. Is there a way
> > within R to test if R has been compile as a 64 bit application? This
> > would allow me to automatically skip the test when I know it is going to
> > fail.
> >
> 
> I don't think so.  You could use a simple C function
> 
>   void is64bit (int *sizeptr){
>         *sizeptr = sizeof sizeptr ==8;
>         return;
>         }
> 
>   is64bit<-function(){
>         .C("is64bit",logical(1))[[1]]
>         }
> 
>         -thomas
> 
> ______________________________________________
> R-help@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

From p.dalgaard at biostat.ku.dk  Thu May 15 20:45:50 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu May 15 21:45:52 2003
Subject: [Rd] update.lme trouble (PR#2985)
In-Reply-To: <6ry918i37i.fsf@bates4.stat.wisc.edu>
References: <200305121554.h4CFsf2b019255@pubhealth.ku.dk>
	<6ry918i37i.fsf@bates4.stat.wisc.edu>
Message-ID: <x2znlodm4r.fsf@biostat.ku.dk>

Douglas Bates <bates@stat.wisc.edu> writes:

> p.dalgaard@biostat.ku.dk writes:
> 
> > Try this
> > 
> > data(Assay)
> > as1 <- lme(logDens~sample*dilut, data=Assay,
> >            random=pdBlocked(list(
> >                      pdIdent(~1),
> >                      pdIdent(~sample-1),
> >                      pdIdent(~dilut-1))))
> > 
> > update(as1,random=pdCompSymm(~sample-1))
> > update(as1,random=pdCompSymm(~sample-1))
> > update(as1,random=pdCompSymm(~sample-1))
> > update(as1,random=pdCompSymm(~sample-1))
> > 
> > I'm getting different results on different invocations!
> 
> I'm not sure exactly what the problem was but it could be triggered by
> calling lme directly rather than through update.  That is, successive
> calls to
>   lme(logDens~sample*dilut, data=Assay, random=pdCompSymm(~sample-1))
> would alternate between a successful fit and an error.
> 
> The problem does *not* occur with the current r-patched, which will be
> released as R-1.7.1 in early June.

It does for me! (RedHat 8.0):

R : Copyright 2003, The R Development Core Team
Version 1.7.0 Patched (2003-05-15)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

> library(nlme)
Loading required package: lattice
Loading required package: grid
> data(Assay)
> lme(logDens~sample*dilut, data=Assay, random=pdCompSymm(~sample-1))
Error in if ((aux <- mean(aux[row(aux) != col(aux)])) <= -1/(nc - 1))
{ :
        missing value where TRUE/FALSE needed
In addition: There were 25 warnings (use warnings() to see them)
> lme(logDens~sample*dilut, data=Assay, random=pdCompSymm(~sample-1))
Linear mixed-effects model fit by REML
  Data: Assay
  Log-restricted-likelihood: 38.47943
  Fixed: logDens ~ sample * dilut
   (Intercept)        sampleb        samplec        sampled
samplee
  -0.182791540    0.080753295    0.133976305    0.207698745
-0.023672400
       samplef         dilut2         dilut3         dilut4
dilut5
   0.073569240    0.204429030    0.405863085    0.573191050
0.720635465
sampleb:dilut2 samplec:dilut2 sampled:dilut2 samplee:dilut2 samplef:dilut2
   0.008938930   -0.008495275    0.001079295   -0.041917525
0.019352105
sampleb:dilut3 samplec:dilut3 sampled:dilut3 samplee:dilut3 samplef:dilut3
  -0.025066045    0.018645100    0.003988575   -0.027712815
0.054316035
sampleb:dilut4 samplec:dilut4 sampled:dilut4 samplee:dilut4 samplef:dilut4
   0.060788600    0.005259755   -0.016485510    0.049798755
0.063371900
sampleb:dilut5 samplec:dilut5 sampled:dilut5 samplee:dilut5 samplef:dilut5
  -0.045762455   -0.072598205   -0.177756610    0.013610930
0.004023400

Random effects:
 Formula: ~sample - 1 | Block
 Structure: Compound Symmetry
         StdDev     Corr
samplea  0.02712464
sampleb  0.02712464 0.154
samplec  0.02712464 0.154 0.154
sampled  0.02712464 0.154 0.154 0.154
samplee  0.02712464 0.154 0.154 0.154 0.154
samplef  0.02712464 0.154 0.154 0.154 0.154 0.154
Residual 0.04255631

Number of Observations: 60
Number of Groups: 2
> lme(logDens~sample*dilut, data=Assay, random=pdCompSymm(~sample-1))
Linear mixed-effects model fit by REML
  Data: Assay
  Log-restricted-likelihood: 36.62856
  Fixed: logDens ~ sample * dilut
   (Intercept)        sampleb        samplec        sampled
samplee
  -0.182791540    0.080753295    0.133976305    0.207698745
-0.023672400
       samplef         dilut2         dilut3         dilut4
dilut5
   0.073569240    0.204429030    0.405863085    0.573191050
0.720635465
sampleb:dilut2 samplec:dilut2 sampled:dilut2 samplee:dilut2 samplef:dilut2
   0.008938930   -0.008495275    0.001079295   -0.041917525
0.019352105
sampleb:dilut3 samplec:dilut3 sampled:dilut3 samplee:dilut3 samplef:dilut3
  -0.025066045    0.018645100    0.003988575   -0.027712815
0.054316035
sampleb:dilut4 samplec:dilut4 sampled:dilut4 samplee:dilut4 samplef:dilut4
   0.060788600    0.005259755   -0.016485510    0.049798755
0.063371900
sampleb:dilut5 samplec:dilut5 sampled:dilut5 samplee:dilut5 samplef:dilut5
  -0.045762455   -0.072598205   -0.177756610    0.013610930
0.004023400

Random effects:
 Formula: ~sample - 1 | Block
 Structure: Compound Symmetry
         StdDev        Corr
samplea  1.464982e-141
sampleb  1.464982e-141 0
samplec  1.464982e-141 0    0
sampled  1.464982e-141 0    0 0
samplee  1.464982e-141 0    0 0 0
samplef  1.464982e-141 0    0 0 0 0
Residual  5.046555e-02

Number of Observations: 60
Number of Groups: 2
There were 50 or more warnings (use warnings() to see the first 50)



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From b7d3c6slyssb7d3c6ss at angelfire.com  Fri May 16 16:09:46 2003
From: b7d3c6slyssb7d3c6ss at angelfire.com (b7d3c6slyssb7d3c6ss@angelfire.com)
Date: Fri May 16 15:09:59 2003
Subject: [Rd] r-bugs_Loans_Purchase_Rentals_46 (PR#3022)
Message-ID: <200305161309.h4GD9k2b026749@pubhealth.ku.dk>

Hello, r-bugs

The best loans online!
http://mortgagesearch-usa.net/index.htm
F-R-E-E info!
http://mortgagesearch-usa.net/index.htm

r-bugs~FAST~FREE~CONFIDENTIAL~GOOD~CREDIT~BAD~CREDIT~SELF~EMPLOYED~

So Long:
http://mortgagesearch-usa.net/remove_page.htm

Have a happy day!

From wl at eimb.ru  Fri May 16 17:15:45 2003
From: wl at eimb.ru (wl@eimb.ru)
Date: Fri May 16 16:16:50 2003
Subject: [Rd] possibly bug in 'reshape' (PR#3024)
Message-ID: <200305161415.h4GEFj2b026950@pubhealth.ku.dk>

Dear R-tists,

the source code of the 'reshape' function contains the following

reshapeLong <- function(data, varying, v.names = NULL, timevar,
       idvar, ids = 1:NROW(date), times, drop = NULL, new.row.names = NULL) {

I suspect the expression

ids=1:NROW(date)

is erroneous.
The 'date' variable doesn't appear anywhere else in this function.
Maybe, 'data' ?

-- 
Best regards
Wladimir Eremeev                                     mailto:wl@eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534

From tlumley at u.washington.edu  Fri May 16 08:34:48 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri May 16 16:38:08 2003
Subject: [Rd] possibly bug in 'reshape' (PR#3024)
In-Reply-To: <200305161415.h4GEFj2b026950@pubhealth.ku.dk>
Message-ID: <Pine.A41.4.44.0305160734290.116418-100000@homer38.u.washington.edu>

On Fri, 16 May 2003 wl@eimb.ru wrote:

> Dear R-tists,
>
> the source code of the 'reshape' function contains the following
>
> reshapeLong <- function(data, varying, v.names = NULL, timevar,
>        idvar, ids = 1:NROW(date), times, drop = NULL, new.row.names = NULL) {
>
> I suspect the expression
>
> ids=1:NROW(date)
>
> is erroneous.
> The 'date' variable doesn't appear anywhere else in this function.
> Maybe, 'data' ?

Yes, that looks likely.

Thanks.
	-thomas

From wevp at morgansmagic.biz  Sat May 17 04:23:29 2003
From: wevp at morgansmagic.biz (wevp@morgansmagic.biz)
Date: Fri May 16 23:07:48 2003
Subject: [Rd] oeqm odjp FW: RE: Finally a Digital _Cable Descrambler
Message-ID: <cf9301c31be0$a161a0a0$9f5859d0@cipyarritgy>


	[[alternate HTML version deleted]]

From rexmcCabe_54 at blvdmedia.com  Sat May 17 02:57:23 2003
From: rexmcCabe_54 at blvdmedia.com (rexmcCabe_54@blvdmedia.com)
Date: Sat May 17 01:57:35 2003
Subject: [Rd] What is your name? (PR#3029)
Message-ID: <200305162357.h4GNvN2b028610@pubhealth.ku.dk>

CQkJCTxodG1sPg0KICANCjxib2R5IEJHQ09MT1I9I2ZmZmZmZj4JDQoJCQ0K
CTxwIGFsaWduPSJjZW50ZXIiPjxmb250IGZhY2U9InZlcmRhbmEiPjxDR1hS
Pg0KZ2V0IGw8S0taPmFyZzxXRFQ+ZXIgYmFsbHMgYW5kIHA8V1ZXUj5lPEtL
U0g+bjxDV1RYPu1zLCAgbW9yZQ0KIHA8S1VNUz5sZWFzdXJlLCAgDQoJDQog
IDxDVkdEPm1vcjxZS1g+ZQ0KIHNhPFk+dGk8WFRXWT5zPFFXPmY8UUFCPmFj
PFlJREc+dGk8WD5vbjxicj4NCjxhIGhyZWY9Imh0dHA6Ly9oZUFMdGguZUFz
eUhvc1QyMDA0LkNvbS9wZSU2Qi8lNmQyYy4lNzBocD8lNkQlNjFuPWslNkIl
MzQlMzIlMzJhIj5DaGVjayBpdCBvdXQgPFhIPmhlcjxaRj5lPC9hPjxicj4N
Cjxicj4gPGEgaHJlZj0iaHR0cDovL2hlQWxUaC5FQXNZaE9zVDIwMDQuY09N
LyU3MGUlNkIvJTZkMmMucCU2OCU3MD8lNkQlNjElNkU9ayU2QiUzNCUzMjJh
Ij4JDQoJDQo8aW1nIGJvcmRlcj0wIHNyYz0iaHR0cDovL0hlYUx0aC5FQVN5
aG9TdDIwMDQuY09NL3AuJTZBcGciPiANCiAgPC9hPjxicj48YnI+PGJyPg0K
PGEgaHJlZj0iaHR0cDovL2hFYUx0SC5FYVNZSG9TdDIwMDQuY29NLyU3MiU2
NSU2ZG92ZS8iPk5vIDxDTFVNPm1vPEtYTD5yZSBwbGVhc2U8L2E+DQo8YnI+
LT00dW9la2QxYmEwc2Q9LTwvZm9udD48L3A+PC9ib2R5PgkJCQ0KCTwvSFRN
TD4NCg0K

From ajro at morgansmagic.biz  Sat May 17 01:42:21 2003
From: ajro at morgansmagic.biz (ajro@morgansmagic.biz)
Date: Sat May 17 02:10:48 2003
Subject: [Rd] gwnfixvem a all internet junkies need this
Message-ID: <3bc901c31c0d$2d126a40$227c5515@vsxkjfo>


	[[alternate HTML version deleted]]

From rosebush3 at morgansmagic.biz  Sat May 17 03:17:11 2003
From: rosebush3 at morgansmagic.biz (rosebush3@morgansmagic.biz)
Date: Sat May 17 10:10:52 2003
Subject: [Rd] lwl hsea RE: Descramble Digital _Cable
Message-ID: <feb301c31c3b$f408c710$177a67e9@xhn>


	[[alternate HTML version deleted]]

From don at delphioutpost.com  Sat May 17 18:03:22 2003
From: don at delphioutpost.com (don@delphioutpost.com)
Date: Sat May 17 17:03:33 2003
Subject: [Rd] read.table fails with \246 separator (PR#3035)
Message-ID: <200305171503.h4HF3M2b000811@pubhealth.ku.dk>

Full_Name: Don Allen
Version: 1.6.2
OS: Solaris
Submission from: (NULL) (140.186.148.11)


If you use '\246' to separate fields in a csv-like file, read.table fails if
you
have more than 5 lines in the file (in the following, the separators in junk.csv
are really '\246's, despite the way they printed):

Fails:


> read.table("/tmp/junk.csv",as.is=T,header=T,sep="\246")

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :

	line 5 did not have 5 elements

junk.csv
----------------
xabcd
17131925
28142026
39152127
410162228
511172329
612182430
----------------

That works if you delete the last two lines:


> read.table("/tmp/junk.csv",as.is=T,header=T,sep="\246")

  x  a  b  c  d
1 1  7 13 19 25
2 2  8 14 20 26
3 3  9 15 21 27
4 4 10 16 22 28

When using tabs or vertical bars as separators, you do not encounter this
problem. The suspicion, of course, is that this has something to do with using a
separator
that has the high-order bit set (Insightful introduced just such a bug in Splus
6.1
that completely breaks their read.table for such separators).

From ripley at stats.ox.ac.uk  Sat May 17 18:12:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May 17 18:12:41 2003
Subject: [Rd] read.table fails with \246 separator (PR#3035)
In-Reply-To: <200305171503.h4HF3M2b000811@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305171642450.21365-100000@gannet.stats>

It transpires this is not to do with read.table: scan fails on your 
example and it is in scan that a character is being compared with an 
unsigned char after each has been coerced to int.  It's of long standing 
(but 1.6.2 is not current, and please do check on the current version).

It will be fixed for 1.7.1.

On Sat, 17 May 2003 don@delphioutpost.com wrote:

> Full_Name: Don Allen
> Version: 1.6.2
> OS: Solaris
> Submission from: (NULL) (140.186.148.11)
> 
> 
> If you use '\246' to separate fields in a csv-like file, read.table fails if
> you
> have more than 5 lines in the file (in the following, the separators in junk.csv
> are really '\246's, despite the way they printed):
> 
> Fails:
> 
> 
> > read.table("/tmp/junk.csv",as.is=T,header=T,sep="\246")
> 
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
> 
> 	line 5 did not have 5 elements
> 
> junk.csv
> ----------------
> x?a?b?c?d
> 1?7?13?19?25
> 2?8?14?20?26
> 3?9?15?21?27
> 4?10?16?22?28
> 5?11?17?23?29
> 6?12?18?24?30
> ----------------
> 
> That works if you delete the last two lines:
> 
> 
> > read.table("/tmp/junk.csv",as.is=T,header=T,sep="\246")
> 
>   x  a  b  c  d
> 1 1  7 13 19 25
> 2 2  8 14 20 26
> 3 3  9 15 21 27
> 4 4 10 16 22 28
> 
> When using tabs or vertical bars as separators, you do not encounter this
> problem. The suspicion, of course, is that this has something to do with using a
> separator
> that has the high-order bit set (Insightful introduced just such a bug in Splus
> 6.1
> that completely breaks their read.table for such separators).
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From cc4g3d2srlc4g3d2ssz at angelfire.com  Sat May 17 22:45:03 2003
From: cc4g3d2srlc4g3d2ssz at angelfire.com (cc4g3d2srlc4g3d2ssz@angelfire.com)
Date: Sat May 17 21:45:18 2003
Subject: [Rd] r-bugs_Post_WARTIME_invester_tip_#25 (PR#3036)
Message-ID: <200305171945.h4HJj32b001550@pubhealth.ku.dk>

One question, r-bugs

r-bugs_Do_You_Know_The_Impact_of_Post_War_on_Global_Financial_Markets?

r-bugs_Are_Your_Investments_Safe?

r-bugs_You_can_not_afford_to_ignore_the_vital_information_contained_within_this_special_report. 

http://www.pesutis.com.ar/invest/war_impact.html

r-bugs_Feel_free_to_forward_this_email_to_friends_and_associates
If you would rather say goodbye, please visit:
http://www.pesutis.com.ar/invest/cleanlist.html

You joined us as  r-bugs

From rolland at mikesmagic.biz  Mon May 19 06:09:40 2003
From: rolland at mikesmagic.biz (rolland@mikesmagic.biz)
Date: Sun May 18 20:26:41 2003
Subject: [Rd] eermitp gcrqrc Inexpensive Digital Cable Box Descrambler
Message-ID: <dd4c01c31d68$a67eadb0$26ab0dbf@csx>


	[[alternate HTML version deleted]]

From john.maindonald at anu.edu.au  Mon May 19 07:16:09 2003
From: john.maindonald at anu.edu.au (john.maindonald@anu.edu.au)
Date: Mon May 19 06:16:22 2003
Subject: [Rd] predict.lm(), se=TRUE, with weights; erroneous SEs (PR#3043)
Message-ID: <200305190416.h4J4G92b006930@pubhealth.ku.dk>

<<insert bug report here>>
"xy" <-
     structure(list(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
                    y = c(1.036, 1.883, 3.11, 3.148, 4.226,
                    6.291, 7.312, 7.796, 9.563, 9.563),
                    w = c(0.067, 0.06, 1.588, 0.239, 0.015,
                    0.938, 0.041, 0.473, 0.483, 0.044)),
               .Names = c("x", "y", "w"),
               row.names = c("1", "2", "3", "4", "5",
               "6", "7", "8", "9", "10"), class = "data.frame")
 > xy.lm <- lm(y~x, weights=w, data=xy)  # Result is wrong
 > predict(xy.lm, se=T)$se
  [1] 0.05895647 0.04606261 0.19247671 0.06140987 0.01380818 0.11510861
  [7] 0.02865223 0.11991962 0.14786285 0.05331879
 > predict(xy.lm, newdata=xy, se=T)$se  # This gives the correct result
         1         2         3         4         5         6         7   
       8
0.2277687 0.1880498 0.1527401 0.1256144 0.1127433 0.1188520 0.1415033 
0.1743652
         9        10
0.2127578 0.2541874

Find the lines
             if (type != "terms") {
             if (missing(newdata))

The fix is to replace the next line (around line 47):
                 XRinv <- qr.Q(object$qr)[,  p1,  drop = FALSE]
     by
                 XRinv <- if(is.null(w)) qr.Q(object$qr)[,  p1,  drop = 
FALSE]
             else qr.Q(object$qr)[,  p1,  drop = FALSE]/sqrt(w)}

As far as I can discover, this bug is left over from extensive fixes
that I contributed to predict.lm() just after version 1.0.  If so, this
has never worked correctly.

I note that further down the code, following     if (interval != 
"none") {
the symbol w is used for another purpose.  To avoid  confusing
casual perusers of the code, this second use of w might be
changed to, e.g., halfwid

--please do not edit the information below--

Version:
  platform = powerpc-apple-darwin6.5
  arch = powerpc
  os = darwin6.5
  system = powerpc, darwin6.5
  status =
  major = 1
  minor = 7.0
  year = 2003
  month = 04
  day = 16
  language = R

Search Path:
  .GlobalEnv, package:methods, package:ctest, package:mva, 
package:modreg, package:nls, package:ts, Autoloads, package:base

John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From dmurdoch at pair.com  Mon May 19 22:56:24 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue May 20 03:56:55 2003
Subject: [Rd] Extending %*%
Message-ID: <te2jcvkqn8uq9it881386oqi1n4j8ncakh@4ax.com>

I have lists of matrices stored in various ways.  I'd like to extend
%*% to work on these.  Is this possible, or should I create my own new
operator?

A simplified example would be as follows:

A <- list( A1, A2, A3)
B <- list( B1, B2, B3)

where A1,...,B3 are all matrices, and I'd like A %*% B to return 

list( A1 %*% B1, A2 %*% B2, A3 %*% B3)

In the real case A and B are sometimes arrays, sometimes something
else; lists haven't come up so far, but the principle should be the
same.

Duncan Murdoch

From ligges at statistik.uni-dortmund.de  Tue May 20 09:35:08 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue May 20 08:35:22 2003
Subject: [Rd] Extending %*%
In-Reply-To: <te2jcvkqn8uq9it881386oqi1n4j8ncakh@4ax.com>
References: <te2jcvkqn8uq9it881386oqi1n4j8ncakh@4ax.com>
Message-ID: <3EC9CC9C.2080204@statistik.uni-dortmund.de>

Duncan Murdoch wrote:
> I have lists of matrices stored in various ways.  I'd like to extend
> %*% to work on these.  Is this possible, or should I create my own new
> operator?
> 
> A simplified example would be as follows:
> 
> A <- list( A1, A2, A3)
> B <- list( B1, B2, B3)
> 
> where A1,...,B3 are all matrices, and I'd like A %*% B to return 
> 
> list( A1 %*% B1, A2 %*% B2, A3 %*% B3)
> 
> In the real case A and B are sometimes arrays, sometimes something
> else; lists haven't come up so far, but the principle should be the
> same.
> 
> Duncan Murdoch

The straightforward way without extending %*% (I feel that extending it 
is dangerous, in a way) is
   mapply("%*%", A, B, SIMPLIFY = FALSE)

Uwe Ligges

From kuehn at halle.ufz.de  Mon May 19 16:54:57 2003
From: kuehn at halle.ufz.de (kuehn@halle.ufz.de)
Date: Tue May 20 12:43:08 2003
Subject: [Rd] PR#2798
Message-ID: <200305191354.h4JDsv2b014202@pubhealth.ku.dk>

I have the same problem and a similar workaround. The problem 
arises when I use the  "Copy and paste" button or the "copy" button 
and then the "paste" button, but not when using the keys ctrl-c and 
ctrl-v from the keyboard.
When pressing the "Copy and paste" button twice (second time 
without marking any text), the system resumes, as well.

R Version 1.70
Window XP

================================================
Dr. Ingolf Kuehn
UFZ - Umweltforschungszentrum Leipzig-Halle GmbH
- Sektion Biozoenoseforschung -
UFZ - Centre for Environmental Research
- Department of Community Ecology -
Theodor-Lieser-Strasse 4
06120 Halle
Germany
Tel (+49)345 / 558 5311
Fax (+49)345 / 558 5329
email: kuehn@halle.ufz.de
http://www.ufz.de/spb/bioz/

From maechler at stat.math.ethz.ch  Tue May 20 13:19:29 2003
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue May 20 12:43:34 2003
Subject: [Rd] predict.lm(), se=TRUE, with weights; erroneous SEs (PR#3043)
Message-ID: <200305201019.h4KAJT2b021886@pubhealth.ku.dk>

Thank you, John.

This has been fixed in "R-patched"  to become R 1.7.1 early June.
Martin

From ripley at stats.ox.ac.uk  Tue May 20 12:56:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue May 20 12:56:20 2003
Subject: [Rd] PR#2798
In-Reply-To: <200305191354.h4JDsv2b014202@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305201153030.9925-100000@gannet.stats>

If you read that bug report on R-bugs, it specifically asks if you can
reproduce it on the current R-patched: the only usable data point now is
about the current R-patched.  So can you please report on R-patched?

On Mon, 19 May 2003 kuehn@halle.ufz.de wrote:

> I have the same problem and a similar workaround. The problem 
> arises when I use the  "Copy and paste" button or the "copy" button 
> and then the "paste" button, but not when using the keys ctrl-c and 
> ctrl-v from the keyboard.
> When pressing the "Copy and paste" button twice (second time 
> without marking any text), the system resumes, as well.
> 
> R Version 1.70
> Window XP

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gregory_r_warnes at groton.pfizer.com  Tue May 20 16:41:16 2003
From: gregory_r_warnes at groton.pfizer.com (gregory_r_warnes@groton.pfizer.com)
Date: Tue May 20 15:41:28 2003
Subject: [Rd] FW: print.matrix incorrectly formatting string matrixes when
	righ (PR#3058)
Message-ID: <200305201341.h4KDfG2b024847@pubhealth.ku.dk>


> When printing a string matrix with right=TRUE and na.print specified, an
> incorrect amount of spaced is provided for NA columns leading to incorrect
> formatting:
> 
> 
> > a <- matrix( c(NA, "a", "b", "10",
> +                NA, NA,  "d", "12",
> +                NA, NA,  NA,  "14"),
> +              byrow=T, ncol=4 )
> > print(a) # correct
>      [,1] [,2] [,3] [,4]
> [1,] NA   "a"  "b"  "10"
> [2,] NA   NA   "d"  "12"
> [3,] NA   NA   NA   "14"
> > print(a, right=T) # correct
>      [,1] [,2] [,3] [,4]
> [1,]   NA  "a"  "b" "10"
> [2,]   NA   NA  "d" "12"
> [3,]   NA   NA   NA "14"
> > print(a, right=T, na.print=" ") # wrong
>      [,1] [,2] [,3] [,4]
> [1,]      "a"  "b" "10"
> [2,]          "d" "12"
> [3,]             "14"
> > print(a, right=T, na.print="      ") # wrong
>      [,1]   [,2]   [,3]   [,4]
> [1,]               "a"    "b" "10"
> [2,]                          "d" "12"
> [3,]                                  "14"
> >  
> 
> 
> This does not occur with numeric matrixes:
> 
> > a <- matrix( c(NA, 1.0, 2.0, 3.0,
> +                NA, NA,  4.0, 5.0,
> +                NA, NA,   NA, 6.0 ),
> 
> +                byrow=T, ncol=4 )
> > print(a)
>      [,1] [,2] [,3] [,4]
> [1,]   NA    1    2    3
> [2,]   NA   NA    4    5
> [3,]   NA   NA   NA    6
> > print(a,right=T)
>      [,1] [,2] [,3] [,4]
> [1,]   NA    1    2    3
> [2,]   NA   NA    4    5
> [3,]   NA   NA   NA    6
> > print(a,right=T,na.print=" ")
>      [,1] [,2] [,3] [,4]
> [1,]         1    2    3
> [2,]              4    5
> [3,]                   6
> > print(a, right=T, na.print="      ")
>        [,1]   [,2]   [,3] [,4]
> [1,]             1      2    3
> [2,]                    4    5
> [3,]                         6
> >
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From murdoch at stats.uwo.ca  Tue May 20 10:59:57 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue May 20 15:58:36 2003
Subject: [Rd] Extending %*%
In-Reply-To: <te2jcvkqn8uq9it881386oqi1n4j8ncakh@4ax.com>
References: <te2jcvkqn8uq9it881386oqi1n4j8ncakh@4ax.com>
Message-ID: <61bkcv4hqepnl5evk8eubbvudqekfhdadv@4ax.com>

On Mon, 19 May 2003 21:56:24 -0400, you wrote in message
<te2jcvkqn8uq9it881386oqi1n4j8ncakh@4ax.com>:

>I have lists of matrices stored in various ways.  I'd like to extend
>%*% to work on these.  Is this possible, or should I create my own new
>operator?

In answer to my own question:  yes, it's possible, using the S4
classes and methods.  It would look something like this:


setClass("special", representation(m = "list"))

setMethod("%*%", 
                signature(x = "special", y="special"),
                function(x,y) 
		new("special", 
			m = mapply("%*%", x@m, y@m, SIMPLIFY=FALSE))
)


A1 <- A2 <- A3 <- B1 <- B2 <- B3 <- diag(c(2,3))

A <- new("special", m = list(A1, A2, A3))

B <- new("special", m = list(A1, A2, A3))

A %*% B

(Thanks Uwe for the compact expression to implement the method!)

Duncan Murdoch

From ripley at stats.ox.ac.uk  Tue May 20 17:01:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue May 20 17:02:04 2003
Subject: (PR#3058) [Rd] FW: print.matrix incorrectly formatting string
	matrixes when right=T
In-Reply-To: <200305201341.h4KDfG2b024847@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305201559060.23387-100000@gannet.stats>

Fixed for R-patched.

Note that right=TRUE (sic) is not used for numeric matrices: it is the 
default and cannot be altered.

On Tue, 20 May 2003 gregory_r_warnes@groton.pfizer.com wrote:

> 
> > When printing a string matrix with right=TRUE and na.print specified, an
> > incorrect amount of spaced is provided for NA columns leading to incorrect
> > formatting:
> > 
> > 
> > > a <- matrix( c(NA, "a", "b", "10",
> > +                NA, NA,  "d", "12",
> > +                NA, NA,  NA,  "14"),
> > +              byrow=T, ncol=4 )
> > > print(a) # correct
> >      [,1] [,2] [,3] [,4]
> > [1,] NA   "a"  "b"  "10"
> > [2,] NA   NA   "d"  "12"
> > [3,] NA   NA   NA   "14"
> > > print(a, right=T) # correct
> >      [,1] [,2] [,3] [,4]
> > [1,]   NA  "a"  "b" "10"
> > [2,]   NA   NA  "d" "12"
> > [3,]   NA   NA   NA "14"
> > > print(a, right=T, na.print=" ") # wrong
> >      [,1] [,2] [,3] [,4]
> > [1,]      "a"  "b" "10"
> > [2,]          "d" "12"
> > [3,]             "14"
> > > print(a, right=T, na.print="      ") # wrong
> >      [,1]   [,2]   [,3]   [,4]
> > [1,]               "a"    "b" "10"
> > [2,]                          "d" "12"
> > [3,]                                  "14"
> > >  
> > 
> > 
> > This does not occur with numeric matrixes:
> > 
> > > a <- matrix( c(NA, 1.0, 2.0, 3.0,
> > +                NA, NA,  4.0, 5.0,
> > +                NA, NA,   NA, 6.0 ),
> > 
> > +                byrow=T, ncol=4 )
> > > print(a)
> >      [,1] [,2] [,3] [,4]
> > [1,]   NA    1    2    3
> > [2,]   NA   NA    4    5
> > [3,]   NA   NA   NA    6
> > > print(a,right=T)
> >      [,1] [,2] [,3] [,4]
> > [1,]   NA    1    2    3
> > [2,]   NA   NA    4    5
> > [3,]   NA   NA   NA    6
> > > print(a,right=T,na.print=" ")
> >      [,1] [,2] [,3] [,4]
> > [1,]         1    2    3
> > [2,]              4    5
> > [3,]                   6
> > > print(a, right=T, na.print="      ")
> >        [,1]   [,2]   [,3] [,4]
> > [1,]             1      2    3
> > [2,]                    4    5
> > [3,]                         6
> > >
> > 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jerome at hivnet.ubc.ca  Tue May 20 16:39:11 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed May 21 00:39:55 2003
Subject: [Rd] axis() default values for "lty", "lwd", and "col"
Message-ID: <200305202245.PAA15730@hivnet.ubc.ca>


Hi,

I would like to recommend a minor modification in axis() which I believe 
can simplify the making of plots for publications. I am trying to define 
default values for par() in order to make labels bigger and lines thicker, 
so that the resulting plots look good when resized for publication 
purposes. I ran into the following problem...

axis() does not use par() values as default for "lty", "lwd", and "col". 
Here is an example.

par(lty=2,lwd=3,col="blue")
plot(1,1,bty="n",axes=F)
axis(1)
axis(2)

Because axis() doesn't use the par() values, I have to explicitely define 
the parameters "lty", "lwd", and "col" in my axis() calls. It would make 
sense if axis() used the par() values by default.

Hence, I recommend this simple fix in the axis() function([...]) statement 
in order to have axis() read the par() values for "lty", "lwd", and "col".

axis <- 
function (side, at = NULL, labels = TRUE, tick = TRUE, line = NA,
    pos = NA, outer = FALSE, font = NA, vfont = NULL, lty = par("lty"),
    lwd = par("lwd"), col = par("col"), ...)
{ [...] }

I use R1.7.0 on Red Hat Linux 7.2.

Sincerely,
Jerome Asselin

-- 

Jerome Asselin (J?r?me), Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, 608 - 1081 Burrard Street
Vancouver, British Columbia, CANADA V6Z 1Y6
Email: jerome@hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044

From john.maindonald at anu.edu.au  Wed May 21 10:46:26 2003
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed May 21 01:41:02 2003
Subject: [Rd] predict.lm(); zero weights; follow-on to PR#3043
Message-ID: <4544B012-8B1D-11D7-864A-000393073F7A@anu.edu.au>

I have now looked at implications for zero weights

The code (lines 45-47)

         if (type != "terms") {
             if (missing(newdata))
                 XRinv <- qr.Q(object$qr)[, p1, drop = FALSE]

requires the more extensive change:
            if (missing(newdata)&(is.null(w)|all(w>0))){
                 XRinv <- if(is.null(w)) qr.Q(object$qr)[,  p1,  drop = 
FALSE]
             else qr.Q(object$qr)[,  p1,  drop = FALSE]/sqrt(w)}

The issue here is that the object returned by qr.Q(object$qr)
has only as many rows as there are non-zero values of w.
So the easy way to fix the matter is that taken above, to revert
to the more straightforward but probably lengthier calculation
                Rinv <- qr.solve(qr.R(object$qr)[p1, p1])
                XRinv <- X[, piv] %*% Rinv

   I was aware that this was probably an issue when I
submitted the earlier bug report, but did not not want to
delay reporting that issue.

SEs of prediction values (i.e., predicted value for a new
observation) seem to me an ambiguous notion when there
are weights.  As it stands the code effectively assumes a
weight of one for SEs of prediction values.  I guess this is
reasonable.

Here is code that exercises this patch:
"xy0" <-
     structure(list(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
                    y = c(1.036, 1.883, 3.11, 3.148, 4.226,
                    6.291, 7.312, 7.796, 9.563, 9.563),
                    w = c(0.067, 0, 1.588, 0.239, 0.015,
                    0.938, 0.041, 0.473, 0.483, 0.044)),
               .Names = c("x", "y", "w"), class = "data.frame",
               row.names = c("1", "2", "3", "4", "5", "6", "7",
               "8", "9", "10"))
 > xy0.lm <- lm(y ~ x, weights=w, data=xy0)
 > my.predict(xy0.lm, se=T)$se
         1         2         3         4         5         6         7   
       8
0.2485517 0.2052760 0.1666100 0.1365279 0.1215779 0.1272119 0.1511453 
0.1864598
         9        10
0.2279254 0.2727509

John Maindonald             email: john.maindonald@anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

From pd at pubhealth.ku.dk  Wed May 21 08:15:03 2003
From: pd at pubhealth.ku.dk (Peter Dalgaard BSA)
Date: Wed May 21 07:09:27 2003
Subject: [Rd] Bug list summary (automatic post)
Message-ID: <200305210515.h4L5F3ke006339@blueberry.kubism.ku.dk>

=================================================
This is an automated summary of the status of the R-bugs
repository.

Note that this may be neither complete nor perfectly
correct at any given instance: Not all bugs are reported,
and some reported bugs may have been fixed, but the
repository not yet updated.

Some bug fixes are difficult to verify because they pertain
to specific hardware or operating system versions. If you
have information to contribute, please do so.

If you happen to know how to fix a problem please send
patches to the bug repository, too.

New bugs are reported either through the web
interface at r-bugs.r-project.org or via email to
r-bugs@r-project.org. The bug.report() function can be
used to automate parts of the procedure on many systems.
Followups on older bugs can be done by including the string
"(PR#999)" in the Subject of an email (change 999 to the
actual reference number, of course!).
=================================================

Directory:  Accuracy

* PR# 1228 *
Subject: bug with var(rep(1e30, 3))
From: Emmanuel Paradis <paradis@isem.univ-montp2.fr>
Date: Wed, 26 Dec 2001 13:03:31 +0100
* PR# 1664 *
Subject: Bug in rnorm.
From: Rolf Turner <rolf@math.unb.ca>
Date: Thu, 13 Jun 2002 16:35:59 -0300 (ADT)
..Strange interaction between "Marsaglia-Multicarry" generator and
.."Kinderman-Ramage" 
..method for normal variates. Apparently, switching either of them will help.
* PR# 2214 *
Subject: qgamma precision
From: terra@diku.dk
Date: Fri, 25 Oct 2002 16:50:17 +0200 (MET DST)

Directory:  Add-ons

* PR# 974 *
Subject: Lattice: panel.superpose with ordered factor groups
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sat, 9 Jun 2001 11:08:51 +1000 (EST)
..The warning is standard S and R behaviour.
..Probably xyplot needs to avoid it (by unclassing?)
..Still there in lattice 0.3-0, 0.6-8
* PR# 1361 *
Subject: Matrix identification bug
From: hyu@stats.uwo.ca
Date: Tue, 5 Mar 2002 21:19:46 +0100 (MET)
..seems to be about Matrix package, not solve
* PR# 1662 *
Subject: fisher.test FEXACT memory bug "should not occur"
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Thu, 13 Jun 2002 08:21:50 +0200
..The supplementary (table of sum one) is fixed for 1.5.1.
..Detection code for the first problem has been added to 1.5.1 which will stop
..the crash, but the underlying cause is still open.
* PR# 1729 *
Subject: problem with qq( )
From: Jarno.Tuimala@Helsinki.Fi
Date: Tue, 2 Jul 2002 10:37:10 +0200 (MET DST)
..A report on lattice
* PR# 1741 *
Subject: groupedData constructor from a function
From: dieter.menne@menne-biomed.de
Date: Thu, 4 Jul 2002 15:59:59 +0200 (MET DST)
* PR# 1972 *
Subject: lattice install
From: robert.king@newcastle.edu.au
Date: Mon, 2 Sep 2002 04:55:41 +0200 (MET DST)
..Perhaps lattice should require(grid) and print a clearer message?
* PR# 1974 *
Subject: Rwave installation problem
From: ld-temp-qt3i@pobox.com
Date: Mon, 2 Sep 2002 09:27:36 +0200 (MET DST)
..Instead, this should use ISO C headers, namely <stdlib.h>
* PR# 2173 *
Subject: xlim in plot.survfit() [with a discussion on "..."]
From: jerome@hivnet.ubc.ca
Date: Wed, 16 Oct 2002 18:46:11 +0200 (MET DST)
* PR# 2320 *
Subject: Segmentation fault using "survival" package
From: jerome@hivnet.ubc.ca
Date: Sat, 23 Nov 2002 00:51:50 +0100 (MET)
* PR# 2322 *
Subject: simplex
From: george@lecompte.org
Date: Sat, 23 Nov 2002 17:30:37 +0100 (MET)
..report on boot, I think (not mentioned, though)
* PR# 2352 *
Subject: avas: segmentation fault on empty args
From: vograno@arbitrade.com
Date: Fri, 6 Dec 2002 19:41:48 +0100 (MET)
* PR# 2363 *
Subject: nlme() and parameters "model", "fixed" and "random"
From: jerome@hivnet.ubc.ca
Date: Wed, 11 Dec 2002 22:29:47 +0100 (MET)
* PR# 2369 *
Subject: convergence problem with nlme()
From: jerome@hivnet.ubc.ca
Date: Thu, 12 Dec 2002 23:43:14 +0100 (MET)
* PR# 2374 *
Subject: quantreg package - predict method for rq objects
From: John Maindonald <u9801539@leonard.anu.edu.au>
Date: Sat, 14 Dec 2002 20:46:34 +1100 (EST)
* PR# 2384 *
Subject: degrees of freedom in nlme()
From: jerome@hivnet.ubc.ca
Date: Fri, 20 Dec 2002 01:40:06 +0100 (MET)
* PR# 2385 *
Subject: read.xport and lookup.xport in foreign
From: Frank E Harrell Jr <fharrell@virginia.edu>
Date: Fri, 20 Dec 2002 12:47:58 -0500
* PR# 2386 *
Subject: ace and avas in acepack
From: Frank E Harrell Jr <fharrell@virginia.edu>
Date: Fri, 20 Dec 2002 12:59:07 -0500
* PR# 2480 *
Subject: bug in CrossTable (package:gregmisc)
From: John_Hendrickx@yahoo.com
Date: Tue, 21 Jan 2003 13:51:01 +0100 (MET)
* PR# 2499 *
Subject: survival bug?
From: Pius Korner <korner@eco.umnw.ethz.ch>
Date: Mon, 27 Jan 2003 17:28:11 +0100
..Needs to resubmit in more useful format.
* PR# 2520 *
Subject: Apparent parser problem
From: "Jim Rogers" <jrogers@cantatapharm.com>
Date: Sat, 1 Feb 2003 16:51:41 -0500
..Its an ESS or XEmacs problem. I redirected him to ESS-bugs.
* PR# 2859 *
Subject: bug and proposed fix in print.trellis 1.7.0
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Sun, 27 Apr 2003 01:56:30 -0400
..Lattice
* PR# 2865 *
Subject: bug in y limits in bwplot
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Mon, 28 Apr 2003 02:19:53 -0400 (EDT)
* PR# 2933 *
Subject: frailty models in survreg() -- survival package
From: Jerome Asselin <jerome@hivnet.ubc.ca>
Date: Tue, 6 May 2003 15:36:23 -0700
* PR# 2934 *
Subject: Re: frailty models in survreg() -- survival package
From: Thomas Lumley <tlumley@u.washington.edu>
Date: Tue, 6 May 2003 15:58:37 -0700 (PDT)
* PR# 2985 *
Subject: update.lme trouble
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 12 May 2003 17:59:41 +0200
* PR# 2986 *
Subject: plot.ranef.lme
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 12 May 2003 18:19:28 +0200

Directory:  Analyses

* PR# 2993 *
Subject: small bug in power.t.test for two-sided alternatives
From: vangel@nmr.mgh.harvard.edu
Date: Tue, 13 May 2003 14:12:24 +0200 (MET DST)

Directory:  Documentation

* PR# 988 *
Subject: input for R-intro
From: "Paul E. Johnson" <pauljohn@ku.edu>
Date: Mon, 18 Jun 2001 13:57:10 -0500
* PR# 1011 *
Subject: R-intro suggestions part II
From: "Paul E. Johnson" <pauljohn@ukans.edu>
Date: Tue, 03 Jul 2001 15:50:06 -0500
* PR# 1772 *
Subject: bug(?) in R FAQ - Should I run R from within Emacs?
From: Tim.Harrold@csiro.au
Date: Thu, 11 Jul 2002 18:21:42 +1000
* PR# 2794 *
Subject: prop.test  confidence intervals
From: rbaer@kcom.edu
Date: Fri, 18 Apr 2003 19:01:03 +0200 (MET DST)
..prop.test should say how it computes confidence intervals.

Directory:  Graphics

* PR# 202 *
Subject: persp box occlusion bug
From: wsi@gcal.ac.uk
Date: Wed, 2 Jun 1999 15:02:03 +0200 (MET DST)
..The persp algorithm does not apply the occlusion rules to the frame, 
..which is always plotted first. 
..A bug, but not very simple to fix.
* PR# 660 *
Subject: identify.default ignores any setting of cex.
From: Prof Brian Ripley <ripley@stats.ox.ac.uk>
Date: Fri, 15 Sep 2000 10:23:39 +0100 (BST)
* PR# 776 *
Subject: strwidth does not take font into account
From: Martyn Plummer <plummer@iarc.fr>
Date: Tue, 19 Dec 2000 14:56:01 +0100 (CET)
..This needs a substantial redesign.
* PR# 791 *
Subject:  par(lab= *) / axis(*) bug 
From: maechler@stat.math.ethz.ch
Date: Fri, 22 Dec 2000 10:59:26 +0100
* PR# 816 *
Subject: dotplot: character size of labels
From: RINNER Heinrich <H.RINNER@TIROL.GV.AT>
Date: Thu, 18 Jan 2001 14:54:32 +0100
..Suggested fix is incorporated in 1.2.2.
..
..There is a deeper problem:  mtext() ignores par(cex=.5) in general.  
..To see the problem try:  par(cex=.5); mtext("hi")
..Paul thinks the right fix is to change the argument list for mtext so that
..cex=par(cex) by default rather than cex=NA by default (plus corresponding
..internal changes to  do_mtext in plot.c).
..This needs to be done very carefully because (i) the change suggested above 
..mayhave side-effects in many other pieces of interpreted code 
..(ii) do_mtext ignores dd->gp.cexbase unlike, for example, do_plot_xy 
..and anything to do with cexbase needs extreme care.
* PR# 831 *
Subject: screen can't go back to (split) screen with log="y" plot
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 30 Jan 2001 00:39:41 -0500
..Still there. Suggested fix included in followups, but we didn't get around to
..try it in time for 1.2.3.
..
..Fix doesn't work. One problem is that the opar<-par();par(opar) idiom updates
..xaxp before xlog, and the new value of xaxp may only be valid under the new
..value of xlog.
* PR# 837 *
Subject: screen doesn't handle redrawing properly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 01 Feb 2001 14:20:52 -0500
* PR# 887 *
Subject: axis(adj=anything) has no effect
From: jhallman@frb.gov
Date: Wed, 28 Mar 2001 20:51:05 +0200 (MET DST)
* PR# 943 *
Subject: legend() with xpd=T; omission of initial plot character
From: John Maindonald <john.maindonald@anu.edu.au>
Date: Sun, 20 May 2001 10:35:16 +1000
* PR# 997 *
Subject:  las=1 with log axis 
From: Peter Dalgaard BSA <pd@pubhealth.ku.dk>
Date: Wed, 27 Jun 2001 11:54:06 +0200
* PR# 1045 *
Subject: Palette changes on redraw
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 08 Aug 2001 19:08:01 +0200
* PR# 1147 *
Subject: postscript problem
From: kjetil halvorsen <kjetilh@umsanet.edu.bo>
Date: Fri, 26 Oct 2001 15:23:45 -0400
..This seems to be a problem with screen/layout rather than postscript.
* PR# 1161 *
Subject: x-axis label in persp()
From: Rolf Turner <rolf@maths.uwa.edu.au>
Date: Wed, 7 Nov 2001 18:07:22 +0800 (WST)
* PR# 1207 *
Subject: boxplot labels incorrect when horizontal = TRUE
From: Rashid Nassar <rnassar@duke.edu>
Date: Sun, 9 Dec 2001 21:46:32 -0500 (EST)
* PR# 1235 *
Subject: Axes labelling with logarithmic scales
From: tobias.hoevekamp@ilw.agrl.ethz.ch
Date: Thu, 3 Jan 2002 15:29:02 +0100 (MET)
* PR# 1300 *
Subject: FW: layout and piechart diameter problem
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Thu, 7 Feb 2002 11:05:15 -0500 
* PR# 1395 *
Subject: mgp parameter in par()
From: mh.smith@niwa.cri.nz
Date: Tue, 19 Mar 2002 06:11:49 +0100 (MET)
* PR# 1505 *
Subject: pictex 
From: luchini@ehess.cnrs-mrs.fr
Date: Thu, 2 May 2002 12:23:21 +0200 (MET DST)
* PR# 1653 *
Subject: coplot behaviour
From: "RenE J.V. Bertin" <rjvbertin@hotmail.com>
Date: Mon, 10 Jun 2002 20:11:02 +0200
* PR# 1654 *
Subject: R 1.5.0: axis() does not honor the xaxp argument
From: "Robert D. Merithew" <merithew@ccmr.cornell.edu>
Date: Tue, 11 Jun 2002 09:29:39 -0400 (EDT)
* PR# 1659 *
Subject:  mtext() alignment of perpendicular text 
From: p.murrell@auckland.ac.nz
Date: Wed, 12 Jun 2002 13:29:45 +1200 (NZST)
* PR# 1878 *
Subject: close.screen
From: Martin.Schlather@uni-bayreuth.de
Date: Mon, 5 Aug 2002 22:35:02 +0200 (MET DST)
* PR# 1933 *
Subject: dev2eps() prints ticks with wrong length!
From: Timur Elzhov <Timur.Elzhov@jinr.ru>
Date: Fri, 23 Aug 2002 17:22:15 +0400
..dev.copy problem
* PR# 2069 *
Subject: split.screen problem
From: cbodily@att.net
Date: Thu, 26 Sep 2002 19:37:40 +0200 (MET DST)
* PR# 2283 *
Subject: Wandering usr values in par(no.readonly=TRUW)
From: Jari Oksanen <jarioksa@sun3.oulu.fi>
Date: Tue, 12 Nov 2002 13:50:44 +0200
* PR# 2578 *
Subject: "trace" argument in legend()
From: jerome@hivnet.ubc.ca
Date: Mon, 24 Feb 2003 18:53:29 +0100 (MET)
* PR# 2628 *
Subject: cex.axis in boxplot
From: Torsten Hothorn <Torsten.Hothorn@rzmail.uni-erlangen.de>
Date: Wed, 12 Mar 2003 17:27:34 +0100 (CET)
* PR# 2630 *
Subject: plot() with type="s" and lty=2
From: jerome@hivnet.ubc.ca
Date: Wed, 12 Mar 2003 23:35:59 +0100 (MET)

Directory:  In-Out

* PR# 1688 *
Subject: Maybe a problem in binary read/write
From: accot@free.fr
Date: Tue, 18 Jun 2002 22:51:17 +0200 (MET DST)
..I don't think file() is said to work with devices!

Directory:  Installation

* PR# 1222 *
Subject: configure: sed: Function s%@PDFLATEX@%/usr/local/bin/pdflatex%g
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Thu, 20 Dec 2001 14:09:42 +0100 (CET)
..problem is on hppa2.0-hp-hpux10.20: may be HP-UX specific
* PR# 1268 *
Subject: Solaris 2.6 Compile
From: gm81640@development.nssmb.com
Date: Thu, 17 Jan 2002 06:28:26 +0100 (MET)
..Most likely a compiler installation problem
* PR# 1291 *
Subject: Installation problem : SunOS
From: brendan_mcmahon@prusec.com
Date: Thu, 31 Jan 2002 18:00:55 +0100 (MET)
..looks like gcc compiled under different OS version.
* PR# 1500 *
Subject: configure script fails on comment in tkConfig.sh
From: Peter Kleiweg <kleiweg@let.rug.nl>
Date: Tue, 30 Apr 2002 16:41:51 +0200 (CEST)
..Looks like a conspiracy between a shell problem and an oddity in Tk 8.0 rather
..than an R problem. Good to know for the workaround though. The comment in
..TK_XINCLUDES has since disappeared, at least in Tk 8.3.3.
* PR# 1658 *
Subject: make install fails - index.html not found
From: dhouston@bio.ri.ccf.org
Date: Tue, 11 Jun 2002 22:14:07 +0200 (MET DST)
..Missing perl??
* PR# 1676 *
Subject: R configure.in makes bad alpha assumptions
From: mcmahill@mtl.mit.edu
Date: Sat, 15 Jun 2002 19:21:09 -0400 (EDT)
..Probably fixed in 1.5.1
* PR# 1825 *
Subject: bug in R-1.5.1 for Mac OS X installer
From: Kow Kuroda <kkuroda@crl.ucsd.edu>
Date: Mon, 22 Jul 2002 16:40:26 -0700
..Darwin port
* PR# 1829 *
Subject: R config failure on solaris
From: "Siva Ginjupalli" <gsivrao@hotmail.com>
Date: Wed, 24 Jul 2002 20:08:49 +0000
..Missing info on R version and compilers.

Directory:  Language

* PR# 408 *
Subject: convolution bug
From: wsimpson@gcal.ac.uk
Date: Fri, 28 Jan 2000 11:17:36 +0100 (MET)
* PR# 412 *
Subject: anomalies with call objects
From: Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk>
Date: 06 Feb 2000 01:18:50 +0100
* PR# 669 *
Subject: Bug(s) w/ rbind.data.frame(); fix also read.table(*, as.is = TRUE) ?
From: Martin Maechler <maechler@stat.math.ethz.ch>
Date: Mon, 25 Sep 2000 10:17:15 +0200
..status of AsIs columns
* PR# 1073 *
Subject: Wierd problem comparing numeric values and list using ==
From: "Warnes, Gregory R" <gregory_r_warnes@groton.pfizer.com>
Date: Fri, 24 Aug 2001 22:07:41 -0400
..see also PR#1075
* PR# 1076 *
Subject: Re: [Rd] Wierd problem comparing numeric values and list using == 
From: John Chambers <jmc@research.bell-labs.com>
Date: Mon, 27 Aug 2001 08:44:22 -0400
..part of PR#1073
* PR# 1186 *
Subject: a patch to tapply
From: Vadim Ogranovich <vograno@arbitrade.com>
Date: Thu, 29 Nov 2001 14:48:35 -0600
* PR# 1214 *
Subject: syntax questtion, maybe a bug
From: Rich Heiberger <rmh@surfer.sbm.temple.edu>
Date: Thu, 13 Dec 2001 13:46:54 -0500 (EST)
..Is .2logl meant to be a valid name in R? It is S
* PR# 1241 *
Subject:  Problem with "missing" in "local" 
From: J.C.Rougier@durham.ac.uk
Date: Fri, 4 Jan 2002 13:34:34 GMT
* PR# 1556 *
Subject: lib.fixup, .GlobalEnv, and R1.5.0
From: mark.bravington@csiro.au
Date: Wed, 15 May 2002 08:30:50 +0200 (MET DST)

Directory:  Low-level

* PR# 989 *
Subject: "[.data.frame" allows un-named 3rd subscript
From: "Charles C. Berry" <cberry@tajo.ucsd.edu>
Date: Mon, 18 Jun 2001 13:13:46 -0700 (PDT)
* PR# 1068 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: Luke Tierney <luke@nokomis.stat.umn.edu>
Date: Wed, 22 Aug 2001 19:32:51 -0500
..see also followup in PR#1069
* PR# 1069 *
Subject: Interrupts (was Re: [Rd] X11 protocol errors ...)
From: "John W. Eaton" <jwe@bevo.che.wisc.edu>
Date: Wed, 22 Aug 2001 21:56:33 -0500
..part of PR#1068
* PR# 1880 *
Subject:  You requested this report 
From: Berwin Turlach <berwin@maths.uwa.edu.au>
Date: Tue, 6 Aug 2002 16:57:54 +0800
..The bug is that we get as far as mkCLOSXP before an error is reported
* PR# 2253 *
Subject: [R] CTRL-C suspends echo of shell (R versions 1.6.0 and 1.6.1)
From: Wolfram Fischer - Z/I/M <wolfram@fischer-zim.ch>
Date: Mon, 4 Nov 2002 10:18:48 +0100
* PR# 2846 *
Subject: Kinderman-Ramage
From: Josef Leydold <leydold@statistik.wu-wien.ac.at>
Date: Fri, 25 Apr 2003 13:18:53 +0200 (CEST)
* PR# 2991 *
Subject: qt(p,df) discontinuous in p for df in 1.01->1.7
From: jens.lund@nordea.com
Date: Tue, 13 May 2003 13:29:14 +0200 (MET DST)

Directory:  Macintosh

* PR# 1819 *
Subject: Date arithmetic fails
From: RML27@cornell.edu
Date: Sun, 21 Jul 2002 20:26:12 +0200 (MET DST)
..In fact, as.POSIXct is off by 66 years. See
..   http://developer.apple.com/qa/ops/ops23.html
..This is semifixed, but timezones still don't work
* PR# 1991 *
Subject: Mac Save As... bug
From: Tim Cole <tjc1@cam.ac.uk>
Date: Sun, 8 Sep 2002 13:47:00 +0100
* PR# 2276 *
Subject: Mac specific - quartz leads to crash
From: h95mr@mun.ca
Date: Fri, 8 Nov 2002 16:28:50 +0100 (MET)
* PR# 2550 *
Subject: eigen() error: R Version 1.6.1 on Mac OS X
From: "Daniel E. Weeks" <dweeks@watson.hgen.pitt.edu>
Date: Fri, 14 Feb 2003 15:36:15 -0500
* PR# 2725 *
Subject: Default broswer for OS X
From: james@freelancepropaganda.com
Date: Fri, 4 Apr 2003 06:04:48 +0200 (MET DST)
* PR# 2813 *
Subject: Search Engine
From: leroy@ucsd.edu
Date: Tue, 22 Apr 2003 06:21:19 +0200 (MET DST)
* PR# 2875 *
Subject: configure succeeds without dlfcn.h, but fails to compile (OS X)
From: buerkla@uwec.edu
Date: Tue, 29 Apr 2003 20:24:12 +0200 (MET DST)

Directory:  Misc

* PR# 1126 *
Subject: R-bug report www page whishlist
From: jens.lund@nordea.com
Date: Wed, 10 Oct 2001 18:24:29 +0200 (MET DST)
* PR# 1158 *
Subject: bug.report()sends empty message
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Mon, 05 Nov 2001 10:05:27 -0500
* PR# 1503 *
Subject: R-GNOME
From: Patrick Gonin <gonin@genethon.fr>
Date: Thu, 2 May 2002 09:29:07 +0200
..1) is not a bug, as jpeg etc work.  capabilities() has been changed for 1.5.1
..2) system() needs a new version for GNOME.
* PR# 2644 *
Subject: R CMD SHLIB uses foo.c instead of foo.cc if both are present
From: faheem@email.unc.edu
Date: Sun, 16 Mar 2003 19:47:55 +0100 (MET)
* PR# 2645 *
Subject: Re: [Rd] R CMD SHLIB uses foo.c instead of foo.cc if both are present
From: Faheem Mitha <faheem@email.unc.edu>
Date: Sun, 16 Mar 2003 15:44:14 -0500 (EST)
..part of 2644
* PR# 2648 *
Subject: Re: [Rd] R CMD SHLIB uses foo.c instead of foo.cc if both are present
From: Kurt Hornik <hornik@ci.tuwien.ac.at>
Date: Mon, 17 Mar 2003 21:32:55 +0100
..part of 2644

Directory:  Models

* PR# 1861 *
Subject: update() can not find objects
From: yzhou@arcturusag.com
Date: Thu, 1 Aug 2002 19:01:59 +0200 (MET DST)
..The problem is actually deeper than this.
..
..Sometime update() wants to evaluate arguments in the environment where the model
..was defined, as here. 
..
..Sometimes it wants to use the current environment, eg this snippet from MASS 
..ph.fun <- function(data, i) {
..  d <- data
..  d$calls <- d$fitted + d$res[i]
..  coef(update(fit, data=d))
..}

Directory:  Startup

none

Directory:  System-specific

* PR# 848 *
Subject: X11 device doesn't handle destroy events correcly
From: Thomas Vogels <tov@ece.cmu.edu>
Date: 13 Feb 2001 17:40:46 -0500
* PR# 1020 *
Subject: .Call and Mandrake 8.0
From: lcottret@yahoo.fr
Date: Wed, 11 Jul 2001 15:34:23 +0200 (MET DST)
..problem with symbol names only on Mandrake 8.0, not 7.2
..needs reply to follow-up
* PR# 1097 *
Subject: R 1.3.1 fails 'make check' on arm in the Bessel example
From: Dirk Eddelbuettel <edd@debian.org>
Date: Thu, 20 Sep 2001 23:54:19 -0500
..This platform turned out to have badly broken FPU behaviour. Given up, at 
..least for now .
* PR# 1140 *
Subject: Possible bug, Rprof() and scan(pipe())
From: Don MacQueen <macq@llnl.gov>
Date: Tue, 23 Oct 2001 13:50:26 -0700
..MacOS X: Doesn't happen on Solaris or Linux
* PR# 1261 *
Subject: R_140 AND RHL_72 AND Packages
From: Patrick Gonin <gonin@genethon.fr>
Date: Wed, 15 Jan 2003 13:25:17 +0100
..Seems to relate to RH7.2 rpms
* PR# 1272 *
Subject: eigen segfault with GCC 3 on Solaris
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Thu, 17 Jan 2002 15:14:33 -0500
..Seems to be a problem with g77 in gcc 3.0.2 on Solaris only.
..Probably a compiler bug
* PR# 1275 *
Subject: compile problem with bessel_i.c on IRIX64 flexor 6.5 10100655 IP35 (uname -a)
From: Walter Tautz <wtautz@math.uwaterloo.ca>
Date: Tue, 22 Jan 2002 10:05:20 -0500 (EST)
* PR# 1289 *
Subject: R 1.4.0 build fails on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Wed, 30 Jan 2002 14:10:30 +0100 (MET)
* PR# 1316 *
Subject: shared libraries on AIX
From: lio@hpss1.ccs.ornl.gov
Date: Mon, 18 Feb 2002 18:53:41 +0100 (MET)
* PR# 1461 *
Subject: make check fails d-p-q-r-tests.R - OpenBSD 3.0
From: Jason Turner <jasont@indigoindustrial.co.nz>
Date: Mon, 15 Apr 2002 10:13:36 +0000
* PR# 1606 *
Subject: hitting ^C breaks readline history
From: Cyril Humbert <humbertc@univ-mlv.fr>
Date: Tue, 28 May 2002 12:07:07 +0200 (MET DST)
* PR# 2730 *
Subject: Re: Bug#187537: r-base: FTBFS: hangs in tcltk test
From: Dirk Eddelbuettel <edd@debian.org>
Date: Fri, 4 Apr 2003 06:27:15 -0600
..something obscure in debian: pbuilder is not part of R
* PR# 2733 *
Subject: Re: Bug#187537: r-base: FTBFS: hangs in tcltk test
From: Daniel Schepler <schepler@math.berkeley.edu>
Date: 05 Apr 2003 14:06:09 -0800
..part of 2730
* PR# 2736 *
Subject: Re: Bug#187537: r-base: FTBFS: hangs in tcltk test
From: Dirk Eddelbuettel <edd@debian.org>
Date: Sun, 6 Apr 2003 21:20:29 -0500
..part of 2730
* PR# 2836 *
Subject: R-1.7.0: build feedback: OpenBSD 3.2
From: "Nelson H. F. Beebe" <beebe@math.utah.edu>
Date: Thu, 24 Apr 2003 11:40:35 -0600 (MDT)
* PR# 2837 *
Subject: R-1.7.0 build feedback: NetBSD 1.6
From: "Nelson H. F. Beebe" <beebe@math.utah.edu>
Date: Thu, 24 Apr 2003 11:45:20 -0600 (MDT)
* PR# 2887 *
Subject: tools/ldAIX4 Assumes AIX nm
From: rgrubbfink@cox.net
Date: Wed, 30 Apr 2003 22:24:34 +0200 (MET DST)
* PR# 2888 *
Subject: AIX 4.3.3 nm will not read all of dounzip.o
From: rgrubbfink@cox.net
Date: Wed, 30 Apr 2003 22:33:24 +0200 (MET DST)
..Looks like an AIX bug, not an R one.
..Other people have succeeded on AIX 5.1.

Directory:  TooMuchAtOnce

none

Directory:  Windows

* PR# 2798 *
Subject: Re: [R] Keyboard problem using RWin 1.7.0
From: DJNordlund@aol.com
Date: Sat, 19 Apr 2003 18:56:25 EDT
..Can't reproduce so far.

Directory:  incoming

* PR# 2461 *
Subject: apropos() with partial name
From: John Maindonald <u9801539@leonard.anu.edu.au>
Date: Thu, 16 Jan 2003 20:22:23 +1100 (EST)
..The proposed fix would make it impossible to pass a variable to apropos
..
..eg 
..
..> sor<-"plot"
..> apropos(sor)
..[1] "sor"          "isoreg"       "sortedXyData" "is.unsorted"  "sort"        
..[6] "sort.list"   
..
..A better fix might be to require the argument to be a string.
* PR# 2577 *
Subject: Problem with hessian in deriv3 
From: j.c.rougier@durham.ac.uk
Date: Mon, 24 Feb 2003 17:01:47 GMT
* PR# 2593 *
Subject: density(), with argument of length 1
From: John Maindonald <u9801539@leonard.anu.edu.au>
Date: Sat, 1 Mar 2003 16:35:56 +1100 (EST)
* PR# 2656 *
Subject: recursive default argument reference in debugger
From: pburns@pburns.seanet.com
Date: Wed, 19 Mar 2003 12:23:40 +0100 (MET)
* PR# 2808 *
Subject: building R 1.7.0 under RH7.3
From: Tim Hoar <thoar@cgd.ucar.edu>
Date: Mon, 21 Apr 2003 13:16:16 -0600 (MDT)
* PR# 2809 *
Subject: sweave provoked segfault
From: Paul Gilbert <pgilbert@bank-banque-canada.ca>
Date: Mon, 21 Apr 2003 17:01:53 -0400
* PR# 2822 *
Subject: "LAPACK routine DGESDD gave error code -12" with Debian
From: Ramon Diaz <rdiaz@cnio.es>
Date: Tue, 22 Apr 2003 20:06:21 +0200
* PR# 2823 *
Subject: Re: [Rd] 
From: Kurt Hornik <hornik@ci.tuwien.ac.at>
Date: Tue, 22 Apr 2003 20:15:19 +0200
..part of 2822
* PR# 2824 *
Subject: coplot panels malrendered / 1653
From: dmaszle@mendelbio.com
Date: Wed, 23 Apr 2003 02:19:53 +0200 (MET DST)
* PR# 2876 *
Subject: Re: [Rd]  configure succeeds without dlfcn.h, but fails to compile
From: Thomas Lumley <tlumley@u.washington.edu>
Date: Tue, 29 Apr 2003 13:02:25 -0700 (PDT)
* PR# 2878 *
Subject: Problem with R CMD INSTALL and package versions
From: rpeng@stat.ucla.edu
Date: Wed, 30 Apr 2003 08:23:12 +0200 (MET DST)
* PR# 2894 *
Subject: qbeta hang
From: terra@gnome.org
Date: Thu, 1 May 2003 22:43:59 +0200 (MET DST)
* PR# 2923 *
Subject: segfault when applying strange coercion
From: Uwe Ligges <ligges@statistik.uni-dortmund.de>
Date: Mon, 05 May 2003 19:36:01 +0200
* PR# 3059 *
Subject: Re: Approved (Ref: 3394-65467)
From: <support@microsoft.com>
Date: Tue, 20 May 2003 17:46:52 +0200
* PR# 3060 *
Subject: Cool screensaver
From: <support@microsoft.com>
Date: Tue, 20 May 2003 12:12:47 --0500
* PR# 3061 *
Subject: Increase your penis size naturally xpt
From: "Adriana Funk" <073saxzkf@hotmail.com>
Date: Tue, 20 May 03 21:57:30 GMT
* PR# 3062 *
Subject: CRY FOR HELP
From: james burudu <jamesburudu@netscape.net>
Date: Wed, 21 May 2003 00:18:44 +0200
* PR# 3063 *
Subject: Classified advertising is absolutely useless on the Internet!
From: tuxeco@polbox.pl
Date: Mon, 19 May 2003 09:19:12 -0500
* PR# 3064 *
Subject: athenuan indelicle
From: "Darcy Phelps" <k71w5x3z13@yhaoo.com>
Date: Wed, 21 May 03 23:58:50 GMT

From ripley at stats.ox.ac.uk  Wed May 21 08:28:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed May 21 08:29:14 2003
Subject: [Rd] axis() default values for "lty", "lwd", and "col"
In-Reply-To: <200305202245.PAA15730@hivnet.ubc.ca>
Message-ID: <Pine.LNX.4.44.0305210718180.28736-100000@gannet.stats>

I believe this to be deliberate.  If I do

par(lty=2,lwd=3,col="blue")
plot(1:10)

I do not want the axes to be thick, dotted and blue, with black labels.
(It is also I suspect deliberate that

plot(1:10,lty=2,lwd=3,col="blue")

does not pass any of those parameters on to axis().)

You say you made the labels bigger: to do that you needed to set cex.axis 
and cex.main, not cex.

I'm afraid this change would break a lot of existing code.  I am aware 
that S-PLUS does this (with blue labels too), and I have always found it
irritating to have to work around it.


On Tue, 20 May 2003, Jerome Asselin wrote:

> I would like to recommend a minor modification in axis() which I believe 
> can simplify the making of plots for publications. I am trying to define 
> default values for par() in order to make labels bigger and lines thicker, 
> so that the resulting plots look good when resized for publication 
> purposes. I ran into the following problem...
> 
> axis() does not use par() values as default for "lty", "lwd", and "col". 
> Here is an example.
> 
> par(lty=2,lwd=3,col="blue")
> plot(1,1,bty="n",axes=F)
> axis(1)
> axis(2)
> 
> Because axis() doesn't use the par() values, I have to explicitely define 
> the parameters "lty", "lwd", and "col" in my axis() calls. It would make 
> sense if axis() used the par() values by default.
> 
> Hence, I recommend this simple fix in the axis() function([...]) statement 
> in order to have axis() read the par() values for "lty", "lwd", and "col".
> 
> axis <- 
> function (side, at = NULL, labels = TRUE, tick = TRUE, line = NA,
>     pos = NA, outer = FALSE, font = NA, vfont = NULL, lty = par("lty"),
>     lwd = par("lwd"), col = par("col"), ...)
> { [...] }
> 
> I use R1.7.0 on Red Hat Linux 7.2.
> 
> Sincerely,
> Jerome Asselin
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jerome at hivnet.ubc.ca  Wed May 21 02:27:36 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed May 21 10:28:58 2003
Subject: [Rd] axis() default values for "lty", "lwd", and "col"
In-Reply-To: <Pine.LNX.4.44.0305210718180.28736-100000@gannet.stats>
References: <Pine.LNX.4.44.0305210718180.28736-100000@gannet.stats>
Message-ID: <200305210833.BAA02862@hivnet.ubc.ca>


Thank you Prof Ripley for your comments. Let me explain in greater detail 
what I was thinking.

I agree that blue dotted axes are quite unusual, but thicker axes are 
useful. With the default lwd=1, some tickmarks don't show up if I shrink 
my plot and then print it on paper. Using lwd=2 for axes does fix that 
problem, but I have to make separate calls to axis() with option lwd=2 in 
order to do that.

My vision was that par() would give default values for everything 
(including lwd, lty and col) to be plotted in the graphical device. The 
user would explicitely define parameters in specific functions when 
different options are required.

For example, the following would give axes and tickmarks of lwd=2, but the 
diagonal line would be of lwd=4.
par(lwd=2)
plot(1:10,type="l",lwd=4)
Note that the box around the plot is of lwd=2 (as I would expect), but the 
axes (which are hidden under the box) and tickmarks are drawn with lwd=1. 
So there is an inconsistency between the width of the box and the 
tickmarks (and "hidden" axes). Why should there be?

Moreover, I think the user should have a good reason for using
  par(lty=2,lwd=3,col="blue")
  plot(1:10)
as opposed to
  dev.off() #clean up!
  plot(1:10,lty=2,lwd=3,col="blue")
These two ways of plotting are very different. In the first way, the 
parameters lty=2, lwd=3, and col="blue" should apply to everything in the 
graphical window, whereas in the second way they should apply only to the 
points.

Ideally, the distinction should be clear and consistent for all plotting 
functions. I also share your concerns that "this change would break a lot 
of existing code".

Sincerely,
Jerome Asselin

On May 20, 2003 11:28 pm, Prof Brian Ripley wrote:
> I believe this to be deliberate.  If I do
>
> par(lty=2,lwd=3,col="blue")
> plot(1:10)
>
> I do not want the axes to be thick, dotted and blue, with black labels.
> (It is also I suspect deliberate that
>
> plot(1:10,lty=2,lwd=3,col="blue")
>
> does not pass any of those parameters on to axis().)
>
> You say you made the labels bigger: to do that you needed to set
> cex.axis and cex.main, not cex.
>
> I'm afraid this change would break a lot of existing code.  I am aware
> that S-PLUS does this (with blue labels too), and I have always found it
> irritating to have to work around it.
>
> On Tue, 20 May 2003, Jerome Asselin wrote:
> > I would like to recommend a minor modification in axis() which I
> > believe can simplify the making of plots for publications. I am trying
> > to define default values for par() in order to make labels bigger and
> > lines thicker, so that the resulting plots look good when resized for
> > publication purposes. I ran into the following problem...
> >
> > axis() does not use par() values as default for "lty", "lwd", and
> > "col". Here is an example.
> >
> > par(lty=2,lwd=3,col="blue")
> > plot(1,1,bty="n",axes=F)
> > axis(1)
> > axis(2)
> >
> > Because axis() doesn't use the par() values, I have to explicitely
> > define the parameters "lty", "lwd", and "col" in my axis() calls. It
> > would make sense if axis() used the par() values by default.
> >
> > Hence, I recommend this simple fix in the axis() function([...])
> > statement in order to have axis() read the par() values for "lty",
> > "lwd", and "col".
> >
> > axis <-
> > function (side, at = NULL, labels = TRUE, tick = TRUE, line = NA,
> >     pos = NA, outer = FALSE, font = NA, vfont = NULL, lty =
> > par("lty"), lwd = par("lwd"), col = par("col"), ...)
> > { [...] }
> >
> > I use R1.7.0 on Red Hat Linux 7.2.
> >
> > Sincerely,
> > Jerome Asselin

From maechler at stat.math.ethz.ch  Wed May 21 13:06:28 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed May 21 12:07:09 2003
Subject: [Rd] axis() default values for "lty", "lwd", and "col"
In-Reply-To: <200305210833.BAA02862@hivnet.ubc.ca>
References: <Pine.LNX.4.44.0305210718180.28736-100000@gannet.stats>
	<200305210833.BAA02862@hivnet.ubc.ca>
Message-ID: <16075.20388.509660.12666@gargle.gargle.HOWL>

Jerome,

I understand your wish, but as Prof Ripley said, 
we have very good reasons to not got that way.
For your situation, please use global  par() settings.

But for the general problem, I'm musing on a bit... :

1.  One should use  library(grid) {plus sometimes (lattice)}
    instead, but given the current non-compatibility with
    base graphics, this won't always work.

2.
  R has more  par() options than AT&T S or S-plus -- exactly for
  the purpose of setting col/cex/... setting for axis labels separately,
  and (as Prof Ripley suggested) on purpose we're not taking other
  global par() settings for drawing of the axis() line {and the box() around!}.

Consider e.g.

  > nP <- names(par(no.readonly = TRUE))

  > nP[grep("^col",nP)]
  [1] "col"      "col.axis" "col.lab"  "col.main" "col.sub" 

  > nP[grep("axis",nP)]
  [1] "cex.axis"  "col.axis"  "font.axis"
  > 

then,
  > example(axis)

and,

  > plot(1:10, col.axis = "red", cex.axis = 2)

which does use double-sized axis *labels* in red.
If you read help(par), you'll see that the *.axis parameters are
used for axis *annotation* only.
One thing which would not break back-compatibility  I could
imagine is to introduce more par attributes:

  "col.axline"
  "lwd.axline"
  "lty.axline"
and default the axis() arguments to these.

Further, the box(lty = ) {and implicit "lwd" and "col") arguments would
also need new par() defaults {or have to default to the the
above *.axline ones}.

Finally, one might consider yet another set of par()s and
high-level plot arguments :

"col.ALL", "lty.ALL" , "lwd.ALL"
(and "cex.ALL" ?)  would change all the  col.* {or lty.* or ...}
at once.

Not sure these additions (and entailing complications) are
worth the effort.

--

Martin Maechler <maechler@stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

From ripley at stats.ox.ac.uk  Wed May 21 16:33:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed May 21 16:33:44 2003
Subject: [Rd] Size of x11 device
Message-ID: <Pine.LNX.4.44.0305211519250.32308-100000@gannet.stats>

I've fairly recently changed my Linux desktop, and now use a XFree86 
server.  The default X11() window is rather small: it is supposed to be 
7" x 7".  However,

1) It is actually just over 5" x 5" and
2) 7" x 7" would be rather small on a 21" screen.

The reason for 1) is that DisplayWidthMM give 542mm, when it is really 
close to 400mm (and the correct monitor was specified).

So two questions.

a) does anyone know how to get the X server to give the correct size (on a
Matrox G550), or do we need (as on Windows) to have a means for the user
to override it?

b) should there be an option to set the default size of an X11 device?
(On Windows the default size depends on the screen size, since 7" would be
very large for a 10.4" LCD.)

The answers probably depend on how common a problem this is.

Brian

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From MSchwartz at medanalytics.com  Wed May 21 16:01:12 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed May 21 17:01:15 2003
Subject: [Rd] Size of x11 device
In-Reply-To: <Pine.LNX.4.44.0305211519250.32308-100000@gannet.stats>
References: <Pine.LNX.4.44.0305211519250.32308-100000@gannet.stats>
Message-ID: <1053529218.20704.27.camel@localhost>

On Wed, 2003-05-21 at 09:33, Prof Brian Ripley wrote:
> I've fairly recently changed my Linux desktop, and now use a XFree86 
> server.  The default X11() window is rather small: it is supposed to be 
> 7" x 7".  However,
> 
> 1) It is actually just over 5" x 5" and
> 2) 7" x 7" would be rather small on a 21" screen.
> 
> The reason for 1) is that DisplayWidthMM give 542mm, when it is really 
> close to 400mm (and the correct monitor was specified).
> 
> So two questions.
> 
> a) does anyone know how to get the X server to give the correct size (on a
> Matrox G550), or do we need (as on Windows) to have a means for the user
> to override it?
> 
> b) should there be an option to set the default size of an X11 device?
> (On Windows the default size depends on the screen size, since 7" would be
> very large for a 10.4" LCD.)
> 
> The answers probably depend on how common a problem this is.
> 
> Brian


Professor Ripley,

One thing that you may want to check is to see what the dpi setting is
for your display in the X11 setup.

On my Dell i8200 laptop, which has a 1600 x 1200 LCD panel, I have the
dpi set to 133 (305 mm x 229 mm), which is the actual measure.  If I set
this to some other figure then all graphics and fonts are scaled
accordingly.

On RH 9, this is set under System Settings -> Display -> Advanced.

This is also reflected in /etc/X11/XF86Config:

Section "Monitor"
	Identifier   "Monitor0"
	VendorName   "Monitor Vendor"
	ModelName    "Dell 1600x1200 Laptop Display Panel"
	DisplaySize  305	229
	HorizSync    31.5 - 90.0
	VertRefresh  59.0 - 85.0
	Option	    "dpms"
EndSection

Section "Device"
	Identifier  "Videocard0"
	Driver      "nvidia"
	VendorName  "Videocard vendor"
	BoardName   "NVIDIA GeForce 4 (generic)"
	VideoRam    65536
EndSection

Section "Screen"
	Identifier "Screen0"
	Device     "Videocard0"
	Monitor    "Monitor0"
	DefaultDepth     24
	SubSection "Display"
		Depth     24
		Modes    "1600x1200" "1400x1050" "1280x1024" "1280x960" "1152x864"
"1024x768" "800x600" "640x480"
	EndSubSection
EndSection


I hope that is of some help to you.  If I can provide any other
information, please let me know.

Best regards,

Marc Schwartz

From ripley at stats.ox.ac.uk  Wed May 21 20:35:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed May 21 20:36:41 2003
Subject: [Rd] Size of x11 device
In-Reply-To: <Pine.LNX.4.44.0305211519250.32308-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0305211926230.941-100000@gannet.stats>

On Wed, 21 May 2003, Prof Brian Ripley wrote:

> I've fairly recently changed my Linux desktop, and now use a XFree86 
> server.  The default X11() window is rather small: it is supposed to be 
> 7" x 7".  However,
> 
> 1) It is actually just over 5" x 5" and
> 2) 7" x 7" would be rather small on a 21" screen.
> 
> The reason for 1) is that DisplayWidthMM give 542mm, when it is really 
> close to 400mm (and the correct monitor was specified).

Thanks to Marc Schwartz and Simon Urbanek for help on examining this.  It
seems there is a bug in my setup: it is configured (correctly) for 400 x
300mm, 1600x1200 and hence 102dpi, but 1600 at 75dpi is 542mm.


Is anyone else unhappy with what the default 7" x 7" gives them?

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Wed May 21 20:52:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed May 21 21:52:54 2003
Subject: [Rd] Size of x11 device
In-Reply-To: <Pine.LNX.4.44.0305211926230.941-100000@gannet.stats>
References: <Pine.LNX.4.44.0305211926230.941-100000@gannet.stats>
Message-ID: <x2fzn8f4wi.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> On Wed, 21 May 2003, Prof Brian Ripley wrote:
> 
> > I've fairly recently changed my Linux desktop, and now use a XFree86 
> > server.  The default X11() window is rather small: it is supposed to be 
> > 7" x 7".  However,
> > 
> > 1) It is actually just over 5" x 5" and
> > 2) 7" x 7" would be rather small on a 21" screen.
> > 
> > The reason for 1) is that DisplayWidthMM give 542mm, when it is really 
> > close to 400mm (and the correct monitor was specified).
> 
> Thanks to Marc Schwartz and Simon Urbanek for help on examining this.  It
> seems there is a bug in my setup: it is configured (correctly) for 400 x
> 300mm, 1600x1200 and hence 102dpi, but 1600 at 75dpi is 542mm.
> 
> 
> Is anyone else unhappy with what the default 7" x 7" gives them?

Not on this machine, no. On a 17" screen it fills just about half the
screenwidth, which is quite reasonable if you want to be able to
navigate between multiple windows.

My resolution is a bit on the high side too: xdpyinfo claims 75 dpi
and display width of 347mm but it's actually closer to 325mm, and the
window about 166mm instead of 178mm.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From B.Rowlingson at lancaster.ac.uk  Thu May 22 11:43:30 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu May 22 11:44:10 2003
Subject: [Rd] Size of x11 device
In-Reply-To: <x2fzn8f4wi.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0305211926230.941-100000@gannet.stats>
	<x2fzn8f4wi.fsf@biostat.ku.dk>
Message-ID: <3ECC9BC2.3050302@lancaster.ac.uk>


>>
>>Is anyone else unhappy with what the default 7" x 7" gives them?
> 

  My Sony Vaio C-series sub-notebook has a screen that is about 5" high. 
I dont think I've tried running R in linux on it yet, but I dont like 
the idea of having 2 inches of X11 display hanging off the bottom.

  What alternatives are there to initial graphic device window size?

  A: fixed at 7"x7" (or some other size)
  B: fixed at 600pixels by 600pixels (or some other pixel size)
  C: fixed at X% by Y% of the screen size
  D: fixed at some absolute size unless the screen isnt big enough, in 
which case go as big as possible but remaining completely visible

  Some of these options may be confounded by window manager decorations, 
of course. I'm not that picky about which option I prefer, as long as 
its easy enough to choose a new one and save it as a preference.

Baz

From ross at biostat.ucsf.edu  Wed May 21 22:18:10 2003
From: ross at biostat.ucsf.edu (ross@biostat.ucsf.edu)
Date: Thu May 22 12:14:11 2003
Subject: [Rd] Possible R CMD check problem (PR#3070)
Message-ID: <200305211918.h4LJIA2b007276@pubhealth.ku.dk>

Using R 1.7.0 I get 
* checking parcv-manual.tex ... ERROR
Could not create DVI version.

Although there is no apparent error.  The dvi file exists.
Possibly there is some problem with my TeX setup, but the following
messages don't suggest that either.

Here's the full log, which does show some documentation issues:
sheep:~$R CMD check --library=.R/library/ src/parcv
* checking for working latex ... OK
* using log directory '/space/home/ross/parcv.Rcheck'
* checking for file 'parcv/DESCRIPTION' ... OK
* checking if this is a source package ... OK

* Installing *source* package 'parcv' ...
** R
** demo
** inst
** help
 >>> Building/Updating help pages for package 'parcv'
     Formats: text html latex example
* DONE (parcv)

* DONE (INSTALL)

* checking package directory ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking package dependencies ... OK
* checking index information ... WARNING
Demos with missing or empty index information:
[1] "parDemo1"
See the information on INDEX files and package subdirectories in
* section
'Creating R packages' of the 'Writing R Extensions' manual.
* checking package subdirectories ... OK
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking generic/method consistency ... OK
* checking for assignment functions with final arg not named 'value'
* ... OK
* checking Rd files ... WARNING
Rd files without 'alias':
  man/parcv-internal.Rd
These tags are required in an Rd file.
See chapter 'Writing R documentation' in manual 'Writing R
Extensions'.
* checking for undocumented objects ... WARNING
Undocumented code objects:
[1] "crossval.fit"      "crossval.outerfit" "crossval.setup"
[4] "gcv"
* checking for code/documentation mismatches ... OK
* checking for undocumented arguments in \usage ... OK
* creating parcv-Ex.R ... OK
* checking examples ... OK
* creating parcv-manual.tex ... OK
* checking parcv-manual.tex ... ERROR
Could not create DVI version.
This typically indicates Rd problems.

From ross at biostat.ucsf.edu  Wed May 21 22:22:43 2003
From: ross at biostat.ucsf.edu (ross@biostat.ucsf.edu)
Date: Thu May 22 12:14:32 2003
Subject: [Rd] ~ files not excluded from build (PR#3071)
Message-ID: <200305211922.h4LJMh2b007293@pubhealth.ku.dk>

My docs say files ending in ~ are excluded by default from R CMD build.
Doesn't look that way to me.  I got them with 1.6.2 and 1.7.0.
My documenation is 1.6.0 (that is, the one saying *~ is excluded).

I have no .Rbuildignore of my own.

From Friedrich.Leisch at ci.tuwien.ac.at  Thu May 22 13:52:42 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu May 22 12:53:25 2003
Subject: [Rd] Possible R CMD check problem (PR#3070)
In-Reply-To: <200305211918.h4LJIA2b007276@pubhealth.ku.dk>
References: <200305211918.h4LJIA2b007276@pubhealth.ku.dk>
Message-ID: <16076.44026.665412.70300@galadriel.ci.tuwien.ac.at>


Why do you think there is a bug in R rather than in your package? (I
assume that it is a package of yours, at least it's not on CRAN).

How should we be able to track this problem for you? You don't specify
your computing platform and give us no examples we could try to
reproduce.

Does running latex on parcv-manual.tex in a shell work?

fritz leisch


>>>>> On Wed, 21 May 2003 21:18:10 +0200 (MET DST),
>>>>> ross  (r) wrote:

  > Using R 1.7.0 I get 
  > * checking parcv-manual.tex ... ERROR
  > Could not create DVI version.

  > Although there is no apparent error.  The dvi file exists.
  > Possibly there is some problem with my TeX setup, but the following
  > messages don't suggest that either.

  > Here's the full log, which does show some documentation issues:
  > sheep:~$R CMD check --library=.R/library/ src/parcv
  > * checking for working latex ... OK
  > * using log directory '/space/home/ross/parcv.Rcheck'
  > * checking for file 'parcv/DESCRIPTION' ... OK
  > * checking if this is a source package ... OK

  > * Installing *source* package 'parcv' ...
  > ** R
  > ** demo
  > ** inst
  > ** help
  >>>> Building/Updating help pages for package 'parcv'
  >      Formats: text html latex example
  > * DONE (parcv)

  > * DONE (INSTALL)

  > * checking package directory ... OK
  > * checking for sufficient/correct file permissions ... OK
  > * checking DESCRIPTION meta-information ... OK
  > * checking package dependencies ... OK
  > * checking index information ... WARNING
  > Demos with missing or empty index information:
  > [1] "parDemo1"
  > See the information on INDEX files and package subdirectories in
  > * section
  > 'Creating R packages' of the 'Writing R Extensions' manual.
  > * checking package subdirectories ... OK
  > * checking R files for syntax errors ... OK
  > * checking R files for library.dynam ... OK
  > * checking generic/method consistency ... OK
  > * checking for assignment functions with final arg not named 'value'
  > * ... OK
  > * checking Rd files ... WARNING
  > Rd files without 'alias':
  >   man/parcv-internal.Rd
  > These tags are required in an Rd file.
  > See chapter 'Writing R documentation' in manual 'Writing R
  > Extensions'.
  > * checking for undocumented objects ... WARNING
  > Undocumented code objects:
  > [1] "crossval.fit"      "crossval.outerfit" "crossval.setup"
  > [4] "gcv"
  > * checking for code/documentation mismatches ... OK
  > * checking for undocumented arguments in \usage ... OK
  > * creating parcv-Ex.R ... OK
  > * checking examples ... OK
  > * creating parcv-manual.tex ... OK
  > * checking parcv-manual.tex ... ERROR
  > Could not create DVI version.
  > This typically indicates Rd problems.

  > ______________________________________________
  > R-devel@stat.math.ethz.ch mailing list
  > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

From Friedrich.Leisch at ci.tuwien.ac.at  Thu May 22 13:57:46 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu May 22 12:58:31 2003
Subject: [Rd] ~ files not excluded from build (PR#3071)
In-Reply-To: <200305211922.h4LJMh2b007293@pubhealth.ku.dk>
References: <200305211922.h4LJMh2b007293@pubhealth.ku.dk>
Message-ID: <16076.44330.909526.573376@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 21 May 2003 21:22:43 +0200 (MET DST),
>>>>> ross  (r) wrote:

  > My docs say files ending in ~ are excluded by default from R CMD build.
  > Doesn't look that way to me.  I got them with 1.6.2 and 1.7.0.
  > My documenation is 1.6.0 (that is, the one saying *~ is excluded).

  > I have no .Rbuildignore of my own.

Again, hard to track down without more information on your compyting
platform and reproducible examples.

The feature works for me using 1.7.0 on debian linux, i.e., files
ending in ~ are excluded (without a .Rbuildignore file).

fritz leisch

From pgilbert at bank-banque-canada.ca  Thu May 22 11:00:17 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu May 22 16:01:31 2003
Subject: [Rd] ~ files not excluded from build (PR#3071)
In-Reply-To: <200305211922.h4LJMh2b007293@pubhealth.ku.dk>
References: <200305211922.h4LJMh2b007293@pubhealth.ku.dk>
Message-ID: <3ECCD7F1.8020203@bank-banque-canada.ca>

ross@biostat.ucsf.edu wrote:
> My docs say files ending in ~ are excluded by default from R CMD build.
> Doesn't look that way to me.  I got them with 1.6.2 and 1.7.0.
> My documenation is 1.6.0 (that is, the one saying *~ is excluded).
> 
> I have no .Rbuildignore of my own.

The exclude features have worked for me on Linux but never on Solaris. 
Somewhere the documentation says that a tar newer than 1.13 is needed. 
This is available with versions of Linux, but is a bit of a problem on 
other systems since the latest version on ftp://ftp.gnu.org/gnu/tar/ is 
1.13.

Paul Gilbert

From jotero at lsi.uniovi.es  Thu May 22 17:54:31 2003
From: jotero at lsi.uniovi.es (jotero@lsi.uniovi.es)
Date: Thu May 22 16:55:16 2003
Subject: [Rd] faraway package installation failed (PR#3076)
Message-ID: <200305221454.h4MEsV2b015692@pubhealth.ku.dk>

Full_Name: Jos Otero
Version: Version 1.5.0  (2002-04-29)
OS: Redhat 7.3
Submission from: (NULL) (192.187.16.164)


Hi:
Installation of package faraway 
as root, from tarbal:

R CMD INSTALL ./faraway.tar.gz 
ERROR: cannot extract package from './faraway.tar.gz'

idem, from zipped package:

R CMD INSTALL faraway.zip 
gzip: faraway.zip has more than one entry--rest ignored
ERROR: cannot extract package from 'faraway.zip'

It seems to WORK if the package is untared FIRST 
but not from the compressed file. It is of course a minor bug.
Many thanks. Follow explanation...

The files seem to be ok:

file faraway.*
faraway.tar.gz: gzip compressed data, deflated, original filename,
`faraway.tar', last modified: Mon May  5 21:35:19 2003, os: Unix
faraway.zip:    Zip archive data, at least v1.0 to extract
unzip -l faraway.zip
Archive:  faraway.zip
  Length     Date   Time    Name
 --------    ----   ----    ----
        0  05-05-03 15:32   faraway/
        0  05-05-03 15:32   faraway/chtml/
     8158  05-05-03 15:32   faraway/CONTENTS
        0  05-05-03 15:32   faraway/data/
     1864  05-05-03 15:32   faraway/data/00Index
     1777  05-05-03 15:32   faraway/data/babyfood.rda
     1373  05-05-03 15:32   faraway/data/beetle.rda
      589  05-05-03 15:32   faraway/data/bliss.rda
     2921  05-05-03 15:32   faraway/data/breaking.rda
     2729  05-05-03 15:32   faraway/data/cathedral.rda
     5909  05-05-03 15:32   faraway/data/chicago.rda
     2181  05-05-03 15:32   faraway/data/chiczip.rda
     5449  05-05-03 15:32   faraway/data/chmiss.rda
     2133  05-05-03 15:32   faraway/data/clot.rda
     2341  05-05-03 15:32   faraway/data/coagulation.rda
     1389  05-05-03 15:32   faraway/data/corrosion.rda
    24960  05-05-03 15:32   faraway/data/ctsib.rda
     2061  05-05-03 15:32   faraway/data/death.rda
     2065  05-05-03 15:32   faraway/data/drugpsy.rda
     2989  05-05-03 15:32   faraway/data/eco.rda
     4881  05-05-03 15:32   faraway/data/eggs.rda
    26901  05-05-03 15:32   faraway/data/epilepsy.rda
    18089  05-05-03 15:32   faraway/data/exa.rda
     1641  05-05-03 15:32   faraway/data/exb.rda
    16933  05-05-03 15:32   faraway/data/faithful.rda
     4177  05-05-03 15:32   faraway/data/gala.rda
     1095  05-05-03 15:32   faraway/data/hormone.rda
     3025  05-05-03 15:32   faraway/data/irrigation.rda
   223469  05-05-03 15:32   faraway/data/jsp.rda
    14296  05-05-03 15:32   faraway/data/kanga.rda
     7293  05-05-03 15:32   faraway/data/leafblotch.rda
     2121  05-05-03 15:32   faraway/data/melanoma.rda
     1901  05-05-03 15:32   faraway/data/odor.rda
    42169  05-05-03 15:32   faraway/data/ozone.rda
     2677  05-05-03 15:32   faraway/data/penicillin.rda
    42496  05-05-03 15:32   faraway/data/pima.rda
     2577  05-05-03 15:32   faraway/data/pneumo.rda
     3557  05-05-03 15:32   faraway/data/rabbit.rda
     4237  05-05-03 15:32   faraway/data/rats.rda
     5317  05-05-03 15:32   faraway/data/savings.rda
    71017  05-05-03 15:32   faraway/data/solder.rda
     7737  05-05-03 15:32   faraway/data/speedo.rda
     3885  05-05-03 15:32   faraway/data/star.rda
     2551  05-05-03 15:32   faraway/data/stat500.rda
     1537  05-05-03 15:32   faraway/data/strongx.rda
     4069  05-05-03 15:32   faraway/data/suicide.rda
     5629  05-05-03 15:32   faraway/data/truck.rda
     2777  05-05-03 15:32   faraway/data/twins.rda
     4337  05-05-03 15:32   faraway/data/uncviet.rda
     5445  05-05-03 15:32   faraway/data/vision.rda
     1729  05-05-03 15:32   faraway/data/wheat.rda
      420  05-05-03 15:32   faraway/DESCRIPTION
        0  05-05-03 15:32   faraway/help/
      836  05-05-03 15:32   faraway/help/AnIndex
      601  05-05-03 15:32   faraway/help/babyfood
      519  05-05-03 15:32   faraway/help/beetle
      504  05-05-03 15:32   faraway/help/bliss
      599  05-05-03 15:32   faraway/help/breaking
      569  05-05-03 15:32   faraway/help/cathedral
      521  05-05-03 15:32   faraway/help/chicago
      523  05-05-03 15:32   faraway/help/chiczip
      545  05-05-03 15:32   faraway/help/chmiss
      498  05-05-03 15:32   faraway/help/clot
      533  05-05-03 15:32   faraway/help/coagulation
      526  05-05-03 15:32   faraway/help/corrosion
      526  05-05-03 15:32   faraway/help/Cpplot
      550  05-05-03 15:32   faraway/help/ctsib
      563  05-05-03 15:32   faraway/help/death
      550  05-05-03 15:32   faraway/help/drugpsy
      523  05-05-03 15:32   faraway/help/eco
      559  05-05-03 15:32   faraway/help/eggs
      565  05-05-03 15:32   faraway/help/epilepsy
      541  05-05-03 15:32   faraway/help/exa
      541  05-05-03 15:32   faraway/help/exb
      581  05-05-03 15:32   faraway/help/faithful
      530  05-05-03 15:32   faraway/help/foo
      558  05-05-03 15:32   faraway/help/gala
      757  05-05-03 15:32   faraway/help/halfnorm
      531  05-05-03 15:32   faraway/help/hormone
      634  05-05-03 15:32   faraway/help/ilogit
      559  05-05-03 15:32   faraway/help/irrigation
      502  05-05-03 15:32   faraway/help/jsp
      494  05-05-03 15:32   faraway/help/kanga
      505  05-05-03 15:32   faraway/help/leafblotch
      657  05-05-03 15:32   faraway/help/logit
      754  05-05-03 15:32   faraway/help/maxadjr
      584  05-05-03 15:32   faraway/help/melanoma
      549  05-05-03 15:32   faraway/help/odor
      496  05-05-03 15:32   faraway/help/ozone
      558  05-05-03 15:32   faraway/help/penicillin
      527  05-05-03 15:32   faraway/help/pima
      546  05-05-03 15:32   faraway/help/pneumo
      640  05-05-03 15:32   faraway/help/prplot
      730  05-05-03 15:32   faraway/help/qqnorml
      543  05-05-03 15:32   faraway/help/rabbit
      556  05-05-03 15:32   faraway/help/rats
      523  05-05-03 15:32   faraway/help/savings
      557  05-05-03 15:32   faraway/help/solder
      521  05-05-03 15:32   faraway/help/speedo
      551  05-05-03 15:32   faraway/help/star
      542  05-05-03 15:32   faraway/help/stat500
      540  05-05-03 15:32   faraway/help/strongx
      485  05-05-03 15:32   faraway/help/suicide
      502  05-05-03 15:32   faraway/help/truck
      490  05-05-03 15:32   faraway/help/twins
      555  05-05-03 15:32   faraway/help/uncviet
      682  05-05-03 15:32   faraway/help/vif
      497  05-05-03 15:32   faraway/help/vision
      530  05-05-03 15:32   faraway/help/wheat
        0  05-05-03 15:32   faraway/html/
     6521  05-05-03 15:32   faraway/html/00Index.html
      848  05-05-03 15:32   faraway/html/babyfood.html
      782  05-05-03 15:32   faraway/html/beetle.html
      769  05-05-03 15:32   faraway/html/bliss.html
      848  05-05-03 15:32   faraway/html/breaking.html
      827  05-05-03 15:32   faraway/html/cathedral.html
      785  05-05-03 15:32   faraway/html/chicago.html
      789  05-05-03 15:32   faraway/html/chiczip.html
      802  05-05-03 15:32   faraway/html/chmiss.html
      762  05-05-03 15:32   faraway/html/clot.html
      805  05-05-03 15:32   faraway/html/coagulation.html
      797  05-05-03 15:32   faraway/html/corrosion.html
      900  05-05-03 15:32   faraway/html/Cpplot.html
      805  05-05-03 15:32   faraway/html/ctsib.html
      815  05-05-03 15:32   faraway/html/death.html
      807  05-05-03 15:32   faraway/html/drugpsy.html
      777  05-05-03 15:32   faraway/html/eco.html
      808  05-05-03 15:32   faraway/html/eggs.html
      820  05-05-03 15:32   faraway/html/epilepsy.html
      793  05-05-03 15:32   faraway/html/exa.html
      793  05-05-03 15:32   faraway/html/exb.html
      832  05-05-03 15:32   faraway/html/faithful.html
      786  05-05-03 15:32   faraway/html/foo.html
      806  05-05-03 15:32   faraway/html/gala.html
     1308  05-05-03 15:32   faraway/html/halfnorm.html
      793  05-05-03 15:32   faraway/html/hormone.html
      973  05-05-03 15:32   faraway/html/ilogit.html
      818  05-05-03 15:32   faraway/html/irrigation.html
      763  05-05-03 15:32   faraway/html/jsp.html
      761  05-05-03 15:32   faraway/html/kanga.html
      782  05-05-03 15:32   faraway/html/leafblotch.html
     1006  05-05-03 15:32   faraway/html/logit.html
     1154  05-05-03 15:32   faraway/html/maxadjr.html
      834  05-05-03 15:32   faraway/html/melanoma.html
      800  05-05-03 15:32   faraway/html/odor.html
      765  05-05-03 15:32   faraway/html/ozone.html
      820  05-05-03 15:32   faraway/html/penicillin.html
      784  05-05-03 15:32   faraway/html/pima.html
      800  05-05-03 15:32   faraway/html/pneumo.html
     1029  05-05-03 15:32   faraway/html/prplot.html
     1279  05-05-03 15:32   faraway/html/qqnorml.html
      802  05-05-03 15:32   faraway/html/rabbit.html
      806  05-05-03 15:32   faraway/html/rats.html
      789  05-05-03 15:32   faraway/html/savings.html
      810  05-05-03 15:32   faraway/html/solder.html
      782  05-05-03 15:32   faraway/html/speedo.html
      800  05-05-03 15:32   faraway/html/star.html
      803  05-05-03 15:32   faraway/html/stat500.html
      799  05-05-03 15:32   faraway/html/strongx.html
      761  05-05-03 15:32   faraway/html/suicide.html
      769  05-05-03 15:32   faraway/html/truck.html
      761  05-05-03 15:32   faraway/html/twins.html
      813  05-05-03 15:32   faraway/html/uncviet.html
     1013  05-05-03 15:32   faraway/html/vif.html
      766  05-05-03 15:32   faraway/html/vision.html
      789  05-05-03 15:32   faraway/html/wheat.html
      177  05-05-03 15:32   faraway/INDEX
        0  05-05-03 15:32   faraway/latex/
      515  05-05-03 15:32   faraway/latex/babyfood.tex
      479  05-05-03 15:32   faraway/latex/beetle.tex
      471  05-05-03 15:32   faraway/latex/bliss.tex
      515  05-05-03 15:32   faraway/latex/breaking.tex
      506  05-05-03 15:32   faraway/latex/cathedral.tex
      482  05-05-03 15:32   faraway/latex/chicago.tex
      484  05-05-03 15:32   faraway/latex/chiczip.tex
      489  05-05-03 15:32   faraway/latex/chmiss.tex
      466  05-05-03 15:32   faraway/latex/clot.tex
      498  05-05-03 15:32   faraway/latex/coagulation.tex
      491  05-05-03 15:32   faraway/latex/corrosion.tex
      631  05-05-03 15:32   faraway/latex/Cpplot.tex
      489  05-05-03 15:32   faraway/latex/ctsib.tex
      494  05-05-03 15:32   faraway/latex/death.tex
      493  05-05-03 15:32   faraway/latex/drugpsy.tex
      472  05-05-03 15:32   faraway/latex/eco.tex
      489  05-05-03 15:32   faraway/latex/eggs.tex
      501  05-05-03 15:32   faraway/latex/epilepsy.tex
      480  05-05-03 15:32   faraway/latex/exa.tex
      480  05-05-03 15:32   faraway/latex/exb.tex
      507  05-05-03 15:32   faraway/latex/faithful.tex
      478  05-05-03 15:32   faraway/latex/foo.tex
      488  05-05-03 15:32   faraway/latex/gala.tex
      852  05-05-03 15:32   faraway/latex/halfnorm.tex
      486  05-05-03 15:32   faraway/latex/hormone.tex
      689  05-05-03 15:32   faraway/latex/ilogit.tex
      503  05-05-03 15:32   faraway/latex/irrigation.tex
      465  05-05-03 15:32   faraway/latex/jsp.tex
      467  05-05-03 15:32   faraway/latex/kanga.tex
      485  05-05-03 15:32   faraway/latex/leafblotch.tex
      713  05-05-03 15:32   faraway/latex/logit.tex
      824  05-05-03 15:32   faraway/latex/maxadjr.tex
      508  05-05-03 15:32   faraway/latex/melanoma.tex
      485  05-05-03 15:32   faraway/latex/odor.tex
      469  05-05-03 15:32   faraway/latex/ozone.tex
      504  05-05-03 15:32   faraway/latex/penicillin.tex
      477  05-05-03 15:32   faraway/latex/pima.tex
      488  05-05-03 15:32   faraway/latex/pneumo.tex
      723  05-05-03 15:32   faraway/latex/prplot.tex
      825  05-05-03 15:32   faraway/latex/qqnorml.tex
      489  05-05-03 15:32   faraway/latex/rabbit.tex
      488  05-05-03 15:32   faraway/latex/rats.tex
      484  05-05-03 15:32   faraway/latex/savings.tex
      493  05-05-03 15:32   faraway/latex/solder.tex
      479  05-05-03 15:32   faraway/latex/speedo.tex
      485  05-05-03 15:32   faraway/latex/star.tex
      491  05-05-03 15:32   faraway/latex/stat500.tex
      489  05-05-03 15:32   faraway/latex/strongx.tex
      470  05-05-03 15:32   faraway/latex/suicide.tex
      471  05-05-03 15:32   faraway/latex/truck.tex
      467  05-05-03 15:32   faraway/latex/twins.tex
      496  05-05-03 15:32   faraway/latex/uncviet.tex
      743  05-05-03 15:32   faraway/latex/vif.tex
      471  05-05-03 15:32   faraway/latex/vision.tex
      481  05-05-03 15:32   faraway/latex/wheat.tex
        0  05-05-03 15:32   faraway/man/
    19486  05-05-03 15:32   faraway/man/faraway.Rd
        0  05-05-03 15:32   faraway/Meta/
     2645  05-05-03 15:32   faraway/Meta/data.rds
     7836  05-05-03 15:32   faraway/Meta/Rd.rds
        0  05-05-03 15:32   faraway/R/
     3200  05-05-03 15:32   faraway/R/faraway
        0  05-05-03 15:32   faraway/R-ex/
      112  05-05-03 15:32   faraway/R-ex/Cpplot.R
      122  05-05-03 15:32   faraway/R-ex/halfnorm.R
      177  05-05-03 15:32   faraway/R-ex/ilogit.R
      189  05-05-03 15:32   faraway/R-ex/logit.R
      133  05-05-03 15:32   faraway/R-ex/maxadjr.R
      191  05-05-03 15:32   faraway/R-ex/prplot.R
      118  05-05-03 15:32   faraway/R-ex/qqnorml.R
      188  05-05-03 15:32   faraway/R-ex/vif.R
 --------                   -------
   758372                   239 files


tar tvfz faraway.tar.gz

drwxr-xr-x faraway/users     0 2003-05-05 20:19:51 faraway/
-rw-r--r-- faraway/users     0 1999-12-13 00:00:34 faraway/CONTENTS
-rw-r--r-- faraway/users   177 1999-12-13 00:03:58 faraway/INDEX
-rw-r--r-- faraway/users    48 1999-11-28 20:21:56 faraway/TITLE
drwxr-xr-x faraway/users     0 2003-05-05 20:30:03 faraway/R/
-rw-r--r-- faraway/users  3199 2002-11-11 22:24:22 faraway/R/faraway.R~
-rw-r--r-- faraway/users  3200 2003-05-05 20:30:07 faraway/R/faraway.R
drwxr-xr-x faraway/users     0 2003-01-02 22:11:12 faraway/data/
-rw-r--r-- faraway/users  5909 1999-11-28 20:21:58 faraway/data/chicago.rda
-rw-r--r-- faraway/users  2921 1999-11-28 20:21:58 faraway/data/breaking.rda
-rw-r--r-- faraway/users  1864 2002-06-19 20:05:44 faraway/data/00Index
-rw-r--r-- faraway/users  2729 1999-11-28 20:22:00 faraway/data/cathedral.rda
-rw-r--r-- faraway/users  2341 1999-11-28 20:22:00 faraway/data/coagulation.rda
-rw-r--r-- faraway/users  4177 1999-11-28 20:22:02 faraway/data/gala.rda
-rw-r--r-- faraway/users  1901 1999-11-28 20:22:02 faraway/data/odor.rda
-rw-r--r-- faraway/users  2677 1999-11-28 20:22:02 faraway/data/penicillin.rda
-rw-r--r-- faraway/users  3557 1999-11-28 20:22:04 faraway/data/rabbit.rda
-rw-r--r-- faraway/users  4237 1999-11-28 20:22:04 faraway/data/rats.rda
-rw-r--r-- faraway/users  5317 1999-11-28 20:22:04 faraway/data/savings.rda
-rw-r--r-- faraway/users  7737 1999-11-28 20:22:06 faraway/data/speedo.rda
-rw-r--r-- faraway/users  3885 1999-11-28 20:22:06 faraway/data/star.rda
-rw-r--r-- faraway/users  1537 1999-11-28 20:22:08 faraway/data/strongx.rda
-rw-r--r-- faraway/users  2777 1999-11-28 20:22:08 faraway/data/twins.rda
-rw-r--r-- faraway/users  1389 1999-12-07 02:21:44 faraway/data/corrosion.rda
-rw-r--r-- faraway/users  5449 1999-12-08 02:25:16 faraway/data/chmiss.rda
-rw-r--r-- faraway/users  2181 1999-12-08 02:30:22 faraway/data/chiczip.rda
-rw-r--r-- faraway/users  1777 1999-12-23 20:48:52 faraway/data/babyfood.rda
-rw-r--r-- faraway/users  1373 1999-12-23 21:19:42 faraway/data/beetle.rda
-rw-r--r-- faraway/users  2133 1999-12-26 18:27:32 faraway/data/clot.rda
-rw-r--r-- faraway/users 26901 1999-12-26 20:55:38 faraway/data/epilepsy.rda
-rw-r--r-- faraway/users 18089 1999-12-27 17:08:38 faraway/data/exa.rda
-rw-r--r-- faraway/users  1641 1999-12-27 17:14:46 faraway/data/exb.rda
-rw-r--r-- faraway/users 16933 1999-12-27 17:15:56 faraway/data/faithful.rda
-rw-r--r-- faraway/users  7293 1999-12-26 19:57:42 faraway/data/leafblotch.rda
-rw-r--r-- faraway/users  2577 1999-12-24 21:56:24 faraway/data/pneumo.rda
-rw-r--r-- faraway/users 71017 1999-12-27 16:37:48 faraway/data/solder.rda
-rw-r--r-- faraway/users  5629 1999-12-26 22:17:56 faraway/data/truck.rda
-rw-r--r-- faraway/users 42169 1999-12-28 18:02:40 faraway/data/ozone.rda
-rw-r--r-- faraway/users  4881 1999-12-31 04:55:24 faraway/data/eggs.rda
-rw-r--r-- faraway/users  3025 1999-12-31 04:55:10 faraway/data/irrigation.rda
-rw-r--r-- faraway/users  5445 1999-12-31 17:17:56 faraway/data/vision.rda
-rw-r--r-- faraway/users  1729 1999-12-30 19:48:32 faraway/data/wheat.rda
-rw-r--r-- faraway/users  2065 2000-01-02 18:29:58 faraway/data/drugpsy.rda
-rw-r--r-- faraway/users  2121 2000-01-02 05:41:06 faraway/data/melanoma.rda
-rw-r--r-- faraway/users  2061 2000-01-02 21:42:26 faraway/data/death.rda
-rw-r--r-- faraway/users  4069 2000-01-02 22:18:44 faraway/data/suicide.rda
-rw-r--r-- faraway/users  4337 2000-01-02 18:03:54 faraway/data/uncviet.rda
-rw-r--r-- faraway/users   589 2000-08-14 18:02:52 faraway/data/bliss.rda
-rw-r--r-- faraway/users  2989 2001-01-01 20:49:34 faraway/data/eco.rda
-rw-r--r-- faraway/users 223469 2001-01-01 20:49:50 faraway/data/jsp.rda
-rw-r--r-- faraway/users   2551 2002-06-19 20:02:24 faraway/data/stat500.rda
-rw-r--r-- faraway/users  42496 2002-06-19 20:03:56 faraway/data/pima.rda
-rw-r--r-- faraway/users  24960 2002-02-22 17:52:22 faraway/data/ctsib.rda
-rw-r--r-- faraway/users   1095 2003-01-02 20:46:31 faraway/data/hormone.rda
-rw-r--r-- faraway/users  14296 2003-01-02 21:20:18 faraway/data/kanga.rda
drwxr-xr-x faraway/users      0 2003-05-05 20:31:06 faraway/man/
-rw-r--r-- faraway/users    538 2002-06-19 20:56:30 faraway/man/halfnorm.Rd
-rw-r--r-- faraway/users    362 2002-06-19 20:27:54 faraway/man/ilogit.Rd
-rw-r--r-- faraway/users    383 2001-07-31 22:58:16 faraway/man/logit.Rd
-rw-r--r-- faraway/users    497 2001-07-31 22:59:34 faraway/man/maxadjr.Rd
-rw-r--r-- faraway/users    306 2002-06-19 20:54:36 faraway/man/Cpplot.Rd
-rw-r--r-- faraway/users    328 2002-06-19 21:11:40 faraway/man/foo.Rd
-rw-r--r-- faraway/users    388 2002-06-19 20:54:56 faraway/man/prplot.Rd
-rw-r--r-- faraway/users    501 2002-06-19 20:53:52 faraway/man/qqnorml.Rd
-rw-r--r-- faraway/users    375 2002-06-19 20:53:18 faraway/man/vif.default.Rd~
-rw-r--r-- faraway/users    365 2002-06-19 21:22:16 faraway/man/babyfood.Rd
-rw-r--r-- faraway/users    329 2002-06-19 21:22:16 faraway/man/beetle.Rd
-rw-r--r-- faraway/users    321 2002-06-19 21:22:16 faraway/man/bliss.Rd
-rw-r--r-- faraway/users    365 2002-06-19 21:22:16 faraway/man/breaking.Rd
-rw-r--r-- faraway/users    356 2002-06-19 21:22:16 faraway/man/cathedral.Rd
-rw-r--r-- faraway/users    332 2002-06-19 21:22:16 faraway/man/chicago.Rd
-rw-r--r-- faraway/users    334 2002-06-19 21:22:16 faraway/man/chiczip.Rd
-rw-r--r-- faraway/users    339 2002-06-19 21:22:16 faraway/man/chmiss.Rd
-rw-r--r-- faraway/users    316 2002-06-19 21:22:16 faraway/man/clot.Rd
-rw-r--r-- faraway/users    348 2002-06-19 21:22:16 faraway/man/coagulation.Rd
-rw-r--r-- faraway/users    341 2002-06-19 21:22:16 faraway/man/corrosion.Rd
-rw-r--r-- faraway/users    344 2002-06-19 21:22:16 faraway/man/death.Rd
-rw-r--r-- faraway/users    343 2002-06-19 21:22:16 faraway/man/drugpsy.Rd
-rw-r--r-- faraway/users    322 2002-06-19 21:22:16 faraway/man/eco.Rd
-rw-r--r-- faraway/users    339 2002-06-19 21:22:16 faraway/man/eggs.Rd
-rw-r--r-- faraway/users    351 2002-06-19 21:22:16 faraway/man/epilepsy.Rd
-rw-r--r-- faraway/users    330 2002-06-19 21:22:16 faraway/man/exa.Rd
-rw-r--r-- faraway/users    330 2002-06-19 21:22:16 faraway/man/exb.Rd
-rw-r--r-- faraway/users    357 2002-06-19 21:22:16 faraway/man/faithful.Rd
-rw-r--r-- faraway/users    338 2002-06-19 21:22:16 faraway/man/gala.Rd
-rw-r--r-- faraway/users    354 2002-06-19 21:22:16 faraway/man/irrigation.Rd
-rw-r--r-- faraway/users    315 2002-06-19 21:22:16 faraway/man/jsp.Rd
-rw-r--r-- faraway/users    335 2002-06-19 21:22:16 faraway/man/leafblotch.Rd
-rw-r--r-- faraway/users    358 2002-06-19 21:22:16 faraway/man/melanoma.Rd
-rw-r--r-- faraway/users    335 2002-06-19 21:22:16 faraway/man/odor.Rd
-rw-r--r-- faraway/users    319 2002-06-19 21:22:16 faraway/man/ozone.Rd
-rw-r--r-- faraway/users    354 2002-06-19 21:22:16 faraway/man/penicillin.Rd
-rw-r--r-- faraway/users    327 2002-06-19 21:22:16 faraway/man/pima.Rd
-rw-r--r-- faraway/users    338 2002-06-19 21:22:16 faraway/man/pneumo.Rd
-rw-r--r-- faraway/users    339 2002-06-19 21:22:16 faraway/man/rabbit.Rd
-rw-r--r-- faraway/users    338 2002-06-19 21:22:16 faraway/man/rats.Rd
-rw-r--r-- faraway/users    334 2002-06-19 21:22:16 faraway/man/savings.Rd
-rw-r--r-- faraway/users    343 2002-06-19 21:22:16 faraway/man/solder.Rd
-rw-r--r-- faraway/users    329 2002-06-19 21:22:16 faraway/man/speedo.Rd
-rw-r--r-- faraway/users    335 2002-06-19 21:22:16 faraway/man/star.Rd
-rw-r--r-- faraway/users    341 2002-06-19 21:22:16 faraway/man/stat500.Rd
-rw-r--r-- faraway/users    339 2002-06-19 21:22:16 faraway/man/strongx.Rd
-rw-r--r-- faraway/users    320 2002-06-19 21:22:16 faraway/man/suicide.Rd
-rw-r--r-- faraway/users    321 2002-06-19 21:22:16 faraway/man/truck.Rd
-rw-r--r-- faraway/users    317 2002-06-19 21:22:16 faraway/man/twins.Rd
-rw-r--r-- faraway/users    346 2002-06-19 21:22:16 faraway/man/uncviet.Rd
-rw-r--r-- faraway/users    321 2002-06-19 21:22:16 faraway/man/vision.Rd
-rw-r--r-- faraway/users    331 2002-06-19 21:22:16 faraway/man/wheat.Rd
-rw-r--r-- faraway/users    427 2003-05-05 20:30:51 faraway/man/vif.Rd
-rw-r--r-- faraway/users    315 2003-01-02 21:55:48 faraway/man/kanga.Rd~
-rw-r--r-- faraway/users    315 2003-01-02 21:55:55 faraway/man/hormone.Rd~
-rw-r--r-- faraway/users    317 2003-05-05 20:29:04 faraway/man/kanga.Rd
-rw-r--r-- faraway/users    339 2003-05-05 20:28:15 faraway/man/ctsib.Rd
-rw-r--r-- faraway/users    336 2003-05-05 20:29:34 faraway/man/hormone.Rd
-rw-r--r-- faraway/users    373 2003-05-05 20:15:26 faraway/DESCRIPTION

regards,

Jos Otero

From ligges at statistik.uni-dortmund.de  Thu May 22 18:30:52 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Thu May 22 17:31:35 2003
Subject: [Rd] faraway package installation failed (PR#3076)
Message-ID: <200305221530.h4MFUq2b015976@pubhealth.ku.dk>

jotero@lsi.uniovi.es wrote:
> Full_Name: Jos? Otero
> Version: Version 1.5.0  (2002-04-29)
> OS: Redhat 7.3
> Submission from: (NULL) (192.187.16.164)
> 
> 
> Hi:
> Installation of package faraway 
> as root, from tarbal:
> 
> R CMD INSTALL ./faraway.tar.gz 
> ERROR: cannot extract package from './faraway.tar.gz'
> 
> idem, from zipped package:
> 
> R CMD INSTALL faraway.zip 
> gzip: faraway.zip has more than one entry--rest ignored
> ERROR: cannot extract package from 'faraway.zip'
> 
> It seems to WORK if the package is untared FIRST 
> but not from the compressed file. It is of course a minor bug.
> Many thanks. Follow explanation...
> 
> The files seem to be ok:
> 
> file faraway.*
> faraway.tar.gz: gzip compressed data, deflated, original filename,
> `faraway.tar', last modified: Mon May  5 21:35:19 2003, os: Unix
> faraway.zip:    Zip archive data, at least v1.0 to extract
> unzip -l faraway.zip
> Archive:  faraway.zip

[snipped huge amount of garbage]

This is not a bug in R!!! Why do you think so?


1) faraway.tar.gz is not from CRAN, so please refer to it appropriately.

2) It looks like the package is inappropriately packaged, so it's 
presumably a bug in that package, not in R.

3) R-1.5.0 is completely outdated (we are two major versions later these 
days). Please check a recent version before sending bug reports.


Uwe Ligges

From jmc at research.bell-labs.com  Thu May 22 12:37:18 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Thu May 22 17:39:27 2003
Subject: [Rd] Re: as(df, "list") does not propagate names
References: <6r1xyrenp5.fsf@r-project.org>
Message-ID: <3ECCEEAE.5AEEBF94@research.bell-labs.com>

(I enlarged this mail from r-core to r-devel since it's an interesting
question for general discussion.)

Douglas Bates wrote:
> 
> In a recent r-patched I notice that when df is a data.frame
> as(df, "list") does not propagate the names whereas as.list(df) does.
> Is this intentional?

Well, it's explicit anyway.  The as() function uses method dispatch for
coerce() to find methods.

R> selectMethod("coerce", c("data.frame", "list"))
function (from, to, strict = TRUE) 
{
    value <- as.list(from)
    if (strict) 
        attributes(value) <- NULL
    value
}

(This is actually the method for c("ANY","list").)

The strict=FALSE option is analogous to what would happen in method
dispatch if "list" were a superclass of "data.frame" (which it isn't
since "data.frame" is an S3 class.)

Two points about as.list:

1- Generally, it leaves all attributes alone.

2- There is an S3 method, as.list.data.frame, that deletes the "class"
and "row.names" attributes, but leaves the names.

So putting these all together:  Given 1, I think the general behavior
needs to stay the same (in fact, one might argue that even with
strict=FALSE, the class attribute should be reset).

But it seems reasonable to promote the as.list.data.frame method to an
S4 method for coerce().  

This prompts a general question:  do we want to promote certain S3
methods?  (It happens that as.list.data.frame is the only non-default
method for as.list, but there are 31 apparent non-default as.* methods. 
Promoting them would encourage use of as() for consistent programming.)

John

PS: The comparative behavior of as() and as.list() is illustrated below:

R> attributes(as.list(women))
$names
[1] "height" "weight"

R> attributes(as(women, "list"))
NULL
R> attributes(as(women, "list", strict=F))
$names
[1] "height" "weight"

R> x <- list(a=1,b=2)
R> class(x) <- "something"
R> attr(x, "foo") <- pi
R> as.list(x)
$a
[1] 1

$b
[1] 2

attr(,"class")
[1] "something"
attr(,"foo")
[1] 3.141593
R> as(x, "list")
[[1]]
[1] 1

[[2]]
[1] 2

and as(x, "list", FALSE) is the same result as as.list(x).




> 
> > data(women)
> > class(women)
> [1] "data.frame"
> > as.list(women)
> $height
>  [1] 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
> 
> $weight
>  [1] 115 117 120 123 126 129 132 135 139 142 146 150 154 159 164
> 
> > as(women, "list")
> [[1]]
>  [1] 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
> 
> [[2]]
>  [1] 115 117 120 123 126 129 132 135 139 142 146 150 154 159 164
> 
> _______________________________________________


-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From gregory_r_warnes at groton.pfizer.com  Thu May 22 14:27:07 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu May 22 19:27:56 2003
Subject: [Rd] Re: as(df, "list") does not propagate names
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C9CB@groexmb02.pfizer.com>



> -----Original Message-----
> From: John Chambers [mailto:jmc@research.bell-labs.com]
> Sent: Thursday, May 22, 2003 11:37 AM

> This prompts a general question:  do we want to promote certain S3
> methods?  (It happens that as.list.data.frame is the only non-default
> method for as.list, but there are 31 apparent non-default 
> as.* methods. 
> Promoting them would encourage use of as() for consistent 
> programming.)

Yes, please.

-Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From ligges at statistik.uni-dortmund.de  Thu May 22 21:05:24 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu May 22 20:04:09 2003
Subject: [Rd] Bug Tracking page: missing info what a bug is
Message-ID: <3ECD1164.76C45DF8@statistik.uni-dortmund.de>

I think it would be a great idea to add some information to
 http://r-bugs.biostat.ku.dk/cgi-bin/R
what a bug is and how to report it. In particular something like (or a
link to) Section 9 of the R FAQ, or the stuff from ?bug.report. I wasn't
aware that this information is missing on that page (Thanks to Jose
Otero for pointing it out). 

In addition, one may consider to add a help topic "Bug" that might point
to ?bug.report (e.g. just as an \alias{}).

Uwe Ligges

From gregory_r_warnes at groton.pfizer.com  Thu May 22 15:07:10 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu May 22 20:08:25 2003
Subject: [Rd] How to avoid function masking
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C9CC@groexmb02.pfizer.com>


Hi All,

I've been working on updating the 'genetics' package.  As a consequence of
the upgrade, .First.lib() looks like:

	.First.lib <- function(libname, pkgname) 
	{
	    if (!require(combinat)) 
	        warning("Unable to load 'combinat' library.  Function
`diseq.ci' will fail.")
	    require(gregmisc)
	    genotype <- get("genotype",pos="package:genetics")
	}

the First.lib of the "gregmisc" package in turn does 
	require("MASS")
which defines a data set "genotype" which masks the "genotype" function in
my genetics library.

Is there any clean way to load libraries in .First.lib while preventing this
kind of masking?  Ideally, there would be something like

	require("gregmisc", top=FALSE)

which would load the library (and any libraries it loads) into the *third*
position rather than the second position of the search path (.GlobalEnv is
in the first slot)?   Actually, does it make sense in general to have
top=FALSE be  the default behavior when loading packages from .First.lib to
avoid masking of this type?

For the moment I'm doing :

	.First.lib <- function(libname, pkgname) 
	{
	    if (!require(combinat)) 
	        warning("Unable to load 'combinat' library.  Function
`diseq.ci' will fail.")
	    require(gregmisc)
	    assign("genotype", get("genotype",pos="package:genetics"),
pos=.GlobalEnv )
	}

but this is a hack and doesn't solve the general problem.

-Greg



LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From rpeng at stat.ucla.edu  Thu May 22 12:39:40 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Thu May 22 20:38:44 2003
Subject: [Rd] How to avoid function masking
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C9CC@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C202F2C9CC@groexmb02.pfizer.com>
Message-ID: <3ECD196C.4060008@stat.ucla.edu>

I believe recent R-devel has a `pos' argument to library() which lets 
you attach a package in a certain position.  Can't think of anything 
else though.

-roger

Warnes, Gregory R wrote:
> Hi All,
> 
> I've been working on updating the 'genetics' package.  As a consequence of
> the upgrade, .First.lib() looks like:
> 
> 	.First.lib <- function(libname, pkgname) 
> 	{
> 	    if (!require(combinat)) 
> 	        warning("Unable to load 'combinat' library.  Function
> `diseq.ci' will fail.")
> 	    require(gregmisc)
> 	    genotype <- get("genotype",pos="package:genetics")
> 	}
> 
> the First.lib of the "gregmisc" package in turn does 
> 	require("MASS")
> which defines a data set "genotype" which masks the "genotype" function in
> my genetics library.
> 
> Is there any clean way to load libraries in .First.lib while preventing this
> kind of masking?  Ideally, there would be something like
> 
> 	require("gregmisc", top=FALSE)
> 
> which would load the library (and any libraries it loads) into the *third*
> position rather than the second position of the search path (.GlobalEnv is
> in the first slot)?   Actually, does it make sense in general to have
> top=FALSE be  the default behavior when loading packages from .First.lib to
> avoid masking of this type?
> 
> For the moment I'm doing :
> 
> 	.First.lib <- function(libname, pkgname) 
> 	{
> 	    if (!require(combinat)) 
> 	        warning("Unable to load 'combinat' library.  Function
> `diseq.ci' will fail.")
> 	    require(gregmisc)
> 	    assign("genotype", get("genotype",pos="package:genetics"),
> pos=.GlobalEnv )
> 	}
> 
> but this is a hack and doesn't solve the general problem.
> 
> -Greg
> 
> 
> 
> LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
>

From ross at biostat.ucsf.edu  Thu May 22 19:59:25 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu May 22 20:59:28 2003
Subject: [Rd] Possible R CMD check problem (PR#3070)
In-Reply-To: <16076.44026.665412.70300@galadriel.ci.tuwien.ac.at>
References: <200305211918.h4LJIA2b007276@pubhealth.ku.dk>
	<16076.44026.665412.70300@galadriel.ci.tuwien.ac.at>
Message-ID: <1053629847.1219.20.camel@epibiosun115-4>

On Thu, 2003-05-22 at 03:52, Friedrich.Leisch@ci.tuwien.ac.at wrote:
> Why do you think there is a bug in R rather than in your package? (I
> assume that it is a package of yours, at least it's not on CRAN).

Well, I did say "possible" problem.  The reason I think so is that part
of the error message (Could not create DVI version) is wrong (a dvi file
was produced) and part of it (This typically indicates Rd problems) is
misleading.  There is also some chance that the problems are deeper than
that.

> 
> How should we be able to track this problem for you? You don't specify
> your computing platform and give us no examples we could try to
> reproduce.

I'm happy to try to isolate it here.  I'm running on Solaris 2.8.  I can
send the files if that would help.

> 
> Does running latex on parcv-manual.tex in a shell work?
> 
Yes (once I found out how to tell it where Rd.sty was).  However, there
is an error in the tex log, also visible (now that I look!) in the
original run.  It seems to indicate some problem with my font setup:
-----------------------------------
(/usr/local/teTeX/share/texmf/tex/latex/base/t1enc.def)kpathsea: Running
mktextfm  ecrm1000
mkdir: Failed to make directory "/usr/local/teTeXfonts/tfm"; Permission
denied
kpsestat: /usr/local/teTeXfonts/tfm/..: No such file or directory
usage:  chmod [-fR] <absolute-mode> file ...
        chmod [-fR] <symbolic-mode-list> file ...
where   <symbolic-mode-list> is a comma-separated list of
        [ugoa]{+|-|=}[rwxXlstugo]
mkdir: Failed to make directory "/usr/local/teTeXfonts/tfm/jknappen"; No
such file or directory
kpsestat: /usr/local/teTeXfonts/tfm/jknappen/..: No such file or
directory
usage:  chmod [-fR] <absolute-mode> file ...
        chmod [-fR] <symbolic-mode-list> file ...
where   <symbolic-mode-list> is a comma-separated list of
        [ugoa]{+|-|=}[rwxXlstugo]
mkdir: Failed to make directory "/usr/local/teTeXfonts/tfm/jknappen/ec";
No such file or directory
kpsestat: /usr/local/teTeXfonts/tfm/jknappen/ec/..: No such file or
directory
usage:  chmod [-fR] <absolute-mode> file ...
        chmod [-fR] <symbolic-mode-list> file ...
where   <symbolic-mode-list> is a comma-separated list of
        [ugoa]{+|-|=}[rwxXlstugo]
mktextfm: mktexdir /usr/local/teTeXfonts/tfm/jknappen/ec failed.
kpathsea: Appending font creation commands to missfont.log.

! Font T1/cmr/m/n/10=ecrm1000 at 10.0pt not loadable: Metric (TFM) file
not fou
nd.
<to be read again> 
                   relax 
l.96 \fontencoding\encodingdefault\selectfont
                                             
? 
) (/usr/local/teTeX/share/texmf/tex/latex/ae/ae.sty
(/usr/local/teTeX/share/texmf/tex/latex/base/fontenc.sty
(/usr/local ....
--------------------------------------

So here's my theory:
latex runs into the problem above, which appears to be with our local
TeX setup, and returns an error code.
R thinks the code means TeX has failed to produce the dvi file.  And
then it emits the error message.

Does this seem a plausible diagnosis?

If that's correct, the undesirable behavior on R's part just relates to
the error handling and reporting.

> fritz leisch
> 
> 
> >>>>> On Wed, 21 May 2003 21:18:10 +0200 (MET DST),
> >>>>> ross  (r) wrote:
> 
>   > Using R 1.7.0 I get 
>   > * checking parcv-manual.tex ... ERROR
>   > Could not create DVI version.
> 
>   > Although there is no apparent error.  The dvi file exists.
>   > Possibly there is some problem with my TeX setup, but the following
>   > messages don't suggest that either.
> 
>   > Here's the full log, which does show some documentation issues:
>   > sheep:~$R CMD check --library=.R/library/ src/parcv
>   > * checking for working latex ... OK
>   > * using log directory '/space/home/ross/parcv.Rcheck'
>   > * checking for file 'parcv/DESCRIPTION' ... OK
>   > * checking if this is a source package ... OK
> 
>   > * Installing *source* package 'parcv' ...
>   > ** R
>   > ** demo
>   > ** inst
>   > ** help
>   >>>> Building/Updating help pages for package 'parcv'
>   >      Formats: text html latex example
>   > * DONE (parcv)
> 
>   > * DONE (INSTALL)
> 
>   > * checking package directory ... OK
>   > * checking for sufficient/correct file permissions ... OK
>   > * checking DESCRIPTION meta-information ... OK
>   > * checking package dependencies ... OK
>   > * checking index information ... WARNING
>   > Demos with missing or empty index information:
>   > [1] "parDemo1"
>   > See the information on INDEX files and package subdirectories in
>   > * section
>   > 'Creating R packages' of the 'Writing R Extensions' manual.
>   > * checking package subdirectories ... OK
>   > * checking R files for syntax errors ... OK
>   > * checking R files for library.dynam ... OK
>   > * checking generic/method consistency ... OK
>   > * checking for assignment functions with final arg not named 'value'
>   > * ... OK
>   > * checking Rd files ... WARNING
>   > Rd files without 'alias':
>   >   man/parcv-internal.Rd
>   > These tags are required in an Rd file.
>   > See chapter 'Writing R documentation' in manual 'Writing R
>   > Extensions'.
>   > * checking for undocumented objects ... WARNING
>   > Undocumented code objects:
>   > [1] "crossval.fit"      "crossval.outerfit" "crossval.setup"
>   > [4] "gcv"
>   > * checking for code/documentation mismatches ... OK
>   > * checking for undocumented arguments in \usage ... OK
>   > * creating parcv-Ex.R ... OK
>   > * checking examples ... OK
>   > * creating parcv-manual.tex ... OK
>   > * checking parcv-manual.tex ... ERROR
>   > Could not create DVI version.
>   > This typically indicates Rd problems.
> 
>   > ______________________________________________
>   > R-devel@stat.math.ethz.ch mailing list
>   > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
-- 
Ross Boylan <ross@biostat.ucsf.edu>              wk: (415) 502-4031
University of California, San Francisco         fax: (415) 476-9856
Dept of Epidemiology and Biostatistics           hm: (415) 550-1062
530 Parnassus Avenue (Library) rm 115-4
San Francisco, CA 94143-0840

From ross at biostat.ucsf.edu  Thu May 22 20:05:45 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu May 22 21:05:47 2003
Subject: [Rd] ~ files not excluded from build (PR#3071)
In-Reply-To: <3ECCD7F1.8020203@bank-banque-canada.ca>
References: <200305211922.h4LJMh2b007293@pubhealth.ku.dk>
	<3ECCD7F1.8020203@bank-banque-canada.ca>
Message-ID: <1053630269.1219.23.camel@epibiosun115-4>

On Thu, 2003-05-22 at 07:00, Paul Gilbert wrote:
> ross@biostat.ucsf.edu wrote:
> > My docs say files ending in ~ are excluded by default from R CMD build.
> > Doesn't look that way to me.  I got them with 1.6.2 and 1.7.0.
> > My documenation is 1.6.0 (that is, the one saying *~ is excluded).
> > 
> > I have no .Rbuildignore of my own.
> 
> The exclude features have worked for me on Linux but never on Solaris. 
> Somewhere the documentation says that a tar newer than 1.13 is needed. 
> This is available with versions of Linux, but is a bit of a problem on 
> other systems since the latest version on ftp://ftp.gnu.org/gnu/tar/ is 
> 1.13.
> 
> Paul Gilbert

Yes, that's the problem.  This was on Solaris 2.8.
tar --version
tar (GNU tar) 1.13

I actually tried it on 2 different Solaris systems and Debian, but my
Debian system had none of the *~ files to begin with.
-- 
Ross Boylan <ross@biostat.ucsf.edu>              wk: (415) 502-4031
University of California, San Francisco         fax: (415) 476-9856
Dept of Epidemiology and Biostatistics           hm: (415) 550-1062
530 Parnassus Avenue (Library) rm 115-4
San Francisco, CA 94143-0840

From gregory_r_warnes at groton.pfizer.com  Thu May 22 23:32:13 2003
From: gregory_r_warnes at groton.pfizer.com (gregory_r_warnes@groton.pfizer.com)
Date: Thu May 22 22:33:10 2003
Subject: [Rd] grep, gsub, sub have problems with NA values (PR#3078)
Message-ID: <200305222032.h4MKWD2b017261@pubhealth.ku.dk>


In a string context, grep, gsub, sub are improperly treating NA (missing) as
the string "NA", and returning unexpected results

> grep("A", c(NA,"NA"))
[1] 1 2

# expected: 
# [1] 2

> gsub("A", "X", c(NA,"NA"))
[1] "NX" "NX"
# expected
# [1] NA "NX"

> sub("A", "X", c(NA,"NA"))
[1] "NX" "NX"
# expected
# [1] NA "NX"

These same functions also don't like 'bare' NA's, presumably because a bare
NA is technically a factor object.  

> grep("A", NA)
Error in grep(pattern, x, ignore.case, extended, value) : 
 invalid argument

This is, understandable to users who are aware of the actual class of NA,
but it would be helpful if bare NAs were treated the same as character NAs
(when handling of these is fixed, of course!).

-Greg
 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From xoaquin at computer.org  Fri May 23 00:09:34 2003
From: xoaquin at computer.org (xoaquin@computer.org)
Date: Thu May 22 23:10:17 2003
Subject: [Rd] Conflict with tseries package?? (PR#3079)
Message-ID: <200305222109.h4ML9Y2b017386@pubhealth.ku.dk>

Full_Name: Joaquin Diaz-Saiz
Version: 1.7.0
OS: Windows XP
Submission from: (NULL) (12.82.4.17)


After installing the package "tseries" R does not start. A window with an error
message appears, apparently from the operating system, with a question regarding
sending the error information to Microsoft(??) or not.

Deleting the tseries directory from the library directory, or changing the name
to something like atseries, solves the starting problem. Of course after that
the package  cannot be used.

I tried to find a report concerning this issue but did not find anything.

From gregory_r_warnes at groton.pfizer.com  Thu May 22 18:20:59 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu May 22 23:21:57 2003
Subject: [Rd] How to avoid function masking
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C9CE@groexmb02.pfizer.com>


I just checked, and r-devel does not have a "pos" argument to library() or
require(). 

-G

> -----Original Message-----
> From: Roger D. Peng [mailto:rpeng@stat.ucla.edu]
> Sent: Thursday, May 22, 2003 2:40 PM
> To: Warnes, Gregory R
> Cc: 'R-devel@stat.math.ethz.ch'
> Subject: Re: [Rd] How to avoid function masking
> 
> 
> I believe recent R-devel has a `pos' argument to library() which lets 
> you attach a package in a certain position.  Can't think of anything 
> else though.
> 
> -roger
> 
> Warnes, Gregory R wrote:
> > Hi All,
> > 
> > I've been working on updating the 'genetics' package.  As a 
> consequence of
> > the upgrade, .First.lib() looks like:
> > 
> > 	.First.lib <- function(libname, pkgname) 
> > 	{
> > 	    if (!require(combinat)) 
> > 	        warning("Unable to load 'combinat' library.  Function
> > `diseq.ci' will fail.")
> > 	    require(gregmisc)
> > 	    genotype <- get("genotype",pos="package:genetics")
> > 	}
> > 
> > the First.lib of the "gregmisc" package in turn does 
> > 	require("MASS")
> > which defines a data set "genotype" which masks the 
> "genotype" function in
> > my genetics library.
> > 
> > Is there any clean way to load libraries in .First.lib 
> while preventing this
> > kind of masking?  Ideally, there would be something like
> > 
> > 	require("gregmisc", top=FALSE)
> > 
> > which would load the library (and any libraries it loads) 
> into the *third*
> > position rather than the second position of the search path 
> (.GlobalEnv is
> > in the first slot)?   Actually, does it make sense in 
> general to have
> > top=FALSE be  the default behavior when loading packages 
> from .First.lib to
> > avoid masking of this type?
> > 
> > For the moment I'm doing :
> > 
> > 	.First.lib <- function(libname, pkgname) 
> > 	{
> > 	    if (!require(combinat)) 
> > 	        warning("Unable to load 'combinat' library.  Function
> > `diseq.ci' will fail.")
> > 	    require(gregmisc)
> > 	    assign("genotype", get("genotype",pos="package:genetics"),
> > pos=.GlobalEnv )
> > 	}
> > 
> > but this is a hack and doesn't solve the general problem.
> > 
> > -Greg
> > 
> > 
> > 
> > LEGAL NOTICE\ Unless expressly stated otherwise, this 
> message is... {{dropped}}
> > 
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> > 
> > 
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From ligges at statistik.uni-dortmund.de  Fri May 23 10:20:31 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri May 23 09:20:44 2003
Subject: [Rd] Conflict with tseries package?? (PR#3079)
In-Reply-To: <200305222109.h4ML9Y2b017386@pubhealth.ku.dk>
References: <200305222109.h4ML9Y2b017386@pubhealth.ku.dk>
Message-ID: <3ECDCBBF.9090501@statistik.uni-dortmund.de>

xoaquin@computer.org wrote:
> Full_Name: Joaquin Diaz-Saiz
> Version: 1.7.0
> OS: Windows XP
> Submission from: (NULL) (12.82.4.17)
> 
> 
> After installing the package "tseries" R does not start. A window with an error
> message appears, apparently from the operating system, with a question regarding
> sending the error information to Microsoft(??) or not.
> 
> Deleting the tseries directory from the library directory, or changing the name
> to something like atseries, solves the starting problem. Of course after that
> the package  cannot be used.
> 
> I tried to find a report concerning this issue but did not find anything.

It works for me.
Can you please tell us a) which version of tseries, b) the way you 
installed it?

Uwe Ligges

From Friedrich.Leisch at ci.tuwien.ac.at  Fri May 23 11:40:57 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri May 23 10:41:13 2003
Subject: [Rd] Possible R CMD check problem (PR#3070)
In-Reply-To: <1053629847.1219.20.camel@epibiosun115-4>
References: <200305211918.h4LJIA2b007276@pubhealth.ku.dk>
	<16076.44026.665412.70300@galadriel.ci.tuwien.ac.at>
	<1053629847.1219.20.camel@epibiosun115-4>
Message-ID: <16077.56985.126689.145546@galadriel.ci.tuwien.ac.at>

>>>>> On 22 May 2003 11:57:28 -0700,
>>>>> Ross Boylan (RB) wrote:

  > On Thu, 2003-05-22 at 03:52, Friedrich.Leisch@ci.tuwien.ac.at wrote:
  >> Why do you think there is a bug in R rather than in your package? (I
  >> assume that it is a package of yours, at least it's not on CRAN).

  > Well, I did say "possible" problem.

Yes, but you also filed it into the R bug tracking system ... and
reporting "bugs" that in fact are mostly installation problems on your side
doesn't make life easier for us. 


  > The reason I think so is that part
  > of the error message (Could not create DVI version) is wrong (a dvi file
  > was produced)

Thanks for the hint, I'll fix that message.


  > and part of it (This typically indicates Rd problems) is
  > misleading. There is also some chance that the problems are deeper than
  > that.

Well, the message says that *typically* Rd problems are the reason
(which probably is true in 95% of all case), not that they are the
only possible cause.

Regards

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch@ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

From maechler at stat.math.ethz.ch  Fri May 23 16:00:10 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri May 23 15:00:21 2003
Subject: [Rd] How to avoid function masking
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C9CE@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C202F2C9CE@groexmb02.pfizer.com>
Message-ID: <16078.7002.496844.694646@gargle.gargle.HOWL>

>>>>> "Greg" == Warnes, Gregory R <gregory_r_warnes@groton.pfizer.com>
>>>>>     on Thu, 22 May 2003 17:20:59 -0400 writes:

    Greg> I just checked, and r-devel does not have a "pos"
    Greg> argument to library() or require().

You checked wrongly. library() *does* for several days now.
(require doesn't -- on purpose?)

Martin

From p.dalgaard at biostat.ku.dk  Fri May 23 14:39:34 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri May 23 15:41:38 2003
Subject: [Rd] R-1.7.1 scheduled for June 16
Message-ID: <x2n0hd22uh.fsf@biostat.ku.dk>

The release of R-1.7.1 is scheduled for Monday, June 16. I plan to
start the automatic generation of daily beta releases on June 2. It
would be good if package maintainers could get any planned changes
done as soon as possible, and test their packages carefully against
the beta releases.

For recommended packages, we should avoid changes to the API once the
beta releases start rolling out.

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From tlumley at u.washington.edu  Fri May 23 07:40:56 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri May 23 15:41:55 2003
Subject: [Rd] How to avoid function masking
In-Reply-To: <16078.7002.496844.694646@gargle.gargle.HOWL>
Message-ID: <Pine.A41.4.44.0305230635540.25218-100000@homer32.u.washington.edu>

On Fri, 23 May 2003, Martin Maechler wrote:

> >>>>> "Greg" == Warnes, Gregory R <gregory_r_warnes@groton.pfizer.com>
> >>>>>     on Thu, 22 May 2003 17:20:59 -0400 writes:
>
>     Greg> I just checked, and r-devel does not have a "pos"
>     Greg> argument to library() or require().
>
> You checked wrongly. library() *does* for several days now.
> (require doesn't -- on purpose?)

On purpose, I think. Firstly, if you want that level of control you can
use library().  Secondly, what should require("MASS",pos=4) return if MASS
is at pos=2? -- it seems to me it should return FALSE.

	-thomas

From gzambre at ieee.org  Fri May 23 17:16:21 2003
From: gzambre at ieee.org (gzambre@ieee.org)
Date: Fri May 23 16:16:41 2003
Subject: [Rd] RGui Startup Error on Win2000 (PR#3084)
Message-ID: <200305231416.h4NEGL2b025535@pubhealth.ku.dk>

Full_Name: Girish Zambre
Version: 1.7.0
OS: Win2000
Submission from: (NULL) (66.7.170.2)


I just started looking at and trying R.  The problem could be external to R, but
I really don't know. It reads 

'The instruction at "0x004412f0" referenced memory a "0x0095e40c". the memory
could not be "read" '

I get this after installing modules "waveslim.zip" and "tseries.zip" and
restarting.

From abroman at jhsph.edu  Fri May 23 18:16:23 2003
From: abroman at jhsph.edu (abroman@jhsph.edu)
Date: Fri May 23 17:16:36 2003
Subject: [Rd] library(MASS) in .First() (PR#3085)
Message-ID: <200305231516.h4NFGN2b025959@pubhealth.ku.dk>

Full_Name: Aimee Teo Broman
Version: 1.7.0
OS: Windows XP vers5.1
Submission from: (NULL) (162.129.145.77)



My .First() function contains the command library(MASS) -- when I open R 1.7.0,
I get this error:

Error in get(x, envir, mode, inherits) : variable "biplot" was not found
Error in library(MASS) : package/namespace load failed

If I run library(MASS) outside of the .First() function, it does not produce an
error, and the functions from that library seem to work fine.  I was not getting
this error in 1.6.2.

The .First() function I'm using:

.First <- function(){
  library(foreign)
  library(modreg)
  library(MASS)
}

thanks,
Aimee

From ligges at statistik.uni-dortmund.de  Fri May 23 18:34:44 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri May 23 17:34:54 2003
Subject: [Rd] RGui Startup Error on Win2000 (PR#3084)
In-Reply-To: <200305231416.h4NEGL2b025535@pubhealth.ku.dk>
References: <200305231416.h4NEGL2b025535@pubhealth.ku.dk>
Message-ID: <3ECE3F94.2020400@statistik.uni-dortmund.de>

gzambre@ieee.org wrote:
> Full_Name: Girish Zambre
> Version: 1.7.0
> OS: Win2000
> Submission from: (NULL) (66.7.170.2)
> 
> 
> I just started looking at and trying R.  The problem could be external to R, but
> I really don't know. It reads 
> 
> 'The instruction at "0x004412f0" referenced memory a "0x0095e40c". the memory
> could not be "read" '
> 
> I get this after installing modules "waveslim.zip" and "tseries.zip" and
> restarting.

Dear all,

this is the 2nd bug report on this within one or two days (the other one 
has #3079).
Please check
  a) whether there is really a bug and
  b) whether it has been reported before.


And again two questions:
  a) which version of *package* tseries?
  b) what way did you install it?

For me
   install.packages("tseries")
works!

I guess you downloaded a tseries version that was compiled for R<1.7.0.
The most recent Windows binary on CRAN ( != most recent tseries version) 
for R-1.7.0 should be called tseries_0.9-11.zip on 
CRAN/bin/windows/contrib/1.7  --- note the 1.7!!!

Joaquin and Girish, does the correct binary solve your problem?

Uwe Ligges

From tlumley at u.washington.edu  Fri May 23 09:46:35 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri May 23 17:46:52 2003
Subject: [Rd] grep, gsub, sub have problems with NA values (PR#3078)
In-Reply-To: <200305222032.h4MKWD2b017261@pubhealth.ku.dk>
Message-ID: <Pine.A41.4.44.0305230841310.17962-100000@homer26.u.washington.edu>

On Thu, 22 May 2003 gregory_r_warnes@groton.pfizer.com wrote:

>
> In a string context, grep, gsub, sub are improperly treating NA (missing) as
> the string "NA", and returning unexpected results
>

as were chartr, abbreviate, substr, substring, strsplit. Fixed in r-devel,
for the case of NA in the `main' string. Haven't yet decided what to do
about
  grep(as.character(NA), x)
or
  substr(x,1,2)<-as.charcter(NA)



	-thomas

From xoaquin at worldnet.att.net  Fri May 23 11:58:20 2003
From: xoaquin at worldnet.att.net (Joaquin Diaz-Saiz)
Date: Fri May 23 17:58:50 2003
Subject: [Rd] RGui Startup Error on Win2000 (PR#3084)
In-Reply-To: <3ECE3F94.2020400@statistik.uni-dortmund.de>
References: <200305231416.h4NEGL2b025535@pubhealth.ku.dk>
	<3ECE3F94.2020400@statistik.uni-dortmund.de>
Message-ID: <3ECE451C.3030101@worldnet.att.net>

Uwe Ligges escribi?:

> gzambre@ieee.org wrote:
>
>> Full_Name: Girish Zambre
>> Version: 1.7.0
>> OS: Win2000
>> Submission from: (NULL) (66.7.170.2)
>>
>>
>> I just started looking at and trying R.  The problem could be 
>> external to R, but
>> I really don't know. It reads
>> 'The instruction at "0x004412f0" referenced memory a "0x0095e40c". 
>> the memory
>> could not be "read" '
>>
>> I get this after installing modules "waveslim.zip" and "tseries.zip" and
>> restarting.
>
>
> Dear all,
>
> this is the 2nd bug report on this within one or two days (the other 
> one has #3079).
> Please check
>  a) whether there is really a bug and
>  b) whether it has been reported before.
>
>
> And again two questions:
>  a) which version of *package* tseries?
>  b) what way did you install it?
>
> For me
>   install.packages("tseries")
> works!
>
> I guess you downloaded a tseries version that was compiled for R<1.7.0.
> The most recent Windows binary on CRAN ( != most recent tseries 
> version) for R-1.7.0 should be called tseries_0.9-11.zip on 
> CRAN/bin/windows/contrib/1.7  --- note the 1.7!!!
>
> Joaquin and Girish, does the correct binary solve your problem?
>
> Uwe Ligges
>
>
The version is 0.9-11 and was installed fron CRAN directly using the 
menu on R-gui, I assume that it was compiled for R 1.7.0. Also, the 
problem is not that I cannot load the package tseries, the problem is 
that R does not even start unless I use the option

R_DEFAULT_PACKAGES=ctest

at startup.

Also, I should mention that the problem arises only under Windows XP. It 
works just fine under Windows 95, Windows 98, as well as RedHat Linus 7.3.

Joaquin Diaz-Saiz

From jgentry at jimmy.harvard.edu  Fri May 23 13:02:07 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Fri May 23 18:02:15 2003
Subject: [Rd] Problem building R-devel
Message-ID: <Pine.SOL.4.20.0305231159520.23138-100000@santiam.dfci.harvard.edu>

Hello ...

I went to build R-devel today (Redhat Linux 7.2, kernel 2.4.9-31, gcc
2.96) and am getting this error:

gcc -I../../src/extra/zlib   -I. -I../../src/include -I../../src/include
-I/usr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp  -g -O2
-c pcre.c -o pcre.o
pcre.c: In function `do_pgrep':
pcre.c:71: parse error before `char'
pcre.c:72: `s' undeclared (first use in this function)
pcre.c:72: (Each undeclared identifier is reported only once
pcre.c:72: for each function it appears in.)
make[3]: *** [pcre.o] Error 1
make[3]: Leaving directory `/home/jgentry/R-1.8.0/src/main'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/home/jgentry/R-1.8.0/src/main'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/jgentry/R-1.8.0/src'
make: *** [R] Error 1

On my initial attempt I did a 'make clean' before configuring &
building.  On my second attempt I re-rsynced the entire r-devel
distribution to a new directory and am still getting this error.

Is this a problem w/ r-devel or a problem on my end?

Thanks
-J

From gzambre at 4dv.net  Fri May 23 11:10:31 2003
From: gzambre at 4dv.net (Girish Zambre)
Date: Fri May 23 18:10:57 2003
Subject: [Rd] RGui Startup Error on Win2000 (PR#3084)
References: <200305231416.h4NEGL2b025535@pubhealth.ku.dk>
	<3ECE3F94.2020400@statistik.uni-dortmund.de>
Message-ID: <001e01c32145$d5dc7200$0100a8c0@littleton>

Uwe,

I just did some experimentation.   The problem on my computer comes from
tseries.zip.  I  removed the directories "/library/tseries" and
"/library/waveslim" and R started up fine.  Then I restored
"/library/waveslim" ; again R started fine. I then removed
"/library/waveslim" and restored "/library/tseries"; and R DID NOT start up
fine.   I don't know what version of tseries it is.  It is just the current
tseries.zip off of the United States mirror http://cran.us.r-project.org/
dated  04-Mar-2003 12:57 .

I just downloaded tseries_0.9-11.tgz and from the changelog it suggests I
have version 0.9-10.  This might be the problem.

waveslim, though, works just great.  This beats Octave !



GB Zambre

----- Original Message ----- 
From: "Uwe Ligges" <ligges@statistik.uni-dortmund.de>
To: <gzambre@ieee.org>
Cc: <r-devel@stat.math.ethz.ch>; "Joaquin Diaz-Saiz"
<xoaquin@worldnet.att.net>
Sent: Friday, May 23, 2003 9:34 AM
Subject: Re: [Rd] RGui Startup Error on Win2000 (PR#3084)


> gzambre@ieee.org wrote:
> > Full_Name: Girish Zambre
> > Version: 1.7.0
> > OS: Win2000
> > Submission from: (NULL) (66.7.170.2)
> >
> >
> > I just started looking at and trying R.  The problem could be external
to R, but
> > I really don't know. It reads
> >
> > 'The instruction at "0x004412f0" referenced memory a "0x0095e40c". the
memory
> > could not be "read" '
> >
> > I get this after installing modules "waveslim.zip" and "tseries.zip" and
> > restarting.
>
> Dear all,
>
> this is the 2nd bug report on this within one or two days (the other one
> has #3079).
> Please check
>   a) whether there is really a bug and
>   b) whether it has been reported before.
>
>
> And again two questions:
>   a) which version of *package* tseries?
>   b) what way did you install it?
>
> For me
>    install.packages("tseries")
> works!
>
> I guess you downloaded a tseries version that was compiled for R<1.7.0.
> The most recent Windows binary on CRAN ( != most recent tseries version)
> for R-1.7.0 should be called tseries_0.9-11.zip on
> CRAN/bin/windows/contrib/1.7  --- note the 1.7!!!
>
> Joaquin and Girish, does the correct binary solve your problem?
>
> Uwe Ligges
>

From maechler at stat.math.ethz.ch  Fri May 23 19:26:57 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri May 23 18:27:47 2003
Subject: [Rd] Problem building R-devel
In-Reply-To: <Pine.SOL.4.20.0305231159520.23138-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0305231159520.23138-100000@santiam.dfci.harvard.edu>
Message-ID: <16078.19409.980882.202677@gargle.gargle.HOWL>

>>>>> "JeffG" == Jeff Gentry <jgentry@jimmy.harvard.edu>
>>>>>     on Fri, 23 May 2003 12:02:07 -0400 (EDT) writes:

    JeffG> Hello ...  I went to build R-devel today (Redhat
    JeffG> Linux 7.2, kernel 2.4.9-31, gcc 2.96) and am getting
    JeffG> this error:

    JeffG> gcc -I../../src/extra/zlib -I. -I../../src/include
    JeffG> -I../../src/include -I/usr/local/include
    JeffG> -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -g -O2
    JeffG> -c pcre.c -o pcre.o pcre.c: In function `do_pgrep':
    JeffG> pcre.c:71: parse error before `char' pcre.c:72: `s'
    JeffG> undeclared (first use in this function) pcre.c:72:
    JeffG> (Each undeclared identifier is reported only once
    JeffG> pcre.c:72: for each function it appears in.)
    JeffG> make[3]: *** [pcre.o] Error 1 make[3]: Leaving
    JeffG> directory `/home/jgentry/R-1.8.0/src/main' make[2]:
    JeffG> *** [R] Error 2 make[2]: Leaving directory
    JeffG> `/home/jgentry/R-1.8.0/src/main' make[1]: *** [R]
    JeffG> Error 1 make[1]: Leaving directory
    JeffG> `/home/jgentry/R-1.8.0/src' make: *** [R] Error 1

    JeffG> On my initial attempt I did a 'make clean' before
    JeffG> configuring & building.  On my second attempt I
    JeffG> re-rsynced the entire r-devel distribution to a new
    JeffG> directory and am still getting this error.

    JeffG> Is this a problem w/ r-devel or a problem on my end?

on your end.

using old redhat with the "bad" compiler gcc 2.96 ...

{this is used to be an almost-FAQ about a year ago, when people
 still had such olde versions of Redhat / gcc ... ;-) }

From xoaquin at worldnet.att.net  Fri May 23 12:30:42 2003
From: xoaquin at worldnet.att.net (Joaquin Diaz-Saiz)
Date: Fri May 23 18:31:12 2003
Subject: [Rd] RGui Startup Error on Win2000 (PR#3084)
In-Reply-To: <001e01c32145$d5dc7200$0100a8c0@littleton>
References: <200305231416.h4NEGL2b025535@pubhealth.ku.dk>
	<3ECE3F94.2020400@statistik.uni-dortmund.de>
	<001e01c32145$d5dc7200$0100a8c0@littleton>
Message-ID: <3ECE4CB2.7040409@worldnet.att.net>

Girish Zambre escribi?:

>Uwe,
>
>I just did some experimentation.   The problem on my computer comes from
>tseries.zip.  I  removed the directories "/library/tseries" and
>"/library/waveslim" and R started up fine.  Then I restored
>"/library/waveslim" ; again R started fine. I then removed
>"/library/waveslim" and restored "/library/tseries"; and R DID NOT start up
>fine.   I don't know what version of tseries it is.  It is just the current
>tseries.zip off of the United States mirror http://cran.us.r-project.org/
>dated  04-Mar-2003 12:57 .
>
>I just downloaded tseries_0.9-11.tgz and from the changelog it suggests I
>have version 0.9-10.  This might be the problem.
>
>waveslim, though, works just great.  This beats Octave !
>
>
>
>GB Zambre
>
>----- Original Message ----- 
>From: "Uwe Ligges" <ligges@statistik.uni-dortmund.de>
>To: <gzambre@ieee.org>
>Cc: <r-devel@stat.math.ethz.ch>; "Joaquin Diaz-Saiz"
><xoaquin@worldnet.att.net>
>Sent: Friday, May 23, 2003 9:34 AM
>Subject: Re: [Rd] RGui Startup Error on Win2000 (PR#3084)
>
>
>  
>
>>gzambre@ieee.org wrote:
>>    
>>
>>>Full_Name: Girish Zambre
>>>Version: 1.7.0
>>>OS: Win2000
>>>Submission from: (NULL) (66.7.170.2)
>>>
>>>
>>>I just started looking at and trying R.  The problem could be external
>>>      
>>>
>to R, but
>  
>
>>>I really don't know. It reads
>>>
>>>'The instruction at "0x004412f0" referenced memory a "0x0095e40c". the
>>>      
>>>
>memory
>  
>
>>>could not be "read" '
>>>
>>>I get this after installing modules "waveslim.zip" and "tseries.zip" and
>>>restarting.
>>>      
>>>
>>Dear all,
>>
>>this is the 2nd bug report on this within one or two days (the other one
>>has #3079).
>>Please check
>>  a) whether there is really a bug and
>>  b) whether it has been reported before.
>>
>>
>>And again two questions:
>>  a) which version of *package* tseries?
>>  b) what way did you install it?
>>
>>For me
>>   install.packages("tseries")
>>works!
>>
>>I guess you downloaded a tseries version that was compiled for R<1.7.0.
>>The most recent Windows binary on CRAN ( != most recent tseries version)
>>for R-1.7.0 should be called tseries_0.9-11.zip on
>>CRAN/bin/windows/contrib/1.7  --- note the 1.7!!!
>>
>>Joaquin and Girish, does the correct binary solve your problem?
>>
>>Uwe Ligges
>>
>>    
>>
>
>
>  
>
Hi All:

I just downloaded the tseries_0.0-11.zip file and installed. I have the 
same problem, R would not start. Attached is the file produced by the 
operating system that may be of some help.

Joaquin Diaz-Saiz
-------------- next part --------------
??<










































From tlumley at u.washington.edu  Fri May 23 10:41:33 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri May 23 18:41:50 2003
Subject: [Rd] Problem building R-devel
In-Reply-To: <16078.19409.980882.202677@gargle.gargle.HOWL>
Message-ID: <Pine.A41.4.44.0305230936580.17962-100000@homer26.u.washington.edu>

On Fri, 23 May 2003, Martin Maechler wrote:

> >>>>> "JeffG" == Jeff Gentry <jgentry@jimmy.harvard.edu>
> >>>>>     on Fri, 23 May 2003 12:02:07 -0400 (EDT) writes:
>
>     JeffG> Hello ...  I went to build R-devel today (Redhat
>     JeffG> Linux 7.2, kernel 2.4.9-31, gcc 2.96) and am getting
>     JeffG> this error:
>
>     JeffG> gcc -I../../src/extra/zlib -I. -I../../src/include
>     JeffG> -I../../src/include -I/usr/local/include
>     JeffG> -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -g -O2
>     JeffG> -c pcre.c -o pcre.o pcre.c: In function `do_pgrep':
>     JeffG> pcre.c:71: parse error before `char' pcre.c:72: `s'
>     JeffG> undeclared (first use in this function) pcre.c:72:
<snip>
>     JeffG> Is this a problem w/ r-devel or a problem on my end?
>
> on your end.
>
> using old redhat with the "bad" compiler gcc 2.96 ...

Not entirely.  It's my fault.

While it compiles and passes check-devel on my system, the code I inserted
is technically incorrect C (it has a variable declaration after executable
code in a block).  In this case the bad compiler is right.

	-thomas

From ligges at statistik.uni-dortmund.de  Fri May 23 19:49:43 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri May 23 18:49:53 2003
Subject: [Rd] RGui Startup Error on Win2000 (PR#3084)
In-Reply-To: <3ECE4CB2.7040409@worldnet.att.net>
References: <200305231416.h4NEGL2b025535@pubhealth.ku.dk>
	<3ECE3F94.2020400@statistik.uni-dortmund.de>
	<001e01c32145$d5dc7200$0100a8c0@littleton>
	<3ECE4CB2.7040409@worldnet.att.net>
Message-ID: <3ECE5127.1030908@statistik.uni-dortmund.de>

Joaquin Diaz-Saiz wrote:
> Girish Zambre escribi?:
> 
>> Uwe,
>>
>> I just did some experimentation.   The problem on my computer comes from
>> tseries.zip.  I  removed the directories "/library/tseries" and
>> "/library/waveslim" and R started up fine.  Then I restored
>> "/library/waveslim" ; again R started fine. I then removed
>> "/library/waveslim" and restored "/library/tseries"; and R DID NOT 
>> start up
>> fine.   I don't know what version of tseries it is.  It is just the 
>> current
>> tseries.zip off of the United States mirror http://cran.us.r-project.org/
>> dated  04-Mar-2003 12:57 .
>>
>> I just downloaded tseries_0.9-11.tgz and from the changelog it suggests I
>> have version 0.9-10.  This might be the problem.
>>
>> waveslim, though, works just great.  This beats Octave !
>>
>>
>>
>> GB Zambre
>>
>> ----- Original Message ----- From: "Uwe Ligges" 
>> <ligges@statistik.uni-dortmund.de>
>> To: <gzambre@ieee.org>
>> Cc: <r-devel@stat.math.ethz.ch>; "Joaquin Diaz-Saiz"
>> <xoaquin@worldnet.att.net>
>> Sent: Friday, May 23, 2003 9:34 AM
>> Subject: Re: [Rd] RGui Startup Error on Win2000 (PR#3084)
>>
>>
>>  
>>
>>> gzambre@ieee.org wrote:
>>>   
>>>
>>>> Full_Name: Girish Zambre
>>>> Version: 1.7.0
>>>> OS: Win2000
>>>> Submission from: (NULL) (66.7.170.2)
>>>>
>>>>
>>>> I just started looking at and trying R.  The problem could be external
>>>>     
>>
>> to R, but
>>  
>>
>>>> I really don't know. It reads
>>>>
>>>> 'The instruction at "0x004412f0" referenced memory a "0x0095e40c". the
>>>>     
>>
>> memory
>>  
>>
>>>> could not be "read" '
>>>>
>>>> I get this after installing modules "waveslim.zip" and "tseries.zip" 
>>>> and
>>>> restarting.
>>>>     
>>>
>>> Dear all,
>>>
>>> this is the 2nd bug report on this within one or two days (the other one
>>> has #3079).
>>> Please check
>>>  a) whether there is really a bug and
>>>  b) whether it has been reported before.
>>>
>>>
>>> And again two questions:
>>>  a) which version of *package* tseries?
>>>  b) what way did you install it?
>>>
>>> For me
>>>   install.packages("tseries")
>>> works!
>>>
>>> I guess you downloaded a tseries version that was compiled for R<1.7.0.
>>> The most recent Windows binary on CRAN ( != most recent tseries version)
>>> for R-1.7.0 should be called tseries_0.9-11.zip on
>>> CRAN/bin/windows/contrib/1.7  --- note the 1.7!!!
>>>
>>> Joaquin and Girish, does the correct binary solve your problem?
>>>
>>> Uwe Ligges
>>> 
>>
> Hi All:
> 
> I just downloaded the tseries_0.0-11.zip file and installed. I have the 
> same problem, R would not start. Attached is the file produced by the 
> operating system that may be of some help.

I cannot reproduce this,
  neither on Windows NT4.0 SP6, nor on Windows XP SP1;
  neither with the R-1.7.0 binaries from CRAN nor with my self-compiled 
versions (R-1.7.0 and R-1.7.0 patched).

Uwe

From gregory_r_warnes at groton.pfizer.com  Fri May 23 13:50:05 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri May 23 18:50:25 2003
Subject: [Rd] How to avoid function masking
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C9D3@groexmb02.pfizer.com>


> -----Original Message-----
> From: Martin Maechler [mailto:maechler@stat.math.ethz.ch]
> Sent: Friday, May 23, 2003 9:00 AM
> To: Warnes, Gregory R

> You checked wrongly. library() *does* for several days now.
> (require doesn't -- on purpose?)

Yes, I was wrong.   have a typo in my script that calls rsync, and the
updates went into a different directory, so the code that I was looking at
was actually the released 1.7.0 code.

Looking at the new code, it appears that the pos argument only applies the
the package explicitly named in library() and not to a any packages it
loads.  Is this intentional?

-G


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From Laurens.Leerink at tudor.com  Fri May 23 14:48:01 2003
From: Laurens.Leerink at tudor.com (Laurens Leerink)
Date: Fri May 23 19:48:06 2003
Subject: [Rd] Opening a file in mode "r+" or "r+b" 
Message-ID: <C00E92D3970A4F41A95D70A813D544051089AE@tudor.com>

While using the file functions have found a few more issues (on both Unix
and Windows) ie

R documentation: 
In the "close" description (base package) we see that the possible values
for the mode 'open' the "r+" and "r+b" values are repeated, and are
incorrect the second time. The second set actually corresponds to the "w+" /
"w+b", see "man fopen" on unix.

File connections:
I had trouble using "r+" / "r+b" modes when processing files, all files
opened in this mode does not allow one to write to the file.  Saw that the
isOpen(con, "w") function always returns F in this mode, ie one can read
from them but cannot write.  After experimenting with flag combinations it
seems that all the other modes work well, so looked at the source code.  If
I'm not mistaken line 247 in connections.c should be changed from

    if(mlen >= 2 && con->mode[1] == '+') con->canread = TRUE;

to

    if(mlen >= 2 && con->mode[1] == '+') con->canwrite = TRUE;

This explained my earlier R script tests, ie that the only way to write to a
file is to truncate it ("w"/"w+" flag) or by appending to it ("a"/"ab").

Regards,
Laurens

>  -----Original Message-----
> From: 	Laurens Leerink  
> Sent:	Friday, May 23, 2003 9:33 AM
> To:	'r-help@stat.math.ethz.ch'
> Subject:	isSeekable returns F on seekable file
> 
> Hi,
> 
> Seems that on RWin 1.7.0 and 1.6.2 isSeekable returns F on binary files,
> while seek() works as expected on the same connection - see example below:
> 
> > con = file(nm, "rb")
> > isSeekable(con)
> [1] FALSE
> > readBin(con, double(), 10)
>  [1] 7.263824e-317 5.968155e-317 2.340685e-317 2.734062e-312 4.088386e-312
> 4.670335e-317
>  [7] 6.097545e-317 3.396341e-312 6.615484e-317 1.365171e-312
> > readBin(con, double(), 10)
>  [1] 1.303796e-317 5.577835e-317 3.409314e-312 1.303543e-317 3.893617e-317
> 4.077940e-312
>  [7] 6.910006e-313 2.694357e-318 4.088373e-312 6.484955e-317
> > seek(con, 0, origin="start")
> [1] 160
> > readBin(con, double(), 10)
>  [1] 7.263824e-317 5.968155e-317 2.340685e-317 2.734062e-312 4.088386e-312
> 4.670335e-317
>  [7] 6.097545e-317 3.396341e-312 6.615484e-317 1.365171e-312
> > 
> 
> Am I doing something silly or is the function returning the wrong value?
> 
> Regards,
> Laurens Leerink

	[[alternate HTML version deleted]]

From dmurdoch at pair.com  Fri May 23 15:05:28 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri May 23 20:06:08 2003
Subject: [Rd] Documenting S4 classes; debugging them
Message-ID: <ffoscvkcht69hhsnkhr1t8ci28psb2p10n@4ax.com>

1.  I'm putting together my first package that uses S4 classes and
objects.  I'd like to document them, but I'm not sure what the
documentation should look like, and package.skeleton doesn't produce
any at all for the classes or methods.

Are there any good examples to follow?

2.  How do I do the equivalent of debug(foo), when foo is an anonymous
function being used as a method?  

Duncan Murdoch

From rpeng at stat.ucla.edu  Fri May 23 13:35:26 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Fri May 23 21:35:35 2003
Subject: [Rd] Documenting S4 classes; debugging them
In-Reply-To: <ffoscvkcht69hhsnkhr1t8ci28psb2p10n@4ax.com>
References: <ffoscvkcht69hhsnkhr1t8ci28psb2p10n@4ax.com>
Message-ID: <3ECE77FE.8080100@stat.ucla.edu>

I was a little stumped with documenting S4 classes too when writing the 
`gpclib' package.  There are the promptClass() and promptMethods() which 
provide a bare-bones Rd file for a particular class.

-roger

Duncan Murdoch wrote:
> 1.  I'm putting together my first package that uses S4 classes and
> objects.  I'd like to document them, but I'm not sure what the
> documentation should look like, and package.skeleton doesn't produce
> any at all for the classes or methods.
> 
> Are there any good examples to follow?
> 
> 2.  How do I do the equivalent of debug(foo), when foo is an anonymous
> function being used as a method?  
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 
>

From jmc at research.bell-labs.com  Fri May 23 16:37:50 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Fri May 23 21:38:24 2003
Subject: [Rd] Documenting S4 classes; debugging them
References: <ffoscvkcht69hhsnkhr1t8ci28psb2p10n@4ax.com>
Message-ID: <3ECE788E.5329E293@research.bell-labs.com>

Duncan Murdoch wrote:
> 
> 1.  I'm putting together my first package that uses S4 classes and
> objects.  I'd like to document them, but I'm not sure what the
> documentation should look like, and package.skeleton doesn't produce
> any at all for the classes or methods.

Hmm, sounds as if it should.

Meanwhile, promptClass and promptMethods generate skeleton
documentation.


> 
> Are there any good examples to follow?

The bioconductor packages (e.g, Biobase) have some examples.

> 
> 2.  How do I do the equivalent of debug(foo), when foo is an anonymous
> function being used as a method?

The S4-style trace() function allows you to insert debugging functions
(or any expressions) into functions; it has a `signature' argument that
causes the debugging to be inserted into the method with the
corresponding signature.

Usually either `browser' or `recover' are suitable functions to insert.

My canonical piece of debugging code is along the lines of:

   trace("f", signature = "numeric", browser, exit = browser)

If you are really attached to debug(), you can insert an extra level of
function call; i.e., instead of:

  fNumeric <- function(x)x+1
  setMethod("f", "numeric", fNumeric)

and then the call to trace, do
  setMethod("f", "numeric", function(x)fNumeric(x))
  debug(fNumeric)

But trace() is more flexible, though requiring a bit more typing.

John

> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From gregory_r_warnes at groton.pfizer.com  Fri May 23 18:22:28 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri May 23 23:22:44 2003
Subject: [Rd] grep, gsub, sub have problems with NA values (PR#3078)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C9DC@groexmb02.pfizer.com>


FormatC also has the reverse problem, it detects any factor contianing the
string "NA" and converts it to a factor:

> formatC(factor("NAME"),width=8)
[1] <NA>
Levels: NAME

-Greg



> -----Original Message-----
> From: Thomas Lumley [mailto:tlumley@u.washington.edu]
> Sent: Friday, May 23, 2003 11:47 AM
> To: gregory_r_warnes@groton.pfizer.com
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] grep, gsub, sub have problems with NA 
> values (PR#3078)
> 
> 
> On Thu, 22 May 2003 gregory_r_warnes@groton.pfizer.com wrote:
> 
> >
> > In a string context, grep, gsub, sub are improperly 
> treating NA (missing) as
> > the string "NA", and returning unexpected results
> >
> 
> as were chartr, abbreviate, substr, substring, strsplit. 
> Fixed in r-devel,
> for the case of NA in the `main' string. Haven't yet decided 
> what to do
> about
>   grep(as.character(NA), x)
> or
>   substr(x,1,2)<-as.charcter(NA)
> 
> 
> 
> 	-thomas
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From ripley at stats.ox.ac.uk  Sat May 24 11:09:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May 24 11:09:28 2003
Subject: [Rd] library(MASS) in .First() (PR#3085)
In-Reply-To: <200305231516.h4NFGN2b025959@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305241008030.4516-100000@gannet.stats>

This is already solved in R-patched, and has been discussed on R-help 
several times with solutions.

The short answer is: don't do that or use R-patched.

On Fri, 23 May 2003 abroman@jhsph.edu wrote:

> Full_Name: Aimee Teo Broman
> Version: 1.7.0
> OS: Windows XP vers5.1
> Submission from: (NULL) (162.129.145.77)
> 
> 
> 
> My .First() function contains the command library(MASS) -- when I open R 1.7.0,
> I get this error:
> 
> Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> Error in library(MASS) : package/namespace load failed
> 
> If I run library(MASS) outside of the .First() function, it does not produce an
> error, and the functions from that library seem to work fine.  I was not getting
> this error in 1.6.2.
> 
> The .First() function I'm using:
> 
> .First <- function(){
>   library(foreign)
>   library(modreg)
>   library(MASS)
> }
> 
> thanks,
> Aimee
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat May 24 11:11:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May 24 11:12:31 2003
Subject: [Rd] Opening a file in mode "r+" or "r+b" 
In-Reply-To: <C00E92D3970A4F41A95D70A813D544051089AE@tudor.com>
Message-ID: <Pine.LNX.4.44.0305241010590.4516-100000@gannet.stats>

This is already corrected in R-patched and R-devel: see their NEWS files.


On Fri, 23 May 2003, Laurens Leerink wrote:

> While using the file functions have found a few more issues (on both Unix
> and Windows) ie
> 
> R documentation: 
> In the "close" description (base package) we see that the possible values
> for the mode 'open' the "r+" and "r+b" values are repeated, and are
> incorrect the second time. The second set actually corresponds to the "w+" /
> "w+b", see "man fopen" on unix.
> 
> File connections:
> I had trouble using "r+" / "r+b" modes when processing files, all files
> opened in this mode does not allow one to write to the file.  Saw that the
> isOpen(con, "w") function always returns F in this mode, ie one can read
> from them but cannot write.  After experimenting with flag combinations it
> seems that all the other modes work well, so looked at the source code.  If
> I'm not mistaken line 247 in connections.c should be changed from
> 
>     if(mlen >= 2 && con->mode[1] == '+') con->canread = TRUE;
> 
> to
> 
>     if(mlen >= 2 && con->mode[1] == '+') con->canwrite = TRUE;
> 
> This explained my earlier R script tests, ie that the only way to write to a
> file is to truncate it ("w"/"w+" flag) or by appending to it ("a"/"ab").
> 
> Regards,
> Laurens
> 
> >  -----Original Message-----
> > From: 	Laurens Leerink  
> > Sent:	Friday, May 23, 2003 9:33 AM
> > To:	'r-help@stat.math.ethz.ch'
> > Subject:	isSeekable returns F on seekable file
> > 
> > Hi,
> > 
> > Seems that on RWin 1.7.0 and 1.6.2 isSeekable returns F on binary files,
> > while seek() works as expected on the same connection - see example below:
> > 
> > > con = file(nm, "rb")
> > > isSeekable(con)
> > [1] FALSE
> > > readBin(con, double(), 10)
> >  [1] 7.263824e-317 5.968155e-317 2.340685e-317 2.734062e-312 4.088386e-312
> > 4.670335e-317
> >  [7] 6.097545e-317 3.396341e-312 6.615484e-317 1.365171e-312
> > > readBin(con, double(), 10)
> >  [1] 1.303796e-317 5.577835e-317 3.409314e-312 1.303543e-317 3.893617e-317
> > 4.077940e-312
> >  [7] 6.910006e-313 2.694357e-318 4.088373e-312 6.484955e-317
> > > seek(con, 0, origin="start")
> > [1] 160
> > > readBin(con, double(), 10)
> >  [1] 7.263824e-317 5.968155e-317 2.340685e-317 2.734062e-312 4.088386e-312
> > 4.670335e-317
> >  [7] 6.097545e-317 3.396341e-312 6.615484e-317 1.365171e-312
> > > 
> > 
> > Am I doing something silly or is the function returning the wrong value?
> > 
> > Regards,
> > Laurens Leerink
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From smyth at wehi.edu.au  Sat May 24 20:30:36 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sat May 24 11:30:51 2003
Subject: [Rd] Interpretation of escaped characters in \examples{}
Message-ID: <5.2.0.9.1.20030524191550.00ac35c0@imaphost.wehi.edu.au>

I've noticed a curious interpretation of escaped characters in \examples{} 
in .Rd files.

For example, if I type

     files <- dir(pattern="\\.txt")

at the R prompt, I will get a vector containing all file names in the 
current directory containing the string ".txt". If I put

     \examples{ files <- dir(pattern="\\.txt") }

in an .Rd file of a package, then the generated documentation will replace 
my command with

     Examples

     files <- dir(pattern="\.txt")

i.e., the escaped backslash has been interpreted into a single backlash. If 
a user types example(myfun) at the R prompt, where myfun is the topic alias 
of the .Rd file, then they will actually get

     files <- dir(pattern=".txt")

i.e., the backslash is interpreted a second time.

This seems an undesirable feature. What is in the .Rd file, what is 
displayed in the online help, and what is generated by
example() are all different commands. I had expected anything in 
\examples{} to be reproduced in the online help and by \example{} entirely 
literally with no intepretation.

I am using R 1.7.0pat under Windows 2000 Professional.

Gordon
---------------------------------------------------------------------------------------
Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
Walter and Eliza Hall Institute of Medical Research,
1G Royal Parade, Parkville, Vic 3050, Australia
Tel: (03) 9345 2326, Fax (03) 9347 0852,
Email: smyth@wehi.edu.au, www: http://www.statsci.org

From ripley at stats.ox.ac.uk  Sat May 24 11:42:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May 24 11:42:49 2003
Subject: [Rd] ~ files not excluded from build (PR#3071)
In-Reply-To: <3ECCD7F1.8020203@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.44.0305241038040.4728-100000@gannet.stats>

On Thu, 22 May 2003, Paul Gilbert wrote:

> ross@biostat.ucsf.edu wrote:
> > My docs say files ending in ~ are excluded by default from R CMD build.
> > Doesn't look that way to me.  I got them with 1.6.2 and 1.7.0.
> > My documenation is 1.6.0 (that is, the one saying *~ is excluded).
> > 
> > I have no .Rbuildignore of my own.
> 
> The exclude features have worked for me on Linux but never on Solaris. 
> Somewhere the documentation says that a tar newer than 1.13 is needed. 
> This is available with versions of Linux, but is a bit of a problem on 
> other systems since the latest version on ftp://ftp.gnu.org/gnu/tar/ is 
> 1.13.

Look on a mirror of the site alpha.gnu.org.

It's a known bug in GNU tar.  The `alpha' version tar-1.13.25 fixes it,
and is already 18 months old (1.13 is nearly 4 years old): makes one
wonder if GNU tar is being maintained.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat May 24 12:03:28 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May 24 12:03:41 2003
Subject: [Rd] How to avoid function masking
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C9D3@groexmb02.pfizer.com>
Message-ID: <Pine.LNX.4.44.0305241058270.4728-100000@gannet.stats>

On Fri, 23 May 2003, Warnes, Gregory R wrote:

> 
> > -----Original Message-----
> > From: Martin Maechler [mailto:maechler@stat.math.ethz.ch]
> > Sent: Friday, May 23, 2003 9:00 AM
> > To: Warnes, Gregory R
> 
> > You checked wrongly. library() *does* for several days now.
> > (require doesn't -- on purpose?)
> 
> Yes, I was wrong.   have a typo in my script that calls rsync, and the
> updates went into a different directory, so the code that I was looking at
> was actually the released 1.7.0 code.
> 
> Looking at the new code, it appears that the pos argument only applies the
> the package explicitly named in library() and not to a any packages it
> loads.  Is this intentional?

Yes.  What a package does is its own business, not library's, and if you 
read the help file you will see that pos is computed *after* .First.lib is 
run.

Authors of packages which load up other packages need to take 
responsibility for what thay may do to the search path: at least now they 
can arrange to load those packages at the end (and we may well make that
easier to achieve, by letting pos="base" mean load immediately before 
base).

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gregory_r_warnes at groton.pfizer.com  Sat May 24 09:17:22 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Sat May 24 14:17:53 2003
Subject: [Rd] grep, gsub, sub have problems with NA values (PR#3078)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C9DD@groexmb02.pfizer.com>


I see that this came out garbled.  It should have read:

FormatC also has problems:  It incorrectly convertys any factor level
*containing* the characters 'NA' to a missing value.

> > formatC(factor("NAME"),width=8)
> [1] <NA>
> Levels: NAME

-G


> -----Original Message-----
> From: Warnes, Gregory R 
> Sent: Friday, May 23, 2003 5:22 PM
> To: 'Thomas Lumley'; Warnes, Gregory R
> Cc: r-devel@stat.math.ethz.ch
> Subject: RE: [Rd] grep, gsub, sub have problems with NA 
> values (PR#3078)
> 
> 
> 
> FormatC also has the reverse problem, it detects any factor 
> contianing the string "NA" and converts it to a factor:
> 
> > formatC(factor("NAME"),width=8)
> [1] <NA>
> Levels: NAME
> 
> -Greg
> 
> 
> 
> > -----Original Message-----
> > From: Thomas Lumley [mailto:tlumley@u.washington.edu]
> > Sent: Friday, May 23, 2003 11:47 AM
> > To: gregory_r_warnes@groton.pfizer.com
> > Cc: r-devel@stat.math.ethz.ch
> > Subject: Re: [Rd] grep, gsub, sub have problems with NA 
> > values (PR#3078)
> > 
> > 
> > On Thu, 22 May 2003 gregory_r_warnes@groton.pfizer.com wrote:
> > 
> > >
> > > In a string context, grep, gsub, sub are improperly 
> > treating NA (missing) as
> > > the string "NA", and returning unexpected results
> > >
> > 
> > as were chartr, abbreviate, substr, substring, strsplit. 
> > Fixed in r-devel,
> > for the case of NA in the `main' string. Haven't yet decided 
> > what to do
> > about
> >   grep(as.character(NA), x)
> > or
> >   substr(x,1,2)<-as.charcter(NA)
> > 
> > 
> > 
> > 	-thomas
> > 
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From gregory_r_warnes at groton.pfizer.com  Sat May 24 09:35:49 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Sat May 24 14:36:40 2003
Subject: [Rd] grep, gsub, sub have problems with NA values (PR#3078)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C9E0@groexmb02.pfizer.com>

Oh dear, more careful checking shows that all elements of a factor get
converted to NA by formatC, but the results retain the factor levels:

>  x <- factor(letters[1:5], width=8)
> formatC(x)
[1] <NA> <NA> <NA> <NA> <NA>
Levels: a b c d e

I have a hard time justifying this behavior.  I expected it to act like
format.char:

> format.char(x,width=8)
[1] "a       " "b       " "c       " "d       " "e       "
Warning message: 
format.char: coercing 'x' to 'character' in: format.char(x, width = 8) 

The way this came up was in formatting all of the elements of a dataframe to
have width 8 so that I could create a fixed width output file...

-G

> -----Original Message-----
> From: Warnes, Gregory R 
> Sent: Saturday, May 24, 2003 8:17 AM
> To: Warnes, Gregory R; 'Thomas Lumley'
> Cc: 'r-devel@stat.math.ethz.ch'
> Subject: RE: [Rd] grep, gsub, sub have problems with NA 
> values (PR#3078)
> 
> 
> 
> I see that this came out garbled.  It should have read:
> 
> FormatC also has problems:  It incorrectly convertys any 
> factor level *containing* the characters 'NA' to a missing value.
> 
> > > formatC(factor("NAME"),width=8)
> > [1] <NA>
> > Levels: NAME
> 
> -G
> 
> 
> > -----Original Message-----
> > From: Warnes, Gregory R 
> > Sent: Friday, May 23, 2003 5:22 PM
> > To: 'Thomas Lumley'; Warnes, Gregory R
> > Cc: r-devel@stat.math.ethz.ch
> > Subject: RE: [Rd] grep, gsub, sub have problems with NA 
> > values (PR#3078)
> > 
> > 
> > 
> > FormatC also has the reverse problem, it detects any factor 
> > contianing the string "NA" and converts it to a factor:
> > 
> > > formatC(factor("NAME"),width=8)
> > [1] <NA>
> > Levels: NAME
> > 
> > -Greg
> > 
> > 
> > 
> > > -----Original Message-----
> > > From: Thomas Lumley [mailto:tlumley@u.washington.edu]
> > > Sent: Friday, May 23, 2003 11:47 AM
> > > To: gregory_r_warnes@groton.pfizer.com
> > > Cc: r-devel@stat.math.ethz.ch
> > > Subject: Re: [Rd] grep, gsub, sub have problems with NA 
> > > values (PR#3078)
> > > 
> > > 
> > > On Thu, 22 May 2003 gregory_r_warnes@groton.pfizer.com wrote:
> > > 
> > > >
> > > > In a string context, grep, gsub, sub are improperly 
> > > treating NA (missing) as
> > > > the string "NA", and returning unexpected results
> > > >
> > > 
> > > as were chartr, abbreviate, substr, substring, strsplit. 
> > > Fixed in r-devel,
> > > for the case of NA in the `main' string. Haven't yet decided 
> > > what to do
> > > about
> > >   grep(as.character(NA), x)
> > > or
> > >   substr(x,1,2)<-as.charcter(NA)
> > > 
> > > 
> > > 
> > > 	-thomas
> > > 
> > 
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}

From smyth at wehi.edu.au  Sun May 25 00:30:52 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sat May 24 15:30:52 2003
Subject: [Rd] Re: R-devel Digest, Vol 3, Issue 23
In-Reply-To: <200305241000.h4OA0gMo020451@hypatia.math.ethz.ch>
Message-ID: <5.2.0.9.1.20030524221045.00abf6c8@imaphost.wehi.edu.au>

I am another person who has had trouble documenting S4 classes and 
(particularly) methods. The methods package itself is pretty cool by the 
way, but it is a pity that there are as yet no guidelines on S4 in the 
"Writing R Extensions" document.

I have actually put together a guide on S4 documentation myself for the use 
of my own lab which is at http://bioinf.wehi.edu.au/limma/Rdocs.html. I 
don't pretend that the guide is perfect - I can already see problems with 
it - but it has proved adequate so far for our own use (writing the limma 
package) and has gained some more general acceptance from the Bioconductor 
community.

I found it hard to use the skeleton documentation provided by 
promptMethods. Suppose for example that I wish to document a method for 
generic function 'foo' with argument list (x,y,...) for x of class 'bar1' 
and y of class 'bar2':

1. The skeleton .Rd file contains \alias{foo-methods}. If two or more more 
packages document methods for 'foo', they'll all have the same alias entry, 
and the help that a user will get by typing ?"foo-methods" will depend on 
which package happens to have been loaded most recently.

2. There seems to be no allowance for documenting extra named arguments for 
this method which are not specified in the generic. There is no usage 
entry, no argument list, and no process for R CMD check to check the 
argument list against the definition of the method. In S3 one can write 
\usage{\method{generic}{class}} and it would be nice to have an extension 
of this facility for S4 methods. I have been abandoning the skeleton 
structure produced by promptMethods and have been using \section{Usage} and 
\section{Arguments}.

3. The aliases for methods are pretty verbose and make the html contents 
page for the package look rather cluttered. I have been deleting the 
\alias{foo-methods} alias and been replacing \alias{foo,bar1,bar2-method} 
with \alias{foo.bar1.bar2}. I know that using a syntactically valid name 
for the alias has the potential problem that a function could actually 
exist with that name, but I just like to use something shorter.

4. There don't seem to be any guidelines for documenting a method with the 
generic, if the generic happens to be defined in the same package, or with 
the object class, if the generic dispatches on only one argument. I know 
that you have thought about this, and in the document 
http://developer.r-project.org/moreClassMethodIssues.html you refer to the 
'addTo' argument for 'promptMethods'. The 'addTo' argument however has not 
yet been implemented in R.

It would be nice to have a method for finding dynamically all available 
documentation for methods for a given generic function. I wrote a little 
prototype function called 'helpMethods' which simply extracts the list of 
available methods and prompts the user for which help topic they'd like to 
read. For this to work though, developers need to use a consistent alias 
system for documenting methods. I haven't seen any package yet which is 
using the aliases suggested by promptMethods.

Do you think there is any value in my S4 documentation guide? Are there 
errors or mis-understandings in it which should be corrected before it is 
adopted as a guideline by Bioconductor?

Are there major changes planned for the documentation system for S4 methods 
and classes in R in the near future? Is it worth our while spending time 
working out guidelines now or should we wait a bit until the situation 
stabilizes?

Best wishes
Gordon

>Date: Fri, 23 May 2003 15:37:50 -0400
>From: John Chambers <jmc@research.bell-labs.com>
>Subject: Re: [Rd] Documenting S4 classes; debugging them
>To: Duncan Murdoch <dmurdoch@pair.com>
>Cc: r-devel@stat.math.ethz.ch
>
>Duncan Murdoch wrote:
> >
> > 1.  I'm putting together my first package that uses S4 classes and
> > objects.  I'd like to document them, but I'm not sure what the
> > documentation should look like, and package.skeleton doesn't produce
> > any at all for the classes or methods.
>
>Hmm, sounds as if it should.
>
>Meanwhile, promptClass and promptMethods generate skeleton
>documentation.
>
> >
> > Are there any good examples to follow?
>
>The bioconductor packages (e.g, Biobase) have some examples.

...

>John
>
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>--
>John M. Chambers                  jmc@bell-labs.com
>Bell Labs, Lucent Technologies    office: (908)582-2681
>700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
>Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

---------------------------------------------------------------------------------------
Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
Walter and Eliza Hall Institute of Medical Research,
1G Royal Parade, Parkville, Vic 3050, Australia
Tel: (03) 9345 2326, Fax (03) 9347 0852,
Email: smyth@wehi.edu.au, www: http://www.statsci.org

From smyth at wehi.edu.au  Sun May 25 00:39:56 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sat May 24 15:39:46 2003
Subject: [Rd] Documenting S4 classes; debugging them
Message-ID: <5.2.0.9.1.20030524233428.00abdba8@imaphost.wehi.edu.au>

My previous post should have had this subject heading - my apologies.

Gordon
---------------------------------------------------------------------------------------
Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
Walter and Eliza Hall Institute of Medical Research,
1G Royal Parade, Parkville, Vic 3050, Australia
Tel: (03) 9345 2326, Fax (03) 9347 0852,
Email: smyth@wehi.edu.au, www: http://www.statsci.org

From dmurdoch at pair.com  Sun May 25 09:20:30 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun May 25 14:20:45 2003
Subject: [Rd] Re: [R] help output paged in separate window
In-Reply-To: <XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
	<XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <ntc1dvkmh7a4sei8jhpdc37ptamh7fk8cr@4ax.com>

On Sun, 25 May 2003 10:42:27 +0100 (BST), Ted.Harding@nessie.mcc.ac.uk
wrote in r-help:

>Thanks to Jonathan Baron and Peter Dalgaard for private comments and help
>on this question. Peter in particular pointed out that
>  library(tcltk); options(pager=tkpager)

I notice a bug in the behaviour when used with help().  In Windows
(and elsewhere?) the pager gets called through file.show, with the
help topic given as the "header", rather than the "title".  According
to the docs, "title" is supposed to be an overall title common to all
displayed files, while "header" is file-specific.  In Windows, a
combination of both args is used as the window title.

However, tkpager only uses the "title" argument for the window title,
putting "header" into the text being displayed, with the result that
the windows end up with no title.

Is this an inconsistency in the usage for "header" between Windows and
other platforms, or a bug in tkpager?

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Sun May 25 14:29:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun May 25 15:29:07 2003
Subject: [Rd] Re: [R] help output paged in separate window
In-Reply-To: <ntc1dvkmh7a4sei8jhpdc37ptamh7fk8cr@4ax.com>
References: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
	<XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>
	<ntc1dvkmh7a4sei8jhpdc37ptamh7fk8cr@4ax.com>
Message-ID: <x2k7cf9mj0.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> On Sun, 25 May 2003 10:42:27 +0100 (BST), Ted.Harding@nessie.mcc.ac.uk
> wrote in r-help:
> 
> >Thanks to Jonathan Baron and Peter Dalgaard for private comments and help
> >on this question. Peter in particular pointed out that
> >  library(tcltk); options(pager=tkpager)
> 
> I notice a bug in the behaviour when used with help().  In Windows
> (and elsewhere?) the pager gets called through file.show, with the
> help topic given as the "header", rather than the "title".  According
> to the docs, "title" is supposed to be an overall title common to all
> displayed files, while "header" is file-specific.  In Windows, a
> combination of both args is used as the window title.
> 
> However, tkpager only uses the "title" argument for the window title,
> putting "header" into the text being displayed, with the result that
> the windows end up with no title.
> 
> Is this an inconsistency in the usage for "header" between Windows and
> other platforms, or a bug in tkpager?

A bit of both, I think. The Unix version of help() has

                  file.show(zfile, title = paste("R Help on `",
                    topic, "'", sep = ""), delete.file = (zfile !=
                    file), pager = pager)

so everything is in the title. We could still paste the title and the
header arguments rather than put the header in the displayed text, of
course. 

I don't read the docs as "overall title common to all displayed files"
though, just as common to the set of files displayed by file.show. Or
was that what you meant too?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Sun May 25 11:27:55 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun May 25 16:28:08 2003
Subject: [Rd] Re: [R] help output paged in separate window
In-Reply-To: <x2k7cf9mj0.fsf@biostat.ku.dk>
References: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
	<XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>
	<ntc1dvkmh7a4sei8jhpdc37ptamh7fk8cr@4ax.com>
	<x2k7cf9mj0.fsf@biostat.ku.dk>
Message-ID: <cni1dv401rs091o93bplh3h73eh6c0qe7h@4ax.com>

On 25 May 2003 15:35:47 +0200, you wrote:
>
>A bit of both, I think. The Unix version of help() has
>
>                  file.show(zfile, title = paste("R Help on `",
>                    topic, "'", sep = ""), delete.file = (zfile !=
>                    file), pager = pager)
>so everything is in the title. We could still paste the title and the
>header arguments rather than put the header in the displayed text, of
>course. 

Windows has

 file.show(zfile, title = "", header = paste("`", topic, "' help", 
	sep=""), delete.file = (zfile!=file), pager = pager)

Probably I should change Windows to use title= instead of header=.
It'll make no difference to the behaviour with the standard Windows
pager, which combines the title and header.

I think tkpager should combine the title and header too, since it
shows each file in a separate window, but the change above would be
enough to solve the bug I reported.

>I don't read the docs as "overall title common to all displayed files"
>though, just as common to the set of files displayed by file.show. Or
>was that what you meant too?

Yes, common to all files displayed in that call.

Duncan

From p.dalgaard at biostat.ku.dk  Sun May 25 15:52:31 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun May 25 16:52:33 2003
Subject: [Rd] Re: [R] help output paged in separate window
In-Reply-To: <cni1dv401rs091o93bplh3h73eh6c0qe7h@4ax.com>
References: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
	<XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>
	<ntc1dvkmh7a4sei8jhpdc37ptamh7fk8cr@4ax.com>
	<x2k7cf9mj0.fsf@biostat.ku.dk>
	<cni1dv401rs091o93bplh3h73eh6c0qe7h@4ax.com>
Message-ID: <x2fzn39ior.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch@pair.com> writes:

> On 25 May 2003 15:35:47 +0200, you wrote:
> >
> >A bit of both, I think. The Unix version of help() has
> >
> >                  file.show(zfile, title = paste("R Help on `",
> >                    topic, "'", sep = ""), delete.file = (zfile !=
> >                    file), pager = pager)
> >so everything is in the title. We could still paste the title and the
> >header arguments rather than put the header in the displayed text, of
> >course. 
> 
> Windows has
> 
>  file.show(zfile, title = "", header = paste("`", topic, "' help", 
> 	sep=""), delete.file = (zfile!=file), pager = pager)
> 
> Probably I should change Windows to use title= instead of header=.
> It'll make no difference to the behaviour with the standard Windows
> pager, which combines the title and header.
> 
> I think tkpager should combine the title and header too, since it
> shows each file in a separate window, but the change above would be
> enough to solve the bug I reported.

Hmm... So would changing tkpager, and without having to change the
documented API. So that would probably be a more straightforward
solution. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Sun May 25 17:57:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun May 25 17:57:26 2003
Subject: [Rd] Re: [R] help output paged in separate window
In-Reply-To: <x2fzn39ior.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0305251646120.522-100000@gannet.stats>

We do have an API for file.show and the underlying C (in 
src/unix/system.txt).  It seem clear to me that the Windows help 
code is incorrect (and at least it used to set a title).
Duncan changed it, and I cannot recall the exact rationale.

It seems that tkpager is also not doing what file.show says is needed.

Brian

On 25 May 2003, Peter Dalgaard BSA wrote:

> Duncan Murdoch <dmurdoch@pair.com> writes:
> 
> > On 25 May 2003 15:35:47 +0200, you wrote:
> > >
> > >A bit of both, I think. The Unix version of help() has
> > >
> > >                  file.show(zfile, title = paste("R Help on `",
> > >                    topic, "'", sep = ""), delete.file = (zfile !=
> > >                    file), pager = pager)
> > >so everything is in the title. We could still paste the title and the
> > >header arguments rather than put the header in the displayed text, of
> > >course. 
> > 
> > Windows has
> > 
> >  file.show(zfile, title = "", header = paste("`", topic, "' help", 
> > 	sep=""), delete.file = (zfile!=file), pager = pager)
> > 
> > Probably I should change Windows to use title= instead of header=.
> > It'll make no difference to the behaviour with the standard Windows
> > pager, which combines the title and header.
> > 
> > I think tkpager should combine the title and header too, since it
> > shows each file in a separate window, but the change above would be
> > enough to solve the bug I reported.
> 
> Hmm... So would changing tkpager, and without having to change the
> documented API. So that would probably be a more straightforward
> solution. 
> 
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dmurdoch at pair.com  Sun May 25 13:13:21 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun May 25 18:13:33 2003
Subject: [Rd] Re: [R] help output paged in separate window
In-Reply-To: <Pine.LNX.4.44.0305251646120.522-100000@gannet.stats>
References: <x2fzn39ior.fsf@biostat.ku.dk>
	<Pine.LNX.4.44.0305251646120.522-100000@gannet.stats>
Message-ID: <7oq1dv0rnuphmbrnph8olbo2c1nl0bte13@4ax.com>

On Sun, 25 May 2003 16:57:12 +0100 (BST), you wrote:

>We do have an API for file.show and the underlying C (in 
>src/unix/system.txt).  It seem clear to me that the Windows help 
>code is incorrect (and at least it used to set a title).
>Duncan changed it, and I cannot recall the exact rationale.

No, it never used title.  I changed the text being shown (so that it
would still be informative when truncated in the Windows taskbar), but
using title seems to have been a change in the Unix version after it
was split from the Windows one.

I've now changed Windows to use title like Unix does.

Duncan

From ligges at statistik.uni-dortmund.de  Sun May 25 19:33:49 2003
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Sun May 25 18:34:04 2003
Subject: [Rd] surprising behaviour of "bgroup": sets all in greek letters
	(PR#3099)
Message-ID: <200305251633.h4PGXn2b004593@pubhealth.ku.dk>

Let me summarize the bug reported by Ulf Martin on R-help with the same 
subject line.

The code

   plot(1:10)
   text(1, 9, expression(F == bgroup("{", x, "")))

results in greek letters, which is not expected here.
That happens if the user tries to set only a left delimeter, the same with:

   text(2, 8, expression(F == bgroup("{", x, ".")))

or

   text(3, 7, expression(F == bgroup(".", x, "}")))

but it works if delimeters are specified, as in:

   text(4, 6, expression(F == bgroup("{", x, ")")))


I don't know whether I have just fixed the symptoms here (Paul ?). 
Anyway, the following fix of  .../src/main/plotmath.c  works as expected.

Uwe Ligges



==========================
(diff'ed to R-1.7.0 patched (2003-05-25))
 >  diff -u ./plotmath.old ./r-patched/src/main/plotmath.c


--- ./plotmath.old     2003-05-25 17:47:23.000000000 +0200
+++ ./r-patched/src/main/plotmath.c     2003-05-25 17:49:38.000000000 +0200
@@ -2075,10 +2075,12 @@
      delim2 = DelimCode(expr, CADDDR(expr));
      bbox = RenderElement(CADDR(expr), 0);
      dist = max(bboxHeight(bbox) - axisHeight, bboxDepth(bbox) + 
axisHeight);
-    bbox = RenderDelim(delim1, dist + extra, draw);
+    if (delim1 != '.')
+        bbox = RenderDelim(delim1, dist + extra, draw);
      bbox = CombineBBoxes(bbox, RenderElement(CADDR(expr), draw));
      bbox = RenderItalicCorr(bbox, draw);
-    bbox = CombineBBoxes(bbox, RenderDelim(delim2, dist + extra, draw));
+    if (delim2 != '.')
+        bbox = CombineBBoxes(bbox,     RenderDelim(delim2, dist + 
extra, draw));
      return bbox;
  }

From hornik at ci.tuwien.ac.at  Sun May 25 22:22:10 2003
From: hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Sun May 25 23:06:20 2003
Subject: [Rd] Interpretation of escaped characters in \examples{}
In-Reply-To: <5.2.0.9.1.20030524191550.00ac35c0@imaphost.wehi.edu.au>
References: <5.2.0.9.1.20030524191550.00ac35c0@imaphost.wehi.edu.au>
Message-ID: <16081.6114.772360.84685@mithrandir.hornik.net>

>>>>> Gordon Smyth writes:

> I've noticed a curious interpretation of escaped characters in \examples{} 
> in .Rd files.

> For example, if I type

>      files <- dir(pattern="\\.txt")

> at the R prompt, I will get a vector containing all file names in the 
> current directory containing the string ".txt". If I put

>      \examples{ files <- dir(pattern="\\.txt") }

> in an .Rd file of a package, then the generated documentation will replace 
> my command with

>      Examples

>      files <- dir(pattern="\.txt")

> i.e., the escaped backslash has been interpreted into a single backlash. If 
> a user types example(myfun) at the R prompt, where myfun is the topic alias 
> of the .Rd file, then they will actually get

>      files <- dir(pattern=".txt")

> i.e., the backslash is interpreted a second time.

> This seems an undesirable feature. What is in the .Rd file, what is
> displayed in the online help, and what is generated by example() are
> all different commands. I had expected anything in \examples{} to be
> reproduced in the online help and by \example{} entirely literally
> with no intepretation.

> I am using R 1.7.0pat under Windows 2000 Professional.

R-exts clearly says

	   The "comment" and "control" characters `%' and `\' _always_
	need to be escaped.  Inside the verbatim-like commands (`\code'
	and `\examples'), no other(1) characters are special.  Note that
	`\file' is *not* a verbatim-like command.

-k

From charlotte_melton7 at bmxtrix.com  Mon May 26 00:47:33 2003
From: charlotte_melton7 at bmxtrix.com (charlotte_melton7@bmxtrix.com)
Date: Sun May 25 23:47:47 2003
Subject: [Rd] I have been searching for you! (PR#3102)
Message-ID: <200305252147.h4PLlX2b005548@pubhealth.ku.dk>

ICAgDQoJPEhUTUw+CQ0KCQkJCQ0KPEJPRFkgYmdjb2xvcj0jZmZmZmZmPgkN
CgkNCgk8cCBhbGlnbj0iY2VudGVyIj48Zm9udCBmYWNlPSJ2ZXJkYW5hIj48
WlpXQj4NCkdldCBsPFhIVkw+YTxYPnI8WFdVPmdlPFk+ciBiYWxscyBhbmQg
PFhDPnA8Qz5lPFhXWVI+bu08V00+czxLS0E+LCANCiBtPFo+b3JlDQogPFhD
PnBsPFhBVD5lPENIPmFzdXJlLCANCgkNCgkgbTxaT1U+b3I8V1Q+ZQ0KIDxX
PnNhdGlzZmE8UUo+YzxXSUlIPnQ8Vz5pbzxLQT5uPGJyPg0KPGEgaHJlZj0i
aHR0cDovL3dXVy5zb25JY0JVQ2tzLmNvbS8lNzBpJTZjbHMvJTZEJTMyYy4l
NzBoJTcwP20lNjElNkU9JTczJTc0JTM0JTc2cCI+TGVhcm4gYWJvdXQgaXQg
aGU8UUhQTT5yPFhVPmU8L2E+PGJyPg0KPGJyPg0KCQkNCjxBIEhSRUY9Imh0
dHA6Ly93V3cuc09uSWNCVUNLcy5Db20vcCU2OWwlNkNzLyU2ZCUzMiU2My5w
aHA/bSU2MW49JTczdCUzNHYlNzAiPiAgPElNRyBTUkM9Imh0dHA6Ly93V3cu
Q0hlQVBPTm5FVC5ORXQvcC5qcGciIEJPUkRFUj0wPg0KIA0KCQ0KPC9BPjxi
cj48YnI+PGJyPg0KPHByZT4NCi0tLS1PcmlnaW5hbCBNZXNzYWdlLS0tLQ0K
ci1idWdzQGJpb3N0YXQua3UuZGsgd3JvdGU6DQo+IEkgZG9uJ3Qga25vdw0K
DQo8L3ByZT4NCjxhIGhyZWY9Imh0dHA6Ly93V3cuQ0hFYXBvbm5ldC5OZVQv
ciU2NW1vdmUvIj5ObyBtbzxDQ0Y+cjxaTVg+ZSBwbGVhc2U8L2E+DQo8YnI+
LT1icjdiaDlOYXN4M2JUQ3dnSnNzUnR4UW1saFQ9LTwvZm9udD48L3A+DQoJ
CQ0KCTwvYm9keT4gICANCgk8L0hUTUw+ICANCgkNCg0KDQo=

From smyth at wehi.edu.au  Mon May 26 13:05:03 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Mon May 26 04:05:20 2003
Subject: [Rd] Interpretation of escaped characters in \examples{}
In-Reply-To: <16081.6114.772360.84685@mithrandir.hornik.net>
References: <5.2.0.9.1.20030524191550.00ac35c0@imaphost.wehi.edu.au>
	<5.2.0.9.1.20030524191550.00ac35c0@imaphost.wehi.edu.au>
Message-ID: <5.2.0.9.1.20030526114014.00ac1008@imaphost.wehi.edu.au>

At 05:22 AM 26/05/2003, Kurt Hornik wrote:
> >>>>> Gordon Smyth writes:
>
> > I've noticed a curious interpretation of escaped characters in \examples{}
> > in .Rd files.
>
> > For example, if I type
>
> >      files <- dir(pattern="\\.txt")
>
> > at the R prompt, I will get a vector containing all file names in the
> > current directory containing the string ".txt". If I put
>
> >      \examples{ files <- dir(pattern="\\.txt") }
>
> > in an .Rd file of a package, then the generated documentation will replace
> > my command with
>
> >      Examples
>
> >      files <- dir(pattern="\.txt")
>
> > i.e., the escaped backslash has been interpreted into a single 
> backlash. If
> > a user types example(myfun) at the R prompt, where myfun is the topic 
> alias
> > of the .Rd file, then they will actually get
>
> >      files <- dir(pattern=".txt")
>
> > i.e., the backslash is interpreted a second time.
>
> > This seems an undesirable feature. What is in the .Rd file, what is
> > displayed in the online help, and what is generated by example() are
> > all different commands. I had expected anything in \examples{} to be
> > reproduced in the online help and by \example{} entirely literally
> > with no intepretation.
>
> > I am using R 1.7.0pat under Windows 2000 Professional.
>
>R-exts clearly says
>
>            The "comment" and "control" characters `%' and `\' _always_
>         need to be escaped.  Inside the verbatim-like commands (`\code'
>         and `\examples'), no other(1) characters are special.  Note that
>         `\file' is *not* a verbatim-like command.
>
>-k

Dear Kurt,

Thanks very much for this reference from the R-exts document. You don't 
address though the main point of my post, which is that the code displayed 
the online help and executed and checked by R CMD check is different from 
the code extracted and executed by the function 'example'.

Suppose I have an .Rd file for a function 'readFiles' containing the text 
'\examples{dir(pattern="\\\\.txt")}'. The quadruple-backlash will ensure 
that 'help' displays and R CMD checks the correct command 
'dir(pattern="\\.txt")'. However, if a user types 'example("readFiles")' at 
the R prompt, the command that R will execute is 'dir(pattern=".txt")'. 
This is *different command* and will generally give *wrong* results. There 
is no way that I can see to ensure that R CMD check and 'example' execute 
the same code.

My concern here is the with actual behavior of R rather than what R-exts 
says but, since you are emphasising the clarity of the R-exts document, it 
may be worth pointing out that R-exts also says

        \examples{...}
        Examples of how to use the function. These are set verbatim in 
typewriter font.

This seems to say that \examples{} is a verbatim environment rather than 
merely verbatim-like. This statement comes 4 pages earlier in the pdf 
version than the paragraph you quote.

Best wishes
Gordon

From hornik at ci.tuwien.ac.at  Mon May 26 08:21:57 2003
From: hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Mon May 26 07:25:53 2003
Subject: [Rd] Interpretation of escaped characters in \examples{}
In-Reply-To: <5.2.0.9.1.20030526114014.00ac1008@imaphost.wehi.edu.au>
References: <5.2.0.9.1.20030524191550.00ac35c0@imaphost.wehi.edu.au>
	<5.2.0.9.1.20030526114014.00ac1008@imaphost.wehi.edu.au>
Message-ID: <16081.42101.218072.218770@mithrandir.hornik.net>

>>>>> Gordon Smyth writes:

> At 05:22 AM 26/05/2003, Kurt Hornik wrote:
>> >>>>> Gordon Smyth writes:
>> 
>> > I've noticed a curious interpretation of escaped characters in \examples{}
>> > in .Rd files.
>> 
>> > For example, if I type
>> 
>> >      files <- dir(pattern="\\.txt")
>> 
>> > at the R prompt, I will get a vector containing all file names in the
>> > current directory containing the string ".txt". If I put
>> 
>> >      \examples{ files <- dir(pattern="\\.txt") }
>> 
>> > in an .Rd file of a package, then the generated documentation will replace
>> > my command with
>> 
>> >      Examples
>> 
>> >      files <- dir(pattern="\.txt")
>> 
>> > i.e., the escaped backslash has been interpreted into a single 
>> backlash. If
>> > a user types example(myfun) at the R prompt, where myfun is the topic 
>> alias
>> > of the .Rd file, then they will actually get
>> 
>> >      files <- dir(pattern=".txt")
>> 
>> > i.e., the backslash is interpreted a second time.
>> 
>> > This seems an undesirable feature. What is in the .Rd file, what is
>> > displayed in the online help, and what is generated by example() are
>> > all different commands. I had expected anything in \examples{} to be
>> > reproduced in the online help and by \example{} entirely literally
>> > with no intepretation.
>> 
>> > I am using R 1.7.0pat under Windows 2000 Professional.
>> 
>> R-exts clearly says
>> 
>> The "comment" and "control" characters `%' and `\' _always_
>> need to be escaped.  Inside the verbatim-like commands (`\code'
>> and `\examples'), no other(1) characters are special.  Note that
>> `\file' is *not* a verbatim-like command.
>> 
>> -k

> Dear Kurt,

> Thanks very much for this reference from the R-exts document. You
> don't address though the main point of my post, which is that the code
> displayed the online help and executed and checked by R CMD check is
> different from the code extracted and executed by the function
> 'example'.

> Suppose I have an .Rd file for a function 'readFiles' containing the
> text '\examples{dir(pattern="\\\\.txt")}'. The quadruple-backlash will
> ensure that 'help' displays and R CMD checks the correct command
> 'dir(pattern="\\.txt")'. However, if a user types
> 'example("readFiles")' at the R prompt, the command that R will
> execute is 'dir(pattern=".txt")'.  This is *different command* and
> will generally give *wrong* results. There is no way that I can see to
> ensure that R CMD check and 'example' execute the same code.

Gordon,

I may be missing something obvious here but if e.g. look at strsplit.Rd
in the base package, this has

     unlist(strsplit("a.b.c", "."))
     ## [1] "" "" "" "" ""
     ## Note that `split' is a regexp!
     ## If you really want to split on `.', use
     unlist(strsplit("a.b.c", "\\."))
     ## [1] "a" "b" "c"

in the rendered version and

strspl> unlist(strsplit("a.b.c", "."))
[1] "" "" "" "" ""

strspl> unlist(strsplit("a.b.c", "\\."))
[1] "a" "b" "c"

and I also get

R> unlist(strsplit("a.b.c", "\\."))
[1] "a" "b" "c"

so these seem rather consistent to me?

> My concern here is the with actual behavior of R rather than what R-exts 
> says but, since you are emphasising the clarity of the R-exts document, it 
> may be worth pointing out that R-exts also says

>         \examples{...}
>         Examples of how to use the function. These are set verbatim in 
> typewriter font.

> This seems to say that \examples{} is a verbatim environment rather
> than merely verbatim-like. This statement comes 4 pages earlier in the
> pdf version than the paragraph you quote.

And the same is said for \usage.  Perhaps the part about being set
verbatim should be removed then.

Thanks
-k

From Simon.Urbanek at math.uni-augsburg.de  Mon May 26 14:25:13 2003
From: Simon.Urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Mon May 26 13:25:35 2003
Subject: [Rd] R's DYLD_LIBRARY_PATH override problems on Mac OS X
Message-ID: <B7DBEFC0-8F6C-11D7-88FC-000393CE9026@math.uni-augsburg.de>

In Mac OS X native version: The R shell wrapper (bin/R) overrides 
default library search path with DYLD_LIBRARY_PATH and adds (among 
others) /usr/X11R6/lib. This causes problems when modules need 
(directly or indirectly) libraries from Apple's frameworks which are 
masked by X11. Examples for such packages are SJava and RGL. SJava 
needs JavaVM which in turn loads OpenGL framework. RGL needs the OpenGL 
framework directly. The problem is that specifying /usr/X11R6/lib in 
DYLD_LIBRARY_PATH forces the libGL to be loaded from the X11 directory 
instead of the OpenGL framework library. This crashes R due to missing 
symbols, since the modules must link to the OpenGL framework. In fact 
the OpenGL framework libraries load the X11 libraries internally (but 
not vice versa) - that's why the default load path is frameworks first 
then X11.

Currently a workaround is to remove /usr/X11R6/lib in R from the 
environment variable prior to loading those packages, but more general 
solution would be better imho. Is the /usr/X11R6/lib really necessary 
in the DYLD_LIBRARY_PATH for some older OS X versions? At least for OS 
X 10.2 with Apple's X11 it is not necessary since X11 is already in the 
default load path.
Btw: the situation didn't crash R in OS X 10.1 (you could load libGL 
from X11 instead of the framework). To analyze the situation: by 
setting DYLD_PRINT_LIBRARIES=1 you can see exactly the sequence of 
loaded libraries and their locations.

  Cheers,
  Simon

	  _
  platform powerpc-apple-darwin6.6
  arch powerpc
  os darwin6.6
  system powerpc, darwin6.6
  status Patched
  major 1
  minor 7.0
  year 2003
  month 05
  day 15
  language R

---
Simon Urbanek
Department of computer oriented statistics and data analysis
University of Augsburg
Universit?tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2280

Simon.Urbanek@Math.Uni-Augsburg.de
http://simon.urbanek.info

From deleeuw at stat.ucla.edu  Mon May 26 08:41:10 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Mon May 26 16:41:24 2003
Subject: [Rd] R's DYLD_LIBRARY_PATH override problems on Mac OS X
In-Reply-To: <B7DBEFC0-8F6C-11D7-88FC-000393CE9026@math.uni-augsburg.de>
Message-ID: <17E1872C-8F88-11D7-B37C-000393BB6D36@stat.ucla.edu>

I don't think  there is a reason to set  DYLD_LIBRARY_PATH in bin/R.  
Not even fink sets this variable.

--- Jan

On Monday, May 26, 2003, at 04:25 US/Pacific, Simon Urbanek wrote:

> In Mac OS X native version: The R shell wrapper (bin/R) overrides  
> default library search path with DYLD_LIBRARY_PATH and adds (among  
> others) /usr/X11R6/lib. This causes problems when modules need  
> (directly or indirectly) libraries from Apple's frameworks which are  
> masked by X11. Examples for such packages are SJava and RGL. SJava  
> needs JavaVM which in turn loads OpenGL framework. RGL needs the  
> OpenGL framework directly. The problem is that specifying  
> /usr/X11R6/lib in DYLD_LIBRARY_PATH forces the libGL to be loaded from  
> the X11 directory instead of the OpenGL framework library. This  
> crashes R due to missing symbols, since the modules must link to the  
> OpenGL framework. In fact the OpenGL framework libraries load the X11  
> libraries internally (but not vice versa) - that's why the default  
> load path is frameworks first then X11.
>
> Currently a workaround is to remove /usr/X11R6/lib in R from the  
> environment variable prior to loading those packages, but more general  
> solution would be better imho. Is the /usr/X11R6/lib really necessary  
> in the DYLD_LIBRARY_PATH for some older OS X versions? At least for OS  
> X 10.2 with Apple's X11 it is not necessary since X11 is already in  
> the default load path.
> Btw: the situation didn't crash R in OS X 10.1 (you could load libGL  
> from X11 instead of the framework). To analyze the situation: by  
> setting DYLD_PRINT_LIBRARIES=1 you can see exactly the sequence of  
> loaded libraries and their locations.
>
>  Cheers,
>  Simon
>
> 	  _
>  platform powerpc-apple-darwin6.6
>  arch powerpc
>  os darwin6.6
>  system powerpc, darwin6.6
>  status Patched
>  major 1
>  minor 7.0
>  year 2003
>  month 05
>  day 15
>  language R
>
> ---
> Simon Urbanek
> Department of computer oriented statistics and data analysis
> University of Augsburg
> Universit?tsstr. 14
> 86135 Augsburg
> Germany
>
> Tel: +49-821-598-2236
> Fax: +49-821-598-2280
>
> Simon.Urbanek@Math.Uni-Augsburg.de
> http://simon.urbanek.info
>
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From jmc at research.bell-labs.com  Mon May 26 11:45:40 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Mon May 26 16:46:13 2003
Subject: Documenting classes and methods: was [Rd] Re: R-devel Digest,
	Vol 3, Issue 23
References: <5.2.0.9.1.20030524221045.00abf6c8@imaphost.wehi.edu.au>
Message-ID: <3ED22894.57F62EB7@research.bell-labs.com>

Gordon Smyth wrote:
> 
> I am another person who has had trouble documenting S4 classes and
> (particularly) methods. The methods package itself is pretty cool by the
> way, but it is a pity that there are as yet no guidelines on S4 in the
> "Writing R Extensions" document.
> 
> I have actually put together a guide on S4 documentation myself for the use
> of my own lab which is at http://bioinf.wehi.edu.au/limma/Rdocs.html. I
> don't pretend that the guide is perfect - I can already see problems with
> it - but it has proved adequate so far for our own use (writing the limma
> package) and has gained some more general acceptance from the Bioconductor
> community.
> 
> I found it hard to use the skeleton documentation provided by
> promptMethods. 

The "structure" of the skeletons (the \alias lines especially) are
intended to be used by the help system.  You're not meant to "use" these
directly, much of the time.  It's the case that the tools to work with
the .Rd structure haven't caught up yet, but please don't modify the
skeleton's structure arbitrarily.

> Suppose for example that I wish to document a method for
> generic function 'foo' with argument list (x,y,...) for x of class 'bar1'
> and y of class 'bar2':
> 
> 1. The skeleton .Rd file contains \alias{foo-methods}. If two or more more
> packages document methods for 'foo', they'll all have the same alias entry,
> and the help that a user will get by typing ?"foo-methods" will depend on
> which package happens to have been loaded most recently.

Good point, but related to the behavior of "?".  It's related to a
number of other issues about multiple packages referring to the same
generic function.  Not likely to change for 1.7.1, but likely to be
different in several ways in 1.8

> 
> 2. There seems to be no allowance for documenting extra named arguments for
> this method which are not specified in the generic. There is no usage
> entry, no argument list, and no process for R CMD check to check the
> argument list against the definition of the method. In S3 one can write
> \usage{\method{generic}{class}} and it would be nice to have an extension
> of this facility for S4 methods. I have been abandoning the skeleton
> structure produced by promptMethods and have been using \section{Usage} and
> \section{Arguments}.

Seems ok to have separate discussion of arguments, but don't "abandon"
the rest of the material in the skeleton (see below).

Heavy use of extra arguments in the methods is a little bit worrisome. 
There is an efficiency penalty, though not likely serious in sizable
computations.  More basic (this is just my personal view), I like to
think of the function as having a single conceptual definition--what it
does and (by and large) what arguments it takes to describe what it
should do.  Then the methods are the implementation.  The function
description is likely what users, begining users particularly, want to
see.  More advanced users and programmers may also be concerned with the
implementation.

So, most of the time, one would like the function to define the
arguments, and the methods to work from these.

In some examples of extra arguments (the S3 print() methods, for
instance), these are style-setting parameters, or perhaps control
parameters for numeric computations.  It might be clearer in such cases
to say that "..." is always passed to a (class-dependant)
parameter-setting function.  Documenting that function is then a
separate step.

Again, this is just by way of what may help users to understand the
functions and help designers to write functions cleanly; not suggesting
you should be forced to take this route.

> 
> 3. The aliases for methods are pretty verbose and make the html contents
> page for the package look rather cluttered. I have been deleting the
> \alias{foo-methods} alias and been replacing \alias{foo,bar1,bar2-method}
> with \alias{foo.bar1.bar2}. I know that using a syntactically valid name
> for the alias has the potential problem that a function could actually
> exist with that name, but I just like to use something shorter.

Don't do that.  It's not what you like that counts, it's what works with
the ? function, and your change will wipe out the ability of the help
functions to identify correctly which method is being documented.

For 1.8 (unfortunately, unlikely to be ironed out for 1.7.1), users
should be able to get documentation on the method, say, for function
f(x,y) corresponding to signature(x = "character", y = "numeric") by the
expression
  method ? f(x="character", y = "numeric")
(or something along these lines).

In any case, the \alias lines are crucial to going from any way of
requesting method documentation to the correct documentation.

> 
> 4. There don't seem to be any guidelines for documenting a method with the
> generic, if the generic happens to be defined in the same package, or with
> the object class, if the generic dispatches on only one argument. I know
> that you have thought about this, and in the document
> http://developer.r-project.org/moreClassMethodIssues.html you refer to the
> 'addTo' argument for 'promptMethods'. The 'addTo' argument however has not
> yet been implemented in R.
> 
> It would be nice to have a method for finding dynamically all available
> documentation for methods for a given generic function. I wrote a little
> prototype function called 'helpMethods' which simply extracts the list of
> available methods and prompts the user for which help topic they'd like to
> read. For this to work though, developers need to use a consistent alias
> system for documenting methods. I haven't seen any package yet which is
> using the aliases suggested by promptMethods.
> 
> Do you think there is any value in my S4 documentation guide? Are there
> errors or mis-understandings in it which should be corrected before it is
> adopted as a guideline by Bioconductor?

It's a useful document to have.  The whole area of documentation and
online help is being worked on by a number of people, so there is the
"moving target" difficulty.

You mention in your document altering the output of the promptMethods
skeleton.  Adding material, up to a point, is OK, but changing or
deleting the "\" lines is not a good idea if you want the documentation
to work with R's (evolving) help system.  As noted, the \alias lines
should be left alone.

There are a few other points we can discuss off-list, not directly
related to this thread.

> 
> Are there major changes planned for the documentation system for S4 methods
> and classes in R in the near future? Is it worth our while spending time
> working out guidelines now or should we wait a bit until the situation
> stabilizes?

Commented on above--yes changes are in prospect.  Bioconductor may want
to encourage documentation even before things settle down--really for
the people in the project to assess whether guidelines are helpful at
this point.

As said, there will be some changes for 1.8, mostly additions to the
code that processes the online help requests. It's a fairly good guess
that the structure of \ lines, esp. the \alias lines, will be kept or
extended, not radically changed, so keeping the current prompt output of
these lines would be desirable.  If there are changes in the structure,
you're more likely to see tools to modify what you have if you follow
the current prompt output.

In the longer run, it would be useful to have a documentation system
based on a more modern form (e.g., XML), making possible more powerful
online help software.  Duncan Temple Lang and others have done some good
work on such systems.  My crystal ball is very foggy on what will happen
with the R community in this direction.

Regards,
 John

> 
> Best wishes
> Gordon
> 
> >Date: Fri, 23 May 2003 15:37:50 -0400
> >From: John Chambers <jmc@research.bell-labs.com>
> >Subject: Re: [Rd] Documenting S4 classes; debugging them
> >To: Duncan Murdoch <dmurdoch@pair.com>
> >Cc: r-devel@stat.math.ethz.ch
> >
> >Duncan Murdoch wrote:
> > >
> > > 1.  I'm putting together my first package that uses S4 classes and
> > > objects.  I'd like to document them, but I'm not sure what the
> > > documentation should look like, and package.skeleton doesn't produce
> > > any at all for the classes or methods.
> >
> >Hmm, sounds as if it should.
> >
> >Meanwhile, promptClass and promptMethods generate skeleton
> >documentation.
> >
> > >
> > > Are there any good examples to follow?
> >
> >The bioconductor packages (e.g, Biobase) have some examples.
> 
> ...
> 
> >John
> >
> > >
> > > Duncan Murdoch
> > >
> > > ______________________________________________
> > > R-devel@stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> >
> >--
> >John M. Chambers                  jmc@bell-labs.com
> >Bell Labs, Lucent Technologies    office: (908)582-2681
> >700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
> >Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc
> 
> ---------------------------------------------------------------------------------------
> Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
> Walter and Eliza Hall Institute of Medical Research,
> 1G Royal Parade, Parkville, Vic 3050, Australia
> Tel: (03) 9345 2326, Fax (03) 9347 0852,
> Email: smyth@wehi.edu.au, www: http://www.statsci.org
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From b.rowlingson at lancaster.ac.uk  Mon May 26 19:48:11 2003
From: b.rowlingson at lancaster.ac.uk (b.rowlingson@lancaster.ac.uk)
Date: Mon May 26 18:48:24 2003
Subject: [Rd] internet.R test hangs if http proxy needed (PR#3108)
Message-ID: <200305261648.h4QGmB2b015467@pubhealth.ku.dk>

Full_Name: Barry Rowlingson
Version: 1.7.0
OS: RH8/Mandrake 9.1
Submission from: (NULL) (194.80.32.8)


internet.R in the tests directory hangs during 'make check' if an http proxy is
needed for http access from the machine. This happens in the httpget function
defined therein.

It tries to make a direct socket connection to port 80 of a remote machine, and
if local network policy does not permit that, then the test can hang. 

A fix? Perhaps skip that test if Sys.getenv("http_proxy") is defined. Or rewrite
httpget to use the proxy if defined.

Barry

From Simon.Urbanek at math.uni-augsburg.de  Mon May 26 21:37:30 2003
From: Simon.Urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Mon May 26 20:37:49 2003
Subject: [Rd] R's DYLD_LIBRARY_PATH override problems on Mac OS X
In-Reply-To: <17E1872C-8F88-11D7-B37C-000393BB6D36@stat.ucla.edu>
Message-ID: <1BB66614-8FA9-11D7-B7E9-000393CE9026@math.uni-augsburg.de>

On Monday, May 26, 2003, at 04:41  PM, Jan de Leeuw wrote:

> I don't think  there is a reason to set  DYLD_LIBRARY_PATH in bin/R. 
> Not even fink sets this variable.
Well, that's what I think as well .. so my question is, why is it there 
then?

My guess is that it's due to the fact that the script was written for 
all unix platforms, therefore it explicitly sets it since some unixes 
need it. It is in src/scripts/R.sh.in (this one is from today's 
R-devel):
## NOTE:
## We must set this here rather than in the main binary.
: ${R_LD_LIBRARY_PATH=${R_HOME}/bin:@R_LD_LIBRARY_PATH@}
if test -z "${@shlibpath_var@}"; then
   @shlibpath_var@="${R_LD_LIBRARY_PATH}"
else
   @shlibpath_var@="${R_LD_LIBRARY_PATH}:${@shlibpath_var@}"
fi
export @shlibpath_var@

... and in turn autoconf generates:
darwin* | rhapsody*)
[...]
shlibpath_var=DYLD_LIBRARY_PATH

So what's the most clean way to fix that? One more "if" or for Darwin 
in R.sh.in? Remove X11 from R_LD_LIBRARY_PATH for Darwin?

Simon
---
Simon Urbanek
Department of computer oriented statistics and data analysis
University of Augsburg
Universit?tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2200

Simon.Urbanek@Math.Uni-Augsburg.de
http://simon.urbanek.info

From ripley at stats.ox.ac.uk  Tue May 27 09:44:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue May 27 09:45:08 2003
Subject: [Rd] internet.R test hangs if http proxy needed (PR#3108)
In-Reply-To: <200305261648.h4QGmB2b015467@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305270832280.9066-100000@gannet.stats>

This is intended to be a test of the socket functions.  It should fail
within the time-out period, not hang.

On Mon, 26 May 2003 b.rowlingson@lancaster.ac.uk wrote:

> Full_Name: Barry Rowlingson
> Version: 1.7.0
> OS: RH8/Mandrake 9.1
> Submission from: (NULL) (194.80.32.8)
> 
> 
> internet.R in the tests directory hangs during 'make check' if an http proxy is
> needed for http access from the machine. This happens in the httpget function
> defined therein.
> 
> It tries to make a direct socket connection to port 80 of a remote machine, and
> if local network policy does not permit that, then the test can hang. 

Why does it hang?  Isn't that the bug that needs fixing?  Do the other
tests fail gracefully if no proxy is set?  (They all do the couple of
places I have tried them in very restricted setups.)

> A fix? Perhaps skip that test if Sys.getenv("http_proxy") is defined. Or rewrite
> httpget to use the proxy if defined.

There seem to be two possibilities:

a) make.socket is failing and hanging or

b) the local setup is listening on the port and not sending replies, or 
replies that cannot be parsed.

We need help, as to reproduce this needs some particular local setup and 
there have been no reports from anyone during the beta-test period for 
1.7.0, nor from previous versions.  (That makes me suspect it is rare 
local setup.)  Can you please debug this further.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From B.Rowlingson at lancaster.ac.uk  Tue May 27 14:23:26 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue May 27 14:23:43 2003
Subject: [Rd] internet.R test hangs if http proxy needed (PR#3108)
In-Reply-To: <Pine.LNX.4.44.0305270832280.9066-100000@gannet.stats>
References: <Pine.LNX.4.44.0305270832280.9066-100000@gannet.stats>
Message-ID: <3ED358BE.9070403@lancaster.ac.uk>

Prof Brian Ripley wrote:

> We need help, as to reproduce this needs some particular local setup and 
> there have been no reports from anyone during the beta-test period for 
> 1.7.0, nor from previous versions.  (That makes me suspect it is rare 
> local setup.)  Can you please debug this further.
> 

It appears to be partly a bug in my impatience:

> 
system.time(httpget("http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat"))
Error in make.socket(host, port = port) : Socket not established
Timing stopped at: 0 0 189 0 0

  The function times out after 189 seconds, whereas my impatience
timeout is 3 minutes. I will upgrade my impatience to the latest version
so that it is compatible with everyone elses.

  At first I thought it was taking 3 * options()$timeout to produce the
timeout in make.socket. A quick investigation shows that to be purely 
coincidental with the initial value of options()$timeout:

> options(timeout=2)
> 
system.time(httpget("http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat"))
making socket
Error in make.socket(host, port = port) : Socket not established
Timing stopped at: 0 0 189.04 0 0

  The 189 second timeout appears to be part of our particular local
setup (port 80 is blocked off-site).

options()$timeout seems to have no effect on connections that fail due
to  non-use of our proxies. Is this a bug? The doc claims:

timeout: integer.  The timeout for Internet operations, in seconds.
           Default 60 seconds.

which is a bit vague. If I do something like:
  read.table("http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat")
without setting my proxy I get 189 seconds, regardless of
options()$timeout yet it is undoubtedly an internet operation.

  Back to the original problem: the httpget function in tests/internet.R 
can be modified to obey an http_proxy setting with a fairly simple 
adjustment near the start:

   hp <- Sys.getenv("http_proxy")
   if(hp != ""){
## we need to extract host and port from the proxy:
## split on / or : thusly:
## [http]:[]/[]/[hostname]:[port]
##   1     2  3      4        5
     hpbits <- strsplit(hp,"[/:]")[[1]]
     host <- hpbits[4]
     port <- hpbits[5]
## ask the proxy for the full URL with all its http:// glory:
     rurl <- url
   }else{
## no proxy, connect direct and ask for the URL relative to root:
     host <- urlel[3]
     rurl <- paste(c("", urlel[-(1:3)]), collapse = "/")
   }


  I still have some qualms about tests that rely on things external to 
the test site, but without including a socket server program (which 
would need its own set of tests, I suppose) I cant see any way of 
testing socket functionality without dribbling on the internet at large.

Barry

From ripley at stats.ox.ac.uk  Tue May 27 14:32:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue May 27 14:33:47 2003
Subject: [Rd] internet.R test hangs if http proxy needed (PR#3108)
In-Reply-To: <3ED358BE.9070403@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.44.0305271326120.21068-100000@gannet.stats>

On Tue, 27 May 2003, Barry Rowlingson wrote:

> Prof Brian Ripley wrote:
> 
> > We need help, as to reproduce this needs some particular local setup and 
> > there have been no reports from anyone during the beta-test period for 
> > 1.7.0, nor from previous versions.  (That makes me suspect it is rare 
> > local setup.)  Can you please debug this further.
> > 
> 
> It appears to be partly a bug in my impatience:
> 
> > 
> system.time(httpget("http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat"))
> Error in make.socket(host, port = port) : Socket not established
> Timing stopped at: 0 0 189 0 0
> 
>   The function times out after 189 seconds, whereas my impatience
> timeout is 3 minutes. I will upgrade my impatience to the latest version
> so that it is compatible with everyone elses.
> 
>   At first I thought it was taking 3 * options()$timeout to produce the
> timeout in make.socket. A quick investigation shows that to be purely 
> coincidental with the initial value of options()$timeout:
> 
> > options(timeout=2)
> > 
> system.time(httpget("http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat"))
> making socket
> Error in make.socket(host, port = port) : Socket not established
> Timing stopped at: 0 0 189.04 0 0
> 
>   The 189 second timeout appears to be part of our particular local
> setup (port 80 is blocked off-site).
> 
> options()$timeout seems to have no effect on connections that fail due
> to  non-use of our proxies. Is this a bug? The doc claims:
> 
> timeout: integer.  The timeout for Internet operations, in seconds.
>            Default 60 seconds.
> 
> which is a bit vague. If I do something like:
>   read.table("http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat")
> without setting my proxy I get 189 seconds, regardless of
> options()$timeout yet it is undoubtedly an internet operation.

It is several internet operations.  However, ?download.file says

     The remaining details apply to method `"internal"' only.

     The timeout for many parts of the transfer can be set by the
     option `timeout' which defaults to 60 seconds.

and note, not all parts.

> 
>   Back to the original problem: the httpget function in tests/internet.R 
> can be modified to obey an http_proxy setting with a fairly simple 
> adjustment near the start:
> 
>    hp <- Sys.getenv("http_proxy")
>    if(hp != ""){
> ## we need to extract host and port from the proxy:
> ## split on / or : thusly:
> ## [http]:[]/[]/[hostname]:[port]
> ##   1     2  3      4        5
>      hpbits <- strsplit(hp,"[/:]")[[1]]
>      host <- hpbits[4]
>      port <- hpbits[5]
> ## ask the proxy for the full URL with all its http:// glory:
>      rurl <- url
>    }else{
> ## no proxy, connect direct and ask for the URL relative to root:
>      host <- urlel[3]
>      rurl <- paste(c("", urlel[-(1:3)]), collapse = "/")
>    }

Just how general is that?  It will not cope with authenticating proxies, 
for example.  I would rather skip the test.

>   I still have some qualms about tests that rely on things external to 
> the test site, but without including a socket server program (which 
> would need its own set of tests, I suppose) I cant see any way of 
> testing socket functionality without dribbling on the internet at large.

Well, R can itself be a socket server, but we cannot presume that
there are resources to run two copies of R, for example.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From roger at ysidro.econ.uiuc.edu  Tue May 27 11:22:51 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Tue May 27 17:17:26 2003
Subject: [Rd] setGeneric?
Message-ID: <Pine.SOL.4.30.0305271000490.14688-100000@ysidro.econ.uiuc.edu>

In the last few days I've received  couple of messages pointing out that our SparseM
package fails to install on the patched version of 1.7.0.  Laurent Gaultier kindly
suggested that replacing:

setGeneric("as.matrix.csr")

by

setGeneric("as.matrix.csr", function(x, nrow, ncol, eps) standardGeneric("as.matrix.csr"))

was sufficient to fix the problem.  Unfortunately, the story is a bit more complicated
than that.  After this substitution and some similar ones for a few other setGeneric()
calls, the package fails R CMD check in the examples --
from the end of SparseM.Rcheck-Ex/SparseM.Rout:

> image(as.matrix.csr(A)%*%as.matrix.csr(t(B)))
Error in str(eps) : Argument "eps" is missing, with no default
Execution halted

This is the beginning of the function as.matrix.csr.  The cat(str(eps)) is there just
for debugging purposes, but it is quite mysterious to me how eps can be considered
missing with no default.  I tried without success to construct a simpler example of
this phenomena.  I would, as always, be  very grateful for any suggestions.

"as.matrix.csr" <-
function(x, nrow = 1, ncol = 1, eps = .Machine$double.eps){
         cat(str(eps))
         if(is.matrix.csr(x)) {x; return(x)}
         if (!is.matrix(x)) {
			..........

Roger

PS.  While I'm at it I might as well inquire why the def argument of setGeneric is
now needed since my reading of the its documentation suggests that it isn't needed
in the present circumstances.



url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker@uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gordon St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

From jmc at research.bell-labs.com  Tue May 27 12:48:28 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue May 27 17:49:02 2003
Subject: [Rd] setGeneric?
References: <Pine.SOL.4.30.0305271000490.14688-100000@ysidro.econ.uiuc.edu>
Message-ID: <3ED388CC.76E94E2E@research.bell-labs.com>

Hmm.  Unfortunately (perhaps) it seems to work for me, with the current
R-patched and with the 0.27 version of SparseM from CRAN, I could
install and also run CMD check w/o error.

(This has the simpler version , setGeneric("as.matrix.csr"), which would
seem to me to be what you want.)

Could you try again, and send me the SparseM.Rcheck/SparseM-Ex.Rout*
files if it still fails?

Thanks,
 John

Roger Koenker wrote:
> 
> In the last few days I've received  couple of messages pointing out that our SparseM
> package fails to install on the patched version of 1.7.0.  Laurent Gaultier kindly
> suggested that replacing:
> 
> setGeneric("as.matrix.csr")
> 
> by
> 
> setGeneric("as.matrix.csr", function(x, nrow, ncol, eps) standardGeneric("as.matrix.csr"))
> 
> was sufficient to fix the problem.  Unfortunately, the story is a bit more complicated
> than that.  After this substitution and some similar ones for a few other setGeneric()
> calls, the package fails R CMD check in the examples --
> from the end of SparseM.Rcheck-Ex/SparseM.Rout:
> 
> > image(as.matrix.csr(A)%*%as.matrix.csr(t(B)))
> Error in str(eps) : Argument "eps" is missing, with no default
> Execution halted
> 
> This is the beginning of the function as.matrix.csr.  The cat(str(eps)) is there just
> for debugging purposes, but it is quite mysterious to me how eps can be considered
> missing with no default.  I tried without success to construct a simpler example of
> this phenomena.  I would, as always, be  very grateful for any suggestions.
> 
> "as.matrix.csr" <-
> function(x, nrow = 1, ncol = 1, eps = .Machine$double.eps){
>          cat(str(eps))
>          if(is.matrix.csr(x)) {x; return(x)}
>          if (!is.matrix(x)) {
>                         ..........
> 
> Roger
> 
> PS.  While I'm at it I might as well inquire why the def argument of setGeneric is
> now needed since my reading of the its documentation suggests that it isn't needed
> in the present circumstances.
> 
> url:    www.econ.uiuc.edu       Roger Koenker           Dept. of Economics UCL,
> email   rkoenker@uiuc.edu       Department of Economics Drayton House,
> vox:    217-333-4558            University of Illinois  30 Gordon St,
> fax:    217-244-6678            Champaign, IL 61820     London,WC1H 0AX, UK
>                                                         vox:    020-7679-5838
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From roger at ysidro.econ.uiuc.edu  Tue May 27 12:46:50 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Tue May 27 18:41:26 2003
Subject: [Rd] setGeneric?
In-Reply-To: <3ED388CC.76E94E2E@research.bell-labs.com>
Message-ID: <Pine.SOL.4.30.0305271135220.14688-100000@ysidro.econ.uiuc.edu>

John,

I updated to the current R-patched and now SparseM_0.27 seems to be fine.  The
reports I had received complained about:

> >  R CMD INSTALL SparseM_0.27.tar.gz -l /usr/local/r-cran/
> > dies with:
> > [1] "summary.slm"
> > Error in setGeneric("as.matrix.csr") : Must supply a function skeleton, explicitly or via
an existing function
> > Execution halted

but it looks fine with the original version of SparseM now...so either this was something
machine specific -- or something that only arose in some intermediate version of R-patched.

Thanks for looking at it,

Roger

url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker@uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gordon St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

On Tue, 27 May 2003, John Chambers wrote:

> Hmm.  Unfortunately (perhaps) it seems to work for me, with the current
> R-patched and with the 0.27 version of SparseM from CRAN, I could
> install and also run CMD check w/o error.
>
> (This has the simpler version , setGeneric("as.matrix.csr"), which would
> seem to me to be what you want.)
>
> Could you try again, and send me the SparseM.Rcheck/SparseM-Ex.Rout*
> files if it still fails?
>
> Thanks,
>  John
>
> Roger Koenker wrote:
> >
> > In the last few days I've received  couple of messages pointing out that our SparseM
> > package fails to install on the patched version of 1.7.0.  Laurent Gaultier kindly
> > suggested that replacing:
> >
> > setGeneric("as.matrix.csr")
> >
> > by
> >
> > setGeneric("as.matrix.csr", function(x, nrow, ncol, eps) standardGeneric("as.matrix.csr"))
> >
> > was sufficient to fix the problem.  Unfortunately, the story is a bit more complicated
> > than that.  After this substitution and some similar ones for a few other setGeneric()
> > calls, the package fails R CMD check in the examples --
> > from the end of SparseM.Rcheck-Ex/SparseM.Rout:
> >
> > > image(as.matrix.csr(A)%*%as.matrix.csr(t(B)))
> > Error in str(eps) : Argument "eps" is missing, with no default
> > Execution halted
> >
> > This is the beginning of the function as.matrix.csr.  The cat(str(eps)) is there just
> > for debugging purposes, but it is quite mysterious to me how eps can be considered
> > missing with no default.  I tried without success to construct a simpler example of
> > this phenomena.  I would, as always, be  very grateful for any suggestions.
> >
> > "as.matrix.csr" <-
> > function(x, nrow = 1, ncol = 1, eps = .Machine$double.eps){
> >          cat(str(eps))
> >          if(is.matrix.csr(x)) {x; return(x)}
> >          if (!is.matrix(x)) {
> >                         ..........
> >
> > Roger
> >
> > PS.  While I'm at it I might as well inquire why the def argument of setGeneric is
> > now needed since my reading of the its documentation suggests that it isn't needed
> > in the present circumstances.
> >
> > url:    www.econ.uiuc.edu       Roger Koenker           Dept. of Economics UCL,
> > email   rkoenker@uiuc.edu       Department of Economics Drayton House,
> > vox:    217-333-4558            University of Illinois  30 Gordon St,
> > fax:    217-244-6678            Champaign, IL 61820     London,WC1H 0AX, UK
> >                                                         vox:    020-7679-5838
> >
> > ______________________________________________
> > R-devel@stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
>
> --
> John M. Chambers                  jmc@bell-labs.com
> Bell Labs, Lucent Technologies    office: (908)582-2681
> 700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
> Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc
>

From jmc at research.bell-labs.com  Tue May 27 15:16:48 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue May 27 20:17:12 2003
Subject: [Rd] setGeneric?
References: <Pine.SOL.4.30.0305271135220.14688-100000@ysidro.econ.uiuc.edu>
Message-ID: <3ED3AB90.4C66384A@research.bell-labs.com>

Roger Koenker wrote:
> 
> John,
> 
> I updated to the current R-patched and now SparseM_0.27 seems to be fine.  The
> reports I had received complained about:
> 
> > >  R CMD INSTALL SparseM_0.27.tar.gz -l /usr/local/r-cran/
> > > dies with:
> > > [1] "summary.slm"
> > > Error in setGeneric("as.matrix.csr") : Must supply a function skeleton, explicitly or via
> an existing function
> > > Execution halted

This is the message one would get if there was no ordinary as.matrix.csr
function visible when the setGeneric call occurred.

In your source, you assign as.matrix.csr in R/SparseM.R, but if someone
contrived to run R/SparseM_Methods.R first, that's the error you would
see.

> 
> but it looks fine with the original version of SparseM now...so either this was something
> machine specific -- or something that only arose in some intermediate version of R-patched.

My guess would be neither of the above, rather the dependency on
ordering (and hence on the alphabetic names of the files in the
SparseM/R directory).  You can reproduce the error by 
  cd SparseM/R
  mv SparseM_Methods.R ASparseM_Methods.R

and then doing the INSTALL.

(Suggests that good practice would be to define an ordinary function
version of something just before turning it into a generic.)

John
John
> 
> Thanks for looking at it,
> 
> Roger
> 
> url:    www.econ.uiuc.edu       Roger Koenker           Dept. of Economics UCL,
> email   rkoenker@uiuc.edu       Department of Economics Drayton House,
> vox:    217-333-4558            University of Illinois  30 Gordon St,
> fax:    217-244-6678            Champaign, IL 61820     London,WC1H 0AX, UK
>                                                         vox:    020-7679-5838
> 
> On Tue, 27 May 2003, John Chambers wrote:
> 
> > Hmm.  Unfortunately (perhaps) it seems to work for me, with the current
> > R-patched and with the 0.27 version of SparseM from CRAN, I could
> > install and also run CMD check w/o error.
> >
> > (This has the simpler version , setGeneric("as.matrix.csr"), which would
> > seem to me to be what you want.)
> >
> > Could you try again, and send me the SparseM.Rcheck/SparseM-Ex.Rout*
> > files if it still fails?
> >
> > Thanks,
> >  John
> >
> > Roger Koenker wrote:
> > >
> > > In the last few days I've received  couple of messages pointing out that our SparseM
> > > package fails to install on the patched version of 1.7.0.  Laurent Gaultier kindly
> > > suggested that replacing:
> > >
> > > setGeneric("as.matrix.csr")
> > >
> > > by
> > >
> > > setGeneric("as.matrix.csr", function(x, nrow, ncol, eps) standardGeneric("as.matrix.csr"))
> > >
> > > was sufficient to fix the problem.  Unfortunately, the story is a bit more complicated
> > > than that.  After this substitution and some similar ones for a few other setGeneric()
> > > calls, the package fails R CMD check in the examples --
> > > from the end of SparseM.Rcheck-Ex/SparseM.Rout:
> > >
> > > > image(as.matrix.csr(A)%*%as.matrix.csr(t(B)))
> > > Error in str(eps) : Argument "eps" is missing, with no default
> > > Execution halted
> > >
> > > This is the beginning of the function as.matrix.csr.  The cat(str(eps)) is there just
> > > for debugging purposes, but it is quite mysterious to me how eps can be considered
> > > missing with no default.  I tried without success to construct a simpler example of
> > > this phenomena.  I would, as always, be  very grateful for any suggestions.
> > >
> > > "as.matrix.csr" <-
> > > function(x, nrow = 1, ncol = 1, eps = .Machine$double.eps){
> > >          cat(str(eps))
> > >          if(is.matrix.csr(x)) {x; return(x)}
> > >          if (!is.matrix(x)) {
> > >                         ..........
> > >
> > > Roger
> > >
> > > PS.  While I'm at it I might as well inquire why the def argument of setGeneric is
> > > now needed since my reading of the its documentation suggests that it isn't needed
> > > in the present circumstances.
> > >
> > > url:    www.econ.uiuc.edu       Roger Koenker           Dept. of Economics UCL,
> > > email   rkoenker@uiuc.edu       Department of Economics Drayton House,
> > > vox:    217-333-4558            University of Illinois  30 Gordon St,
> > > fax:    217-244-6678            Champaign, IL 61820     London,WC1H 0AX, UK
> > >                                                         vox:    020-7679-5838
> > >
> > > ______________________________________________
> > > R-devel@stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> >
> > --
> > John M. Chambers                  jmc@bell-labs.com
> > Bell Labs, Lucent Technologies    office: (908)582-2681
> > 700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
> > Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc
> >

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From hornik at ci.tuwien.ac.at  Wed May 28 12:18:12 2003
From: hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Wed May 28 11:26:20 2003
Subject: [Rd] R's DYLD_LIBRARY_PATH override problems on Mac OS X
In-Reply-To: <1BB66614-8FA9-11D7-B7E9-000393CE9026@math.uni-augsburg.de>
References: <17E1872C-8F88-11D7-B37C-000393BB6D36@stat.ucla.edu>
	<1BB66614-8FA9-11D7-B7E9-000393CE9026@math.uni-augsburg.de>
Message-ID: <16084.32468.665397.915680@mithrandir.hornik.net>

>>>>> Simon Urbanek writes:

> On Monday, May 26, 2003, at 04:41  PM, Jan de Leeuw wrote:
>> I don't think  there is a reason to set  DYLD_LIBRARY_PATH in bin/R. 
>> Not even fink sets this variable.
> Well, that's what I think as well .. so my question is, why is it there 
> then?

> My guess is that it's due to the fact that the script was written for 
> all unix platforms, therefore it explicitly sets it since some unixes 
> need it. It is in src/scripts/R.sh.in (this one is from today's 
> R-devel):
> ## NOTE:
> ## We must set this here rather than in the main binary.
> : ${R_LD_LIBRARY_PATH=${R_HOME}/bin:@R_LD_LIBRARY_PATH@}
> if test -z "${@shlibpath_var@}"; then
>    @shlibpath_var@="${R_LD_LIBRARY_PATH}"
> else
>    @shlibpath_var@="${R_LD_LIBRARY_PATH}:${@shlibpath_var@}"
> fi
> export @shlibpath_var@

> ... and in turn autoconf generates:
> darwin* | rhapsody*)
> [...]
> shlibpath_var=DYLD_LIBRARY_PATH

> So what's the most clean way to fix that? One more "if" or for Darwin 
> in R.sh.in? Remove X11 from R_LD_LIBRARY_PATH for Darwin?

The configure code currently has

for arg in ${LDFLAGS} ${FLIBS} ${BLAS_LIBS} ${LAPACK_LIBS} ${X_LIBS} \
           ${TCLTK_LIBS} ${GNOME_LIBS}; do
  case "${arg}" in
    -L*)
      lib=`echo ${arg} | sed "s/^-L//"`
      R_SH_VAR_ADD(R_LD_LIBRARY_PATH, [${lib}], [${PATH_SEPARATOR}])
      ;;
  esac
done

which follows that the idea that any -L flag in the above that was
either given explicitly or determined by configure should be added to
the run time path.  It is one of the autoconf macros which knows about
typical locations of X11 and adds the -L X11 stuff by default.

My preference would be to leave this mechanism untouched but maybe add
to LDFLAGS on platforms where this is necessary.  We already have

## LDFLAGS.
if test -f "/sw/etc/fink.conf"; then
  : ${CPPFLAGS="-I/sw/include -I/usr/local/include"}
  : ${LDFLAGS="-L/sw/lib -L/usr/local/lib"}
else
  : ${CPPFLAGS="-I/usr/local/include"}
  : ${LDFLAGS="-L/usr/local/lib"}
fi

and could add something which adds the frameworks that should come first
in the run time path.

Best
-k

From jerome at hivnet.ubc.ca  Wed May 28 19:49:58 2003
From: jerome at hivnet.ubc.ca (jerome@hivnet.ubc.ca)
Date: Wed May 28 18:50:21 2003
Subject: [Rd] "trace" argument in legend() (PR#2578)
Message-ID: <200305281649.h4SGnw2b008510@pubhealth.ku.dk>


Another easy fix for legend() with trace=TRUE would be to
replace "...)" by ", ...)" in this code:
[...]
        if (trace)
            catn("  rect2(", left, ",", top, ", w=", w, ", h=",
                h, "...)", sep = "")
[...]

Cheers,
Jerome

From mpvenkatesh at lycos.com  Wed May 28 14:10:19 2003
From: mpvenkatesh at lycos.com (Venkatesh)
Date: Wed May 28 22:10:44 2003
Subject: [Rd] R Enhancements
Message-ID: <MOIEEJGEDDPOIDAA@mailcity.com>

Hi, 

We - Venkatesh Mysore and Salvatore Paxia of the New York University's Bioinformatics Group under Prof.Bud Mishra - have been working on enhancements to R for a while now. 

We're happy to announce that we have some good stuff up and running now:

1. A debuggable Microsoft Visual C version ( _MSC_VER) of R-1.7.0: R-1.7.0-msc (YES !!!!)

2. COM/OLE-support that will allow invoking of functions defined elsewhere (similar to the .ole functionality in S+): R-1.7.0-msc-com

3. Minor Fixes/Extensions: R-1.7.0-msc-com-minor

Note that these extensions are NOT dependent on each other. More documentation and downloadable material is avilable at:

http://www.bioinformatics.nyu.edu/~mpvenkat/R-1.7.0/index.htm



Please let me know how I can submit the material to you more 'formally'.


Thanks.
Venkatesh Mysore

PS: I will be in town for only two more days, so I will apreciate it if you could look into this as soon as you can ! Thanks again.

--------------------------
Home:
144 Kensington Avenue #2,
Jersey City,
NJ 07304
Ph: 201 536 1314

Office:
715 Broadway #1014,
New York, 
NY 10003
Ph: 212 998 3373

From dmurdoch at pair.com  Wed May 28 17:33:36 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed May 28 22:34:04 2003
Subject: [Rd] R Enhancements
In-Reply-To: <MOIEEJGEDDPOIDAA@mailcity.com>
References: <MOIEEJGEDDPOIDAA@mailcity.com>
Message-ID: <db6adv8knp6dk8ue8op5slh3t6h8cobvei@4ax.com>

On Wed, 28 May 2003 13:10:19 -0700, you wrote:

>Hi, 
>
>We - Venkatesh Mysore and Salvatore Paxia of the New York University's Bioinformatics Group under Prof.Bud Mishra - have been working on enhancements to R for a while now. 
>
>We're happy to announce that we have some good stuff up and running now:
>
>1. A debuggable Microsoft Visual C version ( _MSC_VER) of R-1.7.0: R-1.7.0-msc (YES !!!!)

How many changes were necessary to do this?  Was it mostly a matter of
working out instructions to get MSVC to work, or did you need a lot of
changes to the R source code?  Does your version pass make check?

I don't use that compiler, so I can't test any of your changes.  I'm
not interested in maintaining multiple compiler targets, but if it's
easy, I'd consider it (or at least try to avoid doing things that will
make it hard for you to do it).

>2. COM/OLE-support that will allow invoking of functions defined elsewhere (similar to the .ole functionality in S+): R-1.7.0-msc-com

That should be put together as a package.  

>3. Minor Fixes/Extensions: R-1.7.0-msc-com-minor

In your minor extension I, could you submit a bug report showing how
to invoke the bug, and how to fix it?  There's still time to get this
into 1.7.1.

Could you write up a description of why the changes in II and III are
a good idea?  I'll put them into 1.8.0 if they make sense.

Re the suggestion for a global "dont_exit" flag:  My first answer is
that global flags are bad, we have way too many of them now.  What we
need are bigger changes that make all of our global flags unnecessary.

Duncan Murdoch

From John.Marsland at CommerzbankIB.com  Thu May 29 09:43:25 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Thu May 29 09:43:44 2003
Subject: [Rd] R Enhancements
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E786@xmx8lonib.lonib.commerzbank.com>

COM support is already available with the innovative RDCOMClient and
RDCOMServer packages from Omegahat. I have been corresponding with the
author of these packages, Duncan Temple Lang, and have been able to use them
in 'anger'. We have found the packages very stable and have successfully
connected some quite strange ActiveX components to R.

Regards,

John Marsland

> -----Original Message-----
> From: Duncan Murdoch [mailto:dmurdoch@pair.com]
> Sent: 28 May 2003 21:34
> To: mpvenkatesh@lycos.com
> Cc: r-devel@stat.math.ethz.ch
> Subject: Re: [Rd] R Enhancements
> 
> 
> On Wed, 28 May 2003 13:10:19 -0700, you wrote:
> 
> >Hi, 
> >
> >We - Venkatesh Mysore and Salvatore Paxia of the New York 
> University's Bioinformatics Group under Prof.Bud Mishra - 
> have been working on enhancements to R for a while now. 
> >
> >We're happy to announce that we have some good stuff up and 
> running now:
> >
> >1. A debuggable Microsoft Visual C version ( _MSC_VER) of 
> R-1.7.0: R-1.7.0-msc (YES !!!!)
> 
> How many changes were necessary to do this?  Was it mostly a matter of
> working out instructions to get MSVC to work, or did you need a lot of
> changes to the R source code?  Does your version pass make check?
> 
> I don't use that compiler, so I can't test any of your changes.  I'm
> not interested in maintaining multiple compiler targets, but if it's
> easy, I'd consider it (or at least try to avoid doing things that will
> make it hard for you to do it).
> 
> >2. COM/OLE-support that will allow invoking of functions 
> defined elsewhere (similar to the .ole functionality in S+): 
> R-1.7.0-msc-com
> 
> That should be put together as a package.  
> 
> >3. Minor Fixes/Extensions: R-1.7.0-msc-com-minor
> 
> In your minor extension I, could you submit a bug report showing how
> to invoke the bug, and how to fix it?  There's still time to get this
> into 1.7.1.
> 
> Could you write up a description of why the changes in II and III are
> a good idea?  I'll put them into 1.8.0 if they make sense.
> 
> Re the suggestion for a global "dont_exit" flag:  My first answer is
> that global flags are bad, we have way too many of them now.  What we
> need are bigger changes that make all of our global flags unnecessary.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ This ... {{dropped}}

From p.dalgaard at biostat.ku.dk  Fri May 30 02:39:23 2003
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Fri May 30 01:39:41 2003
Subject: [Rd] Re: [R] Postscript query: plotting long vectors (PR#3132)
Message-ID: <200305292339.h4TNdN2b015668@pubhealth.ku.dk>

Don MacQueen <macq@llnl.gov> writes:

> When I run the example in R 1.6.2, and view it with gs, I get a good plot.
> When I run the example in R 1.7.0, and view it with gs, I get a bad plot.
> (run on the same host)
> 
> My "bad plot" is as described by Stephen.
...
> (followed by ~200000 lines of the same type, with slowly changing values)
> 
> In the "bad" postscript file, at about the same point in the file, is this:
> %%EndProlog
> %%Page: 1 1
> bp
> 77.04 91.44 743.76 534.96 cl
> 0 0 0 rgb
> 0.75 setlinewidth
> [] 0 setdash
> np
> 101.73 313.20 m
> 0.00 0.01 l
> 0.00 0.01 l
> 0.00 0.01 l
> 0.00 0.01 l
> 0.00 0.01 l
> (followed by ~200000 lines, including some like these)

Confirmed on RedHat Linux 8.0. Filing as bug report. (An old
version of Splus had a similar bug: If you want to use rlineto, you
need to round *before* differencing.)  

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From dmurdoch at pair.com  Thu May 29 23:03:53 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri May 30 04:04:09 2003
Subject: [Rd] Creating a vector class
Message-ID: <creddv80t0693ebb5b3qdt847jvr4r95p5@4ax.com>

I'm trying to create a package for working on orientation data, i.e.
data where the observations are 3D rotations.

There are several different representations of orientations in common
use:  SO(3) matrices, Euler angles, unit quaternions, etc.  One thing
I'd like is to make it convenient to work in any representation, and
have conversions to others done as needed.

I'm trying to do all of this in S4 classes.  Here's the current class
structure I'm using; please let me know if there's something wrong
with this:

The base class is abstract.  All representations will deal with
vectors of orientations, but at this level I don't know how that will
be implemented:

setClass('orientation')		
setIs('orientation', 'vector')

First questions:  is this the way to say that orientations behave as
vectors?  Do I need to say that?  Should I say that?

One representation is as an SO(3) matrix (i.e. a 3x3 matrix with
determinant 1).  I have a descendant class that stores these in a 
3 x 3 x n array:

setClass('rotmatrix', representation(x = 'array'))
setIs('rotmatrix','orientation')

rotmatrix <- function(a) {
    d <- dim(a)
    if (length(d) < 3) d <- c(d,1)
    a <- array(a, d)
    stopifnot(dim(a)[1] == 3, dim(a)[2] == 3)
    new('rotmatrix', x = a)
}

Other representations have other storage methods, e.g.

setClass('quaternion', representation(x = 'matrix'))
setIs('quaternion', 'orientation')

Now I want to make sure these work as vectors.  I don't need to define
a '[' method for the abstract base class, do I?  I originally set this
definition for the rotmatrix class:

setMethod('[', 'rotmatrix',
    def = function(x, i) rotmatrix(x@x[,,i,drop=FALSE])
)

However, this gives warnings:

>In method for function "[": Expanding the signature to 
>include omitted arguments in definition: j = "missing", 
>drop = "missing" 

I notice in the setMethod example the right way to do it:

setMethod('[', 'rotmatrix',
    function(x, i, j, ..., drop) rotmatrix(x@x[,,i,drop=FALSE])
)

But where are the meanings for j and drop defined?  Even if I don't
declare orientation to be a vector, I get this warning, so where is it
coming from?  Is it good or bad to say that orientation is a vector?
What implications does it have?

Duncan Murdoch

From p.dalgaard at biostat.ku.dk  Fri May 30 13:48:03 2003
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Fri May 30 12:48:15 2003
Subject: [Rd] Re: [R] Postscript query: plotting long vectors (PR#3132)
Message-ID: <200305301048.h4UAm32b019101@pubhealth.ku.dk>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> Except that there is nothing reproducible in that report, not even the 
> claimed (by Don MacQueen) incorrect lines!

Er, right, sorry. Here's a version of the effect, for inclusiont with
the report:

postscript()
x <- seq(0,2*pi,,50000)
plot(x,sin(x),type="l")
dev.off()

Count reduced from the original 200000 to show quantization effect.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard@biostat.ku.dk)             FAX: (+45) 35327907

From ripley at stats.ox.ac.uk  Fri May 30 13:45:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May 30 13:46:13 2003
Subject: [Rd] Re: [R] Postscript query: plotting long vectors (PR#3132)
In-Reply-To: <200305301048.h4UAm32b019101@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305301241250.1144-100000@gannet.stats>

That isn't actually the same effect, but both examples (with 50000 and 
200000) work in R-patched now.

On Fri, 30 May 2003 p.dalgaard@biostat.ku.dk wrote:

> Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:
> 
> > Except that there is nothing reproducible in that report, not even the 
> > claimed (by Don MacQueen) incorrect lines!

(there seemed no problem with them).

> Er, right, sorry. Here's a version of the effect, for inclusiont with
> the report:
> 
> postscript()
> x <- seq(0,2*pi,,50000)
> plot(x,sin(x),type="l")
> dev.off()
> 
> Count reduced from the original 200000 to show quantization effect.


-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jmc at research.bell-labs.com  Fri May 30 10:14:42 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Fri May 30 15:15:18 2003
Subject: [Rd] Creating a vector class
References: <creddv80t0693ebb5b3qdt847jvr4r95p5@4ax.com>
Message-ID: <3ED75942.D218FA87@research.bell-labs.com>

Sounds like a nice example.  Just a quick comment on one question before
I have to run, will try to react more later.

John

Duncan Murdoch wrote:
> 
> I'm trying to create a package for working on orientation data, i.e.
> data where the observations are 3D rotations.
> 
> There are several different representations of orientations in common
> use:  SO(3) matrices, Euler angles, unit quaternions, etc.  One thing
> I'd like is to make it convenient to work in any representation, and
> have conversions to others done as needed.
> 
> I'm trying to do all of this in S4 classes.  Here's the current class
> structure I'm using; please let me know if there's something wrong
> with this:
> 
> The base class is abstract.  All representations will deal with
> vectors of orientations, but at this level I don't know how that will
> be implemented:
> 
> setClass('orientation')
> setIs('orientation', 'vector')
> 
> First questions:  is this the way to say that orientations behave as
> vectors?  Do I need to say that?  Should I say that?
> 
> One representation is as an SO(3) matrix (i.e. a 3x3 matrix with
> determinant 1).  I have a descendant class that stores these in a
> 3 x 3 x n array:
> 
> setClass('rotmatrix', representation(x = 'array'))
> setIs('rotmatrix','orientation')
> 
> rotmatrix <- function(a) {
>     d <- dim(a)
>     if (length(d) < 3) d <- c(d,1)
>     a <- array(a, d)
>     stopifnot(dim(a)[1] == 3, dim(a)[2] == 3)
>     new('rotmatrix', x = a)
> }
> 
> Other representations have other storage methods, e.g.
> 
> setClass('quaternion', representation(x = 'matrix'))
> setIs('quaternion', 'orientation')
> 
> Now I want to make sure these work as vectors.  I don't need to define
> a '[' method for the abstract base class, do I?  I originally set this
> definition for the rotmatrix class:
> 
> setMethod('[', 'rotmatrix',
>     def = function(x, i) rotmatrix(x@x[,,i,drop=FALSE])
> )
> 
> However, this gives warnings:
> 
> >In method for function "[": Expanding the signature to
> >include omitted arguments in definition: j = "missing",
> >drop = "missing"
> 
> I notice in the setMethod example the right way to do it:
> 
> setMethod('[', 'rotmatrix',
>     function(x, i, j, ..., drop) rotmatrix(x@x[,,i,drop=FALSE])
> )
> 
> But where are the meanings for j and drop defined?  Even if I don't
> declare orientation to be a vector, I get this warning, so where is it
> coming from?  Is it good or bad to say that orientation is a vector?
> What implications does it have?

Actually, even though the message was a "warning", it really says what I
think you want to do.

The arguments j and drop arise in matrix or matrix-like objects
(data.frame) and are in the generic so that methods can be dispatched
(e.g.) on the column index argument.

But in your case, indeed they had BETTER be missing, assuming they're
meaningless in this example.

So you could just accept the warning as a harmless nag (and maybe it
should be a message rather than a warning in this case, but in other
functions the omission might in fact have been a mistake).

Or to be fastidious, you could supply the arguments with class "missing"
in the signature to make explicit that the user had better not try to
supply them.

 setMethod('[', signature(x='rotmatrix', j= 'missing', drop =
'missing'),
     def = function(x, i) rotmatrix(x@x[,,i,drop=FALSE])
 )

> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel

-- 
John M. Chambers                  jmc@bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc

From rossini at blindglobe.net  Fri May 30 18:50:10 2003
From: rossini at blindglobe.net (rossini@blindglobe.net)
Date: Fri May 30 17:50:21 2003
Subject: [Rd] power.t.test needs to check delta==NULL before abs(delta)
	(PR#3139)
Message-ID: <200305301550.h4UFoA2b021132@pubhealth.ku.dk>


Something like the following should be done for power.t.test to make
sure that it doesn't try to evaluate abs(NULL), which results in an
error.

--- rossini.power.t.test.R      2003-05-30 07:24:49.000000000 -0700
+++ rossini.power.t.test.R.~1~  2003-05-30 08:47:09.000000000 -0700
@@ -10,7 +10,7 @@
   alternative <- match.arg(alternative)
   tsample <- switch(type, one.sample = 1, two.sample = 2, paired = 1)
   tside <- switch(alternative, one.sided = 1, two.sided = 2)
-  if (tside == 2 && !is.null(delta))
+  if (tside == 2)
     delta <- abs(delta)
   p.body <- quote({
     nu <- (n - 1) * tsample


--please do not edit the information below--

Version:
 platform = powerpc-unknown-linux-gnu
 arch = powerpc
 os = linux-gnu
 system = powerpc, linux-gnu
 status = Patched
 major = 1
 minor = 7.0
 year = 2003
 month = 05
 day = 25
 language = R

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base

From ripley at stats.ox.ac.uk  Fri May 30 18:05:11 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May 30 18:05:43 2003
Subject: [Rd] power.t.test needs to check delta==NULL before abs(delta)
	(PR#3139)
In-Reply-To: <200305301550.h4UFoA2b021132@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.44.0305301701470.8311-100000@gannet.stats>

It's the same as PR#2993, fixed yesterday in R-patched & R-devel

On Fri, 30 May 2003 rossini@blindglobe.net wrote:

> 
> Something like the following should be done for power.t.test to make
> sure that it doesn't try to evaluate abs(NULL), which results in an
> error.

That's a backwards patch, I presume, or you revert the fix.

> --- rossini.power.t.test.R      2003-05-30 07:24:49.000000000 -0700
> +++ rossini.power.t.test.R.~1~  2003-05-30 08:47:09.000000000 -0700
> @@ -10,7 +10,7 @@
>    alternative <- match.arg(alternative)
>    tsample <- switch(type, one.sample = 1, two.sample = 2, paired = 1)
>    tside <- switch(alternative, one.sided = 1, two.sided = 2)
> -  if (tside == 2 && !is.null(delta))
> +  if (tside == 2)
>      delta <- abs(delta)
>    p.body <- quote({
>      nu <- (n - 1) * tsample
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = powerpc-unknown-linux-gnu
>  arch = powerpc
>  os = linux-gnu
>  system = powerpc, linux-gnu
>  status = Patched
>  major = 1
>  minor = 7.0
>  year = 2003
>  month = 05
>  day = 25
>  language = R
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri May 30 19:05:13 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri May 30 18:06:15 2003
Subject: [Rd] power.t.test needs to check delta==NULL before abs(delta)
	(PR#3140)
Message-ID: <200305301605.h4UG5D2b021203@pubhealth.ku.dk>

It's the same as PR#2993, fixed yesterday in R-patched & R-devel

On Fri, 30 May 2003 rossini@blindglobe.net wrote:

> 
> Something like the following should be done for power.t.test to make
> sure that it doesn't try to evaluate abs(NULL), which results in an
> error.

That's a backwards patch, I presume, or you revert the fix.

> --- rossini.power.t.test.R      2003-05-30 07:24:49.000000000 -0700
> +++ rossini.power.t.test.R.~1~  2003-05-30 08:47:09.000000000 -0700
> @@ -10,7 +10,7 @@
>    alternative <- match.arg(alternative)
>    tsample <- switch(type, one.sample = 1, two.sample = 2, paired = 1)
>    tside <- switch(alternative, one.sided = 1, two.sided = 2)
> -  if (tside == 2 && !is.null(delta))
> +  if (tside == 2)
>      delta <- abs(delta)
>    p.body <- quote({
>      nu <- (n - 1) * tsample
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = powerpc-unknown-linux-gnu
>  arch = powerpc
>  os = linux-gnu
>  system = powerpc, linux-gnu
>  status = Patched
>  major = 1
>  minor = 7.0
>  year = 2003
>  month = 05
>  day = 25
>  language = R
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg, package:nls, package:ts, Autoloads, package:base
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rossini at blindglobe.net  Fri May 30 10:10:22 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri May 30 18:13:03 2003
Subject: [Rd] power.t.test needs to check delta==NULL before abs(delta)
	(PR#3139)
In-Reply-To: <Pine.LNX.4.44.0305301701470.8311-100000@gannet.stats> (Brian
	Ripley's message of "Fri, 30 May 2003 17:05:11 +0100 (BST)")
References: <Pine.LNX.4.44.0305301701470.8311-100000@gannet.stats>
Message-ID: <873ciwct5d.fsf@jeeves.blindglobe.net>

Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:

> It's the same as PR#2993, fixed yesterday in R-patched & R-devel

I don't have a record of that bug report being sent to r-devel mailing
list.  Is there a way to recieve bug reports other than firing up a
browser? 

best,
-tony

-- 
A.J. Rossini  /  rossini@u.washington.edu  /  rossini@scharp.org
Biomedical/Health Informatics and Biostatistics, University of Washington.
Biostatistics, HVTN/SCHARP, Fred Hutchinson Cancer Research Center.
FHCRC: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}

From ripley at stats.ox.ac.uk  Fri May 30 18:15:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri May 30 18:15:53 2003
Subject: [Rd] power.t.test needs to check delta==NULL before abs(delta)
	(PR#3139)
In-Reply-To: <873ciwct5d.fsf@jeeves.blindglobe.net>
Message-ID: <Pine.LNX.4.44.0305301713251.8311-100000@gannet.stats>

On Fri, 30 May 2003, A.J. Rossini wrote:

> Prof Brian Ripley <ripley@stats.ox.ac.uk> writes:
> 
> > It's the same as PR#2993, fixed yesterday in R-patched & R-devel
> 
> I don't have a record of that bug report being sent to r-devel mailing
> list.  Is there a way to recieve bug reports other than firing up a
> browser? 

Peter automatically sends a weekly list to R-devel.  They should all be
copied to R-devel, but some do fail to get through.

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From deleeuw at stat.ucla.edu  Fri May 30 22:34:37 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sat May 31 06:34:51 2003
Subject: [Rd] g77-3.3 on darwin
Message-ID: <2FE85382-9321-11D7-BB8A-000393BB6D36@stat.ucla.edu>

The new g77 in fink/unstable is 3.3. It fails to build R, unless
I setenv LDFLAGS to -lcc_dynamic.

I now also

setenv MACOSX_DEPLOYMENT_TARGET 10.2

which uses the various dylibs as weak libraries.
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw@stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au

From fharrell at virginia.edu  Sat May 31 08:26:26 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat May 31 15:59:00 2003
Subject: [Rd] acepack
Message-ID: <20030531072626.005822dc.fharrell@virginia.edu>

Many moons ago I reported to r-bugs some easy to fix errors in ace and avas.  I wonder if someone would mind making those corrections.

Thanks very much,

Frank
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat

From spencer.graves at pdf.com  Sat May 31 11:05:45 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat May 31 19:06:04 2003
Subject: [Rd] fac.design & mean.default(..., weights)
Message-ID: <3ED8E0E9.1090205@pdf.com>

Dear R-Developers:

	  I had a need for a weighted mean, so I added a "weights" argument to 
"mean.default", similar to the "weights" argument in "lm".  The 
resulting code is copied below, in case any of you might find this an 
interesting and useful option to include in a future release.

	  Is this something you like to hear about, or is this email a waste of 
your time and mine?

	  Thanks for your valuable work on the R project.

Best Wishes,
Spencer Graves
####################################
mean.default <-
function (x, trim = 0, na.rm = FALSE,
	weights=NULL, ...)
{
#	mean.default with a "weights" argument
     if (!is.numeric(x) && !is.complex(x) && !is.logical(x)) {
         warning("argument is not numeric or logical: returning NA")
         return(as.numeric(NA))
     }
	 if(is.null(weights)) weights <- rep(1, length(x))
     if (na.rm) {
	     rm.na <- !(is.na(x)|is.na(weights))
	     weights <- weights[rm.na]
         x <- x[rm.na]
  	 }
     trim <- trim[1]
     n <- length(c(x, recursive = TRUE))
     if (trim > 0 && n > 0) {
         if (is.complex(x))
             stop("trimmed means are not defined for complex data")
         if (trim >= 0.5)
             return(median(x, na.rm = FALSE))
         lo <- floor(n * trim) + 1
         hi <- n + 1 - lo
#       x <- sort(x, partial = unique(c(lo, hi)))[lo:hi]
		  iord <- order(x)
		  x <- x[iord][lo:hi]
		  weights <- weights[iord][lo:hi]
         n <- hi - lo + 1
     }
     if (is.integer(x))
         sum(weights*as.numeric(x))/sum(weights)
     else sum(weights*x)/sum(weights)
}

From ripley at stats.ox.ac.uk  Sat May 31 19:20:34 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat May 31 19:20:48 2003
Subject: [Rd] fac.design & mean.default(..., weights)
In-Reply-To: <3ED8E0E9.1090205@pdf.com>
Message-ID: <Pine.LNX.4.44.0305311818110.11154-100000@gannet.stats>

See ?weighted.mean

On Sat, 31 May 2003, Spencer Graves wrote:

> Dear R-Developers:
> 
> 	  I had a need for a weighted mean, so I added a "weights" argument to 
> "mean.default", similar to the "weights" argument in "lm".  The 
> resulting code is copied below, in case any of you might find this an 
> interesting and useful option to include in a future release.
> 
> 	  Is this something you like to hear about, or is this email a waste of 
> your time and mine?

Looks like the latter.

BTW, please use sort.list instead of order when the first is appropriate, 
as it is more efficient (slightly).


> 	  Thanks for your valuable work on the R project.
> 
> Best Wishes,
> Spencer Graves
> ####################################
> mean.default <-
> function (x, trim = 0, na.rm = FALSE,
> 	weights=NULL, ...)
> {
> #	mean.default with a "weights" argument
>      if (!is.numeric(x) && !is.complex(x) && !is.logical(x)) {
>          warning("argument is not numeric or logical: returning NA")
>          return(as.numeric(NA))
>      }
> 	 if(is.null(weights)) weights <- rep(1, length(x))
>      if (na.rm) {
> 	     rm.na <- !(is.na(x)|is.na(weights))
> 	     weights <- weights[rm.na]
>          x <- x[rm.na]
>   	 }
>      trim <- trim[1]
>      n <- length(c(x, recursive = TRUE))
>      if (trim > 0 && n > 0) {
>          if (is.complex(x))
>              stop("trimmed means are not defined for complex data")
>          if (trim >= 0.5)
>              return(median(x, na.rm = FALSE))
>          lo <- floor(n * trim) + 1
>          hi <- n + 1 - lo
> #       x <- sort(x, partial = unique(c(lo, hi)))[lo:hi]
> 		  iord <- order(x)
> 		  x <- x[iord][lo:hi]
> 		  weights <- weights[iord][lo:hi]
>          n <- hi - lo + 1
>      }
>      if (is.integer(x))
>          sum(weights*as.numeric(x))/sum(weights)
>      else sum(weights*x)/sum(weights)
> }
> 
> ______________________________________________
> R-devel@stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Brian D. Ripley,                  ripley@stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

