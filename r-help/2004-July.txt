From petertgaffney at yahoo.com  Thu Jul  1 01:32:59 2004
From: petertgaffney at yahoo.com (Peter Gaffney)
Date: Wed, 30 Jun 2004 16:32:59 -0700 (PDT)
Subject: [R] linear models and colinear variables...
Message-ID: <20040630233259.95850.qmail@web60005.mail.yahoo.com>

Hi!

I'm having some issues on both conceptual and
technical levels for selecting the right combination
of variables for this model I'm working on. The basic,
all inclusive form looks like

lm(mic ~ B * D * S * U * V * ICU)

Where mic, U, V, and ICU are numeric values and B D
and S are factors with about 16, 16 and 2 levels
respectively. In short, there's a ton of actual
explanatory variables that look something like this:

Bstaph.aureus:Dvan:Sr:U:ICU

There are a good number of hits but there's also a
staggering number of complete misses, due to a
combination of scare data in that particular niche and
actual lack of deviation from the categorical mean. 
My suspicion is that there's a large degree of
colinearity in some of these variables that serves to
reduce the total effect of either of a nearly colinear
pair to an insignificant level; my hope is that
removing one of a mostly colinear group would allow
the other variables' possibly significant effects to
be measured.

Question 1) Is this legitimate at all? Can I do
regression using the entire data set over only
selected factors while ignoring others?
(Admittedly I only just got my Bachelor's in math; the
gaps in my knowlege here are profound and
aggravating.)

Question 2) How do I go about selecting possible
colinear explanatory variables?
I had originally thought I'd just make a matrix of
coefficients of colinearity for each pair of variables
and iteratively re-run the model until I got the
results I wanted, but I can't really figure out how to
do this.  In addition, I'm not sure how to do this in
the model syntax once I've actually decided on some
variables to exclude.
For instance, supposing I wanted to run the model as
above without the variable
Bstaph.aureus:Dvan:Sr:U:ICU.  What I tried was

lm(mic ~ B * D * S * U * V * ICU -
Bstaph.aureus:Dvan:Sr:U:ICU).

Obviously this doesn't work because the variable name
Bstaph.aureus:Dvan:Sr:U:ICU hasn't been recognized
yet.  How do I do this?  My best guess so far is to
build and define each of the variables like
Bstaph.aureus:Dvan:Sr:U:ICU by hand with some
imperative/iterative style programming using some kind
of string generation system.  This sounds like a royal
pain, and is something I'd rather avoid doing if at
all possible.

Any suggestions? :-D

-petertgaffney



From axelrod1 at llnl.gov  Thu Jul  1 01:44:54 2004
From: axelrod1 at llnl.gov (Michael Axelrod)
Date: Wed, 30 Jun 2004 16:44:54 -0700
Subject: [R] R can find some functions in assist package
Message-ID: <5.2.1.1.2.20040630163345.019bf7e8@popcorn.llnl.gov>

I am a new user to R. I installed and loaded the smoothing spline package 
called "assist." The function "ssr" seems to work, but "predict.ssr" and 
some others don't seem to be available, I get a "can't find" message. But 
they appear in the extensions folder, c:program 
files\R\rw1091\library\assist\R-ex. What's wrong?



From baron at psych.upenn.edu  Thu Jul  1 01:47:17 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 30 Jun 2004 19:47:17 -0400
Subject: [R] linear models and colinear variables...
In-Reply-To: <20040630233259.95850.qmail@web60005.mail.yahoo.com>
References: <20040630233259.95850.qmail@web60005.mail.yahoo.com>
Message-ID: <20040630234717.GA22317@psych>

On 06/30/04 16:32, Peter Gaffney wrote:
>Hi!
>
>I'm having some issues on both conceptual and
>technical levels for selecting the right combination
>of variables for this model I'm working on. The basic,
>all inclusive form looks like
>
>lm(mic ~ B * D * S * U * V * ICU)

When you do this, you are including all the interaction terms.
The * indicates an interaction, as opposed to +.  That might make
sense unders some circumstances, for example if you are just
trying to get the best model and you plan to eliminate
higher-order interactions that are not significant, but usually
it does more to obscure the interesting effects than to display
them.

>My suspicion is that there's a large degree of
>colinearity in some of these variables that serves to
>reduce the total effect of either of a nearly colinear
>pair to an insignificant level; my hope is that
>removing one of a mostly colinear group would allow
>the other variables' possibly significant effects to
>be measured.

There may be colinearity, but the most likely problem is that you
are including too many interactions, at too high a level.
Inclusion of nonsignificant interaction terms often turns
significant main effects into nonsignificant effects.

>Question 1) Is this legitimate at all? Can I do
>regression using the entire data set over only
>selected factors while ignoring others?
>(Admittedly I only just got my Bachelor's in math; the
>gaps in my knowlege here are profound and
>aggravating.)

If you select predictors on the basis of which ones are
significant, then the final significance levels don't mean much,
usually.  Remember, 1 out of 20 will be significant at .05 even
if you are using random numbers.

>Question 2) How do I go about selecting possible
>colinear explanatory variables?

If there is colinearity, then what to do about it depends on the
substance of the questions you are asking.  Some options are to
combine variables, do some sort of factor analysis and use
factors rather than variables as predictors, use the most
meaningful of the variables that are colinear, or just live with
it, if the substantive issues rule out the other options.  (I'm
sure there are other solutions that others might point out.)

>I had originally thought I'd just make a matrix of
>coefficients of colinearity for each pair of variables
>and iteratively re-run the model until I got the
>results I wanted, but I can't really figure out how to
>do this.  In addition, I'm not sure how to do this in
>the model syntax once I've actually decided on some
>variables to exclude.
>For instance, supposing I wanted to run the model as
>above without the variable
>Bstaph.aureus:Dvan:Sr:U:ICU.  What I tried was
>
>lm(mic ~ B * D * S * U * V * ICU -
>Bstaph.aureus:Dvan:Sr:U:ICU).
>
>Obviously this doesn't work because the variable name
>Bstaph.aureus:Dvan:Sr:U:ICU hasn't been recognized
>yet.  How do I do this?  My best guess so far is to

Not clear what you mean here.

>build and define each of the variables like
>Bstaph.aureus:Dvan:Sr:U:ICU by hand with some
>imperative/iterative style programming using some kind
>of string generation system.  This sounds like a royal
>pain, and is something I'd rather avoid doing if at
>all possible.
>
>Any suggestions? :-D
>
>-petertgaffney

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From solares at unsl.edu.ar  Thu Jul  1 01:55:48 2004
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Wed, 30 Jun 2004 20:55:48 -0300 (ART)
Subject: [R] help with tclVar
Message-ID: <59221.170.210.173.216.1088639748.squirrel@inter17.unsl.edu.ar>

Hi, I can' t load a variable tcltk declared with tclVar, why is this?, the
exmple above explain me ,Thanks Ruben
a<-tclVar(init="")
> f<-function(){
+ a<<-"pipo"
+ }
> f()
> a
[1] "pipo"
> tclvalue(a)
Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class =
"tclObj") :
        [tcl] can't read "pipo": no such variable.
>



From axelrod1 at llnl.gov  Thu Jul  1 02:00:48 2004
From: axelrod1 at llnl.gov (Michael Axelrod)
Date: Wed, 30 Jun 2004 17:00:48 -0700
Subject: [R] R can't find some functions in assist package
Message-ID: <5.2.1.1.2.20040630165635.024e7e00@popcorn.llnl.gov>

Oh yes. The "load package" under the "packages menu" in the Windows version 
does that. To check I typed "library(assist)" after starting R. Same 
behavior, ssr is found, but others like predict.ssr, and plot.ssr, give a 
"not found" message.

Thanks for the suggestion.

Mike



From James.Callahan at CityofOrlando.net  Thu Jul  1 02:08:45 2004
From: James.Callahan at CityofOrlando.net (James.Callahan@CityofOrlando.net)
Date: Wed, 30 Jun 2004 20:08:45 -0400
Subject: [R] MS OLAP -- RODBC to SQL Server "Slice Server" pass-through query
	to MS OLAP 
Message-ID: <OFE2F7DFB3.B96A4290-ON85256EC3.007C74C9-85256EC4.0000A9F7@ci.orlando.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040630/5b8469c7/attachment.pl

From jasont at indigoindustrial.co.nz  Thu Jul  1 03:02:03 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 1 Jul 2004 13:02:03 +1200 (NZST)
Subject: [R] R can't find some functions in assist package
In-Reply-To: <5.2.1.1.2.20040630165635.024e7e00@popcorn.llnl.gov>
References: <5.2.1.1.2.20040630165635.024e7e00@popcorn.llnl.gov>
Message-ID: <37556.203.9.176.60.1088643723.squirrel@webmail.maxnet.co.nz>

> Oh yes. The "load package" under the "packages menu" in the Windows
> version
> does that. To check I typed "library(assist)" after starting R. Same
> behavior, ssr is found, but others like predict.ssr, and plot.ssr, give a
> "not found" message.

Short answer:  Try using "predict" instead of "predict.ssr".  I think
you're meant to quietly use the predict and plot methods provided, and not
mention their inner names.

Long answer:
Namespaces.  This means that a method for an object isn't visible to R as
a whole.  This avoids conflics should another package pick the same names.

Does this work?

getAnywhere(predict.ssr)

Cheers

Jason



From andy_liaw at merck.com  Thu Jul  1 03:03:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 30 Jun 2004 21:03:18 -0400
Subject: [R] R can't find some functions in assist package
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FB6@usrymx25.merck.com>

That's because `assist' has a namespace:

> library(assist)
Loading required package: nlme 
> predict.ssr
Error: Object "predict.ssr" not found
> methods("predict")
 [1] predict.ar*                predict.Arima*            
 [3] predict.arima0*            predict.glm               
 [5] predict.gls*               predict.gnls*             
 [7] predict.HoltWinters*       predict.lm                
 [9] predict.lme*               predict.lmList*           
[11] predict.loess*             predict.mlm               
[13] predict.nlme*              predict.nls*              
[15] predict.poly               predict.ppr*              
[17] predict.princomp*          predict.slm*              
[19] predict.smooth.spline*     predict.smooth.spline.fit*
[21] predict.snm*               predict.snr*              
[23] predict.ssr*               predict.StructTS*         

    Non-visible functions are asterisked

Use either assist:::predict.ssr or getAnywhere("predict.ssr").

Andy

> From: Michael Axelrod
> 
> Oh yes. The "load package" under the "packages menu" in the 
> Windows version 
> does that. To check I typed "library(assist)" after starting R. Same 
> behavior, ssr is found, but others like predict.ssr, and 
> plot.ssr, give a 
> "not found" message.
> 
> Thanks for the suggestion.
> 
> Mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From rkoenker at uiuc.edu  Thu Jul  1 03:22:54 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Wed, 30 Jun 2004 20:22:54 -0500
Subject: [R] R can't find some functions in assist package
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7FB6@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7FB6@usrymx25.merck.com>
Message-ID: <2D71B096-CAFD-11D8-B2B4-000393A361A2@uiuc.edu>

An R-News or J. of Statistical Software note titled, "Getting to the 
Source
of the Problem"  detailing the basic strategies for these adventures in 
the
new world of S4 methods and namespaces would be very useful.

url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Jun 30, 2004, at 8:03 PM, Liaw, Andy wrote:

> That's because `assist' has a namespace:
>
>> library(assist)
> Loading required package: nlme
>> predict.ssr
> Error: Object "predict.ssr" not found
>> methods("predict")
>  [1] predict.ar*                predict.Arima*
>  [3] predict.arima0*            predict.glm
>  [5] predict.gls*               predict.gnls*
>  [7] predict.HoltWinters*       predict.lm
>  [9] predict.lme*               predict.lmList*
> [11] predict.loess*             predict.mlm
> [13] predict.nlme*              predict.nls*
> [15] predict.poly               predict.ppr*
> [17] predict.princomp*          predict.slm*
> [19] predict.smooth.spline*     predict.smooth.spline.fit*
> [21] predict.snm*               predict.snr*
> [23] predict.ssr*               predict.StructTS*
>
>     Non-visible functions are asterisked
>
> Use either assist:::predict.ssr or getAnywhere("predict.ssr").
>
> Andy
>
>> From: Michael Axelrod
>>
>> Oh yes. The "load package" under the "packages menu" in the
>> Windows version
>> does that. To check I typed "library(assist)" after starting R. Same
>> behavior, ssr is found, but others like predict.ssr, and
>> plot.ssr, give a
>> "not found" message.
>>
>> Thanks for the suggestion.
>>
>> Mike
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Thu Jul  1 03:46:16 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 30 Jun 2004 21:46:16 -0400
Subject: [R] Developing functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FB8@usrymx25.merck.com>

> From: daniel at sintesys.com.ar
> 
> Hi,
> I??m new in R. I??m working with similarity coefficients for clustering
> items. I created one function (coef), to calculate the 
> coefficients from
> two pairs of vectors and then, as an example, the function
> simple_matching,
> taking a data.frame(X) and using coef in a for cicle.
> It works, but I believe it is a bad way to do so (I believe 
> the for cicle
> is not necessary). Somebody can suggest anything better.
> Thanks
> Daniel Rozengardt
> 
> coef<-function(x1,x2){a<-sum(ifelse(x1==1&x2==1,1,0));
> b<-sum(ifelse(x1==1&x2==0,1,0));
> c<-sum(ifelse(x1==0&x2==1,1,0));
> d<-sum(ifelse(x1==0&x2==0,1,0));
> ret<-cbind(a,b,c,d);
> ret
> }
> 
> simple_matching<-function(X) {
> ret<-matrix(ncol=dim(X)[1],nrow=dim(X)[1]);
> diag(ret)<-1;
> for (i in 2:length(X[,1])) {
> 	for (j in i:length(X[,1])) {
> 	vec<-coef(X[i-1,],X[j,]);
> 	result<-(vec[1]+vec[3])/sum(vec);
> 	ret[i-1,j]<-result;
> 	ret[j,i-1]<-result}};
> ret}

A few comments first:

1. Unless you are putting multiple statements on the same line, there's no
need to use ";".

2. In `coef' (which is a bad choice for a function name: There's a built-in
generic function by that name in R, for extracting coefficients from fitted
model objects), a, b, c and d are scalars.  You don't need to cbind() them;
c() works just fine.

3. One of the best strategies for efficiency is to vectorize.  Try to
formulate the problem in matrix/vector operations as much as possible.

4. The computation looks a bit odd to me.  Assuming the data are binary
(i.e., all 0s and 1s), you are computing (N11 + N01) / N, where N is the
length of the vectors, N11 is the number of 1-1 matches and N01 is the
number of 0-1 matches.  Are you sure that's what you want to compute?

Here's what I'd do (assuming the input matrix contains all 0s and 1s):

simple_matching <- function(X) {
    N11 <- crossprod(t(X))
    N01 <- crossprod(t(X), t(1-X))
    ans <- (N11 + N01) / ncol(X)
    diag(ans) <- 1
    ans
}

HTH,
Andy



From James.Callahan at CityofOrlando.net  Thu Jul  1 04:27:00 2004
From: James.Callahan at CityofOrlando.net (James.Callahan@CityofOrlando.net)
Date: Wed, 30 Jun 2004 22:27:00 -0400
Subject: [R] .Net & Mono language news: C, C++, C#, Java, Python & Perl
Message-ID: <OF07EA2AEA.8C03D0B7-ON85256EC4.0001F824-85256EC4.000D5227@ci.orlando.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040630/941376cd/attachment.pl

From pwilkinson at videotron.ca  Thu Jul  1 05:57:38 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Wed, 30 Jun 2004 23:57:38 -0400
Subject: [R] how to drop rows from a data.frame
Message-ID: <6.1.1.1.2.20040630235041.01bf2360@pop.videotron.ca>

here is a snippet of data where I would like to drop all rows that have 
zeros across them, and keep the rest of the rows while maintaining the row 
names (1,2,3, ...10). The idea here is that a row of zeros is an indication 
that the row must be dropped. There will never be the case where there is a 
row(of n columns) with less than 5 zeros in this case(n zeros

I am unsure how to manipulate the data frame to drop rows whiles keeping 
row names.

Peter

the data (imagine separated by tabs):

       SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
  [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
  [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
  [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
  [4,]   0.0000    0.0000   0.0000   0.0000   0.0000
  [5,]   0.0000    0.0000   0.0000   0.0000   0.0000
  [6,]   0.0000    0.0000   0.0000   0.0000   0.0000
  [7,]   0.0000    0.0000   0.0000   0.0000   0.0000
  [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
  [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
[10,]   0.0000    0.0000   0.0000   0.0000   0.0000

what I want it to look like:

       SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
  [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
  [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
  [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
  [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
  [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485



From p.connolly at hortresearch.co.nz  Thu Jul  1 06:13:40 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 1 Jul 2004 16:13:40 +1200
Subject: [R] how to drop rows from a data.frame
In-Reply-To: <6.1.1.1.2.20040630235041.01bf2360@pop.videotron.ca>; from
	pwilkinson@videotron.ca on Wed, Jun 30, 2004 at 11:57:38PM -0400
References: <6.1.1.1.2.20040630235041.01bf2360@pop.videotron.ca>
Message-ID: <20040701161340.D11533@hortresearch.co.nz>

On Wed, 30-Jun-2004 at 11:57PM -0400, Peter Wilkinson wrote:

|> here is a snippet of data where I would like to drop all rows that have 
|> zeros across them, and keep the rest of the rows while maintaining the row 
|> names (1,2,3, ...10). The idea here is that a row of zeros is an indication 
|> that the row must be dropped. There will never be the case where there is a 
|> row(of n columns) with less than 5 zeros in this case(n zeros
|> 
|> I am unsure how to manipulate the data frame to drop rows whiles keeping 
|> row names.
|> 
|> Peter
|> 
|> the data (imagine separated by tabs):
|> 
|>        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
|>   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
|>   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
|>   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
|>   [4,]   0.0000    0.0000   0.0000   0.0000   0.0000
|>   [5,]   0.0000    0.0000   0.0000   0.0000   0.0000
|>   [6,]   0.0000    0.0000   0.0000   0.0000   0.0000
|>   [7,]   0.0000    0.0000   0.0000   0.0000   0.0000
|>   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
|>   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
|> [10,]   0.0000    0.0000   0.0000   0.0000   0.0000

I'm curious to know how you got those row names.  I suspect you really
have a matrix.

If it were a dataframe, it would behave exactly how you are reqesting
-- depending on how you got rid of rows 4:7.

Try as.data.frame(<whatever.your.data.is.now>)

Then deleting the rows will look like:

  SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
1 256.1139  256.1139 256.1139 256.1139 256.1139
2 283.0741  695.1000 614.5117 453.0342 500.1436
3 257.3578  305.0818 257.3578 257.3578 257.3578
8 257.0000  257.0000 257.0000 257.0000 257.0000
9 305.7857 2450.0417 335.5428 305.7857 584.2485


HTH


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From pwilkinson at videotron.ca  Thu Jul  1 06:29:48 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Thu, 01 Jul 2004 00:29:48 -0400
Subject: [R] how to drop rows from a data.frame
In-Reply-To: <20040701161340.D11533@hortresearch.co.nz>
References: <6.1.1.1.2.20040630235041.01bf2360@pop.videotron.ca>
	<20040701161340.D11533@hortresearch.co.nz>
Message-ID: <6.1.1.1.2.20040701001944.01c0a350@pop.videotron.ca>

You right its a matrix (I ran an is.matrix() on my object).

Thanks,

Peter


At 12:13 AM 7/1/2004, Patrick Connolly wrote:
>On Wed, 30-Jun-2004 at 11:57PM -0400, Peter Wilkinson wrote:
>
>|> here is a snippet of data where I would like to drop all rows that have
>|> zeros across them, and keep the rest of the rows while maintaining the row
>|> names (1,2,3, ...10). The idea here is that a row of zeros is an 
>indication
>|> that the row must be dropped. There will never be the case where there 
>is a
>|> row(of n columns) with less than 5 zeros in this case(n zeros
>|>
>|> I am unsure how to manipulate the data frame to drop rows whiles keeping
>|> row names.
>|>
>|> Peter
>|>
>|> the data (imagine separated by tabs):
>|>
>|>        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
>|>   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
>|>   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
>|>   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
>|>   [4,]   0.0000    0.0000   0.0000   0.0000   0.0000
>|>   [5,]   0.0000    0.0000   0.0000   0.0000   0.0000
>|>   [6,]   0.0000    0.0000   0.0000   0.0000   0.0000
>|>   [7,]   0.0000    0.0000   0.0000   0.0000   0.0000
>|>   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
>|>   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
>|> [10,]   0.0000    0.0000   0.0000   0.0000   0.0000
>
>I'm curious to know how you got those row names.  I suspect you really
>have a matrix.
>
>If it were a dataframe, it would behave exactly how you are reqesting
>-- depending on how you got rid of rows 4:7.
>
>Try as.data.frame(<whatever.your.data.is.now>)
>
>Then deleting the rows will look like:
>
>   SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
>1 256.1139  256.1139 256.1139 256.1139 256.1139
>2 283.0741  695.1000 614.5117 453.0342 500.1436
>3 257.3578  305.0818 257.3578 257.3578 257.3578
>8 257.0000  257.0000 257.0000 257.0000 257.0000
>9 305.7857 2450.0417 335.5428 305.7857 584.2485
>
>
>HTH
>
>
>--
>Patrick Connolly
>HortResearch
>Mt Albert
>Auckland
>New Zealand
>Ph: +64-9 815 4200 x 7188
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
>I have the world`s largest collection of seashells. I keep it on all
>the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From ggrothendieck at myway.com  Thu Jul  1 06:36:07 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 1 Jul 2004 04:36:07 +0000 (UTC)
Subject: [R] how to drop rows from a data.frame
References: <6.1.1.1.2.20040630235041.01bf2360@pop.videotron.ca>
Message-ID: <loom.20040701T063235-932@post.gmane.org>


Assuming all the entries are non-negative and non-NA this will do it:

    DF[rowSums(DF) > 0,]



Peter Wilkinson <pwilkinson <at> videotron.ca> writes:

: 
: here is a snippet of data where I would like to drop all rows that have 
: zeros across them, and keep the rest of the rows while maintaining the row 
: names (1,2,3, ...10). The idea here is that a row of zeros is an indication 
: that the row must be dropped. There will never be the case where there is a 
: row(of n columns) with less than 5 zeros in this case(n zeros
: 
: I am unsure how to manipulate the data frame to drop rows whiles keeping 
: row names.
: 
: Peter
: 
: the data (imagine separated by tabs):
: 
:        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
:   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
:   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
:   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
:   [4,]   0.0000    0.0000   0.0000   0.0000   0.0000
:   [5,]   0.0000    0.0000   0.0000   0.0000   0.0000
:   [6,]   0.0000    0.0000   0.0000   0.0000   0.0000
:   [7,]   0.0000    0.0000   0.0000   0.0000   0.0000
:   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
:   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
: [10,]   0.0000    0.0000   0.0000   0.0000   0.0000
: 
: what I want it to look like:
: 
:        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
:   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
:   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
:   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
:   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
:   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485



From pwilkinson at videotron.ca  Thu Jul  1 06:45:48 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Thu, 01 Jul 2004 00:45:48 -0400
Subject: [R] drop rows
In-Reply-To: <200407010422.i614Mb410599@gator.dt.uh.edu>
References: <200407010422.i614Mb410599@gator.dt.uh.edu>
Message-ID: <6.1.1.1.2.20040701004509.01bea9d8@pop.videotron.ca>

his ...

hmmmm looks like your working with microarray data as well .... The actual 
matrix that I am working with is 19000 x 340

Thanks for the help, that was perfect.  I am still getting used to the R 
language way of doing things.I will look into the apply function as you 
have written it.

Peter

At 12:22 AM 7/1/2004, Erin Hodgess wrote:
>Hi Peter!
>
>Here is an example:
>
> > x
>             [,1]        [,2]        [,3]       [,4]        [,5]
>  [1,]  2.1632497  0.43219960  0.05329827  0.1484550  2.12996660
>  [2,]  0.0000000  0.00000000  0.00000000  0.0000000  0.00000000
>  [3,] -1.2230673  0.83467155 -0.14820752 -0.1012919 -0.04410457
>  [4,] -0.5397403  0.92664487 -0.30390539  0.3105849 -0.69958321
>  [5,]  1.0112805  1.13063148 -1.59802451  0.7597861 -0.72821421
>  [6,] -1.1170756 -0.05128944  0.02755781 -0.8896866  0.12294861
>  [7,]  0.0000000  0.00000000  0.00000000  0.0000000  0.00000000
>  [8,]  0.7043937  0.82557039 -1.38759266  0.5266536  0.67345991
>  [9,]  0.7522765  0.25513348 -1.00076227  0.1141770  1.70003769
>[10,]  0.3371948 -1.48590028 -0.67115529 -0.8242699  1.32741665
> > #This takes out the rows with ANY zeros
> > x[!apply(x,1,function(x)any(x)==0),]
>            [,1]        [,2]        [,3]       [,4]        [,5]
>[1,]  2.1632497  0.43219960  0.05329827  0.1484550  2.12996660
>[2,] -1.2230673  0.83467155 -0.14820752 -0.1012919 -0.04410457
>[3,] -0.5397403  0.92664487 -0.30390539  0.3105849 -0.69958321
>[4,]  1.0112805  1.13063148 -1.59802451  0.7597861 -0.72821421
>[5,] -1.1170756 -0.05128944  0.02755781 -0.8896866  0.12294861
>[6,]  0.7043937  0.82557039 -1.38759266  0.5266536  0.67345991
>[7,]  0.7522765  0.25513348 -1.00076227  0.1141770  1.70003769
>[8,]  0.3371948 -1.48590028 -0.67115529 -0.8242699  1.32741665
> > #This takes out the rows with ALL zeros
> > x[!apply(x,1,function(x)all(x)==0),]
>            [,1]        [,2]        [,3]       [,4]        [,5]
>[1,]  2.1632497  0.43219960  0.05329827  0.1484550  2.12996660
>[2,] -1.2230673  0.83467155 -0.14820752 -0.1012919 -0.04410457
>[3,] -0.5397403  0.92664487 -0.30390539  0.3105849 -0.69958321
>[4,]  1.0112805  1.13063148 -1.59802451  0.7597861 -0.72821421
>[5,] -1.1170756 -0.05128944  0.02755781 -0.8896866  0.12294861
>[6,]  0.7043937  0.82557039 -1.38759266  0.5266536  0.67345991
>[7,]  0.7522765  0.25513348 -1.00076227  0.1141770  1.70003769
>[8,]  0.3371948 -1.48590028 -0.67115529 -0.8242699  1.32741665
> >
>
>  Hope this helps!
>  Sincerely,
>Erin Hodgess
>Associate Professor
>Department of Computer and Mathematical Sciences
>University of Houston - Downtown
>mailto: hodgess at gator.uhd.edu
>
>
>
>From: Peter Wilkinson <pwilkinson at videotron.ca>
>Subject: [R] how to drop rows from a data.frame
>
>here is a snippet of data where I would like to drop all rows that have
>zeros across them, and keep the rest of the rows while maintaining the row
>names (1,2,3, ...10). The idea here is that a row of zeros is an indication
>that the row must be dropped. There will never be the case where there is a
>row(of n columns) with less than 5 zeros in this case(n zeros
>
>I am unsure how to manipulate the data frame to drop rows whiles keeping
>row names.
>
>Peter
>
>the data (imagine separated by tabs):
>
>        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
>   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
>   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
>   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
>   [4,]   0.0000    0.0000   0.0000   0.0000   0.0000
>   [5,]   0.0000    0.0000   0.0000   0.0000   0.0000
>   [6,]   0.0000    0.0000   0.0000   0.0000   0.0000
>   [7,]   0.0000    0.0000   0.0000   0.0000   0.0000
>   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
>   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
>[10,]   0.0000    0.0000   0.0000   0.0000   0.0000
>
>what I want it to look like:
>
>        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
>   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
>   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
>   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
>   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
>   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pwilkinson at videotron.ca  Thu Jul  1 06:46:54 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Thu, 01 Jul 2004 00:46:54 -0400
Subject: [R] how to drop rows from a data.frame
In-Reply-To: <loom.20040701T063235-932@post.gmane.org>
References: <6.1.1.1.2.20040630235041.01bf2360@pop.videotron.ca>
	<loom.20040701T063235-932@post.gmane.org>
Message-ID: <6.1.1.1.2.20040701004614.01c31428@pop.videotron.ca>

Thanks for everyone's help, there seems to be many ways of solving the 
problem that work well.

Peter


At 12:36 AM 7/1/2004, Gabor Grothendieck wrote:

>Assuming all the entries are non-negative and non-NA this will do it:
>
>     DF[rowSums(DF) > 0,]
>
>
>
>Peter Wilkinson <pwilkinson <at> videotron.ca> writes:
>
>:
>: here is a snippet of data where I would like to drop all rows that have
>: zeros across them, and keep the rest of the rows while maintaining the row
>: names (1,2,3, ...10). The idea here is that a row of zeros is an indication
>: that the row must be dropped. There will never be the case where there is a
>: row(of n columns) with less than 5 zeros in this case(n zeros
>:
>: I am unsure how to manipulate the data frame to drop rows whiles keeping
>: row names.
>:
>: Peter
>:
>: the data (imagine separated by tabs):
>:
>:        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
>:   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
>:   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
>:   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
>:   [4,]   0.0000    0.0000   0.0000   0.0000   0.0000
>:   [5,]   0.0000    0.0000   0.0000   0.0000   0.0000
>:   [6,]   0.0000    0.0000   0.0000   0.0000   0.0000
>:   [7,]   0.0000    0.0000   0.0000   0.0000   0.0000
>:   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
>:   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
>: [10,]   0.0000    0.0000   0.0000   0.0000   0.0000
>:
>: what I want it to look like:
>:
>:        SEKH0001  SEKH0002 SEKH0003 SEKH0004 SEKH0005
>:   [1,] 256.1139  256.1139 256.1139 256.1139 256.1139
>:   [2,] 283.0741  695.1000 614.5117 453.0342 500.1436
>:   [3,] 257.3578  305.0818 257.3578 257.3578 257.3578
>:   [8,] 257.0000  257.0000 257.0000 257.0000 257.0000
>:   [9,] 305.7857 2450.0417 335.5428 305.7857 584.2485
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From owl_of_minerva at hotmail.com  Thu Jul  1 07:01:36 2004
From: owl_of_minerva at hotmail.com (Matthew Cohen)
Date: Thu, 01 Jul 2004 01:01:36 -0400
Subject: [R] RGL on Mac OS X
Message-ID: <BD0912F0.76D3%owl_of_minerva@hotmail.com>

Scanning various lists for R, I've noticed that a few people have raised the
question of getting the "rgl" package to run in R on the Mac operating
system.  As far as I can tell (and I must admit to being a novice here), the
problem has to do with the inclusion of the /usr/X11R6/lib in R's
environment, masking one framework with another.  More than one of the
people commenting on the problem seemed to suggest that it should be fairly
simple to fix or at least temporarily hack.  However, it is not clear to me
how to do it, given that I know very little about UNIX and even less about
R.  Could someone please give step-by-step instructions on what I need to do
to get rgl working in OS X?  Thanks a lot.

Matt


https://stat.ethz.ch/pipermail/r-sig-mac/2003-June/000868.html



From ligges at statistik.uni-dortmund.de  Thu Jul  1 09:50:27 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 01 Jul 2004 09:50:27 +0200
Subject: [R] help with tclVar
In-Reply-To: <59221.170.210.173.216.1088639748.squirrel@inter17.unsl.edu.ar>
References: <59221.170.210.173.216.1088639748.squirrel@inter17.unsl.edu.ar>
Message-ID: <40E3C243.4060509@statistik.uni-dortmund.de>

solares at unsl.edu.ar wrote:

> Hi, I can' t load a variable tcltk declared with tclVar, why is this?, the
> exmple above explain me ,Thanks Ruben
> a<-tclVar(init="")
> 
>>f<-function(){
> 
> + a<<-"pipo"
> + }
> 
>>f()
>>a
> 
> [1] "pipo"
> 
>>tclvalue(a)


He? You have initialized "a" correctly at the beginning, but overwritten 
by a character vector. Now it is no longer of class "tclVar", so what do 
you expect?

I guess you are going to use something like

  tclvalue(a) <- "pipo"
  tclvalue(a)

Uwe Ligges


> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class =
> "tclObj") :
>         [tcl] can't read "pipo": no such variable.



From assuncao.senra at portugalmail.com  Thu Jul  1 12:20:12 2004
From: assuncao.senra at portugalmail.com (assuncao.senra@portugalmail.com)
Date: Thu,  1 Jul 2004 11:20:12 +0100
Subject: [R] Factors.
Message-ID: <1088677212.40e3e55c65348@webmail2.portugalmail.pt>


Hello,

I'm new with R. I need some help; I have a matrix of data to wich i want to 
apply the function dudi.acm to perform multiple correspondence analysis. 
However to use it all variables must be factors, so how can i turn each column 
of the matrix into a factor? I've tried as.factor. It works isolated for each 
column, but when I form the matrix of all factors it doesnt work.
Please help me!

Thanks.
Assun????o

__________________________________________________________
Continua a preferir gastar mais? Adira ?? liga????o Portugalmail.
http://acesso.portugalmail.pt/compare



From Tom.Joy at rmbinternational.com  Thu Jul  1 12:20:33 2004
From: Tom.Joy at rmbinternational.com (Joy, Tom)
Date: Thu, 1 Jul 2004 11:20:33 +0100
Subject: [R] Customizing Cluster Analysis plots created with hclust
Message-ID: <576A4B4724813147AF478CAC91B8CF71A982C5@bank.rmbi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040701/1f3764da/attachment.pl

From jconnor at stat.cmu.edu  Thu Jul  1 12:37:15 2004
From: jconnor at stat.cmu.edu (Jason Connor)
Date: Thu, 1 Jul 2004 06:37:15 -0400 (EDT)
Subject: [R] xtabs
Message-ID: <Pine.LNX.4.44.0407010631290.2285-100000@hydra4.stat.cmu.edu>


I'm running 1.9.1 on Mac OS X 10.1.

My simple question is whether there is a crosstabs-like command (I know
about "xtabs" which is much like "table") that computes not only cell
counts but also row, column, and cell percents.  Something like
crosstabs(~x+y) in S-PLUS.

Thank you.



From ccleland at optonline.net  Thu Jul  1 12:59:31 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 01 Jul 2004 06:59:31 -0400
Subject: [R] xtabs
In-Reply-To: <Pine.LNX.4.44.0407010631290.2285-100000@hydra4.stat.cmu.edu>
References: <Pine.LNX.4.44.0407010631290.2285-100000@hydra4.stat.cmu.edu>
Message-ID: <40E3EE93.4030807@optonline.net>

   Try the CrossTable() function in the gregmisc package.

help.search("crosstabulation")

   would have found it for you.

Jason Connor wrote:
> I'm running 1.9.1 on Mac OS X 10.1.
> 
> My simple question is whether there is a crosstabs-like command (I know
> about "xtabs" which is much like "table") that computes not only cell
> counts but also row, column, and cell percents.  Something like
> crosstabs(~x+y) in S-PLUS.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From sam.kemp2 at ntlworld.com  Thu Jul  1 13:02:40 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Thu, 1 Jul 2004 12:02:40 +0100
Subject: [R] linking .lib and/or .dll files
Message-ID: <20040701110139.ITTM24958.mta04-svc.ntlworld.com@universi6iunz0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040701/95100cd9/attachment.pl

From temiz at deprem.gov.tr  Thu Jul  1 13:06:34 2004
From: temiz at deprem.gov.tr (temiz)
Date: Thu, 01 Jul 2004 14:06:34 +0300
Subject: [R] spatial autocorrelation
Message-ID: <40E3F03A.30006@deprem.gov.tr>

hello

what is the logic behind spatial autocorrelation ?
I will appreciate if you sent me any link, doc or
short explanation

kind regards


Ahmet Temiz
TURKEY


______________________________________
Inflex - installed on mailserver for domain @deprem.gov.tr
Queries to: postmaster at deprem.gov.tr

______________________________________
The views and opinions expressed in this e-mail message are ...{{dropped}}



From ripley at stats.ox.ac.uk  Thu Jul  1 13:14:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 1 Jul 2004 12:14:44 +0100 (GMT Daylight Time)
Subject: [R] linking .lib and/or .dll files
In-Reply-To: <20040701110139.ITTM24958.mta04-svc.ntlworld.com@universi6iunz0>
Message-ID: <Pine.WNT.4.44.0407011206260.2468-100000@gannet.stats.ox.ac.uk>

On Thu, 1 Jul 2004, Samuel Kemp wrote:

> Linking C++ dynamic libraries has become the bane of my R life.  I have a
> piece of C++ code that I would like to make into a .dll (to call into R).
> However, this piece of C++ code needs to be linked with a .dll or .lib -
> which I have been created in Visual C++. Is it possible to link this for use
> in R?

Yes with .lib, if it is a recent VC++.  You need to make a mingw import
library, and you can use a tool called reimp to convert a VC++6.0 .lib (but
not earlier).

Alternatively, a tool called pexports can be used to create an exports file
and dlltool can be used to make an import library from that.

Finally, it is supposedly possible to link against a .dll, but I have found
that to be really buggy.

> If so, how do I go about doing this is MINGW?

Create an import library and link against it, and make sure the dlls are in
your path.

CAVEAT: if the C++ code you are calling contains name-mangled symbols you
will be in trouble as VC++ name-mangles in a unique way.  In that case you
need to write a piece of C++ glue code that you can compile in VC++ and
that has C entry points that you can call from R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdrees at sdrees.de  Thu Jul  1 13:25:03 2004
From: sdrees at sdrees.de (Stefan Drees)
Date: Thu, 1 Jul 2004 13:25:03 +0200
Subject: [R] spatial autocorrelation
In-Reply-To: <40E3F03A.30006@deprem.gov.tr>
References: <40E3F03A.30006@deprem.gov.tr>
Message-ID: <20040701112503.GA9946@knoten.biz>

On Thu, Jul 01, 2004 at 02:06:34PM +0300 - temiz wrote:
> what is the logic behind spatial autocorrelation ?
> I will appreciate if you sent me any link, doc or
> short explanation
Hm, your favorite search interface to the web (eg google) might have
said:
- ? --- spatial autocorrelation -->
[PPT] Spatial Autocorrelation
1. www.css.cornell.edu/courses/620/lecture9.ppt

[PPT] Spatial Autocorrelation  Join Count
2. 	www.css.cornell.edu/courses/620/lecture10.ppt

Multivariate Statistics - Spatial Autocorrelation
3. www.pfc.forestry.ca/profiles/ wulder/mvstats/spatial_e.html

Local Spatial Autocorrelation Statistics - Gi and G*i
4. "www.uottawa.ca/academic/arts/geographie/lpcweb/newlook/data_and_downloads/download/sawsoft/gistats.htm"

Spatial Autocorrelation And Autoregressive Models In Ecology
5. www.srs.fs.usda.gov/pubs/viewpub.jsp?index=5315

[PDF] Spatial Autocorrelation Refresher
6. sal.agecon.uiuc.edu/courses/se/pdf/w2_spauto_slides.pdf
...
approx 55000 locations to follow ;)

Me, having a pdf-reader at hand might start withreference 6, but
your mileage may vary.

All the best,
Stefan.
-- 
.o. e-mail: stefan at drees.name, web: www.sdrees.org, +49 700 SDREESDE
..o fingerprint = 516C C4EF 712A B26F 15C9  C7B7 5651 6964 D508 1B56
ooo  stefan drees  -  consulting and lecturing  -  problems to tasks



From notulei at yahoo.com  Thu Jul  1 15:46:28 2004
From: notulei at yahoo.com (Alex Nu)
Date: Thu, 1 Jul 2004 06:46:28 -0700 (PDT)
Subject: [R] QR decomposition question
Message-ID: <20040701134628.87556.qmail@web60107.mail.yahoo.com>


 Hi all,

 I wonder if this kind of questions are ok in this
list...

 Quick question:

 What does it mean than the rank of the QR
 decomposition of a NxN matrix  is  N-1 ?

  m: NxN matrix
  qr(m)$rank equal to (N-1) 


 Long version:
 I'm doing a manova on a matrix of 10 variables
 and 16 observations.

> dim(tmp)
[1] 16 10
> fit <- manova( tmp ~ treatment*mouse )

>results <- summary(fit,test="Wilks")
...
residuals have rank 9 < 10

So the QR decomposition returns with a rank
 of 9. What does this mean ?

 Does this necessarily mean a linear dependency
 among the columns of the matrix ?

 Thanks

 Alex



From Jussi.Makinen at valtiokonttori.fi  Thu Jul  1 15:55:20 2004
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-1?Q?M=E4kinen_Jussi?=)
Date: Thu, 1 Jul 2004 16:55:20 +0300
Subject: [R] QR decomposition question
Message-ID: <0BDE2460F08BF0429F933A40431A61E8D87170@vk2kmail01.valtiokonttori.local>

There is N-1 linearly independent columns in the NxN matrix.

Jussi

Jussi M??kinen
Analyst, State Treasury, Finance, Finland



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alex Nu
Sent: 1. hein??kuuta 2004 16:46
To: r-help at stat.math.ethz.ch
Subject: [R] QR decomposition question



 Hi all,

 I wonder if this kind of questions are ok in this
list...

 Quick question:

 What does it mean than the rank of the QR
 decomposition of a NxN matrix  is  N-1 ?

  m: NxN matrix
  qr(m)$rank equal to (N-1) 


 Long version:
 I'm doing a manova on a matrix of 10 variables
 and 16 observations.

> dim(tmp)
[1] 16 10
> fit <- manova( tmp ~ treatment*mouse )

>results <- summary(fit,test="Wilks")
...
residuals have rank 9 < 10

So the QR decomposition returns with a rank
 of 9. What does this mean ?

 Does this necessarily mean a linear dependency
 among the columns of the matrix ?

 Thanks

 Alex

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From christian.hoffmann at wsl.ch  Thu Jul  1 16:00:29 2004
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Thu, 01 Jul 2004 16:00:29 +0200
Subject: [R] path related problem XEmacs Unix
Message-ID: <40E418FD.5000506@wsl.ch>

Hi there,

May I ask the following question.
Our Solaris installation of Xemacs and R:

SunOS fluke 5.9 Generic_117171-02 sun4u sparc SUNW,Sun-Fire-480R

one cannot start R inside xemacs:
M-x R

"symbol's function definition is void".

Also, loading a *.tex file into Xemacs will result in

"loading tex mode .. done", but the additional buttons to call TeX 
related processes do not show.

Last week everything was working fine both for R and TeX, but suddenly 
things got broken. May be this has something to do with compiling the 
patch 1.9.0..?

To me it is looking like a path problem. So, to find out, I would think 
of a mode in Xemacs that that traces the startup of R tells me, which 
file it was not able to find and why (environment variable wrong, ...)

Can anybody please give a hint?

Thanks
Christian
-- 
Dr.sc.math.Christian W. Hoffmann, 
http://www.wsl.ch/staff/christian.hoffmann
Mathematics + Statistical Computing   e-mail: christian.hoffmann at wsl.ch
Swiss Federal Research Institute WSL  Tel: ++41-44-73922-   -77  (office)
CH-8903 Birmensdorf, Switzerland             -11(exchange), -15  (fax)



From maechler at stat.math.ethz.ch  Thu Jul  1 16:22:34 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Jul 2004 16:22:34 +0200
Subject: [R] Customizing Cluster Analysis plots created with hclust
In-Reply-To: <576A4B4724813147AF478CAC91B8CF71A982C5@bank.rmbi.com>
References: <576A4B4724813147AF478CAC91B8CF71A982C5@bank.rmbi.com>
Message-ID: <16612.7722.982223.623283@gargle.gargle.HOWL>

>>>>> "TomJ" == Joy, Tom <Tom.Joy at rmbinternational.com>
>>>>>     on Thu, 1 Jul 2004 11:20:33 +0100 writes:

    TomJ> I am trying to cluster stock prices through time using
    TomJ> hclust.  To help with the interpretation of the output
    TomJ> I would like to change the colour of the lines and the
    TomJ> labels based on which sector a stock is in.  Is it
    TomJ> possible to customize a plot of the output of hclust
    TomJ> in this way?

It will be possible in the next versoin of R,
and soon in "R-devel" --
by 

 myhcl <- hclust(..........)
 myd <- as.dendrogram(myhcl)

i.e. working with the dendrogram (and its plot method) rather
than with the original "hclust" object and its much less
flexible plotting method.

Since the needed changes only need R-code changes, you
can ask me "off line" and I'll send you the R code needed.

Regards,
Martin



From notulei at yahoo.com  Thu Jul  1 16:59:41 2004
From: notulei at yahoo.com (Alex Nu)
Date: Thu, 1 Jul 2004 07:59:41 -0700 (PDT)
Subject: [R] QR decomposition and rank of a matrix
Message-ID: <20040701145941.27118.qmail@web60106.mail.yahoo.com>


 In summary.manova the qr decomposition of a NxN
matrix
 is calculated and for some cases is giving me
 a rank <  N.

 However, following suggestions of professor Ripley to

 calculate the rank of a Matrix 

On 7 Jun 2002, Brian Ripley wrote: 
> For a more reliable answer, look at the SVD 
> (function svd) and look at the
> singular values. For example (from lda.default)

    X.s <- svd(X, nu = 0)
    rank <- sum(X.s$d > tol * X.s$d[1])

I'm getting rrank = N,

 I wonder wether use this new method for
 calculating the rank inside the manova.R 

 I'd appreciate any suggestions.

 Thanks

 Alex



From ripley at stats.ox.ac.uk  Thu Jul  1 17:32:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Jul 2004 16:32:40 +0100 (BST)
Subject: [R] QR decomposition and rank of a matrix
In-Reply-To: <20040701145941.27118.qmail@web60106.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0407011628340.1421-100000@gannet.stats>

It depends on what you set as tol, of course.  The point is that if you 
get that warning

1) the calculations in the R code would be unreliable
2) the residuals are really of low rank, and it would be statistical 
nonsense to use their SSq in ANOVA calculation.

Yes, we could make it work in those cases but it is much better to solve
the problem at source and transform the response variables.

On Thu, 1 Jul 2004, Alex Nu wrote:

> 
>  In summary.manova the qr decomposition of a NxN
> matrix
>  is calculated and for some cases is giving me
>  a rank <  N.
> 
>  However, following suggestions of professor Ripley to
> 
>  calculate the rank of a Matrix 
> 
> On 7 Jun 2002, Brian Ripley wrote: 
> > For a more reliable answer, look at the SVD 
> > (function svd) and look at the
> > singular values. For example (from lda.default)
> 
>     X.s <- svd(X, nu = 0)
>     rank <- sum(X.s$d > tol * X.s$d[1])
> 
> I'm getting rrank = N,
> 
>  I wonder wether use this new method for
>  calculating the rank inside the manova.R 

It's not a `new method' but as old as the hills (and older than most 
statistics).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rxg218 at psu.edu  Thu Jul  1 17:37:23 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 01 Jul 2004 11:37:23 -0400
Subject: [R] list structure question
Message-ID: <1088696243.9740.3.camel@blue.chem.psu.edu>

Hi,
  I have a list in which element is a vector (all of the same length and
all numeric). I want to find the mean of the first elements of the
vectors, the mean of the second elements of the vectors and so on.

Currently I convert the list to a data.frame and apply rowMeans(). But
is there a way to to do this directly on the list? I seem to recall a
post in which there was such a function (or expression) but I just cant
seem to find it.

Could somebody point me in the right direction?

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Despite the high cost of living, it remains popular.



From ripley at stats.ox.ac.uk  Thu Jul  1 17:39:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Jul 2004 16:39:03 +0100 (BST)
Subject: [R] list structure question
In-Reply-To: <1088696243.9740.3.camel@blue.chem.psu.edu>
Message-ID: <Pine.LNX.4.44.0407011638190.1566-100000@gannet.stats>

?mapply, but I think what you are doing is as good as anything.

On Thu, 1 Jul 2004, Rajarshi Guha wrote:

>   I have a list in which element is a vector (all of the same length and
> all numeric). I want to find the mean of the first elements of the
> vectors, the mean of the second elements of the vectors and so on.
> 
> Currently I convert the list to a data.frame and apply rowMeans(). But
> is there a way to to do this directly on the list? I seem to recall a
> post in which there was such a function (or expression) but I just cant
> seem to find it.
> 
> Could somebody point me in the right direction?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pauling at giub.unibe.ch  Thu Jul  1 17:49:20 2004
From: pauling at giub.unibe.ch (Andreas Pauling)
Date: Thu,  1 Jul 2004 17:49:20 +0200
Subject: [R] R BATCH problem
Message-ID: <1088696960.40e43280c31e6@www.cx.unibe.ch>

Dear all

Entering

rows<-as.matrix(c(4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,300,304,308,312,316,320,324,328,332,336,340,344,348,352,356,360,364,368,372,376,380,384,388,392,396,400,404,408,412,416,420,424,428,432,436,440,444,448,452,456,460,464,468,472,476,480,484,488,492,496,500,504,508,512,516,520,524,528,532,536,540,544,548,552,556,560,564,568,572,576,580,584,588,592,596,600,604,608,612,616,620,624,628,632,636,640,644,648,652,656,660,664,668,672,676,680,684,688,692,696,868,872,876,880,884,888,892,896,900,904,908,912,916,920,924,928,932,936,940,944,948,952,956,960,964,968,972,976,980,984,988,992,996,1000,1004,1008,1012,1016,1020,1024,1028,1032,1036,1040,1044,1048,1052,1056,1060,1064,1068,1072,1076,1080,1084,1088,1092,1096,1100,1104,1108,1112,1116,1120,1124,1128,1132,
 1136,1140,1144,1148,1152,1156,1160,1164,1168,1172,1176,1180,1184,1188,1192,1196,1200,1204,1208,1212,1216,1220))

at the prompt works fine. Also source() works well. However, when
calling a script that contains just this single command with R
BATCH <script> the number "1160" is changed to "116+ 0" and this
results in a syntax error. Why is that and how can it be fixed? I
use R Version 1.8.1 under Linux SUSE 9.

Any help is appreciated!

Andreas



From MartinAusChemnitz at gmx.net  Thu Jul  1 17:49:57 2004
From: MartinAusChemnitz at gmx.net (Martin aus Chemnitz)
Date: Thu, 01 Jul 2004 17:49:57 +0200
Subject: [R] Inflection Points
Message-ID: <40E432A5.6010700@gmx.net>

Hi!

Some weeks ago I discovered R. Now, I have a somewhat complicated task 
and am not sure whether R is the right tool to solve it.

I got data of several series or measurements where I have to find the 
two inflection points. I did a linear regression (with ^2 and ^3 
arguments), the problem there was that I had to look only at a very 
narrow band of measurement in order to get the approximation right at 
the essential point. (Maybe there is a better way than lm?)

Now that I have an appromiated function, I need its inflection point, 
but I could not find any R function for that. Is there any? Or can 
anyone recommend a good (possibly free) mathematical programme?

Maybe this could be helpful: All the measurements look like this and I 
marked the points of interest.

                  ,-------
                 /
                /  <--
               /
         ,----??
        /
       |  <--
       /
-----??


Thank you very much for your help

Martin



From ggrothendieck at myway.com  Thu Jul  1 17:59:40 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 1 Jul 2004 15:59:40 +0000 (UTC)
Subject: [R] list structure question
References: <1088696243.9740.3.camel@blue.chem.psu.edu>
Message-ID: <loom.20040701T175724-278@post.gmane.org>


Here are three solutions but I think the original idea of just
converting to a data frame and using rowMeans (last solution) is simplest:

L <- list(1:5, 6:10) # test list

do.call("mapply", c(sum,L)) / length(L)

sapply(seq(along=L),function(i)mean(sapply(L,"[[",i)))

rowMeans(as.data.frame(L))





Rajarshi Guha <rxg218 <at> psu.edu> writes:

: 
: Hi,
:   I have a list in which element is a vector (all of the same length and
: all numeric). I want to find the mean of the first elements of the
: vectors, the mean of the second elements of the vectors and so on.
: 
: Currently I convert the list to a data.frame and apply rowMeans(). But
: is there a way to to do this directly on the list? I seem to recall a
: post in which there was such a function (or expression) but I just cant
: seem to find it.
: 
: Could somebody point me in the right direction?



From rkoenker at uiuc.edu  Thu Jul  1 18:10:26 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Thu, 1 Jul 2004 11:10:26 -0500
Subject: [R] Inflection Points
In-Reply-To: <40E432A5.6010700@gmx.net>
References: <40E432A5.6010700@gmx.net>
Message-ID: <2A20B93C-CB79-11D8-9E56-000A95A7E3AA@uiuc.edu>

take a look at predict.smooth.Pspline in the package pspline...

url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Jul 1, 2004, at 10:49 AM, Martin aus Chemnitz wrote:

> Hi!
>
> Some weeks ago I discovered R. Now, I have a somewhat complicated task 
> and am not sure whether R is the right tool to solve it.
>
> I got data of several series or measurements where I have to find the 
> two inflection points. I did a linear regression (with ^2 and ^3 
> arguments), the problem there was that I had to look only at a very 
> narrow band of measurement in order to get the approximation right at 
> the essential point. (Maybe there is a better way than lm?)
>
> Now that I have an appromiated function, I need its inflection point, 
> but I could not find any R function for that. Is there any? Or can 
> anyone recommend a good (possibly free) mathematical programme?
>
> Maybe this could be helpful: All the measurements look like this and I 
> marked the points of interest.
>
>                  ,-------
>                 /
>                /  <--
>               /
>         ,----??
>        /
>       |  <--
>       /
> -----??
>
>
> Thank you very much for your help
>
> Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Thu Jul  1 18:11:02 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 01 Jul 2004 09:11:02 -0700
Subject: [R] QR decomposition question
In-Reply-To: <0BDE2460F08BF0429F933A40431A61E8D87170@vk2kmail01.valtiokonttori.local>
References: <0BDE2460F08BF0429F933A40431A61E8D87170@vk2kmail01.valtiokonttori.local>
Message-ID: <40E43796.1050205@pdf.com>

      It does indeed mean a linear dependency between the response 
variables.  For a discussion of an example with 2 linear dependencies, 
see: 

Box, G. E. P., Hunter, W. G., MacGregor, J. F. and Erjavec, J. (1973)
Some problems associated with the analysis of multiresponse data
Technometrics, 15, 33-51
Keywords: Estimation; Linear dependencies; Eigenvalue-Eigenvector 
analysis; Nonlinear models; Chemical kinetics

      There are doubtless more recent references, but I know this paper 
and I can't think of any more recent off the top of my head. 

      hope this helps. spencer graves

M??kinen Jussi wrote:

>There is N-1 linearly independent columns in the NxN matrix.
>
>Jussi
>
>Jussi M??kinen
>Analyst, State Treasury, Finance, Finland
>
>
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alex Nu
>Sent: 1. hein??kuuta 2004 16:46
>To: r-help at stat.math.ethz.ch
>Subject: [R] QR decomposition question
>
>
>
> Hi all,
>
> I wonder if this kind of questions are ok in this
>list...
>
> Quick question:
>
> What does it mean than the rank of the QR
> decomposition of a NxN matrix  is  N-1 ?
>
>  m: NxN matrix
>  qr(m)$rank equal to (N-1) 
>
>
> Long version:
> I'm doing a manova on a matrix of 10 variables
> and 16 observations.
>
>  
>
>>dim(tmp)
>>    
>>
>[1] 16 10
>  
>
>>fit <- manova( tmp ~ treatment*mouse )
>>    
>>
>
>  
>
>>results <- summary(fit,test="Wilks")
>>    
>>
>...
>residuals have rank 9 < 10
>
>So the QR decomposition returns with a rank
> of 9. What does this mean ?
>
> Does this necessarily mean a linear dependency
> among the columns of the matrix ?
>
> Thanks
>
> Alex
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From talitaperciano at hotmail.com  Thu Jul  1 18:14:32 2004
From: talitaperciano at hotmail.com (Talita Leite)
Date: Thu, 01 Jul 2004 13:14:32 -0300
Subject: [R] RMySQL
Message-ID: <BAY14-F29NgzcwWcsOA0003be5a@hotmail.com>

Hi!!

I want some help to install the RMySQL package. I've tried to configure some 
things but i'm still getting erros. Anybody could help me??

Thank's



Talita Perciano Costa Leite
Graduanda em Ci??ncia da Computa????o
Universidade Federal de Alagoas - UFAL
Departamento de Tecnologia da Informa????o - TCI
Constru????o de Conhecimento por Agrupamento de Dados - CoCADa



From ripley at stats.ox.ac.uk  Thu Jul  1 18:15:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Jul 2004 17:15:46 +0100 (BST)
Subject: [R] R BATCH problem
In-Reply-To: <1088696960.40e43280c31e6@www.cx.unibe.ch>
Message-ID: <Pine.LNX.4.44.0407011703360.1621-100000@gannet.stats>

On Thu, 1 Jul 2004, Andreas Pauling wrote:

> Dear all
> 
> Entering
> 
> rows<-as.matrix(c(4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,300,304,308,312,316,320,324,328,332,336,340,344,348,352,356,360,364,368,372,376,380,384,388,392,396,400,404,408,412,416,420,424,428,432,436,440,444,448,452,456,460,464,468,472,476,480,484,488,492,496,500,504,508,512,516,520,524,528,532,536,540,544,548,552,556,560,564,568,572,576,580,584,588,592,596,600,604,608,612,616,620,624,628,632,636,640,644,648,652,656,660,664,668,672,676,680,684,688,692,696,868,872,876,880,884,888,892,896,900,904,908,912,916,920,924,928,932,936,940,944,948,952,956,960,964,968,972,976,980,984,988,992,996,1000,1004,1008,1012,1016,1020,1024,1028,1032,1036,1040,1044,1048,1052,1056,1060,1064,1068,1072,1076,1080,1084,1088,1092,1096,1100,1104,1108,1112,1116,1120,1124,1128,11!
 32,
>  1136,1140,1144,1148,1152,1156,1160,1164,1168,1172,1176,1180,1184,1188,1192,1196,1200,1204,1208,1212,1216,1220))
> 
> at the prompt works fine. 

Are you sure? It does not work for me, stopping in exactly the same place 
as you report for batch, and assuming the line break is casued by the mail 
system.

> Also source() works well. However, when
> calling a script that contains just this single command with R
> BATCH <script> the number "1160" is changed to "116+ 0" and this
> results in a syntax error. Why is that and how can it be fixed? I

By using a reasonable line length!  R has a line length limit of 1024 
chars on input.  The + is a continuation prompt for the next line.

> use R Version 1.8.1 under Linux SUSE 9.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From roebuck at odin.mdacc.tmc.edu  Thu Jul  1 18:15:38 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Thu, 1 Jul 2004 11:15:38 -0500 (CDT)
Subject: [R] R BATCH problem
In-Reply-To: <1088696960.40e43280c31e6@www.cx.unibe.ch>
References: <1088696960.40e43280c31e6@www.cx.unibe.ch>
Message-ID: <Pine.OSF.4.58.0407011108220.450578@odin.mdacc.tmc.edu>

On Thu, 1 Jul 2004, Andreas Pauling wrote:

> Entering
>
> rows<-as.matrix(c(4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,300,304,308,312,316,320,324,328,332,336,340,344,348,352,356,360,364,368,372,376,380,384,388,392,396,400,404,408,412,416,420,424,428,432,436,440,444,448,452,456,460,464,468,472,476,480,484,488,492,496,500,504,508,512,516,520,524,528,532,536,540,544,548,552,556,560,564,568,572,576,580,584,588,592,596,600,604,608,612,616,620,624,628,632,636,640,644,648,652,656,660,664,668,672,676,680,684,688,692,696,868,872,876,880,884,888,892,896,900,904,908,912,916,920,924,928,932,936,940,944,948,952,956,960,964,968,972,976,980,984,988,992,996,1000,1004,1008,1012,1016,1020,1024,1028,1032,1036,1040,1044,1048,1052,1056,1060,1064,1068,1072,1076,1080,1084,1088,1092,1096,1100,1104,1108,1112,1116,1120,1124,1128,11!
32,
>  1136,1140,1144,1148,1152,1156,1160,1164,1168,1172,1176,1180,1184,1188,1192,1196,1200,1204,1208,1212,1216,1220))
>
> at the prompt works fine. Also source() works well. However, when
> calling a script that contains just this single command with R
> BATCH <script> the number "1160" is changed to "116+ 0" and this
> results in a syntax error. Why is that and how can it be fixed? I
> use R Version 1.8.1 under Linux SUSE 9.

What happens if you convert to a more compact format?

> rows<-as.matrix(c(seq(4, 696, by = 4),
                    seq(868, 1220, by = 4)))

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From cornulier at cebc.cnrs.fr  Thu Jul  1 18:15:42 2004
From: cornulier at cebc.cnrs.fr (cornulier)
Date: Thu, 01 Jul 2004 18:15:42 +0200
Subject: [R] Inflection Points
References: <40E432A5.6010700@gmx.net>
Message-ID: <40E438AD.7F1F5FB7@cebc.cnrs.fr>

does locpoly in package KernSmooth help?


Martin aus Chemnitz wrote:

> Hi!
>
> Some weeks ago I discovered R. Now, I have a somewhat complicated task
> and am not sure whether R is the right tool to solve it.
>
> I got data of several series or measurements where I have to find the
> two inflection points. I did a linear regression (with ^2 and ^3
> arguments), the problem there was that I had to look only at a very
> narrow band of measurement in order to get the approximation right at
> the essential point. (Maybe there is a better way than lm?)
>
> Now that I have an appromiated function, I need its inflection point,
> but I could not find any R function for that. Is there any? Or can
> anyone recommend a good (possibly free) mathematical programme?
>
> Maybe this could be helpful: All the measurements look like this and I
> marked the points of interest.
>
>                   ,-------
>                  /
>                 /  <--
>                /
>          ,----??
>         /
>        |  <--
>        /
> -----??
>
> Thank you very much for your help
>
> Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--
--------------------------------------------
             Thomas Cornulier
Centre d'Etudes Biologiques de Chiz?? - CNRS
         79360 Beauvoir sur Niort

+33 (0)549099613 / fax +33 (0)549096526
mobile +33 (0)620660784



From owl_of_minerva at hotmail.com  Thu Jul  1 18:40:59 2004
From: owl_of_minerva at hotmail.com (Matthew Cohen)
Date: Thu, 01 Jul 2004 16:40:59 +0000
Subject: [R] RGL on Mac OS X
Message-ID: <BAY12-F114piacp6Q5B00028671@hotmail.com>



I should have included in my last message a reference to the discussion of 
this issue on the R developers' list:

http://maths.newcastle.edu.au/~rking/R/devel/03a/0982.html

Here, Simon Urbanek says:

>In Mac OS X native version: The R shell wrapper (bin/R) overrides default 
>library search path with DYLD_LIBRARY_PATH and adds (among others) 
>/usr/X11R6/lib. This causes problems when modules need (directly or 
>indirectly) libraries from Apple's frameworks which are masked by X11. 
>Examples for such packages are SJava and RGL. SJava needs JavaVM which in 
>turn loads OpenGL framework. RGL needs the OpenGL framework directly. The 
>problem is that specifying /usr/X11R6/lib in DYLD_LIBRARY_PATH forces the 
>libGL to be loaded from the X11 directory instead of the OpenGL framework 
>library. This crashes R due to missing symbols, since the modules must link 
>to the OpenGL framework. In fact the OpenGL framework libraries load the 
>X11 libraries internally (but not vice versa) - that's why the default load 
>path is frameworks first then X11.

He suggests a temporary workaround:

>Currently a workaround is to remove /usr/X11R6/lib in R from the 
>environment variable prior to loading those packages, but more general 
>solution would be better imho. Is the /usr/X11R6/lib really necessary in 
>the DYLD_LIBRARY_PATH for some older OS X versions? At least for OS X 10.2 
>with Apple's X11 it is not necessary since X11 is already in the default 
>load path.

Clearly the "more general solution" was never arrived at, given that the 
problem still exists.  So how, exactly, do I go about implementing this 
workaround?  In other words, where is the "usr/X11R6/lib" path included in 
R, and how do I remove it?  (and, if necessary, how do I put it back 
afterwards?)

Also, in case it is needed, here is what typing "library(rgl)" returns in R:

>Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library  
>"/usr/local/lib/R/library/rgl/libs/rgl.so":
>   dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
>_glArrayElement
>_glBegin
>_glBindTexture
>_glBitmap
>_glBlendFunc
>_glCallList
>_glCallLists
>_glClear
>_glClearColor
>_glClearDepth
>_glColor3f
>_glColor4fv
>_glColor4ubv
>_glColorMaterial
>_glColorPointe
>Error in library(rgl) : .First.lib failed

Any help would be very much appreciated.  Also, apologies for sending out 
two messages asking the same question in such a short span of time, but I 
realized after sending that I did not include all of the relevant 
information in the first.

Matt


Guide! http://dollar.msn.com



From wolski at molgen.mpg.de  Thu Jul  1 18:46:06 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 01 Jul 2004 18:46:06 +0200
Subject: [R] RMySQL
In-Reply-To: <BAY14-F29NgzcwWcsOA0003be5a@hotmail.com>
References: <BAY14-F29NgzcwWcsOA0003be5a@hotmail.com>
Message-ID: <200407011846060859.11A26492@mail.math.fu-berlin.de>

Hi!
I was installing RMySQL quite recently on Linux and had some troubles which I was able to solve. So maybee I can help you.
But first I have to know what error messages you are getting on which operating system you are installing, which version of the package.

Sincerely Eryk



*********** REPLY SEPARATOR  ***********

On 01.07.2004 at 13:14 Talita Leite wrote:

>Hi!!
>
>I want some help to install the RMySQL package. I've tried to configure
>some 
>things but i'm still getting erros. Anybody could help me??
>
>Thank's
>
>
>
>Talita Perciano Costa Leite
>Graduanda em Ci??ncia da Computa????o
>Universidade Federal de Alagoas - UFAL
>Departamento de Tecnologia da Informa????o - TCI
>Constru????o de Conhecimento por Agrupamento de Dados - CoCADa
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kbartz at loyaltymatrix.com  Thu Jul  1 18:50:15 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Thu, 1 Jul 2004 09:50:15 -0700
Subject: [R] Seg. faults in mapthin
Message-ID: <20040701165524.A27A3400A0@omta16.mta.everyone.net>

Hi everyone! I know segmentation faults are awfully hard to diagnose, but
I'm experiencing a fairly regular pattern of seg. faults when plotting using
map in the maps package. Starting R fresh, I run:

require(maps)
for (i in 1:50) {
  cat(i, "\n")
  map("state")
}

I always get the same result:

1 
2 
3 
4 
5 

Process R segmentation fault at Thu Jul  1 09:07:39 2004

With some browsering, I've zeroed in on the source of the segmentation
fault: map's call to mapthin. Funny thing is, when I comment out the call to
mapthin, everything works consistently, without a hitch, and with no
apparent difference in the map.

Still, I'd rather work with the package the way it was built. I must be
losing something by cutting out the call to mapthin. 

I was wondering if anyone has any ideas. I've never had a segmentation fault
before on this particular machine, but these few lines always produce the
same unfortunate result. Has anyone else experienced segmentation faults
plotting using map in the maps package? Is there any way I might rectify it?
I'm on SuSE Linux, by the way, with:

> version
         _                       
platform x86_64-unknown-linux-gnu
arch     x86_64                  
os       linux-gnu               
system   x86_64, linux-gnu       
status   alpha                   
major    1                       
minor    9.1                     
year     2004                    
month    06                      
day      13                      
language R                       

Thanks for any help you can provide,

Kevin



From sdavis2 at mail.nih.gov  Thu Jul  1 19:01:04 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 01 Jul 2004 13:01:04 -0400
Subject: [R] RGL on Mac OS X
In-Reply-To: <BAY12-F114piacp6Q5B00028671@hotmail.com>
Message-ID: <BD09BB90.A302%sdavis2@mail.nih.gov>

Interestingly, on R 1.9.0 and MacOS 10.3.4, I was just able to install rgl
without problems this morning.  Is this perhaps an issue with movement from
10.2 to 10.3, as I know the X11 stuff changed quite a bit.  (I have to admit
that I haven't been following this thread closely, but just wanted to point
this out.)

On 7/1/04 12:40 PM, "Matthew Cohen" <owl_of_minerva at hotmail.com> wrote:

> 
> 
> I should have included in my last message a reference to the discussion of
> this issue on the R developers' list:
> 
> http://maths.newcastle.edu.au/~rking/R/devel/03a/0982.html
> 
> Here, Simon Urbanek says:
> 
>> In Mac OS X native version: The R shell wrapper (bin/R) overrides default
>> library search path with DYLD_LIBRARY_PATH and adds (among others)
>> /usr/X11R6/lib. This causes problems when modules need (directly or
>> indirectly) libraries from Apple's frameworks which are masked by X11.
>> Examples for such packages are SJava and RGL. SJava needs JavaVM which in
>> turn loads OpenGL framework. RGL needs the OpenGL framework directly. The
>> problem is that specifying /usr/X11R6/lib in DYLD_LIBRARY_PATH forces the
>> libGL to be loaded from the X11 directory instead of the OpenGL framework
>> library. This crashes R due to missing symbols, since the modules must link
>> to the OpenGL framework. In fact the OpenGL framework libraries load the
>> X11 libraries internally (but not vice versa) - that's why the default load
>> path is frameworks first then X11.
> 
> He suggests a temporary workaround:
> 
>> Currently a workaround is to remove /usr/X11R6/lib in R from the
>> environment variable prior to loading those packages, but more general
>> solution would be better imho. Is the /usr/X11R6/lib really necessary in
>> the DYLD_LIBRARY_PATH for some older OS X versions? At least for OS X 10.2
>> with Apple's X11 it is not necessary since X11 is already in the default
>> load path.
> 
> Clearly the "more general solution" was never arrived at, given that the
> problem still exists.  So how, exactly, do I go about implementing this
> workaround?  In other words, where is the "usr/X11R6/lib" path included in
> R, and how do I remove it?  (and, if necessary, how do I put it back
> afterwards?)
> 
> Also, in case it is needed, here is what typing "library(rgl)" returns in R:
> 
>> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>>         unable to load shared library
>> "/usr/local/lib/R/library/rgl/libs/rgl.so":
>>   dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
>> _glArrayElement
>> _glBegin
>> _glBindTexture
>> _glBitmap
>> _glBlendFunc
>> _glCallList
>> _glCallLists
>> _glClear
>> _glClearColor
>> _glClearDepth
>> _glColor3f
>> _glColor4fv
>> _glColor4ubv
>> _glColorMaterial
>> _glColorPointe
>> Error in library(rgl) : .First.lib failed
> 
> Any help would be very much appreciated.  Also, apologies for sending out
> two messages asking the same question in such a short span of time, but I
> realized after sending that I did not include all of the relevant
> information in the first.
> 
> Matt
> 
> 
> Guide! http://dollar.msn.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Jul  1 19:06:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Jul 2004 18:06:56 +0100 (BST)
Subject: [R] Seg. faults in mapthin (in package maps!)
In-Reply-To: <20040701165524.A27A3400A0@omta16.mta.everyone.net>
Message-ID: <Pine.LNX.4.44.0407011801230.1824-100000@gannet.stats>

You are on a 64-bit architecture and the C interface is declared as

void mapthin(x, y, n, delta, symmetric)
     double *x, *y, *delta;
     long *n, *symmetric;

R's integer type is int, not long, but they are the same on a 32-bit 
platform.

I am pretty sure that changing long to int will fix this.

There are a few other quirks, and I would check some of the other uses of 
`long' in the C sources.

On Thu, 1 Jul 2004, Kevin Bartz wrote:

> Hi everyone! I know segmentation faults are awfully hard to diagnose, but
> I'm experiencing a fairly regular pattern of seg. faults when plotting using
> map in the maps package. Starting R fresh, I run:
> 
> require(maps)
> for (i in 1:50) {
>   cat(i, "\n")
>   map("state")
> }
> 
> I always get the same result:
> 
> 1 
> 2 
> 3 
> 4 
> 5 
> 
> Process R segmentation fault at Thu Jul  1 09:07:39 2004
> 
> With some browsering, I've zeroed in on the source of the segmentation
> fault: map's call to mapthin. Funny thing is, when I comment out the call to
> mapthin, everything works consistently, without a hitch, and with no
> apparent difference in the map.
> 
> Still, I'd rather work with the package the way it was built. I must be
> losing something by cutting out the call to mapthin. 
> 
> I was wondering if anyone has any ideas. I've never had a segmentation fault
> before on this particular machine, but these few lines always produce the
> same unfortunate result. Has anyone else experienced segmentation faults
> plotting using map in the maps package? Is there any way I might rectify it?
> I'm on SuSE Linux, by the way, with:
> 
> > version
>          _                       
> platform x86_64-unknown-linux-gnu
> arch     x86_64                  
> os       linux-gnu               
> system   x86_64, linux-gnu       
> status   alpha                   
> major    1                       
> minor    9.1                     
> year     2004                    
> month    06                      
> day      13                      
> language R                       
> 
> Thanks for any help you can provide,
> 
> Kevin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kbartz at loyaltymatrix.com  Thu Jul  1 19:18:36 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Thu, 1 Jul 2004 10:18:36 -0700
Subject: [R] Seg. faults in mapthin (in package maps!)
In-Reply-To: <Pine.LNX.4.44.0407011801230.1824-100000@gannet.stats>
Message-ID: <20040701172340.AFD1440086@omta16.mta.everyone.net>

Dr. Ripley, you are the master. That fix worked like a charm! All the way to
50, with no problems. Thanks again,

Kevin

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Thursday, July 01, 2004 10:07 AM
To: Kevin Bartz
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Seg. faults in mapthin (in package maps!)

You are on a 64-bit architecture and the C interface is declared as

void mapthin(x, y, n, delta, symmetric)
     double *x, *y, *delta;
     long *n, *symmetric;

R's integer type is int, not long, but they are the same on a 32-bit 
platform.

I am pretty sure that changing long to int will fix this.

There are a few other quirks, and I would check some of the other uses of 
`long' in the C sources.

On Thu, 1 Jul 2004, Kevin Bartz wrote:

> Hi everyone! I know segmentation faults are awfully hard to diagnose, but
> I'm experiencing a fairly regular pattern of seg. faults when plotting
using
> map in the maps package. Starting R fresh, I run:
> 
> require(maps)
> for (i in 1:50) {
>   cat(i, "\n")
>   map("state")
> }
> 
> I always get the same result:
> 
> 1 
> 2 
> 3 
> 4 
> 5 
> 
> Process R segmentation fault at Thu Jul  1 09:07:39 2004
> 
> With some browsering, I've zeroed in on the source of the segmentation
> fault: map's call to mapthin. Funny thing is, when I comment out the call
to
> mapthin, everything works consistently, without a hitch, and with no
> apparent difference in the map.
> 
> Still, I'd rather work with the package the way it was built. I must be
> losing something by cutting out the call to mapthin. 
> 
> I was wondering if anyone has any ideas. I've never had a segmentation
fault
> before on this particular machine, but these few lines always produce the
> same unfortunate result. Has anyone else experienced segmentation faults
> plotting using map in the maps package? Is there any way I might rectify
it?
> I'm on SuSE Linux, by the way, with:
> 
> > version
>          _                       
> platform x86_64-unknown-linux-gnu
> arch     x86_64                  
> os       linux-gnu               
> system   x86_64, linux-gnu       
> status   alpha                   
> major    1                       
> minor    9.1                     
> year     2004                    
> month    06                      
> day      13                      
> language R                       
> 
> Thanks for any help you can provide,
> 
> Kevin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sigma at consultoresestadisticos.com  Thu Jul  1 19:36:36 2004
From: sigma at consultoresestadisticos.com (Carlos J. Gil Bellosta)
Date: Thu, 01 Jul 2004 19:36:36 +0200
Subject: [R] write.table() performance.
Message-ID: <40E44BA4.30306@consultoresestadisticos.com>

Dear r-helpers,

I know that there has already been enough questions on IO performance 
these last days, but I came accross the following situation today. I was 
comparing the performance of R with that of SAS's Risk Dimensions at 
generating random "scenarios". My dataset --all numeric entries-- would 
nicely fit into RAM and R would outperform SAS until... I wanted to 
export the results to a .csv file using the write.table() function. For 
reference, this output file was of about 30MB.  Moreover, the memory 
needed by R would increase sharply during the writing process.

I had a look at the code for the write.table() function and I found out 
that, basically, what it does is to create a very long text string from 
the data using paste() and then to print it using writeLines(). Rprof() 
showed that writeLines() would only use a mere 3% of the computing time, 
the rest being taken almost entirely by paste().

There are two directions in which performance could potentially be improved:

1.- Writing speed.
2.- Memory usage.

Regarding memory usage, I thought that perhaps a little rewriting of the 
write.table() function could be considered: instead of writing in RAM a 
single long text string, with a little overhead, the data frame to be 
printed could be splitted into shorter, recyclable, chunks, then 
paste()-ing them into shorter "buffer" strings and print them 
sequentially into the the output file. (Note: I am a complete ignorant 
on R's memory recycling rules and this could perhaps not work as 
intended because of them).

Regarding speed considerations, I see little hope as long as the paste() 
function is implicitly called by write.table(). Most likely, its 
execution time scales linearly with the number of lines in the data 
frame, so splitting it would render no benefits. Are there any hints on 
how could a performance improvement (other than linking external, ad hoc 
C code) be achieved? Do we really need to go through parse()? Would it 
perhaps be beneficial to include in R some specialized functions that 
achieved high output performance for writing out, say, only numeric 
values (this happens to be the case for me most of the time)?

Sorry for the long posting.

Carlos J. Gil Bellosta



From umalvarez at fata.unam.mx  Thu Jul  1 19:45:06 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Thu, 1 Jul 2004 12:45:06 -0500 (CDT)
Subject: [R] RGL on Mac OS X
In-Reply-To: <BAY12-F114piacp6Q5B00028671@hotmail.com>
Message-ID: <Pine.LNX.4.44.0407011218370.13536-100000@athena.fata.unam.mx>

Hi!

I can't tell you much about the problem that you are describing below. 
However, I can tell you the following:

- I downloaded the R sources for 1.9.1

- I compiled R following the instructions of the RMacOS-FAQ

- Then, after launching R from a terminal with 'sudo R', I downloaded and 
install a bunch of libraries (rgl, among them) using 
'install.packages(c("library1","library2",etc))'. Everything went OK.

-Now, I usually launch my Xserver (from Apple) and then Emacs. Then, using 
ESS 5.2.0, I launch R from within Emacs. If I type on the R console 
'library(rgl); demo(rgl)', the demo runs smoothly. On the other hand, if I 
launch the carbon GUI of R (from the /Applications folder) the result is 
the same, everything is OK. 

I'm using Mac OS 10.3.4, with the Developer tools and Xserver installed, 
and fink 0.7.0.cvs on an iBook G3.


Good look.



PS. I should tell you that I can't tell the same of the rgl library on a 
PC running Fedora 2. Maybe one of this days I'll make rgl run.



On Thu, 1 Jul 2004, Matthew Cohen wrote:

> 
> 
> I should have included in my last message a reference to the discussion of 
> this issue on the R developers' list:
> 
> http://maths.newcastle.edu.au/~rking/R/devel/03a/0982.html
> 
> Here, Simon Urbanek says:
> 
> >In Mac OS X native version: The R shell wrapper (bin/R) overrides default 
> >library search path with DYLD_LIBRARY_PATH and adds (among others) 
> >/usr/X11R6/lib. This causes problems when modules need (directly or 
> >indirectly) libraries from Apple's frameworks which are masked by X11. 
> >Examples for such packages are SJava and RGL. SJava needs JavaVM which in 
> >turn loads OpenGL framework. RGL needs the OpenGL framework directly. The 
> >problem is that specifying /usr/X11R6/lib in DYLD_LIBRARY_PATH forces the 
> >libGL to be loaded from the X11 directory instead of the OpenGL framework 
> >library. This crashes R due to missing symbols, since the modules must link 
> >to the OpenGL framework. In fact the OpenGL framework libraries load the 
> >X11 libraries internally (but not vice versa) - that's why the default load 
> >path is frameworks first then X11.
> 
> He suggests a temporary workaround:
> 
> >Currently a workaround is to remove /usr/X11R6/lib in R from the 
> >environment variable prior to loading those packages, but more general 
> >solution would be better imho. Is the /usr/X11R6/lib really necessary in 
> >the DYLD_LIBRARY_PATH for some older OS X versions? At least for OS X 10.2 
> >with Apple's X11 it is not necessary since X11 is already in the default 
> >load path.
> 
> Clearly the "more general solution" was never arrived at, given that the 
> problem still exists.  So how, exactly, do I go about implementing this 
> workaround?  In other words, where is the "usr/X11R6/lib" path included in 
> R, and how do I remove it?  (and, if necessary, how do I put it back 
> afterwards?)
> 
> Also, in case it is needed, here is what typing "library(rgl)" returns in R:
> 
> >Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >         unable to load shared library  
> >"/usr/local/lib/R/library/rgl/libs/rgl.so":
> >   dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
> >_glArrayElement
> >_glBegin
> >_glBindTexture
> >_glBitmap
> >_glBlendFunc
> >_glCallList
> >_glCallLists
> >_glClear
> >_glClearColor
> >_glClearDepth
> >_glColor3f
> >_glColor4fv
> >_glColor4ubv
> >_glColorMaterial
> >_glColorPointe
> >Error in library(rgl) : .First.lib failed
> 
> Any help would be very much appreciated.  Also, apologies for sending out 
> two messages asking the same question in such a short span of time, but I 
> realized after sending that I did not include all of the relevant 
> information in the first.
> 
> Matt
> 
> 
> Guide! http://dollar.msn.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From pgoodman at nwifc.org  Thu Jul  1 19:54:01 2004
From: pgoodman at nwifc.org (Pam Goodman)
Date: Thu, 1 Jul 2004 10:54:01 -0700
Subject: [R] y-axis of lattice panels not printing to paper
Message-ID: <6031B4FBF1423E4B943AD7E070B3C0AD031F66@bluefin>

Greetings, 

I am printing lattice plots from the R-interface to a printer, and although the y-axes of the left-most panels are visable on the screen, they are not present on the paper when  there are multiple panels (ie, >1). 

For example:

trellis.device(bg='white')
histogram(~dbh, data=diameter.df)

###print to a printer from the R-interface by clicking the print button on the toolbar

The above prints fine. All axes intact. 

However, 
trellis.device(bg='white')
histogram(~dbh|species, data=diameter.df)

###print to a printer from the R-interface by clicking the print button on the main toolbar

This second example does not have y-axes for the left-most panels. 

There is at least one work-around. For example, if I copy/paste as a metafile into Word, the axes are present in the printed document. However, I'm currently in the EDA phase, it's relatively more convenient to print directly to the printer, because in reality I have several graphs I am printing in a loop:

trellis.device(bg='white')
for(i in 1:50){
 print(histogram(~dbh|species.c, data=eval(parse(text=site.names.sort[i])), 
 breaks=c(0,seq(4,92,by=2)), main=site.names.sort[i], type="density"))
dev.copy()
dev.print(device=win.print)
 }

All 50 of the plots lack the y-axes in the left-most panels. Also, I tested xyplot(), and I get the same behavior. 

How can I get the y-axes of the left-most panels to be printed to the page? 

Thanks in advance, 
Pam

####################################
Pam Goodman
Biometrian
Northwest Indian Fisheries Commission
6730 Martin Way E
Olympia, WA 98516
phone: 360-438-1180
http://www.nwifc.org/
####################################



From madrid at linuxmeeting.net  Thu Jul  1 19:58:50 2004
From: madrid at linuxmeeting.net (Daniele Medri)
Date: Thu, 1 Jul 2004 19:58:50 +0200
Subject: [R] BIC vz SBIC vz SIC
Message-ID: <200407011958.50538.madrid@linuxmeeting.net>

DeaRs,

I have a doubt about:
	BIC (Bayesian Information Criterion)
	SBIC (Schwartz Bayesian Informarion Criterion)
	SIC (Schwartz Information Criterion)
In many references these are know as the same (eg. stepAIC() function) but I 
just found a SAS8.2 output that show either the BIC and SIC values for a 
logistic regression.. simillary values but different.

1) question: What are the differences?

2) question: alwasy on BIC, from stepAIC() function help page I found a 
"k=log(n)" argument to add. Since that produce an error, is there a way to 
found the "n" dinamically? Why don't add a "k=AIC" or "k=BIC" or something 
simillary?

Thanks in advance,

Bye
-- 
Daniele Medri



From madrid at linuxmeeting.net  Thu Jul  1 20:31:53 2004
From: madrid at linuxmeeting.net (Daniele Medri)
Date: Thu, 1 Jul 2004 20:31:53 +0200
Subject: [R] BIC vz SBIC vz SIC
In-Reply-To: <200407011958.50538.madrid@linuxmeeting.net>
References: <200407011958.50538.madrid@linuxmeeting.net>
Message-ID: <200407012031.53376.madrid@linuxmeeting.net>

Alle 19:58, gioved?? 1 luglio 2004, Daniele Medri ha scritto:
> DeaRs,
>
> I have a doubt about:
> 	BIC (Bayesian Information Criterion)
> 	SBIC (Schwartz Bayesian Informarion Criterion)
> 	SIC (Schwartz Information Criterion)
> In many references these are know as the same (eg. stepAIC() function) but
> I just found a SAS8.2 output that show either the BIC and SIC values for a
> logistic regression.. simillary values but different.
>
> 1) question: What are the differences?

Kevin Kuan (University of Michigan)  turn on the light!

AIC = nlog(SSE/n) + 2k

BIC = nlog(SSE/n) + 2(k+2)(n/s^2) - 2(ns^2/SSE)^2

SBIC = nlog(SSE/n) + klog(n)

SIC = [(n-k-2)/2]log(SSE) + (k/2)log(n) + (1/2)log(det[X'X])

Dear Prof. Ripley (maintainer of stepAIC() function) is there a way to 
implement a generic function for these criterions or add these to stepAIC k 
value in a way to be "easy-daily-use"? Thank you.

Bye

-- 
Daniele Medri



From r-eugenesalinas at comcast.net  Thu Jul  1 20:47:30 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Thu, 01 Jul 2004 14:47:30 -0400
Subject: [R] product of chi-sq distributions
Message-ID: <40E45C42.6030500@comcast.net>

Hi,

Does anyone know what the expectation of the product of two chi-squares 
distributions is? Is the product of two chi-squared distributions 
anything useful (as in a nice distribution)?

thanks, eugene.



From r-eugenesalinas at comcast.net  Thu Jul  1 20:51:31 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Thu, 01 Jul 2004 14:51:31 -0400
Subject: [R] product of two chi-squared
Message-ID: <40E45D33.7070808@comcast.net>

Hi,

Does anyone know what the expectation of the product of two chi-squares 
distributions is? Is the product of two chi-squared distributions 
anything useful (as in a nice distribution)?

thanks, eugene.



From GPetris at uark.edu  Thu Jul  1 21:03:06 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Thu, 1 Jul 2004 14:03:06 -0500 (CDT)
Subject: [R] product of two chi-squared
In-Reply-To: <40E45D33.7070808@comcast.net> (r-eugenesalinas@comcast.net)
References: <40E45D33.7070808@comcast.net>
Message-ID: <200407011903.i61J36Q0015750@definetti.uark.edu>


There is not enough information here: you need to know the joint
distribution of the two. If they are independent, the expectation of
the product is just the product of expectations - as any elementary
textbook will tell you.

Giovanni

> Date: Thu, 01 Jul 2004 14:51:31 -0400
> From: "Eugene Salinas (R)" <r-eugenesalinas at comcast.net>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US;	rv:1.6b)
>  Gecko/20031205 Thunderbird/0.4
> 
> Hi,
> 
> Does anyone know what the expectation of the product of two chi-squares 
> distributions is? Is the product of two chi-squared distributions 
> anything useful (as in a nice distribution)?
> 
> thanks, eugene.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From kkelley at nd.edu  Thu Jul  1 21:23:16 2004
From: kkelley at nd.edu (Ken Kelley)
Date: Thu, 1 Jul 2004 14:23:16 -0500
Subject: [R] Individual log likelihoods of nlsList objects.
Message-ID: <001701c45fa0$dc5e7340$45b74a81@ND.EDU>

Hello all.

I was wondering if the logLike.nls() and logLike.nlme() functions are still
being used. Neither function seems to be available in the most recent
release of R (1.9.1). The following is contained in the help file for
logLik(): "classes which already have methods for this function include:
'glm', 'lm', 'nls' and 'gls', 'lme' and others in package 'nlme'." Thus, I
was expecting that logLik.nls() and logLik.nlme() could be used for objects
of the nls and nlme class, respectively. Are these functions no longer
needed because logLike() subsumes logLike.nls() and logLike.nlme() as
special cases? Did/does logLike.nls() and logLike.nlme() have any advantages
above and beyond logLike() when applying them to nls and nlme objects? 

On a related note, is there a way to get the log likelihoods of each
individual from an nlsList object? 

On p. 349 of Pinheiro and Bates (2000) the logLik() function is said to give
the sum of the individual nls log-likelihoods. However,
logLike(some.nlsList.object) does not work for me (even when there are no
NAs). Any ideas?

Thanks for any thoughts or feedback. Have a good day,
Ken



From andy_liaw at merck.com  Thu Jul  1 21:27:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 1 Jul 2004 15:27:29 -0400
Subject: [R] list structure question
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FC4@usrymx25.merck.com>

Here's a test:

> n <- 1e4 
> m <- 100
> x <- lapply(1:m, function(...) rnorm(n))
> gc(); system.time(ans1 <- rowMeans(as.data.frame(x))) 
          used (Mb) gc trigger (Mb)
Ncells  432336 23.1     818163 43.7
Vcells 1125819  8.6    5012280 38.3
[1] 7.43 0.03 7.61 0.00 0.00
> gc(); system.time(ans2 <- rowMeans(do.call("cbind", x)))
          used (Mb) gc trigger (Mb)
Ncells  442338 23.7     818163 43.7
Vcells 1155810  8.9    6821883 52.1
[1] 0.03 0.00 0.03 0.00 0.00
> all(ans1 == ans2)
[1] TRUE

HTH,
Andy


> From: Rajarshi Guha
> 
> Hi,
>   I have a list in which element is a vector (all of the same 
> length and
> all numeric). I want to find the mean of the first elements of the
> vectors, the mean of the second elements of the vectors and so on.
> 
> Currently I convert the list to a data.frame and apply rowMeans(). But
> is there a way to to do this directly on the list? I seem to recall a
> post in which there was such a function (or expression) but I 
> just cant
> seem to find it.
> 
> Could somebody point me in the right direction?
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> Despite the high cost of living, it remains popular.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From deepayan at cs.wisc.edu  Thu Jul  1 21:40:44 2004
From: deepayan at cs.wisc.edu (Deepayan Sarkar)
Date: Thu,  1 Jul 2004 14:40:44 -0500
Subject: [R] y-axis of lattice panels not printing to paper
In-Reply-To: <6031B4FBF1423E4B943AD7E070B3C0AD031F66@bluefin>
References: <6031B4FBF1423E4B943AD7E070B3C0AD031F66@bluefin>
Message-ID: <1088710844.40e468bc4e7d9@www-auth.cs.wisc.edu>

Quoting Pam Goodman <pgoodman at nwifc.org>:

> Greetings, 
> 
> I am printing lattice plots from the R-interface to a printer, and although
> the y-axes of the left-most panels are visable on the screen, they are not
> present on the paper when  there are multiple panels (ie, >1). 
> 
> For example:
> 
> trellis.device(bg='white')
> histogram(~dbh, data=diameter.df)
> 
> ###print to a printer from the R-interface by clicking the print button on
> the toolbar
> 
> The above prints fine. All axes intact. 
> 
> However, 
> trellis.device(bg='white')
> histogram(~dbh|species, data=diameter.df)
> 
> ###print to a printer from the R-interface by clicking the print button on
> the main toolbar
> 
> This second example does not have y-axes for the left-most panels. 
> 
> There is at least one work-around. For example, if I copy/paste as a metafile
> into Word, the axes are present in the printed document. However, I'm
> currently in the EDA phase, it's relatively more convenient to print directly
> to the printer, because in reality I have several graphs I am printing in a
> loop:
> 
> trellis.device(bg='white')
> for(i in 1:50){
>  print(histogram(~dbh|species.c, data=eval(parse(text=site.names.sort[i])), 
>  breaks=c(0,seq(4,92,by=2)), main=site.names.sort[i], type="density"))
> dev.copy()
> dev.print(device=win.print)
>  }
> 
> All 50 of the plots lack the y-axes in the left-most panels. Also, I tested
> xyplot(), and I get the same behavior. 
> 
> How can I get the y-axes of the left-most panels to be printed to the page? 

I have no idea what the problem is. Might it have something to do with paper
size? Does changing the size of your screen devices/win.print help?

I should mention that this is probably not a good way to print lattice graphs.
The settings for screen devices are not suitable for printing. I think there
are also more general issues with converting output of one device to another (I
don't understand all the details). In this situation, I would use 

trellis.device(pdf, file = "foo.pdf")
for(i in 1:50){
  print(histogram(~dbh|species.c, data=eval(parse(text=site.names.sort[i])), 
  breaks=c(0,seq(4,92,by=2)), main=site.names.sort[i], type="density"))
  }
dev.off()

and then print the PDF file.

Deepayan



From ripley at stats.ox.ac.uk  Thu Jul  1 22:34:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Jul 2004 21:34:27 +0100 (BST)
Subject: [R] Individual log likelihoods of nlsList objects.
In-Reply-To: <001701c45fa0$dc5e7340$45b74a81@ND.EDU>
Message-ID: <Pine.LNX.4.44.0407012119000.5526-100000@gannet.stats>

The function is logLik, not logLike!  Try

> library(nlme)
> methods("logLik")
 [1] logLik.Arima*        logLik.corStruct*    logLik.glm*         
 [4] logLik.gls*          logLik.glsStruct*    logLik.gnls*        
 [7] logLik.gnlsStruct*   logLik.lm*           logLik.lme*         
[10] logLik.lmeStruct*    logLik.lmeStructInt* logLik.lmList*      
[13] logLik.nls*          logLik.reStruct*     logLik.varComb*     
[16] logLik.varFunc*     

    Non-visible functions are asterisked

so logLik.nls is still being used.

On Thu, 1 Jul 2004, Ken Kelley wrote:

> I was wondering if the logLike.nls() and logLike.nlme() functions are still
> being used. Neither function seems to be available in the most recent
> release of R (1.9.1). 

I suspect you don't understand how R looks for them.  Have you read the
article on namespaces in R-News?  Do you know what getAnywhere() does? The
"nls" method for function logLik is not necessarily the same thing as a
function logLik.nls, and even if it is, that function is not necessarily
visible to the user (as distinct to the function logLik).

> The following is contained in the help file for logLik(): "classes which
> already have methods for this function include: 'glm', 'lm', 'nls' and
> 'gls', 'lme' and others in package 'nlme'." 

NB: NO mention of "nlme" fits.

> Thus, I was expecting that logLik.nls() and logLik.nlme() could be used
> for objects of the nls and nlme class, respectively.

Why do you expect so?  It doesn't even mention the "nlme" class. There is
no logLik.nlme, and never was. (As nlme does not do exact ML fitting, it
is not going to be able to calculate a likelihood without doing
integration which it does not do. What nlme does is ML in a local linear
approximation.)

> Are these functions no longer needed because logLike() subsumes
> logLike.nls() and logLike.nlme() as special cases? Did/does
> logLike.nls() and logLike.nlme() have any advantages above and beyond
> logLike() when applying them to nls and nlme objects?

Please do read up about methods, method dispatch and namespaces.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Thu Jul  1 22:48:09 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 01 Jul 2004 13:48:09 -0700
Subject: [R] product of two chi-squared
In-Reply-To: <200407011903.i61J36Q0015750@definetti.uark.edu>
References: <40E45D33.7070808@comcast.net>
	<200407011903.i61J36Q0015750@definetti.uark.edu>
Message-ID: <40E47889.9030801@pdf.com>

      Assuming independence, the expectation of a product is the product 
of the expectations.  From this you could easily get moments of all 
orders and thence the moment generating function or characteristic 
function.  By direct computation (or consulting Johnson and Kotz, 
Distributions in Statistics-1, ch. 17), we see that the chi-square is 
just a gamma with alpha = df/2 and scale = 2, and for the gamma 
distribution, the r-th moment is

      E(X^r) = gamma(alpha+r)/gamma(alpha) = 
alpha*(alpha+1)*...*(alpha+r-1). 

      Therefore, the r-th moment of the product of two chi-squares with 
the same number of degrees of freedom is just the square of this 
expression.  This same approach can be used to obtain moments of all 
orders for products of an arbitrary number of chi-squares with different 
numbers of degrees of freedom. 

      Somewhat more generally, if the two chi-squares arose in the same 
linear model context, if they are NOT independent, then I might expect 
them to be something like (X1+X2) and (X2+X3), where X1, X2, and X3 are 
independent.  In that case, the above rule could still be used to easily 
get the expected value and variance, plus (with more effort) moments of 
higher order. 

      Beyond that, I know of no general result about products of 
chi-squares (even when they are independent).  I just did a search on 
"querry.statindex.org" for "product of chi-square" and got nothing.  
When I searched for "product of gamma", I got the following: 

O'Brien, Robert and Sinha, Bimal K. (1993)
On shortest confidence intervals for product of gamma means
Calcutta Statistical Association Bulletin, 43, 181-190

Rukhin, Andrew L. and Sinha, Bimal K. (1991)
Decision-theoretic estimation of the product of gamma scales and 
generalized variance
Calcutta Statistical Association Bulletin, 40, 257-265
Keywords: Admissibility

      I don't know if these articles would help you, but they might. 

      spencer graves

Giovanni Petris wrote:

>There is not enough information here: you need to know the joint
>distribution of the two. If they are independent, the expectation of
>the product is just the product of expectations - as any elementary
>textbook will tell you.
>
>Giovanni
>
>  
>
>>Date: Thu, 01 Jul 2004 14:51:31 -0400
>>From: "Eugene Salinas (R)" <r-eugenesalinas at comcast.net>
>>Sender: r-help-bounces at stat.math.ethz.ch
>>Precedence: list
>>User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US;	rv:1.6b)
>> Gecko/20031205 Thunderbird/0.4
>>
>>Hi,
>>
>>Does anyone know what the expectation of the product of two chi-squares 
>>distributions is? Is the product of two chi-squared distributions 
>>anything useful (as in a nice distribution)?
>>
>>thanks, eugene.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
>>    
>>
>
>  
>



From maechler at stat.math.ethz.ch  Thu Jul  1 23:12:31 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Jul 2004 23:12:31 +0200
Subject: [R] Individual log likelihoods of nlsList objects.
In-Reply-To: <001701c45fa0$dc5e7340$45b74a81@ND.EDU>
References: <001701c45fa0$dc5e7340$45b74a81@ND.EDU>
Message-ID: <16612.32319.383824.128299@gargle.gargle.HOWL>

>>>>> "Ken" == Ken Kelley <kkelley at nd.edu>
>>>>>     on Thu, 1 Jul 2004 14:23:16 -0500 writes:

    Ken> Hello all.
    Ken> I was wondering if the logLike.nls() and logLike.nlme() functions are still
    Ken> being used. 
no, but the correctly spelled ones,   logLik.nls and logLik.nlme
are

    Ken> Neither function seems to be available in the most recent
    Ken> release of R (1.9.1). 

how do you know?

    Ken> The following is contained in the help file for
    Ken> logLik(): "classes which already have methods for this
    Ken> function include: 'glm', 'lm', 'nls' and 'gls', 'lme'
    Ken> and others in package 'nlme'." 

Hence do rather believe the documentation ....

    Ken> Thus, I was expecting
    Ken> that logLik.nls() and logLik.nlme() could be used for
    Ken> objects of the nls and nlme class, respectively. 

They *are* used whenever you (or your code indirectly) call
logLik(.) on  "nls" or "nlme" objects respectively.

You were never to call these directly, and you this has been
discouraged a bit more as a side effect of the introduction of
name spaces for all "core" and recommended (and quite a few more
CRAN and bioconductor) packages.

You definitely need to learn about Classes and Methods
("S3" in this case) in R {or the S language in general},
and read the article about "Namespaces" in R-news, or (more
technical), Luke Tierney's pages on this.

If you want to see them use, e.g.,

getAnywhere("logLik.nls")

    Ken> Are these functions no longer needed because logLike()
    Ken> subsumes logLike.nls() and logLike.nlme() as special
    Ken> cases? Did/does logLike.nls() and logLike.nlme() have
    Ken> any advantages above and beyond logLike() when applying
    Ken> them to nls and nlme objects?

    Ken> On a related note, is there a way to get the log likelihoods of each
    Ken> individual from an nlsList object? 

    Ken> On p. 349 of Pinheiro and Bates (2000) the logLik() function is said to give
    Ken> the sum of the individual nls log-likelihoods. However,
    Ken> logLike(some.nlsList.object) does not work for me (even when there are no
    Ken> NAs). Any ideas?

if you are insisting on typo-ing you will have more problems
with all versions of S  ;-)
or did you try logLik( <...> ) ?

In any case use, (small) reproducible examples for these.
Have you read the posting guide, mentioned at the tail of this message?

Regards,
Martin



From ray at mcs.vuw.ac.nz  Thu Jul  1 23:24:33 2004
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Fri, 2 Jul 2004 09:24:33 +1200 (NZST)
Subject: [R] Seg. faults in mapthin (in package maps!)
Message-ID: <200407012124.i61LOXsb018812@tahi.mcs.vuw.ac.nz>

> From: "Kevin Bartz" <kbartz at loyaltymatrix.com>
> Date: Thu, 1 Jul 2004 10:18:36 -0700
> 
> Dr. Ripley, you are the master. That fix worked like a charm! All the way to
> 50, with no problems. Thanks again,
> 
And all while I was asleep!   I'll submit a corrected maps package in a
couple of weeks, when I return from China (no guaranteed connection
where I'll be).

Ray Brownrigg



From Eric.Kort at vai.org  Thu Jul  1 23:59:10 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Thu, 1 Jul 2004 17:59:10 -0400
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
Message-ID: <74D0F0AB07F2E647A02D839ED79520F9208931@VAIEXCH02.vai.org>

Hello.  By way of background, I am running out of memory when attempting to normalize the data from 160 affymetrix microarrays using justRMA (from the affy package).  This is despite making 6 gigabytes of swap space available on our sgi irix machine (which has 2 gigabytes of ram).  I have seen in various discussions statements such as "you will need at least 6 gigabytes of memory to normalize that many chips", but my question is this:

I cannot set the memory limits of R (1.9.1) higher than 4 gigabytes as attempting to do so results in this message:

WARNING: --max-vsize=4098M=4098`M': too large and ignored

I experience this both on my windows box (on which I cannot allocate more than 4 gigabytes of swap space anyway), and on an the above mentioned sgi irix machine (on which I can).  In view of that, I do not see what good it does to make > 4 gigabytes of ram+swap space available.  Does this mean 4 gigabytes is the absolute upper limit of R's memory usage...or perhaps 8 gigabytes since you can set both the stack and the heap size to 4 gigabytes?

Thanks,
Eric


This email message, including any attachments, is for the so...{{dropped}}



From andy_liaw at merck.com  Fri Jul  2 00:07:13 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 1 Jul 2004 18:07:13 -0400
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FC8@usrymx25.merck.com>

Did you compile R as 64-bit executable on the Irix?  If not, R will be
subjected to the 4GB limit of 32-bit systems.

Search the archive for `Opteron' and you'll see that the limit is not 4GB,
for 64-bit executables.

Andy

> From:  Kort, Eric
> 
> Hello.  By way of background, I am running out of memory when 
> attempting to normalize the data from 160 affymetrix 
> microarrays using justRMA (from the affy package).  This is 
> despite making 6 gigabytes of swap space available on our sgi 
> irix machine (which has 2 gigabytes of ram).  I have seen in 
> various discussions statements such as "you will need at 
> least 6 gigabytes of memory to normalize that many chips", 
> but my question is this:
> 
> I cannot set the memory limits of R (1.9.1) higher than 4 
> gigabytes as attempting to do so results in this message:
> 
> WARNING: --max-vsize=4098M=4098`M': too large and ignored
> 
> I experience this both on my windows box (on which I cannot 
> allocate more than 4 gigabytes of swap space anyway), and on 
> an the above mentioned sgi irix machine (on which I can).  In 
> view of that, I do not see what good it does to make > 4 
> gigabytes of ram+swap space available.  Does this mean 4 
> gigabytes is the absolute upper limit of R's memory 
> usage...or perhaps 8 gigabytes since you can set both the 
> stack and the heap size to 4 gigabytes?
> 
> Thanks,
> Eric
> 
> 
> This email message, including any attachments, is for the 
> so...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From Eric.Kort at vai.org  Fri Jul  2 00:14:49 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Thu, 1 Jul 2004 18:14:49 -0400
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
Message-ID: <74D0F0AB07F2E647A02D839ED79520F9D46B45@VAIEXCH02.vai.org>



>From: Liaw, Andy [mailto:andy_liaw at merck.com]
>
>Did you compile R as 64-bit executable on the Irix?  If not, R will be
>subjected to the 4GB limit of 32-bit systems.
>

No...

>Search the archive for `Opteron' and you'll see that the limit is not 4GB,
>for 64-bit executables.
>
>Andy

Excellent.  I will recompile and try again.

Thanks,
Eric

>> From:  Kort, Eric
>> 
>> Hello.  By way of background, I am running out of memory when 
>> attempting to normalize the data from 160 affymetrix 
>> microarrays using justRMA (from the affy package).  This is 
>> despite making 6 gigabytes of swap space available on our sgi 
>> irix machine (which has 2 gigabytes of ram).  I have seen in 
>> various discussions statements such as "you will need at 
>> least 6 gigabytes of memory to normalize that many chips", 
>> but my question is this:
>> 
>> I cannot set the memory limits of R (1.9.1) higher than 4 
>> gigabytes as attempting to do so results in this message:
>> 
>> WARNING: --max-vsize=4098M=4098`M': too large and ignored
>> 
>> I experience this both on my windows box (on which I cannot 
>> allocate more than 4 gigabytes of swap space anyway), and on 
>> an the above mentioned sgi irix machine (on which I can).  In 
>> view of that, I do not see what good it does to make > 4 
>> gigabytes of ram+swap space available.  Does this mean 4 
>> gigabytes is the absolute upper limit of R's memory 
>> usage...or perhaps 8 gigabytes since you can set both the 
>> stack and the heap size to 4 gigabytes?
>> 
>> Thanks,
>> Eric
>> 
>> 
This email message, including any attachments, is for the so...{{dropped}}



From pgoodman at nwifc.org  Fri Jul  2 00:24:03 2004
From: pgoodman at nwifc.org (Pam Goodman)
Date: Thu, 1 Jul 2004 15:24:03 -0700
Subject: [R] y-axis of lattice panels not printing to paper
Message-ID: <6031B4FBF1423E4B943AD7E070B3C0AD031F68@bluefin>

Deepayan,
Thanks for the suggestions for changing the size of the screen devices/win.print. They did not work for me. 

Mea culpa, I neglected in my orinal email to say that it's just the vertical line of the y-axis that does not print, not the entire y-axis and associated labels. Tick marks, tick labels, and the y-axis label print nicely.  Hopefully, this information will help isolate the problem (?). 

Also, I should note that our office has the option of printing through our network to an HP laser printer or to a photocopier, and both of these options produce the same problem, no vertical line of the y-axis. Our default paper size, which I have been using, is 8.5x11 inches. 

Thanks again!

Pam


-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan at cs.wisc.edu]
Sent: Thursday, July 01, 2004 12:41 PM
To: Pam Goodman
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] y-axis of lattice panels not printing to paper


Quoting Pam Goodman <pgoodman at nwifc.org>:

> Greetings, 
> 
> I am printing lattice plots from the R-interface to a printer, and although
> the y-axes of the left-most panels are visable on the screen, they are not
> present on the paper when  there are multiple panels (ie, >1). 
> 
> For example:
> 
> trellis.device(bg='white')
> histogram(~dbh, data=diameter.df)
> 
> ###print to a printer from the R-interface by clicking the print button on
> the toolbar
> 
> The above prints fine. All axes intact. 
> 
> However, 
> trellis.device(bg='white')
> histogram(~dbh|species, data=diameter.df)
> 
> ###print to a printer from the R-interface by clicking the print button on
> the main toolbar
> 
> This second example does not have y-axes for the left-most panels. 
> 
> There is at least one work-around. For example, if I copy/paste as a metafile
> into Word, the axes are present in the printed document. However, I'm
> currently in the EDA phase, it's relatively more convenient to print directly
> to the printer, because in reality I have several graphs I am printing in a
> loop:
> 
> trellis.device(bg='white')
> for(i in 1:50){
>  print(histogram(~dbh|species.c, data=eval(parse(text=site.names.sort[i])), 
>  breaks=c(0,seq(4,92,by=2)), main=site.names.sort[i], type="density"))
> dev.copy()
> dev.print(device=win.print)
>  }
> 
> All 50 of the plots lack the y-axes in the left-most panels. Also, I tested
> xyplot(), and I get the same behavior. 
> 
> How can I get the y-axes of the left-most panels to be printed to the page? 

I have no idea what the problem is. Might it have something to do with paper
size? Does changing the size of your screen devices/win.print help?

I should mention that this is probably not a good way to print lattice graphs.
The settings for screen devices are not suitable for printing. I think there
are also more general issues with converting output of one device to another (I
don't understand all the details). In this situation, I would use 

trellis.device(pdf, file = "foo.pdf")
for(i in 1:50){
  print(histogram(~dbh|species.c, data=eval(parse(text=site.names.sort[i])), 
  breaks=c(0,seq(4,92,by=2)), main=site.names.sort[i], type="density"))
  }
dev.off()

and then print the PDF file.

Deepayan



From lauraholt_983 at hotmail.com  Fri Jul  2 01:49:34 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Thu, 01 Jul 2004 18:49:34 -0500
Subject: [R] [gently off topic]  arima seasonal question
Message-ID: <BAY12-F24lGVECooXMd00001981@hotmail.com>

Hello R People:

When using the arima function with the seasonal option, are the seasonal 
options only good for monthly and quarterly data, please?

Also, I believe that weekly and daily data are not appropriate for seasonal 
parm estimation via arima.

Is that correct, please?

Thanks,
Sincerely,
Laura Holt
mailto: lauraholt_983 at hotmail.com


download! http://toolbar.msn.click-url.com/go/onm00200413ave/direct/01/



From thchung at tgen.org  Fri Jul  2 01:52:24 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Thu, 1 Jul 2004 16:52:24 -0700
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
In-Reply-To: <74D0F0AB07F2E647A02D839ED79520F9208931@VAIEXCH02.vai.org>
References: <74D0F0AB07F2E647A02D839ED79520F9208931@VAIEXCH02.vai.org>
Message-ID: <B30C2054-CBB9-11D8-AA36-000A95B43CDE@tgen.org>

Hi, Eric.
It seems a little bit puzzling to me. Which Affymetrix chip do you use? 
The reason I'm asking this is that yesterday I was able to normalize 
150 HU-133A CEL files (containing 22283 probes) using R 1.9.1 in Mac OS 
X 10.3.3 with 1.5 GB memory. If your chip has more probes than this, 
then it must be understandable ...

On Jul 1, 2004, at 2:59 PM, Kort, Eric wrote:

> Hello.  By way of background, I am running out of memory when 
> attempting to normalize the data from 160 affymetrix microarrays using 
> justRMA (from the affy package).  This is despite making 6 gigabytes 
> of swap space available on our sgi irix machine (which has 2 gigabytes 
> of ram).  I have seen in various discussions statements such as "you 
> will need at least 6 gigabytes of memory to normalize that many 
> chips", but my question is this:
>
> I cannot set the memory limits of R (1.9.1) higher than 4 gigabytes as 
> attempting to do so results in this message:
>
> WARNING: --max-vsize=4098M=4098`M': too large and ignored
>
> I experience this both on my windows box (on which I cannot allocate 
> more than 4 gigabytes of swap space anyway), and on an the above 
> mentioned sgi irix machine (on which I can).  In view of that, I do 
> not see what good it does to make > 4 gigabytes of ram+swap space 
> available.  Does this mean 4 gigabytes is the absolute upper limit of 
> R's memory usage...or perhaps 8 gigabytes since you can set both the 
> stack and the heap size to 4 gigabytes?
>
> Thanks,
> Eric
>
>
> This email message, including any attachments, is for the 
> so...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From hodgess at gator.uhd.edu  Fri Jul  2 02:02:07 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Thu, 1 Jul 2004 19:02:07 -0500
Subject: [R] priceIts problem
Message-ID: <200407020002.i62027p24397@gator.dt.uh.edu>

Dear R People:

In library(its), there is a command priceIts.

There is a problem with this command.  It is returning an error message:

> ibm1 <- priceIts(instrument="ibm",start="1998-01-01",quote="Open")
Error in download.file(url, destfile, method = method, quiet = quiet) : 
        cannot open URL `http://chart.yahoo.com/table.csv?s=ibm&a=0&b=01&c=1998&d=5&e=30&f=2004&g=d&q=q&y=0&z=ibm&x=.csv'
In addition: Warning message: 
cannot open: HTTP status was `404 Not Found' 
> 


This has been working fine until tonight.

Has anyone else seen this, please?
thanks in advance!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From ok at cs.otago.ac.nz  Fri Jul  2 02:22:21 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Fri, 2 Jul 2004 12:22:21 +1200 (NZST)
Subject: [R] naive question
Message-ID: <200407020022.i620MLcM241434@atlas.otago.ac.nz>

As part of a continuing thread on the cost of loading large
amounts of data into R,

"Vadim Ogranovich" <vograno at evafunds.com> wrote:
	R's IO is indeed 20 - 50 times slower than that of equivalent C code
	no matter what you do, which has been a pain for some of us.

I wondered to myself just how bad R is at reading,
when it is given a fair chance.  So I performed an experiment.
My machine (according to "Workstation Info") is a SunBlade 100 with 640MB
of physical memory running SunOS 5.9 Generic, according to fpversion this
is an Ultra2e with the CPU clock running at 500MHz and the main memory
clock running at 84MHz (wow, slow memory).  R.version is
platform sparc-sun-solaris2.9
arch     sparc               
os       solaris2.9          
system   sparc, solaris2.9   
status                       
major    1                   
minor    9.0                 
year     2004                
month    04                  
day      12                  
language R                   
and althnough this is a 64-bit machine, it's a 32-bit installation of R.

The experiment was this:
(1) I wrote a C program that generated 12500 rows of 800 columns, the
    numbers were integers 0..999,999,999 generated using drand48().
    These numbers were written using printf().  It is possible to do
    quite a bit better by avoiding printf(), but that would ruin the
    spirit of the comparison, which is to see what can be done with
    *straightforward* code using *existing* library functions.

    21.7 user + 0.9 system = 22.6 cpu seconds; 109 real seconds.

    The sizes were chosen to get 100MB; the actual size was
    12500 (lines) 10000000 (words) 100012500 (bytes)

(2) I wrote a C program that read these numbers using scanf("%d"); it    
    "knew" there were 800 numbers per row and 12500 numbers in all.
    Again, it is possible to do better by avoiding scanf(), but the
    point is to look at *straightforward* code.

    18.4 user + 0.6 system = 19.0 cpu seconds; 100 real seconds.

(3) I started R, played around a bit doing other things, then issued this
    command:

    > system.time(xx <- read.table("/tmp/big.dat", header=FALSE, quote="",
    + row.names=NULL, colClasses=rep("numeric",800), nrows=12500,
    + comment.char="")

    So how long _did_ it take to read 100MB on this machine?

    71.4 user + 2.2 system = 73.5 cpu seconds; 353 real seconds.

The result:  the R/C ratio was less than 4, whether you measure cpu time
or real time.  It certainly wasn't anywhere near 20-50 times slower.

Of course, *binary* I/O in C *would* be quite a bit faster:
(1') generate same integers but write a row at a time using fwrite():
     5 seconds cpu, 25 seconds real; 40 MB.

(2') read same integers a row at a time using fread()
     0.26 seconds cpu, 1 second real.

This would appear to more than justify "20-50 times slower", but reading
binary data and reading data in a textual representation are different
things, "less than 4 times slower" is the fairer measure.  However, it
does emphasise the usefulness of problem-specific bulk reading techniques.

I thought I'd give you another R measurement:
> system.time(xx <- read.table("/tmp/big.dat", header=FALSE))
But I got sick of waiting for it, and killed it after 843 cpu seconds,
3075 real seconds.  Without knowing how far it had got, one can say no
more than that this is at least 10 times slower than the more informed
call to read.table.

What this tells me is that if you know something about the data that
you _could_ tell read.table about, you do yourself no favour by keeping
read.table in the dark.  All those options are there for a reason, and
it *will* pay to use them.



From MSchwartz at MedAnalytics.com  Fri Jul  2 02:26:16 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 01 Jul 2004 19:26:16 -0500
Subject: [R] priceIts problem
In-Reply-To: <200407020002.i62027p24397@gator.dt.uh.edu>
References: <200407020002.i62027p24397@gator.dt.uh.edu>
Message-ID: <1088727976.3929.33.camel@localhost.localdomain>

On Thu, 2004-07-01 at 19:02, Erin Hodgess wrote:
> Dear R People:
> 
> In library(its), there is a command priceIts.
> 
> There is a problem with this command.  It is returning an error message:
> 
> > ibm1 <- priceIts(instrument="ibm",start="1998-01-01",quote="Open")
> Error in download.file(url, destfile, method = method, quiet = quiet) : 
>         cannot open URL `http://chart.yahoo.com/table.csv?s=ibm&a=0&b=01&c=1998&d=5&e=30&f=2004&g=d&q=q&y=0&z=ibm&x=.csv'
> In addition: Warning message: 
> cannot open: HTTP status was `404 Not Found' 
> > 
> 
> 
> This has been working fine until tonight.
> 
> Has anyone else seen this, please?
> thanks in advance!


It would appear that the URL at Yahoo has changed. If you try your URL
in a browser, you get the same 404 msg.

Going to the page for securing an IBM quote:

http://finance.yahoo.com/q/hp?s=IBM&a=00&b=1&c=1998&d=05&e=30&f=2004&g=d

The URL towards the bottom of the page for the CSV download is:

http://ichart.yahoo.com/table.csv?s=IBM&a=00&b=1&c=1998&d=05&e=30&f=2004&g=d&ignore=.csv

Note the 'ichart' as opposed to 'chart' in your error msg above. A quick
review of the R source in the 'its' package suggests that the base URL
for Yahoo is hard coded in the priceIts() function and the 'provider'
argument is not yet used.

I have copied Heywood Giles on this reply as an FYI and for
confirmation.

A short term workaround would be to edit the function's code using
fix(priceIts) and change the base URL in the function body as indicated
above. That seems to work for me with a quick check.

HTH,

Marc Schwartz



From MSchwartz at MedAnalytics.com  Fri Jul  2 02:35:05 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 01 Jul 2004 19:35:05 -0500
Subject: [R] priceIts problem
In-Reply-To: <1088727976.3929.33.camel@localhost.localdomain>
References: <200407020002.i62027p24397@gator.dt.uh.edu>
	<1088727976.3929.33.camel@localhost.localdomain>
Message-ID: <1088728505.3929.36.camel@localhost.localdomain>

On Thu, 2004-07-01 at 19:26, Marc Schwartz wrote:
> On Thu, 2004-07-01 at 19:02, Erin Hodgess wrote:
> > Dear R People:
> > 
> > In library(its), there is a command priceIts.
> > 
> > There is a problem with this command.  It is returning an error message:
> > 
> > > ibm1 <- priceIts(instrument="ibm",start="1998-01-01",quote="Open")
> > Error in download.file(url, destfile, method = method, quiet = quiet) : 
> >         cannot open URL `http://chart.yahoo.com/table.csv?s=ibm&a=0&b=01&c=1998&d=5&e=30&f=2004&g=d&q=q&y=0&z=ibm&x=.csv'
> > In addition: Warning message: 
> > cannot open: HTTP status was `404 Not Found' 
> > > 
> > 
> > 
> > This has been working fine until tonight.
> > 
> > Has anyone else seen this, please?
> > thanks in advance!

snip

> I have copied Heywood Giles on this reply as an FYI and for
> confirmation.

Apologies. That should be Giles Heywood. 

Marc



From petertgaffney at yahoo.com  Fri Jul  2 02:53:43 2004
From: petertgaffney at yahoo.com (Peter Gaffney)
Date: Thu, 1 Jul 2004 17:53:43 -0700 (PDT)
Subject: [R] linear models and colinear variables...
In-Reply-To: <20040630234717.GA22317@psych>
Message-ID: <20040702005343.63887.qmail@web60003.mail.yahoo.com>

Hi!

> When you do this, you are including all the
> interaction terms.
> The * indicates an interaction, as opposed to +.

In this particular case I need to do exactly this;
this is a study of antibiotic resistance - two of the
variables respectively are type of bacteria and
antibacterial agent. The evolutionary/epidemiological
behavior of each pairing of these factors is
different.  Can I remove some lower order terms; for
example, if I get rid of Bugtype:Usage.level.ofdrug
and Drugtype:Usage.level.of.drug will 
Bugtype:Drugtype:Usage.level.of.drug still be valid?

> If you select predictors on the basis of which ones
> are
> significant, then the final significance levels
> don't mean much,
> usually.  Remember, 1 out of 20 will be significant
> at .05 even
> if you are using random numbers.
> 

This is an excellent point; were I to proceed I would
need to select based strictly on removing from
collinear pairs or groups of explanatory variables,
probably according to an a priori established ordering
of classes of variables; ie B:D:U might be more
interesting than B:U or D:U or B:D:U:ICU, so remove
collinear variables from the latter three first,
irrespective of statistical significance.

Thanks for you help. :-)

-petertgaffney



From vkhurana at mail.nmfs.hawaii.edu  Fri Jul  2 03:12:18 2004
From: vkhurana at mail.nmfs.hawaii.edu (Vikram Khurana)
Date: Thu, 1 Jul 2004 15:12:18 -1000
Subject: [R] ROracle returning zero rows
In-Reply-To: <3D54769C.8080108@noaa.gov>
Message-ID: <003701c45fd1$a1a2a150$d5a410ac@swfc2.nmfs.gov>

Hi,

I have ROracle 0.5-5 installed on RH 7.2 machine trying to access Oracle
8.1.7 and DBI 0.1-8

I can get to Oracle using sqlplus & retrieve the data from the table "test".
However when I try doing the same using ROracle I get the following

> library("ROracle")
> ora = Oracle()
> con <-oraNewConnection(ora,username="user",password="pwd",
dbname="database SID")
> dbGetQuery(con,"select * from test where rownum<9")
[1] VESSEL_CODE   CRUISE_NUMBER EVENT_YEAR    EVENT_MONTH   EVENT_DAY
[6] MIN_OCTANT    MAX_OCTANT
<0 rows> (or 0-length row.names)
> dbListTables(con)
character(0)

When I do a dbGetQuery, I get just the column names of the table show up &
no data. There are 1000+ rows in this table in the database.
When I do a dbListTables, I get no results, which is not true

What is the issue here? Am I doing something wrong?

I have googled on it & found another person with the same problem, but no
solution.
Please cc me on the reply as I'm not subscribed to the R list.

Thanks for your time,
Vikram



From vograno at evafunds.com  Fri Jul  2 03:49:49 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Thu, 1 Jul 2004 18:49:49 -0700
Subject: [R] naive question
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A5568D09@phost015.EVAFUNDS.intermedia.net>

Richard,

 Thank you for the analysis. I don't think there is an inconsistency
between the factor of 4 you've found in your example and 20 - 50 I found
in my data. I guess the major cause of the difference lies with the
structure of your data set. Specifically, your test data set differs
from mine in two respects:
* you have fewer lines, but each line contains many more fields (12500 *
800 in your case and 3.8M * 10 in my)
* all of your data fields are doubles, not strings. I have a mixture of
doubles and strings.

I posted a more technical message to r-devel where I discussed possible
reasons for the IO slowness. One of them is that R is slow at making
strings. So if you try to read your data as strings,
colClasses=rep("character", 800), I'd guess you will see a very
different timing. Even simple reshaping of your matrix, say make it
(12500*80) rows by 10 columns, will considerably worsen it.
Please let me know the results if you do anything of the above.

In my message to r-devel you may also find some timing that supports my
estimates.

Thanks,
Vadim

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Richard A. O'Keefe
> Sent: Thursday, July 01, 2004 5:22 PM
> To: r-help at stat.math.ethz.ch
> Subject: RE: [R] naive question
> 
> As part of a continuing thread on the cost of loading large 
> amounts of data into R,
> 
> "Vadim Ogranovich" <vograno at evafunds.com> wrote:
> 	R's IO is indeed 20 - 50 times slower than that of 
> equivalent C code
> 	no matter what you do, which has been a pain for some of us.
> 
> I wondered to myself just how bad R is at reading, when it is 
> given a fair chance.  So I performed an experiment.
> My machine (according to "Workstation Info") is a SunBlade 
> 100 with 640MB of physical memory running SunOS 5.9 Generic, 
> according to fpversion this is an Ultra2e with the CPU clock 
> running at 500MHz and the main memory clock running at 84MHz 
> (wow, slow memory).  R.version is platform sparc-sun-solaris2.9
> arch     sparc               
> os       solaris2.9          
> system   sparc, solaris2.9   
> status                       
> major    1                   
> minor    9.0                 
> year     2004                
> month    04                  
> day      12                  
> language R                   
> and althnough this is a 64-bit machine, it's a 32-bit 
> installation of R.
> 
> The experiment was this:
> (1) I wrote a C program that generated 12500 rows of 800 columns, the
>     numbers were integers 0..999,999,999 generated using drand48().
>     These numbers were written using printf().  It is possible to do
>     quite a bit better by avoiding printf(), but that would ruin the
>     spirit of the comparison, which is to see what can be done with
>     *straightforward* code using *existing* library functions.
> 
>     21.7 user + 0.9 system = 22.6 cpu seconds; 109 real seconds.
> 
>     The sizes were chosen to get 100MB; the actual size was
>     12500 (lines) 10000000 (words) 100012500 (bytes)
> 
> (2) I wrote a C program that read these numbers using 
> scanf("%d"); it    
>     "knew" there were 800 numbers per row and 12500 numbers in all.
>     Again, it is possible to do better by avoiding scanf(), but the
>     point is to look at *straightforward* code.
> 
>     18.4 user + 0.6 system = 19.0 cpu seconds; 100 real seconds.
> 
> (3) I started R, played around a bit doing other things, then 
> issued this
>     command:
> 
>     > system.time(xx <- read.table("/tmp/big.dat", 
> header=FALSE, quote="",
>     + row.names=NULL, colClasses=rep("numeric",800), nrows=12500,
>     + comment.char="")
> 
>     So how long _did_ it take to read 100MB on this machine?
> 
>     71.4 user + 2.2 system = 73.5 cpu seconds; 353 real seconds.
> 
> The result:  the R/C ratio was less than 4, whether you 
> measure cpu time or real time.  It certainly wasn't anywhere 
> near 20-50 times slower.
> 
> Of course, *binary* I/O in C *would* be quite a bit faster:
> (1') generate same integers but write a row at a time using fwrite():
>      5 seconds cpu, 25 seconds real; 40 MB.
> 
> (2') read same integers a row at a time using fread()
>      0.26 seconds cpu, 1 second real.
> 
> This would appear to more than justify "20-50 times slower", 
> but reading binary data and reading data in a textual 
> representation are different things, "less than 4 times 
> slower" is the fairer measure.  However, it does emphasise 
> the usefulness of problem-specific bulk reading techniques.
> 
> I thought I'd give you another R measurement:
> > system.time(xx <- read.table("/tmp/big.dat", header=FALSE))
> But I got sick of waiting for it, and killed it after 843 cpu seconds,
> 3075 real seconds.  Without knowing how far it had got, one 
> can say no more than that this is at least 10 times slower 
> than the more informed call to read.table.
> 
> What this tells me is that if you know something about the 
> data that you _could_ tell read.table about, you do yourself 
> no favour by keeping read.table in the dark.  All those 
> options are there for a reason, and it *will* pay to use them.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From deepayan at stat.wisc.edu  Fri Jul  2 03:57:20 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 1 Jul 2004 20:57:20 -0500
Subject: [R] y-axis of lattice panels not printing to paper
In-Reply-To: <6031B4FBF1423E4B943AD7E070B3C0AD031F68@bluefin>
References: <6031B4FBF1423E4B943AD7E070B3C0AD031F68@bluefin>
Message-ID: <200407012057.20903.deepayan@stat.wisc.edu>

On Thursday 01 July 2004 17:24, Pam Goodman wrote:
> Deepayan,
> Thanks for the suggestions for changing the size of the screen
> devices/win.print. They did not work for me.
>
> Mea culpa, I neglected in my orinal email to say that it's just the
> vertical line of the y-axis that does not print, not the entire
> y-axis and associated labels. Tick marks, tick labels, and the y-axis
> label print nicely.  Hopefully, this information will help isolate
> the problem (?).

Ah, in that case this sounds like a bug that has been reported 
intermittently but never reproducibly. It's probably something in some 
device driver(s), but we haven't figured out the exact problem.

Have you checked if this happens with all multipanel plots, or is it 
just with your particular data? Could you create a small artificial 
dataset (along with plot commands) that shows this problem and send it 
to me? (This may or may not help, depending on whether the same 
behaviour is seen on other computers.)

Deepayan



From baron at psych.upenn.edu  Fri Jul  2 04:43:36 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 1 Jul 2004 22:43:36 -0400
Subject: [R] linear models and colinear variables...
In-Reply-To: <20040702005343.63887.qmail@web60003.mail.yahoo.com>
References: <20040630234717.GA22317@psych>
	<20040702005343.63887.qmail@web60003.mail.yahoo.com>
Message-ID: <20040702024336.GA1586@psych>

On 07/01/04 17:53, Peter Gaffney wrote:
>Hi!
>
>> When you do this, you are including all the
>> interaction terms.
>> The * indicates an interaction, as opposed to +.
>
>In this particular case I need to do exactly this;
>this is a study of antibiotic resistance - two of the
>variables respectively are type of bacteria and
>antibacterial agent. The evolutionary/epidemiological

Then you should use at most the interaction of every agent with
every germ.  Including all the interaction terms means that you
look at germ*germ and drug*drug interactions too.

>behavior of each pairing of these factors is
>different.  Can I remove some lower order terms; for
>example, if I get rid of Bugtype:Usage.level.ofdrug
>and Drugtype:Usage.level.of.drug will
>Bugtype:Drugtype:Usage.level.of.drug still be valid?

I don't think this example is "removing lower order terms," or
else I don't understand it.  I think it is what I was just
saying.  You would want something like (to use my terms),
germ1*drug1 + germ1*drug2 + ... + germN*drug(M-1) + germN*drugM.
Each of these would automatically include the relevant
first-order terms.  For example, germ1*drug1 would include germ1
and drug1 effects alone.  And I think you want those, if you are
really interested in the interaction.  Otherwise, what you think
is an interaction could just be a main effect.

But I really don't understand this setup.  It sounds like each
observation consists of a randomly chosen SET of germs and a SET
of drugs, so you can classify each data point in terms of the
presence or absence of each germ and the presence or absence of
each drug.  Is that it?  It isn't crazy, but it is unusual.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron



From ripley at stats.ox.ac.uk  Fri Jul  2 06:57:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Jul 2004 05:57:00 +0100 (BST)
Subject: [R] [gently off topic]  arima seasonal question
In-Reply-To: <BAY12-F24lGVECooXMd00001981@hotmail.com>
Message-ID: <Pine.LNX.4.44.0407020550230.6585-100000@gannet.stats>

arima() fits a seasonal ARIMA model.  I have no idea what `seasons' you 
have in mind, but they can be used for weekly effects in daily data, for 
example, and might also be appropriate for a yearly effect in weekly data 
(provided you have the same number of weeks each year and are not subject 
to the vagarities of holidays -- e.g. weekly abundance measures of 
animals).

This is answered in all good books on time series, including some of those 
referred to in ?arima.

On Thu, 1 Jul 2004, Laura Holt wrote:

> When using the arima function with the seasonal option, are the seasonal 
> options only good for monthly and quarterly data, please?
> 
> Also, I believe that weekly and daily data are not appropriate for seasonal 
> parm estimation via arima.
> 
> Is that correct, please?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From anne.piotet at urbanet.ch  Fri Jul  2 10:22:14 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Fri, 2 Jul 2004 10:22:14 +0200
Subject: [R] Reading and treating multiple files....
Message-ID: <004501c4600d$aeb02fc0$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040702/6e90a0ee/attachment.pl

From Eric.Kort at vai.org  Fri Jul  2 15:06:36 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Fri, 2 Jul 2004 09:06:36 -0400
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
Message-ID: <74D0F0AB07F2E647A02D839ED79520F9208933@VAIEXCH02.vai.org>

Yes, we are using the HGU-133plus2 chips with 50,000+ probes, and I suppose that the memory requirements increase geometrically as the chip size increases.
 
Thanks for your email...I can let you know if we have any success if you are interested for future reference.
 
-Eric

	-----Original Message----- 
	From: Tae-Hoon Chung [mailto:thchung at tgen.org] 
	Sent: Thu 7/1/2004 7:52 PM 
	To: Kort, Eric 
	Cc: r-help at stat.math.ethz.ch 
	Subject: Re: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
	
	

	Hi, Eric.
	It seems a little bit puzzling to me. Which Affymetrix chip do you use?
	The reason I'm asking this is that yesterday I was able to normalize
	150 HU-133A CEL files (containing 22283 probes) using R 1.9.1 in Mac OS
	X 10.3.3 with 1.5 GB memory. If your chip has more probes than this,
	then it must be understandable ...
	
	On Jul 1, 2004, at 2:59 PM, Kort, Eric wrote:
	
	> Hello.  By way of background, I am running out of memory when
	> attempting to normalize the data from 160 affymetrix microarrays using
	> justRMA (from the affy package).  This is despite making 6 gigabytes
	> of swap space available on our sgi irix machine (which has 2 gigabytes
	> of ram).  I have seen in various discussions statements such as "you
	> will need at least 6 gigabytes of memory to normalize that many
	> chips", but my question is this:
	>
	> I cannot set the memory limits of R (1.9.1) higher than 4 gigabytes as
	> attempting to do so results in this message:
	>
	> WARNING: --max-vsize=4098M=4098`M': too large and ignored
	>
	> I experience this both on my windows box (on which I cannot allocate
	> more than 4 gigabytes of swap space anyway), and on an the above
	> mentioned sgi irix machine (on which I can).  In view of that, I do
	> not see what good it does to make > 4 gigabytes of ram+swap space
	> available.  Does this mean 4 gigabytes is the absolute upper limit of
	> R's memory usage...or perhaps 8 gigabytes since you can set both the
	> stack and the heap size to 4 gigabytes?
	>
	> Thanks,
	> Eric
	>
	>
	> This email message, including any attachments, is for the
	> so...{{dropped}}
	>
	> ______________________________________________
	> R-help at stat.math.ethz.ch mailing list
	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
	> PLEASE do read the posting guide!
	> http://www.R-project.org/posting-guide.html
	>
	>
	Tae-Hoon Chung, Ph.D
	
	Post-doctoral Research Fellow
	Molecular Diagnostics and Target Validation Division
	Translational Genomics Research Institute
	1275 W Washington St, Tempe AZ 85281 USA
	Phone: 602-343-8724
	
	


This email message, including any attachments, is for the so...{{dropped}}



From r-eugenesalinas at comcast.net  Fri Jul  2 15:27:33 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Fri, 02 Jul 2004 09:27:33 -0400
Subject: [R] help computing a covariance
Message-ID: <40E562C5.4050308@comcast.net>

Hi everyone,

(This is related to my posting on chi-squared from a day ago. I have 
tried simulating this but I am still unable to calculate it analytically.)

Let y be an n times 1 vector of random normal variables mean zero 
variance 1 and x be an n times k vector of random normal variables mean 
zero variance 1. x and y are independent.

Then P is the projection matrix  P=x*inv(x'*x)*x'

I need to figure out the covariance
 
Cov ( y'*P*y , (A'*x'*y)^2 ) where A is a constant of dimension k times 1.

thanks, eugene.



From robin_gruna at hotmail.com  Fri Jul  2 15:41:42 2004
From: robin_gruna at hotmail.com (Robin Gruna)
Date: Fri, 2 Jul 2004 15:41:42 +0200
Subject: [R] Error:length of dimnames [2] not equal to array extent ?
Message-ID: <BAY2-DAV1DbfodiVRef00032f62@hotmail.com>

Hi everyone,
I have the following problem:
I want to perform a LDA with the function lda().
My data object mat.data is a matrix with dimensions

> dim(mat.data)
[1] 1228   44

and my grouping vector grp has length 1228:

> length(grp)
[1] 1228

Every time I call lda(), the following error message occurs:

> lda(mat.data,grp)
Error in lda.default(x, grouping, ...) : length of dimnames [2] not equal to
array extent

In order to find the error I created a matrix mat.test

mat.test<-matrix(1:500,nrow=1228,ncol=44)

with arbitrary entries an the same attributes as mat.data:

> dimnames(mat.test)
NULL

> dimnames(mat.data)
NULL

But with the test object mat.test there occurs no error !
Can somebody help me, this really makes me crazy,
thanks,
Robin



From rolf at math.unb.ca  Fri Jul  2 15:46:36 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 2 Jul 2004 10:46:36 -0300 (ADT)
Subject: [R] [gently off topic]  arima seasonal question
Message-ID: <200407021346.i62DkafQ006443@erdos.math.unb.ca>

The seasonal aspect of arima models allows, essentially, for a
special realtionship between X_t and X_{t+s} where s is the
``seasonality'' of the model.  It (``the model'') couldn't care less
what the time ***units*** are --- they could be weeks, quarters,
days, hours, microseconds, 1.14135*microseconds, ....  What matters
is:  Do you have reason to believe that there is a special
relationship between X_t and X_{t+s}???  If so, go for it.  If not,
don't.

Such relationships are ***most likely*** to arise in quarterly and
monthly data --- with s = 4 in the quarterly data, s = 12 in the
monthly data.  You could conceiveably get seasonality with s = 7 in
daily data; at a stretch with s = 30 (pretending all months are 30
days long ... a bit dubious).  You might (ah, well, sort of ....)
also have s = 365 seasonality in daily data, but such a large s is
unlikely to ``work'' very well.  You might get seasonality with s =
52 in weekly data.  (Dubious.)  You might get seasonality with s = 24
in hourly data.  U.s.w.

It might clarify your thinking to note that a seasonal ARIMA model is
just an ``ordinary'' ARIMA model with some coefficients constrained
to be 0 in an efficient way.  E.g.  a seasonal AR(1) s = 4 model is
the same as an ordinary (nonseasonal) AR(4) model with coefficients
theta_1, theta_2, and theta_3 constrained to be 0.  You can get the
same answer as from a seasonal model by using the ``fixed'' argument
to arima.  E.g.:

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
 > set.seed(42)
 > x <- arima.sim(list(ar=c(0,0,0,0.5)),300)
 > f1 <- arima(x,seasonal=list(order=c(1,0,0),period=4))
 > f2 <- arima(x,order=c(4,0,0),fixed=c(0,0,0,NA,NA),transform.pars=FALSE)
 > f1
   .
Coefficients:
        sar1  intercept
      0.4987    -0.0775
s.e.  0.0499     0.1051

sigma^2 estimated as 0.8536:  log likelihood = -402.51,  aic = 811.02

 > f2
   .
Coefficients:
      ar1  ar2  ar3     ar4  intercept
        0    0    0  0.4987    -0.0774
s.e.    0    0    0  0.0499     0.1051

sigma^2 estimated as 0.8536:  log likelihood = -402.51,  aic = 811.02
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

Hope this is a bit enlightening.

					cheers,

						Rolf Turner
						rolf at math.unb.ca

> Hello R People:
> 
> When using the arima function with the seasonal option, are the
> seasonal options only good for monthly and quarterly data, please?
> 
> Also, I believe that weekly and daily data are not appropriate for
> seasonal parm estimation via arima.
> 
> Is that correct, please?
> 
> Thanks,
> Sincerely,
> Laura Holt
> mailto: lauraholt_983 at hotmail.com



From fm3a004 at math.uni-hamburg.de  Fri Jul  2 16:00:31 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Fri, 2 Jul 2004 16:00:31 +0200 (MET DST)
Subject: [R] How to make eps out of a trellis graphic?
Message-ID: <Pine.GSO.3.95q.1040702155629.1738C-100000@sun11.math.uni-hamburg.de>

Hi list,

I produced a trellis graphic with qqnorm (R-package lattice, no changes in
graphical parameters were made).
1) The graphic uses some grey and some green colors and I would like to
have it black and white as usual.
2) I would like to produce an eps-file of it. Usually I do this with
something like

postscript("Rout.eps", horizontal=FALSE, onefile=FALSE,
           paper="special", height=8, width=8)
nr <- dev.cur()
dev.set(dev.prev())
dev.copy(which=nr)
dev.off(nr)
 
but this gives me an empty (plain white) eps-file this time.
So how to make an eps-figure out of my trellis plot?

Thanks,
Christian

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From deepayan at stat.wisc.edu  Fri Jul  2 16:05:29 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 2 Jul 2004 09:05:29 -0500
Subject: [R] Re: How to make eps out of a trellis graphic?
In-Reply-To: <Pine.GSO.3.95q.1040702155629.1738C-100000@sun11.math.uni-hamburg.de>
References: <Pine.GSO.3.95q.1040702155629.1738C-100000@sun11.math.uni-hamburg.de>
Message-ID: <200407020905.29429.deepayan@stat.wisc.edu>

On Friday 02 July 2004 09:00, Christian Hennig wrote:
> Hi list,
>
> I produced a trellis graphic with qqnorm (R-package lattice, no
> changes in graphical parameters were made).
> 1) The graphic uses some grey and some green colors and I would like
> to have it black and white as usual.
> 2) I would like to produce an eps-file of it. Usually I do this with
> something like
>
> postscript("Rout.eps", horizontal=FALSE, onefile=FALSE,
>            paper="special", height=8, width=8)
> nr <- dev.cur()
> dev.set(dev.prev())
> dev.copy(which=nr)
> dev.off(nr)
>
> but this gives me an empty (plain white) eps-file this time.
> So how to make an eps-figure out of my trellis plot?

Do something like

postscript("Rout.eps", horizontal=FALSE, onefile=FALSE,
           paper="special", height=8, width=8)
qqnorm(<whatever>)
dev.off()

Deepayan



From madrid at linuxmeeting.net  Fri Jul  2 16:21:03 2004
From: madrid at linuxmeeting.net (Daniele Medri)
Date: Fri, 2 Jul 2004 16:21:03 +0200
Subject: [R] BIC vz SBIC vz SIC
In-Reply-To: <200407011958.50538.madrid@linuxmeeting.net>
References: <200407011958.50538.madrid@linuxmeeting.net>
Message-ID: <200407021621.03438.madrid@linuxmeeting.net>


> 2) question: alwasy on BIC, from stepAIC() function help page I found a
> "k=log(n)" argument to add. Since that produce an error, is there a way to
> found the "n" dinamically? 

stepAIC(mydata.logistic, trace = F, k=log(nrow(mydata)))

-- 
Daniele Medri



From robin_gruna at hotmail.com  Fri Jul  2 16:38:45 2004
From: robin_gruna at hotmail.com (Robin Gruna)
Date: Fri, 2 Jul 2004 16:38:45 +0200
Subject: [R] Error:length of dimnames [2] not equal to array extent ?
Message-ID: <BAY2-DAV1433diWF5lQ00025b50@hotmail.com>

Hi everyone,
I have the following problem:
I want to perform a LDA with the function lda().
My data object mat.data is a matrix with dimensions

> dim(mat.data)
[1] 1228   44

and my grouping vector grp has length 1228:

> length(grp)
[1] 1228

Every time I call lda(), the following error message occurs:

> lda(mat.data,grp)
Error in lda.default(x, grouping, ...) : length of dimnames [2] not equal to
array extent

In order to find the error I created a matrix mat.test

mat.test<-matrix(1:500,nrow=1228,ncol=44)

with arbitrary entries an the same attributes as mat.data:

> dimnames(mat.test)
NULL

> dimnames(mat.data)
NULL

But with the test object mat.test there occurs no error !
Can somebody help me, this really makes me crazy,
thanks,
Robin



From pgilbert at bank-banque-canada.ca  Fri Jul  2 16:39:37 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 02 Jul 2004 10:39:37 -0400
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
In-Reply-To: <74D0F0AB07F2E647A02D839ED79520F9208933@VAIEXCH02.vai.org>
References: <74D0F0AB07F2E647A02D839ED79520F9208933@VAIEXCH02.vai.org>
Message-ID: <40E573A9.1090405@bank-banque-canada.ca>

It looks like you have R compiled as a 32 bit application, and you will 
need to compile it as a 64 bit application if you want to address more 
than 4G memory. I am not familiar with the sgi irix machine, but you can 
do this on many workstations that have processors with a 64 bit 
architecture and an OS that supports it.  The R-admin notes have some 
hints about how to do this for various platforms.

Paul Gilbert

Kort, Eric wrote:

>Yes, we are using the HGU-133plus2 chips with 50,000+ probes, and I suppose that the memory requirements increase geometrically as the chip size increases.
> 
>Thanks for your email...I can let you know if we have any success if you are interested for future reference.
> 
>-Eric
>
>	-----Original Message----- 
>	From: Tae-Hoon Chung [mailto:thchung at tgen.org] 
>	Sent: Thu 7/1/2004 7:52 PM 
>	To: Kort, Eric 
>	Cc: r-help at stat.math.ethz.ch 
>	Subject: Re: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
>	
>	
>
>	Hi, Eric.
>	It seems a little bit puzzling to me. Which Affymetrix chip do you use?
>	The reason I'm asking this is that yesterday I was able to normalize
>	150 HU-133A CEL files (containing 22283 probes) using R 1.9.1 in Mac OS
>	X 10.3.3 with 1.5 GB memory. If your chip has more probes than this,
>	then it must be understandable ...
>	
>	On Jul 1, 2004, at 2:59 PM, Kort, Eric wrote:
>	
>	> Hello.  By way of background, I am running out of memory when
>	> attempting to normalize the data from 160 affymetrix microarrays using
>	> justRMA (from the affy package).  This is despite making 6 gigabytes
>	> of swap space available on our sgi irix machine (which has 2 gigabytes
>	> of ram).  I have seen in various discussions statements such as "you
>	> will need at least 6 gigabytes of memory to normalize that many
>	> chips", but my question is this:
>	>
>	> I cannot set the memory limits of R (1.9.1) higher than 4 gigabytes as
>	> attempting to do so results in this message:
>	>
>	> WARNING: --max-vsize=4098M=4098`M': too large and ignored
>	>
>	> I experience this both on my windows box (on which I cannot allocate
>	> more than 4 gigabytes of swap space anyway), and on an the above
>	> mentioned sgi irix machine (on which I can).  In view of that, I do
>	> not see what good it does to make > 4 gigabytes of ram+swap space
>	> available.  Does this mean 4 gigabytes is the absolute upper limit of
>	> R's memory usage...or perhaps 8 gigabytes since you can set both the
>	> stack and the heap size to 4 gigabytes?
>	>
>	> Thanks,
>	> Eric
>	>
>	>
>	> This email message, including any attachments, is for the
>	> so...{{dropped}}
>	>
>	> ______________________________________________
>	> R-help at stat.math.ethz.ch mailing list
>	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>	> PLEASE do read the posting guide!
>	> http://www.R-project.org/posting-guide.html
>	>
>	>
>	Tae-Hoon Chung, Ph.D
>	
>	Post-doctoral Research Fellow
>	Molecular Diagnostics and Target Validation Division
>	Translational Genomics Research Institute
>	1275 W Washington St, Tempe AZ 85281 USA
>	Phone: 602-343-8724
>	
>	
>
>
>This email message, including any attachments, is for the so...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From HDoran at air.org  Fri Jul  2 16:58:47 2004
From: HDoran at air.org (Doran, Harold)
Date: Fri, 2 Jul 2004 10:58:47 -0400
Subject: [R] Problem in lme4
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7403E71E31@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040702/0d0439a1/attachment.pl

From ozric at web.de  Fri Jul  2 17:03:44 2004
From: ozric at web.de (Christian Schulz)
Date: Fri, 2 Jul 2004 17:03:44 +0200
Subject: [R] replace values but different replacement length
Message-ID: <200407021703.45368.ozric@web.de>

Hi,

have anybody a hint/help how it's possible replace i.e.
the NA values  from BL02DATE with  non-Missing 
values from BLOCKED  and vice versa. 
Both variables are with an id  in a 188.249 rows data.frame and
my fr function didn't count the NA's.

Many thanks 
Christian


>>fr(BL02DATE)
       Count Prcnt
1     140660  84.6 
2      25589  15.4 
Total 166249 100.0

>>fr(BLOCKED)
       Count Prcnt
1     151982  85.4 
2      25976  14.6 
Total 177958 100.0

>>match02$BL02DATE[is.na(match02$BL02DATE)] <-  match02$BLOCKED
Warning message: number of items to replace is not a multiple of
replacement length



From spencer.graves at pdf.com  Fri Jul  2 17:22:01 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 02 Jul 2004 08:22:01 -0700
Subject: [R] replace values but different replacement length
In-Reply-To: <200407021703.45368.ozric@web.de>
References: <200407021703.45368.ozric@web.de>
Message-ID: <40E57D99.7000302@pdf.com>

      What are the lengths of

match02$BL02DATE[is.na(match02$BL02DATE)] and match02$BLOCKED?  

	  In particular, have you considered the following:  

match02$BL02DATE[is.na(match02$BL02DATE)] <-  match02$BLOCKED[is.na(match02$BL02DATE)]


      hope this helps.  spencer graves

Christian Schulz wrote:

>Hi,
>
>have anybody a hint/help how it's possible replace i.e.
>the NA values  from BL02DATE with  non-Missing 
>values from BLOCKED  and vice versa. 
>Both variables are with an id  in a 188.249 rows data.frame and
>my fr function didn't count the NA's.
>
>Many thanks 
>Christian
>
>
>  
>
>>>fr(BL02DATE)
>>>      
>>>
>       Count Prcnt
>1     140660  84.6 
>2      25589  15.4 
>Total 166249 100.0
>
>  
>
>>>fr(BLOCKED)
>>>      
>>>
>       Count Prcnt
>1     151982  85.4 
>2      25976  14.6 
>Total 177958 100.0
>
>  
>
>>>match02$BL02DATE[is.na(match02$BL02DATE)] <-  match02$BLOCKED
>>>      
>>>
>Warning message: number of items to replace is not a multiple of
>replacement length
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ripley at stats.ox.ac.uk  Fri Jul  2 17:22:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Jul 2004 16:22:15 +0100 (BST)
Subject: [R] Error:length of dimnames [2] not equal to array extent ?
In-Reply-To: <BAY2-DAV1DbfodiVRef00032f62@hotmail.com>
Message-ID: <Pine.LNX.4.44.0407021616130.27303-100000@gannet.stats>

Please use the debugging facilities to investigate further -- you 
have not even shown the traceback, let alone used dump.frames and the 
debugger.

On Fri, 2 Jul 2004, Robin Gruna wrote:

> Hi everyone,
> I have the following problem:
> I want to perform a LDA with the function lda().
> My data object mat.data is a matrix with dimensions
> 
> > dim(mat.data)
> [1] 1228   44
> 
> and my grouping vector grp has length 1228:
> 
> > length(grp)
> [1] 1228
> 
> Every time I call lda(), the following error message occurs:
> 
> > lda(mat.data,grp)
> Error in lda.default(x, grouping, ...) : length of dimnames [2] not equal to
> array extent

dimnames [2] are the column names.  That's an error in dimnames<-.

> In order to find the error I created a matrix mat.test
> 
> mat.test<-matrix(1:500,nrow=1228,ncol=44)
> 
> with arbitrary entries an the same attributes as mat.data:
> 
> > dimnames(mat.test)
> NULL
> 
> > dimnames(mat.data)
> NULL
> 
> But with the test object mat.test there occurs no error !
> Can somebody help me, this really makes me crazy,
> thanks,

Learning to debug R will alleviate the symptoms.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From YToubouti at epimgh.mcgill.ca  Fri Jul  2 17:24:27 2004
From: YToubouti at epimgh.mcgill.ca (Youssef Toubouti)
Date: Fri, 02 Jul 2004 11:24:27 -0400
Subject: [R] GSL library and R?
Message-ID: <40E57E2B.9030904@epimgh.mcgill.ca>

Hello everybody,
Is-it possible to include GSL library in the .C Interface?
Best regards
Youssef

-- 
Youssef Toubouti, MSc
Research Institute, McGill University Health Centre
The Montreal General Hospital
Division of Clinical Epidemiology, L10-508
1650, Cedar Ave
Montreal (Quebec) H3G 1A4
Tel: (514) 934-1934 X 44730
Fax: (514) 934-8293
Home:(514) 522-5045



From ivo_welch-rstat8783 at mailblocks.com  Fri Jul  2 17:38:44 2004
From: ivo_welch-rstat8783 at mailblocks.com (ivo_welch-rstat8783@mailblocks.com)
Date: Fri, 02 Jul 2004 08:38:44 -0700
Subject: [R] Seg Fault on R 1.8.1 under linux
Message-ID: <200407021538.i62FckEP026531@hypatia.math.ethz.ch>


This may be known, but if it is not, maybe it is helpful.
   h<- 1:1000;  save(h, file=pipe(">see"));
causes a Segmentation fault on my system.  The more sensible save(h, 
file=pipe("cat >see")) hangs.  I obviously have everything wrong here, 
my point is only about suggesting a better error trapping somewhere.

regards, /iaw



From fm3a004 at math.uni-hamburg.de  Fri Jul  2 17:44:21 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Fri, 2 Jul 2004 17:44:21 +0200 (MET DST)
Subject: [R] Re: How to make eps out of a trellis graphic?
In-Reply-To: <200407020905.29429.deepayan@stat.wisc.edu>
Message-ID: <Pine.GSO.3.95q.1040702174333.1738D-100000@sun11.math.uni-hamburg.de>

a) Thank you, this works.
b) I meant qqmath, not qqnorm (you realized that).

Christian

On Fri, 2 Jul 2004, Deepayan Sarkar wrote:

> On Friday 02 July 2004 09:00, Christian Hennig wrote:
> > Hi list,
> >
> > I produced a trellis graphic with qqnorm (R-package lattice, no
> > changes in graphical parameters were made).
> > 1) The graphic uses some grey and some green colors and I would like
> > to have it black and white as usual.
> > 2) I would like to produce an eps-file of it. Usually I do this with
> > something like
> >
> > postscript("Rout.eps", horizontal=FALSE, onefile=FALSE,
> >            paper="special", height=8, width=8)
> > nr <- dev.cur()
> > dev.set(dev.prev())
> > dev.copy(which=nr)
> > dev.off(nr)
> >
> > but this gives me an empty (plain white) eps-file this time.
> > So how to make an eps-figure out of my trellis plot?
> 
> Do something like
> 
> postscript("Rout.eps", horizontal=FALSE, onefile=FALSE,
>            paper="special", height=8, width=8)
> qqnorm(<whatever>)
> dev.off()
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From spencer.graves at pdf.com  Fri Jul  2 18:17:48 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 02 Jul 2004 09:17:48 -0700
Subject: [R] help computing a covariance
In-Reply-To: <40E562C5.4050308@comcast.net>
References: <40E562C5.4050308@comcast.net>
Message-ID: <40E58AAC.6090000@pdf.com>

      Have you considered Cochran's theorem?  (A Google search just 
produce 387 hits for this, the second of which 
"http://mcs.une.edu.au/~stat354/notes/node37.html" provided details that 
might help.)  By construction, P is n x n, idempotent of rank k, so y'Py 
is chi-square(k).  Also, xA is an n-vector in the (rank k) column space 
of x;  indeed, PxA = [x*inv(x'x)*x]xA = xA.  I can't see the details now 
but I believe you can write (A'x'y)^2 = y'xAA'x'y as a weighted sum of k 
independent chi-squares each with one degree of freedom (since x and P 
have rank k), and then get what you want from the sum of the weights.  
Then check your result using Monte Carlo. 

      hope this helps.  spencer graves

Eugene Salinas (R) wrote:

> Hi everyone,
>
> (This is related to my posting on chi-squared from a day ago. I have 
> tried simulating this but I am still unable to calculate it 
> analytically.)
>
> Let y be an n times 1 vector of random normal variables mean zero 
> variance 1 and x be an n times k vector of random normal variables 
> mean zero variance 1. x and y are independent.
>
> Then P is the projection matrix  P=x*inv(x'*x)*x'
>
> I need to figure out the covariance
>
> Cov ( y'*P*y , (A'*x'*y)^2 ) where A is a constant of dimension k 
> times 1.
>
> thanks, eugene.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From bates at stat.wisc.edu  Fri Jul  2 18:26:20 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 02 Jul 2004 11:26:20 -0500
Subject: [R] Problem in lme4
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7403E71E31@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7403E71E31@dc1ex2.air.org>
Message-ID: <40E58CAC.5050100@stat.wisc.edu>

Doran, Harold wrote:


> I was able to run the following in nlme successfully, but the same model
> and code (same dataset) failed to run in lme4 and gave me the error
> message below. Any thoughts?
>  
> 
> lme(math~year, data=egsingle, random=~year|schoolid/childid)
>  
> 
> Error in lme(formula = math ~ year, data = egsingle, random =
> structure(list( : 
> 
>         Unable to invert singular factor of downdated X'X

Is childid unique?  If not, you will need to generate a unique id for 
the child for the lme4 version of lme.  (This change is required because 
the lme4 package can fit models with crossed or partially crossed 
grouping factors.)

A simple way of creating the necessary factor (thanks to Martin Maechler 
for showing me this) is

egsingle$chld <- (egsingle$schoolid : egsingle$childid)[drop = TRUE]

(I haven't checked this.  I don't have R on the machine that I use for 
email connectivity.  I can check this later today.  Is the egsingle data 
set the same one you sent me earlier?)



From ripley at stats.ox.ac.uk  Fri Jul  2 18:28:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Jul 2004 17:28:58 +0100 (BST)
Subject: [R] Creating unique combinations of factors (was Problem in lme4)
In-Reply-To: <40E58CAC.5050100@stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0407021726220.27527-100000@gannet.stats>

On Fri, 2 Jul 2004, Douglas Bates wrote:

> Doran, Harold wrote:
> 
> 
> > I was able to run the following in nlme successfully, but the same model
> > and code (same dataset) failed to run in lme4 and gave me the error
> > message below. Any thoughts?
> >  
> > 
> > lme(math~year, data=egsingle, random=~year|schoolid/childid)
> >  
> > 
> > Error in lme(formula = math ~ year, data = egsingle, random =
> > structure(list( : 
> > 
> >         Unable to invert singular factor of downdated X'X
> 
> Is childid unique?  If not, you will need to generate a unique id for 
> the child for the lme4 version of lme.  (This change is required because 
> the lme4 package can fit models with crossed or partially crossed 
> grouping factors.)
> 
> A simple way of creating the necessary factor (thanks to Martin Maechler 
> for showing me this) is
> 
> egsingle$chld <- (egsingle$schoolid : egsingle$childid)[drop = TRUE]

interaction(egsingle$schoolid, egsingle$childid, drop=TRUE)

is very similar and might be a bit more self-documenting (so I tend to 
prefer it).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From r-eugenesalinas at comcast.net  Fri Jul  2 18:33:31 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Fri, 02 Jul 2004 12:33:31 -0400
Subject: [R] help computing a covariance
In-Reply-To: <40E58AAC.6090000@pdf.com>
References: <40E562C5.4050308@comcast.net> <40E58AAC.6090000@pdf.com>
Message-ID: <40E58E5B.1060206@comcast.net>

Thanks. This is sort of what I have been trying to do... but I keep 
ending up with products of non-independent chi-squares where I am sort 
of getting stuck. I knew this Theorem just never knew it was called 
Cochran's Thm. Btw, do you know of a good book that deals with 
multivariate statistics using vector notation etc. All the books I have 
seem to be focused on scalar random variables and they don't even 
mention it.)

thanks, eugene.


Spencer Graves wrote:

>      Have you considered Cochran's theorem?  (A Google search just 
> produce 387 hits for this, the second of which 
> "http://mcs.une.edu.au/~stat354/notes/node37.html" provided details 
> that might help.)  By construction, P is n x n, idempotent of rank k, 
> so y'Py is chi-square(k).  Also, xA is an n-vector in the (rank k) 
> column space of x;  indeed, PxA = [x*inv(x'x)*x]xA = xA.  I can't see 
> the details now but I believe you can write (A'x'y)^2 = y'xAA'x'y as a 
> weighted sum of k independent chi-squares each with one degree of 
> freedom (since x and P have rank k), and then get what you want from 
> the sum of the weights.  Then check your result using Monte Carlo.
>      hope this helps.  spencer graves
>
> Eugene Salinas (R) wrote:
>
>> Hi everyone,
>>
>> (This is related to my posting on chi-squared from a day ago. I have 
>> tried simulating this but I am still unable to calculate it 
>> analytically.)
>>
>> Let y be an n times 1 vector of random normal variables mean zero 
>> variance 1 and x be an n times k vector of random normal variables 
>> mean zero variance 1. x and y are independent.
>>
>> Then P is the projection matrix  P=x*inv(x'*x)*x'
>>
>> I need to figure out the covariance
>>
>> Cov ( y'*P*y , (A'*x'*y)^2 ) where A is a constant of dimension k 
>> times 1.
>>
>> thanks, eugene.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
>
>



From Eric.Kort at vai.org  Fri Jul  2 18:36:00 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Fri, 2 Jul 2004 12:36:00 -0400
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
Message-ID: <74D0F0AB07F2E647A02D839ED79520F9208934@VAIEXCH02.vai.org>

Yes...unfortunately it looks like the lab that owns the irix does not have a license for Sun's compilers which are required for compiling a 64bit R (I used gcc to compile the 32 bit version, but have not had success compiling a 64 bit R with gcc on the irix).  But I am sure we will manage to compile a 64 bit R somewhere sometime soon.
 
Thanks,
Eric

	-----Original Message----- 
	From: Paul Gilbert [mailto:pgilbert at bank-banque-canada.ca] 
	Sent: Fri 7/2/2004 10:39 AM 
	To: Kort, Eric 
	Cc: Tae-Hoon Chung; r-help at stat.math.ethz.ch 
	Subject: Re: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
	
	

	It looks like you have R compiled as a 32 bit application, and you will
	need to compile it as a 64 bit application if you want to address more
	than 4G memory. I am not familiar with the sgi irix machine, but you can
	do this on many workstations that have processors with a 64 bit
	architecture and an OS that supports it.  The R-admin notes have some
	hints about how to do this for various platforms.
	
	Paul Gilbert
	
	Kort, Eric wrote:
	
	>Yes, we are using the HGU-133plus2 chips with 50,000+ probes, and I suppose that the memory requirements increase geometrically as the chip size increases.
	>
	>Thanks for your email...I can let you know if we have any success if you are interested for future reference.
	>
	>-Eric
	>
	>       -----Original Message-----
	>       From: Tae-Hoon Chung [mailto:thchung at tgen.org]
	>       Sent: Thu 7/1/2004 7:52 PM
	>       To: Kort, Eric
	>       Cc: r-help at stat.math.ethz.ch
	>       Subject: Re: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
	>      
	>      
	>
	>       Hi, Eric.
	>       It seems a little bit puzzling to me. Which Affymetrix chip do you use?
	>       The reason I'm asking this is that yesterday I was able to normalize
	>       150 HU-133A CEL files (containing 22283 probes) using R 1.9.1 in Mac OS
	>       X 10.3.3 with 1.5 GB memory. If your chip has more probes than this,
	>       then it must be understandable ...
	>      
	>       On Jul 1, 2004, at 2:59 PM, Kort, Eric wrote:
	>      
	>       > Hello.  By way of background, I am running out of memory when
	>       > attempting to normalize the data from 160 affymetrix microarrays using
	>       > justRMA (from the affy package).  This is despite making 6 gigabytes
	>       > of swap space available on our sgi irix machine (which has 2 gigabytes
	>       > of ram).  I have seen in various discussions statements such as "you
	>       > will need at least 6 gigabytes of memory to normalize that many
	>       > chips", but my question is this:
	>       >
	>       > I cannot set the memory limits of R (1.9.1) higher than 4 gigabytes as
	>       > attempting to do so results in this message:
	>       >
	>       > WARNING: --max-vsize=4098M=4098`M': too large and ignored
	>       >
	>       > I experience this both on my windows box (on which I cannot allocate
	>       > more than 4 gigabytes of swap space anyway), and on an the above
	>       > mentioned sgi irix machine (on which I can).  In view of that, I do
	>       > not see what good it does to make > 4 gigabytes of ram+swap space
	>       > available.  Does this mean 4 gigabytes is the absolute upper limit of
	>       > R's memory usage...or perhaps 8 gigabytes since you can set both the
	>       > stack and the heap size to 4 gigabytes?
	>       >
	>       > Thanks,
	>       > Eric
	>       >
	>       >
	>       > This email message, including any attachments, is for the
	>       > so...{{dropped}}
	>       >
	>       > ______________________________________________
	>       > R-help at stat.math.ethz.ch mailing list
	>       > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
	>       > PLEASE do read the posting guide!
	>       > http://www.R-project.org/posting-guide.html
	>       >
	>       >
	>       Tae-Hoon Chung, Ph.D
	>      
	>       Post-doctoral Research Fellow
	>       Molecular Diagnostics and Target Validation Division
	>       Translational Genomics Research Institute
	>       1275 W Washington St, Tempe AZ 85281 USA
	>       Phone: 602-343-8724
	>      
	>      
	>
	>
	>This email message, including any attachments, is for the so...{{dropped}}
	>
	>______________________________________________
	>R-help at stat.math.ethz.ch mailing list
	>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
	>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
	>
	> 
	>
	
	


This email message, including any attachments, is for the so...{{dropped}}



From JEFHEN at SAFECO.com  Fri Jul  2 18:37:46 2004
From: JEFHEN at SAFECO.com (HENRIKSON, JEFFREY)
Date: Fri, 2 Jul 2004 09:37:46 -0700
Subject: [R] reading large data
Message-ID: <9410EC84C0872141B27A2726613EF45D02A52D6B@psmrdcex01.psm.pin.safeco.com>

Hello,

I have trouble using read.table for flat files of larger than about
300MB on windows 2000.  Any ideas of how to file a bug report?  Is it a
known issue?  I have three cuts of data, a 1%, 10% and 100% sample in
flat text files.  The 100% sample is about 350MB.  When I read the 1%
and 10% files, besides being slow, everything works.  RAM footprint
appears to increase approximately 2x of text file size when loaded.  I
have 1.5GB of ram on my machine.  The 10% file takes < 1.5 minutes to
load.  So the 100% file I would think would load in < 15 minutes.  But
it grinds for about 15 mins and then seg faults instead.  I don't think
there's really very special about my data.  Just several columns by ~5M
rows.

The same thing happens when I read the 100% sample in from an RDBMS with
RODBC.

For the time being I have worked around by feeding in small cross
sections 100% from the RDBMS, and storing a 10% whole sample in RAM.
But in the future it would be nice if I could just use the RAM in my
box.


Jeff Henrikson



From ripley at stats.ox.ac.uk  Fri Jul  2 18:50:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Jul 2004 17:50:20 +0100 (BST)
Subject: [R] Seg Fault on R 1.8.1 under linux
In-Reply-To: <200407021538.i62FckEP026531@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0407021744260.27527-100000@gannet.stats>

Yes, save does not check if the connection is

a) open for
b) binary
c) writes.

Three missing checks: file = pipe("cat >see", "wb") has a chance of
working.

On Fri, 2 Jul 2004 ivo_welch-rstat8783 at mailblocks.com wrote:

> This may be known, but if it is not, maybe it is helpful.
>    h<- 1:1000;  save(h, file=pipe(">see"));
> causes a Segmentation fault on my system.  The more sensible save(h, 
> file=pipe("cat >see")) hangs.  I obviously have everything wrong here, 
> my point is only about suggesting a better error trapping somewhere.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Colin.Bleay at bristol.ac.uk  Fri Jul  2 18:53:11 2004
From: Colin.Bleay at bristol.ac.uk (CR Bleay, School Biological Sciences)
Date: Fri, 02 Jul 2004 17:53:11 +0100
Subject: [R] problems with errors in randomization tests
In-Reply-To: <40E58AAC.6090000@pdf.com>
References: <40E562C5.4050308@comcast.net> <40E58AAC.6090000@pdf.com>
Message-ID: <10640485.1088790791@bio-colinbleaymac.bio.bris.ac.uk>


I have been having problems with a randomization test.

essentially the goal is to use an original dataset and create a new data 
set with a pre-specified number of data points removed at random points. 
then to perform a glm.nb model on the new data set and store the 
coefficients and statistics from an anova table of the model in a number of 
arrays . this process is repeated a number of times (say 1000) so that i 
can perform descriptive stats and so look at the power of the original 
model as a function of sample size.


The section of code i am having problems with is :

while (countn<repetitions) {
												countn<-countn+1
												x<-1:33
												shit<-unique(sample(x, no)) # randomly selects the data points 
																				to be removed
												density.random1<-density.2
												density.random2<-density.random1[-shit,] #cretes new dataset
 
	random.model<-(glm.nb(Total~log(Dose)*time2+time2.sq+offset(log(no.adults)
), data=density.random2, na.action=na.omit, control = 
glm.control(maxit=100)) #performs model
												random.coefficients<-coefficients(random.model)
												interceptn[countn]<-random.coefficients[1]
												log.dosen[countn]<-random.coget<-random.coefficients[2]
												time2n[countn]<-random.coefficients[3]
												time2.sqn[countn]<-random.coefficients[4]
												log.doseXtime2n[countn]<-random.coefficients[5]
												random.anova<-anova.glm(random.model, test="Chisq")
												sign.diffn[countn]<-random.anova[5,5]
												signdiff[countn]<-random.anova[5,5]
												}


The problem that i am having is that every so often a data set will be 
created that will generate the following error that stops the function at 
the point of the glm.nb function:

Error: NA/NaN/Inf in foreign function call (arg 1)/In addition: Warning 
message: Step size truncated due to divergence


I have a number of questions about this.

1/ how can i prevent it from exiting the function. i have tried "try" and 
this will not resolve the issue, if i place it at the glm.nb function it 
results in an error:

Step size truncated due to divergence 
Error in "[<-"(`*tmp*`, countn, 
value = random.coefficients[1]) : 
	incompatible types

Is it possible to create an "if" step, ie. if error ignore and don't 
perform the assignment of data to the arrays else continue?

2/ given that a data set that would generate this error will be a valid 
dataset what should i do about the coefficients etc that are generated, 
ignoring those datasets would result in selection on my results.

3/ what is the actual cause of the error in the first place with respect to 
the data and the model

any assistance would be very much appreciated.

i have searched through the archives and could not find a solution. I have 
to admit that i do not adequately understand error capture and handling in 
R, and have been unable to find any documentation that gives a good 
explanation of it.

cheers,

colin

----------------------
Dr Colin Bleay
Dept. Biological Sciences,
University of Bristol,
Woodlands rd.,
Bristol,
BS8 1UG.
UK

Tel: 44 (0)117 928 7470
Fax: 44 (0)117



From spencer.graves at pdf.com  Fri Jul  2 19:07:06 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 02 Jul 2004 10:07:06 -0700
Subject: [R] help computing a covariance
In-Reply-To: <40E58E5B.1060206@comcast.net>
References: <40E562C5.4050308@comcast.net> <40E58AAC.6090000@pdf.com>
	<40E58E5B.1060206@comcast.net>
Message-ID: <40E5963A.3000400@pdf.com>

      Have you tried simulating several special cases?  The right set of 
simulations should suggest an answer, which might then lead you to a 
proof. 

      hope this helps.  spencer graves

Eugene Salinas (R) wrote:

> Thanks. This is sort of what I have been trying to do... but I keep 
> ending up with products of non-independent chi-squares where I am sort 
> of getting stuck. I knew this Theorem just never knew it was called 
> Cochran's Thm. Btw, do you know of a good book that deals with 
> multivariate statistics using vector notation etc. All the books I 
> have seem to be focused on scalar random variables and they don't even 
> mention it.)
>
> thanks, eugene.
>
>
> Spencer Graves wrote:
>
>>      Have you considered Cochran's theorem?  (A Google search just 
>> produce 387 hits for this, the second of which 
>> "http://mcs.une.edu.au/~stat354/notes/node37.html" provided details 
>> that might help.)  By construction, P is n x n, idempotent of rank k, 
>> so y'Py is chi-square(k).  Also, xA is an n-vector in the (rank k) 
>> column space of x;  indeed, PxA = [x*inv(x'x)*x]xA = xA.  I can't see 
>> the details now but I believe you can write (A'x'y)^2 = y'xAA'x'y as 
>> a weighted sum of k independent chi-squares each with one degree of 
>> freedom (since x and P have rank k), and then get what you want from 
>> the sum of the weights.  Then check your result using Monte Carlo.
>>      hope this helps.  spencer graves
>>
>> Eugene Salinas (R) wrote:
>>
>>> Hi everyone,
>>>
>>> (This is related to my posting on chi-squared from a day ago. I have 
>>> tried simulating this but I am still unable to calculate it 
>>> analytically.)
>>>
>>> Let y be an n times 1 vector of random normal variables mean zero 
>>> variance 1 and x be an n times k vector of random normal variables 
>>> mean zero variance 1. x and y are independent.
>>>
>>> Then P is the projection matrix  P=x*inv(x'*x)*x'
>>>
>>> I need to figure out the covariance
>>>
>>> Cov ( y'*P*y , (A'*x'*y)^2 ) where A is a constant of dimension k 
>>> times 1.
>>>
>>> thanks, eugene.
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rpeng at jhsph.edu  Fri Jul  2 19:19:50 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 02 Jul 2004 13:19:50 -0400
Subject: [R] reading large data
In-Reply-To: <9410EC84C0872141B27A2726613EF45D02A52D6B@psmrdcex01.psm.pin.safeco.com>
References: <9410EC84C0872141B27A2726613EF45D02A52D6B@psmrdcex01.psm.pin.safeco.com>
Message-ID: <40E59936.8080606@jhsph.edu>

You may be interested in this thread:

https://www.stat.math.ethz.ch/pipermail/r-help/2004-June/052102.html

-roger

HENRIKSON, JEFFREY wrote:
> Hello,
> 
> I have trouble using read.table for flat files of larger than about
> 300MB on windows 2000.  Any ideas of how to file a bug report?  Is it a
> known issue?  I have three cuts of data, a 1%, 10% and 100% sample in
> flat text files.  The 100% sample is about 350MB.  When I read the 1%
> and 10% files, besides being slow, everything works.  RAM footprint
> appears to increase approximately 2x of text file size when loaded.  I
> have 1.5GB of ram on my machine.  The 10% file takes < 1.5 minutes to
> load.  So the 100% file I would think would load in < 15 minutes.  But
> it grinds for about 15 mins and then seg faults instead.  I don't think
> there's really very special about my data.  Just several columns by ~5M
> rows.
> 
> The same thing happens when I read the 100% sample in from an RDBMS with
> RODBC.
> 
> For the time being I have worked around by feeding in small cross
> sections 100% from the RDBMS, and storing a 10% whole sample in RAM.
> But in the future it would be nice if I could just use the RAM in my
> box.
> 
> 
> Jeff Henrikson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From spencer.graves at pdf.com  Fri Jul  2 19:23:54 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 02 Jul 2004 10:23:54 -0700
Subject: [R] help computing a covariance
In-Reply-To: <40E58E5B.1060206@comcast.net>
References: <40E562C5.4050308@comcast.net> <40E58AAC.6090000@pdf.com>
	<40E58E5B.1060206@comcast.net>
Message-ID: <40E59A2A.7080801@pdf.com>

Another thought:  Do you really need A to be an arbitrary k-vector? 
Might it have other structure that you can use?  spencer graves
	
#################
      Have you tried simulating several special cases?  The right set of
simulations should suggest an answer, which might then lead you to a
proof.

      hope this helps.  spencer graves

Eugene Salinas (R) wrote:

> Thanks. This is sort of what I have been trying to do... but I keep 
> ending up with products of non-independent chi-squares where I am sort 
> of getting stuck. I knew this Theorem just never knew it was called 
> Cochran's Thm. Btw, do you know of a good book that deals with 
> multivariate statistics using vector notation etc. All the books I 
> have seem to be focused on scalar random variables and they don't even 
> mention it.)
>
> thanks, eugene.
>
>
> Spencer Graves wrote:
>
>>      Have you considered Cochran's theorem?  (A Google search just 
>> produce 387 hits for this, the second of which 
>> "http://mcs.une.edu.au/~stat354/notes/node37.html" provided details 
>> that might help.)  By construction, P is n x n, idempotent of rank k, 
>> so y'Py is chi-square(k).  Also, xA is an n-vector in the (rank k) 
>> column space of x;  indeed, PxA = [x*inv(x'x)*x]xA = xA.  I can't see 
>> the details now but I believe you can write (A'x'y)^2 = y'xAA'x'y as 
>> a weighted sum of k independent chi-squares each with one degree of 
>> freedom (since x and P have rank k), and then get what you want from 
>> the sum of the weights.  Then check your result using Monte Carlo.
>>      hope this helps.  spencer graves
>>
>> Eugene Salinas (R) wrote:
>>
>>> Hi everyone,
>>>
>>> (This is related to my posting on chi-squared from a day ago. I have 
>>> tried simulating this but I am still unable to calculate it 
>>> analytically.)
>>>
>>> Let y be an n times 1 vector of random normal variables mean zero 
>>> variance 1 and x be an n times k vector of random normal variables 
>>> mean zero variance 1. x and y are independent.
>>>
>>> Then P is the projection matrix  P=x*inv(x'*x)*x'
>>>
>>> I need to figure out the covariance
>>>
>>> Cov ( y'*P*y , (A'*x'*y)^2 ) where A is a constant of dimension k 
>>> times 1.
>>>
>>> thanks, eugene.
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Fri Jul  2 19:45:10 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 02 Jul 2004 19:45:10 +0200
Subject: [R] Vertical text in plot
Message-ID: <200407021945100791.16FEDF4E@mail.math.fu-berlin.de>

Hallo!
Would like to add vertical text labels to a histogram. Was trying with las but without sucess.
I am using the standard histogram.
This is what I was trying.

hist(resS2$sam,breaks=seq(0,1,0.01),col=3,border=0,freq=F,add=T,xlim=c(0,1))
text(quantile(resS2$dif,0.005),5, "0.5% FP rate" ,pos=2,cex=0.6,las=2)

Thanks in advance.
Eryk



From MSchwartz at MedAnalytics.com  Fri Jul  2 19:52:28 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 02 Jul 2004 12:52:28 -0500
Subject: [R] Vertical text in plot
In-Reply-To: <200407021945100791.16FEDF4E@mail.math.fu-berlin.de>
References: <200407021945100791.16FEDF4E@mail.math.fu-berlin.de>
Message-ID: <1088790748.3929.91.camel@localhost.localdomain>

On Fri, 2004-07-02 at 12:45, Wolski wrote:
> Hallo!
> Would like to add vertical text labels to a histogram. Was trying with las but without sucess.
> I am using the standard histogram.
> This is what I was trying.
> 
> hist(resS2$sam,breaks=seq(0,1,0.01),col=3,border=0,freq=F,add=T,xlim=c(0,1))
> text(quantile(resS2$dif,0.005),5, "0.5% FP rate" ,pos=2,cex=0.6,las=2)
> 
> Thanks in advance.
> Eryk


Hi Eryk!

Try using 'srt' instead of 'las', which is for the axis labels.

For example:

text(quantile(resS2$dif, 0.005), 5, "0.5% FP rate", 
     pos = 2, cex = 0.6, srt = 90)

See ?par for more information.

HTH,

Marc Schwartz



From talitaperciano at hotmail.com  Fri Jul  2 20:07:03 2004
From: talitaperciano at hotmail.com (Talita Leite)
Date: Fri, 02 Jul 2004 15:07:03 -0300
Subject: [R] Re: RMySQL
Message-ID: <BAY14-F28mTZqTDvn8G00045a38@hotmail.com>

Hi!

I'm installing on windows XP and the version of the package is
RMySQL_0.5-3.
About the errors...when I try to read the package on R I get this:

Error in load(dataFile, myEnv) : unused argument(s) ( ...)
Error in library(pkg, character.only = TRUE) :
        .First.lib failed

So...what can I do?

Talita Perciano Costa Leite
Graduanda em Ci??ncia da Computa????o
Universidade Federal de Alagoas - UFAL
Departamento de Tecnologia da Informa????o - TCI
Constru????o de Conhecimento por Agrupamento de Dados - CoCADa





>From: "Wolski" <wolski at molgen.mpg.de>
>To: "Talita Leite" <talitaperciano at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] RMySQL
>Date: Thu, 01 Jul 2004 18:46:06 +0200
>
>Hi!
>I was installing RMySQL quite recently on Linux and had some troubles
>which
>I was able to solve. So maybee I can help you.
>But first I have to know what error messages you are getting on which
>operating system you are installing, which version of the package.
>
>Sincerely Eryk
>
>
>
*********** REPLY SEPARATOR  ***********

>>On 01.07.2004 at 13:14 Talita Leite wrote:
>>
> >Hi!!
> >
> >I want some help to install the RMySQL package. I've tried to configure
> >some
> >things but i'm still getting erros. Anybody could help me??
> >
> >Thank's
> >
> >
> >
> >Talita Perciano Costa Leite
> >Graduanda em Ci??ncia da Computa????o
> >Universidade Federal de Alagoas - UFAL
> >Departamento de Tecnologia da Informa????o - TCI
> >Constru????o de Conhecimento por Agrupamento de Dados - CoCADa
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> >http://www.R-project.org/posting-guide.html






Talita Perciano Costa Leite
Graduanda em Ci??ncia da Computa????o
Universidade Federal de Alagoas - UFAL
Departamento de Tecnologia da Informa????o - TCI
Constru????o de Conhecimento por Agrupamento de Dados - CoCADa



From wolski at molgen.mpg.de  Fri Jul  2 20:21:50 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 02 Jul 2004 20:21:50 +0200
Subject: [R] Vertical text in plot
In-Reply-To: <1088790748.3929.91.camel@localhost.localdomain>
References: <200407021945100791.16FEDF4E@mail.math.fu-berlin.de>
	<1088790748.3929.91.camel@localhost.localdomain>
Message-ID: <200407022021500828.0BFC78C9@mail.math.fu-berlin.de>

Hi Mark!

Just wonderfull. 
Was searching in the par documention file for vertical, angle, horizontal. The word rotation was out of my mind.
Thanks a lot.

Eryk



*********** REPLY SEPARATOR  ***********

On 7/2/2004 at 12:52 PM Marc Schwartz wrote:

>>>On Fri, 2004-07-02 at 12:45, Wolski wrote:
>>>> Hallo!
>>>> Would like to add vertical text labels to a histogram. Was trying with
>>>las but without sucess.
>>>> I am using the standard histogram.
>>>> This is what I was trying.
>>>> 
>>>>
>>>hist(resS2$sam,breaks=seq(0,1,0.01),col=3,border=0,freq=F,add=T,xlim=c(0,1))
>>>> text(quantile(resS2$dif,0.005),5, "0.5% FP rate" ,pos=2,cex=0.6,las=2)
>>>> 
>>>> Thanks in advance.
>>>> Eryk
>>>
>>>
>>>Hi Eryk!
>>>
>>>Try using 'srt' instead of 'las', which is for the axis labels.
>>>
>>>For example:
>>>
>>>text(quantile(resS2$dif, 0.005), 5, "0.5% FP rate", 
>>>     pos = 2, cex = 0.6, srt = 90)
>>>
>>>See ?par for more information.
>>>
>>>HTH,
>>>
>>>Marc Schwartz
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From daisy.wang at rtc.bosch.com  Fri Jul  2 21:31:32 2004
From: daisy.wang at rtc.bosch.com (daisy)
Date: Fri, 2 Jul 2004 12:31:32 -0700
Subject: [R] Half Million features Selection (Random Forest)
Message-ID: <000801c4606b$2e4641e0$ac3a190a@palpc172>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040702/c2f34cbf/attachment.pl

From ririzarr at jhsph.edu  Fri Jul  2 21:50:46 2004
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Fri, 2 Jul 2004 15:50:46 -0400 (EDT)
Subject: [R] hclust
Message-ID: <Pine.GSO.4.10.10407021538070.1414-100000@athena.biostat.jhsph.edu>

im using plclust  and want the labels to be different colors. 
i took a look at getS3method("plot","hclust")
and saw a call to .Internal. i looked at the help on .Internal and dont
know where to go next. any help appreciated!

thanks,
rafael



From fzh113 at hecky.it.northwestern.edu  Fri Jul  2 22:02:15 2004
From: fzh113 at hecky.it.northwestern.edu (Fred)
Date: Fri, 2 Jul 2004 15:02:15 -0500
Subject: [R] How to get the normal direction to a plane?
Message-ID: <000001c4606f$78da5f30$ab8d7ca5@FYOC1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040702/d878ab91/attachment.pl

From rif at MIT.EDU  Fri Jul  2 23:33:58 2004
From: rif at MIT.EDU (rif)
Date: Fri, 2 Jul 2004 17:33:58 -0400
Subject: [R] plotting many line segments in different colors
Message-ID: <200407022133.i62LXwOR011605@five-percent-nation.mit.edu>


I want to plot a large number of line segments, with a color
associated with each line segment (I'm actually plotting a function of
the edges of a 2d graph, and I want to use color to indicate the level
of the function.)  I originally thought I could use lines, but lines
puts all its lines in one color (from help(lines), "col: color to use.
This can be vector of length greater than one, but only the first
value will be used.").

Is there a function that does what I want?  Right now I'm using the
obvious solution of calling lines in a loop with a single segment, but
this is really quite slow for my purposes, as I have several thousand
lines total to plot.

Cheers,

rif



From MSchwartz at MedAnalytics.com  Fri Jul  2 23:44:33 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 02 Jul 2004 16:44:33 -0500
Subject: [R] plotting many line segments in different colors
In-Reply-To: <200407022133.i62LXwOR011605@five-percent-nation.mit.edu>
References: <200407022133.i62LXwOR011605@five-percent-nation.mit.edu>
Message-ID: <1088804673.4804.5.camel@localhost.localdomain>

On Fri, 2004-07-02 at 16:33, rif wrote:
> I want to plot a large number of line segments, with a color
> associated with each line segment (I'm actually plotting a function of
> the edges of a 2d graph, and I want to use color to indicate the level
> of the function.)  I originally thought I could use lines, but lines
> puts all its lines in one color (from help(lines), "col: color to use.
> This can be vector of length greater than one, but only the first
> value will be used.").
> 
> Is there a function that does what I want?  Right now I'm using the
> obvious solution of calling lines in a loop with a single segment, but
> this is really quite slow for my purposes, as I have several thousand
> lines total to plot.


Take a look at ?matplot or ?matlines depending upon which one might make
sense for your particular application. Both functions are on the same
help page.

HTH,

Marc Schwartz



From p.dalgaard at biostat.ku.dk  Fri Jul  2 23:44:02 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Jul 2004 23:44:02 +0200
Subject: [R] plotting many line segments in different colors
In-Reply-To: <200407022133.i62LXwOR011605@five-percent-nation.mit.edu>
References: <200407022133.i62LXwOR011605@five-percent-nation.mit.edu>
Message-ID: <x2vfh66q59.fsf@biostat.ku.dk>

rif <rif at MIT.EDU> writes:

> I want to plot a large number of line segments, with a color
> associated with each line segment 
[snip]
> Is there a function that does what I want?  Right now I'm using the
> obvious solution of calling lines in a loop with a single segment, but
> this is really quite slow for my purposes, as I have several thousand
> lines total to plot.

I don't know how to break this to you, but....

Have you considered segments()?

> plot(1:10,1:10)
> segments(1:9,1:9,2:10,2:10,col=1:9,lwd=3)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rkoenker at uiuc.edu  Fri Jul  2 23:47:09 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Fri, 2 Jul 2004 16:47:09 -0500
Subject: [R] plotting many line segments in different colors
In-Reply-To: <200407022133.i62LXwOR011605@five-percent-nation.mit.edu>
References: <200407022133.i62LXwOR011605@five-percent-nation.mit.edu>
Message-ID: <5E5ED2E0-CC71-11D8-9634-000A95A7E3AA@uiuc.edu>

?segments

url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Jul 2, 2004, at 4:33 PM, rif wrote:

>
> I want to plot a large number of line segments, with a color
> associated with each line segment (I'm actually plotting a function of
> the edges of a 2d graph, and I want to use color to indicate the level
> of the function.)  I originally thought I could use lines, but lines
> puts all its lines in one color (from help(lines), "col: color to use.
> This can be vector of length greater than one, but only the first
> value will be used.").
>
> Is there a function that does what I want?  Right now I'm using the
> obvious solution of calling lines in a loop with a single segment, but
> this is really quite slow for my purposes, as I have several thousand
> lines total to plot.
>
> Cheers,
>
> rif
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Sat Jul  3 00:18:04 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 02 Jul 2004 15:18:04 -0700
Subject: [R] How to get the normal direction to a plane?
In-Reply-To: <000001c4606f$78da5f30$ab8d7ca5@FYOC1>
References: <000001c4606f$78da5f30$ab8d7ca5@FYOC1>
Message-ID: <40E5DF1C.103@pdf.com>

      While we need 3 points to determine a line, we need only 2 
vectors, provided they both have the same origin and differ in direction 
not just magnitude;  this latter condition is the same as saying that 
the 3 points can not lie on a line. 

      To apply this, suppose a, b, and c are 3 vectors in k-space, and 
let X = the k x 2 matrix with columns b-a and c-a.  By the assumption 
that the three points do not lie on a line, the matrix X has rank 2, so 
X'X is nonsingular.  Let P = X*inv(X'X)X'.  Note that P is idempotent, 
i.e., P*P = P.  Further, note that Pz is a vector in the column space of 
X, for any k-vector z.  Further, (I-P) is also idempotent and projects 
any vector onto the subspace orthogonal to P.  Thus, (I-P)z will be 
orthogonal to P and therefore also orthogonal to X, for any k-vector z. 

      This discussion reveals a subtle flaw in the logic as stated 
(which I didn't see until I worked the exercise):  Only in the case 
where k = 3 is there only one direction that is orthogonal to this 
plane.  In general, there are (k-2) such directions.  For more 
information, see any good book on finite dimensional vector spaces such 
as Halmos (1974), or Google this or see ?svd or ?qr or the references 
cited therein. 

      hope this helps.  spencer graves

Fred wrote:

>Dear All
> 
>Maybe the following is a stupid question.
>Assume I have 3 coordinate points (not limited to be in 2D or 3D space)
>a, b, c.
>It is known that these 3 points will define a plane.
>The problem is how to get the normal direction that is orthogonal to
>this plane.
> 
>Is there an easy way to calculate it using the values of a, b, and c?
> 
>Thanks for any point or help on this.
> 
>Fred
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From fzh113 at hecky.it.northwestern.edu  Sat Jul  3 00:35:02 2004
From: fzh113 at hecky.it.northwestern.edu (Fred)
Date: Fri, 2 Jul 2004 17:35:02 -0500
Subject: [R] How to get the normal direction to a plane?
References: <000001c4606f$78da5f30$ab8d7ca5@FYOC1> <40E5DF1C.103@pdf.com>
Message-ID: <000801c46084$d1180b60$a7560d18@f0z6305>

Thanks a lot, Spencer

Fred
----- Original Message ----- 
From: "Spencer Graves" <spencer.graves at pdf.com>
To: "Fred" <fzh113 at hecky.it.northwestern.edu>
Cc: "'R-help'" <R-help at stat.math.ethz.ch>
Sent: Friday, July 02, 2004 5:18 PM
Subject: Re: [R] How to get the normal direction to a plane?


>       While we need 3 points to determine a line, we need only 2
> vectors, provided they both have the same origin and differ in direction
> not just magnitude;  this latter condition is the same as saying that
> the 3 points can not lie on a line.
>
>       To apply this, suppose a, b, and c are 3 vectors in k-space, and
> let X = the k x 2 matrix with columns b-a and c-a.  By the assumption
> that the three points do not lie on a line, the matrix X has rank 2, so
> X'X is nonsingular.  Let P = X*inv(X'X)X'.  Note that P is idempotent,
> i.e., P*P = P.  Further, note that Pz is a vector in the column space of
> X, for any k-vector z.  Further, (I-P) is also idempotent and projects
> any vector onto the subspace orthogonal to P.  Thus, (I-P)z will be
> orthogonal to P and therefore also orthogonal to X, for any k-vector z.
>
>       This discussion reveals a subtle flaw in the logic as stated
> (which I didn't see until I worked the exercise):  Only in the case
> where k = 3 is there only one direction that is orthogonal to this
> plane.  In general, there are (k-2) such directions.  For more
> information, see any good book on finite dimensional vector spaces such
> as Halmos (1974), or Google this or see ?svd or ?qr or the references
> cited therein.
>
>       hope this helps.  spencer graves
>
> Fred wrote:
>
> >Dear All
> >
> >Maybe the following is a stupid question.
> >Assume I have 3 coordinate points (not limited to be in 2D or 3D space)
> >a, b, c.
> >It is known that these 3 points will define a plane.
> >The problem is how to get the normal direction that is orthogonal to
> >this plane.
> >
> >Is there an easy way to calculate it using the values of a, b, and c?
> >
> >Thanks for any point or help on this.
> >
> >Fred
> >
> > [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>



From ggrothendieck at myway.com  Sat Jul  3 03:20:40 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 3 Jul 2004 01:20:40 +0000 (UTC)
Subject: [R] How to get the normal direction to a plane?
References: <000001c4606f$78da5f30$ab8d7ca5@FYOC1>
Message-ID: <loom.20040703T031608-866@post.gmane.org>


In R^3 there is a unique answer if the points don't all lie on a line.
See the discussion a few weeks ago on the list available at this thread:

   http://tolstoy.newcastle.edu.au/R/help/04/05/1487.html

Also you might want to google for    

   cross product



Fred <fzh113 <at> hecky.it.northwestern.edu> writes:

: 
: Dear All
:  
: Maybe the following is a stupid question.
: Assume I have 3 coordinate points (not limited to be in 2D or 3D space)
: a, b, c.
: It is known that these 3 points will define a plane.
: The problem is how to get the normal direction that is orthogonal to
: this plane.
: 
: Is there an easy way to calculate it using the values of a, b, and c?
: 
: Thanks for any point or help on this.
: 
: Fred



From ggrothendieck at myway.com  Sat Jul  3 03:44:56 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 3 Jul 2004 01:44:56 +0000 (UTC)
Subject: [R] How to get the normal direction to a plane?
References: <000001c4606f$78da5f30$ab8d7ca5@FYOC1>
	<loom.20040703T031608-866@post.gmane.org>
Message-ID: <loom.20040703T034241-382@post.gmane.org>


I just reread my post and "a unique answer" should be "an answer that can
be chosen in a unique way based on certain additional standard conventions"


Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: In R^3 there is a unique answer if the points don't all lie on a line.
: See the discussion a few weeks ago on the list available at this thread:
: 
:    http://tolstoy.newcastle.edu.au/R/help/04/05/1487.html
: 
: Also you might want to google for    
: 
:    cross product
: 
: 
: Fred <fzh113 <at> hecky.it.northwestern.edu> writes:
: 
: : 
: : Dear All
: :  
: : Maybe the following is a stupid question.
: : Assume I have 3 coordinate points (not limited to be in 2D or 3D space)
: : a, b, c.
: : It is known that these 3 points will define a plane.
: : The problem is how to get the normal direction that is orthogonal to
: : this plane.
: : 
: : Is there an easy way to calculate it using the values of a, b, and c?
: : 
: : Thanks for any point or help on this.
: : 
: : Fred
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From hatespam at volcanomail.com  Sat Jul  3 04:11:23 2004
From: hatespam at volcanomail.com (John Doe)
Date: Fri, 2 Jul 2004 19:11:23 -0700 (PDT)
Subject: [R] Installation of R in Windows
Message-ID: <20040703021123.1C9193955@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040702/4ce70492/attachment.pl

From seniorr at aracnet.com  Sat Jul  3 06:59:14 2004
From: seniorr at aracnet.com (Russell Senior)
Date: 02 Jul 2004 21:59:14 -0700
Subject: [R] solving for a 2D transformation matrix
Message-ID: <86r7rtwusd.fsf@coulee.tdb.com>


We have recently digitized a set of points from some scanned
engineering drawings (in the form of PDFs).  The digitization resulted
in x,y page coordinates for each point.  The scans were not aligned
perfectly so there is a small rotation, and furthermore each
projection (e.g. the yz-plane) on the drawing has a different offset
from the page origin to the projection origin.  From the dimensions
indicated on the drawing, I know the intended "world" coordinates of a
subset of the points.  I want to use this subset of points to compute
a best-fit transformation matrix so that the remaining points can be
converted to world coordinates.

The transformation matrix is (I think) of the form:

 [ x' ]   [ a11 a12 a13 ] [ x ]
 | y' | = | a21 a22 a23 | | y |
 [ w' ]   [ a31 a32 a33 ] [ w ]

 where:
 
    x,y = page coordinates
    x',y' = world coordinates

    a13 = translation of x
    a23 = translation of y

    a11 = scale * cos(theta)
    a12 = sin(theta)
    a21 = -sin(theta)
    a22 = scale * cos(theta)

    a31 = 0
    a31 = 0
    a33 = 1
    w' = 1
    w = 1

Can anyone give me a pointer on how to go about solving for the
transformation matrix given a set of points, where x,y and x',y' are
available?  I sense the presence a solution lingering in the murky
mists, (some kind of least squares?) but I am not sure what it is or
how to go about it exactly.

Thanks for your help!

-- 
Russell Senior         ``I have nine fingers; you have ten.''
seniorr at aracnet.com



From ripley at stats.ox.ac.uk  Sat Jul  3 07:51:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Jul 2004 06:51:17 +0100 (BST)
Subject: [R] Installation of R in Windows
In-Reply-To: <20040703021123.1C9193955@sitemail.everyone.net>
Message-ID: <Pine.LNX.4.44.0407030643130.32334-100000@gannet.stats>

On Fri, 2 Jul 2004, John Doe wrote:

> I tried to install R (V 1.9.1) on an XP Home Edition box with loads of
> disk space and 256 MB of RAM.  During installation, I get messages
> stating that some files are corrupted.  I used two copies of the install
> exe downloaded from different sites and still get the same messages at
> the same spots in the install.  What do I need to do to get around this?

Sort out the local problem with your downloading.  It may be your client,
so could you perhaps try a different browser, or ftp in binary mode?

> I ran md5sum on the downloaded exe file:
> 
> C:\WINDOWS\Temp>md5sum rw1091.exe
> c45bbe46e9a9bc1c0995e896f3bd4537 *rw1091.exe
> 
> This seems to be different from what is shown at
> http://cran.r-project.org/bin/windows/base/md5sum.txt:
> 
> 2e92742add3194fc22ada0cd2634ac61 *rw1091.exe
> 
> What's going on?

Something in your downloading is corrupting the file: that's the purpose
of md5sums (and the copy I just downloaded has the stated checksum).  Is
the size correct?  (21688072 bytes.)  If not, you may be running out of
some resource (temp space, for example) during the download.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ashjari_j at yahoo.com  Sat Jul  3 07:53:54 2004
From: ashjari_j at yahoo.com (Javad Ashjari)
Date: Fri, 2 Jul 2004 22:53:54 -0700 (PDT)
Subject: [R] R CMD line45
Message-ID: <20040703055354.95550.qmail@web51710.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040702/7b217cf0/attachment.pl

From ripley at stats.ox.ac.uk  Sat Jul  3 07:58:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Jul 2004 06:58:15 +0100 (BST)
Subject: [R] Half Million features Selection (Random Forest)
In-Reply-To: <000801c4606b$2e4641e0$ac3a190a@palpc172>
Message-ID: <Pine.LNX.4.44.0407030651550.32334-100000@gannet.stats>

How many cases do you have?  Since you apparently expect the dataset to be 
usable in R, you only have room to store a dataset with 200 cases or so 
(let alone space to analyse it).

Even selecting *one* variable is statistically nonsensical with less than
millions of cases (as otherwise the possibility of chance agreement of
predictors is too high -- and I don't known enough about your problem to 
do even a rough calculation with any confidence).

On Fri, 2 Jul 2004, daisy wrote:

> I have about half million binary features, and would like to find a
> model to estimate the continous response. According to the inference, I
> can express predictors and response by linear model. (ie. Design matrix:
> large sparse matrix with 0/1. Response: Continous number) Since it is
> not a classification problem, someone suggested me to try random forest
> in R. However, in the randomForest help page, it points out "For large
> data sets, especially those with large number of variables, calling
> 'randomForest' via the formula interface is not advised: There may be
> too much overhead in handling the formula." and I also gave a try on 300
> variables and R either gave me error message or no response. (OS:
> Windows XP; R:1.9.0 ; RAM:512MB) Is there any way to implement random
> forest on this big dataset? Any suggestion is welcome! Many thanks!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Jul  3 08:02:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Jul 2004 07:02:27 +0100 (BST)
Subject: [R] hclust
In-Reply-To: <Pine.GSO.4.10.10407021538070.1414-100000@athena.biostat.jhsph.edu>
Message-ID: <Pine.LNX.4.44.0407030658380.32334-100000@gannet.stats>

On Fri, 2 Jul 2004, Rafael A. Irizarry wrote:

> im using plclust  and want the labels to be different colors. 
> i took a look at getS3method("plot","hclust")
> and saw a call to .Internal. i looked at the help on .Internal and dont
> know where to go next. any help appreciated!

The R source code, specifically src/main/names.c which maps the .Internal 
named call to C calls.  In your case the lines

{"dend",	do_dend,	0,	111,	6,	{PP_FUNCALL, 
PREC_FN,	0}},
{"dend.window",	do_dendwindow,	0,	111,	5,	{PP_FUNCALL, 
PREC_FN,	0}},

and 

gannet% grep do_dend *.c
...
plot.c:SEXP do_dend(SEXP call, SEXP op, SEXP args, SEXP env)
plot.c:SEXP do_dendwindow(SEXP call, SEXP op, SEXP args, SEXP env)

(This might be better continued on R-devel, if it need continuing.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Jul  3 08:07:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Jul 2004 07:07:40 +0100 (BST)
Subject: [R] solving for a 2D transformation matrix
In-Reply-To: <86r7rtwusd.fsf@coulee.tdb.com>
Message-ID: <Pine.LNX.4.44.0407030703540.32334-100000@gannet.stats>

The best least-squares fit maps centroid to centroid.  So find the mean of
the observed and target, and shift the observed to match the target. That
just leaves a rotation, and I would directly maximize the sum of squared
errors over that using optimize().

On 2 Jul 2004, Russell Senior wrote:

> 
> We have recently digitized a set of points from some scanned
> engineering drawings (in the form of PDFs).  The digitization resulted
> in x,y page coordinates for each point.  The scans were not aligned
> perfectly so there is a small rotation, and furthermore each
> projection (e.g. the yz-plane) on the drawing has a different offset
> from the page origin to the projection origin.  From the dimensions
> indicated on the drawing, I know the intended "world" coordinates of a
> subset of the points.  I want to use this subset of points to compute
> a best-fit transformation matrix so that the remaining points can be
> converted to world coordinates.
> 
> The transformation matrix is (I think) of the form:
> 
>  [ x' ]   [ a11 a12 a13 ] [ x ]
>  | y' | = | a21 a22 a23 | | y |
>  [ w' ]   [ a31 a32 a33 ] [ w ]
> 
>  where:
>  
>     x,y = page coordinates
>     x',y' = world coordinates
> 
>     a13 = translation of x
>     a23 = translation of y
> 
>     a11 = scale * cos(theta)
>     a12 = sin(theta)
>     a21 = -sin(theta)
>     a22 = scale * cos(theta)
> 
>     a31 = 0
>     a31 = 0
>     a33 = 1
>     w' = 1
>     w = 1
> 
> Can anyone give me a pointer on how to go about solving for the
> transformation matrix given a set of points, where x,y and x',y' are
> available?  I sense the presence a solution lingering in the murky
> mists, (some kind of least squares?) but I am not sure what it is or
> how to go about it exactly.
> 
> Thanks for your help!
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Jul  3 08:12:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Jul 2004 07:12:23 +0100 (BST)
Subject: [R] R CMD line45
In-Reply-To: <20040703055354.95550.qmail@web51710.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0407030707590.32334-100000@gannet.stats>

On Fri, 2 Jul 2004, Javad Ashjari wrote:

> I use R in linux. I have problem by installing a package. when i use "R
> CMD" coomond, i recived a d a erroe line " /usr/lib/R/bin/Rcmd: line45:
> exec: INSTAL~1 not found. how can i solve my problem? thank you for your
> advise

Given the rather random nature of the characters in that message I don't 
trust anything, so do you have a keyboard problem?  The command to 
install a package is

R CMD INSTALL pkgpath

R has received something which was received here as `INSTAL~1' rather than 
`INSTALL'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bitwrit at ozemail.com.au  Sat Jul  3 08:48:59 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sat, 3 Jul 2004 16:48:59 +1000
Subject: [R] R CMD line45
In-Reply-To: <20040703055354.95550.qmail@web51710.mail.yahoo.com>
References: <20040703055354.95550.qmail@web51710.mail.yahoo.com>
Message-ID: <20040703064341.TNNP5908.smta02.mail.ozemail.net@there>

Javad Ashjari wrote:
> Dear Friends
> I use R in linux. I have problem by installing a package. when i use "R
> CMD" coomond, i recived a d a erroe line " /usr/lib/R/bin/Rcmd: line45:
> exec: INSTAL~1 not found. how can i solve my problem? thank you for your
> advise
>
I'll have a guess at this one. I think you're using Windows, and the ~1 looks 
suspiciously like a Windows->DOS filename mangle. Is there a space between 
the INSTALL part of the command and whatever follows it?

Jim



From ligges at statistik.uni-dortmund.de  Sat Jul  3 11:51:55 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 03 Jul 2004 11:51:55 +0200
Subject: [R] Re: RMySQL
In-Reply-To: <BAY14-F28mTZqTDvn8G00045a38@hotmail.com>
References: <BAY14-F28mTZqTDvn8G00045a38@hotmail.com>
Message-ID: <40E681BB.6050601@statistik.uni-dortmund.de>

Talita Leite wrote:

> Hi!
> 
> I'm installing on windows XP and the version of the package is
> RMySQL_0.5-3.
> About the errors...when I try to read the package on R I get this:
> 
> Error in load(dataFile, myEnv) : unused argument(s) ( ...)
> Error in library(pkg, character.only = TRUE) :
>        .First.lib failed
> 
> So...what can I do?

Which version of R?
How did you try to install the package and where did you get it from?
I guess you tried to install a source package without compiling it.

The appropiate ReadMe abourt pre-compiled packages for recent R versions 
for Windows (http://cran.r-project.org/bin/windows/contrib/1.9/ReadMe) 
tells you that David James kindly provides precompiled RMySQL packages 
for Windows at http://stat.bell-labs.com/RS-DBI/download

Uwe Ligges


> Talita Perciano Costa Leite
> Graduanda em Ci??ncia da Computa????o
> Universidade Federal de Alagoas - UFAL
> Departamento de Tecnologia da Informa????o - TCI
> Constru????o de Conhecimento por Agrupamento de Dados - CoCADa
> 
> 
> 
> 
> 
>> From: "Wolski" <wolski at molgen.mpg.de>
>> To: "Talita Leite" <talitaperciano at hotmail.com>
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] RMySQL
>> Date: Thu, 01 Jul 2004 18:46:06 +0200
>>
>> Hi!
>> I was installing RMySQL quite recently on Linux and had some troubles
>> which
>> I was able to solve. So maybee I can help you.
>> But first I have to know what error messages you are getting on which
>> operating system you are installing, which version of the package.
>>
>> Sincerely Eryk
>>
>>
>>
> *********** REPLY SEPARATOR  ***********
> 
>>> On 01.07.2004 at 13:14 Talita Leite wrote:
>>>
>> >Hi!!
>> >
>> >I want some help to install the RMySQL package. I've tried to configure
>> >some
>> >things but i'm still getting erros. Anybody could help me??
>> >
>> >Thank's
>> >
>> >
>> >
>> >Talita Perciano Costa Leite
>> >Graduanda em Ci??ncia da Computa????o
>> >Universidade Federal de Alagoas - UFAL
>> >Departamento de Tecnologia da Informa????o - TCI
>> >Constru????o de Conhecimento por Agrupamento de Dados - CoCADa
>> >
>> >______________________________________________
>> >R-help at stat.math.ethz.ch mailing list
>> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide!
>> >http://www.R-project.org/posting-guide.html
> 
> 
> 
> 
> 
> 
> 
> Talita Perciano Costa Leite
> Graduanda em Ci??ncia da Computa????o
> Universidade Federal de Alagoas - UFAL
> Departamento de Tecnologia da Informa????o - TCI
> Constru????o de Conhecimento por Agrupamento de Dados - CoCADa
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From bates at stat.wisc.edu  Sat Jul  3 13:35:59 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 03 Jul 2004 06:35:59 -0500
Subject: [R] How to get the normal direction to a plane?
In-Reply-To: <000001c4606f$78da5f30$ab8d7ca5@FYOC1>
References: <000001c4606f$78da5f30$ab8d7ca5@FYOC1>
Message-ID: <40E69A1F.3020602@stat.wisc.edu>

Fred wrote:

> Dear All
>  
> Maybe the following is a stupid question.
> Assume I have 3 coordinate points (not limited to be in 2D or 3D space)
> a, b, c.
> It is known that these 3 points will define a plane.
> The problem is how to get the normal direction that is orthogonal to
> this plane.
>  
> Is there an easy way to calculate it using the values of a, b, and c?

In the general problem of k vectors of length n, create the n by k-1 
matrix of differences v_i - v_k for i = 1,...,k-1, take its QR 
decomposition, and form Q.  The last n + 1 - k columns of Q are 
orthogonal to the affine subspace that contains the k original points.



From rvaradha at jhsph.edu  Sat Jul  3 16:31:52 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Sat, 3 Jul 2004 10:31:52 -0400
Subject: [R] counting the occurrences of vectors
Message-ID: <E619BDBD99B4F74D9DCA32F43BE926714C73A9@XCH-VN02.sph.ad.jhsph.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040703/dadddd69/attachment.pl

From spencer.graves at pdf.com  Sat Jul  3 17:27:43 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 03 Jul 2004 08:27:43 -0700
Subject: [R] counting the occurrences of vectors
In-Reply-To: <E619BDBD99B4F74D9DCA32F43BE926714C73A9@XCH-VN02.sph.ad.jhsph.edu>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73A9@XCH-VN02.sph.ad.jhsph.edu>
Message-ID: <40E6D06F.4010005@pdf.com>

      What have you tried?  Have you considered something like the 
following: 


n <- 4
m <- 3
k <- 2
A <- array(1, dim=c(n, k))
B <- array(1, dim=c(m,k))

BinA <- rep(NA, m)
tA <- t(A)
for(i in 1:m){
  BinA[i] <- sum(apply(B[i,]==tA, 2, sum)==k)
}
 
 > BinA
[1] 4 4 4

      hope this helps.  spencer graves

Ravi Varadhan wrote:

>Hi:
> 
>I have two matrices, A and B, where A is n x k, and B is m x k, where n >> m >> k.  Is there a computationally fast way to count the number of times each row (a k-vector) of B occurs in A?  Thanks for any suggestions.
> 
>Best,
>Ravi. 
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ivo_welch-rstat8783 at mailblocks.com  Sat Jul  3 17:45:45 2004
From: ivo_welch-rstat8783 at mailblocks.com (ivo_welch-rstat8783@mailblocks.com)
Date: Sat, 03 Jul 2004 08:45:45 -0700
Subject: [R] options  --- na.rm , save-on-exit
In-Reply-To: <200407031002.i63A1qci000680@hypatia.math.ethz.ch>
References: <200407031002.i63A1qci000680@hypatia.math.ethz.ch>
Message-ID: <200407031545.i63Fjkr2008658@hypatia.math.ethz.ch>


dear R wizzards:  two options() related questions.

[a] options(na.action):  many of my variables have missing variables, 
so I would like to set a default to ignore, especially in univariate 
functions like mean() and median() .  alas, without na.rm=T in the 
functions themselves, I always get an NA.  my code is full of na.rm=T 
is there a magic invokation of options with na.action that is honored 
by these functions?

[b] options(?): how do I get R to not prompt me for saving the 
workspace upon exit, but to instead automatically save the command 
history .Rhistory but not the data .RData ?

help appreciated.

sincerely,

/iaw
---
ivo welch
professor of finance and economics
brown / nber / yale



From a.prioglio at city.ac.uk  Sat Jul  3 17:45:26 2004
From: a.prioglio at city.ac.uk (a.prioglio@city.ac.uk)
Date: Sat, 3 Jul 2004 16:45:26 +0100
Subject: [R] Recoding scores of negatively worded item
Message-ID: <20040703154526.GA3517@anaconda.dogbert.ntt.it>

Hi,

I'm new to R so please fogive if I write someting silly ...

I need to recode a series of responses from a number of questionnaires.

The data is read via ODBC from a database where all responses are coded
as tables of the form (id, question, score).

After dealing with recoding of missing values, I need to "invert" the
scores of some questionnaire's item in the form x <- (n - x) where n is
the range of allowed responses + 1, e.g. if score can range from 1 to 4
n would by 5.

I am using R version 1.9.1 and 1.8.1 with identical outcome.

If from the R interpreter I write

ces[is.element(ces$question,c(1,3,5),]$score <- 5 -
ces[is.element(ces$question,c(1,3,5),]$score

the system correctly recode the scores for questions 1,3,5 on the table
ces.

If the same expression is processed as part of a script I get a "syntax
error".

My question is a) is this the best way to recode scores? (I did look at
the package car but I did not see how to perform a conditional recoding,
nor was obvious how to to operations on scores)

b) why there is a different behavior from the command line and from a
script?

c) how to solve the problem? (As the amount of data is large I need to
do everything via scripts)

Thank you for your attention.
-- 
Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From MSchwartz at MedAnalytics.com  Sat Jul  3 17:50:14 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat, 03 Jul 2004 10:50:14 -0500
Subject: [R] counting the occurrences of vectors
In-Reply-To: <E619BDBD99B4F74D9DCA32F43BE926714C73A9@XCH-VN02.sph.ad.jhsph.edu>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73A9@XCH-VN02.sph.ad.jhsph.edu>
Message-ID: <1088869814.10847.94.camel@localhost.localdomain>

On Sat, 2004-07-03 at 09:31, Ravi Varadhan wrote:
> Hi:
>  
> I have two matrices, A and B, where A is n x k, and B is m x k, where
> n >> m >> k.  Is there a computationally fast way to count the number
> of times each row (a k-vector) of B occurs in A?  Thanks for any
> suggestions.
>  
> Best,
> Ravi. 

How about something like this:

row.match <- function(m1, m2)
{
  if (ncol(m1) != (ncol(m2)))
    stop("Matrices must have the same number of columns")

  m1.l <- apply(m1, 1, list)
  m2.l <- apply(m2 ,1, list)

  # return boolean for m1.l in m2.l
  m1.l %in% m2.l
}


Example of use:

m <- matrix(1:20, ncol = 4, byrow = TRUE)
n <- matrix(1:40, ncol = 4, byrow = TRUE)

> m
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    5    6    7    8
[3,]    9   10   11   12
[4,]   13   14   15   16
[5,]   17   18   19   20

> n
      [,1] [,2] [,3] [,4]
 [1,]    1    2    3    4
 [2,]    5    6    7    8
 [3,]    9   10   11   12
 [4,]   13   14   15   16
 [5,]   17   18   19   20
 [6,]   21   22   23   24
 [7,]   25   26   27   28
 [8,]   29   30   31   32
 [9,]   33   34   35   36
[10,]   37   38   39   40

> row.match(n, m)
 [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE

If you want to know which rows from n are matches:

> n[row.match(n, m), ]
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    5    6    7    8
[3,]    9   10   11   12
[4,]   13   14   15   16
[5,]   17   18   19   20

and if you just want the indices from n:

> which(row.match(n, m))
[1] 1 2 3 4 5



For timing, if I create some large matrices:

> m <- matrix(1:20000, ncol = 4, byrow = TRUE)
> nrow(m)
[1] 5000

> n <- matrix(1:40000, ncol = 4, byrow = TRUE)
> nrow(n)
[1] 10000

> system.time(row.match(n, m))
[1] 0.39 0.01 0.41 0.00 0.00

> length(row.match(n, m))
[1] 10000


Does that get you what you want?

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Sat Jul  3 18:12:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 3 Jul 2004 16:12:10 +0000 (UTC)
Subject: [R] counting the occurrences of vectors
References: <E619BDBD99B4F74D9DCA32F43BE926714C73A9@XCH-VN02.sph.ad.jhsph.edu>
Message-ID: <loom.20040703T180845-770@post.gmane.org>

Ravi Varadhan <rvaradha <at> jhsph.edu> writes:

> Hi:
> 
> I have two matrices, A and B, where A is n x k, and B is m x k, where n >> m 
>> k.  Is there a computationally fast way to
> count the number of times each row (a k-vector) of B occurs in A?  Thanks 
for any suggestions.
> 
> Best,
> Ravi. 

Here are two approaches.  The first one is an order of magnitude faster
than the second.

R> # test matrices
R> set.seed(1)
R> a <- matrix(sample(3,1000,rep=T),nc=5)
R> b <- matrix(sample(3,100,rep=T),nc=5)

R> f1 <- function(a,b) {
+ a2 <- apply(a, 1, paste, collapse=":")
+ b2 <- apply(b, 1, paste, collapse=":")
+ c(table(c(a2,unique(b2)))[b2] - 1)
+ }

R> f2 <- function(a,b) {
+ ta <- t(a)
+ apply(b,1,function(x)sum(apply(ta == x,2,all)))
+ }

R> gc(); system.time(ans1 <- f1(a,b))
         used (Mb) gc trigger (Mb)
Ncells 458311 12.3     818163 21.9
Vcells 124264  1.0     786432  6.0
[1] 0.03 0.00 0.03   NA   NA

R> gc(); system.time(ans2 <- f2(a,b))
         used (Mb) gc trigger (Mb)
Ncells 458312 12.3     818163 21.9
Vcells 124270  1.0     786432  6.0
[1] 0.1 0.0 0.1  NA  NA

R> all.equal(ans1, ans2)
[1] TRUE



From ligges at statistik.uni-dortmund.de  Sat Jul  3 18:15:04 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 03 Jul 2004 18:15:04 +0200
Subject: [R] options  --- na.rm , save-on-exit
In-Reply-To: <200407031545.i63Fjkr2008658@hypatia.math.ethz.ch>
References: <200407031002.i63A1qci000680@hypatia.math.ethz.ch>
	<200407031545.i63Fjkr2008658@hypatia.math.ethz.ch>
Message-ID: <40E6DB88.6030406@statistik.uni-dortmund.de>

ivo_welch-rstat8783 at mailblocks.com wrote:
> 
> dear R wizzards:  two options() related questions.
> 
> [a] options(na.action):  many of my variables have missing variables, so 
> I would like to set a default to ignore, especially in univariate 
> functions like mean() and median() .  alas, without na.rm=T in the 
> functions themselves, I always get an NA.  my code is full of na.rm=T is 
> there a magic invokation of options with na.action that is honored by 
> these functions?

No.


> [b] options(?): how do I get R to not prompt me for saving the workspace 
> upon exit, but to instead automatically save the command history 
> .Rhistory but not the data .RData ?

you can define a function like:

Q <- function (save = "no", status = 0, runLast = TRUE){
   savehistory()
   .Internal(quit(save, status, runLast))
}

and call Q(), if you want to exit.

Uwe Ligges



> help appreciated.
> 
> sincerely,
> 
> /iaw
> ---
> ivo welch
> professor of finance and economics
> brown / nber / yale
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From baron at psych.upenn.edu  Sat Jul  3 18:17:11 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 3 Jul 2004 12:17:11 -0400
Subject: [R] Recoding scores of negatively worded item
In-Reply-To: <20040703154526.GA3517@anaconda.dogbert.ntt.it>
References: <20040703154526.GA3517@anaconda.dogbert.ntt.it>
Message-ID: <20040703161711.GA10228@psych>

On 07/03/04 16:45, a.prioglio at city.ac.uk wrote:
>Hi,
>
>I'm new to R so please fogive if I write someting silly ...
>
>I need to recode a series of responses from a number of questionnaires.
>
>The data is read via ODBC from a database where all responses are coded
>as tables of the form (id, question, score).
>
>After dealing with recoding of missing values, I need to "invert" the
>scores of some questionnaire's item in the form x <- (n - x) where n is
>the range of allowed responses + 1, e.g. if score can range from 1 to 4
>n would by 5.
>
>I am using R version 1.9.1 and 1.8.1 with identical outcome.
>
>If from the R interpreter I write
>
>ces[is.element(ces$question,c(1,3,5),]$score <- 5 -
>ces[is.element(ces$question,c(1,3,5),]$score
>
>the system correctly recode the scores for questions 1,3,5 on the table
>ces.
>
>If the same expression is processed as part of a script I get a "syntax
>error".
>
>My question is a) is this the best way to recode scores? (I did look at
>the package car but I did not see how to perform a conditional recoding,
>nor was obvious how to to operations on scores)

Other (but similar) ways you might try are:

ces[ces$question %in% c(1,3,5),]$score <- 5-ces[ces$question %in%
 c(1,3,5),]$score

ces$score <- ifelse(ces$question %in% c(1,3,5),5-ces$score,ces$score)

>b) why there is a different behavior from the command line and from a
>script?

Could the problem be on the line before the one that gives the error?

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From spencer.graves at pdf.com  Sat Jul  3 18:49:48 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 03 Jul 2004 09:49:48 -0700
Subject: [R] options  --- na.rm , save-on-exit
In-Reply-To: <40E6DB88.6030406@statistik.uni-dortmund.de>
References: <200407031002.i63A1qci000680@hypatia.math.ethz.ch>	<200407031545.i63Fjkr2008658@hypatia.math.ethz.ch>
	<40E6DB88.6030406@statistik.uni-dortmund.de>
Message-ID: <40E6E3AC.6020905@pdf.com>

      I presume by "no" Uwe means that there is apparently nothing as 
simple as changing "na.rm" to TRUE in "options". 

      However, you could redefine the functions "mean" and "median" so 
the default was "na.rm=TRUE".  That's easy to do with median:  Type 
"median" at a command prompt, copy the result to a script file, modify 
it, and source it.  You could also build your own package and attach it 
in a leading position in your search path so your version of median, 
etc., got used instead of the system version.  Doing this with "mean" is 
harder, because is a generic function, which means that you would need 
to know how to modify generic functions. 

      I would not recommend this.  To take an extreme analogy, I'm 
reminded of the old joke about a state senator in the sovereign state of 
__________ (you pick it), who declared that 3.14, etc., was too hard for 
school children to learn, and it school would be easier if pi were 3.  
He therefore introduced legislation to make pi = 3 (in his state, of 
course).  You can do that in R, just by typing "pi <- 3" at any command 
prompt.  However, it might have unintended consequences. 

      hope this helps. 
      spencer graves

Uwe Ligges wrote:

> ivo_welch-rstat8783 at mailblocks.com wrote:
>
>>
>> dear R wizzards:  two options() related questions.
>>
>> [a] options(na.action):  many of my variables have missing variables, 
>> so I would like to set a default to ignore, especially in univariate 
>> functions like mean() and median() .  alas, without na.rm=T in the 
>> functions themselves, I always get an NA.  my code is full of na.rm=T 
>> is there a magic invokation of options with na.action that is honored 
>> by these functions?
>
>
> No.
>
>
>> [b] options(?): how do I get R to not prompt me for saving the 
>> workspace upon exit, but to instead automatically save the command 
>> history .Rhistory but not the data .RData ?
>
>
> you can define a function like:
>
> Q <- function (save = "no", status = 0, runLast = TRUE){
>   savehistory()
>   .Internal(quit(save, status, runLast))
> }
>
> and call Q(), if you want to exit.
>
> Uwe Ligges
>
>
>
>> help appreciated.
>>
>> sincerely,
>>
>> /iaw
>> ---
>> ivo welch
>> professor of finance and economics
>> brown / nber / yale
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Sat Jul  3 19:17:38 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 3 Jul 2004 17:17:38 +0000 (UTC)
Subject: [R] Recoding scores of negatively worded item
References: <20040703154526.GA3517@anaconda.dogbert.ntt.it>
	<20040703161711.GA10228@psych>
Message-ID: <loom.20040703T191451-970@post.gmane.org>

Jonathan Baron <baron <at> psych.upenn.edu> writes:


: ces$score <- ifelse(ces$question %in% c(1,3,5),5-ces$score,ces$score)

One minor improvement in readability might be:

ces$score <- with(ces, ifelse(question %in% c(1,3,5), 5-score, score))



From a.prioglio at city.ac.uk  Sat Jul  3 19:52:34 2004
From: a.prioglio at city.ac.uk (a.prioglio@city.ac.uk)
Date: Sat, 3 Jul 2004 18:52:34 +0100
Subject: [R] Recoding scores of negatively worded item
In-Reply-To: <20040703161711.GA10228@psych>
References: <20040703154526.GA3517@anaconda.dogbert.ntt.it>
	<20040703161711.GA10228@psych>
Message-ID: <20040703175234.GD3517@anaconda.dogbert.ntt.it>

On Sat, Jul 03, 2004 at 12:17:11PM -0400, Jonathan Baron wrote:
> >b) why there is a different behavior from the command line and from a
> >script?
> 
> Could the problem be on the line before the one that gives the error?

I guess I discovered what was the issue ( I knew it was something silly)

In the script I broke the line in two for easier reading forgetting that
the left hand side is a valid statement in itself!

This is nasty.

Thanks again for your help.

-- 
Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From ripley at stats.ox.ac.uk  Sat Jul  3 20:02:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Jul 2004 19:02:38 +0100 (BST)
Subject: [R] options  --- na.rm , save-on-exit
In-Reply-To: <200407031545.i63Fjkr2008658@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0407031900060.1296-100000@gannet.stats>

On Sat, 3 Jul 2004 ivo_welch-rstat8783 at mailblocks.com wrote:

> [b] options(?): how do I get R to not prompt me for saving the 
> workspace upon exit, but to instead automatically save the command 
> history .Rhistory but not the data .RData ?

The first is in the appendix to An Introduction to R: --no-save etc.

For the second, see ?savehistory and especially its example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Jul  3 20:07:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Jul 2004 19:07:37 +0100 (BST)
Subject: [R] options  --- na.rm , save-on-exit
In-Reply-To: <40E6E3AC.6020905@pdf.com>
Message-ID: <Pine.LNX.4.44.0407031903260.1296-100000@gannet.stats>

On Sat, 3 Jul 2004, Spencer Graves wrote:

>       I presume by "no" Uwe means that there is apparently nothing as 
> simple as changing "na.rm" to TRUE in "options". 
> 
>       However, you could redefine the functions "mean" and "median" so 
> the default was "na.rm=TRUE".  That's easy to do with median:  Type 
> "median" at a command prompt, copy the result to a script file, modify 
> it, and source it.  You could also build your own package and attach it 
> in a leading position in your search path so your version of median, 
> etc., got used instead of the system version.  Doing this with "mean" is 
> harder, because is a generic function, which means that you would need 
> to know how to modify generic functions. 
> 
>       I would not recommend this.  To take an extreme analogy, I'm 
> reminded of the old joke about a state senator in the sovereign state of 
> __________ (you pick it), who declared that 3.14, etc., was too hard for 
> school children to learn, and it school would be easier if pi were 3.  
> He therefore introduced legislation to make pi = 3 (in his state, of 
> course).  You can do that in R, just by typing "pi <- 3" at any command 
> prompt.  However, it might have unintended consequences. 

In this case, it may not have the intended consequence.  mean (and to a 
lesser extent median) is widely used by R itself, and namespaces make sure 
that most of those uses will ignore your redefinitions.  So please don't 
redefine system functions, but rather define your own like medianNoNA.
Then only you get affected, and in particular the R-helpers don't have to 
second guess what you have done several months later when you forget about 
the change.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From robin_gruna at hotmail.com  Sat Jul  3 20:26:38 2004
From: robin_gruna at hotmail.com (Robin Gruna)
Date: Sat, 3 Jul 2004 20:26:38 +0200
Subject: [R] graphic representation of a qda object
Message-ID: <BAY2-DAV11WfL2O7vPj0003beba@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040703/7e16fe18/attachment.pl

From gvozdik at brno.cas.cz  Sat Jul  3 23:11:26 2004
From: gvozdik at brno.cas.cz (Lumir Gvozdik)
Date: Sat, 03 Jul 2004 23:11:26 +0200
Subject: [R] recommended citation
Message-ID: <40E720FE.8090605@brno.cas.cz>

Dear Sirs,

I used the nlme package for the statistical analysis of my data for 
prepared MS. Please, can you write me what is your recommended form of 
citation of this program?
Thanks in advance for your reply.

Sincerely,

Lumir Gvozdik



From owl_of_minerva at hotmail.com  Sun Jul  4 02:51:41 2004
From: owl_of_minerva at hotmail.com (Matthew Cohen)
Date: Sat, 03 Jul 2004 20:51:41 -0400
Subject: [R] Embarrassingly naive question regarding graphics on Mac OS X
Message-ID: <BD0CCCDD.7734%owl_of_minerva@hotmail.com>

I am having trouble saving graphs.  Using the Aqua interface (which is not
my preferred interface), I have no problems plotting a graph, adding
additional lines, points, references, etc., and then saving it to a file
using, for example, the dev2bitmap command.  I have found that, running R
with Xemacs+ESS under X11 (which I prefer over Aqua), this is not possible.
I can either send the graph to a Quartz or X11 window, where I can then
manipulate it using my mouse, but not save it (using dev2bitmap or
postscript or any other saving command creates a 4kb file that is entirely
blank when loaded using another viewing program); or I can save it, but
without the opportunity of manipulating it first.

I'm guessing that when I run R through X11/Xemacs/ESS, that it doesn't have
access to the postscript converter that it uses when I run it through the
Aqua interface.  But this is just a guess, and regardless of whether it is
correct, I have no idea how to fix the problem.  Any suggestions would be
enormously appreciated.

I am running R 1.9.1 on Mac OS 10.3.4 with Xemacs 21.4-15 and ESS 5.2.0.
I've installed Xemacs using Fink 0.7.0, manually installed ESS according to
the directions included in its readme file, and compiled R from source,
placing the R.Framework in my /sw directory.

Matt



From wang at galton.uchicago.edu  Sun Jul  4 03:32:02 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sat, 3 Jul 2004 20:32:02 -0500 (CDT)
Subject: [R] the commands to easily find the dual variables of a standard LP
 problem
In-Reply-To: <200406271001.i5RA0dPf006004@hypatia.math.ethz.ch>
References: <200406271001.i5RA0dPf006004@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0407032022440.21091@aitken.uchicago.edu>

Dear  all
I use "simplex" to resolve a standard LP problem, further, I want to know 
the dual variables of the LP problem (the dual variables when the standard 
LP ,or the primal problem, get its optimal solution).
 
Is there any command for me to easily get them(the dual variables)?
any suggestions appreciated
thank you in advance

best regards
y.w



From ronpicci at yahoo.fr  Sun Jul  4 04:11:25 2004
From: ronpicci at yahoo.fr (=?iso-8859-1?q?Ron=20Piccinini?=)
Date: Sun, 4 Jul 2004 04:11:25 +0200 (CEST)
Subject: [R] Use of nnet() with package SNOW ?
Message-ID: <20040704021125.20801.qmail@web52908.mail.yahoo.com>

Hello R masteRs,

I am trying to train a neural network whose training
set is about 910,000 rows by 5 columns. I am running R
on a small cluster of 8 machines (7 slaves) using the
SNOW package. Is there a smart way to use all 8
processors to train the neural net? or am I just
better off putting all the RAM possible on one machine
and run nnet on one processor? I thought about storing
each column of the training set on a seperate node and
have the master node execute something of the sort:
nnet((cbind(clustr[[1]],clustr[[2]],...,clustr[[5]])),targetvector,,5)

(where clstr is the name of the contents of the 
cluster (is diferent from "cl")
However I think that when I do that R loads the
cbind-ed matrix in the master's node environment and
therefore no parallel processing gains are realized.
Thanks in advance for your comments and suggestions,

Ron.



From umalvarez at fata.unam.mx  Sun Jul  4 05:25:27 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Sat, 3 Jul 2004 22:25:27 -0500 (CDT)
Subject: [R] Embarrassingly naive question regarding graphics on Mac OS X
In-Reply-To: <BD0CCCDD.7734%owl_of_minerva@hotmail.com>
Message-ID: <Pine.LNX.4.44.0407032221020.22984-100000@athena.fata.unam.mx>

Hi, Mathew!

Once you are done with your graphic 

dev.copy2eps(file="some_name.eps")

If you/like another format, take a look at 

?dev.copy

Regards.


On Sat, 3 Jul 2004, Matthew Cohen wrote:

> I am having trouble saving graphs.  Using the Aqua interface (which is not
> my preferred interface), I have no problems plotting a graph, adding
> additional lines, points, references, etc., and then saving it to a file
> using, for example, the dev2bitmap command.  I have found that, running R
> with Xemacs+ESS under X11 (which I prefer over Aqua), this is not possible.
> I can either send the graph to a Quartz or X11 window, where I can then
> manipulate it using my mouse, but not save it (using dev2bitmap or
> postscript or any other saving command creates a 4kb file that is entirely
> blank when loaded using another viewing program); or I can save it, but
> without the opportunity of manipulating it first.
> 
> I'm guessing that when I run R through X11/Xemacs/ESS, that it doesn't have
> access to the postscript converter that it uses when I run it through the
> Aqua interface.  But this is just a guess, and regardless of whether it is
> correct, I have no idea how to fix the problem.  Any suggestions would be
> enormously appreciated.
> 
> I am running R 1.9.1 on Mac OS 10.3.4 with Xemacs 21.4-15 and ESS 5.2.0.
> I've installed Xemacs using Fink 0.7.0, manually installed ESS according to
> the directions included in its readme file, and compiled R from source,
> placing the R.Framework in my /sw directory.
> 
> Matt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From keithw at med.usyd.edu.au  Sun Jul  4 09:21:36 2004
From: keithw at med.usyd.edu.au (Keith Wong)
Date: Sun,  4 Jul 2004 17:21:36 +1000
Subject: [R] Random intercept model with time-dependent covariates,
	results different from SAS
In-Reply-To: <200407031005.i63A1qdB000680@hypatia.math.ethz.ch>
References: <200407031005.i63A1qdB000680@hypatia.math.ethz.ch>
Message-ID: <1088925696.40e7b00087429@www.mail.med.usyd.edu.au>

Dear list-members

I am new to R and a statistics beginner. I really like the ease with which I can
extract and manipulate data in R, and would like to use it primarily.  I've
been  learning by checking analyses that have already been run in SAS.

In an experiment with Y being a response variable, and group a 2-level
between-subject factor, and time a 5-level within-subject factor. 2
time-dependent covariates are also measured (continuous variables W and Z). The
subject id variable (ID) is unique to each subject, and is not duplicated
across groups.

I tried to fit a random intercept model in R (after setting options(contrasts =
c(factor = "contr.SAS", ordered = "contr.poly")) as recommended on this list),
and making the time, group and id variables factors:

> g2 = lme(Y ~ time + group + time:group + W + Z, random = ~ 1 | id, data =
datamod)

> anova(g2)
            numDF denDF  F-value p-value
(Intercept)     1    42  5.54545  0.0233
time            4    42 16.41069  <.0001
group           1    11  0.83186  0.3813
W               1    42  0.07555  0.7848
Z               1    42 45.23577  <.0001
time:group      4    42  3.04313  0.0273


I compared the results using SAS proc mixed:
proc mixed data = datamod;
class id time group;
model Y = time group time*group W Z /s;
random int / sub = id;
run;

And get the following anova table for the fixed effects:

                              Type 3 Tests of Fixed Effects

                                    Num     Den
                     Effect          DF      DF    F Value    Pr > F

                     time             4      42       2.55    0.0534
                     group            1      42       0.54    0.4664
                     time*group       4      42       3.04    0.0273
                     W                1      42       8.80    0.0050
                     Z                1      42      32.52    <.0001

I am perplexed to see that the test for the main effect "time" is quite
different. Both models seem to be specified equivalently to me, am I doing
something wrong - particularly with the inclusion of the time-dependent
covariates W and Z? I have looked at the data in both programmes and they are
the same. There are no missing observations.

I a simpler model without the time-dependent covariates, and in this case the
results are similar:
[R]
> g1 = lme(Y ~ time + group + time:group, random = ~ 1 | id, data = datamod)
> anova(g1)
            numDF denDF   F-value p-value
(Intercept)     1    44  3.387117  0.0725
time            4    44 10.620547  <.0001
group           1    11  0.508092  0.4908
time:group      4    44  3.961726  0.0079


[SAS]
proc mixed data = datamod;
class id time group;
model Y = time group time*group /s;
random int / sub = id;
run;

                              Type 3 Tests of Fixed Effects

                                    Num     Den
                     Effect          DF      DF    F Value    Pr > F

                     time             4      44       7.75    <.0001
                     group            1      44       0.51    0.4797
                     time*group       4      44       3.96    0.0079

Secondly, is there no R equivalent of the "LSMEANS" statement in SAS? Is there a
work-around?

I would very much appreciate assistance.

Thanks. Keith



From ripley at stats.ox.ac.uk  Sun Jul  4 10:13:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 4 Jul 2004 09:13:57 +0100 (BST)
Subject: [R] Random intercept model with time-dependent covariates,
	results different from SAS
In-Reply-To: <1088925696.40e7b00087429@www.mail.med.usyd.edu.au>
Message-ID: <Pine.LNX.4.44.0407040840540.9814-100000@gannet.stats>

Looking at the significance of a main effect (group) in the presence of an
interaction (time:group) is hard to interpret, and in your case is I think
not even interesting.  (The `main effect' probably represents difference
in intercept for the time effect, that is the group difference at the last
time.  But see the next para.)  Note that the two systems are returning
different denominator dfs.

At this point you have not told us enough.  My guess is that you have
complete balance with the same number of subjects in each group.  In that
case the `group' effect is in the between-subjects stratum (as defined for
the use of Error in aov, which you could also do), and thus R's 11 df
would be right (rather than 44, without W and Z).  Without balance Type
III tests get much harder to interpret and the `group' effect would appear
in two strata and there is no simple F test in the classical theory.  So
further guessing, SAS may have failed to detect balance and so used the
wrong test.

The time-dependent covariates muddy the issue more, and I looked mainly at 
the analyses without them.  Again, a crucial fact is not here: do the 
covariates depend on the subjects as well?

The good news is that the results _are_ similar.  You do have different
time behaviour in the two groups.  So stop worrying about tests of
uninteresting hypotheses and concentrate of summarizing that difference.

On Sun, 4 Jul 2004, Keith Wong wrote:

> Dear list-members
> 
> I am new to R and a statistics beginner. I really like the ease with which I can
> extract and manipulate data in R, and would like to use it primarily.  I've
> been  learning by checking analyses that have already been run in SAS.

That presumes SAS gets them `right'.  A body of experienced statisticians
thinks that `Type III' tests are somewhere between `often misleading' and
`evil'. It certainly presents tests that are uninteresting without you
asking for them.  It reminds me of the days of yore when we taught using
Minitab and had to explain that the Durbin-Watson test was not relevant to
almost all regressions the students would see, yet appeared on every piece
of output.

The standard output from the lme fit (which you have not shown us) would 
be more revealing.  I don't think I have ever used anova() on a single lme 
fit (I would look at the estimates and use anova on two fits, which is 
full (RE)ML likelihood ratio not a Wald approximation).

May I suggest a better way to learn is to understand published examples 
using lme, in Pinheiro & Bates (2000) or MASS4 for example.


> In an experiment with Y being a response variable, and group a 2-level
> between-subject factor, and time a 5-level within-subject factor. 2
> time-dependent covariates are also measured (continuous variables W and
> Z). The subject id variable (ID) is unique to each subject, and is not
> duplicated across groups.
> 
> I tried to fit a random intercept model in R (after setting options(contrasts =
> c(factor = "contr.SAS", ordered = "contr.poly")) as recommended on this list),
> and making the time, group and id variables factors:
> 
> > g2 = lme(Y ~ time + group + time:group + W + Z, random = ~ 1 | id, data =
> datamod)
> 
> > anova(g2)
>             numDF denDF  F-value p-value
> (Intercept)     1    42  5.54545  0.0233
> time            4    42 16.41069  <.0001
> group           1    11  0.83186  0.3813
> W               1    42  0.07555  0.7848
> Z               1    42 45.23577  <.0001
> time:group      4    42  3.04313  0.0273
> 
> 
> I compared the results using SAS proc mixed:
> proc mixed data = datamod;
> class id time group;
> model Y = time group time*group W Z /s;
> random int / sub = id;
> run;
> 
> And get the following anova table for the fixed effects:
> 
>                               Type 3 Tests of Fixed Effects
> 
>                                     Num     Den
>                      Effect          DF      DF    F Value    Pr > F
> 
>                      time             4      42       2.55    0.0534
>                      group            1      42       0.54    0.4664
>                      time*group       4      42       3.04    0.0273
>                      W                1      42       8.80    0.0050
>                      Z                1      42      32.52    <.0001
> 
> I am perplexed to see that the test for the main effect "time" is quite
> different. Both models seem to be specified equivalently to me, am I doing
> something wrong - particularly with the inclusion of the time-dependent
> covariates W and Z? I have looked at the data in both programmes and they are
> the same. There are no missing observations.
> 
> I a simpler model without the time-dependent covariates, and in this case the
> results are similar:
> [R]
> > g1 = lme(Y ~ time + group + time:group, random = ~ 1 | id, data = datamod)
> > anova(g1)
>             numDF denDF   F-value p-value
> (Intercept)     1    44  3.387117  0.0725
> time            4    44 10.620547  <.0001
> group           1    11  0.508092  0.4908
> time:group      4    44  3.961726  0.0079
> 
> 
> [SAS]
> proc mixed data = datamod;
> class id time group;
> model Y = time group time*group /s;
> random int / sub = id;
> run;
> 
>                               Type 3 Tests of Fixed Effects
> 
>                                     Num     Den
>                      Effect          DF      DF    F Value    Pr > F
> 
>                      time             4      44       7.75    <.0001
>                      group            1      44       0.51    0.4797
>                      time*group       4      44       3.96    0.0079
> 
> Secondly, is there no R equivalent of the "LSMEANS" statement in SAS? Is there a
> work-around?
> 
> I would very much appreciate assistance.
> 
> Thanks. Keith
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ajayshah at mayin.org  Sun Jul  4 10:45:37 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 4 Jul 2004 14:15:37 +0530
Subject: [R] Re: Seasonal ARMA model
Message-ID: <20040704084537.GQ897@igidr.ac.in>

> It might clarify your thinking to note that a seasonal ARIMA model
> is just an ``ordinary'' ARIMA model with some coefficients
> constrained to be 0 in an efficient way.  E.g.  a seasonal AR(1) s =
> 4 model is the same as an ordinary (nonseasonal) AR(4) model with
> coefficients theta_1, theta_2, and theta_3 constrained to be 0.  You
> can get the same answer as from a seasonal model by using the
> ``fixed'' argument to arima.  E.g.:

   set.seed(42)
   x <- arima.sim(list(ar=c(0,0,0,0.5)),300)
   f1 = arima(x,seasonal=list(order=c(1,0,0),period=4))
   f2 = arima(x,order=c(4,0,0),fixed=c(0,0,0,NA,NA),transform.pars=FALSE)

Is there a convenient URL which shows the mathematics of the seasonal
ARMA model, as implemented by R?

I understand f2 fine. I understand that you are saying that f1 is just
an AR(4) with the lags 1,2,3 constrained to 0. But I'm unable to
generalise this. What would be the meaning of mixing up both order and
seasonal? E.g. what would it mean to do something like:

 arima(x,order=c(2,0,0),seasonal=list(order=c(2,0,0),period=12))

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From keithw at med.usyd.edu.au  Sun Jul  4 11:21:32 2004
From: keithw at med.usyd.edu.au (Keith Wong)
Date: Sun,  4 Jul 2004 19:21:32 +1000
Subject: [R] Random intercept model with time-dependent covariates,
	results different from SAS
In-Reply-To: <Pine.LNX.4.44.0407040840540.9814-100000@gannet.stats>
References: <Pine.LNX.4.44.0407040840540.9814-100000@gannet.stats>
Message-ID: <1088932892.40e7cc1c8c24d@www.mail.med.usyd.edu.au>

Thank you for the very prompt response. I only included a small part of the
output to make the message brief. I'm sorry it did not provide enough detail to
answer my question. I have appended the summary() and anova() outputs to the
two models I fitted in R.

Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> Looking at the significance of a main effect (group) in the presence of an
> interaction (time:group) is hard to interpret, and in your case is I think
> not even interesting.  (The `main effect' probably represents difference
> in intercept for the time effect, that is the group difference at the last
> time.  But see the next para.)  Note that the two systems are returning
> different denominator dfs.


I take your point that the main effect is probably not interesting in the
presence of an interaction. I was checking the results for consistency to see
if I was doing the right thing. I was not 100% sure that the SAS code was in
itself correct. 
 
> At this point you have not told us enough.  My guess is that you have
> complete balance with the same number of subjects in each group.  In that
> case the `group' effect is in the between-subjects stratum (as defined for
> the use of Error in aov, which you could also do), and thus R's 11 df
> would be right (rather than 44, without W and Z).  Without balance Type
> III tests get much harder to interpret and the `group' effect would appear
> in two strata and there is no simple F test in the classical theory.  So
> further guessing, SAS may have failed to detect balance and so used the
> wrong test.

I had not appreciated the need for balance: in actual fact, one group has 5
subjects and the other 7. Will this be a problem? Would the R analysis still be
valid in that case?

 
> The time-dependent covariates muddy the issue more, and I looked mainly at 
> the analyses without them.  Again, a crucial fact is not here: do the 
> covariates depend on the subjects as well?

Yes the covariates are measures of blood pressure and pulse, and they depend on
the subjects as well.

> The good news is that the results _are_ similar.  You do have different
> time behaviour in the two groups.  So stop worrying about tests of
> uninteresting hypotheses and concentrate of summarizing that difference.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


Thank you. I was concerned that one or both methods were incorrect given the
results were inconsistent. Perhaps reassuringly, the parameter estimates for
the fixed effects in both SAS and R were the same.

Is the model specification OK for the model with just time, group and their
interaction?
Is the model specification with the 2 time dependent covariates appropriate?

Once again, I'm very grateful for the time you've taken to answer my questions.

Keith

[Output from the 2 models fitted in R follows]

> g1 = lme(Y ~ time + group + time:group, random = ~ 1 | id, data = datamod)

> anova(g1)
            numDF denDF   F-value p-value
(Intercept)     1    44  3.387117  0.0725
time            4    44 10.620547  <.0001
group           1    11  0.508092  0.4908
time:group      4    44  3.961726  0.0079
> summary(g1)
Linear mixed-effects model fit by REML
 Data: datamod 
       AIC      BIC    logLik
  372.4328 396.5208 -174.2164

Random effects:
 Formula: ~1 | id
        (Intercept) Residual
StdDev:    11.05975 3.228684

Fixed effects: Y ~ time + group + time:group 
              Value Std.Error DF   t-value p-value
(Intercept)   8.250  4.073428 44  2.025321  0.0489
time1        -0.250  1.614342 44 -0.154862  0.8776
time2        -8.125  1.614342 44 -5.033011  0.0000
time3        -8.875  1.614342 44 -5.497596  0.0000
time4        -4.250  1.614342 44 -2.632652  0.0116
group1        2.126  6.568205 11  0.323681  0.7523
time1:group1 -2.734  2.603048 44 -1.050307  0.2993
time2:group1  5.583  2.603048 44  2.144793  0.0375
time3:group1  5.549  2.603048 44  2.131732  0.0387
time4:group1  3.634  2.603048 44  1.396056  0.1697
 Correlation: 
             (Intr) time1  time2  time3  time4  group1 tm1:g1 tm2:g1 tm3:g1
time1        -0.198                                                        
time2        -0.198  0.500                                                 
time3        -0.198  0.500  0.500                                          
time4        -0.198  0.500  0.500  0.500                                   
group1       -0.620  0.123  0.123  0.123  0.123                            
time1:group1  0.123 -0.620 -0.310 -0.310 -0.310 -0.198                     
time2:group1  0.123 -0.310 -0.620 -0.310 -0.310 -0.198  0.500              
time3:group1  0.123 -0.310 -0.310 -0.620 -0.310 -0.198  0.500  0.500       
time4:group1  0.123 -0.310 -0.310 -0.310 -0.620 -0.198  0.500  0.500  0.500

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.63416413 -0.42033405  0.03577472  0.46164486  1.74068368 

Number of Observations: 65
Number of Groups: 13 


> g2 = lme(Y ~ time + group + time:group + W + Z, random = ~ 1 | id, data =
datamod)

> anova(g2)
            numDF denDF  F-value p-value
(Intercept)     1    42  5.54545  0.0233
time            4    42 16.41069  <.0001
group           1    11  0.83186  0.3813
W               1    42  0.07555  0.7848
Z               1    42 45.23577  <.0001
time:group      4    42  3.04313  0.0273

> summary(g2)
Linear mixed-effects model fit by REML
 Data: datamod 
       AIC      BIC    logLik
  355.2404 382.8245 -163.6202

Random effects:
 Formula: ~1 | id
        (Intercept) Residual
StdDev:    8.639157 2.597380

Fixed effects: Y ~ time + group + time:group + W + Z 
                 Value Std.Error DF   t-value p-value
(Intercept)  10.056433  9.583658 42  1.049331  0.3000
time1         0.209668  1.301306 42  0.161121  0.8728
time2         4.111435  2.556420 42  1.608278  0.1153
time3         0.423056  2.077066 42  0.203679  0.8396
time4        -3.976417  1.300572 42 -3.057437  0.0039
group1        4.677706  5.162006 11  0.906180  0.3843
W             0.377142  0.127146 42  2.966212  0.0050
Z            -0.531895  0.093276 42 -5.702395  0.0000
time1:group1 -0.845857  2.126289 42 -0.397809  0.6928
time2:group1 -5.145361  2.962470 42 -1.736848  0.0897
time3:group1 -3.261241  2.597008 42 -1.255769  0.2161
time4:group1  4.153245  2.096587 42  1.980956  0.0542
 Correlation: 
             (Intr) time1  time2  time3  time4  group1 W      Z      tm1:g1
tm2:g1
time1        -0.051                                                             
 
time2         0.199  0.308                                                      
 
time3         0.023  0.361  0.817                                               
 
time4        -0.029  0.501  0.293  0.342                                        
 
group1       -0.202  0.131  0.136  0.146  0.129                                 
 
W            -0.790  0.019  0.243  0.366 -0.015  0.044                          
 
Z            -0.146 -0.063 -0.853 -0.779 -0.041 -0.086 -0.409                   
 
time1:group1 -0.028 -0.601 -0.043 -0.074 -0.302 -0.187  0.147 -0.144            
 
time2:group1 -0.293 -0.262 -0.818 -0.642 -0.255 -0.198 -0.051  0.665  0.276     
 
time3:group1 -0.016 -0.286 -0.626 -0.774 -0.273 -0.214 -0.277  0.590  0.308 
0.668
time4:group1  0.065 -0.306 -0.116 -0.159 -0.616 -0.199  0.002 -0.046  0.497 
0.318
             tm3:g1
time1              
time2              
time3              
time4              
group1             
W                  
Z                  
time1:group1       
time2:group1       
time3:group1       
time4:group1  0.376

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.11181231 -0.43210237  0.04949838  0.32444580  2.77710590 

Number of Observations: 65
Number of Groups: 13 
>



From ripley at stats.ox.ac.uk  Sun Jul  4 11:24:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 4 Jul 2004 10:24:47 +0100 (BST)
Subject: [R] Re: Seasonal ARMA model
In-Reply-To: <20040704084537.GQ897@igidr.ac.in>
Message-ID: <Pine.LNX.4.44.0407041021440.9904-100000@gannet.stats>

On Sun, 4 Jul 2004, Ajay Shah wrote:

> > It might clarify your thinking to note that a seasonal ARIMA model
> > is just an ``ordinary'' ARIMA model with some coefficients
> > constrained to be 0 in an efficient way.  E.g.  a seasonal AR(1) s =
> > 4 model is the same as an ordinary (nonseasonal) AR(4) model with
> > coefficients theta_1, theta_2, and theta_3 constrained to be 0.  You
> > can get the same answer as from a seasonal model by using the
> > ``fixed'' argument to arima.  E.g.:
> 
>    set.seed(42)
>    x <- arima.sim(list(ar=c(0,0,0,0.5)),300)
>    f1 = arima(x,seasonal=list(order=c(1,0,0),period=4))
>    f2 = arima(x,order=c(4,0,0),fixed=c(0,0,0,NA,NA),transform.pars=FALSE)
> 
> Is there a convenient URL which shows the mathematics of the seasonal
> ARMA model, as implemented by R?

No, but there is a book, MASS4 (see the FAQ).  Although the software is in 
base R it was in fact written by me to support MASS4.

R follows S-PLUS in some of its choices of signs, which do differ between 
accounts.

> I understand f2 fine. I understand that you are saying that f1 is just
> an AR(4) with the lags 1,2,3 constrained to 0. But I'm unable to
> generalise this. What would be the meaning of mixing up both order and
> seasonal? E.g. what would it mean to do something like:
> 
>  arima(x,order=c(2,0,0),seasonal=list(order=c(2,0,0),period=12))

That is in MASS4 and most of the books referenced on the help page.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mathe at wias-berlin.de  Sun Jul  4 11:38:30 2004
From: mathe at wias-berlin.de (Peter Mathe)
Date: Sun, 04 Jul 2004 11:38:30 +0200
Subject: [R] Is there rpm for suse 9.1 under x86_64?
Message-ID: <40E7D016.4060705@wias-berlin.de>

I recently upgraded to Suse 9.1 for Amd64.
So far I could not find precompiled binaries of R-1.9.1 for this case.
So I tried installation from source, but could not succeed. Although the 
configuration/installation procedure ran without problems, the make 
check always ended with errors. When trying to run R , to see what's 
going on, the eigen() reported error code -18.
So, is a  rpm for R-base-1.9.1 under x86_64 for Suse available, or how 
can I succesfully install from sources?
Thank's for reading this message, Peter



From p.dalgaard at biostat.ku.dk  Sun Jul  4 11:53:54 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Jul 2004 11:53:54 +0200
Subject: [R] Is there rpm for suse 9.1 under x86_64?
In-Reply-To: <40E7D016.4060705@wias-berlin.de>
References: <40E7D016.4060705@wias-berlin.de>
Message-ID: <x2ekns2j4d.fsf@biostat.ku.dk>

Peter Mathe <mathe at wias-berlin.de> writes:

> I recently upgraded to Suse 9.1 for Amd64.
> So far I could not find precompiled binaries of R-1.9.1 for this case.
> So I tried installation from source, but could not succeed. Although
> the configuration/installation procedure ran without problems, the
> make check always ended with errors. When trying to run R , to see
> what's going on, the eigen() reported error code -18.
> So, is a  rpm for R-base-1.9.1 under x86_64 for Suse available, or how
> can I succesfully install from sources?

I can't get the upgrade working for me (SATA trouble -- again!) but I
have 9.0 on a system. This has run cleanly for a while with a
home-built RPM based on Detlef's SPEC file, as well as several local
builds. 

A good guess is that they upgraded GCC and something got broken --
again. You could try reducing the optimization levels on the relevant
files, or as the first thing on everything (-O0 in CFLAGS and FFLAGS).  

> Thank's for reading this message, Peter

How did you know I would, Peter? ;-)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jiachengyuan at hotmail.com  Sun Jul  4 16:09:28 2004
From: jiachengyuan at hotmail.com (Jiacheng Yuan)
Date: Sun, 04 Jul 2004 14:09:28 +0000
Subject: [R] how to use a script file for all the codes?
Message-ID: <BAY16-F36Cd5dqy4PqZ0000cac7@hotmail.com>

Hi there,

I am using the windows version R1.9.0.
I used to be a Splus user. When I used Splus to try some computation, I like 
to put all my codes in a script file and check them line by line. This way I 
can keep track of all my thinking and it's very easy to make correction at 
some earlier steps.

Now I can not find this script-file style in R. The software itself doesn't 
seem to have a script file editor. I can only use other editor software 
(e.g., notepad) to write a ".R" file, and then "source" it in R. It's not 
convenient to debug in this way.

Any one can help me?
Thank you very much!

Jia



From ripley at stats.ox.ac.uk  Sun Jul  4 16:15:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 4 Jul 2004 15:15:15 +0100 (BST)
Subject: [R] graphic representation of a qda object
In-Reply-To: <BAY2-DAV11WfL2O7vPj0003beba@hotmail.com>
Message-ID: <Pine.LNX.4.44.0407032025430.1393-100000@gannet.stats>

Please do your homework. qda is part of MASS (uncredited by you) and the 
posting guide does ask you to consult that book.  If you had done so you 
would have found examples (start with the one on p.340)

On Sat, 3 Jul 2004, Robin Gruna wrote:

> I'm a R newbie and I have a supervised 2-class classification problem.
> To find out the best representation of my data (dim = 45). I want to
> perform LDA und QDA on the diffrent data representations to find out,
> which is best to discriminate the 2 sets. For LDA there exists a method
> plot.lda shows (in the 2 class case) a histogramm of the data, projected
> onto the linear discriminants (pleas correct me if i'm wrong...). 

You have the help pages, so please do read them, carefully.  There is only 
one linear discriminant, and the plot method for lda can do more than 
that.

In your problem there is only one quadratic discriminant, and you could do 
the same thing.  I'll leave you to work out why it would be a lot less 
useful.

> Now to my question:  Is there a similiar possibility for plotting a QDA
> object ? I know, the discriminat function is quadratic, but perhaps
> someone has in idea of to represent this problem graphically.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Jul  4 16:29:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 4 Jul 2004 15:29:54 +0100 (BST)
Subject: [R] how to use a script file for all the codes?
In-Reply-To: <BAY16-F36Cd5dqy4PqZ0000cac7@hotmail.com>
Message-ID: <Pine.LNX.4.44.0407041515400.10220-100000@gannet.stats>

On Sun, 4 Jul 2004, Jiacheng Yuan wrote:

> I am using the windows version R1.9.0.
> I used to be a Splus user. When I used Splus to try some computation, I like 
> to put all my codes in a script file and check them line by line. This way I 
> can keep track of all my thinking and it's very easy to make correction at 
> some earlier steps.
> 
> Now I can not find this script-file style in R. The software itself doesn't 
> seem to have a script file editor. I can only use other editor software 
> (e.g., notepad) to write a ".R" file, and then "source" it in R. It's not 
> convenient to debug in this way.

You are not expected to.  I usually copy and paste from an external
editor, and rarely use source.  Both S(-PLUS) and R have long had modes
for editors allowing much more than the S-PLUS script windows: indeed they
were copied from such modes.  Take a look at

http://cran.r-project.org/other-software.html

In ESS (and I believe R-WinEdt) you can submit code by highlighting and 
using an editor command.

> Any one can help me?

You can already display a file in RGui using the File menu, and highlight
lines there and submit them.  If you want to change them, use up-arrow and 
edit them in the commands buffer.

You could also try the R-devel prerelease (on CRAN), as it can edit such a
displayed file.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wuertz at itp.phys.ethz.ch  Sun Jul  4 16:54:52 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Sun, 04 Jul 2004 14:54:52 +0000
Subject: [R] Rmetrics 191.10057
Message-ID: <40E81A3C.3070705@itp.phys.ethz.ch>



It is a pleasure for me to announce the new built for Rmetrics Version
191.0057. The source files and Windows binary packages can be downloaded
from www.rmetrics.org .

The new built has also been submitted to the CRAN server. Some new 
functions
and example files have been added. Unfortunately the user guides and 
reference
guides are not yet updated, they have still the status of Version 181.000xx.

Diethelm Wuertz
info at rmetrics.org


________________________________________________________________________________
2004-07-04
    NEW BUILT RMETRICS VERSION 1091.10057

2004-07-04 Rmetrics
    The new version is now proofed to be Debian license conform for all
    its functions.
    
2004-07-04 FAQ
    The FAQ file has been updated, now the FAQ's are providing more
    information about Rmetrics.     
    
2004-07-04 fbasics/R
    In function .FirstLib we set a timezone if none found in
    environment variables or options, as suggested by Dirk Eddelbuettel,
    thanks Dirk.
    
2004-06-30 fExtremes/R
    A new utility function named "gridVector" has been added which
    creates all grid points from two vectors which span a rectangular
    grid.
    
2004-06-29 fOptions/demo
    A new example file named "funDensitiesEBM.R" has been added
    which adds some distributions and related functions which are
    useful in the theory of exponential Brownian Motion.
    The functions compute densities and probabilities for the
    log-Normal distribution, the Gamma distribution, the
    Reciprocal-Gamma distribution, and the Johnson Type-I
    distribution. Functions are made available for the compution
    of moments including the Normal, the log-Normal, the
    Reciprocal-Gamma, and the Asian-Option Density. In addition
    a function is given to compute numerically first and second
    derivatives of a given function.
        
2004-06-29 fOptions/demo
    A new example file named "funSpecFunsEBM.R" has been added
    with special mathematical functions which are used in the
    theory of exponential Brownian Motion. The functions included
    are: In Part I, the Error Function "erf", the Psi or Digamma
    Function "Psi", the Incomplete Gamma Function "igamma", the
    Gamma Function fpr complex arguments, and the Pochhammer Symbol
    "Pochhammer". In Part II, the Confluent Hypergeometric Functions
    of the 1st Kind and 2nd Kind "kummerM" and "kummerU", the
    Whittaker Functions "whittakerM" and "whittakerW" and the
    Hermite Polynomials "hermiteH"

2004-06-29 fOptions/demo
    A new example file named "xmpSpecFunsEBM.R" has been added
    which shows how to use Gamma Functions, Confluent Hypergeometric
    and related functions under R.  
        
2004-06-29 fSeries/R
    New functions to fit the parameters by the maximum log-likelihood
    method for the symmetric and skew Normal, Student-t with unit
    variance, and generalized error distribution have been added.
                
2004-06-28 fBasics/demo
    A new example file "xmpImportForecasts.R" has been added including
    a function named "forecastsImport" to download monthly financial
    market data from the "www.forecasts.org" web site.

2004-06-28 fBasics/R
    A new function named "keystatsImport" has been added which
    downloads key statistic and fundamental data for equities from
    Yahoo's web site.
       
2004-06-25 fBasics/R
    The function "as.timeSeries" got two additional arguments which
    allow to pass dimension names and the timeDate format in POSIX
    notation to the returned "timeSeries" object.

2004-06-25 fSeries/R
    New functions "[dpqr]ged" and "[dpqr]sged" have been added which
    compute density, distribution function, quantile function and
    generate random variates for the symmetric and skew generalized
    error distribution.

2004-06-25 fSeries/R
    New functions "[dpqr]std" and "[dpqr]sstd" have been added which
    compute density, distribution function, quantile function and  
    generate random variates for the symmetric and skew Student-t
    distribution with unit variance.

2004-06-25 fSeries/R
    New functions "[dpqr]snorm" have been added which compute density,
    distribution function, quantile function and generate random
    variates for the skew normal distribution.
        
2004-06-25 fSeries/demo
    A new example file "xmpDistTESTskew.R" has been added with
    integration tests for the skew normal, for the skew Student-t
    with unit variance, and for the skew GED distribution.      
                
2004-06-25 fSeries/R
    New functions have been added which compute the Haeviside "H" and
    related functions; just another sign function "Sign", the delta
    function "delta", the boxcar function "boxcar" and the ramp
    function "ramp".
        
2004-06-24 fOptions/demo
    The 3D Plot functions for the generalized Black-Scholes option
    prices and the sensitivities have been moved to the examples
    located in the demo directory.

2004-06-14 fSeries/data
    The data sets from the book "The Econometric Modelling of
    Financial Time Series" (2nd Edition) written by Terence C.
    Mills have been added to the data directory.
    
    + many other smaller improvements and fixings ...



From ggrothendieck at myway.com  Sun Jul  4 17:01:17 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 4 Jul 2004 15:01:17 +0000 (UTC)
Subject: [R] how to use a script file for all the codes?
References: <BAY16-F36Cd5dqy4PqZ0000cac7@hotmail.com>
Message-ID: <loom.20040704T165258-305@post.gmane.org>


You can do this:

f <- function(x)x
fix(f)
# you are now put into an editor and can change the function
# when you save the file you will be taken back to R with the new version of f

Alternately, you can ease the use of the source style of operating
by hitting up-arrow a few times in the R console to get your last 
source command so its just a matter of upwarrowing and pressing Enter.

One other thing to note is that there are a number of editors that support
R syntax highlighting including ESS and gvim and that can ease development
too.

Jiacheng Yuan <jiachengyuan <at> hotmail.com> writes:

: 
: Hi there,
: 
: I am using the windows version R1.9.0.
: I used to be a Splus user. When I used Splus to try some computation, I like 
: to put all my codes in a script file and check them line by line. This way I 
: can keep track of all my thinking and it's very easy to make correction at 
: some earlier steps.
: 
: Now I can not find this script-file style in R. The software itself doesn't 
: seem to have a script file editor. I can only use other editor software 
: (e.g., notepad) to write a ".R" file, and then "source" it in R. It's not 
: convenient to debug in this way.
: 
: Any one can help me?
: Thank you very much!
: 
: Jia
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From edd at debian.org  Sun Jul  4 18:07:09 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 4 Jul 2004 11:07:09 -0500
Subject: [R] Re: Rmetrics 191.10057
In-Reply-To: <40E81A3C.3070705@itp.phys.ethz.ch>
References: <40E81A3C.3070705@itp.phys.ethz.ch>
Message-ID: <20040704160709.GA23525@sonny.eddelbuettel.com>


Many thanks to Diethelm for the new Rmetrics release 191.10057, and to the
CRAN masters for including it in the archive.

I have updated the initial packages that had been prepared for and included
in Quantian 0.5.9.2, and just completed uploading them to Debian's incoming/
directory. As brand-new packages, they will have to wait the customary ten
or more days until the ftpmasters insert them into the archive.  Once that
has happened, they will be apt-get'able from you favourite mirror.

In the meantime, you can fetch sources and i386 Debian packages manually
(sorry, no apt-get support here) from

	http://dirk.eddelbuettel.com/code/rmetrics/
	
Happy 4th of July,  Dirk	

-- 
White House officials praised the performance of the controversial 
new Diebold electronic voting machines, which successfully tabulated 
final results from Florida before a single vote was cast.
          -- Andy Borowitz, http://borowitzreport.com, 29 June 2004



From mayeul.kauffmann at tiscali.fr  Sun Jul  4 18:46:01 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Sun, 4 Jul 2004 18:46:01 +0200
Subject: [R] smooth non cumulative baseline hazard in Cox model
Message-ID: <000b01c461e6$648f1ed0$43449b53@amd>

Hi everyone.
There's been several threads on baseline hazard in Cox model but I think
they were all on cumulative baseline hazard,
for instance
http://tolstoy.newcastle.edu.au/R/help/01a/0464.html
http://tolstoy.newcastle.edu.au/R/help/01a/0436.html


"basehaz" in package survival seems to do a cumulative hazard.

extract from the basehaz function:
    sfit <- survfit(fit)
    H <- -log(sfit$surv)

Since sfit$surv is monotonic, H will be monotonic too, which makes me think
it is a cumulative function. I think H(t) it is the "sum" ("integration") of
lambda's from 0 to t (Am I right?)

What I need might be lambda(t) or lambda(t)dt  (I do not know for sure),
something involving the instantaneous baseline risk.
But, for sure,  I 've seen elsewhere what I need.
Specifically, here:
http://econ.worldbank.org/files/13214_CivilPeace.pdf
that is page 41 of HEGRE, H??vard; ELLINGSEN, Tanja; GATES, Scott; GLEDITSCH,
Nils Petter (2001). "Toward a Democratic Civil Peace? Democracy, Political
Change, and Civil War, 1816-1992". American Political Science Review, vol.
95, no 1.

I'm doing the same job as Hegre et al. (studying civil wars) but with the
counting process formulation of the Cox model. (I use intervals, my formula
looks like Surv(start,stop,status)~  etc.).
Like Hegre and alii (who use the stata software) I would like to have a
curve showing what is the (instantaneous) overall risk of civil war at a
given time, taking away the effect of the covariates.

For those who also use the SAS software (which I'm not, unfortunately), the
job I need to be done seems to be done by the SMOOTH macro described in

"Survival Analysis Using the SAS System: A Practical Guide" by Paul D.
Allison (see below).

There is a graph (output 5.22 "smoothes hazard functions for two financial
aid groups") P. 170 of his book which shows another example (except I only
need it for 1 group, at mean values)



I hope I am clear enough. Thank you a lot for any help.
(sorry for mistakes in English as I'm on non native English speaker)

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France
------------

SMOOTH Macro  (SAS)

------------

%macro smooth (data=_last_, time=, width=, survival=survival);

/*********************************************************************

MACRO SMOOTH produces graphs of smoothed hazard functions using output

from either PROC LIFETEST or PROC PHREG. With PROC LIFETEST, it uses the

data set produced by the OUTSURV option in the PROC statement. With PROC

PHREG, it uses the data set produced by the BASELINE statement. SMOOTH

employs a kernel smoothing method described by H. Ramlau-Hansen (1983),

"Smoothing Counting Process Intensities by Means of Kernel Functions,"

The Annals of Statistics 11, 453-466. If there is more than one survival

curve in the input data set, SMOOTH will produce multiple smoothed

hazard curves on the same axes.

There are four parameters:

DATA is the name of the data set containing survivor function

estimates. The default is the most recently created data set.

TIME is name of the variable containing event times.

SURVIVAL is the name of a variable containing survivor function

estimates (the default is SURVIVAL, which is the automatic name in

PROC LIFETEST).

WIDTH is bandwidth of smoothing function. The default is 1/5 of the range

of event times.

Example of usage:

%smooth(data=my.data,time=duration,width=8,survival=s)

Author: Paul D. Allison, University of Pennsylvania

allison at ssc.upenn.edu

*************************************************************************/

data _inset_;

set &data end=final;

retain _grp_ _censor_ 0;

t=&time;

survival=&survival;

if t=0 and survival=1 then _grp_=_grp_+1;

keep _grp_ t survival;

if final and _grp_ > 1 then call symput('nset','yes');

else if final then call symput('nset','no');

if _censor_ = 1 then delete;

if survival in (0,1) then delete;

run;

proc iml;

use _inset_;

read all var {t _grp_};

%if &width ne %then %let w2=&width;

%else %let w2=(max(t)-min(t))/5;

w=&w2;

z=char(w,8,2);

call symput('width',z);

numset=max(_grp_);

create _plt_ var{ lambda s group};

setin _inset_ ;

do m=1 to numset;

read all var {t survival _grp_} where (_grp_=m);

n=nrow(survival);

lo=t[1] + w;

hi=t[n] - w;

npt=50;

inc=(hi-lo)/npt;

s=lo+(1:npt)`*inc;

group=j(npt,1,m);

slag=1//survival[1:n-1];

h=1-survival/slag;

x = (j(npt,1,1)*t` - s*j(1,n,1))/w;

k=.75*(1-x#x)#(abs(x)<=1);

lambda=k*h/w;

append;

end;

quit;

%if &nset = yes %then %let c==group;

%else %let c=;

proc gplot data=_plt_;

plot lambda*s &c / vaxis=axis1 vzero haxis=axis2;

axis1 label=(angle=90 f=titalic 'Hazard Function' ) minor=none ;

axis2 label=(f=titalic "Time (bandwidth=&width)") minor=none;

symbol1 i=join color=black line=1;

symbol2 i=join color=red line=2;

symbol3 i=join color=green line=3;

symbol4 i=join color=blue line=4;

run;

quit;

%mend smooth;



From spencer.graves at pdf.com  Sun Jul  4 18:53:01 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 04 Jul 2004 09:53:01 -0700
Subject: [R] Chambers' Programming with Data? 
Message-ID: <40E835ED.4000101@pdf.com>

      I'm trying to read John Chambers (1998) Programming with Data 
(Springer), and I'm finding many functions (e.g., deparseText on p. 102 
or levelsIndex on p. 203) that seem not to be available on R 1.9.1;  
many of these are available in S-Plus 6.2, though often with limited 
documentation.  I have two questions about this: 

      1.  Does anyone have suggestions on which parts of this book 
should receive most attention and which parts might be skipped as (a) it 
is not used by the most important material later in the book, and (b) 
much of what is different from other convenient sources has not been 
implemented in R? 

      2.  Is there a package available that provides an R implementation 
of these functions?  If yes, how can I get it? 

      Thanks,
      Spencer Graves



From ludomax at ix.netcom.com  Sun Jul  4 22:06:57 2004
From: ludomax at ix.netcom.com (Ludo Max)
Date: Sun, 04 Jul 2004 16:06:57 -0400
Subject: [R] doubly multivariate analysis in R
Message-ID: <1088971617.2109.2.camel@localhost>


20 subjects were measured in 5 conditions (thus repeated measures) and
for each subject in each condition there are 4 response measures (thus
multivariate as it is a combined score that needs to be compared across
the conditions).
 
So, using a multivariate approach to repeated measures this is a doubly
multivariate analysis.
 
I would appreciate any suggestions as to the best way to do such a
doubly multivariate analysis in R (I have done it in SPSS and SAS but
would like to see what it takes to do the same in R).
 
Thank you in advance for any help.
 
Ludo



From ripley at stats.ox.ac.uk  Sun Jul  4 22:23:10 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 4 Jul 2004 21:23:10 +0100 (BST)
Subject: [R] smooth non cumulative baseline hazard in Cox model
In-Reply-To: <000b01c461e6$648f1ed0$43449b53@amd>
Message-ID: <Pine.LNX.4.44.0407042105110.15369-100000@gannet.stats>

If you have a smooth cumulative hazard you can differentiate it to get a 
differentiable hazard (using smooth in its technical sense).

Try 

http://www.stats.ox.ac.uk/pub/MASS4/VR4stat.pdf

for possible approaches in S/R.  There are several, e.g. in packages 
muhaz, polspline, sm, locfit, ....  What you cannot have is

- The Cox proportional hazards approach
- A smooth baseline hazard

since the derivation of the partial likelihood assumes a non-smooth 
baseline hazard.  You can have proportional hazards and e.g. penalized 
log-likelihood, though.  As an approximation you can smooth the fitted 
baseline cumulative hazard (e.g. by package pspline) and ask for its 
derivative.


On Sun, 4 Jul 2004, Mayeul KAUFFMANN wrote:

> Hi everyone.
> There's been several threads on baseline hazard in Cox model but I think
> they were all on cumulative baseline hazard,
> for instance
> http://tolstoy.newcastle.edu.au/R/help/01a/0464.html
> http://tolstoy.newcastle.edu.au/R/help/01a/0436.html
> 
> 
> "basehaz" in package survival seems to do a cumulative hazard.
> 
> extract from the basehaz function:
>     sfit <- survfit(fit)
>     H <- -log(sfit$surv)
> 
> Since sfit$surv is monotonic, H will be monotonic too, which makes me think
> it is a cumulative function. I think H(t) it is the "sum" ("integration") of
> lambda's from 0 to t (Am I right?)
> 
> What I need might be lambda(t) or lambda(t)dt  (I do not know for sure),
> something involving the instantaneous baseline risk.
> But, for sure,  I 've seen elsewhere what I need.
> Specifically, here:
> http://econ.worldbank.org/files/13214_CivilPeace.pdf
> that is page 41 of HEGRE, H??vard; ELLINGSEN, Tanja; GATES, Scott; GLEDITSCH,
> Nils Petter (2001). "Toward a Democratic Civil Peace? Democracy, Political
> Change, and Civil War, 1816-1992". American Political Science Review, vol.
> 95, no 1.
> 
> I'm doing the same job as Hegre et al. (studying civil wars) but with the
> counting process formulation of the Cox model. (I use intervals, my formula
> looks like Surv(start,stop,status)~  etc.).

Careful, that is left- and right- censored, not intervals.  Surv has a 
type= argument.

> Like Hegre and alii (who use the stata software) I would like to have a
> curve showing what is the (instantaneous) overall risk of civil war at a
> given time, taking away the effect of the covariates.
> 
> For those who also use the SAS software (which I'm not, unfortunately), the
> job I need to be done seems to be done by the SMOOTH macro described in
> 
> "Survival Analysis Using the SAS System: A Practical Guide" by Paul D.
> Allison (see below).
> 
> There is a graph (output 5.22 "smoothes hazard functions for two financial
> aid groups") P. 170 of his book which shows another example (except I only
> need it for 1 group, at mean values)
> 
> 
> 
> I hope I am clear enough. Thank you a lot for any help.
> (sorry for mistakes in English as I'm on non native English speaker)
> 
> Mayeul KAUFFMANN
> Univ. Pierre Mendes France
> Grenoble - France
> ------------

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sun Jul  4 23:31:49 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Jul 2004 23:31:49 +0200
Subject: [R] smooth non cumulative baseline hazard in Cox model
In-Reply-To: <Pine.LNX.4.44.0407042105110.15369-100000@gannet.stats>
References: <Pine.LNX.4.44.0407042105110.15369-100000@gannet.stats>
Message-ID: <x2vfh3h322.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> > I'm doing the same job as Hegre et al. (studying civil wars) but with the
> > counting process formulation of the Cox model. (I use intervals, my formula
> > looks like Surv(start,stop,status)~  etc.).
> 
> Careful, that is left- and right- censored, not intervals.  Surv has a 
> type= argument.

Nitpick: That's left-*truncated* and right-censored (the status refers
to the condition at the right end, people who die before the start are
not registered at all).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jasont at indigoindustrial.co.nz  Sun Jul  4 23:34:09 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 5 Jul 2004 09:34:09 +1200 (NZST)
Subject: [R] recommended citation
In-Reply-To: <40E720FE.8090605@brno.cas.cz>
References: <40E720FE.8090605@brno.cas.cz>
Message-ID: <54937.203.9.176.60.1088976849.squirrel@webmail.maxnet.co.nz>

> Dear Sirs,
>
> I used the nlme package for the statistical analysis of my data for
> prepared MS. Please, can you write me what is your recommended form of
> citation of this program?
> Thanks in advance for your reply.
>

I "cheat" and cite the book that supports it:

@Book{Pinheiro:2000:MMS,
  author =       "Jose C. Pinheiro and Douglas M. Bates",
  title =        "Mixed-effects models in {S} and {S-PLUS}",
  publisher =    Springer Verlag,
  address =      New York,
  year =         "2000",
}



From rvaradha at jhsph.edu  Mon Jul  5 01:22:56 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Sun, 4 Jul 2004 19:22:56 -0400
Subject: [R] counting the occurrences of vectors
Message-ID: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040704/77125547/attachment.pl

From spencer.graves at pdf.com  Mon Jul  5 02:28:35 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 04 Jul 2004 17:28:35 -0700
Subject: [R] counting the occurrences of vectors
In-Reply-To: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
Message-ID: <40E8A0B3.1050404@pdf.com>

      I see a case where "f1" gives the wrong answer: 

      b <- array(c("a:b", "a", "c", "b:c"), dim=c(2,2))
      a <- b[c(1,1),]

      For these two matrices, f1(a,b) == c(2,2), while f2(a,b) == 
c(2,0).  If b does not contain ":", e.g., if it is numeric, then this 
pathology can not occur.  However, if "f1" is used with objects of class 
character or string that could contain the "collapse" character, it 
could give an incorrect answer without warning. 

      hope this helps.  spencer graves

Ravi Varadhan wrote:

>Thanks to Gabor, Marc, and Spencer for their elegant solutions.  Gabor's first solution worked the best for me.
> 
>Best,
>Ravi.
>
>________________________________
>
>From: r-help-bounces at stat.math.ethz.ch on behalf of Gabor Grothendieck
>Sent: Sat 7/3/2004 12:12 PM
>To: r-help at stat.math.ethz.ch
>Subject: Re: [R] counting the occurrences of vectors
>
>
>
>Ravi Varadhan <rvaradha <at> jhsph.edu> writes:
>
>  
>
>>Hi:
>>
>>I have two matrices, A and B, where A is n x k, and B is m x k, where n >> m
>>    
>>
>>>k.  Is there a computationally fast way to
>>>      
>>>
>>count the number of times each row (a k-vector) of B occurs in A?  Thanks
>>    
>>
>for any suggestions.
>  
>
>>Best,
>>Ravi.
>>    
>>
>
>Here are two approaches.  The first one is an order of magnitude faster
>than the second.
>
>R> # test matrices
>R> set.seed(1)
>R> a <- matrix(sample(3,1000,rep=T),nc=5)
>R> b <- matrix(sample(3,100,rep=T),nc=5)
>
>R> f1 <- function(a,b) {
>+ a2 <- apply(a, 1, paste, collapse=":")
>+ b2 <- apply(b, 1, paste, collapse=":")
>+ c(table(c(a2,unique(b2)))[b2] - 1)
>+ }
>
>R> f2 <- function(a,b) {
>+ ta <- t(a)
>+ apply(b,1,function(x)sum(apply(ta == x,2,all)))
>+ }
>
>R> gc(); system.time(ans1 <- f1(a,b))
>         used (Mb) gc trigger (Mb)
>Ncells 458311 12.3     818163 21.9
>Vcells 124264  1.0     786432  6.0
>[1] 0.03 0.00 0.03   NA   NA
>
>R> gc(); system.time(ans2 <- f2(a,b))
>         used (Mb) gc trigger (Mb)
>Ncells 458312 12.3     818163 21.9
>Vcells 124270  1.0     786432  6.0
>[1] 0.1 0.0 0.1  NA  NA
>
>R> all.equal(ans1, ans2)
>[1] TRUE
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ok at cs.otago.ac.nz  Mon Jul  5 02:41:58 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Mon, 5 Jul 2004 12:41:58 +1200 (NZST)
Subject: [R] Outliers
Message-ID: <200407050041.i650fwA7283607@atlas.otago.ac.nz>

Last week there was a thread on outlier detection.
I came across an article which has a very interesting paragraph.

The article is
    Missing Values, Outliers, Robust Statistics, & Non-parametric Methods
    by Shaun Burke, RHM Techology Ltd, High Wycombe, Buckinghamshire, UK.
It was the fourth article in a series which appeared in
    Scientific Data Management
in 1998 and 1998.

The very interesting paragraph is this:

    NB: It should be noted that following a
    judgement in a US court, the Food and
    Drug Administration 9FDA) in a guide -
    Guide to inspection of pharmaceutical
    quality control laboratories - has
    specifically prohibited the use of outlier
    tests.

Elsewhere, the article recommends the use of outlier tests as a way of
locating possible transcription errors, but NOT as a way of discarding data.



From baron at psych.upenn.edu  Mon Jul  5 02:55:57 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 4 Jul 2004 20:55:57 -0400
Subject: [R] doubly multivariate analysis in R
In-Reply-To: <1088971617.2109.2.camel@localhost>
References: <1088971617.2109.2.camel@localhost>
Message-ID: <20040705005557.GB27335@psych>

On 07/04/04 16:06, Ludo Max wrote:
>
>20 subjects were measured in 5 conditions (thus repeated measures) and
>for each subject in each condition there are 4 response measures (thus
>multivariate as it is a combined score that needs to be compared across
>the conditions).
>
>So, using a multivariate approach to repeated measures this is a doubly
>multivariate analysis.
>
>I would appreciate any suggestions as to the best way to do such a
>doubly multivariate analysis in R (I have done it in SPSS and SAS but
>would like to see what it takes to do the same in R).

This is the format of most of what I do.  You might find it
useful to look at our "Notes on R for psychology...", reachable
through the R page in my signature.

But the real answer depends heavily on what you want to find out.
I use the same basic format for most of what I do - experiments
on the Web using Javascript to generate items and questions - but
the data analysis varies greatly from study to study, so the
format does not determine the analysis.

I do put all my analysis scripts and experiments in my web page
under "Public archives...."  If you go back and forth between the
experiments and the R scripts, you can even get some idea of the
relation between the two, although probably not much.  (Also,
some of these are pretty old and I've found much better ways to
do things in both R and JavaScript.)  At least you might find
these helpful for getting started.

Now, I usually use an array with the dimensions: subjects,
conditions, and questions.  A lot of what I do involves
calculating within-subject correlations and regressions.  I used
to do that entirely with loops, but lately I've found that R's
mapply() function can do some of it, as well as apply().

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From mayeul.kauffmann at tiscali.fr  Mon Jul  5 03:22:07 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Mon, 5 Jul 2004 03:22:07 +0200
Subject: [R] smooth non cumulative baseline hazard in Cox model
References: <Pine.LNX.4.44.0407042105110.15369-100000@gannet.stats>
	<x2vfh3h322.fsf@biostat.ku.dk>
Message-ID: <000601c4622e$80b6d560$cac59853@amd>

Thank you all for your quick answers.

With respect to my question on smooth noncumulative baseline cox hazard, I
followed Prof Brian Ripley and I used the following:

library(survival)
plot(basehaz(coxfinal2)[,2]/365.25+1945,basehaz(coxfinal2)[,1],t="l")
xx <-
seq(min(basehaz(coxfinal2)[,2]/365.25+1945),max(basehaz(coxfinal2)[,2]/365.2
5+1945),length=100) #my start value was 1st january 1945
library(pspline)
lines(xx,
predict(sm.spline(x=basehaz(coxfinal2)[,2]/365.25+1945,y=basehaz(coxfinal2)[
,1],norder=2), xarg=xx,nderiv=1))

it might seem that computing the derivative when time is expressed in years
gives the annual probability of event.
The previous commands give a graphic exactly identical to:

plot(basehaz(coxfinal2)[,2],basehaz(coxfinal2)[,1],t="l")
xx <-
seq(min(basehaz(coxfinal2)[,2]),max(basehaz(coxfinal2)[,2]),length=100)
lines(xx,
365.25*predict(sm.spline(x=basehaz(coxfinal2)[,2],y=basehaz(coxfinal2)[,1],n
order=2), xarg=xx,nderiv=1))  # [second command]

However, if p is the probability of event for the 1st day of a given year,
it is not obvious to me
that the probability that there is one event for the 1st year equals 365*p.
Am I mistaken? If no, what does the second command computes?

So if someone can help me say what is the time unit for the risk shown by
lines(xx,
predict(sm.spline(x=basehaz(coxfinal2)[,2]/365.25+1945,y=basehaz(coxfinal2)[
,1],norder=2), xarg=xx,nderiv=1))
...

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

With respect to censoring, I think we all agree:

Peter Dalgaard wrote:
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>
> > > I'm doing the same job as Hegre et al. (studying civil wars) but with
the
> > > counting process formulation of the Cox model. (I use intervals, my
formula
> > > looks like Surv(start,stop,status)~  etc.).
> >
> > Careful, that is left- and right- censored, not intervals.  Surv has a
> > type= argument.
>
> Nitpick: That's left-*truncated* and right-censored (the status refers
> to the condition at the right end, people who die before the start are
> not registered at all).

I use the following dataset:
id    start    stop    status  ... covariates
1    1    365    0    ...
1    365    400    1    ... [the war starts at 400 and ens at 550]
1    550    730    0    ... [there are possibly repeated events so the
country re-enters the study]
2    1    365    0    ...
2    365    730    0    ...
etc...
where there is one id for every country, that is several lines for each
country (each line thus representing an "interval" of time).

with
coxph(Surv(start, stop, status, type = "interval") ~ x1+...+cluster(id)

I did not meant interval censoring (althought I think it is present here for
country 1 from time 400 to 550), I meant "interval" in the same meaning as
in the R help for Surv:
"time2ending
time of the interval for interval censored or counting process data only.
Intervals are assumed to be open on the left and closed on the right,
(start, end]. For counting process data, event indicates whether an event
occurred at the end of the interval."
"Surv has a  type= argument." Yes, and the help says "The default is "right"
or "counting" depending on whether the time2 argument is absent or present,
respectively." Here, I omited the type, which means I used a counting
process.

Thus, the union of all intervals for country 2 (here, lines 4 and 5) lead to
one big interval which is left truncated and right censored.

Anyway, I think there is no ambiguity, since if one tries     type =
"interval"   it says:
Error in coxph(Surv(start, stop, status, type = "interval") ~ ....
 Cox model doesn't support "interval" survival data

But thanks to Prof. Ripley for the comment, as I am not fully aware of the
exact terminology in English.

Regards,

Mayeul KAUFFMANN



From Toby.Patterson at csiro.au  Mon Jul  5 04:02:43 2004
From: Toby.Patterson at csiro.au (Toby.Patterson@csiro.au)
Date: Mon, 5 Jul 2004 12:02:43 +1000
Subject: [R] date Axes and formats  in lattice plots
Message-ID: <C4178DC99E08604EA5E2BDB989F09380025D0C2A@extas2-hba.tas.csiro.au>


All,

I have some data of animal movements that I'm plotting using xyplot() from lattice. I want to have the date (class POSIXct object) on the Y-axis and the animals longitude on X-axis.
Eg. 

xyplot(date ~ longitude, groups = animal, data = my.data) 

with data like:

     animal   ptt year month day    lon                date
125 03P0014 13273 2003     7  10 150.38 2003-07-10 14:03:48
126 03P0192 20890 2003     7  10 151.13 2003-07-10 14:00:47
127 03P0197 30466 2003     7  10 150.74 2003-07-10 14:02:21
...etc

It all works fine except for the format of the dates that gets displayed. 

I am not sure what I need to change within the lattice frame work to get a specific date format (eg. "%Y-%-m-%d"). Does anyone have any tips or, even better, some example code that they could pass on?

Many thanks. 
Toby



From MSchwartz at MedAnalytics.com  Mon Jul  5 04:05:07 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sun, 04 Jul 2004 21:05:07 -0500
Subject: [R] Outliers
In-Reply-To: <200407050041.i650fwA7283607@atlas.otago.ac.nz>
References: <200407050041.i650fwA7283607@atlas.otago.ac.nz>
Message-ID: <1088993107.10847.240.camel@localhost.localdomain>

On Sun, 2004-07-04 at 19:41, Richard A. O'Keefe wrote:
> Last week there was a thread on outlier detection.
> I came across an article which has a very interesting paragraph.
> 
> The article is
>     Missing Values, Outliers, Robust Statistics, & Non-parametric Methods
>     by Shaun Burke, RHM Techology Ltd, High Wycombe, Buckinghamshire, UK.
> It was the fourth article in a series which appeared in
>     Scientific Data Management
> in 1998 and 1998.
> 
> The very interesting paragraph is this:
> 
>     NB: It should be noted that following a
>     judgement in a US court, the Food and
>     Drug Administration 9FDA) in a guide -
>     Guide to inspection of pharmaceutical
>     quality control laboratories - has
>     specifically prohibited the use of outlier
>     tests.
> 
> Elsewhere, the article recommends the use of outlier tests as a way of
> locating possible transcription errors, but NOT as a way of discarding data.


The FDA Guide referred to in that article is here:

http://www.fda.gov/ora/inspect_ref/igs/pharm.html

If you search that page using the keyword 'outlier' you will note
several references.

The part of the document relevant to the above citation is:

In a recent court decision the judge used the term
"out-of-specification" (OOS) laboratory result rather than the term
"product failure" which is more common to FDA investigators and
analysts. He ruled that an OOS result identified as a laboratory error
by a failure investigation or an outlier test. The court provided
explicit limitations on the use of outlier tests and these are discussed
in a later segment of this document., or overcome by retesting. The
court ruled on the use of retesting which is covered in a later segment
of this document. is not a product failure.



Some of the above and elsewhere in the document, relative to grammar and
punctuation, suggests that the HTML page was converted from another
format, perhaps Word or PDF. Some things do not quite make sense, but
you can get the basic idea.

Note also the use of the word 'limitation' above rather than
'prohibited'.

HTH,

Marc Schwartz



From deepayan at stat.wisc.edu  Mon Jul  5 04:16:15 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 4 Jul 2004 21:16:15 -0500
Subject: [R] date Axes and formats  in lattice plots
In-Reply-To: <C4178DC99E08604EA5E2BDB989F09380025D0C2A@extas2-hba.tas.csiro.au>
References: <C4178DC99E08604EA5E2BDB989F09380025D0C2A@extas2-hba.tas.csiro.au>
Message-ID: <200407042116.15191.deepayan@stat.wisc.edu>

On Sunday 04 July 2004 21:02, Toby.Patterson at csiro.au wrote:
> All,
>
> I have some data of animal movements that I'm plotting using xyplot()
> from lattice. I want to have the date (class POSIXct object) on the
> Y-axis and the animals longitude on X-axis. Eg.
>
> xyplot(date ~ longitude, groups = animal, data = my.data)
>
> with data like:
>
>      animal   ptt year month day    lon                date
> 125 03P0014 13273 2003     7  10 150.38 2003-07-10 14:03:48
> 126 03P0192 20890 2003     7  10 151.13 2003-07-10 14:00:47
> 127 03P0197 30466 2003     7  10 150.74 2003-07-10 14:02:21
> ...etc
>
> It all works fine except for the format of the dates that gets
> displayed.
>
> I am not sure what I need to change within the lattice frame work to
> get a specific date format (eg. "%Y-%-m-%d"). Does anyone have any
> tips or, even better, some example code that they could pass on?

For R 1.9.0 and above, you should be able to do this with 

xyplot(date ~ longitude, groups = animal, data = my.data,
       scales = list(y = list(format = "%Y-%-m-%d")))

Deepayan



From tlumley at u.washington.edu  Mon Jul  5 05:28:33 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 4 Jul 2004 20:28:33 -0700 (PDT)
Subject: [R] What happened to the excellent R-Newsletter ?
In-Reply-To: <cbgpm2$b50$1@sea.gmane.org>
References: <cbgpm2$b50$1@sea.gmane.org>
Message-ID: <Pine.A41.4.58.0407042027330.176302@homer06.u.washington.edu>

On Fri, 25 Jun 2004, Henrik Andersson wrote:

> The last newsletter found on www.r-project.org is from December 2003.
>
> I was looking forward to the next issue, will there be one soon, or what
> happened ?
>

Yes, there will be one very soon.

	-thomas

BTW: the last issue, while titled December 2003 actually appeared at the
end of January



From jozef.deherdt at pandora.be  Mon Jul  5 09:47:29 2004
From: jozef.deherdt at pandora.be (Jozef De Herdt)
Date: Mon, 5 Jul 2004 09:47:29 +0200
Subject: [R] Why does summary does not produce output?
Message-ID: <CIEIJIPIJFGBCBBNMJFJKEAHCAAA.jozef.deherdt@pandora.be>

Hello,

I'm a starting user of R. I have installed R 1.9.1 and winedt 5.4

If I run the example from written with winedt. The summary command does not
produce any output. It does when I repeat the command manualy in R. Can
someone explain me what can be the problem?

     library(MASS)
     data(anorexia)
     anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
                 family = gaussian, data = anorexia)
     summary(anorex.1)

Regards
De Herdt J



From Tom.Joy at rmbinternational.com  Mon Jul  5 10:26:46 2004
From: Tom.Joy at rmbinternational.com (Joy, Tom)
Date: Mon, 5 Jul 2004 09:26:46 +0100
Subject: [R] help changing the size of labels in a dendrogram plot
Message-ID: <576A4B4724813147AF478CAC91B8CF71A982DE@bank.rmbi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040705/ede9c46a/attachment.pl

From p.dalgaard at biostat.ku.dk  Mon Jul  5 10:32:36 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Jul 2004 10:32:36 +0200
Subject: [R] Why does summary does not produce output?
In-Reply-To: <CIEIJIPIJFGBCBBNMJFJKEAHCAAA.jozef.deherdt@pandora.be>
References: <CIEIJIPIJFGBCBBNMJFJKEAHCAAA.jozef.deherdt@pandora.be>
Message-ID: <x2eknqua57.fsf@biostat.ku.dk>

"Jozef De Herdt" <jozef.deherdt at pandora.be> writes:

> If I run the example from written with winedt. The summary command does not
> produce any output. It does when I repeat the command manualy in R. Can
> someone explain me what can be the problem?
> 
>      library(MASS)
>      data(anorexia)
>      anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
>                  family = gaussian, data = anorexia)
>      summary(anorex.1)

Is the winedt interface like source() or like source(...,echo=TRUE)? 

If the former, you need to print() objects explicitly, including
summaries.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tpapp at axelero.hu  Mon Jul  5 09:39:30 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Mon, 5 Jul 2004 09:39:30 +0200
Subject: [R] general questions about R on debian/powerpc
Message-ID: <20040705073930.GB1363@axelero.hu>

Hi,

I am about to but a laptop, and have narrowed the choices down to a
Dell Latitude 600 and an Apple Powerbook G4 Aluminium (Princeton
provides these models at a discount for grad students).

I am biased towards the Powerbook, and would like to run Debian on it.
I have only used debian on i386 platforms so far.  I use R quite
frequently, so I would be interested in your experience of running R
in debian/ppc --- are there any quirks with libraries, any packages
that don't compile, anything that should discourage me from buying a
powerbook or running debian on it, etc.

I would also be interested in your experience with the speed of the
platform.  I have never used a RISC processor before, so I don't know
whether the claims that it delivers much more power per MHz are valid.

Please share anything that you consider relevant.  If you think that
it's not R-related, please send an e-mail to the either address below
instead of the list.

Thanks,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
        tpapp at princeton.edu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From maechler at stat.math.ethz.ch  Mon Jul  5 10:55:47 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 5 Jul 2004 10:55:47 +0200
Subject: [R] hclust plotting
In-Reply-To: <Pine.GSO.4.10.10407021538070.1414-100000@athena.biostat.jhsph.edu>
References: <Pine.GSO.4.10.10407021538070.1414-100000@athena.biostat.jhsph.edu>
Message-ID: <16617.6035.875983.965628@gargle.gargle.HOWL>

>>>>> "Rafael" == Rafael A Irizarry <ririzarr at jhsph.edu>
>>>>>     on Fri, 2 Jul 2004 15:50:46 -0400 (EDT) writes:

    Rafael> im using plclust and want the labels to be different
    Rafael> colors.  i took a look at
    Rafael> getS3method("plot","hclust") and saw a call to
    Rafael> .Internal. i looked at the help on .Internal and
    Rafael> dont know where to go next. any help appreciated!

{Brian already helped about finding where the C code for those
 .Internals is}.

Just a few days ago, there was a question with almost identical
content (though different wording).
Please see in the archives for my answer with
Subject 'Re: [R] Customizing Cluster Analysis plots created with hclust'

Short answer: It will be possible in "R-devel" via as.dendrogram(..)

Martin Maechler



From assuncao.senra at portugalmail.com  Mon Jul  5 11:32:46 2004
From: assuncao.senra at portugalmail.com (assuncao.senra@portugalmail.com)
Date: Mon,  5 Jul 2004 10:32:46 +0100
Subject: [R] replacing values in a matrix or data.frame
Message-ID: <1089019966.40e9203ec4c98@webmail1.portugalmail.pt>



Hi,

I have a matrix where I want to replace the entries of each column by the 
proportion value of the times each entrie appears in that column, that is, In 
each column there 4 to 10 repeated values, for wich i can compute frequencies 
in the respective column, and then i want to replace each value for its 
respective frequencie in another matrix. Can someone help me?

Thanks for all the help.
__________________________________________________________
Quanto gasta de Acesso ?? Internet? Fa??a as contas!
http://acesso.portugalmail.pt/contas



From rossini at blindglobe.net  Mon Jul  5 11:35:59 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 05 Jul 2004 02:35:59 -0700
Subject: [R] general questions about R on debian/powerpc
In-Reply-To: <20040705073930.GB1363@axelero.hu> (Tamas Papp's message of
	"Mon, 5 Jul 2004 09:39:30 +0200")
References: <20040705073930.GB1363@axelero.hu>
Message-ID: <85k6xin6dc.fsf@servant.blindglobe.net>


I ran Debian/PPC for about a year, 1-2 years ago -- it worked fine at
that point, on a G3 iBook.

Of course, you get  weird looks with MacOS / Linux dual boots, but
that's different than whether it functions.

I switched back to intel-based hardware because it was cheaper and
faster, not necessarily better.

best,
-tony


Tamas Papp <tpapp at axelero.hu> writes:

> Hi,
>
> I am about to but a laptop, and have narrowed the choices down to a
> Dell Latitude 600 and an Apple Powerbook G4 Aluminium (Princeton
> provides these models at a discount for grad students).
>
> I am biased towards the Powerbook, and would like to run Debian on it.
> I have only used debian on i386 platforms so far.  I use R quite
> frequently, so I would be interested in your experience of running R
> in debian/ppc --- are there any quirks with libraries, any packages
> that don't compile, anything that should discourage me from buying a
> powerbook or running debian on it, etc.
>
> I would also be interested in your experience with the speed of the
> platform.  I have never used a RISC processor before, so I don't know
> whether the claims that it delivers much more power per MHz are valid.
>
> Please share anything that you consider relevant.  If you think that
> it's not R-related, please send an e-mail to the either address below
> instead of the list.
>
> Thanks,
>
> Tamas
>
> -- 
> Tam??s K. Papp
> E-mail: tpapp at axelero.hu
>         tpapp at princeton.edu
> Please try to send only (latin-2) plain text, not HTML or other garbage.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From a.prioglio at city.ac.uk  Mon Jul  5 11:44:09 2004
From: a.prioglio at city.ac.uk (a.prioglio@city.ac.uk)
Date: Mon, 5 Jul 2004 10:44:09 +0100
Subject: [R] What is a sane way to deal with changes in library loadings
	after 1.9.0?
In-Reply-To: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
Message-ID: <20040705094409.GA5708@anaconda.dogbert.ntt.it>

Hi,
perhaps this is again a silly question ...

As I am using R on different machines, some are version 1.8.1 and some
1.9.1.

One of the changes between these versions is the change in default
libraries loaded when reading scripts.

So I started my scripts with:

if (R.version$minor>="9.0") {
	library(utils)
	library(graphics)
	library(stats)
}

It appeard to work but now I get "could'n find function factanal" in
version 1.8.1.

What would be a safe and sane way to ensure all relevant libraries are
loaded irrespective of version?

-- 
Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Jul  5 11:53:23 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 5 Jul 2004 11:53:23 +0200
Subject: [R] replacing values in a matrix or data.frame
References: <1089019966.40e9203ec4c98@webmail1.portugalmail.pt>
Message-ID: <001f01c46275$ea12c1d0$ad133a86@www.domain>

Hi,

you could try something like this,

x <- matrix(sample(1:10,25, rep=TRUE), 5 ,5)
x

apply(x, 2, function(y){
  a <- table(y)
  rep(a/sum(a), a)
})


I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <assuncao.senra at portugalmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, July 05, 2004 11:32 AM
Subject: [R] replacing values in a matrix or data.frame


>
>
> Hi,
>
> I have a matrix where I want to replace the entries of each column
by the
> proportion value of the times each entrie appears in that column,
that is, In
> each column there 4 to 10 repeated values, for wich i can compute
frequencies
> in the respective column, and then i want to replace each value for
its
> respective frequencie in another matrix. Can someone help me?
>
> Thanks for all the help.
> __________________________________________________________
> Quanto gasta de Acesso ?? Internet? Fa??a as contas!
> http://acesso.portugalmail.pt/contas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Mon Jul  5 11:59:59 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Jul 2004 11:59:59 +0200
Subject: [R] What is a sane way to deal with changes in library loadings
	after 1.9.0?
In-Reply-To: <20040705094409.GA5708@anaconda.dogbert.ntt.it>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
	<20040705094409.GA5708@anaconda.dogbert.ntt.it>
Message-ID: <x23c46u63k.fsf@biostat.ku.dk>

a.prioglio at city.ac.uk writes:

> Hi,
> perhaps this is again a silly question ...
> 
> As I am using R on different machines, some are version 1.8.1 and some
> 1.9.1.
> 
> One of the changes between these versions is the change in default
> libraries loaded when reading scripts.
> 
> So I started my scripts with:
> 
> if (R.version$minor>="9.0") {
> 	library(utils)
> 	library(graphics)
> 	library(stats)
> }
> 
> It appeard to work but now I get "could'n find function factanal" in
> version 1.8.1.

 help.search("factanal") should get you there in a jiffy...


> What would be a safe and sane way to ensure all relevant libraries are
> loaded irrespective of version?

They're back-compatible (for a while yet) -- library(mva) will get you
the stats package, so just including the packages that were relevant
for 1.8.x should do. There are a few cases where you'll include too
much, e.g. som things were moved from MASS into stats, so these days
you might not require MASS where you did before, but that is a
relatively rare situation.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ajayshah at mayin.org  Mon Jul  5 12:14:42 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Mon, 5 Jul 2004 15:44:42 +0530
Subject: [R] Failing on reading a "slightly big" dataset
Message-ID: <20040705101442.GQ897@igidr.ac.in>

I have a file with 4 columns per line, all pipe delimited.

$ wc -l cmie_firm_data.text 
89325 cmie_firm_data.text
$ ls -al cmie_firm_data.text 
-rw-r--r--    1 ajayshah ajayshah  4415637 Jul  5 15:25 cmie_firm_data.text
$ awk -F\| '(NF != 4)' cmie_firm_data.text 
$ head cmie_firm_data.text 
All figures are for the year 20030331|||
Company|GVA Less Interest (Rs. thousand)|Interest (Rs. thousand)|GVA (Rs. thousand)
'R' INVEST PVT. LTD.|-510.45|0.18|-510.27
20 MICRONS LTD.|60700|41200|101900
20TH CENTURY FOX CORPN. (INDIA) PVT. LTD.|50|0.33|50.33
21ST CENTURY AUTOMOTIVE INDIA LTD.|201.14|0.19|201.33
21ST CENTURY ENTERTAINMENT PVT. LTD.|-6.10|0|-6.10
21ST CENTURY EQUIPMENTS PVT. LTD.|-1599.53|1262.76|-336.77
21ST CENTURY INFRASTRUCTURE (INDIA) PVT. LTD.|140.48|1.74|142.22
21ST CENTURY PEST CONTROL SERVICES LTD.|50.21|7.13|57.34

When I try to read this into R, I get a mysterious error, and then it
reads only 38,244 observations. Any idea what might be going wrong?
In case it matters, I'm confident this is a Unix text file; no DOSisms
of CR-LF here.

$ R --vanilla < picture.R 

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3

> firms <- read.table("cmie_firm_data.text", sep="|", skip=2,
+                     col.names=c("name", "gva.less.interest",
+                       "interest", "gva"))
Warning message: 
number of items read is not a multiple of the number of columns 

> summary(firms)
                                            name       gva.less.interest   
 20 MICRONS LTD.                              :    1   Min.   :-1.049e+07  
 20TH CENTURY FOX CORPN. (INDIA) PVT. LTD.    :    1   1st Qu.: 1.720e+01  
 21ST CENTURY AUTOMOTIVE INDIA LTD.           :    1   Median : 5.664e+02  
 21ST CENTURY ENTERTAINMENT PVT. LTD.         :    1   Mean   : 4.858e+04  
 21ST CENTURY EQUIPMENTS PVT. LTD.            :    1   3rd Qu.: 2.587e+03  
 21ST CENTURY INFRASTRUCTURE (INDIA) PVT. LTD.:    1   Max.   : 1.968e+08  
 (Other)                                      :38244   NA's   : 1.000e+00  
    interest              gva            
 Min.   :0.000e+00   Min.   :-2.349e+06  
 1st Qu.:5.500e-01   1st Qu.: 4.909e+01  
 Median :4.462e+01   Median : 7.711e+02  
 Mean   :6.301e+03   Mean   : 4.565e+04  
 3rd Qu.:5.788e+02   3rd Qu.: 3.436e+03  
 Max.   :9.558e+06   Max.   : 2.004e+08  
 NA's   :2.530e+02   NA's   : 2.530e+02  

Sniffing, I find that the last observation in the data frame `firms'
is wonky:

> print(firms[38249,])
                          name gva.less.interest interest     gva
38249 YOUNG POLYMERS PVT. LTD.           2542.08   652.71 3194.79
> system("grep -n '^YOUNG POLY' cmie*")
88904:YOUNG POLYMERS PVT. LTD.|2542.08|652.71|3194.79

where we see that YOUNG POLYMERS was observation 88,904 in the
file. How did it become #38249 to R?

And,

> print(firms[38250,])

makes him go nuts --

38250 YOUNG WOMENS CHRISTIAN ASSN. OF INDIA|9477.71|24.82|9502.53\nYOUNGMAN WOOL
LEN MILLS LTD.|5395.08|6316.75|11711.83\nYOUNGSTAR CONSTRUCTION PVT. LTD.|850.71
|128.07|978.78\nYOUR INVESTMENT (INDIA) LTD.|90.85|0|90.85\nYOURCHOICE CHIT FUND
 PVT. LTD.|0|0|0\nYOUTH FORUM TOWERS & CONSTRUCTION PVT. LTD.|289.79|1.75|291.54
\nYOUTH PROMOTERS PVT. LTD.|104.87|30.23|135.10\nYU BO INVST. CO. PVT. LTD.|708.
08|5209.60|5917.68\nYU TECHNOLOGIES PVT. LTD.|923.79|46.69|970.48\nYU-MEN TRADEL
INK PVT. LTD.|-321.47|14.35|-307.12\nYUCCA AGENCIES PVT. LTD.|1243.49|464.33|170
7.82\nYUCON EXPORTS PVT. LTD.|503.30|326.49|829.79\nYUCON MARKETING & INVSTS. PV
T. LTD.|-4.73|0.20|-4.53\nYUG MARKETING PVT. LTD.|2696.58|304.42|3001\nYUG TRADE
RS PVT. LTD.|-12.25|0.15|-12.10\nYUGAL CHIT FUND & TRADING CO. PVT. LTD.|-7.52|0
.20|-7.32\nYUGAL KISHORE FABRICS & GARMENTS PVT. LTD.|914.82|1298.56|2213.38\nYU
GANTAR ENGINEERS PVT. LTD.|193.56|0.69|194.25\nYUGANTAR INVESTMENTS LTD.|44.38|0
.06|44.44\nYUGANTAR TRADING PVT. LTD.|-4.81|0|-4.81\nYUGO INTRACO PVT. LTD.|1588
.49|29.16|1617.65\nYUGSUDO (INDIA) ENGG. SERVICE

(deleted).

The file is fine:

$ grep -n 'YOUNG WOM' cmie_firm_data.text 
88905:YOUNG WOMEN'S CHRISTIAN ASSN. OF INDIA|9477.71|24.82|9502.53

Any idea what might be going on?

My machine is linux 2.4.17 #2 (got new Debian packages for 1.9.1 today).

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From ripley at stats.ox.ac.uk  Mon Jul  5 12:25:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 11:25:00 +0100 (BST)
Subject: [R] Failing on reading a "slightly big" dataset
In-Reply-To: <20040705101442.GQ897@igidr.ac.in>
Message-ID: <Pine.LNX.4.44.0407051121140.19814-100000@gannet.stats>

You are asking read.table to interpret both quote and comment characters
in your file.  You do seem to have quotes -- are they always matched?

Please read through the Data Import/Export manual and check out all the 
options.

On Mon, 5 Jul 2004, Ajay Shah wrote:

> I have a file with 4 columns per line, all pipe delimited.
> 
> $ wc -l cmie_firm_data.text 
> 89325 cmie_firm_data.text
> $ ls -al cmie_firm_data.text 
> -rw-r--r--    1 ajayshah ajayshah  4415637 Jul  5 15:25 cmie_firm_data.text
> $ awk -F\| '(NF != 4)' cmie_firm_data.text 
> $ head cmie_firm_data.text 
> All figures are for the year 20030331|||
> Company|GVA Less Interest (Rs. thousand)|Interest (Rs. thousand)|GVA (Rs. thousand)
> 'R' INVEST PVT. LTD.|-510.45|0.18|-510.27
> 20 MICRONS LTD.|60700|41200|101900
> 20TH CENTURY FOX CORPN. (INDIA) PVT. LTD.|50|0.33|50.33
> 21ST CENTURY AUTOMOTIVE INDIA LTD.|201.14|0.19|201.33
> 21ST CENTURY ENTERTAINMENT PVT. LTD.|-6.10|0|-6.10
> 21ST CENTURY EQUIPMENTS PVT. LTD.|-1599.53|1262.76|-336.77
> 21ST CENTURY INFRASTRUCTURE (INDIA) PVT. LTD.|140.48|1.74|142.22
> 21ST CENTURY PEST CONTROL SERVICES LTD.|50.21|7.13|57.34
> 
> When I try to read this into R, I get a mysterious error, and then it
> reads only 38,244 observations. Any idea what might be going wrong?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dave at evocapital.com  Mon Jul  5 12:26:30 2004
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Mon, 5 Jul 2004 11:26:30 +0100
Subject: [R] Failing on reading a "slightly big" dataset
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D179929@sqlsrvr.evocapital.com>

Try specifying quote=NULL as an argument to read.table. It could be that
one of your fields has a quote symbol in it.

-----Original Message-----
From: Ajay Shah [mailto:ajayshah at mayin.org] 
Sent: 05 July 2004 11:15
To: r-help
Subject: [R] Failing on reading a "slightly big" dataset


I have a file with 4 columns per line, all pipe delimited.

$ wc -l cmie_firm_data.text 
89325 cmie_firm_data.text
$ ls -al cmie_firm_data.text 
-rw-r--r--    1 ajayshah ajayshah  4415637 Jul  5 15:25
cmie_firm_data.text
$ awk -F\| '(NF != 4)' cmie_firm_data.text 
$ head cmie_firm_data.text 
All figures are for the year 20030331|||
Company|GVA Less Interest (Rs. thousand)|Interest (Rs. thousand)|GVA 
Company|(Rs. thousand)
'R' INVEST PVT. LTD.|-510.45|0.18|-510.27
20 MICRONS LTD.|60700|41200|101900
20TH CENTURY FOX CORPN. (INDIA) PVT. LTD.|50|0.33|50.33
21ST CENTURY AUTOMOTIVE INDIA LTD.|201.14|0.19|201.33
21ST CENTURY ENTERTAINMENT PVT. LTD.|-6.10|0|-6.10
21ST CENTURY EQUIPMENTS PVT. LTD.|-1599.53|1262.76|-336.77
21ST CENTURY INFRASTRUCTURE (INDIA) PVT. LTD.|140.48|1.74|142.22 21ST
CENTURY PEST CONTROL SERVICES LTD.|50.21|7.13|57.34

When I try to read this into R, I get a mysterious error, and then it
reads only 38,244 observations. Any idea what might be going wrong? In
case it matters, I'm confident this is a Unix text file; no DOSisms of
CR-LF here.

$ R --vanilla < picture.R 

R : Copyright 2004, The R Foundation for Statistical Computing Version
1.9.1  (2004-06-21), ISBN 3-900051-00-3

> firms <- read.table("cmie_firm_data.text", sep="|", skip=2,
+                     col.names=c("name", "gva.less.interest",
+                       "interest", "gva"))
Warning message: 
number of items read is not a multiple of the number of columns 

> summary(firms)
                                            name       gva.less.interest

 20 MICRONS LTD.                              :    1   Min.
:-1.049e+07  
 20TH CENTURY FOX CORPN. (INDIA) PVT. LTD.    :    1   1st Qu.:
1.720e+01  
 21ST CENTURY AUTOMOTIVE INDIA LTD.           :    1   Median :
5.664e+02  
 21ST CENTURY ENTERTAINMENT PVT. LTD.         :    1   Mean   :
4.858e+04  
 21ST CENTURY EQUIPMENTS PVT. LTD.            :    1   3rd Qu.:
2.587e+03  
 21ST CENTURY INFRASTRUCTURE (INDIA) PVT. LTD.:    1   Max.   :
1.968e+08  
 (Other)                                      :38244   NA's   :
1.000e+00  
    interest              gva            
 Min.   :0.000e+00   Min.   :-2.349e+06  
 1st Qu.:5.500e-01   1st Qu.: 4.909e+01  
 Median :4.462e+01   Median : 7.711e+02  
 Mean   :6.301e+03   Mean   : 4.565e+04  
 3rd Qu.:5.788e+02   3rd Qu.: 3.436e+03  
 Max.   :9.558e+06   Max.   : 2.004e+08  
 NA's   :2.530e+02   NA's   : 2.530e+02  

Sniffing, I find that the last observation in the data frame `firms' is
wonky:

> print(firms[38249,])
                          name gva.less.interest interest     gva
38249 YOUNG POLYMERS PVT. LTD.           2542.08   652.71 3194.79
> system("grep -n '^YOUNG POLY' cmie*")
88904:YOUNG POLYMERS PVT. LTD.|2542.08|652.71|3194.79

where we see that YOUNG POLYMERS was observation 88,904 in the file. How
did it become #38249 to R?

And,

> print(firms[38250,])

makes him go nuts --

38250 YOUNG WOMENS CHRISTIAN ASSN. OF
INDIA|9477.71|24.82|9502.53\nYOUNGMAN WOOL LEN MILLS
LTD.|5395.08|6316.75|11711.83\nYOUNGSTAR CONSTRUCTION PVT. LTD.|850.71
|128.07|978.78\nYOUR INVESTMENT (INDIA) LTD.|90.85|0|90.85\nYOURCHOICE 
|CHIT FUND
 PVT. LTD.|0|0|0\nYOUTH FORUM TOWERS & CONSTRUCTION PVT.
LTD.|289.79|1.75|291.54 \nYOUTH PROMOTERS PVT.
LTD.|104.87|30.23|135.10\nYU BO INVST. CO. PVT. LTD.|708.
08|5209.60|5917.68\nYU TECHNOLOGIES PVT. 
08|LTD.|923.79|46.69|970.48\nYU-MEN TRADEL
INK PVT. LTD.|-321.47|14.35|-307.12\nYUCCA AGENCIES PVT.
LTD.|1243.49|464.33|170 7.82\nYUCON EXPORTS PVT.
LTD.|503.30|326.49|829.79\nYUCON MARKETING & INVSTS. PV T.
LTD.|-4.73|0.20|-4.53\nYUG MARKETING PVT. LTD.|2696.58|304.42|3001\nYUG
TRADE RS PVT. LTD.|-12.25|0.15|-12.10\nYUGAL CHIT FUND & TRADING CO.
PVT. LTD.|-7.52|0 .20|-7.32\nYUGAL KISHORE FABRICS & GARMENTS PVT.
LTD.|914.82|1298.56|2213.38\nYU GANTAR ENGINEERS PVT.
LTD.|193.56|0.69|194.25\nYUGANTAR INVESTMENTS LTD.|44.38|0
.06|44.44\nYUGANTAR TRADING PVT. LTD.|-4.81|0|-4.81\nYUGO INTRACO PVT.
LTD.|1588 .49|29.16|1617.65\nYUGSUDO (INDIA) ENGG. SERVICE

(deleted).

The file is fine:

$ grep -n 'YOUNG WOM' cmie_firm_data.text 
88905:YOUNG WOMEN'S CHRISTIAN ASSN. OF INDIA|9477.71|24.82|9502.53

Any idea what might be going on?

My machine is linux 2.4.17 #2 (got new Debian packages for 1.9.1 today).

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From a.prioglio at city.ac.uk  Mon Jul  5 12:35:43 2004
From: a.prioglio at city.ac.uk (a.prioglio@city.ac.uk)
Date: Mon, 5 Jul 2004 11:35:43 +0100
Subject: [R] What is a sane way to deal with changes in library loadings
	after 1.9.0?
In-Reply-To: <x23c46u63k.fsf@biostat.ku.dk>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
	<20040705094409.GA5708@anaconda.dogbert.ntt.it>
	<x23c46u63k.fsf@biostat.ku.dk>
Message-ID: <20040705103543.GA6439@anaconda.dogbert.ntt.it>

On Mon, Jul 05, 2004 at 11:59:59AM +0200, Peter Dalgaard wrote:
> > As I am using R on different machines, some are version 1.8.1 and some
> > 1.9.1.
> > 
> > One of the changes between these versions is the change in default
> > libraries loaded when reading scripts.
> > 
> > So I started my scripts with:
> > 
> > if (R.version$minor>="9.0") {
> > 	library(utils)
> > 	library(graphics)
> > 	library(stats)
> > }
> > 
> > It appeard to work but now I get "could'n find function factanal" in
> > version 1.8.1.
> 
>  help.search("factanal") should get you there in a jiffy...

Yes! True thanks.
> 
> 
> > What would be a safe and sane way to ensure all relevant libraries are
> > loaded irrespective of version?
> 
> They're back-compatible (for a while yet) -- library(mva) will get you
> the stats package, so just including the packages that were relevant
> for 1.8.x should do. There are a few cases where you'll include too
> much, e.g. som things were moved from MASS into stats, so these days
> you might not require MASS where you did before, but that is a
> relatively rare situation.

Well, I'm certainly new to R. Still without the explicit loading of the
above libraries my scripts while loading on 1.8.1 were definetely not
loading on 1.9.1. I'm using the same account on all machines so I expect
to have the same environment. Or should I?

One thing I noticed now, a search() on a 1.8.1 machine after the loading
of the scripts now returns nothing (after encountering an error though).

How can one know what environments are loaded? Calling R --verbose did
not seem to clarify this point.

Thanks for any help.
-- 
Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From ripley at stats.ox.ac.uk  Mon Jul  5 12:51:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 11:51:25 +0100 (BST)
Subject: [R] What is a sane way to deal with changes in library loadings
	after 1.9.0?
In-Reply-To: <20040705103543.GA6439@anaconda.dogbert.ntt.it>
Message-ID: <Pine.LNX.4.44.0407051142520.20361-100000@gannet.stats>

On Mon, 5 Jul 2004 a.prioglio at city.ac.uk wrote:

> On Mon, Jul 05, 2004 at 11:59:59AM +0200, Peter Dalgaard wrote:
> > > As I am using R on different machines, some are version 1.8.1 and some
> > > 1.9.1.
> > > 
> > > One of the changes between these versions is the change in default
> > > libraries loaded when reading scripts.
> > > 
> > > So I started my scripts with:
> > > 
> > > if (R.version$minor>="9.0") {
> > > 	library(utils)
> > > 	library(graphics)
> > > 	library(stats)
> > > }
> > > 
> > > It appeard to work but now I get "could'n find function factanal" in
> > > version 1.8.1.
> > 
> >  help.search("factanal") should get you there in a jiffy...
> 
> Yes! True thanks.
> > 
> > 
> > > What would be a safe and sane way to ensure all relevant libraries are
> > > loaded irrespective of version?
> > 
> > They're back-compatible (for a while yet) -- library(mva) will get you
> > the stats package, so just including the packages that were relevant
> > for 1.8.x should do. There are a few cases where you'll include too
> > much, e.g. som things were moved from MASS into stats, so these days
> > you might not require MASS where you did before, but that is a
> > relatively rare situation.
> 
> Well, I'm certainly new to R. Still without the explicit loading of the
> above libraries my scripts while loading on 1.8.1 were definetely not
> loading on 1.9.1. I'm using the same account on all machines so I expect
> to have the same environment. Or should I?
> 
> One thing I noticed now, a search() on a 1.8.1 machine after the loading
> of the scripts now returns nothing (after encountering an error though).

And what was the error?

It seems that you have been fiddling with the default set of packages.
Have you set R_DEFAULT_PACKAGES?  Have you set option "defaultPackages"?
If so, set them to "", or try starting R with --vanilla.

Packages utils, graphics and stats are loaded by default on 1.9.1.  And
package mva is loaded by default on 1.8.1.  People who answer here tend to
assume that people who know enough to change the default packages loaded
know enough to revert the changes ....

> How can one know what environments are loaded? Calling R --verbose did
> not seem to clarify this point.

search()  (attached, not loaded, BTW, as there are loaded namespace 
environments which are not attached).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ajayshah at mayin.org  Mon Jul  5 12:58:39 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Mon, 5 Jul 2004 16:28:39 +0530
Subject: [R] More difficulties in getting data into R
Message-ID: <20040705105839.GS897@igidr.ac.in>

In order to get around the problems of my posting a few minutes ago, I
thought:

$ awk -F\| '(NR > 2) {print $2}' cmie_firm_data.text > col2
$ awk -F\| '(NR > 2) {print $4}' cmie_firm_data.text > col4
$ paste col2 col4 | head -2
-510.45 -510.27
60700   101900
$ paste col2 col4 | tail -2
28648.12        31617.02
491014.77       494308.52
$ wc -l col2 col4
  89323 col2
  89323 col4
 178646 total

So all is well.

But R doesn't like it:

$ R --vanilla < picture.R 

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3

> col2 <- read.table(file="col2")
> col4 <- read.table(file="col4")
> print(nrow(col2))
[1] 89323
> print(nrow(col4))
[1] 88746

Why might I be getting 89,323 and 88,746 obs for two files which `wc'
believes are each 89,323 lines long?

I checked, and there is no single quote or C-m in either file.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From rksh at soc.soton.ac.uk  Mon Jul  5 13:02:54 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Mon, 5 Jul 2004 12:02:54 +0100
Subject: [R] "make" error for R-1.9.1
Message-ID: <a06002002bd0edf3504be@[139.166.242.29]>

Hello everybody.

I am trying to upgrade from R-1.9.0 to R-1.9.1 on  a RedHat linux 
2.4.18 system.  I get
the following error after "tar -xvzf R-1.9.1.tgz ; cd ./R-1.9.1/ ; ./configure"
  and  "make" :



[make works for 10 minutes  ... snip ...]

   varExp                            text    html    latex
   varFixed                          text    html    latex
   varFunc                           text    html    latex
   varIdent                          text    html    latex
   varPower                          text    html    latex
   varWeights                        text    html    latex
   varWeights.glsStruct              text    html    latex
   varWeights.lmeStruct              text    html    latex
Error in .installPackageIndices(".", 
"/working/jrd/sat/rksh/R-1.9.1/library/nlme 
") :
         cannot open directory'/working/jrd/sat/rksh/R-1.9.1/library/nlme/Meta'
Execution halted
ERROR: installing package indices failed
** Removing '/working/jrd/sat/rksh/R-1.9.1/library/nlme'
make[2]: *** [nlme.ts] Error 1
make[2]: Leaving directory 
`/working/jrd/sat/rksh/R-1.9.1/src/library/Recommende 
d'
make[1]: *** [recommended-packages] Error 2
make[1]: Leaving directory 
`/working/jrd/sat/rksh/R-1.9.1/src/library/Recommende 
d'
make: *** [stamp-recommended] Error 2
jagungal:/working/jrd/sat/rksh/R-1.9.1%


I've had this three times now.
How do I get round this?





-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From ligges at statistik.uni-dortmund.de  Mon Jul  5 13:52:51 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 05 Jul 2004 13:52:51 +0200
Subject: [R] Why does summary does not produce output?
In-Reply-To: <x2eknqua57.fsf@biostat.ku.dk>
References: <CIEIJIPIJFGBCBBNMJFJKEAHCAAA.jozef.deherdt@pandora.be>
	<x2eknqua57.fsf@biostat.ku.dk>
Message-ID: <40E94113.7090307@statistik.uni-dortmund.de>

Peter Dalgaard wrote:

> "Jozef De Herdt" <jozef.deherdt at pandora.be> writes:
> 
> 
>>If I run the example from written with winedt. The summary command does not
>>produce any output. It does when I repeat the command manualy in R. Can
>>someone explain me what can be the problem?
>>
>>     library(MASS)
>>     data(anorexia)
>>     anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
>>                 family = gaussian, data = anorexia)
>>     summary(anorex.1)
> 
> 
> Is the winedt interface like source() or like source(...,echo=TRUE)? 

source()

> If the former, you need to print() objects explicitly, including
> summaries.
> 

Well, you can also submit code using the "paste" button or shortcut (Alt-P).

Uwe Ligges



From p.dalgaard at biostat.ku.dk  Mon Jul  5 13:53:29 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Jul 2004 13:53:29 +0200
Subject: [R] "make" error for R-1.9.1
In-Reply-To: <a06002002bd0edf3504be@[139.166.242.29]>
References: <a06002002bd0edf3504be@[139.166.242.29]>
Message-ID: <x2vfh2sm9y.fsf@biostat.ku.dk>

Robin Hankin <rksh at soc.soton.ac.uk> writes:

> Error in .installPackageIndices(".",
> "/working/jrd/sat/rksh/R-1.9.1/library/nlme ") :
>          cannot open directory'/working/jrd/sat/rksh/R-1.9.1/library/nlme/Meta'
> Execution halted
...
> I've had this three times now.
> How do I get round this?

An offhand guess is that your umask is set strangely, causing
permission trouble. Try building with umask 22.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From HDoran at air.org  Mon Jul  5 14:01:10 2004
From: HDoran at air.org (Doran, Harold)
Date: Mon, 5 Jul 2004 08:01:10 -0400
Subject: [R] doubly multivariate analysis in R
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7404044C92@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040705/43490312/attachment.pl

From a.prioglio at city.ac.uk  Mon Jul  5 14:10:08 2004
From: a.prioglio at city.ac.uk (a.prioglio@city.ac.uk)
Date: Mon, 5 Jul 2004 13:10:08 +0100
Subject: [R] What is a sane way to deal with changes in library loadings
	after 1.9.0?
In-Reply-To: <Pine.LNX.4.44.0407051142520.20361-100000@gannet.stats>
References: <20040705103543.GA6439@anaconda.dogbert.ntt.it>
	<Pine.LNX.4.44.0407051142520.20361-100000@gannet.stats>
Message-ID: <20040705121008.GB6439@anaconda.dogbert.ntt.it>

On Mon, Jul 05, 2004 at 11:51:25AM +0100, Prof Brian Ripley wrote:
> > Well, I'm certainly new to R. Still without the explicit loading of the
> > above libraries my scripts while loading on 1.8.1 were definetely not
> > loading on 1.9.1. I'm using the same account on all machines so I expect
> > to have the same environment. Or should I?
> > 
> > One thing I noticed now, a search() on a 1.8.1 machine after the loading
> > of the scripts now returns nothing (after encountering an error though).
> 
> And what was the error?
After a call to factanal()
Error in sc %% S: non conformable arguments

If the offending line is removed search() returns its normal output

So it appears that the interpreter environment is affected by
encountering errors in the script. I did not know or noticed before.
> 
> It seems that you have been fiddling with the default set of packages.
> Have you set R_DEFAULT_PACKAGES?  Have you set option "defaultPackages"?
> If so, set them to "", or try starting R with --vanilla.

No the R environment is "vanilla", i.e. no variables set and a call to
"set" from bash does not show any R variable. R is from official RPM binaries
for RH9 (on RH9) and the 1.9.1 from the RPM for SuSE 9.0 (on SuSE 9.0).

The only option changed in the scripts is the width of output for text
files, which is restored at the end of the script.

No other option is changed.

> 
> Packages utils, graphics and stats are loaded by default on 1.9.1.  And
> package mva is loaded by default on 1.8.1.  People who answer here tend to
> assume that people who know enough to change the default packages loaded
> know enough to revert the changes ....

This is not my experience. The Changelog document for 1.9.0 indicates 
clearly that scripts that used to work before 1.9.0 now need to
explicitly load stats, utils and graphics libraries.
Indeed these pachages are loaded by default if
one starts R as an interpreter. This is not my the case, as I explicitly
stated as I run R with a script loaded with the .First mechanism in
.Rprofile.

My confusion derives from the fact that after I had to explicitly
load/attach the libraries to cope with the changes as described in the
Changelog document for 1.9.0, I started to experience problems that I did
not notice before and more intersting even when using the 1.8.1
version with the same script.
.

> 
> > How can one know what environments are loaded? Calling R --verbose did
> > not seem to clarify this point.
> 
> search()  (attached, not loaded, BTW, as there are loaded namespace 
> environments which are not attached).
>
Well, what I was hoping for was a way to see something from the unix
shell like R --show-environment (I know it's not on the man page ...) or
something like --verbose that did report the working environment. By the
time I get to the R prompt I see nothing.

-- 
Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From daniela.marconi at libero.it  Mon Jul  5 14:46:43 2004
From: daniela.marconi at libero.it (daniela.marconi@libero.it)
Date: Mon,  5 Jul 2004 14:46:43 +0200
Subject: [R] design
Message-ID: <I0DQ5V$2482DF0610E362D87C720A95D53E1025@libero.it>

Hi

I have not understood very well how to realize, in limma package, 
the design (using factor in model.matrix) to insert in lmFit.
I have an experiment with 4 groups (a,b,c,d) with 3 replicates for each-one
and i have to compare a vs b; c vs d; ( a&c )vs (b&d).
List Sample in pdata is like this: 
1a
1c
1b
1d
2a
2c
2b
2d
3a
3c
3b
3d
How can i do this design with matrix model?
thanks 
daniela



From rado.bonk at jrc.it  Mon Jul  5 14:53:37 2004
From: rado.bonk at jrc.it (Rado Bonk)
Date: Mon, 05 Jul 2004 14:53:37 +0200
Subject: [R] extract columns from a dataframe
Message-ID: <40E94F51.1060006@jrc.it>

Dear R users,

I'm coming back to R after while. I have a data frame with 200 columns, 
each column has a name. How to extract all columns to a new dataset, but 
the specified (by names) ones?

I was playing with that for a little bit using the vector syntax but got 
several syntax errors.


Thanks,

Rado



From ripley at stats.ox.ac.uk  Mon Jul  5 14:55:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 13:55:34 +0100 (BST)
Subject: [R] What is a sane way to deal with changes in library loadings
	after 1.9.0?
In-Reply-To: <20040705121008.GB6439@anaconda.dogbert.ntt.it>
Message-ID: <Pine.LNX.4.44.0407051351140.20516-100000@gannet.stats>

Your confusion is that you are trying to run scripts from .First.
You did not say so, and that is strongly not recommended, especially if 
they might have errors.

Use R CMD BATCH to run scripts and you will find it much easier.

BTW, please send replies to the individual asking, not just to the list.

On Mon, 5 Jul 2004 a.prioglio at city.ac.uk wrote:

> On Mon, Jul 05, 2004 at 11:51:25AM +0100, Prof Brian Ripley wrote:
> > > Well, I'm certainly new to R. Still without the explicit loading of the
> > > above libraries my scripts while loading on 1.8.1 were definetely not
> > > loading on 1.9.1. I'm using the same account on all machines so I expect
> > > to have the same environment. Or should I?
> > > 
> > > One thing I noticed now, a search() on a 1.8.1 machine after the loading
> > > of the scripts now returns nothing (after encountering an error though).
> > 
> > And what was the error?
> After a call to factanal()
> Error in sc %% S: non conformable arguments
> 
> If the offending line is removed search() returns its normal output
> 
> So it appears that the interpreter environment is affected by
> encountering errors in the script. I did not know or noticed before.
> > 
> > It seems that you have been fiddling with the default set of packages.
> > Have you set R_DEFAULT_PACKAGES?  Have you set option "defaultPackages"?
> > If so, set them to "", or try starting R with --vanilla.
> 
> No the R environment is "vanilla", i.e. no variables set and a call to
> "set" from bash does not show any R variable. R is from official RPM binaries
> for RH9 (on RH9) and the 1.9.1 from the RPM for SuSE 9.0 (on SuSE 9.0).
> 
> The only option changed in the scripts is the width of output for text
> files, which is restored at the end of the script.
> 
> No other option is changed.
> 
> > 
> > Packages utils, graphics and stats are loaded by default on 1.9.1.  And
> > package mva is loaded by default on 1.8.1.  People who answer here tend to
> > assume that people who know enough to change the default packages loaded
> > know enough to revert the changes ....
> 
> This is not my experience. The Changelog document for 1.9.0 indicates 
> clearly that scripts that used to work before 1.9.0 now need to
> explicitly load stats, utils and graphics libraries.
> Indeed these pachages are loaded by default if
> one starts R as an interpreter. This is not my the case, as I explicitly
> stated as I run R with a script loaded with the .First mechanism in
> .Rprofile.
> 
> My confusion derives from the fact that after I had to explicitly
> load/attach the libraries to cope with the changes as described in the
> Changelog document for 1.9.0, I started to experience problems that I did
> not notice before and more intersting even when using the 1.8.1
> version with the same script.
> .
> 
> > 
> > > How can one know what environments are loaded? Calling R --verbose did
> > > not seem to clarify this point.
> > 
> > search()  (attached, not loaded, BTW, as there are loaded namespace 
> > environments which are not attached).
> >
> Well, what I was hoping for was a way to see something from the unix
> shell like R --show-environment (I know it's not on the man page ...) or
> something like --verbose that did report the working environment. By the
> time I get to the R prompt I see nothing.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Jul  5 15:02:08 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 14:02:08 +0100 (BST)
Subject: [R] extract columns from a dataframe
In-Reply-To: <40E94F51.1060006@jrc.it>
Message-ID: <Pine.LNX.4.44.0407051357090.20516-100000@gannet.stats>

myDF[! names(myDF) %in% not_wanted]

if I understand you aright.  E.g.

library(MASS)
hills[! names(hills) %in% "climb"]

which can also be done by

subset(hills, select=-climb)

On Mon, 5 Jul 2004, Rado Bonk wrote:

> I'm coming back to R after while. I have a data frame with 200 columns, 
> each column has a name. How to extract all columns to a new dataset, but 
> the specified (by names) ones?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Mon Jul  5 15:04:06 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 05 Jul 2004 09:04:06 -0400
Subject: [R] extract columns from a dataframe
In-Reply-To: <40E94F51.1060006@jrc.it>
Message-ID: <BD0ECA06.A618%sdavis2@mail.nih.gov>

Rado,

If you have a data.frame df like:

Col1  Col2  Col3 Col4
1     2     A    B

Then you should be able to do:

df[,c("Col2","Col4")]

to get the second and fourth columns.

Sean


On 7/5/04 8:53 AM, "Rado Bonk" <rado.bonk at jrc.it> wrote:

> Dear R users,
> 
> I'm coming back to R after while. I have a data frame with 200 columns,
> each column has a name. How to extract all columns to a new dataset, but
> the specified (by names) ones?
> 
> I was playing with that for a little bit using the vector syntax but got
> several syntax errors.
> 
> 
> Thanks,
> 
> Rado
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Mon Jul  5 15:05:06 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 5 Jul 2004 09:05:06 -0400
Subject: [R] extract columns from a dataframe
In-Reply-To: <40E94F51.1060006@jrc.it>
Message-ID: <20040705130506.IGBS14757.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Rado,

If the data frame is named df and nms is a vector names of the columns that
you want to exclude, then

df[,-sapply(nms, function(x) which(x == names(df)))] 

Should give you what you want.

I hope that this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rado Bonk
> Sent: Monday, July 05, 2004 7:54 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] extract columns from a dataframe
> 
> Dear R users,
> 
> I'm coming back to R after while. I have a data frame with 
> 200 columns, each column has a name. How to extract all 
> columns to a new dataset, but the specified (by names) ones?
> 
> I was playing with that for a little bit using the vector 
> syntax but got several syntax errors.



From Christoph.Hanck at WIWI.UNI-MUENSTER.DE  Mon Jul  5 15:34:11 2004
From: Christoph.Hanck at WIWI.UNI-MUENSTER.DE (Christoph Hanck)
Date: Mon, 05 Jul 2004 15:34:11 +0200
Subject: [R] density(x)
Message-ID: <40E974F3.618.131ED43@localhost>

Dear experts, 

when trying to estimate an kernel density function with density(x) I get the following 
error message with imported data from either EXCEL or text files:

Error in density(spr) : argument must be numeric.

Other procedues such as truehist work. If I generate data within R density works fine. 
Does anybody have an idea?

Yours
--
Christoph Hanck
Wissenschaftliche Hilfskraft
Lehrstuhl f??r Empirische Wirtschaftsforschung, Prof. Dr. Wilfling
http://www.wiwi.uni-muenster.de/~05/
WWU Muenster
Tel.: +49-251-83 25043
eMail: 05chha at wiwi.uni-muenster.de



From theis at statistik.uni-dortmund.de  Mon Jul  5 17:43:39 2004
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Mon, 05 Jul 2004 17:43:39 +0200
Subject: [R] density(x)
In-Reply-To: <40E974F3.618.131ED43@localhost>
References: <40E974F3.618.131ED43@localhost>
Message-ID: <1089042219.25202.90.camel@malepartus.statistik.uni-dortmund.de>

Hello!
On Mon, 2004-07-05 at 15:34, Christoph Hanck wrote:
> Dear experts, 
> 
> when trying to estimate an kernel density function with density(x) I get the following 
> error message with imported data from either EXCEL or text files:
> 
> Error in density(spr) : argument must be numeric.
Well, as R tells you: You should check, whether your data is of type
"numeric". Depending on the way you import the data "spr" this may not
be the case and you have to do 
> density(as.numeric(spr))
which should work... Besides: please read the guidelines for posting
(see http://www.R-project.org/posting-guide.html) giving some details on
the procedure you use to read in the data may have helped to give you a
precise answer!

Regards,

Winfried

-- 
-----------------------------------------------------------------
Dr. Dipl.-Math. Winfried Theis, SFB 475, Projekt C5,
Universit??t Dortmund, 44221 Dortmund
e-mail: theis at statistik.uni-dortmund.de
Tel.: +49/231/755-5903 FAX: +49/231/755-4387



From ym at climpact.com  Mon Jul  5 15:49:15 2004
From: ym at climpact.com (Yves Magliulo)
Date: 05 Jul 2004 15:49:15 +0200
Subject: [R] extract columns from a dataframe
In-Reply-To: <40E94F51.1060006@jrc.it>
References: <40E94F51.1060006@jrc.it>
Message-ID: <1089035355.3855.21.camel@new-york.climpact.net>

hi,

see colnames() 
simple use, good result.

ex: if df is your data.frame and toto = the column name you want to
extract do:

df2<-df[,colnames(df)==toto)] #extract all toto column



Le lun 05/07/2004 ?? 14:53, Rado Bonk a ??crit :
> Dear R users,
> 
> I'm coming back to R after while. I have a data frame with 200 columns, 
> each column has a name. How to extract all columns to a new dataset, but 
> the specified (by names) ones?
> 
> I was playing with that for a little bit using the vector syntax but got 
> several syntax errors.
> 
> 
> Thanks,
> 
> Rado
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
------
Yves Magliulo <ym at climpact.com>
Climatology research department, CLIMPACT

Tel.   : +33 (0) 1 55 07 85 77
Fax.   : +33 (0) 1 55 07 85 79
Universite Pierre et Marie Curie
Boite 101 - Tour 45 - 5eme etage - Couloir 45/46
4 place Jussieu, 75252 Paris CEDEX 05, France



From MSchwartz at MedAnalytics.com  Mon Jul  5 15:57:34 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 05 Jul 2004 08:57:34 -0500
Subject: [R] density(x)
In-Reply-To: <40E974F3.618.131ED43@localhost>
References: <40E974F3.618.131ED43@localhost>
Message-ID: <1089035854.10847.272.camel@localhost.localdomain>

On Mon, 2004-07-05 at 08:34, Christoph Hanck wrote:
> Dear experts, 
> 
> when trying to estimate an kernel density function with density(x) I get the following 
> error message with imported data from either EXCEL or text files:
> 
> Error in density(spr) : argument must be numeric.
> 
> Other procedues such as truehist work. If I generate data within R density works fine. 
> Does anybody have an idea?


More than likely, your vector 'spr' was imported as a factor. This would
possibly suggest that at least one value in 'spr' is not numeric. If the
entire vector was numeric, this would not be a problem.

It is also possible that you may have not specified the proper
delimiting character during the import, which would compromise the
parsed structure of the incoming data.

Use:

str(spr)

and you will probably get 

Factor ...

First, check to be sure that you have used the proper delimiting
character during your import. See ?read.table for the family of related
functions and the default argument values for 'sep', which is the
delimiting character.

You should also check your source data file, since it may be
problematic.

HTH,

Marc Schwartz



From mjw at celos.net  Mon Jul  5 16:12:24 2004
From: mjw at celos.net (Mark White)
Date: Mon, 5 Jul 2004 15:12:24 +0100
Subject: [R] Tk force refresh
Message-ID: <20040705141224.GC23027@celos.net>

I'm trying to use a Tk widget to show some progress &
intermediate results in a long-running R calculation.

Does anybody know how (or whether) I can force a window
redraw without waiting for the idle loop?  Currently,
refreshes only seem to happen when we return to the R
toplevel read-eval-print loop.

Thanks,
Mark <><



From p.dalgaard at biostat.ku.dk  Mon Jul  5 16:20:19 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Jul 2004 16:20:19 +0200
Subject: [R] Tk force refresh
In-Reply-To: <20040705141224.GC23027@celos.net>
References: <20040705141224.GC23027@celos.net>
Message-ID: <x26592sfh8.fsf@biostat.ku.dk>

Mark White <mjw at celos.net> writes:

> I'm trying to use a Tk widget to show some progress &
> intermediate results in a long-running R calculation.
> 
> Does anybody know how (or whether) I can force a window
> redraw without waiting for the idle loop?  Currently,
> refreshes only seem to happen when we return to the R
> toplevel read-eval-print loop.

I think it's tkcmd("update") or tkcmd("update", "idletasks"). In
general the advise seems to be to use the  latter form if you can,
since there there can be some nasty reentrancy issues with the former.
(I forgot where I saw the description of exactly what can go wrong;
possibly, it was on wiki.tcl.dk) 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From i.visser at uva.nl  Mon Jul  5 16:19:02 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Mon, 05 Jul 2004 16:19:02 +0200
Subject: [R] passing char's from C to Fortran (mac os x)
Message-ID: <BD0F2FF6.44DA%i.visser@uva.nl>


Hello All,

In some package I use a c-routine which calls a fortran routine which
expects a char-string as input.

As per the writing R-extensions manual,
the Fortran routine is declared in C as:
void F77_NAME (setoptions) (char **option);

and then it is calles as follows:

   char **option; 
   option = new char*[1];
   option[0] = new char[256];
   option[0] = strcpy(option[0],"Iteration Limit = 100");
   Rprintf(option[0]);
   F77_CALL (setoptions) (option);

Unfortunately this does not work, ie the fortran routine setoptions does
not correctly get the intended character string. Can anyone point me to a
working example  of passing characters from C to Fortran? Or tell me what's
wrong in my code above?

My platform is below, I use R CMD INSTALL to compile and install the
complete package.

thanks in advance, ingmar visser

platform powerpc-apple-darwin6.8
arch     powerpc   
os       darwin6.8 
system   powerpc, darwin6.8
status             
major    1         
minor    9.0       
year     2004      
month    04        
day      12        
language R



From ripley at stats.ox.ac.uk  Mon Jul  5 16:23:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 15:23:54 +0100 (BST)
Subject: [R] extract columns from a dataframe
In-Reply-To: <1089035355.3855.21.camel@new-york.climpact.net>
Message-ID: <Pine.LNX.4.44.0407051519510.20598-100000@gannet.stats>

On 5 Jul 2004, Yves Magliulo wrote:

> see colnames() 
> simple use, good result.

Not really correct use, though.  A data frame has names for its columns,
and a matrix has colnames.

> ex: if df is your data.frame and toto = the column name you want to
> extract do:
> 
> df2<-df[,colnames(df)==toto)] #extract all toto column

df["toto"] is much easier (and you do need the quotes, I believe).  It
even works with a vector of names.

> Le lun 05/07/2004 ?? 14:53, Rado Bonk a ??crit :
> > Dear R users,
> > 
> > I'm coming back to R after while. I have a data frame with 200 columns, 
> > each column has a name. How to extract all columns to a new dataset, but 
> > the specified (by names) ones?

I read that as meaning `all except the specified columns'.

> > I was playing with that for a little bit using the vector syntax but got 
> > several syntax errors.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rado.bonk at jrc.it  Mon Jul  5 16:25:45 2004
From: rado.bonk at jrc.it (Rado Bonk)
Date: Mon, 05 Jul 2004 16:25:45 +0200
Subject: [R] R and databases (Oracle)
Message-ID: <40E964E9.6070200@jrc.it>

Dear R users,

I'm working on implementation of hydrometeorological DB in Oracle9i and 
would like to use R, as a plotting engine for graphs and maps and also 
to perform some non trivial statistics on DB data using R. Thus any 
links with examples or efforts on:
- general DB and R cooperation
- Oracle91 and R cooperation
- Oracle PL/SQL and R

are welcomed.

Thanks in advance,

Rado


-- 
Radoslav Bonk
European Commission - DG Joint Research Centre (JRC)
Institute for Environment and Sustainability (IES)
LM Unit - Natural Hazards
Weather Driven Natural Hazards Action
Via E. Fermi, TP 261, 21020 Ispra (Va), Italy
Tel.: 0039-0332-786013
Fax: 0039-0332-786653
Webpage: http://natural-hazards.jrc.it/floods/



From ernesto at ipimar.pt  Mon Jul  5 16:49:45 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 05 Jul 2004 15:49:45 +0100
Subject: [R] Function for skewness
Message-ID: <1089038985.12557.225.camel@gandalf.local>

Hi,

Is there a function to estimate the skewness of a distribution ?

Thanks

EJ



From Christoph.Hanck at WIWI.UNI-MUENSTER.DE  Mon Jul  5 16:41:47 2004
From: Christoph.Hanck at WIWI.UNI-MUENSTER.DE (Christoph Hanck)
Date: Mon, 05 Jul 2004 16:41:47 +0200
Subject: [R] density(x)
In-Reply-To: <1089038327.10847.280.camel@localhost.localdomain>
References: <40E98312.1290.1691627@localhost>
Message-ID: <40E984CC.8942.16FD3B8@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040705/1318c90d/attachment.pl

From ripley at stats.ox.ac.uk  Mon Jul  5 16:43:14 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 15:43:14 +0100 (BST)
Subject: [R] passing char's from C to Fortran (mac os x)
In-Reply-To: <BD0F2FF6.44DA%i.visser@uva.nl>
Message-ID: <Pine.LNX.4.44.0407051533430.20598-100000@gannet.stats>

On Mon, 5 Jul 2004, Ingmar Visser wrote:

> 
> Hello All,
> 
> In some package I use a c-routine which calls a fortran routine which
> expects a char-string as input.
> 
> As per the writing R-extensions manual,
> the Fortran routine is declared in C as:
> void F77_NAME (setoptions) (char **option);

That's not in that manual.  It says

 The following table gives the mapping between the modes of R vectors and 
 the types of arguments to a C function or FORTRAN subroutine.

and not between the latter two.

> and then it is calles as follows:
> 
>    char **option; 
>    option = new char*[1];
>    option[0] = new char[256];
>    option[0] = strcpy(option[0],"Iteration Limit = 100");
>    Rprintf(option[0]);
>    F77_CALL (setoptions) (option);
> 
> Unfortunately this does not work, ie the fortran routine setoptions does
> not correctly get the intended character string. Can anyone point me to a
> working example  of passing characters from C to Fortran? Or tell me what's
> wrong in my code above?

It's not C!  (It looks like C++.)  Where did you get the idea that Fortran 
character corresponds to char** in C?  It probably corresponds to char*, 
possibly with a length passed separately.  Since you are probably using 
g77 I expect passing char * from C to Fortran will work, but passing back 
might not.

R is a C program and it manages to pass characters to Fortran in quite a 
few places, such as Lapack.c and loessc.c/loessf.f.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at MedAnalytics.com  Mon Jul  5 16:44:42 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 05 Jul 2004 09:44:42 -0500
Subject: [R] Function for skewness
In-Reply-To: <1089038985.12557.225.camel@gandalf.local>
References: <1089038985.12557.225.camel@gandalf.local>
Message-ID: <1089038682.10847.283.camel@localhost.localdomain>

On Mon, 2004-07-05 at 09:49, Ernesto Jardim wrote:
> Hi,
> 
> Is there a function to estimate the skewness of a distribution ?
> 
> Thanks
> 
> EJ


See skewness() in CRAN package 'e1071'.

HTH,

Marc Schwartz



From ernesto at ipimar.pt  Mon Jul  5 16:57:41 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 05 Jul 2004 15:57:41 +0100
Subject: [R] Function for skewness
In-Reply-To: <1089038682.10847.283.camel@localhost.localdomain>
References: <1089038985.12557.225.camel@gandalf.local>
	<1089038682.10847.283.camel@localhost.localdomain>
Message-ID: <1089039460.12561.227.camel@gandalf.local>


On Mon, 2004-07-05 at 15:44, Marc Schwartz wrote:
> On Mon, 2004-07-05 at 09:49, Ernesto Jardim wrote:
> > Hi,
> > 
> > Is there a function to estimate the skewness of a distribution ?
> > 
> > Thanks
> > 
> > EJ
> 
> 
> See skewness() in CRAN package 'e1071'.
> 
> HTH,
> 
> Marc Schwartz
> 

Thanks

EJ



From ripley at stats.ox.ac.uk  Mon Jul  5 16:49:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 15:49:16 +0100 (BST)
Subject: [R] density(x)
In-Reply-To: <40E984CC.8942.16FD3B8@localhost>
Message-ID: <Pine.LNX.4.44.0407051544560.20598-100000@gannet.stats>

OK, so sp is a data frame.  Probably you want density(sp$sp) there since 
the single column is already numeric.

It just so happens that truehist does an implicit drop() on a 1-column 
data frame.

On Mon, 5 Jul 2004, Christoph Hanck wrote:

> Hello and thanks for your reply
> 
> Hopefully, my answer arrives at the correct place like that (if not, I am sorry for bothering you, but please let me know...)
> 
> To sum up my procedure (sp is exactly the same thing as spr, I had just tinkered with
> the names while trying sth. to solve this problem)
> 
> > sp<-read.table("c:/ratsdata/sp3.txt", col.names="sp")
> > xd<-density(sp)
> Error in density(sp) : argument must be numeric
> 
> The suggested remedies yield the following
> > str(sp)
> `data.frame':   195 obs. of  1 variable:
>  $ sp: int  11 10 10 12 25 22 12 23 13 15 ...
> > xd<-density(as.numeric(sp))
> Error in as.double.default(sp) : (list) object cannot be coerced to double
> 
> Hence, it does not seem to be a factor. Declaring it as numeric gives another error
> message, on which I haven't yet found any help in Google/the archive.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Christoph.Hanck at WIWI.UNI-MUENSTER.DE  Mon Jul  5 16:57:06 2004
From: Christoph.Hanck at WIWI.UNI-MUENSTER.DE (Christoph Hanck)
Date: Mon, 05 Jul 2004 16:57:06 +0200
Subject: [R] density(x)
In-Reply-To: <Pine.LNX.4.44.0407051544560.20598-100000@gannet.stats>
References: <40E984CC.8942.16FD3B8@localhost>
Message-ID: <40E98863.31033.17DDA32@localhost>

Hello, 

> OK, so sp is a data frame.  Probably you want density(sp$sp) there since 
> the single column is already numeric.

Yes, that works just the way I hoped. So what I am essentially doing is selecting (just 
to know what I'm doing) the column that contains sp from the data frame sp?

Thank you very much!

Christoph



From gavin.simpson at ucl.ac.uk  Mon Jul  5 16:57:31 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 05 Jul 2004 15:57:31 +0100
Subject: [R] density(x)
In-Reply-To: <40E984CC.8942.16FD3B8@localhost>
References: <40E98312.1290.1691627@localhost> <40E984CC.8942.16FD3B8@localhost>
Message-ID: <40E96C5B.3030007@ucl.ac.uk>

Christoph Hanck wrote:
> Hello and thanks for your reply
> 
> Hopefully, my answer arrives at the correct place like that (if not,
> I am sorry for bothering you, but please let me know...)
> 
> To sum up my procedure (sp is exactly the same thing as spr, I had
> just tinkered with the names while trying sth. to solve this problem)
> 
>> sp<-read.table("c:/ratsdata/sp3.txt", col.names="sp") 
>> xd<-density(sp)
> 
> Error in density(sp) : argument must be numeric
> 
> The suggested remedies yield the following
> 
>> str(sp)
> 
> `data.frame':   195 obs. of  1 variable: $ sp: int  11 10 10 12 25 22
> 12 23 13 15 ...
> 
>> xd<-density(as.numeric(sp))
> 
> Error in as.double.default(sp) : (list) object cannot be coerced to
> double

It is telling you that it cannot convert a list into a numeric object. A 
data frame is a list so it is telling you that you cannot convert the 
data frame into a numeric vector.

> Hence, it does not seem to be a factor. Declaring it as numeric gives
> another error message, on which I haven't yet found any help in
> Google/the archive.

You want the sp column of the data frame sp not the data frame sp itself 
(perhaps you should choose a name for the data frame that is different 
to a column name)

 > sp <- data.frame(sp = rnorm(100))
 > density(sp)
Error in density(sp) : argument must be numeric
 > density(sp$sp)

Call:
         density(x = sp$sp)

Data: sp$sp (100 obs.); Bandwidth 'bw' = 0.3007

        x                  y
  Min.   :-3.37457   Min.   :0.0001983
  1st Qu.:-1.73138   1st Qu.:0.0389884
  Median :-0.08819   Median :0.1157180
  Mean   :-0.08819   Mean   :0.1519886
  3rd Qu.: 1.55500   3rd Qu.:0.2227940
  Max.   : 3.19818   Max.   :0.4766640

Does this help?

with(sp, density(sp)) would also do what you want, see ?with, and there 
are other ways.

Gavin

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From ottorino-luca.pantani at unifi.it  Mon Jul  5 16:57:35 2004
From: ottorino-luca.pantani at unifi.it (8rino-Luca Pantani)
Date: Mon, 05 Jul 2004 16:57:35 +0200
Subject: [R] using perm.cond & index.cond in lattice package
In-Reply-To: <I0DQ5V$2482DF0610E362D87C720A95D53E1025@libero.it>
Message-ID: <DAEBLEBOOMBHMLACIMKCIEFKCFAA.OLPantani@unifi.it>

Dear R users,
this is my first question to the list.
I hope it will be not a trivial one.

My problem is to change the order in which the panel are plotted in a
lattice/Trellis plot.
I've read the S-plus Trellis Graphics user manual, in which there is a
function called "reorder.factor",
that, as far as I can catch from ?xyplot, in the lattice package is
substituted by two others:
"index.cond" & "perm.cond"


here below the (fictitious) data

cbind.data.frame(TREAT=c(rep(c("YES", "NO"), each=12)),
                 OM=rep(rep(c(5, 1, 3, 7), each=3), 2),
                 LOCATION=rep(rep(c("here5%OM", "there1%OM",
"elsewhere3%OM",
                                               "overthere7%OM"),
                                      each=3), 2),
                 Y=c(rnorm(3, mean=5),rnorm(3, mean=1),rnorm(3,
mean=3),rnorm(3, mean=7),
                     rnorm(3, mean=6),rnorm(3, mean=2),rnorm(3,
mean=4),rnorm(3, mean=8))
                )->mydframe
library(lattice)
bwplot(Y~TREAT|LOCATION, data=mydframe)
#The panels are plotted in alphabetical order, but I would rather have
something like
bwplot(Y~TREAT|OM, data=mydframe)
# i.e. the panels ordered by OM (Organic Matter) content
#but with LOCATION written in the strip.
#From
#str(bwplot(Y~TREAT|OM, data=mydframe))
#I can see that
# $ index.cond       :List of 1
# ..$ : int [1:4] 1 2 3 4
# $ perm.cond        : num 1
#so I tried
bwplot(Y~TREAT|LOCATION,
       data=mydframe,
       index.cond=
list((1:4)[order(unique(mydframe$OM[order(mydframe$LOCATION)]))])
       )
#and it seems to work, but without the darker tag for OM in the strips.

Now I have one perplexity and one question:

The last "list((1:4)[order(...." works fine, but it seems to me inelegant,
too complicate
                                        and not practical for plots with
more factors.
Any suggestion to simplify/improve the matter?

How can I keep the tags in the strips, still ordering the panels by OM?

Thanks in advance.

PS
The following lines are copied from ?xyplot
(I suspect that "order.cond" stands for "index.cond",
since I cannot find it in any other page of the lattice help, nor in the
general help)

 The order in which the panels are drawn depends on the order
          in which the conditioning variables are specified ('g1'
          varies fastest). Within a conditioning variable, the order
          depends on the order of the levels (which for factors is
          usually in alphabetical order). Both of these orders can be
          modified using the 'order.cond' and 'perm.cond' arguments,
          typically in the 'update' method.

Ottorino-Luca Pantani, Universit?? di Firenze
Dip. Scienza del Suolo e Nutrizione della Pianta



From MSchwartz at MedAnalytics.com  Mon Jul  5 17:05:52 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 05 Jul 2004 10:05:52 -0500
Subject: [R] density(x)
In-Reply-To: <40E984CC.8942.16FD3B8@localhost>
References: <40E98312.1290.1691627@localhost> <40E984CC.8942.16FD3B8@localhost>
Message-ID: <1089039952.10847.304.camel@localhost.localdomain>

On Mon, 2004-07-05 at 09:41, Christoph Hanck wrote:
> Hello and thanks for your reply
> 
> Hopefully, my answer arrives at the correct place like that (if not, I
> am sorry for bothering you, but please let me know...)
> 
> To sum up my procedure (sp is exactly the same thing as spr, I had
> just tinkered with
> the names while trying sth. to solve this problem)
> 
> > sp<-read.table("c:/ratsdata/sp3.txt", col.names="sp")
> > xd<-density(sp)
> Error in density(sp) : argument must be numeric
> 
> The suggested remedies yield the following
> > str(sp)
> `data.frame':   195 obs. of  1 variable:
>  $ sp: int  11 10 10 12 25 22 12 23 13 15 ...
> > xd<-density(as.numeric(sp))
> Error in as.double.default(sp) : (list) object cannot be coerced to
> double
> 
> Hence, it does not seem to be a factor. Declaring it as numeric gives
> another error
> message, on which I haven't yet found any help in Google/the archive.


In this case, you are trying to pass a data frame as an argument to
density() rather than a single column vector. The same problem is the
reason for the error in "xd<-density(as.numeric(sp))". You are trying to
coerce a data frame to a double.

Example:

# create a data frame called 'sp', that has a column called 'sp'
> sp <- data.frame(sp = 1:195)

> str(sp)
`data.frame':	195 obs. of  1 variable:
 $ sp: int  1 2 3 4 5 6 7 8 9 10 ...

# Now try to use density()
> density(sp)
Error in density(sp) : argument must be numeric

# Now call density() properly with the column 'sp' as an argument
# using the data.frame$column notation:
> density(sp$sp)

Call:
	density(x = sp$sp)

Data: sp$sp (195 obs.);	Bandwidth 'bw' = 17.69

       x                y            
 Min.   :-52.08   Min.   :7.688e-06  
 1st Qu.: 22.96   1st Qu.:1.009e-03  
 Median : 98.00   Median :4.600e-03  
 Mean   : 98.00   Mean   :3.328e-03  
 3rd Qu.:173.04   3rd Qu.:5.131e-03  
 Max.   :248.08   Max.   :5.133e-03


Two other options in this case:

1. Use attach() to place the data frame 'sp' in the current search path.
Now you do not need to explicitly use the data.frame$column notation.
Then detach is then used to clean up.

attach(sp)
density(sp)
detach(sp)


2. Use with(), which is the preferred notation when dealing with data
frames:

with(sp, density(sp))


To avoid your own confusion in the future, it would be better to not
name the data frame with the same name as a vector. It also helps when
others may need to review your code.

See ?with and ?attach for more information.

Reading through "An Introduction to R" which is part of the default
documentation set would be helpful to you in better understanding data
types and dealing with data frame structures.

I see that Prof. Ripley has also replied regarding the nature of
truehist(), so that helps to clear up that mystery.... :-)

HTH,

Marc Schwartz



From sdavis2 at mail.nih.gov  Mon Jul  5 17:07:02 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 05 Jul 2004 11:07:02 -0400
Subject: [R] R and databases (Oracle)
In-Reply-To: <40E964E9.6070200@jrc.it>
Message-ID: <BD0EE6D6.A637%sdavis2@mail.nih.gov>

Rado,

Did you look at the package Roracle
(http://cran.r-project.org/src/contrib/Descriptions/ROracle.html)?

Sean

On 7/5/04 10:25 AM, "Rado Bonk" <rado.bonk at jrc.it> wrote:

> Dear R users,
> 
> I'm working on implementation of hydrometeorological DB in Oracle9i and
> would like to use R, as a plotting engine for graphs and maps and also
> to perform some non trivial statistics on DB data using R. Thus any
> links with examples or efforts on:
> - general DB and R cooperation
> - Oracle91 and R cooperation
> - Oracle PL/SQL and R
> 
> are welcomed.
> 
> Thanks in advance,
> 
> Rado
>



From Christoph.Hanck at WIWI.UNI-MUENSTER.DE  Mon Jul  5 17:09:53 2004
From: Christoph.Hanck at WIWI.UNI-MUENSTER.DE (Christoph Hanck)
Date: Mon, 05 Jul 2004 17:09:53 +0200
Subject: [R] density(x)
In-Reply-To: <1089039952.10847.304.camel@localhost.localdomain>
References: <40E984CC.8942.16FD3B8@localhost>
Message-ID: <40E98B62.23109.1898E93@localhost>

Hello, 

thanks again.
 
> Reading through "An Introduction to R" which is part of the default
> documentation set would be helpful to you in better understanding data
> types and dealing with data frame structures.

I got the message! I admit that my systematic efforts into R may be considered 
wanting.

--
Christoph Hanck
Wissenschaftliche Hilfskraft
Lehrstuhl f??r Empirische Wirtschaftsforschung, Prof. Dr. Wilfling
http://www.wiwi.uni-muenster.de/~05/
WWU Muenster
Tel.: +49-251-83 25043
eMail: 05chha at wiwi.uni-muenster.de



From mjw at celos.net  Mon Jul  5 17:24:18 2004
From: mjw at celos.net (Mark White)
Date: Mon, 5 Jul 2004 16:24:18 +0100
Subject: [R] Tk force refresh
In-Reply-To: <x26592sfh8.fsf@biostat.ku.dk>
References: <20040705141224.GC23027@celos.net> <x26592sfh8.fsf@biostat.ku.dk>
Message-ID: <20040705152418.GA23719@celos.net>

Peter Dalgaard writes:
> Mark White <mjw at celos.net> writes:
> > Does anybody know how (or whether) I can force a window
> > redraw without waiting for the idle loop?  Currently,
> > refreshes only seem to happen when we return to the R
> > toplevel read-eval-print loop.
> 
> I think it's tkcmd("update") or tkcmd("update", "idletasks"). In
> general the advise seems to be to use the  latter form if you can,
> since there there can be some nasty reentrancy issues with the former.
> (I forgot where I saw the description of exactly what can go wrong;
> possibly, it was on wiki.tcl.dk) 

Thank you: that solves the problem nicely.  It turns out the
second one only redraws things which have been changed; so
it runs a little faster, too.

Mark <><



From r.mueller at oeko-sorpe.de  Mon Jul  5 17:36:34 2004
From: r.mueller at oeko-sorpe.de (Richard =?iso-8859-1?q?M=FCller?=)
Date: Mon, 5 Jul 2004 17:36:34 +0200
Subject: [R] Behaviour of R with win98 and XP?
Message-ID: <200407051736.34770.r.mueller@oeko-sorpe.de>

Dear list,
I encounter a strange problem: I hav R (1.6.1) installed on a notebook with 
winXP-Prof and a similar installation (same path names etc.) on a desktop 
computer with W98.
I use rcmd BATCH filename to display graphs from the data stored in filename.
With R on my notebook everything works fine. I have the same data, the same 
filenames, the same paths on th w98-computer. Here I see just a short 
flickering of the console window and that was it. 
Whe I copy the lines of the script in the console window of R, I get the 
following message:

... /Code: (snip)....
file="c://Temp//TempFile.csv"
inp <- scan(file, sep=";", dec=",", list(0,0,0,0,0,0,0,0,0,0,0,0,0,0), skip = 
13, nlines = 58)
..../code(end) snip......
The error message:
Error in file(file, "r"): unable to open connection
In addition: Warning message:
cannot open file `c://Temp//TempFile.csv'

Does R behave different unter W98 than it does under XP?
Thanks for helping
Richard
-- 
--
Richard M??ller - Am Spring 9 - D-58802 Balve-Eisborn
r.mueller at oeko-sorpe.de      -     www.oeko-sorpe.de



From scott.waichler at pnl.gov  Mon Jul  5 18:08:38 2004
From: scott.waichler at pnl.gov (Scott Waichler)
Date: Mon, 05 Jul 2004 09:08:38 -0700
Subject: [R] Apparent conflict between \Sexpr in Sweave and R2HTML
Message-ID: <200407051608.i65G8ck23686@snow.pnl.gov>

I have come across an apparent bug in the operation of Sweave.  If I
load the package R2HTML then execution of \Sexpr{} in an *.Rnw file no
longer works.  The \Sexpr{} code is simply written to the *.tex file.
Below are my *.Rnw file, commands, and output.  

The Sweave file, Sweave-test-1_short.Rnw:

% -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
\documentclass{article}
\title{A Test File}
\author{Friedrich Leisch}
\SweaveOpts{echo=FALSE}
\begin{document}
\maketitle
Now we look at Gaussian data:
<<>>=
library(stats)
x <- rnorm(20)
print(x)
print(t1 <- t.test(x))
@
Note that we can easily integrate some numbers into standard text: The
third element of vector \texttt{x} is \Sexpr{x[3]}, the
$p$-value of the test is \Sexpr{format.pval(t1$p.value)}. % $
\end{document}


My commands:
> R.version.string
[1] "R version 1.9.1, 2004-06-21"
> library(R2HTML)

Loading R2HTML package...
> Sweave("Sweave-test-1_short.Rnw")
Writing to file Sweave-test-1_short.tex
Processing code chunks ...
 1 : term verbatim

You can now run LaTeX on Sweave-test-1_short.tex
>


The Sweave output file, Sweave-test-1_short.tex:

% -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
\documentclass{article}
\title{A Test File}
\author{Friedrich Leisch}

\usepackage{/usr/lib/R/share/texmf/Sweave}
\begin{document}
\maketitle
Now we look at Gaussian data:
\begin{Schunk}
\begin{Soutput}
 [1] -1.80980347  1.41215325 -0.01118795  1.69149919  0.04621916  0.43672840
 [7]  0.05831105  1.26632742  0.41980267 -0.45035200 -0.73382409 -0.92390546
[13]  0.28338334 -0.05982873 -0.15500443 -2.43182528 -0.69751187 -0.30238204
[19]  0.99555389 -1.80047878
\end{Soutput}
\begin{Soutput}
	One Sample t-test

data:  x 
t = -0.5728, df = 19, p-value = 0.5735
alternative hypothesis: true mean is not equal to 0 
95 percent confidence interval:
 -0.6436499  0.3670373 
sample estimates:
 mean of x 
-0.1383063 
\end{Soutput}
\end{Schunk}
Note that we can easily integrate some numbers into standard text: The
third element of vector \texttt{x} is \Sexpr{x[3]}, the
$p$-value of the test is \Sexpr{format.pval(t1$p.value)}. % $
\end{document}



Scott Waichler
Pacific Northwest National Laboratory
Richland, Washington USA
scott.waichler at pnl.gov



From rl241 at columbia.edu  Mon Jul  5 18:08:58 2004
From: rl241 at columbia.edu (Ruei-Che Liu)
Date: Mon, 5 Jul 2004 12:08:58 -0400 (EDT)
Subject: [R] nonlinear regression with M estimation
In-Reply-To: <200405121002.i4CA1diI002635@hypatia.math.ethz.ch>
References: <200405121002.i4CA1diI002635@hypatia.math.ethz.ch>
Message-ID: <Pine.GSO.4.60.0407051159130.18991@hazelnut.cc.columbia.edu>

Hi All,
   Could any one tells me if R or S has the capacity to fit nonlinear 
regression with Huber's M estimation? Any suggestion is appreciated. I was
aware of 'rlm' in MASS library for robust linear regression and 'nls' for 
nonlinear least squares regression, but did not seem to be able to find 
robust non-linear regression function.

   Thanks and regards,

   Ray Liu



From ripley at stats.ox.ac.uk  Mon Jul  5 18:25:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 17:25:19 +0100 (BST)
Subject: [R] Behaviour of R with win98 and XP?
In-Reply-To: <200407051736.34770.r.mueller@oeko-sorpe.de>
Message-ID: <Pine.LNX.4.44.0407051720350.20875-100000@gannet.stats>

What are you doing that creates a file path c://Temp//TempFile.csv? That
is not a valid path under Windows: use / not // or, better, use
file.path().  As far as I recall NT-based systems accept empty path
elements and W98 does not.

If this is really R 1.6.1, you are way overdue for an upgrade.

On Mon, 5 Jul 2004, Richard M??ller wrote:

> Dear list,
> I encounter a strange problem: I hav R (1.6.1) installed on a notebook with 
> winXP-Prof and a similar installation (same path names etc.) on a desktop 
> computer with W98.
> I use rcmd BATCH filename to display graphs from the data stored in filename.
> With R on my notebook everything works fine. I have the same data, the same 
> filenames, the same paths on th w98-computer. Here I see just a short 
> flickering of the console window and that was it. 
> Whe I copy the lines of the script in the console window of R, I get the 
> following message:
> 
> ... /Code: (snip)....
> file="c://Temp//TempFile.csv"
> inp <- scan(file, sep=";", dec=",", list(0,0,0,0,0,0,0,0,0,0,0,0,0,0), skip = 
> 13, nlines = 58)
> ..../code(end) snip......
> The error message:
> Error in file(file, "r"): unable to open connection
> In addition: Warning message:
> cannot open file `c://Temp//TempFile.csv'
> 
> Does R behave different unter W98 than it does under XP?

Not in this way, but W98 behaves differently from XP in many ways.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rkoenker at uiuc.edu  Mon Jul  5 18:30:12 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Mon, 5 Jul 2004 11:30:12 -0500
Subject: [R] nonlinear regression with M estimation
In-Reply-To: <Pine.GSO.4.60.0407051159130.18991@hazelnut.cc.columbia.edu>
References: <200405121002.i4CA1diI002635@hypatia.math.ethz.ch>
	<Pine.GSO.4.60.0407051159130.18991@hazelnut.cc.columbia.edu>
Message-ID: <969C64E4-CEA0-11D8-9289-000A95A7E3AA@uiuc.edu>

the package nlrq does median nonlinear regression...  among other 
things.



url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Jul 5, 2004, at 11:08 AM, Ruei-Che Liu wrote:

> Hi All,
>   Could any one tells me if R or S has the capacity to fit nonlinear 
> regression with Huber's M estimation? Any suggestion is appreciated. I 
> was
> aware of 'rlm' in MASS library for robust linear regression and 'nls' 
> for nonlinear least squares regression, but did not seem to be able to 
> find robust non-linear regression function.
>
>   Thanks and regards,
>
>   Ray Liu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Mon Jul  5 18:31:52 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 17:31:52 +0100 (BST)
Subject: [R] nonlinear regression with M estimation
In-Reply-To: <Pine.GSO.4.60.0407051159130.18991@hazelnut.cc.columbia.edu>
Message-ID: <Pine.LNX.4.44.0407051725440.20875-100000@gannet.stats>

I don't think there is one.  One problem is that both nls and robust
procedures need a starting point and so you would need a good non-linear
resistant method to start.  (For certain Huber-type linear regressions you
can show there is a unique solution and so any starting point will do.  
But that is rather unusual.)

The nearest equivalent I can think of is package nlrq, which also needs 
suitable starting values.  Once you have those, you could just call optim 
to minimize the log-likelihood under the Huber long-tailed model.

On Mon, 5 Jul 2004, Ruei-Che  Liu wrote:

>    Could any one tells me if R or S has the capacity to fit nonlinear 
> regression with Huber's M estimation? Any suggestion is appreciated. I was
> aware of 'rlm' in MASS library for robust linear regression and 'nls' for 
> nonlinear least squares regression, but did not seem to be able to find 
> robust non-linear regression function.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From deepayan at stat.wisc.edu  Mon Jul  5 20:02:57 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 5 Jul 2004 13:02:57 -0500
Subject: [R] using perm.cond & index.cond in lattice package
In-Reply-To: <DAEBLEBOOMBHMLACIMKCIEFKCFAA.OLPantani@unifi.it>
References: <DAEBLEBOOMBHMLACIMKCIEFKCFAA.OLPantani@unifi.it>
Message-ID: <200407051302.57924.deepayan@stat.wisc.edu>

On Monday 05 July 2004 09:57, 8rino-Luca Pantani wrote:
> Dear R users,
> this is my first question to the list.
> I hope it will be not a trivial one.
>
> My problem is to change the order in which the panel are plotted in a
> lattice/Trellis plot.
> I've read the S-plus Trellis Graphics user manual, in which there is
> a function called "reorder.factor",

Hmm, I didn't know about this function, but it seems easy enough to 
define. In fact the groupedData() constructor in nlme does this, and 
that can be adapted to have

reorder.factor <- function(Factor, X, Function = mean, ...)
    ordered(Factor,
            levels = names(sort(tapply(X, Factor, Function, ...))))

which you may then use. 

> that, as far as I can catch from ?xyplot, in the lattice package is
> substituted by two others:
> "index.cond" & "perm.cond"

[...]

> bwplot(Y~TREAT|LOCATION, data=mydframe)
> #The panels are plotted in alphabetical order, but I would rather
> have something like
> bwplot(Y~TREAT|OM, data=mydframe)
> # i.e. the panels ordered by OM (Organic Matter) content
> #but with LOCATION written in the strip.
> #From
> #str(bwplot(Y~TREAT|OM, data=mydframe))
> #I can see that
> # $ index.cond       :List of 1
> # ..$ : int [1:4] 1 2 3 4
> # $ perm.cond        : num 1
> #so I tried
> bwplot(Y~TREAT|LOCATION,
>        data=mydframe,
>        index.cond=
> list((1:4)[order(unique(mydframe$OM[order(mydframe$LOCATION)]))])
>        )

You might as well just have

list(order(unique(mydframe$OM[order(mydframe$LOCATION)])))

> #and it seems to work, but without the darker tag for OM in the
> strips.

The darker portion has to do with the default 'style' in the strip 
function. It's always there for numeric (shingle) variables. For 
factors, S-PLUS defaults to style=3, which shows the darker parts, 
while lattice default to style=1, which doesn't.

> Now I have one perplexity and one question:
>
> The last "list((1:4)[order(...." works fine, but it seems to me
> inelegant, too complicate and not practical for plots with more
> factors. Any suggestion to simplify/improve the matter?

As a matter of fact, I'm working on something like this for a future 
version of lattice. But in your example, where you know beforehand how 
your factor levels should be ordered, I think you should just define 
your factor properly. e.g.,

LOCATION = factor(rep(rep(c(5, 1, 3, 7), each=3), 2),
                  levels = c(1, 3, 5, 7), 
                  labels = c("there1%OM", "elsewhere3%OM", 
                             "here5%OM", "overthere7%OM"))

What's happening now is that LOCATION is defined as a character vector, 
which is eventually coerced to a factor with levels in the default (in 
this case undesirable) order. 

> How can I keep the tags in the strips, still ordering the panels by
> OM?

You need to add something like

  strip = function(..., style) strip.default(..., style = 3)

to your bwplot call.


> Thanks in advance.
>
> PS
> The following lines are copied from ?xyplot
> (I suspect that "order.cond" stands for "index.cond",
> since I cannot find it in any other page of the lattice help, nor in
> the general help)

You are right. I'll fix that.

Deepayan



From roebuck at odin.mdacc.tmc.edu  Mon Jul  5 22:00:53 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Mon, 5 Jul 2004 15:00:53 -0500 (CDT)
Subject: [R] contrib.url binary paths inconsistent
Message-ID: <Pine.OSF.4.58.0407051439230.212412@odin.mdacc.tmc.edu>

Binary distribution [Windows]
-----------------------------
> contrib.url(getOption("CRAN"))
[1] "http://cran.r-project.org/bin/windows/contrib/1.9"

Binary distribution [Mac OS X]
-----------------------------
> contrib.url(getOption("CRAN"), type = "mac.binary")
[1] "http://cran.r-project.org/bin/macosx/1.9"



Possible update for Mac OS X version:

contrib.url <-
function(CRAN, type = c("source", "mac.binary")) {
    type <- match.arg(type)
    ver <- paste(R.version$major,
                 substring(R.version$minor, 1, 1),
                 sep = ".")
    switch(type,
           source =     file.path(CRAN, "src", "contrib"),
           mac.binary = file.path(CRAN, "bin", "macosx", "contrib", ver))
}

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From vantini at mate.polimi.it  Mon Jul  5 22:22:31 2004
From: vantini at mate.polimi.it (Simone Vantini)
Date: Mon, 5 Jul 2004 22:22:31 +0200 (CEST)
Subject: [R] how to personalize split function in rpart
Message-ID: <17632.81.208.60.192.1089058951.squirrel@webmail.mate.polimi.it>


Hallo!
I am a student of the Politecnico di Milano (Milan, italy) and I'm working
on CARTs. I'm trying to use the R rpart function with a personalized splitfunction... but I'm not able  to do it!
More precisely, I would like to know what is the meaning of the function
'init', 'split' and 'eval' named in the help page.I can't find any answer
in 'Classification and regression trees' (Breiman, ...) , in 'Modern
applied statistics with S-plus' (Venables, Ripley) or even in the on-line
forum.Thank You very much
Simone Vantini



From ripley at stats.ox.ac.uk  Mon Jul  5 22:34:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jul 2004 21:34:23 +0100 (BST)
Subject: [R] how to personalize split function in rpart
In-Reply-To: <17632.81.208.60.192.1089058951.squirrel@webmail.mate.polimi.it>
Message-ID: <Pine.LNX.4.44.0407052125581.21324-100000@gannet.stats>

Have you looked at the package sources? Do read rpart/tests/usersplits.R.

On Mon, 5 Jul 2004, Simone Vantini wrote:

> I am a student of the Politecnico di Milano (Milan, italy) and I'm working
> on CARTs. I'm trying to use the R rpart function with a personalized splitfunction... but I'm not able  to do it!
> More precisely, I would like to know what is the meaning of the function
> 'init', 'split' and 'eval' named in the help page.I can't find any answer
> in 'Classification and regression trees' (Breiman, ...) , in 'Modern
> applied statistics with S-plus' (Venables, Ripley) or even in the on-line
> forum.Thank You very much

Those are not about rpart.  See the S original at

	http://www.mayo.edu/hsr/Sfunc.html

for some further details (in rpart/Manuscript/AddMethods, about adding 
C-level split functions).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Mon Jul  5 23:35:12 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 05 Jul 2004 23:35:12 +0200
Subject: [R] contrib.url binary paths inconsistent
In-Reply-To: <Pine.OSF.4.58.0407051439230.212412@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0407051439230.212412@odin.mdacc.tmc.edu>
Message-ID: <40E9C990.3010509@statistik.uni-dortmund.de>

Paul Roebuck wrote:

> Binary distribution [Windows]
> -----------------------------
> 
>>contrib.url(getOption("CRAN"))
> 
> [1] "http://cran.r-project.org/bin/windows/contrib/1.9"

Correct.


> Binary distribution [Mac OS X]
> -----------------------------
> 
>>contrib.url(getOption("CRAN"), type = "mac.binary")
> 
> [1] "http://cran.r-project.org/bin/macosx/1.9"

Correct. (In particular, there *must not* be .../contrib/... in the Mac 
version!)

Uwe Ligges


> 
> 
> Possible update for Mac OS X version:
> 
> contrib.url <-
> function(CRAN, type = c("source", "mac.binary")) {
>     type <- match.arg(type)
>     ver <- paste(R.version$major,
>                  substring(R.version$minor, 1, 1),
>                  sep = ".")
>     switch(type,
>            source =     file.path(CRAN, "src", "contrib"),
>            mac.binary = file.path(CRAN, "bin", "macosx", "contrib", ver))
> }
> 
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From f.duan at yale.edu  Mon Jul  5 23:46:40 2004
From: f.duan at yale.edu (F Duan)
Date: Mon, 05 Jul 2004 17:46:40 -0400
Subject: [R] How to check the code for generic function in a specific
	package?
Message-ID: <01LC40466EZ6001W4L@biomed.med.yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040705/29d4a479/attachment.pl

From ligges at statistik.uni-dortmund.de  Mon Jul  5 23:57:31 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 05 Jul 2004 23:57:31 +0200
Subject: [R] How to check the code for generic function in a specific
	package?
In-Reply-To: <01LC40466EZ6001W4L@biomed.med.yale.edu>
References: <01LC40466EZ6001W4L@biomed.med.yale.edu>
Message-ID: <40E9CECB.8090509@statistik.uni-dortmund.de>

F Duan wrote:

> Hello, R people,
> 
>  
> 
> I am a R beginner. I searched the R-FAQ and R-help and failed to find the
> answers. 
> 
>  
> 
> Could anyone tell me how to check (or edit) a generic function within a
> specific package? If the function is not generic, I can just type the
> function name at the R prompt or use "fix()" and "edit()".

fix() *does* work for me, giving you expect that the fucntion is not 
"fixed" within the package, but a new (changed) instance is created in 
your Workspace.....

What do you expect to happen? What is the error message (if there is any)?

In order to change packages, you might want to edit the package sources 
directly.

Uwe Ligges



>  
> 
> Thanks a lot.
> 
>  
> 
> Frank
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jeaneid at chass.utoronto.ca  Tue Jul  6 00:11:05 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 5 Jul 2004 18:11:05 -0400
Subject: [R] System memory
Message-ID: <Pine.SGI.4.40.0407051805030.25957489-100000@origin.chass.utoronto.ca>

Dear All,

I have been experiencing the following problem when I use a lot of system
memory when using R heavily.

Everytime I shutdown the process (Xemacs and ESS), my system remains slow
and sometime does  not respond. I use a debian testing machine. Even when
I shutdown (halt) the system, it will crash and on reboot it will check
the disk for errors.

I have also used gc() after I removed everything in the env. This did not
make a difference.

can someone guide me through a solution.


Thank you


Jean Eid
University of Toronto.



From MSchwartz at MedAnalytics.com  Tue Jul  6 01:08:34 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 05 Jul 2004 18:08:34 -0500
Subject: [R] counting the occurrences of vectors
In-Reply-To: <40E8A0B3.1050404@pdf.com>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
	<40E8A0B3.1050404@pdf.com>
Message-ID: <1089068914.10847.387.camel@localhost.localdomain>

On Sun, 2004-07-04 at 19:28, Spencer Graves wrote:
>       I see a case where "f1" gives the wrong answer: 
> 
>       b <- array(c("a:b", "a", "c", "b:c"), dim=c(2,2))
>       a <- b[c(1,1),]
> 
>       For these two matrices, f1(a,b) == c(2,2), while f2(a,b) == 
> c(2,0).  If b does not contain ":", e.g., if it is numeric, then this 
> pathology can not occur.  However, if "f1" is used with objects of class 
> character or string that could contain the "collapse" character, it 
> could give an incorrect answer without warning. 


Greetings,

After seeing Gabor and Spencer's replies, I of course realized that my
initial reply was not entirely what Ravi was looking for.  :-)

However, after seeing Spencer's example above, the thing that I also
noted was the likely overhead involved in paste()ing together the rows
to create objects that could then be tabulated. This is likely to become
more of an issue as the matrix size grows.

It came to me that with a modest modification to my initial function,
combined with Gabor's approach to tabulation, a new function could be
created that avoids the paste()ing overhead:

row.match.count <- function(m1, m2)
{
  if (ncol(m1) != (ncol(m2)))
    stop("Matrices must have the same number of columns")

  if (typeof(m1) != (typeof(m2)))
    stop("Matrices must have the same data type")

  m1.l <- as.character(apply(m1, 1, list))
  m2.l <- as.character(apply(m2 ,1, list))

  # return counts for each row in m1.l in m2.l
  table(c(unique(m1.l), m2.l))[m1.l] - 1
}


Using Gabor's original two matrices:

set.seed(1)
a <- matrix(sample(3,1000,rep=T),nc=5)
b <- matrix(sample(3,100,rep=T),nc=5)

We can then do (Count rows from 'b' in 'a'):

> gc(); system.time(ans <- row.match.count(b, a))
         used (Mb) gc trigger (Mb)
Ncells 541226 14.5     741108 19.8
Vcells 141364  1.1     786432  6.0
[1] 0.01 0.00 0.00 0.00 0.00



Now...the downside to this approach is that the actual output of the
function, due to the coercion, is a wee bit ugly (OK, more than a wee
bit...)

For example, using Spencer's two matrices above, we get:

b <- array(c("a:b", "a", "c", "b:c"), dim=c(2,2))
a <- b[c(1,1),]

> row.match.count(b, a)

list(c("a:b", "c")) list(c("a", "b:c")) 
                  2                   0 


Go back to my two matrices:

> m <- matrix(1:20, ncol = 4, byrow = TRUE)
> n <- matrix(1:40, ncol = 4, byrow = TRUE)

> row.match.count(m, n)

    list(as.integer(c(1, 2, 3, 4)))     list(as.integer(c(5, 6, 7, 8))) 
                                  1                                   1 
 list(as.integer(c(9, 10, 11, 12))) list(as.integer(c(13, 14, 15, 16))) 
                                  1                                   1 
list(as.integer(c(17, 18, 19, 20))) 
                                  1 



So, since we have a few extra CPU cycles to use, we could include some
sub()s to clean up the names in the resultant table:


row.match.count <- function(m1, m2)
{
  if (ncol(m1) != (ncol(m2)))
    stop("Matrices must have the same number of columns")

  if (typeof(m1) != (typeof(m2)))
    stop("Matrices must have the same data type")

  m1.l <- as.character(apply(m1, 1, list))
  m2.l <- as.character(apply(m2 ,1, list))

  # return counts for each m1.l in m2.l
  match.table <- table(c(unique(m1.l), m2.l))[m1.l] - 1

  # clean up table names
  if (typeof(m1) == "integer")
  {
    names(match.table) <- sub("^list\\(as.integer\\(", "", 
                              names(match.table))
    names(match.table) <- sub("\\)\\)$", "", names(match.table))
  }
  else if (typeof(m1) == "character")
  {
    names(match.table) <- sub("^list\\(", "", names(match.table))
    names(match.table) <- sub("\\)$", "", names(match.table))
  }

  match.table
}


Somebody with more regex insight than I could probably clean up the
latter part of the function, but it seems to work well.

That being said, we now get:

> row.match.count(m, n)
    c(1, 2, 3, 4)     c(5, 6, 7, 8)  c(9, 10, 11, 12) c(13, 14, 15, 16) 
                1                 1                 1                 1 
c(17, 18, 19, 20) 
                1 

and

> row.match.count(b, a)
c("a:b", "c") c("a", "b:c") 
            2             0 


Going back to Gabor's original two matrices, the addition of the names
clean up does not seem to add much overhead:

set.seed(1)
a <- matrix(sample(3,2000,rep=T),nc=10)
b <- matrix(sample(3,200,rep=T),nc=10)

> gc(); system.time(ans <- row.match.count(b, a))
         used (Mb) gc trigger (Mb)
Ncells 541243 14.5     818163 21.9
Vcells 140464  1.1     786432  6.0
[1] 0.01 0.00 0.01 0.00 0.00

> ans
c(2, 1, 1, 1, 2) c(3, 3, 1, 3, 2) c(2, 1, 2, 3, 2) c(3, 3, 2, 1, 1) 
               1                1                3                1 
c(1, 1, 1, 2, 3) c(1, 3, 2, 3, 3) c(2, 2, 2, 1, 2) c(2, 1, 1, 1, 1) 
               2                0                0                0 
c(3, 2, 2, 3, 3) c(2, 3, 3, 2, 2) c(3, 2, 1, 1, 2) c(2, 2, 2, 1, 3) 
               2                1                0                2 
c(1, 2, 2, 2, 1) c(3, 3, 3, 2, 1) c(2, 2, 3, 3, 3) c(3, 1, 1, 2, 3) 
               1                0                3                1 
c(3, 2, 3, 3, 1) c(1, 2, 2, 1, 2) c(1, 3, 2, 2, 2) c(1, 1, 1, 2, 3) 
               0                1                0                2 


I'd be curious to get any feedback on this and if someone has any
thoughts on any gotchas with this approach.

Thanks and I hope that this is of some help.

Marc Schwartz



From jasont at indigoindustrial.co.nz  Tue Jul  6 03:04:23 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 6 Jul 2004 13:04:23 +1200 (NZST)
Subject: [R] System memory
In-Reply-To: <Pine.SGI.4.40.0407051805030.25957489-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0407051805030.25957489-100000@origin.chass.utoronto.ca>
Message-ID: <35542.203.9.176.60.1089075863.squirrel@webmail.maxnet.co.nz>

> Dear All,
>
> I have been experiencing the following problem when I use a lot of system
> memory when using R heavily.
...
What version of R, Xemacs, ESS, and Debian?  What are the "crash" symptoms
(error message?).  Have you tried upgrading everything you can (ESS has
recently released a new stable (5.2.x) version).

As a possible item to check, run

ps ajx | grep R

from a terminal after you exit R from within ESS.  On my Win XP box, I've
found that R sometimes fails to exit cleanly after a q("no"), and remains
running after ESS has tried to disengage.  The ESS "*R*" buffer remains
hung, and Rterm's user CPU usage goes to about 98%.  Killing R from the
task manager stopped this.  The same might (might!) be an issue under
Debian, and killing it from the command line might help.

Cheers

Jason



From ggrothendieck at myway.com  Tue Jul  6 05:01:59 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 6 Jul 2004 03:01:59 +0000 (UTC)
Subject: [R] counting the occurrences of vectors
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
	<40E8A0B3.1050404@pdf.com>
	<1089068914.10847.387.camel@localhost.localdomain>
Message-ID: <loom.20040706T050013-906@post.gmane.org>

Marc Schwartz <MSchwartz <at> MedAnalytics.com> writes:
 
> row.match.count <- function(m1, m2)
> {
>   if (ncol(m1) != (ncol(m2)))
>     stop("Matrices must have the same number of columns")
> 
>   if (typeof(m1) != (typeof(m2)))
>     stop("Matrices must have the same data type")
> 
>   m1.l <- as.character(apply(m1, 1, list))
>   m2.l <- as.character(apply(m2 ,1, list))
> 
>   # return counts for each m1.l in m2.l
>   match.table <- table(c(unique(m1.l), m2.l))[m1.l] - 1
> 
>   # clean up table names
>   if (typeof(m1) == "integer")
>   {
>     names(match.table) <- sub("^list\\(as.integer\\(", "", 
>                               names(match.table))
>     names(match.table) <- sub("\\)\\)$", "", names(match.table))
>   }
>   else if (typeof(m1) == "character")
>   {
>     names(match.table) <- sub("^list\\(", "", names(match.table))
>     names(match.table) <- sub("\\)$", "", names(match.table))
>   }
> 
>   match.table
> }

One could still make use of your as.character(apply(m1,1,list)) idea
without the type-specific processing by using the original paste idea
on the answer name vector rather than on m1 and m2. Also, adding 
sep = ":" to the arg list to let the user override it in the
event that : appears in the data and making some other cosmetic changes,
we have:

row.match.count.2 <- function(m1, m2, sep = ":") {

	stopifnot(ncol(m1) == ncol(m2), typeof(m1) == typeof(m2))

	m1 <- as.character(apply(m1, 1, list))
	m2 <- as.character(apply(m2 ,1, list))

	ans <- c(table(c(unique(m1), m2))[m1] - 1)

	f <- function(x)paste(eval(parse(text=x))[[1]], collapse=sep)
	names(ans) <- sapply(names(ans),f)
	
	ans
}

This does not run as fast as row.match.count but its faster than
f1 and it avoids the potentially problematic type-specific regex
name mangling portion of row.match.count.



From lauraholt_983 at hotmail.com  Tue Jul  6 05:39:48 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Mon, 05 Jul 2004 22:39:48 -0500
Subject: [R] What precision is R
Message-ID: <BAY12-F35ue4zBMQTTh0001bf4b@hotmail.com>

Hello R People:

What precision is R, please?  64 bit?

Where would I find that out typically, please?

Thanks in advance!

Sincerely,
Laura Holt
mailto: lauraholt_983 at hotmail.com


FREE! http://join.msn.click-url.com/go/onm00200361ave/direct/01/



From ggrothendieck at myway.com  Tue Jul  6 06:22:22 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 6 Jul 2004 04:22:22 +0000 (UTC)
Subject: [R] counting the occurrences of vectors
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
	<40E8A0B3.1050404@pdf.com>
	<1089068914.10847.387.camel@localhost.localdomain>
Message-ID: <loom.20040706T060536-976@post.gmane.org>

Marc Schwartz <MSchwartz <at> MedAnalytics.com> writes:

> the likely overhead involved in paste()ing together the rows
> to create objects 


I thought I would check this and it seems that in my original f1 function 
its not really the paste itself that's the bottleneck but applying the 
paste.  If we use do.call rather than apply, as shown in f1a below, then 
we see that f1a runs faster than row.match.count (which in turn was faster
than f1):

f1a <- function(a,b,sep=":") {
	f <- function(...) paste(..., sep=sep)
	a2 <- do.call("f", as.data.frame(a))
	b2 <- do.call("f", as.data.frame(b))
	c(table(c(b2,unique(a2)))[a2] - 1)
}

> set.seed(1)
> # note that we have increased the size of the matrices from last post
> # to better show the speed difference
> a <- matrix(sample(3,10000,rep=T),nc=5)
> b <- matrix(sample(3,1000,rep=T),nc=5)

> # row.match.count taken from Marc's post in this thread
> # have put a c(...) around row.match.count to make it comparable to f1a
> gc(); system.time(ans <- c(row.match.count(b,a)))
         used (Mb) gc trigger (Mb)
Ncells 436079 11.7     741108 19.8
Vcells 130663  1.0     786432  6.0
[1] 0.11 0.00 0.11   NA   NA

> gc(); system.time(ansf1a <- f1a(b,a))
         used (Mb) gc trigger (Mb)
Ncells 436080 11.7     741108 19.8
Vcells 130669  1.0     786432  6.0
[1] 0.04 0.00 0.04   NA   NA

> all.equal(ansf1a,ans)
[1] TRUE
>



From ripley at stats.ox.ac.uk  Tue Jul  6 07:50:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Jul 2004 06:50:48 +0100 (BST)
Subject: [R] What precision is R
In-Reply-To: <BAY12-F35ue4zBMQTTh0001bf4b@hotmail.com>
Message-ID: <Pine.LNX.4.44.0407060639590.22023-100000@gannet.stats>

On Mon, 5 Jul 2004, Laura Holt wrote:

> What precision is R, please?  64 bit?

Your question lacks precision :)

R uses the underlying double precision floating-point arithmetic of the OS
it is running on.  On all currrent platforms that we know of, that is
IEC60566 arithmetic, with an (implicit) 53-bit mantissa.

So floating-point operations have double precision, usually with around 53
bits of accuracy.

> Where would I find that out typically, please?

Type ?.Machine, then print(.Machine).

One complication on machines with extended-precision registers (and since 
that includes the ix86 family, that is most of them) is that some 
calculations are done with a 64-bit mantissa and finally stored with a 
53-bit mantissa.  Those may turn out to be more accurate than your expect 
(which makes measuring accuracy difficult).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vito_ricci at yahoo.com  Tue Jul  6 09:20:42 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Tue, 6 Jul 2004 09:20:42 +0200 (CEST)
Subject: [R] R & DataMining
Message-ID: <20040706072042.63879.qmail@web41206.mail.yahoo.com>

Dear R-user,

I wish to know if someone is using R as concern
Datamining or KDD (Knowledge Discovery in Database)
and if already exists a R package specialized in this
kind of analysis. 
I found this contributes on the R web site:

[20] 	Diego Kuonen. Introduction au data mining avec R
: vers la reconqu??te du `knowledge discovery in
databases' par les statisticiens. Bulletin of the
Swiss Statistical Society, 40:3-7, 2001.
[ bib |
http://www.statoo.com/en/publications/2001.R.SSS.40/ ]
[21] 	Diego Kuonen and Reinhard Furrer. Data mining
avec R dans un monde libre. Flash Informatique Sp??cial
??t??, pages 45-50, sep 2001.
[ bib |
http://sawww.epfl.ch/SIC/SA/publications/FI01/fi-sp-1/sp-1-page45.html
]

Brian D. Ripley
http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Ripley.pdf

Could be R an usefull tool for dataming?
Thanks.
Yours,
Vito Ricci

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From wuertz at itp.phys.ethz.ch  Tue Jul  6 09:50:52 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 06 Jul 2004 07:50:52 +0000
Subject: [R] Download Info
Message-ID: <40EA59DC.3020808@itp.phys.ethz.ch>

Maybe somebody can help me with the following questions:

I have submitted Rmetrics to the CRAN server and was looking what happened.

1)  The */contrib/checkSummary.html shows a table which reports the 
daily package check results.
For my packages there is no entry in the column "r-devel", the other 
packages have "OK" or "WARN".
What does it mean?

2) The link to the Mac OSX check summaryseems to be broken?
The requested URL /bin/macosx/r-devel/check/checkSummaryOSX.html was not 
found on this server.
So I couldn't check why one of the packages (fSeries) is missing in the 
MacOSX  binary package
directory.

3)  For other packages, e.g. for "gbm", on the package download page 
there are

Package source: 	gbm_1.2.tar.gz <../gbm_1.2.tar.gz>
MacOS X binary: 	gbm_1.1-2.tgz 
<../../../bin/macosx/r-release/gbm_1.1-2.tgz>
Windows binary: 	gbm_1.2.zip 
<../../../bin/windows/contrib/r-release/gbm_1.2.zip>
Index of contents: 	gbm.INDEX
Reference manual: 	gbm.pdf <../../../doc/packages/gbm.pdf>


In my case there are only the "Package source" file and the "Reference 
manual" link. What I have to do
that also the other links appear on this page?


Many thanks in advance Diethelm



From Giovanni_Millo at generali.com  Tue Jul  6 10:04:08 2004
From: Giovanni_Millo at generali.com (Millo Giovanni)
Date: Tue, 6 Jul 2004 10:04:08 +0200
Subject: [R] Model frame manipulation
Message-ID: <74F2D4ED68558643B63A6CC21746040D9A07CE@BEMAILEXTS1.ad.generali.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040706/4d7634c3/attachment.pl

From Friedrich.Leisch at tuwien.ac.at  Tue Jul  6 10:11:19 2004
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Tue, 6 Jul 2004 10:11:19 +0200
Subject: [R] Apparent conflict between \Sexpr in Sweave and R2HTML
In-Reply-To: <200407051608.i65G8ck23686@snow.pnl.gov>
References: <200407051608.i65G8ck23686@snow.pnl.gov>
Message-ID: <16618.24231.759887.86339@galadriel.ci.tuwien.ac.at>

>>>>> On Mon, 05 Jul 2004 09:08:38 -0700,
>>>>> Scott Waichler (SW) wrote:

  > I have come across an apparent bug in the operation of Sweave.  If I
  > load the package R2HTML then execution of \Sexpr{} in an *.Rnw file no
  > longer works.  The \Sexpr{} code is simply written to the *.tex file.
  > Below are my *.Rnw file, commands, and output.  

R2HTML registers another Sweave driver for HTML files, and after that
the Syntax for HTML is in the search list before the default syntax.

	options(SweaveSyntax="SweaveSyntaxNoweb")

or calling Sweave like

	Sweave(..., syntax="SweaveSyntaxNoweb")

should do the trick.  I'll add this to the Sweave FAQ.

Best,
Fritz



From ernesto at ipimar.pt  Tue Jul  6 11:03:24 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 06 Jul 2004 10:03:24 +0100
Subject: [R] R & DataMining
In-Reply-To: <20040706072042.63879.qmail@web41206.mail.yahoo.com>
References: <20040706072042.63879.qmail@web41206.mail.yahoo.com>
Message-ID: <1089104603.17473.1.camel@gandalf.local>

On Tue, 2004-07-06 at 08:20, Vito Ricci wrote:
> Dear R-user,
> 
> I wish to know if someone is using R as concern
> Datamining or KDD (Knowledge Discovery in Database)
> and if already exists a R package specialized in this
> kind of analysis. 
> I found this contributes on the R web site:
> 
> [20] 	Diego Kuonen. Introduction au data mining avec R
> : vers la reconqu??te du `knowledge discovery in
> databases' par les statisticiens. Bulletin of the
> Swiss Statistical Society, 40:3-7, 2001.
> [ bib |
> http://www.statoo.com/en/publications/2001.R.SSS.40/ ]
> [21] 	Diego Kuonen and Reinhard Furrer. Data mining
> avec R dans un monde libre. Flash Informatique Sp??cial
> ??t??, pages 45-50, sep 2001.
> [ bib |
> http://sawww.epfl.ch/SIC/SA/publications/FI01/fi-sp-1/sp-1-page45.html
> ]
> 
> Brian D. Ripley
> http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Ripley.pdf
> 
> Could be R an usefull tool for dataming?
> Thanks.
> Yours,
> Vito Ricci

Hi,

I've been reading "Data Mining with R" by Luis Torgo and I found it
usefull. Check

http://www.liacc.up.pt/~ltorgo/DataMiningWithR/

Regards

EJ



From ernesto at ipimar.pt  Tue Jul  6 11:09:12 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 06 Jul 2004 10:09:12 +0100
Subject: [R] useR! presentation on "Generic functions for spatial data"
Message-ID: <1089104952.17471.4.camel@gandalf.local>

Hi,

If one of the authors (Roger Bivand, Edzer Pebesma and Barry Rowlingson)
see this message, can you please send me the presentation.

Thanks 

EJ



From thchung at tgen.org  Tue Jul  6 11:12:19 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Tue, 6 Jul 2004 02:12:19 -0700
Subject: [R] ESS does not recognize installed libraries
Message-ID: <95326388-CF2C-11D8-978F-000A95B43CDE@tgen.org>

Hi, all. Something strange happened to my ESS.

I use Mac OS X. When R is used in stand alone mode, it recognizes 
external libraries like "affy", "e1071" etc.
However, when R is invoked through ESS in Emacs, it produces errors 
like:
Error in library(affy) : There is no package called 'affy'
Interestingly, I remember I successfully used these libraries through 
ESS in Emacs before.
I became unable to use these libraries at one moment but I don't recall 
anything strange happened before that.
This kind of strange thing happened sometimes to my R.
In those cases, things restored smoothly when the system is restarted.
However, this time, this trick does not work.

Thanks in advance
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From a.prioglio at city.ac.uk  Tue Jul  6 11:27:41 2004
From: a.prioglio at city.ac.uk (a.prioglio@city.ac.uk)
Date: Tue, 6 Jul 2004 10:27:41 +0100
Subject: [R] What is a sane way to deal with changes in library loadings
	after 1.9.0?
In-Reply-To: <Pine.LNX.4.44.0407051351140.20516-100000@gannet.stats>
References: <20040705121008.GB6439@anaconda.dogbert.ntt.it>
	<Pine.LNX.4.44.0407051351140.20516-100000@gannet.stats>
Message-ID: <20040706092741.GC6439@anaconda.dogbert.ntt.it>

On Mon, Jul 05, 2004 at 01:55:34PM +0100, Prof Brian Ripley wrote:
> Your confusion is that you are trying to run scripts from .First.
> You did not say so, and that is strongly not recommended, especially if 
> they might have errors.
My apologies for not making it clear, I was under the impression that
this was a rather "standard" way of running scripts.

> 
> Use R CMD BATCH to run scripts and you will find it much easier.
> 
Well, not really as now error messages do not seem to reflect line
numbers any more, e.g. I get a complaint about the presence
(broken pipe) of a cat() statement at a line number no way near
any cat() statemnt.

BTW, does this imply that when running in batch mode there is no
connection to standard output? Can this be overcome?



From maechler at stat.math.ethz.ch  Tue Jul  6 11:44:04 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 6 Jul 2004 11:44:04 +0200
Subject: [R] Mailing Lists: Timeout today GMT 18--19.30
Message-ID: <16618.29796.913220.990027@gargle.gargle.HOWL>

Because of installation of a new disk server system,
unfortunately, our mail server has to timeout for about 90
minutes this (local time) evening.

Hoping that it won't be longer than 90 minutes,
I'll give the timeout intervals in some time zones:

CEST	     20.00--21.30
UTC aka GMT  18.00--19.30
US East	     14.00--15.30
US West	     11.00--12.30
OZ...(?)     04.00--05.30
NZST	     06.00--07.30

--------

We know this will be a small of problem (particularly for the
Americans), but this seems inevitable, and should lead to an
hopefully even more stable server enviroment for the mailing
lists.

Martin Maechler, ETH Zurich, Switzerland



From sdavis2 at mail.nih.gov  Tue Jul  6 11:58:09 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 06 Jul 2004 05:58:09 -0400
Subject: [R] ESS does not recognize installed libraries
In-Reply-To: <95326388-CF2C-11D8-978F-000A95B43CDE@tgen.org>
Message-ID: <BD0FEFF1.A668%sdavis2@mail.nih.gov>

Are you sure that the R executable is the same when used "stand-alone" and
in ESS?  

Sean

On 7/6/04 5:12 AM, "Tae-Hoon Chung" <thchung at tgen.org> wrote:

> Hi, all. Something strange happened to my ESS.
> 
> I use Mac OS X. When R is used in stand alone mode, it recognizes
> external libraries like "affy", "e1071" etc.
> However, when R is invoked through ESS in Emacs, it produces errors
> like:
> Error in library(affy) : There is no package called 'affy'
> Interestingly, I remember I successfully used these libraries through
> ESS in Emacs before.
> I became unable to use these libraries at one moment but I don't recall
> anything strange happened before that.
> This kind of strange thing happened sometimes to my R.
> In those cases, things restored smoothly when the system is restarted.
> However, this time, this trick does not work.
> 
> Thanks in advance
> Tae-Hoon Chung, Ph.D
> 
> Post-doctoral Research Fellow
> Molecular Diagnostics and Target Validation Division
> Translational Genomics Research Institute
> 1275 W Washington St, Tempe AZ 85281 USA
> Phone: 602-343-8724
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From thchung at tgen.org  Tue Jul  6 12:04:52 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Tue, 6 Jul 2004 03:04:52 -0700
Subject: [R] ESS does not recognize installed libraries
In-Reply-To: <BD0FEFF1.A668%sdavis2@mail.nih.gov>
References: <BD0FEFF1.A668%sdavis2@mail.nih.gov>
Message-ID: <ECA1054B-CF33-11D8-B6A0-000A95B43CDE@tgen.org>

Hi, Sean.
For this part, I am not quite sure because I don't know how internal 
implementation of ESS handles R under Emacs.
It is definitely a possibility that stand-alone version of R and 
ESS-version of R can use a little bit different library paths.
However, I don't think R program itself is different between 
stand-alone version and ESS-version.

Tae-Hoon

On Jul 6, 2004, at 2:58 AM, Sean Davis wrote:

> Are you sure that the R executable is the same when used "stand-alone" 
> and
> in ESS?
>
> Sean
>
> On 7/6/04 5:12 AM, "Tae-Hoon Chung" <thchung at tgen.org> wrote:
>
>> Hi, all. Something strange happened to my ESS.
>>
>> I use Mac OS X. When R is used in stand alone mode, it recognizes
>> external libraries like "affy", "e1071" etc.
>> However, when R is invoked through ESS in Emacs, it produces errors
>> like:
>> Error in library(affy) : There is no package called 'affy'
>> Interestingly, I remember I successfully used these libraries through
>> ESS in Emacs before.
>> I became unable to use these libraries at one moment but I don't 
>> recall
>> anything strange happened before that.
>> This kind of strange thing happened sometimes to my R.
>> In those cases, things restored smoothly when the system is restarted.
>> However, this time, this trick does not work.
>>
>> Thanks in advance
>> Tae-Hoon Chung, Ph.D
>>
>> Post-doctoral Research Fellow
>> Molecular Diagnostics and Target Validation Division
>> Translational Genomics Research Institute
>> 1275 W Washington St, Tempe AZ 85281 USA
>> Phone: 602-343-8724
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>
>
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From ramasamy at cancer.org.uk  Tue Jul  6 12:04:59 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 06 Jul 2004 11:04:59 +0100
Subject: [R] ESS does not recognize installed libraries
In-Reply-To: <95326388-CF2C-11D8-978F-000A95B43CDE@tgen.org>
References: <95326388-CF2C-11D8-978F-000A95B43CDE@tgen.org>
Message-ID: <1089108265.3036.14.camel@vpn202001.lif.icnet.uk>

Do you by any chance have multiple versions of R installed ? The first
two lines of the header in the iESS buffer should give a clue. Example :

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3

How does that compare to the header in your terminal/standalone mode. If
different, then you may have to set your global path to R correctly.

Other than that, it could be that some of your library paths are
missing. Try '.find.package("affy")' on your terminal. See if this path
is included in '.libPaths()' on your emacs/ESS interface.


On Tue, 2004-07-06 at 10:12, Tae-Hoon Chung wrote:
> Hi, all. Something strange happened to my ESS.
> 
> I use Mac OS X. When R is used in stand alone mode, it recognizes 
> external libraries like "affy", "e1071" etc.
> However, when R is invoked through ESS in Emacs, it produces errors 
> like:
> Error in library(affy) : There is no package called 'affy'
> Interestingly, I remember I successfully used these libraries through 
> ESS in Emacs before.
> I became unable to use these libraries at one moment but I don't recall 
> anything strange happened before that.
> This kind of strange thing happened sometimes to my R.
> In those cases, things restored smoothly when the system is restarted.
> However, this time, this trick does not work.
> 
> Thanks in advance
> Tae-Hoon Chung, Ph.D
> 
> Post-doctoral Research Fellow
> Molecular Diagnostics and Target Validation Division
> Translational Genomics Research Institute
> 1275 W Washington St, Tempe AZ 85281 USA
> Phone: 602-343-8724
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Matthias.Kohl at uni-bayreuth.de  Tue Jul  6 13:17:28 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Tue, 06 Jul 2004 12:17:28 +0100
Subject: [R] questions about setMethod("Arith", ...)
Message-ID: <40EA8A48.3030708@uni-bayreuth.de>

Hi,

we have some questions concerning the definition of new arithmetic methods.

In our package "distr" (on CRAN) we define some new arithmetic methods 
for "+", "-", "*", "/".
After loading "distr" the corresponding arithmetic methods work. Now, if 
we define a new
class and also a new method for one of the arithmetic methods "+", "-", 
"*", "/", still everything works fine. But, if we then define new 
methods for the whole group "Arith", the arithmetic methods of "distr" 
no longer work. (for more details see example code below)
What are we missing?

Moreover, there is a certain precendence; i.e., if one defines a single 
arithmetic method (e.g., "/") and alterwards defines a method for the 
whole group "Arith", the "old" method "/" remains valid. 
However, if we first define a method for the whole group "Arith" and 
afterwards define a new single arithmetic method (e.g., "+") the new one 
is valid. (for more details see example code below).
Is this intended?

Thanks for your help,
Matthias, Thomas

###########################################################
## Example code
###########################################################
require(distr)
getMethods("/")  # shows the corresponding methods of "distr"

## now define a new class "track" (see Chambers (1998))
## and define "/"

setClass("track", representation(x = "numeric", y = "numeric"))
setMethod("/", signature("track", "numeric"),
          function(e1, e2){ e1 at y = e1 at y/e2; e1 })

getMethods("/")  # shows the corresponding methods 
		 # of "distr" and class "track"

(N <- Norm()) # creates an object of standard normal distribution
(N1 <- N/3) # works
(tr <- new("track", x = 1:3, y = 4:6))
(tr1 <- tr/3) # works

## now define new methods for "Arith"
setMethod("Arith", signature("track", "numeric"),
          function(e1, e2){ 
	    e1 at x = callGeneric(e1 at x, e2)
	    e1
	  })

getMethods("/") # "/" for "distr" is lost
N2 <- N/3 # fails
(tr2 <- tr/3) # works, "but" still the "old" method
tr + 2 # works

## now a new method "+"
setMethod("+", signature("track", "numeric"),
          function(e1, e2){ e1 at y = e1 at y+e2; e1 })

tr + 2 # works, "but" with the "new" method



From hughes_sj at hotmail.com  Tue Jul  6 12:33:27 2004
From: hughes_sj at hotmail.com (louis marchand)
Date: Tue, 06 Jul 2004 10:33:27 +0000
Subject: [R] aide pour une affiner une AFD.
Message-ID: <BAY2-F29h74VaxC7TJu0009229e@hotmail.com>

madame, monsieur,  help me please,

Je debute avec R. J'ai r??alis?? une analyse factorielle discriminante avec R. 
J'obtient les resultat graphiques et les tables assici??es ?? l'analyse. 
Cependant je souhaiterais savoir si les distances separant les groupes 
(decades) sont statistiquement significatives. pour cela il me faut utiliser 
la distance de mahalanobis et la statistique de Wilks mais:
<<je n'arrive pas ?? obtenir la table de mahalanobis, ainsi que la 
statistique de wilks.
Pouvez-vous, s'il vous plait, m'indiquer la demarche ?? suivre pour y 
parvenir.
Sachant que meme avec l'aide de R je n'y arrive pas.
Merci.

ps: ce sont les decades que j'essaye de discriminer avec des variables 
quantitatives.
Je vous joints mon fichier de donn??es.

message de hugues santin-janin (06-72-46-09-71)
Institut m??diterann??en du patrimoine cynegetique et faunistique



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: donn?es pigeon.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040706/78283074/iso-8859-1BZG9ubullcyBwaWdlb24udHh0.txt

From Colin.Bleay at bristol.ac.uk  Tue Jul  6 13:53:40 2004
From: Colin.Bleay at bristol.ac.uk (CR Bleay, School Biological Sciences)
Date: Tue, 06 Jul 2004 12:53:40 +0100
Subject: [R] Re: errors in randomization test
In-Reply-To: <BD0FEFF1.A668%sdavis2@mail.nih.gov>
References: <BD0FEFF1.A668%sdavis2@mail.nih.gov>
Message-ID: <1175571.1089118420@bio-colinbleaymac.bio.bris.ac.uk>


hello all,

last week i sent an e-mail about dealing with errors thrown up from a 
glm.nb model carried out on multiple random datasets.

every so often a dataset is created which results in the following error 
after a call to glm.nb:

"Error: NA/NaN/Inf in foreign function call (arg 1)
In addition: Warning message:
Step size truncated due to divergence"


I am at a loss as to how to deal with this.

firstly because the dataset that is generated, although throwing an error 
when the glm.nb model is applied, is a valid dataset. so how do i 
incorporate this dataset in my results (results being descriptive stats on 
the coefficients from the multiple datasets) i.e. shoould coefficients be 
set to zero?

secondly, how do i capture and deal with the error. is it possible to 
construct an "if" statement so that "if error, do this, if not continue"

lastly, i am unsure as to what characteristics of a dataset would result in 
these errors in the glm.nb?

i would be very grateful for any assistance on this matter. i having been 
staring at code for too many days now and so can't see the wood for the 
trees.


cheers,

colin
----------------------
Dr Colin Bleay
Dept. Biological Sciences,
University of Bristol,
Woodlands rd.,
Bristol,
BS8 1UG.
UK

Tel: 44 (0)117 928 7470
Fax: 44 (0)117



From p.dalgaard at biostat.ku.dk  Tue Jul  6 14:13:07 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Jul 2004 14:13:07 +0200
Subject: [R] Re: errors in randomization test
In-Reply-To: <1175571.1089118420@bio-colinbleaymac.bio.bris.ac.uk>
References: <BD0FEFF1.A668%sdavis2@mail.nih.gov>
	<1175571.1089118420@bio-colinbleaymac.bio.bris.ac.uk>
Message-ID: <x24qol9vvw.fsf@biostat.ku.dk>

"CR Bleay, School Biological Sciences" <Colin.Bleay at bristol.ac.uk> writes:

> hello all,
> 
> last week i sent an e-mail about dealing with errors thrown up from a
> glm.nb model carried out on multiple random datasets.
> 
> every so often a dataset is created which results in the following
> error after a call to glm.nb:
> 
> "Error: NA/NaN/Inf in foreign function call (arg 1)
> In addition: Warning message:
> Step size truncated due to divergence"
> 
> 
> I am at a loss as to how to deal with this.
> 
> firstly because the dataset that is generated, although throwing an
> error when the glm.nb model is applied, is a valid dataset. so how do
> i incorporate this dataset in my results (results being descriptive
> stats on the coefficients from the multiple datasets) i.e. shoould
> coefficients be set to zero?

NA, more likely, but it's not easy to say in general. If the algorithm
diverged in a particular way, setting diverged parameters to Inf or
-Inf might be a better idea. It is of course, quite normal that the
MLE does not exist for some data sets, although perhaps the algorithm
might have failed more gracefully. 

> secondly, how do i capture and deal with the error. is it possible to
> construct an "if" statement so that "if error, do this, if not
> continue"
> 
> lastly, i am unsure as to what characteristics of a dataset would
> result in these errors in the glm.nb?
> 
> i would be very grateful for any assistance on this matter. i having
> been staring at code for too many days now and so can't see the wood
> for the trees.
> 

Look at try() 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rolf at math.unb.ca  Tue Jul  6 14:23:59 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 6 Jul 2004 09:23:59 -0300 (ADT)
Subject: [R] Re: errors in randomization test
Message-ID: <200407061223.i66CNxXq029138@erdos.math.unb.ca>

Colin Bleay wrote:

> last week i sent an e-mail about dealing with errors thrown up from a 
> glm.nb model carried out on multiple random datasets.
> 
> every so often a dataset is created which results in the following error 
> after a call to glm.nb:
> 
> "Error: NA/NaN/Inf in foreign function call (arg 1)
> In addition: Warning message:
> Step size truncated due to divergence"
> 
> 
> I am at a loss as to how to deal with this.
> 
> firstly because the dataset that is generated, although throwing an error 
> when the glm.nb model is applied, is a valid dataset. so how do i 
> incorporate this dataset in my results (results being descriptive stats on 
> the coefficients from the multiple datasets) i.e. shoould coefficients be 
> set to zero?

	Almost surely, setting the coefficients equal to 0 is the
	wrong thing to do.  What the right thing is depends on the
	answer to ``lastly''.

	Setting the coefficients to be NA in this case (i.e.
	effectively throwing away such cases) is also wrong, but not
	quite as wrong as setting them equal to 0.

> secondly, how do i capture and deal with the error. is it possible to 
> construct an "if" statement so that "if error, do this, if not continue"

	This should be do-able using try().  Something like:

	c.list <- list()
	save.bummers <- list()
	K <- 0
	for(i in 1:42) {
		repeat {
			X <- generate.random.data.set()
			Y <- try(glm.nb(X,whatever))
			if(inherits(Y,"try-error")) {
				K <- K+1
				save.bummers[[K]] <- X
			} else break
		}
		c.list[[i]] <- coeff(Y)
	}

	This should give you a sample of 42 coefficient vectors from
	the ``successful'' data sets, and a list of all the (a random
	number of) data sets that yielded a lack of success.  You can
	then take the data sets stored in save.bummers and experiment
	with them to see what is causing the problem.

> lastly, i am unsure as to what characteristics of a dataset would result in 
> these errors in the glm.nb?

	Here I have to heed the advice (attributed to a ``great art
	historian'') from George F. Simmons' wonderful book on
	elementary differential equations:  ``A fool he who gives
	more than he has.''

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From andy_liaw at merck.com  Tue Jul  6 14:33:20 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jul 2004 08:33:20 -0400
Subject: [R] More difficulties in getting data into R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FD0@usrymx25.merck.com>

Could it be that you happen you have `#' in `col4'?  Try either (or both):

1. read.table(..., comment.char="")
2. scan(...)

HTH,
Andy

> From: Ajay Shah
> 
> In order to get around the problems of my posting a few minutes ago, I
> thought:
> 
> $ awk -F\| '(NR > 2) {print $2}' cmie_firm_data.text > col2
> $ awk -F\| '(NR > 2) {print $4}' cmie_firm_data.text > col4
> $ paste col2 col4 | head -2
> -510.45 -510.27
> 60700   101900
> $ paste col2 col4 | tail -2
> 28648.12        31617.02
> 491014.77       494308.52
> $ wc -l col2 col4
>   89323 col2
>   89323 col4
>  178646 total
> 
> So all is well.
> 
> But R doesn't like it:
> 
> $ R --vanilla < picture.R 
> 
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3
> 
> > col2 <- read.table(file="col2")
> > col4 <- read.table(file="col4")
> > print(nrow(col2))
> [1] 89323
> > print(nrow(col4))
> [1] 88746
> 
> Why might I be getting 89,323 and 88,746 obs for two files which `wc'
> believes are each 89,323 lines long?
> 
> I checked, and there is no single quote or C-m in either file.
> 
> -- 
> Ajay Shah                                                   Consultant
> ajayshah at mayin.org                      Department of Economic Affairs
> http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
>



From cullens at tcd.ie  Tue Jul  6 14:56:14 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Tue, 06 Jul 2004 13:56:14 +0100
Subject: [R] Improving effeciency - better table()?
Message-ID: <opsapvj0ws1pelvz@smtp.tcd.ie>

Hi,

I've been running some simulations for a while and the performance of R  
has been great. However, I've recently changed the code to perform a sort  
of chi-square goodness-of-fit test. To get the observed values for each  
cell I've been using table() - specifically I've been using cut2 from  
Hmisc to divide up the range into a specified number of cells and then  
using table to count how many observations appear in each cell.

> obs <- table(cut2(z.trun, cuts=breaks))

Having done this I've found that the code takes much longer to run - up to  
10x as long. Is there a more effecient way of doing this? Anyone have any  
thoughts?

-- 
SC

Simon Cullen
Room 3030
Dept. Of Economics
Trinity College Dublin

Ph. (608)3477
Email cullens at tcd.ie



From MSchwartz at MedAnalytics.com  Tue Jul  6 14:54:50 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 06 Jul 2004 07:54:50 -0500
Subject: [R] counting the occurrences of vectors
In-Reply-To: <loom.20040706T060536-976@post.gmane.org>
References: <E619BDBD99B4F74D9DCA32F43BE926714C73AB@XCH-VN02.sph.ad.jhsph.edu>
	<40E8A0B3.1050404@pdf.com>
	<1089068914.10847.387.camel@localhost.localdomain>
	<loom.20040706T060536-976@post.gmane.org>
Message-ID: <1089118490.16727.10.camel@localhost.localdomain>

On Mon, 2004-07-05 at 23:22, Gabor Grothendieck wrote:
> Marc Schwartz <MSchwartz <at> MedAnalytics.com> writes:
> 
> > the likely overhead involved in paste()ing together the rows
> > to create objects 
> 
> 
> I thought I would check this and it seems that in my original f1 function 
> its not really the paste itself that's the bottleneck but applying the 
> paste.  If we use do.call rather than apply, as shown in f1a below, then 
> we see that f1a runs faster than row.match.count (which in turn was faster
> than f1):
> 
> f1a <- function(a,b,sep=":") {
> 	f <- function(...) paste(..., sep=sep)
> 	a2 <- do.call("f", as.data.frame(a))
> 	b2 <- do.call("f", as.data.frame(b))
> 	c(table(c(b2,unique(a2)))[a2] - 1)
> }
> 
> > set.seed(1)
> > # note that we have increased the size of the matrices from last post
> > # to better show the speed difference
> > a <- matrix(sample(3,10000,rep=T),nc=5)
> > b <- matrix(sample(3,1000,rep=T),nc=5)
> 
> > # row.match.count taken from Marc's post in this thread
> > # have put a c(...) around row.match.count to make it comparable to f1a
> > gc(); system.time(ans <- c(row.match.count(b,a)))
>          used (Mb) gc trigger (Mb)
> Ncells 436079 11.7     741108 19.8
> Vcells 130663  1.0     786432  6.0
> [1] 0.11 0.00 0.11   NA   NA
> 
> > gc(); system.time(ansf1a <- f1a(b,a))
>          used (Mb) gc trigger (Mb)
> Ncells 436080 11.7     741108 19.8
> Vcells 130669  1.0     786432  6.0
> [1] 0.04 0.00 0.04   NA   NA
> 
> > all.equal(ansf1a,ans)
> [1] TRUE


Gabor,

Well done!  I liked your approach in the prior message of getting away
from using regex. I had one of those "I could'a had a V-8" moments, when
I realized that of course the resultant table names were syntactically
correct R statements and therefore one could get away from worrying
about the data type issues and use eval(parse(...)).

The above approach is better yet, more flexible, of course more elegant
and notably faster.

Advantage Gabor...  ;-)

Best regards,

Marc



From rpeng at jhsph.edu  Tue Jul  6 15:00:27 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 06 Jul 2004 09:00:27 -0400
Subject: [R] Improving effeciency - better table()?
In-Reply-To: <opsapvj0ws1pelvz@smtp.tcd.ie>
References: <opsapvj0ws1pelvz@smtp.tcd.ie>
Message-ID: <40EAA26B.5010402@jhsph.edu>

Have you tried using hist() with specifying `br' and `plot = FALSE'?
See the note in ?cut.

-roger

Simon Cullen wrote:
> Hi,
> 
> I've been running some simulations for a while and the performance of R  
> has been great. However, I've recently changed the code to perform a 
> sort  of chi-square goodness-of-fit test. To get the observed values for 
> each  cell I've been using table() - specifically I've been using cut2 
> from  Hmisc to divide up the range into a specified number of cells and 
> then  using table to count how many observations appear in each cell.
> 
>> obs <- table(cut2(z.trun, cuts=breaks))
> 
> 
> Having done this I've found that the code takes much longer to run - up 
> to  10x as long. Is there a more effecient way of doing this? Anyone 
> have any  thoughts?
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From andy_liaw at merck.com  Tue Jul  6 15:02:26 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jul 2004 09:02:26 -0400
Subject: [R] Improving effeciency - better table()?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FD1@usrymx25.merck.com>

Since you didn't provide an example of what z.trun and breaks may look like,
most people can only guess.  Before asking how code can be made more
efficient, it might be more helpful to find out where in the code is taking
time.  Try:

Rprof()
obs <- table(cut2(z.trun, cuts=breaks))
Rprof(NULL)
summaryRprof()

Andy

> From: Simon Cullen
> 
> Hi,
> 
> I've been running some simulations for a while and the 
> performance of R  
> has been great. However, I've recently changed the code to 
> perform a sort  
> of chi-square goodness-of-fit test. To get the observed 
> values for each  
> cell I've been using table() - specifically I've been using 
> cut2 from  
> Hmisc to divide up the range into a specified number of cells 
> and then  
> using table to count how many observations appear in each cell.
> 
> > obs <- table(cut2(z.trun, cuts=breaks))
> 
> Having done this I've found that the code takes much longer 
> to run - up to  
> 10x as long. Is there a more effecient way of doing this? 
> Anyone have any  
> thoughts?
> 
> -- 
> SC
> 
> Simon Cullen
> Room 3030
> Dept. Of Economics
> Trinity College Dublin
> 
> Ph. (608)3477
> Email cullens at tcd.ie



From andy_liaw at merck.com  Tue Jul  6 15:06:19 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jul 2004 09:06:19 -0400
Subject: [R] More difficulties in getting data into R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FD2@usrymx25.merck.com>

This is what I'd try:

col2and4 <- matrix(scan(pipe("cut -d\| -f2,4 cmie_firm_data.text |"), 
                   skip=2), ncol=2, byrow=TRUE)

Andy

> From: Liaw, Andy
> 
> Could it be that you happen you have `#' in `col4'?  Try 
> either (or both):
> 
> 1. read.table(..., comment.char="")
> 2. scan(...)
> 
> HTH,
> Andy
> 
> > From: Ajay Shah
> > 
> > In order to get around the problems of my posting a few 
> minutes ago, I
> > thought:
> > 
> > $ awk -F\| '(NR > 2) {print $2}' cmie_firm_data.text > col2
> > $ awk -F\| '(NR > 2) {print $4}' cmie_firm_data.text > col4
> > $ paste col2 col4 | head -2
> > -510.45 -510.27
> > 60700   101900
> > $ paste col2 col4 | tail -2
> > 28648.12        31617.02
> > 491014.77       494308.52
> > $ wc -l col2 col4
> >   89323 col2
> >   89323 col4
> >  178646 total
> > 
> > So all is well.
> > 
> > But R doesn't like it:
> > 
> > $ R --vanilla < picture.R 
> > 
> > R : Copyright 2004, The R Foundation for Statistical Computing
> > Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3
> > 
> > > col2 <- read.table(file="col2")
> > > col4 <- read.table(file="col4")
> > > print(nrow(col2))
> > [1] 89323
> > > print(nrow(col4))
> > [1] 88746
> > 
> > Why might I be getting 89,323 and 88,746 obs for two files 
> which `wc'
> > believes are each 89,323 lines long?
> > 
> > I checked, and there is no single quote or C-m in either file.
> > 
> > -- 
> > Ajay Shah                                                   
> Consultant
> > ajayshah at mayin.org                      Department of 
> Economic Affairs
> > http://www.mayin.org/ajayshah           Ministry of 
> Finance, New Delhi
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
>



From MSchwartz at MedAnalytics.com  Tue Jul  6 15:11:08 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 06 Jul 2004 08:11:08 -0500
Subject: [R] Improving effeciency - better table()?
In-Reply-To: <opsapvj0ws1pelvz@smtp.tcd.ie>
References: <opsapvj0ws1pelvz@smtp.tcd.ie>
Message-ID: <1089119468.16727.20.camel@localhost.localdomain>

On Tue, 2004-07-06 at 07:56, Simon Cullen wrote:
> Hi,
> 
> I've been running some simulations for a while and the performance of R  
> has been great. However, I've recently changed the code to perform a sort  
> of chi-square goodness-of-fit test. To get the observed values for each  
> cell I've been using table() - specifically I've been using cut2 from  
> Hmisc to divide up the range into a specified number of cells and then  
> using table to count how many observations appear in each cell.
> 
> > obs <- table(cut2(z.trun, cuts=breaks))
> 
> Having done this I've found that the code takes much longer to run - up to  
> 10x as long. Is there a more effecient way of doing this? Anyone have any  
> thoughts?


It would appear that you might be attempting to do a Hosmer-Lemeshow
type of GOF test.

If indeed that is the case, before making the above more efficient, you
should spend some time reviewing the following posts by Frank Harrell on
this subject:

http://maths.newcastle.edu.au/~rking/R/help/02b/4210.html

http://maths.newcastle.edu.au/~rking/R/help/02b/3111.html

HTH,

Marc Schwartz



From Colin.Bleay at bristol.ac.uk  Tue Jul  6 15:42:34 2004
From: Colin.Bleay at bristol.ac.uk (CR Bleay, School Biological Sciences)
Date: Tue, 06 Jul 2004 14:42:34 +0100
Subject: [R] Re: errors in randomization test
In-Reply-To: <200407061223.i66CNxXq029138@erdos.math.unb.ca>
References: <200407061223.i66CNxXq029138@erdos.math.unb.ca>
Message-ID: <1567600.1089124954@bio-colinbleaymac.bio.bris.ac.uk>


dear rolf,

thank you for the assistance, i did not know how to catch the errors from 
try.

of course the new code has thrown up a new error:
"Error in terms.default(object) : no terms component"

which i have to resolve.

cheers,

colin

--On Tuesday, July 6, 2004 9:23 am -0300 Rolf Turner <rolf at math.unb.ca> 
wrote:

> Colin Bleay wrote:
>
>> last week i sent an e-mail about dealing with errors thrown up from a
>> glm.nb model carried out on multiple random datasets.
>>
>> every so often a dataset is created which results in the following error
>> after a call to glm.nb:
>>
>> "Error: NA/NaN/Inf in foreign function call (arg 1)
>> In addition: Warning message:
>> Step size truncated due to divergence"
>>
>>
>> I am at a loss as to how to deal with this.
>>
>> firstly because the dataset that is generated, although throwing an
>> error  when the glm.nb model is applied, is a valid dataset. so how do i
>> incorporate this dataset in my results (results being descriptive stats
>> on  the coefficients from the multiple datasets) i.e. shoould
>> coefficients be  set to zero?
>
> 	Almost surely, setting the coefficients equal to 0 is the
> 	wrong thing to do.  What the right thing is depends on the
> 	answer to ``lastly''.
>
> 	Setting the coefficients to be NA in this case (i.e.
> 	effectively throwing away such cases) is also wrong, but not
> 	quite as wrong as setting them equal to 0.
>
>> secondly, how do i capture and deal with the error. is it possible to
>> construct an "if" statement so that "if error, do this, if not continue"
>
> 	This should be do-able using try().  Something like:
>
> 	c.list <- list()
> 	save.bummers <- list()
> 	K <- 0
> 	for(i in 1:42) {
> 		repeat {
> 			X <- generate.random.data.set()
> 			Y <- try(glm.nb(X,whatever))
> 			if(inherits(Y,"try-error")) {
> 				K <- K+1
> 				save.bummers[[K]] <- X
> 			} else break
> 		}
> 		c.list[[i]] <- coeff(Y)
> 	}
>
> 	This should give you a sample of 42 coefficient vectors from
> 	the ``successful'' data sets, and a list of all the (a random
> 	number of) data sets that yielded a lack of success.  You can
> 	then take the data sets stored in save.bummers and experiment
> 	with them to see what is causing the problem.
>
>> lastly, i am unsure as to what characteristics of a dataset would result
>> in  these errors in the glm.nb?
>
> 	Here I have to heed the advice (attributed to a ``great art
> 	historian'') from George F. Simmons' wonderful book on
> 	elementary differential equations:  ``A fool he who gives
> 	more than he has.''
>
> 					cheers,
>
> 						Rolf Turner
> 						rolf at math.unb.ca
>



----------------------
Dr Colin Bleay
Dept. Biological Sciences,
University of Bristol,
Woodlands rd.,
Bristol,
BS8 1UG.
UK

Tel: 44 (0)117 928 7470
Fax: 44 (0)117



From schimpanski at gmx.de  Tue Jul  6 15:54:51 2004
From: schimpanski at gmx.de (schimpanski@gmx.de)
Date: Tue, 6 Jul 2004 15:54:51 +0200 (MEST)
Subject: [R] Converting S-Plus Libraries to R
Message-ID: <14037.1089122091@www26.gmx.net>

Dear all!

I'd like to do multiple imputation of missing values with s-plus libraries
that are provided by Shafer (http://www.stat.psu.edu/~jls/misoftwa.html). I
wonder, whether these libraries are compatible or somehow convertible to R
(because I don't have S-plus), so that I can use this functions using the R
Program.

I would be happy if you could tell me,
-if it is possible to use S-plus libraries with R
-if yes, how I can use the S-Plus libraries in R

Thank you very much,

Will

--



From sdavis2 at mail.nih.gov  Tue Jul  6 16:01:30 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 06 Jul 2004 10:01:30 -0400
Subject: [R] Converting S-Plus Libraries to R
In-Reply-To: <14037.1089122091@www26.gmx.net>
Message-ID: <BD1028FA.A759%sdavis2@mail.nih.gov>

Will,

Here is a general answer.  Check out:
http://cran.r-project.org/doc/FAQ/R-FAQ.html#R%20and%20S

Sean

On 7/6/04 9:54 AM, "schimpanski at gmx.de" <schimpanski at gmx.de> wrote:

> Dear all!
> 
> I'd like to do multiple imputation of missing values with s-plus libraries
> that are provided by Shafer (http://www.stat.psu.edu/~jls/misoftwa.html). I
> wonder, whether these libraries are compatible or somehow convertible to R
> (because I don't have S-plus), so that I can use this functions using the R
> Program.
> 
> I would be happy if you could tell me,
> -if it is possible to use S-plus libraries with R
> -if yes, how I can use the S-Plus libraries in R
> 
> Thank you very much,
> 
> Will
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Tue Jul  6 16:01:17 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jul 2004 10:01:17 -0400
Subject: [R] Converting S-Plus Libraries to R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FD3@usrymx25.merck.com>

Are you looking for the packages `norm', `cat' and `mix' on CRAN? 

Andy

> From: schimpanski at gmx.de
> 
> Dear all!
> 
> I'd like to do multiple imputation of missing values with 
> s-plus libraries
> that are provided by Shafer 
> (http://www.stat.psu.edu/~jls/misoftwa.html). I
> wonder, whether these libraries are compatible or somehow 
> convertible to R
> (because I don't have S-plus), so that I can use this 
> functions using the R
> Program.
> 
> I would be happy if you could tell me,
> -if it is possible to use S-plus libraries with R
> -if yes, how I can use the S-Plus libraries in R
> 
> Thank you very much,
> 
> Will



From MSchwartz at MedAnalytics.com  Tue Jul  6 16:05:12 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 06 Jul 2004 09:05:12 -0500
Subject: [R] Converting S-Plus Libraries to R
In-Reply-To: <14037.1089122091@www26.gmx.net>
References: <14037.1089122091@www26.gmx.net>
Message-ID: <1089122712.16727.23.camel@localhost.localdomain>

On Tue, 2004-07-06 at 08:54, schimpanski at gmx.de wrote:
> Dear all!
> 
> I'd like to do multiple imputation of missing values with s-plus libraries
> that are provided by Shafer (http://www.stat.psu.edu/~jls/misoftwa.html). I
> wonder, whether these libraries are compatible or somehow convertible to R
> (because I don't have S-plus), so that I can use this functions using the R
> Program.
> 
> I would be happy if you could tell me,
> -if it is possible to use S-plus libraries with R
> -if yes, how I can use the S-Plus libraries in R
> 
> Thank you very much,
> 
> Will


I believe that you will find that Prof. Ripley has already done the work
for you in the 'mix' package on CRAN:

http://cran.us.r-project.org/src/contrib/Descriptions/mix.html

HTH,

Marc Schwartz



From myao at ou.edu  Tue Jul  6 16:45:33 2004
From: myao at ou.edu (Yao, Minghua)
Date: Tue, 6 Jul 2004 09:45:33 -0500
Subject: [R] Laplacian Distribution
Message-ID: <78B50CF247E5D04B8A5E02D001CC8E9A595C78@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040706/e111d5cb/attachment.pl

From rolf at math.unb.ca  Tue Jul  6 16:54:38 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 6 Jul 2004 11:54:38 -0300 (ADT)
Subject: [R] Laplacian Distribution
Message-ID: <200407061454.i66EscdU005680@erdos.math.unb.ca>

> Could anybody please tell me how to generate Laplacian distributed
> random numbers? Thanks.

	Yes.  Generate random uniforms and then apply the
	inverse cumulative distribution function of the
	Laplace distribution to these.

	It's about 2 lines of code.  Figure it out.

				cheers,

					Rolf Turner
					rolf at math.unb.ca

P. S.  Is this a homework problem?



From andy_liaw at merck.com  Tue Jul  6 16:56:09 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jul 2004 10:56:09 -0400
Subject: [R] Laplacian Distribution
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FD7@usrymx25.merck.com>

How about something like:

n <- 100
x <- sign(runif(n) - 0.5) * rexp(n)

??

Andy

> From: Yao, Minghua
> 
> All,
>  
> Could anybody please tell me how to generate Laplacian 
> distributed random numbers? Thanks.
>  
> Minghua



From rolf at math.unb.ca  Tue Jul  6 16:58:56 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 6 Jul 2004 11:58:56 -0300 (ADT)
Subject: [R] Converting S-Plus Libraries to R
Message-ID: <200407061458.i66EwuPx006027@erdos.math.unb.ca>

> I'd like to do multiple imputation of missing values with s-plus libraries
> that are provided by Shafer (http://www.stat.psu.edu/~jls/misoftwa.html). I
> wonder, whether these libraries are compatible or somehow convertible to R
> (because I don't have S-plus), so that I can use this functions using the R
> Program.
> 
> I would be happy if you could tell me,
> -if it is possible to use S-plus libraries with R

	Yes.

> -if yes, how I can use the S-Plus libraries in R

	With a certain amount of effort, mutatis muntandis.

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From Anne.Olga.Piotet at omsv.vd.ch  Tue Jul  6 17:33:36 2004
From: Anne.Olga.Piotet at omsv.vd.ch (Anne Piotet)
Date: Tue, 6 Jul 2004 17:33:36 +0200
Subject: [R] marginal effect in a   logistic model
Message-ID: <010a01c4636e$9af90560$83dad10a@prod.omsv.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040706/54e3b80b/attachment.pl

From cullens at tcd.ie  Tue Jul  6 18:11:38 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Tue, 06 Jul 2004 17:11:38 +0100
Subject: [R] Improving effeciency - better table()?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7FD1@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7FD1@usrymx25.merck.com>
Message-ID: <opsap4lodm1pelvz@smtp.tcd.ie>

On Tue, 6 Jul 2004 09:02:26 -0400, Liaw, Andy <andy_liaw at merck.com> wrote:

> Since you didn't provide an example of what z.trun and breaks may look  
> like, most people can only guess.  Before asking how code can be made  
> more
> efficient, it might be more helpful to find out where in the code is  
> taking
> time.  Try:
>
> Rprof()
> obs <- table(cut2(z.trun, cuts=breaks))
> Rprof(NULL)
> summaryRprof()

Thanks, Andy. That helped to clear up some of my confusion. I have now  
eliminated the call to cut2 and table and replaced that with hist, as  
suggested by Roger Peng.

However I had changed much more code than I had initially realised and it  
seems that the other code is having a larger effect. I've attached the  
output of an experiment (a power test with 1000 iterations - code  
included) and it seems that the problem is getting the expected number of  
observations in each cell. I have to integrate the density that I am  
working with in order to do this as it isn't standard.

I know that, firstly, using a for() loop is bad but the problem didn't  
lend itself to vectorisation (I thought). Any help would be appreciated.

-- 
SC

Simon Cullen
Room 3030
Dept. Of Economics
Trinity College Dublin

Ph. (608)3477
Email cullens at tcd.ie

From cullens at tcd.ie  Tue Jul  6 18:21:44 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Tue, 06 Jul 2004 17:21:44 +0100
Subject: [R] Improving effeciency - better table()?
In-Reply-To: <opsap4lodm1pelvz@smtp.tcd.ie>
References: <3A822319EB35174CA3714066D590DCD504AF7FD1@usrymx25.merck.com>
	<opsap4lodm1pelvz@smtp.tcd.ie>
Message-ID: <opsap42ieg1pelvz@smtp.tcd.ie>

It seems that attachments are stripped off so I'll include the code and  
the output of Rprof below:

#apologies for disgusting wrapping

f.powertest <-  
function(path=paste(substr(getwd(),1,3),"R/",sep=""),iter=5000,sample=25,trun.prop=0,m,s){
	rej.2.5 <- 0
			
	for (i in 1:iter){
		z<-c()
		z.trun<-c()
		zeros<- 0
		total<-0
		while(length(z.trun)< sample){
			
			trun<-qnorm(trun.prop,m,s)
			z<-rnorm(sample,m,s)
			ind <- z>trun
			zeros <- zeros + sum(!ind)
			total<- total + sample
			z.trun <- c(z.trun,z[ind])
			
		}

		z.trun<-z.trun[1:sample]
		tau<-ifelse(qnorm(zeros/total)==-Inf,-3,qnorm(zeros/total))
		
		#estimate the true mean
		m.tr <- mean(z.trun)
		s.tr <- sd(z.trun)
		s.untr <- s.tr/sqrt(1-f.lambda(tau)*(f.lambda(tau)-tau))
		m.untr <- m.tr - s.untr*f.lambda(tau)

		#cacluate the breakpoints
		
		#number of breakpoints first:
		br <- ceiling(log2(length(z.trun)) + 1)
		z.trun<- sort(z.trun)
	
		br.len <- (z.trun[sample - 6] - z.trun[1])/(br-1)
		
		breaks <- seq(from=z.trun[1],by=br.len,length=br)
		top <- 1000#top limit of the range - I'm using N(0,1) so for the moment  
this is ok
		breaks <- c(breaks, top)
		tab <- hist(z.trun,br=breaks, plot=F,right=F)$counts
		expect<-f.expect(breaks,m.untr,s.untr,tau)*sample

		stat <- sum((tab-expect)^2/expect)

		if(qchisq(0.975,br-3) < stat){
			rej.2.5 <-rej.2.5 + 1
		}

	}

	return(100*rej.2.5/iter)
}
f.expect <- function(breaks,m,sigma,alpha){
	res<-sapply(breaks,f.tr.pnorm,m=m,sigma=sigma,alpha=alpha)
	return(res[-1] - res[-length(res)])
}
f.tr.dnorm <- function(x,m=0,sigma=1,alpha){
	dnorm((x-m)/sigma)/(sigma*(1-pnorm(alpha)))
}
f.tr.pnorm <- function(q,m=0,sigma=1,alpha){
	integrate(f.tr.dnorm,alpha,q,m=m,sigma=sigma,alpha=alpha)$value#rel.tol=.Machine$double.eps^0.5
}

f.test <- function(){
	Rprof()
	f.powertest(iter=1000,m=0,s=1,sample=200,trun.prop=0.25)
	Rprof(NULL)
	print(summaryRprof())
}

f.lambda <- function(x) dnorm(x)/(1 - pnorm(x))

************************************************

> f.test()
$by.self
                    self.time self.pct total.time total.pct
integrate               0.92     15.2       3.28      51.7
as.double               0.56      9.3       0.68      10.7
dnorm                   0.44      7.3       0.52       8.2
rnorm                   0.30      5.0       0.30       4.7
pnorm                   0.26      4.3       0.26       4.1
>                       0.18      3.0       0.18       2.8
hist.default            0.18      3.0       1.24      19.6
f                       0.16      2.6       0.90      14.2
names                   0.16      2.6       0.18       2.8
f.powertest             0.14      2.3       6.34     100.0
switch                  0.14      2.3       0.14       2.2
==                      0.12      2.0       0.12       1.9
as.double.default       0.12      2.0       0.12       1.9
as.integer              0.12      2.0       0.16       2.5
diff.default            0.12      2.0       0.32       5.0
-                       0.10      1.7       0.10       1.6
paste                   0.10      1.7       0.20       3.2
seq                     0.10      1.7       0.20       3.2
...

$by.total
                    total.time total.pct self.time self.pct
f.powertest              6.34     100.0      0.14      2.3
f.test                   6.34     100.0      0.00      0.0
f.expect                 3.64      57.4      0.02      0.3
sapply                   3.62      57.1      0.04      0.7
lapply                   3.52      55.5      0.04      0.7
FUN                      3.38      53.3      0.02      0.3
integrate                3.28      51.7      0.92     15.2
hist                     1.30      20.5      0.06      1.0
hist.default             1.24      19.6      0.18      3.0
<Anonymous>              0.94      14.8      0.04      0.7
f                        0.90      14.2      0.16      2.6
as.double                0.68      10.7      0.56      9.3
dnorm                    0.52       8.2      0.44      7.3
sort                     0.40       6.3      0.04      0.7
diff                     0.36       5.7      0.00      0.0
storage.mode<-           0.34       5.4      0.02      0.3
diff.default             0.32       5.0      0.12      2.0
rnorm                    0.30       4.7      0.30      5.0
pnorm                    0.26       4.1      0.26      4.3
ifelse                   0.22       3.5      0.04      0.7
eval                     0.20       3.2      0.06      1.0
paste                    0.20       3.2      0.10      1.7
seq                      0.20       3.2      0.10      1.7
...
$sampling.time
[1] 6.34

-- 
SC

Simon Cullen
Room 3030
Dept. Of Economics
Trinity College Dublin

Ph. (608)3477
Email cullens at tcd.ie



From spencer.graves at pdf.com  Tue Jul  6 18:35:16 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 Jul 2004 09:35:16 -0700
Subject: [R] aide pour une affiner une AFD.
In-Reply-To: <BAY2-F29h74VaxC7TJu0009229e@hotmail.com>
References: <BAY2-F29h74VaxC7TJu0009229e@hotmail.com>
Message-ID: <40EAD4C4.6070701@pdf.com>

      1.  The language of this list is English.  Many people who don't 
know French might like to help you but can't because your question does 
not use the established communication protocol. 

      2.  Please read the posting guide at the end of this email 
(http://www.R-project.org/posting-guide.html).  I suspect that many 
potential questioners solve their own problem by using this guide.  If 
they don't, following the guide seems to make their questions more 
focused and easier for other to understand.  This increases the chances 
that the questioner will get a useful reply. 

      3.  I gather you have done some kind of "factorial discriminant 
analysis", obtaining thereby graphs and tables but not associated 
Mahalinobis distances nor Wilks statistics.  Could you please tell us 
what commands you used?  Also, it would help if you reduce your data set 
to, say, 6 observations on 2 response variables in 2 groups.  If you 
format your question so someone else can just copy a few lines from your 
email and paste into R, you are more likely to get a useful answer to 
your question. 

      J'espere que cela vous aiderait. 
      Spencer Graves

louis marchand wrote:

> madame, monsieur,  help me please,
>
> Je debute avec R. J'ai r??alis?? une analyse factorielle discriminante 
> avec R. J'obtient les resultat graphiques et les tables assici??es ?? 
> l'analyse. Cependant je souhaiterais savoir si les distances separant 
> les groupes (decades) sont statistiquement significatives. pour cela 
> il me faut utiliser la distance de mahalanobis et la statistique de 
> Wilks mais:
> <<je n'arrive pas ?? obtenir la table de mahalanobis, ainsi que la 
> statistique de wilks.
> Pouvez-vous, s'il vous plait, m'indiquer la demarche ?? suivre pour y 
> parvenir.
> Sachant que meme avec l'aide de R je n'y arrive pas.
> Merci.
>
> ps: ce sont les decades que j'essaye de discriminer avec des variables 
> quantitatives.
> Je vous joints mon fichier de donn??es.
>
> message de hugues santin-janin (06-72-46-09-71)
> Institut m??diterann??en du patrimoine cynegetique et faunistique



From f.duan at yale.edu  Tue Jul  6 18:52:56 2004
From: f.duan at yale.edu (F Duan)
Date: Tue, 06 Jul 2004 12:52:56 -0400
Subject: [R] How to check the code for generic function in a specific
	package?
In-Reply-To: <40E9CECB.8090509@statistik.uni-dortmund.de>
Message-ID: <01LC545B8PRI001XXL@biomed.med.yale.edu>

Thanks for your answer. My problem is:

For example, I want to check the code for function "boxplot" and do some
modifications in a specific package, but "boxplot" has also been defined in
another package (e.g., graphics). Therefore, when I type "boxplot" or
"fix(boxplot)" at the R prompt, I only get a message like:

> boxplot
 standardGeneric for "boxplot" defined from package "graphics"

 function (x, ...) 
 standardGeneric("boxplot")
 <environment: 02D4FC14>
 Methods may be defined for arguments: x  


There is no source code pop-up, either for the package "graphics" or the
package I am working with.

Frank Duan


-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Monday, July 05, 2004 17:58
To: F Duan
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] How to check the code for generic function in a specific
package?

F Duan wrote:

> Hello, R people,
> 
>  
> 
> I am a R beginner. I searched the R-FAQ and R-help and failed to find the
> answers. 
> 
>  
> 
> Could anyone tell me how to check (or edit) a generic function within a
> specific package? If the function is not generic, I can just type the
> function name at the R prompt or use "fix()" and "edit()".

fix() *does* work for me, giving you expect that the fucntion is not 
"fixed" within the package, but a new (changed) instance is created in 
your Workspace.....

What do you expect to happen? What is the error message (if there is any)?

In order to change packages, you might want to edit the package sources 
directly.

Uwe Ligges



>  
> 
> Thanks a lot.
> 
>  
> 
> Frank
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From thchung at tgen.org  Tue Jul  6 18:58:26 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Tue, 6 Jul 2004 09:58:26 -0700
Subject: [R] ESS does not recognize installed libraries
In-Reply-To: <1089108265.3036.14.camel@vpn202001.lif.icnet.uk>
References: <95326388-CF2C-11D8-978F-000A95B43CDE@tgen.org>
	<1089108265.3036.14.camel@vpn202001.lif.icnet.uk>
Message-ID: <B2D30A74-CF6D-11D8-B6A0-000A95B43CDE@tgen.org>

Thank you Adaikalavan.

The problem was not due to simultaneous multiple versions of R.
The problem was due to missing directories in library path and this has 
been
cured by adding the missing library path using .libPaths().
However, it is uncertain how the same R program has different library 
paths
and how it disappeared in some previous R sessions.

Tae-Hoon.

On Jul 6, 2004, at 3:04 AM, Adaikalavan Ramasamy wrote:

> Do you by any chance have multiple versions of R installed ? The first
> two lines of the header in the iESS buffer should give a clue. Example 
> :
>
> R : Copyright 2004, The R Foundation for Statistical Computing
> Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3
>
> How does that compare to the header in your terminal/standalone mode. 
> If
> different, then you may have to set your global path to R correctly.
>
> Other than that, it could be that some of your library paths are
> missing. Try '.find.package("affy")' on your terminal. See if this path
> is included in '.libPaths()' on your emacs/ESS interface.
>
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From andy_liaw at merck.com  Tue Jul  6 19:09:01 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jul 2004 13:09:01 -0400
Subject: [R] How to check the code for generic function in a
	specific package?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FDA@usrymx25.merck.com>

What version of R are you using?  In R-1.9.1 (on WinXPPro), I get:

> boxplot
function (x, ...) 
UseMethod("boxplot")
<environment: namespace:graphics>

... and that _is_ what an S3 generic looks like.  I suspect you really want
to define a boxplot method for some class for which there's no boxplot
method yet.  If so, just create a function named boxplot.myclass (substitute
`myclass' for the name of the class).  If you want to see what the default
method looks like for boxplot, type boxplot.default (which is _not_ hidden
behind the namespace for `graphics').

Andy

> From: F Duan
> 
> Thanks for your answer. My problem is:
> 
> For example, I want to check the code for function "boxplot" 
> and do some
> modifications in a specific package, but "boxplot" has also 
> been defined in
> another package (e.g., graphics). Therefore, when I type "boxplot" or
> "fix(boxplot)" at the R prompt, I only get a message like:
> 
> > boxplot
>  standardGeneric for "boxplot" defined from package "graphics"
> 
>  function (x, ...) 
>  standardGeneric("boxplot")
>  <environment: 02D4FC14>
>  Methods may be defined for arguments: x  
> 
> 
> There is no source code pop-up, either for the package 
> "graphics" or the
> package I am working with.
> 
> Frank Duan
> 
> 
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Sent: Monday, July 05, 2004 17:58
> To: F Duan
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to check the code for generic function 
> in a specific
> package?
> 
> F Duan wrote:
> 
> > Hello, R people,
> > 
> >  
> > 
> > I am a R beginner. I searched the R-FAQ and R-help and 
> failed to find the
> > answers. 
> > 
> >  
> > 
> > Could anyone tell me how to check (or edit) a generic 
> function within a
> > specific package? If the function is not generic, I can 
> just type the
> > function name at the R prompt or use "fix()" and "edit()".
> 
> fix() *does* work for me, giving you expect that the fucntion is not 
> "fixed" within the package, but a new (changed) instance is 
> created in 
> your Workspace.....
> 
> What do you expect to happen? What is the error message (if 
> there is any)?
> 
> In order to change packages, you might want to edit the 
> package sources 
> directly.
> 
> Uwe Ligges
> 
> 
> 
> >  
> > 
> > Thanks a lot.
> > 
> >  
> > 
> > Frank
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From spe2 at cornell.edu  Tue Jul  6 22:26:52 2004
From: spe2 at cornell.edu (Stephen Ellner)
Date: Tue, 06 Jul 2004 16:26:52 -0400
Subject: [R] lme: extract variance estimate 
Message-ID: <5.2.1.1.2.20040706155615.00b8cab0@postoffice6.mail.cornell.edu>

For a Monte Carlo study I need to extract from an lme model
the estimated standard deviation of a random effect 
and store it in a vector. If I do a print() or summary() 
on the model, the number I need is displayed in the Console 
[it's the 0.1590195 in the output below] 

>print(fit)
>Linear mixed-effects model fit by maximum likelihood
>  Data: datag2 
>  Log-likelihood: -145.0028
>  Fixed: lst1 ~ lst 
>(Intercept)         lst 
>  1.1080629   0.7582595 
>
>Random effects:
> Formula: ~1 | yeart
>        (Intercept)  Residual
>StdDev:   0.1590195 0.3313497

However I have not been able to find that number anywhere in the 
model object returned by lme. Can anyone tell me how to pull it
or compute it from a model returned by lme? Ditto for models with
random intercept fitted by glmmPQL with family=binomial. 

Details:
The relevant data are the first 3 colums from the
data frame extracted below. Yeart is a factor (year of
study) ranging from 1 to 16. The model is linear regression of 
lst1 on lst with constant slope, random intercept varying
across years. I'm using R 1.9.1 in WinXP and the current
version of nlme from CRAN. 

Code: 
datag2=groupedData(lst1~1|yeart,data=cdata); 
mixed.grow=lme(fixed=lst1~lst,random=~1, method="ML",data=datag2);

mixed.surv=glmmPQL(fixed=surv~lst, random=~1|yeart, family=binomial,
data=cdata,niter=50);

Some of the data: 
     yeart      lst     lst1 surv flow
1        1 3.158088 3.331216    1    0
2        1 2.472618 2.486410    1    0
3        1 3.582950 3.417807    1    0
4        1 3.554819 3.377117    1    0
5        1 2.830049 2.992426    1    0
6        1 2.779616 3.240449    1    0
7        1 2.580484 2.930154    1    0

Thanks in advance,
Steve 


Stephen P. Ellner (spe2 at cornell.edu)
Department of Ecology and Evolutionary Biology
Corson Hall, Cornell University, Ithaca NY 14853-2701
Phone (607) 254-4221    FAX (607) 255-8088



From gerifalte28 at hotmail.com  Tue Jul  6 21:39:38 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Tue, 06 Jul 2004 19:39:38 +0000
Subject: [R] Code density functions
Message-ID: <BAY2-F19Ft5MLg060DM00011f78@hotmail.com>

Hello

I would like to see the algorithm that R uses to generate density functions 
for several distributions (i.e. Normal,Weibull, etc).  I tried:

>dnorm
function (x, mean = 0, sd = 1, log = FALSE)
.Internal(dnorm(x, mean, sd, log))
<environment: namespace:stats>

How can I see the code used for densities?

Thanks!



From hastie at stanford.edu  Tue Jul  6 20:24:28 2004
From: hastie at stanford.edu (Trevor Hastie)
Date: Tue, 6 Jul 2004 11:24:28 -0700
Subject: [R] svmpath: fitting the entire SVM regularization path
Message-ID: <00a601c46386$79affa40$ec6640ab@stuk>

svmpath is a contributed package that fits the entire regularization path
for a two-class SVM model.

The SVM (with any kernel), has a regularization or cost parameter C, which
controls the amount of overlap
at the soft margin. When the SVM criterion is expressed in terms of a hinge
loss plus lambda x quadratic penalty, then lambda=1/C.
In many situations, the choice of C can be critical, and different regimes
for C are called for as the other kernel tuning parameters
are changed.

Most software packages come with a default value for C (typically very
large), and the user is left to explore different values of C.
It turns out that the lagrange multipliers which define the SVM solution for
any C are piecewise linear in C (and more usefully piecewise
linear and mostly piecewise constant in lambda) This means that we can
compute the entire sequence of solutions for all values of C exactly.
svmpath does this with essentially the same cost as fitting a single SVM
model with a specified value of C.

See the paper (joint work with Saharon Rosset, Ji Zhu and Rob Tibshirani)
http://www-stat.stanford.edu/~hastie/Papers/svmpath.pdf
for details.

This code has been tested on moderate sized problems, with up to 1000
observations. The current version is not industry
ready; occasionally it will run into situations where the steps are too
small, leading to machine zero situations. Usually increasing the
parameter eps from its default 1e-10 will avoid this.


Trevor Hastie


--------------------------------------------------------------------
  Trevor Hastie                                  hastie at stanford.edu
  Professor, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)          Fax: (650) 725-8977
  (650) 498-5233 (Biostatistics)   Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie
  address: room 104, Department of Statistics, Sequoia Hall
           390 Serra Mall, Stanford University, CA 94305-4065



From yunfeng at scripps.edu  Tue Jul  6 20:16:53 2004
From: yunfeng at scripps.edu (Yunfeng Hu)
Date: Tue, 6 Jul 2004 11:16:53 -0700
Subject: [R] how to print the plots
Message-ID: <A817F2AC-CF78-11D8-9A4A-000A95AB543C@scripps.edu>

Hi, when I type >plot(model1) I get four plots. I want to print the 
Normal Q-Q plot. I found that if I save it as a ps file, the file will 
include much more things than I want. What is the easiest way to just 
save the plot  I want? Thanks.

Yunfeng



From spencer.graves at pdf.com  Tue Jul  6 22:56:06 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 Jul 2004 13:56:06 -0700
Subject: [R] lme: extract variance estimate
In-Reply-To: <5.2.1.1.2.20040706155615.00b8cab0@postoffice6.mail.cornell.edu>
References: <5.2.1.1.2.20040706155615.00b8cab0@postoffice6.mail.cornell.edu>
Message-ID: <40EB11E6.1040604@pdf.com>

      Have you considered "VarCorr"?  I've used it with "lme", and the 
documentation in package lme4 suggests it should work with GLMM, which 
might also do what you want from glmmPQL. 

      hope this helps.  spencer graves

Stephen Ellner wrote:

>For a Monte Carlo study I need to extract from an lme model
>the estimated standard deviation of a random effect 
>and store it in a vector. If I do a print() or summary() 
>on the model, the number I need is displayed in the Console 
>[it's the 0.1590195 in the output below] 
>
>  
>
>>print(fit)
>>Linear mixed-effects model fit by maximum likelihood
>> Data: datag2 
>> Log-likelihood: -145.0028
>> Fixed: lst1 ~ lst 
>>(Intercept)         lst 
>> 1.1080629   0.7582595 
>>
>>Random effects:
>>Formula: ~1 | yeart
>>       (Intercept)  Residual
>>StdDev:   0.1590195 0.3313497
>>    
>>
>
>However I have not been able to find that number anywhere in the 
>model object returned by lme. Can anyone tell me how to pull it
>or compute it from a model returned by lme? Ditto for models with
>random intercept fitted by glmmPQL with family=binomial. 
>
>Details:
>The relevant data are the first 3 colums from the
>data frame extracted below. Yeart is a factor (year of
>study) ranging from 1 to 16. The model is linear regression of 
>lst1 on lst with constant slope, random intercept varying
>across years. I'm using R 1.9.1 in WinXP and the current
>version of nlme from CRAN. 
>
>Code: 
>datag2=groupedData(lst1~1|yeart,data=cdata); 
>mixed.grow=lme(fixed=lst1~lst,random=~1, method="ML",data=datag2);
>
>mixed.surv=glmmPQL(fixed=surv~lst, random=~1|yeart, family=binomial,
>data=cdata,niter=50);
>
>Some of the data: 
>     yeart      lst     lst1 surv flow
>1        1 3.158088 3.331216    1    0
>2        1 2.472618 2.486410    1    0
>3        1 3.582950 3.417807    1    0
>4        1 3.554819 3.377117    1    0
>5        1 2.830049 2.992426    1    0
>6        1 2.779616 3.240449    1    0
>7        1 2.580484 2.930154    1    0
>
>Thanks in advance,
>Steve 
>
>
>Stephen P. Ellner (spe2 at cornell.edu)
>Department of Ecology and Evolutionary Biology
>Corson Hall, Cornell University, Ithaca NY 14853-2701
>Phone (607) 254-4221    FAX (607) 255-8088
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Tue Jul  6 23:57:40 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 Jul 2004 14:57:40 -0700
Subject: [R] how to print the plots
In-Reply-To: <A817F2AC-CF78-11D8-9A4A-000A95AB543C@scripps.edu>
References: <A817F2AC-CF78-11D8-9A4A-000A95AB543C@scripps.edu>
Message-ID: <40EB2054.90004@pdf.com>

      ?plot.lm exposes an argument "which", which sounds to me like it 
will do what you want.  Have you tried that? 

      hope this helps.  spencer graves

Yunfeng Hu wrote:

> Hi, when I type >plot(model1) I get four plots. I want to print the 
> Normal Q-Q plot. I found that if I save it as a ps file, the file will 
> include much more things than I want. What is the easiest way to just 
> save the plot  I want? Thanks.
>
> Yunfeng
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From stephane.dray at umontreal.ca  Wed Jul  7 00:28:46 2004
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Tue, 06 Jul 2004 18:28:46 -0400
Subject: [R] Generate a matrix Q satisfying t(Q)%*%Q=Z and XQ=W
Message-ID: <5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>

Hello,
I have a question that is not directly related to R ... but I try to do it 
in R ;-) :

I would like to generate a matrix Q satisfying (for a given Z, X and W) the 
two following conditions:

t(Q)%*%Q=Z  (1)
XQ=W (2)

where:
Q is m rows and r columns
X is p rows and m columns
D is p rows and r columns
C is r rows and r columns
with m>p,r


e.g:
m=6,
p=2
r=3

Z=matrix(c(1,.2,.5,.2,1,.45,.5,.45,1),3,3)
X=matrix(c(.1,.3,.5,.6,.2,.1,.8,1,.4,.2,.2,.9),2,6)
W=matrix(c(0,.8,.4,.6,.2,0),2,3)

#Create a matrix satisfying (1) is easy:

A=matrix(runif(18),6,3)
Q1=svd(A)$u%*%chol(Z)


#For the second condition (2), a solution is given by

Q2=A%*%ginv(X%*%A)%*%W





I do not know how to create a matrix Q that satisfies the two 
conditions.  I have try to construct an iterative procedure without success 
(no convergence):

eps=10
i=0
while(eps>.5)
{
Q1=svd(Q2)$u%*%chol(Z)
Q2=Q1%*%ginv(X%*%Q1)%*%W
eps=sum(abs(Q1-Q2))
cat(i,":",eps,"\n")
i=i+1
}

Perhaps someone could have any idea to solve the problem, or a reference on 
this kind of question or the email of another list where I should ask this 
question.

Thanks in advance,

Sincerely.

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From andy_liaw at merck.com  Wed Jul  7 00:35:24 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jul 2004 18:35:24 -0400
Subject: [R] Code density functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FE1@usrymx25.merck.com>

Dear <insert your name here>:

You need to look at the C-level source codes, in R-1.9.1/src/nmath/d*.c.

Andy

> From: F Z
> 
> Hello
> 
> I would like to see the algorithm that R uses to generate 
> density functions 
> for several distributions (i.e. Normal,Weibull, etc).  I tried:
> 
> >dnorm
> function (x, mean = 0, sd = 1, log = FALSE)
> .Internal(dnorm(x, mean, sd, log))
> <environment: namespace:stats>
> 
> How can I see the code used for densities?
> 
> Thanks!



From ligges at statistik.uni-dortmund.de  Wed Jul  7 00:57:58 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 Jul 2004 00:57:58 +0200
Subject: [R] Download Info
In-Reply-To: <40EA59DC.3020808@itp.phys.ethz.ch>
References: <40EA59DC.3020808@itp.phys.ethz.ch>
Message-ID: <40EB2E76.2080105@statistik.uni-dortmund.de>

Diethelm Wuertz wrote:

> Maybe somebody can help me with the following questions:
> 
> I have submitted Rmetrics to the CRAN server and was looking what happened.
> 
> 1)  The */contrib/checkSummary.html shows a table which reports the 
> daily package check results.
> For my packages there is no entry in the column "r-devel", the other 
> packages have "OK" or "WARN".
> What does it mean?

When you looked, it was not updated so far .... (but now it is).


> 2) The link to the Mac OSX check summaryseems to be broken?
> The requested URL /bin/macosx/r-devel/check/checkSummaryOSX.html was not 
> found on this server.
> So I couldn't check why one of the packages (fSeries) is missing in the 
> MacOSX  binary package
> directory.

Stefano?


> 3)  For other packages, e.g. for "gbm", on the package download page 
> there are
> 
> Package source:     gbm_1.2.tar.gz <../gbm_1.2.tar.gz>
> MacOS X binary:     gbm_1.1-2.tgz 
> <../../../bin/macosx/r-release/gbm_1.1-2.tgz>
> Windows binary:     gbm_1.2.zip 
> <../../../bin/windows/contrib/r-release/gbm_1.2.zip>
> Index of contents:     gbm.INDEX
> Reference manual:     gbm.pdf <../../../doc/packages/gbm.pdf>
> 
> 
> In my case there are only the "Package source" file and the "Reference 
> manual" link. What I have to do
> that also the other links appear on this page?
> 

Just wait for the CRAN files to be synced. Before that stuff can be 
displayed, it must be uploaded to CRAN, mirrored, and changes must 
reflected in the index by regenerating it (just manually initiated by 
Fritz).

Uwe Ligges


> Many thanks in advance Diethelm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From roebuck at odin.mdacc.tmc.edu  Wed Jul  7 01:50:58 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Tue, 6 Jul 2004 18:50:58 -0500 (CDT)
Subject: [R] Enumeration in R
Message-ID: <Pine.OSF.4.58.0407061527220.265315@odin.mdacc.tmc.edu>

I want the equivalent of this 'C' declaration.
    enum StoplightColor {
        green = 3,
        yellow = 5,
        red = 7
    };

This mostly works except the validity checking doesn't
seem to occur automatically. What didn't I do to enable
it?

setClass("stoplightColor",
         representation(value = "integer"),
         prototype = integer(1))
stoplightColor <- function(value) {
    if (missing(value))
        stop('no value!')
    new("stoplightColor", value)
}
valid.stoplightColor <- function(object) {
    valid <- switch(as(object at value, "character"),
                    "3" = TRUE,
                    "5" = TRUE,
                    "7" = TRUE,
                    FALSE)
    if (valid == FALSE)
        return("Value not in list of valid values [3|5|7]");
    return(TRUE);
}
setValidity("stoplightColor", valid.stoplightColor)
initialize.stoplightColor <- function(.Object, value) {
    .Object at value <- as.integer(value)
    .Object
}
setMethod("initialize",
          signature(.Object = "stoplightColor"),
          initialize.stoplightColor)
green <- stoplightColor(3)
yellow <- stoplightColor(5)
red <- stoplightColor(7)

# error: no value argument
noarg <- stoplightColor()

# error: invalid number argument
bad <- stoplightColor(6)      # WHY NO WARNING HERE?
validObject(bad)


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From p.dalgaard at biostat.ku.dk  Wed Jul  7 02:44:25 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Jul 2004 02:44:25 +0200
Subject: [R] Enumeration in R
In-Reply-To: <Pine.OSF.4.58.0407061527220.265315@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0407061527220.265315@odin.mdacc.tmc.edu>
Message-ID: <x2y8lwodcm.fsf@biostat.ku.dk>

Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:

> I want the equivalent of this 'C' declaration.
>     enum StoplightColor {
>         green = 3,
>         yellow = 5,
>         red = 7
>     };
> 
> This mostly works except the validity checking doesn't
> seem to occur automatically. What didn't I do to enable
> it?

I think you *dis*abled it by specifying an initializer which doesn't
check the validity:

> initialize.stoplightColor <- function(.Object, value) {
>     .Object at value <- as.integer(value)
>     .Object
> }

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From gerifalte28 at hotmail.com  Wed Jul  7 03:35:52 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Wed, 07 Jul 2004 01:35:52 +0000
Subject: [R] Code density functions
Message-ID: <BAY2-F32VkDpY5GT9Ie00015351@hotmail.com>

Dear Andy

Thanks for your reply.  I don't seem to find the file that you suggested. I 
tried:

>file.show('C:/Program Files/R/rw1091/src/nmath/dnorm.c.')
NULL
Warning message:
file.show(): file C:/Program Files/R/rw1091/src/nmath/dnorm.c. does not 
exist

Then I looked at the directory and tried a file with similar name:

>file.show('C:/Program Files/R/rw1091/src/include/Rmath.h')

But this file does not show the actual code used to calculate the densities, 
only the declarations of the procedures.

What am I doing wrong?

Thanks again!

Francisco Zagmutt :)


>From: "Liaw, Andy" <andy_liaw at merck.com>
>To: "'F Z'" <gerifalte28 at hotmail.com>,R-help at stat.math.ethz.ch
>Subject: RE: [R] Code density functions
>Date: Tue, 6 Jul 2004 18:35:24 -0400
>
>Dear <insert your name here>:
>
>You need to look at the C-level source codes, in R-1.9.1/src/nmath/d*.c.
>
>Andy
>
> > From: F Z
> >
> > Hello
> >
> > I would like to see the algorithm that R uses to generate
> > density functions
> > for several distributions (i.e. Normal,Weibull, etc).  I tried:
> >
> > >dnorm
> > function (x, mean = 0, sd = 1, log = FALSE)
> > .Internal(dnorm(x, mean, sd, log))
> > <environment: namespace:stats>
> >
> > How can I see the code used for densities?
> >
> > Thanks!
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains 
>information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New 
>Jersey, USA 08889), and/or its affiliates (which may be known outside the 
>United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
>Banyu) that may be confidential, proprietary copyrighted and/or legally 
>privileged. It is intended solely for the use of the individual or entity 
>named on this message.  If you are not the intended recipient, and have 
>received this message in error, please notify us immediately by reply 
>e-mail and then delete it from your system.
>------------------------------------------------------------------------------



From spencer.graves at pdf.com  Wed Jul  7 06:00:10 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 Jul 2004 21:00:10 -0700
Subject: [R] Generate a matrix Q satisfying t(Q)%*%Q=Z and XQ=W
In-Reply-To: <5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
References: <5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
Message-ID: <40EB754A.4030909@pdf.com>

      Is a solution even possible for the matrices in your example?  
I've tried a few things that have suggested that a solution may not be 
possible. 

      What can you tell us of the problem that you've translated into 
this?  I see a minimization problem subject to constraints, but I'm not 
certain which are the constraints and what is the objective function.  
For example, are you trying to find Q to minimize sum((Z-X'X)^2) subject 
to XQ=W or do you want to minimize sum((XQ-W)^2) subject to Q'Q=Z or 
something else? 

      If it were my problem, I think I would work for a while with the 
singular value decompositions of X, W and Z, and see if that would lead 
me to more information about Q, including conditions under which a 
solution existed, expressions for Q when multiple solutions existed, and 
a solution minimizing your chosen objective function when solutions do 
not exist.  (A google search produced many hits for "singular value 
decomposition", implemented as "svd" in R.) 

      hope this helps.  spencer graves    

Stephane DRAY wrote:

> Hello,
> I have a question that is not directly related to R ... but I try to 
> do it in R ;-) :
>
> I would like to generate a matrix Q satisfying (for a given Z, X and 
> W) the two following conditions:
>
> t(Q)%*%Q=Z  (1)
> XQ=W (2)
>
> where:
> Q is m rows and r columns
> X is p rows and m columns
> D is p rows and r columns
> C is r rows and r columns
> with m>p,r
>
>
> e.g:
> m=6,
> p=2
> r=3
>
> Z=matrix(c(1,.2,.5,.2,1,.45,.5,.45,1),3,3)
> X=matrix(c(.1,.3,.5,.6,.2,.1,.8,1,.4,.2,.2,.9),2,6)
> W=matrix(c(0,.8,.4,.6,.2,0),2,3)
>
> #Create a matrix satisfying (1) is easy:
>
> A=matrix(runif(18),6,3)
> Q1=svd(A)$u%*%chol(Z)
>
>
> #For the second condition (2), a solution is given by
>
> Q2=A%*%ginv(X%*%A)%*%W
>
>
>
>
>
> I do not know how to create a matrix Q that satisfies the two 
> conditions.  I have try to construct an iterative procedure without 
> success (no convergence):
>
> eps=10
> i=0
> while(eps>.5)
> {
> Q1=svd(Q2)$u%*%chol(Z)
> Q2=Q1%*%ginv(X%*%Q1)%*%W
> eps=sum(abs(Q1-Q2))
> cat(i,":",eps,"\n")
> i=i+1
> }
>
> Perhaps someone could have any idea to solve the problem, or a 
> reference on this kind of question or the email of another list where 
> I should ask this question.
>
> Thanks in advance,
>
> Sincerely.
>
> St??phane DRAY
> -------------------------------------------------------------------------------------------------- 
>
> D??partement des Sciences Biologiques
> Universit?? de Montr??al, C.P. 6128, succursale centre-ville
> Montr??al, Qu??bec H3C 3J7, Canada
>
> Tel : 514 343 6111 poste 1233
> E-mail : stephane.dray at umontreal.ca
> -------------------------------------------------------------------------------------------------- 
>
> Web                                          
> http://www.steph280.freesurf.fr/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Jul  7 07:51:35 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 Jul 2004 07:51:35 +0200
Subject: [R] Code density functions
In-Reply-To: <BAY2-F32VkDpY5GT9Ie00015351@hotmail.com>
References: <BAY2-F32VkDpY5GT9Ie00015351@hotmail.com>
Message-ID: <40EB8F67.4010608@statistik.uni-dortmund.de>

F Z wrote:
> Dear Andy
> 
> Thanks for your reply.  I don't seem to find the file that you 
> suggested. I tried:
> 
>> file.show('C:/Program Files/R/rw1091/src/nmath/dnorm.c.')

You have installed a binary distribution.
You need to get the source tarball (directly accessible via the main 
CRAN page) that includes the file.

Uwe Ligges



> NULL
> Warning message:
> file.show(): file C:/Program Files/R/rw1091/src/nmath/dnorm.c. does not 
> exist
> 
> Then I looked at the directory and tried a file with similar name:
> 
>> file.show('C:/Program Files/R/rw1091/src/include/Rmath.h')
> 
> 
> But this file does not show the actual code used to calculate the 
> densities, only the declarations of the procedures.
> 
> What am I doing wrong?
> 
> Thanks again!
> 
> Francisco Zagmutt :)
> 
> 
>> From: "Liaw, Andy" <andy_liaw at merck.com>
>> To: "'F Z'" <gerifalte28 at hotmail.com>,R-help at stat.math.ethz.ch
>> Subject: RE: [R] Code density functions
>> Date: Tue, 6 Jul 2004 18:35:24 -0400
>>
>> Dear <insert your name here>:
>>
>> You need to look at the C-level source codes, in R-1.9.1/src/nmath/d*.c.
>>
>> Andy
>>
>> > From: F Z
>> >
>> > Hello
>> >
>> > I would like to see the algorithm that R uses to generate
>> > density functions
>> > for several distributions (i.e. Normal,Weibull, etc).  I tried:
>> >
>> > >dnorm
>> > function (x, mean = 0, sd = 1, log = FALSE)
>> > .Internal(dnorm(x, mean, sd, log))
>> > <environment: namespace:stats>
>> >
>> > How can I see the code used for densities?
>> >
>> > Thanks!
>>
>>
>> ------------------------------------------------------------------------------ 
>>
>> Notice:  This e-mail message, together with any attachments, contains 
>> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, 
>> New Jersey, USA 08889), and/or its affiliates (which may be known 
>> outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD 
>> and in Japan, as Banyu) that may be confidential, proprietary 
>> copyrighted and/or legally privileged. It is intended solely for the 
>> use of the individual or entity named on this message.  If you are not 
>> the intended recipient, and have received this message in error, 
>> please notify us immediately by reply e-mail and then delete it from 
>> your system.
>> ------------------------------------------------------------------------------ 
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Jul  7 09:15:44 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 Jul 2004 09:15:44 +0200
Subject: [R] Factors.
In-Reply-To: <1088677212.40e3e55c65348@webmail2.portugalmail.pt>
References: <1088677212.40e3e55c65348@webmail2.portugalmail.pt>
Message-ID: <40EBA320.3070401@statistik.uni-dortmund.de>

[last week,] assuncao.senra at portugalmail.com wrote:

> Hello,
> 
> I'm new with R. I need some help; I have a matrix of data to wich i want to 
> apply the function dudi.acm to perform multiple correspondence analysis. 
> However to use it all variables must be factors, so how can i turn each column 
> of the matrix into a factor? I've tried as.factor. It works isolated for each 
> column, but when I form the matrix of all factors it doesnt work.
> Please help me!
> 

[Looks like there was no answer until now.]

a) Please tell us which package the functions you are using are in (I 
know, it is ade4).
b) Please follow the posting guide which tells you some more things 
(which are not *that* important here).
c) Please read the help page! ?dudi.acm tells you
"df, df1, df2: data frames containing only factors"
                ^^^^^^^^^^^
You cannot have a matrix of factors, because the required attributes 
cannot be set for each column separately. Instead, use a data.frame.

Uwe Ligges



From vito_ricci at yahoo.com  Wed Jul  7 09:30:54 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Wed, 7 Jul 2004 09:30:54 +0200 (CEST)
Subject: [R] Daily time series
Message-ID: <20040707073054.77705.qmail@web41210.mail.yahoo.com>

Hi, 

I'm dealing with time series with 1 observaton for day
(data sampled daily). I will create a ts object using
that time series and the function ts(). 
In ts() help is written:

The value of argument 'frequency' is used when the
series is sampled an integral number of times in each
unit time interval. For example, one could use a value
of '7' for 'frequency' when the data are sampled
daily, and the natural time period is a week, or '12'
when the data are sampled monthly and the natural time
period
is a year.  Values of '4' and '12' are assumed in
(e.g.) 'print' methods to imply a quarterly and
monthly series respectively.

But what value should assume start in ts function?

Here is a time series:

1/1 10
2/1 20
3/1 30
4/1 40
5/1 50
6/1 60

x<-c(10,20,30,40,50,60) ## observation
serie<-ts(dati, start=c(1,1),frequency=7) ##creating
ts object

serie  ## printing ts output

Time Series:
Start = c(1, 1) 
End = c(1, 6) 
Frequency = 7 
[1] 10 20 30 40 50 60

Could someone help me?

Thanks in advance.

Sincerely.
Vito Ricci


=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From Tristan.Lefebure at univ-lyon1.fr  Wed Jul  7 10:33:58 2004
From: Tristan.Lefebure at univ-lyon1.fr (Lefebure Tristan)
Date: Wed, 7 Jul 2004 10:33:58 +0200
Subject: [R] boxplot a list of objects
Message-ID: <200407071033.58643.lefebure@univ-lyon1.fr>

Hi list,

#Imagine we have vectors of different length (in practice 100 vectors):
a<-c(1:10)
b<-c(1:20)
c<-c(1:30)

#then we got a list of the names of those objects:

list<-c("a","b","c")

#I don't find how to boxplot them using a less stupid way than :

boxplot(get(list[1]),get(list[2]),get(list[3]))


Thanks for any advice !


-- 
------------------------------------------------------------
Tristan LEFEBURE
Laboratoire d'??cologie des hydrosyst??mes fluviaux (UMR 5023)
Universit?? Lyon I - Campus de la Doua
6 rue Dubois 69622 Villeurbanne - France

Phone: (33) (0)4 72 43 29 45
Fax: (33) (0)4 72 43 15 23



From hb at brueckner-keutmann.de  Wed Jul  7 10:48:17 2004
From: hb at brueckner-keutmann.de (Brueckner-Keutmann-GbR)
Date: Wed, 7 Jul 2004 10:48:17 +0200
Subject: [R] Howto debug R on Windows XP?
Message-ID: <DGENIJKPJBBNIGMHCNIAKEALCAAA.hb@brueckner-keutmann.de>

Hello,

I start working with R and I have tried to debug R on a Windows XP system.
Unfortunately I am not able to set a breakpoint in the package SJava, which
I am interested in.
So far I succeed to compile R with the "DEBUG=T" option, and followed the
hints given in the manual/FAQs about debugging.
After starting the gdb, I also succeed with

> break WinMain
> run

so that the program stops there. The debugger is also
able to find und list the function "R_ReadConsole", but the command

> break R_ReadConsole

is replied:

"Cannot access memory at address 0x1e6a0"

Can anybody give a hint how to continue?

My motivation is to use the SJava package and to continue the work Jens
Oehlschlaegel and Ingo von Otte started with.

Thanks for your help!

Herbert Br??ckner



From uth at zhwin.ch  Wed Jul  7 10:48:54 2004
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Wed, 7 Jul 2004 10:48:54 +0200
Subject: AW: [R] boxplot a list of objects
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F258B2F@langouste.zhwin.ch>


One possibility ist

boxplot(sapply(ListOfNames, get, env = .GlobalEnv))

Hope that this helps

Thomas


-----Urspr??ngliche Nachricht-----
Von: Lefebure Tristan [mailto:Tristan.Lefebure at univ-lyon1.fr] 
Gesendet: Mittwoch, 7. Juli 2004 10:34
An: r-help at stat.math.ethz.ch
Betreff: [R] boxplot a list of objects


Hi list,

#Imagine we have vectors of different length (in practice 100 vectors):
a<-c(1:10)
b<-c(1:20)
c<-c(1:30)

#then we got a list of the names of those objects:

list<-c("a","b","c")

#I don't find how to boxplot them using a less stupid way than :

boxplot(get(list[1]),get(list[2]),get(list[3]))


Thanks for any advice !


-- 
------------------------------------------------------------
Tristan LEFEBURE
Laboratoire d'??cologie des hydrosyst??mes fluviaux (UMR 5023) Universit?? Lyon I - Campus de la Doua 6 rue Dubois 69622 Villeurbanne - France

Phone: (33) (0)4 72 43 29 45
Fax: (33) (0)4 72 43 15 23

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From hb at brueckner-keutmann.de  Wed Jul  7 10:50:18 2004
From: hb at brueckner-keutmann.de (Brueckner-Keutmann-GbR)
Date: Wed, 7 Jul 2004 10:50:18 +0200
Subject: [R] AW: Howto debug R on Windows XP?
In-Reply-To: <DGENIJKPJBBNIGMHCNIAKEALCAAA.hb@brueckner-keutmann.de>
Message-ID: <DGENIJKPJBBNIGMHCNIAOEALCAAA.hb@brueckner-keutmann.de>



-----Urspr??ngliche Nachricht-----
Von: Brueckner-Keutmann-GbR [mailto:hb at brueckner-keutmann.de]
Gesendet: Wednesday, July 07, 2004 9:48 AM
An: R_Help Mailing List
Betreff: Howto debug R on Windows XP?


Hello,

I start working with R and I have tried to debug R on a Windows XP system.
Unfortunately I am not able to set a breakpoint in the package SJava, which
I am interested in.
So far I succeed to compile R with the "DEBUG=T" option, and followed the
hints given in the manual/FAQs about debugging.
After starting the gdb, I also succeed with

> break WinMain
> run

so that the program stops there. The debugger is also
able to find und list the function "R_ReadConsole", but the command

> break R_ReadConsole

is replied:

"Cannot access memory at address 0x1e6a0"

Can anybody give a hint how to continue?

My motivation is to use the SJava package and to continue the work Jens
Oehlschlaegel and Ingo von Otte started with.

Thanks for your help!

Herbert Br??ckner



From danbebber at forestecology.co.uk  Wed Jul  7 11:39:40 2004
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Wed, 7 Jul 2004 10:39:40 +0100
Subject: [R] Random intercept model with time-dependent covariates,
	results different from SAS
In-Reply-To: <200407041004.i64A27Xk016305@hypatia.math.ethz.ch>
Message-ID: <008401c46406$5322fdc0$442501a3@plants.ox.ac.uk>

Hello,
I have been struggling with a similar problem, i.e. fitting an LME model to
unbalanced repeated measures data.
I found "Linear Mixed Models" by John Fox
(http://socserv2.socsci.mcmaster.ca/jfox/Books/Companion/appendix-mixed-mode
ls.pdf)
quite helpful.
Fox gives examples which are unbalanced, so I guess that balance is not a
requirement (assuming Fox is correct). However, the sample sizes are large
compared to yours (and mine), which may make a difference.

Dan Bebber

____________________________
Dr. Daniel P. Bebber
Department of Plant Sciences
University of Oxford
South Parks Road
Oxford
OX1 3RB
Tel. 01865 275060
Web. http://www.forestecology.co.uk/

"Data, data, data!" he cried impatiently. "I can't make bricks without
clay"
- Sherlock Holmes, The Adventure of the Copper Beeches, 1892



> Message: 24
> Date: Sun,  4 Jul 2004 19:21:32 +1000
> From: Keith Wong <keithw at med.usyd.edu.au>
> Subject: Re: [R] Random intercept model with time-dependent covariates,
results different from AS
> To: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Cc: r-help at stat.math.ethz.ch
> Message-ID: <1088932892.40e7cc1c8c24d at www.mail.med.usyd.edu.au>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Thank you for the very prompt response. I only included a small
> part of the
> output to make the message brief. I'm sorry it did not provide
> enough detail to
> answer my question. I have appended the summary() and anova()
> outputs to the
> two models I fitted in R.
>
> Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>
> > Looking at the significance of a main effect (group) in the
> presence of an
> > interaction (time:group) is hard to interpret, and in your case
> is I think
> > not even interesting.  (The `main effect' probably represents difference
> > in intercept for the time effect, that is the group difference
> at the last
> > time.  But see the next para.)  Note that the two systems are returning
> > different denominator dfs.
>
>
> I take your point that the main effect is probably not interesting in the
> presence of an interaction. I was checking the results for
> consistency to see
> if I was doing the right thing. I was not 100% sure that the SAS
> code was in
> itself correct.
>
> > At this point you have not told us enough.  My guess is that you have
> > complete balance with the same number of subjects in each
> group.  In that
> > case the `group' effect is in the between-subjects stratum (as
> defined for
> > the use of Error in aov, which you could also do), and thus R's 11 df
> > would be right (rather than 44, without W and Z).  Without balance Type
> > III tests get much harder to interpret and the `group' effect
> would appear
> > in two strata and there is no simple F test in the classical theory.  So
> > further guessing, SAS may have failed to detect balance and so used the
> > wrong test.
>
> I had not appreciated the need for balance: in actual fact, one
> group has 5
> subjects and the other 7. Will this be a problem? Would the R
> analysis still be
> valid in that case?
>
>
> > The time-dependent covariates muddy the issue more, and I
> looked mainly at
> > the analyses without them.  Again, a crucial fact is not here: do the
> > covariates depend on the subjects as well?
>
> Yes the covariates are measures of blood pressure and pulse, and
> they depend on
> the subjects as well.
>
> > The good news is that the results _are_ similar.  You do have different
> > time behaviour in the two groups.  So stop worrying about tests of
> > uninteresting hypotheses and concentrate of summarizing that difference.
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
> Thank you. I was concerned that one or both methods were
> incorrect given the
> results were inconsistent. Perhaps reassuringly, the parameter
> estimates for
> the fixed effects in both SAS and R were the same.
>
> Is the model specification OK for the model with just time, group
> and their
> interaction?
> Is the model specification with the 2 time dependent covariates
> appropriate?
>
> Once again, I'm very grateful for the time you've taken to answer
> my questions.
>
> Keith
>
> [Output from the 2 models fitted in R follows]
>
> > g1 = lme(Y ~ time + group + time:group, random = ~ 1 | id, data
> = datamod)
>
> > anova(g1)
>             numDF denDF   F-value p-value
> (Intercept)     1    44  3.387117  0.0725
> time            4    44 10.620547  <.0001
> group           1    11  0.508092  0.4908
> time:group      4    44  3.961726  0.0079
> > summary(g1)
> Linear mixed-effects model fit by REML
>  Data: datamod
>        AIC      BIC    logLik
>   372.4328 396.5208 -174.2164
>
> Random effects:
>  Formula: ~1 | id
>         (Intercept) Residual
> StdDev:    11.05975 3.228684
>
> Fixed effects: Y ~ time + group + time:group
>               Value Std.Error DF   t-value p-value
> (Intercept)   8.250  4.073428 44  2.025321  0.0489
> time1        -0.250  1.614342 44 -0.154862  0.8776
> time2        -8.125  1.614342 44 -5.033011  0.0000
> time3        -8.875  1.614342 44 -5.497596  0.0000
> time4        -4.250  1.614342 44 -2.632652  0.0116
> group1        2.126  6.568205 11  0.323681  0.7523
> time1:group1 -2.734  2.603048 44 -1.050307  0.2993
> time2:group1  5.583  2.603048 44  2.144793  0.0375
> time3:group1  5.549  2.603048 44  2.131732  0.0387
> time4:group1  3.634  2.603048 44  1.396056  0.1697
>  Correlation:
>              (Intr) time1  time2  time3  time4  group1 tm1:g1
> tm2:g1 tm3:g1
> time1        -0.198
>
> time2        -0.198  0.500
>
> time3        -0.198  0.500  0.500
>
> time4        -0.198  0.500  0.500  0.500
>
> group1       -0.620  0.123  0.123  0.123  0.123
>
> time1:group1  0.123 -0.620 -0.310 -0.310 -0.310 -0.198
>
> time2:group1  0.123 -0.310 -0.620 -0.310 -0.310 -0.198  0.500
>
> time3:group1  0.123 -0.310 -0.310 -0.620 -0.310 -0.198  0.500
> 0.500
> time4:group1  0.123 -0.310 -0.310 -0.310 -0.620 -0.198  0.500
> 0.500  0.500
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.63416413 -0.42033405  0.03577472  0.46164486  1.74068368
>
> Number of Observations: 65
> Number of Groups: 13
>
>
> > g2 = lme(Y ~ time + group + time:group + W + Z, random = ~ 1 |
> id, data =
> datamod)
>
> > anova(g2)
>             numDF denDF  F-value p-value
> (Intercept)     1    42  5.54545  0.0233
> time            4    42 16.41069  <.0001
> group           1    11  0.83186  0.3813
> W               1    42  0.07555  0.7848
> Z               1    42 45.23577  <.0001
> time:group      4    42  3.04313  0.0273
>
> > summary(g2)
> Linear mixed-effects model fit by REML
>  Data: datamod
>        AIC      BIC    logLik
>   355.2404 382.8245 -163.6202
>
> Random effects:
>  Formula: ~1 | id
>         (Intercept) Residual
> StdDev:    8.639157 2.597380
>
> Fixed effects: Y ~ time + group + time:group + W + Z
>                  Value Std.Error DF   t-value p-value
> (Intercept)  10.056433  9.583658 42  1.049331  0.3000
> time1         0.209668  1.301306 42  0.161121  0.8728
> time2         4.111435  2.556420 42  1.608278  0.1153
> time3         0.423056  2.077066 42  0.203679  0.8396
> time4        -3.976417  1.300572 42 -3.057437  0.0039
> group1        4.677706  5.162006 11  0.906180  0.3843
> W             0.377142  0.127146 42  2.966212  0.0050
> Z            -0.531895  0.093276 42 -5.702395  0.0000
> time1:group1 -0.845857  2.126289 42 -0.397809  0.6928
> time2:group1 -5.145361  2.962470 42 -1.736848  0.0897
> time3:group1 -3.261241  2.597008 42 -1.255769  0.2161
> time4:group1  4.153245  2.096587 42  1.980956  0.0542
>  Correlation:
>              (Intr) time1  time2  time3  time4  group1 W      Z
>    tm1:g1
> tm2:g1
> time1        -0.051
>
>
> time2         0.199  0.308
>
>
> time3         0.023  0.361  0.817
>
>
> time4        -0.029  0.501  0.293  0.342
>
>
> group1       -0.202  0.131  0.136  0.146  0.129
>
>
> W            -0.790  0.019  0.243  0.366 -0.015  0.044
>
>
> Z            -0.146 -0.063 -0.853 -0.779 -0.041 -0.086 -0.409
>
>
> time1:group1 -0.028 -0.601 -0.043 -0.074 -0.302 -0.187  0.147
> -0.144
>
> time2:group1 -0.293 -0.262 -0.818 -0.642 -0.255 -0.198 -0.051
> 0.665  0.276
>
> time3:group1 -0.016 -0.286 -0.626 -0.774 -0.273 -0.214 -0.277
> 0.590  0.308
> 0.668
> time4:group1  0.065 -0.306 -0.116 -0.159 -0.616 -0.199  0.002
> -0.046  0.497
> 0.318
>              tm3:g1
> time1
> time2
> time3
> time4
> group1
> W
> Z
> time1:group1
> time2:group1
> time3:group1
> time4:group1  0.376
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.11181231 -0.43210237  0.04949838  0.32444580  2.77710590
>
> Number of Observations: 65
> Number of Groups: 13
> >
>
>
>
> ------------------------------
>
> Message: 25
> Date: Sun, 4 Jul 2004 10:24:47 +0100 (BST)
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Subject: Re: [R] Re: Seasonal ARMA model
> To: Ajay Shah <ajayshah at mayin.org>
> Cc: r-help at stat.math.ethz.ch
> Message-ID: <Pine.LNX.4.44.0407041021440.9904-100000 at gannet.stats>
> Content-Type: TEXT/PLAIN; charset=US-ASCII
>
> On Sun, 4 Jul 2004, Ajay Shah wrote:
>
> > > It might clarify your thinking to note that a seasonal ARIMA model
> > > is just an ``ordinary'' ARIMA model with some coefficients
> > > constrained to be 0 in an efficient way.  E.g.  a seasonal AR(1) s =
> > > 4 model is the same as an ordinary (nonseasonal) AR(4) model with
> > > coefficients theta_1, theta_2, and theta_3 constrained to be 0.  You
> > > can get the same answer as from a seasonal model by using the
> > > ``fixed'' argument to arima.  E.g.:
> >
> >    set.seed(42)
> >    x <- arima.sim(list(ar=c(0,0,0,0.5)),300)
> >    f1 = arima(x,seasonal=list(order=c(1,0,0),period=4))
> >    f2 =
> arima(x,order=c(4,0,0),fixed=c(0,0,0,NA,NA),transform.pars=FALSE)
> >
> > Is there a convenient URL which shows the mathematics of the seasonal
> > ARMA model, as implemented by R?
>
> No, but there is a book, MASS4 (see the FAQ).  Although the
> software is in
> base R it was in fact written by me to support MASS4.
>
> R follows S-PLUS in some of its choices of signs, which do differ between
> accounts.
>
> > I understand f2 fine. I understand that you are saying that f1 is just
> > an AR(4) with the lags 1,2,3 constrained to 0. But I'm unable to
> > generalise this. What would be the meaning of mixing up both order and
> > seasonal? E.g. what would it mean to do something like:
> >
> >  arima(x,order=c(2,0,0),seasonal=list(order=c(2,0,0),period=12))
>
> That is in MASS4 and most of the books referenced on the help page.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
>
> ------------------------------
>
> Message: 26
> Date: Sun, 04 Jul 2004 11:38:30 +0200
> From: Peter Mathe <mathe at wias-berlin.de>
> Subject: [R] Is there rpm for suse 9.1 under x86_64?
> To: R-help at stat.math.ethz.ch
> Message-ID: <40E7D016.4060705 at wias-berlin.de>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> I recently upgraded to Suse 9.1 for Amd64.
> So far I could not find precompiled binaries of R-1.9.1 for this case.
> So I tried installation from source, but could not succeed. Although the
> configuration/installation procedure ran without problems, the make
> check always ended with errors. When trying to run R , to see what's
> going on, the eigen() reported error code -18.
> So, is a  rpm for R-base-1.9.1 under x86_64 for Suse available, or how
> can I succesfully install from sources?
> Thank's for reading this message, Peter
>
>
>
> ------------------------------
>
> Message: 27
> Date: 04 Jul 2004 11:53:54 +0200
> From: Peter Dalgaard <p.dalgaard at biostat.ku.dk>
> Subject: Re: [R] Is there rpm for suse 9.1 under x86_64?
> To: Peter Mathe <mathe at wias-berlin.de>
> Cc: R-help at stat.math.ethz.ch
> Message-ID: <x2ekns2j4d.fsf at biostat.ku.dk>
> Content-Type: text/plain; charset=us-ascii
>
> Peter Mathe <mathe at wias-berlin.de> writes:
>
> > I recently upgraded to Suse 9.1 for Amd64.
> > So far I could not find precompiled binaries of R-1.9.1 for this case.
> > So I tried installation from source, but could not succeed. Although
> > the configuration/installation procedure ran without problems, the
> > make check always ended with errors. When trying to run R , to see
> > what's going on, the eigen() reported error code -18.
> > So, is a  rpm for R-base-1.9.1 under x86_64 for Suse available, or how
> > can I succesfully install from sources?
>
> I can't get the upgrade working for me (SATA trouble -- again!) but I
> have 9.0 on a system. This has run cleanly for a while with a
> home-built RPM based on Detlef's SPEC file, as well as several local
> builds.
>
> A good guess is that they upgraded GCC and something got broken --
> again. You could try reducing the optimization levels on the relevant
> files, or as the first thing on everything (-O0 in CFLAGS and FFLAGS).
>
> > Thank's for reading this message, Peter
>
> How did you know I would, Peter? ;-)
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>
>
>
> ------------------------------
>
> _______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE read the posting guide! http://www.R-project.org/posting-guide.html
>
>
> End of R-help Digest, Vol 17, Issue 4
> *************************************
>



From Tristan.Lefebure at univ-lyon1.fr  Wed Jul  7 11:40:13 2004
From: Tristan.Lefebure at univ-lyon1.fr (Lefebure Tristan)
Date: Wed, 7 Jul 2004 11:40:13 +0200
Subject: [R] boxplot a list of objects
In-Reply-To: <53A181E56FB0694ABFD212F8AEDA7F6F258B2F@langouste.zhwin.ch>
References: <53A181E56FB0694ABFD212F8AEDA7F6F258B2F@langouste.zhwin.ch>
Message-ID: <200407071140.13219.lefebure@univ-lyon1.fr>

thanks a lot !

an other simple solution proposed by Stefano Guazzetti is  :
boxplot(list(a, b, c))

(ok I will never use again a function name for an object name)

On Wednesday 07 July 2004 10:48, "Untern??hrer Thomas, uth" wrote:
> One possibility ist
>
> boxplot(sapply(ListOfNames, get, env = .GlobalEnv))
>
> Hope that this helps
>
> Thomas
>
>
> -----Urspr??ngliche Nachricht-----
> Von: Lefebure Tristan [mailto:Tristan.Lefebure at univ-lyon1.fr]
> Gesendet: Mittwoch, 7. Juli 2004 10:34
> An: r-help at stat.math.ethz.ch
> Betreff: [R] boxplot a list of objects
>
>
> Hi list,
>
> #Imagine we have vectors of different length (in practice 100 vectors):
> a<-c(1:10)
> b<-c(1:20)
> c<-c(1:30)
>
> #then we got a list of the names of those objects:
>
> list<-c("a","b","c")
>
> #I don't find how to boxplot them using a less stupid way than :
>
> boxplot(get(list[1]),get(list[2]),get(list[3]))
>
>
> Thanks for any advice !

-- 
------------------------------------------------------------
Tristan LEFEBURE
Laboratoire d'??cologie des hydrosyst??mes fluviaux (UMR 5023)
Universit?? Lyon I - Campus de la Doua
6 rue Dubois 69622 Villeurbanne - France

Phone: (33) (0)4 72 43 29 45
Fax: (33) (0)4 72 43 15 23



From dmurdoch at pair.com  Wed Jul  7 12:20:34 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 07 Jul 2004 06:20:34 -0400
Subject: [R] AW: Howto debug R on Windows XP?
In-Reply-To: <DGENIJKPJBBNIGMHCNIAOEALCAAA.hb@brueckner-keutmann.de>
References: <DGENIJKPJBBNIGMHCNIAKEALCAAA.hb@brueckner-keutmann.de>
	<DGENIJKPJBBNIGMHCNIAOEALCAAA.hb@brueckner-keutmann.de>
Message-ID: <4bjne05hsgveb92mu7c1dcqbftodc117nt@4ax.com>

On Wed, 7 Jul 2004 10:50:18 +0200, "Brueckner-Keutmann-GbR"
<hb at brueckner-keutmann.de> wrote:

>
>-----Urspr??ngliche Nachricht-----
>Von: Brueckner-Keutmann-GbR [mailto:hb at brueckner-keutmann.de]
>Gesendet: Wednesday, July 07, 2004 9:48 AM
>An: R_Help Mailing List
>Betreff: Howto debug R on Windows XP?
>
>
>Hello,
>
>I start working with R and I have tried to debug R on a Windows XP system.
>Unfortunately I am not able to set a breakpoint in the package SJava, which
>I am interested in.
>So far I succeed to compile R with the "DEBUG=T" option, and followed the
>hints given in the manual/FAQs about debugging.
>After starting the gdb, I also succeed with
>
>> break WinMain
>> run
>
>so that the program stops there. The debugger is also
>able to find und list the function "R_ReadConsole", but the command
>
>> break R_ReadConsole
>
>is replied:
>
>"Cannot access memory at address 0x1e6a0"
>
>Can anybody give a hint how to continue?
>
>My motivation is to use the SJava package and to continue the work Jens
>Oehlschlaegel and Ingo von Otte started with.

I've written some web pages about debugging in R that are mostly
oriented towards Windows users.  Go to
http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR  I'm not
sure what's going wrong for you, but you're not doing things the way I
would.

These web pages are quite new; please let me know what is missing or
unclear.

Duncan Murdoch



From wuertz at itp.phys.ethz.ch  Wed Jul  7 12:51:56 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Wed, 07 Jul 2004 10:51:56 +0000
Subject: [R] Rmetrics Documentation Update
Message-ID: <40EBD5CC.5070504@itp.phys.ethz.ch>


I like to announce that some of the Rmetrics
Documents have been updated to Version
R 191.10057

    Rmetrics Flyer: 
http://www.itp.phys.ethz.ch/econophysics/R/pdf/DocRmetrics.pdf
    Rmetrics Fact Sheet: 
http://www.itp.phys.ethz.ch/econophysics/R/pdf/DocFactsheet.pdf
    Rmetrics Reference Card: 
http://www.itp.phys.ethz.ch/econophysics/R/pdf/DocRefcard.pdf

Unfortunately, the User Guides are still behind, having Version No 1.8.1.
They will be updated in the near future.
   
Best Regards

Diethelm



From Ted.Harding at nessie.mcc.ac.uk  Wed Jul  7 12:56:13 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 07 Jul 2004 11:56:13 +0100 (BST)
Subject: [R] Converting S-Plus Libraries to R
In-Reply-To: <14037.1089122091@www26.gmx.net>
Message-ID: <XFMail.040707115613.Ted.Harding@nessie.mcc.ac.uk>

On 06-Jul-04 schimpanski at gmx.de wrote:
> Dear all!
> 
> I'd like to do multiple imputation of missing values with s-plus
> libraries that are provided by Shafer
> (http://www.stat.psu.edu/~jls/misoftwa.html).
> I wonder, whether these libraries are compatible or somehow convertible
> to R (because I don't have S-plus), so that I can use this functions
> using the R Program.
> 
> I would be happy if you could tell me,
> -if it is possible to use S-plus libraries with R
> -if yes, how I can use the S-Plus libraries in R
> 
> Thank you very much,
> 
> Will

Schafer's multiple imputation libraries for S-Plus, on his website,
are CAT, NORM, MIX and PAN.

These have all been converted to R libraries, by various people.
Go to

  http://www.r-project.org

and then, via "CRAN", to any convenient CRAN site, e.g.

  http://cran.at.r-project.org/

and then go to "Packages", which will take you to

  http://cran.at.r-project.org/src/contrib/PACKAGES.html

where you will find a list of all extra libraries. In this list
you will find "cat", "norm", "mix" and "pan", and each of these
will take you to a page for the package in question from which
you can download either the R source of the package or a compiled
binary version for Windows or Mac OX-X, as well as the reference
manual for the package in PDF format which summarises usage and
provides examples of usage with supplied example datasets.

As a general rule, the packages should work exactly as Schafer
intended; any modifications introduced in the R versions are there
either to avoid problems due to differences between R and S-plus,
or to evade bugs or problems which may have been detected in Schafer's
original software.

These packages have been created directly from the S-plus code on
Schafer's website. They have counterparts in the S-plus library
"missing", whose routines are based on Schafer's originals.
For "cat", "norm" and "mix" the corresponding S-plus routines
are in the "Loglin", "Gauss" and "Cgm" [conditional gaussian model]
families of routines in the S-plus "missing" library. I'm not sure
about what corresponds to "pan". Nor am I sure what differences from
Schafer's original public-domain software may have been introduced
when the S-plus library was created.

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 07-Jul-04                                       Time: 11:56:13
------------------------------ XFMail ------------------------------



From bsl8096 at liverpool.ac.uk  Wed Jul  7 13:47:05 2004
From: bsl8096 at liverpool.ac.uk (Brian Lane)
Date: Wed, 07 Jul 2004 12:47:05 +0100
Subject: [R] Using permax with Data Frame Containing Missing Values
Message-ID: <12665171.1089204425@182105-93607r.liv.ac.uk>

I'm new to this site so I hope this isn't too naive a problem. I'm trying 
to use the permax function with a data frame containing gene expression 
measurements taken from 79 microarray experiments with >3000 genes per 
array. The data contains missing values and every time I use permax with 
the data frame I get the error:

NA/NaN/Inf in foreign function call (arg 1)

Could anyone suggest how I might get round this problem?

Regards,
Brian Lane
Dept of Haematology
University of Liverpool



From amackey at pcbi.upenn.edu  Tue Jul  6 14:17:55 2004
From: amackey at pcbi.upenn.edu (Aaron J. Mackey)
Date: Tue, 6 Jul 2004 08:17:55 -0400
Subject: [R] vectorizing sapply() code (Modified by Aaron J. Mackey)
Message-ID: <53CCF276-D00C-11D8-BD00-000A9577009E@pcbi.upenn.edu>

[ Not sure why, but the first time I sent this it never seemed to go 
through; apologies if you're seeing this twice ... ]

I have some fully functional code that I'm guessing can be done 
better/quicker with some savvy R vector tricks; any help to make this 
run a bit faster would be greatly appreciated; I'm particularly stuck 
on how to calculate using "row-wise" vectors without iterating 
explicitly over the dataframe or table ...

library(stats4);
d <- data.frame( ix=c(0,1,2,3,4,5,6,7),
                  ct=c(253987,  9596, 18680,  2630,  8224,  3590,  5534, 
18937),
                  A=c(      0,     1,     0,     1,     0,     1,     0, 
     1),
                  B=c(      0,     0,     1,     1,     0,     0,     1, 
     1),
                  C=c(      0,     0,     0,     0,     1,     1,     1, 
     1)
                );
ct <- round(logb(length(d$ix), 2))
ll <- function( th=0.5,
                 a1=log(0.5), a2=log(0.5), a3=log(0.5),
                 b1=log(0.5), b2=log(0.5), b3=log(0.5)
               ) {
   a <- exp(sapply(1:ct, function (x) { get(paste("a", x, sep="")) }));
   b <- exp(sapply(1:ct, function (x) { get(paste("b", x, sep="")) }));
   -sum( d$ct * log( sapply( d$ix,
                             function (ix, th, a, b) {
                               x <- d[ix+1,3:(ct+2)]
                               (th     * prod((b ^ (1-x)) * ((1-b) ^ x   
  ))) +
                               ((1-th) * prod((a ^ x    ) * ((1-a) ^ 
(1-x))))
                             },
                             th, a, b
                           )
                   )
   );
}

ml <- mle(ll,
           lower=c(0+1e-5, rep(log(0+1e-8), 2*ct)),
           upper=c(1-1e-5, rep(log(1-1e-8), 2*ct)),
           method="L-BFGS-B"
          );

For those interested in the math, this is the MLE procedure to estimate 
the false positive/false negative rates (a and b) of three diagnostic 
(A, B and C) tests that have the observed performance recapitulated in 
dataframe "d", but no "gold standard" (sometimes called "latent class 
analysis", or LCA).

Thanks for any help,

-Aaron



From rgentlem at jimmy.harvard.edu  Wed Jul  7 13:55:05 2004
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Wed, 7 Jul 2004 07:55:05 -0400
Subject: [R] Using permax with Data Frame Containing Missing Values
In-Reply-To: <12665171.1089204425@182105-93607r.liv.ac.uk>;
	from bsl8096@liverpool.ac.uk on Wed, Jul 07, 2004 at 12:47:05PM
	+0100
References: <12665171.1089204425@182105-93607r.liv.ac.uk>
Message-ID: <20040707075505.G24152@jimmy.harvard.edu>

There is currently no handling of NAs in permax. Your only simple
option is to drop those rows with NA's in them, or to perform some
sort of imputation.

I will mention it to the package's author, 
 Robert

On Wed, Jul 07, 2004 at 12:47:05PM +0100, Brian Lane wrote:
> I'm new to this site so I hope this isn't too naive a problem. I'm trying 
> to use the permax function with a data frame containing gene expression 
> measurements taken from 79 microarray experiments with >3000 genes per 
> array. The data contains missing values and every time I use permax with 
> the data frame I get the error:
> 
> NA/NaN/Inf in foreign function call (arg 1)
> 
> Could anyone suggest how I might get round this problem?
> 
> Regards,
> Brian Lane
> Dept of Haematology
> University of Liverpool
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20                            |
| Harvard School of Public Health  email: rgentlem at jimmy.harvard.edu        |
+---------------------------------------------------------------------------+



From A.McCulloch at socsci.gla.ac.uk  Wed Jul  7 14:15:24 2004
From: A.McCulloch at socsci.gla.ac.uk (Andrew McCulloch)
Date: Wed, 7 Jul 2004 13:15:24 +0100
Subject: [R] Mapinfo mid and mif files
Message-ID: <NGBBKCPDMKCABBEOPADHEEBCCFAA.A.McCulloch@socsci.gla.ac.uk>


Hi ,

	Has anyone any experience of converting Mapinfo mid and mif
files into a format that can be used with the R spatial packages. 
Thanks.

yours sincerely
Andrew McCulloch
Department of Urban Studies
University of Glasgow
G12 8RS



From HDoran at air.org  Wed Jul  7 14:57:15 2004
From: HDoran at air.org (Doran, Harold)
Date: Wed, 7 Jul 2004 08:57:15 -0400
Subject: [R] Creating Binary Outcomes from a continuous variable
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7403E71F3D@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040707/cc87e743/attachment.pl

From Roger.Bivand at nhh.no  Wed Jul  7 15:01:24 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 7 Jul 2004 15:01:24 +0200 (CEST)
Subject: [R] Creating Binary Outcomes from a continuous variable
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7403E71F3D@dc1ex2.air.org>
Message-ID: <Pine.LNX.4.44.0407071501151.6449-100000@reclus.nhh.no>

On Wed, 7 Jul 2004, Doran, Harold wrote:

> Dear List:
> 

?cut

>  
> 
> I have searched the archives and my R books and cannot find a method to
> transform a continuous variable into a binary variable. For example, I
> have test score data along a continuous scale. I want to create a new
> variable in my dataset that is 1=above a cutpoint (or passed the test)
> and 0=otherwise.
> 
>  
> 
> My instinct tells me that this will require a combination of the
> transform command along with a conditional selection. Any help is much
> appreciated.
> 
>  
> 
> Thanks,
> 
> Harold
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From etptupaf at bs.ehu.es  Wed Jul  7 15:01:44 2004
From: etptupaf at bs.ehu.es (F. Tusell)
Date: Wed, 07 Jul 2004 15:01:44 +0200
Subject: [R] Mapinfo mid and mif files
Message-ID: <40EBF438.1040803@bs.ehu.es>

Not sure if it will work straight with .mid or .mif files, but it works 
for me on .tab files, which were
supposed to be read with the Excel map tool package and beleive confro 
to the MapInfo format.

I asked Roger Bivand at the recent useR!2004 meeting and he made several 
suggestions. Following the
leads he gave me, I found a small program (ogr2ogr) which translates my 
.tab files into .shp files,
which I can then read into R. The MapInfo format is explicitly supported.

I use Debian Linux (sarge), and ogr2ogr  is part of the package 
gdal-bin. A batch
file like

for i in *.tab ; do
ogr2ogr ${i%.*}.shp $i ;
done

converted a bunch of files in a snap. Hope it may be of help to you.

ft.

-- 
Fernando TUSELL                                e-mail:
Departamento de Econometr??a y Estad??stica           etptupaf at bs.ehu.es 
Facultad de CC.EE. y Empresariales             Tel:   (+34)94.601.3733
Avenida Lendakari Aguirre, 83                  Fax:   (+34)94.601.3754
E-48015 BILBAO  (Spain)                        Secr:  (+34)94.601.3740



From MSchwartz at MedAnalytics.com  Wed Jul  7 15:03:06 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 07 Jul 2004 08:03:06 -0500
Subject: [R] Creating Binary Outcomes from a continuous variable
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7403E71F3D@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7403E71F3D@dc1ex2.air.org>
Message-ID: <1089205386.16727.123.camel@localhost.localdomain>

On Wed, 2004-07-07 at 07:57, Doran, Harold wrote:
> Dear List:
> 
> I have searched the archives and my R books and cannot find a method to
> transform a continuous variable into a binary variable. For example, I
> have test score data along a continuous scale. I want to create a new
> variable in my dataset that is 1=above a cutpoint (or passed the test)
> and 0=otherwise.

> My instinct tells me that this will require a combination of the
> transform command along with a conditional selection. Any help is much
> appreciated.

Example:

> a <- rnorm(20)
> b <- ifelse(a < 0, 0, 1)

> a
 [1] -1.0735800 -0.6788456  1.9979801 -0.4026760  0.1781791 -1.1540434
 [7] -1.0842728  1.6042602 -0.7950492 -0.1194323  0.4450296  1.9269333
[13] -0.4456181 -0.8374677 -1.1898772  1.7353067  1.8619422 -0.1679996
[19] -0.2656138 -1.5529884
> b
 [1] 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0

HTH,

Marc Schwartz



From Stefano.Guazzetti at ausl.re.it  Wed Jul  7 15:05:15 2004
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Wed, 7 Jul 2004 15:05:15 +0200
Subject: R: [R] Creating Binary Outcomes from a continuous variable
Message-ID: <F298786BF61DE64590054AF31EA1B4C8016D2071@PEPI.ausl.org>

consider a cutpoint of 20

x<-runif(100, min=1, max=50)
as.integer(x > 20)

Stefano

> -----Messaggio originale-----
> Da: Doran, Harold [mailto:HDoran at air.org]
> Inviato: mercoled?? 7 luglio 2004 14.57
> A: r-help at stat.math.ethz.ch
> Oggetto: [R] Creating Binary Outcomes from a continuous variable
> 
> 
> Dear List:
> 
>  
> 
> I have searched the archives and my R books and cannot find a 
> method to
> transform a continuous variable into a binary variable. For example, I
> have test score data along a continuous scale. I want to create a new
> variable in my dataset that is 1=above a cutpoint (or passed the test)
> and 0=otherwise.
> 
>  
> 
> My instinct tells me that this will require a combination of the
> transform command along with a conditional selection. Any help is much
> appreciated.
> 
>  
> 
> Thanks,
> 
> Harold
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From a.beckerman at sheffield.ac.uk  Wed Jul  7 15:09:18 2004
From: a.beckerman at sheffield.ac.uk (Andrew Beckerman)
Date: Wed, 7 Jul 2004 14:09:18 +0100
Subject: [R] lme with poly(x,2) terms
Message-ID: <DB06F698-D016-11D8-BBDA-000A95CD7F02@sheffield.ac.uk>

Hi there.

Mac OSX 3.3.4 R 1.9.1

I am analysing a data set with the following model

m4<- 
lme(fixed=sr~time*poly(energy,2)*poly(dist,2),random=~time|pot,data=deh)

where time is one of six months, pot is a jar in which the repeated  
measures of species number (sr) was made.  energy and dist  
(disturbance) are fixed experimental treatments. We are trying to test  
the hypothesis that there is an interaction between energy and  
disturbance that varies through time, with the expectation that sr  
varies quadratically with energy and with disturbance.  Our difficulty  
is interpreting the various outputs from the model, assuming it is  
specified correctly - sorry if this is more a stats question than a R  
mechanics question.

summary(m1) and anova(m1) produce the tables below the --------.

Q1) Am i correct to assume that the anova table is sequential?
Q2) How does one interpret the fixed effects/"coefficients table"?  Do  
the insignificant terms for poly(dist)2 all the way down (Up) to its  
main effect suggest that a quadratic function in dist is not  
significant?
Q3) If we remove the quadratic term in dist and compare it to the model  
with poly(dist,2), the anova says the polynomial is significant

 > anova(update(m2,~.,method="ML"),update(m4,~.,method="ML"))
                               Model df      AIC      BIC    logLik    
Test L.Ratio p-value
update(m2, ~., method = "ML")     1 16 2781.683 2858.271 -1374.841
update(m4, ~., method = "ML")     2 22 2771.380 2876.688 -1363.690 1 vs  
2  22.303  0.0011

despite only the main effect of poly(dist,2) being significant in the  
terms. Is the best approach to use the anova test or the coefficients?   
How does one justify the insignificance of every term with poly(dist)2  
in it?

Many thanks in advance
andrew


---------------------------------
 >summary(m1)
Linear mixed-effects model fit by REML
  Data: deh
        AIC      BIC    logLik
   2687.974 2792.830 -1321.987

Random effects:
  Formula: ~time | pot
  Structure: General positive-definite, Log-Cholesky parametrization
             StdDev    Corr
(Intercept) 1.5503393 (Intr)
time        0.1858609 -0.862
Residual    0.9234853

Fixed effects: sr ~ time * poly(energy, 2) * poly(dist, 2)
                                         Value Std.Error  DF   t-value  
p-value
(Intercept)                            8.2424   0.14576 721  56.54737   
0.0000
time                                  -1.1447   0.02376 721 -48.16926   
0.0000
poly(energy, 2)1                      18.2052   4.34118 721   4.19361   
0.0000
poly(energy, 2)2                     -43.8133   4.34213 721 -10.09028   
0.0000
poly(dist, 2)1                        -9.9600   4.34169 721  -2.29403   
0.0221
poly(dist, 2)2                       -10.6639   4.34198 721  -2.45599   
0.0143
time:poly(energy, 2)1                  1.7320   0.70705 721   2.44961   
0.0145
time:poly(energy, 2)2                  5.6245   0.70695 721   7.95608   
0.0000
time:poly(dist, 2)1                   -0.6569   0.70701 721  -0.92908   
0.3532
time:poly(dist, 2)2                    0.0400   0.70697 721   0.05657   
0.9549
poly(energy, 2)1:poly(dist, 2)1      356.6786 128.77967 721   2.76968   
0.0058
poly(energy, 2)2:poly(dist, 2)1      -99.7288 128.60505 721  -0.77547   
0.4383
poly(energy, 2)1:poly(dist, 2)2      -11.4295 129.65263 721  -0.08816   
0.9298
poly(energy, 2)2:poly(dist, 2)2      149.5420 129.80979 721   1.15201   
0.2497
time:poly(energy, 2)1:poly(dist, 2)1 -79.3803  20.96606 721  -3.78613   
0.0002
time:poly(energy, 2)2:poly(dist, 2)1  59.4570  20.93577 721   2.83997   
0.0046
time:poly(energy, 2)1:poly(dist, 2)2 -20.6131  21.10723 721  -0.97659   
0.3291
time:poly(energy, 2)2:poly(dist, 2)2 -22.3304  21.13159 721  -1.05673   
0.2910

 > anova(m4)
                                    numDF denDF   F-value p-value
(Intercept)                            1   721  888.6686  <.0001
time                                   1   721 2321.2473  <.0001
poly(energy, 2)                        2   721   77.1328  <.0001
poly(dist, 2)                          2   721   22.9940  <.0001
time:poly(energy, 2)                   2   721   34.6873  <.0001
time:poly(dist, 2)                     2   721    0.4551  0.6345
poly(energy, 2):poly(dist, 2)          4   721    2.5824  0.0361
time:poly(energy, 2):poly(dist, 2)     4   721    6.1290  0.0001



From Pieter.Hazenberg21 at wur.nl  Wed Jul  7 15:32:14 2004
From: Pieter.Hazenberg21 at wur.nl (Hazenberg21, Pieter)
Date: Wed, 7 Jul 2004 15:32:14 +0200
Subject: [R] KalmanSmooth problem
Message-ID: <7263F1C61318A24080FBC425CA4AE4C6F381B7@salte0008.wurnet.nl>

Hello,
In R I am trying to use Kalman filtering to find a solution for an hydrological problem. With Kalman Filtering I want to estimate the discharge comming from three storage bassins. I have programmed a function in R which can run KalmanSmooth. When I'm asking for the function and putting in values, R detects the following error: "Error in as.vector(data) : Argument "S1" is missing, with no default".
I have try to find a solution for this error in the R help file, and in different manuals, but I can't find it. Please help me find a solution.
Question: What does R mean with "S1" and what am I doing wrong?
Here is the way I have programmed the hydrological problem in R. 
 
> discharge=read.table(file="C:/Program Files/R/rw1090/discharge.txt",header=T)
> deb=discharge[,1]
> deb
  [1] 11.545313  8.045465  5.670868  4.044584  2.919311  2.306668  2.940956
  [8]  4.238159  5.017374  3.818236  2.928805  2.262183  1.757765  1.633945
 [15]  2.295130  3.454054  4.035224  3.193967  2.533181  2.012406  1.600836
 [22]  1.652155  2.428678  3.642827  4.019545  3.209473  2.563617  2.048347
 [29]  1.637041  1.828952  2.757842  4.050821  4.147013  3.316503  2.652490
 [36]  2.121535  1.696934  2.027763  3.107366  4.429670  4.160178  3.327950
 [43]  2.662237  2.129710  1.703717  2.158095  3.337039  4.582359  3.905901
 [50]  3.124690  2.499732  1.999772  1.599810  2.130893  3.302622  4.336081
 [57]  3.468857  2.775081  2.220062  1.776048  1.560859  2.169537  3.348081
 [64]  4.170552  3.336440  2.669151  2.135320  1.708256  1.648859  2.374217
 [71]  3.624091  4.248563  3.398850  2.719080  2.175264  1.740211  1.826122
 [78]  2.704749  4.056438  4.437309  3.549847  2.839878  2.271902  1.817522
 [85]  2.053994  3.107875  4.548436  4.600601  3.680481  2.944385  2.355508
 [92]  1.884406  2.273248  3.490148  4.949898  4.584409  3.667527  2.934022
 [99]  2.347217  1.877774
> Kalm = function(x,O1,O2,O3,T1,T2,T3,T4,T5,t,ga){
+ t=array(c(1+ga*O1+t/O1*(-(1/T2)-(1/T3)-(1/T1)),t/O1*(1/T2),t/O1*(1/T3),
+ t/O2*(1/T2),1+ga*O2+t/O2*(-(1/T2)-(1/T4)),t/O2*(1/T4),
+ t/O3*(1/T3),t/O3*(1/T4),1+ga*O3+t/O3*(-(1/T3)-(1/T4)-(1/T5))),dim=c(3,3));
+ h=0.5;
+ r=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
+ q=1;
+ v=r*q*t(r);
+ a=10.14286;
+ z=array(c((1/T1),0,0,0,0,0,0,0,(1/T5)), dim=c(3,3));
+ p=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
+ pn=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
+ kal=KalmanSmooth(x, list(T=t,Z=z,h=h,V=v,a=a,P=p,Pn=pn), nit=0)
+ kal}
 
> Kalm(deb,4,.5,5,.7,.1,2,3,4,1,0.65)
Error in as.vector(data) : Argument "S1" is missing, with no default
 
First I thought I had to make a timeserie of deb. But this doesn't change the problem.
Lot's of thanks trying to help me. 
Best regards,
Pieter Hazenberg
Student Hydrology and Watermanagement
Wageningen University
The Netherlands



From vincent.goulet at act.ulaval.ca  Wed Jul  7 15:56:27 2004
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Wed, 7 Jul 2004 09:56:27 -0400
Subject: [R] Daily time series
In-Reply-To: <20040707073054.77705.qmail@web41210.mail.yahoo.com>
References: <20040707073054.77705.qmail@web41210.mail.yahoo.com>
Message-ID: <200407070956.27553.vincent.goulet@act.ulaval.ca>

Hi Vito,

Short answer: argument 'start' can take any value you want. For monthly 
observations (the case 'ts()' handles most nicely, with quarterly 
observations), 'start' will be used to specify the year and month (or 
quarter) of the first observation.

>From what I can gather from the help page, something like, say, 

	ts(x, freq=7, start=c(35, 1))

would mean that the first observation is on the first day of week 35.

Bear in mind that, to the best of my knowledge, the value of 'start' has 
absolutely no impact on calculations. It is merely there for labeling 
purposes.

Hope this helps!

On Wednesday 07 July 2004 03:30, Vito Ricci wrote:
> Hi,
>
> I'm dealing with time series with 1 observaton for day
> (data sampled daily). I will create a ts object using
> that time series and the function ts().
> In ts() help is written:
>
> The value of argument 'frequency' is used when the
> series is sampled an integral number of times in each
> unit time interval. For example, one could use a value
> of '7' for 'frequency' when the data are sampled
> daily, and the natural time period is a week, or '12'
> when the data are sampled monthly and the natural time
> period
> is a year.  Values of '4' and '12' are assumed in
> (e.g.) 'print' methods to imply a quarterly and
> monthly series respectively.
>
> But what value should assume start in ts function?
>
> Here is a time series:
>
> 1/1 10
> 2/1 20
> 3/1 30
> 4/1 40
> 5/1 50
> 6/1 60
>
> x<-c(10,20,30,40,50,60) ## observation
> serie<-ts(dati, start=c(1,1),frequency=7) ##creating
> ts object
>
> serie  ## printing ts output
>
> Time Series:
> Start = c(1, 1)
> End = c(1, 6)
> Frequency = 7
> [1] 10 20 30 40 50 60
>
> Could someone help me?
>
> Thanks in advance.
>
> Sincerely.
> Vito Ricci
>
>
> =====
> Diventare costruttori di soluzioni
>
> Visitate il portale http://www.modugno.it/
> e in particolare la sezione su Palese
> http://www.modugno.it/archivio/cat_palese.shtml
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
  Vincent Goulet, Associate Professor
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From ivo_welch at mailblocks.com  Wed Jul  7 16:35:44 2004
From: ivo_welch at mailblocks.com (ivo welch)
Date: Wed, 07 Jul 2004 07:35:44 -0700
Subject: [R] fast NA elimination ?
In-Reply-To: <200407061003.i66A1vZc012302@hypatia.math.ethz.ch>
References: <200407061003.i66A1vZc012302@hypatia.math.ethz.ch>
Message-ID: <ivo_welch-0wKLHAZe4v0ELHyFEwC4LtF0zFpUXUq@mailblocks.com>


dear R wizards: an operation I execute often is the deletion of all 
observations (in a matrix or data set) that have at least one NA. (I 
now need this operation for kde2d, because its internal quantile call 
complains;  could this be considered a buglet?)   usually, my data sets 
are small enough for speed not to matter, and there I do not care 
whether my method is pretty inefficient (ok, I admit it: I use the 
sum() function and test whether the result is NA)---but now I have some 
bigger data sets. Is there a recommended method of doing NA elimination 
most efficiently? sincerely, /iaw
---
ivo welch
professor of finance and economics
brown / nber / yale



From rpeng at jhsph.edu  Wed Jul  7 16:40:40 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 07 Jul 2004 10:40:40 -0400
Subject: [R] fast NA elimination ?
In-Reply-To: <ivo_welch-0wKLHAZe4v0ELHyFEwC4LtF0zFpUXUq@mailblocks.com>
References: <200407061003.i66A1vZc012302@hypatia.math.ethz.ch>
	<ivo_welch-0wKLHAZe4v0ELHyFEwC4LtF0zFpUXUq@mailblocks.com>
Message-ID: <40EC0B68.5060805@jhsph.edu>

I find complete.cases() to be very useful for this kind of stuff (and 
very fast).  As in,

 > d <- data.frame(x = c(1,2,3,NA,5), y = c(1,NA,3,4,5))
 > d
    x  y
1  1  1
2  2 NA
3  3  3
4 NA  4
5  5  5
 > complete.cases(d)
[1]  TRUE FALSE  TRUE FALSE  TRUE
 > use <- complete.cases(d)
 > d[use, ]
   x y
1 1 1
3 3 3
5 5 5
 >


-roger

ivo welch wrote:
> 
> dear R wizards: an operation I execute often is the deletion of all 
> observations (in a matrix or data set) that have at least one NA. (I now 
> need this operation for kde2d, because its internal quantile call 
> complains;  could this be considered a buglet?)   usually, my data sets 
> are small enough for speed not to matter, and there I do not care 
> whether my method is pretty inefficient (ok, I admit it: I use the sum() 
> function and test whether the result is NA)---but now I have some bigger 
> data sets. Is there a recommended method of doing NA elimination most 
> efficiently? sincerely, /iaw
> ---
> ivo welch
> professor of finance and economics
> brown / nber / yale
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From MSchwartz at MedAnalytics.com  Wed Jul  7 16:41:39 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 07 Jul 2004 09:41:39 -0500
Subject: [R] fast NA elimination ?
In-Reply-To: <ivo_welch-0wKLHAZe4v0ELHyFEwC4LtF0zFpUXUq@mailblocks.com>
References: <200407061003.i66A1vZc012302@hypatia.math.ethz.ch>
	<ivo_welch-0wKLHAZe4v0ELHyFEwC4LtF0zFpUXUq@mailblocks.com>
Message-ID: <1089211299.16727.134.camel@localhost.localdomain>

On Wed, 2004-07-07 at 09:35, ivo welch wrote:
> dear R wizards: an operation I execute often is the deletion of all 
> observations (in a matrix or data set) that have at least one NA. (I 
> now need this operation for kde2d, because its internal quantile call 
> complains;  could this be considered a buglet?)   usually, my data sets 
> are small enough for speed not to matter, and there I do not care 
> whether my method is pretty inefficient (ok, I admit it: I use the 
> sum() function and test whether the result is NA)---but now I have some 
> bigger data sets. Is there a recommended method of doing NA elimination 
> most efficiently? sincerely, /iaw
> ---
> ivo welch
> professor of finance and economics
> brown / nber / yale


Take a look at ?complete.cases

HTH,

Marc Schwartz



From gerifalte28 at hotmail.com  Wed Jul  7 17:40:39 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Wed, 07 Jul 2004 15:40:39 +0000
Subject: [R] Code density functions
Message-ID: <BAY2-F24jUWxDxCyvLD00017fde@hotmail.com>

Thanks to Andy Liaw, James Holtman and Uwe Ligges;  I downloaded and looked 
at the source and found what I need!!

Francisco



>From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
>To: F Z <gerifalte28 at hotmail.com>
>CC: andy_liaw at merck.com, R-help at stat.math.ethz.ch
>Subject: Re: [R] Code density functions
>Date: Wed, 07 Jul 2004 07:51:35 +0200
>
>F Z wrote:
>>Dear Andy
>>
>>Thanks for your reply.  I don't seem to find the file that you suggested. 
>>I tried:
>>
>>>file.show('C:/Program Files/R/rw1091/src/nmath/dnorm.c.')
>
>You have installed a binary distribution.
>You need to get the source tarball (directly accessible via the main CRAN 
>page) that includes the file.
>
>Uwe Ligges
>
>
>
>>NULL
>>Warning message:
>>file.show(): file C:/Program Files/R/rw1091/src/nmath/dnorm.c. does not 
>>exist
>>
>>Then I looked at the directory and tried a file with similar name:
>>
>>>file.show('C:/Program Files/R/rw1091/src/include/Rmath.h')
>>
>>
>>But this file does not show the actual code used to calculate the 
>>densities, only the declarations of the procedures.
>>
>>What am I doing wrong?
>>
>>Thanks again!
>>
>>Francisco Zagmutt :)
>>
>>
>>>From: "Liaw, Andy" <andy_liaw at merck.com>
>>>To: "'F Z'" <gerifalte28 at hotmail.com>,R-help at stat.math.ethz.ch
>>>Subject: RE: [R] Code density functions
>>>Date: Tue, 6 Jul 2004 18:35:24 -0400
>>>
>>>Dear <insert your name here>:
>>>
>>>You need to look at the C-level source codes, in R-1.9.1/src/nmath/d*.c.
>>>
>>>Andy
>>>
>>> > From: F Z
>>> >
>>> > Hello
>>> >
>>> > I would like to see the algorithm that R uses to generate
>>> > density functions
>>> > for several distributions (i.e. Normal,Weibull, etc).  I tried:
>>> >
>>> > >dnorm
>>> > function (x, mean = 0, sd = 1, log = FALSE)
>>> > .Internal(dnorm(x, mean, sd, log))
>>> > <environment: namespace:stats>
>>> >
>>> > How can I see the code used for densities?
>>> >
>>> > Thanks!
>>>
>>>
>>>------------------------------------------------------------------------------
>>>
>>>Notice:  This e-mail message, together with any attachments, contains 
>>>information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, 
>>>New Jersey, USA 08889), and/or its affiliates (which may be known outside 
>>>the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in 
>>>Japan, as Banyu) that may be confidential, proprietary copyrighted and/or 
>>>legally privileged. It is intended solely for the use of the individual 
>>>or entity named on this message.  If you are not the intended recipient, 
>>>and have received this message in error, please notify us immediately by 
>>>reply e-mail and then delete it from your system.
>>>------------------------------------------------------------------------------
>>>
>>
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>



From gerifalte28 at hotmail.com  Wed Jul  7 18:35:11 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Wed, 07 Jul 2004 16:35:11 +0000
Subject: [R] fast NA elimination ?
Message-ID: <BAY2-F42AAJg9akCt2d00089e11@hotmail.com>

Hi Ivo

Try ?na.omit

Example :

>d <- data.frame(x = c(1:5,NA), y = c(NA,3:7)) d
   x  y
1  1 NA
2  2  3
3  3  4
4  4  5
5  5  6
6 NA  7
>do<-na.omit(d)
>do
  x y
2 2 3
3 3 4
4 4 5
5 5 6

I usually pass na.omit within the data argument of a function i.e.  
m<-lm(x~y,data=na.omit(d)). In this way you don't have to store 2 datasets.

I hopw that this helps

Francisco

>From: Marc Schwartz <MSchwartz at MedAnalytics.com>
>Reply-To: MSchwartz at MedAnalytics.com
>To: ivo welch <ivo_welch at mailblocks.com>
>CC: R-Help <r-help at stat.math.ethz.ch>
>Subject: Re: [R] fast NA elimination ?
>Date: Wed, 07 Jul 2004 09:41:39 -0500
>
>On Wed, 2004-07-07 at 09:35, ivo welch wrote:
> > dear R wizards: an operation I execute often is the deletion of all
> > observations (in a matrix or data set) that have at least one NA. (I
> > now need this operation for kde2d, because its internal quantile call
> > complains;  could this be considered a buglet?)   usually, my data sets
> > are small enough for speed not to matter, and there I do not care
> > whether my method is pretty inefficient (ok, I admit it: I use the
> > sum() function and test whether the result is NA)---but now I have some
> > bigger data sets. Is there a recommended method of doing NA elimination
> > most efficiently? sincerely, /iaw
> > ---
> > ivo welch
> > professor of finance and economics
> > brown / nber / yale
>
>
>Take a look at ?complete.cases
>
>HTH,
>
>Marc Schwartz
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html


Technology 101. http://special.msn.com/tech/technology101.armx



From kbartz at loyaltymatrix.com  Wed Jul  7 19:00:25 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Wed, 7 Jul 2004 10:00:25 -0700
Subject: [R] Visualizing Marketing Campaigns With R
Message-ID: <20040707170539.29FD93FD2E@omta16.mta.everyone.net>

Warning: This is a bit off-topic.

Using R, I'm trying to develop a way of visualizing a marketing campaign
that is divided into lists, each with a mailing and control group. Within a
mailing group, we have respondents and sales conversions (think "successes")
and the overlap between the two. We also have conversions among those
subjects in the list's control group, who were withheld the mailing. There
are several lists to a campaign, with varied numbers of subjects in the
mailing and control groups.

I want some way of illustrating this information visually, a display that
communicates:

1) The relative sizes of each list's mailing and control groups
2) The lists' relative importance to the overall campaign
3) The effect each list's mailing has on proportion of conversions to sales
4) The volume of the overlap relative to the number of respondents and
number of conversions
5) Confidence intervals about all of these figures

I've taken a stab at developing my own type of display using R and grid,
which you can see, along with comments and the raw data set, at
http://r.loyaltymatrix.com. Unfortunately, my display feels clunky and
nonintuitive. Any suggestions? Please feel free to comment or to share any
ideas, either through e-mail or the commenting feature in the blog or on
this list.

As a subtext, I've looked into rmeta, which has a funnelplot function and a
plot for the Mantel-Haenszel test, meta.MH. Neither is quite what I want.
The funnel plot tells me nothing about the relative sizes of the mailing and
control groups; I would like to be able to see it when a control group is
tiny. By the same token, it shows no confidence intervals, which are
important if the control groups are too small to make any real statement.
plot.meta.MH shows the intervals, but doesn't offer any information about
the size of the lists and their relative importance in the campaign.
Additionally, neither utilizes the information I have available about
respondents (as opposed to conversions) and their overlap with converted
customers.

Sorry to bother everyone with a somewhat off-topic note, but it is my hope
that someone may have dealt with this question previously and may have some
wisdom to share. Thanks for any help you can provide,

Kevin



From cullens at tcd.ie  Wed Jul  7 19:15:51 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Wed, 07 Jul 2004 18:15:51 +0100
Subject: [R] Win32 & C code
Message-ID: <opsar18pms1pelvz@smtp.tcd.ie>

Hi,

I'm trying to get C code working with R. This is my first time writing C  
on Windows and I'm making a mess of it. Help!

I'm following the example in Roger Peng's "An Introduction to the .C  
interface to R". The C code is:

#include <R.h>
void hello(int *n){
	int i;
	for(i=0; i < *n; i++) {
		Rprintf("Hello, world!\n");
	}
}

I seem to be unable to make Windows pay attention to additions to the PATH  
variable so I stuck the code (test.c) into the $R_HOME\bin directory. I  
copied into the same directory mingw32-make.exe and renamed it make.exe  
(as the perl script SHLIB seems to want a make.exe).

When I type Rcmd SHLIB test.c at a command prompt I get the following:

C:\Program Files\R\rw1091\bin>Rcmd SHLIB test.c
C:/PROGRA~1/R/rw1091/src/gnuwin32/MkRules:110: warning: overriding  
commands for target `.c.d'
C:/PROGRA~1/R/rw1091/src/gnuwin32/MkRules:98: warning: ignoring old  
commands for target `.c.d'
C:/PROGRA~1/R/rw1091/src/gnuwin32/MkRules:126: warning: overriding  
commands for target `.c.o'
C:/PROGRA~1/R/rw1091/src/gnuwin32/MkRules:114: warning: ignoring old  
commands for target `.c.o'
MkRules:110: warning: overriding commands for target `.c.d'
MkRules:98: warning: ignoring old commands for target `.c.d'
MkRules:126: warning: overriding commands for target `.c.o'
MkRules:114: warning: ignoring old commands for target `.c.o'
MkRules:110: warning: overriding commands for target `.c.d'
MkRules:98: warning: ignoring old commands for target `.c.d'
MkRules:126: warning: overriding commands for target `.c.o'
MkRules:114: warning: ignoring old commands for target `.c.o'
make: *** No rule to make target `'test.c'', needed by `makeMakedeps'.   
Stop.

I'm obviously an idiot but any help offered would be much appreciated.

-- 
SC



From roebuck at odin.mdacc.tmc.edu  Wed Jul  7 19:20:17 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed, 7 Jul 2004 12:20:17 -0500 (CDT)
Subject: [R] Enumeration in R
In-Reply-To: <x2y8lwodcm.fsf@biostat.ku.dk>
References: <Pine.OSF.4.58.0407061527220.265315@odin.mdacc.tmc.edu>
	<x2y8lwodcm.fsf@biostat.ku.dk>
Message-ID: <Pine.OSF.4.58.0407070952570.338741@odin.mdacc.tmc.edu>

On Tue, 7 Jul 2004, Peter Dalgaard wrote:

> Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:
>
> > I want the equivalent of this 'C' declaration.
> >     enum StoplightColor {
> >         green = 3,
> >         yellow = 5,
> >         red = 7
> >     };
>
> I think you *dis*abled it by specifying an initializer which doesn't
> check the validity:

Thanks. It all seems obvious once it's pointed out to you.
I have a couple related questions:

1) When I was reading Chambers book (pg 288), my initial
impression was that there was a way I could have done this
class without specifying the representation in 'setClass'
- I just couldn't figure out how to assign values that
way. Could this class have been defined 'slotless'? If so,
how?

2) How do you define a class and instantiate some, yet
prevent more from being created after that. Possibly better
stated, from the package's API view, I would like these to
be instance variables of opaque types. So I would like to
create my 'global' constants in an initialization routine
then prevent use of 'new' to create any more. I tried the
following with no success. Possible?

setMethod("new",
          "stoplightColor",
          function(Class, ...) stop("can't make any more"))

3) This seems kind of painful for trivial stuff. My idea
was to move some of the validation error checking out of my
project by converting certain function arguments into classes
that could be validated upon creation, improving the clarity
of project routines. What is the canonical style used in R
package authoring?




--------- stoplightColor.R ------------------------------------
setClass("stoplightColor",
         representation(value = "integer"),
         prototype = integer(1))
stoplightColor <- function(value) {
    new("stoplightColor", value)
}
valid.stoplightColor <- function(object) {
    valid <- switch(as(object at value, "character"),
                    "3" = TRUE,
                    "5" = TRUE,
                    "7" = TRUE,
                    FALSE)
    if (valid == FALSE)
        return('Invalid value - must be [3|5|7]');
    return(TRUE);
}
setValidity("stoplightColor", valid.stoplightColor)
initialize.stoplightColor <- function(.Object, value) {
    if (missing(value) || is.na(value))
        stop('Argument "value" is missing or NA')
    .Object at value <- as.integer(value)
    validObject(.Object)
    .Object
}
setMethod("initialize",
          signature(.Object = "stoplightColor"),
          initialize.stoplightColor)
stoplightColor.as.integer <- function(from) {
    return(from at value)
}
setAs("stoplightColor", "integer", stoplightColor.as.integer)

green <- stoplightColor(3)
yellow <- stoplightColor(5)
red <- stoplightColor(7)

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From bacolli at uark.edu  Wed Jul  7 19:29:40 2004
From: bacolli at uark.edu (Bret Collier)
Date: Wed, 07 Jul 2004 12:29:40 -0500
Subject: [R] Histograms, density, and relative frequencies
Message-ID: <5.2.1.1.0.20040707113402.00aa5f80@mail.uark.edu>

R-users,
         I have been using R for about 1 year, and I have run across a 
couple of graphics problem that I am not quite sure how to address.  I have 
read up on the email threads regarding the differences between density and 
relative frequencies (count/sum(count) on the R list, and I am hoping that 
someone could provide me with some advice/comments concerning my 
approach.  I will admit that some of the underlying mathematics of the 
density discussion are beyond my current understanding, but I am looking 
into it.

I have a data set (600,000 obs) used to parameterize a probabilistic causal 
model where each obs is a population response for one of 2 classes (either 
regs1 and regs2).  I have been attempting to create 1 marginal probability 
plot with 2 lines (one for each class).  Using my rather rough code, I 
created a plot that seems to adhere to the commonly used (although from 
what I can understand wrong) relative frequency histogram approach.

My rough code looks like this:

bk <- c(0, .05, .1, .15, .2, .25,.3, .35, 1)
par(mfrow=c(1, 1))
fawn1 <- hist(MFAWNRESID[regs1], plot=F, breaks=bk)
fawn2 <- hist(MFAWNRESID[regs2], plot=F, breaks=bk)
count1 <- fawn1$counts/sum(fawn1$counts)
count2 <- fawn2$counts/sum(fawn2$counts)
b <- c(0, .05, .1, .15, .2, .25, .3, .35)
plot(count1~b,xaxt="n", xlim=c(0, .5), ylim=c(0, .40), pch=".", bty="l")
lines(spline(count1~b), lty=c(1), lwd=c(2), col="black")
lines(spline(count2~b), lty=c(2), lwd=c(2), col="black")
axis(side=1, at=c(0, .05, .1, .15, .2,  .25, .3, .35))

Using the above, I get frequency values for regs1 that look like this 
(which is the same as output for my probabilistic model):
 > count1
[1] 1.213378e-01 3.454324e-01 3.365343e-01 1.580839e-01 3.342101e-02
[6] 4.698426e-03 4.488942e-04 4.322685e-05

First, count1 is the frequency of occurrence within range 0-0.05, but when 
plotted is the value at b=0 and does not really represent the range?  Are 
there any suggestions on a technique to approach this?

Next:  Using the above code, the x-axis values end at 0.35, but the axis 
continues (because bk ends at 1)?  While there is the chance of occurrence 
out past .35, it is low and I want to extend the lines to about .35 and 
clip the x-axis.  But, I have been unable to figure out how to clip  Could 
someone point me in the correct direction?


TIA,

Bret A. Collier
Arkansas Cooperative Fish and Wildlife Research Unit
Department of Biological Sciences University of Arkansas



From roebuck at odin.mdacc.tmc.edu  Wed Jul  7 19:32:41 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed, 7 Jul 2004 12:32:41 -0500 (CDT)
Subject: [R] Win32 & C code
In-Reply-To: <opsar18pms1pelvz@smtp.tcd.ie>
References: <opsar18pms1pelvz@smtp.tcd.ie>
Message-ID: <Pine.OSF.4.58.0407071222230.338741@odin.mdacc.tmc.edu>

On Wed, 7 Jul 2004, Simon Cullen wrote:

> I'm trying to get C code working with R. This is my first time writing C
> on Windows and I'm making a mess of it. Help!
> ...
> I seem to be unable to make Windows pay attention to additions to the PATH
> variable so I stuck the code (test.c) into the $R_HOME\bin directory. I
> copied into the same directory mingw32-make.exe and renamed it make.exe
> (as the perl script SHLIB seems to want a make.exe).
> ...


I wrote a batch file to get mine working. Change directory
paths to match your setup.

WINBUILD.CMD
---------------------------------------------------------
@cls
@SETLOCAL
@set PROJ=rwt
@set RBINDIR=C:\R\rw1091\bin
@set TOOLSBINDIR=C:\Rtools\bin
@set MINGWBINDIR=C:\MinGW\bin
@set PERLBINDIR=C:\Perl\bin
@set TEXBINDIR=C:\PROGRA~1\TeXLive\bin\win32
@set HCCBINDIR=C:\PROGRA~1\HTMLHE~1
   #### Next line split for readability ####
@set PATH=%TOOLSBINDIR%;%RBINDIR%;%MINGWBINDIR%;%PERLBINDIR%;
      %TEXBINDIR%;%HCCBINDIR%;%WINDIR%\system32;%WINDIR%
@echo PATH=%PATH%
Rcmd build --binary %PROJ%
Rcmd check %PROJ%
@ENDLOCAL


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From cullens at tcd.ie  Wed Jul  7 20:01:49 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Wed, 07 Jul 2004 19:01:49 +0100
Subject: [R] Win32 & C code
In-Reply-To: <Pine.OSF.4.58.0407071222230.338741@odin.mdacc.tmc.edu>
References: <opsar18pms1pelvz@smtp.tcd.ie>
	<Pine.OSF.4.58.0407071222230.338741@odin.mdacc.tmc.edu>
Message-ID: <opsar4dbt61pelvz@smtp.tcd.ie>

On Wed, 7 Jul 2004 12:32:41 -0500 (CDT), Paul Roebuck  
<roebuck at odin.mdacc.tmc.edu> wrote:

> I wrote a batch file to get mine working. Change directory
> paths to match your setup.

That batch file was exactly what I needed! Thanks.

-- 
SC



From gwang at nrel.colostate.edu  Wed Jul  7 20:13:56 2004
From: gwang at nrel.colostate.edu (Guiming Wang)
Date: Wed, 7 Jul 2004 12:13:56 -0600
Subject: [R] Observational error in ARIMA 
Message-ID: <00dd01c4644e$2b11f3c0$6b685281@nrelwang>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040707/cbd2af60/attachment.pl

From kyong.ho.park at us.army.mil  Wed Jul  7 20:21:42 2004
From: kyong.ho.park at us.army.mil (Park, Kyong H Mr. RDECOM)
Date: Wed, 7 Jul 2004 14:21:42 -0400 
Subject: [R] Importing an Excel file
Message-ID: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040707/45809b35/attachment.pl

From kyong.ho.park at us.army.mil  Wed Jul  7 20:28:42 2004
From: kyong.ho.park at us.army.mil (Park, Kyong H Mr. RDECOM)
Date: Wed, 7 Jul 2004 14:28:42 -0400 
Subject: [R] Sorry forgot to mention about OS system in an previous email
Message-ID: <3007F52DF96EB74CAC3054FF85C4318F7A7ACA@mail2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040707/72eefd00/attachment.pl

From amackey at pcbi.upenn.edu  Wed Jul  7 20:31:05 2004
From: amackey at pcbi.upenn.edu (Aaron J. Mackey)
Date: Wed, 7 Jul 2004 14:31:05 -0400
Subject: [R] lost messages
Message-ID: <CE8AD16F-D043-11D8-BD00-000A9577009E@pcbi.upenn.edu>


I've posted a message twice to this list, and never seen it appear yet 
... perhaps this one will go through ... ?


--
Aaron J. Mackey, Ph.D.
Dept. of Biology, Goddard 212
University of Pennsylvania       email:  amackey at pcbi.upenn.edu
415 S. University Avenue         office: 215-898-1205
Philadelphia, PA  19104-6017     fax:    215-746-6697



From stephane.dray at umontreal.ca  Wed Jul  7 20:32:51 2004
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Wed, 07 Jul 2004 14:32:51 -0400
Subject: [R] Generate a matrix Q satisfying t(Q)%*%Q=Z and XQ=W
In-Reply-To: <40EB754A.4030909@pdf.com>
References: <5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
	<5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
Message-ID: <5.2.1.1.0.20040707142417.00b47218@magellan.umontreal.ca>

thanks,
I want to create matrices for simulation purpose (in order to evaluate the 
efficiency of different methods on this simulated data set). So, I want to 
create a data matrix Q (m individuals and r variables). I want to specify 
the variance-covariance structure for this matrix (t(Q)%*%Q=Z ) but I want 
also to create another constraint due to another matrix of data. I want 
that the covariance of Q and X are equal to those given in W (XQ=W).
The example I gave is just to illustrate my problem and perhaps it has no 
solution (I cannot see it because I have no idea how to construct Q such as 
Q=Q1=Q2)




At 00:00 07/07/2004, Spencer Graves wrote:
>      Is a solution even possible for the matrices in your example?
>I've tried a few things that have suggested that a solution may not be 
>possible.
>      What can you tell us of the problem that you've translated into 
> this?  I see a minimization problem subject to constraints, but I'm not 
> certain which are the constraints and what is the objective function.
>For example, are you trying to find Q to minimize sum((Z-X'X)^2) subject 
>to XQ=W or do you want to minimize sum((XQ-W)^2) subject to Q'Q=Z or 
>something else?
>      If it were my problem, I think I would work for a while with the 
> singular value decompositions of X, W and Z, and see if that would lead 
> me to more information about Q, including conditions under which a 
> solution existed, expressions for Q when multiple solutions existed, and 
> a solution minimizing your chosen objective function when solutions do 
> not exist.  (A google search produced many hits for "singular value 
> decomposition", implemented as "svd" in R.)
>      hope this helps.  spencer graves
>
>Stephane DRAY wrote:
>
>>Hello,
>>I have a question that is not directly related to R ... but I try to do 
>>it in R ;-) :
>>
>>I would like to generate a matrix Q satisfying (for a given Z, X and W) 
>>the two following conditions:
>>
>>t(Q)%*%Q=Z  (1)
>>XQ=W (2)
>>
>>where:
>>Q is m rows and r columns
>>X is p rows and m columns
>>D is p rows and r columns
>>C is r rows and r columns
>>with m>p,r
>>
>>
>>e.g:
>>m=6,
>>p=2
>>r=3
>>
>>Z=matrix(c(1,.2,.5,.2,1,.45,.5,.45,1),3,3)
>>X=matrix(c(.1,.3,.5,.6,.2,.1,.8,1,.4,.2,.2,.9),2,6)
>>W=matrix(c(0,.8,.4,.6,.2,0),2,3)
>>
>>#Create a matrix satisfying (1) is easy:
>>
>>A=matrix(runif(18),6,3)
>>Q1=svd(A)$u%*%chol(Z)
>>
>>
>>#For the second condition (2), a solution is given by
>>
>>Q2=A%*%ginv(X%*%A)%*%W
>>
>>
>>
>>
>>
>>I do not know how to create a matrix Q that satisfies the two 
>>conditions.  I have try to construct an iterative procedure without 
>>success (no convergence):
>>
>>eps=10
>>i=0
>>while(eps>.5)
>>{
>>Q1=svd(Q2)$u%*%chol(Z)
>>Q2=Q1%*%ginv(X%*%Q1)%*%W
>>eps=sum(abs(Q1-Q2))
>>cat(i,":",eps,"\n")
>>i=i+1
>>}
>>
>>Perhaps someone could have any idea to solve the problem, or a reference 
>>on this kind of question or the email of another list where I should ask 
>>this question.
>>
>>Thanks in advance,
>>
>>Sincerely.
>>
>>St??phane DRAY
>>-------------------------------------------------------------------------------------------------- 
>>
>>D??partement des Sciences Biologiques
>>Universit?? de Montr??al, C.P. 6128, succursale centre-ville
>>Montr??al, Qu??bec H3C 3J7, Canada
>>
>>Tel : 514 343 6111 poste 1233
>>E-mail : stephane.dray at umontreal.ca
>>-------------------------------------------------------------------------------------------------- 
>>
>>Web
>>http://www.steph280.freesurf.fr/
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From amackey at pcbi.upenn.edu  Tue Jul  6 14:17:55 2004
From: amackey at pcbi.upenn.edu (Aaron J. Mackey)
Date: Tue, 6 Jul 2004 08:17:55 -0400
Subject: [R] vectorizing sapply() code (Modified by Aaron J. Mackey)
Message-ID: <14A8E742-D044-11D8-BD00-000A9577009E@pcbi.upenn.edu>

[ Not sure why, but the first two times I sent this it never seemed to 
go through; apologies if you're seeing this thrice ... ]

I have some fully functional code that I'm guessing can be done 
better/quicker with some savvy R vector tricks; any help to make this 
run a bit faster would be greatly appreciated; I'm particularly stuck 
on how to calculate using "row-wise" vectors without iterating 
explicitly over the dataframe or table ...

library(stats4);
d <- data.frame( ix=c(0,1,2,3,4,5,6,7),
                  ct=c(253987,  9596, 18680,  2630,  8224,  3590,  5534, 
18937),
                  A=c(      0,     1,     0,     1,     0,     1,     0, 
     1),
                  B=c(      0,     0,     1,     1,     0,     0,     1, 
     1),
                  C=c(      0,     0,     0,     0,     1,     1,     1, 
     1)
                );
ct <- round(logb(length(d$ix), 2))
ll <- function( th=0.5,
                 a1=log(0.5), a2=log(0.5), a3=log(0.5),
                 b1=log(0.5), b2=log(0.5), b3=log(0.5)
               ) {
   a <- exp(sapply(1:ct, function (x) { get(paste("a", x, sep="")) }));
   b <- exp(sapply(1:ct, function (x) { get(paste("b", x, sep="")) }));
   -sum( d$ct * log( sapply( d$ix,
                             function (ix, th, a, b) {
                               x <- d[ix+1,3:(ct+2)]
                               (th     * prod((b ^ (1-x)) * ((1-b) ^ x   
  ))) +
                               ((1-th) * prod((a ^ x    ) * ((1-a) ^ 
(1-x))))
                             },
                             th, a, b
                           )
                   )
   );
}

ml <- mle(ll,
           lower=c(0+1e-5, rep(log(0+1e-8), 2*ct)),
           upper=c(1-1e-5, rep(log(1-1e-8), 2*ct)),
           method="L-BFGS-B"
          );

For those interested in the math, this is the MLE procedure to estimate 
the false positive/false negative rates (a and b) of three diagnostic 
(A, B and C) tests that have the observed performance recapitulated in 
dataframe "d", but no "gold standard" (sometimes called "latent class 
analysis", or LCA).

Thanks for any help,

-Aaron



From ramasamy at cancer.org.uk  Wed Jul  7 20:36:05 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 07 Jul 2004 19:36:05 +0100
Subject: [R] Histograms, density, and relative frequencies
In-Reply-To: <5.2.1.1.0.20040707113402.00aa5f80@mail.uark.edu>
References: <5.2.1.1.0.20040707113402.00aa5f80@mail.uark.edu>
Message-ID: <1089225365.24043.12.camel@vpn202001.lif.icnet.uk>

On Wed, 2004-07-07 at 18:29, Bret Collier wrote:
> R-users,
>          I have been using R for about 1 year, and I have run across a 
> couple of graphics problem that I am not quite sure how to address.  I have 
> read up on the email threads regarding the differences between density and 
> relative frequencies (count/sum(count) on the R list, and I am hoping that 
> someone could provide me with some advice/comments concerning my 
> approach.  I will admit that some of the underlying mathematics of the 
> density discussion are beyond my current understanding, but I am looking 
> into it.
> 
> I have a data set (600,000 obs) used to parameterize a probabilistic causal 
> model where each obs is a population response for one of 2 classes (either 
> regs1 and regs2).  I have been attempting to create 1 marginal probability 
> plot with 2 lines (one for each class).  Using my rather rough code, I 
> created a plot that seems to adhere to the commonly used (although from 
> what I can understand wrong) relative frequency histogram approach.
> 
> My rough code looks like this:
> 
> bk <- c(0, .05, .1, .15, .2, .25,.3, .35, 1)
> par(mfrow=c(1, 1))
> fawn1 <- hist(MFAWNRESID[regs1], plot=F, breaks=bk)
> fawn2 <- hist(MFAWNRESID[regs2], plot=F, breaks=bk)
> count1 <- fawn1$counts/sum(fawn1$counts)
> count2 <- fawn2$counts/sum(fawn2$counts)
> b <- c(0, .05, .1, .15, .2, .25, .3, .35)
> plot(count1~b,xaxt="n", xlim=c(0, .5), ylim=c(0, .40), pch=".", bty="l")	
> lines(spline(count1~b), lty=c(1), lwd=c(2), col="black")
> lines(spline(count2~b), lty=c(2), lwd=c(2), col="black")
> axis(side=1, at=c(0, .05, .1, .15, .2,  .25, .3, .35))

Have you considered density() and plot.density() by any change ?

> Using the above, I get frequency values for regs1 that look like this 
> (which is the same as output for my probabilistic model):
>  > count1
> [1] 1.213378e-01 3.454324e-01 3.365343e-01 1.580839e-01 3.342101e-02
> [6] 4.698426e-03 4.488942e-04 4.322685e-05

I would tend to use the term proportion rather than frequency.

> First, count1 is the frequency of occurrence within range 0-0.05, but when 
> plotted is the value at b=0 and does not really represent the range?  Are 
> there any suggestions on a technique to approach this?

You can plot it in the mid-points like hist() does. fawn1$mids would
give you these values.

> Next:  Using the above code, the x-axis values end at 0.35, but the axis 
> continues (because bk ends at 1)?  While there is the chance of occurrence 
> out past .35, it is low and I want to extend the lines to about .35 and 
> clip the x-axis.  But, I have been unable to figure out how to clip  Could 
> someone point me in the correct direction?

In your plot() function, set xlim=c(0,0.35). If you mean 'clipping' as
in truncating the density, then you probably need to do re-adjust your
proportions such that they sum up to 1.



From ligges at statistik.uni-dortmund.de  Wed Jul  7 20:36:57 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 Jul 2004 20:36:57 +0200
Subject: [R] KalmanSmooth problem
In-Reply-To: <7263F1C61318A24080FBC425CA4AE4C6F381B7@salte0008.wurnet.nl>
References: <7263F1C61318A24080FBC425CA4AE4C6F381B7@salte0008.wurnet.nl>
Message-ID: <40EC42C9.4080309@statistik.uni-dortmund.de>

Hazenberg21, Pieter wrote:

> Hello,
> In R I am trying to use Kalman filtering to find a solution for an hydrological problem. With Kalman Filtering I want to estimate the discharge comming from three storage bassins. I have programmed a function in R which can run KalmanSmooth. When I'm asking for the function and putting in values, R detects the following error: "Error in as.vector(data) : Argument "S1" is missing, with no default".
> I have try to find a solution for this error in the R help file, and in different manuals, but I can't find it. Please help me find a solution.
> Question: What does R mean with "S1" and what am I doing wrong?
> Here is the way I have programmed the hydrological problem in R. 
>  
> 
>>discharge=read.table(file="C:/Program Files/R/rw1090/discharge.txt",header=T)
>>deb=discharge[,1]
>>deb
> 
>   [1] 11.545313  8.045465  5.670868  4.044584  2.919311  2.306668  2.940956
>   [8]  4.238159  5.017374  3.818236  2.928805  2.262183  1.757765  1.633945
>  [15]  2.295130  3.454054  4.035224  3.193967  2.533181  2.012406  1.600836
>  [22]  1.652155  2.428678  3.642827  4.019545  3.209473  2.563617  2.048347
>  [29]  1.637041  1.828952  2.757842  4.050821  4.147013  3.316503  2.652490
>  [36]  2.121535  1.696934  2.027763  3.107366  4.429670  4.160178  3.327950
>  [43]  2.662237  2.129710  1.703717  2.158095  3.337039  4.582359  3.905901
>  [50]  3.124690  2.499732  1.999772  1.599810  2.130893  3.302622  4.336081
>  [57]  3.468857  2.775081  2.220062  1.776048  1.560859  2.169537  3.348081
>  [64]  4.170552  3.336440  2.669151  2.135320  1.708256  1.648859  2.374217
>  [71]  3.624091  4.248563  3.398850  2.719080  2.175264  1.740211  1.826122
>  [78]  2.704749  4.056438  4.437309  3.549847  2.839878  2.271902  1.817522
>  [85]  2.053994  3.107875  4.548436  4.600601  3.680481  2.944385  2.355508
>  [92]  1.884406  2.273248  3.490148  4.949898  4.584409  3.667527  2.934022
>  [99]  2.347217  1.877774
> 
>>Kalm = function(x,O1,O2,O3,T1,T2,T3,T4,T5,t,ga){
> 
> + t=array(c(1+ga*O1+t/O1*(-(1/T2)-(1/T3)-(1/T1)),t/O1*(1/T2),t/O1*(1/T3),
> + t/O2*(1/T2),1+ga*O2+t/O2*(-(1/T2)-(1/T4)),t/O2*(1/T4),
> + t/O3*(1/T3),t/O3*(1/T4),1+ga*O3+t/O3*(-(1/T3)-(1/T4)-(1/T5))),dim=c(3,3));
> + h=0.5;
> + r=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
> + q=1;
> + v=r*q*t(r);
> + a=10.14286;
> + z=array(c((1/T1),0,0,0,0,0,0,0,(1/T5)), dim=c(3,3));
> + p=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
> + pn=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
> + kal=KalmanSmooth(x, list(T=t,Z=z,h=h,V=v,a=a,P=p,Pn=pn), nit=0)
> + kal}
>  
> 
>>Kalm(deb,4,.5,5,.7,.1,2,3,4,1,0.65)
> 
> Error in as.vector(data) : Argument "S1" is missing, with no default
>  
> First I thought I had to make a timeserie of deb. But this doesn't change the problem.
> Lot's of thanks trying to help me. 

a) Please tell us R Version and OS (OK, implicitly done that we are 
talking about R-1.9.0 on Windows).
b) Please tell us which packages you are using (I don't know 
KalmanSmooth(), for example).
c) Please try to specify reproducible examples.

Conclusion for a-c): Please read the posting-guide.

My hint is to try to debug yourself, at least *try*, starting eith 
calling traceback() right after the error appeared, in order to get a 
guess where the error really happens. Then look at the data that is 
passed to the function -  and I'm pretty sure you will get at least an 
idea what goes wrong.

Uwe Ligges





> Best regards,
> Pieter Hazenberg
> Student Hydrology and Watermanagement
> Wageningen University
> The Netherlands
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From MSchwartz at MedAnalytics.com  Wed Jul  7 20:44:44 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 07 Jul 2004 13:44:44 -0500
Subject: [R] Importing an Excel file
In-Reply-To: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>
References: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>
Message-ID: <1089225884.6345.27.camel@localhost.localdomain>

On Wed, 2004-07-07 at 13:21, Park, Kyong H Mr. RDECOM wrote:
> Hello, R users,
> I am  a very beginner of R and tried read.csv to import an excel file after
> saving an excel file as csv. But it added alternating rows of fictitious NA
> values after row number 16. When I applied read.delim, there were trailing
> several commas at the end of each row after row number 16 instead of NA
> values. Appreciate your help. 
> 
> Kyong


Yep. This is one of the behaviors that I had seen with Excel when I was
running Windows XP. Seemingly empty cells outside the data range would
get exported in the CSV file causing a data integrity problem.

It is one of the reasons that I installed OpenOffice under Windows and
used Calc to open the Excel files and then do the CSV exports before I
switched to Linux.... :-)

Depending upon the version of Excel you are using, you might try to
highlight and copy only the rectangular range of cells in the sheet that
actually have data to a new sheet and then export the new sheet to a CSV
file.

Do not just click on the upper left hand corner of the sheet to
highlight the entire sheet to copy it. Only highlight the range of cells
you actually need for copying.

Another option is to use the read.xls() function in the 'gregmisc'
package on CRAN or install OpenOffice.

HTH,

Marc Schwartz



From ramasamy at cancer.org.uk  Wed Jul  7 20:47:46 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 07 Jul 2004 19:47:46 +0100
Subject: [R] Importing an Excel file
In-Reply-To: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>
References: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>
Message-ID: <1089226066.24043.24.camel@vpn202001.lif.icnet.uk>

Are all you data numerical or does it contain characters as well ?

Check for the common culprits - the hash (#) which is the comment
character in R, unbalanced single and double quotes and other suspicious
characters around line 16 and in general.

If that does not work, open in Excel and just delete all the unwanted
columns (and rows) even if they appear empty. Then save as csv and try
again.

read.delim() will not work properly in your case because it recognises
tab as separator.


On Wed, 2004-07-07 at 19:21, Park, Kyong H Mr. RDECOM wrote:
> Hello, R users,
> I am  a very beginner of R and tried read.csv to import an excel file after
> saving an excel file as csv. But it added alternating rows of fictitious NA
> values after row number 16. When I applied read.delim, there were trailing
> several commas at the end of each row after row number 16 instead of NA
> values. Appreciate your help. 
> 
> Kyong
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From MSchwartz at MedAnalytics.com  Wed Jul  7 20:50:46 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 07 Jul 2004 13:50:46 -0500
Subject: [R] Importing an Excel file
In-Reply-To: <1089225884.6345.27.camel@localhost.localdomain>
References: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>
	<1089225884.6345.27.camel@localhost.localdomain>
Message-ID: <1089226246.6345.31.camel@localhost.localdomain>

On Wed, 2004-07-07 at 13:44, Marc Schwartz wrote:
> On Wed, 2004-07-07 at 13:21, Park, Kyong H Mr. RDECOM wrote:
> > Hello, R users,
> > I am  a very beginner of R and tried read.csv to import an excel file after
> > saving an excel file as csv. But it added alternating rows of fictitious NA
> > values after row number 16. When I applied read.delim, there were trailing
> > several commas at the end of each row after row number 16 instead of NA
> > values. Appreciate your help. 
> > 
> > Kyong


One other thing:

The default delimiting characters in read.csv() and read.delim() are NOT
the same.

The former uses a comma and the latter a TAB character. If you did not
change the defaults in Excel when you created your CSV file, that would
account for the difference behaviors upon import.

Be sure that the delimiting character in the R function you use properly
corresponds to the actual delimiting character in your CSV file.

Marc



From spencer.graves at pdf.com  Wed Jul  7 20:55:29 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 07 Jul 2004 11:55:29 -0700
Subject: [R] Generate a matrix Q satisfying t(Q)%*%Q=Z and XQ=W
In-Reply-To: <5.2.1.1.0.20040707142417.00b47218@magellan.umontreal.ca>
References: <5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
	<5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
	<5.2.1.1.0.20040707142417.00b47218@magellan.umontreal.ca>
Message-ID: <40EC4721.9040209@pdf.com>

      How about generating matrices (X1|X2), dim(X1) = c(n, k1), dim(X2) 
= c(n, k2), with mean 0 and covariance matrix as follows: 

(S11 | S12)
(S21 | S22),

with S12 = W, S22 = Z and S11 = whatever you want?  With X = t(X1), and 
Q = X2, we have E(XQ) = W and E(Q'Q) = Z. 

      This can be done using rmvnorm in package mvtnorm. 

      hope this helps.  spencer graves    

Stephane DRAY wrote:

> thanks,
> I want to create matrices for simulation purpose (in order to evaluate 
> the efficiency of different methods on this simulated data set). So, I 
> want to create a data matrix Q (m individuals and r variables). I want 
> to specify the variance-covariance structure for this matrix 
> (t(Q)%*%Q=Z ) but I want also to create another constraint due to 
> another matrix of data. I want that the covariance of Q and X are 
> equal to those given in W (XQ=W).
> The example I gave is just to illustrate my problem and perhaps it has 
> no solution (I cannot see it because I have no idea how to construct Q 
> such as Q=Q1=Q2)
>
>
>
>
> At 00:00 07/07/2004, Spencer Graves wrote:
>
>>      Is a solution even possible for the matrices in your example?
>> I've tried a few things that have suggested that a solution may not 
>> be possible.
>>      What can you tell us of the problem that you've translated into 
>> this?  I see a minimization problem subject to constraints, but I'm 
>> not certain which are the constraints and what is the objective 
>> function.
>> For example, are you trying to find Q to minimize sum((Z-X'X)^2) 
>> subject to XQ=W or do you want to minimize sum((XQ-W)^2) subject to 
>> Q'Q=Z or something else?
>>      If it were my problem, I think I would work for a while with the 
>> singular value decompositions of X, W and Z, and see if that would 
>> lead me to more information about Q, including conditions under which 
>> a solution existed, expressions for Q when multiple solutions 
>> existed, and a solution minimizing your chosen objective function 
>> when solutions do not exist.  (A google search produced many hits for 
>> "singular value decomposition", implemented as "svd" in R.)
>>      hope this helps.  spencer graves
>>
>> Stephane DRAY wrote:
>>
>>> Hello,
>>> I have a question that is not directly related to R ... but I try to 
>>> do it in R ;-) :
>>>
>>> I would like to generate a matrix Q satisfying (for a given Z, X and 
>>> W) the two following conditions:
>>>
>>> t(Q)%*%Q=Z  (1)
>>> XQ=W (2)
>>>
>>> where:
>>> Q is m rows and r columns
>>> X is p rows and m columns
>>> D is p rows and r columns
>>> C is r rows and r columns
>>> with m>p,r
>>>
>>>
>>> e.g:
>>> m=6,
>>> p=2
>>> r=3
>>>
>>> Z=matrix(c(1,.2,.5,.2,1,.45,.5,.45,1),3,3)
>>> X=matrix(c(.1,.3,.5,.6,.2,.1,.8,1,.4,.2,.2,.9),2,6)
>>> W=matrix(c(0,.8,.4,.6,.2,0),2,3)
>>>
>>> #Create a matrix satisfying (1) is easy:
>>>
>>> A=matrix(runif(18),6,3)
>>> Q1=svd(A)$u%*%chol(Z)
>>>
>>>
>>> #For the second condition (2), a solution is given by
>>>
>>> Q2=A%*%ginv(X%*%A)%*%W
>>>
>>>
>>>
>>>
>>>
>>> I do not know how to create a matrix Q that satisfies the two 
>>> conditions.  I have try to construct an iterative procedure without 
>>> success (no convergence):
>>>
>>> eps=10
>>> i=0
>>> while(eps>.5)
>>> {
>>> Q1=svd(Q2)$u%*%chol(Z)
>>> Q2=Q1%*%ginv(X%*%Q1)%*%W
>>> eps=sum(abs(Q1-Q2))
>>> cat(i,":",eps,"\n")
>>> i=i+1
>>> }
>>>
>>> Perhaps someone could have any idea to solve the problem, or a 
>>> reference on this kind of question or the email of another list 
>>> where I should ask this question.
>>>
>>> Thanks in advance,
>>>
>>> Sincerely.
>>>
>>> St??phane DRAY
>>> -------------------------------------------------------------------------------------------------- 
>>>
>>> D??partement des Sciences Biologiques
>>> Universit?? de Montr??al, C.P. 6128, succursale centre-ville
>>> Montr??al, Qu??bec H3C 3J7, Canada
>>>
>>> Tel : 514 343 6111 poste 1233
>>> E-mail : stephane.dray at umontreal.ca
>>> -------------------------------------------------------------------------------------------------- 
>>>
>>> Web
>>> http://www.steph280.freesurf.fr/
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>
>
> St??phane DRAY
> -------------------------------------------------------------------------------------------------- 
>
> D??partement des Sciences Biologiques
> Universit?? de Montr??al, C.P. 6128, succursale centre-ville
> Montr??al, Qu??bec H3C 3J7, Canada
>
> Tel : 514 343 6111 poste 1233
> E-mail : stephane.dray at umontreal.ca
> -------------------------------------------------------------------------------------------------- 
>
> Web                                          
> http://www.steph280.freesurf.fr/
> -------------------------------------------------------------------------------------------------- 
>
>



From spe2 at cornell.edu  Wed Jul  7 21:26:41 2004
From: spe2 at cornell.edu (Stephen Ellner)
Date: Wed, 07 Jul 2004 15:26:41 -0400
Subject: [R] lme: extract variance estimate
Message-ID: <5.2.1.1.2.20040707151055.00b981d0@postoffice6.mail.cornell.edu>

Spencer Graves wrote: 

>     Have you considered "VarCorr"?  I've used it with "lme", and the 
>documentation in package lme4 suggests it should work with GLMM, which 
>might also do what you want from glmmPQL. 

Thanks for the pointer (I was not aware that nlme and lme4 had different
versions of lme), but I'm still stuck at the same place using lme4:> VarCorr(fit)
 Groups   Name        Variance Std.Dev.
 yeart    (Intercept) 0.040896 0.20223 
 Residual             0.091125 0.30187 

The number I need to extract and store is the .20223, but all the 
components I can find in VarCorr(fit) are something else. 

u=VarCorr(fit); slotNames(u)
[1] "scale"    "reSumry"  "useScale"
> u at scale
[1] 0.3018693
> u at reSumry
$yeart
An object of class "corrmatrix"
            (Intercept)
(Intercept)           1
Slot "stdDev":
(Intercept) 
  0.6699156 
> u at useScale
[1] TRUE

In glmmML the estimate is returned as the $sigma component
of the model, but I also need the same info from 'family=gaussian' 
models. 


Stephen P. Ellner (spe2 at cornell.edu)
Department of Ecology and Evolutionary Biology
Corson Hall, Cornell University, Ithaca NY 14853-2701
Phone (607) 254-4221    FAX (607) 255-8088



From stephane.dray at umontreal.ca  Wed Jul  7 21:28:45 2004
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Wed, 07 Jul 2004 15:28:45 -0400
Subject: [R] Generate a matrix Q satisfying t(Q)%*%Q=Z and XQ=W
In-Reply-To: <40EC4721.9040209@pdf.com>
References: <5.2.1.1.0.20040707142417.00b47218@magellan.umontreal.ca>
	<5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
	<5.2.1.1.0.20040706165552.03a95138@magellan.umontreal.ca>
	<5.2.1.1.0.20040707142417.00b47218@magellan.umontreal.ca>
Message-ID: <5.2.1.1.0.20040707152448.03812450@magellan.umontreal.ca>

Thanks but it does not solve my problem because I would like to generate Q 
(X2) for a given X(X1). X is fixed. But It seems hard to do it and perhaps 
It would be easier to change my approach.

Thanks again for your help


At 14:55 07/07/2004, Spencer Graves wrote:
>      How about generating matrices (X1|X2), dim(X1) = c(n, k1), dim(X2) = 
> c(n, k2), with mean 0 and covariance matrix as follows:
>(S11 | S12)
>(S21 | S22),
>
>with S12 = W, S22 = Z and S11 = whatever you want?  With X = t(X1), and Q 
>= X2, we have E(XQ) = W and E(Q'Q) = Z.
>      This can be done using rmvnorm in package mvtnorm.
>      hope this helps.  spencer graves
>
>Stephane DRAY wrote:
>
>>thanks,
>>I want to create matrices for simulation purpose (in order to evaluate 
>>the efficiency of different methods on this simulated data set). So, I 
>>want to create a data matrix Q (m individuals and r variables). I want to 
>>specify the variance-covariance structure for this matrix (t(Q)%*%Q=Z ) 
>>but I want also to create another constraint due to another matrix of 
>>data. I want that the covariance of Q and X are equal to those given in W 
>>(XQ=W).
>>The example I gave is just to illustrate my problem and perhaps it has no 
>>solution (I cannot see it because I have no idea how to construct Q such 
>>as Q=Q1=Q2)
>>
>>
>>
>>
>>At 00:00 07/07/2004, Spencer Graves wrote:
>>
>>>      Is a solution even possible for the matrices in your example?
>>>I've tried a few things that have suggested that a solution may not be 
>>>possible.
>>>      What can you tell us of the problem that you've translated into 
>>> this?  I see a minimization problem subject to constraints, but I'm not 
>>> certain which are the constraints and what is the objective function.
>>>For example, are you trying to find Q to minimize sum((Z-X'X)^2) subject 
>>>to XQ=W or do you want to minimize sum((XQ-W)^2) subject to Q'Q=Z or 
>>>something else?
>>>      If it were my problem, I think I would work for a while with the 
>>> singular value decompositions of X, W and Z, and see if that would lead 
>>> me to more information about Q, including conditions under which a 
>>> solution existed, expressions for Q when multiple solutions existed, 
>>> and a solution minimizing your chosen objective function when solutions 
>>> do not exist.  (A google search produced many hits for "singular value 
>>> decomposition", implemented as "svd" in R.)
>>>      hope this helps.  spencer graves
>>>
>>>Stephane DRAY wrote:
>>>
>>>>Hello,
>>>>I have a question that is not directly related to R ... but I try to do 
>>>>it in R ;-) :
>>>>
>>>>I would like to generate a matrix Q satisfying (for a given Z, X and W) 
>>>>the two following conditions:
>>>>
>>>>t(Q)%*%Q=Z  (1)
>>>>XQ=W (2)
>>>>
>>>>where:
>>>>Q is m rows and r columns
>>>>X is p rows and m columns
>>>>D is p rows and r columns
>>>>C is r rows and r columns
>>>>with m>p,r
>>>>
>>>>
>>>>e.g:
>>>>m=6,
>>>>p=2
>>>>r=3
>>>>
>>>>Z=matrix(c(1,.2,.5,.2,1,.45,.5,.45,1),3,3)
>>>>X=matrix(c(.1,.3,.5,.6,.2,.1,.8,1,.4,.2,.2,.9),2,6)
>>>>W=matrix(c(0,.8,.4,.6,.2,0),2,3)
>>>>
>>>>#Create a matrix satisfying (1) is easy:
>>>>
>>>>A=matrix(runif(18),6,3)
>>>>Q1=svd(A)$u%*%chol(Z)
>>>>
>>>>
>>>>#For the second condition (2), a solution is given by
>>>>
>>>>Q2=A%*%ginv(X%*%A)%*%W
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>I do not know how to create a matrix Q that satisfies the two 
>>>>conditions.  I have try to construct an iterative procedure without 
>>>>success (no convergence):
>>>>
>>>>eps=10
>>>>i=0
>>>>while(eps>.5)
>>>>{
>>>>Q1=svd(Q2)$u%*%chol(Z)
>>>>Q2=Q1%*%ginv(X%*%Q1)%*%W
>>>>eps=sum(abs(Q1-Q2))
>>>>cat(i,":",eps,"\n")
>>>>i=i+1
>>>>}
>>>>
>>>>Perhaps someone could have any idea to solve the problem, or a 
>>>>reference on this kind of question or the email of another list where I 
>>>>should ask this question.
>>>>
>>>>Thanks in advance,
>>>>
>>>>Sincerely.
>>>>
>>>>St??phane DRAY
>>>>-------------------------------------------------------------------------------------------------- 
>>>>
>>>>D??partement des Sciences Biologiques
>>>>Universit?? de Montr??al, C.P. 6128, succursale centre-ville
>>>>Montr??al, Qu??bec H3C 3J7, Canada
>>>>
>>>>Tel : 514 343 6111 poste 1233
>>>>E-mail : stephane.dray at umontreal.ca
>>>>-------------------------------------------------------------------------------------------------- 
>>>>
>>>>Web
>>>>http://www.steph280.freesurf.fr/
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>http://www.R-project.org/posting-guide.html
>>>
>>
>>St??phane DRAY
>>-------------------------------------------------------------------------------------------------- 
>>
>>D??partement des Sciences Biologiques
>>Universit?? de Montr??al, C.P. 6128, succursale centre-ville
>>Montr??al, Qu??bec H3C 3J7, Canada
>>
>>Tel : 514 343 6111 poste 1233
>>E-mail : stephane.dray at umontreal.ca
>>-------------------------------------------------------------------------------------------------- 
>>
>>Web
>>http://www.steph280.freesurf.fr/
>>-------------------------------------------------------------------------------------------------- 
>>

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From parilov at cat.nyu.edu  Wed Jul  7 21:30:06 2004
From: parilov at cat.nyu.edu (Evgueni Parilov)
Date: Wed, 07 Jul 2004 15:30:06 -0400
Subject: [R] a small bug in spatstat::rmh
Message-ID: <40EC4F3E.4030402@cat.nyu.edu>

Time to time, rmh.default fails to simulate a "lookup"-type process on a 
statement:

if(all.equal(diff(r),rep(deltar,nlook-1))) {
        equisp <- 1
        par <- c(beta,nlook,equisp,deltar,rmax,h)
    } else {
        equisp <- 0
        par <- c(beta,nlook,equisp,deltar,rmax,h,r)
    }

According to the manual, all.equal should not be used in if-statement 
directly. This works:
identical(all.equal(diff(r), rep(deltar, nlook - 1)),TRUE)

Evgueni



From r.mueller at oeko-sorpe.de  Wed Jul  7 21:21:57 2004
From: r.mueller at oeko-sorpe.de (Richard =?iso-8859-15?q?M=FCller?=)
Date: Wed, 7 Jul 2004 21:21:57 +0200
Subject: [R] Importing an Excel file
In-Reply-To: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>
References: <3007F52DF96EB74CAC3054FF85C4318F7A7AC8@mail2>
Message-ID: <200407072121.57612.r.mueller@oeko-sorpe.de>

Am Mittwoch, 7. Juli 2004 20:21 schrieb Park, Kyong H Mr. RDECOM:
> Hello, R users,
> I am  a very beginner of R and tried read.csv to import an excel file after
> saving an excel file as csv. But it added alternating rows of fictitious NA
> values after row number 16. When I applied read.delim, there were trailing
> several commas at the end of each row after row number 16 instead of NA
> values. Appreciate your help.

I import my OpenOffice calc files as follows (OOo or Excel won't make any 
difference, the csv-format is the same):

inp <- (scan(file, sep=";", dec=",", list(0,0), skip = 13, nlines = 58)
x <- inp[[1]]; y <- inp [[2]]

sep=";": column separator ;
dec="," decimal separator ,
list(0,0): first two columns
skip: no of lines to skip (these lines contain comments etc.)
nlines=58: 58 lines of values to plot
hth, Richard
--
Richard M??ller - Am Spring 9 - D-58802 Balve-Eisborn
r.mueller at oeko-sorpe.de      -     www.oeko-sorpe.de



From roebuck at odin.mdacc.tmc.edu  Wed Jul  7 21:59:04 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed, 7 Jul 2004 14:59:04 -0500 (CDT)
Subject: [R] NAMESPACE and tests for unexported functions
Message-ID: <Pine.OSF.4.58.0407071441420.338741@odin.mdacc.tmc.edu>

How do you get around the problem of having tests for
functions that are not exported in NAMESPACE? It seems
rather self-defeating to have to export everything so
that 'R CMD CHECK pkg' won't crash when it encounters
a test case for an internal function. I don't want
someone using the package to call the function, but the
package itself should be able to see its own contents.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From spencer.graves at pdf.com  Wed Jul  7 22:02:11 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 07 Jul 2004 13:02:11 -0700
Subject: [R] lme: extract variance estimate
In-Reply-To: <5.2.1.1.2.20040707151055.00b981d0@postoffice6.mail.cornell.edu>
References: <5.2.1.1.2.20040707151055.00b981d0@postoffice6.mail.cornell.edu>
Message-ID: <40EC56C3.5070101@pdf.com>

      I just tried it in both lme4 and nlme.  I got it in nlme but not 
lme4.  I'm sure lme4 is better in many ways, but I could not figure out 
how to get what you want in lme4. 

      Specifically, I tried the following: 

DF <- data.frame(x=rep(letters[1:2], 2), y=rep(1:2, 2)+0.01*(1:4))
fit <- lme(y~1, random=~1|x, data=DF)
VC <- VarCorr(fit)
VC
VC[1,2]

      When I did this in library(nlme), I got the following: 

 > VC
x = pdLogChol(1)
            Variance     StdDev   
(Intercept) 0.5101563004 0.71425227
Residual    0.0001999596 0.01414071
 > VC[1,2]
[1] "0.71425227"

      However, when I did it in library(lme4), I got something different: 

 > VC
 Groups   Name        Variance Std.Dev.
 x        (Intercept) 0.50995  0.71411
 Residual             2e-04    0.014142
 > VC[1,2]
Error in VC[1, 2] : incorrect number of dimensions

      I was concerned by the differences in the estimates in this case, 
so I ported this problem to S-Plus 6.2.  There I got the "lme4" answers 
from both "lme" and "varcomp". 

      hope this helps.  spencer graves

Stephen Ellner wrote:

>Spencer Graves wrote: 
>
>  
>
>>    Have you considered "VarCorr"?  I've used it with "lme", and the 
>>documentation in package lme4 suggests it should work with GLMM, which 
>>might also do what you want from glmmPQL. 
>>    
>>
>
>Thanks for the pointer (I was not aware that nlme and lme4 had different
>versions of lme), but I'm still stuck at the same place using lme4:> VarCorr(fit)
> Groups   Name        Variance Std.Dev.
> yeart    (Intercept) 0.040896 0.20223 
> Residual             0.091125 0.30187 
>
>The number I need to extract and store is the .20223, but all the 
>components I can find in VarCorr(fit) are something else. 
>
>u=VarCorr(fit); slotNames(u)
>[1] "scale"    "reSumry"  "useScale"
>  
>
>>u at scale
>>    
>>
>[1] 0.3018693
>  
>
>>u at reSumry
>>    
>>
>$yeart
>An object of class "corrmatrix"
>            (Intercept)
>(Intercept)           1
>Slot "stdDev":
>(Intercept) 
>  0.6699156 
>  
>
>>u at useScale
>>    
>>
>[1] TRUE
>
>In glmmML the estimate is returned as the $sigma component
>of the model, but I also need the same info from 'family=gaussian' 
>models. 
>
>
>Stephen P. Ellner (spe2 at cornell.edu)
>Department of Ecology and Evolutionary Biology
>Corson Hall, Cornell University, Ithaca NY 14853-2701
>Phone (607) 254-4221    FAX (607) 255-8088
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Wed Jul  7 22:01:58 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 7 Jul 2004 16:01:58 -0400
Subject: [R] NAMESPACE and tests for unexported functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FEE@usrymx25.merck.com>

Not sure if this is recommended for testing purposes, but you can try using
`:::'; e.g., mypkg:::invisibleFunction(...).

Andy

> From: Paul Roebuck
> 
> How do you get around the problem of having tests for
> functions that are not exported in NAMESPACE? It seems
> rather self-defeating to have to export everything so
> that 'R CMD CHECK pkg' won't crash when it encounters
> a test case for an internal function. I don't want
> someone using the package to call the function, but the
> package itself should be able to see its own contents.
> 
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)



From ligges at statistik.uni-dortmund.de  Wed Jul  7 22:09:43 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 Jul 2004 22:09:43 +0200
Subject: [R] KalmanSmooth problem
In-Reply-To: <40EC4902.2050401@pdf.com>
References: <7263F1C61318A24080FBC425CA4AE4C6F381B7@salte0008.wurnet.nl>
	<40EC42C9.4080309@statistik.uni-dortmund.de>
	<40EC4902.2050401@pdf.com>
Message-ID: <40EC5887.5040007@statistik.uni-dortmund.de>

Spencer Graves wrote:

> Hi, Uwe:  "KalmanSmooth" is in the "stats" package in R 1.9.1.  R is 
> moving so fast that it is impossible to keep current with all parts of 
> it.  Best Wishes, Spencer Graves

Uhhhh .... thanks, Spencer. My apologies to Pieter.

Indeed, looks like I forgot to upgrade my R version on the machine at 
home. I only did so in my office and on my laptop.

Uwe


> Uwe Ligges wrote:
> 
>> Hazenberg21, Pieter wrote:
>>
>>> Hello,
>>> In R I am trying to use Kalman filtering to find a solution for an 
>>> hydrological problem. With Kalman Filtering I want to estimate the 
>>> discharge comming from three storage bassins. I have programmed a 
>>> function in R which can run KalmanSmooth. When I'm asking for the 
>>> function and putting in values, R detects the following error: "Error 
>>> in as.vector(data) : Argument "S1" is missing, with no default".
>>> I have try to find a solution for this error in the R help file, and 
>>> in different manuals, but I can't find it. Please help me find a 
>>> solution.
>>> Question: What does R mean with "S1" and what am I doing wrong?
>>> Here is the way I have programmed the hydrological problem in R. 
>>>
>>>> discharge=read.table(file="C:/Program 
>>>> Files/R/rw1090/discharge.txt",header=T)
>>>> deb=discharge[,1]
>>>> deb
>>>
>>>
>>>
>>>   [1] 11.545313  8.045465  5.670868  4.044584  2.919311  2.306668  
>>> 2.940956
>>>   [8]  4.238159  5.017374  3.818236  2.928805  2.262183  1.757765  
>>> 1.633945
>>>  [15]  2.295130  3.454054  4.035224  3.193967  2.533181  2.012406  
>>> 1.600836
>>>  [22]  1.652155  2.428678  3.642827  4.019545  3.209473  2.563617  
>>> 2.048347
>>>  [29]  1.637041  1.828952  2.757842  4.050821  4.147013  3.316503  
>>> 2.652490
>>>  [36]  2.121535  1.696934  2.027763  3.107366  4.429670  4.160178  
>>> 3.327950
>>>  [43]  2.662237  2.129710  1.703717  2.158095  3.337039  4.582359  
>>> 3.905901
>>>  [50]  3.124690  2.499732  1.999772  1.599810  2.130893  3.302622  
>>> 4.336081
>>>  [57]  3.468857  2.775081  2.220062  1.776048  1.560859  2.169537  
>>> 3.348081
>>>  [64]  4.170552  3.336440  2.669151  2.135320  1.708256  1.648859  
>>> 2.374217
>>>  [71]  3.624091  4.248563  3.398850  2.719080  2.175264  1.740211  
>>> 1.826122
>>>  [78]  2.704749  4.056438  4.437309  3.549847  2.839878  2.271902  
>>> 1.817522
>>>  [85]  2.053994  3.107875  4.548436  4.600601  3.680481  2.944385  
>>> 2.355508
>>>  [92]  1.884406  2.273248  3.490148  4.949898  4.584409  3.667527  
>>> 2.934022
>>>  [99]  2.347217  1.877774
>>>
>>>> Kalm = function(x,O1,O2,O3,T1,T2,T3,T4,T5,t,ga){
>>>
>>>
>>>
>>> + 
>>> t=array(c(1+ga*O1+t/O1*(-(1/T2)-(1/T3)-(1/T1)),t/O1*(1/T2),t/O1*(1/T3),
>>> + t/O2*(1/T2),1+ga*O2+t/O2*(-(1/T2)-(1/T4)),t/O2*(1/T4),
>>> + 
>>> t/O3*(1/T3),t/O3*(1/T4),1+ga*O3+t/O3*(-(1/T3)-(1/T4)-(1/T5))),dim=c(3,3)); 
>>>
>>> + h=0.5;
>>> + r=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
>>> + q=1;
>>> + v=r*q*t(r);
>>> + a=10.14286;
>>> + z=array(c((1/T1),0,0,0,0,0,0,0,(1/T5)), dim=c(3,3));
>>> + p=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
>>> + pn=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
>>> + kal=KalmanSmooth(x, list(T=t,Z=z,h=h,V=v,a=a,P=p,Pn=pn), nit=0)
>>> + kal}
>>>  
>>>
>>>> Kalm(deb,4,.5,5,.7,.1,2,3,4,1,0.65)
>>>
>>>
>>>
>>> Error in as.vector(data) : Argument "S1" is missing, with no default
>>>  
>>> First I thought I had to make a timeserie of deb. But this doesn't 
>>> change the problem.
>>> Lot's of thanks trying to help me. 
>>
>>
>>
>> a) Please tell us R Version and OS (OK, implicitly done that we are 
>> talking about R-1.9.0 on Windows).
>> b) Please tell us which packages you are using (I don't know 
>> KalmanSmooth(), for example).
>> c) Please try to specify reproducible examples.
>>
>> Conclusion for a-c): Please read the posting-guide.
>>
>> My hint is to try to debug yourself, at least *try*, starting eith 
>> calling traceback() right after the error appeared, in order to get a 
>> guess where the error really happens. Then look at the data that is 
>> passed to the function -  and I'm pretty sure you will get at least an 
>> idea what goes wrong.
>>
>> Uwe Ligges
>>
>>
>>
>>
>>
>>> Best regards,
>>> Pieter Hazenberg
>>> Student Hydrology and Watermanagement
>>> Wageningen University
>>> The Netherlands
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
>



From ligges at statistik.uni-dortmund.de  Wed Jul  7 22:17:08 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 Jul 2004 22:17:08 +0200
Subject: [R] a small bug in spatstat::rmh
In-Reply-To: <40EC4F3E.4030402@cat.nyu.edu>
References: <40EC4F3E.4030402@cat.nyu.edu>
Message-ID: <40EC5A44.9070200@statistik.uni-dortmund.de>

Evgueni Parilov wrote:

> Time to time, rmh.default fails to simulate a "lookup"-type process on a 
> statement:
> 
> if(all.equal(diff(r),rep(deltar,nlook-1))) {
>        equisp <- 1
>        par <- c(beta,nlook,equisp,deltar,rmax,h)
>    } else {
>        equisp <- 0
>        par <- c(beta,nlook,equisp,deltar,rmax,h,r)
>    }
> 
> According to the manual, all.equal should not be used in if-statement 
> directly. This works:
> identical(all.equal(diff(r), rep(deltar, nlook - 1)),TRUE)
> 
> Evgueni
> 

According to library(help = spatstat), Adrian Baddeley 
<adrian at maths.uwa.edu.au> (in CC) is maintainer of the spatstat package 
- and therefore the right addressee of this message.

Uwe Ligges



From Pieter.Hazenberg21 at wur.nl  Wed Jul  7 22:26:30 2004
From: Pieter.Hazenberg21 at wur.nl (Hazenberg21, Pieter)
Date: Wed, 7 Jul 2004 22:26:30 +0200
Subject: [R] KalmanSmooth problem
Message-ID: <7263F1C61318A24080FBC425CA4AE4C6F381BA@salte0008.wurnet.nl>

Dear Uwe and Spencer,
Thanks for replying so soon. The R version I wrote is indeed R 1.9.1, and the package is stats. Sorry I didn't wrote it in my first email. I've have tried to use the comments you gave, and simplified my function. 
It is changed to:
 
> Kalm = function(x){
+ t=array(c(-1.4248, 2.5, .1250, 20, -19.3183, .6667, .1, .0667, 1.7945), dim=c(3,3))
+ h=0.5;
+ r=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
+ q=1;
+ v=r*q*t(r);
+ a=10.14286;
+ z=array(c(.3574, 0, 0, 0, 0, 0, 0, 0, .2), dim=c(3,3))
+ p=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
+ pn=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
+ kal=KalmanSmooth(x,list(T=t,Z=z,h=h,V=v,a=a,P=p,Pn=pn),nit=0)
+ kal}
>Kalm(deb)
 
Wonderfully it is running quite well now. Thank you for your spare time.
Best regards,
Pieter Hazenberg

	-----Oorspronkelijk bericht----- 
	Van: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
	Verzonden: wo 7-7-2004 22:09 
	Aan: Spencer Graves; Hazenberg21, Pieter 
	CC: R Help Mailing List 
	Onderwerp: Re: [R] KalmanSmooth problem
	
	

	Spencer Graves wrote:
	
	> Hi, Uwe:  "KalmanSmooth" is in the "stats" package in R 1.9.1.  R is
	> moving so fast that it is impossible to keep current with all parts of
	> it.  Best Wishes, Spencer Graves
	
	Uhhhh .... thanks, Spencer. My apologies to Pieter.
	
	Indeed, looks like I forgot to upgrade my R version on the machine at
	home. I only did so in my office and on my laptop.
	
	Uwe
	
	
	> Uwe Ligges wrote:
	>
	>> Hazenberg21, Pieter wrote:
	>>
	>>> Hello,
	>>> In R I am trying to use Kalman filtering to find a solution for an
	>>> hydrological problem. With Kalman Filtering I want to estimate the
	>>> discharge comming from three storage bassins. I have programmed a
	>>> function in R which can run KalmanSmooth. When I'm asking for the
	>>> function and putting in values, R detects the following error: "Error
	>>> in as.vector(data) : Argument "S1" is missing, with no default".
	>>> I have try to find a solution for this error in the R help file, and
	>>> in different manuals, but I can't find it. Please help me find a
	>>> solution.
	>>> Question: What does R mean with "S1" and what am I doing wrong?
	>>> Here is the way I have programmed the hydrological problem in R.
	>>>
	>>>> discharge=read.table(file="C:/Program
	>>>> Files/R/rw1090/discharge.txt",header=T)
	>>>> deb=discharge[,1]
	>>>> deb
	>>>
	>>>
	>>>
	>>>   [1] 11.545313  8.045465  5.670868  4.044584  2.919311  2.306668 
	>>> 2.940956
	>>>   [8]  4.238159  5.017374  3.818236  2.928805  2.262183  1.757765 
	>>> 1.633945
	>>>  [15]  2.295130  3.454054  4.035224  3.193967  2.533181  2.012406 
	>>> 1.600836
	>>>  [22]  1.652155  2.428678  3.642827  4.019545  3.209473  2.563617 
	>>> 2.048347
	>>>  [29]  1.637041  1.828952  2.757842  4.050821  4.147013  3.316503 
	>>> 2.652490
	>>>  [36]  2.121535  1.696934  2.027763  3.107366  4.429670  4.160178 
	>>> 3.327950
	>>>  [43]  2.662237  2.129710  1.703717  2.158095  3.337039  4.582359 
	>>> 3.905901
	>>>  [50]  3.124690  2.499732  1.999772  1.599810  2.130893  3.302622 
	>>> 4.336081
	>>>  [57]  3.468857  2.775081  2.220062  1.776048  1.560859  2.169537 
	>>> 3.348081
	>>>  [64]  4.170552  3.336440  2.669151  2.135320  1.708256  1.648859 
	>>> 2.374217
	>>>  [71]  3.624091  4.248563  3.398850  2.719080  2.175264  1.740211 
	>>> 1.826122
	>>>  [78]  2.704749  4.056438  4.437309  3.549847  2.839878  2.271902 
	>>> 1.817522
	>>>  [85]  2.053994  3.107875  4.548436  4.600601  3.680481  2.944385 
	>>> 2.355508
	>>>  [92]  1.884406  2.273248  3.490148  4.949898  4.584409  3.667527 
	>>> 2.934022
	>>>  [99]  2.347217  1.877774
	>>>
	>>>> Kalm = function(x,O1,O2,O3,T1,T2,T3,T4,T5,t,ga){
	>>>
	>>>
	>>>
	>>> +
	>>> t=array(c(1+ga*O1+t/O1*(-(1/T2)-(1/T3)-(1/T1)),t/O1*(1/T2),t/O1*(1/T3),
	>>> + t/O2*(1/T2),1+ga*O2+t/O2*(-(1/T2)-(1/T4)),t/O2*(1/T4),
	>>> +
	>>> t/O3*(1/T3),t/O3*(1/T4),1+ga*O3+t/O3*(-(1/T3)-(1/T4)-(1/T5))),dim=c(3,3));
	>>>
	>>> + h=0.5;
	>>> + r=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
	>>> + q=1;
	>>> + v=r*q*t(r);
	>>> + a=10.14286;
	>>> + z=array(c((1/T1),0,0,0,0,0,0,0,(1/T5)), dim=c(3,3));
	>>> + p=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
	>>> + pn=array(c(1,0,0,0,1,0,0,0,1),dim=c(3,3));
	>>> + kal=KalmanSmooth(x, list(T=t,Z=z,h=h,V=v,a=a,P=p,Pn=pn), nit=0)
	>>> + kal}
	>>> 
	>>>
	>>>> Kalm(deb,4,.5,5,.7,.1,2,3,4,1,0.65)
	>>>
	>>>
	>>>
	>>> Error in as.vector(data) : Argument "S1" is missing, with no default
	>>> 
	>>> First I thought I had to make a timeserie of deb. But this doesn't
	>>> change the problem.
	>>> Lot's of thanks trying to help me.
	>>
	>>
	>>
	>> a) Please tell us R Version and OS (OK, implicitly done that we are
	>> talking about R-1.9.0 on Windows).
	>> b) Please tell us which packages you are using (I don't know
	>> KalmanSmooth(), for example).
	>> c) Please try to specify reproducible examples.
	>>
	>> Conclusion for a-c): Please read the posting-guide.
	>>
	>> My hint is to try to debug yourself, at least *try*, starting eith
	>> calling traceback() right after the error appeared, in order to get a
	>> guess where the error really happens. Then look at the data that is
	>> passed to the function -  and I'm pretty sure you will get at least an
	>> idea what goes wrong.
	>>
	>> Uwe Ligges
	>>
	>>
	>>
	>>
	>>
	>>> Best regards,
	>>> Pieter Hazenberg
	>>> Student Hydrology and Watermanagement
	>>> Wageningen University
	>>> The Netherlands
	>>>
	>>> ______________________________________________
	>>> R-help at stat.math.ethz.ch mailing list
	>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
	>>> PLEASE do read the posting guide!
	>>> http://www.R-project.org/posting-guide.html
	>>
	>>
	>>
	>> ______________________________________________
	>> R-help at stat.math.ethz.ch mailing list
	>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
	>> PLEASE do read the posting guide!
	>> http://www.R-project.org/posting-guide.html
	>
	>
	>



From lauraholt_983 at hotmail.com  Wed Jul  7 22:30:47 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Wed, 07 Jul 2004 15:30:47 -0500
Subject: [R] question about seq.dates from chron vs. as.POSIXct
Message-ID: <BAY12-F5ufVma0osA9100000198@hotmail.com>

Dear R People:

Here is an interesting question:

>library(chron)
>xt <- seq.dates(from="01/01/2004",by="days",length=5)
>xt
[1] 01/01/04 01/02/04 01/03/04 01/04/04 01/05/04
>
#Fine so far
>as.POSIXct(xt)
[1] "2003-12-31 18:00:00 Central Standard Time"
[2] "2004-01-01 18:00:00 Central Standard Time"
[3] "2004-01-02 18:00:00 Central Standard Time"
[4] "2004-01-03 18:00:00 Central Standard Time"
[5] "2004-01-04 18:00:00 Central Standard Time"
>
Why do the dates change, please?  Presumably the as.POSIXct is taking the xt 
as midnight GMT and converting to Central Standard Time.

Is the best solution to:
>as.POSIXlt(xt, "CST")
[1] "2004-01-01 CST" "2004-01-02 CST" "2004-01-03 CST" "2004-01-04 CST"
[5] "2004-01-05 CST"
>

Thanks in advance!

Sincerely,
Laura Holt
who is corrupted by dates and times
mailto: lauraholt_983 at hotmail.com


download! http://toolbar.msn.click-url.com/go/onm00200413ave/direct/01/



From amackey at pcbi.upenn.edu  Wed Jul  7 22:31:25 2004
From: amackey at pcbi.upenn.edu (Aaron J. Mackey)
Date: Wed, 7 Jul 2004 16:31:25 -0400
Subject: [R] lost messages
In-Reply-To: <XFMail.040707210555.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.040707210555.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <9DC76C6E-D054-11D8-A117-000A9577009E@pcbi.upenn.edu>


The second two resends did go through (I checked on the web archive), 
but the first did not; additionally, the second two resends both came 
through with the exact same timestamp, even though I resent them over 
the space of 4 hours or so (and only after I had sent the "lost 
messages" message, which did come through to me just fine).  So there 
was something "stuck", but seems to be unstuck now.

Thanks to all,

-Aaron

On Jul 7, 2004, at 4:05 PM, (Ted Harding) wrote:

> On 07-Jul-04 Aaron J. Mackey wrote:
>>
>> I've posted a message twice to this list, and never seen it appear yet
>> ... perhaps this one will go through ... ?
>
> Hi Aaron,
> Yes, it did get through. If you have not received it yourself, then
> possibly your subscription to R-help has got set to "nomail" or
> equivalent. It would be worth checking.
>
> Best wishes,
> Ted.



From yzhou at sdsc.edu  Thu Jul  8 00:47:37 2004
From: yzhou at sdsc.edu (Yi-Xiong Sean Zhou)
Date: Wed, 7 Jul 2004 15:47:37 -0700
Subject: [R] text editor for R
Message-ID: <000601c46474$68109e40$9941f984@D3BC5441>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040707/7f5886cf/attachment.pl

From sundar.dorai-raj at PDF.COM  Thu Jul  8 01:01:43 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 07 Jul 2004 18:01:43 -0500
Subject: [R] text editor for R
In-Reply-To: <000601c46474$68109e40$9941f984@D3BC5441>
References: <000601c46474$68109e40$9941f984@D3BC5441>
Message-ID: <40EC80D7.9050605@pdf.com>



Yi-Xiong Sean Zhou wrote:
> Hi, 
> 
>  
> 
> What is the best text editor for programming in R? I am using JEdit as the
> text editor, however, it does not have anything specific for R. It will be
> nice to have a developing environment where the keywords are highlighted,
> plus some other debugging functions. 
> 
>  
> 
> Yi-Xiong
> 
>  

"best" is subjective, but (X)Emacs with ESS seems to be the most 
popular. See the following for more:

http://cran.us.r-project.org/other-software.html

--sundar



From MSchwartz at MedAnalytics.com  Thu Jul  8 01:04:42 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 07 Jul 2004 18:04:42 -0500
Subject: [R] text editor for R
In-Reply-To: <000601c46474$68109e40$9941f984@D3BC5441>
References: <000601c46474$68109e40$9941f984@D3BC5441>
Message-ID: <1089241482.8740.27.camel@localhost.localdomain>

On Wed, 2004-07-07 at 17:47, Yi-Xiong Sean Zhou wrote:
> Hi, 

> What is the best text editor for programming in R? I am using JEdit as the
> text editor, however, it does not have anything specific for R. It will be
> nice to have a developing environment where the keywords are highlighted,
> plus some other debugging functions. 
> 
> Yi-Xiong

More information is available at:

http://www.sciviews.org/_rgui/

Your e-mail headers suggest that you are using Windows. Thus, perhaps
the two best choices (subject to challenge by others) would be:

1. R-WinEdt (Under IDE/Script Editors)

2. ESS for Windows

The above two tools provide for a wide variety of functionality beyond
syntax highlighting.

There is a syntax highlighting file listed at the above site for jEdit.

HTH,

Marc Schwartz



From maj at stats.waikato.ac.nz  Thu Jul  8 01:37:23 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 08 Jul 2004 11:37:23 +1200
Subject: [R] text editor for R
In-Reply-To: <1089241482.8740.27.camel@localhost.localdomain>
References: <000601c46474$68109e40$9941f984@D3BC5441>
	<1089241482.8740.27.camel@localhost.localdomain>
Message-ID: <40EC8933.70704@stats.waikato.ac.nz>

I tried R-WinEdt a few years ago, but as I remember it interfered with 
my usual use of WinEdt which is as a front end to MiKTeX. Is there a way 
to use WinEdt both ways?

Murray Jorgensen

Marc Schwartz wrote:

> On Wed, 2004-07-07 at 17:47, Yi-Xiong Sean Zhou wrote:
> 
>>Hi, 
> 
> 
>>What is the best text editor for programming in R? I am using JEdit as the
>>text editor, however, it does not have anything specific for R. It will be
>>nice to have a developing environment where the keywords are highlighted,
>>plus some other debugging functions. 
>>
>>Yi-Xiong
> 
> 
> More information is available at:
> 
> http://www.sciviews.org/_rgui/
> 
> Your e-mail headers suggest that you are using Windows. Thus, perhaps
> the two best choices (subject to challenge by others) would be:
> 
> 1. R-WinEdt (Under IDE/Script Editors)
> 
> 2. ESS for Windows
> 
> The above two tools provide for a wide variety of functionality beyond
> syntax highlighting.
> 
> There is a syntax highlighting file listed at the above site for jEdit.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From andy_liaw at merck.com  Thu Jul  8 01:44:56 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 7 Jul 2004 19:44:56 -0400
Subject: [R] text editor for R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FF0@usrymx25.merck.com>

Uwe would be the authority on this 8-), but my impression is that if you
keep two separate shortcuts, you should be fine.  The one for R-WinEdt has
flags that sets it up for R, which should not be used in the one for MikTeX.

Andy

> From: Murray Jorgensen
> 
> I tried R-WinEdt a few years ago, but as I remember it 
> interfered with 
> my usual use of WinEdt which is as a front end to MiKTeX. Is 
> there a way 
> to use WinEdt both ways?
> 
> Murray Jorgensen
> 
> Marc Schwartz wrote:
> 
> > On Wed, 2004-07-07 at 17:47, Yi-Xiong Sean Zhou wrote:
> > 
> >>Hi, 
> > 
> > 
> >>What is the best text editor for programming in R? I am 
> using JEdit as the
> >>text editor, however, it does not have anything specific 
> for R. It will be
> >>nice to have a developing environment where the keywords 
> are highlighted,
> >>plus some other debugging functions. 
> >>
> >>Yi-Xiong
> > 
> > 
> > More information is available at:
> > 
> > http://www.sciviews.org/_rgui/
> > 
> > Your e-mail headers suggest that you are using Windows. 
> Thus, perhaps
> > the two best choices (subject to challenge by others) would be:
> > 
> > 1. R-WinEdt (Under IDE/Script Editors)
> > 
> > 2. ESS for Windows
> > 
> > The above two tools provide for a wide variety of 
> functionality beyond
> > syntax highlighting.
> > 
> > There is a syntax highlighting file listed at the above 
> site for jEdit.
> > 
> > HTH,
> > 
> > Marc Schwartz
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> -- 
> Dr 
> Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ivo_welch-rstat8783 at mailblocks.com  Thu Jul  8 01:52:10 2004
From: ivo_welch-rstat8783 at mailblocks.com (ivo_welch-rstat8783@mailblocks.com)
Date: Wed, 07 Jul 2004 16:52:10 -0700
Subject: [R] omit complete cases
In-Reply-To: <200407061003.i66A1vZc012302@hypatia.math.ethz.ch>
References: <200407061003.i66A1vZc012302@hypatia.math.ethz.ch>
Message-ID: <200407072352.i67NqBoe030463@hypatia.math.ethz.ch>


thanks everyone.   all solutions were better than what I had, and 
simple.

R is an interesting experience.  Extremely powerful and awe-inspiring 
for its elegance;  things work like I would never have believed how 
elegantly  they work.  The IQ in the subsetting alone is superbly 
clever.  And then it turns around: figuring out how to do simple things 
can take a long time---until I realize that it is somewhere somehow 
built in already.  So, R (and the answers from helpful souls on this 
list) often makes me feel quite stupid.  Yes, I first search; yes, I 
always look---but either I did not know or I had forgotten.

I used to use perl for much work, and although there is much to like 
about it, R seems to be even better for most tasks---except that there 
is one perl resource that R cannot beat:  the Perl Cookbook.  if I only 
had an R cookbook...

regards,

/ivo
---
ivo welch
professor of finance and economics
brown / nber / yale



From lschaffe at gnf.org  Thu Jul  8 01:56:11 2004
From: lschaffe at gnf.org (Lana Schaffer)
Date: Wed, 7 Jul 2004 16:56:11 -0700
Subject: [R] command line interface
Message-ID: <833E32F61B9F8746878F2A1865BECE60014553FE@EXCHCLUSTER01.lj.gnf.org>


How can plots (histograms) be implemented with the command line interface to R?
Lana Schaffer



From wangk at maths.anu.edu.au  Thu Jul  8 02:01:24 2004
From: wangk at maths.anu.edu.au (Kevin Wang)
Date: Thu, 8 Jul 2004 10:01:24 +1000 (EST)
Subject: [R] text editor for R
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7FF0@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7FF0@usrymx25.merck.com>
Message-ID: <Pine.GSO.4.58.0407080958530.24831@yin>

Hi,

> Uwe would be the authority on this 8-), but my impression is that if you
> keep two separate shortcuts, you should be fine.  The one for R-WinEdt has
> flags that sets it up for R, which should not be used in the one for MikTeX.

I think Andy is correct.  A few years ago (back in the dark ages -- before
I discovered Emacs/ESS), I had two short cuts, one calls R-WinEdt (i.e.
with flags...etc) and the other with just a normal WinEdt icon.

However, I *think* now you can interact R-WinEdt within R directly (I
tried the new version about 2 ~ 3 months ago just for fun, and that seemed
to be the case, but I can't quite remember *_*).

Cheers,

Kevin

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7411
Ph (M): +61-40-451-8301



From d.scott at auckland.ac.nz  Thu Jul  8 02:21:09 2004
From: d.scott at auckland.ac.nz (David Scott)
Date: Thu, 8 Jul 2004 12:21:09 +1200 (NZST)
Subject: [R] text editor for R
In-Reply-To: <40EC8933.70704@stats.waikato.ac.nz>
Message-ID: <Pine.LNX.4.44.0407081210400.25647-100000@hydra.stat.auckland.ac.nz>

On Thu, 8 Jul 2004, Murray Jorgensen wrote:

> I tried R-WinEdt a few years ago, but as I remember it interfered with 
> my usual use of WinEdt which is as a front end to MiKTeX. Is there a way 
> to use WinEdt both ways?
> 
> Murray Jorgensen
> 
This problem annoyed me for a while too. My solution (which is not perhaps 
ideal) is this. You want two different incarnations of WinEdt, one for 
TeX, the other for R. On the desktop I have a shortcut to WinEdt which is 
the one for TeX stuff. I open the other one with R syntax highlighting etc 
by starting R and using library(RWinEdt). To do this you have to install 
the RWinEdt package and SWinRegistry. This is all well explained in the 
ReadMe.txt for RWinEdt.

I think with the right additions to the Target field in a shortcut to 
WinEdt you can call up the incarnation of WinEdt that is suitable for R. I 
haven't done that. You would then have two shortcuts to WinEdt, one for 
your TeX stuff, one for R.

Uwe Ligges is the guru for this though.

David Scott

________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 


Graduate Officer, Department of Statistics



From mkimpel at iupui.edu  Thu Jul  8 03:10:11 2004
From: mkimpel at iupui.edu (Kimpel, Mark W)
Date: Wed, 7 Jul 2004 20:10:11 -0500
Subject: [R] S data library
Message-ID: <2E6C5260C7C387449A96DF46EE76313C012D5C5C@iu-mssg-mbx02.exchange.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040707/0687a57a/attachment.pl

From flom at ndri.org  Thu Jul  8 03:30:51 2004
From: flom at ndri.org (Peter Flom)
Date: Wed, 07 Jul 2004 21:30:51 -0400
Subject: [R] text editor for R
Message-ID: <s0ec6b9f.062@MAIL.NDRI.ORG>

I use WinEdt for both.  I simply installed it twice, and set up one
version for R and one for LaTeX, I have seperate icons on the desktop,
with different names, and it works fine.

HTH

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)


>>> maj at stats.waikato.ac.nz 07/07/04 7:37 PM >>>
I tried R-WinEdt a few years ago, but as I remember it interfered with 
my usual use of WinEdt which is as a front end to MiKTeX. Is there a way

to use WinEdt both ways?

Murray Jorgensen

Marc Schwartz wrote:

> On Wed, 2004-07-07 at 17:47, Yi-Xiong Sean Zhou wrote:
> 
>>Hi, 
> 
> 
>>What is the best text editor for programming in R? I am using JEdit as
the
>>text editor, however, it does not have anything specific for R. It
will be
>>nice to have a developing environment where the keywords are
highlighted,
>>plus some other debugging functions. 
>>
>>Yi-Xiong
> 
> 
> More information is available at:
> 
> http://www.sciviews.org/_rgui/
> 
> Your e-mail headers suggest that you are using Windows. Thus, perhaps
> the two best choices (subject to challenge by others) would be:
> 
> 1. R-WinEdt (Under IDE/Script Editors)
> 
> 2. ESS for Windows
> 
> The above two tools provide for a wide variety of functionality beyond
> syntax highlighting.
> 
> There is a syntax highlighting file listed at the above site for
jEdit.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From maj at stats.waikato.ac.nz  Thu Jul  8 03:46:53 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 08 Jul 2004 13:46:53 +1200
Subject: [R] text editor for R
In-Reply-To: <Pine.LNX.4.44.0407081210400.25647-100000@hydra.stat.auckland.ac.nz>
References: <Pine.LNX.4.44.0407081210400.25647-100000@hydra.stat.auckland.ac.nz>
Message-ID: <40ECA78D.50608@stats.waikato.ac.nz>

Oh, yes. I think I did do something like this, but for some reason the 
two incarnations bothered me.

Murray Jorgensen

David Scott wrote:

> On Thu, 8 Jul 2004, Murray Jorgensen wrote:
> 
> 
>>I tried R-WinEdt a few years ago, but as I remember it interfered with 
>>my usual use of WinEdt which is as a front end to MiKTeX. Is there a way 
>>to use WinEdt both ways?
>>
>>Murray Jorgensen
>>
> 
> This problem annoyed me for a while too. My solution (which is not perhaps 
> ideal) is this. You want two different incarnations of WinEdt, one for 
> TeX, the other for R. On the desktop I have a shortcut to WinEdt which is 
> the one for TeX stuff. I open the other one with R syntax highlighting etc 
> by starting R and using library(RWinEdt). To do this you have to install 
> the RWinEdt package and SWinRegistry. This is all well explained in the 
> ReadMe.txt for RWinEdt.
> 
> I think with the right additions to the Target field in a shortcut to 
> WinEdt you can call up the incarnation of WinEdt that is suitable for R. I 
> haven't done that. You would then have two shortcuts to WinEdt, one for 
> your TeX stuff, one for R.
> 
> Uwe Ligges is the guru for this though.
> 
> David Scott
> 
> ________________________________________________________________
> David Scott	Department of Statistics, Tamaki Campus
> 		The University of Auckland, PB 92019
> 		Auckland	NEW ZEALAND
> Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
> Email:	d.scott at auckland.ac.nz 
> 
> 
> Graduate Officer, Department of Statistics
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From biocperi at yahoo.com  Thu Jul  8 04:56:07 2004
From: biocperi at yahoo.com (S Peri)
Date: Wed, 7 Jul 2004 19:56:07 -0700 (PDT)
Subject: [R] read.frame
Message-ID: <20040708025607.44751.qmail@web50004.mail.yahoo.com>

Hello group, 
  I am learning R and I am new to many concepts.I face
the following errors when I am trying to execute the
following. I have 4 text files with protein accession
numbers. I wanted to represent them in a venn diagram
and for that I using intersect and setdiff functions.

My data looks like this:

file1.txt (c):
NP_000005
NP_000020
NP_000030
NP_000053

file2.txt(e):
NP_000005
NP_000020
NP_000030
NP_000031
NP_000053
NP_000055
NP_000087

file3.txt(h):
NP_000005
NP_000020
NP_000030
NP_000053
NP_000055
NP_000057
NP_000087

file4.txt (s):
NP_000005
NP_000020
NP_000030
NP_000033
NP_000053
NP_000055
NP_000087
NP_000168


Now I did the following FIRST time:
c=read.table("file1.txt")
e=read.table("file2.txt")
s=read.table("file4.txt")
h=read.table("file3.txt")

> class(c)
[1] "data.frame"
> class(s)
[1] "data.frame"
> CiS=intersect(c,s)
> CiS
NULL data frame with 0 rows 
##### Why am I getting NULL data error. I know there
are common elements between c and S. ##########

> CiS<-intersect(read.matrix(c,s))
Error in unique(y[match(x, y, 0)]) : Argument "y" is
missing, with no default
> CiS<-intersect(read.frame(c,s))
Error in unique(y[match(x, y, 0)]) : Argument "y" is
missing, with no default

##### Why am I getting this error.



Second thing I did:

I loaded the data as data.frame instead read.table(). 
Again I never get intersection of C,E and S,H. 


Can any one please help me. 
thank you

SP



From arin99 at rediffmail.com  Thu Jul  8 05:01:32 2004
From: arin99 at rediffmail.com (Arin Basu)
Date: 8 Jul 2004 03:01:32 -0000
Subject: R cookbook (Re: [R] omit complete cases)
Message-ID: <20040708030132.21412.qmail@webmail45.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040708/01636abc/attachment.pl

From astephen at efs.mq.edu.au  Thu Jul  8 05:24:20 2004
From: astephen at efs.mq.edu.au (Alec Stephenson)
Date: Thu, 08 Jul 2004 13:24:20 +1000
Subject: [R] read.frame
Message-ID: <s0ed4b1a.010@efs04.efs.mq.edu.au>

The help file on the intersect function says
     Performs set union, intersection, (asymmetric!) difference,
     equality and membership on two vectors.

and so intersect(s[,1],c[,1]) is probably what you want.

Alec

Alec Stephenson                                               
Department of Statistics
Macquarie University
NSW 2109, Australia 

>>> S Peri <biocperi at yahoo.com> 07/08/04 12:56pm >>>
Hello group, 
  I am learning R and I am new to many concepts.I face
the following errors when I am trying to execute the
following. I have 4 text files with protein accession
numbers. I wanted to represent them in a venn diagram
and for that I using intersect and setdiff functions.

My data looks like this:

file1.txt (c):
NP_000005
NP_000020
NP_000030
NP_000053

file2.txt(e):
NP_000005
NP_000020
NP_000030
NP_000031
NP_000053
NP_000055
NP_000087

file3.txt(h):
NP_000005
NP_000020
NP_000030
NP_000053
NP_000055
NP_000057
NP_000087

file4.txt (s):
NP_000005
NP_000020
NP_000030
NP_000033
NP_000053
NP_000055
NP_000087
NP_000168


Now I did the following FIRST time:
c=read.table("file1.txt")
e=read.table("file2.txt")
s=read.table("file4.txt")
h=read.table("file3.txt")

> class(c)
[1] "data.frame"
> class(s)
[1] "data.frame"
> CiS=intersect(c,s)
> CiS
NULL data frame with 0 rows 
##### Why am I getting NULL data error. I know there
are common elements between c and S. ##########

> CiS<-intersect(read.matrix(c,s))
Error in unique(y[match(x, y, 0)]) : Argument "y" is
missing, with no default
> CiS<-intersect(read.frame(c,s))
Error in unique(y[match(x, y, 0)]) : Argument "y" is
missing, with no default

##### Why am I getting this error.



Second thing I did:

I loaded the data as data.frame instead read.table(). 
Again I never get intersection of C,E and S,H. 


Can any one please help me. 
thank you

SP

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From biocperi at yahoo.com  Thu Jul  8 06:41:14 2004
From: biocperi at yahoo.com (S Peri)
Date: Wed, 7 Jul 2004 21:41:14 -0700 (PDT)
Subject: [R] read.frame
In-Reply-To: <20040708025607.44751.qmail@web50004.mail.yahoo.com>
Message-ID: <20040708044114.87704.qmail@web50008.mail.yahoo.com>

Dear Alec, 
 Thank you for your response and it worked. Further, I
have another mathematical problem. I apologize ahead
as this question is not apt for this list. I am a
biologist working at Johns Hopkins School of Medicine.

As I listed in my previous e-mail (attached below)I
mentioned I have 4 protein sets.  I am now trying to
calculate the combinatorics of these sets.  My
ultimate aim is to draw a venn diagram and find out
the proteins that are unique to set C,S,E and H. 
 I drew a venn diagram graph and I am banging my head
to deduce the combinations.  It is easy for me to
deduce the intersections - that means the protein
entries that are present in common. However, it proved
very difficult to deduce the following: 

I could calculate the following:

NP_*** present in both C and E (C intersection E)
NP_*** present in both C and H (C intersection H)
NP_*** present in both C and S (C ^ S)
NP_*** present in both E and H (E ^ H)
NP_*** present in both E and S (E ^ S)
NP_*** present in both H and S (H ^ S)

NP_*** present in C, E and H (C^E^H)
NP_*** present in C, H and S (C^H^S)
NP_*** present in E, H and S (E^H^S)
NP_*** present in E, S and C (E^S^C)


It is very difficult for me to deduce the following:

NP_**** entries specific to E
NP_**** entries specific to H
NP_**** entries specific to S


I waster many pages but could not derive some solution
to get unique elements for sets, s,e,h,and C.

Can any one help me by suggesting some way to get
these.

Thank you and I apologise again for posting the wrong
question. 

SP


--- S Peri <biocperi at yahoo.com> wrote:
> Hello group, 
>   I am learning R and I am new to many concepts.I
> face
> the following errors when I am trying to execute the
> following. I have 4 text files with protein
> accession
> numbers. I wanted to represent them in a venn
> diagram
> and for that I using intersect and setdiff
> functions.
> 
> My data looks like this:
> 
> file1.txt (c):
> NP_000005
> NP_000020
> NP_000030
> NP_000053
> 
> file2.txt(e):
> NP_000005
> NP_000020
> NP_000030
> NP_000031
> NP_000053
> NP_000055
> NP_000087
> 
> file3.txt(h):
> NP_000005
> NP_000020
> NP_000030
> NP_000053
> NP_000055
> NP_000057
> NP_000087
> 
> file4.txt (s):
> NP_000005
> NP_000020
> NP_000030
> NP_000033
> NP_000053
> NP_000055
> NP_000087
> NP_000168
> 
> 
> Now I did the following FIRST time:
> c=read.table("file1.txt")
> e=read.table("file2.txt")
> s=read.table("file4.txt")
> h=read.table("file3.txt")
> 
> > class(c)
> [1] "data.frame"
> > class(s)
> [1] "data.frame"
> > CiS=intersect(c,s)
> > CiS
> NULL data frame with 0 rows 
> ##### Why am I getting NULL data error. I know there
> are common elements between c and S. ##########
> 
> > CiS<-intersect(read.matrix(c,s))
> Error in unique(y[match(x, y, 0)]) : Argument "y" is
> missing, with no default
> > CiS<-intersect(read.frame(c,s))
> Error in unique(y[match(x, y, 0)]) : Argument "y" is
> missing, with no default
> 
> ##### Why am I getting this error.
> 
> 
> 
> Second thing I did:
> 
> I loaded the data as data.frame instead
> read.table(). 
> Again I never get intersection of C,E and S,H. 
> 
> 
> Can any one please help me. 
> thank you
> 
> SP
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Thu Jul  8 07:00:55 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu,  8 Jul 2004 01:00:55 -0400 (EDT)
Subject: [R] question about seq.dates from chron vs. as.POSIXct
Message-ID: <20040708050055.8995B12CCC@mprdmxin.myway.com>



Yes, its assuming GMT.

I find it best to use an intermediate conversion
to character to avoid these sorts of problems.
If, as in your example, you just have dates and
no times then the following would do it (and has the
advantage that you don't have to specify your
time zone explicitly so it will still work if
someone in another timezone tries your code):

   as.POSIXct(format(as.Date(xt)))

The reason to convert it to Date first, before 
formatting is so that the format will use Date's
default format (which is accepted by as.POSIXct)
rather than chron's default format.

---

Date:   	Wed, 07 Jul 2004 15:30:47 -0500
From:   	Laura Holt <lauraholt_983 at hotmail.com>
To:   	<r-help at stat.math.ethz.ch>
Subject:   	[R] question about seq.dates from chron vs. as.POSIXct

Dear R People:

Here is an interesting question:

>library(chron)
>xt <- seq.dates(from="01/01/2004",by="days",length=5)
>xt
[1] 01/01/04 01/02/04 01/03/04 01/04/04 01/05/04
>
#Fine so far
>as.POSIXct(xt)
[1] "2003-12-31 18:00:00 Central Standard Time"
[2] "2004-01-01 18:00:00 Central Standard Time"
[3] "2004-01-02 18:00:00 Central Standard Time"
[4] "2004-01-03 18:00:00 Central Standard Time"
[5] "2004-01-04 18:00:00 Central Standard Time"
>
Why do the dates change, please? Presumably the as.POSIXct is taking the xt
as midnight GMT and converting to Central Standard Time.

Is the best solution to:
>as.POSIXlt(xt, "CST")
[1] "2004-01-01 CST" "2004-01-02 CST" "2004-01-03 CST" "2004-01-04 CST"
[5] "2004-01-05 CST"
>

Thanks in advance!

Sincerely,
Laura Holt
who is corrupted by dates and times
mailto: lauraholt_983 at hotmail.com



From DJNordlund at aol.com  Thu Jul  8 07:35:07 2004
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Thu, 8 Jul 2004 01:35:07 EDT
Subject: [R] read.frame
Message-ID: <1e3.24a4c715.2e1e370b@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040708/cb183a94/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Jul  8 08:34:31 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 08:34:31 +0200
Subject: [R] command line interface
In-Reply-To: <833E32F61B9F8746878F2A1865BECE60014553FE@EXCHCLUSTER01.lj.gnf.org>
References: <833E32F61B9F8746878F2A1865BECE60014553FE@EXCHCLUSTER01.lj.gnf.org>
Message-ID: <40ECEAF7.4020401@statistik.uni-dortmund.de>

Lana Schaffer wrote:
> How can plots (histograms) be implemented with the command line interface to R?

I don't understand this question. There's a chance that you are looking 
for the function hist().
Please read the posting guides beeing added at the end of your posting.

Uwe Ligges


> Lana Schaffer
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Jul  8 08:56:18 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 08:56:18 +0200
Subject: [R] text editor for R - summary on R-WinEdt 
In-Reply-To: <s0ec6b9f.062@MAIL.NDRI.ORG>
References: <s0ec6b9f.062@MAIL.NDRI.ORG>
Message-ID: <40ECF012.5090908@statistik.uni-dortmund.de>

Dear all,

let me try to summarize this thread's R-WinEdt related messages and give 
a few comments:



Murray Jorgensen wrote:

 > I tried R-WinEdt a few years ago, but as I remember it interfered with
 > my usual use of WinEdt which is as a front end to MiKTeX. Is there a
 > way to use WinEdt both ways?

Yes, as already answered by some others ...

There are plans to be able to have an R mode in the usual WinEdt 
setting, so R's highlighting will adapt to the current document 
settings, but I don't know when there will be time to implement that in 
a clean manner.



David Scott wrote [in response to Murray Jorgensen]:

 > This problem annoyed me for a while too. My solution (which is not
 > perhaps ideal) is this. You want two different incarnations of WinEdt,
 > one for TeX, the other for R. On the desktop I have a shortcut to
 > WinEdt which is the one for TeX stuff. I open the other one with R
 > syntax highlighting etc by starting R and using library(RWinEdt). To
 > do this you have to install the RWinEdt package and SWinRegistry. This
 > is all well explained in the ReadMe.txt for RWinEdt.
 >
 > I think with the right additions to the Target field in a shortcut to
 > WinEdt you can call up the incarnation of WinEdt that is suitable for
 > R. I haven't done that. You would then have two shortcuts to WinEdt,
 > one for your TeX stuff, one for R.

Thanks for this detailed and accurate description.



Liaw, Andy wrote:

 > Uwe would be the authority on this 8-), but my impression is that if
 > you keep two separate shortcuts, you should be fine.  The one for
 > R-WinEdt has flags that sets it up for R, which should not be used
 > in the one for MikTeX.

Indeed.



Kevin Wang wrote:

 > I think Andy is correct.  A few years ago (back in the dark ages --
 > before I discovered Emacs/ESS), I had two short cuts, one calls
 > R-WinEdt (i.e. with flags...etc) and the other with just a normal
 > WinEdt icon.
 >
 > However, I *think* now you can interact R-WinEdt within R directly
 > (I tried the new version about 2 ~ 3 months ago just for fun, and
 > that seemed to be the case, but I can't quite remember *_*).

You can fire up R-WinEdt from R, but I would not call it "interact 
within R directly".



Peter Flom wrote:

 > I use WinEdt for both.  I simply installed it twice, and set up one
 > version for R and one for LaTeX, I have seperate icons on the desktop,
 > with different names, and it works fine.

It is not necessary to have two installations.


Uwe Ligges



From vito_ricci at yahoo.com  Thu Jul  8 09:15:15 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Thu, 8 Jul 2004 09:15:15 +0200 (CEST)
Subject: [R] Importing an Excel file 
Message-ID: <20040708071515.94906.qmail@web41215.mail.yahoo.com>

I use very much Excel in my job and often I've to read
Excel data in R. Usually I save Excel file as a .txt
file and then I read it in R with read.table().

I find really interesting the suggest of using the
function read.xls() in the 'gregmisc' package.

I work also with R in Excel sheets by
R-Com/R-Interface (see:
http://www.sciviews.org/_rgui/projects/RDcom.html)

It has several limits, but for some analysis is
helpfull.

Bye 
Vito Ricci


Park, Kyong H Mr. RDECOM kyong.ho.park at us.army.mil
Wed Jul 7 20:21:42 CEST 2004


Hello, R users,
I am  a very beginner of R and tried read.csv to
import an excel file after
saving an excel file as csv. But it added alternating
rows of fictitious NA
values after row number 16. When I applied read.delim,
there were trailing
several commas at the end of each row after row number
16 instead of NA
values. Appreciate your help. 

Kyong

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From aubert at inapg.fr  Thu Jul  8 09:20:44 2004
From: aubert at inapg.fr (aubert@inapg.fr)
Date: Thu, 08 Jul 2004 09:20:44 +0200
Subject: [R] Problem with the grep function
Message-ID: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>

Let me present to you my problem :

I have a character vector x and I would like to  obtain the indices of the 
elements of
this vector that yielded exactly a match.

For example,  x=nom, pattern="b", I would to obtain 2 because "b" is on the 
second position.

First program :
nom <- c("a","b","ab")
grep("b",nom)
2 3

Then I try the option extended =FALSE (instead of TRUE by default) and I 
obtain '2 3' a second time.

Please can you help me : How can I obtain only 2 in using the grep function 
(without using the match function).

Thanks you

Julie AUBERT



From astephen at efs.mq.edu.au  Thu Jul  8 09:25:40 2004
From: astephen at efs.mq.edu.au (Alec Stephenson)
Date: Thu, 08 Jul 2004 17:25:40 +1000
Subject: [R] read.frame
Message-ID: <s0ed83af.045@efs04.efs.mq.edu.au>

For E:
e <- e[,1] ; uni <- union(c[,1],union(s[,1],h[,1]))
Then e[!match(e, uni, 0)] should get you there. 

Alec

Alec Stephenson                                               
Department of Statistics
Macquarie University
NSW 2109, Australia 

>>> S Peri <biocperi at yahoo.com> 07/08/04 02:41pm >>>
Dear Alec, 
 Thank you for your response and it worked. Further, I
have another mathematical problem. I apologize ahead
as this question is not apt for this list. I am a
biologist working at Johns Hopkins School of Medicine.

As I listed in my previous e-mail (attached below)I
mentioned I have 4 protein sets.  I am now trying to
calculate the combinatorics of these sets.  My
ultimate aim is to draw a venn diagram and find out
the proteins that are unique to set C,S,E and H. 
 I drew a venn diagram graph and I am banging my head
to deduce the combinations.  It is easy for me to
deduce the intersections - that means the protein
entries that are present in common. However, it proved
very difficult to deduce the following: 

I could calculate the following:

NP_*** present in both C and E (C intersection E)
NP_*** present in both C and H (C intersection H)
NP_*** present in both C and S (C ^ S)
NP_*** present in both E and H (E ^ H)
NP_*** present in both E and S (E ^ S)
NP_*** present in both H and S (H ^ S)

NP_*** present in C, E and H (C^E^H)
NP_*** present in C, H and S (C^H^S)
NP_*** present in E, H and S (E^H^S)
NP_*** present in E, S and C (E^S^C)


It is very difficult for me to deduce the following:

NP_**** entries specific to E
NP_**** entries specific to H
NP_**** entries specific to S


I waster many pages but could not derive some solution
to get unique elements for sets, s,e,h,and C.

Can any one help me by suggesting some way to get
these.

Thank you and I apologise again for posting the wrong
question. 

SP


--- S Peri <biocperi at yahoo.com> wrote:
> Hello group, 
>   I am learning R and I am new to many concepts.I
> face
> the following errors when I am trying to execute the
> following. I have 4 text files with protein
> accession
> numbers. I wanted to represent them in a venn
> diagram
> and for that I using intersect and setdiff
> functions.
> 
> My data looks like this:
> 
> file1.txt (c):
> NP_000005
> NP_000020
> NP_000030
> NP_000053
> 
> file2.txt(e):
> NP_000005
> NP_000020
> NP_000030
> NP_000031
> NP_000053
> NP_000055
> NP_000087
> 
> file3.txt(h):
> NP_000005
> NP_000020
> NP_000030
> NP_000053
> NP_000055
> NP_000057
> NP_000087
> 
> file4.txt (s):
> NP_000005
> NP_000020
> NP_000030
> NP_000033
> NP_000053
> NP_000055
> NP_000087
> NP_000168
> 
> 
> Now I did the following FIRST time:
> c=read.table("file1.txt")
> e=read.table("file2.txt")
> s=read.table("file4.txt")
> h=read.table("file3.txt")
> 
> > class(c)
> [1] "data.frame"
> > class(s)
> [1] "data.frame"
> > CiS=intersect(c,s)
> > CiS
> NULL data frame with 0 rows 
> ##### Why am I getting NULL data error. I know there
> are common elements between c and S. ##########
> 
> > CiS<-intersect(read.matrix(c,s))
> Error in unique(y[match(x, y, 0)]) : Argument "y" is
> missing, with no default
> > CiS<-intersect(read.frame(c,s))
> Error in unique(y[match(x, y, 0)]) : Argument "y" is
> missing, with no default
> 
> ##### Why am I getting this error.
> 
> 
> 
> Second thing I did:
> 
> I loaded the data as data.frame instead
> read.table(). 
> Again I never get intersection of C,E and S,H. 
> 
> 
> Can any one please help me. 
> thank you
> 
> SP
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Thu Jul  8 09:36:40 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 08 Jul 2004 09:36:40 +0200
Subject: [R] Problem with the grep function
In-Reply-To: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>
References: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>
Message-ID: <200407080936400236.00658426@mail.math.fu-berlin.de>

Hi!

For exact matches you can use
== or is.element.
To get the indices use which.

e.g. ==

> x<-c("a","b","ab")
> x=="a"
[1]  TRUE FALSE FALSE
> which((x=="a")==T)
[1] 1

or

e.g. is.element

> is.element(x,"a")
[1]  TRUE FALSE FALSE
> which(is.element(x,"a")==TRUE)
[1] 1
> 

Sincerely
Eryk


*********** REPLY SEPARATOR  ***********

On 7/8/2004 at 9:20 AM aubert at inapg.fr wrote:

>>>Let me present to you my problem :
>>>
>>>I have a character vector x and I would like to  obtain the indices of
>>>the 
>>>elements of
>>>this vector that yielded exactly a match.
>>>
>>>For example,  x=nom, pattern="b", I would to obtain 2 because "b" is on
>>>the 
>>>second position.
>>>
>>>First program :
>>>nom <- c("a","b","ab")
>>>grep("b",nom)
>>>2 3
>>>
>>>Then I try the option extended =FALSE (instead of TRUE by default) and I 
>>>obtain '2 3' a second time.
>>>
>>>Please can you help me : How can I obtain only 2 in using the grep
>>>function 
>>>(without using the match function).
>>>
>>>Thanks you
>>>
>>>Julie AUBERT
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From astephen at efs.mq.edu.au  Thu Jul  8 09:41:04 2004
From: astephen at efs.mq.edu.au (Alec Stephenson)
Date: Thu, 08 Jul 2004 17:41:04 +1000
Subject: [R] Problem with the grep function
Message-ID: <s0ed874a.064@efs04.efs.mq.edu.au>

grep("^b$",nom) will match "b" only.

Alec


Alec Stephenson                                               
Department of Statistics
Macquarie University
NSW 2109, Australia 

>>> "aubert at inapg.fr" <aubert at inapg.fr> 07/08/04 05:20pm >>>
Let me present to you my problem :

I have a character vector x and I would like to  obtain the indices of
the 
elements of
this vector that yielded exactly a match.

For example,  x=nom, pattern="b", I would to obtain 2 because "b" is on
the 
second position.

First program :
nom <- c("a","b","ab")
grep("b",nom)
2 3

Then I try the option extended =FALSE (instead of TRUE by default) and
I 
obtain '2 3' a second time.

Please can you help me : How can I obtain only 2 in using the grep
function 
(without using the match function).

Thanks you

Julie AUBERT

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From aubert at inapg.fr  Thu Jul  8 09:43:04 2004
From: aubert at inapg.fr (aubert@inapg.fr)
Date: Thu, 08 Jul 2004 09:43:04 +0200
Subject: [R] Problem with the grep function
In-Reply-To: <001801c464bd$bc009d90$dd28e182@santamaria>
References: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>
Message-ID: <5.1.0.14.0.20040708094221.00b77830@pop1.inapg.fr>

Hi Christian,

It works better now. Thanks a lot.

Julie

At 09:32 08/07/2004 +0200, you wrote:
>Hi Julie,
>
>as I understand your question you only want indices for exact matches to
>"b". This can be achieved using regular expressions (see ?regex)
>
>nom <- c("a","b","ab")
>grep("^b$",nom)
>
>I hope this helps?
>
>Christian



From vito_ricci at yahoo.com  Thu Jul  8 09:44:51 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Thu, 8 Jul 2004 09:44:51 +0200 (CEST)
Subject: [R] Importing an Excel file  
Message-ID: <20040708074451.74503.qmail@web41213.mail.yahoo.com>

Hi,
I'm trying to use read.xls() function to import Excel
data, but I've this error:

Error in system(cmd, intern = !verbose) : perl not
found

R is running under Win2000;

This function works translating the named Microsoft
Excel file into a temporary .csv file, using Greg
Warnes' xls2csv perl script (installed as part of the
gregmisc package).

What happens?
Cordially
Vito Ricci

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From Jan_Svatos at eurotel.cz  Thu Jul  8 09:47:19 2004
From: Jan_Svatos at eurotel.cz (Jan_Svatos@eurotel.cz)
Date: Thu, 8 Jul 2004 09:47:19 +0200
Subject: [R] Problem with the grep function
Message-ID: <OFA0250497.4B4C4C92-ONC1256ECB.002A6E95@eurotel.cz>

Hi Julie,

match is not exactly what you need, as it works with regular expressions 
and takes anything what includes a letter "b".
For your case, there is perfectly suitable

which(nom=="b")

nom <- c("a","b","ab", "b")
which(nom=="b")
[1] 2 4

Jan


- - - Original message: - - -
From: r-help-bounces at stat.math.ethz.ch
Send: 8.7.2004 9:24:58
To: r-help at stat.math.ethz.ch
Subject: [R] Problem with the grep function

Let me present to you my problem :

I have a character vector x and I would like to  obtain the indices of the
elements of
this vector that yielded exactly a match.

For example,  x=nom, pattern="b", I would to obtain 2 because "b" is on 
the
second position.

First program :
nom <- c("a","b","ab")
grep("b",nom)
2 3

Then I try the option extended =FALSE (instead of TRUE by default) and I
obtain '2 3' a second time.

Please can you help me : How can I obtain only 2 in using the grep 
function
(without using the match function).

Thanks you

Julie AUBERT

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Thu Jul  8 09:49:00 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 08 Jul 2004 09:49:00 +0200
Subject: [R] Problem with the grep function
In-Reply-To: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>
References: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>
Message-ID: <200407080949000009.0070CDE4@mail.math.fu-berlin.de>


Or you must mark the word beginning with ^ and the end $ if you like to use grep.

grep("^b$",nom)


Sincerely
Eryk


*********** REPLY SEPARATOR  ***********

On 7/8/2004 at 9:20 AM aubert at inapg.fr wrote:

>>>Let me present to you my problem :
>>>
>>>I have a character vector x and I would like to  obtain the indices of
>>>the 
>>>elements of
>>>this vector that yielded exactly a match.
>>>
>>>For example,  x=nom, pattern="b", I would to obtain 2 because "b" is on
>>>the 
>>>second position.
>>>
>>>First program :
>>>nom <- c("a","b","ab")
>>>grep("b",nom)
>>>2 3
>>>
>>>Then I try the option extended =FALSE (instead of TRUE by default) and I 
>>>obtain '2 3' a second time.
>>>
>>>Please can you help me : How can I obtain only 2 in using the grep
>>>function 
>>>(without using the match function).
>>>
>>>Thanks you
>>>
>>>Julie AUBERT
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From ligges at statistik.uni-dortmund.de  Thu Jul  8 09:54:27 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 09:54:27 +0200
Subject: [R] Problem with the grep function
In-Reply-To: <200407080936400236.00658426@mail.math.fu-berlin.de>
References: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>
	<200407080936400236.00658426@mail.math.fu-berlin.de>
Message-ID: <40ECFDB3.3000305@statistik.uni-dortmund.de>

Wolski wrote:

> Hi!
> 
> For exact matches you can use
> == or is.element.
> To get the indices use which.
> 
> e.g. ==
> 
> 
>>x<-c("a","b","ab")
>>x=="a"
> 
> [1]  TRUE FALSE FALSE
> 
>>which((x=="a")==T)

Note, the "==T" part is superflously (same below).

In grep()'s regular expression, you can also use:
    grep("^b$", nom)
or similar stuff.

Uwe Ligges


> [1] 1
> 
> or
> 
> e.g. is.element
> 
> 
>>is.element(x,"a")
> 
> [1]  TRUE FALSE FALSE
> 
>>which(is.element(x,"a")==TRUE)
> 
> [1] 1
> 
> 
> Sincerely
> Eryk
> 
> 
> *********** REPLY SEPARATOR  ***********
> 
> On 7/8/2004 at 9:20 AM aubert at inapg.fr wrote:
> 
> 
>>>>Let me present to you my problem :
>>>>
>>>>I have a character vector x and I would like to  obtain the indices of
>>>>the 
>>>>elements of
>>>>this vector that yielded exactly a match.
>>>>
>>>>For example,  x=nom, pattern="b", I would to obtain 2 because "b" is on
>>>>the 
>>>>second position.
>>>>
>>>>First program :
>>>>nom <- c("a","b","ab")
>>>>grep("b",nom)
>>>>2 3
>>>>
>>>>Then I try the option extended =FALSE (instead of TRUE by default) and I 
>>>>obtain '2 3' a second time.
>>>>
>>>>Please can you help me : How can I obtain only 2 in using the grep
>>>>function 
>>>>(without using the match function).
>>>>
>>>>Thanks you
>>>>
>>>>Julie AUBERT
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
> Ihnestrasse 63-73 14195 Berlin       'v'    
> tel: 0049-30-83875219               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From wangk at maths.anu.edu.au  Thu Jul  8 10:01:52 2004
From: wangk at maths.anu.edu.au (Kevin Wang)
Date: Thu, 8 Jul 2004 18:01:52 +1000 (EST)
Subject: [R] Importing an Excel file  
In-Reply-To: <20040708074451.74503.qmail@web41213.mail.yahoo.com>
References: <20040708074451.74503.qmail@web41213.mail.yahoo.com>
Message-ID: <Pine.GSO.4.58.0407081801030.29020@yin>

Hi,

On Thu, 8 Jul 2004, [iso-8859-1] Vito Ricci wrote:

> Hi,
> I'm trying to use read.xls() function to import Excel
> data, but I've this error:
>
> Error in system(cmd, intern = !verbose) : perl not
> found
>
> What happens?

It means it cannot find Perl.  You need Perl installed (and in your Path)
in your system.

Kev

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7411
Ph (M): +61-40-451-8301



From ligges at statistik.uni-dortmund.de  Thu Jul  8 10:03:53 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 10:03:53 +0200
Subject: [R] Importing an Excel file
In-Reply-To: <20040708074451.74503.qmail@web41213.mail.yahoo.com>
References: <20040708074451.74503.qmail@web41213.mail.yahoo.com>
Message-ID: <40ECFFE9.2060108@statistik.uni-dortmund.de>

Vito Ricci wrote:

> Hi,
> I'm trying to use read.xls() function to import Excel
> data, but I've this error:
> 
> Error in system(cmd, intern = !verbose) : perl not
> found
> 
> R is running under Win2000;
> 
> This function works translating the named Microsoft
> Excel file into a temporary .csv file, using Greg
> Warnes' xls2csv perl script (installed as part of the
> gregmisc package).
> 
> What happens?


You already told us that there is a perl script, and the error message 
says that perl has not been found.
So what about installing perl and adding it to your path?

Uwe Ligges




> Cordially
> Vito Ricci
> 
> =====
> Diventare costruttori di soluzioni
> 
> Visitate il portale http://www.modugno.it/
> e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From cheiz at juice.nl  Thu Jul  8 10:37:14 2004
From: cheiz at juice.nl (Gijs)
Date: Thu, 08 Jul 2004 17:37:14 +0900
Subject: [R] How to pass strings to functions?
Message-ID: <40ED07BA.7070807@juice.nl>



From wangk at maths.anu.edu.au  Thu Jul  8 10:43:27 2004
From: wangk at maths.anu.edu.au (Kevin Wang)
Date: Thu, 8 Jul 2004 18:43:27 +1000 (EST)
Subject: [R] How to pass strings to functions?
In-Reply-To: <40ED07BA.7070807@juice.nl>
References: <40ED07BA.7070807@juice.nl>
Message-ID: <Pine.GSO.4.58.0407081842590.1433@yin>

Please do not use the subject to ask a question without clarifying it!

So what exactly do you want?  Can you give some more descriptions?

Kev

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7411
Ph (M): +61-40-451-8301



From maechler at stat.math.ethz.ch  Thu Jul  8 11:24:30 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Jul 2004 11:24:30 +0200
Subject: [R] lost messages
In-Reply-To: <9DC76C6E-D054-11D8-A117-000A9577009E@pcbi.upenn.edu>
References: <XFMail.040707210555.Ted.Harding@nessie.mcc.ac.uk>
	<9DC76C6E-D054-11D8-A117-000A9577009E@pcbi.upenn.edu>
Message-ID: <16621.4814.946971.598077@gargle.gargle.HOWL>

>>>>> "Aaron" == Aaron J Mackey <amackey at pcbi.upenn.edu>
>>>>>     on Wed, 7 Jul 2004 16:31:25 -0400 writes:

    Aaron> The second two resends did go through (I checked on
    Aaron> the web archive), but the first did not;
    Aaron> additionally, the second two resends both came
    Aaron> through with the exact same timestamp, even though I
    Aaron> resent them over the space of 4 hours or so (and only
    Aaron> after I had sent the "lost messages" message, which
    Aaron> did come through to me just fine).  So there was
    Aaron> something "stuck", but seems to be unstuck now.

    Aaron> Thanks to all,

yes, and please all do learn from this:

Just because *you* may not have got your message back in time, don't jump
to wrong conclusions. At least look into the mailing list
archives first.  
If you still see a problem, check with your local IT E-mail
support and then send mail to R-help-owner at ... (or me directly)
rather than the whole list	    ^^^^^^

Please don't "spam" the 2500 R-help readers with such things in
the future.

Martin Maechler



From gplomp at brain.riken.jp  Thu Jul  8 11:27:53 2004
From: gplomp at brain.riken.jp (Gijs Plomp)
Date: Thu, 08 Jul 2004 18:27:53 +0900
Subject: [R] 
 How to pass strings to functions? [once more, now With content I
 hope...]
Message-ID: <40ED1399.9030809@brain.riken.jp>



From meinhardploner at gmx.net  Thu Jul  8 11:25:27 2004
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Thu, 8 Jul 2004 11:25:27 +0200
Subject: [R] building packages with NAMESPACE
Message-ID: <BFC70228-D0C0-11D8-AB52-0003930EA956@gmx.net>

hi!
I tried to build a very simple package with NAMESPACE file,
such that datasets are loaded only dynamically.

 > a2 <- function(x=a1) x+4
 > a1 <- 1:10
 > package.skeleton("aaa", list=c("a1", "a2"))

Then I modified the help files and added the file NAMESPACE with these 
2 lines:
useDynLib(aaa)
export(a1, a2)

Then "R CMD BUILD aaa" works fine, but "R CMD CHECK aaa" gives:
.........
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :
         package/namespace load failed
Execution halted
* checking for replacement functions with final arg not named 'value' 
... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :
         package/namespace load failed
Execution halted

Without NAMESPACE file there wasn't any error, so anybody could help me?
Thanks
Meinhard Ploner


PS: version
          _
platform powerpc-apple-darwin7.2.0
arch     powerpc
os       darwin7.2.0
system   powerpc, darwin7.2.0
status
major    1
minor    8.1
year     2003
month    11
day      21
language R



From catch_utsav at yahoo.com  Thu Jul  8 11:53:10 2004
From: catch_utsav at yahoo.com (Utsav Boobna)
Date: Thu, 8 Jul 2004 02:53:10 -0700 (PDT)
Subject: [R] loding *.o file in windows environment
Message-ID: <20040708095310.16068.qmail@web14810.mail.yahoo.com>

Hi,
   Assuming that I dont have the source C file, is it
anyhow possible for me to load the object file (*.o)
in R under windows environment. I tried using
dyn.load(), but obviously it didnt worked.

Thanks,
Utsav



From wolfram at fischer-zim.ch  Thu Jul  8 11:58:02 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Thu, 8 Jul 2004 11:58:02 +0200
Subject: [R] Getting elements of a matrix by a vector of column indices
Message-ID: <20040708095802.GA2922@s1x.local>

I have e.g.
    t <- matrix( nrow=2, ncol=3, byrow=TRUE, c('a1','a2','a3','b1','b2','b3') )
and
    i <- c( 3, 2)

Is it possible to formulate a simple expression that gets
    c( t[ 1, i[1] ], t[ 2, i[2] ] )
(and so on for longer matrices)?

The result would be:
    [1] "a3" "b2"

Thanks - Wolfram



From cullens at tcd.ie  Thu Jul  8 12:06:56 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Thu, 08 Jul 2004 11:06:56 +0100
Subject: [R] How to pass strings to functions? [once more,
	now With content I hope...]
In-Reply-To: <40ED1399.9030809@brain.riken.jp>
References: <40ED1399.9030809@brain.riken.jp>
Message-ID: <opsatc1utk1pelvz@smtp.tcd.ie>

There is still no content in the body - perhaps you are sending HTML only  
mail? If so, try changing your outgoing mail setting to "Plain Text".

-- 
SC



From gplomp at brain.riken.jp  Thu Jul  8 12:23:36 2004
From: gplomp at brain.riken.jp (Gijs Plomp)
Date: Thu, 08 Jul 2004 19:23:36 +0900
Subject: [R] How to pass strings to functions? [once once more,
 now With content I hope...]
Message-ID: <40ED20A8.2030008@brain.riken.jp>

Dear expeRts,

I fail to succesfully pass strings to functions. It comes down to the 
observation that

 > plot(someVariable,anotherVariable)

works fine, but

 > x <- "someVariable"
 > y <- "anotherVariable"
 > plot(x,y)

does not.

Does this have something to do with the returned value of x being 
/"someVariable"/ and not /someVariable/, i.e. without the quotation 
marks? Is there any way to work around this?

Ultimately I'd like to make multiple graphs by looping throught the 
values in vectors. Something like:
 > var<-c(var1,var2...n)
 > for (v in var)
 >{
 > plot(var, x))
 >}

I've looked around for help on this but am stuck.

Hope you can help,
Gijs Plomp



From ligges at statistik.uni-dortmund.de  Thu Jul  8 12:28:20 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 12:28:20 +0200
Subject: [R] loding *.o file in windows environment
In-Reply-To: <20040708095310.16068.qmail@web14810.mail.yahoo.com>
References: <20040708095310.16068.qmail@web14810.mail.yahoo.com>
Message-ID: <40ED21C4.8080703@statistik.uni-dortmund.de>

Utsav Boobna wrote:

> Hi,
>    Assuming that I dont have the source C file, is it
> anyhow possible for me to load the object file (*.o)

Well, the sources must be compiled under Windows (or at least 
cross-compiled on another platform). Most probably, an .o file has been 
compiled under Unix-alikes.
You do need the sources in this case.

Uwe Ligges


> in R under windows environment. I tried using
> dyn.load(), but obviously it didnt worked.
> 
> Thanks,
> Utsav
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From michael.watson at bbsrc.ac.uk  Thu Jul  8 12:57:01 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 8 Jul 2004 11:57:01 +0100
Subject: [R] Statistics::R
Message-ID: <8975119BCD0AC5419D61A9CF1A923E957C27BF@iahce2knas1.iah.bbsrc.reserved>

Hello

I am looking (possibly in vain!) for the Author of the Statistics::R
perl package - I believe he announced the package on this mailing list
some months ago.  The name is Graciliano Monteiro Passos, and his e-mail
address, gm at virtuasites.com.br, is giving permanent errors.

Can anyone help?  Does anyone use this perl package with R?  I am having
a few problems with it.

Sorry to everyone whom this message is irrelevant to.

Thanks
Mick



From ligges at statistik.uni-dortmund.de  Thu Jul  8 13:04:23 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 13:04:23 +0200
Subject: [R] How to pass strings to functions? [once once more, now With
	content I hope...]
In-Reply-To: <40ED20A8.2030008@brain.riken.jp>
References: <40ED20A8.2030008@brain.riken.jp>
Message-ID: <40ED2A37.6080901@statistik.uni-dortmund.de>

Gijs Plomp wrote:

> Dear expeRts,
> 
> I fail to succesfully pass strings to functions. It comes down to the 
> observation that
> 
>  > plot(someVariable,anotherVariable)
> 
> works fine, but
> 
>  > x <- "someVariable"
>  > y <- "anotherVariable"
>  > plot(x,y)

Do you mean
  x <- someVariable
  y <- anotherVariable
  plot(x,y)

Why are you not calling
  plot(someVariable, anotherVariable)



> does not.
> 
> Does this have something to do with the returned value of x being 
> /"someVariable"/ and not /someVariable/, i.e. without the quotation 
> marks? Is there any way to work around this?
> 
> Ultimately I'd like to make multiple graphs by looping throught the 
> values in vectors. Something like:
>  > var<-c(var1,var2...n)
>  > for (v in var)
>  >{
>  > plot(var, x))
>  >}

Does not make sense. You need to use "v" within the loop..... But I 
don't know what you are intending? You still need to be more specific!

Uwe Ligges




> I've looked around for help on this but am stuck.
> 
> Hope you can help,
> Gijs Plomp
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From Matthias.Kohl at uni-bayreuth.de  Thu Jul  8 13:08:08 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias.Kohl@uni-bayreuth.de)
Date: Thu, 8 Jul 2004 13:08:08 +0200 (MEST)
Subject: [R] How to pass strings to functions? [once once more,
	now With content I hope...]
In-Reply-To: <40ED20A8.2030008@brain.riken.jp>
References: <40ED20A8.2030008@brain.riken.jp>
Message-ID: <1084.132.180.246.48.1089284888.squirrel@mail.uni-bayreuth.de>

> Dear expeRts,
>
> I fail to succesfully pass strings to functions. It comes down to the
> observation that
>
>  > plot(someVariable,anotherVariable)
>
> works fine, but
>
>  > x <- "someVariable"
>  > y <- "anotherVariable"
>  > plot(x,y)
>
> does not.
>
> Does this have something to do with the returned value of x being
> /"someVariable"/ and not /someVariable/, i.e. without the quotation
> marks? Is there any way to work around this?
>
> Ultimately I'd like to make multiple graphs by looping throught the
> values in vectors. Something like:
>  > var<-c(var1,var2...n)
>  > for (v in var)
>  >{
>  > plot(var, x))
>  >}
>

what about plot(get(v), x)?

> I've looked around for help on this but am stuck.
>
> Hope you can help,
> Gijs Plomp
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Jul  8 13:21:53 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 13:21:53 +0200
Subject: [R] Getting elements of a matrix by a vector of column indices
In-Reply-To: <20040708095802.GA2922@s1x.local>
References: <20040708095802.GA2922@s1x.local>
Message-ID: <40ED2E51.9040006@statistik.uni-dortmund.de>

Wolfram Fischer wrote:

> I have e.g.
>     t <- matrix( nrow=2, ncol=3, byrow=TRUE, c('a1','a2','a3','b1','b2','b3') )
> and
>     i <- c( 3, 2)
> 
> Is it possible to formulate a simple expression that gets
>     c( t[ 1, i[1] ], t[ 2, i[2] ] )
> (and so on for longer matrices)?
> 
> The result would be:
>     [1] "a3" "b2"
>

Two solutions are (there might be better ones):

a)
   mapply(function(x,y) t[x,y], 1:nrow(t), i)
b)
   t(t)[i + (1:nrow(t) - 1) * (ncol(t))]

Note that calling the matrix "t" is not the best idea.

Uwe Ligges


> Thanks - Wolfram
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Jul  8 13:49:21 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jul 2004 13:49:21 +0200
Subject: [R] building packages with NAMESPACE
In-Reply-To: <BFC70228-D0C0-11D8-AB52-0003930EA956@gmx.net>
References: <BFC70228-D0C0-11D8-AB52-0003930EA956@gmx.net>
Message-ID: <40ED34C1.6050102@statistik.uni-dortmund.de>

Meinhard Ploner wrote:

> hi!
> I tried to build a very simple package with NAMESPACE file,
> such that datasets are loaded only dynamically.
> 
>  > a2 <- function(x=a1) x+4
>  > a1 <- 1:10
>  > package.skeleton("aaa", list=c("a1", "a2"))
> 
> Then I modified the help files and added the file NAMESPACE with these 2 
> lines:
> useDynLib(aaa)
> export(a1, a2)

a) Don't export data frames.
b) Don't useDynLib, if there is no library to be used.

=> The correct NAMESPACE file contains not more than the single line

export(a2)


Uwe Ligges


> 
> Then "R CMD BUILD aaa" works fine, but "R CMD CHECK aaa" gives:
> .........
> * checking R files for syntax errors ... OK
> * checking R files for library.dynam ... OK
> * checking S3 generic/method consistency ... WARNING
> Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
> character.only = TRUE, verbose = FALSE) :
>         package/namespace load failed
> Execution halted
> * checking for replacement functions with final arg not named 'value' 
> ... WARNING
> Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
> character.only = TRUE, verbose = FALSE) :
>         package/namespace load failed
> Execution halted
> 
> Without NAMESPACE file there wasn't any error, so anybody could help me?
> Thanks
> Meinhard Ploner
> 
> 
> PS: version
>          _
> platform powerpc-apple-darwin7.2.0
> arch     powerpc
> os       darwin7.2.0
> system   powerpc, darwin7.2.0
> status
> major    1
> minor    8.1
> year     2003
> month    11
> day      21
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kyong.ho.park at us.army.mil  Thu Jul  8 14:01:11 2004
From: kyong.ho.park at us.army.mil (Park, Kyong H Mr. RDECOM)
Date: Thu, 8 Jul 2004 08:01:11 -0400 
Subject: [R] Replies  for Importing Excel  File
Message-ID: <3007F52DF96EB74CAC3054FF85C4318F7A7ACB@mail2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040708/0116d328/attachment.pl

From petr.pikal at precheza.cz  Thu Jul  8 14:18:03 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 08 Jul 2004 14:18:03 +0200
Subject: [R] Importing an Excel file 
In-Reply-To: <20040708071515.94906.qmail@web41215.mail.yahoo.com>
Message-ID: <40ED579B.7660.16624A1@localhost>

Hi

If you do not have complicated items with spaces and special 
characters and you want some easy copiing on fly just issue in R

read.delim("clipboard")

after selecting an area in Excel file and pressing Ctrl-C

Cheers
Petr


On 8 Jul 2004 at 9:15, Vito Ricci wrote:

> I use very much Excel in my job and often I've to read
> Excel data in R. Usually I save Excel file as a .txt
> file and then I read it in R with read.table().
> 
> I find really interesting the suggest of using the
> function read.xls() in the 'gregmisc' package.
> 
> I work also with R in Excel sheets by
> R-Com/R-Interface (see:
> http://www.sciviews.org/_rgui/projects/RDcom.html)
> 
> It has several limits, but for some analysis is
> helpfull.
> 
> Bye 
> Vito Ricci
> 
> 
> Park, Kyong H Mr. RDECOM kyong.ho.park at us.army.mil
> Wed Jul 7 20:21:42 CEST 2004
> 
> 
> Hello, R users,
> I am  a very beginner of R and tried read.csv to
> import an excel file after
> saving an excel file as csv. But it added alternating
> rows of fictitious NA
> values after row number 16. When I applied read.delim,
> there were trailing
> several commas at the end of each row after row number
> 16 instead of NA
> values. Appreciate your help. 
> 
> Kyong
> 
> =====
> Diventare costruttori di soluzioni
> 
> Visitate il portale http://www.modugno.it/
> e in particolare la sezione su Palese
> http://www.modugno.it/archivio/cat_palese.shtml
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From andy_liaw at merck.com  Thu Jul  8 14:21:37 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 8 Jul 2004 08:21:37 -0400
Subject: [R] Getting elements of a matrix by a vector of column
 indice s
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FF2@usrymx25.merck.com>

See if the following helps:

> m <- outer(letters[1:5], 1:4, paste, sep="")
> m
     [,1] [,2] [,3] [,4]
[1,] "a1" "a2" "a3" "a4"
[2,] "b1" "b2" "b3" "b4"
[3,] "c1" "c2" "c3" "c4"
[4,] "d1" "d2" "d3" "d4"
[5,] "e1" "e2" "e3" "e4"
> idx <- c(2, 1, 3, 4, 2)
> m[cbind(1:5, idx)]
[1] "a2" "b1" "c3" "d4" "e2"

Andy

> From: Wolfram Fischer
> 
> I have e.g.
>     t <- matrix( nrow=2, ncol=3, byrow=TRUE, 
> c('a1','a2','a3','b1','b2','b3') )
> and
>     i <- c( 3, 2)
> 
> Is it possible to formulate a simple expression that gets
>     c( t[ 1, i[1] ], t[ 2, i[2] ] )
> (and so on for longer matrices)?
> 
> The result would be:
>     [1] "a3" "b2"
> 
> Thanks - Wolfram
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From petr.pikal at precheza.cz  Thu Jul  8 14:28:13 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 08 Jul 2004 14:28:13 +0200
Subject: [R] Problem with the grep function
In-Reply-To: <5.1.0.14.0.20040708091023.00b2f650@pop1.inapg.fr>
Message-ID: <40ED59FD.21021.16F7362@localhost>

Hi

You can use  %in%

> nom%in%"b"
[1] FALSE  TRUE FALSE

which gives you a logical vector of exact matches

> (1:3)[nom%in%"b"]
[1] 2

or charmatch

> charmatch("b",nom)
[1] 2
> charmatch("ab",nom)
[1] 3

if you expect only one exact match.

But I expect someone can give you better answer.

Cheers
Petr

On 8 Jul 2004 at 9:20, aubert at inapg.fr wrote:

> Let me present to you my problem :
> 
> I have a character vector x and I would like to  obtain the indices of
> the elements of this vector that yielded exactly a match.
> 
> For example,  x=nom, pattern="b", I would to obtain 2 because "b" is
> on the second position.
> 
> First program :
> nom <- c("a","b","ab")
> grep("b",nom)
> 2 3
> 
> Then I try the option extended =FALSE (instead of TRUE by default) and
> I obtain '2 3' a second time.
> 
> Please can you help me : How can I obtain only 2 in using the grep
> function (without using the match function).
> 
> Thanks you
> 
> Julie AUBERT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From amackey at pcbi.upenn.edu  Thu Jul  8 14:58:57 2004
From: amackey at pcbi.upenn.edu (Aaron J. Mackey)
Date: Thu, 8 Jul 2004 08:58:57 -0400
Subject: [R] parallel mle/optim and instability
Message-ID: <9300D41A-D0DE-11D8-A117-000A9577009E@pcbi.upenn.edu>


I have a MLE task that for a small number of parameters finishes in a 
reasonable amount of time, but for my "real" case (with 17 parameters 
to be estimated) either takes far too long (over a day), or fails with 
"computationally singular" errors.  So a) are there any parallel 
implementations of optim() (in R or otherwise) and b) how can I make my 
function more robust? (I've already resorted to using bounded 
parameters and log transformations, which has helped to some degree)

Thanks, -Aaron

library(stats4);
d <- data.frame( ix=c(0,1,2,3,4,5,6,7),
                  ct=c(1000,9609,18403,2617,8237,3619,5520,18908),
                  A=c(0,1,0,1,0,1,0,1),
                  B=c(0,0,1,1,0,0,1,1),
                  C=c(0,0,0,0,1,1,1,1)
                );
ct <- round(logb(length(d$ix), 2))
ll <- function( th=0.5,
                 a1=log(0.5), a2=log(0.5), a3=log(0.5),
                 b1=log(0.5), b2=log(0.5), b3=log(0.5)
               ) {
   a <- exp(sapply(1:ct, function (x) { get(paste("a", x, sep="")) }));
   b <- exp(sapply(1:ct, function (x) { get(paste("b", x, sep="")) }));
   s <- -sum( d$ct * log( sapply( d$ix,
                                  function (ix, th, a, b) {
                                     x <- d[ix+1,3:(ct+2)]
                                     (th     * prod((b ^ (1-x)) * ((1-b) 
^ x    ))) +
                                     ((1-th) * prod((a ^ x    ) * ((1-a) 
^ (1-x))))
                                   },
                                   th, a, b
                                )
                        )
         );
   if (!is.finite(s)) stop(cat(th, a, b, s, sep="\n"));
   s;
}

ml <- mle(ll,
           lower=c(    1e-10, rep(log(    1e-10), 2*ct)),
           upper=c(1 - 1e-10, rep(log(1 - 1e-10), 2*ct)),
           method="L-BFGS-B",
          );



From arin99 at rediffmail.com  Thu Jul  8 15:39:15 2004
From: arin99 at rediffmail.com (Arin Basu)
Date: 8 Jul 2004 13:39:15 -0000
Subject: [R] Importing an Excel file
Message-ID: <20040708133915.19371.qmail@webmail26.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040708/ba826c6b/attachment.pl

From biocperi at yahoo.com  Thu Jul  8 15:56:01 2004
From: biocperi at yahoo.com (S Peri)
Date: Thu, 8 Jul 2004 06:56:01 -0700 (PDT)
Subject: [R] Parsing protein sequences
In-Reply-To: <40ED579B.7660.16624A1@localhost>
Message-ID: <20040708135601.73216.qmail@web50007.mail.yahoo.com>

Dear All,
  I have two files with peptide sequences. These two
have peptide sequences(obtained from tryptic and
semi-tryptic digestion using Mass spec analysis). 
There are two columns :peptide sequence and protein
name.
 
File 2 has both tryptic and semi-tryptic peptides and
File 1 has only semi-tryptic peptides. Is there a way
out that I can filter semi-tryptic peptides from
typtic ones.  There are ~30,000 peptides in each file.

Please suggest if this can be done in R. I want to do
further analysis involving some statistics using R.

Thank you in advance.
SP


File 1 (is a comma seperated file):
pepseq	 proteinname
FENGAFT	NP_065081.1
SLLEDIR	NP_062571.1
VCCEGMLIQ	NP_064583
NWGLSVYADKPETTK	NP_000598
MLAFDVNDEK	NP_000598


File 2 (comma seperated file):
SLLEDIR	NP_062571
TYMLAFDVNDEK	NP_000598
ASSLSESSPPK	NP_057441
LSIVVSLGTGR	NP_003551



From KSA at ssi.dk  Thu Jul  8 16:08:48 2004
From: KSA at ssi.dk (Klaus Jensen)
Date: Thu, 08 Jul 2004 16:08:48 +0200
Subject: [R] Predicting X from Y in four-parameter fit (SSfpl)
Message-ID: <s0ed71ac.094@mailgw.ssi.dk>

While analyzing titration-data using four parameter fit, I need to
predict single values from the model: I need to predict both ways (ie:
X->Y & Y->X): 

Example:

library(nls) 
cramp<-c(33,100,300,900,2700,8100,24300,72900) 
myo<-c(2.7130,2.6790,1.5255,0.7675,0.3670,0.2150,0.1575,0.1400) 
titration<-data.frame(cramp,myo) 
nls(myo~SSfpl(log(cramp),A,B,xmid,scal),data=titration) 
SSfpl(log(2000), coef(sm)[1],coef(sm)[2],coef(sm)[3],coef(sm)[4]) 

-> [1] 1.060424 

This is an example of predicting single values X->Y 

Here is my question:
How do I predict the other way around Y->X ?? 

Any help is appreciated 

Best regards, 
Klaus 
State Serum Institute, Copenhagen



From andy_liaw at merck.com  Thu Jul  8 16:06:45 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 8 Jul 2004 10:06:45 -0400
Subject: [R] [R-pkgs] randomForest 4.3-0 released
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FF4@usrymx25.merck.com>

Dear all,

Version 4.3-0 of the randomForest package is now available on CRAN (in
source; binaries will follow in due course).  There are some interface
changes and a few new features, as well as bug fixes.  For those who had
used previous versions, the important things to note are: 1. there's a
namespace now, and 2. some functions have been renamed.  The list of changes
since 4.0-7 (last public release) is shown below.

As many changes were made to the package, it's very likely that new bugs
have crept in.  I'd very much appreciate bug reports or even patches!

The plan is still to add features to the package so that it matches the
features in Breiman and Cutler's latest Fortran version.  There is also plan
to add some functions so that the package will work with Adele Cutler's Java
visualization program (RAFT).

Best,
Andy

====================================================
Changes in 4.3-0:

* Thanks to Adele Cutler, there's now casewise variable importance 
  measures in classification.  Similar feature is also added for 
  regression.  Use the new localImp option in randomForest().

* The `importance' component of randomForest object has been changed:  
  The permutation-based measures are not divided by their `standard 
  errors'.  Instead, the `standard errors' are stored in the 
  `importanceSD' component.  One should use the importance() extractor 
  function rather than something like rf.obj$importance for extracting 
  the importance measures.

* The importance() extractor function has been updated:  If the 
  permutation-based measures are available, calling importance() 
  with only a randomForest object returns the matrix of variable 
  importance measures.  There is the `scale' argument, which defaults 
  to TRUE.

* In predict.randomForest, there is a new argument `nodes' (default to 
  FALSE).  For classification, if nodes=TRUE, the returned object has an
  attribute `nodes', which is an n by ntree matrix of terminal node
  indicators.  This is ignored for regression.

Changes in 4.2-1:

* There is now a package name space.  Only generics are exported.

* Some function names have been changed: 
    partial.plot -> partialPlot
    var.imp.plot -> varImpPlot
    var.used     -> varUsed

* There is a new option `replace' in randomForest() (default to TRUE)
  indicating whether the sampling of cases is with or without
  replacement. 

* In randomForest(), the `sampsize' option now works for both
  classification and regression, and indicate the number of cases to be 
  drawn to grow each tree.  For classification, if sampsize is a vector of
  length the number of classes, then sampling is stratified by class.

* With the formula interface for randomForest(), the default na.action,	
  na.fail, is effective.  I.e., an error is given if there are NAs present
  in the data.  If na.omit is desired, it must be given explicitly.

* For classification, the err.rate component of the randomForest object
  (and the corresponding one for test set) now is a ntree by (nclass + 1)
  matrix, the first column of which contains the overall error rate, and
  the remaining columns the class error rates.  The running output now
  also prints class error rates.  The plot method for randomForest will
  plot the class error rates as well.

* The predict() method now checks whether the variable names in newdata 
  match those from the training data (if the randomForest object is not
  created from the formula interface).

* partialPlot() and varImpPlot() now have optional arguments xlab, ylab
  and main for more flexible labelling.  Also, if a factor is given as
  the variable, a real bar plot is produced.

* partialPlot() will now remove rows with NAs from the data frame given.

* For regression, if proximity=FALSE, an n by n array of integers is 
  erroneously allocated but not used (it's only used for proximity 
  calculation, so not needed otherwise).

* Updated combine() to conform to the new randomForest object.

* na.roughfix() was not working correctly for matrices, which in turns 
  causes problem in rfImpute().

 
Changes in 4.1-0:

* In randomForest(), if sampsize is given, the sampling is now done
  without replacement, in addition to stratified by class.  Therefore 
  sampsize can not be larger than the class frequencies.

* In classification randomForest, checks are added to avoid trees with 
  only the root node.

* Fixed a bug in the Fortran code for classification that caused segfault 
  on some system when encountering a tree with only root node.

* The help page for predict.randomForest() now states the fact that when 
  newdata is not specified, the OOB predictions from the randomForest 
  object is returned.

* plot.randomForest() and print.randomForest() were not checking for 
  existence of performance (err.rate or mse) on test data correctly.

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From bates at stat.wisc.edu  Thu Jul  8 16:21:58 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 08 Jul 2004 09:21:58 -0500
Subject: [R] Creating Binary Outcomes from a continuous variable
In-Reply-To: <1089205386.16727.123.camel@localhost.localdomain>
References: <88EAF3512A55DF46B06B1954AEF73F7403E71F3D@dc1ex2.air.org>
	<1089205386.16727.123.camel@localhost.localdomain>
Message-ID: <40ED5886.1040109@stat.wisc.edu>

Marc Schwartz wrote:

> On Wed, 2004-07-07 at 07:57, Doran, Harold wrote:
> 
>>Dear List:
>>
>>I have searched the archives and my R books and cannot find a method to
>>transform a continuous variable into a binary variable. For example, I
>>have test score data along a continuous scale. I want to create a new
>>variable in my dataset that is 1=above a cutpoint (or passed the test)
>>and 0=otherwise.
> 
> 
>>My instinct tells me that this will require a combination of the
>>transform command along with a conditional selection. Any help is much
>>appreciated.
> 
> 
> Example:
> 
> 
>>a <- rnorm(20)
>>b <- ifelse(a < 0, 0, 1)
> 
> 
>>a
> 
>  [1] -1.0735800 -0.6788456  1.9979801 -0.4026760  0.1781791 -1.1540434
>  [7] -1.0842728  1.6042602 -0.7950492 -0.1194323  0.4450296  1.9269333
> [13] -0.4456181 -0.8374677 -1.1898772  1.7353067  1.8619422 -0.1679996
> [19] -0.2656138 -1.5529884
> 
>>b
> 
>  [1] 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0
> 
> HTH,
> 
> Marc Schwartz
For your application Harold I would consider converting the response to 
a factor while dichotomizing it so that summary will give a meaningful table

b <- factor(ifelse(a < 0, "Neg", "Pos"))

BTW, there are many examples like this in the notes for the short course 
that you took last summer  :-)



From KSA at ssi.dk  Thu Jul  8 16:20:59 2004
From: KSA at ssi.dk (Klaus Jensen)
Date: Thu, 08 Jul 2004 16:20:59 +0200
Subject: [R] Code OK - Predicting X from Y in four-parameter fit (SSfpl) -
Message-ID: <s0ed7475.011@mailgw.ssi.dk>

[Sorry for any inconvenience - Code is OK now]

While analyzing titration-data using four parameter fit, I need to
predict single values from the model: I need to predict both ways (ie:
X->Y & Y->X): 

Example:

library(nls) 
cramp<-c(33,100,300,900,2700,8100,24300,72900) 
myo<-c(2.7130,2.6790,1.5255,0.7675,0.3670,0.2150,0.1575,0.1400) 
titration<-data.frame(cramp,myo) 
fi<-nls(myo~SSfpl(log(cramp),A,B,xmid,scal),data=titration) 
SSfpl(log(2000), coef(fi)[1],coef(fi)[2],coef(fi)[3],coef(fi)[4]) 

-> 0.3689212 

This is an example of predicting single values X->Y 

Here is my question:
How do I predict the other way around Y->X ?? 

Any help is appreciated 

Best regards, 
Klaus 
State Serum Institute, Copenhagen



From wolfram at fischer-zim.ch  Thu Jul  8 16:26:00 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Thu, 8 Jul 2004 16:26:00 +0200
Subject: [R] Getting elements of a matrix by a vector of column indice s
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7FF2@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7FF2@usrymx25.merck.com>
Message-ID: <20040708142600.GA3441@s1x.local>

Thanks for you answer! It works.

>	m <- outer(letters[1:5], 1:4, paste, sep="")

The following works with the help of your proposition:
>	rowidx.n <- c( 2, 3, 4)
>	colidx.n <- c( 1, 3, 2)
>	idx.n <- cbind( rowidx.n, colidx.n )
>	m[idx.n]
[1] "b1" "c3" "d2"

In my real data there was an additional difficulty:
I had names of rows and columns as indices:
>	rownames(m) <- paste('R', 1:nrow(m), sep="")
>	colnames(m) <- paste('C', 1:ncol(m), sep="" )

And the following did not work anymore:
>	rowidx <- c( 'R2', 'R3', 'R4' )
>	colidx <- c( 'C1', 'C3', 'C2' )
>	idx <- cbind( rowidx, colidx )
>	m[idx]
<NA> <NA> <NA> <NA> <NA> <NA> 
  NA   NA   NA   NA   NA   NA 

Do you have another suggestion? - Thanks! Wolfram

--- In reply to: ---
>Date:    08.07.04 08:21 (-0400)
>From:    "Liaw, Andy" <andy_liaw at merck.com>
>Subject: RE: [R] Getting elements of a matrix by a vector of column indice s
>
> See if the following helps:
> 
> > m <- outer(letters[1:5], 1:4, paste, sep="")
> > m
>      [,1] [,2] [,3] [,4]
> [1,] "a1" "a2" "a3" "a4"
> [2,] "b1" "b2" "b3" "b4"
> [3,] "c1" "c2" "c3" "c4"
> [4,] "d1" "d2" "d3" "d4"
> [5,] "e1" "e2" "e3" "e4"
> > idx <- c(2, 1, 3, 4, 2)
> > m[cbind(1:5, idx)]
> [1] "a2" "b1" "c3" "d4" "e2"
> 
> Andy
> 
> > From: Wolfram Fischer
> > 
> > I have e.g.
> >     t <- matrix( nrow=2, ncol=3, byrow=TRUE, 
> > c('a1','a2','a3','b1','b2','b3') )
> > and
> >     i <- c( 3, 2)
> > 
> > Is it possible to formulate a simple expression that gets
> >     c( t[ 1, i[1] ], t[ 2, i[2] ] )
> > (and so on for longer matrices)?
> > 
> > The result would be:
> >     [1] "a3" "b2"
> > 
> > Thanks - Wolfram
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
> ------------------------------------------------------------------------------



From Colin.Bleay at bristol.ac.uk  Thu Jul  8 16:35:25 2004
From: Colin.Bleay at bristol.ac.uk (CR Bleay, School Biological Sciences)
Date: Thu, 08 Jul 2004 15:35:25 +0100
Subject: [R] Re: errors in randomization test
In-Reply-To: <200407061223.i66CNxXq029138@erdos.math.unb.ca>
References: <200407061223.i66CNxXq029138@erdos.math.unb.ca>
Message-ID: <3188593.1089300925@bio-colinbleaymac.bio.bris.ac.uk>

Dear Rolf,

I tried using you code, however i have found that the whole routine is 
still stopped by the call to GLM.nb fro certain datasets before it enters 
the "if" statement. is there anyway to ensure that this does not occur.

cheers,

colin

--On Tuesday, July 6, 2004 9:23 am -0300 Rolf Turner <rolf at math.unb.ca> 
wrote:

> Colin Bleay wrote:
>
>> last week i sent an e-mail about dealing with errors thrown up from a
>> glm.nb model carried out on multiple random datasets.
>>
>> every so often a dataset is created which results in the following error
>> after a call to glm.nb:
>>
>> "Error: NA/NaN/Inf in foreign function call (arg 1)
>> In addition: Warning message:
>> Step size truncated due to divergence"
>>
>>
>> I am at a loss as to how to deal with this.
>>
>> firstly because the dataset that is generated, although throwing an
>> error  when the glm.nb model is applied, is a valid dataset. so how do i
>> incorporate this dataset in my results (results being descriptive stats
>> on  the coefficients from the multiple datasets) i.e. shoould
>> coefficients be  set to zero?
>
> 	Almost surely, setting the coefficients equal to 0 is the
> 	wrong thing to do.  What the right thing is depends on the
> 	answer to ``lastly''.
>
> 	Setting the coefficients to be NA in this case (i.e.
> 	effectively throwing away such cases) is also wrong, but not
> 	quite as wrong as setting them equal to 0.
>
>> secondly, how do i capture and deal with the error. is it possible to
>> construct an "if" statement so that "if error, do this, if not continue"
>
> 	This should be do-able using try().  Something like:
>
> 	c.list <- list()
> 	save.bummers <- list()
> 	K <- 0
> 	for(i in 1:42) {
> 		repeat {
> 			X <- generate.random.data.set()
> 			Y <- try(glm.nb(X,whatever))
> 			if(inherits(Y,"try-error")) {
> 				K <- K+1
> 				save.bummers[[K]] <- X
> 			} else break
> 		}
> 		c.list[[i]] <- coeff(Y)
> 	}
>
> 	This should give you a sample of 42 coefficient vectors from
> 	the ``successful'' data sets, and a list of all the (a random
> 	number of) data sets that yielded a lack of success.  You can
> 	then take the data sets stored in save.bummers and experiment
> 	with them to see what is causing the problem.
>
>> lastly, i am unsure as to what characteristics of a dataset would result
>> in  these errors in the glm.nb?
>
> 	Here I have to heed the advice (attributed to a ``great art
> 	historian'') from George F. Simmons' wonderful book on
> 	elementary differential equations:  ``A fool he who gives
> 	more than he has.''
>
> 					cheers,
>
> 						Rolf Turner
> 						rolf at math.unb.ca
>



----------------------
Dr Colin Bleay
Dept. Biological Sciences,
University of Bristol,
Woodlands rd.,
Bristol,
BS8 1UG.
UK

Tel: 44 (0)117 928 7470
Fax: 44 (0)117



From andy_liaw at merck.com  Thu Jul  8 16:44:56 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 8 Jul 2004 10:44:56 -0400
Subject: [R] Getting elements of a matrix by a vector of column
 indice s
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7FF5@usrymx25.merck.com>

This should work:

> idx <- cbind(match(rowidx, rownames(m)), match(colidx, colnames(m)))
> m[idx]
[1] "b1" "c3" "d2"

Andy

> From: Wolfram Fischer
> 
> Thanks for you answer! It works.
> 
> >	m <- outer(letters[1:5], 1:4, paste, sep="")
> 
> The following works with the help of your proposition:
> >	rowidx.n <- c( 2, 3, 4)
> >	colidx.n <- c( 1, 3, 2)
> >	idx.n <- cbind( rowidx.n, colidx.n )
> >	m[idx.n]
> [1] "b1" "c3" "d2"
> 
> In my real data there was an additional difficulty:
> I had names of rows and columns as indices:
> >	rownames(m) <- paste('R', 1:nrow(m), sep="")
> >	colnames(m) <- paste('C', 1:ncol(m), sep="" )
> 
> And the following did not work anymore:
> >	rowidx <- c( 'R2', 'R3', 'R4' )
> >	colidx <- c( 'C1', 'C3', 'C2' )
> >	idx <- cbind( rowidx, colidx )
> >	m[idx]
> <NA> <NA> <NA> <NA> <NA> <NA> 
>   NA   NA   NA   NA   NA   NA 
> 
> Do you have another suggestion? - Thanks! Wolfram
> 
> --- In reply to: ---
> >Date:    08.07.04 08:21 (-0400)
> >From:    "Liaw, Andy" <andy_liaw at merck.com>
> >Subject: RE: [R] Getting elements of a matrix by a vector of 
> column indice s
> >
> > See if the following helps:
> > 
> > > m <- outer(letters[1:5], 1:4, paste, sep="")
> > > m
> >      [,1] [,2] [,3] [,4]
> > [1,] "a1" "a2" "a3" "a4"
> > [2,] "b1" "b2" "b3" "b4"
> > [3,] "c1" "c2" "c3" "c4"
> > [4,] "d1" "d2" "d3" "d4"
> > [5,] "e1" "e2" "e3" "e4"
> > > idx <- c(2, 1, 3, 4, 2)
> > > m[cbind(1:5, idx)]
> > [1] "a2" "b1" "c3" "d4" "e2"
> > 
> > Andy
> > 
> > > From: Wolfram Fischer
> > > 
> > > I have e.g.
> > >     t <- matrix( nrow=2, ncol=3, byrow=TRUE, 
> > > c('a1','a2','a3','b1','b2','b3') )
> > > and
> > >     i <- c( 3, 2)
> > > 
> > > Is it possible to formulate a simple expression that gets
> > >     c( t[ 1, i[1] ], t[ 2, i[2] ] )
> > > (and so on for longer matrices)?
> > > 
> > > The result would be:
> > >     [1] "a3" "b2"
> > > 
> > > Thanks - Wolfram
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > 
> > 
> > 
> --------------------------------------------------------------
> ----------------
> > Notice:  This e-mail message, together with any 
> attachments, contains information of Merck & Co., Inc. (One 
> Merck Drive, Whitehouse Station, New Jersey, USA 08889), 
> and/or its affiliates (which may be known outside the United 
> States as Merck Frosst, Merck Sharp & Dohme or MSD and in 
> Japan, as Banyu) that may be confidential, proprietary 
> copyrighted and/or legally privileged. It is intended solely 
> for the use of the individual or entity named on this 
> message.  If you are not the intended recipient, and have 
> received this message in error, please notify us immediately 
> by reply e-mail and then delete it from your system.
> > 
> --------------------------------------------------------------
> ----------------
> 
>



From JonesW at kssg.com  Thu Jul  8 17:06:38 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 8 Jul 2004 16:06:38 +0100 
Subject: [R] k nearest neighbor prediction
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02BD10A4@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040708/6aa71c81/attachment.pl

From roebuck at odin.mdacc.tmc.edu  Thu Jul  8 17:37:17 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Thu, 8 Jul 2004 10:37:17 -0500 (CDT)
Subject: [R] Statistics::R
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E957C27BF@iahce2knas1.iah.bbsrc.reserved>
References: <8975119BCD0AC5419D61A9CF1A923E957C27BF@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <Pine.OSF.4.58.0407081033550.418197@odin.mdacc.tmc.edu>

On Thu, 8 Jul 2004, michael watson (IAH-C) wrote:

> I am looking (possibly in vain!) for the Author of the Statistics::R
> perl package - I believe he announced the package on this mailing list
> some months ago.  The name is Graciliano Monteiro Passos, and his e-mail
> address, gm at virtuasites.com.br, is giving permanent errors.
>
> Can anyone help?  Does anyone use this perl package with R?  I am having
> a few problems with it.

I used it for one of my projects and also tried unsuccessfully
to contact the author. I forgot to follow-up on that failure so
if you find him, let me know too.

Can't help without a description of the problem you are having
though...

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From spencer.graves at pdf.com  Thu Jul  8 18:17:00 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 08 Jul 2004 09:17:00 -0700
Subject: [R] parallel mle/optim and instability
In-Reply-To: <9300D41A-D0DE-11D8-A117-000A9577009E@pcbi.upenn.edu>
References: <9300D41A-D0DE-11D8-A117-000A9577009E@pcbi.upenn.edu>
Message-ID: <40ED737C.5060305@pdf.com>

      Does "optim" give you "computationally singular" errors?  I've had 
similar problems with "nls", but "optim" have given me answers even in 
such cases. 

      Do your numbers have substantially different orders of magnitude?  
Is it feasible to rescale everything to mean 0, standard deviation of 1, 
and then write your model in terms of these rescaled variables?  If yes, 
this can help. 

      I suggest you reparameterize the problem to move the constraints 
to +/-Inf.  If you can't do that, add penalty function corresponding to 
the constraints, while making sure your objective function will never 
give NA nor +/-Inf.  Find the conditions that generate that and 
eliminate them. 

      Without box constraints, "optim" has 4 methods.  I'd try the first 
3;  the fourth is simulated annealing, which may be wonderful for 
objective functions with many local minima but otherwise takes forever 
and produces answers that are inferior to the other three methods, in 
the few cases I've tried. 

      Also, with a problem with many parameters, I've written a function 
that allows me to pass as a "..." argument the subset of parameters I 
want to estimate.  Then I can try different subsets until I isolate the 
problem. 

      hope this helps.  spencer graves

Aaron J. Mackey wrote:

>
> I have a MLE task that for a small number of parameters finishes in a 
> reasonable amount of time, but for my "real" case (with 17 parameters 
> to be estimated) either takes far too long (over a day), or fails with 
> "computationally singular" errors.  So a) are there any parallel 
> implementations of optim() (in R or otherwise) and b) how can I make 
> my function more robust? (I've already resorted to using bounded 
> parameters and log transformations, which has helped to some degree)
>
> Thanks, -Aaron
>
> library(stats4);
> d <- data.frame( ix=c(0,1,2,3,4,5,6,7),
>                  ct=c(1000,9609,18403,2617,8237,3619,5520,18908),
>                  A=c(0,1,0,1,0,1,0,1),
>                  B=c(0,0,1,1,0,0,1,1),
>                  C=c(0,0,0,0,1,1,1,1)
>                );
> ct <- round(logb(length(d$ix), 2))
> ll <- function( th=0.5,
>                 a1=log(0.5), a2=log(0.5), a3=log(0.5),
>                 b1=log(0.5), b2=log(0.5), b3=log(0.5)
>               ) {
>   a <- exp(sapply(1:ct, function (x) { get(paste("a", x, sep="")) }));
>   b <- exp(sapply(1:ct, function (x) { get(paste("b", x, sep="")) }));
>   s <- -sum( d$ct * log( sapply( d$ix,
>                                  function (ix, th, a, b) {
>                                     x <- d[ix+1,3:(ct+2)]
>                                     (th     * prod((b ^ (1-x)) * 
> ((1-b) ^ x    ))) +
>                                     ((1-th) * prod((a ^ x    ) * 
> ((1-a) ^ (1-x))))
>                                   },
>                                   th, a, b
>                                )
>                        )
>         );
>   if (!is.finite(s)) stop(cat(th, a, b, s, sep="\n"));
>   s;
> }
>
> ml <- mle(ll,
>           lower=c(    1e-10, rep(log(    1e-10), 2*ct)),
>           upper=c(1 - 1e-10, rep(log(1 - 1e-10), 2*ct)),
>           method="L-BFGS-B",
>          );
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jmc at research.bell-labs.com  Thu Jul  8 22:18:05 2004
From: jmc at research.bell-labs.com (John Chambers)
Date: Thu, 08 Jul 2004 16:18:05 -0400
Subject: [R] questions about setMethod("Arith", ...)
References: <40EA8A48.3030708@uni-bayreuth.de>
Message-ID: <40EDABFD.56E38AB5@research.bell-labs.com>

The version of "distr" on CRAN at the time of this posting is seriously
broken, in ways that are not directly related to Arith or to group
generics in general, but which are enough to explain the problems you
report (and much else besides).

You include a NAMESPACE file with this package.  If you really want to
use namespaces (somewhat questionable in this case), you must include
exportMethods() directives for all functions in setMethod() calls.  You
have not done so, therefore in principle all your methods are private,
except those for generic functions exported from distr itself.

(Because of the way primitive functions currently dispatch methods, you
probably didn't see as much evidence as you should have showing the
error.  If you had used the  showMethods() function recommended in
"Programming with Data" to view methods, not the getMethods() function,
you would have seen that distr created no public methods for "/" or the
other arithmetic operators.)

The distr package has a couple of other obvious questionable features. 
It takes a very long time for library(distr) to be executed.  For
packages with substantial class and method definitions, the
traditionally installed R package is slow to attach, because R does all
the computations in the package source each time the library is
attached.  You should use the -s option to INSTALL to create a saved
image.  Also, package distr overrides the objects F and T in the base
package, which is likely to cause problems for many users, especially
those coming from S-Plus.

Your other comments below mostly come from not recognizing that methods
for a specific member of the group ("/", "+") always take precedence
over any methods for the group generic.

It's very desirable that reports to r-help  (especially those implying a
bug) be based on clear, self-contained examples using reliable packages
only.  Otherwise anyone trying to respond has to search through your
code trying to find out what's going on, which will make a response to
any further postings less likely.  This posting is an example.

Sorry to be severe.  Your package looks interesting--do persevere with
it, but you should test future versions more thoroughly before
submitting them to CRAN.

John Chambers


Matthias Kohl wrote:
> 
> Hi,
> 
> we have some questions concerning the definition of new arithmetic methods.
> 
> In our package "distr" (on CRAN) we define some new arithmetic methods
> for "+", "-", "*", "/".
> After loading "distr" the corresponding arithmetic methods work. Now, if
> we define a new
> class and also a new method for one of the arithmetic methods "+", "-",
> "*", "/", still everything works fine. But, if we then define new
> methods for the whole group "Arith", the arithmetic methods of "distr"
> no longer work. (for more details see example code below)
> What are we missing?
> 
> Moreover, there is a certain precendence; i.e., if one defines a single
> arithmetic method (e.g., "/") and alterwards defines a method for the
> whole group "Arith", the "old" method "/" remains valid.
> However, if we first define a method for the whole group "Arith" and
> afterwards define a new single arithmetic method (e.g., "+") the new one
> is valid. (for more details see example code below).
> Is this intended?
> 
> Thanks for your help,
> Matthias, Thomas
> 
> ###########################################################
> ## Example code
> ###########################################################
> require(distr)
> getMethods("/")  # shows the corresponding methods of "distr"
> 
> ## now define a new class "track" (see Chambers (1998))
> ## and define "/"
> 
> setClass("track", representation(x = "numeric", y = "numeric"))
> setMethod("/", signature("track", "numeric"),
>           function(e1, e2){ e1 at y = e1 at y/e2; e1 })
> 
> getMethods("/")  # shows the corresponding methods
>                  # of "distr" and class "track"
> 
> (N <- Norm()) # creates an object of standard normal distribution
> (N1 <- N/3) # works
> (tr <- new("track", x = 1:3, y = 4:6))
> (tr1 <- tr/3) # works
> 
> ## now define new methods for "Arith"
> setMethod("Arith", signature("track", "numeric"),
>           function(e1, e2){
>             e1 at x = callGeneric(e1 at x, e2)
>             e1
>           })
> 
> getMethods("/") # "/" for "distr" is lost
> N2 <- N/3 # fails
> (tr2 <- tr/3) # works, "but" still the "old" method
> tr + 2 # works
> 
> ## now a new method "+"
> setMethod("+", signature("track", "numeric"),
>           function(e1, e2){ e1 at y = e1 at y+e2; e1 })
> 
> tr + 2 # works, "but" with the "new" method
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From salarode at yahoo.com.ar  Thu Jul  8 22:33:57 2004
From: salarode at yahoo.com.ar (=?iso-8859-1?q?Rodrigo=20Sala?=)
Date: Thu, 8 Jul 2004 17:33:57 -0300 (ART)
Subject: [R] New user
Message-ID: <20040708203357.20405.qmail@web52705.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040708/e9f12ba0/attachment.pl

From spencer.graves at pdf.com  Thu Jul  8 22:55:09 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 08 Jul 2004 13:55:09 -0700
Subject: [R] New user
In-Reply-To: <20040708203357.20405.qmail@web52705.mail.yahoo.com>
References: <20040708203357.20405.qmail@web52705.mail.yahoo.com>
Message-ID: <40EDB4AD.6080503@pdf.com>

      Have you considered "sem" = "structural equation models, which you 
may know is another name for path analysis? 

      hope this helps.  spencer graves
p.s. PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html.  It might help you answer 
questions like this yourself. 

Rodrigo Sala wrote:

>Hi all R users. I'm just starting to use R, and I'm still a little lost. I'd like to analyse some data following the path analysis aproach. I'd like to know if there is some package for implement this kind of analysis.
>Many thanks
> 
>
>
>Rodrigo Sala
>Posgrado en Producci??n Vegetal
>E.E.A. INTA Balcarce
>Ruta Nacional 226 km 73.5 (7620)
>Balcarce, Buenos Aires, Argentina
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From bates at stat.wisc.edu  Fri Jul  9 03:18:13 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 08 Jul 2004 20:18:13 -0500
Subject: [R] lme: extract variance estimate
In-Reply-To: <40EC56C3.5070101@pdf.com>
References: <5.2.1.1.2.20040707151055.00b981d0@postoffice6.mail.cornell.edu>
	<40EC56C3.5070101@pdf.com>
Message-ID: <40EDF255.4040204@stat.wisc.edu>

I'm actually replying to Stephen's message but I had already deleted it 
before I read Spencer's message.  (I'm on a slow connection and I am 
simultaneously downloading a big file so I am trying to optimize 
bandwidth, sometimes with unfortunate results.)

In the previous message the author showed the slots u at scale (a numeric 
scalar), u at reSumry (a list of corrmatrix objects), and u at useScale 
(logical).  The quantity that you are looking for is calculated as

  unlist(lapply(u at reSumry, function(x, scal) scal*x at stdDev,
          scal = ifelse(u at useScale, u at scale, 1.)))

plus-or-minus a parenthesis or two.

The reSumry contains the relative variance-covariance matrices in the 
form of correlations and standard deviations.  Some models, such as lme 
models, use a scale parameter.  Others, such as binomial generalized 
linear mixed models, do not.  That is why the estimate of the scale 
parameter is stored separately along with a flag indicating whether 
scaling should be used.



From tlumley at u.washington.edu  Fri Jul  9 05:30:38 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 8 Jul 2004 20:30:38 -0700 (PDT)
Subject: [R] How to pass strings to functions? [once once more, now With
	content I hope...]
In-Reply-To: <40ED20A8.2030008@brain.riken.jp>
References: <40ED20A8.2030008@brain.riken.jp>
Message-ID: <Pine.A41.4.58.0407082030090.208436@homer05.u.washington.edu>

On Thu, 8 Jul 2004, Gijs Plomp wrote:

> Dear expeRts,
>
> I fail to succesfully pass strings to functions. It comes down to the
> observation that
>
>  > plot(someVariable,anotherVariable)
>
> works fine, but
>
>  > x <- "someVariable"
>  > y <- "anotherVariable"
>  > plot(x,y)
>
> does not.
>
> Does this have something to do with the returned value of x being
> /"someVariable"/ and not /someVariable/, i.e. without the quotation
> marks? Is there any way to work around this?
>

This is in the FAQ.

	-thomas



From papydien at yahoo.fr  Fri Jul  9 10:04:43 2004
From: papydien at yahoo.fr (=?iso-8859-1?q?Papy=20Gaston?=)
Date: Fri, 9 Jul 2004 10:04:43 +0200 (CEST)
Subject: [R] Two additive  effets in random of lme
Message-ID: <20040709080443.47613.qmail@web50908.mail.yahoo.com>

how I can put two additive effects in random of lme ?

Thanks



From M.Mamin at intershop.de  Fri Jul  9 10:55:19 2004
From: M.Mamin at intershop.de (Marc Mamin)
Date: Fri, 9 Jul 2004 10:55:19 +0200
Subject: [R] Problem with the grep function
Message-ID: <A03188C6623C0D46A703CB5AA59907F21706DD@JENMAIL01.ad.intershop.net>

Hi,

you can use regular expression with grep. 

For example:

>exactmatch<-function(s,l){return(grep(paste('^',s,'$',sep=''),l))}

>t<-c('a','ab','abc','c','ca','ab')

> exactmatch('ab',t)
[1] 2 6

HTH

Marc



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Petr Pikal
Sent: Thursday, July 08, 2004 2:28 PM
To: aubert at inapg.fr; r-help at stat.math.ethz.ch
Subject: Re: [R] Problem with the grep function


Hi

You can use  %in%

> nom%in%"b"
[1] FALSE  TRUE FALSE

which gives you a logical vector of exact matches

> (1:3)[nom%in%"b"]
[1] 2

or charmatch

> charmatch("b",nom)
[1] 2
> charmatch("ab",nom)
[1] 3

if you expect only one exact match.

But I expect someone can give you better answer.

Cheers
Petr

On 8 Jul 2004 at 9:20, aubert at inapg.fr wrote:

> Let me present to you my problem :
> 
> I have a character vector x and I would like to  obtain the indices of
> the elements of this vector that yielded exactly a match.
> 
> For example,  x=nom, pattern="b", I would to obtain 2 because "b" is
> on the second position.
> 
> First program :
> nom <- c("a","b","ab")
> grep("b",nom)
> 2 3
> 
> Then I try the option extended =FALSE (instead of TRUE by default) and
> I obtain '2 3' a second time.
> 
> Please can you help me : How can I obtain only 2 in using the grep
> function (without using the match function).
> 
> Thanks you
> 
> Julie AUBERT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From catch_utsav at yahoo.com  Fri Jul  9 10:58:27 2004
From: catch_utsav at yahoo.com (Utsav Boobna)
Date: Fri, 9 Jul 2004 01:58:27 -0700 (PDT)
Subject: [R] dyn.load() for windows
Message-ID: <20040709085827.19361.qmail@web14821.mail.yahoo.com>

Hi,
   I compiled several C program files on Borland C++
compiler to get one dll output (as instructed in the
file readme.package). Now when I try to load this
*.dll to R using dyn.load(), then the machine gives
the error message "*.dll is not a valid windows
data,....". The out put of R is 

I am working on win2k.
What could be the possible reason for that?

Thanks,
Utsav



From dmurdoch at pair.com  Fri Jul  9 12:11:16 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 09 Jul 2004 06:11:16 -0400
Subject: [R] dyn.load() for windows
In-Reply-To: <20040709085827.19361.qmail@web14821.mail.yahoo.com>
References: <20040709085827.19361.qmail@web14821.mail.yahoo.com>
Message-ID: <uirse0t597od2p28lkdoticq2ga9652mfa@4ax.com>

On Fri, 9 Jul 2004 01:58:27 -0700 (PDT), Utsav Boobna
<catch_utsav at yahoo.com> wrote:

>Hi,
>   I compiled several C program files on Borland C++
>compiler to get one dll output (as instructed in the
>file readme.package). Now when I try to load this
>*.dll to R using dyn.load(), then the machine gives
>the error message "*.dll is not a valid windows
>data,....". The out put of R is 
>
>I am working on win2k.
>What could be the possible reason for that?

Please show us your code and the exact error message (using cut and
paste).  It might also help if you gave an exact description of how
you produced the DLL (though I'm not familiar with BC++, someone else
might be), and gave version numbers of BC++ and R.

Duncan Murdoch



From catch_utsav at yahoo.com  Fri Jul  9 12:29:55 2004
From: catch_utsav at yahoo.com (Utsav Boobna)
Date: Fri, 9 Jul 2004 03:29:55 -0700 (PDT)
Subject: [R] dyn.load() for windows
In-Reply-To: <uirse0t597od2p28lkdoticq2ga9652mfa@4ax.com>
Message-ID: <20040709102955.36191.qmail@web14807.mail.yahoo.com>

Hi 
I am using Borland C++ compiler 5.5 and R 1.7.1

got the dll using 

c:\> bcc32 -u- -6 -O2 -osample.dll -WDE sample.c


Then in R I used

> dyn.load("sample.dll")

Error in dyn.load(x, as.logical(local),
as.logical(now)) : 
        unable to load shared library "C:/sample.dll":
  LoadLibrary failure:  %1 ist keine zulssige
Win32-Anwendung.

(Its in German ... meaning "%1 is not a valid Win32
application.")



Thanks,
Utsav

--- Duncan Murdoch <dmurdoch at pair.com> wrote:
> On Fri, 9 Jul 2004 01:58:27 -0700 (PDT), Utsav
> Boobna
> <catch_utsav at yahoo.com> wrote:
> 
> >Hi,
> >   I compiled several C program files on Borland
> C++
> >compiler to get one dll output (as instructed in
> the
> >file readme.package). Now when I try to load this
> >*.dll to R using dyn.load(), then the machine gives
> >the error message "*.dll is not a valid windows
> >data,....". The out put of R is 
> >
> >I am working on win2k.
> >What could be the possible reason for that?
> 
> Please show us your code and the exact error message
> (using cut and
> paste).  It might also help if you gave an exact
> description of how
> you produced the DLL (though I'm not familiar with
> BC++, someone else
> might be), and gave version numbers of BC++ and R.
> 
> Duncan Murdoch
>



From bavorak at klobouk.fsv.cvut.cz  Fri Jul  9 13:19:23 2004
From: bavorak at klobouk.fsv.cvut.cz (bavorak@klobouk.fsv.cvut.cz)
Date: Fri, 9 Jul 2004 13:19:23 +0200 (CEST)
Subject: [R] Re: combined graph in R
In-Reply-To: <Pine.LNX.4.43.0407071047080.5017-201002@klobouk.fsv.cvut.cz>
Message-ID: <Pine.LNX.4.43.0407091316210.9494-100003@klobouk.fsv.cvut.cz>

 Hello,
  I could not yet create combined graph in R. To avoid misunderstands,
 three examples (originally created in Quattro pro) have been attached.
 At first, I don't know how to create graph composed of bars and areas in
 the same picture as it is shown in the balance graph (h2plc02.gif).
 I am sendind the original data table from that I need make the same
 charts. First column (julian day) is also the scale for x-axis, next two
 to skip, 6th to 8th precipitation daily totals (blue columns), leakage
 (red polygon) and transpiration (green columns negative oriented).
 Can you send me an algorithm to plot this in this form?

 With thanks and regards

 Tomas Bayer


-------------- next part --------------
A non-text attachment was scrubbed...
Name: cb99tokd.png
Type: image/png
Size: 15679 bytes
Desc: flow chart
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20040709/ba2468a5/cb99tokd.png

From B.Rowlingson at lancaster.ac.uk  Fri Jul  9 13:57:09 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 09 Jul 2004 12:57:09 +0100
Subject: [R] Re: combined graph in R
In-Reply-To: <Pine.LNX.4.43.0407091316210.9494-100003@klobouk.fsv.cvut.cz>
References: <Pine.LNX.4.43.0407091316210.9494-100003@klobouk.fsv.cvut.cz>
Message-ID: <40EE8815.3030405@lancaster.ac.uk>

bavorak at klobouk.fsv.cvut.cz wrote:
>  Hello,
>   I could not yet create combined graph in R. To avoid misunderstands,
>  three examples (originally created in Quattro pro) have been attached.

  Only one graph seems to have made it through to the mailing list. You 
should avoid posting things with attachments.

  My initial response is "Why?". This graph is horrible. Most of the 
information is obscured by the overlapping graphics. You can't see the 
red line for about 90% of the plot, although it occasionally peeks out 
between the green and yellow. The spikes seem to be clipped at the top 
of the plot (do the values go higher or is there a hard limit on what 
they can go up to?) and the sharpness of the spikes makes it hard to 
tell what's going on.

  The X-axis numbering is in increments of 11. Do you have an extra 
finger? And which of the numerous tick marks corresponds to the number?
>
>  Can you send me an algorithm to plot this in this form?
> 
  We could probably do better, but the data didn't make it through 
either. The important thing with any plot is to design it to help tell 
the viewer what you want to say. All this plot says to me is 'the green 
and yellow are correlated (when not obscured by blue)', 'blue and red 
spikes seem correlated (when red not obscured)', and 'blue and red are 
more spiky than green and yellow'.

  Look at the documentation for 'matplot', which draws multiple lines 
from a matrix of data. I'd plot the data as simple lines, not coloured 
areas, so there's less obscuring, and probably transform the Y-values to 
smooth it out a bit. R will automatically make the X-axis values in 
multiples of 5 or 10, and give you a decent number of tick marks. You 
can even have the X-axis labeled with the calendar date.

  This is a classic example of bad spreadsheet graphics!

Barry



From dmb at mrc-dunn.cam.ac.uk  Fri Jul  9 14:22:13 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Fri, 9 Jul 2004 13:22:13 +0100 (BST)
Subject: [R] Simple 'frequency' function?
Message-ID: <Pine.LNX.4.21.0407091315020.7191-100000@mail.mrc-dunn.cam.ac.uk>


Hi, I have designed the following function to extract count frequencies
from an array of integers. For example...

# Tipical array
x <- cbind(1,1,1,1,1,2,2,2,2,3,3,3,3,4,5,6,7,22)

# Define the frequency function
frequency <-
  function(x){
    max <- max(x)
    j <- c()
    for(i in 1:max){
      j[i] <- length(x[x==i])
    }
    return(j)
}

fre <- frequency(x)
plot(fre)

How can I ... 

1) Make this a general function so my array could be of the form

# eats!
x <- cbind( "egg","egg","egg","egg","ham","ham","ham","ham","chicken" )

fre <- frequency(x)
plot(fre)

2) Make frequency return an object which I can call plot on (allowing the
prob=TRUE option).

Cheers,
Dan.



From ligges at statistik.uni-dortmund.de  Fri Jul  9 14:19:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 09 Jul 2004 14:19:24 +0200
Subject: [R] Simple 'frequency' function?
In-Reply-To: <Pine.LNX.4.21.0407091315020.7191-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0407091315020.7191-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <40EE8D4C.9050706@statistik.uni-dortmund.de>

Dan Bolser wrote:

> Hi, I have designed the following function to extract count frequencies
> from an array of integers. For example...
> 
> # Tipical array
> x <- cbind(1,1,1,1,1,2,2,2,2,3,3,3,3,4,5,6,7,22)
> 
> # Define the frequency function
> frequency <-
>   function(x){
>     max <- max(x)
>     j <- c()
>     for(i in 1:max){
>       j[i] <- length(x[x==i])
>     }
>     return(j)
> }
> 
> fre <- frequency(x)
> plot(fre)
> 
> How can I ... 
> 
> 1) Make this a general function so my array could be of the form
> 
> # eats!
> x <- cbind( "egg","egg","egg","egg","ham","ham","ham","ham","chicken" )
> 
> fre <- frequency(x)
> plot(fre)
> 
> 2) Make frequency return an object which I can call plot on (allowing the
> prob=TRUE option).


See ?table:

   table(x)
   plot(table(x))
   plot(table(x) / sum(table(x)))

Uwe Ligges



> Cheers,
> Dan.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rpeng at jhsph.edu  Fri Jul  9 14:22:08 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 09 Jul 2004 08:22:08 -0400
Subject: [R] Simple 'frequency' function?
In-Reply-To: <Pine.LNX.4.21.0407091315020.7191-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0407091315020.7191-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <40EE8DF0.3040202@jhsph.edu>

I think:

frequency <- function(x) table(as.factor(x))

should work generally.  Not sure what you mean by the plotting.

-roger

Dan Bolser wrote:
> Hi, I have designed the following function to extract count frequencies
> from an array of integers. For example...
> 
> # Tipical array
> x <- cbind(1,1,1,1,1,2,2,2,2,3,3,3,3,4,5,6,7,22)
> 
> # Define the frequency function
> frequency <-
>   function(x){
>     max <- max(x)
>     j <- c()
>     for(i in 1:max){
>       j[i] <- length(x[x==i])
>     }
>     return(j)
> }
> 
> fre <- frequency(x)
> plot(fre)
> 
> How can I ... 
> 
> 1) Make this a general function so my array could be of the form
> 
> # eats!
> x <- cbind( "egg","egg","egg","egg","ham","ham","ham","ham","chicken" )
> 
> fre <- frequency(x)
> plot(fre)
> 
> 2) Make frequency return an object which I can call plot on (allowing the
> prob=TRUE option).
> 
> Cheers,
> Dan.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bates at stat.wisc.edu  Fri Jul  9 14:33:45 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 09 Jul 2004 07:33:45 -0500
Subject: [R] Two additive  effets in random of lme
In-Reply-To: <20040709080443.47613.qmail@web50908.mail.yahoo.com>
References: <20040709080443.47613.qmail@web50908.mail.yahoo.com>
Message-ID: <40EE90A9.7060306@stat.wisc.edu>

Papy Gaston wrote:

> how I can put two additive effects in random of lme ?

It is best to use the version of lme from the lme4 package to do this.

In that version you can use a formula for random like

   random = ~ 1 | rows + columns

The most general form of the random specification is as a named list 
where the names correspond to the grouping factors.

   random = list(rows = ~ time, columns = ~ 1)

This only works in the version of lme from the lme4 package.  It does 
not work in the version from the nlme package.



From meinhardploner at gmx.net  Fri Jul  9 15:02:25 2004
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Fri, 9 Jul 2004 15:02:25 +0200
Subject: [R] packages & data-sets & name spaces
Message-ID: <39770F50-D1A8-11D8-A2BD-0003930EA956@gmx.net>

> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Date: June 17, 2004 12:15:01 PM CEST
> To: Meinhard Ploner <meinhardploner at gmx.net>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] packages & data-sets
>
> On Thu, 17 Jun 2004, Meinhard Ploner wrote:
>
>> It's possible to create a package with functions and data,
>> from which the use
>>
>> library(pkg-name)
>>
>> "attaches" not only the functions, but also the data?
>> I want avoid to use
>>
>> data(dataset, package="name")
>>
>> because this makes a global copy of the data-set ...
>
> What do you mean by `global'?  You cannot have access to R data without
> having it in memory and having it visible.  You don't need to have it 
> in
> the user workspace (.GlobalEnv), though.  Suggestions:
>
> 1) See how MASS does it.  Data objects are loaded into the MASS 
> namespace
> on first use.

After some playing-around I found that I forgot to insert in NAMESPACE
export(package.load.data) which I defined as you in MASS/R 
(MASS.load.data).
Now all works fine and I'm very happy about this solution!

Thanks a lot!
Meinhard Ploner

> 2) See ?attach and attach an R save file containing your datasets --
> wasteful unless you use them all at once.
>
> It is planned that data() will be superseded by a better mechanism in R
> 2.0.0 (but that plan has slipped a bit already, which is why MASS does 
> it
> differently).
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From simon.woodhead at bristol.ac.uk  Fri Jul  9 16:15:41 2004
From: simon.woodhead at bristol.ac.uk (Simon Woodhead)
Date: Fri, 09 Jul 2004 15:15:41 +0100
Subject: [R] Viewport parameters
Message-ID: <40EEA88D.6000301@bristol.ac.uk>

Hello all,

In the Grid addon package from Paul Murrell is there a way of finding 
the parameter settings for the viewport you are in? I understand in 
Lattice there is a function trellis.get.par(), is there something 
similar for Grid?

Cheers
Simon Woodhead



From anne.piotet at urbanet.ch  Fri Jul  9 16:20:16 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Fri, 9 Jul 2004 16:20:16 +0200
Subject: [R] creating plots by batch
Message-ID: <001501c465bf$dbd980c0$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040709/4496e01e/attachment.pl

From rolf at math.unb.ca  Fri Jul  9 16:44:45 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 9 Jul 2004 11:44:45 -0300 (ADT)
Subject: [R] creating plots by batch
Message-ID: <200407091444.i69Eij0K024195@erdos.math.unb.ca>

You wrote:

> Hello RHelpers!
> I'm very ashamed but....
> I'm creating quite a lot of plots in a big loop...each times the
> program ask me :
> > Hit <Return> to see next plot: 
> How do I avoid that?

In the file from which your batch job is running (or perhaps in your
.Rprofile, or somewhere like that) you have set ``par(ask=TRUE)''.
You need set par(ask=FALSE) somehow before running the batch job.

You might possibly want to do something like

	par(ask=interactive())

in the file from which your batch job takes its input.

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From dmurdoch at pair.com  Fri Jul  9 16:50:18 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 09 Jul 2004 10:50:18 -0400
Subject: [R] dyn.load() for windows
In-Reply-To: <20040709102955.36191.qmail@web14807.mail.yahoo.com>
References: <uirse0t597od2p28lkdoticq2ga9652mfa@4ax.com>
	<20040709102955.36191.qmail@web14807.mail.yahoo.com>
Message-ID: <mobte0553ot9dhqj7n8ab31q8dckv53qk4@4ax.com>

On Fri, 9 Jul 2004 03:29:55 -0700 (PDT), Utsav Boobna
<catch_utsav at yahoo.com> wrote :

>Hi 
>I am using Borland C++ compiler 5.5 and R 1.7.1
>
>got the dll using 
>
>c:\> bcc32 -u- -6 -O2 -osample.dll -WDE sample.c

I don't know the bcc32 command line options.  Can you examine the
sample.dll file (using e.g. "tdump sample.dll", if you have tdump, or 
"objdump -x sample.dll" using the objdump tool from our tools
collection), and make sure it really is a DLL file?

Once you work out what is necessary to produce a DLL that works,
please write up a short description and send it to me to include on my
page

http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/

I don't think there's anything there now that would help you, but you
might browse it for inspiration...

Duncan Murdoch

>
>
>Then in R I used
>
>> dyn.load("sample.dll")
>
>Error in dyn.load(x, as.logical(local),
>as.logical(now)) : 
>        unable to load shared library "C:/sample.dll":
>  LoadLibrary failure:  %1 ist keine zul??ssige
>Win32-Anwendung.
>
>(Its in German ... meaning "%1 is not a valid Win32
>application.")
>
>
>
>Thanks,
>Utsav
>
>--- Duncan Murdoch <dmurdoch at pair.com> wrote:
>> On Fri, 9 Jul 2004 01:58:27 -0700 (PDT), Utsav
>> Boobna
>> <catch_utsav at yahoo.com> wrote:
>> 
>> >Hi,
>> >   I compiled several C program files on Borland
>> C++
>> >compiler to get one dll output (as instructed in
>> the
>> >file readme.package). Now when I try to load this
>> >*.dll to R using dyn.load(), then the machine gives
>> >the error message "*.dll is not a valid windows
>> >data,....". The out put of R is 
>> >
>> >I am working on win2k.
>> >What could be the possible reason for that?
>> 
>> Please show us your code and the exact error message
>> (using cut and
>> paste).  It might also help if you gave an exact
>> description of how
>> you produced the DLL (though I'm not familiar with
>> BC++, someone else
>> might be), and gave version numbers of BC++ and R.
>> 
>> Duncan Murdoch
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmb at mrc-dunn.cam.ac.uk  Fri Jul  9 17:37:35 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Fri, 9 Jul 2004 16:37:35 +0100 (BST)
Subject: [R] Simple 'frequency' function?
In-Reply-To: <40EE8D4C.9050706@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.21.0407091637040.7191-100000@mail.mrc-dunn.cam.ac.uk>

On Fri, 9 Jul 2004, Uwe Ligges wrote:

>Dan Bolser wrote:
>
>> Hi, I have designed the following function to extract count frequencies
>> from an array of integers. For example...
>> 
>> # Tipical array
>> x <- cbind(1,1,1,1,1,2,2,2,2,3,3,3,3,4,5,6,7,22)
>> 
>> # Define the frequency function
>> frequency <-
>>   function(x){
>>     max <- max(x)
>>     j <- c()
>>     for(i in 1:max){
>>       j[i] <- length(x[x==i])
>>     }
>>     return(j)
>> }
>> 
>> fre <- frequency(x)
>> plot(fre)
>> 
>> How can I ... 
>> 
>> 1) Make this a general function so my array could be of the form
>> 
>> # eats!
>> x <- cbind( "egg","egg","egg","egg","ham","ham","ham","ham","chicken" )
>> 
>> fre <- frequency(x)
>> plot(fre)
>> 
>> 2) Make frequency return an object which I can call plot on (allowing the
>> prob=TRUE option).
>
>
>See ?table:
>
>   table(x)
>   plot(table(x))
>   plot(table(x) / sum(table(x)))
>

Minter!

Thanks all for replies!

Dan.


>Uwe Ligges
>
>
>
>> Cheers,
>> Dan.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dmb at mrc-dunn.cam.ac.uk  Fri Jul  9 17:43:43 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Fri, 9 Jul 2004 16:43:43 +0100 (BST)
Subject: [R] Simple 'frequency' function?
In-Reply-To: <40EE8D4C.9050706@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.21.0407091642041.7191-100000@mail.mrc-dunn.cam.ac.uk>

On Fri, 9 Jul 2004, Uwe Ligges wrote:

>Dan Bolser wrote:
>
>> Hi, I have designed the following function to extract count frequencies
>> from an array of integers. For example...
>> 
>> # Tipical array
>> x <- cbind(1,1,1,1,1,2,2,2,2,3,3,3,3,4,5,6,7,22)
>> 
>> # Define the frequency function
>> frequency <-
>>   function(x){
>>     max <- max(x)
>>     j <- c()
>>     for(i in 1:max){
>>       j[i] <- length(x[x==i])
>>     }
>>     return(j)
>> }
>> 
>> fre <- frequency(x)
>> plot(fre)
>> 
>> How can I ... 
>> 
>> 1) Make this a general function so my array could be of the form
>> 
>> # eats!
>> x <- cbind( "egg","egg","egg","egg","ham","ham","ham","ham","chicken" )
>> 
>> fre <- frequency(x)
>> plot(fre)
>> 
>> 2) Make frequency return an object which I can call plot on (allowing the
>> prob=TRUE option).
>
>
>See ?table:
>
>   table(x)
>   plot(table(x))
>   plot(table(x) / sum(table(x)))
>

Sorry, why does 

plot(table(x),log='y')

fail?

I am looking at count/frequency distributions which are linear on log/log
scales.





>Uwe Ligges
>
>
>
>> Cheers,
>> Dan.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From MSchwartz at MedAnalytics.com  Fri Jul  9 17:50:35 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 09 Jul 2004 10:50:35 -0500
Subject: [R] Simple 'frequency' function?
In-Reply-To: <Pine.LNX.4.21.0407091642041.7191-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0407091642041.7191-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <1089388235.18501.25.camel@localhost.localdomain>

On Fri, 2004-07-09 at 10:43, Dan Bolser wrote:
> On Fri, 9 Jul 2004, Uwe Ligges wrote:
> 
> >Dan Bolser wrote:
> >
> >> Hi, I have designed the following function to extract count frequencies
> >> from an array of integers. For example...
> >> 
> >> # Tipical array
> >> x <- cbind(1,1,1,1,1,2,2,2,2,3,3,3,3,4,5,6,7,22)
> >> 
> >> # Define the frequency function
> >> frequency <-
> >>   function(x){
> >>     max <- max(x)
> >>     j <- c()
> >>     for(i in 1:max){
> >>       j[i] <- length(x[x==i])
> >>     }
> >>     return(j)
> >> }
> >> 
> >> fre <- frequency(x)
> >> plot(fre)
> >> 
> >> How can I ... 
> >> 
> >> 1) Make this a general function so my array could be of the form
> >> 
> >> # eats!
> >> x <- cbind( "egg","egg","egg","egg","ham","ham","ham","ham","chicken" )
> >> 
> >> fre <- frequency(x)
> >> plot(fre)
> >> 
> >> 2) Make frequency return an object which I can call plot on (allowing the
> >> prob=TRUE option).
> >
> >
> >See ?table:
> >
> >   table(x)
> >   plot(table(x))
> >   plot(table(x) / sum(table(x)))
> >
> 
> Sorry, why does 
> 
> plot(table(x),log='y')
> 
> fail?
> 
> I am looking at count/frequency distributions which are linear on log/log
> scales.


Presumably you are getting the following:

> x <- cbind( "egg","egg","egg","egg","ham",
              "ham","ham","ham","chicken" )
> plot(table(x),log='y')
Error in plot.window(xlim, ylim, log, asp, ...) :
        Infinite axis extents [GEPretty(0,inf,5)]
In addition: Warning message:
Nonfinite axis limits [GScale(-inf,0.60206,2, .); log=1]

The problem here is that the range for the default y axis is being set
to limits that cannot be used on a log scale.

If you review the code for plot.table(), which is the method that will
be used here, you see the function definition as follows:

> graphics:::plot.table
function (x, type = "h", ylim = c(0, max(x)), lwd = 2, xlab = NULL,
    ylab = NULL, frame.plot = is.num, ...)

Note that the default ylim is set to have a min value of 0, which of
course you cannot have on a log scale.

Thus, instead, use the following:

plot(table(x), log = "y", ylim = range(table(x)))

or otherwise explicitly define the y axis range, such that the min value
is >0.

Note also that the default plot type here is 'h', which will result in a
histogram type of plot using vertical lines. If you want a scatterplot
type of graphic, use:

plot(table(x), log = "y", ylim = range(table(x)), type = "p")

HTH,

Marc Schwartz



From Lars.Peters at Uni-Konstanz.de  Fri Jul  9 18:06:49 2004
From: Lars.Peters at Uni-Konstanz.de (Lars Peters)
Date: Fri, 9 Jul 2004 18:06:49 +0200
Subject: [R] Mixed model ANOVA with a nested design
Message-ID: <20040709160707.4702D1F800D@viribus.rz.uni-konstanz.de>

Dear all,

I've got a big problem. I try to analyse my data using R with a mixed model
ANOVA without useful results and success.
My data are as follows:

3 factors (Treatment, Site, Subsite) with 'Subsite' as random factor and
nested into 'Site'.

I want to analyse the effects of the three main effects (factorial design to
a specified degrees (2)) with the interactions between 'Treatment x Site'
and 'Treatment x Subsite' but without 'Site x Subsite'.

I also want to analyse the "magnitude of effects" of all effects

Is anybody out there who could help me with the function and the syntax

Thanks and cheers!

Lars


-----
Lars Peters

University of Konstanz
Limnological Institute
D-78457 Konstanz
Germany

phone: +49 (0)7531 88-2930
fax:   +49 (0)7531 88-3533
e-mail: Lars.Peters at Uni-Konstanz.de
http://www.uni-konstanz.de/sfb454/tp_eng/A1/doc/peters/peters.html
http://www.uni-konstanz.de/sfb454/tp_eng/A1/index.htm



From cpwww at comcast.net  Fri Jul  9 18:05:14 2004
From: cpwww at comcast.net (Coburn Watson)
Date: Fri, 9 Jul 2004 09:05:14 -0700
Subject: [R] Queueing models
Message-ID: <200407090905.14168.cpwww@comcast.net>


Hello R-Help,

Is anyone aware of an R package which which handles queueing models (M/M/1, 
etc)? Basically I was looking for a package which applies Little's law and 
other methods to analysis of continuous state Markov processes (to calculate 
predicted time spent in queue based on workload).  I might be off base on 
this and be looking for something which shouldn't exist within a package like 
R (but just a simple spreadsheet program).  There are such plug-ins for Excel 
(QTP, etc) but I have started using R more significantly at work and was 
looking to see if it had additions in the queueiing arena as well.

Thanks,

Coburn (please remove _nospam from email to reply directly).



From dray at biomserv.univ-lyon1.fr  Fri Jul  9 18:07:36 2004
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Fri, 09 Jul 2004 18:07:36 +0200 (CEST)
Subject: [R] analytic solution for equation
Message-ID: <1089389256.40eec2c89ea90@webmail.univ-lyon1.fr>

Hello,
I have search on R website but do not find any solution.
I would like to know if R has some functionalities to produce analytical results
of equation. or more generally if it contains some functions to simplify equation.

For example:
I would like to obtain x1 from:
x1+x2=8  (x1=8-x2)

x1^2+x2=8 (x1=sqrt(8-x2))



Is is possible in R ? if not, do you know a (free) software that could do the job ?

Thanks in advance !

Stephane DRAY



From ernesto at ipimar.pt  Fri Jul  9 18:41:12 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri, 09 Jul 2004 17:41:12 +0100
Subject: [R] Problem with bwplot
Message-ID: <1089391272.11160.7.camel@gandalf.local>

Hi, 

I'm ploting some box-and-whisker plots with bwplot but I'm not getting
any box-and-whiskers ... just dots.

I'm using lattice 0.9-16 with R 1.9.1.

Try

library(lattice)
rnorm(60)->vec1
rep(1:3,20)->vec2
rep(LETTERS[1:2],30)->vec3
bwplot(vec1~vec2|vec3)

Thanks

EJ



From maustin at amgen.com  Fri Jul  9 18:36:49 2004
From: maustin at amgen.com (Austin, Matt)
Date: Fri, 9 Jul 2004 09:36:49 -0700 
Subject: [R] Problem with bwplot
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F10F9C@teal-exch.amgen.com>

Try factor(vec2) in your bwplot() call.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ernesto Jardim
Sent: Friday, July 09, 2004 9:41 AM
To: Mailing List R
Subject: [R] Problem with bwplot


Hi, 

I'm ploting some box-and-whisker plots with bwplot but I'm not getting
any box-and-whiskers ... just dots.

I'm using lattice 0.9-16 with R 1.9.1.

Try

library(lattice)
rnorm(60)->vec1
rep(1:3,20)->vec2
rep(LETTERS[1:2],30)->vec3
bwplot(vec1~vec2|vec3)

Thanks

EJ

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ccleland at optonline.net  Fri Jul  9 18:42:42 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 09 Jul 2004 12:42:42 -0400
Subject: [R] Problem with bwplot
In-Reply-To: <1089391272.11160.7.camel@gandalf.local>
References: <1089391272.11160.7.camel@gandalf.local>
Message-ID: <40EECB02.7050303@optonline.net>

Do you want this?

bwplot(as.factor(vec2) ~ vec1 | as.factor(vec3))

Ernesto Jardim wrote:
> I'm ploting some box-and-whisker plots with bwplot but I'm not getting
> any box-and-whiskers ... just dots.
> 
> I'm using lattice 0.9-16 with R 1.9.1.
> 
> Try
> 
> library(lattice)
> rnorm(60)->vec1
> rep(1:3,20)->vec2
> rep(LETTERS[1:2],30)->vec3
> bwplot(vec1~vec2|vec3)

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ramasamy at cancer.org.uk  Fri Jul  9 18:44:15 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 09 Jul 2004 17:44:15 +0100
Subject: [R] analytic solution for equation
In-Reply-To: <1089389256.40eec2c89ea90@webmail.univ-lyon1.fr>
References: <1089389256.40eec2c89ea90@webmail.univ-lyon1.fr>
Message-ID: <1089391455.3034.35.camel@vpn202001.lif.icnet.uk>

What would be the purpose of a function/software to rewrite x1 in terms
of x2 ? Perhaps you could explain further how it might be of some use.

There is uniroot(), polyroot(), optimize(), nlm(), solve() and many
others that you want to look into.

On Fri, 2004-07-09 at 17:07, Stephane Dray wrote:
> Hello,
> I have search on R website but do not find any solution.
> I would like to know if R has some functionalities to produce analytical results
> of equation. or more generally if it contains some functions to simplify equation.
> 
> For example:
> I would like to obtain x1 from:
> x1+x2=8  (x1=8-x2)
> 
> x1^2+x2=8 (x1=sqrt(8-x2))
> 
> 
> 
> Is is possible in R ? if not, do you know a (free) software that could do the job ?
> 
> Thanks in advance !
> 
> Stephane DRAY
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From B.Rowlingson at lancaster.ac.uk  Fri Jul  9 18:44:40 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 09 Jul 2004 17:44:40 +0100
Subject: [R] analytic solution for equation
In-Reply-To: <1089389256.40eec2c89ea90@webmail.univ-lyon1.fr>
References: <1089389256.40eec2c89ea90@webmail.univ-lyon1.fr>
Message-ID: <40EECB78.5060109@lancaster.ac.uk>

Stephane Dray wrote:

> For example:
> I would like to obtain x1 from:
> x1+x2=8  (x1=8-x2)
> 
> x1^2+x2=8 (x1=sqrt(8-x2))
> 
> 
> Is is possible in R ? if not, do you know a (free) software that could do the job ?

  You want a computer algebra system. Try 'maxima', free, and from here:

  http://maxima.sourceforge.net/

  Of course its possible to do in R, you'd just have to rewrite most of 
maxima....

Barry



From ernesto at ipimar.pt  Fri Jul  9 19:05:31 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri, 09 Jul 2004 18:05:31 +0100
Subject: [R] Problem with bwplot
In-Reply-To: <E7D5AB4811D20B489622AABA9C53859101F10F9C@teal-exch.amgen.com>
References: <E7D5AB4811D20B489622AABA9C53859101F10F9C@teal-exch.amgen.com>
Message-ID: <1089392731.11162.11.camel@gandalf.local>

Yes,

It works.

Thanks

EJ

PS: It's inconsistent with boxplot, which works without making vec2 a
factor. 


On Fri, 2004-07-09 at 17:36, Austin, Matt wrote:
> Try factor(vec2) in your bwplot() call.
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ernesto Jardim
> Sent: Friday, July 09, 2004 9:41 AM
> To: Mailing List R
> Subject: [R] Problem with bwplot
> 
> 
> Hi, 
> 
> I'm ploting some box-and-whisker plots with bwplot but I'm not getting
> any box-and-whiskers ... just dots.
> 
> I'm using lattice 0.9-16 with R 1.9.1.
> 
> Try
> 
> library(lattice)
> rnorm(60)->vec1
> rep(1:3,20)->vec2
> rep(LETTERS[1:2],30)->vec3
> bwplot(vec1~vec2|vec3)
> 
> Thanks
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From pwilkinson at videotron.ca  Fri Jul  9 18:55:38 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Fri, 09 Jul 2004 12:55:38 -0400
Subject: [R] using R libraries in S
Message-ID: <6.0.3.0.0.20040709125449.01b8dbe0@pop.videotron.ca>

Is it possible to use R libraries in S?

Peter



From msvika at mscc.huji.ac.il  Fri Jul  9 20:15:42 2004
From: msvika at mscc.huji.ac.il (Victoria Landsman)
Date: Fri, 9 Jul 2004 20:15:42 +0200
Subject: [R] Example using Rdqags 
Message-ID: <004301c465e0$bf7df840$8600a8c0@home2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040709/0687bb9b/attachment.pl

From deepayan at stat.wisc.edu  Fri Jul  9 19:15:47 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 9 Jul 2004 12:15:47 -0500
Subject: [R] Problem with bwplot
In-Reply-To: <1089392731.11162.11.camel@gandalf.local>
References: <E7D5AB4811D20B489622AABA9C53859101F10F9C@teal-exch.amgen.com>
	<1089392731.11162.11.camel@gandalf.local>
Message-ID: <200407091215.47711.deepayan@stat.wisc.edu>

On Friday 09 July 2004 12:05, Ernesto Jardim wrote:
> Yes,
>
> It works.
>
> Thanks
>
> EJ
>
> PS: It's inconsistent with boxplot, which works without making vec2 a
> factor.

Yes, and that's a design decision. In particular, it's controlled by the 
horizontal argument in panel.bwplot, which comes into effect when 
neither of the variables are factors (and hence an arbitrary choice has 
to be made).

Deepayan



From andy_liaw at merck.com  Fri Jul  9 19:14:31 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 9 Jul 2004 13:14:31 -0400
Subject: [R] Problem with bwplot
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8003@usrymx25.merck.com>

> From: Ernesto Jardim
> 
> Yes,
> 
> It works.
> 
> Thanks
> 
> EJ
> 
> PS: It's inconsistent with boxplot, which works without making vec2 a
> factor. 

I think the problem is in the flexibility of bwplot.  If `horizontal' is not
set explicitly, it tries to guess by testing whether `y' or `x' is factor.
It probably should throw either an error or at least a warning if not one
and only one of them is factor.

Andy
 
> On Fri, 2004-07-09 at 17:36, Austin, Matt wrote:
> > Try factor(vec2) in your bwplot() call.
> > 
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ernesto Jardim
> > 
> > Hi, 
> > 
> > I'm ploting some box-and-whisker plots with bwplot but I'm 
> not getting
> > any box-and-whiskers ... just dots.
> > 
> > I'm using lattice 0.9-16 with R 1.9.1.
> > 
> > Try
> > 
> > library(lattice)
> > rnorm(60)->vec1
> > rep(1:3,20)->vec2
> > rep(LETTERS[1:2],30)->vec3
> > bwplot(vec1~vec2|vec3)
> > 
> > Thanks
> > 
> > EJ



From andy_liaw at merck.com  Fri Jul  9 19:21:35 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 9 Jul 2004 13:21:35 -0400
Subject: [R] Example using Rdqags
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8004@usrymx25.merck.com>

This is not a direct answer to your question, but if all you want to do is
integrate a function numerically, you don't need to be doing it through R.
You should be able to find codes that you can use directly, such as quadpack
or even GSL.  You may want to search on GAMS (Guide to Available
Mathematical Software, http://gams.nist.gov/).

Andy

> From: Victoria Landsman
> 
> Dear all, 
> I'd like to use the Rmath library for calling R functions in 
> C code. I have no any experience in this. I am trying to read 
> the "Writing  R extensions" manual but with no success. I 
> searched the Web and archives but did not find appropriate 
> example. To be specific, I am looking for an example of the 
> .c file and .R file aimed to compute the integral of f(x)=x^2 
> from 0 to 1 using Rdqags?
> 
> I am running R 1.9.1 on Sun.
> Much thanks for any comments/help. 
> Vicky.



From f.harrell at vanderbilt.edu  Fri Jul  9 20:10:15 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 09 Jul 2004 13:10:15 -0500
Subject: [R] library( ) and verbose=
Message-ID: <40EEDF87.6060602@vanderbilt.edu>

The Hmisc package has in its .First.lib function a verbose argument, 
which I thought was the way to allow users to suppress certain messages, 
by issuing library(Hmisc, verbose=FALSE).  But I see that library( ) 
does not pass verbose to .First.lib.  The default for verbose in Hmisc 
is TRUE because .First.lib prints some important information about 
masked functions.  What is the best way to fix this?  Is it reasonable 
to expect library to pass verbose along?  I'm running R 1.9.
-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ggrothendieck at myway.com  Fri Jul  9 19:54:06 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 9 Jul 2004 17:54:06 +0000 (UTC)
Subject: [R] analytic solution for equation
References: <1089389256.40eec2c89ea90@webmail.univ-lyon1.fr>
Message-ID: <loom.20040709T195215-152@post.gmane.org>

Stephane Dray <dray <at> biomserv.univ-lyon1.fr> writes:
: 
: Hello,
: I have search on R website but do not find any solution.
: I would like to know if R has some functionalities to produce analytical 
results
: of equation. or more generally if it contains some functions to simplify 
equation.
: 
: For example:
: I would like to obtain x1 from:
: x1+x2=8  (x1=8-x2)
: 
: x1^2+x2=8 (x1=sqrt(8-x2))
: 
: Is is possible in R ? if not, do you know a (free) software that could do the 
job ?

I don't think R has this capability built in but you could try a computer
algebra system.  Yacas (http://yacas.sourceforge.net) as well as a number
of others are free.  Here is your calculation in yacas:

C:\yacas>yacas
True;
This is Yacas version '1.0.54'.
Yacas is Free Software--Free as in Freedom--so you can redistribute Yacas or
modify it under certain conditions. Yacas comes with ABSOLUTELY NO WARRANTY.
See the GNU General Public License (GPL) for the full conditions.
See http://yacas.sf.net for more information and documentation on Yacas.

Numeric mode: "Internal"
To exit Yacas, enter  Exit(); or quit or Ctrl-c. Type ?? for help.
Or type ?function for help on a function.
Type 'restart' to restart Yacas.
To see example commands, keep typing Example();
In> Solve(x1+x2==8,x1);
Out> 8-x2;
In> Solve(x1^2+x2==8,x1);
Out> (8-x2)^(1/2);



From Jason.L.Higbee at stls.frb.org  Fri Jul  9 22:05:20 2004
From: Jason.L.Higbee at stls.frb.org (Jason.L.Higbee@stls.frb.org)
Date: Fri, 9 Jul 2004 15:05:20 -0500
Subject: [R] cor.test p-value ties
Message-ID: <20040709200521.91EE61D041@p3fed1.frb.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040709/e87dd67c/attachment.pl

From Soichi.Hayashi at acxiom.com  Fri Jul  9 22:17:08 2004
From: Soichi.Hayashi at acxiom.com (Hayashi Soichi - shayas)
Date: Fri, 9 Jul 2004 15:17:08 -0500
Subject: [R] Can R read data from stdin?
Message-ID: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE5B3@conmsx05.corp.acxiom.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040709/8bd5cc15/attachment.pl

From tplate at blackmesacapital.com  Fri Jul  9 22:34:51 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri, 09 Jul 2004 14:34:51 -0600
Subject: [R] Can R read data from stdin?
In-Reply-To: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE5B3@conmsx05.corp.acx
	iom.net>
References: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE5B3@conmsx05.corp.acxiom.net>
Message-ID: <6.1.0.6.2.20040709142858.05c0ba48@mailhost.blackmesacapital.com>

The easiest way would probably be to do the hack of creating a temporary 
file to hold stdin, then call R to process that file.  That would be easy 
to do in a shell script.

If this really won't suffice, this older message might lead to something 
useful:

>Rd] R scripting patches for R-1.8.0
>Neil McKay mckay at repsac.gmr.com
>Thu Oct 16 20:30:20 MEST 2003
>
>Previous message: [Rd] data() misbehaving inside a function
>Next message: [Rd] R scripting patches for R-1.8.0
>Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]
>
>--------------------------------------------------------------------------------
>
>I've updated my scripting patches to R-1.8.0. These patches
>allow you to write shell scripts in R (at least on *nix systems)
>by putting
>
>#!/path/to/R.bin --script
>
>on the first line of the script file. If you're interested
>in the patches, e-mail me at
>
>         mckay at gmr.com
>
>--
>Neil D. McKay, Mail Code 480-106-359    Phone: (586)986-1470 (GM:8-226-1470)
>Manufacturing Systems Research Lab      FAX:   (586)986-0574 (GM:8-226-0574)
>GM Research & Development Center        Internet e-mail: mckay at gmr.com
>30500 Mound Road
>Warren, Mich. 48090


At Friday 02:17 PM 7/9/2004, Hayashi Soichi - shayas wrote:
>Is there anyway I can write a script which feed input datasource from stdin
>and let R process it (maybe frequency report) then output the report to
>stdout?
>
>
>
>I can't seem to find much info on documentation or FAQ on this topic.
>
>
>
>Thanks!
>
>Soichi Hayashi
>
>
>
>**********************************************************************
>The information contained in this communication is
>confidential, is intended only for the use of the recipient
>named above, and may be legally privileged.
>If the reader of this message is not the intended
>recipient, you are hereby notified that any dissemination,
>distribution, or copying of this communication is strictly
>prohibited.
>If you have received this communication in error,
>please re-send this communication to the sender and
>delete the original message or any copy of it from your
>computer system. Thank You.
>
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From amackey at pcbi.upenn.edu  Fri Jul  9 23:09:32 2004
From: amackey at pcbi.upenn.edu (Aaron J. Mackey)
Date: Fri, 9 Jul 2004 17:09:32 -0400
Subject: [R] Can R read data from stdin?
In-Reply-To: <6.1.0.6.2.20040709142858.05c0ba48@mailhost.blackmesacapital.com>
References: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE5B3@conmsx05.corp.acxiom.net>
	<6.1.0.6.2.20040709142858.05c0ba48@mailhost.blackmesacapital.com>
Message-ID: <461C9AFD-D1EC-11D8-9BB9-000A9577009E@pcbi.upenn.edu>


I think the original poster wanted to read data from stdin, not execute  
an entire script from stdin; this works on many UNIX-like systems:

d <- read.table("/dev/stdin", header=F);

Otherwise, for code, you can simply pipe (or redirect) to R from the  
shell:

% R --vanilla --slave < input > outfile

-Aaron

On Jul 9, 2004, at 4:34 PM, Tony Plate wrote:

> The easiest way would probably be to do the hack of creating a  
> temporary file to hold stdin, then call R to process that file.  That  
> would be easy to do in a shell script.
>
> If this really won't suffice, this older message might lead to  
> something useful:
>
>> Rd] R scripting patches for R-1.8.0
>> Neil McKay mckay at repsac.gmr.com
>> Thu Oct 16 20:30:20 MEST 2003
>>
>> Previous message: [Rd] data() misbehaving inside a function
>> Next message: [Rd] R scripting patches for R-1.8.0
>> Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]
>>
>> ---------------------------------------------------------------------- 
>> ----------
>>
>> I've updated my scripting patches to R-1.8.0. These patches
>> allow you to write shell scripts in R (at least on *nix systems)
>> by putting
>>
>> #!/path/to/R.bin --script
>>
>> on the first line of the script file. If you're interested
>> in the patches, e-mail me at
>>
>>         mckay at gmr.com
>>
>> --
>> Neil D. McKay, Mail Code 480-106-359    Phone: (586)986-1470  
>> (GM:8-226-1470)
>> Manufacturing Systems Research Lab      FAX:   (586)986-0574  
>> (GM:8-226-0574)
>> GM Research & Development Center        Internet e-mail: mckay at  
>> gmr.com
>> 30500 Mound Road
>> Warren, Mich. 48090
>
>
> At Friday 02:17 PM 7/9/2004, Hayashi Soichi - shayas wrote:
>> Is there anyway I can write a script which feed input datasource from  
>> stdin
>> and let R process it (maybe frequency report) then output the report  
>> to
>> stdout?
>>
>>
>>
>> I can't seem to find much info on documentation or FAQ on this topic.
>>
>>
>>
>> Thanks!
>>
>> Soichi Hayashi



From gerifalte28 at hotmail.com  Fri Jul  9 23:09:29 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Fri, 09 Jul 2004 21:09:29 +0000
Subject: [R] Mixed model ANOVA with a nested design
Message-ID: <BAY2-F32XYev6hNo6j30003932f@hotmail.com>

Try the book Mixed-effects model in S and S-PLus by Pinheiro and Bates.  
They have pretty good examples of code and analysis techniques to tackle 
your data.

Francisco


>From: "Lars Peters" <Lars.Peters at Uni-Konstanz.de>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] Mixed model ANOVA with a nested design
>Date: Fri, 9 Jul 2004 18:06:49 +0200
>
>Dear all,
>
>I've got a big problem. I try to analyse my data using R with a mixed model
>ANOVA without useful results and success.
>My data are as follows:
>
>3 factors (Treatment, Site, Subsite) with 'Subsite' as random factor and
>nested into 'Site'.
>
>I want to analyse the effects of the three main effects (factorial design 
>to
>a specified degrees (2)) with the interactions between 'Treatment x Site'
>and 'Treatment x Subsite' but without 'Site x Subsite'.
>
>I also want to analyse the "magnitude of effects" of all effects
>
>Is anybody out there who could help me with the function and the syntax
>
>Thanks and cheers!
>
>Lars
>
>
>-----
>Lars Peters
>
>University of Konstanz
>Limnological Institute
>D-78457 Konstanz
>Germany
>
>phone: +49 (0)7531 88-2930
>fax:   +49 (0)7531 88-3533
>e-mail: Lars.Peters at Uni-Konstanz.de
>http://www.uni-konstanz.de/sfb454/tp_eng/A1/doc/peters/peters.html
>http://www.uni-konstanz.de/sfb454/tp_eng/A1/index.htm
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From Ted.Harding at nessie.mcc.ac.uk  Fri Jul  9 23:25:20 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 09 Jul 2004 22:25:20 +0100 (BST)
Subject: [R] cor.test p-value ties
In-Reply-To: <20040709200521.91EE61D041@p3fed1.frb.org>
Message-ID: <XFMail.040709222520.Ted.Harding@nessie.mcc.ac.uk>

On 09-Jul-04 Jason.L.Higbee at stls.frb.org wrote:
> I got a warning message when running the cor.test function
> using both Spearman and Kendall rank correlations saying that
> the p-value may be incorrect due to ties in the data. My data
> has 35 obs and one series has 6 pairs of ties. Does anyone
> know if this would likely have a great effect on the p-values
> calculated..
> The values look good; tau = -0.68 with p-value = 8e-9 and
> rho = =0.84 with p-value = 8e-8.

With P-values like that, probably not!

However, one can always check it by doing random tie-breaking,
e.g.

  x.1 <- x + 0.001*runif(n)
  y.1 <- y + 0.001*runif(n)

and then repeating the correlation test, where n is the length
of x and y. You can run a simulation loop to get the distribution
of the P-value under random tie-breaking if you like.

The "0.001" could be replaced by something smaller, depending on
the scale of the x and y values (e.g. if all less than 0.01 in
magnitude) -- the important thing is to break the ties without
allowing the perturbed values to step past adjacent values and
upsetting the ordering.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 09-Jul-04                                       Time: 22:25:20
------------------------------ XFMail ------------------------------



From h.wickham at gmail.com  Fri Jul  9 23:29:32 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 10 Jul 2004 09:29:32 +1200
Subject: [R] Viewport parameters
In-Reply-To: <40EEA88D.6000301@bristol.ac.uk>
References: <40EEA88D.6000301@bristol.ac.uk>
Message-ID: <f8e6ff0504070914296483f974@mail.gmail.com>

How about current.viewport()? (str(current.viewport()) to see the data
it contains)

Hadley



From Soichi.Hayashi at acxiom.com  Fri Jul  9 23:41:48 2004
From: Soichi.Hayashi at acxiom.com (Hayashi Soichi - shayas)
Date: Fri, 9 Jul 2004 16:41:48 -0500
Subject: [R] Can R read data from stdin?
Message-ID: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE627@conmsx05.corp.acxiom.net>

Thanks! That's what I was wanted to know.

Also, is there a similar way I can do read.table from a pipe?

For example, if there is a command that I am running to generate the
datasource, I want to read that data as it comes..

Thanks...

-----Original Message-----
From: Aaron J. Mackey [mailto:amackey at pcbi.upenn.edu] 
Sent: Friday, July 09, 2004 4:10 PM
To: Tony Plate
Cc: R-help at stat.math.ethz.ch; Hayashi Soichi - shayas
Subject: Re: [R] Can R read data from stdin?


I think the original poster wanted to read data from stdin, not execute  
an entire script from stdin; this works on many UNIX-like systems:

d <- read.table("/dev/stdin", header=F);

Otherwise, for code, you can simply pipe (or redirect) to R from the  
shell:

% R --vanilla --slave < input > outfile

-Aaron

On Jul 9, 2004, at 4:34 PM, Tony Plate wrote:

> The easiest way would probably be to do the hack of creating a  
> temporary file to hold stdin, then call R to process that file.  That  
> would be easy to do in a shell script.
>
> If this really won't suffice, this older message might lead to  
> something useful:
>
>> Rd] R scripting patches for R-1.8.0
>> Neil McKay mckay at repsac.gmr.com
>> Thu Oct 16 20:30:20 MEST 2003
>>
>> Previous message: [Rd] data() misbehaving inside a function
>> Next message: [Rd] R scripting patches for R-1.8.0
>> Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]
>>
>> ---------------------------------------------------------------------- 
>> ----------
>>
>> I've updated my scripting patches to R-1.8.0. These patches
>> allow you to write shell scripts in R (at least on *nix systems)
>> by putting
>>
>> #!/path/to/R.bin --script
>>
>> on the first line of the script file. If you're interested
>> in the patches, e-mail me at
>>
>>         mckay at gmr.com
>>
>> --
>> Neil D. McKay, Mail Code 480-106-359    Phone: (586)986-1470  
>> (GM:8-226-1470)
>> Manufacturing Systems Research Lab      FAX:   (586)986-0574  
>> (GM:8-226-0574)
>> GM Research & Development Center        Internet e-mail: mckay at  
>> gmr.com
>> 30500 Mound Road
>> Warren, Mich. 48090
>
>
> At Friday 02:17 PM 7/9/2004, Hayashi Soichi - shayas wrote:
>> Is there anyway I can write a script which feed input datasource from  
>> stdin
>> and let R process it (maybe frequency report) then output the report  
>> to
>> stdout?
>>
>>
>>
>> I can't seem to find much info on documentation or FAQ on this topic.
>>
>>
>>
>> Thanks!
>>
>> Soichi Hayashi


**********************************************************************
The information contained in this communication is
confidential, is intended only for the use of the recipient
named above, and may be legally privileged.
If the reader of this message is not the intended
recipient, you are hereby notified that any dissemination, 
distribution, or copying of this communication is strictly
prohibited.
If you have received this communication in error,
please re-send this communication to the sender and
delete the original message or any copy of it from your
computer system. Thank You.



From amackey at pcbi.upenn.edu  Fri Jul  9 23:45:02 2004
From: amackey at pcbi.upenn.edu (Aaron J. Mackey)
Date: Fri, 9 Jul 2004 17:45:02 -0400
Subject: [R] Can R read data from stdin?
In-Reply-To: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE627@conmsx05.corp.acxiom.net>
References: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE627@conmsx05.corp.acxiom.net>
Message-ID: <3BD3DC4B-D1F1-11D8-9BB9-000A9577009E@pcbi.upenn.edu>



On Jul 9, 2004, at 5:41 PM, Hayashi Soichi - shayas wrote:

> Also, is there a similar way I can do read.table from a pipe?

% command | R CMD BATCH --vanilla --slave input.R output

Where input.R is R code that contains a line similar to:

d <- read.table("/dev/stdin")



From dmb at mrc-dunn.cam.ac.uk  Sat Jul 10 01:19:36 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Sat, 10 Jul 2004 00:19:36 +0100 (BST)
Subject: [R] Simple 'frequency' function?
In-Reply-To: <1089388235.18501.25.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.21.0407100006240.7191-100000@mail.mrc-dunn.cam.ac.uk>

On Fri, 9 Jul 2004, Marc Schwartz wrote:

>On Fri, 2004-07-09 at 10:43, Dan Bolser wrote:
>> On Fri, 9 Jul 2004, Uwe Ligges wrote:
>> 
>> >Dan Bolser wrote:
>> >
>> >> Hi, I have designed the following function to extract count frequencies
>> >> from an array of integers. For example...
>> >> 
>> >> # Tipical array
>> >> x <- cbind(1,1,1,1,1,2,2,2,2,3,3,3,3,4,5,6,7,22)
>> >> 
>> >> # Define the frequency function
>> >> frequency <-
>> >>   function(x){
>> >>     max <- max(x)
>> >>     j <- c()
>> >>     for(i in 1:max){
>> >>       j[i] <- length(x[x==i])
>> >>     }
>> >>     return(j)
>> >> }
>> >> 
>> >> fre <- frequency(x)
>> >> plot(fre)
>> >> 
>> >> How can I ... 
>> >> 
>> >> 1) Make this a general function so my array could be of the form
>> >> 
>> >> # eats!
>> >> x <- cbind( "egg","egg","egg","egg","ham","ham","ham","ham","chicken" )
>> >> 
>> >> fre <- frequency(x)
>> >> plot(fre)
>> >> 
>> >> 2) Make frequency return an object which I can call plot on (allowing the
>> >> prob=TRUE option).
>> >
>> >
>> >See ?table:
>> >
>> >   table(x)
>> >   plot(table(x))
>> >   plot(table(x) / sum(table(x)))
>> >
>> 
>> Sorry, why does 
>> 
>> plot(table(x),log='y')
>> 
>> fail?
>> 
>> I am looking at count/frequency distributions which are linear on log/log
>> scales.
>
>
>Presumably you are getting the following:
>
>> x <- cbind( "egg","egg","egg","egg","ham",
>              "ham","ham","ham","chicken" )
>> plot(table(x),log='y')
>Error in plot.window(xlim, ylim, log, asp, ...) :
>        Infinite axis extents [GEPretty(0,inf,5)]
>In addition: Warning message:
>Nonfinite axis limits [GScale(-inf,0.60206,2, .); log=1]
>
>The problem here is that the range for the default y axis is being set
>to limits that cannot be used on a log scale.
>
>If you review the code for plot.table(), which is the method that will
>be used here, you see the function definition as follows:
>
>> graphics:::plot.table
>function (x, type = "h", ylim = c(0, max(x)), lwd = 2, xlab = NULL,
>    ylab = NULL, frame.plot = is.num, ...)
>
>Note that the default ylim is set to have a min value of 0, which of
>course you cannot have on a log scale.
>
>Thus, instead, use the following:
>
>plot(table(x), log = "y", ylim = range(table(x)))
>
>or otherwise explicitly define the y axis range, such that the min value
>is >0.
>
>Note also that the default plot type here is 'h', which will result in a
>histogram type of plot using vertical lines. If you want a scatterplot
>type of graphic, use:
>
>plot(table(x), log = "y", ylim = range(table(x)), type = "p")
>

Thanks for the exceedingly clear answer. In general I have difficulty
inspecting the 'internals' of a function, but you have given me some
clues as how to do this in the future.

Cheers,
Dan.


>HTH,
>
>Marc Schwartz
>
>



From tmchoi at ris.chonnam.ac.kr  Sat Jul 10 02:59:53 2004
From: tmchoi at ris.chonnam.ac.kr (Taemyong Choi)
Date: Sat, 10 Jul 2004 09:59:53 +0900
Subject: [R] k nearest neighbor prediction
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB02BD10A4@GIMLI>
Message-ID: <200407100059.i6A0x4Vt007424@ris.chonnam.ac.kr>

EMV package is a package for k nearest neighbours prediction.
Goodluck ^^

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wayne Jones
Sent: Friday, July 09, 2004 12:07 AM
To: r-help at stat.math.ethz.ch
Subject: [R] k nearest neighbor prediction

Hi there fellow R-users, 

Does anyone know if there is a package for k nearest neighbours prediction
as opposed to classification? I have found the package knncat but can't see
a way to adjust it to predict a continuous variable. 

Any help would be great, 

Regards

Wayne Jones



KSS Ltd
Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS
England
Company Registration Number 2800886
Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
mailto:kssg at kssg.com		http://www.kssg.com


The information in this Internet email is confidential and m...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From lgarcia at Math.Berkeley.EDU  Sat Jul 10 04:04:38 2004
From: lgarcia at Math.Berkeley.EDU (Luis David Garcia)
Date: Fri, 9 Jul 2004 19:04:38 -0700 (PDT)
Subject: [R] Exact Maximum Likelihood Package 
Message-ID: <Pine.LNX.4.44.0407091816190.28941-100000@bluegrass.math.berkeley.edu>


Dear R users,

I am a mathematics postdoc at UC Berkeley. I have written a package
in a Computational Algebra System named Singular

http://www.singular.uni-kl.de

to compute the Maximum Likelihood of a given probability distribution over
several discrete random variables. This package gives exact answers to the
problem. But more importantly, it gives All MLE solutions.

My understanding is that current algorithms (like the one in R) only find
one solution at a time, and there is no way to decide if that local max is
really a global one. That is the power that computer algebra brings to
the table.

I have two goals in mind:

1. I would like to create a link between Singular (or any other CAS)
   and R. The problem of MLE computation is just one instance of the
   benefits that symbolic computations has to offer to statisticians.

For a more detail account of this interaction, you can check the
articles written by Pachter and Sturmfels that will be published in
Science

http://math.berkeley.edu/~lpachter/papers.html

In those articles it is explained how computational algebra can be used to
help in many problems of Computational Biology, like Sequence Analysis.


MY PROBLEM IS THAT I JUST STARTED LEARNING R. I really don't know what to
do to create such a link, and I would be very interested in having some
help/advice on this direction.

2. This is just an example of my ignoRance. I have tried to use R to solve
the following MLE problem. But I cannot figure out how to do it. Your help
would also be appreciated.

Consider the mixture of a pair of four-times repeated Bernoulli trials.
Let s and t be the Bernoulli parameters and p the mixing parameter. There
are  5 possible outcomes

f0 = p*(1-s)^4 + (1-p)*(1-t)^4;
f1 = 4*p*s*(1-s)^3 + 4*(1-p)*t*(1-t)^3;
f2 = 6*p*s^2*(1-s)^2 + 6*(1-p)*t^2*(1-t)^2;
f3 = 4*p*s^3*(1-s) + 4*(1-p)*t^3*(1-t);
f4 = p*s^4 + (1-p)*t^4;

The polynomial f_i represents the probability of seeing i successes.
Suppose we repeat this experiment 1000 times, and u_i is the number of
times we saw i successes.

The likelihood of this event is f_0^u_0*f_1^u_1*f_2^u_2*f_3^u_3*f_4^u_4,
and we seek to find those parameter values for s,t,p which maximize the
likelihood.

My Singular package has as input the 5 polynomials and a data vector u.
For the particular example of u = (3,5,7,11,13). The output are the
following
four roots (p,s,t) and the corresponding Likelihoood value:

(0.99998692268562, 0.666609253585517, 5.056808689815264)

0.118420271386274e-27

(0.0000130773153387599,  5.056808689815264, 0.666609254644253)

0.118420271386274e-27

(0.312819438453599, 0.307857785707541, 0.830004221502637)

0.508592337077813e-25

(0.687180561546401, 0.830004221502637, 0.307857785707541)

0.508592337077813e-25

Can anyone tell me how to do the same thing in R. I tried
using nlm, but the help on this function is not enough for me, and I
cannot get it right.

Thank you very much,

Luis David Garcia



From ggrothendieck at myway.com  Sat Jul 10 08:57:57 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 10 Jul 2004 06:57:57 +0000 (UTC)
Subject: [R] Exact Maximum Likelihood Package
References: <Pine.LNX.4.44.0407091816190.28941-100000@bluegrass.math.berkeley.edu>
Message-ID: <loom.20040710T083834-92@post.gmane.org>


In the example you have below, two of the
solutions should be rejected since the parameters
are outside of the valid range and the remaining
two can be derived from each other due to the
symmetry of the problem so actually you only need
one solution in this case.

At any rate, you can create a coarse grid using
grid.expand and apply the likelihood function using apply
to evaluate your likelihood on each point of the
grid.   Try running optim a few times starting at
each of the top few values found in your grid search.
You will want to give optim derivatives and for this
R has deriv to calculate symbolic derivatives.

See:

?expand.grid
?apply
?deriv
?optim



Luis David Garcia <lgarcia <at> math.berkeley.edu> writes:

: 
: Dear R users,
: 
: I am a mathematics postdoc at UC Berkeley. I have written a package
: in a Computational Algebra System named Singular
: 
: http://www.singular.uni-kl.de
: 
: to compute the Maximum Likelihood of a given probability distribution over
: several discrete random variables. This package gives exact answers to the
: problem. But more importantly, it gives All MLE solutions.
: 
: My understanding is that current algorithms (like the one in R) only find
: one solution at a time, and there is no way to decide if that local max is
: really a global one. That is the power that computer algebra brings to
: the table.
: 
: I have two goals in mind:
: 
: 1. I would like to create a link between Singular (or any other CAS)
:    and R. The problem of MLE computation is just one instance of the
:    benefits that symbolic computations has to offer to statisticians.
: 
: For a more detail account of this interaction, you can check the
: articles written by Pachter and Sturmfels that will be published in
: Science
: 
: http://math.berkeley.edu/~lpachter/papers.html
: 
: In those articles it is explained how computational algebra can be used to
: help in many problems of Computational Biology, like Sequence Analysis.
: 
: MY PROBLEM IS THAT I JUST STARTED LEARNING R. I really don't know what to
: do to create such a link, and I would be very interested in having some
: help/advice on this direction.
: 
: 2. This is just an example of my ignoRance. I have tried to use R to solve
: the following MLE problem. But I cannot figure out how to do it. Your help
: would also be appreciated.
: 
: Consider the mixture of a pair of four-times repeated Bernoulli trials.
: Let s and t be the Bernoulli parameters and p the mixing parameter. There
: are  5 possible outcomes
: 
: f0 = p*(1-s)^4 + (1-p)*(1-t)^4;
: f1 = 4*p*s*(1-s)^3 + 4*(1-p)*t*(1-t)^3;
: f2 = 6*p*s^2*(1-s)^2 + 6*(1-p)*t^2*(1-t)^2;
: f3 = 4*p*s^3*(1-s) + 4*(1-p)*t^3*(1-t);
: f4 = p*s^4 + (1-p)*t^4;
: 
: The polynomial f_i represents the probability of seeing i successes.
: Suppose we repeat this experiment 1000 times, and u_i is the number of
: times we saw i successes.
: 
: The likelihood of this event is f_0^u_0*f_1^u_1*f_2^u_2*f_3^u_3*f_4^u_4,
: and we seek to find those parameter values for s,t,p which maximize the
: likelihood.
: 
: My Singular package has as input the 5 polynomials and a data vector u.
: For the particular example of u = (3,5,7,11,13). The output are the
: following
: four roots (p,s,t) and the corresponding Likelihoood value:
: 
: (0.99998692268562, 0.666609253585517, 5.056808689815264)
: 
: 0.118420271386274e-27
: 
: (0.0000130773153387599,  5.056808689815264, 0.666609254644253)
: 
: 0.118420271386274e-27
: 
: (0.312819438453599, 0.307857785707541, 0.830004221502637)
: 
: 0.508592337077813e-25
: 
: (0.687180561546401, 0.830004221502637, 0.307857785707541)
: 
: 0.508592337077813e-25
: 
: Can anyone tell me how to do the same thing in R. I tried
: using nlm, but the help on this function is not enough for me, and I
: cannot get it right.
: 
: Thank you very much,
: 
: Luis David Garcia



From spencer.graves at pdf.com  Sat Jul 10 16:07:48 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 10 Jul 2004 07:07:48 -0700
Subject: [R] Exact Maximum Likelihood Package
In-Reply-To: <loom.20040710T083834-92@post.gmane.org>
References: <Pine.LNX.4.44.0407091816190.28941-100000@bluegrass.math.berkeley.edu>
	<loom.20040710T083834-92@post.gmane.org>
Message-ID: <40EFF834.4020202@pdf.com>

      Beyond this, I believe it may be possible to write an interface 
between R and Singular;  see "Writing R Extensions", available from 
www.r-project.org -> Documentation:  Manuals or via help.start() from 
within and R session.  There already exists an interface between Excel 
and R;  see www.r-project.org -> CRAN -> (select a local CRAN Mirror, 
e.g., http://cran.stat.ucla.edu/) -> Software:  Other -> R-(D)COM 
Interface. 

      I have not done this, but I suspect it should be possible to 
interface R and Singular, and there my even be folks in your local 
Statistics Department who have done crudely similar things. 

      hope this helps.  spencer graves
p.s.  Gabor  mentioned both "grid.expand" and "expand.grid";  
"expand.grid works, while "grid.expand" seems to be a typo. 

Gabor Grothendieck wrote:

>In the example you have below, two of the
>solutions should be rejected since the parameters
>are outside of the valid range and the remaining
>two can be derived from each other due to the
>symmetry of the problem so actually you only need
>one solution in this case.
>
>At any rate, you can create a coarse grid using
>grid.expand and apply the likelihood function using apply
>to evaluate your likelihood on each point of the
>grid.   Try running optim a few times starting at
>each of the top few values found in your grid search.
>You will want to give optim derivatives and for this
>R has deriv to calculate symbolic derivatives.
>
>See:
>
>?expand.grid
>?apply
>?deriv
>?optim
>
>
>
>Luis David Garcia <lgarcia <at> math.berkeley.edu> writes:
>
>: 
>: Dear R users,
>: 
>: I am a mathematics postdoc at UC Berkeley. I have written a package
>: in a Computational Algebra System named Singular
>: 
>: http://www.singular.uni-kl.de
>: 
>: to compute the Maximum Likelihood of a given probability distribution over
>: several discrete random variables. This package gives exact answers to the
>: problem. But more importantly, it gives All MLE solutions.
>: 
>: My understanding is that current algorithms (like the one in R) only find
>: one solution at a time, and there is no way to decide if that local max is
>: really a global one. That is the power that computer algebra brings to
>: the table.
>: 
>: I have two goals in mind:
>: 
>: 1. I would like to create a link between Singular (or any other CAS)
>:    and R. The problem of MLE computation is just one instance of the
>:    benefits that symbolic computations has to offer to statisticians.
>: 
>: For a more detail account of this interaction, you can check the
>: articles written by Pachter and Sturmfels that will be published in
>: Science
>: 
>: http://math.berkeley.edu/~lpachter/papers.html
>: 
>: In those articles it is explained how computational algebra can be used to
>: help in many problems of Computational Biology, like Sequence Analysis.
>: 
>: MY PROBLEM IS THAT I JUST STARTED LEARNING R. I really don't know what to
>: do to create such a link, and I would be very interested in having some
>: help/advice on this direction.
>: 
>: 2. This is just an example of my ignoRance. I have tried to use R to solve
>: the following MLE problem. But I cannot figure out how to do it. Your help
>: would also be appreciated.
>: 
>: Consider the mixture of a pair of four-times repeated Bernoulli trials.
>: Let s and t be the Bernoulli parameters and p the mixing parameter. There
>: are  5 possible outcomes
>: 
>: f0 = p*(1-s)^4 + (1-p)*(1-t)^4;
>: f1 = 4*p*s*(1-s)^3 + 4*(1-p)*t*(1-t)^3;
>: f2 = 6*p*s^2*(1-s)^2 + 6*(1-p)*t^2*(1-t)^2;
>: f3 = 4*p*s^3*(1-s) + 4*(1-p)*t^3*(1-t);
>: f4 = p*s^4 + (1-p)*t^4;
>: 
>: The polynomial f_i represents the probability of seeing i successes.
>: Suppose we repeat this experiment 1000 times, and u_i is the number of
>: times we saw i successes.
>: 
>: The likelihood of this event is f_0^u_0*f_1^u_1*f_2^u_2*f_3^u_3*f_4^u_4,
>: and we seek to find those parameter values for s,t,p which maximize the
>: likelihood.
>: 
>: My Singular package has as input the 5 polynomials and a data vector u.
>: For the particular example of u = (3,5,7,11,13). The output are the
>: following
>: four roots (p,s,t) and the corresponding Likelihoood value:
>: 
>: (0.99998692268562, 0.666609253585517, 5.056808689815264)
>: 
>: 0.118420271386274e-27
>: 
>: (0.0000130773153387599,  5.056808689815264, 0.666609254644253)
>: 
>: 0.118420271386274e-27
>: 
>: (0.312819438453599, 0.307857785707541, 0.830004221502637)
>: 
>: 0.508592337077813e-25
>: 
>: (0.687180561546401, 0.830004221502637, 0.307857785707541)
>: 
>: 0.508592337077813e-25
>: 
>: Can anyone tell me how to do the same thing in R. I tried
>: using nlm, but the help on this function is not enough for me, and I
>: cannot get it right.
>: 
>: Thank you very much,
>: 
>: Luis David Garcia
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From sdhyok at email.unc.edu  Sun Jul 11 01:44:24 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Sat, 10 Jul 2004 19:44:24 -0400
Subject: [R] where does R search when source()?
Message-ID: <OAEOKPIGCLDDHAEMCAKIOEHGCPAA.sdhyok@email.unc.edu>

Exactly where does R search for foo.R if I type source("foo.R")?
Only from current working directory (same as getwd()), from all directories
specified by e.g. $PATH?  Thanks.

Daehyok Shin



From nov_tao at yahoo.com  Sun Jul 11 02:36:08 2004
From: nov_tao at yahoo.com (Y C Tao)
Date: Sat, 10 Jul 2004 17:36:08 -0700 (PDT)
Subject: [R] Interpreting Results of Bootstrapping
Message-ID: <20040711003608.74177.qmail@web53507.mail.yahoo.com>

I tried to bootstrap the correlation between two
variables x1 and x2. The resulting distribution has
two distinct peaks, how should I interprete it?

The original code is attached.

Y. C. Tao

----------------

library(boot);
 
my.correl<-function(d, i) cor(d[i,1], d[i,2])
 
x1<-c(-2.612,-0.7859,-0.5229,-1.246,1.647,1.647,0.1811,-0.07097,0.8711,0.4323,0.1721,2.143,
4.33,0.5002,0.4015,-0.5225,2.538,0.07959,-0.6645,4.521,-1.371,0.3327,25.24,-0.5417,2.094,0.6064,-0.4476,-0.5891,-0.08879,-0.9487,-2.459e-05,-0.03887,0.2116,-0.0625,1.555,0.2069,-0.2142,-0.807,-0.6499,2.384,-0.02063,1.179,-0.0003586,-1.408,0.6928,0.689,0.1854,0.4351,0.5663,0.07171,-0.07004);
 
x2<-c(0.08742,0.2555,-0.00337,0.03995,-1.208,-1.208,-0.001374,-1.282,1.341,-0.9069,-0.2011,1.557,0.4517,-0.4376,0.4747,0.04965,-0.1668,-0.6811,-0.7011,-1.457,0.04652,-1.117,6.744,-1.332,0.1327,-0.1479,-2.303,0.1235,0.5916,0.05018,-0.7811,0.5869,-0.02608,0.9594,-0.1392,0.4089,0.1468,-1.507,-0.6882,-0.1781,0.5434,-0.4957,0.02557,-1.406,-0.5053,-0.7345,-1.314,0.3178,-0.2108,0.4186,-0.03347);
 
b<-boot(cbind(x1, x2), my.correl, 2000)
hist(b$t, breaks=50)



From spencer.graves at pdf.com  Sun Jul 11 03:13:50 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 10 Jul 2004 18:13:50 -0700
Subject: [R] where does R search when source()?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKIOEHGCPAA.sdhyok@email.unc.edu>
References: <OAEOKPIGCLDDHAEMCAKIOEHGCPAA.sdhyok@email.unc.edu>
Message-ID: <40F0944E.3030702@pdf.com>

  In case no one who knows has time to reply to this, I will report on 
my empirical investigation of this question using R 1.9.1 under Windows 
2000. First, I saved a simple script file "tst-source.R" in the working 
directory, e.g., "d:/sg/proj1". When I said, "source('tst-source.R')", 
it sourced the file appropriately. Then I moved this file to the 
immediate parent, e.g., "d:/sg" and tried the same source command. It 
replied, "Error ... unable to open connection ... ." Then I got a 
command prompt, said, "path", and moved the file into one of the 
directories in the search path. When I repeated the "source" command, it 
was still "unable to open connection ... ."

Conclusion: From this and other experiences, I have found three ways to 
specify file names:

(1) If the complete path and file name are supplied for an existing 
file, 'source' will find it.

(2) If a file is in the working directory, specifying that name will get 
it.

(3) If a file is in a subdirectory of the working directory, e.g., 
"d:/sg/proj1/sub1/tst-source.R", then specifying 
"source('sub1/tst-source.R')" will get it.

hope this helps. spencer graves

Shin, Daehyok wrote:

>Exactly where does R search for foo.R if I type source("foo.R")?
>Only from current working directory (same as getwd()), from all directories
>specified by e.g. $PATH?  Thanks.
>
>Daehyok Shin
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Sun Jul 11 03:36:14 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 10 Jul 2004 21:36:14 -0400
Subject: [R] Interpreting Results of Bootstrapping
Message-ID: <3A822319EB35174CA3714066D590DCD504AF800C@usrymx25.merck.com>

Have you actually look at plot(x1, x2)?  That ought to be quite
enlightening.

You have one data point:

    x1     x2 
25.240  6.744 

that's way out in the upper right.  Every bootstrap sample that include that
point will give an correlation that's high, and every bootstrap sample that
does not include that point will give low (near zero) correlation.  Now, the
probability that one point is included in a bootstrap sample is roughly
63.8%.  You can easily see that:

> mean(b$t>.5)
[1] 0.6385


Andy

> From: Y C Tao
> 
> I tried to bootstrap the correlation between two
> variables x1 and x2. The resulting distribution has
> two distinct peaks, how should I interprete it?
> 
> The original code is attached.
> 
> Y. C. Tao
> 
> ----------------
> 
> library(boot);
>  
> my.correl<-function(d, i) cor(d[i,1], d[i,2])
>  
> x1<-c(-2.612,-0.7859,-0.5229,-1.246,1.647,1.647,0.1811,-0.0709
7,0.8711,0.4323,0.1721,2.143,
> 4.33,0.5002,0.4015,-0.5225,2.538,0.07959,-0.6645,4.521,-1.371,
> 0.3327,25.24,-0.5417,2.094,0.6064,-0.4476,-0.5891,-0.08879,-0.
> 9487,-2.459e-05,-0.03887,0.2116,-0.0625,1.555,0.2069,-0.2142,-
> 0.807,-0.6499,2.384,-0.02063,1.179,-0.0003586,-1.408,0.6928,0.
689,0.1854,0.4351,0.5663,0.07171,-0.07004);
>  
> x2<-c(0.08742,0.2555,-0.00337,0.03995,-1.208,-1.208,-0.001374,
> -1.282,1.341,-0.9069,-0.2011,1.557,0.4517,-0.4376,0.4747,0.049
> 65,-0.1668,-0.6811,-0.7011,-1.457,0.04652,-1.117,6.744,-1.332,
> 0.1327,-0.1479,-2.303,0.1235,0.5916,0.05018,-0.7811,0.5869,-0.
> 02608,0.9594,-0.1392,0.4089,0.1468,-1.507,-0.6882,-0.1781,0.54
> 34,-0.4957,0.02557,-1.406,-0.5053,-0.7345,-1.314,0.3178,-0.210
> 8,0.4186,-0.03347);
>  
> b<-boot(cbind(x1, x2), my.correl, 2000)
> hist(b$t, breaks=50)
>



From andy_liaw at merck.com  Sun Jul 11 03:41:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 10 Jul 2004 21:41:36 -0400
Subject: [R] where does R search when source()?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF800D@usrymx25.merck.com>

> From: Shin, Daehyok
> 
> Exactly where does R search for foo.R if I type source("foo.R")?
> Only from current working directory (same as getwd()), from 
> all directories
> specified by e.g. $PATH?  Thanks.
> 
> Daehyok Shin

The former.  No documentation says otherwise, so why would you think that it
might search somewhere else?

Andy



From MSchwartz at MedAnalytics.com  Sun Jul 11 03:48:30 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat, 10 Jul 2004 20:48:30 -0500
Subject: [R] where does R search when source()?
In-Reply-To: <40F0944E.3030702@pdf.com>
References: <OAEOKPIGCLDDHAEMCAKIOEHGCPAA.sdhyok@email.unc.edu>
	<40F0944E.3030702@pdf.com>
Message-ID: <1089510509.6078.18.camel@localhost.localdomain>

On Sat, 2004-07-10 at 20:13, Spencer Graves wrote:
>   In case no one who knows has time to reply to this, I will report on 
> my empirical investigation of this question using R 1.9.1 under Windows 
> 2000. First, I saved a simple script file "tst-source.R" in the working 
> directory, e.g., "d:/sg/proj1". When I said, "source('tst-source.R')", 
> it sourced the file appropriately. Then I moved this file to the 
> immediate parent, e.g., "d:/sg" and tried the same source command. It 
> replied, "Error ... unable to open connection ... ." Then I got a 
> command prompt, said, "path", and moved the file into one of the 
> directories in the search path. When I repeated the "source" command, it 
> was still "unable to open connection ... ."
> 
> Conclusion: From this and other experiences, I have found three ways to 
> specify file names:
> 
> (1) If the complete path and file name are supplied for an existing 
> file, 'source' will find it.
> 
> (2) If a file is in the working directory, specifying that name will get 
> it.
> 
> (3) If a file is in a subdirectory of the working directory, e.g., 
> "d:/sg/proj1/sub1/tst-source.R", then specifying 
> "source('sub1/tst-source.R')" will get it.
> 
> hope this helps. spencer graves
> 
> Shin, Daehyok wrote:
> 
> >Exactly where does R search for foo.R if I type source(`foo.R')?
> >Only from current working directory (same as getwd()), from all directories
> >specified by e.g. $PATH?  Thanks.
> >
> >Daehyok Shin


The relevant code snippet from source() is:

    Ne <- length(exprs <- parse(n = -1, file = file))

Note that the argument 'file' from the initial call to source() is used
'as is' in the 'file = file' argument to parse(). There is no searching
of the $PATH.

Thus, the file will be used based upon either the filename itself or a
proper absolute or relative path as Spencer notes above. If the filename
only is used, it needs to be in the current working directory or you get
the error that Spencer experienced.

HTH,

Marc Schwartz



From sdhyok at email.unc.edu  Sun Jul 11 04:00:32 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Sat, 10 Jul 2004 22:00:32 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF800D@usrymx25.merck.com>
Message-ID: <OAEOKPIGCLDDHAEMCAKIKEHICPAA.sdhyok@email.unc.edu>

The reason I asked is to separate script files from data files.
Usually, I am working in the directory containing data files, but some
script files are in other shared directories. In the case, is there any way
to access the script files conveniently without specifying its absolute
path? In other word, any way to set up default search paths for script
files?

Daehyok Shin (Peter)

>
> The former.  No documentation says otherwise, so why would you
> think that it
> might search somewhere else?
>
> Andy
>
>
> ------------------------------------------------------------------
> ------------
> Notice:  This e-mail message, together with any attachments,
> contains information of Merck & Co., Inc. (One Merck Drive,
> Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
> (which may be known outside the United States as Merck Frosst,
> Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
> confidential, proprietary copyrighted and/or legally privileged.
> It is intended solely for the use of the individual or entity
> named on this message.  If you are not the intended recipient,
> and have received this message in error, please notify us
> immediately by reply e-mail and then delete it from your system.
> ------------------------------------------------------------------
> ------------
>



From andy_liaw at merck.com  Sun Jul 11 04:07:05 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 10 Jul 2004 22:07:05 -0400
Subject: [R] where does R search when source()?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF800F@usrymx25.merck.com>

Not really.  The best I can come up with is something like:

runScript <- function(script, dir="", ...) source(file.path(dir, script,
...) 
scriptdir <- "/path/to/scripts"

runScript(scriptdir, "myScript.R")

Andy

> From: Shin, Daehyok
> 
> The reason I asked is to separate script files from data files.
> Usually, I am working in the directory containing data files, but some
> script files are in other shared directories. In the case, is 
> there any way
> to access the script files conveniently without specifying 
> its absolute
> path? In other word, any way to set up default search paths for script
> files?
> 
> Daehyok Shin (Peter)
> 
> >
> > The former.  No documentation says otherwise, so why would you
> > think that it
> > might search somewhere else?
> >
> > Andy
> >
> >
> > ------------------------------------------------------------------
> > ------------
> > Notice:  This e-mail message, together with any attachments,
> > contains information of Merck & Co., Inc. (One Merck Drive,
> > Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
> > (which may be known outside the United States as Merck Frosst,
> > Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
> > confidential, proprietary copyrighted and/or legally privileged.
> > It is intended solely for the use of the individual or entity
> > named on this message.  If you are not the intended recipient,
> > and have received this message in error, please notify us
> > immediately by reply e-mail and then delete it from your system.
> > ------------------------------------------------------------------
> > ------------
> >
> 
> 
>



From sdhyok at email.unc.edu  Sun Jul 11 04:40:27 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Sat, 10 Jul 2004 22:40:27 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF800F@usrymx25.merck.com>
Message-ID: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>

To my knowledge, it is a common practice for users to archive some script
files in other directories than current working directory, when the script
files are frequently used in many cases. So, it is somewhat surprising to me
there is no elegant solution to set up default search paths in R.

Here is my suggestion.
According to the setup of Python (http://docs.python.org/tut/node8.html),
when source() is called,

1. Search current working directory.
2. If not found, search the directories specified by the environment
variable RPATH.

I think this change will help users to manage script files more easily. What
do you think of it?

Daehyok Shin

> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: Saturday, July 10, 2004 PM 10:07
> To: 'sdhyok at email.unc.edu'; R, Help
> Subject: RE: [R] where does R search when source()?
>
>
> Not really.  The best I can come up with is something like:
>
> runScript <- function(script, dir="", ...) source(file.path(dir, script,
> ...)
> scriptdir <- "/path/to/scripts"
>
> runScript(scriptdir, "myScript.R")
>
> Andy
>
> > From: Shin, Daehyok
> >
> > The reason I asked is to separate script files from data files.
> > Usually, I am working in the directory containing data files, but some
> > script files are in other shared directories. In the case, is
> > there any way
> > to access the script files conveniently without specifying
> > its absolute
> > path? In other word, any way to set up default search paths for script
> > files?
> >
> > Daehyok Shin (Peter)
> >
> > >
> > > The former.  No documentation says otherwise, so why would you
> > > think that it
> > > might search somewhere else?
> > >
> > > Andy
> > >
> > >
> > > ------------------------------------------------------------------
> > > ------------
> > > Notice:  This e-mail message, together with any attachments,
> > > contains information of Merck & Co., Inc. (One Merck Drive,
> > > Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
> > > (which may be known outside the United States as Merck Frosst,
> > > Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
> > > confidential, proprietary copyrighted and/or legally privileged.
> > > It is intended solely for the use of the individual or entity
> > > named on this message.  If you are not the intended recipient,
> > > and have received this message in error, please notify us
> > > immediately by reply e-mail and then delete it from your system.
> > > ------------------------------------------------------------------
> > > ------------
> > >
> >
> >
> >
>
>
> ------------------------------------------------------------------
> ------------
> Notice:  This e-mail message, together with any attachments,
> contains information of Merck & Co., Inc. (One Merck Drive,
> Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
> (which may be known outside the United States as Merck Frosst,
> Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
> confidential, proprietary copyrighted and/or legally privileged.
> It is intended solely for the use of the individual or entity
> named on this message.  If you are not the intended recipient,
> and have received this message in error, please notify us
> immediately by reply e-mail and then delete it from your system.
> ------------------------------------------------------------------
> ------------
>



From edd at debian.org  Sun Jul 11 04:47:27 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 10 Jul 2004 21:47:27 -0500
Subject: [R] where does R search when source()?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
References: <3A822319EB35174CA3714066D590DCD504AF800F@usrymx25.merck.com>
	<OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
Message-ID: <20040711024727.GA24761@sonny.eddelbuettel.com>

On Sat, Jul 10, 2004 at 10:40:27PM -0400, Shin, Daehyok wrote:
> To my knowledge, it is a common practice for users to archive some script
> files in other directories than current working directory, when the script
> files are frequently used in many cases. So, it is somewhat surprising to me
> there is no elegant solution to set up default search paths in R.
> 
> Here is my suggestion.
> According to the setup of Python (http://docs.python.org/tut/node8.html),
> when source() is called,
> 
> 1. Search current working directory.
> 2. If not found, search the directories specified by the environment
> variable RPATH.
> 
> I think this change will help users to manage script files more easily. What
> do you think of it?

With all due respect, I think you really want to learn how packages work in
R, and how you can create them.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From dmurdoch at pair.com  Sun Jul 11 04:53:36 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 10 Jul 2004 22:53:36 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
References: <3A822319EB35174CA3714066D590DCD504AF800F@usrymx25.merck.com>
	<OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
Message-ID: <ioa1f01kg3l6noj5hti5avejm5hme3s0qr@4ax.com>

On Sat, 10 Jul 2004 22:40:27 -0400, "Shin, Daehyok"
<sdhyok at email.unc.edu> wrote:

>To my knowledge, it is a common practice for users to archive some script
>files in other directories than current working directory, when the script
>files are frequently used in many cases. So, it is somewhat surprising to me
>there is no elegant solution to set up default search paths in R.

The normal way to do this in R is to put your commonly used scripts
into functions.  You can put the functions into packages if you want
to group them together, then attach the package to load a group all at
once.

Duncan Murdoch



From rpeng at jhsph.edu  Sun Jul 11 05:14:06 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat, 10 Jul 2004 23:14:06 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
Message-ID: <40F0B07E.5060105@jhsph.edu>

In fact, there is an elegant solution, and that is to write a 
package.  If this is all for personal use, then writing a package 
can be as simple as creating a few directories, copying the 
script files, and then running R CMD INSTALL.  I do this all the 
time when I have multiple projects that use the same code.

-roger

Shin, Daehyok wrote:
> To my knowledge, it is a common practice for users to archive some script
> files in other directories than current working directory, when the script
> files are frequently used in many cases. So, it is somewhat surprising to me
> there is no elegant solution to set up default search paths in R.
> 
> Here is my suggestion.
> According to the setup of Python (http://docs.python.org/tut/node8.html),
> when source() is called,
> 
> 1. Search current working directory.
> 2. If not found, search the directories specified by the environment
> variable RPATH.
> 
> I think this change will help users to manage script files more easily. What
> do you think of it?
> 
> Daehyok Shin
> 
> 
>>-----Original Message-----
>>From: Liaw, Andy [mailto:andy_liaw at merck.com]
>>Sent: Saturday, July 10, 2004 PM 10:07
>>To: 'sdhyok at email.unc.edu'; R, Help
>>Subject: RE: [R] where does R search when source()?
>>
>>
>>Not really.  The best I can come up with is something like:
>>
>>runScript <- function(script, dir="", ...) source(file.path(dir, script,
>>...)
>>scriptdir <- "/path/to/scripts"
>>
>>runScript(scriptdir, "myScript.R")
>>
>>Andy
>>
>>
>>>From: Shin, Daehyok
>>>
>>>The reason I asked is to separate script files from data files.
>>>Usually, I am working in the directory containing data files, but some
>>>script files are in other shared directories. In the case, is
>>>there any way
>>>to access the script files conveniently without specifying
>>>its absolute
>>>path? In other word, any way to set up default search paths for script
>>>files?
>>>
>>>Daehyok Shin (Peter)
>>>
>>>
>>>>The former.  No documentation says otherwise, so why would you
>>>>think that it
>>>>might search somewhere else?
>>>>
>>>>Andy
>>>>
>>>>
>>>>------------------------------------------------------------------
>>>>------------
>>>>Notice:  This e-mail message, together with any attachments,
>>>>contains information of Merck & Co., Inc. (One Merck Drive,
>>>>Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
>>>>(which may be known outside the United States as Merck Frosst,
>>>>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
>>>>confidential, proprietary copyrighted and/or legally privileged.
>>>>It is intended solely for the use of the individual or entity
>>>>named on this message.  If you are not the intended recipient,
>>>>and have received this message in error, please notify us
>>>>immediately by reply e-mail and then delete it from your system.
>>>>------------------------------------------------------------------
>>>>------------
>>>>
>>>
>>>
>>>
>>
>>------------------------------------------------------------------
>>------------
>>Notice:  This e-mail message, together with any attachments,
>>contains information of Merck & Co., Inc. (One Merck Drive,
>>Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
>>(which may be known outside the United States as Merck Frosst,
>>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
>>confidential, proprietary copyrighted and/or legally privileged.
>>It is intended solely for the use of the individual or entity
>>named on this message.  If you are not the intended recipient,
>>and have received this message in error, please notify us
>>immediately by reply e-mail and then delete it from your system.
>>------------------------------------------------------------------
>>------------
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sdhyok at email.unc.edu  Sun Jul 11 05:28:39 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Sat, 10 Jul 2004 23:28:39 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <40F0B07E.5060105@jhsph.edu>
Message-ID: <OAEOKPIGCLDDHAEMCAKIEEHKCPAA.sdhyok@email.unc.edu>

Considering replies to my question, typical practices of R users seem:
1. Creating a special function to source frequently used scripts.
2. Creating a personal package containing frequently used scripts.

Both of them needs additional steps to edit the function or to
create/install the package
when a script file is edited or added. My suggestion can save the effort.
In the sense to make R more convenient environment to users, is it trivial?

Daehyok Shin

> -----Original Message-----
> From: Roger D. Peng [mailto:rpeng at jhsph.edu]
> Sent: Saturday, July 10, 2004 PM 11:14
> To: sdhyok at email.unc.edu
> Cc: Liaw, Andy; R, Help
> Subject: Re: [R] where does R search when source()?
>
>
> In fact, there is an elegant solution, and that is to write a
> package.  If this is all for personal use, then writing a package
> can be as simple as creating a few directories, copying the
> script files, and then running R CMD INSTALL.  I do this all the
> time when I have multiple projects that use the same code.
>
> -roger
>



From tlumley at u.washington.edu  Sun Jul 11 05:38:00 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 10 Jul 2004 20:38:00 -0700 (PDT)
Subject: [R] newsletter
Message-ID: <Pine.LNX.4.43.0407102038000.6216@hymn14.u.washington.edu>


The new issue of the R Newsletter (1/2004) is out on http://www.r-project.org/

         -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From ggrothendieck at myway.com  Sun Jul 11 06:53:34 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 11 Jul 2004 04:53:34 +0000 (UTC)
Subject: [R] where does R search when source()?
References: <40F0B07E.5060105@jhsph.edu>
	<OAEOKPIGCLDDHAEMCAKIEEHKCPAA.sdhyok@email.unc.edu>
Message-ID: <loom.20040711T064955-525@post.gmane.org>


How about this:


search.path <- function(fn, 
                        paths = strsplit(Sys.getenv("PATH"), split = ";")[[1]],
			fsep = "\\") {
	for(d in paths) {
		f <- file.path(d, fn, fsep = fsep)
		if (file.exists(f)) return(f)
	}
	return(NULL)
}

source(search.path("myscript.R"))





Shin, Daehyok <sdhyok <at> email.unc.edu> writes:

: 
: Considering replies to my question, typical practices of R users seem:
: 1. Creating a special function to source frequently used scripts.
: 2. Creating a personal package containing frequently used scripts.
: 
: Both of them needs additional steps to edit the function or to
: create/install the package
: when a script file is edited or added. My suggestion can save the effort.
: In the sense to make R more convenient environment to users, is it trivial?
: 
: Daehyok Shin
: 
: > -----Original Message-----
: > From: Roger D. Peng [mailto:rpeng <at> jhsph.edu]
: > Sent: Saturday, July 10, 2004 PM 11:14
: > To: sdhyok <at> email.unc.edu
: > Cc: Liaw, Andy; R, Help
: > Subject: Re: [R] where does R search when source()?
: >
: >
: > In fact, there is an elegant solution, and that is to write a
: > package.  If this is all for personal use, then writing a package
: > can be as simple as creating a few directories, copying the
: > script files, and then running R CMD INSTALL.  I do this all the
: > time when I have multiple projects that use the same code.
: >
: > -roger
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From ggrothendieck at myway.com  Sun Jul 11 07:40:33 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 11 Jul 2004 05:40:33 +0000 (UTC)
Subject: [R] Creating a minimal package (was: where does R search when
	source()?)
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
	<40F0B07E.5060105@jhsph.edu>
Message-ID: <loom.20040711T073351-641@post.gmane.org>

Roger,

A list of the steps referred to below would be of interest.
I realize the extensions manual exists but what I was
thinking of was just a list of the minimal steps you take
when you create a package for yourself.

Thanks.


Roger D. Peng <rpeng <at> jhsph.edu> writes:

: 
: In fact, there is an elegant solution, and that is to write a 
: package.  If this is all for personal use, then writing a package 
: can be as simple as creating a few directories, copying the 
: script files, and then running R CMD INSTALL.  I do this all the 
: time when I have multiple projects that use the same code.
: 
: -roger
: 
: Shin, Daehyok wrote:
: > To my knowledge, it is a common practice for users to archive some script
: > files in other directories than current working directory, when the script
: > files are frequently used in many cases. So, it is somewhat surprising to 
me
: > there is no elegant solution to set up default search paths in R.
: > 
: > Here is my suggestion.
: > According to the setup of Python (http://docs.python.org/tut/node8.html),
: > when source() is called,
: > 
: > 1. Search current working directory.
: > 2. If not found, search the directories specified by the environment
: > variable RPATH.
: > 
: > I think this change will help users to manage script files more easily. 
What
: > do you think of it?
: > 
: > Daehyok Shin
: > 
: > 
: >>-----Original Message-----
: >>From: Liaw, Andy [mailto:andy_liaw <at> merck.com]
: >>Sent: Saturday, July 10, 2004 PM 10:07
: >>To: 'sdhyok <at> email.unc.edu'; R, Help
: >>Subject: RE: [R] where does R search when source()?
: >>
: >>
: >>Not really.  The best I can come up with is something like:
: >>
: >>runScript <- function(script, dir="", ...) source(file.path(dir, script,
: >>...)
: >>scriptdir <- "/path/to/scripts"
: >>
: >>runScript(scriptdir, "myScript.R")
: >>
: >>Andy
: >>
: >>
: >>>From: Shin, Daehyok
: >>>
: >>>The reason I asked is to separate script files from data files.
: >>>Usually, I am working in the directory containing data files, but some
: >>>script files are in other shared directories. In the case, is
: >>>there any way
: >>>to access the script files conveniently without specifying
: >>>its absolute
: >>>path? In other word, any way to set up default search paths for script
: >>>files?
: >>>
: >>>Daehyok Shin (Peter)
: >>>
: >>>
: >>>>The former.  No documentation says otherwise, so why would you
: >>>>think that it
: >>>>might search somewhere else?
: >>>>
: >>>>Andy
: >>>>
: >>>>
: >>>>------------------------------------------------------------------
: >>>>------------
: >>>>Notice:  This e-mail message, together with any attachments,
: >>>>contains information of Merck & Co., Inc. (One Merck Drive,
: >>>>Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
: >>>>(which may be known outside the United States as Merck Frosst,
: >>>>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
: >>>>confidential, proprietary copyrighted and/or legally privileged.
: >>>>It is intended solely for the use of the individual or entity
: >>>>named on this message.  If you are not the intended recipient,
: >>>>and have received this message in error, please notify us
: >>>>immediately by reply e-mail and then delete it from your system.
: >>>>------------------------------------------------------------------
: >>>>------------
: >>>>
: >>>
: >>>
: >>>
: >>
: >>------------------------------------------------------------------
: >>------------
: >>Notice:  This e-mail message, together with any attachments,
: >>contains information of Merck & Co., Inc. (One Merck Drive,
: >>Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
: >>(which may be known outside the United States as Merck Frosst,
: >>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
: >>confidential, proprietary copyrighted and/or legally privileged.
: >>It is intended solely for the use of the individual or entity
: >>named on this message.  If you are not the intended recipient,
: >>and have received this message in error, please notify us
: >>immediately by reply e-mail and then delete it from your system.
: >>------------------------------------------------------------------
: >>------------
: >>
: > 
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! http://www.R-project.org/posting-
guide.html
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From wang at galton.uchicago.edu  Sun Jul 11 07:42:20 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sun, 11 Jul 2004 00:42:20 -0500 (CDT)
Subject: [R] your reference on this problem  highly appreciated
In-Reply-To: <200407101006.i6AA4HfS008298@hypatia.math.ethz.ch>
References: <200407101006.i6AA4HfS008298@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0407110040410.2040@aitken.uchicago.edu>

please help me on this
----- Message Text -----
Dear all R users
first, sorry for that this question might not be appropriate to ask here.
                                                                                
I wanna know theories or techinques aimed at following questions:
                                                                                
I have a sample, say,K(at the range from 0 to 20000); the sample data's
central  moments m(1)---m(j) are estimated(j can be large).
also, I can use some methodology to calculate the upper and lower bound of
the probabilty of any interested interval, say, for the interval  
(400--800)
                                                                                
with all these information, I wanna recover the distribution of the data,
at least recover to some approximating  analytic form.Does anybady know
such theory or techiniques?
                                                                                
your help will be highly appreciated.
best regards
yong



From renaud.lancelot at cirad.fr  Sun Jul 11 09:13:52 2004
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Sun, 11 Jul 2004 10:13:52 +0300
Subject: [R] where does R search when source()?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKIEEHKCPAA.sdhyok@email.unc.edu>
References: <OAEOKPIGCLDDHAEMCAKIEEHKCPAA.sdhyok@email.unc.edu>
Message-ID: <40F0E8B0.3060804@cirad.fr>

I do agree with you: in my opinion, creating a package is not a general 
solution when you just want to save the script of a whole data analysis 
for the purpose of, say, a paper or a report.

To meet this goal, I save the script in a text file and I use a text 
editor with sourcing facilities (e.g. WinEdt + R-WinEdt, Xemacs + 
ESS,...: see Software ==> Other section on CRAN).

See recent threads on this topic, e.g. 
http://tolstoy.newcastle.edu.au/R/help/04/07/0195.html

Best,

Renaud

Shin, Daehyok wrote:
> Considering replies to my question, typical practices of R users seem:
> 1. Creating a special function to source frequently used scripts.
> 2. Creating a personal package containing frequently used scripts.
> 
> Both of them needs additional steps to edit the function or to
> create/install the package
> when a script file is edited or added. My suggestion can save the effort.
> In the sense to make R more convenient environment to users, is it trivial?
> 
> Daehyok Shin
> 
> 
>>-----Original Message-----
>>From: Roger D. Peng [mailto:rpeng at jhsph.edu]
>>Sent: Saturday, July 10, 2004 PM 11:14
>>To: sdhyok at email.unc.edu
>>Cc: Liaw, Andy; R, Help
>>Subject: Re: [R] where does R search when source()?
>>
>>
>>In fact, there is an elegant solution, and that is to write a
>>package.  If this is all for personal use, then writing a package
>>can be as simple as creating a few directories, copying the
>>script files, and then running R CMD INSTALL.  I do this all the
>>time when I have multiple projects that use the same code.
>>
>>-roger
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Dr Renaud Lancelot, v??t??rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 04 824 55 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From Ted.Harding at nessie.mcc.ac.uk  Sun Jul 11 11:40:34 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 11 Jul 2004 10:40:34 +0100 (BST)
Subject: [R] Interpreting Results of Bootstrapping
In-Reply-To: <20040711003608.74177.qmail@web53507.mail.yahoo.com>
Message-ID: <XFMail.040711104034.Ted.Harding@nessie.mcc.ac.uk>

Hi!

Simply plot(x1,x2): you will see that there is one point
(number 23) at (x1,x2) = (25.34,6.744) which is a very
long way from all the other points (which, among themselves,
form a somewhat diffuse cluster with some suggestion of
further structure).

When you bootstrap, the correlation you obtain in any sample
will depend on whether or not this outlying point is included
in the sample. If it is included, this single point will generate
a relatively high value of the correlation coefficient simply
because it is such a long way from all the others (i.e. it is
highly influential).

If it is not included, then the diffuse character of the other
points will generate a very low value of the correlation
coefficient.

  > cor(x1,x2)
  [1] 0.7471931
  > cor(x1[-23],x2[-23])
  [1] 0.03914653

Therefore your bootstrap distribution will have two peaks: one
peak, around 0.75, corresponding to the bootstrap samples which
include this outlying point, and the other, around 0, corresponding
to the bootstrap samples which do not include it.

This is the explanation and, at the same time, the interpretation.

Best wishes,
Ted.

On 11-Jul-04 Y C Tao wrote:
> I tried to bootstrap the correlation between two
> variables x1 and x2. The resulting distribution has
> two distinct peaks, how should I interprete it?
> 
> The original code is attached.
> 
> Y. C. Tao
> 
> ----------------
> 
> library(boot);
>  
> my.correl<-function(d, i) cor(d[i,1], d[i,2])
>  
> x1<-c(-2.612,-0.7859,-0.5229,-1.246,1.647,1.647,0.1811,
>       -0.07097,0.8711,0.4323,0.1721,2.143,4.33,0.5002,
>        0.4015,-0.5225,2.538,0.07959,-0.6645,4.521,-1.371,
>        0.3327,25.24,-0.5417,2.094,0.6064,-0.4476,-0.5891,
>       -0.08879,-0.9487,-2.459e-05,-0.03887,0.2116,-0.0625,1.555,
>        0.2069,-0.2142,-0.807,-0.6499,2.384,-0.02063,1.179,
>       -0.0003586,-1.408,0.6928,0.689,0.1854,0.4351,0.5663,
>        0.07171,-0.07004);
>  
> x2<-c( 0.08742,0.2555,-0.00337,0.03995,-1.208,-1.208,-0.001374,
>       -1.282,1.341,-0.9069,-0.2011,1.557,0.4517,-0.4376,
>        0.4747,0.04965,-0.1668,-0.6811,-0.7011,-1.457,0.04652,
>       -1.117,6.744,-1.332,0.1327,-0.1479,-2.303,0.1235,      
>        0.5916,0.05018,-0.7811,0.5869,-0.02608,0.9594,-0.1392,
>        0.4089,0.1468,-1.507,-0.6882,-0.1781,0.5434,-0.4957,
>        0.02557,-1.406,-0.5053,-0.7345,-1.314,0.3178,-0.2108,
>        0.4186,-0.03347);
>  
> b<-boot(cbind(x1, x2), my.correl, 2000)
> hist(b$t, breaks=50)

[The above rearranged to have 7 values in each conplete line]



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 11-Jul-04                                       Time: 10:40:34
------------------------------ XFMail ------------------------------



From wegmann_mailinglist at gmx.net  Sun Jul 11 13:10:36 2004
From: wegmann_mailinglist at gmx.net (Martin Wegmann)
Date: Sun, 11 Jul 2004 13:10:36 +0200
Subject: [R] Fwd: newsletter
Message-ID: <200407111310.36708.wegmann_mailinglist@gmx.net>



----------  Forwarded Message  ----------

Subject: newsletter
Date: Sunday 11 July 2004 05:38
From: Thomas Lumley <tlumley at u.washington.edu>
To: r-announce at r-project.org

The new issue of the R Newsletter (1/2004) is out on
 http://www.r-project.org/

         -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From wegmann_mailinglist at gmx.net  Sun Jul 11 13:16:52 2004
From: wegmann_mailinglist at gmx.net (Martin Wegmann)
Date: Sun, 11 Jul 2004 13:16:52 +0200
Subject: [R] Fwd: newsletter
In-Reply-To: <200407111310.36708.wegmann_mailinglist@gmx.net>
References: <200407111310.36708.wegmann_mailinglist@gmx.net>
Message-ID: <200407111316.52663.wegmann_mailinglist@gmx.net>

sorry, did not intend to forward this mail to r-help ... Martin

On Sunday 11 July 2004 13:10, Martin Wegmann wrote:
> ----------  Forwarded Message  ----------
>
> Subject: newsletter
> Date: Sunday 11 July 2004 05:38
> From: Thomas Lumley <tlumley at u.washington.edu>
> To: r-announce at r-project.org
>
> The new issue of the R Newsletter (1/2004) is out on
>  http://www.r-project.org/
>
>          -thomas
>
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
>
> _______________________________________________
> R-announce at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-announce
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Sun Jul 11 13:58:06 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 11 Jul 2004 07:58:06 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKIEEHKCPAA.sdhyok@email.unc.edu>
References: <40F0B07E.5060105@jhsph.edu>
	<OAEOKPIGCLDDHAEMCAKIEEHKCPAA.sdhyok@email.unc.edu>
Message-ID: <6na2f0hb599ce32nrhnk09v17j6ur5kin0@4ax.com>

On Sat, 10 Jul 2004 23:28:39 -0400, "Shin, Daehyok"
<sdhyok at email.unc.edu> wrote:

>Considering replies to my question, typical practices of R users seem:
>1. Creating a special function to source frequently used scripts.

That's not right.  The practice I was describing is to have frequently
used code in a function, not in a script.

>2. Creating a personal package containing frequently used scripts.

And here it would be frequently used *functions*.
>
>Both of them needs additional steps to edit the function or to
>create/install the package
>when a script file is edited or added.

There's no additional step.  You write the function and use it.  

Duncan Murdoch



From dmurdoch at pair.com  Sun Jul 11 14:25:40 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 11 Jul 2004 08:25:40 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <40F0E8B0.3060804@cirad.fr>
References: <OAEOKPIGCLDDHAEMCAKIEEHKCPAA.sdhyok@email.unc.edu>
	<40F0E8B0.3060804@cirad.fr>
Message-ID: <m2c2f01d2ripcrpnj3i4b292r9bv5eu3oo@4ax.com>

On Sun, 11 Jul 2004 10:13:52 +0300, Renaud Lancelot
<renaud.lancelot at cirad.fr> wrote:

>I do agree with you: in my opinion, creating a package is not a general 
>solution when you just want to save the script of a whole data analysis 
>for the purpose of, say, a paper or a report.

I agree that this is a good use for a script, but I don't think it's
what Daehyok was talking about. He wants a library of frequently used
scripts to be available in multiple projects.   In R, the best way to
do that isn't to use scripts at all, it's to put the code in
functions.  

The problem with script code that is not in functions is that it needs
to have hard-coded variable names, and those can have undesirable side
effects.  But if you start R with an empty workspace, then load data
for a particular project from a script, collisions are unlikely.

>To meet this goal, I save the script in a text file and I use a text 
>editor with sourcing facilities (e.g. WinEdt + R-WinEdt, Xemacs + 
>ESS,...: see Software ==> Other section on CRAN).

R for Windows will have such an editor built in with the next major
release (in the fall).

Duncan Murdoch



From dmurdoch at pair.com  Sun Jul 11 14:27:52 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 11 Jul 2004 08:27:52 -0400
Subject: [R] Creating a minimal package (was: where does R search when
	source()?)
In-Reply-To: <loom.20040711T073351-641@post.gmane.org>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
	<40F0B07E.5060105@jhsph.edu>
	<loom.20040711T073351-641@post.gmane.org>
Message-ID: <ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>

On Sun, 11 Jul 2004 05:40:33 +0000 (UTC), Gabor Grothendieck
<ggrothendieck at myway.com> wrote:

>Roger,
>
>A list of the steps referred to below would be of interest.
>I realize the extensions manual exists but what I was
>thinking of was just a list of the minimal steps you take
>when you create a package for yourself.

There's really just one step: call package.skeleton().

Duncan Murdoch



From bates at stat.wisc.edu  Sun Jul 11 14:31:37 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 11 Jul 2004 07:31:37 -0500
Subject: [R] Creating a minimal package
In-Reply-To: <loom.20040711T073351-641@post.gmane.org>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>	<40F0B07E.5060105@jhsph.edu>
	<loom.20040711T073351-641@post.gmane.org>
Message-ID: <40F13329.4060905@stat.wisc.edu>

Gabor Grothendieck wrote:
> Roger,
> 
> A list of the steps referred to below would be of interest.
> I realize the extensions manual exists but what I was
> thinking of was just a list of the minimal steps you take
> when you create a package for yourself.
> 
> Thanks.

It has already been automated.  See

?package.skeleton


> 
> Roger D. Peng <rpeng <at> jhsph.edu> writes:
> 
> : 
> : In fact, there is an elegant solution, and that is to write a 
> : package.  If this is all for personal use, then writing a package 
> : can be as simple as creating a few directories, copying the 
> : script files, and then running R CMD INSTALL.  I do this all the 
> : time when I have multiple projects that use the same code.
> : 
> : -roger
> : 
> : Shin, Daehyok wrote:
> : > To my knowledge, it is a common practice for users to archive some script
> : > files in other directories than current working directory, when the script
> : > files are frequently used in many cases. So, it is somewhat surprising to 
> me
> : > there is no elegant solution to set up default search paths in R.
> : > 
> : > Here is my suggestion.
> : > According to the setup of Python (http://docs.python.org/tut/node8.html),
> : > when source() is called,
> : > 
> : > 1. Search current working directory.
> : > 2. If not found, search the directories specified by the environment
> : > variable RPATH.
> : > 
> : > I think this change will help users to manage script files more easily. 
> What
> : > do you think of it?
> : > 
> : > Daehyok Shin
> : > 
> : > 
> : >>-----Original Message-----
> : >>From: Liaw, Andy [mailto:andy_liaw <at> merck.com]
> : >>Sent: Saturday, July 10, 2004 PM 10:07
> : >>To: 'sdhyok <at> email.unc.edu'; R, Help
> : >>Subject: RE: [R] where does R search when source()?
> : >>
> : >>
> : >>Not really.  The best I can come up with is something like:
> : >>
> : >>runScript <- function(script, dir="", ...) source(file.path(dir, script,
> : >>...)
> : >>scriptdir <- "/path/to/scripts"
> : >>
> : >>runScript(scriptdir, "myScript.R")
> : >>
> : >>Andy
> : >>
> : >>
> : >>>From: Shin, Daehyok
> : >>>
> : >>>The reason I asked is to separate script files from data files.
> : >>>Usually, I am working in the directory containing data files, but some
> : >>>script files are in other shared directories. In the case, is
> : >>>there any way
> : >>>to access the script files conveniently without specifying
> : >>>its absolute
> : >>>path? In other word, any way to set up default search paths for script
> : >>>files?
> : >>>
> : >>>Daehyok Shin (Peter)
> : >>>
> : >>>
> : >>>>The former.  No documentation says otherwise, so why would you
> : >>>>think that it
> : >>>>might search somewhere else?
> : >>>>
> : >>>>Andy
> : >>>>
> : >>>>
> : >>>>------------------------------------------------------------------
> : >>>>------------
> : >>>>Notice:  This e-mail message, together with any attachments,
> : >>>>contains information of Merck & Co., Inc. (One Merck Drive,
> : >>>>Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
> : >>>>(which may be known outside the United States as Merck Frosst,
> : >>>>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
> : >>>>confidential, proprietary copyrighted and/or legally privileged.
> : >>>>It is intended solely for the use of the individual or entity
> : >>>>named on this message.  If you are not the intended recipient,
> : >>>>and have received this message in error, please notify us
> : >>>>immediately by reply e-mail and then delete it from your system.
> : >>>>------------------------------------------------------------------
> : >>>>------------
> : >>>>
> : >>>
> : >>>
> : >>>
> : >>
> : >>------------------------------------------------------------------
> : >>------------
> : >>Notice:  This e-mail message, together with any attachments,
> : >>contains information of Merck & Co., Inc. (One Merck Drive,
> : >>Whitehouse Station, New Jersey, USA 08889), and/or its affiliates
> : >>(which may be known outside the United States as Merck Frosst,
> : >>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
> : >>confidential, proprietary copyrighted and/or legally privileged.
> : >>It is intended solely for the use of the individual or entity
> : >>named on this message.  If you are not the intended recipient,
> : >>and have received this message in error, please notify us
> : >>immediately by reply e-mail and then delete it from your system.
> : >>------------------------------------------------------------------
> : >>------------
> : >>
> : > 
> : > 
> : > ______________________________________________
> : > R-help <at> stat.math.ethz.ch mailing list
> : > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> : > PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html
> : >
> : 
> : ______________________________________________
> : R-help <at> stat.math.ethz.ch mailing list
> : https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> : PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> : 
> :
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From nov_tao at yahoo.com  Sun Jul 11 15:55:50 2004
From: nov_tao at yahoo.com (Y C Tao)
Date: Sun, 11 Jul 2004 06:55:50 -0700 (PDT)
Subject: [R] Interpreting Results of Bootstrapping
In-Reply-To: <XFMail.040711104034.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20040711135550.22535.qmail@web53506.mail.yahoo.com>

You are right, the outlier caused the problem. Using
Spearman or Kendall's correlation seems to solve the
problem. Thanks!

Y. C. Tao

--- Ted.Harding at nessie.mcc.ac.uk wrote:
> Hi!
> 
> Simply plot(x1,x2): you will see that there is one
> point
> (number 23) at (x1,x2) = (25.34,6.744) which is a
> very
> long way from all the other points (which, among
> themselves,
> form a somewhat diffuse cluster with some suggestion
> of
> further structure).
> 
> When you bootstrap, the correlation you obtain in
> any sample
> will depend on whether or not this outlying point is
> included
> in the sample. If it is included, this single point
> will generate
> a relatively high value of the correlation
> coefficient simply
> because it is such a long way from all the others
> (i.e. it is
> highly influential).
> 
> If it is not included, then the diffuse character of
> the other
> points will generate a very low value of the
> correlation
> coefficient.
> 
>   > cor(x1,x2)
>   [1] 0.7471931
>   > cor(x1[-23],x2[-23])
>   [1] 0.03914653
> 
> Therefore your bootstrap distribution will have two
> peaks: one
> peak, around 0.75, corresponding to the bootstrap
> samples which
> include this outlying point, and the other, around
> 0, corresponding
> to the bootstrap samples which do not include it.
> 
> This is the explanation and, at the same time, the
> interpretation.
> 
> Best wishes,
> Ted.
> 
> On 11-Jul-04 Y C Tao wrote:
> > I tried to bootstrap the correlation between two
> > variables x1 and x2. The resulting distribution
> has
> > two distinct peaks, how should I interprete it?
> > 
> > The original code is attached.
> > 
> > Y. C. Tao
> > 
> > ----------------
> > 
> > library(boot);
> >  
> > my.correl<-function(d, i) cor(d[i,1], d[i,2])
> >  
> >
>
x1<-c(-2.612,-0.7859,-0.5229,-1.246,1.647,1.647,0.1811,
> >      
> -0.07097,0.8711,0.4323,0.1721,2.143,4.33,0.5002,
> >       
> 0.4015,-0.5225,2.538,0.07959,-0.6645,4.521,-1.371,
> >       
> 0.3327,25.24,-0.5417,2.094,0.6064,-0.4476,-0.5891,
> >      
>
-0.08879,-0.9487,-2.459e-05,-0.03887,0.2116,-0.0625,1.555,
> >       
> 0.2069,-0.2142,-0.807,-0.6499,2.384,-0.02063,1.179,
> >      
> -0.0003586,-1.408,0.6928,0.689,0.1854,0.4351,0.5663,
> >        0.07171,-0.07004);
> >  
> > x2<-c(
>
0.08742,0.2555,-0.00337,0.03995,-1.208,-1.208,-0.001374,
> >      
> -1.282,1.341,-0.9069,-0.2011,1.557,0.4517,-0.4376,
> >       
>
0.4747,0.04965,-0.1668,-0.6811,-0.7011,-1.457,0.04652,
> >      
> -1.117,6.744,-1.332,0.1327,-0.1479,-2.303,0.1235,   
>   
> >       
>
0.5916,0.05018,-0.7811,0.5869,-0.02608,0.9594,-0.1392,
> >       
> 0.4089,0.1468,-1.507,-0.6882,-0.1781,0.5434,-0.4957,
> >       
>
0.02557,-1.406,-0.5053,-0.7345,-1.314,0.3178,-0.2108,
> >        0.4186,-0.03347);
> >  
> > b<-boot(cbind(x1, x2), my.correl, 2000)
> > hist(b$t, breaks=50)
> 
> [The above rearranged to have 7 values in each
> conplete line]
> 
> 
> 
>
--------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 11-Jul-04                                     
>  Time: 10:40:34
> ------------------------------ XFMail
> ------------------------------
>



From ronpicci at yahoo.fr  Sun Jul 11 17:25:42 2004
From: ronpicci at yahoo.fr (=?iso-8859-1?q?Ron=20Piccinini?=)
Date: Sun, 11 Jul 2004 17:25:42 +0200 (CEST)
Subject: [R] Neural Net and SNOW
Message-ID: <20040711152542.77987.qmail@web52904.mail.yahoo.com>

Hello R masteRs,

I was wondering if somebody had already implemented a
parallel version of the function Nnet (with the SNOW
package for instance) and would be willing to share a
few pointers on how to achieve it. I have a training
set of dimensions 905,000 X 5. Should I just get more
RAM and run the nnet on one procesor? Or is there a
slick way to parallelize the computations?
I have tried to load the training set on each node and
have the nnet function run on the master, but it seems
that the master node will still put the whole training
set in memory....

Thank you in advance for your suggestions,

Ron Piccinini.



From andrew.c at bu.ac.th  Sun Jul 11 17:02:03 2004
From: andrew.c at bu.ac.th (Andrew R. Criswell)
Date: Sun, 11 Jul 2004 22:02:03 +0700 (ICT)
Subject: [R] variable definition
Message-ID: <32966.169.210.7.172.1089558123.squirrel@email.bu.ac.th>

Hello All:

This function obviously fails

    x <- function(z) paste("go", z, sep = ".") <- 10
    x("now")

But is there a way to define the name of a variable through passing a
parameter in a function call?

Thanks,
ANDREW



From spencer.graves at pdf.com  Sun Jul 11 18:04:48 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 11 Jul 2004 09:04:48 -0700
Subject: [R] Distribution of Data (was:  your reference on this problem
	highly appreciated)
In-Reply-To: <Pine.LNX.4.58.0407110040410.2040@aitken.uchicago.edu>
References: <200407101006.i6AA4HfS008298@hypatia.math.ethz.ch>
	<Pine.LNX.4.58.0407110040410.2040@aitken.uchicago.edu>
Message-ID: <40F16520.6040902@pdf.com>

      There are many tools for this, e.g., qqnorm, density, and in 
library(MASS) fitdistr.  Also do a literature search on transformations 
(especially to transformations to normality) and on mixture 
distributions, esp. Titterington, Smith and Makov (1986) Statistical 
Analysis of Finite Mixture Distributions (Wiley). 

      What is the nature of your application?  If you tell us more about 
the context, many people could tell you which distributions might be 
plausible and which would not be credible except as an approximation, 
e.g., a normal distribution for numbers that can not be negative and 
whose distribution might be positively skewed. 

      hope this helps.  spencer graves
p.s.  PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html     

Yong Wang wrote:

>please help me on this
>----- Message Text -----
>Dear all R users
>first, sorry for that this question might not be appropriate to ask here.
>                                                                                
>I wanna know theories or techinques aimed at following questions:
>                                                                                
>I have a sample, say,K(at the range from 0 to 20000); the sample data's
>central  moments m(1)---m(j) are estimated(j can be large).
>also, I can use some methodology to calculate the upper and lower bound of
>the probabilty of any interested interval, say, for the interval  
>(400--800)
>                                                                                
>with all these information, I wanna recover the distribution of the data,
>at least recover to some approximating  analytic form.Does anybady know
>such theory or techiniques?
>                                                                                
>your help will be highly appreciated.
>best regards
>yong
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From wolski at molgen.mpg.de  Sun Jul 11 18:05:29 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Sun, 11 Jul 2004 18:05:29 +0200
Subject: [R] variable definition
In-Reply-To: <32966.169.210.7.172.1089558123.squirrel@email.bu.ac.th>
References: <32966.169.210.7.172.1089558123.squirrel@email.bu.ac.th>
Message-ID: <200407111805290512.012F1DE8@mail.math.fu-berlin.de>

Hallo!
?assign

z<-"now"
assign(paste("go", z, sep = ".") ,10)


Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 7/11/2004 at 10:02 PM Andrew R. Criswell wrote:

>>>Hello All:
>>>
>>>This function obviously fails
>>>
>>>    x <- function(z) <- 10
>>>    x("now")
>>>
>>>But is there a way to define the name of a variable through passing a
>>>parameter in a function call?
>>>
>>>Thanks,
>>>ANDREW
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Achim.Zeileis at wu-wien.ac.at  Sun Jul 11 18:11:00 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Sun, 11 Jul 2004 18:11:00 +0200 (CEST)
Subject: [R] variable definition
In-Reply-To: <32966.169.210.7.172.1089558123.squirrel@email.bu.ac.th>
References: <32966.169.210.7.172.1089558123.squirrel@email.bu.ac.th>
Message-ID: <Pine.LNX.4.58.0407111809580.6830@thorin.ci.tuwien.ac.at>


On Sun, 11 Jul 2004, Andrew R. Criswell wrote:

> Hello All:
>
> This function obviously fails
>
>     x <- function(z) paste("go", z, sep = ".") <- 10
>     x("now")
>
> But is there a way to define the name of a variable through passing a
> parameter in a function call?

I'm not exactly sure what you want to do, but looking at
  ?assign
might be of some help.
Z

> Thanks,
> ANDREW
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From catch_utsav at yahoo.com  Sun Jul 11 18:13:17 2004
From: catch_utsav at yahoo.com (Utsav Boobna)
Date: Sun, 11 Jul 2004 09:13:17 -0700 (PDT)
Subject: [R] dyn.load() for windows
In-Reply-To: <mobte0553ot9dhqj7n8ab31q8dckv53qk4@4ax.com>
Message-ID: <20040711161317.25358.qmail@web14828.mail.yahoo.com>

Hi, 

When I check the dll file by tdump, following error
message was recieved.

C:\Borland\BCC55\Bin>tdump Sample.dll
Turbo Dump  Version 5.0.16.12 Copyright (c) 1988, 2000
Inprise Corporation
                    Display of File SAMPLE.DLL
ERROR: Invalid signature for an .EXE file - found
0C80, expected 5A4D

Please help.

Cheers,
Utsav


--- Duncan Murdoch <dmurdoch at pair.com> wrote:
> On Fri, 9 Jul 2004 03:29:55 -0700 (PDT), Utsav
> Boobna
> <catch_utsav at yahoo.com> wrote :
> 
> >Hi 
> >I am using Borland C++ compiler 5.5 and R 1.7.1
> >
> >got the dll using 
> >
> >c:\> bcc32 -u- -6 -O2 -osample.dll -WDE sample.c
> 
> I don't know the bcc32 command line options.  Can
> you examine the
> sample.dll file (using e.g. "tdump sample.dll", if
> you have tdump, or 
> "objdump -x sample.dll" using the objdump tool from
> our tools
> collection), and make sure it really is a DLL file?
> 
> Once you work out what is necessary to produce a DLL
> that works,
> please write up a short description and send it to
> me to include on my
> page
> 
>
http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/
> 
> I don't think there's anything there now that would
> help you, but you
> might browse it for inspiration...
> 
> Duncan Murdoch
> 
> >
> >
> >Then in R I used
> >
> >> dyn.load("sample.dll")
> >
> >Error in dyn.load(x, as.logical(local),
> >as.logical(now)) : 
> >        unable to load shared library
> "C:/sample.dll":
> >  LoadLibrary failure:  %1 ist keine zulssige
> >Win32-Anwendung.
> >
> >(Its in German ... meaning "%1 is not a valid Win32
> >application.")
> >
> >
> >
> >Thanks,
> >Utsav
> >
> >--- Duncan Murdoch <dmurdoch at pair.com> wrote:
> >> On Fri, 9 Jul 2004 01:58:27 -0700 (PDT), Utsav
> >> Boobna
> >> <catch_utsav at yahoo.com> wrote:
> >> 
> >> >Hi,
> >> >   I compiled several C program files on Borland
> >> C++
> >> >compiler to get one dll output (as instructed in
> >> the
> >> >file readme.package). Now when I try to load
> this
> >> >*.dll to R using dyn.load(), then the machine
> gives
> >> >the error message "*.dll is not a valid windows
> >> >data,....". The out put of R is 
> >> >
> >> >I am working on win2k.
> >> >What could be the possible reason for that?
> >> 
> >> Please show us your code and the exact error
> message
> >> (using cut and
> >> paste).  It might also help if you gave an exact
> >> description of how
> >> you produced the DLL (though I'm not familiar
> with
> >> BC++, someone else
> >> might be), and gave version numbers of BC++ and
> R.
> >> 
> >> Duncan Murdoch
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
>
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From dmurdoch at pair.com  Sun Jul 11 18:27:07 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 11 Jul 2004 12:27:07 -0400
Subject: [R] dyn.load() for windows
In-Reply-To: <20040711161317.25358.qmail@web14828.mail.yahoo.com>
References: <mobte0553ot9dhqj7n8ab31q8dckv53qk4@4ax.com>
	<20040711161317.25358.qmail@web14828.mail.yahoo.com>
Message-ID: <kvp2f09hbcgpnr5fu3pufln09r9fijtclf@4ax.com>

On Sun, 11 Jul 2004 09:13:17 -0700 (PDT), Utsav Boobna
<catch_utsav at yahoo.com> wrote:

>Hi, 
>
>When I check the dll file by tdump, following error
>message was recieved.
>
>C:\Borland\BCC55\Bin>tdump Sample.dll
>Turbo Dump  Version 5.0.16.12 Copyright (c) 1988, 2000
>Inprise Corporation
>                    Display of File SAMPLE.DLL
>ERROR: Invalid signature for an .EXE file - found
>0C80, expected 5A4D

That's a sign that there's something wrong with your bcc32 command.
It's producing something (an .OBJ file?) that's named SAMPLE.DLL, but
isn't a true DLL.

You need to check the Borland documentation to find how to create a
DLL.   Once you work this out and you've got things working well,
*please* write up the details and send them to me.

Alternatively, use the tools we recommend.  There are lots of people
here who are familiar with them and can help you to get them to work.
Borland has a better debugger than gdb and probably produces faster
code than gcc, but there's a big advantage in using something that
someone else can help you with.  As far as I know, *you're* the
world's foremost expert on using BCC32 with R.  If that's not a
position you feel qualified to hold, then use different tools.

Duncan Murdoch



From sdhyok at email.unc.edu  Sun Jul 11 18:41:20 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Sun, 11 Jul 2004 12:41:20 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <m2c2f01d2ripcrpnj3i4b292r9bv5eu3oo@4ax.com>
Message-ID: <OAEOKPIGCLDDHAEMCAKICEHOCPAA.sdhyok@email.unc.edu>


I agree that this is a good use for a script, but I don't think it's
what Daehyok was talking about. He wants a library of frequently used
scripts to be available in multiple projects.   In R, the best way to
do that isn't to use scripts at all, it's to put the code in
functions.
What I asked is the way to set up default search paths for source function,
whether or not files in the paths contain a set of functions or simple
script code.
Daehyok Shin



From ggrothendieck at myway.com  Sun Jul 11 18:47:04 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 11 Jul 2004 16:47:04 +0000 (UTC)
Subject: [R] variable definition
References: <32966.169.210.7.172.1089558123.squirrel@email.bu.ac.th>
	<200407111805290512.012F1DE8@mail.math.fu-berlin.de>
Message-ID: <loom.20040711T182945-616@post.gmane.org>

Wolski <wolski <at> molgen.mpg.de> writes:

> 
> Hallo!
> ?assign
> 
> z<-"now"
> assign(paste("go", z, sep = ".") ,10)

Assuming that you wish to create a variable called go.now with the
value of 10 in the caller environment to f:

   R> f <- function(z) assign(paste("go", z, sep = "."), 10, parent.frame())
   R> f("now")
   R> go.now
   [1] 10



From dmurdoch at pair.com  Sun Jul 11 19:12:31 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 11 Jul 2004 13:12:31 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKICEHOCPAA.sdhyok@email.unc.edu>
References: <m2c2f01d2ripcrpnj3i4b292r9bv5eu3oo@4ax.com>
	<OAEOKPIGCLDDHAEMCAKICEHOCPAA.sdhyok@email.unc.edu>
Message-ID: <9is2f09uuhheps65u8ecufkj5km39upk9p@4ax.com>

I wrote:

>I agree that this is a good use for a script, but I don't think it's
>what Daehyok was talking about. He wants a library of frequently used
>scripts to be available in multiple projects.   In R, the best way to
>do that isn't to use scripts at all, it's to put the code in
>functions.

On Sun, 11 Jul 2004 12:41:20 -0400, "Shin, Daehyok"
<sdhyok at email.unc.edu> wrote:

>What I asked is the way to set up default search paths for source function,
>whether or not files in the paths contain a set of functions or simple
>script code.

Gabor gave you a way to do that.  I was responding to your suggestion
that R should be modified to make this more convenient, because

>To my knowledge, it is a common practice for users to archive some script
>files in other directories than current working directory, when the script
>files are frequently used in many cases. So, it is somewhat surprising to me
>there is no elegant solution to set up default search paths in R.

I don't think this is a common practice; if it is, it shouldn't be.
Frequently used code should be in functions.  There are a lot of ways
to get those functions into your workspace, but R packages are the
best one.  There *is* a mechanism (the .libPaths function) for
specifying a search path for packages.

Duncan Murdoch



From sdhyok at email.unc.edu  Sun Jul 11 19:16:40 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Sun, 11 Jul 2004 13:16:40 -0400
Subject: [R] where does R search when source()?
In-Reply-To: <6na2f0hb599ce32nrhnk09v17j6ur5kin0@4ax.com>
Message-ID: <OAEOKPIGCLDDHAEMCAKIEEHPCPAA.sdhyok@email.unc.edu>

> >Considering replies to my question, typical practices of R users seem:
> >1. Creating a special function to source frequently used scripts.
>
> That's not right.  The practice I was describing is to have frequently
> used code in a function, not in a script.

Here, I meant "scripts " is "script files" whether they contains a series of
commands, or reusable functions.
This practice is not based on other replies, not yours.

>
> >2. Creating a personal package containing frequently used scripts.
>
> And here it would be frequently used *functions*.
> >

If the script files is a collection of functions, as you said, creating a
package can be one solution.

> >Both of them needs additional steps to edit the function or to
> >create/install the package
> >when a script file is edited or added.
>
> There's no additional step.  You write the function and use it.

Why are there no additional steps?
You suggested creating and installing a package is the solution to source
frequently used functions.
Then, every time I add/modify a function in a script file, or add new script
file, I have to re-create and re-install the package,
which are additional steps, not directly related with the addition or
modification.

More fundamental problem here is that the functions may have no common
context except "frequently used".
In the case, bundling all the functions into one package may not be a proper
choice.

So, I still think creating new package mayb be too heavy solution.
Why don't we simply extend a little bit the searching range of source
function?

>
> Duncan Murdoch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From msvika at mscc.huji.ac.il  Sun Jul 11 22:54:19 2004
From: msvika at mscc.huji.ac.il (Victoria Landsman)
Date: Sun, 11 Jul 2004 22:54:19 +0200
Subject: [R] How to bring an Splus object into R
Message-ID: <009701c46789$3c54fe00$8600a8c0@home2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040711/998547a5/attachment.pl

From andy_liaw at merck.com  Sun Jul 11 22:06:28 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 11 Jul 2004 16:06:28 -0400
Subject: [R] How to bring an Splus object into R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8013@usrymx25.merck.com>

>From the `R Data Import/Export' manual, shipped with R, as well as available
from the official R web site (last three paragraphs of Section 3.1,
describing functions in the `foreign' package):

Function read.S which can read binary objects produced by S-PLUS 3.x, 4.x or
2000
on (32-bit) Unix or Windows (and can read them on a di
erent OS). This is able to read
many but not all S objects: in particular it can read vectors, matrices and
data frames and
lists containing those.
Function data.restore reads S-PLUS data dumps (created by data.dump) with
the same restrictions (except that dumps from the Alpha platform can also be
read).
It should be possible to read data dumps from S-PLUS 5.x and 6.x written
with
data.dump(oldStyle=T).
If you have access to S-PLUS, it is usually more reliable to dump the
object(s) in S-PLUS
and source the dumpfile in R. For S-PLUS 5.x and 6.x you may need to use
dump(...,
oldStyle=T), and to read in very large objects it may be preferable to use
the dumpfile as
a batch script rather than source.

Please learn to read the manual yourself.

Andy

> From: Victoria Landsman
> 
> Dear all, 
> I like to bring the list created in Splus into R. What is the 
> shortest way to do this? 
> Much thanks, Vicky. 
> 	[[alternative HTML version deleted]]
>



From pwilkinson at videotron.ca  Sun Jul 11 22:51:59 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Sun, 11 Jul 2004 16:51:59 -0400
Subject: [R] How to bring an Splus object into R
In-Reply-To: <009701c46789$3c54fe00$8600a8c0@home2>
References: <009701c46789$3c54fe00$8600a8c0@home2>
Message-ID: <6.1.1.1.2.20040711165025.01bd87a0@pop.videotron.ca>

Actually I have wondered about the same but from R to S.  To solve that I 
have written the data from R into a tab separated file, then imported it 
into S.

Peter


At 04:54 PM 7/11/2004, Victoria Landsman wrote:
>Dear all,
>I like to bring the list created in Splus into R. What is the shortest way 
>to do this?
>Much thanks, Vicky.
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From msvika at mscc.huji.ac.il  Mon Jul 12 00:06:08 2004
From: msvika at mscc.huji.ac.il (Victoria Landsman)
Date: Mon, 12 Jul 2004 00:06:08 +0200
Subject: [R] How to bring an Splus object into R
References: <009701c46789$3c54fe00$8600a8c0@home2>
	<6.1.1.1.2.20040711165025.01bd87a0@pop.videotron.ca>
Message-ID: <00b601c46793$4519f900$8600a8c0@home2>

Much thanks to all who replied me. I used 'dump' in Splus5 and then 'source'
in R 1.9.1 (both on Unix) and it works.
Vicky.



----- Original Message -----
From: "Peter Wilkinson" <pwilkinson at videotron.ca>
To: "Victoria Landsman" <msvika at mscc.huji.ac.il>; <r-help at stat.math.ethz.ch>
Sent: Sunday, July 11, 2004 10:51 PM
Subject: Re: [R] How to bring an Splus object into R


> Actually I have wondered about the same but from R to S.  To solve that I
> have written the data from R into a tab separated file, then imported it
> into S.
>
> Peter
>
>
> At 04:54 PM 7/11/2004, Victoria Landsman wrote:
> >Dear all,
> >I like to bring the list created in Splus into R. What is the shortest
way
> >to do this?
> >Much thanks, Vicky.
> >         [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From p.murrell at auckland.ac.nz  Sun Jul 11 23:09:06 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 12 Jul 2004 09:09:06 +1200
Subject: [R] Viewport parameters
References: <40EEA88D.6000301@bristol.ac.uk>
Message-ID: <40F1AC72.7040307@stat.auckland.ac.nz>

Hi


Simon Woodhead wrote:
> Hello all,
> 
> In the Grid addon package from Paul Murrell is there a way of finding 
> the parameter settings for the viewport you are in? I understand in 
> Lattice there is a function trellis.get.par(), is there something 
> similar for Grid?


If you're using R 1.9.something, then get.gpar() should do the trick.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ggrothendieck at myway.com  Sun Jul 11 23:28:44 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 11 Jul 2004 21:28:44 +0000 (UTC)
Subject: [R] Creating a minimal package (was: where does R search
	=?utf-8?b?d2hlbglzb3VyY2UoKT8p?=
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
	<40F0B07E.5060105@jhsph.edu>
	<loom.20040711T073351-641@post.gmane.org>
	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>
Message-ID: <loom.20040711T231128-574@post.gmane.org>

Duncan Murdoch <dmurdoch <at> pair.com> writes:

: 
: On Sun, 11 Jul 2004 05:40:33 +0000 (UTC), Gabor Grothendieck
: <ggrothendieck <at> myway.com> wrote:
: 
: >Roger,
: >
: >A list of the steps referred to below would be of interest.
: >I realize the extensions manual exists but what I was
: >thinking of was just a list of the minimal steps you take
: >when you create a package for yourself.
: 
: There's really just one step: call package.skeleton().
: 
: Duncan Murdoch

I was hoping for something that really was that simple but
I tried and so far it seems that I also must also 

1. when I run skeleton.package realize that I must use the arg
   path = "library"
   The example that is shown there appears to omit that.

2. download and install tools.zip, perl and windows help as listed at:

   http://www.murdoch-sutherland.com/Rtools/

I got tripped up for quite a while when it could not find hhc.exe and
I finally realized I had not downloaded the windows help distribution.

3. change the name of the package in the DESCRIPTION file -- it seems
that the name = arg on package.skeleton did not change it for me.

4. make changes to the documentation files.  I am just working on this
now.  Some default null documentation exists but it appears that it
MUST be modified in order to get a working package so this makes another
step.

There maybe other things but its taken me several hours just to get
this far and I do not yet have a functioning package.

I think it would be handy if everything you need to know to actually
create a minimal functioning package were in ?skeleton.package
so that one could create a minimal functioning package without actually
reading the extensions manual and then incrementally improve it.  Right
now there is quite a bit you have to know just to get to that point.

I have so far looked at skeleton.package, readme.packages in rw1091,
murdoch-suthertherland.com link mentioned above and the extensions manual
so the startup to doing this is really a multi-step complex process.

The skeleton.package idea actually seems quite nifty but I think it
needs more work before one can really claim that its a one-step process
to create the example package.



From charles.edwin.white at us.army.mil  Sun Jul 11 23:36:08 2004
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Sun, 11 Jul 2004 17:36:08 -0400
Subject: [R] WinXP "developer" asks: Tcl/Tk (Rcmdr) under OS X?
Message-ID: <12D0D00E1404D511A4820090274CA09C03FBA6E0@dasmtyjqf010.amedd.army.mil>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040711/353a4d34/attachment.pl

From umalvarez at fata.unam.mx  Mon Jul 12 02:59:29 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Sun, 11 Jul 2004 19:59:29 -0500 (CDT)
Subject: [R] WinXP "developer" asks: Tcl/Tk (Rcmdr) under OS X?
In-Reply-To: <12D0D00E1404D511A4820090274CA09C03FBA6E0@dasmtyjqf010.amedd.army.mil>
Message-ID: <Pine.LNX.4.44.0407111951240.5455-100000@athena.fata.unam.mx>

Take a look at the aqua binary of Tcl/Tk at

http://www.apple.com/downloads/macosx/unix_open_source/


Or you could try with the R binary of Jan de Leeuw (which includes Tcl/Tk)  
at

http://gifi.stat.ucla.edu/pub/

Regards.


On Sun, 11 Jul 2004, White, Charles E WRAIR-Wash DC wrote:

> It is my understanding that Tcl/Tk does not come with the base installation of R under OS X ( http://www.sciviews.org/_rgui/projects/TclTk.html). Is there a simple way to explain how a user with limited tolerance for computer complexity can obtain and install Tcl/Tk for OS X?
>  
> Thanks. 
>  
> Chuck
>  
> Background: Roughly a third of my target audience uses OS X. I do not and I do not have access to a machine I could use as a development platform. 
>  
> Charles E. White, Senior Biostatistician, MS
> Walter Reed Army Institute of Research
> 503 Robert Grant Ave., Room 1w102
> Silver Spring, MD 20910-1557
> 301 319-9781
> Personal/Professional Site: http://users.starpower.net/cwhite571/professional/ 
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From dmurdoch at pair.com  Mon Jul 12 04:22:32 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 11 Jul 2004 22:22:32 -0400
Subject: [R] Creating a minimal package (was: where does R search when
	source()?)
In-Reply-To: <loom.20040711T231128-574@post.gmane.org>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
	<40F0B07E.5060105@jhsph.edu>
	<loom.20040711T073351-641@post.gmane.org>
	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>
	<loom.20040711T231128-574@post.gmane.org>
Message-ID: <ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>

Thanks for the information.  It *should* be that simple; thanks for
pointing out ways in which it is not.

Some more specific comments below...

On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
<ggrothendieck at myway.com> wrote:

>Duncan Murdoch <dmurdoch <at> pair.com> writes:
>
>: 
>: On Sun, 11 Jul 2004 05:40:33 +0000 (UTC), Gabor Grothendieck
>: <ggrothendieck <at> myway.com> wrote:
>: 
>: >Roger,
>: >
>: >A list of the steps referred to below would be of interest.
>: >I realize the extensions manual exists but what I was
>: >thinking of was just a list of the minimal steps you take
>: >when you create a package for yourself.
>: 
>: There's really just one step: call package.skeleton().
>: 
>: Duncan Murdoch
>
>I was hoping for something that really was that simple but
>I tried and so far it seems that I also must also 
>
>1. when I run skeleton.package realize that I must use the arg
>   path = "library"
>   The example that is shown there appears to omit that.

The default is to put it in the current directory.  The assumption is
that you started R where you want to work, or have switched to that
directory later.  This is usually true for Unix users, but generally
not for Windows users.

I'm not sure what sort of change to make here.  path = "library"
(literally) won't usually work, because it won't try to create the
directory.  Suggestion?

>2. download and install tools.zip, perl and windows help as listed at:
>
>   http://www.murdoch-sutherland.com/Rtools/
>
>I got tripped up for quite a while when it could not find hhc.exe and
>I finally realized I had not downloaded the windows help distribution.

Something I've meant to do for a long time (and got started on, once)
is to write a program that checks your system for the package building
requirements.  Just run it, and it'll tell you what it thinks is
missing (and how to find it).

>3. change the name of the package in the DESCRIPTION file -- it seems
>that the name = arg on package.skeleton did not change it for me.

Sounds like an oversight to me, but very easy to fix.  

>4. make changes to the documentation files.  I am just working on this
>now.  Some default null documentation exists but it appears that it
>MUST be modified in order to get a working package so this makes another
>step.

Should also be pretty easy to fix...
>
>There maybe other things but its taken me several hours just to get
>this far and I do not yet have a functioning package.
>
>I think it would be handy if everything you need to know to actually
>create a minimal functioning package were in ?skeleton.package
>so that one could create a minimal functioning package without actually
>reading the extensions manual and then incrementally improve it.  Right
>now there is quite a bit you have to know just to get to that point.

That's a good point.  I think we're moving towards a point where Perl
won't be necessary; the other tools are mostly reasonably small, and I
think we could set things up so that the install process worked with
or without HHC.

>I have so far looked at skeleton.package, readme.packages in rw1091,
>murdoch-suthertherland.com link mentioned above and the extensions manual
>so the startup to doing this is really a multi-step complex process.

>The skeleton.package idea actually seems quite nifty but I think it
>needs more work before one can really claim that its a one-step process
>to create the example package.



From ggrothendieck at myway.com  Mon Jul 12 06:32:55 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 12 Jul 2004 04:32:55 +0000 (UTC)
Subject: [R] Creating a minimal package (was: where does R search
	=?utf-8?b?d2hlbglzb3VyY2UoKT8p?=
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
	<40F0B07E.5060105@jhsph.edu>
	<loom.20040711T073351-641@post.gmane.org>
	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>
	<loom.20040711T231128-574@post.gmane.org>
	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>
Message-ID: <loom.20040712T055834-547@post.gmane.org>

Duncan Murdoch <dmurdoch <at> pair.com> writes:

: On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
: <ggrothendieck <at> myway.com> wrote:
: 

: >1. when I run skeleton.package realize that I must use the arg
: >   path = "library"
: >   The example that is shown there appears to omit that.
: 
: The default is to put it in the current directory.  The assumption is
: that you started R where you want to work, or have switched to that
: directory later.  This is usually true for Unix users, but generally
: not for Windows users.
: 
: I'm not sure what sort of change to make here.  path = "library"
: (literally) won't usually work, because it won't try to create the
: directory.  Suggestion?

Perhaps we could use:

   path = .libPaths()[[1]]

as the default value of path in package.skeleton.



From ok at cs.otago.ac.nz  Mon Jul 12 08:23:12 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Mon, 12 Jul 2004 18:23:12 +1200 (NZST)
Subject: [R] Association between discrete and continuous variable
Message-ID: <200407120623.i6C6NChO415915@atlas.otago.ac.nz>

What's the reommended way, in R, to determine the strength of
association between a discrete variable and a continuous variable?

Yes, I have read the manuals, trawled the archives, &c.



From ligges at statistik.uni-dortmund.de  Mon Jul 12 08:43:46 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 Jul 2004 08:43:46 +0200
Subject: [R] Creating a minimal package
In-Reply-To: <loom.20040712T055834-547@post.gmane.org>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>	<40F0B07E.5060105@jhsph.edu>	<loom.20040711T073351-641@post.gmane.org>	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>	<loom.20040711T231128-574@post.gmane.org>	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>
	<loom.20040712T055834-547@post.gmane.org>
Message-ID: <40F23322.6010809@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:

> Duncan Murdoch <dmurdoch <at> pair.com> writes:
> 
> : On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
> : <ggrothendieck <at> myway.com> wrote:
> : 
> 
> : >1. when I run skeleton.package realize that I must use the arg
> : >   path = "library"
> : >   The example that is shown there appears to omit that.
> : 
> : The default is to put it in the current directory.  The assumption is
> : that you started R where you want to work, or have switched to that
> : directory later.  This is usually true for Unix users, but generally
> : not for Windows users.
> : 
> : I'm not sure what sort of change to make here.  path = "library"
> : (literally) won't usually work, because it won't try to create the
> : directory.  Suggestion?
> 
> Perhaps we could use:
> 
>    path = .libPaths()[[1]]
> 
> as the default value of path in package.skeleton.

Actually, that's a bad idea, because you don't want a source package in 
your binary library tree.
I'm really happy with the default and the documentation which tells us 
about the "path" argument. Most (all?) functions I know do write to the 
current working directory. You do not want another default for 
write.table() et al. to write the data to, do you?

Uwe Ligges


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From baron at psych.upenn.edu  Mon Jul 12 09:40:33 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 12 Jul 2004 03:40:33 -0400
Subject: [R] Association between discrete and continuous variable
In-Reply-To: <200407120623.i6C6NChO415915@atlas.otago.ac.nz>
References: <200407120623.i6C6NChO415915@atlas.otago.ac.nz>
Message-ID: <20040712074033.GA95@psych>

On 07/12/04 18:23, Richard A. O'Keefe wrote:
>What's the reommended way, in R, to determine the strength of
>association between a discrete variable and a continuous variable?

Analysis of variance?  aov()?  R^2?

It seems to me, though, that there are many possible answers, and
this really doesn't have much to do with R because R could
implement them all.  It may matter whether the discrete variable
is ordered or not, whether it is fixed or random, what the error
distributions of the continuous variable look like, what measures
of association are traditional in your field, etc. etc.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From jawegelin at ucdavis.edu  Mon Jul 12 09:50:58 2004
From: jawegelin at ucdavis.edu (Jacob Wegelin)
Date: Mon, 12 Jul 2004 00:50:58 -0700 (PDT)
Subject: [R] lme unequal random-effects variances varIdent pdMat Pinheiro
 Bates nlme
Message-ID: <Pine.OSX.4.53.0407101928480.2644@biostat5.ucdavis.edu>


How does one implement a likelihood-ratio test, to test whether the
variances of the random effects differ between two groups of subjects?

Suppose your data consist of repeated measures on subjects belonging to
two groups, say boys and girls, and you are fitting a linear mixed-effects
model for the response as a function of time.  The within-subject errors
(residuals) have the same variance in both groups. But the dispersion of
the random effects differs between the groups.  The boys' random effects
-- say, the intercepts -- have greater variance than the girls'.  One can
see this by partitioning the data by sex and fitting two separate models.

The model for the girls,

	library("nlme")
	mylmeF0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="F")

yields a variance of about one for the random intercepts:

            StdDev    Corr
(Intercept) 0.9765052 (Intr)
time        0.1121913 -0.254
Residual    0.1806528

whereas in the model for the boys, the corresponding variance is ten times
that amount:

	mylmeM0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="M")

            StdDev     Corr
(Intercept) 10.1537946 (Intr)
time         0.1230063 -0.744
Residual     0.1298910

I would like to use a likelihood ratio to test this difference.  The
smaller ("null") model would be

	mylme0 <- lme( y ~ time, data=DAT, random=~time | id )  .

This model forces the random intercepts for both boys and girls to come
from a single normal distribution.

The larger model would allow the boys' and girls' random intercepts (or
more generally their random effects) to come from separate normal
distributions with possibly unequal variances.

There must be some straightforward obvious way to fit the larger model,
but I do not see it.

Pinheiro and Bates, chapter 5.2, show how to model unequal *residual*
("within-group") variances for the two groups using varIdent.  They also
tantalizingly say, "The single-level variance function model (5.10) can be
generalized to multilevel models" (page 206), which seems to suggest that
a solution to the current problem might exist.

The pdMat classes provide a way to *constrain* the dispersion matrix of
the random effects, not make it more general.

Of course, one way to test for unequal variances is to apply an F-test for
equal variances to the random intercepts. If the data are as shown at the
bottom of this email, the test can be implemented as follows:

	stuff<-as.data.frame(summary(mylme0)$coefficients$random$id)
	stuff$sex<-factor(substring(row.names(stuff), 1,1))
	mysplit<-split(stuff[,"(Intercept)"], stuff[,"sex"])
	ns<-sapply(mysplit, length)
	vars<-sapply(mysplit, var)
	p<- 1-pf( vars["M"]/vars["F"], ns["M"]-1, ns["F"]-1)

Alternatively, one could implement a permutation test for the ratio of the
variances of the random intercepts--these variances derived from the two
halves of the partitioned data.

But surely there's a direct, model-based way to do this?

Thanks for any suggestions

Jake

P.S. Here is the code by which the "data" were generated.

	nb<-1
	ntimepts<-3
	girls<-data.frame(
		y= rep(-nb:nb , each=ntimepts)
		,
		id=rep( paste("F", 1:(2*nb+1), sep=""), each=ntimepts)
		,
		time=rep(1:(2*nb+1), length=ntimepts)
		)
	boys <-data.frame(
		y= rep(10*(-nb:nb) , each=ntimepts)
		,
		id=rep( paste("M", 1:(2*nb+1), sep=""), each=ntimepts)
		,
		time=rep(1:(2*nb+1), length=ntimepts)
		)
	DAT<-rbind(girls,boys)
	DAT$y<-DAT$y + rnorm(nrow(DAT))/5
	DAT$sex<-factor(substring( as.character(DAT[,"id"]), 1,1))
	row.names(DAT)<-paste( DAT[,"id"], DAT[,"time"], sep=".")

Jacob A. Wegelin
Assistant Professor
Division of Biostatistics, School of Medicine
University of California, Davis
One Shields Ave, TB-168
Davis CA 95616-8638 USA
http://wegelin.ucdavis.edu/
jawegelin at ucdavis.edu



From maj at stats.waikato.ac.nz  Mon Jul 12 10:52:03 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon, 12 Jul 2004 20:52:03 +1200
Subject: [R] Association between discrete and continuous variable
In-Reply-To: <200407120623.i6C6NChO415915@atlas.otago.ac.nz>
References: <200407120623.i6C6NChO415915@atlas.otago.ac.nz>
Message-ID: <40F25133.6030207@stats.waikato.ac.nz>

I'm wondering if mutual information al la Cover & Thomas (1991, Ch 2) is 
not the killer association measure for all types of random variables?

Murray Jorgensen

PS  Yes, this is probably OT!

Richard A. O'Keefe wrote:
> What's the reommended way, in R, to determine the strength of
> association between a discrete variable and a continuous variable?
> 
> Yes, I have read the manuals, trawled the archives, &c.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From maj at stats.waikato.ac.nz  Mon Jul 12 11:00:44 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon, 12 Jul 2004 21:00:44 +1200
Subject: [R] Nested source()s
Message-ID: <40F2533C.9080709@stats.waikato.ac.nz>

I had an error message while running a macro from Yudi Pawitan's web site:

 > source("ex2-13.r")
Error in parse(file, n, text, prompt) : syntax error on line 2

Inspecting ex2-13.r I found that the error was generated by another 
source() command.

Clearly R does not like nested source()s, which is fair enough when you 
think about it. Still it's something that you might want to do. Does 
anyone know how to get achieve the substance of what nested source() 
commands would give you?

Murray Jorgensen

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From christoph.lehmann at gmx.ch  Mon Jul 12 11:25:37 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 12 Jul 2004 11:25:37 +0200
Subject: [R] pixmapIndexed color question
Message-ID: <40F25911.3070607@gmx.ch>

Hi

I use pixmapIndexed

tmp.vimp <- array(0,c(x.dim,y.dim))
tmp.vimp <- pixmapIndexed(tmp.vimp, col=rainbow)

to plot values of a 2D matrix. I 'fill' the pixmapIndexed like:

     for (x in 1:x.dim) {
         for (y in 1:y.dim) {
                     tmp.vimp at index[x,y] <- my.matrix[x,y]
     }}


how can I define, that the colors are painted e.g. according the rainbow 
palette?

plot(tmp.vimp) paints all 'pixels' in red even though I specified it 
with col=rainbow (see above)

many thanks

cheers

christoph

p.s. is there an easier method for 'painting' the values of a 2d matrix?



From christoph.lehmann at gmx.ch  Mon Jul 12 13:08:35 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 12 Jul 2004 13:08:35 +0200
Subject: [R] image NAs error
Message-ID: <40F27133.7080407@gmx.ch>

tmp.vimp <- matrix(NA, nrow = x.dim, ncol = y.dim)
tmp.vimp <- image(tmp.vimp, col=rainbow)

gives:

Error in image.default(tmp.vimp, col = rainbow) :
         invalid z limits
In addition: Warning messages:
1: no finite arguments to min; returning Inf
2: no finite arguments to max; returning -Inf


even though NAs are allowed in image

what went wrong here?

thank you

Christoph



From ggrothendieck at myway.com  Mon Jul 12 13:30:24 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 12 Jul 2004 11:30:24 +0000 (UTC)
Subject: [R] Creating a minimal package
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>	<40F0B07E.5060105@jhsph.edu>	<loom.20040711T073351-641@post.gmane.org>	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>	<loom.20040711T231128-574@post.gmane.org>	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>
	<loom.20040712T055834-547@post.gmane.org>
	<40F23322.6010809@statistik.uni-dortmund.de>
Message-ID: <loom.20040712T131806-594@post.gmane.org>

Uwe Ligges <ligges <at> statistik.uni-dortmund.de> writes:

: 
: Gabor Grothendieck wrote:
: 
: > Duncan Murdoch <dmurdoch <at> pair.com> writes:
: > 
: > : On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
: > : <ggrothendieck <at> myway.com> wrote:
: > : 
: > 
: > : >1. when I run skeleton.package realize that I must use the arg
: > : >   path = "library"
: > : >   The example that is shown there appears to omit that.
: > : 
: > : The default is to put it in the current directory.  The assumption is
: > : that you started R where you want to work, or have switched to that
: > : directory later.  This is usually true for Unix users, but generally
: > : not for Windows users.
: > : 
: > : I'm not sure what sort of change to make here.  path = "library"
: > : (literally) won't usually work, because it won't try to create the
: > : directory.  Suggestion?
: > 
: > Perhaps we could use:
: > 
: >    path = .libPaths()[[1]]
: > 
: > as the default value of path in package.skeleton.
: 
: Actually, that's a bad idea, because you don't want a source package in 
: your binary library tree.
: I'm really happy with the default and the documentation which tells us 
: about the "path" argument. Most (all?) functions I know do write to the 
: current working directory. You do not want another default for 
: write.table() et al. to write the data to, do you?

The objective should be that creating a package is as easy as this:

   f <- function()1; g <- function()2; d <- 3; e <- 4:5
   package.skeleton(list=c("f","g","d","e"), name="AnExample")
   library(AnExample)
   f()
   
which means that the package needs to be inserted where library will
find it. It should not be necessary to have an understanding of this.



From rolf at math.unb.ca  Mon Jul 12 13:45:32 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 12 Jul 2004 08:45:32 -0300 (ADT)
Subject: [R] Nested source()s
Message-ID: <200407121145.i6CBjWj4021683@erdos.math.unb.ca>

Murray Jorgensen wrote:

> I had an error message while running a macro from Yudi Pawitan's web site:
> 
>  > source("ex2-13.r")
> Error in parse(file, n, text, prompt) : syntax error on line 2
> 
> Inspecting ex2-13.r I found that the error was generated by another 
> source() command.
> 
> Clearly R does not like nested source()s, which is fair enough when you 
  ^^^^^^^
  |||||||
  Nothing clear about it!

> think about it. Still it's something that you might want to do. Does 
> anyone know how to get achieve the substance of what nested source() 
> commands would give you?

	You're leaping to conclusions, mate.  There is no
	proscription of nested sources in R.  I just checked
	this:  I built a file called ``melvin'':

	x <- 42
	source('clyde')

	and a file called ``clyde'':

	y <- 2*x
	print(y)

	and then executed

	> source('melvin')

	and got

	[1] 84

	OMMMMMMMMMMMMMMMMMMMMMMM.

	There is something else wrong in the files that you
	are sourcing.

					cheers,

						Rolf
						rolf at math.unb.ca



From rpeng at jhsph.edu  Mon Jul 12 14:09:07 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 12 Jul 2004 08:09:07 -0400
Subject: [R] image NAs error
In-Reply-To: <40F27133.7080407@gmx.ch>
References: <40F27133.7080407@gmx.ch>
Message-ID: <40F27F63.6090202@jhsph.edu>

It can't calculate the range of the x/y axes so there's nothing to plot.

-roger

Christoph Lehmann wrote:
> tmp.vimp <- matrix(NA, nrow = x.dim, ncol = y.dim)
> tmp.vimp <- image(tmp.vimp, col=rainbow)
> 
> gives:
> 
> Error in image.default(tmp.vimp, col = rainbow) :
>         invalid z limits
> In addition: Warning messages:
> 1: no finite arguments to min; returning Inf
> 2: no finite arguments to max; returning -Inf
> 
> 
> even though NAs are allowed in image
> 
> what went wrong here?
> 
> thank you
> 
> Christoph
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Mon Jul 12 14:56:02 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 12 Jul 2004 13:56:02 +0100
Subject: [R] Nested source()s
In-Reply-To: <200407121145.i6CBjWj4021683@erdos.math.unb.ca>
References: <200407121145.i6CBjWj4021683@erdos.math.unb.ca>
Message-ID: <1089636770.3030.63.camel@vpn202001.lif.icnet.uk>

Yes, I have source()-ed recursively without problems before. Try
sourcing the second script on its own and see what errors it has.

I have download lkpack.zip
(http://www.mep.ki.se/~yudpaw/likelihood/lkpack.zip)
and source("EX2-13.R") and source("li.r") which is called without
problem. The timestamp appears to show that it was not modified
recently.

Are you sure you have the latest version ?

On Mon, 2004-07-12 at 12:45, Rolf Turner wrote:
> Murray Jorgensen wrote:
> 
> > I had an error message while running a macro from Yudi Pawitan's web site:
> > 
> >  > source("ex2-13.r")
> > Error in parse(file, n, text, prompt) : syntax error on line 2
> > 
> > Inspecting ex2-13.r I found that the error was generated by another 
> > source() command.
> > 
> > Clearly R does not like nested source()s, which is fair enough when you 
>   ^^^^^^^
>   |||||||
>   Nothing clear about it!
> 
> > think about it. Still it's something that you might want to do. Does 
> > anyone know how to get achieve the substance of what nested source() 
> > commands would give you?
> 
> 	You're leaping to conclusions, mate.  There is no
> 	proscription of nested sources in R.  I just checked
> 	this:  I built a file called ``melvin'':
> 
> 	x <- 42
> 	source('clyde')
> 
> 	and a file called ``clyde'':
> 
> 	y <- 2*x
> 	print(y)
> 
> 	and then executed
> 
> 	> source('melvin')
> 
> 	and got
> 
> 	[1] 84
> 
> 	OMMMMMMMMMMMMMMMMMMMMMMM.
> 
> 	There is something else wrong in the files that you
> 	are sourcing.
> 
> 					cheers,
> 
> 						Rolf
> 						rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Mon Jul 12 15:14:27 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 Jul 2004 15:14:27 +0200
Subject: [R] Creating a minimal package
In-Reply-To: <loom.20040712T131806-594@post.gmane.org>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>	<40F0B07E.5060105@jhsph.edu>	<loom.20040711T073351-641@post.gmane.org>	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>	<loom.20040711T231128-574@post.gmane.org>	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>	<loom.20040712T055834-547@post.gmane.org>	<40F23322.6010809@statistik.uni-dortmund.de>
	<loom.20040712T131806-594@post.gmane.org>
Message-ID: <40F28EB3.7060902@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:

> Uwe Ligges <ligges <at> statistik.uni-dortmund.de> writes:
> 
> : 
> : Gabor Grothendieck wrote:
> : 
> : > Duncan Murdoch <dmurdoch <at> pair.com> writes:
> : > 
> : > : On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
> : > : <ggrothendieck <at> myway.com> wrote:
> : > : 
> : > 
> : > : >1. when I run skeleton.package realize that I must use the arg
> : > : >   path = "library"
> : > : >   The example that is shown there appears to omit that.
> : > : 
> : > : The default is to put it in the current directory.  The assumption is
> : > : that you started R where you want to work, or have switched to that
> : > : directory later.  This is usually true for Unix users, but generally
> : > : not for Windows users.
> : > : 
> : > : I'm not sure what sort of change to make here.  path = "library"
> : > : (literally) won't usually work, because it won't try to create the
> : > : directory.  Suggestion?
> : > 
> : > Perhaps we could use:
> : > 
> : >    path = .libPaths()[[1]]
> : > 
> : > as the default value of path in package.skeleton.
> : 
> : Actually, that's a bad idea, because you don't want a source package in 
> : your binary library tree.
> : I'm really happy with the default and the documentation which tells us 
> : about the "path" argument. Most (all?) functions I know do write to the 
> : current working directory. You do not want another default for 
> : write.table() et al. to write the data to, do you?
> 
> The objective should be that creating a package is as easy as this:
> 
>    f <- function()1; g <- function()2; d <- 3; e <- 4:5
>    package.skeleton(list=c("f","g","d","e"), name="AnExample")
>    library(AnExample)
>    f()
>    
> which means that the package needs to be inserted where library will
> find it. It should not be necessary to have an understanding of this.
> 

OK, I understand what you are going to do, but in that case you can use 
dump() into an *.R or save() into an *.RData file and use 
source()/load() to load it again. I don't see any advantage of a package 
if you don't want to modify documentation or other stuff in the package.
Also, you would need the tools to make a binary package from the source 
package somewhere. package.skeleton() is clearly not intended to be used 
for that purpose, but to create the template for your source package.
Hence the default should not be changed.

Uwe Ligges



From Veronique.Verrier at aventis.com  Mon Jul 12 15:15:01 2004
From: Veronique.Verrier at aventis.com (Veronique.Verrier@aventis.com)
Date: Mon, 12 Jul 2004 15:15:01 +0200
Subject: [R] help
Message-ID: <B13F58013757F9418D1C98DC764330D501A44C33@frasmxsusr14.pharma.aventis.com>



From andy_liaw at merck.com  Mon Jul 12 15:16:23 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 09:16:23 -0400
Subject: [R] Creating a minimal package
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8014@usrymx25.merck.com>

> From: Gabor Grothendieck
> 
[snip]
> 
> The objective should be that creating a package is as easy as this:
> 
>    f <- function()1; g <- function()2; d <- 3; e <- 4:5
>    package.skeleton(list=c("f","g","d","e"), name="AnExample")
>    library(AnExample)
>    f()
>    
> which means that the package needs to be inserted where library will
> find it. It should not be necessary to have an understanding of this.

To the best of my knowledge (which is not saying much, admittedly) no
version of R on any OS would that work.  package.skeleton() only create the
directory tree and populate it with code and template files.  You still need
to package it up from a shell with R CMD build AnExample (or R CMD build
--binary AnExample for Windows, and maybe Mac?).  Then you need the
install.package("AnExample", CRAN=NULL), before you can actually do
library(AnExample).

BTW, for functions/objects that you would like to use over and over, but do
not want to go through the hurdle of packaging, there's a fairly simple way
to achieve similar effect: save all of them in a .rda file, and when you
need them, just attach() the .rda file.

Let me bring up the old phrase:  R is Open Source.  If you want something
bad enough, you can try to make it happen yourself.  A good example is the
scripting patch announced on R-devel by Neil McKay.  Neil had provided
patches to various versions of R for a while.  If the packaging situation
bothers you enough, feel free to contribute.  I'm quite sure DM will be
happy to get help...

Andy



From dmurdoch at pair.com  Mon Jul 12 15:24:43 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 09:24:43 -0400
Subject: [R] Creating a minimal package (was: where does R search when
	source()?)
In-Reply-To: <loom.20040712T055834-547@post.gmane.org>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
	<40F0B07E.5060105@jhsph.edu>
	<loom.20040711T073351-641@post.gmane.org>
	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>
	<loom.20040711T231128-574@post.gmane.org>
	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>
	<loom.20040712T055834-547@post.gmane.org>
Message-ID: <cs35f0tbt5upagnq83l6al5vv1agv14f9e@4ax.com>

On Mon, 12 Jul 2004 04:32:55 +0000 (UTC), Gabor Grothendieck
<ggrothendieck at myway.com> wrote :

>Duncan Murdoch <dmurdoch <at> pair.com> writes:
>
>: On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
>: <ggrothendieck <at> myway.com> wrote:
>: 
>
>: >1. when I run skeleton.package realize that I must use the arg
>: >   path = "library"
>: >   The example that is shown there appears to omit that.
>: 
>: The default is to put it in the current directory.  The assumption is
>: that you started R where you want to work, or have switched to that
>: directory later.  This is usually true for Unix users, but generally
>: not for Windows users.
>: 
>: I'm not sure what sort of change to make here.  path = "library"
>: (literally) won't usually work, because it won't try to create the
>: directory.  Suggestion?
>
>Perhaps we could use:
>
>   path = .libPaths()[[1]]
>
>as the default value of path in package.skeleton.

I've now fixed the DESCRIPTION file generation so it sets the package
name.

I didn't change the path default, but I changed the example (on
Windows) to set the working directory to the user's home directory,
and added a bit of text explaining what else is necessary to make use
of the new package.

When I test it now, the example produces a package that installs and
runs properly (though you do get warnings in the build because of 
various things that need to be manually edited in the man pages).

These changes are available in r-patched.  I'll do a binary build
today, and they should be downloadable from CRAN tomorrow.

Thanks for your suggestions.

BTW, the new R Newsletter describes a facility for working with
packages; I haven't tried it out yet, but it looks like it would be
useful.

Duncan Murdoch



From dmurdoch at pair.com  Mon Jul 12 15:41:31 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 09:41:31 -0400
Subject: [R] Creating a minimal package
In-Reply-To: <40F28EB3.7060902@statistik.uni-dortmund.de>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>	<40F0B07E.5060105@jhsph.edu>	<loom.20040711T073351-641@post.gmane.org>	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>	<loom.20040711T231128-574@post.gmane.org>	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>	<loom.20040712T055834-547@post.gmane.org>	<40F23322.6010809@statistik.uni-dortmund.de>
	<loom.20040712T131806-594@post.gmane.org>
	<40F28EB3.7060902@statistik.uni-dortmund.de>
Message-ID: <ta45f0ljhetd4ai746fs18dff7mim7o1i0@4ax.com>

On Mon, 12 Jul 2004 15:14:27 +0200, Uwe Ligges
<ligges at statistik.uni-dortmund.de> wrote :

>Gabor Grothendieck wrote:

>> The objective should be that creating a package is as easy as this:
>> 
>>    f <- function()1; g <- function()2; d <- 3; e <- 4:5
>>    package.skeleton(list=c("f","g","d","e"), name="AnExample")
>>    library(AnExample)
>>    f()
>>    
>> which means that the package needs to be inserted where library will
>> find it. It should not be necessary to have an understanding of this.
>> 
>
>OK, I understand what you are going to do, but in that case you can use 
>dump() into an *.R or save() into an *.RData file and use 
>source()/load() to load it again. I don't see any advantage of a package 
>if you don't want to modify documentation or other stuff in the package.
>Also, you would need the tools to make a binary package from the source 
>package somewhere. package.skeleton() is clearly not intended to be used 
>for that purpose, but to create the template for your source package.
>Hence the default should not be changed.

I agree with both of you on this.  Currently the method that Uwe
describes is a lot easier than creating a package, but I think the
objective should be to make things almost as easy as Gabor describes.

Not completely as easy:  he's missing the step where the package is
installed.  I think we want to keep that (because the distinction
between the source of a package and the installed copy of it is
important), but it should be easier to install a new package than it
is now, especially in Windows.  So I'm suggesting that it would be
nice to be able to do something like this:

 f <- function()1; g <- function()2; d <- 3; e <- 4:5
 package.skeleton(list=c("f","g","d","e"), name="AnExample")
 install.packages("AnExample", build = TRUE)
 library(AnExample)
 f()

but currently install.packages doesn't know how to build, and for most
Windows users, a fairly substantial effort is necessary to obtain all
the tools.

Duncan Murdoch



From r-stats at arcriswell.com  Mon Jul 12 08:16:06 2004
From: r-stats at arcriswell.com (Andrew Criswell)
Date: Mon, 12 Jul 2004 13:16:06 +0700
Subject: [R] help with paste
Message-ID: <40F22CA6.6090609@arcriswell.com>

Hello All:

Suppose the following little data frame:

 > x <- data.frame(dog = c(3,4,6,2,8), cat = c(8,2,3,6,1))
 >
 > x$cat
[1] 8 2 3 6 1
 >

How can I get the paste() function to do the same thing. The command 
below is obviously wrong

 > paste(x, cat, sep = "$")
 >

Thanks,
ANDREW



From andy_liaw at merck.com  Mon Jul 12 15:56:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 09:56:47 -0400
Subject: [R] help with paste
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8017@usrymx25.merck.com>

Do you mean something like:

> paste(x$cat, collapse=" ")
[1] "8 2 3 6 1"

??

Andy

> From: Andrew Criswell
> 
> Hello All:
> 
> Suppose the following little data frame:
> 
>  > x <- data.frame(dog = c(3,4,6,2,8), cat = c(8,2,3,6,1))
>  >
>  > x$cat
> [1] 8 2 3 6 1
>  >
> 
> How can I get the paste() function to do the same thing. The command 
> below is obviously wrong
> 
>  > paste(x, cat, sep = "$")
>  >
> 
> Thanks,
> ANDREW



From dmurdoch at pair.com  Mon Jul 12 15:59:36 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 09:59:36 -0400
Subject: [R] help with paste
In-Reply-To: <40F22CA6.6090609@arcriswell.com>
References: <40F22CA6.6090609@arcriswell.com>
Message-ID: <5u55f09ok4v72nbu384qa4uffhg9kk1muc@4ax.com>

On Mon, 12 Jul 2004 13:16:06 +0700, Andrew Criswell
<r-stats at arcriswell.com> wrote :

>Hello All:
>
>Suppose the following little data frame:
>
> > x <- data.frame(dog = c(3,4,6,2,8), cat = c(8,2,3,6,1))
> >
> > x$cat
>[1] 8 2 3 6 1
> >
>
>How can I get the paste() function to do the same thing. The command 
>below is obviously wrong
>
> > paste(x, cat, sep = "$")

I'm not 100% sure I know what the "same thing" is, but I think you
want

 eval(parse(text=paste("x", "cat", sep="$")))

The parse() function converts the string to an expression, and the
eval() function evaluates it.  You can use variables in place of "x"
and "cat" if you want, e.g.

 animal <- "dog"
 eval(parse(text=paste("x", animal, sep="$")))

Duncan Murdoch



From rolf at math.unb.ca  Mon Jul 12 15:57:39 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 12 Jul 2004 10:57:39 -0300 (ADT)
Subject: [R] help with paste
Message-ID: <200407121357.i6CDvda5027333@erdos.math.unb.ca>

Andrew Criswell wrote:

> Suppose the following little data frame:
> 
>  > x <- data.frame(dog = c(3,4,6,2,8), cat = c(8,2,3,6,1))
>  >
>  > x$cat
> [1] 8 2 3 6 1
>  >
> 
> How can I get the paste() function to do the same thing. The command 
                                           ^^^^^^^^^^^^^^
                                           Same thing as ***what***????
> below is obviously wrong
> 
>  > paste(x, cat, sep = "$")
>  >

It's not at all clear what you want to do.  Do you just wish
to create the string ``x$cat''?  This would be done via

	> paste("x","cat",sep="$")

But why?  It's a bad idea to use ``$'' in strings since ``$''
has a special meaning in R (i.e. to refer to components of lists).


				cheers,

					Rolf Turner
					rolf at math.unb.ca



From MSchwartz at MedAnalytics.com  Mon Jul 12 16:04:18 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 12 Jul 2004 09:04:18 -0500
Subject: [R] help with paste
In-Reply-To: <40F22CA6.6090609@arcriswell.com>
References: <40F22CA6.6090609@arcriswell.com>
Message-ID: <1089641058.22864.23.camel@localhost.localdomain>

On Mon, 2004-07-12 at 01:16, Andrew Criswell wrote:
> Hello All:
> 
> Suppose the following little data frame:
> 
>  > x <- data.frame(dog = c(3,4,6,2,8), cat = c(8,2,3,6,1))
>  >
>  > x$cat
> [1] 8 2 3 6 1
>  >
> 
> How can I get the paste() function to do the same thing. The command 
> below is obviously wrong
> 
>  > paste(x, cat, sep = "$")


You need to quote the "x" and the "cat" as explicit names, otherwise the
objects 'x' and 'cat' are passed as arguments. 'x' in this case being
your data frame and 'cat' being the function cat().

Try this:

> eval(parse(text = paste("x", "cat", sep = "$")))
[1] 8 2 3 6 1

HTH,

Marc Schwartz



From andy_liaw at merck.com  Mon Jul 12 16:13:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 10:13:18 -0400
Subject: [R] help with paste
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8018@usrymx25.merck.com>

Now that I see Duncan's reply, I believe that's what Andrew wanted.  I
really should read messages more carefully...

Andy

> From: Liaw, Andy
> 
> Do you mean something like:
> 
> > paste(x$cat, collapse=" ")
> [1] "8 2 3 6 1"
> 
> ??
> 
> Andy
> 
> > From: Andrew Criswell
> > 
> > Hello All:
> > 
> > Suppose the following little data frame:
> > 
> >  > x <- data.frame(dog = c(3,4,6,2,8), cat = c(8,2,3,6,1))
> >  >
> >  > x$cat
> > [1] 8 2 3 6 1
> >  >
> > 
> > How can I get the paste() function to do the same thing. 
> The command 
> > below is obviously wrong
> > 
> >  > paste(x, cat, sep = "$")
> >  >
> > 
> > Thanks,
> > ANDREW
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
>



From ligges at statistik.uni-dortmund.de  Mon Jul 12 16:32:32 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 Jul 2004 16:32:32 +0200
Subject: [R] help with paste
In-Reply-To: <1089641058.22864.23.camel@localhost.localdomain>
References: <40F22CA6.6090609@arcriswell.com>
	<1089641058.22864.23.camel@localhost.localdomain>
Message-ID: <40F2A100.7010602@statistik.uni-dortmund.de>

Marc Schwartz wrote:

> On Mon, 2004-07-12 at 01:16, Andrew Criswell wrote:
> 
>>Hello All:
>>
>>Suppose the following little data frame:
>>
>> > x <- data.frame(dog = c(3,4,6,2,8), cat = c(8,2,3,6,1))
>> >
>> > x$cat
>>[1] 8 2 3 6 1
>> >
>>
>>How can I get the paste() function to do the same thing. The command 
>>below is obviously wrong
>>
>> > paste(x, cat, sep = "$")
> 
> 
> 
> You need to quote the "x" and the "cat" as explicit names, otherwise the
> objects 'x' and 'cat' are passed as arguments. 'x' in this case being
> your data frame and 'cat' being the function cat().
> 
> Try this:
> 
> 
>>eval(parse(text = paste("x", "cat", sep = "$")))
> 
> [1] 8 2 3 6 1


OK. That thread gets boring, because nobody is sure what the questioner 
is asking. Anyway, I guess Andrew Criswell is looking for:

    get("x")[["cat"]]

- Use [[]] rather than $ for subsetting with characters ($ is just 
provided for convenience and not that helpful here).
- Use get() to get values from objects specified in form of a character 
vector.


Uwe Ligges



> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From MatUnt at gmx.de  Mon Jul 12 16:34:51 2004
From: MatUnt at gmx.de (Matthias Unterhuber)
Date: Mon, 12 Jul 2004 16:34:51 +0200 (MEST)
Subject: [R] multiple hierarchical anova models
Message-ID: <337.1089642891@www12.gmx.net>

Hello,

My name is Matthias and I do look for syntax regarding hierarchal anova
models in R. How can I express that a factor is nested within the
combination of two other factors A(B,C), e.g. for aov(...)? I did not find
the corresponding expression. Furthermore, I wanted to ask whether block
factors have to be specified in a specific way or are they just treated as
other factors (with no interactions).

Furthermore, in general an overview might be useful for beginners that
describes the structural equations of more complicated anova-designs
(hierarchical and block factor designs...) in the syntax of R.

Best wishes and thanks,

Matthias



From rado.bonk at jrc.it  Mon Jul 12 17:02:40 2004
From: rado.bonk at jrc.it (Rado Bonk)
Date: Mon, 12 Jul 2004 17:02:40 +0200
Subject: [R] ROracle package error
Message-ID: <40F2A810.7010705@jrc.it>

Dear R-users,

In order to use ROracle (v. 0.5-5) package I compiled R-1.9.1 on Linux 
(2.4.20-28.9smp) and installed it. I need to use Oracle9i on Solaris. 
When executing "library(ROracle)" I got the following error message:

 > library(ROracle)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
unable to load shared library
/home/bonkrad/bin/R/lib/R/library/ROracle/libs/ROracle.so":
/home/bonkrad/bin/R/lib/R/library/ROracle/libs/ROracle.so: undefined 
symbol: sqlca
Error in library(ROracle) : .First.lib failed

What is wrong? Is an error on ROracle side or on R side?

Thanks in advance,

Rado



-- 
Radoslav Bonk
European Commission - DG Joint Research Centre (JRC)
Institute for Environment and Sustainability (IES)
LM Unit - Natural Hazards
Weather Driven Natural Hazards Action
Via E. Fermi, TP 261, 21020 Ispra (Va), Italy
Tel.: 0039-0332-786013
Fax: 0039-0332-786653
Webpage: http://natural-hazards.jrc.it/floods/



From Soichi.Hayashi at acxiom.com  Mon Jul 12 17:09:42 2004
From: Soichi.Hayashi at acxiom.com (Hayashi Soichi - shayas)
Date: Mon, 12 Jul 2004 10:09:42 -0500
Subject: [R] How can I package R into RPM?
Message-ID: <EA80FFF5E80CD5118A81009027DE9DFC0F1DE8DC@conmsx05.corp.acxiom.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040712/8963d2d2/attachment.pl

From pernilla.karlsson at mednut.ki.se  Mon Jul 12 17:17:00 2004
From: pernilla.karlsson at mednut.ki.se (Pernilla Karlsson)
Date: Mon, 12 Jul 2004 17:17:00 +0200
Subject: [R] Excel file
Message-ID: <ENEMJICLOKFKLLMBDLHLOEIMCBAA.pernilla.karlsson@mednut.ki.se>

Hi,

How do I open an excel file in R? I have save the excel file in unicode text
format, but it is not possible to open the file in R.

/Pernilla



From dj at research.bell-labs.com  Mon Jul 12 17:16:08 2004
From: dj at research.bell-labs.com (David James)
Date: Mon, 12 Jul 2004 11:16:08 -0400
Subject: [R] ROracle package error
In-Reply-To: <40F2A810.7010705@jrc.it>;
	from rado.bonk@jrc.it on Mon, Jul 12, 2004 at 05:02:40PM +0200
References: <40F2A810.7010705@jrc.it>
Message-ID: <20040712111607.B2961@jessie.research.bell-labs.com>

Rado Bonk wrote:
> Dear R-users,
> 
> In order to use ROracle (v. 0.5-5) package I compiled R-1.9.1 on Linux 
> (2.4.20-28.9smp) and installed it. I need to use Oracle9i on Solaris. 
> When executing "library(ROracle)" I got the following error message:
> 
>  > library(ROracle)
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
> unable to load shared library
> /home/bonkrad/bin/R/lib/R/library/ROracle/libs/ROracle.so":
> /home/bonkrad/bin/R/lib/R/library/ROracle/libs/ROracle.so: undefined 
> symbol: sqlca

This clearly cannot be an R problem: the undefined symbol is clearly
an Oracle one.  It's possibly an Oracle misconfiguration problem,
but you may need to read the various README's in the source ROracle
distribution (simply untar the source tar file into a temporary
directory and look at the "ROracle/inst" subdirectory.)

Hope this helps,

--
David
> Error in library(ROracle) : .First.lib failed
> 
> What is wrong? Is an error on ROracle side or on R side?
> 
> Thanks in advance,
> 
> Rado
> 
> 
> 
> -- 
> Radoslav Bonk
> European Commission - DG Joint Research Centre (JRC)
> Institute for Environment and Sustainability (IES)
> LM Unit - Natural Hazards
> Weather Driven Natural Hazards Action
> Via E. Fermi, TP 261, 21020 Ispra (Va), Italy
> Tel.: 0039-0332-786013
> Fax: 0039-0332-786653
> Webpage: http://natural-hazards.jrc.it/floods/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Matthias.Templ at statistik.gv.at  Mon Jul 12 17:29:48 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Mon, 12 Jul 2004 17:29:48 +0200
Subject: [R] Excel file
Message-ID: <83536658864BC243BE3C06D7E936ABD501BE186D@xchg1.statistik.gv.at>


 -----Urspr??ngliche Nachricht-----
 Von: TEMPL Matthias 
 Gesendet: Montag, 12. Juli 2004 17:29
 An: 'Pernilla Karlsson'
 Betreff: Re: [R] Excel file
 
 
 It is possible to open the file in R.
 
 ?read.table
 
 excelfile <- read.table("../file.txt", sep=",", header=T)
 
 when you have a komma as seperator and a header in your .txt file.
 
 The seperator and the header should be set correctly.
 
 
 Or save your excel file in the .csv format and do
 
 read.csv(...)
 
 Best,
 Matthias
 
> > -----Urspr??ngliche Nachricht-----
> > Von: Pernilla Karlsson [mailto:pernilla.karlsson at mednut.ki.se]
> > Gesendet: Montag, 12. Juli 2004 17:17
> > An: R-help at stat.math.ethz.ch
> > Betreff: [R] Excel file
> > 
> > 
> > Hi,
> > 
> > How do I open an excel file in R? I have save the excel file
> > in unicode text format, but it is not possible to open the 
> file in R.
> > 
> > /Pernilla
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> > PLEASE 
> > do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
>



From dmurdoch at pair.com  Mon Jul 12 17:30:07 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 11:30:07 -0400
Subject: [R] Excel file
In-Reply-To: <ENEMJICLOKFKLLMBDLHLOEIMCBAA.pernilla.karlsson@mednut.ki.se>
References: <ENEMJICLOKFKLLMBDLHLOEIMCBAA.pernilla.karlsson@mednut.ki.se>
Message-ID: <0eb5f0d6htv01fcih857g31vkqpkodcnsa@4ax.com>

On Mon, 12 Jul 2004 17:17:00 +0200, "Pernilla Karlsson"
<pernilla.karlsson at mednut.ki.se> wrote :

>Hi,
>
>How do I open an excel file in R? I have save the excel file in unicode text
>format, but it is not possible to open the file in R.

See the R Data Import/Export manual (via Help|Manuals).  You probably
want to save in CSV format. 

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Mon Jul 12 17:32:37 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 Jul 2004 17:32:37 +0200
Subject: [R] Excel file
In-Reply-To: <ENEMJICLOKFKLLMBDLHLOEIMCBAA.pernilla.karlsson@mednut.ki.se>
References: <ENEMJICLOKFKLLMBDLHLOEIMCBAA.pernilla.karlsson@mednut.ki.se>
Message-ID: <40F2AF15.1010108@statistik.uni-dortmund.de>

Pernilla Karlsson wrote:

> Hi,
> 
> How do I open an excel file in R? I have save the excel file in unicode text
> format, but it is not possible to open the file in R.
> 
> /Pernilla
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

See the "R Data Import/Export" manual and the Posting Guide cited above.

Uwe Ligges



From marzban at caps.ou.edu  Mon Jul 12 17:45:11 2004
From: marzban at caps.ou.edu (marzban)
Date: Mon, 12 Jul 2004 08:45:11 -0700 (PDT)
Subject: [R] lda()
Message-ID: <Pine.LNX.4.44.0407120844060.7984-100000@x1-6-00-0f-1f-0c-15-4b>


Hello,

For a simple problem with 1 predictor (x) and 2 classes (0 and 1), the
linear discriminant function should be something like
                                                                            
 2(mu_0 - mu_1)/var  x    +    x-independent-terms
                                                                            
where var is the common variance.
                                                                            
Question 1: Why does lda() report only a single "Coefficients of linear 
discriminants" when there are in fact two coefficients (the x-dependent
and the x-independent terms)?
                                                                            
Question 2: And how is that single coefficient computed? It is certainly
not equal to 2(mu_0 -mu_1)/var .
                                                                            
Regards,
Caren
-- 
http://www.nhn.ou.edu/~marzban



From Darren.Shaw at ed.ac.uk  Mon Jul 12 17:45:10 2004
From: Darren.Shaw at ed.ac.uk (Darren Shaw)
Date: Mon, 12 Jul 2004 16:45:10 +0100
Subject: [R] proportions confidence intervals
Message-ID: <5.1.0.14.2.20040712164139.01fec558@staffmail.ed.ac.uk>

Dear R users

this may be a simple question - but i would appreciate any thoughts

does anyone know how you would get one lower and one upper confidence 
interval for a set of data that consists of proportions.  i.e. taking a 
usual confidence interval for normal data would result in the lower 
confidence interval being negative - which is not possible given the data 
(which is constrained between 0 and 1)

i can see how you calculate a upper and lower confidence interval for a 
single proportion, but not for a set of proportions

many thanks


Darren Shaw



-----------------------------------------------------------------
Dr Darren J Shaw
Centre for Tropical Veterinary Medicine (CTVM)
The University of Edinburgh
Scotland, EH25 9RG, UK



From vito_ricci at yahoo.com  Mon Jul 12 17:54:41 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Mon, 12 Jul 2004 17:54:41 +0200 (CEST)
Subject: [R] Excel File
Message-ID: <20040712155441.79226.qmail@web41202.mail.yahoo.com>

Hi,

We just discussed about this matter last week; see the
subject in the mailing list:

[R]Importing an Excel file

If you do not have complicated items with spaces and
special characters and you want some easy copiing on
fly just issue in R

read.delim("clipboard")

after selecting an area in Excel file and pressing
Ctrl-C

as seggested by Petr

or you can you can use read.xls() function included in
the package "gregmisc", but you must install Perl on
your PC. In this way you could import MS Excel file
directly in format xls, without saving it as .csv or
.txt.
Bye
Vito




Hi,

How do I open an excel file in R? I have save the
excel file in unicode text
format, but it is not possible to open the file in R.

/Pernilla

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From roebuck at odin.mdacc.tmc.edu  Mon Jul 12 18:01:49 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Mon, 12 Jul 2004 11:01:49 -0500 (CDT)
Subject: .Platform addition (was Re: [R] where does R search when source()?)
Message-ID: <Pine.OSF.4.58.0407121058490.370151@odin.mdacc.tmc.edu>

On Sun, 11 Jul 2004, Gabor Grothendieck wrote:

> search.path <-
> function(fn,
>          paths = strsplit(Sys.getenv("PATH"), split = ";")[[1]],
>          fsep = "\\") {
>     for(d in paths) {
>         f <- file.path(d, fn, fsep = fsep)
>         if (file.exists(f))
>             return(f)
>     }
>     return(NULL)
> }
>
> source(search.path("myscript.R"))

I glanced this and thought this might be handy to keep for
possible use. To make it less Windows-specific, I was going
to replace Gabor's fsep default value with '.Platform$file.sep'
when I noticed that .Platform doesn't have a '$path.sep'
field. Just missing or available elsewhere?

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From ligges at statistik.uni-dortmund.de  Mon Jul 12 18:06:37 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 Jul 2004 18:06:37 +0200
Subject: [R] pixmapIndexed color question
In-Reply-To: <40F25911.3070607@gmx.ch>
References: <40F25911.3070607@gmx.ch>
Message-ID: <40F2B70D.6080605@statistik.uni-dortmund.de>

Christoph Lehmann wrote:

> Hi
> 
> I use pixmapIndexed
> 
> tmp.vimp <- array(0,c(x.dim,y.dim))
> tmp.vimp <- pixmapIndexed(tmp.vimp, col=rainbow)
> 
> to plot values of a 2D matrix. I 'fill' the pixmapIndexed like:
> 
>     for (x in 1:x.dim) {
>         for (y in 1:y.dim) {
>                     tmp.vimp at index[x,y] <- my.matrix[x,y]
>     }}

I guess you are going to call it like this:
   pixmapIndexed(my.matrix, col=rainbow)

If you change the data after the call to pixmapIndexed(), the color 
information won't be calculated again. See the function definition 
itself for details (as well as the help page).

Uwe Ligges


> 
> how can I define, that the colors are painted e.g. according the rainbow 
> palette?
> 
> plot(tmp.vimp) paints all 'pixels' in red even though I specified it 
> with col=rainbow (see above)
> 
> many thanks
> 
> cheers
> 
> christoph
> 
> p.s. is there an easier method for 'painting' the values of a 2d matrix?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Mon Jul 12 18:34:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 12:34:29 -0400
Subject: .Platform addition (was Re: [R] where does R search when
	sour ce ()?)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF801F@usrymx25.merck.com>

> From: Paul Roebuck
> 
> On Sun, 11 Jul 2004, Gabor Grothendieck wrote:
> 
> > search.path <-
> > function(fn,
> >          paths = strsplit(Sys.getenv("PATH"), split = ";")[[1]],
> >          fsep = "\\") {
> >     for(d in paths) {
> >         f <- file.path(d, fn, fsep = fsep)
> >         if (file.exists(f))
> >             return(f)
> >     }
> >     return(NULL)
> > }
> >
> > source(search.path("myscript.R"))
> 
> I glanced this and thought this might be handy to keep for
> possible use. To make it less Windows-specific, I was going
> to replace Gabor's fsep default value with '.Platform$file.sep'
> when I noticed that .Platform doesn't have a '$path.sep'
> field. Just missing or available elsewhere?

The fsep is fine, as file.path() has the logical default (so I don't know
why Gabor had to specify it).  The bigger problem (for me) is delimiter for
PATH (used in the `sep' argument for the strsplit() call):  It's ";" on
Windows and ":" on *nix.  Don't know about other OSes that R runs on.

Andy



From dmurdoch at pair.com  Mon Jul 12 18:50:30 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 12:50:30 -0400
Subject: .Platform addition (was Re: [R] where does R search when
	source()?)
In-Reply-To: <Pine.OSF.4.58.0407121058490.370151@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0407121058490.370151@odin.mdacc.tmc.edu>
Message-ID: <8tf5f05qic5bd53l5483kftnc4a1mauuh8@4ax.com>

On Mon, 12 Jul 2004 11:01:49 -0500 (CDT), Paul Roebuck
<roebuck at odin.mdacc.tmc.edu> wrote :

>I glanced this and thought this might be handy to keep for
>possible use. To make it less Windows-specific, I was going
>to replace Gabor's fsep default value with '.Platform$file.sep'
>when I noticed that .Platform doesn't have a '$path.sep'
>field. Just missing or available elsewhere?

I'm not sure I follow.  What would be the difference between
.Platform$file.sep and .Platform$path.sep ?

By the way, as far as I know .Platform$file.sep is "/" on all
platforms now.  In Windows R converts these to "\" when necessary.

Duncan Murdoch



From dmurdoch at pair.com  Mon Jul 12 19:04:13 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 13:04:13 -0400
Subject: .Platform addition (was Re: [R] where does R search when
	source()?)
In-Reply-To: <8tf5f05qic5bd53l5483kftnc4a1mauuh8@4ax.com>
References: <Pine.OSF.4.58.0407121058490.370151@odin.mdacc.tmc.edu>
	<8tf5f05qic5bd53l5483kftnc4a1mauuh8@4ax.com>
Message-ID: <r2h5f0po0fmrgm4ao1dh7khotpv62r4730@4ax.com>

On Mon, 12 Jul 2004 12:50:30 -0400, Duncan Murdoch <dmurdoch at pair.com>
wrote :

>I'm not sure I follow.  What would be the difference between
>.Platform$file.sep and .Platform$path.sep ?

Stupid me:  path.sep would be the separator between paths in the PATH
variable.

Duncan Murdoch



From Stefano.Guazzetti at ausl.re.it  Mon Jul 12 19:14:52 2004
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Mon, 12 Jul 2004 19:14:52 +0200
Subject: R: [R] proportions confidence intervals
Message-ID: <F298786BF61DE64590054AF31EA1B4C8016D2088@PEPI.ausl.org>

You should consider "prop.test" or  "binom.test". 
The problem you will find is that these functions are 
not intended to do what you want but to give you one
confidence interval at a time.

However a starting point could be :

 I<-sample(1:50) #the numerator
 N<-sample(50:200, 50) #the denominator
 conf.intervals<-t( sapply(
	mapply(binom.test, SIMPLIFY=F, x=I, n=N), "[[", "conf.int") )

 cbind(I, N, P=I/N, conf.int)



best whishes, 

Stefano


-----Messaggio originale-----
Da: Darren Shaw [mailto:Darren.Shaw at ed.ac.uk]
Inviato: luned?? 12 luglio 2004 17.45
A: r-help at stat.math.ethz.ch
Oggetto: [R] proportions confidence intervals


Dear R users

this may be a simple question - but i would appreciate any thoughts

does anyone know how you would get one lower and one upper confidence 
interval for a set of data that consists of proportions.  i.e. taking a 
usual confidence interval for normal data would result in the lower 
confidence interval being negative - which is not possible given the data 
(which is constrained between 0 and 1)

i can see how you calculate a upper and lower confidence interval for a 
single proportion, but not for a set of proportions

many thanks


Darren Shaw



-----------------------------------------------------------------
Dr Darren J Shaw
Centre for Tropical Veterinary Medicine (CTVM)
The University of Edinburgh
Scotland, EH25 9RG, UK

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Mon Jul 12 19:18:59 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jul 2004 10:18:59 -0700
Subject: [R] lme unequal random-effects variances varIdent pdMat Pinheiro
	Bates nlme
In-Reply-To: <Pine.OSX.4.53.0407101928480.2644@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0407101928480.2644@biostat5.ucdavis.edu>
Message-ID: <40F2C803.3040103@pdf.com>

      Have you tried something like the following: 

	mylmeMF0 <- lme( y ~ time, data=DAT, random=~time | id, method="ML")

 

	mylmeMF1 <- lme( y ~ time*sex, data=DAT, random=~time | id, method="ML")

         
               anova(mylemFM0, mylmeMF1)

      Please check Pinheiro and Bates regarding "method".  They explain 
when "ML" and "REML" are appropriate.  I don't have the book handy, and 
I can't remember for sure, but I believe that "REML" is would only be 
apropriate here if "sex" were NOT in the "fixed" model. 

      hope this helps.  spencer graves
   

Jacob Wegelin wrote:

>How does one implement a likelihood-ratio test, to test whether the
>variances of the random effects differ between two groups of subjects?
>
>Suppose your data consist of repeated measures on subjects belonging to
>two groups, say boys and girls, and you are fitting a linear mixed-effects
>model for the response as a function of time.  The within-subject errors
>(residuals) have the same variance in both groups. But the dispersion of
>the random effects differs between the groups.  The boys' random effects
>-- say, the intercepts -- have greater variance than the girls'.  One can
>see this by partitioning the data by sex and fitting two separate models.
>
>The model for the girls,
>
>	library("nlme")
>	mylmeF0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="F")
>
>yields a variance of about one for the random intercepts:
>
>            StdDev    Corr
>(Intercept) 0.9765052 (Intr)
>time        0.1121913 -0.254
>Residual    0.1806528
>
>whereas in the model for the boys, the corresponding variance is ten times
>that amount:
>
>	mylmeM0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="M")
>
>            StdDev     Corr
>(Intercept) 10.1537946 (Intr)
>time         0.1230063 -0.744
>Residual     0.1298910
>
>I would like to use a likelihood ratio to test this difference.  The
>smaller ("null") model would be
>
>	mylme0 <- lme( y ~ time, data=DAT, random=~time | id )  .
>
>This model forces the random intercepts for both boys and girls to come
>from a single normal distribution.
>
>The larger model would allow the boys' and girls' random intercepts (or
>more generally their random effects) to come from separate normal
>distributions with possibly unequal variances.
>
>There must be some straightforward obvious way to fit the larger model,
>but I do not see it.
>
>Pinheiro and Bates, chapter 5.2, show how to model unequal *residual*
>("within-group") variances for the two groups using varIdent.  They also
>tantalizingly say, "The single-level variance function model (5.10) can be
>generalized to multilevel models" (page 206), which seems to suggest that
>a solution to the current problem might exist.
>
>The pdMat classes provide a way to *constrain* the dispersion matrix of
>the random effects, not make it more general.
>
>Of course, one way to test for unequal variances is to apply an F-test for
>equal variances to the random intercepts. If the data are as shown at the
>bottom of this email, the test can be implemented as follows:
>
>	stuff<-as.data.frame(summary(mylme0)$coefficients$random$id)
>	stuff$sex<-factor(substring(row.names(stuff), 1,1))
>	mysplit<-split(stuff[,"(Intercept)"], stuff[,"sex"])
>	ns<-sapply(mysplit, length)
>	vars<-sapply(mysplit, var)
>	p<- 1-pf( vars["M"]/vars["F"], ns["M"]-1, ns["F"]-1)
>
>Alternatively, one could implement a permutation test for the ratio of the
>variances of the random intercepts--these variances derived from the two
>halves of the partitioned data.
>
>But surely there's a direct, model-based way to do this?
>
>Thanks for any suggestions
>
>Jake
>
>P.S. Here is the code by which the "data" were generated.
>
>	nb<-1
>	ntimepts<-3
>	girls<-data.frame(
>		y= rep(-nb:nb , each=ntimepts)
>		,
>		id=rep( paste("F", 1:(2*nb+1), sep=""), each=ntimepts)
>		,
>		time=rep(1:(2*nb+1), length=ntimepts)
>		)
>	boys <-data.frame(
>		y= rep(10*(-nb:nb) , each=ntimepts)
>		,
>		id=rep( paste("M", 1:(2*nb+1), sep=""), each=ntimepts)
>		,
>		time=rep(1:(2*nb+1), length=ntimepts)
>		)
>	DAT<-rbind(girls,boys)
>	DAT$y<-DAT$y + rnorm(nrow(DAT))/5
>	DAT$sex<-factor(substring( as.character(DAT[,"id"]), 1,1))
>	row.names(DAT)<-paste( DAT[,"id"], DAT[,"time"], sep=".")
>
>Jacob A. Wegelin
>Assistant Professor
>Division of Biostatistics, School of Medicine
>University of California, Davis
>One Shields Ave, TB-168
>Davis CA 95616-8638 USA
>http://wegelin.ucdavis.edu/
>jawegelin at ucdavis.edu
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Mon Jul 12 19:19:07 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jul 2004 10:19:07 -0700
Subject: [R] Association between discrete and continuous variable
In-Reply-To: <40F25133.6030207@stats.waikato.ac.nz>
References: <200407120623.i6C6NChO415915@atlas.otago.ac.nz>
	<40F25133.6030207@stats.waikato.ac.nz>
Message-ID: <40F2C80B.2060203@pdf.com>

      My recommendations would depend on the nature of the discrete and 
continuous variables.  What is the application?  Is one variable random 
and the other a control variable that might be used to predict?  If the 
continuous variable is random, what about using the R^2 produced by 
"lm"?  For the case where the discrete variable is random, I just tried 
"www.r-project.org" -> search -> "R site search" for "coefficient of 
determination for glm".  This produced 4 hits, the first of which (dated 
Mon Jul 21 2003) cited 3 papers published between 1991 and 1997. 

      Mutual information 
(http://www.engineering.usu.edu/classes/ece/7680/lecture2/node3.html), 
as you suggest, would be appropriate when you have appropriate models 
for the random nature of both variables, separately and together. 

      More generally, what problem are you trying to solve with this?  
Who will use the numbers?  How will they use them? 

      hope this helps.  spencer graves    

Murray Jorgensen wrote:

> I'm wondering if mutual information al la Cover & Thomas (1991, Ch 2) 
> is not the killer association measure for all types of random variables?
>
> Murray Jorgensen
>
> PS  Yes, this is probably OT!
>
> Richard A. O'Keefe wrote:
>
>> What's the reommended way, in R, to determine the strength of
>> association between a discrete variable and a continuous variable?
>>
>> Yes, I have read the manuals, trawled the archives, &c.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>>
>



From roebuck at odin.mdacc.tmc.edu  Mon Jul 12 19:21:20 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Mon, 12 Jul 2004 12:21:20 -0500 (CDT)
Subject: [R] Re: .Platform addition
In-Reply-To: <8tf5f05qic5bd53l5483kftnc4a1mauuh8@4ax.com>
References: <Pine.OSF.4.58.0407121058490.370151@odin.mdacc.tmc.edu>
	<8tf5f05qic5bd53l5483kftnc4a1mauuh8@4ax.com>
Message-ID: <Pine.OSF.4.58.0407121218060.370151@odin.mdacc.tmc.edu>

On Mon, 12 Jul 2004, Duncan Murdoch wrote:

> On Mon, 12 Jul 2004 11:01:49 -0500 (CDT), Paul Roebuck
> <roebuck at odin.mdacc.tmc.edu> wrote :
>
> >I glanced this and thought this might be handy to keep for
> >possible use. To make it less Windows-specific, I was going
> >to replace Gabor's fsep default value with '.Platform$file.sep'
> >when I noticed that .Platform doesn't have a '$path.sep'
> >field. Just missing or available elsewhere?
>
> By the way, as far as I know .Platform$file.sep is "/" on all
> platforms now.  In Windows R converts these to "\" when necessary.

While that may be great for R itself, it would be of little
help attempting to parse the Windows PATH environment variable.
The actual raw value of '\\' is actually more appropriate in this
case, no?

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From gerifalte28 at hotmail.com  Mon Jul 12 19:28:47 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Mon, 12 Jul 2004 17:28:47 +0000
Subject: [R] Excel file
Message-ID: <BAY2-F18j3nAmct9UQq00095e9e@hotmail.com>

Hi Pernilla

Under menu go to help >manuals > R Data Import/Export and read the section 
on spreadsheet-like data import.
Also you can try  ?read.table

Francisco


>From: "Pernilla Karlsson" <pernilla.karlsson at mednut.ki.se>
>To: <R-help at stat.math.ethz.ch>
>Subject: [R] Excel file
>Date: Mon, 12 Jul 2004 17:17:00 +0200
>
>Hi,
>
>How do I open an excel file in R? I have save the excel file in unicode 
>text
>format, but it is not possible to open the file in R.
>
>/Pernilla
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Mon Jul 12 19:31:39 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 12 Jul 2004 10:31:39 -0700
Subject: [R] Creating a minimal package
References: <3A822319EB35174CA3714066D590DCD504AF8014@usrymx25.merck.com>
Message-ID: <40F2CAFB.8DFD41BB@gene.com>

Folks:

Without entering the debate, just a little addendum to Andy's suggestions and
Duncan's and Gabor's comments about the difficulty of building (simple,
containing no binaries and just a few functions) packages for R.

I have for some time now built such R-code only .rda files. It is a trivial
matter to automatically attach them at startup (through .Rprofile, .First, or
other startup options) so that they are then "transparently" available for use. I
have also found it to be a simple matter to bundle such customized bunches of
functions for "naive" users into a little UI so that they click on a desktop icon
and R opens with the necessary functions and data (and maybe even prompts them,
etc.). You could get quite fancy with this with TK-type stuff, but I haven't
found it necessary to do this.

Please note: I know this is only for small stuff, risks clashes because the
function names are global variables, is not for general distribution, etc.
However, in the "Pareto Principle" spirit or doing things simply when that
suffices, I have found such quick and dirty approaches quite useful. Why bang
your head on a wall if you don't need to?

Cheers,
Bert


"Liaw, Andy" wrote:

> BTW, for functions/objects that you would like to use over and over, but do
> not want to go through the hurdle of packaging, there's a fairly simple way
> to achieve similar effect: save all of them in a .rda file, and when you
> need them, just attach() the .rda file.
>
> Andy
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box



From rolf at math.unb.ca  Mon Jul 12 19:37:55 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 12 Jul 2004 14:37:55 -0300 (ADT)
Subject: [R] proportions confidence intervals
Message-ID: <200407121737.i6CHbt8c005381@erdos.math.unb.ca>


Darren Shaw wrote:

> this may be a simple question - but i would appreciate any thoughts
> 
> does anyone know how you would get one lower and one upper confidence 
> interval for a set of data that consists of proportions.  i.e. taking a 
> usual confidence interval for normal data would result in the lower 
> confidence interval being negative - which is not possible given the data 
> (which is constrained between 0 and 1)
> 
> i can see how you calculate a upper and lower confidence interval for a 
> single proportion, but not for a set of proportions


(1) Your question appears to be a bit ``off topic''.  I.e. it is
really about statistical methodology, rather than about how to
implement methodology in R.

(2) You need to make the scenario clearer.  What do your data
actually consist of?  What are you assuming?

The only reasonable scenario that springs to mind (perhaps this is
merely indicative of poverty of imagination on my part) is that you
have a number of ***independent*** samples, each yielding a sample
proportion, and each coming from the same population (or at least
from populations having the same population proportion ``p''.  I.e.
you have p.hat_1, ..., p.hat_n and from these you wish to calculate a
confidence interval for p.

You need to know the sample ***sizes*** for each sample.  If you
don't, you're screwed.  Full stop.  There is absolutely nothing
sensible you can do.  If you ***do*** know the sample sizes (say k_1,
..., k_n) then the problem is trivial.

You have p.hat_j = x_j/k_j for j = 1, ..., n.

Let x = x_1 + ... + x_n  and k = k_1 + ... + k_n.

Form p.hat = x/k.  (I.e. you ***really*** just have one big
happy sample.)  Then calculate the confidence interval for p
in the usual way:

	p.hat +/- (z-value) * sqrt(p.hat * (1 - p.hat)/k)

If this is not the scenario with which you need to cope, then
you'll have to explain what that scenario actually is.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From jawegelin at ucdavis.edu  Mon Jul 12 19:41:07 2004
From: jawegelin at ucdavis.edu (Jacob Wegelin)
Date: Mon, 12 Jul 2004 10:41:07 -0700 (PDT)
Subject: [R] lme unequal random-effects variances varIdent pdMat Pinheiro
	Bates nlme
In-Reply-To: <40F2C803.3040103@pdf.com>
References: <Pine.OSX.4.53.0407101928480.2644@biostat5.ucdavis.edu>
	<40F2C803.3040103@pdf.com>
Message-ID: <Pine.OSX.4.53.0407121040450.2958@biostat5.ucdavis.edu>


Dear Mr. Graves:

Thank you.  You're right -- I should have said method="ML".

Putting sex into the model as a fixed effect enables us to see if the relationship
between time and y differs between the sexes.  But it doesn't do anything to the
covariance of the random effects.

Jake

On Mon, 12 Jul 2004, Spencer Graves wrote:

>       Have you tried something like the following:
>
> 	mylmeMF0 <- lme( y ~ time, data=DAT, random=~time | id, method="ML")
>
>
>
> 	mylmeMF1 <- lme( y ~ time*sex, data=DAT, random=~time | id, method="ML")
>
>
>                anova(mylemFM0, mylmeMF1)
>
>       Please check Pinheiro and Bates regarding "method".  They explain
> when "ML" and "REML" are appropriate.  I don't have the book handy, and
> I can't remember for sure, but I believe that "REML" is would only be
> apropriate here if "sex" were NOT in the "fixed" model.
>
>       hope this helps.  spencer graves
>
>
> Jacob Wegelin wrote:
>
> >How does one implement a likelihood-ratio test, to test whether the
> >variances of the random effects differ between two groups of subjects?
> >
> >Suppose your data consist of repeated measures on subjects belonging to
> >two groups, say boys and girls, and you are fitting a linear mixed-effects
> >model for the response as a function of time.  The within-subject errors
> >(residuals) have the same variance in both groups. But the dispersion of
> >the random effects differs between the groups.  The boys' random effects
> >-- say, the intercepts -- have greater variance than the girls'.  One can
> >see this by partitioning the data by sex and fitting two separate models.
> >
> >The model for the girls,
> >
> >	library("nlme")
> >	mylmeF0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="F")
> >
> >yields a variance of about one for the random intercepts:
> >
> >            StdDev    Corr
> >(Intercept) 0.9765052 (Intr)
> >time        0.1121913 -0.254
> >Residual    0.1806528
> >
> >whereas in the model for the boys, the corresponding variance is ten times
> >that amount:
> >
> >	mylmeM0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="M")
> >
> >            StdDev     Corr
> >(Intercept) 10.1537946 (Intr)
> >time         0.1230063 -0.744
> >Residual     0.1298910
> >
> >I would like to use a likelihood ratio to test this difference.  The
> >smaller ("null") model would be
> >
> >	mylme0 <- lme( y ~ time, data=DAT, random=~time | id )  .
> >
> >This model forces the random intercepts for both boys and girls to come
> >from a single normal distribution.
> >
> >The larger model would allow the boys' and girls' random intercepts (or
> >more generally their random effects) to come from separate normal
> >distributions with possibly unequal variances.
> >
> >There must be some straightforward obvious way to fit the larger model,
> >but I do not see it.
> >
> >Pinheiro and Bates, chapter 5.2, show how to model unequal *residual*
> >("within-group") variances for the two groups using varIdent.  They also
> >tantalizingly say, "The single-level variance function model (5.10) can be
> >generalized to multilevel models" (page 206), which seems to suggest that
> >a solution to the current problem might exist.
> >
> >The pdMat classes provide a way to *constrain* the dispersion matrix of
> >the random effects, not make it more general.
> >
> >Of course, one way to test for unequal variances is to apply an F-test for
> >equal variances to the random intercepts. If the data are as shown at the
> >bottom of this email, the test can be implemented as follows:
> >
> >	stuff<-as.data.frame(summary(mylme0)$coefficients$random$id)
> >	stuff$sex<-factor(substring(row.names(stuff), 1,1))
> >	mysplit<-split(stuff[,"(Intercept)"], stuff[,"sex"])
> >	ns<-sapply(mysplit, length)
> >	vars<-sapply(mysplit, var)
> >	p<- 1-pf( vars["M"]/vars["F"], ns["M"]-1, ns["F"]-1)
> >
> >Alternatively, one could implement a permutation test for the ratio of the
> >variances of the random intercepts--these variances derived from the two
> >halves of the partitioned data.
> >
> >But surely there's a direct, model-based way to do this?
> >
> >Thanks for any suggestions
> >
> >Jake
> >
> >P.S. Here is the code by which the "data" were generated.
> >
> >	nb<-1
> >	ntimepts<-3
> >	girls<-data.frame(
> >		y= rep(-nb:nb , each=ntimepts)
> >		,
> >		id=rep( paste("F", 1:(2*nb+1), sep=""), each=ntimepts)
> >		,
> >		time=rep(1:(2*nb+1), length=ntimepts)
> >		)
> >	boys <-data.frame(
> >		y= rep(10*(-nb:nb) , each=ntimepts)
> >		,
> >		id=rep( paste("M", 1:(2*nb+1), sep=""), each=ntimepts)
> >		,
> >		time=rep(1:(2*nb+1), length=ntimepts)
> >		)
> >	DAT<-rbind(girls,boys)
> >	DAT$y<-DAT$y + rnorm(nrow(DAT))/5
> >	DAT$sex<-factor(substring( as.character(DAT[,"id"]), 1,1))
> >	row.names(DAT)<-paste( DAT[,"id"], DAT[,"time"], sep=".")
> >
> >Jacob A. Wegelin
> >Assistant Professor
> >Division of Biostatistics, School of Medicine
> >University of California, Davis
> >One Shields Ave, TB-168
> >Davis CA 95616-8638 USA
> >http://wegelin.ucdavis.edu/
> >jawegelin at ucdavis.edu
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>



From spencer.graves at pdf.com  Mon Jul 12 19:44:25 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jul 2004 10:44:25 -0700
Subject: [R] proportions confidence intervals
In-Reply-To: <5.1.0.14.2.20040712164139.01fec558@staffmail.ed.ac.uk>
References: <5.1.0.14.2.20040712164139.01fec558@staffmail.ed.ac.uk>
Message-ID: <40F2CDF9.30904@pdf.com>

      Please see: 

      Brown, Cai and DasGupta (2001) Statistical Science, 16:  101-133 
and (2002) Annals of Statistics, 30:  160-2001 

      They show that the actual coverage probability of the standard 
approximate confidence intervals for a binomial proportion are quite 
poor, while the standard asymptotic theory applied to logits produces 
rather better answers. 

      I would expect "confint.glm" in library(MASS) to give decent 
results, possibly the best available without a very careful study of 
this particular question.  Consider the following: 

  library(MASS)# needed for confint.glm
  library(boot)# needed for inv.logit
  DF10 <- data.frame(y=.1, size=10)
  DF100 <- data.frame(y=.1, size=100)
  fit10 <- glm(y~1, family=binomial, data=DF10, weights=size)
  fit100 <- glm(y~1, family=binomial, data=DF100, weights=size)
  inv.logit(coef(fit10))
 
  (CI10 <- confint(fit10))
  (CI100 <- confint(fit100))
 
  inv.logit(CI10)
  inv.logit(CI100)

      In R 1.9.1, Windows 2000, I got the following: 

>   inv.logit(coef(fit10))
(Intercept)
        0.1
>  
>   (CI10 <- confint(fit10))
Waiting for profiling to be done...
     2.5 %     97.5 %
-5.1122123 -0.5258854
>   (CI100 <- confint(fit100))
Waiting for profiling to be done...
    2.5 %    97.5 %
-2.915193 -1.594401
>  
>   inv.logit(CI10)
      2.5 %      97.5 %
0.005986688 0.371477058
>   inv.logit(CI100)
    2.5 %    97.5 %
0.0514076 0.1687655
>
>   (naiveCI10 <- .1+c(-2, 2)*sqrt(.1*.9/10))
[1] -0.08973666  0.28973666
>   (naiveCI100 <- .1+c(-2, 2)*sqrt(.1*.9/100))
[1] 0.04 0.16

      hope this helps.  spencer graves

Darren Shaw wrote:

> Dear R users
>
> this may be a simple question - but i would appreciate any thoughts
>
> does anyone know how you would get one lower and one upper confidence 
> interval for a set of data that consists of proportions.  i.e. taking 
> a usual confidence interval for normal data would result in the lower 
> confidence interval being negative - which is not possible given the 
> data (which is constrained between 0 and 1)
>
> i can see how you calculate a upper and lower confidence interval for 
> a single proportion, but not for a set of proportions
>
> many thanks
>
>
> Darren Shaw
>
>
>
> -----------------------------------------------------------------
> Dr Darren J Shaw
> Centre for Tropical Veterinary Medicine (CTVM)
> The University of Edinburgh
> Scotland, EH25 9RG, UK
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From mhassan at scitegic.com  Mon Jul 12 19:45:39 2004
From: mhassan at scitegic.com (Moises Hassan)
Date: Mon, 12 Jul 2004 10:45:39 -0700
Subject: [R] Graphics in BATCH CMD mode
Message-ID: <830D8D4719112B418ABBC3A0EBA9581272EA7F@webmail.scitegic.com>

Running R scripts via 'R_exe BATCH CMD inpufile outputfile' works fine
with jpeg commands in Windows, but the jpeg commands give an error under
Linux because GUI is set to none. Is there a way to use jpeg commands in
BATCH CMD in Linux.
Thanks, Moises



From gerifalte28 at hotmail.com  Mon Jul 12 19:44:20 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Mon, 12 Jul 2004 17:44:20 +0000
Subject: [R] multiple hierarchical anova models
Message-ID: <BAY2-F7vDSNpJZMAlQj0000ab59@hotmail.com>

Hi Matthias

Under the main menu try help > manuals > An Introduction to R and read the 
section Statistical Model in R.  This contains a very good general 
background on model syntax in R.  Also try ?aov to see the use of the error 
argument within an ANOVA model for using multiple error strata.

I hope that this helps

Francisco



>From: "Matthias Unterhuber" <MatUnt at gmx.de>
>To: r-help at stat.math.ethz.ch
>Subject: [R] multiple hierarchical anova models
>Date: Mon, 12 Jul 2004 16:34:51 +0200 (MEST)
>
>Hello,
>
>My name is Matthias and I do look for syntax regarding hierarchal anova
>models in R. How can I express that a factor is nested within the
>combination of two other factors A(B,C), e.g. for aov(...)? I did not find
>the corresponding expression. Furthermore, I wanted to ask whether block
>factors have to be specified in a specific way or are they just treated as
>other factors (with no interactions).
>
>Furthermore, in general an overview might be useful for beginners that
>describes the structural equations of more complicated anova-designs
>(hierarchical and block factor designs...) in the syntax of R.
>
>Best wishes and thanks,
>
>Matthias
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html


your life. http://lifeevents.msn.com



From spencer.graves at pdf.com  Mon Jul 12 19:50:22 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jul 2004 10:50:22 -0700
Subject: [R] lme unequal random-effects variances varIdent pdMat Pinheiro
	Bates nlme
In-Reply-To: <Pine.OSX.4.53.0407121040450.2958@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0407101928480.2644@biostat5.ucdavis.edu>
	<40F2C803.3040103@pdf.com>
	<Pine.OSX.4.53.0407121040450.2958@biostat5.ucdavis.edu>
Message-ID: <40F2CF5E.5050405@pdf.com>

      What about: 

	mylmeMF1 <- lme( y ~ time*sex, data=DAT, random=~time*sex | id, method="ML")


   I meant to put "sex" into both "fixed" and "random".  It should work fine, provided the configuration of the data will honestly support estimating everything.  

	  hope this helps.  spencer graves	  

Jacob Wegelin wrote:

>Dear Mr. Graves:
>
>Thank you.  You're right -- I should have said method="ML".
>
>Putting sex into the model as a fixed effect enables us to see if the relationship
>between time and y differs between the sexes.  But it doesn't do anything to the
>covariance of the random effects.
>
>Jake
>
>On Mon, 12 Jul 2004, Spencer Graves wrote:
>
>  
>
>>      Have you tried something like the following:
>>
>>	mylmeMF0 <- lme( y ~ time, data=DAT, random=~time | id, method="ML")
>>
>>
>>
>>	mylmeMF1 <- lme( y ~ time*sex, data=DAT, random=~time | id, method="ML")
>>
>>
>>               anova(mylemFM0, mylmeMF1)
>>
>>      Please check Pinheiro and Bates regarding "method".  They explain
>>when "ML" and "REML" are appropriate.  I don't have the book handy, and
>>I can't remember for sure, but I believe that "REML" is would only be
>>apropriate here if "sex" were NOT in the "fixed" model.
>>
>>      hope this helps.  spencer graves
>>
>>
>>Jacob Wegelin wrote:
>>
>>    
>>
>>>How does one implement a likelihood-ratio test, to test whether the
>>>variances of the random effects differ between two groups of subjects?
>>>
>>>Suppose your data consist of repeated measures on subjects belonging to
>>>two groups, say boys and girls, and you are fitting a linear mixed-effects
>>>model for the response as a function of time.  The within-subject errors
>>>(residuals) have the same variance in both groups. But the dispersion of
>>>the random effects differs between the groups.  The boys' random effects
>>>-- say, the intercepts -- have greater variance than the girls'.  One can
>>>see this by partitioning the data by sex and fitting two separate models.
>>>
>>>The model for the girls,
>>>
>>>	library("nlme")
>>>	mylmeF0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="F")
>>>
>>>yields a variance of about one for the random intercepts:
>>>
>>>           StdDev    Corr
>>>(Intercept) 0.9765052 (Intr)
>>>time        0.1121913 -0.254
>>>Residual    0.1806528
>>>
>>>whereas in the model for the boys, the corresponding variance is ten times
>>>that amount:
>>>
>>>	mylmeM0 <- lme( y ~ time, data=DAT, random=~time | id, subset=sex=="M")
>>>
>>>           StdDev     Corr
>>>(Intercept) 10.1537946 (Intr)
>>>time         0.1230063 -0.744
>>>Residual     0.1298910
>>>
>>>I would like to use a likelihood ratio to test this difference.  The
>>>smaller ("null") model would be
>>>
>>>	mylme0 <- lme( y ~ time, data=DAT, random=~time | id )  .
>>>
>>>This model forces the random intercepts for both boys and girls to come
>>>      
>>>
>>>from a single normal distribution.
>>    
>>
>>>The larger model would allow the boys' and girls' random intercepts (or
>>>more generally their random effects) to come from separate normal
>>>distributions with possibly unequal variances.
>>>
>>>There must be some straightforward obvious way to fit the larger model,
>>>but I do not see it.
>>>
>>>Pinheiro and Bates, chapter 5.2, show how to model unequal *residual*
>>>("within-group") variances for the two groups using varIdent.  They also
>>>tantalizingly say, "The single-level variance function model (5.10) can be
>>>generalized to multilevel models" (page 206), which seems to suggest that
>>>a solution to the current problem might exist.
>>>
>>>The pdMat classes provide a way to *constrain* the dispersion matrix of
>>>the random effects, not make it more general.
>>>
>>>Of course, one way to test for unequal variances is to apply an F-test for
>>>equal variances to the random intercepts. If the data are as shown at the
>>>bottom of this email, the test can be implemented as follows:
>>>
>>>	stuff<-as.data.frame(summary(mylme0)$coefficients$random$id)
>>>	stuff$sex<-factor(substring(row.names(stuff), 1,1))
>>>	mysplit<-split(stuff[,"(Intercept)"], stuff[,"sex"])
>>>	ns<-sapply(mysplit, length)
>>>	vars<-sapply(mysplit, var)
>>>	p<- 1-pf( vars["M"]/vars["F"], ns["M"]-1, ns["F"]-1)
>>>
>>>Alternatively, one could implement a permutation test for the ratio of the
>>>variances of the random intercepts--these variances derived from the two
>>>halves of the partitioned data.
>>>
>>>But surely there's a direct, model-based way to do this?
>>>
>>>Thanks for any suggestions
>>>
>>>Jake
>>>
>>>P.S. Here is the code by which the "data" were generated.
>>>
>>>	nb<-1
>>>	ntimepts<-3
>>>	girls<-data.frame(
>>>		y= rep(-nb:nb , each=ntimepts)
>>>		,
>>>		id=rep( paste("F", 1:(2*nb+1), sep=""), each=ntimepts)
>>>		,
>>>		time=rep(1:(2*nb+1), length=ntimepts)
>>>		)
>>>	boys <-data.frame(
>>>		y= rep(10*(-nb:nb) , each=ntimepts)
>>>		,
>>>		id=rep( paste("M", 1:(2*nb+1), sep=""), each=ntimepts)
>>>		,
>>>		time=rep(1:(2*nb+1), length=ntimepts)
>>>		)
>>>	DAT<-rbind(girls,boys)
>>>	DAT$y<-DAT$y + rnorm(nrow(DAT))/5
>>>	DAT$sex<-factor(substring( as.character(DAT[,"id"]), 1,1))
>>>	row.names(DAT)<-paste( DAT[,"id"], DAT[,"time"], sep=".")
>>>
>>>Jacob A. Wegelin
>>>Assistant Professor
>>>Division of Biostatistics, School of Medicine
>>>University of California, Davis
>>>One Shields Ave, TB-168
>>>Davis CA 95616-8638 USA
>>>http://wegelin.ucdavis.edu/
>>>jawegelin at ucdavis.edu
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>
>>>      
>>>



From flom at ndri.org  Mon Jul 12 20:03:37 2004
From: flom at ndri.org (Peter Flom)
Date: Mon, 12 Jul 2004 14:03:37 -0400
Subject: [R] Vaseplots
Message-ID: <s0f29a66.087@MAIL.NDRI.ORG>

In The American Statistician vol 42 (1988) pages 257 - 280, Yoav
Benjamini investigates some variations on the box plot, including
vaseplots, which maek the width of each box vary proportionally to he
estimated density at a particular point.

Has anyone implemented these in R ?

Thanks as always

Peter



From ccleland at optonline.net  Mon Jul 12 20:19:16 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 12 Jul 2004 14:19:16 -0400
Subject: [R] proportions confidence intervals
In-Reply-To: <40F2CDF9.30904@pdf.com>
References: <5.1.0.14.2.20040712164139.01fec558@staffmail.ed.ac.uk>
	<40F2CDF9.30904@pdf.com>
Message-ID: <40F2D624.9040002@optonline.net>

   Darren also might consider binconf() in library(Hmisc).

 > library(Hmisc)

 > binconf(1, 10, method="all")
            PointEst        Lower     Upper
Exact           0.1  0.002528579 0.4450161
Wilson          0.1  0.005129329 0.4041500
Asymptotic      0.1 -0.085938510 0.2859385

 > binconf(10, 100, method="all")
            PointEst      Lower     Upper
Exact           0.1 0.04900469 0.1762226
Wilson          0.1 0.05522914 0.1743657
Asymptotic      0.1 0.04120108 0.1587989

Spencer Graves wrote:
>      Please see:
>      Brown, Cai and DasGupta (2001) Statistical Science, 16:  101-133 
> and (2002) Annals of Statistics, 30:  160-2001
>      They show that the actual coverage probability of the standard 
> approximate confidence intervals for a binomial proportion are quite 
> poor, while the standard asymptotic theory applied to logits produces 
> rather better answers.
>      I would expect "confint.glm" in library(MASS) to give decent 
> results, possibly the best available without a very careful study of 
> this particular question.  Consider the following:
>  library(MASS)# needed for confint.glm
>  library(boot)# needed for inv.logit
>  DF10 <- data.frame(y=.1, size=10)
>  DF100 <- data.frame(y=.1, size=100)
>  fit10 <- glm(y~1, family=binomial, data=DF10, weights=size)
>  fit100 <- glm(y~1, family=binomial, data=DF100, weights=size)
>  inv.logit(coef(fit10))
> 
>  (CI10 <- confint(fit10))
>  (CI100 <- confint(fit100))
> 
>  inv.logit(CI10)
>  inv.logit(CI100)
> 
>      In R 1.9.1, Windows 2000, I got the following:
> 
>>   inv.logit(coef(fit10))
> 
> (Intercept)
>        0.1
> 
>>  
>>   (CI10 <- confint(fit10))
> 
> Waiting for profiling to be done...
>     2.5 %     97.5 %
> -5.1122123 -0.5258854
> 
>>   (CI100 <- confint(fit100))
> 
> Waiting for profiling to be done...
>    2.5 %    97.5 %
> -2.915193 -1.594401
> 
>>  
>>   inv.logit(CI10)
> 
>      2.5 %      97.5 %
> 0.005986688 0.371477058
> 
>>   inv.logit(CI100)
> 
>    2.5 %    97.5 %
> 0.0514076 0.1687655
> 
>>
>>   (naiveCI10 <- .1+c(-2, 2)*sqrt(.1*.9/10))
> 
> [1] -0.08973666  0.28973666
> 
>>   (naiveCI100 <- .1+c(-2, 2)*sqrt(.1*.9/100))
> 
> [1] 0.04 0.16

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From clint at ecy.wa.gov  Mon Jul 12 20:24:39 2004
From: clint at ecy.wa.gov (Clint Bowman)
Date: Mon, 12 Jul 2004 11:24:39 -0700 (PDT)
Subject: [R] proportions confidence intervals
In-Reply-To: <200407121737.i6CHbt8c005381@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.44.0407121107490.28887-100000@aeolus.ecy.wa.gov>

It seems to me that a transformation is in order since [0,1] can't 
possibly contain a normal distribution without cutting off both tails.

On Mon, 12 Jul 2004, Rolf Turner wrote:

> 
> Darren Shaw wrote:
> 
> > this may be a simple question - but i would appreciate any thoughts
> > 
> > does anyone know how you would get one lower and one upper confidence 
> > interval for a set of data that consists of proportions.  i.e. taking a 
> > usual confidence interval for normal data would result in the lower 
> > confidence interval being negative - which is not possible given the data 
> > (which is constrained between 0 and 1)
> > 
> > i can see how you calculate a upper and lower confidence interval for a 
> > single proportion, but not for a set of proportions
> 
> 
> (1) Your question appears to be a bit ``off topic''.  I.e. it is
> really about statistical methodology, rather than about how to
> implement methodology in R.
> 
> (2) You need to make the scenario clearer.  What do your data
> actually consist of?  What are you assuming?
> 
> The only reasonable scenario that springs to mind (perhaps this is
> merely indicative of poverty of imagination on my part) is that you
> have a number of ***independent*** samples, each yielding a sample
> proportion, and each coming from the same population (or at least
> from populations having the same population proportion ``p''.  I.e.
> you have p.hat_1, ..., p.hat_n and from these you wish to calculate a
> confidence interval for p.
> 
> You need to know the sample ***sizes*** for each sample.  If you
> don't, you're screwed.  Full stop.  There is absolutely nothing
> sensible you can do.  If you ***do*** know the sample sizes (say k_1,
> ..., k_n) then the problem is trivial.
> 
> You have p.hat_j = x_j/k_j for j = 1, ..., n.
> 
> Let x = x_1 + ... + x_n  and k = k_1 + ... + k_n.
> 
> Form p.hat = x/k.  (I.e. you ***really*** just have one big
> happy sample.)  Then calculate the confidence interval for p
> in the usual way:
> 
> 	p.hat +/- (z-value) * sqrt(p.hat * (1 - p.hat)/k)
> 
> If this is not the scenario with which you need to cope, then
> you'll have to explain what that scenario actually is.
> 
> 				cheers,
> 
> 					Rolf Turner
> 					rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600



From andy_liaw at merck.com  Mon Jul 12 20:45:41 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 14:45:41 -0400
Subject: [R] Graphics in BATCH CMD mode
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8028@usrymx25.merck.com>

See ?bitmap.

Andy

> From: Moises Hassan
> 
> Running R scripts via 'R_exe BATCH CMD inpufile outputfile' works fine
> with jpeg commands in Windows, but the jpeg commands give an 
> error under
> Linux because GUI is set to none. Is there a way to use jpeg 
> commands in
> BATCH CMD in Linux.
> Thanks, Moises



From MSchwartz at MedAnalytics.com  Mon Jul 12 20:58:25 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 12 Jul 2004 13:58:25 -0500
Subject: [R] proportions confidence intervals
In-Reply-To: <40F2D624.9040002@optonline.net>
References: <5.1.0.14.2.20040712164139.01fec558@staffmail.ed.ac.uk>
	<40F2CDF9.30904@pdf.com>  <40F2D624.9040002@optonline.net>
Message-ID: <1089658705.3830.6.camel@localhost.localdomain>

FWIW, if the exact intervals are what is desired here, as another poster
has already suggested, binom.test() will get you there:

> binom.test(1, 10)$conf.int
[1] 0.002528579 0.445016117
attr(,"conf.level")
[1] 0.95

> binom.test(10, 100)$conf.int
[1] 0.04900469 0.17622260
attr(,"conf.level")
[1] 0.95

HTH,

Marc Schwartz

On Mon, 2004-07-12 at 13:19, Chuck Cleland wrote:
>    Darren also might consider binconf() in library(Hmisc).
> 
>  > library(Hmisc)
> 
>  > binconf(1, 10, method="all")
>             PointEst        Lower     Upper
> Exact           0.1  0.002528579 0.4450161
> Wilson          0.1  0.005129329 0.4041500
> Asymptotic      0.1 -0.085938510 0.2859385
> 
>  > binconf(10, 100, method="all")
>             PointEst      Lower     Upper
> Exact           0.1 0.04900469 0.1762226
> Wilson          0.1 0.05522914 0.1743657
> Asymptotic      0.1 0.04120108 0.1587989
> 
> Spencer Graves wrote:
> >      Please see:
> >      Brown, Cai and DasGupta (2001) Statistical Science, 16:  101-133 
> > and (2002) Annals of Statistics, 30:  160-2001
> >      They show that the actual coverage probability of the standard 
> > approximate confidence intervals for a binomial proportion are quite 
> > poor, while the standard asymptotic theory applied to logits produces 
> > rather better answers.
> >      I would expect "confint.glm" in library(MASS) to give decent 
> > results, possibly the best available without a very careful study of 
> > this particular question.  Consider the following:
> >  library(MASS)# needed for confint.glm
> >  library(boot)# needed for inv.logit
> >  DF10 <- data.frame(y=.1, size=10)
> >  DF100 <- data.frame(y=.1, size=100)
> >  fit10 <- glm(y~1, family=binomial, data=DF10, weights=size)
> >  fit100 <- glm(y~1, family=binomial, data=DF100, weights=size)
> >  inv.logit(coef(fit10))
> > 
> >  (CI10 <- confint(fit10))
> >  (CI100 <- confint(fit100))
> > 
> >  inv.logit(CI10)
> >  inv.logit(CI100)
> > 
> >      In R 1.9.1, Windows 2000, I got the following:
> > 
> >>   inv.logit(coef(fit10))
> > 
> > (Intercept)
> >        0.1
> > 
> >>  
> >>   (CI10 <- confint(fit10))
> > 
> > Waiting for profiling to be done...
> >     2.5 %     97.5 %
> > -5.1122123 -0.5258854
> > 
> >>   (CI100 <- confint(fit100))
> > 
> > Waiting for profiling to be done...
> >    2.5 %    97.5 %
> > -2.915193 -1.594401
> > 
> >>  
> >>   inv.logit(CI10)
> > 
> >      2.5 %      97.5 %
> > 0.005986688 0.371477058
> > 
> >>   inv.logit(CI100)
> > 
> >    2.5 %    97.5 %
> > 0.0514076 0.1687655
> > 
> >>
> >>   (naiveCI10 <- .1+c(-2, 2)*sqrt(.1*.9/10))
> > 
> > [1] -0.08973666  0.28973666
> > 
> >>   (naiveCI100 <- .1+c(-2, 2)*sqrt(.1*.9/100))
> > 
> > [1] 0.04 0.16



From spencer.graves at pdf.com  Mon Jul 12 21:07:00 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jul 2004 12:07:00 -0700
Subject: [R] proportions confidence intervals
In-Reply-To: <40F2D624.9040002@optonline.net>
References: <5.1.0.14.2.20040712164139.01fec558@staffmail.ed.ac.uk>
	<40F2CDF9.30904@pdf.com> <40F2D624.9040002@optonline.net>
Message-ID: <40F2E154.9020708@pdf.com>

      According to Brown, Cai and DasGupta (cited below), the "exact" 
confidence intervals are hyperconservative, as they are designed to 
produce actual coverage probabilities at least the nominal.  Thus for a 
95% confidence interval, the actual coverage could be 98% or more, 
depending on the true but unknown proportion;  please check their papers 
for exact numbers.  They report that the Wilson procedure performs 
reasonably well, as does the asymptotic logit procedure.  I can't say 
without checking, but I would naively expect that confint.glm would 
likely also be among the leaders. 

      By the way, confint.glm is independent of the parameterization, 
assuming 2*log(likelihood ratio) is approximately chi-square.  It is 
therefore subject to intrinsic nonlinearity but is at least free of 
parameter effects (see, e.g., Bates and Watts (1988) Nonlinear 
Regression Analysis and Its Applications (Wiley)).  To check this, 
consider the following: 

  fit10c <- glm(y~1, family=binomial(link=cloglog), data=DF10, weights=size)
  fit100c <- glm(y~1, family=binomial(link=cloglog), data=DF100, 
weights=size)
  (CI10c <- confint(fit10c))
  (CI100c <- confint(fit100c))
>   1-exp(-exp(CI10c))
      2.5 %      97.5 %
0.005989334 0.371562793
>   1-exp(-exp(CI100c))
     2.5 %     97.5 %
0.05140762 0.16875918

      These are precisely the number reported below with the default 
binomial link = logit. 
      hope this helps.  spencer graves

Chuck Cleland wrote:

>   Darren also might consider binconf() in library(Hmisc).
>
> > library(Hmisc)
>
> > binconf(1, 10, method="all")
>            PointEst        Lower     Upper
> Exact           0.1  0.002528579 0.4450161
> Wilson          0.1  0.005129329 0.4041500
> Asymptotic      0.1 -0.085938510 0.2859385
>
> > binconf(10, 100, method="all")
>            PointEst      Lower     Upper
> Exact           0.1 0.04900469 0.1762226
> Wilson          0.1 0.05522914 0.1743657
> Asymptotic      0.1 0.04120108 0.1587989
>
> Spencer Graves wrote:
>
>>      Please see:
>>      Brown, Cai and DasGupta (2001) Statistical Science, 16:  101-133 
>> and (2002) Annals of Statistics, 30:  160-2001
>>      They show that the actual coverage probability of the standard 
>> approximate confidence intervals for a binomial proportion are quite 
>> poor, while the standard asymptotic theory applied to logits produces 
>> rather better answers.
>>      I would expect "confint.glm" in library(MASS) to give decent 
>> results, possibly the best available without a very careful study of 
>> this particular question.  Consider the following:
>>  library(MASS)# needed for confint.glm
>>  library(boot)# needed for inv.logit
>>  DF10 <- data.frame(y=.1, size=10)
>>  DF100 <- data.frame(y=.1, size=100)
>>  fit10 <- glm(y~1, family=binomial, data=DF10, weights=size)
>>  fit100 <- glm(y~1, family=binomial, data=DF100, weights=size)
>>  inv.logit(coef(fit10))
>>
>>  (CI10 <- confint(fit10))
>>  (CI100 <- confint(fit100))
>>
>>  inv.logit(CI10)
>>  inv.logit(CI100)
>>
>>      In R 1.9.1, Windows 2000, I got the following:
>>
>>>   inv.logit(coef(fit10))
>>
>>
>> (Intercept)
>>        0.1
>>
>>>  
>>>   (CI10 <- confint(fit10))
>>
>>
>> Waiting for profiling to be done...
>>     2.5 %     97.5 %
>> -5.1122123 -0.5258854
>>
>>>   (CI100 <- confint(fit100))
>>
>>
>> Waiting for profiling to be done...
>>    2.5 %    97.5 %
>> -2.915193 -1.594401
>>
>>>  
>>>   inv.logit(CI10)
>>
>>
>>      2.5 %      97.5 %
>> 0.005986688 0.371477058
>>
>>>   inv.logit(CI100)
>>
>>
>>    2.5 %    97.5 %
>> 0.0514076 0.1687655
>>
>>>
>>>   (naiveCI10 <- .1+c(-2, 2)*sqrt(.1*.9/10))
>>
>>
>> [1] -0.08973666  0.28973666
>>
>>>   (naiveCI100 <- .1+c(-2, 2)*sqrt(.1*.9/100))
>>
>>
>> [1] 0.04 0.16
>
>



From flom at ndri.org  Mon Jul 12 21:17:06 2004
From: flom at ndri.org (Peter Flom)
Date: Mon, 12 Jul 2004 15:17:06 -0400
Subject: [R] proportions confidence intervals
Message-ID: <s0f2ab85.050@MAIL.NDRI.ORG>

There's also an article by Agresti and Coull

author = {Alan Agresti and B. A. Coull},
title = {Approximate is better than "exact" for interval estimation of
binomial proportions},
   journal = {American Statistician},
   year = {1998},
   volume = {52},
   number = {},
   pages = {119-126},

which may be of interest.

Peter


Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



>>> Spencer Graves <spencer.graves at pdf.com> 7/12/2004 3:07:00 PM >>>
      According to Brown, Cai and DasGupta (cited below), the "exact" 
confidence intervals are hyperconservative, as they are designed to 
produce actual coverage probabilities at least the nominal.  Thus for a

95% confidence interval, the actual coverage could be 98% or more, 
depending on the true but unknown proportion;  please check their
papers 
for exact numbers.  They report that the Wilson procedure performs 
reasonably well, as does the asymptotic logit procedure.  I can't say 
without checking, but I would naively expect that confint.glm would 
likely also be among the leaders. 

      By the way, confint.glm is independent of the parameterization, 
assuming 2*log(likelihood ratio) is approximately chi-square.  It is 
therefore subject to intrinsic nonlinearity but is at least free of 
parameter effects (see, e.g., Bates and Watts (1988) Nonlinear 
Regression Analysis and Its Applications (Wiley)).  To check this, 
consider the following: 

  fit10c <- glm(y~1, family=binomial(link=cloglog), data=DF10,
weights=size)
  fit100c <- glm(y~1, family=binomial(link=cloglog), data=DF100, 
weights=size)
  (CI10c <- confint(fit10c))
  (CI100c <- confint(fit100c))
>   1-exp(-exp(CI10c))
      2.5 %      97.5 %
0.005989334 0.371562793
>   1-exp(-exp(CI100c))
     2.5 %     97.5 %
0.05140762 0.16875918

      These are precisely the number reported below with the default 
binomial link = logit. 
      hope this helps.  spencer graves

Chuck Cleland wrote:

>   Darren also might consider binconf() in library(Hmisc).
>
> > library(Hmisc)
>
> > binconf(1, 10, method="all")
>            PointEst        Lower     Upper
> Exact           0.1  0.002528579 0.4450161
> Wilson          0.1  0.005129329 0.4041500
> Asymptotic      0.1 -0.085938510 0.2859385
>
> > binconf(10, 100, method="all")
>            PointEst      Lower     Upper
> Exact           0.1 0.04900469 0.1762226
> Wilson          0.1 0.05522914 0.1743657
> Asymptotic      0.1 0.04120108 0.1587989
>
> Spencer Graves wrote:
>
>>      Please see:
>>      Brown, Cai and DasGupta (2001) Statistical Science, 16: 
101-133 
>> and (2002) Annals of Statistics, 30:  160-2001
>>      They show that the actual coverage probability of the standard

>> approximate confidence intervals for a binomial proportion are quite

>> poor, while the standard asymptotic theory applied to logits
produces 
>> rather better answers.
>>      I would expect "confint.glm" in library(MASS) to give decent 
>> results, possibly the best available without a very careful study of

>> this particular question.  Consider the following:
>>  library(MASS)# needed for confint.glm
>>  library(boot)# needed for inv.logit
>>  DF10 <- data.frame(y=.1, size=10)
>>  DF100 <- data.frame(y=.1, size=100)
>>  fit10 <- glm(y~1, family=binomial, data=DF10, weights=size)
>>  fit100 <- glm(y~1, family=binomial, data=DF100, weights=size)
>>  inv.logit(coef(fit10))
>>
>>  (CI10 <- confint(fit10))
>>  (CI100 <- confint(fit100))
>>
>>  inv.logit(CI10)
>>  inv.logit(CI100)
>>
>>      In R 1.9.1, Windows 2000, I got the following:
>>
>>>   inv.logit(coef(fit10))
>>
>>
>> (Intercept)
>>        0.1
>>
>>>  
>>>   (CI10 <- confint(fit10))
>>
>>
>> Waiting for profiling to be done...
>>     2.5 %     97.5 %
>> -5.1122123 -0.5258854
>>
>>>   (CI100 <- confint(fit100))
>>
>>
>> Waiting for profiling to be done...
>>    2.5 %    97.5 %
>> -2.915193 -1.594401
>>
>>>  
>>>   inv.logit(CI10)
>>
>>
>>      2.5 %      97.5 %
>> 0.005986688 0.371477058
>>
>>>   inv.logit(CI100)
>>
>>
>>    2.5 %    97.5 %
>> 0.0514076 0.1687655
>>
>>>
>>>   (naiveCI10 <- .1+c(-2, 2)*sqrt(.1*.9/10))
>>
>>
>> [1] -0.08973666  0.28973666
>>
>>>   (naiveCI100 <- .1+c(-2, 2)*sqrt(.1*.9/100))
>>
>>
>> [1] 0.04 0.16
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From hastie at stanford.edu  Mon Jul 12 21:25:53 2004
From: hastie at stanford.edu (Trevor Hastie)
Date: Mon, 12 Jul 2004 12:25:53 -0700
Subject: [R] Statistical Learning and Data Mining Course
Message-ID: <004301c46846$0c941fd0$ec6640ab@stuk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040712/527ffa3b/attachment.pl

From rolf at math.unb.ca  Mon Jul 12 21:29:57 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 12 Jul 2004 16:29:57 -0300 (ADT)
Subject: [R] proportions confidence intervals
Message-ID: <200407121929.i6CJTvph009083@erdos.math.unb.ca>


There has been a plethora of responses over the past hour or so to a
question posed by Darren Shaw about how to estimate (get a confidence
interval for) a proportion based on a data set consisting of a number
of proportions.  These responses have been all off the point.  I
would suggest to the responders:

			RTFQ

The question was not about how to calculate a confidence interval for
a proportion.  Responders have gone on and on with academic wanking
about alternatives to the ``standard'' procedure, some of which give
better coverage properties (and some of which don't; so-called
``exact'' methods are notoriously bad).

The point of the question was how to combine the information from a
number of (sample) proportions.  If the structure and context are as
I conjectured in my posting then

	(a) this is simple, and

	(b) the combined sample size is almost surely large enough so
	that the simple and easy standard procedure will produce an
	eminently adequate result.  (Thus making the alternative
	approaches even more of an academic wank than they usually are.)

	I think at this point it is worthwhile repeating the
	quote posted a while back by Doug Bates.  (He attributed
	the quote to George Box, but was unable to supply a 
	citation; I wrote to Box asking him about the quote, and
	he said ``Nope.  'Twarn't me.'')  But irrespective of the
	source of the quote, the point it makes is valid:

	``You have a big approximation and a small approximation.  The
	big approximation is your approximation to the problem you
	want to solve.  The small approximation is involved in
	getting the solution to the approximate problem.''

That is to say there are ***many*** effects which will have an impact
on the proportion estimate required.  (Were the samples really random?
Were they really independent?  Were they really all taken from the
same population or populations with the same sample proportion?)  The
impact of such considerations causes the issue of the roughness of
the usual/standard approximate CI for a proportion to pale by
comparison.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From andy_liaw at merck.com  Mon Jul 12 21:47:34 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 15:47:34 -0400
Subject: [R] Vaseplots
Message-ID: <3A822319EB35174CA3714066D590DCD504AF802A@usrymx25.merck.com>

I don't have that article handy, but it sounds like `violin plots' that I've
read (also in Am. Stat.) quite a while ago.  I wrote a S-PLUS function to do
something like it back in the dark ages.  It probably isn't too hard to
modify for use with R.  See if it does something similar:

violin.plot<-function(y, x=NULL, ...) {
    if (is.null(x)) {
        cx <- boxplot(y,style.bxp='old')
        den.y <- ksmooth(y,ker='n')
        polygon(c(cx+40*den.y$y,cx-40*rev(den.y$y)),
                c(den.y$x,rev(den.y$x)),...)
    } else {
        if (!is.factor(x)) x<-factor(x)
        cx <- boxplot(split(y,x),style.bxp='old')
        lev.x<-levels(x)
        wd<-45/length(lev.x)
        for(i in 1:length(lev.x)) {
            den.y<-ksmooth(y[x==lev.x[i]],ker='n')
            polygon(c(cx[i]+wd*den.y$y,cx[i]-wd*rev(den.y$y)),
                    c(den.y$x,rev(den.y$x)),...)
        }
    }
}

[Note that I had to do quite a bit of fudging to get the x-coordinates sort
of right in S-PLUS.  In R this is a LOT easier.]

Andy

> From: Peter Flom
> 
> In The American Statistician vol 42 (1988) pages 257 - 280, Yoav
> Benjamini investigates some variations on the box plot, including
> vaseplots, which maek the width of each box vary proportionally to he
> estimated density at a particular point.
> 
> Has anyone implemented these in R ?
> 
> Thanks as always
> 
> Peter
>



From assaf at u.washington.edu  Mon Jul 12 21:52:58 2004
From: assaf at u.washington.edu (Assaf P Oron)
Date: Mon, 12 Jul 2004 12:52:58 -0700 (PDT)
Subject: [R] Smooth monotone estimation on R
Message-ID: <Pine.LNX.4.43.0407121252580.1882@hymn11.u.washington.edu>

Hi all,

I'm looking for smooth monotone estimation packages, preferably using splines.

I downloaded the 'cobs' package and intend to use it, but since it offers only quadratic splines based on L1 minimization, I'd like to compare its performance to that of a more 'mainstream' cubic-spline, L2-norm minimizing spline. Preferably a smoothing spline.

Does anyone know of such code existing anywhere? Or another smooth monotone alternative?

Thanks in advance,

Assaf Oron
Statistics Department
University of Washington



From feldesmanm at pdx.edu  Mon Jul 12 22:03:59 2004
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Mon, 12 Jul 2004 13:03:59 -0700
Subject: [R] lda()
In-Reply-To: <Pine.LNX.4.44.0407120844060.7984-100000@x1-6-00-0f-1f-0c-1 5-4b>
References: <Pine.LNX.4.44.0407120844060.7984-100000@x1-6-00-0f-1f-0c-15-4b>
Message-ID: <6.0.3.0.2.20040712130125.021e0ec0@pop4.attglobal.net>

At 08:45 AM 7/12/2004, marzban wrote:
 >
 >Hello,
 >
 >For a simple problem with 1 predictor (x) and 2 classes (0 and 1), the
 >linear discriminant function should be something like
 >
 > 2(mu_0 - mu_1)/var  x    +    x-independent-terms
 >
 >where var is the common variance.
 >
 >Question 1: Why does lda() report only a single "Coefficients of linear
 >discriminants" when there are in fact two coefficients (the x-dependent
 >and the x-independent terms)?
 >
 >Question 2: And how is that single coefficient computed? It is certainly
 >not equal to 2(mu_0 -mu_1)/var .
 >
 >Regards,
 >Caren
 >--
 >http://www.nhn.ou.edu/~marzban


Perhaps some reading would be helpful.  I suggest you look first at the 
help file for lda().  Second, I suggest you read Venables and Ripley, MASS, 
4th Edition, where lda() is discussed extensively.  Third, I suggest you 
read Ripley's Pattern Recognition and Neural Networks, where the theory is 
laid out clearly.  Both of these latter books are referenced in lda's help 
file.

Finally, you might want to tell us what version of lda() you're using, what 
version of R you're using, and what platform you're running on.   For all 
we know, you're using a 2-year old version of R and lda, both long 
superceded by vastly improved programs and packages.



From andy_liaw at merck.com  Mon Jul 12 22:08:07 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 16:08:07 -0400
Subject: [R] Smooth monotone estimation on R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF802C@usrymx25.merck.com>

I believe the `mgcv' package has facility for monotone splines.

HTH,
Andy

> From: Assaf P Oron
> 
> Hi all,
> 
> I'm looking for smooth monotone estimation packages, 
> preferably using splines.
> 
> I downloaded the 'cobs' package and intend to use it, but 
> since it offers only quadratic splines based on L1 
> minimization, I'd like to compare its performance to that of 
> a more 'mainstream' cubic-spline, L2-norm minimizing spline. 
> Preferably a smoothing spline.
> 
> Does anyone know of such code existing anywhere? Or another 
> smooth monotone alternative?
> 
> Thanks in advance,
> 
> Assaf Oron
> Statistics Department
> University of Washington
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From jlamack at bol.com.br  Mon Jul 12 22:10:18 2004
From: jlamack at bol.com.br (jlamack)
Date: Mon, 12 Jul 2004 17:10:18 -0300
Subject: [R] simultaneous confidence intervals
Message-ID: <I0R9D6$0791B958A3D957406AE3FCC8CED6804B@bol.com.br>

 Dear all, there is a R function to construct 
simultaneous confidence intervals for multinomial 
proportions?

 Best regards

jl
 
__________________________________________________________________________
Acabe com aquelas janelinhas que pulam na sua tela.
AntiPop-up UOL - ?? gr??tis!
http://antipopup.uol.com.br/



From marzban at caps.ou.edu  Mon Jul 12 22:13:41 2004
From: marzban at caps.ou.edu (marzban)
Date: Mon, 12 Jul 2004 13:13:41 -0700 (PDT)
Subject: [R] lda()
In-Reply-To: <6.0.3.0.2.20040712130125.021e0ec0@pop4.attglobal.net>
Message-ID: <Pine.LNX.4.44.0407121308510.8411-100000@x1-6-00-0f-1f-0c-15-4b>


> Perhaps some reading would be helpful.  I suggest you look first at the 
> help file for lda().  Second, I suggest you read Venables and Ripley, MASS, 
> 4th Edition, where lda() is discussed extensively.  Third, I suggest you 
> read Ripley's Pattern Recognition and Neural Networks, where the theory is 
> laid out clearly.  Both of these latter books are referenced in lda's help 
> file.

I am quite familiar with all of these references. The theory behind LDA 
is not where the problem is - I'm comfortable with that. The problem is 
that I do not know what R is computing when it prints "Coefficients of 
linear discriminants". (According to the source code (lda.R), it's 
x$scaling, but I don't know what that is either.) 

> Finally, you might want to tell us what version of lda() you're using, what 
> version of R you're using, and what platform you're running on.   For all 
> we know, you're using a 2-year old version of R and lda, both long 
> superceded by vastly improved programs and packages. 

R-1.9.1 on linux

Caren



From biocperi at yahoo.com  Mon Jul 12 22:22:14 2004
From: biocperi at yahoo.com (S Peri)
Date: Mon, 12 Jul 2004 13:22:14 -0700 (PDT)
Subject: [R] Excel file
In-Reply-To: <BAY2-F18j3nAmct9UQq00095e9e@hotmail.com>
Message-ID: <20040712202214.57665.qmail@web50002.mail.yahoo.com>

Hi Group, 
 I have a set of number (~300) and I want to find the
unique numbers in it. Basically I want to get rid of
duplicate numbers. Is there a function in R to do
this. 

Please help. 

thank you

SP




--- F Z <gerifalte28 at hotmail.com> wrote:
> Hi Pernilla
> 
> Under menu go to help >manuals > R Data
> Import/Export and read the section 
> on spreadsheet-like data import.
> Also you can try  ?read.table
> 
> Francisco
> 
> 
> >From: "Pernilla Karlsson"
> <pernilla.karlsson at mednut.ki.se>
> >To: <R-help at stat.math.ethz.ch>
> >Subject: [R] Excel file
> >Date: Mon, 12 Jul 2004 17:17:00 +0200
> >
> >Hi,
> >
> >How do I open an excel file in R? I have save the
> excel file in unicode 
> >text
> >format, but it is not possible to open the file in
> R.
> >
> >/Pernilla
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
>
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From Benjamin.STABLER at odot.state.or.us  Mon Jul 12 22:24:57 2004
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Mon, 12 Jul 2004 13:24:57 -0700
Subject: [R] text editor for R
Message-ID: <76A000A82289D411952F001083F9DD06047FE7A4@exsalem4-bu.odot.state.or.us>

JEdit has an R syntax highlighting file at http://community.jedit.org.  It
is listed as a file pretty far down on the right side menus as "R Edit Mode
- Extensive Version".

Ben Stabler

-----Original Message-----
From: Yi-Xiong Sean Zhou [mailto:yzhou at sdsc.edu] 
Sent: Wednesday, July 07, 2004 3:48 PM
To: r-help at stat.math.ethz.ch
Subject: [R] text editor for R


Hi, 

 

What is the best text editor for programming in R? I am using JEdit as the
text editor, however, it does not have anything specific for R. It will be
nice to have a developing environment where the keywords are highlighted,
plus some other debugging functions. 

 

Yi-Xiong

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Benjamin.STABLER at odot.state.or.us  Mon Jul 12 22:37:12 2004
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Mon, 12 Jul 2004 13:37:12 -0700
Subject: [R] text editor for R - summary on R-WinEdt 
Message-ID: <76A000A82289D411952F001083F9DD06047FE7A5@exsalem4-bu.odot.state.or.us>

I implemented Uwe's R-WinEdt package as a closer to true WinEdt mode so that
WinEdt could be used with other modes as well.  I sent Uwe the
implementation and we talked a little about cleaning it up, but I haven't
gotten around to it and I don't think he has either.  It is still a little
messy as Uwe noted below but it works well.  There is no code changes, just
running a WinEdt macro and editing a few start up files.  Below are the
instructions.  I'll post all the required files (rwinedt2.zip file) on our
website at: http://www.odot.state.or.us/tddtpau/R.html.  

All the best,
Ben Stabler


Customizing R-WinEdt Mode
Ben Stabler 12/19/03

1) Install R-WinEdt as instructed.

2) Unzip rwinedt2.zip

3) Run R-Mode.edt macro from the WinEdt interface.

4) Add the following lines to your Rprofile file (under R\etc)

options(pager="c:/program files/winedt team/winedt/winedt.exe")
options(editor="c:/program files/winedt team/winedt/winedt.exe")

5) Open WinEdt.btn and add this to the end of the list of bitmaps

246 %B\Bitmaps\Buttons\R-history.bmp
247 %B\Bitmaps\Buttons\R-paste.bmp
248 %B\Bitmaps\Buttons\R-source.bmp
249 %B\Bitmaps\Buttons\R-script.bmp

6) Open WinEdt.img and add this to the end of the list of bitmaps

246 %B\Bitmaps\Images\R_history.bmp
247 %B\Bitmaps\Images\R_paste.bmp
248 %B\Bitmaps\Images\R_source.bmp
249 %B\Bitmaps\Images\R_script.bmp

7) Add the R menu items to the Default WinEdt Toolbar by right
 clicking on the toolbar.  Then select Enter Toolbar Setup.
 Finally, click the R buttons (there are four) and add them one
 at a time to the toolbar.  




-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Wednesday, July 07, 2004 11:56 PM
To: r-help at stat.math.ethz.ch
Cc: wangk at maths.anu.edu.au; d.scott at auckland.ac.nz; maj at stats.waikato.ac.nz;
andy_liaw at merck.com
Subject: Re: [R] text editor for R - summary on R-WinEdt 


Dear all,

let me try to summarize this thread's R-WinEdt related messages and give 
a few comments:



Murray Jorgensen wrote:

 > I tried R-WinEdt a few years ago, but as I remember it interfered with
 > my usual use of WinEdt which is as a front end to MiKTeX. Is there a
 > way to use WinEdt both ways?

Yes, as already answered by some others ...

There are plans to be able to have an R mode in the usual WinEdt 
setting, so R's highlighting will adapt to the current document 
settings, but I don't know when there will be time to implement that in 
a clean manner.



David Scott wrote [in response to Murray Jorgensen]:

 > This problem annoyed me for a while too. My solution (which is not
 > perhaps ideal) is this. You want two different incarnations of WinEdt,
 > one for TeX, the other for R. On the desktop I have a shortcut to
 > WinEdt which is the one for TeX stuff. I open the other one with R
 > syntax highlighting etc by starting R and using library(RWinEdt). To
 > do this you have to install the RWinEdt package and SWinRegistry. This
 > is all well explained in the ReadMe.txt for RWinEdt.
 >
 > I think with the right additions to the Target field in a shortcut to
 > WinEdt you can call up the incarnation of WinEdt that is suitable for
 > R. I haven't done that. You would then have two shortcuts to WinEdt,
 > one for your TeX stuff, one for R.

Thanks for this detailed and accurate description.



Liaw, Andy wrote:

 > Uwe would be the authority on this 8-), but my impression is that if
 > you keep two separate shortcuts, you should be fine.  The one for
 > R-WinEdt has flags that sets it up for R, which should not be used
 > in the one for MikTeX.

Indeed.



Kevin Wang wrote:

 > I think Andy is correct.  A few years ago (back in the dark ages --
 > before I discovered Emacs/ESS), I had two short cuts, one calls
 > R-WinEdt (i.e. with flags...etc) and the other with just a normal
 > WinEdt icon.
 >
 > However, I *think* now you can interact R-WinEdt within R directly
 > (I tried the new version about 2 ~ 3 months ago just for fun, and
 > that seemed to be the case, but I can't quite remember *_*).

You can fire up R-WinEdt from R, but I would not call it "interact 
within R directly".



Peter Flom wrote:

 > I use WinEdt for both.  I simply installed it twice, and set up one
 > version for R and one for LaTeX, I have seperate icons on the desktop,
 > with different names, and it works fine.

It is not necessary to have two installations.


Uwe Ligges

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Mon Jul 12 22:38:55 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jul 2004 13:38:55 -0700
Subject: [R] Excel file
In-Reply-To: <20040712202214.57665.qmail@web50002.mail.yahoo.com>
References: <20040712202214.57665.qmail@web50002.mail.yahoo.com>
Message-ID: <40F2F6DF.7010106@pdf.com>

?unique

S Peri wrote:

>Hi Group, 
> I have a set of number (~300) and I want to find the
>unique numbers in it. Basically I want to get rid of
>duplicate numbers. Is there a function in R to do
>this. 
>
>Please help. 
>
>thank you
>
>SP
>
>
>
>
>--- F Z <gerifalte28 at hotmail.com> wrote:
>  
>
>>Hi Pernilla
>>
>>Under menu go to help >manuals > R Data
>>Import/Export and read the section 
>>on spreadsheet-like data import.
>>Also you can try  ?read.table
>>
>>Francisco
>>
>>
>>    
>>
>>>From: "Pernilla Karlsson"
>>>      
>>>
>><pernilla.karlsson at mednut.ki.se>
>>    
>>
>>>To: <R-help at stat.math.ethz.ch>
>>>Subject: [R] Excel file
>>>Date: Mon, 12 Jul 2004 17:17:00 +0200
>>>
>>>Hi,
>>>
>>>How do I open an excel file in R? I have save the
>>>      
>>>
>>excel file in unicode 
>>    
>>
>>>text
>>>format, but it is not possible to open the file in
>>>      
>>>
>>R.
>>    
>>
>>>/Pernilla
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>      
>>>
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>    
>>
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>>      
>>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>
>>    
>>
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From rpeng at jhsph.edu  Mon Jul 12 22:49:55 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 12 Jul 2004 16:49:55 -0400
Subject: [R] lda()
In-Reply-To: <Pine.LNX.4.44.0407121308510.8411-100000@x1-6-00-0f-1f-0c-15-4b>
References: <Pine.LNX.4.44.0407121308510.8411-100000@x1-6-00-0f-1f-0c-15-4b>
Message-ID: <40F2F973.60507@jhsph.edu>

I haven't done this in years but I think the `scaling' element in the 
list returned by lda is the original data matrix multiplied by the 
rotation matrix from the SVD.  Taking a look at

getAnywhere("lda.default")

will probably answer your question.

-roger

marzban wrote:
>>Perhaps some reading would be helpful.  I suggest you look first at the 
>>help file for lda().  Second, I suggest you read Venables and Ripley, MASS, 
>>4th Edition, where lda() is discussed extensively.  Third, I suggest you 
>>read Ripley's Pattern Recognition and Neural Networks, where the theory is 
>>laid out clearly.  Both of these latter books are referenced in lda's help 
>>file.
> 
> 
> I am quite familiar with all of these references. The theory behind LDA 
> is not where the problem is - I'm comfortable with that. The problem is 
> that I do not know what R is computing when it prints "Coefficients of 
> linear discriminants". (According to the source code (lda.R), it's 
> x$scaling, but I don't know what that is either.) 
> 
> 
>>Finally, you might want to tell us what version of lda() you're using, what 
>>version of R you're using, and what platform you're running on.   For all 
>>we know, you're using a 2-year old version of R and lda, both long 
>>superceded by vastly improved programs and packages. 
> 
> 
> R-1.9.1 on linux
> 
> Caren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From cliff at ms.washington.edu  Mon Jul 12 23:39:44 2004
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Mon, 12 Jul 2004 14:39:44 -0700
Subject: [R] Where does R search when source() ?
References: <200407121004.i6CA3q0o023643@hypatia.math.ethz.ch>
Message-ID: <003101c46858$bf8c9a10$1ba21218@C56909A>

I have found the use of save( ) and attach( ) when supported by a pair
of functions written by my colleague John Miyamoto, move( ) and rm.sv( )
quite useful in managing (1) collections of useful homebrew functions,
(2) project workspaces, and (3) "packages" under development. An .Rdata
file containing these and other handy functions together with a brief
supporting document can be downloaded from a course website:

http://faculty.washington.edu/lunnebor/Stat342/

Click on Exercises to get to the proper page.

**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
cliff at ms.washington.edu





----- Original Message ----- 
From: <r-help-request at stat.math.ethz.ch>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, July 12, 2004 3:04 AM
Subject: R-help Digest, Vol 17, Issue 11


| Send R-help mailing list submissions to
| r-help at stat.math.ethz.ch
|
| To subscribe or unsubscribe via the World Wide Web, visit
| https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| or, via email, send a message with subject or body 'help' to
| r-help-request at stat.math.ethz.ch
|
| You can reach the person managing the list at
| r-help-owner at stat.math.ethz.ch
|
| When replying, please edit your Subject line so it is more specific
| than "Re: Contents of R-help digest..."
|
|
| Today's Topics:
|
|    1. Fwd: newsletter (Martin Wegmann)
|    2. Re: Fwd: newsletter (Martin Wegmann)
|    3. Re: where does R search when source()? (Duncan Murdoch)
|    4. Re: where does R search when source()? (Duncan Murdoch)
|    5. Re: Creating a minimal package (was: where does R search when
|       source()?) (Duncan Murdoch)
|    6. Re: Creating a minimal package (Douglas Bates)
|    7. RE: Interpreting Results of Bootstrapping (Y C Tao)
|    8. Neural Net and SNOW (Ron Piccinini)
|    9. variable definition (Andrew R. Criswell)
|   10. Re: Distribution of Data (was:  your reference on this
|       problem highly appreciated) (Spencer Graves)
|   11. Re: variable definition (Wolski)
|   12. Re: variable definition (Achim Zeileis)
|   13. Re: dyn.load() for windows (Utsav Boobna)
|   14. Re: dyn.load() for windows (Duncan Murdoch)
|   15. RE: where does R search when source()? (Shin, Daehyok)
|   16. Re: variable definition (Gabor Grothendieck)
|   17. Re: where does R search when source()? (Duncan Murdoch)
|   18. RE: where does R search when source()? (Shin, Daehyok)
|   19. How to bring an Splus object into R (Victoria Landsman)
|   20. RE: How to bring an Splus object into R (Liaw, Andy)
|   21. Re: How to bring an Splus object into R (Peter Wilkinson)
|   22. Re: How to bring an Splus object into R (Victoria Landsman)
|   23. Re: Viewport parameters (Paul Murrell)
|   24. Re: Creating a minimal package (was: where does R search when
|       source()?) (Gabor Grothendieck)
|   25. WinXP "developer" asks: Tcl/Tk (Rcmdr) under OS X?
|       (White, Charles E WRAIR-Wash DC)
|   26. Re: WinXP "developer" asks: Tcl/Tk (Rcmdr) under OS X?
|       (Ulises Mora Alvarez)
|   27. Re: Creating a minimal package (was: where does R search when
|       source()?) (Duncan Murdoch)
|   28. Re: Creating a minimal package (was: where does R search when
|       source()?) (Gabor Grothendieck)
|   29. Association between discrete and continuous variable
|       (Richard A. O'Keefe)
|   30. Re: Creating a minimal package (Uwe Ligges)
|   31. Re: Association between discrete and continuous variable
|       (Jonathan Baron)
|   32. lme unequal random-effects variances varIdent pdMat Pinheiro
|       Bates nlme (Jacob Wegelin)
|   33. Re: Association between discrete and continuous variable
|       (Murray Jorgensen)
|   34. Nested source()s (Murray Jorgensen)
|   35. pixmapIndexed color question (Christoph Lehmann)
|
|
| ----------------------------------------------------------------------
|
| Message: 1
| Date: Sun, 11 Jul 2004 13:10:36 +0200
| From: Martin Wegmann <wegmann_mailinglist at gmx.net>
| Subject: [R] Fwd: newsletter
| To: "R-list" <r-help at stat.math.ethz.ch>
| Message-ID: <200407111310.36708.wegmann_mailinglist at gmx.net>
| Content-Type: text/plain;  charset="iso-8859-1"
|
|
|
| ----------  Forwarded Message  ----------
|
| Subject: newsletter
| Date: Sunday 11 July 2004 05:38
| From: Thomas Lumley <tlumley at u.washington.edu>
| To: r-announce at r-project.org
|
| The new issue of the R Newsletter (1/2004) is out on
|  http://www.r-project.org/
|
|          -thomas
|
| Thomas Lumley Assoc. Professor, Biostatistics
| tlumley at u.washington.edu University of Washington, Seattle
|
| _______________________________________________
| R-announce at stat.math.ethz.ch mailing list
| https://www.stat.math.ethz.ch/mailman/listinfo/r-announce
|
|
|
| ------------------------------
|
| Message: 2
| Date: Sun, 11 Jul 2004 13:16:52 +0200
| From: Martin Wegmann <wegmann_mailinglist at gmx.net>
| Subject: Re: [R] Fwd: newsletter
| To: r-help at stat.math.ethz.ch
| Message-ID: <200407111316.52663.wegmann_mailinglist at gmx.net>
| Content-Type: text/plain;  charset="iso-8859-1"
|
| sorry, did not intend to forward this mail to r-help ... Martin
|
| On Sunday 11 July 2004 13:10, Martin Wegmann wrote:
| > ----------  Forwarded Message  ----------
| >
| > Subject: newsletter
| > Date: Sunday 11 July 2004 05:38
| > From: Thomas Lumley <tlumley at u.washington.edu>
| > To: r-announce at r-project.org
| >
| > The new issue of the R Newsletter (1/2004) is out on
| >  http://www.r-project.org/
| >
| >          -thomas
| >
| > Thomas Lumley Assoc. Professor, Biostatistics
| > tlumley at u.washington.edu University of Washington, Seattle
| >
| > _______________________________________________
| > R-announce at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-announce
| >
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide!
| > http://www.R-project.org/posting-guide.html
|
|
|
| ------------------------------
|
| Message: 3
| Date: Sun, 11 Jul 2004 07:58:06 -0400
| From: Duncan Murdoch <dmurdoch at pair.com>
| Subject: Re: [R] where does R search when source()?
| To: sdhyok at email.unc.edu
| Cc: "R, Help" <r-help at stat.math.ethz.ch>
| Message-ID: <6na2f0hb599ce32nrhnk09v17j6ur5kin0 at 4ax.com>
| Content-Type: text/plain; charset=us-ascii
|
| On Sat, 10 Jul 2004 23:28:39 -0400, "Shin, Daehyok"
| <sdhyok at email.unc.edu> wrote:
|
| >Considering replies to my question, typical practices of R users
seem:
| >1. Creating a special function to source frequently used scripts.
|
| That's not right.  The practice I was describing is to have frequently
| used code in a function, not in a script.
|
| >2. Creating a personal package containing frequently used scripts.
|
| And here it would be frequently used *functions*.
| >
| >Both of them needs additional steps to edit the function or to
| >create/install the package
| >when a script file is edited or added.
|
| There's no additional step.  You write the function and use it.
|
| Duncan Murdoch
|
|
|
| ------------------------------
|
| Message: 4
| Date: Sun, 11 Jul 2004 08:25:40 -0400
| From: Duncan Murdoch <dmurdoch at pair.com>
| Subject: Re: [R] where does R search when source()?
| To: renaud.lancelot at cirad.fr
| Cc: sdhyok at email.unc.edu, "R, Help" <r-help at stat.math.ethz.ch>, "Liaw,
| Andy" <andy_liaw at merck.com>
| Message-ID: <m2c2f01d2ripcrpnj3i4b292r9bv5eu3oo at 4ax.com>
| Content-Type: text/plain; charset=us-ascii
|
| On Sun, 11 Jul 2004 10:13:52 +0300, Renaud Lancelot
| <renaud.lancelot at cirad.fr> wrote:
|
| >I do agree with you: in my opinion, creating a package is not a
general
| >solution when you just want to save the script of a whole data
analysis
| >for the purpose of, say, a paper or a report.
|
| I agree that this is a good use for a script, but I don't think it's
| what Daehyok was talking about. He wants a library of frequently used
| scripts to be available in multiple projects.   In R, the best way to
| do that isn't to use scripts at all, it's to put the code in
| functions.
|
| The problem with script code that is not in functions is that it needs
| to have hard-coded variable names, and those can have undesirable side
| effects.  But if you start R with an empty workspace, then load data
| for a particular project from a script, collisions are unlikely.
|
| >To meet this goal, I save the script in a text file and I use a text
| >editor with sourcing facilities (e.g. WinEdt + R-WinEdt, Xemacs +
| >ESS,...: see Software ==> Other section on CRAN).
|
| R for Windows will have such an editor built in with the next major
| release (in the fall).
|
| Duncan Murdoch
|
|
|
| ------------------------------
|
| Message: 5
| Date: Sun, 11 Jul 2004 08:27:52 -0400
| From: Duncan Murdoch <dmurdoch at pair.com>
| Subject: Re: [R] Creating a minimal package (was: where does R search
| when source()?)
| To: Gabor Grothendieck <ggrothendieck at myway.com>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <ngc2f0h8up0ip07bshguimh85644ltme39 at 4ax.com>
| Content-Type: text/plain; charset=us-ascii
|
| On Sun, 11 Jul 2004 05:40:33 +0000 (UTC), Gabor Grothendieck
| <ggrothendieck at myway.com> wrote:
|
| >Roger,
| >
| >A list of the steps referred to below would be of interest.
| >I realize the extensions manual exists but what I was
| >thinking of was just a list of the minimal steps you take
| >when you create a package for yourself.
|
| There's really just one step: call package.skeleton().
|
| Duncan Murdoch
|
|
|
| ------------------------------
|
| Message: 6
| Date: Sun, 11 Jul 2004 07:31:37 -0500
| From: Douglas Bates <bates at stat.wisc.edu>
| Subject: Re: [R] Creating a minimal package
| To: Gabor Grothendieck <ggrothendieck at myway.com>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <40F13329.4060905 at stat.wisc.edu>
| Content-Type: text/plain; charset=us-ascii; format=flowed
|
| Gabor Grothendieck wrote:
| > Roger,
| >
| > A list of the steps referred to below would be of interest.
| > I realize the extensions manual exists but what I was
| > thinking of was just a list of the minimal steps you take
| > when you create a package for yourself.
| >
| > Thanks.
|
| It has already been automated.  See
|
| ?package.skeleton
|
|
| >
| > Roger D. Peng <rpeng <at> jhsph.edu> writes:
| >
| > :
| > : In fact, there is an elegant solution, and that is to write a
| > : package.  If this is all for personal use, then writing a package
| > : can be as simple as creating a few directories, copying the
| > : script files, and then running R CMD INSTALL.  I do this all the
| > : time when I have multiple projects that use the same code.
| > :
| > : -roger
| > :
| > : Shin, Daehyok wrote:
| > : > To my knowledge, it is a common practice for users to archive
some script
| > : > files in other directories than current working directory, when
the script
| > : > files are frequently used in many cases. So, it is somewhat
surprising to
| > me
| > : > there is no elegant solution to set up default search paths in
R.
| > : >
| > : > Here is my suggestion.
| > : > According to the setup of Python
(http://docs.python.org/tut/node8.html),
| > : > when source() is called,
| > : >
| > : > 1. Search current working directory.
| > : > 2. If not found, search the directories specified by the
environment
| > : > variable RPATH.
| > : >
| > : > I think this change will help users to manage script files more
easily.
| > What
| > : > do you think of it?
| > : >
| > : > Daehyok Shin
| > : >
| > : >
| > : >>-----Original Message-----
| > : >>From: Liaw, Andy [mailto:andy_liaw <at> merck.com]
| > : >>Sent: Saturday, July 10, 2004 PM 10:07
| > : >>To: 'sdhyok <at> email.unc.edu'; R, Help
| > : >>Subject: RE: [R] where does R search when source()?
| > : >>
| > : >>
| > : >>Not really.  The best I can come up with is something like:
| > : >>
| > : >>runScript <- function(script, dir="", ...) source(file.path(dir,
script,
| > : >>...)
| > : >>scriptdir <- "/path/to/scripts"
| > : >>
| > : >>runScript(scriptdir, "myScript.R")
| > : >>
| > : >>Andy
| > : >>
| > : >>
| > : >>>From: Shin, Daehyok
| > : >>>
| > : >>>The reason I asked is to separate script files from data files.
| > : >>>Usually, I am working in the directory containing data files,
but some
| > : >>>script files are in other shared directories. In the case, is
| > : >>>there any way
| > : >>>to access the script files conveniently without specifying
| > : >>>its absolute
| > : >>>path? In other word, any way to set up default search paths for
script
| > : >>>files?
| > : >>>
| > : >>>Daehyok Shin (Peter)
| > : >>>
| > : >>>
| > : >>>>The former.  No documentation says otherwise, so why would you
| > : >>>>think that it
| > : >>>>might search somewhere else?
| > : >>>>
| > : >>>>Andy
| > : >>>>
| > : >>>>
| > :
>>>>------------------------------------------------------------------
| > : >>>>------------
| > : >>>>Notice:  This e-mail message, together with any attachments,
| > : >>>>contains information of Merck & Co., Inc. (One Merck Drive,
| > : >>>>Whitehouse Station, New Jersey, USA 08889), and/or its
affiliates
| > : >>>>(which may be known outside the United States as Merck Frosst,
| > : >>>>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
| > : >>>>confidential, proprietary copyrighted and/or legally
privileged.
| > : >>>>It is intended solely for the use of the individual or entity
| > : >>>>named on this message.  If you are not the intended recipient,
| > : >>>>and have received this message in error, please notify us
| > : >>>>immediately by reply e-mail and then delete it from your
system.
| > :
>>>>------------------------------------------------------------------
| > : >>>>------------
| > : >>>>
| > : >>>
| > : >>>
| > : >>>
| > : >>
| > :
>>------------------------------------------------------------------
| > : >>------------
| > : >>Notice:  This e-mail message, together with any attachments,
| > : >>contains information of Merck & Co., Inc. (One Merck Drive,
| > : >>Whitehouse Station, New Jersey, USA 08889), and/or its
affiliates
| > : >>(which may be known outside the United States as Merck Frosst,
| > : >>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be
| > : >>confidential, proprietary copyrighted and/or legally privileged.
| > : >>It is intended solely for the use of the individual or entity
| > : >>named on this message.  If you are not the intended recipient,
| > : >>and have received this message in error, please notify us
| > : >>immediately by reply e-mail and then delete it from your system.
| > :
>>------------------------------------------------------------------
| > : >>------------
| > : >>
| > : >
| > : >
| > : > ______________________________________________
| > : > R-help <at> stat.math.ethz.ch mailing list
| > : > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > : > PLEASE do read the posting guide!
http://www.R-project.org/posting-
| > guide.html
| > : >
| > :
| > : ______________________________________________
| > : R-help <at> stat.math.ethz.ch mailing list
| > : https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > : PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
| > :
| > :
| >
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
|
|
|
| ------------------------------
|
| Message: 7
| Date: Sun, 11 Jul 2004 06:55:50 -0700 (PDT)
| From: Y C Tao <nov_tao at yahoo.com>
| Subject: RE: [R] Interpreting Results of Bootstrapping
| To: ted.harding at nessie.mcc.ac.uk, andy_liaw at merck.com
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <20040711135550.22535.qmail at web53506.mail.yahoo.com>
| Content-Type: text/plain; charset=us-ascii
|
| You are right, the outlier caused the problem. Using
| Spearman or Kendall's correlation seems to solve the
| problem. Thanks!
|
| Y. C. Tao
|
| --- Ted.Harding at nessie.mcc.ac.uk wrote:
| > Hi!
| >
| > Simply plot(x1,x2): you will see that there is one
| > point
| > (number 23) at (x1,x2) = (25.34,6.744) which is a
| > very
| > long way from all the other points (which, among
| > themselves,
| > form a somewhat diffuse cluster with some suggestion
| > of
| > further structure).
| >
| > When you bootstrap, the correlation you obtain in
| > any sample
| > will depend on whether or not this outlying point is
| > included
| > in the sample. If it is included, this single point
| > will generate
| > a relatively high value of the correlation
| > coefficient simply
| > because it is such a long way from all the others
| > (i.e. it is
| > highly influential).
| >
| > If it is not included, then the diffuse character of
| > the other
| > points will generate a very low value of the
| > correlation
| > coefficient.
| >
| >   > cor(x1,x2)
| >   [1] 0.7471931
| >   > cor(x1[-23],x2[-23])
| >   [1] 0.03914653
| >
| > Therefore your bootstrap distribution will have two
| > peaks: one
| > peak, around 0.75, corresponding to the bootstrap
| > samples which
| > include this outlying point, and the other, around
| > 0, corresponding
| > to the bootstrap samples which do not include it.
| >
| > This is the explanation and, at the same time, the
| > interpretation.
| >
| > Best wishes,
| > Ted.
| >
| > On 11-Jul-04 Y C Tao wrote:
| > > I tried to bootstrap the correlation between two
| > > variables x1 and x2. The resulting distribution
| > has
| > > two distinct peaks, how should I interprete it?
| > >
| > > The original code is attached.
| > >
| > > Y. C. Tao
| > >
| > > ----------------
| > >
| > > library(boot);
| > >
| > > my.correl<-function(d, i) cor(d[i,1], d[i,2])
| > >
| > >
| >
| x1<-c(-2.612,-0.7859,-0.5229,-1.246,1.647,1.647,0.1811,
| > >
| > -0.07097,0.8711,0.4323,0.1721,2.143,4.33,0.5002,
| > >
| > 0.4015,-0.5225,2.538,0.07959,-0.6645,4.521,-1.371,
| > >
| > 0.3327,25.24,-0.5417,2.094,0.6064,-0.4476,-0.5891,
| > >
| >
| -0.08879,-0.9487,-2.459e-05,-0.03887,0.2116,-0.0625,1.555,
| > >
| > 0.2069,-0.2142,-0.807,-0.6499,2.384,-0.02063,1.179,
| > >
| > -0.0003586,-1.408,0.6928,0.689,0.1854,0.4351,0.5663,
| > >        0.07171,-0.07004);
| > >
| > > x2<-c(
| >
| 0.08742,0.2555,-0.00337,0.03995,-1.208,-1.208,-0.001374,
| > >
| > -1.282,1.341,-0.9069,-0.2011,1.557,0.4517,-0.4376,
| > >
| >
| 0.4747,0.04965,-0.1668,-0.6811,-0.7011,-1.457,0.04652,
| > >
| > -1.117,6.744,-1.332,0.1327,-0.1479,-2.303,0.1235,
| >
| > >
| >
| 0.5916,0.05018,-0.7811,0.5869,-0.02608,0.9594,-0.1392,
| > >
| > 0.4089,0.1468,-1.507,-0.6882,-0.1781,0.5434,-0.4957,
| > >
| >
| 0.02557,-1.406,-0.5053,-0.7345,-1.314,0.3178,-0.2108,
| > >        0.4186,-0.03347);
| > >
| > > b<-boot(cbind(x1, x2), my.correl, 2000)
| > > hist(b$t, breaks=50)
| >
| > [The above rearranged to have 7 values in each
| > conplete line]
| >
| >
| >
| >
| --------------------------------------------------------------------
| > E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
| > Fax-to-email: +44 (0)870 167 1972
| > Date: 11-Jul-04
| >  Time: 10:40:34
| > ------------------------------ XFMail
| > ------------------------------
| >
|
|
|
| ------------------------------
|
| Message: 8
| Date: Sun, 11 Jul 2004 17:25:42 +0200 (CEST)
| From: Ron Piccinini <ronpicci at yahoo.fr>
| Subject: [R] Neural Net and SNOW
| To: r-help at stat.math.ethz.ch
| Message-ID: <20040711152542.77987.qmail at web52904.mail.yahoo.com>
| Content-Type: text/plain; charset=iso-8859-1
|
| Hello R masteRs,
|
| I was wondering if somebody had already implemented a
| parallel version of the function Nnet (with the SNOW
| package for instance) and would be willing to share a
| few pointers on how to achieve it. I have a training
| set of dimensions 905,000 X 5. Should I just get more
| RAM and run the nnet on one procesor? Or is there a
| slick way to parallelize the computations?
| I have tried to load the training set on each node and
| have the nnet function run on the master, but it seems
| that the master node will still put the whole training
| set in memory....
|
| Thank you in advance for your suggestions,
|
| Ron Piccinini.
|
|
|
| ------------------------------
|
| Message: 9
| Date: Sun, 11 Jul 2004 22:02:03 +0700 (ICT)
| From: "Andrew R. Criswell" <andrew.c at bu.ac.th>
| Subject: [R] variable definition
| To: r-help at stat.math.ethz.ch
| Message-ID: <32966.169.210.7.172.1089558123.squirrel at email.bu.ac.th>
| Content-Type: text/plain; charset=windows-874
|
| Hello All:
|
| This function obviously fails
|
|     x <- function(z) paste("go", z, sep = ".") <- 10
|     x("now")
|
| But is there a way to define the name of a variable through passing a
| parameter in a function call?
|
| Thanks,
| ANDREW
|
|
|
| ------------------------------
|
| Message: 10
| Date: Sun, 11 Jul 2004 09:04:48 -0700
| From: Spencer Graves <spencer.graves at pdf.com>
| Subject: Re: [R] Distribution of Data (was:  your reference on this
| problem highly appreciated)
| To: Yong Wang <wang at galton.uchicago.edu>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <40F16520.6040902 at pdf.com>
| Content-Type: text/plain; charset=ISO-8859-1; format=flowed
|
|       There are many tools for this, e.g., qqnorm, density, and in
| library(MASS) fitdistr.  Also do a literature search on
transformations
| (especially to transformations to normality) and on mixture
| distributions, esp. Titterington, Smith and Makov (1986) Statistical
| Analysis of Finite Mixture Distributions (Wiley).
|
|       What is the nature of your application?  If you tell us more
about
| the context, many people could tell you which distributions might be
| plausible and which would not be credible except as an approximation,
| e.g., a normal distribution for numbers that can not be negative and
| whose distribution might be positively skewed.
|
|       hope this helps.  spencer graves
| p.s.  PLEASE do read the posting guide!
| http://www.R-project.org/posting-guide.html
|
| Yong Wang wrote:
|
| >please help me on this
| >----- Message Text -----
| >Dear all R users
| >first, sorry for that this question might not be appropriate to ask
here.
| >
| >I wanna know theories or techinques aimed at following questions:
| >
| >I have a sample, say,K(at the range from 0 to 20000); the sample
data's
| >central  moments m(1)---m(j) are estimated(j can be large).
| >also, I can use some methodology to calculate the upper and lower
bound of
| >the probabilty of any interested interval, say, for the interval
| >(400--800)
| >
| >with all these information, I wanna recover the distribution of the
data,
| >at least recover to some approximating  analytic form.Does anybady
know
| >such theory or techiniques?
| >
| >your help will be highly appreciated.
| >best regards
| >yong
| >
| >______________________________________________
| >R-help at stat.math.ethz.ch mailing list
| >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| >PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
| >
| >
|
|
|
| ------------------------------
|
| Message: 11
| Date: Sun, 11 Jul 2004 18:05:29 +0200
| From: "Wolski" <wolski at molgen.mpg.de>
| Subject: Re: [R] variable definition
| To: andrew.c at bu.ac.th, r-help at stat.math.ethz.ch
| Message-ID: <200407111805290512.012F1DE8 at mail.math.fu-berlin.de>
| Content-Type: text/plain; charset="us-ascii"
|
| Hallo!
| ?assign
|
| z<-"now"
| assign(paste("go", z, sep = ".") ,10)
|
|
| Sincerely
| Eryk
|
| *********** REPLY SEPARATOR  ***********
|
| On 7/11/2004 at 10:02 PM Andrew R. Criswell wrote:
|
| >>>Hello All:
| >>>
| >>>This function obviously fails
| >>>
| >>>    x <- function(z) <- 10
| >>>    x("now")
| >>>
| >>>But is there a way to define the name of a variable through passing
a
| >>>parameter in a function call?
| >>>
| >>>Thanks,
| >>>ANDREW
| >>>
| >>>______________________________________________
| >>>R-help at stat.math.ethz.ch mailing list
| >>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| >>>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
|
|
|
| Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic
| Ihnestrasse 63-73 14195 Berlin       'v'
| tel: 0049-30-83875219               /   \
| mail: wolski at molgen.mpg.de        ---W-W---- 
http://www.molgen.mpg.de/~wolski
|
|
|
| ------------------------------
|
| Message: 12
| Date: Sun, 11 Jul 2004 18:11:00 +0200 (CEST)
| From: Achim Zeileis <Achim.Zeileis at wu-wien.ac.at>
| Subject: Re: [R] variable definition
| To: "Andrew R. Criswell" <andrew.c at bu.ac.th>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <Pine.LNX.4.58.0407111809580.6830 at thorin.ci.tuwien.ac.at>
| Content-Type: TEXT/PLAIN; charset=US-ASCII
|
|
| On Sun, 11 Jul 2004, Andrew R. Criswell wrote:
|
| > Hello All:
| >
| > This function obviously fails
| >
| >     x <- function(z) paste("go", z, sep = ".") <- 10
| >     x("now")
| >
| > But is there a way to define the name of a variable through passing
a
| > parameter in a function call?
|
| I'm not exactly sure what you want to do, but looking at
|   ?assign
| might be of some help.
| Z
|
| > Thanks,
| > ANDREW
| >
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
| >
|
|
|
| ------------------------------
|
| Message: 13
| Date: Sun, 11 Jul 2004 09:13:17 -0700 (PDT)
| From: Utsav Boobna <catch_utsav at yahoo.com>
| Subject: Re: [R] dyn.load() for windows
| To: Duncan Murdoch <dmurdoch at pair.com>
| Cc: rhelp <r-help at stat.math.ethz.ch>
| Message-ID: <20040711161317.25358.qmail at web14828.mail.yahoo.com>
| Content-Type: text/plain; charset=us-ascii
|
| Hi,
|
| When I check the dll file by tdump, following error
| message was recieved.
|
| C:\Borland\BCC55\Bin>tdump Sample.dll
| Turbo Dump  Version 5.0.16.12 Copyright (c) 1988, 2000
| Inprise Corporation
|                     Display of File SAMPLE.DLL
| ERROR: Invalid signature for an .EXE file - found
| 0C80, expected 5A4D
|
| Please help.
|
| Cheers,
| Utsav
|
|
| --- Duncan Murdoch <dmurdoch at pair.com> wrote:
| > On Fri, 9 Jul 2004 03:29:55 -0700 (PDT), Utsav
| > Boobna
| > <catch_utsav at yahoo.com> wrote :
| >
| > >Hi
| > >I am using Borland C++ compiler 5.5 and R 1.7.1
| > >
| > >got the dll using
| > >
| > >c:\> bcc32 -u- -6 -O2 -osample.dll -WDE sample.c
| >
| > I don't know the bcc32 command line options.  Can
| > you examine the
| > sample.dll file (using e.g. "tdump sample.dll", if
| > you have tdump, or
| > "objdump -x sample.dll" using the objdump tool from
| > our tools
| > collection), and make sure it really is a DLL file?
| >
| > Once you work out what is necessary to produce a DLL
| > that works,
| > please write up a short description and send it to
| > me to include on my
| > page
| >
| >
| http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/
| >
| > I don't think there's anything there now that would
| > help you, but you
| > might browse it for inspiration...
| >
| > Duncan Murdoch
| >
| > >
| > >
| > >Then in R I used
| > >
| > >> dyn.load("sample.dll")
| > >
| > >Error in dyn.load(x, as.logical(local),
| > >as.logical(now)) :
| > >        unable to load shared library
| > "C:/sample.dll":
| > >  LoadLibrary failure:  %1 ist keine zul??ssige
| > >Win32-Anwendung.
| > >
| > >(Its in German ... meaning "%1 is not a valid Win32
| > >application.")
| > >
| > >
| > >
| > >Thanks,
| > >Utsav
| > >
| > >--- Duncan Murdoch <dmurdoch at pair.com> wrote:
| > >> On Fri, 9 Jul 2004 01:58:27 -0700 (PDT), Utsav
| > >> Boobna
| > >> <catch_utsav at yahoo.com> wrote:
| > >>
| > >> >Hi,
| > >> >   I compiled several C program files on Borland
| > >> C++
| > >> >compiler to get one dll output (as instructed in
| > >> the
| > >> >file readme.package). Now when I try to load
| > this
| > >> >*.dll to R using dyn.load(), then the machine
| > gives
| > >> >the error message "*.dll is not a valid windows
| > >> >data,....". The out put of R is
| > >> >
| > >> >I am working on win2k.
| > >> >What could be the possible reason for that?
| > >>
| > >> Please show us your code and the exact error
| > message
| > >> (using cut and
| > >> paste).  It might also help if you gave an exact
| > >> description of how
| > >> you produced the DLL (though I'm not familiar
| > with
| > >> BC++, someone else
| > >> might be), and gave version numbers of BC++ and
| > R.
| > >>
| > >> Duncan Murdoch
| > >>
| > >
| > >______________________________________________
| > >R-help at stat.math.ethz.ch mailing list
| >
| >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > >PLEASE do read the posting guide!
| > http://www.R-project.org/posting-guide.html
| >
| >
|
|
|
| ------------------------------
|
| Message: 14
| Date: Sun, 11 Jul 2004 12:27:07 -0400
| From: Duncan Murdoch <dmurdoch at pair.com>
| Subject: Re: [R] dyn.load() for windows
| To: Utsav Boobna <catch_utsav at yahoo.com>
| Cc: rhelp <r-help at stat.math.ethz.ch>
| Message-ID: <kvp2f09hbcgpnr5fu3pufln09r9fijtclf at 4ax.com>
| Content-Type: text/plain; charset=us-ascii
|
| On Sun, 11 Jul 2004 09:13:17 -0700 (PDT), Utsav Boobna
| <catch_utsav at yahoo.com> wrote:
|
| >Hi,
| >
| >When I check the dll file by tdump, following error
| >message was recieved.
| >
| >C:\Borland\BCC55\Bin>tdump Sample.dll
| >Turbo Dump  Version 5.0.16.12 Copyright (c) 1988, 2000
| >Inprise Corporation
| >                    Display of File SAMPLE.DLL
| >ERROR: Invalid signature for an .EXE file - found
| >0C80, expected 5A4D
|
| That's a sign that there's something wrong with your bcc32 command.
| It's producing something (an .OBJ file?) that's named SAMPLE.DLL, but
| isn't a true DLL.
|
| You need to check the Borland documentation to find how to create a
| DLL.   Once you work this out and you've got things working well,
| *please* write up the details and send them to me.
|
| Alternatively, use the tools we recommend.  There are lots of people
| here who are familiar with them and can help you to get them to work.
| Borland has a better debugger than gdb and probably produces faster
| code than gcc, but there's a big advantage in using something that
| someone else can help you with.  As far as I know, *you're* the
| world's foremost expert on using BCC32 with R.  If that's not a
| position you feel qualified to hold, then use different tools.
|
| Duncan Murdoch
|
|
|
| ------------------------------
|
| Message: 15
| Date: Sun, 11 Jul 2004 12:41:20 -0400
| From: "Shin, Daehyok" <sdhyok at email.unc.edu>
| Subject: RE: [R] where does R search when source()?
| To: "Duncan Murdoch" <dmurdoch at pair.com>, <renaud.lancelot at cirad.fr>
| Cc: "R, Help" <r-help at stat.math.ethz.ch>
| Message-ID: <OAEOKPIGCLDDHAEMCAKICEHOCPAA.sdhyok at email.unc.edu>
| Content-Type: text/plain; charset="us-ascii"
|
|
| I agree that this is a good use for a script, but I don't think it's
| what Daehyok was talking about. He wants a library of frequently used
| scripts to be available in multiple projects.   In R, the best way to
| do that isn't to use scripts at all, it's to put the code in
| functions.
| What I asked is the way to set up default search paths for source
function,
| whether or not files in the paths contain a set of functions or simple
| script code.
| Daehyok Shin
|
|
|
| ------------------------------
|
| Message: 16
| Date: Sun, 11 Jul 2004 16:47:04 +0000 (UTC)
| From: Gabor Grothendieck <ggrothendieck at myway.com>
| Subject: Re: [R] variable definition
| To: r-help at stat.math.ethz.ch
| Message-ID: <loom.20040711T182945-616 at post.gmane.org>
| Content-Type: text/plain; charset=us-ascii
|
| Wolski <wolski <at> molgen.mpg.de> writes:
|
| >
| > Hallo!
| > ?assign
| >
| > z<-"now"
| > assign(paste("go", z, sep = ".") ,10)
|
| Assuming that you wish to create a variable called go.now with the
| value of 10 in the caller environment to f:
|
|    R> f <- function(z) assign(paste("go", z, sep = "."), 10,
parent.frame())
|    R> f("now")
|    R> go.now
|    [1] 10
|
|
|
| ------------------------------
|
| Message: 17
| Date: Sun, 11 Jul 2004 13:12:31 -0400
| From: Duncan Murdoch <dmurdoch at pair.com>
| Subject: Re: [R] where does R search when source()?
| To: <sdhyok at email.unc.edu>
| Cc: "R, Help" <r-help at stat.math.ethz.ch>
| Message-ID: <9is2f09uuhheps65u8ecufkj5km39upk9p at 4ax.com>
| Content-Type: text/plain; charset=us-ascii
|
| I wrote:
|
| >I agree that this is a good use for a script, but I don't think it's
| >what Daehyok was talking about. He wants a library of frequently used
| >scripts to be available in multiple projects.   In R, the best way to
| >do that isn't to use scripts at all, it's to put the code in
| >functions.
|
| On Sun, 11 Jul 2004 12:41:20 -0400, "Shin, Daehyok"
| <sdhyok at email.unc.edu> wrote:
|
| >What I asked is the way to set up default search paths for source
function,
| >whether or not files in the paths contain a set of functions or
simple
| >script code.
|
| Gabor gave you a way to do that.  I was responding to your suggestion
| that R should be modified to make this more convenient, because
|
| >To my knowledge, it is a common practice for users to archive some
script
| >files in other directories than current working directory, when the
script
| >files are frequently used in many cases. So, it is somewhat
surprising to me
| >there is no elegant solution to set up default search paths in R.
|
| I don't think this is a common practice; if it is, it shouldn't be.
| Frequently used code should be in functions.  There are a lot of ways
| to get those functions into your workspace, but R packages are the
| best one.  There *is* a mechanism (the .libPaths function) for
| specifying a search path for packages.
|
| Duncan Murdoch
|
|
|
| ------------------------------
|
| Message: 18
| Date: Sun, 11 Jul 2004 13:16:40 -0400
| From: "Shin, Daehyok" <sdhyok at email.unc.edu>
| Subject: RE: [R] where does R search when source()?
| To: "Duncan Murdoch" <dmurdoch at pair.com>
| Cc: "R, Help" <r-help at stat.math.ethz.ch>
| Message-ID: <OAEOKPIGCLDDHAEMCAKIEEHPCPAA.sdhyok at email.unc.edu>
| Content-Type: text/plain; charset="us-ascii"
|
| > >Considering replies to my question, typical practices of R users
seem:
| > >1. Creating a special function to source frequently used scripts.
| >
| > That's not right.  The practice I was describing is to have
frequently
| > used code in a function, not in a script.
|
| Here, I meant "scripts " is "script files" whether they contains a
series of
| commands, or reusable functions.
| This practice is not based on other replies, not yours.
|
| >
| > >2. Creating a personal package containing frequently used scripts.
| >
| > And here it would be frequently used *functions*.
| > >
|
| If the script files is a collection of functions, as you said,
creating a
| package can be one solution.
|
| > >Both of them needs additional steps to edit the function or to
| > >create/install the package
| > >when a script file is edited or added.
| >
| > There's no additional step.  You write the function and use it.
|
| Why are there no additional steps?
| You suggested creating and installing a package is the solution to
source
| frequently used functions.
| Then, every time I add/modify a function in a script file, or add new
script
| file, I have to re-create and re-install the package,
| which are additional steps, not directly related with the addition or
| modification.
|
| More fundamental problem here is that the functions may have no common
| context except "frequently used".
| In the case, bundling all the functions into one package may not be a
proper
| choice.
|
| So, I still think creating new package mayb be too heavy solution.
| Why don't we simply extend a little bit the searching range of source
| function?
|
| >
| > Duncan Murdoch
| >
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide!
| > http://www.R-project.org/posting-guide.html
| >
|
|
|
| ------------------------------
|
| Message: 19
| Date: Sun, 11 Jul 2004 22:54:19 +0200
| From: "Victoria Landsman" <msvika at mscc.huji.ac.il>
| Subject: [R] How to bring an Splus object into R
| To: <r-help at stat.math.ethz.ch>
| Message-ID: <009701c46789$3c54fe00$8600a8c0 at home2>
| Content-Type: text/plain
|
| Dear all,
| I like to bring the list created in Splus into R. What is the shortest
way to do this?
| Much thanks, Vicky.
| [[alternative HTML version deleted]]
|
|
|
| ------------------------------
|
| Message: 20
| Date: Sun, 11 Jul 2004 16:06:28 -0400
| From: "Liaw, Andy" <andy_liaw at merck.com>
| Subject: RE: [R] How to bring an Splus object into R
| To: "'Victoria Landsman'" <msvika at mscc.huji.ac.il>,
| r-help at stat.math.ethz.ch
| Message-ID:
| <3A822319EB35174CA3714066D590DCD504AF8013 at usrymx25.merck.com>
| Content-Type: text/plain
|
| >From the `R Data Import/Export' manual, shipped with R, as well as
available
| from the official R web site (last three paragraphs of Section 3.1,
| describing functions in the `foreign' package):
|
| Function read.S which can read binary objects produced by S-PLUS 3.x,
4.x or
| 2000
| on (32-bit) Unix or Windows (and can read them on a di
| erent OS). This is able to read
| many but not all S objects: in particular it can read vectors,
matrices and
| data frames and
| lists containing those.
| Function data.restore reads S-PLUS data dumps (created by data.dump)
with
| the same restrictions (except that dumps from the Alpha platform can
also be
| read).
| It should be possible to read data dumps from S-PLUS 5.x and 6.x
written
| with
| data.dump(oldStyle=T).
| If you have access to S-PLUS, it is usually more reliable to dump the
| object(s) in S-PLUS
| and source the dumpfile in R. For S-PLUS 5.x and 6.x you may need to
use
| dump(...,
| oldStyle=T), and to read in very large objects it may be preferable to
use
| the dumpfile as
| a batch script rather than source.
|
| Please learn to read the manual yourself.
|
| Andy
|
| > From: Victoria Landsman
| >
| > Dear all,
| > I like to bring the list created in Splus into R. What is the
| > shortest way to do this?
| > Much thanks, Vicky.
| > [[alternative HTML version deleted]]
| >
|
|
|
| ------------------------------
|
| Message: 21
| Date: Sun, 11 Jul 2004 16:51:59 -0400
| From: Peter Wilkinson <pwilkinson at videotron.ca>
| Subject: Re: [R] How to bring an Splus object into R
| To: Victoria Landsman <msvika at mscc.huji.ac.il>,
| r-help at stat.math.ethz.ch
| Message-ID: <6.1.1.1.2.20040711165025.01bd87a0 at pop.videotron.ca>
| Content-Type: text/plain; charset=us-ascii; format=flowed
|
| Actually I have wondered about the same but from R to S.  To solve
that I
| have written the data from R into a tab separated file, then imported
it
| into S.
|
| Peter
|
|
| At 04:54 PM 7/11/2004, Victoria Landsman wrote:
| >Dear all,
| >I like to bring the list created in Splus into R. What is the
shortest way
| >to do this?
| >Much thanks, Vicky.
| >         [[alternative HTML version deleted]]
| >
| >______________________________________________
| >R-help at stat.math.ethz.ch mailing list
| >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| >PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
|
|
|
| ------------------------------
|
| Message: 22
| Date: Mon, 12 Jul 2004 00:06:08 +0200
| From: "Victoria Landsman" <msvika at mscc.huji.ac.il>
| Subject: Re: [R] How to bring an Splus object into R
| To: <r-help at stat.math.ethz.ch>
| Message-ID: <00b601c46793$4519f900$8600a8c0 at home2>
| Content-Type: text/plain; charset="iso-8859-1"
|
| Much thanks to all who replied me. I used 'dump' in Splus5 and then
'source'
| in R 1.9.1 (both on Unix) and it works.
| Vicky.
|
|
|
| ----- Original Message -----
| From: "Peter Wilkinson" <pwilkinson at videotron.ca>
| To: "Victoria Landsman" <msvika at mscc.huji.ac.il>;
<r-help at stat.math.ethz.ch>
| Sent: Sunday, July 11, 2004 10:51 PM
| Subject: Re: [R] How to bring an Splus object into R
|
|
| > Actually I have wondered about the same but from R to S.  To solve
that I
| > have written the data from R into a tab separated file, then
imported it
| > into S.
| >
| > Peter
| >
| >
| > At 04:54 PM 7/11/2004, Victoria Landsman wrote:
| > >Dear all,
| > >I like to bring the list created in Splus into R. What is the
shortest
| way
| > >to do this?
| > >Much thanks, Vicky.
| > >         [[alternative HTML version deleted]]
| > >
| > >______________________________________________
| > >R-help at stat.math.ethz.ch mailing list
| > >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > >PLEASE do read the posting guide!
| http://www.R-project.org/posting-guide.html
| >
| >
|
|
|
| ------------------------------
|
| Message: 23
| Date: Mon, 12 Jul 2004 09:09:06 +1200
| From: Paul Murrell <p.murrell at auckland.ac.nz>
| Subject: Re: [R] Viewport parameters
| To: simon.woodhead at bristol.ac.uk
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <40F1AC72.7040307 at stat.auckland.ac.nz>
| Content-Type: text/plain; charset=us-ascii; format=flowed
|
| Hi
|
|
| Simon Woodhead wrote:
| > Hello all,
| >
| > In the Grid addon package from Paul Murrell is there a way of
finding
| > the parameter settings for the viewport you are in? I understand in
| > Lattice there is a function trellis.get.par(), is there something
| > similar for Grid?
|
|
| If you're using R 1.9.something, then get.gpar() should do the trick.
|
| Paul
| -- 
| Dr Paul Murrell
| Department of Statistics
| The University of Auckland
| Private Bag 92019
| Auckland
| New Zealand
| 64 9 3737599 x85392
| paul at stat.auckland.ac.nz
| http://www.stat.auckland.ac.nz/~paul/
|
|
|
| ------------------------------
|
| Message: 24
| Date: Sun, 11 Jul 2004 21:28:44 +0000 (UTC)
| From: Gabor Grothendieck <ggrothendieck at myway.com>
| Subject: Re: [R] Creating a minimal package (was: where does R search
| when source()?)
| To: r-help at stat.math.ethz.ch
| Message-ID: <loom.20040711T231128-574 at post.gmane.org>
| Content-Type: text/plain; charset=us-ascii
|
| Duncan Murdoch <dmurdoch <at> pair.com> writes:
|
| :
| : On Sun, 11 Jul 2004 05:40:33 +0000 (UTC), Gabor Grothendieck
| : <ggrothendieck <at> myway.com> wrote:
| :
| : >Roger,
| : >
| : >A list of the steps referred to below would be of interest.
| : >I realize the extensions manual exists but what I was
| : >thinking of was just a list of the minimal steps you take
| : >when you create a package for yourself.
| :
| : There's really just one step: call package.skeleton().
| :
| : Duncan Murdoch
|
| I was hoping for something that really was that simple but
| I tried and so far it seems that I also must also
|
| 1. when I run skeleton.package realize that I must use the arg
|    path = "library"
|    The example that is shown there appears to omit that.
|
| 2. download and install tools.zip, perl and windows help as listed at:
|
|    http://www.murdoch-sutherland.com/Rtools/
|
| I got tripped up for quite a while when it could not find hhc.exe and
| I finally realized I had not downloaded the windows help distribution.
|
| 3. change the name of the package in the DESCRIPTION file -- it seems
| that the name = arg on package.skeleton did not change it for me.
|
| 4. make changes to the documentation files.  I am just working on this
| now.  Some default null documentation exists but it appears that it
| MUST be modified in order to get a working package so this makes
another
| step.
|
| There maybe other things but its taken me several hours just to get
| this far and I do not yet have a functioning package.
|
| I think it would be handy if everything you need to know to actually
| create a minimal functioning package were in ?skeleton.package
| so that one could create a minimal functioning package without
actually
| reading the extensions manual and then incrementally improve it.
Right
| now there is quite a bit you have to know just to get to that point.
|
| I have so far looked at skeleton.package, readme.packages in rw1091,
| murdoch-suthertherland.com link mentioned above and the extensions
manual
| so the startup to doing this is really a multi-step complex process.
|
| The skeleton.package idea actually seems quite nifty but I think it
| needs more work before one can really claim that its a one-step
process
| to create the example package.
|
|
|
| ------------------------------
|
| Message: 25
| Date: Sun, 11 Jul 2004 17:36:08 -0400
| From: "White, Charles E WRAIR-Wash DC"
| <charles.edwin.white at us.army.mil>
| Subject: [R] WinXP "developer" asks: Tcl/Tk (Rcmdr) under OS X?
| To: <r-help at stat.math.ethz.ch>
| Cc: jfox at mcmaster.ca
| Message-ID:
| <12D0D00E1404D511A4820090274CA09C03FBA6E0 at dasmtyjqf010.amedd.army.mil>
| Content-Type: text/plain
|
| It is my understanding that Tcl/Tk does not come with the base
installation of R under OS X (
http://www.sciviews.org/_rgui/projects/TclTk.html). Is there a simple
way to explain how a user with limited tolerance for computer complexity
can obtain and install Tcl/Tk for OS X?
|
| Thanks.
|
| Chuck
|
| Background: Roughly a third of my target audience uses OS X. I do not
and I do not have access to a machine I could use as a development
platform.
|
| Charles E. White, Senior Biostatistician, MS
| Walter Reed Army Institute of Research
| 503 Robert Grant Ave., Room 1w102
| Silver Spring, MD 20910-1557
| 301 319-9781
| Personal/Professional Site:
http://users.starpower.net/cwhite571/professional/
|
|
| [[alternative HTML version deleted]]
|
|
|
| ------------------------------
|
| Message: 26
| Date: Sun, 11 Jul 2004 19:59:29 -0500 (CDT)
| From: Ulises Mora Alvarez <umalvarez at fata.unam.mx>
| Subject: Re: [R] WinXP "developer" asks: Tcl/Tk (Rcmdr) under OS X?
| To: "White, Charles E WRAIR-Wash DC" <charles.edwin.white at us.army.mil>
| Cc: jfox at mcmaster.ca, r-help at stat.math.ethz.ch
| Message-ID:
| <Pine.LNX.4.44.0407111951240.5455-100000 at athena.fata.unam.mx>
| Content-Type: TEXT/PLAIN; charset=US-ASCII
|
| Take a look at the aqua binary of Tcl/Tk at
|
| http://www.apple.com/downloads/macosx/unix_open_source/
|
|
| Or you could try with the R binary of Jan de Leeuw (which includes
Tcl/Tk)
| at
|
| http://gifi.stat.ucla.edu/pub/
|
| Regards.
|
|
| On Sun, 11 Jul 2004, White, Charles E WRAIR-Wash DC wrote:
|
| > It is my understanding that Tcl/Tk does not come with the base
installation of R under OS X (
http://www.sciviews.org/_rgui/projects/TclTk.html). Is there a simple
way to explain how a user with limited tolerance for computer complexity
can obtain and install Tcl/Tk for OS X?
| >
| > Thanks.
| >
| > Chuck
| >
| > Background: Roughly a third of my target audience uses OS X. I do
not and I do not have access to a machine I could use as a development
platform.
| >
| > Charles E. White, Senior Biostatistician, MS
| > Walter Reed Army Institute of Research
| > 503 Robert Grant Ave., Room 1w102
| > Silver Spring, MD 20910-1557
| > 301 319-9781
| > Personal/Professional Site:
http://users.starpower.net/cwhite571/professional/
| >
| >
| > [[alternative HTML version deleted]]
| >
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
| >
|
| -- 
| Ulises M. Alvarez
| LAB. DE ONDAS DE CHOQUE
| FISICA APLICADA Y TECNOLOGIA AVANZADA
| UNAM
| umalvarez at fata.unam.mx
|
|
|
| ------------------------------
|
| Message: 27
| Date: Sun, 11 Jul 2004 22:22:32 -0400
| From: Duncan Murdoch <dmurdoch at pair.com>
| Subject: Re: [R] Creating a minimal package (was: where does R search
| when source()?)
| To: Gabor Grothendieck <ggrothendieck at myway.com>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <ebr3f098aho62muqapebiplkh1n3prf7et at 4ax.com>
| Content-Type: text/plain; charset=us-ascii
|
| Thanks for the information.  It *should* be that simple; thanks for
| pointing out ways in which it is not.
|
| Some more specific comments below...
|
| On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
| <ggrothendieck at myway.com> wrote:
|
| >Duncan Murdoch <dmurdoch <at> pair.com> writes:
| >
| >:
| >: On Sun, 11 Jul 2004 05:40:33 +0000 (UTC), Gabor Grothendieck
| >: <ggrothendieck <at> myway.com> wrote:
| >:
| >: >Roger,
| >: >
| >: >A list of the steps referred to below would be of interest.
| >: >I realize the extensions manual exists but what I was
| >: >thinking of was just a list of the minimal steps you take
| >: >when you create a package for yourself.
| >:
| >: There's really just one step: call package.skeleton().
| >:
| >: Duncan Murdoch
| >
| >I was hoping for something that really was that simple but
| >I tried and so far it seems that I also must also
| >
| >1. when I run skeleton.package realize that I must use the arg
| >   path = "library"
| >   The example that is shown there appears to omit that.
|
| The default is to put it in the current directory.  The assumption is
| that you started R where you want to work, or have switched to that
| directory later.  This is usually true for Unix users, but generally
| not for Windows users.
|
| I'm not sure what sort of change to make here.  path = "library"
| (literally) won't usually work, because it won't try to create the
| directory.  Suggestion?
|
| >2. download and install tools.zip, perl and windows help as listed
at:
| >
| >   http://www.murdoch-sutherland.com/Rtools/
| >
| >I got tripped up for quite a while when it could not find hhc.exe and
| >I finally realized I had not downloaded the windows help
distribution.
|
| Something I've meant to do for a long time (and got started on, once)
| is to write a program that checks your system for the package building
| requirements.  Just run it, and it'll tell you what it thinks is
| missing (and how to find it).
|
| >3. change the name of the package in the DESCRIPTION file -- it seems
| >that the name = arg on package.skeleton did not change it for me.
|
| Sounds like an oversight to me, but very easy to fix.
|
| >4. make changes to the documentation files.  I am just working on
this
| >now.  Some default null documentation exists but it appears that it
| >MUST be modified in order to get a working package so this makes
another
| >step.
|
| Should also be pretty easy to fix...
| >
| >There maybe other things but its taken me several hours just to get
| >this far and I do not yet have a functioning package.
| >
| >I think it would be handy if everything you need to know to actually
| >create a minimal functioning package were in ?skeleton.package
| >so that one could create a minimal functioning package without
actually
| >reading the extensions manual and then incrementally improve it.
Right
| >now there is quite a bit you have to know just to get to that point.
|
| That's a good point.  I think we're moving towards a point where Perl
| won't be necessary; the other tools are mostly reasonably small, and I
| think we could set things up so that the install process worked with
| or without HHC.
|
| >I have so far looked at skeleton.package, readme.packages in rw1091,
| >murdoch-suthertherland.com link mentioned above and the extensions
manual
| >so the startup to doing this is really a multi-step complex process.
|
| >The skeleton.package idea actually seems quite nifty but I think it
| >needs more work before one can really claim that its a one-step
process
| >to create the example package.
|
|
|
| ------------------------------
|
| Message: 28
| Date: Mon, 12 Jul 2004 04:32:55 +0000 (UTC)
| From: Gabor Grothendieck <ggrothendieck at myway.com>
| Subject: Re: [R] Creating a minimal package (was: where does R search
| when source()?)
| To: r-help at stat.math.ethz.ch
| Message-ID: <loom.20040712T055834-547 at post.gmane.org>
| Content-Type: text/plain; charset=us-ascii
|
| Duncan Murdoch <dmurdoch <at> pair.com> writes:
|
| : On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
| : <ggrothendieck <at> myway.com> wrote:
| :
|
| : >1. when I run skeleton.package realize that I must use the arg
| : >   path = "library"
| : >   The example that is shown there appears to omit that.
| :
| : The default is to put it in the current directory.  The assumption
is
| : that you started R where you want to work, or have switched to that
| : directory later.  This is usually true for Unix users, but generally
| : not for Windows users.
| :
| : I'm not sure what sort of change to make here.  path = "library"
| : (literally) won't usually work, because it won't try to create the
| : directory.  Suggestion?
|
| Perhaps we could use:
|
|    path = .libPaths()[[1]]
|
| as the default value of path in package.skeleton.
|
|
|
| ------------------------------
|
| Message: 29
| Date: Mon, 12 Jul 2004 18:23:12 +1200 (NZST)
| From: "Richard A. O'Keefe" <ok at cs.otago.ac.nz>
| Subject: [R] Association between discrete and continuous variable
| To: r-help at stat.math.ethz.ch
| Message-ID: <200407120623.i6C6NChO415915 at atlas.otago.ac.nz>
|
| What's the reommended way, in R, to determine the strength of
| association between a discrete variable and a continuous variable?
|
| Yes, I have read the manuals, trawled the archives, &c.
|
|
|
| ------------------------------
|
| Message: 30
| Date: Mon, 12 Jul 2004 08:43:46 +0200
| From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
| Subject: Re: [R] Creating a minimal package
| To: Gabor Grothendieck <ggrothendieck at myway.com>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <40F23322.6010809 at statistik.uni-dortmund.de>
| Content-Type: text/plain; charset=us-ascii; format=flowed
|
| Gabor Grothendieck wrote:
|
| > Duncan Murdoch <dmurdoch <at> pair.com> writes:
| >
| > : On Sun, 11 Jul 2004 21:28:44 +0000 (UTC), Gabor Grothendieck
| > : <ggrothendieck <at> myway.com> wrote:
| > :
| >
| > : >1. when I run skeleton.package realize that I must use the arg
| > : >   path = "library"
| > : >   The example that is shown there appears to omit that.
| > :
| > : The default is to put it in the current directory.  The assumption
is
| > : that you started R where you want to work, or have switched to
that
| > : directory later.  This is usually true for Unix users, but
generally
| > : not for Windows users.
| > :
| > : I'm not sure what sort of change to make here.  path = "library"
| > : (literally) won't usually work, because it won't try to create the
| > : directory.  Suggestion?
| >
| > Perhaps we could use:
| >
| >    path = .libPaths()[[1]]
| >
| > as the default value of path in package.skeleton.
|
| Actually, that's a bad idea, because you don't want a source package
in
| your binary library tree.
| I'm really happy with the default and the documentation which tells us
| about the "path" argument. Most (all?) functions I know do write to
the
| current working directory. You do not want another default for
| write.table() et al. to write the data to, do you?
|
| Uwe Ligges
|
|
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
|
|
|
| ------------------------------
|
| Message: 31
| Date: Mon, 12 Jul 2004 03:40:33 -0400
| From: Jonathan Baron <baron at psych.upenn.edu>
| Subject: Re: [R] Association between discrete and continuous variable
| To: "Richard A. O'Keefe" <ok at cs.otago.ac.nz>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <20040712074033.GA95 at psych>
| Content-Type: text/plain; charset=us-ascii
|
| On 07/12/04 18:23, Richard A. O'Keefe wrote:
| >What's the reommended way, in R, to determine the strength of
| >association between a discrete variable and a continuous variable?
|
| Analysis of variance?  aov()?  R^2?
|
| It seems to me, though, that there are many possible answers, and
| this really doesn't have much to do with R because R could
| implement them all.  It may matter whether the discrete variable
| is ordered or not, whether it is fixed or random, what the error
| distributions of the continuous variable look like, what measures
| of association are traditional in your field, etc. etc.
|
| Jon
| -- 
| Jonathan Baron, Professor of Psychology, University of Pennsylvania
| Home page:            http://www.sas.upenn.edu/~baron
| R search page:        http://finzi.psych.upenn.edu/
|
|
|
| ------------------------------
|
| Message: 32
| Date: Mon, 12 Jul 2004 00:50:58 -0700 (PDT)
| From: Jacob Wegelin <jawegelin at ucdavis.edu>
| Subject: [R] lme unequal random-effects variances varIdent pdMat
| Pinheiro Bates nlme
| To: r-help at stat.math.ethz.ch
| Message-ID: <Pine.OSX.4.53.0407101928480.2644 at biostat5.ucdavis.edu>
| Content-Type: TEXT/PLAIN; charset=US-ASCII
|
|
| How does one implement a likelihood-ratio test, to test whether the
| variances of the random effects differ between two groups of subjects?
|
| Suppose your data consist of repeated measures on subjects belonging
to
| two groups, say boys and girls, and you are fitting a linear
mixed-effects
| model for the response as a function of time.  The within-subject
errors
| (residuals) have the same variance in both groups. But the dispersion
of
| the random effects differs between the groups.  The boys' random
effects
| -- say, the intercepts -- have greater variance than the girls'.  One
can
| see this by partitioning the data by sex and fitting two separate
models.
|
| The model for the girls,
|
| library("nlme")
| mylmeF0 <- lme( y ~ time, data=DAT, random=~time | id,
subset=sex=="F")
|
| yields a variance of about one for the random intercepts:
|
|             StdDev    Corr
| (Intercept) 0.9765052 (Intr)
| time        0.1121913 -0.254
| Residual    0.1806528
|
| whereas in the model for the boys, the corresponding variance is ten
times
| that amount:
|
| mylmeM0 <- lme( y ~ time, data=DAT, random=~time | id,
subset=sex=="M")
|
|             StdDev     Corr
| (Intercept) 10.1537946 (Intr)
| time         0.1230063 -0.744
| Residual     0.1298910
|
| I would like to use a likelihood ratio to test this difference.  The
| smaller ("null") model would be
|
| mylme0 <- lme( y ~ time, data=DAT, random=~time | id )  .
|
| This model forces the random intercepts for both boys and girls to
come
| from a single normal distribution.
|
| The larger model would allow the boys' and girls' random intercepts
(or
| more generally their random effects) to come from separate normal
| distributions with possibly unequal variances.
|
| There must be some straightforward obvious way to fit the larger
model,
| but I do not see it.
|
| Pinheiro and Bates, chapter 5.2, show how to model unequal *residual*
| ("within-group") variances for the two groups using varIdent.  They
also
| tantalizingly say, "The single-level variance function model (5.10)
can be
| generalized to multilevel models" (page 206), which seems to suggest
that
| a solution to the current problem might exist.
|
| The pdMat classes provide a way to *constrain* the dispersion matrix
of
| the random effects, not make it more general.
|
| Of course, one way to test for unequal variances is to apply an F-test
for
| equal variances to the random intercepts. If the data are as shown at
the
| bottom of this email, the test can be implemented as follows:
|
| stuff<-as.data.frame(summary(mylme0)$coefficients$random$id)
| stuff$sex<-factor(substring(row.names(stuff), 1,1))
| mysplit<-split(stuff[,"(Intercept)"], stuff[,"sex"])
| ns<-sapply(mysplit, length)
| vars<-sapply(mysplit, var)
| p<- 1-pf( vars["M"]/vars["F"], ns["M"]-1, ns["F"]-1)
|
| Alternatively, one could implement a permutation test for the ratio of
the
| variances of the random intercepts--these variances derived from the
two
| halves of the partitioned data.
|
| But surely there's a direct, model-based way to do this?
|
| Thanks for any suggestions
|
| Jake
|
| P.S. Here is the code by which the "data" were generated.
|
| nb<-1
| ntimepts<-3
| girls<-data.frame(
| y= rep(-nb:nb , each=ntimepts)
| ,
| id=rep( paste("F", 1:(2*nb+1), sep=""), each=ntimepts)
| ,
| time=rep(1:(2*nb+1), length=ntimepts)
| )
| boys <-data.frame(
| y= rep(10*(-nb:nb) , each=ntimepts)
| ,
| id=rep( paste("M", 1:(2*nb+1), sep=""), each=ntimepts)
| ,
| time=rep(1:(2*nb+1), length=ntimepts)
| )
| DAT<-rbind(girls,boys)
| DAT$y<-DAT$y + rnorm(nrow(DAT))/5
| DAT$sex<-factor(substring( as.character(DAT[,"id"]), 1,1))
| row.names(DAT)<-paste( DAT[,"id"], DAT[,"time"], sep=".")
|
| Jacob A. Wegelin
| Assistant Professor
| Division of Biostatistics, School of Medicine
| University of California, Davis
| One Shields Ave, TB-168
| Davis CA 95616-8638 USA
| http://wegelin.ucdavis.edu/
| jawegelin at ucdavis.edu
|
|
|
| ------------------------------
|
| Message: 33
| Date: Mon, 12 Jul 2004 20:52:03 +1200
| From: Murray Jorgensen <maj at stats.waikato.ac.nz>
| Subject: Re: [R] Association between discrete and continuous variable
| To: "Richard A. O'Keefe" <ok at cs.otago.ac.nz>
| Cc: r-help at stat.math.ethz.ch
| Message-ID: <40F25133.6030207 at stats.waikato.ac.nz>
| Content-Type: text/plain; charset=us-ascii; format=flowed
|
| I'm wondering if mutual information al la Cover & Thomas (1991, Ch 2)
is
| not the killer association measure for all types of random variables?
|
| Murray Jorgensen
|
| PS  Yes, this is probably OT!
|
| Richard A. O'Keefe wrote:
| > What's the reommended way, in R, to determine the strength of
| > association between a discrete variable and a continuous variable?
| >
| > Yes, I have read the manuals, trawled the archives, &c.
| >
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
| >
| >
|
| -- 
| Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
| Department of Statistics, University of Waikato, Hamilton, New Zealand
| Email: maj at waikato.ac.nz                                Fax 7 838 4155
| Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
|
|
|
| ------------------------------
|
| Message: 34
| Date: Mon, 12 Jul 2004 21:00:44 +1200
| From: Murray Jorgensen <maj at stats.waikato.ac.nz>
| Subject: [R] Nested source()s
| To: R-help <r-help at stat.math.ethz.ch>
| Message-ID: <40F2533C.9080709 at stats.waikato.ac.nz>
| Content-Type: text/plain; charset=us-ascii; format=flowed
|
| I had an error message while running a macro from Yudi Pawitan's web
site:
|
|  > source("ex2-13.r")
| Error in parse(file, n, text, prompt) : syntax error on line 2
|
| Inspecting ex2-13.r I found that the error was generated by another
| source() command.
|
| Clearly R does not like nested source()s, which is fair enough when
you
| think about it. Still it's something that you might want to do. Does
| anyone know how to get achieve the substance of what nested source()
| commands would give you?
|
| Murray Jorgensen
|
| -- 
| Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
| Department of Statistics, University of Waikato, Hamilton, New Zealand
| Email: maj at waikato.ac.nz                                Fax 7 838 4155
| Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
|
|
|
| ------------------------------
|
| Message: 35
| Date: Mon, 12 Jul 2004 11:25:37 +0200
| From: Christoph Lehmann <christoph.lehmann at gmx.ch>
| Subject: [R] pixmapIndexed color question
| To: r-help at stat.math.ethz.ch
| Message-ID: <40F25911.3070607 at gmx.ch>
| Content-Type: text/plain; charset=us-ascii; format=flowed
|
| Hi
|
| I use pixmapIndexed
|
| tmp.vimp <- array(0,c(x.dim,y.dim))
| tmp.vimp <- pixmapIndexed(tmp.vimp, col=rainbow)
|
| to plot values of a 2D matrix. I 'fill' the pixmapIndexed like:
|
|      for (x in 1:x.dim) {
|          for (y in 1:y.dim) {
|                      tmp.vimp at index[x,y] <- my.matrix[x,y]
|      }}
|
|
| how can I define, that the colors are painted e.g. according the
rainbow
| palette?
|
| plot(tmp.vimp) paints all 'pixels' in red even though I specified it
| with col=rainbow (see above)
|
| many thanks
|
| cheers
|
| christoph
|
| p.s. is there an easier method for 'painting' the values of a 2d
matrix?
|
|
|
| ------------------------------
|
| _______________________________________________
| R-help at stat.math.ethz.ch mailing list
| https://www.stat.math.ethz.ch/mailman/listinfo/r-help
| PLEASE read the posting guide!
http://www.R-project.org/posting-guide.html
|
|
| End of R-help Digest, Vol 17, Issue 11
| **************************************
|



From sijeon at ucdavis.edu  Tue Jul 13 01:59:18 2004
From: sijeon at ucdavis.edu (Sangick Jeon)
Date: Mon, 12 Jul 2004 16:59:18 -0700 (PDT)
Subject: [R] Regular Expressions
Message-ID: <200407122359.i6CNxIcS007123@phaenicia.ucdavis.edu>



Hi,

Is there a way to use regular expressions to capture two or more words in a 
sentence?  For example, I wish to to find all the lines that have the words "thomas", 
"perl", and "program", such as "thomas uses a program called perl", or "perl is a 
program that thomas uses", etc.

I'm sure this is a very easy task, I would greatly appreciate any help.  Thanks!

Sangick



From thchung at tgen.org  Tue Jul 13 02:06:03 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Mon, 12 Jul 2004 17:06:03 -0700
Subject: [R] e1071 question: what's the definition of performance in tune.*
	functions?
Message-ID: <6E385CAE-D460-11D8-A8FF-000A95B43CDE@tgen.org>

Hi, all;

Basically, the subject contains the all information I need to know.
In e1071 library, there are functions to tune parameters.
They provide several values one of which is the performance.
Does any body know the "definition" of performance here?
Is it percentage of error or just the error rate or anything else?

Thanks in advance!

Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From tplate at blackmesacapital.com  Tue Jul 13 02:11:57 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Mon, 12 Jul 2004 18:11:57 -0600
Subject: [R] Regular Expressions
In-Reply-To: <200407122359.i6CNxIcS007123@phaenicia.ucdavis.edu>
References: <200407122359.i6CNxIcS007123@phaenicia.ucdavis.edu>
Message-ID: <6.1.0.6.2.20040712180757.03fe47c8@mailhost.blackmesacapital.com>

I'd suggest doing it with multiple regular expressions -- you could 
construct a single regular expression for this, but I expect it would get 
quite complicated and possibly very slow.

The expression for "y" in the example below tabulates how many words 
matched for each line (i.e., line 2 matched 1 word, line 3 matched 3 words, 
and line 4 matched 2 words).


 > x <- readLines("clipboard", -1)
 > x
[1] "Is there a way to use regular expressions to capture two or more words 
in a "
[2] "sentence?  For example, I wish to to find all the lines that have the 
words \"thomas\", "
[3] "\"perl\", and \"program\", such as \"thomas uses a program called 
perl\", or \"perl is a "
[4] "program that thomas uses\", 
etc."
 > sapply(c("perl","program","thomas"), function(re) grep(re, x))
$perl
[1] 3

$program
[1] 3 4

$thomas
[1] 2 3 4

 > unlist(sapply(c("perl","program","thomas"), function(re) grep(re, x)), 
use.names=F)
[1] 3 3 4 2 3 4
 > y <- table(unlist(sapply(c("perl","program","thomas"), function(re) 
grep(re, x)), use.names=F))
 > y

2 3 4
1 3 2
 > which(y>=2)
3 4
2 3
 >

hope this helps,

Tony Plate

At Monday 05:59 PM 7/12/2004, Sangick Jeon wrote:


>Hi,
>
>Is there a way to use regular expressions to capture two or more words in a
>sentence?  For example, I wish to to find all the lines that have the 
>words "thomas",
>"perl", and "program", such as "thomas uses a program called perl", or 
>"perl is a
>program that thomas uses", etc.
>
>I'm sure this is a very easy task, I would greatly appreciate any 
>help.  Thanks!
>
>Sangick
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Tue Jul 13 02:13:49 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 13 Jul 2004 00:13:49 +0000 (UTC)
Subject: .Platform addition (was Re: [R] where does R search when
	source()?)
References: <Pine.OSF.4.58.0407121058490.370151@odin.mdacc.tmc.edu>
Message-ID: <loom.20040713T013042-296@post.gmane.org>

Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:

> 
> On Sun, 11 Jul 2004, Gabor Grothendieck wrote:
> 
> > search.path <-
> > function(fn,
> >          paths = strsplit(Sys.getenv("PATH"), split = ";")[[1]],
> >          fsep = "\\") {
> >     for(d in paths) {
> >         f <- file.path(d, fn, fsep = fsep)
> >         if (file.exists(f))
> >             return(f)
> >     }
> >     return(NULL)
> > }
> >
> > source(search.path("myscript.R"))
> 
> I glanced this and thought this might be handy to keep for
> possible use. To make it less Windows-specific, I was going
> to replace Gabor's fsep default value with '.Platform$file.sep'
> when I noticed that .Platform doesn't have a '$path.sep'
> field. Just missing or available elsewhere?

AFAIK the OS-specific separators are not available in R which is why I 
had tried to localize them into the arg list.  The following seems to work
on Windows.  I don't have access to UNIX so perhaps you could see
if it works there too.  In this version the arg list has been reduced
to two arguments and both separators are localized into the default for the
second:

# search for file in paths
# fn is filename
# paths is a vector of path names, default is constructed from PATH
#
# e.g.: source(search.path("myscript.R"))

search.path <- function(fn, 
     paths = strsplit(chartr("\\", "/", Sys.getenv("PATH")), split = 
                switch(.Platform$OS.type, windows = ";", ":"))[[1]]) {
  for(d in paths) 
     if (file.exists(f <- file.path(d, fn)))
        return(f)
  return(NULL)
}



From andy_liaw at merck.com  Tue Jul 13 02:55:05 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 20:55:05 -0400
Subject: [R] e1071 question: what's the definition of performance in
	t une.* functions?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8030@usrymx25.merck.com>

Basically, the `Detail' section of ?tune says it all:

Details:

     As performance measure, the classification error is used for
     classification, and the mean squared error for regression. ...


Andy

> From: Tae-Hoon Chung
> 
> Hi, all;
> 
> Basically, the subject contains the all information I need to know.
> In e1071 library, there are functions to tune parameters.
> They provide several values one of which is the performance.
> Does any body know the "definition" of performance here?
> Is it percentage of error or just the error rate or anything else?
> 
> Thanks in advance!
> 
> Tae-Hoon Chung, Ph.D
> 
> Post-doctoral Research Fellow
> Molecular Diagnostics and Target Validation Division
> Translational Genomics Research Institute
> 1275 W Washington St, Tempe AZ 85281 USA
> Phone: 602-343-8724
>



From thchung at tgen.org  Tue Jul 13 03:11:26 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Mon, 12 Jul 2004 18:11:26 -0700
Subject: [R] e1071 question: what's the definition of performance in t
	une.* functions?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8030@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8030@usrymx25.merck.com>
Message-ID: <905AA680-D469-11D8-A8FF-000A95B43CDE@tgen.org>

Thanks Andy, however, let me make it more clear.

When you run tune.*, you will get performance value like 0.7...
If this value is percent, we get error rate of 0.7% which is excellent
(of course, we should be sure whether this is really a case of  
over-fitting ...
but anyway nominally this error rate is great).
However, if this error rate is ratio, than 0.7 is poor because  
basically we have 70% error rate.
So my question is whether the error rate is presented in percent or is  
just the error rate.
One puzzling thing is that when you run tune.*, you will also get  
values like
1.2* which makes it absurd to regard it as ratio because ratio larger  
than
1 is really absurd, right?
However, since the definition is not explicitly given anywhere, it is  
hard to interpret the result properly.

Thanks in advance;
TH

On Jul 12, 2004, at 5:55 PM, Liaw, Andy wrote:

> Basically, the `Detail' section of ?tune says it all:
>
> Details:
>
>      As performance measure, the classification error is used for
>      classification, and the mean squared error for regression. ...
>
>
> Andy
>
>> From: Tae-Hoon Chung
>>
>> Hi, all;
>>
>> Basically, the subject contains the all information I need to know.
>> In e1071 library, there are functions to tune parameters.
>> They provide several values one of which is the performance.
>> Does any body know the "definition" of performance here?
>> Is it percentage of error or just the error rate or anything else?
>>
>> Thanks in advance!
>>
>> Tae-Hoon Chung, Ph.D
>>
>> Post-doctoral Research Fellow
>> Molecular Diagnostics and Target Validation Division
>> Translational Genomics Research Institute
>> 1275 W Washington St, Tempe AZ 85281 USA
>> Phone: 602-343-8724
>>
>
>
> ----------------------------------------------------------------------- 
> -------
> Notice:  This e-mail message, together with any attachments, contains  
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,  
> New Jersey, USA 08889), and/or its affiliates (which may be known  
> outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD  
> and in Japan, as Banyu) that may be confidential, proprietary  
> copyrighted and/or legally privileged. It is intended solely for the  
> use of the individual or entity named on this message.  If you are not  
> the intended recipient, and have received this message in error,  
> please notify us immediately by reply e-mail and then delete it from  
> your system.
> ----------------------------------------------------------------------- 
> -------
>
>
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From dmurdoch at pair.com  Tue Jul 13 03:11:31 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 21:11:31 -0400
Subject: [R] Creating a minimal package (was: where does R search when
	source()?)
In-Reply-To: <cs35f0tbt5upagnq83l6al5vv1agv14f9e@4ax.com>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>
	<40F0B07E.5060105@jhsph.edu>
	<loom.20040711T073351-641@post.gmane.org>
	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>
	<loom.20040711T231128-574@post.gmane.org>
	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>
	<loom.20040712T055834-547@post.gmane.org>
	<cs35f0tbt5upagnq83l6al5vv1agv14f9e@4ax.com>
Message-ID: <rjd6f0hg3i9ja1bm2pr1gb7nf8bmqh3iu7@4ax.com>

On Mon, 12 Jul 2004 09:24:43 -0400, Duncan Murdoch <dmurdoch at pair.com>
wrote:


>These changes are available in r-patched.  I'll do a binary build
>today, and they should be downloadable from CRAN tomorrow.

Oops, I did the build but forgot the upload.  Make that "available on
Wednesday".

Duncan Murdoch



From kjetil at acelerate.com  Tue Jul 13 01:31:54 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Mon, 12 Jul 2004 19:31:54 -0400
Subject: [R] Smooth monotone estimation on R
References: <Pine.LNX.4.43.0407121252580.1882@hymn11.u.washington.edu>
Message-ID: <40F31F6A.9080906@acelerate.com>

help.search()
on my machine turns up only:

mono.con(mgcv)          Monotonicity constraints for a cubic
                        regression spline.

smooth.monotone(fda)    Monotone Smoothing of Data
pmreg(ftnonpar)         Piecewise monotone regression with taut
                        strings
backSpline(splines)     Monotone Inverse Spline
isoreg(stats)           Isotonic / Monotone Regression

so you should find something of use in packages mgvc, fda, ftnonpar, splines
or stats (.loaded by default)

Kjetil Halvorsen


Assaf P Oron wrote:

>Hi all,
>
>I'm looking for smooth monotone estimation packages, preferably using splines.
>
>I downloaded the 'cobs' package and intend to use it, but since it offers only quadratic splines based on L1 minimization, I'd like to compare its performance to that of a more 'mainstream' cubic-spline, L2-norm minimizing spline. Preferably a smoothing spline.
>
>Does anyone know of such code existing anywhere? Or another smooth monotone alternative?
>
>Thanks in advance,
>
>Assaf Oron
>Statistics Department
>University of Washington
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From andy_liaw at merck.com  Tue Jul 13 03:40:26 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jul 2004 21:40:26 -0400
Subject: [R] e1071 question: what's the definition of performance in
	t une.* functions?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8031@usrymx25.merck.com>

Looking at the body of tune(), it has:

...
                repeat.errors[reps] <- if (is.factor(true.y)) 
                  1 - classAgreement(table(pred, true.y))
                else crossprod(pred - true.y)/length(pred)
...

where classAgreement() is a function defined inside tune() that computes the
fraction of correctly predicted cases.  So it looks like tune() and friends
are returning error rates as fractions, not percentages.

You're right that the fraction shouldn't be larger than 1.  Did you make
sure that tune() sees the data as classification, not regression (i.e., did
you make sure that the class labels given to tune.*() are factor)?

HTH,
Andy

> From: Tae-Hoon Chung [mailto:thchung at tgen.org] 
> 
> Thanks Andy, however, let me make it more clear.
> 
> When you run tune.*, you will get performance value like 0.7...
> If this value is percent, we get error rate of 0.7% which is excellent
> (of course, we should be sure whether this is really a case of  
> over-fitting ...
> but anyway nominally this error rate is great).
> However, if this error rate is ratio, than 0.7 is poor because  
> basically we have 70% error rate.
> So my question is whether the error rate is presented in 
> percent or is  
> just the error rate.
> One puzzling thing is that when you run tune.*, you will also get  
> values like
> 1.2* which makes it absurd to regard it as ratio because 
> ratio larger  
> than
> 1 is really absurd, right?
> However, since the definition is not explicitly given 
> anywhere, it is  
> hard to interpret the result properly.
> 
> Thanks in advance;
> TH
> 
> On Jul 12, 2004, at 5:55 PM, Liaw, Andy wrote:
> 
> > Basically, the `Detail' section of ?tune says it all:
> >
> > Details:
> >
> >      As performance measure, the classification error is used for
> >      classification, and the mean squared error for regression. ...
> >
> >
> > Andy
> >
> >> From: Tae-Hoon Chung
> >>
> >> Hi, all;
> >>
> >> Basically, the subject contains the all information I need to know.
> >> In e1071 library, there are functions to tune parameters.
> >> They provide several values one of which is the performance.
> >> Does any body know the "definition" of performance here?
> >> Is it percentage of error or just the error rate or anything else?
> >>
> >> Thanks in advance!
> >>
> >> Tae-Hoon Chung, Ph.D
> >>
> >> Post-doctoral Research Fellow
> >> Molecular Diagnostics and Target Validation Division
> >> Translational Genomics Research Institute
> >> 1275 W Washington St, Tempe AZ 85281 USA
> >> Phone: 602-343-8724
> >>
> >
> >
> > 
> --------------------------------------------------------------
> --------- 
> > -------
> > Notice:  This e-mail message, together with any 
> attachments, contains  
> > information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station,  
> > New Jersey, USA 08889), and/or its affiliates (which may be known  
> > outside the United States as Merck Frosst, Merck Sharp & 
> Dohme or MSD  
> > and in Japan, as Banyu) that may be confidential, proprietary  
> > copyrighted and/or legally privileged. It is intended 
> solely for the  
> > use of the individual or entity named on this message.  If 
> you are not  
> > the intended recipient, and have received this message in error,  
> > please notify us immediately by reply e-mail and then 
> delete it from  
> > your system.
> > 
> --------------------------------------------------------------
> --------- 
> > -------
> >
> >
> Tae-Hoon Chung, Ph.D
> 
> Post-doctoral Research Fellow
> Molecular Diagnostics and Target Validation Division
> Translational Genomics Research Institute
> 1275 W Washington St, Tempe AZ 85281 USA
> Phone: 602-343-8724
> 
> 
>



From ggrothendieck at myway.com  Tue Jul 13 03:41:30 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 13 Jul 2004 01:41:30 +0000 (UTC)
Subject: [R] Regular Expressions
References: <200407122359.i6CNxIcS007123@phaenicia.ucdavis.edu>
Message-ID: <loom.20040713T033932-208@post.gmane.org>

Sangick Jeon <sijeon <at> ucdavis.edu> writes:

> Is there a way to use regular expressions to capture two or more words in a 
> sentence?  For example, I wish to to find all the lines that have the 
words "thomas", 
> "perl", and "program", such as "thomas uses a program called perl", or "perl 
is a 
> program that thomas uses", etc.

If you only have two patterns to search for then a regular expression can
be done this way:

   data(state)
   grep("i.*n|n.*i", state.name)  # states with i and n in name

but it gets unwieldy if you have three since there are 6 permutations, not 2.
In that case, you are probably better off iterating greps like this:

   lookfor <- 
   function(pat, x) { for(p in pat) x <- grep(p, x, value = TRUE); x }

   lookfor(c("i","n","g"), state.name)  # states with i, n and g in name



From gtg746b at mail.gatech.edu  Tue Jul 13 03:53:34 2004
From: gtg746b at mail.gatech.edu (Tianyu Tom Wang)
Date: Mon, 12 Jul 2004 21:53:34 -0400 (EDT)
Subject: [R] memory problem?
Message-ID: <Pine.SOL.4.33.0407122147360.17213-100000@acmez.gatech.edu>

Hi everyone,
   I'm running R1.9.1 on RedHat Linux.  I'm trying to read in a matrix
file with 13956 by 858 dimensions.  I realize this is pretty huge, though
I think the amount of memory I have should be able to handle it.  R reads
the entire file and tells me "Read in 11974247 values".  This is exactly
one less value than what it should have read in (11974248 = 13956*856).
I'm pretty sure this is a memory problem.  Any ideas on how to allocate
more memory/fix this problem?

thanks,
Tom



From dmurdoch at pair.com  Tue Jul 13 04:00:12 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 Jul 2004 22:00:12 -0400
Subject: [R] memory problem?
In-Reply-To: <Pine.SOL.4.33.0407122147360.17213-100000@acmez.gatech.edu>
References: <Pine.SOL.4.33.0407122147360.17213-100000@acmez.gatech.edu>
Message-ID: <dfg6f0hndmjennjcmgp6ff64kggurgri6i@4ax.com>

On Mon, 12 Jul 2004 21:53:34 -0400 (EDT), Tianyu Tom Wang
<gtg746b at mail.gatech.edu> wrote:

>Hi everyone,
>   I'm running R1.9.1 on RedHat Linux.  I'm trying to read in a matrix
>file with 13956 by 858 dimensions.  I realize this is pretty huge, though
>I think the amount of memory I have should be able to handle it.  R reads
>the entire file and tells me "Read in 11974247 values".  This is exactly
>one less value than what it should have read in (11974248 = 13956*856).
>I'm pretty sure this is a memory problem.  Any ideas on how to allocate
>more memory/fix this problem?

What function are you using to read the data?  It seems pretty
unlikely that it's running out of memory; more likely there's an
off-by-one calculation somewhere.

Duncan Murdoch



From rpeng at jhsph.edu  Tue Jul 13 04:00:57 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 12 Jul 2004 22:00:57 -0400
Subject: [R] memory problem?
In-Reply-To: <Pine.SOL.4.33.0407122147360.17213-100000@acmez.gatech.edu>
References: <Pine.SOL.4.33.0407122147360.17213-100000@acmez.gatech.edu>
Message-ID: <40F34259.1040402@jhsph.edu>

I doubt this is a memory problem, considering that R reported that it 
read in the data!  What exactly were the commands that you used to read 
in the data?

-roger

Tianyu Tom Wang wrote:

> Hi everyone,
>    I'm running R1.9.1 on RedHat Linux.  I'm trying to read in a matrix
> file with 13956 by 858 dimensions.  I realize this is pretty huge, though
> I think the amount of memory I have should be able to handle it.  R reads
> the entire file and tells me "Read in 11974247 values".  This is exactly
> one less value than what it should have read in (11974248 = 13956*856).
> I'm pretty sure this is a memory problem.  Any ideas on how to allocate
> more memory/fix this problem?
> 
> thanks,
> Tom
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Tue Jul 13 04:02:02 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jul 2004 19:02:02 -0700
Subject: [R] confint.glm in a function
Message-ID: <40F3429A.2000801@pdf.com>

      I can't get confint.glm to work from within a function.  Consider 
the following (using R 1.9.1, Windows 2000): 

# FIRST: SOMETHING THAT WORKS FROM A COMMAND PROMPT
DF <- data.frame(y=.1, N=100)
(fit <- glm(y~1, family=binomial, data=DF,
            weights=DF[,"N"]))
Call:  glm(formula = y ~ 1, family = binomial, data = DF, weights = 
DF[,      "N"])

Coefficients:
(Intercept) 
     -2.197 

Degrees of Freedom: 0 Total (i.e. Null);  0 Residual
Null Deviance:        0
Residual Deviance: -1.11e-14     AIC: 6.052

confint(fit)
 > confint(fit)
            2.5 % 97.5 %
(Intercept)   NaN    NaN
Warning message:
NaNs produced in: qt(p, df, lower.tail, log.p)
# The default confint thinks it knows glm, but doesn't.  This is fixed 
with: 
library(MASS)
confint(fit)
Waiting for profiling to be done...
    2.5 %    97.5 %
-2.915193 -1.594401
# This is on the logit space.  For proportions: 
Waiting for profiling to be done...
    2.5 %    97.5 %
0.0514076 0.1687655

# PUT IT IN A FUNCTION: 
confint.binom <- function(y="y", size="N", data.=DF){
  fit <- glm(y~1, family=binomial, data=data.,
             weights=data.[,size])
  CI <- confint(fit)
  CI
}
 > confint.binom()
Waiting for profiling to be done...
Error in model.frame.default(formula = y ~ 1, data = data., weights = 
data.[,  :
    Object "data." not found

##To get around this, assign both data. and size to some place where 
confint.glm can find them
confint.binom.pos <- function(y="y", size="N", data.=DF,
            pos=0){
  assign("data.", data., pos)
  assign("size", size, pos)
  fit <- glm(y~1, family=binomial, data=data.,
             weights=data.[,size])
  CI <- confint(fit)
  CI
}
 > confint.binom.pos()
Error in as.environment(pos) : invalid argument

 > confint.binom.pos(pos=-1)
Waiting for profiling to be done...
Error in model.frame.default(formula = y ~ 1, data = data., weights = 
data.[,  :
    Object "data." not found
 > confint.binom.pos(pos=1)
Waiting for profiling to be done...
    2.5 %    97.5 %
-2.915193 -1.594401
# This works. 
#  HOWEVER, THIS ASSIGNS data. AND size TO THE WORKING DIRECTORY. 
# HOW CAN I GET AROUND THIS? 

      If I had "confint.glm", I could modify it so it could find data. 
and size.  However, its hidden. 

      Thanks for your help. 
      Spencer Graves



From john.bullock at stanford.edu  Tue Jul 13 04:47:15 2004
From: john.bullock at stanford.edu (John Bullock)
Date: Mon, 12 Jul 2004 19:47:15 -0700
Subject: [R] Regular Expressions
References: <200407122359.i6CNxIcS007123@phaenicia.ucdavis.edu>
Message-ID: <01a301c46883$b5d50ea0$87ac0c80@stanford.edu>


If you use the RPerl interface
(http://www.omegahat.org/RSPerl/), you can do this simply
for any number of expressions by letting Perl do the
matching.  If "strings" is the array of strings that you
want to test, all you need is

    for (@strings) {
        if (/thomas/ && /perl/ && /prog/) {do something}
        }

But I don't know a simple way to do it in R.

--John

----- Original Message ----- 
From: "Sangick Jeon" <sijeon at ucdavis.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, July 12, 2004 4:59 PM
Subject: [R] Regular Expressions


>
>
> Hi,
>
> Is there a way to use regular expressions to capture
two or more words in a
> sentence?  For example, I wish to to find all the lines
that have the words "thomas",
> "perl", and "program", such as "thomas uses a program
called perl", or "perl is a
> program that thomas uses", etc.
>
> I'm sure this is a very easy task, I would greatly
appreciate any help.  Thanks!
>
> Sangick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Veronique.Verrier at aventis.com  Tue Jul 13 07:55:17 2004
From: Veronique.Verrier at aventis.com (Veronique.Verrier@aventis.com)
Date: Tue, 13 Jul 2004 07:55:17 +0200
Subject: [R] need help
Message-ID: <B13F58013757F9418D1C98DC764330D501A39FD6@frasmxsusr14.pharma.aventis.com>



From henric.nilsson at statisticon.se  Tue Jul 13 09:07:49 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Tue, 13 Jul 2004 09:07:49 +0200
Subject: [R] confint.glm in a function
In-Reply-To: <40F3429A.2000801@pdf.com>
References: <40F3429A.2000801@pdf.com>
Message-ID: <6.0.3.0.0.20040713085737.0635b980@10.0.10.66>

At 19:02 2004-07-12 -0700, you wrote:

>     If I had "confint.glm", I could modify it so it could find data. and 
> size.  However, its hidden.

Try

library(MASS)
MASS:::confint.glm

or navigate to /.../library/MASS/R and open the MASS file in your favourite 
editor.

HTH,
Henric



From christoph.lehmann at gmx.ch  Tue Jul 13 09:16:09 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 13 Jul 2004 09:16:09 +0200
Subject: [R] multiple hierarchical anova models
In-Reply-To: <337.1089642891@www12.gmx.net>
References: <337.1089642891@www12.gmx.net>
Message-ID: <40F38C39.6000804@gmx.ch>


Hi
I can recommend you two files

a) http://www.psych.upenn.edu/~baron/rpsych/rpsych.html

b) http://www.pallier.org/ressources/stats_with_R/stats_with_R.pdf (in 
french)

cheers

let me know whether this helped you

cheers

christoph

Matthias Unterhuber wrote:
> Hello,
> 
> My name is Matthias and I do look for syntax regarding hierarchal anova
> models in R. How can I express that a factor is nested within the
> combination of two other factors A(B,C), e.g. for aov(...)? I did not find
> the corresponding expression. Furthermore, I wanted to ask whether block
> factors have to be specified in a specific way or are they just treated as
> other factors (with no interactions).
> 
> Furthermore, in general an overview might be useful for beginners that
> describes the structural equations of more complicated anova-designs
> (hierarchical and block factor designs...) in the syntax of R.
> 
> Best wishes and thanks,
> 
> Matthias
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From Jean-Pierre.Mueller at dssp.unil.ch  Tue Jul 13 09:28:31 2004
From: Jean-Pierre.Mueller at dssp.unil.ch (=?ISO-8859-1?Q?Jean-Pierre_M=FCller?=)
Date: Tue, 13 Jul 2004 09:28:31 +0200
Subject: [R] Regular Expressions
In-Reply-To: <200407122359.i6CNxIcS007123@phaenicia.ucdavis.edu>
References: <200407122359.i6CNxIcS007123@phaenicia.ucdavis.edu>
Message-ID: <3D918278-D49E-11D8-B131-000D93AE2752@dssp.unil.ch>

Hello,

Not really regular expressions but you may also look at the first 
version of my package ttda at
http://wwwpeople.unil.ch/jean-pierre.mueller/

and the functions:

ttda.get.text
ttda.segmentation
ttda.forms.frame
ttda.TLE

HTH.
-- 
Jean-Pierre M??ller
SSP / BFSH2 / UNIL / CH - 1015 Lausanne
Voice:+41 21 692 3116 / Fax:+41 21 692 3115

Please avoid sending me Word or PowerPoint attachments.
  See http://www.fsf.org/philosophy/no-word-attachments.html
S'il vous pla??t, ??vitez de m'envoyer des attachements au format Word ou 
PowerPoint.
  Voir http://www.fsf.org/philosophy/no-word-attachments.fr.html



From Mark.Palmer at csiro.au  Tue Jul 13 09:40:55 2004
From: Mark.Palmer at csiro.au (Mark.Palmer@csiro.au)
Date: Tue, 13 Jul 2004 15:40:55 +0800
Subject: [R] Regular Expressions
Message-ID: <41FA45064D9534448E73B46B367F71F116A1AF@exwa2-per.wa.csiro.au>

Is there something wrong with this URL?

Mark Palmer				
Environmetrics Monitoring for Management		
CSIRO Mathematical and Information Sciences	
Private bag 5, Wembley, Western Australia, 6913			
Phone 		61-8-9333-6293
Mobile              0427-50-2353
Fax:		61-8-9333-6121
Email:		Mark.Palmer at csiro.au 
URL:		www.cmis.csiro.au/envir



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Jean-Pierre M??ller
Sent: Tuesday, 13 July 2004 3:29 PM
To: Sangick Jeon
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Regular Expressions


Hello,

Not really regular expressions but you may also look at the first 
version of my package ttda at
http://wwwpeople.unil.ch/jean-pierre.mueller/

and the functions:

ttda.get.text
ttda.segmentation
ttda.forms.frame
ttda.TLE

HTH.
-- 
Jean-Pierre M??ller
SSP / BFSH2 / UNIL / CH - 1015 Lausanne
Voice:+41 21 692 3116 / Fax:+41 21 692 3115

Please avoid sending me Word or PowerPoint attachments.
  See http://www.fsf.org/philosophy/no-word-attachments.html
S'il vous pla??t, ??vitez de m'envoyer des attachements au format Word ou 
PowerPoint.
  Voir http://www.fsf.org/philosophy/no-word-attachments.fr.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From V.Khamenia at biovision-discovery.de  Tue Jul 13 11:04:32 2004
From: V.Khamenia at biovision-discovery.de (Khamenia, Valery)
Date: Tue, 13 Jul 2004 11:04:32 +0200
Subject: [R] SMP, Single System Image clustering, multithreading
Message-ID: <D15343265276D31197BC00A024A6C110C7931B@EXS_BDC>

Hi All,

  I have looked through the following thread:

http://tolstoy.newcastle.edu.au/R/help/02b/4551.html

  and would like to ask after 1.5 year the same question:

  Are there any plans to involve multithread 
  computations in R?

Few word about my motivation:

  I use R on my OpenSSI cluster with 7 CPUs, so one 
  could simply think of this cluster as of single computer 
  with 7 CPU. My own C++ maths run good in parallel
  on the cluster. What is even better for me: my C++ code
  has *no* any statements about parallelization. 
  All parallezation is done at command line. When I 
  start a new piece of calculation from command line,
  the process is migrated to a free cluster node 
  automatically, it migrates even during the calculation.

  The whole project is calculated nearly up to 7 time 
  quicker then on a single CPU. Thus, I do see the boost 
  clearly.

  However the same approach applied to R will force me
  to use batch mode instead of nice interactive mode.

  Now I am writing this mail and R is still busy with
  stats in usual interactive mode. Other 6 processors
  are idling unfortunately. It would be really nice 
  to change this situation.

my best regards,
Valery.



From luciana.scalone at unimi.it  Tue Jul 13 12:28:36 2004
From: luciana.scalone at unimi.it (luciana)
Date: Tue, 13 Jul 2004 12:28:36 +0200
Subject: [R] paired t-test with bootstrap
Message-ID: <000d01c468c4$287a02e0$cf58959f@Centro>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040713/2cfb0a69/attachment.pl

From philipp.heuser at uni-koeln.de  Tue Jul 13 12:48:31 2004
From: philipp.heuser at uni-koeln.de (Philipp Heuser)
Date: Tue, 13 Jul 2004 12:48:31 +0200
Subject: [R] Synatx Error on start with R --no-save < myfile.R
Message-ID: <200407131248.31620.philipp.heuser@uni-koeln.de>

Dear all!

I wrote my R-code with an editor and loaded it with source("my_file.R"). 
Everything works fine as expected.

When I try to start my code with:
R --no-save < my_file.R 

I do get a synatx error half way through. The version is 1.9.0 on a Linux 
system. To start it with  R --no-save < my_file.R works on some machines but 
on some it doesn't.

Are there any rules I've to consider, when I want to start it that way?
Any ideas what might cause syntax errors when starting code like that?

Regards
Philipp


-- 
*************************************
Philipp Heuser

CUBIC - Cologne University Bioinformatics Center
Institute of Biochemistry       
University of Cologne                    

Zuelpicher Str. 47                       
D-50674 Cologne, GERMANY       

EMail: philipp.heuser at uni-koeln.de
Phone :  Office +49-221/470-7427 
Fax:     Office +49-221/470-5092



From vsxo at hotmail.com  Tue Jul 13 12:52:18 2004
From: vsxo at hotmail.com (Remy X.O. Martin)
Date: Tue, 13 Jul 2004 12:52:18 +0200
Subject: [R] an(other) anova question
Message-ID: <20040713125218.493d2171@bola.college-de-france.fr>

[sorry if this arrives in duplo: it doesn't show up in the archives and it seems that the address I posted this from originally is no longer functional]

Hello,

I think I could do with some suggestions concerning the following problem.

I have data from a set of experiments on motion sickness where for each subject, I have
1) personal data like age and gender
2) a subjective rating of discomfort/sickness, on a 10-level scale, "sampled" by the subjects as changes occurred. This rating is normalised per subject to the individual maxima given: Sickness.norm .
3) a conclusive, objective rating sick/not-sick. (WasSick)
4) various objective observables, sampled throughout the experiment. These are averaged either per time-interval (of say 2") or per "plateau" of the subjective discomfort rating.

I intend to analyse the averaged observables from (4) (say mean and power/variance) as a function of the (2), (3) and (1). It would be interesting, at least for first looks, to be able to do something like

> summary( aov( mean~Sickness.norm*Gender + Error(Subject/(Sickness.norm*Gender) ) )

or

> summary( aov( mean~Sickness.norm*WasSick + Error(Subject/(Sickness.norm*WasSick) ) )

To stick with the latter example: my data is sufficiently balanced (about 50% sick subjects), so I would expect that there are sufficient samples to perform an ANOVA with. I get the message 

"Error in "names<-.default"(`*tmp*`, value = nmstrata) : 
	names attribute must be the same length as the vector"

I expect that this has to do with the fact that none of my independent variables are in fact truely independent (controlled by the experimenter), but instead depend on the subject. For the age, gender and 'WasSick' data, there is only a single number per subject (indeed, removing them from the anova makes the analysis "possible").
So I reckon that they must enter elsewhere in the Error() expression...
I'd appreciate it if somebody is capable and willing to explain if and how this can be done!

Thanks in advance!

R.



From christoph.lehmann at gmx.ch  Tue Jul 13 13:36:05 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 13 Jul 2004 13:36:05 +0200
Subject: [R] locator() in a multiple plot setting
Message-ID: <40F3C925.40907@gmx.ch>

Hi

based on some code from Thomas Petzoldt, I have a question:

---
opar <- par(mfrow = c(2,4))
slices <- 8
m <- matrix(runif(100),10,10)
my.list <- list()
for (slice in 1:slices) {
     my.list[[slice]] <- m
}

for  (slice in 1:slices) {
     x <- 1*(1:25)
     y <- 1*(1:25)
     z <- my.list[[slice]]
     image(list(x = 0:9, y = 0:9, z = z))
}
par(opar) #restore device parameters


p <- locator(1)
c(round(p$x), round(p$y))
---

how can I get the "correct" location in the sense of a
3d info: (a) which slice (p$slice) (b) p$x (c) p$y

so that it could be used in the sense of:

	my.list[[p$slice]][round(p$x), round(p$y)]


many thanks

Cheers

christoph



From HankeA at mar.dfo-mpo.gc.ca  Tue Jul 13 13:37:43 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Tue, 13 Jul 2004 08:37:43 -0300
Subject: [R] Vaseplots
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE1249D3@msgmarsta01.bio.dfo.ca>

Hi Peter,
It sounds like you want simple.violinplot from package Simple by author
John Verzani.
Alex

-----Original Message-----
From: Peter Flom [mailto:flom at ndri.org] 
Sent: July 12, 2004 3:04 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Vaseplots


In The American Statistician vol 42 (1988) pages 257 - 280, Yoav
Benjamini investigates some variations on the box plot, including
vaseplots, which maek the width of each box vary proportionally to he
estimated density at a particular point.

Has anyone implemented these in R ?

Thanks as always

Peter

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From B.Rowlingson at lancaster.ac.uk  Tue Jul 13 14:06:02 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 13 Jul 2004 13:06:02 +0100
Subject: [R] locator() in a multiple plot setting
In-Reply-To: <40F3C925.40907@gmx.ch>
References: <40F3C925.40907@gmx.ch>
Message-ID: <40F3D02A.7020103@lancaster.ac.uk>


> 
> p <- locator(1)
> c(round(p$x), round(p$y))
> ---
> 
> how can I get the "correct" location in the sense of a
> 3d info: (a) which slice (p$slice) (b) p$x (c) p$y
> 

Okay, purely off the top of my head here...

You can use par()$usr, par()$plt, and par()$fig to transform from 
locator()'s coordinates to device coordinates (0,0 at one corner to 1,1 
at opposite corner). This lets you work out which of an NxM layout of 
plots you have clicked in.

  If you store par()$usr,plt,fig for each little plot then you can also 
work out the location within the plot. Its pretty much the inverse 
transform of the first computation, with an offset...

  And after much handwaving, you can work it out. And by the time I send 
this someone will have posted a full solution as an R package with 
documented functions and vignettes....

Baz



From Christian.Stratowa at vie.boehringer-ingelheim.com  Tue Jul 13 14:06:25 2004
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Tue, 13 Jul 2004 14:06:25 +0200
Subject: [R] Comparison of correlation coefficients
Message-ID: <F848C7E68BD94E489A03F6C2351BB0013CFD6D@vieex02.eu.boehringer.com>

Dear expeRts

Is it possible to compare correlation coefficients or to normalize 
different correlation coefficients?

Concretely, we have the following situation:
We have gene expression profiles for different tissues, where the 
number of samples per tissue are different, ranging from 10 to 250.
We are able to determine the correlation between two genes A and B
for each tissue separately, using "cor.test". However, the question
arises if the correlation coefficients between different tissues
can be compared or if they must somehow be "normalized", since the
number of samples per tissue varyies. 

Searching the web I found the function "compcorr", see:
http://www.fon.hum.uva.nl/Service/Statistics/Two_Correlations.html
http://ftp.sas.com/techsup/download/stat/compcorr.html
and implemented it in R:

compcorr <- function(n1, r1, n2, r2){
# compare two correlation coefficients
# return difference and p-value as list(diff, pval)

#	Fisher Z-transform
	zf1 <- 0.5*log((1 + r1)/(1 - r1))
	zf2 <- 0.5*log((1 + r2)/(1 - r2))

#	difference
	dz <- (zf1 - zf2)/sqrt(1/(n1 - 3) + (1/(n2 - 3)))

#	p-value
	pv <- 2*(1 - pnorm(abs(dz)))

	return(list(diff=dz, pval=pv))
}

Would it make sense to use the resultant p-value to "normalize"
the correlation coefficients, using: corr <- corr * compcorr()$pval

Is there a better way or an alternative to "normalize" the
correlation coefficients obtained for different tissues?

Thank you in advance for your help.
Since in the company I am not subscribed to r-help, could you 
please reply to me (in addition to r-help)

Best regards
Christian Stratowa

==============================================
Christian Stratowa, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2470
Fax: ++43-1-80105-2782
email: christian.stratowa at vie.boehringer-ingelheim.com



From rpeng at jhsph.edu  Tue Jul 13 14:21:17 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 13 Jul 2004 08:21:17 -0400
Subject: [R] SMP, Single System Image clustering, multithreading
In-Reply-To: <D15343265276D31197BC00A024A6C110C7931B@EXS_BDC>
References: <D15343265276D31197BC00A024A6C110C7931B@EXS_BDC>
Message-ID: <40F3D3BD.1090808@jhsph.edu>

I think there are plans to work on multithreading in R (see 
http://developer.r-project.org/) but it's probably a long-term 
project.  For now, you might want to try building R with a 
multithreaded BLAS.

-roger

Khamenia, Valery wrote:
> Hi All,
> 
>   I have looked through the following thread:
> 
> http://tolstoy.newcastle.edu.au/R/help/02b/4551.html
> 
>   and would like to ask after 1.5 year the same question:
> 
>   Are there any plans to involve multithread 
>   computations in R?
> 
> Few word about my motivation:
> 
>   I use R on my OpenSSI cluster with 7 CPUs, so one 
>   could simply think of this cluster as of single computer 
>   with 7 CPU. My own C++ maths run good in parallel
>   on the cluster. What is even better for me: my C++ code
>   has *no* any statements about parallelization. 
>   All parallezation is done at command line. When I 
>   start a new piece of calculation from command line,
>   the process is migrated to a free cluster node 
>   automatically, it migrates even during the calculation.
> 
>   The whole project is calculated nearly up to 7 time 
>   quicker then on a single CPU. Thus, I do see the boost 
>   clearly.
> 
>   However the same approach applied to R will force me
>   to use batch mode instead of nice interactive mode.
> 
>   Now I am writing this mail and R is still busy with
>   stats in usual interactive mode. Other 6 processors
>   are idling unfortunately. It would be really nice 
>   to change this situation.
> 
> my best regards,
> Valery.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From petr.pikal at precheza.cz  Tue Jul 13 14:28:15 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 13 Jul 2004 14:28:15 +0200
Subject: [R] paired t-test with bootstrap
Message-ID: <40F3F17F.19490.176E757@localhost>

Hi

On 13 Jul 2004 at 12:28, luciana wrote:

> Dear Sirs,
> 
> I am a R beginning user: by mean of R I would like to apply the
> bootstrap to my data in order to test cost differences between
> independent or paired samples of people affected by a certain
> disease.
> 
> My problem is that even if I am reading the book by Efron
> (introduction to the bootstrap), looking at the examples in internet
> and available in R, learning a lot of theoretical things on
> bootstrap, I can't apply bootstrap with R to my data because of many
> doubts and difficulties. This is the reason why I have decided to
> ask the expert for help.
> 
> 
> 
> I have a sample of diabetic people, matched (by age and sex) with a
> control sample. The variable I would like to compare is their drug
> and hospital monthly cost. The variable cost has a very far from
> gaussian distribution, but I need any way to compare the mean
> between the two group. So, in the specific case of a paired sample
> t-test, I aim at testing if the difference of cost is close to 0.
> What is the better way to follow for that?
> 
> 
> 
> Another question is that sometimes I have missing data in my dataset
> (for example I have the cost for a patients but not for a control).
> If I introduce NA or a dot, R doesn't estimate the statistic I need
> (for instance the mean). To overcome this problem I have replaced
> the missing data with the mean computed with the remaining part of
> data. Anyway, I think R can actually compute the mean even with the
> presence of missing data. Is it right? What can I do?

your.statistic(your.data, na.rm=T)

e.g.
mean(your.data, na.rm=T)

or look at ?na.action e.g  mean(na.omit(your.data))

Cheers
Petr Pikal


> 
> 
> 
> Thank you very much for your attention and, I hope, your help.
> 
> 
> 
> Best wishes 
> 
> 
> 
> Luciana Scalone
> 
> Center of Pharmacoeconomics
> 
> University of Milan
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From anne.piotet at urbanet.ch  Tue Jul 13 14:34:17 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Tue, 13 Jul 2004 14:34:17 +0200
Subject: [R] table lookup n R
Message-ID: <000a01c468d5$b7512e10$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040713/a14a41a0/attachment.pl

From laurent.buffat at it-omics.com  Tue Jul 13 14:35:30 2004
From: laurent.buffat at it-omics.com (laurent buffat)
Date: Tue, 13 Jul 2004 14:35:30 +0200
Subject: [R] Absolute ceiling on R's memory usage = 4 gigabytes?
In-Reply-To: <B30C2054-CBB9-11D8-AA36-000A95B43CDE@tgen.org>
Message-ID: <20040713123530.2251293EE@heart.itomics.local>

Hi Tae-Hoon,

I am very surprise by your answers : 

When I try to make an affybatch with bioconductor and R 1.9.1, I was unable
to read and normalise more than 80 HU-133A CEL file with a Linux 32 bits
computer and 4 GB of RAM + 8 GB of swap (Of course, without any other
process on the computer and I don't' want do to "JustRMA" because I want the
probe level information in the affybatch, And it's not a limit in R
configuration, because if I follow the memory usage during the R session, R
is using all the 4GB RAM memory (the swap is not use) before the memory
error) 

For this raison we are planning to buy a 64 bits under Linux, but, if with
Mac OS X and 1.5 GB of RAM, we can solve this problem, I will buy a Mac and
not a linux 64 bits computer.

So, what kind of normalization are you doing ? Some one with bioconductor
and the affy package or an other one ? Could you precise ?

For the other R & BioC :

Do you think that there is a difference between linux and MacOS for the
memory management under R ?

What is a "good" hardward solution for "R / Linux 64 bits" ?

Thanks for your help.

laurent


-----Message d'origine-----
De : r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] De la part de Tae-Hoon Chung
Envoye : vendredi 2 juillet 2004 01:52
A : Kort, Eric
Cc : r-help at stat.math.ethz.ch
Objet : Re: [R] Absolute ceiling on R's memory usage = 4 gigabytes?

Hi, Eric.
It seems a little bit puzzling to me. Which Affymetrix chip do you use? 
The reason I'm asking this is that yesterday I was able to normalize 
150 HU-133A CEL files (containing 22283 probes) using R 1.9.1 in Mac OS 
X 10.3.3 with 1.5 GB memory. If your chip has more probes than this, 
then it must be understandable ...

On Jul 1, 2004, at 2:59 PM, Kort, Eric wrote:

> Hello.  By way of background, I am running out of memory when 
> attempting to normalize the data from 160 affymetrix microarrays using 
> justRMA (from the affy package).  This is despite making 6 gigabytes 
> of swap space available on our sgi irix machine (which has 2 gigabytes 
> of ram).  I have seen in various discussions statements such as "you 
> will need at least 6 gigabytes of memory to normalize that many 
> chips", but my question is this:
>
> I cannot set the memory limits of R (1.9.1) higher than 4 gigabytes as 
> attempting to do so results in this message:
>
> WARNING: --max-vsize=4098M=4098`M': too large and ignored
>
> I experience this both on my windows box (on which I cannot allocate 
> more than 4 gigabytes of swap space anyway), and on an the above 
> mentioned sgi irix machine (on which I can).  In view of that, I do 
> not see what good it does to make > 4 gigabytes of ram+swap space 
> available.  Does this mean 4 gigabytes is the absolute upper limit of 
> R's memory usage...or perhaps 8 gigabytes since you can set both the 
> stack and the heap size to 4 gigabytes?
>
> Thanks,
> Eric
>
>
> This email message, including any attachments, is for the 
> so...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From christoph.lehmann at gmx.ch  Tue Jul 13 14:42:05 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 13 Jul 2004 14:42:05 +0200
Subject: [R] paired t-test with bootstrap
In-Reply-To: <000d01c468c4$287a02e0$cf58959f@Centro>
References: <000d01c468c4$287a02e0$cf58959f@Centro>
Message-ID: <40F3D89D.1090002@gmx.ch>

just a hint for further bootstrapping examples (worked out with R):

"Bootstrap Methods and Their Applications" by A.C. Davison and D.V. Hinkley

cheers

christoph

luciana wrote:
> Dear Sirs,
> 
> I am a R beginning user: by mean of R I would like to apply the bootstrap to my data in order to test cost differences between independent or paired samples of people affected by a certain disease.
> 
> My problem is that even if I am reading the book by Efron (introduction to the bootstrap), looking at the examples in internet and available in R, learning a lot of theoretical things on bootstrap, I can't apply bootstrap with R to my data because of many doubts and difficulties. This is the reason why I have decided to ask the expert for help.
> 
>  
> 
> I have a sample of diabetic people, matched (by age and sex) with a control sample. The variable I would like to compare is their drug and hospital monthly cost. The variable cost has a very far from gaussian distribution, but I need any way to compare the mean between the two group. So, in the specific case of a paired sample t-test, I aim at testing if the difference of cost is close to 0. What is the better way to follow for that?
> 
>  
> 
> Another question is that sometimes I have missing data in my dataset (for example I have the cost for a patients but not for a control). If I introduce NA or a dot, R doesn't estimate the statistic I need (for instance the mean). To overcome this problem I have replaced the missing data with the mean computed with the remaining part of data. Anyway, I think R can actually compute the mean even with the presence of missing data. Is it right? What can I do?
> 
>  
> 
> Thank you very much for your attention and, I hope, your help.
> 
>  
> 
> Best wishes 
> 
>  
> 
> Luciana Scalone
> 
> Center of Pharmacoeconomics
> 
> University of Milan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Tue Jul 13 14:56:21 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 13 Jul 2004 08:56:21 -0400
Subject: [R] confint.glm in a function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8033@usrymx25.merck.com>

You actually don't need to load the package first:

> MASS:::confint.glm
function (object, parm, level = 0.95, trace = FALSE, ...) 
{
    pnames <- names(coef(object))
    if (missing(parm)) 
        parm <- seq(along = pnames)
    else if (is.character(parm)) 
        parm <- match(parm, pnames, nomatch = 0)
    cat("Waiting for profiling to be done...\n")
    object <- profile(object, which = parm, alpha = (1 - level)/4, 
        trace = trace)
    confint(object, parm = parm, level = level, trace = trace, 
        ...)
}
<environment: namespace:MASS>
> search()
[1] ".GlobalEnv"       "package:methods"  "package:stats"
"package:graphics"
[5] "package:utils"    "Autoloads"        "package:base"    

Andy


> From: Henric Nilsson
> 
> At 19:02 2004-07-12 -0700, you wrote:
> 
> >     If I had "confint.glm", I could modify it so it could 
> find data. and 
> > size.  However, its hidden.
> 
> Try
> 
> library(MASS)
> MASS:::confint.glm
> 
> or navigate to /.../library/MASS/R and open the MASS file in 
> your favourite 
> editor.
> 
> HTH,
> Henric
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ggrothendieck at myway.com  Tue Jul 13 15:05:20 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 13 Jul 2004 13:05:20 +0000 (UTC)
Subject: [R] table lookup n R
References: <000a01c468d5$b7512e10$6c00a8c0@mtd4>
Message-ID: <loom.20040713T145356-531@post.gmane.org>


Try subscripting, e.g.

   # L holds numbers; its names hold lookup keys
   L <- 1:26; names(L) <- letters
   L[c("d","f")]  # look up numbers of d and f

or merge, e.g.

   merge(c("d","f"), L, by.x = 1, by.y = 0)


Anne <anne.piotet <at> urbanet.ch> writes:

: 
: Hello R helpers!
: I looked  but did not find a table-lookup R-utility. I could use a loop to 
do the job (old FORTRAN/C habits die
: hard) but if I have a big table in which I have to search for the values 
corresponding to a vector, I end up
: logically with a double loop.
: Is there already such a utility? Otherwise, is there a way without loops?
: 
: Thanks as always
: Anne



From anne.piotet at urbanet.ch  Tue Jul 13 15:11:10 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Tue, 13 Jul 2004 15:11:10 +0200
Subject: [R] table lookup n R
References: <000a01c468d5$b7512e10$6c00a8c0@mtd4>
	<1089722731.3147.40.camel@vpn202001.lif.icnet.uk>
Message-ID: <001c01c468da$de1b5930$6c00a8c0@mtd4>

Thank you! It should do the job... (it was jeust a question to know where to
look!)
Anne

----- Original Message ----- 
From: "Adaikalavan Ramasamy" <ramasamy at cancer.org.uk>
To: "Anne" <anne.piotet at urbanet.ch>
Sent: Tuesday, July 13, 2004 2:45 PM
Subject: Re: [R] table lookup n R


> See match(), %in% and related functions.
>
> Description:
>
> 'match' returns a vector of the positions of (first) matches of its
> first argument in its second.
>
> '%in%' is a more intuitive interface as a binary operator, which returns
> a logical vector indicating if there is a match or not for   its left
> operand.
>
>
>
> On Tue, 2004-07-13 at 13:34, Anne wrote:
> > Hello R helpers!
> > I looked  but did not find a table-lookup R-utility. I could use a loop
to do the job (old FORTRAN/C habits die hard) but if I have a big table in
which I have to search for the values corresponding to a vector, I end up
logically with a double loop.
> > Is there already such a utility? Otherwise, is there a way without
loops?
> >
> > Thanks as always
> > Anne
> > ----------------------------------------------------
> > Anne Piotet
> > Tel: +41 79 359 83 32 (mobile)
> > Email: anne.piotet at m-td.com
> > ---------------------------------------------------
> > M-TD Modelling and Technology Development
> > PSE-C
> > CH-1015 Lausanne
> > Switzerland
> > Tel: +41 21 693 83 98
> > Fax: +41 21 646 41 33
> > --------------------------------------------------
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
>
>



From petr.pikal at precheza.cz  Tue Jul 13 15:12:58 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 13 Jul 2004 15:12:58 +0200
Subject: [R] table lookup n R
In-Reply-To: <000a01c468d5$b7512e10$6c00a8c0@mtd4>
Message-ID: <40F3FBFA.6942.19FD85C@localhost>

Hi

On 13 Jul 2004 at 14:34, Anne wrote:

> Hello R helpers!
> I looked  but did not find a table-lookup R-utility. I could use a
> loop to do the job (old FORTRAN/C habits die hard) but if I have a big
> table in which I have to search for the values corresponding to a
> vector, I end up logically with a double loop. Is there already such a
> utility? Otherwise, is there a way without loops?

Well, if I understand you correctly, you want to find something in 
your table (data.frame)

try:

your.table==your.vector
to get TRUE/FALSE table with same dimensions as your table

and

which(your.table==your.vector, arr.ind=T)

to obtain row/col indices of TRUE values

In case you want something else please try to be more specific.

Cheers
Petr

> 
> Thanks as always
> Anne
> ----------------------------------------------------
> Anne Piotet
> Tel: +41 79 359 83 32 (mobile)
> Email: anne.piotet at m-td.com
> ---------------------------------------------------
> M-TD Modelling and Technology Development
> PSE-C
> CH-1015 Lausanne
> Switzerland
> Tel: +41 21 693 83 98
> Fax: +41 21 646 41 33
> --------------------------------------------------
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From MSchwartz at MedAnalytics.com  Tue Jul 13 15:23:44 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 13 Jul 2004 08:23:44 -0500
Subject: [R] paired t-test with bootstrap
In-Reply-To: <40F3F17F.19490.176E757@localhost>
References: <40F3F17F.19490.176E757@localhost>
Message-ID: <1089725024.3830.158.camel@localhost.localdomain>

On Tue, 2004-07-13 at 07:28, Petr Pikal wrote:
> Hi
> 
> On 13 Jul 2004 at 12:28, luciana wrote:
> 
> > Dear Sirs,
> > 
> > I am a R beginning user: by mean of R I would like to apply the
> > bootstrap to my data in order to test cost differences between
> > independent or paired samples of people affected by a certain
> > disease.
> > 
> > My problem is that even if I am reading the book by Efron
> > (introduction to the bootstrap), looking at the examples in internet
> > and available in R, learning a lot of theoretical things on
> > bootstrap, I can't apply bootstrap with R to my data because of many
> > doubts and difficulties. This is the reason why I have decided to
> > ask the expert for help.
> > 
> > 
> > 
> > I have a sample of diabetic people, matched (by age and sex) with a
> > control sample. The variable I would like to compare is their drug
> > and hospital monthly cost. The variable cost has a very far from
> > gaussian distribution, but I need any way to compare the mean
> > between the two group. So, in the specific case of a paired sample
> > t-test, I aim at testing if the difference of cost is close to 0.
> > What is the better way to follow for that?
> > 
> > 
> > 
> > Another question is that sometimes I have missing data in my dataset
> > (for example I have the cost for a patients but not for a control).
> > If I introduce NA or a dot, R doesn't estimate the statistic I need
> > (for instance the mean). To overcome this problem I have replaced
> > the missing data with the mean computed with the remaining part of
> > data. Anyway, I think R can actually compute the mean even with the
> > presence of missing data. Is it right? What can I do?
> 
> your.statistic(your.data, na.rm=T)
> 
> e.g.
> mean(your.data, na.rm=T)
> 
> or look at ?na.action e.g  mean(na.omit(your.data))
> 
> Cheers
> Petr Pikal


A couple of other thoughts here with respect to the use of a paired
t-test for the comparison.

As Luciana notes above, cost data is typically highly skewed, raising
doubt as to the use of a simple parametric test to compare the two
groups.

One of the many reasons such data is skewed is that there are notable
differences in the populations that are not accounted for when using
simple characteristics for matching as is done here. What makes a
patient an "outlier" with respect to cost and how does the distribution
of these patients differ between the two groups and the individual
pairs?

For example, are all the patients in both groups insulin dependent or
are some controlled with oral agents or diet alone? If all are using
insulin, are some using self-administered injections while others are
using implanted infusion pumps? What is the interval from disease onset?
Have any had Pancreas/Islet Cell transplants? Do the matched patients
have similar diabetic related sequelae such as diabetic retinopathy,
neuropathy, vasculopathy, renal dysfunction and others? If not, the
costs to treat these other issues, such as dialysis and wound care
alone, can dramatically alter the cost profile for patients even when
matched by age and gender.

If you are not considering these issues (ie. such as inclusion/exclusion
criteria), you risk significant challenges in your conclusions with
respect to the comparison of costs for these two groups. I would raise
similar concerns when using a sample mean as the imputed value for
missing data.

If you have not done so already, a Medline search of the literature
would be in order to better understand what others have done in this
area for diabetic treatment costs and the pros and cons of their
respective approaches. I suspect that others here will have additional
recommendations.

HTH,

Marc Schwartz



From bates at stat.wisc.edu  Tue Jul 13 15:49:04 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Jul 2004 08:49:04 -0500
Subject: [R] Creating a minimal package
In-Reply-To: <ta45f0ljhetd4ai746fs18dff7mim7o1i0@4ax.com>
References: <OAEOKPIGCLDDHAEMCAKICEHJCPAA.sdhyok@email.unc.edu>	<40F0B07E.5060105@jhsph.edu>	<loom.20040711T073351-641@post.gmane.org>	<ngc2f0h8up0ip07bshguimh85644ltme39@4ax.com>	<loom.20040711T231128-574@post.gmane.org>	<ebr3f098aho62muqapebiplkh1n3prf7et@4ax.com>	<loom.20040712T055834-547@post.gmane.org>	<40F23322.6010809@statistik.uni-dortmund.de>	<loom.20040712T131806-594@post.gmane.org>	<40F28EB3.7060902@statistik.uni-dortmund.de>
	<ta45f0ljhetd4ai746fs18dff7mim7o1i0@4ax.com>
Message-ID: <40F3E850.8020202@stat.wisc.edu>

Duncan Murdoch wrote:
> On Mon, 12 Jul 2004 15:14:27 +0200, Uwe Ligges
> <ligges at statistik.uni-dortmund.de> wrote :
> 
> 
>>Gabor Grothendieck wrote:
> 
> 
>>>The objective should be that creating a package is as easy as this:
>>>
>>>   f <- function()1; g <- function()2; d <- 3; e <- 4:5
>>>   package.skeleton(list=c("f","g","d","e"), name="AnExample")
>>>   library(AnExample)
>>>   f()
>>>   
>>>which means that the package needs to be inserted where library will
>>>find it. It should not be necessary to have an understanding of this.
>>>
>>
>>OK, I understand what you are going to do, but in that case you can use 
>>dump() into an *.R or save() into an *.RData file and use 
>>source()/load() to load it again. I don't see any advantage of a package 
>>if you don't want to modify documentation or other stuff in the package.
>>Also, you would need the tools to make a binary package from the source 
>>package somewhere. package.skeleton() is clearly not intended to be used 
>>for that purpose, but to create the template for your source package.
>>Hence the default should not be changed.
> 
> 
> I agree with both of you on this.  Currently the method that Uwe
> describes is a lot easier than creating a package, but I think the
> objective should be to make things almost as easy as Gabor describes.
> 
> Not completely as easy:  he's missing the step where the package is
> installed.  I think we want to keep that (because the distinction
> between the source of a package and the installed copy of it is
> important), but it should be easier to install a new package than it
> is now, especially in Windows.  So I'm suggesting that it would be
> nice to be able to do something like this:
> 
>  f <- function()1; g <- function()2; d <- 3; e <- 4:5
>  package.skeleton(list=c("f","g","d","e"), name="AnExample")
>  install.packages("AnExample", build = TRUE)
>  library(AnExample)
>  f()
> 
> but currently install.packages doesn't know how to build, and for most
> Windows users, a fairly substantial effort is necessary to obtain all
> the tools.
> 
> Duncan Murdoch

I haven't checked on the installation tools under Windows but I think 
that most, if not all, of the creation and installation of a binary 
package (i.e. building indices, etc.) could be done in R for packages 
that do not require compilation of source code and provided that you are 
willing to go without some forms of the man pages.



From maechler at stat.math.ethz.ch  Tue Jul 13 14:54:43 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 13 Jul 2004 14:54:43 +0200
Subject: [R] inv.logit() from "boot" ..[was "proportions confidence.."]
In-Reply-To: <40F2CDF9.30904@pdf.com>
References: <5.1.0.14.2.20040712164139.01fec558@staffmail.ed.ac.uk>
	<40F2CDF9.30904@pdf.com>
Message-ID: <16627.56211.934604.276464@gargle.gargle.HOWL>

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Mon, 12 Jul 2004 10:44:25 -0700 writes:

    Spencer>       Please see: Brown, Cai and DasGupta (2001)
    Spencer> Statistical Science, 16: 101-133 and (2002) Annals
    Spencer> of Statistics, 30: 160-2001

    Spencer>       They show that the actual coverage
    Spencer> probability of the standard approximate confidence
    Spencer> intervals for a binomial proportion are quite poor,
    Spencer> while the standard asymptotic theory applied to
    Spencer> logits produces rather better answers.

    Spencer>       I would expect "confint.glm" in library(MASS)
    Spencer> to give decent results, possibly the best available
    Spencer> without a very careful study of this particular
    Spencer> question.  Consider the following:

    Spencer> library(MASS)# needed for confint.glm
    Spencer> library(boot)# needed for inv.logit
	                    ^^^^^^^^^^^^^^^^^^^^

    Spencer>  <.............>

well, did you ever look at the definition of inv.logit() ?

doing it for you:

      inv.logit <- function(x) plogis(x)

hence I'd think "boot" is not really needed.

And, BTW, consequently the  logit() function in the 'boot'
package is the same as  qlogis() 
[and could well be defined that way instead of slightly more complicated].

I'll add a \concept{logit} to the plogis / qlogis help page and
a \note{} telling this to those who forget..

Martin Maechler, ETH Zurich



From zboshao at yahoo.com  Tue Jul 13 16:25:35 2004
From: zboshao at yahoo.com (boshao zhang)
Date: Tue, 13 Jul 2004 07:25:35 -0700 (PDT)
Subject: [R] MLE, precision
Message-ID: <20040713142535.81415.qmail@web12210.mail.yahoo.com>

Hi, everyone

I am trying to estimate 3 parameters for my survival
function. It's very complicated. The negative
loglikelihood function is:

l<- function(m1,m2,b)  -sum(    d*( log(m1) + log(m2)
+ log(1- exp(-(b + m2)*t)) ) + (m1/b - d)*log(m2 +
b*exp(-(b + m2)*t) ) + m1*t - m1/b*log(b+m2)      )

here d and t are given, "sum"  means sum over these
two vairables. 
the parameters are assumed small, m1, m2 in
thousandth, m2 in millionth.

I used the function "nlm" to estimate m1,m2,b. But the
result is very bad. you can get more than 50 warnings,
most of them are about "negative infinity"in log. And
the results are initial value dependent, or you will
get nothing when you choose some values.

So I tried brutal force, i.e. evaluate the values of
grid point. It works well. Also, you can get the
correct answer of log(1e-12).

My questions are:
 What is the precision of a variable in R?
 How to specify the constraint interval of parameters
in nlm? I tried lower, upper, it doesn't work.
any advice on MLE is appreciated.

Thank you.

Boshao



From a.prioglio at city.ac.uk  Tue Jul 13 16:31:57 2004
From: a.prioglio at city.ac.uk (Antonio Prioglio)
Date: Tue, 13 Jul 2004 15:31:57 +0100 (BST)
Subject: [R] Help with factanal and missing values
Message-ID: <Pine.LNX.4.44.0407131518120.1865-100000@ws7.dogbert.ntt.it>

Hi list,

I'm performing a series of confirmatory factor analysis on different 
groupings of items from data collected with questionnaires. There are some 
missing values.

For those sets with no missing values I call
factanal(datamatrix,factors=n)

where datamatrix is a table of all observations for the items under 
investigation.

This call fails when there are missing values.
help(factanal) does not give an example on calls with  na.action and and 
mentiones a formula.

(Venables and Ripley, 2002 give only one example on p. 323 for a case 
where the covariance has already been calculated)

Could someone give me an example on such a call for a simple CFA?

Thanks for the help.



Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From vito_ricci at yahoo.com  Tue Jul 13 16:36:12 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Tue, 13 Jul 2004 16:36:12 +0200 (CEST)
Subject: [R] paired t-test with bootstrap
Message-ID: <20040713143612.60313.qmail@web41215.mail.yahoo.com>

Hi

On 13 Jul 2004 at 12:28, luciana wrote:

> Dear Sirs,
 
> I have a sample of diabetic people, matched (by age
and sex) with a
> control sample. The variable I would like to compare
is their drug
> and hospital monthly cost. The variable cost has a
very far from
> gaussian distribution, but I need any way to compare
the mean
> between the two group. So, in the specific case of a
paired sample
> t-test, I aim at testing if the difference of cost
is close to 0.
> What is the better way to follow for that?
> 

I can suggest to see:

? pairwise.wilcox.test()
? wilcox.test

using non-parametric tests instead of t-test.

Cordially
Vito


=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From saroj at wayne.edu  Tue Jul 13 19:51:50 2004
From: saroj at wayne.edu (Saroj Mohapatra)
Date: Tue, 13 Jul 2004 10:51:50 -0700
Subject: [R] Difference between normalizeWithinArrays and stat.ma
Message-ID: <000101c46902$13abbe10$7fe40992@BIOINFO>

Dear friends

I have recently migrated to R (8.0) for analysis of microarray data. I
am doing a loess (print-tip, perhaps scaled) normalization. I find that
there are 2 options to do this: using normalizeWithinArrays (Limma) and
stat.ma(sma). I find the objects returned by the two functions are
different, however the M and A values seem to be the same. Is one
function preferable over the other? Any feedback regarding this would be
appreciated.

Thanks and regards,

Saroj

--------------------------
Saroj K Mohapatra, MD
Research Associate
Karmanos Cancer Institute
Wayne State University School of Medicine
110 E. Warren, Room 311
Detroit MI 48201
313-833-0715 x2424
saroj at wayne.edu



From V.Khamenia at biovision-discovery.de  Tue Jul 13 16:54:50 2004
From: V.Khamenia at biovision-discovery.de (Khamenia, Valery)
Date: Tue, 13 Jul 2004 16:54:50 +0200
Subject: [R] LLVM for next R generations
Message-ID: <D15343265276D31197BC00A024A6C110C7931E@EXS_BDC>

Hi R-developers,

  R (unlike say C++) is rather interactive/interpreter language 
  with some high-order functions support. There is a nice project, 
  which able to bring exactly these type of language implementations
  to a next performance level. I mean LLVM (http://llvm.cs.uiuc.edu/)

  LLVM could bring performance of R very close to 
  compilable languages like C++ or even overperform them
  in some cases. Every function in LLVM might be compiled
  in run-time before execution, what is very nice for 
  interactive environments.

  It would be nice if R-developers could take a glance 
  at LLVM before they start to move towards next major 
  version of R.

P.S. i guess this mail is rather for this page with other 
     ideas: http://developer.r-project.org/ideas.txt

with best regards
--
Valery



From f.calboli at ucl.ac.uk  Tue Jul 13 18:06:00 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 13 Jul 2004 17:06:00 +0100
Subject: [R] plotting a table together with graphs
Message-ID: <1089734760.2963.39.camel@monkey>

Dear All,

I would like to ask how to add a table to a "matrix" of graphs.

I have three non linear regression graphs plotted together after:

par(mfrow=c(2,2))

which leaves an empty bottom right corner. I would like to use the space
to add a table (at the moment that's problem number one, adding a "nice"
table will come later). I know it is possible to print tables through
LaTeX and the Design/Hmisc libraries, although I would not have a clue
about printing it together with graphs, but I'd like something "quicker"
if at all possible.

Regards,

Federico Calboli
-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it



From dtrenkler at nts6.oec.uni-osnabrueck.de  Tue Jul 13 17:30:25 2004
From: dtrenkler at nts6.oec.uni-osnabrueck.de (Trenkler, Dietrich)
Date: Tue, 13 Jul 2004 17:30:25 +0200
Subject: [R] plotting a table together with graphs
Message-ID: <FB75CFC167F3D311B11D00A0CC20FB0E885536@nts7.oec.Uni-Osnabrueck.DE>



> -----Original Message-----
> From:	Federico Calboli 
> Sent:	Tuesday, July 13, 2004 6:06 PM
> To:	r-help
> Subject:	[R] plotting a table together with graphs
> 
> Dear All,
> 
> I would like to ask how to add a table to a "matrix" of graphs.
> 
> I have three non linear regression graphs plotted together after:
> 
> par(mfrow=c(2,2))
> 
> which leaves an empty bottom right corner. I would like to use the space
> to add a table (at the moment that's problem number one, adding a "nice"
> table will come later). I know it is possible to print tables through
> LaTeX and the Design/Hmisc libraries, although I would not have a clue
> about printing it together with graphs, but I'd like something "quicker"
> if at all possible.
> 
	[Dietrich Trenkler]  I understand you are using LaTeX. 
	So have a look at the psfrag package.

	HTH

	D. Trenkler



From aubert at inapg.fr  Tue Jul 13 17:32:35 2004
From: aubert at inapg.fr (aubert@inapg.fr)
Date: Tue, 13 Jul 2004 17:32:35 +0200
Subject: [R] compiled C code
Message-ID: <5.1.0.14.0.20040713172944.00b266d0@pop1.inapg.fr>

Hi

I would like to access compiled C code used in hclust and in dist functions 
(in order to create my own functions using new methods). Is it possible ?

Thanks

Julie AUBERT



From spencer.graves at pdf.com  Tue Jul 13 17:30:39 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 13 Jul 2004 08:30:39 -0700
Subject: [R] MLE, precision
In-Reply-To: <20040713142535.81415.qmail@web12210.mail.yahoo.com>
References: <20040713142535.81415.qmail@web12210.mail.yahoo.com>
Message-ID: <40F4001F.80609@pdf.com>

      Have you considered estimating ln.m1, ln.m2, and ln.b, which makes 
the negative log likelihood something like the following: 

l.ln<- function(ln.m1,ln.m2,ln.b){
    m1 <- exp(ln.m1); m2 <- exp(ln.m2); b <- exp(ln.b)
    lglk <- d*( ln.m1 + ln.m2        
         + log1p(-exp(-(b+m2)*t)
         + (m1/b-d)*log(m2+b*exp(-b+m2)*t))
          + m1*t - m1/b*log(b+m2) )

   (-sum(lglk))
}
# NOT TESTED

	  I don't know if I have this correct, but you should get the idea.  Parameterizing in terms of logarithms automatically eliminates the constraints that m1, m2, and b must be positive.  

	  I also prefer to play with the function until I'm reasonably confident it will never produce NAs, and I use a few tricks to preserve numerical precision where I can.  For example, log(b+m2) = log(b) + log1p(m2/b) = log(m2) + log1p(b/m2).  If you use the first form when b is larger and the second when m1 is larger, you should get more accurate answers.  Using, e.g.:  

	  log.apb <- function(log.a, log.b){
	  	  min.ab <- pmin(log.a, log.b)
		  max.ab <- pmax(log.a, log.b)
	  	  max.ab + log1p(exp(min.ab-max.ab))
	  }
	  # NOT TESTED

If log.a and log.b are both really large, a and b could be Inf when log.a and log.b are finite.  Computing log(a+b) like this eliminates that problem.  The same problem occurs when log.a and log.b are so far negative that a and b are both numerically 0, even though log.a and log.b are very finite.  This function eliminates that problem.  

	  Also, have you tried plotting your "l" vs. m1 with m2 and b constant, and then vs. m2 with m2 and b constant and vs. b with m1 and m2 constant?  Or (better) make contour plots of "l" vs. any 2 of these parameters with the other held constant.  When I've done this in crudely similar situations, I've typically found that the log(likelihood) was more nearly parabolic in terms of ln.m1, ln.m2, and ln.b than in terms of the untransformed variables.  This means that the traditional Wald confidence region procedures are more accurate, as they assume that the log(likelihood) is parabolic in the parameters estimated.  

	  hope this  helps.  spencer graves
p.s.  I suggest you avoid using "t" as a variable name:  That's the name of the function for the transpose of a matrix.  R and usually though not always tell from the context what you want.  However, it's best to avoid that ambiguity.  I often test at a command prompt variable names I want to use.  If the response is "object not found", then I feel like I can use it.  

boshao zhang wrote:

>Hi, everyone
>
>I am trying to estimate 3 parameters for my survival
>function. It's very complicated. The negative
>loglikelihood function is:
>
>l<- function(m1,m2,b)  -sum(    d*( log(m1) + log(m2)
>+ log(1- exp(-(b + m2)*t)) ) + (m1/b - d)*log(m2 +
>b*exp(-(b + m2)*t) ) + m1*t - m1/b*log(b+m2)      )
>
>here d and t are given, "sum"  means sum over these
>two vairables. 
>the parameters are assumed small, m1, m2 in
>thousandth, m2 in millionth.
>
>I used the function "nlm" to estimate m1,m2,b. But the
>result is very bad. you can get more than 50 warnings,
>most of them are about "negative infinity"in log. And
>the results are initial value dependent, or you will
>get nothing when you choose some values.
>
>So I tried brutal force, i.e. evaluate the values of
>grid point. It works well. Also, you can get the
>correct answer of log(1e-12).
>
>My questions are:
> What is the precision of a variable in R?
> How to specify the constraint interval of parameters
>in nlm? I tried lower, upper, it doesn't work.
>any advice on MLE is appreciated.
>
>Thank you.
>
>Boshao
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From jmacdon at med.umich.edu  Tue Jul 13 18:12:08 2004
From: jmacdon at med.umich.edu (James MacDonald)
Date: Tue, 13 Jul 2004 12:12:08 -0400
Subject: [R] Difference between normalizeWithinArrays and stat.ma
Message-ID: <s0f3cc8b.071@med-gwia-01a.med.umich.edu>

Since both of the packages you mention are part of Bioconductor, you
would do well to re-post in the correct list
(bioconductor at stat.math.ethz.ch).

Best,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> "Saroj Mohapatra" <saroj at wayne.edu> 07/13/04 01:51PM >>>
Dear friends

I have recently migrated to R (8.0) for analysis of microarray data. I
am doing a loess (print-tip, perhaps scaled) normalization. I find
that
there are 2 options to do this: using normalizeWithinArrays (Limma)
and
stat.ma(sma). I find the objects returned by the two functions are
different, however the M and A values seem to be the same. Is one
function preferable over the other? Any feedback regarding this would
be
appreciated.

Thanks and regards,

Saroj

--------------------------
Saroj K Mohapatra, MD
Research Associate
Karmanos Cancer Institute
Wayne State University School of Medicine
110 E. Warren, Room 311
Detroit MI 48201
313-833-0715 x2424
saroj at wayne.edu 

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Tue Jul 13 18:12:53 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 13 Jul 2004 12:12:53 -0400
Subject: [R] Help with factanal and missing values
In-Reply-To: <Pine.LNX.4.44.0407131518120.1865-100000@ws7.dogbert.ntt.it>
Message-ID: <20040713161255.CAAV26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Antonio, 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Antonio Prioglio
> Sent: Tuesday, July 13, 2004 9:32 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Help with factanal and missing values
> 
> Hi list,
> 
> I'm performing a series of confirmatory factor analysis on 
> different groupings of items from data collected with 
> questionnaires. There are some missing values.
> 
> For those sets with no missing values I call
> factanal(datamatrix,factors=n)
> 
> where datamatrix is a table of all observations for the items 
> under investigation.
> 
> This call fails when there are missing values.
> help(factanal) does not give an example on calls with  
> na.action and and mentiones a formula.
> 
> (Venables and Ripley, 2002 give only one example on p. 323 
> for a case where the covariance has already been calculated)
> 
> Could someone give me an example on such a call for a simple CFA?

Two solutions are to use na.omit() to eliminate observations with missing
data -- factanal(na.omit(datamatrix), factors=n) -- or to use a formula
argument to factanal and pass the data as a data frame via the data argument
-- factanal(~ var1 + ... + vark, factors=n, data=as.data.frame(datamatrix)).

By the way, what factanal() does would conventionally be described as
exploratory, not confirmatory, factor analysis. For the latter, you might
try the sem package.

I hope that this helps,
 John



From saroj at wayne.edu  Tue Jul 13 21:39:11 2004
From: saroj at wayne.edu (Saroj Mohapatra)
Date: Tue, 13 Jul 2004 12:39:11 -0700
Subject: [R] Difference between normalizeWithinArrays and stat.ma
Message-ID: <000001c46911$13fec240$7fe40992@BIOINFO>

Dear friends

I have recently migrated to R (8.0) for analysis of microarray data. I
am doing a loess (print-tip, perhaps scaled) normalization. I find that
there are 2 options to do this: using normalizeWithinArrays (Limma) and
stat.ma(sma). I find the objects returned by the two functions are
different, however the M and A values seem to be the same. Is one
function preferable over the other? Any feedback regarding this would be
appreciated.

Thanks and regards,

Saroj

--------------------------
Saroj K Mohapatra, MD
Research Associate
Karmanos Cancer Institute
Wayne State University School of Medicine
110 E. Warren, Room 311
Detroit MI 48201
313-833-0715 x2424
saroj at wayne.edu



From thchung at tgen.org  Tue Jul 13 18:46:20 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Tue, 13 Jul 2004 09:46:20 -0700
Subject: [R] e1071 question: what's the definition of performance in t
	une.* functions?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8031@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8031@usrymx25.merck.com>
Message-ID: <2B3678E6-D4EC-11D8-A8FF-000A95B43CDE@tgen.org>

Thank you Andy.

It seems like this can be the reason for the confusion.
I never thought that there can be this kind of catches for using tune.* 
functions.
For the record, I actually emailed to Dr. Friedrich Leisch the author 
of this library.
When I get some reply, I will post it also.

Regards,
TH

On Jul 12, 2004, at 6:40 PM, Liaw, Andy wrote:

> Looking at the body of tune(), it has:
>
> ...
>                 repeat.errors[reps] <- if (is.factor(true.y))
>                   1 - classAgreement(table(pred, true.y))
>                 else crossprod(pred - true.y)/length(pred)
> ...
>
> where classAgreement() is a function defined inside tune() that 
> computes the
> fraction of correctly predicted cases.  So it looks like tune() and 
> friends
> are returning error rates as fractions, not percentages.
>
> You're right that the fraction shouldn't be larger than 1.  Did you 
> make
> sure that tune() sees the data as classification, not regression 
> (i.e., did
> you make sure that the class labels given to tune.*() are factor)?
>
> HTH,
> Andy

Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From ligges at statistik.uni-dortmund.de  Tue Jul 13 18:59:25 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 Jul 2004 18:59:25 +0200
Subject: [R] compiled C code
In-Reply-To: <5.1.0.14.0.20040713172944.00b266d0@pop1.inapg.fr>
References: <5.1.0.14.0.20040713172944.00b266d0@pop1.inapg.fr>
Message-ID: <40F414ED.1040303@statistik.uni-dortmund.de>

aubert at inapg.fr wrote:

> Hi
> 
> I would like to access compiled C code used in hclust and in dist 
> functions (in order to create my own functions using new methods). Is it 
> possible ?

Yes. Do you want to modify it or just use it? Using it is simple. Just 
load the package and go ahead ....

Uwe Ligges


> Thanks
> 
> Julie AUBERT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Jul 13 19:04:18 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 Jul 2004 19:04:18 +0200
Subject: [R] Synatx Error on start with R --no-save < myfile.R
In-Reply-To: <200407131248.31620.philipp.heuser@uni-koeln.de>
References: <200407131248.31620.philipp.heuser@uni-koeln.de>
Message-ID: <40F41612.30407@statistik.uni-dortmund.de>

Philipp Heuser wrote:

> Dear all!
> 
> I wrote my R-code with an editor and loaded it with source("my_file.R"). 
> Everything works fine as expected.
> 
> When I try to start my code with:
> R --no-save < my_file.R 
> 
> I do get a synatx error half way through. The version is 1.9.0 on a Linux 
> system. To start it with  R --no-save < my_file.R works on some machines but 
> on some it doesn't.


Strange, you might experience that some buffers reaching their limits. 
But we cannot know without the code in my_file.R

Anyway, please try the recommended solution instead:

   R BATCH --no-save my_file.R

Uwe Ligges





> Are there any rules I've to consider, when I want to start it that way?
> Any ideas what might cause syntax errors when starting code like that?
> 
> Regards
> Philipp
> 
>



From partha_bagchi at hgsi.com  Tue Jul 13 17:32:17 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 13 Jul 2004 11:32:17 -0400
Subject: [R] plotting a table together with graphs
Message-ID: <OFC02DE29C.0082A6B5-ON85256ED0.00554F0F-85256ED0.00555B2A@hgsi.com>

Take a look at Textplot in the gregmisc package ...





Federico Calboli <f.calboli at ucl.ac.uk>
Sent by: r-help-bounces at stat.math.ethz.ch
07/13/2004 12:06 PM
Please respond to f.calboli

 
        To:     r-help <r-help at stat.math.ethz.ch>
        cc: 
        Subject:        [R] plotting a table together with graphs


Dear All,

I would like to ask how to add a table to a "matrix" of graphs.

I have three non linear regression graphs plotted together after:

par(mfrow=c(2,2))

which leaves an empty bottom right corner. I would like to use the space
to add a table (at the moment that's problem number one, adding a "nice"
table will come later). I know it is possible to print tables through
LaTeX and the Design/Hmisc libraries, although I would not have a clue
about printing it together with graphs, but I'd like something "quicker"
if at all possible.

Regards,

Federico Calboli
--



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From partha_bagchi at hgsi.com  Tue Jul 13 17:19:58 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 13 Jul 2004 11:19:58 -0400
Subject: [R] plotting a table together with graphs
Message-ID: <OFA438F547.E75F2E2A-ON85256ED0.0053FAAC-85256ED0.00543A4A@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040713/2a8e0923/attachment.pl

From scott.waichler at pnl.gov  Tue Jul 13 18:57:54 2004
From: scott.waichler at pnl.gov (Scott Waichler)
Date: Tue, 13 Jul 2004 09:57:54 -0700
Subject: [R] summary() doesn't work with Date class objects
Message-ID: <200407131657.i6DGvsv18895@snow.pnl.gov>


The handy function summary() doesn't work correctly with Date class
objects:

> R.version.string
[1] "R version 1.9.1, 2004-06-21"
> b <- as.Date(c("2002-12-26", "2002-12-27", "2002-12-28", "2002-12-29", "2002-12-30"))
> b
[1] "2002-12-26" "2002-12-27" "2002-12-28" "2002-12-29" "2002-12-30"
> summary(b)
        Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
"2002-12-29" "2002-12-29" "2002-12-29" "2002-12-29" "2002-12-29" "2002-12-29"

Scott Waichler
Pacific Northwest National Laboratory
Richland, WA   99352    USA
scott.waichler at pnl.gov



From a.prioglio at city.ac.uk  Tue Jul 13 19:49:55 2004
From: a.prioglio at city.ac.uk (Antonio Prioglio)
Date: Tue, 13 Jul 2004 18:49:55 +0100 (BST)
Subject: [R] Help with factanal and missing values
In-Reply-To: <20040713161255.CAAV26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.44.0407131842430.1865-100000@ws7.dogbert.ntt.it>

On Tue, 13 Jul 2004, John Fox wrote:
> 
> Two solutions are to use na.omit() to eliminate observations with missing
> data -- factanal(na.omit(datamatrix), factors=n) -- or to use a formula
> argument to factanal and pass the data as a data frame via the data argument
> -- factanal(~ var1 + ... + vark, factors=n, data=as.data.frame(datamatrix)).

Thanks this was helpful and more elegant than my solution to select the 
data with a call to complete.cases().

> 
> By the way, what factanal() does would conventionally be described as
> exploratory, not confirmatory, factor analysis. For the latter, you might
> try the sem package.
> 

Actually these CFAs are preliminary to a Path Analysis I had ambitions to 
do with the sem package rather than LISREL.

Could you give an example on how to do CFA with sem?

Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From jfox at mcmaster.ca  Tue Jul 13 20:13:49 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 13 Jul 2004 14:13:49 -0400
Subject: [R] Help with factanal and missing values
In-Reply-To: <Pine.LNX.4.44.0407131842430.1865-100000@ws7.dogbert.ntt.it>
Message-ID: <20040713181351.UFVB6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Antonio, 

> -----Original Message-----
> From: Antonio Prioglio [mailto:a.prioglio at city.ac.uk] 
> Sent: Tuesday, July 13, 2004 12:50 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Help with factanal and missing values
> 
> On Tue, 13 Jul 2004, John Fox wrote:
> > 
> > Two solutions are to use na.omit() to eliminate observations with 
> > missing data -- factanal(na.omit(datamatrix), factors=n) -- 
> or to use 
> > a formula argument to factanal and pass the data as a data 
> frame via 
> > the data argument
> > -- factanal(~ var1 + ... + vark, factors=n, 
> data=as.data.frame(datamatrix)).
> 
> Thanks this was helpful and more elegant than my solution to 
> select the data with a call to complete.cases().
> 
> > 
> > By the way, what factanal() does would conventionally be 
> described as 
> > exploratory, not confirmatory, factor analysis. For the latter, you 
> > might try the sem package.
> > 
> 
> Actually these CFAs are preliminary to a Path Analysis I had 
> ambitions to do with the sem package rather than LISREL.
> 
> Could you give an example on how to do CFA with sem?

Among the examples in ?sem is a second-order CFA.

Regards,
 John



From f.duan at yale.edu  Tue Jul 13 20:34:44 2004
From: f.duan at yale.edu (F Duan)
Date: Tue, 13 Jul 2004 14:34:44 -0400
Subject: [R] Is there a statistics that can summarize the correlation for
 more than two random variables?
Message-ID: <01LCEZQ1LKA20035KD@biomed.med.yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040713/45c15359/attachment.pl

From baron at psych.upenn.edu  Tue Jul 13 20:47:06 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 13 Jul 2004 14:47:06 -0400
Subject: [R] Is there a statistics that can summarize the correlation for
	more than two random variables?
In-Reply-To: <01LCEZQ1LKA20035KD@biomed.med.yale.edu>
References: <01LCEZQ1LKA20035KD@biomed.med.yale.edu>
Message-ID: <20040713184706.GA27275@psych>

On 07/13/04 14:34, F Duan wrote:
>Hi, R people,
>
>
>
>I wonder if there is a statistics than can measure the correlation for more
>than two random variables, instead of computing the correlation coefficient
>matrix. If so, what R package should I use?

One possibility is Cronbach's alpha, which is in the psy
package.  It is describe a little in our "Notes on R for
psychology ..." (linked from the R page below), written befpre
psy was available.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From a.prioglio at city.ac.uk  Tue Jul 13 20:52:51 2004
From: a.prioglio at city.ac.uk (Antonio Prioglio)
Date: Tue, 13 Jul 2004 19:52:51 +0100 (BST)
Subject: [R] Help with factanal and missing values
In-Reply-To: <20040713181351.UFVB6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.44.0407131937500.1865-100000@ws7.dogbert.ntt.it>

On Tue, 13 Jul 2004, John Fox wrote:
> > Could you give an example on how to do CFA with sem?
> 
> Among the examples in ?sem is a second-order CFA.

Ok, sorry I forgot about the Thurstone example as I was focusing on Path 
Analysis example when reading the sem doc.

I understand this is a model taken from another source.

In the model specification I notice a F4->F1, F4->F2, F4->F3.

This is something I do not understand.

In a "normal" case where one is iterested in the factorial validity of the 
indicator variables, would it be appropiate to use the same specification 
just omitting the above links?

Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From altirriba at hotmail.com  Tue Jul 13 21:07:00 2004
From: altirriba at hotmail.com (=?iso-8859-1?B?Sm9yZGkgQWx0aXJyaWJhIEd1dGnpcnJleg==?=)
Date: Tue, 13 Jul 2004 21:07:00 +0200
Subject: [R] Permutations
Message-ID: <BAY15-F21OSCBfAbdxk0001f04a@hotmail.com>

Dear R users,
I?m a beginner user of R and I?ve a problem with permutations that I don?t 
know how to solve. I?ve 12 elements in blocks of 3 elements and I want only 
to make permutations inter-blocks (no intra-blocks) (sorry if the 
terminology is not accurate), something similar to:

1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation

1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
   -  -
3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
-  -  -
1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
      -    -
4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
-  -  -   -  -  -
4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
           -  -
....

  Thanks for your time,

Jordi Altirriba
Ph D student

Hospital Clinic - Barcelona - Spain


MSN Motor. http://motor.msn.es/researchcentre/



From MSchwartz at MedAnalytics.com  Tue Jul 13 21:29:59 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 13 Jul 2004 14:29:59 -0500
Subject: [R] Permutations
In-Reply-To: <BAY15-F21OSCBfAbdxk0001f04a@hotmail.com>
References: <BAY15-F21OSCBfAbdxk0001f04a@hotmail.com>
Message-ID: <1089746999.3830.236.camel@localhost.localdomain>

On Tue, 2004-07-13 at 14:07, Jordi Altirriba Gutirrez wrote:
> Dear R users,
> Im a beginner user of R and Ive a problem with permutations that I dont 
> know how to solve. Ive 12 elements in blocks of 3 elements and I want only 
> to make permutations inter-blocks (no intra-blocks) (sorry if the 
> terminology is not accurate), something similar to:
> 
> 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation
> 
> 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
>    -  -
> 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
> -  -  -
> 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
>       -    -
> 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
> -  -  -   -  -  -
> 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
>            -  -
> ....

You can use the permutations() function in the 'gregmisc' package on
CRAN:

# Assuming you installed 'gregmisc' and used library(gregmisc)
# First create 'groups' consisting of the four blocks
groups <- c("1 2 3", "4 5 6", "7 8 9", "10 11 12")

# Now create a 4 column matrix containing the permutations
# The call to permutations() here indicates the number of blocks in
# groups (4), the required length of the output (4) and the vector of
# elements to permute
perms <- matrix(permutations(4, 4, groups), ncol = 4)

> perms
      [,1]       [,2]       [,3]       [,4]      
 [1,] "1 2 3"    "10 11 12" "4 5 6"    "7 8 9"   
 [2,] "1 2 3"    "10 11 12" "7 8 9"    "4 5 6"   
 [3,] "1 2 3"    "4 5 6"    "10 11 12" "7 8 9"   
 [4,] "1 2 3"    "4 5 6"    "7 8 9"    "10 11 12"
 [5,] "1 2 3"    "7 8 9"    "10 11 12" "4 5 6"   
 [6,] "1 2 3"    "7 8 9"    "4 5 6"    "10 11 12"
 [7,] "10 11 12" "1 2 3"    "4 5 6"    "7 8 9"   
 [8,] "10 11 12" "1 2 3"    "7 8 9"    "4 5 6"   
 [9,] "10 11 12" "4 5 6"    "1 2 3"    "7 8 9"   
[10,] "10 11 12" "4 5 6"    "7 8 9"    "1 2 3"   
[11,] "10 11 12" "7 8 9"    "1 2 3"    "4 5 6"   
[12,] "10 11 12" "7 8 9"    "4 5 6"    "1 2 3"   
[13,] "4 5 6"    "1 2 3"    "10 11 12" "7 8 9"   
[14,] "4 5 6"    "1 2 3"    "7 8 9"    "10 11 12"
[15,] "4 5 6"    "10 11 12" "1 2 3"    "7 8 9"   
[16,] "4 5 6"    "10 11 12" "7 8 9"    "1 2 3"   
[17,] "4 5 6"    "7 8 9"    "1 2 3"    "10 11 12"
[18,] "4 5 6"    "7 8 9"    "10 11 12" "1 2 3"   
[19,] "7 8 9"    "1 2 3"    "10 11 12" "4 5 6"   
[20,] "7 8 9"    "1 2 3"    "4 5 6"    "10 11 12"
[21,] "7 8 9"    "10 11 12" "1 2 3"    "4 5 6"   
[22,] "7 8 9"    "10 11 12" "4 5 6"    "1 2 3"   
[23,] "7 8 9"    "4 5 6"    "1 2 3"    "10 11 12"
[24,] "7 8 9"    "4 5 6"    "10 11 12" "1 2 3"   

HTH,

Marc Schwartz



From MSchwartz at MedAnalytics.com  Tue Jul 13 21:39:01 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 13 Jul 2004 14:39:01 -0500
Subject: [R] Permutations
In-Reply-To: <1089746999.3830.236.camel@localhost.localdomain>
References: <BAY15-F21OSCBfAbdxk0001f04a@hotmail.com>
	<1089746999.3830.236.camel@localhost.localdomain>
Message-ID: <1089747541.3830.244.camel@localhost.localdomain>

On Tue, 2004-07-13 at 14:29, Marc Schwartz wrote:
> On Tue, 2004-07-13 at 14:07, Jordi Altirriba Gutirrez wrote:
> > Dear R users,
> > Im a beginner user of R and Ive a problem with permutations that I dont 
> > know how to solve. Ive 12 elements in blocks of 3 elements and I want only 
> > to make permutations inter-blocks (no intra-blocks) (sorry if the 
> > terminology is not accurate), something similar to:
> > 
> > 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation
> > 
> > 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
> >    -  -
> > 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
> > -  -  -
> > 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
> >       -    -
> > 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
> > -  -  -   -  -  -
> > 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
> >            -  -
> > ....
> 
> You can use the permutations() function in the 'gregmisc' package on
> CRAN:
> 
> # Assuming you installed 'gregmisc' and used library(gregmisc)
> # First create 'groups' consisting of the four blocks
> groups <- c("1 2 3", "4 5 6", "7 8 9", "10 11 12")
> 
> # Now create a 4 column matrix containing the permutations
> # The call to permutations() here indicates the number of blocks in
> # groups (4), the required length of the output (4) and the vector of
> # elements to permute
> perms <- matrix(permutations(4, 4, groups), ncol = 4)


Ack....one correction. The use of matrix() here was actually redundant.

You can use:

> permutations(4, 4, groups)
      [,1]       [,2]       [,3]       [,4]      
 [1,] "1 2 3"    "10 11 12" "4 5 6"    "7 8 9"   
 [2,] "1 2 3"    "10 11 12" "7 8 9"    "4 5 6"   
 [3,] "1 2 3"    "4 5 6"    "10 11 12" "7 8 9"   
 [4,] "1 2 3"    "4 5 6"    "7 8 9"    "10 11 12"
 [5,] "1 2 3"    "7 8 9"    "10 11 12" "4 5 6"   
 [6,] "1 2 3"    "7 8 9"    "4 5 6"    "10 11 12"
 [7,] "10 11 12" "1 2 3"    "4 5 6"    "7 8 9"   
 [8,] "10 11 12" "1 2 3"    "7 8 9"    "4 5 6"   
 [9,] "10 11 12" "4 5 6"    "1 2 3"    "7 8 9"   
[10,] "10 11 12" "4 5 6"    "7 8 9"    "1 2 3"   
[11,] "10 11 12" "7 8 9"    "1 2 3"    "4 5 6"   
[12,] "10 11 12" "7 8 9"    "4 5 6"    "1 2 3"   
[13,] "4 5 6"    "1 2 3"    "10 11 12" "7 8 9"   
[14,] "4 5 6"    "1 2 3"    "7 8 9"    "10 11 12"
[15,] "4 5 6"    "10 11 12" "1 2 3"    "7 8 9"   
[16,] "4 5 6"    "10 11 12" "7 8 9"    "1 2 3"   
[17,] "4 5 6"    "7 8 9"    "1 2 3"    "10 11 12"
[18,] "4 5 6"    "7 8 9"    "10 11 12" "1 2 3"   
[19,] "7 8 9"    "1 2 3"    "10 11 12" "4 5 6"   
[20,] "7 8 9"    "1 2 3"    "4 5 6"    "10 11 12"
[21,] "7 8 9"    "10 11 12" "1 2 3"    "4 5 6"   
[22,] "7 8 9"    "10 11 12" "4 5 6"    "1 2 3"   
[23,] "7 8 9"    "4 5 6"    "1 2 3"    "10 11 12"
[24,] "7 8 9"    "4 5 6"    "10 11 12" "1 2 3"  

Sorry about that.

Marc



From dsheuman at rogers.com  Tue Jul 13 21:58:42 2004
From: dsheuman at rogers.com (Danny Heuman)
Date: Tue, 13 Jul 2004 15:58:42 -0400 (EDT)
Subject: [R] Calculating sum of squares deviation between 2 similar matrices
Message-ID: <20040713195842.74411.qmail@web88002.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040713/410cf475/attachment.pl

From rolf at math.unb.ca  Tue Jul 13 22:02:25 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 13 Jul 2004 17:02:25 -0300 (ADT)
Subject: [R] Permutations
Message-ID: <200407132002.i6DK2PPK018059@erdos.math.unb.ca>


Marc Schwartz wrote (in response to a question from Jordi Altirriba):

> You can use the permutations() function in the 'gregmisc' package on
> CRAN:
> 
> # Assuming you installed 'gregmisc' and used library(gregmisc)
> # First create 'groups' consisting of the four blocks
> groups <- c("1 2 3", "4 5 6", "7 8 9", "10 11 12")
> 
> # Now create a 4 column matrix containing the permutations
> # The call to permutations() here indicates the number of blocks in
> # groups (4), the required length of the output (4) and the vector of
> # elements to permute
> perms <- matrix(permutations(4, 4, groups), ncol = 4)
> 
> > perms
>       [,1]       [,2]       [,3]       [,4]      
>  [1,] "1 2 3"    "10 11 12" "4 5 6"    "7 8 9"   
>  [2,] "1 2 3"    "10 11 12" "7 8 9"    "4 5 6"   
>  [3,] "1 2 3"    "4 5 6"    "10 11 12" "7 8 9"   
>  [4,] "1 2 3"    "4 5 6"    "7 8 9"    "10 11 12"
>  [5,] "1 2 3"    "7 8 9"    "10 11 12" "4 5 6"   
>  [6,] "1 2 3"    "7 8 9"    "4 5 6"    "10 11 12"
>  [7,] "10 11 12" "1 2 3"    "4 5 6"    "7 8 9"   
>  [8,] "10 11 12" "1 2 3"    "7 8 9"    "4 5 6"   
>  [9,] "10 11 12" "4 5 6"    "1 2 3"    "7 8 9"   
> [10,] "10 11 12" "4 5 6"    "7 8 9"    "1 2 3"   
> [11,] "10 11 12" "7 8 9"    "1 2 3"    "4 5 6"   
> [12,] "10 11 12" "7 8 9"    "4 5 6"    "1 2 3"   
> [13,] "4 5 6"    "1 2 3"    "10 11 12" "7 8 9"   
> [14,] "4 5 6"    "1 2 3"    "7 8 9"    "10 11 12"
> [15,] "4 5 6"    "10 11 12" "1 2 3"    "7 8 9"   
> [16,] "4 5 6"    "10 11 12" "7 8 9"    "1 2 3"   
> [17,] "4 5 6"    "7 8 9"    "1 2 3"    "10 11 12"
> [18,] "4 5 6"    "7 8 9"    "10 11 12" "1 2 3"   
> [19,] "7 8 9"    "1 2 3"    "10 11 12" "4 5 6"   
> [20,] "7 8 9"    "1 2 3"    "4 5 6"    "10 11 12"
> [21,] "7 8 9"    "10 11 12" "1 2 3"    "4 5 6"   
> [22,] "7 8 9"    "10 11 12" "4 5 6"    "1 2 3"   
> [23,] "7 8 9"    "4 5 6"    "1 2 3"    "10 11 12"
> [24,] "7 8 9"    "4 5 6"    "10 11 12" "1 2 3"   

This does not solve the problem that was posed.  It only permutes the
blocks, and does not allow for swapping between blocks.  For instance
it does produce the ``acceptable'' permutation

	1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation

I would guess that a correct solution is likely to be pretty
difficult.  I mean, one ***could*** just generate all 12!
permutations of 1 to 12 and filter out the unacceptable ones.  But
this is getting unwieldy (12! is close to half a billion) and is
inelegant.  And the method does not ``generalize'' worth a damn.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From flom at ndri.org  Tue Jul 13 22:05:43 2004
From: flom at ndri.org (Peter Flom)
Date: Tue, 13 Jul 2004 16:05:43 -0400
Subject: [R] Is there a statistics that can summarize the
	correlation formore than two random variables?
Message-ID: <s0f40884.042@MAIL.NDRI.ORG>

This seems more like a STATS question than an R question - asking on a
list like STAT-L or ALLSTAT may result in more replies

Nevertheless, it seems to me that you need to describe (and maybe
decide) what you mean by 'summarize' the correlations.  Certainly the
mean DOES summarize them, but is it the summary you want? Maybe, maybe
not.  Perhaps the median? Or a trimmed mean? Do you want to take the
absolute values of the correlations, or not? 

HTH



Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)


>>> F Duan <f.duan at yale.edu> 07/13/04 2:34 PM >>>
Hi, R people,

 

I wonder if there is a statistics than can measure the correlation for
more
than two random variables, instead of computing the correlation
coefficient
matrix. If so, what R package should I use? 

 

Right now I can only think of the mean of all pair-wise correlation
coefficients, e.g., (corr(x,y) + corr(x,z) + corr(y,z)) / 3 for three
random
variables (x, y, z). 

 

Thanks a lot,

 

Frank


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From cdbroeckling at noble.org  Tue Jul 13 22:06:35 2004
From: cdbroeckling at noble.org (Broeckling, Corey)
Date: Tue, 13 Jul 2004 15:06:35 -0500
Subject: [R] slicing interaction terms
Message-ID: <6B4878EA887E6C45AAA5AAC4C6017B0E0101165F@mail-1.noble.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040713/b2edacee/attachment.pl

From RBaskin at ahrq.gov  Tue Jul 13 22:12:46 2004
From: RBaskin at ahrq.gov (Baskin, Robert)
Date: Tue, 13 Jul 2004 16:12:46 -0400
Subject: [R] Permutations
Message-ID: <6BCD3F430455B1418750004BCD279259029262A5@exchange2.ahrq.gov>

I may be confused, but I think what you described will produce greater than
472 million permutations.  I think your second permutation <1 2 4 | 3 5 6 |
7 8 9 | 10 11 12   YES-----2nd permutation> shows that you want more than
just a permutation of entire blocks.

There are a total of 12! (12 factorial) permutations of 1:12 ignoring your
blocking restriction.

There are 3! * 9! Permutations in which the first block has an intrablock
permutation and the rest of the 9 symbols can do anything.  Since there are
4 blocks then there are fewer than 4 * 3! * 9! permutations with intra-block
transfers (this 4*3!*9! double counts some intrablock permutations - you
need to take out of the 9! the count of intra-block only permutations among
the remaining 9 symbols: 3!*3!*3!).

This gives more than 
12! - 4*3!*9! + 1 = 9!*[12*11*10 - 4*3*2*1] + 1 = 12*9![110 - 2] + 1 ~ 472
million permutations.

How could you possibly deal with all of these permutations?  If you can deal
with this much junk then maybe you can generate all 12! Permutations and
take out the ones you don't want.

Sorry if I got it totally wrong
bob



-----Original Message-----
From: Jordi Altirriba Guti??rrez [mailto:altirriba at hotmail.com] 
Sent: Tuesday, July 13, 2004 3:07 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Permutations


Dear R users,
I'm a beginner user of R and I've a problem with permutations that I don't 
know how to solve. I've 12 elements in blocks of 3 elements and I want only 
to make permutations inter-blocks (no intra-blocks) (sorry if the 
terminology is not accurate), something similar to:

1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation

1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
   -  -
3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
-  -  -
1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
      -    -
4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
-  -  -   -  -  -
4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
           -  -
....

  Thanks for your time,

Jordi Altirriba
Ph D student

Hospital Clinic - Barcelona - Spain


MSN Motor. http://motor.msn.es/researchcentre/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From a.prioglio at city.ac.uk  Tue Jul 13 22:21:57 2004
From: a.prioglio at city.ac.uk (Antonio Prioglio)
Date: Tue, 13 Jul 2004 21:21:57 +0100 (BST)
Subject: [R] Help with factanal and missing values
In-Reply-To: <20040713181351.UFVB6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.44.0407132114290.1865-100000@ws7.dogbert.ntt.it>

On Tue, 13 Jul 2004, John Fox wrote:

> 
> Among the examples in ?sem is a second-order CFA.
> 
Thanks now I have it running, hopefully in a correct way.

By the way I notice in the output a GFI index that in your online appendix
to your 2002 book describe as an ad hoc measure.

Could you comment on how it compares with the Comparative Fit Index (CFI; 
Bentler, 1990) which according to Byrne 1994 is a revised version of the 
Bentler-Bonnet (1980) Normed Fit Index?

Thanks again for your valuable help.

Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From david.meyer at wu-wien.ac.at  Tue Jul 13 22:54:31 2004
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Tue, 13 Jul 2004 22:54:31 +0200
Subject: [R] Re: R library(e1071) question: definition of performance in
 tune.* functions
Message-ID: <20040713225431.4547a14c.david.meyer@wu-wien.ac.at>

Tae-Hoon:

> When we run tune.* for parameter tuning, we get performance value.
> Can you tell me what the definition of it is?

The values returned by tune() are Mean Squared Errors in case of
regression, and simple rates (*no* percentages) in case of
classification. As Andy already suggested, you might want to check if
your target variable is indeed a factor. In case it is and you still get
values greater than 1, drop me a mail with a piece of code (and data)
enabling me to reproduce the phenomenon. 

Best,
David

-- 
Dr. David Meyer
Department of Information Systems

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Fax: +43-1-313 36x746 
Tel: +43-1-313 36x4393
HP:  http://wi.wu-wien.ac.at/Wer_sind_wir/meyer/



From thchung at tgen.org  Tue Jul 13 23:04:19 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Tue, 13 Jul 2004 14:04:19 -0700
Subject: [R] Re: R library(e1071) question: definition of performance in
	tune.* functions
In-Reply-To: <20040713225431.4547a14c.david.meyer@wu-wien.ac.at>
References: <20040713225431.4547a14c.david.meyer@wu-wien.ac.at>
Message-ID: <356C6C2E-D510-11D8-A8FF-000A95B43CDE@tgen.org>

Thank you David and Andy. Now, everything is clear.
For others, the problem is the one said in the subject, and the answer 
is the one excerpted from reply from David.

TH.
On Jul 13, 2004, at 1:54 PM, David Meyer wrote:

> Tae-Hoon:
>
>> When we run tune.* for parameter tuning, we get performance value.
>> Can you tell me what the definition of it is?
>
> The values returned by tune() are Mean Squared Errors in case of
> regression, and simple rates (*no* percentages) in case of
> classification. As Andy already suggested, you might want to check if
> your target variable is indeed a factor. In case it is and you still 
> get
> values greater than 1, drop me a mail with a piece of code (and data)
> enabling me to reproduce the phenomenon.
>
> Best,
> David
>
> -- 
> Dr. David Meyer
> Department of Information Systems
>
> Vienna University of Economics and Business Administration
> Augasse 2-6, A-1090 Wien, Austria, Europe
> Fax: +43-1-313 36x746
> Tel: +43-1-313 36x4393
> HP:  http://wi.wu-wien.ac.at/Wer_sind_wir/meyer/
>
>
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From anne at wjh.harvard.edu  Wed Jul 14 00:00:37 2004
From: anne at wjh.harvard.edu (Anne G)
Date: Tue, 13 Jul 2004 18:00:37 -0400 (EDT)
Subject: [R] creating your own glm link function
Message-ID: <Pine.SOL.4.30.0407131753490.7348-100000@wjh1.wjh.harvard.edu>

In sas and matlab, I have been using a modified link
function.

I use a binomial distribution with the link log(p-.5/1-p)
instead of log(p/1-p) which is the usual logit link. This
allows the probabilities to go from .5 to 1 instead of 0 to
1. which is typical when probabilities vary between chance
(.5) and certainty (1) in psychophysics experiments.

I am trying to access if R can do it. If so could someone
show me how to set up the link function so I can call it in
the glm function?

I know very little about R, the help reads like greek to me,
and I can't find an example anywhere.

Getting desperate!

Anne



From rolf at math.unb.ca  Tue Jul 13 23:58:54 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 13 Jul 2004 18:58:54 -0300 (ADT)
Subject: [R] Permutations
Message-ID: <200407132158.i6DLwsjP021961@erdos.math.unb.ca>

As has been pointed out by Robert Baskin, your ``restricted''
permutations comprise the bulk of all permutations; i.e. the
restriction isn't as restrictive as one might have expected.

So constructing ***all*** restricted permutations is probably not
very useful.

However if you simply wish to ***generate*** restricted permutations
at random, then your problem is (I think) solvable as follows:
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
restr.perm <- function () 
{
S <- 4:12
G <- NULL
A <- list(1:3,4:6,7:9,10:12)
for(k in 1:4) {
	for(i in A[[k]]) {
		tmp <- union(i,S)
		tmp <- setdiff(tmp,G)
		x <- if(length(tmp)==1) tmp else sample(tmp,1)
		G <- c(G,x)
		S <- setdiff(S,G)
	}
	S <- union(S,A[[k]])
	R <- if(k < 4) A[[k+1]] else NULL
	R <- union(R,G)
	S <- setdiff(S,R)
}
G
}
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

Sample output:

 > set.seed(42)
 > restr.perm()
 [1] 12 11  5  2 10  9  4  8  3  7  1  6
 > restr.perm()
 [1] 10 12  5  9  3  2  7  1  4  8 11  6

which look O.K. according to my understanding of your criterion
for ``acceptable'' permutations.

				cheers,

					Rolf Turner
					rolf at math.unb.ca

Jordi Altirriba wrote:

> Dear R users,
> I'm a beginner user of R and I've a problem with permutations that I
> don't know how to solve. I've 12 elements in blocks of 3 elements and
> I want only to make permutations inter-blocks (no intra-blocks)
> (sorry if the terminology is not accurate), something similar to:
> 
> 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation
> 
> 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
>    -  -
> 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
> -  -  -
> 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
>       -    -
> 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
> -  -  -   -  -  -
> 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
>            -  -
> ....
> 
>   Thanks for your time,
> 
> Jordi Altirriba
> Ph D student
> 
> Hospital Clinic - Barcelona - Spain
> 
> 
> MSN Motor. http://motor.msn.es/researchcentre/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> From r-help-bounces at stat.math.ethz.ch Tue Jul 13 17:19:55 2004
> From: "Baskin, Robert" <RBaskin at ahrq.gov>
> To: =?iso-8859-1?Q?=27Jordi_Altirriba_Guti=E9rrez=27?= <altirriba at hotmail.com>,
>         r-help at stat.math.ethz.ch
> Subject: RE: [R] Permutations
> Date: Tue, 13 Jul 2004 16:12:46 -0400
> MIME-Version: 1.0
> X-OriginalArrivalTime: 13 Jul 2004 20:14:08.0328 (UTC)
> 	FILETIME=[F4123480:01C46915]
> Received-SPF: none (hypatia: domain of r-help-bounces at stat.math.ethz.ch does not designate permitted sender hosts)
> Received-SPF: none (hypatia: domain of rbaskin at ahrq.gov does not designate
> 	permitted sender hosts)
> X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
> Content-Transfer-Encoding: 8bit
> X-MIME-Autoconverted: from quoted-printable to 8bit by hypatia.math.ethz.ch id
> 	i6DKABdp031609
> Cc: 
> X-BeenThere: r-help at stat.math.ethz.ch
> X-Mailman-Version: 2.1.5
> List-Id: "Main R Mailing List: Primary help" <r-help.stat.math.ethz.ch>
> List-Unsubscribe: <https://www.stat.math.ethz.ch/mailman/listinfo/r-help>,
> 	<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
> List-Archive: <https://www.stat.math.ethz.ch/pipermail/r-help>
> List-Post: <mailto:r-help at stat.math.ethz.ch>
> List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
> List-Subscribe: <https://www.stat.math.ethz.ch/mailman/listinfo/r-help>,
> 	<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
> X-Spam-Math-Flag: NO
> X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on erdos.math.unb.ca
> X-Spam-Math-Status: No, hits=-4.9 required=5.0 tests=BAYES_00 autolearn=ham 
> 	version=2.63
> 
> I may be confused, but I think what you described will produce greater than
> 472 million permutations.  I think your second permutation <1 2 4 | 3 5 6 |
> 7 8 9 | 10 11 12   YES-----2nd permutation> shows that you want more than
> just a permutation of entire blocks.
> 
> There are a total of 12! (12 factorial) permutations of 1:12 ignoring your
> blocking restriction.
> 
> There are 3! * 9! Permutations in which the first block has an intrablock
> permutation and the rest of the 9 symbols can do anything.  Since there are
> 4 blocks then there are fewer than 4 * 3! * 9! permutations with intra-block
> transfers (this 4*3!*9! double counts some intrablock permutations - you
> need to take out of the 9! the count of intra-block only permutations among
> the remaining 9 symbols: 3!*3!*3!).
> 
> This gives more than 
> 12! - 4*3!*9! + 1 = 9!*[12*11*10 - 4*3*2*1] + 1 = 12*9![110 - 2] + 1 ~ 472
> million permutations.
> 
> How could you possibly deal with all of these permutations?  If you can deal
> with this much junk then maybe you can generate all 12! Permutations and
> take out the ones you don't want.
> 
> Sorry if I got it totally wrong
> bob
> 
> 
> 
> -----Original Message-----
> From: Jordi Altirriba Guti??rrez [mailto:altirriba at hotmail.com] 
> Sent: Tuesday, July 13, 2004 3:07 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Permutations
> 
> 
> Dear R users,
> I'm a beginner user of R and I've a problem with permutations that I don't 
> know how to solve. I've 12 elements in blocks of 3 elements and I want only 
> to make permutations inter-blocks (no intra-blocks) (sorry if the 
> terminology is not accurate), something similar to:
> 
> 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation
> 
> 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
>    -  -
> 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
> -  -  -
> 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
>       -    -
> 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
> -  -  -   -  -  -
> 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
>            -  -
> ....
> 
>   Thanks for your time,
> 
> Jordi Altirriba
> Ph D student
> 
> Hospital Clinic - Barcelona - Spain
> 
> 
> MSN Motor. http://motor.msn.es/researchcentre/



From MSchwartz at MedAnalytics.com  Wed Jul 14 00:04:50 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 13 Jul 2004 17:04:50 -0500
Subject: [R] Permutations
In-Reply-To: <200407132002.i6DK2PPK018059@erdos.math.unb.ca>
References: <200407132002.i6DK2PPK018059@erdos.math.unb.ca>
Message-ID: <1089756289.3830.291.camel@localhost.localdomain>

On Tue, 2004-07-13 at 15:02, Rolf Turner wrote:
> Marc Schwartz wrote (in response to a question from Jordi Altirriba):

snip

> This does not solve the problem that was posed.  It only permutes the
> blocks, and does not allow for swapping between blocks.  For instance
> it does produce the ``acceptable'' permutation
> 
> 	1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
> 
> I would guess that a correct solution is likely to be pretty
> difficult.  I mean, one ***could*** just generate all 12!
> permutations of 1 to 12 and filter out the unacceptable ones.  But
> this is getting unwieldy (12! is close to half a billion) and is
> inelegant.  And the method does not ``generalize'' worth a damn.

Rolf,

You are correct. I missed that (not so subtle) change in the line above.
I mis-read the "inter-blocks (no intra-blocks)" requirement as simply
permuting the blocks, rather than allowing for the swapping of values
between blocks. Time for new bi-focals...

As Robert has also pointed out in his reply, this gets quite unwieldy.

One of the follow up questions might be, is it only allowable that one
value at a time can be swapped between blocks or can multiple values be
swapped between blocks simultaneously? 

I am not sure that it makes a substantive impact on the problem or its
solution, however. The question is what is to be done with the resultant
set of permutations?

FWIW, on a 3.2 Ghz P4 with 2Gb of RAM:

> system.time(perms <- permutations(12, 12, 1:12))

Error: cannot allocate vector of size 1403325 Kb
Timing stopped at: 2274.27 54.58 2787.76 0 0


Marc



From jfox at mcmaster.ca  Wed Jul 14 00:13:23 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 13 Jul 2004 18:13:23 -0400
Subject: [R] Help with factanal and missing values
In-Reply-To: <Pine.LNX.4.44.0407131937500.1865-100000@ws7.dogbert.ntt.it>
Message-ID: <20040713221326.GDHS26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Antonio,

This example is (as stated) a second-order CFI, where each of the primary
factors, F1, F2, and F3 depends upon the second-order factor F4. To have no
second-order structure, simply define variances and (assuming that you're
specifying correlated factors) covariances among the factors. For the
Thurstone example, these would be, in addition to the variances already set
to 1, F1 <-> F2, F1 <-> F3, and F2 <-> F3.

I hope that this helps,
 John 

> -----Original Message-----
> From: Antonio Prioglio [mailto:a.prioglio at city.ac.uk] 
> Sent: Tuesday, July 13, 2004 1:53 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Help with factanal and missing values
> 
> On Tue, 13 Jul 2004, John Fox wrote:
> > > Could you give an example on how to do CFA with sem?
> > 
> > Among the examples in ?sem is a second-order CFA.
> 
> Ok, sorry I forgot about the Thurstone example as I was 
> focusing on Path Analysis example when reading the sem doc.
> 
> I understand this is a model taken from another source.
> 
> In the model specification I notice a F4->F1, F4->F2, F4->F3.
> 
> This is something I do not understand.
> 
> In a "normal" case where one is iterested in the factorial 
> validity of the indicator variables, would it be appropiate 
> to use the same specification just omitting the above links?
> 
> Saluti,
> Antonio Prioglio
> 
> --
> We are what we repeatedly do. Excellence, then, is not an 
> act, but a habit.
> 							Aristoteles
> 
> 
>     /"\
>     \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
>      X                           - AGAINST MS ATTACHMENTS
>     / \
> 
> http://www.gnu.org/philosophy/no-word-attachments.html
> 
>



From rolf at math.unb.ca  Wed Jul 14 00:16:42 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 13 Jul 2004 19:16:42 -0300 (ADT)
Subject: [R] Permutations
Message-ID: <200407132216.i6DMGgpA022388@erdos.math.unb.ca>


Dang!!! Forget it.  My random restricted permutation generator
doesn't ``quite'' work.  Further testing --- which I should've done
before posting (sigh) --- reveals that it can get into a situation in
which there's nothing left to sample from, and it still needs to fill
out the permutation.  I.e. it has painted itself into a corner.

Perhaps one could put in a test for this situation and just start
again if it happens, but this makes me uneasy.  What happens to the
``equal probability'' of all the generated permutations?

Mebbe somebody else can come up with something cleverer.  Sorry if I
got your hopes up.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From jfox at mcmaster.ca  Wed Jul 14 00:20:25 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 13 Jul 2004 18:20:25 -0400
Subject: [R] Help with factanal and missing values
In-Reply-To: <Pine.LNX.4.44.0407132114290.1865-100000@ws7.dogbert.ntt.it>
Message-ID: <20040713222026.GFHB26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Antonio,

I'm afraid that you're asking the wrong person about this, because the
literature on goodness of fit measures in SEMs strikes me as mostly alchemy.

As I recall, there are several chapters discussing fit measures in Bollen
and Long, eds., Testing Structural Equation Models. Perhaps these would be
of help.

Regards,
 John 

> -----Original Message-----
> From: Antonio Prioglio [mailto:a.prioglio at city.ac.uk] 
> Sent: Tuesday, July 13, 2004 3:22 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Help with factanal and missing values
> 
> On Tue, 13 Jul 2004, John Fox wrote:
> 
> > 
> > Among the examples in ?sem is a second-order CFA.
> > 
> Thanks now I have it running, hopefully in a correct way.
> 
> By the way I notice in the output a GFI index that in your 
> online appendix to your 2002 book describe as an ad hoc measure.
> 
> Could you comment on how it compares with the Comparative Fit 
> Index (CFI; Bentler, 1990) which according to Byrne 1994 is a 
> revised version of the Bentler-Bonnet (1980) Normed Fit Index?
> 
> Thanks again for your valuable help.



From altirriba at hotmail.com  Wed Jul 14 00:41:35 2004
From: altirriba at hotmail.com (=?iso-8859-1?B?Sm9yZGkgQWx0aXJyaWJhIEd1dGnpcnJleg==?=)
Date: Wed, 14 Jul 2004 00:41:35 +0200
Subject: [R] (no subject)
Message-ID: <BAY15-F30qkqoCGr2BG00013f5c@hotmail.com>

  Dear R users,
  First of all, thanks for the incredibly fast answers and help of Rolf, 
Marc and Robert.
  Yes, I noticed that it was a lot of permutacions, but my intention was to 
make this process automatic and take only 5.000 - 10.000 permutations. 
Therefore, I wanted only to take that "interesting permutations" with "some 
information" [inter-block permutations].
  The reason why I'm interested in these permutations is because I'm using 
some packages of Bioconductor to analyse my data from some microarrays and I 
thought that perhaps could be interesting to see what happens when I permute 
my data and I compare it against the not permuted data.
  Thanks again for your time and suggestions.

Jordi Altirriba
Ph. D. Student

Hospital Clinic-Barcelona-Spain



From rolf at math.unb.ca  Wed Jul 14 00:37:05 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 13 Jul 2004 19:37:05 -0300 (ADT)
Subject: For what it's worth (was Re: [R] Permutations).
Message-ID: <200407132237.i6DMb5Rx022960@erdos.math.unb.ca>


For what it's worth, here is a mild revision of my restr.perm()
function, which seems NOT to fall over.  I.e. it appears to
``reliably'' generate restricted permutations.

Whether these are genuinely ***random*** restricted permutations
(i.e. does each restricted permutation of 1:12 have the same
probability of being generated?) is not clear to me.  So ***DON'T
TRUST IT***!!!

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
restr.perm <- function ()
{
S <- 4:12
G <- NULL
A <- list(1:3,4:6,7:9,10:12)
for(k in 1:4) {
	for(i in A[[k]]) {
		tmp <- union(i,S)
		tmp <- setdiff(tmp,G)
		if(length(tmp)==0) return(Recall())
		x <- if(length(tmp)==1) tmp else sample(tmp,1)
		G <- c(G,x)
		S <- setdiff(S,G)
	}
	S <- union(S,A[[k]])
	R <- if(k < 4) A[[k+1]] else NULL
	R <- union(R,G)
	S <- setdiff(S,R)
}
G
}
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From assaf at u.washington.edu  Wed Jul 14 00:45:44 2004
From: assaf at u.washington.edu (Eliyahu-Oron)
Date: Tue, 13 Jul 2004 15:45:44 -0700
Subject: [R] Smooth monotone estimation on R
In-Reply-To: <40F31F6A.9080906@acelerate.com>
Message-ID: <LFEMIJPCNKKCFAIAPAGLMEMLCFAA.assaf@u.washington.edu>

Kjetil and Andy,

Thanks for your helpful answers! The first two (mgcv and fda) seem to be in
the direction I'm looking for. I downloaded them both.

I'm running into a lot of implementation difficulties, though. I wonder if
there's anyone who tried to do a monotone spline using either the 'mgcv' or
the 'fda' packages, whom I could ask directly?

Thanks again, Assaf

-----Original Message-----
From: Kjetil Halvorsen [mailto:kjetil at acelerate.com]
Sent: Monday, July 12, 2004 4:32 PM
To: Assaf P Oron
Cc: R-help at stat.math.ethz.ch
Subject: Re: [R] Smooth monotone estimation on R


help.search()
on my machine turns up only:

mono.con(mgcv)          Monotonicity constraints for a cubic
                        regression spline.

smooth.monotone(fda)    Monotone Smoothing of Data
pmreg(ftnonpar)         Piecewise monotone regression with taut
                        strings
backSpline(splines)     Monotone Inverse Spline
isoreg(stats)           Isotonic / Monotone Regression

so you should find something of use in packages mgvc, fda, ftnonpar, splines
or stats (.loaded by default)

Kjetil Halvorsen


Assaf P Oron wrote:

>Hi all,
>
>I'm looking for smooth monotone estimation packages, preferably using
splines.
>
>I downloaded the 'cobs' package and intend to use it, but since it offers
only quadratic splines based on L1 minimization, I'd like to compare its
performance to that of a more 'mainstream' cubic-spline, L2-norm minimizing
spline. Preferably a smoothing spline.
>
>Does anyone know of such code existing anywhere? Or another smooth monotone
alternative?
>
>Thanks in advance,
>
>Assaf Oron
>Statistics Department
>University of Washington
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>
>
>



From a.prioglio at city.ac.uk  Wed Jul 14 00:54:03 2004
From: a.prioglio at city.ac.uk (Antonio Prioglio)
Date: Tue, 13 Jul 2004 23:54:03 +0100 (BST)
Subject: [R] Help with factanal and missing values
In-Reply-To: <20040713221326.GDHS26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.44.0407132329130.1865-100000@ws7.dogbert.ntt.it>

On Tue, 13 Jul 2004, John Fox wrote:

> Dear Antonio,
> 
> This example is (as stated) a second-order CFI, where each of the primary
> factors, F1, F2, and F3 depends upon the second-order factor F4. To have no
> second-order structure, simply define variances and (assuming that you're
> specifying correlated factors) covariances among the factors. For the
> Thurstone example, these would be, in addition to the variances already set
> to 1, F1 <-> F2, F1 <-> F3, and F2 <-> F3.

Ok I understand the second order part in relation to F4.

I'm afraid I'm a bit slow on the last part.

"Fn <-> Fn 	NA	1" is the variance for the factor n.
"Fn -> Item.a   lam.z	NA" is the grouping of the items to each factor
"Fn <-> Fm      gam.w	NA" I take is the covariance among factors.

Is this correct? Do I need to set variances for each item (Item.a <-> 
Item.a)? 

Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From marzban at caps.ou.edu  Wed Jul 14 00:56:47 2004
From: marzban at caps.ou.edu (marzban)
Date: Tue, 13 Jul 2004 15:56:47 -0700 (PDT)
Subject: [R] lda() - again.
Message-ID: <Pine.LNX.4.44.0407131547230.18003-100000@x1-6-00-0f-1f-0c-15-4b>


Hi.

I asked a question about lda() and got some answers. However, one 
question remains (which is not independent of the earlier ones):

What output does lda() produce which I can use to compute the
posteriors? I know predict(lda())$posterior will give me precisely the
posteriors, but suppose I'd like to compute them myself, outside
of R. 

So far, I have not been able to use "coefficients of linear 
discrimiants" to do this, for they don't seem to be the alpha and beta
in     log(post) ~ alpha x + beta  (this eqn being a caricature of 
LDA in Ripley).

Caren
-- 
http://www.nhn.ou.edu/~marzban



From jfox at mcmaster.ca  Wed Jul 14 01:06:59 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 13 Jul 2004 19:06:59 -0400
Subject: [R] Help with factanal and missing values
In-Reply-To: <Pine.LNX.4.44.0407132329130.1865-100000@ws7.dogbert.ntt.it>
Message-ID: <20040713230700.XAZM28143.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Antonio, 

> -----Original Message-----
> From: Antonio Prioglio [mailto:a.prioglio at city.ac.uk] 
> Sent: Tuesday, July 13, 2004 5:54 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Help with factanal and missing values
> 
> On Tue, 13 Jul 2004, John Fox wrote:
> 
> > Dear Antonio,
> > 
> > This example is (as stated) a second-order CFI, where each of the 
> > primary factors, F1, F2, and F3 depends upon the 
> second-order factor 
> > F4. To have no second-order structure, simply define variances and 
> > (assuming that you're specifying correlated factors) 
> covariances among 
> > the factors. For the Thurstone example, these would be, in 
> addition to 
> > the variances already set to 1, F1 <-> F2, F1 <-> F3, and F2 <-> F3.
> 
> Ok I understand the second order part in relation to F4.
> 
> I'm afraid I'm a bit slow on the last part.
> 
> "Fn <-> Fn 	NA	1" is the variance for the factor n.

Yes. This is set to 1, standardizing the factors, which is conventional.

> "Fn -> Item.a   lam.z	NA" is the grouping of the items to each factor

These (i.e., the lambdas) are conventionally called factor loadings.

> "Fn <-> Fm      gam.w	NA" I take is the covariance among factors.
> 

Yes, though it is unconventional to use gamma to represent a covariance (a
correlation, since the factors are presumably standardized) in factor
analysis.

> Is this correct? Do I need to set variances for each item 
> (Item.a <-> Item.a)? 
> 

Yes. These *error* variances, which should be free parameters, are
conventionally called uniquenesses in factor analysis.

As a general matter, it would help, I think, to look more carefully at the
example, since it includes factor loadings and uniquenesses. If you haven't
already done so, you might also look at the appendix on structural-equation
models to my R and S-PLUS Companion, which is at
<http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/appendix-sems.pdf>.
This appendix doesn't include a CFA example, but it does explain how to
prepare input to the sem() function.

Regards,
John

> Saluti,
> Antonio Prioglio
> 
> --
> We are what we repeatedly do. Excellence, then, is not an 
> act, but a habit.
> 							Aristoteles
> 
> 
>     /"\
>     \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
>      X                           - AGAINST MS ATTACHMENTS
>     / \
> 
> http://www.gnu.org/philosophy/no-word-attachments.html
> 
>



From solares at unsl.edu.ar  Wed Jul 14 01:33:41 2004
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Tue, 13 Jul 2004 20:33:41 -0300 (ART)
Subject: [R] help with as.function
Message-ID: <47072.170.210.173.216.1089761621.squirrel@inter17.unsl.edu.ar>

HI, sorry but i don't understand how to make a function with as.function()

formula<-"2+3*x"
 formu<-as.symbol(formula)
> formu
2+3*x
 formul<-as.function(alist(x=,formu))
curve(formul,1,5,col="blue")
Error in xy.coords(x, y, xlabel, ylabel, log) :
        x and y lengths differ
> typeof(formul)
[1] "closure"

and not plot the curve function, Why? Thanks Ruben



From Gavin.Kennedy at csiro.au  Wed Jul 14 02:12:45 2004
From: Gavin.Kennedy at csiro.au (Gavin.Kennedy@csiro.au)
Date: Wed, 14 Jul 2004 10:12:45 +1000
Subject: [R] RCMD fails in Windows XP
Message-ID: <88DB795AFFC61D44A9AD0AA87191809301DD3C22@exact5-cbr.act.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040714/a61b596e/attachment.pl

From sundar.dorai-raj at PDF.COM  Wed Jul 14 02:28:40 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 13 Jul 2004 17:28:40 -0700
Subject: [R] help with as.function
In-Reply-To: <47072.170.210.173.216.1089761621.squirrel@inter17.unsl.edu.ar>
References: <47072.170.210.173.216.1089761621.squirrel@inter17.unsl.edu.ar>
Message-ID: <40F47E38.8020100@pdf.com>



solares at unsl.edu.ar wrote:

> HI, sorry but i don't understand how to make a function with as.function()
> 
> formula<-"2+3*x"
>  formu<-as.symbol(formula)
> 
>>formu
> 
> 2+3*x
>  formul<-as.function(alist(x=,formu))
> curve(formul,1,5,col="blue")
> Error in xy.coords(x, y, xlabel, ylabel, log) :
>         x and y lengths differ
> 
>>typeof(formul)
> 
> [1] "closure"
> 
> and not plot the curve function, Why? Thanks Ruben
> 

Hi Ruben,
How about this?

ftext <- "2 + 3 * x"
f <- as.function(alist(x=, eval(parse(text = ftext))))

or as a one-liner:

f <- as.function(alist(x=, eval(parse(text = "2 + 3 * x"))))

--sundar



From kjetil at acelerate.com  Wed Jul 14 03:07:10 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Tue, 13 Jul 2004 21:07:10 -0400
Subject: [R] Smooth monotone estimation on R
References: <LFEMIJPCNKKCFAIAPAGLMEMLCFAA.assaf@u.washington.edu>
Message-ID: <40F4873E.2040207@acelerate.com>

Hola!

Experimenting a little, package fda seems very much under development, 
and help pages are definitely not finished.
It would certainly help to read the book "functional data analysis" by 
the author of fda, which is in our library.
On the other hand package mgcv is more mature, so it would seem easier 
to use that.

It is not totally automatic, but the example
library(mgcv)
example(mono.con)

has everything necessary to get started.

Kjetil Halvorsen

Eliyahu-Oron wrote:

>Kjetil and Andy,
>
>Thanks for your helpful answers! The first two (mgcv and fda) seem to be in
>the direction I'm looking for. I downloaded them both.
>
>I'm running into a lot of implementation difficulties, though. I wonder if
>there's anyone who tried to do a monotone spline using either the 'mgcv' or
>the 'fda' packages, whom I could ask directly?
>
>Thanks again, Assaf
>
>-----Original Message-----
>From: Kjetil Halvorsen [mailto:kjetil at acelerate.com]
>Sent: Monday, July 12, 2004 4:32 PM
>To: Assaf P Oron
>Cc: R-help at stat.math.ethz.ch
>Subject: Re: [R] Smooth monotone estimation on R
>
>
>help.search()
>on my machine turns up only:
>
>mono.con(mgcv)          Monotonicity constraints for a cubic
>                        regression spline.
>
>smooth.monotone(fda)    Monotone Smoothing of Data
>pmreg(ftnonpar)         Piecewise monotone regression with taut
>                        strings
>backSpline(splines)     Monotone Inverse Spline
>isoreg(stats)           Isotonic / Monotone Regression
>
>so you should find something of use in packages mgvc, fda, ftnonpar, splines
>or stats (.loaded by default)
>
>Kjetil Halvorsen
>
>
>Assaf P Oron wrote:
>
>  
>
>>Hi all,
>>
>>I'm looking for smooth monotone estimation packages, preferably using
>>    
>>
>splines.
>  
>
>>I downloaded the 'cobs' package and intend to use it, but since it offers
>>    
>>
>only quadratic splines based on L1 minimization, I'd like to compare its
>performance to that of a more 'mainstream' cubic-spline, L2-norm minimizing
>spline. Preferably a smoothing spline.
>  
>
>>Does anyone know of such code existing anywhere? Or another smooth monotone
>>    
>>
>alternative?
>  
>
>>Thanks in advance,
>>
>>Assaf Oron
>>Statistics Department
>>University of Washington
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>    
>>
>http://www.R-project.org/posting-guide.html
>  
>
>>
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From dmurdoch at pair.com  Wed Jul 14 03:08:20 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 13 Jul 2004 21:08:20 -0400
Subject: [R] RCMD fails in Windows XP
In-Reply-To: <88DB795AFFC61D44A9AD0AA87191809301DD3C22@exact5-cbr.act.csiro.au>
References: <88DB795AFFC61D44A9AD0AA87191809301DD3C22@exact5-cbr.act.csiro.au>
Message-ID: <c509f0ltb1a2l2o6udsav2oin3grvt21h9@4ax.com>

On Wed, 14 Jul 2004 10:12:45 +1000, <Gavin.Kennedy at csiro.au> wrote:

>I have setup R 1.9.1 on my Dell laptop running windows XP. I have
>installed it to C:\R\rw1091. Rgui runs fine, but Rcmd fails if run with
>parameters (i.e. install). The windows dialog box cheerfully says "R for
>Windows front-end has encountered a problem and needs to close.  We are
>sorry for the inconvenience." Running the visual C++ debugger informs me
>that there is an unhandled exception in rcmd.exe. I have seen similar
>problems in R-help and have tried to follow the advice given, but the
>earlier problems occurred for Rgui.exe and were overcome by setting the
>HOMEPATH variable. I have tried this and set every variable possible to
>ensure no blank spaces appear in any of the paths. But still I get this
>error. Any further suggestions would be appreciated.

You don't mention your setup.  Have you followed the instructions in
readme.packages?  Rcmd INSTALL sets up environment variables, then
runs Perl.  I think it's pretty much equivalent to doing the sequence
below in a command shell.  Can you try those commands, and see if you
get an error?

set R_HOME=C:/R/rw1091
set R_VERSION=1.9.1
set R_CMD=R CMD
set R_OSTYPE=windows
set PATH=C:\R\rw1091\bin;your old path
set TMPDIR=c:/TEMP  (unless you already had TMPDIR set)
set PERL5LIB=C:\R\rw1091\share\perl;<old PERL5LIB value, if you had
one>
set TEXINPUTS=C:\R\rw1091\share\texmf;<old TEXINPUTS, if you had one>

perl C:\R\rw1091/bin/INSTALL  <other command line args>


I think I got all the \ and / right, but I'm not certain.

Duncan Murdoch



From ramasamy at cancer.org.uk  Wed Jul 14 03:17:06 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 14 Jul 2004 02:17:06 +0100
Subject: permutations (was Re: [R] (no subject))
In-Reply-To: <BAY15-F30qkqoCGr2BG00013f5c@hotmail.com>
References: <BAY15-F30qkqoCGr2BG00013f5c@hotmail.com>
Message-ID: <1089767826.4110.34.camel@localhost.localdomain>

I think I may know what you want. Try this :

# code
strata.restricted.sample <- function( grp ){
  K       <- length(unique(grp))     # number of levels  
  new.grp <- sample(grp)

  xtab    <- table(grp, new.grp)
  propA   <- apply(xtab, 1, function(x) max(x) / sum(x))
  no.A    <- sum( propA == 1 )

  if(no.A == K){ Recall(grp=grp) }
  return(new.grp)
}

# description
You cross-tabulate original and permuted groups (line4) to calculate the
proportion of agreement (line5) and find out how many groups have
perfect agreement (line6). If ALL groups have perfect agreement, you
discard and re-sample (line8). Look at matchClasses in e1071 package for
perhaps a more elegant method. 

# usage
> g1 <- rep(1:4, each=3); n  <- length(g1)
> g2 <- strata.restricted.sample(g1)
> g2  # new groupings
 [1] 1 1 2 3 4 2 4 1 4 3 2 3
 
To show the indice (with some random tie breaking), do this :
> c(1:n) [ order( g2 + 10e-6 * rnorm(n) ) ]
 [1]  8  1  2  3  6 11 12 10  4  7  5  9

# detail
Just in case anyone is wondering why this might be of use, consider the
following two lines which gives the same goodness of fit test measures.
  g <- rep(1:4, each=3); lm( x ~ g, each=3) ) 
  g <- rep(4:1, each=3); lm( x ~ g, each=3) )

PS : Please do not change the subject unless you have a good reason !



On Tue, 2004-07-13 at 23:41, Jordi Altirriba Gutirrez wrote:
>   Dear R users,
>   First of all, thanks for the incredibly fast answers and help of Rolf, 
> Marc and Robert.
>   Yes, I noticed that it was a lot of permutacions, but my intention was to 
> make this process automatic and take only 5.000 - 10.000 permutations. 
> Therefore, I wanted only to take that "interesting permutations" with "some 
> information" [inter-block permutations].
>   The reason why I'm interested in these permutations is because I'm using 
> some packages of Bioconductor to analyse my data from some microarrays and I 
> thought that perhaps could be interesting to see what happens when I permute 
> my data and I compare it against the not permuted data.
>   Thanks again for your time and suggestions.
> 
> Jordi Altirriba
> Ph. D. Student
> 
> Hospital Clinic-Barcelona-Spain
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Wed Jul 14 03:35:11 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 14 Jul 2004 02:35:11 +0100
Subject: [R] lda() - again.
In-Reply-To: <Pine.LNX.4.44.0407131547230.18003-100000@x1-6-00-0f-1f-0c-15-4b>
References: <Pine.LNX.4.44.0407131547230.18003-100000@x1-6-00-0f-1f-0c-15-4b>
Message-ID: <1089768910.4110.39.camel@localhost.localdomain>

I remember doing this some time ago but forgot. Perhaps this might help
you

 MASS:::predict.lda


On Tue, 2004-07-13 at 23:56, marzban wrote:
> Hi.
> 
> I asked a question about lda() and got some answers. However, one 
> question remains (which is not independent of the earlier ones):
> 
> What output does lda() produce which I can use to compute the
> posteriors? I know predict(lda())$posterior will give me precisely the
> posteriors, but suppose I'd like to compute them myself, outside
> of R. 
> 
> So far, I have not been able to use "coefficients of linear 
> discrimiants" to do this, for they don't seem to be the alpha and beta
> in     log(post) ~ alpha x + beta  (this eqn being a caricature of 
> LDA in Ripley).
> 
> Caren



From lauraholt_983 at hotmail.com  Wed Jul 14 05:13:15 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Tue, 13 Jul 2004 22:13:15 -0500
Subject: [R] subsets in data frame
Message-ID: <BAY12-F8pawS4PtkyVK00009ed9@hotmail.com>

Hello R People:

I have a data frame with 2 numeric variables and 1 factor.

There are 3 levels of the factor.

I would like to get sums/means/etc of the numeric variables with respect to 
the factor level.

I tried "table" and "subset" but have not hit upon a solution.

I thought maybe "apply" would be the answer but can't figure out how to 
break out by factor.

Any suggestions would be most appreciated.

Thanks yet again.
R Version 1.9.1 for windows
Sincerely,
Laura Holt
mailto: lauraholt_983 at hotmail.com


your life. http://lifeevents.msn.com



From spencer.graves at pdf.com  Wed Jul 14 05:28:20 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 13 Jul 2004 20:28:20 -0700
Subject: [R] subsets in data frame
In-Reply-To: <BAY12-F8pawS4PtkyVK00009ed9@hotmail.com>
References: <BAY12-F8pawS4PtkyVK00009ed9@hotmail.com>
Message-ID: <40F4A854.7050809@pdf.com>

?tapply

The examples there seem to describe what you want.  hope this helps.  
spencer graves

Laura Holt wrote:

> Hello R People:
>
> I have a data frame with 2 numeric variables and 1 factor.
>
> There are 3 levels of the factor.
>
> I would like to get sums/means/etc of the numeric variables with 
> respect to the factor level.
>
> I tried "table" and "subset" but have not hit upon a solution.
>
> I thought maybe "apply" would be the answer but can't figure out how 
> to break out by factor.
>
> Any suggestions would be most appreciated.
>
> Thanks yet again.
> R Version 1.9.1 for windows
> Sincerely,
> Laura Holt
> mailto: lauraholt_983 at hotmail.com
>
>
> your life. http://lifeevents.msn.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kathryn.jones at jcu.edu.au  Wed Jul 14 05:52:27 2004
From: kathryn.jones at jcu.edu.au (Kathryn Jones)
Date: Wed, 14 Jul 2004 13:52:27 +1000
Subject: [R] SJava - restart() is defunct
Message-ID: <80e2a1eb.5f93e365.a591500@mirapoint-ms1.jcu.edu.au>

Hi, 
I'm using the SJava package and am trying to get event 
handling to work, but no examples from 
http://www.omegahat.org/RSJava/examples/ that have any event 
handling work in R 1.9.0. I think the examples were all 
written around 2001 so most probably used an older version 
of R. The error message that displays in R is:

Error: 'restart' is defunct.
See ?Defunct.

The restart function (part of the base package I think?) is 
not in the code I am using but I'm guessing it's being used 
somewhere internally? It says in the documentation that 
restart has been replaced by try, is this correct? If so, 
how do I fix this problem considering I'm not actually using 
the restart function in my code? Should I download an older 
version of R? 

Any help would be greatly appreciated
Thanks!
Kathryn J

James Cook Uni, 
Townsville QLD Australia



From kathryn.jones at jcu.edu.au  Wed Jul 14 06:17:08 2004
From: kathryn.jones at jcu.edu.au (Kathryn Jones)
Date: Wed, 14 Jul 2004 14:17:08 +1000
Subject: [R] SJava - restart() is defunct
Message-ID: <d92359aa.5f9625c4.822cd00@mirapoint-ms1.jcu.edu.au>

Hi, 
I'm using the SJava package and am trying to get event 
handling to work, but no examples from 
http://www.omegahat.org/RSJava/examples/ that have any event 
handling work in R 1.9.0. I think the examples were all 
written around 2001 so most probably used an older version 
of R. The error message that displays in R is:

Error: 'restart' is defunct.
See ?Defunct.

The restart function (part of the base package I think?) is 
not in the code I am using but I'm guessing it's being used 
somewhere internally? It says in the documentation that 
restart has been replaced by try, is this correct? If so, 
how do I fix this problem considering I'm not actually using 
the restart function in my code? Should I download an older 
version of R? 

Any help would be greatly appreciated
Thanks!
Kathryn J

James Cook Uni, 
Townsville QLD Australia



From rmusk at postoffice.utas.edu.au  Wed Jul 14 06:43:34 2004
From: rmusk at postoffice.utas.edu.au (Robert Musk)
Date: Wed, 14 Jul 2004 14:43:34 +1000
Subject: [R] solving for a transition point in a piecewise nonlinear model
Message-ID: <5.2.0.9.0.20040714143225.00a92210@postoffice.utas.edu.au>

I want to fit a piecewise nonlinear model in which the transition point is 
an estimated parameter.

Something like:

F(x)=F1(x) when x>alpha,
F(x)=F2(x) when x<=alpha.

How can I solve for alpha within the nls call?

Thanks,
Rob



From ggrothendieck at myway.com  Wed Jul 14 07:25:45 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 14 Jul 2004 05:25:45 +0000 (UTC)
Subject: [R] help with as.function
References: <47072.170.210.173.216.1089761621.squirrel@inter17.unsl.edu.ar>
Message-ID: <loom.20040714T065346-614@post.gmane.org>

 <solares <at> unsl.edu.ar> writes:

> 
> HI, sorry but i don't understand how to make a function with as.function()
> 
> formula<-"2+3*x"
>  formu<-as.symbol(formula)
> > formu
> 2+3*x
>  formul<-as.function(alist(x=,formu))
> curve(formul,1,5,col="blue")
> Error in xy.coords(x, y, xlabel, ylabel, log) :
>         x and y lengths differ
> > typeof(formul)
> [1] "closure"
> 
> and not plot the curve function, Why? Thanks Ruben

Here are two ways to create a function out of strings although
neither uses as.function:

f <- function(x){}
body(f) <- parse(text="2+3*x")

f <- eval(parse(text=paste("function(x)","2+3*x")))



From vito.muggeo at giustizia.it  Wed Jul 14 08:17:55 2004
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Wed, 14 Jul 2004 08:17:55 +0200
Subject: R: [R] solving for a transition point in a piecewise nonlinear model
References: <5.2.0.9.0.20040714143225.00a92210@postoffice.utas.edu.au>
Message-ID: <006501c4696a$524acc20$5c13070a@PROCGEN>

Dear Robert,
In general it may be difficult to estimate a model with generic (possibly
nonlinear) functions before/after the changepoint  to be estimated too.

However if you are willing to make some restrinctions on your F1(.) and
F2(.), you could semplify the problem..

For instance, have a look to the strucchange and segmented packages. The
former mainly deals with time series data, the latter with GLM.

hope this helps,
vito

PS Of course you can always perform a grid-search algorithm by fitting
different models for each fixed alpha, and picking the value that maximizes
the Lik..



----- Original Message -----
From: Robert Musk <rmusk at postoffice.utas.edu.au>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, July 14, 2004 6:43 AM
Subject: [R] solving for a transition point in a piecewise nonlinear model


> I want to fit a piecewise nonlinear model in which the transition point is
> an estimated parameter.
>
> Something like:
>
> F(x)=F1(x) when x>alpha,
> F(x)=F2(x) when x<=alpha.
>
> How can I solve for alpha within the nls call?
>
> Thanks,
> Rob
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Jul 14 08:52:45 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Jul 2004 08:52:45 +0200
Subject: [R] summary() doesn't work with Date class objects
In-Reply-To: <200407131657.i6DGvsv18895@snow.pnl.gov>
References: <200407131657.i6DGvsv18895@snow.pnl.gov>
Message-ID: <40F4D83D.5020104@statistik.uni-dortmund.de>

Scott Waichler wrote:

> The handy function summary() doesn't work correctly with Date class
> objects:
> 
> 
>>R.version.string
> 
> [1] "R version 1.9.1, 2004-06-21"
> 
>>b <- as.Date(c("2002-12-26", "2002-12-27", "2002-12-28", "2002-12-29", "2002-12-30"))
>>b
> 
> [1] "2002-12-26" "2002-12-27" "2002-12-28" "2002-12-29" "2002-12-30"
> 
>>summary(b)
> 
>         Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
> "2002-12-29" "2002-12-29" "2002-12-29" "2002-12-29" "2002-12-29" "2002-12-29"

The obvious fix is to change summary.date (in 
.../src/library/base/R/dates.R) as follows:

old:

summary.Date <- function(object, ...)
{
     x <- summary.default(unclass(object), ...)[1:6]# not NA's
     class(x) <- oldClass(object)
     x
}

new:

summary.Date <- function(object, ...)
{
     x <- unclass(object)
     x <- summary.default(x, digits = floor(log(x)) + 1, ...)[1:6]# not NA's
     class(x) <- oldClass(object)
     x
}



One might want to change "floor(log(x)) + 1" to something less 
computational in intensive like "10". ;-)

Uwe Ligges

BTW: Should I submit a bug report or does anybody fix the sources at once?


> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA   99352    USA
> scott.waichler at pnl.gov
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From erich.neuwirth at univie.ac.at  Wed Jul 14 08:56:30 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 14 Jul 2004 08:56:30 +0200
Subject: [R] RGui Titlebar
Message-ID: <40F4D91E.9030405@univie.ac.at>

In the windows version (RGui), is there a way to set
the text displayed in the titlebar of the R window?

When I have 2 instances of RGui running, it would be helpul
if the titlebar could help to understand which is which.


-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From agustin.perez at umh.es  Wed Jul 14 08:58:12 2004
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Wed, 14 Jul 2004 08:58:12 +0200
Subject: [R] A function likes table
Message-ID: <5AFDDD57E2771B409224CD858CC6DE0D04E2758F@mailer-e051.umh.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040714/b2c7d9cf/attachment.pl

From wang at galton.uchicago.edu  Wed Jul 14 00:44:31 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Tue, 13 Jul 2004 17:44:31 -0500 (CDT)
Subject: [R] Re:
Message-ID: <Pine.LNX.4.58.0407131743480.3145@aitken.uchicago.edu>

use 

unique(data) 

or

table(data)



From etptupaf at bs.ehu.es  Wed Jul 14 09:19:45 2004
From: etptupaf at bs.ehu.es (F. Tusell)
Date: Wed, 14 Jul 2004 09:19:45 +0200
Subject: [R] Permutations
Message-ID: <40F4DE91.7030405@bs.ehu.es>

Jordi:

If I understand you well, the function below may do what you asked for.

It is not clear to me from your posting wether e.g.

   1 2 4   3 5 6   7 8 9    10 11 12

and

   1 4 2   3 5 6   7 8 9    10 11 12

should count as differente permutations, i.e., wether once one pair of 
elements interchange their
blocks, permutations within any block are allowable. I have assumed that 
only one pair of
elements are interchanged (but the function could be modified to account 
for other possibilities).

 > permutations
function(elements,blocks) {
    n <- length(elements)
    el.per.block <- n / blocks
    for (i in 1:n) {                    # For each element in turn,
      b <- floor(i/(el.per.block+.1))+1 # find which block it belongs to.
      if (b==blocks)                    # If in the last block, we are done.
        break
      allow.pos <- b*el.per.block + 1   # Find first position it could 
migrate to...
      for (j in (allow.pos:n)) {        # and create permutations with 
all allowable
        perm <- elements                # interchanges.
        perm[i] <- elements[j]
        perm[j] <- elements[i]
        print(perm)
      }
    }   
  }

 > permutations(1:4,2)
[1] 3 2 1 4
[1] 4 2 3 1
[1] 1 3 2 4
[1] 1 4 3 2
 > permutations(1:6,2)
[1] 4 2 3 1 5 6
[1] 5 2 3 4 1 6
[1] 6 2 3 4 5 1
[1] 1 4 3 2 5 6
[1] 1 5 3 4 2 6
[1] 1 6 3 4 5 2
[1] 1 2 4 3 5 6
[1] 1 2 5 4 3 6
[1] 1 2 6 4 5 3
 > permutations(1:9,3)
[1] 4 2 3 1 5 6 7 8 9
[1] 5 2 3 4 1 6 7 8 9
[1] 6 2 3 4 5 1 7 8 9
[1] 7 2 3 4 5 6 1 8 9
[1] 8 2 3 4 5 6 7 1 9
[1] 9 2 3 4 5 6 7 8 1
[1] 1 4 3 2 5 6 7 8 9
[1] 1 5 3 4 2 6 7 8 9
[1] 1 6 3 4 5 2 7 8 9
[1] 1 7 3 4 5 6 2 8 9
[1] 1 8 3 4 5 6 7 2 9
[1] 1 9 3 4 5 6 7 8 2
[1] 1 2 4 3 5 6 7 8 9
[1] 1 2 5 4 3 6 7 8 9
[1] 1 2 6 4 5 3 7 8 9
[1] 1 2 7 4 5 6 3 8 9
[1] 1 2 8 4 5 6 7 3 9
[1] 1 2 9 4 5 6 7 8 3
[1] 1 2 3 7 5 6 4 8 9
[1] 1 2 3 8 5 6 7 4 9
[1] 1 2 3 9 5 6 7 8 4
[1] 1 2 3 4 7 6 5 8 9
[1] 1 2 3 4 8 6 7 5 9
[1] 1 2 3 4 9 6 7 8 5
[1] 1 2 3 4 5 7 6 8 9
[1] 1 2 3 4 5 8 7 6 9
[1] 1 2 3 4 5 9 7 8 6

Notice that no error checking of any kind is done: one should check, 
e.g. that el.per.block is
integer.

Best,

ft.

-- 
Fernando TUSELL                                e-mail:
Departamento de Econometr??a y Estad??stica           etptupaf at bs.ehu.es 
Facultad de CC.EE. y Empresariales             Tel:   (+34)94.601.3733
Avenida Lendakari Aguirre, 83                  Fax:   (+34)94.601.3754
E-48015 BILBAO  (Spain)                        Secr:  (+34)94.601.3740



From erich.neuwirth at univie.ac.at  Wed Jul 14 09:49:00 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 14 Jul 2004 09:49:00 +0200
Subject: [R] Permutations
In-Reply-To: <BAY15-F21OSCBfAbdxk0001f04a@hotmail.com>
References: <BAY15-F21OSCBfAbdxk0001f04a@hotmail.com>
Message-ID: <40F4E56C.3090001@univie.ac.at>

Perhaps what you want might better be described as
ordered partitions?

Is what you want the following:

We study sequences of length 12 and divide them in
4 segments
position 1 2 3, position 4 5 6,
position 7 8 9, position 10 11 12,

Find all permutation sequences of the numbers 1 to 12
with the property that all segment sequences
are monotonically increasing.

I think that produces what you need.
Since the segments are ordered, you avoid intra-block permutations.

If that is what you want, writing a recursive function should not be
too hard.




Jordi Altirriba Gutirrez wrote:

> Dear R users,
> Im a beginner user of R and Ive a problem with permutations that I 
> dont know how to solve. Ive 12 elements in blocks of 3 elements and I 
> want only to make permutations inter-blocks (no intra-blocks) (sorry if 
> the terminology is not accurate), something similar to:
> 
> 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation
> 
> 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
>   -  -
> 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
> -  -  -
> 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
>      -    -
> 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
> -  -  -   -  -  -
> 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
>           -  -
> ....
> 
>  Thanks for your time,
> 
> Jordi Altirriba
> Ph D student
> 
> Hospital Clinic - Barcelona - Spain
> 
> 
> MSN Motor. http://motor.msn.es/researchcentre/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From hb at maths.lth.se  Wed Jul 14 09:55:26 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 14 Jul 2004 09:55:26 +0200
Subject: [R] RGui Titlebar
In-Reply-To: <40F4D91E.9030405@univie.ac.at>
Message-ID: <002901c46977$f0fbe040$dfc6ed82@hblaptop>

It look like this will be possible from R v2.0.0;

>From http://cran.r-project.org/bin/windows/base/CHANGES.rw2000dev

 Added functions setWindowTitle(), getWindowTitle(), and
getIdentification().

To R-devel: Will this be 1) Rgui only? and/or 2) Windows only?

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erich Neuwirth
> Sent: Wednesday, July 14, 2004 8:57 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] RGui Titlebar
> 
> 
> In the windows version (RGui), is there a way to set
> the text displayed in the titlebar of the R window?
> 
> When I have 2 instances of RGui running, it would be helpul
> if the titlebar could help to understand which is which.
> 
> 
> -- 
> Erich Neuwirth, Computer Supported Didactics Working Group 
> Visit our SunSITE at http://sunsite.univie.ac.at
> Phone: +43-1-4277-38624 Fax: +43-1-4277-9386
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From hi_ono2001 at ybb.ne.jp  Wed Jul 14 10:12:24 2004
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Wed, 14 Jul 2004 17:12:24 +0900
Subject: [R] SWIG for R
References: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
Message-ID: <006701c4697a$4b5f4d40$3b8001db@webgis>

Hi.

 Has R dev. team considered employing SWIG(http://www.swig.org/), which
supports PHP, Ruby, Java etc.,
for connecting C/C++ libraries with R?


 Regards.



From rksh at soc.soton.ac.uk  Wed Jul 14 10:11:48 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 14 Jul 2004 09:11:48 +0100
Subject: [R] (no subject) (was: Permutations)
In-Reply-To: <BAY15-F30qkqoCGr2BG00013f5c@hotmail.com>
References: <BAY15-F30qkqoCGr2BG00013f5c@hotmail.com>
Message-ID: <a06002000bd1a99606b1d@[139.166.242.29]>

Jordi

try this


R> x <- c(1,2,3,  10,11,12,  41,42,43,  81,82,83)
R> dim(x) <- c(3,4)
R> x
      [,1] [,2] [,3] [,4]
[1,]    1   10   41   81
[2,]    2   11   42   82
[3,]    3   12   43   83
R>  jj <- t(apply(x,1,sample))
R> jj
      [,1] [,2] [,3] [,4]
[1,]    1   41   10   81
[2,]    2   11   82   42
[3,]   12    3   43   83
R> as.vector(jj)
R>
    [1]  1 2 12 41 11 3 10 82 43 81 42 83




and I think that does what you want...

We take the vector, rearrange it into a matrix with three rows, then 
sample *within* the rows,
then rearrange into a vector again.

There will be one forbidden permutation, namely the identity (which 
may or may not be
desirable).

This method doesn't allow "intra block" permutations.

best

rksh



>  Dear R users,
>  First of all, thanks for the incredibly fast answers and help of 
>Rolf, Marc and Robert.
>  Yes, I noticed that it was a lot of permutacions, but my intention 
>was to make this process automatic and take only 5.000 - 10.000 
>permutations. Therefore, I wanted only to take that "interesting 
>permutations" with "some information" [inter-block permutations].
>  The reason why I'm interested in these permutations is because I'm 
>using some packages of Bioconductor to analyse my data from some 
>microarrays and I thought that perhaps could be interesting to see 
>what happens when I permute my data and I compare it against the not 
>permuted data.
>  Thanks again for your time and suggestions.
>
>Jordi Altirriba
>Ph. D. Student
>
>Hospital Clinic-Barcelona-Spain
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From rado.bonk at jrc.it  Wed Jul 14 10:38:49 2004
From: rado.bonk at jrc.it (Rado Bonk)
Date: Wed, 14 Jul 2004 10:38:49 +0200
Subject: [R] ROracle - fetch gives empty dataframe
Message-ID: <40F4F119.9040008@jrc.it>

Dear R-users,

I was able to make ROracle package to connect to the DB (Oracle91, 
64bit, on Solaris). But after executing siple SQL query, "fetch" 
commaned gives me an empty dataframe.

### RORACLE INSTALATION PROCEDURE ###
R CMD INSTALL --configure-args='--enable-extralibs' --enable-oracle32=no 
~/tmp/ROracle_0.5-5.tar.gz  #since we have 64bit Oracle9i instalation

PROBLEM: after executing simple statement, from within R, "fetch" 
function gives me the empty dataframe:

### CONNECTION, and SQL QUERY EXECUTION
 > ora <- dbDriver("Oracle")
 > con <- dbConnect(ora, "rado/only2admin"
 > dbListTables(con)
character(0)
 > rs <- dbSendQuery(con, "desc * from si_r where id=498")
 > d <- fetch(rs, n= -1)
 > dim(d)
[1] 0 3
str(d)
data.frame':   0 obs. of  3 variables:
$ ID : int
$ DAY: chr
$ R  : num

#### seems like connections has been established
 > dbGetInfo(ora)
$drvName
[1] "Oracle (ProC/C++)"

$connectionIds
$connectionIds[[1]]
<OraConnection:(14939,0)>


$fetch_default_rec
[1] 500

$managerId
<OraDriver:(14939)>

$length
[1] 10

$num_con
[1] 1

$counter
[1] 1

$clientVersion
[1] "0.5-4"

Maybe it is something stupid (and I need just a hint), or may be it is 
something major.

Thanks in advance,

Rado Bonk


-- 
Dr. Radoslav Bonk
European Commission - DG Joint Research Centre (JRC)
Institute for Environment and Sustainability (IES)
LM Unit - Natural Hazards
Weather Driven Natural Hazards Action
Via E. Fermi, TP 261, 21020 Ispra (Va), Italy
Tel.: 0039-0332-786013
Fax: 0039-0332-786653
Webpage: http://natural-hazards.jrc.it/floods/



From meinhardploner at gmx.net  Wed Jul 14 10:53:24 2004
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Wed, 14 Jul 2004 10:53:24 +0200
Subject: [R] list of S3-methods
Message-ID: <43E08DA0-D573-11D8-BB8F-0003930EA956@gmx.net>

how can I get a list of all S3-methods (of a package)
such that I know which functions to include in the S3method()
in the NAMESPACE-file?
Maybe separated by generic=T/F.

thx
Meinhard Ploner
Vienna



From ligges at statistik.uni-dortmund.de  Wed Jul 14 11:01:50 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Jul 2004 11:01:50 +0200
Subject: [R] RGui Titlebar
In-Reply-To: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
References: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
Message-ID: <40F4F67E.5040105@statistik.uni-dortmund.de>

Henrik Bengtsson wrote:

> It look like this will be possible from R v2.0.0;
> 
>>From http://cran.r-project.org/bin/windows/base/CHANGES.rw2000dev
> 
>  Added functions setWindowTitle(), getWindowTitle(), and
> getIdentification().
> 
> To R-devel: Will this be 1) Rgui only? and/or 2) Windows only?

Well, the title of that page already tells us "Windows-specific changes 
to R" ....

Uwe Ligges



> Cheers
> 
> Henrik Bengtsson
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erich Neuwirth
>>Sent: Wednesday, July 14, 2004 8:57 AM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] RGui Titlebar
>>
>>
>>In the windows version (RGui), is there a way to set
>>the text displayed in the titlebar of the R window?
>>
>>When I have 2 instances of RGui running, it would be helpul
>>if the titlebar could help to understand which is which.
>>
>>
>>-- 
>>Erich Neuwirth, Computer Supported Didactics Working Group 
>>Visit our SunSITE at http://sunsite.univie.ac.at
>>Phone: +43-1-4277-38624 Fax: +43-1-4277-9386
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list 
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rado.bonk at jrc.it  Wed Jul 14 11:08:03 2004
From: rado.bonk at jrc.it (Rado Bonk)
Date: Wed, 14 Jul 2004 11:08:03 +0200
Subject: [R] ROracle - fetch gives...(corrected SQL code)
Message-ID: <40F4F7F3.5030006@jrc.it>

Sorry for posting the second time, I corrected the SQL code:

PROBLEM: after executing simple statement, from within R, "fetch" 
function gives me the empty dataframe:

### CONNECTION, and SQL QUERY EXECUTION
 > ora <- dbDriver("Oracle")
 > con <- dbConnect(ora, "rado/only2admin"
 > dbListTables(con)
character(0)
 > rs <- dbSendQuery(con, "select * from si_r where id=498")
                           ^^^^^^ CORRECTION
 > d <- fetch(rs, n= -1)
 > dim(d)
[1] 0 3
str(d)
data.frame':   0 obs. of  3 variables:
$ ID : int
$ DAY: chr
$ R  : num

#### seems like connection has been established
 > dbGetInfo(ora)
$drvName
[1] "Oracle (ProC/C++)"

$connectionIds
$connectionIds[[1]]
<OraConnection:(14939,0)>


$fetch_default_rec
[1] 500

$managerId
<OraDriver:(14939)>

$length
[1] 10

$num_con
[1] 1

$counter
[1] 1

$clientVersion
[1] "0.5-4"

Maybe it is something stupid (and I need just a hint), or may be it is 
something major.

Thanks in advance,

Rado Bonk

-- 
Dr. Radoslav Bonk
European Commission - DG Joint Research Centre (JRC)
Institute for Environment and Sustainability (IES)
LM Unit - Natural Hazards
Weather Driven Natural Hazards Action
Via E. Fermi, TP 261, 21020 Ispra (Va), Italy
Tel.: 0039-0332-786013
Fax: 0039-0332-786653
Webpage: http://natural-hazards.jrc.it/floods/



From ligges at statistik.uni-dortmund.de  Wed Jul 14 11:25:20 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Jul 2004 11:25:20 +0200
Subject: [R] list of S3-methods
In-Reply-To: <43E08DA0-D573-11D8-BB8F-0003930EA956@gmx.net>
References: <43E08DA0-D573-11D8-BB8F-0003930EA956@gmx.net>
Message-ID: <40F4FC00.5020305@statistik.uni-dortmund.de>

Meinhard Ploner wrote:

> how can I get a list of all S3-methods (of a package)
> such that I know which functions to include in the S3method()
> in the NAMESPACE-file?
> Maybe separated by generic=T/F.
> 
> thx
> Meinhard Ploner
> Vienna


Since one you does not register S3 methods (except for the Namespace 
file), you cannot get such a list very easily.
You might want to look for function names with a dot in it and then look 
whether the second part of that name corresponds to a class.

Uwe Ligges



From dmurdoch at pair.com  Wed Jul 14 11:25:39 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 14 Jul 2004 05:25:39 -0400
Subject: [R] RGui Titlebar
In-Reply-To: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
References: <40F4D91E.9030405@univie.ac.at>
	<002901c46977$f0fbe040$dfc6ed82@hblaptop>
Message-ID: <uou9f0dhbb7qgn9eulj4v7l2cn64mm4l2s@4ax.com>

On Wed, 14 Jul 2004 09:55:26 +0200, "Henrik Bengtsson"
<hb at maths.lth.se> wrote:

>It look like this will be possible from R v2.0.0;
>
>>From http://cran.r-project.org/bin/windows/base/CHANGES.rw2000dev
>
> Added functions setWindowTitle(), getWindowTitle(), and
>getIdentification().
>
>To R-devel: Will this be 1) Rgui only? and/or 2) Windows only?

>From the man page:


     This sets the title of the frame in MDI mode, the title of the
     console for 'RGui --sdi', and the title of the window from which
     it was launched for 'Rterm'. It has no effect in embedded uses of
     R.

Duncan Murdoch



From meinhardploner at gmx.net  Wed Jul 14 11:32:20 2004
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Wed, 14 Jul 2004 11:32:20 +0200
Subject: [R] list of S3-methods
In-Reply-To: <40F4FC00.5020305@statistik.uni-dortmund.de>
References: <43E08DA0-D573-11D8-BB8F-0003930EA956@gmx.net>
	<40F4FC00.5020305@statistik.uni-dortmund.de>
Message-ID: <B4555685-D578-11D8-BB8F-0003930EA956@gmx.net>

> Meinhard Ploner wrote:
>
>> how can I get a list of all S3-methods (of a package)
>> such that I know which functions to include in the S3method()
>> in the NAMESPACE-file?
>> Maybe separated by generic=T/F.
>> thx
>> Meinhard Ploner
>> Vienna
>
>
> Since one you does not register S3 methods (except for the Namespace 
> file), you cannot get such a list very easily.
> You might want to look for function names with a dot in it and then 
> look whether the second part of that name corresponds to a class.
>
> Uwe Ligges
>
Thank you.
Usually users "register" S3-methods prior to make libraries or
is this possible only for S4 classes?

Meinhard Ploner



From dmurdoch at pair.com  Wed Jul 14 11:37:42 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 14 Jul 2004 05:37:42 -0400
Subject: [R] SWIG for R
In-Reply-To: <006701c4697a$4b5f4d40$3b8001db@webgis>
References: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
	<006701c4697a$4b5f4d40$3b8001db@webgis>
Message-ID: <9ev9f0pi9k100j0j5kahuk3mhqo4iecglg@4ax.com>

On Wed, 14 Jul 2004 17:12:24 +0900, "Hisaji ONO"
<hi_ono2001 at ybb.ne.jp> wrote:

>Hi.
>
> Has R dev. team considered employing SWIG(http://www.swig.org/), which
>supports PHP, Ruby, Java etc.,
>for connecting C/C++ libraries with R?

I don't know, but it looks from their web page as though you're asking
the wrong question, i.e. you should be asking:

Has the SWIG dev. team considered supporting R?

>From my understanding based on a quick read, we wouldn't need to do
anything at all. SWIG would generate R interface code.

What I couldn't find on the page is a discussion of how hard it is to
add support for another language to SWIG.  I don't know if this is
something a SWIG user could do, or whether it requires a major effort.

Duncan Murdoch



From joehl at gmx.de  Wed Jul 14 12:24:21 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Wed, 14 Jul 2004 12:24:21 +0200 (MEST)
Subject: [R] RGui Titlebar
Message-ID: <10401.1089800661@www22.gmx.net>


An ugly workaround for versions prior 2.0 would be creating a copy of
Rgui.exe and change its icon (google for 'change icon'). Under xp I also can
just deactivate the icon on the compatibility tab (disable visual themes).

Best


Jens Oehlschl??gel



From ligges at statistik.uni-dortmund.de  Wed Jul 14 12:47:41 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Jul 2004 12:47:41 +0200
Subject: [R] list of S3-methods
In-Reply-To: <B4555685-D578-11D8-BB8F-0003930EA956@gmx.net>
References: <43E08DA0-D573-11D8-BB8F-0003930EA956@gmx.net>
	<40F4FC00.5020305@statistik.uni-dortmund.de>
	<B4555685-D578-11D8-BB8F-0003930EA956@gmx.net>
Message-ID: <40F50F4D.9030506@statistik.uni-dortmund.de>

Meinhard Ploner wrote:

>> Meinhard Ploner wrote:
>>
>>> how can I get a list of all S3-methods (of a package)
>>> such that I know which functions to include in the S3method()
>>> in the NAMESPACE-file?
>>> Maybe separated by generic=T/F.
>>> thx
>>> Meinhard Ploner
>>> Vienna
>>
>>
>>
>> Since one you does not register S3 methods (except for the Namespace 
>> file), you cannot get such a list very easily.
>> You might want to look for function names with a dot in it and then 
>> look whether the second part of that name corresponds to a class.
>>
>> Uwe Ligges
>>
> Thank you.
> Usually users "register" S3-methods prior to make libraries or
> is this possible only for S4 classes?
> 
> Meinhard Ploner
> 

Yes. S3 method dispatchj is solely based on the naming conventions.

Uwe



From maechler at stat.math.ethz.ch  Wed Jul 14 14:02:53 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Jul 2004 14:02:53 +0200
Subject: [R] list of S3-methods
In-Reply-To: <40F4FC00.5020305@statistik.uni-dortmund.de>
References: <43E08DA0-D573-11D8-BB8F-0003930EA956@gmx.net>
	<40F4FC00.5020305@statistik.uni-dortmund.de>
Message-ID: <16629.8429.374113.623396@gargle.gargle.HOWL>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>     on Wed, 14 Jul 2004 11:25:20 +0200 writes:

    UweL> Meinhard Ploner wrote:
    >> how can I get a list of all S3-methods (of a package)
    >> such that I know which functions to include in the
    >> S3method() in the NAMESPACE-file?  Maybe separated by
    >> generic=T/F.
    >> 
    >> thx Meinhard Ploner Vienna


    UweL> Since one you does not register S3 methods (except for
    UweL> the Namespace file), you cannot get such a list very
    UweL> easily.  You might want to look for function names
    UweL> with a dot in it and then look whether the second part
    UweL> of that name corresponds to a class.

yes;  and for this you can re-use some of the code the current
methods() function has. It *is* doing a very related thing:

Looking for all S3 methods belonging to a given class or to a
given generic.

Martin Maechler



From mseewald at gmx.de  Wed Jul 14 14:11:44 2004
From: mseewald at gmx.de (Michael Seewald)
Date: Wed, 14 Jul 2004 14:11:44 +0200 (CEST)
Subject: [R] ROracle - fetch gives empty dataframe
In-Reply-To: <40F4F119.9040008@jrc.it>
References: <40F4F119.9040008@jrc.it>
Message-ID: <Pine.LNX.4.53.0407141409180.184@lakeforest.homelinux.com>


Dear Rado,

I think you didn't get a proper db connection at all. You forgot to specify
the database to connect to.

On Wed, 14 Jul 2004, Rado Bonk wrote:
> ### CONNECTION, and SQL QUERY EXECUTION
>  > ora <- dbDriver("Oracle")
>  > con <- dbConnect(ora, "rado/only2admin"

Which database???

>  > dbListTables(con)
> character(0)

dbListTables would display something, if you had connected. You should get
this working before you proceed.

Regards,
Michael



From Marlene.Mueller at gmx.de  Wed Jul 14 14:59:01 2004
From: Marlene.Mueller at gmx.de (Marlene Mueller)
Date: Wed, 14 Jul 2004 14:59:01 +0200 (MEST)
Subject: [R] constrOptim and function with additional parameters?
Message-ID: <13650.1089809941@www40.gmx.net>


How can I use a function with some additional input parameters
in constrOptim? For example, something like

fr <- function(x,a) {   ## Rosenbrock Banana function
  x1 <- x[1]
  x2 <- x[2]
  a * (x2 - x1 * x1)^2 + (1 - x1)^2
}

where the optimum is to be found w.r.t. x. Calling
optim(c(-1.2,1), fr, NULL, a=100) works as expected, but I fail 
to provide the a=100 in the constrained case:

>  constrOptim(c(-1.2,0.9), fr, NULL, ui=rbind(c(-1,0),c(0,-1)),
ci=c(-1,-1),a=100)
Error in f(theta) : Argument "a" is missing, with no default

Is this a bug or is there a different solution that I miss here?

TIA, Marlene



From rolf at math.unb.ca  Wed Jul 14 15:06:41 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 14 Jul 2004 10:06:41 -0300 (ADT)
Subject: [R] Permutations
Message-ID: <200407141306.i6ED6feX013295@erdos.math.unb.ca>

In respect of generating random ``restricted'' permutations, it
occurred to me as I was driving home last night .... If one is going
to invoke some kind of ``try again if it doesn't work procedure''
then one might as well keep it simple:  Essentially use the rejection
method.  Just generate a random permutation, and then check whether
it meets the restriction criterion.   If yes, return that
permutation, if not, throw it away and try again.

This will definitely (???) genererate a genuinely random restricted
permutation.  I figured that since a very large fraction of permutations
are acutally restricted permutions one wouldn't reject much of the
time, and so the rejection method should be pretty efficient.

I wrote the following code to do the work:

restr.perm2 <- function () {
#
okay <- function (x) {
	m1 <- cbind(1:12,rep(1:4,rep(3,4)))
	m2 <- m1[x,]
	all((m2[,1] == m1[,1]) | (m2[,2] != m1[,2]))
}
#
repeat{
	x <- sample(12,12)
	if(okay(x)) return(x)
}
}

I'm bothered again, but:  I did a little test to see how many tries
it would take on average.  On 1000 attempts I got a mean of 8.44
tries, with a standard deviation of 7.7610 (standard error of the
mean = 0.2454).  The value of 7.76 is roughly consistent with
sqrt(1-p.hat)/p.hat = 7.92 that one gets from the geometric
distribution.

This would indicate that the fraction of ``restricted'' permutations
is something like p.hat = 1/8.44 = 0.1184834.  Which is a lot less
than the rough estimate of (4.7 x 10^6)/12! approx. = 0.9853 from
Robert Baskin's back-of-the-envelope calculations.

What's going on/wrong?
				cheers,

					Rolf Turner
					rolf at math.unb.ca



From andy_liaw at merck.com  Wed Jul 14 15:16:44 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 14 Jul 2004 09:16:44 -0400
Subject: [R] Smooth monotone estimation on R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF803E@usrymx25.merck.com>

Browsing over the FDA book, I can not find any discussion of monotone
smoothing.

Andy

> From: Kjetil  Halvorsen
> 
> Hola!
> 
> Experimenting a little, package fda seems very much under 
> development, 
> and help pages are definitely not finished.
> It would certainly help to read the book "functional data 
> analysis" by 
> the author of fda, which is in our library.
> On the other hand package mgcv is more mature, so it would 
> seem easier 
> to use that.
> 
> It is not totally automatic, but the example
> library(mgcv)
> example(mono.con)
> 
> has everything necessary to get started.
> 
> Kjetil Halvorsen
> 
> Eliyahu-Oron wrote:
> 
> >Kjetil and Andy,
> >
> >Thanks for your helpful answers! The first two (mgcv and 
> fda) seem to be in
> >the direction I'm looking for. I downloaded them both.
> >
> >I'm running into a lot of implementation difficulties, 
> though. I wonder if
> >there's anyone who tried to do a monotone spline using 
> either the 'mgcv' or
> >the 'fda' packages, whom I could ask directly?
> >
> >Thanks again, Assaf
> >
> >-----Original Message-----
> >From: Kjetil Halvorsen [mailto:kjetil at acelerate.com]
> >Sent: Monday, July 12, 2004 4:32 PM
> >To: Assaf P Oron
> >Cc: R-help at stat.math.ethz.ch
> >Subject: Re: [R] Smooth monotone estimation on R
> >
> >
> >help.search()
> >on my machine turns up only:
> >
> >mono.con(mgcv)          Monotonicity constraints for a cubic
> >                        regression spline.
> >
> >smooth.monotone(fda)    Monotone Smoothing of Data
> >pmreg(ftnonpar)         Piecewise monotone regression with taut
> >                        strings
> >backSpline(splines)     Monotone Inverse Spline
> >isoreg(stats)           Isotonic / Monotone Regression
> >
> >so you should find something of use in packages mgvc, fda, 
> ftnonpar, splines
> >or stats (.loaded by default)
> >
> >Kjetil Halvorsen
> >
> >
> >Assaf P Oron wrote:
> >
> >  
> >
> >>Hi all,
> >>
> >>I'm looking for smooth monotone estimation packages, 
> preferably using
> >>    
> >>
> >splines.
> >  
> >
> >>I downloaded the 'cobs' package and intend to use it, but 
> since it offers
> >>    
> >>
> >only quadratic splines based on L1 minimization, I'd like to 
> compare its
> >performance to that of a more 'mainstream' cubic-spline, 
> L2-norm minimizing
> >spline. Preferably a smoothing spline.
> >  
> >
> >>Does anyone know of such code existing anywhere? Or another 
> smooth monotone
> >>    
> >>
> >alternative?
> >  
> >
> >>Thanks in advance,
> >>
> >>Assaf Oron
> >>Statistics Department
> >>University of Washington
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>    
> >>
> >http://www.R-project.org/posting-guide.html
> >  
> >
> >>
> >>
> >>    
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> >
> >  
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Jul 14 15:17:46 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 14 Jul 2004 15:17:46 +0200
Subject: [R] constrOptim and function with additional parameters?
References: <13650.1089809941@www40.gmx.net>
Message-ID: <001101c469a4$f4fb9d20$ad133a86@www.domain>

Hi Marlene,

from the on-line help file of `constrOptim' you can see that the "..."
argument is used for passing extra arguments to the `optim' function
and not in the function being optimized under constraints.

A simple solution would be to pass the value of the extra argument
directly to the function definition e.g., `fr(x, a=100)'. Otherwise
you could create a new version of `constrOptim' that passes the "..."
to the function being optimized and `optim'

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "Marlene Mueller" <Marlene.Mueller at gmx.de>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, July 14, 2004 2:59 PM
Subject: [R] constrOptim and function with additional parameters?


>
> How can I use a function with some additional input parameters
> in constrOptim? For example, something like
>
> fr <- function(x,a) {   ## Rosenbrock Banana function
>   x1 <- x[1]
>   x2 <- x[2]
>   a * (x2 - x1 * x1)^2 + (1 - x1)^2
> }
>
> where the optimum is to be found w.r.t. x. Calling
> optim(c(-1.2,1), fr, NULL, a=100) works as expected, but I fail
> to provide the a=100 in the constrained case:
>
> >  constrOptim(c(-1.2,0.9), fr, NULL, ui=rbind(c(-1,0),c(0,-1)),
> ci=c(-1,-1),a=100)
> Error in f(theta) : Argument "a" is missing, with no default
>
> Is this a bug or is there a different solution that I miss here?
>
> TIA, Marlene
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Wed Jul 14 15:20:11 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 14 Jul 2004 09:20:11 -0400
Subject: [R] constrOptim and function with additional parameters?
In-Reply-To: <13650.1089809941@www40.gmx.net>
References: <13650.1089809941@www40.gmx.net>
Message-ID: <n8caf0dpfndok0lgh80rrfqnlmt90voa3e@4ax.com>

On Wed, 14 Jul 2004 14:59:01 +0200 (MEST), "Marlene Mueller"
<Marlene.Mueller at gmx.de> wrote :

>How can I use a function with some additional input parameters
>in constrOptim? For example, something like
>
>fr <- function(x,a) {   ## Rosenbrock Banana function
>  x1 <- x[1]
>  x2 <- x[2]
>  a * (x2 - x1 * x1)^2 + (1 - x1)^2
>}
>
>where the optimum is to be found w.r.t. x. Calling
>optim(c(-1.2,1), fr, NULL, a=100) works as expected, but I fail 
>to provide the a=100 in the constrained case:
>
>>  constrOptim(c(-1.2,0.9), fr, NULL, ui=rbind(c(-1,0),c(0,-1)),
>ci=c(-1,-1),a=100)
>Error in f(theta) : Argument "a" is missing, with no default
>
>Is this a bug or is there a different solution that I miss here?

I can't spot why your use of constrOptim isn't working, but you should
be able to workaround it by doing something  like this:

applyDefaults <- function(fn, ...) {
  function(x) fn(x, ...)
}

constrOptim(c(-1.2,0.9), applyDefaults(fr, a=100), NULL,
ui=rbind(c(-1,0),c(0,-1)),ci=c(-1,-1))

The applyDefaults function creates a new function which evaluates the
old one with some of the parameters set to fixed values.

Duncan Murdoch



From rpeng at jhsph.edu  Wed Jul 14 16:01:45 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 14 Jul 2004 10:01:45 -0400
Subject: [R] constrOptim and function with additional parameters?
In-Reply-To: <n8caf0dpfndok0lgh80rrfqnlmt90voa3e@4ax.com>
References: <13650.1089809941@www40.gmx.net>
	<n8caf0dpfndok0lgh80rrfqnlmt90voa3e@4ax.com>
Message-ID: <40F53CC9.9070305@jhsph.edu>

Actually, I think this is a bug.  Take a look at this part of constrOptim:

 > constrOptim
function (theta, f, grad, ui, ci, mu = 1e-04, control = list(),
     method = if (is.null(grad)) "Nelder-Mead" else "BFGS", 
outer.iterations = 10
0,
     outer.eps = 1e-05, ...)
{
     if (!is.null(control$fnscale) && control$fnscale < 0)
         mu <- -mu
     [...]
     obj <- f(theta)
     ^^^^^^^^^^^^^^^
     r <- R(theta, theta)
     for (i in 1:outer.iterations) {
         obj.old <- obj
         r.old <- r
     [...]
}

So the object function `f' is called on the starting value `theta' but 
the `...' is not passed through.

-roger

Duncan Murdoch wrote:
> On Wed, 14 Jul 2004 14:59:01 +0200 (MEST), "Marlene Mueller"
> <Marlene.Mueller at gmx.de> wrote :
> 
> 
>>How can I use a function with some additional input parameters
>>in constrOptim? For example, something like
>>
>>fr <- function(x,a) {   ## Rosenbrock Banana function
>> x1 <- x[1]
>> x2 <- x[2]
>> a * (x2 - x1 * x1)^2 + (1 - x1)^2
>>}
>>
>>where the optimum is to be found w.r.t. x. Calling
>>optim(c(-1.2,1), fr, NULL, a=100) works as expected, but I fail 
>>to provide the a=100 in the constrained case:
>>
>>
>>> constrOptim(c(-1.2,0.9), fr, NULL, ui=rbind(c(-1,0),c(0,-1)),
>>
>>ci=c(-1,-1),a=100)
>>Error in f(theta) : Argument "a" is missing, with no default
>>
>>Is this a bug or is there a different solution that I miss here?
> 
> 
> I can't spot why your use of constrOptim isn't working, but you should
> be able to workaround it by doing something  like this:
> 
> applyDefaults <- function(fn, ...) {
>   function(x) fn(x, ...)
> }
> 
> constrOptim(c(-1.2,0.9), applyDefaults(fr, a=100), NULL,
> ui=rbind(c(-1,0),c(0,-1)),ci=c(-1,-1))
> 
> The applyDefaults function creates a new function which evaluates the
> old one with some of the parameters set to fixed values.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From HermanD at intra.nimh.nih.gov  Wed Jul 14 16:02:42 2004
From: HermanD at intra.nimh.nih.gov (Herman, David (NIH/NIMH))
Date: Wed, 14 Jul 2004 10:02:42 -0400
Subject: [R] (no subject)
Message-ID: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040714/ef567854/attachment.pl

From assaf at u.washington.edu  Wed Jul 14 16:06:14 2004
From: assaf at u.washington.edu (Eliyahu-Oron)
Date: Wed, 14 Jul 2004 07:06:14 -0700
Subject: [R] Smooth monotone estimation on R
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF803E@usrymx25.merck.com>
Message-ID: <LFEMIJPCNKKCFAIAPAGLGEMNCFAA.assaf@u.washington.edu>

Andy, Kjetil, hi,

I figured out how to run this, after visiting Jim Ramsay's FDA webpage
example on monotone smoothing:
http://ego.psych.mcgill.ca/misc/fda/ex-growth-d1.html

The code there is Matlab, using very similar names to the R names.

First one needs to create a 'blank' B-spline object (using
create.bspline.basis(), then data2fd() with a 'blank' data vector of, say,
zeros).
Then this object is used as the 'Wfdobj' argument in 'smooth.monotone()'.
The smoothing spline version (lambda=some positive constant) seems to work
better than non-penalized splines (lambda=0).
So the command would be
solution<-smooth.monotone(x,y,Wfdobj=createdbspline,lambda=0.1)

The fit may be shown using
fitted<-solution$beta[1]+solution$beta[2]*eval.monfd(xx,solution$Wfdobj).

eval.monfd() is a utility to perform the integration on the exponent of the
'embedded' B-spline object.

Algebraic details do appear in the 'smooth.monotone()' help, and also on the
webpage.

Ramsay's approach seems to be the one most 'popular' in literature at the
moment, so I'll probably use this package a lot over the next few weeks. If
someone can't access Jim Ramsay or some other 'FDA insider', you can
probably forward them to me regarding smooth.monotone().

Thanks so much again,

Assaf

-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com]
Sent: Wednesday, July 14, 2004 6:17 AM
To: 'Kjetil Halvorsen'; Eliyahu-Oron
Cc: R-help at stat.math.ethz.ch
Subject: RE: [R] Smooth monotone estimation on R


Browsing over the FDA book, I can not find any discussion of monotone
smoothing.

Andy

> From: Kjetil  Halvorsen
>
> Hola!
>
> Experimenting a little, package fda seems very much under
> development,
> and help pages are definitely not finished.
> It would certainly help to read the book "functional data
> analysis" by
> the author of fda, which is in our library.
> On the other hand package mgcv is more mature, so it would
> seem easier
> to use that.
>
> It is not totally automatic, but the example
> library(mgcv)
> example(mono.con)
>
> has everything necessary to get started.
>
> Kjetil Halvorsen
>
> Eliyahu-Oron wrote:
>
> >Kjetil and Andy,
> >
> >Thanks for your helpful answers! The first two (mgcv and
> fda) seem to be in
> >the direction I'm looking for. I downloaded them both.
> >
> >I'm running into a lot of implementation difficulties,
> though. I wonder if
> >there's anyone who tried to do a monotone spline using
> either the 'mgcv' or
> >the 'fda' packages, whom I could ask directly?
> >
> >Thanks again, Assaf
> >
> >-----Original Message-----
> >From: Kjetil Halvorsen [mailto:kjetil at acelerate.com]
> >Sent: Monday, July 12, 2004 4:32 PM
> >To: Assaf P Oron
> >Cc: R-help at stat.math.ethz.ch
> >Subject: Re: [R] Smooth monotone estimation on R
> >
> >
> >help.search()
> >on my machine turns up only:
> >
> >mono.con(mgcv)          Monotonicity constraints for a cubic
> >                        regression spline.
> >
> >smooth.monotone(fda)    Monotone Smoothing of Data
> >pmreg(ftnonpar)         Piecewise monotone regression with taut
> >                        strings
> >backSpline(splines)     Monotone Inverse Spline
> >isoreg(stats)           Isotonic / Monotone Regression
> >
> >so you should find something of use in packages mgvc, fda,
> ftnonpar, splines
> >or stats (.loaded by default)
> >
> >Kjetil Halvorsen
> >
> >
> >Assaf P Oron wrote:
> >
> >
> >
> >>Hi all,
> >>
> >>I'm looking for smooth monotone estimation packages,
> preferably using
> >>
> >>
> >splines.
> >
> >
> >>I downloaded the 'cobs' package and intend to use it, but
> since it offers
> >>
> >>
> >only quadratic splines based on L1 minimization, I'd like to
> compare its
> >performance to that of a more 'mainstream' cubic-spline,
> L2-norm minimizing
> >spline. Preferably a smoothing spline.
> >
> >
> >>Does anyone know of such code existing anywhere? Or another
> smooth monotone
> >>
> >>
> >alternative?
> >
> >
> >>Thanks in advance,
> >>
> >>Assaf Oron
> >>Statistics Department
> >>University of Washington
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>
> >>
> >http://www.R-project.org/posting-guide.html
> >
> >
> >>
> >>
> >>
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> >
> >
> >
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>


----------------------------------------------------------------------------
--
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From vincent.goulet at act.ulaval.ca  Wed Jul 14 16:11:30 2004
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Wed, 14 Jul 2004 10:11:30 -0400
Subject: [R] (no subject)
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>
Message-ID: <200407141011.30940.vincent.goulet@act.ulaval.ca>

Hi,

I but you left out the extension that Windows is hiding from you.

Vincent

On Wednesday 14 July 2004 10:02, Herman, David (NIH/NIMH) wrote:
> Hello,
>             I'm new to R, and I'm having trouble importing a text file (I'm
> on Windows XP)
>
> >  m <- read.table("/Desktop/work/128_L")
>
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `/Desktop/work/128_L'
>
>
> do you know why this isn't working?  All I have is a bunch of text files,
> each with a single column of about 30,000 rows.
>
> thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
  Vincent Goulet, Professeur agr??g??
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From wolski at molgen.mpg.de  Wed Jul 14 16:18:51 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 14 Jul 2004 16:18:51 +0200
Subject: [R] (no subject)
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>
Message-ID: <200407141618510948.0BB9A23F@mail.math.fu-berlin.de>

Hello!

It just is not able to find the file as the error message says.
You can check if you are specified the right directory path using dir.

?dir

dir("/Desktop/work/")

I gues you are not.

If you are specifying the full path, precede it with the drive name c:/

Eryk


*********** REPLY SEPARATOR  ***********

On 7/14/2004 at 10:02 AM Herman, David (NIH/NIMH) wrote:

>>>Hello,
>>>            I'm new to R, and I'm having trouble importing a text file
>>>(I'm
>>>on Windows XP)
>>> 
>>>>  m <- read.table("/Desktop/work/128_L")
>>>Error in file(file, "r") : unable to open connection
>>>In addition: Warning message: 
>>>cannot open file `/Desktop/work/128_L'
>>> 
>>> 
>>>do you know why this isn't working?  All I have is a bunch of text files,
>>>each with a single column of about 30,000 rows.
>>> 
>>>thanks
>>>
>>>	[[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From macq at llnl.gov  Wed Jul 14 16:28:10 2004
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 14 Jul 2004 07:28:10 -0700
Subject: [R] ROracle - fetch gives empty dataframe
In-Reply-To: <40F4F119.9040008@jrc.it>
References: <40F4F119.9040008@jrc.it>
Message-ID: <p06002005bd1af1e6c512@[128.115.153.6]>

This is what I would try next if I were in your situation; I don't 
know it will help.

Try
     con <- dbConnect(ora, "rado/only2admin at dbname")
instead of
    con <- dbConnect(ora, "rado/only2admin"

The default dbname is Sys.getenv("ORACLE_SID"), have you checked that?

For myself, when I make connections to Oracle 9i using ROracle, I use the form
      dbConnect,ora, user='oracleuid',dbname='adbname',password='whatever')

-Don

At 10:38 AM +0200 7/14/04, Rado Bonk wrote:
>Dear R-users,
>
>I was able to make ROracle package to connect to the DB (Oracle91, 
>64bit, on Solaris). But after executing siple SQL query, "fetch" 
>commaned gives me an empty dataframe.
>
>### RORACLE INSTALATION PROCEDURE ###
>R CMD INSTALL --configure-args='--enable-extralibs' 
>--enable-oracle32=no ~/tmp/ROracle_0.5-5.tar.gz  #since we have 
>64bit Oracle9i instalation
>
>PROBLEM: after executing simple statement, from within R, "fetch" 
>function gives me the empty dataframe:
>
>### CONNECTION, and SQL QUERY EXECUTION
>  > ora <- dbDriver("Oracle")
>  > con <- dbConnect(ora, "rado/only2admin"
>  > dbListTables(con)
>character(0)
>>  rs <- dbSendQuery(con, "desc * from si_r where id=498")
>>  d <- fetch(rs, n= -1)
>>  dim(d)
>[1] 0 3
>str(d)
>data.frame':   0 obs. of  3 variables:
>$ ID : int
>$ DAY: chr
>$ R  : num
>
>#### seems like connections has been established
>>  dbGetInfo(ora)
>$drvName
>[1] "Oracle (ProC/C++)"
>
>$connectionIds
>$connectionIds[[1]]
><OraConnection:(14939,0)>
>
>
>$fetch_default_rec
>[1] 500
>
>$managerId
><OraDriver:(14939)>
>
>$length
>[1] 10
>
>$num_con
>[1] 1
>
>$counter
>[1] 1
>
>$clientVersion
>[1] "0.5-4"
>
>Maybe it is something stupid (and I need just a hint), or may be it 
>is something major.
>
>Thanks in advance,
>
>Rado Bonk
>
>
>--
>Dr. Radoslav Bonk
>European Commission - DG Joint Research Centre (JRC)
>Institute for Environment and Sustainability (IES)
>LM Unit - Natural Hazards
>Weather Driven Natural Hazards Action
>Via E. Fermi, TP 261, 21020 Ispra (Va), Italy
>Tel.: 0039-0332-786013
>Fax: 0039-0332-786653
>Webpage: http://natural-hazards.jrc.it/floods/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From dmurdoch at pair.com  Wed Jul 14 16:29:06 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 14 Jul 2004 10:29:06 -0400
Subject: [R] (no subject)
In-Reply-To: <200407141011.30940.vincent.goulet@act.ulaval.ca>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>
	<200407141011.30940.vincent.goulet@act.ulaval.ca>
Message-ID: <fjgaf05jrd28quvck8e5birvpsknlt95oh@4ax.com>

On Wed, 14 Jul 2004 10:11:30 -0400, Vincent Goulet
<vincent.goulet at act.ulaval.ca> wrote :

>Hi,
>
>I but you left out the extension that Windows is hiding from you.

Yes indeed!  Why Windows hides extensions has never made any sense to
me.  To turn off this seriously broken behaviour, open a folder, then
in the Tools|Folder Options dialog, find "Hide extensions for known
file types" and make sure it is not checked.  In Win XP it's under the
View tab, around 10 lines down; I think it's in other places in other
versions.

Duncan Murdoch

>
>Vincent
>
>On Wednesday 14 July 2004 10:02, Herman, David (NIH/NIMH) wrote:
>> Hello,
>>             I'm new to R, and I'm having trouble importing a text file (I'm
>> on Windows XP)
>>
>> >  m <- read.table("/Desktop/work/128_L")
>>
>> Error in file(file, "r") : unable to open connection
>> In addition: Warning message:
>> cannot open file `/Desktop/work/128_L'
>>
>>
>> do you know why this isn't working?  All I have is a bunch of text files,
>> each with a single column of about 30,000 rows.
>>
>> thanks
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html



From msvika at mscc.huji.ac.il  Wed Jul 14 17:36:07 2004
From: msvika at mscc.huji.ac.il (Victoria Landsman)
Date: Wed, 14 Jul 2004 17:36:07 +0200
Subject: [R] Running the optimization on the subset of parameters 
Message-ID: <004901c469b8$47dbc2a0$8600a8c0@home2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040714/2bf6e257/attachment.pl

From macq at llnl.gov  Wed Jul 14 16:35:02 2004
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 14 Jul 2004 07:35:02 -0700
Subject: [R] table lookup n R
In-Reply-To: <000a01c468d5$b7512e10$6c00a8c0@mtd4>
References: <000a01c468d5$b7512e10$6c00a8c0@mtd4>
Message-ID: <p06002006bd1af4385038@[128.115.153.6]>

There is also the match() function, and the %in% operator, either of 
which might do the job, depending on your exact details. For example,

    (1:26)[letters %in% c('x','t','j')]

-Don

At 2:34 PM +0200 7/13/04, Anne wrote:
>Hello R helpers!
>I looked  but did not find a table-lookup R-utility. I could use a 
>loop to do the job (old FORTRAN/C habits die hard) but if I have a 
>big table in which I have to search for the values corresponding to 
>a vector, I end up logically with a double loop.
>Is there already such a utility? Otherwise, is there a way without loops?
>
>Thanks as always
>Anne
>----------------------------------------------------
>Anne Piotet
>Tel: +41 79 359 83 32 (mobile)
>Email: anne.piotet at m-td.com
>---------------------------------------------------
>M-TD Modelling and Technology Development
>PSE-C
>CH-1015 Lausanne
>Switzerland
>Tel: +41 21 693 83 98
>Fax: +41 21 646 41 33
>--------------------------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Jul 14 16:36:31 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 14 Jul 2004 16:36:31 +0200
Subject: [R] constrOptim and function with additional parameters?
References: <13650.1089809941@www40.gmx.net><n8caf0dpfndok0lgh80rrfqnlmt90voa3e@4ax.com>
	<40F53CC9.9070305@jhsph.edu>
Message-ID: <005f01c469af$fc0fe570$ad133a86@www.domain>

This is why the `...' argument is passed to `optim' and not to the
function being optimized, as it also referred in the help file of
`constrOptim'

> constrOptim
function (theta, f, grad, ui, ci, mu = 1e-04, control = list(),
    method = if (is.null(grad)) "Nelder-Mead" else "BFGS",
outer.iterations = 100,
    outer.eps = 1e-05, ...)

...

 a <- optim(theta.old, fun, gradient, control = control,
            method = method, ...)

...
}


Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Roger D. Peng" <rpeng at jhsph.edu>
To: "Duncan Murdoch" <dmurdoch at pair.com>
Cc: <R-help at stat.math.ethz.ch>; "Marlene Mueller"
<Marlene.Mueller at gmx.de>
Sent: Wednesday, July 14, 2004 4:01 PM
Subject: Re: [R] constrOptim and function with additional parameters?


> Actually, I think this is a bug.  Take a look at this part of
constrOptim:
>
>  > constrOptim
> function (theta, f, grad, ui, ci, mu = 1e-04, control = list(),
>      method = if (is.null(grad)) "Nelder-Mead" else "BFGS",
> outer.iterations = 10
> 0,
>      outer.eps = 1e-05, ...)
> {
>      if (!is.null(control$fnscale) && control$fnscale < 0)
>          mu <- -mu
>      [...]
>      obj <- f(theta)
>      ^^^^^^^^^^^^^^^
>      r <- R(theta, theta)
>      for (i in 1:outer.iterations) {
>          obj.old <- obj
>          r.old <- r
>      [...]
> }
>
> So the object function `f' is called on the starting value `theta'
but
> the `...' is not passed through.
>
> -roger
>
> Duncan Murdoch wrote:
> > On Wed, 14 Jul 2004 14:59:01 +0200 (MEST), "Marlene Mueller"
> > <Marlene.Mueller at gmx.de> wrote :
> >
> >
> >>How can I use a function with some additional input parameters
> >>in constrOptim? For example, something like
> >>
> >>fr <- function(x,a) {   ## Rosenbrock Banana function
> >> x1 <- x[1]
> >> x2 <- x[2]
> >> a * (x2 - x1 * x1)^2 + (1 - x1)^2
> >>}
> >>
> >>where the optimum is to be found w.r.t. x. Calling
> >>optim(c(-1.2,1), fr, NULL, a=100) works as expected, but I fail
> >>to provide the a=100 in the constrained case:
> >>
> >>
> >>> constrOptim(c(-1.2,0.9), fr, NULL, ui=rbind(c(-1,0),c(0,-1)),
> >>
> >>ci=c(-1,-1),a=100)
> >>Error in f(theta) : Argument "a" is missing, with no default
> >>
> >>Is this a bug or is there a different solution that I miss here?
> >
> >
> > I can't spot why your use of constrOptim isn't working, but you
should
> > be able to workaround it by doing something  like this:
> >
> > applyDefaults <- function(fn, ...) {
> >   function(x) fn(x, ...)
> > }
> >
> > constrOptim(c(-1.2,0.9), applyDefaults(fr, a=100), NULL,
> > ui=rbind(c(-1,0),c(0,-1)),ci=c(-1,-1))
> >
> > The applyDefaults function creates a new function which evaluates
the
> > old one with some of the parameters set to fixed values.
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Jul 14 16:57:38 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Jul 2004 16:57:38 +0200
Subject: [R] notes on specifying paths and file extensions in Windows;
	was: (no subject)
In-Reply-To: <fjgaf05jrd28quvck8e5birvpsknlt95oh@4ax.com>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>	<200407141011.30940.vincent.goulet@act.ulaval.ca>
	<fjgaf05jrd28quvck8e5birvpsknlt95oh@4ax.com>
Message-ID: <40F549E2.1010400@statistik.uni-dortmund.de>

Duncan Murdoch wrote:

> On Wed, 14 Jul 2004 10:11:30 -0400, Vincent Goulet
> <vincent.goulet at act.ulaval.ca> wrote :
> 
> 
>>Hi,
>>
>>I but you left out the extension that Windows is hiding from you.
> 
> 
> Yes indeed!  Why Windows hides extensions has never made any sense to
> me.  To turn off this seriously broken behaviour, open a folder, then
> in the Tools|Folder Options dialog, find "Hide extensions for known
> file types" and make sure it is not checked.  In Win XP it's under the
> View tab, around 10 lines down; I think it's in other places in other
> versions.

In particular, the path for sure does not realy start with "/Desktop"...

You might want to try
   dir(file.path(Sys.getenv("USERPROFILE"), "Desktop/work"))
and correct the entry to
   read.table(file.path(Sys.getenv("USERPROFILE"), 
"Desktop/work/128_L.YourExtension"))

Uwe Ligges

BTW: I wonder why nobody uses a sensible subject in this thread....



> Duncan Murdoch
> 
> 
>>Vincent
>>
>>On Wednesday 14 July 2004 10:02, Herman, David (NIH/NIMH) wrote:
>>
>>>Hello,
>>>            I'm new to R, and I'm having trouble importing a text file (I'm
>>>on Windows XP)
>>>
>>>
>>>> m <- read.table("/Desktop/work/128_L")
>>>
>>>Error in file(file, "r") : unable to open connection
>>>In addition: Warning message:
>>>cannot open file `/Desktop/work/128_L'
>>>
>>>
>>>do you know why this isn't working?  All I have is a bunch of text files,
>>>each with a single column of about 30,000 rows.
>>>
>>>thanks
>>>
>>>	[[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rado.bonk at jrc.it  Wed Jul 14 17:05:25 2004
From: rado.bonk at jrc.it (Rado Bonk)
Date: Wed, 14 Jul 2004 17:05:25 +0200
Subject: [R] ROracle - fetch gives empty dataframe
In-Reply-To: <Pine.LNX.4.53.0407141409180.184@lakeforest.homelinux.com>
References: <40F4F119.9040008@jrc.it>
	<Pine.LNX.4.53.0407141409180.184@lakeforest.homelinux.com>
Message-ID: <40F54BB5.4010004@jrc.it>

Michael,

Yes you are right, I forgot to specify the dbname when posting in R-help 
list. But not in my R-code, since it is specified in ORACLE_SID variable 
on Linux. Using the proper syntax I still get an empty data frame:

 > library(ROracle)
 > drv <- dbDriver("Oracle")
 > con <- dbConnect(drv, "rado/mypassword at dea")
 > dbListTables(con)
character(0)
 > q.sql <- c("select * from si_r where id=498")
 > rs <- dbSendQuery(con, q.sql)
 > data <- fetch(rs, n= -1)
 > dim(data)
[1] 0 3
 > dbGetStatement(rs)
[1] "select * from si_r where id=498"
 > dbGetInfo(con)
$dbname
[1] "dea"

$user
[1] "rado"

$passwd
[1] "mypassword"

$conType
[1] NA

$serverVersion
[1] NA

$protocolVersion
[1] NA

$threadId
[1] -1

$resultSetIds
$resultSetIds[[1]]
<OraResult:(15551,0,2)>

 > data
[1] ID  DAY R
<0 rows> (or 0-length row.names)

> 
>>### CONNECTION, and SQL QUERY EXECUTION
>> > ora <- dbDriver("Oracle")
>> > con <- dbConnect(ora, "rado/only2admin"
> 
> 
> Which database???

-- 
Radoslav Bonk
European Commission - DG Joint Research Centre (JRC)
Institute for Environment and Sustainability (IES)
LM Unit - Natural Hazards
Weather Driven Natural Hazards Action
Via E. Fermi, TP 261, 21020 Ispra (Va), Italy
Tel.: 0039-0332-786013
Fax: 0039-0332-786653
Webpage: http://natural-hazards.jrc.it/floods/



From HermanD at intra.nimh.nih.gov  Wed Jul 14 17:12:43 2004
From: HermanD at intra.nimh.nih.gov (Herman, David (NIH/NIMH))
Date: Wed, 14 Jul 2004 11:12:43 -0400
Subject: [R] duplicate row importing issue
Message-ID: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C8@nihexchange20.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040714/462732a6/attachment.pl

From talitaperciano at hotmail.com  Wed Jul 14 17:13:08 2004
From: talitaperciano at hotmail.com (Talita Leite)
Date: Wed, 14 Jul 2004 12:13:08 -0300
Subject: [R] Tcl/Tk and R
Message-ID: <BAY14-F30oACgxdvzhT0009cd5c@hotmail.com>

Hi!!

I'm using the R package tcltk. See the stretch of code below:

>tbn1 = tclvalue(tkadd(tn,label="Modify Data"))
>tkpack(tbw1 <- .Tk.newwin(tbn1))
>tkpack(fr1 <- tkframe(tbw1))
>tkpack(lb1<- tkwidget(fr1,"iwidgets::labeledframe"))

When I try to execute this I have this error at the last line:

Error in structure(.External("dotTclObjv", objv, PACKAGE = "tcltk"), class = 
"tclObj") :
        [tcl] can't find usual code for tag "Frame".

Please help me!!

Thank's

Talita Perciano Costa Leite
Graduanda em Ci??ncia da Computa????o
Universidade Federal de Alagoas - UFAL
Departamento de Tecnologia da Informa????o - TCI
Constru????o de Conhecimento por Agrupamento de Dados - CoCADa



From ramasamy at cancer.org.uk  Wed Jul 14 17:35:26 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 14 Jul 2004 16:35:26 +0100
Subject: [R] duplicate row importing issue
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C8@nihexchange20.nih.gov>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C8@nihexchange20.nih.gov>
Message-ID: <1089819326.3047.41.camel@vpn202001.lif.icnet.uk>

Try read.table(choose.files(), row.names=NULL).

BTW, I think you might be using an older R version because in R-1.9.1,
the value for row.names is missing by default in read.table(). 

> args(read.table)
function (file, header = FALSE, sep = "", quote = "\"'", dec = ".",
   row.names, col.names, as.is = FALSE, na.strings = "NA", 
   colClasses = NA, nrows = -1, skip = 0, check.names = TRUE, 
   fill = !blank.lines.skip, strip.white = FALSE, 
   blank.lines.skip = TRUE, comment.char = "#")

Try read.delim() or read.csv() if the data is tab-delimited or comma
separated. Also check to see if you have a header, in which case you
would set the option header=TRUE. For more info, help("read.table").

Do dim(m), head(m) to see if the data has been read correctly.


On Wed, 2004-07-14 at 16:12, Herman, David (NIH/NIMH) wrote:
> Hello,
>             I'm simply trying to import a .txt file that has a column of
> about 30,000 pts. I found the file, but I'm getting an error:
> > m <- read.table(choose.files())
> Error in "row.names<-.data.frame"(`*tmp*`, value = row.names) : 
>         duplicate row.names are not allowed
>  
> Any help with getting around this?
>  
> I really appreciate all the help.
> Thanks
> dave
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Wed Jul 14 17:39:29 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 14 Jul 2004 11:39:29 -0400
Subject: [R]  reading text file in Windows (was no subject)
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>
Message-ID: <20040714153931.ECYB28143.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear David,

You got several useful suggestions for what you may have done wrong. I often
find that it's easier to use read.table(file.choose()) and to navigate to
the file in the resulting dialog than to type the path to the file.

I hope that this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Herman, David (NIH/NIMH)
> Sent: Wednesday, July 14, 2004 9:03 AM
> To: 'R-help at lists.R-project.org'
> Subject: [R] (no subject)
> 
> Hello,
>             I'm new to R, and I'm having trouble importing a 
> text file (I'm on Windows XP)
>  
> >  m <- read.table("/Desktop/work/128_L")
> Error in file(file, "r") : unable to open connection In 
> addition: Warning message: 
> cannot open file `/Desktop/work/128_L'
>  
>  
> do you know why this isn't working?  All I have is a bunch of 
> text files, each with a single column of about 30,000 rows.
>  
> thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Wed Jul 14 17:43:59 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 14 Jul 2004 11:43:59 -0400
Subject: [R] duplicate row importing issue
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C8@nihexchange20.nih.gov>
Message-ID: <20040714154401.JVXX14757.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear David,

If there is one fewer variable name in the first row of the data file than
fields in the remaining rows, then read.table() will treat the first entry
in each row as the row name. Simply add a new first variable (such as
"name") to the first row, and specify header=TRUE in the call to
read.table(). (Of course, this assumes that I've correctly guessed the
source of the problem.)

I hope that this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Herman, David (NIH/NIMH)
> Sent: Wednesday, July 14, 2004 10:13 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] duplicate row importing issue
> 
> Hello,
>             I'm simply trying to import a .txt file that has 
> a column of about 30,000 pts. I found the file, but I'm 
> getting an error:
> > m <- read.table(choose.files())
> Error in "row.names<-.data.frame"(`*tmp*`, value = row.names) : 
>         duplicate row.names are not allowed
>  
> Any help with getting around this?
>  
> I really appreciate all the help.
> Thanks
> dave
>



From dmurdoch at pair.com  Wed Jul 14 18:01:06 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 14 Jul 2004 12:01:06 -0400
Subject: [R] SWIG for R
In-Reply-To: <20040714150128.GD9544@wald.ucdavis.edu>
References: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
	<006701c4697a$4b5f4d40$3b8001db@webgis>
	<9ev9f0pi9k100j0j5kahuk3mhqo4iecglg@4ax.com>
	<20040714150128.GD9544@wald.ucdavis.edu>
Message-ID: <oflaf0dvs5qaa5plte2dqed2kkievllpef@4ax.com>

On Wed, 14 Jul 2004 08:01:28 -0700, Duncan Temple Lang
<duncan at wald.ucdavis.edu> wrote :

>SWIG is an extensible system and so people
>other than the SWIG developers can indeed 
>provide facilities for supporting R.
>I am surprised nobody has done it yet
>and remember asking you whether you had considered
>using SWIG for your OpenGL about 3 years ago.

Sorry, I forgot about that.

I don't think SWIG would be much help with OpenGL, because there the
difficulty is in translating the R ideas of what data is like and what
people want to do with it into corresponding concepts in OpenGL, the
actual calls to the OpenGL API are a pretty easy part of the whole
exercise.  In any case, they probably have to be written in compiled
code for performance reasons, since you make so many OpenGL calls 
for every frame being drawn.

But I'm sure there are other libraries where this isn't true, and SWIG
would be useful for them.  Maybe Hisaji has one, and would want to
tackle the R support.

Duncan Murdoch



From altirriba at hotmail.com  Wed Jul 14 18:16:34 2004
From: altirriba at hotmail.com (=?iso-8859-1?B?Sm9yZGkgQWx0aXJyaWJhIEd1dGnpcnJleg==?=)
Date: Wed, 14 Jul 2004 18:16:34 +0200
Subject: [R]  Permutations
Message-ID: <BAY15-F20Zuqydb2paw00055d00@hotmail.com>

  Dear R users,
  First of all, thanks to Rolf, Brad, Robin, Erich, Fernando and Adaikalavan 
for your time and suggestions.
  I?ve been testing some algorithms (sorry for the delay, I?m very slow, and 
I?m a completely beginner in R?s world).
  First, the Robin algorithm.
  I think that there is a problem because I?ve done 200 permutations and 
I?ve found that these permutations are the same:
52 and 91, 99 and 110, 121 and 122, 51 and 141, 130 and 134.
  Thanks again,

Jordi Altirriba
Hospital Clinic - Barcelona - Spain

>x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
>dim(x) <- c(3,4) a<-matrix(1,200,12)
>for (i in 1:200)
+ {
+  jj <- t(apply(x,1,sample))
+ a[i,]<-as.vector(jj)
+ }
>a
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
  [1,]    7    2    3    1   11    6    4    8    9    10     5    12
  [2,]    1    2    9    7   11    6    4    8   12    10     5     3
  [3,]    7    2    9    1   11    3    4    5    6    10     8    12
  [4,]   10    8    6    4    5   12    7    2    9     1    11     3
  [5,]   10    2   12    1   11    9    7    8    6     4     5     3
  [6,]    7    8    6    1    5    9    4   11   12    10     2     3
  [7,]    1    5   12    7    2    6    4    8    9    10    11     3
  [8,]    1    5    9   10    8    6    4    2    3     7    11    12
  [9,]    1   11    6    7    2   12    4    5    9    10     8     3
[10,]    4    5   12   10   11    9    1    8    6     7     2     3
[11,]    1   11    9    7    5    6    4    8   12    10     2     3
[12,]    1    8    3    4    2   12   10    5    9     7    11     6
[13,]    1    2    3    7   11    6   10    5   12     4     8     9
[14,]    4    8    3   10    5   12    7    2    9     1    11     6
[15,]   10    2    3    4    8    6    7   11    9     1     5    12
[16,]    4    8    9   10    2   12    7    5    6     1    11     3
[17,]    1    2    6   10    5    3    7    8   12     4    11     9
[18,]   10    2    9    4   11   12    1    5    6     7     8     3
[19,]    4    8    6    7   11   12    1    2    9    10     5     3
[20,]    1    8   12    7    2    3   10   11    6     4     5     9
[21,]   10    2   12    1    5    9    7   11    6     4     8     3
[22,]    4   11   12    1    2    3   10    8    6     7     5     9
[23,]    1   11    3    7    2    6   10    5    9     4     8    12
[24,]    7    2    9   10    5   12    1   11    3     4     8     6
[25,]    7    8    9    1    2    6    4    5    3    10    11    12
[26,]    4    5   12   10    2    3    7   11    6     1     8     9
[27,]    4    5    9    1   11    3    7    8   12    10     2     6
[28,]    1    5    6    4   11    3    7    8    9    10     2    12
[29,]    4    5    6    1   11    9   10    2   12     7     8     3
[30,]    4   11    3    7    8   12   10    5    6     1     2     9
[31,]   10    2    3    1   11    6    7    8    9     4     5    12
[32,]   10    2    3    7    8    9    1   11    6     4     5    12
[33,]    7   11    6    1    8    9    4    5   12    10     2     3
[34,]    7    5   12    1    8    6    4   11    3    10     2     9
[35,]    1    2    3    4    8    6    7    5    9    10    11    12
[36,]    7    8    3    1   11    9   10    2   12     4     5     6
[37,]   10    2    6    1   11   12    7    5    3     4     8     9
[38,]    1    5    9    4   11   12    7    8    3    10     2     6
[39,]    1    2   12    7    5    9   10    8    3     4    11     6
[40,]    1    8    3   10    2   12    7   11    6     4     5     9
[41,]    1    2    9    4    8    3   10   11   12     7     5     6
[42,]    4    5    6    1    2    9   10    8    3     7    11    12
[43,]    1    2    6    7   11   12   10    5    9     4     8     3
[44,]    1    2    9   10   11   12    4    8    6     7     5     3
[45,]   10    5    9    7   11    6    4    2    3     1     8    12
[46,]    1    2    3    4   11    6    7    5    9    10     8    12
[47,]    4    2    6    1    8    3   10    5   12     7    11     9
[48,]    4    8    9    7    2    3    1    5   12    10    11     6
[49,]   10    8   12    1    2    9    4   11    3     7     5     6
[50,]   10    8    6    1    2    3    7    5   12     4    11     9
[51,]    7    2   12   10   11    6    4    8    3     1     5     9
[52,]    4    5    6    1    2   12   10   11    9     7     8     3
[53,]    1    2    3    7    5    6    4    8    9    10    11    12
[54,]   10    5    3    7   11    9    1    8    6     4     2    12
[55,]    7   11   12    4    2    3   10    8    6     1     5     9
[56,]    1    5    9    4   11   12   10    8    3     7     2     6
[57,]    4    5    9    7   11    3   10    2    6     1     8    12
[58,]   10   11    3    4    5    6    1    8   12     7     2     9
[59,]    4    8    9   10    5    6    7    2    3     1    11    12
[60,]    4    2   12    1    8    6   10    5    9     7    11     3
[61,]    4    8    6    7   11    9   10    5   12     1     2     3
[62,]    7    8    3   10    5    6    1   11   12     4     2     9
[63,]   10    5    3    7    8    6    1    2    9     4    11    12
[64,]   10    2    9    4   11   12    1    5    3     7     8     6
[65,]    1   11    6    4    8   12    7    2    3    10     5     9
[66,]    1    5    3    7   11    9    4    2   12    10     8     6
[67,]    4    2    6    7    5   12   10    8    9     1    11     3
[68,]    4   11   12   10    2    3    7    8    6     1     5     9
[69,]    4    5    6   10    2    3    7    8    9     1    11    12
[70,]    1   11   12   10    2    6    4    5    3     7     8     9
[71,]   10    5    6    7    8   12    4    2    9     1    11     3
[72,]   10    8   12    1   11    9    7    5    3     4     2     6
[73,]   10    8    3    7   11    9    4    5   12     1     2     6
[74,]    7    2   12    1    5    6    4    8    9    10    11     3
[75,]    7    2   12   10    8    9    1   11    6     4     5     3
[76,]    7    2    3    1    5    9    4    8   12    10    11     6
[77,]    1   11    3   10    5    6    7    2    9     4     8    12
[78,]    7    2    6   10   11   12    4    8    9     1     5     3
[79,]   10    8    6    7    5    3    1    2    9     4    11    12
[80,]   10   11    3    7    2   12    4    8    6     1     5     9
[81,]   10    5    6    1    8    3    4   11    9     7     2    12
[82,]    1   11    3    7    5   12   10    2    6     4     8     9
[83,]    4   11    9   10    5   12    7    2    6     1     8     3
[84,]    1   11   12    7    8    3    4    2    6    10     5     9
[85,]   10    2    9    7    5    6    1   11   12     4     8     3
[86,]    7   11    9    4    5    6   10    2   12     1     8     3
[87,]    4    5   12    7    2    3   10   11    6     1     8     9
[88,]    1    2   12    7    5    3   10    8    6     4    11     9
[89,]    1    8   12    7   11    9   10    2    6     4     5     3
[90,]    4    5    3   10   11    9    7    2    6     1     8    12
[91,]    4    5    6    1    2   12   10   11    9     7     8     3
[92,]   10   11    9    7    5   12    1    2    6     4     8     3
[93,]    4    2    3    7    8    6    1   11   12    10     5     9
[94,]    4    5    3   10    2   12    7    8    9     1    11     6
[95,]    4    8    3   10   11    9    1    2    6     7     5    12
[96,]    7    5   12   10   11    3    1    8    9     4     2     6
[97,]    4    2    3    1    8    6    7   11    9    10     5    12
[98,]    4   11    9    7    5   12   10    8    6     1     2     3
[99,]    1   11   12    4    5    6    7    8    3    10     2     9
[100,]    1    8    3    7    5    6   10    2   12     4    11     9
[101,]    7   11    6    4    8    3    1    2   12    10     5     9
[102,]    7   11   12    1    2    3   10    8    6     4     5     9
[103,]    4    5   12    1    2    9    7    8    3    10    11     6
[104,]   10   11   12    4    8    3    7    5    9     1     2     6
[105,]   10    5    9    1    2    3    4    8    6     7    11    12
[106,]   10   11    9    1    2   12    7    8    3     4     5     6
[107,]   10   11    3    4    8    9    7    5   12     1     2     6
[108,]    7    2    6    1   11    9    4    5   12    10     8     3
[109,]    1    8    6    7    2   12   10    5    3     4    11     9
[110,]    1   11   12    4    5    6    7    8    3    10     2     9
[111,]    7    8    6    1    5    3   10    2   12     4    11     9
[112,]    4    8    3    7    5    6    1    2    9    10    11    12
[113,]    1    2    9    4   11    6    7    5    3    10     8    12
[114,]    4   11    9    1    8    6    7    2    3    10     5    12
[115,]   10    8    3    4   11   12    7    2    9     1     5     6
[116,]    7   11   12    1    2    3    4    8    9    10     5     6
[117,]    1    5    3   10   11   12    7    8    9     4     2     6
[118,]    1   11    6    4    2    9   10    5   12     7     8     3
[119,]   10    2    3    1    5    9    4    8   12     7    11     6
[120,]    1    2    3    4   11   12    7    8    9    10     5     6
[121,]    7    8    3    4    5   12   10    2    6     1    11     9
[122,]    7    8    3    4    5   12   10    2    6     1    11     9
[123,]    4    5    3   10   11    9    7    8    6     1     2    12
[124,]    4    5    6    7   11    9    1    8   12    10     2     3
[125,]   10    8    6    1   11    9    4    2   12     7     5     3
[126,]   10    8   12    4   11    9    7    2    6     1     5     3
[127,]    7    8   12    1   11    6   10    5    9     4     2     3
[128,]    1    8   12   10   11    3    7    5    9     4     2     6
[129,]    7    8    3   10    2    6    1   11    9     4     5    12
[130,]    7   11    9    1    2    6   10    8    3     4     5    12
[131,]   10    2    3    4   11    9    1    5    6     7     8    12
[132,]    4   11    3    1    5    9   10    2    6     7     8    12
[133,]   10    2   12    7    8    3    4    5    6     1    11     9
[134,]    7   11    9    1    2    6   10    8    3     4     5    12
[135,]    7    8    3    4   11    6   10    2    9     1     5    12
[136,]   10    8    9    7   11   12    1    2    6     4     5     3
[137,]   10    8   12    4    5    3    1    2    9     7    11     6
[138,]    1    2    6   10    8   12    7   11    9     4     5     3
[139,]    4    5    3    7   11    9    1    2   12    10     8     6
[140,]    4    5   12    7    8    6   10   11    3     1     2     9
[141,]    7    2   12   10   11    6    4    8    3     1     5     9
[142,]   10   11   12    7    2    6    1    5    3     4     8     9
[143,]    7    2    3   10   11    6    1    8    9     4     5    12
[144,]    1    2    9   10    5   12    4    8    3     7    11     6
[145,]    1   11    6    4    8    9    7    5   12    10     2     3
[146,]    4    5    3   10    2    6    1   11    9     7     8    12
[147,]    7   11    9    1    2    3   10    8   12     4     5     6
[148,]    4    2    3    1    5   12    7    8    6    10    11     9
[149,]   10   11   12    4    8    3    1    2    9     7     5     6
[150,]    4    8    3   10    5    6    1   11    9     7     2    12
[151,]    1    8    6   10    5    9    4   11    3     7     2    12
[152,]    4    8    6    7   11   12   10    5    3     1     2     9
[153,]    7    2    3   10    5    6    4   11    9     1     8    12
[154,]   10    5   12    1    8    9    7    2    3     4    11     6
[155,]    1    8    6    4    2    9   10    5    3     7    11    12
[156,]   10    2    3    7    5    9    4   11   12     1     8     6
[157,]   10    5    3    1    2    6    7    8    9     4    11    12
[158,]    7   11   12    4    5    9   10    8    3     1     2     6
[159,]    7    5    3    1    8   12   10    2    6     4    11     9
[160,]    7    2    6    4   11    3    1    5   12    10     8     9
[161,]    7    5    3    1    2   12    4    8    9    10    11     6
[162,]    7    8   12    1    5    6   10   11    9     4     2     3
[163,]   10   11    9    4    8    6    1    2    3     7     5    12
[164,]    7   11    6    1    5    9    4    2   12    10     8     3
[165,]    4   11    9   10    8    3    7    2   12     1     5     6
[166,]    4    2    6   10    8    9    7   11   12     1     5     3
[167,]    7    5    3   10    2   12    4    8    6     1    11     9
[168,]    1    8   12    7    2    3    4    5    9    10    11     6
[169,]    7    8   12    1    5    6    4    2    3    10    11     9
[170,]    4    5    3    7    8    9    1    2   12    10    11     6
[171,]    7   11    9    1    8    6    4    2   12    10     5     3
[172,]   10    8    3    1    2    9    4   11   12     7     5     6
[173,]   10    5   12    7    8    9    4   11    3     1     2     6
[174,]   10   11    6    7    5    3    4    8   12     1     2     9
[175,]    7   11   12    1    2    3   10    8    9     4     5     6
[176,]    1   11   12    7    2    3    4    8    9    10     5     6
[177,]   10   11   12    4    5    3    7    8    6     1     2     9
[178,]   10    5    3    7    2    6    4    8   12     1    11     9
[179,]    1    5    6    7    2    9   10   11    3     4     8    12
[180,]    1   11   12   10    5    6    4    2    3     7     8     9
[181,]    7    2   12    4   11    9    1    5    6    10     8     3
[182,]   10   11   12    1    5    3    7    8    9     4     2     6
[183,]    4    8    3    1   11    9    7    2    6    10     5    12
[184,]    4    8    9    7    2    3   10    5    6     1    11    12
[185,]   10   11    9    1    5    6    7    2   12     4     8     3
[186,]   10    5   12    4    8    9    7    2    6     1    11     3
[187,]    4    2    3    1    8    6    7    5   12    10    11     9
[188,]   10    2    9    4   11   12    1    8    3     7     5     6
[189,]   10    2   12    7   11    3    4    5    9     1     8     6
[190,]    4    5    6    7    8    3   10   11    9     1     2    12
[191,]   10    5    9    1    2    3    7   11   12     4     8     6
[192,]    4   11    9    7    2    6   10    5    3     1     8    12
[193,]   10   11   12    1    2    6    4    5    9     7     8     3
[194,]   10    2    3    4   11   12    7    5    6     1     8     9
[195,]    4    2    6    7    8    9    1   11    3    10     5    12
[196,]   10    2   12    4    8    6    7    5    3     1    11     9
[197,]    7    5   12    4   11    9    1    2    3    10     8     6
[198,]   10    5    6    1   11    3    7    2    9     4     8    12
[199,]    1    2    9    7   11    3    4    8    6    10     5    12
[200,]    4    8    3    7   11   12    1    2    6    10     5     9



>From: Robin Hankin <rksh at soc.soton.ac.uk>
>To: Jordi Altirriba Guti??rrez  	<altirriba at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] (no subject) (was: Permutations)
>Date: Wed, 14 Jul 2004 09:11:48 +0100
>
>Jordi
>
>try this
>
>
>R> x <- c(1,2,3,  10,11,12,  41,42,43,  81,82,83)
>R> dim(x) <- c(3,4)
>R> x
>      [,1] [,2] [,3] [,4]
>[1,]    1   10   41   81
>[2,]    2   11   42   82
>[3,]    3   12   43   83
>R>  jj <- t(apply(x,1,sample))
>R> jj
>      [,1] [,2] [,3] [,4]
>[1,]    1   41   10   81
>[2,]    2   11   82   42
>[3,]   12    3   43   83
>R> as.vector(jj)
>R>
>    [1]  1 2 12 41 11 3 10 82 43 81 42 83
>
>
>
>
>and I think that does what you want...
>
>We take the vector, rearrange it into a matrix with three rows, then sample 
>*within* the rows,
>then rearrange into a vector again.
>
>There will be one forbidden permutation, namely the identity (which may or 
>may not be
>desirable).
>
>This method doesn't allow "intra block" permutations.
>
>best
>
>rksh
>
>
>
>>  Dear R users,
>>  First of all, thanks for the incredibly fast answers and help of Rolf, 
>>Marc and Robert.
>>  Yes, I noticed that it was a lot of permutacions, but my intention was 
>>to make this process automatic and take only 5.000 - 10.000 permutations. 
>>Therefore, I wanted only to take that "interesting permutations" with 
>>"some information" [inter-block permutations].
>>  The reason why I'm interested in these permutations is because I'm using 
>>some packages of Bioconductor to analyse my data from some microarrays and 
>>I thought that perhaps could be interesting to see what happens when I 
>>permute my data and I compare it against the not permuted data.
>>  Thanks again for your time and suggestions.
>>
>>Jordi Altirriba
>>Ph. D. Student
>>
>>Hospital Clinic-Barcelona-Spain
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>
>
>--
>Robin Hankin
>Uncertainty Analyst
>Southampton Oceanography Centre
>SO14 3ZH
>tel +44(0)23-8059-7743
>initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From rossini at blindglobe.net  Wed Jul 14 18:33:06 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 14 Jul 2004 09:33:06 -0700
Subject: [R] SWIG for R
In-Reply-To: <oflaf0dvs5qaa5plte2dqed2kkievllpef@4ax.com> (Duncan Murdoch's
	message of "Wed, 14 Jul 2004 12:01:06 -0400")
References: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
	<006701c4697a$4b5f4d40$3b8001db@webgis>
	<9ev9f0pi9k100j0j5kahuk3mhqo4iecglg@4ax.com>
	<20040714150128.GD9544@wald.ucdavis.edu>
	<oflaf0dvs5qaa5plte2dqed2kkievllpef@4ax.com>
Message-ID: <858ydmpn0d.fsf@servant.blindglobe.net>


I like SWIG (well, it facilitates wrappers for Python really well),
but it's not perfect. 

I've not delved into the difficulties in any detail yet, but we've had
problems with mixing SWIG and Boost.python for connections with Python
code -- and the Boost.python mechanism "feels" like DTL's RS<your
language here> code, where as SWIG doesn't quite have the same flavor.

(sorry for failing on the details, but I'm doing something else
today).




Duncan Murdoch <dmurdoch at pair.com> writes:

> On Wed, 14 Jul 2004 08:01:28 -0700, Duncan Temple Lang
> <duncan at wald.ucdavis.edu> wrote :
>
>>SWIG is an extensible system and so people
>>other than the SWIG developers can indeed 
>>provide facilities for supporting R.
>>I am surprised nobody has done it yet
>>and remember asking you whether you had considered
>>using SWIG for your OpenGL about 3 years ago.
>
> Sorry, I forgot about that.
>
> I don't think SWIG would be much help with OpenGL, because there the
> difficulty is in translating the R ideas of what data is like and what
> people want to do with it into corresponding concepts in OpenGL, the
> actual calls to the OpenGL API are a pretty easy part of the whole
> exercise.  In any case, they probably have to be written in compiled
> code for performance reasons, since you make so many OpenGL calls 
> for every frame being drawn.
>
> But I'm sure there are other libraries where this isn't true, and SWIG
> would be useful for them.  Maybe Hisaji has one, and would want to
> tackle the R support.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From monica.palaseanu-lovejoy at stud.man.ac.uk  Wed Jul 14 18:43:33 2004
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Wed, 14 Jul 2004 17:43:33 +0100
Subject: [R] Ord-Getis O statistics
Message-ID: <E1BkmrE-000C8I-0o@probity.mcc.ac.uk>

Hi list,

I am wondering if anybody knows if the Ord-Getis O statistics of 
local spatial autocorrelation in the presence of the global spatial 
association is implemented in any of the R packages - and of 
course in which package ;-)). I am not interested in Getis-Ord G 
statistics, for now.

Thank you in advance,

Monica




Monica Palaseanu-Lovejoy
University of Manchester
School of Geography
Mansfield Cooper Bld. 3.21
Oxford Road
Manchester M13 9PL
England, UK
Tel: +44 (0) 275 8689
Email: monica.palaseanu-lovejoy at stud.man.ac.uk



From ggrothendieck at myway.com  Wed Jul 14 18:47:07 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 14 Jul 2004 16:47:07 +0000 (UTC)
Subject: [R] Permutations
References: <BAY15-F21OSCBfAbdxk0001f04a@hotmail.com>
	<40F4E56C.3090001@univie.ac.at>
Message-ID: <loom.20040714T184231-229@post.gmane.org>


As Erich points out, there is some question as to
what the original problem really is but lets
assume its as Erich describes.  Then, to get a
random ordered permutation we just get a random 
permutation of 12 elements and sort the intra-block 
elements like this:

   c(apply(matrix(sample(12,12),3),2,sort))

Note that there are 12! = 479,001,600 permutations
of 12 elements and 3!^4 = 1,296 of those
permutations correspond to each ordered
permutation so there are 479,001,600 / 1,296 =
369,600 ordered permutations in all.  

Erich Neuwirth <erich.neuwirth <at> univie.ac.at> writes:

: 
: Perhaps what you want might better be described as
: ordered partitions?
: 
: Is what you want the following:
: 
: We study sequences of length 12 and divide them in
: 4 segments
: position 1 2 3, position 4 5 6,
: position 7 8 9, position 10 11 12,
: 
: Find all permutation sequences of the numbers 1 to 12
: with the property that all segment sequences
: are monotonically increasing.
: 
: I think that produces what you need.
: Since the segments are ordered, you avoid intra-block permutations.
: 
: If that is what you want, writing a recursive function should not be
: too hard.
: 
: Jordi Altirriba Gutirrez wrote:
: 
: > Dear R users,
: > I'm a beginner user of R and I've a problem with permutations that I 
: > don't know how to solve. I've 12 elements in blocks of 3 elements and I 
: > want only to make permutations inter-blocks (no intra-blocks) (sorry if 
: > the terminology is not accurate), something similar to:
: > 
: > 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   ----------1st permutation
: > 
: > 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO
: >   -  -
: > 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO
: > -  -  -
: > 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
: >      -    -
: > 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
: > -  -  -   -  -  -
: > 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO
: >           -  -
: > ....
: > 
: >  Thanks for your time,
: > 
: > Jordi Altirriba
: > Ph D student
: > 
: > Hospital Clinic "Barcelona - Spain
: > 
: > 
: > MSN Motor. http://motor.msn.es/researchcentre/
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: > 
:



From rossini at blindglobe.net  Wed Jul 14 18:48:37 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 14 Jul 2004 09:48:37 -0700
Subject: [R] SWIG for R
In-Reply-To: <858ydmpn0d.fsf@servant.blindglobe.net> (A. J. Rossini's
	message of "Wed, 14 Jul 2004 09:33:06 -0700")
References: <002901c46977$f0fbe040$dfc6ed82@hblaptop>
	<006701c4697a$4b5f4d40$3b8001db@webgis>
	<9ev9f0pi9k100j0j5kahuk3mhqo4iecglg@4ax.com>
	<20040714150128.GD9544@wald.ucdavis.edu>
	<oflaf0dvs5qaa5plte2dqed2kkievllpef@4ax.com>
	<858ydmpn0d.fsf@servant.blindglobe.net>
Message-ID: <85smbuo7q2.fsf@servant.blindglobe.net>

rossini at blindglobe.net (A.J. Rossini) writes:

> I like SWIG (well, it facilitates wrappers for Python really well),
> but it's not perfect. 
>
> I've not delved into the difficulties in any detail yet, but we've had
> problems with mixing SWIG and Boost.python for connections with Python
> code -- and the Boost.python mechanism "feels" like DTL's RS<your
> language here> code, where as SWIG doesn't quite have the same flavor.
>
> (sorry for failing on the details, but I'm doing something else
> today).

Argh.  To be clear, this is in the context of C++ systems.  Which is
relevant but completely different.

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From f.duan at yale.edu  Wed Jul 14 18:47:38 2004
From: f.duan at yale.edu (F Duan)
Date: Wed, 14 Jul 2004 12:47:38 -0400
Subject: [R] Is there a statistics that can summarize the correlation for
	more than two random variables?
In-Reply-To: <s0f40884.043@MAIL.NDRI.ORG>
Message-ID: <01LCGAAKB0MO0038KR@biomed.med.yale.edu>

Thank you for your reminding. Could you tell me the addresses of STAT-L and
ALLSTAT lists?

By the way, I found Cronbach's alpha suggested by Prof. Baron might be the
one I am looking for though it's not perfect. 

Frank

-----Original Message-----
From: Peter Flom [mailto:flom at ndri.org] 
Sent: Tuesday, July 13, 2004 16:06
To: r-help at stat.math.ethz.ch; f.duan at yale.edu
Subject: Re: [R] Is there a statistics that can summarize the correlation
formore than two random variables?

This seems more like a STATS question than an R question - asking on a
list like STAT-L or ALLSTAT may result in more replies

Nevertheless, it seems to me that you need to describe (and maybe
decide) what you mean by 'summarize' the correlations.  Certainly the
mean DOES summarize them, but is it the summary you want? Maybe, maybe
not.  Perhaps the median? Or a trimmed mean? Do you want to take the
absolute values of the correlations, or not? 

HTH



Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)


>>> F Duan <f.duan at yale.edu> 07/13/04 2:34 PM >>>
Hi, R people,

 

I wonder if there is a statistics than can measure the correlation for
more
than two random variables, instead of computing the correlation
coefficient
matrix. If so, what R package should I use? 

 

Right now I can only think of the mean of all pair-wise correlation
coefficients, e.g., (corr(x,y) + corr(x,z) + corr(y,z)) / 3 for three
random
variables (x, y, z). 

 

Thanks a lot,

 

Frank


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Marlene.Mueller at gmx.de  Wed Jul 14 18:53:33 2004
From: Marlene.Mueller at gmx.de (Marlene Mueller)
Date: Wed, 14 Jul 2004 18:53:33 +0200 (MEST)
Subject: [R] constrOptim and function with additional parameters?
References: <005f01c469af$fc0fe570$ad133a86@www.domain>
Message-ID: <31211.1089824013@www40.gmx.net>


OK, I got the point why the help refers to the arguments
of 'optim' only. (Of course, I have read this but did'nt
believe it ... ;-))

Thanks to all of you for the clarification and special thanks 
to Duncan Murdoch for the workaround, which is very close to 
what I want. I am doing a lot of constrained regression in the 
moment, so including additional parameters (=the data) is an 
issue for me.

Best regards, Marlene



> This is why the `...' argument is passed to `optim' and not to the
> function being optimized, as it also referred in the help file of
> `constrOptim'
> 
> > constrOptim
> function (theta, f, grad, ui, ci, mu = 1e-04, control = list(),
>     method = if (is.null(grad)) "Nelder-Mead" else "BFGS",
> outer.iterations = 100,
>     outer.eps = 1e-05, ...)
> 
> ...
> 
>  a <- optim(theta.old, fun, gradient, control = control,
>             method = method, ...)
> 
> ...
> }
> 
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Doctoral Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Roger D. Peng" <rpeng at jhsph.edu>
> To: "Duncan Murdoch" <dmurdoch at pair.com>
> Cc: <R-help at stat.math.ethz.ch>; "Marlene Mueller"
> <Marlene.Mueller at gmx.de>
> Sent: Wednesday, July 14, 2004 4:01 PM
> Subject: Re: [R] constrOptim and function with additional parameters?
> 
> 
> > Actually, I think this is a bug.  Take a look at this part of
> constrOptim:
> >
> >  > constrOptim
> > function (theta, f, grad, ui, ci, mu = 1e-04, control = list(),
> >      method = if (is.null(grad)) "Nelder-Mead" else "BFGS",
> > outer.iterations = 10
> > 0,
> >      outer.eps = 1e-05, ...)
> > {
> >      if (!is.null(control$fnscale) && control$fnscale < 0)
> >          mu <- -mu
> >      [...]
> >      obj <- f(theta)
> >      ^^^^^^^^^^^^^^^
> >      r <- R(theta, theta)
> >      for (i in 1:outer.iterations) {
> >          obj.old <- obj
> >          r.old <- r
> >      [...]
> > }
> >
> > So the object function `f' is called on the starting value `theta'
> but
> > the `...' is not passed through.
> >
> > -roger
> >
> > Duncan Murdoch wrote:
> > > On Wed, 14 Jul 2004 14:59:01 +0200 (MEST), "Marlene Mueller"
> > > <Marlene.Mueller at gmx.de> wrote :
> > >
> > >
> > >>How can I use a function with some additional input parameters
> > >>in constrOptim? For example, something like
> > >>
> > >>fr <- function(x,a) {   ## Rosenbrock Banana function
> > >> x1 <- x[1]
> > >> x2 <- x[2]
> > >> a * (x2 - x1 * x1)^2 + (1 - x1)^2
> > >>}
> > >>
> > >>where the optimum is to be found w.r.t. x. Calling
> > >>optim(c(-1.2,1), fr, NULL, a=100) works as expected, but I fail
> > >>to provide the a=100 in the constrained case:
> > >>
> > >>
> > >>> constrOptim(c(-1.2,0.9), fr, NULL, ui=rbind(c(-1,0),c(0,-1)),
> > >>
> > >>ci=c(-1,-1),a=100)
> > >>Error in f(theta) : Argument "a" is missing, with no default
> > >>
> > >>Is this a bug or is there a different solution that I miss here?
> > >
> > >
> > > I can't spot why your use of constrOptim isn't working, but you
> should
> > > be able to workaround it by doing something  like this:
> > >
> > > applyDefaults <- function(fn, ...) {
> > >   function(x) fn(x, ...)
> > > }
> > >
> > > constrOptim(c(-1.2,0.9), applyDefaults(fr, a=100), NULL,
> > > ui=rbind(c(-1,0),c(0,-1)),ci=c(-1,-1))
> > >
> > > The applyDefaults function creates a new function which evaluates
> the
> > > old one with some of the parameters set to fixed values.
> > >
> > > Duncan Murdoch
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From f.duan at yale.edu  Wed Jul 14 18:58:01 2004
From: f.duan at yale.edu (F Duan)
Date: Wed, 14 Jul 2004 12:58:01 -0400
Subject: [R] duplicate row importing issue
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C8@nihexchange20.nih.gov>
Message-ID: <01LCGANFGGK60035X4@biomed.med.yale.edu>

How about you delete the first row (column names) and then use
"header=FALSE" in read.table()?

Frank

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Herman, David
(NIH/NIMH)
Sent: Wednesday, July 14, 2004 11:13
To: 'r-help at stat.math.ethz.ch'
Subject: [R] duplicate row importing issue

Hello,
            I'm simply trying to import a .txt file that has a column of
about 30,000 pts. I found the file, but I'm getting an error:
> m <- read.table(choose.files())
Error in "row.names<-.data.frame"(`*tmp*`, value = row.names) : 
        duplicate row.names are not allowed
 
Any help with getting around this?
 
I really appreciate all the help.
Thanks
dave

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Wed Jul 14 19:03:43 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 14 Jul 2004 17:03:43 +0000 (UTC)
Subject: [R]  reading text file in Windows (was no subject)
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7C6@nihexchange20.nih.gov>
	<20040714153931.ECYB28143.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <loom.20040714T185922-9@post.gmane.org>

John Fox <jfox <at> mcmaster.ca> writes:

> You got several useful suggestions for what you may have done wrong. I often
> find that it's easier to use read.table(file.choose()) and to navigate to
> the file in the resulting dialog than to type the path to the file.

Related to this, you could issue the command exactly as shown without
any arguments at all:

  file.choose()

from the R console, navigate to the correct file and it will return the
correct text representation of the filename to use in your read.table.

For example, below I navigated to the AUTHORS file in the rw1091
R distribution:

   R> file.choose()
   [1] "C:\\Program Files\\R\\rw1091\\AUTHORS"

This should help you decipher whether you got the path wrong, the filename
wrong, etc.



From ramasamy at cancer.org.uk  Wed Jul 14 19:00:49 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 14 Jul 2004 18:00:49 +0100
Subject: [R]  Permutations
In-Reply-To: <BAY15-F20Zuqydb2paw00055d00@hotmail.com>
References: <BAY15-F20Zuqydb2paw00055d00@hotmail.com>
Message-ID: <1089824449.3047.103.camel@vpn202001.lif.icnet.uk>

I think the issue here is in the two keywords - permutations or sample.

AFAIK, permutations should return all admissible (by some rule)
combinations. If this is a large number, as some have pointed out, then
one essentially takes a _sample_ of all admissible combinations. Since
you earlier mentioned that you only want 5-10 outputs, perhaps the
correct term is sampling with restrictions.

There main problem with Robin's method in that all elements within a row
are mutually exclusive to the other. e.g. only one of either 1, 4, 7, 10
can appear in block 1. Furthermore they can only appear in the first
slot of the first block (so no intra-block randomness). This limits the
number of possible outputs.

Can you clearly define the rules (with examples) for an admissible
combination ? They seem to have a different meaning every time I read
the mail. Maybe I am just confused.


On Wed, 2004-07-14 at 17:16, Jordi Altirriba Gutirrez wrote:
>   Dear R users,
>   First of all, thanks to Rolf, Brad, Robin, Erich, Fernando and Adaikalavan 
> for your time and suggestions.
>   Ive been testing some algorithms (sorry for the delay, Im very slow, and 
> Im a completely beginner in Rs world).
>   First, the Robin algorithm.
>   I think that there is a problem because Ive done 200 permutations and 
> Ive found that these permutations are the same:
> 52 and 91, 99 and 110, 121 and 122, 51 and 141, 130 and 134.
>   Thanks again,
> 
> Jordi Altirriba
> Hospital Clinic  Barcelona - Spain
> 
> >x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
> >dim(x) <- c(3,4) a<-matrix(1,200,12)
> >for (i in 1:200)
> + {
> +  jj <- t(apply(x,1,sample))
> + a[i,]<-as.vector(jj)
> + }
> >a
>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
>   [1,]    7    2    3    1   11    6    4    8    9    10     5    12
>   [2,]    1    2    9    7   11    6    4    8   12    10     5     3
>   [3,]    7    2    9    1   11    3    4    5    6    10     8    12
>   [4,]   10    8    6    4    5   12    7    2    9     1    11     3
>   [5,]   10    2   12    1   11    9    7    8    6     4     5     3
>   [6,]    7    8    6    1    5    9    4   11   12    10     2     3
>   [7,]    1    5   12    7    2    6    4    8    9    10    11     3
>   [8,]    1    5    9   10    8    6    4    2    3     7    11    12
>   [9,]    1   11    6    7    2   12    4    5    9    10     8     3
> [10,]    4    5   12   10   11    9    1    8    6     7     2     3
> [11,]    1   11    9    7    5    6    4    8   12    10     2     3
> [12,]    1    8    3    4    2   12   10    5    9     7    11     6
> [13,]    1    2    3    7   11    6   10    5   12     4     8     9
> [14,]    4    8    3   10    5   12    7    2    9     1    11     6
> [15,]   10    2    3    4    8    6    7   11    9     1     5    12
> [16,]    4    8    9   10    2   12    7    5    6     1    11     3
> [17,]    1    2    6   10    5    3    7    8   12     4    11     9
> [18,]   10    2    9    4   11   12    1    5    6     7     8     3
> [19,]    4    8    6    7   11   12    1    2    9    10     5     3
> [20,]    1    8   12    7    2    3   10   11    6     4     5     9
> [21,]   10    2   12    1    5    9    7   11    6     4     8     3
> [22,]    4   11   12    1    2    3   10    8    6     7     5     9
> [23,]    1   11    3    7    2    6   10    5    9     4     8    12
> [24,]    7    2    9   10    5   12    1   11    3     4     8     6
> [25,]    7    8    9    1    2    6    4    5    3    10    11    12
> [26,]    4    5   12   10    2    3    7   11    6     1     8     9
> [27,]    4    5    9    1   11    3    7    8   12    10     2     6
> [28,]    1    5    6    4   11    3    7    8    9    10     2    12
> [29,]    4    5    6    1   11    9   10    2   12     7     8     3
> [30,]    4   11    3    7    8   12   10    5    6     1     2     9
> [31,]   10    2    3    1   11    6    7    8    9     4     5    12
> [32,]   10    2    3    7    8    9    1   11    6     4     5    12
> [33,]    7   11    6    1    8    9    4    5   12    10     2     3
> [34,]    7    5   12    1    8    6    4   11    3    10     2     9
> [35,]    1    2    3    4    8    6    7    5    9    10    11    12
> [36,]    7    8    3    1   11    9   10    2   12     4     5     6
> [37,]   10    2    6    1   11   12    7    5    3     4     8     9
> [38,]    1    5    9    4   11   12    7    8    3    10     2     6
> [39,]    1    2   12    7    5    9   10    8    3     4    11     6
> [40,]    1    8    3   10    2   12    7   11    6     4     5     9
> [41,]    1    2    9    4    8    3   10   11   12     7     5     6
> [42,]    4    5    6    1    2    9   10    8    3     7    11    12
> [43,]    1    2    6    7   11   12   10    5    9     4     8     3
> [44,]    1    2    9   10   11   12    4    8    6     7     5     3
> [45,]   10    5    9    7   11    6    4    2    3     1     8    12
> [46,]    1    2    3    4   11    6    7    5    9    10     8    12
> [47,]    4    2    6    1    8    3   10    5   12     7    11     9
> [48,]    4    8    9    7    2    3    1    5   12    10    11     6
> [49,]   10    8   12    1    2    9    4   11    3     7     5     6
> [50,]   10    8    6    1    2    3    7    5   12     4    11     9
> [51,]    7    2   12   10   11    6    4    8    3     1     5     9
> [52,]    4    5    6    1    2   12   10   11    9     7     8     3
> [53,]    1    2    3    7    5    6    4    8    9    10    11    12
> [54,]   10    5    3    7   11    9    1    8    6     4     2    12
> [55,]    7   11   12    4    2    3   10    8    6     1     5     9
> [56,]    1    5    9    4   11   12   10    8    3     7     2     6
> [57,]    4    5    9    7   11    3   10    2    6     1     8    12
> [58,]   10   11    3    4    5    6    1    8   12     7     2     9
> [59,]    4    8    9   10    5    6    7    2    3     1    11    12
> [60,]    4    2   12    1    8    6   10    5    9     7    11     3
> [61,]    4    8    6    7   11    9   10    5   12     1     2     3
> [62,]    7    8    3   10    5    6    1   11   12     4     2     9
> [63,]   10    5    3    7    8    6    1    2    9     4    11    12
> [64,]   10    2    9    4   11   12    1    5    3     7     8     6
> [65,]    1   11    6    4    8   12    7    2    3    10     5     9
> [66,]    1    5    3    7   11    9    4    2   12    10     8     6
> [67,]    4    2    6    7    5   12   10    8    9     1    11     3
> [68,]    4   11   12   10    2    3    7    8    6     1     5     9
> [69,]    4    5    6   10    2    3    7    8    9     1    11    12
> [70,]    1   11   12   10    2    6    4    5    3     7     8     9
> [71,]   10    5    6    7    8   12    4    2    9     1    11     3
> [72,]   10    8   12    1   11    9    7    5    3     4     2     6
> [73,]   10    8    3    7   11    9    4    5   12     1     2     6
> [74,]    7    2   12    1    5    6    4    8    9    10    11     3
> [75,]    7    2   12   10    8    9    1   11    6     4     5     3
> [76,]    7    2    3    1    5    9    4    8   12    10    11     6
> [77,]    1   11    3   10    5    6    7    2    9     4     8    12
> [78,]    7    2    6   10   11   12    4    8    9     1     5     3
> [79,]   10    8    6    7    5    3    1    2    9     4    11    12
> [80,]   10   11    3    7    2   12    4    8    6     1     5     9
> [81,]   10    5    6    1    8    3    4   11    9     7     2    12
> [82,]    1   11    3    7    5   12   10    2    6     4     8     9
> [83,]    4   11    9   10    5   12    7    2    6     1     8     3
> [84,]    1   11   12    7    8    3    4    2    6    10     5     9
> [85,]   10    2    9    7    5    6    1   11   12     4     8     3
> [86,]    7   11    9    4    5    6   10    2   12     1     8     3
> [87,]    4    5   12    7    2    3   10   11    6     1     8     9
> [88,]    1    2   12    7    5    3   10    8    6     4    11     9
> [89,]    1    8   12    7   11    9   10    2    6     4     5     3
> [90,]    4    5    3   10   11    9    7    2    6     1     8    12
> [91,]    4    5    6    1    2   12   10   11    9     7     8     3
> [92,]   10   11    9    7    5   12    1    2    6     4     8     3
> [93,]    4    2    3    7    8    6    1   11   12    10     5     9
> [94,]    4    5    3   10    2   12    7    8    9     1    11     6
> [95,]    4    8    3   10   11    9    1    2    6     7     5    12
> [96,]    7    5   12   10   11    3    1    8    9     4     2     6
> [97,]    4    2    3    1    8    6    7   11    9    10     5    12
> [98,]    4   11    9    7    5   12   10    8    6     1     2     3
> [99,]    1   11   12    4    5    6    7    8    3    10     2     9
> [100,]    1    8    3    7    5    6   10    2   12     4    11     9
> [101,]    7   11    6    4    8    3    1    2   12    10     5     9
> [102,]    7   11   12    1    2    3   10    8    6     4     5     9
> [103,]    4    5   12    1    2    9    7    8    3    10    11     6
> [104,]   10   11   12    4    8    3    7    5    9     1     2     6
> [105,]   10    5    9    1    2    3    4    8    6     7    11    12
> [106,]   10   11    9    1    2   12    7    8    3     4     5     6
> [107,]   10   11    3    4    8    9    7    5   12     1     2     6
> [108,]    7    2    6    1   11    9    4    5   12    10     8     3
> [109,]    1    8    6    7    2   12   10    5    3     4    11     9
> [110,]    1   11   12    4    5    6    7    8    3    10     2     9
> [111,]    7    8    6    1    5    3   10    2   12     4    11     9
> [112,]    4    8    3    7    5    6    1    2    9    10    11    12
> [113,]    1    2    9    4   11    6    7    5    3    10     8    12
> [114,]    4   11    9    1    8    6    7    2    3    10     5    12
> [115,]   10    8    3    4   11   12    7    2    9     1     5     6
> [116,]    7   11   12    1    2    3    4    8    9    10     5     6
> [117,]    1    5    3   10   11   12    7    8    9     4     2     6
> [118,]    1   11    6    4    2    9   10    5   12     7     8     3
> [119,]   10    2    3    1    5    9    4    8   12     7    11     6
> [120,]    1    2    3    4   11   12    7    8    9    10     5     6
> [121,]    7    8    3    4    5   12   10    2    6     1    11     9
> [122,]    7    8    3    4    5   12   10    2    6     1    11     9
> [123,]    4    5    3   10   11    9    7    8    6     1     2    12
> [124,]    4    5    6    7   11    9    1    8   12    10     2     3
> [125,]   10    8    6    1   11    9    4    2   12     7     5     3
> [126,]   10    8   12    4   11    9    7    2    6     1     5     3
> [127,]    7    8   12    1   11    6   10    5    9     4     2     3
> [128,]    1    8   12   10   11    3    7    5    9     4     2     6
> [129,]    7    8    3   10    2    6    1   11    9     4     5    12
> [130,]    7   11    9    1    2    6   10    8    3     4     5    12
> [131,]   10    2    3    4   11    9    1    5    6     7     8    12
> [132,]    4   11    3    1    5    9   10    2    6     7     8    12
> [133,]   10    2   12    7    8    3    4    5    6     1    11     9
> [134,]    7   11    9    1    2    6   10    8    3     4     5    12
> [135,]    7    8    3    4   11    6   10    2    9     1     5    12
> [136,]   10    8    9    7   11   12    1    2    6     4     5     3
> [137,]   10    8   12    4    5    3    1    2    9     7    11     6
> [138,]    1    2    6   10    8   12    7   11    9     4     5     3
> [139,]    4    5    3    7   11    9    1    2   12    10     8     6
> [140,]    4    5   12    7    8    6   10   11    3     1     2     9
> [141,]    7    2   12   10   11    6    4    8    3     1     5     9
> [142,]   10   11   12    7    2    6    1    5    3     4     8     9
> [143,]    7    2    3   10   11    6    1    8    9     4     5    12
> [144,]    1    2    9   10    5   12    4    8    3     7    11     6
> [145,]    1   11    6    4    8    9    7    5   12    10     2     3
> [146,]    4    5    3   10    2    6    1   11    9     7     8    12
> [147,]    7   11    9    1    2    3   10    8   12     4     5     6
> [148,]    4    2    3    1    5   12    7    8    6    10    11     9
> [149,]   10   11   12    4    8    3    1    2    9     7     5     6
> [150,]    4    8    3   10    5    6    1   11    9     7     2    12
> [151,]    1    8    6   10    5    9    4   11    3     7     2    12
> [152,]    4    8    6    7   11   12   10    5    3     1     2     9
> [153,]    7    2    3   10    5    6    4   11    9     1     8    12
> [154,]   10    5   12    1    8    9    7    2    3     4    11     6
> [155,]    1    8    6    4    2    9   10    5    3     7    11    12
> [156,]   10    2    3    7    5    9    4   11   12     1     8     6
> [157,]   10    5    3    1    2    6    7    8    9     4    11    12
> [158,]    7   11   12    4    5    9   10    8    3     1     2     6
> [159,]    7    5    3    1    8   12   10    2    6     4    11     9
> [160,]    7    2    6    4   11    3    1    5   12    10     8     9
> [161,]    7    5    3    1    2   12    4    8    9    10    11     6
> [162,]    7    8   12    1    5    6   10   11    9     4     2     3
> [163,]   10   11    9    4    8    6    1    2    3     7     5    12
> [164,]    7   11    6    1    5    9    4    2   12    10     8     3
> [165,]    4   11    9   10    8    3    7    2   12     1     5     6
> [166,]    4    2    6   10    8    9    7   11   12     1     5     3
> [167,]    7    5    3   10    2   12    4    8    6     1    11     9
> [168,]    1    8   12    7    2    3    4    5    9    10    11     6
> [169,]    7    8   12    1    5    6    4    2    3    10    11     9
> [170,]    4    5    3    7    8    9    1    2   12    10    11     6
> [171,]    7   11    9    1    8    6    4    2   12    10     5     3
> [172,]   10    8    3    1    2    9    4   11   12     7     5     6
> [173,]   10    5   12    7    8    9    4   11    3     1     2     6
> [174,]   10   11    6    7    5    3    4    8   12     1     2     9
> [175,]    7   11   12    1    2    3   10    8    9     4     5     6
> [176,]    1   11   12    7    2    3    4    8    9    10     5     6
> [177,]   10   11   12    4    5    3    7    8    6     1     2     9
> [178,]   10    5    3    7    2    6    4    8   12     1    11     9
> [179,]    1    5    6    7    2    9   10   11    3     4     8    12
> [180,]    1   11   12   10    5    6    4    2    3     7     8     9
> [181,]    7    2   12    4   11    9    1    5    6    10     8     3
> [182,]   10   11   12    1    5    3    7    8    9     4     2     6
> [183,]    4    8    3    1   11    9    7    2    6    10     5    12
> [184,]    4    8    9    7    2    3   10    5    6     1    11    12
> [185,]   10   11    9    1    5    6    7    2   12     4     8     3
> [186,]   10    5   12    4    8    9    7    2    6     1    11     3
> [187,]    4    2    3    1    8    6    7    5   12    10    11     9
> [188,]   10    2    9    4   11   12    1    8    3     7     5     6
> [189,]   10    2   12    7   11    3    4    5    9     1     8     6
> [190,]    4    5    6    7    8    3   10   11    9     1     2    12
> [191,]   10    5    9    1    2    3    7   11   12     4     8     6
> [192,]    4   11    9    7    2    6   10    5    3     1     8    12
> [193,]   10   11   12    1    2    6    4    5    9     7     8     3
> [194,]   10    2    3    4   11   12    7    5    6     1     8     9
> [195,]    4    2    6    7    8    9    1   11    3    10     5    12
> [196,]   10    2   12    4    8    6    7    5    3     1    11     9
> [197,]    7    5   12    4   11    9    1    2    3    10     8     6
> [198,]   10    5    6    1   11    3    7    2    9     4     8    12
> [199,]    1    2    9    7   11    3    4    8    6    10     5    12
> [200,]    4    8    3    7   11   12    1    2    6    10     5     9
> 
> 
> 
> >From: Robin Hankin <rksh at soc.soton.ac.uk>
> >To: Jordi Altirriba Gutirrez  	<altirriba at hotmail.com>
> >CC: r-help at stat.math.ethz.ch
> >Subject: Re: [R] (no subject) (was: Permutations)
> >Date: Wed, 14 Jul 2004 09:11:48 +0100
> >
> >Jordi
> >
> >try this
> >
> >
> >R> x <- c(1,2,3,  10,11,12,  41,42,43,  81,82,83)
> >R> dim(x) <- c(3,4)
> >R> x
> >      [,1] [,2] [,3] [,4]
> >[1,]    1   10   41   81
> >[2,]    2   11   42   82
> >[3,]    3   12   43   83
> >R>  jj <- t(apply(x,1,sample))
> >R> jj
> >      [,1] [,2] [,3] [,4]
> >[1,]    1   41   10   81
> >[2,]    2   11   82   42
> >[3,]   12    3   43   83
> >R> as.vector(jj)
> >R>
> >    [1]  1 2 12 41 11 3 10 82 43 81 42 83
> >
> >
> >
> >
> >and I think that does what you want...
> >
> >We take the vector, rearrange it into a matrix with three rows, then sample 
> >*within* the rows,
> >then rearrange into a vector again.
> >
> >There will be one forbidden permutation, namely the identity (which may or 
> >may not be
> >desirable).
> >
> >This method doesn't allow "intra block" permutations.
> >
> >best
> >
> >rksh
> >
> >
> >
> >>  Dear R users,
> >>  First of all, thanks for the incredibly fast answers and help of Rolf, 
> >>Marc and Robert.
> >>  Yes, I noticed that it was a lot of permutacions, but my intention was 
> >>to make this process automatic and take only 5.000 - 10.000 permutations. 
> >>Therefore, I wanted only to take that "interesting permutations" with 
> >>"some information" [inter-block permutations].
> >>  The reason why I'm interested in these permutations is because I'm using 
> >>some packages of Bioconductor to analyse my data from some microarrays and 
> >>I thought that perhaps could be interesting to see what happens when I 
> >>permute my data and I compare it against the not permuted data.
> >>  Thanks again for your time and suggestions.
> >>
> >>Jordi Altirriba
> >>Ph. D. Student
> >>
> >>Hospital Clinic-Barcelona-Spain
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
> >
> >
> >--
> >Robin Hankin
> >Uncertainty Analyst
> >Southampton Oceanography Centre
> >SO14 3ZH
> >tel +44(0)23-8059-7743
> >initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Wed Jul 14 19:09:06 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 14 Jul 2004 18:09:06 +0100
Subject: [R] Is there a statistics that can summarize the correlation
	for more than two random variables?
In-Reply-To: <01LCGAAKB0MO0038KR@biomed.med.yale.edu>
References: <01LCGAAKB0MO0038KR@biomed.med.yale.edu>
Message-ID: <1089824945.3047.106.camel@vpn202001.lif.icnet.uk>

http://www.jiscmail.ac.uk/lists/ALLSTAT.html


On Wed, 2004-07-14 at 17:47, F Duan wrote:
> Thank you for your reminding. Could you tell me the addresses of STAT-L and
> ALLSTAT lists?
> 
> By the way, I found Cronbach's alpha suggested by Prof. Baron might be the
> one I am looking for though it's not perfect. 
> 
> Frank
> 
> -----Original Message-----
> From: Peter Flom [mailto:flom at ndri.org] 
> Sent: Tuesday, July 13, 2004 16:06
> To: r-help at stat.math.ethz.ch; f.duan at yale.edu
> Subject: Re: [R] Is there a statistics that can summarize the correlation
> formore than two random variables?
> 
> This seems more like a STATS question than an R question - asking on a
> list like STAT-L or ALLSTAT may result in more replies
> 
> Nevertheless, it seems to me that you need to describe (and maybe
> decide) what you mean by 'summarize' the correlations.  Certainly the
> mean DOES summarize them, but is it the summary you want? Maybe, maybe
> not.  Perhaps the median? Or a trimmed mean? Do you want to take the
> absolute values of the correlations, or not? 
> 
> HTH
> 
> 
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> 
> >>> F Duan <f.duan at yale.edu> 07/13/04 2:34 PM >>>
> Hi, R people,
> 
>  
> 
> I wonder if there is a statistics than can measure the correlation for
> more
> than two random variables, instead of computing the correlation
> coefficient
> matrix. If so, what R package should I use? 
> 
>  
> 
> Right now I can only think of the mean of all pair-wise correlation
> coefficients, e.g., (corr(x,y) + corr(x,z) + corr(y,z)) / 3 for three
> random
> variables (x, y, z). 
> 
>  
> 
> Thanks a lot,
> 
>  
> 
> Frank
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From maechler at stat.math.ethz.ch  Wed Jul 14 19:15:42 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Jul 2004 19:15:42 +0200
Subject: [R] Convex smoothing via 'Iterative Convex Minorant' ?
Message-ID: <16629.27198.599723.446157@gargle.gargle.HOWL>

I've been asked, and interested myself:

Has anybody implemented the above in R or another S language dialect?

We are talking about the algorithms / methodology
by Wellner, Groeneboom and Jongbloed, e.g., from the following article

@Article{Jongbloed:1998:ICM,
  author =       "Geurt Jongbloed",
  title =        "The Iterative Convex Minorant Algorithm for
                 Nonparametric Estimation",
  journal =      j-J-COMPUT-GRAPH-STAT,
  volume =       "7",
  number =       "3",
  pages =        "310--321",
  month =        sep,
  year =         "1998",
  CODEN =        "????",
  ISSN =         "1061-8600",
  MRclass =      "62G05",
  MRnumber =     "1 646 718",
  bibdate =      "Sat Jan 2 17:33:21 MST 1999",
  URL =          "http://www.amstat.org/publications/jcgs/abstracts98/jongbloed.html",
  acknowledgement = ack-nhfb,
}

------

I know about Roger Koenker and Pin Ng's very interesting "nprq"
package (and its earlier version "cobs") where one can fit splines
with convexity constraints. 

At the moment however, we are specifically interested in the ICM
algorithm for convex nonparametric regression.

Thank you for pointers in advance.
Martin Maechler, ETH Zurich



From andy_liaw at merck.com  Wed Jul 14 19:19:42 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 14 Jul 2004 13:19:42 -0400
Subject: [R] duplicate row importing issue
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8042@usrymx25.merck.com>

Or just read.table(..., header=FALSE, skip=1)

Andy

> From:  F Duan
> 
> How about you delete the first row (column names) and then use
> "header=FALSE" in read.table()?
> 
> Frank
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Herman, David
> (NIH/NIMH)
> Sent: Wednesday, July 14, 2004 11:13
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] duplicate row importing issue
> 
> Hello,
>             I'm simply trying to import a .txt file that has 
> a column of
> about 30,000 pts. I found the file, but I'm getting an error:
> > m <- read.table(choose.files())
> Error in "row.names<-.data.frame"(`*tmp*`, value = row.names) : 
>         duplicate row.names are not allowed
>  
> Any help with getting around this?
>  
> I really appreciate all the help.
> Thanks
> dave
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From altirriba at hotmail.com  Wed Jul 14 19:42:49 2004
From: altirriba at hotmail.com (=?iso-8859-1?B?Sm9yZGkgQWx0aXJyaWJhIEd1dGnpcnJleg==?=)
Date: Wed, 14 Jul 2004 19:42:49 +0200
Subject: [R] Permutations
Message-ID: <BAY15-F3FD4LXfKCzxg00042002@hotmail.com>

Dear Adaikalavan,
  Now I've send a similar e-mail to Robin and Rolf, therefore I can deduce 
that my first e-mail was not enough clear (sorry).
  Therefore, I'm going to try it again with an explanation of why I don't 
want those permutations:

I?ve 12 elements in blocks of 3 elements and I want only to make 
permutations inter-blocks (no intra-blocks) (sorry if the terminology is not 
accurate), something similar to:

1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   YES-------1st permutation

1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
permutation of permutation 1
   -  -
3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
permutation of permutation 1
-  -  -
1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation

4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation

4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
permutation of permutation 3
           -  -
10 1 7 | 4 8 7 | 5 6 12 | 3 2 9    YES---Xth permutation

1 10 7 | 4 8 7 | 5 6 12 | 3 2 9    NO ----because it's an 
"intra-block"permutation of permutation X
-   -

So, what is a "not correct" permutation is an "intra-block" permutation of a 
permutation created before.

Again, thanks for your time and suggestions,


Jordi Altirriba
PhD student
Hospital Clinic - Barcelona - Spain

P.S. Probably (it's the way of how I'm testing the algorithms now with 
Excel) [sorry if it's stupid], could be interesting something similar to:

1 2 3 | 4 5 6 | 7 8 9 | 10 11 12 ---> 1*2*3=6 | 4*5*6=120 | 7*8*9=504 | 
10*11*12=1320

1 3 2 | 4 5 6 | 7 8 9 | 10 11 12 ---> 1*3*2=6 | 4*5*6=120 | 7*8*9=504 | 
10*11*12=1320

4 5 6 | 1 2 3 | 7 8 9 | 10 11 12 ---> 4*5*6=120 | 1*2*3=6 | 7*8*9=504 | 
10*11*12=1320


Results:
permutation1: 6 | 120 | 504 | 1320
permutation2: 6 | 120 | 504 | 1320
permutation3: 120 | 6 | 504 | 1320

Order the permutations according first to the first parameter, second to the 
second...and to the fourth.

In this case it's the same:
permutation1: 6 | 120 | 504 | 1320
permutation2: 6 | 120 | 504 | 1320
permutation3: 120 | 6 | 504 | 1320

Therefore, if the first, second, third and fourth parameter of a 
permutations have the same value that the next permutation it's because 
there is an "intra-block" permutation. So, permutation 2 is an "intra-block" 
permutation of permutation 1.


P.S. Sorry for having forgotten the title of the last e-mail



>From: Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
>To: Jordi Altirriba Guti??rrez <altirriba at hotmail.com>
>CC: rksh at soc.soton.ac.uk, R-help <r-help at stat.math.ethz.ch>
>Subject: Re: [R]  Permutations
>Date: Wed, 14 Jul 2004 18:00:49 +0100
>
>I think the issue here is in the two keywords - permutations or sample.
>
>AFAIK, permutations should return all admissible (by some rule)
>combinations. If this is a large number, as some have pointed out, then
>one essentially takes a _sample_ of all admissible combinations. Since
>you earlier mentioned that you only want 5-10 outputs, perhaps the
>correct term is sampling with restrictions.
>
>There main problem with Robin's method in that all elements within a row
>are mutually exclusive to the other. e.g. only one of either 1, 4, 7, 10
>can appear in block 1. Furthermore they can only appear in the first
>slot of the first block (so no intra-block randomness). This limits the
>number of possible outputs.
>
>Can you clearly define the rules (with examples) for an admissible
>combination ? They seem to have a different meaning every time I read
>the mail. Maybe I am just confused.
>
>
>On Wed, 2004-07-14 at 17:16, Jordi Altirriba Guti????rrez wrote:
> >   Dear R users,
> >   First of all, thanks to Rolf, Brad, Robin, Erich, Fernando and 
>Adaikalavan
> > for your time and suggestions.
> >   Ive been testing some algorithms (sorry for the delay, Im very slow, 
>and
> > Im a completely beginner in Rs world).
> >   First, the Robin algorithm.
> >   I think that there is a problem because Ive done 200 permutations and
> > Ive found that these permutations are the same:
> > 52 and 91, 99 and 110, 121 and 122, 51 and 141, 130 and 134.
> >   Thanks again,
> >
> > Jordi Altirriba
> > Hospital Clinic  Barcelona - Spain
> >
> > >x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
> > >dim(x) <- c(3,4) a<-matrix(1,200,12)
> > >for (i in 1:200)
> > + {
> > +  jj <- t(apply(x,1,sample))
> > + a[i,]<-as.vector(jj)
> > + }
> > >a
> >        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
> >   [1,]    7    2    3    1   11    6    4    8    9    10     5    12
> >   [2,]    1    2    9    7   11    6    4    8   12    10     5     3
> >   [3,]    7    2    9    1   11    3    4    5    6    10     8    12
> >   [4,]   10    8    6    4    5   12    7    2    9     1    11     3
> >   [5,]   10    2   12    1   11    9    7    8    6     4     5     3
> >   [6,]    7    8    6    1    5    9    4   11   12    10     2     3
> >   [7,]    1    5   12    7    2    6    4    8    9    10    11     3
> >   [8,]    1    5    9   10    8    6    4    2    3     7    11    12
> >   [9,]    1   11    6    7    2   12    4    5    9    10     8     3
> > [10,]    4    5   12   10   11    9    1    8    6     7     2     3
> > [11,]    1   11    9    7    5    6    4    8   12    10     2     3
> > [12,]    1    8    3    4    2   12   10    5    9     7    11     6
> > [13,]    1    2    3    7   11    6   10    5   12     4     8     9
> > [14,]    4    8    3   10    5   12    7    2    9     1    11     6
> > [15,]   10    2    3    4    8    6    7   11    9     1     5    12
> > [16,]    4    8    9   10    2   12    7    5    6     1    11     3
> > [17,]    1    2    6   10    5    3    7    8   12     4    11     9
> > [18,]   10    2    9    4   11   12    1    5    6     7     8     3
> > [19,]    4    8    6    7   11   12    1    2    9    10     5     3
> > [20,]    1    8   12    7    2    3   10   11    6     4     5     9
> > [21,]   10    2   12    1    5    9    7   11    6     4     8     3
> > [22,]    4   11   12    1    2    3   10    8    6     7     5     9
> > [23,]    1   11    3    7    2    6   10    5    9     4     8    12
> > [24,]    7    2    9   10    5   12    1   11    3     4     8     6
> > [25,]    7    8    9    1    2    6    4    5    3    10    11    12
> > [26,]    4    5   12   10    2    3    7   11    6     1     8     9
> > [27,]    4    5    9    1   11    3    7    8   12    10     2     6
> > [28,]    1    5    6    4   11    3    7    8    9    10     2    12
> > [29,]    4    5    6    1   11    9   10    2   12     7     8     3
> > [30,]    4   11    3    7    8   12   10    5    6     1     2     9
> > [31,]   10    2    3    1   11    6    7    8    9     4     5    12
> > [32,]   10    2    3    7    8    9    1   11    6     4     5    12
> > [33,]    7   11    6    1    8    9    4    5   12    10     2     3
> > [34,]    7    5   12    1    8    6    4   11    3    10     2     9
> > [35,]    1    2    3    4    8    6    7    5    9    10    11    12
> > [36,]    7    8    3    1   11    9   10    2   12     4     5     6
> > [37,]   10    2    6    1   11   12    7    5    3     4     8     9
> > [38,]    1    5    9    4   11   12    7    8    3    10     2     6
> > [39,]    1    2   12    7    5    9   10    8    3     4    11     6
> > [40,]    1    8    3   10    2   12    7   11    6     4     5     9
> > [41,]    1    2    9    4    8    3   10   11   12     7     5     6
> > [42,]    4    5    6    1    2    9   10    8    3     7    11    12
> > [43,]    1    2    6    7   11   12   10    5    9     4     8     3
> > [44,]    1    2    9   10   11   12    4    8    6     7     5     3
> > [45,]   10    5    9    7   11    6    4    2    3     1     8    12
> > [46,]    1    2    3    4   11    6    7    5    9    10     8    12
> > [47,]    4    2    6    1    8    3   10    5   12     7    11     9
> > [48,]    4    8    9    7    2    3    1    5   12    10    11     6
> > [49,]   10    8   12    1    2    9    4   11    3     7     5     6
> > [50,]   10    8    6    1    2    3    7    5   12     4    11     9
> > [51,]    7    2   12   10   11    6    4    8    3     1     5     9
> > [52,]    4    5    6    1    2   12   10   11    9     7     8     3
> > [53,]    1    2    3    7    5    6    4    8    9    10    11    12
> > [54,]   10    5    3    7   11    9    1    8    6     4     2    12
> > [55,]    7   11   12    4    2    3   10    8    6     1     5     9
> > [56,]    1    5    9    4   11   12   10    8    3     7     2     6
> > [57,]    4    5    9    7   11    3   10    2    6     1     8    12
> > [58,]   10   11    3    4    5    6    1    8   12     7     2     9
> > [59,]    4    8    9   10    5    6    7    2    3     1    11    12
> > [60,]    4    2   12    1    8    6   10    5    9     7    11     3
> > [61,]    4    8    6    7   11    9   10    5   12     1     2     3
> > [62,]    7    8    3   10    5    6    1   11   12     4     2     9
> > [63,]   10    5    3    7    8    6    1    2    9     4    11    12
> > [64,]   10    2    9    4   11   12    1    5    3     7     8     6
> > [65,]    1   11    6    4    8   12    7    2    3    10     5     9
> > [66,]    1    5    3    7   11    9    4    2   12    10     8     6
> > [67,]    4    2    6    7    5   12   10    8    9     1    11     3
> > [68,]    4   11   12   10    2    3    7    8    6     1     5     9
> > [69,]    4    5    6   10    2    3    7    8    9     1    11    12
> > [70,]    1   11   12   10    2    6    4    5    3     7     8     9
> > [71,]   10    5    6    7    8   12    4    2    9     1    11     3
> > [72,]   10    8   12    1   11    9    7    5    3     4     2     6
> > [73,]   10    8    3    7   11    9    4    5   12     1     2     6
> > [74,]    7    2   12    1    5    6    4    8    9    10    11     3
> > [75,]    7    2   12   10    8    9    1   11    6     4     5     3
> > [76,]    7    2    3    1    5    9    4    8   12    10    11     6
> > [77,]    1   11    3   10    5    6    7    2    9     4     8    12
> > [78,]    7    2    6   10   11   12    4    8    9     1     5     3
> > [79,]   10    8    6    7    5    3    1    2    9     4    11    12
> > [80,]   10   11    3    7    2   12    4    8    6     1     5     9
> > [81,]   10    5    6    1    8    3    4   11    9     7     2    12
> > [82,]    1   11    3    7    5   12   10    2    6     4     8     9
> > [83,]    4   11    9   10    5   12    7    2    6     1     8     3
> > [84,]    1   11   12    7    8    3    4    2    6    10     5     9
> > [85,]   10    2    9    7    5    6    1   11   12     4     8     3
> > [86,]    7   11    9    4    5    6   10    2   12     1     8     3
> > [87,]    4    5   12    7    2    3   10   11    6     1     8     9
> > [88,]    1    2   12    7    5    3   10    8    6     4    11     9
> > [89,]    1    8   12    7   11    9   10    2    6     4     5     3
> > [90,]    4    5    3   10   11    9    7    2    6     1     8    12
> > [91,]    4    5    6    1    2   12   10   11    9     7     8     3
> > [92,]   10   11    9    7    5   12    1    2    6     4     8     3
> > [93,]    4    2    3    7    8    6    1   11   12    10     5     9
> > [94,]    4    5    3   10    2   12    7    8    9     1    11     6
> > [95,]    4    8    3   10   11    9    1    2    6     7     5    12
> > [96,]    7    5   12   10   11    3    1    8    9     4     2     6
> > [97,]    4    2    3    1    8    6    7   11    9    10     5    12
> > [98,]    4   11    9    7    5   12   10    8    6     1     2     3
> > [99,]    1   11   12    4    5    6    7    8    3    10     2     9
> > [100,]    1    8    3    7    5    6   10    2   12     4    11     9
> > [101,]    7   11    6    4    8    3    1    2   12    10     5     9
> > [102,]    7   11   12    1    2    3   10    8    6     4     5     9
> > [103,]    4    5   12    1    2    9    7    8    3    10    11     6
> > [104,]   10   11   12    4    8    3    7    5    9     1     2     6
> > [105,]   10    5    9    1    2    3    4    8    6     7    11    12
> > [106,]   10   11    9    1    2   12    7    8    3     4     5     6
> > [107,]   10   11    3    4    8    9    7    5   12     1     2     6
> > [108,]    7    2    6    1   11    9    4    5   12    10     8     3
> > [109,]    1    8    6    7    2   12   10    5    3     4    11     9
> > [110,]    1   11   12    4    5    6    7    8    3    10     2     9
> > [111,]    7    8    6    1    5    3   10    2   12     4    11     9
> > [112,]    4    8    3    7    5    6    1    2    9    10    11    12
> > [113,]    1    2    9    4   11    6    7    5    3    10     8    12
> > [114,]    4   11    9    1    8    6    7    2    3    10     5    12
> > [115,]   10    8    3    4   11   12    7    2    9     1     5     6
> > [116,]    7   11   12    1    2    3    4    8    9    10     5     6
> > [117,]    1    5    3   10   11   12    7    8    9     4     2     6
> > [118,]    1   11    6    4    2    9   10    5   12     7     8     3
> > [119,]   10    2    3    1    5    9    4    8   12     7    11     6
> > [120,]    1    2    3    4   11   12    7    8    9    10     5     6
> > [121,]    7    8    3    4    5   12   10    2    6     1    11     9
> > [122,]    7    8    3    4    5   12   10    2    6     1    11     9
> > [123,]    4    5    3   10   11    9    7    8    6     1     2    12
> > [124,]    4    5    6    7   11    9    1    8   12    10     2     3
> > [125,]   10    8    6    1   11    9    4    2   12     7     5     3
> > [126,]   10    8   12    4   11    9    7    2    6     1     5     3
> > [127,]    7    8   12    1   11    6   10    5    9     4     2     3
> > [128,]    1    8   12   10   11    3    7    5    9     4     2     6
> > [129,]    7    8    3   10    2    6    1   11    9     4     5    12
> > [130,]    7   11    9    1    2    6   10    8    3     4     5    12
> > [131,]   10    2    3    4   11    9    1    5    6     7     8    12
> > [132,]    4   11    3    1    5    9   10    2    6     7     8    12
> > [133,]   10    2   12    7    8    3    4    5    6     1    11     9
> > [134,]    7   11    9    1    2    6   10    8    3     4     5    12
> > [135,]    7    8    3    4   11    6   10    2    9     1     5    12
> > [136,]   10    8    9    7   11   12    1    2    6     4     5     3
> > [137,]   10    8   12    4    5    3    1    2    9     7    11     6
> > [138,]    1    2    6   10    8   12    7   11    9     4     5     3
> > [139,]    4    5    3    7   11    9    1    2   12    10     8     6
> > [140,]    4    5   12    7    8    6   10   11    3     1     2     9
> > [141,]    7    2   12   10   11    6    4    8    3     1     5     9
> > [142,]   10   11   12    7    2    6    1    5    3     4     8     9
> > [143,]    7    2    3   10   11    6    1    8    9     4     5    12
> > [144,]    1    2    9   10    5   12    4    8    3     7    11     6
> > [145,]    1   11    6    4    8    9    7    5   12    10     2     3
> > [146,]    4    5    3   10    2    6    1   11    9     7     8    12
> > [147,]    7   11    9    1    2    3   10    8   12     4     5     6
> > [148,]    4    2    3    1    5   12    7    8    6    10    11     9
> > [149,]   10   11   12    4    8    3    1    2    9     7     5     6
> > [150,]    4    8    3   10    5    6    1   11    9     7     2    12
> > [151,]    1    8    6   10    5    9    4   11    3     7     2    12
> > [152,]    4    8    6    7   11   12   10    5    3     1     2     9
> > [153,]    7    2    3   10    5    6    4   11    9     1     8    12
> > [154,]   10    5   12    1    8    9    7    2    3     4    11     6
> > [155,]    1    8    6    4    2    9   10    5    3     7    11    12
> > [156,]   10    2    3    7    5    9    4   11   12     1     8     6
> > [157,]   10    5    3    1    2    6    7    8    9     4    11    12
> > [158,]    7   11   12    4    5    9   10    8    3     1     2     6
> > [159,]    7    5    3    1    8   12   10    2    6     4    11     9
> > [160,]    7    2    6    4   11    3    1    5   12    10     8     9
> > [161,]    7    5    3    1    2   12    4    8    9    10    11     6
> > [162,]    7    8   12    1    5    6   10   11    9     4     2     3
> > [163,]   10   11    9    4    8    6    1    2    3     7     5    12
> > [164,]    7   11    6    1    5    9    4    2   12    10     8     3
> > [165,]    4   11    9   10    8    3    7    2   12     1     5     6
> > [166,]    4    2    6   10    8    9    7   11   12     1     5     3
> > [167,]    7    5    3   10    2   12    4    8    6     1    11     9
> > [168,]    1    8   12    7    2    3    4    5    9    10    11     6
> > [169,]    7    8   12    1    5    6    4    2    3    10    11     9
> > [170,]    4    5    3    7    8    9    1    2   12    10    11     6
> > [171,]    7   11    9    1    8    6    4    2   12    10     5     3
> > [172,]   10    8    3    1    2    9    4   11   12     7     5     6
> > [173,]   10    5   12    7    8    9    4   11    3     1     2     6
> > [174,]   10   11    6    7    5    3    4    8   12     1     2     9
> > [175,]    7   11   12    1    2    3   10    8    9     4     5     6
> > [176,]    1   11   12    7    2    3    4    8    9    10     5     6
> > [177,]   10   11   12    4    5    3    7    8    6     1     2     9
> > [178,]   10    5    3    7    2    6    4    8   12     1    11     9
> > [179,]    1    5    6    7    2    9   10   11    3     4     8    12
> > [180,]    1   11   12   10    5    6    4    2    3     7     8     9
> > [181,]    7    2   12    4   11    9    1    5    6    10     8     3
> > [182,]   10   11   12    1    5    3    7    8    9     4     2     6
> > [183,]    4    8    3    1   11    9    7    2    6    10     5    12
> > [184,]    4    8    9    7    2    3   10    5    6     1    11    12
> > [185,]   10   11    9    1    5    6    7    2   12     4     8     3
> > [186,]   10    5   12    4    8    9    7    2    6     1    11     3
> > [187,]    4    2    3    1    8    6    7    5   12    10    11     9
> > [188,]   10    2    9    4   11   12    1    8    3     7     5     6
> > [189,]   10    2   12    7   11    3    4    5    9     1     8     6
> > [190,]    4    5    6    7    8    3   10   11    9     1     2    12
> > [191,]   10    5    9    1    2    3    7   11   12     4     8     6
> > [192,]    4   11    9    7    2    6   10    5    3     1     8    12
> > [193,]   10   11   12    1    2    6    4    5    9     7     8     3
> > [194,]   10    2    3    4   11   12    7    5    6     1     8     9
> > [195,]    4    2    6    7    8    9    1   11    3    10     5    12
> > [196,]   10    2   12    4    8    6    7    5    3     1    11     9
> > [197,]    7    5   12    4   11    9    1    2    3    10     8     6
> > [198,]   10    5    6    1   11    3    7    2    9     4     8    12
> > [199,]    1    2    9    7   11    3    4    8    6    10     5    12
> > [200,]    4    8    3    7   11   12    1    2    6    10     5     9
> >
> >
> >
> > >From: Robin Hankin <rksh at soc.soton.ac.uk>
> > >To: Jordi Altirriba Guti????rrez  	<altirriba at hotmail.com>
> > >CC: r-help at stat.math.ethz.ch
> > >Subject: Re: [R] (no subject) (was: Permutations)
> > >Date: Wed, 14 Jul 2004 09:11:48 +0100
> > >
> > >Jordi
> > >
> > >try this
> > >
> > >
> > >R> x <- c(1,2,3,  10,11,12,  41,42,43,  81,82,83)
> > >R> dim(x) <- c(3,4)
> > >R> x
> > >      [,1] [,2] [,3] [,4]
> > >[1,]    1   10   41   81
> > >[2,]    2   11   42   82
> > >[3,]    3   12   43   83
> > >R>  jj <- t(apply(x,1,sample))
> > >R> jj
> > >      [,1] [,2] [,3] [,4]
> > >[1,]    1   41   10   81
> > >[2,]    2   11   82   42
> > >[3,]   12    3   43   83
> > >R> as.vector(jj)
> > >R>
> > >    [1]  1 2 12 41 11 3 10 82 43 81 42 83
> > >
> > >
> > >
> > >
> > >and I think that does what you want...
> > >
> > >We take the vector, rearrange it into a matrix with three rows, then 
>sample
> > >*within* the rows,
> > >then rearrange into a vector again.
> > >
> > >There will be one forbidden permutation, namely the identity (which may 
>or
> > >may not be
> > >desirable).
> > >
> > >This method doesn't allow "intra block" permutations.
> > >
> > >best
> > >
> > >rksh
> > >
> > >
> > >
> > >>  Dear R users,
> > >>  First of all, thanks for the incredibly fast answers and help of 
>Rolf,
> > >>Marc and Robert.
> > >>  Yes, I noticed that it was a lot of permutacions, but my intention 
>was
> > >>to make this process automatic and take only 5.000 - 10.000 
>permutations.
> > >>Therefore, I wanted only to take that "interesting permutations" with
> > >>"some information" [inter-block permutations].
> > >>  The reason why I'm interested in these permutations is because I'm 
>using
> > >>some packages of Bioconductor to analyse my data from some microarrays 
>and
> > >>I thought that perhaps could be interesting to see what happens when I
> > >>permute my data and I compare it against the not permuted data.
> > >>  Thanks again for your time and suggestions.
> > >>
> > >>Jordi Altirriba
> > >>Ph. D. Student
> > >>
> > >>Hospital Clinic-Barcelona-Spain
> > >>
> > >>______________________________________________
> > >>R-help at stat.math.ethz.ch mailing list
> > >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >>PLEASE do read the posting guide!
> > >>http://www.R-project.org/posting-guide.html
> > >
> > >
> > >--
> > >Robin Hankin
> > >Uncertainty Analyst
> > >Southampton Oceanography Centre
> > >SO14 3ZH
> > >tel +44(0)23-8059-7743
> > >initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam 
>precaution)
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
> >
>



From MSchwartz at MedAnalytics.com  Wed Jul 14 20:49:30 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 14 Jul 2004 13:49:30 -0500
Subject: [R] Permutations
In-Reply-To: <200407141306.i6ED6feX013295@erdos.math.unb.ca>
References: <200407141306.i6ED6feX013295@erdos.math.unb.ca>
Message-ID: <1089830970.28515.131.camel@localhost.localdomain>

On Wed, 2004-07-14 at 08:06, Rolf Turner wrote:
> In respect of generating random ``restricted'' permutations, it
> occurred to me as I was driving home last night .... If one is going
> to invoke some kind of ``try again if it doesn't work procedure''
> then one might as well keep it simple:  Essentially use the rejection
> method.  Just generate a random permutation, and then check whether
> it meets the restriction criterion.   If yes, return that
> permutation, if not, throw it away and try again.
> 
> This will definitely (???) genererate a genuinely random restricted
> permutation.  I figured that since a very large fraction of permutations
> are acutally restricted permutions one wouldn't reject much of the
> time, and so the rejection method should be pretty efficient.
> 
> I wrote the following code to do the work:
> 
> restr.perm2 <- function () {
> #
> okay <- function (x) {
> 	m1 <- cbind(1:12,rep(1:4,rep(3,4)))
> 	m2 <- m1[x,]
> 	all((m2[,1] == m1[,1]) | (m2[,2] != m1[,2]))
> }
> #
> repeat{
> 	x <- sample(12,12)
> 	if(okay(x)) return(x)
> }
> }
> 
> I'm bothered again, but:  I did a little test to see how many tries
> it would take on average.  On 1000 attempts I got a mean of 8.44
> tries, with a standard deviation of 7.7610 (standard error of the
> mean = 0.2454).  The value of 7.76 is roughly consistent with
> sqrt(1-p.hat)/p.hat = 7.92 that one gets from the geometric
> distribution.
> 
> This would indicate that the fraction of ``restricted'' permutations
> is something like p.hat = 1/8.44 = 0.1184834.  Which is a lot less
> than the rough estimate of (4.7 x 10^6)/12! approx. = 0.9853 from
> Robert Baskin's back-of-the-envelope calculations.
> 
> What's going on/wrong?


Rolf,

I have not quite figured out what the issues are, but I took your
approach above and combined it with Gabor's f1a() function that was the
result of the recent thread on matching/counting rows between matrices
and came up with the following. The basic concept is that we know (or
think that we know) what the non-allowable set of intra-block
permutations are:

  # Create non-allowable 'intra-block' permutations
  # Need a generalizable way to do this, but
  # good enough for now
  a <- permutations(3, 3, 1:3)
  b <- permutations(3, 3, 4:6)
  c <- permutations(3, 3, 7:9)
  d <- permutations(3, 3, 10:12)
  intra <- rbind(a[-1, ], b[-1, ], c[-1, ], d[-1, ])

'intra' looks like:

> intra
      [,1] [,2] [,3]
 [1,]    1    3    2
 [2,]    2    1    3
 [3,]    2    3    1
 [4,]    3    1    2
 [5,]    3    2    1
 [6,]    4    6    5
 [7,]    5    4    6
 [8,]    5    6    4
 [9,]    6    4    5
[10,]    6    5    4
[11,]    7    9    8
[12,]    8    7    9
[13,]    8    9    7
[14,]    9    7    8
[15,]    9    8    7
[16,]   10   12   11
[17,]   11   10   12
[18,]   11   12   10
[19,]   12   10   11
[20,]   12   11   10


With that in place, we can then take the randomly generated 'x', coerce
it into a 3 column matrix by row and use Gabor's function to check for
any matches of the rows of 3 in 'x' with the non-allowable permutations
in 'intra'. 

Thus, the function will assign 'x' to the appropriate row in 'results'
(which is pre-allocated based upon the number of runs) if 'x' passes or
sets the row to NA's if it does not. 

I then use complete.cases() to return only the valid rows. Presumably,
some of the randomly generated 'x' vectors could be duplicates, so I
also use unique():

restr.perm3 <- function(runs)
{
  results <- matrix(numeric(runs * 12), ncol = 12)

  # use Gabor's function to check for row matches
  # between 'x' and 'intra' to filter out in okay()
  f1a <- function(a,b,sep=":")
  {
    f <- function(...) paste(..., sep=sep)
    a2 <- do.call("f", as.data.frame(a))
    b2 <- do.call("f", as.data.frame(b))
    c(table(c(b2,unique(a2)))[a2] - 1)
  }

  okay <- function (x)
  {
    x.match <- matrix(x, ncol = 3, byrow = TRUE)
    all(f1a(x.match, intra) == 0)
  }

  for (i in 1:runs)
  {
    x <- sample(12,12)
    if (okay(x))
      results[i, ] <- x
    else
      results[i, ] <- rep(NA, 12)
  }

  unique(results[complete.cases(results), ])
}


So, with all that in place, we can then do something like the following:

r <- replicate(10, restr.perm3(1000))

> str(r)
List of 10
 $ : num [1:934, 1:12] 10 6 8 7 7 11 1 1 8 4 ...
 $ : num [1:944, 1:12] 7 4 4 11 1 11 8 3 3 9 ...
 $ : num [1:953, 1:12] 8 4 11 1 11 6 7 11 9 10 ...
 $ : num [1:951, 1:12] 1 2 1 4 4 10 8 10 3 12 ...
 $ : num [1:949, 1:12] 1 7 11 9 2 2 11 7 11 4 ...
 $ : num [1:937, 1:12] 3 3 11 10 4 8 12 10 3 2 ...
 $ : num [1:952, 1:12] 7 3 1 6 4 4 4 11 2 8 ...
 $ : num [1:946, 1:12] 1 9 3 10 11 6 1 7 8 11 ...
 $ : num [1:945, 1:12] 8 9 1 2 8 3 4 1 7 11 ...
 $ : num [1:933, 1:12] 9 1 12 3 4 1 10 1 1 8 ...


So the above would suggest that indeed, the restricted permutations are
a fairly high proportion of the total.

I went ahead and did the following 50 replicates of 1000 each:

> system.time(r <- replicate(50, restr.perm3(1000)))
[1] 91.20  0.06 92.98  0.00  0.00

> mean(unlist(lapply(r, nrow)))
[1] 941.52

> sd(unlist(lapply(r, nrow)))
[1] 6.494079

There are likely to be some efficiencies in the function that can be
brought to bear, but it is a start.

In either case, the restricted permutations appear to be around 94%, if
all of the assumptions are correct.

HTH,

Marc Schwartz



From jlamack at bol.com.br  Wed Jul 14 22:02:47 2004
From: jlamack at bol.com.br (jlamack)
Date: Wed, 14 Jul 2004 17:02:47 -0300
Subject: [R] simultaneous confidence intervals --- question
Message-ID: <I0UYCN$C4B2B2A7A739B2A62929FBDA31C12DA5@bol.com.br>

Dear all, is there a R function to construct 
 simultaneous confidence intervals for multinomial 
 proportions?
 
 Best wishes 
  
 jl

 
__________________________________________________________________________
Acabe com aquelas janelinhas que pulam na sua tela.
AntiPop-up UOL - ?? gr??tis!
http://antipopup.uol.com.br/



From HermanD at intra.nimh.nih.gov  Wed Jul 14 22:05:44 2004
From: HermanD at intra.nimh.nih.gov (Herman, David (NIH/NIMH))
Date: Wed, 14 Jul 2004 16:05:44 -0400
Subject: [R] PCA in R
Message-ID: <5F9DE1C25708B04EAD634A1AE3D91130049DD7DE@nihexchange20.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040714/e6053586/attachment.pl

From baron at psych.upenn.edu  Wed Jul 14 22:16:44 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 14 Jul 2004 16:16:44 -0400
Subject: [R] PCA in R
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7DE@nihexchange20.nih.gov>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7DE@nihexchange20.nih.gov>
Message-ID: <20040714201644.GA12239@psych>

On 07/14/04 16:05, Herman, David (NIH/NIMH) wrote:
>Hello,
>            I'm attempting to run a PCA on an example data set. I ran it
>just fine, but I don't know how to few the output?

Take a look at the help file for prcomp, especially the bottom of
it.  (This is completely general advice for any R function.)  You
will see under "See also" a number of things listed, and if you
look them up or try them, then you will see several different
ways of viewing the result.  Under that is "Examples," which
provides more hints still.  And, if this isn't enough, type

example(prcomp)

on the command line.  The biplot function is especially nice.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From andy_liaw at merck.com  Wed Jul 14 22:19:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 14 Jul 2004 16:19:47 -0400
Subject: [R] PCA in R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8048@usrymx25.merck.com>

When all else fails, RTFM; e.g., see ?princomp and read it in its entirety.
Then maybe also try running example(princomp).

Andy

> From: Herman, David (NIH/NIMH)
> 
> Hello,
>             I'm attempting to run a PCA on an example data 
> set. I ran it
> just fine, but I don't know how to few the output?  I listed what the
> variable got stored in it, but I don't know how I can get 
> anything else out
> of it. Are there other ways to view the results?
> Also, I'm confused about the last line "6  variables and  8 
> observations"
> Aren't the rows the variables and the columns the observations?
>  
> (NOTE: if anyone knows a good guide for doing a PCA on an 
> example data set,
> from start to finish, it would be greatly appreciated)
>  
> > m
>      [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]    1    2    3    4    5    6
> [2,]    3    4    3    7    8    1
> [3,]    1    2    3    4    5    6
> [4,]    8    7    4    1    4    3
> [5,]    1    2    3    4    5    6
> [6,]    4    5    8    2    1    3
> [7,]    9    8    7    6    7    8
> [8,]    1    3    7    3    5    0
> > pc.cr<-princomp(m,cor=TRUE)
> > pc.cr
> Call:
> princomp(x = m, cor = TRUE)
>  
> Standard deviations:
>       Comp.1       Comp.2       Comp.3       Comp.4       Comp.5
> Comp.6 
> 1.545609e+00 1.407093e+00 9.886649e-01 7.539927e-01 2.919276e-01
> 2.460515e-09 
>  
>  6  variables and  8 observations.
> >
>  
> thanks! 
> Dave 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ggrothendieck at myway.com  Wed Jul 14 22:30:34 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 14 Jul 2004 20:30:34 +0000 (UTC)
Subject: [R] Permutations
References: <BAY15-F3FD4LXfKCzxg00042002@hotmail.com>
Message-ID: <loom.20040714T221513-762@post.gmane.org>


Based on your description below and our off-list
discussion I gather than the problem is equivalent
to sampling ordered permutations in the sense
defined by Erich (i.e.  permutations which are
increasing within blocks) WITHOUT replacement.

Actually one of your valid permutations in your
example is not ordered but it seems arbitrary
which representative of the 3!^4 intrablock
permutations is used which is why I believe this
solves your problem. 

The following code (not extensively tested) does this:

ordered.perm <- function(N) {
   samp <- function() c(apply(matrix(sample(12,12),3),2,sort))
   z <- vector(length=N, mode="character")
   for(i in 1:N) 
      while( (z[i]<-paste(samp(),collapse=" ")) %in% z[seq(len=i-1)] ) {}
   matrix(as.numeric(unlist(strsplit(z, split = " "))), nc = 12, byrow = TRUE)
}
ordered.perm(3)  # test run

In the above, samp(), which is from my previous
response, gets one sample WITH replacement. It generates
an unrestricted permutation of 12 and then projects that
onto its associated ordered permutation of 12.  Note that
samp does not use rejection.  That comes later which is
why there are relatively few rejections.
 
Each iteration of the for loop gets one sample without
replacement storing the unrejected sammples as
character strings in vector z.  Each iteration of this
for loop uses a while to call samp() repeatedly until it 
finds a sample that has not previously been generated
(i.e. rejecting the others). The line beginning
with matrix converts the strings to numbers.


Jordi Altirriba Gutirrez <altirriba <at> hotmail.com> writes:

: 
: Dear Adaikalavan,
:   Now I've send a similar e-mail to Robin and Rolf, therefore I can deduce 
: that my first e-mail was not enough clear (sorry).
:   Therefore, I'm going to try it again with an explanation of why I don't 
: want those permutations:
: 
: Ive 12 elements in blocks of 3 elements and I want only to make 
: permutations inter-blocks (no intra-blocks) (sorry if the terminology is not 
: accurate), something similar to:
: 
: 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   YES-------1st permutation
: 
: 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
: permutation of permutation 1
:    -  -
: 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
: permutation of permutation 1
: -  -  -
: 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
: 
: 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
: 
: 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
: permutation of permutation 3
:            -  -
: 10 1 7 | 4 8 7 | 5 6 12 | 3 2 9    YES---Xth permutation
: 
: 1 10 7 | 4 8 7 | 5 6 12 | 3 2 9    NO ----because it's an 
: "intra-block"permutation of permutation X
: -   -
: 
: So, what is a "not correct" permutation is an "intra-block" permutation of a 
: permutation created before.
: 
: Again, thanks for your time and suggestions,
: 
: Jordi Altirriba
: PhD student
: Hospital Clinic - Barcelona - Spain
: 
: P.S. Probably (it's the way of how I'm testing the algorithms now with 
: Excel) [sorry if it's stupid], could be interesting something similar to:
: 
: 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12 ---> 1*2*3=6 | 4*5*6=120 | 7*8*9=504 | 
: 10*11*12=1320
: 
: 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12 ---> 1*3*2=6 | 4*5*6=120 | 7*8*9=504 | 
: 10*11*12=1320
: 
: 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12 ---> 4*5*6=120 | 1*2*3=6 | 7*8*9=504 | 
: 10*11*12=1320
: 
: 
: Results:
: permutation1: 6 | 120 | 504 | 1320
: permutation2: 6 | 120 | 504 | 1320
: permutation3: 120 | 6 | 504 | 1320
: 
: Order the permutations according first to the first parameter, second to the 
: second...and to the fourth.
: 
: In this case it's the same:
: permutation1: 6 | 120 | 504 | 1320
: permutation2: 6 | 120 | 504 | 1320
: permutation3: 120 | 6 | 504 | 1320
: 
: Therefore, if the first, second, third and fourth parameter of a 
: permutations have the same value that the next permutation it's because 
: there is an "intra-block" permutation. So, permutation 2 is an "intra-block" 
: permutation of permutation 1.
: 
: P.S. Sorry for having forgotten the title of the last e-mail
: 
: 
: >From: Adaikalavan Ramasamy <ramasamy <at> cancer.org.uk>
: >To: Jordi Altirriba Gutirrez <altirriba <at> hotmail.com>
: >CC: rksh <at> soc.soton.ac.uk, R-help <r-help <at> stat.math.ethz.ch>
: >Subject: Re: [R]  Permutations
: >Date: Wed, 14 Jul 2004 18:00:49 +0100
: >
: >I think the issue here is in the two keywords - permutations or sample.
: >
: >AFAIK, permutations should return all admissible (by some rule)
: >combinations. If this is a large number, as some have pointed out, then
: >one essentially takes a _sample_ of all admissible combinations. Since
: >you earlier mentioned that you only want 5-10 outputs, perhaps the
: >correct term is sampling with restrictions.
: >
: >There main problem with Robin's method in that all elements within a row
: >are mutually exclusive to the other. e.g. only one of either 1, 4, 7, 10
: >can appear in block 1. Furthermore they can only appear in the first
: >slot of the first block (so no intra-block randomness). This limits the
: >number of possible outputs.
: >
: >Can you clearly define the rules (with examples) for an admissible
: >combination ? They seem to have a different meaning every time I read
: >the mail. Maybe I am just confused.
: >
: >
: >On Wed, 2004-07-14 at 17:16, Jordi Altirriba Gutirrez wrote:
: > >   Dear R users,
: > >   First of all, thanks to Rolf, Brad, Robin, Erich, Fernando and 
: >Adaikalavan
: > > for your time and suggestions.
: > >   Ive been testing some algorithms (sorry for the delay, Im very slow, 
: >and
: > > Im a completely beginner in Rs world).
: > >   First, the Robin algorithm.
: > >   I think that there is a problem because Ive done 200 permutations and
: > > Ive found that these permutations are the same:
: > > 52 and 91, 99 and 110, 121 and 122, 51 and 141, 130 and 134.
: > >   Thanks again,
: > >
: > > Jordi Altirriba
: > > Hospital Clinic  Barcelona - Spain
: > >
: > > >x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
: > > >dim(x) <- c(3,4) a<-matrix(1,200,12)
: > > >for (i in 1:200)
: > > + {
: > > +  jj <- t(apply(x,1,sample))
: > > + a[i,]<-as.vector(jj)
: > > + }
: > > >a
: > >        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
: > >   [1,]    7    2    3    1   11    6    4    8    9    10     5    12
: > >   [2,]    1    2    9    7   11    6    4    8   12    10     5     3
: > >   [3,]    7    2    9    1   11    3    4    5    6    10     8    12
: > >   [4,]   10    8    6    4    5   12    7    2    9     1    11     3
: > >   [5,]   10    2   12    1   11    9    7    8    6     4     5     3
: > >   [6,]    7    8    6    1    5    9    4   11   12    10     2     3
: > >   [7,]    1    5   12    7    2    6    4    8    9    10    11     3
: > >   [8,]    1    5    9   10    8    6    4    2    3     7    11    12
: > >   [9,]    1   11    6    7    2   12    4    5    9    10     8     3
: > > [10,]    4    5   12   10   11    9    1    8    6     7     2     3
: > > [11,]    1   11    9    7    5    6    4    8   12    10     2     3
: > > [12,]    1    8    3    4    2   12   10    5    9     7    11     6
: > > [13,]    1    2    3    7   11    6   10    5   12     4     8     9
: > > [14,]    4    8    3   10    5   12    7    2    9     1    11     6
: > > [15,]   10    2    3    4    8    6    7   11    9     1     5    12
: > > [16,]    4    8    9   10    2   12    7    5    6     1    11     3
: > > [17,]    1    2    6   10    5    3    7    8   12     4    11     9
: > > [18,]   10    2    9    4   11   12    1    5    6     7     8     3
: > > [19,]    4    8    6    7   11   12    1    2    9    10     5     3
: > > [20,]    1    8   12    7    2    3   10   11    6     4     5     9
: > > [21,]   10    2   12    1    5    9    7   11    6     4     8     3
: > > [22,]    4   11   12    1    2    3   10    8    6     7     5     9
: > > [23,]    1   11    3    7    2    6   10    5    9     4     8    12
: > > [24,]    7    2    9   10    5   12    1   11    3     4     8     6
: > > [25,]    7    8    9    1    2    6    4    5    3    10    11    12
: > > [26,]    4    5   12   10    2    3    7   11    6     1     8     9
: > > [27,]    4    5    9    1   11    3    7    8   12    10     2     6
: > > [28,]    1    5    6    4   11    3    7    8    9    10     2    12
: > > [29,]    4    5    6    1   11    9   10    2   12     7     8     3
: > > [30,]    4   11    3    7    8   12   10    5    6     1     2     9
: > > [31,]   10    2    3    1   11    6    7    8    9     4     5    12
: > > [32,]   10    2    3    7    8    9    1   11    6     4     5    12
: > > [33,]    7   11    6    1    8    9    4    5   12    10     2     3
: > > [34,]    7    5   12    1    8    6    4   11    3    10     2     9
: > > [35,]    1    2    3    4    8    6    7    5    9    10    11    12
: > > [36,]    7    8    3    1   11    9   10    2   12     4     5     6
: > > [37,]   10    2    6    1   11   12    7    5    3     4     8     9
: > > [38,]    1    5    9    4   11   12    7    8    3    10     2     6
: > > [39,]    1    2   12    7    5    9   10    8    3     4    11     6
: > > [40,]    1    8    3   10    2   12    7   11    6     4     5     9
: > > [41,]    1    2    9    4    8    3   10   11   12     7     5     6
: > > [42,]    4    5    6    1    2    9   10    8    3     7    11    12
: > > [43,]    1    2    6    7   11   12   10    5    9     4     8     3
: > > [44,]    1    2    9   10   11   12    4    8    6     7     5     3
: > > [45,]   10    5    9    7   11    6    4    2    3     1     8    12
: > > [46,]    1    2    3    4   11    6    7    5    9    10     8    12
: > > [47,]    4    2    6    1    8    3   10    5   12     7    11     9
: > > [48,]    4    8    9    7    2    3    1    5   12    10    11     6
: > > [49,]   10    8   12    1    2    9    4   11    3     7     5     6
: > > [50,]   10    8    6    1    2    3    7    5   12     4    11     9
: > > [51,]    7    2   12   10   11    6    4    8    3     1     5     9
: > > [52,]    4    5    6    1    2   12   10   11    9     7     8     3
: > > [53,]    1    2    3    7    5    6    4    8    9    10    11    12
: > > [54,]   10    5    3    7   11    9    1    8    6     4     2    12
: > > [55,]    7   11   12    4    2    3   10    8    6     1     5     9
: > > [56,]    1    5    9    4   11   12   10    8    3     7     2     6
: > > [57,]    4    5    9    7   11    3   10    2    6     1     8    12
: > > [58,]   10   11    3    4    5    6    1    8   12     7     2     9
: > > [59,]    4    8    9   10    5    6    7    2    3     1    11    12
: > > [60,]    4    2   12    1    8    6   10    5    9     7    11     3
: > > [61,]    4    8    6    7   11    9   10    5   12     1     2     3
: > > [62,]    7    8    3   10    5    6    1   11   12     4     2     9
: > > [63,]   10    5    3    7    8    6    1    2    9     4    11    12
: > > [64,]   10    2    9    4   11   12    1    5    3     7     8     6
: > > [65,]    1   11    6    4    8   12    7    2    3    10     5     9
: > > [66,]    1    5    3    7   11    9    4    2   12    10     8     6
: > > [67,]    4    2    6    7    5   12   10    8    9     1    11     3
: > > [68,]    4   11   12   10    2    3    7    8    6     1     5     9
: > > [69,]    4    5    6   10    2    3    7    8    9     1    11    12
: > > [70,]    1   11   12   10    2    6    4    5    3     7     8     9
: > > [71,]   10    5    6    7    8   12    4    2    9     1    11     3
: > > [72,]   10    8   12    1   11    9    7    5    3     4     2     6
: > > [73,]   10    8    3    7   11    9    4    5   12     1     2     6
: > > [74,]    7    2   12    1    5    6    4    8    9    10    11     3
: > > [75,]    7    2   12   10    8    9    1   11    6     4     5     3
: > > [76,]    7    2    3    1    5    9    4    8   12    10    11     6
: > > [77,]    1   11    3   10    5    6    7    2    9     4     8    12
: > > [78,]    7    2    6   10   11   12    4    8    9     1     5     3
: > > [79,]   10    8    6    7    5    3    1    2    9     4    11    12
: > > [80,]   10   11    3    7    2   12    4    8    6     1     5     9
: > > [81,]   10    5    6    1    8    3    4   11    9     7     2    12
: > > [82,]    1   11    3    7    5   12   10    2    6     4     8     9
: > > [83,]    4   11    9   10    5   12    7    2    6     1     8     3
: > > [84,]    1   11   12    7    8    3    4    2    6    10     5     9
: > > [85,]   10    2    9    7    5    6    1   11   12     4     8     3
: > > [86,]    7   11    9    4    5    6   10    2   12     1     8     3
: > > [87,]    4    5   12    7    2    3   10   11    6     1     8     9
: > > [88,]    1    2   12    7    5    3   10    8    6     4    11     9
: > > [89,]    1    8   12    7   11    9   10    2    6     4     5     3
: > > [90,]    4    5    3   10   11    9    7    2    6     1     8    12
: > > [91,]    4    5    6    1    2   12   10   11    9     7     8     3
: > > [92,]   10   11    9    7    5   12    1    2    6     4     8     3
: > > [93,]    4    2    3    7    8    6    1   11   12    10     5     9
: > > [94,]    4    5    3   10    2   12    7    8    9     1    11     6
: > > [95,]    4    8    3   10   11    9    1    2    6     7     5    12
: > > [96,]    7    5   12   10   11    3    1    8    9     4     2     6
: > > [97,]    4    2    3    1    8    6    7   11    9    10     5    12
: > > [98,]    4   11    9    7    5   12   10    8    6     1     2     3
: > > [99,]    1   11   12    4    5    6    7    8    3    10     2     9
: > > [100,]    1    8    3    7    5    6   10    2   12     4    11     9
: > > [101,]    7   11    6    4    8    3    1    2   12    10     5     9
: > > [102,]    7   11   12    1    2    3   10    8    6     4     5     9
: > > [103,]    4    5   12    1    2    9    7    8    3    10    11     6
: > > [104,]   10   11   12    4    8    3    7    5    9     1     2     6
: > > [105,]   10    5    9    1    2    3    4    8    6     7    11    12
: > > [106,]   10   11    9    1    2   12    7    8    3     4     5     6
: > > [107,]   10   11    3    4    8    9    7    5   12     1     2     6
: > > [108,]    7    2    6    1   11    9    4    5   12    10     8     3
: > > [109,]    1    8    6    7    2   12   10    5    3     4    11     9
: > > [110,]    1   11   12    4    5    6    7    8    3    10     2     9
: > > [111,]    7    8    6    1    5    3   10    2   12     4    11     9
: > > [112,]    4    8    3    7    5    6    1    2    9    10    11    12
: > > [113,]    1    2    9    4   11    6    7    5    3    10     8    12
: > > [114,]    4   11    9    1    8    6    7    2    3    10     5    12
: > > [115,]   10    8    3    4   11   12    7    2    9     1     5     6
: > > [116,]    7   11   12    1    2    3    4    8    9    10     5     6
: > > [117,]    1    5    3   10   11   12    7    8    9     4     2     6
: > > [118,]    1   11    6    4    2    9   10    5   12     7     8     3
: > > [119,]   10    2    3    1    5    9    4    8   12     7    11     6
: > > [120,]    1    2    3    4   11   12    7    8    9    10     5     6
: > > [121,]    7    8    3    4    5   12   10    2    6     1    11     9
: > > [122,]    7    8    3    4    5   12   10    2    6     1    11     9
: > > [123,]    4    5    3   10   11    9    7    8    6     1     2    12
: > > [124,]    4    5    6    7   11    9    1    8   12    10     2     3
: > > [125,]   10    8    6    1   11    9    4    2   12     7     5     3
: > > [126,]   10    8   12    4   11    9    7    2    6     1     5     3
: > > [127,]    7    8   12    1   11    6   10    5    9     4     2     3
: > > [128,]    1    8   12   10   11    3    7    5    9     4     2     6
: > > [129,]    7    8    3   10    2    6    1   11    9     4     5    12
: > > [130,]    7   11    9    1    2    6   10    8    3     4     5    12
: > > [131,]   10    2    3    4   11    9    1    5    6     7     8    12
: > > [132,]    4   11    3    1    5    9   10    2    6     7     8    12
: > > [133,]   10    2   12    7    8    3    4    5    6     1    11     9
: > > [134,]    7   11    9    1    2    6   10    8    3     4     5    12
: > > [135,]    7    8    3    4   11    6   10    2    9     1     5    12
: > > [136,]   10    8    9    7   11   12    1    2    6     4     5     3
: > > [137,]   10    8   12    4    5    3    1    2    9     7    11     6
: > > [138,]    1    2    6   10    8   12    7   11    9     4     5     3
: > > [139,]    4    5    3    7   11    9    1    2   12    10     8     6
: > > [140,]    4    5   12    7    8    6   10   11    3     1     2     9
: > > [141,]    7    2   12   10   11    6    4    8    3     1     5     9
: > > [142,]   10   11   12    7    2    6    1    5    3     4     8     9
: > > [143,]    7    2    3   10   11    6    1    8    9     4     5    12
: > > [144,]    1    2    9   10    5   12    4    8    3     7    11     6
: > > [145,]    1   11    6    4    8    9    7    5   12    10     2     3
: > > [146,]    4    5    3   10    2    6    1   11    9     7     8    12
: > > [147,]    7   11    9    1    2    3   10    8   12     4     5     6
: > > [148,]    4    2    3    1    5   12    7    8    6    10    11     9
: > > [149,]   10   11   12    4    8    3    1    2    9     7     5     6
: > > [150,]    4    8    3   10    5    6    1   11    9     7     2    12
: > > [151,]    1    8    6   10    5    9    4   11    3     7     2    12
: > > [152,]    4    8    6    7   11   12   10    5    3     1     2     9
: > > [153,]    7    2    3   10    5    6    4   11    9     1     8    12
: > > [154,]   10    5   12    1    8    9    7    2    3     4    11     6
: > > [155,]    1    8    6    4    2    9   10    5    3     7    11    12
: > > [156,]   10    2    3    7    5    9    4   11   12     1     8     6
: > > [157,]   10    5    3    1    2    6    7    8    9     4    11    12
: > > [158,]    7   11   12    4    5    9   10    8    3     1     2     6
: > > [159,]    7    5    3    1    8   12   10    2    6     4    11     9
: > > [160,]    7    2    6    4   11    3    1    5   12    10     8     9
: > > [161,]    7    5    3    1    2   12    4    8    9    10    11     6
: > > [162,]    7    8   12    1    5    6   10   11    9     4     2     3
: > > [163,]   10   11    9    4    8    6    1    2    3     7     5    12
: > > [164,]    7   11    6    1    5    9    4    2   12    10     8     3
: > > [165,]    4   11    9   10    8    3    7    2   12     1     5     6
: > > [166,]    4    2    6   10    8    9    7   11   12     1     5     3
: > > [167,]    7    5    3   10    2   12    4    8    6     1    11     9
: > > [168,]    1    8   12    7    2    3    4    5    9    10    11     6
: > > [169,]    7    8   12    1    5    6    4    2    3    10    11     9
: > > [170,]    4    5    3    7    8    9    1    2   12    10    11     6
: > > [171,]    7   11    9    1    8    6    4    2   12    10     5     3
: > > [172,]   10    8    3    1    2    9    4   11   12     7     5     6
: > > [173,]   10    5   12    7    8    9    4   11    3     1     2     6
: > > [174,]   10   11    6    7    5    3    4    8   12     1     2     9
: > > [175,]    7   11   12    1    2    3   10    8    9     4     5     6
: > > [176,]    1   11   12    7    2    3    4    8    9    10     5     6
: > > [177,]   10   11   12    4    5    3    7    8    6     1     2     9
: > > [178,]   10    5    3    7    2    6    4    8   12     1    11     9
: > > [179,]    1    5    6    7    2    9   10   11    3     4     8    12
: > > [180,]    1   11   12   10    5    6    4    2    3     7     8     9
: > > [181,]    7    2   12    4   11    9    1    5    6    10     8     3
: > > [182,]   10   11   12    1    5    3    7    8    9     4     2     6
: > > [183,]    4    8    3    1   11    9    7    2    6    10     5    12
: > > [184,]    4    8    9    7    2    3   10    5    6     1    11    12
: > > [185,]   10   11    9    1    5    6    7    2   12     4     8     3
: > > [186,]   10    5   12    4    8    9    7    2    6     1    11     3
: > > [187,]    4    2    3    1    8    6    7    5   12    10    11     9
: > > [188,]   10    2    9    4   11   12    1    8    3     7     5     6
: > > [189,]   10    2   12    7   11    3    4    5    9     1     8     6
: > > [190,]    4    5    6    7    8    3   10   11    9     1     2    12
: > > [191,]   10    5    9    1    2    3    7   11   12     4     8     6
: > > [192,]    4   11    9    7    2    6   10    5    3     1     8    12
: > > [193,]   10   11   12    1    2    6    4    5    9     7     8     3
: > > [194,]   10    2    3    4   11   12    7    5    6     1     8     9
: > > [195,]    4    2    6    7    8    9    1   11    3    10     5    12
: > > [196,]   10    2   12    4    8    6    7    5    3     1    11     9
: > > [197,]    7    5   12    4   11    9    1    2    3    10     8     6
: > > [198,]   10    5    6    1   11    3    7    2    9     4     8    12
: > > [199,]    1    2    9    7   11    3    4    8    6    10     5    12
: > > [200,]    4    8    3    7   11   12    1    2    6    10     5     9
: > >
: > >
: > >
: > > >From: Robin Hankin <rksh <at> soc.soton.ac.uk>
: > > >To: Jordi Altirriba Gutirrez  	<altirriba <at> hotmail.com>
: > > >CC: r-help <at> stat.math.ethz.ch
: > > >Subject: Re: [R] (no subject) (was: Permutations)
: > > >Date: Wed, 14 Jul 2004 09:11:48 +0100
: > > >
: > > >Jordi
: > > >
: > > >try this
: > > >
: > > >
: > > >R> x <- c(1,2,3,  10,11,12,  41,42,43,  81,82,83)
: > > >R> dim(x) <- c(3,4)
: > > >R> x
: > > >      [,1] [,2] [,3] [,4]
: > > >[1,]    1   10   41   81
: > > >[2,]    2   11   42   82
: > > >[3,]    3   12   43   83
: > > >R>  jj <- t(apply(x,1,sample))
: > > >R> jj
: > > >      [,1] [,2] [,3] [,4]
: > > >[1,]    1   41   10   81
: > > >[2,]    2   11   82   42
: > > >[3,]   12    3   43   83
: > > >R> as.vector(jj)
: > > >R>
: > > >    [1]  1 2 12 41 11 3 10 82 43 81 42 83
: > > >
: > > >
: > > >
: > > >
: > > >and I think that does what you want...
: > > >
: > > >We take the vector, rearrange it into a matrix with three rows, then 
: >sample
: > > >*within* the rows,
: > > >then rearrange into a vector again.
: > > >
: > > >There will be one forbidden permutation, namely the identity (which may 
: >or
: > > >may not be
: > > >desirable).
: > > >
: > > >This method doesn't allow "intra block" permutations.
: > > >
: > > >best
: > > >
: > > >rksh
: > > >
: > > >
: > > >
: > > >>  Dear R users,
: > > >>  First of all, thanks for the incredibly fast answers and help of 
: >Rolf,
: > > >>Marc and Robert.
: > > >>  Yes, I noticed that it was a lot of permutacions, but my intention 
: >was
: > > >>to make this process automatic and take only 5.000 - 10.000 
: >permutations.
: > > >>Therefore, I wanted only to take that "interesting permutations" with
: > > >>"some information" [inter-block permutations].
: > > >>  The reason why I'm interested in these permutations is because I'm 
: >using
: > > >>some packages of Bioconductor to analyse my data from some microarrays 
: >and
: > > >>I thought that perhaps could be interesting to see what happens when I
: > > >>permute my data and I compare it against the not permuted data.
: > > >>  Thanks again for your time and suggestions.
: > > >>
: > > >>Jordi Altirriba
: > > >>Ph. D. Student
: > > >>
: > > >>Hospital Clinic-Barcelona-Spain
: > > >>
: > > >>______________________________________________
: > > >>R-help <at> stat.math.ethz.ch mailing list
: > > >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: > > >>PLEASE do read the posting guide!
: > > >>http://www.R-project.org/posting-guide.html
: > > >
: > > >
: > > >--
: > > >Robin Hankin
: > > >Uncertainty Analyst
: > > >Southampton Oceanography Centre
: > > >SO14 3ZH
: > > >tel +44(0)23-8059-7743
: > > >initialDOTsurname <at> soc.soton.ac.uk (edit in obvious way; spam 
: >precaution)
: > >
: > > ______________________________________________
: > > R-help <at> stat.math.ethz.ch mailing list
: > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: > > PLEASE do read the posting guide! 
: >http://www.R-project.org/posting-guide.html
: > >
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From lists at revelle.net  Wed Jul 14 22:45:21 2004
From: lists at revelle.net (William Revelle)
Date: Wed, 14 Jul 2004 15:45:21 -0500
Subject: [R] using "mean" in by(x,y,mean)
Message-ID: <p0611041fbd1b4a15b0d1@[192.168.1.11]>

Dear list friends

I fail to understand how to find means for multiple groups using the 
by() function. Help would be appreciated. Thanks.
Bill


x <- runif(20,0,10)
group <- rep(c("A","B"),10)
df <-data.frame(x,group)
#df            #show the data

rm(x,group)
attach(df)

sd(x)       # sd is defined
mean(x)     #so is mean

by(x,group,sd)   #this works for both groups
by(x,group,mean)  #this does not


produces this output:


>  x <- runif(20,0,10)
>  group <- rep(c("A","B"),10)
>  df <-data.frame(x,group)
>  #df            #show the data
>
>  rm(x,group)
>  attach(df)
>
>  sd(x)       # sd is defined
[1] 2.952699
>  mean(x)     #so is mean
[1] 5.026441
>
>  by(x,group,sd)   #this works for both groups
INDICES: A
[1] 2.813504
------------------------------------------------------------------------------------------------------------ 

INDICES: B
[1] 3.236663
>  by(x,group,mean)  #this does not
Error in FUN(X[[as.integer(1)]], ...) : couldn't find function "FUN"


I am using a Mac OS 10.3.4 running R 1.9.1
-- 
----------------------------
William Revelle               http://pmc.psych.northwestern.edu/revelle.html
Department of Psychology, Northwestern University
Personality Project: http://personality-project.org/personality.html



From sundar.dorai-raj at PDF.COM  Wed Jul 14 22:52:28 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 14 Jul 2004 13:52:28 -0700
Subject: [R] using "mean" in by(x,y,mean)
In-Reply-To: <p0611041fbd1b4a15b0d1@[192.168.1.11]>
References: <p0611041fbd1b4a15b0d1@[192.168.1.11]>
Message-ID: <40F59D0C.4070104@pdf.com>

William Revelle wrote:

> Dear list friends
> 
> I fail to understand how to find means for multiple groups using the 
> by() function. Help would be appreciated. Thanks.
> Bill
> 
> 
> x <- runif(20,0,10)
> group <- rep(c("A","B"),10)
> df <-data.frame(x,group)
> #df            #show the data
> 
> rm(x,group)
> attach(df)
> 
> sd(x)       # sd is defined
> mean(x)     #so is mean
> 
> by(x,group,sd)   #this works for both groups
> by(x,group,mean)  #this does not
> 
> 
> produces this output:
> 
> 
>>  x <- runif(20,0,10)
>>  group <- rep(c("A","B"),10)
>>  df <-data.frame(x,group)
>>  #df            #show the data
>>
>>  rm(x,group)
>>  attach(df)
>>
>>  sd(x)       # sd is defined
> 
> [1] 2.952699
> 
>>  mean(x)     #so is mean
> 
> [1] 5.026441
> 
>>
>>  by(x,group,sd)   #this works for both groups
> 
> INDICES: A
> [1] 2.813504
> ------------------------------------------------------------------------------------------------------------ 
> 
> INDICES: B
> [1] 3.236663
> 
>>  by(x,group,mean)  #this does not
> 
> Error in FUN(X[[as.integer(1)]], ...) : couldn't find function "FUN"
> 
> 
> I am using a Mac OS 10.3.4 running R 1.9.1

Hi Bill,

Works for me. Do you have a local "mean" defined? Try rm(mean) and re-try.

 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

--sundar



From andy_liaw at merck.com  Thu Jul 15 00:04:14 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 14 Jul 2004 18:04:14 -0400
Subject: [R] using "mean" in by(x,y,mean)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF804A@usrymx25.merck.com>

> From: Sundar Dorai-Raj
> 
> William Revelle wrote:
> 
> > Dear list friends
> > 
> > I fail to understand how to find means for multiple groups 
> using the 
> > by() function. Help would be appreciated. Thanks.
> > Bill
> > 
> > 
> > x <- runif(20,0,10)
> > group <- rep(c("A","B"),10)
> > df <-data.frame(x,group)
> > #df            #show the data
> > 
> > rm(x,group)
> > attach(df)
> > 
> > sd(x)       # sd is defined
> > mean(x)     #so is mean
> > 
> > by(x,group,sd)   #this works for both groups
> > by(x,group,mean)  #this does not
> > 
> > 
> > produces this output:
> > 
> > 
> >>  x <- runif(20,0,10)
> >>  group <- rep(c("A","B"),10)
> >>  df <-data.frame(x,group)
> >>  #df            #show the data
> >>
> >>  rm(x,group)
> >>  attach(df)
> >>
> >>  sd(x)       # sd is defined
> > 
> > [1] 2.952699
> > 
> >>  mean(x)     #so is mean
> > 
> > [1] 5.026441
> > 
> >>
> >>  by(x,group,sd)   #this works for both groups
> > 
> > INDICES: A
> > [1] 2.813504
> > 
> --------------------------------------------------------------
> ---------------------------------------------- 
> > 
> > INDICES: B
> > [1] 3.236663
> > 
> >>  by(x,group,mean)  #this does not
> > 
> > Error in FUN(X[[as.integer(1)]], ...) : couldn't find function "FUN"
> > 
> > 
> > I am using a Mac OS 10.3.4 running R 1.9.1
> 
> Hi Bill,
> 
> Works for me. Do you have a local "mean" defined? Try 
> rm(mean) and re-try.
> 
>  > R.version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> --sundar

Or try replacing `mean' with `base:::mean'.  BTW, why not just use tapply(x,
group, mean)?

Andy



From Jo.Hardin at pomona.edu  Thu Jul 15 00:05:34 2004
From: Jo.Hardin at pomona.edu (Johanna Hardin)
Date: Wed, 14 Jul 2004 15:05:34 -0700
Subject: [R] MASS package?
Message-ID: <5B526011BAC3D511BFBA00B0D020615A06A79F43@excsrv-acd1.pomona.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040714/c95ea502/attachment.pl

From kbartz at loyaltymatrix.com  Thu Jul 15 00:08:47 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Wed, 14 Jul 2004 15:08:47 -0700
Subject: [R] RODBC repeated rows problem
Message-ID: <20040714221410.A65D440193@omta12.mta.everyone.net>

Hello everyone! I'm having the dreaded repeated rows problem in RODBC.
Specifically, when I have a NULL value in a column, odbcFetchRows reads the
value not as NULL or NA but as the most recent non-NULL value in the column.
If there is no such non-NULL column, odbcFetchRows reads the value as 0. Let
me give you an example (though you won't be able to run it with the
"product" table--just use some table you've defined):

> head(sqlQuery(channel, "select NULL from product"))
  c("0", "0", "0", "0", "0", "0")
1                               0
2                               0
3                               0
4                               0
5                               0
6                               0

Obviously, I'd like to see NAs here, not 0s. Let me give you some of my
specs:

> version
         _                       
platform x86_64-unknown-linux-gnu
arch     x86_64                  
os       linux-gnu               
system   x86_64, linux-gnu       
status                           
major    1                       
minor    9.1                     
year     2004                    
month    06                      
day      21                      
language R                       

Other specs: I'm reading a unixODBC ODBC driver. When I run from isql and
try the same query, I get, as I might expect, a bunch of blanks.

SQL> select top 5 NULL from product
+------------+
|            |
+------------+
|            |
|            |
|            |
|            |
|            |
+------------+
SQLRowCount returns 5
5 rows fetched

It shouldn't be relevant, but the ODBC is powered by a FreeTDS driver hooked
to an MS SQL Server 2000 Professional.

I noticed a previous note from Professor Ripley reporting that this problem
had been fixed with a version of RODBC from long ago. I am running RODBC
version 1.04, the latest version, however, so I'm at a loss as to what to
do.

One last note: I looked at the relevant line from sql.h that defines my
SQL_NULL_DATA, which RODBC (presumably) compares to its results. It says:

#define SQL_NULL_DATA             (-1)

Unfortunately, I have no idea what this should mean to me :(

Are there any further diagnostics I can run? Any new versions of software I
should install? Any workarounds for the time being?

Thanks for any help you can provide.

Kevin



From andy_liaw at merck.com  Thu Jul 15 00:37:11 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 14 Jul 2004 18:37:11 -0400
Subject: [R] MASS package?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF804C@usrymx25.merck.com>

Search on the R site ought to show you.  cov.rob() is in MASS (part of the
`VR' bundle, and should be part of all R distribution).  There's also the
rrcov package with the covMcd() function.

Andy

> From: Johanna Hardin
> 
> Did the MASS package disappear?  Specifically, I'm looking 
> for a function to
> find the MCD (robust measure of shape and location) for a 
> multi-dimensional
> data matrix.
> 
>  
> 
> Anyone know anything about this?
> 
>  
> 
> Thanks, Jo
> 
>  
> 
> Jo Hardin
> 
> Assistant Professor
> 
> Department of Mathematics
> 
> Pomona College
> 
> 610 N. College Ave.
> 
> Claremont, CA 91711
> 
> 909-607-8717
> 
> jo.hardin at pomona.edu
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From MSchwartz at MedAnalytics.com  Thu Jul 15 00:37:47 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 14 Jul 2004 17:37:47 -0500
Subject: [R] MASS package?
In-Reply-To: <5B526011BAC3D511BFBA00B0D020615A06A79F43@excsrv-acd1.pomona.edu>
References: <5B526011BAC3D511BFBA00B0D020615A06A79F43@excsrv-acd1.pomona.edu>
Message-ID: <1089844667.28515.151.camel@localhost.localdomain>

On Wed, 2004-07-14 at 17:05, Johanna Hardin wrote:
> Did the MASS package disappear?  Specifically, I'm looking for a function to
> find the MCD (robust measure of shape and location) for a multi-dimensional
> data matrix.
> 
>  
> 
> Anyone know anything about this?


Try:

library(MASS)
?cov.rob

It's there, unless you have a corrupted/incomplete installation.

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Thu Jul 15 01:14:49 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 14 Jul 2004 23:14:49 +0000 (UTC)
Subject: [R] Permutations
References: <BAY15-F3FD4LXfKCzxg00042002@hotmail.com>
	<loom.20040714T221513-762@post.gmane.org>
Message-ID: <loom.20040715T010859-408@post.gmane.org>


Just in case my last post is wrong in assuming that 
ordered repesentatives of the 3!^4 intragroup permutations
are adequate, the following minor variation of the routine 
in my last post will provide an unordered representative.
Its actually easy to do since sample(12,12), which we
already calculated, is that representative so we merely
store it.  

ordered.perm2 <- function(N) {
   samp <- function() c(apply(matrix(z[i,] <<- sample(12,12),3),2,sort))
   s <- vector(length = N, mode = "character")
   z <- matrix(nr = N, nc = 12)
   for(i in 1:N) 
      while( (s[i]<-paste(samp(),collapse=" ")) %in% s[seq(len=i-1)] ) {}
   z
}

# test
set.seed(1)
ordered.perm(3)  



Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Based on your description below and our off-list
: discussion I gather than the problem is equivalent
: to sampling ordered permutations in the sense
: defined by Erich (i.e.  permutations which are
: increasing within blocks) WITHOUT replacement.
: 
: Actually one of your valid permutations in your
: example is not ordered but it seems arbitrary
: which representative of the 3!^4 intrablock
: permutations is used which is why I believe this
: solves your problem. 
: 
: The following code (not extensively tested) does this:
: 
: ordered.perm <- function(N) {
:    samp <- function() c(apply(matrix(sample(12,12),3),2,sort))
:    z <- vector(length=N, mode="character")
:    for(i in 1:N) 
:       while( (z[i]<-paste(samp(),collapse=" ")) %in% z[seq(len=i-1)] ) {}
:    matrix(as.numeric(unlist(strsplit(z, split = " "))), nc = 12, byrow = 
TRUE)
: }
: ordered.perm(3)  # test run
: 
: In the above, samp(), which is from my previous
: response, gets one sample WITH replacement. It generates
: an unrestricted permutation of 12 and then projects that
: onto its associated ordered permutation of 12.  Note that
: samp does not use rejection.  That comes later which is
: why there are relatively few rejections.
: 
: Each iteration of the for loop gets one sample without
: replacement storing the unrejected sammples as
: character strings in vector z.  Each iteration of this
: for loop uses a while to call samp() repeatedly until it 
: finds a sample that has not previously been generated
: (i.e. rejecting the others). The line beginning
: with matrix converts the strings to numbers.
: 
: Jordi Altirriba Gutirrez <altirriba <at> hotmail.com> writes:
: 
: : 
: : Dear Adaikalavan,
: :   Now I've send a similar e-mail to Robin and Rolf, therefore I can deduce 
: : that my first e-mail was not enough clear (sorry).
: :   Therefore, I'm going to try it again with an explanation of why I don't 
: : want those permutations:
: : 
: : Ive 12 elements in blocks of 3 elements and I want only to make 
: : permutations inter-blocks (no intra-blocks) (sorry if the terminology is 
not 
: : accurate), something similar to:
: : 
: : 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12   YES-------1st permutation
: : 
: : 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
: : permutation of permutation 1
: :    -  -
: : 3 2 1 | 4 5 6 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
: : permutation of permutation 1
: : -  -  -
: : 1 2 4 | 3 5 6 | 7 8 9 | 10 11 12   YES-----2nd permutation
: : 
: : 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12   YES-----3rd permutation
: : 
: : 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block" 
: : permutation of permutation 3
: :            -  -
: : 10 1 7 | 4 8 7 | 5 6 12 | 3 2 9    YES---Xth permutation
: : 
: : 1 10 7 | 4 8 7 | 5 6 12 | 3 2 9    NO ----because it's an 
: : "intra-block"permutation of permutation X
: : -   -
: : 
: : So, what is a "not correct" permutation is an "intra-block" permutation of 
a 
: : permutation created before.
: : 
: : Again, thanks for your time and suggestions,
: : 
: : Jordi Altirriba
: : PhD student
: : Hospital Clinic - Barcelona - Spain
: : 
: : P.S. Probably (it's the way of how I'm testing the algorithms now with 
: : Excel) [sorry if it's stupid], could be interesting something similar to:
: : 
: : 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12 ---> 1*2*3=6 | 4*5*6=120 | 7*8*9=504 | 
: : 10*11*12=1320
: : 
: : 1 3 2 | 4 5 6 | 7 8 9 | 10 11 12 ---> 1*3*2=6 | 4*5*6=120 | 7*8*9=504 | 
: : 10*11*12=1320
: : 
: : 4 5 6 | 1 2 3 | 7 8 9 | 10 11 12 ---> 4*5*6=120 | 1*2*3=6 | 7*8*9=504 | 
: : 10*11*12=1320
: : 
: : 
: : Results:
: : permutation1: 6 | 120 | 504 | 1320
: : permutation2: 6 | 120 | 504 | 1320
: : permutation3: 120 | 6 | 504 | 1320
: : 
: : Order the permutations according first to the first parameter, second to 
the 
: : second...and to the fourth.
: : 
: : In this case it's the same:
: : permutation1: 6 | 120 | 504 | 1320
: : permutation2: 6 | 120 | 504 | 1320
: : permutation3: 120 | 6 | 504 | 1320
: : 
: : Therefore, if the first, second, third and fourth parameter of a 
: : permutations have the same value that the next permutation it's because 
: : there is an "intra-block" permutation. So, permutation 2 is an "intra-
block" 
: : permutation of permutation 1.
: : 
: : P.S. Sorry for having forgotten the title of the last e-mail
: : 
: : 
: : >From: Adaikalavan Ramasamy <ramasamy <at> cancer.org.uk>
: : >To: Jordi Altirriba Gutirrez <altirriba <at> hotmail.com>
: : >CC: rksh <at> soc.soton.ac.uk, R-help <r-help <at> stat.math.ethz.ch>
: : >Subject: Re: [R]  Permutations
: : >Date: Wed, 14 Jul 2004 18:00:49 +0100
: : >
: : >I think the issue here is in the two keywords - permutations or sample.
: : >
: : >AFAIK, permutations should return all admissible (by some rule)
: : >combinations. If this is a large number, as some have pointed out, then
: : >one essentially takes a _sample_ of all admissible combinations. Since
: : >you earlier mentioned that you only want 5-10 outputs, perhaps the
: : >correct term is sampling with restrictions.
: : >
: : >There main problem with Robin's method in that all elements within a row
: : >are mutually exclusive to the other. e.g. only one of either 1, 4, 7, 10
: : >can appear in block 1. Furthermore they can only appear in the first
: : >slot of the first block (so no intra-block randomness). This limits the
: : >number of possible outputs.
: : >
: : >Can you clearly define the rules (with examples) for an admissible
: : >combination ? They seem to have a different meaning every time I read
: : >the mail. Maybe I am just confused.
: : >
: : >
: : >On Wed, 2004-07-14 at 17:16, Jordi Altirriba Gutirrez wrote:
: : > >   Dear R users,
: : > >   First of all, thanks to Rolf, Brad, Robin, Erich, Fernando and 
: : >Adaikalavan
: : > > for your time and suggestions.
: : > >   Ive been testing some algorithms (sorry for the delay, Im very slow, 
: : >and
: : > > Im a completely beginner in Rs world).
: : > >   First, the Robin algorithm.
: : > >   I think that there is a problem because Ive done 200 permutations and
: : > > Ive found that these permutations are the same:
: : > > 52 and 91, 99 and 110, 121 and 122, 51 and 141, 130 and 134.
: : > >   Thanks again,
: : > >
: : > > Jordi Altirriba
: : > > Hospital Clinic  Barcelona - Spain
: : > >
: : > > >x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
: : > > >dim(x) <- c(3,4) a<-matrix(1,200,12)
: : > > >for (i in 1:200)
: : > > + {
: : > > +  jj <- t(apply(x,1,sample))
: : > > + a[i,]<-as.vector(jj)
: : > > + }
: : > > >a
: : > >        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
: : > >   [1,]    7    2    3    1   11    6    4    8    9    10     5    12
: : > >   [2,]    1    2    9    7   11    6    4    8   12    10     5     3
: : > >   [3,]    7    2    9    1   11    3    4    5    6    10     8    12
: : > >   [4,]   10    8    6    4    5   12    7    2    9     1    11     3
: : > >   [5,]   10    2   12    1   11    9    7    8    6     4     5     3
: : > >   [6,]    7    8    6    1    5    9    4   11   12    10     2     3
: : > >   [7,]    1    5   12    7    2    6    4    8    9    10    11     3
: : > >   [8,]    1    5    9   10    8    6    4    2    3     7    11    12
: : > >   [9,]    1   11    6    7    2   12    4    5    9    10     8     3
: : > > [10,]    4    5   12   10   11    9    1    8    6     7     2     3
: : > > [11,]    1   11    9    7    5    6    4    8   12    10     2     3
: : > > [12,]    1    8    3    4    2   12   10    5    9     7    11     6
: : > > [13,]    1    2    3    7   11    6   10    5   12     4     8     9
: : > > [14,]    4    8    3   10    5   12    7    2    9     1    11     6
: : > > [15,]   10    2    3    4    8    6    7   11    9     1     5    12
: : > > [16,]    4    8    9   10    2   12    7    5    6     1    11     3
: : > > [17,]    1    2    6   10    5    3    7    8   12     4    11     9
: : > > [18,]   10    2    9    4   11   12    1    5    6     7     8     3
: : > > [19,]    4    8    6    7   11   12    1    2    9    10     5     3
: : > > [20,]    1    8   12    7    2    3   10   11    6     4     5     9
: : > > [21,]   10    2   12    1    5    9    7   11    6     4     8     3
: : > > [22,]    4   11   12    1    2    3   10    8    6     7     5     9
: : > > [23,]    1   11    3    7    2    6   10    5    9     4     8    12
: : > > [24,]    7    2    9   10    5   12    1   11    3     4     8     6
: : > > [25,]    7    8    9    1    2    6    4    5    3    10    11    12
: : > > [26,]    4    5   12   10    2    3    7   11    6     1     8     9
: : > > [27,]    4    5    9    1   11    3    7    8   12    10     2     6
: : > > [28,]    1    5    6    4   11    3    7    8    9    10     2    12
: : > > [29,]    4    5    6    1   11    9   10    2   12     7     8     3
: : > > [30,]    4   11    3    7    8   12   10    5    6     1     2     9
: : > > [31,]   10    2    3    1   11    6    7    8    9     4     5    12
: : > > [32,]   10    2    3    7    8    9    1   11    6     4     5    12
: : > > [33,]    7   11    6    1    8    9    4    5   12    10     2     3
: : > > [34,]    7    5   12    1    8    6    4   11    3    10     2     9
: : > > [35,]    1    2    3    4    8    6    7    5    9    10    11    12
: : > > [36,]    7    8    3    1   11    9   10    2   12     4     5     6
: : > > [37,]   10    2    6    1   11   12    7    5    3     4     8     9
: : > > [38,]    1    5    9    4   11   12    7    8    3    10     2     6
: : > > [39,]    1    2   12    7    5    9   10    8    3     4    11     6
: : > > [40,]    1    8    3   10    2   12    7   11    6     4     5     9
: : > > [41,]    1    2    9    4    8    3   10   11   12     7     5     6
: : > > [42,]    4    5    6    1    2    9   10    8    3     7    11    12
: : > > [43,]    1    2    6    7   11   12   10    5    9     4     8     3
: : > > [44,]    1    2    9   10   11   12    4    8    6     7     5     3
: : > > [45,]   10    5    9    7   11    6    4    2    3     1     8    12
: : > > [46,]    1    2    3    4   11    6    7    5    9    10     8    12
: : > > [47,]    4    2    6    1    8    3   10    5   12     7    11     9
: : > > [48,]    4    8    9    7    2    3    1    5   12    10    11     6
: : > > [49,]   10    8   12    1    2    9    4   11    3     7     5     6
: : > > [50,]   10    8    6    1    2    3    7    5   12     4    11     9
: : > > [51,]    7    2   12   10   11    6    4    8    3     1     5     9
: : > > [52,]    4    5    6    1    2   12   10   11    9     7     8     3
: : > > [53,]    1    2    3    7    5    6    4    8    9    10    11    12
: : > > [54,]   10    5    3    7   11    9    1    8    6     4     2    12
: : > > [55,]    7   11   12    4    2    3   10    8    6     1     5     9
: : > > [56,]    1    5    9    4   11   12   10    8    3     7     2     6
: : > > [57,]    4    5    9    7   11    3   10    2    6     1     8    12
: : > > [58,]   10   11    3    4    5    6    1    8   12     7     2     9
: : > > [59,]    4    8    9   10    5    6    7    2    3     1    11    12
: : > > [60,]    4    2   12    1    8    6   10    5    9     7    11     3
: : > > [61,]    4    8    6    7   11    9   10    5   12     1     2     3
: : > > [62,]    7    8    3   10    5    6    1   11   12     4     2     9
: : > > [63,]   10    5    3    7    8    6    1    2    9     4    11    12
: : > > [64,]   10    2    9    4   11   12    1    5    3     7     8     6
: : > > [65,]    1   11    6    4    8   12    7    2    3    10     5     9
: : > > [66,]    1    5    3    7   11    9    4    2   12    10     8     6
: : > > [67,]    4    2    6    7    5   12   10    8    9     1    11     3
: : > > [68,]    4   11   12   10    2    3    7    8    6     1     5     9
: : > > [69,]    4    5    6   10    2    3    7    8    9     1    11    12
: : > > [70,]    1   11   12   10    2    6    4    5    3     7     8     9
: : > > [71,]   10    5    6    7    8   12    4    2    9     1    11     3
: : > > [72,]   10    8   12    1   11    9    7    5    3     4     2     6
: : > > [73,]   10    8    3    7   11    9    4    5   12     1     2     6
: : > > [74,]    7    2   12    1    5    6    4    8    9    10    11     3
: : > > [75,]    7    2   12   10    8    9    1   11    6     4     5     3
: : > > [76,]    7    2    3    1    5    9    4    8   12    10    11     6
: : > > [77,]    1   11    3   10    5    6    7    2    9     4     8    12
: : > > [78,]    7    2    6   10   11   12    4    8    9     1     5     3
: : > > [79,]   10    8    6    7    5    3    1    2    9     4    11    12
: : > > [80,]   10   11    3    7    2   12    4    8    6     1     5     9
: : > > [81,]   10    5    6    1    8    3    4   11    9     7     2    12
: : > > [82,]    1   11    3    7    5   12   10    2    6     4     8     9
: : > > [83,]    4   11    9   10    5   12    7    2    6     1     8     3
: : > > [84,]    1   11   12    7    8    3    4    2    6    10     5     9
: : > > [85,]   10    2    9    7    5    6    1   11   12     4     8     3
: : > > [86,]    7   11    9    4    5    6   10    2   12     1     8     3
: : > > [87,]    4    5   12    7    2    3   10   11    6     1     8     9
: : > > [88,]    1    2   12    7    5    3   10    8    6     4    11     9
: : > > [89,]    1    8   12    7   11    9   10    2    6     4     5     3
: : > > [90,]    4    5    3   10   11    9    7    2    6     1     8    12
: : > > [91,]    4    5    6    1    2   12   10   11    9     7     8     3
: : > > [92,]   10   11    9    7    5   12    1    2    6     4     8     3
: : > > [93,]    4    2    3    7    8    6    1   11   12    10     5     9
: : > > [94,]    4    5    3   10    2   12    7    8    9     1    11     6
: : > > [95,]    4    8    3   10   11    9    1    2    6     7     5    12
: : > > [96,]    7    5   12   10   11    3    1    8    9     4     2     6
: : > > [97,]    4    2    3    1    8    6    7   11    9    10     5    12
: : > > [98,]    4   11    9    7    5   12   10    8    6     1     2     3
: : > > [99,]    1   11   12    4    5    6    7    8    3    10     2     9
: : > > [100,]    1    8    3    7    5    6   10    2   12     4    11     9
: : > > [101,]    7   11    6    4    8    3    1    2   12    10     5     9
: : > > [102,]    7   11   12    1    2    3   10    8    6     4     5     9
: : > > [103,]    4    5   12    1    2    9    7    8    3    10    11     6
: : > > [104,]   10   11   12    4    8    3    7    5    9     1     2     6
: : > > [105,]   10    5    9    1    2    3    4    8    6     7    11    12
: : > > [106,]   10   11    9    1    2   12    7    8    3     4     5     6
: : > > [107,]   10   11    3    4    8    9    7    5   12     1     2     6
: : > > [108,]    7    2    6    1   11    9    4    5   12    10     8     3
: : > > [109,]    1    8    6    7    2   12   10    5    3     4    11     9
: : > > [110,]    1   11   12    4    5    6    7    8    3    10     2     9
: : > > [111,]    7    8    6    1    5    3   10    2   12     4    11     9
: : > > [112,]    4    8    3    7    5    6    1    2    9    10    11    12
: : > > [113,]    1    2    9    4   11    6    7    5    3    10     8    12
: : > > [114,]    4   11    9    1    8    6    7    2    3    10     5    12
: : > > [115,]   10    8    3    4   11   12    7    2    9     1     5     6
: : > > [116,]    7   11   12    1    2    3    4    8    9    10     5     6
: : > > [117,]    1    5    3   10   11   12    7    8    9     4     2     6
: : > > [118,]    1   11    6    4    2    9   10    5   12     7     8     3
: : > > [119,]   10    2    3    1    5    9    4    8   12     7    11     6
: : > > [120,]    1    2    3    4   11   12    7    8    9    10     5     6
: : > > [121,]    7    8    3    4    5   12   10    2    6     1    11     9
: : > > [122,]    7    8    3    4    5   12   10    2    6     1    11     9
: : > > [123,]    4    5    3   10   11    9    7    8    6     1     2    12
: : > > [124,]    4    5    6    7   11    9    1    8   12    10     2     3
: : > > [125,]   10    8    6    1   11    9    4    2   12     7     5     3
: : > > [126,]   10    8   12    4   11    9    7    2    6     1     5     3
: : > > [127,]    7    8   12    1   11    6   10    5    9     4     2     3
: : > > [128,]    1    8   12   10   11    3    7    5    9     4     2     6
: : > > [129,]    7    8    3   10    2    6    1   11    9     4     5    12
: : > > [130,]    7   11    9    1    2    6   10    8    3     4     5    12
: : > > [131,]   10    2    3    4   11    9    1    5    6     7     8    12
: : > > [132,]    4   11    3    1    5    9   10    2    6     7     8    12
: : > > [133,]   10    2   12    7    8    3    4    5    6     1    11     9
: : > > [134,]    7   11    9    1    2    6   10    8    3     4     5    12
: : > > [135,]    7    8    3    4   11    6   10    2    9     1     5    12
: : > > [136,]   10    8    9    7   11   12    1    2    6     4     5     3
: : > > [137,]   10    8   12    4    5    3    1    2    9     7    11     6
: : > > [138,]    1    2    6   10    8   12    7   11    9     4     5     3
: : > > [139,]    4    5    3    7   11    9    1    2   12    10     8     6
: : > > [140,]    4    5   12    7    8    6   10   11    3     1     2     9
: : > > [141,]    7    2   12   10   11    6    4    8    3     1     5     9
: : > > [142,]   10   11   12    7    2    6    1    5    3     4     8     9
: : > > [143,]    7    2    3   10   11    6    1    8    9     4     5    12
: : > > [144,]    1    2    9   10    5   12    4    8    3     7    11     6
: : > > [145,]    1   11    6    4    8    9    7    5   12    10     2     3
: : > > [146,]    4    5    3   10    2    6    1   11    9     7     8    12
: : > > [147,]    7   11    9    1    2    3   10    8   12     4     5     6
: : > > [148,]    4    2    3    1    5   12    7    8    6    10    11     9
: : > > [149,]   10   11   12    4    8    3    1    2    9     7     5     6
: : > > [150,]    4    8    3   10    5    6    1   11    9     7     2    12
: : > > [151,]    1    8    6   10    5    9    4   11    3     7     2    12
: : > > [152,]    4    8    6    7   11   12   10    5    3     1     2     9
: : > > [153,]    7    2    3   10    5    6    4   11    9     1     8    12
: : > > [154,]   10    5   12    1    8    9    7    2    3     4    11     6
: : > > [155,]    1    8    6    4    2    9   10    5    3     7    11    12
: : > > [156,]   10    2    3    7    5    9    4   11   12     1     8     6
: : > > [157,]   10    5    3    1    2    6    7    8    9     4    11    12
: : > > [158,]    7   11   12    4    5    9   10    8    3     1     2     6
: : > > [159,]    7    5    3    1    8   12   10    2    6     4    11     9
: : > > [160,]    7    2    6    4   11    3    1    5   12    10     8     9
: : > > [161,]    7    5    3    1    2   12    4    8    9    10    11     6
: : > > [162,]    7    8   12    1    5    6   10   11    9     4     2     3
: : > > [163,]   10   11    9    4    8    6    1    2    3     7     5    12
: : > > [164,]    7   11    6    1    5    9    4    2   12    10     8     3
: : > > [165,]    4   11    9   10    8    3    7    2   12     1     5     6
: : > > [166,]    4    2    6   10    8    9    7   11   12     1     5     3
: : > > [167,]    7    5    3   10    2   12    4    8    6     1    11     9
: : > > [168,]    1    8   12    7    2    3    4    5    9    10    11     6
: : > > [169,]    7    8   12    1    5    6    4    2    3    10    11     9
: : > > [170,]    4    5    3    7    8    9    1    2   12    10    11     6
: : > > [171,]    7   11    9    1    8    6    4    2   12    10     5     3
: : > > [172,]   10    8    3    1    2    9    4   11   12     7     5     6
: : > > [173,]   10    5   12    7    8    9    4   11    3     1     2     6
: : > > [174,]   10   11    6    7    5    3    4    8   12     1     2     9
: : > > [175,]    7   11   12    1    2    3   10    8    9     4     5     6
: : > > [176,]    1   11   12    7    2    3    4    8    9    10     5     6
: : > > [177,]   10   11   12    4    5    3    7    8    6     1     2     9
: : > > [178,]   10    5    3    7    2    6    4    8   12     1    11     9
: : > > [179,]    1    5    6    7    2    9   10   11    3     4     8    12
: : > > [180,]    1   11   12   10    5    6    4    2    3     7     8     9
: : > > [181,]    7    2   12    4   11    9    1    5    6    10     8     3
: : > > [182,]   10   11   12    1    5    3    7    8    9     4     2     6
: : > > [183,]    4    8    3    1   11    9    7    2    6    10     5    12
: : > > [184,]    4    8    9    7    2    3   10    5    6     1    11    12
: : > > [185,]   10   11    9    1    5    6    7    2   12     4     8     3
: : > > [186,]   10    5   12    4    8    9    7    2    6     1    11     3
: : > > [187,]    4    2    3    1    8    6    7    5   12    10    11     9
: : > > [188,]   10    2    9    4   11   12    1    8    3     7     5     6
: : > > [189,]   10    2   12    7   11    3    4    5    9     1     8     6
: : > > [190,]    4    5    6    7    8    3   10   11    9     1     2    12
: : > > [191,]   10    5    9    1    2    3    7   11   12     4     8     6
: : > > [192,]    4   11    9    7    2    6   10    5    3     1     8    12
: : > > [193,]   10   11   12    1    2    6    4    5    9     7     8     3
: : > > [194,]   10    2    3    4   11   12    7    5    6     1     8     9
: : > > [195,]    4    2    6    7    8    9    1   11    3    10     5    12
: : > > [196,]   10    2   12    4    8    6    7    5    3     1    11     9
: : > > [197,]    7    5   12    4   11    9    1    2    3    10     8     6
: : > > [198,]   10    5    6    1   11    3    7    2    9     4     8    12
: : > > [199,]    1    2    9    7   11    3    4    8    6    10     5    12
: : > > [200,]    4    8    3    7   11   12    1    2    6    10     5     9
: : > >
: : > >
: : > >
: : > > >From: Robin Hankin <rksh <at> soc.soton.ac.uk>
: : > > >To: Jordi Altirriba Gutirrez  	<altirriba <at> hotmail.com>
: : > > >CC: r-help <at> stat.math.ethz.ch
: : > > >Subject: Re: [R] (no subject) (was: Permutations)
: : > > >Date: Wed, 14 Jul 2004 09:11:48 +0100
: : > > >
: : > > >Jordi
: : > > >
: : > > >try this
: : > > >
: : > > >
: : > > >R> x <- c(1,2,3,  10,11,12,  41,42,43,  81,82,83)
: : > > >R> dim(x) <- c(3,4)
: : > > >R> x
: : > > >      [,1] [,2] [,3] [,4]
: : > > >[1,]    1   10   41   81
: : > > >[2,]    2   11   42   82
: : > > >[3,]    3   12   43   83
: : > > >R>  jj <- t(apply(x,1,sample))
: : > > >R> jj
: : > > >      [,1] [,2] [,3] [,4]
: : > > >[1,]    1   41   10   81
: : > > >[2,]    2   11   82   42
: : > > >[3,]   12    3   43   83
: : > > >R> as.vector(jj)
: : > > >R>
: : > > >    [1]  1 2 12 41 11 3 10 82 43 81 42 83
: : > > >
: : > > >
: : > > >
: : > > >
: : > > >and I think that does what you want...
: : > > >
: : > > >We take the vector, rearrange it into a matrix with three rows, then 
: : >sample
: : > > >*within* the rows,
: : > > >then rearrange into a vector again.
: : > > >
: : > > >There will be one forbidden permutation, namely the identity (which 
may 
: : >or
: : > > >may not be
: : > > >desirable).
: : > > >
: : > > >This method doesn't allow "intra block" permutations.
: : > > >
: : > > >best
: : > > >
: : > > >rksh
: : > > >
: : > > >
: : > > >
: : > > >>  Dear R users,
: : > > >>  First of all, thanks for the incredibly fast answers and help of 
: : >Rolf,
: : > > >>Marc and Robert.
: : > > >>  Yes, I noticed that it was a lot of permutacions, but my intention 
: : >was
: : > > >>to make this process automatic and take only 5.000 - 10.000 
: : >permutations.
: : > > >>Therefore, I wanted only to take that "interesting permutations" with
: : > > >>"some information" [inter-block permutations].
: : > > >>  The reason why I'm interested in these permutations is because I'm 
: : >using
: : > > >>some packages of Bioconductor to analyse my data from some 
microarrays 
: : >and
: : > > >>I thought that perhaps could be interesting to see what happens when 
I
: : > > >>permute my data and I compare it against the not permuted data.
: : > > >>  Thanks again for your time and suggestions.
: : > > >>
: : > > >>Jordi Altirriba
: : > > >>Ph. D. Student
: : > > >>
: : > > >>Hospital Clinic-Barcelona-Spain
: : > > >>
: : > > >>______________________________________________
: : > > >>R-help <at> stat.math.ethz.ch mailing list
: : > > >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: : > > >>PLEASE do read the posting guide!
: : > > >>http://www.R-project.org/posting-guide.html
: : > > >
: : > > >
: : > > >--
: : > > >Robin Hankin
: : > > >Uncertainty Analyst
: : > > >Southampton Oceanography Centre
: : > > >SO14 3ZH
: : > > >tel +44(0)23-8059-7743
: : > > >initialDOTsurname <at> soc.soton.ac.uk (edit in obvious way; spam 
: : >precaution)
: : > >
: : > > ______________________________________________
: : > > R-help <at> stat.math.ethz.ch mailing list
: : > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: : > > PLEASE do read the posting guide! 
: : >http://www.R-project.org/posting-guide.html
: : > >
: : >
: : 
: : ______________________________________________
: : R-help <at> stat.math.ethz.ch mailing list
: : https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: : PLEASE do read the posting guide! http://www.R-project.org/posting-
guide.html
: : 
: :
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From house-ball at yahoo.com.tw  Thu Jul 15 06:00:51 2004
From: house-ball at yahoo.com.tw (=?big5?q?house-ball?=)
Date: Thu, 15 Jul 2004 12:00:51 +0800 (CST)
Subject: [R] questions about R
Message-ID: <20040715040051.46226.qmail@web16811.mail.tpe.yahoo.com>

Hi,
 
I try to compute critical value for multivariate normal distribution, and I find the crit(fit, const = c(0, 1), d = 1, cov = 0.95, rdf = 0) which seems to compute critical value. However, I can't compute right critical value for multivariate normal distribution which I want. I don't know how to solve my question. I send my question in the file. Would you help me to solve it, please? My English is not very well, but I appreciate you very much.
                            
                                                                               Chia-Yi



From kathryn.jones at jcu.edu.au  Thu Jul 15 07:33:32 2004
From: kathryn.jones at jcu.edu.au (Kathryn Jones)
Date: Thu, 15 Jul 2004 15:33:32 +1000
Subject: [R] older versions of R (v1.0)
Message-ID: <81481e9.6020f98f.8202e00@mirapoint-ms1.jcu.edu.au>

Hi folks,
Does anyone know where I can find downloads for old versions 
of R, around version 1.0? I found the downloads for unix but 
not windows. Any help would be greatly appreciated!
Thank you,
Kathryn



From ligges at statistik.uni-dortmund.de  Thu Jul 15 08:38:39 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 15 Jul 2004 08:38:39 +0200
Subject: [R] older versions of R (v1.0)
In-Reply-To: <81481e9.6020f98f.8202e00@mirapoint-ms1.jcu.edu.au>
References: <81481e9.6020f98f.8202e00@mirapoint-ms1.jcu.edu.au>
Message-ID: <40F6266F.5080800@statistik.uni-dortmund.de>

Kathryn Jones wrote:

> Hi folks,
> Does anyone know where I can find downloads for old versions 
> of R, around version 1.0? I found the downloads for unix but 
> not windows. Any help would be greatly appreciated!
> Thank you,
> Kathryn

Windows binary versions are not archived on CRAN. You may compile it 
from sources (won't be that easy to get the required outdated tools 
together), if you REALLY need it (I cannot imagine why).
It might be the case someone else has still lying a version around 
(quite sure I have one at home).

Uwe Ligges



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Jul 15 08:41:55 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 15 Jul 2004 08:41:55 +0200 (CEST)
Subject: [R] questions about R
In-Reply-To: <20040715040051.46226.qmail@web16811.mail.tpe.yahoo.com>
References: <20040715040051.46226.qmail@web16811.mail.tpe.yahoo.com>
Message-ID: <Pine.LNX.4.51.0407150840290.28036@artemis.imbe.med.uni-erlangen.de>

On Thu, 15 Jul 2004, [big5] house-ball wrote:

> Hi,
>
> I try to compute critical value for multivariate normal distribution, and I find the crit(fit, const = c(0, 1), d = 1, cov = 0.95, rdf = 0) which seems to compute critical value. However, I can't compute right critical value for multivariate normal distribution which I want. I don't know how to solve my question. I send my question in the file. Would you help me to solve it, please? My English is not very well, but I appreciate you very much.
>

one possibility is to invert the P-value function `pmvnorm' from
package `mvtnorm' using `uniroot' - There is FORTRAN 90 code solving this
problem available from Alan Genz' homepage at

http://www.math.wsu.edu/math/faculty/genz/homepage

Best,

Torsten

>                                                                                Chia-Yi


From jacques.veslot at cirad.fr  Thu Jul 15 09:23:50 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Thu, 15 Jul 2004 11:23:50 +0400
Subject: [R] About lattice plots and loops
Message-ID: <HHEDKBCGCMDOHEDELFBCKELBCAAA.jacques.veslot@cirad.fr>


I cannot operate lattice plots, notably those in package gstat, within for()
loops.
(I can neither read such graphics included in a .R (or .txt) file with the
source() function).

However same commands executed one by one don't fail.

Could you please help me find a means to execute lattice plots inside a loop
?


Jacques VESLOT
CIRAD


-----------------------------------------------------
CIRAD 3P Reunion - MailScanner
----------------------------------------------------- 
Ce message a ??t?? v??rifi?? par MailScanner
et analyse par 4 antivirus :
ClamAv - BitDefender - F-Prot - Panda.

Aucun virus,ni rien de suspect n'a ??t?? trouv??.

This message has been scanned for viruses and
dangerous content, and is believed to be clean.



From ligges at statistik.uni-dortmund.de  Thu Jul 15 09:35:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 15 Jul 2004 09:35:13 +0200
Subject: [R] About lattice plots and loops
In-Reply-To: <HHEDKBCGCMDOHEDELFBCKELBCAAA.jacques.veslot@cirad.fr>
References: <HHEDKBCGCMDOHEDELFBCKELBCAAA.jacques.veslot@cirad.fr>
Message-ID: <40F633B1.4050602@statistik.uni-dortmund.de>

Jacques VESLOT wrote:

> I cannot operate lattice plots, notably those in package gstat, within for()
> loops.
> (I can neither read such graphics included in a .R (or .txt) file with the
> source() function).
> 
> However same commands executed one by one don't fail.
> 
> Could you please help me find a means to execute lattice plots inside a loop
> ?


I guess you forgot to print() those graphics.
Printing is done automatically if you are executing one by one in an 
interactive session, but not within loops or in batch mode.

Uwe Ligges


> 
> Jacques VESLOT
> CIRAD
> 
> 
> -----------------------------------------------------
> CIRAD 3P Reunion - MailScanner
> ----------------------------------------------------- 
> Ce message a ??t?? v??rifi?? par MailScanner
> et analyse par 4 antivirus :
> ClamAv - BitDefender - F-Prot - Panda.
> 
> Aucun virus,ni rien de suspect n'a ??t?? trouv??.
> 
> This message has been scanned for viruses and
> dangerous content, and is believed to be clean.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From cts at debian.org  Thu Jul 15 09:31:21 2004
From: cts at debian.org (Christian T. Steigies)
Date: Thu, 15 Jul 2004 09:31:21 +0200
Subject: [R] Permutations
In-Reply-To: <BAY15-F3FD4LXfKCzxg00042002@hotmail.com>
References: <BAY15-F3FD4LXfKCzxg00042002@hotmail.com>
Message-ID: <20040715073120.GA7285@skeeve>

On Wed, Jul 14, 2004 at 07:42:49PM +0200, Jordi Altirriba Guti??rrez wrote:
> 
> I?ve 12 elements in blocks of 3 elements and I want only to make 
> permutations inter-blocks (no intra-blocks) (sorry if the terminology is 
> not accurate)

I am not a mathematician, but this sounds to me a little bit like Kirkman's
Schoolgirl Problem:

In a boarding school there are fifteen schoolgirls who always take their
daily walks in rows of threes. How can it be arranged so that each
schoolgirl walks in the same row with every other schoolgirl exactly once a
week?

http://mathworld.wolfram.com/KirkmansSchoolgirlProblem.html

Christian



From jacques.veslot at cirad.fr  Thu Jul 15 09:51:37 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Thu, 15 Jul 2004 11:51:37 +0400
Subject: [R] About lattice plots and loops
In-Reply-To: <40F633B1.4050602@statistik.uni-dortmund.de>
Message-ID: <HHEDKBCGCMDOHEDELFBCEELDCAAA.jacques.veslot@cirad.fr>

It works indeed.
Thanks a lot.

Jacques VESLOT
CIRAD


-----Message d'origine-----
De : Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
Envoy?? : jeudi 15 juillet 2004 11:35
?? : jacques.veslot at cirad.fr
Cc : r-help at stat.math.ethz.ch
Objet : Re: [R] About lattice plots and loops


Jacques VESLOT wrote:

> I cannot operate lattice plots, notably those in package gstat, within
for()
> loops.
> (I can neither read such graphics included in a .R (or .txt) file with the
> source() function).
>
> However same commands executed one by one don't fail.
>
> Could you please help me find a means to execute lattice plots inside a
loop
> ?


I guess you forgot to print() those graphics.
Printing is done automatically if you are executing one by one in an
interactive session, but not within loops or in batch mode.

Uwe Ligges


>
> Jacques VESLOT
> CIRAD
>
>
> -----------------------------------------------------
> CIRAD 3P Reunion - MailScanner
> -----------------------------------------------------
> Ce message a ??t?? v??rifi?? par MailScanner
> et analyse par 4 antivirus :
> ClamAv - BitDefender - F-Prot - Panda.
>
> Aucun virus,ni rien de suspect n'a ??t?? trouv??.
>
> This message has been scanned for viruses and
> dangerous content, and is believed to be clean.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


-----------------------------------------------------
CIRAD 3P Reunion - MailScanner
-----------------------------------------------------
Ce message a ??t?? v??rifi?? par MailScanner
et analyse par 4 antivirus :
ClamAv - BitDefender - F-Prot - Panda.

Aucun virus,ni rien de suspect n'a ??t?? trouv??.

This message has been scanned for viruses and
dangerous content, and is believed to be clean.
-----------------------------------------------------


-----------------------------------------------------
CIRAD 3P Reunion - MailScanner
----------------------------------------------------- 
Ce message a ??t?? v??rifi?? par MailScanner
et analyse par 4 antivirus :
ClamAv - BitDefender - F-Prot - Panda.

Aucun virus,ni rien de suspect n'a ??t?? trouv??.

This message has been scanned for viruses and
dangerous content, and is believed to be clean.



From a.prioglio at city.ac.uk  Thu Jul 15 10:01:53 2004
From: a.prioglio at city.ac.uk (Antonio Prioglio)
Date: Thu, 15 Jul 2004 09:01:53 +0100 (BST)
Subject: [R] (Newbie) scope of with()
Message-ID: <Pine.LNX.4.44.0407150825000.1865-100000@ws7.dogbert.ntt.it>

Hi list,
As I understand statements within with() are local to what is enclosed 
within its expression.

As some excellent examples given to me previously have illustrated it is 
nevertheless possible to assign the evaluation of an expression to an 
external variable like x <- with(data, if(..))

During a "normalisation" phase of data read from a database I have a long 
list of statements of the type
participant$longfieldname[is.na(participant$longfieldname)]<-expr(...)
or similar that makes cumbersome reading. (participant is a table of 
demographic data)

If there a neat way to do something of the sort
"participant<-with(participant,{...})"

it would make nicer reading.

Apparently attach(), detach() would not do as
fieldname<-expr(fieldname)
creates a new variable and not a change to the value of the field!

Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From rksh at soc.soton.ac.uk  Thu Jul 15 10:14:48 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Thu, 15 Jul 2004 09:14:48 +0100
Subject: [R] Permutations
In-Reply-To: <BAY15-F393XgbPhRaUM00022505@hotmail.com>
References: <BAY15-F393XgbPhRaUM00022505@hotmail.com>
Message-ID: <a06002002bd1beae38720@[139.166.242.29]>

hi again


what a stimulating R discussion!  This is R-help at its very best!

I think I understand why you don't want pure inter-block permutations.

My solution would be to realize that weeding out "forbidden" permutations is
quite difficult and time-consuming (also as several people have pointed out
forbidden permutations are very rare, accounting for only a proportion of
(3!)^4/12!  ...about one in 400000).

The extra expense of this weeding process
is likely to outweigh the slight loss of efficiency caused by
generating a forbidden permutation.  My solution would therefore be:

x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
x.new <- sample(x)


(note the not-inconsiderable advantage of code simplicity!)

I think my algorithm generated repeats because in 
it there are only (4!)^3=13284 distinct
permutations; see help(birthday).  The system 
above has 12! ~= 4x10^8, much higher.

Hope this helps

Robin




>
>}
>7.- Robin Hankin
>a<-matrix(1,200,12)
>for (i in 1:200)
>{
>x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
>dim(x) <- c(3,4)
>  jj <- t(apply(x,1,sample))
>a[i,]<-as.vector(jj)
>}
>##In 200 permutations, there are 5 repetitions.
>
>Thanks to all and sorryfor the confusion that 
>have generated the "intra-block" permutation.
>
>Jordi Altirriba
>PhD student
>Hospital Clinic - Barcelona - Spain
>
>P.S. I think that I don't have forgot to anybody...(sorry if I have done it)
>
>_________________________________________________________________
>??Cu??nto vale tu auto? Tips para mantener tu 
>carro. ??De todo en MSN Latino Autos! 
>http://latino.msn.com/autos/


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From altirriba at hotmail.com  Thu Jul 15 01:35:49 2004
From: altirriba at hotmail.com (=?iso-8859-1?B?Sm9yZGkgQWx0aXJyaWJhIEd1dGnpcnJleg==?=)
Date: Thu, 15 Jul 2004 01:35:49 +0200
Subject: [R] Permutations
Message-ID: <BAY15-F393XgbPhRaUM00022505@hotmail.com>

  Dear R users,
  First of all, I want to thank the algorithms , time and suggestions to 
Rolf, Robert, Marc, Gabor, Adaikalavan, Cliff, Robin, Erich and Fernando.
  I want to sum up a little bit all the e-mails, the algorithms and the 
results of a test for 1000 permutations (in my last e-mail is explained (+ 
or -) what kind of permutations I wanted).


1.- Gabor Grothendieck
ordered.perm <- function(N) {
   samp <- function() c(apply(matrix(sample(12,12),3),2,sort))
   z <- vector(length=N, mode="character")
   for(i in 1:N)
      while( (z[i]<-paste(samp(),collapse=" ")) %in% z[seq(len=i-1)] ) {}
   matrix(as.numeric(unlist(strsplit(z, split = " "))), nc = 12, byrow = 
TRUE)
}
ordered.perm(1000)
##It's the correct algorithm, there isn't any repetition and there aren't 
"intra-block" permutations.

2.- Rolf Turner (1)
restr.perm <- function ()
{
S <- 4:12
G <- NULL
A <- list(1:3,4:6,7:9,10:12)
for(k in 1:4) {
	for(i in A[[k]]) {
		tmp <- union(i,S)
		tmp <- setdiff(tmp,G)
		if(length(tmp)==0) return(Recall())
		x <- if(length(tmp)==1) tmp else sample(tmp,1)
		G <- c(G,x)
		S <- setdiff(S,G)
	}
	S <- union(S,A[[k]])
	R <- if(k < 4) A[[k+1]] else NULL
	R <- union(R,G)
	S <- setdiff(S,R)
}
G
}

a<-matrix(1,1000,12)
for (i in 1:1000)
{
a[i,]<-restr.perm()
}
##With 1000 permutations I have found 3 "intra-block" permutations.

3.- Rolf Turner (2)
restr.perm2 <- function () {
#
okay <- function (x) {
	m1 <- cbind(1:12,rep(1:4,rep(3,4)))
	m2 <- m1[x,]
	all((m2[,1] == m1[,1]) | (m2[,2] != m1[,2]))
}
#
repeat{
	x <- sample(12,12)
	if(okay(x)) return(x)
}
}

a<-matrix(1,1000,12)
for (i in 1:1000)
{
a[i,]<-restr.perm2()
}
##With 1000 permutations I have found 4 "intra-block" permutations.

4.- Marc Schwartz
library(gregmisc)
  # Create non-allowable 'intra-block' permutations
  # Need a generalizable way to do this, but
  # good enough for now
  a <- permutations(3, 3, 1:3)
  b <- permutations(3, 3, 4:6)
  c <- permutations(3, 3, 7:9)
  d <- permutations(3, 3, 10:12)
  intra <- rbind(a[-1, ], b[-1, ], c[-1, ], d[-1, ])

restr.perm3 <- function(runs)
{
  results <- matrix(numeric(runs * 12), ncol = 12)

  # use Gabor's function to check for row matches
  # between 'x' and 'intra' to filter out in okay()
  f1a <- function(a,b,sep=":")
  {
    f <- function(...) paste(..., sep=sep)
    a2 <- do.call("f", as.data.frame(a))
    b2 <- do.call("f", as.data.frame(b))
    c(table(c(b2,unique(a2)))[a2] - 1)
  }

  okay <- function (x)
  {
    x.match <- matrix(x, ncol = 3, byrow = TRUE)
    all(f1a(x.match, intra) == 0)
  }

  for (i in 1:runs)
  {
    x <- sample(12,12)
    if (okay(x))
      results[i, ] <- x
    else
      results[i, ] <- rep(NA, 12)
  }

  unique(results[complete.cases(results), ])
}

a<-matrix(1,1000,12)
for (i in 1:1000)
{
a[i,]<-restr.perm3()
}
restr.perm3(1000)
##With 1000 permutations, the function has taken 960 and I have found 4 
"intra-block" permutations there.

5.- Fernando Tusell
permutations<-function(elements,blocks) {
   n <- length(elements)
   el.per.block <- n / blocks
   for (i in 1:n) {                    # For each element in turn,
     b <- floor(i/(el.per.block+.1))+1 # find which block it belongs to.
     if (b==blocks)                    # If in the last block, we are done.
       break
     allow.pos <- b*el.per.block + 1   # Find first position it could 
migrate to...
     for (j in (allow.pos:n)) {        # and create permutations with all 
allowable
       perm <- elements                # interchanges.
       perm[i] <- elements[j]
       perm[j] <- elements[i]
       print(perm)
     }
   }    }

permutations(1:12,3)
##There are only 48 permutations

6.- Cliff Lunneborg
swap<-function(data,blocks)
{
dd<- data
cc<- 1:length(data)
bb<- unique(blocks)
aa<- sample(bb,2,replace=FALSE)
a1<- sample(cc[blocks==aa[1]],1)
a2<- sample(cc[blocks==aa[2]],1)
dd[a1]<- data[a2]
dd[a2]<- data[a1]
dd
}

x.d<- c(1,2,3,4,5,6,7,8,9,10,11,12)
x.b<- c(1,1,1,2,2,2,3,3,3,4,4,4)

a<-matrix(1,1000,12)
for (i in 1:1000)
{
if (i==1)
{a[i,]<-swap(x.d,x.b)
f<-swap(x.d,x.b)}
else
{a[i,]<-swap(f,x.b)
f<-swap(f,x.b)}
}

##There are 2 repetitions a 2 "intra-block" permutations

7.- Robin Hankin
a<-matrix(1,200,12)
for (i in 1:200)
{
x <- c(1,2,3,4,5,6,7,8,9,10,11,12)
dim(x) <- c(3,4)
  jj <- t(apply(x,1,sample))
a[i,]<-as.vector(jj)
}
##In 200 permutations, there are 5 repetitions.

Thanks to all and sorryfor the confusion that have generated the 
"intra-block" permutation.

Jordi Altirriba
PhD student
Hospital Clinic - Barcelona - Spain

P.S. I think that I don't have forgot to anybody...(sorry if I have done it)



From anne.piotet at urbanet.ch  Thu Jul 15 11:55:32 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Thu, 15 Jul 2004 11:55:32 +0200
Subject: [R] areg.boot use of inverseTrans and ytype
Message-ID: <000a01c46a51$defb6890$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040715/a074825d/attachment.pl

From john.gavin at ubs.com  Thu Jul 15 12:07:20 2004
From: john.gavin at ubs.com (john.gavin@ubs.com)
Date: Thu, 15 Jul 2004 11:07:20 +0100
Subject: [R] formatting tables with long column names via package:xtable
	within Sweave 
Message-ID: <012821F286ED1D4ABDC72F9E1DD63D0C0361B77B@NLDNC003PEX1.ubsgs.ubsgroup.net>

Hi,

I use the excellent Sweave tools for writing documents
but was wondering how to neatly print a data.frame
with long column headings.
I cant manage to do this via package:xtable.

Typically the labels that I would like use 
for each column consist of more than one word, 
but even with just one word,
the heading is often wider than the contents of the column.
So the number of columns that fits onto a page 
is limited by the width of the column names.
I would like to spread the column names over 
two or more lines, to reduce that column's width,
but xtable doesn't seem to allow for this.

For example, the code

xtable(data.frame(
  longColumnHeading            = 1, 
  "column heading with spaces" = "b"))

produces the following latex.

% latex table generated in R 1.9.1 by xtable 1.2-2 package
% Thu Jul 15 10:36:24 2004
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrl}
\hline
 & longColumnHeading & column.heading.with.spaces \\
\hline
1 & 1.00 & b \\
\hline
\end{tabular}
\end{center}
\end{table}

I would like to be able to change the line with the column headings

 & longColumHeading & column.heading.with.spaces \\

to a  mulit-line format (with narrower column widths), 
something like:

 & long    & column  \\
 & Column  & heading \\
 & Heading & with    \\
 &         & spaces  \\

What is the best way to do this or something similar?

I am on XP with R 1.9.1 (using XEmacs and ESS).

Regards,

John.

John Gavin <john.gavin at ubs.com>,
Quantitative Risk Models and Statistics,
UBS Investment Bank, 6th floor, 
100 Liverpool St., London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352

Visit our website at http://www.ubs.com

This message contains confidential information and is intend...{{dropped}}



From pcovelli at tin.it  Thu Jul 15 12:41:13 2004
From: pcovelli at tin.it (Paolo Covelli)
Date: Thu, 15 Jul 2004 12:41:13 +0200
Subject: [R] Newbie
Message-ID: <002d01c46a58$435a6380$a40f6850@paolo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040715/0f9cb2b7/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Jul 15 12:57:34 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 15 Jul 2004 12:57:34 +0200
Subject: [R] Newbie
In-Reply-To: <002d01c46a58$435a6380$a40f6850@paolo>
References: <002d01c46a58$435a6380$a40f6850@paolo>
Message-ID: <40F6631E.1090203@statistik.uni-dortmund.de>

Paolo Covelli wrote:

> Hi, 
> 
> I wish build a R-script (or a  R-function) that read a number from the keyboard and then process it.
> For example: from R I load the function X, that ask me the level of confidence "\alpha", by keyboard I write 5 and the function go on.

scan()

Uwe Ligges


> Thanks in advance
> 
> Paolo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From baron at psych.upenn.edu  Thu Jul 15 13:08:03 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 15 Jul 2004 07:08:03 -0400
Subject: [R] formatting tables with long column names via package:xtable
	within Sweave
In-Reply-To: <012821F286ED1D4ABDC72F9E1DD63D0C0361B77B@NLDNC003PEX1.ubsgs.ubsgroup.net>
References: <012821F286ED1D4ABDC72F9E1DD63D0C0361B77B@NLDNC003PEX1.ubsgs.ubsgroup.net>
Message-ID: <20040715110803.GA27009@psych>

On 07/15/04 11:07, john.gavin at ubs.com wrote:
>Hi,
>
>I use the excellent Sweave tools for writing documents
>but was wondering how to neatly print a data.frame
>with long column headings.
>I cant manage to do this via package:xtable.

I think a problem with xtable is this:

> xtable(d1,align=c("|l|","c","c","c","c|"))
Error in "align<-.xtable"(`*tmp*`, value = switch(1 +
is.null(align),  : 
		 "align" must be containing elements of
		 {"r","l","c"}

So the align attribute won't accept p(1cm) either, for example,
but this might not be the best solution anyway.  It seems just as
easy to modify your table after xtable makes it than to modify
xtable to allow such things, since xtable would not save you any
typing time.  You could stick in your long headers using
\multicolumn{1}{p(2cm)}{blah blah blah}, or \parbox{}, or just
use two rows.  (I haven't tested any of this.)

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From ramasamy at cancer.org.uk  Thu Jul 15 13:17:13 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 15 Jul 2004 12:17:13 +0100
Subject: [R] Newbie
In-Reply-To: <002d01c46a58$435a6380$a40f6850@paolo>
References: <002d01c46a58$435a6380$a40f6850@paolo>
Message-ID: <1089890233.3044.5.camel@vpn202001.lif.icnet.uk>

> library("sm")
> x <- ask("Enter a number")
Enter a number: 5
> x
[1] 5



On Thu, 2004-07-15 at 11:41, Paolo Covelli wrote:
> Hi, 
> 
> I wish build a R-script (or a  R-function) that read a number from the keyboard and then process it.
> For example: from R I load the function X, that ask me the level of confidence "\alpha", by keyboard I write 5 and the function go on.
> 
> Thanks in advance
> 
> Paolo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From john_hendrickx at yahoo.com  Thu Jul 15 14:02:31 2004
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Thu, 15 Jul 2004 05:02:31 -0700 (PDT)
Subject: [R] indexing a parameter in nls
Message-ID: <20040715120231.8995.qmail@web52709.mail.yahoo.com>

I'm trying to estimate a "diagonal reference model" in nls. In its
basic form, the model consists of two factors with equal categories
and a dependent variable. The model fits the main effects of the two
factors such that they are proportional to each other. So the model I
want to fit is:

Y=p*m[f1]+(1-p)*m[f2]

The m-parameters indicate the "average" main effect of factors f1 and
f2 (with no intercept). The p-parameter indicates the relative impact
of the two factors on Y. If p=.5, f1 and f2 have equal impact, for
p>.5, f1 has greater impact, for p<.5 f2 has greater impact. 

I can estimate the model as follows for f1="row", f2="col",
Y="nkids":

rd<-model.matrix(~as.factor(row)-1)
cd<-model.matrix(~as.factor(col)-1)

strt<-list(m1=2,m2=2,m3=2,m4=2,m5=3,p=.5)

nls(nkids~p*(rd[,1]*m1+rd[,2]*m2+rd[,3]*m3+rd[,4]*m4+rd[,5]*m5) +
      (1-p)*(cd[,1]*m1+cd[,2]*m2+cd[,3]*m3+cd[,4]*m4+cd[,5]*m5),
      start=strt)
---

What I want however, is a more compact specification, where "row" and
"col" are used to index which m-parameter should be used, something
like:

nls(nkids~p*strt[row]+(1-p)*strt[col],start=strt)

This specification produces an error: "Error in nlsModel(formula, mf,
start) : singular gradient matrix at initial parameter estimates". I
suspect the problem is that "strt[row]" evaluates to a list of
starting values rather than the object names m1, m2, etc. I've tried

nls(nkids~p*get(names(strt[row]))+(1-p)*get(names(strt[col])),start=strt)

But this produces an error as well: "Error in qr.qty(QR, resid) : qr
and y must have the same number of rows"

Can anyone point me in the right direction? How can I use "row" and
"col" to index the appropriate "m" parameter in this model?



From ggrothendieck at myway.com  Thu Jul 15 14:15:12 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 15 Jul 2004 12:15:12 +0000 (UTC)
Subject: [R] (Newbie) scope of with()
References: <Pine.LNX.4.44.0407150825000.1865-100000@ws7.dogbert.ntt.it>
Message-ID: <loom.20040715T134052-322@post.gmane.org>


You could copy them back out at the end of your with like this:

   data(iris) # fetch test data
   with(iris, {
      Sepal.Length[Sepal.Length > 5] <- 5
      Sepal.Width <- Sepal.Width + 10
      for(n in names(iris)) iris[n] <<- get(n)
   } )

Antonio Prioglio <a.prioglio <at> city.ac.uk> writes:

: 
: Hi list,
: As I understand statements within with() are local to what is enclosed 
: within its expression.
: 
: As some excellent examples given to me previously have illustrated it is 
: nevertheless possible to assign the evaluation of an expression to an 
: external variable like x <- with(data, if(..))
: 
: During a "normalisation" phase of data read from a database I have a long 
: list of statements of the type
: participant$longfieldname[is.na(participant$longfieldname)]<-expr(...)
: or similar that makes cumbersome reading. (participant is a table of 
: demographic data)
: 
: If there a neat way to do something of the sort
: "participant<-with(participant,{...})"
: 
: it would make nicer reading.
: 
: Apparently attach(), detach() would not do as
: fieldname<-expr(fieldname)
: creates a new variable and not a change to the value of the field!
: 
: Saluti,
: Antonio Prioglio
:



From deepayan at stat.wisc.edu  Thu Jul 15 14:11:32 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 15 Jul 2004 07:11:32 -0500
Subject: [R] (Newbie) scope of with()
In-Reply-To: <Pine.LNX.4.44.0407150825000.1865-100000@ws7.dogbert.ntt.it>
References: <Pine.LNX.4.44.0407150825000.1865-100000@ws7.dogbert.ntt.it>
Message-ID: <200407150711.32467.deepayan@stat.wisc.edu>

On Thursday 15 July 2004 03:01, Antonio Prioglio wrote:
> Hi list,
> As I understand statements within with() are local to what is
> enclosed within its expression.
>
> As some excellent examples given to me previously have illustrated it
> is nevertheless possible to assign the evaluation of an expression to
> an external variable like x <- with(data, if(..))
>
> During a "normalisation" phase of data read from a database I have a
> long list of statements of the type
> participant$longfieldname[is.na(participant$longfieldname)]<-expr(...
>) or similar that makes cumbersome reading. (participant is a table of
> demographic data)
>
> If there a neat way to do something of the sort
> "participant<-with(participant,{...})"

You may want to take a look at ?transform

Deepayan



From i.visser at uva.nl  Thu Jul 15 15:09:06 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Thu, 15 Jul 2004 15:09:06 +0200
Subject: [R] Permutations
In-Reply-To: <BAY15-F3FD4LXfKCzxg00042002@hotmail.com>
Message-ID: <BD1C4E92.4A69%i.visser@uva.nl>

On 7/14/04 7:42 PM, "Jordi Altirriba Guti??rrez" <altirriba at hotmail.com>
wrote:

> 4 5 6 | 2 1 3 | 7 8 9 | 10 11 12   NO ----because it's an "intra-block"
> permutation of permutation 3
>          -  -
> 10 1 7 | 4 8 7 | 5 6 12 | 3 2 9    YES---Xth permutation
> 
> 1 10 7 | 4 8 7 | 5 6 12 | 3 2 9    NO ----because it's an
> "intra-block"permutation of permutation X
> -   -
> 
> So, what is a "not correct" permutation is an "intra-block" permutation of a
> permutation created before.
> 
> Again, thanks for your time and suggestions,

Hi Jordi, 

If it is allowed to combine permutations then allowing inter block
permutations will generate all possible permutations:

eg
1 2 3 | 4 5 6 
1 4 3 | 2 5 6
2 4 3 | 1 5 6
2 1 3 | 4 5 6

According to your inter- and intra-block permissions, this sequence is
allowed but the result is not ...

best, ingmar



From jfox at mcmaster.ca  Thu Jul 15 16:09:46 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Jul 2004 10:09:46 -0400
Subject: [R] contriburl argument to install.packages
Message-ID: <20040715140948.PSXD6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear list members,

I can't figure out how to specify the contriburl argument to
install.packages() properly when the packages to be installed are in a
directory on my local machine. I have in mind a command something like

	install.packages(missing.packages, contriburl=directory,
lib=.libPaths()[1])

Where missing.packages is a character vector of package names (without
versions) and directory is the location where they reside (less PACKAGES, I
guess). I'm using R version 1.9.1 on a Windows XP machine. Several
variations on directory <- "file:c:/temp" don't seem to work.

Any help would be appreciated.

John



From macq at llnl.gov  Thu Jul 15 16:19:42 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 15 Jul 2004 07:19:42 -0700
Subject: [R] Newbie
In-Reply-To: <002d01c46a58$435a6380$a40f6850@paolo>
References: <002d01c46a58$435a6380$a40f6850@paolo>
Message-ID: <p0600200abd1c42cdbc6a@[128.115.153.6]>

Also,

   readline()

-Don

At 12:41 PM +0200 7/15/04, Paolo Covelli wrote:
>Hi,
>
>I wish build a R-script (or a  R-function) that read a number from 
>the keyboard and then process it.
>For example: from R I load the function X, that ask me the level of 
>confidence "\alpha", by keyboard I write 5 and the function go on.
>
>Thanks in advance
>
>Paolo
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From rpeng at jhsph.edu  Thu Jul 15 16:29:48 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 15 Jul 2004 10:29:48 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <20040715140948.PSXD6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <20040715140948.PSXD6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <40F694DC.9070700@jhsph.edu>

Would this work for you?

install.packages(pathtopackagezipfile, CRAN = NULL)

Although, you can only do one at a time, I think.

-roger

John Fox wrote:
> Dear list members,
> 
> I can't figure out how to specify the contriburl argument to
> install.packages() properly when the packages to be installed are in a
> directory on my local machine. I have in mind a command something like
> 
> 	install.packages(missing.packages, contriburl=directory,
> lib=.libPaths()[1])
> 
> Where missing.packages is a character vector of package names (without
> versions) and directory is the location where they reside (less PACKAGES, I
> guess). I'm using R version 1.9.1 on a Windows XP machine. Several
> variations on directory <- "file:c:/temp" don't seem to work.
> 
> Any help would be appreciated.
> 
> John
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dtrenkler at nts6.oec.uni-osnabrueck.de  Thu Jul 15 16:59:53 2004
From: dtrenkler at nts6.oec.uni-osnabrueck.de (Trenkler, Dietrich)
Date: Thu, 15 Jul 2004 16:59:53 +0200
Subject: [R] GHK simulator
Message-ID: <FB75CFC167F3D311B11D00A0CC20FB0E88553B@nts7.oec.Uni-Osnabrueck.DE>

Dear R-community,

not to re-invent the wheel I wonder if someone of you
has ever written a function to compute the GHK smooth recursive
simulator to estimate multivariate normal probabilities. See for instance
page 194 of

@BOOK{Greene97,
  author = {William H. Greene},
  year = 1997,
  title = {Econometric Analysis},
  edition = {3rd},
  publisher = {Prentice-Hall},
  address = {New Jersey 07458}
}


Thank you.           

Dietrich Trenkler

--
Dietrich Trenkler   Universit??t Osnabr??ck                                  
FB Wirtschaftswissenschaften           
Rolandstr.8              D-49069 Osnabr??ck

dtrenkler at nts6.oec.uni-osnabrueck.de



From dmurdoch at pair.com  Thu Jul 15 16:55:33 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 15 Jul 2004 10:55:33 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <20040715140948.PSXD6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <20040715140948.PSXD6357.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <d26df0d9l2fsfadnu8oqpg023fpavtki35@4ax.com>

On Thu, 15 Jul 2004 10:09:46 -0400, "John Fox" <jfox at mcmaster.ca>
wrote :

>Dear list members,
>
>I can't figure out how to specify the contriburl argument to
>install.packages() properly when the packages to be installed are in a
>directory on my local machine. I have in mind a command something like
>
>	install.packages(missing.packages, contriburl=directory,
>lib=.libPaths()[1])
>
>Where missing.packages is a character vector of package names (without
>versions) and directory is the location where they reside (less PACKAGES, I
>guess). I'm using R version 1.9.1 on a Windows XP machine. Several
>variations on directory <- "file:c:/temp" don't seem to work.
>
>Any help would be appreciated.

You need a file called PACKAGES in the same directory as the packages,
which contains the package information; for example

 http://www.cran.mirrors.pair.com/bin/windows/contrib/1.9/PACKAGES

I imagine the CRAN maintainers have scripts to produce this from the
package files, but I'm not sure where they are.

To refer to a local version of this file, use the syntax you had, e.g.

 CRAN.packages(contriburl="file:c:/temp")

will look for c:/temp/PACKAGES and display the information in it.  

If you don't want to maintain this file, then you can construct the
information in it using the "available=" argument to the package
functions.

Duncan



From jfox at mcmaster.ca  Thu Jul 15 17:02:27 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Jul 2004 11:02:27 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <40F694DC.9070700@jhsph.edu>
Message-ID: <20040715150229.EMEJ13900.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Roger, 

> -----Original Message-----
> From: Roger D. Peng [mailto:rpeng at jhsph.edu] 
> Sent: Thursday, July 15, 2004 9:30 AM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] contriburl argument to install.packages
> 
> Would this work for you?
> 
> install.packages(pathtopackagezipfile, CRAN = NULL)
> 

This doesn't work for me since it requires that one to include the version
part of the file name.

Thanks,
 John

> Although, you can only do one at a time, I think.
> 
> -roger
> 
> John Fox wrote:
> > Dear list members,
> > 
> > I can't figure out how to specify the contriburl argument to
> > install.packages() properly when the packages to be 
> installed are in a 
> > directory on my local machine. I have in mind a command 
> something like
> > 
> > 	install.packages(missing.packages, contriburl=directory,
> > lib=.libPaths()[1])
> > 
> > Where missing.packages is a character vector of package 
> names (without
> > versions) and directory is the location where they reside (less 
> > PACKAGES, I guess). I'm using R version 1.9.1 on a Windows 
> XP machine. 
> > Several variations on directory <- "file:c:/temp" don't 
> seem to work.
> > 
> > Any help would be appreciated.
> > 
> > John
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >



From jfox at mcmaster.ca  Thu Jul 15 17:05:43 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Jul 2004 11:05:43 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <d26df0d9l2fsfadnu8oqpg023fpavtki35@4ax.com>
Message-ID: <20040715150545.UDNA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Duncan, 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> Sent: Thursday, July 15, 2004 9:56 AM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] contriburl argument to install.packages
> 
> On Thu, 15 Jul 2004 10:09:46 -0400, "John Fox" 
> <jfox at mcmaster.ca> wrote :
> 
> >Dear list members,
> >
> >I can't figure out how to specify the contriburl argument to
> >install.packages() properly when the packages to be 
> installed are in a 
> >directory on my local machine. I have in mind a command 
> something like
> >
> >	install.packages(missing.packages, contriburl=directory,
> >lib=.libPaths()[1])
> >
> >Where missing.packages is a character vector of package 
> names (without
> >versions) and directory is the location where they reside (less 
> >PACKAGES, I guess). I'm using R version 1.9.1 on a Windows 
> XP machine. 
> >Several variations on directory <- "file:c:/temp" don't seem to work.
> >
> >Any help would be appreciated.
> 
> You need a file called PACKAGES in the same directory as the 
> packages, which contains the package information; for example
> 
>  http://www.cran.mirrors.pair.com/bin/windows/contrib/1.9/PACKAGES
> 
> I imagine the CRAN maintainers have scripts to produce this 
> from the package files, but I'm not sure where they are.
> 
> To refer to a local version of this file, use the syntax you had, e.g.
> 
>  CRAN.packages(contriburl="file:c:/temp")
> 
> will look for c:/temp/PACKAGES and display the information in it.  
> 

I had already tried this, and it doesn't appear to work for me. For example,

	> CRAN.packages(contriburl="file:c:/temp")
	Error in file(file, "r") : unable to open connection
	In addition: Warning message: 
	cannot open file `c:/temp/PACKAGES' 

I *do* have a directory c:\temp\PACKAGES

Regards,
 John



> If you don't want to maintain this file, then you can 
> construct the information in it using the "available=" 
> argument to the package functions.
> 
> Duncan



From dmurdoch at pair.com  Thu Jul 15 17:11:53 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 15 Jul 2004 11:11:53 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <20040715150545.UDNA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>
References: <d26df0d9l2fsfadnu8oqpg023fpavtki35@4ax.com>
	<20040715150545.UDNA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <ah7df0d29mtq5uloe0vgj14obdd61jvp3m@4ax.com>

On Thu, 15 Jul 2004 11:05:43 -0400, "John Fox" <jfox at mcmaster.ca>
wrote :

>	> CRAN.packages(contriburl="file:c:/temp")
>	Error in file(file, "r") : unable to open connection
>	In addition: Warning message: 
>	cannot open file `c:/temp/PACKAGES' 
>
>I *do* have a directory c:\temp\PACKAGES

Is that a typo?  PACKAGES is a file, not a directory.  The packages
should be sitting in c:\temp, not in c:\temp\PACKAGES.

Duncan



From solares at unsl.edu.ar  Thu Jul 15 17:28:30 2004
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 15 Jul 2004 12:28:30 -0300 (ART)
Subject: [R] formula
Message-ID: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>

Hi, i 'dont understand how to take a general formula, view this:

x<-1:5
y<-c(0,1,1.7,2,2.1.4)
 dummy<-data.frame(x=x,y=y)
formula<-"y~A*log(x)/log(2)"
formu<-as.formula(formula)
fm<-lm(formu,data=dummy)
Error in eval(expr, envir, enclos) : Object "A" not found

but A is the parameter of fitting, why is this?Thanks Ruben



From anne.piotet at urbanet.ch  Thu Jul 15 17:50:17 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Thu, 15 Jul 2004 17:50:17 +0200
Subject: [R] color scale to label a plot
Message-ID: <007e01c46a83$6dbcdb50$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040715/955fb4d0/attachment.pl

From vito_ricci at yahoo.com  Thu Jul 15 17:58:01 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Thu, 15 Jul 2004 17:58:01 +0200 (CEST)
Subject: [R] Formula
Message-ID: <20040715155801.64051.qmail@web41215.mail.yahoo.com>

The '*' operator denotes factor crossing: 'a*b'
interpreted as 'a+b+a:b'
read ? formula.
Best
Vito

Hi, i 'dont understand how to take a general formula,
view this:

x<-1:5
y<-c(0,1,1.7,2,2.1.4)
 dummy<-data.frame(x=x,y=y)
formula<-"y~A*log(x)/log(2)"
formu<-as.formula(formula)
fm<-lm(formu,data=dummy)
Error in eval(expr, envir, enclos) : Object "A" not
found

but A is the parameter of fitting, why is this?Thanks
Ruben


 The '*' operator denotes factor crossing:
     'a*b' interpreted as 'a+b+a:b'

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From ltorgo at liacc.up.pt  Thu Jul 15 18:04:57 2004
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Thu, 15 Jul 2004 17:04:57 +0100
Subject: [R] formula
In-Reply-To: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
References: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
Message-ID: <1089907497.6983.27.camel@nassa.niaad.liacc.up.pt>

On Thu, 2004-07-15 at 16:28, solares at unsl.edu.ar wrote:
> Hi, i 'dont understand how to take a general formula, view this:
> 
> x<-1:5
> y<-c(0,1,1.7,2,2.1.4)
>  dummy<-data.frame(x=x,y=y)
> formula<-"y~A*log(x)/log(2)"
> formu<-as.formula(formula)
> fm<-lm(formu,data=dummy)

You probably meant something similar to this:
> lm(as.formula("y ~ log(x)"),dummy)
 
Call:
lm(formula = as.formula("y ~log(x)"), data = dummy)
 
Coefficients:
(Intercept)       log(x)
     0.0473       1.3793

And your "A" in this case would be 1.3793

Luis Torgo

-- 
Luis Torgo
  FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
  Machine Learning Group           Fax   : (+351) 22 600 36 54
  R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
  4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From ramasamy at cancer.org.uk  Thu Jul 15 18:04:25 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 15 Jul 2004 17:04:25 +0100
Subject: [R] formula
In-Reply-To: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
References: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
Message-ID: <1089907132.3044.30.camel@vpn202001.lif.icnet.uk>

If you want to fit "y = a + bx", then you use "lm(y ~ x)" instead of "lm(y ~ A + bx)". 
See the details section of help("formula").

> x <- 1:5
> y <- c(0, 1.0, 1.7, 2.0, 2.1)
> lm(x ~ y)

Call:
lm(formula = x ~ y)

Coefficients:
(Intercept)            y
     0.6828       1.7038

PS : I think there is a typo in y as there is no such number as 2.1.4


On Thu, 2004-07-15 at 16:28, solares at unsl.edu.ar wrote:
> Hi, i 'dont understand how to take a general formula, view this:
> 
> x<-1:5
> y<-c(0,1,1.7,2,2.1.4)
>  dummy<-data.frame(x=x,y=y)
> formula<-"y~A*log(x)/log(2)"
> formu<-as.formula(formula)
> fm<-lm(formu,data=dummy)
> Error in eval(expr, envir, enclos) : Object "A" not found
> 
> but A is the parameter of fitting, why is this?Thanks Ruben
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Thu Jul 15 18:04:56 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 15 Jul 2004 17:04:56 +0100
Subject: [R] formula
In-Reply-To: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
References: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
Message-ID: <1089907465.3044.35.camel@vpn202001.lif.icnet.uk>

If you want to fit "y = a + bx", then you use "lm(y ~ x)" instead of "lm(y ~ A + bx)". 
See the details section of help("formula").

> x <- 1:5
> y <- c(0, 1.0, 1.7, 2.0, 2.1)
> lm(x ~ y)

Call:
lm(formula = x ~ y)

Coefficients:
(Intercept)            y
     0.6828       1.7038

If A was already defined, and you are trying to multiply the y-values, then use the I() operator.
This protects the term/calculation and inhibits the usual term interpretation in linear models.

> lm(x ~ I(2*y) )

Call:
lm(formula = x ~ I(2 * y))

Coefficients:
(Intercept)     I(2 * y)
     0.6828       0.8519

PS : I think there is a typo in the y input as there is no such number as 2.1.4




On Thu, 2004-07-15 at 16:28, solares at unsl.edu.ar wrote:
> Hi, i 'dont understand how to take a general formula, view this:
> 
> x<-1:5
> y<-c(0,1,1.7,2,2.1.4)
>  dummy<-data.frame(x=x,y=y)
> formula<-"y~A*log(x)/log(2)"
> formu<-as.formula(formula)
> fm<-lm(formu,data=dummy)
> Error in eval(expr, envir, enclos) : Object "A" not found
> 
> but A is the parameter of fitting, why is this?Thanks Ruben
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Thu Jul 15 18:06:07 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 15 Jul 2004 17:06:07 +0100
Subject: [R] formula
In-Reply-To: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
References: <38070.170.210.173.216.1089905310.squirrel@inter17.unsl.edu.ar>
Message-ID: <1089907567.3044.38.camel@vpn202001.lif.icnet.uk>

If you want to fit "y = a + bx", then you use "lm(y ~ x)" instead of "lm(y ~ A + bx)". 
'A' is not a parameter but coefficient and you do not need to specify coefficients, 
which is what the linear model is trying to do anyway !
See the details section of help("formula").

> x <- 1:5
> y <- c(0, 1.0, 1.7, 2.0, 2.1)
> lm(x ~ y)

Call:
lm(formula = x ~ y)

Coefficients:
(Intercept)            y
     0.6828       1.7038

If A was already defined, and you are trying to multiply the y-values, then use the I() operator.
This protects the term/calculation and inhibits the usual term interpretation in linear models.

> lm(x ~ I(2*y) )

Call:
lm(formula = x ~ I(2 * y))

Coefficients:
(Intercept)     I(2 * y)
     0.6828       0.8519

PS : I think there is a typo in the y input as there is no such number as 2.1.4




On Thu, 2004-07-15 at 16:28, solares at unsl.edu.ar wrote:
> Hi, i 'dont understand how to take a general formula, view this:
> 
> x<-1:5
> y<-c(0,1,1.7,2,2.1.4)
>  dummy<-data.frame(x=x,y=y)
> formula<-"y~A*log(x)/log(2)"
> formu<-as.formula(formula)
> fm<-lm(formu,data=dummy)
> Error in eval(expr, envir, enclos) : Object "A" not found
> 
> but A is the parameter of fitting, why is this?Thanks Ruben
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From anne.piotet at urbanet.ch  Thu Jul 15 18:41:54 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Thu, 15 Jul 2004 18:41:54 +0200
Subject: [R] color scale to label a plot
References: <007e01c46a83$6dbcdb50$6c00a8c0@mtd4> <40F6A8DB.EFC25E57@gene.com>
Message-ID: <009701c46a8a$a3d7b370$6c00a8c0@mtd4>

yes..  legend sould help. I still do not know how to paint my color sacle
and put the corresp. labels correctly
Thanks
Anne

----- Original Message ----- 
From: "Berton Gunter" <gunter.berton at gene.com>
To: "Anne" <anne.piotet at urbanet.ch>
Sent: Thursday, July 15, 2004 5:55 PM
Subject: Re: [R] color scale to label a plot


> Do you mean ?legend  ??
>
> On lattice plots, the key= argument controls legends. ?xyplot gives
details.
>
>
>
> --
>
> Bert Gunter
>
> Non-Clinical Biostatistics
> Genentech
> MS: 240B
> Phone: 650-467-7374
>
>
> "The business of the statistician is to catalyze the scientific learning
process."
>
>  -- George E.P. Box
>
>



From maechler at stat.math.ethz.ch  Thu Jul 15 18:42:09 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 Jul 2004 18:42:09 +0200
Subject: [R] color scale to label a plot
In-Reply-To: <007e01c46a83$6dbcdb50$6c00a8c0@mtd4>
References: <007e01c46a83$6dbcdb50$6c00a8c0@mtd4>
Message-ID: <16630.46049.947478.485791@gargle.gargle.HOWL>


>>>>> "Anne" == Anne Piotet <anne.piotet at urbanet.ch>
>>>>>     on Thu, 15 Jul 2004 17:50:17 +0200 writes:

    Anne> Hello R-helpers
    Anne> I want to put a color scale in a plot:
  
    Anne> I've got an xy plot where the values of the response
    Anne> (z=f(x,y)) is symbolically given by colors (like heat
    Anne> or rainbow color scale) I would like to put such a
    Anne> scale with apprpriates labels in the plot, so as to
    Anne> facilitate the interpretation (like in a finite
    Anne> elements result plot) How is taht possible?

Use
         filled.contour()   
or also  image(*); contour(*, add=TRUE)

Martin

  
    Anne> [[alternative HTML version deleted]]
	   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Anne, have you ever tried to get rid of this?  

      --> http://www.R-project.org/mail.html and look for "HTML"

Bonnes salutations de Zurich,
Martin Maechler



From anne.piotet at urbanet.ch  Thu Jul 15 18:44:23 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Thu, 15 Jul 2004 18:44:23 +0200
Subject: [R] color scale to label a plot
References: <007e01c46a83$6dbcdb50$6c00a8c0@mtd4>
	<16630.46049.947478.485791@gargle.gargle.HOWL>
Message-ID: <009e01c46a8a$fc885240$6c00a8c0@mtd4>

Thanks! That is what I was looking for!

Anne

----- Original Message ----- 
From: "Martin Maechler" <maechler at stat.math.ethz.ch>
To: "Anne" <anne.piotet at urbanet.ch>
Cc: "R list" <r-help at stat.math.ethz.ch>
Sent: Thursday, July 15, 2004 6:42 PM
Subject: Re: [R] color scale to label a plot


> 
> >>>>> "Anne" == Anne Piotet <anne.piotet at urbanet.ch>
> >>>>>     on Thu, 15 Jul 2004 17:50:17 +0200 writes:
> 
>     Anne> Hello R-helpers
>     Anne> I want to put a color scale in a plot:
>   
>     Anne> I've got an xy plot where the values of the response
>     Anne> (z=f(x,y)) is symbolically given by colors (like heat
>     Anne> or rainbow color scale) I would like to put such a
>     Anne> scale with apprpriates labels in the plot, so as to
>     Anne> facilitate the interpretation (like in a finite
>     Anne> elements result plot) How is taht possible?
> 
> Use
>          filled.contour()   
> or also  image(*); contour(*, add=TRUE)
> 
> Martin
> 
>   
>     Anne> [[alternative HTML version deleted]]
>    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Anne, have you ever tried to get rid of this?  
> 
>       --> http://www.R-project.org/mail.html and look for "HTML"
> 
> Bonnes salutations de Zurich,
> Martin Maechler
>



From solares at unsl.edu.ar  Thu Jul 15 18:46:29 2004
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 15 Jul 2004 13:46:29 -0300 (ART)
Subject: [R] formula and lm
Message-ID: <40696.170.210.173.216.1089909989.squirrel@inter17.unsl.edu.ar>

Hi, don' t understand why the function fomula have this error, i enclose
the parameter "a" with the function I()
Thank Ruben
 x<-1:5
y<-c(  2  ,4 , 6 , 8 ,11)
formu<-y~I(a*x)
form<-formula(formu)
dummy<-data.frame(x=x,y=y)
fm<-lm(form,data=dummy)
Error in unique(c("AsIs", oldClass(x))) : Object "a" not found



From Charles.Annis at StatisticalEngineering.com  Thu Jul 15 19:02:52 2004
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Thu, 15 Jul 2004 13:02:52 -0400
Subject: [R] color scale to label a plot
In-Reply-To: <009701c46a8a$a3d7b370$6c00a8c0@mtd4>
Message-ID: <200407151702.i6FH2kft010246@hypatia.math.ethz.ch>

Anne:

Perhaps this example will help.  

I have data (several dozen observations at each condition) for different
R=stress.ratio.  The stress.ratios are:

> stress.ratio
 [1] 0.1 0.1 0.1 0.2 0.3 0.5 0.6 0.7 0.8 0.9 0.9 0.9 0.9 0.9 0.9

You will notice multiple datasets for R=0.1 and R=0.9.

I assigned colors to each stress.ratio, such that

 R.color
 [1] "black"      "black"      "black"      "red"        "orange"     "gray"
"green"      "light blue" "blue"       "dark blue" 
[11] "dark blue"  "dark blue"  "dark blue"  "dark blue"  "dark blue" 


Then I plotted the legend on my plot this way:

legend(x.coordinate, y.coordinate, unique(stress.ratio),
col=unique(R.color), pch=15, cex=0.8)

Best wishes.

Charles Annis, P.E.
 
Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  503-217-5849
http://www.StatisticalEngineering.com
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anne
Sent: Thursday, July 15, 2004 12:42 PM
To: r-help at stat.math.ethz.ch; Berton Gunter
Subject: Re: [R] color scale to label a plot

yes..  legend sould help. I still do not know how to paint my color sacle
and put the corresp. labels correctly
Thanks
Anne

----- Original Message ----- 
From: "Berton Gunter" <gunter.berton at gene.com>
To: "Anne" <anne.piotet at urbanet.ch>
Sent: Thursday, July 15, 2004 5:55 PM
Subject: Re: [R] color scale to label a plot


> Do you mean ?legend  ??
>
> On lattice plots, the key= argument controls legends. ?xyplot gives
details.
>
>
>
> --
>
> Bert Gunter
>
> Non-Clinical Biostatistics
> Genentech
> MS: 240B
> Phone: 650-467-7374
>
>
> "The business of the statistician is to catalyze the scientific learning
process."
>
>  -- George E.P. Box
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Thu Jul 15 19:05:57 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Jul 2004 13:05:57 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <ah7df0d29mtq5uloe0vgj14obdd61jvp3m@4ax.com>
Message-ID: <web-54100708@cgpsrv2.cis.mcmaster.ca>

Dear Duncan,

On Thu, 15 Jul 2004 11:11:53 -0400
 Duncan Murdoch <dmurdoch at pair.com> wrote:
> On Thu, 15 Jul 2004 11:05:43 -0400, "John Fox" <jfox at mcmaster.ca>
> wrote :
> 
> >	> CRAN.packages(contriburl="file:c:/temp")
> >	Error in file(file, "r") : unable to open connection
> >	In addition: Warning message: 
> >	cannot open file `c:/temp/PACKAGES' 
> >
> >I *do* have a directory c:\temp\PACKAGES
> 
> Is that a typo?  PACKAGES is a file, not a directory.  The packages
> should be sitting in c:\temp, not in c:\temp\PACKAGES.
> 

It's not a typo, but a misunderstanding on my part (and a failure to
read your last message carefully enough). 

Thanks,
 John

> Duncan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From kbartz at loyaltymatrix.com  Thu Jul 15 19:06:05 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Thu, 15 Jul 2004 10:06:05 -0700
Subject: [R] GHK simulator
In-Reply-To: <FB75CFC167F3D311B11D00A0CC20FB0E88553B@nts7.oec.Uni-Osnabrueck.DE>
Message-ID: <20040715171129.2B2723FD3E@omta16.mta.everyone.net>

Yes. See the mvtnorm package on CRAN. It implements Genz's algorithm, the
fastest method in town. (I have a version I converted to S-PLUS as well, if
you, or anyone, might need it.)

Kevin

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Trenkler, Dietrich
Sent: Thursday, July 15, 2004 8:00 AM
To: 'r-help'
Subject: [R] GHK simulator

Dear R-community,

not to re-invent the wheel I wonder if someone of you
has ever written a function to compute the GHK smooth recursive
simulator to estimate multivariate normal probabilities. See for instance
page 194 of

@BOOK{Greene97,
  author = {William H. Greene},
  year = 1997,
  title = {Econometric Analysis},
  edition = {3rd},
  publisher = {Prentice-Hall},
  address = {New Jersey 07458}
}


Thank you.           

Dietrich Trenkler

--
Dietrich Trenkler   Universit??t Osnabr??ck                                  
FB Wirtschaftswissenschaften           
Rolandstr.8              D-49069 Osnabr??ck

dtrenkler at nts6.oec.uni-osnabrueck.de

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From pcovelli at tin.it  Thu Jul 15 19:39:19 2004
From: pcovelli at tin.it (Paolo Covelli)
Date: Thu, 15 Jul 2004 19:39:19 +0200
Subject: [R] newbie
Message-ID: <005c01c46a92$ab0a1270$9b116850@paolo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040715/4bbae8a5/attachment.pl

From rolf at math.unb.ca  Thu Jul 15 19:51:13 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 15 Jul 2004 14:51:13 -0300 (ADT)
Subject: [R] newbie
Message-ID: <200407151751.i6FHpD8J022872@erdos.math.unb.ca>

Paolo Covelli wrote:

> does it exist a sintax-comand to clear thre console (the screen)?
> I've finded nothing on the standard manuals. (apart from the manual
> comand CTRL+L)

You don't say what operating system you're using .....

Anyhow, as far as I know there is no built-in to clear the screen.
But one is easy to build.  On a Unix system you could do

	cl <- function(){system("clear")}

then executing cl() will clear the screen for you.

On a Windoze system I think replacing ``clear'' by ``cls''
in the definition of cl() should work.

				cheers,

					Rolf Turner



From Mike.Prager at noaa.gov  Thu Jul 15 20:15:28 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 15 Jul 2004 14:15:28 -0400
Subject: [R] Where is global environment?
Message-ID: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>

I am using R 1.9.1 under Windows XP Professional.

Is there any R function that returns the filesystem path from which the 
global environment (workspace) was loaded (and to which it will, by 
default, be saved)?  This seems identical with the current directory, so in 
any given session it is not too difficult to find out by other means.  But 
for several reasons I would like to find this out from within R.

Thanks.


-- 
Michael Prager, Ph.D.
Population Dynamics Team, NMFS SE Fisheries Science Center
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From sundar.dorai-raj at PDF.COM  Thu Jul 15 20:20:14 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 15 Jul 2004 11:20:14 -0700
Subject: [R] Where is global environment?
In-Reply-To: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>
References: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>
Message-ID: <40F6CADE.6040202@pdf.com>



Mike Prager wrote:
> I am using R 1.9.1 under Windows XP Professional.
> 
> Is there any R function that returns the filesystem path from which the 
> global environment (workspace) was loaded (and to which it will, by 
> default, be saved)?  This seems identical with the current directory, so 
> in any given session it is not too difficult to find out by other 
> means.  But for several reasons I would like to find this out from 
> within R.
> 
> Thanks.
> 
> 

Is ?getwd suitable?

--sundar



From Mike.Prager at noaa.gov  Thu Jul 15 20:22:12 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 15 Jul 2004 14:22:12 -0400
Subject: [R] dput and dget
Message-ID: <6.1.0.6.2.20040715141812.01e6eb20@hermes.nos.noaa.gov>

I am seeking advice about dput() and dget().

We are using the ascii format supported by these functions as a way to 
write data from other programs that can be read into R easily.  We are able 
to save complicated results (in the form of an R list) to a single file 
that can be read trivially into R or S-Plus.

My question is whether that format can be considered a safe one for 
medium-term (say 10 years) data storage. Assuming R is still used then 
(which I suppose will be true), will "dget" work with old files?

Thanks!

Mike Prager



From ramasamy at cancer.org.uk  Thu Jul 15 20:25:59 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 15 Jul 2004 19:25:59 +0100
Subject: [R] Where is global environment?
In-Reply-To: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>
References: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>
Message-ID: <1089915959.3064.56.camel@localhost.localdomain>

getwd(), setwd()

On Thu, 2004-07-15 at 19:15, Mike Prager wrote:
> I am using R 1.9.1 under Windows XP Professional.
> 
> Is there any R function that returns the filesystem path from which the 
> global environment (workspace) was loaded (and to which it will, by 
> default, be saved)?  This seems identical with the current directory, so in 
> any given session it is not too difficult to find out by other means.  But 
> for several reasons I would like to find this out from within R.
> 
> Thanks.
>



From Mike.Prager at noaa.gov  Thu Jul 15 20:27:54 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 15 Jul 2004 14:27:54 -0400
Subject: [R] Where is global environment?
In-Reply-To: <40F6CADE.6040202@pdf.com>
References: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>
	<40F6CADE.6040202@pdf.com>
Message-ID: <6.1.0.6.2.20040715142432.01e68430@hermes.nos.noaa.gov>


>>I am using R 1.9.1 under Windows XP Professional.
>>Is there any R function that returns the filesystem path from which the 
>>global environment (workspace) was loaded (and to which it will, by 
>>default, be saved)?  This seems identical with the current directory, so 
>>in any given session it is not too difficult to find out by other 
>>means.  But for several reasons I would like to find this out from within R.
>
>Is ?getwd suitable?

Yes!   My thanks to Sundar Dorai-Raj, Rolf Turner, and Chuck Cleland for 
supplying the answer within minutes of my query.

(I had tried pwd(), cwd(), and so on, and tried looking in the help. It 
*can* be hard to find things sometimes....)

Mike



From HermanD at intra.nimh.nih.gov  Thu Jul 15 20:35:08 2004
From: HermanD at intra.nimh.nih.gov (Herman, David (NIH/NIMH))
Date: Thu, 15 Jul 2004 14:35:08 -0400
Subject: [R] row naming
Message-ID: <5F9DE1C25708B04EAD634A1AE3D91130049DD7EC@nihexchange20.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040715/67e42644/attachment.pl

From f.calboli at ucl.ac.uk  Thu Jul 15 20:35:12 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Thu, 15 Jul 2004 20:35:12 +0200
Subject: [R] how to upload [forwarded]
Message-ID: <16630.52832.917819.872118@gargle.gargle.HOWL>

[ This was posted to the R-packages list (which I moderate), 
  but definitely doesn't belong there.  Martin Maechler 
]

------- start of forwarded message -------
From: Federico Calboli <f.calboli at ucl.ac.uk>
To: r-packages at stat.math.ethz.ch
Subject: how to upload
Date: 15 Jul 2004 18:30:26 +0100

Dear All,

I just finished a add on lib called Malmig, to calculate Malecot
migration model and associated functions. I am meant, according to
R-exts, to upload the tar.gz at:

ftp://ftp.ci.tuwien.ac.at/incoming

How? never uploaded anything in my life.

Cheers,
Federico Calboli

=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it
------- end of forwarded message -------



From dmurdoch at pair.com  Thu Jul 15 20:41:16 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 15 Jul 2004 14:41:16 -0400
Subject: [R] Where is global environment?
In-Reply-To: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>
References: <6.1.0.6.2.20040715141006.01e795e0@hermes.nos.noaa.gov>
Message-ID: <m9jdf09gkhp5vsdhclfb6jojshh4rnpar4@4ax.com>

On Thu, 15 Jul 2004 14:15:28 -0400, "Mike Prager"
<Mike.Prager at noaa.gov> wrote :

>I am using R 1.9.1 under Windows XP Professional.
>
>Is there any R function that returns the filesystem path from which the 
>global environment (workspace) was loaded (and to which it will, by 
>default, be saved)?  This seems identical with the current directory, so in 
>any given session it is not too difficult to find out by other means.  But 
>for several reasons I would like to find this out from within R.

I don't think R can do that reliably.  Appendix B of the Intro manual
describes the startup sequence.  .RData generally comes from the
current directory, but that's not necessarily the same at the time you
test as it was when R started.

Duncan Murdoch



From Mike.Prager at noaa.gov  Thu Jul 15 20:45:41 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 15 Jul 2004 14:45:41 -0400
Subject: [R] More on global environment
Message-ID: <6.1.0.6.2.20040715143759.01e91668@hermes.nos.noaa.gov>

To follow up on my previous question, suppose a user R session wants to 
unload one workspace and load another within an R session.  Is the 
following the correct sequence?

1.  save.image() to save the current workspace as .Rdata in the current 
working directory.
2.  rm(list=ls()) to remove everything from the workspace.
3.  setcwd("xxx") to set the new working directory.
4.  load(".Rdata") to load the new workspace.


-- 
Michael Prager, Ph.D.
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From dmurdoch at pair.com  Thu Jul 15 20:57:35 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 15 Jul 2004 14:57:35 -0400
Subject: [R] dput and dget
In-Reply-To: <6.1.0.6.2.20040715141812.01e6eb20@hermes.nos.noaa.gov>
References: <6.1.0.6.2.20040715141812.01e6eb20@hermes.nos.noaa.gov>
Message-ID: <g0kdf0d2kltdsgrmtgurbe7bulelucv43c@4ax.com>

On Thu, 15 Jul 2004 14:22:12 -0400, "Mike Prager"
<Mike.Prager at noaa.gov> wrote :

>I am seeking advice about dput() and dget().
>
>We are using the ascii format supported by these functions as a way to 
>write data from other programs that can be read into R easily.  We are able 
>to save complicated results (in the form of an R list) to a single file 
>that can be read trivially into R or S-Plus.
>
>My question is whether that format can be considered a safe one for 
>medium-term (say 10 years) data storage. Assuming R is still used then 
>(which I suppose will be true), will "dget" work with old files?

I don't think dput alone is a very safe data storage strategy, but it
depends on what sorts of things you are storing.  For numerical or
character data in lists and data frames, it's probably perfectly safe.
For more complicated things (e.g. results of an analysis), it may not
be.  I'd recommend saving both as a dump and in a binary image.

The problem is that dput() in 1.9.x does not do a very complete job of
deparsing, and there are many objects for which dput followed by dget
changes the object. (Version 2 will be a tiny bit better by default,
and will have an option to be reasonably good, but there are still
some exotic objects which can't be dumped at all.  dump() will by
default do a better job.)

Assuming you've got a relatively simple object which can be dumped
correctly now, there might be changes to the syntax that mean dget
won't work.  Recent changes like that include the move of "_" from
being an assignment operator to being legal in object names.  There
are some aspects of R syntax that are still described as experimental
("::", ":::" come to mind); those might not be supported 10 years from
now.

For more complicated objects, I'd guess that binary images saved by
save() are safer.  Whenever the binary image format changes, there
will be an effort to make sure older images can still be read.  But
it's likely that only R is going to be able to read binary images, and
10 years from now you might be using some other program:  so you want
the dump as well.

Duncan Murdoch



From Mike.Prager at noaa.gov  Thu Jul 15 21:01:53 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 15 Jul 2004 15:01:53 -0400
Subject: [R] row naming
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7EC@nihexchange20.nih .gov>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7EC@nihexchange20.nih.gov>
Message-ID: <6.1.0.6.2.20040715145605.01e4e6a0@hermes.nos.noaa.gov>

At 7/15/2004 02:35 PM Thursday, you wrote:
>Hello,
>             If I have a four column data set (with thousands of rows), that
>doesn't have a header, how do I load in this text file, WITHOUT a row added
>for naming(i.e. numbering the rows, 1 2 3 4 5......).
>Also, if a row is added for naming, then will it be actually included in the
>data? That is, will that numbered row be included in analysis I run? (like
>PCA)

I assume you really mean "a column added for naming the rows".  My 
understanding is that data frames always have row names, but matrices do 
not.  If memory is limiting (probably not), you could read the data into a 
matrix instead of a data frame.

To answer your other question, row names are NOT included in any 
analysis.  They are saved as character strings anyway, not numbers.

MHP



From rpeng at jhsph.edu  Thu Jul 15 21:06:18 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 15 Jul 2004 15:06:18 -0400
Subject: [R] More on global environment
In-Reply-To: <6.1.0.6.2.20040715143759.01e91668@hermes.nos.noaa.gov>
References: <6.1.0.6.2.20040715143759.01e91668@hermes.nos.noaa.gov>
Message-ID: <40F6D5AA.5010904@jhsph.edu>

That seems reasonable, although you might use

rm(list = ls(all.names = TRUE))

if you are interested in removing objects whose names begin with a period.

-roger

Mike Prager wrote:
> To follow up on my previous question, suppose a user R session wants to 
> unload one workspace and load another within an R session.  Is the 
> following the correct sequence?
> 
> 1.  save.image() to save the current workspace as .Rdata in the current 
> working directory.
> 2.  rm(list=ls()) to remove everything from the workspace.
> 3.  setcwd("xxx") to set the new working directory.
> 4.  load(".Rdata") to load the new workspace.
> 
>



From kbartz at loyaltymatrix.com  Thu Jul 15 21:05:40 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Thu, 15 Jul 2004 12:05:40 -0700
Subject: [R] row naming
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7EC@nihexchange20.nih.gov>
Message-ID: <20040715191104.4DBBB40155@omta18.mta.everyone.net>

The rownames of a data.frame are there for reference; they are not
considered a column in your data set and will not be included in any
analyses. The short answer as to whether you should try to remove them is
no. To read in the file, use read.table(file, header=F), as you probably
already discovered.

Kevin

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Herman, David
(NIH/NIMH)
Sent: Thursday, July 15, 2004 11:35 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] row naming

Hello,
            If I have a four column data set (with thousands of rows), that
doesn't have a header, how do I load in this text file, WITHOUT a row added
for naming(i.e. numbering the rows, 1 2 3 4 5......).
Also, if a row is added for naming, then will it be actually included in the
data? That is, will that numbered row be included in analysis I run? (like
PCA)
 
 
Thanks!
 

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Thu Jul 15 21:23:49 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 15 Jul 2004 15:23:49 -0400
Subject: [R] More on global environment
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8058@usrymx25.merck.com>

I've posted the following to R-help before.  Hope it helps you.

cd <- function(dir = tclvalue(tkchooseDirectory()), saveOld=FALSE,
               loadNew=TRUE) {
    stopifnot(require(tcltk))
    if (saveOld) save.image(compress=TRUE)
    setwd(dir)
    rm(list=ls(all=TRUE, envir=.GlobalEnv), envir=.GlobalEnv)
    if (loadNew && file.exists(".RData")) {
        loaded <- load(".RData", envir=.GlobalEnv)
        return(invisible(loaded))
    }
}

[The tcltk part is based on Prof. Fox's help.]

Andy

> From: Mike Prager
> 
> To follow up on my previous question, suppose a user R 
> session wants to 
> unload one workspace and load another within an R session.  Is the 
> following the correct sequence?
> 
> 1.  save.image() to save the current workspace as .Rdata in 
> the current 
> working directory.
> 2.  rm(list=ls()) to remove everything from the workspace.
> 3.  setcwd("xxx") to set the new working directory.
> 4.  load(".Rdata") to load the new workspace.
> 
> 
> -- 
> Michael Prager, Ph.D.
> NOAA Center for Coastal Fisheries and Habitat Research
> Beaufort, North Carolina  28516
> http://shrimp.ccfhrb.noaa.gov/~mprager/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From Mike.Prager at noaa.gov  Thu Jul 15 21:36:06 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 15 Jul 2004 15:36:06 -0400
Subject: [R] More on global environment
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8058@usrymx25.merck.co
 m>
References: <3A822319EB35174CA3714066D590DCD504AF8058@usrymx25.merck.com>
Message-ID: <6.1.0.6.2.20040715153313.01eb66f8@hermes.nos.noaa.gov>

At 7/15/2004 03:23 PM Thursday, Andy Liaw wrote:
>I've posted the following to R-help before.  Hope it helps you.
>
>cd <- function(dir = tclvalue(tkchooseDirectory()), saveOld=FALSE,
>                loadNew=TRUE) {
>     stopifnot(require(tcltk))

         flush.console()

>     if (saveOld) save.image(compress=TRUE)
>     setwd(dir)
>     rm(list=ls(all=TRUE, envir=.GlobalEnv), envir=.GlobalEnv)
>     if (loadNew && file.exists(".RData")) {
>         loaded <- load(".RData", envir=.GlobalEnv)
>         return(invisible(loaded))
>     }
>}
>
>[The tcltk part is based on Prof. Fox's help.]
>
>Andy

Thanks!  It's lovely.  I added the call to flush.console() as shown, which 
(under Windows RGUI at least) issues the message that tcl is loading in a 
more timely way.

Mike



From spencer.graves at pdf.com  Thu Jul 15 22:02:00 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 15 Jul 2004 13:02:00 -0700
Subject: [R] formula and lm
In-Reply-To: <40696.170.210.173.216.1089909989.squirrel@inter17.unsl.edu.ar>
References: <40696.170.210.173.216.1089909989.squirrel@inter17.unsl.edu.ar>
Message-ID: <40F6E2B8.9080209@pdf.com>

It wants to compute a*x given a and x, and then use ordinarly least 
squares to estimate b0 and b1 in y = b0 + b1*I(a*x).  If that is what 
you intend, you must supply a.  If you want to estimate a, e.g., with no 
constant, use   y~x-1.  Does this answer the question?  hope this 
helps.  spencer graves

solares at unsl.edu.ar wrote:

>Hi, don' t understand why the function fomula have this error, i enclose
>the parameter "a" with the function I()
>Thank Ruben
> x<-1:5
>y<-c(  2  ,4 , 6 , 8 ,11)
>formu<-y~I(a*x)
>form<-formula(formu)
>dummy<-data.frame(x=x,y=y)
>fm<-lm(form,data=dummy)
>Error in unique(c("AsIs", oldClass(x))) : Object "a" not found
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Thu Jul 15 22:18:43 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 15 Jul 2004 16:18:43 -0400
Subject: [R] adding option in the Windows installer for --internet2
Message-ID: <3A822319EB35174CA3714066D590DCD504AF805D@usrymx25.merck.com>

[Not sure if such wishlist item should go to R-help or R-devel...]

It would be nice if an option can be added to the R for Windows installer
that will add the --internet2 option to the command line in the shortcut
that gets created.  Also, is it possible to make that an option that can be
set at the R prompt, or perhaps even better, as the default no matter
how/where R is started?  For those of us behind corporate firewalls, life
w/o --internet2 is not terribly pleasant, and na??ve users are too na??ve to
remember that...

Best,
Andy

Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw at merck.com        732-594-0820



From kjetil at acelerate.com  Thu Jul 15 17:47:58 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Thu, 15 Jul 2004 11:47:58 -0400
Subject: [R] table lookup n R
References: <000a01c468d5$b7512e10$6c00a8c0@mtd4>
Message-ID: <40F6A72E.6070409@acelerate.com>

?match
%in%

Kjetil Halvorsen

Anne wrote:

>Hello R helpers!
>I looked  but did not find a table-lookup R-utility. I could use a loop to do the job (old FORTRAN/C habits die hard) but if I have a big table in which I have to search for the values corresponding to a vector, I end up logically with a double loop.
>Is there already such a utility? Otherwise, is there a way without loops?
>
>Thanks as always
>Anne
>----------------------------------------------------
>Anne Piotet
>Tel: +41 79 359 83 32 (mobile)
>Email: anne.piotet at m-td.com
>---------------------------------------------------
>M-TD Modelling and Technology Development
>PSE-C
>CH-1015 Lausanne
>Switzerland
>Tel: +41 21 693 83 98
>Fax: +41 21 646 41 33
>--------------------------------------------------
> 
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From rpiper at med.usyd.edu.au  Thu Jul 15 22:47:23 2004
From: rpiper at med.usyd.edu.au (Richard Piper)
Date: Fri, 16 Jul 2004 06:47:23 +1000
Subject: [R] Eclipse plugin for R or perhaps S-plus. 
Message-ID: <40F6ED5B.1080904@med.usyd.edu.au>

Does any one know of an eclipse (http://eclipse.org) plugin for R/S.

thanks

RIchard

-- 
Richard Piper

Web: http://icu.rnsh.org
Mobile: 0438-120860
Sydney: 9926-8617
Kippax: 6550-5117
Email: rpiper at med.usyd.edu.au

GPG key ID: F6DFFB33 @ wwwkeys.pgp.net
Key fingerprint: 3FB8 8355 3AAA 84C3 D548  8FFF EFDB C6B5 F6DF FB33



From dmurdoch at pair.com  Thu Jul 15 22:51:06 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 15 Jul 2004 16:51:06 -0400
Subject: [R] adding option in the Windows installer for --internet2
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF805D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF805D@usrymx25.merck.com>
Message-ID: <ttqdf0hhhf5iphqseml3qs9lgau6qrhok4@4ax.com>

On Thu, 15 Jul 2004 16:18:43 -0400, "Liaw, Andy" <andy_liaw at merck.com>
wrote :

>[Not sure if such wishlist item should go to R-help or R-devel...]
>
>It would be nice if an option can be added to the R for Windows installer
>that will add the --internet2 option to the command line in the shortcut
>that gets created.  Also, is it possible to make that an option that can be
>set at the R prompt, or perhaps even better, as the default no matter
>how/where R is started?  For those of us behind corporate firewalls, life
>w/o --internet2 is not terribly pleasant, and na??ve users are too na??ve to
>remember that...

It would be easy to put there, but I can't for the life of me figure
out how I would document it.  If a user is too naive to know to use it
when running R, how would they know which choice to make when
installing it?

Alternatively, if you know a test that could determine whether
--internet2 is desirable, perhaps the installer could use that.

As to the idea of switching at the R prompt or as a global
configuration option:  those are probably possible, possibly tricky,
patches to do them will be considered.

Duncan Murdoch



From ramasamy at cancer.org.uk  Fri Jul 16 01:22:02 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 16 Jul 2004 00:22:02 +0100
Subject: [R] adding option in the Windows installer for --internet2
In-Reply-To: <ttqdf0hhhf5iphqseml3qs9lgau6qrhok4@4ax.com>
References: <3A822319EB35174CA3714066D590DCD504AF805D@usrymx25.merck.com>
	<ttqdf0hhhf5iphqseml3qs9lgau6qrhok4@4ax.com>
Message-ID: <1089933722.3064.92.camel@localhost.localdomain>

Yes, corporate firewall can be a real pain at times. Duncan does have a
point that many users (especially new ones) will not know what this is
for.

Would it be possible to test during the installation process if
--internet2 is suitable and ask for confirmation from the user. A
message as follows may suffice 

"The installation process has detected that you might be behind a
firewall which could affect downloading of new packages. If this is
true, a modification(?) will be made."
[Yes/No]



On Thu, 2004-07-15 at 21:51, Duncan Murdoch wrote:
> On Thu, 15 Jul 2004 16:18:43 -0400, "Liaw, Andy" <andy_liaw at merck.com>
> wrote :
> 
> >[Not sure if such wishlist item should go to R-help or R-devel...]
> >
> >It would be nice if an option can be added to the R for Windows installer
> >that will add the --internet2 option to the command line in the shortcut
> >that gets created.  Also, is it possible to make that an option that can be
> >set at the R prompt, or perhaps even better, as the default no matter
> >how/where R is started?  For those of us behind corporate firewalls, life
> >w/o --internet2 is not terribly pleasant, and nave users are too nave to
> >remember that...
> 
> It would be easy to put there, but I can't for the life of me figure
> out how I would document it.  If a user is too naive to know to use it
> when running R, how would they know which choice to make when
> installing it?
> 
> Alternatively, if you know a test that could determine whether
> --internet2 is desirable, perhaps the installer could use that.
> 
> As to the idea of switching at the R prompt or as a global
> configuration option:  those are probably possible, possibly tricky,
> patches to do them will be considered.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Fri Jul 16 01:41:54 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 15 Jul 2004 19:41:54 -0400
Subject: [R] adding option in the Windows installer for --internet2
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8060@usrymx25.merck.com>

> From: Duncan Murdoch 
> 
> On Thu, 15 Jul 2004 16:18:43 -0400, "Liaw, Andy" <andy_liaw at merck.com>
> wrote :
> 
> >[Not sure if such wishlist item should go to R-help or R-devel...]
> >
> >It would be nice if an option can be added to the R for 
> Windows installer
> >that will add the --internet2 option to the command line in 
> the shortcut
> >that gets created.  Also, is it possible to make that an 
> option that can be
> >set at the R prompt, or perhaps even better, as the default no matter
> >how/where R is started?  For those of us behind corporate 
> firewalls, life
> >w/o --internet2 is not terribly pleasant, and na??ve users 
> are too na??ve to
> >remember that...
> 
> It would be easy to put there, but I can't for the life of me figure
> out how I would document it.  If a user is too naive to know to use it
> when running R, how would they know which choice to make when
> installing it?
> 
> Alternatively, if you know a test that could determine whether
> --internet2 is desirable, perhaps the installer could use that.

The XEmacs and cygwin netinstaller has three install options: "Use IE5
settings", "Direct connection" (or something like that) and "Install from
local disk".  Option #2 never work for me, but #1 does.  I suspect the R
installer can do something similar:  offer the two options (with and
without), and somehow test if the connection (to CRAN) works.  If not,
prompt the user to try the other option.  My take is that this option should
be (semi?) permanent:  If it's needed, it's needed all the time for that
installation.  Wouldn't it make sense to have the setting written to some
file in, say, $R_HOME/etc, that tells R to use that option, instead of using
the command line argument?


> As to the idea of switching at the R prompt or as a global
> configuration option:  those are probably possible, possibly tricky,
> patches to do them will be considered.

Would what I suggested above be easier than this?  Not that I have any clue
as to how to do this, unfortunately...

Cheers,
Andy
 
> Duncan Murdoch
> 
>



From rpeng at jhsph.edu  Fri Jul 16 02:17:05 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 15 Jul 2004 20:17:05 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <20040715150545.UDNA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>
References: <20040715150545.UDNA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <40F71E81.5060503@jhsph.edu>

Hmm...is this maybe a bug?  Check out this section of 
install.packages():

     localcran <- length(grep("^file:", contriburl)) > 0
     if (!localcran) {
         if (is.null(destdir)) {
             tmpd <- tempfile("Rinstdir")
             if (!dir.create(tmpd))
                 stop("Unable to create temp directory ", tmpd)
         }
         else tmpd <- destdir
     }
     foundpkgs <- download.packages(pkgs, destdir = tmpd, 
available = available,
         contriburl = contriburl, method = method)

So if `localcran' is TRUE (which in this case, it is), then 
`tmpd' never gets defined but is passed to download.packages().

When I run a traceback() after getting the error from running 
install.packages(), it fails in download.packages() when trying 
to create the download directory.

For example, try defining `tmpd' in your workspace and the run 
install.packages.  This works for me:

tmpd <- "~/tmp"
install.packages("bzTools", contriburl = "file:c:/Rlibs/build")

Of course, you still need the PACKAGES file in the contriburl 
directory.

-roger

John Fox wrote:
> Dear Duncan, 
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
>>Sent: Thursday, July 15, 2004 9:56 AM
>>To: John Fox
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] contriburl argument to install.packages
>>
>>On Thu, 15 Jul 2004 10:09:46 -0400, "John Fox" 
>><jfox at mcmaster.ca> wrote :
>>
>>
>>>Dear list members,
>>>
>>>I can't figure out how to specify the contriburl argument to
>>>install.packages() properly when the packages to be 
>>
>>installed are in a 
>>
>>>directory on my local machine. I have in mind a command 
>>
>>something like
>>
>>>	install.packages(missing.packages, contriburl=directory,
>>>lib=.libPaths()[1])
>>>
>>>Where missing.packages is a character vector of package 
>>
>>names (without
>>
>>>versions) and directory is the location where they reside (less 
>>>PACKAGES, I guess). I'm using R version 1.9.1 on a Windows 
>>
>>XP machine. 
>>
>>>Several variations on directory <- "file:c:/temp" don't seem to work.
>>>
>>>Any help would be appreciated.
>>
>>You need a file called PACKAGES in the same directory as the 
>>packages, which contains the package information; for example
>>
>> http://www.cran.mirrors.pair.com/bin/windows/contrib/1.9/PACKAGES
>>
>>I imagine the CRAN maintainers have scripts to produce this 
>>from the package files, but I'm not sure where they are.
>>
>>To refer to a local version of this file, use the syntax you had, e.g.
>>
>> CRAN.packages(contriburl="file:c:/temp")
>>
>>will look for c:/temp/PACKAGES and display the information in it.  
>>
> 
> 
> I had already tried this, and it doesn't appear to work for me. For example,
> 
> 	> CRAN.packages(contriburl="file:c:/temp")
> 	Error in file(file, "r") : unable to open connection
> 	In addition: Warning message: 
> 	cannot open file `c:/temp/PACKAGES' 
> 
> I *do* have a directory c:\temp\PACKAGES
> 
> Regards,
>  John
> 
> 
> 
> 
>>If you don't want to maintain this file, then you can 
>>construct the information in it using the "available=" 
>>argument to the package functions.
>>
>>Duncan
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ruidantas at netcabo.pt  Fri Jul 16 03:16:43 2004
From: ruidantas at netcabo.pt (Rui Dantas)
Date: Fri, 16 Jul 2004 02:16:43 +0100
Subject: [R] Functions in a package not visible to a user 
Message-ID: <004701c46ad2$8e82a6e0$335c5451@maipcrpdantas>

Dear all,
Sorry if this is obvious, but I couldn't find the answer in any place I
looked.
I have a package with several R functions. Some are internal auxiliary
functions, and should not be available to the user (nor do they, for
example, need "user" documentation). How can I hide them?

Best regards,
Rui Dantas



From andy_liaw at merck.com  Fri Jul 16 03:15:43 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 15 Jul 2004 21:15:43 -0400
Subject: [R] Functions in a package not visible to a user
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8063@usrymx25.merck.com>

That's one of the purposes of the namespace.  See Prof. Tierney's article in
the R Newsletter, or the slides of his keynote lecture at the useR! 2004
conference.  It's also explained in the `Writing R Extensions' manual.
Basically you only export functions that the users should see.  The manual
also explains how to not document functions that aren't intended to be
called by users.

Andy

> From: Rui Dantas
> 
> Dear all,
> Sorry if this is obvious, but I couldn't find the answer in 
> any place I
> looked.
> I have a package with several R functions. Some are internal auxiliary
> functions, and should not be available to the user (nor do they, for
> example, need "user" documentation). How can I hide them?
> 
> Best regards,
> Rui Dantas



From sundar.dorai-raj at PDF.COM  Fri Jul 16 03:17:56 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 15 Jul 2004 18:17:56 -0700
Subject: [R] Functions in a package not visible to a user
In-Reply-To: <004701c46ad2$8e82a6e0$335c5451@maipcrpdantas>
References: <004701c46ad2$8e82a6e0$335c5451@maipcrpdantas>
Message-ID: <40F72CC4.7030807@pdf.com>



Rui Dantas wrote:
> Dear all,
> Sorry if this is obvious, but I couldn't find the answer in any place I
> looked.
> I have a package with several R functions. Some are internal auxiliary
> functions, and should not be available to the user (nor do they, for
> example, need "user" documentation). How can I hide them?
> 
> Best regards,
> Rui Dantas
> 

Read about namespaces in "Writing R Extensions".

Section 1.6 Package name spaces (p.18 on the R-1.9.1 PDF version)

--sundar



From jfox at mcmaster.ca  Fri Jul 16 04:29:18 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Jul 2004 22:29:18 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <40F71E81.5060503@jhsph.edu>
Message-ID: <20040716022921.AER1816.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Roger,

After Duncan pointed out my error, I was able to get things to work fine.
(The context was a discussion on the R-GUI list, in response to which I
wrote a tcltk dialog to download missing packages or install them from a
local directory. It was the latter that was giving me trouble -- because I
misinterpreted PACKAGES as a directory.)

Anyway, thanks for your help.
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Roger D. Peng
> Sent: Thursday, July 15, 2004 7:17 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch; 'Duncan Murdoch'
> Subject: Re: [R] contriburl argument to install.packages
> 
> Hmm...is this maybe a bug?  Check out this section of
> install.packages():
> 
>      localcran <- length(grep("^file:", contriburl)) > 0
>      if (!localcran) {
>          if (is.null(destdir)) {
>              tmpd <- tempfile("Rinstdir")
>              if (!dir.create(tmpd))
>                  stop("Unable to create temp directory ", tmpd)
>          }
>          else tmpd <- destdir
>      }
>      foundpkgs <- download.packages(pkgs, destdir = tmpd, 
> available = available,
>          contriburl = contriburl, method = method)
> 
> So if `localcran' is TRUE (which in this case, it is), then 
> `tmpd' never gets defined but is passed to download.packages().
> 
> When I run a traceback() after getting the error from running 
> install.packages(), it fails in download.packages() when 
> trying to create the download directory.
> 
> For example, try defining `tmpd' in your workspace and the 
> run install.packages.  This works for me:
> 
> tmpd <- "~/tmp"
> install.packages("bzTools", contriburl = "file:c:/Rlibs/build")
> 
> Of course, you still need the PACKAGES file in the contriburl 
> directory.
> 
> -roger
> 
> John Fox wrote:
> > Dear Duncan,
> > 
> > 
> >>-----Original Message-----
> >>From: r-help-bounces at stat.math.ethz.ch 
> >>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Duncan Murdoch
> >>Sent: Thursday, July 15, 2004 9:56 AM
> >>To: John Fox
> >>Cc: r-help at stat.math.ethz.ch
> >>Subject: Re: [R] contriburl argument to install.packages
> >>
> >>On Thu, 15 Jul 2004 10:09:46 -0400, "John Fox" 
> >><jfox at mcmaster.ca> wrote :
> >>
> >>
> >>>Dear list members,
> >>>
> >>>I can't figure out how to specify the contriburl argument to
> >>>install.packages() properly when the packages to be
> >>
> >>installed are in a
> >>
> >>>directory on my local machine. I have in mind a command
> >>
> >>something like
> >>
> >>>	install.packages(missing.packages, contriburl=directory,
> >>>lib=.libPaths()[1])
> >>>
> >>>Where missing.packages is a character vector of package
> >>
> >>names (without
> >>
> >>>versions) and directory is the location where they reside (less 
> >>>PACKAGES, I guess). I'm using R version 1.9.1 on a Windows
> >>
> >>XP machine. 
> >>
> >>>Several variations on directory <- "file:c:/temp" don't 
> seem to work.
> >>>
> >>>Any help would be appreciated.
> >>
> >>You need a file called PACKAGES in the same directory as 
> the packages, 
> >>which contains the package information; for example
> >>
> >> http://www.cran.mirrors.pair.com/bin/windows/contrib/1.9/PACKAGES
> >>
> >>I imagine the CRAN maintainers have scripts to produce this 
> from the 
> >>package files, but I'm not sure where they are.
> >>
> >>To refer to a local version of this file, use the syntax 
> you had, e.g.
> >>
> >> CRAN.packages(contriburl="file:c:/temp")
> >>
> >>will look for c:/temp/PACKAGES and display the information in it.  
> >>
> > 
> > 
> > I had already tried this, and it doesn't appear to work for me. For 
> > example,
> > 
> > 	> CRAN.packages(contriburl="file:c:/temp")
> > 	Error in file(file, "r") : unable to open connection
> > 	In addition: Warning message: 
> > 	cannot open file `c:/temp/PACKAGES' 
> > 
> > I *do* have a directory c:\temp\PACKAGES
> > 
> > Regards,
> >  John
> > 
> > 
> > 
> > 
> >>If you don't want to maintain this file, then you can construct the 
> >>information in it using the "available="
> >>argument to the package functions.
> >>
> >>Duncan
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rpeng at jhsph.edu  Fri Jul 16 04:30:10 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 15 Jul 2004 22:30:10 -0400
Subject: [R] Functions in a package not visible to a user
In-Reply-To: <004701c46ad2$8e82a6e0$335c5451@maipcrpdantas>
References: <004701c46ad2$8e82a6e0$335c5451@maipcrpdantas>
Message-ID: <40F73DB2.9090107@jhsph.edu>

The old way was to define the internal functions inside the 
functions that used them.  Nowadays it's better to use a 
namespace.  `R CMD check' will only check code/docs for exported 
functions so non-exported/internal functions don't need to have a 
help file.

-roger

Rui Dantas wrote:
> Dear all,
> Sorry if this is obvious, but I couldn't find the answer in any place I
> looked.
> I have a package with several R functions. Some are internal auxiliary
> functions, and should not be available to the user (nor do they, for
> example, need "user" documentation). How can I hide them?
> 
> Best regards,
> Rui Dantas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Peter.Caley at csiro.au  Fri Jul 16 04:50:43 2004
From: Peter.Caley at csiro.au (Peter.Caley@csiro.au)
Date: Fri, 16 Jul 2004 12:50:43 +1000
Subject: [R] Does AIC() applied to a nls() object use the correct number of
	estimated parameters?
Message-ID: <662FF5A611597C41987B05E11DFE359237991C@exact3-cbr.act.csiro.au>

I'm wondering whether AIC scores extracted from nls() objects using
AIC() are based on the correct number of estimated parameters.  

Using the example under nls() documentation:

> data( DNase )
> DNase1 <- DNase[ DNase$Run == 1, ]
> ## using a selfStart model
> fm1DNase1 <- nls( density ~ SSlogis( log(conc), Asym, xmid, scal ),
DNase1 )

Using AIC() function:

> AIC(fm1DNase1)
[1] -78.41642

Using number of estimable coefficients (including residual error):

> -2*logLik(fm1DNase1) + 2*(length(coef(fm1DNase1))+1)
[1] -76.41642
attr(,"df")
[1] 3
attr(,"nall")
[1] 16
attr(,"nobs")
[1] 16
attr(,"class")
[1] "logLik"

Based on the difference in AIC of 2 between the two approaches, it
appears that when applied to a nls() object, AIC() doesn't include the
estimate of residual error in the number of estimated parameters ... or
is my understanding of nls() fitting confused. 

Any help appreciated.

cheers

Peter

*********************************************************************
Dr Peter Caley
CSIRO Entomology
GPO Box 1700, Canberra,
ACT 2601
Email: peter.caley at csiro.au
Ph: +61 (0)2 6246 4076   Fax: +61 (0)2 6246 4000



From kathryn.jones at jcu.edu.au  Fri Jul 16 03:53:37 2004
From: kathryn.jones at jcu.edu.au (Kathryn Jones)
Date: Fri, 16 Jul 2004 11:53:37 +1000
Subject: [R] SJava - restart function
Message-ID: <13527b9d.6090ac81.c471700@mirapoint-ms1.jcu.edu.au>

Hi folks,
Does anyone know about using event handling in SJava?? I 
tried examples from here: 
http://www.omegahat.org/RSJava/examples/
but they are quite old I think and don't work in newer 
versions of R due to the restart() function being defunct. 
Does anyone know how to get around this problem? I'm trying 
to find an older version of R (for windows) to see if the 
examples work there. Any help would be great!
Thanks
Kathryn Jones



From ramasamy at cancer.org.uk  Fri Jul 16 05:13:35 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 16 Jul 2004 04:13:35 +0100
Subject: [R] Does AIC() applied to a nls() object use the correct
	number of estimated parameters?
In-Reply-To: <662FF5A611597C41987B05E11DFE359237991C@exact3-cbr.act.csiro.au>
References: <662FF5A611597C41987B05E11DFE359237991C@exact3-cbr.act.csiro.au>
Message-ID: <1089947615.4692.6.camel@localhost.localdomain>

I do not know anything about nls(), so apologies if I get it completely
wrong. help("AIC") says that AIC is defined to be 
-2*log-likelihood + k*npar; where k = 2 by default. 

I think you calculated -2*log-likelihood + k*(npar + 1) instead. Does
this help ?

On Fri, 2004-07-16 at 03:50, Peter.Caley at csiro.au wrote:
> I'm wondering whether AIC scores extracted from nls() objects using
> AIC() are based on the correct number of estimated parameters.  
> 
> Using the example under nls() documentation:
> 
> > data( DNase )
> > DNase1 <- DNase[ DNase$Run == 1, ]
> > ## using a selfStart model
> > fm1DNase1 <- nls( density ~ SSlogis( log(conc), Asym, xmid, scal ),
> DNase1 )
> 
> Using AIC() function:
> 
> > AIC(fm1DNase1)
> [1] -78.41642
> 
> Using number of estimable coefficients (including residual error):
> 
> > -2*logLik(fm1DNase1) + 2*(length(coef(fm1DNase1))+1)
> [1] -76.41642
> attr(,"df")
> [1] 3
> attr(,"nall")
> [1] 16
> attr(,"nobs")
> [1] 16
> attr(,"class")
> [1] "logLik"
> 
> Based on the difference in AIC of 2 between the two approaches, it
> appears that when applied to a nls() object, AIC() doesn't include the
> estimate of residual error in the number of estimated parameters ... or
> is my understanding of nls() fitting confused. 
> 
> Any help appreciated.
> 
> cheers
> 
> Peter
> 
> *********************************************************************
> Dr Peter Caley
> CSIRO Entomology
> GPO Box 1700, Canberra,
> ACT 2601
> Email: peter.caley at csiro.au
> Ph: +61 (0)2 6246 4076   Fax: +61 (0)2 6246 4000
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Peter.Caley at csiro.au  Fri Jul 16 05:57:03 2004
From: Peter.Caley at csiro.au (Peter.Caley@csiro.au)
Date: Fri, 16 Jul 2004 13:57:03 +1000
Subject: [R] Does AIC() applied to a nls() object use the correctnumber of
	estimated parameters?
Message-ID: <662FF5A611597C41987B05E11DFE35920273FF90@exact3-cbr.act.csiro.au>

Thanks Adaikalavan, however the problem remains.  

Considering AIC() as applied to the linear model in AIC() help
documentation: 

> data(swiss)
> lm1 <- lm(Fertility ~ . , data = swiss)
> AIC(lm1)
[1] 326.0716

Clearly this includes the estimation of the residual standard error as
an estimated parameter, as this gives the correct score:

> -2*logLik(lm1) + 2*(length(coef(lm1))+1)
[1] 326.0716
attr(,"nall")
[1] 47
attr(,"nobs")
[1] 47
attr(,"df")
[1] 7
attr(,"class")
[1] "logLik"

I thought the same would have held for nls() objects.

> -----Original Message-----
> From: Adaikalavan Ramasamy [mailto:ramasamy at cancer.org.uk] 
> Sent: Friday, 16 July 2004 1:14 PM
> To: Caley, Peter (Entomology, Black Mountain)
> Cc: R-help
> Subject: Re: [R] Does AIC() applied to a nls() object use the 
> correctnumber of estimated parameters?
> 
> 
> I do not know anything about nls(), so apologies if I get it 
> completely wrong. help("AIC") says that AIC is defined to be 
> -2*log-likelihood + k*npar; where k = 2 by default. 
> 
> I think you calculated -2*log-likelihood + k*(npar + 1) 
> instead. Does this help ?
> 
> On Fri, 2004-07-16 at 03:50, Peter.Caley at csiro.au wrote:
> > I'm wondering whether AIC scores extracted from nls() objects using
> > AIC() are based on the correct number of estimated parameters.
> > 
> > Using the example under nls() documentation:
> > 
> > > data( DNase )
> > > DNase1 <- DNase[ DNase$Run == 1, ]
> > > ## using a selfStart model
> > > fm1DNase1 <- nls( density ~ SSlogis( log(conc), Asym, 
> xmid, scal ),
> > DNase1 )
> > 
> > Using AIC() function:
> > 
> > > AIC(fm1DNase1)
> > [1] -78.41642
> > 
> > Using number of estimable coefficients (including residual error):
> > 
> > > -2*logLik(fm1DNase1) + 2*(length(coef(fm1DNase1))+1)
> > [1] -76.41642
> > attr(,"df")
> > [1] 3
> > attr(,"nall")
> > [1] 16
> > attr(,"nobs")
> > [1] 16
> > attr(,"class")
> > [1] "logLik"
> > 
> > Based on the difference in AIC of 2 between the two approaches, it 
> > appears that when applied to a nls() object, AIC() doesn't 
> include the 
> > estimate of residual error in the number of estimated 
> parameters ... 
> > or is my understanding of nls() fitting confused.
> > 
> > Any help appreciated.
> > 
> > cheers
> > 
> > Peter
> > 
> > 
> *********************************************************************
> > Dr Peter Caley
> > CSIRO Entomology
> > GPO Box 1700, Canberra,
> > ACT 2601
> > Email: peter.caley at csiro.au
> > Ph: +61 (0)2 6246 4076   Fax: +61 (0)2 6246 4000
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> 
>



From keithw at galen.med.usyd.edu.au  Fri Jul 16 06:14:40 2004
From: keithw at galen.med.usyd.edu.au (Keith Wong)
Date: Fri, 16 Jul 2004 14:14:40 +1000
Subject: [R] Random intercept model with time-dependent covariates,
	results different from SAS [SUMMARY]
In-Reply-To: <Pine.LNX.4.44.0407040840540.9814-100000@gannet.stats>
References: <1088925696.40e7b00087429@www.mail.med.usyd.edu.au>
	<Pine.LNX.4.44.0407040840540.9814-100000@gannet.stats>
Message-ID: <6.0.0.22.2.20040716140257.02587240@galen.med.usyd.edu.au>

Thank you Prof Ripley and Dr Bebber for the helpful responses to my post on 
4 July 2004, and references to further reading.

To close the thread, I summarize the answer to my question. The different 
results between SAS and R arose from more than one cause.

1. SAS incorrectly assumed that Group was a within-subjects effect: as seen 
in the difference in denominator degrees of freedom..

2. The two between subjects levels of Group contained unequal numbers of 
subjects.

3. R reports type I sums of squares with the anova() function on an lme 
object, whereas type III sums of squares are the default in SAS PROC MIXED. 
Placing the variable time last in the model in R resulted in a p-value 
similar to that given in SAS. I accept Prof Ripley's point that this main 
effect is not very relevant in the presence of a significant interaction 
between time and group.

Thank you again to the list.

Keith Wong



From ligges at statistik.uni-dortmund.de  Fri Jul 16 08:19:39 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 08:19:39 +0200
Subject: [R] newbie - clear console
In-Reply-To: <200407151751.i6FHpD8J022872@erdos.math.unb.ca>
References: <200407151751.i6FHpD8J022872@erdos.math.unb.ca>
Message-ID: <40F7737B.9000709@statistik.uni-dortmund.de>

Rolf Turner wrote:

> Paolo Covelli wrote:
> 
> 
>>does it exist a sintax-comand to clear thre console (the screen)?
>>I've finded nothing on the standard manuals. (apart from the manual
>>comand CTRL+L)
> 
> 
> You don't say what operating system you're using .....
> 
> Anyhow, as far as I know there is no built-in to clear the screen.
> But one is easy to build.  On a Unix system you could do
> 
> 	cl <- function(){system("clear")}
> 
> then executing cl() will clear the screen for you.
> 
> On a Windoze system I think replacing ``clear'' by ``cls''
> in the definition of cl() should work.

That's true for the Windows shell, but for RGui there's no R function.

Uwe Ligges


> 				cheers,
> 
> 					Rolf Turner
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Jul 16 08:41:18 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 08:41:18 +0200
Subject: [R] how to upload [forwarded]
In-Reply-To: <16630.52832.917819.872118@gargle.gargle.HOWL>
References: <16630.52832.917819.872118@gargle.gargle.HOWL>
Message-ID: <40F7788E.6040201@statistik.uni-dortmund.de>

Federico Calboli wrote:

> [ This was posted to the R-packages list (which I moderate), 
>   but definitely doesn't belong there.  Martin Maechler 
> ]
> 
> ------- start of forwarded message -------
> From: Federico Calboli <f.calboli at ucl.ac.uk>
> To: r-packages at stat.math.ethz.ch
> Subject: how to upload
> Date: 15 Jul 2004 18:30:26 +0100
> 
> Dear All,
> 
> I just finished a add on lib 

Martin forgot to point out that you are talking about a *package*, not a 
lib.


 > called Malmig, to calculate Malecot
> migration model and associated functions. I am meant, according to
> R-exts, to upload the tar.gz at:
> 
> ftp://ftp.ci.tuwien.ac.at/incoming

Use any ftp client, specify the address, login as anonymous and upload 
the file in binary mode. That's all.

Mozilla 1.7.x as well as a couple of other browsers are capable of FTP 
uploading these days. Just browse to the URL and click on file-upload file.

Uwe Ligges


> How? never uploaded anything in my life.


> Cheers,
> Federico Calboli
> 
> =================================
> 
> Federico C. F. Calboli
> 
> Dipartimento di Biologia
> Via Selmi 3
> 40126 Bologna
> Italy
> 
> tel (+39) 051 209 4187
> fax (+39) 051 209 4286
> 
> f.calboli at ucl.ac.uk
> fcalboli at alma.unibo.it
> ------- end of forwarded message -------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Jul 16 08:45:48 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 08:45:48 +0200
Subject: [R] More on global environment
In-Reply-To: <6.1.0.6.2.20040715153313.01eb66f8@hermes.nos.noaa.gov>
References: <3A822319EB35174CA3714066D590DCD504AF8058@usrymx25.merck.com>
	<6.1.0.6.2.20040715153313.01eb66f8@hermes.nos.noaa.gov>
Message-ID: <40F7799C.3040308@statistik.uni-dortmund.de>

Mike Prager wrote:

> At 7/15/2004 03:23 PM Thursday, Andy Liaw wrote:
> 
>> I've posted the following to R-help before.  Hope it helps you.
>>
>> cd <- function(dir = tclvalue(tkchooseDirectory()), saveOld=FALSE,
>>                loadNew=TRUE) {
>>     stopifnot(require(tcltk))
> 
> 
>         flush.console()


What you want in a general function is

   if(.Platform$OS.type == "windows")
       flush.console()

Since flush.console() does not exist in any other version than the 
Windows versions of R.

Uwe Ligges


>>     if (saveOld) save.image(compress=TRUE)
>>     setwd(dir)
>>     rm(list=ls(all=TRUE, envir=.GlobalEnv), envir=.GlobalEnv)
>>     if (loadNew && file.exists(".RData")) {
>>         loaded <- load(".RData", envir=.GlobalEnv)
>>         return(invisible(loaded))
>>     }
>> }
>>
>> [The tcltk part is based on Prof. Fox's help.]
>>
>> Andy
> 
> 
> Thanks!  It's lovely.  I added the call to flush.console() as shown, 
> which (under Windows RGUI at least) issues the message that tcl is 
> loading in a more timely way.
> 
> Mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Fri Jul 16 08:49:37 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 16 Jul 2004 08:49:37 +0200
Subject: [R] formula and lm
In-Reply-To: <40696.170.210.173.216.1089909989.squirrel@inter17.unsl.edu.ar>
Message-ID: <40F796A1.2548.2731C0@localhost>

Hallo

On 15 Jul 2004 at 13:46, solares at unsl.edu.ar wrote:

> Hi, don' t understand why the function fomula have this error, i
> enclose the parameter "a" with the function I() Thank Ruben
>  x<-1:5
> y<-c(  2  ,4 , 6 , 8 ,11)
> formu<-y~I(a*x)
> form<-formula(formu)
> dummy<-data.frame(x=x,y=y)
> fm<-lm(form,data=dummy)
> Error in unique(c("AsIs", oldClass(x))) : Object "a" not found

You did not created object "a" before you have done your 
calculations, as the error message clearly states. 

try

a<-5
x<-1:5
y<-c(  2  ,4 , 6 , 8 ,11)
formu<-y~I(a*x)
form<-formula(formu)
dummy<-data.frame(x=x,y=y)
fm<-lm(form,data=dummy)

But if you want to estimate "a" follow previous replies and try to 
read help page for lm(). 

formu<-y~x

is probably what you want :-).

Cheers
Petr

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ligges at statistik.uni-dortmund.de  Fri Jul 16 09:02:20 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 09:02:20 +0200
Subject: [R] contriburl argument to install.packages
In-Reply-To: <40F71E81.5060503@jhsph.edu>
References: <20040715150545.UDNA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>
	<40F71E81.5060503@jhsph.edu>
Message-ID: <40F77D7C.7090604@statistik.uni-dortmund.de>

Roger D. Peng wrote:

> Hmm...is this maybe a bug?  Check out this section of install.packages():
> 
>     localcran <- length(grep("^file:", contriburl)) > 0
>     if (!localcran) {
>         if (is.null(destdir)) {
>             tmpd <- tempfile("Rinstdir")
>             if (!dir.create(tmpd))
>                 stop("Unable to create temp directory ", tmpd)
>         }
>         else tmpd <- destdir
>     }
>     foundpkgs <- download.packages(pkgs, destdir = tmpd, available = 
> available,
>         contriburl = contriburl, method = method)
> 
> So if `localcran' is TRUE (which in this case, it is), then `tmpd' never 
> gets defined but is passed to download.packages().

The help pages tells us (correctly):
"If CRAN is local, i.e., the URL starts with "file:", then the packages 
are not downloaded but used directly."
hence we don't need a destdir in this case, therefore no need to define 
tmpd.


> When I run a traceback() after getting the error from running 
> install.packages(), it fails in download.packages() when trying to 
> create the download directory.

Works for me without any error. Are you sure the path you specified was 
correct? If you are sure, is this R-1.9.1?

Uwe Ligges



> For example, try defining `tmpd' in your workspace and the run 
> install.packages.  This works for me:
> 
> tmpd <- "~/tmp"
> install.packages("bzTools", contriburl = "file:c:/Rlibs/build")
> 
> Of course, you still need the PACKAGES file in the contriburl directory.
> 
> -roger
> 
> John Fox wrote:
> 
>> Dear Duncan,
>>
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch 
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
>>> Sent: Thursday, July 15, 2004 9:56 AM
>>> To: John Fox
>>> Cc: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] contriburl argument to install.packages
>>>
>>> On Thu, 15 Jul 2004 10:09:46 -0400, "John Fox" <jfox at mcmaster.ca> 
>>> wrote :
>>>
>>>
>>>> Dear list members,
>>>>
>>>> I can't figure out how to specify the contriburl argument to
>>>> install.packages() properly when the packages to be 
>>>
>>>
>>> installed are in a
>>>
>>>> directory on my local machine. I have in mind a command 
>>>
>>>
>>> something like
>>>
>>>>     install.packages(missing.packages, contriburl=directory,
>>>> lib=.libPaths()[1])
>>>>
>>>> Where missing.packages is a character vector of package 
>>>
>>>
>>> names (without
>>>
>>>> versions) and directory is the location where they reside (less 
>>>> PACKAGES, I guess). I'm using R version 1.9.1 on a Windows 
>>>
>>>
>>> XP machine.
>>>
>>>> Several variations on directory <- "file:c:/temp" don't seem to work.
>>>>
>>>> Any help would be appreciated.
>>>
>>>
>>> You need a file called PACKAGES in the same directory as the 
>>> packages, which contains the package information; for example
>>>
>>> http://www.cran.mirrors.pair.com/bin/windows/contrib/1.9/PACKAGES
>>>
>>> I imagine the CRAN maintainers have scripts to produce this from the 
>>> package files, but I'm not sure where they are.
>>>
>>> To refer to a local version of this file, use the syntax you had, e.g.
>>>
>>> CRAN.packages(contriburl="file:c:/temp")
>>>
>>> will look for c:/temp/PACKAGES and display the information in it. 
>>
>>
>>
>> I had already tried this, and it doesn't appear to work for me. For 
>> example,
>>
>>     > CRAN.packages(contriburl="file:c:/temp")
>>     Error in file(file, "r") : unable to open connection
>>     In addition: Warning message:     cannot open file `c:/temp/PACKAGES'
>> I *do* have a directory c:\temp\PACKAGES
>>
>> Regards,
>>  John
>>
>>
>>
>>
>>> If you don't want to maintain this file, then you can construct the 
>>> information in it using the "available=" argument to the package 
>>> functions.
>>>
>>> Duncan
>>
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From martina.renninger at tns-infratest.com  Fri Jul 16 09:49:38 2004
From: martina.renninger at tns-infratest.com (Martina Renninger)
Date: Fri, 16 Jul 2004 09:49:38 +0200
Subject: [R] labels for 3d Plots
Message-ID: <000001c46b09$726d7430$5e011e0a@wet.eu.nfowg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/9b2c39c6/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Jul 16 10:30:00 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 10:30:00 +0200
Subject: [R] labels for 3d Plots
In-Reply-To: <000001c46b09$726d7430$5e011e0a@wet.eu.nfowg.com>
References: <000001c46b09$726d7430$5e011e0a@wet.eu.nfowg.com>
Message-ID: <40F79208.3040604@statistik.uni-dortmund.de>

Martina Renninger wrote:

> High!
> 
>  
> 
> How can I add variable labels (rownames for instance)

So, dou you mean the variable label or stuff in rownames???

What about
   cloud(1:10~1:10+1:10, xlab="x", ylab="y", zlab="z")


 > to a plot created
> with ?clouds? ( clouds(dim3~dim1*dim2)) - package lattice?

It is called cloud() ...

Uwe Ligges

> Thanks in advance!
> 
>  
> 
> Martina Renninger
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From garbade at mip.paed.uni-muenchen.de  Fri Jul 16 10:36:53 2004
From: garbade at mip.paed.uni-muenchen.de (Sven Garbade)
Date: Fri, 16 Jul 2004 10:36:53 +0200
Subject: [R] Fixed and random factors in aov()
Message-ID: <20040716103653.09fd308e.garbade@psy.uni-muenchen.de>

Hi, 
I'm confused about how to specify random and fixed factors in an aov()
term. I tried to reproduce a textbook example: One fixed factor (Game, 4
levels) and one random factor (Store, 12 levels), response is Points.
The random factor Store is nested in Game. I tried 

> str(kh.df)
`data.frame':	48 obs. of  4 variables:
 $ Subj  : Factor w/ 48 levels "vp1","vp10","vp11",..: 1 12 23 34 44... 
 $ Game  : Factor w/ 4 levels "S1","S2","S3",..: 1 1 1 1 1 1 1 1 ... 
 $ Store : Factor w/ 12 levels "KH1","KH10","KH11",..: 1 1 1 1 5 ... 
 $ Points: num  7 9 12 7 6 5 8 6 9 6 ...

> summary(aov(Points ~ Game + Error(Game:Store),dat=kh.df))

Error: Game:Store
          Df Sum Sq Mean Sq F value  Pr(>F)  
Game       3 391.50  130.50  5.9771 0.01934 *
Residuals  8 174.67   21.83                  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Error: Within
          Df  Sum Sq Mean Sq F value Pr(>F)
Residuals 36 149.500   4.153               
Warning message: 
Error model is singular in: aov(Points ~ Game + Error(Game:Store), dat =
kh.df) 

which gives me the correct F-statistic for the fixed factor Game and 

> summary(aov(Points ~ Game + Game:Store,dat=kh.df))
            Df Sum Sq Mean Sq F value    Pr(>F)    
Game         3 391.50  130.50 31.4247 3.707e-10 ***
Game:Store   8 174.67   21.83  5.2575 0.0002126 ***
Residuals   36 149.50    4.15                      
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

which calcultes the correct Game:Store F statistic but the incorrect
F value for Game (because its a fixed factor). I'm wondering about how
to specify a correct model formula for the fixed and random factors with
an appropiate Error() term.

Thanks, Sven



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Jul 16 10:52:29 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 16 Jul 2004 10:52:29 +0200
Subject: [R] Fixed and random factors in aov()
References: <20040716103653.09fd308e.garbade@psy.uni-muenchen.de>
Message-ID: <00c601c46b12$3a871090$ad133a86@www.domain>

Hi Sven,

I think that you could also use `lme', i.e., something like:

library(nlme)
lme1 <- lme(Points~Game, random=~1|Store, data=kh.df)
lme2 <- lme(Points~Game, random=~1|Store/Game, data=kh.df)

anova(lme1)
anova(lme2)
anova(lme1, lme2)

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm




----- Original Message ----- 
From: "Sven Garbade" <garbade at mip.paed.uni-muenchen.de>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, July 16, 2004 10:36 AM
Subject: [R] Fixed and random factors in aov()


> Hi,
> I'm confused about how to specify random and fixed factors in an
aov()
> term. I tried to reproduce a textbook example: One fixed factor
(Game, 4
> levels) and one random factor (Store, 12 levels), response is
Points.
> The random factor Store is nested in Game. I tried
>
> > str(kh.df)
> `data.frame': 48 obs. of  4 variables:
>  $ Subj  : Factor w/ 48 levels "vp1","vp10","vp11",..: 1 12 23 34
44...
>  $ Game  : Factor w/ 4 levels "S1","S2","S3",..: 1 1 1 1 1 1 1 1 ...
>  $ Store : Factor w/ 12 levels "KH1","KH10","KH11",..: 1 1 1 1 5 ...
>  $ Points: num  7 9 12 7 6 5 8 6 9 6 ...
>
> > summary(aov(Points ~ Game + Error(Game:Store),dat=kh.df))
>
> Error: Game:Store
>           Df Sum Sq Mean Sq F value  Pr(>F)
> Game       3 391.50  130.50  5.9771 0.01934 *
> Residuals  8 174.67   21.83
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> Error: Within
>           Df  Sum Sq Mean Sq F value Pr(>F)
> Residuals 36 149.500   4.153
> Warning message:
> Error model is singular in: aov(Points ~ Game + Error(Game:Store),
dat =
> kh.df)
>
> which gives me the correct F-statistic for the fixed factor Game and
>
> > summary(aov(Points ~ Game + Game:Store,dat=kh.df))
>             Df Sum Sq Mean Sq F value    Pr(>F)
> Game         3 391.50  130.50 31.4247 3.707e-10 ***
> Game:Store   8 174.67   21.83  5.2575 0.0002126 ***
> Residuals   36 149.50    4.15
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> which calcultes the correct Game:Store F statistic but the incorrect
> F value for Game (because its a fixed factor). I'm wondering about
how
> to specify a correct model formula for the fixed and random factors
with
> an appropiate Error() term.
>
> Thanks, Sven
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From idimakos at upatras.gr  Fri Jul 16 11:24:20 2004
From: idimakos at upatras.gr (Ioannis Dimakos)
Date: Fri, 16 Jul 2004 12:24:20 +0300
Subject: [R] Fixed and random factors in aov()
In-Reply-To: <00c601c46b12$3a871090$ad133a86@www.domain>
References: <20040716103653.09fd308e.garbade@psy.uni-muenchen.de>
	<00c601c46b12$3a871090$ad133a86@www.domain>
Message-ID: <40F79EC4.7060704@upatras.gr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dimitris Rizopoulos wrote:


maybe the following is working?

aov(Points~Game*Store+Error(subj+Store:subj))

IKD



| Hi Sven,
|
| I think that you could also use `lme', i.e., something like:
|
| library(nlme)
| lme1 <- lme(Points~Game, random=~1|Store, data=kh.df)
| lme2 <- lme(Points~Game, random=~1|Store/Game, data=kh.df)
|
| anova(lme1)
| anova(lme2)
| anova(lme1, lme2)
|
| I hope this helps.
|
|  -======
|
|>Hi,
|>I'm confused about how to specify random and fixed factors in an
|
| aov()
|
|>term. I tried to reproduce a textbook example: One fixed factor
|
| (Game, 4
|
|>levels) and one random factor (Store, 12 levels), response is
|
| Points.
|
|>The random factor Store is nested in Game. I tried
|>
|>
|>>str(kh.df)
|>
|>`data.frame': 48 obs. of  4 variables:
|> $ Subj  : Factor w/ 48 levels "vp1","vp10","vp11",..: 1 12 23 34
|
| 44...
|
|> $ Game  : Factor w/ 4 levels "S1","S2","S3",..: 1 1 1 1 1 1 1 1 ...
|> $ Store : Factor w/ 12 levels "KH1","KH10","KH11",..: 1 1 1 1 5 ...
|> $ Points: num  7 9 12 7 6 5 8 6 9 6 ...
|>
|>
|>>summary(aov(Points ~ Game + Error(Game:Store),dat=kh.df))
|>
|>Error: Game:Store
|>          Df Sum Sq Mean Sq F value  Pr(>F)
|>Game       3 391.50  130.50  5.9771 0.01934 *
|>Residuals  8 174.67   21.83
|>---
|>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
|>
|>Error: Within
|>          Df  Sum Sq Mean Sq F value Pr(>F)
|>Residuals 36 149.500   4.153
|>Warning message:
|>Error model is singular in: aov(Points ~ Game + Error(Game:Store),
|
| dat =
|
|>kh.df)
|>
|>which gives me the correct F-statistic for the fixed factor Game and
|>
|>
|>>summary(aov(Points ~ Game + Game:Store,dat=kh.df))
|>
|>            Df Sum Sq Mean Sq F value    Pr(>F)
|>Game         3 391.50  130.50 31.4247 3.707e-10 ***
|>Game:Store   8 174.67   21.83  5.2575 0.0002126 ***
|>Residuals   36 149.50    4.15
|>---
|>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
|>
|>which calcultes the correct Game:Store F statistic but the incorrect
|>F value for Game (because its a fixed factor). I'm wondering about
|
| how
|
|>to specify a correct model formula for the fixed and random factors
|
| with
|
|>an appropiate Error() term.
|>
|>Thanks, Sven
|>


- --
Ioannis Dimakos
University of Patras
Dept. of Elementary Education
Division of Psychology
Patras, GR-26500, Greece
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.2.1 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFA957D+es8s84M8DARAvPTAJ4l48lNp4xG/SxnpPd4t4RP0aO0GwCeK4BM
eKQAXZiJgaQ5M/Df3vNiEBQ=
=QBdB
-----END PGP SIGNATURE-----



From p.campbell at econ.bbk.ac.uk  Fri Jul 16 11:51:13 2004
From: p.campbell at econ.bbk.ac.uk (Campbell)
Date: Fri, 16 Jul 2004 10:51:13 +0100
Subject: [R] Block Bootstrap Simulation
Message-ID: <s0f7b342.047@markets.econ.bbk.ac.uk>

I am trying to run a time series block bootstrap.  I have a dataset of length t = n*k. 
I want to sample n blocks of length k from the data.  

I don't want to use loop because a) the overhead and b) I'm comparing it with another technique that doesn't require a loop, and programming the simulation without the loop gave me an insight into the solution of the problem
Is there a way of doing this without using a loop?

s<-1:n
v<-sample(s, replace=TRUE)
w<-v:(v+k)

Doesn't work

Phineas Campbell
www.phineas.pwp.blueyonder.co.uk



From vonbing at Math.Berkeley.EDU  Fri Jul 16 12:34:12 2004
From: vonbing at Math.Berkeley.EDU (Von Bing Yap)
Date: Fri, 16 Jul 2004 03:34:12 -0700 (PDT)
Subject: [R] marginal homogeneity in n by n tables (n > 2)
Message-ID: <Pine.SOL.4.44.0407160329270.23493-100000@blue1>


Hello,

Is there a function that finds the most likely probabilities p_ij with the
marginal homogeneity constraint p_i. = p_.i, all i, for an n by n table, n
> 2?  For n = 2, mcnemar.test does it.  Any analogous function for n > 2?

Thanks,
Von Bing



---------------------------------------------------------------------------
Von Bing Yap
Department of Mathematics,
1071 Evans Hall,
University of California,                 Tel: 510 642-0756
Berkeley, CA 94720-3840,                  Fax: 510 642-8204
USA.                                      Web: math.berkeley.edu/~vonbing



From anne.piotet at urbanet.ch  Fri Jul 16 12:38:54 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Fri, 16 Jul 2004 12:38:54 +0200
Subject: [R] small problem with predict
Message-ID: <002201c46b21$17974960$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/4fa6a198/attachment.pl

From i.visser at uva.nl  Fri Jul 16 12:47:44 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Fri, 16 Jul 2004 12:47:44 +0200
Subject: [R] Block Bootstrap Simulation
In-Reply-To: <s0f7b342.047@markets.econ.bbk.ac.uk>
Message-ID: <BD1D7EF0.4B06%i.visser@uva.nl>

On 7/16/04 11:51 AM, "Campbell" <p.campbell at econ.bbk.ac.uk> wrote:

> I don't want to use loop because a) the overhead and b) I'm comparing it with
> another technique that doesn't require a loop, and programming the simulation
> without the loop gave me an insight into the solution of the problem
> Is there a way of doing this without using a loop?
> 
> s<-1:n
> v<-sample(s, replace=TRUE)
> w<-v:(v+k)
> 
> Doesn't work

Why doesn't it work, ie if you replace w<-v:(v+k) by
w<-(v*k):((v+1)*k)?

ingmar



From petr.pikal at precheza.cz  Fri Jul 16 13:19:10 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 16 Jul 2004 13:19:10 +0200
Subject: [R] small problem with predict
In-Reply-To: <002201c46b21$17974960$6c00a8c0@mtd4>
Message-ID: <40F7D5CE.8919.11E93D4@localhost>

Hi

On 16 Jul 2004 at 12:38, Anne wrote:

> hello to all!
> 
> I have a small problem wit predict() for lm
> 
> Let's say I have predictors x1 and x2, response y
> 
> I want to predict for a new ds say
> dn<-data.frame(x1=
> seq(min(x1),max(x1),length=10),x2=rep(median(x2),10))
> 
> predict(lm(y~x1+x2),dn,se.fit=T)
> 
> 
> Error message
> >  Error: variables 'x1', 'x2' were specified differently from the fit

AFAIK predixt require to be fed by dataframe in which the 
variables has the same names as was in lm() call. Either call lm() 
with variables named "x1" and "x2" or build the dataframe "dn" 
with names identical as are names in lm() call

Cheers
Petr


> 
> (I looked in the help and found the example
> 
>  x <- rnorm(15)
>      y <- x + rnorm(15)
>     new <- data.frame(x = seq(-3, 3, 0.5))
>      predict(lm(y ~ x), new, se.fit = TRUE)
> 
> where is the difference?)
> 
> 
> Anne
> 
> ----------------------------------------------------
> Anne Piotet
> Tel: +41 79 359 83 32 (mobile)
> Email: anne.piotet at m-td.com
> ---------------------------------------------------
> M-TD Modelling and Technology Development
> PSE-C
> CH-1015 Lausanne
> Switzerland
> Tel: +41 21 693 83 98
> Fax: +41 21 646 41 33
> --------------------------------------------------
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From petr.pikal at precheza.cz  Fri Jul 16 13:39:29 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 16 Jul 2004 13:39:29 +0200
Subject: [R] small problem with predict
In-Reply-To: <40F7D5CE.8919.11E93D4@localhost>
References: <002201c46b21$17974960$6c00a8c0@mtd4>
Message-ID: <40F7DA91.36.1312CA2@localhost>

Hi Ann

As I read your code mode closely, I suspect that there could be 
another variables x1 and x2 somewhere in your search path which 
led to the error.

With fresh R session without any data this works as expected

dold<-data.frame(x1=rnorm(10),x2=5*rnorm(10))
y<-1:10
predict(lm(y~x1+x2,dold),dn,se.fit=T)

Cheers 
Petr

On 16 Jul 2004 at 13:19, Petr Pikal wrote:

> Hi
> 
> On 16 Jul 2004 at 12:38, Anne wrote:
> 
> > hello to all!
> > 
> > I have a small problem wit predict() for lm
> > 
> > Let's say I have predictors x1 and x2, response y
> > 
> > I want to predict for a new ds say
> > dn<-data.frame(x1=
> > seq(min(x1),max(x1),length=10),x2=rep(median(x2),10))
> > 
> > predict(lm(y~x1+x2),dn,se.fit=T)
> > 
> > 
> > Error message
> > >  Error: variables 'x1', 'x2' were specified differently from the
> > >  fit
> 
> AFAIK predixt require to be fed by dataframe in which the 
> variables has the same names as was in lm() call. Either call lm()
> with variables named "x1" and "x2" or build the dataframe "dn" with
> names identical as are names in lm() call
> 
> Cheers
> Petr
> 
> 
> > 
> > (I looked in the help and found the example
> > 
> >  x <- rnorm(15)
> >      y <- x + rnorm(15)
> >     new <- data.frame(x = seq(-3, 3, 0.5))
> >      predict(lm(y ~ x), new, se.fit = TRUE)
> > 
> > where is the difference?)
> > 
> > 
> > Anne
> > 
> > ----------------------------------------------------
> > Anne Piotet
> > Tel: +41 79 359 83 32 (mobile)
> > Email: anne.piotet at m-td.com
> > ---------------------------------------------------
> > M-TD Modelling and Technology Development
> > PSE-C
> > CH-1015 Lausanne
> > Switzerland
> > Tel: +41 21 693 83 98
> > Fax: +41 21 646 41 33
> > --------------------------------------------------
> > 
> >  [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From rolf at math.unb.ca  Fri Jul 16 13:44:11 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 16 Jul 2004 08:44:11 -0300 (ADT)
Subject: [R] small problem with predict
Message-ID: <200407161144.i6GBiBuY018333@erdos.math.unb.ca>

You wrote:

> I have a small problem wit predict() for lm
> 
> Let's say I have predictors x1 and x2, response y
> 
> I want to predict for a new ds say
> dn<-data.frame(x1= seq(min(x1),max(x1),length=10),x2=rep(median(x2),10))
> 
> predict(lm(y~x1+x2),dn,se.fit=T)
> 
> 
> Error message
> >  Error: variables 'x1', 'x2' were specified differently from the fit

	I tried your example (with a made-up ``original'' x1 and x2,
	and y) and got a perfectly reasonable result, with no error
	message.

	Explicitly I did:

	> x1 <- runif(42)
	> x2 <- rnorm(42)
	> y  <- 4 + 2*x1 + 3*x2 + rnorm(42)
	> dn <-data.frame(x1=seq(min(x1),max(x1),length=10),
                          x2=rep(median(x2),10))
	> predict(lm(y~x1+x2),dn,se.fit=T)

	No problema.

	Are you sure you did what you say you did?

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From bitwrit at ozemail.com.au  Fri Jul 16 13:45:42 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Fri, 16 Jul 2004 21:45:42 +1000
Subject: [R] Stumped on methods
Message-ID: <20040716121101.XSHG1245.smta01.mail.ozemail.net@there>

I have been trying to write a "proper" print method for a package, and have 
almost gotten what I want. From a reading of the relevant section in R 
Extensions and the introduction to methods, I've stuck the whole business 
into a character object and used:

NextMethod("print")

However, instead of not printing quotes and displaying the usual 
representation of the string, I get the whole string, newlines and all, in 
quotes. My attempt to shamelessly copy someone else's print method 
was foiled as most of them don't display when one types the function name. I 
presume this is a feature of namespaces.

Needless to say, searching the archives for "print & method" retrieved a 
cornucopia of useless information. I wonder if anyone would be kind enough to 
inform me where to look for the proper incantation? Thanks.

RedHat EL3 L:inux
R-1.9.1
Last.Drink - Aurora Expresso

Jim



From rpeng at jhsph.edu  Fri Jul 16 14:14:19 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 16 Jul 2004 08:14:19 -0400
Subject: [R] contriburl argument to install.packages
In-Reply-To: <40F77D7C.7090604@statistik.uni-dortmund.de>
References: <20040715150545.UDNA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>
	<40F71E81.5060503@jhsph.edu>
	<40F77D7C.7090604@statistik.uni-dortmund.de>
Message-ID: <40F7C69B.3090606@jhsph.edu>

Argh, yes.  I forgot I was using R 1.9.0.  Everything works correctly 
in 1.9.1.

-roger

Uwe Ligges wrote:
> Roger D. Peng wrote:
> 
>> Hmm...is this maybe a bug?  Check out this section of install.packages():
>>
>>     localcran <- length(grep("^file:", contriburl)) > 0
>>     if (!localcran) {
>>         if (is.null(destdir)) {
>>             tmpd <- tempfile("Rinstdir")
>>             if (!dir.create(tmpd))
>>                 stop("Unable to create temp directory ", tmpd)
>>         }
>>         else tmpd <- destdir
>>     }
>>     foundpkgs <- download.packages(pkgs, destdir = tmpd, available = 
>> available,
>>         contriburl = contriburl, method = method)
>>
>> So if `localcran' is TRUE (which in this case, it is), then `tmpd' 
>> never gets defined but is passed to download.packages().
> 
> 
> The help pages tells us (correctly):
> "If CRAN is local, i.e., the URL starts with "file:", then the packages 
> are not downloaded but used directly."
> hence we don't need a destdir in this case, therefore no need to define 
> tmpd.
> 
> 
>> When I run a traceback() after getting the error from running 
>> install.packages(), it fails in download.packages() when trying to 
>> create the download directory.
> 
> 
> Works for me without any error. Are you sure the path you specified was 
> correct? If you are sure, is this R-1.9.1?
> 
> Uwe Ligges



From anne.piotet at urbanet.ch  Fri Jul 16 14:19:14 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Fri, 16 Jul 2004 14:19:14 +0200
Subject: [R] small problem with predict
References: <002201c46b21$17974960$6c00a8c0@mtd4>
	<40F7DA91.36.1312CA2@localhost>
Message-ID: <001a01c46b2f$1bb26e90$6c00a8c0@mtd4>

Thanks Petr,

That was indeed the root of the problem! 

Have a nice week end

Anne


In fact it must be the problem
----- Original Message ----- 
From: "Petr Pikal" <petr.pikal at precheza.cz>
To: <r-help at stat.math.ethz.ch>; "Anne" <anne.piotet at urbanet.ch>
Sent: Friday, July 16, 2004 1:39 PM
Subject: Re: [R] small problem with predict


> Hi Ann
> 
> As I read your code mode closely, I suspect that there could be 
> another variables x1 and x2 somewhere in your search path which 
> led to the error.
> 
> With fresh R session without any data this works as expected
> 
> dold<-data.frame(x1=rnorm(10),x2=5*rnorm(10))
> y<-1:10
> predict(lm(y~x1+x2,dold),dn,se.fit=T)
> 
> Cheers 
> Petr
> 
> On 16 Jul 2004 at 13:19, Petr Pikal wrote:
> 
> > Hi
> > 
> > On 16 Jul 2004 at 12:38, Anne wrote:
> > 
> > > hello to all!
> > > 
> > > I have a small problem wit predict() for lm
> > > 
> > > Let's say I have predictors x1 and x2, response y
> > > 
> > > I want to predict for a new ds say
> > > dn<-data.frame(x1=
> > > seq(min(x1),max(x1),length=10),x2=rep(median(x2),10))
> > > 
> > > predict(lm(y~x1+x2),dn,se.fit=T)
> > > 
> > > 
> > > Error message
> > > >  Error: variables 'x1', 'x2' were specified differently from the
> > > >  fit
> > 
> > AFAIK predixt require to be fed by dataframe in which the 
> > variables has the same names as was in lm() call. Either call lm()
> > with variables named "x1" and "x2" or build the dataframe "dn" with
> > names identical as are names in lm() call
> > 
> > Cheers
> > Petr
> > 
> > 
> > > 
> > > (I looked in the help and found the example
> > > 
> > >  x <- rnorm(15)
> > >      y <- x + rnorm(15)
> > >     new <- data.frame(x = seq(-3, 3, 0.5))
> > >      predict(lm(y ~ x), new, se.fit = TRUE)
> > > 
> > > where is the difference?)
> > > 
> > > 
> > > Anne
> > > 
> > > ----------------------------------------------------
> > > Anne Piotet
> > > Tel: +41 79 359 83 32 (mobile)
> > > Email: anne.piotet at m-td.com
> > > ---------------------------------------------------
> > > M-TD Modelling and Technology Development
> > > PSE-C
> > > CH-1015 Lausanne
> > > Switzerland
> > > Tel: +41 21 693 83 98
> > > Fax: +41 21 646 41 33
> > > --------------------------------------------------
> > > 
> > >  [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > 
> > Petr Pikal
> > petr.pikal at precheza.cz
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
>



From rpeng at jhsph.edu  Fri Jul 16 14:22:10 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 16 Jul 2004 08:22:10 -0400
Subject: [R] Stumped on methods
In-Reply-To: <20040716121101.XSHG1245.smta01.mail.ozemail.net@there>
References: <20040716121101.XSHG1245.smta01.mail.ozemail.net@there>
Message-ID: <40F7C872.5050505@jhsph.edu>

If a method is hidden in a namespace, use getAnywhere(print.whatever) 
to see the code.

-roger

Jim Lemon wrote:
> I have been trying to write a "proper" print method for a package, and have 
> almost gotten what I want. From a reading of the relevant section in R 
> Extensions and the introduction to methods, I've stuck the whole business 
> into a character object and used:
> 
> NextMethod("print")
> 
> However, instead of not printing quotes and displaying the usual 
> representation of the string, I get the whole string, newlines and all, in 
> quotes. My attempt to shamelessly copy someone else's print method 
> was foiled as most of them don't display when one types the function name. I 
> presume this is a feature of namespaces.
> 
> Needless to say, searching the archives for "print & method" retrieved a 
> cornucopia of useless information. I wonder if anyone would be kind enough to 
> inform me where to look for the proper incantation? Thanks.
> 
> RedHat EL3 L:inux
> R-1.9.1
> Last.Drink - Aurora Expresso
> 
> Jim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Fri Jul 16 14:24:31 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 14:24:31 +0200
Subject: [R] Stumped on methods
In-Reply-To: <20040716121101.XSHG1245.smta01.mail.ozemail.net@there>
References: <20040716121101.XSHG1245.smta01.mail.ozemail.net@there>
Message-ID: <40F7C8FF.9080407@statistik.uni-dortmund.de>

Jim Lemon wrote:

> I have been trying to write a "proper" print method for a package, and have 
> almost gotten what I want. From a reading of the relevant section in R 
> Extensions and the introduction to methods, I've stuck the whole business 
> into a character object and used:
> 
> NextMethod("print")

Well, it depends.
If you have some inheritance of classes, you may reallay want to use 
NextMethod(), but that's not necessary if you want to write your own 
print method print.myclass() to print stuff that is not from any 
superclass....
Check out how to write methods in, e.g., Venables and Ripley (2000): "S 
Programming", Springer.

Uwe Ligges



> However, instead of not printing quotes and displaying the usual 
> representation of the string, I get the whole string, newlines and all, in 
> quotes. My attempt to shamelessly copy someone else's print method 
> was foiled as most of them don't display when one types the function name. I 
> presume this is a feature of namespaces.
> 
> Needless to say, searching the archives for "print & method" retrieved a 
> cornucopia of useless information. I wonder if anyone would be kind enough to 
> inform me where to look for the proper incantation? Thanks.
> 
> RedHat EL3 L:inux
> R-1.9.1
> Last.Drink - Aurora Expresso
> 
> Jim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Fri Jul 16 14:41:27 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 16 Jul 2004 08:41:27 -0400
Subject: [R] Stumped on methods
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8068@usrymx25.merck.com>

Jim,

As Uwe said, that's not what NextMethod() is for.  I suspect what you really
want is simply cat()ing the object that you created in your print() method.
If you look in must print() and summary() methods, you'll see a lot of
cat().

HTH,
Andy

> From: Uwe Ligges
> 
> Jim Lemon wrote:
> 
> > I have been trying to write a "proper" print method for a 
> package, and have 
> > almost gotten what I want. From a reading of the relevant 
> section in R 
> > Extensions and the introduction to methods, I've stuck the 
> whole business 
> > into a character object and used:
> > 
> > NextMethod("print")
> 
> Well, it depends.
> If you have some inheritance of classes, you may reallay want to use 
> NextMethod(), but that's not necessary if you want to write your own 
> print method print.myclass() to print stuff that is not from any 
> superclass....
> Check out how to write methods in, e.g., Venables and Ripley 
> (2000): "S 
> Programming", Springer.
> 
> Uwe Ligges
> 
> 
> 
> > However, instead of not printing quotes and displaying the usual 
> > representation of the string, I get the whole string, 
> newlines and all, in 
> > quotes. My attempt to shamelessly copy someone else's print method 
> > was foiled as most of them don't display when one types the 
> function name. I 
> > presume this is a feature of namespaces.
> > 
> > Needless to say, searching the archives for "print & 
> method" retrieved a 
> > cornucopia of useless information. I wonder if anyone would 
> be kind enough to 
> > inform me where to look for the proper incantation? Thanks.
> > 
> > RedHat EL3 L:inux
> > R-1.9.1
> > Last.Drink - Aurora Expresso
> > 
> > Jim
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From hkawakat at qub.ac.uk  Fri Jul 16 14:52:21 2004
From: hkawakat at qub.ac.uk (Hiroyuki Kawakatsu)
Date: Fri, 16 Jul 2004 13:52:21 +0100
Subject: [R] rd2dvi bug on windoze?
Message-ID: <Pine.CYG.4.58.0407161341170.912@erdos>

hi,

can anyone confirm the following problem? when i do

dos> rcmd rd2dvi --pdf my-package-name

i get

dos> Can't open perl script "c:\PROGRA~1\r\rw1091/bin/rd2dvi": No such file or directory

might the problem be in (double back slashes rather than forward slashes)

R-1.9.1\src\gnuwin32\front-ends\rcmdfn.c(251): strcat(cmd, RHome); strcat(cmd, "/bin/Rd2dvi.sh");


> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

@windoze xp sp1

h.
----------------------------------
Hiroyuki Kawakatsu
School of Management and Economics
25 University Square
Queen's University, Belfast
Belfast BT7 1NN
Northern Ireland
United Kingdom
Tel +44 (0)28 9097 3290
Fax +44 (0)28 9033 5156



From dmurdoch at pair.com  Fri Jul 16 15:14:22 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 16 Jul 2004 09:14:22 -0400
Subject: [R] rd2dvi bug on windoze?
In-Reply-To: <Pine.CYG.4.58.0407161341170.912@erdos>
References: <Pine.CYG.4.58.0407161341170.912@erdos>
Message-ID: <jokff09rh2t6l0s67itu3dq1reeku4se0m@4ax.com>

On Fri, 16 Jul 2004 13:52:21 +0100, Hiroyuki Kawakatsu
<hkawakat at qub.ac.uk> wrote :

>hi,
>
>can anyone confirm the following problem? when i do
>
>dos> rcmd rd2dvi --pdf my-package-name
>
>i get
>
>dos> Can't open perl script "c:\PROGRA~1\r\rw1091/bin/rd2dvi": No such file or directory

No, the problem is that rcmd processes commands in a case sensitive
way.  You need

 rcmd Rd2dvi ....

When you have an unrecognized command, rcmd tries to figure out if
it's a Perl script (no extension) or a SH script (.sh extension), then
passes it to the OS to process.  This means

 rcmd rd2dvi.sh ....

works in a case-insensitive way, but that's more or less by accident.
Generally R tries to be case sensitive, but sometimes the work is done
by the OS, and then it depends on the file system.

Duncan Murdoch



From maechler at stat.math.ethz.ch  Fri Jul 16 15:27:44 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 16 Jul 2004 15:27:44 +0200
Subject: R-help or R-devel [was "Re: [R] adding option ..."]
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF805D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF805D@usrymx25.merck.com>
Message-ID: <16631.55248.672778.514149@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Thu, 15 Jul 2004 16:18:43 -0400 writes:

    AndyL> [Not sure if such wishlist item should go to R-help or R-devel...] 

to R-devel  {next time ..}

Note that the posting guide (at the very end of this message)
has been updated recently now has a section on this exact topic
`` Which list: R-help or R-devel? ''

Regards, Martin



From ligges at statistik.uni-dortmund.de  Fri Jul 16 15:29:31 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 15:29:31 +0200
Subject: [R] rd2dvi bug on windoze?
In-Reply-To: <Pine.CYG.4.58.0407161341170.912@erdos>
References: <Pine.CYG.4.58.0407161341170.912@erdos>
Message-ID: <40F7D83B.1@statistik.uni-dortmund.de>

Hiroyuki Kawakatsu wrote:

> hi,
> 
> can anyone confirm the following problem? when i do
> 
> dos> rcmd rd2dvi --pdf my-package-name

a) It's not "dos>", but the Windows command shell.
b) It's called Windows, not windoze
c) The script is called Rd2dvi.sh and in this case the command name 
(Rd2dvi) is case sensitive, hence use

   R CMD Rd2dvi --pdf my-package-name

Uwe Ligges


> i get
> 
> dos> Can't open perl script "c:\PROGRA~1\r\rw1091/bin/rd2dvi": No such file or directory
> 
> might the problem be in (double back slashes rather than forward slashes)
> 
> R-1.9.1\src\gnuwin32\front-ends\rcmdfn.c(251): strcat(cmd, RHome); strcat(cmd, "/bin/Rd2dvi.sh");
> 
> 
> 
>>version
> 
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> @windoze xp sp1
> 
> h.
> ----------------------------------
> Hiroyuki Kawakatsu
> School of Management and Economics
> 25 University Square
> Queen's University, Belfast
> Belfast BT7 1NN
> Northern Ireland
> United Kingdom
> Tel +44 (0)28 9097 3290
> Fax +44 (0)28 9033 5156
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rolf at math.unb.ca  Fri Jul 16 15:47:42 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 16 Jul 2004 10:47:42 -0300 (ADT)
Subject: [R] rd2dvi bug on windoze?
Message-ID: <200407161347.i6GDlgYv022143@erdos.math.unb.ca>

Uwe Ligges wrote:

> b) It's called Windows, not windoze

	No!!! It's definitely Windoze!!!

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From djisgitt at soundenergy.com  Fri Jul 16 15:57:35 2004
From: djisgitt at soundenergy.com (Don Isgitt)
Date: Fri, 16 Jul 2004 08:57:35 -0500
Subject: [R] postscript plotting to 36" roll plotter
Message-ID: <40F7DECF.3030904@soundenergy.com>

Hello,

First, my thanks to the R developers; it is a wonderful tool and 
supports my development and production activities in many helpful ways. 
My problem is as follows:

I want to make long (~ 20-30 feet) plots on a HP 755 (36" color roll 
plotter) using the R postscript command. I have tried paper="special" 
with appropriate width and height, and everything seems ok from the 
postscript side. But the plot gets truncated to whatever -o PageSize I 
specify (which, of course, makes sense). But using -o w2592 (36" roll 
unlimited) truncates to letter. Enough words: here is what I am using now.

postscript("|lpr -P hp755 -o PageSize=ARCHE", 
paper="special",width=ww,length=ll)

This limits me to 48 inches (ARCHE=36*48).

In summary, does anyone know the correct  choice of parameters to get a 
roll plot without a predefined limit.

I did set ps.options(paper)="default" instead of "letter" and I am using 
R 1.8.1 on Linux.

Thank you,

Don

p.s. I am not subscribed to this list, so cc'ing me would be appreciated.



From H.Schuurmans at geog.uu.nl  Fri Jul 16 15:44:28 2004
From: H.Schuurmans at geog.uu.nl (Hanneke Schuurmans)
Date: Fri, 16 Jul 2004 15:44:28 +0200
Subject: [R] median filter
Message-ID: <5.1.1.6.0.20040716153613.00af6578@pop.geog.uu.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/a2733586/attachment.pl

From altirriba at hotmail.com  Fri Jul 16 16:08:16 2004
From: altirriba at hotmail.com (=?iso-8859-1?B?Sm9yZGkgQWx0aXJyaWJhIEd1dGnpcnJleg==?=)
Date: Fri, 16 Jul 2004 16:08:16 +0200
Subject: [R] Permutations (summary)
Message-ID: <BAY15-F17iseXxp6h7900075349@hotmail.com>

Dear R users,

This is a second summary of the permutation problem I previously posted.  
This summary restates the problem as well as the solution.

First of all thanks to everyone including Erich, Robin, Gabor, Christian, 
Ingmar and others for your suggestions.
With the help of an off-list discussion with Gabor I?m going to summarize.


THE PROBLEM

We have 12 elements in blocks of 3 :

   1 2 3 | 4 5 6 | 7 8 9 | 10 11 12

and we want to generate random permutations of these 12 elements such that 
no permutation so generated can be obtained solely through intra-block 
permutations of some previously generated permutation.

In the last sentence intra-block permutations are those permutations which 
shuffle the first three numbers among themselves, the second three numbers 
among themselves, the third three numbers among themselves and the fourth 
three numbers among themselves.  Numbers in one block cannot be permuted 
into another block through an intra-block permutation.  (That would be an 
inter-block permutation.)

For example, if we consider the following potential candidates as successive 
permutations the first is ok, the second is not since its an intra-block 
permutation of the first (thus the 2nd would be rejected) and the third is 
ok since it is not an intra-block permutation of the first.

1 2 3 | 4 5 6 | 7 8 9 | 10 11 12 ---> perm 1
1 3 2 | 4 5 6 | 7 8 9 | 10 11 12 ---> perm 2. NO, swapping 2 & 3 is 
intra-block
1 2 4 | 3 5 6 | 7 8 9 | 10 11 12 ---> perm 3. YES, swapping 3 & 4 is 
inter-block

Here is another example where perm 2 is ok but perm 3 would be rejected as 
perm 3 is an intra-block permutation of perm 2.

1 2 3 | 4 5 6 | 7 8 9 | 10 11 12 ---> perm 1
5 8 10 | 7 9 4 | 12 1 3 | 11 6 2 ---> perm 2. YES. not an intra-block perm 
of 1
5 10 8 | 7 9 4 | 12 1 3 | 11 6 2 ---> perm 3. NO. is intra-block perm of 
perm 2


SOLUTION

Erich Neuwirth defined ordered permutations to be permutations that are 
increasing within each block.  The ordered permutation corresponding to an 
arbitrary permutation of 12 elements is formed by sorting all elements 
within each of the 4 blocks to make them increasing.

With this in mind we can redefine the problem as requiring the generation of 
random permutations such no two permutations on our list can correspond to 
the same ordered permutation.

Gabor Grothendieck provided the following code which uses this idea.  samp() 
generates a permutation of 12 that is stored in z[i,] and returns the 
ordered permutation that corresponds to it.  Each iteration of the for loop 
generates one random permutation using rejection.  That is, each such 
iteration uses a while loop to repeatedly call samp converting the resulting 
ordered permutation to a string and looking it up in z, the vector of all 
previously accepted ordered
permutations.  If its found then the while loop tries again and if it is NOT 
found then the permutation that samp just stored in z[i,] is accepted.

The code is followed by a test generating 10,000 random permutations.

ordered.perm2 <- function(N) {
   samp <- function() c(apply(matrix(z[i,] <<- sample(12,12),3),2,sort))
   s <- vector(length = N, mode = "character")
   z <- matrix(nr = N, nc = 12)
   for(i in 1:N)
      while( (s[i]<-paste(samp(),collapse=" ")) %in% s[seq(len=i-1)] ) {}
   z
}

set.seed(1)
ordered.perm2(10000)


KIRKMAN SCHOOL GIRL PROBLEM

Christian pointed out the Kirkman School Girl Problem.
It is intrigingly similar to the current problem.  At the same time it is 
not exactly the same because the present problem can permute only one 
element and Kirkman's School Girl Problem can not.

For example, the following is an acceptable permutation in our problem but 
not for the Kirkman problem:

1 2 3 | 4 5 6 | 7 8 9 | 10 11 12
1 2 4 | 3 5 6 | 7 8 9 | 10 11 12

For Kirkman?s problem, the four blocks should be different in the two 
permutations.


Thanks to all, and sorry for the initial confusion with intra-block 
permutations,

Jordi Altirriba
PhD student
Hospital Clinic - Barcelona - Spain



From andy_liaw at merck.com  Fri Jul 16 16:23:48 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 16 Jul 2004 10:23:48 -0400
Subject: [R] median filter
Message-ID: <3A822319EB35174CA3714066D590DCD504AF806C@usrymx25.merck.com>

None that I'm aware of, but I believe there are C and Fortran codes floating
around on the 'Net that you can try to link to R.

Andy

> From: Hanneke Schuurmans
> 
> Dear R users,
> 
> Does anyone know if there's a median filter available in R?
> I have a considerable amount of images as 256 by 256 matrices 
> and want to 
> smooth them with a 5x5 median filter. Until now I'm not lucky 
> in searching 
> the R-help list/files.
> 
> Thanks,
> 
> Hanneke
> 
> ir. J.M. (Hanneke) Schuurmans (PhD student)
> Department of Physical Geography
> Faculty of Geosciences, Utrecht University, The Netherlands
> E-mail: h.schuurmans at geog.uu.nl
> Telephone: +31(0)30-2532988 (direct), +31(0)30-2532749 (secretary)
> Fax: +31(0)30-2531145
> Visiting address: Heidelberglaan 2, Utrecht
> Postal address: P.O.Box 80.115, 3508 TC Utrecht
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From bill.shipley at usherbrooke.ca  Fri Jul 16 17:19:45 2004
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Fri, 16 Jul 2004 11:19:45 -0400
Subject: [R] specifying a function in nls
Message-ID: <001901c46b48$535c45f0$801ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/738a7d0c/attachment.pl

From sundar.dorai-raj at PDF.COM  Fri Jul 16 17:28:18 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 16 Jul 2004 08:28:18 -0700
Subject: [R] specifying a function in nls
In-Reply-To: <001901c46b48$535c45f0$801ad284@BIO041>
References: <001901c46b48$535c45f0$801ad284@BIO041>
Message-ID: <40F7F412.5090000@pdf.com>



Bill Shipley wrote:
> Hello.  I am trying to understand the syntax of the nonlinear least
> squares function (nls) when the function definition is made outside of
> the call.  Here is the context.
> 
> 1.	If I specify the following command, it works fine:
> 
>  
> 
> 
>>fit2<-nls(
> 
> 
> + A~Am*(1-exp(-alpha*(I-LCP))),data=dat1,
> 
> + start=list(Am=3.6,alpha=0.01,LCP=20))
> 
>  
> 
> 2.	Now, I want to be able to specify the function definition
> outside of nls.  I do the following:
> 
>  
> 
> 
>>Mitscherlich<-function(Am,alpha,I,LCP,...){
> 
> 
> Am*(1-exp(-alpha*(I-LCP)))
> 
> }
> 
>  
> 
> and then:
> 
>  
> 
> 
>>fit3<-nls(
> 
> 
> + A~Mitscherlich,data=dat1,
> 
> + start=list(Am=2.7,alpha=0.006,LCP=45))
> 
>  
> 
> and I get the error message: Error in lhs - rhs : non-numeric argument
> to binary operator
> 
>  
> 
> What am I doing wrong?
> 

Hi Bill,

I think you want:

fit3 <- nls(A ~ Mitscherlich(Am, alpha, I, LCP),
             data = dat1,
             start = list(Am = 2.7, alpha = 0.006, LCP = 45))

Also, I don't see where you supply "I" (which is a bad choice for a 
variable name).

There is an example of this in ?nls.

--sundar



From anne.piotet at urbanet.ch  Fri Jul 16 17:30:54 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Fri, 16 Jul 2004 17:30:54 +0200
Subject: [R] still problems with predict!
Message-ID: <000701c46b49$e2852de0$6c00a8c0@mtd4>

Hi all,

I still have problems with the predict function by setting up the values on
which I want to predict

ie:
original df: p1 (193 obs) variates y x1 x2

rm(list=ls())
x1<-rnorm(193)
x2<-runif(193,-5,5)
y<-rnorm(193)+x1+x2
p1<-as.data.frame(cbind(y,x1,x2))
p1
             y         x1         x2
1   -0.6056448 -0.1113607 -0.5859728
2   -4.2841793 -1.0432688 -3.3116807
......
192 -1.3228239  1.0263013 -2.7801324
193  1.8736683  1.0480632  0.4746959

newdf<-data.frame(x1= seq(min( p1$x1),max( p1$x1),length=10),
                              x2=rep(median( p1$x2),10) )
pr<-predict(g<-lm(p1$y~p1$x1+p1$x2) ,newdf, se.fit = TRUE)

newdf
           x1         x2
1  -2.3844149 -0.2594991
2  -1.8388635 -0.2594991
...
9   1.9799963 -0.2594991
10  2.5255477 -0.2594991

pr$fit
1   -0.6766906
2   -4.4198864
.....
192 -1.6531906
193  1.6395442

so apparently the predict() function did not take up the new data.frame


I looked up with conflicts() to see if I had masked objects in the search
path potentially causing this problem
but found none



Thanks and a good week end! (I for one need it)
Anne
----------------------------------------------------
Anne Piotet
Tel: +41 79 359 83 32 (mobile)
Email: anne.piotet at m-td.com
---------------------------------------------------
M-TD Modelling and Technology Development
PSE-C
CH-1015 Lausanne
Switzerland
Tel: +41 21 693 83 98
Fax: +41 21 646 41 33



From roebuck at odin.mdacc.tmc.edu  Fri Jul 16 17:43:16 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 16 Jul 2004 10:43:16 -0500 (CDT)
Subject: [R] Functions in a package not visible to a user
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8063@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8063@usrymx25.merck.com>
Message-ID: <Pine.OSF.4.58.0407161010191.158666@odin.mdacc.tmc.edu>

On Thu, 15 Jul 2004, Andy Liaw wrote:

> Rui Dantas wrote:
>
> > I have a package with several R functions. Some are internal auxiliary
> > functions, and should not be available to the user (nor do they, for
> > example, need "user" documentation). How can I hide them?
>
> That's one of the purposes of the namespace.  See Prof. Tierney's article in
> the R Newsletter, or the slides of his keynote lecture at the useR! 2004
> conference.  It's also explained in the `Writing R Extensions' manual.
> Basically you only export functions that the users should see.  The manual
> also explains how to not document functions that aren't intended to be
> called by users.

Am I the only one who finds the namespace still too limited?
It still lacks the middle ground of being able to have only
package level access without declaring functions public.

I also found the suggested documentation standard for private
functions too limiting. I modified the R-ext 1.1.4 recommendation
for my package to use multiple '<function>-internal.Rd' instead of
a single '<package>-internal.Rd'; this allowed me to document the
disparate functions with logical grouping rather than using the
suggested "bag" approach.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From thpe at hhbio.wasser.tu-dresden.de  Fri Jul 16 17:52:14 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 16 Jul 2004 17:52:14 +0200
Subject: [R] strucchange: breakpoints in inequally spaced data
Message-ID: <40F7F9AE.5080409@hhbio.wasser.tu-dresden.de>

Hello,

we want to identify breakpoints (different phases) in environmental 
data, algae cell counts of three years with intervals between 7 and 30 
days (N=40). We found that

breakpoints(cells ~1)

works great and identifies 5 very good breaks, however we are uncertain 
about these, because the data are unequally spaced. Is there a way to 
include the information about the measurement intervals, e.g.

breakpoints(cells[-1] ~ diff(time))

Furthermore we wonder, why the OLS-CUSUM indicates several of these 
breakpoints but does not mark them as significant.

Thanks in advance!

Thomas P.



From sundar.dorai-raj at PDF.COM  Fri Jul 16 17:55:43 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 16 Jul 2004 08:55:43 -0700
Subject: [R] still problems with predict!
In-Reply-To: <000701c46b49$e2852de0$6c00a8c0@mtd4>
References: <000701c46b49$e2852de0$6c00a8c0@mtd4>
Message-ID: <40F7FA7F.3090003@pdf.com>



Anne wrote:

> Hi all,
> 
> I still have problems with the predict function by setting up the values on
> which I want to predict
> 
> ie:
> original df: p1 (193 obs) variates y x1 x2
> 
> rm(list=ls())
> x1<-rnorm(193)
> x2<-runif(193,-5,5)
> y<-rnorm(193)+x1+x2
> p1<-as.data.frame(cbind(y,x1,x2))
> p1
>              y         x1         x2
> 1   -0.6056448 -0.1113607 -0.5859728
> 2   -4.2841793 -1.0432688 -3.3116807
> ......
> 192 -1.3228239  1.0263013 -2.7801324
> 193  1.8736683  1.0480632  0.4746959
> 
> newdf<-data.frame(x1= seq(min( p1$x1),max( p1$x1),length=10),
>                               x2=rep(median( p1$x2),10) )
> pr<-predict(g<-lm(p1$y~p1$x1+p1$x2) ,newdf, se.fit = TRUE)
> 
> newdf
>            x1         x2
> 1  -2.3844149 -0.2594991
> 2  -1.8388635 -0.2594991
> ...
> 9   1.9799963 -0.2594991
> 10  2.5255477 -0.2594991
> 
> pr$fit
> 1   -0.6766906
> 2   -4.4198864
> .....
> 192 -1.6531906
> 193  1.6395442
> 
> so apparently the predict() function did not take up the new data.frame
> 
> 
> I looked up with conflicts() to see if I had masked objects in the search
> path potentially causing this problem
> but found none
> 
> 
> 

Hi Anne,

predict is working properly (though not as you expected). It's not 
evaluating your newdf because it has no columns called p1$x1 or p1$x2. 
Try this instead:

pr <- predict(g <- lm(y ~ x1 + x2, p1), newdf, se.fit = TRUE)

 > str(pr)
List of 4
  $ fit           : Named num [1:10] -2.365 -1.865 -1.366 -0.867 -0.367 ...
   ..- attr(*, "names")= chr [1:10] "1" "2" "3" "4" ...
  $ se.fit        : Named num [1:10] 0.1751 0.1424 0.1120 0.0868 0.0723 ...
   ..- attr(*, "names")= chr [1:10] "1" "2" "3" "4" ...
  $ df            : int 190
  $ residual.scale: num 0.987


--sundar



From ligges at statistik.uni-dortmund.de  Fri Jul 16 18:00:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jul 2004 18:00:13 +0200
Subject: [R] still problems with predict!
In-Reply-To: <000701c46b49$e2852de0$6c00a8c0@mtd4>
References: <000701c46b49$e2852de0$6c00a8c0@mtd4>
Message-ID: <40F7FB8D.3070105@statistik.uni-dortmund.de>

Anne wrote:

> Hi all,
> 
> I still have problems with the predict function by setting up the values on
> which I want to predict
> 
> ie:
> original df: p1 (193 obs) variates y x1 x2
> 
> rm(list=ls())
> x1<-rnorm(193)
> x2<-runif(193,-5,5)
> y<-rnorm(193)+x1+x2
> p1<-as.data.frame(cbind(y,x1,x2))
> p1
>              y         x1         x2
> 1   -0.6056448 -0.1113607 -0.5859728
> 2   -4.2841793 -1.0432688 -3.3116807
> ......
> 192 -1.3228239  1.0263013 -2.7801324
> 193  1.8736683  1.0480632  0.4746959
> 
> newdf<-data.frame(x1= seq(min( p1$x1),max( p1$x1),length=10),
>                               x2=rep(median( p1$x2),10) )
> pr<-predict(g<-lm(p1$y~p1$x1+p1$x2) ,newdf, se.fit = TRUE)

Anne, predict cannot replace the data set properly, because you have 
specified fixed values in

   g <- lm(p1$y ~ p1$x1 + p1$x2)

Instead, use:

   g <- lm(y ~ x1 + x2, data = p1)

and all the stuff will work.



Please insert some blanks in your code to make it readable, and try to 
give reproducable examples by, e.g., setting the seed as in:

   set.seed(123)
   rm(list=ls())
   x1 <- rnorm(193)
   x2 <- runif(193, -5, 5)
   y  <- rnorm(193) + x1 + x2
   p1 <- data.frame(y = y, x1 = x1, x2 = x2)

   newdf <- data.frame(x1 = seq(min(p1$x1), max(p1$x1), length = 10),
                       x2 = rep(median(p1$x2), 10))

   g <- lm(y ~ x1 + x2, data = p1)

   pr1 <- predict(g, se.fit = TRUE)
   pr2 <- predict(g, newdata = newdf, se.fit = TRUE)


Uwe Ligges



> newdf
>            x1         x2
> 1  -2.3844149 -0.2594991
> 2  -1.8388635 -0.2594991
> ...
> 9   1.9799963 -0.2594991
> 10  2.5255477 -0.2594991
> 
> pr$fit
> 1   -0.6766906
> 2   -4.4198864
> .....
> 192 -1.6531906
> 193  1.6395442
> 
> so apparently the predict() function did not take up the new data.frame
> 
> 
> I looked up with conflicts() to see if I had masked objects in the search
> path potentially causing this problem
> but found none
> 
> 
> 
> Thanks and a good week end! (I for one need it)
> Anne
> ----------------------------------------------------
> Anne Piotet
> Tel: +41 79 359 83 32 (mobile)
> Email: anne.piotet at m-td.com
> ---------------------------------------------------
> M-TD Modelling and Technology Development
> PSE-C
> CH-1015 Lausanne
> Switzerland
> Tel: +41 21 693 83 98
> Fax: +41 21 646 41 33
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From 0034058 at fudan.edu.cn  Fri Jul 16 18:13:17 2004
From: 0034058 at fudan.edu.cn (ronggui)
Date: Sat, 17 Jul 2004 00:13:17 +0800
Subject: [R] any package can do such job?
Message-ID: <0I0Y00H2YCRIOE@mail.fudan.edu.cn>

any one know any packages can do the job describe in Michael E. Sobel's artical NEARAND
LOG-NONLINEAR MODELS   FOR ORDINALSCALES WITH     MIDPOINTS, WITHAN  APPLICATION TO PUBLIC
OPINION DATA .it is said that "A set of S Plus instructions to fit the models described in Section 3 of this  paper is available from Statlib at     htp://lib.stat.cmu.edu/general/midpoints.splus, or
by sending the E-mail message send midpoints.splus from general to statlib at stat.
cmu.edu."  but it seems can't be found on the website above.

thank you in advance !



From andy_liaw at merck.com  Fri Jul 16 18:40:20 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 16 Jul 2004 12:40:20 -0400
Subject: [R] still problems with predict!
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8074@usrymx25.merck.com>

One thing to etch into your brain:  Don't use constructs like

  lm(p1$y~p1$x1+p1$x2)

Instead, use:

  lm(y ~ x1 + x2, data=p1)

Doing the former is only asking for trouble when it comes time to do
prediction.  It will look for `p1$y' in the newdata, and of course, won't
find it there!

Andy


> From: Anne
> 
> Hi all,
> 
> I still have problems with the predict function by setting up 
> the values on
> which I want to predict
> 
> ie:
> original df: p1 (193 obs) variates y x1 x2
> 
> rm(list=ls())
> x1<-rnorm(193)
> x2<-runif(193,-5,5)
> y<-rnorm(193)+x1+x2
> p1<-as.data.frame(cbind(y,x1,x2))
> p1
>              y         x1         x2
> 1   -0.6056448 -0.1113607 -0.5859728
> 2   -4.2841793 -1.0432688 -3.3116807
> ......
> 192 -1.3228239  1.0263013 -2.7801324
> 193  1.8736683  1.0480632  0.4746959
> 
> newdf<-data.frame(x1= seq(min( p1$x1),max( p1$x1),length=10),
>                               x2=rep(median( p1$x2),10) )
> pr<-predict(g<-lm(p1$y~p1$x1+p1$x2) ,newdf, se.fit = TRUE)
> 
> newdf
>            x1         x2
> 1  -2.3844149 -0.2594991
> 2  -1.8388635 -0.2594991
> ...
> 9   1.9799963 -0.2594991
> 10  2.5255477 -0.2594991
> 
> pr$fit
> 1   -0.6766906
> 2   -4.4198864
> .....
> 192 -1.6531906
> 193  1.6395442
> 
> so apparently the predict() function did not take up the new 
> data.frame
> 
> 
> I looked up with conflicts() to see if I had masked objects 
> in the search
> path potentially causing this problem
> but found none
> 
> 
> 
> Thanks and a good week end! (I for one need it)
> Anne
> ----------------------------------------------------
> Anne Piotet
> Tel: +41 79 359 83 32 (mobile)
> Email: anne.piotet at m-td.com
> ---------------------------------------------------
> M-TD Modelling and Technology Development
> PSE-C
> CH-1015 Lausanne
> Switzerland
> Tel: +41 21 693 83 98
> Fax: +41 21 646 41 33
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From WWei at mdanderson.org  Fri Jul 16 19:48:15 2004
From: WWei at mdanderson.org (WWei@mdanderson.org)
Date: Fri, 16 Jul 2004 12:48:15 -0500
Subject: [R] rpart and TREE, can be the same?
Message-ID: <OF3C1FA028.FEACEA60-ON86256ED3.005FBB49-86256ED3.0061C856@mdacc.tmc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/4b300363/attachment.pl

From bill.shipley at usherbrooke.ca  Fri Jul 16 19:49:35 2004
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Fri, 16 Jul 2004 13:49:35 -0400
Subject: [R] specifying a complex function in nls
Message-ID: <002001c46b5d$41b26f40$801ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/253711f0/attachment.pl

From andy_liaw at merck.com  Fri Jul 16 20:01:06 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 16 Jul 2004 14:01:06 -0400
Subject: [R] rpart and TREE, can be the same?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8075@usrymx25.merck.com>

I guess if you define the splitting criterion in rpart so that it matches
the one used in tree(), that's possible.  However, I believe the two also
differ in how they handle NAs.

Andy

> From:  WWei at mdanderson.org
> 
> Hi, all,
> 
> I am wondering if it is possible to set parameters of 'rpart' 
> and 'tree' 
> such that they will produce the exact same tree? Thanks.
> 
> Auston Wei
> Statistical Analyst
> Department of Biostatistics and Applied Mathematics
> The University of Texas MD Anderson Cancer Center
> Tel: 713-563-4281
> Email: wwei at mdanderson.org
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From liao1k at cmich.edu  Fri Jul 16 20:47:10 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Fri, 16 Jul 2004 14:47:10 -0400
Subject: [R] Install R on AIX 5.2 64 Bit
Message-ID: <291B348BC59B47468C7824603C326082946054@cmail3.central.cmich.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/ff82d411/attachment.pl

From k.hansen at biostat.ku.dk  Fri Jul 16 21:59:57 2004
From: k.hansen at biostat.ku.dk (Kasper Daniel Hansen)
Date: Fri, 16 Jul 2004 21:59:57 +0200
Subject: [R] interpreting profiling output
Message-ID: <wqroemflo3m.fsf@biostat.ku.dk>

I have some trouble interpreting the output from profiling. I have
read the help pages Rprof, summaryRprof and consult the R extensions
manual, but I still have problems understanding the output.

Basically the output consist of self.time and total.time. I have the
understanding that total.time is the time spent in a given function
including any subcalls or child functions or whatever the technical
term for that activity is. In contrasts self.time is the time spent in
the function excluding subcalls.

Now, in my understanding basically everything in R is functions. I
would then guess that for almost any function (except the "atomic
ones") the self.time would be very small as it would spend most of its
time calling other functions (again, since almost everything is a
function). So how do R determine when a subfunction is called?

Looking at a practical example, which basically consists of a model
search, with each model being evaluated by a nnet fit, I get (using
the default value of interval=0.02 - the output is basically similar
for interval = 0.01)

> prof02.out$by.total[1:10,]
                     total.time total.pct self.time self.pct
cv.risk.dsa2            2373.50     100.0      0.00      0.0
validation.risk.dsa2    2373.50     100.0      0.00      0.0
avg.pred.nnet           2370.98      99.9      4.36      1.5
dsa.2                   2337.32      98.5      0.00      0.0
best.move.dsa2          2335.22      98.4      0.06      0.0
avg.nnet                2335.10      98.4      0.04      0.0
nnet                    2188.22      92.2      1.74      0.6
nnet.default            2186.48      92.1     33.32     11.2
sub.dsa2                1466.32      61.8      0.18      0.1
del.dsa2                 560.36      23.6      0.02      0.0

This tells me that the majority (92%) is spent in the nnet
fit. Therefore it seems that the only real improvement to the code
would be to change the algorithm in order to call nnet fewer
times. The actual search code only amounts to a little amout of the
total time.

Looking at sampling.time, the fourth column (total.time in percent) is
the third column (total.time) divided by sampling.time (which makes
sense).

My trouble really begins when I look at the self.time column.

> prof02.out$by.self[1:10,]
                  self.time self.pct total.time total.pct
nnet.default          33.32     11.2    2186.48      92.1
FUN                   23.42      7.8      46.34       2.0
as.integer            22.28      7.5      30.92       1.3
mean.default          16.14      5.4      22.92       1.0
as.double.default     11.52      3.9      11.52       0.5
apply                 10.22      3.4      60.80       2.6
as.double             10.14      3.4      30.24       1.3
rep.default            9.98      3.3      19.96       0.8
matrix                 9.62      3.2      75.86       3.2
add.net                8.80      2.9      10.16       0.4

First of, I would guess that the sum of the self.time column
_ought_??? to be equal to the sampling time, which it is not
> sum(prof02.out$by.self[,1])
[1] 298.4
> prof02.out$sampling.time
[1] 2373.5
Why does such a large discrepancy happen?

Secondly, looking at the output for as.integer, there is a big
difference between total.time and self.time - but I would _guess_
as.integer to be a pretty basic function, which does not call any
subfunctions, and in that case I would expect total.time to be equal
to self.time.

In short : I think I grasp the total time concept, but I have a hard
time understanding self.time. Specifically
 - Why is the sampling time so different from the sum of the self.time
 - Which function calls (or operations) are considered to belong to a
 given function's self.time and which are not.
 - Why is total.time != self.time for the as.integer function.

I guess some of the answers would be clear if I had a firm grasp of
the inner workings of R :)

Thanks in advance, Kasper
-- 
Kasper Daniel Hansen, Research Assistant
Department of Biostatistics, University of Copenhagen



From paulangonzalez at hotmail.com  Fri Jul 16 22:09:05 2004
From: paulangonzalez at hotmail.com (pau gonzalez)
Date: Fri, 16 Jul 2004 20:09:05 +0000
Subject: [R] plot
Message-ID: <Sea1-F135HsjCGvseE40000513d@hotmail.com>

Hi! R users
I want make a plot with grouping variables.
Can you help me?
Thanks
Paula



From chun.49 at osu.edu  Fri Jul 16 22:15:52 2004
From: chun.49 at osu.edu (Yongwan Chun)
Date: Fri, 16 Jul 2004 16:15:52 -0400
Subject: [R] question in foreign library
Message-ID: <000001c46b71$b20decb0$6500a8c0@ywchun>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/51fdbdc1/attachment.pl

From valentin.todorov at chello.at  Fri Jul 16 22:26:33 2004
From: valentin.todorov at chello.at (Valentin Todorov)
Date: Fri, 16 Jul 2004 22:26:33 +0200
Subject: [R] Eclipse plugin for R or perhaps S-plus. 
Message-ID: <004201c46b73$2f47eb30$0101a8c0@KILER>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040716/10487b5c/attachment.pl

From sundar.dorai-raj at PDF.COM  Fri Jul 16 22:19:30 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 16 Jul 2004 13:19:30 -0700
Subject: [R] plot
In-Reply-To: <Sea1-F135HsjCGvseE40000513d@hotmail.com>
References: <Sea1-F135HsjCGvseE40000513d@hotmail.com>
Message-ID: <40F83852.4060802@pdf.com>



pau gonzalez wrote:

> Hi! R users
> I want make a plot with grouping variables.
> Can you help me?
> Thanks
> Paula
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Please read the manuals and try the examples and of course the posting 
guide. There's no telling from your question what you want to see.

--sundar



From yuleih at umich.edu  Fri Jul 16 22:40:43 2004
From: yuleih at umich.edu (Yulei He)
Date: Fri, 16 Jul 2004 16:40:43 -0400 (EDT)
Subject: [R] for loops in Gibbs sampler
Message-ID: <Pine.SOL.4.58.0407151418020.9130@zektor.gpcc.itd.umich.edu>

Dear all:

I am using R to do multiple imputation for longitudinal data set. The
Gibbs chain basically requires draw posterior distribution of model
parameters, including the random effects. The multiple imputation requires
several independent Gibbs chains. So my program structure is like:

for (chain in 1:5)
{
 # perform Gibbs sampling...

 for (row in 1:row.no)
 {
  b.row=some function # draw random effects from each row of the data
 matrix;
  ...
 }
 ...
}

I used two for loops. I know that for loops should be avoided in R. Since
the Gibbs chains are independent, so does the draw of the random effects
for the data matrix, I am just wondering if there exists faster command in
R to do above operation. I happen to see function sapply(), will it be
faster than my double for loops? Your help will be greatly appreciated.

Yulei


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Yulei He
1586 Murfin Ave. Apt 37
Ann Arbor, MI 48105-3135
yuleih at umich.edu
734-647-0305(H)
734-763-0421(O)
734-763-0427(O)
734-764-8263(fax)
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$



From h.wickham at gmail.com  Fri Jul 16 22:50:03 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 17 Jul 2004 08:50:03 +1200
Subject: [R] Strange (non-deterministic) problem with strsplit
Message-ID: <f8e6ff05040716135022ed686e@mail.gmail.com>

I'm having an odd problem with strsplit (well I think it's strplit
that's causing the problem).  When I run the code below as follows:
 str(parseFormulaMin(y +x +d ~ b +d +e| a * b))

I expect to get
List of 3
 $ y: chr "y+x+d"
 $ x: chr "b+d+e"
 $ g: chr "a*b"

But about half the time I get 

List of 3
 $ y: chr "y+x+d"
 $ x: chr "b+d+e"
 $ g: chr "a*[square box]"
(square box not reproduced here because copy and pasting it seems to
break my web mail)

Can anyone reproduce the problem and/or suggest any solutions? 

parseFormula <- function(formula) {
	splitvars <- function(x) {
		strsplit(x, "\\+|\\*")[[1]]
	}
	stripwhitespace <- function(x) {
		gsub("\\s", "", x, perl=T)
	}
	
	vars <- stripwhitespace(as.character(formula)[3])
	varsplit <- strsplit(vars, "|", fixed=TRUE)[[1]]

	parts <- list(
		y = stripwhitespace(as.character(formula)[2]),
		x = varsplit[1],
		g = varsplit[2]
	)
	lapply(parts, splitvars)
} 

Thanks,

Hadley



From plorch at email.unc.edu  Fri Jul 16 23:32:45 2004
From: plorch at email.unc.edu (Patrick Lorch)
Date: Fri, 16 Jul 2004 17:32:45 -0400
Subject: [R] highlighting subset of point with xyplot (or Hmisc(xYplot))
Message-ID: <AD3C6746-D76F-11D8-91B5-000A95903B7A@email.unc.edu>

Hello all,
	I am trying to use xyplot to give a six panel plot and to highlight 
only points (in any panel) that meet a certain criterion.  With the 
plot command I would do something like:
	plot.default(filein$Site,filein$circ.conc)
	points(filein$Site,filein$circ.conc,type="p",
		pch=ifelse(filein$p.value<5e-02,19,21))
I had thought I could just stick in the pch line from above into either 
xyplot or xYplot with groups set to Site like:
	xyplot(circ.conc~Day|Site,data=allsites.byday,groups=Site, 
pch=ifelse(allsites.byday$p.value<5e-02,19,21))
This does not produce any highlighting (all symbols come out as open 
circles (19)).  I have not messed with writing my own panel functions, 
though I know that is where the solution must lie.  Hopefully someone 
has an example that is close enough to help me.  I can send an example 
plot to anyone that wants one.
	Thanks,
	 -Pat

Dr. Patrick D. Lorch

                 plorch at email.unc.edu
      http://www.unc.edu/~plorch/lorch.html
Department of Biology           W: 919-843-2320
University of North Carolina    F: 919-962-1625
   at Chapel Hill
CB#3280, Coker Hall
Chapel Hill, NC 27599-3280
USA



From axelrod1 at llnl.gov  Fri Jul 16 23:40:57 2004
From: axelrod1 at llnl.gov (Michael Axelrod)
Date: Fri, 16 Jul 2004 14:40:57 -0700
Subject: [R] Random Fields
Message-ID: <5.2.1.1.2.20040716143542.019b6538@mail.llnl.gov>

I have tried to install the package RandomFields (using the packages menu) 
from CRAN and it fails to open the zip file. I then tried downloading the 
package from the author's site, but it still fails to install. Anyone had 
any success with this? Or am I doing something wrong.

Thanks in advance for any help.

Michael Axelrod



From deepayan at stat.wisc.edu  Fri Jul 16 23:42:21 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 16 Jul 2004 16:42:21 -0500
Subject: [R] highlighting subset of point with xyplot (or Hmisc(xYplot))
In-Reply-To: <AD3C6746-D76F-11D8-91B5-000A95903B7A@email.unc.edu>
References: <AD3C6746-D76F-11D8-91B5-000A95903B7A@email.unc.edu>
Message-ID: <200407161642.21266.deepayan@stat.wisc.edu>

On Friday 16 July 2004 16:32, Patrick Lorch wrote:
> Hello all,
> 	I am trying to use xyplot to give a six panel plot and to highlight 
> only points (in any panel) that meet a certain criterion.  With the 
> plot command I would do something like:
> 	plot.default(filein$Site,filein$circ.conc)
> 	points(filein$Site,filein$circ.conc,type="p",
> 		pch=ifelse(filein$p.value<5e-02,19,21))
> I had thought I could just stick in the pch line from above into either 
> xyplot or xYplot with groups set to Site like:
> 	xyplot(circ.conc~Day|Site,data=allsites.byday,groups=Site, 
> pch=ifelse(allsites.byday$p.value<5e-02,19,21))
> This does not produce any highlighting (all symbols come out as open 
> circles (19)).  I have not messed with writing my own panel functions, 
> though I know that is where the solution must lie.  Hopefully someone 
> has an example that is close enough to help me.  I can send an example 
> plot to anyone that wants one.

It's difficult to check without data, but I believe the following would work:

xyplot(circ.conc ~ Day | Site, data=allsites.byday, 
       ## groups=Site, I don't see the point of this
       groups = p.value<5e-02, 
       pch = c(19, 21))

Note that I have removed the original groups variable, because I don't see a 
point in having that (since Site is already used as a conditioning variable). 
If you really need another grouping variable, then this would become slightly 
more complicated. 

Deepayan



From solares at unsl.edu.ar  Sat Jul 17 00:00:35 2004
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Fri, 16 Jul 2004 19:00:35 -0300 (ART)
Subject: [R] help with tkbind.tag
Message-ID: <42506.170.210.173.216.1090015235.squirrel@inter17.unsl.edu.ar>

Hi, excuse me, i don??t understan how bind a tag in R, how to use the
function tkbind.tag, i used them but appear an error
library(tcltk)
tt<-tktoplevel()
editor<-tktext(tt)
tkpack(editor)
tkinsert(editor,"1.0","first line \n")
tkinsert(editor,"2.0","Second line \n")
tkinsert(editor,"3.0","Third line \n")
tkinsert(editor,"end", "1. Texto que reacciona a eventos. d1")
tkinsert(editor,"end","\n\n")
tktag.configure(editor,"d1",foreground="red")
 tktag.bind(editor,"d1",command=function(){})
tkbind(editor,"d1",<B1-Motion>, command=function(){print("hello"))})

i wish when move the mouse under the text appear a message "hello", how i
have this?, i search help in the R mailing list
but not exist. Thanks Ruben
>Error ......
thanks Ruben



From bitwrit at ozemail.com.au  Sat Jul 17 00:08:58 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sat, 17 Jul 2004 08:08:58 +1000
Subject: [R] Stumped on methods
Message-ID: <20040716220256.WGPA29860.smta07.mail.ozemail.net@there>

Thank you all, gentlemen. getAnywhere(), which I blush to say I have seen 
flash by in a few recent messages, allowed me to see the awful truth. But for 
the fact that it sounds like one of those gizmos in science fiction that 
allow one to turn up in the next galaxy, I might have twigged.

Jim



From gadkison at email.wcu.edu  Sat Jul 17 00:18:10 2004
From: gadkison at email.wcu.edu (Greg Adkison)
Date: Fri, 16 Jul 2004 18:18:10 -0400
Subject: [R] sas to r
Message-ID: <40F81BE2.3410.424D13@localhost>

I would be incredibly grateful to anyone who'll help me translate some 
SAS code into R code.

Say for example that I have a dataset named "dat1" that includes five 
variables:  wshed, site, species, bda, and sla.  I can calculate with the 
following SAS code the mean, CV, se, and number of observations of 
"bda" and "sla" for each combination of "wshed," "species," and "site," 
restricting the species considered to only three of several species in 
dat1 (b, c, and p).  Moreover, I can output these calculations and 
grouping variables to a dataset named "dat2" that will reside in RAM 
and include the variables  wshed, site, species, mBdA, msla, cBda, 
sBdA, ssla, nBda, and nsla.

proc sort data=dat1;
  by wshed site species;
proc means data=dat1 noprint mean cv stderr n;
  by wshed site species;
  where species in ('b', 'c', 'p');
  var BdA sla;
  output out=dat2
    mean=mBdA msla
    cv=cBdA csla
    stderr=sBdA ssla
    n=nBdA nsla;

Thanks,
Greg



From andrewr at uidaho.edu  Sat Jul 17 00:22:47 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Fri, 16 Jul 2004 18:22:47 -0400
Subject: [R] nlm doesn't detect a gradient in my function
Message-ID: <1e3b741e4548.1e45481e3b74@uidaho.edu>

Hi R-community,

I wonder if anyone has dealt with this problem?  I've written a negative log-likelihood function of 4 parameters, and I want to minimize it. It doesn't have derivative information (it actually requires running an external program).  I can detect a gradient in it, e.g.:



> toy.likelihood.4.2(c(80.5, 43.0, 0.385, 6.5))
[1] 24664.62
> toy.likelihood.4.2(c(79.5, 43.0, 0.385, 6.5))
[1] 24657.32
> toy.likelihood.4.2(c(79.5, 43.0, 0.375, 6.5))
[1] 24669.77



but nlm can't detect a gradient in that region:



> unweighted.mle.1 <- nlm(toy.likelihood.4.2,
+                         c(80.5, 43.0, 0.385 6.5),
+                         hessian=T, print.level=2)
iteration = 0
Parameter:
[1] 80.500 43.000  0.385  6.500
Function Value
[1] 24664.62
Gradient:
[1] 0 0 0 0

Relative gradient close to zero.
Current iterate is probably solution.



Can anyone suggest a remedy?

Thanks much,

Andrew



From macq at llnl.gov  Sat Jul 17 00:58:08 2004
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 16 Jul 2004 15:58:08 -0700
Subject: [R] sas to r
In-Reply-To: <40F81BE2.3410.424D13@localhost>
References: <40F81BE2.3410.424D13@localhost>
Message-ID: <p06002015bd1e0dd65432@[128.115.153.6]>

Here's one way...

Not tested, so there maybe typos and such, but I've used this 
approach successfully quite a few times.

It can get kind of slow if dat1 has many, many rows.
The coding assumes no missing data, though that could be handled by 
adding the na.rm argument in apppropriate places, and changing the 
nrow() to something that counts only non-missing data.

myfun <- function(dfr) {
   data.frame(
              wshed=dfr$wshed[1],
              site=dfr$site[1],
              species=dfr$species[1],
              mBda=mean(dfr$BdA),
              cBda=sd(dfr$Bda)/mean(dfr$Bda),
              sBda=sd(dfr$Bda)/sqrt(nrow(dfr)),
              nBda=nrow(dfr),
              msla=mean(dfr$BdA),
              csla=sd(dfr$sla)/mean(dfr$sla),
              ssla=sd(dfr$sla)/sqrt(nrow(dfr)),
              nsla=nrow(dfr))
}

tmp1 <- split(dat1,paste(dat1$wshed,dat1$site,dat1$species))
tmp2 <- lapply(tmp1,myfun)
dat2 <- do.call('rbind',tmp2)

-Don

At 6:18 PM -0400 7/16/04, Greg Adkison wrote:
>I would be incredibly grateful to anyone who'll help me translate some
>SAS code into R code.
>
>Say for example that I have a dataset named "dat1" that includes five
>variables:  wshed, site, species, bda, and sla.  I can calculate with the
>following SAS code the mean, CV, se, and number of observations of
>"bda" and "sla" for each combination of "wshed," "species," and "site,"
>restricting the species considered to only three of several species in
>dat1 (b, c, and p).  Moreover, I can output these calculations and
>grouping variables to a dataset named "dat2" that will reside in RAM
>and include the variables  wshed, site, species, mBdA, msla, cBda,
>sBdA, ssla, nBda, and nsla.
>
>proc sort data=dat1;
>   by wshed site species;
>proc means data=dat1 noprint mean cv stderr n;
>   by wshed site species;
>   where species in ('b', 'c', 'p');
>   var BdA sla;
>   output out=dat2
>     mean=mBdA msla
>     cv=cBdA csla
>     stderr=sBdA ssla
>     n=nBdA nsla;
>
>Thanks,
>Greg
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From ramasamy at cancer.org.uk  Sat Jul 17 01:10:48 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sat, 17 Jul 2004 00:10:48 +0100
Subject: [R] sas to r
In-Reply-To: <40F81BE2.3410.424D13@localhost>
References: <40F81BE2.3410.424D13@localhost>
Message-ID: <1090019448.3003.49.camel@localhost.localdomain>

On Fri, 2004-07-16 at 23:18, Greg Adkison wrote:
> I would be incredibly grateful to anyone who'll help me translate some 
> SAS code into R code.

Searching for "SAS code OR script OR translate" on
http://maths.newcastle.edu.au/~rking/R/ gives a few results, one of
which looks promising is
http://tolstoy.newcastle.edu.au/R/help/04/04/0009.html and
http://tolstoy.newcastle.edu.au/R/help/04/02/0660.html

> Say for example that I have a dataset named "dat1" that includes five 
> variables:  wshed, site, species, bda, and sla.  I can calculate with the 
> following SAS code the mean, CV, se, and number of observations of 
> "bda" and "sla" for each combination of "wshed," "species," and "site," 
> restricting the species considered to only three of several species in 
> dat1 (b, c, and p).  Moreover, I can output these calculations and 
> grouping variables to a dataset named "dat2" that will reside in RAM 
> and include the variables  wshed, site, species, mBdA, msla, cBda, 
> sBdA, ssla, nBda, and nsla.

data(iris)
attach(iris)
iris[c(1,2,51,52,101,102), ]
    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
1            5.1         3.5          1.4         0.2     setosa
2            4.9         3.0          1.4         0.2     setosa
...
51           7.0         3.2          4.7         1.4 versicolor
52           6.4         3.2          4.5         1.5 versicolor
...
101          6.3         3.3          6.0         2.5  virginica
102          5.8         2.7          5.1         1.9  virginica

> tapply(Sepal.Length, Species, function(x) c( mean(x), sd(x)/mean(x),
length(x) ))
$setosa
[1]  5.00600000  0.07041344 50.00000000

$versicolor
[1]  5.93600000  0.08695606 50.00000000

$virginica
[1]  6.58800000  0.09652089 50.00000000


> proc sort data=dat1;
>   by wshed site species;
> proc means data=dat1 noprint mean cv stderr n;
>   by wshed site species;
>   where species in ('b', 'c', 'p');
>   var BdA sla;
>   output out=dat2
>     mean=mBdA msla
>     cv=cBdA csla
>     stderr=sBdA ssla
>     n=nBdA nsla;
> 
> Thanks,
> Greg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From hb at maths.lth.se  Sat Jul 17 01:59:17 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 17 Jul 2004 01:59:17 +0200
Subject: [R] Strange (non-deterministic) problem with strsplit
In-Reply-To: <f8e6ff05040716135022ed686e@mail.gmail.com>
Message-ID: <004501c46b90$efe19ea0$0701a8c0@hblaptop>

[Moving this thread to R-devel instead]

I suspect your "random" results are due to a bug in gsub(). On my R v1.9.0
(Rterm and Rgui) R crashes when I do

% R --vanilla
> gsub(" ", "", "abb + c | a*b", perl=TRUE)

Trying 

> gsub(" ", "", "b c + d | a * b", perl=TRUE)

and I'll get NULL. With 

> gsub("\\s", "", "bc + d | a * b", perl=TRUE)

it works as expected. So there is something buggy for sure.

This might have been fixed in R v1.9.1 or its patched version. (I'm still
busy to recover from a HDD crash, but, yes, I will update to Rv1.9.1. BTW,
what's the name of the error logger for Windows that is once in a while
recommended on this list and that gives more detailed errors than the
default Windows one?)

Cheers

Henrik

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of hadley wickham
> Sent: Friday, July 16, 2004 10:50 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Strange (non-deterministic) problem with strsplit
> 
> 
> I'm having an odd problem with strsplit (well I think it's 
> strplit that's causing the problem).  When I run the code 
> below as follows:  str(parseFormulaMin(y +x +d ~ b +d +e| a * b))
> 
> I expect to get
> List of 3
>  $ y: chr "y+x+d"
>  $ x: chr "b+d+e"
>  $ g: chr "a*b"
> 
> But about half the time I get 
> 
> List of 3
>  $ y: chr "y+x+d"
>  $ x: chr "b+d+e"
>  $ g: chr "a*[square box]"
> (square box not reproduced here because copy and pasting it 
> seems to break my web mail)
> 
> Can anyone reproduce the problem and/or suggest any solutions? 
> 
> parseFormula <- function(formula) {
> 	splitvars <- function(x) {
> 		strsplit(x, "\\+|\\*")[[1]]
> 	}
> 	stripwhitespace <- function(x) {
> 		gsub("\\s", "", x, perl=T)
> 	}
> 	
> 	vars <- stripwhitespace(as.character(formula)[3])
> 	varsplit <- strsplit(vars, "|", fixed=TRUE)[[1]]
> 
> 	parts <- list(
> 		y = stripwhitespace(as.character(formula)[2]),
> 		x = varsplit[1],
> 		g = varsplit[2]
> 	)
> 	lapply(parts, splitvars)
> } 
> 
> Thanks,
> 
> Hadley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From maechler at stat.math.ethz.ch  Sat Jul 17 10:44:43 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 17 Jul 2004 10:44:43 +0200
Subject: [R] Strange (non-deterministic) problem with strsplit
In-Reply-To: <004501c46b90$efe19ea0$0701a8c0@hblaptop>
References: <f8e6ff05040716135022ed686e@mail.gmail.com>
	<004501c46b90$efe19ea0$0701a8c0@hblaptop>
Message-ID: <16632.59131.544548.337755@gargle.gargle.HOWL>

>>>>> "HenrikB" == Henrik Bengtsson <hb at maths.lth.se>
>>>>>     on Sat, 17 Jul 2004 01:59:17 +0200 writes:

    HenrikB> [Moving this thread to R-devel instead] I suspect
    HenrikB> your "random" results are due to a bug in
    HenrikB> gsub(). On my R v1.9.0 (Rterm and Rgui) R crashes
    HenrikB> when I do

    HenrikB> % R --vanilla
    >> gsub(" ", "", "abb + c | a*b", perl=TRUE)

    HenrikB> Trying

    >> gsub(" ", "", "b c + d | a * b", perl=TRUE)

    HenrikB> and I'll get NULL. With

    >> gsub("\\s", "", "bc + d | a * b", perl=TRUE)

    HenrikB> it works as expected. So there is something buggy
    HenrikB> for sure.

    HenrikB> This might have been fixed in R v1.9.1 or its
    HenrikB> patched version.

probably not.  Here are results from 1.91-patched

> gsub(" ",   "", "b c + d | a * b", perl=TRUE)
NULL
> gsub("\\s", "", "b c + d | a * b", perl=TRUE)
NULL
> gsub("\\s", "", "bc + d | a * b", perl=TRUE)
[1] "bc+d|a*b"
> gsub(" ",   "", "bc + d | a * b", perl=TRUE)
[1] "bc+d|a*b"
> 

Martin Maechler, ETH Zurich



From ligges at statistik.uni-dortmund.de  Sat Jul 17 12:43:43 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 17 Jul 2004 12:43:43 +0200
Subject: [R] sas to r
In-Reply-To: <1090019448.3003.49.camel@localhost.localdomain>
References: <40F81BE2.3410.424D13@localhost>
	<1090019448.3003.49.camel@localhost.localdomain>
Message-ID: <40F902DF.2070408@statistik.uni-dortmund.de>

Adaikalavan Ramasamy wrote:

> On Fri, 2004-07-16 at 23:18, Greg Adkison wrote:
> 
>>I would be incredibly grateful to anyone who'll help me translate some 
>>SAS code into R code.
> 
> 
> Searching for "SAS code OR script OR translate" on
> http://maths.newcastle.edu.au/~rking/R/ gives a few results, one of
> which looks promising is


> http://tolstoy.newcastle.edu.au/R/help/04/04/0009.html and

I anticipated the above citation from 01 Apr 2004 (hint: 01 April !!!!!)
when I looked at the thread and realized URLs were cited ...

Uwe


> http://tolstoy.newcastle.edu.au/R/help/04/02/0660.html
> 
> 
>>Say for example that I have a dataset named "dat1" that includes five 
>>variables:  wshed, site, species, bda, and sla.  I can calculate with the 
>>following SAS code the mean, CV, se, and number of observations of 
>>"bda" and "sla" for each combination of "wshed," "species," and "site," 
>>restricting the species considered to only three of several species in 
>>dat1 (b, c, and p).  Moreover, I can output these calculations and 
>>grouping variables to a dataset named "dat2" that will reside in RAM 
>>and include the variables  wshed, site, species, mBdA, msla, cBda, 
>>sBdA, ssla, nBda, and nsla.
> 
> 
> data(iris)
> attach(iris)
> iris[c(1,2,51,52,101,102), ]
>     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
> 1            5.1         3.5          1.4         0.2     setosa
> 2            4.9         3.0          1.4         0.2     setosa
> ...
> 51           7.0         3.2          4.7         1.4 versicolor
> 52           6.4         3.2          4.5         1.5 versicolor
> ...
> 101          6.3         3.3          6.0         2.5  virginica
> 102          5.8         2.7          5.1         1.9  virginica
> 
> 
>>tapply(Sepal.Length, Species, function(x) c( mean(x), sd(x)/mean(x),
> 
> length(x) ))
> $setosa
> [1]  5.00600000  0.07041344 50.00000000
> 
> $versicolor
> [1]  5.93600000  0.08695606 50.00000000
> 
> $virginica
> [1]  6.58800000  0.09652089 50.00000000
> 
> 
> 
>>proc sort data=dat1;
>>  by wshed site species;
>>proc means data=dat1 noprint mean cv stderr n;
>>  by wshed site species;
>>  where species in ('b', 'c', 'p');
>>  var BdA sla;
>>  output out=dat2
>>    mean=mBdA msla
>>    cv=cBdA csla
>>    stderr=sBdA ssla
>>    n=nBdA nsla;
>>
>>Thanks,
>>Greg
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Jul 17 12:52:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 17 Jul 2004 12:52:02 +0200
Subject: [R] Random Fields
In-Reply-To: <5.2.1.1.2.20040716143542.019b6538@mail.llnl.gov>
References: <5.2.1.1.2.20040716143542.019b6538@mail.llnl.gov>
Message-ID: <40F904D2.6040703@statistik.uni-dortmund.de>

Michael Axelrod wrote:

> I have tried to install the package RandomFields (using the packages 
> menu) from CRAN and it fails to open the zip file. I then tried 
> downloading the package from the author's site, but it still fails to 
> install. Anyone had any success with this? Or am I doing something wrong.
> 
> Thanks in advance for any help.

Please try again. It should work now (at least from CRAN master).

Uwe Ligges


> Michael Axelrod
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From f.harrell at vanderbilt.edu  Sat Jul 17 14:36:20 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 17 Jul 2004 07:36:20 -0500
Subject: [R] sas to r
In-Reply-To: <40F81BE2.3410.424D13@localhost>
References: <40F81BE2.3410.424D13@localhost>
Message-ID: <40F91D44.7000208@vanderbilt.edu>

Greg Adkison wrote:
> I would be incredibly grateful to anyone who'll help me translate some 
> SAS code into R code.
> 
> Say for example that I have a dataset named "dat1" that includes five 
> variables:  wshed, site, species, bda, and sla.  I can calculate with the 
> following SAS code the mean, CV, se, and number of observations of 
> "bda" and "sla" for each combination of "wshed," "species," and "site," 
> restricting the species considered to only three of several species in 
> dat1 (b, c, and p).  Moreover, I can output these calculations and 
> grouping variables to a dataset named "dat2" that will reside in RAM 
> and include the variables  wshed, site, species, mBdA, msla, cBda, 
> sBdA, ssla, nBda, and nsla.
> 
> proc sort data=dat1;
>   by wshed site species;
> proc means data=dat1 noprint mean cv stderr n;
>   by wshed site species;
>   where species in ('b', 'c', 'p');
>   var BdA sla;
>   output out=dat2
>     mean=mBdA msla
>     cv=cBdA csla
>     stderr=sBdA ssla
>     n=nBdA nsla;
> 
> Thanks,
> Greg

The following handles any number of analysis variables, with automatic
naming of all statistics computed from them.  It requires the Hmisc package.

# Generate some data.  Put one NA in sla.
set.seed(1)
dat1 <- expand.grid(wshed=1:2, site=c('A','B'),
                     species=c('a','b','c','p'),
                     reps=1:10)
n <- nrow(dat1)
dat1 <- transform(dat1,
                   BdA = rnorm(n, 100, 20),
                   sla = c(rnorm(n-1, 200, 30), NA))
# Can use upData function in Hmisc in place of transform

# Summarization function, per stratum, for a matrix of analysis
# variables
g <- function(y) {
   n <- apply(y, 2, function(z) sum(!is.na(z)))
   m <- apply(y, 2, mean, na.rm=TRUE)
   s <- apply(y, 2, sd,   na.rm=TRUE)
   cv <- s/m
   se <- s/sqrt(n)
   w <- c(m, cv, se, n)
   names(w) <- t(outer(c('m','c','s','n'), colnames(y), paste, sep=''))
   w
}
library(Hmisc)
dat2 <-  with(dat1,
               summarize(cbind(BdA, sla),
                         llist(wshed, site, species),
                         g,
                         subset=species %in% c('b','c','p'),
                         stat.name='mBdA')
               )

options(digits=3)
dat2  # is a data frame

    wshed site species  mBdA msla  cBdA   csla sBdA  ssla nBdA nsla
1      1    A       b 100.5  195 0.133 0.1813 4.23 11.20   10   10
2      1    A       c  99.7  206 0.101 0.1024 3.17  6.68   10   10
3      1    A       p 101.4  188 0.239 0.1580 7.65  9.39   10   10
4      1    B       b 109.9  203 0.118 0.1433 4.09  9.21   10   10
5      1    B       c  98.4  221 0.193 0.1250 6.01  8.72   10   10
6      1    B       p 102.9  203 0.216 0.1446 7.03  9.29   10   10
7      2    A       b  95.8  195 0.241 0.2011 7.31 12.40   10   10
8      2    A       c  98.7  207 0.194 0.1274 6.04  8.33   10   10
9      2    A       p 102.2  191 0.217 0.1709 7.01 10.31   10   10
10     2    B       b  97.8  191 0.235 0.2079 7.27 12.58   10   10
11     2    B       c 100.9  194 0.164 0.0987 5.24  6.07   10   10
12     2    B       p 103.0  209 0.144 0.0769 4.69  5.35   10    9


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ramasamy at cancer.org.uk  Sat Jul 17 16:59:06 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sat, 17 Jul 2004 15:59:06 +0100
Subject: [R] sas to r
In-Reply-To: <40F902DF.2070408@statistik.uni-dortmund.de>
References: <40F81BE2.3410.424D13@localhost>
	<1090019448.3003.49.camel@localhost.localdomain>
	<40F902DF.2070408@statistik.uni-dortmund.de>
Message-ID: <1090076346.5710.1.camel@localhost.localdomain>

I am must be a bigger/slower fool to have fallen for April fools trick
in the mid of July !

Sorry Greg for misleading you.


On Sat, 2004-07-17 at 11:43, Uwe Ligges wrote:
> Adaikalavan Ramasamy wrote:
> 
> > On Fri, 2004-07-16 at 23:18, Greg Adkison wrote:
> > 
> >>I would be incredibly grateful to anyone who'll help me translate some 
> >>SAS code into R code.
> > 
> > 
> > Searching for "SAS code OR script OR translate" on
> > http://maths.newcastle.edu.au/~rking/R/ gives a few results, one of
> > which looks promising is
> 
> 
> > http://tolstoy.newcastle.edu.au/R/help/04/04/0009.html and
> 
> I anticipated the above citation from 01 Apr 2004 (hint: 01 April !!!!!)
> when I looked at the thread and realized URLs were cited ...
> 
> Uwe
> 
> 
> > http://tolstoy.newcastle.edu.au/R/help/04/02/0660.html
> > 
> > 
> >>Say for example that I have a dataset named "dat1" that includes five 
> >>variables:  wshed, site, species, bda, and sla.  I can calculate with the 
> >>following SAS code the mean, CV, se, and number of observations of 
> >>"bda" and "sla" for each combination of "wshed," "species," and "site," 
> >>restricting the species considered to only three of several species in 
> >>dat1 (b, c, and p).  Moreover, I can output these calculations and 
> >>grouping variables to a dataset named "dat2" that will reside in RAM 
> >>and include the variables  wshed, site, species, mBdA, msla, cBda, 
> >>sBdA, ssla, nBda, and nsla.
> > 
> > 
> > data(iris)
> > attach(iris)
> > iris[c(1,2,51,52,101,102), ]
> >     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
> > 1            5.1         3.5          1.4         0.2     setosa
> > 2            4.9         3.0          1.4         0.2     setosa
> > ...
> > 51           7.0         3.2          4.7         1.4 versicolor
> > 52           6.4         3.2          4.5         1.5 versicolor
> > ...
> > 101          6.3         3.3          6.0         2.5  virginica
> > 102          5.8         2.7          5.1         1.9  virginica
> > 
> > 
> >>tapply(Sepal.Length, Species, function(x) c( mean(x), sd(x)/mean(x),
> > 
> > length(x) ))
> > $setosa
> > [1]  5.00600000  0.07041344 50.00000000
> > 
> > $versicolor
> > [1]  5.93600000  0.08695606 50.00000000
> > 
> > $virginica
> > [1]  6.58800000  0.09652089 50.00000000
> > 
> > 
> > 
> >>proc sort data=dat1;
> >>  by wshed site species;
> >>proc means data=dat1 noprint mean cv stderr n;
> >>  by wshed site species;
> >>  where species in ('b', 'c', 'p');
> >>  var BdA sla;
> >>  output out=dat2
> >>    mean=mBdA msla
> >>    cv=cBdA csla
> >>    stderr=sBdA ssla
> >>    n=nBdA nsla;
> >>
> >>Thanks,
> >>Greg
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From ligges at statistik.uni-dortmund.de  Sat Jul 17 17:18:58 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 17 Jul 2004 17:18:58 +0200
Subject: [R] sas to r
In-Reply-To: <1090076346.5710.1.camel@localhost.localdomain>
References: <40F81BE2.3410.424D13@localhost>	
	<1090019448.3003.49.camel@localhost.localdomain>	
	<40F902DF.2070408@statistik.uni-dortmund.de>
	<1090076346.5710.1.camel@localhost.localdomain>
Message-ID: <40F94362.4000001@statistik.uni-dortmund.de>

Adaikalavan Ramasamy wrote:
> I am must be a bigger/slower fool to have fallen for April fools trick
> in the mid of July !
> 
> Sorry Greg for misleading you.

Adaikalavan, I think you don't need to apologize.
I had read that message three times, and visited the cited web page 
within that message which looked very professional, before realizing 
that it is an April fool. And I had the advantage to know it was April 
01 that day .... ;-)

Uwe



From rpeng at jhsph.edu  Sat Jul 17 19:59:30 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat, 17 Jul 2004 13:59:30 -0400
Subject: [R] Running the optimization on the subset of parameters
In-Reply-To: <004901c469b8$47dbc2a0$8600a8c0@home2>
References: <004901c469b8$47dbc2a0$8600a8c0@home2>
Message-ID: <40F96902.90901@jhsph.edu>

If you use the mle() function in the `stats4' package, you don't
have to do anything special.  For example,

 > negloglik <- function(a, b) { a^2 + b^2 }
 > mle(negloglik, start = list(a = 2), fixed = list(b = 4))

Call:
mle(minuslogl = negloglik, start = list(a = 2), fixed = list(b = 4))

Coefficients:
            a            b
2.202682e-13 4.000000e+00
 > mle(negloglik, start = list(b = 2), fixed = list(a = 4))

Call:
mle(minuslogl = negloglik, start = list(b = 2), fixed = list(a = 4))

Coefficients:
            a            b
4.000000e+00 2.202682e-13
 >

-roger

Victoria Landsman wrote:

> Dear all, I'd like to find a minimum of (-loglik) function
> which is a function of k parameters. I'd like to run the
> minimization algorithm for the different subsets of the
> parameters and assign the fixed values to the complementary
> subset. How should I define my (-loglik) function such that it
> can be passed to the optim or other optimization function?
> 
> Much thanks for any suggestions. Vicky Landsman. [[alternative
> HTML version deleted]]
> 
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help PLEASE
> do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From f.harrell at vanderbilt.edu  Sat Jul 17 19:55:58 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 17 Jul 2004 12:55:58 -0500
Subject: [R] areg.boot use of inverseTrans and ytype
In-Reply-To: <000a01c46a51$defb6890$6c00a8c0@mtd4>
References: <000a01c46a51$defb6890$6c00a8c0@mtd4>
Message-ID: <40F9682E.6030300@vanderbilt.edu>

Anne wrote:
> Hi R helpers!
> 
> I'm still a bit ( alot) confused by the use of "inverseTrans" and "ytype" in areg.boot (Hmisc): What I want to do seems very simple, but I do not get the result I want:
> plot the predicted values in the original scale. (I did not understand the documentation, sorry!)
> 
> 
> for instance the following code
> f<-areg.boot(Pe[here]~monotone(t[here])+monotone(v[here])+I(Pa[here]-Pm[here])+......,B=100)

In models don't subset every variable.  Use subset=here.

> 
> f.origScale<-Function(f,ytype="inverse")                         #  works up to here OK, back to original Pe scale
> 
> 
> 
>  Now if use predict() to make prediction for given input values , how do I transform the result back into the original response scale?
> 
> (in the documentation:
> 
>  A 'predict' method computes predicted
>      values on the original or transformed response scale, or a matrix
>      of transformed predictors)
> 
> 
> 
> so I tried 
> 
> y.predicted<-predict(f,data2predict, type='inverse')   #result is in transformed scale
> 
> y.predicted<-predict(f,data2predict, type='fitted',scale="original")....without success


y.predicted <- predict(f, statistic='fitted')
# similar to statistic='median'

> 
> (I did not find the documentation for the predict method of areg.boot)

It's there.  Do ?areg.boot and you'll see it.

Frank

> 
> 
> 
> 
> 
> as the inverse transformation of response obtained by areg.boot is not analytical, I do not see how I can use inverseTrans 
> 
> 
> 
> .
> 
> 
> 
> Thank for any help
> 
> 
> 
> Anne
> 
> 
> 
> ----------------------------------------------------
> Anne Piotet
> Tel: +41 79 359 83 32 (mobile)
> Email: anne.piotet at m-td.com
> ---------------------------------------------------
> M-TD Modelling and Technology Development
> PSE-C
> CH-1015 Lausanne
> Switzerland
> Tel: +41 21 693 83 98
> Fax: +41 21 646 41 33
> --------------------------------------------------
>  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From f.harrell at vanderbilt.edu  Sun Jul 18 00:09:47 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 17 Jul 2004 17:09:47 -0500
Subject: [R] sas to r
In-Reply-To: <40F91D44.7000208@vanderbilt.edu>
References: <40F81BE2.3410.424D13@localhost> <40F91D44.7000208@vanderbilt.edu>
Message-ID: <40F9A3AB.3010708@vanderbilt.edu>

Here is an improvement to what I sent earlier today.

g <- function(y) {
   s <- apply(y, 2,
              function(z) {
                z <- z[!is.na(z)]
                n <- length(z)
                if(n==0) c(NA,NA,NA,0) else
                if(n==1) c(z, NA,NA,1) else {
                  m <- mean(z)
                  s <- sd(z)
                  c(Mean=m, CV=s/m, SE=s/sqrt(n), N=n)
                }
              })
   w <- as.vector(s)
   names(w) <-  as.vector(outer(rownames(s), colnames(s), paste, sep=''))
   w
}
library(Hmisc)
dat2 <-  with(dat1,
               summarize(cbind(BdA, sla),
                         llist(wshed, site, species),
                         g,
                         subset=species %in% c('b','c','p'),
                         stat.name=NULL)
               )

options(digits=3)
dat2  # is a data frame

    wshed site species MeanBdA CVBdA SEBdA NBdA Meansla  CVsla SEsla Nsla
1      1    A       b   100.5 0.133  4.23   10     195 0.1813 11.20   10
2      1    A       c    99.7 0.101  3.17   10     206 0.1024  6.68   10
3      1    A       p   101.4 0.239  7.65   10     188 0.1580  9.39   10
4      1    B       b   109.9 0.118  4.09   10     203 0.1433  9.21   10
5      1    B       c    98.4 0.193  6.01   10     221 0.1250  8.72   10
6      1    B       p   102.9 0.216  7.03   10     203 0.1446  9.29   10
7      2    A       b    95.8 0.241  7.31   10     195 0.2011 12.40   10
8      2    A       c    98.7 0.194  6.04   10     207 0.1274  8.33   10
9      2    A       p   102.2 0.217  7.01   10     191 0.1709 10.31   10
10     2    B       b    97.8 0.235  7.27   10     191 0.2079 12.58   10
11     2    B       c   100.9 0.164  5.24   10     194 0.0987  6.07   10
12     2    B       p   103.0 0.144  4.69   10     209 0.0769  5.35    9

# Another approach, but does casewise deletion of NAs and computes all
# possible marginal summaries
dat2 <- summary(cbind(BdA, sla) ~ wshed + site + species,
              data=dat1, fun=g, method='cross')
print.data.frame(dat2)  # after Sept 2004 just say dat2
# dat2 is similar to but not really a data frame, with a matrix of 
statistics S
# Remove method='cross' to just get all one-way summaries

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From niels.waller at vanderbilt.edu  Sun Jul 18 01:03:53 2004
From: niels.waller at vanderbilt.edu (Niels Waller)
Date: Sat, 17 Jul 2004 18:03:53 -0500
Subject: [R] R question about spectrum metric
Message-ID: <200407172303.i6HN3nHD027661@imap3.mail.vanderbilt.edu>

 
Dear R community,

I would like to conduct a simulation study that involves the 
generation and recovery of times series spectra.  Spectrum analysis 
is a new area for me so I am very much in the crawling stage at this point.

I am having difficulty understanding the output of the spec.pgram (or
spectrum) 
function. Specifically, I do not understand the metric of the results.  In
my 
simulation the recovered coefficients correlate  .99 with the generating 
coefficients, so everything appears in order -- accept for my 
confusion regarding the metric of the recovered coefficients.

I have written a function (makeWave) to generate the series. I then call
this
function with the required arguments. Next I analyze the resulting series
with 
spec.pgram and compare the results with the generating coefficients 
(at the appropriate frequencies).  In a small simulation study the
generating 
and recovered coefficients correlated .99 -- however the metric of the two 
sets of coefficients differ by several orders of magnitude.

I would be very happy to send the actual code of this simulation 
(less than 2 pages of code) to anyone who could help me understand how 
to scale my recovered coefficients to the metric of the generating
parameters. 
Specifically, I am looking for a general solution to the scaling problem (if
one exists).

Thank you in advance for any and all help.

Niels Waller
Vanderbilt University
R 1.9.1
Windows XP

##------------------------------------------------------------------##
##FUNCTION:   makeWave
##Purpose:    to generate periodic time series (no white noise)
##Arguments
## c0        :: coefficient for frequency 0
## c.n       :: vector of (complex) coefficients for frequencies 1...+n
## cminus.n  :: vector of (complex) coefficients for frequencies 1...-n
## N         :: number of time points in generated wave
## f         :: fundamental frequency of wave


makeWave<-function(c0, c.n, cminus.n, N, f){
k<-1:N  #k = time point
x<-rep(0,N)
w <- 2*pi*f
   for(t.i in 1:N){   ## over time t.i
      x[t.i] <- c0 
      temp<-0 
          for(j in 1:length(c.n)){   ## over frequency j
          temp<-temp +  c.n[j] * exp(1i*w*j*t.i) + 
                        cminus.n[j] * exp(1i*w*j*t.i) 
          }   
    x[t.i]<-x[t.i]+temp   
   }
 x  ##  composite wave
}



From cliff at ms.washington.edu  Sun Jul 18 02:01:51 2004
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Sat, 17 Jul 2004 17:01:51 -0700
Subject: [R] More on global environment
Message-ID: <023901c46c5a$6df55e70$e2bd1218@C56909A>

You may want to look at the notes on and functions for workspace
management that guide me. They can be downloaded from

http://faculty.washington.edu/lunnebor/Stat342/

by checking on "Exercises." I use the .GlobalEnv (position 1 on search
path) solely for scratch and have project work attached further down the
path. The two functions move() and rm.sv() contributed by my colleague
John Miyamoto and described in the above make this easy to do.

Michael Prager wrote:

: Date: Thu, 15 Jul 2004 14:45:41 -0400
: From: "Mike Prager" <Mike.Prager at noaa.gov>
: Subject: [R] More on global environment
: To: R Help list <r-help at stat.math.ethz.ch>
: Message-ID: <6.1.0.6.2.20040715143759.01e91668 at hermes.nos.noaa.gov>
: Content-Type: text/plain; charset="us-ascii"; format=flowed
:
: To follow up on my previous question, suppose a user R session wants
to
: unload one workspace and load another within an R session.  Is the
: following the correct sequence?
:
(snip)
: Michael Prager, Ph.D.
: NOAA Center for Coastal Fisheries and Habitat Research
: Beaufort, North Carolina  28516
: http://shrimp.ccfhrb.noaa.gov/~mprager/


**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
cliff at ms.washington.edu



From sundar.dorai-raj at PDF.COM  Sun Jul 18 04:13:53 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Sat, 17 Jul 2004 21:13:53 -0500
Subject: [R] gray background in png
Message-ID: <40F9DCE1.9030901@pdf.com>

Hi all,
   I'm having a problem creating png images with trellis.device. I would 
like to create many plots with a white background using a sequence 
number in the file argument (i.e. "%02d"). The first plot is as expected 
with a white background. However, the second and all subsequent plots 
have a gray background. I would like all plots to have a white (or 
transparent) background. Below is an example:

library(lattice)
z <- expand.grid(A = LETTERS[1:8], B = letters[1:6])
z$x <- z$y <- rep(1, nrow(z))
trellis.device(png, file = "test%02d.png", bg = "white")
lset(col.whitebg())
xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
dev.off()

This is also the case for jpeg and bmp though win.metafile and 
postscript do not have this problem. Is this a bug or am I missing 
something obvious?

I found one reference that implies this may be expected behaviour but 
I'm not sure if I interpretted the comment correctly.

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/18890.html

 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R
 > help(package = lattice)

		Information on Package 'lattice'

Description:

Package: lattice
Version: 0.9-12
Date: 2004/06/01
<snip>



From patrick.giraudoux at univ-fcomte.fr  Sun Jul 18 09:13:23 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 18 Jul 2004 09:13:23 +0200
Subject: [R] bootstrap and nls
Message-ID: <003a01c46c96$be10e910$7eca80d9@PC728329681112>

Hi,

I am trying to bootstrap the difference between each parameters among two non linear regression (distributed loss model) as
following:

# data.frame
> Raies[1:10,]
   Tps  SolA  Solb
1    0 32.97 35.92
2    0 32.01 31.35
3    1 21.73 22.03
4    1 23.73 18.53
5    2 19.68 18.28
6    2 18.56 16.79
7    3 18.79 15.61
8    3 17.60 13.43
9    4 14.83 12.76
10   4 17.33 14.91
etc...

# non linear model (work well)

RaiesLossA.nls<-nls(SolA~a/(1+b*Tps)^c,start=c(a=32,b=0.5,c=0.6))
RaiesLossB.nls<-nls(Solb~a/(1+b*Tps)^c,start=c(a=33,b=1.5,c=0.5))


# bootstrap
library(boot)

dif.param<-function(data,i){
RaiesLossA.nls<-nls(SolA[i]~a/(1+b*Tps[i])^c,start=c(a=31,b=0.5,c=0.6))
RaiesLossB.nls<-nls(Solb[i]~a/(1+b*Tps[i])^c,start=c(a=33,b=1.4,c=0.5))
RaiesLossA.nls$m$getPars()-RaiesLossB.nls$m$getPars()
}

>  myboot<-boot(Raies,dif.param,R=1000)

Error in numericDeriv(form[[3]], names(ind), env) :
        Missing value or an Infinity produced when evaluating the model

It seems that the init values (start=) may come not to be suitable while bootstraping. Data can be sent offline to whom wanted to
try on the dataset.

Any hint welcome!

Best regards,

Patrick Giraudoux


University of Franche-Comt??
Department of Environmental Biology
EA3184 af. INRA
F-25030 Besan??on Cedex

tel.: +33 381 665 745
fax.: +33 381 665 797
http://lbe.univ-fcomte.fr



From pvremort at vub.ac.be  Sun Jul 18 13:17:42 2004
From: pvremort at vub.ac.be (PvR)
Date: Sun, 18 Jul 2004 13:17:42 +0200
Subject: [R] a problem: factors, names, tables .. 
Message-ID: <opsbbyzsbvxpv241@jodokus.pietnet.net>

Hi all,

I am *completely* lost in trying to solve a relatively simple task.

I want to compute the relative number of occurences of an event, the data  
of which sits in a large table (read from file).

I have the occurences of the events in a table 'tt'

0  2 10 11 13 14 15
15  6  1  3  8 15 10

.. meaning that event of type '0' occurs 15 times, type '2' occurs 6 times  
etc.

Now I want to divide the occurence counts by the total number of events of  
that type, which is given in the table tt2:

  0   1   2  10  11  12  13  14  15
817 119 524  96 700  66 559 358 283

Saying that event type '0' occurred 817 times, type '1' occurs 119 times  
etc.

The obvious problem is that not all events in tt2 are present in tt, which  
is the result of the experiment so that cannot be changed.

What needs to be done is loop over tt, take the occurence count, and  
divide that with the corresponding count in tt2.  This corresponding tt2  
count is *not* at the same index in tt2, so I need a reverse lookup of the  
type number.  For example:

event type 10:
occurs 1 time (from table tt)
occurs 96 times in total (from table tt2)  <- this is found by looking up  
type '10' in tt2 and reading out 96

result: 1/96



I have tried programming this as follows:


tt <- table(V32[V48 == 0]) # this is taking the events I want counted
tt2 <- table(V32) # this is taking the total event count per type
df <- as.data.frame(tt) #convert to dataframe to allow access to  
type-numbers .. ?
df2 <-  as.data.frame(tt2) #same here

print(tt);
print(df);

print(tt2);
print(df2);

for( i in 1:length(tt) ) { #loop over smallest table tt
	print("i:"); #index
	print(i);
	print( "denominator "); #corresponds to the "1" in the example
	print(	 df$Freq[i] );
	denomtag = ( df$Var1[ i ] );	# corresponds to the "10" in the example,  
being the type number of the event
	print("denomtag ");
	print( denomtag );
	print( "nominator: " );
	print( df2[2][ df[1] == as.numeric(denomtag) ] );  #this fails ....
	#result would then be somthing like :  denomitor / nominator	
}

The problem is that the factor names that are extracted in 'denomtag' are  
not usable as index in the dataframe in the last line.   I have tried  
converting to numeric using 'as.numeric', but that fails since this  
returns the index in the factor rather then the factor name I need from  
the list.

Any suggestions .. ?   I am sure its dead simple, as always.


Thanks,


Piet (Belgium)

PS: please reply to pvremortNOSPAM at vub.ac.be



From ligges at statistik.uni-dortmund.de  Sun Jul 18 14:05:26 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 18 Jul 2004 14:05:26 +0200
Subject: [R] a problem: factors, names, tables ..
In-Reply-To: <opsbbyzsbvxpv241@jodokus.pietnet.net>
References: <opsbbyzsbvxpv241@jodokus.pietnet.net>
Message-ID: <40FA6786.30604@statistik.uni-dortmund.de>

PvR wrote:
> Hi all,
> 
> I am *completely* lost in trying to solve a relatively simple task.
> 
> I want to compute the relative number of occurences of an event, the 
> data  of which sits in a large table (read from file).
> 
> I have the occurences of the events in a table 'tt'
> 
> 0  2 10 11 13 14 15
> 15  6  1  3  8 15 10
> 
> .. meaning that event of type '0' occurs 15 times, type '2' occurs 6 
> times  etc.
> 
> Now I want to divide the occurence counts by the total number of events 
> of  that type, which is given in the table tt2:
> 
>  0   1   2  10  11  12  13  14  15
> 817 119 524  96 700  66 559 358 283
> 
> Saying that event type '0' occurred 817 times, type '1' occurs 119 
> times  etc.
> 
> The obvious problem is that not all events in tt2 are present in tt, 
> which  is the result of the experiment so that cannot be changed.
> 
> What needs to be done is loop over tt, take the occurence count, and  
> divide that with the corresponding count in tt2.  This corresponding 
> tt2  count is *not* at the same index in tt2, so I need a reverse lookup 
> of the  type number.  For example:
> 
> event type 10:
> occurs 1 time (from table tt)
> occurs 96 times in total (from table tt2)  <- this is found by looking 
> up  type '10' in tt2 and reading out 96
> 
> result: 1/96
> 
> 
> 
> I have tried programming this as follows:


It's *much* easier. Just make V32 a factor. After that, table() knows 
all the levels and counts also the zeros:

V32 <- factor(V32)
table(V32[V48 == 0]) / table(V32)

Uwe Ligges




> 
> tt <- table(V32[V48 == 0]) # this is taking the events I want counted
> tt2 <- table(V32) # this is taking the total event count per type
> df <- as.data.frame(tt) #convert to dataframe to allow access to  
> type-numbers .. ?
> df2 <-  as.data.frame(tt2) #same here
> 
> print(tt);
> print(df);
> 
> print(tt2);
> print(df2);
> 
> for( i in 1:length(tt) ) { #loop over smallest table tt
>     print("i:"); #index
>     print(i);
>     print( "denominator "); #corresponds to the "1" in the example
>     print(     df$Freq[i] );
>     denomtag = ( df$Var1[ i ] );    # corresponds to the "10" in the 
> example,  being the type number of the event
>     print("denomtag ");
>     print( denomtag );
>     print( "nominator: " );
>     print( df2[2][ df[1] == as.numeric(denomtag) ] );  #this fails ....
>     #result would then be somthing like :  denomitor / nominator   
> }
> 
> The problem is that the factor names that are extracted in 'denomtag' 
> are  not usable as index in the dataframe in the last line.   I have 
> tried  converting to numeric using 'as.numeric', but that fails since 
> this  returns the index in the factor rather then the factor name I need 
> from  the list.
> 
> Any suggestions .. ?   I am sure its dead simple, as always.
> 
> 
> Thanks,
> 
> 
> Piet (Belgium)
> 
> PS: please reply to pvremortNOSPAM at vub.ac.be
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sun Jul 18 14:18:59 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 18 Jul 2004 14:18:59 +0200
Subject: [R] Install R on AIX 5.2 64 Bit
In-Reply-To: <291B348BC59B47468C7824603C326082946054@cmail3.central.cmich.local>
References: <291B348BC59B47468C7824603C326082946054@cmail3.central.cmich.local>
Message-ID: <40FA6AB3.9090101@statistik.uni-dortmund.de>

Liao, Kexiao wrote:

> Hi your guys,
> 
>     Recently, I installed R-1.9.1 on AIX 5.2 with 64 bits environment; I
> already have following software installed on AIX before I compile
> R-1.9.1 source codes:
> 
>  
> 
> g++ 2.9.aix51.020209-4  The GNU C++ compiler and headers
> 
> gcc 2.9.aix51.020209-4  The GNU gcc C compiler and headers
> 
> xlf  XL   Fortran for AIX
> 
> perl 5.6.1-2 
> 
> zlib 1.1.3-10
> 
>  
> 
>    For latex and makeinfo stuffs, I have not found from my AIX 5.2 P690
> system.
> 
>  
> 
>  After I run the following command:
> 
> configure
> 
> make
> 

What about "make check"? And thereafter "make install"?

> 
> Following executable binaries codes have been generated in RHOME/bin
> directory:
> 
>  
> 
> bash-2.05b$ ls -al
> 

[SNIP]

> bash-2.05b$ pwd
> 
> /home/liao1k/r-1.9.1/R-1.9.1/bin
> 
> bash-2.05b$
> 
> 
> However if I run R command, I got following error message:
> 
> bash-2.05b$ ./R
> 
> Fatal error: unable to open the base package

So either you don't have permission to read .../library/base/...
or compilation was not successful and the package(s) have not been created.
Please tell us the error messages which appeared during compilation, and 
try running make check, if there were no error messages....

Uwe Ligges


> 
>   Can any one give me some advice? Thanks in advance!
> 
>  
> 
> Kexiao



From spencer.graves at pdf.com  Sun Jul 18 15:45:53 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 18 Jul 2004 06:45:53 -0700
Subject: [R] bootstrap and nls
In-Reply-To: <003a01c46c96$be10e910$7eca80d9@PC728329681112>
References: <003a01c46c96$be10e910$7eca80d9@PC728329681112>
Message-ID: <40FA7F11.5000006@pdf.com>

      1.  Have you studied the documentation, including working the 
examples, for "nls" and "boot"?  I don't see "data" as an argument to 
"nls", as I'm used to, and your use of "i" also seems disconcerting to 
me.  Something like the following seems to me to be closer to the 
standard syntax and therefore safer: 
     
      nls(SolA~a/(1+b*Tps)^c,start=c(a=31,b=0.5,c=0.6), data=data[i,])

This may not help with this problem, but it might help you with others 
-- possibly even in understanding how R is structured more generally. 

      2.  If this error occurs in only a very few cases and you can 
afford to ignore such cases, then you could use "try".  I didn't 
remember exactly the way to do this, so I performed the following 
experiment: 

 > Er <- try(if(NA)2)
Error in if (NA) 2 : missing value where TRUE/FALSE needed
 > class(Er)
[1] "try-error"

      This leads me to suggest the following: 

dif.param<-function(data,i){
RaiesLossA.nls<-try(nls(SolA[i]~a/(1+b*Tps[i])^c,start=c(a=31,b=0.5,c=0.6)))
RaiesLossB.nls<-try(nls(Solb[i]~a/(1+b*Tps[i])^c,start=c(a=33,b=1.4,c=0.5)))
if((class(RaiesLossA.nls)=="try-error") | 
	(class(RaiesLossB.nls)=="try-error"))
	return("whatever you want in this case")
else RaiesLossA.nls$m$getPars()-RaiesLossB.nls$m$getPars()
}

#  UNTRIED

      3.  What is the nature of your data and the physical context?  Can 
the deviations from this model reasonably be considered to be 
independent normal with constant variance?  If yes, then you have a 
reasonable model.  Alternatively, if all numbers are positive, have you 
considered the following: 

      log(SolA) = ln.a + c*log(1+b*Tps)

If the deviations from this model seem close to being normally 
distributed, then you might try using this form with method="plinear".  
If you do this, you only need starting values for "b".  Whether you use 
"plinear" or not, have you tried getting starting values as follows:  
Recall that log(1+x) = x+x^2/2+O(x^2).  If b*Tps is usually small, then 
the following might work to produce reasonable starting values: 

      fit0 <- lm(SolA~Tps + I(Tps^2), data=data[i,])

Then coef(fit0) estimates log(a), c*b and c*b^2/2.  Thus, b <- 
2*coef(fit0)[3]/coef(fit0)[2], etc. 
     
      hope this helps.  spencer graves
p.s.  PLEASE do read the posting guide! 
"http://www.R-project.org/posting-guide.html".  It may help you answer 
questions for yourself, and when it doesn't, it can make it easier for 
someone else to understand your problem and respond helpfully. 

Patrick Giraudoux wrote:

>Hi,
>
>I am trying to bootstrap the difference between each parameters among two non linear regression (distributed loss model) as
>following:
>
># data.frame
>  
>
>>Raies[1:10,]
>>    
>>
>   Tps  SolA  Solb
>1    0 32.97 35.92
>2    0 32.01 31.35
>3    1 21.73 22.03
>4    1 23.73 18.53
>5    2 19.68 18.28
>6    2 18.56 16.79
>7    3 18.79 15.61
>8    3 17.60 13.43
>9    4 14.83 12.76
>10   4 17.33 14.91
>etc...
>
># non linear model (work well)
>
>RaiesLossA.nls<-nls(SolA~a/(1+b*Tps)^c,start=c(a=32,b=0.5,c=0.6))
>RaiesLossB.nls<-nls(Solb~a/(1+b*Tps)^c,start=c(a=33,b=1.5,c=0.5))
>
>
># bootstrap
>library(boot)
>
>dif.param<-function(data,i){
>RaiesLossA.nls<-nls(SolA[i]~a/(1+b*Tps[i])^c,start=c(a=31,b=0.5,c=0.6))
>RaiesLossB.nls<-nls(Solb[i]~a/(1+b*Tps[i])^c,start=c(a=33,b=1.4,c=0.5))
>RaiesLossA.nls$m$getPars()-RaiesLossB.nls$m$getPars()
>}
>
>  
>
>> myboot<-boot(Raies,dif.param,R=1000)
>>    
>>
>
>Error in numericDeriv(form[[3]], names(ind), env) :
>        Missing value or an Infinity produced when evaluating the model
>
>It seems that the init values (start=) may come not to be suitable while bootstraping. Data can be sent offline to whom wanted to
>try on the dataset.
>
>Any hint welcome!
>
>Best regards,
>
>Patrick Giraudoux
>
>
>University of Franche-Comt??
>Department of Environmental Biology
>EA3184 af. INRA
>F-25030 Besan??on Cedex
>
>tel.: +33 381 665 745
>fax.: +33 381 665 797
>http://lbe.univ-fcomte.fr
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ramasamy at cancer.org.uk  Sun Jul 18 16:19:14 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sun, 18 Jul 2004 15:19:14 +0100
Subject: [R] a problem: factors, names, tables ..
In-Reply-To: <40FA6786.30604@statistik.uni-dortmund.de>
References: <opsbbyzsbvxpv241@jodokus.pietnet.net>
	<40FA6786.30604@statistik.uni-dortmund.de>
Message-ID: <1090160354.28511.10.camel@localhost.localdomain>

Please give a reproducible example. Here is one way :

# generate example
> v1 <- rep( c(0, 2, 10, 11, 13, 14, 15), c(15, 6, 1, 3, 8, 15, 10) )
> t1 <- table(v1)
> t1
v1
 0  2 10 11 13 14 15 
15  6  1  3  8 15 10 

> v2 <- rep( c(0, 1, 2, 10, 11, 12, 13, 14, 15), c(817, 119, 524, 96,
700, 66, 559, 358, 283) )
> t2 <- table(v2)
> t2
v2
  0   1   2  10  11  12  13  14  15 
817 119 524  96 700  66 559 358 283 

# find results
> merge(t1, t2, by=1, all.x=TRUE)
  v1 Freq.x Freq.y
1  0     15    817
2 10      1     96
3 11      3    700
4 13      8    559
5 14     15    358
6 15     10    283
7  2      6    524

Uwe's suggestion may need a slight modification as the two table have
different labels/levels and hence non-conformable for division

> t2.f <- table( v2.f <- factor(v2) )
> t1.f <- table( v1.f <- factor(v1, levels=levels(v2.f)) )

> cbind( t1.f, t2.f, ratio=t1.f / t2.f )
   t1.f t2.f       ratio
0    15  817 0.018359853
1     0  119 0.000000000
2     6  524 0.011450382
10    1   96 0.010416667
11    3  700 0.004285714
12    0   66 0.000000000
13    8  559 0.014311270
14   15  358 0.041899441
15   10  283 0.035335689
> 

Also have a look at this related posting
http://tolstoy.newcastle.edu.au/R/help/04/06/0594.html

Regards, Adai.


On Sun, 2004-07-18 at 13:05, Uwe Ligges wrote:
> PvR wrote:
> > Hi all,
> > 
> > I am *completely* lost in trying to solve a relatively simple task.
> > 
> > I want to compute the relative number of occurences of an event, the 
> > data  of which sits in a large table (read from file).
> > 
> > I have the occurences of the events in a table 'tt'
> > 
> > 0  2 10 11 13 14 15
> > 15  6  1  3  8 15 10
> > 
> > .. meaning that event of type '0' occurs 15 times, type '2' occurs 6 
> > times  etc.
> > 
> > Now I want to divide the occurence counts by the total number of events 
> > of  that type, which is given in the table tt2:
> > 
> >  0   1   2  10  11  12  13  14  15
> > 817 119 524  96 700  66 559 358 283
> > 
> > Saying that event type '0' occurred 817 times, type '1' occurs 119 
> > times  etc.
> > 
> > The obvious problem is that not all events in tt2 are present in tt, 
> > which  is the result of the experiment so that cannot be changed.
> > 
> > What needs to be done is loop over tt, take the occurence count, and  
> > divide that with the corresponding count in tt2.  This corresponding 
> > tt2  count is *not* at the same index in tt2, so I need a reverse lookup 
> > of the  type number.  For example:
> > 
> > event type 10:
> > occurs 1 time (from table tt)
> > occurs 96 times in total (from table tt2)  <- this is found by looking 
> > up  type '10' in tt2 and reading out 96
> > 
> > result: 1/96
> > 
> > 
> > 
> > I have tried programming this as follows:
> 
> 
> It's *much* easier. Just make V32 a factor. After that, table() knows 
> all the levels and counts also the zeros:
> 
> V32 <- factor(V32)
> table(V32[V48 == 0]) / table(V32)
> 
> Uwe Ligges
> 
> 
> 
> 
> > 
> > tt <- table(V32[V48 == 0]) # this is taking the events I want counted
> > tt2 <- table(V32) # this is taking the total event count per type
> > df <- as.data.frame(tt) #convert to dataframe to allow access to  
> > type-numbers .. ?
> > df2 <-  as.data.frame(tt2) #same here
> > 
> > print(tt);
> > print(df);
> > 
> > print(tt2);
> > print(df2);
> > 
> > for( i in 1:length(tt) ) { #loop over smallest table tt
> >     print("i:"); #index
> >     print(i);
> >     print( "denominator "); #corresponds to the "1" in the example
> >     print(     df$Freq[i] );
> >     denomtag = ( df$Var1[ i ] );    # corresponds to the "10" in the 
> > example,  being the type number of the event
> >     print("denomtag ");
> >     print( denomtag );
> >     print( "nominator: " );
> >     print( df2[2][ df[1] == as.numeric(denomtag) ] );  #this fails ....
> >     #result would then be somthing like :  denomitor / nominator   
> > }
> > 
> > The problem is that the factor names that are extracted in 'denomtag' 
> > are  not usable as index in the dataframe in the last line.   I have 
> > tried  converting to numeric using 'as.numeric', but that fails since 
> > this  returns the index in the factor rather then the factor name I need 
> > from  the list.
> > 
> > Any suggestions .. ?   I am sure its dead simple, as always.
> > 
> > 
> > Thanks,
> > 
> > 
> > Piet (Belgium)
> > 
> > PS: please reply to pvremortNOSPAM at vub.ac.be
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Sun Jul 18 17:29:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 18 Jul 2004 11:29:47 -0400
Subject: [R] gray background in png
Message-ID: <3A822319EB35174CA3714066D590DCD504AF807B@usrymx25.merck.com>

Seems like a bug to me.  I tried setting theme=col.whitebg in arguments to
trellis.device, same result.  Setting options(lattice.theme=col.whitebg)
also does the same thing.  The same thing happens win.metafile() for me.
This is on WinXPPro, R-1.9.1 and

> packageDescription("lattice")
Package: lattice
Version: 0.9-16
Date: 2004/07/07
Priority: recommended
Title: Lattice Graphics
Author: Deepayan Sarkar <deepayan at stat.wisc.edu>
Maintainer: Deepayan Sarkar <deepayan at stat.wisc.edu>
Description: Implementation of Trellis Graphics. See ?Lattice for a brief
        introduction
Depends: R (>= 1.9.0), grid
License: GPL version 2 or later
Packaged: Wed Jul 7 02:39:54 2004; deepayan
Built: R 1.9.1; i386-pc-mingw32; 2004-07-07 14:00:16; windows

-- File: C:/R/rw1091/library/lattice/DESCRIPTION 

Andy

> From: Sundar Dorai-Raj
> 
> Hi all,
>    I'm having a problem creating png images with 
> trellis.device. I would 
> like to create many plots with a white background using a sequence 
> number in the file argument (i.e. "%02d"). The first plot is 
> as expected 
> with a white background. However, the second and all subsequent plots 
> have a gray background. I would like all plots to have a white (or 
> transparent) background. Below is an example:
> 
> library(lattice)
> z <- expand.grid(A = LETTERS[1:8], B = letters[1:6])
> z$x <- z$y <- rep(1, nrow(z))
> trellis.device(png, file = "test%02d.png", bg = "white")
> lset(col.whitebg())
> xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
> dev.off()
> 
> This is also the case for jpeg and bmp though win.metafile and 
> postscript do not have this problem. Is this a bug or am I missing 
> something obvious?
> 
> I found one reference that implies this may be expected behaviour but 
> I'm not sure if I interpretted the comment correctly.
> 
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/18890.html

 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R
 > help(package = lattice)

		Information on Package 'lattice'

Description:

Package: lattice
Version: 0.9-12
Date: 2004/06/01
<snip>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sun Jul 18 17:39:18 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 18 Jul 2004 17:39:18 +0200
Subject: [R] a problem: factors, names, tables ..
In-Reply-To: <1090160354.28511.10.camel@localhost.localdomain>
References: <opsbbyzsbvxpv241@jodokus.pietnet.net>	
	<40FA6786.30604@statistik.uni-dortmund.de>
	<1090160354.28511.10.camel@localhost.localdomain>
Message-ID: <40FA99A6.7070504@statistik.uni-dortmund.de>

Adaikalavan Ramasamy wrote:

> Please give a reproducible example. Here is one way :
> 
> # generate example
> 
>>v1 <- rep( c(0, 2, 10, 11, 13, 14, 15), c(15, 6, 1, 3, 8, 15, 10) )
>>t1 <- table(v1)
>>t1
> 
> v1
>  0  2 10 11 13 14 15 
> 15  6  1  3  8 15 10 
> 
> 
>>v2 <- rep( c(0, 1, 2, 10, 11, 12, 13, 14, 15), c(817, 119, 524, 96,
> 
> 700, 66, 559, 358, 283) )
> 
>>t2 <- table(v2)
>>t2
> 
> v2
>   0   1   2  10  11  12  13  14  15 
> 817 119 524  96 700  66 559 358 283 
> 
> # find results
> 
>>merge(t1, t2, by=1, all.x=TRUE)
> 
>   v1 Freq.x Freq.y
> 1  0     15    817
> 2 10      1     96
> 3 11      3    700
> 4 13      8    559
> 5 14     15    358
> 6 15     10    283
> 7  2      6    524
> 
> Uwe's suggestion may need a slight modification as the two table have
> different labels/levels and hence non-conformable for division

No!
Uwe's suggestion works perfectly well, since *the same* variable is used 
for calculating both tables, expect: in one case it's a *subset*. Hence 
converting to factor at first is completely sufficient!!!

Reproducible example from your v2:
v2 <- rep(c(0, 1, 2, 10, 11, 12, 13, 14, 15),
           c(817, 119, 524, 96, 700, 66, 559, 358, 283))
v1 <- factor(v2)
set.seed(1)
v1 <- sample(v1, 10)
table(v1)
table(v2)
table(v1)/table(v2)

So, what's the problem???

Uwe Ligges



> 
>>t2.f <- table( v2.f <- factor(v2) )
>>t1.f <- table( v1.f <- factor(v1, levels=levels(v2.f)) )
> 
> 
>>cbind( t1.f, t2.f, ratio=t1.f / t2.f )
> 
>    t1.f t2.f       ratio
> 0    15  817 0.018359853
> 1     0  119 0.000000000
> 2     6  524 0.011450382
> 10    1   96 0.010416667
> 11    3  700 0.004285714
> 12    0   66 0.000000000
> 13    8  559 0.014311270
> 14   15  358 0.041899441
> 15   10  283 0.035335689
> 
> 
> Also have a look at this related posting
> http://tolstoy.newcastle.edu.au/R/help/04/06/0594.html
> 
> Regards, Adai.
> 
> 
> On Sun, 2004-07-18 at 13:05, Uwe Ligges wrote:
> 
>>PvR wrote:
>>
>>>Hi all,
>>>
>>>I am *completely* lost in trying to solve a relatively simple task.
>>>
>>>I want to compute the relative number of occurences of an event, the 
>>>data  of which sits in a large table (read from file).
>>>
>>>I have the occurences of the events in a table 'tt'
>>>
>>>0  2 10 11 13 14 15
>>>15  6  1  3  8 15 10
>>>
>>>.. meaning that event of type '0' occurs 15 times, type '2' occurs 6 
>>>times  etc.
>>>
>>>Now I want to divide the occurence counts by the total number of events 
>>>of  that type, which is given in the table tt2:
>>>
>>> 0   1   2  10  11  12  13  14  15
>>>817 119 524  96 700  66 559 358 283
>>>
>>>Saying that event type '0' occurred 817 times, type '1' occurs 119 
>>>times  etc.
>>>
>>>The obvious problem is that not all events in tt2 are present in tt, 
>>>which  is the result of the experiment so that cannot be changed.
>>>
>>>What needs to be done is loop over tt, take the occurence count, and  
>>>divide that with the corresponding count in tt2.  This corresponding 
>>>tt2  count is *not* at the same index in tt2, so I need a reverse lookup 
>>>of the  type number.  For example:
>>>
>>>event type 10:
>>>occurs 1 time (from table tt)
>>>occurs 96 times in total (from table tt2)  <- this is found by looking 
>>>up  type '10' in tt2 and reading out 96
>>>
>>>result: 1/96
>>>
>>>
>>>
>>>I have tried programming this as follows:
>>
>>
>>It's *much* easier. Just make V32 a factor. After that, table() knows 
>>all the levels and counts also the zeros:
>>
>>V32 <- factor(V32)
>>table(V32[V48 == 0]) / table(V32)
>>
>>Uwe Ligges
>>
>>
>>
>>
>>
>>>tt <- table(V32[V48 == 0]) # this is taking the events I want counted
>>>tt2 <- table(V32) # this is taking the total event count per type
>>>df <- as.data.frame(tt) #convert to dataframe to allow access to  
>>>type-numbers .. ?
>>>df2 <-  as.data.frame(tt2) #same here
>>>
>>>print(tt);
>>>print(df);
>>>
>>>print(tt2);
>>>print(df2);
>>>
>>>for( i in 1:length(tt) ) { #loop over smallest table tt
>>>    print("i:"); #index
>>>    print(i);
>>>    print( "denominator "); #corresponds to the "1" in the example
>>>    print(     df$Freq[i] );
>>>    denomtag = ( df$Var1[ i ] );    # corresponds to the "10" in the 
>>>example,  being the type number of the event
>>>    print("denomtag ");
>>>    print( denomtag );
>>>    print( "nominator: " );
>>>    print( df2[2][ df[1] == as.numeric(denomtag) ] );  #this fails ....
>>>    #result would then be somthing like :  denomitor / nominator   
>>>}
>>>
>>>The problem is that the factor names that are extracted in 'denomtag' 
>>>are  not usable as index in the dataframe in the last line.   I have 
>>>tried  converting to numeric using 'as.numeric', but that fails since 
>>>this  returns the index in the factor rather then the factor name I need 
>>>from  the list.
>>>
>>>Any suggestions .. ?   I am sure its dead simple, as always.
>>>
>>>
>>>Thanks,
>>>
>>>
>>>Piet (Belgium)
>>>
>>>PS: please reply to pvremortNOSPAM at vub.ac.be
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
>



From deepayan at stat.wisc.edu  Sun Jul 18 18:36:16 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 18 Jul 2004 11:36:16 -0500
Subject: [R] gray background in png
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF807B@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF807B@usrymx25.merck.com>
Message-ID: <200407181136.16960.deepayan@stat.wisc.edu>

On Sunday 18 July 2004 10:29, Liaw, Andy wrote:
> Seems like a bug to me.  I tried setting theme=col.whitebg in
> arguments to trellis.device, same result.  Setting
> options(lattice.theme=col.whitebg) also does the same thing.  The
> same thing happens win.metafile() for me. This is on WinXPPro,
> R-1.9.1 and

Definitely a bug, but probably not where you would think. Note that 
col.whitebg() is misnamed, the background is actually  'transparent'. 
As far as I can make out, the first plot is the one that's wrong, all 
the subsequent ones are fine. (The apparent 'grayness' of the 
background is probably just a feature of your png displayer.) 

The workaround depends on whether you really want a white or transparent 
background.


For transparent:

library(lattice)
z <- expand.grid(A = LETTERS[1:8], B = letters[1:6], x = 1, y = 1)

trellis.device(png, file = "test%02d.png")
par(bg = "transparent")
lset(col.whitebg())

xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
dev.off()


For white:

library(lattice)
z <- expand.grid(A = LETTERS[1:8], B = letters[1:6], x = 1, y = 1)

trellis.device(png, file = "test%02d.png") 
par(bg = "white")
lset(col.whitebg())
lset(list(background = list(col = "white")))

xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
dev.off()


The reason for this, I think, is that grid seems to use par("bg") for 
the background of the first plot, but not for the rest. See, for 
example. the results of 

png(bg = "yellow")
grid.lines()
grid.newpage()
grid.lines()
dev.off()

I'll have to think about the best way to fix this. 

Deepayan



From ramasamy at cancer.org.uk  Sun Jul 18 18:58:14 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sun, 18 Jul 2004 17:58:14 +0100
Subject: [R] a problem: factors, names, tables ..
In-Reply-To: <40FA99A6.7070504@statistik.uni-dortmund.de>
References: <opsbbyzsbvxpv241@jodokus.pietnet.net>
	<40FA6786.30604@statistik.uni-dortmund.de>
	<1090160354.28511.10.camel@localhost.localdomain>
	<40FA99A6.7070504@statistik.uni-dortmund.de>
Message-ID: <1090169844.28511.13.camel@localhost.localdomain>

Yes, you are right ! I did not realise that the first variable is a
subset of the second. I tried this instead 

> v1 <- rep( c(0, 2, 10, 11, 13, 14, 15), c(15, 6, 1, 3, 8, 15, 10) )
> v2 <- rep( c(0, 1, 2, 10, 11, 12, 13, 14, 15), c(817, 119, 524, 96,
700, 66, 559, 358, 283) )
> table(factor(v1)) / table(factor(v2))
Error in table(factor(v1))/table(factor(v2)) : 
	non-conformable arrays
> 


On Sun, 2004-07-18 at 16:39, Uwe Ligges wrote:
> Adaikalavan Ramasamy wrote:
> 
> > Please give a reproducible example. Here is one way :
> > 
> > # generate example
> > 
> >>v1 <- rep( c(0, 2, 10, 11, 13, 14, 15), c(15, 6, 1, 3, 8, 15, 10) )
> >>t1 <- table(v1)
> >>t1
> > 
> > v1
> >  0  2 10 11 13 14 15 
> > 15  6  1  3  8 15 10 
> > 
> > 
> >>v2 <- rep( c(0, 1, 2, 10, 11, 12, 13, 14, 15), c(817, 119, 524, 96,
> > 
> > 700, 66, 559, 358, 283) )
> > 
> >>t2 <- table(v2)
> >>t2
> > 
> > v2
> >   0   1   2  10  11  12  13  14  15 
> > 817 119 524  96 700  66 559 358 283 
> > 
> > # find results
> > 
> >>merge(t1, t2, by=1, all.x=TRUE)
> > 
> >   v1 Freq.x Freq.y
> > 1  0     15    817
> > 2 10      1     96
> > 3 11      3    700
> > 4 13      8    559
> > 5 14     15    358
> > 6 15     10    283
> > 7  2      6    524
> > 
> > Uwe's suggestion may need a slight modification as the two table have
> > different labels/levels and hence non-conformable for division
> 
> No!
> Uwe's suggestion works perfectly well, since *the same* variable is used 
> for calculating both tables, expect: in one case it's a *subset*. Hence 
> converting to factor at first is completely sufficient!!!
> 
> Reproducible example from your v2:
> v2 <- rep(c(0, 1, 2, 10, 11, 12, 13, 14, 15),
>            c(817, 119, 524, 96, 700, 66, 559, 358, 283))
> v1 <- factor(v2)
> set.seed(1)
> v1 <- sample(v1, 10)
> table(v1)
> table(v2)
> table(v1)/table(v2)
> 
> So, what's the problem???
> 
> Uwe Ligges
> 
> 
> 
> > 
> >>t2.f <- table( v2.f <- factor(v2) )
> >>t1.f <- table( v1.f <- factor(v1, levels=levels(v2.f)) )
> > 
> > 
> >>cbind( t1.f, t2.f, ratio=t1.f / t2.f )
> > 
> >    t1.f t2.f       ratio
> > 0    15  817 0.018359853
> > 1     0  119 0.000000000
> > 2     6  524 0.011450382
> > 10    1   96 0.010416667
> > 11    3  700 0.004285714
> > 12    0   66 0.000000000
> > 13    8  559 0.014311270
> > 14   15  358 0.041899441
> > 15   10  283 0.035335689
> > 
> > 
> > Also have a look at this related posting
> > http://tolstoy.newcastle.edu.au/R/help/04/06/0594.html
> > 
> > Regards, Adai.
> > 
> > 
> > On Sun, 2004-07-18 at 13:05, Uwe Ligges wrote:
> > 
> >>PvR wrote:
> >>
> >>>Hi all,
> >>>
> >>>I am *completely* lost in trying to solve a relatively simple task.
> >>>
> >>>I want to compute the relative number of occurences of an event, the 
> >>>data  of which sits in a large table (read from file).
> >>>
> >>>I have the occurences of the events in a table 'tt'
> >>>
> >>>0  2 10 11 13 14 15
> >>>15  6  1  3  8 15 10
> >>>
> >>>.. meaning that event of type '0' occurs 15 times, type '2' occurs 6 
> >>>times  etc.
> >>>
> >>>Now I want to divide the occurence counts by the total number of events 
> >>>of  that type, which is given in the table tt2:
> >>>
> >>> 0   1   2  10  11  12  13  14  15
> >>>817 119 524  96 700  66 559 358 283
> >>>
> >>>Saying that event type '0' occurred 817 times, type '1' occurs 119 
> >>>times  etc.
> >>>
> >>>The obvious problem is that not all events in tt2 are present in tt, 
> >>>which  is the result of the experiment so that cannot be changed.
> >>>
> >>>What needs to be done is loop over tt, take the occurence count, and  
> >>>divide that with the corresponding count in tt2.  This corresponding 
> >>>tt2  count is *not* at the same index in tt2, so I need a reverse lookup 
> >>>of the  type number.  For example:
> >>>
> >>>event type 10:
> >>>occurs 1 time (from table tt)
> >>>occurs 96 times in total (from table tt2)  <- this is found by looking 
> >>>up  type '10' in tt2 and reading out 96
> >>>
> >>>result: 1/96
> >>>
> >>>
> >>>
> >>>I have tried programming this as follows:
> >>
> >>
> >>It's *much* easier. Just make V32 a factor. After that, table() knows 
> >>all the levels and counts also the zeros:
> >>
> >>V32 <- factor(V32)
> >>table(V32[V48 == 0]) / table(V32)
> >>
> >>Uwe Ligges
> >>
> >>
> >>
> >>
> >>
> >>>tt <- table(V32[V48 == 0]) # this is taking the events I want counted
> >>>tt2 <- table(V32) # this is taking the total event count per type
> >>>df <- as.data.frame(tt) #convert to dataframe to allow access to  
> >>>type-numbers .. ?
> >>>df2 <-  as.data.frame(tt2) #same here
> >>>
> >>>print(tt);
> >>>print(df);
> >>>
> >>>print(tt2);
> >>>print(df2);
> >>>
> >>>for( i in 1:length(tt) ) { #loop over smallest table tt
> >>>    print("i:"); #index
> >>>    print(i);
> >>>    print( "denominator "); #corresponds to the "1" in the example
> >>>    print(     df$Freq[i] );
> >>>    denomtag = ( df$Var1[ i ] );    # corresponds to the "10" in the 
> >>>example,  being the type number of the event
> >>>    print("denomtag ");
> >>>    print( denomtag );
> >>>    print( "nominator: " );
> >>>    print( df2[2][ df[1] == as.numeric(denomtag) ] );  #this fails ....
> >>>    #result would then be somthing like :  denomitor / nominator   
> >>>}
> >>>
> >>>The problem is that the factor names that are extracted in 'denomtag' 
> >>>are  not usable as index in the dataframe in the last line.   I have 
> >>>tried  converting to numeric using 'as.numeric', but that fails since 
> >>>this  returns the index in the factor rather then the factor name I need 
> >>>from  the list.
> >>>
> >>>Any suggestions .. ?   I am sure its dead simple, as always.
> >>>
> >>>
> >>>Thanks,
> >>>
> >>>
> >>>Piet (Belgium)
> >>>
> >>>PS: please reply to pvremortNOSPAM at vub.ac.be
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide! 
> >>>http://www.R-project.org/posting-guide.html
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> > 
> > 
> 
>



From r-stats at arcriswell.com  Sun Jul 18 19:17:54 2004
From: r-stats at arcriswell.com (Andrew Criswell)
Date: Mon, 19 Jul 2004 00:17:54 +0700
Subject: [R] gray background in png
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF807B@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF807B@usrymx25.merck.com>
Message-ID: <40FAB0C2.10806@arcriswell.com>

Hello:

I was able to get two graphs with white background in JPG format, but 
only the first graph with PNG format (as previously remarked). 
Curiously, I only got the first graph saved (with white background) for 
the PDF format. Code follows...

ANDREW

library(lattice)
z <- expand.grid(A = LETTERS[1:8], B = letters[1:6])
z$x <- z$y <- rep(1, nrow(z))

png(file = "~/tmp/test%02d.png")
lset(theme = col.whitebg())
xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
dev.off()

jpeg(file = "~/tmp/test%02d.jpg")
lset(theme = col.whitebg())
xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
dev.off()

pdf(file = "~/tmp/test%02d.pdf")
lset(theme = col.whitebg())
xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
dev.off()

 > version

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    9.0
year     2004
month    04
day      12
language R



From r-stats at arcriswell.com  Sun Jul 18 19:29:02 2004
From: r-stats at arcriswell.com (Andrew Criswell)
Date: Mon, 19 Jul 2004 00:29:02 +0700
Subject: [R] gray background in png
In-Reply-To: <200407181136.16960.deepayan@stat.wisc.edu>
References: <3A822319EB35174CA3714066D590DCD504AF807B@usrymx25.merck.com>
	<200407181136.16960.deepayan@stat.wisc.edu>
Message-ID: <40FAB35E.2040109@arcriswell.com>

It also seems to work with two lines of code crossed out.

library(lattice)
z <- expand.grid(A = LETTERS[1:8], B = letters[1:6], x = 1, y = 1)

trellis.device(png, file = "test%02d.png") 
# par(bg = "white")
# lset(col.whitebg())
lset(list(background = list(col = "white")))
xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
dev.off()

ANDREW


Deepayan Sarkar wrote:

>On Sunday 18 July 2004 10:29, Liaw, Andy wrote:
>  
>
>>Seems like a bug to me.  I tried setting theme=col.whitebg in
>>arguments to trellis.device, same result.  Setting
>>options(lattice.theme=col.whitebg) also does the same thing.  The
>>same thing happens win.metafile() for me. This is on WinXPPro,
>>R-1.9.1 and
>>    
>>
>
>Definitely a bug, but probably not where you would think. Note that 
>col.whitebg() is misnamed, the background is actually  'transparent'. 
>As far as I can make out, the first plot is the one that's wrong, all 
>the subsequent ones are fine. (The apparent 'grayness' of the 
>background is probably just a feature of your png displayer.) 
>
>The workaround depends on whether you really want a white or transparent 
>background.
>
>
>For transparent:
>
>library(lattice)
>z <- expand.grid(A = LETTERS[1:8], B = letters[1:6], x = 1, y = 1)
>
>trellis.device(png, file = "test%02d.png")
>par(bg = "transparent")
>lset(col.whitebg())
>
>xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
>dev.off()
>
>
>For white:
>
>library(lattice)
>z <- expand.grid(A = LETTERS[1:8], B = letters[1:6], x = 1, y = 1)
>
>trellis.device(png, file = "test%02d.png") 
>par(bg = "white")
>lset(col.whitebg())
>lset(list(background = list(col = "white")))
>
>xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
>dev.off()
>
>
>The reason for this, I think, is that grid seems to use par("bg") for 
>the background of the first plot, but not for the rest. See, for 
>example. the results of 
>
>png(bg = "yellow")
>grid.lines()
>grid.newpage()
>grid.lines()
>dev.off()
>
>I'll have to think about the best way to fix this. 
>
>Deepayan
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From rcmcll at yahoo.com  Sun Jul 18 19:38:52 2004
From: rcmcll at yahoo.com (bob mccall)
Date: Sun, 18 Jul 2004 10:38:52 -0700 (PDT)
Subject: [R] stl,package=stats
Message-ID: <20040718173852.58174.qmail@web60008.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040718/fb331e8e/attachment.pl

From deepayan at stat.wisc.edu  Sun Jul 18 19:52:02 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 18 Jul 2004 12:52:02 -0500
Subject: [R] gray background in png
In-Reply-To: <40FAB35E.2040109@arcriswell.com>
References: <3A822319EB35174CA3714066D590DCD504AF807B@usrymx25.merck.com>
	<200407181136.16960.deepayan@stat.wisc.edu>
	<40FAB35E.2040109@arcriswell.com>
Message-ID: <200407181252.02421.deepayan@stat.wisc.edu>

On Sunday 18 July 2004 12:29, Andrew Criswell wrote:
> It also seems to work with two lines of code crossed out.
>
> library(lattice)
> z <- expand.grid(A = LETTERS[1:8], B = letters[1:6], x = 1, y = 1)
>
> trellis.device(png, file = "test%02d.png")
> # par(bg = "white")
> # lset(col.whitebg())
> lset(list(background = list(col = "white")))
> xyplot(y ~ x | A * B, data = z, layout = c(4, 6))
> dev.off()

Yes, that's because after trellis.device() is called, par("bg") is 
already white, which makes the first commented line redundant. However, 
it won't 'work' if you want to replace white by another color.

Moreover, I would consider this bad usage. The default color scheme for 
png is designed for a gray background. What you have done (by 
commenting the second line) is to change the background to white while 
keeping everything else unchanged. This technically gives you the 
desired objective of a white background, but with very light colors for 
the points.

Deepayan



From ligges at statistik.uni-dortmund.de  Sun Jul 18 20:00:32 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 18 Jul 2004 20:00:32 +0200
Subject: [R] stl,package=stats
In-Reply-To: <20040718173852.58174.qmail@web60008.mail.yahoo.com>
References: <20040718173852.58174.qmail@web60008.mail.yahoo.com>
Message-ID: <40FABAC0.2040905@statistik.uni-dortmund.de>

bob mccall wrote:
> Greetings:
>  
> I'm using the time series decomposition routine "stl" from the package "stats".
> But how do I get the results into a vector to work with them?
> example:
>  
> data(AirPassengers)
> m<-stl(AirPassengers,"per")
> print(m)
>  
> This lists the output but can't figure out how to extract the individual series like seasonal, trend, irregular.

There are two ways:
Either use str(m) to look at the structure of the object or read the 
help page ?stl which tells you that

   ... 'stl returns an object of class "stl" with components
    time.series     a multiple time series with columns
                    seasonal, trend and remainder.' ...

I don't know whether there are any specific extractor methods, but to 
extract the decomposed seasonal values, you can simply write:

    m$time.series[,"seasonal"]

Uwe Ligges


> Thanks,
> Bob
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From prodrigues at dcc.fc.up.pt  Sun Jul 18 20:07:41 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: Sun, 18 Jul 2004 19:07:41 +0100
Subject: [R] stl,package=stats
In-Reply-To: <20040718173852.58174.qmail@web60008.mail.yahoo.com>
References: <20040718173852.58174.qmail@web60008.mail.yahoo.com>
Message-ID: <1090174061.3090.18.camel@atlantic>

On Sun, 2004-07-18 at 18:38, bob mccall wrote:
> Greetings:
>  
> I'm using the time series decomposition routine "stl" from the package "stats".
> But how do I get the results into a vector to work with them?
> example:
>  
> data(AirPassengers)
> m<-stl(AirPassengers,"per")
> print(m)
>  
> This lists the output but can't figure out how to extract the individual series like seasonal, trend, irregular.

# Seasonal
as.vector(m$time.series[,1])
# Trend
as.vector(m$time.series[,2])
# Remainder
as.vector(m$time.series[,3])

>  
> Thanks,
> Bob
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From AvMailGate at ns.beta-n.ro  Sun Jul 18 20:11:58 2004
From: AvMailGate at ns.beta-n.ro (AvMailGate@ns.beta-n.ro)
Date: Sun, 18 Jul 2004 21:11:58 +0300
Subject: [R] AntiVir ALERT [your mail: "Mail Authentication"]
Message-ID: <200407181811.i6IIBwQB002841@ns.beta-n.ro>

* * * * * * * * * * * * * * * AntiVir ALERT * * * * * * * * * * * * * * *
This version of AntiVir is licensed for private and non-commercial use.

AntiVir has detected the following in a mail from your address:

        Worm/NetSky.P worm	

The mail was not delivered.

Please remove any potential malicious software from your computer before
sending a new mail with attachments.

Mail-Info:
--8<--
 From: r-help at stat.math.ethz.ch
 To: office at beta-n.ro
 Date: Sun, 18 Jul 2004 20:15:05 +0200
 Subject: Mail Authentication
--8<--


--
AntiVir for UNIX
Copyright (C) 1994-2002 by H+BEDV Datentechnik GmbH. All rights reserved.
For more information see http://www.antivir.de/ or http://www.hbedv.com/



From martin.Posch at univie.ac.at  Sun Jul 18 22:08:19 2004
From: martin.Posch at univie.ac.at (M. Posch)
Date: Sun, 18 Jul 2004 22:08:19 +0200
Subject: [R] Bootstrap of Kaplan-Meier Estimate for clustered data
Message-ID: <6.1.2.0.1.20040718214434.01c0dac0@ims02.mstat.univie.ac.at>

Is there an R-procedure to calculate a Kaplan Meier estimate with 
confidence bounds for correlated survival times (with correlated groups of 
observations  which can be accounted for with the "cluster" argument in the 
cox regression). I would need it to estimate the survival time of dental 
implants, where each patient has several implants.

Thanks,

Martin



From pwilkinson at videotron.ca  Mon Jul 19 01:08:16 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Sun, 18 Jul 2004 19:08:16 -0400
Subject: [R] ifelse, evaluating to given number
In-Reply-To: <6.1.2.0.1.20040718214434.01c0dac0@ims02.mstat.univie.ac.at>
References: <6.1.2.0.1.20040718214434.01c0dac0@ims02.mstat.univie.ac.at>
Message-ID: <6.1.1.1.2.20040718185738.01bfbbd8@pop.videotron.ca>


I would like to take advantage of the  vectorized 'ifelse' command. Given a 
filter number of 'filter', if the nm'th value in a n x m matrix I would 
like to perform the following.

newMatrix <- ifelse(myMat <=filter, filter+1, "existing nm'th value").

What do I use to express the "existing nm'th value" in this expression if I 
want to test an nm th value is less than 'filter', if false use the 
existing nm'th value.

This does not seem to be documented in the help().

Peter W.



From ramasamy at cancer.org.uk  Mon Jul 19 01:23:45 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 19 Jul 2004 00:23:45 +0100
Subject: [R] ifelse, evaluating to given number
In-Reply-To: <6.1.1.1.2.20040718185738.01bfbbd8@pop.videotron.ca>
References: <6.1.2.0.1.20040718214434.01c0dac0@ims02.mstat.univie.ac.at>
	<6.1.1.1.2.20040718185738.01bfbbd8@pop.videotron.ca>
Message-ID: <1090193025.4343.1.camel@localhost.localdomain>

Is this what you want ?

> m <- matrix( 1:12, nc=3 )
> m
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12

> ifelse( m < 6.5, 999, m )
     [,1] [,2] [,3]
[1,]  999  999    9
[2,]  999  999   10
[3,]  999    7   11
[4,]  999    8   12


On Mon, 2004-07-19 at 00:08, Peter Wilkinson wrote:
> I would like to take advantage of the  vectorized 'ifelse' command. Given a 
> filter number of 'filter', if the nm'th value in a n x m matrix I would 
> like to perform the following.
> 
> newMatrix <- ifelse(myMat <=filter, filter+1, "existing nm'th value").
> 
> What do I use to express the "existing nm'th value" in this expression if I 
> want to test an nm th value is less than 'filter', if false use the 
> existing nm'th value.
> 
> This does not seem to be documented in the help().
> 
> Peter W.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From pwilkinson at videotron.ca  Mon Jul 19 01:35:22 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Sun, 18 Jul 2004 19:35:22 -0400
Subject: [R] ifelse, evaluating to given number
In-Reply-To: <1090193025.4343.1.camel@localhost.localdomain>
References: <6.1.2.0.1.20040718214434.01c0dac0@ims02.mstat.univie.ac.at>
	<6.1.1.1.2.20040718185738.01bfbbd8@pop.videotron.ca>
	<1090193025.4343.1.camel@localhost.localdomain>
Message-ID: <6.1.1.1.2.20040718193233.01b9a008@pop.videotron.ca>

yes,

so the short of it is ifelse uses whatever I use to represent the existing 
value in the 'test' expression.

I was thinking there was a reserved word for that like the $_ in perl 
...  but that works fine for me.


Peter


At 07:23 PM 7/18/2004, Adaikalavan Ramasamy wrote:
>Is this what you want ?
>
> > m <- matrix( 1:12, nc=3 )
> > m
>      [,1] [,2] [,3]
>[1,]    1    5    9
>[2,]    2    6   10
>[3,]    3    7   11
>[4,]    4    8   12
>
> > ifelse( m < 6.5, 999, m )
>      [,1] [,2] [,3]
>[1,]  999  999    9
>[2,]  999  999   10
>[3,]  999    7   11
>[4,]  999    8   12
>
>
>On Mon, 2004-07-19 at 00:08, Peter Wilkinson wrote:
> > I would like to take advantage of the  vectorized 'ifelse' command. 
> Given a
> > filter number of 'filter', if the nm'th value in a n x m matrix I would
> > like to perform the following.
> >
> > newMatrix <- ifelse(myMat <=filter, filter+1, "existing nm'th value").
> >
> > What do I use to express the "existing nm'th value" in this expression 
> if I
> > want to test an nm th value is less than 'filter', if false use the
> > existing nm'th value.
> >
> > This does not seem to be documented in the help().
> >
> > Peter W.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >



From singin at personainternet.com  Mon Jul 19 02:00:40 2004
From: singin at personainternet.com (Mark St. John)
Date: Sun, 18 Jul 2004 20:00:40 -0400
Subject: [R] Dendrogram plotting options?
Message-ID: <AC0E868C-D916-11D8-8822-000A959C34EA@personainternet.com>

Hi, I was wondering if there is more flexibility in the output of 
dendrograms when plotting a hclust object. I can't seem to find 
information on how to change the default output of a "hanging" style 
tree with the axis on the right to a left-to-right plot with and axis 
on the bottom. Example  code follows:

library(vegan) #loads the "vegan" module that compuptes ANOSIM
library(cluster)
community <- read.csv("ANOSIMmites.csv", header=TRUE) #reads the data 
file into memory under the name "community"
enviro <- read.csv("ANOSIMenv.csv", header=TRUE) #reads the grouping 
variables into memory
attach(enviro)
attach(community)
community.dist <- vegdist(community)
community.ano <- anosim(community.dist, plant)
summary(community.ano)
clust <- hclust(community.dist, method = "complete", members=NULL)
plot(clust, labels = sample, hang = 0.05, axes = TRUE, frame.plot = 
FALSE, ann = F, main = "Dendrogram of sample similarity", sub = "based 
on associated soil mite species", xlab = NULL, ylab = "Height")

Thanks! Mark



From H.A.L.KIERS at ppsw.rug.nl  Mon Jul 19 04:43:59 2004
From: H.A.L.KIERS at ppsw.rug.nl (H.A.L.KIERS@ppsw.rug.nl)
Date: Mon, 19 Jul 2004 3:43:59 +0100
Subject: [R] your job? (I found that!)
Message-ID: <1B74CDF2CC4@PPSWMAIL.ppsw.rug.nl>

This is to confirm that your email reached my mailbox. 
I am out of town till July 20; I may read email still at July 12, 
but after that probbaly not before July 20. 

with best regards
Henk

Uw bericht is bij mij aangekomen, 
maar ik zal het pas vanaf 20 juli terug zijn. 
Voor vragen over het tentamen statistiek 1B kunt u zich wenden tot 
Rink Hoekstra (R.Hoekstra1 at ppsw.rug.nl)

vr.gr.
Henk Kiers



From ray at mcs.vuw.ac.nz  Mon Jul 19 04:12:37 2004
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Mon, 19 Jul 2004 14:12:37 +1200 (NZST)
Subject: [R] Seg. faults in mapthin (in package maps!)
Message-ID: <200407190212.i6J2Cae6005705@tahi.mcs.vuw.ac.nz>

> From: "Kevin Bartz" <kbartz at loyaltymatrix.com>
> Date: Thu, 1 Jul 2004 10:18:36 -0700
> 
> Dr. Ripley, you are the master. That fix worked like a charm! All the way to
> 50, with no problems. Thanks again,
> 
Hear, hear!

> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Thursday, July 01, 2004 10:07 AM
> 
> There are a few other quirks, and I would check some of the other uses of 
> `long' in the C sources.
> 
OK, I've changed most of the 'long's to 'int's in the next version
(maps_2.0-22), soon to appear on CRAN.  It passes R CMD check on my 32-bit
systems, but please test it thoroughly on a 64-bit system.

Ray Brownrigg



From ru68y7s at myrealbox.com  Mon Jul 19 06:03:20 2004
From: ru68y7s at myrealbox.com (s viswanath)
Date: Sun, 18 Jul 2004 21:03:20 -0700
Subject: [R] (no subject)
Message-ID: <1090209800.d688989cru68y7s@myrealbox.com>

hello R experts,

my question is regarding arma modelling and specification. 

in another older, statistics package , after determining stationarity, i would try to work out the number of ar and ma lags using an lm test. 
to do this i would 

1. regress my dependant variable on an intercept term then
2. use LM test for serial correlation, and finally
3. use the p value of the ols residuals to get the maximum lags for the arma specification.

I am interested to know how to do this LM test in R say using a function, using perhaps the fseries package?

Thank you in advance,

Sri



From ftcheung at hkusua.hku.hk  Mon Jul 19 08:08:25 2004
From: ftcheung at hkusua.hku.hk (Frankie Cheung)
Date: Mon, 19 Jul 2004 14:08:25 +0800 (HKT)
Subject: [R] R 1.9.1 compilation error (on AIX 5.1)
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7F53@usrymx25.merck.com>
Message-ID: <Pine.GSO.4.10.10407191353120.6912-100000@hkusua>

Dear Sir,

Still encounter another error message during compilation of R 1.9.1 on
AIX 5.1 (target expall not found):

make[1]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/m4'
make[1]: Nothing to be done for `R'.
make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/m4'
make[1]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/tools'
make[1]: Nothing to be done for `R'.
make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/tools'
make[1]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/afm'
make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/afm'
make[1]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/doc'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/doc/html'
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
        LC_ALL = (unset),
        LC__FASTMSG = "true",
        LANG = "en_US"
    are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").
make[3]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/doc/html/search'
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/doc/html/search'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/doc/html'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/doc/manual'
make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/doc'
make[1]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/etc'
make[1]: Nothing to be done for `R'.
make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/etc'
make[1]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/share'
make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/share'
make[1]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/scripts'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/scripts'
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/scripts'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/scripts'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/include'
make[3]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/include/R_ext'
make[3]: Nothing to be done for `R'.
make[3]: Leaving directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/include/R_ext'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/include'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/appl'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/appl'
make[3]: `Makedeps' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/appl'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/appl'
make[3]: `libappl.a' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/appl'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/appl'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/nmath'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/nmath'
make[3]: `Makedeps' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/nmath'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/nmath'
make[3]: `libnmath.a' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/nmath'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/nmath'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/unix'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/unix'
make[3]: `Makedeps' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/unix'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/unix'
make[3]: `libunix.a' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/unix'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/unix'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra'
make[3]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/bzip2'
make[4]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/bzip2'
make[4]: `Makedeps' is up to date.
make[4]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/bzip2'
make[4]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/bzip2'
make[4]: `libbz2.a' is up to date.
make[4]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/bzip2'
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/bzip2'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/pcre'
make[4]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/pcre'
make[4]: `Makedeps' is up to date.
make[4]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/pcre'
make[4]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/pcre'
make[4]: `libpcre.a' is up to date.
make[4]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/pcre'
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/pcre'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/zlib'
make[4]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/zlib'
make[4]: `Makedeps' is up to date.
make[4]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/zlib'
make[4]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/zlib'
make[4]: `libz.a' is up to date.
make[4]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/zlib'
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra/zlib'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/extra'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
make[3]: `Makedeps' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
make[3]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
make[3]: `R.bin' is up to date.
make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
make[2]: Entering directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules'
make[3]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules/internet'

make[4]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules/internet'

make[4]: `Makedeps' is up to date.
make[4]: Leaving directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules/internet'

make[4]: Entering directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules/internet'

gcc -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall
-Wl,-bI:../../../
etc/R.exp -L/usr/local/lib -o internet.so  Rsock.lo internet.lo nanoftp.lo
nanoh
ttp.lo sock.lo sockconn.lo 
/usr/local/bin/ld: target expall not found
collect2: ld returned 1 exit status
make[4]: *** [internet.so] Error 1

ake[4]: Leaving directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules/internet'

make[3]: *** [R] Error 2
make[3]: Leaving directory
`/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules/internet'

make[2]: *** [R] Error 1
make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src'
make: *** [R] Error 1

Any suggestion?

with regards,
Frankie Cheung 

On Wed, 23 Jun 2004, Liaw, Andy wrote:

> Date: Wed, 23 Jun 2004 11:02:09 -0400
> From: "Liaw, Andy" <andy_liaw at merck.com>
> To: 'Prof Brian Ripley' <ripley at stats.ox.ac.uk>,
     Frankie Cheung <ftcheung at hkusua.hku.hk>
> Cc: R-help at stat.math.ethz.ch
> Subject: RE: [R] R 1.9.1 compilation error (on AIX 5.1)
> 
> > From: Prof Brian Ripley
> > 
> > We do have alpha/beta test periods for new releases of R, so 
> > would anyone 
> > who did test AIX please confirm that they did succeed.  (No 
> > one reported 
> > an error, including yourself: are any AIX users interested in helping 
> > having R available for AIX?)   It is much better to have such reports 
> > during alpha test, or at least beta test.
> 
> I just tried compiling R-1.9.1 as 64-bit on powerpc-ibm-aix5.1.0.0 using
> xlc/xlf.  The compile went fine, and the only part of make check that failed
> was internet.R (since there's no 'Net access from that box).  The GCC on
> that box is probably too outdated to try, unfortunately.
> 
> Best,
> Andy
> 
>  
> > On Wed, 23 Jun 2004, Frankie Cheung wrote:
> > 
> > > Dear Sir/Madam,
> > > 
> > > I encounter some problem duuring compilation of R 1.9.1 on 
> > AIX 5.1, after
> > > running "./configure" then I type "make" to compile:
> > > 
> > > # make
> > > .....
> > > gcc -I../../src/extra/zlib -I../../src/extra/bzip2 
> > -I../../src/extra/pcre
> > > -I. -I../../src/include -I../../src/include -I/usr/local/include
> > > -DHAVE_CONFIG_H -mno-fp-in-toc  -g -O2 -c registration.c -o 
> > registration.o
> > > g77   -g -O2 -c xxxpr.f -o xxxpr.o
> > > gcc -Wl,-bdynamic -Wl,-bE:../../etc/R.exp -Wl,-bM:SRE 
> > -L/usr/local/lib -o
> > > R.bin  CConverters.o Rdynload.o RNG.o apply.o arithmetic.o 
> > apse.o array.o
> > > attrib.o base.o bind.o builtin.o character.o coerce.o 
> > colors.o complex.o
> > > connections.o context.o cov.o cum.o dcf.o datetime.o debug.o devPS.o
> > > devPicTeX.o deparse.o deriv.o devices.o dotcode.o dounzip.o 
> > dstruct.o
> > > duplicate.o engine.o envir.o errors.o eval.o format.o 
> > fourier.o gram.o
> > > gram-ex.o graphics.o identical.o internet.o iosupport.o 
> > lapack.o list.o
> > > logic.o main.o mapply.o match.o memory.o model.o names.o 
> > objects.o optim.o
> > > optimize.o options.o par.o paste.o pcre.o platform.o plot.o plot3d.o
> > > plotmath.o print.o printarray.o printvector.o printutils.o qsort.o
> > > random.o regex.o relop.o saveload.o scan.o seq.o 
> > serialize.o size.o sort.o
> > > source.o split.o sprintf.o subassign.o subscript.o subset.o 
> > summary.o
> > > unique.o util.o version.o vfonts.o registration.o xxxpr.o
> > > ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a   
> > -L/usr/local/lib
> > > -L/usr/local/lib/gcc-lib/powerpc-ibm-aix5.1.0.0/3.3.3
> > > 
> > -L/usr/local/lib/gcc-lib/powerpc-ibm-aix5.1.0.0/3.3.3/../../..
> > /../powerpc-ibm-aix5.1.0.0/lib
> > > 
> > -L/usr/local/lib/gcc-lib/powerpc-ibm-aix5.1.0.0/3.3.3/../../..
> >  -lfrtbegin
> > > -lg2c -lm -lgcc_s
> > > /usr/local/lib/gcc-lib/powerpc-ibm-aix5.1.0.0/3.3.3/libgcc.a -lg
> > > /lib/crt0.o ../extra/zlib/libz.a ../extra/bzip2/libbz2.a
> > > ../extra/pcre/libpcre.a -ldl -lm -lc
> > > /usr/local/bin/ld: target dynamic not found
> > > collect2: ld returned 1 exit status
> > > make[3]: *** [R.bin] Error 1
> > > make[3]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
> > > make[2]: *** [R] Error 2
> > > make[2]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src/main'
> > > make[1]: *** [R] Error 1
> > > make[1]: Leaving directory `/d1/ftcheung_GoIn/tmp/R-1.9.1/src'
> > > make: *** [R] Error 1
> > > 
> > > I've tried to use AIX xlc compiler and GCC compiler (v2.95 
> > and v3.3.3) but
> > > all of them result to the same error message shown above. 
> > Can anyone give
> > > me some hint of how to solve it?
> > 
> > You appear not to be using the standard loader 
> > (`/usr/local/bin/ld').  
> > Please set MAIN_LDFLAGS (ideally in config.site before 
> > configure, but you
> > can edit Makeconf now) to whatever your loader needs.  If 
> > this is GNU ld
> > then I guess you need -Wl,--export-dynamic.
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
> ------------------------------------------------------------------------------
>



From maechler at stat.math.ethz.ch  Mon Jul 19 09:32:50 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Jul 2004 09:32:50 +0200
Subject: [R] Dendrogram plotting options?
In-Reply-To: <AC0E868C-D916-11D8-8822-000A959C34EA@personainternet.com>
References: <AC0E868C-D916-11D8-8822-000A959C34EA@personainternet.com>
Message-ID: <16635.31010.854586.303819@gargle.gargle.HOWL>


    Mark> Hi, I was wondering if there is more flexibility in the output of 
    Mark> dendrograms when plotting a hclust object. 

This is becoming a real FAQ.
{Have you tried to find the answer in the searchable "R-help" archives?}

    Mark> dendrograms when plotting a hclust object. I can't seem to find 
    Mark> information on how to change the default output of a "hanging" style 
    Mark> tree with the axis on the right to a left-to-right plot with and axis 
    Mark> on the bottom. Example  code follows:

    Mark> library(vegan) #loads the "vegan" module that compuptes ANOSIM
    Mark> library(cluster)
    Mark> community <- read.csv("ANOSIMmites.csv", header=TRUE) #reads the data 

we don't have that file. So why don't you rather use a
*reproducible* example as the posting guide (bottom line of
every R-help message) tells you to ?

    Mark>  <<... hence irrelevant ...>

    Mark> clust <- hclust(community.dist, method = "complete", members=NULL)

    Mark> plot(clust, labels = sample, hang = 0.05, axes = TRUE, frame.plot = 
    Mark>      FALSE, ann = F, main = "Dendrogram of sample similarity", 
    Mark>      sub = "based on associated soil mite species", 
    Mark>      xlab = NULL, ylab = "Height")

"The" answer in principle is

    d.cl <- as.dendrogram(clust, hang = 0.05)## <-- 'hang' must be here
    plot(d.cl, ..................., horiz = TRUE)

and the "R-devel" version allows even quite a few more options to
dendrogram plotting than "current R".

Martin Maechler, Seminar fuer Statistik, ETH Zurich



From muteau at ensam.inra.fr  Mon Jul 19 10:05:56 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Mon, 19 Jul 2004 10:05:56 +0200
Subject: [R] problem with read.table
Message-ID: <5.0.2.1.2.20040719095046.02d4b898@ensam.inra.fr>

Hello R-users,
I apologize for my question but I'm a newbie. I want to read a file which 
columns separator is "\t". At the end of each row there is a "\n" to go to 
the following line. The three first lines are remarks lines and the fourth 
contains columns titles ( variables names, ids, dates, calculated values, 
observed values...) . I do:
read.table("myFile", header=TRUE, sep = "\t", skip = 3)

I obtain a strange result, lines are in a bad order:

    cell6/voxel15   1998/365a       2.0     1.0     0.55 
0.27480000257492065     0\nRendement de la 
culture      0.0     crop4   0/0a    0.0     1.0     0.0     0.0 
0\nRendement de la 
culture      0.0     crop4   1998/75a        0.0     1.0     0.0     0.0 
  0\nRendement de la 
culture      0.0     crop4   1998/150a       0.0     1.0     0.0     0.0 
  0\nRendement de la 
culture      0.0     crop4   1998/225a       0.0     1.0     0.0     0.0 
  0\nRendement de la 
culture      0.0     crop4   1998/300a       0.0     1.0     0.0 
3.0368848       0\nRayonnement diffu 
re??u       0.0     crop1   0/0a    0.0     2.0     0.0     0.0 
0\nRayonnement diffu 
re??u       0.0     crop1   1998/50a        0.0     2.0     0.0 
6.8406434       0\nRayonnement diffu 
re??u       0.0     crop1   1998/100a       0.0     2.0     0.0 
14.235084       0\nRayonnement diffu 
re??u       0.0     crop1   1998/150a       0.0     2.0     0.0     14.15452 
        0\nRayonnement diffu 
re??u       0.0     crop1   1998/200a       0.0     2.0     0.0 
13.691006       0\nRayonnement diffu 
re??u       0.0     crop1   1998/250a       0.0     2.0     0.0 
10.997387       0\nRayonnement diffu 
re??u       0.0     crop1   1998/300a       0.0     2.0     0.0 
10.333394       0\nRayonnement diffu 
re??u       0.0     crop1   1998/350a       0.0     2.0     0.0     4.198115 
        0\nRayonnement diffu 
re??u       0.0     crop9   0/0a    2.0     0.0     0.0     0.0 
0\nRayonnement diffu 
re??u       0.0     crop9   1998/50a        2.0     0.0     0.0 
6.8406434       0\nRayonnement diffu 
re??u       0.0     crop9   1998/100a       2.0     0.0     0.0 
14.235084       0\nRayonnement diffu 
re??u       0.0     crop9   1998/150a       2.0     0.0     0.0     14.15452 
        0\nRayonnement diffu 
re??u       0.0     crop9   1998/200a       2.0     0.0     0.0 
13.676454       0\nRayonnement diffu 
re??u       0.0     crop9   1998/250a       2.0     0.0     0.0 
10.983188       0\nRayonnement diffu 
re??u       0.0     crop9   1998/300a       2.0     0.0     0.0 
10.333394       0\nRayonnement diffu 
re??u       0.0     crop9   1998/350a       2.0     0.0     0.0     4.198115 
        0\n
   weighting            id      date   x   y    z   calculated observed
1         0         tree1 1998/365a 1.5 1.5 0.00 1.580000e+02  162.000
2         0         tree1      0/0a 1.5 1.5 0.00 6.242254e-03    0.007
3         0         tree1 1998/365a 1.5 1.5 0.00 1.038187e-02    0.011
4         0         tree1 1998/365a 1.5 1.5 0.00 1.008111e+00    0.000
5         0 cell4/voxel23 1998/365a 0.0 1.0 0.55 0.000000e+00    0.000
6         0 cell5/voxel18 1998/365a 1.0 1.0 0.25 0.000000e+00    0.000
7         0 cell5/voxel20 1998/365a 1.0 1.0 0.90 0.000000e+00    0.000
8         0 cell6/voxel15 1998/365a 2.0 1.0 0.55 0.000000e+00    0.000
9        NA                          NA  NA   NA           NA       NA

The "\n" is read like a word and not like a symbol to skip a line.
What should I do?

Thanks



From luciana.scalone at unimi.it  Mon Jul 19 10:27:14 2004
From: luciana.scalone at unimi.it (luciana)
Date: Mon, 19 Jul 2004 10:27:14 +0200
Subject: [R] variance stabilizing bootstrap
Message-ID: <007501c46d6a$328403d0$cf58959f@Centro>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/40c2dd2b/attachment.pl

From asemeria at cramont.it  Mon Jul 19 10:40:04 2004
From: asemeria at cramont.it (asemeria@cramont.it)
Date: Mon, 19 Jul 2004 10:40:04 +0200
Subject: [R] problem with read.table
Message-ID: <OF9DF18340.D37F1D7D-ONC1256ED6.002F3259-C1256ED6.002E4B8E@tomware.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/1093a9fc/attachment.pl

From prodrigues at dcc.fc.up.pt  Mon Jul 19 10:42:46 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: Mon, 19 Jul 2004 09:42:46 +0100
Subject: [R] problem with read.table
In-Reply-To: <5.0.2.1.2.20040719095046.02d4b898@ensam.inra.fr>
References: <5.0.2.1.2.20040719095046.02d4b898@ensam.inra.fr>
Message-ID: <1090226566.3096.2.camel@atlantic.ncc.up.pt>

This is a strange result. I couldn't have a similar result, even with
your exact call to read.table. Maybe there is a problem with the file
(possibly some white space characters not cleaned).

If you send the first 5 lines of your text file I could say something
more.

On Mon, 2004-07-19 at 09:05, Vincent MUTEAUD wrote:
> Hello R-users,
> I apologize for my question but I'm a newbie. I want to read a file which 
> columns separator is "\t". At the end of each row there is a "\n" to go to 
> the following line. The three first lines are remarks lines and the fourth 
> contains columns titles ( variables names, ids, dates, calculated values, 
> observed values...) . I do:
> read.table("myFile", header=TRUE, sep = "\t", skip = 3)
> 
> I obtain a strange result, lines are in a bad order:
> 
>     cell6/voxel15   1998/365a       2.0     1.0     0.55 
> 0.27480000257492065     0\nRendement de la 
> culture      0.0     crop4   0/0a    0.0     1.0     0.0     0.0 
> 0\nRendement de la 
> culture      0.0     crop4   1998/75a        0.0     1.0     0.0     0.0 
>   0\nRendement de la 
> culture      0.0     crop4   1998/150a       0.0     1.0     0.0     0.0 
>   0\nRendement de la 
> culture      0.0     crop4   1998/225a       0.0     1.0     0.0     0.0 
>   0\nRendement de la 
> culture      0.0     crop4   1998/300a       0.0     1.0     0.0 
> 3.0368848       0\nRayonnement diffu 
> re??u       0.0     crop1   0/0a    0.0     2.0     0.0     0.0 
> 0\nRayonnement diffu 
> re??u       0.0     crop1   1998/50a        0.0     2.0     0.0 
> 6.8406434       0\nRayonnement diffu 
> re??u       0.0     crop1   1998/100a       0.0     2.0     0.0 
> 14.235084       0\nRayonnement diffu 
> re??u       0.0     crop1   1998/150a       0.0     2.0     0.0     14.15452 
>         0\nRayonnement diffu 
> re??u       0.0     crop1   1998/200a       0.0     2.0     0.0 
> 13.691006       0\nRayonnement diffu 
> re??u       0.0     crop1   1998/250a       0.0     2.0     0.0 
> 10.997387       0\nRayonnement diffu 
> re??u       0.0     crop1   1998/300a       0.0     2.0     0.0 
> 10.333394       0\nRayonnement diffu 
> re??u       0.0     crop1   1998/350a       0.0     2.0     0.0     4.198115 
>         0\nRayonnement diffu 
> re??u       0.0     crop9   0/0a    2.0     0.0     0.0     0.0 
> 0\nRayonnement diffu 
> re??u       0.0     crop9   1998/50a        2.0     0.0     0.0 
> 6.8406434       0\nRayonnement diffu 
> re??u       0.0     crop9   1998/100a       2.0     0.0     0.0 
> 14.235084       0\nRayonnement diffu 
> re??u       0.0     crop9   1998/150a       2.0     0.0     0.0     14.15452 
>         0\nRayonnement diffu 
> re??u       0.0     crop9   1998/200a       2.0     0.0     0.0 
> 13.676454       0\nRayonnement diffu 
> re??u       0.0     crop9   1998/250a       2.0     0.0     0.0 
> 10.983188       0\nRayonnement diffu 
> re??u       0.0     crop9   1998/300a       2.0     0.0     0.0 
> 10.333394       0\nRayonnement diffu 
> re??u       0.0     crop9   1998/350a       2.0     0.0     0.0     4.198115 
>         0\n
>    weighting            id      date   x   y    z   calculated observed
> 1         0         tree1 1998/365a 1.5 1.5 0.00 1.580000e+02  162.000
> 2         0         tree1      0/0a 1.5 1.5 0.00 6.242254e-03    0.007
> 3         0         tree1 1998/365a 1.5 1.5 0.00 1.038187e-02    0.011
> 4         0         tree1 1998/365a 1.5 1.5 0.00 1.008111e+00    0.000
> 5         0 cell4/voxel23 1998/365a 0.0 1.0 0.55 0.000000e+00    0.000
> 6         0 cell5/voxel18 1998/365a 1.0 1.0 0.25 0.000000e+00    0.000
> 7         0 cell5/voxel20 1998/365a 1.0 1.0 0.90 0.000000e+00    0.000
> 8         0 cell6/voxel15 1998/365a 2.0 1.0 0.55 0.000000e+00    0.000
> 9        NA                          NA  NA   NA           NA       NA
> 
> The "\n" is read like a word and not like a symbol to skip a line.
> What should I do?
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From muteau at ensam.inra.fr  Mon Jul 19 10:43:21 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Mon, 19 Jul 2004 10:43:21 +0200
Subject: [R] problem with read.table
In-Reply-To: <OF9DF18340.D37F1D7D-ONC1256ED6.002F3259-C1256ED6.002E4B8E@
	tomware.it>
Message-ID: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/67bd10ac/attachment.pl

From prodrigues at dcc.fc.up.pt  Mon Jul 19 11:00:06 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: Mon, 19 Jul 2004 10:00:06 +0100
Subject: [R] problem with read.table
In-Reply-To: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
References: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
Message-ID: <1090227606.3096.7.camel@atlantic.ncc.up.pt>

The email has changed the file. Please send attached.

On Mon, 2004-07-19 at 09:43, Vincent MUTEAUD wrote:
> Thanks for your quick answer but I don't see the escape character "\n" in 
> "myFile" I see it on the result of my R command.
> 
> This is an extract of myFile:
> 
> # Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004
> 
> 
> varName 
> weighting       id      date    x       y       z       calculated 
> observed
> Date de 
> d??bourrement    0.0     tree1   1998/365a       1.5     1.5     0.0     158 
>      162
> Diam??tre du 
> tronc       0.0     tree1   0/0a    1.5     1.5     0.0 
> 0.0062422542832791805   0.007
> Diam??tre du 
> tronc       0.0     tree1   1998/365a       1.5     1.5     0.0 
> 0.010381871834397316    0.011
> Hauteur totale de 
> l'arbre       0.0     tree1   0/0a    1.5     1.5     0.0     1.0     0
> 
> 
> 
> I don't know why "\n" appears in R.
> 
> 
> A 10:40 19/07/2004 +0200, asemeria at cramont.it a ??crit :
> 
> >You should'nt see the escape character "\n" on "myfile".
> >Try deleting with a text editor "\n"
> >A.S.
> >
> >----------------------------
> >
> >Alessandro Semeria
> >Models and Simulations Laboratory
> >Montecatini Environmental Research Center (Edison Group),
> >Via Ciro Menotti 48,
> >48023 Marina di Ravenna (RA), Italy
> >Tel. +39 544 536811
> >Fax. +39 544 538663
> >E-mail: alessandro.semeria at cramont.it
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From prodrigues at dcc.fc.up.pt  Mon Jul 19 11:08:42 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: Mon, 19 Jul 2004 10:08:42 +0100
Subject: [R] problem with read.table
In-Reply-To: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
References: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
Message-ID: <1090228122.3096.10.camel@atlantic.ncc.up.pt>

If your file looks like attached, you should call

read.table("temp.txt", header=TRUE, sep="\t", skip=3, quote="")



On Mon, 2004-07-19 at 09:43, Vincent MUTEAUD wrote:
> Thanks for your quick answer but I don't see the escape character "\n" in 
> "myFile" I see it on the result of my R command.
> 
> This is an extract of myFile:
> 
> # Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004
> 
> 
> varName 
> weighting       id      date    x       y       z       calculated 
> observed
> Date de 
> d??bourrement    0.0     tree1   1998/365a       1.5     1.5     0.0     158 
>      162
> Diam??tre du 
> tronc       0.0     tree1   0/0a    1.5     1.5     0.0 
> 0.0062422542832791805   0.007
> Diam??tre du 
> tronc       0.0     tree1   1998/365a       1.5     1.5     0.0 
> 0.010381871834397316    0.011
> Hauteur totale de 
> l'arbre       0.0     tree1   0/0a    1.5     1.5     0.0     1.0     0
> 
> 
> 
> I don't know why "\n" appears in R.
> 
> 
> A 10:40 19/07/2004 +0200, asemeria at cramont.it a ??crit :
> 
> >You should'nt see the escape character "\n" on "myfile".
> >Try deleting with a text editor "\n"
> >A.S.
> >
> >----------------------------
> >
> >Alessandro Semeria
> >Models and Simulations Laboratory
> >Montecatini Environmental Research Center (Edison Group),
> >Via Ciro Menotti 48,
> >48023 Marina di Ravenna (RA), Italy
> >Tel. +39 544 536811
> >Fax. +39 544 538663
> >E-mail: alessandro.semeria at cramont.it
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-------------- next part --------------
# Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004


varName	 weighting	id	date	x	y	z	calculated	observed
Date de d??bourrement	0.0	tree1	1998/365a	1.5	1.5	0.0	158	162
Diam??tre du tronc	0.0	tree1	0/0a	1.5	1.5	0.0	0.0062422542832791805	0.007
Diam??tre du tronc	0.0	tree1	1998/365a	1.5	1.5	0.0	0.010381871834397316	0.011
Hauteur totale de l'arbre	0.0	tree1	0/0a	1.5	1.5	0.0	1.0	0

From muteau at ensam.inra.fr  Mon Jul 19 11:09:23 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Mon, 19 Jul 2004 11:09:23 +0200
Subject: [R] problem with read.table
In-Reply-To: <1090227606.3096.7.camel@atlantic.ncc.up.pt>
References: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
	<5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
Message-ID: <5.0.2.1.2.20040719110716.02d26008@ensam.inra.fr>

Sorry, I may have suspect that the format will be changed.


A 10:00 19/07/2004 +0100, Pedro Rodrigues a ?crit :
>The email has changed the file. Please send attached.
>
>On Mon, 2004-07-19 at 09:43, Vincent MUTEAUD wrote:
> > Thanks for your quick answer but I don't see the escape character "\n" in
> > "myFile" I see it on the result of my R command.
> >
> > This is an extract of myFile:
> >
> > # Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004
> >
> >
> > varName
> > weighting       id      date    x       y       z       calculated
> > observed
> > Date de
> > 
> d?bourrement    0.0     tree1   1998/365a       1.5     1.5     0.0     158
> >      162
> > Diam?tre du
> > tronc       0.0     tree1   0/0a    1.5     1.5     0.0
> > 0.0062422542832791805   0.007
> > Diam?tre du
> > tronc       0.0     tree1   1998/365a       1.5     1.5     0.0
> > 0.010381871834397316    0.011
> > Hauteur totale de
> > l'arbre       0.0     tree1   0/0a    1.5     1.5     0.0     1.0     0
> >
> >
> >
> > I don't know why "\n" appears in R.
> >
> >
> > A 10:40 19/07/2004 +0200, asemeria at cramont.it a ?crit :
> >
> > >You should'nt see the escape character "\n" on "myfile".
> > >Try deleting with a text editor "\n"
> > >A.S.
> > >
> > >----------------------------
> > >
> > >Alessandro Semeria
> > >Models and Simulations Laboratory
> > >Montecatini Environmental Research Center (Edison Group),
> > >Via Ciro Menotti 48,
> > >48023 Marina di Ravenna (RA), Italy
> > >Tel. +39 544 536811
> > >Fax. +39 544 538663
> > >E-mail: alessandro.semeria at cramont.it
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
-------------- next part --------------
# Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004


varName	weighting	id	date	x	y	z	calculated	observed
Date de d?bourrement	0.0	tree1	1998/365a	1.5	1.5	0.0	158	162
Diam?tre du tronc  	0.0	tree1	0/0a	1.5	1.5	0.0	0.0062422542832791805	0.007
Diam?tre du tronc  	0.0	tree1	1998/365a	1.5	1.5	0.0	0.010381871834397316	0.011
Hauteur totale de l'arbre	0.0	tree1	0/0a	1.5	1.5	0.0	1.0	0
Hauteur totale de l'arbre	0.0	tree1	1998/365a	1.5	1.5	0.0	1.0081111192703247	0
Densit? de racines fines de l'arbre	0.0	cell4/voxel22	1998/365a	0.0	1.0	0.25	0.0	0
Densit? de racines fines de l'arbre	0.0	cell4/voxel23	1998/365a	0.0	1.0	0.55	0.0	0
Densit? de racines fines de l'arbre	0.0	cell4/voxel24	1998/365a	0.0	1.0	0.9	0.0	0
Densit? de racines fines de l'arbre	0.0	cell5/voxel18	1998/365a	1.0	1.0	0.25	0.0	0
Densit? de racines fines de l'arbre	0.0	cell5/voxel19	1998/365a	1.0	1.0	0.55	0.0	0
Densit? de racines fines de l'arbre	0.0	cell5/voxel20	1998/365a	1.0	1.0	0.9	0.0	0
Densit? de racines fines de l'arbre	0.0	cell6/voxel14	1998/365a	2.0	1.0	0.25	0.0	0
Densit? de racines fines de l'arbre	0.0	cell6/voxel15	1998/365a	2.0	1.0	0.55	0.0	0
Densit? de racines fines de l'arbre	0.0	cell6/voxel16	1998/365a	2.0	1.0	0.9	0.0	0
Teneur en eau	0.0	cell6/voxel15	1998/365a	2.0	1.0	0.55	0.27480000257492065	0
Rendement de la culture	0.0	crop4	0/0a	0.0	1.0	0.0	0.0	0
Rendement de la culture	0.0	crop4	1998/75a	0.0	1.0	0.0	0.0	0
Rendement de la culture	0.0	crop4	1998/150a	0.0	1.0	0.0	0.0	0
Rendement de la culture	0.0	crop4	1998/225a	0.0	1.0	0.0	0.0	0
Rendement de la culture	0.0	crop4	1998/300a	0.0	1.0	0.0	3.0368848	0
Rayonnement diffu re?u	0.0	crop1	0/0a	0.0	2.0	0.0	0.0	0
Rayonnement diffu re?u	0.0	crop1	1998/50a	0.0	2.0	0.0	6.8406434	0
Rayonnement diffu re?u	0.0	crop1	1998/100a	0.0	2.0	0.0	14.235084	0
Rayonnement diffu re?u	0.0	crop1	1998/150a	0.0	2.0	0.0	14.15452	0
Rayonnement diffu re?u	0.0	crop1	1998/200a	0.0	2.0	0.0	13.691006	0
Rayonnement diffu re?u	0.0	crop1	1998/250a	0.0	2.0	0.0	10.997387	0
Rayonnement diffu re?u	0.0	crop1	1998/300a	0.0	2.0	0.0	10.333394	0
Rayonnement diffu re?u	0.0	crop1	1998/350a	0.0	2.0	0.0	4.198115	0
Rayonnement diffu re?u	0.0	crop9	0/0a	2.0	0.0	0.0	0.0	0
Rayonnement diffu re?u	0.0	crop9	1998/50a	2.0	0.0	0.0	6.8406434	0
Rayonnement diffu re?u	0.0	crop9	1998/100a	2.0	0.0	0.0	14.235084	0
Rayonnement diffu re?u	0.0	crop9	1998/150a	2.0	0.0	0.0	14.15452	0
Rayonnement diffu re?u	0.0	crop9	1998/200a	2.0	0.0	0.0	13.676454	0
Rayonnement diffu re?u	0.0	crop9	1998/250a	2.0	0.0	0.0	10.983188	0
Rayonnement diffu re?u	0.0	crop9	1998/300a	2.0	0.0	0.0	10.333394	0
Rayonnement diffu re?u	0.0	crop9	1998/350a	2.0	0.0	0.0	4.198115	0

From ernesto at ipimar.pt  Mon Jul 19 11:23:57 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 19 Jul 2004 10:23:57 +0100
Subject: [R] Eclipse plugin for R or perhaps S-plus.
In-Reply-To: <004201c46b73$2f47eb30$0101a8c0@KILER>
References: <004201c46b73$2f47eb30$0101a8c0@KILER>
Message-ID: <1090229036.21446.12.camel@gandalf.local>

On Fri, 2004-07-16 at 21:26, Valentin Todorov wrote:
> Hi Richard,
> 
> A couple of months ago I did some investigation but could not find anything. For some time I played with the idea to implement it myself, but I am still at nowhere.
> 
> I am using WinEdt, unfortunately only on Windows.
> 
> best regards,
> Valentin
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Hi, 

Having a R module for eclipse could be very interesting. It works with
OOP and UML so it might be possible in the future to design S4 methods
in R with UML ;-)

Unfortunately I can not do anything helpfull about it, but I can help
implementing syntax highlighting (I did it for NEdit).

If someone takes over the task I'll be willing to help.

Best regards

EJ



From Achim.Zeileis at wu-wien.ac.at  Mon Jul 19 11:22:18 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 19 Jul 2004 11:22:18 +0200
Subject: [R] strucchange: breakpoints in inequally spaced data
In-Reply-To: <40F7F9AE.5080409@hhbio.wasser.tu-dresden.de>
References: <40F7F9AE.5080409@hhbio.wasser.tu-dresden.de>
Message-ID: <20040719112218.0926ff44.Achim.Zeileis@wu-wien.ac.at>

I already replied privately to Thomas about this issue; here is a brief
reply to the list, just in case anyone is interested:

> we want to identify breakpoints (different phases) in environmental 
> data, algae cell counts of three years with intervals between 7 and 30
> days (N=40). We found that
> 
> breakpoints(cells ~1)
> 
> works great and identifies 5 very good breaks, however we are
> uncertain about these, because the data are unequally spaced. Is there
> a way to include the information about the measurement intervals, e.g.
> 
> breakpoints(cells[-1] ~ diff(time))

None of the methods in strucchange require the data to be equally
spaced, so both models could lead to sensible estimates of the
breakpoints. It depends on the biological interpretation which of the
two models is to be preferred.

> Furthermore we wonder, why the OLS-CUSUM indicates several of these 
> breakpoints but does not mark them as significant.

If there are mutliple breaks in opposite directions, the OLS-CUSUM test
might be a bad choice. MOSUM or ME techniques or F statistics might be
more suitable for detecting multiple breaks.
Z

> Thanks in advance!
> 
> Thomas P.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From muteau at ensam.inra.fr  Mon Jul 19 11:25:32 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Mon, 19 Jul 2004 11:25:32 +0200
Subject: [R] problem with read.table
In-Reply-To: <1090228122.3096.10.camel@atlantic.ncc.up.pt>
References: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
	<5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
Message-ID: <5.0.2.1.2.20040719112315.02d4b898@ensam.inra.fr>

That's allright, thanks a lot.
What is the signification of quote exactly?


A 10:08 19/07/2004 +0100, Pedro Rodrigues a ??crit :
>If your file looks like attached, you should call
>
>read.table("temp.txt", header=TRUE, sep="\t", skip=3, quote="")
>
>
>
>On Mon, 2004-07-19 at 09:43, Vincent MUTEAUD wrote:
> > Thanks for your quick answer but I don't see the escape character "\n" in
> > "myFile" I see it on the result of my R command.
> >
> > This is an extract of myFile:
> >
> > # Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004
> >
> >
> > varName
> > weighting       id      date    x       y       z       calculated
> > observed
> > Date de
> > 
> d??bourrement    0.0     tree1   1998/365a       1.5     1.5     0.0     158
> >      162
> > Diam??tre du
> > tronc       0.0     tree1   0/0a    1.5     1.5     0.0
> > 0.0062422542832791805   0.007
> > Diam??tre du
> > tronc       0.0     tree1   1998/365a       1.5     1.5     0.0
> > 0.010381871834397316    0.011
> > Hauteur totale de
> > l'arbre       0.0     tree1   0/0a    1.5     1.5     0.0     1.0     0
> >
> >
> >
> > I don't know why "\n" appears in R.
> >
> >
> > A 10:40 19/07/2004 +0200, asemeria at cramont.it a ??crit :
> >
> > >You should'nt see the escape character "\n" on "myfile".
> > >Try deleting with a text editor "\n"
> > >A.S.
> > >
> > >----------------------------
> > >
> > >Alessandro Semeria
> > >Models and Simulations Laboratory
> > >Montecatini Environmental Research Center (Edison Group),
> > >Via Ciro Menotti 48,
> > >48023 Marina di Ravenna (RA), Italy
> > >Tel. +39 544 536811
> > >Fax. +39 544 538663
> > >E-mail: alessandro.semeria at cramont.it
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From prodrigues at dcc.fc.up.pt  Mon Jul 19 11:27:09 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: Mon, 19 Jul 2004 10:27:09 +0100
Subject: [R] problem with read.table
In-Reply-To: <5.0.2.1.2.20040719112315.02d4b898@ensam.inra.fr>
References: <5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
	<5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
	<5.0.2.1.2.20040719112315.02d4b898@ensam.inra.fr>
Message-ID: <1090229229.3096.18.camel@atlantic.ncc.up.pt>

The option quote states the character that encloses strings in your
file. for instance if you had a file with

"Name"	"Height"
"Tree1"	100.3

you should call read.table with quote="\"".

On Mon, 2004-07-19 at 10:25, Vincent MUTEAUD wrote:
> That's allright, thanks a lot.
> What is the signification of quote exactly?
> 
> 
> A 10:08 19/07/2004 +0100, Pedro Rodrigues a ??crit :
> >If your file looks like attached, you should call
> >
> >read.table("temp.txt", header=TRUE, sep="\t", skip=3, quote="")
> >
> >
> >
> >On Mon, 2004-07-19 at 09:43, Vincent MUTEAUD wrote:
> > > Thanks for your quick answer but I don't see the escape character "\n" in
> > > "myFile" I see it on the result of my R command.
> > >
> > > This is an extract of myFile:
> > >
> > > # Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004
> > >
> > >
> > > varName
> > > weighting       id      date    x       y       z       calculated
> > > observed
> > > Date de
> > > 
> > d??bourrement    0.0     tree1   1998/365a       1.5     1.5     0.0     158
> > >      162
> > > Diam??tre du
> > > tronc       0.0     tree1   0/0a    1.5     1.5     0.0
> > > 0.0062422542832791805   0.007
> > > Diam??tre du
> > > tronc       0.0     tree1   1998/365a       1.5     1.5     0.0
> > > 0.010381871834397316    0.011
> > > Hauteur totale de
> > > l'arbre       0.0     tree1   0/0a    1.5     1.5     0.0     1.0     0
> > >
> > >
> > >
> > > I don't know why "\n" appears in R.
> > >
> > >
> > > A 10:40 19/07/2004 +0200, asemeria at cramont.it a ??crit :
> > >
> > > >You should'nt see the escape character "\n" on "myfile".
> > > >Try deleting with a text editor "\n"
> > > >A.S.
> > > >
> > > >----------------------------
> > > >
> > > >Alessandro Semeria
> > > >Models and Simulations Laboratory
> > > >Montecatini Environmental Research Center (Edison Group),
> > > >Via Ciro Menotti 48,
> > > >48023 Marina di Ravenna (RA), Italy
> > > >Tel. +39 544 536811
> > > >Fax. +39 544 538663
> > > >E-mail: alessandro.semeria at cramont.it
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
>



From muteau at ensam.inra.fr  Mon Jul 19 11:37:41 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Mon, 19 Jul 2004 11:37:41 +0200
Subject: [R] problem with read.table
In-Reply-To: <1090229229.3096.18.camel@atlantic.ncc.up.pt>
References: <5.0.2.1.2.20040719112315.02d4b898@ensam.inra.fr>
	<5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
	<5.0.2.1.2.20040719104312.02d4b898@ensam.inra.fr>
	<5.0.2.1.2.20040719112315.02d4b898@ensam.inra.fr>
Message-ID: <5.0.2.1.2.20040719113641.02d26008@ensam.inra.fr>

Thank you for your help and the quickness of your answers.

A 10:27 19/07/2004 +0100, Pedro Rodrigues a ??crit :
>The option quote states the character that encloses strings in your
>file. for instance if you had a file with
>
>"Name"  "Height"
>"Tree1" 100.3
>
>you should call read.table with quote="\"".
>
>On Mon, 2004-07-19 at 10:25, Vincent MUTEAUD wrote:
> > That's allright, thanks a lot.
> > What is the signification of quote exactly?
> >
> >
> > A 10:08 19/07/2004 +0100, Pedro Rodrigues a ??crit :
> > >If your file looks like attached, you should call
> > >
> > >read.table("temp.txt", header=TRUE, sep="\t", skip=3, quote="")
> > >
> > >
> > >
> > >On Mon, 2004-07-19 at 09:43, Vincent MUTEAUD wrote:
> > > > Thanks for your quick answer but I don't see the escape character 
> "\n" in
> > > > "myFile" I see it on the result of my R command.
> > > >
> > > > This is an extract of myFile:
> > > >
> > > > # Capsis 4.1.3 generated file - Mon Jul 19 10:39:56 CEST 2004
> > > >
> > > >
> > > > varName
> > > > weighting       id      date    x       y       z       calculated
> > > > observed
> > > > Date de
> > > >
> > > 
> d??bourrement    0.0     tree1   1998/365a       1.5     1.5     0.0     158
> > > >      162
> > > > Diam??tre du
> > > > tronc       0.0     tree1   0/0a    1.5     1.5     0.0
> > > > 0.0062422542832791805   0.007
> > > > Diam??tre du
> > > > tronc       0.0     tree1   1998/365a       1.5     1.5     0.0
> > > > 0.010381871834397316    0.011
> > > > Hauteur totale de
> > > > l'arbre       0.0     tree1   0/0a    1.5     1.5     0.0     1.0     0
> > > >
> > > >
> > > >
> > > > I don't know why "\n" appears in R.
> > > >
> > > >
> > > > A 10:40 19/07/2004 +0200, asemeria at cramont.it a ??crit :
> > > >
> > > > >You should'nt see the escape character "\n" on "myfile".
> > > > >Try deleting with a text editor "\n"
> > > > >A.S.
> > > > >
> > > > >----------------------------
> > > > >
> > > > >Alessandro Semeria
> > > > >Models and Simulations Laboratory
> > > > >Montecatini Environmental Research Center (Edison Group),
> > > > >Via Ciro Menotti 48,
> > > > >48023 Marina di Ravenna (RA), Italy
> > > > >Tel. +39 544 536811
> > > > >Fax. +39 544 538663
> > > > >E-mail: alessandro.semeria at cramont.it
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> >



From milev at mar.ist.utl.pt  Mon Jul 19 13:35:50 2004
From: milev at mar.ist.utl.pt (milev)
Date: Mon, 19 Jul 2004 11:35:50 -0000
Subject: [R] how to keep R resident in memory?
In-Reply-To: <mailman.0.1090232898.2036.r-help@stat.math.ethz.ch>
References: <mailman.0.1090232898.2036.r-help@stat.math.ethz.ch>
Message-ID: <opsbduh0yr1ebk8d@mail.mar.ist.utl.pt>

Dear All,

I have the following problem to solve:

I've been reading on
http://www.stat.unipg.it/stat/statlib/R/CRAN/contrib/extra/dcom/ReadMe.txt
about the DCOM Active X object. But I am not very familiar with the
Windows programming, therefore I would like to ask few questions aobut
thie DCom object.

I need to access an R application/script that is already made, from
another application that I shell write. I need to export text and
graphics. I saw that with the Com you can export text easily. What about
the graphics? Can you give me simple example? I really do not have much of
experience. My main goal is to be able to keep the R and the script
resident in the memory because it load big data that takes time.

I should do the same with web interface. I managed to make a php script
that triggers the R script and returns the info, but each time the R is
starting and stoping and the necessary data is read and loaded and is very
very slow. So I need similar solution with holding R resident in the
memory also. Do you have any ideas?

Regards,

Mladen Milev



From andy_liaw at merck.com  Mon Jul 19 14:25:39 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 08:25:39 -0400
Subject: [R] R 1.9.1 compilation error (on AIX 5.1)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF807E@usrymx25.merck.com>

The following are the entries in the config.site file I used to compile
R-1.9.1 on AIX.  See if that helps.

CC=xlc
CFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"
F77=xlf
FFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -qextname -q64"
SHLIB_LDFLAGS="-Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
-Wl,-bexpall"
CXX=xlC
CXXFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"



Andy



> From: Frankie Cheung [mailto:ftcheung at hkusua.hku.hk] 
> 
> Dear Sir,
> 
> Still encounter another error message during compilation of R 1.9.1 on
> AIX 5.1 (target expall not found):
[snip]
> 
> Any suggestion?
> 
> with regards,
> Frankie Cheung



From spencer.graves at pdf.com  Mon Jul 19 14:50:15 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 19 Jul 2004 05:50:15 -0700
Subject: [R] (no subject)
In-Reply-To: <1090209800.d688989cru68y7s@myrealbox.com>
References: <1090209800.d688989cru68y7s@myrealbox.com>
Message-ID: <40FBC387.2040606@pdf.com>

      I'm not familiar with the "lm" test.  I used to work out the order 
starting from plots of the autocorrelation and partial autocorrelation 
functions, see "acf" and "pacf" in R.  Traditional estimation can be 
handled with the "arima" command. 

      Beyond this, have you seen the time series discussion on Venables 
and Ripley (2002) Modern Applied Statistics with S (Springer)?  Also, 
have you reviewed the posting guide, 
"http://www.R-project.org/posting-guide.html"?  Following the steps 
there may help you answer many of your own questions and improve the 
quality of the response you get from this list when those steps do not 
yield a satisfactory answer. 

      In particular, have you tried "www.r-project.org" -> search -> "R 
site search"?  You might find the package "dse" particularly useful, 
especially regarding state space modeling and more recent time series 
techniques. 

      hope this helps.  spencer graves
   
s viswanath wrote:

>hello R experts,
>
>my question is regarding arma modelling and specification. 
>
>in another older, statistics package , after determining stationarity, i would try to work out the number of ar and ma lags using an lm test. 
>to do this i would 
>
>1. regress my dependant variable on an intercept term then
>2. use LM test for serial correlation, and finally
>3. use the p value of the ols residuals to get the maximum lags for the arma specification.
>
>I am interested to know how to do this LM test in R say using a function, using perhaps the fseries package?
>
>Thank you in advance,
>
>Sri
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From cantini at ifc.cnr.it  Mon Jul 19 15:27:37 2004
From: cantini at ifc.cnr.it (Federico Cantini)
Date: Mon, 19 Jul 2004 15:27:37 +0200
Subject: [R] undefined symbol: modperl_perl_global_avcv_call
Message-ID: <1090243657.4066.20.camel@federico>

Hi everybody,
i'm new in this list.
i have some problem in order to use RSPerl module.
I installed the module RSPerl_0.5-7.tar.gz as described in
http://www.omegahat.org/RSPerl/ and in RFromPerl.pdf, but when i try to
run 

"perl -I /usr/lib/R/library/RSPerl/share/blib/arch -I
/usr/lib/R/library/RSPerl/share/blib/lib -I /usr/lib/R/library/RSPerl
test.pl"

from command line, i get this:

"Can't load '/usr/lib/R/library/RSPerl/share/blib/arch/auto/R/R.so' for
module R:
/usr/lib/perl5/vendor_perl/5.8.1/i386-linux-thread-multi/auto/ModPerl/Global/Global.so: undefined symbol: modperl_perl_global_avcv_call at /usr/lib/perl5/5.8.3/i386-linux-thread-multi/DynaLoader.pm line 229"

I run Fedora core 1 and R-1.9.1 compiled to be used as shared library.

Have you any suggestions?

Best regards
-- 
Federico Cantini <cantini at ifc.cnr.it>



From david_foreman at doctors.org.uk  Mon Jul 19 13:53:05 2004
From: david_foreman at doctors.org.uk (david_foreman@doctors.org.uk)
Date: Mon, 19 Jul 2004 13:53:05 (GMT)
Subject: [R] why won't rq draw lines?
Message-ID: <1090245185_12236@drn10msi01>

I've been trying to draw quantile linear regression lines across a scatterplot of my data using 

attach(forrq)
     plot(PREGNANT,DAY8,xlab="pregnant EPDS",ylab="postnatal EPDS",cex=.5)
     taus <- c(.05,.1,.25,.75,.9,.95)
     xx <- seq(min(PREGNANT),max(PREGNANT),100)
     for(tau in taus){
             f <- coef(rq(DAY8~PREGNANT,tau=tau))
             yy <- (f[1]+f[2]*xx)
             lines(xx,yy)
             }
which is simply the method from the help file with my dataset attached, and the variable names substituted where appropriate.  I get the scatterplot, but no lines.  Any ideas about what's going on? or wrong?


_______________________________________________________________________
Most doctors use http://www.Doctors.net.uk e-mail.
Move to a free professional address with spam and virus protection.



From rossini at blindglobe.net  Mon Jul 19 16:01:43 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 19 Jul 2004 07:01:43 -0700
Subject: [R] Eclipse plugin for R or perhaps S-plus.
In-Reply-To: <1090229036.21446.12.camel@gandalf.local> (Ernesto Jardim's
	message of "Mon, 19 Jul 2004 10:23:57 +0100")
References: <004201c46b73$2f47eb30$0101a8c0@KILER>
	<1090229036.21446.12.camel@gandalf.local>
Message-ID: <85r7r8m6yg.fsf@servant.blindglobe.net>

Ernesto Jardim <ernesto at ipimar.pt> writes:

> Having a R module for eclipse could be very interesting. It works with
> OOP and UML so it might be possible in the future to design S4 methods
> in R with UML ;-)

Not clear.  Yes, in principle, but not clear in practice how this work
work.  Using Java/C++/Python approaches to OOP in S don't quite map as
well as one might want.  

(I've tried in the past to map R to COGRE, the (still incomplete)
(X)Emacs UML tool, but that project will perhaps never see the light
of day).

best,
-tony

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From andy_liaw at merck.com  Mon Jul 19 16:04:55 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 10:04:55 -0400
Subject: [R] why won't rq draw lines?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8085@usrymx25.merck.com>

This works for me:

data(engel)
plot(engel$x, engel$y, xlab="household income", ylab="food expenditure",
     cex=.5)
taus <- c(.05,.1,.25,.75,.9,.95)
lapply(taus, function(tau) abline(coef(rq(y~x, data=engel, tau=tau))))

HTH,
Andy

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> david_foreman at doctors.org.uk
> Sent: Monday, July 19, 2004 9:53 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] why won't rq draw lines?
> 
> 
> I've been trying to draw quantile linear regression lines 
> across a scatterplot of my data using 
> 
> attach(forrq)
>      plot(PREGNANT,DAY8,xlab="pregnant EPDS",ylab="postnatal 
> EPDS",cex=.5)
>      taus <- c(.05,.1,.25,.75,.9,.95)
>      xx <- seq(min(PREGNANT),max(PREGNANT),100)
>      for(tau in taus){
>              f <- coef(rq(DAY8~PREGNANT,tau=tau))
>              yy <- (f[1]+f[2]*xx)
>              lines(xx,yy)
>              }
> which is simply the method from the help file with my dataset 
> attached, and the variable names substituted where 
> appropriate.  I get the scatterplot, but no lines.  Any ideas 
> about what's going on? or wrong?
> 
> 
> ______________________________________________________________
> _________
> Most doctors use http://www.Doctors.net.uk e-mail.
> Move to a free professional address with spam and virus protection.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ernesto at ipimar.pt  Mon Jul 19 16:18:14 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 19 Jul 2004 15:18:14 +0100
Subject: [R] Eclipse plugin for R or perhaps S-plus.
In-Reply-To: <85r7r8m6yg.fsf@servant.blindglobe.net>
References: <004201c46b73$2f47eb30$0101a8c0@KILER>
	<1090229036.21446.12.camel@gandalf.local>
	<85r7r8m6yg.fsf@servant.blindglobe.net>
Message-ID: <1090246693.21443.20.camel@gandalf.local>

On Mon, 2004-07-19 at 15:01, A.J. Rossini wrote:
> Ernesto Jardim <ernesto at ipimar.pt> writes:
> 
> > Having a R module for eclipse could be very interesting. It works with
> > OOP and UML so it might be possible in the future to design S4 methods
> > in R with UML ;-)
> 
> Not clear.  Yes, in principle, but not clear in practice how this work
> work.  Using Java/C++/Python approaches to OOP in S don't quite map as
> well as one might want.  
> 
> (I've tried in the past to map R to COGRE, the (still incomplete)
> (X)Emacs UML tool, but that project will perhaps never see the light
> of day).
> 
> best,
> -tony

Well,

I guess that this is not easy but it's a godd idea, now that R is moving
towards OOP, mapping with UML would be very interesting.

I'm not an expert on none of this subjects so I'm not of much help. I
simply have tried to move on to S4 and a lot of work looks like
"reenventing the wheel". Something like UML could help on this ...

Best regards

EJ



From ramasamy at cancer.org.uk  Mon Jul 19 16:22:24 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 19 Jul 2004 15:22:24 +0100
Subject: [R] why won't rq draw lines?
In-Reply-To: <1090245185_12236@drn10msi01>
References: <1090245185_12236@drn10msi01>
Message-ID: <1090246943.3027.75.camel@vpn202001.lif.icnet.uk>

The example in help(rq) works for me. 

I presume the problem is not due to attach(forrq) as you get the
scatterplot. Why don't you try printing 'xx' and 'yy' inside the loop
and see what you get.

On Mon, 2004-07-19 at 14:53, david_foreman at doctors.org.uk wrote:
> I've been trying to draw quantile linear regression lines across a scatterplot of my data using 
> 
> attach(forrq)
>      plot(PREGNANT,DAY8,xlab="pregnant EPDS",ylab="postnatal EPDS",cex=.5)
>      taus <- c(.05,.1,.25,.75,.9,.95)
>      xx <- seq(min(PREGNANT),max(PREGNANT),100)
>      for(tau in taus){
>              f <- coef(rq(DAY8~PREGNANT,tau=tau))
>              yy <- (f[1]+f[2]*xx)
>              lines(xx,yy)
>              }
> which is simply the method from the help file with my dataset attached, and the variable names substituted where appropriate.  I get the scatterplot, but no lines.  Any ideas about what's going on? or wrong?
> 
> 
> _______________________________________________________________________
> Most doctors use http://www.Doctors.net.uk e-mail.
> Move to a free professional address with spam and virus protection.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rcmcll at yahoo.com  Mon Jul 19 16:23:53 2004
From: rcmcll at yahoo.com (bob mccall)
Date: Mon, 19 Jul 2004 07:23:53 -0700 (PDT)
Subject: [R] stl,package=stats
In-Reply-To: <1090174061.3090.18.camel@atlantic>
Message-ID: <20040719142353.71211.qmail@web60004.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/b021de70/attachment.pl

From WWei at mdanderson.org  Mon Jul 19 16:30:28 2004
From: WWei at mdanderson.org (WWei@mdanderson.org)
Date: Mon, 19 Jul 2004 09:30:28 -0500
Subject: [R] rpart and TREE, can be the same?
Message-ID: <OFF61CE680.A7A28746-ON86256ED6.004E4365-86256ED6.004FAC59@mdacc.tmc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/4337c8c6/attachment.pl

From JonesW at kssg.com  Mon Jul 19 16:37:24 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Mon, 19 Jul 2004 15:37:24 +0100
Subject: [R] converting  character strings to eval
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02BD122D@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/22d84f49/attachment.pl

From rpeng at jhsph.edu  Mon Jul 19 16:46:32 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 19 Jul 2004 10:46:32 -0400
Subject: [R] converting  character strings to eval
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB02BD122D@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB02BD122D@gimli.middleearth.kssg.com>
Message-ID: <40FBDEC8.1020104@jhsph.edu>

eval(parse(text = str))

-roger

Wayne Jones wrote:
> Hi there fellow R-users, 
> 
> I'm stuck on this seemingly trivial problem.
> 
> All I want to coerce a character string into a command. 
> 
> For example: 
> 
> x<-rnorm(20)
> y<-rnorm(20)
> str<-"lm(y~x)"
> 
> I want to evaluate the "str" command. 
> 
> I have tried 
> 
> eval(as.expression(str))
> 
> But it doesn't seem to work.  I am aware of the call command, but for
> reasons I won't go into I would prefer not to use it. 
> 
> Any help would be great. 
> 
> Regards,
> Wayne
> 
> 
> 
> 
> 
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and m...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From HermanD at intra.nimh.nih.gov  Mon Jul 19 16:49:24 2004
From: HermanD at intra.nimh.nih.gov (Herman, David (NIH/NIMH))
Date: Mon, 19 Jul 2004 10:49:24 -0400
Subject: [R] hclust error
Message-ID: <5F9DE1C25708B04EAD634A1AE3D91130049DD7FE@nihexchange20.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/0f604a40/attachment.pl

From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Jul 19 16:49:25 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 19 Jul 2004 16:49:25 +0200
Subject: [R] converting  character strings to eval
References: <6B5A9304046AD411BD0200508BDFB6CB02BD122D@gimli.middleearth.kssg.com>
Message-ID: <001101c46d9f$96e03440$ad133a86@www.domain>

Hi Wayne,

what you need is,

eval(parse(text=str))

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Wayne Jones" <JonesW at kssg.com>
To: "R-help" <r-help at stat.math.ethz.ch>
Sent: Monday, July 19, 2004 4:37 PM
Subject: [R] converting character strings to eval


>
> Hi there fellow R-users,
>
> I'm stuck on this seemingly trivial problem.
>
> All I want to coerce a character string into a command.
>
> For example:
>
> x<-rnorm(20)
> y<-rnorm(20)
> str<-"lm(y~x)"
>
> I want to evaluate the "str" command.
>
> I have tried
>
> eval(as.expression(str))
>
> But it doesn't seem to work.  I am aware of the call command, but
for
> reasons I won't go into I would prefer not to use it.
>
> Any help would be great.
>
> Regards,
> Wayne
>
>
>
>
>
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester
M1 6SS  England
> Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040 Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com http://www.kssg.com
>
>
> The information in this Internet email is confidential and
m...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Mon Jul 19 16:52:35 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 19 Jul 2004 09:52:35 -0500
Subject: [R] converting  character strings to eval
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB02BD122D@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB02BD122D@gimli.middleearth.kssg.com>
Message-ID: <200407190952.35670.deepayan@stat.wisc.edu>

On Monday 19 July 2004 09:37, Wayne Jones wrote:
> Hi there fellow R-users,
>
> I'm stuck on this seemingly trivial problem.
>
> All I want to coerce a character string into a command.
>
> For example:
>
> x<-rnorm(20)
> y<-rnorm(20)
> str<-"lm(y~x)"
>
> I want to evaluate the "str" command.
>
> I have tried
>
> eval(as.expression(str))

eval(parse(text = str))

seems to work.

Deepayan



From JonesW at kssg.com  Mon Jul 19 16:54:12 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Mon, 19 Jul 2004 15:54:12 +0100
Subject: [R] converting  character strings to eval
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02BD122E@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/35934221/attachment.pl

From vito_ricci at yahoo.com  Mon Jul 19 17:02:24 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Mon, 19 Jul 2004 17:02:24 +0200 (CEST)
Subject: [R] converting character strings to eval
Message-ID: <20040719150224.49677.qmail@web41205.mail.yahoo.com>

Hi,

try with the package cluster!
Bye
Vito


Hello,
            I'm trying to do a cluster analysis on a
large data set.  I
tried it out with a smaller one first, but I got this
error:
 
> hc<-hclust(dist(x),"ave")
Error: cannot allocate vector of size 4129151 Kb
 
The data sample used (i.e. "x")  is a numerical data
set of size 32513 by 31
 
Does anyone know how I can do this analysis?  Is R
capable of this data
size?  
Ultimately I wanna do an analysis on a dataset of size
32513 by 220
 
 
Thanks!
 
dave

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From andy_liaw at merck.com  Mon Jul 19 17:14:21 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 11:14:21 -0400
Subject: [R] hclust error
Message-ID: <3A822319EB35174CA3714066D590DCD504AF808B@usrymx25.merck.com>

This has been asked on R-help several times in the past.

The `dist' object for the data of that size would be:

> 32513*32512/2
[1] 528531328

To store a vector of that size in double precision (8 bytes), you'd need:

> 32513*32512/2*8/1024^2
[1] 4032.374

I.e., that's nearly 4 GB.  Is your computer capable of doing that?

Andy

> From: Herman, David (NIH/NIMH)
> 
> Hello,
>             I'm trying to do a cluster analysis on a large 
> data set.  I
> tried it out with a smaller one first, but I got this error:
>  
> > hc<-hclust(dist(x),"ave")
> Error: cannot allocate vector of size 4129151 Kb
>  
> The data sample used (i.e. "x")  is a numerical data set of 
> size 32513 by 31
>  
> Does anyone know how I can do this analysis?  Is R capable of 
> this data
> size?  
> Ultimately I wanna do an analysis on a dataset of size 32513 by 220
>  
>  
> Thanks!
>  
> dave
>  
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From stecalza at tiscali.it  Mon Jul 19 19:18:29 2004
From: stecalza at tiscali.it (Stefano Calza)
Date: Mon, 19 Jul 2004 17:18:29 +0000
Subject: [R] hclust error
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D91130049DD7FE@nihexchange20.nih.gov>
References: <5F9DE1C25708B04EAD634A1AE3D91130049DD7FE@nihexchange20.nih.gov>
Message-ID: <20040719171829.GA8325@med.unibs.it>

Try 

hc <- hclust(t(x),"average")

HIH,
Ste

On Mon, Jul 19, 2004 at 10:49:24AM -0400, Herman, David (NIH/NIMH) wrote:
> Hello,
>             I'm trying to do a cluster analysis on a large data set.  I
> tried it out with a smaller one first, but I got this error:
>  
> > hc<-hclust(dist(x),"ave")
> Error: cannot allocate vector of size 4129151 Kb
>  
> The data sample used (i.e. "x")  is a numerical data set of size 32513 by 31
>  
> Does anyone know how I can do this analysis?  Is R capable of this data
> size?  
> Ultimately I wanna do an analysis on a dataset of size 32513 by 220
>  
>  
> Thanks!
>  
> dave
>  
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Mon Jul 19 17:56:07 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 19 Jul 2004 16:56:07 +0100
Subject: [R] hclust error
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF808B@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF808B@usrymx25.merck.com>
Message-ID: <1090252567.3027.97.camel@vpn202001.lif.icnet.uk>

Herman,

Just out of curiosity, have you tried Mike Eisen's software Cluster
(http://rana.lbl.gov/EisenSoftware.htm). Try version 2.12 instead as
version 2.20 appears to give wrong results.

I never tried with 32000 rows, but when I tried a 10000 row last year it
seem to produce the results in a few minutes whereas R took either too
long or ran out of memory. Let us know if it works.

I assume you are trying to cluster the rows/genes here in which case the
number of columns/samples will not matter in your case.

Regards, Adai.



On Mon, 2004-07-19 at 16:14, Liaw, Andy wrote:
> This has been asked on R-help several times in the past.
> 
> The `dist' object for the data of that size would be:
> 
> > 32513*32512/2
> [1] 528531328
> 
> To store a vector of that size in double precision (8 bytes), you'd need:
> 
> > 32513*32512/2*8/1024^2
> [1] 4032.374
> 
> I.e., that's nearly 4 GB.  Is your computer capable of doing that?
> 
> Andy
> 
> > From: Herman, David (NIH/NIMH)
> > 
> > Hello,
> >             I'm trying to do a cluster analysis on a large 
> > data set.  I
> > tried it out with a smaller one first, but I got this error:
> >  
> > > hc<-hclust(dist(x),"ave")
> > Error: cannot allocate vector of size 4129151 Kb
> >  
> > The data sample used (i.e. "x")  is a numerical data set of 
> > size 32513 by 31
> >  
> > Does anyone know how I can do this analysis?  Is R capable of 
> > this data
> > size?  
> > Ultimately I wanna do an analysis on a dataset of size 32513 by 220
> >  
> >  
> > Thanks!
> >  
> > dave
> >  
> >  
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From WWei at mdanderson.org  Mon Jul 19 17:58:52 2004
From: WWei at mdanderson.org (WWei@mdanderson.org)
Date: Mon, 19 Jul 2004 10:58:52 -0500
Subject: [R] rpart and TREE, can be the same?
Message-ID: <OF3A964A2B.73B595B2-ON86256ED6.0056ABE5-86256ED6.0057C443@mdacc.tmc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/3ce608c2/attachment.pl

From liao1k at cmich.edu  Mon Jul 19 18:10:30 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Mon, 19 Jul 2004 12:10:30 -0400
Subject: [R] Define location for makeinfo, tex and latex
Message-ID: <291B348BC59B47468C7824603C326082946070@cmail3.central.cmich.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/7a39cd74/attachment.pl

From f.duan at yale.edu  Mon Jul 19 19:25:33 2004
From: f.duan at yale.edu (F Duan)
Date: Mon, 19 Jul 2004 13:25:33 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
Message-ID: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/93da462f/attachment.pl

From liao1k at cmich.edu  Mon Jul 19 20:00:00 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Mon, 19 Jul 2004 14:00:00 -0400
Subject: [R] R 1.9.1 compilation error (on AIX 5.1)
Message-ID: <291B348BC59B47468C7824603C326082946076@cmail3.central.cmich.local>

Dear R Development Team,
   I have IBM AIX 5.2 and am trying to install R-1.9.1 on it. If I use
the CC=xlc as the C compiler command, I got the following error message.

configure:3641: checking for gcc
configure:3667: result: xlc
configure:3911: checking for C compiler version
configure:3914: xlc --version </dev/null >&5
./configure[3915]: xlc:  not found
configure:3917: $? = 127
configure:3919: xlc -v </dev/null >&5
./configure[3920]: xlc:  not found
configure:3922: $? = 127
configure:3924: xlc -V </dev/null >&5
./configure[3925]: xlc:  not found
configure:3927: $? = 127
configure:3950: checking for C compiler default output file name
configure:3953: xlc -O -qmaxmem=-1 -qarch=auto -qtune=auto -q64
-I/usr/local/inc
lude -L/usr/local/lib conftest.c  >&5

  It seems AIX does not have xlc, gcc is the correct choice for most of
the AIX system.

Kexiao



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
Sent: Monday, July 19, 2004 8:26 AM
To: 'Frankie Cheung'
Cc: 'Prof Brian Ripley'; R-help at stat.math.ethz.ch
Subject: RE: [R] R 1.9.1 compilation error (on AIX 5.1)

The following are the entries in the config.site file I used to compile
R-1.9.1 on AIX.  See if that helps.

CC=xlc
CFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"
F77=xlf
FFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -qextname -q64"
SHLIB_LDFLAGS="-Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
-Wl,-bexpall"
CXX=xlC
CXXFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"



Andy



> From: Frankie Cheung [mailto:ftcheung at hkusua.hku.hk] 
> 
> Dear Sir,
> 
> Still encounter another error message during compilation of R 1.9.1 on
> AIX 5.1 (target expall not found):
[snip]
> 
> Any suggestion?
> 
> with regards,
> Frankie Cheung

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at PDF.COM  Mon Jul 19 20:03:39 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Mon, 19 Jul 2004 13:03:39 -0500
Subject: [R] How to compare X1 = X2 = ... = Xn?
In-Reply-To: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
Message-ID: <40FC0CFB.8080603@pdf.com>



F Duan wrote:

> Dear All,
> 
>  
> 
> I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
> new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.
> 
>  
> 
> How to do that in a quick way instead of doing (n choose 2) comparisons? 
> 
>  
> 
> Thank you,
> 
>  
> 
> Frank
> 
> 

How about something like?

x <- data.frame(X1 = c(1, 1, 2, 4),
                 X2 = c(4, 1, 2, 5),
                 X3 = c(2, 1, 2, 2))
nuniq <- function(x) length(unique(x))
as.numeric(apply(as.matrix(x), 1, nuniq) == 1)

--sundar



From ligges at statistik.uni-dortmund.de  Mon Jul 19 20:06:16 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 19 Jul 2004 20:06:16 +0200
Subject: [R] How to compare X1 = X2 = ... = Xn?
In-Reply-To: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
Message-ID: <40FC0D98.90905@statistik.uni-dortmund.de>

F Duan wrote:

> Dear All,
> 
>  
> 
> I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
> new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.
> 

One idea is:

   apply(apply(X, 2, "==", X[,1]), 1, all)

but there may be better solutions.

Uwe Ligges


> 
> How to do that in a quick way instead of doing (n choose 2) comparisons? 
> 
>  
> 
> Thank you,
> 
>  
> 
> Frank
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Mon Jul 19 20:09:40 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 14:09:40 -0400
Subject: [R] R 1.9.1 compilation error (on AIX 5.1)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8090@usrymx25.merck.com>

xlc/xlf are IBM compilers.  I don't know if they are bundled with the OS.
GCC is free, but not necessarily found on all AIX systems (unless IBM
decided to bundle GCC with AIX, which would seem odd to me...).

Can't really help you here:  The GCC on our AIX is too outdated to try.

Andy

> From: Liao, Kexiao
> 
> Dear R Development Team,
>    I have IBM AIX 5.2 and am trying to install R-1.9.1 on it. If I use
> the CC=xlc as the C compiler command, I got the following 
> error message.
> 
> configure:3641: checking for gcc
> configure:3667: result: xlc
> configure:3911: checking for C compiler version
> configure:3914: xlc --version </dev/null >&5
> ./configure[3915]: xlc:  not found
> configure:3917: $? = 127
> configure:3919: xlc -v </dev/null >&5
> ./configure[3920]: xlc:  not found
> configure:3922: $? = 127
> configure:3924: xlc -V </dev/null >&5
> ./configure[3925]: xlc:  not found
> configure:3927: $? = 127
> configure:3950: checking for C compiler default output file name
> configure:3953: xlc -O -qmaxmem=-1 -qarch=auto -qtune=auto -q64
> -I/usr/local/inc
> lude -L/usr/local/lib conftest.c  >&5
> 
>   It seems AIX does not have xlc, gcc is the correct choice 
> for most of
> the AIX system.
> 
> Kexiao
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
> Sent: Monday, July 19, 2004 8:26 AM
> To: 'Frankie Cheung'
> Cc: 'Prof Brian Ripley'; R-help at stat.math.ethz.ch
> Subject: RE: [R] R 1.9.1 compilation error (on AIX 5.1)
> 
> The following are the entries in the config.site file I used 
> to compile
> R-1.9.1 on AIX.  See if that helps.
> 
> CC=xlc
> CFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"
> F77=xlf
> FFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -qextname -q64"
> SHLIB_LDFLAGS="-Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
> -Wl,-bexpall"
> CXX=xlC
> CXXFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"
> 
> 
> 
> Andy
> 
> 
> 
> > From: Frankie Cheung [mailto:ftcheung at hkusua.hku.hk] 
> > 
> > Dear Sir,
> > 
> > Still encounter another error message during compilation of 
> R 1.9.1 on
> > AIX 5.1 (target expall not found):
> [snip]
> > 
> > Any suggestion?
> > 
> > with regards,
> > Frankie Cheung
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Mon Jul 19 20:13:52 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 14:13:52 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8091@usrymx25.merck.com>

Here's an alternative:

> x <- data.frame(X1 = c(1, 1, 2, 4),
+                  X2 = c(4, 1, 2, 5),
+                  X3 = c(2, 1, 2, 2))
> check <- paste(names(x), collapse=" == ")
> with(x, eval(parse(text=check)))
[1] FALSE  TRUE FALSE FALSE

Cheers,
Andy


> From: Sundar Dorai-Raj
> 
> F Duan wrote:
> 
> > Dear All,
> > 
> > I have a data frame with n columns: X1, X2, ., Xn. Now I 
> want to create a
> > new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, 
> the value is 0.
> > 
> > How to do that in a quick way instead of doing (n choose 2) 
> comparisons? 
> > 
> > Thank you,
> > 
> > Frank
> 
> How about something like?
> 
> x <- data.frame(X1 = c(1, 1, 2, 4),
>                  X2 = c(4, 1, 2, 5),
>                  X3 = c(2, 1, 2, 2))
> nuniq <- function(x) length(unique(x))
> as.numeric(apply(as.matrix(x), 1, nuniq) == 1)
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From sundar.dorai-raj at PDF.COM  Mon Jul 19 20:30:49 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Mon, 19 Jul 2004 13:30:49 -0500
Subject: [R] How to compare X1 = X2 = ... = Xn?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8091@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8091@usrymx25.merck.com>
Message-ID: <40FC1359.3090702@pdf.com>


Liaw, Andy wrote:

> Here's an alternative:
> 
> 
>>x <- data.frame(X1 = c(1, 1, 2, 4),
> 
> +                  X2 = c(4, 1, 2, 5),
> +                  X3 = c(2, 1, 2, 2))
> 
>>check <- paste(names(x), collapse=" == ")
>>with(x, eval(parse(text=check)))
> 
> [1] FALSE  TRUE FALSE FALSE

Oops. Should be

 > [1] FALSE  TRUE  TRUE FALSE

This is TRUE for the second case by accident since the second element is 1.

 > x$X4 <- (x$X1 == x$X2)
 > as.numeric(x$X4)
[1] 0 1 1 0
 > x$X4 == x$X3
[1] FALSE  TRUE FALSE FALSE
 >



From gunter.berton at gene.com  Mon Jul 19 20:32:25 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 19 Jul 2004 11:32:25 -0700
Subject: [R] How to compare X1 = X2 = ... = Xn?
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
Message-ID: <40FC13B9.B8F18721@gene.com>

How about:


X<-as.matrix(yourframe)
apply(X,2, '==',X[,1])%*%rep(1,ncol(X)) == ncol(x)

avoiding the rowwise apply overhead?

Cheers,

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box
F Duan wrote:

> Dear All,
>
>
>
> I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
> new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.
>
>
>
> How to do that in a quick way instead of doing (n choose 2) comparisons?
>
>
>
> Thank you,
>
>
>
> Frank
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Mon Jul 19 20:32:44 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 19 Jul 2004 18:32:44 +0000 (UTC)
Subject: [R] How to compare X1 = X2 = ... = Xn?
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
Message-ID: <loom.20040719T202032-502@post.gmane.org>

F Duan <f.duan <at> yale.edu> writes:

> I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
> new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.

Here is one possibility if your data frame is all numeric:

   x$new <- (sd(t(x))==0)+0

x is the data frame, new is the new column, sd(t(x)) is TRUE for
rows with zero standard deviation (which occurs iff the entries
are all zero) and FALSE otherwise and +0 converts that to 1 or 0.



From andy_liaw at merck.com  Mon Jul 19 20:38:39 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 14:38:39 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8095@usrymx25.merck.com>

Stupid me: fell into this trap:

> 0 == 0 == 0
[1] FALSE

Andy

> From: Sundar Dorai-Raj
> 
> Liaw, Andy wrote:
> 
> > Here's an alternative:
> > 
> > 
> >>x <- data.frame(X1 = c(1, 1, 2, 4),
> > 
> > +                  X2 = c(4, 1, 2, 5),
> > +                  X3 = c(2, 1, 2, 2))
> > 
> >>check <- paste(names(x), collapse=" == ")
> >>with(x, eval(parse(text=check)))
> > 
> > [1] FALSE  TRUE FALSE FALSE
> 
> Oops. Should be
> 
>  > [1] FALSE  TRUE  TRUE FALSE
> 
> This is TRUE for the second case by accident since the second 
> element is 1.
> 
>  > x$X4 <- (x$X1 == x$X2)
>  > as.numeric(x$X4)
> [1] 0 1 1 0
>  > x$X4 == x$X3
> [1] FALSE  TRUE FALSE FALSE
>  >
> 
> 
> 
>



From liao1k at cmich.edu  Mon Jul 19 20:47:43 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Mon, 19 Jul 2004 14:47:43 -0400
Subject: [R] R 1.9.1 compilation error (on AIX 5.1)
Message-ID: <291B348BC59B47468C7824603C326082946077@cmail3.central.cmich.local>

Hi Andy,
   Can you give me the explanation for each parameter of FFLAGS="-O
-qmaxmem=-1 -qarch=auto -qtune=auto -qextname -q64". My xlf does not
support them. Thanks.

Kexiao


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
Sent: Monday, July 19, 2004 8:26 AM
To: 'Frankie Cheung'
Cc: 'Prof Brian Ripley'; R-help at stat.math.ethz.ch
Subject: RE: [R] R 1.9.1 compilation error (on AIX 5.1)

The following are the entries in the config.site file I used to compile
R-1.9.1 on AIX.  See if that helps.

CC=xlc
CFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"
F77=xlf
FFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -qextname -q64"
SHLIB_LDFLAGS="-Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
-Wl,-bexpall"
CXX=xlC
CXXFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"



Andy



> From: Frankie Cheung [mailto:ftcheung at hkusua.hku.hk] 
> 
> Dear Sir,
> 
> Still encounter another error message during compilation of R 1.9.1 on
> AIX 5.1 (target expall not found):
[snip]
> 
> Any suggestion?
> 
> with regards,
> Frankie Cheung

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Mon Jul 19 20:48:47 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 19 Jul 2004 18:48:47 +0000 (UTC)
Subject: [R] How to compare X1 = X2 = ... = Xn?
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
	<loom.20040719T202032-502@post.gmane.org>
Message-ID: <loom.20040719T204706-819@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: F Duan <f.duan <at> yale.edu> writes:
: 
: > I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
: > new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.
: 
: Here is one possibility if your data frame is all numeric:
: 
:    x$new <- (sd(t(x))==0)+0
: 
: x is the data frame, new is the new column, sd(t(x)) is TRUE for
: rows with zero standard deviation (which occurs iff the entries
: are all zero) and FALSE otherwise and +0 converts that to 1 or 0.
          ^^^^

"zero" should be replaced by "the same".



From andy_liaw at merck.com  Mon Jul 19 20:53:40 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 14:53:40 -0400
Subject: [R] R 1.9.1 compilation error (on AIX 5.1)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8097@usrymx25.merck.com>

> From: Liao, Kexiao [mailto:liao1k at cmich.edu] 
> 
> Hi Andy,
>    Can you give me the explanation for each parameter of FFLAGS="-O
> -qmaxmem=-1 -qarch=auto -qtune=auto -qextname -q64". My xlf does not
> support them. Thanks.

I can't.  Those are Greek to me.  I should have said that those are flags
that the AIX sysadmin used to compile R-1.8.1.  I simply copied them over to
test whether they still work in R-1.9.1.  I'm afraid you'll have to either:

1. check the compiler manual;
2. ask the sysadmin;
3. ask IBM support, or check their web site.

Andy
 
> Kexiao
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
> Sent: Monday, July 19, 2004 8:26 AM
> To: 'Frankie Cheung'
> Cc: 'Prof Brian Ripley'; R-help at stat.math.ethz.ch
> Subject: RE: [R] R 1.9.1 compilation error (on AIX 5.1)
> 
> The following are the entries in the config.site file I used 
> to compile
> R-1.9.1 on AIX.  See if that helps.
> 
> CC=xlc
> CFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"
> F77=xlf
> FFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -qextname -q64"
> SHLIB_LDFLAGS="-Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
> -Wl,-bexpall"
> CXX=xlC
> CXXFLAGS="-O -qmaxmem=-1 -qarch=auto -qtune=auto -q64"
> 
> 
> 
> Andy
> 
> 
> 
> > From: Frankie Cheung [mailto:ftcheung at hkusua.hku.hk] 
> > 
> > Dear Sir,
> > 
> > Still encounter another error message during compilation of 
> R 1.9.1 on
> > AIX 5.1 (target expall not found):
> [snip]
> > 
> > Any suggestion?
> > 
> > with regards,
> > Frankie Cheung
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From f.duan at yale.edu  Mon Jul 19 21:08:57 2004
From: f.duan at yale.edu (F Duan)
Date: Mon, 19 Jul 2004 15:08:57 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
In-Reply-To: <40FC13B9.B8F18721@gene.com>
Message-ID: <01LCNEOJ2BW0003YVG@biomed.med.yale.edu>

Thanks for all your quick answers.

That's exactly what I want.

Best, 

Frank

-----Original Message-----
From: Berton Gunter [mailto:gunter.berton at gene.com] 
Sent: Monday, July 19, 2004 14:32
To: F Duan; R-Help
Subject: Re: [R] How to compare X1 = X2 = ... = Xn?

How about:


X<-as.matrix(yourframe)
apply(X,2, '==',X[,1])%*%rep(1,ncol(X)) == ncol(x)

avoiding the rowwise apply overhead?

Cheers,

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box
F Duan wrote:

> Dear All,
>
>
>
> I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
> new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is
0.
>
>
>
> How to do that in a quick way instead of doing (n choose 2) comparisons?
>
>
>
> Thank you,
>
>
>
> Frank
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From f.duan at yale.edu  Mon Jul 19 21:27:44 2004
From: f.duan at yale.edu (F Duan)
Date: Mon, 19 Jul 2004 15:27:44 -0400
Subject: [R] An image() problem related to Affy package in BioC
Message-ID: <01LCNFBTPJT8003R7M@biomed.med.yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040719/a357f0a9/attachment.pl

From lisawang at uhnres.utoronto.ca  Mon Jul 19 21:37:07 2004
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Mon, 19 Jul 2004 15:37:07 -0400
Subject: [R] Evaluating the Yield of Medical Tests
Message-ID: <40FC22E3.E7A90C47@uhnres.utoronto.ca>

Hello,

I'm a biostatistician in Toronto. I would like to know if there is
anything in survival analysis developed in R for the method "Evaluating
the Yield of Medical Test" (JAMA. May 14,1982--Vol 247, No.18  Frank E.
Harrell, Jr,PhD; Robert M. Califf, MD; David B. Pryor, MD;Kerry L.Lee,
PhD; Robert A. Rosait,MD.)

Hope to hear from you and thanks

Lisa Wang, MSc
Project Organiser & Researcher
Cancer Informatics,
Ontario Cancer Institute/Princess Margaret Hospital, University Health
Network;
Email: lisawang at uhnres.utoronto.ca
Phone: 416 946 4501 ext. 5201
Fax: 416 946 4619



From ggrothendieck at myway.com  Mon Jul 19 21:41:03 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 19 Jul 2004 19:41:03 +0000 (UTC)
Subject: [R] How to compare X1 = X2 = ... = Xn?
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
	<40FC13B9.B8F18721@gene.com>
Message-ID: <loom.20040719T213750-702@post.gmane.org>

Berton Gunter <gunter.berton <at> gene.com> writes:

: 
: How about:
: 
: X<-as.matrix(yourframe)
: apply(X,2, '==',X[,1])%*%rep(1,ncol(X)) == ncol(x)
: 
: avoiding the rowwise apply overhead?

Following up on your idea we can use rowSums instead of matrix multiplication
to speed it up even more:

R> x <- data.frame(X1 = c(1.5, 1.5, 2.5, 4.5), 
+ X2 = c(4.5, 1.5, 2.5, 5.5), X3 = c(2.5, 1.5, 2.5, 2.5))
R> set.seed(1)
R> x1 <- x2 <- x[sample(4,100000,rep=T),]
 
R> gc();system.time({x1$new <- (rowSums(x1==x1[,1])==ncol(x))+0})
          used (Mb) gc trigger (Mb)
Ncells  634654 17.0    1590760 42.5
Vcells 1017322  7.8    3820120 29.2
[1] 0.48 0.00 0.48   NA   NA

R> gc(); system.time({X <- as.matrix(x2); x2$new <- c(apply(X,2, '==',X[,1])%*%
rep(1,ncol(X)) == ncol(x))+0})
          used (Mb) gc trigger (Mb)
Ncells  634668 17.0    1590760 42.5
Vcells 1517333 11.6    3820120 29.2
[1] 1.39 0.03 1.50   NA   NA

R> all.equal(x1,x2)
[1] TRUE



From rossini at blindglobe.net  Mon Jul 19 22:34:22 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 19 Jul 2004 13:34:22 -0700
Subject: [R] Thanks to Dirk for making the parallel R packages available on
 debian!
Message-ID: <85r7r7u46p.fsf@servant.blindglobe.net>


For those tracking debian unstable, note that thanks to Dirk E.,
installation is now mostly trivial.

(i.e. for snow, rpvm, rmpi, rsprng, and the sprng libraries).

best,
-tony

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From ramasamy at cancer.org.uk  Mon Jul 19 22:52:49 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 19 Jul 2004 21:52:49 +0100
Subject: [R] An image() problem related to Affy package in BioC
In-Reply-To: <01LCNFBTPJT8003R7M@biomed.med.yale.edu>
References: <01LCNFBTPJT8003R7M@biomed.med.yale.edu>
Message-ID: <1090270265.3064.16.camel@localhost.localdomain>

# Blue - yellow 
library(arrayMagic)
x <- matrix( rnorm(1000*100), nc=100 )
plot.imageMatrix( x )

# Red - green
library(sma)
plot.mat(x)

Looking at the codes, the author utilise rgb(). Hope this helps.

Regards, Adai.


On Mon, 2004-07-19 at 20:27, F Duan wrote:
> Dear All,
> 
>  
> 
> There is a question I met when using Affy package in Bioconductor. I asked
> it in BioC and didn't get any responses. Sorry to post again:
> 
>  
> 
> Could anyone tell me how to draw a deep-blue Affymetrix image through
> Image() function in Affy package? The default settings of image() draw me a
> black-white image and if I modify it to 256 colors, I get a somehow
> yellowish image. The reason for me to draw a deep-blue one is because I
> found most of papers display the spotted cDNA microarray image as red-green
> and the Affymetrix chip image as deep-blue.
> 
>  
> 
> Thank you very much,
> 
>  
> 
> Frank
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From thchung at tgen.org  Mon Jul 19 23:05:35 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Mon, 19 Jul 2004 14:05:35 -0700
Subject: [R] R on IBM P-Series either with AIX or Linux
Message-ID: <60F79569-D9C7-11D8-8804-000A95B43CDE@tgen.org>

Hi, all;

I have a quick question. Does R work properly on IBM P-series? Is there 
any technical catches that should be payed special attention to? 
Currently, we tried to install and run R on an IBM P-series machine 
with AIX 5.1 but we experienced some technical difficulties. In 
particular, R does not properly use all available memory and there 
seems to be some other minor difficulties.

Thanks in advance;
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From valentin.todorov at chello.at  Mon Jul 19 23:08:05 2004
From: valentin.todorov at chello.at (Valentin Todorov)
Date: Mon, 19 Jul 2004 23:08:05 +0200
Subject: [R] Eclipse plugin for R or perhaps S-plus.
Message-ID: <002c01c46dd4$7c01e5d0$0101a8c0@KILER>

There are some Eclipse plugins for UML, like Omondo UML:
http://www.omondo.com and Visual Paradigm fo UML:
http://www.visual-paradigm.com/ but neither of them is Open Source (though
both have a free light version).

By the way, there is a Latex plugin for Eclipse - ecletext at
http://sourceforge.net/projects/etex/. Some experience?

Best regards,
Valentin





On Mon, 2004-07-19 at 15:01, A.J. Rossini wrote:
> Ernesto Jardim <ernesto at ipimar.pt> writes:
>
> > Having a R module for eclipse could be very interesting. It works with
> > OOP and UML so it might be possible in the future to design S4 methods
> > in R with UML ;-)
>
> Not clear.  Yes, in principle, but not clear in practice how this work
> work.  Using Java/C++/Python approaches to OOP in S don't quite map as
> well as one might want.
>
> (I've tried in the past to map R to COGRE, the (still incomplete)
> (X)Emacs UML tool, but that project will perhaps never see the light
> of day).
>
> best,
> -tony

>Well,

>I guess that this is not easy but it's a godd idea, now that R is moving
>towards OOP, mapping with UML would be very interesting.

>I'm not an expert on none of this subjects so I'm not of much help. I
>simply have tried to move on to S4 and a lot of work looks like
>"reenventing the wheel". Something like UML could help on this ...

>Best regards

>EJ



From MSchwartz at MedAnalytics.com  Mon Jul 19 23:44:22 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 19 Jul 2004 16:44:22 -0500
Subject: [R] Evaluating the Yield of Medical Tests
In-Reply-To: <40FC22E3.E7A90C47@uhnres.utoronto.ca>
References: <40FC22E3.E7A90C47@uhnres.utoronto.ca>
Message-ID: <1090273462.3449.131.camel@localhost.localdomain>

On Mon, 2004-07-19 at 14:37, Lisa Wang wrote:
> Hello,
> 
> I'm a biostatistician in Toronto. I would like to know if there is
> anything in survival analysis developed in R for the method "Evaluating
> the Yield of Medical Test" (JAMA. May 14,1982--Vol 247, No.18  Frank E.
> Harrell, Jr,PhD; Robert M. Califf, MD; David B. Pryor, MD;Kerry L.Lee,
> PhD; Robert A. Rosait,MD.)
> 
> Hope to hear from you and thanks


I do not have access to the full text of Frank's article, however I read
the brief abstract on Medline and cross-referenced the citation of the
article with content in Frank's book (Regression Modeling Strategies -
http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/RmS). 

Thus, I am going to take a (hopefully well considered) guess that what
you are looking for will be in the combination of the Hmisc and Design
packages, which Frank has kindly made available for R. These are
available for installation from CRAN.

More information on Hmisc and Design is available at:

http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/RS

which is the link to Frank's site at Vanderbilt. Looking at the authors'
names, Frank was at Duke when the cited article was written.

I suspect that Frank will reply (RSN) with the acceptance or rejection
of my guess, however...  ;-)

HTH,

Marc Schwartz



From solares at unsl.edu.ar  Mon Jul 19 23:59:38 2004
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 19 Jul 2004 18:59:38 -0300 (ART)
Subject: [R] help with tktag.bind
Message-ID: <42782.170.210.173.216.1090274378.squirrel@inter17.unsl.edu.ar>

Hi, i newbee in R and not understand the command tktag.bind, the code below
not work find, (not change the foreground to red at move the cursos on the
lines in the tktext and the for sentence appear not work) Why is
this?Thanks


library(tcltk)
tt<-tktoplevel()
editor<-tktext(tt)
tkpack(editor)
tkinsert(editor,"1.0","first line \n")
tkinsert(editor,"2.0","Second line \n")
tkinsert(editor,"3.0","Third line \n")

cambio1<-function(t){
         tktag.configure(editor,t,foreground="red")
         }
cambio2<-function(t){
         tktag.configure(editor,t,foreground="black")
         }

tktag.add(editor,"t1","1.0","1.end")
tktag.add(editor,"t2","2.0","2.end")
tktag.add(editor,"t3","3.0","3.end")
tkbind(editor,"<ButtonPress-1>",cambio1)
tkbind(editor,"<ButtonRelease-1>",cambio2)
hello<-function() print("hello")
tktag.bind(editor,"t1","<1>",hello)
tktag.bind(editor,"t1","<Motion>",cambio1(t1))
tktag.bind(editor,"t1","<Leave>",cambio2(t1))

l<-c("t1","t2","t3")
for (t in l) 
tktag.bind(editor,t,"<Motion>",tktag.configure(editor,t,foreground="red"))
for (t in l) 
tktag.bind(editor,t,"<Leave>",tktag.configure(editor,t,foreground="black"))



From jfbrennan at rogers.com  Tue Jul 20 03:20:43 2004
From: jfbrennan at rogers.com (Jim Brennan)
Date: Mon, 19 Jul 2004 21:20:43 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu><40FC13B9.B8F18721@gene.com>
	<loom.20040719T213750-702@post.gmane.org>
Message-ID: <00ab01c46df7$c8354320$3b8ac445@slnt.phub.net.cable.rogers.com>

This similar method may  be quicker
 x1$new <- 1*(rowSums(x1)/ncol(x1)==x1[,1])
Learning lots from these type questions!

Jim
----- Original Message -----
From: "Gabor Grothendieck" <ggrothendieck at myway.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, July 19, 2004 3:41 PM
Subject: Re: [R] How to compare X1 = X2 = ... = Xn?


> Berton Gunter <gunter.berton <at> gene.com> writes:
>
> :
> : How about:
> :
> : X<-as.matrix(yourframe)
> : apply(X,2, '==',X[,1])%*%rep(1,ncol(X)) == ncol(x)
> :
> : avoiding the rowwise apply overhead?
>
> Following up on your idea we can use rowSums instead of matrix
multiplication
> to speed it up even more:
>
> R> x <- data.frame(X1 = c(1.5, 1.5, 2.5, 4.5),
> + X2 = c(4.5, 1.5, 2.5, 5.5), X3 = c(2.5, 1.5, 2.5, 2.5))
> R> set.seed(1)
> R> x1 <- x2 <- x[sample(4,100000,rep=T),]
>
> R> gc();system.time({x1$new <- (rowSums(x1==x1[,1])==ncol(x))+0})
>           used (Mb) gc trigger (Mb)
> Ncells  634654 17.0    1590760 42.5
> Vcells 1017322  7.8    3820120 29.2
> [1] 0.48 0.00 0.48   NA   NA
>
> R> gc(); system.time({X <- as.matrix(x2); x2$new <- c(apply(X,2,
'==',X[,1])%*%
> rep(1,ncol(X)) == ncol(x))+0})
>           used (Mb) gc trigger (Mb)
> Ncells  634668 17.0    1590760 42.5
> Vcells 1517333 11.6    3820120 29.2
> [1] 1.39 0.03 1.50   NA   NA
>
> R> all.equal(x1,x2)
> [1] TRUE
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Tue Jul 20 03:45:34 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jul 2004 21:45:34 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80A0@usrymx25.merck.com>

Not so fast:

> x <- matrix(rep(c(2, 1, 3), 2), nr=2, byrow=TRUE)
> x
     [,1] [,2] [,3]
[1,]    2    1    3
[2,]    2    1    3
> rowSums(x) / ncol(x) == x[,1]
[1] TRUE TRUE

Andy

> From: Jim Brennan
> 
> This similar method may  be quicker
>  x1$new <- 1*(rowSums(x1)/ncol(x1)==x1[,1])
> Learning lots from these type questions!
> 
> Jim
> 
> From: "Gabor Grothendieck"
> 
> > Berton Gunter <gunter.berton <at> gene.com> writes:
> >
> > :
> > : How about:
> > :
> > : X<-as.matrix(yourframe)
> > : apply(X,2, '==',X[,1])%*%rep(1,ncol(X)) == ncol(x)
> > :
> > : avoiding the rowwise apply overhead?
> >
> > Following up on your idea we can use rowSums instead of matrix
> multiplication
> > to speed it up even more:
> >
> > R> x <- data.frame(X1 = c(1.5, 1.5, 2.5, 4.5),
> > + X2 = c(4.5, 1.5, 2.5, 5.5), X3 = c(2.5, 1.5, 2.5, 2.5))
> > R> set.seed(1)
> > R> x1 <- x2 <- x[sample(4,100000,rep=T),]
> >
> > R> gc();system.time({x1$new <- (rowSums(x1==x1[,1])==ncol(x))+0})
> >           used (Mb) gc trigger (Mb)
> > Ncells  634654 17.0    1590760 42.5
> > Vcells 1017322  7.8    3820120 29.2
> > [1] 0.48 0.00 0.48   NA   NA
> >
> > R> gc(); system.time({X <- as.matrix(x2); x2$new <- c(apply(X,2,
> '==',X[,1])%*%
> > rep(1,ncol(X)) == ncol(x))+0})
> >           used (Mb) gc trigger (Mb)
> > Ncells  634668 17.0    1590760 42.5
> > Vcells 1517333 11.6    3820120 29.2
> > [1] 1.39 0.03 1.50   NA   NA
> >
> > R> all.equal(x1,x2)
> > [1] TRUE
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From jfbrennan at rogers.com  Tue Jul 20 03:52:55 2004
From: jfbrennan at rogers.com (Jim Brennan)
Date: Mon, 19 Jul 2004 21:52:55 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
References: <3A822319EB35174CA3714066D590DCD504AF80A0@usrymx25.merck.com>
Message-ID: <00bc01c46dfc$474f9300$3b8ac445@slnt.phub.net.cable.rogers.com>

 Yep it is faster but it is wrong! :-)  Maybe good for two columns only...
----- Original Message -----
From: "Liaw, Andy" <andy_liaw at merck.com>
To: "'Jim Brennan'" <jfbrennan at rogers.com>; <r-help at stat.math.ethz.ch>
Sent: Monday, July 19, 2004 9:45 PM
Subject: RE: [R] How to compare X1 = X2 = ... = Xn?


> Not so fast:
>
> > x <- matrix(rep(c(2, 1, 3), 2), nr=2, byrow=TRUE)
> > x
>      [,1] [,2] [,3]
> [1,]    2    1    3
> [2,]    2    1    3
> > rowSums(x) / ncol(x) == x[,1]
> [1] TRUE TRUE
>
> Andy
>
> > From: Jim Brennan
> >
> > This similar method may  be quicker
> >  x1$new <- 1*(rowSums(x1)/ncol(x1)==x1[,1])
> > Learning lots from these type questions!
> >
> > Jim
> >
> > From: "Gabor Grothendieck"
> >
> > > Berton Gunter <gunter.berton <at> gene.com> writes:
> > >
> > > :
> > > : How about:
> > > :
> > > : X<-as.matrix(yourframe)
> > > : apply(X,2, '==',X[,1])%*%rep(1,ncol(X)) == ncol(x)
> > > :
> > > : avoiding the rowwise apply overhead?
> > >
> > > Following up on your idea we can use rowSums instead of matrix
> > multiplication
> > > to speed it up even more:
> > >
> > > R> x <- data.frame(X1 = c(1.5, 1.5, 2.5, 4.5),
> > > + X2 = c(4.5, 1.5, 2.5, 5.5), X3 = c(2.5, 1.5, 2.5, 2.5))
> > > R> set.seed(1)
> > > R> x1 <- x2 <- x[sample(4,100000,rep=T),]
> > >
> > > R> gc();system.time({x1$new <- (rowSums(x1==x1[,1])==ncol(x))+0})
> > >           used (Mb) gc trigger (Mb)
> > > Ncells  634654 17.0    1590760 42.5
> > > Vcells 1017322  7.8    3820120 29.2
> > > [1] 0.48 0.00 0.48   NA   NA
> > >
> > > R> gc(); system.time({X <- as.matrix(x2); x2$new <- c(apply(X,2,
> > '==',X[,1])%*%
> > > rep(1,ncol(X)) == ncol(x))+0})
> > >           used (Mb) gc trigger (Mb)
> > > Ncells  634668 17.0    1590760 42.5
> > > Vcells 1517333 11.6    3820120 29.2
> > > [1] 1.39 0.03 1.50   NA   NA
> > >
> > > R> all.equal(x1,x2)
> > > [1] TRUE
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>
>
> --------------------------------------------------------------------------
----
> Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
Jersey, USA 08889), and/or its affiliates (which may be known outside the
United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
Banyu) that may be confidential, proprietary copyrighted and/or legally
privileged. It is intended solely for the use of the individual or entity
named on this message.  If you are not the intended recipient, and have
received this message in error, please notify us immediately by reply e-mail
and then delete it from your system.
> --------------------------------------------------------------------------
----



From kjetil at acelerate.com  Tue Jul 20 00:13:31 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Mon, 19 Jul 2004 18:13:31 -0400
Subject: [R] How to compare X1 = X2 = ... = Xn?
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
Message-ID: <40FC478B.70800@acelerate.com>

This is'nt very elegant, and you may want to replace identical ()
with a function doing more appropiate numerical floating-point
comparison:

 > midentical <-
function(...){
   dots <- list(...)
   n <- length(dots)
   ans <- TRUE
   for ( i in (1:(n-1))) {
      ans <- ans && identical(dots[i], dots[i+1])
   }
   return(ans)
}

 > x1 <- c(1,2,3,4,5)
 > x2 <- c(1,3,2,4,5)
 > x3 <- c(1,6,7,4,5)
 > mapply(function(...) ifelse(midentical(...),1,0),x1,x2,x3)
[1] 1 0 0 1 1


Kjetil Halvorsen


F Duan wrote:

>Dear All,
>
> 
>
>I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
>new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.
>
> 
>
>How to do that in a quick way instead of doing (n choose 2) comparisons? 
>
> 
>
>Thank you,
>
> 
>
>Frank
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From arin99 at rediffmail.com  Tue Jul 20 06:03:45 2004
From: arin99 at rediffmail.com (Arin Basu)
Date: 20 Jul 2004 04:03:45 -0000
Subject: [R] a problem: factors, names, tables ..
Message-ID: <20040720040345.8280.qmail@webmail25.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040720/213b233c/attachment.pl

From r.darnell at uq.edu.au  Tue Jul 20 07:23:16 2004
From: r.darnell at uq.edu.au (Ross Darnell)
Date: 20 Jul 2004 15:23:16 +1000
Subject: [R] Histogram without common borders
Message-ID: <bribl0aj.fsf@uq.edu.au>

Is it possible to produce a histogram directly using the hist()
function with the common borders removed?

It can be done by plotting the histogram object using type 's'teps.

my.hist <- hist(x,plot=FALSE)
plot(my.hist$breaks,c(0,my.hist$counts),type='s')

I would appreciate help

Ross Darnell 
-- 
University of Queensland, Brisbane QLD 4067 AUSTRALIA
Email: <r.darnell at uq.edu.au>
Phone: +61 7 3365 6087     Fax: +61 7 3365 4754
http://www.shrs.uq.edu.au/shrs/school_staff/ross_darnell.html



From thpe at hhbio.wasser.tu-dresden.de  Tue Jul 20 07:52:06 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 20 Jul 2004 07:52:06 +0200
Subject: [R] Histogram without common borders
In-Reply-To: <bribl0aj.fsf@uq.edu.au>
References: <bribl0aj.fsf@uq.edu.au>
Message-ID: <40FCB306.7040901@hhbio.wasser.tu-dresden.de>

Ross Darnell wrote:
> Is it possible to produce a histogram directly using the hist()
> function with the common borders removed?
> 
> It can be done by plotting the histogram object using type 's'teps.
> 
> my.hist <- hist(x,plot=FALSE)
> plot(my.hist$breaks,c(0,my.hist$counts),type='s')

Hello Ross,

I think, your approach is not too bad, however you should use "S" 
instead of "s", see:

my.hist <- hist(x, lty=1)
lines(my.hist$breaks,c(0, my.hist$counts),
       type='S', lty="dotted", col="red")

avoiding unwanted vertical lines with:

my.hist <- hist(x, lty=0)
lines(c(my.hist$breaks, max(my.hist$breaks)),
       c(0,my.hist$counts,0), type='S')

OR simply use filled bars:

hist(x, col="grey", lty=0)

Hope it helps

Thomas P.



From rksh at soc.soton.ac.uk  Tue Jul 20 10:12:54 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 20 Jul 2004 09:12:54 +0100
Subject: [R] How to compare X1 = X2 = ... = Xn?
In-Reply-To: <40FC13B9.B8F18721@gene.com>
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
	<40FC13B9.B8F18721@gene.com>
Message-ID: <a0600200cbd2283c25e6d@[139.166.242.29]>


just one more that seems natural but hasn't been mentioned:

library(magic)
x <- data.frame(a=c(1,2,1,2,1),b=c(1,2,2,1,2),c=c(1,2,1,2,1))
apply(x,1,minmax)

     1     2     3     4     5
  TRUE  TRUE FALSE FALSE FALSE
>

[
here
  minmax <-
function (x)
{
     max(x) == min(x)
}

]


rksh


>How about:
>
>
>X<-as.matrix(yourframe)
>apply(X,2, '==',X[,1])%*%rep(1,ncol(X)) == ncol(x)
>
>avoiding the rowwise apply overhead?
>
>Cheers,
>
>Bert Gunter
>
>Non-Clinical Biostatistics
>Genentech
>MS: 240B
>Phone: 650-467-7374
>
>
>"The business of the statistician is to catalyze the scientific learning
>process."
>
>  -- George E.P. Box
>F Duan wrote:
>
>>  Dear All,
>>
>>
>>
>>  I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
>>  new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.
>>
>>
>>
>>  How to do that in a quick way instead of doing (n choose 2) comparisons?
>>
>>
>>
>>  Thank you,
>>
>>
>>
>  > Frank
>

-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From Luisr at frs.fo  Tue Jul 20 10:51:33 2004
From: Luisr at frs.fo (Luis Rideau Cruz)
Date: Tue, 20 Jul 2004 09:51:33 +0100
Subject: [R] Sort a data frame
Message-ID: <s0fceb37.030@ffdata.setur.fo>

Hi all 

I have the next data frame 

    year   STOD    SLAGNR  TAL TALT   TALVEKT
1 2002  2120006     57      1      NA      1
2 1997  97030032    57     NA   NA      NA
3 1997  97030071    27     1      NA      NA
4 1997  97030005    57     1      NA      NA
5 1997  97020127    60     NA   1         NA
6 2001  1160025     27      1      NA      1
7 1998  98020069    60     1      NA      NA
8 1996  96030009    57     NA   1         NA

How to sort it according to "year" column
Sort does seem to work only on vectors

Thank you

Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo
Web:                www.frs.fo



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Jul 20 10:56:23 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 20 Jul 2004 10:56:23 +0200
Subject: [R] Sort a data frame
References: <s0fceb37.030@ffdata.setur.fo>
Message-ID: <009901c46e37$6fbe5de0$ad133a86@www.domain>

Hi Luis,

you could try something like,

data[order(data$year),]

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Luis Rideau Cruz" <Luisr at frs.fo>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, July 20, 2004 10:51 AM
Subject: [R] Sort a data frame


> Hi all
>
> I have the next data frame
>
>     year   STOD    SLAGNR  TAL TALT   TALVEKT
> 1 2002  2120006     57      1      NA      1
> 2 1997  97030032    57     NA   NA      NA
> 3 1997  97030071    27     1      NA      NA
> 4 1997  97030005    57     1      NA      NA
> 5 1997  97020127    60     NA   1         NA
> 6 2001  1160025     27      1      NA      1
> 7 1998  98020069    60     1      NA      NA
> 8 1996  96030009    57     NA   1         NA
>
> How to sort it according to "year" column
> Sort does seem to work only on vectors
>
> Thank you
>
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Tue Jul 20 11:01:22 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 20 Jul 2004 11:01:22 +0200
Subject: [R] Sort a data frame
In-Reply-To: <s0fceb37.030@ffdata.setur.fo>
References: <s0fceb37.030@ffdata.setur.fo>
Message-ID: <200407201101220892.48B70C16@mail.math.fu-berlin.de>

Hi

Lets assign your data frame to the variable yourdf
then:

yourdf[ , order( yourdf$year ) ]

should sort it.

For decreasing increasing sorting
see 
?order

Sincerely Eryk.



*********** REPLY SEPARATOR  ***********

On 20.07.2004 at 09:51 Luis Rideau Cruz wrote:

>Hi all 
>
>I have the next data frame 
>
>    year   STOD    SLAGNR  TAL TALT   TALVEKT
>1 2002  2120006     57      1      NA      1
>2 1997  97030032    57     NA   NA      NA
>3 1997  97030071    27     1      NA      NA
>4 1997  97030005    57     1      NA      NA
>5 1997  97020127    60     NA   1         NA
>6 2001  1160025     27      1      NA      1
>7 1998  98020069    60     1      NA      NA
>8 1996  96030009    57     NA   1         NA
>
>How to sort it according to "year" column
>Sort does seem to work only on vectors
>
>Thank you
>
>Luis Ridao Cruz
>Fiskiranns??knarstovan
>N??at??n 1
>P.O. Box 3051
>FR-110 T??rshavn
>Faroe Islands
>Phone:             +298 353900
>Phone(direct): +298 353912
>Mobile:             +298 580800
>Fax:                 +298 353901
>E-mail:              luisr at frs.fo
>Web:                www.frs.fo
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From vito_ricci at yahoo.com  Tue Jul 20 11:02:31 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Tue, 20 Jul 2004 11:02:31 +0200 (CEST)
Subject: [R] Sort a data frame
Message-ID: <20040720090231.94042.qmail@web41201.mail.yahoo.com>

Try to convert the dataframe in a matrix:

z<-as.matrix(yourdataframe)
sort(z)

It would run!
Ciao
Vito






Hi all 

I have the next data frame 

    year   STOD    SLAGNR  TAL TALT   TALVEKT
1 2002  2120006     57      1      NA      1
2 1997  97030032    57     NA   NA      NA
3 1997  97030071    27     1      NA      NA
4 1997  97030005    57     1      NA      NA
5 1997  97020127    60     NA   1         NA
6 2001  1160025     27      1      NA      1
7 1998  98020069    60     1      NA      NA
8 1996  96030009    57     NA   1         NA

How to sort it according to "year" column
Sort does seem to work only on vectors

Thank you

Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo
Web:                www.frs.fo

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From B.Rowlingson at lancaster.ac.uk  Tue Jul 20 11:08:21 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 20 Jul 2004 10:08:21 +0100
Subject: [R] Multiple comparisons: its a trap!
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8095@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8095@usrymx25.merck.com>
Message-ID: <40FCE105.1060702@lancaster.ac.uk>

Liaw, Andy wrote:
> Stupid me: fell into this trap:
> 
> 
>>0 == 0 == 0
> 
> [1] FALSE
> 

  Ouch!

  Python's comparison operators don't have this trap, since they unravel 
each comparison pair in a chain so that:

   (A op1 B op2 C)

becomes:

   (A op1 B) and (B op2 C)


If you want:

  (A op1 B) op2 C

you have to put the parens in, and that makes you remember there's some 
Boolean arithmetic going on in there.

This is a nice feature, since we all are used to reading expressions 
like 2 < X < 10, and you can write them like that in Python, and they 
mean what they look like.

You can write like that in R, but beware, its not just 0 == 0 == 0 that 
opens the trap:

  > X = 5
  > 10 < X < 0
  [1] FALSE
  > 0 > X > 10
  [1] TRUE

  Of course old hand Fortran programmers understand all this since the 
second thing they learnt (after learning how to tap the space bar six 
times) was the order of precedence of operators...

Baz

PS oh, and in Perl (0 == 0 == 0) is a syntax error!



From gerhard.krennrich at basf-ag.de  Tue Jul 20 11:23:25 2004
From: gerhard.krennrich at basf-ag.de (gerhard.krennrich@basf-ag.de)
Date: Tue, 20 Jul 2004 11:23:25 +0200
Subject: [R] Performance problem
Message-ID: <OF79E18D67.A9A4078E-ONC1256ED7.0032096F@rz-c007-j650.basf-ag.de>

Dear all,
I have a performance problem in terms of computing time.
I estimate mixed models on a fairly large number of subgroups (10000) using
lme(.) within the by(.) function and it takes hours to do the calculation
on a fast notebook under Windows.
I suspect by(.) to be a poor implementation for doing individual analysis
on subgroups.
Is there an alternative and more efficient way for doing by-group
processing within lme(.).

Here some code to give you a glimpse
gfit <- by(longdata, gen, function(x) lme(fixed=response ~ dye + C(treat,
base = 4 ),
            data=x,random =~ 1 | slide)  )

Thanks in advance & regards
Gerhard Krennrich


------------------------------------------------------------------------
BASF Aktiengesellschaft
GVC/S - B009
Gerhard Krennrich
Tel.: +49 621 60-78299



From david_foreman at doctors.org.uk  Tue Jul 20 09:30:40 2004
From: david_foreman at doctors.org.uk (david_foreman@doctors.org.uk)
Date: Tue, 20 Jul 2004 09:30:40 (GMT)
Subject: [R] why won't rq draw lines?
Message-ID: <1090315841_18752@drn10msi01>

Thanks, this works for me as well, though the lines extend beyond the Y axes (sometimes).  I'm very grateful.  

---------- Original Message ----------------------------------
From: "Liaw, Andy" <andy_liaw at merck.com>
Date:  Mon, 19 Jul 2004 10:04:55 -0400

>This works for me:
>
>data(engel)
>plot(engel$x, engel$y, xlab="household income", ylab="food expenditure",
>     cex=.5)
>taus <- c(.05,.1,.25,.75,.9,.95)
>lapply(taus, function(tau) abline(coef(rq(y~x, data=engel, tau=tau))))
>
>HTH,
>Andy
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
>> david_foreman at doctors.org.uk
>> Sent: Monday, July 19, 2004 9:53 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] why won't rq draw lines?
>>
>>
>> I've been trying to draw quantile linear regression lines
>> across a scatterplot of my data using
>>
>> attach(forrq)
>>      plot(PREGNANT,DAY8,xlab="pregnant EPDS",ylab="postnatal
>> EPDS",cex=.5)
>>      taus <- c(.05,.1,.25,.75,.9,.95)
>>      xx <- seq(min(PREGNANT),max(PREGNANT),100)
>>      for(tau in taus){
>>              f <- coef(rq(DAY8~PREGNANT,tau=tau))
>>              yy <- (f[1]+f[2]*xx)
>>              lines(xx,yy)
>>              }
>> which is simply the method from the help file with my dataset
>> attached, and the variable names substituted where
>> appropriate.  I get the scatterplot, but no lines.  Any ideas
>> about what's going on? or wrong?
>>
>>
>> ______________________________________________________________
>> _________
>> Most doctors use http://www.Doctors.net.uk e-mail.
>> Move to a free professional address with spam and virus protection.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
>------------------------------------------------------------------------------
>
>________________________________________________________________________
>Doctors.net.uk e-mail protects you from viruses and unsolicited messages
>________________________________________________________________________
>


_______________________________________________________________________
Most doctors use http://www.Doctors.net.uk e-mail.
Move to a free professional address with spam and virus protection.



From christoph.lehmann at gmx.ch  Tue Jul 20 11:31:04 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 20 Jul 2004 11:31:04 +0200
Subject: [R] vectorizing a matrix computation
Message-ID: <40FCE658.50708@gmx.ch>

Dear R users

I have a 4-dimensional matrix (actually several 3d (x,y, slices) 
matrices appended over time (volumes))

say, e.g. I want to z-transform the data (subtract the mean and divide 
by the std-deviation)

for (slice in 1:slices) {
     for (x in 1:x.dim) {
         for (y in 1:y.dim) {
         t <- as.matrix(my.matrix[x,y,slice,1:volumes])
         for (vol in 1:volumes) {
             my.matrix.transformed[x,y,slice,vol] <- 
(my.matrix[x,y,slice,vol] - mean(t))/sqrt(var(t))
             }
         }
     }
}

how can I vectorize such a function using, one of the *apply functions?

many thanks

Cheers

Christoph



From bitwrit at ozemail.com.au  Tue Jul 20 11:49:27 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Tue, 20 Jul 2004 19:49:27 +1000
Subject: [R] How to compare X1 = X2 = ... = Xn?
In-Reply-To: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
References: <01LCNB2BL8YA003ZIX@biomed.med.yale.edu>
Message-ID: <20040720094255.BFQW9810.smta04.mail.ozemail.net@there>

F Duan wrote:
> Dear All,
>
>
>
> I have a data frame with n columns: X1, X2, ., Xn. Now I want to create a
> new column: if X1 = X2 = . = Xn, the value is 1; Otherwise, the value is 0.
>
>
>
> How to do that in a quick way instead of doing (n choose 2) comparisons?
>
Assuming that the Xs are numeric, and your data frame is named data.df:

data.df$newcol<-
as.numeric(apply(as.matrix(my.df),1,function(x) return(length(unique(x))==1)))

Jim



From gvg at vwl.wi.tu-muenchen.de  Tue Jul 20 11:54:18 2004
From: gvg at vwl.wi.tu-muenchen.de (Georg von Graevenitz)
Date: Tue, 20 Jul 2004 11:54:18 +0200
Subject: [R] Installing rgl on linux
Message-ID: <1090317258.8805.16.camel@pear.local>

Hi,

I'm new to R. I installed several packages in R (R-1.9.1) without
problems. I am trying to set R up to use Rcmdr, all I need now is rgl -
unfortunately I can't get it to install. There is a previous message
regarding this issue from June but even with information in those
answers I get stuck. 

I have attempted to install rgl form within R and from a shell using the
tarball (rgl_0.64-13.tar.gz). I attach the output for both attempts
below.

I`m running SuSE`s Linux (9.1) and have installed R from an rpm on CRAN
(Version 1.9.0 Patched (2004-05-05), ISBN 3-900051-00-3). 

It seems to make little difference which rpm I use (there is a 1.9.1 rpm
too).

I'd appreciate help as I would like to use R with a large group of
undergrads and they would really benefit from Rcmdr.

Thanks Georg

OUTPUT: 

-> FROM SHELL

pear:~/Dlds # R CMD INSTALL 
--configure-args="--x-includes=/usr/X11R6/include,
--x-libraries=/usr/X11R6/lib, --with-gl-includes=/usr/include/GL,
--with-gl-libraries=/usr/lib/GL --with-libpng=/usr/lib"  rgl
* Installing *source* package 'rgl' ...
checking build system type... i686-pc-linux-gnu
checking host system type... i686-pc-linux-gnu
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for X... libraries /usr/X11R6/lib,, headers /usr/X11R6/include,

checking for libpng-config... no
checking libpng in /usr/local... not found
checking libpng in /usr... not found
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -I/usr/lib/R/include -I/usr/X11R6/include, -I/usr/include/GL,
-I/usr/local/include -I/opt/gnome/include -mieee-fp -Wall -pedantic
-fno-exceptions -fno-rtti -fPIC  -g -O2 -c x11lib.cpp -o x11lib.o
In file included from glgui.h:9,
                 from gui.h:10,
                 from x11gui.h:10,
                 from x11lib.cpp:13:
opengl.h:19:19: GL/gl.h: No such file or directory
opengl.h:20:20: GL/glu.h: No such file or directory
In file included from gui.h:10,
                 from x11gui.h:10,
                 from x11lib.cpp:13:
glgui.h:27: error: 'GLuint' is used as a type, but is not defined as a
type.
glgui.h:28: error: 'GLuint' is used as a type, but is not defined as a
type.
glgui.h:29: error: 'GLuint' is used as a type, but is not defined as a
type.
glgui.h: In member function `void GLBitmapFont::enable()':
glgui.h:22: error: `listBase' undeclared (first use this function)
glgui.h:22: error: (Each undeclared identifier is reported only once for
each
   function it appears in.)
glgui.h:22: error: `glListBase' undeclared (first use this function)
In file included from x11lib.cpp:13:
x11gui.h:12:22: X11/Xlib.h: No such file or directory
x11gui.h:13:20: GL/glx.h: No such file or directory
In file included from x11lib.cpp:13:
x11gui.h: At global scope:
x11gui.h:35: error: `::Window' undeclared (first use here)
x11gui.h:35: error: syntax error before `)' token
x11gui.h:44: error: syntax error before `*' token
x11gui.h:45: error: syntax error before `*' token
x11gui.h:47: error: syntax error before `[' token
x11gui.h:52: error: 'GLXContext' is used as a type, but is not defined
as a
   type.
x11gui.h:56: error: syntax error before `;' token
x11gui.h:66: error: `XID' was not declared in this scope
x11gui.h:66: error: `X11WindowImpl' was not declared in this scope
x11gui.h:66: error: syntax error before `>' token
x11gui.h:68: error: 'WindowMap' is used as a type, but is not defined as
a
   type.
x11gui.h: In member function `bool gui::X11GUIFactory::isConnected()':
x11gui.h:32: error: `xdisplay' undeclared (first use this function)
x11gui.h: In member function `int gui::X11GUIFactory::getFD()':
x11gui.h:33: error: `xdisplay' undeclared (first use this function)
x11gui.h:33: error: `ConnectionNumber' undeclared (first use this
function)
make: *** [x11lib.o] Error 1
ERROR: compilation failed for package 'rgl'
** Removing '/usr/lib/R/library/rgl'


-> FROM INSIDE R:


> install.packages("rlg")
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 180100 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .....
downloaded 175Kb

Warning message:
No package "rlg" on CRAN. in: download.packages(pkgs, destdir = tmpd,
available = available,
> install.packages("rgl")
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 180100 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .....
downloaded 175Kb

trying URL `http://cran.r-project.org/src/contrib/rgl_0.64-13.tar.gz'
Content type `application/x-tar' length 472493 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .
downloaded 461Kb

* Installing *source* package 'rgl' ...
checking build system type... i686-pc-linux-gnu
checking host system type... i686-pc-linux-gnu
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for X... no
configure: error: X11 not found, configure aborted.
reason: RGL requires X11 on non-win32 platforms.
ERROR: configuration failed for package 'rgl'
** Removing '/usr/lib/R/library/rgl'

Delete downloaded files (y/N)? y

Warning message:
Installation of package rgl had non-zero exit status in:
install.packages("rgl")



Thanks, 
Georg



From wolski at molgen.mpg.de  Tue Jul 20 11:54:54 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 20 Jul 2004 11:54:54 +0200
Subject: [R] vectorizing a matrix computation
In-Reply-To: <40FCE658.50708@gmx.ch>
References: <40FCE658.50708@gmx.ch>
Message-ID: <200407201154540564.0595F3F0@mail.math.fu-berlin.de>

Hallo Christoph!

Using apply and sweep.
Both of them accept  as the second argument (MARGIN) a vector which specifies the dimension.

?apply
?sweep.

To specify the subscripts accurately I always need some trials, and to run tests, so I cant you provide with the final solution.

Hope it helps anyway.

Sincerely Eryk.



*********** REPLY SEPARATOR  ***********

On 7/20/2004 at 11:31 AM Christoph Lehmann wrote:

>>>Dear R users
>>>
>>>I have a 4-dimensional matrix (actually several 3d (x,y, slices) 
>>>matrices appended over time (volumes))
>>>
>>>say, e.g. I want to z-transform the data (subtract the mean and divide 
>>>by the std-deviation)
>>>
>>>for (slice in 1:slices) {
>>>     for (x in 1:x.dim) {
>>>         for (y in 1:y.dim) {
>>>         t <- as.matrix(my.matrix[x,y,slice,1:volumes])
>>>         for (vol in 1:volumes) {
>>>             my.matrix.transformed[x,y,slice,vol] <- 
>>>(my.matrix[x,y,slice,vol] - mean(t))/sqrt(var(t))
>>>             }
>>>         }
>>>     }
>>>}
>>>
>>>how can I vectorize such a function using, one of the *apply functions?
>>>
>>>many thanks
>>>
>>>Cheers
>>>
>>>Christoph
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From stephan.moratti at uni-konstanz.de  Tue Jul 20 13:03:04 2004
From: stephan.moratti at uni-konstanz.de (Stephan Moratti)
Date: Tue, 20 Jul 2004 13:03:04 +0200
Subject: [R] Performance problem
In-Reply-To: <200407201006.i6KA6Vo4011174@hypatia.math.ethz.ch>
Message-ID: <3.0.5.32.20040720130304.00acf2c0@popserver.uni-konstanz.de>


>From: gerhard.krennrich at basf-ag.de
>Precedence: list
>MIME-Version: 1.0
>To: r-help at stat.math.ethz.ch
>Date: Tue, 20 Jul 2004 11:23:25 +0200
>Message-ID: <OF79E18D67.A9A4078E-ONC1256ED7.0032096F at rz-c007-j650.basf-ag.de>
>Content-Type: text/plain; charset=us-ascii
>Subject: [R] Performance problem
>Message: 60
>
>Dear all,
>I have a performance problem in terms of computing time.
>I estimate mixed models on a fairly large number of subgroups (10000) using
>lme(.) within the by(.) function and it takes hours to do the calculation
>on a fast notebook under Windows.
>I suspect by(.) to be a poor implementation for doing individual analysis
>on subgroups.
>Is there an alternative and more efficient way for doing by-group
>processing within lme(.).
>
>Here some code to give you a glimpse
>gfit <- by(longdata, gen, function(x) lme(fixed=response ~ dye + C(treat,
>base = 4 ),
>            data=x,random =~ 1 | slide)  )
>
>Thanks in advance & regards
>Gerhard Krennrich
>

Sorry, that I can't contribute to a solution. But I have a similar problem,
doing lme's on 350 source estimations of MEG brain data. So if somebody
knows some improvement, please let me know !

Stephan Moratti



-----------------------------
Dipl. Psych. Stephan Moratti
Dept. of Psychology
University of Konstanz
P.O Box D25
Phone: +40 (0)7531 882385
Fax: +49 (0)7531 884601
D-78457 Konstanz, Germany

e-mail: Stephan.Moratti at uni-konstanz.de
http://www.clinical-psychology.uni-konstanz.de/



From ernesto at ipimar.pt  Tue Jul 20 13:17:50 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 20 Jul 2004 12:17:50 +0100
Subject: [R] vectorizing a matrix computation
In-Reply-To: <200407201154540564.0595F3F0@mail.math.fu-berlin.de>
References: <40FCE658.50708@gmx.ch>
	<200407201154540564.0595F3F0@mail.math.fu-berlin.de>
Message-ID: <1090322270.25668.76.camel@gandalf.local>

On Tue, 2004-07-20 at 10:54, Wolski wrote:
> Hallo Christoph!
> 
> Using apply and sweep.
> Both of them accept  as the second argument (MARGIN) a vector which specifies the dimension.
> 
> ?apply
> ?sweep.
> 
> To specify the subscripts accurately I always need some trials, and to run tests, so I cant you provide with the final solution.
> 
> Hope it helps anyway.
> 
> Sincerely Eryk.
> 
> 
> 
> *********** REPLY SEPARATOR  ***********
> 
> On 7/20/2004 at 11:31 AM Christoph Lehmann wrote:
> 
> >>>Dear R users
> >>>
> >>>I have a 4-dimensional matrix (actually several 3d (x,y, slices) 
> >>>matrices appended over time (volumes))
> >>>
> >>>say, e.g. I want to z-transform the data (subtract the mean and divide 
> >>>by the std-deviation)
> >>>
> >>>for (slice in 1:slices) {
> >>>     for (x in 1:x.dim) {
> >>>         for (y in 1:y.dim) {
> >>>         t <- as.matrix(my.matrix[x,y,slice,1:volumes])
> >>>         for (vol in 1:volumes) {
> >>>             my.matrix.transformed[x,y,slice,vol] <- 
> >>>(my.matrix[x,y,slice,vol] - mean(t))/sqrt(var(t))
> >>>             }
> >>>         }
> >>>     }
> >>>}
> >>>
> >>>how can I vectorize such a function using, one of the *apply functions?
> >>>
> >>>many thanks
> >>>
> >>>Cheers
> >>>
> >>>Christoph
> >>>

Hi,


You may try to use the "continuous indexing". Notice that if you have a
matrix with dim=c(3,3,2,2)

matriz<-array(rnorm(36, 2,2),dim=c(3,3,2,2))

matriz[1:3] calls matriz[,1,1,1]
matriz[4:6] calls matriz[,2,1,1]
matriz[10:12] calls matriz[,1,2,1] 

etc

I think you can use that to perform the calculations you want althought
I'm not sure you're vectorizing 

vec <- 1:36
fac <- rep(1:12, rep(3,12))
lapply(split(vec, fac), FUN=function(x){(x-mean(x))/sd(x)})

or simply

tapply(c(matriz),fac,FUN=function(x){(x-mean(x))/sd(x)})

Hope it helps

Best regards

EJ



From john_hendrickx at yahoo.com  Tue Jul 20 13:19:17 2004
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Tue, 20 Jul 2004 04:19:17 -0700 (PDT)
Subject: [R] converting  character strings to eval
In-Reply-To: <200407190952.35670.deepayan@stat.wisc.edu>
Message-ID: <20040720111917.44015.qmail@web52707.mail.yahoo.com>

--- Deepayan Sarkar <deepayan at stat.wisc.edu> wrote:
> On Monday 19 July 2004 09:37, Wayne Jones wrote:
> > Hi there fellow R-users,
> >
> > I'm stuck on this seemingly trivial problem.
> >
> > All I want to coerce a character string into a command.
> >
> > For example:
> >
> > x<-rnorm(20)
> > y<-rnorm(20)
> > str<-"lm(y~x)"
> >
> > I want to evaluate the "str" command.
> >
> > I have tried
> >
> > eval(as.expression(str))
> 
> eval(parse(text = str))
> 
> seems to work.
> 
Couldn't eval be modified to automatically parse arguments if they're
not expressions? Something like:
eval2<-function(arg) {
	if (!is.expression(arg)) arg<-parse(text=arg)
	eval(arg)
}
Would a construction like eval2 have a downside or cause problems
down the line?



From nkdas at veccal.ernet.in  Tue Jul 20 13:32:19 2004
From: nkdas at veccal.ernet.in (nkdas@veccal.ernet.in)
Date: Tue, 20 Jul 2004 16:32:19 +0500
Subject: [R] Statistical package
Message-ID: <bf9fb1b9.b1b9bf9f@veccal.ernet.in>


 Dear Martin Maechler,

     I came accross your valuable contribution in the domain of statistical computing
 through Web site. I can't but appreciate your great endeavour. 
     I would be grateful to you if you could kindly suggest me or help me  to utilize
 the free statistical pckage like R  with Mannual.  I am esepcially interested in Time
 Series Analysis and plotting of experimental data. It transpires that you have a good 
 number of  excellent package for the same. To name a few - Lag, Lag plot, embed,  
 spectrum, spec, plot spec, spec.pgram, acf, plot acf, ccf, acf2AR etc. would be very  
 useful for my work. 

 Looking forward to hear you soon.

 With best regards.


                                   Nisith  Das
                            Helium Laboratory
                      variable Energy Cyclotron Centre
                      1/AF, Bidhan Nagar ; Kolkata- 700 064
                                   India ; 
                  Phone : +91-33- 2334 1523 (R); +91-33 - 2321 4983 (Office)
                   FAX : +91-33-2337 46 37



From Luisr at frs.fo  Tue Jul 20 14:03:39 2004
From: Luisr at frs.fo (Luis Rideau Cruz)
Date: Tue, 20 Jul 2004 13:03:39 +0100
Subject: [R] Problem with plot
Message-ID: <s0fd1833.051@ffdata.setur.fo>

Hi all 
 
I'm trying to plot  2 columns of a frame but whatever option I choose for argument "type" I always get bars with height equal to 1.

I quit and restart but problem remais

Help! 

Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo
Web:                www.frs.fo



From rado.bonk at jrc.it  Tue Jul 20 14:25:05 2004
From: rado.bonk at jrc.it (Rado Bonk)
Date: Tue, 20 Jul 2004 14:25:05 +0200
Subject: [R] print variables values within c(" ") 
Message-ID: <40FD0F21.1040008@jrc.it>

Dear R-users;

I would like to print some variable values within the text in " ".

Ex: q1 <- c("select" names(dataframe1) "from my table")
                       ^^^^^^^^^^^^^^^^^
How to use R objects names within the quotes?

Also, is there package which can put some longer text on multipage 
graphics? such as some table, or simple data summary. text() is too 
complicated for longer texts with breaklines.

Thanks,


Rado Bonk



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Jul 20 14:30:18 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 20 Jul 2004 14:30:18 +0200
Subject: [R] print variables values within c(" ") 
References: <40FD0F21.1040008@jrc.it>
Message-ID: <001901c46e55$51f47fb0$ad133a86@www.domain>

Hi Rado,

dou want something like,

paste("select", names(dataframe1), "from my table")

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Rado Bonk" <rado.bonk at jrc.it>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, July 20, 2004 2:25 PM
Subject: [R] print variables values within c(" ")


> Dear R-users;
>
> I would like to print some variable values within the text in " ".
>
> Ex: q1 <- c("select" names(dataframe1) "from my table")
>                        ^^^^^^^^^^^^^^^^^
> How to use R objects names within the quotes?
>
> Also, is there package which can put some longer text on multipage
> graphics? such as some table, or simple data summary. text() is too
> complicated for longer texts with breaklines.
>
> Thanks,
>
>
> Rado Bonk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ym at climpact.com  Tue Jul 20 14:35:13 2004
From: ym at climpact.com (Yves Magliulo)
Date: 20 Jul 2004 14:35:13 +0200
Subject: [R] Sort a data frame
In-Reply-To: <s0fceb37.030@ffdata.setur.fo>
References: <s0fceb37.030@ffdata.setur.fo>
Message-ID: <1090326912.15673.7.camel@new-york.climpact.net>

hi,
i had this trouble a while ago and found this function in latest R-help.
SortMat <- function(Mat, sort)
{
        m <- do.call("order", as.data.frame(Mat[, Sort]))
        Mat[m, ]
}

where mat is a matrix and sort the column you want to be sorted.
convert you dataframe into matrix or change this function to be used
with dataframe.

Best,
 


Le mar 20/07/2004 ?? 10:51, Luis Rideau Cruz a ??crit :
> Hi all 
> 
> I have the next data frame 
> 
>     year   STOD    SLAGNR  TAL TALT   TALVEKT
> 1 2002  2120006     57      1      NA      1
> 2 1997  97030032    57     NA   NA      NA
> 3 1997  97030071    27     1      NA      NA
> 4 1997  97030005    57     1      NA      NA
> 5 1997  97020127    60     NA   1         NA
> 6 2001  1160025     27      1      NA      1
> 7 1998  98020069    60     1      NA      NA
> 8 1996  96030009    57     NA   1         NA
> 
> How to sort it according to "year" column
> Sort does seem to work only on vectors
> 
> Thank you
> 
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
------
Yves Magliulo <ym at climpact.com>
Climatology research department, CLIMPACT

Tel.   : +33 (0) 1 55 07 85 77
Fax.   : +33 (0) 1 55 07 85 79
Universite Pierre et Marie Curie
Boite 101 - Tour 45 - 5eme etage - Couloir 45/46
4 place Jussieu, 75252 Paris CEDEX 05, France



From andy_liaw at merck.com  Tue Jul 20 14:36:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Jul 2004 08:36:32 -0400
Subject: [R] print variables values within c(" ")
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80A3@usrymx25.merck.com>

> From: Dimitris Rizopoulos
> 
> Hi Rado,
> 
> dou want something like,
> 
> paste("select", names(dataframe1), "from my table")

If so, I suspect it probably should be

paste("select", paste(dataframe1), collapse=","), "from mytable")

Andy


 
> I hope this helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Doctoral Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Rado Bonk" <rado.bonk at jrc.it>
> To: <r-help at stat.math.ethz.ch>
> Sent: Tuesday, July 20, 2004 2:25 PM
> Subject: [R] print variables values within c(" ")
> 
> 
> > Dear R-users;
> >
> > I would like to print some variable values within the text in " ".
> >
> > Ex: q1 <- c("select" names(dataframe1) "from my table")
> >                        ^^^^^^^^^^^^^^^^^
> > How to use R objects names within the quotes?
> >
> > Also, is there package which can put some longer text on multipage
> > graphics? such as some table, or simple data summary. text() is too
> > complicated for longer texts with breaklines.
> >
> > Thanks,
> >
> >
> > Rado Bonk
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From petr.pikal at precheza.cz  Tue Jul 20 14:45:06 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 20 Jul 2004 14:45:06 +0200
Subject: [R] Problem with plot
In-Reply-To: <s0fd1833.051@ffdata.setur.fo>
Message-ID: <40FD2FF2.31976.14E4A8D@localhost>

Hallo

both variables are probably factors.

try

str(your.data.frame)

to see what type are the 2 columns you want to plot. You need to 
change them to numeric (maybe:-)

Cheers
Petr

On 20 Jul 2004 at 13:03, Luis Rideau Cruz wrote:

> Hi all 
> 
> I'm trying to plot  2 columns of a frame but whatever option I choose
> for argument "type" I always get bars with height equal to 1.
> 
> I quit and restart but problem remais
> 
> Help! 
> 
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From petr.pikal at precheza.cz  Tue Jul 20 14:49:10 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 20 Jul 2004 14:49:10 +0200
Subject: [R] Sort a data frame
In-Reply-To: <1090326912.15673.7.camel@new-york.climpact.net>
References: <s0fceb37.030@ffdata.setur.fo>
Message-ID: <40FD30E6.17658.1520459@localhost>

Hallo

or you can

your.df[order(your.df$year),]

Cheers

Petr


On 20 Jul 2004 at 14:35, Yves Magliulo wrote:

> hi,
> i had this trouble a while ago and found this function in latest
> R-help. SortMat <- function(Mat, sort) {
>         m <- do.call("order", as.data.frame(Mat[, Sort]))
>         Mat[m, ]
> }
> 
> where mat is a matrix and sort the column you want to be sorted.
> convert you dataframe into matrix or change this function to be used
> with dataframe.
> 
> Best,
> 
> 
> 
> Le mar 20/07/2004 ?? 10:51, Luis Rideau Cruz a ??crit :
> > Hi all 
> > 
> > I have the next data frame 
> > 
> >     year   STOD    SLAGNR  TAL TALT   TALVEKT
> > 1 2002  2120006     57      1      NA      1
> > 2 1997  97030032    57     NA   NA      NA
> > 3 1997  97030071    27     1      NA      NA
> > 4 1997  97030005    57     1      NA      NA
> > 5 1997  97020127    60     NA   1         NA
> > 6 2001  1160025     27      1      NA      1
> > 7 1998  98020069    60     1      NA      NA
> > 8 1996  96030009    57     NA   1         NA
> > 
> > How to sort it according to "year" column
> > Sort does seem to work only on vectors
> > 
> > Thank you
> > 
> > Luis Ridao Cruz
> > Fiskiranns??knarstovan
> > N??at??n 1
> > P.O. Box 3051
> > FR-110 T??rshavn
> > Faroe Islands
> > Phone:             +298 353900
> > Phone(direct): +298 353912
> > Mobile:             +298 580800
> > Fax:                 +298 353901
> > E-mail:              luisr at frs.fo
> > Web:                www.frs.fo
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> -- 
> ------
> Yves Magliulo <ym at climpact.com>
> Climatology research department, CLIMPACT
> 
> Tel.   : +33 (0) 1 55 07 85 77
> Fax.   : +33 (0) 1 55 07 85 79
> Universite Pierre et Marie Curie
> Boite 101 - Tour 45 - 5eme etage - Couloir 45/46
> 4 place Jussieu, 75252 Paris CEDEX 05, France
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ozric at web.de  Tue Jul 20 14:55:56 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 20 Jul 2004 14:55:56 +0200
Subject: [R] --max-vsize and --max-nsize linux?
Message-ID: <200407201455.56145.ozric@web.de>

Hi,

somtimes i have trivial recodings like this:

> dim(tt)
[1] 252382     98

system.time(for(i in 2:length(tt)){
              tt[,i][is.na(tt[,i])] <- 0
    })
    
...and a win2000(XP2000+,1GB) machine makes it in several minutes, but
my linux notebook (XP2.6GHZ,512MB) don't get success after some hours.

I recognize that the cpu load is most time relative small, but  the hardisk 
have a lot of work.

Is this a problem of --max-vsize and --max-nsize and i should play with that, 
because i can't believe that the difference of RAM is the reason?

Have anybody experience what is an "optimal" setting with i.e.
512 MB  RAM in Linux?

Many thanks for help and comments
regards,christian



From andy_liaw at merck.com  Tue Jul 20 14:59:35 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Jul 2004 08:59:35 -0400
Subject: [R] Sort a data frame
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80A4@usrymx25.merck.com>

Since this is such an FAQ, perhaps sort() could be made generic, with a
method for data frame?  Here's a crack at it:

sort.data.frame <- function(x, key, ...) {
    if (missing(key)) {
        rn <- rownames(x)
        if (all(rn %in% 1:nrow(x))) rn <- as.numeric(rn)
        x[order(rn, ...), , drop=FALSE]
    } else {
        x[do.call("order", c(x[key], ...)), , drop=FALSE]
    }
}

Here the default behavior, when `key' is not supplied, is to sort by
rownames.  One (more sensible?) alternative is to sort by all columns in the
data frame, by making key=names(x).

[If the rownames of the data frame are numbers but not consecutive integers,
it may give the unintuitive result.  Does anyone know how to test whether a
character can be coerced into numeric without generating a warning?]

Andy

> From: Luis Rideau Cruz
> 
> Hi all 
> 
> I have the next data frame 
> 
>     year   STOD    SLAGNR  TAL TALT   TALVEKT
> 1 2002  2120006     57      1      NA      1
> 2 1997  97030032    57     NA   NA      NA
> 3 1997  97030071    27     1      NA      NA
> 4 1997  97030005    57     1      NA      NA
> 5 1997  97020127    60     NA   1         NA
> 6 2001  1160025     27      1      NA      1
> 7 1998  98020069    60     1      NA      NA
> 8 1996  96030009    57     NA   1         NA
> 
> How to sort it according to "year" column
> Sort does seem to work only on vectors
> 
> Thank you
> 
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From deepayan at stat.wisc.edu  Tue Jul 20 15:05:32 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 20 Jul 2004 08:05:32 -0500
Subject: [R] converting  character strings to eval
In-Reply-To: <20040720111917.44015.qmail@web52707.mail.yahoo.com>
References: <20040720111917.44015.qmail@web52707.mail.yahoo.com>
Message-ID: <200407200805.32956.deepayan@stat.wisc.edu>

On Tuesday 20 July 2004 06:19, John Hendrickx wrote:

> Couldn't eval be modified to automatically parse arguments if they're
> not expressions? Something like:
> eval2<-function(arg) {
> 	if (!is.expression(arg)) arg<-parse(text=arg)
> 	eval(arg)
> }
> Would a construction like eval2 have a downside or cause problems
> down the line?

If eval itself is modified, that would cause backward incompatibilities. 
e.g.,

> k = "mystring"
> eval(k)
[1] "mystring"
> eval2(k)
Error in eval(expr, envir, enclos) : Object "mystring" not found

Deepayan



From f.harrell at vanderbilt.edu  Tue Jul 20 13:52:20 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 20 Jul 2004 06:52:20 -0500
Subject: [R] Evaluating the Yield of Medical Tests
Message-ID: <40FD0774.1070900@vanderbilt.edu>

Marc Schwartz <MSchwartz at MedAnalytics.com> is correct.  The rcorr.cens 
function in the Hmisc package was written to do what is described in 
that article.  It also computes standard errors, and there is a function 
rcorrp.cens that in paired predictions can assess whether one predictor 
is "more concordant" with survival time than the other.  In the binary Y 
case rcorr.cens gives you the ordinary Somers Dxy and standard error, 
translatable to ROC area.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ggrothendieck at myway.com  Tue Jul 20 15:21:00 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 20 Jul 2004 13:21:00 +0000 (UTC)
Subject: [R] Sort a data frame
References: <3A822319EB35174CA3714066D590DCD504AF80A4@usrymx25.merck.com>
Message-ID: <loom.20040720T151608-490@post.gmane.org>

Liaw, Andy <andy_liaw <at> merck.com> writes:
> Does anyone know how to test whether a
> character can be coerced into numeric without generating a warning?

   res <- tryCatch(as.numeric(x), warning = function(x)x)

res is now numeric if x was successfully converted and is unchanged
if it was not.  You can test res using is.numeric and take
appropriate action or you can put the action into the body of the
warning function such as having it return 0.



From MSchwartz at MedAnalytics.com  Tue Jul 20 15:24:43 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 20 Jul 2004 08:24:43 -0500
Subject: [R] --max-vsize and --max-nsize linux?
In-Reply-To: <200407201455.56145.ozric@web.de>
References: <200407201455.56145.ozric@web.de>
Message-ID: <1090329883.3449.225.camel@localhost.localdomain>

On Tue, 2004-07-20 at 07:55, Christian Schulz wrote:
> Hi,
> 
> somtimes i have trivial recodings like this:
> 
> > dim(tt)
> [1] 252382     98
> 
> system.time(for(i in 2:length(tt)){
>               tt[,i][is.na(tt[,i])] <- 0
>     })
>     
> ...and a win2000(XP2000+,1GB) machine makes it in several minutes, but
> my linux notebook (XP2.6GHZ,512MB) don't get success after some hours.
> 
> I recognize that the cpu load is most time relative small, but  the hardisk 
> have a lot of work.
> 
> Is this a problem of --max-vsize and --max-nsize and i should play with that, 
> because i can't believe that the difference of RAM is the reason?
> 
> Have anybody experience what is an "optimal" setting with i.e.
> 512 MB  RAM in Linux?
> 
> Many thanks for help and comments
> regards,christian


Christian,

I am unclear as to the nature of your loop above. 

Note that:

> length(tt)
[1] 24733436

which is  252382 * 98. Your looping approach is not efficient and
incorrect.

Note that when trying to run your loop 'as is', I get:

> system.time(for(i in 2:length(tt)){
+               tt[,i][is.na(tt[,i])] <- 0
+     })
Error: subscript out of bounds
Timing stopped at: 3.54 1.81 5.5 0 0 

This is because 'i' eventually exceeds the number of columns (98) in
'tt', since you have 'i' going from 2 to 24733436.


I am presuming that you simply want to set any 'NA' values in 'tt' to 0?

Take note of using a vectorized approach:


tt <- matrix(sample(c(1:10, NA), 252382 * 98, replace = TRUE), 
             ncol = 98)

> dim(tt)
[1] 252382     98

> table(is.na(tt))

   FALSE     TRUE 
22484834  2248602 


Now use:

> system.time(tt[is.na(tt)] <- 0)
[1] 1.56 0.73 2.42 0.00 0.00

> table(is.na(tt))

   FALSE 
24733436 


This is on a 3.2 Ghz system with 2 Gb of RAM.

However, this is not a memory issue, it is an inefficient use of loops.

HTH,

Marc Schwartz



From ozric at web.de  Tue Jul 20 15:40:58 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 20 Jul 2004 15:40:58 +0200
Subject: [R] --max-vsize and --max-nsize linux?
In-Reply-To: <1090329883.3449.225.camel@localhost.localdomain>
References: <200407201455.56145.ozric@web.de>
	<1090329883.3449.225.camel@localhost.localdomain>
Message-ID: <200407201540.58396.ozric@web.de>

Many thanks  for clear me up the 
vectorized approach what's  indeed the advantage of R.

regards, christian


Am Dienstag, 20. Juli 2004 15:24 schrieb Marc Schwartz:
> On Tue, 2004-07-20 at 07:55, Christian Schulz wrote:
> > Hi,
> >
> > somtimes i have trivial recodings like this:
> > > dim(tt)
> >
> > [1] 252382     98
> >
> > system.time(for(i in 2:length(tt)){
> >               tt[,i][is.na(tt[,i])] <- 0
> >     })
> >
> > ...and a win2000(XP2000+,1GB) machine makes it in several minutes, but
> > my linux notebook (XP2.6GHZ,512MB) don't get success after some hours.
> >
> > I recognize that the cpu load is most time relative small, but  the
> > hardisk have a lot of work.
> >
> > Is this a problem of --max-vsize and --max-nsize and i should play with
> > that, because i can't believe that the difference of RAM is the reason?
> >
> > Have anybody experience what is an "optimal" setting with i.e.
> > 512 MB  RAM in Linux?
> >
> > Many thanks for help and comments
> > regards,christian
>
> Christian,
>
> I am unclear as to the nature of your loop above.
>
> Note that:
> > length(tt)
>
> [1] 24733436
>
> which is  252382 * 98. Your looping approach is not efficient and
> incorrect.
>
> Note that when trying to run your loop 'as is', I get:
> > system.time(for(i in 2:length(tt)){
>
> +               tt[,i][is.na(tt[,i])] <- 0
> +     })
> Error: subscript out of bounds
> Timing stopped at: 3.54 1.81 5.5 0 0
>
> This is because 'i' eventually exceeds the number of columns (98) in
> 'tt', since you have 'i' going from 2 to 24733436.
>
>
> I am presuming that you simply want to set any 'NA' values in 'tt' to 0?
>
> Take note of using a vectorized approach:
>
>
> tt <- matrix(sample(c(1:10, NA), 252382 * 98, replace = TRUE),
>              ncol = 98)
>
> > dim(tt)
>
> [1] 252382     98
>
> > table(is.na(tt))
>
>    FALSE     TRUE
> 22484834  2248602
>
> Now use:
> > system.time(tt[is.na(tt)] <- 0)
>
> [1] 1.56 0.73 2.42 0.00 0.00
>
> > table(is.na(tt))
>
>    FALSE
> 24733436
>
>
> This is on a 3.2 Ghz system with 2 Gb of RAM.
>
> However, this is not a memory issue, it is an inefficient use of loops.
>
> HTH,
>
> Marc Schwartz



From maechler at stat.math.ethz.ch  Tue Jul 20 16:02:56 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Jul 2004 16:02:56 +0200
Subject: [R] Statistical package
In-Reply-To: <bf9fb1b9.b1b9bf9f@veccal.ernet.in>
References: <bf9fb1b9.b1b9bf9f@veccal.ernet.in>
Message-ID: <16637.9744.754568.259998@gargle.gargle.HOWL>

Dear Nisith,

>>>>> "nkdas" == nkdas  <nkdas at veccal.ernet.in>
>>>>>     on Tue, 20 Jul 2004 16:32:19 +0500 writes:

    nkdas> Dear Martin Maechler,

    nkdas> I came accross your valuable contribution in the
    nkdas> domain of statistical computing through Web site. I
    nkdas> can't but appreciate your great endeavour.  I would
    nkdas> be grateful to you if you could kindly suggest me or
    nkdas> help me to utilize the free statistical pckage like R
    nkdas> with Mannual.  I am esepcially interested in Time
    nkdas> Series Analysis and plotting of experimental data. It
    nkdas> transpires that you have a good number of excellent
    nkdas> package for the same. To name a few - Lag, Lag plot,
    nkdas> embed, spectrum, spec, plot spec, spec.pgram, acf,
    nkdas> plot acf, ccf, acf2AR etc. would be very useful for
    nkdas> my work.

    nkdas> Looking forward to hear you soon.

      ......

    nkdas> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Do what the line above says ..
then do read the "Introduction to R" Manual
then you probably won't have to ask again or you will ask very differently.

Regards,
Martin Maechler



From stephane.dray at umontreal.ca  Tue Jul 20 16:44:14 2004
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Tue, 20 Jul 2004 10:44:14 -0400
Subject: [R] a bug with LAPACK ? non orthogonal vectors obtained with eigen
 of a symmetric matrix
Message-ID: <5.2.1.1.0.20040720101756.00b48cf8@magellan.umontreal.ca>

Hello,
I have obtained strange results using eigen on a symmetric matrix:

# this function perform a double centering of a matrix 
(xij-rowmean(i)-colmean(j)+meantot)
dbcenter=function(mat){
rmean=apply(mat,1,mean)
cmean=apply(mat,2,mean)
newmat=sweep(mat,1,rmean,"-")
newmat=sweep(newmat,2,cmean,"-")
newmat=newmat+mean(mat)
newmat}

# i use spdep package to create a spatial contiguity matrix
library(spdep)
x=dbcenter(nb2mat(cell2nb(3,3),style="B"))

#compute eigenvalues of a 9 by 9 matrix
res=eigen(x)

# some eigenvalues are equal to 0
eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 0), 
TRUE))

# I remove the corresponding eigenvectors
res0=res$vec[,-which(eq0)]

# then I compute the Froebenius norm with the identity matrix
sum((diag(1,ncol(res0))-crossprod(res0))^2)

[1] 1.515139e-30

# The results are correct,
# then I do it again with a biggest matrix(100 by 100)

x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
res=eigen(x)
eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 0), 
TRUE))
res0=res$vec[,-which(eq0)]
sum((diag(1,ncol(res0))-crossprod(res0))^2)

[1] 3.986387


I have try the same with res=eigen(x,EISPACK=T):

  x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
res=eigen(x,EISPACK=T)
eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 0), 
TRUE))
res0=res$vec[,-which(eq0)]
sum((diag(1,ncol(res0))-crossprod(res0))^2)
[1] 1.315542e-27


So I wonder I there is a bug in the LAPACK algorithm or if there are some 
things that I have not understood. Note that my matrix has some pairs of 
equal eigenvalues.

Thanks in advance.

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From spencer.graves at pdf.com  Tue Jul 20 16:59:55 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 20 Jul 2004 07:59:55 -0700
Subject: [R] Performance problem
In-Reply-To: <3.0.5.32.20040720130304.00acf2c0@popserver.uni-konstanz.de>
References: <3.0.5.32.20040720130304.00acf2c0@popserver.uni-konstanz.de>
Message-ID: <40FD336B.2000601@pdf.com>

      1.  Are you using "nlme" or "lme4"?  If the former, try the 
latter.  I'm told it is quite a bit different and potentially 
substantially faster, depending on the mode. 

      2.  Have you tried what people would have done before "lme", 
namely computing and summarizing, e.g, 350 separate analyses, 
summarizing the results on a data.frame, and then analyzing those 
coefficients as data?  If you want to fix certain parameters across all 
350, have you considered fitting a reduced model, e.g., using "lm", then 
including some of the estimated parameters in the 350 individual fits 
using "offset"?  This may be good enough for some purposes.  In my 
experience, after I've done things like this, I've often found that the 
big model I could not estimate in "lme" was not appropriate, anyway. 

      hope this helps.  spencer graves

Stephan Moratti wrote:

>>From: gerhard.krennrich at basf-ag.de
>>Precedence: list
>>MIME-Version: 1.0
>>To: r-help at stat.math.ethz.ch
>>Date: Tue, 20 Jul 2004 11:23:25 +0200
>>Message-ID: <OF79E18D67.A9A4078E-ONC1256ED7.0032096F at rz-c007-j650.basf-ag.de>
>>Content-Type: text/plain; charset=us-ascii
>>Subject: [R] Performance problem
>>Message: 60
>>
>>Dear all,
>>I have a performance problem in terms of computing time.
>>I estimate mixed models on a fairly large number of subgroups (10000) using
>>lme(.) within the by(.) function and it takes hours to do the calculation
>>on a fast notebook under Windows.
>>I suspect by(.) to be a poor implementation for doing individual analysis
>>on subgroups.
>>Is there an alternative and more efficient way for doing by-group
>>processing within lme(.).
>>
>>Here some code to give you a glimpse
>>gfit <- by(longdata, gen, function(x) lme(fixed=response ~ dye + C(treat,
>>base = 4 ),
>>           data=x,random =~ 1 | slide)  )
>>
>>Thanks in advance & regards
>>Gerhard Krennrich
>>
>>    
>>
>
>Sorry, that I can't contribute to a solution. But I have a similar problem,
>doing lme's on 350 source estimations of MEG brain data. So if somebody
>knows some improvement, please let me know !
>
>Stephan Moratti
>
>
>
>-----------------------------
>Dipl. Psych. Stephan Moratti
>Dept. of Psychology
>University of Konstanz
>P.O Box D25
>Phone: +40 (0)7531 882385
>Fax: +49 (0)7531 884601
>D-78457 Konstanz, Germany
>
>e-mail: Stephan.Moratti at uni-konstanz.de
>http://www.clinical-psychology.uni-konstanz.de/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ernesto at ipimar.pt  Tue Jul 20 17:43:01 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 20 Jul 2004 16:43:01 +0100
Subject: [R] prior weights in binomial gam
Message-ID: <1090338180.25670.100.camel@gandalf.local>

Hi,

I'm adjusting a binomial gam and I use the inverse variance of each
proportion as weights in the gam function (it's a model for the sex
ratio of hake).

My doubt is what are these weights doing ? I get a negative UBRE and if
I use GCV the scale parameter is close to 0 ...

Regards

EJ



From ggrothendieck at myway.com  Tue Jul 20 17:32:55 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 20 Jul 2004 15:32:55 +0000 (UTC)
Subject: [R] Sort a data frame
References: <3A822319EB35174CA3714066D590DCD504AF80A4@usrymx25.merck.com>
	<loom.20040720T151608-490@post.gmane.org>
Message-ID: <loom.20040720T172854-216@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

> 
> Liaw, Andy <andy_liaw <at> merck.com> writes:
> > Does anyone know how to test whether a
> > character can be coerced into numeric without generating a warning?
> 
>    res <- tryCatch(as.numeric(x), warning = function(x)x)
> 
> res is now numeric if x was successfully converted and is unchanged
> if it was not.  You can test res using is.numeric and take
> appropriate action or you can put the action into the body of the
> warning function such as having it return 0.

Sorry.  The above has an error.  It should be:

    # res is x converted to numeric or x without change if that fails
    res <- tryCatch(as.numeric(x), warning = function(warn)x)

or

    # res is x converted to numeric or 0 if that fails
    res <- tryCatch(as.numeric(x), warning = function(warn)0)



From andy_liaw at merck.com  Tue Jul 20 17:47:25 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Jul 2004 11:47:25 -0400
Subject: [R] vectorizing a matrix computation
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80A9@usrymx25.merck.com>

I think this should do:

z <- apply(my.matrix, 1:3, scale)
z <- aperm(z, c(2:4, 1))

Andy

> From: Christoph Lehmann
> 
> Dear R users
> 
> I have a 4-dimensional matrix (actually several 3d (x,y, slices) 
> matrices appended over time (volumes))
> 
> say, e.g. I want to z-transform the data (subtract the mean 
> and divide 
> by the std-deviation)
> 
> for (slice in 1:slices) {
>      for (x in 1:x.dim) {
>          for (y in 1:y.dim) {
>          t <- as.matrix(my.matrix[x,y,slice,1:volumes])
>          for (vol in 1:volumes) {
>              my.matrix.transformed[x,y,slice,vol] <- 
> (my.matrix[x,y,slice,vol] - mean(t))/sqrt(var(t))
>              }
>          }
>      }
> }
> 
> how can I vectorize such a function using, one of the *apply 
> functions?
> 
> many thanks
> 
> Cheers
> 
> Christoph
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From adelmaas at musc.edu  Tue Jul 20 17:55:32 2004
From: adelmaas at musc.edu (adelmaas@musc.edu)
Date: Tue, 20 Jul 2004 11:55:32 -0400
Subject: [R] Precision in R
Message-ID: <3B210A05-DA65-11D8-B8F7-000A9591E11C@musc.edu>

Greetings.

I'm trying to recreate in R some regression models I've done in SAS, 
but I'm not getting the same results.  My advisor suspects this may be 
due to differences in precision between R and SAS.  Does anyone know 
where I can find specifications for R's type double?  (It doesn't seem 
to be in the R Language Definition.)  Thanks in advance for any help 
anyone can provide.

Aaron

-------------
Aaron Solomon (ben Saul Joseph) Adelman
E-mail:  adelmaas at musc.edu
Web site:  http://people.musc.edu/~adelmaas/
AOL Instant Messenger & Yahoo! Messenger:  Hiergargo
AIM chat-room (preferred):  Adelmania



From Simon.Bond at mrc-bsu.cam.ac.uk  Tue Jul 20 17:58:29 2004
From: Simon.Bond at mrc-bsu.cam.ac.uk (Simon.Bond)
Date: Tue, 20 Jul 2004 16:58:29 +0100 (BST)
Subject: [R] Interpretation of poly(x, y, degree=2) coefficients
In-Reply-To: <200406111004.i5BA2AGZ018453@hypatia.math.ethz.ch>
References: <200406111004.i5BA2AGZ018453@hypatia.math.ethz.ch>
Message-ID: <Pine.GSO.4.58.0407201638230.19779@bononcini>

Does anyone know of a function that turns the coefficients of

lm( y~ poly(x1 , x2, degree=2))

into something that can be interpreted easily.  I was think along the
lines of the matrix representation of quadratic forms:

(x-mu)'A(x-mu) +k ,

and finding the eigenvectors/values of A, and the vector mu, but anything
that allows me to visualise a contour plot would be great.

Thanks

Simon Bond



From avril.coghlan at ucd.ie  Tue Jul 20 18:02:47 2004
From: avril.coghlan at ucd.ie (Avril Coghlan)
Date: Tue, 20 Jul 2004 17:02:47 +0100
Subject: [R] regression slope
Message-ID: <1090339367.3773.85.camel@bioinf14>

Hello,

  I'm a newcomer to R so please
forgive me if this is a silly question.

It's that I have a linear regression:
fm <- lm (x ~ y)
and I want to test whether the
slope of the regression is significantly
less than 1. How can I do this in R?

I'm also interested in comparing the
slopes of two regressions:
fm1 <- lm (x ~ y)
fm2 <- lm (a ~ b)
and asking if the slope of fm1 is
less than the slope of fm2. Is this
easy to do in R?


I will be very grateful for any help.

regards,
Avril Coghlan
(University College Dublin, Ireland)



From stephane.dray at umontreal.ca  Tue Jul 20 18:57:18 2004
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Tue, 20 Jul 2004 12:57:18 -0400
Subject: [R] a bug with LAPACK ? non orthogonal vectors obtained
	with eigen of a symmetric matrix
In-Reply-To: <5.2.1.1.0.20040720101756.00b48cf8@magellan.umontreal.ca>
Message-ID: <5.2.1.1.0.20040720125511.00b7eaf8@biomserv.univ-lyon1.fr>

I have continue my experiments in changing the size of my matrix :
(3^2 by 3^2, 4^2 by 4^2... 20^2 by 20^2)

EISPACK is always correct but LINPACK provide very strange results:


 > for(i in 3:20){
+ x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
+ res=eigen(x,EIS=T)
+ eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
0), TRUE))
+ res0=res$vec[,-which(eq0)]
+ print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
+ }
[1] 7.939371e-30
[1] 2.268788e-29
[1] 9.237286e-29
[1] 1.806393e-28
[1] 3.24619e-28
[1] 5.239195e-28
[1] 9.78079e-28
[1] 1.315542e-27
[1] 1.838600e-27
[1] 3.114150e-27
[1] 5.499297e-27
[1] 5.471782e-27
[1] 1.075098e-26
[1] 1.534822e-26
[1] 1.771326e-26
[1] 2.342404e-26
[1] 3.462522e-26
[1] 4.310143e-26
 > for(i in 3:20){
+ x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
+ res=eigen(x)
+ eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
0), TRUE))
+ res0=res$vec[,-which(eq0)]
+ print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
+ }
[1] 1.515139e-30
[1] 1.054286e-27
[1] 9.553017e-29
[1] 2.263455e-28
[1] 5.641993e-27
[1] 4.442088e-26
[1] 3.996714
[1] 3.986387
[1] 3.996545
[1] 7.396718
[1] NaN
[1] 7.980621
[1] 7.996769
[1] 3.984399
[1] NaN
[1] NaN
[1] NaN
[1] NaN


 > R.Version()
$platform
[1] "i386-pc-mingw32"

$arch
[1] "i386"

$os
[1] "mingw32"

$system
[1] "i386, mingw32"

$status
[1] ""

$major
[1] "1"

$minor
[1] "9.1"

$year
[1] "2004"

$month
[1] "06"

$day
[1] "21"

$language
[1] "R"




At 10:44 20/07/2004, Stephane DRAY wrote:
>Hello,
>I have obtained strange results using eigen on a symmetric matrix:
>
># this function perform a double centering of a matrix 
>(xij-rowmean(i)-colmean(j)+meantot)
>dbcenter=function(mat){
>rmean=apply(mat,1,mean)
>cmean=apply(mat,2,mean)
>newmat=sweep(mat,1,rmean,"-")
>newmat=sweep(newmat,2,cmean,"-")
>newmat=newmat+mean(mat)
>newmat}
>
># i use spdep package to create a spatial contiguity matrix
>library(spdep)
>x=dbcenter(nb2mat(cell2nb(3,3),style="B"))
>
>#compute eigenvalues of a 9 by 9 matrix
>res=eigen(x)
>
># some eigenvalues are equal to 0
>eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>0), TRUE))
>
># I remove the corresponding eigenvectors
>res0=res$vec[,-which(eq0)]
>
># then I compute the Froebenius norm with the identity matrix
>sum((diag(1,ncol(res0))-crossprod(res0))^2)
>
>[1] 1.515139e-30
>
># The results are correct,
># then I do it again with a biggest matrix(100 by 100)
>
>x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
>res=eigen(x)
>eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>0), TRUE))
>res0=res$vec[,-which(eq0)]
>sum((diag(1,ncol(res0))-crossprod(res0))^2)
>
>[1] 3.986387
>
>
>I have try the same with res=eigen(x,EISPACK=T):
>
>  x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
>res=eigen(x,EISPACK=T)
>eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>0), TRUE))
>res0=res$vec[,-which(eq0)]
>sum((diag(1,ncol(res0))-crossprod(res0))^2)
>[1] 1.315542e-27
>
>
>So I wonder I there is a bug in the LAPACK algorithm or if there are some 
>things that I have not understood. Note that my matrix has some pairs of 
>equal eigenvalues.
>
>Thanks in advance.
>
>St??phane DRAY
>-------------------------------------------------------------------------------------------------- 
>
>D??partement des Sciences Biologiques
>Universit?? de Montr??al, C.P. 6128, succursale centre-ville
>Montr??al, Qu??bec H3C 3J7, Canada
>
>Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
>E-mail : stephane.dray at umontreal.ca
>-------------------------------------------------------------------------------------------------- 
>
>Web                                          http://www.steph280.freesurf.fr/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From andy_liaw at merck.com  Tue Jul 20 19:01:13 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Jul 2004 13:01:13 -0400
Subject: [R] Precision in R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80AA@usrymx25.merck.com>

You can find the info in ?numeric, which says:

Note:

     _R has no single precision data type.  All real numbers are stored
     in double precision format_. ...

I suspect the most likely difference is in the actual algorithms used for
the least squares computation.  AFAIK SAS uses the sweep operator on the
extended cross-product matrix, whereas lm() in R uses QR decomposition on
the X matrix.

You can read Prof. Bates' article on least squares computations in R in the
most recent issue of the R News, available on www.r-project.org.

HTH,
Andy

> From: adelmaas at musc.edu
> 
> Greetings.
> 
> I'm trying to recreate in R some regression models I've done in SAS, 
> but I'm not getting the same results.  My advisor suspects 
> this may be 
> due to differences in precision between R and SAS.  Does anyone know 
> where I can find specifications for R's type double?  (It 
> doesn't seem 
> to be in the R Language Definition.)  Thanks in advance for any help 
> anyone can provide.
> 
> Aaron
> 
> -------------
> Aaron Solomon (ben Saul Joseph) Adelman
> E-mail:  adelmaas at musc.edu
> Web site:  http://people.musc.edu/~adelmaas/
> AOL Instant Messenger & Yahoo! Messenger:  Hiergargo
> AIM chat-room (preferred):  Adelmania
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From murdoch at stats.uwo.ca  Tue Jul 20 19:13:16 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 20 Jul 2004 13:13:16 -0400
Subject: [R] Precision in R
In-Reply-To: <3B210A05-DA65-11D8-B8F7-000A9591E11C@musc.edu>
References: <3B210A05-DA65-11D8-B8F7-000A9591E11C@musc.edu>
Message-ID: <c7kqf0h43gb1aoshe3bbm6v1p663fg7jof@4ax.com>

On Tue, 20 Jul 2004 11:55:32 -0400, adelmaas at musc.edu wrote :
>Does anyone know 
>where I can find specifications for R's type double?  

As far as I know, all platforms use the IEEE-754 standard double
precision numbers.  Google will give you a description; here's one:

http://research.microsoft.com/~hollasch/cgindex/coding/ieeefloat.html

This isn't relevant to your question, but I found the history of the
development of the standard interesting:

http://http.cs.berkeley.edu/~wkahan/ieee754status/754story.html

Duncan Murdoch



From tlumley at u.washington.edu  Tue Jul 20 19:40:37 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 20 Jul 2004 10:40:37 -0700 (PDT)
Subject: [R] constrOptim and function with additional parameters?
In-Reply-To: <40F53CC9.9070305@jhsph.edu>
References: <13650.1089809941@www40.gmx.net>
	<n8caf0dpfndok0lgh80rrfqnlmt90voa3e@4ax.com>
	<40F53CC9.9070305@jhsph.edu>
Message-ID: <Pine.A41.4.58.0407201039260.147824@homer07.u.washington.edu>

On Wed, 14 Jul 2004, Roger D. Peng wrote:

> Actually, I think this is a bug.  Take a look at this part of constrOptim:

Yes, as the author I can definitively say that it is a bug.  As other
people have pointed out there are work-arounds.

	-thomas



>
>  > constrOptim
> function (theta, f, grad, ui, ci, mu = 1e-04, control = list(),
>      method = if (is.null(grad)) "Nelder-Mead" else "BFGS",
> outer.iterations = 10
> 0,
>      outer.eps = 1e-05, ...)
> {
>      if (!is.null(control$fnscale) && control$fnscale < 0)
>          mu <- -mu
>      [...]
>      obj <- f(theta)
>      ^^^^^^^^^^^^^^^
>      r <- R(theta, theta)
>      for (i in 1:outer.iterations) {
>          obj.old <- obj
>          r.old <- r
>      [...]
> }
>
> So the object function `f' is called on the starting value `theta' but
> the `...' is not passed through.
>
> -roger
>
> Duncan Murdoch wrote:
> > On Wed, 14 Jul 2004 14:59:01 +0200 (MEST), "Marlene Mueller"
> > <Marlene.Mueller at gmx.de> wrote :
> >
> >
> >>How can I use a function with some additional input parameters
> >>in constrOptim? For example, something like
> >>
> >>fr <- function(x,a) {   ## Rosenbrock Banana function
> >> x1 <- x[1]
> >> x2 <- x[2]
> >> a * (x2 - x1 * x1)^2 + (1 - x1)^2
> >>}
> >>
> >>where the optimum is to be found w.r.t. x. Calling
> >>optim(c(-1.2,1), fr, NULL, a=100) works as expected, but I fail
> >>to provide the a=100 in the constrained case:
> >>
> >>
> >>> constrOptim(c(-1.2,0.9), fr, NULL, ui=rbind(c(-1,0),c(0,-1)),
> >>
> >>ci=c(-1,-1),a=100)
> >>Error in f(theta) : Argument "a" is missing, with no default
> >>
> >>Is this a bug or is there a different solution that I miss here?
> >
> >
> > I can't spot why your use of constrOptim isn't working, but you should
> > be able to workaround it by doing something  like this:
> >
> > applyDefaults <- function(fn, ...) {
> >   function(x) fn(x, ...)
> > }
> >
> > constrOptim(c(-1.2,0.9), applyDefaults(fr, a=100), NULL,
> > ui=rbind(c(-1,0),c(0,-1)),ci=c(-1,-1))
> >
> > The applyDefaults function creates a new function which evaluates the
> > old one with some of the parameters set to fixed values.
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ramasamy at cancer.org.uk  Tue Jul 20 19:44:30 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 20 Jul 2004 18:44:30 +0100
Subject: [R] regression slope
In-Reply-To: <1090339367.3773.85.camel@bioinf14>
References: <1090339367.3773.85.camel@bioinf14>
Message-ID: <1090345351.3088.43.camel@localhost.localdomain>

I would try to construct the confidence intervals and compare them to
the value that you want
> x <- rnorm(20)
> y <- 2*x + rnorm(20)
> summary( m1 <- lm(y~x) )

<snip>
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   0.1418     0.1294   1.095    0.288
x             2.2058     0.1289  17.108  1.4e-12 ***
<snip>

That says that the slope estimate is 2.2058 with standard error of
0.1289. So the approximate 99% CI is 2.2058 +/- 3*0.1289 = (1.819,
2.593) which is clearly greater than 1.

> summary(m1)[[4]][2,1] + 3* summary(m1)[[4]][2,2]
[1] 2.592629
> summary(m1)[[4]][2,1] - 3* summary(m1)[[4]][2,2]
[1] 1.819026

For your next question, you simply compare the CI of one slope to
another and see if they overlap. 

There is probably a way to construct proper significance testing to get
p-values and such. You can try reading MASS4 or hopefully someone in the
list might provide with a neater answer.


On Tue, 2004-07-20 at 17:02, Avril Coghlan wrote:
> Hello,
> 
>   I'm a newcomer to R so please
> forgive me if this is a silly question.
> 
> It's that I have a linear regression:
> fm <- lm (x ~ y)
> and I want to test whether the
> slope of the regression is significantly
> less than 1. How can I do this in R?
> 
> I'm also interested in comparing the
> slopes of two regressions:
> fm1 <- lm (x ~ y)
> fm2 <- lm (a ~ b)
> and asking if the slope of fm1 is
> less than the slope of fm2. Is this
> easy to do in R?
> 
> 
> I will be very grateful for any help.
> 
> regards,
> Avril Coghlan
> (University College Dublin, Ireland)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From MSchwartz at MedAnalytics.com  Tue Jul 20 19:50:55 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 20 Jul 2004 12:50:55 -0500
Subject: [R] Precision in R
In-Reply-To: <c7kqf0h43gb1aoshe3bbm6v1p663fg7jof@4ax.com>
References: <3B210A05-DA65-11D8-B8F7-000A9591E11C@musc.edu>
	<c7kqf0h43gb1aoshe3bbm6v1p663fg7jof@4ax.com>
Message-ID: <1090345854.3449.318.camel@localhost.localdomain>

On Tue, 2004-07-20 at 12:13, Duncan Murdoch wrote:
> On Tue, 20 Jul 2004 11:55:32 -0400, adelmaas at musc.edu wrote :
> >Does anyone know 
> >where I can find specifications for R's type double?  
> 
> As far as I know, all platforms use the IEEE-754 standard double
> precision numbers.  Google will give you a description; here's one:
> 
> http://research.microsoft.com/~hollasch/cgindex/coding/ieeefloat.html
> 
> This isn't relevant to your question, but I found the history of the
> development of the standard interesting:
> 
> http://http.cs.berkeley.edu/~wkahan/ieee754status/754story.html
> 
> Duncan Murdoch


Duncan, 

The standard is there, but not all applications stick to it faithfully.
A good example being how certain <cough> spreadsheets <\cough> deal with
numbers "close to zero".

For example, Excel will round numbers "close to zero" to zero. You may
recall this thread from last year covered this topic

http://maths.newcastle.edu.au/~rking/R/help/03a/6597.html

More information on Excel's varied compliance with the IEEE 754 standard
is available here

http://support.microsoft.com/default.aspx?scid=kb;en-us;78113

The official IEEE 754 page is at http://grouper.ieee.org/groups/754/ and
there are some good reading materials and FAQ's there.

This above is beyond the scope of SAS in particular, but I suspect that
the difference that Aaron is experiencing, as Andy has noted, is
methodologic and not precision related.

Aaron, one other source for information on the precision of R on your
particular machine is the use of .Machine, which will provide you with a
list of specifications. See ?.Machine for additional information here.

HTH,

Marc Schwartz



From marie-pierre.sylvestre at mail.mcgill.ca  Tue Jul 20 20:12:54 2004
From: marie-pierre.sylvestre at mail.mcgill.ca (Marie-Pierre Sylvestre)
Date: Tue, 20 Jul 2004 14:12:54 -0400
Subject: [R] Error: subscript out of bounds
Message-ID: <001901c46e85$2d3af200$1392a8c0@epimgh.mcgill.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040720/31000453/attachment.pl

From vangyzen at stat.duke.edu  Tue Jul 20 20:24:03 2004
From: vangyzen at stat.duke.edu (Eric van Gyzen)
Date: Tue, 20 Jul 2004 14:24:03 -0400
Subject: [R] Profiling dynamically-loaded code
Message-ID: <40FD6343.8030600@stat.duke.edu>

I'm trying to compile R with support for profiling dynamically-loaded C 
code.  I configured R with:

   export CFLAGS="-O0 -pg -pipe"
   export CXXFLAGS="-O0 -pg -pipe"
   export FFLAGS="-O0 -pg -pipe"

   ./configure --prefix=/tmp/Rprof --with-lapack="-llapack"
     --with-blas="-lblas" --with-bzlib --with-pcre
     --without-recommended-packages

When I try to compile it, I get:

   dumping R code in package 'methods'
   Saving namespace image ...
   Error in dyn.load(x, as.logical(local), as.logical(now)) :
       unable to load shared library
         "/tmp/R-1.9.1/library/methods/libs/methods.so":
     Service unavailable
   Execution halted
   *** Error code 1

   Stop in /tmp/R-1.9.1/src/library/methods.
   *** Error code 1

The 'file' command tells me that methods.so is:

   ELF 32-bit LSB shared object, Intel 80386, version 1 (FreeBSD),
     not stripped

What shall I try next?  Please forgive me if I missed some very obvious 
documentation on the web or in the mailing-list archives.

Thanks!

Eric

-- 
Eric van Gyzen                        Sr. Systems Programmer
http://www.stat.duke.edu/~vangyzen/   ISDS, Duke University



From cmoffet at nwrc.ars.usda.gov  Tue Jul 20 20:26:10 2004
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Tue, 20 Jul 2004 12:26:10 -0600
Subject: [R] regression slope
In-Reply-To: <1090345351.3088.43.camel@localhost.localdomain>
References: <1090339367.3773.85.camel@bioinf14>
	<1090339367.3773.85.camel@bioinf14>
Message-ID: <3.0.6.32.20040720122610.0109d018@pxms.nwrc.ars.usda.gov>

At 06:44 PM 7/20/2004 +0100, Adaikalavan Ramasamy wrote:
>I would try to construct the confidence intervals and compare them to
>the value that you want
>> x <- rnorm(20)
>> y <- 2*x + rnorm(20)
>> summary( m1 <- lm(y~x) )
>
><snip>
>Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
>(Intercept)   0.1418     0.1294   1.095    0.288
>x             2.2058     0.1289  17.108  1.4e-12 ***
><snip>
>
>That says that the slope estimate is 2.2058 with standard error of
>0.1289. So the approximate 99% CI is 2.2058 +/- 3*0.1289 = (1.819,
>2.593) which is clearly greater than 1.

Another method which gives the p value etc. was shared with this list by
Prof. Ripley several years ago:


set.seed(1)
x <- rnorm(20)
x.hypoth <- 1    # i.e., Null hypothesis is that x != 1
y <- 2*x + rnorm(20)
summary( m1 <- lm(y - x.hypoth*x~x) )

Produces:

Call:
lm(formula = y - x.hypoth * x ~ x)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.69133 -0.43739 -0.07132  0.68033  1.63937 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)  0.03307    0.19981   0.166    0.870   
x            0.79245    0.21951   3.610    0.002 **
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 0.8738 on 18 degrees of freedom
Multiple R-Squared:  0.42,      Adjusted R-squared: 0.3878 
F-statistic: 13.03 on 1 and 18 DF,  p-value: 0.002001 






>
>> summary(m1)[[4]][2,1] + 3* summary(m1)[[4]][2,2]
>[1] 2.592629
>> summary(m1)[[4]][2,1] - 3* summary(m1)[[4]][2,2]
>[1] 1.819026
>
>For your next question, you simply compare the CI of one slope to
>another and see if they overlap. 
>
>There is probably a way to construct proper significance testing to get
>p-values and such. You can try reading MASS4 or hopefully someone in the
>list might provide with a neater answer.
>
>
>On Tue, 2004-07-20 at 17:02, Avril Coghlan wrote:
>> Hello,
>> 
>>   I'm a newcomer to R so please
>> forgive me if this is a silly question.
>> 
>> It's that I have a linear regression:
>> fm <- lm (x ~ y)
>> and I want to test whether the
>> slope of the regression is significantly
>> less than 1. How can I do this in R?
>> 
>> I'm also interested in comparing the
>> slopes of two regressions:
>> fm1 <- lm (x ~ y)
>> fm2 <- lm (a ~ b)
>> and asking if the slope of fm1 is
>> less than the slope of fm2. Is this
>> easy to do in R?
>> 
>> 
>> I will be very grateful for any help.
>> 
>> regards,
>> Avril Coghlan
>> (University College Dublin, Ireland)
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Rangeland Scientist

##################################################################
                                            ####		     
USDA-ARS                                        #		     
Northwest Watershed Research Center             #		     
800 Park Blvd, Plaza IV, Suite 105          ###########   ####    
Boise, ID 83712-7716                       #    #      # #        
Voice: (208) 422-0718                      #    #  ####   ####    
FAX:   (208) 334-1502                      #    # #           #   
                                            ####   ###########    
##################################################################



From sundar.dorai-raj at PDF.COM  Tue Jul 20 20:28:05 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 20 Jul 2004 13:28:05 -0500
Subject: [R] regression slope
In-Reply-To: <1090345351.3088.43.camel@localhost.localdomain>
References: <1090339367.3773.85.camel@bioinf14>
	<1090345351.3088.43.camel@localhost.localdomain>
Message-ID: <40FD6435.3010003@pdf.com>



Adaikalavan Ramasamy wrote:

> I would try to construct the confidence intervals and compare them to
> the value that you want
> 
>>x <- rnorm(20)
>>y <- 2*x + rnorm(20)
>>summary( m1 <- lm(y~x) )
> 
> 
> <snip>
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.1418     0.1294   1.095    0.288
> x             2.2058     0.1289  17.108  1.4e-12 ***
> <snip>
> 
> That says that the slope estimate is 2.2058 with standard error of
> 0.1289. So the approximate 99% CI is 2.2058 +/- 3*0.1289 = (1.819,
> 2.593) which is clearly greater than 1.
> 
> 
>>summary(m1)[[4]][2,1] + 3* summary(m1)[[4]][2,2]
> 
> [1] 2.592629
> 
>>summary(m1)[[4]][2,1] - 3* summary(m1)[[4]][2,2]
> 
> [1] 1.819026
> 

I think the preferred way of doing this is with confint:

# 3 sigma limits
confint(m1, parm = "x", level = 1 - pt(-3, m1$df.resid) * 2)
# 95% confidence (default)
confint(m1, parm = "x")

> For your next question, you simply compare the CI of one slope to
> another and see if they overlap. 
> 
> There is probably a way to construct proper significance testing to get
> p-values and such. You can try reading MASS4 or hopefully someone in the
> list might provide with a neater answer.
> 
> 
> On Tue, 2004-07-20 at 17:02, Avril Coghlan wrote:
> 
>>Hello,
>>
>>  I'm a newcomer to R so please
>>forgive me if this is a silly question.
>>
>>It's that I have a linear regression:
>>fm <- lm (x ~ y)
>>and I want to test whether the
>>slope of the regression is significantly
>>less than 1. How can I do this in R?
>>
>>I'm also interested in comparing the
>>slopes of two regressions:
>>fm1 <- lm (x ~ y)
>>fm2 <- lm (a ~ b)
>>and asking if the slope of fm1 is
>>less than the slope of fm2. Is this
>>easy to do in R?
>>
>>
>>I will be very grateful for any help.
>>
>>regards,
>>Avril Coghlan
>>(University College Dublin, Ireland)
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From MSchwartz at MedAnalytics.com  Tue Jul 20 20:49:20 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 20 Jul 2004 13:49:20 -0500
Subject: [R] Error: subscript out of bounds
In-Reply-To: <001901c46e85$2d3af200$1392a8c0@epimgh.mcgill.ca>
References: <001901c46e85$2d3af200$1392a8c0@epimgh.mcgill.ca>
Message-ID: <1090349360.3449.342.camel@localhost.localdomain>

On Tue, 2004-07-20 at 13:12, Marie-Pierre Sylvestre wrote:
> Hi
> 
> I am running a simulation that involves a loop calling three 2
> functions that I have written. Everything works fine when the inside
> of the loop is performed up to 1000 times (for (i in 1:750)). 
> 
> However, I sometimes get : ''Error: subscript out of bounds'' if I try
> to increase the loop 'size' to 1000. I am thinking it has to to with
> memory but I am not sure. I have increased my memory size to 512M but
> it does not solve my problem.
> 
> It would take to much place to copy and paste my code here. It would
> be helpful if you could tell me whether my problem may or may not be
> related to memory size.
> 
> Beside, what's the difference between
> 
>      Error: subscript out of bounds
>      Error: subscript out of range  ?
> 
> 
> Regards
> 
> M-P Sylvestre


If this was a memory error, you would probably get a "cannot allocate
..." type of error message.

More than likely, the object upon which you are using the loop has
dimensions which are smaller than the value(s) that your loops are using
for indexing into the object. The use of either dim(object) or
str(object) will give you more information here. When you increase the
loop size, presumably, you have not increased the size of your
underlying object in kind.

For example, if your object (say a matrix) has dimensions of 500 rows
and 10 columns, your loop is trying to index object[510, 12], which is
'out of bounds' for your object.

A search of the R source code using grep suggests that the 'out of
bounds' message is generally used when trying to index (subset) an
object with a value or values that are not correct as I have above. This
could also be a single dimension vector, BTW. For example, trying to
index object[100] when your vector is only 50 elements in size.

In the case of the 'out of range' message, that appears to be typically
used when an argument to a function or other constrained parameter is
above or below the valid range that the argument or parameter may have. 

A scan of where and how the messages are used indicates some
variability, probably as a result of the multiple authors involved.

HTH,

Marc Schwartz



From kjetil at acelerate.com  Tue Jul 20 21:07:57 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Tue, 20 Jul 2004 15:07:57 -0400
Subject: [R] Sort a data frame
References: <3A822319EB35174CA3714066D590DCD504AF80A4@usrymx25.merck.com>	<loom.20040720T151608-490@post.gmane.org>
	<loom.20040720T172854-216@post.gmane.org>
Message-ID: <40FD6D8D.2010602@acelerate.com>



Gabor Grothendieck wrote:

>Gabor Grothendieck <ggrothendieck <at> myway.com> writes:
>
>  
>
>>Liaw, Andy <andy_liaw <at> merck.com> writes:
>>    
>>
>>>Does anyone know how to test whether a
>>>character can be coerced into numeric without generating a warning?
>>>      
>>>
>>   res <- tryCatch(as.numeric(x), warning = function(x)x)
>>
>>res is now numeric if x was successfully converted and is unchanged
>>if it was not.  You can test res using is.numeric and take
>>appropriate action or you can put the action into the body of the
>>warning function such as having it return 0.
>>    
>>
Also:
library(Hmisc)
example(all.is.numeric)

Kjetil Halvorsen


>Sorry.  The above has an error.  It should be:
>
>    # res is x converted to numeric or x without change if that fails
>    res <- tryCatch(as.numeric(x), warning = function(warn)x)
>
>or
>
>    # res is x converted to numeric or 0 if that fails
>    res <- tryCatch(as.numeric(x), warning = function(warn)0)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From kjetil at acelerate.com  Tue Jul 20 21:07:57 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Tue, 20 Jul 2004 15:07:57 -0400
Subject: [R] Sort a data frame
References: <3A822319EB35174CA3714066D590DCD504AF80A4@usrymx25.merck.com>	<loom.20040720T151608-490@post.gmane.org>
	<loom.20040720T172854-216@post.gmane.org>
Message-ID: <40FD6D8D.2010602@acelerate.com>



Gabor Grothendieck wrote:

>Gabor Grothendieck <ggrothendieck <at> myway.com> writes:
>
>  
>
>>Liaw, Andy <andy_liaw <at> merck.com> writes:
>>    
>>
>>>Does anyone know how to test whether a
>>>character can be coerced into numeric without generating a warning?
>>>      
>>>
>>   res <- tryCatch(as.numeric(x), warning = function(x)x)
>>
>>res is now numeric if x was successfully converted and is unchanged
>>if it was not.  You can test res using is.numeric and take
>>appropriate action or you can put the action into the body of the
>>warning function such as having it return 0.
>>    
>>
Also:
library(Hmisc)
example(all.is.numeric)

Kjetil Halvorsen


>Sorry.  The above has an error.  It should be:
>
>    # res is x converted to numeric or x without change if that fails
>    res <- tryCatch(as.numeric(x), warning = function(warn)x)
>
>or
>
>    # res is x converted to numeric or 0 if that fails
>    res <- tryCatch(as.numeric(x), warning = function(warn)0)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From umeno at uiuc.edu  Wed Jul 21 00:16:19 2004
From: umeno at uiuc.edu (Soyoko Umeno)
Date: Tue, 20 Jul 2004 17:16:19 -0500
Subject: [R] read a file
Message-ID: <a284e55e.631009f4.8276400@expms3.cites.uiuc.edu>

Hi everyone,

I am having a problem reading my data file in R.  It only 
reads part of it, and stops doing it in half way through the 
data.  I looked at the observation where reading stops, but 
it is really not different from the observations read it.  I 
expanded the matrix size, but it did not help.  I am using a 
text format to read the data file.  Could someone help me?

Thank you
Soyoko



From supton at referentia.com  Wed Jul 21 00:25:20 2004
From: supton at referentia.com (Steve Upton)
Date: Tue, 20 Jul 2004 18:25:20 -0400
Subject: [R] read a file
In-Reply-To: <a284e55e.631009f4.8276400@expms3.cites.uiuc.edu>
Message-ID: <004301c46ea8$714ba340$6401a8c0@shodzilla>

Soyoko,

It would really help if you could provide just a little bit more info. For
example, what R commands are you using now to read in your data, and can you
provide say the first couple of rows of data that you're trying to read in,
and what, if any, errors are getting reported. 

Thanx
steve

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Soyoko Umeno
Sent: Tuesday, July 20, 2004 6:16 PM
To: r-help at stat.math.ethz.ch
Subject: [R] read a file


Hi everyone,

I am having a problem reading my data file in R.  It only 
reads part of it, and stops doing it in half way through the 
data.  I looked at the observation where reading stops, but 
it is really not different from the observations read it.  I 
expanded the matrix size, but it did not help.  I am using a 
text format to read the data file.  Could someone help me?

Thank you
Soyoko

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Wed Jul 21 00:26:50 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Jul 2004 18:26:50 -0400
Subject: [R] read a file
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80B0@usrymx25.merck.com>

> From: Soyoko Umeno
> 
> Hi everyone,
> 
> I am having a problem reading my data file in R.  It only 
> reads part of it, and stops doing it in half way through the 
> data.  I looked at the observation where reading stops, but 
> it is really not different from the observations read it.  I 
> expanded the matrix size, but it did not help.  I am using a 
> text format to read the data file.  Could someone help me?
> 
> Thank you
> Soyoko
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Following the above instruction would help people to help you.  You really
don't give us much to go on here.  What were the commands you used?  Were
there any warnings or errors?  What version of R on what OS are you using?
Have you consulted the `R Data Import/Export' manual?

Andy



From jim.lemon at uts.edu.au  Wed Jul 21 00:55:50 2004
From: jim.lemon at uts.edu.au (Jim Lemon)
Date: Wed, 21 Jul 2004 08:55:50 +1000
Subject: [R] LaTeX errors
Message-ID: <0I1600AXRA3KPM@mail.uts.edu.au>

Hello again,

Having successfully mastered the creation of fairly unsophisticated print 
methods, I have encountered the dreaded LaTeX error, i.e.:

* checking concord-manual.tex ... ERROR
LaTeX errors when creating DVI version.
This typically indicates Rd problems.

As I have no idea what these errors might be, I wondered if there is any way 
to cozen such information out of whatever program is creating the DVI version.

Jim

Feel free to ignore any garbage beneath this line.

-- 

DISCLAIMER: This email message and any accompanying attachme...{{dropped}}



From Mike.Prager at noaa.gov  Wed Jul 21 01:41:11 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Tue, 20 Jul 2004 19:41:11 -0400
Subject: [R] read a file
In-Reply-To: <a284e55e.631009f4.8276400@expms3.cites.uiuc.edu>
References: <a284e55e.631009f4.8276400@expms3.cites.uiuc.edu>
Message-ID: <6.1.2.0.0.20040720193851.01b43598@hermes.nos.noaa.gov>

To get better help, I suggest you specify--

1. How big is the data matrix (file)?
2. How as it created?
3. How are you reading it? (You might post the pertinent part of the R code)


At 06:16 PM 07/20/2004, Soyoko Umeno wrote:
>Hi everyone,
>
>I am having a problem reading my data file in R.  It only
>reads part of it, and stops doing it in half way through the
>data.  I looked at the observation where reading stops, but
>it is really not different from the observations read it.  I
>expanded the matrix size, but it did not help.  I am using a
>text format to read the data file.  Could someone help me?
>
>Thank you
>Soyoko
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Michael Prager, Ph.D.                <Mike.Prager at noaa.gov>
NOAA Beaufort Laboratory
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/
***



From ramasamy at cancer.org.uk  Wed Jul 21 02:03:53 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 21 Jul 2004 01:03:53 +0100
Subject: [R] read a file
In-Reply-To: <6.1.2.0.0.20040720193851.01b43598@hermes.nos.noaa.gov>
References: <a284e55e.631009f4.8276400@expms3.cites.uiuc.edu>
	<6.1.2.0.0.20040720193851.01b43598@hermes.nos.noaa.gov>
Message-ID: <1090368233.7115.5.camel@localhost.localdomain>

The question is poorly specified. I can only guess the problem much less
the answers, but try reading through 
http://tolstoy.newcastle.edu.au/R/help/04/07/0443.html
http://tolstoy.newcastle.edu.au/R/help/04/07/0224.html

On Wed, 2004-07-21 at 00:41, Mike Prager wrote:
> To get better help, I suggest you specify--
> 
> 1. How big is the data matrix (file)?
> 2. How as it created?
> 3. How are you reading it? (You might post the pertinent part of the R code)
> 
> 
> At 06:16 PM 07/20/2004, Soyoko Umeno wrote:
> >Hi everyone,
> >
> >I am having a problem reading my data file in R.  It only
> >reads part of it, and stops doing it in half way through the
> >data.  I looked at the observation where reading stops, but
> >it is really not different from the observations read it.  I
> >expanded the matrix size, but it did not help.  I am using a
> >text format to read the data file.  Could someone help me?
> >
> >Thank you
> >Soyoko
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Paul.Boutros at utoronto.ca  Wed Jul 21 03:39:21 2004
From: Paul.Boutros at utoronto.ca (Paul Boutros)
Date: Tue, 20 Jul 2004 21:39:21 -0400
Subject: [R] Cutting heatmap dendrogram
Message-ID: <CPEAKHBKLBNIKJDIELLCEEOBCKAA.Paul.Boutros@utoronto.ca>

Hello,

I've been clustering my data using hclust and cutting the resulting tree
with cutree.  Separately, I visualize the clusterings with heatmap.  Is it
possible to have the dendrogram on the heatmap reflect the cutree results?
That is, instead of having one large dendrogram, it would have 4 or 25 in
the example below.  Any guidance on if that's possible or not, and what
kinds of commands I should be looking into would be very much appreciated.
I'm using R 1.9.0 on Windows XP.

Thanks!
Paul

# load libraries
library(stats);

# working copy of data
set1 <- as.matrix(data);
set2 <- t(set1);

# genes
genes.distance <- as.dist(1-cor(set2));
genes.clusters <- hclust(genes.distance);
genes.dendrogr <- as.dendrogram(genes.clusters);

# samples
samples.distance <- as.dist(1-cor(set1));
samples.clusters <- hclust(samples.distance1);
samples.dendrogr <- as.dendrogram(samples.clusters1);

# cut the trees
samples.members  <- cutree(samples.clusters, k=4);
genes.members    <- cutree(genes.clusters,   k=25);

# heatmap colouring
my.colors <- function(n = 20, low.col = 0.35, high.col=1, saturation = 0.85)
{
  if (n < 2) stop("n must be greater than 2")
  n1 <- n%/%2
  n2 <- n - n1
  c(hsv(low.col, saturation, seq(1,0,length=n1)),
     hsv(high.col, saturation, seq(0,1,length=n2)))
}

# make the heatmap
hv <- heatmap(as.matrix(data), Rowv=genes.dendrogr, Colv=samples.dendrogr,
col=my.colors());



From andrewr at uidaho.edu  Wed Jul 21 05:28:30 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 21 Jul 2004 13:28:30 +1000
Subject: [R] nlm doesn't detect a gradient in my function - odd solution
 (bug?)
Message-ID: <f1e9127ea.127eaf1e9@uidaho.edu>

Dear R community,

I sent a question to the list a few days ago.  Using nlm, I was unable to detect a gradient in a four-parameter function that I had written in the region that I was searching, even though the function surface clearly varied in the fourth significant figure there.

I stumbled across a peculiar solution: the nlm function was able to detect a non-zero gradient when the ndigit value was *reduced*.  The default value is 12, I was able to detect a gradient in one of the four dimensions if I used 10, and in all of the four if I used 8.

Does that make any sense to anyone?

Thanks,

Andrew



From andrewr at uidaho.edu  Wed Jul 21 05:31:35 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 21 Jul 2004 13:31:35 +1000
Subject: [R] Interpreting negative diagonal values in a hessian
Message-ID: <14cc810cc8.10cc814cc8@uidaho.edu>

Hi R-community,

I've been trying to fit a model using maximum likelihood in nlm.  Upon convergence I examine the hessian and it has a few (not all) positive values on its diagonal, as does its inverse.  I am minimizing the negative log likelihood, so I would expect all the members of the diagonal to be negative (I think).

Can anyone shed light on how this might be interpreted?

Thanks much,

Andrew



From rpeng at jhsph.edu  Wed Jul 21 05:42:29 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 20 Jul 2004 23:42:29 -0400
Subject: [R] [R-pkgs] NMMAPSdata package
Message-ID: <40FDE625.3030506@jhsph.edu>

We would like to announce release of version 0.3-3 of the 
NMMAPSdata package.  NMMAPSdata is an R package which contains 
time series data on air pollution, weather, and mortality for 108 
United States cities for the years 1987--2000.  These data were 
originally assembled for the National Morbidity, Mortality, and 
Air Pollution Study sponsored by the Health Effects Institute and 
have since been updated.  While the data have been publicly 
available for some time now, NMMAPSdata, in addition to being a 
convenience for R users, assembles all of the city data into one 
package and contains some utility functions for managing the 
database.

NMMAPSdata can be downloaded from

http://www.ihapss.jhsph.edu/data/NMMAPS/R/

The package comes with a vignette which contains an overview of 
the data and a few example analyses.

Comments and suggestions are greatly appreciated.

Roger Peng
Leah Welty

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From jacques.veslot at cirad.fr  Wed Jul 21 08:35:05 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Wed, 21 Jul 2004 10:35:05 +0400
Subject: [R] How to sort TWO columns ?
Message-ID: <HHEDKBCGCMDOHEDELFBCKEOPCAAA.jacques.veslot@cirad.fr>

Dear ALL,

I fear my question has already been answered many times before, but I
haven't fund that in archives...

I am working on spatial datasets and, in most arrays I'm handling, there are
two columns dedicated to (x,y)-coords.
For different reasons - notably to draw image() plots, I need to have these
two columns sorted in increasing order.
But sort() and order() seem to apply to vectors - or one single column -
only.

Could somedy please let me know how to sort two columns of a dataframe, with
priority to one of them, just like in access ?

Thanks,

Jacques VESLOT
CIRAD

Another related question :
How to put legend on image() plots - or image-based plots like
image.kriging() in geoR ?
Despite help pages, I haven't succeeded.



-----------------------------------------------------
CIRAD 3P Reunion - MailScanner
----------------------------------------------------- 
Ce message a ??t?? v??rifi?? par MailScanner
et analyse par 4 antivirus :
ClamAv - BitDefender - F-Prot - Panda.

Aucun virus,ni rien de suspect n'a ??t?? trouv??.

This message has been scanned for viruses and
dangerous content, and is believed to be clean.



From ligges at statistik.uni-dortmund.de  Wed Jul 21 08:44:35 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 Jul 2004 08:44:35 +0200
Subject: [R] LaTeX errors
In-Reply-To: <0I1600AXRA3KPM@mail.uts.edu.au>
References: <0I1600AXRA3KPM@mail.uts.edu.au>
Message-ID: <40FE10D3.8090602@statistik.uni-dortmund.de>

Jim Lemon wrote:

> Hello again,
> 
> Having successfully mastered the creation of fairly unsophisticated print 
> methods, I have encountered the dreaded LaTeX error, i.e.:
> 
> * checking concord-manual.tex ... ERROR
> LaTeX errors when creating DVI version.
> This typically indicates Rd problems.
> 
> As I have no idea what these errors might be, I wondered if there is any way 
> to cozen such information out of whatever program is creating the DVI version.

Well, LaTeX is creating the DVI version.
And yes, there is a way. Check out the file

concord.Rcheck/concord-manual.log

for any error messages. Probably at least one of your Rd files has at 
least one entry that causes LaTeX to fail  ...

Uwe Ligges


> 
> Jim
> 
> Feel free to ignore any garbage beneath this line.
>



From ligges at statistik.uni-dortmund.de  Wed Jul 21 08:48:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 Jul 2004 08:48:02 +0200
Subject: [R] How to sort TWO columns ?
In-Reply-To: <HHEDKBCGCMDOHEDELFBCKEOPCAAA.jacques.veslot@cirad.fr>
References: <HHEDKBCGCMDOHEDELFBCKEOPCAAA.jacques.veslot@cirad.fr>
Message-ID: <40FE11A2.5050303@statistik.uni-dortmund.de>

Jacques VESLOT wrote:

> Dear ALL,
> 
> I fear my question has already been answered many times before, but I
> haven't fund that in archives...
> 
> I am working on spatial datasets and, in most arrays I'm handling, there are
> two columns dedicated to (x,y)-coords.
> For different reasons - notably to draw image() plots, I need to have these
> two columns sorted in increasing order.
> But sort() and order() seem to apply to vectors - or one single column -
> only.
> 
> Could somedy please let me know how to sort two columns of a dataframe, with
> priority to one of them, just like in access ?

See ?order

Uwe Ligges


> Thanks,
> 
> Jacques VESLOT
> CIRAD
> 
> Another related question :
> How to put legend on image() plots - or image-based plots like
> image.kriging() in geoR ?
> Despite help pages, I haven't succeeded.
> 
> 
> 
> -----------------------------------------------------
> CIRAD 3P Reunion - MailScanner
> ----------------------------------------------------- 
> Ce message a ??t?? v??rifi?? par MailScanner
> et analyse par 4 antivirus :
> ClamAv - BitDefender - F-Prot - Panda.
> 
> Aucun virus,ni rien de suspect n'a ??t?? trouv??.
> 
> This message has been scanned for viruses and
> dangerous content, and is believed to be clean.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From xiwu at uoguelph.ca  Wed Jul 21 08:57:11 2004
From: xiwu at uoguelph.ca (ximing wu)
Date: Wed, 21 Jul 2004 02:57:11 -0400
Subject: [R] nonparametetric bivariate regression
Message-ID: <5.1.0.14.2.20040721025436.00bc7ee0@staff.mail.uoguelph.ca>

Hi there,
Does R has built-in codes for nonpara. bivariate regression so that I can 
estimate the joint distribution of two variables as a function of some 
covariates? Thanks a lot.


---------------------------------------------------
Ximing Wu
Department of Economics
University of Guelph
Guelph, Ontario, Canada, N1G 2W1

Tel: (519) 842-4120, ext 53014
Fax: (519) 763-8497
email: xiwu at uoguelph.ca
Webpage: http://www.uoguelph.ca/~xiwu/



From P.Lemmens at nici.kun.nl  Wed Jul 21 08:57:27 2004
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Wed, 21 Jul 2004 08:57:27 +0200
Subject: [R] How to sort TWO columns ?
In-Reply-To: <HHEDKBCGCMDOHEDELFBCKEOPCAAA.jacques.veslot@cirad.fr>
References: <HHEDKBCGCMDOHEDELFBCKEOPCAAA.jacques.veslot@cirad.fr>
Message-ID: <C3C0CB869A65B1F31F853FE5@lemmens.socsci.kun.nl>

Hoi Jacques,

--On woensdag 21 juli 2004 10:35 +0400 Jacques VESLOT 
<jacques.veslot at cirad.fr> wrote:

> Could somedy please let me know how to sort two columns of a dataframe,
> with priority to one of them, just like in access ?
>
Would this <http://www.ku.edu/~pauljohn/R/Rtips.html#2.12> help?

kind regards,
Paul



-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.05)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From Matthias.Templ at statistik.gv.at  Wed Jul 21 09:03:07 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Wed, 21 Jul 2004 09:03:07 +0200
Subject: [R] How to sort TWO columns ?
Message-ID: <83536658864BC243BE3C06D7E936ABD501BE1892@xchg1.statistik.gv.at>

Hi,

It would be discussed yesterday.

See e.g. in Google for ("sorting a data frame" R) http://www.r-project.org/nocvs/mail/r-help/2002/0088.html
Or one entry yesterday:

Best,
Matthias

>Hi

>Lets assign your data frame to the variable yourdf
>then:

>yourdf[ , order( yourdf$year ) ]

>should sort it.

>For decreasing increasing sorting
>see 
>?order

>Sincerely Eryk.



>*********** REPLY SEPARATOR  ***********

>On 20.07.2004 at 09:51 Luis Rideau Cruz wrote:

>Hi all
>
>I have the next data frame
>
>    year   STOD    SLAGNR  TAL TALT   TALVEKT
>1 2002  2120006     57      1      NA      1
>2 1997  97030032    57     NA   NA      NA
>3 1997  97030071    27     1      NA      NA
>4 1997  97030005    57     1      NA      NA
>5 1997  97020127    60     NA   1         NA
>6 2001  1160025     27      1      NA      1
>7 1998  98020069    60     1      NA      NA
>8 1996  96030009    57     NA   1         NA
>
>How to sort it according to "year" column
>Sort does seem to work only on vectors
>
>Thank you
>
>Luis Ridao Cruz
>Fiskiranns??knarstovan
>N??at??n 1
>P.O. Box 3051
>FR-110 T??rshavn
>Faroe Islands
>Phone:             +298 353900
>Phone(direct): +298 353912
>Mobile:             +298 580800
>Fax:                 +298 353901
>E-mail:              luisr at frs.fo
>Web:                www.frs.fo
>

> 
> Dear ALL,
> 
> I fear my question has already been answered many times 
> before, but I haven't fund that in archives...
> 
> I am working on spatial datasets and, in most arrays I'm 
> handling, there are two columns dedicated to (x,y)-coords. 
> For different reasons - notably to draw image() plots, I need 
> to have these two columns sorted in increasing order. But 
> sort() and order() seem to apply to vectors - or one single 
> column - only.
> 
> Could somedy please let me know how to sort two columns of a 
> dataframe, with priority to one of them, just like in access ?
> 
> Thanks,
> 
> Jacques VESLOT
> CIRAD
> 
> Another related question :
> How to put legend on image() plots - or image-based plots like
> image.kriging() in geoR ?
> Despite help pages, I haven't succeeded.
> 
> 
> 
> -----------------------------------------------------
> CIRAD 3P Reunion - MailScanner
> ----------------------------------------------------- 
> Ce message a ??t?? v??rifi?? par MailScanner
> et analyse par 4 antivirus :
> ClamAv - BitDefender - F-Prot - Panda.
> 
> Aucun virus,ni rien de suspect n'a ??t?? trouv??.
> 
> This message has been scanned for viruses and
> dangerous content, and is believed to be clean.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jacques.veslot at cirad.fr  Wed Jul 21 09:27:50 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Wed, 21 Jul 2004 11:27:50 +0400
Subject: [R] How to sort TWO columns ?
In-Reply-To: <40FE11A2.5050303@statistik.uni-dortmund.de>
Message-ID: <HHEDKBCGCMDOHEDELFBCGEPBCAAA.jacques.veslot@cirad.fr>

Sorry sorry,
I didn't pay enough attention to order() help pages indeed...
and it costs me much useless indexing.

As concerns how to put legend in image() plot, is there a piece of
information about somewhere ?
thanks a lot for helping,

Jacques VESLOT







-----Message d'origine-----
De : Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
Envoy?? : mercredi 21 juillet 2004 10:48
?? : jacques.veslot at cirad.fr
Cc : r-help at stat.math.ethz.ch
Objet : Re: [R] How to sort TWO columns ?


Jacques VESLOT wrote:

> Dear ALL,
>
> I fear my question has already been answered many times before, but I
> haven't fund that in archives...
>
> I am working on spatial datasets and, in most arrays I'm handling, there
are
> two columns dedicated to (x,y)-coords.
> For different reasons - notably to draw image() plots, I need to have
these
> two columns sorted in increasing order.
> But sort() and order() seem to apply to vectors - or one single column -
> only.
>
> Could somedy please let me know how to sort two columns of a dataframe,
with
> priority to one of them, just like in access ?

See ?order

Uwe Ligges


> Thanks,
>
> Jacques VESLOT
> CIRAD
>
> Another related question :
> How to put legend on image() plots - or image-based plots like
> image.kriging() in geoR ?
> Despite help pages, I haven't succeeded.
>
>
>
> -----------------------------------------------------
> CIRAD 3P Reunion - MailScanner
> -----------------------------------------------------
> Ce message a ??t?? v??rifi?? par MailScanner
> et analyse par 4 antivirus :
> ClamAv - BitDefender - F-Prot - Panda.
>
> Aucun virus,ni rien de suspect n'a ??t?? trouv??.
>
> This message has been scanned for viruses and
> dangerous content, and is believed to be clean.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


-----------------------------------------------------
CIRAD 3P Reunion - MailScanner
-----------------------------------------------------
Ce message a ??t?? v??rifi?? par MailScanner
et analyse par 4 antivirus :
ClamAv - BitDefender - F-Prot - Panda.

Aucun virus,ni rien de suspect n'a ??t?? trouv??.

This message has been scanned for viruses and
dangerous content, and is believed to be clean.
-----------------------------------------------------


-----------------------------------------------------
CIRAD 3P Reunion - MailScanner
----------------------------------------------------- 
Ce message a ??t?? v??rifi?? par MailScanner
et analyse par 4 antivirus :
ClamAv - BitDefender - F-Prot - Panda.

Aucun virus,ni rien de suspect n'a ??t?? trouv??.

This message has been scanned for viruses and
dangerous content, and is believed to be clean.



From vito_ricci at yahoo.com  Wed Jul 21 09:34:42 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Wed, 21 Jul 2004 09:34:42 +0200 (CEST)
Subject: [R] Testing autocorrelation & heteroskedasticity of residuals in ts
Message-ID: <20040721073442.57641.qmail@web41204.mail.yahoo.com>

Hi,

I'm dealing with time series. I usually use stl() to
estimate trend, stagionality and residuals. I test for
normality of residuals using shapiro.test(), but I
can't test for autocorrelation and heteroskedasticity.
Is there a way to perform Durbin-Watson test and
Breusch-Pagan test (or other simalar tests) for time
series?
I find dwtest() and bptest() in the package lmtest,
but it requieres an lm object, while I've a ts object.
Any help will be appreciated.
Best
Vito

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From ligges at statistik.uni-dortmund.de  Wed Jul 21 09:44:00 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 Jul 2004 09:44:00 +0200
Subject: [R] How to sort TWO columns ?
In-Reply-To: <HHEDKBCGCMDOHEDELFBCGEPBCAAA.jacques.veslot@cirad.fr>
References: <HHEDKBCGCMDOHEDELFBCGEPBCAAA.jacques.veslot@cirad.fr>
Message-ID: <40FE1EC0.2050907@statistik.uni-dortmund.de>

Jacques VESLOT wrote:

> Sorry sorry,
> I didn't pay enough attention to order() help pages indeed...
> and it costs me much useless indexing.
> 
> As concerns how to put legend in image() plot, is there a piece of
> information about somewhere ?
> thanks a lot for helping,
> 
> Jacques VESLOT
> 

In the same way as in usual plots.
Note that filled.contour() might be another choice of such a plot that 
already plots a legend ...

Uwe Ligges


> 
> 
> 
> 
> 
> -----Message d'origine-----
> De : Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Envoy?? : mercredi 21 juillet 2004 10:48
> ?? : jacques.veslot at cirad.fr
> Cc : r-help at stat.math.ethz.ch
> Objet : Re: [R] How to sort TWO columns ?
> 
> 
> Jacques VESLOT wrote:
> 
> 
>>Dear ALL,
>>
>>I fear my question has already been answered many times before, but I
>>haven't fund that in archives...
>>
>>I am working on spatial datasets and, in most arrays I'm handling, there
> 
> are
> 
>>two columns dedicated to (x,y)-coords.
>>For different reasons - notably to draw image() plots, I need to have
> 
> these
> 
>>two columns sorted in increasing order.
>>But sort() and order() seem to apply to vectors - or one single column -
>>only.
>>
>>Could somedy please let me know how to sort two columns of a dataframe,
> 
> with
> 
>>priority to one of them, just like in access ?
> 
> 
> See ?order
> 
> Uwe Ligges
> 
> 
> 
>>Thanks,
>>
>>Jacques VESLOT
>>CIRAD
>>
>>Another related question :
>>How to put legend on image() plots - or image-based plots like
>>image.kriging() in geoR ?
>>Despite help pages, I haven't succeeded.
>>
>>
>>
>>-----------------------------------------------------
>>CIRAD 3P Reunion - MailScanner
>>-----------------------------------------------------
>>Ce message a ??t?? v??rifi?? par MailScanner
>>et analyse par 4 antivirus :
>>ClamAv - BitDefender - F-Prot - Panda.
>>
>>Aucun virus,ni rien de suspect n'a ??t?? trouv??.
>>
>>This message has been scanned for viruses and
>>dangerous content, and is believed to be clean.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
> 
> http://www.R-project.org/posting-guide.html
> 
> 
> -----------------------------------------------------
> CIRAD 3P Reunion - MailScanner
> -----------------------------------------------------
> Ce message a ??t?? v??rifi?? par MailScanner
> et analyse par 4 antivirus :
> ClamAv - BitDefender - F-Prot - Panda.
> 
> Aucun virus,ni rien de suspect n'a ??t?? trouv??.
> 
> This message has been scanned for viruses and
> dangerous content, and is believed to be clean.
> -----------------------------------------------------
> 
> 
> -----------------------------------------------------
> CIRAD 3P Reunion - MailScanner
> ----------------------------------------------------- 
> Ce message a ??t?? v??rifi?? par MailScanner
> et analyse par 4 antivirus :
> ClamAv - BitDefender - F-Prot - Panda.
> 
> Aucun virus,ni rien de suspect n'a ??t?? trouv??.
> 
> This message has been scanned for viruses and
> dangerous content, and is believed to be clean.
> -----------------------------------------------------
>



From Bernhard.Pfaff at drkw.com  Wed Jul 21 09:55:04 2004
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Wed, 21 Jul 2004 09:55:04 +0200
Subject: [R] regression slope
Message-ID: <18D602BD42B7E24EB810D6454A58DB900A29BA16@ibfftce505.de.ad.drkw.net>

see also the contributed document by John Verzani, Simple R, page 87f.

> Adaikalavan Ramasamy wrote:
> 
> > I would try to construct the confidence intervals and 
> compare them to
> > the value that you want
> > 
> >>x <- rnorm(20)
> >>y <- 2*x + rnorm(20)
> >>summary( m1 <- lm(y~x) )
> > 
> > 
> > <snip>
> > Coefficients:
> >             Estimate Std. Error t value Pr(>|t|)
> > (Intercept)   0.1418     0.1294   1.095    0.288
> > x             2.2058     0.1289  17.108  1.4e-12 ***
> > <snip>
> > 
> > That says that the slope estimate is 2.2058 with standard error of
> > 0.1289. So the approximate 99% CI is 2.2058 +/- 3*0.1289 = (1.819,
> > 2.593) which is clearly greater than 1.
> > 
> > 
> >>summary(m1)[[4]][2,1] + 3* summary(m1)[[4]][2,2]
> > 
> > [1] 2.592629
> > 
> >>summary(m1)[[4]][2,1] - 3* summary(m1)[[4]][2,2]
> > 
> > [1] 1.819026
> > 
> 


> I think the preferred way of doing this is with confint:
> 
> # 3 sigma limits
> confint(m1, parm = "x", level = 1 - pt(-3, m1$df.resid) * 2)
> # 95% confidence (default)
> confint(m1, parm = "x")
> 
> > For your next question, you simply compare the CI of one slope to
> > another and see if they overlap. 
> > 
> > There is probably a way to construct proper significance 
> testing to get
> > p-values and such. You can try reading MASS4 or hopefully 
> someone in the
> > list might provide with a neater answer.
> > 
> > 
> > On Tue, 2004-07-20 at 17:02, Avril Coghlan wrote:
> > 
> >>Hello,
> >>
> >>  I'm a newcomer to R so please
> >>forgive me if this is a silly question.
> >>
> >>It's that I have a linear regression:
> >>fm <- lm (x ~ y)
> >>and I want to test whether the
> >>slope of the regression is significantly
> >>less than 1. How can I do this in R?
> >>
> >>I'm also interested in comparing the
> >>slopes of two regressions:
> >>fm1 <- lm (x ~ y)
> >>fm2 <- lm (a ~ b)
> >>and asking if the slope of fm1 is
> >>less than the slope of fm2. Is this
> >>easy to do in R?
> >>
> >>
> >>I will be very grateful for any help.
> >>
> >>regards,
> >>Avril Coghlan
> >>(University College Dublin, Ireland)
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From Bernhard.Pfaff at drkw.com  Wed Jul 21 10:28:41 2004
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Wed, 21 Jul 2004 10:28:41 +0200
Subject: [R] Testing autocorrelation & heteroskedasticity of residuals in
	ts
Message-ID: <18D602BD42B7E24EB810D6454A58DB900A29BA17@ibfftce505.de.ad.drkw.net>

> 
> Hi,
> 
> I'm dealing with time series. I usually use stl() to
> estimate trend, stagionality and residuals. I test for
> normality of residuals using shapiro.test(), but I
> can't test for autocorrelation and heteroskedasticity.
> Is there a way to perform Durbin-Watson test and
> Breusch-Pagan test (or other simalar tests) for time
> series?
> I find dwtest() and bptest() in the package lmtest,

Hello Vito,

how about:

library(lmtest)
data(nottem)
test <- summary(stl(nottem, s.win=4))
bptest(formula(nottem ~ -1 + test$time.series[,1] + test$time.series[,2]))
dwtest(formula(nottem ~ -1 + test$time.series[,1] + test$time.series[,2]))

i.e. you define the residuals by providing the residuals as formula. 
Note:
testres <- nottem-test$time.series[,1]-test$time.series[,2]
cbind(testres, test$time.series[,3])

Anyway, are these tests applicable to stl as far as the underlying
assumptions for the error term is concerned?

Bernhard


> but it requieres an lm object, while I've a ts object.
> Any help will be appreciated.
> Best
> Vito
> 
> =====
> Diventare costruttori di soluzioni
> 
> Visitate il portale http://www.modugno.it/
> e in particolare la sezione su Palese 
http://www.modugno.it/archivio/cat_palese.shtml

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From Claudio_Donati at chiron.it  Wed Jul 21 10:41:24 2004
From: Claudio_Donati at chiron.it (Donati, Claudio)
Date: Wed, 21 Jul 2004 10:41:24 +0200
Subject: [R] error "evaluation nested too deeply" {was "Heatmap"}
Message-ID: <1090399284.5710.4.camel@chisieW48QD.siena.chiron.com>

Hi,

Trying to plot a large dendrogram, I get the recursion limit error


	Error in match.fun(FUN) : evaluation nested too deeply: infinite
recursion / options(expression=)?

 but setting

 	options(expressions = 10000)

or something large enough to solve the infinite recursion  limit
problem,


I get 

	Error: protect(): stack overflow


Is there anything that can be done?

Thanks

Claudio Donati



From JonesW at kssg.com  Wed Jul 21 10:41:07 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Wed, 21 Jul 2004 09:41:07 +0100
Subject: [R] Testing autocorrelation & heteroskedasticity of residuals
	in ts
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02BD126B@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040721/134275a4/attachment.pl

From Achim.Zeileis at wu-wien.ac.at  Wed Jul 21 11:32:58 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 21 Jul 2004 11:32:58 +0200
Subject: [R] Testing autocorrelation & heteroskedasticity of residuals
	in ts
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB900A29BA17@ibfftce505.de.ad.drkw.net>
References: <18D602BD42B7E24EB810D6454A58DB900A29BA17@ibfftce505.de.ad.drkw.net>
Message-ID: <20040721113258.4a902f17.Achim.Zeileis@wu-wien.ac.at>

On Wed, 21 Jul 2004 10:28:41 +0200 Pfaff, Bernhard wrote:

> > 
> > Hi,
> > 
> > I'm dealing with time series. I usually use stl() to
> > estimate trend, stagionality and residuals. I test for
> > normality of residuals using shapiro.test(), but I
> > can't test for autocorrelation and heteroskedasticity.
> > Is there a way to perform Durbin-Watson test and
> > Breusch-Pagan test (or other simalar tests) for time
> > series?
> > I find dwtest() and bptest() in the package lmtest,
> 
> Hello Vito,
> 
> how about:
> 
> library(lmtest)
> data(nottem)
> test <- summary(stl(nottem, s.win=4))
> bptest(formula(nottem ~ -1 + test$time.series[,1] +
> test$time.series[,2])) dwtest(formula(nottem ~ -1 +
> test$time.series[,1] + test$time.series[,2]))
> 
> i.e. you define the residuals by providing the residuals as formula. 
> Note:
> testres <- nottem-test$time.series[,1]-test$time.series[,2]
> cbind(testres, test$time.series[,3])

Further note that testres are not the residuals that you supply to
dwtest() above because the coefficients are

R> coef(lm(formula(nottem ~ -1 + test$time.series[,1] +
        test$time.series[,2])))
test$time.series[, 1] test$time.series[, 2] 
            0.9988047             1.0002117 

but they are close to 1.

Anyway: for dwtest() I would probably just supply the residuals and
regress them on a constant.

R> dwtest(test$time.series[,3] ~ 1)

which is very close to Bernhard's suggestion but a bit simpler.

For bptest() you could do something like

bptest(test$time.series[,3] ~ 1 ,
       varformula = ~ -1 + test$time.series[,1] + test$time.series[,2]) 

if that is the model you would like to test. At least it makes more
explicit what is tested.

> Anyway, are these tests applicable to stl as far as the underlying
> assumptions for the error term is concerned?

I don't know any formal results about this but it should not be
difficult to find a set of assumptions where a nonparametric estimate of
trend and season via STL yields a stationary, independent and
homoskedastic sequence of the residuals. (whether these apply to Vito's
data is of course a different question :))

Best,
Achim


 
> Bernhard
> 
> 
> > but it requieres an lm object, while I've a ts object.
> > Any help will be appreciated.
> > Best
> > Vito
> > 
> > =====
> > Diventare costruttori di soluzioni
> > 
> > Visitate il portale http://www.modugno.it/
> > e in particolare la sezione su Palese 
> http://www.modugno.it/archivio/cat_palese.shtml
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 
> ---------------------------------------------------------------------
> ----------- The information contained herein is confidential and is
> inte...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Wed Jul 21 12:01:33 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 21 Jul 2004 06:01:33 -0400
Subject: [R] Cutting heatmap dendrogram
In-Reply-To: <CPEAKHBKLBNIKJDIELLCEEOBCKAA.Paul.Boutros@utoronto.ca>
References: <CPEAKHBKLBNIKJDIELLCEEOBCKAA.Paul.Boutros@utoronto.ca>
Message-ID: <F2486EFA-DAFC-11D8-BCBC-000A95D7BA10@mail.nih.gov>

Paul,

You can certainly get a heatmap of a subset of your data by simply 
subsetting.  If you have a group of genes obtained from cutree, simply 
do a heatmap on that set of genes.  If you obtain a set of genes, say 
A, and want to do a heatmap on that subset, simply do 
heatmap(as.matrix(data[A,])) where A contains either a logical vector 
or indices for the genes of interest.  The dendrograms will be 
generated for those samples and genes based on the subset of data.  You 
could, of course, pass in the sample dendrogram from the original 
clustering of all genes if you like.

It sounds like you are aiming for interactive clustering, which R does 
not do well.  Consider using an external viewer such as the 
cluster/treeview combo or the TIGR clustering program (can't remember 
name).

Finally, for future reference, it is probably worthwhile posting 
microarray questions to the Bioconductor mailing list rather than 
R-Help.

Sean

On Jul 20, 2004, at 9:39 PM, Paul Boutros wrote:

> Hello,
>
> I've been clustering my data using hclust and cutting the resulting 
> tree
> with cutree.  Separately, I visualize the clusterings with heatmap.  
> Is it
> possible to have the dendrogram on the heatmap reflect the cutree 
> results?
> That is, instead of having one large dendrogram, it would have 4 or 25 
> in
> the example below.  Any guidance on if that's possible or not, and what
> kinds of commands I should be looking into would be very much 
> appreciated.
> I'm using R 1.9.0 on Windows XP.
>
> Thanks!
> Paul
>
> # load libraries
> library(stats);
>
> # working copy of data
> set1 <- as.matrix(data);
> set2 <- t(set1);
>
> # genes
> genes.distance <- as.dist(1-cor(set2));
> genes.clusters <- hclust(genes.distance);
> genes.dendrogr <- as.dendrogram(genes.clusters);
>
> # samples
> samples.distance <- as.dist(1-cor(set1));
> samples.clusters <- hclust(samples.distance1);
> samples.dendrogr <- as.dendrogram(samples.clusters1);
>
> # cut the trees
> samples.members  <- cutree(samples.clusters, k=4);
> genes.members    <- cutree(genes.clusters,   k=25);
>
> # heatmap colouring
> my.colors <- function(n = 20, low.col = 0.35, high.col=1, saturation = 
> 0.85)
> {
>   if (n < 2) stop("n must be greater than 2")
>   n1 <- n%/%2
>   n2 <- n - n1
>   c(hsv(low.col, saturation, seq(1,0,length=n1)),
>      hsv(high.col, saturation, seq(0,1,length=n2)))
> }
>
> # make the heatmap
> hv <- heatmap(as.matrix(data), Rowv=genes.dendrogr, 
> Colv=samples.dendrogr,
> col=my.colors());
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Wed Jul 21 12:22:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 21 Jul 2004 06:22:32 -0400
Subject: [R] nonparametetric bivariate regression
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80B8@usrymx25.merck.com>

There may very well be others, but these packages ought to get you started:
locfit, sm, and if I'm not mistaken, mgcv (which is shipped with R).

Andy

> From: ximing wu
> 
> Hi there,
> Does R has built-in codes for nonpara. bivariate regression 
> so that I can 
> estimate the joint distribution of two variables as a 
> function of some 
> covariates? Thanks a lot.
> 
> 
> ---------------------------------------------------
> Ximing Wu
> Department of Economics
> University of Guelph
> Guelph, Ontario, Canada, N1G 2W1
> 
> Tel: (519) 842-4120, ext 53014
> Fax: (519) 763-8497
> email: xiwu at uoguelph.ca
> Webpage: http://www.uoguelph.ca/~xiwu/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From maechler at stat.math.ethz.ch  Wed Jul 21 12:25:21 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 Jul 2004 12:25:21 +0200
Subject: [R] Cutting heatmap dendrogram
In-Reply-To: <F2486EFA-DAFC-11D8-BCBC-000A95D7BA10@mail.nih.gov>
References: <CPEAKHBKLBNIKJDIELLCEEOBCKAA.Paul.Boutros@utoronto.ca>
	<F2486EFA-DAFC-11D8-BCBC-000A95D7BA10@mail.nih.gov>
Message-ID: <16638.17553.173756.722315@gargle.gargle.HOWL>

>>>>> "Sean" == Sean Davis <sdavis2 at mail.nih.gov>
>>>>>     on Wed, 21 Jul 2004 06:01:33 -0400 writes:

    Sean> Paul, You can certainly get a heatmap of a subset of
    Sean> your data by simply subsetting.  If you have a group
    Sean> of genes obtained from cutree, simply do a heatmap on
    Sean> that set of genes.  If you obtain a set of genes, say
    Sean> A, and want to do a heatmap on that subset, simply do
    Sean> heatmap(as.matrix(data[A,])) where A contains either a
    Sean> logical vector or indices for the genes of interest.
    Sean> The dendrograms will be generated for those samples
    Sean> and genes based on the subset of data.  You could, of
    Sean> course, pass in the sample dendrogram from the
    Sean> original clustering of all genes if you like.

this was probably helpful but didn't really answer the original question.

One thing you (Paul) should do is to "cut()" the dendrogram
instead of "cutree()"ing the hclust result and then *pass* the
cut()ed dendrogram directly to heatmap(). 

I'm interested to hear if that works (haven't got time to
experiment with that just now).

    Sean> It sounds like you are aiming for interactive
    Sean> clustering, which R does not do well.  Consider using
    Sean> an external viewer such as the cluster/treeview combo
    Sean> or the TIGR clustering program (can't remember name).

    Sean> Finally, for future reference, it is probably worthwhile posting 
    Sean> microarray questions to the Bioconductor mailing list rather than 
    Sean> R-Help.

I disagree.  This was a question about heatmap() an R function
of more general use than microarrays.
I would have found it "wrong" to ask this question on the
bioconductor mailing list.

Martin Maechler

    Sean> Sean

    Sean> On Jul 20, 2004, at 9:39 PM, Paul Boutros wrote:

    >> Hello,
    >> 
    >> I've been clustering my data using hclust and cutting the resulting 
    >> tree
    >> with cutree.  Separately, I visualize the clusterings with heatmap.  
    >> Is it
    >> possible to have the dendrogram on the heatmap reflect the cutree 
    >> results?
    >> That is, instead of having one large dendrogram, it would have 4 or 25 
    >> in
    >> the example below.  Any guidance on if that's possible or not, and what
    >> kinds of commands I should be looking into would be very much 
    >> appreciated.
    >> I'm using R 1.9.0 on Windows XP.
    >> 
    >> Thanks!
    >> Paul
    >> 
    >> # load libraries
    >> library(stats);
    >> 
    >> # working copy of data
    >> set1 <- as.matrix(data);
    >> set2 <- t(set1);
    >> 
    >> # genes
    >> genes.distance <- as.dist(1-cor(set2));
    >> genes.clusters <- hclust(genes.distance);
    >> genes.dendrogr <- as.dendrogram(genes.clusters);
    >> 
    >> # samples
    >> samples.distance <- as.dist(1-cor(set1));
    >> samples.clusters <- hclust(samples.distance1);
    >> samples.dendrogr <- as.dendrogram(samples.clusters1);
    >> 
    >> # cut the trees
    >> samples.members  <- cutree(samples.clusters, k=4);
    >> genes.members    <- cutree(genes.clusters,   k=25);
    >> 
    >> # heatmap colouring
    >> my.colors <- function(n = 20, low.col = 0.35, high.col=1, saturation = 
    >> 0.85)
    >> {
    >> if (n < 2) stop("n must be greater than 2")
    >> n1 <- n%/%2
    >> n2 <- n - n1
    >> c(hsv(low.col, saturation, seq(1,0,length=n1)),
    >> hsv(high.col, saturation, seq(0,1,length=n2)))
    >> }
    >> 
    >> # make the heatmap
    >> hv <- heatmap(as.matrix(data), Rowv=genes.dendrogr, 
    >> Colv=samples.dendrogr,
    >> col=my.colors());
    >>



From bates at stat.wisc.edu  Wed Jul 21 12:30:46 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 21 Jul 2004 05:30:46 -0500
Subject: [R] regression slope
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB900A29BA16@ibfftce505.de.ad.drkw.net>
References: <18D602BD42B7E24EB810D6454A58DB900A29BA16@ibfftce505.de.ad.drkw.net>
Message-ID: <40FE45D6.5040308@stat.wisc.edu>

>>>On Tue, 2004-07-20 at 17:02, Avril Coghlan wrote:
>>>
>>>
>>>>Hello,
>>>>
>>>> I'm a newcomer to R so please
>>>>forgive me if this is a silly question.
>>>>
>>>>It's that I have a linear regression:
>>>>fm <- lm (x ~ y)
>>>>and I want to test whether the
>>>>slope of the regression is significantly
>>>>less than 1. How can I do this in R?

Another way of doing this is to use offset(x) in the model formula

summary(fm <- lm(y ~ x + offset(x)))

(I know you wrote lm(x ~ y) but I find I have to think of it as lm(y ~ 
x) - old habits are hard to break.)

If you want to test for "slope is significantly less than 2" you would use

summary(fm <- lm(y ~ x + offset(2*x)))



From Christian.Stratowa at vie.boehringer-ingelheim.com  Wed Jul 21 13:19:59 2004
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Wed, 21 Jul 2004 13:19:59 +0200
Subject: [R] RE: Comparison of correlation coefficients - Details
Message-ID: <F848C7E68BD94E489A03F6C2351BB0013CFD98@vieex02.eu.boehringer.com>

Dear all

I apologize for cross-posting, but first it is accepted custom to 
thank the repliers and give a summary, and second I have still 
the feeling that this problem might be a general statistical problem 
and not necessarily related to microarrays only, but I might be wrong.

First, I want to thank Robert Gentleman, Mark Kimpel and Mark Reiners
for their kind replies. Robert Gentleman kindly pointed me to the
Bioconductor package "MeasurementError.cor" as alternative to "cor.test".
Mark Kimpel suggested that 2-way factorial Anova or the Bioconductor
package "limma", respectively, may be helpful. Mark Reiners suggested
to use the p-value of "cor.test" to test the significance.

Maybe, I miss the point, but being not a statistician I am still unsure
if it is possible to compare correlation coefficients from different 
sample sets. Both, the p-values from "cor.test" and from "compcorr",
could be used as measure of the significance. 
However, is it possible to "normalize" correlation coefficients from
different sample sets? Could an expression such as "corr * (1 - pval)" 
be used for normalization? Maybe, it is not possible to normalize
correlation coefficients?
Would a barplot comparing the correlation coefficients between two
genes for different tissues be meaningful? (Alternatively, I have 
tried to use (1-pval) to calculate the gray-level of the bars.)

Any further suggestions would be appreciated very much.

Best regards
Christian Stratowa

-----Original Message-----
From: Stratowa,Dr.,Christian FEX BIG-AT-V 
Sent: Monday, July 19, 2004 15:00
To: 'bioconductor at stat.math.ethz.ch'
Subject: Comparison of correlation coefficients - Details


Dear all

Maybe, my last mail did not explain my problem correctly:
Since we are interested, which genes have similar expression profiles in a
certain tissue or in different tissues, we have calculated the 
correlation coefficients between all 46,000 x 46,000 genes of the 
HG_U133A/B chipset for about 70 tissues, where the number of samples 
per tissue ranges from 10 to more than 200.

While writing an R-function to display the correlation coefficients between
gene A and B in the different tissues as bar-graph, I realized that it may
not be correct to compare the different correlation coefficients directly,
since the number of samples per tissue varyies between 10 and 200.

Thus, the question is: Is there a way to compare different correlation
coefficients and/or apply some kind of normalization?

Assuming that this might be a well known statistical problem I was browsing
statistics books and the web for more information, but could only find the
function "compcorr" which gives a p-value how well you can trust the 
comparison of two correlation coefficients from different samples.

Even though this might currently not be a direct Bioconductor question, it
is certainly a microarray analysis related question. Any suggestions how to
solve this problem would be greatly appreciated.

Best regards
Christian Stratowa


-----Original Message-----
From: Stratowa,Dr.,Christian FEX BIG-AT-V 
Sent: Tuesday, July 13, 2004 14:40
To: 'bioconductor at stat.math.ethz.ch'
Subject: Comparison of correlation coefficients


Dear Bioconductor expeRts

Is it possible to compare correlation coefficients or to normalize 
different correlation coefficients?

Concretely, we have the following situation:
We have gene expression profiles for different tissues, where the 
number of samples per tissue are different, ranging from 10 to 250. 
We are able to determine the correlation between two genes A and B 
for each tissue separately, using "cor.test". However, the question 
arises if the correlation coefficients between different tissues can 
be compared or if they must somehow be "normalized", since the 
number of samples per tissue varyies. 

Searching the web I found the function "compcorr", see:
http://www.fon.hum.uva.nl/Service/Statistics/Two_Correlations.html
http://ftp.sas.com/techsup/download/stat/compcorr.html
and implemented it in R:

compcorr <- function(n1, r1, n2, r2){
# compare two correlation coefficients
# return difference and p-value as list(diff, pval)

#	Fisher Z-transform
	zf1 <- 0.5*log((1 + r1)/(1 - r1))
	zf2 <- 0.5*log((1 + r2)/(1 - r2))

#	difference
	dz <- (zf1 - zf2)/sqrt(1/(n1 - 3) + (1/(n2 - 3)))

#	p-value
	pv <- 2*(1 - pnorm(abs(dz)))

	return(list(diff=dz, pval=pv))
}

Would it make sense to use the resultant p-value to "normalize" the 
correlation coefficients, using: corr <- corr * compcorr()$pval

Is there a better way or an alternative to "normalize" the correlation 
coefficients obtained for different tissues?

Thank you in advance for your help.
Since in the company I am not subscribed to bioconductor-help, could you 
please reply to me (in addition to bioconductor-help)

P.S.: I have posted this first at r-help and it was suggested to me to 
post it here, too.

Best regards
Christian Stratowa

==============================================
Christian Stratowa, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2470
Fax: ++43-1-80105-2782
email: christian.stratowa at vie.boehringer-ingelheim.com



From bhx2 at mevik.net  Wed Jul 21 13:48:53 2004
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Wed, 21 Jul 2004 13:48:53 +0200
Subject: [R] Precision in R
In-Reply-To: <3B210A05-DA65-11D8-B8F7-000A9591E11C@musc.edu>
	(adelmaas@musc.edu's message of "Tue, 20 Jul 2004 11:55:32 -0400")
References: <3B210A05-DA65-11D8-B8F7-000A9591E11C@musc.edu>
Message-ID: <m0llhdbmxm.fsf@bar.nemo-project.org>

Since you didn't say anything about _what_ you did, either in SAS or
R, my first thought was:  Have you checked that you use the same
parametrization of the models in R and SAS?

-- 
Bj??rn-Helge Mevik



From rolf at math.unb.ca  Wed Jul 21 13:55:34 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 21 Jul 2004 08:55:34 -0300 (ADT)
Subject: [R] Precision in R
Message-ID: <200407211155.i6LBtYQc013637@erdos.math.unb.ca>

Bj??rn-Helge Mevik wrote:

> Since you didn't say anything about _what_ you did, either in SAS or
> R, my first thought was:  Have you checked that you use the same
> parametrization of the models in R and SAS?

	Good point!

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From laura at env.leeds.ac.uk  Wed Jul 21 14:41:36 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Wed, 21 Jul 2004 13:41:36 +0100 (BST)
Subject: [R] PCA of vectors
Message-ID: <Pine.LNX.4.44.0407211337360.25167-100000@env-pc-phd13>

Hello,

Is it possible to perform PCA using princomp or prcomp on two-component
wind data - ie wind vectors? If not, is anyone able to advise on a
suitable methodology for acheiving this? My data is a time series of
observations taken at different locations.

Thank you in advance for any hints!
Laura

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From Lars.Peters at Uni-Konstanz.de  Wed Jul 21 14:48:51 2004
From: Lars.Peters at Uni-Konstanz.de (Lars Peters)
Date: Wed, 21 Jul 2004 14:48:51 +0200
Subject: [R] Rose Diagrams
Message-ID: <20040721124923.6B8E41F8005@viribus.rz.uni-konstanz.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040721/58432ec0/attachment.pl

From schaber at molgen.mpg.de  Wed Jul 21 14:52:38 2004
From: schaber at molgen.mpg.de (Joerg Schaber)
Date: Wed, 21 Jul 2004 14:52:38 +0200
Subject: [R] MySQL mismatch
Message-ID: <40FE6716.3030502@molgen.mpg.de>

Hi,

library(RMySQL) works, but connecting to the database results in

Warning message:
RS-DBI driver warning: (MySQL mismatch between compiled version 3.23.49 
and runtime version 3.23.51)


Any idea?

Thanks,

joerg



From Matthias.Templ at statistik.gv.at  Wed Jul 21 14:58:48 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Wed, 21 Jul 2004 14:58:48 +0200
Subject: [R] Rose Diagrams
Message-ID: <83536658864BC243BE3C06D7E936ABD501BE1897@xchg1.statistik.gv.at>

Hi,

library(CircStats)
?rose.diag

Hope this helps,

Matthias

> Hi,
> 
> Is it possible to create Rose Diagrams of wind data (speed & 
> direction) with R??
> 
> Best regards,
> 
> Lars Peters
> 
> 
> -----
> Lars Peters
> 
> University of Konstanz
> Limnological Institute
> D-78457 Konstanz
> Germany
> 
> phone: +49 (0)7531 88-2930
> fax:   +49 (0)7531 88-3533
> e-mail: Lars.Peters at Uni-Konstanz.de
> web: Lars Peters 
> <http://www.uni-> konstanz.de/sfb454/tp_eng/A1/doc/peters/peters.html>

> 
> Zoobenthos group 
> <http://www.uni-> konstanz.de/sfb454/tp_eng/A1/index.htm> 
> CRC 
> 454 - Littoral 
> of Lake Constance <http://www.uni-konstanz.de/sfb454/> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From GERMAIDR at nv.doe.gov  Wed Jul 21 15:43:33 2004
From: GERMAIDR at nv.doe.gov (Germain, David)
Date: Wed, 21 Jul 2004 06:43:33 -0700
Subject: [R] Rose Diagrams
Message-ID: <8B401868B80DAB4DB3D11C2B116AF55B1651F8@nlv-exchange3.nv.doe.gov>

Lars,

Look at diag.rose in CircStats and circular packages.

I haven't used these, but I may need to in the future.

David Germain
Las Vegas


-----Original Message-----
From: Lars Peters [mailto:Lars.Peters at Uni-Konstanz.de] 
Sent: Wednesday, July 21, 2004 5:49 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Rose Diagrams

Hi,

Is it possible to create Rose Diagrams of wind data (speed & direction) with
R??

Best regards,

Lars Peters


-----
Lars Peters

University of Konstanz
Limnological Institute
D-78457 Konstanz
Germany

phone: +49 (0)7531 88-2930
fax:   +49 (0)7531 88-3533
e-mail: Lars.Peters at Uni-Konstanz.de
web: Lars Peters
<http://www.uni-konstanz.de/sfb454/tp_eng/A1/doc/peters/peters.html> 

Zoobenthos group <http://www.uni-konstanz.de/sfb454/tp_eng/A1/index.htm> 
CRC 454 - Littoral of Lake Constance <http://www.uni-konstanz.de/sfb454/> 



	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ernesto at ipimar.pt  Wed Jul 21 16:03:43 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 21 Jul 2004 15:03:43 +0100
Subject: [R] MySQL mismatch
In-Reply-To: <40FE6716.3030502@molgen.mpg.de>
References: <40FE6716.3030502@molgen.mpg.de>
Message-ID: <1090418623.29452.53.camel@gandalf.local>

On Wed, 2004-07-21 at 13:52, Joerg Schaber wrote:
> Hi,
> 
> library(RMySQL) works, but connecting to the database results in
> 
> Warning message:
> RS-DBI driver warning: (MySQL mismatch between compiled version 3.23.49 
> and runtime version 3.23.51)
> 
> 
> Any idea?
> 
> Thanks,
> 
> joerg

Joerg,

Have you tried a query ? I get the same message but it works fine. 

I think it results from different versions between the computer/moment
where/when RMySQL was installed and the computer/moment you're
accessing.

Regards

EJ



From Soichi.Hayashi at acxiom.com  Wed Jul 21 16:05:18 2004
From: Soichi.Hayashi at acxiom.com (Hayashi Soichi - shayas)
Date: Wed, 21 Jul 2004 09:05:18 -0500
Subject: [R] Can R work on very large of data?
Message-ID: <EA80FFF5E80CD5118A81009027DE9DFC0F477F28@conmsx05.corp.acxiom.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040721/70aaf2eb/attachment.pl

From spencer.graves at pdf.com  Wed Jul 21 16:09:48 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 21 Jul 2004 07:09:48 -0700
Subject: [R] dumpClass, hasSlot in R? 
Message-ID: <40FE792C.60103@pdf.com>

      Venables and Ripley (2000) R Programming (Springer, sec. 5.1) and 
Chambers (1998) Programming with Data (Springer) describe functions such 
as dumpClass and hasSlot that I can not find in R 1.9.1 for Windows nor 
in the "R site search".  What do people use for similar functionality?  
Also, what resources have people found useful for learning about S4 
classes, other than these 2 references? 

      Thanks, Spencer Graves



From wolski at molgen.mpg.de  Wed Jul 21 16:10:13 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 21 Jul 2004 16:10:13 +0200
Subject: [R] 2 images with 2 color scales on one graphic device. How to
 get it?
Message-ID: <200407211610130966.0BA5F280@mail.math.fu-berlin.de>

Hi!

Would like to plot two image plots with color scale (like levelplot (lattice) implements) in one graphic device.
Tried to plot 2 levelplot's (lattice) (the data has not much in common) in one graphics device by setting par(mfrwo=c(2,1)) which does not work.

Is there a way to force levelplot to use only a half of the graphic device?
Is there a function like image which provides the color scale and is working with par(mfrow, mfcol....?


Eryk



 

Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Kevin.Wang at maths.anu.edu.au  Wed Jul 21 16:14:56 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 22 Jul 2004 00:14:56 +1000 (EST)
Subject: [R] Can R work on very large of data?
In-Reply-To: <EA80FFF5E80CD5118A81009027DE9DFC0F477F28@conmsx05.corp.acxiom.net>
References: <EA80FFF5E80CD5118A81009027DE9DFC0F477F28@conmsx05.corp.acxiom.net>
Message-ID: <Pine.GSO.4.58.0407220013580.2791@yin>

Hi
On Wed, 21 Jul 2004, Hayashi Soichi - shayas wrote:

> Is there anyway I can tweak R around so that it will start processing as
> data comes and not load everthing on memory at once? The reason for this is

Have you read through R Data Import/Export?

There are several other ways, to name a few: scan() and RODBC -- I haven't
used the later though.

Cheers,

Kevin

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7411
Ph (M): +61-40-451-8301



From murdoch at stats.uwo.ca  Wed Jul 21 16:20:59 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 21 Jul 2004 10:20:59 -0400
Subject: [R] Can R work on very large of data?
In-Reply-To: <EA80FFF5E80CD5118A81009027DE9DFC0F477F28@conmsx05.corp.acxiom.net>
References: <EA80FFF5E80CD5118A81009027DE9DFC0F477F28@conmsx05.corp.acxiom.net>
Message-ID: <nhusf09376a31afvuf5mocf7noha40g74j@4ax.com>

On Wed, 21 Jul 2004 09:05:18 -0500, Hayashi Soichi - shayas
<Soichi.Hayashi at acxiom.com> wrote :

>Is there anyway I can tweak R around so that it will start processing as
>data comes and not load everthing on memory at once?

See the ?connections help topic.  You can open a file, and then read
lines from it in groups.  For example,

f <- file('MyData')
open(f)
read.table(f, nrows=100)
read.table(f, nrows=100)

  ...

close(f)

and so on.

Most functions in R won't know what do do with data handled in this
way; you'll have to do a lot of work to do your calculations in
pieces.

Duncan Murdoch



From andy_liaw at merck.com  Wed Jul 21 16:54:09 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 21 Jul 2004 10:54:09 -0400
Subject: [R] nonparametetric bivariate regression
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80C1@usrymx25.merck.com>

Ximing:  Hope you don't mind me cc'ing R-help.

> From: ximing wu
> 
> I am looking for something that can fit
> f(x,y)=g(z_1, z_2, z_3,...).
> 
> It seems that the packages you mentioned work for:
> z=f(x,y).
> 
> Correct me if I am wrong. Thanks anyway for your help.

You're right.  My mistake.  I don't know of packages (or even methods) that
fits the joint distribution.  However, if you're willing to settle for
regression, the polymars() function in the package `polspline' claims to do
this.  mars() in the `mda' package will also accept matrix response, but I
don't know if it just treat the multiple responses as separate univariate
responses.

Cheers,
Andy

> At 06:22 AM 7/21/2004 -0400, you wrote:
> >There may very well be others, but these packages ought to 
> get you started:
> >locfit, sm, and if I'm not mistaken, mgcv (which is shipped with R).
> >
> >Andy
> >
> > > From: ximing wu
> > >
> > > Hi there,
> > > Does R has built-in codes for nonpara. bivariate regression
> > > so that I can
> > > estimate the joint distribution of two variables as a
> > > function of some
> > > covariates? Thanks a lot.
> > >
> > >
> > > ---------------------------------------------------
> > > Ximing Wu
> > > Department of Economics
> > > University of Guelph
> > > Guelph, Ontario, Canada, N1G 2W1
> > >
> > > Tel: (519) 842-4120, ext 53014
> > > Fax: (519) 763-8497
> > > email: xiwu at uoguelph.ca
> > > Webpage: http://www.uoguelph.ca/~xiwu/
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > >
> >
> >
> >-------------------------------------------------------------
> -----------------
> >Notice:  This e-mail message, together with any attachments, 
> contains 
> >information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New 
> >Jersey, USA 08889), and/or its affiliates (which may be 
> known outside the 
> >United States as Merck Frosst, Merck Sharp & Dohme or MSD 
> and in Japan, as 
> >Banyu) that may be confidential, proprietary copyrighted 
> and/or legally 
> >privileged. It is intended solely for the use of the 
> individual or entity 
> >named on this message.  If you are not the intended 
> recipient, and have 
> >received this message in error, please notify us immediately 
> by reply 
> >e-mail and then delete it from your system.
> >-------------------------------------------------------------
> ----------------- 
> >
> 
> ---------------------------------------------------
> Ximing Wu
> Department of Economics
> University of Guelph
> Guelph, Ontario, Canada, N1G 2W1
> 
> Tel: (519) 842-4120, ext 53014
> Fax: (519) 763-8497
> email: xiwu at uoguelph.ca
> Webpage: http://www.uoguelph.ca/~xiwu/
> ----------------------------------------------------
> 
> 
>



From ligges at statistik.uni-dortmund.de  Wed Jul 21 17:08:45 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 Jul 2004 17:08:45 +0200
Subject: [R] 2 images with 2 color scales on one graphic device. How to
	get it?
In-Reply-To: <200407211610130966.0BA5F280@mail.math.fu-berlin.de>
References: <200407211610130966.0BA5F280@mail.math.fu-berlin.de>
Message-ID: <40FE86FD.5060002@statistik.uni-dortmund.de>

Wolski wrote:

> Hi!
> 
> Would like to plot two image plots with color scale (like levelplot (lattice) implements) in one graphic device.
> Tried to plot 2 levelplot's (lattice) (the data has not much in common) in one graphics device by setting par(mfrwo=c(2,1)) which does not work.
> 
> Is there a way to force levelplot to use only a half of the graphic device?
> Is there a function like image which provides the color scale and is working with par(mfrow, mfcol....?

?filled.contour

Uwe Ligges


> 
> Eryk
> 
> 
> 
>  
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
> Ihnestrasse 63-73 14195 Berlin       'v'    
> tel: 0049-30-83875219               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From paul.boutros at utoronto.ca  Wed Jul 21 18:03:39 2004
From: paul.boutros at utoronto.ca (paul.boutros@utoronto.ca)
Date: Wed, 21 Jul 2004 12:03:39 -0400
Subject: [R] Cutting heatmap dendrogram
Message-ID: <1090425819.40fe93db9341b@webmail.utoronto.ca>

Hi Sean, Martin

>>>>>> "Sean" == Sean Davis <sdavis2 at mail.nih.gov>
>>>>>>     on Wed, 21 Jul 2004 06:01:33 -0400 writes:

    Sean>> Paul, You can certainly get a heatmap of a subset of
    Sean>> your data by simply subsetting.  If you have a group
    Sean>> of genes obtained from cutree, simply do a heatmap on
    Sean>> that set of genes.  If you obtain a set of genes, say
    Sean>> A, and want to do a heatmap on that subset, simply do
    Sean>> heatmap(as.matrix(data[A,])) where A contains either a
    Sean>> logical vector or indices for the genes of interest.
    Sean>> The dendrograms will be generated for those samples
    Sean>> and genes based on the subset of data.  You could, of
    Sean>> course, pass in the sample dendrogram from the
    Sean>> original clustering of all genes if you like.

>this was probably helpful but didn't really answer the original question.

Yeah, I'm okay with getting subsets and plotting them separately, but the goal 
is to be able to automatically show and label the subsets on the heatmap itself.

>One thing you (Paul) should do is to "cut()" the dendrogram
>instead of "cutree()"ing the hclust result and then *pass* the
>cut()ed dendrogram directly to heatmap(). 

Ahh, that makes sense, but maybe I'm missing something?

###########################################
> samples.dendrogr2 <- cut(samples.dendrogr1, 4);
> samples.dendrogr2
$upper
`dendrogram' with 2 branches and 2 members total, at height 1.082017 

$lower
$lower[[1]]
`dendrogram' with 2 branches and 4 members total, at height 0.0631504 

$lower[[2]]
`dendrogram' with 2 branches and 12 members total, at height 0.5823986 


> plot(samples.dendrogr2);
Error in plot.window(xlim, ylim, log, asp, ...) : 
        need finite xlim values
In addition: Warning messages: 
1: no finite arguments to min; returning Inf 
2: no finite arguments to max; returning -Inf 
3: no finite arguments to min; returning Inf 
4: no finite arguments to max; returning -Inf

> hv <- heatmap(as.matrix(data), Rowv=genes.dendrogr, Colv=samples.dendrogr2); 
Error in lV + rV : non-numeric argument to binary operator

> traceback();
8: oV(x[[1]], wts)
7: oV(x[[1]], wts)
6: oV(x, wts)
5: inherits(x, "dendrogram")
4: midcache.dendrogram(oV(x, wts))
3: reorder.dendrogram(ddc, Colv)
2: reorder(ddc, Colv)
1: heatmap(as.matrix(data), Rowv = genes.dendrogr, Colv = samples.dendrogr2, 
       col = my.colors())
###########################################

Any ideas are (still) very much appreciated!
Paul

>I'm interested to hear if that works (haven't got time to
>experiment with that just now).

    Sean>> It sounds like you are aiming for interactive
    Sean>> clustering, which R does not do well.  Consider using
    Sean>> an external viewer such as the cluster/treeview combo
    Sean>> or the TIGR clustering program (can't remember name).

I'll check out MeV, then, but since the rest of my processing is in R....

    Sean>> Finally, for future reference, it is probably worthwhile posting 
    Sean>> microarray questions to the Bioconductor mailing list rather than 
    Sean>> R-Help.

>I disagree.  This was a question about heatmap() an R function
>of more general use than microarrays.
>I would have found it "wrong" to ask this question on the
>bioconductor mailing list.

>Martin Maechler

    Sean>> Sean

    Sean>> On Jul 20, 2004, at 9:39 PM, Paul Boutros wrote:

    >> Hello,
    >> 
    >> I've been clustering my data using hclust and cutting the resulting 
    >> tree
    >> with cutree.  Separately, I visualize the clusterings with heatmap.  
    >> Is it
    >> possible to have the dendrogram on the heatmap reflect the cutree 
    >> results?
    >> That is, instead of having one large dendrogram, it would have 4 or 25 
    >> in
    >> the example below.  Any guidance on if that's possible or not, and what
    >> kinds of commands I should be looking into would be very much 
    >> appreciated.
    >> I'm using R 1.9.0 on Windows XP.
    >> 
    >> Thanks!
    >> Paul
    >> 
    >> # load libraries
    >> library(stats);
    >> 
    >> # working copy of data
    >> set1 <- as.matrix(data);
    >> set2 <- t(set1);
    >> 
    >> # genes
    >> genes.distance <- as.dist(1-cor(set2));
    >> genes.clusters <- hclust(genes.distance);
    >> genes.dendrogr <- as.dendrogram(genes.clusters);
    >> 
    >> # samples
    >> samples.distance <- as.dist(1-cor(set1));
    >> samples.clusters <- hclust(samples.distance1);
    >> samples.dendrogr <- as.dendrogram(samples.clusters1);
    >> 
    >> # cut the trees
    >> samples.members  <- cutree(samples.clusters, k=4);
    >> genes.members    <- cutree(genes.clusters,   k=25);
    >> 
    >> # heatmap colouring
    >> my.colors <- function(n = 20, low.col = 0.35, high.col=1, saturation = 
    >> 0.85)
    >> {
    >> if (n < 2) stop("n must be greater than 2")
    >> n1 <- n%/%2
    >> n2 <- n - n1
    >> c(hsv(low.col, saturation, seq(1,0,length=n1)),
    >> hsv(high.col, saturation, seq(0,1,length=n2)))
    >> }
    >> 
    >> # make the heatmap
    >> hv <- heatmap(as.matrix(data), Rowv=genes.dendrogr, 
    >> Colv=samples.dendrogr,
    >> col=my.colors());
    >>



From idimakos at upatras.gr  Wed Jul 21 18:07:12 2004
From: idimakos at upatras.gr (idimakos@upatras.gr)
Date: Wed, 21 Jul 2004 19:07:12 +0300 (EEST)
Subject: [R] RE: Comparison of correlation coefficients - Details
In-Reply-To: <F848C7E68BD94E489A03F6C2351BB0013CFD98@vieex02.eu.boehringer.com>
References: <F848C7E68BD94E489A03F6C2351BB0013CFD98@vieex02.eu.boehringer.com>
Message-ID: <3198.150.140.128.207.1090426032.squirrel@patreas.upatras.gr>

That sounds very close to a meta-analytic comparison of two statistics. 
As a matter of fact, the Rosenthal & Rubin approach transforms all primary
statistics into Pearson r and then to Fisher's z and then follows with
comparisons.  More, comparisons can take into account sample sizes, or the
value of some other predictor variable.

I believe there is a Rosenthal book on meta-analysis published by Sage
publications, as well as a Brian Mullen book published by Lawrence
Erlbaum.
Brian Mullen's book comes (or used to come) with a meta.exe program to
perform meta-analyses.

Hope this helps,

Ioannis

> Dear all
>
> I apologize for cross-posting, but first it is accepted custom to
> thank the repliers and give a summary, and second I have still
> the feeling that this problem might be a general statistical problem
> and not necessarily related to microarrays only, but I might be wrong.
>
> First, I want to thank Robert Gentleman, Mark Kimpel and Mark Reiners
> for their kind replies. Robert Gentleman kindly pointed me to the
> Bioconductor package "MeasurementError.cor" as alternative to "cor.test".
> Mark Kimpel suggested that 2-way factorial Anova or the Bioconductor
> package "limma", respectively, may be helpful. Mark Reiners suggested
> to use the p-value of "cor.test" to test the significance.
>
> Maybe, I miss the point, but being not a statistician I am still unsure
> if it is possible to compare correlation coefficients from different
> sample sets. Both, the p-values from "cor.test" and from "compcorr",
> could be used as measure of the significance.
> However, is it possible to "normalize" correlation coefficients from
> different sample sets? Could an expression such as "corr * (1 - pval)"
> be used for normalization? Maybe, it is not possible to normalize
> correlation coefficients?
> Would a barplot comparing the correlation coefficients between two
> genes for different tissues be meaningful? (Alternatively, I have
> tried to use (1-pval) to calculate the gray-level of the bars.)
>
> Any further suggestions would be appreciated very much.
>
> Best regards
> Christian Stratowa
>
> -----Original Message-----
> From: Stratowa,Dr.,Christian FEX BIG-AT-V
> Sent: Monday, July 19, 2004 15:00
> To: 'bioconductor at stat.math.ethz.ch'
> Subject: Comparison of correlation coefficients - Details
>
>
> Dear all
>
> Maybe, my last mail did not explain my problem correctly:
> Since we are interested, which genes have similar expression profiles in a
> certain tissue or in different tissues, we have calculated the
> correlation coefficients between all 46,000 x 46,000 genes of the
> HG_U133A/B chipset for about 70 tissues, where the number of samples
> per tissue ranges from 10 to more than 200.
>
> While writing an R-function to display the correlation coefficients
> between
> gene A and B in the different tissues as bar-graph, I realized that it may
> not be correct to compare the different correlation coefficients directly,
> since the number of samples per tissue varyies between 10 and 200.
>
> Thus, the question is: Is there a way to compare different correlation
> coefficients and/or apply some kind of normalization?
>
> Assuming that this might be a well known statistical problem I was
> browsing
> statistics books and the web for more information, but could only find the
> function "compcorr" which gives a p-value how well you can trust the
> comparison of two correlation coefficients from different samples.
>
> Even though this might currently not be a direct Bioconductor question, it
> is certainly a microarray analysis related question. Any suggestions how
> to
> solve this problem would be greatly appreciated.
>
> Best regards
> Christian Stratowa
>
>
> -----Original Message-----
> From: Stratowa,Dr.,Christian FEX BIG-AT-V
> Sent: Tuesday, July 13, 2004 14:40
> To: 'bioconductor at stat.math.ethz.ch'
> Subject: Comparison of correlation coefficients
>
>
> Dear Bioconductor expeRts
>
> Is it possible to compare correlation coefficients or to normalize
> different correlation coefficients?
>
> Concretely, we have the following situation:
> We have gene expression profiles for different tissues, where the
> number of samples per tissue are different, ranging from 10 to 250.
> We are able to determine the correlation between two genes A and B
> for each tissue separately, using "cor.test". However, the question
> arises if the correlation coefficients between different tissues can
> be compared or if they must somehow be "normalized", since the
> number of samples per tissue varyies.
>
> Searching the web I found the function "compcorr", see:
> http://www.fon.hum.uva.nl/Service/Statistics/Two_Correlations.html
> http://ftp.sas.com/techsup/download/stat/compcorr.html
> and implemented it in R:
>
> compcorr <- function(n1, r1, n2, r2){
> # compare two correlation coefficients
> # return difference and p-value as list(diff, pval)
>
> #	Fisher Z-transform
> 	zf1 <- 0.5*log((1 + r1)/(1 - r1))
> 	zf2 <- 0.5*log((1 + r2)/(1 - r2))
>
> #	difference
> 	dz <- (zf1 - zf2)/sqrt(1/(n1 - 3) + (1/(n2 - 3)))
>
> #	p-value
> 	pv <- 2*(1 - pnorm(abs(dz)))
>
> 	return(list(diff=dz, pval=pv))
> }
>
> Would it make sense to use the resultant p-value to "normalize" the
> correlation coefficients, using: corr <- corr * compcorr()$pval
>
> Is there a better way or an alternative to "normalize" the correlation
> coefficients obtained for different tissues?
>
> Thank you in advance for your help.
> Since in the company I am not subscribed to bioconductor-help, could you
> please reply to me (in addition to bioconductor-help)
>
> P.S.: I have posted this first at r-help and it was suggested to me to
> post it here, too.
>
> Best regards
> Christian Stratowa
>
> ==============================================
> Christian Stratowa, PhD
> Boehringer Ingelheim Austria
> Dept NCE Lead Discovery - Bioinformatics
> Dr. Boehringergasse 5-11
> A-1121 Vienna, Austria
> Tel.: ++43-1-80105-2470
> Fax: ++43-1-80105-2782
> email: christian.stratowa at vie.boehringer-ingelheim.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From christophe.grova at mail.mcgill.ca  Wed Jul 21 21:07:34 2004
From: christophe.grova at mail.mcgill.ca (Christophe Grova)
Date: Wed, 21 Jul 2004 13:07:34 -0600
Subject: [R] Problem using xfig()
Message-ID: <006501c46f55$fe760ff0$da36d884@cgrova>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040721/025747b5/attachment.pl

From elvis at xlsolutions-corp.com  Wed Jul 21 19:22:11 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Wed, 21 Jul 2004 10:22:11 -0700
Subject: [R] R/S-plus Course***In Houston,
	TX***R/Splus Fundamentals and Programming Techniques,
	August 19-20, 2004
Message-ID: <20040721172211.20113.qmail@webmail01.mesa1.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud 
to announce June 2004 2-day "R/S-plus Fundamentals and 
Programming Techniques". 

****Houston, TX --------------------------------------> August, 19-20

Interested in our R/Splus Advanced Programming course? Please email 
us! 
Reserve your seat now at the early bird rates! Payment due AFTER the 
class. 


Course Description: 
This two-day beginner to intermediate R/S-plus course focuses 
on a broad spectrum of topics, 
from reading raw data to a comparison of R and S. We will learn 
the essentials of data manipulation, graphical visualization 
and R/S-plus programming. We will explore statistical data analysis 
tools,including graphics with data sets. How to enhance your plots. 
We will perform basic statistics and fit linear regression models. 
Participants are encouraged to bring data for interactive sessions 


With the following outline: 
- An Overview of R and S 
- Data Manipulation and Graphics 
- Using Lattice Graphics 
- A Comparison of R and S-Plus 
- How can R Complement SAS? 
- Writing Functions 
- Avoiding Loops 
- Vectorization 
- Statistical Modeling 
- Project Management 
- Techniques for Effective use of R and S 
- Enhancing Plots 
- Using High-level Plotting Functions 
- Building and Distributing Packages (libraries) 


Email us for group discounts. 
Email Sue Turner: sue at xlsolutions-corp.com 
Phone: 206-686-1578 
Visit us: www.xlsolutions-corp.com/training.htm 
Please let us know if you and your colleagues are interested in this 
classto take advantage of group discount. Register now to secure your 
seat! 
Interested in R/Splus Advanced course? email us. 


Cheers, 
Elvis Miller, PhD 
Manager Training. 
XLSolutions Corporation 
206 686 1578 
www.xlsolutions-corp.com 
elvis at xlsolutions-corp.com



From deepayan at stat.wisc.edu  Wed Jul 21 19:22:49 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 21 Jul 2004 12:22:49 -0500
Subject: [R] 2 images with 2 color scales on one graphic device. How to
	get it?
In-Reply-To: <200407211610130966.0BA5F280@mail.math.fu-berlin.de>
References: <200407211610130966.0BA5F280@mail.math.fu-berlin.de>
Message-ID: <200407211222.49564.deepayan@stat.wisc.edu>

On Wednesday 21 July 2004 09:10 am, Wolski wrote:
> Hi!
>
> Would like to plot two image plots with color scale (like levelplot
> (lattice) implements) in one graphic device. Tried to plot 2 levelplot's
> (lattice) (the data has not much in common) in one graphics device by
> setting par(mfrwo=c(2,1)) which does not work.
>
> Is there a way to force levelplot to use only a half of the graphic device?

Yes, see ?print.trellis

Deepayan



From B.Rowlingson at lancaster.ac.uk  Wed Jul 21 19:41:05 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 21 Jul 2004 18:41:05 +0100
Subject: [R] Problem using xfig()
In-Reply-To: <006501c46f55$fe760ff0$da36d884@cgrova>
References: <006501c46f55$fe760ff0$da36d884@cgrova>
Message-ID: <40FEAAB1.9090006@lancaster.ac.uk>

Christophe Grova wrote:
> Hello ... I tried to generate .fig figures with R, using the xfig() function ...When I open the 
 > figures using xfig software  under linux ... the foreground color 
change strangely ...
 > whereas when I display the same figure in R or when I saved it in 
using postscript() function there is no problem.
> 
> Any idea about the behavior of the colors when using xfig ??

  Does it happen even for the simplest plots in R?

  If I do:

  > xfig()
  > plot(1:10)
  > dev.off()

  then the resultant Rplot001.fig looks fine in Xfig.

  And what precisely do you mean by 'the foreground color change 
strangely'? Are black lines green? Are green lines all sorts of colours?

Baz



From marie-pierre.sylvestre at mail.mcgill.ca  Wed Jul 21 20:43:45 2004
From: marie-pierre.sylvestre at mail.mcgill.ca (Marie-Pierre Sylvestre)
Date: Wed, 21 Jul 2004 14:43:45 -0400
Subject: [R] function ms
Message-ID: <003d01c46f52$a77c5040$1392a8c0@epimgh.mcgill.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040721/923430b1/attachment.pl

From andy_liaw at merck.com  Wed Jul 21 20:54:34 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 21 Jul 2004 14:54:34 -0400
Subject: [R] function ms
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80CA@usrymx25.merck.com>

There's an optimizer in S-PLUS called ms(), but not R.  Are you sure you're
using the version of MICE for R?

Andy

> From: Marie-Pierre Sylvestre
> 
> Dear R users,
> 
> I am using the MICE package. Specifically, at some point in 
> my code I have
> 
> imp2=mice(PoptotalMICE,imputationMethod="logreg2")
> 
> And R returns... 
>  
>  iter imp variable
>   1   1  MICEYError in logitreg(xobs, yobs, intercept=F) : 
>         couldn't find function "ms"
> 
> I have been looking for this ms function on the web, hoping 
> it was just a matter of downloading a package. I didn't find anything.
> 
> I have tried getAnywhere without success.
> 
> What can it be? Where is the function ms?
> 
> Thanks
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From lisawang at uhnres.utoronto.ca  Wed Jul 21 21:37:00 2004
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Wed, 21 Jul 2004 15:37:00 -0400
Subject: [R] How to do a "go to " in a loop in R
Message-ID: <40FEC5DC.FC411B26@uhnres.utoronto.ca>

Hi there,

I'm writing a function which involves a loop. What to write in the "?"
place would allow it skips the "for loop" and goes to  "a[i]<-0".
 
 
 a<-b[s>3,]

 if (nrow(a)==0) ?????????????
                 

	for (i in 1:nrow(a)){
  		a[i]<-1
	}
 a[i]<-0


Lisa Wang
Cancer Informatics,
Ontario Cancer Institute/Princess Margaret Hospital, University Health
Network;
Email: lisawang at uhnres.utoronto.ca
Phone: 416 946 4501 ext. 5201
Fax: 416 946 4619



From ggrothendieck at myway.com  Wed Jul 21 22:17:09 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 21 Jul 2004 20:17:09 +0000 (UTC)
Subject: [R] How to do a "go to " in a loop in R
References: <40FEC5DC.FC411B26@uhnres.utoronto.ca>
Message-ID: <loom.20040721T221243-829@post.gmane.org>

Lisa Wang <lisawang <at> uhnres.utoronto.ca> writes:

: 
: Hi there,
: 
: I'm writing a function which involves a loop. What to write in the "?"
: place would allow it skips the "for loop" and goes to  "a[i]<-0".
: 
:  a<-b[s>3,]
: 
:  if (nrow(a)==0) ?????????????
: 
: 	for (i in 1:nrow(a)){
:   		a[i]<-1
: 	}
:  a[i]<-0

There are a number of errors in the above but I assume your question
is how to set up a loop over an index of the rows of  a  so that the
loop executes zero times if a has no rows.  Try this:

  for(i in seq(len=nrow(a))) ...

Also, depending on what you want to do, you might consider whether you 
need a loop in the first place.



From h.wickham at gmail.com  Wed Jul 21 22:53:43 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 22 Jul 2004 08:53:43 +1200
Subject: [R] dumpClass, hasSlot in R?
In-Reply-To: <40FE792C.60103@pdf.com>
References: <40FE792C.60103@pdf.com>
Message-ID: <f8e6ff05040721135354c5d394@mail.gmail.com>

There are a few notes about difference between the R implementation
and the book at http://developer.r-project.org/methodsPackage.html

I found the hardest thing to get to grips in R was method calling -
using multiple dispatch (totally different to what I'm used to from
Java, Python etc.).  I found this tutorial
(http://www.gwydiondylan.org/gdref/tutorial.html, the sections on
generic functions and multiple-dispatch) very useful.  However, it is
for another programming language, and although the method and class
creation process feels very similar to R, the syntax is quite
different.  There is definitely scope for a similarly structured
introduction to S4 classes in R.

Hadley



From MSchwartz at MedAnalytics.com  Wed Jul 21 23:07:37 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 21 Jul 2004 16:07:37 -0500
Subject: [R] dumpClass, hasSlot in R?
In-Reply-To: <f8e6ff05040721135354c5d394@mail.gmail.com>
References: <40FE792C.60103@pdf.com>
	<f8e6ff05040721135354c5d394@mail.gmail.com>
Message-ID: <1090444057.30855.37.camel@localhost.localdomain>

On Wed, 2004-07-21 at 15:53, hadley wickham wrote:
> There are a few notes about difference between the R implementation
> and the book at http://developer.r-project.org/methodsPackage.html
> 
> I found the hardest thing to get to grips in R was method calling -
> using multiple dispatch (totally different to what I'm used to from
> Java, Python etc.).  I found this tutorial
> (http://www.gwydiondylan.org/gdref/tutorial.html, the sections on
> generic functions and multiple-dispatch) very useful.  However, it is
> for another programming language, and although the method and class
> creation process feels very similar to R, the syntax is quite
> different.  There is definitely scope for a similarly structured
> introduction to S4 classes in R.
> 
> Hadley

I have not done any S4 coding yet, but two references that may be of
interest are:

"Converting Packages to S4" 
by Doug Bates
R News Vol 3, No. 1, June 2003
http://cran.r-project.org/doc/Rnews/Rnews_2003-1.pdf

and 

"S4 Classes and Methods"
by Fritz Leisch
useR! 2004 Keynote Lecture
Slides available at: 
http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Leisch.pdf

HTH,

Marc Schwartz



From GPetris at uark.edu  Wed Jul 21 23:59:37 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 21 Jul 2004 16:59:37 -0500 (CDT)
Subject: [R] Building problem: leftover from old OS 
Message-ID: <200407212159.i6LLxbQb023546@definetti.uark.edu>


Hello,

I have updated my OS from Solaris 2.7 to Solaris 2.8, and I am trying
to build R 1.9.1. Configure seems to run fine, resulting in the message:

R is now configured for sparc-sun-solaris2.8

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                cc  -xO5 -dalign -xlic_lib=sunperf
  C++ compiler:              CC  -xO5 -dalign
  Fortran compiler:          f95  -xO5 -dalign -xlic_lib=sunperf

  Interfaces supported:      X11
  External libraries:        BLAS(none), LAPACK(in blas)
  Additional capabilities:   PNG, JPEG
  Options enabled:           R profiling

  Recommended packages:      yes
 
Unfortunately, the generated file ./src/appl/Makefile contains the lines:

approx.o: approx.c ../../src/include/config.h \
 ../../src/include/R_ext/Arith.h \
 /opt/gnu/lib/gcc-lib/sparc-sun-solaris2.7/2.95.2/include/math.h \

and, since the mentioned file doesn't exist (actually, there is no gcc
on my machine yet), invoking make results in the following error:

make[3]: Entering directory `/usr/local/R/R-1.9.1/src/appl'
make[3]: *** No rule to make target
   `/opt/gnu/lib/gcc-lib/sparc-sun-solaris2.7/2.95.2/include/math.h',
   needed by `approx.o'.  Stop. 

Do you have any idea of what is going on here? 

Thanks in advance,
Giovanni

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From rolf at math.unb.ca  Thu Jul 22 00:02:29 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 21 Jul 2004 19:02:29 -0300 (ADT)
Subject: [R] How to do a "go to " in a loop in R
Message-ID: <200407212202.i6LM2TKK007128@erdos.math.unb.ca>

Well, there ain't no such thing in R ....  And your code doesn't
really make sense anyway.  You talk about ``a[i]'' where a is
apparently a ***matrix*** (with the same number of columns as the
matrix b, but with fewer --- possibly 0 --- rows).  And in such as
setting a[i] has a meaning, but probably not what you want.  And
talking about ``a[i] <- 0'' when i is a running index, running in
this case over the empty set (!!!) doesn't make sense either.

Perhaps what you want to accomplish is along something like the
following lines:

a<-b[s>3,]
if(nrow(a)==0) {
	result <- 0
} else {
	result <- numeric(nrow(a))
        for (i in 1:nrow(a)){
		result[i] <- 1
        }
}

Of course if that's what you're really trying to do, the for-loop
is a silly waste of time.  Instead do

a<-b[s>3,]
if(nrow(a)==0) {
        result <- 0
} else result <- rep(1,nrow(a))

or slightly more elegantly

a<-b[s>3,]
result <- if(nrow(a)==0) 0 else rep(1,nrow(a))

				cheers,

					Rolf Turner
					rolf at math.unb.ca

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
You wrote:

> I'm writing a function which involves a loop. What to write in the "?"
> place would allow it skips the "for loop" and goes to  "a[i]<-0".
>  
>  
>  a<-b[s>3,]
> 
>  if (nrow(a)==0) ?????????????
>                  
> 
> 	for (i in 1:nrow(a)){
>   		a[i]<-1
> 	}
>  a[i]<-0
> 
> 
> Lisa Wang
> Cancer Informatics,
> Ontario Cancer Institute/Princess Margaret Hospital, University Health
> Network;
> Email: lisawang at uhnres.utoronto.ca
> Phone: 416 946 4501 ext. 5201
> Fax: 416 946 4619



From anilomjf at yahoo.es  Wed Jul 21 23:30:14 2004
From: anilomjf at yahoo.es (Francisco J Molina)
Date: Wed, 21 Jul 2004 23:30:14 +0200
Subject: [R] add more data to a data file, problem with .Rprofile
Message-ID: <16638.57446.251410.449782@localhost.localdomain>


Hi,

Is there a way to incorporate an R object x to a file already containing R objects?
It seems that 'save' is not capable to do this. If I save x to a file containing
previously saved data, then I will lose this data.

I use the funcion hsv in .Rprofile but it is recognized. Couriously, if I source .Rprofile
when R is already running I do not get any error message. 

Thank you.



From qiaozhen at ntsg.umt.edu  Thu Jul 22 00:33:36 2004
From: qiaozhen at ntsg.umt.edu (Qiaozhen Mu)
Date: Wed, 21 Jul 2004 16:33:36 -0600
Subject: [R] CCA code
Message-ID: <013d01c46f72$c35578d0$5668080a@ntsg.umt.edu>

Hello,

Is there a fortran or C program to do the canonical Coefficient Analysis
(CCA)? Could someone give it to me? Thanks for any help in advance.

Qiaozhen



From yunfeng at scripps.edu  Thu Jul 22 01:01:15 2004
From: yunfeng at scripps.edu (Yunfeng Hu)
Date: Wed, 21 Jul 2004 16:01:15 -0700
Subject: [R] questions about principle component analysis (princomp)
Message-ID: <DE658826-DB69-11D8-9B0D-000A95AB543C@scripps.edu>

Hi, I am a new R user and am currently using princomp to conduct a PCA. 
I have read the help(princomp) and still do not quite understand 
everything in the help. Basically I want to get the covariance matrix, 
and eigenvector/eigenvalues (loadings()?) so that I can find the 
principle components. Thanks!

Yunfeng
###################################
Research Associate, Ph.D
Department of Molecular Biology, MB-5
The Scripps Research Institute
10550 North Torrey Pines Road
La Jolla, CA 92037
Tel. (858) 784-2204
Fax. (858) 784-2860
Emal: yunfeng at scripps.edu
Web: http://www.scripps.edu/~yunfeng
###################################



From andy_liaw at merck.com  Thu Jul 22 01:59:51 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 21 Jul 2004 19:59:51 -0400
Subject: [R] add more data to a data file, problem with .Rprofile
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80D5@usrymx25.merck.com>

> From: Francisco J Molina
> 
> Hi,
> 
> Is there a way to incorporate an R object x to a file already 
> containing R objects?
> It seems that 'save' is not capable to do this. If I save x 
> to a file containing
> previously saved data, then I will lose this data.

See if the following helps:

> x <- 2
> save(x, file="x.rda")
> rm(x)
> attach("x.rda")
> assign("y", 3, pos=2)
> ls(2)
[1] "x" "y"
> save(list=ls(2), file="x.rda")
> detach(2)
> x
Error: Object "x" not found
> y
Error: Object "y" not found
> attach("x.rda")
> x
[1] 2
> y
[1] 3
> ls(2)
[1] "x" "y"

 
> I use the funcion hsv in .Rprofile but it is recognized. 
> Couriously, if I source .Rprofile
> when R is already running I do not get any error message. 

Not sure what you mean...

Andy
 
> Thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From f.harrell at Vanderbilt.Edu  Thu Jul 22 04:19:01 2004
From: f.harrell at Vanderbilt.Edu (Harrell, Frank E)
Date: Wed, 21 Jul 2004 21:19:01 -0500
Subject: [R] Regression Modeling Strategies Short Course
Message-ID: <1090462741.40ff241525e67@vuwebmail.vanderbilt.edu>

I will be giving a one-day short course related to my book Regression Modeling 
Strategies in Toronto as part of the Joint Statistical Meetings on August 8.  
For more information visit the American Statistical Association web site 
amstat.org and biostat.mc.vanderbilt.edu/rms.  The course applies to both R and 
S-Plus and assumes a good general background in multiple regression.

-----------------------------------------------------------------
Harrell, Frank E
Vanderbilt University



From maechler at stat.math.ethz.ch  Wed Jul 21 18:41:31 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 Jul 2004 18:41:31 +0200
Subject: [R] Cutting heatmap dendrogram
In-Reply-To: <1090425819.40fe93db9341b@webmail.utoronto.ca>
References: <1090425819.40fe93db9341b@webmail.utoronto.ca>
Message-ID: <16638.40123.737122.395879@gargle.gargle.HOWL>

>>>>> "paul" == paul boutros <paul.boutros at utoronto.ca>
>>>>>     on Wed, 21 Jul 2004 12:03:39 -0400 writes:

    paul> Hi Sean, Martin
    >>>>>>> "Sean" == Sean Davis <sdavis2 at mail.nih.gov>
    >>>>>>> on Wed, 21 Jul 2004 06:01:33 -0400 writes:

    Sean> Paul, You can certainly get a heatmap of a subset of
    Sean> your data by simply subsetting.  If you have a group
    Sean> of genes obtained from cutree, simply do a heatmap on
    Sean> that set of genes.  If you obtain a set of genes, say
    Sean> A, and want to do a heatmap on that subset, simply do
    Sean> heatmap(as.matrix(data[A,])) where A contains either a
    Sean> logical vector or indices for the genes of interest.
    Sean> The dendrograms will be generated for those samples
    Sean> and genes based on the subset of data.  You could, of
    Sean> course, pass in the sample dendrogram from the
    Sean> original clustering of all genes if you like.

    >> this was probably helpful but didn't really answer the original question.

    paul> Yeah, I'm okay with getting subsets and plotting them
    paul> separately, but the goal is to be able to
    paul> automatically show and label the subsets on the
    paul> heatmap itself.

    >> One thing you (Paul) should do is to "cut()" the dendrogram
    >> instead of "cutree()"ing the hclust result and then *pass* the
    >> cut()ed dendrogram directly to heatmap(). 

    paul> Ahh, that makes sense, but maybe I'm missing something?

yes.  The fact (that I also forget to mention in my reply above,
but clearly visible from  ?cut.dendrogram )
that  cut(<dendrogram>) returns a  list() , not a dendrogram
and from that list, you are really interested in the $upper
component which *is* a dendrogram.

I.e., in your example below
if you replace

    > samples.dendrogr2 <- cut(samples.dendrogr1, 4);
by
    > samples.dendrogr2 <- cut(samples.dendrogr1, 4)$upper

'samples.dendrogr2' *is* a dendrogram.

However, I don't think that it will currently work directly with
the current version of heatmap()
*and* the original data matrix.

Enhancements should be possible, but not today
(and there are some from "heatmap2" that are *still* not in
 R-devel's heatmap() function !).

Regards,
Martin

    paul> ###########################################
    >> samples.dendrogr2 <- cut(samples.dendrogr1, 4);
    >> samples.dendrogr2
    paul> $upper
    paul> `dendrogram' with 2 branches and 2 members total, at height 1.082017 

    paul> $lower
    paul> $lower[[1]]
    paul> `dendrogram' with 2 branches and 4 members total, at height 0.0631504 

    paul> $lower[[2]]
    paul> `dendrogram' with 2 branches and 12 members total, at height 0.5823986 


    >> plot(samples.dendrogr2);
    paul> Error in plot.window(xlim, ylim, log, asp, ...) : 
    paul> need finite xlim values
    paul> In addition: Warning messages: 
    paul> 1: no finite arguments to min; returning Inf 
    paul> 2: no finite arguments to max; returning -Inf 
    paul> 3: no finite arguments to min; returning Inf 
    paul> 4: no finite arguments to max; returning -Inf

    >> hv <- heatmap(as.matrix(data), Rowv=genes.dendrogr, Colv=samples.dendrogr2); 
    paul> Error in lV + rV : non-numeric argument to binary operator

    >> traceback();
    paul> 8: oV(x[[1]], wts)
    paul> 7: oV(x[[1]], wts)
    paul> 6: oV(x, wts)
    paul> 5: inherits(x, "dendrogram")
    paul> 4: midcache.dendrogram(oV(x, wts))
    paul> 3: reorder.dendrogram(ddc, Colv)
    paul> 2: reorder(ddc, Colv)
    paul> 1: heatmap(as.matrix(data), Rowv = genes.dendrogr, Colv = samples.dendrogr2, 
    paul> col = my.colors())
    paul> ###########################################

    paul> Any ideas are (still) very much appreciated!
    paul> Paul

    >> I'm interested to hear if that works (haven't got time to
    >> experiment with that just now).

    Sean> It sounds like you are aiming for interactive
    Sean> clustering, which R does not do well.  Consider using
    Sean> an external viewer such as the cluster/treeview combo
    Sean> or the TIGR clustering program (can't remember name).

    paul> I'll check out MeV, then, but since the rest of my processing is in R....

    Sean> Finally, for future reference, it is probably worthwhile posting 
    Sean> microarray questions to the Bioconductor mailing list rather than 
    Sean> R-Help.

    >> I disagree.  This was a question about heatmap() an R function
    >> of more general use than microarrays.
    >> I would have found it "wrong" to ask this question on the
    >> bioconductor mailing list.

    >> Martin Maechler

    Sean> Sean

    Sean> On Jul 20, 2004, at 9:39 PM, Paul Boutros wrote:

    >>> Hello,
    >>> 
    >>> I've been clustering my data using hclust and cutting the resulting 
    >>> tree
    >>> with cutree.  Separately, I visualize the clusterings with heatmap.  
    >>> Is it
    >>> possible to have the dendrogram on the heatmap reflect the cutree 
    >>> results?
    >>> That is, instead of having one large dendrogram, it would have 4 or 25 
    >>> in
    >>> the example below.  Any guidance on if that's possible or not, and what
    >>> kinds of commands I should be looking into would be very much 
    >>> appreciated.
    >>> I'm using R 1.9.0 on Windows XP.
    >>> 
    >>> Thanks!
    >>> Paul
    >>> 
    >>> # load libraries
    >>> library(stats);
    >>> 
    >>> # working copy of data
    >>> set1 <- as.matrix(data);
    >>> set2 <- t(set1);
    >>> 
    >>> # genes
    >>> genes.distance <- as.dist(1-cor(set2));
    >>> genes.clusters <- hclust(genes.distance);
    >>> genes.dendrogr <- as.dendrogram(genes.clusters);
    >>> 
    >>> # samples
    >>> samples.distance <- as.dist(1-cor(set1));
    >>> samples.clusters <- hclust(samples.distance1);
    >>> samples.dendrogr <- as.dendrogram(samples.clusters1);
    >>> 
    >>> # cut the trees
    >>> samples.members  <- cutree(samples.clusters, k=4);
    >>> genes.members    <- cutree(genes.clusters,   k=25);
    >>> 
    >>> # heatmap colouring
    >>> my.colors <- function(n = 20, low.col = 0.35, high.col=1, saturation = 
    >>> 0.85)
    >>> {
    >>> if (n < 2) stop("n must be greater than 2")
    >>> n1 <- n%/%2
    >>> n2 <- n - n1
    >>> c(hsv(low.col, saturation, seq(1,0,length=n1)),
    >>> hsv(high.col, saturation, seq(0,1,length=n2)))
    >>> }
    >>> 
    >>> # make the heatmap
    >>> hv <- heatmap(as.matrix(data), Rowv=genes.dendrogr, 
    >>> Colv=samples.dendrogr,
    >>> col=my.colors());
    >>>



From a_elhabti at yahoo.fr  Thu Jul 22 06:48:58 2004
From: a_elhabti at yahoo.fr (=?iso-8859-1?q?Ahmed=20Elhabti?=)
Date: Thu, 22 Jul 2004 06:48:58 +0200 (CEST)
Subject: [R] Programmation pour MLE
Message-ID: <20040722044858.88424.qmail@web25107.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040722/2b859816/attachment.pl

From petzoldt at rcs.urz.tu-dresden.de  Thu Jul 22 08:29:37 2004
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 22 Jul 2004 08:29:37 +0200
Subject: [R] questions about principle component analysis (princomp)
In-Reply-To: <DE658826-DB69-11D8-9B0D-000A95AB543C@scripps.edu>
References: <DE658826-DB69-11D8-9B0D-000A95AB543C@scripps.edu>
Message-ID: <40FF5ED1.70605@rcs.urz.tu-dresden.de>

Yunfeng Hu wrote:
> Hi, I am a new R user and am currently using princomp to conduct a PCA. 
> I have read the help(princomp) and still do not quite understand 
> everything in the help. Basically I want to get the covariance matrix, 
> and eigenvector/eigenvalues (loadings()?) so that I can find the 
> principle components. Thanks!

Hello,

you may start with the examples at the bottom of the help page to get 
more understanding. Here is a modified version of that example:

  data(USArrests)
  pc<- princomp(USArrests)

  summary(pc)
  loadings(pc)

  plot(pc)
  biplot(pc)

# some other useful methods mentioned on the help page:

  cov(USArrests)          # covariance matrix
  eigen(cov(USArrests))   # eigenvalues/vector

# and a way to show, what things are stored in pc

  str(pc)

# so they can be extracted as shown on the help page.

# Please note, that the scaled version (correlation matrix)
# would be more appropriate there, e.g.

  pc<- princomp(USArrests, cor=TRUE)
  summary(pc)
  cor(USArrests)
  eigen(cor(USArrests))


Hope it helps

Thomas P.



From ggrothendieck at myway.com  Thu Jul 22 08:41:27 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 22 Jul 2004 06:41:27 +0000 (UTC)
Subject: [R] dumpClass, hasSlot in R?
References: <40FE792C.60103@pdf.com>
	<f8e6ff05040721135354c5d394@mail.gmail.com>
	<1090444057.30855.37.camel@localhost.localdomain>
Message-ID: <loom.20040722T042332-408@post.gmane.org>

Marc Schwartz <MSchwartz <at> MedAnalytics.com> writes:

: 
: On Wed, 2004-07-21 at 15:53, hadley wickham wrote:
: > There are a few notes about difference between the R implementation
: > and the book at http://developer.r-project.org/methodsPackage.html
: > 
: > I found the hardest thing to get to grips in R was method calling -
: > using multiple dispatch (totally different to what I'm used to from
: > Java, Python etc.).  I found this tutorial
: > (http://www.gwydiondylan.org/gdref/tutorial.html, the sections on
: > generic functions and multiple-dispatch) very useful.  However, it is
: > for another programming language, and although the method and class
: > creation process feels very similar to R, the syntax is quite
: > different.  There is definitely scope for a similarly structured
: > introduction to S4 classes in R.
: > 
: > Hadley
: 
: I have not done any S4 coding yet, but two references that may be of
: interest are:
: 
: "Converting Packages to S4" 
: by Doug Bates
: R News Vol 3, No. 1, June 2003
: http://cran.r-project.org/doc/Rnews/Rnews_2003-1.pdf
: 
: and 
: 
: "S4 Classes and Methods"
: by Fritz Leisch
: useR! 2004 Keynote Lecture
: Slides available at: 
: http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Leisch.pdf
: 
: HTH,
: 
: Marc Schwartz

Also:

S4 Classes in 15 pages, more or less
http://www.bioconductor.org/develPage/guidelines/programming/S4Objects.pdf



From ligges at statistik.uni-dortmund.de  Thu Jul 22 08:59:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 22 Jul 2004 08:59:24 +0200
Subject: [R] add more data to a data file, problem with .Rprofile
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF80D5@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF80D5@usrymx25.merck.com>
Message-ID: <40FF65CC.2080204@statistik.uni-dortmund.de>

Liaw, Andy wrote:

>>From: Francisco J Molina
>>
>>Hi,
>>
>>Is there a way to incorporate an R object x to a file already 
>>containing R objects?
>>It seems that 'save' is not capable to do this. If I save x 
>>to a file containing
>>previously saved data, then I will lose this data.
> 
> 
> See if the following helps:
> 
> 
>>x <- 2
>>save(x, file="x.rda")
>>rm(x)
>>attach("x.rda")
>>assign("y", 3, pos=2)
>>ls(2)
> 
> [1] "x" "y"
> 
>>save(list=ls(2), file="x.rda")
>>detach(2)
>>x
> 
> Error: Object "x" not found
> 
>>y
> 
> Error: Object "y" not found
> 
>>attach("x.rda")
>>x
> 
> [1] 2
> 
>>y
> 
> [1] 3
> 
>>ls(2)
> 
> [1] "x" "y"
> 
>  
> 
>>I use the funcion hsv in .Rprofile but it is recognized. 
>>Couriously, if I source .Rprofile
>>when R is already running I do not get any error message. 
> 
> 
> Not sure what you mean...

He meant that .Rprofile is loaded before package graphics is attached, 
and therefore hsv() cannot be found.
Attaching the package in .Rprofile or setting a hook should be sufficient.

Uwe Ligges



> Andy
>  
> 
>>Thank you.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From vito_ricci at yahoo.com  Thu Jul 22 09:30:27 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Thu, 22 Jul 2004 09:30:27 +0200 (CEST)
Subject: [R] Programmation pour MLE 
Message-ID: <20040722073027.24611.qmail@web41202.mail.yahoo.com>

Salut,

je pense tu dois calculer/determiner la function of
vraisemblance di f(x). D'apr??s tu peux chercher le
valeur des parametres a1,a2,a3 che rendent maxime la 
vraisemblance di f(x) en employant les funtions de R:

optimize() or optim() pur maximizer la vraisemblance
di f(x) avec des methodes numeriques.

Hi,

I believe you have to find the likelihood function of
f(x) and after you can obtain the ML estimates of a1,
a2, a3 maximazing the likelihood function using
optimize() or optim().

Best.
Vito




Bonjour,

Je veux cherch?? l?estimateur de vraisemblance maximal
(MLE)d?une fonction ?? 3 param??tre inconue ??tant donn??
une ??chantillon de taille 50 (les observations des
valeurs de x) alors comment je peux proc??d?? 

La fonction de densit?? est d??finie par : 

 

f(x)= 1/3(g(a1)+g(a2)+g(a3))

 

avec g(ai)=(exp(ai)*ai^x)/x! pour i=1,2,3.

 

Je vous remercie beaucoup.

 

A. Elhabti

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From unung at enciety.com  Thu Jul 22 09:45:19 2004
From: unung at enciety.com (Unung Istopo Hartanto)
Date: Thu, 22 Jul 2004 14:45:19 +0700
Subject: [R] Population Pyramid Plot
In-Reply-To: <3198.150.140.128.207.1090426032.squirrel@patreas.upatras.gr>
References: <F848C7E68BD94E489A03F6C2351BB0013CFD98@vieex02.eu.boehringer.com>
	<3198.150.140.128.207.1090426032.squirrel@patreas.upatras.gr>
Message-ID: <1090482319.3106.18.camel@IT05>

Finally, today I able to produce pyramid plot using any part of script
from R-News Vol 3/2, October 2003 by Paul Murrell "Integrating grid
Graphics output with Base Graphics Output".

Title, i using title function from script in
http://www.r-project.org/misc/acpclust.R .

Maybe, anyone to improve this script. cause, i write it roughly.

Thanks for All,

regards,

Unung
-------------- next part --------------
######################################################
###         Piramida Penduduk                      ###
###         Oleh : Unung Istopo                    ###
###         Enciety Business Consult               ###
###         www.enciety.com                        ###
###         22 Juli 2004                           ###
######################################################

require(gridBase)

# This script from : http://www.r-project.org/misc/acpclust.R
ltitle <- function(x,backcolor="darkgreen",forecolor="yellow",cex=2,ypos=0.4){
plot(x=c(-1,1),y=c(0,1),xlim=c(0,1),ylim=c(0,1),type="n",axes=FALSE)
polygon(x=c(-1,-1,1,1),y=c(-1,1,1,-1),col=backcolor,border=NA)
text(x=0,y=ypos,pos=4,cex=cex,labels=x,col=forecolor)
}



### Contoh Data
data <- c(100,110,115,250,350,458,500,567,789,876,600,556,500,465,350,250,145)

data.axes <- c(0,200,400,600,800)

### Kelompok Umur
label <- c("0 - 4", "5 - 9", "10 - 14", "15 - 19", "20 - 24", "24 - 29",
    "30 - 34", "35 - 39", "40 - 44", "44 - 49", "50 - 54", "55 - 59", "60 - 64",
    "65 - 69", "70 - 74", "75 - 79", "80+")

#par(mfrow=c(1,2))
#layout(cbind(1,2))

mylayout=layout(matrix(c(1,1,2,3,4,5),ncol=2,byrow=T),widths=c(1/2,1/2),heights=c(lcm(1),lcm(1),1))

#par(mar = c(bottom, left, top, right))

# Judul Atas
par(mar = c(0.1, 0.8, 0.1, 0.1))
ltitle(paste("                                           R Enciety - Piramida Penduduk"),cex=1.6,ypos=0.4)

# Judul Atas Kiri - Male
par(mar = c(0.1, 0.8, 0.1, 2))
ltitle(paste("                    Laki-Laki"),cex=1.6,ypos=0.4,backcolor="white",forecolor="darkgreen")

# Judul Atas Kanan - Female
par(mar = c(0.1, 0.8, 0.1, 0.5))
ltitle(paste("                    Perempuan"),cex=1.6,ypos=0.4,backcolor="white",forecolor="darkgreen")



### Plot Data Bagian Kiri
par(mar = c(5,1.5,1.5,5))
midpts <- barplot(-data,axes=F,horiz=T,col="blue",xlab="(dalam ribu)")

axis(1,at=-data.axes,labels=FALSE)

# This script from R-News Vol 3/2, October 2003 by Paul Murrell "Integrating grid Graphics output with Base Graphics Output".

vps <- baseViewports()
par(new=TRUE)
push.viewport(vps$inner,vps$figure,vps$plot)
grid.text(c(as.character(data.axes)),x=unit(-data.axes,"native"),y=unit(-1,"lines"),rot=0)
pop.viewport(3)
par(new=FALSE)



### Plot Data Bagian Kanan
par(mar = c(5,2,1.5,4))
midpts <- barplot(data,axes=F,horiz=T,col="orange",xlab="(dalam ribu)")

axis(2,at=midpts,labels=FALSE,col="white")
axis(1,at=data.axes,labels=FALSE)

# This script from R-News Vol 3/2, October 2003 by Paul Murrell "Integrating grid Graphics output with Base Graphics Output".

vps <- baseViewports()
par(new=TRUE)
push.viewport(vps$inner,vps$figure,vps$plot)
grid.text(c(as.character(data.axes)),x=unit(data.axes,"native"),y=unit(-1,"lines"),rot=0)
pop.viewport(3)

vps <- baseViewports()
par(new=TRUE)
push.viewport(vps$inner,vps$figure,vps$plot)
grid.text(c(as.character(label)),y=unit(midpts,"native"),x=unit(-2,"lines"),rot=0)
pop.viewport(3)

par(new=FALSE)

From laura at env.leeds.ac.uk  Thu Jul 22 10:39:30 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Thu, 22 Jul 2004 09:39:30 +0100 (BST)
Subject: [R] Vector to complex scalar
Message-ID: <Pine.LNX.4.44.0407220938490.30001-100000@env-pc-phd13>

Is there an R function to convert vectors into complex scalars?

Thanks

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From thpe at hhbio.wasser.tu-dresden.de  Thu Jul 22 11:28:13 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 22 Jul 2004 11:28:13 +0200
Subject: [R] Vector to complex scalar
In-Reply-To: <Pine.LNX.4.44.0407220938490.30001-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0407220938490.30001-100000@env-pc-phd13>
Message-ID: <40FF88AD.5090808@hhbio.wasser.tu-dresden.de>

Laura Quinn wrote:
> Is there an R function to convert vectors into complex scalars?
> 
> Thanks
Is this because of the wind problem in one of the last questions? For
conversion of two dimensional data into complex numbers and vice-versa
you may look for ?complex in the online help, however I do not know if
the principal components functions in R can handle complex numbers.

Thomas P.



From borut.rajer at borzen.si  Thu Jul 22 11:39:03 2004
From: borut.rajer at borzen.si (Borut Rajer)
Date: Thu, 22 Jul 2004 11:39:03 +0200
Subject: [R] Disriminant analysis with lda (MASS)
Message-ID: <9EF38639FDD6DE40BC8DAC9E6C901A1E0C4995@ps.borzen.local>


Hello,

Does the "lda" function (package MASS) perform or can it perform classic
two-group Fisher discriminant analysis?

R-version: 1.9.1, MASS package (latest available)

Thank you,  

Borut Rajer



From maechler at stat.math.ethz.ch  Thu Jul 22 11:59:24 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jul 2004 11:59:24 +0200
Subject: [R] Building problem: leftover from old OS 
In-Reply-To: <200407212159.i6LLxbQb023546@definetti.uark.edu>
References: <200407212159.i6LLxbQb023546@definetti.uark.edu>
Message-ID: <16639.36860.877937.852602@gargle.gargle.HOWL>

I guess that you built R before (in the same location for
Solaris 2.7) ?

If yes,
  "make clean"

(or just wipe out everything, and unpack the R-1.9.1.tar.gz again)
before calling configure should solve the problem.

BTW: I'd recommend to build in a different directory than the
     source one.
Starting from scratch, I'd do

    tar xfz R-1.9.1.tar.gz
    mkdir   R-1.9.1-inst
    cd      R-1.9.1-inst
    ../R-1.9.1/configure ........
			 ^^^^^^^^^ maybe add some recommended Solaris options
Martin

>>>>> "Giovanni" == Giovanni Petris <GPetris at uark.edu>
>>>>>     on Wed, 21 Jul 2004 16:59:37 -0500 (CDT) writes:

    Giovanni> I have updated my OS from Solaris 2.7 to Solaris
    Giovanni> 2.8, and I am trying to build R 1.9.1. Configure
    Giovanni> seems to run fine, resulting in the message:

    Giovanni> R is now configured for sparc-sun-solaris2.8

    Giovanni> Source directory:          .
    Giovanni> Installation directory:    /usr/local

    Giovanni> C compiler:                cc  -xO5 -dalign -xlic_lib=sunperf
    Giovanni> C++ compiler:              CC  -xO5 -dalign
    Giovanni> Fortran compiler:          f95  -xO5 -dalign -xlic_lib=sunperf

    Giovanni> Interfaces supported:      X11
    Giovanni> External libraries:        BLAS(none), LAPACK(in blas)
    Giovanni> Additional capabilities:   PNG, JPEG
    Giovanni> Options enabled:           R profiling

    Giovanni> Recommended packages:      yes
 
    Giovanni> Unfortunately, the generated file
    Giovanni> ./src/appl/Makefile contains the lines:

    Giovanni> approx.o: approx.c ../../src/include/config.h \
    Giovanni> ../../src/include/R_ext/Arith.h \
    Giovanni> /opt/gnu/lib/gcc-lib/sparc-sun-solaris2.7/2.95.2/include/math.h \

    Giovanni> and, since the mentioned file doesn't exist
    Giovanni> (actually, there is no gcc on my machine yet),
    Giovanni> invoking make results in the following error:

    Giovanni> make[3]: Entering directory `/usr/local/R/R-1.9.1/src/appl'
    Giovanni> make[3]: *** No rule to make target
    Giovanni> `/opt/gnu/lib/gcc-lib/sparc-sun-solaris2.7/2.95.2/include/math.h',
    Giovanni> needed by `approx.o'.  Stop. 

    Giovanni> Do you have any idea of what is going on here? 

    Giovanni> Thanks in advance,
    Giovanni> Giovanni



From R.Knell at qmul.ac.uk  Thu Jul 22 13:25:21 2004
From: R.Knell at qmul.ac.uk (Rob Knell)
Date: Thu, 22 Jul 2004 12:25:21 +0100
Subject: [R] exporting high quality graphics from R in Mac OSX
Message-ID: <D1912480-DBD1-11D8-9ADD-000D9335A24A@qmul.ac.uk>

Hi there

The default option for saving graphics from R (1.9.1) on my Mac is as a 
pdf file. If I open the file in Acrobat reader it looks really good and 
crisp, and is obviously saved as vector graphics, since I can zoom in 
as much as I like and it continues to look really nice. If I import it 
into MS Word (from office 2000), or Textedit, however, it imports it as 
a bitmap and unless I save it as a pretty big image and then shrink it 
in size by about three times after import it looks blurry and 
pixellated. The save it as a really big picture and shrink it option is 
bearable, but hardly elegant.

I'm trying to persuade some other people in my department that we 
should move to using R as a standard analysis package, and this is 
currently one strike against it - it's difficult to export 
decent-looking high-res graphics. If I want to persuade people to use 
R, I need to be able to give them an easy way to do this. There are 
some solutions like importing the text and then the graphics into 
acrobat, or installing ghostscript and trying it with the graphics as 
postscript, but obviously people will respond to this with 'why should 
I waste time and or money doing this when I can just cut and paste out 
of Excel/Statistica/Minitab'. I realise that this is arguably more of a 
problem with Word or Textedit, but does anyone know of a good easy 
solution to this that I can use as part of my program to evangelise my 
colleagues?

Thanks for any help

Rob Knell



From ramasamy at cancer.org.uk  Thu Jul 22 14:01:05 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 22 Jul 2004 13:01:05 +0100
Subject: [R] Disriminant analysis with lda (MASS)
In-Reply-To: <9EF38639FDD6DE40BC8DAC9E6C901A1E0C4995@ps.borzen.local>
References: <9EF38639FDD6DE40BC8DAC9E6C901A1E0C4995@ps.borzen.local>
Message-ID: <1090497664.3101.26.camel@vpn202001.lif.icnet.uk>

If memory serves, Fisher's Discriminant analysis produces the same
results as lda for two groups although the assumption and derivations
are different. Google search produces
http://www.statsoftinc.com/textbook/stdiscan.html

In the middle of page 347 of MASS 3 (sorry no latest copy here), it
mentions how LDA is related to Fishers.

I believe Pattern Recognition and Neural Networks (1996) talks more
about the equivalence of these two with two groups.


On Thu, 2004-07-22 at 10:39, Borut Rajer wrote:
> Hello,
> 
> Does the "lda" function (package MASS) perform or can it perform classic
> two-group Fisher discriminant analysis?
> 
> R-version: 1.9.1, MASS package (latest available)
> 
> Thank you,  
> 
> Borut Rajer
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rpeng at jhsph.edu  Thu Jul 22 14:35:35 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 22 Jul 2004 08:35:35 -0400
Subject: [R] add more data to a data file, problem with .Rprofile
In-Reply-To: <16638.57446.251410.449782@localhost.localdomain>
References: <16638.57446.251410.449782@localhost.localdomain>
Message-ID: <40FFB497.9010609@jhsph.edu>

You should take a look at ?setHook if you use hsv() in .Rprofile. 
That way when the `graphics' package is loaded, it will automatically 
run whatever hook function you specified involving hsv().  For 
example, you might include something like

setHook(packageEvent("graphics", "onLoad"),
	function(...) {
		hsv <- graphics::hsv
		## Do whatever you need to do with hsv()
	})

-roger

Francisco J Molina wrote:
> Hi,
> 
> Is there a way to incorporate an R object x to a file already
> containing R objects? It seems that 'save' is not capable to do
> this. If I save x to a file containing previously saved data, then
> I will lose this data.
> 
> I use the funcion hsv in .Rprofile but it is recognized.
> Couriously, if I source .Rprofile when R is already running I do
> not get any error message.
> 
> Thank you.
> 
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Thu Jul 22 14:55:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jul 2004 13:55:05 +0100 (BST)
Subject: [R] exporting high quality graphics from R in Mac OSX
In-Reply-To: <D1912480-DBD1-11D8-9ADD-000D9335A24A@qmul.ac.uk>
Message-ID: <Pine.LNX.4.44.0407221349400.31003-100000@gannet.stats>

R's PDF is indeed vector graphics.  Given that PDF is supposedly the
native graphics representation on MacOS X, it sounds as if you are not
using MacOS X native applications (and Office 2000 cannot be, given its
date).  If you are indeed using classic MacOS applications then the native
graphics format is different and PDF is foreign.  Might this be as simple
as using up-to-date MacOS X versions of your other applications?

On Thu, 22 Jul 2004, Rob Knell wrote:

> Hi there
> 
> The default option for saving graphics from R (1.9.1) on my Mac is as a 
> pdf file. If I open the file in Acrobat reader it looks really good and 
> crisp, and is obviously saved as vector graphics, since I can zoom in 
> as much as I like and it continues to look really nice. If I import it 
> into MS Word (from office 2000), or Textedit, however, it imports it as 
> a bitmap and unless I save it as a pretty big image and then shrink it 
> in size by about three times after import it looks blurry and 
> pixellated. The save it as a really big picture and shrink it option is 
> bearable, but hardly elegant.
> 
> I'm trying to persuade some other people in my department that we 
> should move to using R as a standard analysis package, and this is 
> currently one strike against it - it's difficult to export 
> decent-looking high-res graphics. 

Not true: the export _is_ high quality and your subject line is blaming
the wrong tool.

> If I want to persuade people to use 
> R, I need to be able to give them an easy way to do this. There are 
> some solutions like importing the text and then the graphics into 
> acrobat, or installing ghostscript and trying it with the graphics as 
> postscript, but obviously people will respond to this with 'why should 
> I waste time and or money doing this when I can just cut and paste out 
> of Excel/Statistica/Minitab'. I realise that this is arguably more of a 
> problem with Word or Textedit, but does anyone know of a good easy 
> solution to this that I can use as part of my program to evangelise my 
> colleagues?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From R.Knell at qmul.ac.uk  Thu Jul 22 15:03:23 2004
From: R.Knell at qmul.ac.uk (Rob Knell)
Date: Thu, 22 Jul 2004 14:03:23 +0100
Subject: [R] exporting high quality graphics from R in Mac OSX
In-Reply-To: <Pine.LNX.4.44.0407221349400.31003-100000@gannet.stats>
References: <Pine.LNX.4.44.0407221349400.31003-100000@gannet.stats>
Message-ID: <8343B631-DBDF-11D8-9ADD-000D9335A24A@qmul.ac.uk>

Nope, sorry, I made a mistake - it's Office vX, native for OSX. I've 
had a look around and found quite a few complaints on the 'net about 
Word X claiming to be OSX native but rendering the image as a scruffy 
bitmap, so I guess this is a Word problem. I don't want to invest in 
the newest version of MS Office, which might do it properly... maybe 
I'll hang on for the Aqua version of Open Office, so I can expunge MS 
from my hard drive.

Cheers


Rob



On 22 Jul 2004, at 13:55, Prof Brian Ripley wrote:

> R's PDF is indeed vector graphics.  Given that PDF is supposedly the
> native graphics representation on MacOS X, it sounds as if you are not
> using MacOS X native applications (and Office 2000 cannot be, given its
> date).  If you are indeed using classic MacOS applications then the 
> native
> graphics format is different and PDF is foreign.  Might this be as 
> simple
> as using up-to-date MacOS X versions of your other applications?
>
> On Thu, 22 Jul 2004, Rob Knell wrote:
>
>> Hi there
>>
>> The default option for saving graphics from R (1.9.1) on my Mac is as 
>> a
>> pdf file. If I open the file in Acrobat reader it looks really good 
>> and
>> crisp, and is obviously saved as vector graphics, since I can zoom in
>> as much as I like and it continues to look really nice. If I import it
>> into MS Word (from office 2000), or Textedit, however, it imports it 
>> as
>> a bitmap and unless I save it as a pretty big image and then shrink it
>> in size by about three times after import it looks blurry and
>> pixellated. The save it as a really big picture and shrink it option 
>> is
>> bearable, but hardly elegant.
>>
>> I'm trying to persuade some other people in my department that we
>> should move to using R as a standard analysis package, and this is
>> currently one strike against it - it's difficult to export
>> decent-looking high-res graphics.
>
> Not true: the export _is_ high quality and your subject line is blaming
> the wrong tool.
>
>> If I want to persuade people to use
>> R, I need to be able to give them an easy way to do this. There are
>> some solutions like importing the text and then the graphics into
>> acrobat, or installing ghostscript and trying it with the graphics as
>> postscript, but obviously people will respond to this with 'why should
>> I waste time and or money doing this when I can just cut and paste out
>> of Excel/Statistica/Minitab'. I realise that this is arguably more of 
>> a
>> problem with Word or Textedit, but does anyone know of a good easy
>> solution to this that I can use as part of my program to evangelise my
>> colleagues?
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From Christian.Stratowa at vie.boehringer-ingelheim.com  Thu Jul 22 15:11:58 2004
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Thu, 22 Jul 2004 15:11:58 +0200
Subject: [R] RE: Comparison of correlation coefficients - Details
Message-ID: <F848C7E68BD94E489A03F6C2351BB0013CFD9D@vieex02.eu.boehringer.com>

Dear Ioannis

Thank you very much for pointing me to meta-analysis. Although it
may not solve my problem with the normalization, it gives me some
other options to display the different correlation coefficients.

One possibility is the use of Funnel plots, which are even available
in library(rmeta). Another possibility is the use of forest-plots, 
as implemented in rmeta as metaplot. Sorrowly, rmeta does not include 
the Rosenthal-Rubin method or the Hunter-Schmidt method, as described
in "Meta-Analysis of Correlations", see:
   http://www.sussex.ac.uk/Users/andyf/teaching/pg/meta.pdf
Probably, the best solution for me may be to modify metaplot for
the Hunter-Schmidt method.
BTW, the manual to the program Meta-Analysis 5.3, is also very helpful,
see: http://userpage.fu-berlin.de/~health/meta_e.htm

Further suggestions in this direction are greatly appreciated.

Best regards
Christian Stratowa

-----Original Message-----
From: idimakos at upatras.gr [mailto:idimakos at upatras.gr] 
Sent: Wednesday, July 21, 2004 18:07
To: Christian.Stratowa at vie.boehringer-ingelheim.com
Cc: bioconductor at stat.math.ethz.ch; r-help at stat.math.ethz.ch
Subject: Re: [R] RE: Comparison of correlation coefficients - Details


That sounds very close to a meta-analytic comparison of two statistics. 
As a matter of fact, the Rosenthal & Rubin approach transforms all primary
statistics into Pearson r and then to Fisher's z and then follows with
comparisons.  More, comparisons can take into account sample sizes, or the
value of some other predictor variable.

I believe there is a Rosenthal book on meta-analysis published by Sage
publications, as well as a Brian Mullen book published by Lawrence Erlbaum.
Brian Mullen's book comes (or used to come) with a meta.exe program to
perform meta-analyses.

Hope this helps,

Ioannis

> Dear all
>
> I apologize for cross-posting, but first it is accepted custom to 
> thank the repliers and give a summary, and second I have still the 
> feeling that this problem might be a general statistical problem and 
> not necessarily related to microarrays only, but I might be wrong.
>
> First, I want to thank Robert Gentleman, Mark Kimpel and Mark Reiners 
> for their kind replies. Robert Gentleman kindly pointed me to the 
> Bioconductor package "MeasurementError.cor" as alternative to 
> "cor.test". Mark Kimpel suggested that 2-way factorial Anova or the 
> Bioconductor package "limma", respectively, may be helpful. Mark 
> Reiners suggested to use the p-value of "cor.test" to test the 
> significance.
>
> Maybe, I miss the point, but being not a statistician I am still 
> unsure if it is possible to compare correlation coefficients from 
> different sample sets. Both, the p-values from "cor.test" and from 
> "compcorr", could be used as measure of the significance. However, is 
> it possible to "normalize" correlation coefficients from different 
> sample sets? Could an expression such as "corr * (1 - pval)" be used 
> for normalization? Maybe, it is not possible to normalize correlation 
> coefficients? Would a barplot comparing the correlation coefficients 
> between two genes for different tissues be meaningful? (Alternatively, 
> I have tried to use (1-pval) to calculate the gray-level of the bars.)
>
> Any further suggestions would be appreciated very much.
>
> Best regards
> Christian Stratowa
>
> -----Original Message-----
> From: Stratowa,Dr.,Christian FEX BIG-AT-V
> Sent: Monday, July 19, 2004 15:00
> To: 'bioconductor at stat.math.ethz.ch'
> Subject: Comparison of correlation coefficients - Details
>
>
> Dear all
>
> Maybe, my last mail did not explain my problem correctly: Since we are 
> interested, which genes have similar expression profiles in a certain 
> tissue or in different tissues, we have calculated the correlation 
> coefficients between all 46,000 x 46,000 genes of the HG_U133A/B 
> chipset for about 70 tissues, where the number of samples per tissue 
> ranges from 10 to more than 200.
>
> While writing an R-function to display the correlation coefficients 
> between gene A and B in the different tissues as bar-graph, I realized 
> that it may not be correct to compare the different correlation 
> coefficients directly, since the number of samples per tissue varyies 
> between 10 and 200.
>
> Thus, the question is: Is there a way to compare different correlation 
> coefficients and/or apply some kind of normalization?
>
> Assuming that this might be a well known statistical problem I was 
> browsing statistics books and the web for more information, but could 
> only find the function "compcorr" which gives a p-value how well you 
> can trust the comparison of two correlation coefficients from 
> different samples.
>
> Even though this might currently not be a direct Bioconductor 
> question, it is certainly a microarray analysis related question. Any 
> suggestions how to solve this problem would be greatly appreciated.
>
> Best regards
> Christian Stratowa
>
>
> -----Original Message-----
> From: Stratowa,Dr.,Christian FEX BIG-AT-V
> Sent: Tuesday, July 13, 2004 14:40
> To: 'bioconductor at stat.math.ethz.ch'
> Subject: Comparison of correlation coefficients
>
>
> Dear Bioconductor expeRts
>
> Is it possible to compare correlation coefficients or to normalize 
> different correlation coefficients?
>
> Concretely, we have the following situation:
> We have gene expression profiles for different tissues, where the 
> number of samples per tissue are different, ranging from 10 to 250. We 
> are able to determine the correlation between two genes A and B for 
> each tissue separately, using "cor.test". However, the question arises 
> if the correlation coefficients between different tissues can be 
> compared or if they must somehow be "normalized", since the number of 
> samples per tissue varyies.
>
> Searching the web I found the function "compcorr", see: 
> http://www.fon.hum.uva.nl/Service/Statistics/Two_Correlations.html
> http://ftp.sas.com/techsup/download/stat/compcorr.html
> and implemented it in R:
>
> compcorr <- function(n1, r1, n2, r2){
> # compare two correlation coefficients
> # return difference and p-value as list(diff, pval)
>
> #	Fisher Z-transform
> 	zf1 <- 0.5*log((1 + r1)/(1 - r1))
> 	zf2 <- 0.5*log((1 + r2)/(1 - r2))
>
> #	difference
> 	dz <- (zf1 - zf2)/sqrt(1/(n1 - 3) + (1/(n2 - 3)))
>
> #	p-value
> 	pv <- 2*(1 - pnorm(abs(dz)))
>
> 	return(list(diff=dz, pval=pv))
> }
>
> Would it make sense to use the resultant p-value to "normalize" the 
> correlation coefficients, using: corr <- corr * compcorr()$pval
>
> Is there a better way or an alternative to "normalize" the correlation 
> coefficients obtained for different tissues?
>
> Thank you in advance for your help.
> Since in the company I am not subscribed to bioconductor-help, could 
> you please reply to me (in addition to bioconductor-help)
>
> P.S.: I have posted this first at r-help and it was suggested to me to 
> post it here, too.
>
> Best regards
> Christian Stratowa
>
> ==============================================
> Christian Stratowa, PhD
> Boehringer Ingelheim Austria
> Dept NCE Lead Discovery - Bioinformatics
> Dr. Boehringergasse 5-11
> A-1121 Vienna, Austria
> Tel.: ++43-1-80105-2470
> Fax: ++43-1-80105-2782
> email: christian.stratowa at vie.boehringer-ingelheim.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Thu Jul 22 15:28:30 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 22 Jul 2004 09:28:30 -0400
Subject: [R] exporting high quality graphics from R in Mac OSX
In-Reply-To: <8343B631-DBDF-11D8-9ADD-000D9335A24A@qmul.ac.uk>
References: <Pine.LNX.4.44.0407221349400.31003-100000@gannet.stats>
	<8343B631-DBDF-11D8-9ADD-000D9335A24A@qmul.ac.uk>
Message-ID: <h3gvf0dghoe1kvbeg5he7bf76rorg0pli2@4ax.com>

On Thu, 22 Jul 2004 14:03:23 +0100, Rob Knell <R.Knell at qmul.ac.uk>
wrote :

>Nope, sorry, I made a mistake - it's Office vX, native for OSX. I've 
>had a look around and found quite a few complaints on the 'net about 
>Word X claiming to be OSX native but rendering the image as a scruffy 
>bitmap, so I guess this is a Word problem. I don't want to invest in 
>the newest version of MS Office, which might do it properly... maybe 
>I'll hang on for the Aqua version of Open Office, so I can expunge MS 
>from my hard drive.

What file formats does Word support?  Do you know what format is used
in a cut and paste operation?

On Windows, cut and paste is usually done via Windows metafiles, and
Windows versions of R can produce those.  I don't think OSX versions
can (but my information might be out of date, I'm not an OSX user).

Duncan Murdoch



From adelmaas at musc.edu  Thu Jul 22 16:02:28 2004
From: adelmaas at musc.edu (adelmaas@musc.edu)
Date: Thu, 22 Jul 2004 10:02:28 -0400
Subject: [R] Precision in R
In-Reply-To: <200407221009.i6MA9VPn013922@hypatia.math.ethz.ch>
References: <200407221009.i6MA9VPn013922@hypatia.math.ethz.ch>
Message-ID: <C486A713-DBE7-11D8-B8F7-000A9591E11C@musc.edu>

On 22 Jul, at 06:09, r-help-request at stat.math.ethz.ch wrote:

> Message: 5
> Date: Wed, 21 Jul 2004 13:48:53 +0200
> From: bhx2 at mevik.net ( Bj?rn-Helge Mevik )
> Subject: Re: [R] Precision in R
> To: r-help at stat.math.ethz.ch
> Message-ID: <m0llhdbmxm.fsf at bar.nemo-project.org>
> Content-Type: text/plain; charset=iso-8859-1
>
> Since you didn't say anything about _what_ you did, either in SAS or
> R, my first thought was:  Have you checked that you use the same
> parametrization of the models in R and SAS?

Well, I'm running Poisson regressions for the incidence of childhood 
acute lymphoblastic leukemia in a set of US counties (and in this data 
set, for some reason, Hawaii counts as an entire county).  Separate 
models are calculated for males and females.  Independent variable of 
interest are race ("white", "black", "other") and (in the model for 
males only) -log(proportion of people in county who moved between 1985 
and 1990) (AKA "minus log proportion moved" or "MLPM").

SAS code:
> title "Males";
> proc genmod data=males order=formatted;
>         class race sex;
>         model observed = race mlpm*mlpm*mlpm mlpm*mlpm mlpm / 
> dist=poisson link=log offset=lPYAR covb;
>
> run;
>
> title "Females";
> proc genmod data=females order=formatted;
>         class race sex;
>         model observed = race / dist=poisson link=log offset=lPYAR;
> run;

R code:
> Female.model <- glm(Observed ~ Black + Other, family = 
> poisson(link=log), offset=log(PYAR), data=Females)
>
> Male.model <- glm(Observed ~ Black + Other + 
> I(Minus.log.proportion.moved^3) + I(Minus.log.proportion.moved^2) + 
> Minus.log.proportion.moved, family = poisson(link=log), 
> offset=log(PYAR), data=Males)

The difference in how race is included in the models is due to me 
wanting both programs to use "whites" as the referent group (seeing as 
I have more data from them than "blacks" and "others").

SAS results:
>                                               Males           12:08 
> Wednesday, April 21, 2004 173
>
>                                       The GENMOD Procedure
>
>                                        Model Information
>
>                                 Data Set              WORK.MALES
>                                 Distribution             Poisson
>                                 Link Function                Log
>                                 Dependent Variable      Observed
>                                 Offset Variable            lPYAR
>                                 Observations Used            526
>
>
>                                      Class Level Information
>
>                                    Class      Levels    Values
>
>                                    Race            3    B O W
>                                    Sex             1    M
>
>
>                                      Parameter Information
>
>                              Parameter       Effect            Race
>
>                              Prm1            Intercept
>                              Prm2            Race              B
>                              Prm3            Race              O
>                              Prm4            Race              W
>                              Prm5            mlPM*mlPM*mlPM
>                              Prm6            mlPM*mlPM
>                              Prm7            mlPM
>
>
>                              Criteria For Assessing Goodness Of Fit
>
>                   Criterion                 DF           Value        
> Value/DF
>
>                   Deviance                 520        239.5025         
>  0.4606
>                   Scaled Deviance          520        239.5025         
>  0.4606
>                   Pearson Chi-Square       520        360.5677         
>  0.6934
>                   Scaled Pearson X2        520        360.5677         
>  0.6934
>                   Log Likelihood                      320.5910
>
> 
>                                               Males           12:08 
> Wednesday, April 21, 2004 174
>
>                                       The GENMOD Procedure
>
>            Algorithm converged.
>
>
>                                   Estimated Covariance Matrix
>
>                 Prm1           Prm2           Prm3           Prm5      
>      Prm6           Prm7
>
>  Prm1        9.25071       -0.01841        0.04877      -13.71192      
>  37.88798      -33.20414
>  Prm2       -0.01841        0.03392       0.002521        0.03045      
>  -0.07720        0.06191
>  Prm3        0.04877       0.002521        0.02027       -0.07622      
>   0.21457       -0.18748
>  Prm5      -13.71192        0.03045       -0.07622       22.11044      
> -59.26190       50.49281
>  Prm6       37.88798       -0.07720        0.21457      -59.26190      
>    160.70        -138.32
>  Prm7      -33.20414        0.06191       -0.18748       50.49281      
>   -138.32         120.18
>
>
>                                 Analysis Of Parameter Estimates
>
>                                         Standard   Wald 95% Confidence 
>      Chi-
>    Parameter            DF   Estimate      Error          Limits       
>    Square   Pr > ChiSq
>
>    Intercept             1   -15.8294     3.0415   -21.7907    -9.8682 
>     27.09       <.0001
>    Race             B    1    -0.6646     0.1842    -1.0256    -0.3036 
>     13.02       0.0003
>    Race             O    1    -0.1058     0.1424    -0.3848     0.1733 
>      0.55       0.4575
>    Race             W    0     0.0000     0.0000     0.0000     0.0000 
>       .          .
>    mlPM*mlPM*mlPM        1    15.4205     4.7022     6.2044    24.6366 
>     10.75       0.0010
>    mlPM*mlPM             1   -36.8423    12.6768   -61.6884   -11.9961 
>      8.45       0.0037
>    mlPM                  1    27.2989    10.9627     5.8124    48.7855 
>      6.20       0.0128
>    Scale                 0     1.0000     0.0000     1.0000     1.0000
>
> NOTE: The scale parameter was held fixed.
>
> 
>                                              Females          12:08 
> Wednesday, April 21, 2004 175
>
>                                       The GENMOD Procedure
>
>                                        Model Information
>
>                                Data Set              WORK.FEMALES
>                                Distribution               Poisson
>                                Link Function                  Log
>                                Dependent Variable        Observed
>                                Offset Variable              lPYAR
>                                Observations Used              534
>
>
>                                      Class Level Information
>
>                                    Class      Levels    Values
>
>                                    Race            3    B O W
>                                    Sex             1    F
>
>
>                              Criteria For Assessing Goodness Of Fit
>
>                   Criterion                 DF           Value        
> Value/DF
>
>                   Deviance                 531        245.2305         
>  0.4618
>                   Scaled Deviance          531        245.2305         
>  0.4618
>                   Pearson Chi-Square       531        484.8219         
>  0.9130
>                   Scaled Pearson X2        531        484.8219         
>  0.9130
>                   Log Likelihood                      183.8640
>
>
>            Algorithm converged.
>
>
>                                  Analysis Of Parameter Estimates
>
>                                       Standard     Wald 95% Confidence 
>       Chi-
>   Parameter         DF    Estimate       Error           Limits        
>     Square    Pr > ChiSq
>
>   Intercept          1     -9.7630      0.0577     -9.8762     -9.6499 
>    28595.0        <.0001
>   Race         B     1     -1.0917      0.2493     -1.5803     -0.6030 
>      19.17        <.0001
>   Race         O     1      0.0014      0.1569     -0.3061      0.3088 
>       0.00        0.9931
>   Race         W     0      0.0000      0.0000      0.0000      0.0000 
>        .           .
>
> 
>                                              Females          12:08 
> Wednesday, April 21, 2004 176
>
>                                       The GENMOD Procedure
>
>                                  Analysis Of Parameter Estimates
>
>                                       Standard     Wald 95% Confidence 
>       Chi-
>   Parameter         DF    Estimate       Error           Limits        
>     Square    Pr > ChiSq
>
>   Scale              0      1.0000      0.0000      1.0000      1.0000
>
> NOTE: The scale parameter was held fixed.

R results:
> > summary(Female.model)
>
> Call:
> glm(formula = Observed ~ Black + Other, family = poisson(link = log),
>     data = Females, offset = log(PYAR))
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -2.4060  -0.5315  -0.1109  -0.0284   2.6520
>
> Coefficients:
>              Estimate Std. Error  z value Pr(>|z|)
> (Intercept) -9.763025   0.057735 -169.101  < 2e-16 ***
> BlackTRUE   -1.091679   0.249309   -4.379 1.19e-05 ***
> OtherTRUE    0.001363   0.156876    0.009    0.993
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> (Dispersion parameter for poisson family taken to be 1)
>
>     Null deviance: 272.49  on 533  degrees of freedom
> Residual deviance: 245.23  on 531  degrees of freedom
> AIC: 520.71
>
> Number of Fisher Scoring iterations: 7
>
> > summary(Male.model)
>
> Call:
> glm(formula = Observed ~ Black + Other + 
> I(Minus.log.proportion.moved^3) +
>     I(Minus.log.proportion.moved^2) + Minus.log.proportion.moved,
>     family = poisson(link = log), data = Males, offset = log(PYAR))
>
> Deviance Residuals:
>      Min        1Q    Median        3Q       Max
> -2.24568  -0.49137  -0.10197  -0.03262   3.88346
>
> Coefficients:
>                                  Estimate Std. Error z value Pr(>|z|)
> (Intercept)                     -16.39065    3.31644  -4.942 7.72e-07 
> ***
> BlackTRUE                        -0.66461    0.18418  -3.608 0.000308 
> ***
> OtherTRUE                        -0.09513    0.14278  -0.666 0.505245
> I(Minus.log.proportion.moved^3)  24.39920    7.51188   3.248 0.001162 
> **
> I(Minus.log.proportion.moved^2) -51.17011   17.75857  -2.881 0.003959 
> **
> Minus.log.proportion.moved       33.48773   13.52491   2.476 0.013286 *
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> (Dispersion parameter for poisson family taken to be 1)
>
>     Null deviance: 278.68  on 525  degrees of freedom
> Residual deviance: 240.54  on 520  degrees of freedom
> AIC: 582.68
>
> Number of Fisher Scoring iterations: 6

Now, you'll notice (after scrolling up and down a lot) that the models 
for females have identical results, but the models for males have 
different results.  Anybody have any ideas why I'm getting a difference 
and which program (if either) is giving me the right answer?  Thanks in 
advance again.

Aaron

-------------
Aaron Solomon (ben Saul Joseph) Adelman
E-mail:  adelmaas at musc.edu
Web site:  http://people.musc.edu/~adelmaas/
AOL Instant Messenger & Yahoo! Messenger:  Hiergargo
AIM chat-room (preferred):  Adelmania



From edd at debian.org  Thu Jul 22 16:26:34 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 22 Jul 2004 09:26:34 -0500
Subject: [R] Programmation pour MLE
In-Reply-To: <20040722044858.88424.qmail@web25107.mail.ukl.yahoo.com>
References: <20040722044858.88424.qmail@web25107.mail.ukl.yahoo.com>
Message-ID: <20040722142633.GA8001@sonny.eddelbuettel.com>

On Thu, Jul 22, 2004 at 06:48:58AM +0200, Ahmed Elhabti wrote:
> Je veux cherch? l?estimateur de vraisemblance maximal (MLE)d?une fonction ? 3 param?tre inconue ?tant donn? une ?chantillon de taille 50 (les observations des valeurs de x) alors comment je peux proc?d? 
> 
> La fonction de densit? est d?finie par : 
> 
>  
> 
> f(x)= 1/3(g(a1)+g(a2)+g(a3))
> 
>  
> 
> avec g(ai)=(exp(ai)*ai^x)/x! pour i=1,2,3.

The list language is English, so please pardon my reply for using it. 

This should be reasonably straightforward with optim() and a simple function
that sums the terms of the log-likelihood, see   help("optim"). 

There is also the mle function / class in stats4 which may help you as it
wraps around optim(),  see  help("mle", package="stats4").

> Je vous remercie beaucoup.

De rien.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From liao1k at cmich.edu  Thu Jul 22 16:34:35 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Thu, 22 Jul 2004 10:34:35 -0400
Subject: [R] makeinfo, tex, latex, tcl/tk
Message-ID: <291B348BC59B47468C7824603C3260829460B5@cmail3.central.cmich.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040722/d56cf4e5/attachment.pl

From liao1k at cmich.edu  Thu Jul 22 17:00:38 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Thu, 22 Jul 2004 11:00:38 -0400
Subject: [R] gcc on AIX is not compatile with R-1.9.1
Message-ID: <291B348BC59B47468C7824603C3260829460B7@cmail3.central.cmich.local>

Hi Uwe Liqqes,
   Does the successful compilation for R-1.9.1 on AIX 5.1 depend on the
IBM AIX compiler for C and C++ (xlc/xlC)? gcc on AIX is not compatible
with R1.9.1.

Kexiao


-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Sunday, July 18, 2004 8:19 AM
To: Liao, Kexiao
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Install R on AIX 5.2 64 Bit

Liao, Kexiao wrote:

> Hi your guys,
> 
>     Recently, I installed R-1.9.1 on AIX 5.2 with 64 bits environment;
I
> already have following software installed on AIX before I compile
> R-1.9.1 source codes:
> 
>  
> 
> g++ 2.9.aix51.020209-4  The GNU C++ compiler and headers
> 
> gcc 2.9.aix51.020209-4  The GNU gcc C compiler and headers
> 
> xlf  XL   Fortran for AIX
> 
> perl 5.6.1-2 
> 
> zlib 1.1.3-10
> 
>  
> 
>    For latex and makeinfo stuffs, I have not found from my AIX 5.2
P690
> system.
> 
>  
> 
>  After I run the following command:
> 
> configure
> 
> make
> 

What about "make check"? And thereafter "make install"?

> 
> Following executable binaries codes have been generated in RHOME/bin
> directory:
> 
>  
> 
> bash-2.05b$ ls -al
> 

[SNIP]

> bash-2.05b$ pwd
> 
> /home/liao1k/r-1.9.1/R-1.9.1/bin
> 
> bash-2.05b$
> 
> 
> However if I run R command, I got following error message:
> 
> bash-2.05b$ ./R
> 
> Fatal error: unable to open the base package

So either you don't have permission to read .../library/base/...
or compilation was not successful and the package(s) have not been
created.
Please tell us the error messages which appeared during compilation, and

try running make check, if there were no error messages....

Uwe Ligges


> 
>   Can any one give me some advice? Thanks in advance!
> 
>  
> 
> Kexiao



From mai99brr at studserv.uni-leipzig.de  Thu Jul 22 17:24:00 2004
From: mai99brr at studserv.uni-leipzig.de (mai99brr@studserv.uni-leipzig.de)
Date: Thu, 22 Jul 2004 17:24:00 +0200 (CEST)
Subject: [R] Problem with listbox
Message-ID: <1090509840.40ffdc1042695@mail.uni-leipzig.de>

Hi!

I'm using two listboxes for some selection. When I select an entry in one 
listbox than the selection in the other listbox disappears. How can I keep the 
selection visible in the listbox which lost the focus?

Thanks!
Torsten



From souleymane.ndoye at gazdefrance.com  Thu Jul 22 17:24:48 2004
From: souleymane.ndoye at gazdefrance.com (Souleymane NDOYE)
Date: Thu, 22 Jul 2004 17:24:48 +0200
Subject: [R] package nls2 for windows
Message-ID: <OF9FAE25D1.93D96A64-ON41256ED9.005A055B-41256ED9.005A294C@notes.edfgdf.fr>

Dear Madam or sir,

Does anyone know if there is a pre-compiled version of package nls2 for
       windows, please?

Thank you.



Souleymane



From ripley at stats.ox.ac.uk  Thu Jul 22 18:09:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jul 2004 17:09:00 +0100 (BST)
Subject: [R] package nls2 for windows
In-Reply-To: <OF9FAE25D1.93D96A64-ON41256ED9.005A055B-41256ED9.005A294C@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.44.0407221705420.8567-100000@gannet.stats>

Have you tried Google?  The first two entries for `nls2 Windows' explain 
this for you.

I suspect very few readers of R-help even know what `nls2' is -- it is 
not a package on CRAN , not in any other repository mentioned in the FAQ.
I am guessing you mean the one Google throws up.


On Thu, 22 Jul 2004, Souleymane NDOYE wrote:

> Dear Madam or sir,
> 
> Does anyone know if there is a pre-compiled version of package nls2 for
>        windows, please?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From umalvarez at fata.unam.mx  Thu Jul 22 19:00:10 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Thu, 22 Jul 2004 12:00:10 -0500 (CDT)
Subject: [R] exporting high quality graphics from R in Mac OSX
In-Reply-To: <8343B631-DBDF-11D8-9ADD-000D9335A24A@qmul.ac.uk>
Message-ID: <Pine.LNX.4.44.0407221157290.12922-100000@athena.fata.unam.mx>

Hi!

There is one more option that you may try:

dev.copy2eps(file="file_name.eps")

Good look.

On Thu, 22 Jul 2004, Rob Knell wrote:

> Nope, sorry, I made a mistake - it's Office vX, native for OSX. I've 
> had a look around and found quite a few complaints on the 'net about 
> Word X claiming to be OSX native but rendering the image as a scruffy 
> bitmap, so I guess this is a Word problem. I don't want to invest in 
> the newest version of MS Office, which might do it properly... maybe 
> I'll hang on for the Aqua version of Open Office, so I can expunge MS 
> from my hard drive.
> 
> Cheers
> 
> 
> Rob
> 
> 
> 
> On 22 Jul 2004, at 13:55, Prof Brian Ripley wrote:
> 
> > R's PDF is indeed vector graphics.  Given that PDF is supposedly the
> > native graphics representation on MacOS X, it sounds as if you are not
> > using MacOS X native applications (and Office 2000 cannot be, given its
> > date).  If you are indeed using classic MacOS applications then the 
> > native
> > graphics format is different and PDF is foreign.  Might this be as 
> > simple
> > as using up-to-date MacOS X versions of your other applications?
> >
> > On Thu, 22 Jul 2004, Rob Knell wrote:
> >
> >> Hi there
> >>
> >> The default option for saving graphics from R (1.9.1) on my Mac is as 
> >> a
> >> pdf file. If I open the file in Acrobat reader it looks really good 
> >> and
> >> crisp, and is obviously saved as vector graphics, since I can zoom in
> >> as much as I like and it continues to look really nice. If I import it
> >> into MS Word (from office 2000), or Textedit, however, it imports it 
> >> as
> >> a bitmap and unless I save it as a pretty big image and then shrink it
> >> in size by about three times after import it looks blurry and
> >> pixellated. The save it as a really big picture and shrink it option 
> >> is
> >> bearable, but hardly elegant.
> >>
> >> I'm trying to persuade some other people in my department that we
> >> should move to using R as a standard analysis package, and this is
> >> currently one strike against it - it's difficult to export
> >> decent-looking high-res graphics.
> >
> > Not true: the export _is_ high quality and your subject line is blaming
> > the wrong tool.
> >
> >> If I want to persuade people to use
> >> R, I need to be able to give them an easy way to do this. There are
> >> some solutions like importing the text and then the graphics into
> >> acrobat, or installing ghostscript and trying it with the graphics as
> >> postscript, but obviously people will respond to this with 'why should
> >> I waste time and or money doing this when I can just cut and paste out
> >> of Excel/Statistica/Minitab'. I realise that this is arguably more of 
> >> a
> >> problem with Word or Textedit, but does anyone know of a good easy
> >> solution to this that I can use as part of my program to evangelise my
> >> colleagues?
> >
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From Rau at demogr.mpg.de  Thu Jul 22 19:17:36 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Thu, 22 Jul 2004 19:17:36 +0200
Subject: [R] Replace only Capital Letters
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A0B60@hermes.demogr.mpg.de>

Dear All,

I have these data:

exampledata <- c("This is one item", "This is Another One", "And so is
This")

I would like to find each occurence of a blank space followed by a Capital
Letter and replace it by a blank space, a left curly brace, the respective
Capital Letter, and then a right curly brace.

I thought the following will do:
gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata,
ignore.case=FALSE)

Unfortunately, the actual output was:
"This {i}s {o}ne {i}tem"    "This {i}s {A}nother {O}ne" "And {s}o {i}s
{T}his"  

But what I wanted was actually:
"This is one item"    "This is {A}nother {O}ne" "And so is {T}his"  

Can anyone tell me what I should change. Should be fairly easy for people
with more experience than me using regular expressions, I guess.

Thanks,
Roland

P.S. The background is my bibliography-file for BibTeX. If the title field
has some content like "An analysis of Denmark", it would actually turn out
to be "An analysis of denmark" in my dvi-document. Of course, R is not the
appropriate tool for this. But apart from the little problem outlined above,
I had a function doing what I wanted in less than 10 minutes.


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From ripley at stats.ox.ac.uk  Thu Jul 22 19:34:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jul 2004 18:34:26 +0100 (BST)
Subject: [R] Replace only Capital Letters
In-Reply-To: <3699CDBC4ED5D511BE6400306E1C0D81030A0B60@hermes.demogr.mpg.de>
Message-ID: <Pine.LNX.4.44.0407221833260.15001-100000@gannet.stats>

This appears to be a bug.  Please try

gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata, perl=TRUE)



On Thu, 22 Jul 2004, Rau, Roland wrote:

> Dear All,
> 
> I have these data:
> 
> exampledata <- c("This is one item", "This is Another One", "And so is
> This")
> 
> I would like to find each occurence of a blank space followed by a Capital
> Letter and replace it by a blank space, a left curly brace, the respective
> Capital Letter, and then a right curly brace.
> 
> I thought the following will do:
> gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata,
> ignore.case=FALSE)
> 
> Unfortunately, the actual output was:
> "This {i}s {o}ne {i}tem"    "This {i}s {A}nother {O}ne" "And {s}o {i}s
> {T}his"  
> 
> But what I wanted was actually:
> "This is one item"    "This is {A}nother {O}ne" "And so is {T}his"  
> 
> Can anyone tell me what I should change. Should be fairly easy for people
> with more experience than me using regular expressions, I guess.
> 
> Thanks,
> Roland
> 
> P.S. The background is my bibliography-file for BibTeX. If the title field
> has some content like "An analysis of Denmark", it would actually turn out
> to be "An analysis of denmark" in my dvi-document. Of course, R is not the
> appropriate tool for this. But apart from the little problem outlined above,
> I had a function doing what I wanted in less than 10 minutes.
> 
> 
> +++++
> This mail has been sent through the MPI for Demographic Rese...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From yunfeng at scripps.edu  Thu Jul 22 19:42:48 2004
From: yunfeng at scripps.edu (Yunfeng Hu)
Date: Thu, 22 Jul 2004 10:42:48 -0700
Subject: [R] questions about principle component analysis (princomp)
In-Reply-To: <40FF5ED1.70605@rcs.urz.tu-dresden.de>
References: <DE658826-DB69-11D8-9B0D-000A95AB543C@scripps.edu>
	<40FF5ED1.70605@rcs.urz.tu-dresden.de>
Message-ID: <8C6E85F1-DC06-11D8-A4C1-000A95AB543C@scripps.edu>

Thank you, Thomas. It is very helpful. I will dig more into the man 
page but for now I get what I want.

Yunfeng
On Jul 21, 2004, at 11:29 PM, Thomas Petzoldt wrote:

> Yunfeng Hu wrote:
>> Hi, I am a new R user and am currently using princomp to conduct a 
>> PCA. I have read the help(princomp) and still do not quite understand 
>> everything in the help. Basically I want to get the covariance 
>> matrix, and eigenvector/eigenvalues (loadings()?) so that I can find 
>> the principle components. Thanks!
>
> Hello,
>
> you may start with the examples at the bottom of the help page to get 
> more understanding. Here is a modified version of that example:
>
>  data(USArrests)
>  pc<- princomp(USArrests)
>
>  summary(pc)
>  loadings(pc)
>
>  plot(pc)
>  biplot(pc)
>
> # some other useful methods mentioned on the help page:
>
>  cov(USArrests)          # covariance matrix
>  eigen(cov(USArrests))   # eigenvalues/vector
>
> # and a way to show, what things are stored in pc
>
>  str(pc)
>
> # so they can be extracted as shown on the help page.
>
> # Please note, that the scaled version (correlation matrix)
> # would be more appropriate there, e.g.
>
>  pc<- princomp(USArrests, cor=TRUE)
>  summary(pc)
>  cor(USArrests)
>  eigen(cor(USArrests))
>
>
> Hope it helps
>
> Thomas P.
>
>
###################################
Research Associate, Ph.D
Department of Molecular Biology, MB-5
The Scripps Research Institute
10550 North Torrey Pines Road
La Jolla, CA 92037
Tel. (858) 784-2204
Fax. (858) 784-2860
Emal: yunfeng at scripps.edu
Web: http://www.scripps.edu/~yunfeng
###################################



From ripley at stats.ox.ac.uk  Thu Jul 22 19:57:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jul 2004 18:57:33 +0100 (BST)
Subject: [R] Replace only Capital Letters
In-Reply-To: <Pine.LNX.4.44.0407221833260.15001-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0407221854110.15085-100000@gannet.stats>

Another solution (that is correct in other locales than C, since I see 
you are not in an English locale).

gsub(pattern = " ([[:upper:]])", replacement = " {\\1}", x=exampledata)

I think this _is_ the problem, as in your locale (and in en_GB) the sort 
order is probably something like

aAbB...zZ

Or just try the C locale.

On Thu, 22 Jul 2004, Prof Brian Ripley wrote:

> This appears to be a bug.  Please try
> 
> gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata, perl=TRUE)
> 
> 
> 
> On Thu, 22 Jul 2004, Rau, Roland wrote:
> 
> > Dear All,
> > 
> > I have these data:
> > 
> > exampledata <- c("This is one item", "This is Another One", "And so is
> > This")
> > 
> > I would like to find each occurence of a blank space followed by a Capital
> > Letter and replace it by a blank space, a left curly brace, the respective
> > Capital Letter, and then a right curly brace.
> > 
> > I thought the following will do:
> > gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata,
> > ignore.case=FALSE)
> > 
> > Unfortunately, the actual output was:
> > "This {i}s {o}ne {i}tem"    "This {i}s {A}nother {O}ne" "And {s}o {i}s
> > {T}his"  
> > 
> > But what I wanted was actually:
> > "This is one item"    "This is {A}nother {O}ne" "And so is {T}his"  
> > 
> > Can anyone tell me what I should change. Should be fairly easy for people
> > with more experience than me using regular expressions, I guess.
> > 
> > Thanks,
> > Roland
> > 
> > P.S. The background is my bibliography-file for BibTeX. If the title field
> > has some content like "An analysis of Denmark", it would actually turn out
> > to be "An analysis of denmark" in my dvi-document. Of course, R is not the
> > appropriate tool for this. But apart from the little problem outlined above,
> > I had a function doing what I wanted in less than 10 minutes.
> > 
> > 
> > +++++
> > This mail has been sent through the MPI for Demographic Rese...{{dropped}}
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From plorch at email.unc.edu  Thu Jul 22 21:10:45 2004
From: plorch at email.unc.edu (Patrick Lorch)
Date: Thu, 22 Jul 2004 15:10:45 -0400
Subject: [R] sorting Trellis panels
Message-ID: <D599630A-DC12-11D8-8C58-000A95903B7A@email.unc.edu>

Can anyone explain how to properly use index.cond?  I cannot include it 
in the xyplot command and get what I expect.  For example,

	plot<-xyplot(y ~ x | z, data)
# let's say z is a factor with six levels

gives a nice plot but I am unhappy with the order of panels.  I can get 
the order I want by

	plot$index.plot[[1]]<-c(1,6,4,3,2,5)

I cannot seem to get it with either

	plot<-xyplot(y ~ x | z, data,index.cond=list(order(c(1, ,6,4,3,2,5))))
or
	plot<-xyplot(y ~ x | z, data)
	plot
	update(plot,index.cond=list(order(c(1,6,4,3,2,5))))

I suspect it is some obvious misunderstanding of my use of 
list(order(...)).

Thanks for any help you can give,
	 -Pat

Dr. Patrick D. Lorch

                 plorch at email.unc.edu
      http://www.unc.edu/~plorch/lorch.html
Department of Biology           W: 919-843-2320
University of North Carolina    F: 919-962-1625
   at Chapel Hill
CB#3280, Coker Hall
Chapel Hill, NC 27599-3280
USA



From wolski at molgen.mpg.de  Thu Jul 22 21:17:30 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 22 Jul 2004 21:17:30 +0200
Subject: [R] biplot & identify
Message-ID: <200407222117300607.11E582B0@mail.math.fu-berlin.de>

Hi!

Is there a way to get biplot and identify to work togheter.

Having the output of prcomp I would like to draw a biplot that.
Instead of plotting the sample (row-names) names plots some "pch" symbols. (thats easy with xlabs)

But now I would like to add using identify the names to only some of the points. I have noticed that both biplot.prcomp and biplot.default does a lot of scaling.

So has anyone a function like identify.prcomp please?


Is it possible?

Sincerely
Eryk


Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From deepayan at cs.wisc.edu  Thu Jul 22 21:19:38 2004
From: deepayan at cs.wisc.edu (Deepayan Sarkar)
Date: Thu, 22 Jul 2004 14:19:38 -0500
Subject: [R] sorting Trellis panels
In-Reply-To: <D599630A-DC12-11D8-8C58-000A95903B7A@email.unc.edu>
References: <D599630A-DC12-11D8-8C58-000A95903B7A@email.unc.edu>
Message-ID: <1090523978.4100134a38100@www-auth.cs.wisc.edu>

Quoting Patrick Lorch <plorch at email.unc.edu>:

> Can anyone explain how to properly use index.cond?  I cannot include it 
> in the xyplot command and get what I expect.  For example,
> 
> 	plot<-xyplot(y ~ x | z, data)
> # let's say z is a factor with six levels
> 
> gives a nice plot but I am unhappy with the order of panels.  I can get 
> the order I want by
> 
> 	plot$index.plot[[1]]<-c(1,6,4,3,2,5)
> 
> I cannot seem to get it with either
> 
> 	plot<-xyplot(y ~ x | z, data,index.cond=list(order(c(1, ,6,4,3,2,5))))
> or
> 	plot<-xyplot(y ~ x | z, data)
> 	plot
> 	update(plot,index.cond=list(order(c(1,6,4,3,2,5))))
> 
> I suspect it is some obvious misunderstanding of my use of 
> list(order(...)).

I don't see why you are trying to use order. Dropping it should give you what
you want, i.e.,

xyplot(y ~ x | z, data, index.cond=list(c(1,6,4,3,2,5)))

Deepayan



From liao1k at cmich.edu  Thu Jul 22 21:39:01 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Thu, 22 Jul 2004 15:39:01 -0400
Subject: [R] compile error on aix 5.2 using gcc 2.9-aix51-020209
Message-ID: <291B348BC59B47468C7824603C3260829460BF@cmail3.central.cmich.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040722/cb9a0c6a/attachment.pl

From adelmaas at musc.edu  Thu Jul 22 21:53:57 2004
From: adelmaas at musc.edu (adelmaas@musc.edu)
Date: Thu, 22 Jul 2004 15:53:57 -0400
Subject: [R] Precision in R--SOLVED!
Message-ID: <DE2289D4-DC18-11D8-928D-000A9591E11C@musc.edu>

Greetings.

I'd like to thank everyone who sent me suggestions of what might have 
been wrong, especially Matt Austin.  He did not actually give me the 
solution, but rather he inadvertently set me on the path to find it by 
effectively getting me to look closer at the code I was using.  And 
thus I found myself examining my R and SAS code line by line to see how 
they differed, and I found that I was not defining "proportion moved" 
in quite the same way in the SAS and R versions.  Once I made R define 
"proportion moved" the same way as I did in SAS, both versions returned 
identical results.  Thanks again, everybody.

Aaron
-------------
Aaron Solomon (ben Saul Joseph) Adelman
E-mail:  adelmaas at musc.edu
Web site:  http://people.musc.edu/~adelmaas/
AOL Instant Messenger & Yahoo! Messenger:  Hiergargo
AIM chat-room (preferred):  Adelmania



From R.Knell at qmul.ac.uk  Thu Jul 22 21:54:07 2004
From: R.Knell at qmul.ac.uk (Rob Knell)
Date: Thu, 22 Jul 2004 20:54:07 +0100
Subject: [R] exporting high quality graphics from R in Mac OSX - solution
In-Reply-To: <Pine.LNX.4.44.0407221157290.12922-100000@athena.fata.unam.mx>
References: <Pine.LNX.4.44.0407221157290.12922-100000@athena.fata.unam.mx>
Message-ID: <E46FAB66-DC18-11D8-9ADD-000D9335A24A@qmul.ac.uk>

Thanks to everyone for all the suggestions. Turns out this is purely a 
Word problem, so the solution is to use the word processor in Apple 
Works, which will happily import lovely crisp vectors from a pdf, do 
99% of the things you might want MS Word to do, and won't try to 
annoyingly pre-empt your desire for bullets or numbering.

Rob



From sdhyok at email.unc.edu  Thu Jul 22 22:07:47 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Thu, 22 Jul 2004 16:07:47 -0400
Subject: [R] Files and classes in a package?
Message-ID: <OAEOKPIGCLDDHAEMCAKIMEGGDBAA.sdhyok@email.unc.edu>

While installing my small package, I met a tricky problem.
For clarity, let me explain it with the following simplified example.

In ~/pkg/R/aclass.R,
    setClass("aclass", contains="bclass", representation(i="numeric"))

In ~/pkg/R/bclass.R,
    setClass("bclass", representation(j="numeric"))

After building a "pkg" package, the file pkg.R in R directory has:

    setClass("aclass", contains="bclass", representation(i="numeric"))
    setClass("bclass", representation(j="numeric"))

When combining the source files, R seems to generate one new source file
based on alphabetic orders of file names. In this case, loading the "pkg"
package failed with the following error message.

> library(pkg)
Error in methodsPackageMetaName("C", name) :
        The name of the object (e.g,. a class or generic function) to find
in the meta-data must be a single string (got an object of class "NULL")
> traceback()
12: methodsPackageMetaName("C", name)
11: classMetaName(Class)
10: getClassDef(Class, where)
9: getClass(cl, TRUE)
8: .validDataPartClass(clDef, name)
7: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,
       where)
6: makeClassRepresentation(Class, properties, superClasses, prototype,
       package, validity, access, version, sealed, where = where)
5: setClass("aclass", contains = "bclass", representation(i = "numeric"))
4: eval(expr, envir, enclos)
3: eval(i, envir)
2: sys.source(codeFile, loadenv, keep.source = keep.source)
1: library(pkg)

I suspect the reason is that class "bclass" is not defined when class
"aclass" is defined. To maintain source files effectively, I don?t want to
combine two files into one file or change their file names.

Surely, there may be elegant solutions for this somewhat trivial issue. But,
I can?t find it. Can you help me? Thanks.

Daehyok Shin



From jgentry at jimmy.harvard.edu  Thu Jul 22 22:13:52 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 22 Jul 2004 16:13:52 -0400 (EDT)
Subject: [R] Files and classes in a package?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKIMEGGDBAA.sdhyok@email.unc.edu>
Message-ID: <Pine.SOL.4.20.0407221612230.2459-100000@jaws.dfci.harvard.edu>

> Surely, there may be elegant solutions for this somewhat trivial issue. But,
> I cant find it. Can you help me? Thanks.

The 'Collate' field for DESCRIPTION.  Section 1.1.1 of the R Extensions
manual should describe it for you.



From ripley at stats.ox.ac.uk  Thu Jul 22 22:18:49 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jul 2004 21:18:49 +0100 (BST)
Subject: [R] Files and classes in a package?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKIMEGGDBAA.sdhyok@email.unc.edu>
Message-ID: <Pine.LNX.4.44.0407222116050.25614-100000@gannet.stats>

Please do read the documentation, in this case the `Writing R Extensions 
Manual.  The para starting

An optional @samp{Collate} field (or OS-specific variants
@samp{Collate. at var{OStype}}, such as e.g.@: @samp{Collate.windows}) can
be used for controlling the collation order for the R code files in a
package when these are concatenated into a single file upon installation
from source.  The default is to try collating according to the @samp{C}
locale. 

explains how to set the collation order.

On Thu, 22 Jul 2004, Shin, Daehyok wrote:

> While installing my small package, I met a tricky problem.
> For clarity, let me explain it with the following simplified example.
> 
> In ~/pkg/R/aclass.R,
>     setClass("aclass", contains="bclass", representation(i="numeric"))
> 
> In ~/pkg/R/bclass.R,
>     setClass("bclass", representation(j="numeric"))
> 
> After building a "pkg" package, the file pkg.R in R directory has:
> 
>     setClass("aclass", contains="bclass", representation(i="numeric"))
>     setClass("bclass", representation(j="numeric"))
> 
> When combining the source files, R seems to generate one new source file
> based on alphabetic orders of file names. In this case, loading the "pkg"
> package failed with the following error message.
> 
> > library(pkg)
> Error in methodsPackageMetaName("C", name) :
>         The name of the object (e.g,. a class or generic function) to find
> in the meta-data must be a single string (got an object of class "NULL")
> > traceback()
> 12: methodsPackageMetaName("C", name)
> 11: classMetaName(Class)
> 10: getClassDef(Class, where)
> 9: getClass(cl, TRUE)
> 8: .validDataPartClass(clDef, name)
> 7: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,
>        where)
> 6: makeClassRepresentation(Class, properties, superClasses, prototype,
>        package, validity, access, version, sealed, where = where)
> 5: setClass("aclass", contains = "bclass", representation(i = "numeric"))
> 4: eval(expr, envir, enclos)
> 3: eval(i, envir)
> 2: sys.source(codeFile, loadenv, keep.source = keep.source)
> 1: library(pkg)
> 
> I suspect the reason is that class "bclass" is not defined when class
> "aclass" is defined. To maintain source files effectively, I don?t want to
> combine two files into one file or change their file names.
> 
> Surely, there may be elegant solutions for this somewhat trivial issue. But,
> I can?t find it. Can you help me? Thanks.
> 
> Daehyok Shin

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jahernan at umn.edu  Thu Jul 22 22:50:42 2004
From: jahernan at umn.edu (Jose A. Hernandez)
Date: Thu, 22 Jul 2004 15:50:42 -0500
Subject: [R] Standard error of a sum
Message-ID: <410028A2.5000605@umn.edu>

Folks,

This is so simple is driving me crazy. It's not really an R question is 
more an Statistics question.

I applied a chemical in 3 different events during a growing season. I 
took 3 samples in each event to estimate mean applied chemical.

Thus, I can easily estimate means and st.err by event. I can then 
estimate the total chemical applied for the whole season by adding the 3 
means for each event. How can I estimate the standard error of this 
total applied chemical.

Thanks in advance,

Jose


event <- c(1,1,1,2,2,2,3,3,3)
chem <- c(131.75,125.92,130.09,42.67,48.26,54.56,85.05,91.17,90.86)
d.1 <- data.frame(event,chem)
attach(d.1)
s.err <- function(x) sd(x)/(sqrt(length(x)))

print(mean_event <- tapply(d.1$chem,factor(data.1$event),mean))
print(s.err_event <- tapply(d.1$chem,factor(data.1$event),s.err))

print(total_chem <- sum(mean_event))
s.err_total_chem <-



-- 
Jose A. Hernandez
Ph.D. Candidate
Precision Agriculture Center

Department of Soil, Water, and Climate
University of Minnesota
1991 Upper Buford Circle
St. Paul, MN 55108

Ph. (612) 625-0445, Fax. (612) 625-2208



From spencer.graves at pdf.com  Thu Jul 22 23:00:28 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 22 Jul 2004 14:00:28 -0700
Subject: [R] Standard error of a sum
In-Reply-To: <410028A2.5000605@umn.edu>
References: <410028A2.5000605@umn.edu>
Message-ID: <41002AEC.6010709@pdf.com>

The variance of a sum is the sum of all the elements of the 
variance-covariance matrix.  If the summands are uncorrelated, then the 
variance of the sum is the sum of the variances.  hope this helps.  
spencer graves

Jose A. Hernandez wrote:

> Folks,
>
> This is so simple is driving me crazy. It's not really an R question 
> is more an Statistics question.
>
> I applied a chemical in 3 different events during a growing season. I 
> took 3 samples in each event to estimate mean applied chemical.
>
> Thus, I can easily estimate means and st.err by event. I can then 
> estimate the total chemical applied for the whole season by adding the 
> 3 means for each event. How can I estimate the standard error of this 
> total applied chemical.
>
> Thanks in advance,
>
> Jose
>
>
> event <- c(1,1,1,2,2,2,3,3,3)
> chem <- c(131.75,125.92,130.09,42.67,48.26,54.56,85.05,91.17,90.86)
> d.1 <- data.frame(event,chem)
> attach(d.1)
> s.err <- function(x) sd(x)/(sqrt(length(x)))
>
> print(mean_event <- tapply(d.1$chem,factor(data.1$event),mean))
> print(s.err_event <- tapply(d.1$chem,factor(data.1$event),s.err))
>
> print(total_chem <- sum(mean_event))
> s.err_total_chem <-
>
>
>



From DAVID.BICKEL at PIONEER.COM  Thu Jul 22 23:50:42 2004
From: DAVID.BICKEL at PIONEER.COM (Bickel, David)
Date: Thu, 22 Jul 2004 16:50:42 -0500
Subject: [R] viewing Postscript file
Message-ID: <5F883C17941B9F4E80E5FA8C9F1C5E0E010FBA22@jhms08.phibred.com>

Is there any R function that can display a Postscript file that is already in the working directory? For example, if 'graph.ps' is such a file, I'd like to type something like this:
> plot.postscript.file(file = 'graph.ps')

If no such function exists, I'd be interested in a way to use existing R functions to do this under UNIX or Windows, preferably without a system call to GhostView (gv).

Thanks,
David
_____________________________
David Bickel  http://davidbickel.com
Research Scientist
Pioneer Hi-Bred International
Bioinformatics & Exploratory Research
7250 NW 62nd Ave., PO Box 552
Johnston, Iowa 50131-0552
515-334-4739 Work
515-334-6634 Fax
david.bickel at pioneer.com, bickel at prueba.info



This communication is for use by the intended recipient and ...{{dropped}}



From laihang79 at yahoo.com  Fri Jul 23 00:14:28 2004
From: laihang79 at yahoo.com (=?gb2312?q?Hang=20Lai?=)
Date: Fri, 23 Jul 2004 06:14:28 +0800 (CST)
Subject: [R] help on R "plot"
Message-ID: <20040722221428.17530.qmail@web50110.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040723/a512ded6/attachment.pl

From jfox at mcmaster.ca  Fri Jul 23 00:40:35 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 22 Jul 2004 18:40:35 -0400
Subject: [R] help on R "plot"
In-Reply-To: <20040722221428.17530.qmail@web50110.mail.yahoo.com>
Message-ID: <20040722224031.NAIQ28143.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Hang,

Take a look at ?par, and in particular the graphical parameters mar and mai,
which can be used to adjust the size of the margins of a plot.

I hope that this helps.
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Hang Lai
> Sent: Thursday, July 22, 2004 5:14 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] help on R "plot"
> 
> Hi:
>    I have a question about the R plot, I change the size of 
> the y axis label from 1 to 2, but part of the word is missing 
> as being cut. So I guess it is over the boudary of the R 
> graphical setting. 
>     Would you please help me with it? How to change the 
> boundary so that the full part of my y axis label will appear?
>     Your help is highly appreciated!
> sincerely hang
>



From krcabrer at epm.net.co  Fri Jul 23 01:27:19 2004
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Thu, 22 Jul 2004 18:27:19 -0500
Subject: [R] Standard error of a sum
In-Reply-To: <410028A2.5000605@umn.edu>
References: <410028A2.5000605@umn.edu>
Message-ID: <41004D57.20304@epm.net.co>

If you supose that each mean is independent then

s.err_total_chem <- sqrt(sum(s.err_event^2))

If not you must estimate de var-covariance matrix to find this s.err.
This estimation will be difficult given the scarce data available.

Hope it will helps.

Kenneth

Jose A. Hernandez wrote:

> Folks,
>
> This is so simple is driving me crazy. It's not really an R question 
> is more an Statistics question.
>
> I applied a chemical in 3 different events during a growing season. I 
> took 3 samples in each event to estimate mean applied chemical.
>
> Thus, I can easily estimate means and st.err by event. I can then 
> estimate the total chemical applied for the whole season by adding the 
> 3 means for each event. How can I estimate the standard error of this 
> total applied chemical.
>
> Thanks in advance,
>
> Jose
>
>
> event <- c(1,1,1,2,2,2,3,3,3)
> chem <- c(131.75,125.92,130.09,42.67,48.26,54.56,85.05,91.17,90.86)
> d.1 <- data.frame(event,chem)
> attach(d.1)
> s.err <- function(x) sd(x)/(sqrt(length(x)))
>
> print(mean_event <- tapply(d.1$chem,factor(data.1$event),mean))
> print(s.err_event <- tapply(d.1$chem,factor(data.1$event),s.err))
>
> print(total_chem <- sum(mean_event))
> s.err_total_chem <-
>
>
>

-- 
Kenneth Roy Cabrera Torres
Celular +57 (315) 504 9339



From ramasamy at cancer.org.uk  Fri Jul 23 01:01:05 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 23 Jul 2004 00:01:05 +0100
Subject: [R] help on R "plot"
In-Reply-To: <20040722221428.17530.qmail@web50110.mail.yahoo.com>
References: <20040722221428.17530.qmail@web50110.mail.yahoo.com>
Message-ID: <1090537265.3126.7.camel@localhost.localdomain>

I am not sure if I understand your question properly but try this 

par(mfrow=c(1,3))
plot(1:10, 1:10, xlab="A very long label here")
plot(1:10, 1:10, xlab="A very long \n label here")
plot(1:10, 1:10, xlab="A very long \n label here", cex.lab=2)

Also have a look at help("par").

On Thu, 2004-07-22 at 23:14, Hang Lai wrote:
> Hi:
>    I have a question about the R plot, I change the size of the y axis label from 1 to 2, but part of the word is missing as being cut. So I guess it is over the boudary of the R graphical setting. 
>     Would you please help me with it? How to change the boundary so that the full part of my y axis label will appear?
>     Your help is highly appreciated!
> sincerely hang
>    
> 
> 
>  No pain no gain.
> That is life , full of sweet and bitter
> 
> 
> 
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jfbrennan at rogers.com  Fri Jul 23 01:35:31 2004
From: jfbrennan at rogers.com (Jim Brennan)
Date: Thu, 22 Jul 2004 19:35:31 -0400
Subject: [R] Standard error of a sum
References: <410028A2.5000605@umn.edu> <41004D57.20304@epm.net.co>
Message-ID: <005601c47044$949fbc80$3b8ac445@slnt.phub.net.cable.rogers.com>

Was just looking at this data and tried this:

> event.var<--tapply(d.1$chem,factor(d.1$event),var)
> event.var
         1          2          3
 -9.022233 -35.385033 -11.884433

Any idea why the variances are coming out negative.

> var(d.1$chem[1:3])
[1] 9.022233

right number ....

Anyway here is the answer I got if we assume independant means-- and I don't
see why not to with the info given.

> sqrt(sum(s.err_event^2))
[1] 4.331732

(sum(event.var/3*-1)^.5)
[1] 4.331732


----- Original Message -----
From: "Kenneth Cabrera" <krcabrer at epm.net.co>
To: <jahernan at umn.edu>; <r-help at stat.math.ethz.ch>
Sent: Thursday, July 22, 2004 7:27 PM
Subject: Re: [R] Standard error of a sum


> If you supose that each mean is independent then
>
> s.err_total_chem <- sqrt(sum(s.err_event^2))
>
> If not you must estimate de var-covariance matrix to find this s.err.
> This estimation will be difficult given the scarce data available.
>
> Hope it will helps.
>
> Kenneth
>
> Jose A. Hernandez wrote:
>
> > Folks,
> >
> > This is so simple is driving me crazy. It's not really an R question
> > is more an Statistics question.
> >
> > I applied a chemical in 3 different events during a growing season. I
> > took 3 samples in each event to estimate mean applied chemical.
> >
> > Thus, I can easily estimate means and st.err by event. I can then
> > estimate the total chemical applied for the whole season by adding the
> > 3 means for each event. How can I estimate the standard error of this
> > total applied chemical.
> >
> > Thanks in advance,
> >
> > Jose
> >
> >
> > event <- c(1,1,1,2,2,2,3,3,3)
> > chem <- c(131.75,125.92,130.09,42.67,48.26,54.56,85.05,91.17,90.86)
> > d.1 <- data.frame(event,chem)
> > attach(d.1)
> > s.err <- function(x) sd(x)/(sqrt(length(x)))
> >
> > print(mean_event <- tapply(d.1$chem,factor(data.1$event),mean))
> > print(s.err_event <- tapply(d.1$chem,factor(data.1$event),s.err))
> >
> > print(total_chem <- sum(mean_event))
> > s.err_total_chem <-
> >
> >
> >
>
> --
> Kenneth Roy Cabrera Torres
> Celular +57 (315) 504 9339
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From MSchwartz at MedAnalytics.com  Fri Jul 23 01:44:02 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 22 Jul 2004 18:44:02 -0500
Subject: [R] viewing Postscript file
In-Reply-To: <5F883C17941B9F4E80E5FA8C9F1C5E0E010FBA22@jhms08.phibred.com>
References: <5F883C17941B9F4E80E5FA8C9F1C5E0E010FBA22@jhms08.phibred.com>
Message-ID: <1090539842.9010.443.camel@localhost.localdomain>

On Thu, 2004-07-22 at 16:50, Bickel, David wrote:
> Is there any R function that can display a Postscript file that is
> already in the working directory? For example, if 'graph.ps' is such a
> file, I'd like to type something like this:
> > plot.postscript.file(file = 'graph.ps')
> 
> If no such function exists, I'd be interested in a way to use existing
> R functions to do this under UNIX or Windows, preferably without a
> system call to GhostView (gv).
> 
> Thanks,
> David


I am not entirely sure what your expectations are here.

As you probably know, Postscript files (like PDF files) are text files
that describe how to draw an image. It requires a Postscript interpreter
(typically Ghostscript) to read the contents of the PS file and then
something like GSview (or gv or ggv or ...) as a front end to render the
image.

It is illusory, but you could create a R wrapper function and call it
plot.postcript.file():

plot.postscript.file <- function(file = "Rplots.ps")
{
  # define viewer for UNIX/LINUX or Windows
  viewer <- ifelse(.Platform$OS.type == "unix", "gv", "GSview")
   
  system(paste(viewer, file, sep = " "))
}


So:

postscript("graph.ps")
barplot(1:5)
dev.off()
plot.postscript.file("graph.ps")

HTH,

Marc Schwartz



From andy_liaw at merck.com  Fri Jul 23 01:58:31 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 22 Jul 2004 19:58:31 -0400
Subject: [R] gcc on AIX is not compatile with R-1.9.1
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80DE@usrymx25.merck.com>

> From: Liao, Kexiao
> 
> Hi Uwe Liqqes,
>    Does the successful compilation for R-1.9.1 on AIX 5.1 
> depend on the
> IBM AIX compiler for C and C++ (xlc/xlC)? gcc on AIX is not compatible
> with R1.9.1.

I believe GCC will work on AIX, but you most likely need a newer version
than what you have.  I believe the R-admin manual mentioned success with
2.95.

With regard to your other question:  You can compile R w/o having any of
those.  You just won't be able to build the manuals or use the tcltk
package.  Go through the R-admin manual carefully to see how to build R
without tcltk.

Andy

 
> Kexiao
>



From sundar.dorai-raj at PDF.COM  Fri Jul 23 01:59:52 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 22 Jul 2004 18:59:52 -0500
Subject: [R] Standard error of a sum
In-Reply-To: <005601c47044$949fbc80$3b8ac445@slnt.phub.net.cable.rogers.com>
References: <410028A2.5000605@umn.edu> <41004D57.20304@epm.net.co>
	<005601c47044$949fbc80$3b8ac445@slnt.phub.net.cable.rogers.com>
Message-ID: <410054F8.20504@pdf.com>



Jim Brennan wrote:
> Was just looking at this data and tried this:
> 
> 
>>event.var<--tapply(d.1$chem,factor(d.1$event),var)
>>event.var
> 
>          1          2          3
>  -9.022233 -35.385033 -11.884433
> 
> Any idea why the variances are coming out negative.
> 

Yes, I think you meant:

event.var <- tapply(d.1$chem,factor(d.1$event),var)

(note: second dash negated your result)
> 
>>var(d.1$chem[1:3])
> 
> [1] 9.022233
> 
> right number ....
> 
> Anyway here is the answer I got if we assume independant means-- and I don't
> see why not to with the info given.
> 
> 
>>sqrt(sum(s.err_event^2))
> 
> [1] 4.331732
> 
> (sum(event.var/3*-1)^.5)
> [1] 4.331732
> 
> 
> ----- Original Message -----
> From: "Kenneth Cabrera" <krcabrer at epm.net.co>
> To: <jahernan at umn.edu>; <r-help at stat.math.ethz.ch>
> Sent: Thursday, July 22, 2004 7:27 PM
> Subject: Re: [R] Standard error of a sum
> 
> 
> 
>>If you supose that each mean is independent then
>>
>>s.err_total_chem <- sqrt(sum(s.err_event^2))
>>
>>If not you must estimate de var-covariance matrix to find this s.err.
>>This estimation will be difficult given the scarce data available.
>>
>>Hope it will helps.
>>
>>Kenneth
>>
>>Jose A. Hernandez wrote:
>>
>>
>>>Folks,
>>>
>>>This is so simple is driving me crazy. It's not really an R question
>>>is more an Statistics question.
>>>
>>>I applied a chemical in 3 different events during a growing season. I
>>>took 3 samples in each event to estimate mean applied chemical.
>>>
>>>Thus, I can easily estimate means and st.err by event. I can then
>>>estimate the total chemical applied for the whole season by adding the
>>>3 means for each event. How can I estimate the standard error of this
>>>total applied chemical.
>>>
>>>Thanks in advance,
>>>
>>>Jose
>>>
>>>
>>>event <- c(1,1,1,2,2,2,3,3,3)
>>>chem <- c(131.75,125.92,130.09,42.67,48.26,54.56,85.05,91.17,90.86)
>>>d.1 <- data.frame(event,chem)
>>>attach(d.1)
>>>s.err <- function(x) sd(x)/(sqrt(length(x)))
>>>
>>>print(mean_event <- tapply(d.1$chem,factor(data.1$event),mean))
>>>print(s.err_event <- tapply(d.1$chem,factor(data.1$event),s.err))
>>>
>>>print(total_chem <- sum(mean_event))
>>>s.err_total_chem <-
>>>
>>>
>>>
>>
>>--
>>Kenneth Roy Cabrera Torres
>>Celular +57 (315) 504 9339
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
> 
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From n.a.mehta-alumni at lse.ac.uk  Fri Jul 23 02:48:15 2004
From: n.a.mehta-alumni at lse.ac.uk (Nirav Mehta)
Date: Thu, 22 Jul 2004 20:48:15 -0400
Subject: [R] vetor autoregressions and BVARs
Message-ID: <4100604F.1040107@lse.ac.uk>

I have not been able to find any programs for running vector 
autoregressions with R. I am interested in running Bayesian VARs and 
also running VARs that run all combinations of variables in the vector. 
Is anyone currently developing this?

-Nirav Mehta



From spencer.graves at pdf.com  Fri Jul 23 03:48:44 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 22 Jul 2004 18:48:44 -0700
Subject: [R] vetor autoregressions and BVARs
In-Reply-To: <4100604F.1040107@lse.ac.uk>
References: <4100604F.1040107@lse.ac.uk>
Message-ID: <41006E7C.2090109@pdf.com>

      A search -> "R site search" from www.r-project.org for "vector 
autoregression" produced documentation of an "mAr" package for vector 
autoregression.  Beyond this, a search for "kalman filter time series" 
produced 29 hits, most of which looked to me to be potentially 
relevant.  Have you looked at these? 

      Hope this helps.  spencer graves
p.s. PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

Nirav Mehta wrote:

> I have not been able to find any programs for running vector 
> autoregressions with R. I am interested in running Bayesian VARs and 
> also running VARs that run all combinations of variables in the 
> vector. Is anyone currently developing this?
>
> -Nirav Mehta
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Fri Jul 23 03:51:14 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 22 Jul 2004 18:51:14 -0700
Subject: [R] dumpClass, hasSlot in R?
In-Reply-To: <loom.20040722T042332-408@post.gmane.org>
References: <40FE792C.60103@pdf.com>	<f8e6ff05040721135354c5d394@mail.gmail.com>	<1090444057.30855.37.camel@localhost.localdomain>
	<loom.20040722T042332-408@post.gmane.org>
Message-ID: <41006F12.9060007@pdf.com>

      Thanks to Hadley Wickham, Mar Schwartz, and Gabor Grothendieck.  
I'm skimming all 5 documents cited, and I will study them more later.  
Thanks again. 

      Best Wishes,
      Spencer Graves

Gabor Grothendieck wrote:

>Marc Schwartz <MSchwartz <at> MedAnalytics.com> writes:
>
>: 
>: On Wed, 2004-07-21 at 15:53, hadley wickham wrote:
>: > There are a few notes about difference between the R implementation
>: > and the book at http://developer.r-project.org/methodsPackage.html
>: > 
>: > I found the hardest thing to get to grips in R was method calling -
>: > using multiple dispatch (totally different to what I'm used to from
>: > Java, Python etc.).  I found this tutorial
>: > (http://www.gwydiondylan.org/gdref/tutorial.html, the sections on
>: > generic functions and multiple-dispatch) very useful.  However, it is
>: > for another programming language, and although the method and class
>: > creation process feels very similar to R, the syntax is quite
>: > different.  There is definitely scope for a similarly structured
>: > introduction to S4 classes in R.
>: > 
>: > Hadley
>: 
>: I have not done any S4 coding yet, but two references that may be of
>: interest are:
>: 
>: "Converting Packages to S4" 
>: by Doug Bates
>: R News Vol 3, No. 1, June 2003
>: http://cran.r-project.org/doc/Rnews/Rnews_2003-1.pdf
>: 
>: and 
>: 
>: "S4 Classes and Methods"
>: by Fritz Leisch
>: useR! 2004 Keynote Lecture
>: Slides available at: 
>: http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Leisch.pdf
>: 
>: HTH,
>: 
>: Marc Schwartz
>
>Also:
>
>S4 Classes in 15 pages, more or less
>http://www.bioconductor.org/develPage/guidelines/programming/S4Objects.pdf
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From spencer.graves at pdf.com  Fri Jul 23 04:55:09 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 22 Jul 2004 19:55:09 -0700
Subject: [R] Modeling Dependent Bernoulli Trials? 
Message-ID: <41007E0D.1090602@pdf.com>

      Is there any software to estimate dependence between Bernoulli 
trials? 

      I have N observations on k-vectors of 0s and 1s, and I need to 
model the dependence.  Consider the simple case with k = 2.  There are 4 
possible outcomes:  (0, 0), (0, 1), (1, 0), and (1, 1).  I assume 0 = 
"failure" and 1 = "success".  I assume further that there are 3 
independent failure mechanisms, one that makes the first outcome 0 with 
probability (1-q1), another that makes the second outcome 0 with 
probability (1-q2), and a third that make them both 0 with probability 
(1-q12).  I compute the probabilities of these 4 outcomes as follows: 

      P00 = Pr(0, 0) = q1*q2*q12 = probability of no failures. 

      P01 = Pr(0, 1) = q1*(1-q2)*q12 = probability of a failure from the 
second mechanism and none from the other 2. 

      P10 = Pr(1, 0) = (1-q1)*q2*q12 = probability of a failure from the 
first mechanism and none from the other 2. 

      P11 = Pr(1, 1) = 1-Pr(0,0)-Pr(0,1)-Pr(1,0). 

      With this setup, I can write a likelihood function, parameterize 
it appropriately, and estimate what I need.  However, I wonder if 
something already exists. 

      Best Wishes,
      Spencer Graves



From Nigel.Brown at qml.com.au  Fri Jul 23 05:52:28 2004
From: Nigel.Brown at qml.com.au (Nigel.Brown@qml.com.au)
Date: Fri, 23 Jul 2004 13:52:28 +1000
Subject: [R] RE:Can R work on very large of data?
Message-ID: <F23B3BCF090CCA43A05E70C7B771E5C802EBC684@qmlmail.qml.com.au>

Hello,
I guess it depends on what you call large and what you want to do and the
memory.
I've used R on 25,000 cases of 50 variables (mostly factor levels) for
exploratory
frequencies and plotting and found it fast (On a T23 IBM Thinkpad 512MB 1GHz
proc).

Regards
Nigel



From Achim.Zeileis at wu-wien.ac.at  Fri Jul 23 10:54:28 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 23 Jul 2004 10:54:28 +0200
Subject: [R] vetor autoregressions and BVARs
In-Reply-To: <41006E7C.2090109@pdf.com>
References: <4100604F.1040107@lse.ac.uk>
	<41006E7C.2090109@pdf.com>
Message-ID: <20040723105428.77211277.Achim.Zeileis@wu-wien.ac.at>

On Thu, 22 Jul 2004 18:48:44 -0700 Spencer Graves wrote:

>       A search -> "R site search" from www.r-project.org for "vector 
> autoregression" produced documentation of an "mAr" package for vector 
> autoregression.  Beyond this, a search for "kalman filter time series"
> produced 29 hits, most of which looked to me to be potentially 
> relevant.  Have you looked at these? 

In addition, simple VAR models can also be fitted by ar(), e.g. by OLS.
hth,
Z
 
>       Hope this helps.  spencer graves
> p.s. PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> Nirav Mehta wrote:
> 
> > I have not been able to find any programs for running vector 
> > autoregressions with R. I am interested in running Bayesian VARs and
> > also running VARs that run all combinations of variables in the 
> > vector. Is anyone currently developing this?
> >
> > -Nirav Mehta
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From Pierre.Olivier.Mazagol at univ-st-etienne.fr  Fri Jul 23 11:49:59 2004
From: Pierre.Olivier.Mazagol at univ-st-etienne.fr (Pierre.Olivier.Mazagol)
Date: Fri, 23 Jul 2004 11:49:59 +0200
Subject: [R] discriminant analysis
Message-ID: <4100DF47.90306@univ-st-etienne.fr>

Hello.
I have a data base with 50 qualitative variables and a lot of 
individuals. I try to estimate the links between one of these variables 
(landcover) and the 49 others (geomorphology, hydrography...). I want to 
use a "discriminant analysis on qualitative variables" (as DISQUAL in 
SPAD) or a " log-linear model ". Which R-Package(s) or other methods can 
you advise me.

Thank you for you help.

POMazagol
Centre de Recherches sur l'ENvironnement et l'AM??nagement
UMR 5600 Cnrs "Ville-Environnement-Soci??t??"
6 Rue Basse des Rives 
42023 - Saint Etienne cedex 02
Tel : +33(0)4 77 42 19 23
Fax : +33(0)4 77 42 19 24
http://www.univ-st-etienne.fr/crenam/vielabo/chercheur/mazagol/

Bonjour.
Je dispose d'une base de donn??es paysag??re constitu??e exclusivement 50 
variables qualitatives nominales et d'un grand nombre d'individus. Je 
cherche ?? estimer les liens existant entre une de ces variables 
(occupation du sol) et les 50 autres (variables g??omorphologiques, 
hydrographiques...). J'ai enviseag?? d'utiliser une "analyse 
discriminante sur variables qualitatives" (??quivalent ?? DISQUAL dans 
SPAD) ou alors un "mod??le log-lin??aire". Je souhaiterais connaitre quels 
packages R vous paraissent les plus judicieux pour mener ?? bien ces 
m??thodes. A moins que vous ne me conseilliez une autre m??thode.

Merci d'avance.

POMazagol



From ripley at stats.ox.ac.uk  Fri Jul 23 12:01:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jul 2004 11:01:57 +0100 (BST)
Subject: [R] discriminant analysis
In-Reply-To: <4100DF47.90306@univ-st-etienne.fr>
Message-ID: <Pine.LNX.4.44.0407231057001.24792-100000@gannet.stats>

I don't think this is `discriminant analysis' as used in English (the 
French translation has a wider meaning).  I suggest you start with 
multinom (in package nnet, part of the standard R distribution) which does 
fit a log-linear model, and rpart (in package rpart) as a classification 
tree is often useful to select variables in this sort of problem (and with 
49 explanatory variables you are presumably hoping that only a few are 
needed).

On Fri, 23 Jul 2004, Pierre.Olivier.Mazagol wrote:

> Hello.
> I have a data base with 50 qualitative variables and a lot of 
> individuals. I try to estimate the links between one of these variables 
> (landcover) and the 49 others (geomorphology, hydrography...). I want to 
> use a "discriminant analysis on qualitative variables" (as DISQUAL in 
> SPAD) or a " log-linear model ". Which R-Package(s) or other methods can 
> you advise me.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gavin.simpson at ucl.ac.uk  Fri Jul 23 12:07:48 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 23 Jul 2004 11:07:48 +0100
Subject: [R] biplot & identify
In-Reply-To: <200407222117300607.11E582B0@mail.math.fu-berlin.de>
References: <200407222117300607.11E582B0@mail.math.fu-berlin.de>
Message-ID: <4100E374.4030409@ucl.ac.uk>

Wolski wrote:
> Hi!
> 
> Is there a way to get biplot and identify to work togheter.
> 
> Having the output of prcomp I would like to draw a biplot that. 
> Instead of plotting the sample (row-names) names plots some "pch"
> symbols. (thats easy with xlabs)
> 
> But now I would like to add using identify the names to only some of
> the points. I have noticed that both biplot.prcomp and biplot.default
> does a lot of scaling.
> 
> So has anyone a function like identify.prcomp please?
> 
> 
> Is it possible?

Yes, take a look at Jari Oksanen's vegan package
http://cc.oulu.fi/~jarioksa/softhelp/vegan.html and on CRAN.

The ordiplot function can be used to plot ordination diagrams including
those from prcomp. There is an identify method for ordiplot that allows
you to label points - you need to store the ordiplot object before using
identify, e.g.:

exmp.pc <- prcomp(some.data)
exmp.ord <- ordiplot(exmp.pc)
identify(exemp.ord, what = "sites")

see ?ordiplot and the example which includes the use of identify.

> Sincerely Eryk

HTH

Gav

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From Anna.H.Persson at astrazeneca.com  Fri Jul 23 12:36:45 2004
From: Anna.H.Persson at astrazeneca.com (Anna.H.Persson@astrazeneca.com)
Date: Fri, 23 Jul 2004 12:36:45 +0200
Subject: [R] confidence intervals for linear combinations when using lme
Message-ID: <C85BC4FA93D21A439AF62D3284BFFFA9B4D792@sesodmsxa01.rd.astrazeneca.net>

Hi 

I really hope someone can help me.

I have just started to work with S-plus, and have not yet understood how it
really works. I am now trying to fit a mixed effects model with lme. My goal
is to compare four different groups, at several different time points, and I
therefore would like to create confidence intervals for linear combinations
of my estimated parameters (as I usually do with "contrast" or "estimate" or
"lsmeans" in SAS). I have now found out that the vcov-function in the
lme4-package could be of great help for me, but I do not know if I can use
lme4 when working with S-PLUS 6.1, or is it only for R. 

When I write 
>library(MASS)
I find lme3, where there is a vcov-function, but if I understand it
correctly it works with lm and not with lme...

If I can use lme4 with s-plus 6.1, what shall I do in order to install it on
my computer?

I am grateful for all help I can get?

best regards
Anna Persson



From deepayan at stat.wisc.edu  Fri Jul 23 13:58:31 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 23 Jul 2004 06:58:31 -0500
Subject: [R] confidence intervals for linear combinations when using lme
In-Reply-To: <C85BC4FA93D21A439AF62D3284BFFFA9B4D792@sesodmsxa01.rd.astrazeneca.net>
References: <C85BC4FA93D21A439AF62D3284BFFFA9B4D792@sesodmsxa01.rd.astrazeneca.net>
Message-ID: <200407230658.31542.deepayan@stat.wisc.edu>

On Friday 23 July 2004 05:36, Anna.H.Persson at astrazeneca.com wrote:
> Hi
>
> I really hope someone can help me.
>
> I have just started to work with S-plus, and have not yet understood
> how it really works. I am now trying to fit a mixed effects model
> with lme. My goal is to compare four different groups, at several
> different time points, and I therefore would like to create
> confidence intervals for linear combinations of my estimated
> parameters (as I usually do with "contrast" or "estimate" or
> "lsmeans" in SAS). I have now found out that the vcov-function in the
> lme4-package could be of great help for me, but I do not know if I
> can use lme4 when working with S-PLUS 6.1, or is it only for R.

As far as I know, there are no plans (by the developers) to port lme4 to 
work with S-PLUS.

Deepayan



From bates at stat.wisc.edu  Fri Jul 23 14:05:02 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 23 Jul 2004 07:05:02 -0500
Subject: [R] confidence intervals for linear combinations when using lme
In-Reply-To: <C85BC4FA93D21A439AF62D3284BFFFA9B4D792@sesodmsxa01.rd.astrazeneca.net>
References: <C85BC4FA93D21A439AF62D3284BFFFA9B4D792@sesodmsxa01.rd.astrazeneca.net>
Message-ID: <4100FEEE.6070202@stat.wisc.edu>

Anna.H.Persson at astrazeneca.com wrote:

> I have just started to work with S-plus, and have not yet understood how it
> really works. I am now trying to fit a mixed effects model with lme. My goal
> is to compare four different groups, at several different time points, and I
> therefore would like to create confidence intervals for linear combinations
> of my estimated parameters (as I usually do with "contrast" or "estimate" or
> "lsmeans" in SAS). I have now found out that the vcov-function in the
> lme4-package could be of great help for me, but I do not know if I can use
> lme4 when working with S-PLUS 6.1, or is it only for R. 

The lme4 package is only available for R at this time.



From cristian at biometria.univr.it  Fri Jul 23 14:06:16 2004
From: cristian at biometria.univr.it (Cristian Pattaro)
Date: Fri, 23 Jul 2004 14:06:16 +0200
Subject: [R] Reading ASCII files 
Message-ID: <4100FF38.9090805@biometria.univr.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040723/b37a6ad4/attachment.pl

From ripley at stats.ox.ac.uk  Fri Jul 23 14:29:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jul 2004 13:29:13 +0100 (BST)
Subject: [R] Reading ASCII files 
In-Reply-To: <4100FF38.9090805@biometria.univr.it>
Message-ID: <Pine.LNX.4.44.0407231326260.24915-100000@gannet.stats>

On Fri, 23 Jul 2004, Cristian Pattaro wrote:

> Dear all,
> I need to read an ASCII file with diffent length lines.
> 
> This is what is contained in the file gene.txt:
> 1st line  ID description snp_id genotype
> 2nd line 10003 Low rs152240 
> 3rd line 10003 Moderate rs189011 TC
> 4th line 10004 Conservative rs152240 GC
> 5th line 10004 Bad rs154354
> 6th line 10013 Bad rs152240
> 7th line 10019 Conservative rs152240 AC
> etc...
> 
> This is what I would like to obtain in R:
> ID        description         snp_id          genotype
> 10003    Low                 rs152240     NA
> 10003    Moderate         rs189011     TC
> 10004    Conservative    rs152240     GC
> 10004    Bad                  rs154354     NA
> 10013    Bad                  rs152240     NA
> 10019    Conservative    rs152240     AC
> 
> Read.table() doesn't work in these situations because of the irregular 
> pattern of data. Have you got any suggestion?

Read the manual, for it does!  In particular, look at the argument

    fill: logical. If 'TRUE' then in case the rows have unequal length,
          blank fields are implicitly added.  See Details.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Fri Jul 23 14:28:56 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 23 Jul 2004 08:28:56 -0400
Subject: [R] Reading ASCII files
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80E5@usrymx25.merck.com>

You can use fill=TRUE and na.string="" in read.table().  E.g.,

> try.dat <- read.table("clipboard", colClasses=rep("character", 6), 
+                       header=TRUE, fill=TRUE, na.string="")
> try.dat
  X1st line    ID  description   snp_id genotype
1  2nd line 10003          Low rs152240     <NA>
2  3rd line 10003     Moderate rs189011       TC
3  4th line 10004 Conservative rs152240       GC
4  5th line 10004          Bad rs154354     <NA>
5  6th line 10013          Bad rs152240     <NA>
6  7th line 10019 Conservative rs152240       AC

HTH,
Andy

> From: Cristian Pattaro
> 
> Dear all,
> I need to read an ASCII file with diffent length lines.
> 
> This is what is contained in the file gene.txt:
> 1st line  ID description snp_id genotype
> 2nd line 10003 Low rs152240 
> 3rd line 10003 Moderate rs189011 TC
> 4th line 10004 Conservative rs152240 GC
> 5th line 10004 Bad rs154354
> 6th line 10013 Bad rs152240
> 7th line 10019 Conservative rs152240 AC
> etc...
> 
> This is what I would like to obtain in R:
> ID        description         snp_id          genotype
> 10003    Low                 rs152240     NA
> 10003    Moderate         rs189011     TC
> 10004    Conservative    rs152240     GC
> 10004    Bad                  rs154354     NA
> 10013    Bad                  rs152240     NA
> 10019    Conservative    rs152240     AC
> 
> Read.table() doesn't work in these situations because of the 
> irregular 
> pattern of data. Have you got any suggestion?
> Thanks a lot!
> Cristian
> 
> ===========================================
> Cristian Pattaro
> ===========================================
> 
> Unit of Epidemiology & Medical Statistics
> Department of Medicine and Public Health
> University of Verona
> cristian at biometria.univr.it
> http://biometria.univr.it
> ===========================================
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From stephan.moratti at uni-konstanz.de  Fri Jul 23 14:33:13 2004
From: stephan.moratti at uni-konstanz.de (Stephan Moratti)
Date: Fri, 23 Jul 2004 14:33:13 +0200
Subject: [R] problem lme using corSymm()
Message-ID: <3.0.5.32.20040723143313.00acf960@popserver.uni-konstanz.de>

Hi,

I got a computational problem with lme (nlme library R 1.9.1) using
corSymm(). Here is the data:

            [,1]       [,2]       [,3]       [,4]       [,5]       [,6]
 [1,] 0.19639793 0.09127954 0.11733288 0.07598273 0.06545106 0.06211532
 [2,] 0.22773467 0.10981912 0.16052847 0.38101187 0.18353474 0.24072918
 [3,] 0.46743388 0.45733836 0.32191178 0.43356107 0.39159746 0.53984221
 [4,] 0.29051642 0.32184177 0.24935224 0.31634000 0.16355260 0.12430647
 [5,] 0.07353932 0.10695346 0.12149297 0.12052110 0.08682816 0.10002020
 [6,] 0.18672701 0.09027081 0.07597009 0.23282325 0.14697649 0.12762290
 [7,] 0.26289407 0.27713945 0.13372536 0.36492799 0.25986507 0.22709220
 [8,] 0.10527164 0.04871462 0.06152876 0.14244950 0.08310103 0.08212435
 [9,] 0.06620246 0.07877543 0.05525695 0.11684909 0.06401386 0.06903739
[10,] 0.12867578 0.07969712 0.09466616 0.12565510 0.10685046 0.11924971
[11,] 0.12426949 0.09819454 0.12543859 0.12321680 0.09282128 0.11261496
[12,] 0.14227878 0.07937399 0.08314904 0.12904447 0.08569169 0.08205721
[13,] 0.13509013 0.09850748 0.09838632 0.16405161 0.09319339 0.10619560
[14,] 0.44856255 0.25898742 0.15940404 0.56595476 0.30830903 0.40427274
[15,] 0.12786080 0.13699933 0.15702839 0.15100094 0.15037274 0.11427119
[16,] 0.15294429 0.12695011 0.11030015 0.13769743 0.09924456 0.08767253
[17,] 0.20091098 0.09847140 0.14685682 0.16175769 0.18205527 0.13926859
[18,] 0.11707101 0.13492758 0.07762873 0.13414458 0.11760926 0.13963532

As you can see, values in row [15,] and columns [,3] to [,5] are very
similar. To produce a vertical design matrix use:

 datamat<-as.data.frame(test)
 datamat<-stack(datamat)
 datamat$subject<-as.factor(rep(c(1:18),times=6))
 datamat$A<-as.factor(rep(c(1:3),each=18,times=2)) 
 datamat$B<-as.factor(rep(c("one","two"),each=54))

Then fitting the model:

fm.datamat<-lme(values~A*B,data=datamat,random=~1|subject,correlation=corSym
m())

produced this error:

"Error in "coef<-.corNatural"(`*tmp*`, value = log((cStNatPar + 1)/(1 -  : 
        NA/NaN/Inf in foreign function call (arg 1)"

If I skip observation subject 15 (row 15 above) the computation is
successfull. Is it because of the similar values ? Does it fail to estimate
a general variance structure ? Is there a better way than skipping row 15 ?

Thanks for some suggestions,

Stephan Moratti



-----------------------------
Dipl. Psych. Stephan Moratti
Dept. of Psychology
University of Konstanz
P.O Box D25
Phone: +40 (0)7531 882385
Fax: +49 (0)7531 884601
D-78457 Konstanz, Germany

e-mail: Stephan.Moratti at uni-konstanz.de
http://www.clinical-psychology.uni-konstanz.de/



From hb at maths.lth.se  Fri Jul 23 14:35:45 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 23 Jul 2004 14:35:45 +0200
Subject: [R] Reading ASCII files 
In-Reply-To: <4100FF38.9090805@biometria.univr.it>
Message-ID: <000501c470b1$96c9daf0$e502eb82@hblaptop>

Have considered using fill=TRUE in read.table()? See ?read.table

If that does not work, there is always scan(). I worst case you can also use
readChar() or readLines()/strsplit(), but that should not be necessary.

Cheers

Henrik Bengtsson
Lund University



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Cristian Pattaro
> Sent: Friday, July 23, 2004 2:06 PM
> To: R Help
> Subject: [R] Reading ASCII files 
> 
> 
> Dear all,
> I need to read an ASCII file with diffent length lines.
> 
> This is what is contained in the file gene.txt:
> 1st line  ID description snp_id genotype
> 2nd line 10003 Low rs152240 
> 3rd line 10003 Moderate rs189011 TC
> 4th line 10004 Conservative rs152240 GC
> 5th line 10004 Bad rs154354
> 6th line 10013 Bad rs152240
> 7th line 10019 Conservative rs152240 AC
> etc...
> 
> This is what I would like to obtain in R:
> ID        description         snp_id          genotype
> 10003    Low                 rs152240     NA
> 10003    Moderate         rs189011     TC
> 10004    Conservative    rs152240     GC
> 10004    Bad                  rs154354     NA
> 10013    Bad                  rs152240     NA
> 10019    Conservative    rs152240     AC
> 
> Read.table() doesn't work in these situations because of the 
> irregular 
> pattern of data. Have you got any suggestion?
> Thanks a lot!
> Cristian
> 
> ===========================================
> Cristian Pattaro
> ===========================================
> 
> Unit of Epidemiology & Medical Statistics
> Department of Medicine and Public Health
> University of Verona
> cristian at biometria.univr.it
> http://biometria.univr.it ===========================================
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ramasamy at cancer.org.uk  Fri Jul 23 14:46:14 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 23 Jul 2004 13:46:14 +0100
Subject: [R] Reading ASCII files
In-Reply-To: <4100FF38.9090805@biometria.univr.it>
References: <4100FF38.9090805@biometria.univr.it>
Message-ID: <1090586735.3101.26.camel@vpn202001.lif.icnet.uk>

Did you read the R data import/export manual or check the mail archives?

You could try to save the input file as comma or pipe separated.
Alternatively you can try this hack if all records are separated by a single space.

> a <- read.delim(file="tmp.txt", sep=" ", na.string="")
> a
     ID  description   snp_id genotype
1 10003          Low rs152240     <NA>
2 10003     Moderate rs189011       TC
3 10004 Conservative rs152240       GC
4 10004          Bad rs154354     <NA>
5 10013          Bad rs152240     <NA>
6 10019 Conservative rs152240       AC



On Fri, 2004-07-23 at 13:06, Cristian Pattaro wrote:
> Dear all,
> I need to read an ASCII file with diffent length lines.
> 
> This is what is contained in the file gene.txt:
> 1st line  ID description snp_id genotype
> 2nd line 10003 Low rs152240 
> 3rd line 10003 Moderate rs189011 TC
> 4th line 10004 Conservative rs152240 GC
> 5th line 10004 Bad rs154354
> 6th line 10013 Bad rs152240
> 7th line 10019 Conservative rs152240 AC
> etc...
> 
> This is what I would like to obtain in R:
> ID        description         snp_id          genotype
> 10003    Low                 rs152240     NA
> 10003    Moderate         rs189011     TC
> 10004    Conservative    rs152240     GC
> 10004    Bad                  rs154354     NA
> 10013    Bad                  rs152240     NA
> 10019    Conservative    rs152240     AC
> 
> Read.table() doesn't work in these situations because of the irregular 
> pattern of data. Have you got any suggestion?
> Thanks a lot!
> Cristian
> 
> ===========================================
> Cristian Pattaro
> ===========================================
> 
> Unit of Epidemiology & Medical Statistics
> Department of Medicine and Public Health
> University of Verona
> cristian at biometria.univr.it
> http://biometria.univr.it
> ===========================================
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From stefano at dsa.unipr.it  Fri Jul 23 15:06:12 2004
From: stefano at dsa.unipr.it (Stefano Leonardi)
Date: Fri, 23 Jul 2004 15:06:12 +0200
Subject: [R] difference between nls and nlme approaches
Message-ID: <1090587972.12589.93.camel@robin>

Hallo,
I have a question that is more  statistic related than
about nlme and R functioning.

I want to fit a complicated nonlinear model with nlme with several
different measures of transpiration taken on each of the 220 trees
grouped in 8 families.  The unknown parameters of the model are three +
their variances (and covariances).  I want to estimate the variances
among families of the parameters.  This would give an idea of the
genetic control of the biological processes modeled.

The question than is:
what would be the conceptual differences between
1) fitting the model with nls on each tree separately and than look at
the variance among families of the parameters with lme
and
2) carry out one single fitting with nlme using Family/Tree
hierarchical grouping (Tree and Families are considered random factors)
and estimate the within and among families variance of the parameters.

I understand from the Pinheiro and Bates book that there is a  degree of
freedom issue, but what are the real advantages and disadvantages of the
two approaches?

This issues is prompted by the fact that it is easy for me to
have results using the first approach but there is no way that
the second approach reaches some kind of convergence: it takes hours and
the it stops without reaching satisfactory results. I have tried several
simplifications of the model with no particular success.

Right now I am using the first approach weighting the parameter with the
inverse of their error estimated with nls. I am using
the weights option with lme using something like:
weight=varFixed(~ 1/vector_of_errors_of_parameter) approach.
Am I out of my mind completely? or am I on a more or less right
direction?

Thank you very much to whoever tries to answer this question.

Stefano
-- 
======================================================================
 Stefano Leonardi
 Dipartimento di Scienze Ambientali
 Universita` di Parma             E-mail: stefano.leonardi _at_ unipr.it
 Parco Area delle Scienze 11a                  Phone : +39-0521-905659
 43100 PARMA  (Italy)                          Fax   : +39-0521-905402



From ggrothendieck at myway.com  Fri Jul 23 15:02:06 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 23 Jul 2004 13:02:06 +0000 (UTC)
Subject: [R] Reading ASCII files
References: <3A822319EB35174CA3714066D590DCD504AF80E5@usrymx25.merck.com>
Message-ID: <loom.20040723T145454-54@post.gmane.org>


Or assuming that you want snp_id to be character and other columns
to have their default class (i.e. ID is numeric, description is factor
and genotype is factor) and also assuming that 1st line, etc. is not 
actually part of the file:

read.table(myfilename, as.is = "snp_id", header = TRUE, fill = TRUE, 
   na.string = "")


Liaw, Andy <andy_liaw <at> merck.com> writes:

: 
: You can use fill=TRUE and na.string="" in read.table().  E.g.,
: 
: > try.dat <- read.table("clipboard", colClasses=rep("character", 6), 
: +                       header=TRUE, fill=TRUE, na.string="")
: > try.dat
:   X1st line    ID  description   snp_id genotype
: 1  2nd line 10003          Low rs152240     <NA>
: 2  3rd line 10003     Moderate rs189011       TC
: 3  4th line 10004 Conservative rs152240       GC
: 4  5th line 10004          Bad rs154354     <NA>
: 5  6th line 10013          Bad rs152240     <NA>
: 6  7th line 10019 Conservative rs152240       AC
: 
: HTH,
: Andy
: 
: > From: Cristian Pattaro
: > 
: > Dear all,
: > I need to read an ASCII file with diffent length lines.
: > 
: > This is what is contained in the file gene.txt:
: > 1st line  ID description snp_id genotype
: > 2nd line 10003 Low rs152240 
: > 3rd line 10003 Moderate rs189011 TC
: > 4th line 10004 Conservative rs152240 GC
: > 5th line 10004 Bad rs154354
: > 6th line 10013 Bad rs152240
: > 7th line 10019 Conservative rs152240 AC
: > etc...
: > 
: > This is what I would like to obtain in R:
: > ID        description         snp_id          genotype
: > 10003    Low                 rs152240     NA
: > 10003    Moderate         rs189011     TC
: > 10004    Conservative    rs152240     GC
: > 10004    Bad                  rs154354     NA
: > 10013    Bad                  rs152240     NA
: > 10019    Conservative    rs152240     AC
: > 
: > Read.table() doesn't work in these situations because of the 
: > irregular 
: > pattern of data. Have you got any suggestion?
: > Thanks a lot!
: > Cristian
: > 
: > ===========================================
: > Cristian Pattaro
: > ===========================================
: > 
: > Unit of Epidemiology & Medical Statistics
: > Department of Medicine and Public Health
: > University of Verona
: > cristian <at> biometria.univr.it
: > http://biometria.univr.it
: > ===========================================
: > 
: > 
: > 	[[alternative HTML version deleted]]
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: > 
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From Jan.Verbesselt at agr.kuleuven.ac.be  Fri Jul 23 15:28:11 2004
From: Jan.Verbesselt at agr.kuleuven.ac.be (Jan Verbesselt)
Date: Fri, 23 Jul 2004 15:28:11 +0200
Subject: [R] ts to irts
Message-ID: <009d01c470b8$e6a67ae0$1145210a@agr.ad10.intern.kuleuven.ac.be>

Hi R-list,

I'm working with irregular time series (time series of climate data,
daily data 365/6 days a year) and would like to create regular time
series from them ( irts 
	e.g. Rain            <-
irts(as.POSIXct(Climate[,1]),Climate[,5]) 
		to ts
    e.g. test <- ts(x, start=c(1997,1), frequency=365) )

such that I can find where the gaps (lacking temperature data, ...) are
and try out methods to fill the gaps.

The main objective is to detect gaps, how long they are and fill them if
possible with average, median values.

All ideas & methods are welcome!

Regards,
Jan

_______________________________________________________________________
Jan Verbesselt 
Research Associate 
Lab of Geomatics and Forest Engineering K.U. Leuven
Vital Decosterstraat 102. B-3000 Leuven Belgium 
Tel:+32-16-329750   Fax: +32-16-329760
http://gloveg.kuleuven.ac.be/



From ripley at stats.ox.ac.uk  Fri Jul 23 15:33:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jul 2004 14:33:37 +0100 (BST)
Subject: [R] difference between nls and nlme approaches
In-Reply-To: <1090587972.12589.93.camel@robin>
Message-ID: <Pine.LNX.4.44.0407231420190.24974-100000@gannet.stats>

Your first approach is quite common, and used to be very common.  The 
difficulty can be to get the individual nls fits to fit, and the advantage 
of the combined fitting is that `borrowing strength' happens.

I don't understand at present why you want to weight the results.  You say 
you are interested in the family-level variance -- given there are around 
30 trees per family you can (and I would) just treat the summary 
statistics of the fit for each tree as the data and apply a one-level 
nested analysis of variance.  How accurately a parameter is determined for 
a single tree seems not to be relevant to the question you are asking.

On Fri, 23 Jul 2004, Stefano Leonardi wrote:

> Hallo,
> I have a question that is more  statistic related than
> about nlme and R functioning.
> 
> I want to fit a complicated nonlinear model with nlme with several
> different measures of transpiration taken on each of the 220 trees
> grouped in 8 families.  The unknown parameters of the model are three +
> their variances (and covariances).  I want to estimate the variances
> among families of the parameters.  This would give an idea of the
> genetic control of the biological processes modeled.
> 
> The question than is:
> what would be the conceptual differences between
> 1) fitting the model with nls on each tree separately and than look at
> the variance among families of the parameters with lme
> and
> 2) carry out one single fitting with nlme using Family/Tree
> hierarchical grouping (Tree and Families are considered random factors)
> and estimate the within and among families variance of the parameters.

This also estimates within and between trees, though.

> I understand from the Pinheiro and Bates book that there is a  degree of
> freedom issue, but what are the real advantages and disadvantages of the
> two approaches?

The standard issues about the use of random vs fixed effects.  With as 
large groups as you have, there should not be much difference.

> This issues is prompted by the fact that it is easy for me to
> have results using the first approach but there is no way that
> the second approach reaches some kind of convergence: it takes hours and
> the it stops without reaching satisfactory results. I have tried several
> simplifications of the model with no particular success.
> 
> Right now I am using the first approach weighting the parameter with the
> inverse of their error estimated with nls. I am using
> the weights option with lme using something like:
> weight=varFixed(~ 1/vector_of_errors_of_parameter) approach.
> Am I out of my mind completely? or am I on a more or less right
> direction?
> 
> Thank you very much to whoever tries to answer this question.
> 
> Stefano
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Luisr at frs.fo  Fri Jul 23 15:36:56 2004
From: Luisr at frs.fo (Luis Rideau Cruz)
Date: Fri, 23 Jul 2004 14:36:56 +0100
Subject: [R] retrieve rows from frame assuming criterion
Message-ID: <s1012290.031@ffdata.setur.fo>

Hi all,

I have a data frame in which one column(PUNTAR) is of character type.
What I want is to retrieve is the frame but only with those rows matching elements of PUNTAR with a list characters (e.g c("IX49","IX48") )

Year    TUR  STODNR   PUNTAR
1994  9412 94020061     IX49
1994  9412 94020062     IX48
1994  9412 94020063      X32
1994  9412 94020065      X23
1994  9412 94020066      X27
1994  9412 94020067     XI19
1994  9412 94020068     XI16
1994  9412 94020069     XI14
1994  9412 94020070      XI8
1994  9412 94020071      X25
1994  9412 94020072      X18
1994  9412 94020073     II23
1994  9412 94020074    XII33
1994  9412 94020075    XII31

"my.function"("frame") should be then equal to 

Year TURNR   STODNR M_PUNTAR
1994  9412 94020061     IX49
1994  9412 94020062     IX48

Thank you in advance


Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo
Web:                www.frs.fo



From pgilbert at bank-banque-canada.ca  Fri Jul 23 15:45:24 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 23 Jul 2004 09:45:24 -0400
Subject: [R] vetor autoregressions and BVARs
In-Reply-To: <4100604F.1040107@lse.ac.uk>
References: <4100604F.1040107@lse.ac.uk>
Message-ID: <41011674.2030500@bank-banque-canada.ca>

Nirav Mehta wrote:

> I have not been able to find any programs for running vector 
> autoregressions with R. I am interested in running Bayesian VARs and 
> also running VARs that run all combinations of variables in the vector.

If you mean linear combinations of the variables, you cannot "run" these 
because there are an infinite number. However, there are several 
techniques related to PCA that find the the "best" linear combination, 
according to some criteria. Much of the early development in this area 
was done by Akaike. Some of these are implemented in the dse bundle of 
packages and there are examples in the Users' Guide. My favorite is the 
bft method (but I am biased).  Avoid the technique promoted by Aoki as 
his main theorem has an error and his approach does not work. (He 
claimed it should only fail occasionally, but it fails often in my 
experience.)

If you really mean to restrict yourself to VAR models there is a 
problem. These techniques are typically based on the state space 
representation. You can find an equivalent ARMA representation, but not 
necessarily an equivalent VAR representation. Even though you may start 
with a VAR model you can end up with no (finite) VAR representation.

As for the Bayesian part, I have not worked on that.

Paul Gilbert

> Is anyone currently developing this?
> 
> -Nirav Mehta
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From wolski at molgen.mpg.de  Fri Jul 23 15:50:37 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 23 Jul 2004 15:50:37 +0200
Subject: [R] retrieve rows from frame assuming criterion
In-Reply-To: <s1012290.031@ffdata.setur.fo>
References: <s1012290.031@ffdata.setur.fo>
Message-ID: <200407231550370170.03D85F08@mail.math.fu-berlin.de>

?subset

Eryk

*********** REPLY SEPARATOR  ***********

On 7/23/2004 at 2:36 PM Luis Rideau Cruz wrote:

>>>Hi all,
>>>
>>>I have a data frame in which one column(PUNTAR) is of character type.
>>>What I want is to retrieve is the frame but only with those rows
>>>matching elements of PUNTAR with a list characters (e.g c("IX49","IX48")
>>>)
>>>
>>>Year    TUR  STODNR   PUNTAR
>>>1994  9412 94020061     IX49
>>>1994  9412 94020062     IX48
>>>1994  9412 94020063      X32
>>>1994  9412 94020065      X23
>>>1994  9412 94020066      X27
>>>1994  9412 94020067     XI19
>>>1994  9412 94020068     XI16
>>>1994  9412 94020069     XI14
>>>1994  9412 94020070      XI8
>>>1994  9412 94020071      X25
>>>1994  9412 94020072      X18
>>>1994  9412 94020073     II23
>>>1994  9412 94020074    XII33
>>>1994  9412 94020075    XII31
>>>
>>>"my.function"("frame") should be then equal to 
>>>
>>>Year TURNR   STODNR M_PUNTAR
>>>1994  9412 94020061     IX49
>>>1994  9412 94020062     IX48
>>>
>>>Thank you in advance
>>>
>>>
>>>Luis Ridao Cruz
>>>Fiskiranns??knarstovan
>>>N??at??n 1
>>>P.O. Box 3051
>>>FR-110 T??rshavn
>>>Faroe Islands
>>>Phone:             +298 353900
>>>Phone(direct): +298 353912
>>>Mobile:             +298 580800
>>>Fax:                 +298 353901
>>>E-mail:              luisr at frs.fo
>>>Web:                www.frs.fo
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Stefano.Guazzetti at ausl.re.it  Fri Jul 23 15:55:28 2004
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Fri, 23 Jul 2004 15:55:28 +0200
Subject: R: [R] retrieve rows from frame assuming criterion
Message-ID: <F298786BF61DE64590054AF31EA1B4C8016D20A0@PEPI.ausl.org>

Assuming your data.frame is called "data"

data[data$PUNTAR==c("IX49","IX48"),]

is probably what you want

Stefano



> -----Messaggio originale-----
> Da: Luis Rideau Cruz [mailto:Luisr at frs.fo]
> Inviato: venerd?? 23 luglio 2004 15.37
> A: r-help at stat.math.ethz.ch
> Oggetto: [R] retrieve rows from frame assuming criterion
> 
> 
> Hi all,
> 
> I have a data frame in which one column(PUNTAR) is of character type.
> What I want is to retrieve is the frame but only with those 
> rows matching elements of PUNTAR with a list characters (e.g 
> c("IX49","IX48") )
> 
> Year    TUR  STODNR   PUNTAR
> 1994  9412 94020061     IX49
> 1994  9412 94020062     IX48
> 1994  9412 94020063      X32
> 1994  9412 94020065      X23
> 1994  9412 94020066      X27
> 1994  9412 94020067     XI19
> 1994  9412 94020068     XI16
> 1994  9412 94020069     XI14
> 1994  9412 94020070      XI8
> 1994  9412 94020071      X25
> 1994  9412 94020072      X18
> 1994  9412 94020073     II23
> 1994  9412 94020074    XII33
> 1994  9412 94020075    XII31
> 
> "my.function"("frame") should be then equal to 
> 
> Year TURNR   STODNR M_PUNTAR
> 1994  9412 94020061     IX49
> 1994  9412 94020062     IX48
> 
> Thank you in advance
> 
> 
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From MSchwartz at MedAnalytics.com  Fri Jul 23 15:58:45 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 23 Jul 2004 08:58:45 -0500
Subject: [R] retrieve rows from frame assuming criterion
In-Reply-To: <s1012290.031@ffdata.setur.fo>
References: <s1012290.031@ffdata.setur.fo>
Message-ID: <1090591124.5194.11.camel@localhost.localdomain>

On Fri, 2004-07-23 at 08:36, Luis Rideau Cruz wrote:
> Hi all,
> 
> I have a data frame in which one column(PUNTAR) is of character type.
> What I want is to retrieve is the frame but only with those rows
> matching elements of PUNTAR with a list characters (e.g
> c("IX49","IX48") )
> 
> Year    TUR  STODNR   PUNTAR
> 1994  9412 94020061     IX49
> 1994  9412 94020062     IX48
> 1994  9412 94020063      X32
> 1994  9412 94020065      X23
> 1994  9412 94020066      X27
> 1994  9412 94020067     XI19
> 1994  9412 94020068     XI16
> 1994  9412 94020069     XI14
> 1994  9412 94020070      XI8
> 1994  9412 94020071      X25
> 1994  9412 94020072      X18
> 1994  9412 94020073     II23
> 1994  9412 94020074    XII33
> 1994  9412 94020075    XII31
> 
> "my.function"("frame") should be then equal to 
> 
> Year TURNR   STODNR M_PUNTAR
> 1994  9412 94020061     IX49
> 1994  9412 94020062     IX48
> 
> Thank you in advance


For a simple subset like this, something like the following, presuming
that your data frame is called MyData:

 MyData[MyData$PUNTAR %in% c("IX49", "IX48"), ]
  Year  TUR   STODNR PUNTAR
1 1994 9412 94020061   IX49
2 1994 9412 94020062   IX48

This basically says to select only those rows where the value of
MyData$PUNTAR is in c("IX49", "IX48").

If you need to engage in more complex boolean comparisons for
subsetting, especially on multiple columns, then the function subset()
would be better suited.

HTH,

Marc Schwartz



From Stefano.Guazzetti at ausl.re.it  Fri Jul 23 16:03:03 2004
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Fri, 23 Jul 2004 16:03:03 +0200
Subject: R: [R] retrieve rows from frame assuming criterion [corrected]
Message-ID: <F298786BF61DE64590054AF31EA1B4C8016D20A1@PEPI.ausl.org>

sorry for my previus (WRONG)
answer, as someone already pointed out
a solution could be

subset(data, PUNTAR==c("IX49","IX48"))



> -----Messaggio originale-----
> Da: Guazzetti Stefano 
> Inviato: venerd?? 23 luglio 2004 15.55
> A: 'Luis Rideau Cruz'; r-help at stat.math.ethz.ch
> Oggetto: R: [R] retrieve rows from frame assuming criterion
> 
> 
> Assuming your data.frame is called "data"
> 
> data[data$PUNTAR==c("IX49","IX48"),]
> 
> is probably what you want
> 
> Stefano
> 
> 
> 
> > -----Messaggio originale-----
> > Da: Luis Rideau Cruz [mailto:Luisr at frs.fo]
> > Inviato: venerd?? 23 luglio 2004 15.37
> > A: r-help at stat.math.ethz.ch
> > Oggetto: [R] retrieve rows from frame assuming criterion
> > 
> > 
> > Hi all,
> > 
> > I have a data frame in which one column(PUNTAR) is of 
> character type.
> > What I want is to retrieve is the frame but only with those 
> > rows matching elements of PUNTAR with a list characters (e.g 
> > c("IX49","IX48") )
> > 
> > Year    TUR  STODNR   PUNTAR
> > 1994  9412 94020061     IX49
> > 1994  9412 94020062     IX48
> > 1994  9412 94020063      X32
> > 1994  9412 94020065      X23
> > 1994  9412 94020066      X27
> > 1994  9412 94020067     XI19
> > 1994  9412 94020068     XI16
> > 1994  9412 94020069     XI14
> > 1994  9412 94020070      XI8
> > 1994  9412 94020071      X25
> > 1994  9412 94020072      X18
> > 1994  9412 94020073     II23
> > 1994  9412 94020074    XII33
> > 1994  9412 94020075    XII31
> > 
> > "my.function"("frame") should be then equal to 
> > 
> > Year TURNR   STODNR M_PUNTAR
> > 1994  9412 94020061     IX49
> > 1994  9412 94020062     IX48
> > 
> > Thank you in advance
> > 
> > 
> > Luis Ridao Cruz
> > Fiskiranns??knarstovan
> > N??at??n 1
> > P.O. Box 3051
> > FR-110 T??rshavn
> > Faroe Islands
> > Phone:             +298 353900
> > Phone(direct): +298 353912
> > Mobile:             +298 580800
> > Fax:                 +298 353901
> > E-mail:              luisr at frs.fo
> > Web:                www.frs.fo
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Fri Jul 23 16:22:06 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 23 Jul 2004 10:22:06 -0400
Subject: [R] retrieve rows from frame assuming criterion [corrected]
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80E8@usrymx25.merck.com>

Still wrong:

> x <- data.frame(a = sample(letters[1:3], 10, replace=T), b=1:10)
> x
   a  b
1  a  1
2  a  2
3  b  3
4  b  4
5  a  5
6  a  6
7  b  7
8  b  8
9  b  9
10 c 10
> subset(x, a == c("b", "c"))
   a  b
3  b  3
7  b  7
9  b  9
10 c 10
> subset(x, a %in% c("b", "c"))
   a  b
3  b  3
4  b  4
7  b  7
8  b  8
9  b  9
10 c 10

What matters is the use of "%in%" instead of "==", not the use of subset().

Andy 

> From: Guazzetti Stefano
> 
> sorry for my previus (WRONG)
> answer, as someone already pointed out
> a solution could be
> 
> subset(data, PUNTAR==c("IX49","IX48"))
> 
> 
> 
> > -----Messaggio originale-----
> > Da: Guazzetti Stefano 
> > Inviato: venerd?? 23 luglio 2004 15.55
> > A: 'Luis Rideau Cruz'; r-help at stat.math.ethz.ch
> > Oggetto: R: [R] retrieve rows from frame assuming criterion
> > 
> > 
> > Assuming your data.frame is called "data"
> > 
> > data[data$PUNTAR==c("IX49","IX48"),]
> > 
> > is probably what you want
> > 
> > Stefano
> > 
> > 
> > 
> > > -----Messaggio originale-----
> > > Da: Luis Rideau Cruz [mailto:Luisr at frs.fo]
> > > Inviato: venerd?? 23 luglio 2004 15.37
> > > A: r-help at stat.math.ethz.ch
> > > Oggetto: [R] retrieve rows from frame assuming criterion
> > > 
> > > 
> > > Hi all,
> > > 
> > > I have a data frame in which one column(PUNTAR) is of 
> > character type.
> > > What I want is to retrieve is the frame but only with those 
> > > rows matching elements of PUNTAR with a list characters (e.g 
> > > c("IX49","IX48") )
> > > 
> > > Year    TUR  STODNR   PUNTAR
> > > 1994  9412 94020061     IX49
> > > 1994  9412 94020062     IX48
> > > 1994  9412 94020063      X32
> > > 1994  9412 94020065      X23
> > > 1994  9412 94020066      X27
> > > 1994  9412 94020067     XI19
> > > 1994  9412 94020068     XI16
> > > 1994  9412 94020069     XI14
> > > 1994  9412 94020070      XI8
> > > 1994  9412 94020071      X25
> > > 1994  9412 94020072      X18
> > > 1994  9412 94020073     II23
> > > 1994  9412 94020074    XII33
> > > 1994  9412 94020075    XII31
> > > 
> > > "my.function"("frame") should be then equal to 
> > > 
> > > Year TURNR   STODNR M_PUNTAR
> > > 1994  9412 94020061     IX49
> > > 1994  9412 94020062     IX48
> > > 
> > > Thank you in advance
> > > 
> > > 
> > > Luis Ridao Cruz
> > > Fiskiranns??knarstovan
> > > N??at??n 1
> > > P.O. Box 3051
> > > FR-110 T??rshavn
> > > Faroe Islands
> > > Phone:             +298 353900
> > > Phone(direct): +298 353912
> > > Mobile:             +298 580800
> > > Fax:                 +298 353901
> > > E-mail:              luisr at frs.fo
> > > Web:                www.frs.fo
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Fri Jul 23 16:29:39 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jul 2004 15:29:39 +0100 (BST)
Subject: R: [R] retrieve rows from frame assuming criterion [corrected]
In-Reply-To: <F298786BF61DE64590054AF31EA1B4C8016D20A1@PEPI.ausl.org>
Message-ID: <Pine.LNX.4.44.0407231524360.1134-100000@gannet.stats>

On Fri, 23 Jul 2004, Guazzetti Stefano wrote:

> sorry for my previus (WRONG)
> answer, as someone already pointed out
> a solution could be
> 
> subset(data, PUNTAR==c("IX49","IX48"))

That's still wrong.  You want PUNTAR %in% c("IX49","IX48").  Using ==
recycles entries, so it tests the first element against "IX49", the second
against "IX48", the third against "IX49" ....

> > -----Messaggio originale-----
> > Da: Guazzetti Stefano 
> > Inviato: venerd?? 23 luglio 2004 15.55
> > A: 'Luis Rideau Cruz'; r-help at stat.math.ethz.ch
> > Oggetto: R: [R] retrieve rows from frame assuming criterion
> > 
> > 
> > Assuming your data.frame is called "data"
> > 
> > data[data$PUNTAR==c("IX49","IX48"),]
> > 
> > is probably what you want
> > 
> > Stefano

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Fri Jul 23 16:57:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 23 Jul 2004 14:57:10 +0000 (UTC)
Subject: [R] ts to irts
References: <009d01c470b8$e6a67ae0$1145210a@agr.ad10.intern.kuleuven.ac.be>
Message-ID: <loom.20040723T165318-55@post.gmane.org>

Jan Verbesselt <Jan.Verbesselt <at> agr.kuleuven.ac.be> writes:

: I'm working with irregular time series (time series of climate data,
: daily data 365/6 days a year) and would like to create regular time
: series from them ( irts 
: 	e.g. Rain            <-
: irts(as.POSIXct(Climate[,1]),Climate[,5]) 
: 		to ts
:     e.g. test <- ts(x, start=c(1997,1), frequency=365) )
: 
: such that I can find where the gaps (lacking temperature data, ...) are
: and try out methods to fill the gaps.
: 
: The main objective is to detect gaps, how long they are and fill them if
: possible with average, median values.

First we create vectors of dates and values, d and val,
to use as test data.

Then we create, dd, a regular time vector of dates using 
class Date and a corresponding logical vector not.na 
indicating which dates in dd correspond to observations.

Finally, we average the previous non-missing and next
non-missing observation for each data point and convert the
result to class ts.  The last line sets the time coordinates
to the numeric representation of the Date class of the
corresponding dates.  (If you leave it out the times will be
1,2,3,...)


d <- structure(c(11,14,20,22), class = "Date")
val <- c(10,20,30,40)

dd <- seq(min(d), max(d), by = "day")
not.na <- dd %in% d

my.ts <- ts(val[cumsum(not.na)] + val[cumsum(not.na)+!not.na]/2)
my.ts <- ts(my.ts, start = as.numeric(min(d)), end = as.numeric(max(d)))



From bcutayar at lfdj.com  Fri Jul 23 17:07:16 2004
From: bcutayar at lfdj.com (Bruno Cutayar)
Date: Fri, 23 Jul 2004 17:07:16 +0200
Subject: [R] merge, cbind, or....?
Message-ID: <200407231507.RAA11088@bombardier2.lfdj.com>



Hi,
i have two data.frame x and y like :
 > x <- data.frame( num = c(1:10), value = runif(10) )
 > y <- data.frame( num = c(6:10), value = runif(5) )
and i want to obtain something like :

 num.x    value.x     num.y   value.y
      1 0.38423828    NA 0.2911089
      2 0.17402507    NA 0.8455208
      3 0.54443465    NA 0.8782199
      4 0.04540406    NA 0.3202252
      5 0.46052426    NA 0.7560559
      6 0.61385464     6 0.2911089
      7 0.48274968     7 0.8455208
      8 0.11961778     8 0.8782199
      9 0.64531394     9 0.3202252
    10 0.92052805    10 0.7560559

with NA in case of missing value for y to x.

{ for this example : i write simply
 > data.frame(num.x=c(1:10), 
value.x=x[[2]],num.y=c(rep(NA,5),6:10),value.y=y[[2]]) }

I didn't find solution in merge(x,y,by="num") : missing rows are no keeping.
Can't you help me ?

thanks,
Bruno



Si vous n'etes pas destinataires de ce message, merci d'avertir l'expediteur de l'erreur de distribution et de le detruire immediatement.
Ce message contient des informations confidentielles ou appartenant a La Francaise des Jeux. Il est etabli a l'intention exclusive de ses destinataires. Toute divulgation, utilisation, diffusion ou reproduction (totale ou partielle) de ce message ou des informations qu'il contient, doit etre prealablement autorisee.
Tout message electronique est susceptible d'alteration et son integrite ne peut etre assuree. La Francaise des Jeux decline toute responsabilite au titre de ce message s'il a ete modifie ou falsifie.

If you are not the intended recipient of this e-mail, please notify the sender of the wrong delivery and delete it immediately from your system.
This e-mail contains confidential information or information belonging to La Francaise des Jeux and is intended solely for the addressees. The unauthorised disclosure, use, dissemination or copying (either whole or partial) of this e-mail, or any information it contains, is prohibited.
E-mails are susceptible to alteration and their integrity cannot be guaranteed. La Francaise des Jeux shall not be liable for this e-mail if modified or falsified.



From Rau at demogr.mpg.de  Fri Jul 23 17:07:45 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Fri, 23 Jul 2004 17:07:45 +0200
Subject: [R] Replace only Capital Letters
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A0B63@hermes.demogr.mpg.de>

Dear all

thanks to the help of Prof. Brian Ripley, my little script is now working.
I use now:
gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata, perl=TRUE)
instead of:
gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata,
ignore.case=FALSE)

With regard to the question of Claus Ekstroem whether it is a problem of the
version of R I am running:
At work, I am using R 1.8.1 on Win32, at home I tried it with R 1.9.0 on
Linux (Mandrake10) but this did not yield any varying results.
However, it seems as if the version of R is relevant. In an older version
(R1.4.1) the "solution" did not work, because of the "unused argument(s)
(perl ...)".

Thanks again,
Roland


> -----Original Message-----
> From:	Prof Brian Ripley [SMTP:ripley at stats.ox.ac.uk]
> Sent:	Thursday, July 22, 2004 7:58 PM
> To:	Rau, Roland
> Cc:	'r-help at stat.math.ethz.ch'
> Subject:	Re: [R] Replace only Capital Letters
> 
> Another solution (that is correct in other locales than C, since I see 
> you are not in an English locale).
> 
> gsub(pattern = " ([[:upper:]])", replacement = " {\\1}", x=exampledata)
> 
> I think this _is_ the problem, as in your locale (and in en_GB) the sort 
> order is probably something like
> 
> aAbB...zZ
> 
> Or just try the C locale.
> 
> On Thu, 22 Jul 2004, Prof Brian Ripley wrote:
> 
> > This appears to be a bug.  Please try
> > 
> > gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata,
> perl=TRUE)
> > 
> > 
> > 
> > On Thu, 22 Jul 2004, Rau, Roland wrote:
> > 
> > > Dear All,
> > > 
> > > I have these data:
> > > 
> > > exampledata <- c("This is one item", "This is Another One", "And so is
> > > This")
> > > 
> > > I would like to find each occurence of a blank space followed by a
> Capital
> > > Letter and replace it by a blank space, a left curly brace, the
> respective
> > > Capital Letter, and then a right curly brace.
> > > 
> > > I thought the following will do:
> > > gsub(pattern = " ([A-Z])", replacement = " {\\1}", x=exampledata,
> > > ignore.case=FALSE)
> > > 
> > > Unfortunately, the actual output was:
> > > "This {i}s {o}ne {i}tem"    "This {i}s {A}nother {O}ne" "And {s}o {i}s
> > > {T}his"  
> > > 
> > > But what I wanted was actually:
> > > "This is one item"    "This is {A}nother {O}ne" "And so is {T}his"  
> > > 
> > > Can anyone tell me what I should change. Should be fairly easy for
> people
> > > with more experience than me using regular expressions, I guess.
> > > 
> > > Thanks,
> > > Roland
> > > 
> > > P.S. The background is my bibliography-file for BibTeX. If the title
> field
> > > has some content like "An analysis of Denmark", it would actually turn
> out
> > > to be "An analysis of denmark" in my dvi-document. Of course, R is not
> the
> > > appropriate tool for this. But apart from the little problem outlined
> above,
> > > I had a function doing what I wanted in less than 10 minutes.
> > > 
> > > 
> > > +++++
> > > This mail has been sent through the MPI for Demographic
> Rese...{{dropped}}
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From Stefano.Guazzetti at ausl.re.it  Fri Jul 23 17:08:20 2004
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Fri, 23 Jul 2004 17:08:20 +0200
Subject: R: R: [R] retrieve rows from frame assuming criterion [corrected]
Message-ID: <F298786BF61DE64590054AF31EA1B4C8E4030E@PEPI.ausl.org>

Yes, 
paraphrasing Murphy I can say of myself:

"Nothing seems to be able to stop a stupid thought
in its pathway from the brain to the keyboard".  :-)

Sorry once again and thank for your patience.

Stefano

> -----Messaggio originale-----
> Da: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Inviato: venerd?? 23 luglio 2004 16.30
> A: Guazzetti Stefano
> Cc: Luis Rideau Cruz; r-help at stat.math.ethz.ch
> Oggetto: Re: R: [R] retrieve rows from frame assuming criterion
> [corrected]
> 
> 
> On Fri, 23 Jul 2004, Guazzetti Stefano wrote:
> 
> > sorry for my previus (WRONG)
> > answer, as someone already pointed out
> > a solution could be
> > 
> > subset(data, PUNTAR==c("IX49","IX48"))
> 
> That's still wrong.  You want PUNTAR %in% c("IX49","IX48").  Using ==
> recycles entries, so it tests the first element against 
> "IX49", the second
> against "IX48", the third against "IX49" ....
> 
> > > -----Messaggio originale-----
> > > Da: Guazzetti Stefano 
> > > Inviato: venerd?? 23 luglio 2004 15.55
> > > A: 'Luis Rideau Cruz'; r-help at stat.math.ethz.ch
> > > Oggetto: R: [R] retrieve rows from frame assuming criterion
> > > 
> > > 
> > > Assuming your data.frame is called "data"
> > > 
> > > data[data$PUNTAR==c("IX49","IX48"),]
> > > 
> > > is probably what you want
> > > 
> > > Stefano
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>



From ramasamy at cancer.org.uk  Fri Jul 23 17:18:49 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 23 Jul 2004 16:18:49 +0100
Subject: [R] merge, cbind, or....?
In-Reply-To: <200407231507.RAA11088@bombardier2.lfdj.com>
References: <200407231507.RAA11088@bombardier2.lfdj.com>
Message-ID: <1090595929.3740.3.camel@vpn202001.lif.icnet.uk>

> x <- data.frame( 1:10, runif(10) )
> y <- data.frame( 6:10, runif(5) )
> merge(x, y, by=1, all=TRUE)
   X1.10 runif.10.   runif.5.
1      1 0.4915303         NA
2      2 0.7108826         NA
3      3 0.5658456         NA
4      4 0.4201561         NA
5      5 0.9575464         NA
6      6 0.1650210 0.82674151
7      7 0.2198187 0.24383035
8      8 0.4571945 0.01177674
9      9 0.9026321 0.76861464
10    10 0.1046505 0.23990883



On Fri, 2004-07-23 at 16:07, Bruno Cutayar wrote:
> Hi,
> i have two data.frame x and y like :
>  > x <- data.frame( num = c(1:10), value = runif(10) )
>  > y <- data.frame( num = c(6:10), value = runif(5) )
> and i want to obtain something like :
> 
>  num.x    value.x     num.y   value.y
>       1 0.38423828    NA 0.2911089
>       2 0.17402507    NA 0.8455208
>       3 0.54443465    NA 0.8782199
>       4 0.04540406    NA 0.3202252
>       5 0.46052426    NA 0.7560559
>       6 0.61385464     6 0.2911089
>       7 0.48274968     7 0.8455208
>       8 0.11961778     8 0.8782199
>       9 0.64531394     9 0.3202252
>     10 0.92052805    10 0.7560559
> 
> with NA in case of missing value for y to x.
> 
> { for this example : i write simply
>  > data.frame(num.x=c(1:10), 
> value.x=x[[2]],num.y=c(rep(NA,5),6:10),value.y=y[[2]]) }
> 
> I didn't find solution in merge(x,y,by="num") : missing rows are no keeping.
> Can't you help me ?
> 
> thanks,
> Bruno
> 
> 
> 
> Si vous n'etes pas destinataires de ce message, merci d'avertir l'expediteur de l'erreur de distribution et de le detruire immediatement.
> Ce message contient des informations confidentielles ou appartenant a La Francaise des Jeux. Il est etabli a l'intention exclusive de ses destinataires. Toute divulgation, utilisation, diffusion ou reproduction (totale ou partielle) de ce message ou des informations qu'il contient, doit etre prealablement autorisee.
> Tout message electronique est susceptible d'alteration et son integrite ne peut etre assuree. La Francaise des Jeux decline toute responsabilite au titre de ce message s'il a ete modifie ou falsifie.
> 
> If you are not the intended recipient of this e-mail, please notify the sender of the wrong delivery and delete it immediately from your system.
> This e-mail contains confidential information or information belonging to La Francaise des Jeux and is intended solely for the addressees. The unauthorised disclosure, use, dissemination or copying (either whole or partial) of this e-mail, or any information it contains, is prohibited.
> E-mails are susceptible to alteration and their integrity cannot be guaranteed. La Francaise des Jeux shall not be liable for this e-mail if modified or falsified.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sundar.dorai-raj at PDF.COM  Fri Jul 23 17:27:55 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 23 Jul 2004 10:27:55 -0500
Subject: [R] merge, cbind, or....?
In-Reply-To: <200407231507.RAA11088@bombardier2.lfdj.com>
References: <200407231507.RAA11088@bombardier2.lfdj.com>
Message-ID: <41012E7B.4000401@pdf.com>



Bruno Cutayar wrote:
> 
> 
> Hi,
> i have two data.frame x and y like :
>  > x <- data.frame( num = c(1:10), value = runif(10) )
>  > y <- data.frame( num = c(6:10), value = runif(5) )
> and i want to obtain something like :
> 
> num.x    value.x     num.y   value.y
>      1 0.38423828    NA 0.2911089
>      2 0.17402507    NA 0.8455208
>      3 0.54443465    NA 0.8782199
>      4 0.04540406    NA 0.3202252
>      5 0.46052426    NA 0.7560559
>      6 0.61385464     6 0.2911089
>      7 0.48274968     7 0.8455208
>      8 0.11961778     8 0.8782199
>      9 0.64531394     9 0.3202252
>    10 0.92052805    10 0.7560559
> 
> with NA in case of missing value for y to x.
> 
> { for this example : i write simply
>  > data.frame(num.x=c(1:10), 
> value.x=x[[2]],num.y=c(rep(NA,5),6:10),value.y=y[[2]]) }
> 
> I didn't find solution in merge(x,y,by="num") : missing rows are no 
> keeping.
> Can't you help me ?
> 

See ?merge which will tell you about the `all' argument. I believe you 
want something like (though I'm not completely sure):

m <- merge(x, y, by = "num", all = TRUE)
# now add `num.x' and `num.y' as in your example
na.x <- is.na(m$value.x)
na.y <- is.na(m$value.y)
m$num.x <- ifelse(m$num %in% x$num, m$num, NA)
m$num.y <- ifelse(m$num %in% y$num, m$num, NA)
# fill in `value.x' and `value.y' with repeated values
m$value.x[na.x] <- rep(x$value, length.out = sum(na.x))
m$value.y[na.y] <- rep(y$value, length.out = sum(na.y))

HTH,

--sundar



From MSchwartz at MedAnalytics.com  Fri Jul 23 17:36:13 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 23 Jul 2004 10:36:13 -0500
Subject: [R] merge, cbind, or....?
In-Reply-To: <200407231507.RAA11088@bombardier2.lfdj.com>
References: <200407231507.RAA11088@bombardier2.lfdj.com>
Message-ID: <1090596973.6476.9.camel@localhost.localdomain>

On Fri, 2004-07-23 at 10:07, Bruno Cutayar wrote:
> Hi,
> i have two data.frame x and y like :
>  > x <- data.frame( num = c(1:10), value = runif(10) )
>  > y <- data.frame( num = c(6:10), value = runif(5) )
> and i want to obtain something like :
> 
>  num.x    value.x     num.y   value.y
>       1 0.38423828    NA 0.2911089
>       2 0.17402507    NA 0.8455208
>       3 0.54443465    NA 0.8782199
>       4 0.04540406    NA 0.3202252
>       5 0.46052426    NA 0.7560559
>       6 0.61385464     6 0.2911089
>       7 0.48274968     7 0.8455208
>       8 0.11961778     8 0.8782199
>       9 0.64531394     9 0.3202252
>     10 0.92052805    10 0.7560559
> 
> with NA in case of missing value for y to x.
> 
> { for this example : i write simply
>  > data.frame(num.x=c(1:10), 
> value.x=x[[2]],num.y=c(rep(NA,5),6:10),value.y=y[[2]]) }
> 
> I didn't find solution in merge(x,y,by="num") : missing rows are no keeping.
> Can't you help me ?
> 
> thanks,
> Bruno

The use of merge(), with the argument 'all' set to TRUE, will get you
the following (note my values are different due to not using the same
'seed' value for runif() ):

> merge(x, y, by = "num", all = TRUE)
   num    value.x   value.y
1    1 0.14057955        NA
2    2 0.60850644        NA
3    3 0.63410731        NA
4    4 0.07196253        NA
5    5 0.51869503        NA
6    6 0.57042428 0.3340535
7    7 0.85874426 0.9340489
8    8 0.03608417 0.5417780
9    9 0.24422205 0.2214993
10  10 0.03383263 0.4947865

The use of 'all = TRUE' will fill in non-matching rows. The default is
FALSE.

Note here however, that the value.y column is not replicated for the
first five rows, as you have above. If that is what you want, you could
do something like the following:

> cbind(x, y$value)
   num      value   y$value
1    1 0.14057955 0.3340535
2    2 0.60850644 0.9340489
3    3 0.63410731 0.5417780
4    4 0.07196253 0.2214993
5    5 0.51869503 0.4947865
6    6 0.57042428 0.3340535
7    7 0.85874426 0.9340489
8    8 0.03608417 0.5417780
9    9 0.24422205 0.2214993
10  10 0.03383263 0.4947865

which takes advantage of the recycling of y$value, since it is shorter
than the number of rows in 'x'. In this case, y$value is repeated twice.
HTH,

Marc Schwartz



From ggrothendieck at myway.com  Fri Jul 23 18:17:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 23 Jul 2004 16:17:02 +0000 (UTC)
Subject: [R] ts to irts
References: <009d01c470b8$e6a67ae0$1145210a@agr.ad10.intern.kuleuven.ac.be>
	<loom.20040723T165318-55@post.gmane.org>
Message-ID: <loom.20040723T181500-934@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Jan Verbesselt <Jan.Verbesselt <at> agr.kuleuven.ac.be> writes:
: 
: : I'm working with irregular time series (time series of climate data,
: : daily data 365/6 days a year) and would like to create regular time
: : series from them ( irts 
: : 	e.g. Rain            <-
: : irts(as.POSIXct(Climate[,1]),Climate[,5]) 
: : 		to ts
: :     e.g. test <- ts(x, start=c(1997,1), frequency=365) )
: : 
: : such that I can find where the gaps (lacking temperature data, ...) are
: : and try out methods to fill the gaps.
: : 
: : The main objective is to detect gaps, how long they are and fill them if
: : possible with average, median values.
: 
: First we create vectors of dates and values, d and val,
: to use as test data.
: 
: Then we create, dd, a regular time vector of dates using 
: class Date and a corresponding logical vector not.na 
: indicating which dates in dd correspond to observations.
: 
: Finally, we average the previous non-missing and next
: non-missing observation for each data point and convert the
: result to class ts.  The last line sets the time coordinates
: to the numeric representation of the Date class of the
: corresponding dates.  (If you leave it out the times will be
: 1,2,3,...)
: 
: d <- structure(c(11,14,20,22), class = "Date")
: val <- c(10,20,30,40)
: 
: dd <- seq(min(d), max(d), by = "day")
: not.na <- dd %in% d
: 
: my.ts <- ts(val[cumsum(not.na)] + val[cumsum(not.na)+!not.na]/2)
: my.ts <- ts(my.ts, start = as.numeric(min(d)), end = as.numeric(max(d)))


I forgot one set of parentheses in the second last line.  It should be:

d <- structure(c(11,14,20,22), class = "Date")
val <- c(10,20,30,40)
 
dd <- seq(min(d), max(d), by = "day")
not.na <- dd %in% d
 
my.ts <- ts((val[cumsum(not.na)] + val[cumsum(not.na)+!not.na])/2)
my.ts <- ts(my.ts, start = as.numeric(min(d)), end = as.numeric(max(d)))



From MZodet at ahrq.gov  Fri Jul 23 18:23:35 2004
From: MZodet at ahrq.gov (Zodet, Marc)
Date: Fri, 23 Jul 2004 12:23:35 -0400
Subject: [R] Complex Surveys...Specifying Design
Message-ID: <6BCD3F430455B1418750004BCD2792590286B141@exchange2.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040723/fdfb85d4/attachment.pl

From asselinj at EXCHANGE.UMontreal.CA  Fri Jul 23 18:23:55 2004
From: asselinj at EXCHANGE.UMontreal.CA (Asselin Jerome)
Date: Fri, 23 Jul 2004 12:23:55 -0400
Subject: [R] R on AMD64 (Opteron)
Message-ID: <5A053D1CB6F677419C283E4D4E21C8D003B8CDCA@etna.sim.umontreal.ca>

Hi,

I was wondering if anyone has had good experiences using R on Linux with dual AMD64 (Opteron) processors. I'm thinking of buying a couple of such servers, but I'd like to make sure R would work fine.

The "R Installation and Administration" guide notes that there may be some problems with BLAS libraries. That's all I could find about R on AMD64.

Please share your experience using R on AMD64.

Many thanks,
Jerome Asselin



From ke1 at sanger.ac.uk  Fri Jul 23 18:25:24 2004
From: ke1 at sanger.ac.uk (Ken Edwards)
Date: Fri, 23 Jul 2004 17:25:24 +0100
Subject: [R] fisher.test FEXACT error 7
Message-ID: <41013BF4.2040505@sanger.ac.uk>

Hello,
I have an error message that doesn't seem to make sense in that having 
read the R documentation I was under the impression that R was able to 
grab as much memory as it needed, and has been able to do so for some 
time, so the advice given below about increasing the size of the 
workspace is redundant. 

If I'm right, does anyone have a solution to the problem of the size of 
LDSTP?  Or is this really a message about the limit of data size that 
the function can handle?

I have tried the function using test data containing a similar number of 
(randomly generated) data points, and it worked then. 
There are 258 data points in two columns (i.e. 2 * 134), if that helps.

Any advice would be very much appreciated,

Many thanks,

Ken Edwards.

R script below:

fisher.test(testData)

Error in fisher.test(testData) :
        FEXACT error 7.
LDSTP is too small for this problem.
Try increasing the size of the workspace.



From swanson at yellowstoneresearch.org  Fri Jul 23 18:35:08 2004
From: swanson at yellowstoneresearch.org (Alan Swanson)
Date: Fri, 23 Jul 2004 10:35:08 -0600
Subject: [R] gaussian model of 3d surface
Message-ID: <20040723163502.2263CA4630@mail01.bridgeband.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040723/9c216eee/attachment.pl

From rpeng at jhsph.edu  Fri Jul 23 18:52:42 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 23 Jul 2004 12:52:42 -0400
Subject: [R] R on AMD64 (Opteron)
In-Reply-To: <5A053D1CB6F677419C283E4D4E21C8D003B8CDCA@etna.sim.umontreal.ca>
References: <5A053D1CB6F677419C283E4D4E21C8D003B8CDCA@etna.sim.umontreal.ca>
Message-ID: <4101425A.8050402@jhsph.edu>

We've succesfully installed R on a dual Opteron machine running SuSE 
SLES 8 and managed to compile ATLAS without any problems.  R can 
access (just about) all of the 6GB of memory on the machine.

-roger

Asselin Jerome wrote:
> Hi,
> 
> I was wondering if anyone has had good experiences using R on Linux
> with dual AMD64 (Opteron) processors. I'm thinking of buying a
> couple of such servers, but I'd like to make sure R would work
> fine.
> 
> The "R Installation and Administration" guide notes that there may
> be some problems with BLAS libraries. That's all I could find about
> R on AMD64.
> 
> Please share your experience using R on AMD64.
> 
> Many thanks, Jerome Asselin
> 
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From sundar.dorai-raj at PDF.COM  Fri Jul 23 19:03:54 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 23 Jul 2004 12:03:54 -0500
Subject: [R] fisher.test FEXACT error 7
In-Reply-To: <41013BF4.2040505@sanger.ac.uk>
References: <41013BF4.2040505@sanger.ac.uk>
Message-ID: <410144FA.6020700@pdf.com>



Ken Edwards wrote:

> Hello,
> I have an error message that doesn't seem to make sense in that having 
> read the R documentation I was under the impression that R was able to 
> grab as much memory as it needed, and has been able to do so for some 
> time, so the advice given below about increasing the size of the 
> workspace is redundant.
> If I'm right, does anyone have a solution to the problem of the size of 
> LDSTP?  Or is this really a message about the limit of data size that 
> the function can handle?
> 
> I have tried the function using test data containing a similar number of 
> (randomly generated) data points, and it worked then. There are 258 data 
> points in two columns (i.e. 2 * 134), if that helps.
> 
> Any advice would be very much appreciated,
> 
> Many thanks,
> 
> Ken Edwards.
> 
> R script below:
> 
> fisher.test(testData)
> 
> Error in fisher.test(testData) :
>        FEXACT error 7.
> LDSTP is too small for this problem.
> Try increasing the size of the workspace.
> 

Maybe you should try increasing the workspace:

fisher.test(testData, workspace = 2e6)

--sundar



From hi_ono2001 at ybb.ne.jp  Fri Jul 23 19:24:46 2004
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Sat, 24 Jul 2004 02:24:46 +0900
Subject: [R] inno setup'iss files for R & RDCOM
Message-ID: <008301c470d9$f32970d0$5b8001db@webgis>

Hi.

 I'd like to build installer for integrate my GUI program for R, R for win
and RDCOM.

 Can the distribution like this be got permission?

 If so, installation of these softwares will be done in just one time.

And where can I get  each inno setup'iss file for R & RDCOM.

 Because these sources seem no to include their own iss file.

 Regards.



From jxdai at cluster.chem.nyu.edu  Thu Jul 22 12:03:50 2004
From: jxdai at cluster.chem.nyu.edu (dai)
Date: Thu, 22 Jul 2004 06:03:50 -0400
Subject: [R] (no subject)
Message-ID: <Pine.SGI.4.44.0407220556210.3628150-100000@cluster.chem.nyu.edu>

Hi,

I want to use PO test function for cointegrated series in Tseries
package which I have downloaded, how should I load the package? Thanks
for your help,

Jixin



From jetches at iwh.on.ca  Fri Jul 23 20:35:58 2004
From: jetches at iwh.on.ca (Jacob Etches)
Date: Fri, 23 Jul 2004 14:35:58 -0400
Subject: [R] Porting plotterm() & gamterms() from s-plus
Message-ID: <C91DF477A51618409DB4B2FC262215DE81A522@iwhmail01.iwh.on.ca>

I'm trying to plot pspline'd explanatory variables from coxph() models as per Therneau and Grambsch (Modeling Survival Data: Extending the Cox Model).  They have s-plus functions for this at:

http://www.mayo.edu/hsr/people/therneau/book/sfunction/gamterms.s
http://www.mayo.edu/hsr/people/therneau/book/sfunction/plotterm.s

I'd like to make these plots in R, but they make use of non-R functions, and I'm not sure how to adapt gamterms and plotterm to R.  Have others done this, or does anyone have advice?

Thanks,

Jacob Etches
University of Toronto


This e-mail may contain confidential information for the sole use of the intended recipient. Any review or distribution by anyone other than the person for whom it was originally intended is prohibited. If you have received this e-mail in error, please delete all copies. Opinions, conclusions or other information contained in this e-mail may not be that of the organization.



From lschaffe at gnf.org  Fri Jul 23 21:29:46 2004
From: lschaffe at gnf.org (Lana Schaffer)
Date: Fri, 23 Jul 2004 12:29:46 -0700
Subject: [R] graphing with error bars
Message-ID: <833E32F61B9F8746878F2A1865BECE6001455436@EXCHCLUSTER01.lj.gnf.org>


I am not able to find information about doing line plots with error bars in the R- help information.
Would someone like to tell me if this can be done in R and either get me started or lead me
to information about how to do the error bars?
Thanks,
Lana



From sundar.dorai-raj at PDF.COM  Fri Jul 23 21:36:03 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 23 Jul 2004 14:36:03 -0500
Subject: [R] graphing with error bars
In-Reply-To: <833E32F61B9F8746878F2A1865BECE6001455436@EXCHCLUSTER01.lj.gnf.org>
References: <833E32F61B9F8746878F2A1865BECE6001455436@EXCHCLUSTER01.lj.gnf.org>
Message-ID: <410168A3.7040705@pdf.com>



Lana Schaffer wrote:

> I am not able to find information about doing line plots with error bars in the R- help information.
> Would someone like to tell me if this can be done in R and either get me started or lead me
> to information about how to do the error bars?
> Thanks,
> Lana
> 

Lana,

?plotCI in package:gregmisc or ?errbar in package:Hmisc might help.

--sundar



From rpeng at jhsph.edu  Fri Jul 23 21:48:03 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 23 Jul 2004 15:48:03 -0400
Subject: [R] graphing with error bars
In-Reply-To: <833E32F61B9F8746878F2A1865BECE6001455436@EXCHCLUSTER01.lj.gnf.org>
References: <833E32F61B9F8746878F2A1865BECE6001455436@EXCHCLUSTER01.lj.gnf.org>
Message-ID: <41016B73.3090007@jhsph.edu>

It's not too hard to write your own function using segments() or 
arrows().  Also, plotCI() in package `gregmisc' may do the job you need.

-roger

Lana Schaffer wrote:
> I am not able to find information about doing line plots with error
> bars in the R- help information. Would someone like to tell me if
> this can be done in R and either get me started or lead me to
> information about how to do the error bars? Thanks, Lana
> 
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From tobias_verbeke at skynet.be  Fri Jul 23 21:49:02 2004
From: tobias_verbeke at skynet.be (Tobias Verbeke)
Date: Fri, 23 Jul 2004 19:49:02 +0000
Subject: [R] Complex Surveys...Specifying Design
In-Reply-To: <6BCD3F430455B1418750004BCD2792590286B141@exchange2.ahrq.gov>
References: <6BCD3F430455B1418750004BCD2792590286B141@exchange2.ahrq.gov>
Message-ID: <20040723194902.6d48ceba.tobias_verbeke@skynet.be>

On Fri, 23 Jul 2004 12:23:35 -0400
"Zodet, Marc" <MZodet at ahrq.gov> wrote:

> I need some guidance from someone who is familiar/has some experience with
> the survey package.
> 
>  
> 
> The data that I am using is from the Medical Expenditure Panel Survey
> (www.meps.ahrq.gov <http://www.meps.ahrq.gov/> ).  The STRATA and PSU
> variables are varstr01 and varpsu01 respectively.  When I try to specify
> them with the svydesign function I get an error message.  An excerpt of my
> session is as follows...
> 
>  
> 
> library(foreign)
> 
> > h60 <- read.xport("h:\\meps\\temptransports\\h60.tpt")
> 
> > names(h60) <- casefold(names(h60))
> 
> > names(h60)
> 
> [1] "dupersid" "sex"      "inscov01" "totexp01" "perwt01f" "varstr01"
> "varpsu01"
> 
> > library(survey)
> 
> > meps.design <- svydesign(id=~varpsu01, strata=~varstr01, weight=~perwt01f,
> data=h60)
> 
> Error in svydesign(id = ~varpsu01, strata = ~varstr01, weight = ~perwt01f,
> : 
> 
>         Clusters not nested in strata
> 
> >
> 
>  
> 
> I'm not sure what is causing this error message or how to get around it
> (i.e., remedy the problem).  Any insight would be much appreciated.

Hi,

I guess the most common way of proceeding is to first stratify, 
and then to sample clusters independently within each stratum.
If this is the case, your data file can be put together like

stratum		psu	...
1		1
1		2
1		3
2		1
2		2
2		3

or like

stratum		psu	...
1		1
1		2
1		3
2		4
2		5
2		6

svydesign only likes the first data structure so
if this is not the case (clusters not 'nested' in
your strata) you should tell svydesign to nest 
(relabel) the clusters for you by passing the 
argument nest = TRUE to svydesign. In other words:

meps.design <- svydesign(ids = ~varpsu01, strata = ~varstr01, 
	weights = ~perwt01f, nest = TRUE, data = h60)

should work. See ?svydesign.

HTH,
Tobias



From kkthird at yahoo.com  Fri Jul 23 22:10:51 2004
From: kkthird at yahoo.com (KKThird@Yahoo.Com)
Date: Fri, 23 Jul 2004 13:10:51 -0700 (PDT)
Subject: [R] nlme parameters in nlmeControl
Message-ID: <20040723201051.61004.qmail@web52504.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040723/767435cf/attachment.pl

From jawegelin at ucdavis.edu  Fri Jul 23 23:28:33 2004
From: jawegelin at ucdavis.edu (Jacob Wegelin)
Date: Fri, 23 Jul 2004 14:28:33 -0700 (PDT)
Subject: [R] lme4 groupedData is missing
Message-ID: <Pine.OSX.4.53.0407231126290.13075@biostat5.ucdavis.edu>


help.search("groupedData") says that it's part of the lme4 package, but it
appears not to be there (details below). Is this because lme4 is new and
(perhaps) still under development?

> update.packages()
trying URL `http://cran.r-project.org/bin/windows/contrib/1.9/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 19113 bytes
opened URL
downloaded 18Kb

> library("lme4")
> groupedData
Error: Object "groupedData" not found
> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

Jake Wegelin



From sundar.dorai-raj at PDF.COM  Fri Jul 23 23:42:31 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 23 Jul 2004 16:42:31 -0500
Subject: [R] lme4 groupedData is missing
In-Reply-To: <Pine.OSX.4.53.0407231126290.13075@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0407231126290.13075@biostat5.ucdavis.edu>
Message-ID: <41018647.6080109@pdf.com>



Jacob Wegelin wrote:
> help.search("groupedData") says that it's part of the lme4 package, but it
> appears not to be there (details below). Is this because lme4 is new and
> (perhaps) still under development?
> 
> 
>>update.packages()
> 
> trying URL `http://cran.r-project.org/bin/windows/contrib/1.9/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 19113 bytes
> opened URL
> downloaded 18Kb
> 
> 
>>library("lme4")
>>groupedData
> 
> Error: Object "groupedData" not found
> 
>>version
> 
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> Jake Wegelin
> 

You've missed the namespace discussion. Try:

lme4:::groupedData

Read the following article to catch up

http://cran.r-project.org/doc/Rnews/Rnews_2003-1.pdf

--sundar



From kjetil at acelerate.com  Fri Jul 23 23:09:53 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Fri, 23 Jul 2004 17:09:53 -0400
Subject: [R] fisher.test FEXACT error 7
References: <41013BF4.2040505@sanger.ac.uk>
Message-ID: <41017EA1.30907@acelerate.com>

It does'nt really answer your question, but you could use
chisq.test(mytable, si=TRUE, B=20000)

Kjetil Halvorsen

Ken Edwards wrote:

> Hello,
> I have an error message that doesn't seem to make sense in that having 
> read the R documentation I was under the impression that R was able to 
> grab as much memory as it needed, and has been able to do so for some 
> time, so the advice given below about increasing the size of the 
> workspace is redundant.
> If I'm right, does anyone have a solution to the problem of the size 
> of LDSTP?  Or is this really a message about the limit of data size 
> that the function can handle?
>
> I have tried the function using test data containing a similar number 
> of (randomly generated) data points, and it worked then. There are 258 
> data points in two columns (i.e. 2 * 134), if that helps.
>
> Any advice would be very much appreciated,
>
> Many thanks,
>
> Ken Edwards.
>
> R script below:
>
> fisher.test(testData)
>
> Error in fisher.test(testData) :
>        FEXACT error 7.
> LDSTP is too small for this problem.
> Try increasing the size of the workspace.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From gwgilc at wm.edu  Sat Jul 24 00:55:46 2004
From: gwgilc at wm.edu (George W. Gilchrist)
Date: Fri, 23 Jul 2004 18:55:46 -0400
Subject: [R] exporting high quality graphics from R in Mac OSX
In-Reply-To: <D1912480-DBD1-11D8-9ADD-000D9335A24A@qmul.ac.uk>
Message-ID: <BD270FB2.1A5C%gwgilc@wm.edu>

I almost always do a bit of tweaking of my R graphics (output as postscript
files) using Adobe Illustrator. The latest version has the option of saving
the file "For Microsoft Office..." under the File menu. The resulting *.png
file comes up clean in PowerPoint or in Word.

Cheers, George
 


On 7/22/04 7:25 AM, "Rob Knell" <R.Knell at qmul.ac.uk> wrote:

> Hi there
> 
> The default option for saving graphics from R (1.9.1) on my Mac is as a
> pdf file. If I open the file in Acrobat reader it looks really good and
> crisp, and is obviously saved as vector graphics, since I can zoom in
> as much as I like and it continues to look really nice. If I import it
> into MS Word (from office 2000), or Textedit, however, it imports it as
> a bitmap and unless I save it as a pretty big image and then shrink it
> in size by about three times after import it looks blurry and
> pixellated. The save it as a really big picture and shrink it option is
> bearable, but hardly elegant.
> 
> I'm trying to persuade some other people in my department that we
> should move to using R as a standard analysis package, and this is
> currently one strike against it - it's difficult to export
> decent-looking high-res graphics. If I want to persuade people to use
> R, I need to be able to give them an easy way to do this. There are
> some solutions like importing the text and then the graphics into
> acrobat, or installing ghostscript and trying it with the graphics as
> postscript, but obviously people will respond to this with 'why should
> I waste time and or money doing this when I can just cut and paste out
> of Excel/Statistica/Minitab'. I realise that this is arguably more of a
> problem with Word or Textedit, but does anyone know of a good easy
> solution to this that I can use as part of my program to evangelise my
> colleagues?
> 
> Thanks for any help
> 
> Rob Knell
> 
> 

==================================================================
George W. Gilchrist                        Email #1: gwgilc at wm.edu
Department of Biology, Box 8795          Email #2: kitesci at cox.net
College of William & Mary                    Phone: (757) 221-7751
Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
http://gwgilc.people.wm.edu/



From deepayan at stat.wisc.edu  Sat Jul 24 01:22:20 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 23 Jul 2004 18:22:20 -0500
Subject: [R] lme4 groupedData is missing
In-Reply-To: <Pine.OSX.4.53.0407231126290.13075@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0407231126290.13075@biostat5.ucdavis.edu>
Message-ID: <200407231822.20516.deepayan@stat.wisc.edu>


On Friday 23 July 2004 16:28, Jacob Wegelin wrote:

> help.search("groupedData") says that it's part of the lme4 package,
> but it appears not to be there (details below). Is this because lme4
> is new and (perhaps) still under development?

Yes, sort of. The groupedData class in nlme inherits from "data.frame". 
Since "data.frame" is not an S4 class, this is difficult to emulate, 
and we are still experimenting on how to represent grouping 
information. The groupedData class in lme4 is one attempt, but the 
current plans are to scrap it and just have the grouping information as 
attributes on a data frame.

It so happens that the current groupedData function is not exported, 
which is why you can't see it. That's an oversight on my part, but 
since it will probably go away anyway, this is a good thing.

Deepayan



From murdoch at stats.uwo.ca  Sat Jul 24 02:26:32 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 23 Jul 2004 20:26:32 -0400
Subject: [R] inno setup'iss files for R & RDCOM
In-Reply-To: <008301c470d9$f32970d0$5b8001db@webgis>
References: <008301c470d9$f32970d0$5b8001db@webgis>
Message-ID: <nja3g09rfprlnkkokkp6go5g4068m93t1k@4ax.com>

On Sat, 24 Jul 2004 02:24:46 +0900, "Hisaji ONO"
<hi_ono2001 at ybb.ne.jp> wrote:

>Hi.
>
> I'd like to build installer for integrate my GUI program for R, R for win
>and RDCOM.
>
> Can the distribution like this be got permission?

The GPL gives you permission to modify R and redistribute, as long as
you leave the GPL license intact and make the source code of what you
distribute available.  (But I'm neither a lawyer nor the copyright
holder for all of R, so don't trust me, read the license).

> If so, installation of these softwares will be done in just one time.
>
>And where can I get  each inno setup'iss file for R & RDCOM.
>
> Because these sources seem no to include their own iss file.

The iss file for R is produced by the JRins.pl Perl script in
src/gnuwin32/installer, after the Makefile in the same directory has
copied an image of R to a temporary directory.  If you just want the
script, you can run

make R.iss

in that directory (assuming you've already made all the constituent
parts).  I'd recommend not editing this file, however:  you're better
off trying to make all your changes to src/gnuwin32/MkRules or one of
the Makefiles if you don't want to go through all the work again as
soon as you've incorporated the next R patch.

Duncan Murdoch



From kirpich at fas.harvard.edu  Sat Jul 24 06:58:56 2004
From: kirpich at fas.harvard.edu (Yevgeniy Kirpichevsky)
Date: Fri, 23 Jul 2004 23:58:56 -0500
Subject: [R] rbind()
Message-ID: <6.1.0.6.2.20040723234947.01c4b420@imap.fas.harvard.edu>

hi.  I'm merging two datasets.
one of them is 51 rows, and a typical row looks like this:

midwar[midwar$dispnum==89,]
    dispnum synch sanum saname sbnum sbname year1 yearn ainit binit fatala
158      89     0   220    FRN   230    SPN  1822  1823     1     1      4
     fatalb       key1       keyn warnum year1.war yearn.war awon
158      5 2202301822 2202301823      1      1823      1823    2

The other is 3 rows, and it looks like this:
   dispnum synch sanum saname sbnum sbname year1 yearn ainit binit fatala 
fatalb
7      NA    NA    70    MEX   220    FRN    NA    NA    NA    NA     NA     NA
   key1 keyn warnum year1.war yearn.war awon
7   NA   NA     40      1862      1867    2

So the column names are identical, and rbind() shouldn't create 
problems.  Here's what happens now when I call this:
midwar[midwar$dispnum==89,]

      dispnum synch sanum saname sbnum sbname year1 yearn ainit binit fatala
158       89     0   220    FRN   230    SPN  1822  1823     1     1      4
NA        NA    NA    NA   <NA>    NA   <NA>    NA    NA    NA    NA     NA
NA.1      NA    NA    NA   <NA>    NA   <NA>    NA    NA    NA    NA     NA
NA.2      NA    NA    NA   <NA>    NA   <NA>    NA    NA    NA    NA     NA
      fatalb       key1       keyn warnum year1.war yearn.war awon
158       5 2202301822 2202301823      1      1823      1823    2
NA       NA         NA         NA     NA        NA        NA   NA
NA.1     NA         NA         NA     NA        NA        NA   NA
NA.2     NA         NA         NA     NA        NA        NA   NA

It gives me extra 3 rows of NAs for each row of the original data set.  The 
only thing that I can think of that may be going on is that in the first 
data set the names of counties are vectors of factors, and in the second 
data set they are characters.  Could that be causing a problem?  I can't 
check, because I can't make factor vectors into character vectors 
(as.character() didn't work).

Sorry for the rambling question.  Any insights are appreciated,

-yev



From patrick.giraudoux at univ-fcomte.fr  Fri Jul 23 17:35:53 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 23 Jul 2004 17:35:53 +0200
Subject: [R] Re: bootstrap and nls
Message-ID: <002d01c4714c$6240e5d0$961e0e50@PC728329681112>

Hi,

Just a recap on the trials done based on Spencer Grave, Bervin A Turlach and Christian Ritz's advise.

On their suggestion, the trouble mentioned has well been turned using the function try() (using the algorithm "plinear" unstead of
"default" was unsuccessful) in the following way:

library(boot)

dif.param<-function(data,i){
RaiesLossA.nls<-try(nls(SolA~a/(1+b*Tps)^c,start=c(a=31,b=0.5,c=0.6),data[i,]),silent=TRUE)
RaiesLossB.nls<-try(nls(Solb~a/(1+b*Tps)^c,start=c(a=33,b=1.4,c=0.5),data[i,]),silent=TRUE)

if ( (inherits(RaiesLossA.nls,"try-error")) |
(inherits(RaiesLossB.nls,"try-error"))) {return(NA)} else {
return(RaiesLossA.nls$m$getPars()-RaiesLossB.nls$m$getPars())}

}

myboot<-boot(Raies,dif.param,R=1000)


The boot objet "myboot" that one get cannot however be handled, eg with boot.ci(),  because "myboot$t" has NA values. This can be
corrected in this way:

myboot$t<-na.omit(myboot$t)
myboot$R<-length(myboot$t[,1])

boot.ci(myboot,index=1, type=c("norm","basic","perc", "bca"))

Studentized CI appear to be quite unstable here and were not used.

That's it!

The effect of omitting some bootstrap replicates (the less than 10% that could not lead to a propper fit)  is however questionable:
may this
biase the result in a way? I am not too much worried about it for my current purpose (crude comparison of parameters), but I
guess that it may be an issue for true statisticians...

Many thanks for the most helpful hints provided,

Patrick Giraudoux




>Hi,
>
>I am trying to bootstrap the difference between each parameters among two non linear regression (distributed loss model) as
>following:
>
># data.frame
>
>
>>Raies[1:10,]
>>
>>
>   Tps  SolA  Solb
>1    0 32.97 35.92
>2    0 32.01 31.35
>3    1 21.73 22.03
>4    1 23.73 18.53
>5    2 19.68 18.28
>6    2 18.56 16.79
>7    3 18.79 15.61
>8    3 17.60 13.43
>9    4 14.83 12.76
>10   4 17.33 14.91
>etc...
>
># non linear model (work well)
>
>RaiesLossA.nls<-nls(SolA~a/(1+b*Tps)^c,start=c(a=32,b=0.5,c=0.6))
>RaiesLossB.nls<-nls(Solb~a/(1+b*Tps)^c,start=c(a=33,b=1.5,c=0.5))
>
>
># bootstrap
>library(boot)
>
>dif.param<-function(data,i){
>RaiesLossA.nls<-nls(SolA[i]~a/(1+b*Tps[i])^c,start=c(a=31,b=0.5,c=0.6))
>RaiesLossB.nls<-nls(Solb[i]~a/(1+b*Tps[i])^c,start=c(a=33,b=1.4,c=0.5))
>RaiesLossA.nls$m$getPars()-RaiesLossB.nls$m$getPars()
>}
>
>
>
>> myboot<-boot(Raies,dif.param,R=1000)
>>
>>
>
>Error in numericDeriv(form[[3]], names(ind), env) :
>        Missing value or an Infinity produced when evaluating the model
>
>It seems that the init values (start=) may come not to be suitable while bootstraping. Data can be sent offline to whom wanted to
>try on the dataset.
>
>Any hint welcome!
>
>Best regards,
>
>Patrick Giraudoux



From ripley at stats.ox.ac.uk  Sat Jul 24 09:41:45 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Jul 2004 08:41:45 +0100 (BST)
Subject: [R] R on AMD64 (Opteron)
In-Reply-To: <5A053D1CB6F677419C283E4D4E21C8D003B8CDCA@etna.sim.umontreal.ca>
Message-ID: <Pine.LNX.4.44.0407240833330.2197-100000@gannet.stats>

On Fri, 23 Jul 2004, Asselin Jerome wrote:

> Hi,
> 
> I was wondering if anyone has had good experiences using R on Linux with
> dual AMD64 (Opteron) processors. I'm thinking of buying a couple of such
> servers, but I'd like to make sure R would work fine.
> 
> The "R Installation and Administration" guide notes that there may be
> some problems with BLAS libraries. That's all I could find about R on
> AMD64.

Actually it says with ATLAS BLAS, not generically.

> Please share your experience using R on AMD64.

Quite a few people, including us, are using R on such servers routinely
with no problems at all.  There are still some issues about how to squeeze 
the maximum performance out of them (e.g. which BLAS to use -- we are 
using Goto's -- and which compiler to use, e.g. Portland Group or Intel).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Sat Jul 24 09:51:47 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 24 Jul 2004 09:51:47 +0200
Subject: [R] ts to irts
In-Reply-To: <loom.20040723T181500-934@post.gmane.org>
Message-ID: <MABBLJDICACNFOLGIHJOKENLEKAA.phgrosjean@sciviews.org>

... huummm, it seems you miss the functions in the PASTECS package. You will
find there all you need to answer your question:
- regul.screen(), which tests different time intervals and starting values
and determines which one is the best (that is, which combinaison leads to
the lower number of interpolated observations in the regular time series),

- regul.adj(), that represent how far are observations from interpolated
values in the time axis, and allows you to determine if you would like to
use a "tolerance window" (an example: your interval is 14 days, a tolerance
window of +/- 1 day will allow you to keep an observation if it is within a
window of +/- 1 day in the irregular time series compared to the regular
time series. Otherwise, interpolation is used),

- regul(), that creates an object of the same name with a sophisticated
plot() method to compare the irregular and regular time series, ident() to
point sensitive observations with the mouse and give them more weight in the
transformation from irregular to regular time series (let's say, isolated
peaks that are possibly lost in the regular time series otherwise...). Also,
regul() allows to treat many series as once, or to save parameters of the
process and reapply them on other series at a later time very easily. It
also proposes several methods for interpolation: constant, linear, spline,
area. We found the area method particularly useful for hydroclimatic
variables in oceanography... so, it would be worth trying them on your
climatic data. As far as I know, this method is not proposed elsewhere in R.

- extract(), or as.tseries() that extract series or transform a 'regul'
object into a ts() or mts() object.

If all this is powerful, it is also quite complex. I advise to follow
examples in the PASTECS manual (currently only in French) that you can
download from http://www.sciviews.org/pastecs/ to get familiarize with these
functions and their philosophy.

Best,

Philippe Grosjean

.......................................................<?}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
Sent: Friday, 23 July, 2004 18:17
To: r-help at stat.math.ethz.ch
Subject: Re: [R] ts to irts


Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

:
: Jan Verbesselt <Jan.Verbesselt <at> agr.kuleuven.ac.be> writes:
:
: : I'm working with irregular time series (time series of climate data,
: : daily data 365/6 days a year) and would like to create regular time
: : series from them ( irts
: : 	e.g. Rain            <-
: : irts(as.POSIXct(Climate[,1]),Climate[,5])
: : 		to ts
: :     e.g. test <- ts(x, start=c(1997,1), frequency=365) )
: :
: : such that I can find where the gaps (lacking temperature data, ...) are
: : and try out methods to fill the gaps.
: :
: : The main objective is to detect gaps, how long they are and fill them if
: : possible with average, median values.
:
: First we create vectors of dates and values, d and val,
: to use as test data.
:
: Then we create, dd, a regular time vector of dates using
: class Date and a corresponding logical vector not.na
: indicating which dates in dd correspond to observations.
:
: Finally, we average the previous non-missing and next
: non-missing observation for each data point and convert the
: result to class ts.  The last line sets the time coordinates
: to the numeric representation of the Date class of the
: corresponding dates.  (If you leave it out the times will be
: 1,2,3,...)
:
: d <- structure(c(11,14,20,22), class = "Date")
: val <- c(10,20,30,40)
:
: dd <- seq(min(d), max(d), by = "day")
: not.na <- dd %in% d
:
: my.ts <- ts(val[cumsum(not.na)] + val[cumsum(not.na)+!not.na]/2)
: my.ts <- ts(my.ts, start = as.numeric(min(d)), end = as.numeric(max(d)))


I forgot one set of parentheses in the second last line.  It should be:

d <- structure(c(11,14,20,22), class = "Date")
val <- c(10,20,30,40)

dd <- seq(min(d), max(d), by = "day")
not.na <- dd %in% d

my.ts <- ts((val[cumsum(not.na)] + val[cumsum(not.na)+!not.na])/2)
my.ts <- ts(my.ts, start = as.numeric(min(d)), end = as.numeric(max(d)))

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andrewr at uidaho.edu  Sat Jul 24 10:07:18 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Sat, 24 Jul 2004 18:07:18 +1000
Subject: [R] R on AMD64 (Opteron)
Message-ID: <1362e4130cf3.130cf31362e4@uidaho.edu>

Professor Ripley,

which operating system are you using for these servers, please?  
Thanks,

Andrew

----- Original Message -----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
Date: Saturday, July 24, 2004 5:41 pm
Subject: Re: [R] R on AMD64 (Opteron)

> On Fri, 23 Jul 2004, Asselin Jerome wrote:
> 
> > Hi,
> > 
> > I was wondering if anyone has had good experiences using R on 
> Linux with
> > dual AMD64 (Opteron) processors. I'm thinking of buying a couple 
> of such
> > servers, but I'd like to make sure R would work fine.
> > 
> > The "R Installation and Administration" guide notes that there 
> may be
> > some problems with BLAS libraries. That's all I could find about 
> R on
> > AMD64.
> 
> Actually it says with ATLAS BLAS, not generically.
> 
> > Please share your experience using R on AMD64.
> 
> Quite a few people, including us, are using R on such servers 
> routinelywith no problems at all.  There are still some issues 
> about how to squeeze 
> the maximum performance out of them (e.g. which BLAS to use -- we 
> are 
> using Goto's -- and which compiler to use, e.g. Portland Group or 
> Intel).
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From bates at stat.wisc.edu  Sat Jul 24 16:12:07 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 24 Jul 2004 09:12:07 -0500
Subject: [R] nlme parameters in nlmeControl
In-Reply-To: <20040723201051.61004.qmail@web52504.mail.yahoo.com>
References: <20040723201051.61004.qmail@web52504.mail.yahoo.com>
Message-ID: <41026E37.9030208@stat.wisc.edu>

KKThird at Yahoo.Com wrote:

> Hello all.
> 
> I'm doing a simulation study where I will be making use of the 'nlme'
> package. I want to loosen up the convergence criteria so that I
> increase the likelihood of convergence (potentially at the cost of
> obtaining slightly less than ideal results). The parameters in the
> function nlmeControl() control the convergence criteria. These
> default values can be modified to make convergence critera more or
> less stringent. In an effort to get more converging results, I first
> increased the iterations for 'maxIter', 'pnlsMaxIter', 'msMaxIter',
> and 'niterEM' by a factor of 20. I don't believe there is any harm in
> doing this.

This may not be the best strategy because nlme has iterations within 
iterations and you are changing the maximum number of iterations for 
both types.  I'll use Don Watts' terms of "innerations" and 
"outerations".  The 'maxiter' parameter is the maximum number of 
"outerations".  Increasing that parameter is fine.  The other parameters 
control different aspects of the "innerations" which consist of a 
penalized nonlinear least squares (pnls) step followed by optimization 
of a locally linear mixed model (llmm).  The llmm step itself has two 
stages: EM iterations and general optimization.

The 'niterEM' parameter is the number of iterations that will be done on 
the first llmm problem.  There is no convergence criterion for the EM 
iterations.  If you set niterEM = 1000 then it will do exactly 1000 
iterations.  This will do no harm but it may be a waste of time for two 
reasons - EM iterations are slow to converge and these iterations apply 
to the first llmm problem, which may be changed radically by the next 
pnls step so you are spending time getting an accurate answer to the 
wrong problem.  The default is 25.  I sometimes increase it to 100 but 
rarely beyond that.

The 'msMaxIter' parameter is the maximum number of iterations allowed in 
the general optimization stage of each llmm step.  That could be 
increased but probably not beyond a couple of hundred.  If the optimizer 
can't converge after, say, 500 iterations then the llmm step is in trouble.

The 'pnlsMaxIter' parameter is the maximum number of iterations in each 
pnls step.  The default is 7.  It is not a good idea to make this very 
large because getting an accurate answer to a pnls step, especially the 
first few, is another case of worrying about getting an accurate answer 
to the wrong problem.  The idea is that you only take a few steps in the 
early pnls problems, then switch to the llmm problem which will provide 
a different pnls problem to solve.


> There are a few parameters, however, in the nlme controls that I'm
> not quite sure what they mean or do. For example, exactly what is
> 'minScale?' The help file says that it is "the minimum factor by
> which to shrink the default step size in an attempt to decrease the
> sum of squares in the 'PNLS' step." What does it mean to increase the
> default value? Will increasing this value lead to more convergence
> because the criteria is more liberal?

Hmm.  If that description doesn't make sense then it is unlikely that I 
will be able to write a better one in this email message.  Perhaps it 
would be best just to say that if you increase minScale then the pnls 
steps will terminate earlier.  It is unlikely that decreasing this 
parameter will help ensure convergence.

> Is the tolerance criteria met when the change in the log likelihood
> is reduced below the specified value, or is it a value other than the
> log likelihood? What about for the pnlsTol? That is, what is the
> quantity whose change must be less than pnlsTol to continue?

The overall convergence is declared when the relative change in the 
parameters after a pnls/llmm pair is below the convergence criterion.
The pnlsTol applies only to the pnls step.

> Is there anything wrong with reducing 'minAbsParApVar' to zero (so
> that a parameter can be fixed across all individuals and thus not
> have a variance)?

That's not the effect of that parameter.  The llmm problem is always 
parameterized in terms of the relative precision matrices, which are the 
inverses of the relative variance-covariance matrices.  A variance of 
zero corresponds to an infinite precision and cannot be represented by 
finite parameter values.

> Is anything, other than the help file, written about the default
> control parameters for nlme? Perhaps I missed it, but I didn't see
> anything in Pinheiro and Bates (2000). To some extent the default
> parameters are arbitrary, so I'm interested in knowing if someone has
> opinions or has considered changing them.
> 
> Thanks for any thoughts, Ken
> 
> 
>  ---------------------------------
> 
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help PLEASE do read
> the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Sat Jul 24 16:41:03 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 24 Jul 2004 16:41:03 +0200
Subject: [R] gaussian model of 3d surface
In-Reply-To: <20040723163502.2263CA4630@mail01.bridgeband.net>
References: <20040723163502.2263CA4630@mail01.bridgeband.net>
Message-ID: <16642.29951.157253.534403@gargle.gargle.HOWL>

>>>>> "Alan" == Alan Swanson <swanson at yellowstoneresearch.org>
>>>>>     on Fri, 23 Jul 2004 10:35:08 -0600 writes:

    Alan> Hi all, I'm working with radar remote sensing data and
    Alan> want to measure the height of 3d spikes created by
    Alan> backscatter from bright objects.  My thought is to fit
    Alan> a gaussian density function to each spike and extract
    Alan> the x, y and z location of the peak.  Can anybody give
    Alan> me a hint of how to do this?

If I understand correctly,
you want to fit what is commonly called a "(finite) Normal
Mixture Model" to your 3d data 
and then extract the (estimated) (3d-)means of each component ?

If yes, then consider using package 'mclust'.

Regards,
Martin Maechler



From spencer.graves at pdf.com  Sat Jul 24 16:53:54 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 24 Jul 2004 07:53:54 -0700
Subject: [R] Re: bootstrap and nls
In-Reply-To: <002d01c4714c$6240e5d0$961e0e50@PC728329681112>
References: <002d01c4714c$6240e5d0$961e0e50@PC728329681112>
Message-ID: <41027802.1050303@pdf.com>

      I would think that having to eliminate close to 10% of bootstrap 
samples could be an issue. 

      Have you considered using
   

	  myboot<-boot(Raies,dif.param,R=1000, sim="permutation")


      Permutation testing does sampling without replacement rather than 
sampling with replacement.  Perhaps someone else can enlighten us both 
on the arguments for and against both permutation testing and 
bootstrapping, but permutation testing could eliminate one source of NAs 
in the output;  in any event, I would want to keep track of the percent 
of NAs obtained under both.  For a statistical audience, you would need 
to cite literature explaining the difference between permutation testing 
and bootsrapping, to help people understand your results. 

      hope this helps.  spencer graves

Patrick Giraudoux wrote:

>Hi,
>
>Just a recap on the trials done based on Spencer Grave, Bervin A Turlach and Christian Ritz's advise.
>
>On their suggestion, the trouble mentioned has well been turned using the function try() (using the algorithm "plinear" unstead of
>"default" was unsuccessful) in the following way:
>
>library(boot)
>
>dif.param<-function(data,i){
>RaiesLossA.nls<-try(nls(SolA~a/(1+b*Tps)^c,start=c(a=31,b=0.5,c=0.6),data[i,]),silent=TRUE)
>RaiesLossB.nls<-try(nls(Solb~a/(1+b*Tps)^c,start=c(a=33,b=1.4,c=0.5),data[i,]),silent=TRUE)
>
>if ( (inherits(RaiesLossA.nls,"try-error")) |
>(inherits(RaiesLossB.nls,"try-error"))) {return(NA)} else {
>return(RaiesLossA.nls$m$getPars()-RaiesLossB.nls$m$getPars())}
>
>}
>
>myboot<-boot(Raies,dif.param,R=1000)
>
>
>The boot objet "myboot" that one get cannot however be handled, eg with boot.ci(),  because "myboot$t" has NA values. This can be
>corrected in this way:
>
>myboot$t<-na.omit(myboot$t)
>myboot$R<-length(myboot$t[,1])
>
>boot.ci(myboot,index=1, type=c("norm","basic","perc", "bca"))
>
>Studentized CI appear to be quite unstable here and were not used.
>
>That's it!
>
>The effect of omitting some bootstrap replicates (the less than 10% that could not lead to a propper fit)  is however questionable:
>may this
>biase the result in a way? I am not too much worried about it for my current purpose (crude comparison of parameters), but I
>guess that it may be an issue for true statisticians...
>
>Many thanks for the most helpful hints provided,
>
>Patrick Giraudoux
>
>
>
>
>  
>
>>Hi,
>>
>>I am trying to bootstrap the difference between each parameters among two non linear regression (distributed loss model) as
>>following:
>>
>># data.frame
>>
>>
>>    
>>
>>>Raies[1:10,]
>>>
>>>
>>>      
>>>
>>  Tps  SolA  Solb
>>1    0 32.97 35.92
>>2    0 32.01 31.35
>>3    1 21.73 22.03
>>4    1 23.73 18.53
>>5    2 19.68 18.28
>>6    2 18.56 16.79
>>7    3 18.79 15.61
>>8    3 17.60 13.43
>>9    4 14.83 12.76
>>10   4 17.33 14.91
>>etc...
>>
>># non linear model (work well)
>>
>>RaiesLossA.nls<-nls(SolA~a/(1+b*Tps)^c,start=c(a=32,b=0.5,c=0.6))
>>RaiesLossB.nls<-nls(Solb~a/(1+b*Tps)^c,start=c(a=33,b=1.5,c=0.5))
>>
>>
>># bootstrap
>>library(boot)
>>
>>dif.param<-function(data,i){
>>RaiesLossA.nls<-nls(SolA[i]~a/(1+b*Tps[i])^c,start=c(a=31,b=0.5,c=0.6))
>>RaiesLossB.nls<-nls(Solb[i]~a/(1+b*Tps[i])^c,start=c(a=33,b=1.4,c=0.5))
>>RaiesLossA.nls$m$getPars()-RaiesLossB.nls$m$getPars()
>>}
>>
>>
>>
>>    
>>
>>>myboot<-boot(Raies,dif.param,R=1000)
>>>
>>>
>>>      
>>>
>>Error in numericDeriv(form[[3]], names(ind), env) :
>>       Missing value or an Infinity produced when evaluating the model
>>
>>It seems that the init values (start=) may come not to be suitable while bootstraping. Data can be sent offline to whom wanted to
>>try on the dataset.
>>
>>Any hint welcome!
>>
>>Best regards,
>>
>>Patrick Giraudoux
>>    
>>
>
>
>
>
>
>
>  
>



From assuncao.senra at portugalmail.com  Sat Jul 24 17:38:43 2004
From: assuncao.senra at portugalmail.com (assuncao.senra@portugalmail.com)
Date: Sat, 24 Jul 2004 16:38:43 +0100
Subject: [R] Population simulation.
Message-ID: <1090683523.4102828339ae3@webmail1.portugalmail.pt>



Hello,

can anyone tell me if R has any special function for simulating the structure 
of human populations? Something like the genetic algorithm?
I need to simulate a sample of a population with a specific structure. Is 
there something on R that can help me?

Thanks to everyone. 
__________________________________________________________




From thpe at hhbio.wasser.tu-dresden.de  Sat Jul 24 17:58:21 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Sat, 24 Jul 2004 17:58:21 +0200
Subject: [R] Population simulation.
In-Reply-To: <1090683523.4102828339ae3@webmail1.portugalmail.pt>
References: <1090683523.4102828339ae3@webmail1.portugalmail.pt>
Message-ID: <4102871D.5060106@hhbio.wasser.tu-dresden.de>

assuncao.senra at portugalmail.com wrote:

> 
> Hello,
> 
> can anyone tell me if R has any special function for simulating the structure 
> of human populations? Something like the genetic algorithm?
> I need to simulate a sample of a population with a specific structure. Is 
> there something on R that can help me?

Please be more specific, what you want: What type of model or which 
state variables do you want to simulate? Differential equations, age 
stucture (Leslie matrix model) discrete event simulations of stochastic 
subsamples (individuals) ...

BTW genetic algorithms are commonly used to solve optimization problems 
and (at least in most cases) not for population models.

Thomas P.



From spencer.graves at pdf.com  Sat Jul 24 18:39:51 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 24 Jul 2004 09:39:51 -0700
Subject: [R] Population simulation.
In-Reply-To: <4102871D.5060106@hhbio.wasser.tu-dresden.de>
References: <1090683523.4102828339ae3@webmail1.portugalmail.pt>
	<4102871D.5060106@hhbio.wasser.tu-dresden.de>
Message-ID: <410290D7.9020702@pdf.com>

      Unless your problem is so trivial it could easily be done in 
Excel, R may well be the best platform available for such simulations, 
with its object orientation, class definitions, etc.  However, as Thomas 
just said, we would need more information to be able to help further. 

      Have you contacted a listserve with the Bioconductor project 
(http://www.bioconductor.org/)?  That uses R and is specifically devoted 
to bio-whatever.  You might find help there that is more closely 
connected to your interests. 

      hope this helps.  spencer graves
p.s.  PLEASE do read the posting guide! 
"http://www.R-project.org/posting-guide.html".  It could help you 
formulate your question so you get a better response. 

Thomas Petzoldt wrote:

> assuncao.senra at portugalmail.com wrote:
>
>>
>> Hello,
>>
>> can anyone tell me if R has any special function for simulating the 
>> structure of human populations? Something like the genetic algorithm?
>> I need to simulate a sample of a population with a specific 
>> structure. Is there something on R that can help me?
>
>
> Please be more specific, what you want: What type of model or which 
> state variables do you want to simulate? Differential equations, age 
> stucture (Leslie matrix model) discrete event simulations of 
> stochastic subsamples (individuals) ...
>
> BTW genetic algorithms are commonly used to solve optimization 
> problems and (at least in most cases) not for population models.
>
> Thomas P.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Sat Jul 24 19:06:02 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 24 Jul 2004 10:06:02 -0700
Subject: [R] help(package)->sink()
Message-ID: <410296FA.1020905@pdf.com>

      I wanted to direct packageInfo to a file, so I could add comments, 
e.g., in MS Word.  The following command stored the desired information 
in an object: 

      mclustInfo <- help(package="mclust")

      Then "mclustInfo" displays it on my screen.  To direct it to a 
file, I tried the following: 

      sink("mclust.txt")
      mclustInfo
      sink()

      This sequence created an empty file "mclust.txt", while displaying 
mclustInfo on my screen.  After a few more failed attempts, I gave up 
trying to be clever and copied the text from the screen into Word. 

      Is this a bug, that sink does not capture the output of objects of 
class packageInfo? 

      Best Wishes,
      spencer graves



From tlumley at u.washington.edu  Sat Jul 24 19:21:37 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 24 Jul 2004 10:21:37 -0700 (PDT)
Subject: [R] gcc on AIX is not compatile with R-1.9.1
In-Reply-To: <291B348BC59B47468C7824603C3260829460B7@cmail3.central.cmich.local>
References: <291B348BC59B47468C7824603C3260829460B7@cmail3.central.cmich.local>
Message-ID: <Pine.A41.4.58.0407241020430.36542@homer10.u.washington.edu>

On Thu, 22 Jul 2004, Liao, Kexiao wrote:

> Hi Uwe Liqqes,
>    Does the successful compilation for R-1.9.1 on AIX 5.1 depend on the
> IBM AIX compiler for C and C++ (xlc/xlC)? gcc on AIX is not compatible
> with R1.9.1.

Are you using g77 or IBM's Fortran?  In the past I found that gcc was not
compatible with the IBM fortran compiler, but was compatible with g77 on
AIX.

	-thomas

>
> Kexiao
>
>
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: Sunday, July 18, 2004 8:19 AM
> To: Liao, Kexiao
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Install R on AIX 5.2 64 Bit
>
> Liao, Kexiao wrote:
>
> > Hi your guys,
> >
> >     Recently, I installed R-1.9.1 on AIX 5.2 with 64 bits environment;
> I
> > already have following software installed on AIX before I compile
> > R-1.9.1 source codes:
> >
> >
> >
> > g++ 2.9.aix51.020209-4  The GNU C++ compiler and headers
> >
> > gcc 2.9.aix51.020209-4  The GNU gcc C compiler and headers
> >
> > xlf  XL   Fortran for AIX
> >
> > perl 5.6.1-2
> >
> > zlib 1.1.3-10
> >
> >
> >
> >    For latex and makeinfo stuffs, I have not found from my AIX 5.2
> P690
> > system.
> >
> >
> >
> >  After I run the following command:
> >
> > configure
> >
> > make
> >
>
> What about "make check"? And thereafter "make install"?
>
> >
> > Following executable binaries codes have been generated in RHOME/bin
> > directory:
> >
> >
> >
> > bash-2.05b$ ls -al
> >
>
> [SNIP]
>
> > bash-2.05b$ pwd
> >
> > /home/liao1k/r-1.9.1/R-1.9.1/bin
> >
> > bash-2.05b$
> >
> >
> > However if I run R command, I got following error message:
> >
> > bash-2.05b$ ./R
> >
> > Fatal error: unable to open the base package
>
> So either you don't have permission to read .../library/base/...
> or compilation was not successful and the package(s) have not been
> created.
> Please tell us the error messages which appeared during compilation, and
>
> try running make check, if there were no error messages....
>
> Uwe Ligges
>
>
> >
> >   Can any one give me some advice? Thanks in advance!
> >
> >
> >
> > Kexiao
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Sat Jul 24 19:36:14 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 24 Jul 2004 10:36:14 -0700 (PDT)
Subject: [R] Porting plotterm() & gamterms() from s-plus
In-Reply-To: <C91DF477A51618409DB4B2FC262215DE81A522@iwhmail01.iwh.on.ca>
References: <C91DF477A51618409DB4B2FC262215DE81A522@iwhmail01.iwh.on.ca>
Message-ID: <Pine.A41.4.58.0407241035060.36542@homer10.u.washington.edu>

On Fri, 23 Jul 2004, Jacob Etches wrote:

> I'm trying to plot pspline'd explanatory variables from coxph() models as per Therneau and Grambsch (Modeling Survival Data: Extending the Cox Model).  They have s-plus functions for this at:
>
> http://www.mayo.edu/hsr/people/therneau/book/sfunction/gamterms.s
> http://www.mayo.edu/hsr/people/therneau/book/sfunction/plotterm.s
>
> I'd like to make these plots in R, but they make use of non-R functions,
> and I'm not sure how to adapt gamterms and plotterm to R.  Have others
> done this, or does anyone have advice?

The termplot() function in R can already handle pspline() terms.

	-thomas



From tlumley at u.washington.edu  Sat Jul 24 19:39:34 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 24 Jul 2004 10:39:34 -0700 (PDT)
Subject: [R] Complex Surveys...Specifying Design
In-Reply-To: <20040723194902.6d48ceba.tobias_verbeke@skynet.be>
References: <6BCD3F430455B1418750004BCD2792590286B141@exchange2.ahrq.gov>
	<20040723194902.6d48ceba.tobias_verbeke@skynet.be>
Message-ID: <Pine.A41.4.58.0407241038150.36542@homer10.u.washington.edu>

On Fri, 23 Jul 2004, Tobias Verbeke wrote:

> I guess the most common way of proceeding is to first stratify,
> and then to sample clusters independently within each stratum.
> If this is the case, your data file can be put together like
>
> stratum		psu	...
> 1		1
> 1		2
> 1		3
> 2		1
> 2		2
> 2		3
>
> or like
>
> stratum		psu	...
> 1		1
> 1		2
> 1		3
> 2		4
> 2		5
> 2		6
>
> svydesign only likes the first data structure so

This is exactly backwards. svydesign by default assumes the *second* data
structure.


>
> meps.design <- svydesign(ids = ~varpsu01, strata = ~varstr01,
> 	weights = ~perwt01f, nest = TRUE, data = h60)
>
> should work. See ?svydesign.

This fix is correct, even if the rationale is backwards.

	-thomas



From tlumley at u.washington.edu  Sat Jul 24 19:44:35 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 24 Jul 2004 10:44:35 -0700 (PDT)
Subject: [R] help(package)->sink()
In-Reply-To: <410296FA.1020905@pdf.com>
References: <410296FA.1020905@pdf.com>
Message-ID: <Pine.A41.4.58.0407241041370.36542@homer10.u.washington.edu>

On Sat, 24 Jul 2004, Spencer Graves wrote:

>       I wanted to direct packageInfo to a file, so I could add comments,
> e.g., in MS Word.  The following command stored the desired information
> in an object:
>
>       mclustInfo <- help(package="mclust")
>
>       Then "mclustInfo" displays it on my screen.  To direct it to a
> file, I tried the following:
>
>       sink("mclust.txt")
>       mclustInfo
>       sink()
>
>       This sequence created an empty file "mclust.txt", while displaying
> mclustInfo on my screen.  After a few more failed attempts, I gave up
> trying to be clever and copied the text from the screen into Word.
>
>       Is this a bug, that sink does not capture the output of objects of
> class packageInfo?
>

Not really.  The output doesn't really appear on your screen, it appears
on your pager.  In your case the pager is the screen, so this isn't
obvious.


	-thomas



From murdoch at stats.uwo.ca  Sat Jul 24 19:57:58 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 24 Jul 2004 13:57:58 -0400
Subject: [R] help(package)->sink()
In-Reply-To: <410296FA.1020905@pdf.com>
References: <410296FA.1020905@pdf.com>
Message-ID: <eb85g09c3l20a17r2arun48h30l5e5d4vh@4ax.com>

On Sat, 24 Jul 2004 10:06:02 -0700, Spencer Graves
<spencer.graves at pdf.com> wrote:

>      I wanted to direct packageInfo to a file, so I could add comments, 
>e.g., in MS Word.  The following command stored the desired information 
>in an object: 
>
>      mclustInfo <- help(package="mclust")
>
>      Then "mclustInfo" displays it on my screen.  To direct it to a 
>file, I tried the following: 
>
>      sink("mclust.txt")
>      mclustInfo
>      sink()
>
>      This sequence created an empty file "mclust.txt", while displaying 
>mclustInfo on my screen.  After a few more failed attempts, I gave up 
>trying to be clever and copied the text from the screen into Word. 
>
>      Is this a bug, that sink does not capture the output of objects of 
>class packageInfo? 

I don't think so.  The print method for that class calls other code to
display it; it doesn't go through the regular "display to console"
route.  Instead, it writes the help page to a file, then calls
file.show.  

It's possible that on some systems file.show would just dump the file
to the console, but that's not what happens on Windows, for example.

Duncan Murdoch



From ggrothendieck at myway.com  Sat Jul 24 20:21:55 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 24 Jul 2004 18:21:55 +0000 (UTC)
Subject: [R] help(package)->sink()
References: <410296FA.1020905@pdf.com>
Message-ID: <loom.20040724T200639-687@post.gmane.org>

Spencer Graves <spencer.graves <at> pdf.com> writes:

: 
: I wanted to direct packageInfo to a file, so I could add comments, 
: e.g., in MS Word.  The following command stored the desired information 
: in an object: 
: 
:       mclustInfo <- help(package="mclust")
: 
:       Then "mclustInfo" displays it on my screen.  To direct it to a 
: file, I tried the following: 
: 
:       sink("mclust.txt")
:       mclustInfo
:       sink()
: 
:       This sequence created an empty file "mclust.txt", while displaying 
: mclustInfo on my screen.  After a few more failed attempts, I gave up 
: trying to be clever and copied the text from the screen into Word. 

In addition to your copy and paste solution:

1. You could intercept the file.show output by redefining the pager:

   a. create a one line file called mypager.bat in \ with this line:

      type %1 > /mclust.txt

   (with appropriate modifications if you are using UNIX).

   b. In R issue these commands:

      old <- options()
      options(pager = "/mypager.bat")
      help(package = "mclust")
      options(old) # reset options back if finished

2. Don't use R but go right to the DESCRIPTION and INDEX
   files.  getwd("library/mclust") should show you where
   to find them.

3. If you don't care about the formatting:

      sink("/mclust.txt")
      writeLines(unlist(help(package="mclust")$info))
      sink()

4. You could modify packageInfo.print adding a file= argument.



From spencer.graves at pdf.com  Sun Jul 25 02:47:17 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 24 Jul 2004 17:47:17 -0700
Subject: [R] help(package)->sink()
In-Reply-To: <loom.20040724T200639-687@post.gmane.org>
References: <410296FA.1020905@pdf.com>
	<loom.20040724T200639-687@post.gmane.org>
Message-ID: <41030315.1010505@pdf.com>

      Thanks to Tom Lumley and Duncan Murdoch for explaining that this 
was a feature not a bug and to Gabor Grothendieck for providing several 
ways to get around the problem.  (Please excuse, Gabor:  I should have 
said I was using R 1.9.1 under Windows 2000.) 

      1.  I failed to make method 1 work, though I've done that kind of 
thing in the past, and I believe I could make it work if I had to. 
    
      2.  I found the DESCRIPTION and INDEX files.  Thanks much.  That 
not only answers this immediate question, it help me understand how R 
packages are structured, which will help me solve many related problems 
in the future. 

      3.  Before I sent the email, I tried dump("mclustInfo", 
"mclust.txt").  That worked, but I did not like the formatting.  I 
should have reported that in my email. 

      4.  A request for "packageInfo.print" returned "object ... not 
found".  A request for class(mclustInfo) confirmed that it was a 
packageInfo object, so I tried getMethod("print",  "packageInfo");   I 
got, 'No generic function defined for "print"'.  Then I tried, 
getMethod("show", "packageInfo");  I got, 'No method defined for 
function "show" and signature object = "packageInfo"'. 

      Anyway, I now have more than one method that works. 
      thanks again.  spencer graves

Gabor Grothendieck wrote:

>Spencer Graves <spencer.graves <at> pdf.com> writes:
>
>: 
>: I wanted to direct packageInfo to a file, so I could add comments, 
>: e.g., in MS Word.  The following command stored the desired information 
>: in an object: 
>: 
>:       mclustInfo <- help(package="mclust")
>: 
>:       Then "mclustInfo" displays it on my screen.  To direct it to a 
>: file, I tried the following: 
>: 
>:       sink("mclust.txt")
>:       mclustInfo
>:       sink()
>: 
>:       This sequence created an empty file "mclust.txt", while displaying 
>: mclustInfo on my screen.  After a few more failed attempts, I gave up 
>: trying to be clever and copied the text from the screen into Word. 
>
>In addition to your copy and paste solution:
>
>1. You could intercept the file.show output by redefining the pager:
>
>   a. create a one line file called mypager.bat in \ with this line:
>
>      type %1 > /mclust.txt
>
>   (with appropriate modifications if you are using UNIX).
>
>   b. In R issue these commands:
>
>      old <- options()
>      options(pager = "/mypager.bat")
>      help(package = "mclust")
>      options(old) # reset options back if finished
>
>2. Don't use R but go right to the DESCRIPTION and INDEX
>   files.  getwd("library/mclust") should show you where
>   to find them.
>
>3. If you don't care about the formatting:
>
>      sink("/mclust.txt")
>      writeLines(unlist(help(package="mclust")$info))
>      sink()
>
>4. You could modify packageInfo.print adding a file= argument.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From quesada at gmail.com  Sun Jul 25 03:57:37 2004
From: quesada at gmail.com (Jose Quesada)
Date: Sat, 24 Jul 2004 21:57:37 -0400
Subject: [R] R on AMD64 (Opteron)
In-Reply-To: <21c05c7d040724093548dbaa00@mail.gmail.com>
References: <1362e4130cf3.130cf31362e4@uidaho.edu>
	<21c05c7d040724093548dbaa00@mail.gmail.com>
Message-ID: <21c05c7d0407241857cf46ef8@mail.gmail.com>

Also, I'm curious...
Not that this would be my first choice for a server, but...
Anyone running Windows XP 64-Bit Edition? Any success compiling R?



On Sat, 24 Jul 2004 18:07:18 +1000, Andrew Robinson <andrewr at uidaho.edu> wrote:
> Professor Ripley,
>
> which operating system are you using for these servers, please?
> Thanks,
>
> Andrew
>
>
>
> ----- Original Message -----
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Date: Saturday, July 24, 2004 5:41 pm
> Subject: Re: [R] R on AMD64 (Opteron)
>
> > On Fri, 23 Jul 2004, Asselin Jerome wrote:
> >
> > > Hi,
> > >
> > > I was wondering if anyone has had good experiences using R on
> > Linux with
> > > dual AMD64 (Opteron) processors. I'm thinking of buying a couple
> > of such
> > > servers, but I'd like to make sure R would work fine.
> > >
> > > The "R Installation and Administration" guide notes that there
> > may be
> > > some problems with BLAS libraries. That's all I could find about
> > R on
> > > AMD64.
> >
> > Actually it says with ATLAS BLAS, not generically.
> >
> > > Please share your experience using R on AMD64.
> >
> > Quite a few people, including us, are using R on such servers
> > routinelywith no problems at all.  There are still some issues
> > about how to squeeze
> > the maximum performance out of them (e.g. which BLAS to use -- we
> > are
> > using Goto's -- and which compiler to use, e.g. Portland Group or
> > Intel).
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-
> > guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Jose Quesada, PhD.

jquesada at andrew.cmu.edu         Research associate
http://lsa.colorado.edu/~quesadaj       Dept. of Social and Decision Sciences
http://www.andrew.cmu.edu/~jquesada     Carnegie Mellon University
Porter Hall     Phone: 412 268 6011
office PH208-J  Fax:   412 268 6938
5000 Forbes ave.
15213, Pittsburgh, PA



-- 
* I have finally put online an exhibition project with my newer paintings *
http://lsa.colorado.edu/~quesadaj/CMUexhibitionProject/

Jose Quesada, PhD.
 
jquesada at andrew.cmu.edu		Research associate
http://lsa.colorado.edu/~quesadaj	Dept. of Social and Decision Sciences
http://www.andrew.cmu.edu/~jquesada	Carnegie Mellon University
Porter Hall	Phone: 412 268 6011
office PH208-J	Fax:   412 268 6938
5000 Forbes ave.
15213, Pittsburgh, PA



From ggrothendieck at myway.com  Sun Jul 25 06:25:49 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 25 Jul 2004 04:25:49 +0000 (UTC)
Subject: [R] help(package)->sink()
References: <410296FA.1020905@pdf.com>
	<loom.20040724T200639-687@post.gmane.org>
	<41030315.1010505@pdf.com>
Message-ID: <loom.20040725T061713-464@post.gmane.org>

Spencer Graves <spencer.graves <at> pdf.com> writes:

:       1.  I failed to make method 1 work, though I've done that kind of 
: thing in the past, and I believe I could make it work if I had to. 
: 

I am using R 1.9.1 patched on Windows XP and at least there it seems
to work.  I did notice that I put a forward slash in the type statement
whereas I meant a backward slash although the forward slash worked anyways,
at least on my system.  Here is the output of an R session:

R> readLines("/mypager.bat")  # check content of mypager.bat file
[1] "type %1 > /myfile.txt"
R> old <- options()
R> options(pager = "/mypager.bat")
R> help(package = "mclust")
R> options(old) # reset options back if finished
R> head(readLines("/myfile.txt"))  # check 1st few lines of myfile.txt
[1] ""                                  "               Information on 
Package 'mclust'"
[3] ""                                  "Description:"                     
[5] ""                                  "Package: mclust"                  
R> R.version.string
[1] "R version 1.9.1, 2004-07-13"

:       4.  A request for "packageInfo.print" returned "object ... not 
: found".  A request for class(mclustInfo) confirmed that it was a 
: packageInfo object, so I tried getMethod("print",  "packageInfo");   I 
: got, 'No generic function defined for "print"'.  Then I tried, 
: getMethod("show", "packageInfo");  I got, 'No method defined for 
: function "show" and signature object = "packageInfo"'. 

Sorry about that.  I should have written print.packageInfo  since
the syntax of these things is genericmethod.class and print is the 
generic method and packageInfo is the class.

 
: Gabor Grothendieck wrote:
: 
: >Spencer Graves <spencer.graves <at> pdf.com> writes:
: >
: >: 
: >: I wanted to direct packageInfo to a file, so I could add comments, 
: >: e.g., in MS Word.  The following command stored the desired information 
: >: in an object: 
: >: 
: >:       mclustInfo <- help(package="mclust")
: >: 
: >:       Then "mclustInfo" displays it on my screen.  To direct it to a 
: >: file, I tried the following: 
: >: 
: >:       sink("mclust.txt")
: >:       mclustInfo
: >:       sink()
: >: 
: >:       This sequence created an empty file "mclust.txt", while displaying 
: >: mclustInfo on my screen.  After a few more failed attempts, I gave up 
: >: trying to be clever and copied the text from the screen into Word. 
: >
: >In addition to your copy and paste solution:
: >
: >1. You could intercept the file.show output by redefining the pager:
: >
: >   a. create a one line file called mypager.bat in \ with this line:
: >
: >      type %1 > /mclust.txt
: >
: >   (with appropriate modifications if you are using UNIX).
: >
: >   b. In R issue these commands:
: >
: >      old <- options()
: >      options(pager = "/mypager.bat")
: >      help(package = "mclust")
: >      options(old) # reset options back if finished
: >
: >2. Don't use R but go right to the DESCRIPTION and INDEX
: >   files.  getwd("library/mclust") should show you where
: >   to find them.
: >
: >3. If you don't care about the formatting:
: >
: >      sink("/mclust.txt")
: >      writeLines(unlist(help(package="mclust")$info))
: >      sink()
: >
: >4. You could modify packageInfo.print adding a file= argument.
: >
: >______________________________________________
: >R-help <at> stat.math.ethz.ch mailing list
: >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: >PLEASE do read the posting guide! http://www.R-project.org/posting-
guide.html
: >  
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From aolinto_r at bignet.com.br  Sun Jul 25 06:32:23 2004
From: aolinto_r at bignet.com.br (Antonio Olinto)
Date: Sun, 25 Jul 2004 01:32:23 -0300
Subject: [R] using ylab=expression()
Message-ID: <1090729943.410337d7e50fe@webmail2.bignet.com.br>

Hi,

A question about expression()

In a plot

ylab=expression(log(C["L,L+1"] *Delta* t)) works

ylab=expression(log(C["L,L+1"] %/% t)) also works

but

ylab=expression(log(C["L,L+1"] %/% *Delta* t)) does not work?

What I'm missing? Which would be the proper sintaxe?

Thanks for any help. Sincerely,

Antonio Olinto


-------------------------------------------------
WebMail Bignet - O seu provedor do litoral
www.bignet.com.br



From ggrothendieck at myway.com  Sun Jul 25 06:44:41 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 25 Jul 2004 04:44:41 +0000 (UTC)
Subject: [R] using ylab=expression()
References: <1090729943.410337d7e50fe@webmail2.bignet.com.br>
Message-ID: <loom.20040725T064343-388@post.gmane.org>

Antonio Olinto <aolinto_r <at> bignet.com.br> writes:

: 
: Hi,
: 
: A question about expression()
: 
: In a plot
: 
: ylab=expression(log(C["L,L+1"] *Delta* t)) works
: 
: ylab=expression(log(C["L,L+1"] %/% t)) also works
: 
: but
: 
: ylab=expression(log(C["L,L+1"] %/% *Delta* t)) does not work?
: 
: What I'm missing? Which would be the proper sintaxe?

You have two operators %/% and * in a row.  Remove the * like this:

   ylab=expression(log(C["L,L+1"] %/% Delta* t))



From allanba at verizon.net  Sun Jul 25 15:36:48 2004
From: allanba at verizon.net (Allan W. Bart, Jr.)
Date: Sun, 25 Jul 2004 06:36:48 -0700
Subject: [R] Econometrics Packages On R
Message-ID: <4103B770.10308@verizon.net>

Hello,

I have just started using R, maybe more like learning it. I am 
interested in using it for Time Series Analysis and I wanted to know if 
anyone was familiar with packages other than TS that might be appropriate.

Allan



From Hagen.Schmoeller at iaew.rwth-aachen.de  Sun Jul 25 16:10:29 2004
From: Hagen.Schmoeller at iaew.rwth-aachen.de (=?iso-8859-1?Q?Hagen_Schm=F6ller?=)
Date: Sun, 25 Jul 2004 16:10:29 +0200
Subject: [R] Multivariate ARMA Model
Message-ID: <000001c47251$245eb340$5c6a8286@iaew.rwthaachen.de>

Hi R-Community,

so far I dealt with univariate processes and used the function "arima" to
estimate an ARMA(1,1)-model. For multivariate processes there are the
functions "estVARXar" and "estVARXls" from package "DSE". But how can I
estimate an VARMA(1,1)-model, or even better determine the orders and
estimate the parameters?

Much thanks in advance,

Hagen Schmoeller
--
Dipl.-Ing. Hagen K. Schm??ller
Leiter Forschungsgruppe Stromerzeugung und -handel
Institut f??r Elektrische Anlagen und Energiewirtschaft, RWTH Aachen
Schinkelstra??e 6, D-52056 Aachen, Germany
Tel.: +49 (0)241 80-96734
Fax : +49 (0)241 80-92197
Hagen.Schmoeller at iaew.rwth-aachen.de



From spencer.graves at pdf.com  Sun Jul 25 17:16:11 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 25 Jul 2004 08:16:11 -0700
Subject: [R] help(package)->sink()
In-Reply-To: <loom.20040725T061713-464@post.gmane.org>
References: <410296FA.1020905@pdf.com>	<loom.20040724T200639-687@post.gmane.org>	<41030315.1010505@pdf.com>
	<loom.20040725T061713-464@post.gmane.org>
Message-ID: <4103CEBB.6010408@pdf.com>

Hi, Gabor: 

      1.  Thanks.  I failed to put "mypager.bat" in "/".  After I moved 
it, I get the following: 

 > readLines("/mypager.bat")
[1] "type %1 > /mclust.txt"
 > old <- options()
 > options(pager = "/mypager.bat")
 > help(package = "mclust")
 > options(old) # reset options back if finished
 > head(readLines("/myfile.txt")) 
Error in file(con, "r") : unable to open connection
In addition: Warning message:
cannot open file `/myfile.txt'

      While R couldn't find the file, it was there, and contained all 
the necessary information. 

      4.  Thanks for the tip on print.packageInfo:  It worked.  [On 
other occasions, I've done things like this routinely.  I got 
sidetracked with the S4 search and frustrated with my failure to get 
much out of that, with the result that I failed to see the obvious.]

      Vielen Dank noch einmal
      spencer graves

Gabor Grothendieck wrote:

>Spencer Graves <spencer.graves <at> pdf.com> writes:
>
>:       1.  I failed to make method 1 work, though I've done that kind of 
>: thing in the past, and I believe I could make it work if I had to. 
>: 
>
>I am using R 1.9.1 patched on Windows XP and at least there it seems
>to work.  I did notice that I put a forward slash in the type statement
>whereas I meant a backward slash although the forward slash worked anyways,
>at least on my system.  Here is the output of an R session:
>
>R> readLines("/mypager.bat")  # check content of mypager.bat file
>[1] "type %1 > /myfile.txt"
>R> old <- options()
>R> options(pager = "/mypager.bat")
>R> help(package = "mclust")
>R> options(old) # reset options back if finished
>R> head(readLines("/myfile.txt"))  # check 1st few lines of myfile.txt
>[1] ""                                  "               Information on 
>Package 'mclust'"
>[3] ""                                  "Description:"                     
>[5] ""                                  "Package: mclust"                  
>R> R.version.string
>[1] "R version 1.9.1, 2004-07-13"
>
>:       4.  A request for "packageInfo.print" returned "object ... not 
>: found".  A request for class(mclustInfo) confirmed that it was a 
>: packageInfo object, so I tried getMethod("print",  "packageInfo");   I 
>: got, 'No generic function defined for "print"'.  Then I tried, 
>: getMethod("show", "packageInfo");  I got, 'No method defined for 
>: function "show" and signature object = "packageInfo"'. 
>
>Sorry about that.  I should have written print.packageInfo  since
>the syntax of these things is genericmethod.class and print is the 
>generic method and packageInfo is the class.
>
> 
>: Gabor Grothendieck wrote:
>: 
>: >Spencer Graves <spencer.graves <at> pdf.com> writes:
>: >
>: >: 
>: >: I wanted to direct packageInfo to a file, so I could add comments, 
>: >: e.g., in MS Word.  The following command stored the desired information 
>: >: in an object: 
>: >: 
>: >:       mclustInfo <- help(package="mclust")
>: >: 
>: >:       Then "mclustInfo" displays it on my screen.  To direct it to a 
>: >: file, I tried the following: 
>: >: 
>: >:       sink("mclust.txt")
>: >:       mclustInfo
>: >:       sink()
>: >: 
>: >:       This sequence created an empty file "mclust.txt", while displaying 
>: >: mclustInfo on my screen.  After a few more failed attempts, I gave up 
>: >: trying to be clever and copied the text from the screen into Word. 
>: >
>: >In addition to your copy and paste solution:
>: >
>: >1. You could intercept the file.show output by redefining the pager:
>: >
>: >   a. create a one line file called mypager.bat in \ with this line:
>: >
>: >      type %1 > /mclust.txt
>: >
>: >   (with appropriate modifications if you are using UNIX).
>: >
>: >   b. In R issue these commands:
>: >
>: >      old <- options()
>: >      options(pager = "/mypager.bat")
>: >      help(package = "mclust")
>: >      options(old) # reset options back if finished
>: >
>: >2. Don't use R but go right to the DESCRIPTION and INDEX
>: >   files.  getwd("library/mclust") should show you where
>: >   to find them.
>: >
>: >3. If you don't care about the formatting:
>: >
>: >      sink("/mclust.txt")
>: >      writeLines(unlist(help(package="mclust")$info))
>: >      sink()
>: >
>: >4. You could modify packageInfo.print adding a file= argument.
>: >
>: >______________________________________________
>: >R-help <at> stat.math.ethz.ch mailing list
>: >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>: >PLEASE do read the posting guide! http://www.R-project.org/posting-
>guide.html
>: >  
>: >
>: 
>: ______________________________________________
>: R-help <at> stat.math.ethz.ch mailing list
>: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>: 
>:
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Sun Jul 25 17:40:03 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 25 Jul 2004 08:40:03 -0700
Subject: [R] Econometrics Packages On R
In-Reply-To: <4103B770.10308@verizon.net>
References: <4103B770.10308@verizon.net>
Message-ID: <4103D453.3040602@pdf.com>

      There are several.  From "www.r-project.org" -> search -> R site 
search -> "econometrics", I got 181 hits;  for "econometrics package", I 
got 91 hits.  May of those may not interest you.  However, I would think 
that enough might be of interest that it might be worth skimming at 
least the first 30 if you haven't already.  I just found packages 
"spdep" for "Spatial simultaneous autoregressive error model 
estimation", "sna" for "social network analysis", and "tseries" with a 
"garch" function.  There are more, and not all that you find will be 
currently available from CRAN:  Some would not run automatically under 
all platforms and so have been removed. 

      However, I have "dse1" and "dse2" running on my machine for 
"dynamic systems estimation", and I believe a search for "irregular time 
series" should produce many references to tools that are currently 
available.  (Even tools not currently dowloadable from CRAN may still be 
available from the contributors, and may work on your machine.  
Moreover, the parts that don't work may not interest you, and if they 
do, you might easily be able to fix them.) 

      hope this helps. 
p.s. PLEASE do read the posting guide! 
"http://www.R-project.org/posting-guide.html".  It can help you answer 
many questions for yourself.  Moreover, when you do submit a question, 
following these steps can increase the expected information content of 
replies. 

Allan W. Bart, Jr. wrote:

> Hello,
>
> I have just started using R, maybe more like learning it. I am 
> interested in using it for Time Series Analysis and I wanted to know 
> if anyone was familiar with packages other than TS that might be 
> appropriate.
>
> Allan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Sun Jul 25 18:22:04 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Jul 2004 18:22:04 +0200
Subject: [R] interpreting profiling output
In-Reply-To: <wqroemflo3m.fsf@biostat.ku.dk>
References: <wqroemflo3m.fsf@biostat.ku.dk>
Message-ID: <x2acxo5a6r.fsf@biostat.ku.dk>

Kasper Daniel Hansen <k.hansen at biostat.ku.dk> writes:

> I have some trouble interpreting the output from profiling. I have
> read the help pages Rprof, summaryRprof and consult the R extensions
> manual, but I still have problems understanding the output.
> 
> Basically the output consist of self.time and total.time. I have the
> understanding that total.time is the time spent in a given function
> including any subcalls or child functions or whatever the technical
> term for that activity is. In contrasts self.time is the time spent in
> the function excluding subcalls.
> 
> Now, in my understanding basically everything in R is functions. I
> would then guess that for almost any function (except the "atomic
> ones") the self.time would be very small as it would spend most of its
> time calling other functions (again, since almost everything is a
> function). So how do R determine when a subfunction is called?
...brutal snippage...
> I guess some of the answers would be clear if I had a firm grasp of
> the inner workings of R :)

In a word, yes... 

The profiling keeps track of R's *context stack* which is not quite
the same as function calls. Essentially, it only counts R functions that
are actually written in R, but not .Internal, .Primitive, etc. So
"self" counts the amount of time that a function was at the top of the
stack. This is done by a periodic poll which dumps out the context
stack at regular intervals. Seeing cases where the self percentages
don't add to 100% is, I believe, simply due to truncation of the tails
-- that is, there is a large number of different functions which each
are counted a few times, and these are not shown in the summary output.

[Sorry about the late reply, but I was out of town, and noone seems to
have answered this.]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Sun Jul 25 18:40:06 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Jul 2004 18:40:06 +0200
Subject: [R] Multiple comparisons: its a trap!
In-Reply-To: <40FCE105.1060702@lancaster.ac.uk>
References: <3A822319EB35174CA3714066D590DCD504AF8095@usrymx25.merck.com>
	<40FCE105.1060702@lancaster.ac.uk>
Message-ID: <x2658c59cp.fsf@biostat.ku.dk>

Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:

> Liaw, Andy wrote:
> > Stupid me: fell into this trap:
> >
> >>0 == 0 == 0
> > [1] FALSE
> >
> 
>   Ouch!
> 
>   Python's comparison operators don't have this trap, since they
> unravel each comparison pair in a chain so that:
> 
>    (A op1 B op2 C)
> 
> becomes:
> 
>    (A op1 B) and (B op2 C)

[chop]

>   Of course old hand Fortran programmers understand all this since the
> second thing they learnt (after learning how to tap the space bar six
> times) was the order of precedence of operators...

SAS does likewise, at least in recent versions. Whether this kind of
syntactical exceptions is actually helpful is debatable. The problem
is that you get to teach people that comparisons are binary operators
except when they are not... 

I wonder how Python actually manages this; doesn't look like something
that is easy to implement in a yacc-style parser.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Sun Jul 25 18:52:28 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Jul 2004 18:52:28 +0200
Subject: [R] Installing rgl on linux
In-Reply-To: <1090317258.8805.16.camel@pear.local>
References: <1090317258.8805.16.camel@pear.local>
Message-ID: <x21xj058s3.fsf@biostat.ku.dk>

Georg von Graevenitz <gvg at vwl.wi.tu-muenchen.de> writes:

> I have attempted to install rgl form within R and from a shell using the
> tarball (rgl_0.64-13.tar.gz). I attach the output for both attempts
> below.
[chop]

> In file included from glgui.h:9,
>                  from gui.h:10,
>                  from x11gui.h:10,
>                  from x11lib.cpp:13:
> opengl.h:19:19: GL/gl.h: No such file or directory
> opengl.h:20:20: GL/glu.h: No such file or directory

This is the problem. rgl needs to work with (surprise) GL libraries
and include files. With SuSE 9.0 the thing you need is

> rpm -qf /usr/include/GL/gl.h
XFree86-Mesa-devel-4.3.0.1-33

and later on 

XFree86-Mesa-4.3.0.1-33

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Sun Jul 25 19:12:41 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Jul 2004 19:12:41 +0200
Subject: [R] R on AMD64 (Opteron)
In-Reply-To: <21c05c7d0407241857cf46ef8@mail.gmail.com>
References: <1362e4130cf3.130cf31362e4@uidaho.edu>
	<21c05c7d040724093548dbaa00@mail.gmail.com>
	<21c05c7d0407241857cf46ef8@mail.gmail.com>
Message-ID: <x2wu0s3t9y.fsf@biostat.ku.dk>

Jose Quesada <quesada at gmail.com> writes:

> Also, I'm curious...
> Not that this would be my first choice for a server, but...
> Anyone running Windows XP 64-Bit Edition? Any success compiling R?

As far as I know, the absense of a mingw64 toolkit precludes it at
this point.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Sun Jul 25 19:15:30 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 25 Jul 2004 13:15:30 -0400 (EDT)
Subject: [R] Multiple comparisons: its a trap!
Message-ID: <20040725171530.42782394F@mprdmxin.myway.com>



Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
> 
> Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:
> 
> > Liaw, Andy wrote:
> > > Stupid me: fell into this trap:
> > >
> > >>0 == 0 == 0
> > > [1] FALSE
> > >
> >
> > Ouch!
> >
> > Python's comparison operators don't have this trap, since they
> > unravel each comparison pair in a chain so that:
> >
> > (A op1 B op2 C)
> >
> > becomes:
> >
> > (A op1 B) and (B op2 C)
> 
> [chop]
> 
> > Of course old hand Fortran programmers understand all this since the
> > second thing they learnt (after learning how to tap the space bar six
> > times) was the order of precedence of operators...
> 
> SAS does likewise, at least in recent versions. Whether this kind of
> syntactical exceptions is actually helpful is debatable. The problem
> is that you get to teach people that comparisons are binary operators
> except when they are not...
> 
> I wonder how Python actually manages this; doesn't look like something
> that is easy to implement in a yacc-style parser.

Don't know how Python does it but its not the only one and I believe its
often done like this.   Rather than have a Boolean type, NULL is defined
to be false and anything else is true.  If the comparison is TRUE then
the right argument is returned; otherwise NULL is returned.

Thus

	3 < 5 < 6
	==> (3 < 5) < 6
	==> 5 < 6
	==> 6

which is interpreted as TRUE in if statements, etc.  

Note that the 5 is only evaluated once in the above whereas in

        (3 < 5) and (5 < 6)

it would evaluated twice -- not important here but if 5 is replaced
by a function with side effects then it matters.



From edd at debian.org  Sun Jul 25 19:29:16 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 25 Jul 2004 12:29:16 -0500
Subject: [R] Econometrics Packages On R
In-Reply-To: <4103B770.10308@verizon.net>
References: <4103B770.10308@verizon.net>
Message-ID: <20040725172916.GA21098@sonny.eddelbuettel.com>

On Sun, Jul 25, 2004 at 06:36:48AM -0700, Allan W. Bart, Jr. wrote:
> I have just started using R, maybe more like learning it. I am 
> interested in using it for Time Series Analysis and I wanted to know if 
> anyone was familiar with packages other than TS that might be appropriate.

Ajay Shah has a helpful pages 'R for Economists' that maps R packages to
the usage terms employed by Economists / Econometricians:

http://www.mayin.org/ajayshah/KB/R/R_for_economists.html

As that currently times out, here is the Google cache as well

http://64.233.161.104/search?q=cache:qfwQtC9FqGMJ:www.mayin.org/ajayshah/KB/R/R_for_economists.html+ajay+shah+econometrics+R&hl=en

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From minhan.science at gmail.com  Sun Jul 25 21:09:53 2004
From: minhan.science at gmail.com (Min-Han Tan)
Date: Sun, 25 Jul 2004 15:09:53 -0400
Subject: [R] Colors in survival plots
Message-ID: <7902152a04072512092b083c99@mail.gmail.com>

Hi,

Sorry to trouble the list - I would like to ask a question - I can't
find the answer in the r-help archives.

I am trying to plot 2 survival curves in different colors.

What I have tried is this 
plot(survfit(sim.surv ~ sim.km.smpl),col="red")

but both the survival curves turn red... 

Your advice would be most appreciated! Thank you.

Min-Han



From maustin at amgen.com  Sun Jul 25 21:14:18 2004
From: maustin at amgen.com (Austin, Matt)
Date: Sun, 25 Jul 2004 12:14:18 -0700
Subject: [R] Colors in survival plots
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F11058@teal-exch.amgen.com>

Try

plot(survfit(sim.surv ~ sim.km.smpl), col=c("red", "blue"))

--Matt

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Min-Han Tan
Sent: Sunday, July 25, 2004 12:10 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Colors in survival plots


Hi,

Sorry to trouble the list - I would like to ask a question - I can't
find the answer in the r-help archives.

I am trying to plot 2 survival curves in different colors.

What I have tried is this 
plot(survfit(sim.surv ~ sim.km.smpl),col="red")

but both the survival curves turn red... 

Your advice would be most appreciated! Thank you.

Min-Han

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Sun Jul 25 22:22:15 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 25 Jul 2004 13:22:15 -0700 (PDT)
Subject: [R] help(package)->sink()
In-Reply-To: <41030315.1010505@pdf.com>
References: <410296FA.1020905@pdf.com>
	<loom.20040724T200639-687@post.gmane.org>
	<41030315.1010505@pdf.com>
Message-ID: <Pine.A41.4.58.0407251319010.197670@homer04.u.washington.edu>

On Sat, 24 Jul 2004, Spencer Graves wrote:

>
>       4.  A request for "packageInfo.print" returned "object ... not
> found".

I think someone may have been contaminated by Java or some such. It should
be print.packageInfo

>		 A request for class(mclustInfo) confirmed that it was a
> packageInfo object, so I tried getMethod("print",  "packageInfo");   I
> got, 'No generic function defined for "print"'.  Then I tried,
> getMethod("show", "packageInfo");  I got, 'No method defined for
> function "show" and signature object = "packageInfo"'.
>

For S3 methods you need getS3method("print","packageInfo") rather than
getMethod.

People often recommend getAnywhere("print.packageInfo"), which does take
less typing, but I prefer getS3method.

	-thomas



From tlumley at u.washington.edu  Sun Jul 25 22:28:13 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 25 Jul 2004 13:28:13 -0700 (PDT)
Subject: [R] Colors in survival plots
In-Reply-To: <7902152a04072512092b083c99@mail.gmail.com>
References: <7902152a04072512092b083c99@mail.gmail.com>
Message-ID: <Pine.A41.4.58.0407251326350.197670@homer04.u.washington.edu>

On Sun, 25 Jul 2004, Min-Han Tan wrote:

> Hi,
>
> Sorry to trouble the list - I would like to ask a question - I can't
> find the answer in the r-help archives.
>
> I am trying to plot 2 survival curves in different colors.
>
> What I have tried is this
> plot(survfit(sim.surv ~ sim.km.smpl),col="red")
>
> but both the survival curves turn red...

Well, you did ask for them to be red :^)

The solution is to supply a vector of colors. For example

library(survival)
data(ovarian)
plot(survfit(Surv(futime,fustat)~rx, data=ovarian),
col=c("goldenrod","forestgreen"))


	-thomas



From Ted.Harding at nessie.mcc.ac.uk  Mon Jul 26 01:09:26 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 26 Jul 2004 00:09:26 +0100 (BST)
Subject: [R] Multiple comparisons: its a trap!
In-Reply-To: <20040725171530.42782394F@mprdmxin.myway.com>
Message-ID: <XFMail.040726000926.Ted.Harding@nessie.mcc.ac.uk>

On 25-Jul-04 Gabor Grothendieck wrote:
> Don't know how Python does it but its not the only one and
> I believe its often done like this. Rather than have a Boolean
> type, NULL is defined to be false and anything else is true.
> If the comparison is TRUE then the right argument is returned;
> otherwise NULL is returned.
> 
> Thus
> 
>       3 < 5 < 6
>       ==> (3 < 5) < 6
>       ==> 5 < 6
>       ==> 6
> 
> which is interpreted as TRUE in if statements, etc.  
> 
> Note that the 5 is only evaluated once in the above whereas in
> 
>         (3 < 5) and (5 < 6)
> 
> it would evaluated twice -- not important here but if 5 is replaced
> by a function with side effects then it matters.

This is weird, and I'm not sure what is being discussed here.

I had been hanging fire on this, to see what others say. Not having
seen anyone else say what I'd thought originally, here it is.

If you write, in R,

  3 < 5 < 6

you get TRUE. I understand this to be parsed as "(3 < 5) < 6",
not as "(3 < 5) and (5 < 6)". Am I right?

If so, then what happens depends on what "(3 < 5)" evaluates to.
In R, this is TRUE, and in R it is the case that "TRUE < 6":

  > 3<5<6
  [1] TRUE
  > 3<5
  [1] TRUE
  > TRUE<6
  [1] TRUE

However, in R it is also the case that

  > 3<5<4
  [1] TRUE

since

  > TRUE<4
  [1] TRUE

the point being, as I understand it, that in a numerical context

  TRUE = 1

e.g.

  > TRUE + 3
  [1] 4

and, since 1 < 4, "TRUE < 4" is TRUE and so "3 < 5 < 4" is TRUE.

However,

  > 0.3 < 0.5 < 0.6
  [1] FALSE

for precisely the same reason.

So there should be no problem so long as you remember to bear in
mind what values binary comparisons have, following evaluation.

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 26-Jul-04                                       Time: 00:09:26
------------------------------ XFMail ------------------------------



From ggrothendieck at myway.com  Mon Jul 26 02:47:58 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 26 Jul 2004 00:47:58 +0000 (UTC)
Subject: [R] Multiple comparisons: its a trap!
References: <20040725171530.42782394F@mprdmxin.myway.com>
	<XFMail.040726000926.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <loom.20040726T024503-498@post.gmane.org>

 <Ted.Harding <at> nessie.mcc.ac.uk> writes:

: 
: On 25-Jul-04 Gabor Grothendieck wrote:
: > Don't know how Python does it but its not the only one and
: > I believe its often done like this. Rather than have a Boolean
: > type, NULL is defined to be false and anything else is true.
: > If the comparison is TRUE then the right argument is returned;
: > otherwise NULL is returned.
: > 
: > Thus
: > 
: >       3 < 5 < 6
: >       ==> (3 < 5) < 6
: >       ==> 5 < 6
: >       ==> 6
: > 
: > which is interpreted as TRUE in if statements, etc.  
: > 
: > Note that the 5 is only evaluated once in the above whereas in
: > 
: >         (3 < 5) and (5 < 6)
: > 
: > it would evaluated twice -- not important here but if 5 is replaced
: > by a function with side effects then it matters.
: 
: This is weird, and I'm not sure what is being discussed here.

We were discussing how some other languages string together comparison 
operators without an intermediate  and  to connect them.  This discussion
has nothing to do with R other than possibly to understand whether it
could fit within the R framework.



From den8dev-admin at ml.esprix.net  Mon Jul 26 04:24:40 2004
From: den8dev-admin at ml.esprix.net (den8dev-admin@ml.esprix.net)
Date: Mon, 26 Jul 2004 11:24:40 +0900
Subject: [R] You r-help@lists.r-project.org are not member (den8dev ML)
References: <200407260224.LAA24690@esprix.net>
Message-ID: <200407261124.FMLAAB24697.den8dev@ml.esprix.net>

$B$"$J$?$O$3$N%a!<%j%s%0%j%9%H(B <den8dev at esprix.net> $B$N%a%s%P!<$G$O$"$j$^$;$s!#(B

$B%a!<%j%s%0%j%9%H$K$D$$$F$N0lHLE*$J0FFb$O%a!<%k$NK\J8$K(B

	guide

$B$H=q$$$?%a!<%k$r(B

	den8dev-ctl at esprix.net

$B08$KAw$k$HAw$i$l$F$-$^$9!#(B



From p.dalgaard at biostat.ku.dk  Mon Jul 26 06:47:07 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Jul 2004 06:47:07 +0200
Subject: [R] Multiple comparisons: its a trap!
In-Reply-To: <loom.20040726T024503-498@post.gmane.org>
References: <20040725171530.42782394F@mprdmxin.myway.com>
	<XFMail.040726000926.Ted.Harding@nessie.mcc.ac.uk>
	<loom.20040726T024503-498@post.gmane.org>
Message-ID: <x2bri3ml2s.fsf@biostat.ku.dk>

Gabor Grothendieck <ggrothendieck at myway.com> writes:

>  <Ted.Harding <at> nessie.mcc.ac.uk> writes:
> 
> : 
> : On 25-Jul-04 Gabor Grothendieck wrote:
> : > Don't know how Python does it but its not the only one and
> : > I believe its often done like this. Rather than have a Boolean
> : > type, NULL is defined to be false and anything else is true.
> : > If the comparison is TRUE then the right argument is returned;
> : > otherwise NULL is returned.
.... 
> : This is weird, and I'm not sure what is being discussed here.
> 
> We were discussing how some other languages string together comparison 
> operators without an intermediate  and  to connect them.  This discussion
> has nothing to do with R other than possibly to understand whether it
> could fit within the R framework.

Yes. The other side of the coin is that we do actually use the
TRUE/FALSE == 1/0  convention in places. E.g. (x>0)-(x<0) for the
sign of x, or x*(x>0) for x left-censored at 0. So changing the
current semantics is not really in the cards. Turning x<y<z  into a
syntax error is on the other hand quite simple (at least according to
5 seconds worth of googling for "yacc nonassoc") and we should
probably consider doing so.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From reneinstl at sbcglobal.net  Mon Jul 26 08:35:39 2004
From: reneinstl at sbcglobal.net (Rene Lindstaedt)
Date: Sun, 25 Jul 2004 23:35:39 -0700 (PDT)
Subject: [R] R_HOME not found
Message-ID: <20040726063539.70359.qmail@web80809.mail.yahoo.com>

Hi,

I have a problem with R 1.9.1. I installed it on my
mac (os 10.2.8), and then tried to start it from the
terminal. I got the following error message:

R_HOME ('/Applications/StartR.app/RAqua.app/Contents')
not found

It also won't let me start the GUI version. Any
comments or suggestions would be greatly appreciated.

Thanks,
Rene



From bob.ohara at helsinki.fi  Mon Jul 26 09:08:06 2004
From: bob.ohara at helsinki.fi (Anon.)
Date: Mon, 26 Jul 2004 10:08:06 +0300
Subject: [R] Population simulation.
References: <1090683523.4102828339ae3@webmail1.portugalmail.pt>
Message-ID: <4104ADD6.9080309@helsinki.fi>

assuncao.senra at portugalmail.com wrote:
 >
 > Hello,
 >
 > can anyone tell me if R has any special function for simulating the 
structure
 > of human populations? Something like the genetic algorithm?
 > I need to simulate a sample of a population with a specific 
structure. Is
 > there something on R that can help me?
 >
As others have pointed out, you need to give us some more details. 
There is an artile about simulation of ecological dynamics in last 
December's R News, which may be of some help:
<http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf>

If you're simulating something like a coalescence process, then it might 
be easier to use some specialist software.  In that case, googling with 
a few relevant terms might be the way to go.

Bob

-- 
Bob O'Hara

Dept. of Mathematics and Statistics
P.O. Box 68 (Gustaf H??llstr??min katu 2b)
FIN-00014 University of Helsinki
Finland

Telephone: +358-9-191 51479
Mobile: +358 50 599 0540
Fax:  +358-9-191 51400
WWW:  http://www.RNI.Helsinki.FI/~boh/
Journal of Negative Results - EEB: http://www.jnr-eeb.org



From karlknoblich at yahoo.de  Mon Jul 26 10:36:33 2004
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Mon, 26 Jul 2004 10:36:33 +0200 (CEST)
Subject: [R] Read SPSS data (*.sav) in R 1.8.0 (ok) and R1.9.1(error)
Message-ID: <20040726083633.90831.qmail@web52508.mail.yahoo.com>

Hallo!

I read SPSS data in the following way:

library(Hmisc)
library(foreign)
dat<-spss.get("surv_abb.sav")

In R1.9.1 I got the message:
"Error in all(arg == choices) : Object "typeDate" not
found"

In R1.8.0 the same script works fine.

Does anybody know a possibilty to read a SPSS file
under R1.9.1?

Thanks!
Karl



From commercial at s-boehringer.de  Mon Jul 26 10:45:52 2004
From: commercial at s-boehringer.de (Stefan =?ISO-8859-1?Q?B=F6hringer?=)
Date: Mon, 26 Jul 2004 10:45:52 +0200
Subject: [R] computing sum of indicator variables
Message-ID: <1090831551.2930.5.camel@pingu.humangenetik>

My problem is as follows:
i is a list of integers of variable length. Now I want to compute a new
vector/array that contains 1's at the positions indicated in i. For
example:
c(2, 4) -> c(0, 1, 0, 1)

Using something like
i = i - c(0, i[2:length(i) - 1]);
sapply(i, function(x) c(rep(0, x - 1), 1)));

faces me with the problem of concatenating the result, which I could
somehow not find a solution for.

Thank you very much in advance.

Stefan



From ligges at statistik.uni-dortmund.de  Mon Jul 26 11:00:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 26 Jul 2004 11:00:02 +0200
Subject: [R] computing sum of indicator variables
In-Reply-To: <1090831551.2930.5.camel@pingu.humangenetik>
References: <1090831551.2930.5.camel@pingu.humangenetik>
Message-ID: <4104C812.506@statistik.uni-dortmund.de>

Stefan B??hringer wrote:

> My problem is as follows:
> i is a list 

Do you mean a vector?

> of integers of variable length. Now I want to compute a new
> vector/array 

A vector or an array (which dimensions?)?

 > that contains 1's at the positions indicated in i. For
> example:
> c(2, 4) -> c(0, 1, 0, 1)

How long should the result be? max(i)???

If you mean simple vectors in both cases, i's suggest:

   i <- c(2, 4)
   x <- numeric(max(i))
   x[i] <- 1

Uwe Ligges


> Using something like
> i = i - c(0, i[2:length(i) - 1]);
> sapply(i, function(x) c(rep(0, x - 1), 1)));
> 
> faces me with the problem of concatenating the result, which I could
> somehow not find a solution for.
> 
> Thank you very much in advance.
> 
> Stefan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Jul 26 10:59:34 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 26 Jul 2004 10:59:34 +0200
Subject: [R] computing sum of indicator variables
References: <1090831551.2930.5.camel@pingu.humangenetik>
Message-ID: <009701c472ee$e0304820$ad133a86@www.domain>

Hi Stefan,

you could try something like,

x <- c(2,4,7)
as.numeric(!is.na(match(seq(1, max(x)), x)))

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Stefan Bhringer" <commercial at s-boehringer.de>
To: "R Help" <r-help at stat.math.ethz.ch>
Sent: Monday, July 26, 2004 10:45 AM
Subject: [R] computing sum of indicator variables


> My problem is as follows:
> i is a list of integers of variable length. Now I want to compute a
new
> vector/array that contains 1's at the positions indicated in i. For
> example:
> c(2, 4) -> c(0, 1, 0, 1)
>
> Using something like
> i = i - c(0, i[2:length(i) - 1]);
> sapply(i, function(x) c(rep(0, x - 1), 1)));
>
> faces me with the problem of concatenating the result, which I could
> somehow not find a solution for.
>
> Thank you very much in advance.
>
> Stefan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From JonesW at kssg.com  Mon Jul 26 11:39:49 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Mon, 26 Jul 2004 10:39:49 +0100
Subject: [R] computing sum of indicator variables
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02BD12F7@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040726/50b82251/attachment.pl

From ke1 at sanger.ac.uk  Mon Jul 26 12:11:29 2004
From: ke1 at sanger.ac.uk (Ken Edwards)
Date: Mon, 26 Jul 2004 11:11:29 +0100
Subject: [R] fisher.test FEXACT error 7
In-Reply-To: <410144FA.6020700@pdf.com>
References: <41013BF4.2040505@sanger.ac.uk> <410144FA.6020700@pdf.com>
Message-ID: <4104D8D1.40904@sanger.ac.uk>

Thanks Sundar,

That changes the behaviour of R, but only in so far as it waits longer 
before giving the same error:

fisher.test(testDataTwoColumns, workspace = 2e8)
Error in fisher.test(testDataTwoColumns, workspace = 2e+08) :
        FEXACT error 7.
LDSTP is too small for this problem.
Try increasing the size of the workspace.

...There also seems to be an upper limit of how big the workspace can be...

 > fisher.test(testDataTwoColumns, workspace = 2e9)
Error in fisher.test(testDataTwoColumns, workspace = 2e+09) :
        negative length vectors are not allowed
 > fisher.test(testDataTwoColumns, workspace = 2e10)
Error in fisher.test(testDataTwoColumns, workspace = 2e+10) :
        NAs in foreign function call (arg 10)
In addition: Warning message:
NAs introduced by coercion


A further question - do you (or anyone else) think that this is a 
problem with the physical capabilities of the box that I'm running on, 
or is it likely to be an upper limit with the amount of data that the 
algorithm can handle? 

Many thanks,

Ken


Sundar Dorai-Raj wrote:

>
>
> Ken Edwards wrote:
>
>> Hello,
>> I have an error message that doesn't seem to make sense in that 
>> having read the R documentation I was under the impression that R was 
>> able to grab as much memory as it needed, and has been able to do so 
>> for some time, so the advice given below about increasing the size of 
>> the workspace is redundant.
>> If I'm right, does anyone have a solution to the problem of the size 
>> of LDSTP?  Or is this really a message about the limit of data size 
>> that the function can handle?
>>
>> I have tried the function using test data containing a similar number 
>> of (randomly generated) data points, and it worked then. There are 
>> 258 data points in two columns (i.e. 2 * 134), if that helps.
>>
>> Any advice would be very much appreciated,
>>
>> Many thanks,
>>
>> Ken Edwards.
>>
>> R script below:
>>
>> fisher.test(testData)
>>
>> Error in fisher.test(testData) :
>>        FEXACT error 7.
>> LDSTP is too small for this problem.
>> Try increasing the size of the workspace.
>>
>
> Maybe you should try increasing the workspace:
>
> fisher.test(testData, workspace = 2e6)
>
> --sundar
>
>
>



From baron at psych.upenn.edu  Mon Jul 26 12:31:06 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 26 Jul 2004 06:31:06 -0400
Subject: [R] Read SPSS data (*.sav) in R 1.8.0 (ok) and R1.9.1(error)
In-Reply-To: <20040726083633.90831.qmail@web52508.mail.yahoo.com>
References: <20040726083633.90831.qmail@web52508.mail.yahoo.com>
Message-ID: <20040726103106.GA29525@psych>

On 07/26/04 10:36, Karl Knoblick wrote:
>Hallo!
>
>I read SPSS data in the following way:
>
>library(Hmisc)
>library(foreign)
>dat<-spss.get("surv_abb.sav")
>
>In R1.9.1 I got the message:
>"Error in all(arg == choices) : Object "typeDate" not
>found"
>
>In R1.8.0 the same script works fine.
>
>Does anybody know a possibilty to read a SPSS file
>under R1.9.1?

I cannot find spss.get in the man pages for the current version
of foreign.  It works for me with read.spss.

But I'm surprised it ever worked.  So, possibly, there is
something wrong with the spss file you are trying to import.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
R search page: http://finzi.psych.upenn.edu/



From stephan.wahlbrink at uni-dortmund.de  Mon Jul 26 12:43:33 2004
From: stephan.wahlbrink at uni-dortmund.de (Stephan Wahlbrink)
Date: Mon, 26 Jul 2004 12:43:33 +0200
Subject: [R] Eclipse plugin for R or perhaps S-plus.
References: <40F6ED5B.1080904@med.usyd.edu.au>
Message-ID: <3ym6acx8gm8t.99tyr7w0l54a.dlg@40tude.net>

Richard Piper wrote:

> Does any one know of an eclipse (http://eclipse.org) plugin for R/S.
> 
> thanks
> 
> RIchard

Hi,

You can download a small Eclipse plug-in for R from my homepage:
http://www.walware.de/rplugin.zip . 

Simply unzip the file into the Eclipse directory. The plug-in requires
version 3.0 of Eclipse, it is not compatible with version 2.x. 

The plug-in provides syntax highlighting for R files and R documentations
(Rd files). Furthermore, editor functions concerning "matching brackets"
(highlighting, goto, select enclosing content on double click) are
implemented. Naturally, you can use the language independent IDE features
of Eclipse such as Local History, QuickDiff, CVS, ... 
You can configure the editors in the Eclipse preference dialog under
"StatET".

Best regards,
Stephan Wahlbrink



From vito_ricci at yahoo.com  Mon Jul 26 13:38:25 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Mon, 26 Jul 2004 13:38:25 +0200 (CEST)
Subject: [R] Econometrics Packages On R
Message-ID: <20040726113825.72566.qmail@web41205.mail.yahoo.com>

Dear Allan,
I still use R principally in ts analysis. Tha main
packages I employ are: ts, tseries, ast (it supplies
some helpfull functions and can be downloaded from
CRAN) and lmtest. Just in this period I preparing a
summary of functions involved in ts analysis grouped
by  goal. I would send this short document to CRAN in
next weeks when I end it. If you wish I'll send you a
copy.

Other functions can be found in:

Rmetrics which is a collection of functions which may
be useful for teaching "Financial Engineering" and
"Computational Finance".

See:

http://www.itp.phys.ethz.ch/econophysics/R/

Cordially

Vito


Hello,

I have just started using R, maybe more like learning
it. I am 
interested in using it for Time Series Analysis and I
wanted to know if 
anyone was familiar with packages other than TS that
might be appropriate.

Allan

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml



From dave_lists at yahoo.co.uk  Mon Jul 26 13:52:24 2004
From: dave_lists at yahoo.co.uk (=?iso-8859-1?q?David=20Whiting?=)
Date: Mon, 26 Jul 2004 12:52:24 +0100 (BST)
Subject: [R] X11 device problem on linux: 100% cpu usage
Message-ID: <20040726115224.74800.qmail@web50110.mail.yahoo.com>

Hi,

I'm using R 1.9.1 (patched, 5th July) on linux
(Mandrake 9.2) and am having a problem with the X11()
device. Trying to plot(1:10) results in my CPU going
to 100% and I have to terminate the process. Using
postscript() with the same plot is fine. Everything
else on my system seems to work fine. I have googled
the R site for X11 and (problem OR error OR cpu) and
have not seen anything that is recent or looks
relevent, so I think this is a problem I have created
myself.

I'm not sure where to start with identifying the
cause. Can someone suggest some things that I should
look at?  

Thanks.

Dave.



From mayeul.kauffmann at tiscali.fr  Mon Jul 26 14:15:42 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Mon, 26 Jul 2004 14:15:42 +0200
Subject: [R] covariate selection in cox model (counting process)
Message-ID: <004601c4730a$461190c0$0fb89853@amd>

Hello everyone,
I am searching for a covariate selection procedure in a cox model
formulated
as a counting process.
I use intervals, my formula looks like coxph(Surv(start,stop,status)~
x1+x2+...+cluster(id),robust=T) where id is a country code (I study
occurence of civil wars from 1962 to 1997).
I'd like something not based on p-values, since they have several flaws
for
this purpose.
I turned to other criteria but all the articles I read seems to apply to
the
classical formulation of the cox model, not the counting process one (or
they apply to both but I am not aware of this)

I've tried AIC with
> step(cox.fit)
or
> stepAIC(cox.fit)

and BIC using
>step(cox.fit,k = log(n))
but there seems to be 2 theoretical problems to address:

(1) These values are based on partial loglikelihood ("loglik")
I wonder if this is correct with the cox model formulated as a *counting
process*, with many (consecutive) observations for a given

individual, and then some observation not being independent

Since "the likelihood ratio and score tests assume independence of
observations within a cluster, the Wald and robust score tests

do not" (R warning), and the likelihood ratio being based on loglik, can
I
use loglik in BIC with some dependent observations?

[I have 170 individuals (namely, countries) for 36 year, some single
countries having up to 140 very short observation intervals, other
having
(on

the other extreme) only 1 long interval per year. That's because I
created
artificial covariates measuring the proximity since some

events: exp(-days.since.event/a.chosen.parameter). I splitted every
yearly
interval for which these covariates change rapidly (i.e.

when the events are recent) yielding up to 11 intervals a year]

(2) What penalized term to used?

It seems natural to include the number of covariates, k.
What about the number of observations?

I found several definitions:
AIC= -2 loglik(b) +  2.k
Schwartz Bayesian information criteria:
SBIC= -2 loglik(b) +  k ln(n)

Fr??d??rique Letu?? (author of PhD thesis "COX MODEL: ESTIMATION VIA MODEL
SELECTION AND BIVARIATE SHOCK MODEL",
http://www-lmc.imag.fr/lmc-sms/Frederique.Letue/These3.ps)
suggested me
AIC= - loglik(b) +  2.k/n
BIC= - loglik(b) +  2.ln(n).k/n, with other possible values for
parameter
"2" in this case (see her thesis p.100, but this section is in French)

All these do not tell *what to take for n*. There are 3 main
possibilities:

a) Taking the number of observations (including censored one) will give
a
huge n (around 6000 to 8000), which may seem meaningless

since some observations are only a few days long.
With n at the denominator (Letu??'s criteria), the penalized term would
be so
low that it's like not having it:
>log(7000)/7000
[1] 0.001264809

(where loglik from summary(cox.fit) range from -155 to -175, dependig on
the
model)

b) Volinsky & Raftery "propose a revision of the penalty term in BIC so
that
the penalty is defined in terms of the number of

uncensored events instead of the number of observations." (Volinsky &
Raftery , Bayesian Information Criterion for Censored

Survival Models, June 16, 1999,
http://www.research.att.com/~volinsky/papers/biocs.ps)

This could be computed with
>sum(coxph.detail(cox.interac.dsi6mois)$nevent)

Letu??'s BIC penalized trerm with 50 events will then be
> 2*log(50)/50
[1] 0.1564809
which will have more effects.

However, adding or removing a country which has data for the 36 years
but no
event (then, it is censored) will not change this BIC.

Thus, it is not suitable to account for missing data that do not reduce
the
number of event.
I'd like the criteria to take this into account, because all covariates
do
not have the same missing data.
The question is: When I have the choice with adding a covariate, x10 or
x11,
which have different (not nested) set of missing

values, which one is best?
Estimating all subsets of the full model (full model = all covariates)
with
a dataset containing no missing data for the full model

would be a solution but would more than halve the dataset for many
subsets
of the covariates.

I should mention that step(cox.fit) gives a warning and stops:
"Error in step(cox.fit) : number of rows in use has changed: remove
missing
values?"

which makes me ask whether the whole procedure is OK with model of
different
sample size.


c) "For discrete time event history analysis, the same choice has been
made,
while the total number of exposure time units has also

been used, for consistency with logistic regresion
(Raftery,Lewis,Aghajanian
and Kahn,1993;Raftery Lewisand Aghajanian,1994)"

(Raftery, Bayesian Model Selection in Social Research, 1994,
http://www.stat.washington.edu/tech.reports/bic.ps)

I am not sure what "exposure time units" mean. But since I could have
used a
logit model with yearly observations [but with many

flaws...], I suggest I could use the number of years (sum of length of
intervals, in year)

> sum((fit$y)[,2]-(fit$y)[,1])/365.25
[1] 3759.537

This may still be too high.

Since I have datas from 1962 to 1997 (36 years), I have the folowing
numbers
of "complete cases"-equivalent:
>sum((fit$y)[,2]-(fit$y)[,1])/ (365.25*36)
[1] 104.4316
This seems more resonable and would account for NAs in different models.

However, it might be to high, because some countries are not at risk
during
the all period: some did not existed because they gain

independence near the end of the period (E.G. ex-USRR countries in arly
1990's) or because they were experiencing an event (new

wars in countries already experiencing a war are not taken into
account).

I may take the *proportion* of available data to time at risk to adjust
for
this: a country at risk during 1 year and for which

data are available for this entire year will increase n by 1, not by
1/36.
If the data frame "dataset" contains all countries at risk (including
some
with NA), assuming id == id[complete.cases(dataset)]

(all countries have at least one complete observation) this will be
computed
by

>attach(dataset)
>sum(tapply(stop[complete.cases(dataset)]-start[complete.cases(dataset)]
,CCO
DE,sum) /tapply(stop-start,CCODE,sum))

But this would be a rather empirical adjustment, maybe with no
theoretical
basis.
And I don't think I can enter this as argument k to step()....


Thank you for having read this. Hope I was not too long.
And thank you a lot for any help, comment, etc.

(sorry for mistakes in English as I'm a non native English speaker)

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France



From B.Rowlingson at lancaster.ac.uk  Mon Jul 26 14:25:30 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 26 Jul 2004 13:25:30 +0100
Subject: [R] X11 device problem on linux: 100% cpu usage
In-Reply-To: <20040726115224.74800.qmail@web50110.mail.yahoo.com>
References: <20040726115224.74800.qmail@web50110.mail.yahoo.com>
Message-ID: <4104F83A.2020704@lancaster.ac.uk>

David Whiting wrote:

> I'm using R 1.9.1 (patched, 5th July) on linux
> (Mandrake 9.2) and am having a problem with the X11()
> device. Trying to plot(1:10) results in my CPU going
> to 100% 

> I'm not sure where to start with identifying the
> cause. Can someone suggest some things that I should
> look at?  

  First off, you can try and figure out if its the client (R) or the 
server (your X-windows display server).

  Can you connect to your problem machine from another host (preferably 
one with a different Linux distro, or different X server) and run R, 
sending the graphics over the network. Does it still cause your problem 
machine to go slow? Then its something on the client side.

  If that works fine, then its something to do with the X server on the 
problem machine. Or an interaction term between client and server!

Baz



From luke at stat.uiowa.edu  Mon Jul 26 14:42:12 2004
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 26 Jul 2004 07:42:12 -0500 (CDT)
Subject: [R] interpreting profiling output
In-Reply-To: <x2acxo5a6r.fsf@biostat.ku.dk>
References: <wqroemflo3m.fsf@biostat.ku.dk> <x2acxo5a6r.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.58.0407260733040.5095@itasca2.stat.uiowa.edu>

On Sun, 25 Jul 2004, Peter Dalgaard wrote:

> Kasper Daniel Hansen <k.hansen at biostat.ku.dk> writes:
> 
> > I have some trouble interpreting the output from profiling. I have
> > read the help pages Rprof, summaryRprof and consult the R extensions
> > manual, but I still have problems understanding the output.
> > 
> > Basically the output consist of self.time and total.time. I have the
> > understanding that total.time is the time spent in a given function
> > including any subcalls or child functions or whatever the technical
> > term for that activity is. In contrasts self.time is the time spent in
> > the function excluding subcalls.
> > 
> > Now, in my understanding basically everything in R is functions. I
> > would then guess that for almost any function (except the "atomic
> > ones") the self.time would be very small as it would spend most of its
> > time calling other functions (again, since almost everything is a
> > function). So how do R determine when a subfunction is called?
> ...brutal snippage...
> > I guess some of the answers would be clear if I had a firm grasp of
> > the inner workings of R :)
> 
> In a word, yes... 
> 
> The profiling keeps track of R's *context stack* which is not quite
> the same as function calls. Essentially, it only counts R functions that
> are actually written in R, but not .Internal, .Primitive, etc. So
> "self" counts the amount of time that a function was at the top of the
> stack. This is done by a periodic poll which dumps out the context
> stack at regular intervals. Seeing cases where the self percentages
> don't add to 100% is, I believe, simply due to truncation of the tails
> -- that is, there is a large number of different functions which each
> are counted a few times, and these are not shown in the summary output.
> 
> [Sorry about the late reply, but I was out of town, and noone seems to
> have answered this.]

Just one additional clarification: There are two flavors of
.Primitive, 'builtin' and 'special'.  You can tell which is which
using typeof().  Builtins are things like arithmetic operations and
specials include control constructs like `for`.  At present profiling
does record builtins but not specials.  Recording specials is
something we would like to do eventually but it requires more changes
to the call stack (and dealing with more interections with those
changes) so it hasn't happened yet. .Internal is a special, so no
.Internal calls are recorded.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From mayeul.kauffmann at tiscali.fr  Mon Jul 26 12:07:02 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Mon, 26 Jul 2004 12:07:02 +0200
Subject: [R] Re: smooth non cumulative baseline hazard in Cox model
Message-ID: <000c01c472f8$4ca95c40$0fb89853@amd>

Hello everyone,
I am searching for a covariate selection procedure in a cox model formulated
as a counting process.
I use intervals, my formula looks like coxph(Surv(start,stop,status)~
x1+x2+...+cluster(id),robust=T) where id is a country code (I study
occurence of civil wars from 1962 to 1997).
I'd like something not based on p-values, since they have several flaws for
this purpose.
I turned to other criteria but all the articles I read seems to apply to the
classical formulation of the cox model, not the counting process one (or
they apply to both but I am not aware of this)

I've tried AIC with
> step(cox.fit)
or
> stepAIC(cox.fit)

and BIC using
>step(cox.fit,k = log(n))
but there seems to be 2 theoretical problems to address:

(1) These values are based on partial loglikelihood ("loglik")
I wonder if this is correct with the cox model formulated as a *counting
process*, with many (consecutive) observations for a given

individual, and then some observation not being independent

Since "the likelihood ratio and score tests assume independence of
observations within a cluster, the Wald and robust score tests

do not" (R warning), and the likelihood ratio being based on loglik, can I
use loglik in BIC with some dependent observations?

[I have 170 individuals (namely, countries) for 36 year, some single
countries having up to 140 very short observation intervals, other having
(on

the other extreme) only 1 long interval per year. That's because I created
artificial covariates measuring the proximity since some

events: exp(-days.since.event/a.chosen.parameter). I splitted every yearly
interval for which these covariates change rapidly (i.e.

when the events are recent) yielding up to 11 intervals a year]

(2) What penalized term to used?

It seems natural to include the number of covariates, k.
What about the number of observations?

I found several definitions:
AIC= -2 loglik(b) +  2.k
Schwartz Bayesian information criteria:
SBIC= -2 loglik(b) +  k ln(n)

Fr??d??rique Letu?? (author of PhD thesis "COX MODEL: ESTIMATION VIA MODEL
SELECTION AND BIVARIATE SHOCK MODEL",
http://www-lmc.imag.fr/lmc-sms/Frederique.Letue/These3.ps)
suggested me
AIC= - loglik(b) +  2.k/n
BIC= - loglik(b) +  2.ln(n).k/n, with other possible values for parameter
"2" in this case (see her thesis p.100, but this section is in French)

All these do not tell *what to take for n*. There are 3 main possibilities:

a) Taking the number of observations (including censored one) will give a
huge n (around 6000 to 8000), which may seem meaningless

since some observations are only a few days long.
With n at the denominator (Letu??'s criteria), the penalized term would be so
low that it's like not having it:
>log(7000)/7000
[1] 0.001264809

(where loglik from summary(cox.fit) range from -155 to -175, dependig on the
model)

b) Volinsky & Raftery "propose a revision of the penalty term in BIC so that
the penalty is defined in terms of the number of

uncensored events instead of the number of observations." (Volinsky &
Raftery , Bayesian Information Criterion for Censored

Survival Models, June 16, 1999,
http://www.research.att.com/~volinsky/papers/biocs.ps)

This could be computed with
>sum(coxph.detail(cox.interac.dsi6mois)$nevent)

Letu??'s BIC penalized trerm with 50 events will then be
> 2*log(50)/50
[1] 0.1564809
which will have more effects.

However, adding or removing a country which has data for the 36 years but no
event (then, it is censored) will not change this BIC.

Thus, it is not suitable to account for missing data that do not reduce the
number of event.
I'd like the criteria to take this into account, because all covariates do
not have the same missing data.
The question is: When I have the choice with adding a covariate, x10 or x11,
which have different (not nested) set of missing

values, which one is best?
Estimating all subsets of the full model (full model = all covariates) with
a dataset containing no missing data for the full model

would be a solution but would more than halve the dataset for many subsets
of the covariates.

I should mention that step(cox.fit) gives a warning and stops:
"Error in step(cox.fit) : number of rows in use has changed: remove missing
values?"

which makes me ask whether the whole procedure is OK with model of different
sample size.


c) "For discrete time event history analysis, the same choice has been made,
while the total number of exposure time units has also

been used, for consistency with logistic regresion (Raftery,Lewis,Aghajanian
and Kahn,1993;Raftery Lewisand Aghajanian,1994)"

(Raftery, Bayesian Model Selection in Social Research, 1994,
http://www.stat.washington.edu/tech.reports/bic.ps)

I am not sure what "exposure time units" mean. But since I could have used a
logit model with yearly observations [but with many

flaws...], I suggest I could use the number of years (sum of length of
intervals, in year)

> sum((fit$y)[,2]-(fit$y)[,1])/365.25
[1] 3759.537

This may still be too high.

Since I have datas from 1962 to 1997 (36 years), I have the folowing numbers
of "complete cases"-equivalent:
>sum((fit$y)[,2]-(fit$y)[,1])/ (365.25*36)
[1] 104.4316
This seems more resonable and would account for NAs in different models.

However, it might be to high, because some countries are not at risk during
the all period: some did not existed because they gain

independence near the end of the period (E.G. ex-USRR countries in arly
1990's) or because they were experiencing an event (new

wars in countries already experiencing a war are not taken into account).

I may take the *proportion* of available data to time at risk to adjust for
this: a country at risk during 1 year and for which

data are available for this entire year will increase n by 1, not by 1/36.
If the data frame "dataset" contains all countries at risk (including some
with NA), assuming id == id[complete.cases(dataset)]

(all countries have at least one complete observation) this will be computed
by

>attach(dataset)
>sum(tapply(stop[complete.cases(dataset)]-start[complete.cases(dataset)],CCO
DE,sum) /tapply(stop-start,CCODE,sum))

But this would be a rather empirical adjustment, maybe with no theoretical
basis.
And I don't think I can enter this as argument k to step()....


Thank you for having read this. Hope I was not too long.
And thank you a lot for any help, comment, etc.

(sorry for mistakes in English as I'm a non native English speaker)

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France



From Luisr at frs.fo  Mon Jul 26 14:52:14 2004
From: Luisr at frs.fo (Luis Rideau Cruz)
Date: Mon, 26 Jul 2004 13:52:14 +0100
Subject: [R] aggregate function
Message-ID: <s1050ca0.083@ffdata.setur.fo>

Hi all,
I have the folowing frame(there are more columns than shown),
   1              2           3        4           5     
Year         Total      Tus    Whi      Norw
1994         1.00      1830       0      355 
1995         1.00         0       0        0 
1995         1.00         0       0        0 
1995         1.00      4910    4280      695 
1997         1.00         0       0      110 
1997         0.58         0       0        0 
1997         1.00         0       0        0 
1994         1.00         0       0        0 
1997         1.00         0      40       70 
1998         1.00         0       0     1252 
1999         1.04         0      74        0 
1999         1.00         0       0        0 
1999         1.02         0       0        0 
1999         1.00         0       0        0 
1999         1.00         0       0      171 
1999         1.00      1794       0      229 
1999         1.00         0    3525        0 
1997         1.00      1335    1185      147 
1997         1.00      4925    1057     4801 
1997         1.00         0    6275     1773 

I try to get sum("Total") by "Year" in which Tus>0,  sum("Total") by "Year" in which Whi>0,,,and so on.

I have done something like this;

a<-as.list(numeric(3))
for (i in 3:5)
{
a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
                                                   Tus=frame$"i">0),sum)
}

But I get

 "Error in FUN(X[[as.integer(1)]], ...) : arguments must have same length"

Also by doing one by one

aggregate(frame[,"Total"],list(Year=frame$"Year",
                                                   Tus=frame$"Tus">0),sum)


The result is something like;

   Year  Tus     x
 1994 FALSE 49.69
 1995 FALSE 49.35
 1996 FALSE 56.95
 1997 FALSE 57.00
 1998 FALSE 57.00
 1999 FALSE 58.09
 2000 FALSE 56.97
 2001 FALSE 57.95
 2002 FALSE 57.10
 2003 FALSE 56.16
 2000  TRUE  1.00
 2002  TRUE  1.00
 2003  TRUE  2.01


Help


Thank you

Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo
Web:                www.frs.fo



From ripley at stats.ox.ac.uk  Mon Jul 26 15:08:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jul 2004 14:08:41 +0100 (BST)
Subject: [R] R on AMD64 (Opteron)
In-Reply-To: <21c05c7d0407241857cf46ef8@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0407261401520.6457-100000@gannet.stats>

We are using Fedora Core 2 and some version(s) of SuSe Linux on various
dual Opteron servers.  We also have a copy of RHEL, but AFAIK are not
currently using it.  I've been using a dual Opteron 248 under FC2

I don't know that Windows XP 64-Bit Edition is actually released yet 
(although there have beem public betas).  However, as Peter D says, one 
would need a suitable compiler, binutils etc and the MinGW project is 
unlikely to provide them any time soon (if ever, although the project's 
FAQ suggests that it does intend to).

On Sat, 24 Jul 2004, Jose Quesada wrote:

> Also, I'm curious...
> Not that this would be my first choice for a server, but...
> Anyone running Windows XP 64-Bit Edition? Any success compiling R?
> 
> 
> 
> On Sat, 24 Jul 2004 18:07:18 +1000, Andrew Robinson <andrewr at uidaho.edu> wrote:
> > Professor Ripley,
> >
> > which operating system are you using for these servers, please?
> > Thanks,
> >
> > Andrew
> >
> >
> >
> > ----- Original Message -----
> > From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> > Date: Saturday, July 24, 2004 5:41 pm
> > Subject: Re: [R] R on AMD64 (Opteron)
> >
> > > On Fri, 23 Jul 2004, Asselin Jerome wrote:
> > >
> > > > Hi,
> > > >
> > > > I was wondering if anyone has had good experiences using R on
> > > Linux with
> > > > dual AMD64 (Opteron) processors. I'm thinking of buying a couple
> > > of such
> > > > servers, but I'd like to make sure R would work fine.
> > > >
> > > > The "R Installation and Administration" guide notes that there
> > > may be
> > > > some problems with BLAS libraries. That's all I could find about
> > > R on
> > > > AMD64.
> > >
> > > Actually it says with ATLAS BLAS, not generically.
> > >
> > > > Please share your experience using R on AMD64.
> > >
> > > Quite a few people, including us, are using R on such servers
> > > routinelywith no problems at all.  There are still some issues
> > > about how to squeeze
> > > the maximum performance out of them (e.g. which BLAS to use -- we
> > > are
> > > using Goto's -- and which compiler to use, e.g. Portland Group or
> > > Intel).
> > > --
> > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Matthias.Templ at statistik.gv.at  Mon Jul 26 15:11:38 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Mon, 26 Jul 2004 15:11:38 +0200
Subject: [R] aggregate function
Message-ID: <83536658864BC243BE3C06D7E936ABD501BE18A9@xchg1.statistik.gv.at>

Hi,

# x ... your frame
attach(x)
sum(Total[Year==1997 & Tus > 0])

I hope this helps

Best,
Matthias


> -----Urspr??ngliche Nachricht-----
> Von: Luis Rideau Cruz [mailto:Luisr at frs.fo] 
> Gesendet: Montag, 26. Juli 2004 14:52
> An: r-help at stat.math.ethz.ch
> Betreff: [R] aggregate function
> 
> 
> Hi all,
> I have the folowing frame(there are more columns than shown),
>    1              2           3        4           5     
> Year         Total      Tus    Whi      Norw
> 1994         1.00      1830       0      355 
> 1995         1.00         0       0        0 
> 1995         1.00         0       0        0 
> 1995         1.00      4910    4280      695 
> 1997         1.00         0       0      110 
> 1997         0.58         0       0        0 
> 1997         1.00         0       0        0 
> 1994         1.00         0       0        0 
> 1997         1.00         0      40       70 
> 1998         1.00         0       0     1252 
> 1999         1.04         0      74        0 
> 1999         1.00         0       0        0 
> 1999         1.02         0       0        0 
> 1999         1.00         0       0        0 
> 1999         1.00         0       0      171 
> 1999         1.00      1794       0      229 
> 1999         1.00         0    3525        0 
> 1997         1.00      1335    1185      147 
> 1997         1.00      4925    1057     4801 
> 1997         1.00         0    6275     1773 
> 
> I try to get sum("Total") by "Year" in which Tus>0,  
> sum("Total") by "Year" in which Whi>0,,,and so on.
> 
> I have done something like this;
> 
> a<-as.list(numeric(3))
> for (i in 3:5)
> {
> a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
>                                                    
> Tus=frame$"i">0),sum) }
> 
> But I get
> 
>  "Error in FUN(X[[as.integer(1)]], ...) : arguments must have 
> same length"
> 
> Also by doing one by one
> 
> aggregate(frame[,"Total"],list(Year=frame$"Year",
>                                                    
> Tus=frame$"Tus">0),sum)
> 
> 
> The result is something like;
> 
>    Year  Tus     x
>  1994 FALSE 49.69
>  1995 FALSE 49.35
>  1996 FALSE 56.95
>  1997 FALSE 57.00
>  1998 FALSE 57.00
>  1999 FALSE 58.09
>  2000 FALSE 56.97
>  2001 FALSE 57.95
>  2002 FALSE 57.10
>  2003 FALSE 56.16
>  2000  TRUE  1.00
>  2002  TRUE  1.00
>  2003  TRUE  2.01
> 
> 
> Help
> 
> 
> Thank you
> 
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Matthias.Templ at statistik.gv.at  Mon Jul 26 15:13:35 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Mon, 26 Jul 2004 15:13:35 +0200
Subject: [R] aggregate function
Message-ID: <83536658864BC243BE3C06D7E936ABD501BE18AA@xchg1.statistik.gv.at>

Hi,
 
# x ... your frame
attach(x)
sum(Total[Year==1997 & Tus > 0])
 
I hope this helps
 
Best,
Matthias Templ
 
 
> > -----Urspr??ngliche Nachricht-----
> > Von: Luis Rideau Cruz [mailto:Luisr at frs.fo]
> > Gesendet: Montag, 26. Juli 2004 14:52
> > An: r-help at stat.math.ethz.ch
> > Betreff: [R] aggregate function
> > 
> > 
> > Hi all,
> > I have the folowing frame(there are more columns than shown),
> >    1              2           3        4           5     
> > Year         Total      Tus    Whi      Norw
> > 1994         1.00      1830       0      355 
> > 1995         1.00         0       0        0 
> > 1995         1.00         0       0        0 
> > 1995         1.00      4910    4280      695 
> > 1997         1.00         0       0      110 
> > 1997         0.58         0       0        0 
> > 1997         1.00         0       0        0 
> > 1994         1.00         0       0        0 
> > 1997         1.00         0      40       70 
> > 1998         1.00         0       0     1252 
> > 1999         1.04         0      74        0 
> > 1999         1.00         0       0        0 
> > 1999         1.02         0       0        0 
> > 1999         1.00         0       0        0 
> > 1999         1.00         0       0      171 
> > 1999         1.00      1794       0      229 
> > 1999         1.00         0    3525        0 
> > 1997         1.00      1335    1185      147 
> > 1997         1.00      4925    1057     4801 
> > 1997         1.00         0    6275     1773 
> > 
> > I try to get sum("Total") by "Year" in which Tus>0,
> > sum("Total") by "Year" in which Whi>0,,,and so on.
> > 
> > I have done something like this;
> > 
> > a<-as.list(numeric(3))
> > for (i in 3:5)
> > {
> > a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
> >                                                    
> > Tus=frame$"i">0),sum) }
> > 
> > But I get
> > 
> >  "Error in FUN(X[[as.integer(1)]], ...) : arguments must have
> > same length"
> > 
> > Also by doing one by one
> > 
> > aggregate(frame[,"Total"],list(Year=frame$"Year",
> >                                                    
> > Tus=frame$"Tus">0),sum)
> > 
> > 
> > The result is something like;
> > 
> >    Year  Tus     x
> >  1994 FALSE 49.69
> >  1995 FALSE 49.35
> >  1996 FALSE 56.95
> >  1997 FALSE 57.00
> >  1998 FALSE 57.00
> >  1999 FALSE 58.09
> >  2000 FALSE 56.97
> >  2001 FALSE 57.95
> >  2002 FALSE 57.10
> >  2003 FALSE 56.16
> >  2000  TRUE  1.00
> >  2002  TRUE  1.00
> >  2003  TRUE  2.01
> > 
> > 
> > Help
> > 
> > 
> > Thank you
> > 
> > Luis Ridao Cruz
> > Fiskiranns??knarstovan
> > N??at??n 1
> > P.O. Box 3051
> > FR-110 T??rshavn
> > Faroe Islands
> > Phone:             +298 353900
> > Phone(direct): +298 353912
> > Mobile:             +298 580800
> > Fax:                 +298 353901
> > E-mail:              luisr at frs.fo
> > Web:                www.frs.fo
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> > PLEASE 
> > do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
>



From andy_liaw at merck.com  Mon Jul 26 15:14:30 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 26 Jul 2004 09:14:30 -0400
Subject: [R] aggregate function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80F8@usrymx25.merck.com>

I would try something like:

> lapply(frame[3:5], function(i) tapply(frame$Total[i>0], frame$Year[i>0],
sum))
$Tus
1994 1995 1997 1999 
   1    1    2    1 

$Whi
1995 1997 1999 
1.00 4.00 2.04 

$Norw
1994 1995 1997 1998 1999 
   1    1    5    1    2 

HTH,
Andy

  
> From: Luis Rideau Cruz
> 
> Hi all,
> I have the folowing frame(there are more columns than shown),
>    1              2           3        4           5     
> Year         Total      Tus    Whi      Norw
> 1994         1.00      1830       0      355 
> 1995         1.00         0       0        0 
> 1995         1.00         0       0        0 
> 1995         1.00      4910    4280      695 
> 1997         1.00         0       0      110 
> 1997         0.58         0       0        0 
> 1997         1.00         0       0        0 
> 1994         1.00         0       0        0 
> 1997         1.00         0      40       70 
> 1998         1.00         0       0     1252 
> 1999         1.04         0      74        0 
> 1999         1.00         0       0        0 
> 1999         1.02         0       0        0 
> 1999         1.00         0       0        0 
> 1999         1.00         0       0      171 
> 1999         1.00      1794       0      229 
> 1999         1.00         0    3525        0 
> 1997         1.00      1335    1185      147 
> 1997         1.00      4925    1057     4801 
> 1997         1.00         0    6275     1773 
> 
> I try to get sum("Total") by "Year" in which Tus>0,  
> sum("Total") by "Year" in which Whi>0,,,and so on.
> 
> I have done something like this;
> 
> a<-as.list(numeric(3))
> for (i in 3:5)
> {
> a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
>                                                    
> Tus=frame$"i">0),sum)
> }
> 
> But I get
> 
>  "Error in FUN(X[[as.integer(1)]], ...) : arguments must have 
> same length"
> 
> Also by doing one by one
> 
> aggregate(frame[,"Total"],list(Year=frame$"Year",
>                                                    
> Tus=frame$"Tus">0),sum)
> 
> 
> The result is something like;
> 
>    Year  Tus     x
>  1994 FALSE 49.69
>  1995 FALSE 49.35
>  1996 FALSE 56.95
>  1997 FALSE 57.00
>  1998 FALSE 57.00
>  1999 FALSE 58.09
>  2000 FALSE 56.97
>  2001 FALSE 57.95
>  2002 FALSE 57.10
>  2003 FALSE 56.16
>  2000  TRUE  1.00
>  2002  TRUE  1.00
>  2003  TRUE  2.01
> 
> 
> Help
> 
> 
> Thank you
> 
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Mon Jul 26 15:18:23 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 26 Jul 2004 09:18:23 -0400
Subject: [R] R on AMD64 (Opteron)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80F9@usrymx25.merck.com>

Just one more thing for folks intending to try Opterons with >1 cpu:  You'll
probably want to use a NUMA kernel, rather than a SMP one.

Cheers,
Andy

> From: Prof Brian Ripley
> 
> We are using Fedora Core 2 and some version(s) of SuSe Linux 
> on various
> dual Opteron servers.  We also have a copy of RHEL, but AFAIK are not
> currently using it.  I've been using a dual Opteron 248 under FC2
> 
> I don't know that Windows XP 64-Bit Edition is actually released yet 
> (although there have beem public betas).  However, as Peter D 
> says, one 
> would need a suitable compiler, binutils etc and the MinGW project is 
> unlikely to provide them any time soon (if ever, although the 
> project's 
> FAQ suggests that it does intend to).
> 
> On Sat, 24 Jul 2004, Jose Quesada wrote:
> 
> > Also, I'm curious...
> > Not that this would be my first choice for a server, but...
> > Anyone running Windows XP 64-Bit Edition? Any success compiling R?
> > 
> > 
> > 
> > On Sat, 24 Jul 2004 18:07:18 +1000, Andrew Robinson 
> <andrewr at uidaho.edu> wrote:
> > > Professor Ripley,
> > >
> > > which operating system are you using for these servers, please?
> > > Thanks,
> > >
> > > Andrew
> > >
> > >
> > >
> > > ----- Original Message -----
> > > From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> > > Date: Saturday, July 24, 2004 5:41 pm
> > > Subject: Re: [R] R on AMD64 (Opteron)
> > >
> > > > On Fri, 23 Jul 2004, Asselin Jerome wrote:
> > > >
> > > > > Hi,
> > > > >
> > > > > I was wondering if anyone has had good experiences using R on
> > > > Linux with
> > > > > dual AMD64 (Opteron) processors. I'm thinking of 
> buying a couple
> > > > of such
> > > > > servers, but I'd like to make sure R would work fine.
> > > > >
> > > > > The "R Installation and Administration" guide notes that there
> > > > may be
> > > > > some problems with BLAS libraries. That's all I could 
> find about
> > > > R on
> > > > > AMD64.
> > > >
> > > > Actually it says with ATLAS BLAS, not generically.
> > > >
> > > > > Please share your experience using R on AMD64.
> > > >
> > > > Quite a few people, including us, are using R on such servers
> > > > routinelywith no problems at all.  There are still some issues
> > > > about how to squeeze
> > > > the maximum performance out of them (e.g. which BLAS to 
> use -- we
> > > > are
> > > > using Goto's -- and which compiler to use, e.g. 
> Portland Group or
> > > > Intel).
> > > > --
> > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> > > > University of 
> Oxford,             Tel:  +44 1865 272861 (self)
> > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From asselinj at exchange.umontreal.ca  Mon Jul 26 15:47:13 2004
From: asselinj at exchange.umontreal.ca (Jerome Asselin)
Date: Mon, 26 Jul 2004 09:47:13 -0400
Subject: [R] R on AMD64 (Opteron)
References: <3A822319EB35174CA3714066D590DCD504AF80F9@usrymx25.merck.com>
Message-ID: <009b01c47317$0e6b1f80$fd8b340a@chum.rr06.rtss>

----- Original Message ----- 
From: "Liaw, Andy" <andy_liaw at merck.com>
To: "'Prof Brian Ripley'" <ripley at stats.ox.ac.uk>; "Jose Quesada"
<quesada at gmail.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, July 26, 2004 9:18 AM
Subject: RE: [R] R on AMD64 (Opteron)


> Just one more thing for folks intending to try Opterons with >1 cpu:
You'll
> probably want to use a NUMA kernel, rather than a SMP one.
>
> Cheers,
> Andy

Thanks for the advice, but is there another reason why you write this beside
a large (I mean >8) number of CPUs?

At http://lse.sourceforge.net/numa/faq/ I read,

What is the difference between NUMA and SMP?
The NUMA architecture was designed to surpass the scalability limits of the
SMP architecture. With SMP, which stands for Symmetric Multi-Processing, all
memory access are posted to the same shared memory bus. This works fine for
a relatively small number of CPUs, but the problem with the shared bus
appears when you have dozens, even hundreds, of CPUs competing for access to
the shared memory bus. NUMA alleviates these bottlenecks by limiting the
number of CPUs on any one memory bus, and connecting the various nodes by
means of a high speed interconnect.



From andy_liaw at merck.com  Mon Jul 26 15:55:01 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 26 Jul 2004 09:55:01 -0400
Subject: [R] R on AMD64 (Opteron)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80FB@usrymx25.merck.com>

> From: Jerome Asselin 
> 
> From: "Liaw, Andy" <andy_liaw at merck.com>
> 
> > Just one more thing for folks intending to try Opterons with >1 cpu:
> You'll
> > probably want to use a NUMA kernel, rather than a SMP one.
> >
> > Cheers,
> > Andy
> 
> Thanks for the advice, but is there another reason why you 
> write this beside
> a large (I mean >8) number of CPUs?
> 
> At http://lse.sourceforge.net/numa/faq/ I read,
> 
> What is the difference between NUMA and SMP?
> The NUMA architecture was designed to surpass the scalability 
> limits of the
> SMP architecture. With SMP, which stands for Symmetric 
> Multi-Processing, all
> memory access are posted to the same shared memory bus. This 
> works fine for
> a relatively small number of CPUs, but the problem with the shared bus
> appears when you have dozens, even hundreds, of CPUs 
> competing for access to
> the shared memory bus. NUMA alleviates these bottlenecks by 
> limiting the
> number of CPUs on any one memory bus, and connecting the 
> various nodes by
> means of a high speed interconnect.

I was told by folks at Penguin Computing (where we bought our Opterons) and
AMD that because of the way memory controller is integrated in the Opteron,
when running two CPU intensive processes on a dual CPU box, one cpu will be
at near 100% while the other will be only around 90%, if you use a SMP
kernel.  Indeed that's what we saw when we ran two R processes
simultaneously.  Switching to the NUMA kernel for the most part `solves'
that problem.

Andy



From tlumley at u.washington.edu  Mon Jul 26 17:36:35 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 26 Jul 2004 08:36:35 -0700 (PDT)
Subject: [R] covariate selection in cox model (counting process)
In-Reply-To: <004601c4730a$461190c0$0fb89853@amd>
References: <004601c4730a$461190c0$0fb89853@amd>
Message-ID: <Pine.A41.4.58.0407260830190.143040@homer04.u.washington.edu>

On Mon, 26 Jul 2004, Mayeul KAUFFMANN wrote:

> Hello everyone,
> I am searching for a covariate selection procedure in a cox model
> formulated
> as a counting process.
> I use intervals, my formula looks like coxph(Surv(start,stop,status)~
> x1+x2+...+cluster(id),robust=T) where id is a country code (I study
> occurence of civil wars from 1962 to 1997).
> I'd like something not based on p-values, since they have several flaws
> for
> this purpose.

You may be out of luck.  In the case of recurrent events coxph() is not
using maximum likelihood or even maximum partial likelihood. It is
maximising the quantity that (roughly speaking) would be the partial
likelihood if the covariates explained all the cluster differences.

Partial likelihood for single events does have an AIC analogue that works
reasonably well (not surprisingly, since the partial likelihood is also a
perfectly valid marginal likelihood for the ranks of the survival times).
For recurrent events this isn't going to work.

If you absolutely have to do covariate selection you may need to look for
a maximum likelihood approach, such as a parametric model with random
effects to describe the dependence.  You might be able to use survreg()
with frailty() terms.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Mon Jul 26 17:28:53 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 26 Jul 2004 08:28:53 -0700 (PDT)
Subject: [R] Read SPSS data (*.sav) in R 1.8.0 (ok) and R1.9.1(error)
In-Reply-To: <20040726083633.90831.qmail@web52508.mail.yahoo.com>
References: <20040726083633.90831.qmail@web52508.mail.yahoo.com>
Message-ID: <Pine.A41.4.58.0407260828300.143040@homer04.u.washington.edu>

On Mon, 26 Jul 2004, [iso-8859-1] Karl Knoblick wrote:

> Hallo!
>
> I read SPSS data in the following way:
>
> library(Hmisc)
> library(foreign)
> dat<-spss.get("surv_abb.sav")
>
> In R1.9.1 I got the message:
> "Error in all(arg == choices) : Object "typeDate" not
> found"
>
> In R1.8.0 the same script works fine.
>
> Does anybody know a possibilty to read a SPSS file
> under R1.9.1?
>

YOu should just be able to use read.spss in the "foreign" package.

	-thomas



From Arne.Muller at aventis.com  Mon Jul 26 17:11:31 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Mon, 26 Jul 2004 17:11:31 +0200
Subject: [R] binning a vector
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>

Hello,

I was wondering wether there's a function in R that takes two vectors (of same length) as input and computes mean values for bins (intervals) or even a sliding window over these vectros.

I've several x/y data set (input/response) that I'd like plot together. Say the x-data for one data set goes from -5 to 14 with 12,000 values, then I'd like to bin the x-vector in steps of +1 and calculate and plot the mean of the x-values and the y-values within each bin.

I was browsing the R-docs but couldn't find anything appropiate.

	thanks for hints + kind regads,

	Arne



From stone at stats.ox.ac.uk  Mon Jul 26 16:57:54 2004
From: stone at stats.ox.ac.uk (Tom Stone)
Date: Mon, 26 Jul 2004 15:57:54 +0100
Subject: [R] choosing constraints for function optim method="L-BFGS-B" when
	they are in terms of other parameter values
Message-ID: <000501c47320$eeab7be0$4ed301a3@stats.ox.ac.uk>

I have a function of several variables which I wish to minimise over four
variables, two of the upper bounds for which are defined in terms of other
variables in the model over which minimisation will take place. I cannot
work out how to code this in such a way as to avoid getting an error message
when I run the code.

If anyone can provide any assistance I will be most grateful.

Best Regards

Tom Stone



From ripley at stats.ox.ac.uk  Mon Jul 26 16:42:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jul 2004 15:42:22 +0100 (BST)
Subject: [R] help(package)->sink()
In-Reply-To: <Pine.A41.4.58.0407251319010.197670@homer04.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0407261537440.6730-100000@gannet.stats>

On Sun, 25 Jul 2004, Thomas Lumley wrote:

> On Sat, 24 Jul 2004, Spencer Graves wrote:
> 
> >
> >       4.  A request for "packageInfo.print" returned "object ... not
> > found".
> 
> I think someone may have been contaminated by Java or some such. It should
> be print.packageInfo
> 
> >		 A request for class(mclustInfo) confirmed that it was a
> > packageInfo object, so I tried getMethod("print",  "packageInfo");   I
> > got, 'No generic function defined for "print"'.  Then I tried,
> > getMethod("show", "packageInfo");  I got, 'No method defined for
> > function "show" and signature object = "packageInfo"'.
> >
> 
> For S3 methods you need getS3method("print","packageInfo") rather than
> getMethod.
> 
> People often recommend getAnywhere("print.packageInfo"), which does take
> less typing, but I prefer getS3method.

They are not exactly equivalent, though.  Although I know of no actual
examples, it is possible to register something like printPackageInfo() as
the S3 method for print() for class "packageInfo".  Then getS3method will
work and getAnywhere will not.

The advantage of getAnywhere is that it is blunderbuss designed to pick up 
all possible matches for any sort of R object, which can be useful.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Mon Jul 26 16:34:49 2004
From: ozric at web.de (Christian Schulz)
Date: Mon, 26 Jul 2004 16:34:49 +0200
Subject: [R] installing problems repeated.tgz linux
Message-ID: <200407261634.49676.ozric@web.de>

Hi,

i try several possibilities adn looking in the archive,
 but didn't getting success to install  j.lindsey's  usefuel "library 
repeated" on my linux (suse9.0 with kernel 2.6.7,R.1.9.1)

P.S. Windows, works  fine

Many thanks for help
Christian


chris at linux:/space/downs> R CMD INSTALL - l /usr/lib/R/library   repeated
WARNING: invalid package '-'
WARNING: invalid package 'l'
WARNING: invalid package '/usr/lib/R/library'
* Installing *source* package 'repeated' ...
** libs
/usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enth??lt kein ??%??.  
Schluss.
ERROR: compilation failed for package 'repeated'
** Removing '/usr/lib/R/library/repeated'



From mayeul.kauffmann at tiscali.fr  Mon Jul 26 13:24:37 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Mon, 26 Jul 2004 13:24:37 +0200
Subject: [R] covariate selection in cox model (counting process)
Message-ID: <002301c47303$25501d40$0fb89853@amd>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040726/4465d7f9/attachment.pl

From jcmartinez at banxico.org.mx  Mon Jul 26 16:07:54 2004
From: jcmartinez at banxico.org.mx (=?iso-8859-1?Q?Mart=EDnez_Ovando_Juan_Carlos?=)
Date: Mon, 26 Jul 2004 09:07:54 -0500
Subject: [R] Econometrics Packages On R
Message-ID: <ED7E0E44EAADFB46A6ABA12A647C1306138F04C1@CORREOINT.banxico.org.mx>


Hello Allan,

In addition to the suggestion of Spencer Graves, you could explore the BACC package (http://www2.cirano.qc.ca/~bacc/) which implements Bayesian analysis for some econometric models. There exist a version to run in R. 

Best regards,
 
Juan Carlos 
 

-----Mensaje original-----
De: Allan W. Bart, Jr. [mailto:allanba at verizon.net] 
Enviado el: Domingo, 25 de Julio de 2004 08:37 AM
Para: r-help at stat.math.ethz.ch
Asunto: [R] Econometrics Packages On R

Hello,

I have just started using R, maybe more like learning it. I am 
interested in using it for Time Series Analysis and I wanted to know if 
anyone was familiar with packages other than TS that might be appropriate.

Allan

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From lhill at ipimar.pt  Mon Jul 26 16:06:50 2004
From: lhill at ipimar.pt (Louize Hill)
Date: Mon, 26 Jul 2004 15:06:50 +0100
Subject: [R] group definition for a bootstrap
Message-ID: <00a201c47319$cbe6e560$36040a0a@Louisept>

Hi,
This is probably really simple, but I am clearly not R-minded, I have read
the help files, and reread them, and I still can't work out what to do...
I have a data frame (d) with 3 columns (age (0-5), quarter (1-4) and x).
I want to estimate the precision of my mean x by age and quarter, so I want
to carry out a bootstrap for each group.
I am trying to do this within a loop, so I don't have to retype the whole
thing out 20 times ...
This is what I have done:

n = length (d$x)
N = 1000
stat = numeric(N)
for (i in 1:N) {
d$x2 = sample (d$x, n, replace=T)
stat[i] = mean(d$x2)
}

I believe I should define the age and quarter groups in the line straight
after "for" - using the split function, or should I use some variant of
[d$age == "1" & d$quarter =="1"] in the sample definition?
Please don't think I am looking for an easy answer - I have been puzzling
for this for over a week already :(
(I am using R1.9 under MS W2000)
Thank you in advance
Louize



From mkondrin at hppi.troitsk.ru  Tue Jul 27 03:16:50 2004
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 26 Jul 2004 18:16:50 -0700
Subject: [R] R 1.9.1: comparison list(1)==list(1)...
Message-ID: <4105AD02.2080403@hppi.troitsk.ru>

... raises an error: comarison of these types is not implemented. But it 
used to be implemented in versions 1.9.0 and earlier. What is wrong?



From rebhi2001 at yahoo.com  Mon Jul 26 17:51:10 2004
From: rebhi2001 at yahoo.com (rebhi bsharat)
Date: Mon, 26 Jul 2004 08:51:10 -0700 (PDT)
Subject: [R] loop avoiding... 
Message-ID: <20040726155110.99149.qmail@web50701.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040726/d6eb0559/attachment.pl

From ggrothendieck at myway.com  Mon Jul 26 18:03:41 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 26 Jul 2004 16:03:41 +0000 (UTC)
Subject: [R] aggregate function
References: <s1050ca0.083@ffdata.setur.fo>
Message-ID: <loom.20040726T180233-679@post.gmane.org>


You can use rowsum like this:

R> rowsum(frame$Total * (frame[,3:5]>0), frame$Year)

Tus Whi Norw
1994 1 0.00 1
1995 1 1.00 1
1997 2 4.00 5
1998 0 0.00 1
1999 1 2.04 2

Note that only years that are actually present will be in the
resulting matrix. 1996 is not in frame so there is
no row for 1996. If that's not a problem or if your data
covers all the years anyways we are done.

If that *is* a problem then merge in some zero rows first. The first
two lines below do this and the third line is the same as the line
above:

R> frame <- merge(frame, 1994:1999, by = 1, all = TRUE)
R> frame[is.na(frame)] <- 0

R> sapply(frame[3:5], function(x) with(frame, tapply(Total*(x>0), Year, sum)))

Tus Whi Norw
1994 1 0.00 1
1995 1 1.00 1
1996 0 0.00 0 <-- now we have a row for 1996
1997 2 4.00 5
1998 0 0.00 1
1999 1 2.04 2


Luis Rideau Cruz <Luisr <at> frs.fo> writes:

:
: Hi all,
: I have the folowing frame(there are more columns than shown),
: 1 2 3 4 5
: Year Total Tus Whi Norw
: 1994 1.00 1830 0 355
: 1995 1.00 0 0 0
: 1995 1.00 0 0 0
: 1995 1.00 4910 4280 695
: 1997 1.00 0 0 110
: 1997 0.58 0 0 0
: 1997 1.00 0 0 0
: 1994 1.00 0 0 0
: 1997 1.00 0 40 70
: 1998 1.00 0 0 1252
: 1999 1.04 0 74 0
: 1999 1.00 0 0 0
: 1999 1.02 0 0 0
: 1999 1.00 0 0 0
: 1999 1.00 0 0 171
: 1999 1.00 1794 0 229
: 1999 1.00 0 3525 0
: 1997 1.00 1335 1185 147
: 1997 1.00 4925 1057 4801
: 1997 1.00 0 6275 1773
:
: I try to get sum("Total") by "Year" in which Tus>0, sum("Total") by "Year"
in which Whi>0,,,and so on.
:
: I have done something like this;
:
: a<-as.list(numeric(3))
: for (i in 3:5)
: {
: a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
: Tus=frame$"i">0),sum)
: }
:
: But I get
:
: "Error in FUN(X[[as.integer(1)]], ...) : arguments must have same length"
:
: Also by doing one by one
:
: aggregate(frame[,"Total"],list(Year=frame$"Year",
: Tus=frame$"Tus">0),sum)
:
: The result is something like;
:
: Year Tus x
: 1994 FALSE 49.69
: 1995 FALSE 49.35
: 1996 FALSE 56.95
: 1997 FALSE 57.00
: 1998 FALSE 57.00
: 1999 FALSE 58.09
: 2000 FALSE 56.97
: 2001 FALSE 57.95
: 2002 FALSE 57.10
: 2003 FALSE 56.16
: 2000 TRUE 1.00
: 2002 TRUE 1.00
: 2003 TRUE 2.01



From kbartz at loyaltymatrix.com  Mon Jul 26 18:06:03 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Mon, 26 Jul 2004 09:06:03 -0700
Subject: [R] binning a vector
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>
Message-ID: <20040726161142.3B574401F4@omta18.mta.everyone.net>

Hi! For vector X, the vector to be averaged, along with binning vector Y,
you'd want to do something like this:

bpts  <- pretty(Y)
INDEX <- cut(Y, bpts, include.lowest = T)
tapply(X, INDEX, mean)

The idea is that R first breaks your binning vector Y into a factor, then
applies the "mean" function to X, over the levels of the factorized Y.
Incidentally, I've wrapped this in a "bapply" function included in a package
I'm working on:

bapply <- function(X, Y, FUN = NULL,
                   pretty.fn = pretty, pretty.arg = NULL,
                   cut.fn    = cut,    cut.arg    = NULL, ...) {
  bpts  <- do.call("pretty", c(list(Y), pretty.arg))
  INDEX <- do.call("cut", c(list(Y), cut.arg))
  tapply(X, INDEX, FUN, ...)
}

This allows you to apply the same way you do with "tapply." Let me know if
you have any questions.

Kevin

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
Arne.Muller at aventis.com
Sent: Monday, July 26, 2004 8:12 AM
To: r-help at stat.math.ethz.ch
Subject: [R] binning a vector

Hello,

I was wondering wether there's a function in R that takes two vectors (of
same length) as input and computes mean values for bins (intervals) or even
a sliding window over these vectros.

I've several x/y data set (input/response) that I'd like plot together. Say
the x-data for one data set goes from -5 to 14 with 12,000 values, then I'd
like to bin the x-vector in steps of +1 and calculate and plot the mean of
the x-values and the y-values within each bin.

I was browsing the R-docs but couldn't find anything appropiate.

	thanks for hints + kind regads,

	Arne

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Mon Jul 26 18:12:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jul 2004 17:12:47 +0100 (BST)
Subject: [R] choosing constraints for function optim method="L-BFGS-B"
	when they are in terms of other parameter values
In-Reply-To: <000501c47320$eeab7be0$4ed301a3@stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.44.0407261710520.7079-100000@gannet.stats>

Basically, you can't as L-BFGS-B implements box constraints and you don't 
have a box.

You could run a nested optimization, the inner one being over the two 
variables that you want to upper-bound.  Contact me offline if that is not 
clear to you.

On Mon, 26 Jul 2004, Tom Stone wrote:

> I have a function of several variables which I wish to minimise over four
> variables, two of the upper bounds for which are defined in terms of other
> variables in the model over which minimisation will take place. I cannot
> work out how to code this in such a way as to avoid getting an error message
> when I run the code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at PDF.COM  Mon Jul 26 18:13:41 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Mon, 26 Jul 2004 11:13:41 -0500
Subject: [R] binning a vector
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>
Message-ID: <41052DB5.9070406@pdf.com>


Arne.Muller at aventis.com wrote:

> Hello,
> 
> I was wondering wether there's a function in R that takes two vectors (of same length) as input and computes mean values for bins (intervals) or even a sliding window over these vectros.
> 
> I've several x/y data set (input/response) that I'd like plot together. Say the x-data for one data set goes from -5 to 14 with 12,000 values, then I'd like to bin the x-vector in steps of +1 and calculate and plot the mean of the x-values and the y-values within each bin.
> 
> I was browsing the R-docs but couldn't find anything appropiate.
> 
> 	thanks for hints + kind regads,
> 
> 	Arne
> 

Take a look at ?running or ?wapply in package:gregmisc.

--sundar



From pgilbert at bank-banque-canada.ca  Mon Jul 26 18:17:51 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 26 Jul 2004 12:17:51 -0400
Subject: [R] Multivariate ARMA Model
In-Reply-To: <000001c47251$245eb340$5c6a8286@iaew.rwthaachen.de>
References: <000001c47251$245eb340$5c6a8286@iaew.rwthaachen.de>
Message-ID: <41052EAF.3040405@bank-banque-canada.ca>



Hagen Schm??ller wrote:

> Hi R-Community,
> 
> so far I dealt with univariate processes and used the function "arima" to
> estimate an ARMA(1,1)-model. For multivariate processes there are the
> functions "estVARXar" and "estVARXls" from package "DSE". But how can I
> estimate an VARMA(1,1)-model, 

You should look at estMaxLik and the dse Users' Guide examples on 
specifying models. The Users' Guide gets installed in 
dse1/doc/dse-guide.pdf. (In dse the ARMA class of models includes VARMA, 
VARMAX, ARIMA, VARIMA, VARIMAX, etc.)

or even better determine the orders and
> estimate the parameters?

If you want to do this automatically, I suggest looking at the 
estimation method called bft in dse1. It estimates VAR models at 
different lag lengths, converts them to state space and does a 
reduction, and then compares the different results. The state space 
reduction results in a more parsimonious representation. This often has 
only an ARMA equivalent and not a VAR equivalent so you should not think 
of this as limiting yourself to VAR models, even thought the estimation 
starts with one. In my experience this does about as well as you can 
hope to do automatically.

If you want to do it manually, estimate the different models you want to 
consider and then compare them. The function informationTests in dse1 is 
a good place to start for doing comparisons.
> 
> Much thanks in advance,
> 
> Hagen Schmoeller
> --
> Dipl.-Ing. Hagen K. Schm??ller
> Leiter Forschungsgruppe Stromerzeugung und -handel
> Institut f??r Elektrische Anlagen und Energiewirtschaft, RWTH Aachen
> Schinkelstra??e 6, D-52056 Aachen, Germany
> Tel.: +49 (0)241 80-96734
> Fax : +49 (0)241 80-92197
> Hagen.Schmoeller at iaew.rwth-aachen.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Mon Jul 26 18:24:56 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 26 Jul 2004 09:24:56 -0700
Subject: [R] computing sum of indicator variables
References: <1090831551.2930.5.camel@pingu.humangenetik>
	<009701c472ee$e0304820$ad133a86@www.domain>
Message-ID: <41053058.7E35053B@gene.com>

Think whole objects!

Simpler and quicker would be:

y<-rep(0,max(i))
y[i]<-1

would it not?

Cheers,
Bert

--

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box



Dimitris Rizopoulos wrote:

> Hi Stefan,
>
> you could try something like,
>
> x <- c(2,4,7)
> as.numeric(!is.na(match(seq(1, max(x)), x)))
>
> I hope this helps.
>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Doctoral Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
> ----- Original Message -----
> From: "Stefan B??hringer" <commercial at s-boehringer.de>
> To: "R Help" <r-help at stat.math.ethz.ch>
> Sent: Monday, July 26, 2004 10:45 AM
> Subject: [R] computing sum of indicator variables
>
> > My problem is as follows:
> > i is a list of integers of variable length. Now I want to compute a
> new
> > vector/array that contains 1's at the positions indicated in i. For
> > example:
> > c(2, 4) -> c(0, 1, 0, 1)
> >
> > Using something like
> > i = i - c(0, i[2:length(i) - 1]);
> > sapply(i, function(x) c(rep(0, x - 1), 1)));
> >
> > faces me with the problem of concatenating the result, which I could
> > somehow not find a solution for.
> >
> > Thank you very much in advance.
> >
> > Stefan
> >



From wolski at molgen.mpg.de  Mon Jul 26 19:56:28 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 26 Jul 2004 19:56:28 +0200
Subject: [R] binning a vector
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>
Message-ID: <200407261956280207.01FE0349@mail.math.fu-berlin.de>

?tapply

*********** REPLY SEPARATOR  ***********

On 7/26/2004 at 5:11 PM Arne.Muller at aventis.com wrote:

>>>Hello,
>>>
>>>I was wondering wether there's a function in R that takes two vectors
>>>(of same length) as input and computes mean values for bins (intervals)
>>>or even a sliding window over these vectros.
>>>
>>>I've several x/y data set (input/response) that I'd like plot together.
>>>Say the x-data for one data set goes from -5 to 14 with 12,000 values,
>>>then I'd like to bin the x-vector in steps of +1 and calculate and plot
>>>the mean of the x-values and the y-values within each bin.
>>>
>>>I was browsing the R-docs but couldn't find anything appropiate.
>>>
>>>	thanks for hints + kind regads,
>>>
>>>	Arne
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From ozric at web.de  Mon Jul 26 19:58:34 2004
From: ozric at web.de (Christian Schulz)
Date: Mon, 26 Jul 2004 19:58:34 +0200
Subject: [R] installing problems repeated.tgz linux
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF80FF@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF80FF@usrymx25.merck.com>
Message-ID: <200407261958.34357.ozric@web.de>

Hello,

 thanks for your and Marc's hint, but it seems not the probleme!?
Is there any  probleme with my make?

many thanks and regards, 
christian


chris at linux:/usr/lib/R> R CMD INSTALL 
-l /usr/lib/R/library  /space/downs/repeated.tgz
* Installing *source* package 'repeated' ...
** libs
/usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enth??lt kein ??%??.  
Schluss.
ERROR: compilation failed for package 'repeated'
** Removing '/usr/lib/R/library/repeated'

chris at linux:/usr/lib/R> R CMD INSTALL 
-l /usr/lib/R/library  /space/downs/repeated
* Installing *source* package 'repeated' ...
** libs
/usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enth??lt kein ??%??.  
Schluss.
ERROR: compilation failed for package 'repeated'
** Removing '/usr/lib/R/library/repeated'

...with your great RandomForest and other packages 
it works!

chris at linux:/usr/lib/R> R CMD INSTALL 
-l /usr/lib/R/library  /space/downs/randomForest*.tar.gz
* Installing *source* package 'randomForest' ...
** libs
gcc -I/usr/lib/R/include  -I/usr/local/include -I/opt/gnome/include 
-D__NO_MATH_INLINES -mieee-fp  -fPIC   -c regrf.c -o regrf.o
g77 -mieee-fp  -fPIC   -c regrfsub.f -o regrfsub.o
gcc -I/usr/lib/R/include  -I/usr/local/include -I/opt/gnome/include 
-D__NO_MATH_INLINES -mieee-fp  -fPIC   -c rf.c -o rf.o
g77 -mieee-fp  -fPIC   -c rfsub.f -o rfsub.o
gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o randomForest.so regrf.o 
regrfsub.o rf.o rfsub.o  -L/usr/local/lib -L/opt/gnome/lib 
-L/usr/lib/gcc-lib/i586-suse-linux/3.3.1 
-L/usr/lib/gcc-lib/i586-suse-linux/3.3.1/../../../../i586-suse-linux/lib 
-L/usr/lib/gcc-lib/i586-suse-linux/3.3.1/../../.. -lfrtbegin -lg2c -lm 
-lgcc_s -L/usr/lib/R/bin -lR
** R
** inst
** help
 >>> Building/Updating help pages for package 'randomForest'
     Formats: text html latex example
  MDSplot                           text    html    latex   example
  combine                           text    html    latex   example
  getTree                           text    html    latex   example
  grow                              text    html    latex   example
  importance                        text    html    latex
  margin                            text    html    latex   example
  na.roughfix                       text    html    latex   example
  partialPlot                       text    html    latex   example
  plot.randomForest                 text    html    latex   example
  predict.randomForest              text    html    latex   example
  randomForest                      text    html    latex   example
  rfImpute                          text    html    latex   example
  treesize                          text    html    latex   example
  tuneRF                            text    html    latex   example
  varImpPlot                        text    html    latex   example
  varUsed                           text    html    latex   example
* DONE (randomForest)






Am Montag, 26. Juli 2004 18:56 schrieb Liaw, Andy:
> > From: Christian Schulz
> >
> > Hi,
> >
> > i try several possibilities adn looking in the archive,
> >  but didn't getting success to install  j.lindsey's  usefuel "library
> > repeated" on my linux (suse9.0 with kernel 2.6.7,R.1.9.1)
> >
> > P.S. Windows, works  fine
> >
> > Many thanks for help
> > Christian
> >
> > > R CMD INSTALL - l /usr/lib/R/library   repeated
>
>                    ^
> Try again without that space.
>
> Andy
>
>
>
> ---------------------------------------------------------------------------
>--- Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
> Jersey, USA 08889), and/or its affiliates (which may be known outside the
> United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
> Banyu) that may be confidential, proprietary copyrighted and/or legally
> privileged. It is intended solely for the use of the individual or entity
> named on this message.  If you are not the intended recipient, and have
> received this message in error, please notify us immediately by reply
> e-mail and then delete it from your system.
> ---------------------------------------------------------------------------
>---



From deepayan at stat.wisc.edu  Mon Jul 26 19:38:07 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 26 Jul 2004 12:38:07 -0500
Subject: [R] binning a vector
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE018461EF@crbsmxsusr04.pharma.aventis.com>
Message-ID: <200407261238.08196.deepayan@stat.wisc.edu>

On Monday 26 July 2004 10:11, Arne.Muller at aventis.com wrote:
> Hello,
>
> I was wondering wether there's a function in R that takes two vectors
> (of same length) as input and computes mean values for bins
> (intervals) or even a sliding window over these vectros.
>
> I've several x/y data set (input/response) that I'd like plot
> together. Say the x-data for one data set goes from -5 to 14 with
> 12,000 values, then I'd like to bin the x-vector in steps of +1 and
> calculate and plot the mean of the x-values and the y-values within
> each bin.
>
> I was browsing the R-docs but couldn't find anything appropiate.

Do you know about loess? It's not exactly what you describe, but maybe 
it's what you really want.

Deepayan



From rossini at blindglobe.net  Mon Jul 26 19:11:16 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 26 Jul 2004 10:11:16 -0700
Subject: [R] zsh and R
Message-ID: <85vfgasngr.fsf@servant.blindglobe.net>


In the process of evaluating new shells, I've run into a few problems
with zsh and the R CMD build, R CMD check scripts.  

I'd like to ask a few questions off-line if anyone has experience with
R and the zsh completion/substitution functionality.

Note that bash continues to work as well as ever, just that zsh is
being finicky.

best,
-tony

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From andy_liaw at merck.com  Mon Jul 26 18:56:48 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 26 Jul 2004 12:56:48 -0400
Subject: [R] installing problems repeated.tgz linux
Message-ID: <3A822319EB35174CA3714066D590DCD504AF80FF@usrymx25.merck.com>

> From: Christian Schulz
> 
> Hi,
> 
> i try several possibilities adn looking in the archive,
>  but didn't getting success to install  j.lindsey's  usefuel "library 
> repeated" on my linux (suse9.0 with kernel 2.6.7,R.1.9.1)
> 
> P.S. Windows, works  fine
> 
> Many thanks for help
> Christian
> 
> 
> > R CMD INSTALL - l /usr/lib/R/library   repeated
                   ^
Try again without that space.

Andy



From a.prioglio at city.ac.uk  Mon Jul 26 18:41:56 2004
From: a.prioglio at city.ac.uk (Antonio Prioglio)
Date: Mon, 26 Jul 2004 17:41:56 +0100 (BST)
Subject: [R] factanal - rotation = "oblimin"
Message-ID: <Pine.LNX.4.44.0407261734460.10360-100000@ws7.dogbert.ntt.it>

Hi list.

To the best of mylimited understandig currently R (unlike S)  does not
support oblimin criterion for exploratory factor analysis.

Searching through the contributed packages I did not notice any additional 
package for factor analysis.

Does anybody know if such function is present within any package?

Saluti,
Antonio Prioglio

-- 
We are what we repeatedly do. Excellence, then, is not an act, but a habit.
							Aristoteles


    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL 
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From arnholt at cs.cs.appstate.edu  Mon Jul 26 19:56:08 2004
From: arnholt at cs.cs.appstate.edu (Alan Arnholt)
Date: Mon, 26 Jul 2004 13:56:08 -0400 (EDT)
Subject: [R] Building Windows Package
Message-ID: <Pine.OSF.4.55.0407261351090.209051@cs.cs.appstate.edu>

I am using R-1.9.1 with windows 2000 and trying to build a package.
However,
when I issue the command:

RCMD build --binary BSDA

I get:

 >>> Building/Updating help pages for package 'BSDA'
     Formats: chm
hhc: not found
cp: cannot stat `C:/R191/R191/JUNK/BSDA/chm/BSDA.chm': No such file or
direc
tory
make[1]: *** [chm-BSDA] Error 1
make: *** [pkg-BSDA] Error 2
*** Installation of BSDA failed ***


My path is:

.;C:\RStools;C:\MinGW\bin;C:\perl\bin;C:\texmf\miktex\bin;C:\Rstools\zip.exe;
C:\Rstools\unzip.exe;C:\HTMLws\hhc.exe;C:\R191\R191\bin;%SystemRoot%\system32;
%SystemRoot%;%SystemRoot%\System32\Wbem;C:\Program
Files\CommonFiles\AdaptecShared\System;
C:\Program Files\ggobi;C:\Program Files\R\rw1091\library\Rggobi\libs

(HTML Help Workshop lives in- "C:\HTMLws\hhc.exe")


I have the directory for HTML Help workshop in MkRules set as:

# Where does 'HTML Help Workshop' live? (unused if compiled HTML help is
# not requested. Spaces allowed.)
HHWDIR=C:/HTMLws

After I issue RCMD build --binary BSDA and get the error messages, if I go
to
`C:/R191/R191/JUNK/BSDA/chm/BSDA.hhp' and manually compile the file (with
HTML Help

workshop) then issue the command RCMD build --binary BSDA   again...the
package builds
without problems.  Any ideas what I am doing wrong?  Thanks in advance for
the help.


Alan




Alan T. Arnholt
Associate Professor
Dept. of Mathematical Sciences
Appalachian State University
2003-2004 International Exchange Scholar
Universidad Publica de Navarra - Nafarroako Unibertsitate Publikoa
Pamplona,  Spain

TEL : +34 948 169 205
CELL: +34 656 668 621



From MSchwartz at MedAnalytics.com  Mon Jul 26 18:35:43 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 26 Jul 2004 11:35:43 -0500
Subject: [R] installing problems repeated.tgz linux
In-Reply-To: <200407261634.49676.ozric@web.de>
References: <200407261634.49676.ozric@web.de>
Message-ID: <1090859742.25830.23.camel@localhost.localdomain>

On Mon, 2004-07-26 at 09:34, Christian Schulz wrote:
> Hi,
> 
> i try several possibilities adn looking in the archive,
>  but didn't getting success to install  j.lindsey's  usefuel "library 
> repeated" on my linux (suse9.0 with kernel 2.6.7,R.1.9.1)
> 
> P.S. Windows, works  fine
> 
> Many thanks for help
> Christian
> 
> 
> chris at linux:/space/downs> R CMD INSTALL - l /usr/lib/R/library   repeated
> WARNING: invalid package '-'
> WARNING: invalid package 'l'
> WARNING: invalid package '/usr/lib/R/library'
> * Installing *source* package 'repeated' ...
> ** libs
> /usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enthlt kein %.  
> Schluss.
> ERROR: compilation failed for package 'repeated'
> ** Removing '/usr/lib/R/library/repeated'

Christian,

There is a space (' ') between the '-' and the 'l', which will be parsed
as two separate arguments.  Hence the initial WARNING messages.

You need to use:

R CMD INSTALL -l /usr/lib/R/library repeated

Also note that you need to have 'root' privileges in order to install
the packages into the /usr/lib/R tree. Thus, you should 'su' to root
before running the command.

You should verify that your R tree is in /usr/lib, as the default is
/usr/local/lib, for which you would not require the '-l
/usr/lib/R/library' argument.

Presumably Windows worked fine because you typically do not require
administrator privileges to install the package locally on Windows or
your account has administrative privileges, which is typical (and bad)
on Windows NT/XP.

HTH,

Marc Schwartz



From wolski at molgen.mpg.de  Mon Jul 26 20:48:05 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 26 Jul 2004 20:48:05 +0200
Subject: [R] ordering of levels.
Message-ID: <200407262048050752.69B68AAE@mail.math.fu-berlin.de>

Hi!
Have the following factors with the following levels.
 tmp$norm
 [1] rank rank rank rank rank log  log  log  rank sqrt sqrt sqrt log  log  rank
[16] rank rank sqrt sqrt sqrt sqrt log  log  log  log  sqrt none none none none
[31] none none none none sqrt none
Levels: log none rank sqrt

I would like to add an ordering to the levels.
none<sqrt<log<rank

I tried with 
tmp$norm <-factor(tmp$norm,labels = c("none","sqrt","log","rank"),ordered=T)
>tmp$norm
 [1] log  log  log  log  log  none none none log  rank rank rank none none log 
[16] log  log  rank rank rank rank none none none none rank sqrt sqrt sqrt sqrt
[31] sqrt sqrt sqrt sqrt rank sqrt
Levels: none < sqrt < log < rank

But this is not what I would like to have because the command not only superimposes an ordering but also changes the factors!

Eryk



From andy_liaw at merck.com  Mon Jul 26 20:57:24 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 26 Jul 2004 14:57:24 -0400
Subject: [R] installing problems repeated.tgz linux
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8104@usrymx25.merck.com>

Sorry, Christian.  I have no idea what those error messages in German say.

Andy

> From: ozric at web.de 
> 
> Hello,
> 
>  thanks for your and Marc's hint, but it seems not the probleme!?
> Is there any  probleme with my make?
> 
> many thanks and regards, 
> christian
> 
> 
> chris at linux:/usr/lib/R> R CMD INSTALL 
> -l /usr/lib/R/library  /space/downs/repeated.tgz
> * Installing *source* package 'repeated' ...
> ** libs
> /usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enth??lt 
> kein ??%??.  
> Schluss.
> ERROR: compilation failed for package 'repeated'
> ** Removing '/usr/lib/R/library/repeated'
> 
> chris at linux:/usr/lib/R> R CMD INSTALL 
> -l /usr/lib/R/library  /space/downs/repeated
> * Installing *source* package 'repeated' ...
> ** libs
> /usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enth??lt 
> kein ??%??.  
> Schluss.
> ERROR: compilation failed for package 'repeated'
> ** Removing '/usr/lib/R/library/repeated'
> 
> ...with your great RandomForest and other packages 
> it works!
> 
> chris at linux:/usr/lib/R> R CMD INSTALL 
> -l /usr/lib/R/library  /space/downs/randomForest*.tar.gz
> * Installing *source* package 'randomForest' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include -I/opt/gnome/include 
> -D__NO_MATH_INLINES -mieee-fp  -fPIC   -c regrf.c -o regrf.o
> g77 -mieee-fp  -fPIC   -c regrfsub.f -o regrfsub.o
> gcc -I/usr/lib/R/include  -I/usr/local/include -I/opt/gnome/include 
> -D__NO_MATH_INLINES -mieee-fp  -fPIC   -c rf.c -o rf.o
> g77 -mieee-fp  -fPIC   -c rfsub.f -o rfsub.o
> gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o 
> randomForest.so regrf.o 
> regrfsub.o rf.o rfsub.o  -L/usr/local/lib -L/opt/gnome/lib 
> -L/usr/lib/gcc-lib/i586-suse-linux/3.3.1 
> -L/usr/lib/gcc-lib/i586-suse-linux/3.3.1/../../../../i586-suse
> -linux/lib 
> -L/usr/lib/gcc-lib/i586-suse-linux/3.3.1/../../.. -lfrtbegin 
> -lg2c -lm 
> -lgcc_s -L/usr/lib/R/bin -lR
> ** R
> ** inst
> ** help
>  >>> Building/Updating help pages for package 'randomForest'
>      Formats: text html latex example
>   MDSplot                           text    html    latex   example
>   combine                           text    html    latex   example
>   getTree                           text    html    latex   example
>   grow                              text    html    latex   example
>   importance                        text    html    latex
>   margin                            text    html    latex   example
>   na.roughfix                       text    html    latex   example
>   partialPlot                       text    html    latex   example
>   plot.randomForest                 text    html    latex   example
>   predict.randomForest              text    html    latex   example
>   randomForest                      text    html    latex   example
>   rfImpute                          text    html    latex   example
>   treesize                          text    html    latex   example
>   tuneRF                            text    html    latex   example
>   varImpPlot                        text    html    latex   example
>   varUsed                           text    html    latex   example
> * DONE (randomForest)
> 
> 
> 
> 
> 
> 
> Am Montag, 26. Juli 2004 18:56 schrieb Liaw, Andy:
> > > From: Christian Schulz
> > >
> > > Hi,
> > >
> > > i try several possibilities adn looking in the archive,
> > >  but didn't getting success to install  j.lindsey's  
> usefuel "library
> > > repeated" on my linux (suse9.0 with kernel 2.6.7,R.1.9.1)
> > >
> > > P.S. Windows, works  fine
> > >
> > > Many thanks for help
> > > Christian
> > >
> > > > R CMD INSTALL - l /usr/lib/R/library   repeated
> >
> >                    ^
> > Try again without that space.
> >
> > Andy
> >
> >
> >
> > 
> --------------------------------------------------------------
> -------------
> >--- Notice:  This e-mail message, together with any 
> attachments, contains
> > information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New
> > Jersey, USA 08889), and/or its affiliates (which may be 
> known outside the
> > United States as Merck Frosst, Merck Sharp & Dohme or MSD 
> and in Japan, as
> > Banyu) that may be confidential, proprietary copyrighted 
> and/or legally
> > privileged. It is intended solely for the use of the 
> individual or entity
> > named on this message.  If you are not the intended 
> recipient, and have
> > received this message in error, please notify us 
> immediately by reply
> > e-mail and then delete it from your system.
> > 
> --------------------------------------------------------------
> -------------
> >---
> 
>



From sundar.dorai-raj at PDF.COM  Mon Jul 26 21:07:05 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Mon, 26 Jul 2004 14:07:05 -0500
Subject: [R] ordering of levels.
In-Reply-To: <200407262048050752.69B68AAE@mail.math.fu-berlin.de>
References: <200407262048050752.69B68AAE@mail.math.fu-berlin.de>
Message-ID: <41055659.3050404@pdf.com>



Wolski wrote:

> Hi!
> Have the following factors with the following levels.
>  tmp$norm
>  [1] rank rank rank rank rank log  log  log  rank sqrt sqrt sqrt log  log  rank
> [16] rank rank sqrt sqrt sqrt sqrt log  log  log  log  sqrt none none none none
> [31] none none none none sqrt none
> Levels: log none rank sqrt
> 
> I would like to add an ordering to the levels.
> none<sqrt<log<rank
> 
> I tried with 
> tmp$norm <-factor(tmp$norm,labels = c("none","sqrt","log","rank"),ordered=T)
> 
>>tmp$norm
> 
>  [1] log  log  log  log  log  none none none log  rank rank rank none none log 
> [16] log  log  rank rank rank rank none none none none rank sqrt sqrt sqrt sqrt
> [31] sqrt sqrt sqrt sqrt rank sqrt
> Levels: none < sqrt < log < rank
> 
> But this is not what I would like to have because the command not only superimposes an ordering but also changes the factors!
> 
> Eryk
> 

Eryk,
   See ?factor or ?ordered which will help. I think what you want is:

lev <- c("none", "sqrt", "log", "rank")
tmp$norm <- ordered(tmp$norm, levels = lev)

or

tmp$norm <- factor(tmp$norm, levels = lev, ordered = TRUE)

Note the use of "levels" and not "labels".

--sundar



From ggrothendieck at myway.com  Mon Jul 26 21:12:30 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 26 Jul 2004 15:12:30 -0400 (EDT)
Subject: [R] aggregate function
Message-ID: <20040726191230.A4CF012D05@mprdmxin.myway.com>


[Sorry if this gets posted twice.  I have been having some
problems with gmane posting.]

We can use rowsum like this:

	> rowsum(frame$Total * (frame[,3:5]>0), frame$Year)

	Tus Whi Norw
	1994 1 0.00 1
	1995 1 1.00 1
	1997 2 4.00 5
	1998 0 0.00 1
	1999 1 2.04 2

Note that only years that are actually present will be in the
resulting matrix. 1996 is not in the sample data in your post
so there is no row for 1996. If that's not a problem or if your 
real data covers all the years anyways we are done.

If missing years is a problem then merge in some zero rows with
the years first. The first two lines below do this and the third 
line is the same as the line above:

	> frame <- merge(frame, 1994:1999, by = 1, all = TRUE)
	> frame[is.na(frame)] <- 0

	> rowsum(frame$Total * (frame[,3:5]>0), frame$Year)

	Tus Whi Norw
	1994 1 0.00 1
	1995 1 1.00 1
	1996 0 0.00 0 <-- now we have a row for 1996
	1997 2 4.00 5
	1998 0 0.00 1
	1999 1 2.04 2


Luis Rideau Cruz <Luisr at frs.fo> :

I have the folowing frame(there are more columns than shown),
1 2 3 4 5
Year Total Tus Whi Norw
1994 1.00 1830 0 355
1995 1.00 0 0 0
1995 1.00 0 0 0
1995 1.00 4910 4280 695
1997 1.00 0 0 110
1997 0.58 0 0 0
1997 1.00 0 0 0
1994 1.00 0 0 0
1997 1.00 0 40 70
1998 1.00 0 0 1252
1999 1.04 0 74 0
1999 1.00 0 0 0
1999 1.02 0 0 0
1999 1.00 0 0 0
1999 1.00 0 0 171
1999 1.00 1794 0 229
1999 1.00 0 3525 0
1997 1.00 1335 1185 147
1997 1.00 4925 1057 4801
1997 1.00 0 6275 1773

I try to get sum("Total") by "Year" in which Tus>0, sum("Total") by "Year" in which Whi>0,,,and so on.

I have done something like this;

a<-as.list(numeric(3))
for (i in 3:5)
{
a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
Tus=frame$"i">0),sum)
}

But I get

"Error in FUN(X[[as.integer(1)]], ...) : arguments must have same length"

Also by doing one by one

aggregate(frame[,"Total"],list(Year=frame$"Year",
Tus=frame$"Tus">0),sum)


The result is something like;

Year Tus x
1994 FALSE 49.69
1995 FALSE 49.35
1996 FALSE 56.95
1997 FALSE 57.00
1998 FALSE 57.00
1999 FALSE 58.09
2000 FALSE 56.97
2001 FALSE 57.95
2002 FALSE 57.10
2003 FALSE 56.16
2000 TRUE 1.00
2002 TRUE 1.00
2003 TRUE 2.01



From andy_liaw at merck.com  Mon Jul 26 21:16:45 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 26 Jul 2004 15:16:45 -0400
Subject: [R] installing problems repeated.tgz linux
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8106@usrymx25.merck.com>

I downloaded repeated.tgz and tried it myself on one of our AMD Opterons
running SLES8, and it worked (R-1.9.1 compiled as 64-bit).  Notice that I do
get a couple of warnings from gcc about labels, and from g77 about the use
of `sum' function.

Andy

[andy at leo:lindsey]% R CMD INSTALL -l ~/rlibs repeated
* Installing *source* package 'repeated' ...
** libs
g77   -fPIC  -O2 -m64 -msse2 -march=k8 -mcpu=k8 -g -c chidden.f -o chidden.o
g77   -fPIC  -O2 -m64 -msse2 -march=k8 -mcpu=k8 -g -c cphidden.f -o
cphidden.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c cutil.c -o cutil.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c dist.c -o dist.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c gar.c -o gar.o
g77   -fPIC  -O2 -m64 -msse2 -march=k8 -mcpu=k8 -g -c hidden.f -o hidden.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c kcountb.c -o kcountb.o
kcountb.c: In function `kcountb':
kcountb.c:263: warning: deprecated use of label at end of compound statement
kcountb.c:270: warning: deprecated use of label at end of compound statement
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c kserieb.c -o kserieb.o
g77   -fPIC  -O2 -m64 -msse2 -march=k8 -mcpu=k8 -g -c logitord.f -o
logitord.o
g77   -fPIC  -O2 -m64 -msse2 -march=k8 -mcpu=k8 -g -c binnest.f -o binnest.o
binnest.f: In subroutine `calcbn':
binnest.f:537: warning:
                    J_Prod = J_Prod * Sum(H2,uph2) ! Calculate the product
of J
                                      ^
Reference to unimplemented intrinsic `SUM' at (^) (assumed EXTERNAL)
binnest.f: In subroutine `calcbn2':
binnest.f:1255: warning:
                    J_Prod = J_Prod * Sum(H2,uph2) ! Calculate the product
of J
                                      ^
Reference to unimplemented intrinsic `SUM' at (^) (assumed EXTERNAL)
g77   -fPIC  -O2 -m64 -msse2 -march=k8 -mcpu=k8 -g -c gausscop.f -o
gausscop.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c gaps.c -o gaps.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c calcs.c -o calcs.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c calcs1.c -o calcs1.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c calcs2.c -o calcs2.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c calcs3.c -o calcs3.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include   -fPIC  -O7 -m64
-msse2 -march=k8 -mcpu=k8 -g -c calcs4.c -o calcs4.o
gcc -shared -o repeated.so chidden.o cphidden.o cutil.o dist.o gar.o
hidden.o kcountb.o kserieb.o logitord.o binnest.o gausscop.o gaps.o calcs.o
calcs1.o calcs2.o calcs3.o calcs4.o -L/usr/local/lib
-L/opt/gcc33/lib64/gcc-lib/x86_64-suse-linux/3.3
-L/opt/gcc33/lib64/gcc-lib/x86_64-suse-linux/3.3/../../../../lib64
-L/opt/gcc33/lib64/gcc-lib/x86_64-suse-linux/3.3/../../.. -L/lib/../lib64
-L/usr/lib/../lib64 -lfrtbegin -lg2c -lm -lgcc_s
** R
** help
 >>> Building/Updating help pages for package 'repeated'
     Formats: text html latex example 
[snipped.  I think you get the idea...]


> From: Liaw, Andy
> 
> Sorry, Christian.  I have no idea what those error messages 
> in German say.
> 
> Andy
> 
> > From: ozric at web.de 
> > 
> > Hello,
> > 
> >  thanks for your and Marc's hint, but it seems not the probleme!?
> > Is there any  probleme with my make?
> > 
> > many thanks and regards, 
> > christian
> > 
> > 
> > chris at linux:/usr/lib/R> R CMD INSTALL 
> > -l /usr/lib/R/library  /space/downs/repeated.tgz
> > * Installing *source* package 'repeated' ...
> > ** libs
> > /usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enth??lt 
> > kein ??%??.  
> > Schluss.
> > ERROR: compilation failed for package 'repeated'
> > ** Removing '/usr/lib/R/library/repeated'
> > 
> > chris at linux:/usr/lib/R> R CMD INSTALL 
> > -l /usr/lib/R/library  /space/downs/repeated
> > * Installing *source* package 'repeated' ...
> > ** libs
> > /usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enth??lt 
> > kein ??%??.  
> > Schluss.
> > ERROR: compilation failed for package 'repeated'
> > ** Removing '/usr/lib/R/library/repeated'
> > 
> > ...with your great RandomForest and other packages 
> > it works!
> > 
> > chris at linux:/usr/lib/R> R CMD INSTALL 
> > -l /usr/lib/R/library  /space/downs/randomForest*.tar.gz
> > * Installing *source* package 'randomForest' ...
> > ** libs
> > gcc -I/usr/lib/R/include  -I/usr/local/include -I/opt/gnome/include 
> > -D__NO_MATH_INLINES -mieee-fp  -fPIC   -c regrf.c -o regrf.o
> > g77 -mieee-fp  -fPIC   -c regrfsub.f -o regrfsub.o
> > gcc -I/usr/lib/R/include  -I/usr/local/include -I/opt/gnome/include 
> > -D__NO_MATH_INLINES -mieee-fp  -fPIC   -c rf.c -o rf.o
> > g77 -mieee-fp  -fPIC   -c rfsub.f -o rfsub.o
> > gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o 
> > randomForest.so regrf.o 
> > regrfsub.o rf.o rfsub.o  -L/usr/local/lib -L/opt/gnome/lib 
> > -L/usr/lib/gcc-lib/i586-suse-linux/3.3.1 
> > -L/usr/lib/gcc-lib/i586-suse-linux/3.3.1/../../../../i586-suse
> > -linux/lib 
> > -L/usr/lib/gcc-lib/i586-suse-linux/3.3.1/../../.. -lfrtbegin 
> > -lg2c -lm 
> > -lgcc_s -L/usr/lib/R/bin -lR
> > ** R
> > ** inst
> > ** help
> >  >>> Building/Updating help pages for package 'randomForest'
> >      Formats: text html latex example
> >   MDSplot                           text    html    latex   example
> >   combine                           text    html    latex   example
> >   getTree                           text    html    latex   example
> >   grow                              text    html    latex   example
> >   importance                        text    html    latex
> >   margin                            text    html    latex   example
> >   na.roughfix                       text    html    latex   example
> >   partialPlot                       text    html    latex   example
> >   plot.randomForest                 text    html    latex   example
> >   predict.randomForest              text    html    latex   example
> >   randomForest                      text    html    latex   example
> >   rfImpute                          text    html    latex   example
> >   treesize                          text    html    latex   example
> >   tuneRF                            text    html    latex   example
> >   varImpPlot                        text    html    latex   example
> >   varUsed                           text    html    latex   example
> > * DONE (randomForest)
> > 
> > 
> > 
> > 
> > 
> > 
> > Am Montag, 26. Juli 2004 18:56 schrieb Liaw, Andy:
> > > > From: Christian Schulz
> > > >
> > > > Hi,
> > > >
> > > > i try several possibilities adn looking in the archive,
> > > >  but didn't getting success to install  j.lindsey's  
> > usefuel "library
> > > > repeated" on my linux (suse9.0 with kernel 2.6.7,R.1.9.1)
> > > >
> > > > P.S. Windows, works  fine
> > > >
> > > > Many thanks for help
> > > > Christian
> > > >
> > > > > R CMD INSTALL - l /usr/lib/R/library   repeated
> > >
> > >                    ^
> > > Try again without that space.
> > >
> > > Andy
> > >
> > >
> > >
> > > 
> > --------------------------------------------------------------
> > -------------
> > >--- Notice:  This e-mail message, together with any 
> > attachments, contains
> > > information of Merck & Co., Inc. (One Merck Drive, 
> > Whitehouse Station, New
> > > Jersey, USA 08889), and/or its affiliates (which may be 
> > known outside the
> > > United States as Merck Frosst, Merck Sharp & Dohme or MSD 
> > and in Japan, as
> > > Banyu) that may be confidential, proprietary copyrighted 
> > and/or legally
> > > privileged. It is intended solely for the use of the 
> > individual or entity
> > > named on this message.  If you are not the intended 
> > recipient, and have
> > > received this message in error, please notify us 
> > immediately by reply
> > > e-mail and then delete it from your system.
> > > 
> > --------------------------------------------------------------
> > -------------
> > >---
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
>



From wolski at molgen.mpg.de  Mon Jul 26 21:19:25 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 26 Jul 2004 21:19:25 +0200
Subject: [R] ordering of levels.
In-Reply-To: <41055659.3050404@pdf.com>
References: <200407262048050752.69B68AAE@mail.math.fu-berlin.de>
	<41055659.3050404@pdf.com>
Message-ID: <200407262119250333.0249F449@mail.math.fu-berlin.de>

Hi!
Thanks a lot.
Eryk

*********** REPLY SEPARATOR  ***********

On 7/26/2004 at 2:07 PM Sundar Dorai-Raj wrote:

>>>Wolski wrote:
>>>
>>>> Hi!
>>>> Have the following factors with the following levels.
>>>>  tmp$norm
>>>>  [1] rank rank rank rank rank log  log  log  rank sqrt sqrt sqrt log 
>>>log  rank
>>>> [16] rank rank sqrt sqrt sqrt sqrt log  log  log  log  sqrt none none
>>>none none
>>>> [31] none none none none sqrt none
>>>> Levels: log none rank sqrt
>>>> 
>>>> I would like to add an ordering to the levels.
>>>> none<sqrt<log<rank
>>>> 
>>>> I tried with 
>>>> tmp$norm <-factor(tmp$norm,labels =
>>>c("none","sqrt","log","rank"),ordered=T)
>>>> 
>>>>>tmp$norm
>>>> 
>>>>  [1] log  log  log  log  log  none none none log  rank rank rank none
>>>none log 
>>>> [16] log  log  rank rank rank rank none none none none rank sqrt sqrt
>>>sqrt sqrt
>>>> [31] sqrt sqrt sqrt sqrt rank sqrt
>>>> Levels: none < sqrt < log < rank
>>>> 
>>>> But this is not what I would like to have because the command not only
>>>superimposes an ordering but also changes the factors!
>>>> 
>>>> Eryk
>>>> 
>>>
>>>Eryk,
>>>   See ?factor or ?ordered which will help. I think what you want is:
>>>
>>>lev <- c("none", "sqrt", "log", "rank")
>>>tmp$norm <- ordered(tmp$norm, levels = lev)
>>>
>>>or
>>>
>>>tmp$norm <- factor(tmp$norm, levels = lev, ordered = TRUE)
>>>
>>>Note the use of "levels" and not "labels".
>>>
>>>--sundar



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From ripley at stats.ox.ac.uk  Mon Jul 26 21:22:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jul 2004 20:22:12 +0100 (BST)
Subject: [R] Building Windows Package
In-Reply-To: <Pine.OSF.4.55.0407261351090.209051@cs.cs.appstate.edu>
Message-ID: <Pine.LNX.4.44.0407262018180.14199-100000@gannet.stats>

You want the directory in your path specification, not the executables.  
As in

.;C:\RStools;C:\MinGW\bin;C:\perl\bin;C:\texmf\miktex\bin;
C:\HTMLws;C:\R191\R191\bin;%SystemRoot%\system32;
%SystemRoot%;%SystemRoot%\System32\Wbem;C:\Program 
Files\CommonFiles\AdaptecShared\System;
C:\Program Files\ggobi;C:\Program Files\R\rw1091\library\Rggobi\libs


On Mon, 26 Jul 2004, Alan Arnholt wrote:

> I am using R-1.9.1 with windows 2000 and trying to build a package.
> However,
> when I issue the command:
> 
> RCMD build --binary BSDA
> 
> I get:
> 
>  >>> Building/Updating help pages for package 'BSDA'
>      Formats: chm
> hhc: not found
> cp: cannot stat `C:/R191/R191/JUNK/BSDA/chm/BSDA.chm': No such file or
> direc
> tory
> make[1]: *** [chm-BSDA] Error 1
> make: *** [pkg-BSDA] Error 2
> *** Installation of BSDA failed ***
> 
> 
> My path is:
> 
> .;C:\RStools;C:\MinGW\bin;C:\perl\bin;C:\texmf\miktex\bin;C:\Rstools\zip.exe;
> C:\Rstools\unzip.exe;C:\HTMLws\hhc.exe;C:\R191\R191\bin;%SystemRoot%\system32;
> %SystemRoot%;%SystemRoot%\System32\Wbem;C:\Program
> Files\CommonFiles\AdaptecShared\System;
> C:\Program Files\ggobi;C:\Program Files\R\rw1091\library\Rggobi\libs
> 
> (HTML Help Workshop lives in- "C:\HTMLws\hhc.exe")
> 
> 
> I have the directory for HTML Help workshop in MkRules set as:
> 
> # Where does 'HTML Help Workshop' live? (unused if compiled HTML help is
> # not requested. Spaces allowed.)
> HHWDIR=C:/HTMLws
> 
> After I issue RCMD build --binary BSDA and get the error messages, if I go
> to
> `C:/R191/R191/JUNK/BSDA/chm/BSDA.hhp' and manually compile the file (with
> HTML Help
> 
> workshop) then issue the command RCMD build --binary BSDA   again...the
> package builds
> without problems.  Any ideas what I am doing wrong?  Thanks in advance for
> the help.
> 
> 
> Alan
> 
> 
> 
> 
> Alan T. Arnholt
> Associate Professor
> Dept. of Mathematical Sciences
> Appalachian State University
> 2003-2004 International Exchange Scholar
> Universidad Publica de Navarra - Nafarroako Unibertsitate Publikoa
> Pamplona,  Spain
> 
> TEL : +34 948 169 205
> CELL: +34 656 668 621
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at MedAnalytics.com  Mon Jul 26 21:39:58 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 26 Jul 2004 14:39:58 -0500
Subject: [R] installing problems repeated.tgz linux
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8106@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8106@usrymx25.merck.com>
Message-ID: <1090870798.25830.36.camel@localhost.localdomain>

I echo Andy's experience on FC2. I was able to install the package here
and got the same warning messages.

Despite trying to use some web sites to translate the german text, I am
unsure of the 'true' meaning. I think it is something pertaining to
target patterns not being found, which leads me to think that this might
be a locale/character encoding issue in the package.

Anyone?

Marc

On Mon, 2004-07-26 at 14:16, Liaw, Andy wrote:
> I downloaded repeated.tgz and tried it myself on one of our AMD Opterons
> running SLES8, and it worked (R-1.9.1 compiled as 64-bit).  Notice that I do
> get a couple of warnings from gcc about labels, and from g77 about the use
> of `sum' function.
> 
> Andy

SNIPPED

> > From: Liaw, Andy
> > 
> > Sorry, Christian.  I have no idea what those error messages 
> > in German say.
> > 
> > Andy
> > 
> > > From: ozric at web.de 
> > > 
> > > Hello,
> > > 
> > >  thanks for your and Marc's hint, but it seems not the probleme!?
> > > Is there any  probleme with my make?
> > > 
> > > many thanks and regards, 
> > > christian
> > > 
> > > 
> > > chris at linux:/usr/lib/R> R CMD INSTALL 
> > > -l /usr/lib/R/library  /space/downs/repeated.tgz
> > > * Installing *source* package 'repeated' ...
> > > ** libs
> > > /usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enthlt 
> > > kein %.  
> > > Schluss.
> > > ERROR: compilation failed for package 'repeated'
> > > ** Removing '/usr/lib/R/library/repeated'
> > > 
> > > chris at linux:/usr/lib/R> R CMD INSTALL 
> > > -l /usr/lib/R/library  /space/downs/repeated
> > > * Installing *source* package 'repeated' ...
> > > ** libs
> > > /usr/lib/R/share/make/shlib.mk:5: *** Target-Muster enthlt 
> > > kein %.  
> > > Schluss.
> > > ERROR: compilation failed for package 'repeated'
> > > ** Removing '/usr/lib/R/library/repeated'

SNIPPED



From I.Visser at uva.nl  Mon Jul 26 22:08:50 2004
From: I.Visser at uva.nl (Ingmar Visser)
Date: Mon, 26 Jul 2004 22:08:50 +0200
Subject: [R] choosing constraints for function optim method="L-BFGS-B"
	whenthey are in terms of other parameter values
Message-ID: <3FA98898AEAA88478AD68CEE89A68C48B56B7B@rea04.fmg.uva.nl>

Hi Tom,

I am not entirely sure what the problem, you haven't been very specific.
If you want general linear constraints on your parameters, ie linear combinations of 
parameters summing to some value, constrOptim may be of help.

hth, ingmar

Ingmar Visser
Developmental Processes Research Group
Department of Psychology
University of Amsterdam
http://users.fmg.uva.nl/ivisser/



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch on behalf of Tom Stone
Sent: Mon 7/26/2004 4:57 PM
To: r-help at stat.math.ethz.ch
Subject: [R] choosing constraints for function optim method="L-BFGS-B" whenthey are in terms of other parameter values
 
I have a function of several variables which I wish to minimise over four
variables, two of the upper bounds for which are defined in terms of other
variables in the model over which minimisation will take place. I cannot
work out how to code this in such a way as to avoid getting an error message
when I run the code.

If anyone can provide any assistance I will be most grateful.

Best Regards

Tom Stone

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From stoffer at pitt.edu  Mon Jul 26 22:26:03 2004
From: stoffer at pitt.edu (David Stoffer)
Date: Mon, 26 Jul 2004 16:26:03 -0400
Subject: [R] spec.pgram() possible bug
Message-ID: <4105309B.462.1624E83@localhost>


> test=spec.pgram(rnorm(128,0,1), kernel("daniell",1))
> test$df
[1] 5.374771

df should be 6= 2*(2*m+1) where m=1 in this case

... and so on



From mmccall at mail.nih.gov  Mon Jul 26 22:30:30 2004
From: mmccall at mail.nih.gov (Matt McCall)
Date: Mon, 26 Jul 2004 16:30:30 -0400
Subject: [R] Significance Test for Correlation Coefficients
Message-ID: <A3653568-DF42-11D8-9E07-000A95AFE190@mail.nih.gov>

Hello all,
I have a set of  microarray timeseries (approx. 18000 genes and 7 time 
points per gene) data that I have correlated with a template (a vector 
of length 7).  I have also correlated random data from a normal 
distribution with the same mean and standard deviation as my data set 
with the template, as well as, correlating a random permutation of my 
data set with the template.  So I now have 3 vectors of length 18000 
contains correlation coefficients.  I was wondering if there was a test 
in R to determine if the correlation coefficients are significantly 
different.  In particular, I want to compare the correlation 
coefficients from my data set with each of the other two.  Thank you 
for any help you can give me.
Sincerely,
Matt



From kkthird at yahoo.com  Mon Jul 26 22:52:40 2004
From: kkthird at yahoo.com (KKThird@Yahoo.Com)
Date: Mon, 26 Jul 2004 13:52:40 -0700 (PDT)
Subject: [R] Problem with a while loop embedded in a function.
Message-ID: <20040726205240.19332.qmail@web52502.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040726/c111debb/attachment.pl

From ripley at stats.ox.ac.uk  Mon Jul 26 22:57:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jul 2004 21:57:19 +0100 (BST)
Subject: [R] spec.pgram() possible bug
In-Reply-To: <4105309B.462.1624E83@localhost>
Message-ID: <Pine.LNX.4.44.0407262143080.20678-100000@gannet.stats>

Perhaps you could take the trouble to read the references (or the code)?
Hint: do you know about tapering and how to work out its effect?

On Mon, 26 Jul 2004, David Stoffer wrote:

> > test=spec.pgram(rnorm(128,0,1), kernel("daniell",1))
> > test$df
> [1] 5.374771
> 
> df should be 6= 2*(2*m+1) where m=1 in this case
> 
> ... and so on

> spec.pgram(rnorm(128,0,1), kernel("daniell",1), taper=0)$df
[1] 6

is what you have calculated, inappropriately for the call you 
actually used.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andrewr at uidaho.edu  Mon Jul 26 23:08:31 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Tue, 27 Jul 2004 07:08:31 +1000
Subject: [R] binning a vector
Message-ID: <1af3fe1b3af7.1b3af71af3fe@uidaho.edu>

Also, you can use cut and tapply to calculate means by bins.  

Andrew

----- Original Message -----
From: Deepayan Sarkar <deepayan at stat.wisc.edu>
Date: Tuesday, July 27, 2004 3:38 am
Subject: Re: [R] binning a vector

> On Monday 26 July 2004 10:11, Arne.Muller at aventis.com wrote:
> > Hello,
> >
> > I was wondering wether there's a function in R that takes two 
> vectors> (of same length) as input and computes mean values for bins
> > (intervals) or even a sliding window over these vectros.
> >
> > I've several x/y data set (input/response) that I'd like plot
> > together. Say the x-data for one data set goes from -5 to 14 with
> > 12,000 values, then I'd like to bin the x-vector in steps of +1 and
> > calculate and plot the mean of the x-values and the y-values within
> > each bin.
> >
> > I was browsing the R-docs but couldn't find anything appropiate.
> 
> Do you know about loess? It's not exactly what you describe, but 
> maybe 
> it's what you really want.
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From arnholt at cs.cs.appstate.edu  Mon Jul 26 23:15:03 2004
From: arnholt at cs.cs.appstate.edu (Alan Arnholt)
Date: Mon, 26 Jul 2004 17:15:03 -0400 (EDT)
Subject: [R] Building Windows Package
In-Reply-To: <Pine.LNX.4.44.0407262018180.14199-100000@gannet.stats>
References: <Pine.LNX.4.44.0407262018180.14199-100000@gannet.stats>
Message-ID: <Pine.OSF.4.55.0407261714330.215222@cs.cs.appstate.edu>

Thanks.  It works great now!

Alan

Alan T. Arnholt
Associate Professor
Dept. of Mathematical Sciences
Appalachian State University
2003-2004 International Exchange Scholar
Universidad Publica de Navarra - Nafarroako Unibertsitate Publikoa
Pamplona,  Spain

TEL : +34 948 169 205
CELL: +34 656 668 621

On Mon, 26 Jul 2004, Prof Brian Ripley wrote:

> You want the directory in your path specification, not the executables.
> As in
>
> .;C:\RStools;C:\MinGW\bin;C:\perl\bin;C:\texmf\miktex\bin;
> C:\HTMLws;C:\R191\R191\bin;%SystemRoot%\system32;
> %SystemRoot%;%SystemRoot%\System32\Wbem;C:\Program
> Files\CommonFiles\AdaptecShared\System;
> C:\Program Files\ggobi;C:\Program Files\R\rw1091\library\Rggobi\libs
>
>
> On Mon, 26 Jul 2004, Alan Arnholt wrote:
>
> > I am using R-1.9.1 with windows 2000 and trying to build a package.
> > However,
> > when I issue the command:
> >
> > RCMD build --binary BSDA
> >
> > I get:
> >
> >  >>> Building/Updating help pages for package 'BSDA'
> >      Formats: chm
> > hhc: not found
> > cp: cannot stat `C:/R191/R191/JUNK/BSDA/chm/BSDA.chm': No such file or
> > direc
> > tory
> > make[1]: *** [chm-BSDA] Error 1
> > make: *** [pkg-BSDA] Error 2
> > *** Installation of BSDA failed ***
> >
> >
> > My path is:
> >
> > .;C:\RStools;C:\MinGW\bin;C:\perl\bin;C:\texmf\miktex\bin;C:\Rstools\zip.exe;
> > C:\Rstools\unzip.exe;C:\HTMLws\hhc.exe;C:\R191\R191\bin;%SystemRoot%\system32;
> > %SystemRoot%;%SystemRoot%\System32\Wbem;C:\Program
> > Files\CommonFiles\AdaptecShared\System;
> > C:\Program Files\ggobi;C:\Program Files\R\rw1091\library\Rggobi\libs
> >
> > (HTML Help Workshop lives in- "C:\HTMLws\hhc.exe")
> >
> >
> > I have the directory for HTML Help workshop in MkRules set as:
> >
> > # Where does 'HTML Help Workshop' live? (unused if compiled HTML help is
> > # not requested. Spaces allowed.)
> > HHWDIR=C:/HTMLws
> >
> > After I issue RCMD build --binary BSDA and get the error messages, if I go
> > to
> > `C:/R191/R191/JUNK/BSDA/chm/BSDA.hhp' and manually compile the file (with
> > HTML Help
> >
> > workshop) then issue the command RCMD build --binary BSDA   again...the
> > package builds
> > without problems.  Any ideas what I am doing wrong?  Thanks in advance for
> > the help.
> >
> >
> > Alan
> >
> >
> >
> >
> > Alan T. Arnholt
> > Associate Professor
> > Dept. of Mathematical Sciences
> > Appalachian State University
> > 2003-2004 International Exchange Scholar
> > Universidad Publica de Navarra - Nafarroako Unibertsitate Publikoa
> > Pamplona,  Spain
> >
> > TEL : +34 948 169 205
> > CELL: +34 656 668 621
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From adiamond at fas.harvard.edu  Tue Jul 27 00:07:43 2004
From: adiamond at fas.harvard.edu (adiamond@fas.harvard.edu)
Date: Mon, 26 Jul 2004 18:07:43 -0400
Subject: [R] qcc package & syndromic surveillance (multivar CUSUM?)
Message-ID: <1090879663.410580af95351@webmail.fas.harvard.edu>

Dear R Community:

I am working on a public health early warning system, and 
I see that the qcc package allows for CUSUM and other statistical quality tests
but I am not sure if my project is a good match for qcc functions as written.
Any advice you may have is very much appreciated.

I have four years worth of daily counts of emergency room admissions for 
different conditions (e.g. respiratory, neurologic, etc) from several local 
hospitals.  the data looks like this...

DAY 1
              Respiratory     Neuro   ...
Hospital A:       10		12
.                  .             .
.                  .             .
Hospital F:        7            14


DAY 2         Respiratory     Neuro   ...
Hospital A:       10		12
.                  .             .
.                  .             .
Hospital F:        7            14    ...

etc.,

and my goal is to do a kind of multivariate quality control test (without 
fitting a GLM), that would run each day after the data is updated and be able 
to answer the question: 
"Has there been a significant variation in the central tendency of the data?"

An analogous problem would be detecting the early signs of a shift in global 
trading patterns by examining stock market indexes in different countries 
around the world, updating and testing the data each business day. 

Thank you, 

Alexis Diamond



From jdi106 at psu.edu  Tue Jul 27 00:16:56 2004
From: jdi106 at psu.edu (Jordan Irvin)
Date: Mon, 26 Jul 2004 18:16:56 -0400
Subject: [R] bad restore file magic number
Message-ID: <BD2AFB18.2E53%jdi106@psu.edu>

I'm running R 1.9.1 and trying to load a macro I've written.  It gives the e
Error: bad restore file magic number (file may be corrupted)-- no data
loaded

what does this error mean, and how can I fix this problem.

thanks,
jordan



From jgentry at jimmy.harvard.edu  Tue Jul 27 00:19:09 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 26 Jul 2004 18:19:09 -0400 (EDT)
Subject: [R] bad restore file magic number
In-Reply-To: <BD2AFB18.2E53%jdi106@psu.edu>
Message-ID: <Pine.SOL.4.20.0407261818330.4385-100000@jaws.dfci.harvard.edu>

> I'm running R 1.9.1 and trying to load a macro I've written.  It gives the e
> Error: bad restore file magic number (file may be corrupted)-- no data
> loaded

You probably want to use source() here, if you have the code in a
file.  The load() command is for use with stuff saved via the
save() command.

-J



From mayeul.kauffmann at tiscali.fr  Tue Jul 27 00:28:45 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Tue, 27 Jul 2004 00:28:45 +0200
Subject: [R] covariate selection in cox model (counting process)
Message-ID: <000c01c4735f$ea6436a0$5ce29a53@amd>

Thank you a lot for your time and your answer, Thomas. Like all good
answers, it raised new questions for me ;-)

>In the case of recurrent events coxph() is not
> using maximum likelihood or even maximum partial likelihood. It is
> maximising the quantity that (roughly speaking) would be the partial
> likelihood if the covariates explained all the cluster differences.

I could have non repeating events by removing countries once they have
experienced a war. But I'm not sure it will change the estimation
procedure since this will change the dataset only, not the formula
coxph(Surv(start,stop,status)~x1+x2+...+cluster(id),robust=T)

I am not sure I understood you well: do you really mean "recurrent events"
alone or "any counting process notation (including allowing for recurrent
events)".


I thought the counting process notation did not differ really from the Cox
model in R, since Terry M. Therneau (A Package for Survival Analysis in S,
April 22, 1996) concludes his mathematical section "3.3 Cox Model" by "The
above notation is derived from the counting process representation [...]
It allows very naturally for several extensions to the original Cox model
formulation: multiple events per subject, discontinuous intervals of risk
[...],left truncation." (I used it to introduce 1. time-dependent
covariates, some covariates changing yearly, other irregularly, and 2.
left truncation: not all countries existed at the beginning of the study)


>In the case of recurrent events coxph() is not
> using maximum likelihood or even maximum partial likelihood.

Then, what does fit$loglik give in this case? Still a likelihood or a
valid criterion to maximise ?
If not, how to get ("manually") the criterion that was maximsed?

That's of interest for me since
> I created artificial covariates measuring the proximity since some
events: exp(-days.since.event/a.chosen.parameter).

...and I used fit$loglik to chose a.chosen.parameter from 8 values, for 3
types of events:


la<-c(263.5, 526.9,1053.9,2107.8,4215.6,8431.1) #list of values to choose
from
z<-NULL;for(a1 in la) for(a2 in la) for(a3 in la) {coxtmp <-
(coxph(Surv(start,stop,status)~
+I(exp(-days.since.event.of.type.one/a1))
+I(exp(-days.since.event.of.type.two/a2))
+I(exp(-days.since.event.of.type.three/a3))
+ other.time.dependent.covariates
+cluster(id)
,data=x,robust=T))
rbind(z,c(a1,a2,a3,coxtmp$wald.test, coxtmp$rscore, coxtmp$loglik,
coxtmp$score))->z
}
z <- data.frame(z)
names(z) <- c("a1","a2", "a3","wald.test", "rscore",
"NULLloglik","loglik", "score")
z[which.max(z$rscore),]
z[which.max(z$loglik),]

The last two commands gave me almost always the same set for c(a1,a2,a3).
But they sometimes differed significantly on some models.

Which criteria (if any ?!) should I use to select the best set c(a1,a2,a3)
?


(If you wish to see what the proximity variables look like, run the
following code. The dashed lines show the "half life" of the proximity
variable,here=6 months, which is determined by a.chosen.parameter, e.g.
a1=la[1]:
#start of code
curve(exp(-(x)/263.5),0,8*365.25,xlab="number of days since last political
regime change (dsrc)",ylab="Proximity of political regime change =
exp(-dsrc/263.5)",las=1)
axis(1,at=365.25/2, labels= "(6 months)");axis(2,at=seq(0,1,.1),las=1)
lines(c(365.25/2,365.25/2,-110),c(-.05,0.5,0.5),lty="dashed")
#end of code)



Thanks a lot again.

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France



From edd at debian.org  Tue Jul 27 01:17:49 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 26 Jul 2004 18:17:49 -0500
Subject: [R] lattice / pdf bug ?
Message-ID: <20040726231749.GA8659@sonny.eddelbuettel.com>


I've been scrathing my head over this one.  Suppose I have a data.frame
which maps to a 'n x k' lattice, and that one of those cells is empty.

An artificial example is generated by

Q<-data.frame(x1=sample(c("A","B"),10,replace=TRUE),
              x2=c("C", rep("D",9)), y=rnorm(10))

where by having only one obs. for the first level of the second factor x2,
we ensure that there won't be full combinations of x1 and x2.

This seems to trip panel.mathdensity(), but only when printing to pdf, and I
can't find a way to avoid it. Consider

		  
stopifnot(require(lattice))
stopifnot(require(grid))

pdf("testfile.pdf")
Q<-data.frame(x1=sample(c("A","B"),10,replace=TRUE),
              x2=c("C", rep("D",9)), y=rnorm(10))
print(histogram(~ y | x1+x2, data=Q,
                panel = function(x, ...) {
                  if (length(x) > 0) {
		    panel.histogram(x, ...)
                    panel.mathdensity(dmath = dnorm, col = "black",
                                      args = list(mean=mean(x, na.rm=TRUE), 
                       		                  sd=sd(x, na.rm=TRUE)))
                  }
                }))
dev.off()


where the resulting pdf file is broken if and only if the panel.mathdensity
call is present.  Without it, it works.  To the screen, it works with and
without -- but copying to pdf again  breaks the pdf file if
panel.mathdensity is used.

It is possible that I am overlooking something simple -- or is it a genuine
bug?

Platform is win2k, R version is 1.9.1.

Thanks for any pointers,  Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From deepayan at stat.wisc.edu  Tue Jul 27 01:50:13 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 26 Jul 2004 18:50:13 -0500
Subject: [R] lattice / pdf bug ?
In-Reply-To: <20040726231749.GA8659@sonny.eddelbuettel.com>
References: <20040726231749.GA8659@sonny.eddelbuettel.com>
Message-ID: <200407261850.13634.deepayan@stat.wisc.edu>

On Monday 26 July 2004 18:17, Dirk Eddelbuettel wrote:
> I've been scrathing my head over this one.  Suppose I have a
> data.frame which maps to a 'n x k' lattice, and that one of those
> cells is empty.
>
> An artificial example is generated by
>
> Q<-data.frame(x1=sample(c("A","B"),10,replace=TRUE),
>               x2=c("C", rep("D",9)), y=rnorm(10))
>
> where by having only one obs. for the first level of the second
> factor x2, we ensure that there won't be full combinations of x1 and
> x2.

The empty cell is not the issue, rather it's the fact that the panel 
that gets the first observation (x2 = "C") has only that one single 
observation. So for that panel, sd(x, na.rm = TRUE) = NA, hence 

dnorm(<mesh points>, mean = <whatever>, sd = NA) 

eventually produces a bunch of NA's, which grid.lines tries to draw. 
grid.lines has known issues with NA's, and I would guess that's what 
causes the broken pdf.

The good news is that there doesn't seem to be any problems in r-devel 
(possibly because grid handles NA's better now).

The natural workaround for your code would be to skip the 
panel.mathdensity call unless length(x) > 1.

Deepayan


> This seems to trip panel.mathdensity(), but only when printing to
> pdf, and I can't find a way to avoid it. Consider
>
>
> stopifnot(require(lattice))
> stopifnot(require(grid))
>
> pdf("testfile.pdf")
> Q<-data.frame(x1=sample(c("A","B"),10,replace=TRUE),
>               x2=c("C", rep("D",9)), y=rnorm(10))
> print(histogram(~ y | x1+x2, data=Q,
>                 panel = function(x, ...) {
>                   if (length(x) > 0) {
> 		    panel.histogram(x, ...)
>                     panel.mathdensity(dmath = dnorm, col = "black",
>                                       args = list(mean=mean(x,
> na.rm=TRUE), sd=sd(x, na.rm=TRUE))) }
>                 }))
> dev.off()
>
>
> where the resulting pdf file is broken if and only if the
> panel.mathdensity call is present.  Without it, it works.  To the
> screen, it works with and without -- but copying to pdf again  breaks
> the pdf file if
> panel.mathdensity is used.
>
> It is possible that I am overlooking something simple -- or is it a
> genuine bug?
>
> Platform is win2k, R version is 1.9.1.
>
> Thanks for any pointers,  Dirk



From spencer.graves at pdf.com  Tue Jul 27 03:07:17 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 26 Jul 2004 18:07:17 -0700
Subject: [R] qcc package & syndromic surveillance (multivar CUSUM?)
In-Reply-To: <1090879663.410580af95351@webmail.fas.harvard.edu>
References: <1090879663.410580af95351@webmail.fas.harvard.edu>
Message-ID: <4105AAC5.5060801@pdf.com>

      What do you think is most plausible:  an abrupt jump or a gradual 
drift?  To detect an abrupt jump from a null hypothesis H0 to an 
alternative H1, the tool of choice seems to be a cumulative sum (CUSUM) 
of log(likelihood ratio).  If H0 and H1 are normal distributions with 
equal variances, this general rule specializes to a one-sided cumulative 
sum of (y[t]-mu.bar), where mu.bar is the average of the means under H0 
and H1. 

      However, to detect a gradual drift modeled as a random walk, the 
theory says that the best tool is something like an exponentially 
weighted moving average (EWMA). 

      For monitor design, I like to write the following: 

      joint = observation * prior = posterior * predictive

      f(y & mu) = f(y | mu)*f(mu) = f(mu | y)*f(y). 

When each observation arrives, I test to see if it is consistent with 
the predictive distribution f(y).  If it is not consistent, I report a 
potential problem.  If it is consistent, I incorporate it into the EWMA 
[or CUSUM], as described by the posterior f(mu | y).  For more 
information on this, see "Bayes' Rule of Information" and other 
"foundations of monitoring" reports downloadable from 
"www.prodsyse.com".  This kind if use of the predictive distribution is 
discussed in the West and Harrison (1999) book cited in the "Bayes' 
Rule" paper, and a Poisson EWMA is derived on p. 5. 

      What you use, of course, depends on the events you hope to 
capture.  For your applications, I might consider running separate 
monitors on each condition-hospital pair plus monitors on the totals for 
each hospital and for each condition, plus one for overall.  I might use 
the qcc package to calibrate my thresholds, but do the daily 
computations in some data base system. 

      Selecting thresholds is not easy, in part because the assumptions 
you make for monitor design will never hold exactly in practice.  The 
result of this is that any thresholds you compute based purely on theory 
will be wrong.  However, if you tune your thresholds based on the years 
of historical data you have, you should be on safer ground.  This theory 
should get you close to an optimal arrangement.  I think I would use 
quite loose thresholds for the hospital-condition (interaction) 
monitors, thighter thresholds for the condition and hospital totals, and 
the tightest threshold for the overall.  Monitors on specific conditions 
should be sensitive to epidemics or to an effective biological warfare 
terrorist attack;  if this is your concern, a CUSUM might be best.  
Monitors on specific hospitals should be sensitive to changes in the 
competence of local staff (suggesting a preference for an EWMA) or to a 
sudden local outbreak of something (suggesting a CUSUM).  Monitors on 
condition-hospital pairs might be sensitive to local changes in 
preferred diagnoses.  I would run Cusums or EWMAs but not both:  Either 
will catch conditions most quickly caught by the other, with possible a 
little longer delay. 

      hope this helps.  spencer graves

adiamond at fas.harvard.edu wrote:

>Dear R Community:
>
>I am working on a public health early warning system, and 
>I see that the qcc package allows for CUSUM and other statistical quality tests
>but I am not sure if my project is a good match for qcc functions as written.
>Any advice you may have is very much appreciated.
>
>I have four years worth of daily counts of emergency room admissions for 
>different conditions (e.g. respiratory, neurologic, etc) from several local 
>hospitals.  the data looks like this...
>
>DAY 1
>              Respiratory     Neuro   ...
>Hospital A:       10		12
>.                  .             .
>.                  .             .
>Hospital F:        7            14
>
>
>DAY 2         Respiratory     Neuro   ...
>Hospital A:       10		12
>.                  .             .
>.                  .             .
>Hospital F:        7            14    ...
>
>etc.,
>
>and my goal is to do a kind of multivariate quality control test (without 
>fitting a GLM), that would run each day after the data is updated and be able 
>to answer the question: 
>"Has there been a significant variation in the central tendency of the data?"
>
>An analogous problem would be detecting the early signs of a shift in global 
>trading patterns by examining stock market indexes in different countries 
>around the world, updating and testing the data each business day. 
>
>Thank you, 
>
>Alexis Diamond
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From spencer.graves at pdf.com  Tue Jul 27 04:02:28 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 26 Jul 2004 19:02:28 -0700
Subject: [R] dumpClass
Message-ID: <4105B7B4.7070404@pdf.com>

      What do people do in R to get something comparable to the 
functionality of "dumpClass" described by Chambers (1998) Programming 
with Data (Springer)? 

      Thanks,
      spencer graves



From arin99 at rediffmail.com  Tue Jul 27 04:46:34 2004
From: arin99 at rediffmail.com (Arin Basu)
Date: 27 Jul 2004 02:46:34 -0000
Subject: [R] Reading SPSS file
Message-ID: <20040727024634.19258.qmail@mailweb33.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040727/9fef7b3e/attachment.pl

From Eve.McDonald-Madden at dse.vic.gov.au  Tue Jul 27 04:51:06 2004
From: Eve.McDonald-Madden at dse.vic.gov.au (Eve.McDonald-Madden@dse.vic.gov.au)
Date: Tue, 27 Jul 2004 12:51:06 +1000
Subject: [R] re: help with lattice plot
Message-ID: <OFDFF410BF.0E78EB0F-ONCA256EDE.000E4422-CA256EDE.000FAA0C@nre.vic.gov.au>

Dear List,

I have been using R to create an xyplot using the panel function within
lattice libraries. This plot is based on the data supplied in R named
'Oats'. The graph represents oat yield by nitro level with an overlay of
each variety of oats for each nitro level.

I have three questions regarding this graph:
1) I cannot seem to specify the type of symbol used by the plot, even
though it is included in the code below, it will change when the code is
changed?
2) I have managed to include a legend on the graph using the key function;
however the labels of the legend do not seem to correspond to the right
coloured symbol as used in the plot itself for Variety. How can I get the
symbols and text in the legend to match that used in the graph itself?
3) Also, I am interested to know how I can manipulate the order in which
each graph (in this instance Nitro level) appears? For example, at the
moment the graphs do not appear in numerical order (based on the levels of
the factor nitro) can I reorder them so that they appear in the order   I,
II,  III,
                                                             IV,  V,   VI
?

The code I have used is included below:

##Data
library(nlme)
data(Oats)

##Factors
Oats$Block<-factor(Oats$Block)
Oats$Variety<-factor(Oats$Variety)
Oats$nitro<-factor(Oats$nitro)
attach(oats)

##Plot
library(lattice)
lset(col.whitebg())
xyplot(yield~nitro|Block, data=Oats,xlab="Nitrogen Level",ylab="Yield of
oats",subscripts=T, groups=Oats$Variety, as.table=T,
panel=function(x,y,groups,subscripts){
panel.superpose(x=x, y=y, groups=Oats$Variety,
subscripts=subscripts,pch=18)
panel.superpose(x=x, y=y, groups=Oats$Variety, subscripts=subscripts, type
="r")
}
,key = list(points = Rows(trellis.par.get("superpose.line"),c(1:2,3)),text
= list(lab = as.character(unique(Oats$Variety))),pch=18)
)


I would greatly appreciate anyone's time in assisting me with this request.

I look forward to your reply

Regards

Eve

Eve McDonald-Madden
Fauna Ecology
Arthur Rylah Institute for Environmental Research
Heidelberg, Victoria.Australia
Email:      eve.mcdonald-madden at nre.vic.gov.au



From deepayan at stat.wisc.edu  Tue Jul 27 06:20:35 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 26 Jul 2004 23:20:35 -0500
Subject: [R] re: help with lattice plot
In-Reply-To: <OFDFF410BF.0E78EB0F-ONCA256EDE.000E4422-CA256EDE.000FAA0C@nre.vic.gov.au>
References: <OFDFF410BF.0E78EB0F-ONCA256EDE.000E4422-CA256EDE.000FAA0C@nre.vic.gov.au>
Message-ID: <200407262320.35259.deepayan@stat.wisc.edu>

On Monday 26 July 2004 21:51, Eve.McDonald-Madden at dse.vic.gov.au wrote:
> Dear List,
>
> I have been using R to create an xyplot using the panel function
> within lattice libraries. This plot is based on the data supplied in
> R named 'Oats'. The graph represents oat yield by nitro level with an
> overlay of each variety of oats for each nitro level.
>
> I have three questions regarding this graph:
> 1) I cannot seem to specify the type of symbol used by the plot, even
> though it is included in the code below, it will change when the code
> is changed?

You are doing several things wrong. There's more than one way to fix it. 
For example, the approach you have taken may be modified to give (after 
the lset(col.whitebg()) call in your example):


lset(list(superpose.symbol = list(pch = 18)))
xyplot(yield ~ nitro | Block,
       data = Oats,
       xlab = "Nitrogen Level",
       ylab = "Yield of oats",
       groups = Variety,
       as.table = T,
       panel = function(x, y, groups, subscripts) {
           panel.superpose(x = x, y = y, groups = groups,
                           subscripts = subscripts)
           panel.superpose(x = x, y = y, groups = groups,
                           subscripts = subscripts,
                           type ="r")
       },
       key =
       list(points = Rows(trellis.par.get("superpose.symbol"), 1:3 ),
            text = list(lab = levels(Oats$Variety))))

A line by line comparison with your code should indicate the 
differences.

But since you are using some lattice-specific features (not available in 
S-PLUS) anyway, I would take it a bit further and simplify this to 
(again, after the lset(col.whitebg()) call in your example):

xyplot(yield ~ nitro | Block,
       data = Oats,
       xlab = "Nitrogen Level",
       ylab = "Yield of oats",
       groups = Variety,
       as.table = TRUE, 
       type = c("p", "r"),
       par.settings = list(superpose.symbol = list(pch = 18)),
       auto.key = TRUE)


> 2) I have managed to include a legend on the graph using the key
> function; however the labels of the legend do not seem to correspond
> to the right coloured symbol as used in the plot itself for Variety.
> How can I get the symbols and text in the legend to match that used
> in the graph itself? 

Wherever there's the need for 'ordering' a factor, the order is 
determined by its levels - given by the levels() function. In this 
case, the order would be given by levels(Oats$Variety), and not 
as.character(unique(Oats$Variety)) which you were using for some 
reason. This fact is relevant to your next question as well.

> 3) Also, I am interested to know how I can 
> manipulate the order in which each graph (in this instance Nitro
> level) appears? For example, at the moment the graphs do not appear
> in numerical order (based on the levels of the factor nitro) can I
> reorder them so that they appear in the order   I, II,  III,
>                                                              IV,  V, 
>  VI ?

Surely you mean Block and not nitro?

It behaves in this way because that's the order given by 
levels(Oats$Block) (the reason should be apparent after 
reading ?groupedData from nlme). You can choose your own order when 
using the factor function (your current use doesn't do anything, by the 
way):

Oats$Block <-
    factor(Oats$Block,
           levels = c("I",  "II",   "III", "IV",  "V",  "VI"))


Hope that helps,

Deepayan



From Jordi.Molins at drkw.com  Tue Jul 27 09:40:50 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Tue, 27 Jul 2004 09:40:50 +0200
Subject: [R] SVD with positivity constraints
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCD6A@ibfftce121.de.ad.drkw.net>


Hello,

I have a matrix equation, Ax=b, that I need to solve for x. x should be a
vector of positive numbers (between 0 and 1). A is not a square matrix in
general. This lead me to using the SVD. However, using the SVD gives me
positive and negative numbers, as well. I have some constraints included in
the A matrix itself (i.e., that the sum of some xi should be equal to 1) but
I do not know how to include the constraint that each xi should be
non-negative.

Is there in R (or somewhere else) an SVD that includes this kind of
constraint? or some other optimizer that can cope with solving non-square
matrix equations, including the positivity constraint?

I know that this is not really an R question, sorry for that.

Jordi


Jordi Molins

Short Term Products / Treasury
Capital Markets

> Dresdner Kleinwort Wasserstein 
phone	+49 69 713 15329
fax	+49 69 713 19804
mobile  +49 171 171 64 61
mailto:jordi.molins at drkw.com





--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From mcm41 at cam.ac.uk  Tue Jul 27 09:50:09 2004
From: mcm41 at cam.ac.uk (Martin McCabe)
Date: Tue, 27 Jul 2004 08:50:09 +0100
Subject: [R] Unable to open html help pages
Message-ID: <952219CA-DFA1-11D8-9428-000A95C9A7BE@cam.ac.uk>

I recently upgraded R to 1.9.1 for Mac from 1.8.1.  I am not able to 
open the help pages online but get the message
"If /usr/bin/open is already running, it is *not* restarted, and you 
must switch to its
     window.
Otherwise, be patient ..."
However, nothing happens.  There are not any other windows open to 
switch to and I don't know what /usr/bin/open is!  I'm using an eMac.  
I know the 1.9.1 download is only supposed to be for a PowerMac or 
PowerBook but 1.8.1 seemed to work fine on my eMac (before I downloaded 
1.9.1 and deleted it!).  Is there anything I can do to open html.help?

--------------------------------------------
Dr. Martin G. McCabe

Cancer Research UK Clinical Research Training Fellow
Cambridge University Department of Pathology
Division of Molecular Histopathology
Box 231
Level 3, Lab Block
Addenbrooke's Hospital
Hilld Road
Cambridge
CB2 2QQ

Tel:		01223 762084
Fax:		01223 586670
email:	mcm41 at cam.ac.uk



From jajanmaat at netscape.net  Tue Jul 27 10:14:17 2004
From: jajanmaat at netscape.net (John Janmaat)
Date: Tue, 27 Jul 2004 10:14:17 +0200
Subject: [R] Underline in expression().
Message-ID: <41060ED9.5070907@netscape.net>

Hello All,

Is there an analogue to \underbar or the AMS math \underline in 
graphical math expressions?

Thanks,

John.
-- 
=====================================================================================
Dr. John Janmaat
Department of Economics
Acadia University
Wolfville, Nova Scotia, Canada
B4P 2R6
TEL: 902-585-1461
WWW: http://ace.acadiau.ca/~jjanmaat/
EMAIL: jjanmaat at acadiau.ca

June 10, 2004 to September 7, 2004
Dr. John Janmaat
Environmental Econmics and Natural Resources Group
Wageningen University.
P.O. Box 8130
6700 EW, Wageningen
The Netherlands.



From ripley at stats.ox.ac.uk  Tue Jul 27 10:12:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Jul 2004 09:12:37 +0100 (BST)
Subject: [R] SVD with positivity constraints
In-Reply-To: <AA0BBC8742AFFF4583B91782E958CB660FCD6A@ibfftce121.de.ad.drkw.net>
Message-ID: <Pine.LNX.4.44.0407270908060.21525-100000@gannet.stats>

If A is not square, which dimension is larger?  There will most likely be 
either no solution or an infinity of solutions.  If the latter, I think 
you are using the Moore-Penrose inverse (depends exactly how you use the 
SVD), that is the shortest solution, but the SVD will give you the whole 
space of solutions and you could compute if that intersects the positive 
orthant.

On Tue, 27 Jul 2004, Molins, Jordi wrote:

> I have a matrix equation, Ax=b, that I need to solve for x. x should be a
> vector of positive numbers (between 0 and 1). A is not a square matrix in
> general. This lead me to using the SVD. However, using the SVD gives me
> positive and negative numbers, as well. I have some constraints included in
> the A matrix itself (i.e., that the sum of some xi should be equal to 1) but
> I do not know how to include the constraint that each xi should be
> non-negative.
> 
> Is there in R (or somewhere else) an SVD that includes this kind of
> constraint? or some other optimizer that can cope with solving non-square
> matrix equations, including the positivity constraint?

optim(method="L-BFGS-B") can cope with [0, 1] constraints.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Jordi.Molins at drkw.com  Tue Jul 27 11:22:31 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Tue, 27 Jul 2004 11:22:31 +0200
Subject: [R] SVD with positivity constraints
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCD6E@ibfftce121.de.ad.drkw.net>

Thank you to Prof Brian Ripley and to Ken Knoblauch for your replies.

I should explain a little bit more about the problem at hand: in principle,
the matrix can have more rows than columns or the other way around. However,
I always could include in an artificial way more equations, such that there
are more equations than unknowns. So, in practical terms, the first question
from Prof Brian Ripley is: more equations than unkowns.

I have 
Additionally, I have seen in several places that is suggested to use La.svd
instead of the standard svd.




-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: 27 July 2004 10:13
To: Molins, Jordi
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] SVD with positivity constraints


If A is not square, which dimension is larger?  There will most likely be 
either no solution or an infinity of solutions.  If the latter, I think 
you are using the Moore-Penrose inverse (depends exactly how you use the 
SVD), that is the shortest solution, but the SVD will give you the whole 
space of solutions and you could compute if that intersects the positive 
orthant.

On Tue, 27 Jul 2004, Molins, Jordi wrote:

> I have a matrix equation, Ax=b, that I need to solve for x. x should be a
> vector of positive numbers (between 0 and 1). A is not a square matrix in
> general. This lead me to using the SVD. However, using the SVD gives me
> positive and negative numbers, as well. I have some constraints included
in
> the A matrix itself (i.e., that the sum of some xi should be equal to 1)
but
> I do not know how to include the constraint that each xi should be
> non-negative.
> 
> Is there in R (or somewhere else) an SVD that includes this kind of
> constraint? or some other optimizer that can cope with solving non-square
> matrix equations, including the positivity constraint?

optim(method="L-BFGS-B") can cope with [0, 1] constraints.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From Jordi.Molins at drkw.com  Tue Jul 27 11:22:40 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Tue, 27 Jul 2004 11:22:40 +0200
Subject: Recall: [R] SVD with positivity constraints
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCD6F@ibfftce121.de.ad.drkw.net>

The sender would like to recall the message, "[R] SVD with positivity
constraints".


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From Jordi.Molins at drkw.com  Tue Jul 27 11:32:43 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Tue, 27 Jul 2004 11:32:43 +0200
Subject: [R] SVD with positivity constraints
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCD70@ibfftce121.de.ad.drkw.net>

Thank you to Prof Brian Ripley and to Ken Knoblauch for your fast replies.

I should explain a little bit more about the problem at hand: in principle,
the matrix can have more rows than columns or the other way around. However,
I always could include in an artificial way more equations, such that there
are more equations than unknowns. So, in practical terms, the answer to the
first question from Prof Brian Ripley is: more equations than unkowns.

I have checked in the "Modern Applied Statistics with S" 4th edition, and in
page 62 it is shown the use of svd. It is written that svd gives, as result,
u, v and d. If there is a space of solutions (as opposed to a unique
solution) how is the solution given? how can I retrieve the whole space of
solutions?

Additionally, I have seen in several places that is suggested to use La.svd
instead of the standard svd. Would the La.svd generate also the whole space
of solutions? I have looked the documentation
(http://cran.r-project.org/doc/packages/RScaLAPACK.pdf) but it is not
explicitly written how to retrieve non-unique solutions.

An additional question: in the Numerical Recipes for C++ it is written that
the "small" numbers in the diagonal of d should be set manually to 0. Is
this done (maybe as an option) in svd or in La.svd? could this resetting
have a material effect in the solutions found?

thank you

J





-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: 27 July 2004 10:13
To: Molins, Jordi
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] SVD with positivity constraints


If A is not square, which dimension is larger?  There will most likely be 
either no solution or an infinity of solutions.  If the latter, I think 
you are using the Moore-Penrose inverse (depends exactly how you use the 
SVD), that is the shortest solution, but the SVD will give you the whole 
space of solutions and you could compute if that intersects the positive 
orthant.

On Tue, 27 Jul 2004, Molins, Jordi wrote:

> I have a matrix equation, Ax=b, that I need to solve for x. x should be a
> vector of positive numbers (between 0 and 1). A is not a square matrix in
> general. This lead me to using the SVD. However, using the SVD gives me
> positive and negative numbers, as well. I have some constraints included
in
> the A matrix itself (i.e., that the sum of some xi should be equal to 1)
but
> I do not know how to include the constraint that each xi should be
> non-negative.
> 
> Is there in R (or somewhere else) an SVD that includes this kind of
> constraint? or some other optimizer that can cope with solving non-square
> matrix equations, including the positivity constraint?

optim(method="L-BFGS-B") can cope with [0, 1] constraints.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From Laetitia.Marisa at cgm.cnrs-gif.fr  Tue Jul 27 11:38:13 2004
From: Laetitia.Marisa at cgm.cnrs-gif.fr (Laetitia Marisa)
Date: Tue, 27 Jul 2004 11:38:13 +0200
Subject: [R] Display on Windows console from script 
Message-ID: <41062285.4010700@cgm.cnrs-gif.fr>

Hello,

When I launch a script under windows it does not display sequentially  
my cat calls or maybe the console is not refreshed at every line of my 
script.

For instance with that code
  cat("\n\n================== IMPORT DATA FROM FILE 
===================\n\n")
fileschosen <- choose.files(caption="Select gpr files", filters = 
matrix(c("genepix file","*.gpr"), nc=2, byrow=T))

The popup browse window is first displayed and once I've selected my 
files the cat "IMPORT..."  is displayed.

What can I do to make my displays appear at the right time?

Thanks a lot.

Laetitia Marisa.



From ripley at stats.ox.ac.uk  Tue Jul 27 11:55:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Jul 2004 10:55:42 +0100 (BST)
Subject: [R] Display on Windows console from script 
In-Reply-To: <41062285.4010700@cgm.cnrs-gif.fr>
Message-ID: <Pine.LNX.4.44.0407271053330.24193-100000@gannet.stats>

Please consult the rw-FAQ, specifically Q6.3 whose subject looks a perfect 
fit for your question (and whose answer contains the answer).

On Tue, 27 Jul 2004, Laetitia Marisa wrote:

> When I launch a script under windows it does not display sequentially  
> my cat calls or maybe the console is not refreshed at every line of my 
> script.
> 
> For instance with that code
>   cat("\n\n================== IMPORT DATA FROM FILE 
> ===================\n\n")
> fileschosen <- choose.files(caption="Select gpr files", filters = 
> matrix(c("genepix file","*.gpr"), nc=2, byrow=T))
> 
> The popup browse window is first displayed and once I've selected my 
> files the cat "IMPORT..."  is displayed.
> 
> What can I do to make my displays appear at the right time?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rksh at soc.soton.ac.uk  Tue Jul 27 12:53:29 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 27 Jul 2004 11:53:29 +0100
Subject: [R] library manual: documentation of funcs not alphabetically
	ordered
Message-ID: <a06002001bd2be2959249@[139.166.242.29]>

Hello everybody

I'm putting finishing touches to a library, and have noticed that the 
.dvi file that R CMD check
creates  does not sort the functions in alphabetical order.

I find this odd because I used the "tidy"  routines in section 3.1 of 
the R-exts manual, which produce R code in which the functions are 
alphabetically ordered (and I performed R CMD check using the 
tidied-and-profiled R code).  My other library manuals are in 
alphabetical order.


How do I get a dvi manual with functions in alphabetical order?
What have I forgotten to do?



-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From Jordi.Molins at drkw.com  Tue Jul 27 13:48:16 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Tue, 27 Jul 2004 13:48:16 +0200
Subject: [R] SVD with positivity constraints
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCD74@ibfftce121.de.ad.drkw.net>


Hello,

what I wrote below is nonsense: if the matrix has more equations than
unknowns, it makes no sense considering the general space of solutions.
Sorry for that.

Another consideration: could somebody give me an opinion about the following
procedure?

the simplex algorithm maximizes

z=a00x0 + a01x1+...+a0(N-1)x(N-1)

subject to x0>=0, ... x(N-1)>=0

and under M=m1+m2+m3 constraints: m1 equations for =< inequalities(with x on
the left), m2 equations for >= inequalities, and m3 equations for equalities
(=).

Consider a00=a01=...=a0(N-1)=0 (degenerate in some sense), and let me choose
also m1=m2=0, and then m3 being the number of equations I have.

Using the simplex method for linear programing would give me "my" solution,
or would this method give me a degenerate solution?

thank you, and please bear with me my desesperation ;->

Jordi

-----Original Message-----
From: Molins, Jordi 
Sent: 27 July 2004 11:33
To: 'r-help at stat.math.ethz.ch'
Cc: 'Prof Brian Ripley'; 'Ken Knoblauch'
Subject: RE: [R] SVD with positivity constraints


Thank you to Prof Brian Ripley and to Ken Knoblauch for your fast replies.

I should explain a little bit more about the problem at hand: in principle,
the matrix can have more rows than columns or the other way around. However,
I always could include in an artificial way more equations, such that there
are more equations than unknowns. So, in practical terms, the answer to the
first question from Prof Brian Ripley is: more equations than unkowns.

I have checked in the "Modern Applied Statistics with S" 4th edition, and in
page 62 it is shown the use of svd. It is written that svd gives, as result,
u, v and d. If there is a space of solutions (as opposed to a unique
solution) how is the solution given? how can I retrieve the whole space of
solutions?

Additionally, I have seen in several places that is suggested to use La.svd
instead of the standard svd. Would the La.svd generate also the whole space
of solutions? I have looked the documentation
(http://cran.r-project.org/doc/packages/RScaLAPACK.pdf) but it is not
explicitly written how to retrieve non-unique solutions.

An additional question: in the Numerical Recipes for C++ it is written that
the "small" numbers in the diagonal of d should be set manually to 0. Is
this done (maybe as an option) in svd or in La.svd? could this resetting
have a material effect in the solutions found?

thank you

J





-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: 27 July 2004 10:13
To: Molins, Jordi
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] SVD with positivity constraints


If A is not square, which dimension is larger?  There will most likely be 
either no solution or an infinity of solutions.  If the latter, I think 
you are using the Moore-Penrose inverse (depends exactly how you use the 
SVD), that is the shortest solution, but the SVD will give you the whole 
space of solutions and you could compute if that intersects the positive 
orthant.

On Tue, 27 Jul 2004, Molins, Jordi wrote:

> I have a matrix equation, Ax=b, that I need to solve for x. x should be a
> vector of positive numbers (between 0 and 1). A is not a square matrix in
> general. This lead me to using the SVD. However, using the SVD gives me
> positive and negative numbers, as well. I have some constraints included
in
> the A matrix itself (i.e., that the sum of some xi should be equal to 1)
but
> I do not know how to include the constraint that each xi should be
> non-negative.
> 
> Is there in R (or somewhere else) an SVD that includes this kind of
> constraint? or some other optimizer that can cope with solving non-square
> matrix equations, including the positivity constraint?

optim(method="L-BFGS-B") can cope with [0, 1] constraints.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From ripley at stats.ox.ac.uk  Tue Jul 27 14:15:14 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Jul 2004 13:15:14 +0100 (BST)
Subject: [R] library manual: documentation of funcs not alphabetically
	ordered
In-Reply-To: <a06002001bd2be2959249@[139.166.242.29]>
Message-ID: <Pine.LNX.4.44.0407271308030.24352-100000@gannet.stats>

On Tue, 27 Jul 2004, Robin Hankin wrote:

> Hello everybody
> 
> I'm putting finishing touches to a library, 

package?

> and have noticed that the .dvi file that R CMD check creates does not
> sort the functions in alphabetical order.

It is not designed to, merely to check that the files can be processed.
Use R CMD Rd2dvi to produce a manual: that sorts the man/*.Rd files in the 
ASCII collate order (which may or may not be the same order as the 
function names).

> I find this odd because I used the "tidy"  routines in section 3.1 of 
> the R-exts manual, which produce R code in which the functions are 
> alphabetically ordered (and I performed R CMD check using the 
> tidied-and-profiled R code).  My other library manuals are in 
> alphabetical order.

The R and man directories are unrelated.

> How do I get a dvi manual with functions in alphabetical order?
> What have I forgotten to do?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From skdrew at qwest.net  Tue Jul 27 14:18:40 2004
From: skdrew at qwest.net (Sara Drew)
Date: Tue, 27 Jul 2004 05:18:40 -0700
Subject: [R] Read SPSS data (*.sav) in R 1.8.0 (ok) and R1.9.1(error)
In-Reply-To: <Pine.A41.4.58.0407260828300.143040@homer04.u.washington.edu>
Message-ID: <MBEPIIKLODKFDMIPFOGAMEMICHAA.skdrew@qwest.net>

I have had the same problem (or at least get the same error msg) using the
spss.get() function from Hmisc using R1.9.1 to read an SPSS file. I think
read.spss() from foreign package still works though. Have not tried
spss.get() with any other version of R.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Thomas Lumley
Sent: Monday, July 26, 2004 7:29 AM
To: Karl Knoblick
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Read SPSS data (*.sav) in R 1.8.0 (ok) and
R1.9.1(error)


On Mon, 26 Jul 2004, [iso-8859-1] Karl Knoblick wrote:

> Hallo!
>
> I read SPSS data in the following way:
>
> library(Hmisc)
> library(foreign)
> dat<-spss.get("surv_abb.sav")
>
> In R1.9.1 I got the message:
> "Error in all(arg == choices) : Object "typeDate" not
> found"
>
> In R1.8.0 the same script works fine.
>
> Does anybody know a possibilty to read a SPSS file
> under R1.9.1?
>

YOu should just be able to use read.spss in the "foreign" package.

	-thomas

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Luisr at frs.fo  Tue Jul 27 14:22:58 2004
From: Luisr at frs.fo (Luis Rideau Cruz)
Date: Tue, 27 Jul 2004 13:22:58 +0100
Subject: [R] list problem
Message-ID: <s106573c.045@ffdata.setur.fo>

Hi all,

I have the folowing frame(there are more columns than shown),
   1              2           3        4           5     
Year         Total      Tus    Whi      Norw
1994         1.00      1830       0      355 
1995         1.00         0       0        0 
1995         1.00         0       0        0 
1995         1.00      4910    4280      695 
1997         1.00         0       0      110 
1997         0.58         0       0        0 
1997         1.00         0       0        0 
1994         1.00         0       0        0 
1997         1.00         0      40       70 
1998         1.00         0       0     1252 
1999         1.04         0      74        0 
1999         1.00         0       0        0 
1999         1.02         0       0        0 
1999         1.00         0       0        0 
1999         1.00         0       0      171 
1999         1.00      1794       0      229 
1999         1.00         0    3525        0 
1997         1.00      1335    1185      147 
1997         1.00      4925    1057     4801 
1997         1.00         0    6275     1773 

I try to get sum("Total") by "Year" in which Tus>0,  sum("Total") by "Year" in which Whi>0,,,and so on.

I have done something like this;

a<-as.list(numeric(3))
for (i in 3:5)
{
a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
                                                   Tus=frame$"i">0),sum)
}


The result is something like;

   Year  Tus     x
 1994 FALSE 49.69
 1995 FALSE 49.35
 1996 FALSE 56.95
 1997 FALSE 57.00
 1998 FALSE 57.00
 1999 FALSE 58.09
 2000 FALSE 56.97
 2001 FALSE 57.95
 2002 FALSE 57.10
 2003 FALSE 56.16
 2000  TRUE  1.00
 2002  TRUE  1.00
 2003  TRUE  2.01


But when I try indexing  frame["Tus"==TRUE,],,,,I just don't get it

Thank you


Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo 
Web:                www.frs.fo 

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo
Web:                www.frs.fo



From avril.coghlan at ucd.ie  Tue Jul 27 14:35:02 2004
From: avril.coghlan at ucd.ie (Avril Coghlan)
Date: Tue, 27 Jul 2004 13:35:02 +0100
Subject: [R] test for difference between non-independent correlations
Message-ID: <1090931702.3777.26.camel@bioinf14>

Hello,

  I am wondering whether there is a way to
test whether two non-independent correlation
coefficients are significantly different, in R?

I have an experimentally measure variable Y,
and two different variables X1, and X2, which
are predictions of Y that were predicted using
two different computational models.

I would like to see whether the correlation
of Y and X1, and Y and X2 is significantly different.
Since Y appears in both correlations
the correlation coefficients will be non-independent.
(so you cannot use a Z test like you would for
comparing independent correlation coefficients, I think).

I have read that there is a test for comparing
non-independent correlation coefficients, by
EJ Williams (1959) and Steiger.
There is also a test called Hotelling's t test.
I'm wondering does anyone know whether I can
somehow carry out any of these using an R package, or compare
non-independent correlations using R by some
other method?

I will greatly appreciate any help,
thankyou,
Avril Coghlan
(University College Dublin, Ireland)



From baron at psych.upenn.edu  Tue Jul 27 15:05:33 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 27 Jul 2004 09:05:33 -0400
Subject: [R] test for difference between non-independent correlations
In-Reply-To: <1090931702.3777.26.camel@bioinf14>
References: <1090931702.3777.26.camel@bioinf14>
Message-ID: <20040727130533.GA16650@psych>

On 07/27/04 13:35, Avril Coghlan wrote:
>Hello,
>
>  I am wondering whether there is a way to
>test whether two non-independent correlation
>coefficients are significantly different, in R?

About 20 years ago I asked the same question (without the "R"),
found Steiger's paper (below) and wrote this BASIC program to do
it.  (If you try to type it in each time you're bound to make a
mistake.  This has been checked repeatedly.)  It is trivial to
write this as an R script, of course.

I and my colleagues have been using this for about 20 years, and
it seems to be OK as judged by comparing it to the jackknife.
(Remember, when we did this, the "bootstrap" was a newfangled
idea that we didn't quite trust.)  My hunch is that something
better has come along, and I'd be interested to see how others
respond.  Hence I haven't bothered to translate this into R.  Or
maybe everyone who has this problem just uses the bootstrap now.
That is certainly easy enough.  (I will eventually add this to
our "Notes on R for psychology...," since it is a very common
problem in psychology research.)

10 print "looks for difference between r12 and r13, given r23"
12 print "(input r12>1 to quit)"
20 input "r12 "; r12
22 if r12>1 then end
30 input "r13 "; r13
40 input "r23 "; r23
50 input "N "; n
52 let rd=1-r12*r12-r13*r13-r23*r23+2*r12*r13*r23
54 let rb=(r12+r13)/2
56 let cube=(1-r23)*(1-r23)*(1-r23)
60 let t2=(r12-r13)*sqrt((n-1)*(1+r23)/(2*rd*(n-1)/(n-3)+rb*rb*cube))
70 print "t (";n-3;") = ";t2
80 print "Steiger, J.H. (1980). Tests for comparing elements of a
82 print "correlation matrix.  Psychological Bulletin, 87, 245-251."
100 goto 12

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
R search page: http://finzi.psych.upenn.edu/



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Jul 27 15:23:24 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 27 Jul 2004 15:23:24 +0200
Subject: [R] list problem
References: <s106573c.045@ffdata.setur.fo>
Message-ID: <00bf01c473dc$e60ce2a0$ad133a86@www.domain>

Hi Luis,

maybe there are better ways but you could try something like this,

n <- length(frame)
lapply(split(frame, frame$Year), function(x, n.){
  res <- numeric(n.-2)
  for(i in 3:n.) res[i-2] <- sum(x$Total[x[,i]>0.])
  res
}, n.=n)

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Luis Rideau Cruz" <Luisr at frs.fo>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, July 27, 2004 2:22 PM
Subject: [R] list problem


> Hi all,
>
> I have the folowing frame(there are more columns than shown),
>    1              2           3        4           5
> Year         Total      Tus    Whi      Norw
> 1994         1.00      1830       0      355
> 1995         1.00         0       0        0
> 1995         1.00         0       0        0
> 1995         1.00      4910    4280      695
> 1997         1.00         0       0      110
> 1997         0.58         0       0        0
> 1997         1.00         0       0        0
> 1994         1.00         0       0        0
> 1997         1.00         0      40       70
> 1998         1.00         0       0     1252
> 1999         1.04         0      74        0
> 1999         1.00         0       0        0
> 1999         1.02         0       0        0
> 1999         1.00         0       0        0
> 1999         1.00         0       0      171
> 1999         1.00      1794       0      229
> 1999         1.00         0    3525        0
> 1997         1.00      1335    1185      147
> 1997         1.00      4925    1057     4801
> 1997         1.00         0    6275     1773
>
> I try to get sum("Total") by "Year" in which Tus>0,  sum("Total") by
"Year" in which Whi>0,,,and so on.
>
> I have done something like this;
>
> a<-as.list(numeric(3))
> for (i in 3:5)
> {
> a[[i]]<-aggregate(frame[,"Total"],list(Year=frame$"Year",
>
Tus=frame$"i">0),sum)
> }
>
>
> The result is something like;
>
>    Year  Tus     x
>  1994 FALSE 49.69
>  1995 FALSE 49.35
>  1996 FALSE 56.95
>  1997 FALSE 57.00
>  1998 FALSE 57.00
>  1999 FALSE 58.09
>  2000 FALSE 56.97
>  2001 FALSE 57.95
>  2002 FALSE 57.10
>  2003 FALSE 56.16
>  2000  TRUE  1.00
>  2002  TRUE  1.00
>  2003  TRUE  2.01
>
>
> But when I try indexing  frame["Tus"==TRUE,],,,,I just don't get it
>
> Thank you
>
>
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
> Luis Ridao Cruz
> Fiskiranns??knarstovan
> N??at??n 1
> P.O. Box 3051
> FR-110 T??rshavn
> Faroe Islands
> Phone:             +298 353900
> Phone(direct): +298 353912
> Mobile:             +298 580800
> Fax:                 +298 353901
> E-mail:              luisr at frs.fo
> Web:                www.frs.fo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From edd at debian.org  Tue Jul 27 15:28:53 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 27 Jul 2004 08:28:53 -0500
Subject: [R] lattice / pdf bug ?
In-Reply-To: <200407261850.13634.deepayan@stat.wisc.edu>
References: <20040726231749.GA8659@sonny.eddelbuettel.com>
	<200407261850.13634.deepayan@stat.wisc.edu>
Message-ID: <20040727132853.GA18345@sonny.eddelbuettel.com>

On Mon, Jul 26, 2004 at 06:50:13PM -0500, Deepayan Sarkar wrote:
> On Monday 26 July 2004 18:17, Dirk Eddelbuettel wrote:
> > I've been scrathing my head over this one.  Suppose I have a
> > data.frame which maps to a 'n x k' lattice, and that one of those
> > cells is empty.
> >
> > An artificial example is generated by
> >
> > Q<-data.frame(x1=sample(c("A","B"),10,replace=TRUE),
> >               x2=c("C", rep("D",9)), y=rnorm(10))
> >
> > where by having only one obs. for the first level of the second
> > factor x2, we ensure that there won't be full combinations of x1 and
> > x2.
> 
> The empty cell is not the issue, rather it's the fact that the panel 
> that gets the first observation (x2 = "C") has only that one single 
> observation. So for that panel, sd(x, na.rm = TRUE) = NA, hence 
> 
> dnorm(<mesh points>, mean = <whatever>, sd = NA) 
> 
> eventually produces a bunch of NA's, which grid.lines tries to draw. 
> grid.lines has known issues with NA's, and I would guess that's what 
> causes the broken pdf.
> 
> The good news is that there doesn't seem to be any problems in r-devel 
> (possibly because grid handles NA's better now).
> 
> The natural workaround for your code would be to skip the 
> panel.mathdensity call unless length(x) > 1.

Confirmed -- that does the trick for 'plain' R 1.9.1 as well. Thanks a lot
for this, I had obviously focussed on the wrong aspect (the 'empty' cell
rather than the one with just one element).

Dirk
 
> Deepayan
> 
> 
> > This seems to trip panel.mathdensity(), but only when printing to
> > pdf, and I can't find a way to avoid it. Consider
> >
> >
> > stopifnot(require(lattice))
> > stopifnot(require(grid))
> >
> > pdf("testfile.pdf")
> > Q<-data.frame(x1=sample(c("A","B"),10,replace=TRUE),
> >               x2=c("C", rep("D",9)), y=rnorm(10))
> > print(histogram(~ y | x1+x2, data=Q,
> >                 panel = function(x, ...) {
> >                   if (length(x) > 0) {
> > 		    panel.histogram(x, ...)
> >                     panel.mathdensity(dmath = dnorm, col = "black",
> >                                       args = list(mean=mean(x,
> > na.rm=TRUE), sd=sd(x, na.rm=TRUE))) }
> >                 }))
> > dev.off()
> >
> >
> > where the resulting pdf file is broken if and only if the
> > panel.mathdensity call is present.  Without it, it works.  To the
> > screen, it works with and without -- but copying to pdf again  breaks
> > the pdf file if
> > panel.mathdensity is used.
> >
> > It is possible that I am overlooking something simple -- or is it a
> > genuine bug?
> >
> > Platform is win2k, R version is 1.9.1.
> >
> > Thanks for any pointers,  Dirk
> 

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From dave_lists at yahoo.co.uk  Tue Jul 27 16:03:09 2004
From: dave_lists at yahoo.co.uk (=?iso-8859-1?q?David=20Whiting?=)
Date: Tue, 27 Jul 2004 15:03:09 +0100 (BST)
Subject: [R] X11 device problem on linux: 100% cpu usage
In-Reply-To: <4104F83A.2020704@lancaster.ac.uk>
Message-ID: <20040727140309.42424.qmail@web50103.mail.yahoo.com>

--- Barry Rowlingson <B.Rowlingson at lancaster.ac.uk>
wrote: > David Whiting wrote:
> 
> > I'm using R 1.9.1 (patched, 5th July) on linux
> > (Mandrake 9.2) and am having a problem with the
> X11()
> > device. Trying to plot(1:10) results in my CPU
> going
> > to 100% 
> 
> > I'm not sure where to start with identifying the
> > cause. Can someone suggest some things that I
> should
> > look at?  
> 
>   First off, you can try and figure out if its the
> client (R) or the 
> server (your X-windows display server).
> 

[...]

Thanks Barry. I don't have another machine I can play
with at the moment, so I dug out an old R-1.8.1 rpm
and installed that: same problem.  I then tried a
different window manager and the problem disappeared. 
So somehow fluxbox (my usual window manager) sees to
be having a proble with R (everything else seems to
run okay in fluxbox). For now I'll just use a
different window manager until I have time to
investigate this further.

Thanks again.

Dave



From ronpicci at yahoo.fr  Tue Jul 27 16:21:09 2004
From: ronpicci at yahoo.fr (=?iso-8859-1?q?Ron=20Piccinini?=)
Date: Tue, 27 Jul 2004 16:21:09 +0200 (CEST)
Subject: [R] Help R - SNOW package...correct indexation syntax??
Message-ID: <20040727142109.23059.qmail@web52903.mail.yahoo.com>

Hello!

I am trying to apply estimators at various data
lengths (data is resident on diferent nodes of a
beowulf cluster) in order to save computation time. 

On one side, suppose that:
x <- clusterCall(cl,runif,100000)
(i.e. 100,000 random numbers on each node)
then the first say 100 numbers of node say #3 are
returned by x.3.100 <- x[[3]][1:100]

On the other side, if one wanted to compute the
average of each series individually, one could use:
x.averages <- parSapply(cl,x,mean)

But what if one wanted to to compute the average of
only the first 100 data points resident on each node?
What would be the approriate syntax? Is the only (and
fastest) solution to write a loop of the type:

for (j in numbernodes){x.avearges.100 <-
mean(x[[j]][1:100]}

Or is there a more efficient par_apply method? I've
been trying and trying to find a better way
unfortunately to no avail. 

Thanks in advance for your time and help,

Renaud Piccinini
University of Nebraska-Lincoln




	

	
		
Vous manquez d?espace pour stocker vos mails ?



From tlumley at u.washington.edu  Tue Jul 27 16:34:09 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 27 Jul 2004 07:34:09 -0700 (PDT)
Subject: [R] covariate selection in cox model (counting process)
In-Reply-To: <000c01c4735f$ea6436a0$5ce29a53@amd>
References: <000c01c4735f$ea6436a0$5ce29a53@amd>
Message-ID: <Pine.A41.4.58.0407270719480.185150@homer07.u.washington.edu>

On Tue, 27 Jul 2004, Mayeul KAUFFMANN wrote:

> Thank you a lot for your time and your answer, Thomas. Like all good
> answers, it raised new questions for me ;-)
>
> >In the case of recurrent events coxph() is not
> > using maximum likelihood or even maximum partial likelihood. It is
> > maximising the quantity that (roughly speaking) would be the partial
> > likelihood if the covariates explained all the cluster differences.
>
> I could have non repeating events by removing countries once they have
> experienced a war. But I'm not sure it will change the estimation
> procedure since this will change the dataset only, not the formula
> coxph(Surv(start,stop,status)~x1+x2+...+cluster(id),robust=T)
>
> I am not sure I understood you well: do you really mean "recurrent events"
> alone or "any counting process notation (including allowing for recurrent
> events)".

No, I mean recurrent events.  With counting process notation but no
recurrent revents the partial likelihood is still valid, and the approach
of treating it as a real likelihood for AIC (and presumably BIC) makes
sense.

Roughly speaking, you can't tell there is dependence until you see
multiple events.

>
> I thought the counting process notation did not differ really from the Cox
> model in R, since Terry M. Therneau (A Package for Survival Analysis in S,
> April 22, 1996) concludes his mathematical section "3.3 Cox Model" by "The
> above notation is derived from the counting process representation [...]
> It allows very naturally for several extensions to the original Cox model
> formulation: multiple events per subject, discontinuous intervals of risk
> [...],left truncation." (I used it to introduce 1. time-dependent
> covariates, some covariates changing yearly, other irregularly, and 2.
> left truncation: not all countries existed at the beginning of the study)
>
>
> >In the case of recurrent events coxph() is not
> > using maximum likelihood or even maximum partial likelihood.
>
> Then, what does fit$loglik give in this case? Still a likelihood or a
> valid criterion to maximise ?
> If not, how to get ("manually") the criterion that was maximsed?

fit$loglik gives the criterion that was maximised.  This is the function
of the data that *would be* the partial likelihood if there was no
within-country dependence.

This is a convenient criterion function because it is easy to maximise,
and it is known to give valid (and reasonably efficient) estimates for
what you might call a "proportional rates" model in the case of recurrent
events.  However, it no longer has the same claim to be a "real
likelihood" that the Cox partial likelihood does, because it is not
modelling the dependence.

>
> That's of interest for me since
> > I created artificial covariates measuring the proximity since some
> events: exp(-days.since.event/a.chosen.parameter).
>
> ...and I used fit$loglik to chose a.chosen.parameter from 8 values, for 3
> types of events:

That's fine -- within a single model maximising the criterion function is
valid.  The problem is that you can not assume either that
differences between nested models have a chisquared distribution nor that
the expected change in loglik is the same as the number of parameters.

This means that you don't have any absolute scale for choosing
penalties, which is a problem in model selection -- it is hard to balance the
increase in fit$loglik with the increase in model complexity.

In principle you could use cross-validation to estimate the
cost-complexity tradeoff in these models, but this requires the ability to
compute the criterion function on a subset not included in the model,
which is not entirely straightforward.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From t.dewez at brgm.fr  Tue Jul 27 16:44:59 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Tue, 27 Jul 2004 16:44:59 +0200
Subject: [R] computing differences between consecutive vector elements
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD687B@SRV0015>

Dear R-users,

I am a newbie to R so please excuse this naive question for which I couldn't
seem to find online answers.

I have this data frame containing a series of locations through time
(x,y,z,t). I would like to compute the difference in x, y and z between t-1
and t.

Sounds easy enough, but how on earth does one loop through vector elements
and compute this difference?

Thanks

Thomas
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
(des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
 e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
v??rifier l'absence de corruption ?? sa r??ception.

The contents of this email and any attachments are confidential. They are intended for 
the named recipient(s) only. If you have received this email in error please notify the 
system manager or  the sender immediately and do not disclose the contents to 
anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
content.
***



From andy_liaw at merck.com  Tue Jul 27 16:50:13 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 27 Jul 2004 10:50:13 -0400
Subject: [R] computing differences between consecutive vector
 elements
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8118@usrymx25.merck.com>

Not exactly sure what you want, but seems like you can sort the data frame
by `t', then do diff() on the x, y, and z columns.

Andy

> From: Dewez Thomas
> 
> Dear R-users,
> 
> I am a newbie to R so please excuse this naive question for 
> which I couldn't
> seem to find online answers.
> 
> I have this data frame containing a series of locations through time
> (x,y,z,t). I would like to compute the difference in x, y and 
> z between t-1
> and t.
> 
> Sounds easy enough, but how on earth does one loop through 
> vector elements
> and compute this difference?
> 
> Thanks
> 
> Thomas
> ***
> Le contenu de cet e-mail et de ses pi??ces jointes est destin?? 
> ?? l'usage exclusif du 
> (des) destinataire(s) express??ment d??sign??(s) comme tel(s). 
> En cas de r??ception de cet 
>  e-mail par erreur, le signaler ?? son exp??diteur et ne pas en 
> divulguer le contenu. 
> L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il 
> convient n??anmoins de 
> v??rifier l'absence de corruption ?? sa r??ception.
> 
> The contents of this email and any attachments are 
> confidential. They are intended for 
> the named recipient(s) only. If you have received this email 
> in error please notify the 
> system manager or  the sender immediately and do not disclose 
> the contents to 
> anyone or make copies. eSafe scanned this email for viruses, 
> vandals and malicious 
> content.
> ***
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From t.dewez at brgm.fr  Tue Jul 27 17:04:47 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Tue, 27 Jul 2004 17:04:47 +0200
Subject: [R] computing differences between consecutive vectorelements
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD687C@SRV0015>

well, sure diff() does it
thanks alot

Thomas

> -----Message d'origine-----
> De: Liaw, Andy [mailto:andy_liaw at merck.com]
> Date: mardi 27 juillet 2004 16:50
> ??: 'Dewez Thomas'; 'r-help at stat.math.ethz.ch'
> Objet: RE: [R] computing differences between consecutive 
> vectorelements
> 
> 
> Not exactly sure what you want, but seems like you can sort 
> the data frame
> by `t', then do diff() on the x, y, and z columns.
> 
> Andy
> 
> > From: Dewez Thomas
> > 
> > Dear R-users,
> > 
> > I am a newbie to R so please excuse this naive question for 
> > which I couldn't
> > seem to find online answers.
> > 
> > I have this data frame containing a series of locations through time
> > (x,y,z,t). I would like to compute the difference in x, y and 
> > z between t-1
> > and t.
> > 
> > Sounds easy enough, but how on earth does one loop through 
> > vector elements
> > and compute this difference?
> > 
> > Thanks
> > 
> > Thomas
> > ***
> > Le contenu de cet e-mail et de ses pi??ces jointes est destin?? 
> > ?? l'usage exclusif du 
> > (des) destinataire(s) express??ment d??sign??(s) comme tel(s). 
> > En cas de r??ception de cet 
> >  e-mail par erreur, le signaler ?? son exp??diteur et ne pas en 
> > divulguer le contenu. 
> > L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il 
> > convient n??anmoins de 
> > v??rifier l'absence de corruption ?? sa r??ception.
> > 
> > The contents of this email and any attachments are 
> > confidential. They are intended for 
> > the named recipient(s) only. If you have received this email 
> > in error please notify the 
> > system manager or  the sender immediately and do not disclose 
> > the contents to 
> > anyone or make copies. eSafe scanned this email for viruses, 
> > vandals and malicious 
> > content.
> > ***
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
> 
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
(des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
 e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
v??rifier l'absence de corruption ?? sa r??ception.

The contents of this email and any attachments are confidential. They are intended for 
the named recipient(s) only. If you have received this email in error please notify the 
system manager or  the sender immediately and do not disclose the contents to 
anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
content.
***



From gunter.berton at gene.com  Tue Jul 27 17:57:28 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 27 Jul 2004 08:57:28 -0700
Subject: [R] list problem
References: <s106573c.045@ffdata.setur.fo>
	<00bf01c473dc$e60ce2a0$ad133a86@www.domain>
Message-ID: <41067B68.7E1DB304@gene.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040727/0344f75c/attachment.pl

From sundar.dorai-raj at PDF.COM  Tue Jul 27 18:04:48 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 27 Jul 2004 11:04:48 -0500
Subject: [R] Underline in expression().
In-Reply-To: <41060ED9.5070907@netscape.net>
References: <41060ED9.5070907@netscape.net>
Message-ID: <41067D20.70108@pdf.com>



John Janmaat wrote:
> Hello All,
> 
> Is there an analogue to \underbar or the AMS math \underline in 
> graphical math expressions?
> 
> Thanks,
> 
> John.

Uwe Ligges posted a solution a couple of years ago. I don't know if 
there is anything built in yet. ?plotmath does not seem to say anything 
about underlining.

http://finzi.psych.upenn.edu/R/Rhelp01/archive/7191.html

plot(0:1, 0:1, type="n")
underlined(0.5, 0.5, expression(widehat(x %*% y)))

--sundar



From pocernic at rap.ucar.edu  Tue Jul 27 18:30:40 2004
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Tue, 27 Jul 2004 10:30:40 -0600 (MDT)
Subject: [R] lattice.device in loop
Message-ID: <Pine.LNX.4.44.0407271023010.415-100000@albedo.rap.ucar.edu>

Hi,

I am having problems creating a pdf file of a lattice graph.  Things work
fine for a single image, but I am having trouble using the commands in a
loop.  To illustrate by example

This works with both ps and pdf files.

dat = list(x= 1:10, y = 1:10)
 trellis.device(postscript, file = "/d1/pocernic/test.ps")
    xyplot(y~x, data = dat)
dev.off()


This does not.   It produces a very small, non working output file.

for(i in 1:1){
 trellis.device(postscript, file = "/d1/pocernic/test.ps")

    xyplot(y~x, data = dat)
dev.off()
 }

Really, I would like something like this to produce a large, appended file
made from different large datasets.  This doesn't work either.

trellis.device(postscript, file = "/d1/pocernic/test.ps", onefile = TRUE)
for(i in 1:5){
    xyplot(y~x, data = dat)
 }

dev.off()

Any thoughts would be welcomed.



Matt Pocernich
NCAR - Research Applications Program
303-497-8312



From sundar.dorai-raj at PDF.COM  Tue Jul 27 18:41:26 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 27 Jul 2004 11:41:26 -0500
Subject: [R] lattice.device in loop
In-Reply-To: <Pine.LNX.4.44.0407271023010.415-100000@albedo.rap.ucar.edu>
References: <Pine.LNX.4.44.0407271023010.415-100000@albedo.rap.ucar.edu>
Message-ID: <410685B6.8060203@pdf.com>



Matt Pocernich wrote:
> Hi,
> 
> I am having problems creating a pdf file of a lattice graph.  Things work
> fine for a single image, but I am having trouble using the commands in a
> loop.  To illustrate by example
> 
> This works with both ps and pdf files.
> 
> dat = list(x= 1:10, y = 1:10)
>  trellis.device(postscript, file = "/d1/pocernic/test.ps")
>     xyplot(y~x, data = dat)
> dev.off()
> 
> 
> This does not.   It produces a very small, non working output file.
> 
> for(i in 1:1){
>  trellis.device(postscript, file = "/d1/pocernic/test.ps")
> 
>     xyplot(y~x, data = dat)
> dev.off()
>  }
> 
> Really, I would like something like this to produce a large, appended file
> made from different large datasets.  This doesn't work either.
> 
> trellis.device(postscript, file = "/d1/pocernic/test.ps", onefile = TRUE)
> for(i in 1:5){
>     xyplot(y~x, data = dat)
>  }
> 
> dev.off()
> 
> Any thoughts would be welcomed.
> 
> 
> 
> Matt Pocernich
> NCAR - Research Applications Program
> 303-497-8312
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

This is a FAQ 7.24.

http://cran.r-project.org/doc/FAQ/R-FAQ.htm

--sundar



From ligges at statistik.uni-dortmund.de  Tue Jul 27 19:55:36 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 27 Jul 2004 19:55:36 +0200
Subject: [R] computing differences between consecutive vector elements
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD687B@SRV0015>
References: <D965434E9D6BD511AE3500306E01C8BE05DD687B@SRV0015>
Message-ID: <41069718.8050602@statistik.uni-dortmund.de>

Dewez Thomas wrote:
> Dear R-users,
> 
> I am a newbie to R so please excuse this naive question for which I couldn't
> seem to find online answers.
> 
> I have this data frame containing a series of locations through time
> (x,y,z,t). I would like to compute the difference in x, y and z between t-1
> and t.
> 
> Sounds easy enough, but how on earth does one loop through vector elements
> and compute this difference?

See ?diff

Hence for a data frame X:
  lapply(X, diff)

Uwe Ligges


> Thanks
> 
> Thomas
> ***
> Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
> (des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
>  e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
> L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
> v??rifier l'absence de corruption ?? sa r??ception.
> 
> The contents of this email and any attachments are confidential. They are intended for 
> the named recipient(s) only. If you have received this email in error please notify the 
> system manager or  the sender immediately and do not disclose the contents to 
> anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
> content.
> ***
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rduarte at unicamp.br  Tue Jul 27 20:31:07 2004
From: rduarte at unicamp.br (Rodrigo Drummond)
Date: Tue, 27 Jul 2004 15:31:07 -0300 (BRT)
Subject: [R] Integration with "adapt"
Message-ID: <3628.143.106.4.184.1090953067.squirrel@143.106.4.184>

Hi all,

I need to calculate  a multidimensional integration on R. I am using the
command "adapt" (from library adapt), although sometimes I get the
following error message:

Ifail=2, lenwrk was too small. -- fix adapt() !
 Check the returned relerr! in: adapt(3, linf, lsup, functn = Integrando1)

I guess it happens because the domain of integration is too small,
although I tried a change of variables to avoid this problem and it didn?t
help. The command adapt calls a fortran routine, but I don?t know fortran
enough to fix the problem.
Can someone help me?
Thanks a lot
Rodrigo Drummond


____________________________________________
Rodrigo D. Drummond
Laboratorio Genoma Funcional
Centro de Biologia Molecular e Eng. Genetica
Universidade Estadual de Campinas
Caixa Postal 6010
13083-875 - Campinas - SP - Brasil
Tel: xx-19-3788-1119 Fax: xx-19-3788-1089



From lroman at banxico.org.mx  Tue Jul 27 20:54:59 2004
From: lroman at banxico.org.mx (=?iso-8859-1?Q?Rom=E1n_Padilla_Lizbeth?=)
Date: Tue, 27 Jul 2004 13:54:59 -0500
Subject: [R] ghyper package
Message-ID: <ED7E0E44EAADFB46A6ABA12A647C1306139E7D30@CORREOINT.banxico.org.mx>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040727/13e0f8c9/attachment.pl

From bwheeler at echip.com  Tue Jul 27 21:02:29 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Tue, 27 Jul 2004 15:02:29 -0400
Subject: [R] ghyper package
References: <ED7E0E44EAADFB46A6ABA12A647C1306139E7D30@CORREOINT.banxico.org.mx>
Message-ID: <4106A6C5.2040609@echip.com>

It is in SuppDists.

Rom??n Padilla Lizbeth wrote:
> Hello
> 
> I am searching ghyper package (generalized hypergeometric distributions).
> 
> Does anyone can send it to me?
> 
>  
> 
> Regards from Mexico
> 
> Lizbeth Rom??n
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From MSchwartz at MedAnalytics.com  Tue Jul 27 21:05:43 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 27 Jul 2004 14:05:43 -0500
Subject: [R] ghyper package
In-Reply-To: <ED7E0E44EAADFB46A6ABA12A647C1306139E7D30@CORREOINT.banxico.org.mx>
References: <ED7E0E44EAADFB46A6ABA12A647C1306139E7D30@CORREOINT.banxico.org.mx>
Message-ID: <1090955143.11580.17.camel@localhost.localdomain>

On Tue, 2004-07-27 at 13:54, Romn Padilla Lizbeth wrote:
> Hello
> 
> I am searching ghyper package (generalized hypergeometric
> distributions).
> 
> Does anyone can send it to me?
> 
>  
> 
> Regards from Mexico
> 
> Lizbeth Romn


You will find that _function_ in Bob Wheeler's "SuppDists" package on
CRAN:

http://cran.us.r-project.org/src/contrib/Descriptions/SuppDists.html

So use:

install.packages("SuppDists")
library(SuppDists)
?ghyper

HTH,

Marc Schwartz



From sundar.dorai-raj at PDF.COM  Tue Jul 27 21:06:53 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 27 Jul 2004 14:06:53 -0500
Subject: [R] ghyper package
In-Reply-To: <ED7E0E44EAADFB46A6ABA12A647C1306139E7D30@CORREOINT.banxico.org.mx>
References: <ED7E0E44EAADFB46A6ABA12A647C1306139E7D30@CORREOINT.banxico.org.mx>
Message-ID: <4106A7CD.8080504@pdf.com>



Rom??n Padilla Lizbeth wrote:

> Hello
> 
> I am searching ghyper package (generalized hypergeometric distributions).
> 
> Does anyone can send it to me?
> 
>  
> 
> Regards from Mexico
> 
> Lizbeth Rom??n
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


Try install.packages("SuppDists").

--sundar

P.S. You could have discovered this yourself searching CRAN for 
"ghyper", which is what I did.



From mayeul.kauffmann at tiscali.fr  Tue Jul 27 22:36:50 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Tue, 27 Jul 2004 22:36:50 +0200
Subject: [R] BIC vz SBIC vz SIC
Message-ID: <000d01c47419$75834c80$2e4b9a53@amd>

>> 2) question: alwasy on BIC, from stepAIC() function help page I found a
>> "k=log(n)" argument to add. Since that produce an error, is there a way
to
>> found the "n" dinamically?
>
>stepAIC(mydata.logistic, trace = F, k=log(nrow(mydata)))
>
>-- 
>Daniele Medri

(It was 3 weeks ago but I was just myself faced to the same question)

Just a little warning, it is not really "dynamically" done: stepAIC takes
the part of "mydata" that was used to fit "mydata.logistic" but
k=log(nrow(mydata)) will still use the entire set.
thus, if there were some missing data in mydata, I suggest you use
something like:
k=log(sum(complete.cases(mydata)))
which will be smaller than k=log(nrow(mydata)).

If some data are missing only for a covariate and this one is withdrawn,
you will have a warning and it will stop:

Error in stepAIC(mydata.logistic (etc.)
 number of rows in use has changed: remove missing values?

Since (I presume) these criteria need to compare two models with identical
dataset.

In any other case, if you have NAs at the start but the number of NAs does
not change in the process, you won't be warned if you use
k=log(nrow(mydata)).

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France



From mayeul.kauffmann at tiscali.fr  Tue Jul 27 23:10:58 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Tue, 27 Jul 2004 23:10:58 +0200
Subject: [R] Reading and treating multiple files....
Message-ID: <001101c4741e$374cafb0$2e4b9a53@amd>

>I will get - in a few days-  a set of  separate files(one for each
records....~80'000 files pro year)
> named key.txt in which other info (measurements of pressure and velocity
at each second )
>is stocked; typically each one of this separate files will hold something
between 200 and
>1500 records....I'm supposed to do statistical analysis on this dataset,
on the yearly information
>Well, as you can suspect my problem is thus:
>- batch processing of these individual files :reading each file
(automatically!),

I suggest you put all files in a single directory, then you use
list.files ()  or dir()
to make a list of this files.
myfiles <- list.files ("c:\\mydir")  #on windows
Then you do a loop over these files with read.table()
You can create a column named "file" with the name of the file.

All of this can be done with:

data <- NULL;for (i in dir("c:\\temp")) data <-
rbind(data,cbind(file=i,read.table( paste("c:\\mydir\\",i,sep=""))))

Hope that helps

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France



From k.hansen at biostat.ku.dk  Tue Jul 27 23:53:30 2004
From: k.hansen at biostat.ku.dk (Kasper Daniel Hansen)
Date: Tue, 27 Jul 2004 23:53:30 +0200
Subject: [R] interpreting profiling output
In-Reply-To: <x2y8l5ncsn.fsf@biostat.ku.dk>
References: <wqroemflo3m.fsf@biostat.ku.dk> <x2acxo5a6r.fsf@biostat.ku.dk>
	<Pine.LNX.4.58.0407260733040.5095@itasca2.stat.uiowa.edu>
	<wqrekmy6ufp.fsf@biostat.ku.dk> <x2y8l5ncsn.fsf@biostat.ku.dk>
Message-ID: <20040727215330.GA25980@carter.kubism.ku.dk>

On Tue, Jul 27, 2004 at 09:12:56AM +0200, Peter Dalgaard wrote:
> [What did ess-help have to do with this?? Snipped from CC:]

This happens when posting in a hurry using a new mail client. Sorry. See 
below btw.

> Kasper Daniel Hansen <k.hansen at biostat.ku.dk> writes:
> 
> > Thanks to both of you for considering my question. I still have some
> > problems however. Consider the nnet.default function which uses the .C
> > interface. As 
> > > typeof(.C)
> > [1] "builtin"
> > I would guess - from my current understanding - that the time spent in
> > the C functions of nn.default are added to its self.time. Now look at
> > the output
> > 
> > > prof02.out$by.self[1:10,]
> >                   self.time self.pct total.time total.pct
> > nnet.default          33.32     11.2    2186.48      92.1
> > 
> > So nnet.default only used 33.3 on its C calls, but 2186 in total
> > time. From this I would guess that nnet.default - in my case - spends
> > its majority of time setting up the fit and postprocessing it (as this
> > is done by R functions which does not add to its self time). The
> > actual fit (which is done by the C functions) only takes very little
> > time. 
> > 
> > Looking further down the table I see
> > 
> >                   self.time self.pct total.time total.pct
> > as.integer            22.28      7.5      30.92       1.3
> > 
> > as.interger is basically a .Internal call - which ought not to be
> > recorded. But why does it then have such a "high" self.time?
> > 
> > And finally, if a program (such as mine) have a high discrepancy
> > between self.time and sampling.time, does this imply that the far
> > majority of time is spent in .Primitives which are of type special?
> 
> Hmm... You're using summaryRprof(), obviously. Do the results match up
> with what you get from R CMD Rprof? Looking at the source for
> summaryRprof, I see that it uses this construction
> 
> selft <- sapply(ls(envir = self), function(f) get(f, envir =
>     self))
>  
> which I suspect does not count function names that start with a dot...

It does not. Runnig everything through R CMD Rprof gives a much moe 
sensible output. I have no further questions.

Do I file a bug report on summaryRprof - it is certainly unintentional 
that it does not compute eg. .C calls when computing the self time?
-- 
Kasper Daniel Hansen, Research Assistant
Department of Biostatistics, University of Copenhagen



From andy_liaw at merck.com  Wed Jul 28 00:17:10 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 27 Jul 2004 18:17:10 -0400
Subject: [R] interpreting profiling output
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8129@usrymx25.merck.com>

> From: Kasper Daniel Hansen
> 
> On Tue, Jul 27, 2004 at 09:12:56AM +0200, Peter Dalgaard wrote:
> > 
> > Hmm... You're using summaryRprof(), obviously. Do the 
> results match up
> > with what you get from R CMD Rprof? Looking at the source for
> > summaryRprof, I see that it uses this construction
> > 
> > selft <- sapply(ls(envir = self), function(f) get(f, envir =
> >     self))
> >  
> > which I suspect does not count function names that start 
> with a dot...
> 
> It does not. Runnig everything through R CMD Rprof gives a much moe 
> sensible output. I have no further questions.
> 
> Do I file a bug report on summaryRprof - it is certainly 
> unintentional 
> that it does not compute eg. .C calls when computing the self time?

I thought I did see .C in the output of summaryRprof() at one time...

Andy

> -- 
> Kasper Daniel Hansen, Research Assistant
> Department of Biostatistics, University of Copenhagen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ross at ln.nimh.nih.gov  Wed Jul 28 00:25:44 2004
From: ross at ln.nimh.nih.gov (Ross Henderson)
Date: Tue, 27 Jul 2004 18:25:44 -0400 (EDT)
Subject: [R] Re: R-help Digest, Vol 17, Issue 25
In-Reply-To: <200407261011.i6QA5wug002309@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.33.0407271804300.27686-100000@ln.nimh.nih.gov>


hello,

I'm trying to use R to take an image matrix and paint it into a 
tcltk canvas.  I'm using R-1.9.0 within ess-5.2.0 on a linux 
machine running the 2.4.30-31.9smp kernel.  I'm using the
ActiveTcl8.4.6.1-linux-ix86 tcltk libraries.

When I run the following comands, however, I get an R segmentation 
fault:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

> library(tcltk)
> addTclPath("/usr/local/ActiveTcl/lib")
> tclRequire("Img")
<Tcl> 1.3
>tkcmd("image","create","photo",tclVar(),file="/path/to/file.jpg")

Process R segmentation fault at Tue Jul 27 18:18:40 2004

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
I've run this as root, and I get the same segmentation fault,  So I don't 
think this is a permissions problem.  Should I somehow be initializing 
tclVar()?  Can anyone point me to the right way to run this piece of 
code so that I don't get the segmentation fault?

Thanks in advance.

--Ross
<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
Ross Henderson                           National Inst. of Mental Health
Computer Scientist                         National Institutes of Health
Laboratory of Neuropsychology                       Bldg. 49, Room 1B-80
Neural Coding and Computation                    Bethesda, MD  USA 20892
tel:  301-496-5625 ext. 251                   http://neuron.nimh.nih.gov
<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>



From kbartz at loyaltymatrix.com  Wed Jul 28 01:08:18 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Tue, 27 Jul 2004 16:08:18 -0700
Subject: [R] DESCRIPTION.in
Message-ID: <20040727231355.4D4C63FC5C@omta16.mta.everyone.net>

Hello R world! I'm building a bundle of four packages, but I don't always
want to build the whole bundle. Usually I just want to tweak one function in
one of the packages and rebuild just that package. As such, I have
DESCRIPTION and DESCRIPTION.in files sitting in all the package folders.
Unfortunately, there's a pesky line in R CMD build that hacks away
DESCRIPTION whenever it sees DESCRIPTION.in. This is okay for building the
whole bundle, but it makes it a major pain to build any of the packages
individually. I am root, so for now I have commented the offending line in
/usr/local/lib/R/bin/build. Is this the proper solution or am I overlooking
something? Thanks for any help you can provide,

Kevin



From p.dalgaard at biostat.ku.dk  Wed Jul 28 01:28:11 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Jul 2004 01:28:11 +0200
Subject: [R] Re: R-help Digest, Vol 17, Issue 25
In-Reply-To: <Pine.LNX.4.33.0407271804300.27686-100000@ln.nimh.nih.gov>
References: <Pine.LNX.4.33.0407271804300.27686-100000@ln.nimh.nih.gov>
Message-ID: <x2wu0pkp2s.fsf@biostat.ku.dk>

Ross Henderson <ross at ln.nimh.nih.gov> writes:

> hello,
> 
> I'm trying to use R to take an image matrix and paint it into a 
> tcltk canvas.  I'm using R-1.9.0 within ess-5.2.0 on a linux 
> machine running the 2.4.30-31.9smp kernel.  I'm using the
> ActiveTcl8.4.6.1-linux-ix86 tcltk libraries.
> 
> When I run the following comands, however, I get an R segmentation 
> fault:
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> > library(tcltk)
> > addTclPath("/usr/local/ActiveTcl/lib")
> > tclRequire("Img")
> <Tcl> 1.3
> >tkcmd("image","create","photo",tclVar(),file="/path/to/file.jpg")
> 
> Process R segmentation fault at Tue Jul 27 18:18:40 2004
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> I've run this as root, and I get the same segmentation fault,  So I don't 
> think this is a permissions problem.  Should I somehow be initializing 
> tclVar()?  Can anyone point me to the right way to run this piece of 
> code so that I don't get the segmentation fault?

You should assign tclVar() to something, or you will find it difficult
to access its value later on. Wouldn't expect that that could provoke a
segfault though. Could you get us a traceback from the debugger (gdb)?
Also, will similar code run from wish? (need to rule out that it could
be a problem entirely within Tcl).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From k.hansen at biostat.ku.dk  Wed Jul 28 01:26:46 2004
From: k.hansen at biostat.ku.dk (Kasper Daniel Hansen)
Date: Wed, 28 Jul 2004 01:26:46 +0200
Subject: [R] interpreting profiling output
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8129@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8129@usrymx25.merck.com>
Message-ID: <20040727232646.GB26123@carter.kubism.ku.dk>

On Tue, Jul 27, 2004 at 06:17:10PM -0400, Liaw, Andy wrote:
> > From: Kasper Daniel Hansen
> > 
> > On Tue, Jul 27, 2004 at 09:12:56AM +0200, Peter Dalgaard wrote:
> > > 
> > > Hmm... You're using summaryRprof(), obviously. Do the 
> > results match up
> > > with what you get from R CMD Rprof? Looking at the source for
> > > summaryRprof, I see that it uses this construction
> > > 
> > > selft <- sapply(ls(envir = self), function(f) get(f, envir =
> > >     self))
> > >  
> > > which I suspect does not count function names that start 
> > with a dot...
> > 
> > It does not. Runnig everything through R CMD Rprof gives a much moe 
> > sensible output. I have no further questions.
> > 
> > Do I file a bug report on summaryRprof - it is certainly 
> > unintentional 
> > that it does not compute eg. .C calls when computing the self time?
> 
> I thought I did see .C in the output of summaryRprof() at one time...

Well, I tried Peter's fix and it solves the problem for me. I have filed 
a bug report including the fix. Thanks for the help everyone.

-- 
Kasper Daniel Hansen, Research Assistant
Department of Biostatistics, University of Copenhagen



From f.gherardini at pigrecodata.net  Wed Jul 28 04:10:31 2004
From: f.gherardini at pigrecodata.net (Federico Gherardini)
Date: Wed, 28 Jul 2004 04:10:31 +0200
Subject: [R] Another big data size problem
Message-ID: <20040728041031.19a4165b@misha>

Hi all,

I'm trying to read a 1220 * 20000 table in R but I'm having lot of problems. Basically what it happens is that R.bin starts eating all my memory until it gets about 90%. At that point it locks itself in a  uninterruptible sleep status (at least that's what top says) where it just sits there barely using the cpu at all but keeping its tons of memory. I've tried with read.table and scan but none of them did the trick. I've also tried some orrible hack like reading one line a time and gradually combining everything in a matrix using rbind... nope! It seems I can read up to 500 lines in a *decent* time but nothing more. The machine is a 3 GHz P4 with HT and 512 MB RAM running R-1.8.1. Will I have to write a little a C program myself to handle this thing or am I missing something?

Thanks in advance for your help,

fede



From demurget at aleks.com  Wed Jul 28 02:42:30 2004
From: demurget at aleks.com (StephaneDemurget)
Date: Tue, 27 Jul 2004 17:42:30 -0700
Subject: [R] Best way to store negative indexes
Message-ID: <4106F676.1060006@aleks.com>

Hi,

I'm trying to figure out how to properly construct a graph of 
frequencies of a difference between 2 values, that is | i | - | j |.
I'd like to know the best way to store the actual data because of course 
doing my_vector[i -j] will not work because the index could be negative.

I know there's no hash table so what's the best solution, 
simplicity-wise ? Use a list of pair of values {index, i - j} ? Or can I 
somehow use negative index, perhaps using 0array ? Any help would be 
appreciated :)

ATM, I use as.character (i-j) to index my data, but I lose all the 
processing power of R there after.

Sorry If it's written somewhere, but I read a lot of docs about it, 
searched through the ML archives and didn't manage to find an answer.

Please also answer me back at my email address as I am not subscribed to 
the list.

Best regards,

--Stephane



From ramasamy at cancer.org.uk  Wed Jul 28 02:47:13 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 28 Jul 2004 01:47:13 +0100
Subject: [R] Best way to store negative indexes
In-Reply-To: <4106F676.1060006@aleks.com>
References: <4106F676.1060006@aleks.com>
Message-ID: <1090975633.3003.14.camel@localhost.localdomain>

Do you mean something like 
  abs( my_vector[i] - my_vector[j] )

See if reading help("subset") helps.


On Wed, 2004-07-28 at 01:42, StephaneDemurget wrote:
> Hi,
> 
> I'm trying to figure out how to properly construct a graph of 
> frequencies of a difference between 2 values, that is | i | - | j |.
> I'd like to know the best way to store the actual data because of course 
> doing my_vector[i -j] will not work because the index could be negative.
> 
> I know there's no hash table so what's the best solution, 
> simplicity-wise ? Use a list of pair of values {index, i - j} ? Or can I 
> somehow use negative index, perhaps using 0array ? Any help would be 
> appreciated :)
> 
> ATM, I use as.character (i-j) to index my data, but I lose all the 
> processing power of R there after.
> 
> Sorry If it's written somewhere, but I read a lot of docs about it, 
> searched through the ML archives and didn't manage to find an answer.
> 
> Please also answer me back at my email address as I am not subscribed to 
> the list.
> 
> Best regards,
> 
> --Stephane
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From lw7s at cms.mail.virginia.edu  Wed Jul 28 03:30:38 2004
From: lw7s at cms.mail.virginia.edu (Lijuan  Wang)
Date: Tue, 27 Jul 2004 21:30:38 -0400
Subject: [R] a question about using nlme
Message-ID: <web-80263602@cgatepro-4.mail.virginia.edu>

Hi,
I am using Splus to run a multiphase mixed-effects model.
The quations of the models are as below:

gf[ij]=b0[i]+b1[i]*age[ij]+b2[i]*max(0,(age[ij]-tau[i]))^2+e[ij]
b0[i]=b00+e[i0]
b1[i]=b10+e[i1]
b2[i]=b20+e[i2]
tau[i]=tau+e[i3]

i: 1,2,...,100 subjects
j: 1,2,...,6 occasions

The main scripts of Splus is:
simu1<-groupedData(gf~age|id)

simu.nlme<-nlme(gf~(b0 + b1 * age + b2 * 
max(0,(age-tau))^2),data=simu1,fixed=list(b0~1,b1~1,b2~1,tau~1),
+ 
random=list(b0~1,b1~1,b2~1,tau~1),start=c(b0=4,b1=5.32,b2=-5.29,tau=14.8))

But it seems like that there are some errors in it.
Error in .C("mixed_EM",: Singularity in backsolve at level 
2, block 1

I think maybe there is something wrong in my scripts, 
could you help me to find it?
Thanks a lot
Peggy



From andy_liaw at merck.com  Wed Jul 28 03:53:23 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 27 Jul 2004 21:53:23 -0400
Subject: [R] Best way to store negative indexes
Message-ID: <3A822319EB35174CA3714066D590DCD504AF812B@usrymx25.merck.com>

Can you give a simple example of what you are trying to do?

Would the following help?

> x <- sample(10)
> diffMat <- outer(x, x, "-")
> x
 [1]  1 10  5  8  9  6  3  2  4  7
> diffMat
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0   -9   -4   -7   -8   -5   -2   -1   -3    -6
 [2,]    9    0    5    2    1    4    7    8    6     3
 [3,]    4   -5    0   -3   -4   -1    2    3    1    -2
 [4,]    7   -2    3    0   -1    2    5    6    4     1
 [5,]    8   -1    4    1    0    3    6    7    5     2
 [6,]    5   -4    1   -2   -3    0    3    4    2    -1
 [7,]    2   -7   -2   -5   -6   -3    0    1   -1    -4
 [8,]    1   -8   -3   -6   -7   -4   -1    0   -2    -5
 [9,]    3   -6   -1   -4   -5   -2    1    2    0    -3
[10,]    6   -3    2   -1   -2    1    4    5    3     0
> diffTab <- table(diffMat[lower.tri(diffMat, diag=FALSE)])
> diffTab

-8 -7 -6 -5 -4 -3 -2 -1  1  2  3  4  5  6  7  8  9 
 1  2  3  3  3  4  5  4  5  3  3  3  2  1  1  1  1 
> diffTab <- table(abs(diffMat[lower.tri(diffMat, diag=FALSE)]))
> diffTab

1 2 3 4 5 6 7 8 9 
9 8 7 6 5 4 3 2 1 

Andy

> From: StephaneDemurget
> 
> Hi,
> 
> I'm trying to figure out how to properly construct a graph of 
> frequencies of a difference between 2 values, that is | i | - | j |.
> I'd like to know the best way to store the actual data 
> because of course 
> doing my_vector[i -j] will not work because the index could 
> be negative.
> 
> I know there's no hash table so what's the best solution, 
> simplicity-wise ? Use a list of pair of values {index, i - j} 
> ? Or can I 
> somehow use negative index, perhaps using 0array ? Any help would be 
> appreciated :)
> 
> ATM, I use as.character (i-j) to index my data, but I lose all the 
> processing power of R there after.
> 
> Sorry If it's written somewhere, but I read a lot of docs about it, 
> searched through the ML archives and didn't manage to find an answer.
> 
> Please also answer me back at my email address as I am not 
> subscribed to 
> the list.
> 
> Best regards,
> 
> --Stephane
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From mayeul.kauffmann at tiscali.fr  Wed Jul 28 04:06:43 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Wed, 28 Jul 2004 04:06:43 +0200
Subject: [R] covariate selection in cox model (counting process)
Message-ID: <000301c47447$880ed530$2e4b9a53@amd>

>No, I mean recurrent events.  With counting process notation but no
>recurrent revents the partial likelihood is still valid, and the approach
>of treating it as a real likelihood for AIC (and presumably BIC) makes
>sense.
>
>Roughly speaking, you can't tell there is dependence until you see
>multiple events.

Thanks a lot, I got it (well, I hope so)!


I've read in several places that events in the Andersen-Gill model must be
"conditionnaly independent", which is sometimes more precisely written as
"conditionnaly independent given the covariates"

or even more precisely:

"the Andersen-Gill (AG) model assumes that each [individual] has a
multi-event counting process with independent increments. The observed
increments must be conditionally independent given the history of all
observable information up to the event times."
(http://www.stat.umu.se/egna/danardono/licdd.pdf)


Then, there is still another option. In fact, I already modelled
explicitely the influence of past events with a "proximity of last event"
covariate, assuming the dependence on the last event decreases at a
constant rate (for instance, the proximity covariate varies from 1 to 0.5
in the first 10 years after an event, then from 0.5 to 0.25 in the next
ten years, etc).

With a well chosen modelisation of the dependence effect, the events
become conditionnaly independent, I do not need a +cluster(id) term, and I
can use fit$loglik to make a covariate selection based on BIC, right?

Thanks a lot again for your time.

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France

PS: I wrongly concluded from the R statement "(Note: the likelihood ratio
and score tests assume independence of observations within a cluster, the
Wald and robust score tests do not). " that it meant independence between
two consecutive observations (without any event). It made sense to  me
because when only one covariate changes for a given individual, and with a
small change, there is a new observation, with a risk very simlar to the
risk for the previous observation. But there is still independence with
respect to the question of recurrent event. Maybe the warning should be
rewritten saying "assume *conditionnal* independence of *events* (given
the covariates)"



From rossini at blindglobe.net  Wed Jul 28 04:40:29 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 27 Jul 2004 19:40:29 -0700
Subject: [R] a question about using nlme
In-Reply-To: <web-80263602@cgatepro-4.mail.virginia.edu> (Lijuan Wang's
	message of "Tue, 27 Jul 2004 21:30:38 -0400")
References: <web-80263602@cgatepro-4.mail.virginia.edu>
Message-ID: <85ekmwhn1e.fsf@servant.blindglobe.net>

"Lijuan  Wang" <lw7s at cms.mail.virginia.edu> writes:

> I am using Splus ...

So why post to an R list?

best,
-tony

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From spamiam at aroint.org  Wed Jul 28 05:14:39 2004
From: spamiam at aroint.org (Daniel)
Date: Tue, 27 Jul 2004 23:14:39 -0400 (EDT)
Subject: [R] automating sequence of multinomial regressions
Message-ID: <Pine.LNX.4.58.0407272301300.10032@aroint.org>

Disclaimer first: I only heard about R fairly recently, so I apologize if
this is either a simple or impossible request, but R looked like it
might be a good framework for this sort of thing...

Is it possible to write a script to run stepwise multinomial regressions
on many *dependent* variables, and then compare results to a validation
data set (e.g., Chow test)? Essentially, automate the process of finding
best predictive model using a host of dependent and independent variables.

I have a fairly short timeframe to work on this, so if someone is
willing to help me in the next couple of days, I would be most
appreciative. (And there might even be a hefty sum of cash involved!)

Thanks,

Daniel



From ggrothendieck at myway.com  Wed Jul 28 07:06:30 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 28 Jul 2004 05:06:30 +0000 (UTC)
Subject: [R] automating sequence of multinomial regressions
References: <Pine.LNX.4.58.0407272301300.10032@aroint.org>
Message-ID: <loom.20040728T062802-397@post.gmane.org>

Daniel <spamiam <at> aroint.org> writes:

> 
> Disclaimer first: I only heard about R fairly recently, so I apologize if
> this is either a simple or impossible request, but R looked like it
> might be a good framework for this sort of thing...
> 
> Is it possible to write a script to run stepwise multinomial regressions
> on many *dependent* variables, and then compare results to a validation
> data set (e.g., Chow test)? Essentially, automate the process of finding
> best predictive model using a host of dependent and independent variables.
> 
> I have a fairly short timeframe to work on this, so if someone is
> willing to help me in the next couple of days, I would be most
> appreciative. (And there might even be a hefty sum of cash involved!)

Setting aside the basic overfitting problems, the following does
a stepwise regression on each of 10 dependent variables using
the first 100 rows of birthwt.  For the result of each of these
10 it then calculates the number of correct predictions using
the remaining rows.


require(nnet)
require(MASS)

# use birthwt data set and generate random matrix whose 10 cols are dep vars
data(birthwt)
set.seed(1)
dep <- matrix(sample(2,189*10,rep=T),189)-1 

# run one stepwise procedure for each dep variable using rows 1 to 100
# and store result in z so that z[[i]] has output from ith dep variable
z <- apply(dep[1:100,], 2, function(d) 
         step(multinom(formula = d ~., data = birthwt[1:100,-1])))

# calculate number of correct predictions for each model using rows 101 to 189
sapply(z,function(x) sum(predict(x, birthwt[101:189,-1]) == birthwt
[101:189,1]))



From jajanmaat at netscape.net  Wed Jul 28 08:16:48 2004
From: jajanmaat at netscape.net (John Janmaat)
Date: Wed, 28 Jul 2004 08:16:48 +0200
Subject: [R] Underline in expression().
In-Reply-To: <41067D20.70108@pdf.com>
References: <41060ED9.5070907@netscape.net> <41067D20.70108@pdf.com>
Message-ID: <410744D0.8080107@netscape.net>

Sundar,

Thanks.  Unfortunately, I am looking for something that also works in 
the margins of the plot.

John.

Sundar Dorai-Raj wrote:
> 
> 
> John Janmaat wrote:
> 
>> Hello All,
>>
>> Is there an analogue to \underbar or the AMS math \underline in 
>> graphical math expressions?
>>
>> Thanks,
>>
>> John.
> 
> 
> Uwe Ligges posted a solution a couple of years ago. I don't know if 
> there is anything built in yet. ?plotmath does not seem to say anything 
> about underlining.
> 
> http://finzi.psych.upenn.edu/R/Rhelp01/archive/7191.html
> 
> plot(0:1, 0:1, type="n")
> underlined(0.5, 0.5, expression(widehat(x %*% y)))
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

-- 
=====================================================================================
Dr. John Janmaat
Department of Economics
Acadia University
Wolfville, Nova Scotia, Canada
B4P 2R6
TEL: 902-585-1461
WWW: http://ace.acadiau.ca/~jjanmaat/
EMAIL: jjanmaat at acadiau.ca

June 10, 2004 to September 7, 2004
Dr. John Janmaat
Environmental Econmics and Natural Resources Group
Wageningen University.
P.O. Box 8130
6700 EW, Wageningen
The Netherlands.



From p.dalgaard at biostat.ku.dk  Wed Jul 28 09:14:43 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Jul 2004 09:14:43 +0200
Subject: [R] Best way to store negative indexes
In-Reply-To: <4106F676.1060006@aleks.com>
References: <4106F676.1060006@aleks.com>
Message-ID: <x21xiw4n8c.fsf@biostat.ku.dk>

StephaneDemurget <demurget at aleks.com> writes:

> Hi,
> 
> I'm trying to figure out how to properly construct a graph of
> frequencies of a difference between 2 values, that is | i | - | j |.
> I'd like to know the best way to store the actual data because of
> course doing my_vector[i -j] will not work because the index could be
> negative.
> 
> I know there's no hash table so what's the best solution,
> simplicity-wise ? Use a list of pair of values {index, i - j} ? Or can
> I somehow use negative index, perhaps using 0array ? Any help would be
> appreciated :)

(i and j are integer vectors, right?)
How about this:

  f <- i - j
  f <- factor(f,levels=min(f):max(f))
  table(f)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Wed Jul 28 09:53:08 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 28 Jul 2004 09:53:08 +0200
Subject: [R] Another big data size problem
In-Reply-To: <20040728041031.19a4165b@misha>
References: <20040728041031.19a4165b@misha>
Message-ID: <41075B64.8080507@statistik.uni-dortmund.de>

Federico Gherardini wrote:

> Hi all,
> 
> I'm trying to read a 1220 * 20000 table in R but I'm having lot of problems. Basically what it happens is that R.bin starts eating all my memory until it gets about 90%. At that point it locks itself in a  uninterruptible sleep status (at least that's what top says) where it just sits there barely using the cpu at all but keeping its tons of memory. I've tried with read.table and scan but none of them did the trick. I've also tried some orrible hack like reading one line a time and gradually combining everything in a matrix using rbind... nope! It seems I can read up to 500 lines in a *decent* time but nothing more. The machine is a 3 GHz P4 with HT and 512 MB RAM running R-1.8.1. Will I have to write a little a C program myself to handle this thing or am I missing something?

If your data is numeric, you will need roughly

1220 * 20000 * 8 / 1024 / 1024  ~~ 200 MB

just to store one copy in memory. If you need more than two copies, your 
machine with its 512MB will start to use swap space .....
Hence either use a machine with more memory, or don't use all the data 
at once in memory, e.g. by making use of a database.

Uwe Ligges




> Thanks in advance for your help,
> 
> fede
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Wed Jul 28 10:03:34 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 28 Jul 2004 10:03:34 +0200
Subject: [R] Integration with "adapt"
In-Reply-To: <3628.143.106.4.184.1090953067.squirrel@143.106.4.184>
References: <3628.143.106.4.184.1090953067.squirrel@143.106.4.184>
Message-ID: <16647.24022.35331.463267@gargle.gargle.HOWL>

>>>>> "Rodrigo" == Rodrigo Drummond <rduarte at unicamp.br>
>>>>>     on Tue, 27 Jul 2004 15:31:07 -0300 (BRT) writes:

    Rodrigo> Hi all, I need to calculate a multidimensional
    Rodrigo> integration on R. I am using the command
    Rodrigo> "adapt" (from library adapt), although

it's a "package", not a library.

    Rodrigo> sometimes I get the following error message:

    Rodrigo> Ifail=2, lenwrk was too small. -- fix adapt() !
    Rodrigo> Check the returned relerr! in: adapt(3, linf, lsup,
    Rodrigo> functn = Integrando1)

If you could give as a *reproducible* example,

we (the adapt authors) would have chance to do what the above
message says, namely "fix adapt()" ..


    Rodrigo> I guess it happens because the domain of
    Rodrigo> integration is too small,

maybe, maybe not. We need an example we can reproduce, see above.

    Rodrigo> although I tried a change of variables to avoid
    Rodrigo> this problem and it didn?t help. The command adapt
    Rodrigo> calls a fortran routine, but I don?t know fortran
    Rodrigo> enough to fix the problem.

Martin Maechler, ETH Zurich



From Nathalie.Peyrard at avignon.inra.fr  Wed Jul 28 10:09:30 2004
From: Nathalie.Peyrard at avignon.inra.fr (Peyrard Nathalie)
Date: Wed, 28 Jul 2004 10:09:30 +0200
Subject: [R] problem with the .Rhistory
Message-ID: <41075F3A.6080901@avignon.inra.fr>

Hello,

The history function doesn't seems to work when I am working with R.
I have a .Rhistory file in my working directory and I have tried
         savehistory(file = ".Rhistory")
or the command given in the history help :
         .Last <- function()
                   if(interactive()) try(savehistory(".Rhistory"))

and I  get the same error message
Error in savehistory(file) : no history available to save

Is there any other variable to set up?


  Nathalie Peyrard



From ripley at stats.ox.ac.uk  Wed Jul 28 10:32:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jul 2004 09:32:53 +0100 (BST)
Subject: [R] problem with the .Rhistory
In-Reply-To: <41075F3A.6080901@avignon.inra.fr>
Message-ID: <Pine.LNX.4.44.0407280928190.5427-100000@gannet.stats>

It depends on your platform.  E.g. on Unix/Linux, ?savehistory says

Details:

     This works under the 'readline' and GNOME interfaces, but not if
     'readline' is not available (for example, in batch use).

To be able to help you further, we would need quite precise details of 
your platform and which interface you are using.


On Wed, 28 Jul 2004, Peyrard Nathalie wrote:

> The history function doesn't seems to work when I am working with R.
> I have a .Rhistory file in my working directory and I have tried
>          savehistory(file = ".Rhistory")
> or the command given in the history help :
>          .Last <- function()
>                    if(interactive()) try(savehistory(".Rhistory"))
> 
> and I  get the same error message
> Error in savehistory(file) : no history available to save

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From matthieu.cornec at insee.fr  Wed Jul 28 10:41:17 2004
From: matthieu.cornec at insee.fr (Cornec Matthieu)
Date: Wed, 28 Jul 2004 10:41:17 +0200
Subject: [R] Latex error about Schunk environment under Windows NT
Message-ID: <4BFA0FD18E9ED311AC040000F6AF0489044EA4BB@S54X01>

Hi,

I am running the Sweave function on a Rnw file.
It produces a tex file with
\begin{Schunk}
\begin{Sinput}

\end{Sinput}
\end{Schunk}

and when I try to compile the tex file, I get a 
"Latex error : Environment Schunk undefined"

However, I wrote "\usepackage{Sweave}" at the beginning of my Rnw file
And the file "Sweave.sty" does exist in my tex files.

I am not experiencing the same trouble with my personal computer at home.
However I did the same steps. Is it due to Windows NT 
(my home computer runs under XP) and shall I install another latex package?

Anything would help.
Thanks a lot in advance,

Matthieu Cornec



From ernesto at ipimar.pt  Wed Jul 28 10:58:54 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 28 Jul 2004 09:58:54 +0100
Subject: [R] Another big data size problem
In-Reply-To: <20040728041031.19a4165b@misha>
References: <20040728041031.19a4165b@misha>
Message-ID: <1091005134.3415.7.camel@gandalf.local>

On Wed, 2004-07-28 at 03:10, Federico Gherardini wrote:
> Hi all,
> 
> I'm trying to read a 1220 * 20000 table in R but I'm having lot of problems. Basically what it happens is that R.bin starts eating all my memory until it gets about 90%. At that point it locks itself in a  uninterruptible sleep status (at least that's what top says) where it just sits there barely using the cpu at all but keeping its tons of memory. I've tried with read.table and scan but none of them did the trick. I've also tried some orrible hack like reading one line a time and gradually combining everything in a matrix using rbind... nope! It seems I can read up to 500 lines in a *decent* time but nothing more. The machine is a 3 GHz P4 with HT and 512 MB RAM running R-1.8.1. Will I have to write a little a C program myself to handle this thing or am I missing something?
> 
> Thanks in advance for your help,
> 
> fede
> 

Hi,

It looks like you're running linux !? if so it will be quite easy to
create a table in MySQL, upload all the data into the database and
access the data with RMySQL (it's _very_ fast). Probably there will be
some operations that you can do on MySQL instead of "eating" memory in
R.

Regards

EJ



From ligges at statistik.uni-dortmund.de  Wed Jul 28 11:20:49 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 28 Jul 2004 11:20:49 +0200
Subject: [R] Latex error about Schunk environment under Windows NT
In-Reply-To: <4BFA0FD18E9ED311AC040000F6AF0489044EA4BB@S54X01>
References: <4BFA0FD18E9ED311AC040000F6AF0489044EA4BB@S54X01>
Message-ID: <41076FF1.9030307@statistik.uni-dortmund.de>

Cornec Matthieu wrote:

> Hi,
> 
> I am running the Sweave function on a Rnw file.
> It produces a tex file with
> \begin{Schunk}
> \begin{Sinput}
> 
> \end{Sinput}
> \end{Schunk}
> 
> and when I try to compile the tex file, I get a 
> "Latex error : Environment Schunk undefined"
> 
> However, I wrote "\usepackage{Sweave}" at the beginning of my Rnw file
> And the file "Sweave.sty" does exist in my tex files.
> 
> I am not experiencing the same trouble with my personal computer at home.
> However I did the same steps. Is it due to Windows NT 
> (my home computer runs under XP) and shall I install another latex package?
> 
> Anything would help.
> Thanks a lot in advance,
> 
> Matthieu Cornec
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

It is required to have the style file, of course.
Calling Swaeve() from R should work (but there are some known MikTeX 
related problems) anyway.

You can find the style file in folder .../share/texmf

Uwe Ligges



From f.gherardini at pigrecodata.net  Wed Jul 28 13:40:58 2004
From: f.gherardini at pigrecodata.net (Federico Gherardini)
Date: Wed, 28 Jul 2004 13:40:58 +0200
Subject: Fw: [R] Another big data size problem
Message-ID: <20040728134058.3918f05e@misha>

On Wed, 28 Jul 2004 09:53:08 +0200
Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:

> 
> If your data is numeric, you will need roughly
> 
> 1220 * 20000 * 8 / 1024 / 1024  ~~ 200 MB
> 
> just to store one copy in memory. If you need more than two copies, your 
> machine with its 512MB will start to use swap space .....
> Hence either use a machine with more memory, or don't use all the data 
> at once in memory, e.g. by making use of a database.
> 
> Uwe Ligges
> 
Well I'd be happy if it used swap space instead of locking itself up! By the way I don't think that the problem is entirely related to memory consumption. I have written a little function that reads the data row by row and does a print each time, to monitor its functioning. Everything starts to crwal to an horrible slowness long before my memory is exhausted... i.e.: after about 100 lines. It seems like R has problems managing very large objects per se? By the way I'll try to upgrade to 1.9 and see what happens...

Ernesto Jardim wrote:

>Hi,
>
>It looks like you're running linux !? if so it will be quite easy to
>create a table in MySQL, upload all the data into the database and
>access the data with RMySQL (it's _very_ fast). Probably there will be
>some operations that you can do on MySQL instead of "eating" memory in
>R.

>Regards

>EJ

I'll give that a try.

Thanks everybody for their time

fede



From ligges at statistik.uni-dortmund.de  Wed Jul 28 12:45:57 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 28 Jul 2004 12:45:57 +0200
Subject: Fw: [R] Another big data size problem
In-Reply-To: <20040728134058.3918f05e@misha>
References: <20040728134058.3918f05e@misha>
Message-ID: <410783E5.3020405@statistik.uni-dortmund.de>

Federico Gherardini wrote:

> On Wed, 28 Jul 2004 09:53:08 +0200
> Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> 
> 
>>If your data is numeric, you will need roughly
>>
>>1220 * 20000 * 8 / 1024 / 1024  ~~ 200 MB
>>
>>just to store one copy in memory. If you need more than two copies, your 
>>machine with its 512MB will start to use swap space .....
>>Hence either use a machine with more memory, or don't use all the data 
>>at once in memory, e.g. by making use of a database.
>>
>>Uwe Ligges
>>
> 
> Well I'd be happy if it used swap space instead of locking itself up! By the way I don't think that the problem is entirely related to memory consumption. I have written a little function that reads the data row by row and does a print each time, to monitor its functioning. Everything starts to crwal to an horrible slowness long before my memory is exhausted... i.e.: after about 100 lines. It seems like R has problems managing very large objects per se? By the way I'll try to upgrade to 1.9 and see what happens...

Well, using swap space takes much time. And what looks like hanging up 
is quite probably the use of swap space  - you will see your hard disc 
LED flashing all the time!

Are you sure that your memory was not exhausted?
Note that it is better to initialize the object to full size before 
inserting -- rather than using rbind() and friends which is indeed slow 
since it need to re-allocate much memory for each step.

Uwe


> Ernesto Jardim wrote:
> 
> 
>>Hi,
>>
>>It looks like you're running linux !? if so it will be quite easy to
>>create a table in MySQL, upload all the data into the database and
>>access the data with RMySQL (it's _very_ fast). Probably there will be
>>some operations that you can do on MySQL instead of "eating" memory in
>>R.
> 
> 
>>Regards
> 
> 
>>EJ
> 
> 
> I'll give that a try.
> 
> Thanks everybody for their time
> 
> fede
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rolf at math.unb.ca  Wed Jul 28 12:53:07 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 28 Jul 2004 07:53:07 -0300 (ADT)
Subject: [R] problem with the .Rhistory
Message-ID: <200407281053.i6SAr7Am027714@erdos.math.unb.ca>


I recall having a similar problem a while back, and it turned out
that it was due to command line editing not being available.  This in
turn was due to a problem with the readline package.  I think we had
a flakey version (obtained as a Sun package?) and when we got another
version (from GNU?) and installed it --- and then rebuilt R ---
command line editing (and savehistory()) worked fine.

Sorry to be vague, but I don't have good records of what went
on, and it was a couple of years ago.

Check on command line editing first --- in R execute

	capabilities()

and if ``cledit'' turns out to be FALSE, then readline is probably
your problem.  Peter Dalgaard may be able to give you better insight
as to how to fix it.

				cheers,

					Rolf Turner
					rolf at math.unb.ca

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

Nathalie.Peyrard wrote:

> The history function doesn't seems to work when I am working with R.
> I have a .Rhistory file in my working directory and I have tried
>          savehistory(file = ".Rhistory")
> or the command given in the history help :
>          .Last <- function()
>                    if(interactive()) try(savehistory(".Rhistory"))
> 
> and I  get the same error message
> Error in savehistory(file) : no history available to save
> 
> Is there any other variable to set up?



From ozric at web.de  Wed Jul 28 13:40:19 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 28 Jul 2004 13:40:19 +0200
Subject: [R] Another big data size problem
In-Reply-To: <20040728041031.19a4165b@misha>
References: <20040728041031.19a4165b@misha>
Message-ID: <200407281340.19999.ozric@web.de>

Hi,

i'm working with a ~ 250.000  * 150  data.frame and can share 
your problems - i've upgraded last weekend my notebook 
from 512MB -> 1024MB, it's really better especially for load, write.table , 
mysqlReadTable, mysqlWriteTable, because machine begin  caching if RAM
is full. One example: 
With 512MB i get after some hours no success write a table to mysql.
With 1024MB it does in some minutes.

regards, christian


Am Mittwoch, 28. Juli 2004 04:10 schrieb Federico Gherardini:
> Hi all,
>
> I'm trying to read a 1220 * 20000 table in R but I'm having lot of
> problems. Basically what it happens is that R.bin starts eating all my
> memory until it gets about 90%. At that point it locks itself in a 
> uninterruptible sleep status (at least that's what top says) where it just
> sits there barely using the cpu at all but keeping its tons of memory. I've
> tried with read.table and scan but none of them did the trick. I've also
> tried some orrible hack like reading one line a time and gradually
> combining everything in a matrix using rbind... nope! It seems I can read
> up to 500 lines in a *decent* time but nothing more. The machine is a 3 GHz
> P4 with HT and 512 MB RAM running R-1.8.1. Will I have to write a little a
> C program myself to handle this thing or am I missing something?
>
> Thanks in advance for your help,
>
> fede
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ernesto at ipimar.pt  Wed Jul 28 14:28:20 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 28 Jul 2004 13:28:20 +0100
Subject: [R] Another big data size problem
In-Reply-To: <200407281340.19999.ozric@web.de>
References: <20040728041031.19a4165b@misha> <200407281340.19999.ozric@web.de>
Message-ID: <1091017700.3416.36.camel@gandalf.local>

On Wed, 2004-07-28 at 12:40, Christian Schulz wrote:
> Hi,
> 
> i'm working with a ~ 250.000  * 150  data.frame and can share 
> your problems - i've upgraded last weekend my notebook 
> from 512MB -> 1024MB, it's really better especially for load, write.table , 
> mysqlReadTable, mysqlWriteTable, because machine begin  caching if RAM
> is full. One example: 
> With 512MB i get after some hours no success write a table to mysql.
> With 1024MB it does in some minutes.
> 

Hi,

When you're writing a table to MySQL you have to be carefull if the
table is created by RMySQL. The fields definition may not be the most
adequate and there will be no indexes in your table, which makes the
queries _very_ slow.

Regards

EJ



From tore.wentzel-larsen at helse-bergen.no  Wed Jul 28 14:25:54 2004
From: tore.wentzel-larsen at helse-bergen.no (Tore Wentzel-Larsen)
Date: Wed, 28 Jul 2004 14:25:54 +0200
Subject: [R] Re: group definition for a bootstrap
Message-ID: <7132663E78AE3E45AD4471CBC2738EF5413DE3@EC3.ihelse.net>

Hi,
There dose not seem to be any other replies so far, may be because the question
is not quite clear. Do you want a separate estimation of the 'precision of the mean'
for each age by quarter subsample? This reply is based on that interpretation.
If not, you may need some sort of stratified bootstrap (see the article by Canty 
mentioned in the code below).
Also, since you want to use the bootstrap for the mean, are the (age by quarter)
subsample sizes small, or the subsamples heavily skewed?
In any case it is better to use the package boot by Canty and Ripley than programming 
from scratch. A good introduction to this package is written by Angelo J. Canty in R 
Newsletter 2/3, December 2002. 
The following code first generates an aretificial (large) data frame dd with the same structure
as your fram d. Then it performs bootstrap calculations in each age by quarter subsample.
The output includes for each subsample bootstrap based bias and standard error for the mean,
plots for checking discreteness problems of the bootstrap and normal and BCa confidence intervals.

To use this code for your sample it should suffice to set 

dd <- d

and start at the line
# prepares bootstrap procedure for the mean

in the code. The code has been checked for the large artificial sample generated.
It will probably break down if some subsamples are empty or nearly so.
And there may be discreteness problems if some subsamples are small, although the
bootstrap is fairly stable for means.

Best,
Tore Wentzel-Larsen


# 'Group definition for a bootstrap'

# generates artificial data frame dd to use (age and quarter as factors in case they are in your data):
nn <- floor(runif(1,1000,2000)) # random sample size
dd <- data.frame(factor(floor(runif(nn,0,6))), factor(floor(runif(nn,1,5))), rnorm(nn,15,3))
names(dd) <- c('age','quarter','x')

# prepares bootstrap procedure for the mean
#	(cf the article by Angelo J. Canty in R Newsletter 2/3, December 2002):

library(boot)
mean.w <- function(xx,ww) sum(xx*ww)

# means, with bootstrap estimates of bias and standard error,
#	for each age by quarter subsample:

nboot <- 1000 # number of bootstrap replications

par(ask = TRUE) # prompts before next plot
for (age in 0:5)
{
for (quarter in 1:4)
{
dd.sub <- dd[dd$age==age&dd$quarter==quarter,] # the subsample
boot.subsample <- boot(data=dd.sub$x, statistic=mean.w, R=nboot, stype='w')
print(boot.subsample)
print(c('age:', age, 'quarter:', quarter)) # for keeping track of the subsamples
plot(boot.subsample,) # checks for discreteness problems
# bootstrap confidence intervals (normal based and BCa):
ci.subsample <- boot.ci(boot.subsample, type=c('norm','bca'), conf=c(.95))
print(ci.subsample)
} 
}

par(ask = FALSE) # back to default setting for ask





> Hi,
> This is probably really simple, but I am clearly not R-minded, I have read
> the help files, and reread them, and I still can't work out what to do...
> I have a data frame (d) with 3 columns (age (0-5), quarter (1-4) and x).
> I want to estimate the precision of my mean x by age and quarter, so I want
> to carry out a bootstrap for each group.
> I am trying to do this within a loop, so I don't have to retype the whole
> thing out 20 times ...
> This is what I have done:
> 
> n = length (d$x)
> N = 1000
> stat = numeric(N)
> for (i in 1:N) {
> d$x2 = sample (d$x, n, replace=T)
> stat[i] = mean(d$x2)
> }
> 
> I believe I should define the age and quarter groups in the line straight
> after "for" - using the split function, or should I use some variant of
> [d$age == "1" & d$quarter =="1"] in the sample definition?
> Please don't think I am looking for an easy answer - I have been puzzling
> for this for over a week already :(
> (I am using R1.9 under MS W2000)
> Thank you in advance
> Louize



From sb at ihe.se  Wed Jul 28 14:58:28 2004
From: sb at ihe.se (Sixten Borg)
Date: Wed, 28 Jul 2004 14:58:28 +0200
Subject: [R] Simulation from a model fitted by survreg.
Message-ID: <s107bf30.052@gwmail.ihe.se>

Dear list,

I would like to simulate individual survival times from a model that has been fitted using the survreg procedure (library survival). Output shown below.

My plan is to extract the shape and scale arguments for use with rweibull() since my error terms are assumed to be Weibull, but it does not make any sense. The mean survival time is easy to predict, but I would like to simulate individual survival times.

I am probably missing something completely obvious. Any hints or advice are appreciated.

Thanks
Sixten

> summary(mod1)

Call:
survreg(formula = Surv(tid, study$first.event.death) ~ regim + 
    age + stadium2, data = study, dist = "weibull")
              Value Std. Error      z        p
(Intercept) 11.6005     0.7539 15.387 2.01e-53
regimposto  -0.1350     0.1558 -0.867 3.86e-01
age         -0.0362     0.0102 -3.533 4.11e-04
stadium2ii  -0.0526     0.2794 -0.188 8.51e-01
Log(scale)  -0.5148     0.1116 -4.615 3.93e-06

Scale= 0.598 

Weibull distribution
Loglik(model)= -680.7   Loglik(intercept only)= -689.2
        Chisq= 16.87 on 3 degrees of freedom, p= 0.00075 
Number of Newton-Raphson Iterations: 8 
n=1183 (4 observations deleted due to missing)

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.1            
year     2003           
month    11             
day      21             
language R              
>



From patrick.giraudoux at univ-fcomte.fr  Wed Jul 28 15:08:59 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 28 Jul 2004 15:08:59 +0200
Subject: [R] Writing polyline shapefiles
Message-ID: <006601c474a4$0e40c1c0$90f00e50@PC728329681112>

Stephane, dear R listers,

I wonder if the idea of developping some functions in R writing shapefiles from a matrix of coordinates  -eg poly2shape()- is still
with us? I currently manage with a home-made function writing an ASCII grass file, then importing it into GRASS as vector file, then
exporting the vector file as a shapefile (ouf!). The main issue to me is still to be capable to wite the *.shx and *.shp from
coordinates (the *.dbf is easier to manage, even indirectly, and can for instance be completed simply via Excel).  I tried to open
*.shp, etc.. files to understand how they were structured and thus write some programme by myself, but unsuccessfully (the way those
files are coded is not ascii)

Maptools is fantastic for importation and data handling within R, but unfortunately cannot export to shapefiles.

Any news?

Patrick Giraudoux


PS: ESRI has managed to distribute ArcTools (with ArcGIS) with no way to importe generate ASCII formats!!! One must get ArcINFO for
that... No comment!



From f.gherardini at pigrecodata.net  Wed Jul 28 17:26:10 2004
From: f.gherardini at pigrecodata.net (Federico Gherardini)
Date: Wed, 28 Jul 2004 17:26:10 +0200
Subject: [R] Another big data size problem
In-Reply-To: <1091017700.3416.36.camel@gandalf.local>
References: <20040728041031.19a4165b@misha> <200407281340.19999.ozric@web.de>
	<1091017700.3416.36.camel@gandalf.local>
Message-ID: <20040728172610.70c9fa2f@misha>

On Wed, 28 Jul 2004 13:28:20 +0100
Ernesto Jardim <ernesto at ipimar.pt> wrote:


> Hi,
> 
> When you're writing a table to MySQL you have to be carefull if the
> table is created by RMySQL. The fields definition may not be the most
> adequate and there will be no indexes in your table, which makes the
> queries _very_ slow.
> 
So, if I understood correctly, if you want to use SQL you'll have to upload the table in SQL, directly from MySQL without using R at all, and then use RMySQL to read the elements in R?

Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:

>Note that it is better to initialize the object to full size before 
>inserting -- rather than using rbind() and friends which is indeed slow
>since it need to re-allocate much memory for each step.

Do you mean something like this?

tab <- matrix(rep(0, 1227 * 20000), 1227, 20000, byrow = TRUE)

for(i in 0:num.lines)
	tab[i + 1,] <- scan("mytab", nlines = 1, what="PS", skip = i)
	

The above doesn't get very far either... it seems that, once it has created the table, it becomes so slow that it's unusable. I'll have to try this with more RAM by the way.

Cheers,

fede



From rksh at soc.soton.ac.uk  Wed Jul 28 15:25:53 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 28 Jul 2004 14:25:53 +0100
Subject: [R] elegant matrix creation
Message-ID: <a0600200abd2d59a97c4d@[139.166.242.29]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040728/468c7de9/attachment.pl

From ernesto at ipimar.pt  Wed Jul 28 16:16:43 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 28 Jul 2004 15:16:43 +0100
Subject: [R] Another big data size problem
In-Reply-To: <20040728172610.70c9fa2f@misha>
References: <20040728041031.19a4165b@misha> <200407281340.19999.ozric@web.de>
	<1091017700.3416.36.camel@gandalf.local>
	<20040728172610.70c9fa2f@misha>
Message-ID: <1091024203.3397.54.camel@gandalf.local>

On Wed, 2004-07-28 at 16:26, Federico Gherardini wrote:
> On Wed, 28 Jul 2004 13:28:20 +0100
> Ernesto Jardim <ernesto at ipimar.pt> wrote:
> 
> 
> > Hi,
> > 
> > When you're writing a table to MySQL you have to be carefull if the
> > table is created by RMySQL. The fields definition may not be the most
> > adequate and there will be no indexes in your table, which makes the
> > queries _very_ slow.
> > 
> So, if I understood correctly, if you want to use SQL you'll have to upload the table in SQL, directly from MySQL without using R at all, and then use RMySQL to read the elements in R?
> 

If you can't get R to read the table then you can't use R/RMySQL ;)

When creating tables in MySQL you may improve a lot the speed of scaning
the table with the proper fields definition and indexing. See the MySQL
manual, it is a very good reference and quite easy to read (at least the
sections related with table design).

The basis is to create indexes for the fields you're supose to restrict
(fields to be used with the "WHERE" clause in SQL statements)
considering the order of those fields.

Regards

EJ



From spencer.graves at pdf.com  Wed Jul 28 16:15:45 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 28 Jul 2004 07:15:45 -0700
Subject: [R] Simulation from a model fitted by survreg.
In-Reply-To: <s107bf30.052@gwmail.ihe.se>
References: <s107bf30.052@gwmail.ihe.se>
Message-ID: <4107B511.1070603@pdf.com>

      Please check the documentation, e.g., Venables and Ripley (2002) 
Modern Applied Statistics with S, p. 360.  The Weibull shape parameter 
is the reciprocal of the scale parameter 0.598 in your printout, so 
shape = 1/0.598 = 1.672;  see also Meeker & Escobar (1998) Statistical 
Methods for Reliability Data (Wiley). 

      Does this answer the question?  You can get coefficients with 
coef(mod1).  Also, have you looked at attributes(summary(mod1))?  If 
"mod1" follows the old S3 standard, attributes may give you a list of 
names you can access via summary(mod1)$whateverthenameis (or via 
summary(mod1)[["whateverthenameis"]]).  If "mod1" follows the new S4 
standard, then getSlots(mod1) and getSlots(summary(mod1)) will give you 
the names of the slots and their classes, which can then be accessed via 
mod1 at nameofslotofinterest.  Sorry, I don't have time to construct an 
example myself, but I've done this kind of thing many times. 

      hope this helps. 
      spencer graves    

Sixten Borg wrote:

>Dear list,
>
>I would like to simulate individual survival times from a model that has been fitted using the survreg procedure (library survival). Output shown below.
>
>My plan is to extract the shape and scale arguments for use with rweibull() since my error terms are assumed to be Weibull, but it does not make any sense. The mean survival time is easy to predict, but I would like to simulate individual survival times.
>
>I am probably missing something completely obvious. Any hints or advice are appreciated.
>
>Thanks
>Sixten
>
>  
>
>>summary(mod1)
>>    
>>
>
>Call:
>survreg(formula = Surv(tid, study$first.event.death) ~ regim + 
>    age + stadium2, data = study, dist = "weibull")
>              Value Std. Error      z        p
>(Intercept) 11.6005     0.7539 15.387 2.01e-53
>regimposto  -0.1350     0.1558 -0.867 3.86e-01
>age         -0.0362     0.0102 -3.533 4.11e-04
>stadium2ii  -0.0526     0.2794 -0.188 8.51e-01
>Log(scale)  -0.5148     0.1116 -4.615 3.93e-06
>
>Scale= 0.598 
>
>Weibull distribution
>Loglik(model)= -680.7   Loglik(intercept only)= -689.2
>        Chisq= 16.87 on 3 degrees of freedom, p= 0.00075 
>Number of Newton-Raphson Iterations: 8 
>n=1183 (4 observations deleted due to missing)
>
>  
>
>>version
>>    
>>
>         _              
>platform i386-pc-mingw32
>arch     i386           
>os       mingw32        
>system   i386, mingw32  
>status                  
>major    1              
>minor    8.1            
>year     2003           
>month    11             
>day      21             
>language R              
>  
>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From t.dewez at brgm.fr  Wed Jul 28 16:23:30 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Wed, 28 Jul 2004 16:23:30 +0200
Subject: [R] using Rterm under cygwin, no possiblity to delete characters
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD6891@SRV0015>

Dear R-users,

When I call Rterm from cygwin, I have no options but typing the exact syntax
the first time. If I happen to hit the "delete" key (backspace), R dies when
I press enter saying :

Error: ... (error concerning the function on the last line of text)
Execution halted

Perhaps some of you have experienced this and found work arounds? One has to
be pretty good to type without ever committing mistakes!

By the way, I am running Cygwin (cygwin_NT-5.0 release 1.5.10(0.116/4/2), I
reinstalled everything fresh last week) on Win 2k and R 1.9.1. Although some
of you find cygwin inefficient in many ways, I don't have the option to
migrate to Linux.

Cheers,

Thomas
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
(des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
 e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
v??rifier l'absence de corruption ?? sa r??ception.

The contents of this email and any attachments are confidential. They are intended for 
the named recipient(s) only. If you have received this email in error please notify the 
system manager or  the sender immediately and do not disclose the contents to 
anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
content.
***



From rossiter at itc.nl  Wed Jul 28 16:25:42 2004
From: rossiter at itc.nl (David Rossiter)
Date: Wed, 28 Jul 2004 16:25:42 +0200
Subject: [R] package.contents() deprecated, what replaces it?
Message-ID: <36141C39871E4D4DAE92F79D183854364EE7E1@itcnt14.itc.nl>

Back on 18-June a colleague (Earl Glynn) asked:
==================
I did a

    ?package.contents

in version 1.9.0. The help file says this is deprecated, and says to
"see also" Deprecated and Defunct, but what is the "new" function that
replaces packge.contents?

The function still seems to work, but it's just tagged as deprecated.

efg  
==================
I have the same question, and also could not find the answer despite
searching "everywhere". I couldn't find a followup to the question.

I've written an instruction manual introducing
R to my institute's students, which includes the suggestion to use this
command, e.g.

   For example, to see what's in the geostatistical package
\texttt{gstat}:
   \begin{verbatim}
   > package.contents("gstat")
    \end{verbatim}

but now they see an off-putting "deprecated" message. Please advise.

D G RossiterD G Rossiter
Senior University Lecturer
Department of Earth Systems Analysis (DESA)
International Institute for Geo-Information Science and Earth
Observation (ITC)
Hengelosestraat 99
PO Box 6, 7500 AA Enschede, The Netherlands
Phone:	+31 (0)53 4874 499
Fax:	+31 (0)53 4874 336
mailto:rossiter at itc.nl,  Internet: http://www.itc.nl/personal/rossiter



From Roger.Bivand at nhh.no  Wed Jul 28 16:27:09 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 28 Jul 2004 16:27:09 +0200 (CEST)
Subject: [R] Re: Writing polyline shapefiles
In-Reply-To: <006601c474a4$0e40c1c0$90f00e50@PC728329681112>
Message-ID: <Pine.LNX.4.44.0407281615400.16455-100000@reclus.nhh.no>

On Wed, 28 Jul 2004, Patrick Giraudoux wrote:

> Stephane, dear R listers,
> 
> I wonder if the idea of developping some functions in R writing
> shapefiles from a matrix of coordinates -eg poly2shape()- is still with
> us? I currently manage with a home-made function writing an ASCII grass
> file, then importing it into GRASS as vector file, then exporting the
> vector file as a shapefile (ouf!). The main issue to me is still to be
> capable to wite the *.shx and *.shp from coordinates (the *.dbf is
> easier to manage, even indirectly, and can for instance be completed
> simply via Excel).  I tried to open *.shp, etc.. files to understand how
> they were structured and thus write some programme by myself, but
> unsuccessfully (the way those files are coded is not ascii)
> 
> Maptools is fantastic for importation and data handling within R, but
> unfortunately cannot export to shapefiles.
> 
> Any news?
> 

Nicholas Lewin-Koh wrote a simple sketch for type 1 (points) files
(undocumented C function "shpwrite"). Lines are probably less interesting,
so the polygon case remains. Is it important that the function pays close
attention to the shapefile specification (ring direction, etc., lakes and
islands) or can it assume that the user has everything under control? The
ESRI specification is clear enough, and the shapelib code is OK. The
longer term aim is to use the sourceforge "sp" package of spatial data
classes in S4 form to read and write SpatialDataFramePolygons, but I guess
doing a simpler function using S3 will get done sooner.

Roger



> Patrick Giraudoux
> 
> 
> PS: ESRI has managed to distribute ArcTools (with ArcGIS) with no way to
> importe generate ASCII formats!!! One must get ArcINFO for that... No
> comment!
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From spencer.graves at pdf.com  Wed Jul 28 16:34:00 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 28 Jul 2004 07:34:00 -0700
Subject: [R] elegant matrix creation
In-Reply-To: <a0600200abd2d59a97c4d@[139.166.242.29]>
References: <a0600200abd2d59a97c4d@[139.166.242.29]>
Message-ID: <4107B958.9070406@pdf.com>

      It's not obvious what pattern you want, but some variants of the 
following would work for jj1 and jj2: 

      1+outer(1:9, 1:9, "+")%%3

In particular the following are equal to your jj1 and jj2:  

jj1. <- 1+outer(0:8, rep(0:2, e=3), "+")%%3

jj2. <- 1+outer(0:8, c(1,2,1,3,1,3,2,3,2)-1, "+")%%3     

      I couldn't figure out jj3, but this system may not work so easily 
for that.  hope this helps.  spencer graves


Robin Hankin wrote:

>Hello everybody.
>
>I am trying to reproduce a particular matrix in an elegant way.  If I
>have
>
>jj1 <-
>structure(c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,
>3,1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,2,3,
>1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,3,1,2,3,1,
>2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,
>2),.Dim = as.integer(c(9,9)))
>
>[ image(jj1) is good here ] then I can get this with
>
>kronecker(matrix(1,3,1),kronecker(1+outer(0:2,0:2,"+")%%3,matrix(1,1,3)))
>
>I want to reproduce the following matrices in an equivalent way:
>
>jj2 <- matrix(c(1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,
>1,2,3,1,2,3,1,2,3,3,1,2,3,1,2,3,1,2,1,2,3,1,2,
>3,1,2,3,3,1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1,3,
>1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1),9,9)
>
>jj3 <- structure(c(1,2,3,2,3,1,3,1,2,1,2,1,2,3,2,3,1,
>3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1,2,3,2,3,
>2,3,1,3,1,2,1,2,1,2,3,2,3,1,3,1,3,1,2,1,2,
>3,2,3,1,3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1, 2),.Dim =
>as.integer(c(9,9)))
>
>[ note that jj1-jj3 each have precisely 3 occurrences of A, B, and C
>along each row, column and (broken) diagonal ].
>
>Can anyone give me a nice elegant way of creating jj2 and jj3 please?
>
>  
>



From ripley at stats.ox.ac.uk  Wed Jul 28 16:34:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jul 2004 15:34:31 +0100 (BST)
Subject: [R] using Rterm under cygwin, no possiblity to delete characters
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD6891@SRV0015>
Message-ID: <Pine.LNX.4.44.0407281528040.21888-100000@gannet.stats>

You have to call Rterm.exe *from a command shell*.  `cygwin' is not a
command shell, but a collection of tools that provides several such.  So
we can only guess at what you are using.

Rterms runs satisfactorily in many shells (I use tcsh, others use Cygwin 
bash ...).  This is all described in the README and rw-FAQ files, 
for example.

On Wed, 28 Jul 2004, Dewez Thomas wrote:

> Dear R-users,
> 
> When I call Rterm from cygwin, I have no options but typing the exact syntax
> the first time. If I happen to hit the "delete" key (backspace), R dies when
> I press enter saying :

backspace and delete are separate keys, so which did you mean?

> Error: ... (error concerning the function on the last line of text)
> Execution halted
> 
> Perhaps some of you have experienced this and found work arounds? One has to
> be pretty good to type without ever committing mistakes!
> 
> By the way, I am running Cygwin (cygwin_NT-5.0 release 1.5.10(0.116/4/2), I
> reinstalled everything fresh last week) on Win 2k and R 1.9.1. Although some
> of you find cygwin inefficient in many ways, I don't have the option to
> migrate to Linux.

The alternative is to use a Windows-native shell, such as tcsh.exe.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Jul 28 16:41:39 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jul 2004 15:41:39 +0100 (BST)
Subject: [R] package.contents() deprecated, what replaces it?
In-Reply-To: <36141C39871E4D4DAE92F79D183854364EE7E1@itcnt14.itc.nl>
Message-ID: <Pine.LNX.4.44.0407281534540.21888-100000@gannet.stats>

package.contents("gstat") is really ugly, and not something we would ever
recommend for end users.  E.g. library(help=gstat) has always done a
better job.

The information package.contents regurgitates is itself deprecated, to be 
replaced by metadata (in package subdir Meta) that other tools, e.g. 
library(help=), can format nicely.  Had namespaces be available back then, 
package.contents would never have been user-visible.


On Wed, 28 Jul 2004, David Rossiter wrote:

> Back on 18-June a colleague (Earl Glynn) asked:
> ==================
> I did a
> 
>     ?package.contents
> 
> in version 1.9.0. The help file says this is deprecated, and says to
> "see also" Deprecated and Defunct, but what is the "new" function that
> replaces packge.contents?
> 
> The function still seems to work, but it's just tagged as deprecated.
> 
> efg  
> ==================
> I have the same question, and also could not find the answer despite
> searching "everywhere". I couldn't find a followup to the question.
> 
> I've written an instruction manual introducing
> R to my institute's students, which includes the suggestion to use this
> command, e.g.
> 
>    For example, to see what's in the geostatistical package
> \texttt{gstat}:
>    \begin{verbatim}
>    > package.contents("gstat")
>     \end{verbatim}
> 
> but now they see an off-putting "deprecated" message. Please advise.
> 
> D G RossiterD G Rossiter
> Senior University Lecturer
> Department of Earth Systems Analysis (DESA)
> International Institute for Geo-Information Science and Earth
> Observation (ITC)
> Hengelosestraat 99
> PO Box 6, 7500 AA Enschede, The Netherlands
> Phone:	+31 (0)53 4874 499
> Fax:	+31 (0)53 4874 336
> mailto:rossiter at itc.nl,  Internet: http://www.itc.nl/personal/rossiter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rksh at soc.soton.ac.uk  Wed Jul 28 16:49:19 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 28 Jul 2004 15:49:19 +0100
Subject: [R] elegant matrix creation
In-Reply-To: <4107B958.9070406@pdf.com>
References: <a0600200abd2d59a97c4d@[139.166.242.29]> <4107B958.9070406@pdf.com>
Message-ID: <a0600200bbd2d6ab47aeb@[139.166.242.29]>

Spencer

thank you!

just what I wanted.   I have a feeling that jj3 is qualitatively 
different from the other two.
Nevertheless, I'm sure it'll crack sooner or later!

best wishes

rksh




At 07:34 am -0700 28/07/04, Spencer Graves wrote:
>      It's not obvious what pattern you want, but some variants of 
>the following would work for jj1 and jj2:
>      1+outer(1:9, 1:9, "+")%%3
>
>In particular the following are equal to your jj1 and jj2: 
>jj1. <- 1+outer(0:8, rep(0:2, e=3), "+")%%3
>
>jj2. <- 1+outer(0:8, c(1,2,1,3,1,3,2,3,2)-1, "+")%%3    
>
>      I couldn't figure out jj3, but this system may not work so 
>easily for that.  hope this helps.  spencer graves
>
>
>Robin Hankin wrote:
>
>>Hello everybody.
>>
>>I am trying to reproduce a particular matrix in an elegant way.  If I
>>have
>>
>>jj1 <-
>>structure(c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,
>>3,1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,2,3,
>>1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,3,1,2,3,1,
>>2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,
>>2),.Dim = as.integer(c(9,9)))
>>
>>[ image(jj1) is good here ] then I can get this with
>>
>>kronecker(matrix(1,3,1),kronecker(1+outer(0:2,0:2,"+")%%3,matrix(1,1,3)))
>>
>>I want to reproduce the following matrices in an equivalent way:
>>
>>jj2 <- matrix(c(1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,
>>1,2,3,1,2,3,1,2,3,3,1,2,3,1,2,3,1,2,1,2,3,1,2,
>>3,1,2,3,3,1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1,3,
>>1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1),9,9)
>>
>>jj3 <- structure(c(1,2,3,2,3,1,3,1,2,1,2,1,2,3,2,3,1,
>>3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1,2,3,2,3,
>>2,3,1,3,1,2,1,2,1,2,3,2,3,1,3,1,3,1,2,1,2,
>>3,2,3,1,3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1, 2),.Dim =
>>as.integer(c(9,9)))
>>
>>[ note that jj1-jj3 each have precisely 3 occurrences of A, B, and C
>>along each row, column and (broken) diagonal ].
>>
>>Can anyone give me a nice elegant way of creating jj2 and jj3 please?
>>
>>


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From wolski at molgen.mpg.de  Wed Jul 28 16:55:35 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 28 Jul 2004 16:55:35 +0200
Subject: [R] as(obj,"matrix")
Message-ID: <200407281655350828.732ED9CA@mail.math.fu-berlin.de>

Hi!

Here a simple example.

setClass("myclass"
,representation(info="character")
,contains="matrix"
)

rownames(dd)<-c("a","b")
tt<-new("myclass",dd)
#the source of pain.
as(tt,"matrix")<-matrix(1,3,3) 
Error: length of dimnames [1] not equal to array extent


Is there a different way to do what I would like to do (I would like to change the @.Data and all its attributes in the object)?

 
Eryk.



From dray at biomserv.univ-lyon1.fr  Wed Jul 28 16:57:20 2004
From: dray at biomserv.univ-lyon1.fr (Stephane DRAY)
Date: Wed, 28 Jul 2004 10:57:20 -0400
Subject: [R] a bug with LAPACK ? non orthogonal vectors obtained with
	eigen of a symmetric matrix
Message-ID: <5.2.1.1.0.20040728105218.00b4b2b8@biomserv.univ-lyon1.fr>

Hello,
I have send send this message one week ago but I have receive no answer. 
Perhaps, some of RListers were in holidays and do not read my message. I 
try again..
My problem is that I obtained non orthonormal eigenvectors with some 
matrices with LAPACK while EISPACK seems to provide "good" results. Is 
there some restrictions with the use of LAPACK ? Is it a bug ? I did not 
find the answer. Here is my experiment:

  I have obtained strange results using eigen on a symmetric matrix:

# this function perform a double centering of a matrix 
(xij-rowmean(i)-colmean(j)+meantot)
dbcenter=function(mat){
rmean=apply(mat,1,mean)
cmean=apply(mat,2,mean)
newmat=sweep(mat,1,rmean,"-")
newmat=sweep(newmat,2,cmean,"-")
newmat=newmat+mean(mat)
newmat}

# i use spdep package to create a spatial contiguity matrix
library(spdep)
x=dbcenter(nb2mat(cell2nb(3,3),style="B"))

#compute eigenvalues of a 9 by 9 matrix
res=eigen(x)

# some eigenvalues are equal to 0
eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 0), 
TRUE))

# I remove the corresponding eigenvectors
res0=res$vec[,-which(eq0)]

# then I compute the Froebenius norm with the identity matrix
sum((diag(1,ncol(res0))-crossprod(res0))^2)

[1] 1.515139e-30

# The results are correct,
# then I do it again with a biggest matrix(100 by 100)

x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
res=eigen(x)
eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 0), 
TRUE))
res0=res$vec[,-which(eq0)]
sum((diag(1,ncol(res0))-crossprod(res0))^2)

[1] 3.986387


I have try the same with res=eigen(x,EISPACK=T):

  x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
res=eigen(x,EISPACK=T)
eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 0), 
TRUE))
res0=res$vec[,-which(eq0)]
sum((diag(1,ncol(res0))-crossprod(res0))^2)
[1] 1.315542e-27


So I wonder I there is a bug in the LAPACK algorithm or if there are some 
things that I have not understood. Note that my matrix has some pairs of 
equal eigenvalues.

Thanks in advance.
++++++++++++++++++++++++++++++++++++

I have continue my experiments in changing the size of my matrix :
(3^2 by 3^2, 4^2 by 4^2... 20^2 by 20^2)

EISPACK is always correct but LINPACK provide very strange results:


 > for(i in 3:20){
+ x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
+ res=eigen(x,EIS=T)
+ eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
0), TRUE))
+ res0=res$vec[,-which(eq0)]
+ print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
+ }
[1] 7.939371e-30
[1] 2.268788e-29
[1] 9.237286e-29
[1] 1.806393e-28
[1] 3.24619e-28
[1] 5.239195e-28
[1] 9.78079e-28
[1] 1.315542e-27
[1] 1.838600e-27
[1] 3.114150e-27
[1] 5.499297e-27
[1] 5.471782e-27
[1] 1.075098e-26
[1] 1.534822e-26
[1] 1.771326e-26
[1] 2.342404e-26
[1] 3.462522e-26
[1] 4.310143e-26
 > for(i in 3:20){
+ x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
+ res=eigen(x)
+ eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
0), TRUE))
+ res0=res$vec[,-which(eq0)]
+ print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
+ }
[1] 1.515139e-30
[1] 1.054286e-27
[1] 9.553017e-29
[1] 2.263455e-28
[1] 5.641993e-27
[1] 4.442088e-26
[1] 3.996714
[1] 3.986387
[1] 3.996545
[1] 7.396718
[1] NaN
[1] 7.980621
[1] 7.996769
[1] 3.984399
[1] NaN
[1] NaN
[1] NaN
[1] NaN

Note that I have do the same with random number and never find this kind of 
problems


 > R.Version()
$platform
[1] "i386-pc-mingw32"

$arch
[1] "i386"

$os
[1] "mingw32"

$system
[1] "i386, mingw32"

$status
[1] ""

$major
[1] "1"

$minor
[1] "9.1"

$year
[1] "2004"

$month
[1] "06"

$day
[1] "21"

$language
[1] "R"

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From liao1k at cmich.edu  Wed Jul 28 16:57:11 2004
From: liao1k at cmich.edu (Liao, Kexiao)
Date: Wed, 28 Jul 2004 10:57:11 -0400
Subject: [R] Parallel Functions on AIX
Message-ID: <291B348BC59B47468C7824603C326082946123@cmail3.central.cmich.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040728/4f665f6f/attachment.pl

From tlumley at u.washington.edu  Wed Jul 28 16:59:57 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 Jul 2004 07:59:57 -0700 (PDT)
Subject: [R] covariate selection in cox model (counting process)
In-Reply-To: <000301c47447$880ed530$2e4b9a53@amd>
References: <000301c47447$880ed530$2e4b9a53@amd>
Message-ID: <Pine.A41.4.58.0407280755080.294680@homer12.u.washington.edu>

On Wed, 28 Jul 2004, Mayeul KAUFFMANN wrote:

> >No, I mean recurrent events.  With counting process notation but no
> >recurrent revents the partial likelihood is still valid, and the approach
> >of treating it as a real likelihood for AIC (and presumably BIC) makes
> >sense.
> >
> >Roughly speaking, you can't tell there is dependence until you see
> >multiple events.
>
> Thanks a lot, I got it (well, I hope so)!
>
>
> I've read in several places that events in the Andersen-Gill model must be
> "conditionnaly independent", which is sometimes more precisely written as
> "conditionnaly independent given the covariates"
>
> or even more precisely:
>
> "the Andersen-Gill (AG) model assumes that each [individual] has a
> multi-event counting process with independent increments. The observed
> increments must be conditionally independent given the history of all
> observable information up to the event times."
> (http://www.stat.umu.se/egna/danardono/licdd.pdf)

More precisely still, for the criterion function in coxph() to be a
partial likelihood the estimating function must be a martingale. This
is actually a slightly weaker assumption than independent increments.

The proportional rates model doesn't require this assumption, and is also
sometimes called the Andersen-Gill model.  The criterion function isn't a
likelihood but it still gives valid estimators.

>
> Then, there is still another option. In fact, I already modelled
> explicitely the influence of past events with a "proximity of last event"
> covariate, assuming the dependence on the last event decreases at a
> constant rate (for instance, the proximity covariate varies from 1 to 0.5
> in the first 10 years after an event, then from 0.5 to 0.25 in the next
> ten years, etc).
>
> With a well chosen modelisation of the dependence effect, the events
> become conditionnaly independent, I do not need a +cluster(id) term, and I
> can use fit$loglik to make a covariate selection based on BIC, right?

If you can get the conditional independence (martingaleness) then, yes,
BIC is fine.

One way to check might be to see how similar the standard errors are with
and without the cluster(id) term.

	-thomas


> Thanks a lot again for your time.
>
> Mayeul KAUFFMANN
> Univ. Pierre Mendes France
> Grenoble - France
>
> PS: I wrongly concluded from the R statement "(Note: the likelihood ratio
> and score tests assume independence of observations within a cluster, the
> Wald and robust score tests do not). " that it meant independence between
> two consecutive observations (without any event). It made sense to  me
> because when only one covariate changes for a given individual, and with a
> small change, there is a new observation, with a risk very simlar to the
> risk for the previous observation. But there is still independence with
> respect to the question of recurrent event. Maybe the warning should be
> rewritten saying "assume *conditionnal* independence of *events* (given
> the covariates)"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From hb at maths.lth.se  Wed Jul 28 17:04:57 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 28 Jul 2004 17:04:57 +0200
Subject: [R] Another big data size problem
In-Reply-To: <20040728172610.70c9fa2f@misha>
Message-ID: <002a01c474b4$4136eb30$3a0040d5@hblaptop>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Federico Gherardini
> Sent: Wednesday, July 28, 2004 5:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Another big data size problem
> 
> 
> On Wed, 28 Jul 2004 13:28:20 +0100
> Ernesto Jardim <ernesto at ipimar.pt> wrote:
> 
> 
> > Hi,
> > 
> > When you're writing a table to MySQL you have to be carefull if the 
> > table is created by RMySQL. The fields definition may not 
> be the most 
> > adequate and there will be no indexes in your table, which 
> makes the 
> > queries _very_ slow.
> > 
> So, if I understood correctly, if you want to use SQL you'll 
> have to upload the table in SQL, directly from MySQL without 
> using R at all, and then use RMySQL to read the elements in R?
> 
> Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> 
> >Note that it is better to initialize the object to full size before
> >inserting -- rather than using rbind() and friends which is 
> indeed slow
> >since it need to re-allocate much memory for each step.
> 
> Do you mean something like this?
> 
> tab <- matrix(rep(0, 1227 * 20000), 1227, 20000, byrow = TRUE)
> 
> for(i in 0:num.lines)
> 	tab[i + 1,] <- scan(file=fh, nlines=1, what="PS", skip = i)

It is better to open a file connection, keep it open during the loop and the
close it afterwards. Something like

  tab <- matrix(rep(0, 1227 * 20000), 1227, 20000, byrow = TRUE)
  fh <- file(filename, open="r");
  for(i in 0:num.lines)
    tab[i + 1,] <- scan(file=fh, nlines=1);
  close(fh);

As you have done it, the file is opened once in each iteration of the loop,
scan() starts reading from the beginning, parse all lines to skip 'i' lines,
and the reads one line. This is done num.lines+1 times!

Anyway, I think you also should read the help for scan(). What do you want
with argument 'what="PS"'? "PS" is not a valid data type; 'what' does not
specify a name of field/column to be read.

> The above doesn't get very far either... it seems that, once 
> it has created the table, it becomes so slow that it's 
> unusable. I'll have to try this with more RAM by the way.

My suggestions to you are that try read.table() with specified data type for
the columns using vector argument 'colClasses'. This way you can help R by
specify that, say, column 3 is an integer (have the memory of a double), and
that column 6-10 are doubles. Unfortunately you can tell read.table() to
skip some of the columns that you are not interested in, which in your case
to help you out a lot. To do this, you have to use scan(), which
read.table() uses internally. In scan() 'what' works similar to 'colClasses'
*and* if you specify 'what' as a 'list' you can tell scan() to skip some
columns by setting its 'what' value to NULL, e.g. what=list("integer",
"integer", NULL, "double", "character"). I think you can get pretty far
doing this!
 
> Cheers,
> 
> fede

Good luck!

Henrik Bengtsson



From hb at maths.lth.se  Wed Jul 28 17:04:58 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 28 Jul 2004 17:04:58 +0200
Subject: [R] using Rterm under cygwin, no possiblity to delete characters
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD6891@SRV0015>
Message-ID: <002b01c474b4$43215610$3a0040d5@hblaptop>

Hi. I used to run R under Cygwin for quite some time, but after, I think, R
v1.8.1 or so, the problems started to show up. There has been some
discussion about (recent) problems running R under Cygwin. Once problem was
for instance that hitting Ctrl-C in R running Cygwin would bring you into a
concurrent forked R and shell environment. Search the r-help archive for
that discussion. Anyway, the final take home message, which was underlined
by B. Ripley, was that R does *not* support Cygwin. For command line R, I
run R in a specially setup Command prompt. It works fine indeed;

Below is the bat-file that I use to initiate a new Command prompt to run
Rterm in. If it does not run out of the box for you, it should not be hard
to modify.

Cheers

Henrik Bengtsson


@echo off
rem ######################################################################
rem # Usage: RCMDprompt.bat [path]
rem #
rem # This script opens a MS-DOS prompt with a enviroment variables
rem # set such that R can be ran and packages can be build. 
rem # If 'path' is given, the working directory will be set accordingly.
rem # 
rem # NOTE: This scripts works even if Cygwin is installed. HOWEVER, you
rem # can not have any Cygwin applications running (not even a shell or
rem # XEmacs for Cygwin) at the same time you try to run RCMD.
rem #
rem # Requires:
rem #  To build and install packages two things must be installed, i.e.
rem # exists in the PATH. First, the Rtools compilation [1,2] must exists. 
rem # The path (R_TOOLS) to it is set below. Second, Perl (must not be 
rem # Cygwin/Perl) must also exists. The path to it is set below.
rem #
rem # Reference:
rem #  [1] http://www.stats.ox.ac.uk/pub/Rtools/
rem #  [2] http://www.murdoch-sutherland.com/Rtools/
rem #  [3] Duncan Murdoch, Using MiKTeX with R for Windows, 2004.
rem #      http://www.murdoch-sutherland.com/Rtools/miktex.html
rem #
rem # Henrik Bengtsson, hb at maths.lth.se, March-June 2004.
rem ######################################################################

rem # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
rem # 1. "Global" environment variables
rem # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
rem # Short version of PROGRAMFILES, e.g. 'C:\Progra~1' instead of
rem # 'C:\Program Files\', which contains spaces that are BAD for R & Co.
rem # 
rem # On Windows XP and NT, variable substitution using 'for' can be used
rem # to do this automatically from %ProgramFiles%. For details see
rem # http://www.microsoft.com/windowsxp/home/using/productdoc/en/for.asp
for %%v in ("%ProgramFiles%") do set PROGRAMFILES_SHORT=%%~sv

rem # Set the main R directory
set R_ROOT=%PROGRAMFILES_SHORT%\R

rem # Set the R_HOME directory
set R_HOME=%R_ROOT%\rw1090

rem # Set the HOME directory. This is the directory where R looks 
rem # for the .Rprofile and .Renviron files. See ?Startup.
set HOME=%UserProfile%

rem # Set TMPDIR to a temporary directory
set TMPDIR=%TEMP%

rem # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
rem # 2. Setup the PATH
rem # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
rem # Clear the PATH (making the main Cygwin installation "invisible")
path ;

rem # Set the LaTeX directory
rem # http://www.miktex.org/
path %SystemDrive%\texmf\miktex\bin;%PATH%

rem # There are recent issues with MikTeX v2.4 and R. The problem occurs 
rem # because e-TeX is used instead of TeX. See [3] for details. 
rem # Try latex -version. If you see "MikTeX-e-TeX" then you should read
rem # the instructions at [3].

rem # Set the Microsoft HTML Help Compiler directory
rem # http://msdn.microsoft.com/library/tools/htmlhelp/chm/HH1Start.htm
path %ProgramFiles%\HTML Help Workshop;%PATH%

rem # Set the Perl directory
rem # http://www.activestate.com/Products/ActivePerl/Download.html
path %SystemDrive%\Perl\bin;%PATH%
 
rem # Set the Rtools [1] directory
rem # http://www.stats.ox.ac.uk/pub/Rtools/
path %R_ROOT%\Rtools;%PATH%

rem # Set the R_HOME directory
path %R_HOME%\bin;%PATH%


rem # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
rem # 3. Start the MSDOS prompt in the given directory
rem # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
rem # Change directory according to argument 1
cd /D "%1"

rem # Start the MSDOS commando prompt
"%SystemRoot%\system32\cmd.exe" 





> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dewez Thomas
> Sent: Wednesday, July 28, 2004 4:24 PM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] using Rterm under cygwin, no possiblity to 
> delete characters
> 
> 
> Dear R-users,
> 
> When I call Rterm from cygwin, I have no options but typing 
> the exact syntax the first time. If I happen to hit the 
> "delete" key (backspace), R dies when I press enter saying :
> 
> Error: ... (error concerning the function on the last line of 
> text) Execution halted
> 
> Perhaps some of you have experienced this and found work 
> arounds? One has to be pretty good to type without ever 
> committing mistakes!
> 
> By the way, I am running Cygwin (cygwin_NT-5.0 release 
> 1.5.10(0.116/4/2), I reinstalled everything fresh last week) 
> on Win 2k and R 1.9.1. Although some of you find cygwin 
> inefficient in many ways, I don't have the option to migrate to Linux.
> 
> Cheers,
> 
> Thomas
> ***
> Le contenu de cet e-mail et de ses pi??ces jointes est destin?? 
> ?? l'usage exclusif du 
> (des) destinataire(s) express??ment d??sign??(s) comme tel(s). 
> En cas de r??ception de cet 
>  e-mail par erreur, le signaler ?? son exp??diteur et ne pas en 
> divulguer le contenu. 
> L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il 
> convient n??anmoins de 
> v??rifier l'absence de corruption ?? sa r??ception.
> 
> The contents of this email and any attachments are 
> confidential. They are intended for 
> the named recipient(s) only. If you have received this email 
> in error please notify the 
> system manager or  the sender immediately and do not disclose 
> the contents to 
> anyone or make copies. eSafe scanned this email for viruses, 
> vandals and malicious 
> content.
> ***
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From tlumley at u.washington.edu  Wed Jul 28 17:10:10 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 Jul 2004 08:10:10 -0700 (PDT)
Subject: [R] Simulation from a model fitted by survreg.
In-Reply-To: <s107bf30.052@gwmail.ihe.se>
References: <s107bf30.052@gwmail.ihe.se>
Message-ID: <Pine.A41.4.58.0407280802430.294680@homer12.u.washington.edu>

On Wed, 28 Jul 2004, Sixten Borg wrote:

> Dear list,
>
> I would like to simulate individual survival times from a model that has
> been fitted using the survreg procedure (library survival). Output shown
> below.
>
> My plan is to extract the shape and scale arguments for use with
> rweibull() since my error terms are assumed to be Weibull, but it does
> not make any sense. The mean survival time is easy to predict, but I
> would like to simulate individual survival times.
>

It's parametrized differently from rweibull. The linear predictor for the
model is the logarithm of the scale, and the scale parameter from the
model is the reciprocal of the shape.

As with the gamma family you always need to check the parametrisation for
weibull distributions.

	-thomas



> I am probably missing something completely obvious. Any hints or advice
> are appreciated.
>
> Thanks
> Sixten
>
> > summary(mod1)
>
> Call:
> survreg(formula = Surv(tid, study$first.event.death) ~ regim +
>     age + stadium2, data = study, dist = "weibull")
>               Value Std. Error      z        p
> (Intercept) 11.6005     0.7539 15.387 2.01e-53
> regimposto  -0.1350     0.1558 -0.867 3.86e-01
> age         -0.0362     0.0102 -3.533 4.11e-04
> stadium2ii  -0.0526     0.2794 -0.188 8.51e-01
> Log(scale)  -0.5148     0.1116 -4.615 3.93e-06
>
> Scale= 0.598
>
> Weibull distribution
> Loglik(model)= -680.7   Loglik(intercept only)= -689.2
>         Chisq= 16.87 on 3 degrees of freedom, p= 0.00075
> Number of Newton-Raphson Iterations: 8
> n=1183 (4 observations deleted due to missing)
>
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    8.1
> year     2003
> month    11
> day      21
> language R
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From christian.lederer at imse.med.tu-muenchen.de  Wed Jul 28 18:38:01 2004
From: christian.lederer at imse.med.tu-muenchen.de (Christian Lederer)
Date: Wed, 28 Jul 2004 18:38:01 +0200
Subject: [R] Gaussian frailty leads to segmentation fault
Message-ID: <4107D669.5080501@imse.med.tu-muenchen.de>


Dear R gurus,

for a simulation concerning study effects and historical controls
in survival analysis, i would like to experiment with a gaussian
frailty model.

The simulated scenario consists of a randomized trial
(treatment and placebo) and historical controls (only placebo).

So the simulated data frames consist of four columns
$time, $cens, $study, $treat.
$time, $cens are the usual survival data.
For the binary thretment indicator we have
$treat == 0 or 1, if $study == 1,
$treat == 1 if $study > 1

Typical parameters for my simulations are:
sample sizes (per arm):         between 100 and 200
number of historical studies:   between 7 and 15
hazard ratio treatment/placebo: between 0.7 and 1
variance of the study effekt:   between 0 and 0.3

Depending on the sample sizes, the following call sometimes leads to
a segmentation fault:

coxph(Surv(time,cens) ~
       as.factor(treatment) + frailty(study, distribution="gaussian"),
       data=data)

I noticed, that this segmentation fault occures most frequently, if the
number of randomized treatment patients is higher than the number of
randomized placebo patients, and the number of historical studies is
large.
There seems to be no problem, if there are at least as many randomized
placebo patients as treated patients. Unfortunately, this is not the
situation i want to investigate (historical controls should be used
to decrease the number of treated patients).

Is there a way to circumwent this problem?

Christian

P.S.
Is it allowed, to attach gzipped sample data sets in this mailing list?



From ernesto at ipimar.pt  Wed Jul 28 17:24:03 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 28 Jul 2004 16:24:03 +0100
Subject: [R] How to add an object to an RData file ?
Message-ID: <1091028242.3416.68.camel@gandalf.local>

Hi,

I've saved an RData file with "save" and now I want to add a new object
to this file. At the moment I do:

attach("file.RData")
save(list=c("new,obj", ls(pos=2)), file="file.RData", compress=T)
detach()

Is there a quicker method that just add the object to the file ?

Thanks

EJ



From wolski at molgen.mpg.de  Wed Jul 28 17:18:30 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 28 Jul 2004 17:18:30 +0200
Subject: [R] as(obj,"matrix")
In-Reply-To: <1091027522.3181.254.camel@vpn202001.lif.icnet.uk>
References: <200407281655350828.732ED9CA@mail.math.fu-berlin.de>
	<1091027522.3181.254.camel@vpn202001.lif.icnet.uk>
Message-ID: <200407281718300474.002F981F@mail.math.fu-berlin.de>


The definition of dd is.
dd<-matrix(0,2,2)


*********** REPLY SEPARATOR  ***********

On 7/28/2004 at 4:12 PM Adaikalavan Ramasamy wrote:

>>>On Wed, 2004-07-28 at 15:55, Wolski wrote:
>>>> Hi!
>>>> 
>>>> Here a simple example.
>>>> 
>>>> setClass("myclass"
>>>> ,representation(info="character")
>>>> ,contains="matrix"
>>>> )
>>>> 
>>>> rownames(dd)<-c("a","b")
>>>
>>>Er, I don't think you have defined 'dd' in the example.
>>>
>>>> tt<-new("myclass",dd)
>>>> #the source of pain.
>>>> as(tt,"matrix")<-matrix(1,3,3) 
>>>> Error: length of dimnames [1] not equal to array extent
>>>> 
>>>> 
>>>> Is there a different way to do what I would like to do (I would like
>>>to change the @.Data and all its attributes in the object)?
>>>> 
>>>>  
>>>> Eryk.
>>>> 
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide!
>>>http://www.R-project.org/posting-guide.html
>>>>



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From danbebber at forestecology.co.uk  Wed Jul 28 17:24:31 2004
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Wed, 28 Jul 2004 16:24:31 +0100
Subject: [R] Modelling compound logistic growth curves
Message-ID: <000401c474b6$faa984e0$442501a3@plants.ox.ac.uk>

Motivated by the discovery of 'loglet analysis'
(http://phe.rockefeller.edu/LogletLab/) that allows one to decompose growth
curves into a series of logistic equations, I attempted to do the same thing
in R.

SIMULATED DATA
Time <- 1:200
pop.size <- SSlogis(Time,10,20,5) + SSlogis(Time,20,100,20) +
rnorm(length(Time))

MY ANALYSIS
results <- nls(size ~ SSlogis(Time, Asym1, xmid1, scal1) + SSlogis(Time,
Asym2, xmid2, scal2),
start = list(Asym1=5, xmid1=15, scal1=30, Asym2=25, xmid2=67, scal2=25))

THE RESULT
I get the error message:
Error in nls(size ~ SSlogis(Time, Asym1, xmid1, scal1) + SSlogis(Time,  :
        step factor 0.000488281 reduced below `minFactor' of 0.000976563

Assistance in doing this analysis would be much appreciated.

Dan Bebber
____________________________
Dr. Daniel P. Bebber
Department of Plant Sciences
University of Oxford
South Parks Road
Oxford
OX1 3RB
Tel. 01865 275060
Web. http://www.forestecology.co.uk/

"Data, data, data!" he cried impatiently. "I can't make bricks without
clay"
- Sherlock Holmes, The Adventure of the Copper Beeches, 1892



From ripley at stats.ox.ac.uk  Wed Jul 28 17:24:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jul 2004 16:24:29 +0100 (BST)
Subject: [R] Parallel Functions on AIX
In-Reply-To: <291B348BC59B47468C7824603C326082946123@cmail3.central.cmich.local>
Message-ID: <Pine.LNX.4.44.0407281620060.508-100000@gannet.stats>

The first thing to ascertain is that R will actually build on such a 
machine -- there have been a lot of reports of failure on AIX, and no 
recent reports of success.

If it does, R itself is single-threaded (but can make use of
multi-threaded BLAS)  but packages such as Rmpi, snow, RScaLAPACK provide 
parallel facilities (and are in the FAQ).

On Wed, 28 Jul 2004, Liao, Kexiao wrote:

> Dear R Development Team,

You actually wrote to R-help!

>    Does the latest version R-1.9.1 provide parallel functions if R is
> running on Multiple CPUs Unix platform (IBM AIX e-server)?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at jhsph.edu  Wed Jul 28 17:25:09 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 28 Jul 2004 11:25:09 -0400
Subject: [R] a bug with LAPACK ? non orthogonal vectors obtained with
	eigen of a symmetric matrix
In-Reply-To: <5.2.1.1.0.20040728105218.00b4b2b8@biomserv.univ-lyon1.fr>
References: <5.2.1.1.0.20040728105218.00b4b2b8@biomserv.univ-lyon1.fr>
Message-ID: <4107C555.1020105@jhsph.edu>

This is interesting.  I can reproduce your results but cannot come up 
with an explanation.  However, using svd(LINPACK = FALSE) seems to 
work every time.  Might you consider trying that instead?

-roger

Stephane DRAY wrote:
> Hello,
> I have send send this message one week ago but I have receive no answer. 
> Perhaps, some of RListers were in holidays and do not read my message. I 
> try again..
> My problem is that I obtained non orthonormal eigenvectors with some 
> matrices with LAPACK while EISPACK seems to provide "good" results. Is 
> there some restrictions with the use of LAPACK ? Is it a bug ? I did not 
> find the answer. Here is my experiment:
> 
>  I have obtained strange results using eigen on a symmetric matrix:
> 
> # this function perform a double centering of a matrix 
> (xij-rowmean(i)-colmean(j)+meantot)
> dbcenter=function(mat){
> rmean=apply(mat,1,mean)
> cmean=apply(mat,2,mean)
> newmat=sweep(mat,1,rmean,"-")
> newmat=sweep(newmat,2,cmean,"-")
> newmat=newmat+mean(mat)
> newmat}
> 
> # i use spdep package to create a spatial contiguity matrix
> library(spdep)
> x=dbcenter(nb2mat(cell2nb(3,3),style="B"))
> 
> #compute eigenvalues of a 9 by 9 matrix
> res=eigen(x)
> 
> # some eigenvalues are equal to 0
> eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
> 0), TRUE))
> 
> # I remove the corresponding eigenvectors
> res0=res$vec[,-which(eq0)]
> 
> # then I compute the Froebenius norm with the identity matrix
> sum((diag(1,ncol(res0))-crossprod(res0))^2)
> 
> [1] 1.515139e-30
> 
> # The results are correct,
> # then I do it again with a biggest matrix(100 by 100)
> 
> x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
> res=eigen(x)
> eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
> 0), TRUE))
> res0=res$vec[,-which(eq0)]
> sum((diag(1,ncol(res0))-crossprod(res0))^2)
> 
> [1] 3.986387
> 
> 
> I have try the same with res=eigen(x,EISPACK=T):
> 
>  x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
> res=eigen(x,EISPACK=T)
> eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
> 0), TRUE))
> res0=res$vec[,-which(eq0)]
> sum((diag(1,ncol(res0))-crossprod(res0))^2)
> [1] 1.315542e-27
> 
> 
> So I wonder I there is a bug in the LAPACK algorithm or if there are 
> some things that I have not understood. Note that my matrix has some 
> pairs of equal eigenvalues.
> 
> Thanks in advance.
> ++++++++++++++++++++++++++++++++++++
> 
> I have continue my experiments in changing the size of my matrix :
> (3^2 by 3^2, 4^2 by 4^2... 20^2 by 20^2)
> 
> EISPACK is always correct but LINPACK provide very strange results:
> 
> 
>  > for(i in 3:20){
> + x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
> + res=eigen(x,EIS=T)
> + eq0 <- apply(as.matrix(res$values),1,function(x) 
> identical(all.equal(x, 0), TRUE))
> + res0=res$vec[,-which(eq0)]
> + print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
> + }
> [1] 7.939371e-30
> [1] 2.268788e-29
> [1] 9.237286e-29
> [1] 1.806393e-28
> [1] 3.24619e-28
> [1] 5.239195e-28
> [1] 9.78079e-28
> [1] 1.315542e-27
> [1] 1.838600e-27
> [1] 3.114150e-27
> [1] 5.499297e-27
> [1] 5.471782e-27
> [1] 1.075098e-26
> [1] 1.534822e-26
> [1] 1.771326e-26
> [1] 2.342404e-26
> [1] 3.462522e-26
> [1] 4.310143e-26
>  > for(i in 3:20){
> + x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
> + res=eigen(x)
> + eq0 <- apply(as.matrix(res$values),1,function(x) 
> identical(all.equal(x, 0), TRUE))
> + res0=res$vec[,-which(eq0)]
> + print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
> + }
> [1] 1.515139e-30
> [1] 1.054286e-27
> [1] 9.553017e-29
> [1] 2.263455e-28
> [1] 5.641993e-27
> [1] 4.442088e-26
> [1] 3.996714
> [1] 3.986387
> [1] 3.996545
> [1] 7.396718
> [1] NaN
> [1] 7.980621
> [1] 7.996769
> [1] 3.984399
> [1] NaN
> [1] NaN
> [1] NaN
> [1] NaN
> 
> Note that I have do the same with random number and never find this kind 
> of problems
> 
> 
>  > R.Version()
> $platform
> [1] "i386-pc-mingw32"
> 
> $arch
> [1] "i386"
> 
> $os
> [1] "mingw32"
> 
> $system
> [1] "i386, mingw32"
> 
> $status
> [1] ""
> 
> $major
> [1] "1"
> 
> $minor
> [1] "9.1"
> 
> $year
> [1] "2004"
> 
> $month
> [1] "06"
> 
> $day
> [1] "21"
> 
> $language
> [1] "R"
> 
> St??phane DRAY
> -------------------------------------------------------------------------------------------------- 
> 
> D??partement des Sciences Biologiques
> Universit?? de Montr??al, C.P. 6128, succursale centre-ville
> Montr??al, Qu??bec H3C 3J7, Canada
> 
> Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
> E-mail : stephane.dray at umontreal.ca
> -------------------------------------------------------------------------------------------------- 
> 
> Web                                          
> http://www.steph280.freesurf.fr/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Wed Jul 28 17:37:18 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 28 Jul 2004 17:37:18 +0200
Subject: [R] Underline in expression().
In-Reply-To: <410744D0.8080107@netscape.net>
References: <41060ED9.5070907@netscape.net> <41067D20.70108@pdf.com>
	<410744D0.8080107@netscape.net>
Message-ID: <4107C82E.2010507@statistik.uni-dortmund.de>

John Janmaat wrote:

> Sundar,
> 
> Thanks.  Unfortunately, I am looking for something that also works in 
> the margins of the plot.

As a workaround, what about frac() (well, vertical justification is not 
that perfect in this case)?

     plot(1:10, xlab = "")
     title(xlab = expression(frac(y == X * beta + e)),
           line = 4.5)

I'll probably take a look how to add that feature during August.

Uwe Ligges



> John.
> 
> Sundar Dorai-Raj wrote:
> 
>>
>>
>> John Janmaat wrote:
>>
>>> Hello All,
>>>
>>> Is there an analogue to \underbar or the AMS math \underline in 
>>> graphical math expressions?
>>>
>>> Thanks,
>>>
>>> John.
>>
>>
>>
>> Uwe Ligges posted a solution a couple of years ago. I don't know if 
>> there is anything built in yet. ?plotmath does not seem to say 
>> anything about underlining.
>>
>> http://finzi.psych.upenn.edu/R/Rhelp01/archive/7191.html
>>
>> plot(0:1, 0:1, type="n")
>> underlined(0.5, 0.5, expression(widehat(x %*% y)))
>>
>> --sundar
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>



From jmc at research.bell-labs.com  Wed Jul 28 17:42:43 2004
From: jmc at research.bell-labs.com (John Chambers)
Date: Wed, 28 Jul 2004 11:42:43 -0400
Subject: [R] as(obj,"matrix")
References: <200407281655350828.732ED9CA@mail.math.fu-berlin.de>
Message-ID: <4107C973.F6C106E0@research.bell-labs.com>

Wolski wrote:
> 
> Hi!
> 
> Here a simple example.
> 
> setClass("myclass"
> ,representation(info="character")
> ,contains="matrix"
> )
> 
> rownames(dd)<-c("a","b")
> tt<-new("myclass",dd)
> #the source of pain.
> as(tt,"matrix")<-matrix(1,3,3)
> Error: length of dimnames [1] not equal to array extent
> 
> Is there a different way to do what I would like to do (I would like to change the @.Data and all its attributes in the object)?

It's not particularly a problem with as().  Your class just doesn't
behave as you expect.

"matrix" is not a formal class with slots.  (It isn't even an S3 class
in R; attr(x,"class") is NULL.)  So you cannot expect classes extending
"matrix" to know what a matrix is supposed to be.

Part of the problem is that matrix objects sometimes have dimnames and
sometimes don't.  And there is basic code in R that assumes or applies
constraints on the "dim" or "dimnames".

In S-Plus, "matrix" is a formal class, always having a slot for
dimnames.  R has not gone that route, at least not yet.

It may be possible to define a new class, "Matrix", say, that looks like
a matrix to old-style code but has a formal definition.  But the details
are likely to be tricky, and it's definitely a topic for r-devel, not
r-help.

John Chambers

> 
> 
> Eryk.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From Jean-Luc_Allard at uqac.ca  Wed Jul 28 17:57:22 2004
From: Jean-Luc_Allard at uqac.ca (Jean-Luc Allard)
Date: Wed, 28 Jul 2004 11:57:22 -0400
Subject: [R] Question ?
Message-ID: <b1566959.6959b156@uqac.ca>

HI,

I would like use header file in the R-HOME/scr/include. What should I do please ?

JL



From ggrothendieck at myway.com  Wed Jul 28 18:04:34 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 28 Jul 2004 16:04:34 +0000 (UTC)
Subject: [R] elegant matrix creation
References: <a0600200abd2d59a97c4d@[139.166.242.29]>
Message-ID: <loom.20040728T174349-361@post.gmane.org>

Not sure if this qualifies as elegant or not but it (1) does allow one
to generate all three matrices using the same scheme, (2) is 
simple requiring only a single one line function, (3) reduces the number 
of numbers you must specify from 81 to 18 per matrix and (4) gives 
some kminimal insight into the patterns. 

The key observation is that each row of each matrix is a cyclically
shifted version of the first row of that same matrix.  Thus given the 
first row and a vector of shifts we can reconstruct the remaining rows.

Define a function which shifts its vector argument v by shift positions
to the left producing a one row matrix.  If shift is a vector the each
row of the result corresponds to one shift in vector shift.

shiftL <- function(v, shift) 
	outer(shift,seq(along=v)-1, function(i,j)v[(i+j)%%length(v)+1])

# now run shiftL using the first row of each matrix and the shift vector
# for each matrix

jj1 <- shiftL(c(1,1,1,2,2,2,3,3,3),c(0,3,6,0,3,6,0,3,6))
jj2 <- shiftL(c(1,2,1,3,1,3,2,3,2),c(0,6,3,0,6,3,0,6,3))
jj3 <- shiftL(c(1,1,1,2,2,2,3,3,3),c(0,4,8,3,7,2,6,1,5))

or turning the input vectors into expressions themselves:

jj1 <- shiftL( rep(1:3,c(3,3,3)), rep(c(0,3,6),3) )
jj2 <- shiftL( c(shiftL(c(1,3,2),c(0,2,0))), rep(c(0,6,3),3) )
jj3 <- shiftL( rep(1:3,c(3,3,3)), seq(0,32,4) %% 9 )


Robin Hankin <rksh <at> soc.soton.ac.uk> writes:

: 
: Hello everybody.
: 
: I am trying to reproduce a particular matrix in an elegant way.  If I
: have
: 
: jj1 <-
: structure(c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,
: 3,1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,2,3,
: 1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,3,1,2,3,1,
: 2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,
: 2),.Dim = as.integer(c(9,9)))
: 
: [ image(jj1) is good here ] then I can get this with
: 
: kronecker(matrix(1,3,1),kronecker(1+outer(0:2,0:2,"+")%%3,matrix(1,1,3)))
: 
: I want to reproduce the following matrices in an equivalent way:
: 
: jj2 <- matrix(c(1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,
: 1,2,3,1,2,3,1,2,3,3,1,2,3,1,2,3,1,2,1,2,3,1,2,
: 3,1,2,3,3,1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1,3,
: 1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1),9,9)
: 
: jj3 <- structure(c(1,2,3,2,3,1,3,1,2,1,2,1,2,3,2,3,1,
: 3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1,2,3,2,3,
: 2,3,1,3,1,2,1,2,1,2,3,2,3,1,3,1,3,1,2,1,2,
: 3,2,3,1,3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1, 2),.Dim =
: as.integer(c(9,9)))
: 
: [ note that jj1-jj3 each have precisely 3 occurrences of A, B, and C
: along each row, column and (broken) diagonal ].
: 
: Can anyone give me a nice elegant way of creating jj2 and jj3 please?
:



From rpeng at jhsph.edu  Wed Jul 28 18:07:28 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 28 Jul 2004 12:07:28 -0400
Subject: [R] How to add an object to an RData file ?
In-Reply-To: <1091028242.3416.68.camel@gandalf.local>
References: <1091028242.3416.68.camel@gandalf.local>
Message-ID: <4107CF40.9080503@jhsph.edu>

I can't think of a faster way.

-roger

Ernesto Jardim wrote:
> Hi,
> 
> I've saved an RData file with "save" and now I want to add a new object
> to this file. At the moment I do:
> 
> attach("file.RData")
> save(list=c("new,obj", ls(pos=2)), file="file.RData", compress=T)
> detach()
> 
> Is there a quicker method that just add the object to the file ?
> 
> Thanks
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From f.gherardini at pigrecodata.net  Wed Jul 28 20:26:24 2004
From: f.gherardini at pigrecodata.net (Federico Gherardini)
Date: Wed, 28 Jul 2004 20:26:24 +0200
Subject: [R] Another big data size problem
In-Reply-To: <002a01c474b4$4136eb30$3a0040d5@hblaptop>
References: <20040728172610.70c9fa2f@misha>
	<002a01c474b4$4136eb30$3a0040d5@hblaptop>
Message-ID: <20040728202624.6fcbd86c@misha>

Thanks for your suggestions,

On Wed, 28 Jul 2004 17:04:57 +0200
"Henrik Bengtsson" <hb at maths.lth.se> wrote:

> 
> Anyway, I think you also should read the help for scan(). What do you want
> with argument 'what="PS"'? "PS" is not a valid data type; 'what' does not
> specify a name of field/column to be read.

>From the scan help page...

   what: the type of 'what' gives the type of data to be read.

It seems to me that I had read somewhere (maybe on the mailing list archives), that 'what' was supposed to be a sort of example of the kind of data you had to read... so I put a character string because I wanted the data to be read as character because I had a column of factors. I know this is not a great way to do it (better have a matrix made up of nubers only, instead of having to subsequently convert columns of character strings to number) but I wanted to do a quick test without having to rearrange my file.

Cheers,

fede



From ggrothendieck at myway.com  Wed Jul 28 18:27:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 28 Jul 2004 12:27:10 -0400 (EDT)
Subject: [R] elegant matrix creation
Message-ID: <20040728162710.5739512D14@mprdmxin.myway.com>



[Sorry if this gets posted twice but I am having more gmane posting problems.]

Not sure if this qualifies as elegant or not but it does (1) bring
all three matrices under a single scheme, (2) reduce the number of
numbers from 81 to 18 per matrix, (3) requires only a single one
line utility function, (4) is simple and (5) gives some minimal
insight into the patterns.

The key thing to note is that each row of each matrix is a cyclic
shift of the first row of that matrix.

Define a shift function which shifts its vector argument v by 
shift positions to the left creating a one row matrix.  If shift is 
a vector it creates a matrix with one row per shift.

shiftL <- function(v, shift) 
	outer(shift,seq(along=v)-1, function(i,j)v[(i+j)%%length(v)+1])

jj1a <- shiftL(c(1,1,1,2,2,2,3,3,3),c(0,3,6,0,3,6,0,3,6))
jj2a <- shiftL(c(1,2,1,3,1,3,2,3,2),c(0,6,3,0,6,3,0,6,3))
jj3a <- shiftL(c(1,1,1,2,2,2,3,3,3),c(0,4,8,3,7,2,6,1,5))

# or finding expressions for the two args in each case:

jj1b <- shiftL( rep(1:3,c(3,3,3)), rep(c(0,3,6),3) )
jj2b <- shiftL( c(shiftL(c(1,3,2),c(0,2,0))), rep(c(0,6,3),3) )
jj3b <- shiftL( rep(1:3,c(3,3,3)), seq(0,32,4) %% 9 )



From pgilbert at bank-banque-canada.ca  Wed Jul 28 18:33:08 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 28 Jul 2004 12:33:08 -0400
Subject: [R] DESCRIPTION.in
In-Reply-To: <20040727231355.4D4C63FC5C@omta16.mta.everyone.net>
References: <20040727231355.4D4C63FC5C@omta16.mta.everyone.net>
Message-ID: <4107D544.6060203@bank-banque-canada.ca>

Kevin

To work around this problem I generate the DESCRIPTION and 
DESCRIPTION.in files from my Makefile. (BTW, using make to control the 
building process is pretty useful.) If I am building a single package I 
generate DESCRIPTION and if I am generating a bundle I generate 
DESCRIPTION.in.

If you want more details on my whole Makefile system then let me know.

Paul Gilbert

Kevin Bartz wrote:

> Hello R world! I'm building a bundle of four packages, but I don't always
> want to build the whole bundle. Usually I just want to tweak one function in
> one of the packages and rebuild just that package. As such, I have
> DESCRIPTION and DESCRIPTION.in files sitting in all the package folders.
> Unfortunately, there's a pesky line in R CMD build that hacks away
> DESCRIPTION whenever it sees DESCRIPTION.in. This is okay for building the
> whole bundle, but it makes it a major pain to build any of the packages
> individually. I am root, so for now I have commented the offending line in
> /usr/local/lib/R/bin/build. Is this the proper solution or am I overlooking
> something? Thanks for any help you can provide,
> 
> Kevin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kjetil at acelerate.com  Wed Jul 28 18:44:02 2004
From: kjetil at acelerate.com (Kjetil Halvorsen)
Date: Wed, 28 Jul 2004 12:44:02 -0400
Subject: [R] elegant matrix creation
References: <a0600200abd2d59a97c4d@[139.166.242.29]>
Message-ID: <4107D7D2.3000602@acelerate.com>



Robin Hankin wrote:
> Hello everybody.
> 
> I am trying to reproduce a particular matrix in an elegant way.  If I
> have
> 
> jj1 <-
> structure(c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,
> 3,1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,2,3,
> 1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,3,1,2,3,1,
> 2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,
> 2),.Dim = as.integer(c(9,9)))
> 
> [ image(jj1) is good here ] then I can get this with
> 
> kronecker(matrix(1,3,1),kronecker(1+outer(0:2,0:2,"+")%%3,matrix(1,1,3)))
> 
> I want to reproduce the following matrices in an equivalent way:
> 
> jj2 <- matrix(c(1,2,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,1,
> 1,2,3,1,2,3,1,2,3,3,1,2,3,1,2,3,1,2,1,2,3,1,2,
> 3,1,2,3,3,1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1,3,
> 1,2,3,1,2,3,1,2,2,3,1,2,3,1,2,3,1),9,9)
> 
> jj3 <- structure(c(1,2,3,2,3,1,3,1,2,1,2,1,2,3,2,3,1,
> 3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1,2,3,2,3,
> 2,3,1,3,1,2,1,2,1,2,3,2,3,1,3,1,3,1,2,1,2,
> 3,2,3,1,3,1,3,1,2,1,2,3,2,3,2,3,1,3,1,2,1, 2),.Dim =
> as.integer(c(9,9)))
> 

some musings. You have not told us hove jj3 arises naturally, but its 
structure seems to have something to do with magic squares. So

library(magic) # on CRAN
is.magic(jj3) # TRUE
       This is not in accordance with my concept of magic squares, since 
an n*n magic square should have all the numbers from 1 to n^2 exactly 
once. But all rowSums and colSums are equal.

Note that if we view jj3 as a 3*3 block matrix, with each block
a 3*3 matrix, then all the blockx are generated rowwise the following 
way: Let x in 1:3 be the generator, and + be sum modulo 3, but we take 
the rep 3 and not 0.
Then we have

x       x        x
x+1     x+1      x+2
x+2     x        x

and the 3*3 matrix of the generators can be generated in the following way:

 > xx <- ((magic(3) %% 3)+1)[,3:1]
 > xx
      [,1] [,2] [,3]
[1,]    1    2    3
[2,]    2    3    1
[3,]    3    1    2

 > "++" <- function(x,a) {
        if ( (x+a)%%3 == 0 ) 3 else (x+a) %% 3 }

 > makeBlock <- function(x) {
+    matrix( c( rep(x,3), rep("++"(x,1), 2), rep("++"(x,2), 2),
+               rep(x,2) ) , 3,3, byrow=TRUE)  }
 > makeBlock(1)
      [,1] [,2] [,3]
[1,]    1    1    1
[2,]    2    2    3
[3,]    3    1    1

 > ans <- matrix (NA,9,9)
 > for (i in 1:3) for (j in 1:3) {
+   ans[3*(i-1)+1:3, 3*(j-1)+1:3] <- makeBlock(xx[i,j]) }
 > ans
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
  [1,]    1    1    1    2    2    2    3    3    3
  [2,]    2    2    3    3    3    1    1    1    2
  [3,]    3    1    1    1    2    2    2    3    3
  [4,]    2    2    2    3    3    3    1    1    1
  [5,]    3    3    1    1    1    2    2    2    3
  [6,]    1    2    2    2    3    3    3    1    1
  [7,]    3    3    3    1    1    1    2    2    2
  [8,]    1    1    2    2    2    3    3    3    1
  [9,]    2    3    3    3    1    1    1    2    2
 > ans ==jj3
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
  [1,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [2,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [3,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [4,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [5,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [6,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [7,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [8,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
  [9,] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE


Kjetil Halvorsen



> [ note that jj1-jj3 each have precisely 3 occurrences of A, B, and C
> along each row, column and (broken) diagonal ].
> 
> Can anyone give me a nice elegant way of creating jj2 and jj3 please?
>



From ligges at statistik.uni-dortmund.de  Wed Jul 28 18:47:01 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 28 Jul 2004 18:47:01 +0200
Subject: [R] Question ?
In-Reply-To: <b1566959.6959b156@uqac.ca>
References: <b1566959.6959b156@uqac.ca>
Message-ID: <4107D885.7060002@statistik.uni-dortmund.de>

Jean-Luc Allard wrote:

> HI,
> 
> I would like use header file in the R-HOME/scr/include. What should I do please ?
> 
> JL

Just by using "include" and the filename.
If you use R CMD SHLIB to create the library or the library is compiled 
during R CMD INSTALL, the path is included in the search path for header 
files.

Uwe Ligges



> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mayeul.kauffmann at tiscali.fr  Wed Jul 28 19:08:35 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Wed, 28 Jul 2004 19:08:35 +0200
Subject: [R] covariate selection in cox model (counting process)
Message-ID: <000d01c474c5$84f059e0$a2599a53@amd>

> If you can get the conditional independence (martingaleness) then, yes,
> BIC is fine.
>
> One way to check might be to see how similar the standard errors are
with
> and without the cluster(id) term.

(Thank you "again !", Thomas.)

At first look, the values seemed very similar (see below, case 2).
However, to check this without being too subjective, and without a
specific test, I needed other values to assess the size of the
differences: what is similar, what is not?


==========================================================================
=====
CASE 1
I first estimated the model without modeling dependence:

Call:
coxph(formula = Surv(start, stop, status) ~ cluster(ccode) +
    pop + pib + pib2 + crois + instab.x1  + instab.autres, data = xstep)


                 coef exp(coef) se(coef) robust se     z       p
pop            0.3606     1.434   0.0978    0.1182  3.05 2.3e-03
pib           -0.5947     0.552   0.1952    0.1828 -3.25 1.1e-03
pib2          -0.4104     0.663   0.1452    0.1270 -3.23 1.2e-03
crois         -0.0592     0.943   0.0245    0.0240 -2.46 1.4e-02
instab.x1      2.2059     9.079   0.4692    0.4097  5.38 7.3e-08
instab.autres  0.9550     2.599   0.4700    0.4936  1.93 5.3e-02

Likelihood ratio test=74  on 6 df, p=6.2e-14  n= 7286

There seems to be a strong linear relationship between standard errors
(se, or naive se) and robust se.

>      summary(lm(sqrt(diag(cox1$var))~ sqrt(diag(cox1$naive.var)) -1))
Coefficients:
                           Estimate Std. Error t value Pr(>|t|)
sqrt(diag(cox1$naive.var))  0.96103    0.04064   23.65 2.52e-06 ***
Multiple R-Squared: 0.9911, Adjusted R-squared: 0.9894


==========================================================================
=====
CASE 2

Then I added a variable (pxcw) measuring the proximity of the previous
event (1>pxcw>0)

n= 7286
                 coef exp(coef) se(coef) robust se     z       p
pxcw           0.9063     2.475   0.4267    0.4349  2.08 3.7e-02
pop            0.3001     1.350   0.1041    0.1295  2.32 2.0e-02
pib           -0.5485     0.578   0.2014    0.1799 -3.05 2.3e-03
pib2          -0.4033     0.668   0.1450    0.1152 -3.50 4.6e-04
crois         -0.0541     0.947   0.0236    0.0227 -2.38 1.7e-02
instab.x1      1.9649     7.134   0.4839    0.4753  4.13 3.6e-05
instab.autres  0.8498     2.339   0.4693    0.4594  1.85 6.4e-02

Likelihood ratio test=78.3  on 7 df, p=3.04e-14  n= 7286


                           Estimate Std. Error t value Pr(>|t|)
sqrt(diag(cox1$naive.var))  0.98397    0.02199   44.74 8.35e-09 ***
Multiple R-Squared: 0.997, Adjusted R-squared: 0.9965

The naive standard errors (se) seem closer to the robust se than they were
when not modeling for dependence.
0.98397 is very close to one, R^2 grew, etc.
The dependence is high (risk is multiplied by 2.475 the day after an
event)
but conditional independence (given covariates) seems hard to reject.


==========================================================================
=====
CASE 3
Finally, I compared these results with those without repeated events
(which gives a smaller dataset). A country is removed as soon as we
observe its first event.
(robust se is still computed, even if naive se should in fact be used here
to compute the pvalue)

coxph(formula = Surv(start, stop, status) ~ cluster(ccode) +
    pop + pib + pib2 + crois + instab.x1  + instab.autres, data =
xstep[no.previous.event, ])

                 coef exp(coef) se(coef) robust se     z       p
pop            0.4236     1.528   0.1030    0.1157  3.66 2.5e-04
pib           -0.7821     0.457   0.2072    0.1931 -4.05 5.1e-05
pib2          -0.3069     0.736   0.1477    0.1254 -2.45 1.4e-02
crois         -0.0432     0.958   0.0281    0.0258 -1.67 9.5e-02
instab.x1      1.9925     7.334   0.5321    0.3578  5.57 2.6e-08
instab.autres  1.3571     3.885   0.5428    0.5623  2.41 1.6e-02

Likelihood ratio test=66.7  on 6 df, p=1.99e-12  n=5971 (2466 observations
deleted due to missing)


>      summary(lm(sqrt(diag(cox1$var))~ sqrt(diag(cox1$naive.var)) -1))
                           Estimate Std. Error t value Pr(>|t|)
sqrt(diag(cox1$naive.var))  0.86682    0.07826   11.08 0.000104 ***
Residual standard error: 0.06328 on 5 degrees of freedom
Multiple R-Squared: 0.9608, Adjusted R-squared: 0.953


There seems to be no evidence that robust se is more different from se in
case 2 than in case 3 (and case 1).
It even seems closer.

I conclude that conditional independence (martingaleness) cannot be
rejected in CASE 2, when modeling the dependence between events with a
covariate.

Mayeul KAUFFMANN
Univ. Pierre Mendes France
Grenoble - France



> > Then, there is still another option. In fact, I already modelled
> > explicitely the influence of past events with a "proximity of last
event"
> > covariate, assuming the dependence on the last event decreases at a
> > constant rate (for instance, the proximity covariate varies from 1 to
0.5
> > in the first 10 years after an event, then from 0.5 to 0.25 in the
next
> > ten years, etc).
> >
> > With a well chosen modelisation of the dependence effect, the events
> > become conditionnaly independent, I do not need a +cluster(id) term,
and I
> > can use fit$loglik to make a covariate selection based on BIC, right?
>
> If you can get the conditional independence (martingaleness) then, yes,
> BIC is fine.
>
> One way to check might be to see how similar the standard errors are
with
> and without the cluster(id) term.



From ggrothendieck at myway.com  Wed Jul 28 19:12:21 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 28 Jul 2004 13:12:21 -0400 (EDT)
Subject: [R] elegant matrix creation
Message-ID: <20040728171221.9571C12D1D@mprdmxin.myway.com>



In reading this over I noticed that the two input vectors to
shiftL could be put in a parameterized form that reduces the
input to two integers:


shiftL <- function(v, shift) 
   outer(shift,seq(along=v)-1, function(i,j)v[(i+j)%%length(v)+1])

jj <- function(i,j)
   shiftL( seq(0,by=i,len=9) %% 9 %/% 3 + 1, seq(0, len=9, by=j) %% 9)

jj1 <- jj(1,3)
jj2 <- jj(5,6)
jj3 <- jj(1,4)



From:   	Gabor Grothendieck <ggrothendieck at myway.com>

[Sorry if this gets posted twice but I am having more gmane posting problems.]

Not sure if this qualifies as elegant or not but it does (1) bring
all three matrices under a single scheme, (2) reduce the number of
numbers from 81 to 18 per matrix, (3) requires only a single one
line utility function, (4) is simple and (5) gives some minimal
insight into the patterns.

The key thing to note is that each row of each matrix is a cyclic
shift of the first row of that matrix.

Define a shift function which shifts its vector argument v by
shift positions to the left creating a one row matrix. If shift is
a vector it creates a matrix with one row per shift.

shiftL <- function(v, shift)
     outer(shift,seq(along=v)-1, function(i,j)v[(i+j)%%length(v)+1])

jj1a <- shiftL(c(1,1,1,2,2,2,3,3,3),c(0,3,6,0,3,6,0,3,6))
jj2a <- shiftL(c(1,2,1,3,1,3,2,3,2),c(0,6,3,0,6,3,0,6,3))
jj3a <- shiftL(c(1,1,1,2,2,2,3,3,3),c(0,4,8,3,7,2,6,1,5))

# or finding expressions for the two args in each case:

jj1b <- shiftL( rep(1:3,c(3,3,3)), rep(c(0,3,6),3) )
jj2b <- shiftL( c(shiftL(c(1,3,2),c(0,2,0))), rep(c(0,6,3),3) )
jj3b <- shiftL( rep(1:3,c(3,3,3)), seq(0,32,4) %% 9 )



From tlumley at u.washington.edu  Wed Jul 28 19:42:01 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 Jul 2004 10:42:01 -0700 (PDT)
Subject: [R] covariate selection in cox model (counting process)
In-Reply-To: <000d01c474c5$84f059e0$a2599a53@amd>
References: <000d01c474c5$84f059e0$a2599a53@amd>
Message-ID: <Pine.A41.4.58.0407281038490.88732@homer07.u.washington.edu>

On Wed, 28 Jul 2004, Mayeul KAUFFMANN wrote:

> > If you can get the conditional independence (martingaleness) then, yes,
> > BIC is fine.
> >
> > One way to check might be to see how similar the standard errors are
> with
> > and without the cluster(id) term.
>
> (Thank you "again !", Thomas.)
>
> At first look, the values seemed very similar (see below, case 2).
> However, to check this without being too subjective, and without a
> specific test, I needed other values to assess the size of the
> differences: what is similar, what is not?
>

I think the econometricians have theory for this (comparing the whole
covariance matrices).

	-thomas

>
> ==========================================================================
> =====
> CASE 1
> I first estimated the model without modeling dependence:
>
> Call:
> coxph(formula = Surv(start, stop, status) ~ cluster(ccode) +
>     pop + pib + pib2 + crois + instab.x1  + instab.autres, data = xstep)
>
>
>                  coef exp(coef) se(coef) robust se     z       p
> pop            0.3606     1.434   0.0978    0.1182  3.05 2.3e-03
> pib           -0.5947     0.552   0.1952    0.1828 -3.25 1.1e-03
> pib2          -0.4104     0.663   0.1452    0.1270 -3.23 1.2e-03
> crois         -0.0592     0.943   0.0245    0.0240 -2.46 1.4e-02
> instab.x1      2.2059     9.079   0.4692    0.4097  5.38 7.3e-08
> instab.autres  0.9550     2.599   0.4700    0.4936  1.93 5.3e-02
>
> Likelihood ratio test=74  on 6 df, p=6.2e-14  n= 7286
>
> There seems to be a strong linear relationship between standard errors
> (se, or naive se) and robust se.
>
> >      summary(lm(sqrt(diag(cox1$var))~ sqrt(diag(cox1$naive.var)) -1))
> Coefficients:
>                            Estimate Std. Error t value Pr(>|t|)
> sqrt(diag(cox1$naive.var))  0.96103    0.04064   23.65 2.52e-06 ***
> Multiple R-Squared: 0.9911, Adjusted R-squared: 0.9894
>
>
> ==========================================================================
> =====
> CASE 2
>
> Then I added a variable (pxcw) measuring the proximity of the previous
> event (1>pxcw>0)
>
> n= 7286
>                  coef exp(coef) se(coef) robust se     z       p
> pxcw           0.9063     2.475   0.4267    0.4349  2.08 3.7e-02
> pop            0.3001     1.350   0.1041    0.1295  2.32 2.0e-02
> pib           -0.5485     0.578   0.2014    0.1799 -3.05 2.3e-03
> pib2          -0.4033     0.668   0.1450    0.1152 -3.50 4.6e-04
> crois         -0.0541     0.947   0.0236    0.0227 -2.38 1.7e-02
> instab.x1      1.9649     7.134   0.4839    0.4753  4.13 3.6e-05
> instab.autres  0.8498     2.339   0.4693    0.4594  1.85 6.4e-02
>
> Likelihood ratio test=78.3  on 7 df, p=3.04e-14  n= 7286
>
>
>                            Estimate Std. Error t value Pr(>|t|)
> sqrt(diag(cox1$naive.var))  0.98397    0.02199   44.74 8.35e-09 ***
> Multiple R-Squared: 0.997, Adjusted R-squared: 0.9965
>
> The naive standard errors (se) seem closer to the robust se than they were
> when not modeling for dependence.
> 0.98397 is very close to one, R^2 grew, etc.
> The dependence is high (risk is multiplied by 2.475 the day after an
> event)
> but conditional independence (given covariates) seems hard to reject.
>
>
> ==========================================================================
> =====
> CASE 3
> Finally, I compared these results with those without repeated events
> (which gives a smaller dataset). A country is removed as soon as we
> observe its first event.
> (robust se is still computed, even if naive se should in fact be used here
> to compute the pvalue)
>
> coxph(formula = Surv(start, stop, status) ~ cluster(ccode) +
>     pop + pib + pib2 + crois + instab.x1  + instab.autres, data =
> xstep[no.previous.event, ])
>
>                  coef exp(coef) se(coef) robust se     z       p
> pop            0.4236     1.528   0.1030    0.1157  3.66 2.5e-04
> pib           -0.7821     0.457   0.2072    0.1931 -4.05 5.1e-05
> pib2          -0.3069     0.736   0.1477    0.1254 -2.45 1.4e-02
> crois         -0.0432     0.958   0.0281    0.0258 -1.67 9.5e-02
> instab.x1      1.9925     7.334   0.5321    0.3578  5.57 2.6e-08
> instab.autres  1.3571     3.885   0.5428    0.5623  2.41 1.6e-02
>
> Likelihood ratio test=66.7  on 6 df, p=1.99e-12  n=5971 (2466 observations
> deleted due to missing)
>
>
> >      summary(lm(sqrt(diag(cox1$var))~ sqrt(diag(cox1$naive.var)) -1))
>                            Estimate Std. Error t value Pr(>|t|)
> sqrt(diag(cox1$naive.var))  0.86682    0.07826   11.08 0.000104 ***
> Residual standard error: 0.06328 on 5 degrees of freedom
> Multiple R-Squared: 0.9608, Adjusted R-squared: 0.953
>
>
> There seems to be no evidence that robust se is more different from se in
> case 2 than in case 3 (and case 1).
> It even seems closer.
>
> I conclude that conditional independence (martingaleness) cannot be
> rejected in CASE 2, when modeling the dependence between events with a
> covariate.
>
> Mayeul KAUFFMANN
> Univ. Pierre Mendes France
> Grenoble - France
>
>
>
> > > Then, there is still another option. In fact, I already modelled
> > > explicitely the influence of past events with a "proximity of last
> event"
> > > covariate, assuming the dependence on the last event decreases at a
> > > constant rate (for instance, the proximity covariate varies from 1 to
> 0.5
> > > in the first 10 years after an event, then from 0.5 to 0.25 in the
> next
> > > ten years, etc).
> > >
> > > With a well chosen modelisation of the dependence effect, the events
> > > become conditionnaly independent, I do not need a +cluster(id) term,
> and I
> > > can use fit$loglik to make a covariate selection based on BIC, right?
> >
> > If you can get the conditional independence (martingaleness) then, yes,
> > BIC is fine.
> >
> > One way to check might be to see how similar the standard errors are
> with
> > and without the cluster(id) term.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From rduarte at unicamp.br  Wed Jul 28 19:50:23 2004
From: rduarte at unicamp.br (Rodrigo Drummond)
Date: Wed, 28 Jul 2004 14:50:23 -0300 (BRT)
Subject: [R] Integration with 'adapt'
In-Reply-To: <16647.24022.35331.463267@gargle.gargle.HOWL>
References: <3628.143.106.4.184.1090953067.squirrel@143.106.4.184>
	<16647.24022.35331.463267@gargle.gargle.HOWL>
Message-ID: <3925.143.106.4.184.1091037023.squirrel@143.106.4.184>

Thank you for your answer to my question.
Here is a reproducible example of the problem:

> A<-2
> B<--1
> C<-1
> linf<-c(-10,-1,0.0003)
> lsup<-c(10,1,0.0004)
> Integrand1<-function(v)
{exp(-1*(A*v[1]^2-B*v[1]+C+(((v[1]-v[2])^2)/(2*v[3]^2))))/(K*v[3])}
> Const<-adapt(3,linf,lsup,functn=Integrand1)$value
Warning message:
Ifail=2, lenwrk was too small. -- fix adapt() !
 Check the returned relerr! in: adapt(3, linf, lsup, functn = Integrand1)

The problem is related to the small range of the third variable,
(0.0003-0.0004), so I tried the change of variables z2<-z/(max(z)-min(z)):

> rang=0.0004-0.0003
> linf[3]<-linf[3]/rang
> lsup[3]<-lsup[3]/rang
> Integrand1<-function(v)
{exp(-1*(A*v[1]^2-B*v[1]+C+(((v[1]-v[2])^2)/(2*(rang^2)*(v[3]^2)))))/(K*v[3])}
> #With the change of variables, the constant "rang" appears in the function.
> Const<-adapt(3,linf,lsup,functn=Integrand1)$value
Warning message:
Ifail=2, lenwrk was too small. -- fix adapt() !
 Check the returned relerr! in: adapt(3, linf, lsup, functn = Integrand1)

And the problem persists, probably because of the small value of "rang",
what can be checked below:

> rang<-.01
> Integrand1<-function(v)
{exp(-1*(A*v[1]^2-B*v[1]+C+(((v[1]-v[2])^2)/(2*(rang^2)*(v[3]^2)))))/(K*v[3])}
> #The same function as before, with a bigger value for "rang"
> Const<-adapt(3,linf,lsup,functn=Integrand1)$value
> Const
[1] 8.766637e-05

How can I evaluate the integral, even with small values of rang?
Thanks a lot for your help.
Best regards.
Rodrigo Drummond



>>>>>> "Rodrigo" == Rodrigo Drummond <rduarte at unicamp.br>
>>>>>>     on Tue, 27 Jul 2004 15:31:07 -0300 (BRT) writes:
>
>     Rodrigo> Hi all, I need to calculate a multidimensional
>     Rodrigo> integration on R. I am using the command
>     Rodrigo> "adapt" (from library adapt), although
>
> it's a "package", not a library.
>
>     Rodrigo> sometimes I get the following error message:
>
>     Rodrigo> Ifail=2, lenwrk was too small. -- fix adapt() !
>     Rodrigo> Check the returned relerr! in: adapt(3, linf, lsup,
>     Rodrigo> functn = Integrando1)
>
> If you could give as a *reproducible* example,
>
> we (the adapt authors) would have chance to do what the above
> message says, namely "fix adapt()" ..
>
>
>     Rodrigo> I guess it happens because the domain of
>     Rodrigo> integration is too small,
>
> maybe, maybe not. We need an example we can reproduce, see above.
>
>     Rodrigo> although I tried a change of variables to avoid
>     Rodrigo> this problem and it didn?t help. The command adapt
>     Rodrigo> calls a fortran routine, but I don?t know fortran
>     Rodrigo> enough to fix the problem.
>
> Martin Maechler, ETH Zurich
>


____________________________________________
Rodrigo D. Drummond
Laboratorio Genoma Funcional
Centro de Biologia Molecular e Eng. Genetica
Universidade Estadual de Campinas
Caixa Postal 6010
13083-875 - Campinas - SP - Brasil
Tel: xx-19-3788-1119 Fax: xx-19-3788-1089



From ggrothendieck at myway.com  Wed Jul 28 20:01:54 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 28 Jul 2004 14:01:54 -0400 (EDT)
Subject: [R] elegant matrix creation
Message-ID: <20040728180154.6448612CD4@mprdmxin.myway.com>



Here is yet one more simplification.  Note that seq9 in this one
is not the same as seq9 in the last one.  This one looks much
more symmetric in the arguments and is shorter:


seq9 <- function(i) seq(0, len = 9, by = i)
jj <- function(i,j) outer( seq9(i), seq9(j), "+" ) %% 9 %/% 3 + 1

jj1. <- jj(3,1)
jj2. <- jj(3,5)
jj3. <- jj(4,1)



From tlumley at u.washington.edu  Wed Jul 28 20:03:08 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 Jul 2004 11:03:08 -0700 (PDT)
Subject: [R] Gaussian frailty leads to segmentation fault
In-Reply-To: <4107D669.5080501@imse.med.tu-muenchen.de>
References: <4107D669.5080501@imse.med.tu-muenchen.de>
Message-ID: <Pine.A41.4.58.0407281102260.88732@homer07.u.washington.edu>


We really need a reproducible example to find segmentation faults.  Can
you make one?

	-thomas


On Wed, 28 Jul 2004, Christian Lederer wrote:

>
> Dear R gurus,
>
> for a simulation concerning study effects and historical controls
> in survival analysis, i would like to experiment with a gaussian
> frailty model.
>
> The simulated scenario consists of a randomized trial
> (treatment and placebo) and historical controls (only placebo).
>
> So the simulated data frames consist of four columns
> $time, $cens, $study, $treat.
> $time, $cens are the usual survival data.
> For the binary thretment indicator we have
> $treat == 0 or 1, if $study == 1,
> $treat == 1 if $study > 1
>
> Typical parameters for my simulations are:
> sample sizes (per arm):         between 100 and 200
> number of historical studies:   between 7 and 15
> hazard ratio treatment/placebo: between 0.7 and 1
> variance of the study effekt:   between 0 and 0.3
>
> Depending on the sample sizes, the following call sometimes leads to
> a segmentation fault:
>
> coxph(Surv(time,cens) ~
>        as.factor(treatment) + frailty(study, distribution="gaussian"),
>        data=data)
>
> I noticed, that this segmentation fault occures most frequently, if the
> number of randomized treatment patients is higher than the number of
> randomized placebo patients, and the number of historical studies is
> large.
> There seems to be no problem, if there are at least as many randomized
> placebo patients as treated patients. Unfortunately, this is not the
> situation i want to investigate (historical controls should be used
> to decrease the number of treated patients).
>
> Is there a way to circumwent this problem?
>
> Christian
>
> P.S.
> Is it allowed, to attach gzipped sample data sets in this mailing list?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From andy_liaw at merck.com  Wed Jul 28 20:27:20 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 28 Jul 2004 14:27:20 -0400
Subject: [R] How to add an object to an RData file ?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF813A@usrymx25.merck.com>

I guess it would be nice if save() has an `append' option...

Andy

> From: Roger D. Peng
> 
> I can't think of a faster way.
> 
> -roger
> 
> Ernesto Jardim wrote:
> > Hi,
> > 
> > I've saved an RData file with "save" and now I want to add 
> a new object
> > to this file. At the moment I do:
> > 
> > attach("file.RData")
> > save(list=c("new,obj", ls(pos=2)), file="file.RData", compress=T)
> > detach()
> > 
> > Is there a quicker method that just add the object to the file ?
> > 
> > Thanks
> > 
> > EJ



From dray at biomserv.univ-lyon1.fr  Wed Jul 28 20:30:49 2004
From: dray at biomserv.univ-lyon1.fr (Stephane DRAY)
Date: Wed, 28 Jul 2004 14:30:49 -0400
Subject: [R] a bug with LAPACK ? non orthogonal vectors obtained
	with eigen of a symmetric matrix
In-Reply-To: <4107C555.1020105@jhsph.edu>
References: <5.2.1.1.0.20040728105218.00b4b2b8@biomserv.univ-lyon1.fr>
	<5.2.1.1.0.20040728105218.00b4b2b8@biomserv.univ-lyon1.fr>
Message-ID: <5.2.1.1.0.20040728140213.00b4b2b8@biomserv.univ-lyon1.fr>

At 11:25 28/07/2004, Roger D. Peng wrote:
>This is interesting.  I can reproduce your results but cannot come up with 
>an explanation.  However, using svd(LINPACK = FALSE) seems to work every 
>time.  Might you consider trying that instead?
>
>-roger

I have try to do it with svd but here the problem is that the matrices 
under study have some equal singular values and in this case, I do not have 
u=v for a symmetric matrix (I supose that a linear combination of u 
corresponding to equal singular values allow to obtain the v for the same 
singular values).
i.e. if d2=d3=d4
u2=av2+bv3+cv4
... and not necessarily u2=v2


But here, I found another problem:

#This is for svd with LINPACK. It works, u vectors are orthogonal (same for v)

or(i in 3:20){
x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
res=svd(x,LIN=T)
eq0 <- apply(as.matrix(res$d),1,function(x) identical(all.equal(x, 0), TRUE))
resu=res$u[,-which(eq0)]
resv=res$v[,-which(eq0)]
print(paste("Grid size",i))
print(paste("u ortho ?",all.equal(diag(1,ncol(resu)),t(resu)%*%resu)))
print(paste("v ortho ?",all.equal(diag(1,ncol(resv)),t(resv)%*%resv)))
print(paste("u == v ?",all.equal(abs(resv),abs(resu))))

}

#But without LINPACK:

for(i in 3:20){
x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
res=svd(x,LIN=F)
eq0 <- apply(as.matrix(res$d),1,function(x) identical(all.equal(x, 0), TRUE))
resu=res$u[,-which(eq0)]
resv=res$v[,-which(eq0)]
print(paste("Grid size",i))
print(paste("u ortho ?",all.equal(diag(1,ncol(resu)),t(resu)%*%resu)))
print(paste("v ortho ?",all.equal(diag(1,ncol(resv)),t(resv)%*%resv)))
print(paste("u == v ?",all.equal(abs(resv),abs(resu))))
}


All is fine, except for i=14 where vectors u (and v) are not orthogonal
[1] "Grid size 14"
[1] "u ortho ? Mean relative  difference: 269.2564"
[1] "v ortho ? Mean relative  difference: 2097.224"
[1] "u == v ? Mean relative  difference: 0.7612647"

I  wonder if it is a general problem, a problem due to the structure of my 
matrix (I don't think so) , a windoze problem or a bug in my head !!!

Sincerely.



>Stephane DRAY wrote:
>>Hello,
>>I have send send this message one week ago but I have receive no answer. 
>>Perhaps, some of RListers were in holidays and do not read my message. I 
>>try again..
>>My problem is that I obtained non orthonormal eigenvectors with some 
>>matrices with LAPACK while EISPACK seems to provide "good" results. Is 
>>there some restrictions with the use of LAPACK ? Is it a bug ? I did not 
>>find the answer. Here is my experiment:
>>  I have obtained strange results using eigen on a symmetric matrix:
>># this function perform a double centering of a matrix 
>>(xij-rowmean(i)-colmean(j)+meantot)
>>dbcenter=function(mat){
>>rmean=apply(mat,1,mean)
>>cmean=apply(mat,2,mean)
>>newmat=sweep(mat,1,rmean,"-")
>>newmat=sweep(newmat,2,cmean,"-")
>>newmat=newmat+mean(mat)
>>newmat}
>># i use spdep package to create a spatial contiguity matrix
>>library(spdep)
>>x=dbcenter(nb2mat(cell2nb(3,3),style="B"))
>>#compute eigenvalues of a 9 by 9 matrix
>>res=eigen(x)
>># some eigenvalues are equal to 0
>>eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>>0), TRUE))
>># I remove the corresponding eigenvectors
>>res0=res$vec[,-which(eq0)]
>># then I compute the Froebenius norm with the identity matrix
>>sum((diag(1,ncol(res0))-crossprod(res0))^2)
>>[1] 1.515139e-30
>># The results are correct,
>># then I do it again with a biggest matrix(100 by 100)
>>x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
>>res=eigen(x)
>>eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>>0), TRUE))
>>res0=res$vec[,-which(eq0)]
>>sum((diag(1,ncol(res0))-crossprod(res0))^2)
>>[1] 3.986387
>>
>>I have try the same with res=eigen(x,EISPACK=T):
>>  x=dbcenter(nb2mat(cell2nb(10,10),style="B"))
>>res=eigen(x,EISPACK=T)
>>eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>>0), TRUE))
>>res0=res$vec[,-which(eq0)]
>>sum((diag(1,ncol(res0))-crossprod(res0))^2)
>>[1] 1.315542e-27
>>
>>So I wonder I there is a bug in the LAPACK algorithm or if there are some 
>>things that I have not understood. Note that my matrix has some pairs of 
>>equal eigenvalues.
>>Thanks in advance.
>>++++++++++++++++++++++++++++++++++++
>>I have continue my experiments in changing the size of my matrix :
>>(3^2 by 3^2, 4^2 by 4^2... 20^2 by 20^2)
>>EISPACK is always correct but LINPACK provide very strange results:
>>
>>  > for(i in 3:20){
>>+ x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
>>+ res=eigen(x,EIS=T)
>>+ eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>>0), TRUE))
>>+ res0=res$vec[,-which(eq0)]
>>+ print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
>>+ }
>>[1] 7.939371e-30
>>[1] 2.268788e-29
>>[1] 9.237286e-29
>>[1] 1.806393e-28
>>[1] 3.24619e-28
>>[1] 5.239195e-28
>>[1] 9.78079e-28
>>[1] 1.315542e-27
>>[1] 1.838600e-27
>>[1] 3.114150e-27
>>[1] 5.499297e-27
>>[1] 5.471782e-27
>>[1] 1.075098e-26
>>[1] 1.534822e-26
>>[1] 1.771326e-26
>>[1] 2.342404e-26
>>[1] 3.462522e-26
>>[1] 4.310143e-26
>>  > for(i in 3:20){
>>+ x=dbcenter(nb2mat(cell2nb(i,i),style="B"))
>>+ res=eigen(x)
>>+ eq0 <- apply(as.matrix(res$values),1,function(x) identical(all.equal(x, 
>>0), TRUE))
>>+ res0=res$vec[,-which(eq0)]
>>+ print(sum((diag(1,ncol(res0))-crossprod(res0))^2))
>>+ }
>>[1] 1.515139e-30
>>[1] 1.054286e-27
>>[1] 9.553017e-29
>>[1] 2.263455e-28
>>[1] 5.641993e-27
>>[1] 4.442088e-26
>>[1] 3.996714
>>[1] 3.986387
>>[1] 3.996545
>>[1] 7.396718
>>[1] NaN
>>[1] 7.980621
>>[1] 7.996769
>>[1] 3.984399
>>[1] NaN
>>[1] NaN
>>[1] NaN
>>[1] NaN
>>Note that I have do the same with random number and never find this kind 
>>of problems
>>
>>  > R.Version()
>>$platform
>>[1] "i386-pc-mingw32"
>>$arch
>>[1] "i386"
>>$os
>>[1] "mingw32"
>>$system
>>[1] "i386, mingw32"
>>$status
>>[1] ""
>>$major
>>[1] "1"
>>$minor
>>[1] "9.1"
>>$year
>>[1] "2004"
>>$month
>>[1] "06"
>>$day
>>[1] "21"
>>$language
>>[1] "R"
>>St??phane DRAY
>>-------------------------------------------------------------------------------------------------- 
>>
>>D??partement des Sciences Biologiques
>>Universit?? de Montr??al, C.P. 6128, succursale centre-ville
>>Montr??al, Qu??bec H3C 3J7, Canada
>>Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
>>E-mail : stephane.dray at umontreal.ca
>>-------------------------------------------------------------------------------------------------- 
>>
>>Web
>>http://www.steph280.freesurf.fr/
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From tlumley at u.washington.edu  Wed Jul 28 21:07:41 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 Jul 2004 12:07:41 -0700 (PDT)
Subject: [R] How to add an object to an RData file ?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF813A@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF813A@usrymx25.merck.com>
Message-ID: <Pine.A41.4.58.0407281206570.88732@homer07.u.washington.edu>

On Wed, 28 Jul 2004, Liaw, Andy wrote:

> I guess it would be nice if save() has an `append' option...

It would still have to read it in and out again, and then we would have
all the issues about multiple objects with the same name.

	-thomas

>
> Andy
>
> > From: Roger D. Peng
> >
> > I can't think of a faster way.
> >
> > -roger
> >
> > Ernesto Jardim wrote:
> > > Hi,
> > >
> > > I've saved an RData file with "save" and now I want to add
> > a new object
> > > to this file. At the moment I do:
> > >
> > > attach("file.RData")
> > > save(list=c("new,obj", ls(pos=2)), file="file.RData", compress=T)
> > > detach()
> > >
> > > Is there a quicker method that just add the object to the file ?
> > >
> > > Thanks
> > >
> > > EJ
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From elvis at xlsolutions-corp.com  Wed Jul 28 21:11:21 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Wed, 28 Jul 2004 12:11:21 -0700
Subject: [R] R/S-plus Course***In Atlanta,
	GA***R/Splus Fundamentals and Programming Techniques,
	August 19-20, 2004
Message-ID: <20040728191121.8410.qmail@webmail01.mesa1.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud 
to announce June 2004 2-day "R/S-plus Fundamentals and 
Programming Techniques". 

****Atlanta, GA --------------------------------------> August, 19-20

Interested in our R/Splus Advanced Programming course? Please email 
us! 
Reserve your seat now at the early bird rates! Payment due AFTER the 
class. 


Course Description: 
This two-day beginner to intermediate R/S-plus course focuses 
on a broad spectrum of topics, 
from reading raw data to a comparison of R and S. We will learn 
the essentials of data manipulation, graphical visualization 
and R/S-plus programming. We will explore statistical data analysis 
tools,including graphics with data sets. How to enhance your plots. 
We will perform basic statistics and fit linear regression models. 
Participants are encouraged to bring data for interactive sessions 


With the following outline: 
- An Overview of R and S 
- Data Manipulation and Graphics 
- Using Lattice Graphics 
- A Comparison of R and S-Plus 
- How can R Complement SAS? 
- Writing Functions 
- Avoiding Loops 
- Vectorization 
- Statistical Modeling 
- Project Management 
- Techniques for Effective use of R and S 
- Enhancing Plots 
- Using High-level Plotting Functions 
- Building and Distributing Packages (libraries) 


Email us for group discounts. 
Email Sue Turner: sue at xlsolutions-corp.com 
Phone: 206-686-1578 
Visit us: www.xlsolutions-corp.com/training.htm 
Please let us know if you and your colleagues are interested in this 
classto take advantage of group discount. Register now to secure your 
seat! 
Interested in R/Splus Advanced course? email us. 


Cheers, 
Elvis Miller, PhD 
Manager Training. 
XLSolutions Corporation 
206 686 1578 
www.xlsolutions-corp.com 
elvis at xlsolutions-corp.com



From ripley at stats.ox.ac.uk  Wed Jul 28 21:59:52 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jul 2004 20:59:52 +0100 (BST)
Subject: [R] How to add an object to an RData file ?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF813A@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0407282052300.794-100000@gannet.stats>

I don't think it is that simple.  There are several save formats, some 
historical that no one wants to touch.  So suppose we confined it to the 
current format.  Then one would need a pass over the saved file to see 
what (e.g. namespaces) should be shared and to find the existing 
references, so I don't think it would actually save anything much.
(If you want to work out if shared can be skipped, the code is in 
serialize.c ....)

On Wed, 28 Jul 2004, Liaw, Andy wrote:

> I guess it would be nice if save() has an `append' option...
> 
> Andy
> 
> > From: Roger D. Peng
> > 
> > I can't think of a faster way.
> > 
> > -roger
> > 
> > Ernesto Jardim wrote:
> > > Hi,
> > > 
> > > I've saved an RData file with "save" and now I want to add 
> > a new object
> > > to this file. At the moment I do:
> > > 
> > > attach("file.RData")
> > > save(list=c("new,obj", ls(pos=2)), file="file.RData", compress=T)
> > > detach()
> > > 
> > > Is there a quicker method that just add the object to the file ?
> > > 
> > > Thanks
> > > 
> > > EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pocernic at rap.ucar.edu  Wed Jul 28 23:36:38 2004
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Wed, 28 Jul 2004 15:36:38 -0600 (MDT)
Subject: [R] lattice variable by page
Message-ID: <Pine.LNX.4.44.0407281532290.24633-100000@albedo.rap.ucar.edu>

Hi,

Using lattice's xyplot, is it possible to specify a variable to group
plots by page.  For example, if I have

xyplot(y~x|A*B*C)

could I get a page created for each unique value in
variable C ?  I am hoping to avoid having pages with the same strip above
each plot on a page.

Thanks,

M

Matt Pocernich
NCAR - Research Applications Program
303-497-8312



From eckart_bindewald at yahoo.de  Wed Jul 28 23:43:17 2004
From: eckart_bindewald at yahoo.de (=?iso-8859-1?q?Eckart=20Bindewald?=)
Date: Wed, 28 Jul 2004 23:43:17 +0200 (CEST)
Subject: [R] where is "average shifted histogram"?
Message-ID: <20040728214317.92936.qmail@web25208.mail.ukl.yahoo.com>

Hello!
In the book Modern Applied Statistics with S (4th ed),
section 5.6 the concept of the "average shifted
histogram" or ASH is mentionend. Also it is mentioned
in the same section "The code used is in the scripts
for this chapter" (from figure caption 5.8, analysis
of the geyser duration data).
*However*, I have trouble finding the code for that
function! Admittedly, I am a newby to R. Where exactly
do I find the scripts to that chapter? Commands like
library(MASS), or help.search("average shifted
histogram") did not help.

Secondly: Is the fact that I have trouble finding a
routine for the average shifted histogram method a
hint, that the method is outdated, and instead method
X or Y should be used? The problem I am trying to
solve is to smoothe a two-dimensional data set, the
y-values change very rapidly between one and zero. The
function "loess" in R seems to do a very reasonable
job for that problem, but I would like to use a second
and different method.

Any help is highly appreciated!

Thanks,

Eckart Bindewald



From sundar.dorai-raj at PDF.COM  Wed Jul 28 23:47:02 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 28 Jul 2004 16:47:02 -0500
Subject: [R] lattice variable by page
In-Reply-To: <Pine.LNX.4.44.0407281532290.24633-100000@albedo.rap.ucar.edu>
References: <Pine.LNX.4.44.0407281532290.24633-100000@albedo.rap.ucar.edu>
Message-ID: <41081ED6.5050004@pdf.com>



Matt Pocernich wrote:

> Hi,
> 
> Using lattice's xyplot, is it possible to specify a variable to group
> plots by page.  For example, if I have
> 
> xyplot(y~x|A*B*C)
> 
> could I get a page created for each unique value in
> variable C ?  I am hoping to avoid having pages with the same strip above
> each plot on a page.
> 
> Thanks,
> 
> M
> 

Others may have a better solution, but when I've done this in the past I 
used a for loop with subset:

# assuming C is a factor to use nlevels
for(ci in nlevels(C)) {
   pl <- xyplot(y ~ x | A * B,
                subset = C == ci,
                main = paste("C ==", ci))
   print(pl)
}

HTH,
--sundar



From sundar.dorai-raj at PDF.COM  Wed Jul 28 23:50:04 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 28 Jul 2004 16:50:04 -0500
Subject: [R] where is "average shifted histogram"?
In-Reply-To: <20040728214317.92936.qmail@web25208.mail.ukl.yahoo.com>
References: <20040728214317.92936.qmail@web25208.mail.ukl.yahoo.com>
Message-ID: <41081F8C.7030807@pdf.com>

Eckart Bindewald wrote:

> Hello!
> In the book Modern Applied Statistics with S (4th ed),
> section 5.6 the concept of the "average shifted
> histogram" or ASH is mentionend. Also it is mentioned
> in the same section "The code used is in the scripts
> for this chapter" (from figure caption 5.8, analysis
> of the geyser duration data).
> *However*, I have trouble finding the code for that
> function! Admittedly, I am a newby to R. Where exactly
> do I find the scripts to that chapter? Commands like
> library(MASS), or help.search("average shifted
> histogram") did not help.
> 
> Secondly: Is the fact that I have trouble finding a
> routine for the average shifted histogram method a
> hint, that the method is outdated, and instead method
> X or Y should be used? The problem I am trying to
> solve is to smoothe a two-dimensional data set, the
> y-values change very rapidly between one and zero. The
> function "loess" in R seems to do a very reasonable
> job for that problem, but I would like to use a second
> and different method.
> 
> Any help is highly appreciated!
> 
> Thanks,
> 
> Eckart Bindewald
> 

Try:

install.packages("ash")
library(ash)

I have found "loess" (or possibly "locfit" in the package of the same 
name) more flexible though.

--sundar



From deepayan at stat.wisc.edu  Wed Jul 28 23:57:47 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 28 Jul 2004 16:57:47 -0500
Subject: [R] lattice variable by page
In-Reply-To: <Pine.LNX.4.44.0407281532290.24633-100000@albedo.rap.ucar.edu>
References: <Pine.LNX.4.44.0407281532290.24633-100000@albedo.rap.ucar.edu>
Message-ID: <200407281657.47731.deepayan@stat.wisc.edu>

On Wednesday 28 July 2004 16:36, Matt Pocernich wrote:
> Hi,
> 
> Using lattice's xyplot, is it possible to specify a variable to group
> plots by page.  For example, if I have
> 
> xyplot(y~x|A*B*C)
> 
> could I get a page created for each unique value in
> variable C ?  I am hoping to avoid having pages with the same strip above
> each plot on a page.

If I understand you correctly (which I'm not sure I do), then no, not 
directly. But you can do the following (assuming C is a factor):


for (l in levels(C)) {
  print(xyplot(y ~ x | A * B, subset = C == l))
}

Is that what you are looking for?

Deepayan



From p.connolly at hortresearch.co.nz  Wed Jul 28 23:59:26 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 29 Jul 2004 09:59:26 +1200
Subject: [R] Transparent backgrounds in png files
Message-ID: <20040729095926.W11533@hortresearch.co.nz>

The result I'm aiming to achieve is a bitmap that can be imported into
a PowerPoint file that shows what's behind the lines of the plot.
There's a way in PowerPoint that almost works.  By choosing a colour
to set as transparent, what is behind the graphic is indeed visible,
but it's at the expense of losing line and text definition.

I notice there have been discussions about transparent backgrounds
mostly with lattice plots.  The problem most people seem to have was
getting a blue background when they wanted a white one.

Mine is the reverse (and I'm using standard graphics, not Lattice).
I'm trying to get a transparent background but it always comes out
white.  Setting bg = "transparent", I've tried using a bitmap device
to create a png file.  I've also tried creating a postscript file and
converting it to a PNG file using the Gimp.  I've always used a
resolution of 300 dpi in bitmaps since the default is far too low.

Other ideas appreciated.

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    9.1              
year     2004             
month    06               
day      21               
language R                



Thanks.

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From sundar.dorai-raj at PDF.COM  Thu Jul 29 00:08:31 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 28 Jul 2004 17:08:31 -0500
Subject: [R] lattice variable by page
In-Reply-To: <41081ED6.5050004@pdf.com>
References: <Pine.LNX.4.44.0407281532290.24633-100000@albedo.rap.ucar.edu>
	<41081ED6.5050004@pdf.com>
Message-ID: <410823DF.1080109@pdf.com>



Sundar Dorai-Raj wrote:

> 
> 
> Matt Pocernich wrote:
> 
>> Hi,
>>
>> Using lattice's xyplot, is it possible to specify a variable to group
>> plots by page.  For example, if I have
>>
>> xyplot(y~x|A*B*C)
>>
>> could I get a page created for each unique value in
>> variable C ?  I am hoping to avoid having pages with the same strip above
>> each plot on a page.
>>
>> Thanks,
>>
>> M
>>
> 
> Others may have a better solution, but when I've done this in the past I 
> used a for loop with subset:
> 
> # assuming C is a factor to use nlevels
> for(ci in nlevels(C)) {
>   pl <- xyplot(y ~ x | A * B,
>                subset = C == ci,
>                main = paste("C ==", ci))
>   print(pl)
> }
> 
> HTH,
> --sundar
> 

Sorry made a typo: "nlevels" should be "levels".

--sundar



From sdavis2 at mail.nih.gov  Thu Jul 29 03:34:21 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 28 Jul 2004 21:34:21 -0400
Subject: [R] R with perl
Message-ID: <005301c4750c$2fa0a110$04653744@WATSON>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040728/ecce6083/attachment.pl

From christianlederer at t-online.de  Thu Jul 29 05:51:23 2004
From: christianlederer at t-online.de (Christian Lederer)
Date: Thu, 29 Jul 2004 05:51:23 +0200
Subject: [R] Gaussian frailty leads to segmentation fault
In-Reply-To: <Pine.A41.4.58.0407281102260.88732@homer07.u.washington.edu>
References: <4107D669.5080501@imse.med.tu-muenchen.de>
	<Pine.A41.4.58.0407281102260.88732@homer07.u.washington.edu>
Message-ID: <4108743B.6050302@t-online.de>

Dear Thomas,

attached you find a data frame which produces the error.
I am using survival 2.11-5 under R 1.9.1-1 and 1.9.0-1.

By the way, if i randomly omit 50% of the data, i usually
get no crash, but a warning message like this:
Inner loop failed to coverge for iterations 1 2 3 in: coxpenal.fit(X, 
Y, strats, offset, init = init, control, weights = weights,

Maybe, the model is not appropriate for this kind of data.
But on the other hand, as soon the treatment group (study == 1, 
treatment == 1) is smaller than the randomized placebo group
(study == 1, treatment == 0), the warnings disappear.
and the model gives reasonable results in my first simulations
with normally distributed study effects.

Christian




Thomas Lumley wrote:
> We really need a reproducible example to find segmentation faults.  Can
> you make one?
> 
> 	-thomas
> 
> 
> On Wed, 28 Jul 2004, Christian Lederer wrote:
> 
> 
>>Dear R gurus,
>>
>>for a simulation concerning study effects and historical controls
>>in survival analysis, i would like to experiment with a gaussian
>>frailty model.
>>
>>The simulated scenario consists of a randomized trial
>>(treatment and placebo) and historical controls (only placebo).
>>
>>So the simulated data frames consist of four columns
>>$time, $cens, $study, $treat.
>>$time, $cens are the usual survival data.
>>For the binary thretment indicator we have
>>$treat == 0 or 1, if $study == 1,
>>$treat == 1 if $study > 1
>>
>>Typical parameters for my simulations are:
>>sample sizes (per arm):         between 100 and 200
>>number of historical studies:   between 7 and 15
>>hazard ratio treatment/placebo: between 0.7 and 1
>>variance of the study effekt:   between 0 and 0.3
>>
>>Depending on the sample sizes, the following call sometimes leads to
>>a segmentation fault:
>>
>>coxph(Surv(time,cens) ~
>>       as.factor(treatment) + frailty(study, distribution="gaussian"),
>>       data=data)
>>
>>I noticed, that this segmentation fault occures most frequently, if the
>>number of randomized treatment patients is higher than the number of
>>randomized placebo patients, and the number of historical studies is
>>large.
>>There seems to be no problem, if there are at least as many randomized
>>placebo patients as treated patients. Unfortunately, this is not the
>>situation i want to investigate (historical controls should be used
>>to decrease the number of treated patients).
>>
>>Is there a way to circumwent this problem?
>>
>>Christian
>>
>>P.S.
>>Is it allowed, to attach gzipped sample data sets in this mailing list?
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


From pwilkinson at videotron.ca  Thu Jul 29 05:33:25 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Wed, 28 Jul 2004 23:33:25 -0400
Subject: [R] Re: [BioC] normalisation for universal reference in 2 channel
	arrays
Message-ID: <6.1.1.1.2.20040728233303.01be5da0@pop.videotron.ca>

Thanks for the suggestions,


one option i was thinking was to center the universal channel and sample 
channels by normalising the medians of each column of the matrix on each 
channel. But I don't know if it is appropriate to do a loess after this?

Does the quantile option actually do this?

Peter

At 06:59 PM 7/28/2004, you wrote:
>At 06:02 AM 29/07/2004, Peter Wilkinson wrote:
>>I would like to know some alternative to normalization for 2 channel 
>>experiments against universal, where samples may have been hybridized in 
>>seperate batches where the universal RNA has changed lot (should not have 
>>happened but it did). What is the same between the batches is that what 
>>looks like up-regulated compared to the universal iis upr-egulated, and 
>>what is down-regulated looks down-regulated. The difference is that the 
>>down-regulated (and not in the up), so so much more down-regulated in one 
>>of the batches. It looks like to be that the universal has more mRNA 
>>abundance in one batch over the other.
>
>Gquantile won't help because it doesn't change the M-values. (It is 
>intended for use with single channel analyses.) You could try 'quantile' 
>or 'scale' normalization (not both) but there are no magic bullets in a 
>situation like this. If you use 'scale normalization, you should always do 
>within-array normalization first. If you use 'quantile' normalization, the 
>within-array normalization step is optional.
>
>Gordon
>
>>so ...
>>
>>I have samples that can be divided into 2 classes: 0,1, and within each 
>>class I have samples that have been run at different times. I would like 
>>to treat my universal channel uniformly across all samples (assuming that 
>>my universal changed lot), and then adjust the Sample (Red) channel to that.
>>
>>is the normalizeBetweenArrays with the method="Gquantile" option the 
>>right option for this?
>>
>>What is the complete work-flow for this case? And after I have normalized 
>>within the Arrays, can I go on to scale option for normalizing between arrays.
>>
>>Peter



From andy_liaw at merck.com  Thu Jul 29 06:02:26 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 Jul 2004 00:02:26 -0400
Subject: [R] Parallel Functions on AIX
Message-ID: <3A822319EB35174CA3714066D590DCD504AF813E@usrymx25.merck.com>

> From: Brian Ripley
> 
> The first thing to ascertain is that R will actually build on such a 
> machine -- there have been a lot of reports of failure on AIX, and no 
> recent reports of success.

According to our AIX sysadmin, R-1.9.1 actually compiles a lot more cleanly
than R-1.8.1 and prior.  I take it the recent reports of difficulties has to
do with (possibly outdated) GCC.  We have no problem with xlc/xlf.

The trouble we're having is getting R to link against readline in 64-bit.
Haven't figure out how to do that yet.  Life w/o readline is rather
trying...

Andy

 
> If it does, R itself is single-threaded (but can make use of
> multi-threaded BLAS)  but packages such as Rmpi, snow, 
> RScaLAPACK provide 
> parallel facilities (and are in the FAQ).
> 
> On Wed, 28 Jul 2004, Liao, Kexiao wrote:
> 
> > Dear R Development Team,
> 
> You actually wrote to R-help!
> 
> >    Does the latest version R-1.9.1 provide parallel 
> functions if R is
> > running on Multiple CPUs Unix platform (IBM AIX e-server)?
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Thu Jul 29 06:08:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 Jul 2004 00:08:36 -0400
Subject: [R] RE: [S] tree function in R language
Message-ID: <3A822319EB35174CA3714066D590DCD504AF813F@usrymx25.merck.com>

1. Could it be that your computer is behind a firewall?  If so, try reading
the R for Windows FAQ.

2. Please ask R-related question on R-help instead of S-news.

Andy

> From: cheng wu 
> 
> Hi, Andy
> 
> Thank you for your answer.  
> 
> Why I can't load CRAN packages?
> 
> the error message is: 
> 
> > {a <- CRAN.packages()
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], 
> available=a)}
> trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> unable to connect to 'cran.r-project.org'.
> Error in download.file(url = paste(contriburl, "PACKAGES", 
> sep = "/"),  : 
>         cannot open URL 
> `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> 
> 
> 
> >From: "Chushu Gu" <chushugu at hotmail.com>
> >To: "cheng wu" <wu_cheng2001 at hotmail.com>
> >Subject: Fw: [S] tree function in R language
> >Date: Wed, 28 Jul 2004 09:14:48 -0400
> >
> >
> >----- Original Message -----
> >From: "Liaw, Andy" <andy_liaw at merck.com>
> >To: "'chushu Gu'" <chushugu at hotmail.com>; 
> <s-news at lists.biostat.wustl.edu>
> >Sent: Tuesday, July 27, 2004 11:22 PM
> >Subject: RE: [S] tree function in R language
> >
> >
> > > Have you read the (latest edition of the) book for which 
> the package 
> you
> >are
> > > using supports?  There are differences in S-PLUS and R 
> (and the 4th
> >edition
> > > of MASS supports both, thus ought to tell you this particular 
> difference
> > > between the two).  tree() in S-PLUS is written originally 
> by Clark and
> > > Pregibon.  If you want that functionality in R, you need 
> to load the
> >`tree'
> > > package (available on CRAN), which is an independent 
> implementation by 
> one
> > > of the co-authors of MASS.
> > >
> > > Another hint: Look in the `scripts' subdirectory of where 
> the `MASS'
> >package
> > > is installed.
> > >
> > > Andy
> > >
> > > > From: chushu Gu
> > > >
> > > > Hi all,
> > > >
> > > > I am using R 1.8.1, I have the following code,
> > > >
> > > > library(MASS)
> > > > data(iris)
> > > > ir.tr <- tree(Species ~., iris)
> > > > ir.tr
> > > > summary(ir.tr)
> > > >
> > > >
> > > > I got the following message:
> > > >
> > > > Error: couldn't find function "tree"
> > > >
> > > > I don't the reason, as I already load the library "MASS".
> > > >
> > > > Could anyone tell me the possible reasons?
> > > >
> > > > Thanks,
> > > >
> > > > Chushu Gu
> > > >
> > > > 
> _________________________________________________________________
> > > > 
> --------------------------------------------------------------------
> > > > This message was distributed by 
> s-news at lists.biostat.wustl.edu.  To
> > > > unsubscribe send e-mail to 
> s-news-request at lists.biostat.wustl.edu 
> with

> > > >
> > > >
> > >
> > >
> > > 
> --------------------------------------------------------------
> ------------
> >----
> > > Notice:  This e-mail message, together with any 
> attachments, contains
> >information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New
> >Jersey, USA 08889), and/or its affiliates (which may be 
> known outside the
> >United States as Merck Frosst, Merck Sharp & Dohme or MSD 
> and in Japan, as
> >Banyu) that may be confidential, proprietary copyrighted 
> and/or legally
> >privileged. It is intended solely for the use of the 
> individual or entity
> >named on this message.  If you are not the intended 
> recipient, and have
> >received this message in error, please notify us immediately 
> by reply 
> e-mail
> >and then delete it from your system.
> > > 
> --------------------------------------------------------------
> ------------
> >----
> > >
> 
> 
> 
>



From MSchwartz at MedAnalytics.com  Thu Jul 29 06:44:08 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 28 Jul 2004 23:44:08 -0500
Subject: [R] RE: [S] tree function in R language
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF813F@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF813F@usrymx25.merck.com>
Message-ID: <1091076248.23861.48.camel@localhost.localdomain>

Shouldn't the URL be (for R 1.8.1 on Windows):

http://cran.r-project.org/bin/windows/contrib/1.8/PACKAGES

There is no URL as listed below, which is presumably why the error
message.

Was options()$CRAN changed improperly or is there some other Windows
specific issue that is escaping me at the moment?

BTW, you should upgrade to R 1.9.1, as you are two versions behind at
this point.

HTH,

Marc Schwartz

On Wed, 2004-07-28 at 23:08, Liaw, Andy wrote:
> 1. Could it be that your computer is behind a firewall?  If so, try reading
> the R for Windows FAQ.
> 
> 2. Please ask R-related question on R-help instead of S-news.
> 
> Andy
> 
> > From: cheng wu 
> > 
> > Hi, Andy
> > 
> > Thank you for your answer.  
> > 
> > Why I can't load CRAN packages?
> > 
> > the error message is: 
> > 
> > > {a <- CRAN.packages()
> > + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], 
> > available=a)}
> > trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> > unable to connect to 'cran.r-project.org'.
> > Error in download.file(url = paste(contriburl, "PACKAGES", 
> > sep = "/"),  : 
> >         cannot open URL 
> > `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> > 
> > 
> > 
> > >From: "Chushu Gu" <chushugu at hotmail.com>
> > >To: "cheng wu" <wu_cheng2001 at hotmail.com>
> > >Subject: Fw: [S] tree function in R language
> > >Date: Wed, 28 Jul 2004 09:14:48 -0400
> > >
> > >
> > >----- Original Message -----
> > >From: "Liaw, Andy" <andy_liaw at merck.com>
> > >To: "'chushu Gu'" <chushugu at hotmail.com>; 
> > <s-news at lists.biostat.wustl.edu>
> > >Sent: Tuesday, July 27, 2004 11:22 PM
> > >Subject: RE: [S] tree function in R language
> > >
> > >
> > > > Have you read the (latest edition of the) book for which 
> > the package 
> > you
> > >are
> > > > using supports?  There are differences in S-PLUS and R 
> > (and the 4th
> > >edition
> > > > of MASS supports both, thus ought to tell you this particular 
> > difference
> > > > between the two).  tree() in S-PLUS is written originally 
> > by Clark and
> > > > Pregibon.  If you want that functionality in R, you need 
> > to load the
> > >`tree'
> > > > package (available on CRAN), which is an independent 
> > implementation by 
> > one
> > > > of the co-authors of MASS.
> > > >
> > > > Another hint: Look in the `scripts' subdirectory of where 
> > the `MASS'
> > >package
> > > > is installed.
> > > >
> > > > Andy
> > > >
> > > > > From: chushu Gu
> > > > >
> > > > > Hi all,
> > > > >
> > > > > I am using R 1.8.1, I have the following code,
> > > > >
> > > > > library(MASS)
> > > > > data(iris)
> > > > > ir.tr <- tree(Species ~., iris)
> > > > > ir.tr
> > > > > summary(ir.tr)
> > > > >
> > > > >
> > > > > I got the following message:
> > > > >
> > > > > Error: couldn't find function "tree"
> > > > >
> > > > > I don't the reason, as I already load the library "MASS".
> > > > >
> > > > > Could anyone tell me the possible reasons?
> > > > >
> > > > > Thanks,
> > > > >
> > > > > Chushu Gu



From kathryn.jones at jcu.edu.au  Thu Jul 29 07:06:43 2004
From: kathryn.jones at jcu.edu.au (Kathryn Jones)
Date: Thu, 29 Jul 2004 15:06:43 +1000
Subject: [R] attach files on start up
Message-ID: <4c7dca11.675449ab.81b3800@mirapoint-ms1.jcu.edu.au>

Hi,
I was wondering if anyone could please tell me if there's a 
way to attach the same files each time R starts up?
Thanks!
Kathryn Jones



From mrennie at utm.utoronto.ca  Thu Jul 29 07:57:02 2004
From: mrennie at utm.utoronto.ca (Michael Rennie)
Date: Thu, 29 Jul 2004 01:57:02 -0400
Subject: [R] extracting the t-statistic: just the numbers, please
Message-ID: <1091080622.410891ae72c05@webmail.utm.utoronto.ca>


Hi, there

I am quite sure there is an easy answer to this, but I am unsure how to gather 
a bunch of t-statistics in an organized format.

I am trying to generate a list of t-statistics for a randomization routine. If 
I try to collect a bunch of t-statistics from a run, this is what happens:


> M <- 10 ; simt <- NULL
> for(i in 1:M)
+     {
+    perm<-sample(site,replace=F)
+ 
+ permute<-cbind(perm, site, a, b, c)
+ 
+ m<- order(perm)
+ 
+ m1<-cbind(perm[m], site[m], a[m], b[m], c[m])
+ 
+ black<-c((m1[1:5,5]),(m1[11:15,5]))
+ #black
+ 
+ white<-c((m1[6:10,5]),(m1[16:20,5]))
+ #white
+ 
+ sims <- t.test(black,white,var.equal=FALSE,mu=0)$statistic
+ simt<-c(simt,sims)
+ #simt
+ } # Next i (next simulation)
> 
> simt
         t          t          t          t          t          t          t 
 0.3474150  0.1542973 -0.4044992  1.2466663 -0.2933944 -0.5809257  0.7799080 
         t          t          t 
-1.4132713  1.2048335 -0.6596936

Which gives me a list, but not in a form that I can do anything with. This is 
in stark contrast to what happens when requesting p-values, which gives output 
like this:



 M <- 10 ; simt <- NULL
> for(i in 1:M)
+     {
+    perm<-sample(site,replace=F)
+ 
+ permute<-cbind(perm, site, a, b, c)
+ 
+ m<- order(perm)
+ 
+ m1<-cbind(perm[m], site[m], a[m], b[m], c[m])
+ 
+ black<-c((m1[1:5,5]),(m1[11:15,5]))
+ #black
+ 
+ white<-c((m1[6:10,29]),(m1[16:20,5]))
+ #white
+ 
+ sims <- t.test(black,white,var.equal=FALSE,mu=0)$p.value
+ simt<-c(simt,sims)
+ #simt
+ } # Next i (next simulation)
> 
> simt
 [1] 0.6763749 0.7480091 0.9447851 0.3342029 0.7852635 0.3199006 0.5272153
 [8] 0.3863616 0.7333693 0.7268907

Now THAT'S what I'd like to get for my t-statistics- a nice vector (simt) that 
I can deal with later, rather than the output I am currently getting (the first 
output above).

Does anyone know a way to extract JUST the t-statistics from the t.test, 
without the "t" character header, so I can generate a nice little vector? 
Alternatively, can I manipulate the output I am currently getting for the t-
statistics so that I can isolate just the numbers? 

-- 
Michael Rennie
Ph.D. Candidate
University of Toronto at Mississauga
3359 Mississauga Rd. N.
Mississauga ON  L5L 1C6
Ph: 905-828-5452  Fax: 905-828-3792



From p.dalgaard at biostat.ku.dk  Thu Jul 29 08:02:54 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Jul 2004 08:02:54 +0200
Subject: [R] where is "average shifted histogram"?
In-Reply-To: <20040728214317.92936.qmail@web25208.mail.ukl.yahoo.com>
References: <20040728214317.92936.qmail@web25208.mail.ukl.yahoo.com>
Message-ID: <x2n01jpcz5.fsf@biostat.ku.dk>

Eckart Bindewald <eckart_bindewald at yahoo.de> writes:

> Hello!
> In the book Modern Applied Statistics with S (4th ed),
> section 5.6 the concept of the "average shifted
> histogram" or ASH is mentionend. Also it is mentioned
> in the same section "The code used is in the scripts
> for this chapter" (from figure caption 5.8, analysis
> of the geyser duration data).
> *However*, I have trouble finding the code for that
> function! Admittedly, I am a newby to R. Where exactly
> do I find the scripts to that chapter? Commands like
> library(MASS), or help.search("average shifted
> histogram") did not help.

The scripts are in simple files installed with the package. So you
need to go to the install directory and read them from there. A
canonical way of finding it from within R is

.path.package("MASS")
dir(file.path(.path.package("MASS"),scripts))
file.show(file.path(.path.package("MASS"),"scripts","ch05.R"))

That being said, I couldn't off-hand spot anything ASH-like in the
file. This might either be a difference between the R and S versions,
or just that the remark in the figure caption does not spefically  
relate to ASH (haven't got the book at hand just now). 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Thu Jul 29 08:16:50 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 29 Jul 2004 08:16:50 +0200
Subject: [R] RE: [S] tree function in R language
In-Reply-To: <1091076248.23861.48.camel@localhost.localdomain>
References: <3A822319EB35174CA3714066D590DCD504AF813F@usrymx25.merck.com>
	<1091076248.23861.48.camel@localhost.localdomain>
Message-ID: <41089652.6060507@statistik.uni-dortmund.de>

Marc Schwartz wrote:
> Shouldn't the URL be (for R 1.8.1 on Windows):
> 
> http://cran.r-project.org/bin/windows/contrib/1.8/PACKAGES
> 
> There is no URL as listed below, which is presumably why the error
> message.

The URL geven below indicates that the code in the base package is R <= 
1.6.x. These outdated versions are not supported any more.

Uwe Ligges

> Was options()$CRAN changed improperly or is there some other Windows
> specific issue that is escaping me at the moment?
> 
> BTW, you should upgrade to R 1.9.1, as you are two versions behind at
> this point.
> 
> HTH,
> 
> Marc Schwartz
> 
> On Wed, 2004-07-28 at 23:08, Liaw, Andy wrote:
> 
>>1. Could it be that your computer is behind a firewall?  If so, try reading
>>the R for Windows FAQ.
>>
>>2. Please ask R-related question on R-help instead of S-news.
>>
>>Andy
>>
>>
>>>From: cheng wu 
>>>
>>>Hi, Andy
>>>
>>>Thank you for your answer.  
>>>
>>>Why I can't load CRAN packages?
>>>
>>>the error message is: 
>>>
>>>
>>>>{a <- CRAN.packages()
>>>
>>>+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], 
>>>available=a)}
>>>trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
>>>unable to connect to 'cran.r-project.org'.
>>>Error in download.file(url = paste(contriburl, "PACKAGES", 
>>>sep = "/"),  : 
>>>        cannot open URL 
>>>`http://cran.r-project.org/bin/windows/contrib/PACKAGES'
>>>
>>>
>>>
>>>
>>>>From: "Chushu Gu" <chushugu at hotmail.com>
>>>>To: "cheng wu" <wu_cheng2001 at hotmail.com>
>>>>Subject: Fw: [S] tree function in R language
>>>>Date: Wed, 28 Jul 2004 09:14:48 -0400
>>>>
>>>>
>>>>----- Original Message -----
>>>>From: "Liaw, Andy" <andy_liaw at merck.com>
>>>>To: "'chushu Gu'" <chushugu at hotmail.com>; 
>>>
>>><s-news at lists.biostat.wustl.edu>
>>>
>>>>Sent: Tuesday, July 27, 2004 11:22 PM
>>>>Subject: RE: [S] tree function in R language
>>>>
>>>>
>>>>
>>>>>Have you read the (latest edition of the) book for which 
>>>
>>>the package 
>>>you
>>>
>>>>are
>>>>
>>>>>using supports?  There are differences in S-PLUS and R 
>>>
>>>(and the 4th
>>>
>>>>edition
>>>>
>>>>>of MASS supports both, thus ought to tell you this particular 
>>>
>>>difference
>>>
>>>>>between the two).  tree() in S-PLUS is written originally 
>>>
>>>by Clark and
>>>
>>>>>Pregibon.  If you want that functionality in R, you need 
>>>
>>>to load the
>>>
>>>>`tree'
>>>>
>>>>>package (available on CRAN), which is an independent 
>>>
>>>implementation by 
>>>one
>>>
>>>>>of the co-authors of MASS.
>>>>>
>>>>>Another hint: Look in the `scripts' subdirectory of where 
>>>
>>>the `MASS'
>>>
>>>>package
>>>>
>>>>>is installed.
>>>>>
>>>>>Andy
>>>>>
>>>>>
>>>>>>From: chushu Gu
>>>>>>
>>>>>>Hi all,
>>>>>>
>>>>>>I am using R 1.8.1, I have the following code,
>>>>>>
>>>>>>library(MASS)
>>>>>>data(iris)
>>>>>>ir.tr <- tree(Species ~., iris)
>>>>>>ir.tr
>>>>>>summary(ir.tr)
>>>>>>
>>>>>>
>>>>>>I got the following message:
>>>>>>
>>>>>>Error: couldn't find function "tree"
>>>>>>
>>>>>>I don't the reason, as I already load the library "MASS".
>>>>>>
>>>>>>Could anyone tell me the possible reasons?
>>>>>>
>>>>>>Thanks,
>>>>>>
>>>>>>Chushu Gu
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ozric at web.de  Thu Jul 29 08:19:23 2004
From: ozric at web.de (Christian Schulz)
Date: Thu, 29 Jul 2004 08:19:23 +0200
Subject: [R] extracting the t-statistic: just the numbers, please
In-Reply-To: <1091080622.410891ae72c05@webmail.utm.utoronto.ca>
References: <1091080622.410891ae72c05@webmail.utm.utoronto.ca>
Message-ID: <200407290819.24154.ozric@web.de>

>	data(sleep)
>      t.test(extra ~ group, data = sleep)$statistic[1]
        t
-1.860813
>      t.test(extra ~ group, data = sleep)$statistic[[1]]
[1] -1.860813

hope this helps,
christian


Am Donnerstag, 29. Juli 2004 07:57 schrieb Michael Rennie:
> Hi, there
>
> I am quite sure there is an easy answer to this, but I am unsure how to
> gather a bunch of t-statistics in an organized format.
>
> I am trying to generate a list of t-statistics for a randomization routine.
> If
>
> I try to collect a bunch of t-statistics from a run, this is what happens:
> > M <- 10 ; simt <- NULL
> > for(i in 1:M)
>
> +     {
> +    perm<-sample(site,replace=F)
> +
> + permute<-cbind(perm, site, a, b, c)
> +
> + m<- order(perm)
> +
> + m1<-cbind(perm[m], site[m], a[m], b[m], c[m])
> +
> + black<-c((m1[1:5,5]),(m1[11:15,5]))
> + #black
> +
> + white<-c((m1[6:10,5]),(m1[16:20,5]))
> + #white
> +
> + sims <- t.test(black,white,var.equal=FALSE,mu=0)$statistic
> + simt<-c(simt,sims)
> + #simt
> + } # Next i (next simulation)
>
> > simt
>
>          t          t          t          t          t          t         
> t 0.3474150  0.1542973 -0.4044992  1.2466663 -0.2933944 -0.5809257 
> 0.7799080 t          t          t
> -1.4132713  1.2048335 -0.6596936
>
> Which gives me a list, but not in a form that I can do anything with. This
> is in stark contrast to what happens when requesting p-values, which gives
> output like this:
>
>
>
>  M <- 10 ; simt <- NULL
>
> > for(i in 1:M)
>
> +     {
> +    perm<-sample(site,replace=F)
> +
> + permute<-cbind(perm, site, a, b, c)
> +
> + m<- order(perm)
> +
> + m1<-cbind(perm[m], site[m], a[m], b[m], c[m])
> +
> + black<-c((m1[1:5,5]),(m1[11:15,5]))
> + #black
> +
> + white<-c((m1[6:10,29]),(m1[16:20,5]))
> + #white
> +
> + sims <- t.test(black,white,var.equal=FALSE,mu=0)$p.value
> + simt<-c(simt,sims)
> + #simt
> + } # Next i (next simulation)
>
> > simt
>
>  [1] 0.6763749 0.7480091 0.9447851 0.3342029 0.7852635 0.3199006 0.5272153
>  [8] 0.3863616 0.7333693 0.7268907
>
> Now THAT'S what I'd like to get for my t-statistics- a nice vector (simt)
> that I can deal with later, rather than the output I am currently getting
> (the first output above).
>
> Does anyone know a way to extract JUST the t-statistics from the t.test,
> without the "t" character header, so I can generate a nice little vector?
> Alternatively, can I manipulate the output I am currently getting for the
> t- statistics so that I can isolate just the numbers?



From spencer.graves at pdf.com  Thu Jul 29 08:20:58 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 28 Jul 2004 23:20:58 -0700
Subject: [R] extracting the t-statistic: just the numbers, please
In-Reply-To: <1091080622.410891ae72c05@webmail.utm.utoronto.ca>
References: <1091080622.410891ae72c05@webmail.utm.utoronto.ca>
Message-ID: <4108974A.1020900@pdf.com>

      The function "as.vector" will remove the names: 

 > t.test(1:9)$statistic
       t
5.477226
 > as.vector(t.test(1:9)$statistic)
[1] 5.477226

      Is this what you want?  spencer graves

Michael Rennie wrote:

>Hi, there
>
>I am quite sure there is an easy answer to this, but I am unsure how to gather 
>a bunch of t-statistics in an organized format.
>
>I am trying to generate a list of t-statistics for a randomization routine. If 
>I try to collect a bunch of t-statistics from a run, this is what happens:
>
>
>  
>
>>M <- 10 ; simt <- NULL
>>for(i in 1:M)
>>    
>>
>+     {
>+    perm<-sample(site,replace=F)
>+ 
>+ permute<-cbind(perm, site, a, b, c)
>+ 
>+ m<- order(perm)
>+ 
>+ m1<-cbind(perm[m], site[m], a[m], b[m], c[m])
>+ 
>+ black<-c((m1[1:5,5]),(m1[11:15,5]))
>+ #black
>+ 
>+ white<-c((m1[6:10,5]),(m1[16:20,5]))
>+ #white
>+ 
>+ sims <- t.test(black,white,var.equal=FALSE,mu=0)$statistic
>+ simt<-c(simt,sims)
>+ #simt
>+ } # Next i (next simulation)
>  
>
>>simt
>>    
>>
>         t          t          t          t          t          t          t 
> 0.3474150  0.1542973 -0.4044992  1.2466663 -0.2933944 -0.5809257  0.7799080 
>         t          t          t 
>-1.4132713  1.2048335 -0.6596936
>
>Which gives me a list, but not in a form that I can do anything with. This is 
>in stark contrast to what happens when requesting p-values, which gives output 
>like this:
>
>
>
> M <- 10 ; simt <- NULL
>  
>
>>for(i in 1:M)
>>    
>>
>+     {
>+    perm<-sample(site,replace=F)
>+ 
>+ permute<-cbind(perm, site, a, b, c)
>+ 
>+ m<- order(perm)
>+ 
>+ m1<-cbind(perm[m], site[m], a[m], b[m], c[m])
>+ 
>+ black<-c((m1[1:5,5]),(m1[11:15,5]))
>+ #black
>+ 
>+ white<-c((m1[6:10,29]),(m1[16:20,5]))
>+ #white
>+ 
>+ sims <- t.test(black,white,var.equal=FALSE,mu=0)$p.value
>+ simt<-c(simt,sims)
>+ #simt
>+ } # Next i (next simulation)
>  
>
>>simt
>>    
>>
> [1] 0.6763749 0.7480091 0.9447851 0.3342029 0.7852635 0.3199006 0.5272153
> [8] 0.3863616 0.7333693 0.7268907
>
>Now THAT'S what I'd like to get for my t-statistics- a nice vector (simt) that 
>I can deal with later, rather than the output I am currently getting (the first 
>output above).
>
>Does anyone know a way to extract JUST the t-statistics from the t.test, 
>without the "t" character header, so I can generate a nice little vector? 
>Alternatively, can I manipulate the output I am currently getting for the t-
>statistics so that I can isolate just the numbers? 
>
>  
>



From p.dalgaard at biostat.ku.dk  Thu Jul 29 08:31:16 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Jul 2004 08:31:16 +0200
Subject: [R] extracting the t-statistic: just the numbers, please
In-Reply-To: <1091080622.410891ae72c05@webmail.utm.utoronto.ca>
References: <1091080622.410891ae72c05@webmail.utm.utoronto.ca>
Message-ID: <x2isc7pbnv.fsf@biostat.ku.dk>

Michael Rennie <mrennie at utm.utoronto.ca> writes:

> > simt
>          t          t          t          t          t          t          t 
>  0.3474150  0.1542973 -0.4044992  1.2466663 -0.2933944 -0.5809257  0.7799080 
>          t          t          t 
> -1.4132713  1.2048335 -0.6596936
> 
> Which gives me a list, but not in a form that I can do anything with. This is 
> in stark contrast to what happens when requesting p-values, which gives output 
> like this:

..

> > simt
>  [1] 0.6763749 0.7480091 0.9447851 0.3342029 0.7852635 0.3199006 0.5272153
>  [8] 0.3863616 0.7333693 0.7268907
> 
> Now THAT'S what I'd like to get for my t-statistics- a nice vector (simt) that 
> I can deal with later, rather than the output I am currently getting (the first 
> output above).
> 
> Does anyone know a way to extract JUST the t-statistics from the t.test, 
> without the "t" character header, so I can generate a nice little vector? 
> Alternatively, can I manipulate the output I am currently getting for the t-
> statistics so that I can isolate just the numbers? 

It *is* a nice little vector! It's just that it has names. 

names(simt) <- NULL 

gets rid of them. 

BTW, simt <- c(simt, sims) is going to kill performance with large repeat
counts since it copies all previous results every time around.
Preallocate the result, or consider using replicate() or sapply().

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Thu Jul 29 08:37:20 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 29 Jul 2004 08:37:20 +0200
Subject: [R] attach files on start up
In-Reply-To: <4c7dca11.675449ab.81b3800@mirapoint-ms1.jcu.edu.au>
References: <4c7dca11.675449ab.81b3800@mirapoint-ms1.jcu.edu.au>
Message-ID: <41089B20.9000906@statistik.uni-dortmund.de>

Kathryn Jones wrote:

> Hi,
> I was wondering if anyone could please tell me if there's a 
> way to attach the same files each time R starts up?

See ?Startup

Uwe Ligges


> Thanks!
> Kathryn Jones
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Thu Jul 29 09:32:17 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Jul 2004 09:32:17 +0200
Subject: [R] where is "average shifted histogram"?
In-Reply-To: <x2n01jpcz5.fsf@biostat.ku.dk>
References: <20040728214317.92936.qmail@web25208.mail.ukl.yahoo.com>
	<x2n01jpcz5.fsf@biostat.ku.dk>
Message-ID: <16648.43009.380873.917574@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>     on 29 Jul 2004 08:02:54 +0200 writes:

    PD> Eckart Bindewald <eckart_bindewald at yahoo.de> writes:
    >> Hello!  In the book Modern Applied Statistics with S (4th
    >> ed), section 5.6 the concept of the "average shifted
    >> histogram" or ASH is mentionend. Also it is mentioned in
    >> the same section "The code used is in the scripts for
    >> this chapter" (from figure caption 5.8, analysis of the
    >> geyser duration data).  *However*, I have trouble finding
    >> the code for that function! Admittedly, I am a newby to
    >> R. Where exactly do I find the scripts to that chapter?
    >> Commands like library(MASS), or help.search("average
    >> shifted histogram") did not help.

    PD> The scripts are in simple files installed with the
    PD> package. So you need to go to the install directory and
    PD> read them from there. A canonical way of finding it from
    PD> within R is

    PD> .path.package("MASS")

which requires that "MASS" has been attached {as by library()}.

    PD> dir(file.path(.path.package("MASS"),scripts))
    PD> file.show(file.path(.path.package("MASS"),"scripts","ch05.R"))

eehm, as the "." in ".path.package()" suggests, there should be
a more canonical way --- and there is, using system.file() :

 dir(system.file("scripts", package = "MASS"))

 ## [1] "ch01.R" "ch02.R" "ch03.R" "ch04.R" "ch05.R" "ch06.R" "ch07.R" "ch08.R"
 ## [9] "ch09.R" "ch10.R" "ch11.R" "ch12.R" "ch13.R" "ch14.R" "ch15.R" "ch16.R"
 ##[17] "README"

 file.show(system.file(file.path("scripts","ch05.R"), package = "MASS"))


--
Martin



From ripley at stats.ox.ac.uk  Thu Jul 29 09:38:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jul 2004 08:38:23 +0100 (BST)
Subject: [R] Transparent backgrounds in png files
In-Reply-To: <20040729095926.W11533@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.44.0407290835410.1679-100000@gannet.stats>

The bitmap() device does not support transparency.  The png() device does.

On Thu, 29 Jul 2004, Patrick Connolly wrote:

> The result I'm aiming to achieve is a bitmap that can be imported into
> a PowerPoint file that shows what's behind the lines of the plot.
> There's a way in PowerPoint that almost works.  By choosing a colour
> to set as transparent, what is behind the graphic is indeed visible,
> but it's at the expense of losing line and text definition.
> 
> I notice there have been discussions about transparent backgrounds
> mostly with lattice plots.  The problem most people seem to have was
> getting a blue background when they wanted a white one.
> 
> Mine is the reverse (and I'm using standard graphics, not Lattice).
> I'm trying to get a transparent background but it always comes out
> white.  Setting bg = "transparent", I've tried using a bitmap device
> to create a png file.  I've also tried creating a postscript file and
> converting it to a PNG file using the Gimp.  I've always used a
> resolution of 300 dpi in bitmaps since the default is far too low.

Really?  You want PNG files of 2000+ pixels in each dimension?  (The
standard size of an R plot is 7", and at 72dpi that is a reasonable size
for on-screen use -- and you should not really be using bitmapped files
for other uses.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Thu Jul 29 09:42:21 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Jul 2004 09:42:21 +0200
Subject: [R] readline or not .. {was "Parallel Functions on AIX"}
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF813E@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF813E@usrymx25.merck.com>
Message-ID: <16648.43613.118017.837920@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Thu, 29 Jul 2004 00:02:26 -0400 writes:

    >> From: Brian Ripley
    >> 
    >> The first thing to ascertain is that R will actually
    >> build on such a machine -- there have been a lot of
    >> reports of failure on AIX, and no recent reports of
    >> success.

    AndyL> According to our AIX sysadmin, R-1.9.1 actually
    AndyL> compiles a lot more cleanly than R-1.8.1 and prior.
    AndyL> I take it the recent reports of difficulties has to
    AndyL> do with (possibly outdated) GCC.  We have no problem
    AndyL> with xlc/xlf.

    AndyL> The trouble we're having is getting R to link against
    AndyL> readline in 64-bit.  Haven't figure out how to do
    AndyL> that yet.  Life w/o readline is rather trying...

well, all ESS users work without readline,
and I think we would find life w/o ESS much more trying...

In other words, using ESS (Emacs Speaks Statistics) gives is you
everything and much more than readline {but it does give some of
it somewhat differently!}

Martin



From ripley at stats.ox.ac.uk  Thu Jul 29 09:59:04 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jul 2004 08:59:04 +0100 (BST)
Subject: [R] where is "average shifted histogram"?
In-Reply-To: <x2n01jpcz5.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0407290854250.1679-100000@gannet.stats>

On 29 Jul 2004, Peter Dalgaard wrote:

> Eckart Bindewald <eckart_bindewald at yahoo.de> writes:
> 
> > Hello!
> > In the book Modern Applied Statistics with S (4th ed),
> > section 5.6 the concept of the "average shifted
> > histogram" or ASH is mentionend. Also it is mentioned
> > in the same section "The code used is in the scripts
> > for this chapter" (from figure caption 5.8, analysis
> > of the geyser duration data).
> > *However*, I have trouble finding the code for that
> > function! Admittedly, I am a newby to R. Where exactly
> > do I find the scripts to that chapter? Commands like
> > library(MASS), or help.search("average shifted
> > histogram") did not help.
> 
> The scripts are in simple files installed with the package. So you
> need to go to the install directory and read them from there. A
> canonical way of finding it from within R is
> 
> .path.package("MASS")
> dir(file.path(.path.package("MASS"),scripts))
> file.show(file.path(.path.package("MASS"),"scripts","ch05.R"))
> 
> That being said, I couldn't off-hand spot anything ASH-like in the
> file. This might either be a difference between the R and S versions,
> or just that the remark in the figure caption does not spefically  
> relate to ASH (haven't got the book at hand just now). 

It's in the MASS3 script but not the MASS4 one.  So look in 

file.show(system.file("scripts3", "ch05.R", package = "MASS"))

at the top of section 5.6.  It is done by hand.  There is a simple 
function to do so in package ash (on CRAN), but really you should be using 
kernel methods as described in the book.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Jul 29 10:24:42 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Jul 2004 10:24:42 +0200
Subject: [R] where is "average shifted histogram"?
In-Reply-To: <16648.43009.380873.917574@gargle.gargle.HOWL>
References: <20040728214317.92936.qmail@web25208.mail.ukl.yahoo.com>
	<x2n01jpcz5.fsf@biostat.ku.dk>
	<16648.43009.380873.917574@gargle.gargle.HOWL>
Message-ID: <x21xivkyph.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

>     PD> file.show(file.path(.path.package("MASS"),"scripts","ch05.R"))
> 
> eehm, as the "." in ".path.package()" suggests, there should be
> a more canonical way --- and there is, using system.file() :
> 
>  dir(system.file("scripts", package = "MASS"))

Drats! Forgot about that completely. As a feeble defense, they don't
quite do the same thing if there are multiple versions of a package
installed though. (system.file gives all of them, .path.package only
loaded packages).

Not that I remembered to check the help pages either, but we should
probably add something to the "See Also" on bothe of them. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ernesto at ipimar.pt  Thu Jul 29 11:33:09 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 29 Jul 2004 10:33:09 +0100
Subject: [R] How to add an object to an RData file ?
In-Reply-To: <Pine.A41.4.58.0407281206570.88732@homer07.u.washington.edu>
References: <3A822319EB35174CA3714066D590DCD504AF813A@usrymx25.merck.com>
	<Pine.A41.4.58.0407281206570.88732@homer07.u.washington.edu>
Message-ID: <1091093589.1340.3.camel@gandalf.local>

On Wed, 2004-07-28 at 20:07, Thomas Lumley wrote:
> On Wed, 28 Jul 2004, Liaw, Andy wrote:
> 
> > I guess it would be nice if save() has an `append' option...
> 
> It would still have to read it in and out again, and then we would have
> all the issues about multiple objects with the same name.
> 
> 	-thomas
> 

Hi,

The best way is to write my own function "append" with the small code
I've inserted in my original message. Any ideas how to make it more
interesting (checking if another object with the same name exists ?) and
...

Thanks

EJ



From bcutayar at lfdj.com  Thu Jul 29 11:43:13 2004
From: bcutayar at lfdj.com (Bruno Cutayar)
Date: Thu, 29 Jul 2004 11:43:13 +0200
Subject: [R] 2 questions : format and hh:mm
Message-ID: <200407290943.LAA04040@bombardier2.lfdj.com>



Dear R-users,
i have two questions :

1- first of all, i wish to know the way to obtain a serie with a format 
like "00" : ( "01","02","03","04"....) or like postal code 
("01100","02222").
for instance, i do :
 > format(strptime(as.character(c(1:4)),"%H"),"%H")
but it sounds complicate and not really efficient....!

 2- i search to generate a serie of hours and minutes on 24h :
"00:00" , "00:01", "00:02", "00:03", ...,...,  "23:59"
for instance, i do :
 > x <- format( strptime (as.character(rep(0:23,each=60)),"%H"),"%H")
 > y <- format( strptime (as.character(rep(0:59,24)),"%M"),"%M")
 > paste (x,y,sep=":")
it works but is it an another way to obtain this ?

thanks
Bruno





Si vous n'etes pas destinataires de ce message, merci d'avertir l'expediteur de l'erreur de distribution et de le detruire immediatement.
Ce message contient des informations confidentielles ou appartenant a La Francaise des Jeux. Il est etabli a l'intention exclusive de ses destinataires. Toute divulgation, utilisation, diffusion ou reproduction (totale ou partielle) de ce message ou des informations qu'il contient, doit etre prealablement autorisee.
Tout message electronique est susceptible d'alteration et son integrite ne peut etre assuree. La Francaise des Jeux decline toute responsabilite au titre de ce message s'il a ete modifie ou falsifie.

If you are not the intended recipient of this e-mail, please notify the sender of the wrong delivery and delete it immediately from your system.
This e-mail contains confidential information or information belonging to La Francaise des Jeux and is intended solely for the addressees. The unauthorised disclosure, use, dissemination or copying (either whole or partial) of this e-mail, or any information it contains, is prohibited.
E-mails are susceptible to alteration and their integrity cannot be guaranteed. La Francaise des Jeux shall not be liable for this e-mail if modified or falsified.



From jacques.veslot at cirad.fr  Thu Jul 29 12:02:50 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Thu, 29 Jul 2004 14:02:50 +0400
Subject: [R] 2 questions : format and hh:mm
In-Reply-To: <200407290943.LAA04040@bombardier2.lfdj.com>
Message-ID: <HHEDKBCGCMDOHEDELFBCIEELCBAA.jacques.veslot@cirad.fr>


in order to generate your series, maybe :
> format(seq(ISOdate(2003,1,1, 0, 0, 0, tz=""), by="min",
length=1440),format="%H:%M")

jacques
-----Message d'origine-----
De : r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]De la part de Bruno Cutayar
Envoy?? : jeudi 29 juillet 2004 13:43
?? : r-help at stat.math.ethz.ch
Objet : [R] 2 questions : format and hh:mm




Dear R-users,
i have two questions :

1- first of all, i wish to know the way to obtain a serie with a format
like "00" : ( "01","02","03","04"....) or like postal code
("01100","02222").
for instance, i do :
 > format(strptime(as.character(c(1:4)),"%H"),"%H")
but it sounds complicate and not really efficient....!

 2- i search to generate a serie of hours and minutes on 24h :
"00:00" , "00:01", "00:02", "00:03", ...,...,  "23:59"
for instance, i do :
 > x <- format( strptime (as.character(rep(0:23,each=60)),"%H"),"%H")
 > y <- format( strptime (as.character(rep(0:59,24)),"%M"),"%M")
 > paste (x,y,sep=":")
it works but is it an another way to obtain this ?

thanks
Bruno





Si vous n'etes pas destinataires de ce message, merci d'avertir l'expediteur
de l'erreur de distribution et de le detruire immediatement.
Ce message contient des informations confidentielles ou appartenant a La
Francaise des Jeux. Il est etabli a l'intention exclusive de ses
destinataires. Toute divulgation, utilisation, diffusion ou reproduction
(totale ou partielle) de ce message ou des informations qu'il contient, doit
etre prealablement autorisee.
Tout message electronique est susceptible d'alteration et son integrite ne
peut etre assuree. La Francaise des Jeux decline toute responsabilite au
titre de ce message s'il a ete modifie ou falsifie.

If you are not the intended recipient of this e-mail, please notify the
sender of the wrong delivery and delete it immediately from your system.
This e-mail contains confidential information or information belonging to La
Francaise des Jeux and is intended solely for the addressees. The
unauthorised disclosure, use, dissemination or copying (either whole or
partial) of this e-mail, or any information it contains, is prohibited.
E-mails are susceptible to alteration and their integrity cannot be
guaranteed. La Francaise des Jeux shall not be liable for this e-mail if
modified or falsified.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

-----------------------------------------------------
CIRAD 3P Reunion - MailScanner - NO VIRUS found
-----------------------------------------------------


-----------------------------------------------------
CIRAD 3P Reunion - MailScanner - NO VIRUS found



From ripley at stats.ox.ac.uk  Thu Jul 29 12:22:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jul 2004 11:22:30 +0100 (BST)
Subject: [R] 2 questions : format and hh:mm
In-Reply-To: <200407290943.LAA04040@bombardier2.lfdj.com>
Message-ID: <Pine.LNX.4.44.0407291113560.7847-100000@gannet.stats>

On Thu, 29 Jul 2004, Bruno Cutayar wrote:

> 
> 
> Dear R-users,
> i have two questions :
> 
> 1- first of all, i wish to know the way to obtain a serie with a format 
> like "00" : ( "01","02","03","04"....) or like postal code 
> ("01100","02222").
> for instance, i do :
>  > format(strptime(as.character(c(1:4)),"%H"),"%H")
> but it sounds complicate and not really efficient....!

It is not clear what you want to do here.  If you want to format numbers 
including leading zeros, see ?sprintf or ?formatC. e.g. 
> formatC(1:4, width=2, flag="0")
[1] "01" "02" "03" "04"

>  2- i search to generate a serie of hours and minutes on 24h :
> "00:00" , "00:01", "00:02", "00:03", ...,...,  "23:59"
> for instance, i do :
>  > x <- format( strptime (as.character(rep(0:23,each=60)),"%H"),"%H")
>  > y <- format( strptime (as.character(rep(0:59,24)),"%M"),"%M")
>  > paste (x,y,sep=":")
> it works but is it an another way to obtain this ?

See ?seq.POSIXt.  E.g.

base <- trunc(Sys.time(), "days") # midnight last night
x <- seq(base, base+86400-59, by="mins")
format(x, "%H:%M")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mayeul.kauffmann at tiscali.fr  Thu Jul 29 12:38:35 2004
From: mayeul.kauffmann at tiscali.fr (Mayeul KAUFFMANN)
Date: Thu, 29 Jul 2004 12:38:35 +0200
Subject: [R] proximity covariate to model dependence in cox model (question
	from Vito Muggeo)
Message-ID: <002101c47558$355325f0$3a7d9a53@amd>

(I received a messsage from Vito Muggeo [who sometimes posts here] about
my previous posts here. Thus, it might be of interest here)

> dear Mayeul,
> I read your post on R -list about survival analysis with multiple (two
if I
> am not right) events  per subject.


Sometimes subjetcs have even 3 events (i.e. civil wars for last 40
years)


> 1)How did you calculate the pxcw variable?
(Note: pxcm stands for ProXimity.of.lastCivil.War)

the answer is at
https://www.stat.math.ethz.ch/pipermail/r-help/2004-July/053556.html
after the words "I used fit$loglik to chose a.chosen.parameter from 8
values, for 3 types of events:"

I used (exp(-days.since.event.of.type.one/a1)), which gives an indicator
between 1 and 0 that falls quickly first then more slowly (see the end of
the above post,  053556.html)

Simply only use  event.of.type.one. I am not doing a competing risk
analysis: I am only counting one type of event (type.one), but the
covariates measure other events that may increase the risk.

The difficulty is to choose the good a1 parameter. You will typically need
values much lower than mine with your exapmle dataset.

It then become:

la<-c(263.5, 526.9,1053.9,2107.8,4215.6,8431.1) #list of values to choose.
Adapt it
from
z<-NULL;for(a1 in la) {coxtmp <-
(coxph(Surv(start,stop,status)~
+I(exp(-days.since.event.of.type.one/a1))
+ other.time.dependent.covariates
+cluster(id)
,data=x,robust=T))
rbind(z,c(a1,coxtmp$wald.test, coxtmp$rscore, coxtmp$loglik,
coxtmp$score))->z
}
z <- data.frame(z)
names(z) <- c("a1","wald.test", "rscore",
"NULLloglik","loglik", "score")
z[which.max(z$rscore),]
z[which.max(z$loglik),]


> Namely, for instance,given the following data set (standard in multiple
> event formulation):
> > data.frame(id=c(3,3,4,4,5),start=c(0,10,0,7,0),stop=c(10,15,7,20,9),
> + event=c(1,1,1,0,0),stratum=c(1,2,1,2,1))
>   id start stop event stratum
> 1  3     0   10     1       1
> 2  3    10   15     1       2
> 3  4     0    7     1       1
> 4  4     7   20     0       2
> 5  5     0    9     0       1
> how the pxcw variable is computed for each *row* in the dataset?
> should be something like "ifelse(stratum==1,0,(stop-start))", i.e.
> (0,5,0,13,0) , or am I wrong?

It looks computationnaly OK, but strange to me.You can choose the function
that matches best the dependence, maybe it is.
But, assuming risk jumps just after an event then decreases slowly , I
would rather use a very high value when there is no previous event, for
instance:
ifelse(stratum==1,100,(stop-start))
Otherwise, a very close event (yesterday) would nearly be coded like no
previous event!
or even better, truncate the decrease :
ifelse(stratum==1,100,ifelse(stop-start>100, 100,stop-start ))
Here, after 100 days, it is like having no previous event.

But you should divide your observations to account for the change in the
proximity variable.
Instead of:
> id start stop event stratum   proxim
> 4     0    7     1       1    100
> 4     7   20     0       2    13

use

> id start stop event stratum   proxim
> 4     0    7     1       1    100
> 4     7    8     0       2    1
> 4     8    9     0       2    2
.
.
> 4     19   20    0       2    13

With the function I used, I used a covariate (days.since.event) which was
coded 9999999 if no previous event, I need:
exp((-days.since.event)/a1)



> Is this a your idea or did you find it elsewhere? could you give me any
> reference?

The proximity covariate is from
http://www.worldbank.org/research/conflict/papers/CivilPeace.pdf

(But they do not use the counting process we use here. They only measure
covariates for all countries when one country experiments an event.
Thus, all the remaining is mine (I think))


>
> Hope you can help me,
> regards,
> vito
>



From m.g.walker at massey.ac.nz  Thu Jul 29 12:53:47 2004
From: m.g.walker at massey.ac.nz (Matthew Walker)
Date: Thu, 29 Jul 2004 22:53:47 +1200
Subject: [R] Lattice graphics: adding lines to a plot
Message-ID: <4108D73B.8010604@massey.ac.nz>

I am trying to use the Lattice package to produce the same result as I 
can with the base graphics.

With base graphics I can type:

x <- 1:100
y <- x+rnorm(length(x))
g <- lm( y ~ x )
model.y <- g$coef[1]+g$coef[2]*x

plot(x,y)   # a plot of the data
lines( x, model.y )   # a plot of the model, superimposed on the first plot


With Lattice graphics I've got this far:

library(lattice)
plot1 <- xyplot(y ~ x)
plot2 <- xyplot(model.y ~ x, panel = function(x, y) { llines(x=x, y=y) })
print(plot1, more=TRUE, position=c(0,0.5,1,1))
print(plot2, position=c(0,0,1,0.5))

But this just produces two graphs, one above the other.  How do I 
overlay them?  What should I be doing in order to get the same result as 
with the base graphics?

Thank you for your thoughts,

Matthew Walker



From bioc at gunnarwrobel.de  Thu Jul 29 13:36:34 2004
From: bioc at gunnarwrobel.de (Gunnar Wrobel)
Date: Thu, 29 Jul 2004 13:36:34 +0200
Subject: [R] Debug S4 Methods
Message-ID: <4108E142.2040808@gunnarwrobel.de>

Dear list,

is there any way to debug the S4 methods using the debug() function in 
R1.9.1?

I am able to use browser() inside a S4 method but I wondered if there is 
a way to debug the function without recompiling the package.

Thanks!

Gunnar

-- 
----------------------------------------------
Dr. Gunnar Wrobel

Divisions of Bioinformatics and Biochemistry
Swiss Institute of Bioinformatics/Biozentrum
Klingelbergstrasse 50/70
CH-4056 Basel / Switzerland
Tel.: +41 61 267 1579
Fax:  +41 61 267 3398
e-mail: work at gunnarwrobel.de
e-mail: gunnar.wrobel at unibas.ch



From ccleland at optonline.net  Thu Jul 29 13:37:46 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 29 Jul 2004 07:37:46 -0400
Subject: [R] Lattice graphics: adding lines to a plot
In-Reply-To: <4108D73B.8010604@massey.ac.nz>
References: <4108D73B.8010604@massey.ac.nz>
Message-ID: <4108E18A.8050100@optonline.net>

How about this?

library(lattice)
xyplot(y ~ x, panel = function(x, y, ...){
                                panel.xyplot(x, y, ...)
                                panel.lmline(x, y, type="l")
                                })

Matthew Walker wrote:
> I am trying to use the Lattice package to produce the same result as I 
> can with the base graphics.
> 
> With base graphics I can type:
> 
> x <- 1:100
> y <- x+rnorm(length(x))
> g <- lm( y ~ x )
> model.y <- g$coef[1]+g$coef[2]*x
> 
> plot(x,y)   # a plot of the data
> lines( x, model.y )   # a plot of the model, superimposed on the first plot
> 
> 
> With Lattice graphics I've got this far:
> 
> library(lattice)
> plot1 <- xyplot(y ~ x)
> plot2 <- xyplot(model.y ~ x, panel = function(x, y) { llines(x=x, y=y) })
> print(plot1, more=TRUE, position=c(0,0.5,1,1))
> print(plot2, position=c(0,0,1,0.5))
> 
> But this just produces two graphs, one above the other.  How do I 
> overlay them?  What should I be doing in order to get the same result as 
> with the base graphics?

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From rpeng at jhsph.edu  Thu Jul 29 13:39:30 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 29 Jul 2004 07:39:30 -0400
Subject: [R] attach files on start up
In-Reply-To: <4c7dca11.675449ab.81b3800@mirapoint-ms1.jcu.edu.au>
References: <4c7dca11.675449ab.81b3800@mirapoint-ms1.jcu.edu.au>
Message-ID: <4108E1F2.8080105@jhsph.edu>

You can put the attach() statements (and any other startup code) 
in the .Rprofile file in your working directory.

-roger

Kathryn Jones wrote:
> Hi,
> I was wondering if anyone could please tell me if there's a 
> way to attach the same files each time R starts up?
> Thanks!
> Kathryn Jones
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From t.dewez at brgm.fr  Thu Jul 29 14:28:55 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Thu, 29 Jul 2004 14:28:55 +0200
Subject: [R] using Rterm under cygwin, no possiblity to delete characters
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD6895@SRV0015>

Dear Brian,

 
> You have to call Rterm.exe *from a command shell*.  `cygwin' is not a
> command shell, but a collection of tools that provides 
> several such.  So
> we can only guess at what you are using.
> 
> Rterms runs satisfactorily in many shells (I use tcsh, others 
> use Cygwin 
> bash ...).  This is all described in the README and rw-FAQ files, 
> for example.

Your confusion is all due to my inaccurate explanation. In fact, Rterm runs
fine when running inside cygwin's bash window. I was running R from a bash
shell inside GRASS 5.7. I didn't think GRASS was altering the bash response.
Perhaps this is something Roger has come across before when developping the
interface. 

> > When I call Rterm from cygwin, I have no options but typing 
> the exact syntax
> > the first time. If I happen to hit the "delete" key 
> (backspace), R dies when
> > I press enter saying :
> 
> backspace and delete are separate keys, so which did you mean?
>

The error comes from hitting anything but a normal key ie arrow keys or
backspace.

> > Error: ... (error concerning the function on the last line of text)
> > Execution halted
> > 
> > Perhaps some of you have experienced this and found work 
> arounds? One has to
> > be pretty good to type without ever committing mistakes!
> > 
> > By the way, I am running Cygwin (cygwin_NT-5.0 release 
> 1.5.10(0.116/4/2), I
> > reinstalled everything fresh last week) on Win 2k and R 
> 1.9.1. Although some
> > of you find cygwin inefficient in many ways, I don't have 
> the option to
> > migrate to Linux.
> 
> The alternative is to use a Windows-native shell, such as tcsh.exe.

Thanks for your ideas

Thomas
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
(des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
 e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
v??rifier l'absence de corruption ?? sa r??ception.

The contents of this email and any attachments are confidential. They are intended for 
the named recipient(s) only. If you have received this email in error please notify the 
system manager or  the sender immediately and do not disclose the contents to 
anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
content.
***



From eesteves at ualg.pt  Thu Jul 29 13:38:19 2004
From: eesteves at ualg.pt (eesteves@ualg.pt)
Date: Thu, 29 Jul 2004 12:38:19 +0100
Subject: [R] Help w/ matrix calc
Message-ID: <1091101099.4108e1abefaba@wmail.ualg.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040729/f3d283c8/attachment.pl

From ramasamy at cancer.org.uk  Thu Jul 29 15:04:29 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 29 Jul 2004 14:04:29 +0100
Subject: [R] Help w/ matrix calc
In-Reply-To: <1091101099.4108e1abefaba@wmail.ualg.pt>
References: <1091101099.4108e1abefaba@wmail.ualg.pt>
Message-ID: <1091106269.3098.61.camel@vpn202001.lif.icnet.uk>

> m <- matrix( 1:12, nc=3 )
> m
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12

> apply(m, 1, mean) # row means
[1] 5 6 7 8

> apply(m, 2, mean) # column means
[1]  2.5  6.5 10.5

Replace 'mean' with 'var' if you want variances instead.

On Thu, 2004-07-29 at 12:38, eesteves at ualg.pt wrote:
> Dear All,
> Help is needed! I have a matrix with frequencies of fish larvae per length 
> class (var. sl) and age-group (var. median.no) obtained with 
> 
> >k<-table(cut(sl,(5:22)),median.no)
> >k[2:5,1:5] #to ilustrate k
> 
>         4  5  6  7 
> (6,7]   3  1  0  0
> (7,8]   3  0  1  0
> (8,9]   3  4  3  5
> (9,10]  3 15  7 13
> 
> from this matrix I would like to obtain the mean age per length class i.e. 
> vector of line means. How can I do this? If, instead of the means I wanted the 
> variances, how could I do it?
> Thanks in advance,
> Eduardo Esteves
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From deepayan at stat.wisc.edu  Thu Jul 29 15:19:53 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 29 Jul 2004 08:19:53 -0500
Subject: [R] Lattice graphics: adding lines to a plot
In-Reply-To: <4108E18A.8050100@optonline.net>
References: <4108D73B.8010604@massey.ac.nz> <4108E18A.8050100@optonline.net>
Message-ID: <200407290819.53027.deepayan@stat.wisc.edu>

On Thursday 29 July 2004 06:37, Chuck Cleland wrote:
> How about this?
>
> library(lattice)
> xyplot(y ~ x, panel = function(x, y, ...){
>                                 panel.xyplot(x, y, ...)
>                                 panel.lmline(x, y, type="l")
>                                 })

That should do it, except the type="l" is not required (panel.lmline 
always draws a line anyway). There's also a shortcut for this, namely,

xyplot(y ~ x, type = c("p", "r"))

Depending on how you would want to generalize this to more than one 
panel, you could also try 

g <- lm( y ~ x )
xyplot(y ~ x, 
       panel = function(x, y, ...){
           panel.xyplot(x, y, ...)
           panel.abline(g, ...)
       })

which draws the same 'global' fit in all panels.

Deepayan

> Matthew Walker wrote:
> > I am trying to use the Lattice package to produce the same result
> > as I can with the base graphics.
> >
> > With base graphics I can type:
> >
> > x <- 1:100
> > y <- x+rnorm(length(x))
> > g <- lm( y ~ x )
> > model.y <- g$coef[1]+g$coef[2]*x
> >
> > plot(x,y)   # a plot of the data
> > lines( x, model.y )   # a plot of the model, superimposed on the
> > first plot
> >
> >
> > With Lattice graphics I've got this far:
> >
> > library(lattice)
> > plot1 <- xyplot(y ~ x)
> > plot2 <- xyplot(model.y ~ x, panel = function(x, y) { llines(x=x,
> > y=y) }) print(plot1, more=TRUE, position=c(0,0.5,1,1))
> > print(plot2, position=c(0,0,1,0.5))
> >
> > But this just produces two graphs, one above the other.  How do I
> > overlay them?  What should I be doing in order to get the same
> > result as with the base graphics?



From ernesto at ipimar.pt  Thu Jul 29 15:38:47 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 29 Jul 2004 14:38:47 +0100
Subject: [R] Help w/ matrix calc
In-Reply-To: <1091101099.4108e1abefaba@wmail.ualg.pt>
References: <1091101099.4108e1abefaba@wmail.ualg.pt>
Message-ID: <1091108327.4544.32.camel@gandalf.local>

On Thu, 2004-07-29 at 12:38, eesteves at ualg.pt wrote:
> Dear All,
> Help is needed! I have a matrix with frequencies of fish larvae per length 
> class (var. sl) and age-group (var. median.no) obtained with 
> 
> >k<-table(cut(sl,(5:22)),median.no)
> >k[2:5,1:5] #to ilustrate k
> 
>         4  5  6  7 
> (6,7]   3  1  0  0
> (7,8]   3  0  1  0
> (8,9]   3  4  3  5
> (9,10]  3 15  7 13
> 
> from this matrix I would like to obtain the mean age per length class i.e. 
> vector of line means. How can I do this? If, instead of the means I wanted the 
> variances, how could I do it?
> Thanks in advance,
> Eduardo Esteves
> 

Ol?? Edu,

To compute that kind of statistics it's better to have a vector with
your length values (you can get it from the names of your matrix if you
prefer). I supose you want to use the mean length interval so you can
use the weigthed.mean function

len <- seq(6.5,9.5,1)

lenbar <- apply(k, 2, FUN=function(x){weighted.mean(len,x)}) 

to get variances you can use

lenvar <- apply(k, 2, FUN=function(x){var(rep(len,x))})

I think you may also use cov.wt but I'm not sure.

A more interesting result can be 

lendesc <- apply(k, 2, FUN=function(x){
	vec <- rep(len,x)	
	c(summary(vec), var=var(vec), mad=mad(vec))
})

I'm sure there are better and more elegant ways of doing this but here
you have a "quick fix" for you're problem.

Abra??os amigos

EJ



From ggrothendieck at myway.com  Thu Jul 29 15:29:23 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 29 Jul 2004 13:29:23 +0000 (UTC)
Subject: [R] 2 questions : format and hh:mm
References: <200407290943.LAA04040@bombardier2.lfdj.com>
Message-ID: <loom.20040729T152806-41@post.gmane.org>

Bruno Cutayar <bcutayar <at> lfdj.com> writes:

>  2- i search to generate a serie of hours and minutes on 24h :
> "00:00" , "00:01", "00:02", "00:03", ...,...,  "23:59"

Using the chron package, if min is sequence of chron times, e.g. 

   require(chron)
   m <- 24 * 60  # minutes in a day
   min <- times(seq(0,m-1)/m)

then you can format them as hh:mm:ss like this:

   format(min)

or as hh:mm like this:

   substring(min, 1, 5)



From David.R.Wille at gsk.com  Thu Jul 29 16:30:37 2004
From: David.R.Wille at gsk.com (David.R.Wille@gsk.com)
Date: Thu, 29 Jul 2004 15:30:37 +0100
Subject: [R] jpeg() on UNIX
In-Reply-To: <mailman.3558.1091110921.2835.r-help@stat.math.ethz.ch>
Message-ID: <OF75059062.38FF73DE-ON80256EE0.004F1B1C-80256EE0.004FB9E5@sb.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040729/8c0f2393/attachment.pl

From tlumley at u.washington.edu  Thu Jul 29 16:34:23 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 29 Jul 2004 07:34:23 -0700 (PDT)
Subject: [R] jpeg() on UNIX
In-Reply-To: <OF75059062.38FF73DE-ON80256EE0.004F1B1C-80256EE0.004FB9E5@sb.com>
References: <OF75059062.38FF73DE-ON80256EE0.004F1B1C-80256EE0.004FB9E5@sb.com>
Message-ID: <Pine.A41.4.58.0407290732550.191682@homer09.u.washington.edu>

On Thu, 29 Jul 2004 David.R.Wille at gsk.com wrote:

> Dear R users,
>
> I am currently having difficulty migrating a web application from XP to a
> SGI UNIX since when I run R in the background (i.e. in a process started
> from the web server) the graphics device jpeg() requires, but cannot
> connect to, X11. I could go via bitmap() and PS but wondered if there was
> another way forward. I am currently running R version 1.6.2. Ideally, I
> would like may R source to be compatible with Windows.
>

The FAQ suggests that running Xvfb, which provides an X server with no
display, may work.  I understand that the CRAN people do this.

	-thomas



From jmacdon at med.umich.edu  Thu Jul 29 16:36:40 2004
From: jmacdon at med.umich.edu (James MacDonald)
Date: Thu, 29 Jul 2004 10:36:40 -0400
Subject: [R] Help w/ matrix calc
Message-ID: <s108d2e9.075@med-gwia-01a.med.umich.edu>

For row or column means with a matrix of any size, you will be much
better served by using
rowMeans()
colMeans()

Best,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Adaikalavan Ramasamy <ramasamy at cancer.org.uk> 07/29/04 09:04AM >>>
> m <- matrix( 1:12, nc=3 )
> m
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12

> apply(m, 1, mean) # row means
[1] 5 6 7 8

> apply(m, 2, mean) # column means
[1]  2.5  6.5 10.5

Replace 'mean' with 'var' if you want variances instead.

On Thu, 2004-07-29 at 12:38, eesteves at ualg.pt wrote:
> Dear All,
> Help is needed! I have a matrix with frequencies of fish larvae per
length 
> class (var. sl) and age-group (var. median.no) obtained with 
> 
> >k<-table(cut(sl,(5:22)),median.no)
> >k[2:5,1:5] #to ilustrate k
> 
>         4  5  6  7 
> (6,7]   3  1  0  0
> (7,8]   3  0  1  0
> (8,9]   3  4  3  5
> (9,10]  3 15  7 13
> 
> from this matrix I would like to obtain the mean age per length class
i.e. 
> vector of line means. How can I do this? If, instead of the means I
wanted the 
> variances, how could I do it?
> Thanks in advance,
> Eduardo Esteves
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From mrennie at utm.utoronto.ca  Thu Jul 29 16:44:22 2004
From: mrennie at utm.utoronto.ca (Michael Rennie)
Date: Thu, 29 Jul 2004 10:44:22 -0400
Subject: [R] Kudos to the R support team
Message-ID: <1091112262.41090d46de2c0@webmail.utm.utoronto.ca>


Hi there,

I just wanted to take a quick second to thank everyone who maintains this 
service- just in case you don't hear it enough, there are a plethora of people 
who rely on this service (as evidenced by the help archives), and even if they 
don't say it, are greatly thankful for what you do here. Not only are you 
providing a service to people who are learning R, but indeed helping 
increase "R literacy". Soon, they'll be speaking R on the subway.

Thank you all, once again. You are all wonderful people.

-- 
Michael Rennie
Ph.D. Candidate
University of Toronto at Mississauga
3359 Mississauga Rd. N.
Mississauga ON  L5L 1C6
Ph: 905-828-5452  Fax: 905-828-3792



From gunter.berton at gene.com  Thu Jul 29 17:36:06 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 29 Jul 2004 08:36:06 -0700
Subject: [R] Kudos to the R support team
References: <1091112262.41090d46de2c0@webmail.utm.utoronto.ca>
Message-ID: <41091966.B40D0711@gene.com>

May I add to Michael's comment:

1) There is no formal service; the R Core team members and other regular
contributors who do yeo-persons' service do so entirely voluntarily and at their
individual discretion..

2) The whole cultural/sociological phenomenon of R strikes me as remarkable.
Granting that S and S-Plus provided the essential framework and template, it still
strikes me as amazing that such a powerful flexible software system could be
constructed, maintained, and documented with such high quality and consistency by
such a geographically separated team, especially as they did/do it "part-time" and
voluntarily. Surely this is testimony to both their wisdom and hard work.

3). Given their efforts on our behalf, I think it behooves us to be as considerate
and solicitous as possible by first following the advice to read Help files, FAQ's
and posting guides before wasting their time with queries that do not require
their sage advice.

--

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning process."

 -- George E.P. Box



Michael Rennie wrote:

> Hi there,
>
> I just wanted to take a quick second to thank everyone who maintains this
> service- just in case you don't hear it enough, there are a plethora of people
> who rely on this service (as evidenced by the help archives), and even if they
> don't say it, are greatly thankful for what you do here. Not only are you
> providing a service to people who are learning R, but indeed helping
> increase "R literacy". Soon, they'll be speaking R on the subway.
>
> Thank you all, once again. You are all wonderful people.
>
> --
> Michael Rennie
> Ph.D. Candidate
> University of Toronto at Mississauga
> 3359 Mississauga Rd. N.
> Mississauga ON  L5L 1C6
> Ph: 905-828-5452  Fax: 905-828-3792
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sopiyo at unlserve.unl.edu  Thu Jul 29 17:56:18 2004
From: sopiyo at unlserve.unl.edu (Stephen Opiyo)
Date: Thu, 29 Jul 2004 10:56:18 -0500
Subject: [R] Question on getting a data from dataframe
Message-ID: <001601c47584$95fff910$21865d81@DHBKP921>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040729/f24c1134/attachment.pl

From deleeuw at stat.ucla.edu  Thu Jul 29 18:16:57 2004
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu, 29 Jul 2004 09:16:57 -0700
Subject: [R] R and the Journal of Statistical Software
Message-ID: <B681A717-E17A-11D8-A09B-000A95A67E82@stat.ucla.edu>

http://www.jstatsoft.org

JSS is now up to Volume 11. This year is the first multi-volume
year, with three volumes so far. JSS now has its own ISSN
number and its own CODEC. A JSS LaTeX format will
become available soon. JSS is aiming to become an
(electronic) ASA journal, independent of JCGS, soon. It's
contents, including back issues, will also soon be in CIS.

Recent volumes of JSS illustrate the fact that R is, indeed,
the lingua franca of computational statistics. Many CRAN
packages have their corresponding JSS articles. And I hope
more package authors will follow. As far as I am concerned
it is perfectly alright to publish something both in R News
and in JSS.

JSS volumes now have four different "departments". One is
"Articles", which has the main contributions (technique +
manual + software). The second is "Code Snippets", which
are shorter and have less emphasis on statistics and more
on software. The third is "Software Reviews", which reviews
mostly commercial programs and packages (for which we
do not have the code). Finally, there are "Book Reviews",
reviewing books on statistical software, computational statistics,
optimization, Monte Carlo, and  numerical linear algebra.

R programmers are also encouraged to contribute "Code
Snippets". We have no clear author guidelines for these
snippets yet, but we are hoping that "short" and "emphasis
on software" is clear enough for now, and that we will
converge to something more standardized.

===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au



From wolski at molgen.mpg.de  Thu Jul 29 18:35:44 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 29 Jul 2004 18:35:44 +0200
Subject: [R] Comparing correlated (paired) ROC curves (sensitivities).
Message-ID: <200407291835440698.004E7947@mail.math.fu-berlin.de>

Hi!


I am looking for functions which I can use to compare correlated ROC curves, or even better correlated (paired - obtained from the same data with different measures) sensitivities given FP rates.


Eryk


Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From xma at Arctur.com  Thu Jul 29 19:13:23 2004
From: xma at Arctur.com (Xiao-Jun Ma)
Date: Thu, 29 Jul 2004 10:13:23 -0700
Subject: [R] fitting gaussian mixtures
Message-ID: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>

Hi R-helpers,

I'm trying to model a univariate as a bi-modal normal mixtures. I need to estimate the parameters of each gaussian (mean and sd) and their weights. What's the best way to do this in R?

Thanks,

Xiao-Jun



From sundar.dorai-raj at PDF.COM  Thu Jul 29 19:25:40 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 29 Jul 2004 12:25:40 -0500
Subject: [R] fitting gaussian mixtures
In-Reply-To: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>
References: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>
Message-ID: <41093314.5000108@pdf.com>



Xiao-Jun Ma wrote:
> Hi R-helpers,
> 
> I'm trying to model a univariate as a bi-modal normal mixtures. I need to estimate the parameters of each gaussian (mean and sd) and their weights. What's the best way to do this in R?
> 
> Thanks,
> 
> Xiao-Jun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

package:mclust should help.

Please read the posting guide. This question was asked less than two 
weeks ago and the answer should surely be in the mail archives.

--sundar



From zboshao at yahoo.com  Thu Jul 29 21:06:27 2004
From: zboshao at yahoo.com (boshao zhang)
Date: Thu, 29 Jul 2004 12:06:27 -0700 (PDT)
Subject: [R] MLE, precision
In-Reply-To: <40F4001F.80609@pdf.com>
Message-ID: <20040729190627.7567.qmail@web12205.mail.yahoo.com>

Dear Spencer:

My problem get solved by using Matlab. It runs pretty
quick(less than 5 seconds)and the result is stable
with respect to the initial values. I was amaized.
Here my t and are as long as 2390, sum the functions
over t and d, the function becomes daunting. But I
still like to try nlmb(I give up ms function in S or
nlm in R). 

But how can I sum the functions over t. To simplify
the problem, I just need to know the following:
t <- 1:2;
I would like to get f = sum(t*x + 1) over t. I tried
the following:
 f<-0
 for (i in 1:2){ 
               g <- function(x){~t[i]*x+1}; f = f +g;
               }
Problem in f + g: needed atomic data, got an object of
class "function" 
Use traceback() to see the call stack

As you see, it refuse to work.

Please give me advice. 
thank you.

Boshao




--- Spencer Graves <spencer.graves at pdf.com> wrote:

>       Have you considered estimating ln.m1, ln.m2,
> and ln.b, which makes 
> the negative log likelihood something like the
> following: 
> 
> l.ln<- function(ln.m1,ln.m2,ln.b){
>     m1 <- exp(ln.m1); m2 <- exp(ln.m2); b <-
> exp(ln.b)
>     lglk <- d*( ln.m1 + ln.m2        
>          + log1p(-exp(-(b+m2)*t)
>          + (m1/b-d)*log(m2+b*exp(-b+m2)*t))
>           + m1*t - m1/b*log(b+m2) )
> 
>    (-sum(lglk))
> }
> # NOT TESTED
> 
> 	  I don't know if I have this correct, but you
> should get the idea.  Parameterizing in terms of
> logarithms automatically eliminates the constraints
> that m1, m2, and b must be positive.  
> 
> 	  I also prefer to play with the function until I'm
> reasonably confident it will never produce NAs, and
> I use a few tricks to preserve numerical precision
> where I can.  For example, log(b+m2) = log(b) +
> log1p(m2/b) = log(m2) + log1p(b/m2).  If you use the
> first form when b is larger and the second when m1
> is larger, you should get more accurate answers. 
> Using, e.g.:  
> 
> 	  log.apb <- function(log.a, log.b){
> 	  	  min.ab <- pmin(log.a, log.b)
> 		  max.ab <- pmax(log.a, log.b)
> 	  	  max.ab + log1p(exp(min.ab-max.ab))
> 	  }
> 	  # NOT TESTED
> 
> If log.a and log.b are both really large, a and b
> could be Inf when log.a and log.b are finite. 
> Computing log(a+b) like this eliminates that
> problem.  The same problem occurs when log.a and
> log.b are so far negative that a and b are both
> numerically 0, even though log.a and log.b are very
> finite.  This function eliminates that problem.  
> 
> 	  Also, have you tried plotting your "l" vs. m1
> with m2 and b constant, and then vs. m2 with m2 and
> b constant and vs. b with m1 and m2 constant?  Or
> (better) make contour plots of "l" vs. any 2 of
> these parameters with the other held constant.  When
> I've done this in crudely similar situations, I've
> typically found that the log(likelihood) was more
> nearly parabolic in terms of ln.m1, ln.m2, and ln.b
> than in terms of the untransformed variables.  This
> means that the traditional Wald confidence region
> procedures are more accurate, as they assume that
> the log(likelihood) is parabolic in the parameters
> estimated.  
> 
> 	  hope this  helps.  spencer graves
> p.s.  I suggest you avoid using "t" as a variable
> name:  That's the name of the function for the
> transpose of a matrix.  R and usually though not
> always tell from the context what you want. 
> However, it's best to avoid that ambiguity.  I often
> test at a command prompt variable names I want to
> use.  If the response is "object not found", then I
> feel like I can use it.  
> 
> boshao zhang wrote:
> 
> >Hi, everyone
> >
> >I am trying to estimate 3 parameters for my
> survival
> >function. It's very complicated. The negative
> >loglikelihood function is:
> >
> >l<- function(m1,m2,b)  -sum(    d*( log(m1) +
> log(m2)
> >+ log(1- exp(-(b + m2)*t)) ) + (m1/b - d)*log(m2 +
> >b*exp(-(b + m2)*t) ) + m1*t - m1/b*log(b+m2)      )
> >
> >here d and t are given, "sum"  means sum over these
> >two vairables. 
> >the parameters are assumed small, m1, m2 in
> >thousandth, m2 in millionth.
> >
> >I used the function "nlm" to estimate m1,m2,b. But
> the
> >result is very bad. you can get more than 50
> warnings,
> >most of them are about "negative infinity"in log.
> And
> >the results are initial value dependent, or you
> will
> >get nothing when you choose some values.
> >
> >So I tried brutal force, i.e. evaluate the values
> of
> >grid point. It works well. Also, you can get the
> >correct answer of log(1e-12).
> >
> >My questions are:
> > What is the precision of a variable in R?
> > How to specify the constraint interval of
> parameters
> >in nlm? I tried lower, upper, it doesn't work.
> >any advice on MLE is appreciated.
> >
> >Thank you.
> >
> >Boshao
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
>
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >  
> >
> 
>



From pwilkinson at videotron.ca  Thu Jul 29 21:22:20 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Thu, 29 Jul 2004 15:22:20 -0400
Subject: [R] Stumped with subsetting
In-Reply-To: <41093314.5000108@pdf.com>
References: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>
	<41093314.5000108@pdf.com>
Message-ID: <6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>

This seems like such a trivial thing to do:

given a data.frame DF and variables w,v, x,y,z I can do

DF["x"] or DF[c("x","y")]

if I create a vector, mylist = c("x",y")

then I do DF[mylist]

I am not getting x and y, I get something else.


what is the correct way to subset a data.frame by columns using a vector, 
as if I were doing DF["x","y"]?

Peter



From sundar.dorai-raj at PDF.COM  Thu Jul 29 21:36:22 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 29 Jul 2004 14:36:22 -0500
Subject: [R] Stumped with subsetting
In-Reply-To: <6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>
References: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>	<41093314.5000108@pdf.com>
	<6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>
Message-ID: <410951B6.1080207@pdf.com>



Peter Wilkinson wrote:

> This seems like such a trivial thing to do:
> 
> given a data.frame DF and variables w,v, x,y,z I can do
> 
> DF["x"] or DF[c("x","y")]
> 
> if I create a vector, mylist = c("x",y")
> 
> then I do DF[mylist]
> 
> I am not getting x and y, I get something else.
> 
> 
> what is the correct way to subset a data.frame by columns using a 
> vector, as if I were doing DF["x","y"]?
> 
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

You want DF[, mylist]. DF[mylist] returns a list. You may want to look 
at "An Introduction to R", which covers this topic.

--sundar

P.S. Please create a new e-mail when posting to the list rather than 
replying to a message and just changing the subject. This is (of course) 
covered in the posting guide.



From tplate at blackmesacapital.com  Thu Jul 29 21:40:58 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 29 Jul 2004 13:40:58 -0600
Subject: [R] Stumped with subsetting
In-Reply-To: <6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>
References: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>
	<41093314.5000108@pdf.com>
	<6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>
Message-ID: <6.1.0.6.2.20040729133824.0cbd4770@mailhost.blackmesacapital.com>

Seems to work fine for me if I understand correctly what you're trying to 
do (there are some typos in your message, which may mean I'm not 
understanding):

 > data <- data.frame(x=1:3,y=4:6,z=7:9)
 > data[c("x","y")]
   x y
1 1 4
2 2 5
3 3 6
 > mylist <- c("x","y")
 > data[mylist]
   x y
1 1 4
2 2 5
3 3 6
 > data[,mylist]
   x y
1 1 4
2 2 5
3 3 6
 >

I'd generally use the second form of subsetting above (i.e., data[,mylist], 
because that will work with matrices as well).

hope this helps,

Tony Plate

At Thursday 01:22 PM 7/29/2004, Peter Wilkinson wrote:
>This seems like such a trivial thing to do:
>
>given a data.frame DF and variables w,v, x,y,z I can do
>
>DF["x"] or DF[c("x","y")]
>
>if I create a vector, mylist = c("x",y")
>
>then I do DF[mylist]
>
>I am not getting x and y, I get something else.
>
>
>what is the correct way to subset a data.frame by columns using a vector, 
>as if I were doing DF["x","y"]?
>
>Peter
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at PDF.COM  Thu Jul 29 21:46:18 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 29 Jul 2004 14:46:18 -0500
Subject: [R] Stumped with subsetting
In-Reply-To: <410951B6.1080207@pdf.com>
References: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>	<41093314.5000108@pdf.com>	<6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>
	<410951B6.1080207@pdf.com>
Message-ID: <4109540A.6010304@pdf.com>



Sundar Dorai-Raj wrote:

> 
> 
> Peter Wilkinson wrote:
> 
>> This seems like such a trivial thing to do:
>>
>> given a data.frame DF and variables w,v, x,y,z I can do
>>
>> DF["x"] or DF[c("x","y")]
>>
>> if I create a vector, mylist = c("x",y")
>>
>> then I do DF[mylist]
>>
>> I am not getting x and y, I get something else.
>>
>>
>> what is the correct way to subset a data.frame by columns using a 
>> vector, as if I were doing DF["x","y"]?
>>
>> Peter
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> You want DF[, mylist]. DF[mylist] returns a list. You may want to look 
> at "An Introduction to R", which covers this topic.
> 

Sorry, typed too quickly.

DF[mylist] and DF[, mylist] are the same if mylist is a vector with more 
than one element.

After re-reading your post, I'm not quite sure what you are expecting. 
Sorry for any confusion....

--sundar



From pwilkinson at videotron.ca  Thu Jul 29 22:03:26 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Thu, 29 Jul 2004 16:03:26 -0400
Subject: [R] Stumped with subsetting
In-Reply-To: <4109540A.6010304@pdf.com>
References: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>
	<41093314.5000108@pdf.com>
	<6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>
	<410951B6.1080207@pdf.com> <4109540A.6010304@pdf.com>
Message-ID: <6.0.3.0.0.20040729160302.01c3bd80@pop.videotron.ca>

Hi there,

thanks for the reply. I was expecting what Tony posted. By the way I got 
the format  for my question out of Introduction to R. So I expected it to 
work as in the text, but it turns out ....

my "list" somehow was not a vector:

 > list[1]
[1] PERH0125
44 Levels:  PERH0015 PERH0019 PERH0023 PERH0029 PERH0037 PERH0045 PERH0053 
PERH0075 ... PERH0360

I did the following:

 > list2 = as.vector(list)
 > list2
  [1] "PERH0125" "PERH0315" "PERH0161" "PERH0181" "PERH0229" "PERH0223" 
"PERH0243" "PERH0269"
  <snip>

I am not sure what format list was in (looks like factor), but I turned it 
into a vector and it worked as expected. I have to go back and see how I 
created list in the first place.

originally I took a row from a data frame, removed NA values, then sorted 
it into an order that I wanted (using 'order') .... so I don't know when it 
turned into something that looked like factor. Any ?

Peter


At 03:46 PM 7/29/2004, Sundar Dorai-Raj wrote:


>Sundar Dorai-Raj wrote:
>
>>
>>Peter Wilkinson wrote:
>>
>>>This seems like such a trivial thing to do:
>>>
>>>given a data.frame DF and variables w,v, x,y,z I can do
>>>
>>>DF["x"] or DF[c("x","y")]
>>>
>>>if I create a vector, mylist = c("x",y")
>>>
>>>then I do DF[mylist]
>>>
>>>I am not getting x and y, I get something else.
>>>
>>>
>>>what is the correct way to subset a data.frame by columns using a 
>>>vector, as if I were doing DF["x","y"]?
>>>
>>>Peter
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>
>>You want DF[, mylist]. DF[mylist] returns a list. You may want to look at 
>>"An Introduction to R", which covers this topic.
>
>Sorry, typed too quickly.
>
>DF[mylist] and DF[, mylist] are the same if mylist is a vector with more 
>than one element.
>
>After re-reading your post, I'm not quite sure what you are expecting. 
>Sorry for any confusion....
>
>--sundar
>



From fzh113 at hecky.it.northwestern.edu  Thu Jul 29 22:08:52 2004
From: fzh113 at hecky.it.northwestern.edu (Fred)
Date: Thu, 29 Jul 2004 15:08:52 -0500
Subject: [R] Any orthnormal matrix can keep the curve's shape and size
	unchnaged?
Message-ID: <000401c475a7$dec92950$ab8d7ca5@FYOC1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040729/0a6abeae/attachment.pl

From spencer.graves at pdf.com  Thu Jul 29 22:17:40 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 29 Jul 2004 13:17:40 -0700
Subject: [R] MLE, precision
In-Reply-To: <20040729190627.7567.qmail@web12205.mail.yahoo.com>
References: <20040729190627.7567.qmail@web12205.mail.yahoo.com>
Message-ID: <41095B64.5000607@pdf.com>

      1.  Don't use "t" as a variable name.  It is the name of the 
matrix transpose function.  In most but not all contexts, R is smart 
enough to tell whether you want the system function or the local object. 

      2.  I can't tell from your question what you want.  "PLEASE do 
read the posting guide! http://www.R-project.org/posting-guide.html".  
You may be able to get answers to many of your questions by following 
that process.  If you follow that guide and still have a question for 
this listserve, the exercise will likely help you formulate a question 
that will be easier for people to understand, increasing thereby the 
likelihood that you will get an appropriate answer. 

      3.  I wonder if the following will help: 

 > (td <- outer(1:3, 4:5))
     [,1] [,2]
[1,]    4    5
[2,]    8   10
[3,]   12   15
 > rowSums(td)
[1]  9 18 27
 > colSums(td)
[1] 24 30

      hope this helps.  spencer graves

boshao zhang wrote:

>Dear Spencer:
>
>My problem get solved by using Matlab. It runs pretty
>quick(less than 5 seconds)and the result is stable
>with respect to the initial values. I was amaized.
>Here my t and are as long as 2390, sum the functions
>over t and d, the function becomes daunting. But I
>still like to try nlmb(I give up ms function in S or
>nlm in R). 
>
>But how can I sum the functions over t. To simplify
>the problem, I just need to know the following:
>t <- 1:2;
>I would like to get f = sum(t*x + 1) over t. I tried
>the following:
> f<-0
> for (i in 1:2){ 
>               g <- function(x){~t[i]*x+1}; f = f +g;
>               }
>Problem in f + g: needed atomic data, got an object of
>class "function" 
>Use traceback() to see the call stack
>
>As you see, it refuse to work.
>
>Please give me advice. 
>thank you.
>
>Boshao
>
>
>
>
>--- Spencer Graves <spencer.graves at pdf.com> wrote:
>
>  
>
>>      Have you considered estimating ln.m1, ln.m2,
>>and ln.b, which makes 
>>the negative log likelihood something like the
>>following: 
>>
>>l.ln<- function(ln.m1,ln.m2,ln.b){
>>    m1 <- exp(ln.m1); m2 <- exp(ln.m2); b <-
>>exp(ln.b)
>>    lglk <- d*( ln.m1 + ln.m2        
>>         + log1p(-exp(-(b+m2)*t)
>>         + (m1/b-d)*log(m2+b*exp(-b+m2)*t))
>>          + m1*t - m1/b*log(b+m2) )
>>
>>   (-sum(lglk))
>>}
>># NOT TESTED
>>
>>	  I don't know if I have this correct, but you
>>should get the idea.  Parameterizing in terms of
>>logarithms automatically eliminates the constraints
>>that m1, m2, and b must be positive.  
>>
>>	  I also prefer to play with the function until I'm
>>reasonably confident it will never produce NAs, and
>>I use a few tricks to preserve numerical precision
>>where I can.  For example, log(b+m2) = log(b) +
>>log1p(m2/b) = log(m2) + log1p(b/m2).  If you use the
>>first form when b is larger and the second when m1
>>is larger, you should get more accurate answers. 
>>Using, e.g.:  
>>
>>	  log.apb <- function(log.a, log.b){
>>	  	  min.ab <- pmin(log.a, log.b)
>>		  max.ab <- pmax(log.a, log.b)
>>	  	  max.ab + log1p(exp(min.ab-max.ab))
>>	  }
>>	  # NOT TESTED
>>
>>If log.a and log.b are both really large, a and b
>>could be Inf when log.a and log.b are finite. 
>>Computing log(a+b) like this eliminates that
>>problem.  The same problem occurs when log.a and
>>log.b are so far negative that a and b are both
>>numerically 0, even though log.a and log.b are very
>>finite.  This function eliminates that problem.  
>>
>>	  Also, have you tried plotting your "l" vs. m1
>>with m2 and b constant, and then vs. m2 with m2 and
>>b constant and vs. b with m1 and m2 constant?  Or
>>(better) make contour plots of "l" vs. any 2 of
>>these parameters with the other held constant.  When
>>I've done this in crudely similar situations, I've
>>typically found that the log(likelihood) was more
>>nearly parabolic in terms of ln.m1, ln.m2, and ln.b
>>than in terms of the untransformed variables.  This
>>means that the traditional Wald confidence region
>>procedures are more accurate, as they assume that
>>the log(likelihood) is parabolic in the parameters
>>estimated.  
>>
>>	  hope this  helps.  spencer graves
>>p.s.  I suggest you avoid using "t" as a variable
>>name:  That's the name of the function for the
>>transpose of a matrix.  R and usually though not
>>always tell from the context what you want. 
>>However, it's best to avoid that ambiguity.  I often
>>test at a command prompt variable names I want to
>>use.  If the response is "object not found", then I
>>feel like I can use it.  
>>
>>boshao zhang wrote:
>>
>>    
>>
>>>Hi, everyone
>>>
>>>I am trying to estimate 3 parameters for my
>>>      
>>>
>>survival
>>    
>>
>>>function. It's very complicated. The negative
>>>loglikelihood function is:
>>>
>>>l<- function(m1,m2,b)  -sum(    d*( log(m1) +
>>>      
>>>
>>log(m2)
>>    
>>
>>>+ log(1- exp(-(b + m2)*t)) ) + (m1/b - d)*log(m2 +
>>>b*exp(-(b + m2)*t) ) + m1*t - m1/b*log(b+m2)      )
>>>
>>>here d and t are given, "sum"  means sum over these
>>>two vairables. 
>>>the parameters are assumed small, m1, m2 in
>>>thousandth, m2 in millionth.
>>>
>>>I used the function "nlm" to estimate m1,m2,b. But
>>>      
>>>
>>the
>>    
>>
>>>result is very bad. you can get more than 50
>>>      
>>>
>>warnings,
>>    
>>
>>>most of them are about "negative infinity"in log.
>>>      
>>>
>>And
>>    
>>
>>>the results are initial value dependent, or you
>>>      
>>>
>>will
>>    
>>
>>>get nothing when you choose some values.
>>>
>>>So I tried brutal force, i.e. evaluate the values
>>>      
>>>
>>of
>>    
>>
>>>grid point. It works well. Also, you can get the
>>>correct answer of log(1e-12).
>>>
>>>My questions are:
>>>What is the precision of a variable in R?
>>>How to specify the constraint interval of
>>>      
>>>
>>parameters
>>    
>>
>>>in nlm? I tried lower, upper, it doesn't work.
>>>any advice on MLE is appreciated.
>>>
>>>Thank you.
>>>
>>>Boshao
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>      
>>>
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>    
>>
>>>PLEASE do read the posting guide!
>>>      
>>>
>>http://www.R-project.org/posting-guide.html
>>    
>>
>>> 
>>>
>>>      
>>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From simon.urbanek at math.uni-augsburg.de  Thu Jul 29 22:37:47 2004
From: simon.urbanek at math.uni-augsburg.de (Simon Urbanek)
Date: Thu, 29 Jul 2004 22:37:47 +0200
Subject: [R] cross-compile R darwin2win, almost there
Message-ID: <26A73152-E19F-11D8-8118-000A959F327E@math.uni-augsburg.de>

I'm trying to cross-compile R on a Mac OS X box to target Win32. It 
works quite well, everything works, except for one fortran file ppr.f 
in the stats package:

---------- Making package stats ------------
   adding build stamp to DESCRIPTION
   installing NAMESPACE file and metadata
   making DLL ...
i386-mingw32-g77 -O2 -Wall   -c ppr.f -o ppr.o
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:803: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:1186: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:1186: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:1186: sorry, unimplemented: data initializer on host with 
different endianness
ppr.f:1186: sorry, unimplemented: data initializer on host with 
different endianness
make[5]: *** [ppr.o] Error 1
make[4]: *** [srcDynlib] Error 2

It's just a "block data" with some common variables that are 
initialized en-block. Obviously g77 tries to copy the whole block and 
bails out, because it's unsure about the endianness conversion (could 
be int/double whatever). My Fortran knowledge is rather limited, so can 
anyone provide me with alternate Fortran code that will use regular 
assignments instead of the "block data", so we can work around the 
missing feature of the compiler? If someone has a different idea, 
that's fine, too :).

Otherwise it works very nicely, the compiled R works (except that stats 
is not compiled of course) ... Solving the above would allow us to 
provide binary packages for both platforms OS X and Windows using just 
one machine to automatically generate both... (for those interested I 
could put the cross-compile tools on my pages..)

Any help is appreciated,
Simon

---
Simon Urbanek
Department of computer oriented statistics and data analysis
Universit??tsstr. 14
86135 Augsburg
Germany

Tel: +49-821-598-2236
Fax: +49-821-598-2280

Simon.Urbanek at Math.Uni-Augsburg.de
http://simon.urbanek.info



From Sinnwell.Jason at mayo.edu  Thu Jul 29 22:46:16 2004
From: Sinnwell.Jason at mayo.edu (Jason Sinnwell)
Date: Thu, 29 Jul 2004 15:46:16 -0500 (CDT)
Subject: [R] perl script in exec/
Message-ID: <200407292046.i6TKkGK25847@tomservo.mayo.edu>


Dear useRs-

I am developing a package that uses output from stand-alone unix software 
programs.  I use multiple perl scripts to process the output and make it ready 
for reading into R.  I would like to keep the perl scripts in the designated 
place for such files, exec/, but I can't find how a user is supposed to be able 
to use those when using the library.   

R-exts 1.1.4: 
..'exec/' could contain additional executables the package needs, ...  This 
mechanism is currently used only by very few packages, and still experimental.  

Any help or referral to the proper documentation would be appreciated.  

Jason

+--------------------------+
|Jason P. Sinnwell, M.S.   |
|Mayo Clinic, Rochester    |
|Health Sciences Research  |
|Division of Biostatistics |
|Harwick 7-97		   |
|507.284.3270              |
+--------------------------+



From Dursun.Bulutoglu at afit.edu  Thu Jul 29 22:56:31 2004
From: Dursun.Bulutoglu at afit.edu (Bulutoglu Dursun A Civ AFIT/ENC)
Date: Thu, 29 Jul 2004 16:56:31 -0400
Subject: [R] Editing Strings in R
Message-ID: <4CFC110AB744244C824D25E59665956C13DC69@ms-afit-04.afit.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040729/9f1adb6a/attachment.pl

From ihok at hotmail.com  Thu Jul 29 23:54:48 2004
From: ihok at hotmail.com (Jack Tanner)
Date: Thu, 29 Jul 2004 17:54:48 -0400
Subject: [R] unwanted as.integer
Message-ID: <41097228.6020906@hotmail.com>

 > a <- sqlQuery(irrdb, "select count(field) from mytable where field = 1")
 > print(a)
  count(field)
1            8
 > paste(a)
[1] "as.integer(8)"

Why the as.integer() representation? I later pass the result into this 
write.html.table(), and what I get is rows of as.integer()... when all I 
want is the integer itself.

as.integer(31) 	as.integer(21) 	as.integer(34) 	as.integer(86)
as.integer(7) 	as.integer(6) 	as.integer(15) 	as.integer(28)


write.html.table <- function(t, file= "", capt= "The Default Title",
                            append = FALSE) {
  head <- paste("<table>\n<caption>", capt, "</caption>\n")
  cat(head, file= file, append= append)
  if (is.null(rownames(t))) {
    rownames(t) <- rep("", nrow(t))
  }
  tp <- rbind(c("<tr><td></td>", colnames(t)),
              cbind(unlist(lapply(rownames(t), function(x) {
                paste("<tr><td>", x)})), t))
  write.table(tp, sep= "<td>", file= file, , eol= "</tr>\n",
              row.names=FALSE,
              col.names=FALSE,
              append=TRUE, quote=FALSE)
  cat("</tr>\n</table>\n", file= file, append= TRUE)
}



From sundar.dorai-raj at PDF.COM  Fri Jul 30 00:06:41 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 29 Jul 2004 17:06:41 -0500
Subject: [R] unwanted as.integer
In-Reply-To: <41097228.6020906@hotmail.com>
References: <41097228.6020906@hotmail.com>
Message-ID: <410974F1.3090306@pdf.com>



Jack Tanner wrote:
>  > a <- sqlQuery(irrdb, "select count(field) from mytable where field = 1")
>  > print(a)
>  count(field)
> 1            8
>  > paste(a)
> [1] "as.integer(8)"
> 
> Why the as.integer() representation? I later pass the result into this 
> write.html.table(), and what I get is rows of as.integer()... when all I 
> want is the integer itself.
> 
> as.integer(31)     as.integer(21)     as.integer(34)     as.integer(86)
> as.integer(7)     as.integer(6)     as.integer(15)     as.integer(28)
> 
> 
> write.html.table <- function(t, file= "", capt= "The Default Title",
>                            append = FALSE) {
>  head <- paste("<table>\n<caption>", capt, "</caption>\n")
>  cat(head, file= file, append= append)
>  if (is.null(rownames(t))) {
>    rownames(t) <- rep("", nrow(t))
>  }
>  tp <- rbind(c("<tr><td></td>", colnames(t)),
>              cbind(unlist(lapply(rownames(t), function(x) {
>                paste("<tr><td>", x)})), t))
>  write.table(tp, sep= "<td>", file= file, , eol= "</tr>\n",
>              row.names=FALSE,
>              col.names=FALSE,
>              append=TRUE, quote=FALSE)
>  cat("</tr>\n</table>\n", file= file, append= TRUE)
> }
> 

Not sure about what sqlQuery is doing but you can wrap your return value 
in a eval(parse(text = x)) to evaluate the "as.integer(.)" string. As in,

a <- eval(parse(text = a))


HTH,
--sundar



From GPetris at uark.edu  Fri Jul 30 00:08:02 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Thu, 29 Jul 2004 17:08:02 -0500 (CDT)
Subject: [R] Any orthnormal matrix can keep the curve's shape and size
	unchnaged?
In-Reply-To: <000401c475a7$dec92950$ab8d7ca5@FYOC1> (message from Fred on Thu, 
	29 Jul 2004 15:08:52 -0500)
References: <000401c475a7$dec92950$ab8d7ca5@FYOC1>
Message-ID: <200407292208.i6TM82iN000908@definetti.uark.edu>


Any orthogonal transformation preserves angles between vectors and
their length. Therefore, I guess shape and size are preserved -- of
course a precise answer depends on how you define these two features
of a curve. 

I am missing what has all this to do with R, though.

Giovanni

> Date: Thu, 29 Jul 2004 15:08:52 -0500
> From: Fred <fzh113 at hecky.it.northwestern.edu>
> Sender: r-help-bounces at stat.math.ethz.ch
> Cc: 
> Importance: Normal
> Precedence: list
> 
> Dear R users,
>  
> I want to know, given a curve f in d-dimensional space, 
> It is possible to keep the curve?s shape and size unchanged by
> an arbitrary dxd orthnormal matrix A?
> That is, the new curve g = A*f is still the same shape and size as f?
>  
> Thanks for your advices and answers.
>  
>  
> Fred
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From MSchwartz at MedAnalytics.com  Fri Jul 30 00:47:45 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 29 Jul 2004 17:47:45 -0500
Subject: [R] Editing Strings in R
In-Reply-To: <4CFC110AB744244C824D25E59665956C13DC69@ms-afit-04.afit.edu>
References: <4CFC110AB744244C824D25E59665956C13DC69@ms-afit-04.afit.edu>
Message-ID: <1091141265.23861.127.camel@localhost.localdomain>

On Thu, 2004-07-29 at 15:56, Bulutoglu Dursun A Civ AFIT/ENC wrote:
> 	I was wondering if there is a way of editting strings in R. I
> have a set of strings and each set is a row of numbers and paranthesis.
> 	For example the first row is: 
> 	(0 2)(3 4)(7 9)(5 9)(1 5)
> 	and I have a thousand or so such rows. I was wondering how I
> could get the corresponding string obtained by adding 1 to all the
> numbers in the string above.
> 	Dursun



I don't know if this is the most efficient approach, but working on a
few hours of sleep, here goes:


NewRow <- function(x)
{
  TempRow <- as.numeric(unlist(strsplit(x, "([\\(\\) ])"))) + 1

  TempMat <- matrix(TempRow[!is.na(TempRow)], ncol = 2, byrow = TRUE)

  paste("(", TempMat[, 1], " ", TempMat[, 2], ")", sep = "", 
        collapse = "")
}


Basically, the first line splits the character vector into its
components using "(", ")" and " " as regex based delimiters. It coerces
the result to a numeric vector and adds 1.

The second line takes the adjusted non-NA values and converts them into
a two column matrix, to make it easier to do the paste in line 3.

Line 3 returns the adjusted character vector reconstructed.


So:

MyRow <- "(0 2)(3 4)(7 9)(5 9)(1 5)"

> NewRow(MyRow)
[1] "(1 3)(4 5)(8 10)(6 10)(2 6)"


So, if you have a bunch of these rows, you could use this function with
apply:

MyData <- matrix(c("(0 2)(3 4)(7 9)(5 9)(1 5)", 
            "(1 6)(4 5)(3 7)(4 8)(9 0)",
            "(3 5)(8 1)(4 7)(2 7)(6 1)"))

> MyData
     [,1]                       
[1,] "(0 2)(3 4)(7 9)(5 9)(1 5)"
[2,] "(1 6)(4 5)(3 7)(4 8)(9 0)"
[3,] "(3 5)(8 1)(4 7)(2 7)(6 1)"

> matrix(apply(MyData, 1, NewRow))
     [,1]                         
[1,] "(1 3)(4 5)(8 10)(6 10)(2 6)"
[2,] "(2 7)(5 6)(4 8)(5 9)(10 1)" 
[3,] "(4 6)(9 2)(5 8)(3 8)(7 2)"  

Somebody may come up with an approach that is more efficient I suspect. 

For 1,200 rows:

> system.time(apply((matrix(rep(MyData, 400))), 1, NewRow))
[1] 0.29 0.00 0.33 0.00 0.00


(Gabor?  ;-)

HTH,

Marc Schwartz



From tlumley at u.washington.edu  Fri Jul 30 00:53:59 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 29 Jul 2004 15:53:59 -0700 (PDT)
Subject: [R] Gaussian frailty leads to segmentation fault
In-Reply-To: <4108743B.6050302@t-online.de>
References: <4107D669.5080501@imse.med.tu-muenchen.de>
	<Pine.A41.4.58.0407281102260.88732@homer07.u.washington.edu>
	<4108743B.6050302@t-online.de>
Message-ID: <Pine.A41.4.58.0407291548490.234570@homer06.u.washington.edu>


The crash happens when the penalty on the frailty term gets so small that
the model is singular and there are no degrees of freedom left for the
treatment effect.  The attached revision for survival/R/coxph.wtest.s
prevents the crash, but the model is still singular.

If you use method="aic" instead of the default method="reml" the model
converges. It is interesting to note that the estimated frailty variance
is then very small, so the two methods of estimating the frailty variance
disagree completely on these data.

This may well indicate that the penalized likelihood approach to the
frailty should be approached with strong distrust in these data.

	-thomas

On Thu, 29 Jul 2004, Christian Lederer wrote:

> Dear Thomas,
>
> attached you find a data frame which produces the error.
> I am using survival 2.11-5 under R 1.9.1-1 and 1.9.0-1.
>
> By the way, if i randomly omit 50% of the data, i usually
> get no crash, but a warning message like this:
> Inner loop failed to coverge for iterations 1 2 3 in: coxpenal.fit(X,
> Y, strats, offset, init = init, control, weights = weights,
>
> Maybe, the model is not appropriate for this kind of data.
> But on the other hand, as soon the treatment group (study == 1,
> treatment == 1) is smaller than the randomized placebo group
> (study == 1, treatment == 0), the warnings disappear.
> and the model gives reasonable results in my first simulations
> with normally distributed study effects.
>
> Christian
>
>
>
>
> Thomas Lumley wrote:
> > We really need a reproducible example to find segmentation faults.  Can
> > you make one?
> >
> > 	-thomas
> >
> >
> > On Wed, 28 Jul 2004, Christian Lederer wrote:
> >
> >
> >>Dear R gurus,
> >>
> >>for a simulation concerning study effects and historical controls
> >>in survival analysis, i would like to experiment with a gaussian
> >>frailty model.
> >>
> >>The simulated scenario consists of a randomized trial
> >>(treatment and placebo) and historical controls (only placebo).
> >>
> >>So the simulated data frames consist of four columns
> >>$time, $cens, $study, $treat.
> >>$time, $cens are the usual survival data.
> >>For the binary thretment indicator we have
> >>$treat == 0 or 1, if $study == 1,
> >>$treat == 1 if $study > 1
> >>
> >>Typical parameters for my simulations are:
> >>sample sizes (per arm):         between 100 and 200
> >>number of historical studies:   between 7 and 15
> >>hazard ratio treatment/placebo: between 0.7 and 1
> >>variance of the study effekt:   between 0 and 0.3
> >>
> >>Depending on the sample sizes, the following call sometimes leads to
> >>a segmentation fault:
> >>
> >>coxph(Surv(time,cens) ~
> >>       as.factor(treatment) + frailty(study, distribution="gaussian"),
> >>       data=data)
> >>
> >>I noticed, that this segmentation fault occures most frequently, if the
> >>number of randomized treatment patients is higher than the number of
> >>randomized placebo patients, and the number of historical studies is
> >>large.
> >>There seems to be no problem, if there are at least as many randomized
> >>placebo patients as treated patients. Unfortunately, this is not the
> >>situation i want to investigate (historical controls should be used
> >>to decrease the number of treated patients).
> >>
> >>Is there a way to circumwent this problem?
> >>
> >>Christian
> >>
> >>P.S.
> >>Is it allowed, to attach gzipped sample data sets in this mailing list?
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >
> >
> > Thomas Lumley			Assoc. Professor, Biostatistics
> > tlumley at u.washington.edu	University of Washington, Seattle
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle
-------------- next part --------------
# SCCS @(#)coxph.wtest.s	1.2 10/28/98
#
# A Wald test routine, used by the Cox model
#  Why not just do  sum(b * solve(var, b))? -- because the solve
#  function chokes on singular matrices.
#
coxph.wtest <- function(var, b, toler.chol=1e-9) {
    if (is.matrix(b)) {
        nvar <- nrow(b)
        ntest<- ncol(b)
        }
    else {
        nvar <- length(b)
        ntest<- 1
        }
    
    if (length(var)==1) {
        if (nvar ==1) return(list(test=b*b/var, df=1, solve=b/var))
        else stop("Argument lengths do not match")
    }

    if (length(var)==0){
        if (nvar==0) return(list(test=numeric(0),df=0,solve=0))
        else  stop("Argument lengths do not match")
    }


    if (!is.matrix(var) || (nrow(var) != ncol(var)))
            stop("First argument must be a square matrix")
    if (nrow(var) != nvar) stop("Argument lengths do not match")

    temp <- .C('coxph_wtest', df=as.integer(nvar),
                              as.integer(ntest),
                              as.double(var),
                              tests= as.double(b),
                              solve= double(nvar*ntest),
	                      as.double(toler.chol),
               PACKAGE="survival")
    if (ntest==1) list(test=temp$tests[1], df=temp$df, solve=temp$solve)
    else          list(test=temp$tests[1:ntest], df=temp$df, 
                       solve=matrix(temp$solve, nvar, ntest))
    }

From ivo_welch-rstat8783 at mailblocks.com  Fri Jul 30 01:37:35 2004
From: ivo_welch-rstat8783 at mailblocks.com (ivo_welch-rstat8783@mailblocks.com)
Date: Thu, 29 Jul 2004 16:37:35 -0700
Subject: [R] expression + paste + arguments + ...
In-Reply-To: <200407281007.i6SA4v2t005108@hypatia.math.ethz.ch>
References: <200407281007.i6SA4v2t005108@hypatia.math.ethz.ch>
Message-ID: <200407292337.i6TNbki3017354@hypatia.math.ethz.ch>


dear R wizards:  I would like to write a function that roughly places 
the equivalent of the following latex text into the current plot:

   \newcommand{ \placesigma }[4]{ \put(\#1,\#2){ \sigma_{A , #3} = #4 }

I cannot figure out how to do this.  I know I have to use a function 
that uses expressions in a text() invoke.  But passing arguments and 
nesting strings and expressions has so far not worked for me.  I hope 
this is an obvious question---if not, please just tell me and I can 
give up.  help appreciated.

sincerely,

/iaw



From p.connolly at hortresearch.co.nz  Fri Jul 30 02:24:20 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 30 Jul 2004 12:24:20 +1200
Subject: [R] Transparent backgrounds in png files
In-Reply-To: <Pine.LNX.4.44.0407290835410.1679-100000@gannet.stats>; from 
	ripley@stats.ox.ac.uk on Thu, Jul 29, 2004 at 08:38:23AM +0100
References: <20040729095926.W11533@hortresearch.co.nz> 
	<Pine.LNX.4.44.0407290835410.1679-100000@gannet.stats>
Message-ID: <20040730122420.Z11533@hortresearch.co.nz>

On Thu, 29-Jul-2004 at 08:38AM +0100, Prof Brian Ripley wrote:

|> The bitmap() device does not support transparency.  The png() device does.

Unfortunately, though png() does a fine job at a transparent
background, it's rather lumpy even on a screen.

|> 
|> On Thu, 29 Jul 2004, Patrick Connolly wrote:
|> 
[...]
 
|> > Mine is the reverse (and I'm using standard graphics, not Lattice).
|> > I'm trying to get a transparent background but it always comes out
|> > white.  Setting bg = "transparent", I've tried using a bitmap device
|> > to create a png file.  I've also tried creating a postscript file and
|> > converting it to a PNG file using the Gimp.  I've always used a
|> > resolution of 300 dpi in bitmaps since the default is far too low.
|> 
|> Really?  You want PNG files of 2000+ pixels in each dimension?  

Well, 300 dpi is somewhat excessive for onscreen, but not for printing
(more below).  For a screen at 1600 by 1200 resolution, a bitmap of
over 1000 pixels in either direction is not excessive.  Using a screen
rated at .25mm dot pitch, 75dpi is rather a lot less than sufficient.
According to my calculations, .25mm dot pitch corresponds to over 100
dpi, and a .27mm screen is over 90 dpi, so I don't get this 72
business.  Perhaps there's something I need to know.

Evidently, there's something others know that I don't since png()
generated files always turn out lumpy for me.  It's worse than the
unsatisfactory result of using PowerPoint's turning colours to
transparent method I mentioned.  People who are used to looking at TV
screens might not think it's low resolution, so perhaps I'm too fussy.

Maybe I should be more fussy about getting an exact ratio between the
number of pixels in the plotting device and the size of the image in
PowerPoint.  I'm somewhat confused by the fact that PP scales to fit
to the slide PNG files that I produce using the Gimp, but not ones
made using the png() method directly.  What is the essential
difference?


|> -- and you should not really be using bitmapped files for other
|> uses.)

Unfortunate as it may be, many people wish to put graphics in Word
files and don't like being unable to see their graphics on their
screen even if they have a postscript printer that could print them
perfectly.  That's where I use 300 dpi PNGs which print at least as
well as WMFs I've seen.

There was a recent discussion on this list about graphics using OSX
which covers most of the same thinking.  Nothing in that discussion
indicated to me a better way to get graphic files from Linux to Word.
If there are any, I'd like to know about them.


best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From chaochao.gao at gmail.com  Fri Jul 30 02:33:39 2004
From: chaochao.gao at gmail.com (Chaochao Gao)
Date: Thu, 29 Jul 2004 20:33:39 -0400
Subject: [R] Do I need a special package to call a fortran program within R?
Message-ID: <c23fbbe04072917331118836e@mail.gmail.com>

Hi, there,

I tried to use " system (command.txt)" to run a executive fortran code
(like a.out) within R. But the screen shows that " impossible to run"
this command. This is the first time I use R, so I was wondering if
there is a special package to run fortran program.  Any help will be
highly aprreciated.

Chaochao



From chaochao.gao at gmail.com  Fri Jul 30 02:33:39 2004
From: chaochao.gao at gmail.com (Chaochao Gao)
Date: Thu, 29 Jul 2004 20:33:39 -0400
Subject: [R] Do I need a special package to call a fortran program within R?
Message-ID: <c23fbbe04072917331118836e@mail.gmail.com>

Hi, there,

I tried to use " system (command.txt)" to run a executive fortran code
(like a.out) within R. But the screen shows that " impossible to run"
this command. This is the first time I use R, so I was wondering if
there is a special package to run fortran program.  Any help will be
highly aprreciated.

Chaochao



From kathryn.jones at jcu.edu.au  Fri Jul 30 03:02:47 2004
From: kathryn.jones at jcu.edu.au (Kathryn Jones)
Date: Fri, 30 Jul 2004 11:02:47 +1000
Subject: [R] getting values out of functions
Message-ID: <1d1de27.67c1c992.8236e00@mirapoint-ms1.jcu.edu.au>

Hi there,
Just wondering if there's a way to get a value you've 
assigned within a function, out of the function?
For example, 

function () 
{
	testing <-read.table("...",header=TRUE)
}

I want to be able to use 'testing' outside of the function, 
so be able to call ls() and testing be there...
Any ideas?
Thanks!
Kathryn



From spencer.graves at pdf.com  Fri Jul 30 03:15:11 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 29 Jul 2004 18:15:11 -0700
Subject: [R] expression + paste + arguments + ...
In-Reply-To: <200407292337.i6TNbki3017354@hypatia.math.ethz.ch>
References: <200407281007.i6SA4v2t005108@hypatia.math.ethz.ch>
	<200407292337.i6TNbki3017354@hypatia.math.ethz.ch>
Message-ID: <4109A11F.6060908@pdf.com>

      I don't know latex, but have you looked at "?plotmath", including 
'demo(plotmath)', the examples in the documentation, and an R site 
search suggested in the posting guide 
(http://www.R-project.org/posting-guide.html)?  What you want is 
probably fairly easy, once you parse the "plotmath" documentation.  hope 
this helps.  spencer graves

ivo_welch-rstat8783 at mailblocks.com wrote:

>
> dear R wizards:  I would like to write a function that roughly places 
> the equivalent of the following latex text into the current plot:
>
>   \newcommand{ \placesigma }[4]{ \put(\#1,\#2){ \sigma_{A , #3} = #4 }
>
> I cannot figure out how to do this.  I know I have to use a function 
> that uses expressions in a text() invoke.  But passing arguments and 
> nesting strings and expressions has so far not worked for me.  I hope 
> this is an obvious question---if not, please just tell me and I can 
> give up.  help appreciated.
>
> sincerely,
>
> /iaw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Fri Jul 30 03:21:05 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 Jul 2004 21:21:05 -0400
Subject: [R] getting values out of functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8148@usrymx25.merck.com>

> From: Kathryn Jones
> 
> Hi there,
> Just wondering if there's a way to get a value you've 
> assigned within a function, out of the function?
> For example, 
> 
> function () 
> {
> 	testing <-read.table("...",header=TRUE)
> }
> 
> I want to be able to use 'testing' outside of the function, 
> so be able to call ls() and testing be there...
> Any ideas?
> Thanks!
> Kathryn

Sure, by return()ing it in the last line of the function.

Alternatively, you can assign() to .GlobalEnv, but you really should avoid
doing that...

Andy



From spencer.graves at pdf.com  Fri Jul 30 03:22:50 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 29 Jul 2004 18:22:50 -0700
Subject: [R] getting values out of functions
In-Reply-To: <1d1de27.67c1c992.8236e00@mirapoint-ms1.jcu.edu.au>
References: <1d1de27.67c1c992.8236e00@mirapoint-ms1.jcu.edu.au>
Message-ID: <4109A2EA.5060100@pdf.com>

      Have you looked at "writing your own functions" in "An 
Introduction to R", downloadable from "www.r-project.org" -> 
Documentation:  Manuals?  If you want more than one object, you can 
return a list with all the objects you want as components;  see "lists 
and data frames" in the same manual. 

      hope this helps.  spencer graves
p.s. "PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html".  You may be able to find 
answers to questions like the quicker following this procedure, and your 
questions may be more likely to elicit more helpful responses. 

Kathryn Jones wrote:

>Hi there,
>Just wondering if there's a way to get a value you've 
>assigned within a function, out of the function?
>For example, 
>
>function () 
>{
>	testing <-read.table("...",header=TRUE)
>}
>
>I want to be able to use 'testing' outside of the function, 
>so be able to call ls() and testing be there...
>Any ideas?
>Thanks!
>Kathryn
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From rpeng at jhsph.edu  Fri Jul 30 03:24:39 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 29 Jul 2004 21:24:39 -0400
Subject: [R] getting values out of functions
In-Reply-To: <1d1de27.67c1c992.8236e00@mirapoint-ms1.jcu.edu.au>
References: <1d1de27.67c1c992.8236e00@mirapoint-ms1.jcu.edu.au>
Message-ID: <4109A357.50807@jhsph.edu>

You can use assign(), but why do you want to do this?  Also, a function 
always returns the last expression in the function body.  Or you can use 
return().

-roger

Kathryn Jones wrote:

> Hi there,
> Just wondering if there's a way to get a value you've 
> assigned within a function, out of the function?
> For example, 
> 
> function () 
> {
> 	testing <-read.table("...",header=TRUE)
> }
> 
> I want to be able to use 'testing' outside of the function, 
> so be able to call ls() and testing be there...
> Any ideas?
> Thanks!
> Kathryn
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Fri Jul 30 03:39:27 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 29 Jul 2004 18:39:27 -0700
Subject: [R] Any orthnormal matrix can keep the curve's shape and size
	unchnaged?
In-Reply-To: <200407292208.i6TM82iN000908@definetti.uark.edu>
References: <000401c475a7$dec92950$ab8d7ca5@FYOC1>
	<200407292208.i6TM82iN000908@definetti.uark.edu>
Message-ID: <4109A6CF.8080402@pdf.com>

  How do you define "size and shape"? The answer is probably yes. 
However, if you have an essentially 2-d circle embedded in a 3-d space, 
and "size and shape" are defined in terms of a 2-d projection, this 
circle could be rotated into an ellipse in any orientation and even to a 
line.

Also, if f is an N x d dimensional matrix approximating your object and 
A is a d x d orthogonal matrix, then I think your transformation in R 
would be written "f %*% A".

hope this helps. spencer graves

Giovanni Petris wrote:

>Any orthogonal transformation preserves angles between vectors and
>their length. Therefore, I guess shape and size are preserved -- of
>course a precise answer depends on how you define these two features
>of a curve. 
>
>I am missing what has all this to do with R, though.
>
>Giovanni
>
>  
>
>>Date: Thu, 29 Jul 2004 15:08:52 -0500
>>From: Fred <fzh113 at hecky.it.northwestern.edu>
>>Sender: r-help-bounces at stat.math.ethz.ch
>>Cc: 
>>Importance: Normal
>>Precedence: list
>>
>>Dear R users,
>> 
>>I want to know, given a curve f in d-dimensional space, 
>>It is possible to keep the curve?s shape and size unchanged by
>>an arbitrary dxd orthnormal matrix A?
>>That is, the new curve g = A*f is still the same shape and size as f?
>> 
>>Thanks for your advices and answers.
>> 
>> 
>>Fred
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
>>
>>    
>>
>
>  
>



From ggrothendieck at myway.com  Fri Jul 30 04:08:25 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 30 Jul 2004 02:08:25 +0000 (UTC)
Subject: [R] Editing Strings in R
References: <4CFC110AB744244C824D25E59665956C13DC69@ms-afit-04.afit.edu>
Message-ID: <loom.20040730T040320-263@post.gmane.org>

Bulutoglu Dursun A Civ AFIT/ENC <Dursun.Bulutoglu <at> afit.edu> writes:

> 
> 	I was wondering if there is a way of editting strings in R. I
> have a set of strings and each set is a row of numbers and paranthesis.
> 	For example the first row is: 
> 	(0 2)(3 4)(7 9)(5 9)(1 5)
> 	and I have a thousand or so such rows. I was wondering how I
> could get the corresponding string obtained by adding 1 to all the
> numbers in the string above.

First do the 1 character translations simultaneously using chartr and
then use gsub for the remaining one to two character translation:

gsub("0","10",chartr("0123456789","1234567890","(0 2)(3 4)(7 9)(5 9)(1 5)"))



From ggrothendieck at myway.com  Fri Jul 30 04:20:41 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 30 Jul 2004 02:20:41 +0000 (UTC)
Subject: [R] Stumped with subsetting
References: <54AB7E948D3B394BAC0B610DB2E606811B4EE8@pegasus.arcturus.local>
	<41093314.5000108@pdf.com>
	<6.0.3.0.0.20040729151052.01c42b80@pop.videotron.ca>
	<410951B6.1080207@pdf.com> <4109540A.6010304@pdf.com>
	<6.0.3.0.0.20040729160302.01c3bd80@pop.videotron.ca>
Message-ID: <loom.20040730T041835-812@post.gmane.org>

Peter Wilkinson <pwilkinson <at> videotron.ca> writes:

: 
: Hi there,
: 
: thanks for the reply. I was expecting what Tony posted. By the way I got 
: the format  for my question out of Introduction to R. So I expected it to 
: work as in the text, but it turns out ....
: 
: my "list" somehow was not a vector:
: 
:  > list[1]
: [1] PERH0125
: 44 Levels:  PERH0015 PERH0019 PERH0023 PERH0029 PERH0037 PERH0045 PERH0053 
: PERH0075 ... PERH0360
: 
: I did the following:
: 
:  > list2 = as.vector(list)
:  > list2
:   [1] "PERH0125" "PERH0315" "PERH0161" "PERH0181" "PERH0229" "PERH0223" 
: "PERH0243" "PERH0269"
:   <snip>
: 
: I am not sure what format list was in (looks like factor), but I turned it 
: into a vector and it worked as expected. I have to go back and see how I 
: created list in the first place.
: 
: originally I took a row from a data frame, removed NA values, then sorted 
: it into an order that I wanted (using 'order') .... so I don't know when it 
: turned into something that looked like factor. Any ?

read.table will read characters in as factors unless you specify otherwise.
See ?read.table and the as.is= argument in particular.



From MSchwartz at MedAnalytics.com  Fri Jul 30 04:36:14 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 29 Jul 2004 21:36:14 -0500
Subject: [R] Editing Strings in R
In-Reply-To: <loom.20040730T040320-263@post.gmane.org>
References: <4CFC110AB744244C824D25E59665956C13DC69@ms-afit-04.afit.edu>
	<loom.20040730T040320-263@post.gmane.org>
Message-ID: <1091154974.23861.324.camel@localhost.localdomain>

On Thu, 2004-07-29 at 21:08, Gabor Grothendieck wrote:
> Bulutoglu Dursun A Civ AFIT/ENC <Dursun.Bulutoglu <at> afit.edu> writes:
> 
> > 
> > 	I was wondering if there is a way of editting strings in R. I
> > have a set of strings and each set is a row of numbers and paranthesis.
> > 	For example the first row is: 
> > 	(0 2)(3 4)(7 9)(5 9)(1 5)
> > 	and I have a thousand or so such rows. I was wondering how I
> > could get the corresponding string obtained by adding 1 to all the
> > numbers in the string above.
> 
> First do the 1 character translations simultaneously using chartr and
> then use gsub for the remaining one to two character translation:
> 
> gsub("0","10",chartr("0123456789","1234567890","(0 2)(3 4)(7 9)(5 9)(1 5)"))


Gabor, 

One problem:  Multi-digit numbers in the source string:

> gsub("0","10",chartr("0123456789","1234567890",
       "(10 99)(3 4)(7 9)(5 9)(1 5)"))
[1] "(21 1010)(4 5)(8 10)(6 10)(2 6)"


Note the first number "10" gets transformed to "21" and the "99" goes to
"1010".


I made a quick update to NewRow, which is not faster, but gets it to two
lines, instead of three, and is a bit cleaner:

NewRow <- function(x)
{
  TempMat <- matrix(as.numeric(unlist(strsplit(x, "([\\(\\) ])"))), 
                    ncol = 3, byrow = TRUE) + 1

  paste("(", TempMat[, 2], " ", TempMat[, 3], ")", sep = "", 
        collapse = "")
}


Note that with multi digit numbers, it gives a correct result:

> NewRow("(10 99)(101 4)(7 9)(5 9)(1 5)")
[1] "(11 100)(102 5)(8 10)(6 10)(2 6)"


HTH,

Marc Schwartz



From ggrothendieck at myway.com  Fri Jul 30 05:25:24 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 30 Jul 2004 03:25:24 +0000 (UTC)
Subject: [R] Editing Strings in R
References: <4CFC110AB744244C824D25E59665956C13DC69@ms-afit-04.afit.edu>
	<loom.20040730T040320-263@post.gmane.org>
	<1091154974.23861.324.camel@localhost.localdomain>
Message-ID: <loom.20040730T044712-397@post.gmane.org>

Marc Schwartz <MSchwartz <at> MedAnalytics.com> writes:

> 
> On Thu, 2004-07-29 at 21:08, Gabor Grothendieck wrote:
> > Bulutoglu Dursun A Civ AFIT/ENC <Dursun.Bulutoglu <at> afit.edu> writes:
> > 
> > > 
> > > 	I was wondering if there is a way of editting strings in R. I
> > > have a set of strings and each set is a row of numbers and paranthesis.
> > > 	For example the first row is: 
> > > 	(0 2)(3 4)(7 9)(5 9)(1 5)
> > > 	and I have a thousand or so such rows. I was wondering how I
> > > could get the corresponding string obtained by adding 1 to all the
> > > numbers in the string above.
> > 
> > First do the 1 character translations simultaneously using chartr and
> > then use gsub for the remaining one to two character translation:
> > 
> > gsub("0","10",chartr("0123456789","1234567890","(0 2)(3 4)(7 9)(5 9)(1 
5)"))
> 
> Gabor, 
> 
> One problem:  Multi-digit numbers in the source string:
> 
> > gsub("0","10",chartr("0123456789","1234567890",
>        "(10 99)(3 4)(7 9)(5 9)(1 5)"))
> [1] "(21 1010)(4 5)(8 10)(6 10)(2 6)"
> 
> Note the first number "10" gets transformed to "21" and the "99" goes to
> "1010".
> 
> I made a quick update to NewRow, which is not faster, but gets it to two
> lines, instead of three, and is a bit cleaner:
> 
> NewRow <- function(x)
> {
>   TempMat <- matrix(as.numeric(unlist(strsplit(x, "([\\(\\) ])"))), 
>                     ncol = 3, byrow = TRUE) + 1
> 
>   paste("(", TempMat[, 2], " ", TempMat[, 3], ")", sep = "", 
>         collapse = "")
> }
> 
> Note that with multi digit numbers, it gives a correct result:
> 
> > NewRow("(10 99)(101 4)(7 9)(5 9)(1 5)")
> [1] "(11 100)(102 5)(8 10)(6 10)(2 6)"

The above assumes a particular pattern of parentheses, based on
the poster's example, just as mine assumed one digit numbers based
on the poster's example.  Both our examples assume the numbers
are non-negative integers.

The poster can advise us on which additional assumptions, if any,
are allowable but, just in case, here is a one line solution that 
handles multi-digit numbers and does not assume a particular pattern 
of parentheses and spaces.

For a number, say 99, the gsub replaces it with ",99+1," and
the inner paste adds c(" to the front and ") to the end making it
a valid R expression which we then evaluate and finally paste back
together using the outer paste:

R> line <- "(10 99)(101 4)(7 9)()((5 9)(1 5))"  # test data

R> paste(eval(parse(text = paste('c("', gsub("([0-9]+)", '",\\1+1,"', line, 
ext = TRUE), '")', sep = ""))), collapse = "")

[1] "(11 100)(102 5)(8 10)()((6 10)(2 6))"



From MSchwartz at MedAnalytics.com  Fri Jul 30 05:34:32 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 29 Jul 2004 22:34:32 -0500
Subject: [R] Transparent backgrounds in png files
In-Reply-To: <20040730122420.Z11533@hortresearch.co.nz>
References: <20040729095926.W11533@hortresearch.co.nz>
	<Pine.LNX.4.44.0407290835410.1679-100000@gannet.stats>
	<20040730122420.Z11533@hortresearch.co.nz>
Message-ID: <1091158472.23861.375.camel@localhost.localdomain>

On Thu, 2004-07-29 at 19:24, Patrick Connolly wrote:
> On Thu, 29-Jul-2004 at 08:38AM +0100, Prof Brian Ripley wrote:
> 
> |> The bitmap() device does not support transparency.  The png() device does.
> 
> Unfortunately, though png() does a fine job at a transparent
> background, it's rather lumpy even on a screen.
> 
> |> 
> |> On Thu, 29 Jul 2004, Patrick Connolly wrote:
> |> 
> [...]
>  
> |> > Mine is the reverse (and I'm using standard graphics, not Lattice).
> |> > I'm trying to get a transparent background but it always comes out
> |> > white.  Setting bg = "transparent", I've tried using a bitmap device
> |> > to create a png file.  I've also tried creating a postscript file and
> |> > converting it to a PNG file using the Gimp.  I've always used a
> |> > resolution of 300 dpi in bitmaps since the default is far too low.
> |> 
> |> Really?  You want PNG files of 2000+ pixels in each dimension?  
> 
> Well, 300 dpi is somewhat excessive for onscreen, but not for printing
> (more below).  For a screen at 1600 by 1200 resolution, a bitmap of
> over 1000 pixels in either direction is not excessive.  Using a screen
> rated at .25mm dot pitch, 75dpi is rather a lot less than sufficient.
> According to my calculations, .25mm dot pitch corresponds to over 100
> dpi, and a .27mm screen is over 90 dpi, so I don't get this 72
> business.  Perhaps there's something I need to know.
> 
> Evidently, there's something others know that I don't since png()
> generated files always turn out lumpy for me.  It's worse than the
> unsatisfactory result of using PowerPoint's turning colours to
> transparent method I mentioned.  People who are used to looking at TV
> screens might not think it's low resolution, so perhaps I'm too fussy.
> 
> Maybe I should be more fussy about getting an exact ratio between the
> number of pixels in the plotting device and the size of the image in
> PowerPoint.  I'm somewhat confused by the fact that PP scales to fit
> to the slide PNG files that I produce using the Gimp, but not ones
> made using the png() method directly.  What is the essential
> difference?
> 
> 
> |> -- and you should not really be using bitmapped files for other
> |> uses.)
> 
> Unfortunate as it may be, many people wish to put graphics in Word
> files and don't like being unable to see their graphics on their
> screen even if they have a postscript printer that could print them
> perfectly.  That's where I use 300 dpi PNGs which print at least as
> well as WMFs I've seen.
> 
> There was a recent discussion on this list about graphics using OSX
> which covers most of the same thinking.  Nothing in that discussion
> indicated to me a better way to get graphic files from Linux to Word.
> If there are any, I'd like to know about them.

Patrick,

Are the Windows recipients of the R graphics involved in
creating/editing the resultant documents, or do they simply require
"read only" access of a final document?

If the latter, then let me suggest that you generate EPS based graphics
in R (for which you can specify height and width arguments in inches as
required). Import those EPS graphics into OO.org's Impress (PP-alike) or
Writer (Word-alike). Then print the file to a PS file and then use
ps2pdf to create a PDF version of the document that the recipients can
view in Acrobat Reader.

If the former, as I believe Frank Harrell noted here some time back, the
recent versions of Word and Powerpoint will create bitmapped previews of
the EPS files upon import. While they are not a high quality image (and
do add to filesize notably), they at least enable the users of the
documents to preview the image for placement/sequencing. They can then
print them to a PS file or if they have the purchased Adobe add-ins,
could print them to a PDF file on their own for viewing in Acrobat.

The major problem with bitmapped images (as has been mentioned here ad
nauseum) is that they do not resize well and what you see on the screen
does not always translate into a quality image when enlarged or sent to
a printer. This is why vector based graphics (such as WMF/EMF, EPS, PDF
and SVG) are preferred. Bitmapped image files also end up being quite
large, whereas EPS files (since they are text files) are relatively
small.

It is not a solution today, but as SVG based graphics become more
available on multiple platforms, that format will probably emerge as the
preferred means of sharing such files. WMF/EMF are limited to Windows as
a realistic option. There is the libEMF library available under Linux,
but from personal experience, it is not a viable option.

HTH,

Marc Schwartz



From John.Field at adelaide.edu.au  Fri Jul 30 07:19:52 2004
From: John.Field at adelaide.edu.au (John Field)
Date: Fri, 30 Jul 2004 14:49:52 +0930
Subject: [R] Scatter plot matrix over several pages
Message-ID: <6.1.1.1.2.20040730143931.08119f28@pop.ozemail.com.au>

Hello R-helpers,

I'm plotting a scatter plot matrix, but have more variables to consider 
than will legibly fit on one page.  I'd appreciate some help on how I can 
persuade pairs or splom to plot the full matrix of plots over several pages.

With thanks,
John Field



From ligges at statistik.uni-dortmund.de  Fri Jul 30 08:46:27 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jul 2004 08:46:27 +0200
Subject: [R] Do I need a special package to call a fortran program within
	R?
In-Reply-To: <c23fbbe04072917331118836e@mail.gmail.com>
References: <c23fbbe04072917331118836e@mail.gmail.com>
Message-ID: <4109EEC3.80704@statistik.uni-dortmund.de>

Chaochao Gao wrote:

> Hi, there,
> 
> I tried to use " system (command.txt)" to run a executive fortran code
> (like a.out) within R. But the screen shows that " impossible to run"
> this command. This is the first time I use R, so I was wondering if
> there is a special package to run fortran program.  Any help will be
> highly aprreciated.

What is command.txt? Does it inhertit the call of any executable? Or 
does it inherit fortran code?
If the latter, please read the mnaual "Writing R Extensions", if the 
former, please read ?system. (BTW: which OS, which version of R?)

Uwe Ligges

> Chaochao
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Jul 30 09:00:51 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jul 2004 09:00:51 +0200
Subject: [R] expression + paste + arguments + ...
In-Reply-To: <200407292337.i6TNbki3017354@hypatia.math.ethz.ch>
References: <200407281007.i6SA4v2t005108@hypatia.math.ethz.ch>
	<200407292337.i6TNbki3017354@hypatia.math.ethz.ch>
Message-ID: <4109F223.7080403@statistik.uni-dortmund.de>

ivo_welch-rstat8783 at mailblocks.com wrote:

> 
> dear R wizards:  I would like to write a function that roughly places 
> the equivalent of the following latex text into the current plot:
> 
>   \newcommand{ \placesigma }[4]{ \put(\#1,\#2){ \sigma_{A , #3} = #4 }

???
You are "just" defining a new LaTeX command ... nothing will be printed 
in LaTeX.


Instead of using \put, you can specify coordinates as usual in R using 
text(), title() or mtext().
Instead of "\sigma_{A , #3} = #4", you can use

   substitute(sigma[v3] == v4, list(v3 = paste("A,",v3), v4 = v4))

which leads to, e.g.

   plot(1:10)
   v3 <- 99
   v4 <- 55
   text(4, 1, label = substitute(sigma[v3] == v4,
                  list(v3 = paste("A,",v3), v4 = v4)))

See also ?plotmath and the R Help Desk Column in R News 2 (3).

Uwe Ligges


> I cannot figure out how to do this.  I know I have to use a function 
> that uses expressions in a text() invoke.  But passing arguments and 
> nesting strings and expressions has so far not worked for me.  I hope 
> this is an obvious question---if not, please just tell me and I can give 
> up.  help appreciated.
> 
> sincerely,
> 
> /iaw
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From hb at maths.lth.se  Fri Jul 30 09:16:27 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 30 Jul 2004 09:16:27 +0200
Subject: [R] unwanted as.integer
In-Reply-To: <41097228.6020906@hotmail.com>
Message-ID: <002f01c47605$21df4190$01000001@hblaptop>

I suspect sqlQuery() returns a data frame, is that correct? Then try to
convert it into a matrix before you paste() it. Example:

> x <- data.frame(a=1:3, b=1:3+0.5)
> as.character(x)
[1] "as.integer(c(1, 2, 3))" "c(1.5, 2.5, 3.5)"
> as.character(as.matrix(x))
[1] "1"   "2"   "3"   "1.5" "2.5" "3.5"

If it returns a list you can do:

> x <- list(a=1:3, b=1:3+0.5)
> as.character(x)
[1] "as.integer(c(1, 2, 3))" "c(1.5, 2.5, 3.5)"      
> lapply(x, FUN=as.character)
$a
[1] "1" "2" "3"

$b
[1] "1.5" "2.5" "3.5"

Hope this helps

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jack Tanner
> Sent: Thursday, July 29, 2004 11:55 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] unwanted as.integer
> 
> 
>  > a <- sqlQuery(irrdb, "select count(field) from mytable 
> where field = 1")  > print(a)
>   count(field)
> 1            8
>  > paste(a)
> [1] "as.integer(8)"
> 
> Why the as.integer() representation? I later pass the result 
> into this 
> write.html.table(), and what I get is rows of as.integer()... 
> when all I 
> want is the integer itself.
> 
> as.integer(31) 	as.integer(21) 	as.integer(34) 	as.integer(86)
> as.integer(7) 	as.integer(6) 	as.integer(15) 	as.integer(28)
> 
> 
> write.html.table <- function(t, file= "", capt= "The Default Title",
>                             append = FALSE) {
>   head <- paste("<table>\n<caption>", capt, "</caption>\n")
>   cat(head, file= file, append= append)
>   if (is.null(rownames(t))) {
>     rownames(t) <- rep("", nrow(t))
>   }
>   tp <- rbind(c("<tr><td></td>", colnames(t)),
>               cbind(unlist(lapply(rownames(t), function(x) {
>                 paste("<tr><td>", x)})), t))
>   write.table(tp, sep= "<td>", file= file, , eol= "</tr>\n",
>               row.names=FALSE,
>               col.names=FALSE,
>               append=TRUE, quote=FALSE)
>   cat("</tr>\n</table>\n", file= file, append= TRUE)
> }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Jul 30 09:35:51 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jul 2004 09:35:51 +0200
Subject: [R] perl script in exec/
In-Reply-To: <200407292046.i6TKkGK25847@tomservo.mayo.edu>
References: <200407292046.i6TKkGK25847@tomservo.mayo.edu>
Message-ID: <4109FA57.1070802@statistik.uni-dortmund.de>

Jason Sinnwell wrote:

> Dear useRs-
> 
> I am developing a package that uses output from stand-alone unix software 
> programs.  I use multiple perl scripts to process the output and make it ready 
> for reading into R.  I would like to keep the perl scripts in the designated 
> place for such files, exec/, but I can't find how a user is supposed to be able 
> to use those when using the library.   


   file.path(.path.package("NameOfThePackage"),
             "exec", "NameOfThePerlScript")

Uwe Ligges


> R-exts 1.1.4: 
> ..'exec/' could contain additional executables the package needs, ...  This 
> mechanism is currently used only by very few packages, and still experimental.  
> 
> Any help or referral to the proper documentation would be appreciated.  
> 
> Jason
> 
> +--------------------------+
> |Jason P. Sinnwell, M.S.   |
> |Mayo Clinic, Rochester    |
> |Health Sciences Research  |
> |Division of Biostatistics |
> |Harwick 7-97		   |
> |507.284.3270              |
> +--------------------------+
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From t.dewez at brgm.fr  Fri Jul 30 11:37:32 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Fri, 30 Jul 2004 11:37:32 +0200
Subject: [R] using Rterm under cygwin, no possiblity to delete characters
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD689F@SRV0015>

Dear R-users,

Thanks to Roger Bivand, it appears that the real problem is coming from the
way R talks to X11 under cygwin. Both other invocations of Rterm, either in
a bash window without Xwindow capability or from the DOS command, work just
fine.

Rterm breaks down every time it is invoked from a bash shell inside an
Xwindow session. The symptoms are the following:
+ No popup window appears when invoking help() or plot() commands
+ Instead, the Windows task bar shows an R icon, but this icon cannot be
restore to full screen
+ Rterm dies when hitting return after correcting typos
the error message then is:
---
Error: syntax error
Execution halted
---

This suggests that Rterm is by-passing fvwm2 and the X11 environment to talk
to windows directly. This is also probably the reason why terminal
properties are forgotten when just using Rterm for typing commands. It
forgets that it was invoked from bash and responds to all the keys pressed.
If typos are corrected with backspace, Rterm reads is a gibberish string
made of printable and non printable characters causing it to misunderstand
the command and fail.

Any clues as to what I should do? I insist on using R in an Xwindow session
because I want to take advantage of the R/GRASS module and compute stats on
GIS layers.

Cheers,

Thomas
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
(des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
 e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
v??rifier l'absence de corruption ?? sa r??ception.

The contents of this email and any attachments are confidential. They are intended for 
the named recipient(s) only. If you have received this email in error please notify the 
system manager or  the sender immediately and do not disclose the contents to 
anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
content.
***



From Roger.Bivand at nhh.no  Fri Jul 30 12:04:50 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 30 Jul 2004 12:04:50 +0200 (CEST)
Subject: [R] using Rterm under cygwin, no possiblity to delete  characters
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD689F@SRV0015>
Message-ID: <Pine.LNX.4.44.0407301154390.17733-100000@reclus.nhh.no>

On Fri, 30 Jul 2004, Dewez Thomas wrote:

> Dear R-users,
> 
> Thanks to Roger Bivand, it appears that the real problem is coming from the
> way R talks to X11 under cygwin. Both other invocations of Rterm, either in
> a bash window without Xwindow capability or from the DOS command, work just
> fine.
> 
> Rterm breaks down every time it is invoked from a bash shell inside an
> Xwindow session. The symptoms are the following:
> + No popup window appears when invoking help() or plot() commands
> + Instead, the Windows task bar shows an R icon, but this icon cannot be
> restore to full screen
> + Rterm dies when hitting return after correcting typos
> the error message then is:
> ---
> Error: syntax error
> Execution halted
> ---
> 
> This suggests that Rterm is by-passing fvwm2 and the X11 environment to talk
> to windows directly. This is also probably the reason why terminal
> properties are forgotten when just using Rterm for typing commands. It
> forgets that it was invoked from bash and responds to all the keys pressed.
> If typos are corrected with backspace, Rterm reads is a gibberish string
> made of printable and non printable characters causing it to misunderstand
> the command and fail.
> 
> Any clues as to what I should do? I insist on using R in an Xwindow session
> because I want to take advantage of the R/GRASS module and compute stats on
> GIS layers.

I'm afraid that this is close to impossible. Rterm will run for the 
Generic GRASS Cygwin version (I have tried with GRASS 5.0.2), but 
not pretending to do X11 under Cygwin. Note also that Glynn Clements has 
commented on the GRASS developers list that X11 Cygwin for the GRASS 5.7 
"new generation" beta is very untried and highly risky in any case.

Can you try to run what you need using generic when you need R, and revert
to X11 when you don't need R? Then you can control the interaction between
the different parts of your software without having them all trying to run
at once.

This is really a GRASS development issue for Cygwin users, since it is 
known that R under Windows and Cygwin are not compatible, and that R for 
Windows is only for Windows (as the name suggests).

Roger


> 
> Cheers,
> 
> Thomas
> ***
> Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
> (des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
>  e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
> L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
> v??rifier l'absence de corruption ?? sa r??ception.
> 
> The contents of this email and any attachments are confidential. They are intended for 
> the named recipient(s) only. If you have received this email in error please notify the 
> system manager or  the sender immediately and do not disclose the contents to 
> anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
> content.
> ***
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From p.dalgaard at biostat.ku.dk  Fri Jul 30 12:10:19 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Jul 2004 12:10:19 +0200
Subject: [R] using Rterm under cygwin, no possiblity to delete characters
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD689F@SRV0015>
References: <D965434E9D6BD511AE3500306E01C8BE05DD689F@SRV0015>
Message-ID: <x2n01hdcvo.fsf@biostat.ku.dk>

Dewez Thomas <t.dewez at brgm.fr> writes:

> + Rterm dies when hitting return after correcting typos
> the error message then is:
> ---
> Error: syntax error
> Execution halted
> ---
> 
> This suggests that Rterm is by-passing fvwm2 and the X11 environment to talk
> to windows directly. This is also probably the reason why terminal
> properties are forgotten when just using Rterm for typing commands. It
> forgets that it was invoked from bash and responds to all the keys pressed.
> If typos are corrected with backspace, Rterm reads is a gibberish string
> made of printable and non printable characters causing it to misunderstand
> the command and fail.

One might also suspect that Rterm does not realize that it is being
run interactively. Will it halt on *all* syntax errors? (e.g. a line
with a single left parenthesis). This doesn't really have anything to
do with bash or the window manager, only whether R uses the readline
interface (which it probably will not if it isn't interactive). 

Which sort of terminal window are you running from?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Jordi.Molins at drkw.com  Fri Jul 30 14:04:30 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Fri, 30 Jul 2004 14:04:30 +0200
Subject: [R] a question about identify and locator
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCD99@ibfftce121.de.ad.drkw.net>


Hello,

I use R 1.9.1 on Windows 2000. I have a chart that I am looking. I use
identify() and locator() to find out the (x,y) values of interesting points
in the chart, but these functions are not always helpful (e.g., sometimes
identify() prints on top of the chart, making the number illegible). What I
would be interested in is in a functionality that identifies the (x,y) point
using something like a text box superimposed on the chart that disappears
when the cursor is away from the chart (for example, similar to Excel) or
even better, small text boxes located both in the x and y axis near to the
points (0,y) and (x,0), resp., that are constantly updated (like charts in
Bloomberg) .

Is there something like this in R? 

Thank you

Jordi



--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From stephan.moratti at uni-konstanz.de  Fri Jul 30 14:29:46 2004
From: stephan.moratti at uni-konstanz.de (Stephan Moratti)
Date: Fri, 30 Jul 2004 14:29:46 +0200
Subject: [R] lme: problems with corARMA
Message-ID: <3.0.5.32.20040730142946.00ad7608@popserver.uni-konstanz.de>


Trying following example from Pinheiro and Bates in order to fit an
ARMA(1,1) model:

library(nlme)
fm1Ovary.lme<-lme(follicles~sin(2*pi*Time)+cos(*pi*Time),data=Ovary,random=p
dDiag(~sin(2*pi*Time)))
fm5Ovary.lme<-update(fm1Ovary.lme,corr=corARMA(p=1,q=1))

I get follwing error message:

Error in "coef<-.corARMA"(`*tmp*`, value = c(62.3428455941166,
62.3428517930051 : 
        Coefficient matrix not invertible

Does somebody know why it doesn't work ?

Stephan Moratti



-----------------------------
Dipl. Psych. Stephan Moratti
Dept. of Psychology
University of Konstanz
P.O Box D25
Phone: +40 (0)7531 882385
Fax: +49 (0)7531 884601
D-78457 Konstanz, Germany

e-mail: Stephan.Moratti at uni-konstanz.de
http://www.clinical-psychology.uni-konstanz.de/



From hmmunro at umich.edu  Fri Jul 30 14:39:16 2004
From: hmmunro at umich.edu (hmmunro@umich.edu)
Date: Fri, 30 Jul 2004 08:39:16 -0400
Subject: [R] classification trees
Message-ID: <1091191156.410a4174cc594@mail.umich.edu>

I'm working with S-Plus 6 in Windows.  Does anyone know if the prune.tree or
prune.misclass function automatically cross-validates or do you have to use
cv.tree if you want to do cross-validation?

Heather



From Camarda at demogr.mpg.de  Fri Jul 30 15:41:27 2004
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Fri, 30 Jul 2004 15:41:27 +0200
Subject: [R] optimisation procedure with flat log-likelihood
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D8106B40FFE@hermes.demogr.mpg.de>

Dear R-friends,
I use

optim(par=c(mystartingpoints), fn=myloglikelihoodfunction, gr=NULL,
                    method=c("L-BFGS-B"),  ## I would like to do not use any
bounds
                    control=list(trace=6, ## just to see what it's going on
                                 maxit=c(20000)), ## to be sure the it
doesn't stop reaching the max iterations
                    data=mydataset)

to optimize some demographic model. I assume that the log-likelihood is
relatively flat because the estimated results are very similar to my
starting values. In addition, I know the "real" parameters as I have used
simulated data (which have been also found by using GAUSS and replicated by
it).
I already tried various methods and also various starting values but it did
not help. Can maybe anyone give me some suggestion what I could do?

Thanks,
Carlo Giovanni Camarda



+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From jmc at research.bell-labs.com  Fri Jul 30 15:46:38 2004
From: jmc at research.bell-labs.com (John Chambers)
Date: Fri, 30 Jul 2004 09:46:38 -0400
Subject: [R] Debug S4 Methods
References: <4108E142.2040808@gunnarwrobel.de>
Message-ID: <410A513E.75969855@research.bell-labs.com>

Gunnar Wrobel wrote:
> 
> Dear list,
> 
> is there any way to debug the S4 methods using the debug() function in
> R1.9.1?
> 
> I am able to use browser() inside a S4 method but I wondered if there is
> a way to debug the function without recompiling the package.

Yes.  Use the trace() function to insert calls to browser or other
debugging code into the method.

trace() takes an argument signature= corresponding to the signature in
the call to setMethod for the method you want to debug.

See the documentation for trace.

As an example, if you had set methods for plot as in the example of the
setMethod documentation, the following will insert  calls to browser in
the plot method shown, one call on entry and one on exit:

R> setMethod("plot", signature(x = "track", y = "missing"), 
  ......

R> trace("plot", browser, exit=browser, signature = c("track",
"missing"))
R> plot(t1)
Tracing plot(t1) on entry 
Called from: plot(t1)
Browse[1]> objects()
[1] "x" "y"
   ....

As an alternative to browser, the function recover works well with
trace(), if you want to browse in other calls in addition to the method
itself.  You might also experiment with options(error=recover).


> 
> Thanks!
> 
> Gunnar
> 
> --
> ----------------------------------------------
> Dr. Gunnar Wrobel
> 
> Divisions of Bioinformatics and Biochemistry
> Swiss Institute of Bioinformatics/Biozentrum
> Klingelbergstrasse 50/70
> CH-4056 Basel / Switzerland
> Tel.: +41 61 267 1579
> Fax:  +41 61 267 3398
> e-mail: work at gunnarwrobel.de
> e-mail: gunnar.wrobel at unibas.ch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From tobias.verbeke at bivv.be  Fri Jul 30 15:54:31 2004
From: tobias.verbeke at bivv.be (tobias.verbeke@bivv.be)
Date: Fri, 30 Jul 2004 15:54:31 +0200
Subject: [OT] Re: [R] Transparent backgrounds in png files
In-Reply-To: <1091158472.23861.375.camel@localhost.localdomain>
Message-ID: <OF3CAC6B22.79102B01-ONC1256EE1.004B27C0-C1256EE1.004C6729@BIVV.BE>







r-help-bounces at stat.math.ethz.ch wrote on 30/07/2004 05:34:32:

<snip>

> Are the Windows recipients of the R graphics involved in
> creating/editing the resultant documents, or do they simply require
> "read only" access of a final document?
>
> If the latter, then let me suggest that you generate EPS based graphics
> in R (for which you can specify height and width arguments in inches as
> required). Import those EPS graphics into OO.org's Impress (PP-alike) or
> Writer (Word-alike). Then print the file to a PS file and then use
> ps2pdf to create a PDF version of the document that the recipients can
> view in Acrobat Reader.

A more direct way than printing to .ps and converting with ps2pdf
could be to use the extendedPDF macros for OOo
(http://www.jdisoftware.co.uk/pages/epdf-home.php) which basically
does the same but can sit there as a button on your taskbar.
Moreover, extendedPDF allows to use `real' PDF hyperlinks and
PDF bookmarks. Unfortunately (as Marc Schwarz told me), extendedPDF
may not work on all Linux distro's (e.g. not on FC2 as FC people work
towards integrating OOo printing with CUPS and do not ship an OOo print
admin program anymore).

Best regards,
Tobias



From t.dewez at brgm.fr  Fri Jul 30 15:43:58 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Fri, 30 Jul 2004 15:43:58 +0200
Subject: [R] using Rterm under cygwin, no possiblity to delete   characters
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD68A4@SRV0015>

Dear all again,

Here is a wrap-up of the fact finding mission Roger and I led over the last
two days (see his reply below my email).

The issue was the following:
---------------------------
1. Rterm breaks down when invoked from Xwindow under Cygwin. This is a
typical Cygwin problem and does not seem to occur on other Unix/Linux
systems.

2. Rterm breaking down in Xwindow had implications for using the R/GRASS
interface. R/GRASS would die as soon as an unrecognized function was
entered.

Solution
--------
1. To execute Rterm in the Cygwin environment, use a terminal window (bash
in my case) directly under windows and NOT in an Xwindow environment.
Running Rterm under Xwindow is the cause of the problem.



2. For subsequent questions concerning R/Grass interface. I sucessfully
managed to run Rterm within GRASS in the following manner:
1. Start an Xwindow session
2. Back in Windows, start a bash terminal window (the bright green and black
icon)
3. Start GRASS in this new bash window (see below for setting this up
correctly)
4. Inside GRASS start Rterm (type just Rterm at the prompt)

If you call the help and graphics functions of R, new R windows will pop up
in Windows, and if you want graphics display for GRASS (e.g. d.mon start=x0;
d.rast myGISlayer), they will appear in the Xwindow session. This is a
hybrid system but it seems to work.

To make sure that GRASS runs inside the bash terminal window, alter the
GRASS_GUI setting of the file .grassrc57 (it is to be found in the directory
that cygwin recognises as your home). In .grassrc57, there is a setting
called GRASS_GUI and usually set to tcltk
GRASS_GUI: tcltk
The option we want is "text" instead of "tcltk"
With this setting you will be able to operate GRASS with command lines in
the bash terminal and see graphics output displayed in the Xwindow session.

By the way, invoking Grass in the terminal also seems to work in GRASS57. I
didn't do anything else than install the precompiled binaries for Windows
following the recommended procedure.

Inside the R/GRASS interface, I stumbled on other problems (concerning
gmeta() command failing to find mapsets). I still need to figure this out.

More later and thank you very much for the brilliant help!

Thomas




> -----Message d'origine-----
> De: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Date: vendredi 30 juillet 2004 13:26
> ??: Dewez Thomas
> Objet: RE: [R] using Rterm under cygwin, no possiblity to delete
> characters
> 
> 
> Thomas,
> 
> Yes and no. I'm refering to 
> 
> http://grass.itc.it/grass50/binary/windows_cygnus/wingrass_generic/
> 
> which appears to have stopped at 5.0.2. Subsequent Cygwin 
> compiles: 5.0.3, 
> 5.3, and 5.7 all require an X-server for the d.* commands. 
> The question is 
> whether you can run the GRASS programs that do not need a 
> running X-server 
> under Cygwin under straight Windows (Cygwin bash running in a Windows 
> command line window, I think). I also think Peter Dalgaard is 
> right that 
> Rterm expects to be used as batch, rather than interactively, 
> and will 
> then halt at errors (although I have run it interactively 
> from a Windows 
> command line window and within Cygwin bash). I think you will make 
> progress if you can avoid all graphics (X11) in using the R/GRASS 
> interface, and not using an X11 windows manager, just 
> straight Windows.
> 
> It would be useful to document this, as other people are 
> likely to run 
> into this trying to run the interface on 5.7 under Cygwin.
> 
> Best wishes,
> 
> Roger
> 
> On Fri, 30 Jul 2004, Dewez Thomas wrote:
> 
> > Roger,
> > 
> > Not sure to understand you statement
> > > Rterm will run for the 
> > > Generic GRASS Cygwin version (I have tried with GRASS 5.0.2), but 
> > > not pretending to do X11 under Cygwin. 
> > 
> > This may be the solution, but how does one run Generic 
> GRASS cygwin? Can you
> > call display procedures with commands like: d.mon start=x0 
> ; d.his h_map=dem
> > i_map=slope? I am confused about this and always assumed 
> that Grass needed
> > to be inside an Xwindow session to use graphics displays.
> > 
> > Your suggestion will probably save my day if you could just 
> precise it a
> > little. Thanks!
> > 
> > Thomas
> > ***
> > Le contenu de cet e-mail et de ses pi??ces jointes est 
> destin?? ?? l'usage exclusif du 
> > (des) destinataire(s) express??ment d??sign??(s) comme tel(s). 
> En cas de r??ception de cet 
> >  e-mail par erreur, le signaler ?? son exp??diteur et ne pas 
> en divulguer le contenu. 
> > L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. 
> Il convient n??anmoins de 
> > v??rifier l'absence de corruption ?? sa r??ception.
> > 
> > The contents of this email and any attachments are 
> confidential. They are intended for 
> > the named recipient(s) only. If you have received this 
> email in error please notify the 
> > system manager or  the sender immediately and do not 
> disclose the contents to 
> > anyone or make copies. eSafe scanned this email for 
> viruses, vandals and malicious 
> > content.
> > ***
> > 
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, 
> Norwegian School of
> Economics and Business Administration, Breiviksveien 40, 
> N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
> e-mail: Roger.Bivand at nhh.no
> 
> 
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin?? ?? l'usage exclusif du 
(des) destinataire(s) express??ment d??sign??(s) comme tel(s). En cas de r??ception de cet 
 e-mail par erreur, le signaler ?? son exp??diteur et ne pas en divulguer le contenu. 
L'absence de virus a ??t?? v??rifi?? ??  l'??mission du message. Il convient n??anmoins de 
v??rifier l'absence de corruption ?? sa r??ception.

The contents of this email and any attachments are confidential. They are intended for 
the named recipient(s) only. If you have received this email in error please notify the 
system manager or  the sender immediately and do not disclose the contents to 
anyone or make copies. eSafe scanned this email for viruses, vandals and malicious 
content.
***



From ligges at statistik.uni-dortmund.de  Fri Jul 30 16:25:50 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jul 2004 16:25:50 +0200
Subject: [R] classification trees
In-Reply-To: <1091191156.410a4174cc594@mail.umich.edu>
References: <1091191156.410a4174cc594@mail.umich.edu>
Message-ID: <410A5A6E.6000308@statistik.uni-dortmund.de>

hmmunro at umich.edu wrote:

> I'm working with S-Plus 6 in Windows.  Does anyone know if the prune.tree or
> prune.misclass function automatically cross-validates or do you have to use
> cv.tree if you want to do cross-validation?

This mailing list is about R. There is, e.g., the s-news lists for 
questions related to S-PLUS.

Uwe Ligges


> Heather
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Jul 30 16:27:19 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jul 2004 16:27:19 +0200
Subject: [R] a question about identify and locator
In-Reply-To: <AA0BBC8742AFFF4583B91782E958CB660FCD99@ibfftce121.de.ad.drkw.net>
References: <AA0BBC8742AFFF4583B91782E958CB660FCD99@ibfftce121.de.ad.drkw.net>
Message-ID: <410A5AC7.3090306@statistik.uni-dortmund.de>

Molins, Jordi wrote:

> Hello,
> 
> I use R 1.9.1 on Windows 2000. I have a chart that I am looking. I use
> identify() and locator() to find out the (x,y) values of interesting points
> in the chart, but these functions are not always helpful (e.g., sometimes
> identify() prints on top of the chart, making the number illegible). 

par(xpd = NA) just before using identify() should help here. See ?par 
for details.


 > What I
> would be interested in is in a functionality that identifies the (x,y) point
> using something like a text box superimposed on the chart that disappears
> when the cursor is away from the chart (for example, similar to Excel) or
> even better, small text boxes located both in the x and y axis near to the
> points (0,y) and (x,0), resp., that are constantly updated (like charts in
> Bloomberg) .
> 
> Is there something like this in R? 

Not within R itself.

Uwe Ligges


> Thank you
> 
> Jordi
> 
> 
> 
> --------------------------------------------------------------------------------
> The information contained herein is confidential and is inte...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Fri Jul 30 16:41:50 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 30 Jul 2004 10:41:50 -0400
Subject: [R] a question about identify and locator
In-Reply-To: <410A5AC7.3090306@statistik.uni-dortmund.de>
Message-ID: <20040730144150.SSIA21087.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Uwe and Jordi,

It is possible to get close to what Jordi wants using the tcltk package:

IDPoints <- function(x, y, labels){
    top <- tktoplevel()
    tkwm.title(top, "Coordinates")
    coords <- tclVar("")
    coordsEntry <- tkentry(top, width="25", textvariable=coords)
    Stop <- tclVar("No")
    onStop <- function() {
        tclvalue(Stop) <- "Yes"
        tkdestroy(top)
        }
    stopButton <- tkbutton(top, text="Stop", fg="red", width="12",
command=onStop)
    tkgrid(coordsEntry)
    tkgrid(stopButton)
    repeat {
        if (tclvalue(Stop) == "Yes") break
        if (missing(x)){
            xy <- format(locator(1), digits=10)
            tclvalue(coords) <- paste(xy, collapse=", ")
            }
        else{
            point <- identify(x, y, rep("", length(labels)), n=1)
            tclvalue(coords) <- labels[point]
            }
        }
    }

Try, e.g.,

plot(1:10)
IDPoints()
IDPoints(1:10, 1:10, letters[1:10])

There is a minor irritation that I haven't been able to remove, however: You
have to identify one more point after pressing the "Stop" button.

Regards,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
> Sent: Friday, July 30, 2004 9:27 AM
> To: Molins, Jordi
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] a question about identify and locator
> 
> Molins, Jordi wrote:
> 
> > Hello,
> > 
> > I use R 1.9.1 on Windows 2000. I have a chart that I am 
> looking. I use
> > identify() and locator() to find out the (x,y) values of 
> interesting 
> > points in the chart, but these functions are not always 
> helpful (e.g., 
> > sometimes
> > identify() prints on top of the chart, making the number 
> illegible). 
> 
> par(xpd = NA) just before using identify() should help here. 
> See ?par for details.
> 
> 
>  > What I
> > would be interested in is in a functionality that 
> identifies the (x,y) point
> > using something like a text box superimposed on the chart 
> that disappears
> > when the cursor is away from the chart (for example, 
> similar to Excel) or
> > even better, small text boxes located both in the x and y 
> axis near to the
> > points (0,y) and (x,0), resp., that are constantly updated 
> (like charts in
> > Bloomberg) .
> > 
> > Is there something like this in R? 
> 
> Not within R itself.
> 
> Uwe Ligges
> 
> 
> > Thank you
> > 
> > Jordi



From supratik at stat.ucc.ie  Fri Jul 30 16:46:36 2004
From: supratik at stat.ucc.ie (Roy, Supratik)
Date: Fri, 30 Jul 2004 15:46:36 +0100
Subject: [R] LaTeX in R
Message-ID: <F64493091FAC4D4DAC46261FEC196799079204A0@xch4.ucc.ie>


I tried to include LaTeX expressions in the header of a plot in R.
(1) Using PlotMath, LaTeX type expressions, e.g., R^x is possible, however,
dist<-"...." (some string)
....main=expression(R^x,dist)....
does not substitute the value of dist, as well do the proper superscripting.
Also within an expression, substitute does not work, (apparently), so that 
explicit substituting of "dist" does not take place. Pasting separately,
like
 ....main=paste(expression(R^x),dist)... does not work either.
Is there any way out? Even if it is "trivial" please indicate any source of
help.

(2) Problem in (1) is stated for a general graphics device and PlotMath has
limited 
capabilities. I am aware that the "TeX" option for the graphics device is a
way out, but when converted to eps or ps, and included in a LaTeX document,
and compiled to produce pdf/ps files,
the headers are not converted into meaningful symbols. Has anyone tried
anything on this?

Many journals now have online submission procedures, which compile pdf files
on site
after the LaTeX file , and the figures, mostly required to be eps, are
uploaded. I expect
others to have come across similar problems.

Regards
Supratik.



From bates at stat.wisc.edu  Fri Jul 30 16:54:08 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 30 Jul 2004 09:54:08 -0500
Subject: [R] lme: problems with corARMA
In-Reply-To: <3.0.5.32.20040730142946.00ad7608@popserver.uni-konstanz.de>
References: <3.0.5.32.20040730142946.00ad7608@popserver.uni-konstanz.de>
Message-ID: <410A6110.9060507@stat.wisc.edu>

Stephan Moratti wrote:

> Trying following example from Pinheiro and Bates in order to fit an
> ARMA(1,1) model:
> 
> library(nlme)
> fm1Ovary.lme<-lme(follicles~sin(2*pi*Time)+cos(*pi*Time),data=Ovary,random=p
> dDiag(~sin(2*pi*Time)))
> fm5Ovary.lme<-update(fm1Ovary.lme,corr=corARMA(p=1,q=1))
> 
> I get follwing error message:
> 
> Error in "coef<-.corARMA"(`*tmp*`, value = c(62.3428455941166,
> 62.3428517930051 : 
>         Coefficient matrix not invertible
> 
> Does somebody know why it doesn't work ?

The optimization code in R's nlm is different from the code in S-PLUS's 
ms.   The nlm optimizer does not converge on that ill-conditioned example.



From ligges at statistik.uni-dortmund.de  Fri Jul 30 16:58:17 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jul 2004 16:58:17 +0200
Subject: [R] LaTeX in R
In-Reply-To: <F64493091FAC4D4DAC46261FEC196799079204A0@xch4.ucc.ie>
References: <F64493091FAC4D4DAC46261FEC196799079204A0@xch4.ucc.ie>
Message-ID: <410A6209.7030205@statistik.uni-dortmund.de>

Roy, Supratik wrote:

> I tried to include LaTeX expressions in the header of a plot in R.
> (1) Using PlotMath, LaTeX type expressions, e.g., R^x is possible, however,
> dist<-"...." (some string)
> ....main=expression(R^x,dist)....
> does not substitute the value of dist, as well do the proper superscripting.
> Also within an expression, substitute does not work, (apparently), so that 
> explicit substituting of "dist" does not take place. Pasting separately,
> like
>  ....main=paste(expression(R^x),dist)... does not work either.
> Is there any way out? Even if it is "trivial" please indicate any source of
> help.

See the examples in ?plotmath and how to use substitute. Also, you might 
want to look into the R Help Desk column in R News 2(3).


> (2) Problem in (1) is stated for a general graphics device and PlotMath has
> limited 
> capabilities. I am aware that the "TeX" option for the graphics device 

What is the "TeX" option, please?

Uwe Ligges


> is a way out, but when converted to eps or ps, and included in a LaTeX document,
> and compiled to produce pdf/ps files,
> the headers are not converted into meaningful symbols. Has anyone tried
> anything on this?
 >
> Many journals now have online submission procedures, which compile pdf files
> on site
> after the LaTeX file , and the figures, mostly required to be eps, are
> uploaded. I expect
> others to have come across similar problems.
> 
> Regards
> Supratik.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Fri Jul 30 17:06:21 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 30 Jul 2004 11:06:21 -0400 (EDT)
Subject: [R] optimisation procedure with flat log-likelihood
Message-ID: <20040730150621.7B54812D15@mprdmxin.myway.com>



Two things to try:

1. Try transforming the parameters.  It may be that one or more
parameters transformed by log or reciprocal, say, will improve the
objective function from the optimizer's viewpoint.

2. specify the gradient explicitly.  If its complicated but not
too complicated you might try a computer algebra package such as 
the free one, yacas, to get the derivative.

Date:   	Fri, 30 Jul 2004 15:41:27 +0200
From:   	Camarda, Carlo Giovanni <Camarda at demogr.mpg.de>
To:   	'r-help at stat.math.ethz.ch' <r-help at stat.math.ethz.ch>
Subject:   	[R] optimisation procedure with flat log-likelihood

Dear R-friends,
I use

optim(par=c(mystartingpoints), fn=myloglikelihoodfunction, gr=NULL,
method=c("L-BFGS-B"), ## I would like to do not use any
bounds
control=list(trace=6, ## just to see what it's going on
maxit=c(20000)), ## to be sure the it
doesn't stop reaching the max iterations
data=mydataset)

to optimize some demographic model. I assume that the log-likelihood is
relatively flat because the estimated results are very similar to my
starting values. In addition, I know the "real" parameters as I have used
simulated data (which have been also found by using GAUSS and replicated by
it).
I already tried various methods and also various starting values but it did
not help. Can maybe anyone give me some suggestion what I could do?

Thanks,
Carlo Giovanni Camarda



From rcmcll at yahoo.com  Fri Jul 30 17:13:05 2004
From: rcmcll at yahoo.com (bob mccall)
Date: Fri, 30 Jul 2004 08:13:05 -0700 (PDT)
Subject: [R] dynamic regression
Message-ID: <20040730151305.61578.qmail@web60001.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040730/cc0df161/attachment.pl

From Laurence.Adair at parsons.com  Fri Jul 30 17:13:13 2004
From: Laurence.Adair at parsons.com (Adair, Laurence)
Date: Fri, 30 Jul 2004 10:13:13 -0500
Subject: [R] Counting question
Message-ID: <8BFCEADFBB3DD611AC3E00B0D0EA321C046B11CE@exchdal08.parsons.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040730/c0d6ff06/attachment.pl

From edd at debian.org  Fri Jul 30 17:24:58 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 30 Jul 2004 10:24:58 -0500
Subject: [R] using Rterm under cygwin, no possiblity to delete characters
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD689F@SRV0015>
References: <D965434E9D6BD511AE3500306E01C8BE05DD689F@SRV0015>
Message-ID: <20040730152458.GA7350@sonny.eddelbuettel.com>

On Fri, Jul 30, 2004 at 11:37:32AM +0200, Dewez Thomas wrote:
> Dear R-users,
> 
> Thanks to Roger Bivand, it appears that the real problem is coming from the
> way R talks to X11 under cygwin. Both other invocations of Rterm, either in
> a bash window without Xwindow capability or from the DOS command, work just
> fine.
> 
> Rterm breaks down every time it is invoked from a bash shell inside an
> Xwindow session. The symptoms are the following:
> + No popup window appears when invoking help() or plot() commands
> + Instead, the Windows task bar shows an R icon, but this icon cannot be
> restore to full screen
> + Rterm dies when hitting return after correcting typos
> the error message then is:
> ---
> Error: syntax error
> Execution halted
> ---

I cannot replicate this. I have been using Cygwin for years at different
workplaces under nt4 and now win2k (IT tends to be conservative in my
industry).

I use bash-inside-of-rxt as my main shell.  R runs in all forms
* as 'Rgui &' to launch the gui
* as Rterm called from ESS inside XEmacs (my main mode)
* as 'Rterm --no-save' to test your conjecture

None of these are influenced in any way or form by also allowing x11 access
(launched from another shell script; you can now launch an Xserver without
taking over the windows desktop; nice for remote apps from Unix boxen).

I don't think my setup is that unusual. I suspect your Cygwin installation
may have a problem.
 
> This suggests that Rterm is by-passing fvwm2 and the X11 environment to talk
> to windows directly. This is also probably the reason why terminal
> properties are forgotten when just using Rterm for typing commands. It
> forgets that it was invoked from bash and responds to all the keys pressed.
> If typos are corrected with backspace, Rterm reads is a gibberish string
> made of printable and non printable characters causing it to misunderstand
> the command and fail.

"Works for me" (TM)

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From barano_s at molgen.mpg.de  Fri Jul 30 17:33:15 2004
From: barano_s at molgen.mpg.de (Serguei Baranov)
Date: Fri, 30 Jul 2004 17:33:15 +0200
Subject: [R] FWER + multiple linear models
Message-ID: <410A6A3B.2030302@molgen.mpg.de>

Could someone kindly help me with the following question:
when I analyze microarray data I need to fit multiple linear regression 
models between genes and clinical patameters followed by estimation of 
the p-values.
What's the solution to implement Westfall and Young's algorithm + 
resampling into the scheme:
lm -> stepAIC -> anova.
Actually permcor works fine for me in the case of one regression 
variable, I need extension for multiple regression models.
Any ideas are very much wellcome!

Sincerely yours,
Serguei Baranov
Research "Obesity & Hypertension" 
MPI of Molecular Genetics, Ihnestr. 73, 14195, Berlin, Germany
phone:   +49 30 84131238
fax:        +49 30 84131228



From tlumley at u.washington.edu  Fri Jul 30 17:34:23 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 30 Jul 2004 08:34:23 -0700 (PDT)
Subject: [R] Counting question
In-Reply-To: <8BFCEADFBB3DD611AC3E00B0D0EA321C046B11CE@exchdal08.parsons.com>
References: <8BFCEADFBB3DD611AC3E00B0D0EA321C046B11CE@exchdal08.parsons.com>
Message-ID: <Pine.A41.4.58.0407300831180.153958@homer09.u.washington.edu>

On Fri, 30 Jul 2004, Adair, Laurence wrote:

> Hi All,
>
> Here is something that sounds simple, but I'm having trouble getting it.  I
> have a data frame with two columns, the first is date and the second is
> employee ID.  I'd like to plot date on the horizontal axis, employee ID on
> the vertical axis, and the number of times the employee appears for the
> given date as a color.  I've kluged something where I make a table
> (table(date, id)) and add points to a plot by looping through the rownames
> (employee ids) of the table.  But certainly there is a better way of doing
> this??
>

The function below takes a correlation matrix and plots circles whose
radius is proportional to the absolute value of the correlation.
Something along these lines would presumably work for your problem.

	-thomas

 shadedcorr <- function(mat, labels = colnames(mat)) {
  n <- NCOL(mat)
  diag(mat) <- NA
  mat <- mat[, n:1]
  mat <- as.vector(mat)
  pos <- mat >= 0
  par(pty = "s", las = 2, mar = c(7, 7, 4, 4))
  xy <- expand.grid(1:n, 1:n)
  plot(xy, type = "n", axes = FALSE, xlab = "", ylab = "",
  xlim = c(0.5, n + 0.5), ylim = c(0.5, n + 0.5))
  if (any(pos %in% TRUE))
  symbols(xy[, 1][pos], xy[, 2][pos], mat[pos]/2, bg = grey(0.8),
  inches = FALSE, add = TRUE)
  if (any(pos %in% FALSE))
  symbols(xy[, 1][!pos], xy[, 2][!pos], -mat[!pos]/2, bg = grey(0.2),
  inches = FALSE, add = TRUE)
  axis(2, n:1, labels)
  axis(1, 1:n, labels)
  invisible(NULL)
 }



From f.duan at yale.edu  Fri Jul 30 17:41:44 2004
From: f.duan at yale.edu (F Duan)
Date: Fri, 30 Jul 2004 11:41:44 -0400
Subject: [R] How to put multiple plots in the same window? (not par(mfrow=))
Message-ID: <1091202104.410a6c38c2b97@webmail.med.yale.edu>

Dear All,

I am sorry if this question has been asked before. Below is my Question:

I want to put several plots in the same window, but I don?t want the blank 
space between plots (like par(mfrow=)) --- that makes the plots too small. 
Could anyone tell me how to do it?

Thanks a lot.

Frank



From jfox at mcmaster.ca  Fri Jul 30 17:39:42 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 30 Jul 2004 11:39:42 -0400
Subject: [R] dynamic regression
In-Reply-To: <20040730151305.61578.qmail@web60001.mail.yahoo.com>
Message-ID: <20040730153941.QYS4787.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Bob,

If you mean regression with autocorrelated errors, take a look at the gls
(generalised least squares) function in the nlme package.

I hope this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of bob mccall
> Sent: Friday, July 30, 2004 10:13 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] dynamic regression
> 
> Greetings:
>  
> Is there an simple way to do dynamic regressions in R? 
> >From what I've seen, one must use arima() and construct the 
> X matrix with lagged values etc. and modify Y as well.
>  
> Thanks,
>  
> Bob



From barano_s at molgen.mpg.de  Fri Jul 30 17:41:05 2004
From: barano_s at molgen.mpg.de (Serguei Baranov)
Date: Fri, 30 Jul 2004 17:41:05 +0200
Subject: [R] FWER + multiple linear models
Message-ID: <410A6C11.7080102@molgen.mpg.de>

Could someone kindly help me with the following question:
when I analyze microarray data I need to fit multiple linear regression 
models between genes and clinical patameters followed by estimation of 
the p-values.
What's the solution to implement Westfall and Young's algorithm + 
resampling into the scheme:
lm -> stepAIC -> anova.
Actually permcor works fine for me in the case of one regression 
variable, I need extension for multiple regression models.
Any ideas are very much wellcome!

Sincerely yours,
Serguei Baranov
Research "Obesity & Hypertension" MPI of Molecular Genetics, Ihnestr. 
73, 14195, Berlin, Germany
phone:   +49 30 84131238
fax:        +49 30 84131228



From tlumley at u.washington.edu  Fri Jul 30 17:42:28 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 30 Jul 2004 08:42:28 -0700 (PDT)
Subject: [R] LaTeX in R
In-Reply-To: <F64493091FAC4D4DAC46261FEC196799079204A0@xch4.ucc.ie>
References: <F64493091FAC4D4DAC46261FEC196799079204A0@xch4.ucc.ie>
Message-ID: <Pine.A41.4.58.0407300836270.153958@homer09.u.washington.edu>

On Fri, 30 Jul 2004, Roy, Supratik wrote:

>
> I tried to include LaTeX expressions in the header of a plot in R.
> (1) Using PlotMath, LaTeX type expressions, e.g., R^x is possible, however,
> dist<-"...." (some string)
> ....main=expression(R^x,dist)....
> does not substitute the value of dist, as well do the proper superscripting.
> Also within an expression, substitute does not work, (apparently), so that
> explicit substituting of "dist" does not take place.


Working from the example in FAQ 7.15 suggests something like
 dist=" is the xth power of R"
 plot(rnorm(10),main=substitute(R^x*dist,list(dist=dist)))

which works fine. A slightly more compact version is
  plot(rnorm(10),main=bquote(R^x*.(dist)))

If that output isn't what you want you will need to explain what you want
more precisely.

	-thomas



From peak_freak at yahoo.com  Fri Jul 30 17:43:17 2004
From: peak_freak at yahoo.com (=?iso-8859-1?q?Jeroen=20Van=20Goey?=)
Date: Fri, 30 Jul 2004 16:43:17 +0100 (BST)
Subject: [R] P-value from the joint cumulative distribution of an
	n-dimensional order statistic
Message-ID: <20040730154317.33148.qmail@web40912.mail.yahoo.com>

Hello,

I want to compute the P-value from the joint cumulative distribution of an n-dimensional
order statistic in R, using the formula found on
http://cmgm.stanford.edu/%7Ekimlab/multiplespecies/Supplement/methods_network.html

My data consists of three different techniques (G2D, POCUS and RANDOM), and each has
associated with it a number of rankings (integer between 0 and 1000), like for example:

	name	r1	r2	r3	r4	r5	r6	r7	r8	r9	r10
1	G2D	939.100	929.400	919.700	910.100	784.200	387.300	377.600	87.130	18.390	17.430
2	POCUS	910.876	910.876	753.944	753.944	0.235	0.208	0.160	0.160	0.016	0.000
3	RANDOM	917.328	893.808	848.294	725.135	462.952	383.682	292.386	46.654	12.466	7.134

I tried already with the package ISMEV from CRAN, (used for order statistics), but the
results I get then don't make me much wiser.

> library(DBI)
> library(RMySQL)
> library(ismev)
> drv <- dbDriver("MySQL")
> con <- dbConnect(drv, group = "mysql")
> ibd <- dbSendQuery(con, statement = paste("SELECT * FROM database") )
> ibddata <- fetch(ibd, n = -1)
> ibdfit <- rlarg.fit(ibddata[,-1])
>ibdfit
$trans
[1] FALSE

$model
$model[[1]]
NULL

$model[[2]]
NULL

$model[[3]]
NULL


$link
[1] "c(identity, identity, identity)"

$conv
[1] 1

$nllh
[1] -195.1587

$data
          r1         r2          r3          r4          r5         r6
1 1.7430e-03 1.8390e-03 3.77600e-03 3.87300e-03 7.84200e-03 8.7130e-03
2 1.0000e-16 8.0000e-15 8.00000e-15 8.00000e-15 1.04000e-14 1.1760e-13
3 7.1338e-02 1.2466e-01 2.92386e-01 3.83682e-01 4.62952e-01 4.6654e-01
           r7          r8          r9         r10
1 9.10100e-03 9.19700e-03 9.29400e-03 9.39100e-03
2 3.76972e-11 3.76972e-11 4.55438e-11 4.55438e-11
3 7.25135e-01 8.48294e-01 8.93808e-01 9.17328e-01

$mle
[1] 0.1332361 0.5694678 4.2741269

$cov
              [,1]         [,2]          [,3]
[1,]  3.998775e-12 2.572874e-17 -3.300609e-18
[2,]  2.572874e-17 3.998854e-12  1.264103e-17
[3,] -3.300609e-18 1.264103e-17  3.998948e-12

$se
[1] 1.999694e-06 1.999713e-06 1.999737e-06

$vals
            mu        sc       xi
[1,] 0.1332361 0.5694678 4.274127
[2,] 0.1332361 0.5694678 4.274127
[3,] 0.1332361 0.5694678 4.274127

$r
[1] 10


Can ayone explain all these values to me, or point me the way how I can implement the
formula from
http://cmgm.stanford.edu/%7Ekimlab/multiplespecies/Supplement/methods_network.html in R?

Thanks in advance.

NB: this message is also crossposted at sci.stat.consult & sci.stat.math



From sundar.dorai-raj at PDF.COM  Fri Jul 30 17:49:10 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 30 Jul 2004 10:49:10 -0500
Subject: [R] How to put multiple plots in the same window? (not
	par(mfrow=))
In-Reply-To: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
References: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
Message-ID: <410A6DF6.7090605@pdf.com>



F Duan wrote:
> Dear All,
> 
> I am sorry if this question has been asked before. Below is my Question:
> 
> I want to put several plots in the same window, but I don?t want the blank 
> space between plots (like par(mfrow=)) --- that makes the plots too small. 
> Could anyone tell me how to do it?
> 
> Thanks a lot.
> 
> Frank
> 

You should definitely use package:lattice.

--sundar



From tlumley at u.washington.edu  Fri Jul 30 17:49:07 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 30 Jul 2004 08:49:07 -0700 (PDT)
Subject: [R] How to put multiple plots in the same window? (not
	par(mfrow=))
In-Reply-To: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
References: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
Message-ID: <Pine.A41.4.58.0407300846050.153958@homer09.u.washington.edu>

On Fri, 30 Jul 2004, F Duan wrote:

> Dear All,
>
> I am sorry if this question has been asked before. Below is my Question:
>
> I want to put several plots in the same window, but I don?t want the blank
> space between plots (like par(mfrow=)) --- that makes the plots too small.
> Could anyone tell me how to do it?
>

There isn't blank space between the plots. There is blank space around
each plot. The amount of space around each plot is controlled by par(mar),
which specifies the number of lines of space on each side of the plotting
area

The default is
> par("mar")
[1] 5.1 4.1 4.1 2.1
and if you do, say,
  par(mar=c(3.1,3.1,1,1))
you will have much less blank space.  You need to make sure enough space
is left for axis label &c.

	-thomas



From maustin at amgen.com  Fri Jul 30 17:56:31 2004
From: maustin at amgen.com (Austin, Matt)
Date: Fri, 30 Jul 2004 08:56:31 -0700
Subject: [R] How to put multiple plots in the same window? (not par(mf
	row=))
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F110B8@teal-exch.amgen.com>

Lattice graphics may be the answer depending on your exact problem.

Here is an example of four traditional plots without space:

par(mfrow=c(2,2), omi=c(.5, .5, .5, .5))
par(mar=c(0, 2, 2, 0))
  plot(rnorm(10), rnorm(10), axes=FALSE)
  box(); axis(2); axis(3)
par(mar=c(0, 0, 2, 2))
  plot(rnorm(10), rnorm(10), axes=FALSE) 
  box(); axis(3); axis(4)
par(mar=c(2, 2, 0, 0))
  plot(rnorm(10), rnorm(10), axes=FALSE)
  box(); axis(1); axis(2)
par(mar=c(2, 0, 0, 2))
  plot(rnorm(10), rnorm(10), axes=FALSE); box()
  box(); axis(1); axis(4)

I have generalized this in the past to allow for more (in a for loop I
think), but I don't have access to my home computer from here.

--Matt



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of F Duan
Sent: Friday, July 30, 2004 8:42 AM
To: r-help at stat.math.ethz.ch
Subject: [R] How to put multiple plots in the same window? (not
par(mfrow=))


Dear All,

I am sorry if this question has been asked before. Below is my Question:

I want to put several plots in the same window, but I don't want the blank 
space between plots (like par(mfrow=)) --- that makes the plots too small. 
Could anyone tell me how to do it?

Thanks a lot.

Frank

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Jul 30 18:00:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jul 2004 18:00:13 +0200
Subject: [R] How to put multiple plots in the same window? (not
	par(mfrow=))
In-Reply-To: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
References: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
Message-ID: <410A708D.5040409@statistik.uni-dortmund.de>

F Duan wrote:

> Dear All,
> 
> I am sorry if this question has been asked before. Below is my Question:
> 
> I want to put several plots in the same window, but I don?t want the blank 
> space between plots (like par(mfrow=)) --- that makes the plots too small. 
> Could anyone tell me how to do it?

E.g. with par(mfrow=...)!
There is no blank space between the plots, just the inner margins. And 
you can control inner margins with par(mar=...).

Uwe Ligges


> Thanks a lot.
> 
> Frank
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Fri Jul 30 18:00:53 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 30 Jul 2004 12:00:53 -0400
Subject: [R] How to put multiple plots in the same window? (not
	par(mfrow=))
In-Reply-To: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
References: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
Message-ID: <A27822F6-E241-11D8-89EE-000A95D7BA10@mail.nih.gov>

Frank,

Why not try using grid graphics?  You can open arbitrary viewports into 
which to place plots.

Sean

On Jul 30, 2004, at 11:41 AM, F Duan wrote:

> Dear All,
>
> I am sorry if this question has been asked before. Below is my 
> Question:
>
> I want to put several plots in the same window, but I don?t want the 
> blank
> space between plots (like par(mfrow=)) --- that makes the plots too 
> small.
> Could anyone tell me how to do it?
>
> Thanks a lot.
>
> Frank
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From liao1k at cmich.edu  Fri Jul 30 18:04:39 2004
From: liao1k at cmich.edu (Liao, Kexiao )
Date: Fri, 30 Jul 2004 12:04:39 -0400
Subject: [R] plot() core dump
Message-ID: <291B348BC59B47468C7824603C32608294616F@cmail3.central.cmich.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040730/729a15de/attachment.pl

From MSchwartz at MedAnalytics.com  Fri Jul 30 18:08:21 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 30 Jul 2004 11:08:21 -0500
Subject: [R] How to put multiple plots in the same window? (not
	par(mfrow=))
In-Reply-To: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
References: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
Message-ID: <1091203701.23861.419.camel@localhost.localdomain>

On Fri, 2004-07-30 at 10:41, F Duan wrote:
> Dear All,
> 
> I am sorry if this question has been asked before. Below is my Question:
> 
> I want to put several plots in the same window, but I dont want the blank 
> space between plots (like par(mfrow=)) --- that makes the plots too small. 
> Could anyone tell me how to do it?
> 
> Thanks a lot.
> 
> Frank

It is not clear if you want a matrix of plots or if you want plots that
actually overlap (ie. inset plots).

For example, for a matrix using par("mfrow"), the actual figure regions
for each plot fill up the full plotting device:

par(mfrow = c(2, 2))
plot(1:5)
box(which = "figure")
plot(1:5)
box(which = "figure")
plot(1:5)
box(which = "figure")
plot(1:5)
box(which = "figure")

Each of the four plots take up one quarter of the overall device. The
outer four boxes represent the figure region for each of the four
plots.  Within each figure region is the plot region and the axes,
labels, etc. for each individual plot.

You can use par("mar") to reduce the amount of space between the plot
region and the figure region. As an extreme example:

par(mfrow = c(2, 2))
par(mar = c(0, 0, 0, 0))
plot(1:5)
box(which = "figure")
plot(1:5)
box(which = "figure")
plot(1:5)
box(which = "figure")
plot(1:5)
box(which = "figure")

In this case, you now would need to play around with the axis tick
marks, labels, etc.

Can you clarify which space you are referring to?

Marc Schwartz



From Achim.Zeileis at wu-wien.ac.at  Fri Jul 30 18:03:39 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 30 Jul 2004 18:03:39 +0200
Subject: [R] dynamic regression
In-Reply-To: <20040730151305.61578.qmail@web60001.mail.yahoo.com>
References: <20040730151305.61578.qmail@web60001.mail.yahoo.com>
Message-ID: <20040730180339.68d06bde.Achim.Zeileis@wu-wien.ac.at>

On Fri, 30 Jul 2004 08:13:05 -0700 (PDT) bob mccall wrote:

> Greetings:
>  
> Is there an simple way to do dynamic regressions in R? 
> >From what I've seen, one must use arima() and construct the X matrix
> >with lagged values etc. and modify Y as well.

If you want OLS regression with lagged regressors you could also
transform your data using lag() and window() and then use lm().
E.g. for a multiplicative SARIMA(1,0,0)(1,0,0) model for the seatbelt
data you could do something like:

data(UKDriverDeaths)
seatbelt <- log10(UKDriverDeaths)
seatbelt <- cbind(seatbelt, lag(seatbelt, k = -1), 
  lag(seatbelt, k = -12))
colnames(seatbelt) <- c("y", "ylag1", "ylag12")
seatbelt <- window(seatbelt, start = c(1970, 1), end = c(1984, 12))

lm(y ~ ylag1 + ylag12, data = seatbelt)

hth,
Z


> Thanks,
>  
> Bob
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From supratik at stat.ucc.ie  Fri Jul 30 18:12:08 2004
From: supratik at stat.ucc.ie (Roy, Supratik)
Date: Fri, 30 Jul 2004 17:12:08 +0100
Subject: [R] LaTeX in R
Message-ID: <F64493091FAC4D4DAC46261FEC196799079204A1@xch4.ucc.ie>

Sorry!, by "TeX" I meant the PicTeX option for graphics devices (which
in anycase produces bulky files!).

-----Original Message-----
From: Uwe Ligges
To: Roy, Supratik
Cc: 'r-help at stat.math.ethz.ch'
Sent: 7/30/2004 3:58 PM
Subject: Re: [R] LaTeX in R

Roy, Supratik wrote:

> I tried to include LaTeX expressions in the header of a plot in R.
> (1) Using PlotMath, LaTeX type expressions, e.g., R^x is possible,
however,
> dist<-"...." (some string)
> ....main=expression(R^x,dist)....
> does not substitute the value of dist, as well do the proper
superscripting.
> Also within an expression, substitute does not work, (apparently), so
that 
> explicit substituting of "dist" does not take place. Pasting
separately,
> like
>  ....main=paste(expression(R^x),dist)... does not work either.
> Is there any way out? Even if it is "trivial" please indicate any
source of
> help.

See the examples in ?plotmath and how to use substitute. Also, you might

want to look into the R Help Desk column in R News 2(3).


> (2) Problem in (1) is stated for a general graphics device and
PlotMath has
> limited 
> capabilities. I am aware that the "TeX" option for the graphics device


What is the "TeX" option, please?

Uwe Ligges


> is a way out, but when converted to eps or ps, and included in a LaTeX
document,
> and compiled to produce pdf/ps files,
> the headers are not converted into meaningful symbols. Has anyone
tried
> anything on this?
 >
> Many journals now have online submission procedures, which compile pdf
files
> on site
> after the LaTeX file , and the figures, mostly required to be eps, are
> uploaded. I expect
> others to have come across similar problems.
> 
> Regards
> Supratik.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ihok at hotmail.com  Fri Jul 30 18:23:37 2004
From: ihok at hotmail.com (Jack Tanner)
Date: Fri, 30 Jul 2004 12:23:37 -0400
Subject: [R] unwanted as.integer
In-Reply-To: <410974F1.3090306@pdf.com>
References: <41097228.6020906@hotmail.com> <410974F1.3090306@pdf.com>
Message-ID: <410A7609.5000502@hotmail.com>

Sundar Dorai-Raj wrote:
> Not sure about what sqlQuery is doing but you can wrap your return value 
> in a eval(parse(text = x)) to evaluate the "as.integer(.)" string. As in,
> 
> a <- eval(parse(text = a))

This works, except it doesn't.

 > a <- sqlQuery(irrdb, "select count(field) from mytable where field=1")
 > print(a)
  count(field)
1            8
 > paste(a)
[1] "as.integer(8)"
 > eval(parse(text=a))
[1] 8
 > paste(eval(parse(text=a)))
[1] "8"

That's great, but...
 > paste(list(eval(parse(text=a)), eval(parse(text=a))))
[1] "as.integer(8)" "as.integer(8)"

Argh!!! What the hell is going on?



From gavin.simpson at ucl.ac.uk  Fri Jul 30 18:27:31 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 30 Jul 2004 17:27:31 +0100
Subject: [R] How to put multiple plots in the same window? (not
	par(mfrow=))
In-Reply-To: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
References: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
Message-ID: <410A76F3.20704@ucl.ac.uk>

F Duan wrote:
> Dear All,
> 
> I am sorry if this question has been asked before. Below is my Question:
> 
> I want to put several plots in the same window, but I don?t want the blank 
> space between plots (like par(mfrow=)) --- that makes the plots too small. 
> Could anyone tell me how to do it?
> 
> Thanks a lot.
> 
> Frank

?split.screen
?layout

are alternatives to par(mfrow = c()), but I think you need to look at 
the margins of the plots and reduce them to suit your purposes. See ?par 
and argument mar. For example:

oldpar <- par(mfrow = c(2,2), mar = c(3,3,1,1) + 0.1)
plot(1:10)
plot(1:10)
plot(1:10)
plot(1:10)
par(oldpar)

# or

layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
layout.show(4)
oldpar <- par(mar=c(3,3,1,1) + 0.1)
plot(1:10)
plot(1:10)
plot(1:10)
plot(1:10)
par(oldpar)

There is no room for labels/titles but adjust the mar to suit your 
requirements.

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From deepayan at stat.wisc.edu  Fri Jul 30 18:31:06 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 30 Jul 2004 11:31:06 -0500
Subject: [R] Counting question
In-Reply-To: <8BFCEADFBB3DD611AC3E00B0D0EA321C046B11CE@exchdal08.parsons.com>
References: <8BFCEADFBB3DD611AC3E00B0D0EA321C046B11CE@exchdal08.parsons.com>
Message-ID: <200407301131.06732.deepayan@stat.wisc.edu>

On Friday 30 July 2004 10:13, Adair, Laurence wrote:
> Hi All,
>
> Here is something that sounds simple, but I'm having trouble getting
> it.  I have a data frame with two columns, the first is date and the
> second is employee ID.  I'd like to plot date on the horizontal axis,
> employee ID on the vertical axis, and the number of times the
> employee appears for the given date as a color.  I've kluged
> something where I make a table (table(date, id)) and add points to a
> plot by looping through the rownames (employee ids) of the table. 
> But certainly there is a better way of doing this??

as.data.frame(table(date, id)) would have been useful, except that it 
coerces date and id to be factors. To work around that, you could do:


u.date <- sort(unique(date))
u.id <- sort(unique(id))
mydf <- as.data.frame(table(date = factor(date, levels = u.date),
                            id = factor(id, levels = u.id)))
mydf <- subset(mydf, Freq > 0)

plot(u.date[mydf$date], u.id[mydf$id], col = mydf$Freq)


Hope that helps,

Deepayan



From Davaren1 at aol.com  Fri Jul 30 18:32:14 2004
From: Davaren1 at aol.com (Davaren1@aol.com)
Date: Fri, 30 Jul 2004 12:32:14 -0400
Subject: [R] Subsetting dataframe
Message-ID: <0AFA8A69.599AAE9F.006F017A@aol.com>

Dear R-help,

I have a question on subsetting a dataframe and I searched all of R-help to no avail.  Please view the following example dataframe:

# Example
> x <- factor(rep(c(1,2,3,4),2))
> y <- c(1,4,3,2,1,2,5,1,2)
> z <- c(10,12,18,21,24,32,34,12,23)
> test <- data.frame(x, y, z)
> test
   x y  z
1  1 1 10
2  2 4 12
3  3 3 18
4  4 2 21
5  1 1 24
6  2 2 32
7  3 5 34
8  4 1 12

I want to subset "y" that is >=4 and return all matching "x" that were found from y>=4.  I know I can do the following:

> test.new <-subset(test, y>=4)
> test.new
  x y  z
2 2 4 12
7 3 5 34

I am trying for the following output:

> test.new
  x y  z
2 2 4 12
3 3 3 18
6 2 2 32
7 3 5 34

I appreciate any help.

Very respectfully,

D. Arenas



From ggrothendieck at myway.com  Fri Jul 30 18:40:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 30 Jul 2004 16:40:37 +0000 (UTC)
Subject: [R] Counting question
References: <8BFCEADFBB3DD611AC3E00B0D0EA321C046B11CE@exchdal08.parsons.com>
Message-ID: <loom.20040730T175954-478@post.gmane.org>

Adair, Laurence <Laurence.Adair <at> parsons.com> writes:

> Here is something that sounds simple, but I'm having trouble getting it.  I
> have a data frame with two columns, the first is date and the second is
> employee ID.  I'd like to plot date on the horizontal axis, employee ID on
> the vertical axis, and the number of times the employee appears for the
> given date as a color.  I've kluged something where I make a table
> (table(date, id)) and add points to a plot by looping through the rownames
> (employee ids) of the table.  But certainly there is a better way of doing
> this??

In the example below the first three lines create a random test 
data frame with columns date and id.   

The fourth line calculates the counts using table, converts it back 
to a data frame (which has the effect of adding a Freq column) and 
removes any row with a Freq of 0.  

The last two lines load package gregmisc and then plot the data 
using balloonplot from that package.



set.seed(1)  
r <- 100 + sample(5, 25, replace = TRUE)
DF <- data.frame(date = structure(rev(r), class = "Date"), id = r)

DF2 <- subset(as.data.frame(table(DF)),Freq > 0)

require(gregmisc)
with(DF2, balloonplot(date, id, Freq))



From f.duan at yale.edu  Fri Jul 30 18:45:49 2004
From: f.duan at yale.edu (F Duan)
Date: Fri, 30 Jul 2004 12:45:49 -0400
Subject: [R] How to put multiple plots in the same window? (not
	par(mfrow=))
In-Reply-To: <410A76F3.20704@ucl.ac.uk>
References: <1091202104.410a6c38c2b97@webmail.med.yale.edu>
	<410A76F3.20704@ucl.ac.uk>
Message-ID: <1091205949.410a7b3ddf44e@webmail.med.yale.edu>

Thank all of you. That's exactly what I want.

Best,

Frank


Quoting Gavin Simpson <gavin.simpson at ucl.ac.uk>:

> F Duan wrote:
> > Dear All,
> > 
> > I am sorry if this question has been asked before. Below is my Question:
> > 
> > I want to put several plots in the same window, but I don?t want the blank
> 
> > space between plots (like par(mfrow=)) --- that makes the plots too small.
> 
> > Could anyone tell me how to do it?
> > 
> > Thanks a lot.
> > 
> > Frank
> 
> ?split.screen
> ?layout
> 
> are alternatives to par(mfrow = c()), but I think you need to look at 
> the margins of the plots and reduce them to suit your purposes. See ?par 
> and argument mar. For example:
> 
> oldpar <- par(mfrow = c(2,2), mar = c(3,3,1,1) + 0.1)
> plot(1:10)
> plot(1:10)
> plot(1:10)
> plot(1:10)
> par(oldpar)
> 
> # or
> 
> layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
> layout.show(4)
> oldpar <- par(mar=c(3,3,1,1) + 0.1)
> plot(1:10)
> plot(1:10)
> plot(1:10)
> plot(1:10)
> par(oldpar)
> 
> There is no room for labels/titles but adjust the mar to suit your 
> requirements.
> 
> Gav
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [T] +44 (0)20 7679 5522
> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> London.  WC1H 0AP.
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> 
>



From sundar.dorai-raj at PDF.COM  Fri Jul 30 19:13:25 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 30 Jul 2004 12:13:25 -0500
Subject: [R] unwanted as.integer
In-Reply-To: <410A7609.5000502@hotmail.com>
References: <41097228.6020906@hotmail.com> <410974F1.3090306@pdf.com>
	<410A7609.5000502@hotmail.com>
Message-ID: <410A81B5.3040607@pdf.com>



Jack Tanner wrote:

> Sundar Dorai-Raj wrote:
> 
>> Not sure about what sqlQuery is doing but you can wrap your return 
>> value in a eval(parse(text = x)) to evaluate the "as.integer(.)" 
>> string. As in,
>>
>> a <- eval(parse(text = a))
> 
> 
> This works, except it doesn't.
> 
>  > a <- sqlQuery(irrdb, "select count(field) from mytable where field=1")
>  > print(a)
>  count(field)
> 1            8
>  > paste(a)
> [1] "as.integer(8)"
>  > eval(parse(text=a))
> [1] 8
>  > paste(eval(parse(text=a)))
> [1] "8"
> 
> That's great, but...
>  > paste(list(eval(parse(text=a)), eval(parse(text=a))))
> [1] "as.integer(8)" "as.integer(8)"
> 
> Argh!!! What the hell is going on?
> 


I think you meant

paste(c(eval(parse(text=a)), eval(parse(text=a))))

or

do.call("paste", list(eval(parse(text=a)), eval(parse(text=a))))

Not sure which you want.

Or better yet, if `a' is a vector:

a <- c(a, a, a, a)
b <- lapply(a, function(x) eval(parse(text = x)))
# I seem to recall you needing to create an HTML table
do.call("paste", c(b, sep = "</td><td>"))
# or
paste(unlist(b), collapse = "</td><td>")

--sundar



From ggrothendieck at myway.com  Fri Jul 30 19:26:04 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 30 Jul 2004 17:26:04 +0000 (UTC)
Subject: [R] Counting question
References: <8BFCEADFBB3DD611AC3E00B0D0EA321C046B11CE@exchdal08.parsons.com>
	<loom.20040730T175954-478@post.gmane.org>
Message-ID: <loom.20040730T192334-549@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Adair, Laurence <Laurence.Adair <at> parsons.com> writes:
: 
: > Here is something that sounds simple, but I'm having trouble getting it.  I
: > have a data frame with two columns, the first is date and the second is
: > employee ID.  I'd like to plot date on the horizontal axis, employee ID on
: > the vertical axis, and the number of times the employee appears for the
: > given date as a color.  I've kluged something where I make a table
: > (table(date, id)) and add points to a plot by looping through the rownames
: > (employee ids) of the table.  But certainly there is a better way of doing
: > this??
: 
: In the example below the first three lines create a random test 
: data frame with columns date and id.   
: 
: The fourth line calculates the counts using table, converts it back 
: to a data frame (which has the effect of adding a Freq column) and 
: removes any row with a Freq of 0.  
: 
: The last two lines load package gregmisc and then plot the data 
: using balloonplot from that package.
: 
: set.seed(1)  
: r <- 100 + sample(5, 25, replace = TRUE)
: DF <- data.frame(date = structure(rev(r), class = "Date"), id = r)
: 
: DF2 <- subset(as.data.frame(table(DF)),Freq > 0)
: 
: require(gregmisc)
: with(DF2, balloonplot(date, id, Freq))

and if you still want the color on the plot too add the dotcolor= arg
where the example uses colors of the rainbow:

with(DF2, balloonplot(date, id, Freq, dotcol = rainbow(max(Freq))[Freq]))



From tlumley at u.washington.edu  Fri Jul 30 19:33:04 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 30 Jul 2004 10:33:04 -0700 (PDT)
Subject: [R] Subsetting dataframe
In-Reply-To: <0AFA8A69.599AAE9F.006F017A@aol.com>
References: <0AFA8A69.599AAE9F.006F017A@aol.com>
Message-ID: <Pine.A41.4.58.0407301025300.153958@homer09.u.washington.edu>

On Fri, 30 Jul 2004 Davaren1 at aol.com wrote:

> Dear R-help,
>
> I have a question on subsetting a dataframe and I searched all of R-help to no avail.  Please view the following example dataframe:
>
> # Example
> > x <- factor(rep(c(1,2,3,4),2))
> > y <- c(1,4,3,2,1,2,5,1,2)
> > z <- c(10,12,18,21,24,32,34,12,23)
> > test <- data.frame(x, y, z)
> > test
>    x y  z
> 1  1 1 10
> 2  2 4 12
> 3  3 3 18
> 4  4 2 21
> 5  1 1 24
> 6  2 2 32
> 7  3 5 34
> 8  4 1 12

You didn't actually run these commands -- y and z have different length
from x.

> I want to subset "y" that is >=4 and return all matching "x" that were
> found from y>=4.  I know I can do the following:
>
> I am trying for the following output:
>
> > test.new
>   x y  z
> 2 2 4 12
> 3 3 3 18
> 6 2 2 32
> 7 3 5 34
>


There's more than one way to do it.  One possibility, especially if you
are going to do a lot of this sort of thing, is to reshape the data to
have only one row for each unique x

Alternatively,

> xkeep <- with(test, x[y>=4])
> test[test$x %in% xkeep,]
  x y  z
2 2 4 12
3 3 3 18
6 2 2 32
7 3 5 34

	-thomas



From tlumley at u.washington.edu  Fri Jul 30 19:34:14 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 30 Jul 2004 10:34:14 -0700 (PDT)
Subject: [R] unwanted as.integer
In-Reply-To: <410A81B5.3040607@pdf.com>
References: <41097228.6020906@hotmail.com> <410974F1.3090306@pdf.com>
	<410A7609.5000502@hotmail.com> <410A81B5.3040607@pdf.com>
Message-ID: <Pine.A41.4.58.0407301033230.153958@homer09.u.washington.edu>


Surely it's simply just to use as.numeric() to stop them being integers?

This is fixed in r-devel anyway -- you have a choice of a bunch of
deparsing options.

	-thomas


On Fri, 30 Jul 2004, Sundar Dorai-Raj wrote:

>
>
> Jack Tanner wrote:
>
> > Sundar Dorai-Raj wrote:
> >
> >> Not sure about what sqlQuery is doing but you can wrap your return
> >> value in a eval(parse(text = x)) to evaluate the "as.integer(.)"
> >> string. As in,
> >>
> >> a <- eval(parse(text = a))
> >
> >
> > This works, except it doesn't.
> >
> >  > a <- sqlQuery(irrdb, "select count(field) from mytable where field=1")
> >  > print(a)
> >  count(field)
> > 1            8
> >  > paste(a)
> > [1] "as.integer(8)"
> >  > eval(parse(text=a))
> > [1] 8
> >  > paste(eval(parse(text=a)))
> > [1] "8"
> >
> > That's great, but...
> >  > paste(list(eval(parse(text=a)), eval(parse(text=a))))
> > [1] "as.integer(8)" "as.integer(8)"
> >
> > Argh!!! What the hell is going on?
> >
>
>
> I think you meant
>
> paste(c(eval(parse(text=a)), eval(parse(text=a))))
>
> or
>
> do.call("paste", list(eval(parse(text=a)), eval(parse(text=a))))
>
> Not sure which you want.
>
> Or better yet, if `a' is a vector:
>
> a <- c(a, a, a, a)
> b <- lapply(a, function(x) eval(parse(text = x)))
> # I seem to recall you needing to create an HTML table
> do.call("paste", c(b, sep = "</td><td>"))
> # or
> paste(unlist(b), collapse = "</td><td>")
>
> --sundar
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From lw7s at cms.mail.virginia.edu  Fri Jul 30 19:53:34 2004
From: lw7s at cms.mail.virginia.edu (Lijuan  Wang)
Date: Fri, 30 Jul 2004 13:53:34 -0400
Subject: [R] a question about nlme
Message-ID: <web-80655476@cgatepro-4.mail.virginia.edu>

Hi,
Sorry to bother those who are not interested in the 
question.

I am using R to run a multiphase mixed-effects model. I 
simulated a data set by using the following model. And now 
I want to use R to estimate the parameters and compare the 
results with the true values. 
The equations of the models are as below:

gf[ij]=b0[i]+b1[i]*age[ij]+b2[i]*max(0,(age[ij]-tau[i]))+e[ij]
b0[i]=b00+e[i0]
b1[i]=b10+e[i1]
b2[i]=b20+e[i2]
tau[i]=tau+e[i3]

i: 1,2,...,111 subjects
j: 1,2,...,6 occasions

The main scripts of R is:

> simu1<-groupedData(gf~age|id,data=simu1)
#fitting a linear mixed-effects model is ok
> mm.lme.1<-lme(gf~age,random=~age|id,data=simu1)
#but when I fit a nonlinear mixed-effects model, it shows 
an error as below
> simu.nlme<-nlme(gf~b0 + b1 * age + b2 * max(0,(age-tau)),data=simu1,fixed=b0+b1+b2+tau~1,random=b0+b1+b2+tau~1, start=c(b0=4,b1=5.32,b2=-5.29,tau=14.8))

Error in MEEM(object, conLin, control$niterEM) : 
         Singularity in backsolve at level 0, block 1

I don't know if my scripts have some mistakes, or my data 
has some problems. 
Any reply will be appreciated. 

Regards,
Peggy



From jeaneid at chass.utoronto.ca  Fri Jul 30 20:21:14 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Fri, 30 Jul 2004 14:21:14 -0400
Subject: [R] legend under plot region?
Message-ID: <Pine.SGI.4.40.0407140827530.27183520-100000@origin.chass.utoronto.ca>

I am trying to put legends underneath the plot (in the outer margins). Is
there an easy way to do this. I have been tinkering with split..screen but
I could not make it work.

Thank in advance

Jean



From partha_bagchi at hgsi.com  Fri Jul 30 20:23:55 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Fri, 30 Jul 2004 14:23:55 -0400
Subject: [R] legend under plot region?
Message-ID: <OF5C5912BD.6C1A019C-ON85256EE1.0064B078-85256EE1.006511E3@hgsi.com>

Have a look at 
?par

You need to have par(xpd = TRUE) and then use par("usr") to get the 
coordinates for the edges of the plot. Also make sure you have enough 
space around the plot to put the legend. For that, have a look at par(oma) 
or par(mar) etc.

HTH.
Partha






Jean Eid <jeaneid at chass.utoronto.ca>
Sent by: r-help-bounces at stat.math.ethz.ch
07/30/2004 02:21 PM

 
        To:     r-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] legend under plot region?


I am trying to put legends underneath the plot (in the outer margins). Is
there an easy way to do this. I have been tinkering with split..screen but
I could not make it work.

Thank in advance

Jean

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From marzban at caps.ou.edu  Fri Jul 30 20:57:38 2004
From: marzban at caps.ou.edu (marzban)
Date: Fri, 30 Jul 2004 11:57:38 -0700 (PDT)
Subject: [R] cannot print/save graphics.
Message-ID: <Pine.LNX.4.44.0407301141520.2881-100000@x1-6-00-0f-1f-0c-15-4b>


Hi,

I'm running the latest version of R on a linux box.
 plot() does produce a grahpics window. But is it 
"normal" for that window to not respond to a left
or right mouse click?

What I'm really trying to do is the save the graphics
to a postscript file, but postscript() produces an "empty postscript 
file".  

Thanks,
Caren
-- 
http://www.nhn.ou.edu/~marzban



From jeaneid at chass.utoronto.ca  Fri Jul 30 21:55:50 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Fri, 30 Jul 2004 15:55:50 -0400
Subject: [R] cannot print/save graphics.
In-Reply-To: <Pine.LNX.4.44.0407301141520.2881-100000@x1-6-00-0f-1f-0c-15-4b>
Message-ID: <Pine.SGI.4.40.0407301553030.28311527-100000@origin.chass.utoronto.ca>

You have to have postscript("foo.eps", ..) before you issue the plot
commands and isuue a dev.off() at the end.

If you want to copy the plot graph to a postscript driver use
dev.copy2eps(file="foo.eps")


?dev.print
?postscript

Hope this helps.







On Fri, 30 Jul 2004, marzban wrote:

>
> Hi,
>
> I'm running the latest version of R on a linux box.
>  plot() does produce a grahpics window. But is it
> "normal" for that window to not respond to a left
> or right mouse click?
>
> What I'm really trying to do is the save the graphics
> to a postscript file, but postscript() produces an "empty postscript
> file".
>
> Thanks,
> Caren
> --
> http://www.nhn.ou.edu/~marzban
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From e.rapsomaniki at mail.cryst.bbk.ac.uk  Fri Jul 30 22:01:56 2004
From: e.rapsomaniki at mail.cryst.bbk.ac.uk (e.rapsomaniki@mail.cryst.bbk.ac.uk)
Date: Fri, 30 Jul 2004 21:01:56 +0100
Subject: [R] Three-way ANOVA?
Message-ID: <1091217716.410aa934608cb@webmail.cryst.bbk.ac.uk>


Hi,

I'm a biologist, so please forgive me if my question sounds absurd! I have 3
parameters x1, x2, x3 and a response variable y.The sample size is 75. I tried
to do the following:
mylm<-lm(y~ x1 + x2 + x3, data="mydata")

but i can only get stats from anova for the first 2 variables. The third comes
up as NA. The degrees of freedom for the third variable are 0.

Is there something else i could do to fit a model that contains all these three
variables?

Many Thanks
Eleni



From rebhi2001 at yahoo.com  Fri Jul 30 22:29:51 2004
From: rebhi2001 at yahoo.com (rebhi bsharat)
Date: Fri, 30 Jul 2004 13:29:51 -0700 (PDT)
Subject: [R] R  question......
Message-ID: <20040730202951.66356.qmail@web50706.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040730/2da3e75b/attachment.pl

From rolf at math.unb.ca  Fri Jul 30 22:46:19 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 30 Jul 2004 17:46:19 -0300 (ADT)
Subject: [R] Three-way ANOVA?
Message-ID: <200407302046.i6UKkJDD008497@erdos.math.unb.ca>


> I'm a biologist, so please forgive me

	Biologists are hard to forgive! :-)

>                                        if my question sounds absurd!

	The only absurd question is the one that is not asked.

> I have 3 parameters x1, x2, x3 and a response variable y.The
> sample size is 75. I tried to do the following:
> mylm<-lm(y~ x1 + x2 + x3, data="mydata")

	You really do need to clarify your thinking.  And your
	terminology.  Parameters are different from ***predictors***!

	So x1, x2, and x3 are predictor variables --- you say.
	Now just what ***kind*** of predictor variables are they?

> but i can only get stats from anova for the first 2 variables. The
> third comes up as NA. The degrees of freedom for the third variable
> are 0.

	If you really are doing ``3 way ANOVA'' each of x1, x2,
	and x3 should be a ***factor***.

	If that really is the case, then your experimental design
	is so ridiculously unbalanced that the x3 factor is
	redundant.  I.e. if you know the levels of x1 and x2 then
	you know what cell of the model you're in and you don't
	need x3 to tell you.

	E.g. suppose x1 has levels 1 and 2, x2 has levels ``a'' and
	``b'', and x3 has levels mung, gorp, clyde, and melvin ....
	but, when x1 = 1 and x2 = a, then x3 = mung,
	     when x1 = 1 and x2 = b, then x3 = gorp,
	     when x1 = 2 and x2 = a, then x3 = clyde,
	     when x1 = 2 and x2 = b, then x3 = melvin. 

	In such a situation x3 would add no further information
	and if you said lm(y~x1+x2+x3) the software would tell
	you to go stick your head in a pig, except it's too polite.

	However I suspect that this is not actually the case.
	I am guessing that you have a one-way ANOVA on a factor
	with 3 levels, and that x1, x2, and x3 are indicator
	variables such that ``xi'' is equal to 1 when the level
	of the factor is the i-th level, and 0 elsewise.

	So you are really doing a regression on (numeric variables)
	x1, x2, and x3 rather than doing an ANOVA.  And since x1 + x2
	+ x3 is identically equal to 1 (``= the constant term in the
	regression'') x3 is again redundant and the software
	essentially makes no use of it.

	This is just my guess; if that's not the case, you'll just
	have to tell us more about what ***is*** the case --- be much
	more explicit about the problem that you are trying to solve;
	tell us the practical background --- if you are going to get
	any useful advice.

> Is there something else i could do to fit a model that contains all
> these three variables?

	In a word no.  If the software tells you that x3 is
	irrelevant, it is irrelevant.  Nothing you can do will change
	that.  We are talking here about statistics, not religeon.

	You simply have to fit an ***appropriate*** model to your
	data, and then understand the output from the software that
	effects the fit.

	In order to choose an appropriate model you need to
	understand the models from which you make your choice; you
	need to know what you are actually ***doing***.  What do you
	really want to know?  How will statistical procedures bring
	you closer to knowing that?  Don't treat statistics as a
	magic wand whose operation is impenetrable to your
	understanding.  It isn't.  Neither a magic wand nor
	impenetrable.

	Finally let me say:  OK, you're a biologist.  There's no
	law against that.  But you are ***trying to do statistics***.
	It is ridiculous to try to do statistics without having
	a clue what it all means.  So, step 1:  Learn some statistics.
	Not all of statistics, but enough to ***understand*** the
	techniques that you seek to apply.


					cheers,

						Rolf Turner
						rolf at math.unb.ca



From MSchwartz at MedAnalytics.com  Sat Jul 31 00:16:40 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 30 Jul 2004 17:16:40 -0500
Subject: [R] Transparent backgrounds in png files
In-Reply-To: <OF3CAC6B22.79102B01-ONC1256EE1.004B27C0-C1256EE1.004C6729@BIVV.BE>
References: <OF3CAC6B22.79102B01-ONC1256EE1.004B27C0-C1256EE1.004C6729@BIVV.BE>
Message-ID: <1091225800.3940.28.camel@localhost.localdomain>

Patrick,

Here is one additional option for you.

I happened to be doing some searching on the OO.org site today for some
printing related issues in their Bugzilla equivalent.

There was a reference to a MS Office PDF import filter available from
ScanSoft that would enable you to create PDF vector based plot files in
R (using pdf()) and then import them into MS Office. 

There is a RFE in the OO.org issues list for this feature, which won't
appear before OO.org V2.0. If and when this becomes available it would
streamline some of the Linux -> Windows issues that have been discussed
in this thread.

More information on PDFConverter is available from the ScanSoft site at:

http://www.scansoft.com/pdfconverter/standard/

There is a standard version available for $49 (U.S) and a professional
version available for $99 (U.S.). Some example PDF -> Word documents are
available at http://www.scansoft.com/pdfconverter/demo/.

HTH,

Marc Schwartz



From ramasamy at cancer.org.uk  Sat Jul 31 01:30:52 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sat, 31 Jul 2004 00:30:52 +0100
Subject: [R] pairwise difference operator
Message-ID: <1091230252.3702.39.camel@localhost.localdomain>

There was a BioConductor thread today where the poster wanted to find
pairwise difference between columns of a matrix. I suggested the slow
solution below, hoping that someone might suggest a faster and/or more
elegant solution, but no other response.

I tried unsuccessfully with the apply() family. Searching the mailing
list was not very fruitful either. The closest I got to was a cryptic
chunk of code in pairwise.table().

Since I do use something similar myself occasionally, I am hoping
someone from the R-help list can suggest alternatives or past threads.
Thank you.

### Code ###
pairwise.difference <- function(m){
  npairs  <- choose( ncol(m), 2 )
  results <- matrix( NA, nc=npairs, nr=nrow(m) )
  cnames  <- rep(NA, npairs)
  if(is.null(colnames(m))) colnames(m) <- paste("col", 1:ncol(m), sep="")
  
  k <- 1
  for(i in 1:ncol(m)){
    for(j in 1:ncol(m)){
      if(j <= i) next;
      results[ ,k] <- m[ ,i] - m[ ,j]
      cnames[k]    <- paste(colnames(m)[ c(i, j) ], collapse=".vs.")
      k <- k + 1
    }
  }
  
  colnames(results) <- cnames
  rownames(results) <- rownames(m)
  return(results)
}

### Example using a matrix with 5 gene/row and 4 columns ###
mat <- matrix( sample(1:20), nc=4 )
colnames(mat) <- LETTERS[1:4]; rownames(mat) <- paste( "g", 1:5, sep="") 
mat
    A  B  C  D
g1 10 16  3 15
g2 18  5 12 19
g3  7  4  8 13
g4 14  2  6 11
g5 17  1 20  9

pairwise.difference(mat)
   A.vs.B A.vs.C A.vs.D B.vs.C B.vs.D C.vs.D
g1     -6      7     -5     13      1    -12
g2     13      6     -1     -7    -14     -7
g3      3     -1     -6     -4     -9     -5
g4     12      8      3     -4     -9     -5
g5     16     -3      8    -19     -8     11

Regards, 
-- 
Adaikalavan Ramasamy                    ramasamy at cancer.org.uk
Centre for Statistics in Medicine       http://www.ihs.ox.ac.uk/csm/
Cancer Research UK                      Tel : 01865 226 677
Old Road Campus, Headington, Oxford     Fax : 01865 226 962



From MSchwartz at MedAnalytics.com  Sat Jul 31 03:28:51 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 30 Jul 2004 20:28:51 -0500
Subject: [R] pairwise difference operator
In-Reply-To: <1091230252.3702.39.camel@localhost.localdomain>
References: <1091230252.3702.39.camel@localhost.localdomain>
Message-ID: <1091237331.3940.71.camel@localhost.localdomain>

On Fri, 2004-07-30 at 18:30, Adaikalavan Ramasamy wrote:
> There was a BioConductor thread today where the poster wanted to find
> pairwise difference between columns of a matrix. I suggested the slow
> solution below, hoping that someone might suggest a faster and/or more
> elegant solution, but no other response.
> 
> I tried unsuccessfully with the apply() family. Searching the mailing
> list was not very fruitful either. The closest I got to was a cryptic
> chunk of code in pairwise.table().
> 
> Since I do use something similar myself occasionally, I am hoping
> someone from the R-help list can suggest alternatives or past threads.
> Thank you.
> 
> ### Code ###
> pairwise.difference <- function(m){
>   npairs  <- choose( ncol(m), 2 )
>   results <- matrix( NA, nc=npairs, nr=nrow(m) )
>   cnames  <- rep(NA, npairs)
>   if(is.null(colnames(m))) colnames(m) <- paste("col", 1:ncol(m), sep="")
>   
>   k <- 1
>   for(i in 1:ncol(m)){
>     for(j in 1:ncol(m)){
>       if(j <= i) next;
>       results[ ,k] <- m[ ,i] - m[ ,j]
>       cnames[k]    <- paste(colnames(m)[ c(i, j) ], collapse=".vs.")
>       k <- k + 1
>     }
>   }
>   
>   colnames(results) <- cnames
>   rownames(results) <- rownames(m)
>   return(results)
> }
> 
> ### Example using a matrix with 5 gene/row and 4 columns ###
> mat <- matrix( sample(1:20), nc=4 )
> colnames(mat) <- LETTERS[1:4]; rownames(mat) <- paste( "g", 1:5, sep="") 
> mat
>     A  B  C  D
> g1 10 16  3 15
> g2 18  5 12 19
> g3  7  4  8 13
> g4 14  2  6 11
> g5 17  1 20  9
> 
> pairwise.difference(mat)
>    A.vs.B A.vs.C A.vs.D B.vs.C B.vs.D C.vs.D
> g1     -6      7     -5     13      1    -12
> g2     13      6     -1     -7    -14     -7
> g3      3     -1     -6     -4     -9     -5
> g4     12      8      3     -4     -9     -5
> g5     16     -3      8    -19     -8     11


How about this:

I am taking advantage of the combinations() function in the 'gregmisc'
package to define the pairwise column combinations based upon the input
matrix colnames. Given that, perhaps Greg might want to add this
function to the package if it holds up to scrutiny. Additional error
checking would be required as I note below.

pairwise.diffs <- function(x)
{
  if(is.null(colnames(x)))
    colnames(x) <- 1:ncol(x)

  col.diffs <- combinations(ncol(x), 2, colnames(x))
  result <- x[, col.diffs[, 1]] - x[, col.diffs[, 2]]
  colnames(result) <- paste(col.diffs[, 1], ".vs.", col.diffs[, 2], 
                            sep = "")
  result
}

What I am essentially doing is creating the matrix 'col.diffs' to hold
the combinations of the colnames in matrix 'x'. If 'x' does not have
colnames, I set them to the column indices. Then in line 2, I do the
pairwise subtractions. Line 3 simply sets up the colnames in the result
as the combinations.

Note that the subtractions, as you have above, are the first column
minus the second column in the pairwise combinations. You would also
want to check for an input matrix of <3 columns, since the 'result' in
that case would be a vector, rather than a matrix. In that case, you
could add code to coerce 'result' to a matrix, or simply not allow
matrices with <3 columns.

So, using your example matrix above (different seed value):

> mat <- matrix(sample(1:20), nc=4)
> colnames(mat) <- LETTERS[1:4]
> rownames(mat) <- paste( "g", 1:5, sep="") 
> mat
    A  B  C  D
g1  1 17 13 10
g2 12  5  7 16
g3  2 19  6 14
g4 20  4 11  8
g5  3 15 18  9

> pairwise.diffs(mat)
   A.vs.B A.vs.C A.vs.D B.vs.C B.vs.D C.vs.D
g1    -16    -12     -9      4      7      3
g2      7      5     -4     -2    -11     -9
g3    -17     -4    -12     13      5     -8
g4     16      9     12     -7     -4      3
g5    -12    -15     -6     -3      6      9


HTH,

Marc Schwartz



From ggrothendieck at myway.com  Sat Jul 31 04:24:33 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 31 Jul 2004 02:24:33 +0000 (UTC)
Subject: [R] pairwise difference operator
References: <1091230252.3702.39.camel@localhost.localdomain>
Message-ID: <loom.20040731T041634-894@post.gmane.org>

Adaikalavan Ramasamy <ramasamy <at> cancer.org.uk> writes:

: 
: There was a BioConductor thread today where the poster wanted to find
: pairwise difference between columns of a matrix. I suggested the slow
: solution below, hoping that someone might suggest a faster and/or more
: elegant solution, but no other response.
: 
: I tried unsuccessfully with the apply() family. Searching the mailing
: list was not very fruitful either. The closest I got to was a cryptic
: chunk of code in pairwise.table().
: 
: Since I do use something similar myself occasionally, I am hoping
: someone from the R-help list can suggest alternatives or past threads.
: Thank you.
: 
: ### Code ###
: pairwise.difference <- function(m){
:   npairs  <- choose( ncol(m), 2 )
:   results <- matrix( NA, nc=npairs, nr=nrow(m) )
:   cnames  <- rep(NA, npairs)
:   if(is.null(colnames(m))) colnames(m) <- paste("col", 1:ncol(m), sep="")
: 
:   k <- 1
:   for(i in 1:ncol(m)){
:     for(j in 1:ncol(m)){
:       if(j <= i) next;
:       results[ ,k] <- m[ ,i] - m[ ,j]
:       cnames[k]    <- paste(colnames(m)[ c(i, j) ], collapse=".vs.")
:       k <- k + 1
:     }
:   }
: 
:   colnames(results) <- cnames
:   rownames(results) <- rownames(m)
:   return(results)
: }
: 
: ### Example using a matrix with 5 gene/row and 4 columns ###
: mat <- matrix( sample(1:20), nc=4 )
: colnames(mat) <- LETTERS[1:4]; rownames(mat) <- paste( "g", 1:5, sep="") 
: mat
:     A  B  C  D
: g1 10 16  3 15
: g2 18  5 12 19
: g3  7  4  8 13
: g4 14  2  6 11
: g5 17  1 20  9
: 
: pairwise.difference(mat)
:    A.vs.B A.vs.C A.vs.D B.vs.C B.vs.D C.vs.D
: g1     -6      7     -5     13      1    -12
: g2     13      6     -1     -7    -14     -7
: g3      3     -1     -6     -4     -9     -5
: g4     12      8      3     -4     -9     -5
: g5     16     -3      8    -19     -8     11



1. Note that  mat[,j] - mat  subtracts each column of mat from the j-th column 
   so we just cbind 3 matrices:

      cbind( mat[,1]-mat[2:4], mat[,2]-mat[,3:4], mat[,3]-mat[,4,drop=F] )

2. For a general matrix a single sapply can do it like this:

      f <- function(i, mat) mat[, i-1] - mat[, i:ncol(mat), drop = FALSE]
      do.call("cbind", sapply(2:ncol(mat), f, mat))

3. To add nice column names just enhance f.  The statements "z <- ..."
   and "do.call ..." are the same as before:

      f <- function(i, mat) {
         z <- mat[, i-1] - mat[, i:ncol(mat), drop = FALSE]
         colnames(z) <- paste(colnames(mat)[i-1], colnames(z), sep = "-")
         z
      }
      do.call("cbind", sapply(2:ncol(mat), f, mat))



From ajayshah at mayin.org  Sat Jul 31 09:13:28 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Sat, 31 Jul 2004 12:43:28 +0530
Subject: [R] Question about manipulating quartiles
Message-ID: <20040731071328.GA15560@igidr.ac.in>

I know the `quantcut' function in the gregmisc package, and using it,
I'm able to use functions like aggregate to compute the mean or sd()
in each quartile.

What if I have a data frame containing x and y, and I want to make
quartiles by x, but then compute sum x / sum y in each quartile?
How does one persuade aggregate to do this?

Thanks,

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From ggrothendieck at myway.com  Sat Jul 31 09:36:50 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 31 Jul 2004 03:36:50 -0400 (EDT)
Subject: [R] Question about manipulating quartiles
Message-ID: <20040731073650.57C2F12CD8@mprdmxin.myway.com>



Check out ?by

For example,

   data(iris)
   by(iris, quantcut(iris[,1]), function(x) sum(x[,1]/x[,2]))

--

From:   	Ajay Shah <ajayshah at mayin.org>

I know the `quantcut' function in the gregmisc package, and using it,
I'm able to use functions like aggregate to compute the mean or sd()
in each quartile.

What if I have a data frame containing x and y, and I want to make
quartiles by x, but then compute sum x / sum y in each quartile?
How does one persuade aggregate to do this?



From ripley at stats.ox.ac.uk  Sat Jul 31 10:04:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 Jul 2004 09:04:05 +0100 (BST)
Subject: [R] Re: Optimizing a nonlinear function
In-Reply-To: <1091177965.410a0ded16707@webmail.iwinet.rug.nl>
Message-ID: <Pine.LNX.4.44.0407310903400.4609-100000@gannet.stats>

Please red the R FAQ, and what it says about not sending questions to 
individuals.

On Fri, 30 Jul 2004 stephen at iwi201.iwinet.rug.nl wrote:

> 
> Hi Prof. Ripley,
> I have a nonlinear function to optimize. Please find the details on the
> attached
> word document. I thought it would be clearer if I gave the formulae typed in
> math format.
> 
> My Question: Is there any nonlinear optimizer in R that can handle this sort of
> problem. Since I have many parameters, is there an optimizer that chooses
> starting values by itself, without having to give them by myself?
> 
> 
> I am on R-help mailing list but currently using a default e-mail address so I
> was not sure whether my mail could go through. So i decided to send you my
> question directly. I could do with a reply through R-help.
> 
> Thanks for your help.
> 
> 
> 
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sebastien.durand at umontreal.ca  Sat Jul 31 22:57:07 2004
From: sebastien.durand at umontreal.ca (Sebastien Durand)
Date: Sat, 31 Jul 2004 16:57:07 -0400
Subject: [R] dudi.pca behaviour and discrimin
Message-ID: <a06110400bd31b1716691@[192.168.2.3]>

Hello,

I not have attached in this e-mail the zipped 
list of matrices I am using because it has 1 meg 
once zipped and anyway we cannot send attached 
files on r-help mailling list.

First, after running the code that is written 
bellow, I realized that the printout of dudi.pca 
gives me for both of my matrices
$cw length that are unequal to either respective $rank or $eig lengths.
Is that normal, if not how can I solve it, or get 
around it?   (discrimin() seems to have an issue 
about that)

Secondly, it does not matter which matrices I am 
treating first, but once the second is pasted on 
the second run of my function best, discrimin 
crashes.
The weared thing about this is, that if I perform 
the same operations directly without making a 
function both matrices can be analysed by 
discrimin.
Is it my function that is wrong or the something within the discrimin code!

Here is my code:
load("~/matrix2.RData")

best<-function(liste=alt.transf,nombre=99){
	x<-liste[[nombre]]
	library(ade4)
	p<-99
	xx<-cov(x[,-(1:3)])
	a<-eigen(xx,only.values=T)
	poids<-cumsum(a$values/sum(a$values))
	nombre<-min(which(poids>=(p/100)),na.rm=T)
	acp<-dudi.pca(x[,-(1:3)],scale=T,scannf=F,nf=nombre) #if ve or vt
	print(acp)
	d<-discrimin(acp, as.factor(x[,1]),scan=F,nf=4)
  	return(d)
  }

  b<-best(k,1)

#look at the print out ...
....
$rank: 166
eigen values: 86.02 17.09 12.76 8.727 8.338 ...
   vector length mode    content
1 $cw    167    numeric column weights
2 $lw    475    numeric row weights
3 $eig   166    numeric eigen values
...
#now try
  b<-best(k,2)

#look at the print out ...
....
$rank: 218
eigen values: 104.7 28.94 14.56 10.62 7.793 ...
   vector length mode    content
1 $cw    219    numeric column weights
2 $lw    507    numeric row weights
3 $eig   218    numeric eigen values
...
Error in tapply(dudi$lw, fac, sum) : arguments must have same length

Any suggestions would be really helpful.  I got ton's a matrices to analyse

Thanks a lot!
-- 
  S??bastien Durand
Ma??trise en biologie
Universit?? de Montr??al
(514) 343-6864
Universit?? du Qu??bec ?? Montr??al
(514) 987-3000 (1572#)



From chzhang at cs.ucr.edu  Sat Jul 31 23:37:29 2004
From: chzhang at cs.ucr.edu (chuanjun zhang)
Date: Sat, 31 Jul 2004 14:37:29 -0700
Subject: [R] smooth.spline
Message-ID: <410C1119.9060201@cs.ucr.edu>

Dear Friends,
Is there anybody know where I can get the code which implement the 
smooth.spline function in R?
I have to know how the smooth.spline is implemented.
Thanks a lot.
Best.
Chuanjun



