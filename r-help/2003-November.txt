From meyer at ci.tuwien.ac.at  Sat Nov  1 00:09:54 2003
From: meyer at ci.tuwien.ac.at (David Meyer)
Date: Sat, 1 Nov 2003 00:09:54 +0100 (CET)
Subject: [R] problem with tune.svm
In-Reply-To: <OFEA899A05.0FE7ED23-ON85256DD0.0070B494-85256DD0.0070F38F@EU.novartis.net>
Message-ID: <Pine.LNX.4.21.0311010007430.5478-100000@boromir.ci.tuwien.ac.at>



On Fri, 31 Oct 2003 ryszard.czerminski at pharma.novartis.com wrote:

> > rng <- list(gamma = 2^(-1:1), cost = 2^(2:4))
> > rng
> $gamma
> [1] 0.5 1.0 2.0
> 
> $cost
> [1]  4  8 16
> 
> > obj <- tune.svm(pIC50 ~ ., data = data, ranges = rng)
> Error in tune(svm, train.x = x, data = data, ranges = ranges, ...) :
>         formal argument "ranges" matched by multiple actual arguments

The function `tune.svm' has no `range' argument, use `gamma' and `cost'
separately. The idea is to make `tune.foo' a `vectorized' function of
`foo' in the parameters. If you want to preconstruct a list, use

tune(svmobj, ranges = ...)

instead.

g.,
-d

> 
> Ay idea why ???
> 
> Ryszard
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ggrothendieck at myway.com  Sat Nov  1 00:31:52 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 31 Oct 2003 18:31:52 -0500 (EST)
Subject: [R] Array Dimension Names
Message-ID: <20031031233152.636E13982@mprdmxin.myway.com>



You could add attributes to your array when creating it
and then retrieve them:

  x <- matrix(1:8,2,4)
  attr(x,"workers") <- 1
  attr(x,"variables") <- 2

  apply(x,attr(x,"variables"),sum)

or perhaps:

  y <- matrix(1:8,2,4)
  attr(y,"margins") <- list(workers = 1, variables = 2)

  apply(y,attr(y,"margins")$variables,sum) 

These are simple enough that you might not need to develop your
own apply but you could pretty them up even more if you did:

  my.apply <- function(x,dim,fn) apply(x,attr(x,dim),fn)

  my.apply(x,"variables",sum)

---

From: <Benjamin.STABLER at odot.state.or.us>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Array Dimension Names 

 
 
I would like to reference array dimensions by name in an apply and a summary
function. For example:

apply(x, "workers", sum)

Is there a better way to do this than creating a new attribute for the array
and then creating new methods for apply and summary? I don't want to name
the individual elements of each dimension (such as with dimnames) but rather
name the dimensions. Thanks for your help.

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301 Ph: 503-986-4104


_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From tlumley at u.washington.edu  Sat Nov  1 01:47:28 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 31 Oct 2003 16:47:28 -0800 (PST)
Subject: [R] Change in 'solve' for r-patched
In-Reply-To: <70E1C0DB4F9B5E4F9CEDB8433F4A68B90306056A@PSBMAIL2>
References: <70E1C0DB4F9B5E4F9CEDB8433F4A68B90306056A@PSBMAIL2>
Message-ID: <Pine.A41.4.58.0310311543440.184628@homer06.u.washington.edu>

On Fri, 31 Oct 2003, Williams, Elliot - BLS wrote:
>
> None of these address the problem of numerical accuracy, which was the
> thrust of Doug's comments.  Has anyone done a quick simulation to
> investigate the stability of the solutions?  Is it small coefficients or
> near-collinearity (or both) that one has to worry about?
>
> Are the solve(crossprod()) methods obviously unstable?  They surely do work
> quickly!
>

They are usually not *very* unstable.  That is, solve(crossprod())
potentially loses about twice as many digits to rounding error as Doug's
proposals. In many cases this is not that serious -- if you have 15 digits
accuracy then losing 2 instead of 1 (or even 8 instead of 4) of them may
not be a big deal.  Back in the days of single precision this was more
obviously important and you would get visible differences between
statistical packages based on their linear algebra routines. (There was a
notorious econometric data set that caused problems in single precision
with the solve(crossprod()) approach but was fine with QR decomposition).

On the other hand, even with double precision in extreme situations the
harm can be noticeable, and the cost of working with QR or Cholesky
decompositions instead is fairly small (and often negative -- with larger
matrices you would probably see the cholesky-based method being faster)

In linear regression the problem happens with collinearity, or when one
variable has much smaller variance than another.  In both of these cases
the eigenvalues of the information matrix are of very different sizes. The
ratio of the smallest to the largest eigenvalue is called the condition
number, and the tolerance in solve() is based on condition numbers.

So how bad is the error? For any matrix M there exists some vector b and
error e in b so that the relative error in solve(M,b+e) compared to
solve(M,b) is the condition number of the matrix M times the relative
error in b.  This means that condition numbers greater than 10^7 (and
finding these in package examples is what prompted Doug's message) can
amplify numerical error ten million times.  This is starting to get
undesirable even when you have 15 digits to work with.

Working with very ill-conditioned matrices is possible, but it requires
care in tracking and bounding errors, and if I wanted to do that I'd be in
applied math, not biostatistics.  That's why a simple fix that reduces
condition numbers from, say, 10^10 to 10^5 really is worthwhile,
especially for software that will be used by other people who don't
understand its internals.


	-thomas



From sigma at consultoresestadisticos.com  Sat Nov  1 02:01:47 2003
From: sigma at consultoresestadisticos.com (Carlos J. Gil Bellosta)
Date: Sat, 01 Nov 2003 02:01:47 +0100
Subject: [R] Partial least squares.
Message-ID: <3FA305FB.7030406@consultoresestadisticos.com>

Dear R-helpers,

I am looking, quite unsuccesfully, for a number of functions/packages.

Firstly, I am interested in a package for partial least squares. I have 
found that there seemed to exist a package called pls, but which seems 
not to run any more with modern versions of R. I have not been able to 
find certain "chemometrics package" I found some people discussing about 
in this list some time ago and that, it seems, included these kind of 
functions.

Secondly, I have not been able to find a function "equivalent" to the 
SAS procedure STEPDISC which performs a step process (only available for 
lm and glm on R) on linear discriminant analysis (lda on R).

Does anybody know of a top-the-shelf answer to these questions?

Carlos J. Gil Bellosta
Sigma Consultores Estad?sticos
http://www.consultoresestadisticos.com



From andy_liaw at merck.com  Sat Nov  1 02:11:58 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 31 Oct 2003 20:11:58 -0500
Subject: [R] Partial least squares.
Message-ID: <3A822319EB35174CA3714066D590DCD50205CD9B@usrymx25.merck.com>

The package `pls.pcr' has NIPALS and SIMPLS.  There's also gpls in
BioConductor 1.3.

Andy

> -----Original Message-----
> From: Carlos J. Gil Bellosta 
> [mailto:sigma at consultoresestadisticos.com] 
> Sent: Friday, October 31, 2003 8:02 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Partial least squares.
> 
> 
> Dear R-helpers,
> 
> I am looking, quite unsuccesfully, for a number of functions/packages.
> 
> Firstly, I am interested in a package for partial least 
> squares. I have 
> found that there seemed to exist a package called pls, but 
> which seems 
> not to run any more with modern versions of R. I have not 
> been able to 
> find certain "chemometrics package" I found some people 
> discussing about 
> in this list some time ago and that, it seems, included these kind of 
> functions.
> 
> Secondly, I have not been able to find a function "equivalent" to the 
> SAS procedure STEPDISC which performs a step process (only 
> available for 
> lm and glm on R) on linear discriminant analysis (lda on R).
> 
> Does anybody know of a top-the-shelf answer to these questions?
> 
> Carlos J. Gil Bellosta
> Sigma Consultores Estad?sticos http://www.consultoresestadisticos.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From ross at biostat.ucsf.edu  Sat Nov  1 02:38:36 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 31 Oct 2003 17:38:36 -0800
Subject: [R] html glitches with help?
Message-ID: <1067650716.2459.39.camel@iron.libaux.ucsf.edu>

Looking at the html generated help pages for a package I'm working on, I
noticed a couple of things that looked a little funny.  I suspect they
are general features of the html for R (I don't usually look at it).

First is a problem of vertical alignment in tables. The first column
consistently aligned vertically *below* the alignment line of the bottom
line of the second column.  This was a problem even when both columns
were a single line; it was worse when they were multiple lines.

In slightly exagerated form, the output looked like this:

       long discussion of what paramater pp does
       and its wonderful features
pp

Likely at least two separate issues: why is it aligning with the last,
rather than the first, line of the second column, and why is it below
that?

It may be relevant that the first column was in \code{a} and the whole
thing was in an \arguments{\item{foo}{\tabular{ll} section.

Second, the items marked with \code{} appeared fainter than the other
text, and were a little hard to read.  I'd expect them to be bolder.

Perhaps the R.css style sheet could be tweaked for this?
R 1.7.1-1 on Debian GNU/Linux
Viewed with Mozilla 1.4
Konqueror from KDE 3.1.3 looked very similar, except the typeface for
\code was identical to that of the rest.

Sample excerpt from the .Rd file:

\value{returns a list:
  \item{singles}{data frame, one row per simulation, with the following
    columns:
    \tabular{ll}{
      coefficients \tab one column per variable\cr

      \code{pi1} \tab conditional probability of sampling cases \cr

Similar behavior in \arguments section.  It is the pi1 above, for
example, that is aligned poorly.  Alignment of the outer level \item's
is better (in fact, the opposite problem, their baseline is above the
baseline of the first line of the second column, though their tops are
not much higher).

-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From hungy at stat.ncu.edu.tw  Sat Nov  1 12:05:53 2003
From: hungy at stat.ncu.edu.tw (hungy@stat.ncu.edu.tw)
Date: Sat, 01 Nov 2003 12:05:53 +0800(CST)
Subject: [R] Question about the high dimensional density estimation
Message-ID: <20031101040553.249E368A2F@stat.ncu.edu.tw>

Hi,
I found that the R package "KernSmooth" can deal with only 1D and 2D data. But now I have a collection of 4-dimensional data (x1,x2,x3,x4) and would like to estimate the "mode" of the underlying density. What can I do about it ?
Thanks a lot.


--
Ying-Chao Hung
Assistant Professor
Graduate Institute of Statistics
National Central University
Chung-Li, Taiwan
TEL: 886-3-426-7219

From hb at maths.lth.se  Sat Nov  1 11:05:58 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 1 Nov 2003 11:05:58 +0100
Subject: [R] strange sprintf() behaviour ?
In-Reply-To: <OF0852459C.E2C634EF-ON85256DD0.006A067D-85256DD0.006C0C72@EU.novartis.net>
Message-ID: <000101c3a05f$c107ff90$4e0040d5@maths.lth.se>

Hi, sprintf() returns a character string ('s' for string). See ?sprintf.
It does not print (to standard output as you think). If you call it at
the R prompt you'll get a string, which is then printed. Thus, to print
it you should call cat(sprintf(...)) or print(sprintf(...)).  

About you previous question about %d and %f etc; If x is a double, %d
can be used with as.integer(x) and %.0f with x to output as an integer.

/Henrik

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> ryszard.czerminski at pharma.novartis.com
> Sent: den 31 oktober 2003 20:39
> To: rossini at u.washington.edu
> Cc: R help list; Bill Shipley; r-help-bounces at stat.math.ethz.ch
> Subject: [R] strange sprintf() behaviour ?
> 
> 
> This is quite strange behaviour - at least for R-novice as myself....
> 
> Consider this:
> 
> > testf <- function() { x <-2; sprintf("%s %f", "x =", x); 
> return(x) } 
> > result <- testf() testf <- function() { x <-2; sprintf("%s 
> %f", "x =", 
> > x) } result <- testf()
> > testf()
> [1] "x = 2.000000"
> 
> Apparently  adding return() statement and invoking function like this 
> "result <- testf()"
> suppresses output from sprintf()
> 
> Output from print() is NOT suppressed:
> 
> > testf <- function() { x <-2; print(c("x =", x)) }
> > result <- testf()
> [1] "x =" "2"
> > testf <- function() { x <-2; print(c("x =", x)); return(x) 
> } result <- 
> > testf()
> [1] "x =" "2"
> 
> Is there a way to use sprintf() inside a function ?
> 
> I guess I can say: print(sprintf()) - is it the only solution 
> for this ?
> 
> R
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> 
>



From mailinglist2_wegmann at web.de  Sat Nov  1 14:05:58 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Sat, 1 Nov 2003 14:05:58 +0100
Subject: [R] first 3 minimums
Message-ID: <200311011405.58086.mailinglist2_wegmann@web.de>

Hello, 

I have a df with plots (60) and their distances to bores (20) and would like 
to compute the three minimum distances to bores of each plot. 

with 
>apply(df, 2, min) 
I get the overall min, but is there a way to get additionally to the first 
min, the second and third minimum distance?

thanks in advance, cheers Martin



From baron at psych.upenn.edu  Sat Nov  1 14:26:01 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 1 Nov 2003 08:26:01 -0500
Subject: [R] first 3 minimums
In-Reply-To: <200311011405.58086.mailinglist2_wegmann@web.de>
References: <200311011405.58086.mailinglist2_wegmann@web.de>
Message-ID: <20031101132601.GA18782@mail1.sas.upenn.edu>

On 11/01/03 14:05, Martin Wegmann wrote:
>Hello, 
>
>I have a df with plots (60) and their distances to bores (20) and would like 
>to compute the three minimum distances to bores of each plot. 
>
>with 
>>apply(df, 2, min) 
>I get the overall min, but is there a way to get additionally to the first 
>min, the second and third minimum distance?

Something like:
apply(df,2,sort)[1:3,]
or
apply(df,2,sort)[,1:3]
or
apply(df,1,sort)[,1:3]
or
apply(df,1,sort)[1:3,]

I can't think through how your data are laid out, but I'm pretty
sure one of these will work.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From mailinglist2_wegmann at web.de  Sat Nov  1 14:36:56 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Sat, 1 Nov 2003 14:36:56 +0100
Subject: [R] first 3 minimums - works
In-Reply-To: <20031101132601.GA18782@mail1.sas.upenn.edu>
References: <200311011405.58086.mailinglist2_wegmann@web.de>
	<20031101132601.GA18782@mail1.sas.upenn.edu>
Message-ID: <200311011436.56777.mailinglist2_wegmann@web.de>

On Saturday 01 November 2003 14:26, Jonathan Baron wrote:
> On 11/01/03 14:05, Martin Wegmann wrote:
> >Hello,
> >
> >I have a df with plots (60) and their distances to bores (20) and would
> > like to compute the three minimum distances to bores of each plot.
> >
> >with
> >
> >>apply(df, 2, min)
> >
> >I get the overall min, but is there a way to get additionally to the first
> >min, the second and third minimum distance?
>
> Something like:
> apply(df,2,sort)[1:3,]
> or
> apply(df,2,sort)[,1:3]
> or
> apply(df,1,sort)[,1:3]
> or
> apply(df,1,sort)[1:3,]
>
> I can't think through how your data are laid out, but I'm pretty
> sure one of these will work.

apply(df,2,sort)[1:3,] worked for my data set

thanks Berwin & Jonathan for the quick help! Martin



From Markus.Koesters at uni-jena.de  Sat Nov  1 15:31:40 2003
From: Markus.Koesters at uni-jena.de (Markus Koesters)
Date: Sat, 01 Nov 2003 15:31:40 +0100
Subject: [R] Beginner: Homogenity of Variances
Message-ID: <3FA3D1DC.3767.11A3C2C@localhost>

Hello,

for my meta-analysis I try to test if two varainces are equal without 
using the raw scores. I have is the SD's, N's and the Means.
I want to test the variances from dependent and independend 
samples.
I assume I can use the var.test procedure for the independent 
samples, but what about the dependent samples ? Has anyone an 
idea how to realise this with R ?
Thanks in advance

Markus



From solares at unsl.edu.ar  Sat Nov  1 15:26:52 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Sat, 1 Nov 2003 11:26:52 -0300 (ART)
Subject: [R] c code in R
Message-ID: <59209.170.210.173.216.1067696812.squirrel@inter14.unsl.edu.ar>

Hi, my question is How i cant to execute c code within R for example
name of program probe.c (in workpath of R)
#include<stdio.h>
void main(){
int x;
scanf("%d\n",&x)
printf("%d\n",x)
}
 and in R i make 
.c("probe.c")
i'm obtain no load table simbol, but i compile the program with Borland C 
5.0 and obtain the .obj archive (probe.obj and the .exe).I have to make the 
load in R?. What is wrong?, Thanks Ruben



From ligges at statistik.uni-dortmund.de  Sat Nov  1 15:51:34 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 01 Nov 2003 15:51:34 +0100
Subject: [R] c code in R
In-Reply-To: <59209.170.210.173.216.1067696812.squirrel@inter14.unsl.edu.ar>
References: <59209.170.210.173.216.1067696812.squirrel@inter14.unsl.edu.ar>
Message-ID: <3FA3C876.40603@statistik.uni-dortmund.de>

solares at unsl.edu.ar wrote:

> Hi, my question is How i cant to execute c code within R for example
> name of program probe.c (in workpath of R)
> #include<stdio.h>
> void main(){
> int x;
> scanf("%d\n",&x)
> printf("%d\n",x)
> }
>  and in R i make 
> .c("probe.c")
> i'm obtain no load table simbol, but i compile the program with Borland C 
> 5.0 and obtain the .obj archive (probe.obj and the .exe).I have to make the 
> load in R?. What is wrong?, Thanks Ruben

Your mistake was that you have read neither
a) the R for Windows FAQ, Section 7.3 "How do I include compiled C 
code?", nor
b) the manual "Writing R Extensions".

Uwe Ligges



From spencer.graves at pdf.com  Sat Nov  1 16:50:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 01 Nov 2003 07:50:02 -0800
Subject: [R] Beginner: Homogenity of Variances
In-Reply-To: <3FA3D1DC.3767.11A3C2C@localhost>
References: <3FA3D1DC.3767.11A3C2C@localhost>
Message-ID: <3FA3D62A.2000206@pdf.com>

      I don't see a way to use var.test without data vectors.  However, 
you could trick it as illustrated by the following: 

      SD1 <- SD2 <- N1 <- N2 <- 5
      var.test(SD1*rnorm(N1), SD2*rnorm(N2))

      For more than two variances, you could use bartlett.test 
similarly.  However, Bartlett's test, and presumably also var.test, is 
highly sensitive to non-normality.  I don't have a citation, but I 
remember hearing George Box say that Bartlett's test is almost a better 
test of non-normality than of inhomogeneity of variance.  If you needed 
a citation for that, I would look first at various papers and book 
sections discussing robustness and Bartlett's test, especially in the 
index of Box on Quality and Discovery (Wiley, 2000) or his earlier 
collected works volumes. 

      This may answer to "independent samples" question.  However, we 
would need to know more about the nature of the dependence to answer the 
dependent samples question, and a sensible answer to the latter may 
require untenable assumptions. 

      hope this helps.  spencer graves

Markus Koesters wrote:

>Hello,
>
>for my meta-analysis I try to test if two varainces are equal without 
>using the raw scores. I have is the SD's, N's and the Means.
>I want to test the variances from dependent and independend 
>samples.
>I assume I can use the var.test procedure for the independent 
>samples, but what about the dependent samples ? Has anyone an 
>idea how to realise this with R ?
>Thanks in advance
>
>Markus
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From Markus.Koesters at uni-jena.de  Sat Nov  1 17:18:40 2003
From: Markus.Koesters at uni-jena.de (Markus Koesters)
Date: Sat, 01 Nov 2003 17:18:40 +0100
Subject: [R] Beginner: Homogenity of Variances
In-Reply-To: <3FA3D62A.2000206@pdf.com>
References: <3FA3D1DC.3767.11A3C2C@localhost>
Message-ID: <3FA3EAF0.1490.90696@localhost>

Thank you very much for the quick answer, I'll try that.

The dependence for the other samples are a result of the designs of 
the studies I want to metaanalyse - most of them are single group 
studies with pre-post measures.

regards,

Markus 




>       I don't see a way to use var.test without data vectors.  However, 
> you could trick it as illustrated by the following: 
> 
>       SD1 <- SD2 <- N1 <- N2 <- 5
>       var.test(SD1*rnorm(N1), SD2*rnorm(N2))
> 
>       For more than two variances, you could use bartlett.test 
> similarly.  However, Bartlett's test, and presumably also var.test, is 
> highly sensitive to non-normality.  I don't have a citation, but I 
> remember hearing George Box say that Bartlett's test is almost a better 
> test of non-normality than of inhomogeneity of variance.  If you needed 
> a citation for that, I would look first at various papers and book 
> sections discussing robustness and Bartlett's test, especially in the 
> index of Box on Quality and Discovery (Wiley, 2000) or his earlier 
> collected works volumes. 
> 
>       This may answer to "independent samples" question.  However, we 
> would need to know more about the nature of the dependence to answer the 
> dependent samples question, and a sensible answer to the latter may 
> require untenable assumptions. 
> 
>       hope this helps.  spencer graves
> 
> Markus Koesters wrote:
> 
> >Hello,
> >
> >for my meta-analysis I try to test if two varainces are equal without 
> >using the raw scores. I have is the SD's, N's and the Means.
> >I want to test the variances from dependent and independend 
> >samples.
> >I assume I can use the var.test procedure for the independent 
> >samples, but what about the dependent samples ? Has anyone an 
> >idea how to realise this with R ?
> >Thanks in advance
> >
> >Markus
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >  
> >
>



From jasont at indigoindustrial.co.nz  Sat Nov  1 17:38:04 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun, 02 Nov 2003 05:38:04 +1300
Subject: [R] Question about the high dimensional density estimation
In-Reply-To: <20031101040553.249E368A2F@stat.ncu.edu.tw>
References: <20031101040553.249E368A2F@stat.ncu.edu.tw>
Message-ID: <3FA3E16C.8050601@indigoindustrial.co.nz>

hungy at stat.ncu.edu.tw wrote:
> Hi,
> I found that the R package "KernSmooth" can deal with 
> only 1D and 2D data. But now I have a collection of
> 4-dimensional data (x1,x2,x3,x4) and would like to estimate
> the "mode" of the underlying density. What can I do
> about it ?

The gss package might do what you want here.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From bates at stat.wisc.edu  Sat Nov  1 19:08:59 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 01 Nov 2003 12:08:59 -0600
Subject: [R] Change in 'solve' for r-patched
In-Reply-To: <Pine.A41.4.58.0310311543440.184628@homer06.u.washington.edu>
References: <70E1C0DB4F9B5E4F9CEDB8433F4A68B90306056A@PSBMAIL2>
	<Pine.A41.4.58.0310311543440.184628@homer06.u.washington.edu>
Message-ID: <6rekwsufk4.fsf@bates4.stat.wisc.edu>

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Fri, 31 Oct 2003, Williams, Elliot - BLS wrote:
> >
> > None of these address the problem of numerical accuracy, which was the
> > thrust of Doug's comments.  Has anyone done a quick simulation to
> > investigate the stability of the solutions?  Is it small coefficients or
> > near-collinearity (or both) that one has to worry about?
> >
> > Are the solve(crossprod()) methods obviously unstable?  They surely do work
> > quickly!
> >
> 
> They are usually not *very* unstable.  That is, solve(crossprod())
> potentially loses about twice as many digits to rounding error as Doug's
> proposals. In many cases this is not that serious -- if you have 15 digits
> accuracy then losing 2 instead of 1 (or even 8 instead of 4) of them may
> not be a big deal.  Back in the days of single precision this was more
> obviously important and you would get visible differences between
> statistical packages based on their linear algebra routines. (There was a
> notorious econometric data set that caused problems in single precision
> with the solve(crossprod()) approach but was fine with QR decomposition).
> 
> On the other hand, even with double precision in extreme situations the
> harm can be noticeable, and the cost of working with QR or Cholesky
> decompositions instead is fairly small (and often negative -- with larger
> matrices you would probably see the cholesky-based method being faster)
> 
> In linear regression the problem happens with collinearity, or when one
> variable has much smaller variance than another.  In both of these cases
> the eigenvalues of the information matrix are of very different sizes. The
> ratio of the smallest to the largest eigenvalue is called the condition
> number, and the tolerance in solve() is based on condition numbers.
> 
> So how bad is the error? For any matrix M there exists some vector b and
> error e in b so that the relative error in solve(M,b+e) compared to
> solve(M,b) is the condition number of the matrix M times the relative
> error in b.  This means that condition numbers greater than 10^7 (and
> finding these in package examples is what prompted Doug's message) can
> amplify numerical error ten million times.  This is starting to get
> undesirable even when you have 15 digits to work with.
> 
> Working with very ill-conditioned matrices is possible, but it requires
> care in tracking and bounding errors, and if I wanted to do that I'd be in
> applied math, not biostatistics.  That's why a simple fix that reduces
> condition numbers from, say, 10^10 to 10^5 really is worthwhile,
> especially for software that will be used by other people who don't
> understand its internals.

As Thomas indicates, the numerical distinction between using X'X and
using X directly for least squares calculations are important in some
cases but not very important in most cases.

Regarding timings, I will agree that if mm is a model matrix and y is
the response then

solve(crossprod(mm), crossprod(mm,y))

is very fast, especially if R is using ATLAS (or, in my case, Goto's
BLAS).  The crossprod and the solve calculations are very highly
optimized.

However, in current versions of R

chol2inv(crossprod(mm)) %*% crossprod(mm,y)

is competitive in terms of timing, should be slightly more stable (it
uses the Cholesky decomposition of the positive-definite matrix
crossprod(mm) rather than an LU decomposition) and also produces the
(X'X)^{-1} matrix.

As an example, I use the model matrix and response from an example in
Koenker and Ng's sparseMatrix package.  The computer is a 2.0 GHz
Pentium 4 (512 KB L2 cache) running Debian GNU/Linux.  R is using
Goto's BLAS.  The mmd matrix is a dense version of the model matrix.

By far the fastest timing uses sparse matrix techniques on the sparse
model matrix mm but that is a different issue.

> str(mm)
 list()
 - attr(*, "p")= int [1:713] 0 13 17 26 38 43 52 56 61 67 ...
 - attr(*, "i")= int [1:8758] 0 2 25 27 163 165 1258 1261 1276 1278 ...
 - attr(*, "x")= num [1:8758] 0.277 0.277 0.277 0.277 0.277 ...
 - attr(*, "nrow")= int 1850
 - attr(*, "class")= atomic [1:1] cscMatrix
  ..- attr(*, "package")= chr "taucs"
> str(y)
 num [1:1850] 64.07  5.88 64.03  5.96 76.41 ...
> mmd = as(mm, "matrix")
> dim(mmd)
[1] 1850  712
> str(mmd)
 num [1:1850, 1:712] 0.277 0.000 0.277 0.000 0.000 ...
> system.time(bsparse <- solve(crossprod(mm), crossprod(mm,y)))
[1] 0.05 0.00 0.05 0.00 0.00
> system.time(bsparse <- solve(crossprod(mm), crossprod(mm,y)))
[1] 0.05 0.00 0.07 0.00 0.00
> str(bsparse)
 num [1:712, 1] 823 340 473 349 188 ...

It turns out that qr(mmd) is considerably slower than crossprod(mmd).
I had thought that this might be because the default for qr is to use
Linpack code, which only uses level-1 BLAS. However, even with
LAPACK=TRUE it is slow.  Presently the LAPACK=TRUE version in R does
full column pivoting and the LAPACK=FALSE version only pivots on
apparent singularity.  It may be that gains from using level-3 BLAS in
the LAPACK version are offset by the expense of doing the full pivoting.

(I will be experimenting with a LAPACK-based version that does
pivoting on apparent singularity but it will take some time to work out
all the details.)

> system.time(crossprod(mmd))
[1] 0.38 0.01 0.40 0.00 0.00
> system.time(crossprod(mmd))
[1] 0.37 0.01 0.38 0.00 0.00
> system.time(qr(mmd))
[1] 3.66 0.06 3.73 0.00 0.00
> system.time(qr(mmd))
[1] 3.57 0.07 3.64 0.00 0.00
> system.time(qr(mmd, LAPACK = TRUE))
[1] 3.50 0.05 3.57 0.00 0.00
> system.time(qr(mmd, LAPACK = TRUE))
[1] 3.51 0.04 3.55 0.00 0.00

A solution of the least squares system using the Cholesky and chol2inv
is relatively fast.  In fact, on this machine, it is marginally faster
than using the LU-based solve and it produces (X'X)^{-1}, in case you
need that.

> system.time(bc2i <- chol2inv(chol(crossprod(mmd))) %*% crossprod(mmd, y))
[1] 0.60 0.02 0.63 0.00 0.00
> system.time(bc2i <- chol2inv(chol(crossprod(mmd))) %*% crossprod(mmd, y))
[1] 0.60 0.03 0.63 0.00 0.00
> all.equal(bsparse, bc2i)
[1] TRUE
> system.time(bLU <- solve(crossprod(mmd), crossprod(mmd, y)))
[1] 0.65 0.06 0.71 0.00 0.00
> system.time(bLU <- solve(crossprod(mmd), crossprod(mmd, y)))
[1] 0.64 0.06 0.71 0.00 0.00
> str(bLU)
 num [1:712, 1] 823 340 473 349 188 ...
> all.equal(bLU, bsparse)
[1] TRUE

Methods using the QR decompositions are much slower but should be more
accurate.

> system.time(bQR <- qr.coef(qr(mmd), y))
[1] 3.95 0.10 4.06 0.00 0.00
> system.time(bQR <- qr.coef(qr(mmd), y))
[1] 3.70 0.11 3.81 0.00 0.00
> str(bQR)
 num [1:712] 823 340 473 349 188 ...
> all.equal(bQR, bsparse[,1])
[1] TRUE

*Warning* Don't try the next timing in R-1.8.0 or earlier.  Wait for
R-1.8.1. There is a bug in the code called by qr.coef when given an
Lapack-based qr object.  I have committed a fix to r-devel and will
also fix r-patched (a.k.a. R-1.8.1 alpha).

> system.time(bLA <- qr.coef(qr(mmd, LAPACK = TRUE), y))
[1] 3.57 0.03 3.61 0.00 0.00
> system.time(bLA <- qr.coef(qr(mmd, LAPACK = TRUE), y))
[1] 3.57 0.04 3.61 0.00 0.00
> all.equal(bLA, bsparse)
[1] "target is numeric, current is matrix"
> all.equal(bLA, bsparse[, 1])
[1] TRUE



From roger at ysidro.econ.uiuc.edu  Sat Nov  1 19:48:46 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Sat, 1 Nov 2003 12:48:46 -0600 (CST)
Subject: [R] Change in 'solve' for r-patched
In-Reply-To: <6rekwsufk4.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.SOL.4.30.0311011241180.6513-100000@ysidro.econ.uiuc.edu>

For those possibly interested in reading something more about the rehabilitation of the
Cholesky decomposition following its long exile in the Siberia of numerical analysis
I would recommend Micheal Saunders brief:

\textsc{Saunders, M.~A.}  (1994): ``Major Cholesky would feel proud,''
  \emph{ORSA J. on Computing}, 6, 23--27.



url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On 1 Nov 2003, Douglas Bates wrote:

> Thomas Lumley <tlumley at u.washington.edu> writes:
>
>
> chol2inv(crossprod(mm)) %*% crossprod(mm,y)
>
> is competitive in terms of timing, should be slightly more stable (it
> uses the Cholesky decomposition of the positive-definite matrix
> crossprod(mm) rather than an LU decomposition) and also produces the
> (X'X)^{-1} matrix.



From johnbkim at fastmail.fm  Sun Nov  2 00:00:04 2003
From: johnbkim at fastmail.fm (John Kim)
Date: Sat, 1 Nov 2003 15:00:04 -0800
Subject: [R] Calling R from PHP on Win2K?
References: <mailman.0.1067726969.30580.r-help@stat.math.ethz.ch>
Message-ID: <00ee01c3a0cb$e5146470$1decbf82@sdsufs04>

Hi everyone,

I'd like to call R from a PHP script to draw graphs (using data selected
from a MySQL database) on Windows 2000. I think what I need to do is:

1) Install R for Windows
2) Install Perl
3) From PHP make a system call to Rcmd.exe
4) ???

Does this seem right and/or possible? I'm not sure how PHP can "receive" the
graphic generated by R. I have Apache/PHP/MySQL running. Any help or
pointers would be appreciated.

-John



From maura.melis at pandora.be  Sun Nov  2 04:32:15 2003
From: maura.melis at pandora.be (Maura Melis)
Date: Sun, 02 Nov 2003 04:32:15 +0100
Subject: [R] Boxplot with full x-range
Message-ID: <oprxzqr1qelcz4ne@mail.pandora.be>

Hi all,

I'm new to R, and have the following problem:

I wish to draw a boxplot of simple data in two columns.   The x-axis 
(taken from first column) is grouped to intervals (using 'cut').
These intervals serve as x-value to the boxplot, and the data from the 
second column are the y-values.

The problem is that I want to give an impression of the trend of the data 
in the x-range.  However, when an interval on the x-axis contains no 
y-data, no box is drawn, and the plot becomes 'narrower' in the 
x-direction, giving a wrong impression of the trend of the y-value.

What I want is that no box is drawn for emtpy interval, but some X-space 
is kept open.  In other words, I want ALL interval to be drawn, including 
the empty ones.

Example scenario:

data.dat:
0.1 5
0.15 4.5
0.3 2
0.31 2.2
0.5 1
0.55 1.1
0.56 1.15
0.7 0.5
0.9 0.1


> mydata <- read.table("data.dat")
> attach(mydata)
> cats = cut( V1, breaks=(0:10)*.1)
> symmary( cats )

(0,0.1] (0.1,0.2] (0.2,0.3] (0.3,0.4] (0.4,0.5] (0.5,0.6] (0.6,0.7] 
(0.7,0.8]
         1         1         1         1         1         2         
1         0
(0.8,0.9]   (0.9,1]
         1         0

## notice two intervals with zero elements

>  boxplot( V2 ~ cats )  ## this draws the boxplot, and just ignores the 
> empty intervals

Any help would be appreciated,

tnx

Piet


(running R1.7.0 on SUSE linux 8.1, AMD Athlon)


---
Piet van Remortel
Belgium
pvremortATvub.ac.be



From kjetil at entelnet.bo  Sun Nov  2 05:39:34 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sun, 02 Nov 2003 00:39:34 -0400
Subject: [R] Boxplot with full x-range
In-Reply-To: <oprxzqr1qelcz4ne@mail.pandora.be>
Message-ID: <3FA45246.25623.A42ADB@localhost>

On 2 Nov 2003 at 4:32, Maura Melis wrote:

?boxplot

look at the argument at=, where you can give the position for each of 
the boxes.

(with this data you could also be interested in 
?coplot)

Kjetil Halvorse

> Hi all,
> 
> I'm new to R, and have the following problem:
> 
> I wish to draw a boxplot of simple data in two columns.   The x-axis 
> (taken from first column) is grouped to intervals (using 'cut').
> These intervals serve as x-value to the boxplot, and the data from the 
> second column are the y-values.
> 
> The problem is that I want to give an impression of the trend of the data 
> in the x-range.  However, when an interval on the x-axis contains no 
> y-data, no box is drawn, and the plot becomes 'narrower' in the 
> x-direction, giving a wrong impression of the trend of the y-value.
> 
> What I want is that no box is drawn for emtpy interval, but some X-space 
> is kept open.  In other words, I want ALL interval to be drawn, including 
> the empty ones.
> 
> Example scenario:
> 
> data.dat:
> 0.1 5
> 0.15 4.5
> 0.3 2
> 0.31 2.2
> 0.5 1
> 0.55 1.1
> 0.56 1.15
> 0.7 0.5
> 0.9 0.1
> 
> 
> > mydata <- read.table("data.dat")
> > attach(mydata)
> > cats = cut( V1, breaks=(0:10)*.1)
> > symmary( cats )
> 
> (0,0.1] (0.1,0.2] (0.2,0.3] (0.3,0.4] (0.4,0.5] (0.5,0.6] (0.6,0.7] 
> (0.7,0.8]
>          1         1         1         1         1         2         
> 1         0
> (0.8,0.9]   (0.9,1]
>          1         0
> 
> ## notice two intervals with zero elements
> 
> >  boxplot( V2 ~ cats )  ## this draws the boxplot, and just ignores the 
> > empty intervals
> 
> Any help would be appreciated,
> 
> tnx
> 
> Piet
> 
> 
> (running R1.7.0 on SUSE linux 8.1, AMD Athlon)
> 
> 
> ---
> Piet van Remortel
> Belgium
> pvremortATvub.ac.be
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun Nov  2 08:31:13 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Nov 2003 07:31:13 +0000 (GMT)
Subject: [R] Calling R from PHP on Win2K?
In-Reply-To: <00ee01c3a0cb$e5146470$1decbf82@sdsufs04>
Message-ID: <Pine.LNX.4.44.0311020726140.3436-100000@gannet.stats>

On Sat, 1 Nov 2003, John Kim wrote:

> I'd like to call R from a PHP script to draw graphs (using data selected
> from a MySQL database) on Windows 2000. I think what I need to do is:
> 
> 1) Install R for Windows
> 2) Install Perl
> 3) From PHP make a system call to Rcmd.exe

No.  Rcmd.exe is just a frontend to R's utilities; it does not run R.
I suggest you do 1) first and understand how R on Windows works.

> 4) ???
> 
> Does this seem right and/or possible? I'm not sure how PHP can "receive" the
> graphic generated by R. 

I am not sure what you mean: PHP is a scripting language, not a graphics 
windowing system.

> I have Apache/PHP/MySQL running. Any help or
> pointers would be appreciated.

The usual way to do this on Windows is via DCOM (see the rw-FAQ), but you 
could call the command-line executable Rterm.exe and either let it display 
files or create e.g. PNGs and subsequently put those on a web page.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tencpa at yahoo.it  Sun Nov  2 08:35:37 2003
From: tencpa at yahoo.it (Paolo Tenconi)
Date: Sun, 02 Nov 2003 08:35:37 +0100
Subject: [R] Calling R from PHP on Win2K?
In-Reply-To: <00ee01c3a0cb$e5146470$1decbf82@sdsufs04>
References: <mailman.0.1067726969.30580.r-help@stat.math.ethz.ch>
	<00ee01c3a0cb$e5146470$1decbf82@sdsufs04>
Message-ID: <oprxz11np20rxtxe@smtp.mail.yahoo.it>

You could query your dbase using the RMySql package and then publish your 
results using the RWeb package.
Paolo



On Sat, 1 Nov 2003 15:00:04 -0800, John Kim <johnbkim at fastmail.fm> wrote:

> Hi everyone,
>
> I'd like to call R from a PHP script to draw graphs (using data selected
> from a MySQL database) on Windows 2000. I think what I need to do is:
>
> 1) Install R for Windows
> 2) Install Perl
> 3) From PHP make a system call to Rcmd.exe
> 4) ???
>
> Does this seem right and/or possible? I'm not sure how PHP can "receive" 
> the
> graphic generated by R. I have Apache/PHP/MySQL running. Any help or
> pointers would be appreciated.
>
> -John
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From bernd.weiss at uni-koeln.de  Sun Nov  2 11:17:24 2003
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Sun, 02 Nov 2003 11:17:24 +0100
Subject: [R] barchart in lattice
Message-ID: <3FA4E7C4.31088.6EB83C@localhost>

Dear all,

I have two factors 'country' and 'status' which I would like to plot via barchart (lattice). 
'status' consist of three different levels and should be the grouping variable, i.e. there 
should be drawn three different panels and within each panel a barchart of 'country'. 

barchart(daten$COUNTRY|daten$STATUS), 
barchart(table(daten$COUNTRY)|table(daten$STATUS)),
etc. are obviously wrong.  

I have absolutely no idea how to do this. 

You can download the datafile from <http://www.uni-koeln.de/~ahf34/meta.txt>

TIA,

Bernd 

-- 
Bernd Weiss, M.A.
Universitaet zu Koeln / University of Cologne
Forschungsinstitut fuer Soziologie / Research Institute for Sociology
Greinstr. 2 / 50 939 Cologne / Germany
Phone: +49 221 / 470-4234
E-Mail: <bernd.weiss at uni-koeln.de>



From christoph.bier at web.de  Sun Nov  2 11:55:41 2003
From: christoph.bier at web.de (Christoph Bier)
Date: Sun, 02 Nov 2003 11:55:41 +0100
Subject: [R] Weird problem with median on a factor
In-Reply-To: <883C49C3E47BD6118B3000902771AB91112994@GUARDIAN>
References: <883C49C3E47BD6118B3000902771AB91112994@GUARDIAN>
Message-ID: <3FA4E2AD.10201@web.de>

Dave Cacela schrieb:
> Christoph,
> 
> I concur with the other respondents who questioned why someone would wish to
> calculate the median of a factor. However, with regard to your actual
> question, I suspect that median() is giving different answers because the
> two vectors are not both factors, i.e., that one of them is a character. Did
> you test that? 

Yes, I did and find the same like Tony Plate:

 > is.factor(fbhint.spss1$V15.SPS) # = column 264
[1] TRUE
 > mode(fbhint.spss1$V15.SPS)
[1] "numeric"
 > is.factor(fbhint.spss1$V15.SP1) # = column 566
[1] TRUE
 > mode(fbhint.spss1$V15.SP1)
[1] "numeric"

> Using S, I have seen quirks in this regard that relate to import procedure
> and the value of the first element in the vector. In your case, the first
> elements differ in that one is NA while the other is "teils/teils".  

It also occurs if the first element is the same. For example "wichtig" in 
columns 263 and 565.

Regards,

Christoph



From p.dalgaard at biostat.ku.dk  Sun Nov  2 12:50:37 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Nov 2003 12:50:37 +0100
Subject: [R] Weird problem with median on a factor
In-Reply-To: <3FA4E2AD.10201@web.de>
References: <883C49C3E47BD6118B3000902771AB91112994@GUARDIAN>
	<3FA4E2AD.10201@web.de>
Message-ID: <x2ad7foupe.fsf@biostat.ku.dk>

Christoph Bier <christoph.bier at web.de> writes:

> Dave Cacela schrieb:
> > Christoph,
> > I concur with the other respondents who questioned why someone would
> > wish to
> > calculate the median of a factor. However, with regard to your actual
> > question, I suspect that median() is giving different answers because the
> > two vectors are not both factors, i.e., that one of them is a character. Did
> > you test that?
> 
> Yes, I did and find the same like Tony Plate:
> 
>  > is.factor(fbhint.spss1$V15.SPS) # = column 264
> [1] TRUE
>  > mode(fbhint.spss1$V15.SPS)
> [1] "numeric"
>  > is.factor(fbhint.spss1$V15.SP1) # = column 566
> [1] TRUE
>  > mode(fbhint.spss1$V15.SP1)
> [1] "numeric"
> 
> > Using S, I have seen quirks in this regard that relate to import procedure
> > and the value of the first element in the vector. In your case, the first
> > elements differ in that one is NA while the other is "teils/teils".
> 
> It also occurs if the first element is the same. For example "wichtig"
> in columns 263 and 565.

I suspect the solution to the riddle was given earlier (I forget by
whom): If there's an odd number of non-NA observations, the median is
the middle obs.; sort(x)[(N+1)/2], if there is an even number, you
take the average of the two middle obs.; sum(sort(x)[c(N/2,N/2+1])/2.
Only the latter involves arithmetic on factors, which is Verboten.
(Arguably, sorting an unordered factor ought to Verboten as well,
though!)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sun Nov  2 14:44:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Nov 2003 13:44:12 +0000 (GMT)
Subject: [R] png() and/or jpeg(): line missing by using box(which="outer")
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB9004730675@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <Pine.LNX.4.44.0311021337030.7617-100000@gannet.stats>

I have an answer for the first of these.  box("outer") tries to draw a
polyline at (0,0), (0,1), (1,1), (1,0), (1,0) in device coordinates. Due
to rounding error, 1 was being plotted at pixel 480, and there are
only pixels 0...479.

This *was* also happening on screen, but for the default screen size on my 
machine it was being rounded down and so shown correctly.

I have added a `fuzz' to ensure 1 gets mapped to pixel 479.

On Tue, 21 Oct 2003, Pfaff, Bernhard wrote:

> Dear R list,
> 
> I do encounter the following problem by generating either a png-file
> (example below) or a jpeg-file: 
> By employing 'box(which="outer")' a box is drawn, except for the right line.
> If I generate the plot without the 'box(which="outer")', a line at the
> bottom in the graphics file still appears. However, both plots are displayed
> correctly in the R Graphics Device Window, i.e  with a box including the
> right side or one without any lines at the outer margins of the plot. Now, I
> want either a file - including the right side of box or one that has none on
> all sides. 
> 
> test <- rnorm(100)
> par(mar=c(6,4,6,4), oma=c(1,1,1,1))
> png("test1.png")
> plot(test)
> grid()
> box(which="outer")
> box(which="plot")
> dev.off()
> 
> png("test2.png")
> plot(test)
> grid()
> box(which="plot")
> dev.off()
> 
> Incidentally, both functions are calling .Internal(devga(....)). I have not
> encountered this problem with version R 1.7.1 (for which I used the binary
> distribution on CRAN). Now, I have source compiled R 1.8.0. Although,
> everything passed 'make check', I am wondering if it could be possible that
> 'devga.c' or any other necessary file for running png() or jpeg() have not
> been compiled 'correctly', or do I have simply to adjust a par()-argument?  
> 
> Any pointers or help is appreciated.
>  
> 
> Bernhard
> 
> 
> platform: "i386-pc-mingw32"
> arch: "i386"
> os: "mingw32"
> system: "i386, mingw32"
> major: "1"
> minor: "8.0"
> Windows NT 5.0
> 
> 
> 
> --------------------------------------------------------------------------------
> The information contained herein is confidential and is intended solely for the
> addressee. Access by any other party is unauthorised without the express
> written permission of the sender. If you are not the intended recipient, please
> contact the sender either via the company switchboard on +44 (0)20 7623 8000, or
> via e-mail return. If you have received this e-mail in error or wish to read our
> e-mail disclaimer statement and monitoring policy, please refer to 
> http://www.drkw.com/disc/email/ or contact the sender.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Sun Nov  2 15:40:14 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 02 Nov 2003 09:40:14 -0500
Subject: [R] Weird problem with median on a factor
In-Reply-To: <x2ad7foupe.fsf@biostat.ku.dk>
References: <883C49C3E47BD6118B3000902771AB91112994@GUARDIAN>
	<3FA4E2AD.10201@web.de> <x2ad7foupe.fsf@biostat.ku.dk>
Message-ID: <5e5aqv829q9tmc0cpai9e8vmcurdkmmrv9@4ax.com>

On 02 Nov 2003 12:50:37 +0100, you wrote:

>(Arguably, sorting an unordered factor ought to Verboten as well,
>though!)

No, arbitrarily assigning an ordering and using that to sort is a
useful thing in many situations, e.g. searching.  

Duncan Murdoch



From friendly at yorku.ca  Sun Nov  2 16:36:18 2003
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 02 Nov 2003 10:36:18 -0500
Subject: [R] Beginner: Homogenity of Variances
In-Reply-To: <200311021106.hA2B6MPW006423@hypatia.math.ethz.ch>
References: <200311021106.hA2B6MPW006423@hypatia.math.ethz.ch>
Message-ID: <3FA52472.1000805@yorku.ca>


"Markus Koesters" <Markus.Koesters at uni-jena.de> wrote:

>for my meta-analysis I try to test if two varainces are equal without 
>using the raw scores. I have is the SD's, N's and the Means.
>I want to test the variances from dependent and independend 
>samples.
>I assume I can use the var.test procedure for the independent 
>samples, but what about the dependent samples ? Has anyone an 
>idea how to realise this with R ?
>Thanks in advance
>
>  
>
For independent samples there is a simple technique described by Larsen, 
Am. Stat, May 1992
for turning summary statistics back into a data set with an equivalent 
ANOVA summary.

This is implemented and described in my STAT2DAT macro,
 http://www.math.yorku.ca/SCS/sasmac/stat2dat.html

It should be easy to translate into R.

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From christoph.bier at web.de  Sun Nov  2 16:53:39 2003
From: christoph.bier at web.de (Christoph Bier)
Date: Sun, 02 Nov 2003 16:53:39 +0100
Subject: [R] Weird problem with median on a factor
In-Reply-To: <x2ad7foupe.fsf@biostat.ku.dk>
References: <883C49C3E47BD6118B3000902771AB91112994@GUARDIAN>	<3FA4E2AD.10201@web.de>
	<x2ad7foupe.fsf@biostat.ku.dk>
Message-ID: <3FA52883.6040709@web.de>

Peter Dalgaard wrote:
> Christoph Bier <christoph.bier at web.de> writes:
> 
> 
>> Dave Cacela schrieb:
>> 
>>> Christoph, I concur with the other respondents who questioned why someone
>>> would wish to calculate the median of a factor. However, with regard to
>>> your actual question, I suspect that median() is giving different answers
>>> because the two vectors are not both factors, i.e., that one of them is a
>>> character. Did you test that?
>> 
>> Yes, I did and find the same like Tony Plate:
>> 
>>> is.factor(fbhint.spss1$V15.SPS) # = column 264
>> [1] TRUE
>>> mode(fbhint.spss1$V15.SPS)
>> [1] "numeric"
>>> is.factor(fbhint.spss1$V15.SP1) # = column 566
>> [1] TRUE
>>> mode(fbhint.spss1$V15.SP1)
>> [1] "numeric"
>> 
>> 
>>> Using S, I have seen quirks in this regard that relate to import
>>> procedure and the value of the first element in the vector. In your case,
>>> the first elements differ in that one is NA while the other is
>>> "teils/teils".
>> 
>> It also occurs if the first element is the same. For example "wichtig" in
>> columns 263 and 565.
> 
> 
> I suspect the solution to the riddle was given earlier (I forget by

Yes, you're right. I just wanted to answer Dave's question.
    Nevertheless I don't understand what I observed above, maybe because of a 
lack of knowledge/understanding of R. But I'm reading your and Brian Ripley's 
book ...

[...]

Best regards,

Christoph



From deepayan at stat.wisc.edu  Sun Nov  2 17:34:10 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 2 Nov 2003 10:34:10 -0600
Subject: [R] barchart in lattice
In-Reply-To: <3FA4E7C4.31088.6EB83C@localhost>
References: <3FA4E7C4.31088.6EB83C@localhost>
Message-ID: <200311021034.10265.deepayan@stat.wisc.edu>


On Sunday 02 November 2003 04:17, Bernd Weiss wrote:
> Dear all,
>
> I have two factors 'country' and 'status' which I would like to plot via
> barchart (lattice). 'status' consist of three different levels and should
> be the grouping variable, 

the correct terminology would be 'conditioning' variable. Grouping variables 
distinguish data within a panel.

> i.e. there should be drawn three different panels
> and within each panel a barchart of 'country'.

I'm not sure what that means. If you mean barchart of the frequency of 
occurrence of each country within each 'status', then you could try 

foo <- read.table("meta.txt")
barchart(daten.COUNTRY ~ Freq| daten.STATUS, 
         data = as.data.frame(table(foo)), 
         origin = 0)

HTH,
Deepayan


> barchart(daten$COUNTRY|daten$STATUS),
> barchart(table(daten$COUNTRY)|table(daten$STATUS)),
> etc. are obviously wrong.
>
> I have absolutely no idea how to do this.
>
> You can download the datafile from
> <http://www.uni-koeln.de/~ahf34/meta.txt>
>
> TIA,
>
> Bernd



From mihastaut at hotmail.com  Sun Nov  2 17:43:08 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Sun, 02 Nov 2003 16:43:08 +0000
Subject: [R] Re: Therotical basis of Kriging
Message-ID: <BAY2-F31XWtjik38dWM00010cdd@hotmail.com>

>hello
>
>I want to know about therotical basis of Kriging in elemantary level.
>I will appreciate if anyone sends me address,link,e-documents, etc..
>
>kind regards
>--
>
>Ahmet Temiz

Practical geostatistics is a comprehensive introductory book to the 
geostatistics. There is a free downloadable copy of the book at:
http://uk.geocities.com/drisobelclark/practica.htm

Miha Staut



From savano at superig.com.br  Sun Nov  2 18:52:08 2003
From: savano at superig.com.br (Savano)
Date: Sun, 02 Nov 2003 14:52:08 -0300
Subject: [R] teste
Message-ID: <6.0.0.20.0.20031102145127.01b2e480@pegasusnet.com.br>

estou testando
I'm testing.



From savano at pegasusnet.com.br  Sun Nov  2 18:55:49 2003
From: savano at pegasusnet.com.br (Savano)
Date: Sun, 02 Nov 2003 14:55:49 -0300
Subject: [R] optim
Message-ID: <6.0.0.20.0.20031102145533.01b3d550@pegasusnet.com.br>

Friends,

I wrote a log-likelihood fuction and optimized but the optim function 
return a error.  The program and the error are below.

Can you help me?



  rm(list=ls(all=TRUE))
 >
 > duration<-read.table("C:/Documents and Settings/Savano/Meus 
documentos/Savano/PUC/estudo/NYSE/durationadj.txt",header=T,sep="");
 >
 > x <- duration$ibm;
 > psi <- array(NaN,c(length(x),1));
 >
 >     logexp <- function(omega,alpha,bbeta){
+
+                 (-sum(log(psi))+sum(x/psi)) #verossimilhan?a
+
+                 psi[1] <- omega/(1-bbeta)   #valor inicial de psi[1]
+
+                  for(i in 2:length(x)) {
+                     psi[i] <- omega+alpha*x+bbeta*psi[i-1] #calculo de psi
+                  }
+                  return(logexp)
+               }
 >
 >
 >
 > optim(c(0.1,0.2,0.3),logexp,method="BFGS")
Error in fn(par, ...) : Argument "bbeta" is missing, with no default
 >



From savano at pegasusnet.com.br  Sun Nov  2 18:55:05 2003
From: savano at pegasusnet.com.br (Savano)
Date: Sun, 02 Nov 2003 14:55:05 -0300
Subject: [R] optim
Message-ID: <6.0.0.20.0.20031102145445.01b3cf78@pegasusnet.com.br>

Friends,

I wrote a log-likelihood fuction and optimized but the optim function 
return a error.  The program and the error are below.

Can you help me?



  rm(list=ls(all=TRUE))
 >
 > duration<-read.table("C:/Documents and Settings/Savano/Meus 
documentos/Savano/PUC/estudo/NYSE/durationadj.txt",header=T,sep="");
 >
 > x <- duration$ibm;
 > psi <- array(NaN,c(length(x),1));
 >
 >     logexp <- function(omega,alpha,bbeta){
+
+                 (-sum(log(psi))+sum(x/psi)) #verossimilhan?a
+
+                 psi[1] <- omega/(1-bbeta)   #valor inicial de psi[1]
+
+                  for(i in 2:length(x)) {
+                     psi[i] <- omega+alpha*x+bbeta*psi[i-1] #calculo de psi
+                  }
+                  return(logexp)
+               }
 >
 >
 >
 > optim(c(0.1,0.2,0.3),logexp,method="BFGS")
Error in fn(par, ...) : Argument "bbeta" is missing, with no default
 >



From bernd.weiss at uni-koeln.de  Sun Nov  2 18:00:55 2003
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Sun, 02 Nov 2003 18:00:55 +0100
Subject: [R] barchart in lattice
In-Reply-To: <200311021034.10265.deepayan@stat.wisc.edu>
References: <3FA4E7C4.31088.6EB83C@localhost>
Message-ID: <3FA54657.30711.315FF8@localhost>

Am 2 Nov 2003 um 10:34 hat Deepayan Sarkar geschrieben:

> 
> On Sunday 02 November 2003 04:17, Bernd Weiss wrote:
> > Dear all,
> >
> > I have two factors 'country' and 'status' which I would like to plot via
> > barchart (lattice). 'status' consist of three different levels and should
> > be the grouping variable, 
> 
> the correct terminology would be 'conditioning' variable. Grouping variables 
> distinguish data within a panel.
> 
> > i.e. there should be drawn three different panels
> > and within each panel a barchart of 'country'.
> 
> I'm not sure what that means. If you mean barchart of the frequency of 
> occurrence of each country within each 'status', then you could try 
> 
> foo <- read.table("meta.txt")
> barchart(daten.COUNTRY ~ Freq| daten.STATUS, 
>          data = as.data.frame(table(foo)), 
>          origin = 0)
> 

That's it! Thank you very much for your help!

Bernd



From ligges at statistik.uni-dortmund.de  Sun Nov  2 18:20:18 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 02 Nov 2003 18:20:18 +0100
Subject: [R] optim
In-Reply-To: <6.0.0.20.0.20031102145533.01b3d550@pegasusnet.com.br>
References: <6.0.0.20.0.20031102145533.01b3d550@pegasusnet.com.br>
Message-ID: <3FA53CD2.9070300@statistik.uni-dortmund.de>

Savano wrote:
> Friends,
> 
> I wrote a log-likelihood fuction and optimized but the optim function 
> return a error.  The program and the error are below.
> 
> Can you help me?
> 
> 
> 
>  rm(list=ls(all=TRUE))
>  >
>  > duration<-read.table("C:/Documents and Settings/Savano/Meus 
> documentos/Savano/PUC/estudo/NYSE/durationadj.txt",header=T,sep="");
>  >
>  > x <- duration$ibm;
>  > psi <- array(NaN,c(length(x),1));
>  >
>  >     logexp <- function(omega,alpha,bbeta){
> +
> +                 (-sum(log(psi))+sum(x/psi)) #verossimilhan?a
> +
> +                 psi[1] <- omega/(1-bbeta)   #valor inicial de psi[1]
> +
> +                  for(i in 2:length(x)) {
> +                     psi[i] <- omega+alpha*x+bbeta*psi[i-1] #calculo de 
> psi
> +                  }
> +                  return(logexp)
> +               }
>  >
>  >
>  >
>  > optim(c(0.1,0.2,0.3),logexp,method="BFGS")
> Error in fn(par, ...) : Argument "bbeta" is missing, with no default


The Error message tells you: you forgot to specify a value for (alpha 
and) bbeta. I guess you want to optimize over all three arguments of 
logexp()? In that case you have to vectorize them into one argument.

But there are SEVERAL other errors in your function!!!

The line
  psi[i] <- omega+alpha*x+bbeta*psi[i-1]
is not sensible given that length(x)>1 ...

The initialization of psi should take place within logexp() using, e.g., 
psi <- numeric(length(x))

I think you don't want to return "logexp", but a single value (that one 
you are goiung to minimize here.

Please read "An Introduction to R" and look into an appropriate book 
(like "Modern Applied Statistics with S" or "S Programming", both by 
W.N. Venables and B.D. Ripley) in order to see how to solve your problem!


BTW: Messages re "teste" are extremely annoying!

Uwe Ligges



From d_pleydell at yahoo.com  Sun Nov  2 18:27:40 2003
From: d_pleydell at yahoo.com (=?iso-8859-1?q?David=20Pleydell?=)
Date: Sun, 2 Nov 2003 17:27:40 +0000 (GMT)
Subject: [R] SWinRegistry & R 1.8.0
Message-ID: <20031102172740.11269.qmail@web41501.mail.yahoo.com>

Hi 
I have R 1.6.2 and use WinEdt as a text editor.  I
have just upgraded to R 1.8.0 but can't set up the
SWinRegistry program.  Using the recommended "Install
packages from local zip files" menu option I get

>
install.packages("C:/R/SWinRegistry_0.3-2_binary.zip",
.libPaths()[1], CRAN = NULL)
Error in file(file, "r") : unable to open connection
In addition: Warning message: 
cannot open file
`SWinRegistry_0.3-2_binary/DESCRIPTION' 

However the same zip file works fine with the old R
1.6.2...

>
install.packages("C:/R/SWinRegistry_0.3-2_binary.zip",
.libPaths()[1], CRAN = NULL)
updating HTML package descriptions

Is this a bug? 

Thanks in advance
Dave



From ripley at stats.ox.ac.uk  Sun Nov  2 18:29:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Nov 2003 17:29:32 +0000 (GMT)
Subject: [R] optim
In-Reply-To: <6.0.0.20.0.20031102145533.01b3d550@pegasusnet.com.br>
Message-ID: <Pine.LNX.4.44.0311021725080.11581-100000@gannet.stats>

On Sun, 2 Nov 2003, Savano wrote:

> Friends,
> 
> I wrote a log-likelihood fuction and optimized but the optim function 
> return a error.  The program and the error are below.
> 
> Can you help me?

The message is not from optim, but from your own function: use traceback() 
to find where errors come from.

Your error is not reading the help page which says

      fn: A function to be minimized (or maximized), with first
          argument the vector of parameters over which minimization is
          to take place. It should return a scalar result.

Since you treat psi as a vector, why define it as an array?

Please don't send the same message repeatedly, and don't send tests.


>   rm(list=ls(all=TRUE))
>  >
>  > duration<-read.table("C:/Documents and Settings/Savano/Meus 
> documentos/Savano/PUC/estudo/NYSE/durationadj.txt",header=T,sep="");
>  >
>  > x <- duration$ibm;
>  > psi <- array(NaN,c(length(x),1));
>  >
>  >     logexp <- function(omega,alpha,bbeta){
> +
> +                 (-sum(log(psi))+sum(x/psi)) #verossimilhan?a
> +
> +                 psi[1] <- omega/(1-bbeta)   #valor inicial de psi[1]
> +
> +                  for(i in 2:length(x)) {
> +                     psi[i] <- omega+alpha*x+bbeta*psi[i-1] #calculo de psi
> +                  }
> +                  return(logexp)
> +               }
>  >
>  >
>  >
>  > optim(c(0.1,0.2,0.3),logexp,method="BFGS")
> Error in fn(par, ...) : Argument "bbeta" is missing, with no default


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ccleland at optonline.net  Sun Nov  2 18:42:31 2003
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 02 Nov 2003 12:42:31 -0500
Subject: [R] SWinRegistry & R 1.8.0
In-Reply-To: <20031102172740.11269.qmail@web41501.mail.yahoo.com>
References: <20031102172740.11269.qmail@web41501.mail.yahoo.com>
Message-ID: <3FA54207.7030706@optonline.net>

David Pleydell wrote:
> I have R 1.6.2 and use WinEdt as a text editor.  I
> have just upgraded to R 1.8.0 but can't set up the
> SWinRegistry program.  Using the recommended "Install
> packages from local zip files" menu option I get
> 
> install.packages("C:/R/SWinRegistry_0.3-2_binary.zip",
> .libPaths()[1], CRAN = NULL)
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file
> `SWinRegistry_0.3-2_binary/DESCRIPTION' 

You need to rename the *.zip file, removing the second 
underscore, as indicated in the instructions.

http://cran.r-project.org/contrib/extra/winedt/ReadMe.txt

hope this helps,

Chuck Cleland

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ligges at statistik.uni-dortmund.de  Sun Nov  2 18:47:49 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 02 Nov 2003 18:47:49 +0100
Subject: [R] SWinRegistry & R 1.8.0
In-Reply-To: <20031102172740.11269.qmail@web41501.mail.yahoo.com>
References: <20031102172740.11269.qmail@web41501.mail.yahoo.com>
Message-ID: <3FA54345.1020005@statistik.uni-dortmund.de>

David Pleydell wrote:

> Hi 
> I have R 1.6.2 and use WinEdt as a text editor.  I
> have just upgraded to R 1.8.0 but can't set up the
> SWinRegistry program.  Using the recommended "Install
> packages from local zip files" menu option I get
> 
> 
> install.packages("C:/R/SWinRegistry_0.3-2_binary.zip",
> .libPaths()[1], CRAN = NULL)
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file
> `SWinRegistry_0.3-2_binary/DESCRIPTION' 
> 
> However the same zip file works fine with the old R
> 1.6.2...
> 
> 
> install.packages("C:/R/SWinRegistry_0.3-2_binary.zip",
> .libPaths()[1], CRAN = NULL)
> updating HTML package descriptions
> 
> Is this a bug? 
> 
> Thanks in advance
> Dave

There is a convention for names of binary packages, and currently 
SWinRegistry does not fullfill this convention (the maintainer of 
SWinRegistry promised to fix that for all Omegahat binaries). Therefore 
the ReadMe.txt for the package RWinEdt, which you are obviously using, 
tells you:

   At the time of writing "SWinRegistry_0.3-2_binary.zip" is the
   current binary version, which has to be renamed to, e.g.,
   "SWinRegistry_0.3-2.zip", because the second underscore is
   not allowed for package installation.

Please read the ReadMe completely.

Uwe Ligges



From ripley at stats.ox.ac.uk  Sun Nov  2 18:56:24 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Nov 2003 17:56:24 +0000 (GMT)
Subject: [R] SWinRegistry & R 1.8.0
In-Reply-To: <20031102172740.11269.qmail@web41501.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311021746110.11638-100000@gannet.stats>

On Sun, 2 Nov 2003, David Pleydell wrote:

> Hi 
> I have R 1.6.2 and use WinEdt as a text editor.  I
> have just upgraded to R 1.8.0 but can't set up the
> SWinRegistry program.  Using the recommended "Install
> packages from local zip files" menu option I get
> 
> >
> install.packages("C:/R/SWinRegistry_0.3-2_binary.zip",
> .libPaths()[1], CRAN = NULL)
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file
> `SWinRegistry_0.3-2_binary/DESCRIPTION' 
> 
> However the same zip file works fine with the old R
> 1.6.2...

Well, binary versions of R are not compatible across one let alone *two*
1.x.0 changes. You really should reinstall from the sources if you find
any problems: did you try that?

> install.packages("C:/R/SWinRegistry_0.3-2_binary.zip",
> .libPaths()[1], CRAN = NULL)
> updating HTML package descriptions
> 
> Is this a bug? 

Yes, in SWinRegistry, or at least the version you have.
Get the latest sources, run Rcmd check on them and if they pass install 
them otherwise correct them.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Sun Nov  2 19:00:35 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 02 Nov 2003 12:00:35 -0600
Subject: Even more timings [was Re: [R] Change in 'solve' for r-patched]
In-Reply-To: <6rekwsufk4.fsf@bates4.stat.wisc.edu>
References: <70E1C0DB4F9B5E4F9CEDB8433F4A68B90306056A@PSBMAIL2>
	<Pine.A41.4.58.0310311543440.184628@homer06.u.washington.edu>
	<6rekwsufk4.fsf@bates4.stat.wisc.edu>
Message-ID: <6rr80qsla4.fsf_-_@bates4.stat.wisc.edu>

Earlier I posted some timings on different ways to solve a least
squares problem in R.  To get a comparison of the raw speed of the
Cholesky and the QR methods I wrote a couple of C functions (shown
below) that call Lapack and BLAS routines directly.

The results from these are
> system.time(blsq <- .Call("lsq_dense_Chol", mmd, y))
[1] 0.46 0.00 0.46 0.00 0.00
> system.time(blsq <- .Call("lsq_dense_Chol", mmd, y))
[1] 0.44 0.01 0.45 0.00 0.00
> all.equal(blsq, bsparse)
[1] TRUE
> system.time(blsQR <- .Call("lsq_dense_QR", mmd, y)[1:ncol(mmd),,drop=FALSE])
[1] 0.94 0.01 0.96 0.00 0.00
> all.equal(blsQR, bsparse)
[1] TRUE
> system.time(blsQR <- .Call("lsq_dense_QR", mmd, y)[1:ncol(mmd),,drop=FALSE])
[1] 0.94 0.03 0.97 0.00 0.00

For the dense matrix methods the timings, in increasing order, are

> system.time(blsq <- .Call("lsq_dense_Chol", mmd, y))
[1] 0.44 0.01 0.45 0.00 0.00
> system.time(bc2i <- chol2inv(chol(crossprod(mmd))) %*% crossprod(mmd, y))
[1] 0.60 0.02 0.63 0.00 0.00
> system.time(bLU <- solve(crossprod(mmd), crossprod(mmd, y)))
[1] 0.64 0.06 0.71 0.00 0.00
> system.time(blsQR <- .Call("lsq_dense_QR", mmd, y)[1:ncol(mmd),,drop=FALSE])
[1] 0.94 0.01 0.96 0.00 0.00
> system.time(bLA <- qr.coef(qr(mmd, LAPACK = TRUE), y))
[1] 3.57 0.04 3.61 0.00 0.00
> system.time(bQR <- qr.coef(qr(mmd), y))
[1] 3.70 0.11 3.81 0.00 0.00

Although only the last two can handle a rank deficient model matrix I
think there is a fairly easy way of modifying the code shown below to
detect apparent singularity and accomodate for it.

I think that the reason that the Linpack-based QR method is slow is
because it is based on Linpack, not Lapack, and the reason the qr(mmd,
LAPACK=TRUE) is slow is because it does full column pivoting.

It appears that QR is a little more than twice as slow as the Cholesky
and about 1.5 times as slow as the naive calculation using an LU
decomposition. 

The team working on FLAME (http://www.cs.utexas.edu/users/flame) has
test versions of blocked algorithms for the QR and the Cholesky
decompositions that are faster than the Lapack code.  I expect to be
testing those in the next few weeks.

Here is the C code called above.  

#include "Rdefines.h"
#include "R_ext/Lapack.h"

SEXP lsq_dense_Chol(SEXP X, SEXP y)
{
    SEXP ans;
    int info, n, p, k, *Xdims, *ydims;
    double *xpx, d_one = 1., d_zero = 0.;

    if (!(isReal(X) & isMatrix(X)))
	error("X must be a numeric (double precision) matrix");
    Xdims = INTEGER(coerceVector(getAttrib(X, R_DimSymbol), INTSXP));
    n = Xdims[0];
    p = Xdims[1];
    if (!(isReal(y) & isMatrix(y)))
	error("y must be a numeric (double precision) matrix");
    ydims = INTEGER(coerceVector(getAttrib(y, R_DimSymbol), INTSXP));
    if (ydims[0] != n)
	error(
	    "number of rows in y (%d) does not match number of rows in X (%d)",
	    ydims[0], n);
    k = ydims[1];
    if (k < 1 || p < 1) return allocMatrix(REALSXP, p, k);
    ans = PROTECT(allocMatrix(REALSXP, p, k));
    F77_CALL(dgemm)("T", "N", &p, &k, &n, &d_one, REAL(X), &n, REAL(y), &n,
		    &d_zero, REAL(ans), &p);
    xpx = Calloc(p * p, double);
    F77_CALL(dsyrk)("U", "T", &p, &n, &d_one, REAL(X), &n, &d_zero,
		    xpx, &p);
    F77_CALL(dposv)("U", &p, &k, xpx, &p, REAL(ans), &p, &info);
    if (info) error("Lapack routine dposv returned error code %d", info);
    Free(xpx); 
    UNPROTECT(1);
    return ans;
}
 
    
SEXP lsq_dense_QR(SEXP X, SEXP y)
{
    SEXP ans;
    int info, n, p, k, *Xdims, *ydims, lwork;
    double *work, d_one = 1., d_zero = 0., tmp, *xvals;

    if (!(isReal(X) & isMatrix(X)))
	error("X must be a numeric (double precision) matrix");
    Xdims = INTEGER(coerceVector(getAttrib(X, R_DimSymbol), INTSXP));
    n = Xdims[0];
    p = Xdims[1];
    if (!(isReal(y) & isMatrix(y)))
	error("y must be a numeric (double precision) matrix");
    ydims = INTEGER(coerceVector(getAttrib(y, R_DimSymbol), INTSXP));
    if (ydims[0] != n)
	error(
	    "number of rows in y (%d) does not match number of rows in X (%d)",
	    ydims[0], n);
    k = ydims[1];
    if (k < 1 || p < 1) return allocMatrix(REALSXP, p, k);
    xvals = Calloc(n * p, double);
    Memcpy(xvals, REAL(X), n * p);
    ans = PROTECT(duplicate(y));
    lwork = -1;
    F77_CALL(dgels)("N", &n, &p, &k, xvals, &n, REAL(ans), &n,
		    &tmp, &lwork, &info);
    if (info)
	error("First call to Lapack routine dgels returned error code %d",
	      info);
    lwork = (int) tmp;
    work = Calloc(lwork, double);
    F77_CALL(dgels)("N", &n, &p, &k, xvals, &n, REAL(ans), &n,
		    work, &lwork, &info);
    if (info)
	error("Second call to Lapack routine dgels returned error code %d",
	      info);
    Free(work); Free(xvals);
    UNPROTECT(1);
    return ans;
}



From ray at mcs.vuw.ac.nz  Sat Nov  1 10:47:10 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Sat, 1 Nov 2003 22:47:10 +1300 (NZDT)
Subject: [R] [R-pkgs] R maps, mapdata and mapproj for Windows
Message-ID: <200311010947.hA19lAjt016231@tahi.mcs.vuw.ac.nz>

Nearly a month ago I announced the availability of a Windows port of
the maps for S package but for various reasons the Windows binaries
did not appear on CRAN until yesterday.  Now I am pleased to announce
that the three packages maps_2.0-8 (the base maps package with
low-resolution databases), mapdata_2.0-6 (high-resolution and other
databases) and mapproj_1.1 (projection add-on for maps, maintained by
Tom Minka) are all now available on CRAN both in source and Windows
binary forms.

I apologise for the delays.
Ray Brownrigg

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From dieter.menne at menne-biomed.de  Sun Nov  2 19:56:56 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sun, 2 Nov 2003 19:56:56 +0100
Subject: [R] Problems with help.start()
Message-ID: <JLEPLGAANFCEAEDCAGJNKEKBCGAA.dieter.menne@menne-biomed.de>

Henrique,

I often have the same problem in r-Help after doing Java development; it
looks like a versioning conflict.
Workaround:

-- Use Netscape (never happened there)
-- Totally uninstall Java runtime (make sure you got all versions), and
reinstall it.

There may be an easier way, but reinstallation is fast and efficient.

Dieter



From dieter.menne at menne-biomed.de  Sun Nov  2 20:13:48 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sun, 2 Nov 2003 20:13:48 +0100
Subject: [R] barchart in lattice
Message-ID: <JLEPLGAANFCEAEDCAGJNEEKCCGAA.dieter.menne@menne-biomed.de>

Bernd,

for counts use histogram instead of barchart, and leave the left side of the
formula empty.

library(lattice)
meta<-read.table("meta.txt",header=T)
histogram(~daten.COUNTRY|daten.STATUS,data=meta)

Check "scales" in xyplot (it's also valid for histogram) so you get the
names of the
countries as vertical x-labels instead of the numbers.

--------- You wrote ----
I have two factors 'country' and 'status' which I would like to plot via
barchart (lattice). 'status' consist of three different levels and should be
the grouping variable, i.e. there should be drawn three different panels and
within each panel a barchart of 'country'.

barchart(daten$COUNTRY|daten$STATUS),
barchart(table(daten$COUNTRY)|table(daten$STATUS)),



From tblackw at umich.edu  Sun Nov  2 21:28:10 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sun, 2 Nov 2003 15:28:10 -0500 (EST)
Subject: [R] cannot have a function argument named 'break'
Message-ID: <Pine.SOL.4.58.0311021522050.1888@zektor.gpcc.itd.umich.edu>

Dear list  -

I just discovered to my surprise that I cannot define
a function with an argument named 'break' or 'while'!
'breaks' is okay.  Maybe this is no surprise to the R
developers.

R-1.7.1,  2003-06-16,  i686-pc-linux-gnu.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From kjetil at entelnet.bo  Sun Nov  2 21:37:32 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sun, 02 Nov 2003 16:37:32 -0400
Subject: [R] lattice function splom
Message-ID: <3FA532CC.20605.1642910@localhost>

Hola!

In the lattice function splom, is it possible to get 
the tickmarks/value labels _outside_ the scatterplot matrix, 
and not inside each of the panels in the antidiagonal of panels 
with variable labels?

Kjetil Halvorsen



From malik25 at sympatico.ca  Sun Nov  2 21:59:49 2003
From: malik25 at sympatico.ca (malick mbaye)
Date: Sun, 2 Nov 2003 15:59:49 -0500
Subject: [R] hello
Message-ID: <000801c3a184$cc482120$b5e9e440@nomw6qa7o7bz4v>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031102/18884372/attachment.pl

From spencer.graves at pdf.com  Sun Nov  2 22:07:00 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 02 Nov 2003 13:07:00 -0800
Subject: [R] cannot have a function argument named 'break'
In-Reply-To: <Pine.SOL.4.58.0311021522050.1888@zektor.gpcc.itd.umich.edu>
References: <Pine.SOL.4.58.0311021522050.1888@zektor.gpcc.itd.umich.edu>
Message-ID: <3FA571F4.9060401@pdf.com>

Yup.  R 1.8.0 gives me a syntax error from "if", also: 

 > iff <- function(if)if
Error: syntax error

spencer graves

Thomas W Blackwell wrote:

>Dear list  -
>
>I just discovered to my surprise that I cannot define
>a function with an argument named 'break' or 'while'!
>'breaks' is okay.  Maybe this is no surprise to the R
>developers.
>
>R-1.7.1,  2003-06-16,  i686-pc-linux-gnu.
>
>-  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From kjetil at entelnet.bo  Sun Nov  2 23:19:02 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sun, 02 Nov 2003 18:19:02 -0400
Subject: [R] hello
In-Reply-To: <000801c3a184$cc482120$b5e9e440@nomw6qa7o7bz4v>
Message-ID: <3FA54A96.16935.1C115A3@localhost>

On 2 Nov 2003 at 15:59, malick mbaye wrote:

I'm afraid you will not get much usefull help without being 
more specific!

Kjetil Halvorsen



i am a student and i need some help to do mod?ling  like to use some methods to select the best model(variables)
thank,s
mail:malik.mbaye at hec.ca
tel:514-975-2601
	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Mon Nov  3 01:48:05 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 2 Nov 2003 16:48:05 -0800 (PST)
Subject: [R] cannot have a function argument named 'break'
In-Reply-To: <Pine.SOL.4.58.0311021522050.1888@zektor.gpcc.itd.umich.edu>
References: <Pine.SOL.4.58.0311021522050.1888@zektor.gpcc.itd.umich.edu>
Message-ID: <Pine.A41.4.58.0311021642300.195064@homer03.u.washington.edu>

On Sun, 2 Nov 2003, Thomas W Blackwell wrote:

> Dear list  -
>
> I just discovered to my surprise that I cannot define
> a function with an argument named 'break' or 'while'!
> 'breaks' is okay.  Maybe this is no surprise to the R
> developers.

You can't use any of the words that are part of the R language (as opposed
to functions).  The ones I can think of are
   for while repeat
   next break
   if else
   function

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From jbsambatti at ucdavis.edu  Mon Nov  3 02:18:51 2003
From: jbsambatti at ucdavis.edu (Julianno Sambatti)
Date: Sun, 2 Nov 2003 17:18:51 -0800
Subject: [R] poisson GLM
Message-ID: <AF09F792-0D9B-11D8-B453-0003939BFCD0@ucdavis.edu>

Does anyone know how to use poison models in general linear models with 
R ?


Julianno



From jasont at indigoindustrial.co.nz  Mon Nov  3 02:29:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 03 Nov 2003 14:29:03 +1300
Subject: [R] poisson GLM
In-Reply-To: <AF09F792-0D9B-11D8-B453-0003939BFCD0@ucdavis.edu>
References: <AF09F792-0D9B-11D8-B453-0003939BFCD0@ucdavis.edu>
Message-ID: <3FA5AF5F.606@indigoindustrial.co.nz>

Julianno Sambatti wrote:
> Does anyone know how to use poison models in general linear models with R ?
> 

?glm

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From spencer.graves at pdf.com  Mon Nov  3 02:45:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 02 Nov 2003 17:45:12 -0800
Subject: [R] poisson GLM
In-Reply-To: <AF09F792-0D9B-11D8-B453-0003939BFCD0@ucdavis.edu>
References: <AF09F792-0D9B-11D8-B453-0003939BFCD0@ucdavis.edu>
Message-ID: <3FA5B328.9020904@pdf.com>

Have you considered the example provided in the documentation "?glm" in 
R 1.8.0?  If that does not satisfy your needs, please explain why it 
doesn't. 

hope this helps.  spencer graves

Julianno Sambatti wrote:

> Does anyone know how to use poison models in general linear models 
> with R ?
>
>
> Julianno
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Simon.Wotherspoon at utas.edu.au  Mon Nov  3 07:53:25 2003
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Mon, 3 Nov 2003 17:53:25 +1100
Subject: [R] Odd r-squared
Message-ID: <JPEJIEHCLCCMMBFGMPDGGEHBCFAA.Simon.Wotherspoon@utas.edu.au>

Hi,
  I would consider the calculation of r-squared in the following to be a
bug, but then, I've been wrong before.  It seems that R looks to see if the
model contains an intercept term, and if it does not, computes r-squared in
a way I don't understand.  To my mind, the following are two alternative
parametrizations of the same model, and should yield the same r-squared.

Any insight much appreciated

Simon.



> set.seed(10,kind=NULL)
> x <- runif(10)
> g <- gl(2,5)
> y <- runif(10)
>
> summary(lm(y ~ g*x))

Call:
lm(formula = y ~ g * x)

Residuals:
     Min       1Q   Median       3Q      Max
-0.35205 -0.14021  0.02486  0.13958  0.39671

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   0.3138     0.2749   1.141    0.297
g2           -0.1568     0.4339  -0.361    0.730
x             0.3556     0.6082   0.585    0.580
g2:x          0.3018     1.0522   0.287    0.784

Residual standard error: 0.276 on 6 degrees of freedom
Multiple R-Squared: 0.1491,     Adjusted R-squared: -0.2763
F-statistic: 0.3505 on 3 and 6 DF,  p-value: 0.7907

> summary(lm(y ~ g/x-1))

Call:
lm(formula = y ~ g/x - 1)

Residuals:
     Min       1Q   Median       3Q      Max
-0.35205 -0.14021  0.02486  0.13958  0.39671

Coefficients:
     Estimate Std. Error t value Pr(>|t|)
g1     0.3138     0.2749   1.141    0.297
g2     0.1570     0.3357   0.468    0.657
g1:x   0.3556     0.6082   0.585    0.580
g2:x   0.6574     0.8586   0.766    0.473

Residual standard error: 0.276 on 6 degrees of freedom
Multiple R-Squared: 0.8061,     Adjusted R-squared: 0.6769
F-statistic: 6.237 on 4 and 6 DF,  p-value: 0.02491



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 1
 minor = 8.0
 year = 2003
 month = 10
 day = 08
 language = R

Windows ME 4.90 (build 3000)

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
package:nls, package:ts, Autoloads, package:base
---



From ripley at stats.ox.ac.uk  Mon Nov  3 08:47:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Nov 2003 07:47:51 +0000 (GMT)
Subject: [R] cannot have a function argument named 'break'
In-Reply-To: <3FA571F4.9060401@pdf.com>
Message-ID: <Pine.LNX.4.44.0311030744170.16466-100000@gannet.stats>

No, they are reserved names.  That is explained in MASS4 and R-lang, for 
example.  The full list (of syntactically valid names) is

FALSE Inf NA NaN NULL TRUE
break else for function if in next repeat while

(S also has return, T and F)

Most progamming languages have reserved words, so I am surprised you are 
surprised.

On Sun, 2 Nov 2003, Spencer Graves wrote:

> Yup.  R 1.8.0 gives me a syntax error from "if", also: 
> 
>  > iff <- function(if)if
> Error: syntax error
> 
> spencer graves
> 
> Thomas W Blackwell wrote:
> 
> >Dear list  -
> >
> >I just discovered to my surprise that I cannot define
> >a function with an argument named 'break' or 'while'!
> >'breaks' is okay.  Maybe this is no surprise to the R
> >developers.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Nov  3 09:02:25 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Nov 2003 08:02:25 +0000 (GMT)
Subject: [R] Odd r-squared
In-Reply-To: <JPEJIEHCLCCMMBFGMPDGGEHBCFAA.Simon.Wotherspoon@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0311030755090.16466-100000@gannet.stats>

On Mon, 3 Nov 2003, Simon Wotherspoon wrote:

>   I would consider the calculation of r-squared in the following to be a
> bug, but then, I've been wrong before.  It seems that R looks to see if the
> model contains an intercept term, and if it does not, computes r-squared in
> a way I don't understand.  To my mind, the following are two alternative
> parametrizations of the same model, and should yield the same r-squared.

But the minimal model contains a overall mean in the first case and not in
the second.  Your models are 1+g+x+g:x and 0+g+g:x.  So whereas they are 
alternative parametrizations of the same full model, R^2 compares two 
models, not just one.

You will find this explained on ?summary.lm (RTFM!) and several times in
the archives.  One solution is to ignore the R^2 lines (as I do and tell
my students to do).  But we might consider labelling the printed output as 
say 

Multiple R-Squared (no int): 0.8061,     Adjusted R-squared: 0.6769

to remind people.

> 
> Any insight much appreciated
> 
> Simon.
> 
> 
> 
> > set.seed(10,kind=NULL)
> > x <- runif(10)
> > g <- gl(2,5)
> > y <- runif(10)
> >
> > summary(lm(y ~ g*x))
> 
> Call:
> lm(formula = y ~ g * x)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max
> -0.35205 -0.14021  0.02486  0.13958  0.39671
> 
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.3138     0.2749   1.141    0.297
> g2           -0.1568     0.4339  -0.361    0.730
> x             0.3556     0.6082   0.585    0.580
> g2:x          0.3018     1.0522   0.287    0.784
> 
> Residual standard error: 0.276 on 6 degrees of freedom
> Multiple R-Squared: 0.1491,     Adjusted R-squared: -0.2763
> F-statistic: 0.3505 on 3 and 6 DF,  p-value: 0.7907
> 
> > summary(lm(y ~ g/x-1))
> 
> Call:
> lm(formula = y ~ g/x - 1)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max
> -0.35205 -0.14021  0.02486  0.13958  0.39671
> 
> Coefficients:
>      Estimate Std. Error t value Pr(>|t|)
> g1     0.3138     0.2749   1.141    0.297
> g2     0.1570     0.3357   0.468    0.657
> g1:x   0.3556     0.6082   0.585    0.580
> g2:x   0.6574     0.8586   0.766    0.473
> 
> Residual standard error: 0.276 on 6 degrees of freedom
> Multiple R-Squared: 0.8061,     Adjusted R-squared: 0.6769
> F-statistic: 6.237 on 4 and 6 DF,  p-value: 0.02491
> 
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 1
>  minor = 8.0
>  year = 2003
>  month = 10
>  day = 08
>  language = R
> 
> Windows ME 4.90 (build 3000)
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
> package:nls, package:ts, Autoloads, package:base
> ---
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From moracsa1 at zhwin.ch  Mon Nov  3 10:35:57 2003
From: moracsa1 at zhwin.ch (Morach Sascha, moracsa1)
Date: Mon, 3 Nov 2003 10:35:57 +0100
Subject: [R] Problem with batch-file
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B90294566D@lobster.zhwin.ch>

Hi
 
I have written a graphical user interface using tcltk. Now I would like to run it under rterm.exe with a batch file. I tried the following code written in a .bat file:
 
 d:\R\rw1071\bin\Rterm.exe --no-restore --no-save <d:\RGui.r> d:\RGui.out
 
The problem is that rterm does open but the gui isn't running properly. After a few seconds rterm is closeing without doing anything more than print the first gui window. If I run the same r-code in the normal RGui.exe I don't have any problems.
Does anyone know what I'm doing wrong, or is there a help file which explains  the needed code?
 
 
thanks
Sascha Morach, a student from ZHW  switzerland



From martin at ist.org  Mon Nov  3 11:37:39 2003
From: martin at ist.org (martin@ist.org)
Date: Mon, 3 Nov 2003 10:37:39 -0000
Subject: [R] calling R from Perl
Message-ID: <twig.1067855858.27681@ist.org>

Hi,

I want to call R from Perl to generate plots to be displayed on a 
webpage. What I found out so far is that there is a package called 
RSPerl on www.omegahat.org which should do what I need. However in 
the description it says it has been tested with R 1.3.* the latest.
I'm using R 1.8.0 right now so the package seems rather unmaintained. 
It is not easy for me to just install it and see if it works because 
I have to contact the sysadmin everytime and he is kind of reluctant 
on 'just trying things out'.

Does anybody have experience with RSPerl or any other solution on how 
to do this? Any help is appreciated,

Martin Keller-Ressel



From ripley at stats.ox.ac.uk  Mon Nov  3 11:51:52 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Nov 2003 10:51:52 +0000 (GMT)
Subject: [R] Problem with batch-file
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B90294566D@lobster.zhwin.ch>
Message-ID: <Pine.LNX.4.44.0311031050520.16893-100000@gannet.stats>

That's exactly what a batch file should do.  There is no GUI to run.

Please tell us what you actually want to do!

On Mon, 3 Nov 2003, Morach Sascha, moracsa1 wrote:

> Hi
>  
> I have written a graphical user interface using tcltk. Now I would like to run it under rterm.exe with a batch file. I tried the following code written in a .bat file:
>  
>  d:\R\rw1071\bin\Rterm.exe --no-restore --no-save <d:\RGui.r> d:\RGui.out
>  
> The problem is that rterm does open but the gui isn't running properly. After a few seconds rterm is closeing without doing anything more than print the first gui window. If I run the same r-code in the normal RGui.exe I don't have any problems.
> Does anyone know what I'm doing wrong, or is there a help file which explains  the needed code?
>  
>  
> thanks
> Sascha Morach, a student from ZHW  switzerland

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From baron at psych.upenn.edu  Mon Nov  3 12:04:12 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 3 Nov 2003 06:04:12 -0500
Subject: [R] calling R from Perl
In-Reply-To: <twig.1067855858.27681@ist.org>
References: <twig.1067855858.27681@ist.org>
Message-ID: <20031103110412.GA26492@mail1.sas.upenn.edu>

On 11/03/03 10:37, martin at ist.org wrote:
>Hi,
>
>I want to call R from Perl to generate plots to be displayed on a 
>webpage. What I found out so far is that there is a package called 
>RSPerl on www.omegahat.org which should do what I need. However in 
>the description it says it has been tested with R 1.3.* the latest.
>I'm using R 1.8.0 right now so the package seems rather unmaintained. 
>It is not easy for me to just install it and see if it works because 
>I have to contact the sysadmin everytime and he is kind of reluctant 
>on 'just trying things out'.
>
>Does anybody have experience with RSPerl or any other solution on how 
>to do this? Any help is appreciated,

RWeb, at http://www.math.montana.edu/Rweb/

actually works, and it does what you are trying to do, although
not necessarily exactly what you are trying to do.  It isn't
being maintained either, it seems.  I wrote Jeff Banfield, the
author, and received no reply.  It is a very nice package, and I
think it could serve as the foundation for a GUI that would be
useful for students.  (That was its intention.)

You might also look at the CRAN package CGIwithR, which I have
not tried.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page: http://finzi.psych.upenn.edu



From vasileios_p at yahoo.gr  Mon Nov  3 12:40:41 2003
From: vasileios_p at yahoo.gr (=?iso-8859-7?q?vasilis=20pappas?=)
Date: Mon, 3 Nov 2003 11:40:41 +0000 (GMT)
Subject: [R] Questions in R
Message-ID: <20031103114041.3596.qmail@web12907.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031103/03758eca/attachment.pl

From jfox at mcmaster.ca  Mon Nov  3 13:42:38 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 03 Nov 2003 07:42:38 -0500
Subject: [R] Questions in R
In-Reply-To: <20031103114041.3596.qmail@web12907.mail.yahoo.com>
Message-ID: <5.1.0.14.2.20031103073642.01fc13f0@127.0.0.1>

At 11:40 AM 11/3/2003 +0000, =?iso-8859-7?q?vasilis=20pappas?= wrote:
>Hello,
>I have 4 questions in R and I am looking for 4 answers!
>the questions are the below:
>1) is there a function in R for the Least Significant Difference method 
>for multiple comparisons?

There is a multcomp package that implements many methods for multiple 
comparisons, but I'm not sure whether it does LSD.

>2) Is there a function in R that gives me the studentized deleted 
>residuals and the leverage points?

rstudent() and hatvalues().

>3) is there a way that I could create a link in a program of mine, so as 
>to select an option when my program is running?

It's not altogether clear to me what you want to do, but see ?menu.

>4) Whis function gives me the opprotunity to give data to my program while 
>it's running?That is, how can i give information, like cin in C++, to my 
>program will it is running in R.
>

See ?readline.

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From ripley at stats.ox.ac.uk  Mon Nov  3 14:37:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Nov 2003 13:37:31 +0000 (GMT)
Subject: [R] Questions in R
In-Reply-To: <5.1.0.14.2.20031103073642.01fc13f0@127.0.0.1>
Message-ID: <Pine.LNX.4.44.0311031330020.17441-100000@gannet.stats>

On Mon, 3 Nov 2003, John Fox wrote:

> At 11:40 AM 11/3/2003 +0000, =?iso-8859-7?q?vasilis=20pappas?= wrote:
> >Hello,
> >I have 4 questions in R and I am looking for 4 answers!
> >the questions are the below:
> >1) is there a function in R for the Least Significant Difference method 
> >for multiple comparisons?
> 
> There is a multcomp package that implements many methods for multiple 
> comparisons, but I'm not sure whether it does LSD.

You don't need a special function.  Fisher's protected LSD first does an
overall F test, then uses the standard formulae as implemented by e.g.
se.contrast.  For balanced layouts the LSD is very simple indeed.

> >4) Whis function gives me the opprotunity to give data to my program while 
> >it's running?That is, how can i give information, like cin in C++, to my 
> >program will it is running in R.
> >
> 
> See ?readline.

scan() would be a closer analog.  You can use source, read.table, the data 
editor, ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Mon Nov  3 14:47:17 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 03 Nov 2003 08:47:17 -0500
Subject: [R] Question about the high dimensional density estimation
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDA0@usrymx25.merck.com>

> From: Jason Turner [mailto:jasont at indigoindustrial.co.nz] 
> 
> hungy at stat.ncu.edu.tw wrote:
> > Hi,
> > I found that the R package "KernSmooth" can deal with
> > only 1D and 2D data. But now I have a collection of
> > 4-dimensional data (x1,x2,x3,x4) and would like to estimate
> > the "mode" of the underlying density. What can I do
> > about it ?
> 
> The gss package might do what you want here.
> 
> Cheers
> 
> Jason
> -- 
> Indigo Industrial Controls Ltd. 
> http://www.indigoindustrial.co.nz 64-21-343-> 545 
> jasont at indigoindustrial.co.nz

 
I believe the `locfit' package will do as well, using local polynomials.

HTH,
Andy



From sagartamrakar at hotmail.com  Mon Nov  3 14:47:48 2003
From: sagartamrakar at hotmail.com (sagar)
Date: Mon, 3 Nov 2003 19:32:48 +0545
Subject: [R] second Y axis
Message-ID: <Law15-DAV45AcJXrMVh00010aca@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031103/86e67238/attachment.pl

From laura at env.leeds.ac.uk  Mon Nov  3 15:15:03 2003
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 3 Nov 2003 14:15:03 +0000 (GMT)
Subject: [R] Visualising Vectors
Message-ID: <Pine.LNX.4.44.0311031407510.16713-100000@env-pc-phd13>

I sent a mail last week asking for some advise in relation to displaying
wind vectors on a contour map of a region. Whilst I have had some useful
feedback relating to the second part of this question (namely how to
animate a time series of still frames), I haven't recieved any advise on
how I might create the still images of the spatially distributed wind
vector data at any given time point.

Firstly, is there a way in which I can input orographical information
(x,y,z co ords) into R to create a map, secondly, is there a way in which
i can superimpose a visual wind vector (i.e. arrow of certain length and
certain orientation) onto such a map?

thanks in advance,
Laura



From wowen at richmond.edu  Mon Nov  3 15:46:57 2003
From: wowen at richmond.edu (Owen, Jason)
Date: Mon, 3 Nov 2003 09:46:57 -0500 
Subject: [R] USA map
Message-ID: <C1F927C74082D311A25B00508B5BFF1704E0C13E@urmail-oz.richmond.edu>

R users,

In S, there was a function called usa() that
would draw the map of the United States, plus
it had other options for graphics.  I have looked
but I can't find the equivalent in R.  Is there one?

Thanks,

Jason



From seanpor at acm.org  Mon Nov  3 15:59:40 2003
From: seanpor at acm.org (Sean O'Riordain)
Date: Mon, 03 Nov 2003 14:59:40 +0000
Subject: [R] Visualising Vectors
In-Reply-To: <Pine.LNX.4.44.0311031407510.16713-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0311031407510.16713-100000@env-pc-phd13>
Message-ID: <3FA66D5C.7010302@acm.org>

Hi Laura,

you should find some useful information in the latest R news Volume 3/2, 
October 2003
http://cran.r-project.org/doc/Rnews/

refer page 8 where Paul's figure 2 shows some novel symbols showing 
"China Sea Wind Speed, Direction and Temperature"... plotted by lat.&long.

s.



Laura Quinn wrote:
> I sent a mail last week asking for some advise in relation to displaying
> wind vectors on a contour map of a region. Whilst I have had some useful
> feedback relating to the second part of this question (namely how to
> animate a time series of still frames), I haven't recieved any advise on
> how I might create the still images of the spatially distributed wind
> vector data at any given time point.
> 
> Firstly, is there a way in which I can input orographical information
> (x,y,z co ords) into R to create a map, secondly, is there a way in which
> i can superimpose a visual wind vector (i.e. arrow of certain length and
> certain orientation) onto such a map?
> 
> thanks in advance,
> Laura



From edd at debian.org  Mon Nov  3 16:06:05 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 3 Nov 2003 09:06:05 -0600
Subject: [R] Problem with batch-file
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B90294566D@lobster.zhwin.ch>
References: <6A4BCEF0FD65344A8F496D7E520DD8B90294566D@lobster.zhwin.ch>
Message-ID: <20031103150605.GA23722@sonny.eddelbuettel.com>

On Mon, Nov 03, 2003 at 10:35:57AM +0100, Morach Sascha, moracsa1 wrote:
> Hi
>  
> I have written a graphical user interface using tcltk. Now I would like to run it under rterm.exe with a batch file. I tried the following code written in a .bat file:
>  
>  d:\R\rw1071\bin\Rterm.exe --no-restore --no-save <d:\RGui.r> d:\RGui.out
>  
> The problem is that rterm does open but the gui isn't running properly. After a few seconds rterm is closeing without doing anything more than print the first gui window. If I run the same r-code in the normal RGui.exe I don't have any problems.
> Does anyone know what I'm doing wrong, or is there a help file which explains  the needed code?

I use a trick which Peter D. once emailed. You need to initialise a
variable, say, wait.gui, to zero. If and when the user wants to quit
(File->Exit or whatever, you also need to fetch the window closing event
from the window manager) you set wait.gui to 1.  Then a call to

	tk.wait(wait.gui)
	
in your main part should be all that is needed.

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From kjetil at entelnet.bo  Mon Nov  3 16:11:09 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 03 Nov 2003 11:11:09 -0400
Subject: [R] Odd r-squared
In-Reply-To: <JPEJIEHCLCCMMBFGMPDGGEHBCFAA.Simon.Wotherspoon@utas.edu.au>
Message-ID: <3FA637CD.2492.9709D5@localhost>

On 3 Nov 2003 at 17:53, Simon Wotherspoon wrote:

If you are really interested, you could write your own function 
to calculate r-squared, deciding from the model matrix if the range
space of the model matrix contains a constant vector.

If model is the model matrix with n rows, one way is to compare the 
$rank components of 
qr(model)  and
qr(cbind(rep(1,n), model))

Kjetil Halvorsen


> Hi,
>   I would consider the calculation of r-squared in the following to be a
> bug, but then, I've been wrong before.  It seems that R looks to see if the
> model contains an intercept term, and if it does not, computes r-squared in
> a way I don't understand.  To my mind, the following are two alternative
> parametrizations of the same model, and should yield the same r-squared.
> 
> Any insight much appreciated
> 
> Simon.
> 
> 
> 
> > set.seed(10,kind=NULL)
> > x <- runif(10)
> > g <- gl(2,5)
> > y <- runif(10)
> >
> > summary(lm(y ~ g*x))
> 
> Call:
> lm(formula = y ~ g * x)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max
> -0.35205 -0.14021  0.02486  0.13958  0.39671
> 
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.3138     0.2749   1.141    0.297
> g2           -0.1568     0.4339  -0.361    0.730
> x             0.3556     0.6082   0.585    0.580
> g2:x          0.3018     1.0522   0.287    0.784
> 
> Residual standard error: 0.276 on 6 degrees of freedom
> Multiple R-Squared: 0.1491,     Adjusted R-squared: -0.2763
> F-statistic: 0.3505 on 3 and 6 DF,  p-value: 0.7907
> 
> > summary(lm(y ~ g/x-1))
> 
> Call:
> lm(formula = y ~ g/x - 1)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max
> -0.35205 -0.14021  0.02486  0.13958  0.39671
> 
> Coefficients:
>      Estimate Std. Error t value Pr(>|t|)
> g1     0.3138     0.2749   1.141    0.297
> g2     0.1570     0.3357   0.468    0.657
> g1:x   0.3556     0.6082   0.585    0.580
> g2:x   0.6574     0.8586   0.766    0.473
> 
> Residual standard error: 0.276 on 6 degrees of freedom
> Multiple R-Squared: 0.8061,     Adjusted R-squared: 0.6769
> F-statistic: 6.237 on 4 and 6 DF,  p-value: 0.02491
> 
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 1
>  minor = 8.0
>  year = 2003
>  month = 10
>  day = 08
>  language = R
> 
> Windows ME 4.90 (build 3000)
> 
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
> package:nls, package:ts, Autoloads, package:base
> ---
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From elzhov at mail.ru  Mon Nov  3 16:14:32 2003
From: elzhov at mail.ru (=?koi8-r?Q?=22?=Timur Elzhov=?koi8-r?Q?=22=20?=)
Date: Mon, 03 Nov 2003 18:14:32 +0300
Subject: [R] lang2(...) with two and more arguments
Message-ID: <E1AGgPY-0009fe-00.elzhov-mail-ru@f16.mail.ru>

Dear R-help,

how could I create an R call in C code using lang2 with 2 and more
arguments? I tried this code:

SEXP f(SEXP fn, SEXP rho)
{
    SEXP R_fcall, x, y;

    PROTECT(R_fcall = lang2(fn, R_NilValue));
    PROTECT(x = allocVector(REALSXP, 1));
    PROTECT(y = allocVector(REALSXP, 1));

    REAL(x)[0] = 10;
    REAL(y)[0] = 20;

    SETCADR(R_fcall, x);
    SETCADR(R_fcall, y);

    UNPROTECT(3);

    return R_fcall;
}

.Call("f", c, new.env()) returns

`.Primitive("c")(20)', but not `.Primitive("c")(10, 20)',
as I expected. How can I recieve the disired result?

Thank you very much.

--
WBR,
Timur.



From v_bill_pikounis at merck.com  Mon Nov  3 16:15:00 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Mon, 03 Nov 2003 10:15:00 -0500
Subject: [R] Calling R from PHP on Win2K?
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F04155E1B@usrymx18.merck.com>

John,
I am sorry for the delayed reply...since it sounds like you would need to
gain some knowledge on how to integrate components like Apache, MySQL, PHP,
and R, I highly recommend one or more of Paul Dubois' books:

1) MySQL
2) MySQL Cookbook
3) MYSQL and Perl for the Web

While the primary focus of these is the MySQL database, the author is very
thorough in explaining how to connect MySQL to other tools like Apache and
PHP.  Even the third book, while certainly Perl-centric, illustrates
concepts that are applicable to other glue languages such as PHP and Python.
Even some of the OS differences between Windows and Linux are included in
his discussions.

There is overlap amongst all three, but enough distinction to make all 3 a
worthwhile investment if indeed you wish to come with a reliable practical
solution.  If you want to invest in only one, I would start with the MySQL
book.

Hope this helps.

Bill
----------------------------------------
Bill Pikounis, Ph.D.

Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY33-300  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

Phone: 732 594 3913
Fax: 732 594 1565



From elzhov at mail.ru  Mon Nov  3 16:30:33 2003
From: elzhov at mail.ru (=?koi8-r?Q?=22?=Timur Elzhov=?koi8-r?Q?=22=20?=)
Date: Mon, 03 Nov 2003 18:30:33 +0300
Subject: [R] lang2(...) with two and more arguments
Message-ID: <E1AGgf3-0001DD-00.elzhov-mail-ru@f17.mail.ru>

Dear R-help,

how could I create an R call in C code using lang2 with 2 and more
arguments? I tried this code:

SEXP f(SEXP fn, SEXP rho)
{
    SEXP R_fcall, x, y;

    PROTECT(R_fcall = lang2(fn, R_NilValue));
    PROTECT(x = allocVector(REALSXP, 1));
    PROTECT(y = allocVector(REALSXP, 1));

    REAL(x)[0] = 10;
    REAL(y)[0] = 20;

    SETCADR(R_fcall, x);
    SETCADR(R_fcall, y);

    UNPROTECT(3);

    return R_fcall;
}

.Call("f", c, new.env()) returns

`.Primitive("c")(20)', but not `.Primitive("c")(10, 20)',
as I expected. How can I recieve the disired result?

Thank you very much.

--
WBR,
Timur.



From RBaskin at ahrq.gov  Mon Nov  3 16:19:59 2003
From: RBaskin at ahrq.gov (RBaskin@ahrq.gov)
Date: Mon, 3 Nov 2003 10:19:59 -0500 
Subject: [R] Weird problem with median on a factor
Message-ID: <3598558AD728D41183350008C7CF291C0F16B98A@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031103/3b0bd92f/attachment.pl

From Arne.Muller at aventis.com  Mon Nov  3 16:33:52 2003
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Mon, 3 Nov 2003 16:33:52 +0100
Subject: [R] FDR in p.adjust
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE410B3B@crbsmxsusr04.pharma.aventis.com>

Hello,

I've a question about the fdr method in p.adjust: What is the threshold of
the FDR, and is it possible to change this threshold?

As I understand the FDR (please correct) it adjusts the p-values so that for
less than N% (say the cutoff is 25%) of the alternative hypothesis the Null
is in fact true.

	thanks a lot for help,
	+regards,

	Arne



From mailinglist2_wegmann at web.de  Mon Nov  3 16:33:15 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Mon, 3 Nov 2003 16:33:15 +0100
Subject: [R] USA map
In-Reply-To: <C1F927C74082D311A25B00508B5BFF1704E0C13E@urmail-oz.richmond.edu>
References: <C1F927C74082D311A25B00508B5BFF1704E0C13E@urmail-oz.richmond.edu>
Message-ID: <200311031633.15120.mailinglist2_wegmann@web.de>

On Monday 03 November 2003 15:46, Owen, Jason wrote:
> R users,
>
> In S, there was a function called usa() that
> would draw the map of the United States, plus
> it had other options for graphics.  I have looked
> but I can't find the equivalent in R.  Is there one?
>Description

I don't know the usa() function in S but usa() in R gives a map of the US

that's the output of a "usa " search, perhaps that is what you are looking 
for:

cheers Martin

P.S.: www.freegis.org -> GeoData is worth a look for more maps

usa() {map}

 This database produces a map of the United States mainland generated from US 
Department of the Census data (see the reference). 


Usage

data(usaMapEnv)

Format


 The data file is merely an assignment to a character string which specifies 
the name of an environment variable which contains the base location of the 
binary files used by the map drawing functions. This environment variable 
(R_MAP_DATA_DIR for the datasets in the maps package) is set at package load 
time if it does not already exist. Hence setting the environment variable 
before loading the package can override the default location of the binary 
datasets. 


References


 Richard A. Becker, and Allan R. Wilks, "Maps in S", AT&T Bell Laboratories 
Statistics Research Report [93.2], 1993. 


Richard A. Becker, and Allan R. Wilks, "Constructing a Geographical Database", 
AT&T Bell Laboratories Statistics Research Report [95.2], 1995. 


US Department of Commerce, Census Bureau, County Boundary File, computer tape, 
available from Customer Services, Bureau of the Census, Washingdon DC 20233.



From king.812 at osu.edu  Mon Nov  3 16:43:02 2003
From: king.812 at osu.edu (WAYNE KING)
Date: Mon, 03 Nov 2003 10:43:02 -0500
Subject: [R] R-1.8 for Suse Linux  rpm question
Message-ID: <1a66811a2737.1a27371a6681@osu.edu>

Hi list, a question for persons using Suse Linux with R. There are two rpms for Suse 8.2 on the mirrors for the base 1.8.0 package, The R-base-1.8.... rpm and one which is named R-patchted-1.8.0... rpm. The second one is 4 megs smaller than the first and the patch is naturally posted later. My question is: Do I need to install both, or is the "patched" version a full version of the base package containing some fixes. 

Thanks, 

wayne king



From p.dalgaard at biostat.ku.dk  Mon Nov  3 17:06:37 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Nov 2003 17:06:37 +0100
Subject: [R] lang2(...) with two and more arguments
In-Reply-To: <E1AGgf3-0001DD-00.elzhov-mail-ru@f17.mail.ru>
References: <E1AGgf3-0001DD-00.elzhov-mail-ru@f17.mail.ru>
Message-ID: <x2llqxe8s2.fsf@biostat.ku.dk>

"Timur Elzhov" <elzhov at mail.ru> writes:

> Dear R-help,
> 
> how could I create an R call in C code using lang2 with 2 and more
> arguments? I tried this code:
> 
> SEXP f(SEXP fn, SEXP rho)
> {
>     SEXP R_fcall, x, y;
> 
>     PROTECT(R_fcall = lang2(fn, R_NilValue));
>     PROTECT(x = allocVector(REALSXP, 1));
>     PROTECT(y = allocVector(REALSXP, 1));
> 
>     REAL(x)[0] = 10;
>     REAL(y)[0] = 20;
> 
>     SETCADR(R_fcall, x);
>     SETCADR(R_fcall, y);
> 
>     UNPROTECT(3);
> 
>     return R_fcall;
> }
> 
> .Call("f", c, new.env()) returns
> 
> `.Primitive("c")(20)', but not `.Primitive("c")(10, 20)',
> as I expected. How can I recieve the disired result?
> 
> Thank you very much.

Hmmm. This is definitely not right:

     SETCADR(R_fcall, x);
     SETCADR(R_fcall, y);

sets the same location first to x, and then to y. I suspect you need 

     SETCADDR(R_fcall, y);

but no guarantees...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Mon Nov  3 17:05:17 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 03 Nov 2003 08:05:17 -0800
Subject: [R] second Y axis
In-Reply-To: <Law15-DAV45AcJXrMVh00010aca@hotmail.com>
References: <Law15-DAV45AcJXrMVh00010aca@hotmail.com>
Message-ID: <3FA67CBD.60806@pdf.com>

      1.  Most of your question was deleted by some HTML translation 
problem;  the entire email I received appears below.  If you set your 
email software for plain text only, your email is more likely to arrive 
intact. 

      2.  Regarding the question in the "Subject", have you considered 
"?axis"? 

      hope this helps.  spencer graves

sagar wrote:

>please send me the manual abnout the 
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From duncan at research.bell-labs.com  Mon Nov  3 17:07:42 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Mon, 3 Nov 2003 11:07:42 -0500
Subject: [R] calling R from Perl
In-Reply-To: <twig.1067855858.27681@ist.org>;
	from martin@ist.org on Mon, Nov 03, 2003 at 10:37:39AM -0000
References: <twig.1067855858.27681@ist.org>
Message-ID: <20031103110742.A14969@jessie.research.bell-labs.com>

martin at ist.org wrote:
> Hi,
> 
> I want to call R from Perl to generate plots to be displayed on a 
> webpage. What I found out so far is that there is a package called 
> RSPerl on www.omegahat.org which should do what I need. However in 
> the description it says it has been tested with R 1.3.* the latest.
> I'm using R 1.8.0 right now so the package seems rather unmaintained. 
> It is not easy for me to just install it and see if it works because 
> I have to contact the sysadmin everytime and he is kind of reluctant 
> on 'just trying things out'.


RSPerl is being maintained and it works on 1.1.* and higher.  I don't
have the time to update _all_ the documentation.

I don't believe you will need the system administrator's assistance to
install the RSPerl package. It is designed to install into a local
directory by default.

If you have problems, you can send mail to omega-help at omegahat.org.

 D.

> 
> Does anybody have experience with RSPerl or any other solution on how 
> to do this? Any help is appreciated,
> 
> Martin Keller-Ressel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From kjetil at entelnet.bo  Mon Nov  3 17:08:34 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 03 Nov 2003 12:08:34 -0400
Subject: [R] USA map
In-Reply-To: <C1F927C74082D311A25B00508B5BFF1704E0C13E@urmail-oz.richmond.edu>
Message-ID: <3FA64542.6708.CB99C3@localhost>

On 3 Nov 2003 at 9:46, Owen, Jason wrote:

library(maps) # since two days available precompiled for windows
map('usa')

Kjetil Halvorsen

> R users,
> 
> In S, there was a function called usa() that
> would draw the map of the United States, plus
> it had other options for graphics.  I have looked
> but I can't find the equivalent in R.  Is there one?
> 
> Thanks,
> 
> Jason
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Mon Nov  3 17:11:52 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Nov 2003 16:11:52 +0000 (GMT)
Subject: [R] lang2(...) with two and more arguments
In-Reply-To: <E1AGgf3-0001DD-00.elzhov-mail-ru@f17.mail.ru>
Message-ID: <Pine.LNX.4.44.0311031610130.17809-100000@gannet.stats>

You set the first argument to x and then to y.  Why are you surprised?

On Mon, 3 Nov 2003, [koi8-r] "Timur Elzhov[koi8-r] "  wrote:

> Dear R-help,
> 
> how could I create an R call in C code using lang2 with 2 and more
> arguments? I tried this code:
> 
> SEXP f(SEXP fn, SEXP rho)
> {
>     SEXP R_fcall, x, y;
> 
>     PROTECT(R_fcall = lang2(fn, R_NilValue));
>     PROTECT(x = allocVector(REALSXP, 1));
>     PROTECT(y = allocVector(REALSXP, 1));
> 
>     REAL(x)[0] = 10;
>     REAL(y)[0] = 20;
> 
>     SETCADR(R_fcall, x);
>     SETCADR(R_fcall, y);
> 
>     UNPROTECT(3);
> 
>     return R_fcall;
> }
> 
> .Call("f", c, new.env()) returns
> 
> `.Primitive("c")(20)', but not `.Primitive("c")(10, 20)',
> as I expected. How can I recieve the disired result?
> 
> Thank you very much.
> 
> --
> WBR,
> Timur.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Nov  3 17:45:36 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Nov 2003 16:45:36 +0000 (GMT)
Subject: [R] Weird problem with median on a factor
In-Reply-To: <3598558AD728D41183350008C7CF291C0F16B98A@exchange1.ahrq.gov>
Message-ID: <Pine.LNX.4.44.0311031644100.17889-100000@gannet.stats>

On Mon, 3 Nov 2003 RBaskin at ahrq.gov wrote:

> Continuing to beat the greasy spot in the road where the dead horse used to
> be....
> 
> 1) I know that the people building r are working on bigger and better things
> than this silly question and I appreciate the existence of this complicated
> package that was dropped in my lap for free.
> 
> 2) Tony Platt succinctly pointed out one of the underlying 'problems'
> (possibly in my understanding):
> 
> 
> > #this is a perfectly reasonable r object
> > some.weird.object<-factor(c("a","b","c"))
> > #this is an internal r function acting on an object
> > typeof(some.weird.object)
> [1] "integer"
> > #this is a primitive r function acting on an object
> > is.numeric(some.weird.object)
> [1] FALSE
> >
> 
> Do these functions behave in a design consistent manor??  Can a single r
> object simultaneously be of type integer and NOT numeric??  If this is
> intentional can someone explain why?

See the help for is.numeric: it *does* explain this.  You should be 
careful not to confuse classes with representations.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From aurora at ebi.ac.uk  Mon Nov  3 17:46:34 2003
From: aurora at ebi.ac.uk (Aurora Torrente)
Date: Mon, 03 Nov 2003 16:46:34 +0000
Subject: [R] comparing characters
Message-ID: <3FA6866A.80007@ebi.ac.uk>

Hi all,
I?m having some trouble when trying to compare character values (to 
check if they are alphabetically ordered). Is it possible to do it in 
any way?
Thanks for your help. Cheers,

        Aurora



From mros at autan.toulouse.inra.fr  Mon Nov  3 17:58:26 2003
From: mros at autan.toulouse.inra.fr (Mathieu Ros)
Date: Mon,  3 Nov 2003 17:58:26 +0100 (MET)
Subject: [R] problem building MS-Windows package under linux
Message-ID: <16294.33559.414891.388411@autan.toulouse.inra.fr>

hi there,
trying to follow the steps of Yan & Rossini 2003, I have two problems
:
first when I 'make CrossCompileBuild', I get :

******************************************************************************

make[1]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
make -f Makefile.docfiles
make[2]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
makeinfo --no-split --html --no-headers --number-sections -o tmp.html tmp.texi
tidy tmp.html > tmp2.html 2> /dev/null
make[2]: [fixed/html/rw-FAQ.html] Error 127 (ignored)
*** tidy appears to be non-functional ***
make[2]: *** [fixed/html/rw-FAQ.html] Error 111
make[2]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
make[1]: *** [docfiles] Error 2
make[1]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
******************************************************************************


and then, trying to go throught, as this didn't look like a big
error, I 'make pkg-multidim_0.5-3' and 


******************************************************************************

-------multidim------
make[1]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'

---------- Making package multidim ------------
  installing inst files
  adding build stamp to DESCRIPTION
  making DLL ...
dataentry.c:27: config.h: No such file or directory
make[4]: *** [dataentry.o] Error 1
make[3]: *** [libR] Error 2
make[2]: *** [srcDynlib] Error 2
make[1]: *** [pkg-multidim] Error 2
make[1]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
  adding: multidim/ (stored 0%)
  adding: multidim/doc/ (stored 0%)
  adding: multidim/DESCRIPTION (deflated 31%)
  adding: multidim/doc/multidim.ps (deflated 77%)

******************************************************************************

I don't understand where this 'config.h' should come from...
any help appreciated, and many thanks to the authors for this
comprehensive article.

-- 
Mathieu Ros
Ph. D. student - "Canalizing selection using Bayesian models"
INRA - Fish Genetics Unit (Paris)/Cell Genetics Unit (Toulouse)
tel : (+0033)1 3465 3414 (FGU) / (+0033)5 6128 5305 (CGU)
mail : ros at diamant.jouy.inra.fr



From an980634 at uni-greifswald.de  Mon Nov  3 18:01:41 2003
From: an980634 at uni-greifswald.de (Arne Neumann)
Date: Mon, 3 Nov 2003 18:01:41 +0100
Subject: [R]  hclust doesn't return merge details
Message-ID: <000701c3a22c$29dff630$1bd1358d@2511>

 Dear R-users,

I tried to receive the merge details of a clustering by using the
summary function of hclust.
For illustration I use the Longley data as done by Prof Ripley (Wed 11
Apr 2001)
d <- dist(longley.y) 
d <- d/max(d) 
hc <- hclust(d, "ave") 

But instead of getting a matrix for $merge I get:
>summary(hc)
		Length Class  Mode     
merge       30     -none- numeric  
height      15     -none- numeric  
order       16     -none- numeric  
labels       0     -none- NULL     
method       1     -none- character
call         3     -none- call     
dist.method  1     -none- character

Am I missing something?
Arne Neumann

> R.version
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    7.1            
year     2003           
month    06             
day      16



From gwiggner at lix.polytechnique.fr  Mon Nov  3 18:03:47 2003
From: gwiggner at lix.polytechnique.fr (Claus Gwiggner)
Date: Mon, 3 Nov 2003 18:03:47 +0100 (CET)
Subject: [R] Binaries for RORacle and V 1.8. needed
In-Reply-To: <1a66811a2737.1a27371a6681@osu.edu>
Message-ID: <Pine.LNX.4.44.0311031754360.14492-100000@lix.polytechnique.fr>

Hi,
there is no Oracle Client on my machine (Redhat Linux 9.0/686i, R1.8.0).
I read the readme.client file and did: 
I unziped the package ROracle and copied it into the R-library path.
I get:
>library(ROracle)
Error in testRversion(descfields) : This package has not been installed properly


Who has a binary version of ROracle for my configuration?

Thanks,
Claus



From jps at sanger.ac.uk  Mon Nov  3 18:47:53 2003
From: jps at sanger.ac.uk (Jason Skelton)
Date: Mon, 03 Nov 2003 17:47:53 +0000
Subject: [R] mva Hclust, heatmap and plotting functions
Message-ID: <3FA694C9.7070404@sanger.ac.uk>

Hi All

Not sure if this a bioconductor question or general R mailing list
so apologies if this has gone to the wrong one.................

When plotting dendrograms created by hclust you can "identify" clusters 
by clicking on the graphics and returning a list of what is contained in 
each cluster. However I'd like to be able to "zoom in" on specific 
clusters and plot them, is this possible at all ?


Also


I have a microarray experiment where I'd like to be able to plot
A gene tree against a condition tree using the heatmap function.
for genes according to treatments and viceversa

I.e Treatments being DIF1, DIF2, DIF3
genes being 324c_F, 634_F etc.


393 genes x 3 treatments

name		DIF1		DIF2		DIF3
324c_F		4.16E-01	2.65E-01	0.298602679
634_F		8.95E-01	6.67E-01	0.337895962
504c_F		4.54E-01	5.94E-01	1.185792741
1302_F		-6.43E-01	-5.39E-01	0.073152009
233c_F		4.20E-01	4.27E-01	0.261216119
1274_F		-5.00E-01	-3.53E-01	-0.161567509
1314_F		1.59E+00	1.08E+00	0.403198377
1791c_F		9.08E-01	4.11E-01	0.461046812
594c_F		6.43E-01	3.93E-01	-0.142807556
854c_F		-5.59E-01	-9.70E-01	-0.766361402

viseversa.

3 treatment x 393 genes

name	324c_F		634_F		504c_F		1302_F..........
DIF1	4.16E-01	8.95E-01	4.54E-01	-6.43E-01......
DIF2	2.65E-01	6.67E-01	5.94E-01	-5.39E-01......
DIF3	0.298602679	0.337895962	1.185792741	0.073152009....

etc.............

And would like to be able to plot one against the other.

I've used as.dendrogram to create dendrograms from the output of hclust 
for each of the data sets mentioned above but..........
I'm having problems with the rest of the functions
Could someone advise me as to which numeric matrix I should be using 
specified as X
in the example:

heatmap(x, dendrogram1, dendrogram2 etc)

I.e. is X coming from the results of dist, hclust or the original data ?

If so do you then need to covert it into a numeric matrix ?
I've thus far tried the data.matrix function on the output from all of 
the above only to get:  `x' must be a numeric matrix

heatmap(DIF123distmatrix, hclustfun=hclust)
This command works nicely but obviously plots the same thing
on both axes.

I've tried something along the lines of:

heatmap(DIF123datamat, DIF123clustFLIPasdendro,
DIF123clustHCmcquittyasdendro, hclustfun=hclust)
but this returns
row dendrogram ordering gave index of wrong length
which has come from the viseversa example above.



thanks for any help and guidance

Jason







-- 
--------------------------------
Jason Skelton
Pathogen Microarrays
Wellcome Trust Sanger Institute
Hinxton
Cambridge
CB10 1SA

Tel +44(0)1223 834244 Ext 7123
Fax +44(0)1223 494919



From spencer.graves at pdf.com  Mon Nov  3 18:50:10 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 03 Nov 2003 09:50:10 -0800
Subject: [R] comparing characters
In-Reply-To: <3FA6866A.80007@ebi.ac.uk>
References: <3FA6866A.80007@ebi.ac.uk>
Message-ID: <3FA69552.9080401@pdf.com>

What sort of trouble are you having?  I just got the following from R 
1.8.0: 

 > "a"<"b"
[1] TRUE
 > "a">"b"
[1] FALSE
 > "ab"<"a"
[1] FALSE
 > "ab">"a"
[1] TRUE

hope this helps.  spencer graves

Aurora Torrente wrote:

> Hi all,
> I?m having some trouble when trying to compare character values (to 
> check if they are alphabetically ordered). Is it possible to do it in 
> any way?
> Thanks for your help. Cheers,
>
>        Aurora
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From GPetris at uark.edu  Mon Nov  3 19:00:41 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Mon, 3 Nov 2003 12:00:41 -0600 (CST)
Subject: [R] comparing characters
In-Reply-To: <3FA6866A.80007@ebi.ac.uk> (message from Aurora Torrente on Mon, 
	03 Nov 2003 16:46:34 +0000)
References: <3FA6866A.80007@ebi.ac.uk>
Message-ID: <200311031800.hA3I0f0f000597@definetti.uark.edu>


You could do something like that: 

> x <- sample(LETTERS, 10)
> x
 [1] "K" "N" "C" "F" "R" "E" "L" "J" "S" "Q"
> all.equal(order(x), 1:length(x))
[1] "Mean relative  difference: 0.5090909"

When x is a numeric vector, I usually use

> any(diff(x) < 0)

although I don't know whether it's more efficient.

HTH,
Giovanni

> Date: Mon, 03 Nov 2003 16:46:34 +0000
> From: Aurora Torrente <aurora at ebi.ac.uk>
> Sender: r-help-bounces at stat.math.ethz.ch
> Organization: EBI
> Precedence: list
> User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.0; en-GB;	rv:0.9.4)
>  Gecko/20011128 Netscape6/6.2.1
> 
> Hi all,
> I?m having some trouble when trying to compare character values (to 
> check if they are alphabetically ordered). Is it possible to do it in 
> any way?
> Thanks for your help. Cheers,
> 
>         Aurora
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 


-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From ligges at statistik.uni-dortmund.de  Mon Nov  3 19:01:49 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 03 Nov 2003 19:01:49 +0100
Subject: [R] comparing characters
In-Reply-To: <3FA6866A.80007@ebi.ac.uk>
References: <3FA6866A.80007@ebi.ac.uk>
Message-ID: <3FA6980D.7060104@statistik.uni-dortmund.de>

Aurora Torrente wrote:

> Hi all,
> I?m having some trouble when trying to compare character values (to 
> check if they are alphabetically ordered). Is it possible to do it in 
> any way?
> Thanks for your help. Cheers,

"a" < "b" should work.
If that's not your question, you have to be more specific.

Uwe Ligges



From paulojus at est.ufpr.br  Mon Nov  3 19:07:21 2003
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Mon, 3 Nov 2003 16:07:21 -0200 (BRST)
Subject: [R] problem building MS-Windows package under linux
In-Reply-To: <16294.33559.414891.388411@autan.toulouse.inra.fr>
References: <16294.33559.414891.388411@autan.toulouse.inra.fr>
Message-ID: <Pine.LNX.4.56.0311031605130.6637@gauss.est.ufpr.br>


I had this same problem before:

you need to install the program "tidy"  in your linux machine

There is a p[ackage for DEBIAN such that you can use
apt-get install tidy

don't know about other distros but it is probably available as well

P.J.

paulojus at notebook:~$ apt-cache search tidy
perltidy - A Perl script indenter and reformatter
tidy - HTML syntax checker and reformatter
tidy-doc - HTML syntax checker and reformatter documentation
tidy-proxy - A small http proxy which tidies html



On Mon, 3 Nov 2003, Mathieu Ros wrote:

> hi there,
> trying to follow the steps of Yan & Rossini 2003, I have two problems
> :
> first when I 'make CrossCompileBuild', I get :
>
> ******************************************************************************
>
> make[1]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> make -f Makefile.docfiles
> make[2]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> makeinfo --no-split --html --no-headers --number-sections -o tmp.html tmp.texi
> tidy tmp.html > tmp2.html 2> /dev/null
> make[2]: [fixed/html/rw-FAQ.html] Error 127 (ignored)
> *** tidy appears to be non-functional ***
> make[2]: *** [fixed/html/rw-FAQ.html] Error 111
> make[2]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> make[1]: *** [docfiles] Error 2
> make[1]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> ******************************************************************************
>
>
> and then, trying to go throught, as this didn't look like a big
> error, I 'make pkg-multidim_0.5-3' and
>
>
> ******************************************************************************
>
> -------multidim------
> make[1]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
>
> ---------- Making package multidim ------------
>   installing inst files
>   adding build stamp to DESCRIPTION
>   making DLL ...
> dataentry.c:27: config.h: No such file or directory
> make[4]: *** [dataentry.o] Error 1
> make[3]: *** [libR] Error 2
> make[2]: *** [srcDynlib] Error 2
> make[1]: *** [pkg-multidim] Error 2
> make[1]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
>   adding: multidim/ (stored 0%)
>   adding: multidim/doc/ (stored 0%)
>   adding: multidim/DESCRIPTION (deflated 31%)
>   adding: multidim/doc/multidim.ps (deflated 77%)
>
> ******************************************************************************
>
> I don't understand where this 'config.h' should come from...
> any help appreciated, and many thanks to the authors for this
> comprehensive article.
>
> --
> Mathieu Ros
> Ph. D. student - "Canalizing selection using Bayesian models"
> INRA - Fish Genetics Unit (Paris)/Cell Genetics Unit (Toulouse)
> tel : (+0033)1 3465 3414 (FGU) / (+0033)5 6128 5305 (CGU)
> mail : ros at diamant.jouy.inra.fr
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From andy_liaw at merck.com  Mon Nov  3 19:10:09 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 03 Nov 2003 13:10:09 -0500
Subject: [R]  hclust doesn't return merge details
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDAB@usrymx25.merck.com>

> From: Arne Neumann [mailto:an980634 at uni-greifswald.de] 
> 
>  Dear R-users,
> 
> I tried to receive the merge details of a clustering by using 
> the summary function of hclust. For illustration I use the 
> Longley data as done by Prof Ripley (Wed 11 Apr 2001) d <- 
> dist(longley.y) 
> d <- d/max(d) 
> hc <- hclust(d, "ave") 
> 
> But instead of getting a matrix for $merge I get:
> >summary(hc)
> 		Length Class  Mode     
> merge       30     -none- numeric  
> height      15     -none- numeric  
> order       16     -none- numeric  
> labels       0     -none- NULL     
> method       1     -none- character
> call         3     -none- call     
> dist.method  1     -none- character
> 
> Am I missing something?

I believe so.

> str(hc)
List of 7
 $ merge      : int [1:15, 1:2] -6 -13 -10 -1 -9 -3 -5 -16 -12 8 ...
 $ height     : num [1:15] 20.1 23.6 27.2 29.2 41.4 ...
 $ order      : int [1:16] 1 2 3 4 16 13 14 12 15 5 ...
 $ labels     : chr [1:16] "1947" "1948" "1949" "1950" ...
 $ method     : chr "average"
 $ call       : language hclust(d = dist(data.matrix(longley)), method =
"ave")
 $ dist.method: chr "euclidean"
 - attr(*, "class")= chr "hclust"

so the "merge" component is a n x 2 matrix, whose mode is "numeric".

Andy


> Arne Neumann
> 
> > R.version
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    7.1            
> year     2003           
> month    06             
> day      16
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From MSchwartz at medanalytics.com  Mon Nov  3 19:14:42 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 03 Nov 2003 12:14:42 -0600
Subject: [R] comparing characters
In-Reply-To: <3FA6866A.80007@ebi.ac.uk>
References: <3FA6866A.80007@ebi.ac.uk>
Message-ID: <1067883281.20030.41.camel@localhost.localdomain>

On Mon, 2003-11-03 at 10:46, Aurora Torrente wrote:
> Hi all,
> I?m having some trouble when trying to compare character values (to 
> check if they are alphabetically ordered). Is it possible to do it in 
> any way?
> Thanks for your help. Cheers,
> 
>         Aurora


Depending upon what it is you are comparing, you may find differences
from what you expect due to to your 'locale'.

See ?Comparison for more information.

HTH,

Marc Schwartz



From aurora at ebi.ac.uk  Mon Nov  3 19:41:42 2003
From: aurora at ebi.ac.uk (Aurora Torrente)
Date: Mon, 03 Nov 2003 18:41:42 +0000
Subject: [R] comparing characters
References: <3FA6866A.80007@ebi.ac.uk> <3FA69552.9080401@pdf.com>
Message-ID: <3FA6A166.6010105@ebi.ac.uk>

That?s what I needed. Thanks!

Spencer Graves wrote:

> What sort of trouble are you having?  I just got the following from R 
> 1.8.0:
> > "a"<"b"
> [1] TRUE
> > "a">"b"
> [1] FALSE
> > "ab"<"a"
> [1] FALSE
> > "ab">"a"
> [1] TRUE
>
> hope this helps.  spencer graves
>
>



From tblackw at umich.edu  Mon Nov  3 19:54:29 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 3 Nov 2003 13:54:29 -0500 (EST)
Subject: [R]  hclust doesn't return merge details
In-Reply-To: <000701c3a22c$29dff630$1bd1358d@2511>
References: <000701c3a22c$29dff630$1bd1358d@2511>
Message-ID: <Pine.SOL.4.58.0311031346140.5892@asteroids.gpcc.itd.umich.edu>

Arne  -

I have carried out exactly your example below, and I
get hc$merge as a matrix with two columns and 15 rows.

Do  str(hc)  to see a useful representation of the
contents of the returned list.  help("hclust")  describes
this list in the section "Value:".  help("Subscript")
shows the various syntactic forms that will extract one
element from a list, but doesn't say quite as explicitly
as one might wish that  hc[["merge"]]  or  hc[[1]]  is
the way to return just element "merge" from the list.

Brian Ripley may correct me if I am wrong, but I think
there have never been 'extractor' functions for the
return value from  hclust()  as there are for  lm().

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 3 Nov 2003, Arne Neumann wrote:

>  Dear R-users,
>
> I tried to receive the merge details of a clustering by using the
> summary function of hclust.
> For illustration I use the Longley data as done by Prof Ripley (Wed 11
> Apr 2001)
> d <- dist(longley.y)
> d <- d/max(d)
> hc <- hclust(d, "ave")
>
> But instead of getting a matrix for $merge I get:
> >summary(hc)
> 		Length Class  Mode
> merge       30     -none- numeric
> height      15     -none- numeric
> order       16     -none- numeric
> labels       0     -none- NULL
> method       1     -none- character
> call         3     -none- call
> dist.method  1     -none- character
>
> Am I missing something?
> Arne Neumann
>
> > R.version
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    7.1
> year     2003
> month    06
> day      16
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Mon Nov  3 20:26:43 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Nov 2003 19:26:43 +0000 (GMT)
Subject: [R] problem building MS-Windows package under linux
In-Reply-To: <16294.33559.414891.388411@autan.toulouse.inra.fr>
Message-ID: <Pine.LNX.4.44.0311031925360.18254-100000@gannet.stats>

You do need to build R before you build a package, when cross-building.
`Small' errors stop make running: try make -k?

On Mon, 3 Nov 2003, Mathieu Ros wrote:

> hi there,
> trying to follow the steps of Yan & Rossini 2003, I have two problems
> :
> first when I 'make CrossCompileBuild', I get :
> 
> ******************************************************************************
> 
> make[1]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> make -f Makefile.docfiles
> make[2]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> makeinfo --no-split --html --no-headers --number-sections -o tmp.html tmp.texi
> tidy tmp.html > tmp2.html 2> /dev/null
> make[2]: [fixed/html/rw-FAQ.html] Error 127 (ignored)
> *** tidy appears to be non-functional ***
> make[2]: *** [fixed/html/rw-FAQ.html] Error 111
> make[2]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> make[1]: *** [docfiles] Error 2
> make[1]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> ******************************************************************************
> 
> 
> and then, trying to go throught, as this didn't look like a big
> error, I 'make pkg-multidim_0.5-3' and 
> 
> 
> ******************************************************************************
> 
> -------multidim------
> make[1]: Entering directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
> 
> ---------- Making package multidim ------------
>   installing inst files
>   adding build stamp to DESCRIPTION
>   making DLL ...
> dataentry.c:27: config.h: No such file or directory
> make[4]: *** [dataentry.o] Error 1
> make[3]: *** [libR] Error 2
> make[2]: *** [srcDynlib] Error 2
> make[1]: *** [pkg-multidim] Error 2
> make[1]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
>   adding: multidim/ (stored 0%)
>   adding: multidim/doc/ (stored 0%)
>   adding: multidim/DESCRIPTION (deflated 31%)
>   adding: multidim/doc/multidim.ps (deflated 77%)
> 
> ******************************************************************************
> 
> I don't understand where this 'config.h' should come from...
> any help appreciated, and many thanks to the authors for this
> comprehensive article.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f0z6305 at labs.tamu.edu  Mon Nov  3 20:32:16 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Mon, 3 Nov 2003 13:32:16 -0600
Subject: [R]A matrix is full rank is equal to having independent columns?
Message-ID: <004e01c3a241$30d475f0$d9bfa543@f0z6305>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031103/63090f1c/attachment.pl

From maechler at stat.math.ethz.ch  Mon Nov  3 20:42:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Nov 2003 20:42:27 +0100
Subject: [R] comparing characters
In-Reply-To: <200311031800.hA3I0f0f000597@definetti.uark.edu>
References: <3FA6866A.80007@ebi.ac.uk>
	<200311031800.hA3I0f0f000597@definetti.uark.edu>
Message-ID: <16294.44963.657719.261164@gargle.gargle.HOWL>

>>>>> "Giovanni" == Giovanni Petris <GPetris at uark.edu>
>>>>>     on Mon, 3 Nov 2003 12:00:41 -0600 (CST) writes:

    Giovanni> You could do something like that:

    >> x <- sample(LETTERS, 10) x
    Giovanni>  [1] "K" "N" "C" "F" "R" "E" "L" "J" "S" "Q"
    >> all.equal(order(x), 1:length(x))
    Giovanni> [1] "Mean relative difference: 0.5090909"

    Giovanni> When x is a numeric vector, I usually use

    >> any(diff(x) < 0)

    Giovanni> although I don't know whether it's more efficient.

There's a builtin R function that is definitely even faster
(at least for largish vectors):

is.unsorted()

--
Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From jmacdon at med.umich.edu  Mon Nov  3 20:45:58 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Mon, 03 Nov 2003 14:45:58 -0500
Subject: [R] FDR in p.adjust
Message-ID: <sfa66a40.024@med-gwia-02a.med.umich.edu>

There is no threshold for fdr. The adjusted p-values give the expected
proportion of false positives for all comparisons with similar p-values
or smaller. In other words, if you choose a p-value of 0.05, you would
expect that ~5% of the tests with a p-value of 0.05 or smaller are false
positives.

HTH,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> <Arne.Muller at aventis.com> 11/03/03 10:33AM >>>
Hello,

I've a question about the fdr method in p.adjust: What is the threshold
of
the FDR, and is it possible to change this threshold?

As I understand the FDR (please correct) it adjusts the p-values so
that for
less than N% (say the cutoff is 25%) of the alternative hypothesis the
Null
is in fact true.

	thanks a lot for help,
	+regards,

	Arne

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ryszard.czerminski at pharma.novartis.com  Mon Nov  3 20:48:12 2003
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Mon, 3 Nov 2003 14:48:12 -0500
Subject: [R] svm in e1071 package: polynomial vs linear kernel
Message-ID: <OF5E5AC438.DA4E75F9-ON85256DD3.006AB568-85256DD3.006CDDE5@EU.novartis.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031103/96c97dc2/attachment.pl

From kjetil at entelnet.bo  Mon Nov  3 20:56:23 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 03 Nov 2003 15:56:23 -0400
Subject: [R] USA map
In-Reply-To: <200311031633.15120.mailinglist2_wegmann@web.de>
References: <C1F927C74082D311A25B00508B5BFF1704E0C13E@urmail-oz.richmond.edu>
Message-ID: <3FA67AA7.31287.155770@localhost>

On 3 Nov 2003 at 16:33, Martin Wegmann wrote:

> On Monday 03 November 2003 15:46, Owen, Jason wrote:
> > R users,
> >
> > In S, there was a function called usa() that
> > would draw the map of the United States, plus
> > it had other options for graphics.  I have looked
> > but I can't find the equivalent in R.  Is there one?
> >Description
> 
> I don't know the usa() function in S but usa() in R gives a map of the US

Where did you find that function? In rw1080 on windows XP I get:

> usa()
Error: couldn't find function "usa"
> 

(and help.search("usa") does'nt give anything usefull)

Kjetil Halvorsen

> 
> that's the output of a "usa " search, perhaps that is what you are looking 
> for:
> 
> cheers Martin
> 
> P.S.: www.freegis.org -> GeoData is worth a look for more maps
> 
> usa() {map}
> 
>  This database produces a map of the United States mainland generated from US 
> Department of the Census data (see the reference). 
> 
> 
> Usage
> 
> data(usaMapEnv)
> 
> Format
> 
> 
>  The data file is merely an assignment to a character string which specifies 
> the name of an environment variable which contains the base location of the 
> binary files used by the map drawing functions. This environment variable 
> (R_MAP_DATA_DIR for the datasets in the maps package) is set at package load 
> time if it does not already exist. Hence setting the environment variable 
> before loading the package can override the default location of the binary 
> datasets. 
> 
> 
> References
> 
> 
>  Richard A. Becker, and Allan R. Wilks, "Maps in S", AT&T Bell Laboratories 
> Statistics Research Report [93.2], 1993. 
> 
> 
> Richard A. Becker, and Allan R. Wilks, "Constructing a Geographical Database", 
> AT&T Bell Laboratories Statistics Research Report [95.2], 1995. 
> 
> 
> US Department of Commerce, Census Bureau, County Boundary File, computer tape, 
> available from Customer Services, Bureau of the Census, Washingdon DC 20233.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From deepayan at stat.wisc.edu  Mon Nov  3 20:56:49 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 3 Nov 2003 13:56:49 -0600
Subject: [R]A matrix is full rank is equal to having independent columns?
In-Reply-To: <004e01c3a241$30d475f0$d9bfa543@f0z6305>
References: <004e01c3a241$30d475f0$d9bfa543@f0z6305>
Message-ID: <200311031356.49887.deepayan@stat.wisc.edu>


For any matrix, the following definitions hold:

   row rank: number of linearly independent rows
column rank: number of linearly independent columns

There is a theorem stating that these 2 numbers must be the same 
for any matrix, and (consequently) that number is defined as the 
'rank' of the matrix.

For a matrix which has less columns than rows (as in your example), to say it 
has 'full column rank' would mean that it's rank = number of columns, and so 
yes, by definition all it's columns are linearly independent. I don't know if 
the description 'full rank' has any concrete interpretation for such 
matrices, though.

HTH.

On Monday 03 November 2003 13:32, Feng Zhang wrote:
> Dear R listers,
>
> Just a simple question.
> If we say an nxm matrix (n>m) is full rank of m,
> does this mean that this matrix has linearly independent columns?
>
> They are the same definition or needs some proof?
>
> Thanks for your answer.
>
> Fred
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Mon Nov  3 21:00:28 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 03 Nov 2003 16:00:28 -0400
Subject: [R]A matrix is full rank is equal to having independent columns?
In-Reply-To: <004e01c3a241$30d475f0$d9bfa543@f0z6305>
Message-ID: <3FA67B9C.15329.1914C6@localhost>

On 3 Nov 2003 at 13:32, Feng Zhang wrote:

This are the same concept, no additional proof is needed.
The rank of a matrix is the max number of li columns, or rows
(which are the same).

Kjetil Halvorsen

> Dear R listers,
> 
> Just a simple question.
> If we say an nxm matrix (n>m) is full rank of m,
> does this mean that this matrix has linearly independent columns?
> 
> They are the same definition or needs some proof?
> 
> Thanks for your answer.
> 
> Fred
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jasont at indigoindustrial.co.nz  Mon Nov  3 21:02:40 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 04 Nov 2003 09:02:40 +1300
Subject: [R]A matrix is full rank is equal to having independent columns?
In-Reply-To: <004e01c3a241$30d475f0$d9bfa543@f0z6305>
References: <004e01c3a241$30d475f0$d9bfa543@f0z6305>
Message-ID: <3FA6B460.9020106@indigoindustrial.co.nz>

Feng Zhang wrote:
> Dear R listers,
> 
> Just a simple question.
> If we say an nxm matrix (n>m) is full rank of m,
> does this mean that this matrix has linearly independent columns?
> 

Yes.  Now be careful how you define rank.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From ray at mcs.vuw.ac.nz  Mon Nov  3 22:04:30 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Tue, 4 Nov 2003 10:04:30 +1300 (NZDT)
Subject: [R] USA map
Message-ID: <200311032104.hA3L4UQm006936@tahi.mcs.vuw.ac.nz>

> > I don't know the usa() function in S but usa() in R gives a map of the US
> 
> Where did you find that function? In rw1080 on windows XP I get:
> 
Some earlier versions of the maps package (which was then available for
"Unix" only), did have individual functions for each country in the
world database.

In the current version, you need to type:
library(maps)
map("usa") 
#or:
map("world2", "USA")

Ray Brownrigg



From apjaworski at mmm.com  Mon Nov  3 22:04:59 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Mon, 3 Nov 2003 15:04:59 -0600
Subject: [R] USA map
Message-ID: <OF5B668DFB.FC69315D-ON86256DD3.0073AD42-86256DD3.0073D035@mmm.com>


I believe in R you need

library(maps)

before using usa().  Of course, the library has to be installed first.

Cheers,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           kjetil at entelnet.bo   |
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           11/03/2003 13:56     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       "R-list" <r-help at stat.math.ethz.ch>                                                                          |
  |        Martin Wegmann <mailinglist2_wegmann at web.de>                                                                         |
  |      cc:       "Owen, Jason" <wowen at richmond.edu>                                                                           |
  |      Subject:  Re: [R] USA map                                                                                              |
  >-----------------------------------------------------------------------------------------------------------------------------|




On 3 Nov 2003 at 16:33, Martin Wegmann wrote:

> On Monday 03 November 2003 15:46, Owen, Jason wrote:
> > R users,
> >
> > In S, there was a function called usa() that
> > would draw the map of the United States, plus
> > it had other options for graphics.  I have looked
> > but I can't find the equivalent in R.  Is there one?
> >Description
>
> I don't know the usa() function in S but usa() in R gives a map of the US

Where did you find that function? In rw1080 on windows XP I get:

> usa()
Error: couldn't find function "usa"
>

(and help.search("usa") does'nt give anything usefull)

Kjetil Halvorsen

>
> that's the output of a "usa " search, perhaps that is what you are
looking
> for:
>
> cheers Martin
>
> P.S.: www.freegis.org -> GeoData is worth a look for more maps
>
> usa() {map}
>
>  This database produces a map of the United States mainland generated
from US
> Department of the Census data (see the reference).
>
>
> Usage
>
> data(usaMapEnv)
>
> Format
>
>
>  The data file is merely an assignment to a character string which
specifies
> the name of an environment variable which contains the base location of
the
> binary files used by the map drawing functions. This environment variable

> (R_MAP_DATA_DIR for the datasets in the maps package) is set at package
load
> time if it does not already exist. Hence setting the environment variable

> before loading the package can override the default location of the
binary
> datasets.
>
>
> References
>
>
>  Richard A. Becker, and Allan R. Wilks, "Maps in S", AT&T Bell
Laboratories
> Statistics Research Report [93.2], 1993.
>
>
> Richard A. Becker, and Allan R. Wilks, "Constructing a Geographical
Database",
> AT&T Bell Laboratories Statistics Research Report [95.2], 1995.
>
>
> US Department of Commerce, Census Bureau, County Boundary File, computer
tape,
> available from Customer Services, Bureau of the Census, Washingdon DC
20233.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From meyer at ci.tuwien.ac.at  Mon Nov  3 22:52:28 2003
From: meyer at ci.tuwien.ac.at (David Meyer)
Date: Mon, 3 Nov 2003 22:52:28 +0100 (CET)
Subject: [R] svm in e1071 package: polynomial vs linear kernel
In-Reply-To: <OF5E5AC438.DA4E75F9-ON85256DD3.006AB568-85256DD3.006CDDE5@EU.novartis.net>
Message-ID: <Pine.LNX.4.21.0311032251010.16435-100000@boromir.ci.tuwien.ac.at>



On Mon, 3 Nov 2003 ryszard.czerminski at pharma.novartis.com wrote:

> I am trying to understand what is the difference between linear and 
> polynomial kernel:
> 
>           linear: u'*v
> 
>           polynomial: (gamma*u'*v + coef0)^degree
> 
> It would seem that polynomial kernel with gamma = 1; coef0 = 0 and degree 
> = 1
> should be identical to linear kernel, however it gives me significantly 
> different results  for very simple
> data set, with linear kernel significantly outperforming polynomial 
> kernel.
> 
> *** mse, r2 = 0.5, 0.9 for linear
> *** mse, r2 = 1.8, 0.1 for polynomial
> 
> What am I missing ?

Well: perhaps, that you should pass *all* parameters from your cv.svm
function to the call of svm()?

g.,
-d

> 
> Ryszard
> 
> P.S.
> 
> Here are my results:
> 
> # simple cross validation function
> cv.svm <- function(formula, data, ntry = 3, kernel = "linear", scale = 
> FALSE, cross = 3,
>                    gamma = 1/(dim(data)-1), degree = 3) {
>    mse <- 0; r2 <- 0
>    for (n in 1:ntry) {
>       svm.model <- svm(formula , data = data, scale = scale, kernel = 
> kernel,
>                        cross = cross)
>       mse <- mse + svm.model$tot.MSE
>       r2  <- r2 + svm.model$scorrcoeff
>    }
>    mse <- mse/ntry; r2 <- r2/ntry; result <- c(mse, r2)
>    cat(sprintf("cv.svm> mse, r2 = %5.3f %5.3f\n", mse, r2))
>    return (result)
> }
> 
> # define data set
> 
> x1 <- rnorm(9); x2 <- rnorm(9)
> df <- data.frame(y = 2*x1 + x2, x1, x2)
> 
> #  invoke cv.svm() for linear and polynomial kernels few times
> 
> > r <- cv.svm( y ~ ., df, kernel = "polynomial", gamma = 1, degree = 1, 
> ntry = 32)
> cv.svm> mse, r2 = 1.888 0.162
> > r <- cv.svm( y ~ ., df, kernel = "polynomial", gamma = 1, degree = 1, 
> ntry = 32)
> cv.svm> mse, r2 = 1.867 0.146
> > r <- cv.svm( y ~ ., df, kernel = "polynomial", gamma = 1, degree = 1, 
> ntry = 32)
> cv.svm> mse, r2 = 1.818 0.105
> > r <- cv.svm( y ~ ., df, kernel = "linear", gamma = 1, degree = 1, ntry = 
> 32)
> cv.svm> mse, r2 = 0.525 0.912
> > r <- cv.svm( y ~ ., df, kernel = "linear", gamma = 1, degree = 1, ntry = 
> 32)
> cv.svm> mse, r2 = 0.537 0.878
> > r <- cv.svm( y ~ ., df, kernel = "linear", gamma = 1, degree = 1, ntry = 
> 32)
> cv.svm> mse, r2 = 0.528 0.913
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.murrell at auckland.ac.nz  Mon Nov  3 22:59:15 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 04 Nov 2003 10:59:15 +1300
Subject: [R] Visualising Vectors
References: <Pine.LNX.4.44.0311031407510.16713-100000@env-pc-phd13>
	<3FA66D5C.7010302@acm.org>
Message-ID: <3FA6CFB3.50900@stat.auckland.ac.nz>

Hi


Sean O'Riordain wrote:
> Hi Laura,
> 
> you should find some useful information in the latest R news Volume 3/2, 
> October 2003
> http://cran.r-project.org/doc/Rnews/
> 
> refer page 8 where Paul's figure 2 shows some novel symbols showing 
> "China Sea Wind Speed, Direction and Temperature"... plotted by lat.&long.


Sorry Laura, I saw the original mail, got interested in the animation 
part, then got distracted :)  As Sean has pointed out, the wind vectors 
could be done like the example in the R News article, but that may not 
be appropriate if there are very many to be drawn (could get slow). 
Here's a modification of that example which just draws wind vectors as 
simple arrows...


library(gridBase)
chinasea <- read.table("chinasea.txt", header=TRUE)
plot(chinasea$lat, chinasea$long, type="n",
   xlab="latitude", ylab="longitude",
   main="China Sea Wind Speed/Direction and Temperature")
speed <- 0.8*chinasea$speed/14 + 0.2
temp <- chinasea$temp/40
vps <- baseViewports()
par(new=TRUE)
push.viewport(vps$inner, vps$figure, vps$plot)

# Just use a grid.arrows instead of a whole viewport per symbol
length <- 1 # "cm"
x1 <- unit(chinasea$lat, "native") -
   unit(0.5*length*cos(pi*chinasea$dir/180), "cm")
y1 <- unit(chinasea$long, "native") -
   unit(0.5*length*sin(pi*chinasea$dir/180), "cm")
x2 <- unit(chinasea$lat, "native") +
   unit(0.5*length*cos(pi*chinasea$dir/180), "cm")
y2 <- unit(chinasea$long, "native") +
   unit(0.5*length*sin(pi*chinasea$dir/180), "cm")
grid.arrows(grob=grid.segments(x1, y1, x2, y2),
             length=unit(3, "mm"))

pop.viewport(3)


... This modification still requires gridBase;  the same effect could be 
achieved with the base arrows() function, i.e., without gridBase, with a 
little more effort required to calculate the "x" and "y" values for the 
arrows.

You might also want to take a look at 
http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html
which gives an overview of the packages related to spatial statistics 
that are available for R.  Somebody may have already done all the work 
for you :)

Paul


> Laura Quinn wrote:
> 
>> I sent a mail last week asking for some advise in relation to displaying
>> wind vectors on a contour map of a region. Whilst I have had some useful
>> feedback relating to the second part of this question (namely how to
>> animate a time series of still frames), I haven't recieved any advise on
>> how I might create the still images of the spatially distributed wind
>> vector data at any given time point.
>>
>> Firstly, is there a way in which I can input orographical information
>> (x,y,z co ords) into R to create a map, secondly, is there a way in which
>> i can superimpose a visual wind vector (i.e. arrow of certain length and
>> certain orientation) onto such a map?
>>
>> thanks in advance,
>> Laura
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From itstruei at rock.com  Mon Nov  3 23:20:17 2003
From: itstruei at rock.com (itstruei@rock.com)
Date: 3 Nov 2003 22:20:17 -0000
Subject: [R] ROC with GLM?
Message-ID: <23345801c3a258$a95222e0$4701020a@corp.load.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031103/465471ba/attachment.pl

From apv at capital.net  Mon Nov  3 23:28:22 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 03 Nov 2003 17:28:22 -0500
Subject: [R] Generic Function
Message-ID: <1067898502.27925.7.camel@redtail.mydomain.home>

Hi,

How to I write a generate function that is "specific to the class of the
argument itself" ?  

For example, I created a data.frame that contains results of an
analysis.  I would like to write a special plot function with the
following usage

plot(data.frame)

I have been looking through the documentation but have not found
anything to show me how to do this.  Any help would be greatly
appreciated.

Thanks in advance,

Arend van der Veen



From ecalvo at houston.rr.com  Mon Nov  3 23:37:33 2003
From: ecalvo at houston.rr.com (Ernesto Calvo)
Date: Mon, 3 Nov 2003 16:37:33 -0600
Subject: [R] inquire
Message-ID: <004901c3a25b$12fefbd0$7f5ca718@your196pm56p6g>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031103/dc639187/attachment.pl

From arnab at myrealbox.com  Tue Nov  4 01:10:16 2003
From: arnab at myrealbox.com (Arnab mukherji)
Date: Tue, 04 Nov 2003 00:10:16 +0000
Subject: [R] write.dta and handling labels
Message-ID: <1067904616.cdd92f40arnab@myrealbox.com>

Hello,

 I need to write out a data matrix as a STATA 7 file and this happens perfectly with write.dta(), except I cannot seem to export the labelnames to Stata. 

 So far I have tried the following:
# X is the data matrix that is to be exported
attributes(X)$var.labels <- c("apple", "banana", "cat")
write(X, filename = "text.dta", version = 7)

When i open the file in stata instead of the label names all I get are the variable names, when i ask stata to "describe" the data.

I am hoping someone can suggest ways in which i can export the label names more effectively!

thanks.

Arnab


-------------
Ph.D. Candidate
RAND Graduate School 
Santa Monica



From spencer.graves at pdf.com  Tue Nov  4 01:24:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 03 Nov 2003 16:24:12 -0800
Subject: [R] write.dta and handling labels
In-Reply-To: <1067904616.cdd92f40arnab@myrealbox.com>
References: <1067904616.cdd92f40arnab@myrealbox.com>
Message-ID: <3FA6F1AC.8030902@pdf.com>

Have you considered "write.table"? 

hope this helps.  spencer graves

Arnab mukherji wrote:

>Hello,
>
> I need to write out a data matrix as a STATA 7 file and this happens perfectly with write.dta(), except I cannot seem to export the labelnames to Stata. 
>
> So far I have tried the following:
># X is the data matrix that is to be exported
>attributes(X)$var.labels <- c("apple", "banana", "cat")
>write(X, filename = "text.dta", version = 7)
>
>When i open the file in stata instead of the label names all I get are the variable names, when i ask stata to "describe" the data.
>
>I am hoping someone can suggest ways in which i can export the label names more effectively!
>
>thanks.
>
>Arnab
>
>
>-------------
>Ph.D. Candidate
>RAND Graduate School 
>Santa Monica
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From ggrothendieck at myway.com  Tue Nov  4 02:04:29 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon,  3 Nov 2003 20:04:29 -0500 (EST)
Subject: [R] Generic Function
Message-ID: <20031104010429.E2632398D@mprdmxin.myway.com>


Here is a simple example using S3 classes.  We define a generic
function myday.  It dispaches, i.e. calls, a function whose name 
is myday followed by a dot followed by the class of the 
first argument to myday.   After defining myday, define two
functions for it to dispatch: myday.POSIXct and myday.numeric.

 
   # generic function
   myday <- function(x, ...) UseMethod("myday")

   # if first argument is of class POSIXct then UseMethod calls this:
   myday.POSIXct <- function(dat) as.POSIXlt(dat)$mday

   # if first argument is of class numeric then UseMethod calls this:
   myday.numeric <- function(x) x



   # Here is how it would be called:

   myday(20)       # causes myday.numeric to be dispached. Returns 20.
   myday(Sys.time()) # myday.POSIXct dispatched. Returns 3 on Nov 3rd.

   # We can also query what methods are available:

  methods(myday) # returns vector c("myday.POSIXct","myday.numeric")

--- 
Date: 03 Nov 2003 17:28:22 -0500 
From: Arend P. van der Veen <apv at capital.net>
To: <R-Help at stat.math.ethz.ch> 
Subject: [R] Generic Function 

 
 
Hi,

How to I write a generate function that is "specific to the class of the
argument itself" ? 

For example, I created a data.frame that contains results of an
analysis. I would like to write a special plot function with the
following usage

plot(data.frame)

I have been looking through the documentation but have not found
anything to show me how to do this. Any help would be greatly
appreciated.

Thanks in advance,

Arend van der Veen



_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From feh3k at spamcop.net  Tue Nov  4 03:13:04 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Mon, 3 Nov 2003 21:13:04 -0500
Subject: [R] ROC with GLM?
In-Reply-To: <23345801c3a258$a95222e0$4701020a@corp.load.com>
References: <23345801c3a258$a95222e0$4701020a@corp.load.com>
Message-ID: <20031103211304.4c7bca66.feh3k@spamcop.net>

On 3 Nov 2003 22:20:17 -0000
itstruei at rock.com wrote:

> Hello R-List:
>  
> Does anybody have code to optimize a logistic regression using ROC
> curves? I've seen S+ code that does it but never in R.
>  

ROC curves are something you might draw once a model is fitted (although I
believe they are overused) but not something you use in fitting the model.
 Logistic models are fitted using maximum likelihood estimation, penalized
maximum likelihood estimation, or Bayesian methods, for example.  Choose
an optimality criterion that yields efficient estimators.

If you are referring to after-fit ROC curves to find "optimum cutpoints"
there are many reasons not to do this either, as detailed in my book
Regression Modeling Strategies.  If you have a loss (utility) function you
can make optimum classifications without the use of ROC curves, but
optimizing classifications on the basis of ROC curves is usually an
exercise in concocting false utilities or in assuming that utilities are
constant across subjects.  My comments pertain to the type of prediction
problems I've seen in medical diagnosis and prognosis.  There may be other
areas in which strictly empirical classification is a more appropriate
endeavor.

---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From spencer.graves at pdf.com  Tue Nov  4 03:20:36 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 03 Nov 2003 18:20:36 -0800
Subject: [R] Using "_" in names? 
Message-ID: <3FA70CF4.7060102@pdf.com>

      I work with data bases that routinely use the underscore, "_", as 
part of names.  I've seen discussion on this list of possibly allowing 
that in a future release of R.  How far are we away from that? 

      I got the following from R 1.8.0 under Windows 2000: 

 > A_1
Error: syntax error
 > A_B <- 1
Error: syntax error
 > "A_B" <- 1
 > DF <- data.frame(A_B=1)
Error: syntax error
 > DF <- data.frame("A_B"=1)
 > DF
  A.B
1   1
 > names(DF) <- "A_B"
 > DF
  A_B
1   1
 > lm("A_B"~1, DF)
Error in terms.formula(formula, data = data) :
        invalid term in model formula
 
      Thanks for your help,
      Spencer Graves



From tlumley at u.washington.edu  Tue Nov  4 04:05:42 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 3 Nov 2003 19:05:42 -0800 (PST)
Subject: [R] write.dta and handling labels
In-Reply-To: <1067904616.cdd92f40arnab@myrealbox.com>
References: <1067904616.cdd92f40arnab@myrealbox.com>
Message-ID: <Pine.A41.4.58.0311031901380.96610@homer09.u.washington.edu>

On Tue, 4 Nov 2003, Arnab mukherji wrote:

> Hello,
>
>  I need to write out a data matrix as a STATA 7 file and this happens
> perfectly with write.dta(), except I cannot seem to export the
> labelnames to Stata.
>
>  So far I have tried the following:
> # X is the data matrix that is to be exported
> attributes(X)$var.labels <- c("apple", "banana", "cat")
> write(X, filename = "text.dta", version = 7)
>

It's not clear whether you want value labels or variable labels. Variable
labels don't get exported to stata, but factor levels do get exported as
value labels.

Eg

data(esoph)
write.dta(esoph, file="esoph.dta",version=7)

	-thomas



From tlumley at u.washington.edu  Tue Nov  4 04:07:21 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 3 Nov 2003 19:07:21 -0800 (PST)
Subject: [R] Using "_" in names? 
In-Reply-To: <3FA70CF4.7060102@pdf.com>
References: <3FA70CF4.7060102@pdf.com>
Message-ID: <Pine.A41.4.58.0311031907040.96610@homer09.u.washington.edu>

On Mon, 3 Nov 2003, Spencer Graves wrote:

>       I work with data bases that routinely use the underscore, "_", as
> part of names.  I've seen discussion on this list of possibly allowing
> that in a future release of R.  How far are we away from that?
>

About five months.

	-thomas



From ripley at stats.ox.ac.uk  Tue Nov  4 07:58:11 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Nov 2003 06:58:11 +0000 (GMT)
Subject: [R] inquire
In-Reply-To: <004901c3a25b$12fefbd0$7f5ca718@your196pm56p6g>
Message-ID: <Pine.LNX.4.44.0311040656580.19878-100000@gannet.stats>

You could compile it from the sources: there is a repository of the 
sources in the same CRAN area as the current sources.

Or you could correct your code.

On Mon, 3 Nov 2003, Ernesto Calvo wrote:

> I am looking for the binary rw1051. I have some code that will only run in version 1.5.1 and I need to install the old binary code. Is there a repository for previous R versions?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From an980634 at uni-greifswald.de  Tue Nov  4 10:11:23 2003
From: an980634 at uni-greifswald.de (Arne Neumann)
Date: Tue, 04 Nov 2003 10:11:23 +0100
Subject: [R]  hclust doesn't return merge details [Solved]
In-Reply-To: <200311040854.hA48seQ25808@mailgate5.cinetic.de>
Message-ID: <3FA77B4B.9993.3FA72A@localhost>

Thanks to Andy and Thomas,

Reading help(hclust) more carefully would have done it but sometimes you do not 
see the wood for the trees...
So hc$merge does exactly what I want.
I have never been aware of  the command str to get the structure of an R-object. It 
seems pretty useful to me.

Thanks,
Arne


> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Sent: Monday, November 03, 2003 7:10 PM
> To: 'Arne Neumann'; r-help at stat.math.ethz.ch
> Subject: RE: [R] hclust doesn't return merge details
> 
> 
> > From: Arne Neumann [mailto:an980634 at uni-greifswald.de]
> > 
> >  Dear R-users,
> > 
> > I tried to receive the merge details of a clustering by using the 
> > summary function of hclust. For illustration I use the Longley data as
> 
> > done by Prof Ripley (Wed 11 Apr 2001) d <-
> > dist(longley.y)
> > d <- d/max(d) 
> > hc <- hclust(d, "ave") 
> > 
> > But instead of getting a matrix for $merge I get:
> > >summary(hc)
> > 		Length Class  Mode     
> > merge       30     -none- numeric  
> > height      15     -none- numeric  
> > order       16     -none- numeric  
> > labels       0     -none- NULL     
> > method       1     -none- character
> > call         3     -none- call     
> > dist.method  1     -none- character
> > 
> > Am I missing something?
> 
> I believe so.
> 
> > str(hc)
> List of 7
>  $ merge      : int [1:15, 1:2] -6 -13 -10 -1 -9 -3 -5 -16 -12 8 ...
>  $ height     : num [1:15] 20.1 23.6 27.2 29.2 41.4 ...
>  $ order      : int [1:16] 1 2 3 4 16 13 14 12 15 5 ...
>  $ labels     : chr [1:16] "1947" "1948" "1949" "1950" ...
>  $ method     : chr "average"
>  $ call       : language hclust(d = dist(data.matrix(longley)), method =
> "ave")
>  $ dist.method: chr "euclidean"
>  - attr(*, "class")= chr "hclust"
> 
> so the "merge" component is a n x 2 matrix, whose mode is "numeric".
> 
> Andy
>



From gwiggner at lix.polytechnique.fr  Tue Nov  4 11:12:40 2003
From: gwiggner at lix.polytechnique.fr (Claus Gwiggner)
Date: 04 Nov 2003 11:12:40 +0100
Subject: [R] Binaries for ROracle and V 1.8. needed
Message-ID: <1067940760.3081.18.camel@claus.lapcpgwiggn>

Sorry for re-posting this message; the first one was lost in another
thread.

>Hi,
> there is no Oracle Client on my machine (Redhat Linux 9.0/686i, 
> R1.8.0). I cannot thus compile the ROracle package.

> I read the readme.client file and did: 
> I unziped the package ROracle and copied it into the R-library path.
> I get:
> >library(ROracle)
> Error in testRversion(descfields) : This package has not been
installed properly
> 
> 
> Who has a binary version of ROracle for my configuration?
> Is there another way to connect to an Oracle base?  
> 
> Thanks,
> Claus



From an980634 at uni-greifswald.de  Tue Nov  4 10:15:47 2003
From: an980634 at uni-greifswald.de (Arne Neumann)
Date: Tue, 04 Nov 2003 10:15:47 +0100
Subject: [R]  hclust doesn't return merge details [Solved]
Message-ID: <3FA77C53.22629.43AE5A@localhost>

Thanks to Andy and Thomas,

Reading help(hclust) more carefully would have done it but 
sometimes you do not 
see the wood for the trees...
So hc$merge does exactly what I want.
I have never been aware of  the command str to get the structure of 
an R-object. It 
seems pretty useful to me.

Thanks,
Arne


> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Sent: Monday, November 03, 2003 7:10 PM
> To: 'Arne Neumann'; r-help at stat.math.ethz.ch
> Subject: RE: [R] hclust doesn't return merge details
> 
> 
> > From: Arne Neumann [mailto:an980634 at uni-greifswald.de]
> > 
> >  Dear R-users,
> > 
> > I tried to receive the merge details of a clustering by using the 
> > summary function of hclust. For illustration I use the Longley data as
> 
> > done by Prof Ripley (Wed 11 Apr 2001) d <-
> > dist(longley.y)
> > d <- d/max(d) 
> > hc <- hclust(d, "ave") 
> > 
> > But instead of getting a matrix for $merge I get:
> > >summary(hc)
> > 		Length Class  Mode     
> > merge       30     -none- numeric  
> > height      15     -none- numeric  
> > order       16     -none- numeric  
> > labels       0     -none- NULL     
> > method       1     -none- character
> > call         3     -none- call     
> > dist.method  1     -none- character
> > 
> > Am I missing something?
> 
> I believe so.
> 
> > str(hc)
> List of 7
>  $ merge      : int [1:15, 1:2] -6 -13 -10 -1 -9 -3 -5 -16 -12 8 ...
>  $ height     : num [1:15] 20.1 23.6 27.2 29.2 41.4 ...
>  $ order      : int [1:16] 1 2 3 4 16 13 14 12 15 5 ...
>  $ labels     : chr [1:16] "1947" "1948" "1949" "1950" ...
>  $ method     : chr "average"
>  $ call       : language hclust(d = dist(data.matrix(longley)), method =
> "ave")
>  $ dist.method: chr "euclidean"
>  - attr(*, "class")= chr "hclust"
> 
> so the "merge" component is a n x 2 matrix, whose mode is "numeric".
> 
> Andy
>



From Nathalie.Peyrard at avignon.inra.fr  Tue Nov  4 10:19:00 2003
From: Nathalie.Peyrard at avignon.inra.fr (Peyrard Nathalie)
Date: Tue, 04 Nov 2003 10:19:00 +0100
Subject: [R] interfacing C into R and R packages
Message-ID: <3FA76F04.4020600@avignon.inra.fr>

Hi,

I would like to interface a C code into R. Is it possible to use in the C code, functions from a R package (for instance, to use pmvnorm within loops in the C code and to call the result in  a R function)?

Nathalie



From mros at autan.toulouse.inra.fr  Tue Nov  4 10:24:48 2003
From: mros at autan.toulouse.inra.fr (Mathieu Ros)
Date: Tue,  4 Nov 2003 10:24:48 +0100 (MET)
Subject: [R] problem building MS-Windows package under linux
In-Reply-To: <Pine.LNX.4.44.0311031925360.18254-100000@gannet.stats>
References: <16294.33559.414891.388411@autan.toulouse.inra.fr>
	<Pine.LNX.4.44.0311031925360.18254-100000@gannet.stats>
Message-ID: <16295.28569.8361.302315@autan.toulouse.inra.fr>

thanks to Paulo Justiniano, I saved an error but still can't build R
(make -k repeat the same error on each package) :

******************************************************************************
<snip>

---------- Making package base ------------
  adding build stamp to DESCRIPTION
  installing demos
  installing data files
  installing man source files
  installing indices
make[4]: *** [indices] Error 1
make[3]: *** [pkg-base] Error 2
make[2]: *** [rpackage] Error 2
make[2]: Leaving directory `/home/ros/RWORK/CROSSSOMP/WinR/R-1.8.0/src/gnuwin32'
******************************************************************************

any idea?

-- 
Mathieu Ros
Ph. D. student - "Canalizing selection using Bayesian models"
INRA - Fish Genetics Unit (Paris)/Cell Genetics Unit (Toulouse)
tel : (+0033)1 3465 3414 (FGU) / (+0033)5 6128 5305 (CGU)
mail : ros at diamant.jouy.inra.fr



From m.mader at gsf.de  Tue Nov  4 10:43:07 2003
From: m.mader at gsf.de (Michael Mader)
Date: Tue, 04 Nov 2003 10:43:07 +0100
Subject: [R] Binaries for ROracle and V 1.8. needed
References: <1067940760.3081.18.camel@claus.lapcpgwiggn>
Message-ID: <3FA774AB.2DC039F6@gsf.de>

Hi

Claus Gwiggner wrote:

> > there is no Oracle Client on my machine (Redhat Linux 9.0/686i,
> > R1.8.0). I cannot thus compile the ROracle package.

You can in principle: Copy libs and the tnsconfig from the Oracle server
manually (no fun, but at least for Ora8i I managed this in some 30 min).

> > Who has a binary version of ROracle for my configuration?

I don't think that this will help you (at least it will NOT be robust!)

> > Is there another way to connect to an Oracle base?

In principle yes, but this is clearly the recommended way.

Regards

Michael
-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-80937 Neuherberg
0049-89-3187-3576

La perfection est atteinte non quand il ne reste rien ? ajouter, mais
quand il ne reste rien ? enlever
	Antoine de Saint-Exup?ry



From kwan022 at stat.auckland.ac.nz  Tue Nov  4 11:02:58 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 4 Nov 2003 23:02:58 +1300 (NZDT)
Subject: [R] interfacing C into R and R packages
In-Reply-To: <3FA76F04.4020600@avignon.inra.fr>
Message-ID: <Pine.LNX.4.44.0311042302080.3153-100000@stat61.stat.auckland.ac.nz>

I think "Writing R Extensions" may help you with that...

On Tue, 4 Nov 2003, Peyrard Nathalie wrote:

> Date: Tue, 04 Nov 2003 10:19:00 +0100
> From: Peyrard Nathalie <Nathalie.Peyrard at avignon.inra.fr>
> To: r-help at stat.math.ethz.ch
> Subject: [R] interfacing C into R and R packages
> 
> Hi,
> 
> I would like to interface a C code into R. Is it possible to use in the C code, functions from a R package (for instance, to use pmvnorm within loops in the C code and to call the result in  a R function)?
> 
> Nathalie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

---------------------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From jtl at saxobank.com  Tue Nov  4 11:11:51 2003
From: jtl at saxobank.com (Jeffrey Todd Lins)
Date: Tue, 4 Nov 2003 11:11:51 +0100
Subject: [R] Error in edit.data.frame
Message-ID: <AD629BECFB921F4F920A53F3B93945DFE7C35B@mal2pro.mid.dom>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/26dd6f39/attachment.pl

From kurt.sys at UGent.be  Tue Nov  4 11:08:01 2003
From: kurt.sys at UGent.be (Kurt sys)
Date: Tue, 04 Nov 2003 11:08:01 +0100
Subject: [R] interfacing C into R and R packages
In-Reply-To: <3FA76F04.4020600@avignon.inra.fr>
References: <3FA76F04.4020600@avignon.inra.fr>
Message-ID: <3FA77A81.2050207@UGent.be>

Hello,

I'm not sure, but if I understand your question well, we have had such 
questions already plenty of times. I guess, Google/STFW/RTFM/writing R 
extensions. It's easy, it's well-explained, ...

Kurt.

Peyrard Nathalie wrote:

> Hi,
>
> I would like to interface a C code into R. Is it possible to use in 
> the C code, functions from a R package (for instance, to use pmvnorm 
> within loops in the C code and to call the result in  a R function)?
>
> Nathalie



From bernd.weiss at uni-koeln.de  Tue Nov  4 11:52:41 2003
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Tue, 04 Nov 2003 11:52:41 +0100
Subject: [R] line breaks in recode
Message-ID: <3FA79309.12667.4F115D@localhost>

Dear all,

it seems to be that 'recode' can't handle any line breaks in its code.

The following command causes no problem:

datameta$smpid.r <- 
recode(datameta$smpid,"c(101,25,167,45,75)=25;c(104,51)=51")

But if I type ...

datameta$smpid.r <-recode(datameta$smpid,
	"c(101,25,167,45,75)=25;
             c(104,51)=51")

... the result is a syntax error. 

TIA

Bernd
-- 
Bernd Weiss, M.A.
Universitaet zu Koeln / University of Cologne
Forschungsinstitut fuer Soziologie / Research Institute for Sociology
Greinstr. 2 / 50 939 Cologne / Germany
Phone: +49 221 / 470-4234
E-Mail: <bernd.weiss at uni-koeln.de>



From kjetil at entelnet.bo  Tue Nov  4 12:31:39 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Tue, 04 Nov 2003 07:31:39 -0400
Subject: [R] USA map
In-Reply-To: <OF5B668DFB.FC69315D-ON86256DD3.0073AD42-86256DD3.0073D035@mmm.com>
Message-ID: <3FA755DB.19673.4A66E@localhost>

On 3 Nov 2003 at 15:04, apjaworski at mmm.com wrote:

> 
> I believe in R you need
> 
> library(maps)
> 
> before using usa().  Of course, the library has to be installed first.
> 

Yes, I new that. When I did help.search("usa") I HAD maps
attached. It dosen't have any function usa(). R is more international 
minded:

> library(maps)
> usa()
Error: couldn't find function "usa"
> map('usa')
> 
map('china')
map('bolivia')

and so on also works!

Kjetil Halvorsen


> Cheers,
> 
> Andy
> 
> __________________________________
> Andy Jaworski
> Engineering Systems Technology Center
> 3M Center, 518-1-01
> St. Paul, MN 55144-1000
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
> 
> 
> |---------+-------------------------------->
> |         |           kjetil at entelnet.bo   |
> |         |           Sent by:             |
> |         |           r-help-bounces at stat.m|
> |         |           ath.ethz.ch          |
> |         |                                |
> |         |                                |
> |         |           11/03/2003 13:56     |
> |         |                                |
> |---------+-------------------------------->
>   >-----------------------------------------------------------------------------------------------------------------------------|
>   |                                                                                                                             |
>   |      To:       "R-list" <r-help at stat.math.ethz.ch>                                                                          |
>   |        Martin Wegmann <mailinglist2_wegmann at web.de>                                                                         |
>   |      cc:       "Owen, Jason" <wowen at richmond.edu>                                                                           |
>   |      Subject:  Re: [R] USA map                                                                                              |
>   >-----------------------------------------------------------------------------------------------------------------------------|
> 
> 
> 
> 
> On 3 Nov 2003 at 16:33, Martin Wegmann wrote:
> 
> > On Monday 03 November 2003 15:46, Owen, Jason wrote:
> > > R users,
> > >
> > > In S, there was a function called usa() that
> > > would draw the map of the United States, plus
> > > it had other options for graphics.  I have looked
> > > but I can't find the equivalent in R.  Is there one?
> > >Description
> >
> > I don't know the usa() function in S but usa() in R gives a map of the US
> 
> Where did you find that function? In rw1080 on windows XP I get:
> 
> > usa()
> Error: couldn't find function "usa"
> >
> 
> (and help.search("usa") does'nt give anything usefull)
> 
> Kjetil Halvorsen
> 
> >
> > that's the output of a "usa " search, perhaps that is what you are
> looking
> > for:
> >
> > cheers Martin
> >
> > P.S.: www.freegis.org -> GeoData is worth a look for more maps
> >
> > usa() {map}
> >
> >  This database produces a map of the United States mainland generated
> from US
> > Department of the Census data (see the reference).
> >
> >
> > Usage
> >
> > data(usaMapEnv)
> >
> > Format
> >
> >
> >  The data file is merely an assignment to a character string which
> specifies
> > the name of an environment variable which contains the base location of
> the
> > binary files used by the map drawing functions. This environment variable
> 
> > (R_MAP_DATA_DIR for the datasets in the maps package) is set at package
> load
> > time if it does not already exist. Hence setting the environment variable
> 
> > before loading the package can override the default location of the
> binary
> > datasets.
> >
> >
> > References
> >
> >
> >  Richard A. Becker, and Allan R. Wilks, "Maps in S", AT&T Bell
> Laboratories
> > Statistics Research Report [93.2], 1993.
> >
> >
> > Richard A. Becker, and Allan R. Wilks, "Constructing a Geographical
> Database",
> > AT&T Bell Laboratories Statistics Research Report [95.2], 1995.
> >
> >
> > US Department of Commerce, Census Bureau, County Boundary File, computer
> tape,
> > available from Customer Services, Bureau of the Census, Washingdon DC
> 20233.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> 
>



From ripley at stats.ox.ac.uk  Tue Nov  4 12:46:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Nov 2003 11:46:37 +0000 (GMT)
Subject: [R] Error in edit.data.frame
In-Reply-To: <AD629BECFB921F4F920A53F3B93945DFE7C35B@mal2pro.mid.dom>
Message-ID: <Pine.LNX.4.44.0311041140520.20491-100000@gannet.stats>

On Tue, 4 Nov 2003, Jeffrey Todd Lins wrote:

> 
> I recently attempted to read a .txt file using both read.table("
> ",header=TRUE)  and read.delim(" ",header=TRUE)  and received the
> following message

Not from those commands, though.

> Error in edit.data.frame(get(subx, envir = parent), ...) :
>         symbol print-name too long
> 
> I am able to also create a variable x<-read.delim (" ",header=TRUE ) ,
> but am unable to fix(x) because of the same errror
> 
> Error in edit.data.frame(get(subx, envir = parent), ...) :
>         symbol print-name too long
> 
> 
> I have read nearly identical files many times without problems - indeed,
> a subsequent, slightly different query of very similar data, formatted
> in same operation, did not give this error when read by R.
> 
> I suspect the error is the result of some overly long string somewhere,
> in a column header, since I do not encounter the error, when changing
> the command to header=FALSE.  However, I need the variable names, and I
> if there are restrictions on the length of these names, then I will need
> to know them so that they are made parameters for data entry in the
> original data source.

There is a limit of 256 on the length of a symbol.

> Do I just have to live with this or is there a fix of some kind?  

You could look at the names (names(x)) and come up with some sensible 
names.  You will be unable to do things like attach() on longer names 
anyway.

You really haven't given us enough information: there are three separate 
versions of the dataeditor, so which OS, which version of R and please 
give us an actual example?  Then we may be able to see if we can 
circumvent this.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Nov  4 12:50:38 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Nov 2003 11:50:38 +0000 (GMT)
Subject: [R] USA map
In-Reply-To: <3FA755DB.19673.4A66E@localhost>
Message-ID: <Pine.LNX.4.44.0311041150150.20491-100000@gannet.stats>

On Tue, 4 Nov 2003 kjetil at entelnet.bo wrote:

> On 3 Nov 2003 at 15:04, apjaworski at mmm.com wrote:
> 
> > 
> > I believe in R you need
> > 
> > library(maps)
> > 
> > before using usa().  Of course, the library has to be installed first.
> > 
> 
> Yes, I new that. When I did help.search("usa") I HAD maps
> attached. It dosen't have any function usa(). R is more international 
> minded:
> 
> > library(maps)
> > usa()
> Error: couldn't find function "usa"
> > map('usa')
> > 
> map('china')
> map('bolivia')
> 
> and so on also works!

You need library(mapdata) for those.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Nov  4 12:51:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Nov 2003 11:51:54 +0000 (GMT)
Subject: [R] line breaks in recode
In-Reply-To: <3FA79309.12667.4F115D@localhost>
Message-ID: <Pine.LNX.4.44.0311041151120.20491-100000@gannet.stats>

Nothing to do with recode: you cannot have line breaks inside quoted 
strings.

> "c(101,25,167,45,75)=25;
Error: syntax error
>              c(104,51)=51"
Error: syntax error


On Tue, 4 Nov 2003, Bernd Weiss wrote:

> Dear all,
> 
> it seems to be that 'recode' can't handle any line breaks in its code.
> 
> The following command causes no problem:
> 
> datameta$smpid.r <- 
> recode(datameta$smpid,"c(101,25,167,45,75)=25;c(104,51)=51")
> 
> But if I type ...
> 
> datameta$smpid.r <-recode(datameta$smpid,
> 	"c(101,25,167,45,75)=25;
>              c(104,51)=51")
> 
> ... the result is a syntax error. 
> 
> TIA
> 
> Bernd
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ucgamdo at ucl.ac.uk  Mon Nov  3 12:51:56 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Mon, 03 Nov 2003 11:51:56 +0000
Subject: [R] Re: C code in R
Message-ID: <3.0.5.32.20031103115156.007ead90@pop-server.ucl.ac.uk>

I strongly encourage you tho check this book:

The basics of S and S-Plus / Andreas Krause, Melvin Olson

It has a very detailed and easy to follow info on how to link C code with S
(which is nearly identical to R). The R documentation is certainly very
complete, but it is written for people that already has some good
knowledge. The book by Krause and Olson helped me a lot in writing some C
code for calculating fractals in R.

Hope this helps.



From jfox at mcmaster.ca  Tue Nov  4 13:34:10 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 04 Nov 2003 07:34:10 -0500
Subject: [R] line breaks in recode
In-Reply-To: <3FA79309.12667.4F115D@localhost>
Message-ID: <5.1.0.14.2.20031104072612.01fc0770@127.0.0.1>

Dear Bernd,

As Brian Ripley points out, the problem is that you can't break a quoted 
string over input lines.

It is nevertheless awkward that you have to provide the recode directives 
in one long line. I'll think about alternatives for the next version of the 
car package. One simple possibility would be to allow several strings, so 
that your example could be entered as

datameta$smpid.r <-recode(datameta$smpid,
         "c(101,25,167,45,75)=25",
              "c(104,51)=51")

It would also be nice to figure out a way to do this without using strings. 
The recode dialog in my Rcmdr package, which assembles a call to recode(), 
has a much nicer interface, but it's able to parse the input.

Thanks for the (implicit) suggestion.

John

At 11:52 AM 11/4/2003 +0100, Bernd Weiss wrote:
>Dear all,
>
>it seems to be that 'recode' can't handle any line breaks in its code.
>
>The following command causes no problem:
>
>datameta$smpid.r <-
>recode(datameta$smpid,"c(101,25,167,45,75)=25;c(104,51)=51")
>
>But if I type ...
>
>datameta$smpid.r <-recode(datameta$smpid,
>         "c(101,25,167,45,75)=25;
>              c(104,51)=51")
>
>... the result is a syntax error.
>
>TIA
>
>Bernd
>--




-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From Timur.Elzhov at jinr.ru  Tue Nov  4 15:04:43 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue, 4 Nov 2003 17:04:43 +0300
Subject: [R] lang2(...) with two and more arguments
In-Reply-To: <E1AH1cF-000GK7-00.elzhov-mail-ru@f25.mail.ru>
References: <x2llqxe8s2.fsf@biostat.ku.dk>
	<E1AH1cF-000GK7-00.elzhov-mail-ru@f25.mail.ru>
Message-ID: <20031104140443.GA3172@nf034.jinr.ru>

On Tue, Nov 03, 2003 at 17:06:37 +0100, you  wrote:

>>      REAL(x)[0] = 10;
>>      REAL(y)[0] = 20;
>>      SETCADR(R_fcall, x);
>>      SETCADR(R_fcall, y);
>>      ...
>>  .Call("f", c, new.env()) returns
>>  `.Primitive("c")(20)'
> Hmmm. This is definitely not right:
> 
>      SETCADR(R_fcall, x);
>      SETCADR(R_fcall, y);
> 
> sets the same location first to x, and then to y. I suspect you need 
> 
>      SETCADDR(R_fcall, y);
> 
> but no guarantees...
This returns message `bad value'.

Ok! the question is: How can I create a call with, say, 10
arguments? I mean C code, of course :)

Thanks.

--
WBR,
Timur.



From r_stuff_online at hotmail.com  Tue Nov  4 15:55:55 2003
From: r_stuff_online at hotmail.com (Neil Osborne)
Date: Tue, 04 Nov 2003 14:55:55 +0000
Subject: [R] R function help arranged in categorical order ?
Message-ID: <Law12-F73gS86aRZlz800007c0e@hotmail.com>

Hi,

I'm new to R and I'm finding it quite a chore trawling through the R 
documentation to find a function to carry out simple atomic tasks. Is any 
one aware of R help documentation that is aranged in functional categories 
for e.g.:

String manipulation
File I/O
Dataframe, List manipulation

etc, etc ...

Thanks

_________________________________________________________________
Get Hotmail on your mobile phone http://www.msn.co.uk/msnmobile



From rpeng at jhsph.edu  Tue Nov  4 16:06:55 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 04 Nov 2003 10:06:55 -0500
Subject: [R] R function help arranged in categorical order ?
In-Reply-To: <Law12-F73gS86aRZlz800007c0e@hotmail.com>
References: <Law12-F73gS86aRZlz800007c0e@hotmail.com>
Message-ID: <3FA7C08F.2010901@jhsph.edu>

That's usually what help.search() is for.  For example,

>  help.search("file", package = "base")

-roger

Neil Osborne wrote:

> Hi,
>
> I'm new to R and I'm finding it quite a chore trawling through the R 
> documentation to find a function to carry out simple atomic tasks. Is 
> any one aware of R help documentation that is aranged in functional 
> categories for e.g.:
>
> String manipulation
> File I/O
> Dataframe, List manipulation
>
> etc, etc ...
>
> Thanks
>
> _________________________________________________________________
> Get Hotmail on your mobile phone http://www.msn.co.uk/msnmobile
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From krcabrer at unalmed.edu.co  Tue Nov  4 16:27:02 2003
From: krcabrer at unalmed.edu.co (Kenneth Cabrera)
Date: Tue, 04 Nov 2003 10:27:02 -0500
Subject: [R] Handling memory
Message-ID: <oprx4c7camfaouaq@200.24.8.4>

Dear R-Users:

Which is the best way to fee memory inside a function to
make room for some other process that uses most of the
RAM available and latter retrive this data again to
finish the function?

Thank you very much for your help

Kenneth Cabrera

--



From bates at stat.wisc.edu  Tue Nov  4 16:28:33 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Nov 2003 09:28:33 -0600
Subject: [R] lang2(...) with two and more arguments
In-Reply-To: <20031104140443.GA3172@nf034.jinr.ru>
References: <x2llqxe8s2.fsf@biostat.ku.dk>
	<E1AH1cF-000GK7-00.elzhov-mail-ru@f25.mail.ru>
	<20031104140443.GA3172@nf034.jinr.ru>
Message-ID: <6r7k2gxie6.fsf@bates4.stat.wisc.edu>

Timur Elzhov <Timur.Elzhov at jinr.ru> writes:

> On Tue, Nov 03, 2003 at 17:06:37 +0100, you  wrote:
> 
> >>      REAL(x)[0] = 10;
> >>      REAL(y)[0] = 20;
> >>      SETCADR(R_fcall, x);
> >>      SETCADR(R_fcall, y);
> >>      ...
> >>  .Call("f", c, new.env()) returns
> >>  `.Primitive("c")(20)'
> > Hmmm. This is definitely not right:
> > 
> >      SETCADR(R_fcall, x);
> >      SETCADR(R_fcall, y);
> > 
> > sets the same location first to x, and then to y. I suspect you need 
> > 
> >      SETCADDR(R_fcall, y);
> > 
> > but no guarantees...
> This returns message `bad value'.
> 
> Ok! the question is: How can I create a call with, say, 10
> arguments? I mean C code, of course :)

Better look at your example more closely.  lang2 is used to create a
function call with *one* argument.  lang2 itself takes two arguments:
the name (i.e. an SEXP of type name) of the function and an SEXP to
the argument.

You create a function call of two arguments with lang3 and a function
call of three arguments with lang4.  After that I think you have to
cons up a (lisp-like) list yourself.

This discussion probably belongs on r-devel not r-help.



From bill.shipley at usherbrooke.ca  Tue Nov  4 16:42:45 2003
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Tue, 4 Nov 2003 10:42:45 -0500
Subject: [R] help with lme()
Message-ID: <02be01c3a2ea$4b0aecc0$8d1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/80303ec5/attachment.pl

From H.RINNER at tirol.gv.at  Tue Nov  4 17:12:40 2003
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Tue, 4 Nov 2003 17:12:40 +0100 
Subject: AW: [R] R function help arranged in categorical order ?
Message-ID: <C4D44AB4CB62D311BA6500041202E886031EE32F@xms1.tirol.gv.at>

There is a very nice Search Engine, with Keywords arranged by topic, that
comes with R.
If you are under Windows (and have Html help installed), you can find this
in the Help menu, under "Html help".
(The relevant file can also be found as
...\doc\html\search\SearchEngine.html.)

Maybe this helps,
Heinrich.

> -----Urspr?ngliche Nachricht-----
> Von: Neil Osborne [mailto:r_stuff_online at hotmail.com] 
> Gesendet: Dienstag, 04. November 2003 15:56
> An: r-help at stat.math.ethz.ch
> Betreff: [R] R function help arranged in categorical order ?
> 
> 
> Hi,
> 
> I'm new to R and I'm finding it quite a chore trawling through the R 
> documentation to find a function to carry out simple atomic 
> tasks. Is any 
> one aware of R help documentation that is aranged in 
> functional categories 
> for e.g.:
> 
> String manipulation
> File I/O
> Dataframe, List manipulation
> 
> etc, etc ...
> 
> Thanks
> 
> _________________________________________________________________
> Get Hotmail on your mobile phone http://www.msn.co.uk/msnmobile
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From vito.muggeo at giustizia.it  Tue Nov  4 17:21:19 2003
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Tue, 4 Nov 2003 17:21:19 +0100
Subject: R: [R] help with lme()
References: <02be01c3a2ea$4b0aecc0$8d1ad284@BIO041>
Message-ID: <023501c3a2ef$b180d640$5c13070a@PROCGEN>

Dear Bill,
I am not a lme-expert, but I believe the Pinheiro&Bates' book is rather
clear here.

However you know that a lme model is, for instance

fixed= y~x1+x2 and random=y~x1|group

and you can fit it by ML or REML.

If you are interested in testing for x2 by means the LRT (namely by
comparing the models with and without x2) you have to fit them by  ML.

hope this helps,
best,
vito



----- Original Message -----
From: Bill Shipley <bill.shipley at usherbrooke.ca>
To: R help list <r-help at stat.math.ethz.ch>
Sent: Tuesday, November 04, 2003 4:42 PM
Subject: [R] help with lme()


Hello. I am trying to determine whether I should be using ML or REML
methods to estimate a linear mixed model.   In the book by Pinheiro &
Bates (Mixed-effects models in S and S-PLUS, page 76) they state that
one difference between REML and ML is that ? LME models with different
fixed-effects structures fit using REML cannot be compared on the basis
of their restricted likelihoods.  In particular, likelihood ratio tests
are not valid under these circumstances."

I am not sure what "fixed-effects structures" means.  Does it mean that,
as long as the types of contrasts are the same between two models, they
ARE comparable, but are NOT comparable if the types of contrasts are
changes?  Or rather, does it simply mean that one should use t or F
tests for the fixed effects, and restrict the likelihood ratio tests to
the random effects only if using REML?



Bill Shipley

Associate Editor, Ecology

North American Editor, Annals of Botany

D?partement de biologie, Universit? de Sherbrooke,

Sherbrooke (Qu?bec) J1K 2R1 CANADA

Bill.Shipley at USherbrooke.ca

 <http://callisto.si.usherb.ca:8080/bshipley/>
http://callisto.si.usherb.ca:8080/bshipley/




[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Tue Nov  4 17:23:50 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 4 Nov 2003 11:23:50 -0500 (EST)
Subject: AW: [R] R function help arranged in categorical order ?
In-Reply-To: <C4D44AB4CB62D311BA6500041202E886031EE32F@xms1.tirol.gv.at>
References: <C4D44AB4CB62D311BA6500041202E886031EE32F@xms1.tirol.gv.at>
Message-ID: <Pine.SOL.4.58.0311041120100.18888@millipede.gpcc.itd.umich.edu>

Neil  -

Maybe also the "Function and variable index", pages 94-96, and
the "Concept index", pages 97-98 in "An Introduction to R",
	cran.r-project.org/doc/manuals/R-intro.pdf.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 4 Nov 2003, RINNER Heinrich wrote:

> There is a very nice Search Engine, with Keywords arranged by topic, that
> comes with R.
> If you are under Windows (and have Html help installed), you can find this
> in the Help menu, under "Html help".
> (The relevant file can also be found as
> ...\doc\html\search\SearchEngine.html.)
>
> Maybe this helps,
> Heinrich.
>
> > -----Urspr?ngliche Nachricht-----
> > Von: Neil Osborne [mailto:r_stuff_online at hotmail.com]
> > Gesendet: Dienstag, 04. November 2003 15:56
> > An: r-help at stat.math.ethz.ch
> > Betreff: [R] R function help arranged in categorical order ?
> >
> > I'm new to R and I'm finding it quite a chore trawling through the R
> > documentation to find a function to carry out simple atomic
> > tasks. Is any
> > one aware of R help documentation that is aranged in
> > functional categories
> > for e.g.:
> >
> > String manipulation
> > File I/O
> > Dataframe, List manipulation
> >
> > etc, etc ...
> >
> > Thanks
> >



From corvin3 at verizon.net  Tue Nov  4 17:36:29 2003
From: corvin3 at verizon.net (DAWN CORVIN)
Date: Tue, 4 Nov 2003 10:36:29 -0600
Subject: Fw: [R] Cigarettes $20.95 per carton S/H 
Message-ID: <003e01c3a2f1$d31ce490$df4b3e04@p424ghz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/82d79f01/attachment.pl

From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Nov  4 16:15:45 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 4 Nov 2003 16:15:45 +0100 (CET)
Subject: [R] interfacing C into R and R packages
In-Reply-To: <3FA76F04.4020600@avignon.inra.fr>
References: <3FA76F04.4020600@avignon.inra.fr>
Message-ID: <Pine.LNX.4.51.0311041603510.25032@artemis.imbe.med.uni-erlangen.de>


> Hi,
>
> I would like to interface a C code into R. Is it possible to use in the C code, functions from a R package (for instance, to use pmvnorm within loops in the C code and to call the result in  a R function)?

Probably the most easiest way is copying the C-sources from the original
package (that's what GPL is about). In this special case you need to
(re)-write the R high level function `pmvnorm' in C and call the Fortran77
subroutine `MVTDST' from your C-code. However, keep in mind that `MVTDST'
requires significant time for non-trivial problems and you should make
sure that re-coding the interface in C is worth the effort: Note that you
can call R functions from C anyway (Section 4.9 of `Writing R
Extensions').

Best,

Torsten

>
> Nathalie
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From Markus.Koesters at uni-jena.de  Tue Nov  4 17:54:14 2003
From: Markus.Koesters at uni-jena.de (Markus Koesters)
Date: Tue, 04 Nov 2003 17:54:14 +0100
Subject: [R] Beginner: Homogenity of Variances
In-Reply-To: <3FA52472.1000805@yorku.ca>
References: <200311021106.hA2B6MPW006423@hypatia.math.ethz.ch>
Message-ID: <3FA7E7C6.6167.7DD441@localhost>


> >
> For independent samples there is a simple technique described by Larsen, 
> Am. Stat, May 1992
> for turning summary statistics back into a data set with an equivalent 
> ANOVA summary.
> 
> This is implemented and described in my STAT2DAT macro,
>  http://www.math.yorku.ca/SCS/sasmac/stat2dat.html
> 
> It should be easy to translate into R.

This is an interesting way - but most software packages test 
homogeneity of variances with the Levene Test. This can't work in 
this way, becas eit uses the median for calculation of the test 
statistics.
But the real problem are the dependent measures...

Markus







> 
> -- 
> Michael Friendly     Email: friendly at yorku.ca 
> Professor, Psychology Dept.
> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From stephane.dray at umontreal.ca  Tue Nov  4 19:14:15 2003
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Tue, 04 Nov 2003 13:14:15 -0500
Subject: [R] real eigenvectors
Message-ID: <5.2.1.1.0.20031104130751.00b43778@magellan.umontreal.ca>

Hello list,

Sorry, these questions are not directly linked to R.

If I consider an indefinte real matrix, I would like to know if the 
symmetry of the matrix is sufficient to say that their eigenvectors are real ?
And what is the conditions to ensure that eigenvectors are real in the case 
of an asymmetric matrix (if some conditions exist)?

Thanks in Advance,
St?phane DRAY
-------------------------------------------------------------------------------------------------- 

D?partement des Sciences Biologiques
Universit? de Montr?al, C.P. 6128, succursale centre-ville
Montr?al, Qu?bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From ray at mcs.vuw.ac.nz  Tue Nov  4 20:21:47 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Wed, 5 Nov 2003 08:21:47 +1300 (NZDT)
Subject: [R] USA map
Message-ID: <200311041921.hA4JLlso014885@tahi.mcs.vuw.ac.nz>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> 
> On Tue, 4 Nov 2003 kjetil at entelnet.bo wrote:
> 
> > On 3 Nov 2003 at 15:04, apjaworski at mmm.com wrote:
> > 
> > > 
> > > I believe in R you need
> > > 
> > > library(maps)
> > > 
> > > before using usa().  Of course, the library has to be installed first.
> > > 
> > 
> > Yes, I new that. When I did help.search("usa") I HAD maps
> > attached. It dosen't have any function usa(). R is more international 
> > minded:
> > 
> > > library(maps)
> > > usa()
> > Error: couldn't find function "usa"
> > > map('usa')
> > > 
> > map('china')
> > map('bolivia')
> > 
> > and so on also works!
> 
> You need library(mapdata) for those.
> 
Except the Bolivia map must be a local one (from kjetil at entelnet.bo?);
it is not in library(mapdata).

Ray Brownrigg



From RBaskin at ahrq.gov  Tue Nov  4 20:40:31 2003
From: RBaskin at ahrq.gov (RBaskin@ahrq.gov)
Date: Tue, 4 Nov 2003 14:40:31 -0500 
Subject: [R] real eigenvectors
Message-ID: <3598558AD728D41183350008C7CF291C0F16B995@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/c35a4bcb/attachment.pl

From stephane.dray at umontreal.ca  Tue Nov  4 21:42:01 2003
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Tue, 04 Nov 2003 15:42:01 -0500
Subject: [R] real eigenvectors
In-Reply-To: <3598558AD728D41183350008C7CF291C0F16B995@exchange1.ahrq.go
 v>
Message-ID: <5.2.1.1.0.20031104153104.00b803d0@magellan.umontreal.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/98bdb237/attachment.pl

From ross at biostat.ucsf.edu  Tue Nov  4 21:57:14 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 04 Nov 2003 12:57:14 -0800
Subject: [R] Architecting an optimization with external calls
Message-ID: <1067979434.26108.38.camel@iron.libaux.ucsf.edu>

I have a likelihood I would like to compute using C++ and then
optimize.  It has data that need to persist across individual calls to
the likelihood.  I'd appreciate any recommendations about the best way
to do this.  There are several, related issues.

1. Use the R optimizer or a C optimizer?
Because of the persistence problems (see below), using a C optimizer has
a certain attraction.  However, the C methods described in 5.8 of the
"Writing R Extensions" include the caveat that "No function is provided
for finite-differencing, nor for approximating the Hessian at the
result."  That's a big drawback, since I need that information. 
(Probably I will be doing this without analytic derivatives.)

2. How to persist the data?
I think my preferred approach would be to pass data back to R (assuming
the "optimize with R" approach above), and then pass it on to subsequent
calls.  The data would be the top of an object graph (i.e., there are
pointers to disconnected chunks of memory) and it is not clear to me how
to do this.  First, the documentation doesn't indicate any "opaque" data
type; should I use character (STRXP)?  Second, I'm not sure how to
protect it and the other chunks of memory.  Does each one need to go
inside a PROTECT call?  And is it safe to have one invocation from R do
PROTECT, and another much later one do UNPROTECT (all the examples I saw
had both calls within the same function invocation).

My hope is that if I allocate an object outside of R and don't tell R
about it, R will never touch it.  So I only need PROTECT for something
going back to R.  True?

Also, the docs say not to protect too many items; there may be a lot. 
So I'd probably end up having to write my own alloc out of pools that
were protected, and that's just another layer of junk in terms of the
original problem.

Another approach would be to just hang the data somewhere in the global
space of the shared library.  On general principles this is a poor
approach ("don't use globals"), manifest in specific failings such as
lack of thread safety.  I also suspect the issues with getting that to
work portably are probably considerable (as in, it may not be possible).

P.S. The example of Zero-finding (4.9.1 in "Writing R Extensions") is,
unfortunately, the reverse of this case.  In the example, the function
to be optimized is in R, while the optimizer is in C.
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From ripley at stats.ox.ac.uk  Tue Nov  4 22:12:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Nov 2003 21:12:56 +0000 (GMT)
Subject: [R] Architecting an optimization with external calls
In-Reply-To: <1067979434.26108.38.camel@iron.libaux.ucsf.edu>
Message-ID: <Pine.LNX.4.44.0311042112180.20905-100000@gannet.stats>

Look into external pointers.  That is how we have tackled this, e.g. in 
the ts package.

On Tue, 4 Nov 2003, Ross Boylan wrote:

> I have a likelihood I would like to compute using C++ and then
> optimize.  It has data that need to persist across individual calls to
> the likelihood.  I'd appreciate any recommendations about the best way
> to do this.  There are several, related issues.
> 
> 1. Use the R optimizer or a C optimizer?
> Because of the persistence problems (see below), using a C optimizer has
> a certain attraction.  However, the C methods described in 5.8 of the
> "Writing R Extensions" include the caveat that "No function is provided
> for finite-differencing, nor for approximating the Hessian at the
> result."  That's a big drawback, since I need that information. 
> (Probably I will be doing this without analytic derivatives.)
> 
> 2. How to persist the data?
> I think my preferred approach would be to pass data back to R (assuming
> the "optimize with R" approach above), and then pass it on to subsequent
> calls.  The data would be the top of an object graph (i.e., there are
> pointers to disconnected chunks of memory) and it is not clear to me how
> to do this.  First, the documentation doesn't indicate any "opaque" data
> type; should I use character (STRXP)?  Second, I'm not sure how to
> protect it and the other chunks of memory.  Does each one need to go
> inside a PROTECT call?  And is it safe to have one invocation from R do
> PROTECT, and another much later one do UNPROTECT (all the examples I saw
> had both calls within the same function invocation).
> 
> My hope is that if I allocate an object outside of R and don't tell R
> about it, R will never touch it.  So I only need PROTECT for something
> going back to R.  True?
> 
> Also, the docs say not to protect too many items; there may be a lot. 
> So I'd probably end up having to write my own alloc out of pools that
> were protected, and that's just another layer of junk in terms of the
> original problem.
> 
> Another approach would be to just hang the data somewhere in the global
> space of the shared library.  On general principles this is a poor
> approach ("don't use globals"), manifest in specific failings such as
> lack of thread safety.  I also suspect the issues with getting that to
> work portably are probably considerable (as in, it may not be possible).
> 
> P.S. The example of Zero-finding (4.9.1 in "Writing R Extensions") is,
> unfortunately, the reverse of this case.  In the example, the function
> to be optimized is in R, while the optimizer is in C.
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From KKelley at nd.edu  Tue Nov  4 22:38:01 2003
From: KKelley at nd.edu (Ken Kelley)
Date: Tue, 04 Nov 2003 16:38:01 -0500
Subject: [R] Ignoring Errors in Simulations
Message-ID: <5.1.0.14.2.20031104160443.00c39af0@imap-k.nd.edu>

Hello all.

I'm doing a large scale simulation study and every so often I get an error 
that stops the simulation. I would like to ignore the errors and identify 
the particular iterations where they occurred. I have tried:

options(error = expression(NULL))

which I thought would ignore the error, but the simulation is still stopped 
when an error occurs. I do not think try() is a good idea because of the 
significant computational time (that I think) it would add.


Specifically I am using factanal() from the mva library and the error is:

Error in factanal(Data, factors = 1, rotation = "none") :
         Unable to optimize from these starting value(s)

Although I increasing the number of starting values attempted would 
(presumably) help reduce the number or errors, I'm looking for a way that 
they are ignored and these (likely) untrustworthy results identified.

Thanks for any thoughts,
Ken



From bates at stat.wisc.edu  Tue Nov  4 23:13:52 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Nov 2003 16:13:52 -0600
Subject: [R] help with lme()
In-Reply-To: <02be01c3a2ea$4b0aecc0$8d1ad284@BIO041>
References: <02be01c3a2ea$4b0aecc0$8d1ad284@BIO041>
Message-ID: <6r1xsnvl37.fsf@bates4.stat.wisc.edu>

"Bill Shipley" <bill.shipley at usherbrooke.ca> writes:

> Hello. I am trying to determine whether I should be using ML or REML
> methods to estimate a linear mixed model.   In the book by Pinheiro &
> Bates (Mixed-effects models in S and S-PLUS, page 76) they state that
> one difference between REML and ML is that "LME models with different
> fixed-effects structures fit using REML cannot be compared on the basis
> of their restricted likelihoods.  In particular, likelihood ratio tests
> are not valid under these circumstances."
> 
> I am not sure what "fixed-effects structures" means.  Does it mean
> that, as long as the types of contrasts are the same between two
> models, they ARE comparable, but are NOT comparable if the types of
> contrasts are changes?  

It means that you would need exactly the same model matrix for the
fixed effects in the two fitted models being compared.  That is, you
need the same terms and the same contrasts.

In the REML criterion there is a term involving the determinant of a
matrix derived from the fixed-effects model matrix.  If you change
anything about the model matrix (except possibly for the order of the
columns) you will change this determinant and induce a systematic
change in the "log-likelihood" (actually the
log-restricted-likelihood) that is not based on the quality of the
fit.  With REML you could fit exactly the same model under two
different parameterizations of the fixed effects and get different
"log-likelihoods".  It would be meaningless to conduct a likelihood
ratio test in such circumstances.

It is possible to obtain fits based on REML but then compare
log-likelihoods, not log-restricted-likelihoods.  Greg Reinsel has
done some work on this, with favorable results.  It is a bit curious
because you don't use the criterion that you actually optimize but it
is effective.  My memory is a bit foggy on the details and I don't
have time to grep through the code right now but I think that this may
be what is done in the anova method for lme models.

> Or rather, does it simply mean that one should use t or F tests for
> the fixed effects, and restrict the likelihood ratio tests to the
> random effects only if using REML?

I think I would agree although it is not clear to me how to parse the
last part of that sentence.  If it could be rewritten as

"... does it simply mean that, if using REML, one should ... to the
random effects only." 

then I agree.



From kjetil at entelnet.bo  Tue Nov  4 23:31:41 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Tue, 04 Nov 2003 18:31:41 -0400
Subject: [R] real eigenvectors
In-Reply-To: <5.2.1.1.0.20031104130751.00b43778@magellan.umontreal.ca>
Message-ID: <3FA7F08D.5549.53C659@localhost>

On 4 Nov 2003 at 13:14, Stephane DRAY wrote:

That the matrix is symmetric is sufficient to guarantee real 
eigenvalues (proof is easy). I don't know about any general 
conditions for asymmetric matrices, and doubt there are. 

But in many structured situation you could be able to show similarity 
with a symmetric matrix, which suffices. Also note that symmetry 
doesn't need to be "visual" symmetry, it is enogh with symmetry
with respect to an inner product.

An example: Let A, B symmetric with B invertible . 
Then B^{-1}A has real eigenvalues, since it is similar to a symmetric 
matrix. 

Kjetil Halvorsen

> Hello list,
> 
> Sorry, these questions are not directly linked to R.
> 
> If I consider an indefinte real matrix, I would like to know if the 
> symmetry of the matrix is sufficient to say that their eigenvectors are real ?
> And what is the conditions to ensure that eigenvectors are real in the case 
> of an asymmetric matrix (if some conditions exist)?
> 
> Thanks in Advance,
> St?phane DRAY
> -------------------------------------------------------------------------------------------------- 
> 
> D?partement des Sciences Biologiques
> Universit? de Montr?al, C.P. 6128, succursale centre-ville
> Montr?al, Qu?bec H3C 3J7, Canada
> 
> Tel : 514 343 6111 poste 1233
> E-mail : stephane.dray at umontreal.ca
> -------------------------------------------------------------------------------------------------- 
> 
> Web                                          http://www.steph280.freesurf.fr/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Tue Nov  4 23:31:41 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Tue, 04 Nov 2003 18:31:41 -0400
Subject: [R] USA map
In-Reply-To: <200311041921.hA4JLlso014885@tahi.mcs.vuw.ac.nz>
Message-ID: <3FA7F08D.31300.53C763@localhost>

On 5 Nov 2003 at 8:21, Ray Brownrigg wrote:

> Except the Bolivia map must be a local one (from kjetil at entelnet.bo?);
> it is not in library(mapdata).
> 
> Ray Brownrigg

Sorry, I should have typed

> library(maps)
> library(mapdata)
> map("worldHires","bolivia")

   which indeed shows a correctly-looking map. 

I also tried

> map("worldHires","sweden")
> map("worldHires","denmark")  # which comes out very small since it  
                                               # includes the Faroe   
                                               # islands properly far-
                                                # away

> map("worldHires","andorra")
> map("worldHires","norway")  # which for some reason is smaller in   
                                           # the graphical window
                                           # than Andorra

but I cannot find any function to find the avalable region names in
a map database


Kjetil Halvorsen



From ray at mcs.vuw.ac.nz  Wed Nov  5 00:12:38 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Wed, 5 Nov 2003 12:12:38 +1300 (NZDT)
Subject: [R] USA map
Message-ID: <200311042312.hA4NCcTc017225@tahi.mcs.vuw.ac.nz>

> From kjetil at entelnet.bo Wed Nov  5 11:31:52 2003
> 
> but I cannot find any function to find the avalable region names in
> a map database
> 
They are in the .N file for the appropriate map.

Try:
library(maps)
data(worldMapEnv)
file.show(paste(Sys.getenv(worldMapEnv), "world.N", sep="/"))

These ASCII files are in the form:
region[:subregion] polygonNumber

Ray Brownrigg



From Paul.Sorenson at vision-bio.com  Wed Nov  5 00:15:03 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Wed, 5 Nov 2003 10:15:03 +1100
Subject: [R] more barplot presentation questions
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C62739C2@ewok.vsl.com.au>

Thanks to those who pointed me at the solutions to the legend overprinting the bars.  I took the "easy" way of rescaling the y axis, picking the scaling factor for stacked bars is somewhat problematic but sufficient for my application.

I have another couple of barplot questions:

	- Can I extend the major ticks on the Y axis across the page?  Or both axes to form a grid?

	- A really neat graph for me would be a combination of side-by-side and stacked bars in a single plot to display an additional category.

The background on the second problem is that I am displaying software defect metrics.  For each month (the bins) the categories of interest are:
	- new/fixed/closed
	- numeric severity (1 - 5)

I am currently displaying 5 separate graphs (6 when you take the aggregate into account) with new/fixed/closed side-by-side.  If within the side-by-side graphs I could show the severity stacked that would be very neat.

Cheers



From f0z6305 at labs.tamu.edu  Wed Nov  5 00:14:32 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue, 4 Nov 2003 17:14:32 -0600
Subject: [R] How to define a function to be smooth?
Message-ID: <001101c3a329$6a9bd510$d9bfa543@f0z6305>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/3fa0ac28/attachment.pl

From hodgess at gator.uhd.edu  Wed Nov  5 00:19:49 2003
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Tue, 4 Nov 2003 17:19:49 -0600
Subject: [R] Cointegration
Message-ID: <200311042319.hA4NJn908116@gator.dt.uh.edu>

Do any packages exist for cointegration, please?

Do we need them, if the answer to the previous is no, please?

Thanks,
Erin
mailto: hodgess at gator.uhd.edu



From tblackw at umich.edu  Wed Nov  5 00:21:23 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 4 Nov 2003 18:21:23 -0500 (EST)
Subject: [R] How to define a function to be smooth?
In-Reply-To: <001101c3a329$6a9bd510$d9bfa543@f0z6305>
References: <001101c3a329$6a9bd510$d9bfa543@f0z6305>
Message-ID: <Pine.SOL.4.58.0311041820540.15316@millipede.gpcc.itd.umich.edu>


Is this a homework assignment ?

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 4 Nov 2003, Feng Zhang wrote:

> Hey, R-listers
>
> When we say a function f(t) is smooth, does this mean that
> f has infinite differentials with respect to t?
>
> Or any other formal definition on this?
>
>
> Thanks for your points.
>
> Fred
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From r.darnell at uq.edu.au  Wed Nov  5 00:22:34 2003
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Wed, 05 Nov 2003 09:22:34 +1000
Subject: [R] help with nomogram function
Message-ID: <7k2fbtxh.fsf@uq.edu.au>

I have fitted a logistic regression model

> failed.lr2$call
lrm(formula = failed ~ Age + task2 + Age:task2, data = time.long, 
    na.action = na.omit)

using the Design package functions and would like to generate a
nomogram from this model.

the datadist information is generated and stored in

> ddist
                time.long$Age time.long$task2
Low:effect                 45            <NA>
Adjust to                  56       both.foam
High:effect                68            <NA>
Low:prediction             21       both.foam
High:prediction            80           right
Low                        20       both.foam
High                       80           right

Values:

time.long$task2 : both.foam left right 
> 

The model fitted and then when I try the nomgram function

> nomogram(failed.lr2)
Error in value.chk(at, i, NA, -nint, Limval, type.range = "full") : 
	variable Age does not have limits defined by datadist
> 

I get an error. The NA values in ddist seem to be the problem but I
don't understand the datadist information.

Can anyone help explain why this is failing.

Thanks

Ross Darnell

-- 

University of Queensland, Brisbane QLD 4067 AUSTRALIA
Email: <r.darnell at uq.edu.au>
Phone +61 7 3365 6087
http://www.shrs.uq.edu/shrs/school_staff/ross_darnell.html



From Wanzare at HCJP.com  Wed Nov  5 00:31:50 2003
From: Wanzare at HCJP.com (Manoj - Hachibushu Capital)
Date: Wed, 5 Nov 2003 08:31:50 +0900
Subject: [R] Cointegration
Message-ID: <1CBA12F2D414914989C723D196B287DC040498@jp-svr-ex1.HCJP.COM>

In tseries, look for ?adf.test & ?pp.test.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erin Hodgess
Sent: Wednesday, November 05, 2003 8:20 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Cointegration

Do any packages exist for cointegration, please?

Do we need them, if the answer to the previous is no, please?

Thanks,
Erin
mailto: hodgess at gator.uhd.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jawegelin at ucdavis.edu  Wed Nov  5 00:58:02 2003
From: jawegelin at ucdavis.edu (Jacob Wegelin)
Date: Tue, 4 Nov 2003 15:58:02 -0800 (PST)
Subject: [R] read.spss Error reading system-file header
Message-ID: <Pine.OSX.4.53.0311031612090.1210@biostat5.ucdavis.edu>


Is there any documentation on what kind of SPSS file can and cannot be
read by read.spss?  Alternatively, how can one modify or "clean" an SPSS
file to make it readable by read.spss?  What properties must a *.sav file
before read.spss can read it?

The file in this example is 270KB, with 5 rows and 173 columns.  I have no
trouble reading larger files with read.spss, so it's not merely a size
problem. I have no difficulty opening the file in SPSS.  I also have no
trouble getting read.spss to read a dummy SPSS file with 5 rows and 173
columns, where each entry was randomly sampled from c(letters, LETTERS).

> library("foreign")
> junk<-read.spss("indata/z2EXvideo.sav")
Error in read.spss("indata/z2EXvideo.sav") :
        Error reading system-file header.
In addition: Warning message:
indata/z2EXvideo.sav: File layout code has unexpected value 50331648.  Value should be 2, in big-endian or little-endian format.

Thanks for any information

Jake Wegelin

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    8.0
year     2003
month    10
day      08
language R



From tblackw at umich.edu  Wed Nov  5 01:06:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 4 Nov 2003 19:06:04 -0500 (EST)
Subject: [R] read.spss Error reading system-file header
In-Reply-To: <Pine.OSX.4.53.0311031612090.1210@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0311031612090.1210@biostat5.ucdavis.edu>
Message-ID: <Pine.SOL.4.58.0311041902400.15316@millipede.gpcc.itd.umich.edu>

Jake  -

The error message and warnign message shown below say something
is wrong with this file's SPSS system-file header.  If you are
really able to open this one in SPSS, do so, change maybe a
column name or row name or two, and save it again under a
different file name.  See if  read.spss() chokes on the new
version too.

Caution - I'm just guessing, here, but it's something to try.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 4 Nov 2003, Jacob Wegelin wrote:

>
> Is there any documentation on what kind of SPSS file can and cannot be
> read by read.spss?  Alternatively, how can one modify or "clean" an SPSS
> file to make it readable by read.spss?  What properties must a *.sav file
> before read.spss can read it?
>
> The file in this example is 270KB, with 5 rows and 173 columns.  I have no
> trouble reading larger files with read.spss, so it's not merely a size
> problem. I have no difficulty opening the file in SPSS.  I also have no
> trouble getting read.spss to read a dummy SPSS file with 5 rows and 173
> columns, where each entry was randomly sampled from c(letters, LETTERS).
>
> > library("foreign")
> > junk<-read.spss("indata/z2EXvideo.sav")
> Error in read.spss("indata/z2EXvideo.sav") :
>         Error reading system-file header.
> In addition: Warning message:
> indata/z2EXvideo.sav: File layout code has unexpected value 50331648.  Value should be 2, in big-endian or little-endian format.
>
> Thanks for any information
>
> Jake Wegelin
>
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    8.0
> year     2003
> month    10
> day      08
> language R
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jawegelin at ucdavis.edu  Wed Nov  5 01:16:32 2003
From: jawegelin at ucdavis.edu (Jacob Wegelin)
Date: Tue, 4 Nov 2003 16:16:32 -0800 (PST)
Subject: [R] Re: [S] LME - fixed effects model and missing values
In-Reply-To: <Pine.OSX.4.53.0311031517070.1210@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0311031517070.1210@biostat5.ucdavis.edu>
Message-ID: <Pine.OSX.4.53.0311031518000.1210@biostat5.ucdavis.edu>


Here is an answer to a 1999 post.  I didn't find a direct answer anywhere
on the Web, perhaps because it is "obvious"  once one sees it.

Suppose you have data from a longitudinal study, where each subject was
measured *up to* four times, with missing measurements, so that the data
look like this:

> MAT<- structure(c(23, 24, 6, 19, 16, 20, 13, 11, NA, 8, NA, 21, 19, 15,
11, NA, 10, 12, 16, 30, 13, 16, NA, NA, NA, NA, 28, 6), .Dim = c(7, 4),
.Dimnames = list(c("SUB1", "SUB2", "SUB3", "SUB4", "SUB5", "SUB6",
"SUB7"), c("BDI0", "BDI3", "BDI6", "BDI12")))

> MAT
     BDI0 BDI3 BDI6 BDI12
SUB1   23   11   11    16
SUB2   24   NA   NA    NA
SUB3    6    8   10    NA
SUB4   19   NA   12    NA
SUB5   16   21   16    NA
SUB6   20   19   30    28
SUB7   13   15   13     6

Let

> x<- c(0,3,6,12)

Then it's a simple matter to regress each row of MAT on x, in spite of
missing values.  Take for instance a row that has three missing values:

> lm(MAT["SUB2",] ~ x)

Call:
lm(formula = MAT["SUB2", ] ~ x)

Coefficients:
(Intercept)            x
         24           NA

But now suppose we want to fit a linear mixed-effects model, borrowing
strength from all the data in estimating each individual's intercept
and slope.

As in the naive lm approach, NAs are not a problem.  Unlike the naive lm
approach, however, we obtain values for slope and intercept even for
subjects for whom we cannot get slope via the lm approach, such as SUB2.

First, you must create a data frame with one row for each time point
within each subject, and you need to create a column to keep track of the
time variable.  For instance:

d<-data.frame(sub=I(rep("", length(MAT))), time=rep(NA, length(MAT)), BDI=rep(NA, length(MAT)) )

count<-0
for (i in 1:nrow(MAT)) for (j in 1:ncol(MAT)) {
	count<-count+1
	d[count, "sub"]<- dimnames(MAT) [[1]][i]
	d[count, "time"]<- c(0,3,6,12) [j]
	d[count, "BDI"]<- MAT[i,j]
	}

d$sub<-factor(d$sub)

Then you call lme, telling it to throw away rows with NAs in them.  Note
that this is *not* complete case analysis.  We are not throwing away
subjects (cases) who happen to have a missing BDI, just the time points
that have missing BDI.

> library("nlme")
> mymodel<-lme( BDI ~ time, random=~ 1 + time | sub, data=d, na.action=na.omit)
> mymodel
Linear mixed-effects model fit by REML
  Data: d
  Log-restricted-likelihood: -63.70296
  Fixed: BDI ~ time
(Intercept)        time
 16.8317095  -0.1449387

Random effects:
 Formula: ~1 + time | sub
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr
(Intercept) 3.5621406 (Intr)
time        0.4671455 0.886
Residual    4.1972943

Number of Observations: 21
Number of Groups: 7

We even get a slope for SUB2, for whom we have only one observation.

> mymodel$coef$random
$sub
     (Intercept)        time
SUB1  -0.4909769 -0.08181262
SUB2   3.0012854  0.34872811
SUB3  -4.5733486 -0.52161792
SUB4  -0.7908920 -0.13009388
SUB5   0.7516454  0.09528318
SUB6   4.4620873  0.61630713
SUB7  -2.3598006 -0.32679398


(Version: R 1.8.0 on Windows.)

This responds to the following email, which may be found at

http://www.biostat.wustl.edu/archives/html/s-news/1999-01/msg00122.html

Jake Wegelin

On Wed, 20 Jan 1999, ziv shkedy wrote:

>
> Dear Jose and all the other S+ users,
> First I want to thank you and Prof. Brian Ripley for your helpful answers.
>
> I'll described the missing values problem in more details.
> I'm modeling longitudinal data where each one of the subjects was measured
> at few time points.
> Some of the subjects dropout from the study, i.e. that the RESPONSE of these
> subjects is missing.
> The analysis in proc MIXED is likelihood based ignorable analysis (i.e. we
> using all available cases at each time point),
> in lme ,if i understood you correctly, if the response is missing then the
> observation is omitted from the dataset. This is a complete case analysis.
> My question is if there is a way to overcome this problem and to use all
> observation at each time point (and in that way the output from proc MIXED
> and lme will be the same).
>
> Now, I'm on my way to get the gls function.
> Thank you once again for your help, Ziv.
>
> =========================================================
> Ziv Shkedy
> Biostatistics
> Center for Statistics
> Limburgs Universitair Centrum
> Universitaire Campus, department WNI
> B-3590 Diepenbeek, Belgium
> Tel: +32-(0)11-26.82.57
> e-mail: ziv.shkedy at luc.ac.be
> =========================================================
>



From hiromoto at rand.org  Wed Nov  5 01:19:44 2003
From: hiromoto at rand.org (Hiromoto, Scott)
Date: Tue, 4 Nov 2003 16:19:44 -0800 
Subject: [R] objects inside curly braces
Message-ID: <FA56A73B8839AF4088504BA4EAFE444E06DEC1DE@smmail1.rand.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/b990b535/attachment.pl

From ivankautter at hotmail.com  Wed Nov  5 01:21:40 2003
From: ivankautter at hotmail.com (Ivan Kautter)
Date: Tue, 04 Nov 2003 16:21:40 -0800
Subject: [R] using LSODA in R
Message-ID: <BAY2-F1414lDPHpNwqe00001c38@hotmail.com>

R help list subscribers,

I am a new user of R.  I am attempting to use R to explore a set of 
equations specifying the dynamics of a three trophic level food chain.  I 
have put together this code for the function that is to be evaluted by 
LSODA.  My equations Rprime, Cprime, and Pprime are meant to describe the 
actual equation of the derivative.  When I run LSODA, I do not get the 
output that these equations should be giving.  Can someone tell me if I have 
set this function up correctly to use with LSODA when the user is specifying 
the equation of the derivative  or offer some advice for using LSODA in R? 
An example of how to code for user specified differential equations would be 
great.

function(times,y,p)
{
Rprime <- 
(R*(1-R))-((xc*yc*C*R)/(R+R0))-((w*xp*ypr*P*R)/(R02+((1-w)*C)+(w*R)))
Cprime <- 
(-1*(xc*C)*(1-(yc*R)/(R+R0)))-(((1-w)*xp*ypc*P*C)/((w*R)+((1-w)*C)+C0))
Pprime <- 
(-1*P)-(((1-w)*xp*ypc*C*P)/((w*R)+((1-w)*C)+C0))+((w*xp*ypr*P*R)/((w*R)+((1-w)*C)+R02))
list(c(Rprime, Cprime, Pprime))
}

The above is the function yprime which the documentation for the odesolve 
says that I may specify.

Thanks for any help that anyone can provide.

Ivan Kautter

_________________________________________________________________
Compare high-speed Internet plans, starting at $26.95.  
https://broadband.msn.com (Prices may vary by service area.)



From tblackw at umich.edu  Wed Nov  5 01:27:54 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 4 Nov 2003 19:27:54 -0500 (EST)
Subject: [R] read.spss Error reading system-file header
In-Reply-To: <Pine.OSX.4.53.0311041617190.1453@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0311031612090.1210@biostat5.ucdavis.edu>
	<Pine.SOL.4.58.0311041902400.15316@millipede.gpcc.itd.umich.edu>
	<Pine.OSX.4.53.0311041617190.1453@biostat5.ucdavis.edu>
Message-ID: <Pine.SOL.4.58.0311041920160.15316@millipede.gpcc.itd.umich.edu>

Jake  -

Very puzzling that a freshly-written copy of the file gives the
same problem.

As to your second question, my recollection is that  read.spss()
will be in package 'foreign'.  The absolute reference is the
source code itself, and this is often quite readable, whether
it's commented or not.

Ah . . . in order to see the source, you need to go back to CRAN
sometimes and download a source version, even though you have no
intention of re-compiling it yourself.  That's highly recommended
for questions of this sort.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 4 Nov 2003, Jacob Wegelin wrote:

>
> Tom,
>
> Thanks very much for your swift reply.  I did change some of the column
> names, eliminating all names with a pound sign in them, and got the same
> problem.  I guess I could change all the column and row names.
>
> It would be nice to know what exactly read.spss needs, though!
>
> Thanks again
>
> Jake
>
> On Tue, 4 Nov 2003, Thomas W Blackwell wrote:
>
> > Jake  -
> >
> > The error message and warnign message shown below say something
> > is wrong with this file's SPSS system-file header.  If you are
> > really able to open this one in SPSS, do so, change maybe a
> > column name or row name or two, and save it again under a
> > different file name.  See if  read.spss() chokes on the new
> > version too.
> >
> > Caution - I'm just guessing, here, but it's something to try.
> >
> > -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> >
> > On Tue, 4 Nov 2003, Jacob Wegelin wrote:
> >
> > >
> > > Is there any documentation on what kind of SPSS file can and cannot be
> > > read by read.spss?  Alternatively, how can one modify or "clean" an SPSS
> > > file to make it readable by read.spss?  What properties must a *.sav file
> > > before read.spss can read it?
> > >
> > > The file in this example is 270KB, with 5 rows and 173 columns.  I have no
> > > trouble reading larger files with read.spss, so it's not merely a size
> > > problem. I have no difficulty opening the file in SPSS.  I also have no
> > > trouble getting read.spss to read a dummy SPSS file with 5 rows and 173
> > > columns, where each entry was randomly sampled from c(letters, LETTERS).
> > >
> > > > library("foreign")
> > > > junk<-read.spss("indata/z2EXvideo.sav")
> > > Error in read.spss("indata/z2EXvideo.sav") :
> > >         Error reading system-file header.
> > > In addition: Warning message:
> > > indata/z2EXvideo.sav: File layout code has unexpected value 50331648.  Value should be 2, in big-endian or little-endian format.
> > >
> > > Thanks for any information
> > >
> > > Jake Wegelin
> > >
> > > > version
> > >          _
> > > platform i386-pc-mingw32
> > > arch     i386
> > > os       mingw32
> > > system   i386, mingw32
> > > status
> > > major    1
> > > minor    8.0
> > > year     2003
> > > month    10
> > > day      08
> > > language R
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> >
>



From ggrothendieck at myway.com  Wed Nov  5 01:54:06 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue,  4 Nov 2003 19:54:06 -0500 (EST)
Subject: [R] read.spss Error reading system-file header
Message-ID: <20031105005406.69C773962@mprdmxin.myway.com>



David Baird has created a free data conversion utility 
called dataload.  See

   http://www.vsn-intl.com/genstat/downloads/dataload.htm

It can translate SPSS files into other formats
including several that are readable by R (including csv
and rda).  I don't use SPSS myself but I have used 
dataload succesfully with Excel files.

(This is the same utility that was mentioned on the list
recently in connection with SAS.)

--- 
Date: Tue, 4 Nov 2003 15:58:02 -0800 (PST) 
From: Jacob Wegelin <jawegelin at ucdavis.edu>
To: <R-help at stat.math.ethz.ch> 
Subject: [R] read.spss Error reading system-file header 

 
 

Is there any documentation on what kind of SPSS file can and cannot be
read by read.spss? Alternatively, how can one modify or "clean" an SPSS
file to make it readable by read.spss? What properties must a *.sav file
before read.spss can read it?

The file in this example is 270KB, with 5 rows and 173 columns. I have no
trouble reading larger files with read.spss, so it's not merely a size
problem. I have no difficulty opening the file in SPSS. I also have no
trouble getting read.spss to read a dummy SPSS file with 5 rows and 173
columns, where each entry was randomly sampled from c(letters, LETTERS).

> library("foreign")
> junk<-read.spss("indata/z2EXvideo.sav")
Error in read.spss("indata/z2EXvideo.sav") :
Error reading system-file header.
In addition: Warning message:
indata/z2EXvideo.sav: File layout code has unexpected value 50331648. Value should be 2, in big-endian or little-endian format.

Thanks for any information

Jake Wegelin

> version
_
platform i386-pc-mingw32
arch i386
os mingw32
system i386, mingw32
status
major 1
minor 8.0
year 2003
month 10
day 08
language R



_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From ir1982 at u.washington.edu  Wed Nov  5 02:04:23 2003
From: ir1982 at u.washington.edu (Igor Roytberg)
Date: Tue, 4 Nov 2003 17:04:23 -0800
Subject: [R] Contrast
Message-ID: <000801c3a338$ccafdf80$47ac8e8c@igor>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031104/4fa45a85/attachment.pl

From mparrat at bu.edu  Wed Nov  5 02:10:00 2003
From: mparrat at bu.edu (Monica L. Parra Torrado)
Date: Tue, 04 Nov 2003 20:10:00 -0500
Subject: [R] Estimate hazard function from right-censored data only
Message-ID: <3FA84DE8.20600@bu.edu>

Dear All,
I would like to ask if it is possible to estimate a hazard function 
using the muhaz command when all the data is right-censored.  My data 
has information of the number of weeks people has been unemployed but 
all of them are unemployed at the date of the survey, that is, I cannot 
observed when the individuals leave the unemployment state.
I appreciate your help,
Best,
Monica L.



From tlumley at u.washington.edu  Wed Nov  5 02:27:36 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 4 Nov 2003 17:27:36 -0800 (PST)
Subject: [R] read.spss Error reading system-file header
In-Reply-To: <Pine.OSX.4.53.0311031612090.1210@biostat5.ucdavis.edu>
References: <Pine.OSX.4.53.0311031612090.1210@biostat5.ucdavis.edu>
Message-ID: <Pine.A41.4.58.0311041724230.81502@homer33.u.washington.edu>

On Tue, 4 Nov 2003, Jacob Wegelin wrote:

>
> Is there any documentation on what kind of SPSS file can and cannot be
> read by read.spss?  Alternatively, how can one modify or "clean" an SPSS
> file to make it readable by read.spss?  What properties must a *.sav file
> before read.spss can read it?
>

I don't think this is known.  The read.spss code is taken from code in
PSPP, which was going to be a GNU implementation of SPSS.  Judging from
some of the comments in the code, at least part of the format was worked
out from files, not documented.

I haven't run across any problems in using it to read SPSS .sav files, but
most of the ones I have tried were created by the same people and don't
represent independent confirmations.

	-thomas



From Simon.Blomberg at anu.edu.au  Wed Nov  5 02:32:07 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed, 5 Nov 2003 12:32:07 +1100
Subject: [R] Contrast
Message-ID: <7A3A13F416B40842BD2C1753E044B35901228154@CASEVS02.cas.anu.edu.au>

see ?fit.contrast in library gregmisc.

Cheers,

Simon.

Simon Blomberg, PhD
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


> -----Original Message-----
> From: Igor Roytberg [mailto:ir1982 at u.washington.edu]
> Sent: Wednesday, 5 November 2003 12:04 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Contrast
> 
> 
> Could anyone please explain how to set up contrasts between 
> means in R. I want to know if "before I conduct an experiment 
> and believe the mean for 1 and 2 will be different from means 
> 3 and 4, Is this true?"  That is what I have to prove or 
> disprove, I thought that contrasts would be the way to go. 
> Thanks for the help. 
> 
> Igor
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jawegelin at ucdavis.edu  Wed Nov  5 02:37:59 2003
From: jawegelin at ucdavis.edu (Jacob Wegelin)
Date: Tue, 4 Nov 2003 17:37:59 -0800 (PST)
Subject: [R] read.spss Error reading system-file header
In-Reply-To: <Pine.A41.4.58.0311041724230.81502@homer33.u.washington.edu>
References: <Pine.OSX.4.53.0311031612090.1210@biostat5.ucdavis.edu>
	<Pine.A41.4.58.0311041724230.81502@homer33.u.washington.edu>
Message-ID: <Pine.OSX.4.53.0311041732180.1453@biostat5.ucdavis.edu>


Thank you for your responses.

Here's the workaround.  In SPSS, I saved the file EXvideo.sav as
Excel.  Still in SPSS, I read in this Excel file, and saved it
under a new name, EXvideo-SPSStoExceltoSPSS.sav, as an SPSS file.
This file I was able to read into R with no problem, using read.spss.

The dataload utility was able to convert some other SPSS files to
xls, but not EXvideo.sav.

Jake

On Tue, 4 Nov 2003, Thomas Lumley wrote:

> On Tue, 4 Nov 2003, Jacob Wegelin wrote:
>
> >
> > Is there any documentation on what kind of SPSS file can and cannot be
> > read by read.spss?  Alternatively, how can one modify or "clean" an SPSS
> > file to make it readable by read.spss?  What properties must a *.sav file
> > before read.spss can read it?
> >
>
> I don't think this is known.  The read.spss code is taken from code in
> PSPP, which was going to be a GNU implementation of SPSS.  Judging from
> some of the comments in the code, at least part of the format was worked
> out from files, not documented.
>
> I haven't run across any problems in using it to read SPSS .sav files, but
> most of the ones I have tried were created by the same people and don't
> represent independent confirmations.
>
> 	-thomas
>



From gall at spookyhill.net  Wed Nov  5 02:38:36 2003
From: gall at spookyhill.net (Norm Gall)
Date: Tue, 4 Nov 2003 18:38:36 -0700
Subject: [R] R 1.8 and MacOS X 10.3
Message-ID: <C614E717-0F30-11D8-955C-000393CF8846@spookyhill.net>

It would seem that R 1.8 doesn't like the version of libiconv that 
Panther has installed. Can we compile this for Aqua ourselves or will 
there be a binary for we who upgrade sooner rather than later?


[ludwig:~] gall% R
dyld: mkdir version mismatch for library: 
/usr/local/lib/libiconv.2.dylib (compatibility version of user: 5.0.0 
greater than library's version: 4.0.0)
/usr/local/bin/R: line 145:  8440 Trace/BPT trap          mkdir 
"${R_SESSION_TMPDIR}"
2003-11-04 18:36:01.091 RAqua[8438] CFLog (21): Error loading 
/usr/local/lib/libiconv.2.dylib:  error code 1, error number 87 (dyld: 
/Applications/StartR.app/RAqua.app/Contents/MacOS/RAqua version 
mismatch for library: /usr/local/lib/libiconv.2.dylib (compatibility 
version of user: 5.0.0 greater than library's version: 4.0.0)
)
2003-11-04 18:36:01.257 RAqua[8438] CFLog (21): Error loading 
/usr/local/lib/libiconv.2.dylib:  error code 1, error number 87 (dyld: 
/Applications/StartR.app/RAqua.app/Contents/MacOS/RAqua version 
mismatch for library: /usr/local/lib/libiconv.2.dylib (compatibility 
version of user: 5.0.0 greater than library's version: 4.0.0)
)

R : Copyright 2003, The R Development Core Team
Version 1.8.0 beta (2003-10-02)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.



From dmurdoch at pair.com  Wed Nov  5 02:48:44 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 04 Nov 2003 20:48:44 -0500
Subject: [R] objects inside curly braces
In-Reply-To: <FA56A73B8839AF4088504BA4EAFE444E06DEC1DE@smmail1.rand.org>
References: <FA56A73B8839AF4088504BA4EAFE444E06DEC1DE@smmail1.rand.org>
Message-ID: <oilgqvcnganki83rhbgbd95f5fhagc9svs@4ax.com>

On Tue, 4 Nov 2003 16:19:44 -0800 , you wrote:

>Hello,
> 
>I am running a program in r that calls a function, which calls another
>function, which calls another etc. These functions are of the form:
> 
>example<- function(x,y,z)
> 
>{x, y, and z are defined within curly braces like this}
> 
>Here's my question. To start the main function, I input as an initial
>parameter a matrix of regressors of the form:
> 
>MyMatrix<-cbind(this.one,that.one)
> 
>That's all fine, but then I get a nonconformability message telling me that
>MyMatrix is not conformable with x. 
> 
>I can check the dimensions of MyMatrix, but x is in curly braces, and so is
>not an object. I'd like to check the dimensions of x, but can't, so it's
>hard to tell what's wrong with it.
> 
>Any suggestions?

The objects within the braces are called local variables; in most
cases they exist only for the life of the function call.

To debug them, use debug().  For example, if the function that's not
working is called foo, then do this:

debug(foo)
foo(x, y, z)

This will let you single step through the code in foo, and see what's
going on.  See ?debug for details.

Duncan Murdoch



From feh3k at spamcop.net  Wed Nov  5 03:03:56 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 4 Nov 2003 21:03:56 -0500
Subject: [R] help with nomogram function
In-Reply-To: <7k2fbtxh.fsf@uq.edu.au>
References: <7k2fbtxh.fsf@uq.edu.au>
Message-ID: <20031104210356.31e2edca.feh3k@spamcop.net>

On Wed, 05 Nov 2003 09:22:34 +1000
Ross Darnell <r.darnell at uq.edu.au> wrote:

> I have fitted a logistic regression model
> 
> > failed.lr2$call
> lrm(formula = failed ~ Age + task2 + Age:task2, data = time.long, 
>     na.action = na.omit)

Use Age*task2 and omit na.action as na.omit is the default

> 
> using the Design package functions and would like to generate a
> nomogram from this model.
> 
> the datadist information is generated and stored in
> 
> > ddist
>                 time.long$Age time.long$task2
> Low:effect                 45            <NA>
> Adjust to                  56       both.foam
> High:effect                68            <NA>
> Low:prediction             21       both.foam
> High:prediction            80           right
> Low                        20       both.foam
> High                       80           right

This looks most strange.  You did not include the original code but I
suspect you had $ in a term.  $ should not appear in column headings
above.  Design wants you to use data= or attach, and avoid $ in terms.

Frank Harrell

> 
> Values:
> 
> time.long$task2 : both.foam left right 
> > 
> 
> The model fitted and then when I try the nomgram function
> 
> > nomogram(failed.lr2)
> Error in value.chk(at, i, NA, -nint, Limval, type.range = "full") : 
> 	variable Age does not have limits defined by datadist
> > 
> 
> I get an error. The NA values in ddist seem to be the problem but I
> don't understand the datadist information.
> 
> Can anyone help explain why this is failing.
> 
> Thanks
> 
> Ross Darnell
> 
> -- 
> 
> University of Queensland, Brisbane QLD 4067 AUSTRALIA
> Email: <r.darnell at uq.edu.au>
> Phone +61 7 3365 6087
> http://www.shrs.uq.edu/shrs/school_staff/ross_darnell.html
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From ross at biostat.ucsf.edu  Wed Nov  5 03:09:57 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 04 Nov 2003 18:09:57 -0800
Subject: [R] Architecting an optimization with external calls
In-Reply-To: <Pine.LNX.4.44.0311042112180.20905-100000@gannet.stats>
References: <Pine.LNX.4.44.0311042112180.20905-100000@gannet.stats>
Message-ID: <1067998197.26108.56.camel@iron.libaux.ucsf.edu>

On Tue, 2003-11-04 at 13:12, Prof Brian Ripley wrote:
> Look into external pointers.  That is how we have tackled this, e.g. in 
> the ts package.
I got the following to work.  Any comments?  I indicated some areas of
uncertainty in the comments.  I'm also unsure about the differences, if
any, between the DOUBLE_DATA(x)[0] = val style and SET_ELEMENT(x, i,
val) style.

The R code was the best way I could think of to retain the state while
using a function that worked with optim.  The C code remembers the
argument from the previous call and prints it out when invoked.

The driving R code was
loglika <- function(initialparms) {
  opaque <- NULL # holds the data returned by the C function
  innerloglik <- function(parms){
    # If .C can handle externalptr, it would be easier
    result <- .Call("loglik", as.double(parms), opaque)
    opaque <<- result$opaque
    return(result$loglik)
  }
  result <- optim(initialparms, innerloglik)
  .Call("cleanup", opaque)
  opaque <- NULL
}

And the C:
#include <R.h>
#include <Rdefines.h>

SEXP loglik(SEXP params, SEXP data){
  double *pd;
  SEXP returnLik, returnVal, returnNames;

  if (TYPEOF(data) == EXTPTRSXP) {
    pd = (double *) EXTPTR_PTR(data);
    Rprintf("I've been here with %f\n", *pd);
  } else {
    pd = malloc(sizeof(double));
    data = R_MakeExternalPtr(pd, R_NilValue, R_NilValue);
    /* do I need PROTECT(data)?  if so, argument to
     UNPROTECT is variable */
  }
  
  *pd = DOUBLE_DATA(params)[0];

  /* Real computation would go here */

  PROTECT(returnLik = NEW_NUMERIC(1));
  NUMERIC_POINTER(returnLik)[0] = (*pd)*(*pd); /* our log likelihood */
     /* When I just set it = 5.0 I got a segfault.  Maybe because I
	rebuilt the library at the same time.... */

  /* update opaque data with first input parameter */
  Rprintf("Just recorded input parameter %f\n", *pd);

  /* construct return list object */
  PROTECT(returnVal = NEW_LIST(2));
  PROTECT(returnNames = NEW_CHARACTER(2));
  SET_STRING_ELT(returnNames, 0, mkChar("loglik"));
  SET_STRING_ELT(returnNames, 1, mkChar("opaque"));
  SET_NAMES(returnVal, returnNames);
  SET_ELEMENT(returnVal, 0, returnLik);
  SET_ELEMENT(returnVal, 1, data);
  UNPROTECT(3);
  return returnVal;
}

SEXP cleanup(SEXP data){
  if (TYPEOF(data) == EXTPTRSXP) {
    free(EXTPTR_PTR(data));
  } else {
    error("cleanup called without an External Pointer argument");
  }
  return R_NilValue;
}

I was going on a lot of hunches, even with the docs and code together.



From jfox at mcmaster.ca  Wed Nov  5 03:23:59 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 04 Nov 2003 21:23:59 -0500
Subject: [R] Estimate hazard function from right-censored data only
In-Reply-To: <3FA84DE8.20600@bu.edu>
Message-ID: <5.1.0.14.2.20031104212205.01fb08c0@127.0.0.1>

Dear Monica,

I'm not sure what the muhaz function is (it's not in the survival package), 
but regardless, unless I'm seriously mistaken, there's no information to 
estimate the hazard function if you haven't observed any events.

I hope that this helps,
  John

At 08:10 PM 11/4/2003 -0500, Monica L. Parra Torrado wrote:
>Dear All,
>I would like to ask if it is possible to estimate a hazard function using 
>the muhaz command when all the data is right-censored.  My data has 
>information of the number of weeks people has been unemployed but all of 
>them are unemployed at the date of the survey, that is, I cannot observed 
>when the individuals leave the unemployment state.
>I appreciate your help,
>Best,
>Monica L.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From spencer.graves at pdf.com  Wed Nov  5 03:47:43 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 04 Nov 2003 18:47:43 -0800
Subject: [R] Estimate hazard function from right-censored data only
In-Reply-To: <5.1.0.14.2.20031104212205.01fb08c0@127.0.0.1>
References: <5.1.0.14.2.20031104212205.01fb08c0@127.0.0.1>
Message-ID: <3FA864CF.6020102@pdf.com>

If you are willing to assume an exponential distribution, then you can 
get a one-sided confidence bound on the exponential parameter.  The 
likelihood is the probability of what you observe.  Write that down and 
figure it out.  I'm sorry I don't have time to say more right now, but 
I've done it in the past.  It works. 

hope this helps.  spencer graves

John Fox wrote:

> Dear Monica,
>
> I'm not sure what the muhaz function is (it's not in the survival 
> package), but regardless, unless I'm seriously mistaken, there's no 
> information to estimate the hazard function if you haven't observed 
> any events.
>
> I hope that this helps,
>  John
>
> At 08:10 PM 11/4/2003 -0500, Monica L. Parra Torrado wrote:
>
>> Dear All,
>> I would like to ask if it is possible to estimate a hazard function 
>> using the muhaz command when all the data is right-censored.  My data 
>> has information of the number of weeks people has been unemployed but 
>> all of them are unemployed at the date of the survey, that is, I 
>> cannot observed when the individuals leave the unemployment state.
>> I appreciate your help,
>> Best,
>> Monica L.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Wed Nov  5 04:06:44 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 05 Nov 2003 03:06:44 -0000 (GMT)
Subject: [R] Estimate hazard function from right-censored data only
In-Reply-To: <5.1.0.14.2.20031104212205.01fb08c0@127.0.0.1>
Message-ID: <XFMail.031105030644.Ted.Harding@nessie.mcc.ac.uk>

On 05-Nov-03 John Fox wrote:
> Dear Monica,
> 
> I'm not sure what the muhaz function is (it's not in the survival
> package), but regardless, unless I'm seriously mistaken, there's no
> information to estimate the hazard function if you haven't observed
> any events.
> 
> I hope that this helps,
>   John

Well, there is _some_ information, to the extent that such data rule
out high levels of hazard ...

I recall seeing a paper by I.J. Good many years ago (can't locate the
reference now) in which he made a Bayesian inference of the probability
of nuclear war (none having occurred).

Basically he assumed a homogeneous Poisson process of nuclear war,
with improper prior (? 1/mu ) for the mean, and got a posterior
distribution for it.
Consequently a probability of NW within the next (say) 20 years could
be evaluated (though I seem to remember th\t a certain amount of
footwork was involved).

In the present case, without going so far as to be Bayesian, assuming
a constant hazard lambda would lead to an upper confidence limit for
lambda given that there had been no events within the observed
intervals (e.g. as the largest value of lambda such that the probability
of no events was not less than 0.05). You don't need survival-data
techniques for this ...

However, I certainly agree with the above to the extent that there
is no information which would support an estimate of a non-constant
hazard function.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 05-Nov-03                                       Time: 03:06:44
------------------------------ XFMail ------------------------------



From MSchwartz at medanalytics.com  Wed Nov  5 04:25:38 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 04 Nov 2003 21:25:38 -0600
Subject: [R] more barplot presentation questions
In-Reply-To: <5E06BFED29594F4C9C5EBE230DE320C62739C2@ewok.vsl.com.au>
References: <5E06BFED29594F4C9C5EBE230DE320C62739C2@ewok.vsl.com.au>
Message-ID: <1068002737.13860.154.camel@localhost.localdomain>

On Tue, 2003-11-04 at 17:15, Paul Sorenson wrote:
> Thanks to those who pointed me at the solutions to the legend
> overprinting the bars.  I took the "easy" way of rescaling the y axis,
> picking the scaling factor for stacked bars is somewhat problematic
> but sufficient for my application.
> 
> I have another couple of barplot questions:
> 
> 	- Can I extend the major ticks on the Y axis across the page?  Or
> both axes to form a grid?

Yes....use par("tck"). The value used represents the proportion (0 - 1)
of the plotting region, that the tick marks will be, for the given axis
side .

Example:
# draw the barplot
barplot(1:10, axes = FALSE)

# draw the x axis with lines going vertical
axis(1, tck = 1)

# draw the y axis with lines going horizontal
axis(2, tck = 1)

# put a box around the whole thing
box()

In this case, the grid will overlay the bars. See ?par for more
information.

> 	- A really neat graph for me would be a combination of side-by-side
> and stacked bars in a single plot to display an additional category.
> 
> The background on the second problem is that I am displaying software
> defect metrics.  For each month (the bins) the categories of interest
> are:
> 	- new/fixed/closed
> 	- numeric severity (1 - 5)
> 
> I am currently displaying 5 separate graphs (6 when you take the
> aggregate into account) with new/fixed/closed side-by-side.  If within
> the side-by-side graphs I could show the severity stacked that would
> be very neat.
> 
> Cheers


This is just a bit more complex. If I understand what you are looking to
do, consider that a single barplot that has 39 five-segment stacked bars
(12 months x 3 status groups, plus 3 bars for the totals) is extremely
busy.  If you really, really wanted that, you could use the combination
of 'beside = FALSE' to get stacked bars and then use the 'space'
argument in barplot(), to separate groups of bars by setting 'space' to
a vector of values.

Here is a very brief example:

barplot(matrix(1:36, ncol = 12), beside = FALSE, space = c(1, 0, 0))

The above will have 4 groups of 3 bars each, where each bar will consist
of 3 colored segments. The 'space' argument starts with a spacing of 1
bar width before the first bar, 0 before the second and 0 before the
third, repeated for each group. The numbers are the proportion of the
average bar widths. See ?barplot for more information. If you want to
annotate the bars, keep in mind that barplot() returns the bar midpoints
(ie.  mp <- barplot(....) )

If you are looking to visually trend/compare groups, you may be best
served by staying with your multiple barplots, but do it within a single
graphic. This can be achieved by using par("mfrow") to break the single
display into multiple sections (ie. a grid of 2 rows by 3 columns) where
you can then use barplot() 6 times, once for each severity level. That
way, it is all on a single page, rather than 6 pages.

A quick example, though using repetitive barplot data just for layout
ideas:

# create some data
data <- matrix(1:36, ncol = 12)

# save current graphic pars
op <- par(no.readonly = TRUE)

# break up the graphic device into a 2 row by 3 column grid
par(mfrow = c(2, 3))

# now draw each barplot, one to each grid position
barplot(data, beside = FALSE)
barplot(data, beside = FALSE)
barplot(data, beside = FALSE)
barplot(data, beside = FALSE)
barplot(data, beside = FALSE)
barplot(data, beside = FALSE)

# restore graphic pars
par(op)

Again see ?par for more information.

In the above example, each grid position can represent one severity
level, with the final being your aggregate. Each individual stacked
barplot() represents your monthly data for each status level.

Alternatively, using barchart() in the grid/lattice package you can
achieve a similar result in a Trellis style graphic, where you can
'condition' the plots on the severity level. You might want to run the
barchart() examples to get a feel for what can be done there.

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Wed Nov  5 05:05:29 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue,  4 Nov 2003 23:05:29 -0500 (EST)
Subject: [R] read.spss Error reading system-file header
Message-ID: <20031105040529.5627D399E@mprdmxin.myway.com>


Sorry, but there was an error in the link that I posted below.
It should have been

  http://www.vsn-intl.com/genstat/downloads/datald.htm

---
 
Date: Tue, 4 Nov 2003 19:54:06 -0500 
From: Gabor Grothendieck <ggrothendieck at myway.com>
To: <jawegelin at ucdavis.edu>, <R-help at stat.math.ethz.ch> 
Cc: <david.baird at agresearch.co.nz> 
Subject: RE: [R] read.spss Error reading system-file header 

David Baird has created a free data conversion utility 
called dataload. See

http://www.vsn-intl.com/genstat/downloads/dataload.htm

It can translate SPSS files into other formats
including several that are readable by R (including csv
and rda). I don't use SPSS myself but I have used 
dataload succesfully with Excel files.

(This is the same utility that was mentioned on the list
recently in connection with SAS.)

--- 
Date: Tue, 4 Nov 2003 15:58:02 -0800 (PST) 
From: Jacob Wegelin <jawegelin at ucdavis.edu>
To: <R-help at stat.math.ethz.ch> 
Subject: [R] read.spss Error reading system-file header 




Is there any documentation on what kind of SPSS file can and cannot be
read by read.spss? Alternatively, how can one modify or "clean" an SPSS
file to make it readable by read.spss? What properties must a *.sav file
before read.spss can read it?

The file in this example is 270KB, with 5 rows and 173 columns. I have no
trouble reading larger files with read.spss, so it's not merely a size
problem. I have no difficulty opening the file in SPSS. I also have no
trouble getting read.spss to read a dummy SPSS file with 5 rows and 173
columns, where each entry was randomly sampled from c(letters, LETTERS).

> library("foreign")
> junk<-read.spss("indata/z2EXvideo.sav")
Error in read.spss("indata/z2EXvideo.sav") :
Error reading system-file header.
In addition: Warning message:
indata/z2EXvideo.sav: File layout code has unexpected value 50331648. Value should be 2, in big-endian or little-endian format.

Thanks for any information

Jake Wegelin

> version
_
platform i386-pc-mingw32
arch i386
os mingw32
system i386, mingw32
status
major 1
minor 8.0
year 2003
month 10
day 08
language R




_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From jfox at mcmaster.ca  Wed Nov  5 05:54:40 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 04 Nov 2003 23:54:40 -0500
Subject: [R] Estimate hazard function from right-censored data only
In-Reply-To: <XFMail.031105030644.Ted.Harding@nessie.mcc.ac.uk>
References: <5.1.0.14.2.20031104212205.01fb08c0@127.0.0.1>
Message-ID: <5.1.0.14.2.20031104234136.02010e18@127.0.0.1>

Dear Ted,

Yes, that makes sense, and I hadn't thought of it -- I was thinking in 
terms of a nonparametric estimate of the hazard function.  Spencer Graves 
makes a similar point. Andy Liaw was kind enough to point out to me that 
the muhaz function is in the muhaz package. As it turns out, muhaz provides 
smooth nonparametric estimates of the hazard function using kernel methods.

Thanks to all,
  John

At 03:06 AM 11/5/2003 +0000, Ted Harding wrote:
>On 05-Nov-03 John Fox wrote:
> > Dear Monica,
> >
> > I'm not sure what the muhaz function is (it's not in the survival
> > package), but regardless, unless I'm seriously mistaken, there's no
> > information to estimate the hazard function if you haven't observed
> > any events.
> >
> > I hope that this helps,
> >   John
>
>Well, there is _some_ information, to the extent that such data rule
>out high levels of hazard ...
>
>I recall seeing a paper by I.J. Good many years ago (can't locate the
>reference now) in which he made a Bayesian inference of the probability
>of nuclear war (none having occurred).
>
>Basically he assumed a homogeneous Poisson process of nuclear war,
>with improper prior (? 1/mu ) for the mean, and got a posterior
>distribution for it.
>Consequently a probability of NW within the next (say) 20 years could
>be evaluated (though I seem to remember th\t a certain amount of
>footwork was involved).
>
>In the present case, without going so far as to be Bayesian, assuming
>a constant hazard lambda would lead to an upper confidence limit for
>lambda given that there had been no events within the observed
>intervals (e.g. as the largest value of lambda such that the probability
>of no events was not less than 0.05). You don't need survival-data
>techniques for this ...
>
>However, I certainly agree with the above to the extent that there
>is no information which would support an estimate of a non-constant
>hazard function.
>
>Best wishes,
>Ted.
>
>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>Fax-to-email: +44 (0)870 167 1972
>Date: 05-Nov-03                                       Time: 03:06:44
>------------------------------ XFMail ------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From Pascal.Niklaus at unibas.ch  Wed Nov  5 09:25:34 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Wed, 05 Nov 2003 09:25:34 +0100
Subject: [R] help with lme()
In-Reply-To: <02be01c3a2ea$4b0aecc0$8d1ad284@BIO041>
References: <02be01c3a2ea$4b0aecc0$8d1ad284@BIO041>
Message-ID: <3FA8B3FE.2030602@unibas.ch>

As far as I understand it, the problem is that REML accounts for the 
degrees of freedom used up by fixed effects (e.g., treatments), whereas 
ML does not account for these. From that perspective, REML appears to be 
the "better" fitting method.

However, if you test for a fixed effect by comparing two models, one 
including the fixed effect and one lacking it but otherwise identical, 
then the model comparison anova(model1,model2) is invalid when you use 
REML (because there is a different number of df consumed by the fixed 
effects in model1 and model2), but it is valid if you use ML (because it 
does not account for the df used up by the fixed effects at all).

Pascal


Bill Shipley wrote:

>Hello. I am trying to determine whether I should be using ML or REML
>methods to estimate a linear mixed model.   In the book by Pinheiro &
>Bates (Mixed-effects models in S and S-PLUS, page 76) they state that
>one difference between REML and ML is that ? LME models with different
>fixed-effects structures fit using REML cannot be compared on the basis
>of their restricted likelihoods.  In particular, likelihood ratio tests
>are not valid under these circumstances.?
>
>I am not sure what ?fixed-effects structures? means.  Does it mean that,
>as long as the types of contrasts are the same between two models, they
>ARE comparable, but are NOT comparable if the types of contrasts are
>changes?  Or rather, does it simply mean that one should use t or F
>tests for the fixed effects, and restrict the likelihood ratio tests to
>the random effects only if using REML?
>
> 
>
>Bill Shipley
>
>Associate Editor, Ecology
>
>North American Editor, Annals of Botany
>
>D?partement de biologie, Universit? de Sherbrooke,
>
>Sherbrooke (Qu?bec) J1K 2R1 CANADA
>
>Bill.Shipley at USherbrooke.ca
>
> <http://callisto.si.usherb.ca:8080/bshipley/>
>http://callisto.si.usherb.ca:8080/bshipley/
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From Pascal.Niklaus at unibas.ch  Wed Nov  5 09:50:01 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Wed, 05 Nov 2003 09:50:01 +0100
Subject: [R] converting column to factor *within* a data frame
Message-ID: <3FA8B9B9.8050107@unibas.ch>

Hi all,

I repeatedly encounter the following problem: After importing a data set 
into a data frame, I wish to set a column with numeric values to be a 
factor, but can't figure out how to do this. Also, I do not wish to 
write as.factor(x) all the time. I can create a new vector with x <- 
factor(x), but the new vector resides outside the attached data frame.

Pascal

 > attach(ngrad)
 > is.factor(STNW)
[1] FALSE

 > ngrad$STNW<-factor(STNW)  ## doesn't work
 > is.factor(STNW)
[1] FALSE

 > is.factor(STNW) <- T    ## doesn't work either
Error: couldn't find function "is.factor<-"



From ripley at stats.ox.ac.uk  Wed Nov  5 10:01:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 09:01:22 +0000 (GMT)
Subject: [R] converting column to factor *within* a data frame
In-Reply-To: <3FA8B9B9.8050107@unibas.ch>
Message-ID: <Pine.LNX.4.44.0311050900250.25126-100000@gannet.stats>

On Wed, 5 Nov 2003, Pascal A. Niklaus wrote:

> Hi all,
> 
> I repeatedly encounter the following problem: After importing a data set 
> into a data frame, I wish to set a column with numeric values to be a 
> factor, but can't figure out how to do this. Also, I do not wish to 
> write as.factor(x) all the time. I can create a new vector with x <- 
> factor(x), but the new vector resides outside the attached data frame.
> 
> Pascal
> 
>  > attach(ngrad)
>  > is.factor(STNW)
> [1] FALSE
> 
>  > ngrad$STNW<-factor(STNW)  ## doesn't work
>  > is.factor(STNW)
> [1] FALSE

It does work.  It changes ngrad, and not the copy you attached.

ngrad$STNW<-factor(ngrad$STNW)
attach(ngrad)

is the correct sequence.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Simon.Fear at synequanon.com  Wed Nov  5 10:11:11 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 5 Nov 2003 09:11:11 -0000
Subject: [R] converting column to factor *within* a data frame
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0E7B@synequanon01>

Your problem is with scoping, not the conversion per se:

>  > attach(ngrad)
>  > is.factor(STNW)
> [1] FALSE

At this moment, STNW is the same as ngrad$STNW

>  > ngrad$STNW<-factor(STNW)  ## doesn't work

Yes it does work, try looking at is.factor(ngrad$STNW)

>  > is.factor(STNW)
> [1] FALSE

After you assign to ngrad$STNW, it is no longer the same
thing as the attached STNW. You would need to detach
and re-attach ngrad for this to be so. There's no
automatic synchronisation between the attached STNW 
and ngrad$STNW; changing one will not change the other.

My advice is: never use attach() if you can help it. It's an 
accident waiting to happen. Get used to typing
dataFrame$varname instead of just varname - that way
you will always get what you expect. Or use with() instead 
of attach() in almost every case. 

HTH  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From pburns at pburns.seanet.com  Wed Nov  5 10:48:50 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed, 05 Nov 2003 09:48:50 +0000
Subject: [R] objects inside curly braces
References: <FA56A73B8839AF4088504BA4EAFE444E06DEC1DE@smmail1.rand.org>
	<oilgqvcnganki83rhbgbd95f5fhagc9svs@4ax.com>
Message-ID: <3FA8C782.3040002@pburns.seanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031105/f5585311/attachment.pl

From glaziou at pasteur-kh.org  Wed Nov  5 11:01:48 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 5 Nov 2003 17:01:48 +0700
Subject: [R] converting column to factor *within* a data frame
In-Reply-To: <3FA8B9B9.8050107@unibas.ch>
References: <3FA8B9B9.8050107@unibas.ch>
Message-ID: <20031105100147.GT483@pasteur-kh.org>

Pascal A. Niklaus <Pascal.Niklaus at unibas.ch> wrote:
> I repeatedly encounter the following problem: After importing a data set 
> into a data frame, I wish to set a column with numeric values to be a 
> factor, but can't figure out how to do this. Also, I do not wish to 
> write as.factor(x) all the time. I can create a new vector with x <- 
> factor(x), but the new vector resides outside the attached data frame.
> 
> Pascal
> 
> > attach(ngrad)
> > is.factor(STNW)
> [1] FALSE
> 
> > ngrad$STNW<-factor(STNW)  ## doesn't work
> > is.factor(STNW)
> [1] FALSE

That command checked the attached dataset, which has not been
modified by the previous command. You seem to be confused by what
attach() does. Read ?attach.

> data <- data.frame(a=1:3, b=4:6)
> data
  a b
1 1 4
2 2 5
3 3 6
> attach(data)
> is.factor(a)
[1] FALSE
> data$a <- as.factor(a)
> is.factor(a)
[1] FALSE
> is.factor(data$a)
[1] TRUE
> detach(data)
> attach(data)
> is.factor(a)
[1] TRUE

-- 
Philippe



From marten.bjellerup at ehv.vxu.se  Wed Nov  5 11:28:08 2003
From: marten.bjellerup at ehv.vxu.se (=?iso-8859-1?Q?M=E5rten_Bjellerup?=)
Date: Wed, 05 Nov 2003 11:28:08 +0100
Subject: [R] Fitting a 3-parameter gammadistribution
Message-ID: <009b01c3a387$81ed7080$5a4d2fc2@MBJEHV>

I have 'grouped' data, that is in the form of:

Interval        Median
0-9.9%:        -25
10-19.9%:     0
20-29.9%:     3
30-39.9%:     10
40-49.9%:     50
50-59.9%:     200
et cetera

and want to fit a three parameter gamma distribution. Does anyone know of an existing routine for doing this (or something similar)? Any help or comment is much appreciated.

Regards,

M?rten

M?rten Bjellerup
Doctoral Student in Economics
School of Management and Economics
V?xj? University
SE-351 95  V?xj?
Sweden

Tel: +46 470 708410 
Fax: +46 470 82478 
Mobile: +46 70 969 88 88 
Mail: marten.bjellerup at ehv.vxu.se 
Web: http://www.ehv.vxu.se
-------------------------------------
"Forecasting is like trying to
drive a car blindfolded and
following directions given 
by a person who is looking
out of the back window"



From mros at autan.toulouse.inra.fr  Wed Nov  5 11:28:42 2003
From: mros at autan.toulouse.inra.fr (Mathieu Ros)
Date: Wed,  5 Nov 2003 11:28:42 +0100 (MET)
Subject: [R] USA map
In-Reply-To: <3FA7F08D.31300.53C763@localhost>
References: <200311041921.hA4JLlso014885@tahi.mcs.vuw.ac.nz>
	<3FA7F08D.31300.53C763@localhost>
Message-ID: <16296.53296.658945.639158@autan.toulouse.inra.fr>

>>>>> "k" == kjetil  <kjetil at entelnet.bo> disait:

 <snip>
    k> I also tried

    k>> map("worldHires","sweden")
    k>> map("worldHires","denmark") # which comes out very small since it
    k>                              # includes the Faroe 
    k>                              # islands properly faraway

and, just to know, how would you do to plot *only* continental
denmark? The same applies for france, UK, ...

-- 
Mathieu Ros
Ph. D. student - "Canalizing selection using Bayesian models"
INRA - Fish Genetics Unit (Paris)/Cell Genetics Unit (Toulouse)
tel : (+0033)1 3465 3414 (FGU) / (+0033)5 6128 5305 (CGU)
mail : ros at diamant.jouy.inra.fr



From Ivar.Herfindal at bio.ntnu.no  Wed Nov  5 11:44:16 2003
From: Ivar.Herfindal at bio.ntnu.no (Ivar Herfindal)
Date: Wed, 05 Nov 2003 11:44:16 +0100
Subject: [R] USA map
In-Reply-To: <16296.53296.658945.639158@autan.toulouse.inra.fr>
References: <200311041921.hA4JLlso014885@tahi.mcs.vuw.ac.nz>
	<3FA7F08D.31300.53C763@localhost>
	<16296.53296.658945.639158@autan.toulouse.inra.fr>
Message-ID: <oprx5ur2f6ndboo6@mail.bio.ntnu.no>

On Wed,  5 Nov 2003 11:28:42 +0100 (MET), Mathieu Ros 
<mros at autan.toulouse.inra.fr> wrote:

>>>>>> "k" == kjetil  <kjetil at entelnet.bo> disait:
>
> <snip>
> k> I also tried
>
> k>> map("worldHires","sweden")
> k>> map("worldHires","denmark") # which comes out very small since it
> k>                              # includes the Faroe k>                   
> # islands properly faraway
>
> and, just to know, how would you do to plot *only* continental
> denmark? The same applies for france, UK, ...
>
Hello

One simple way of doing it is to specify the xlim and ylim of your map, 
e.g. library(maps)
map('world', 'Norway', xlim=c(5, 33), ylim=c(55, 75))


btw. the reason why Norway comes out so small when writing only

map('world', 'Norway')

is due to the Bouvet Island, located south (54 degrees south) in the 
Atlantic Ocean.

Ivar Herfindal



From glaziou at pasteur-kh.org  Wed Nov  5 12:18:49 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 5 Nov 2003 18:18:49 +0700
Subject: [R] map does not display maps, MacOSX
Message-ID: <20031105111848.GA29829@pasteur-kh.org>

Hi,

I installed the maps and mapdata libraries on my R-1.8.0 on
MacOSX 10.2.8 (jaguar on a powerbook G4), and failed to make the
map function work properly:


R : Copyright 2003, The R Development Core Team
Version 1.8.0  (2003-10-08)
[...]

> library(maps)
> map()
Error in file(file, "r") : unable to open connection
In addition: Warning message: 
cannot open file `/Users/glaziou/Library/R/maps/mapdata//world.N' 
> map('usa')
Error in file(file, "r") : unable to open connection
In addition: Warning message: 
cannot open file `/Users/glaziou/Library/R/maps/mapdata//usa.N' 
> system('ls -l /Users/glaziou/Library/R/maps/mapdata')
total 1796
-rw-r--r--   1 root     staff      143902 Oct 14 11:30 county.G
-rw-r--r--   1 root     staff      690260 Oct 14 11:30 county.L
-rw-r--r--   1 root     staff         618 Oct 14 11:30 nz.G
-rw-r--r--   1 root     staff       13040 Oct 14 11:30 nz.L
-rw-r--r--   1 root     staff        2642 Oct 14 11:30 state.G
-rw-r--r--   1 root     staff       96892 Oct 14 11:30 state.L
-rw-r--r--   1 root     staff         282 Oct 14 11:30 usa.G
-rw-r--r--   1 root     staff       58232 Oct 14 11:30 usa.L
-rw-r--r--   1 root     staff       74434 Oct 14 11:30 world.G
-rw-r--r--   1 root     staff      295152 Oct 14 11:30 world.L
-rw-r--r--   1 root     staff       74434 Oct 14 11:30 world2.G
-rw-r--r--   1 root     staff      295152 Oct 14 11:30 world2.L
-rw-r--r--   1 root     staff       54832 Oct 14 11:30 world2.N

Most of contributed libraries are installed in ~/Library/R
because I am the only user of that mac and this simplifies
backup. I checked the access rights of relevant files and
directories and they all seem correct (these are owned by root
but are world readable and directories are world cd'able).
Compilation of both libraries maps and mapdata went ok.  I have
the same libraries installed on a linux server where they work
perfectly well. 

A similar error message occurs whether R is started in an xterm,
within emacs/ESS on X11, or using the RAqua interface.

Any hint appreciated,

-- 
Philippe Glaziou



From ripley at stats.ox.ac.uk  Wed Nov  5 12:34:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 5 Nov 2003 11:34:00 +0000 (GMT Standard Time)
Subject: [R] map does not display maps, MacOSX
In-Reply-To: <20031105111848.GA29829@pasteur-kh.org>
Message-ID: <Pine.WNT.4.44.0311051132160.3584-100000@gannet.stats.ox.ac.uk>

Notice the // in the path

/Users/glaziou/Library/R/maps/mapdata//world.N

Some Windows filesystems do not like that, and my guess is that some MacOS
X ones may not either.

On Wed, 5 Nov 2003, Philippe Glaziou wrote:

> Hi,
>
> I installed the maps and mapdata libraries on my R-1.8.0 on
> MacOSX 10.2.8 (jaguar on a powerbook G4), and failed to make the
> map function work properly:
>
>
> R : Copyright 2003, The R Development Core Team
> Version 1.8.0  (2003-10-08)
> [...]
>
> > library(maps)
> > map()
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `/Users/glaziou/Library/R/maps/mapdata//world.N'
> > map('usa')
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `/Users/glaziou/Library/R/maps/mapdata//usa.N'
> > system('ls -l /Users/glaziou/Library/R/maps/mapdata')
> total 1796
> -rw-r--r--   1 root     staff      143902 Oct 14 11:30 county.G
> -rw-r--r--   1 root     staff      690260 Oct 14 11:30 county.L
> -rw-r--r--   1 root     staff         618 Oct 14 11:30 nz.G
> -rw-r--r--   1 root     staff       13040 Oct 14 11:30 nz.L
> -rw-r--r--   1 root     staff        2642 Oct 14 11:30 state.G
> -rw-r--r--   1 root     staff       96892 Oct 14 11:30 state.L
> -rw-r--r--   1 root     staff         282 Oct 14 11:30 usa.G
> -rw-r--r--   1 root     staff       58232 Oct 14 11:30 usa.L
> -rw-r--r--   1 root     staff       74434 Oct 14 11:30 world.G
> -rw-r--r--   1 root     staff      295152 Oct 14 11:30 world.L
> -rw-r--r--   1 root     staff       74434 Oct 14 11:30 world2.G
> -rw-r--r--   1 root     staff      295152 Oct 14 11:30 world2.L
> -rw-r--r--   1 root     staff       54832 Oct 14 11:30 world2.N
>
> Most of contributed libraries are installed in ~/Library/R
> because I am the only user of that mac and this simplifies
> backup. I checked the access rights of relevant files and
> directories and they all seem correct (these are owned by root
> but are world readable and directories are world cd'able).
> Compilation of both libraries maps and mapdata went ok.  I have
> the same libraries installed on a linux server where they work
> perfectly well.
>
> A similar error message occurs whether R is started in an xterm,
> within emacs/ESS on X11, or using the RAqua interface.
>
> Any hint appreciated,
>
> --
> Philippe Glaziou
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bernd.weiss at uni-koeln.de  Wed Nov  5 12:25:19 2003
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Wed, 05 Nov 2003 12:25:19 +0100
Subject: [R] Match data.frames with different number of rows
Message-ID: <3FA8EC2F.21635.D2EAD6@localhost>

Dear all,

I have two data.frames a and b:

i <- c(1,1,2,2,3,3,4,4)
x <- c(1,53,7,3,4,23,6,2)
a <- data.frame(i,x)

and 

j <- c(1,2,3,4)
y <- c(99,88,77,66)
b <- data.frame(j,y)

So, a looks like this

> a
  i  x
 1  1
 1 53
 2  7
 2  3
 3  4
 3 23
 4  6
 4  2

and b like this

> b
  j  y
 1 99
 2 88
 3 77
 4 66

Now, I would like to match 'b' to 'a', so that a new data.frame 'c' is

> c
  i  x	z
1 1  1	99
2 1 53	99
3 2  7	88	
4 2  3	88
5 3  4	77	
6 3 23	77
7 4  6	66
8 4  2	66

I habe absolutely no idea how to do this. I searched the net, the FAQ, the manuals, my 
four books...

Any help would be appreciated!

Bernd



From spencer.graves at pdf.com  Wed Nov  5 12:40:25 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 05 Nov 2003 03:40:25 -0800
Subject: [R] Fitting a 3-parameter gammadistribution
In-Reply-To: <009b01c3a387$81ed7080$5a4d2fc2@MBJEHV>
References: <009b01c3a387$81ed7080$5a4d2fc2@MBJEHV>
Message-ID: <3FA8E1A9.4050304@pdf.com>

      That's called "interval censoring".  The "likelihood" for such 
cases is the probability of what was observed, i.e., (pgamma3(10, ..., - 
pgamma3(0, ...))*... .  For this kind of problem, I have in the past 
written a function to compute the log(likelihood) and then passed that 
function to "optim". 

      hope this helps.  spencer graves

M?rten Bjellerup wrote:

>I have 'grouped' data, that is in the form of:
>
>Interval        Median
>0-9.9%:        -25
>10-19.9%:     0
>20-29.9%:     3
>30-39.9%:     10
>40-49.9%:     50
>50-59.9%:     200
>et cetera
>
>and want to fit a three parameter gamma distribution. Does anyone know of an existing routine for doing this (or something similar)? Any help or comment is much appreciated.
>
>Regards,
>
>M?rten
>
>M?rten Bjellerup
>Doctoral Student in Economics
>School of Management and Economics
>V?xj? University
>SE-351 95  V?xj?
>Sweden
>
>Tel: +46 470 708410 
>Fax: +46 470 82478 
>Mobile: +46 70 969 88 88 
>Mail: marten.bjellerup at ehv.vxu.se 
>Web: http://www.ehv.vxu.se
>-------------------------------------
>"Forecasting is like trying to
>drive a car blindfolded and
>following directions given 
>by a person who is looking
>out of the back window"
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From glaziou at pasteur-kh.org  Wed Nov  5 12:47:27 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 5 Nov 2003 18:47:27 +0700
Subject: [R] Match data.frames with different number of rows
In-Reply-To: <3FA8EC2F.21635.D2EAD6@localhost>
References: <3FA8EC2F.21635.D2EAD6@localhost>
Message-ID: <20031105114727.GU483@pasteur-kh.org>

Bernd Weiss <bernd.weiss at uni-koeln.de> wrote:
> I have two data.frames a and b:
> 
> i <- c(1,1,2,2,3,3,4,4)
> x <- c(1,53,7,3,4,23,6,2)
> a <- data.frame(i,x)
> 
> and 
> 
> j <- c(1,2,3,4)
> y <- c(99,88,77,66)
> b <- data.frame(j,y)
> 
 Now, I would like to match 'b' to 'a', so that a new data.frame 'c' is
> 
> > c
>   i  x	z
> 1 1  1	99
> 2 1 53	99
> 3 2  7	88	
> 4 2  3	88
> 5 3  4	77	
> 6 3 23	77
> 7 4  6	66
> 8 4  2	66


Merge should do the job:

> merge(a,b,by=1)     
  i  x  y
1 1  1 99
2 1 53 99
3 2  7 88
4 2  3 88
5 3  4 77
6 3 23 77
7 4  6 66
8 4  2 66


--
Philippe Glaziou



From a.trapletti at bluewin.ch  Wed Nov  5 12:52:11 2003
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Wed, 05 Nov 2003 12:52:11 +0100
Subject: [R] Cointegration
Message-ID: <3FA8E46B.4090702@bluewin.ch>

>
>
>In tseries, look for ?adf.test & ?pp.test.
>
These are standard unit-root tests and can only be used to test for 
cointegration indirectly. And then the critical values have to be 
adapted. A direct test for cointegration is po.test from tseries.

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erin Hodgess
>Sent: Wednesday, November 05, 2003 8:20 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Cointegration
>
>Do any packages exist for cointegration, please?
>
No. However, it is pretty simple to implement the Engle-Granger two-step 
procedure by using lm, embed, and maybe arima, together with one of the 
mentioned tests.

>
>Do we need them, if the answer to the previous is no, please?
>
It would be nice to have one, sure. In particular, the Johansen procedures.

>
>Thanks,
>Erin
>mailto: hodgess at gator.uhd.edu
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
best
Adrian

-- 
Dr. Adrian Trapletti
Trapletti Statistical Computing
Wildsbergstrasse 31, 8610 Uster
Switzerland
Phone & Fax : +41 (0) 1 994 5631
Mobile : +41 (0) 76 370 5631
Email : mailto:a.trapletti at bluewin.ch
WWW : http://trapletti.homelinux.com



From glaziou at pasteur-kh.org  Wed Nov  5 12:53:52 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 5 Nov 2003 18:53:52 +0700
Subject: [R] map does not display maps, MacOSX
In-Reply-To: <Pine.WNT.4.44.0311051132160.3584-100000@gannet.stats.ox.ac.uk>
References: <20031105111848.GA29829@pasteur-kh.org>
	<Pine.WNT.4.44.0311051132160.3584-100000@gannet.stats.ox.ac.uk>
Message-ID: <20031105115352.GV483@pasteur-kh.org>

Prof Brian D Ripley <ripley at stats.ox.ac.uk> wrote:
> Notice the // in the path
> 
> /Users/glaziou/Library/R/maps/mapdata//world.N
> 
> Some Windows filesystems do not like that, and my guess is that
> some MacOS X ones may not either.


I noticed that.  However, this does not to seem to bother MacOSX
too much (R internals on MacOSX may not like it):

madeleine:~> pwd
/Users/glaziou
madeleine:~> ls Library/R//maps//mapdata
county.G  nz.G  state.G  usa.G  world.G  world2.G  world2.N
county.L  nz.L  state.L  usa.L  world.L  world2.L
madeleine:~> cd Library///////R/maps//mapdata
madeleine:~/Library/R/maps/mapdata> pwd
/Users/glaziou/Library/R/maps/mapdata

--
Philippe



From gavin.simpson at ucl.ac.uk  Wed Nov  5 12:55:25 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 05 Nov 2003 11:55:25 +0000
Subject: [R] more barplot presentation questions
In-Reply-To: <5E06BFED29594F4C9C5EBE230DE320C62739C2@ewok.vsl.com.au>
References: <5E06BFED29594F4C9C5EBE230DE320C62739C2@ewok.vsl.com.au>
Message-ID: <3FA8E52D.7060507@ucl.ac.uk>

Hi Paul,

for the first question try ?grid

as in:

 > barplot(1:10)
 > grid(nx = NA, ny = NULL, col = "red")

nx = NA sets no lines on x-axis. ny = NULL draws lines from all tick 
marks on the y-axis.

HTH

Gav

Paul Sorenson wrote:

> Thanks to those who pointed me at the solutions to the legend
> overprinting the bars.  I took the "easy" way of rescaling the y
> axis, picking the scaling factor for stacked bars is somewhat
> problematic but sufficient for my application.
> 
> I have another couple of barplot questions:
> 
> - Can I extend the major ticks on the Y axis across the page?  Or
> both axes to form a grid?
> 
> - A really neat graph for me would be a combination of side-by-side
> and stacked bars in a single plot to display an additional category.
> 
> The background on the second problem is that I am displaying software
> defect metrics.  For each month (the bins) the categories of interest
> are: - new/fixed/closed - numeric severity (1 - 5)
> 
> I am currently displaying 5 separate graphs (6 when you take the
> aggregate into account) with new/fixed/closed side-by-side.  If
> within the side-by-side graphs I could show the severity stacked that
> would be very neat.
> 
> Cheers
> 
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From KKelley at nd.edu  Wed Nov  5 14:27:17 2003
From: KKelley at nd.edu (Ken Kelley)
Date: Wed, 05 Nov 2003 08:27:17 -0500
Subject: [R] Ignoring Errors in Simulations
Message-ID: <5.1.0.14.2.20031105080934.00c42bd0@imap-k.nd.edu>

Hello all.

I'm doing a simulation study and every so often I get an error that stops 
the simulation. I would like to ignore the errors *and* identify the 
particular iterations where they occurred. I have tried:

options(error = expression(NULL))

which I thought would ignore the error, but the simulation is still stopped 
when an error occurs. I do not think try() is a good idea because of the 
significant computational time (that I think) it would add.

Specifically I am using factanal() from the mva library and the error is:

Error in factanal(Data, factors = 1, rotation = "none") :
	Unable to optimize from these starting value(s)
-I am using R 1.7.1 on a Windows XP machine.

Although increasing the number of starting values attempted would reduces 
the number or errors, I'm looking for a way that they are ignored and these 
(likely) untrustworthy results identified.
Thanks for any thoughts,
Ken



From bolker at zoo.ufl.edu  Wed Nov  5 14:43:53 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 5 Nov 2003 08:43:53 -0500 (EST)
Subject: [R] using LSODA in R
In-Reply-To: <BAY2-F1414lDPHpNwqe00001c38@hotmail.com>
Message-ID: <Pine.LNX.4.44.0311050843100.2920-100000@bolker.zoo.ufl.edu>


  Try returning list(c(Rprime,Cprime,Pprime),NULL) -- the first element in 
the returned list should be a numeric *vector* of the derivatives.

  Ben  

On Tue, 4 Nov 2003, Ivan Kautter wrote:

> R help list subscribers,
> 
> I am a new user of R.  I am attempting to use R to explore a set of 
> equations specifying the dynamics of a three trophic level food chain.  I 
> have put together this code for the function that is to be evaluted by 
> LSODA.  My equations Rprime, Cprime, and Pprime are meant to describe the 
> actual equation of the derivative.  When I run LSODA, I do not get the 
> output that these equations should be giving.  Can someone tell me if I have 
> set this function up correctly to use with LSODA when the user is specifying 
> the equation of the derivative  or offer some advice for using LSODA in R? 
> An example of how to code for user specified differential equations would be 
> great.
> 
> function(times,y,p)
> {
> Rprime <- 
> (R*(1-R))-((xc*yc*C*R)/(R+R0))-((w*xp*ypr*P*R)/(R02+((1-w)*C)+(w*R)))
> Cprime <- 
> (-1*(xc*C)*(1-(yc*R)/(R+R0)))-(((1-w)*xp*ypc*P*C)/((w*R)+((1-w)*C)+C0))
> Pprime <- 
> (-1*P)-(((1-w)*xp*ypc*C*P)/((w*R)+((1-w)*C)+C0))+((w*xp*ypr*P*R)/((w*R)+((1-w)*C)+R02))
> list(c(Rprime, Cprime, Pprime))
> }
> 
> The above is the function yprime which the documentation for the odesolve 
> says that I may specify.
> 
> Thanks for any help that anyone can provide.
> 
> Ivan Kautter
> 
> _________________________________________________________________
> Compare high-speed Internet plans, starting at $26.95.  
> https://broadband.msn.com (Prices may vary by service area.)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From tblackw at umich.edu  Wed Nov  5 14:38:22 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 5 Nov 2003 08:38:22 -0500 (EST)
Subject: [R] Ignoring Errors in Simulations
In-Reply-To: <5.1.0.14.2.20031105080934.00c42bd0@imap-k.nd.edu>
References: <5.1.0.14.2.20031105080934.00c42bd0@imap-k.nd.edu>
Message-ID: <Pine.SOL.4.58.0311050835001.7258@asteroids.gpcc.itd.umich.edu>

Ken  -

Either test each simulated data set explicitly for the
condition which causes  factanal() to fail (perhaps rank
deficiency ?), or else use  try().  Which is quicker,
using  try() or restarting your simulation from the
beginning each time there's a failure ?

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 5 Nov 2003, Ken Kelley wrote:

> Hello all.
>
> I'm doing a simulation study and every so often I get an error that stops
> the simulation. I would like to ignore the errors *and* identify the
> particular iterations where they occurred. I have tried:
>
> options(error = expression(NULL))
>
> which I thought would ignore the error, but the simulation is still stopped
> when an error occurs. I do not think try() is a good idea because of the
> significant computational time (that I think) it would add.
>
> Specifically I am using factanal() from the mva library and the error is:
>
> Error in factanal(Data, factors = 1, rotation = "none") :
> 	Unable to optimize from these starting value(s)
> -I am using R 1.7.1 on a Windows XP machine.
>
> Although increasing the number of starting values attempted would reduces
> the number or errors, I'm looking for a way that they are ignored and these
> (likely) untrustworthy results identified.
> Thanks for any thoughts,
> Ken
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From bojaniss at poczta.onet.pl  Wed Nov  5 14:40:44 2003
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Wed, 5 Nov 2003 14:40:44 +0100
Subject: [R] Re: R-help Digest, Vol 9, Issue 5
In-Reply-To: <200311051113.hA5B3mQD001755@hypatia.math.ethz.ch>
References: <200311051113.hA5B3mQD001755@hypatia.math.ethz.ch>
Message-ID: <109277734.20031105144044@poczta.onet.pl>

Hello r-help-request,

I'm an email assistant of Mr Micha? Bojanowski.

On Wednesday, November 5, 2003, 12:13:12 PM, you emailed Mr Bojanowski
using address bojaniss at poczta.onet.pl. Unfortunately for you this
address is no longer used by Mr Micha? Bojanowski for his private
correspondence. If, nevertheless, you insist on contacting
Mr Bojanowski, please do it by other means of communication.

=================================================================

Witam r-help-request,

Jestem asystentk? Pana Micha?a Bojanowskiego d/s
obs?ugi poczty email.

Dnia 5 listopada 2003, 14:40:41, napisa?(a) Pan(i) email do Pana Bojanowskiego
u?ywaj?c adresu bojaniss at poczta.onet.pl. Niestety Pan Bojanowski
nie korzysta ju? z tego adresu dla swojej prywatnej korespondencji.
Je?eli zale?y Pan(i) na skontaktowaniu si? mimo to z Panem Bojanowskim
prosz? to uczyni? za pomoc? innych adres?w, ?rodk?w komunikacji.



From d.firth at warwick.ac.uk  Wed Nov  5 14:56:40 2003
From: d.firth at warwick.ac.uk (David Firth)
Date: Wed, 5 Nov 2003 13:56:40 +0000
Subject: [R] matching of arguments in ...?
Message-ID: <E1479E11-0F97-11D8-A143-000A95A6625E@warwick.ac.uk>

I am puzzled by this (with R --vanilla):

   > test <- function(formula, ...) lm(formula, ...)
   > test(1:4 ~ 1, offset=rep(1,4))
   Error in eval(expr, envir, enclos) : ..1 used in an incorrect 
context, no ... to look in
   >  test(1:4 ~ 1, weights=rep(1,4))
   Error in eval(expr, envir, enclos) : ..1 used in an incorrect 
context, no ... to look in
   >  test(1:4 ~ 1, x=TRUE)

   Call:
   lm(formula = formula, x = TRUE)

   Coefficients:
   (Intercept)
           2.5

Some arguments (such as x) seem to pass willingly through ..., while 
others (such as offset and weights) do not.  Same thing happens with 
glm.  I haven't experimented more widely.

Can some kind soul offer an explanation?

Thanks,
David

 > version
          _
platform powerpc-apple-darwin6.7.5
arch     powerpc
os       darwin6.7.5
system   powerpc, darwin6.7.5
status
major    1
minor    8.0
year     2003
month    10
day      08
language R



From igual at mat.uji.es  Wed Nov  5 15:03:30 2003
From: igual at mat.uji.es (Fuensanta Saura Igual)
Date: Wed,  5 Nov 2003 15:03:30 +0100
Subject: [R] question
Message-ID: <1068041010.3fa9033254c04@webmail.uji.es>



Dear all,

I was wondering if someone could tell me what function I must use to know how
long a computing problem has taken using R, I mean, I want to know the amount 
of time R has need to compute some certain task that has developed.

Could anyone answer this?

Thanks



From seanpor at acm.org  Wed Nov  5 14:42:41 2003
From: seanpor at acm.org (Sean O'Riordain)
Date: Wed, 05 Nov 2003 13:42:41 +0000
Subject: [R] Ignoring Errors in Simulations
In-Reply-To: <5.1.0.14.2.20031105080934.00c42bd0@imap-k.nd.edu>
References: <5.1.0.14.2.20031105080934.00c42bd0@imap-k.nd.edu>
Message-ID: <3FA8FE51.10100@acm.org>

?try



Ken Kelley wrote:
> Hello all.
> 
> I'm doing a simulation study and every so often I get an error that 
> stops the simulation. I would like to ignore the errors *and* identify 
> the particular iterations where they occurred. I have tried:
> 
> options(error = expression(NULL))
> 
> which I thought would ignore the error, but the simulation is still 
> stopped when an error occurs. I do not think try() is a good idea 
> because of the significant computational time (that I think) it would add.
> 
> Specifically I am using factanal() from the mva library and the error is:
> 
> Error in factanal(Data, factors = 1, rotation = "none") :
>     Unable to optimize from these starting value(s)
> -I am using R 1.7.1 on a Windows XP machine.
> 
> Although increasing the number of starting values attempted would 
> reduces the number or errors, I'm looking for a way that they are 
> ignored and these (likely) untrustworthy results identified.
> Thanks for any thoughts,
> Ken
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From MSchwartz at medanalytics.com  Wed Nov  5 15:13:13 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 05 Nov 2003 08:13:13 -0600
Subject: [R] question
In-Reply-To: <1068041010.3fa9033254c04@webmail.uji.es>
References: <1068041010.3fa9033254c04@webmail.uji.es>
Message-ID: <1068041593.13860.166.camel@localhost.localdomain>

On Wed, 2003-11-05 at 08:03, Fuensanta Saura Igual wrote:
> Dear all,
> 
> I was wondering if someone could tell me what function I must use to know how
> long a computing problem has taken using R, I mean, I want to know the amount 
> of time R has need to compute some certain task that has developed.
> 
> Could anyone answer this?
> 
> Thanks


See ?system.time

HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Wed Nov  5 15:46:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 14:46:26 +0000 (GMT)
Subject: [R] Ignoring Errors in Simulations
In-Reply-To: <5.1.0.14.2.20031105080934.00c42bd0@imap-k.nd.edu>
Message-ID: <Pine.LNX.4.44.0311051444140.1421-100000@gannet.stats>

On Wed, 5 Nov 2003, Ken Kelley wrote:

> I'm doing a simulation study and every so often I get an error that stops 
> the simulation. I would like to ignore the errors *and* identify the 
> particular iterations where they occurred. I have tried:
> 
> options(error = expression(NULL))
> 
> which I thought would ignore the error, but the simulation is still stopped 
> when an error occurs. I do not think try() is a good idea because of the 
> significant computational time (that I think) it would add.

There is no significant extra computational time.  Why do you think there 
would be?  And if there were, why would this be recommended on the help 
page for try?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ir1982 at u.washington.edu  Wed Nov  5 15:53:34 2003
From: ir1982 at u.washington.edu (Igor Roytberg)
Date: Wed, 5 Nov 2003 06:53:34 -0800
Subject: [R] Mean Significance
Message-ID: <005401c3a3ac$96e2bc50$79a88e8c@igor>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031105/e094a2c9/attachment.pl

From tlumley at u.washington.edu  Wed Nov  5 16:16:23 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 5 Nov 2003 07:16:23 -0800 (PST)
Subject: [R] matching of arguments in ...?
In-Reply-To: <E1479E11-0F97-11D8-A143-000A95A6625E@warwick.ac.uk>
References: <E1479E11-0F97-11D8-A143-000A95A6625E@warwick.ac.uk>
Message-ID: <Pine.A41.4.58.0311050703520.122020@homer01.u.washington.edu>

On Wed, 5 Nov 2003, David Firth wrote:

> I am puzzled by this (with R --vanilla):
>
>    > test <- function(formula, ...) lm(formula, ...)
>    > test(1:4 ~ 1, offset=rep(1,4))
>    Error in eval(expr, envir, enclos) : ..1 used in an incorrect
> context, no ... to look in
>    >  test(1:4 ~ 1, weights=rep(1,4))
>    Error in eval(expr, envir, enclos) : ..1 used in an incorrect
> context, no ... to look in
>    >  test(1:4 ~ 1, x=TRUE)
>
>    Call:
>    lm(formula = formula, x = TRUE)
>
>    Coefficients:
>    (Intercept)
>            2.5
>
> Some arguments (such as x) seem to pass willingly through ..., while
> others (such as offset and weights) do not.  Same thing happens with
> glm.  I haven't experimented more widely.
>
> Can some kind soul offer an explanation?

This is a historical legacy of someone trying to be too helpful.

In lm() and similar functions there are some arguments that are
interpreted as if they were quoted expressions and then are looked up in
data= and in the calling frame (actually in environment(formulas)).

So

 lm(y~x, offset=z, data=df)

will work if z is either a column of df or a variable floating free in the
calling frame.

In order to make this rather unnatural evaluation work, lm and model.frame
have to play tricks with these arguments: they are explicitly evaluated in
environment(formula), in this case the environment inside test().

This sort of thing is why some of us strongly recommend not having
implicit dynamic scoping on new modelling functions, so eg in the survey
package the syntax looks like
  svydesign(id=~id, weights=~w, data=df)
with explicit formulas.  The other option is explicitly quoted
expressions.


	-thomas



From brahm at alum.mit.edu  Wed Nov  5 16:24:42 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Wed, 5 Nov 2003 10:24:42 -0500
Subject: [R] R function help arranged in categorical order ?
References: <Law12-F73gS86aRZlz800007c0e@hotmail.com>
Message-ID: <16297.5690.142523.625697@arbres1a.fmr.com>

Neil Osborne <r_stuff_online at hotmail.com> wrote:
> Is any one aware of R help documentation that is aranged in functional
> categories for e.g.:
>   String manipulation
>   File I/O
>   Dataframe, List manipulation

There really oughta be.  Several people replied with ways to search the help,
but that assumes you know the specific task you want to perform, and the right
"keyword" to describe it.  Beginners often just want to learn what's available.

For a few functional categories there are "general" help pages, and you might
not easily stumble across them.  Here's a list I came up with recently.  Just
type e.g. "?Arithmetic" at the R prompt to learn about Arithmetic Operators.

?Arithmetic
?Comparison
?Control
?DateTimeClasses
?Defunct
?Deprecated
?Devices
?Extract     (same as ?Subscript)
?Foreign
?Logic
?Memory
?Paren
?Rdconv      (RdUtils page: Rdconv, Rd2dvi, Rd2txt, Sd2Rd)
?Special     (beta, gamma, choose, ...)
?Startup
?Syntax
?build       (PkgUtils page: R CMD build, R cmd check)
?connections (file, pipe, ...)
?pi          (Constants page: LETTERS, letters, month.abb, month.name, pi)

-- 
                              -- David Brahm (brahm at alum.mit.edu)



From allan at stats.uct.ac.za  Wed Nov  5 16:45:34 2003
From: allan at stats.uct.ac.za (allan clark)
Date: Wed, 05 Nov 2003 17:45:34 +0200
Subject: [R] package installation problems
Message-ID: <3FA91B1E.8E4D90D8@stats.uct.ac.za>

Hi

I have tried to install some of the packages from the CRAN packages
section.

I am running  a windows system.

I did the following: (for example...)

   1.downloaded the zip file (mgcv_0.9-5.tar) from
http://cran.r-project.org/src/contrib/PACKAGES.html#sm
   2.and saved it in the library folder of R
   3.unzipped the file into the same folder
   4.a folder named sm was created
   5.from within R I loaded the package by using library(mgcv)

Any help would be much appreciated.

From ripley at stats.ox.ac.uk  Wed Nov  5 16:51:09 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 15:51:09 +0000 (GMT)
Subject: [R] R function help arranged in categorical order ?
In-Reply-To: <16297.5690.142523.625697@arbres1a.fmr.com>
Message-ID: <Pine.LNX.4.44.0311051547150.1579-100000@gannet.stats>

On Wed, 5 Nov 2003, David Brahm wrote:

> Neil Osborne <r_stuff_online at hotmail.com> wrote:
> > Is any one aware of R help documentation that is aranged in functional
> > categories for e.g.:
> >   String manipulation
> >   File I/O
> >   Dataframe, List manipulation
> 
> There really oughta be.  Several people replied with ways to search the
> help, but that assumes you know the specific task you want to perform,
> and the right "keyword" to describe it.  Beginners often just want to
> learn what's available.

Well, as described in your quotation you need to know the `functional
categories' and help.start's search page does list the known `functional
categories' and will list under each one. So there really IS, not `oughta 
be',

Similarly help.search can list by categories, aka keywords.  Perhaps its 
help page needs to say where the list of standard keywords is.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From joehl at gmx.de  Wed Nov  5 16:57:07 2003
From: joehl at gmx.de (Jens =?ISO-8859-1?Q?Oehlschl=E4gel?=)
Date: Wed, 5 Nov 2003 16:57:07 +0100 (MET)
Subject: [R] How to represent pure linefeeds chr(10) under R for Windows
Message-ID: <6670.1068047827@www27.gmx.net>


I need to write out with write.table() a csv file allowing for line feeds
(pure chr(10)) as part of character field (not as a line seperator).

How can I do that?

Best regards


Jens Oehlschl?gel

--



From ripley at stats.ox.ac.uk  Wed Nov  5 16:57:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 15:57:53 +0000 (GMT)
Subject: [R] Mean Significance
In-Reply-To: <005401c3a3ac$96e2bc50$79a88e8c@igor>
Message-ID: <Pine.LNX.4.44.0311051552260.1579-100000@gannet.stats>

This is a multiple comparisons problem, so no.  You need to use TukeyHSD 
or the multcomp package.  You can test contrasts via t-tests only if you 
select they before looking at the data.

Time to consult a good book on the subject?

On Wed, 5 Nov 2003, Igor Roytberg wrote:

> If you determine the means of x treatments and see that one is larger
> than the others, can you use a sample normal to determine how
> statistically significant the difference is? or would contrasts by a
> better tool? How would one go about to do this in R?
> 
> Thanks for any help (since R is new to me),

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed Nov  5 16:58:42 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 05 Nov 2003 16:58:42 +0100
Subject: [R] package installation problems
In-Reply-To: <3FA91B1E.8E4D90D8@stats.uct.ac.za>
References: <3FA91B1E.8E4D90D8@stats.uct.ac.za>
Message-ID: <3FA91E32.6090608@statistik.uni-dortmund.de>

allan clark wrote:
> Hi
> 
> I have tried to install some of the packages from the CRAN packages
> section.


This is a FAQ. See the R for Windows FAQs, Section 3.1: "Can I install 
packages (libraries) in this version?"

BTW: Simply typing
   install.packages("mgcv")
should do the trick.

Uwe Ligges


> I am running  a windows system.
> 
> I did the following: (for example...)
> 
>    1.downloaded the zip file (mgcv_0.9-5.tar) from
> http://cran.r-project.org/src/contrib/PACKAGES.html#sm
>    2.and saved it in the library folder of R
>    3.unzipped the file into the same folder
>    4.a folder named sm was created
>    5.from within R I loaded the package by using library(mgcv)
> 
> Any help would be much appreciated.
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed Nov  5 17:00:41 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 16:00:41 +0000 (GMT)
Subject: [R] package installation problems
In-Reply-To: <3FA91B1E.8E4D90D8@stats.uct.ac.za>
Message-ID: <Pine.LNX.4.44.0311051558130.1579-100000@gannet.stats>

PLEASE do read the documentation.  See rw-FAQ Q3.1.

On Wed, 5 Nov 2003, allan clark wrote:

> I have tried to install some of the packages from the CRAN packages
> section.
> 
> I am running  a windows system.
> 
> I did the following: (for example...)
> 
>    1.downloaded the zip file (mgcv_0.9-5.tar) from
> http://cran.r-project.org/src/contrib/PACKAGES.html#sm

That is not a zip file, and you seem to be confusing mgcv and sm: mgcv 
comes with R so you don't need to install it (although you may now need to 
reinstall R).

>    2.and saved it in the library folder of R
>    3.unzipped the file into the same folder
>    4.a folder named sm was created
>    5.from within R I loaded the package by using library(mgcv)
> 
> Any help would be much appreciated.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Wed Nov  5 17:08:09 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 05 Nov 2003 10:08:09 -0600
Subject: [R] package installation problems
In-Reply-To: <3FA91B1E.8E4D90D8@stats.uct.ac.za>
References: <3FA91B1E.8E4D90D8@stats.uct.ac.za>
Message-ID: <1068048489.13860.195.camel@localhost.localdomain>

On Wed, 2003-11-05 at 09:45, allan clark wrote:
> Hi
> 
> I have tried to install some of the packages from the CRAN packages
> section.
> 
> I am running  a windows system.
> 
> I did the following: (for example...)
> 
>    1.downloaded the zip file (mgcv_0.9-5.tar) from


A .tar file is not a ZIP file. It is a Unix/Linux archive file format. 

Please read Windows FAQ 3.1 on installing packages under Windows.

http://cran.r-project.org/bin/windows/rw-FAQ.html

There are several ways to install CRAN packages within the Windows GUI,
either via menus or the command line, described there.

If you should elect to download the .zip file directly from CRAN at:

http://cran.r-project.org/bin/windows/contrib/

be sure that you are in the proper R version specific directory for the
Contributed packages. You can then use the RGui menu option to install
from a local zip file.

HTH,

Marc Schwartz



From Luis.Tito-de-Morais at ird.sn  Wed Nov  5 17:19:07 2003
From: Luis.Tito-de-Morais at ird.sn (Tito de Morais Luis)
Date: 05 Nov 2003 16:19:07 +0000
Subject: [R] editor argument in edit()
Message-ID: <1068049143.14578.237.camel@rap06.ird.sn>

Hi dear listers,

In R 1.7 under linux, if I try to edit a vector, it can be edit using
any editor:
z<- c(1,2,3,4)
edit(z) #opens vi
edit(z, editor="gnumeric") #opens "z" in gnumeric
edit(z, editor="gedit") #opens "z" in gedit

It is similar in Windows98 (R 1.8) :

edit(z) #opens z in notepad
edit(z, editor="C:\\Program Files\\Microsoft Office\\Office\\Excel.exe")
#opens z in excel

The behaviour is similar, yet in gnumeric the values are in separated
cells whereas in excel all z  (in fact c(1,2,3,4)) is in one cell.
 
But if I want to edit the results of a calculation:
data(USArrests)
prres <- prcomp(USArrests, scale = TRUE)

edit(prres$rotation, editor='gnumeric') #in linux it opens the R-editor,
not gnumeric

the same in windows:
edit(prres$rotation, editor="C:\\Program Files\\Microsoft
Office\\Office\\Excel.exe") #in windows runs the R editor, not excel

My questions are:

a) Is it possible to edit the result of a calculation (like
prres$rotation above) using an external spreadsheet program and not the
R-editor ?

b) If (a) is possible how can the data be edited in excel with one
single value per cell ?

c) If (a) is not possible, can the r-editor window be printed directly ?

Thank you for any help.

L. Tito

PS : I know that I can save results with write.table() and then open the
external file with any program. I just want to know if it is possible to
edit the results directly.

-- 
L. Tito de Morais
      UR RAP
   IRD de Dakar
      BP 1386
       Dakar
      S?n?gal

T?l.: + 221 849 33 31
Fax: +221 832 16 75
Courriel: tito at ird.sn



From ripley at stats.ox.ac.uk  Wed Nov  5 17:24:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 16:24:17 +0000 (GMT)
Subject: [R] How to represent pure linefeeds chr(10) under R for Windows
In-Reply-To: <6670.1068047827@www27.gmx.net>
Message-ID: <Pine.LNX.4.44.0311051621210.1714-100000@gannet.stats>

Use \n in the character string, if I understand you aright, as in

foo <-"a\nb"


On Wed, 5 Nov 2003, Jens Oehlschl?gel wrote:

> 
> I need to write out with write.table() a csv file allowing for line feeds
> (pure chr(10)) as part of character field (not as a line seperator).
> 
> How can I do that?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From knoblauch at lyon.inserm.fr  Wed Nov  5 17:28:08 2003
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Wed,  5 Nov 2003 17:28:08 +0100
Subject: [R] Multiple comparisons with a glm
Message-ID: <1068049688.3fa9251841c41@webmail.lyon.inserm.fr>

I've never seen anything written about multiple comparisons,
as in the multcomp package or with TukeyHSD, but using a glm. 
 Do such procedures exist?  Are they sensible?
Are there any packages in R that implement such comparisons?
Thank you.


-- 
Ken Knoblauch
Inserm U371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
Tel: +33 (0)4 72 91 34 77
Fax: +33 (0)4 72 91 34 61
Portable: 06 84 10 64 10
email: knoblauch at lyon.inserm.fr



From rab at nauticom.net  Wed Nov  5 17:50:43 2003
From: rab at nauticom.net (Rick Bilonick)
Date: Wed, 05 Nov 2003 11:50:43 -0500
Subject: [R] Transfer Function Estimation
Message-ID: <3FA92A63.9040006@nauticom.net>

Suppose you estimate the ARIMA(p,d,q) paramters for an input x[t] using 
the arima function. Is there an easy way to apply these values to the 
output y[t] for transfer function modeling? For example, if I estimate a 
(2,1,1) ARIMA for x[t] with ar(1) = 0.5882, ar(2) = -0.01517, and ma(1) 
= -0.9688, how can apply these to y[t] so I can then estimate the ccf 
between the two sets of pre-whitened values?

Rick B.



From zednikova at yahoo.com  Wed Nov  5 18:00:41 2003
From: zednikova at yahoo.com (Mirka Zednikova)
Date: Wed, 5 Nov 2003 09:00:41 -0800 (PST)
Subject: [R] fast nearest-neighbor for R?
Message-ID: <20031105170041.53417.qmail@web12302.mail.yahoo.com>

Is fast nearest-neighbor functionality available for
R?

I was thinking of something along the lines of what's
currently in S+SPATIALSTATS.

Thanks for any information anyone might have on this.

- MZ



From joehl at gmx.de  Wed Nov  5 18:05:34 2003
From: joehl at gmx.de (Jens =?ISO-8859-1?Q?Oehlschl=E4gel?=)
Date: Wed, 5 Nov 2003 18:05:34 +0100 (MET)
Subject: [R] How to represent pure linefeeds chr(10) under R for Windows
Message-ID: <22361.1068051934@www68.gmx.net>



Brian, Simon,

Thanks for your quick answers. Unfortunately neither \n nor \012 works.
Under R for Windows (tried on 1.8.0 and 1.5.1) they are automatically converted
to chr(13)+chr(10).

I need only chr(10) within my string column, and chr(13)+chr(10) at line
ends of the csv file. If it can't be solved within R, I could workaround by
substituting all chr(13)+chr(10) into chr(10) after writing the file using a
system() call. However, writing the files twice would be ugly and performance
reducing (I am writing an interface).

Any idea?

Best regards


Jens Oehlschl?gel

--



From B.Rowlingson at lancaster.ac.uk  Wed Nov  5 18:09:43 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 05 Nov 2003 17:09:43 +0000
Subject: [R] How to represent pure linefeeds chr(10) under R for Windows
In-Reply-To: <Pine.LNX.4.44.0311051621210.1714-100000@gannet.stats>
References: <Pine.LNX.4.44.0311051621210.1714-100000@gannet.stats>
Message-ID: <3FA92ED7.5080900@lancaster.ac.uk>

Prof Brian Ripley wrote:
> Use \n in the character string, if I understand you aright, as in
> 
> foo <-"a\nb"
> 

This produces a CSV file from write.table() with a line-break halfway 
through a record, thus:

"4"  4 "d"
"5"  5 "new
line"
"6"  6 "f"

  R will happily read.table() this back in again, but other packages may 
not be so obliging. OpenOffice spreadsheet makes a hash of it, sticking 
'line"' on a line on its own in the spreadsheet. I hope whatever Jens 
wants to do with these CSV files works!

Barry



From cougar3721 at yahoo.com  Wed Nov  5 18:10:03 2003
From: cougar3721 at yahoo.com (L Z)
Date: Wed, 5 Nov 2003 09:10:03 -0800 (PST)
Subject: [R] for help about R 
Message-ID: <20031105171003.32111.qmail@web14803.mail.yahoo.com>

 just want to ask the following
> > question:
> > > probit<-glm(y1~x1+x2-1,
> > family=binomial(link=probit))
> > Warning message:
> > fitted probabilities numerically 0 or 1 occurred
in:
> > glm.fit(x = X, y = Y,
> > weights = weights, start = start, etastart =
> > etastart,
> > why does that happen?



From aurora at ebi.ac.uk  Wed Nov  5 18:23:09 2003
From: aurora at ebi.ac.uk (Aurora Torrente)
Date: Wed, 05 Nov 2003 17:23:09 +0000
Subject: [R] Logical matrices
References: <3FA92A63.9040006@nauticom.net>
Message-ID: <3FA931FD.60301@ebi.ac.uk>

Hello,
I've been trying to work with 0-1 matrices as if they were logical, but 
using the logical operators doesn't produce what I need, for using the 
matrix B:

     [,1] [,2] [,3] [,4] [,5]
[1,]    1    0    1    0    0
[2,]    0    1    0    0    0
[3,]    0    0    1    0    1

gives me the following:

 > B[1,]<-B[1,] || B[3,]

 > B
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    1    1    1    1
[2,]    0    1    0    0    0
[3,]    0    0    1    0    1

instead of :

     [,1] [,2] [,3] [,4] [,5]
[1,]    1    0    1    0    1
[2,]    0    1    0    0    0
[3,]    0    0    1    0    1

which is what I need.
I've tried to convert it into a logical matrix, but the result was a vector:

 > C<-as.logical(B)
 > C
 [1]  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE 
FALSE  TRUE FALSE  TRUE

What could I do? Thanks for your help,

        Aurora



From andy_liaw at merck.com  Wed Nov  5 18:26:40 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 05 Nov 2003 12:26:40 -0500
Subject: [R] RE: [Rd] fast nearest-neighbor in R?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDCE@usrymx25.merck.com>

Please send such queries to R-help.

See if knn() in the "class" package (part of the VR bundle that is shipped
with R) does what you want.

Andy

> -----Original Message-----
> From: Mirka Zednikova [mailto:zednikova at yahoo.com] 
> Sent: Wednesday, November 05, 2003 11:58 AM
> To: r-devel at stat.math.ethz.ch
> Subject: [Rd] fast nearest-neighbor in R?
> 
> 
> Is fast nearest-neighbor functionality available in R?
> I was thinking of something along the lines of what's
> currently in S+SPATIALSTATS.
> 
> Thanks for any information anyone might have on this.
> 
> - MZ
> 
> ______________________________________________
> R-devel at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-devel
>



From veronica at icmc.usp.br  Wed Nov  5 18:26:01 2003
From: veronica at icmc.usp.br (veronica@icmc.usp.br)
Date: Wed,  5 Nov 2003 15:26:01 -0200
Subject: [R] How to call R from C?
Message-ID: <1068053161.3fa932a9c8481@xapacura.icmc.usp.br>



Hi. I Would like to know if it is possible to call R from C and how can I do 
it. There is any material about this or examples?

tanks for help,

Veronica.



From ligges at statistik.uni-dortmund.de  Wed Nov  5 18:38:18 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 05 Nov 2003 18:38:18 +0100
Subject: [R] Logical matrices
In-Reply-To: <3FA931FD.60301@ebi.ac.uk>
References: <3FA92A63.9040006@nauticom.net> <3FA931FD.60301@ebi.ac.uk>
Message-ID: <3FA9358A.2070606@statistik.uni-dortmund.de>

Aurora Torrente wrote:

> Hello,
> I've been trying to work with 0-1 matrices as if they were logical, but 
> using the logical operators doesn't produce what I need, for using the 
> matrix B:
> 
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    1    0    1    0    0
> [2,]    0    1    0    0    0
> [3,]    0    0    1    0    1
> 
> gives me the following:
> 
>  > B[1,]<-B[1,] || B[3,]


"||" doesn't work vectorized, but "|" does, therefore try:

  B[1,] <- B[1,] | B[3,]

and please read
  ?"|"

Uwe Ligges



>  > B
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    1    1    1    1    1
> [2,]    0    1    0    0    0
> [3,]    0    0    1    0    1
> 
> instead of :
> 
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    1    0    1    0    1
> [2,]    0    1    0    0    0
> [3,]    0    0    1    0    1
> 
> which is what I need.
> I've tried to convert it into a logical matrix, but the result was a 
> vector:
> 
>  > C<-as.logical(B)
>  > C
> [1]  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE 
> FALSE  TRUE FALSE  TRUE
> 
> What could I do? Thanks for your help,
> 
>        Aurora
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Wed Nov  5 18:44:35 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 05 Nov 2003 09:44:35 -0800
Subject: [R] Logical matrices
In-Reply-To: <3FA931FD.60301@ebi.ac.uk>
References: <3FA92A63.9040006@nauticom.net> <3FA931FD.60301@ebi.ac.uk>
Message-ID: <3FA93703.8040605@pdf.com>

      Please read 'help("|")':  "|" performs elementwise comparison, 
while "||" 'evaluates left to right examining only the first element of 
each vector.  Evaluation proceeds only until the result is determined.' 

      Consider the following: 

 > B <- cbind(diag(3), rep(0, 3), c(0,0,1))
 > B[1,3] <- 1
 > B[1,]|B[3,]
[1]  TRUE FALSE  TRUE FALSE  TRUE
 > B[1,]||B[3,]
[1] TRUE

      hope this helps.  spencer graves

Aurora Torrente wrote:

> Hello,
> I've been trying to work with 0-1 matrices as if they were logical, 
> but using the logical operators doesn't produce what I need, for using 
> the matrix B:
>
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    1    0    1    0    0
> [2,]    0    1    0    0    0
> [3,]    0    0    1    0    1
>
> gives me the following:
>
> > B[1,]<-B[1,] || B[3,]
>
> > B
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    1    1    1    1    1
> [2,]    0    1    0    0    0
> [3,]    0    0    1    0    1
>
> instead of :
>
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    1    0    1    0    1
> [2,]    0    1    0    0    0
> [3,]    0    0    1    0    1
>
> which is what I need.
> I've tried to convert it into a logical matrix, but the result was a 
> vector:
>
> > C<-as.logical(B)
> > C
> [1]  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE 
> FALSE  TRUE FALSE  TRUE
>
> What could I do? Thanks for your help,
>
>        Aurora
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From zeileis at ci.tuwien.ac.at  Wed Nov  5 18:45:55 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Wed, 5 Nov 2003 18:45:55 +0100
Subject: [R] Multiple comparisons with a glm
In-Reply-To: <1068049688.3fa9251841c41@webmail.lyon.inserm.fr>
References: <1068049688.3fa9251841c41@webmail.lyon.inserm.fr>
Message-ID: <200311051745.hA5HjuP2031759@thorin.ci.tuwien.ac.at>

On Wednesday 05 November 2003 17:28, Ken Knoblauch wrote:

> I've never seen anything written about multiple comparisons,
> as in the multcomp package or with TukeyHSD, but using a glm.
>  Do such procedures exist?  Are they sensible?
> Are there any packages in R that implement such comparisons?

simint() and simtest() both have methods for "glm" objects.

hth,
Z

> Thank you.



From GPetris at uark.edu  Wed Nov  5 18:45:50 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 5 Nov 2003 11:45:50 -0600 (CST)
Subject: [R] Logical matrices
In-Reply-To: <3FA931FD.60301@ebi.ac.uk> (message from Aurora Torrente on Wed, 
	05 Nov 2003 17:23:09 +0000)
References: <3FA92A63.9040006@nauticom.net> <3FA931FD.60301@ebi.ac.uk>
Message-ID: <200311051745.hA5HjoQ5009131@definetti.uark.edu>


consult the help page for ||

?"||"

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From ripley at stats.ox.ac.uk  Wed Nov  5 18:47:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 17:47:02 +0000 (GMT)
Subject: [R] How to represent pure linefeeds chr(10) under R for Windows
In-Reply-To: <22361.1068051934@www68.gmx.net>
Message-ID: <Pine.LNX.4.44.0311051745090.5625-100000@gannet.stats>

You must be writing a text file.  Use file("foo", "wb"), and sep="\r\n".

On Wed, 5 Nov 2003, Jens Oehlschl?gel wrote:

> Brian, Simon,
> 
> Thanks for your quick answers. Unfortunately neither \n nor \012 works.
> Under R for Windows (tried on 1.8.0 and 1.5.1) they are automatically
> converted to chr(13)+chr(10).
> 
> I need only chr(10) within my string column, and chr(13)+chr(10) at line
> ends of the csv file. If it can't be solved within R, I could workaround by
> substituting all chr(13)+chr(10) into chr(10) after writing the file using a
> system() call. However, writing the files twice would be ugly and performance
> reducing (I am writing an interface).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jgentry at jimmy.harvard.edu  Wed Nov  5 18:49:07 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed, 5 Nov 2003 12:49:07 -0500 (EST)
Subject: [R] How to call R from C?
In-Reply-To: <1068053161.3fa932a9c8481@xapacura.icmc.usp.br>
Message-ID: <Pine.SOL.4.20.0311051248440.3042-100000@santiam.dfci.harvard.edu>

> Hi. I Would like to know if it is possible to call R from C and how can I do 
> it. There is any material about this or examples?

You'll want to read through the "Writing R Extensions" document at:
http://cran.r-project.org/manuals.html

-J



From andy_liaw at merck.com  Wed Nov  5 18:57:47 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 05 Nov 2003 12:57:47 -0500
Subject: [R] Mean Significance
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDD2@usrymx25.merck.com>

As Prof. Ripley said, the test on contrast is valid only if you selected the
contrast before seeing the data.  Using the same data for both hypothesis
generation and hypothesis confirmation is extremely hazardous!

Andy

> From: Igor Roytberg [mailto:ir1982 at u.washington.edu] 
> 
> Hello,
> 
> If you determine the means of x treatments and see that one 
> is larger than the others, can you use a sample normal to 
> determine how statistically significant the difference is? or 
> would contrasts by a better tool? How would one go about to 
> do this in R?
> 
> Thanks for any help (since R is new to me),
> 
> Igor



From ggrothendieck at myway.com  Wed Nov  5 19:27:54 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed,  5 Nov 2003 13:27:54 -0500 (EST)
Subject: [R] save(iris,file="clipboard",ascii=TRUE)
Message-ID: <20031105182754.061D13976@mprdmxin.myway.com>



Is this a bug?  I thought that "clipboard" could always be substituted
for a filename when dealing with ASCII files.

> data(iris)
> save(iris,ascii=TRUE,file="clipboard")
Error in file(file, "wb") : `mode' for the clipboard must be `r' or `w'

Also this (where gclip is a utility found at unxutils.sourceforge.net
that copies its standard input to the clipboard):

> save(iris,ascii=TRUE,file="myiris.rda")
> system("cmd /c gclip < myiris.rda")
> load("clipboard")
Error in open.connection(con, "rb") : unable to open connection
In addition: Warning message:
cannot open compressed file `clipboard'




_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From tlumley at u.washington.edu  Wed Nov  5 19:47:17 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 5 Nov 2003 10:47:17 -0800 (PST)
Subject: [R] How to represent pure linefeeds chr(10) under R for Windows
In-Reply-To: <22361.1068051934@www68.gmx.net>
References: <22361.1068051934@www68.gmx.net>
Message-ID: <Pine.A41.4.58.0311051046130.118158@homer04.u.washington.edu>

On Wed, 5 Nov 2003, Jens [ISO-8859-1] Oehlschl?gel wrote:

>
>
> Brian, Simon,
>
> Thanks for your quick answers. Unfortunately neither \n nor \012 works.
> Under R for Windows (tried on 1.8.0 and 1.5.1) they are automatically converted
> to chr(13)+chr(10).
>

You may have to write as a binary file to get this to work. I would try
opening a binary file connection and passing it to write.csv, but that
might mess up the real line endings.

	-thomas



From Dipti.Kamdar at sun.com  Wed Nov  5 19:57:53 2003
From: Dipti.Kamdar at sun.com (Dipti Kamdar)
Date: Wed, 05 Nov 2003 10:57:53 -0800
Subject: [R] query on proxy settings for R.
Message-ID: <3FA94831.F053DE17@Sun.COM>

Hi,
I have R installed on SuSE.
I am trying to find out as to where is the proxy information
stored and how it is stored. 
I was trying to run the install.package("...")  command on
the R prompt and it complained that it could not find the URL
http://cran....
Thank you,
Dipti

-- 
--------------------------------------------------------------------
    /\       Dipti Kamdar                        
   \\ \      Solution Engineering     
  \ \\ /     Customer Advocacy & Solutions   
 / \/ / /           
/ /   \//\   Sun Microsystems, Inc.
\//\   / /   Phone:(650) 786-8907 / Internal: x88907
 / / /\ /    Email: dipti.kamdar at sun.com
  / \\ \     
   \ \\      
    \/



From ripley at stats.ox.ac.uk  Wed Nov  5 20:01:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 19:01:20 +0000 (GMT)
Subject: [R] save(iris,file="clipboard",ascii=TRUE)
In-Reply-To: <20031105182754.061D13976@mprdmxin.myway.com>
Message-ID: <Pine.LNX.4.44.0311051856290.23591-100000@gannet.stats>

As should be evident , you thought wrong (and you are thinking in the
blinkered Windows way, too).

On Windows, file() can take a filename "clipboard" in text mode only.
load() and save() are not using file(), but you could probably use it
explicitly in ASCII mode.

Don't assume your own errors are bugs in other peoples' work: it is 
discourteous.

On Wed, 5 Nov 2003, Gabor Grothendieck wrote:

> 
> 
> Is this a bug?  I thought that "clipboard" could always be substituted
> for a filename when dealing with ASCII files.
> 
> > data(iris)
> > save(iris,ascii=TRUE,file="clipboard")
> Error in file(file, "wb") : `mode' for the clipboard must be `r' or `w'
> 
> Also this (where gclip is a utility found at unxutils.sourceforge.net
> that copies its standard input to the clipboard):
> 
> > save(iris,ascii=TRUE,file="myiris.rda")
> > system("cmd /c gclip < myiris.rda")
> > load("clipboard")
> Error in open.connection(con, "rb") : unable to open connection
> In addition: Warning message:
> cannot open compressed file `clipboard'
> 
> 
> 
> 
> _______________________________________________
> No banners. No pop-ups. No kidding.
> Introducing My Way - http://www.myway.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ray at mcs.vuw.ac.nz  Wed Nov  5 20:17:09 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 6 Nov 2003 08:17:09 +1300 (NZDT)
Subject: [R] USA map
Message-ID: <200311051917.hA5JH96D024365@tahi.mcs.vuw.ac.nz>

> Ivar Herfindal <Ivar.Herfindal at bio.ntnu.no> wrote:
> 
> On Wed,  5 Nov 2003 11:28:42 +0100 (MET), Mathieu Ros 
> <mros at autan.toulouse.inra.fr> wrote:
> 
> >>>>>> "k" == kjetil  <kjetil at entelnet.bo> disait:
> >
> > <snip>
> > k> I also tried
> >
> > k>> map("worldHires","sweden")
> > k>> map("worldHires","denmark") # which comes out very small since it
> > k>                              # includes the Faroe k>                   
> > # islands properly faraway
> >
> > and, just to know, how would you do to plot *only* continental
> > denmark? The same applies for france, UK, ...
> >
> Hello
> 
> One simple way of doing it is to specify the xlim and ylim of your map, 
> e.g. library(maps)
> map('world', 'Norway', xlim=c(5, 33), ylim=c(55, 75))
> 
But the 'best' way is RTFM!
map("world", "Norway", exact=T)

Ray Brownrigg



From ripley at stats.ox.ac.uk  Wed Nov  5 20:24:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 19:24:49 +0000 (GMT)
Subject: [R] query on proxy settings for R.
In-Reply-To: <3FA94831.F053DE17@Sun.COM>
Message-ID: <Pine.LNX.4.44.0311051923590.23679-100000@gannet.stats>

RTFM, specifically ?download.file.

On Wed, 5 Nov 2003, Dipti Kamdar wrote:

> I have R installed on SuSE.
> I am trying to find out as to where is the proxy information
> stored and how it is stored. 

It is not `stored' it is looked up.

> I was trying to run the install.package("...")  command on
> the R prompt and it complained that it could not find the URL
> http://cran....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Wed Nov  5 20:39:00 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed,  5 Nov 2003 14:39:00 -0500 (EST)
Subject: [R] save(iris,file=
Message-ID: <20031105193900.48067399C@mprdmxin.myway.com>



I tried it using file and it seems to work for saving:

> data(iris)
> con <- file("clipboard","w")
> save(iris,ascii=T,file=con)
> close(con)
> readLines("clipboard")
... lengthy output follows which seems correct ...

but not for loading:

> con <- file("clipboard","r")
> load(con)
Error in load(con) : loading from connections not compatible with magic number

even though when I try it with real files then it works both ways:

> save(iris,ascii=T,file="myiris.rda")
> rm(iris)
> load("myiris.rda")
> ls()
... iris is back ...

--- 

Date: Wed, 5 Nov 2003 19:01:20 +0000 (GMT) 
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: Gabor Grothendieck <ggrothendieck at myway.com> 
Cc: <R-help at stat.math.ethz.ch> 
Subject: Re: [R] save(iris,file="clipboard",ascii=TRUE) 
 
As should be evident , you thought wrong (and you are thinking in the
blinkered Windows way, too).

On Windows, file() can take a filename "clipboard" in text mode only.
load() and save() are not using file(), but you could probably use it
explicitly in ASCII mode.

Don't assume your own errors are bugs in other peoples' work: it is 
discourteous.

On Wed, 5 Nov 2003, Gabor Grothendieck wrote:

> 
> 
> Is this a bug? I thought that "clipboard" could always be substituted
> for a filename when dealing with ASCII files.
> 
> > data(iris)
> > save(iris,ascii=TRUE,file="clipboard")
> Error in file(file, "wb") : `mode' for the clipboard must be `r' or `w'
> 
> Also this (where gclip is a utility found at unxutils.sourceforge.net
> that copies its standard input to the clipboard):
> 
> > save(iris,ascii=TRUE,file="myiris.rda")
> > system("cmd /c gclip < myiris.rda")
> > load("clipboard")
> Error in open.connection(con, "rb") : unable to open connection
> In addition: Warning message:
> cannot open compressed file `clipboard'



_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From ross at biostat.ucsf.edu  Wed Nov  5 20:49:49 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 05 Nov 2003 11:49:49 -0800
Subject: [R] Contributing to the R Extensions documentation
Message-ID: <1068061789.26104.82.camel@iron.libaux.ucsf.edu>

I thought there were some gaps in the R Extensions document; in
particular, I was left wondering how to create a list.  I think a
paragraph on it would be useful.

I would be happy to contribute the paragraph, but I'm not sure if
there's interest or what the procedure is.  Can anyone advise me?

Though I was looking at the 1.7.0 version, I just checked 1.8.0 and the
relevant section seems the same.

My ulterior motive is to discover if my understanding of lists is
actually correct :)
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Nov  5 19:04:14 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 5 Nov 2003 19:04:14 +0100 (CET)
Subject: [R] Multiple comparisons with a glm
In-Reply-To: <1068049688.3fa9251841c41@webmail.lyon.inserm.fr>
References: <1068049688.3fa9251841c41@webmail.lyon.inserm.fr>
Message-ID: <Pine.LNX.4.51.0311051859250.1869@artemis.imbe.med.uni-erlangen.de>


> I've never seen anything written about multiple comparisons,
> as in the multcomp package or with TukeyHSD, but using a glm.
>  Do such procedures exist?  Are they sensible?
> Are there any packages in R that implement such comparisons?

since version 0.4-0 in `multcomp':

 0.4-0 (13.08.2003)

        `simint' and `simtest' now have methods for `lm' and `glm'

But you are right that there is not much theory about it (at least to my
knowledge). The procedures in `multcomp' allow for inference
on parameter estimates which are, asymptotically, multivariate normal
with known correlation structure.

Best,

Torsten


> Thank you.
>
>
> --
> Ken Knoblauch
> Inserm U371
> Cerveau et Vision
> 18 avenue du Doyen Lepine
> 69675 Bron cedex
> France
> Tel: +33 (0)4 72 91 34 77
> Fax: +33 (0)4 72 91 34 61
> Portable: 06 84 10 64 10
> email: knoblauch at lyon.inserm.fr
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ray at mcs.vuw.ac.nz  Wed Nov  5 20:51:48 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 6 Nov 2003 08:51:48 +1300 (NZDT)
Subject: [R] map does not display maps, MacOSX
Message-ID: <200311051951.hA5Jpmtq024459@tahi.mcs.vuw.ac.nz>

Philippe Glaziou <glaziou at pasteur-kh.org> wrote:
> 
> I installed the maps and mapdata libraries on my R-1.8.0 on
> MacOSX 10.2.8 (jaguar on a powerbook G4), and failed to make the
> map function work properly:
> 
> 
> R : Copyright 2003, The R Development Core Team
> Version 1.8.0  (2003-10-08)
> [...]
> 
> > library(maps)
> > map()
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `/Users/glaziou/Library/R/maps/mapdata//world.N' 
> > map('usa')
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `/Users/glaziou/Library/R/maps/mapdata//usa.N' 
> > system('ls -l /Users/glaziou/Library/R/maps/mapdata')
> total 1796
> -rw-r--r--   1 root     staff      143902 Oct 14 11:30 county.G
> -rw-r--r--   1 root     staff      690260 Oct 14 11:30 county.L
> -rw-r--r--   1 root     staff         618 Oct 14 11:30 nz.G
> -rw-r--r--   1 root     staff       13040 Oct 14 11:30 nz.L
> -rw-r--r--   1 root     staff        2642 Oct 14 11:30 state.G
> -rw-r--r--   1 root     staff       96892 Oct 14 11:30 state.L
> -rw-r--r--   1 root     staff         282 Oct 14 11:30 usa.G
> -rw-r--r--   1 root     staff       58232 Oct 14 11:30 usa.L
> -rw-r--r--   1 root     staff       74434 Oct 14 11:30 world.G
> -rw-r--r--   1 root     staff      295152 Oct 14 11:30 world.L
> -rw-r--r--   1 root     staff       74434 Oct 14 11:30 world2.G
> -rw-r--r--   1 root     staff      295152 Oct 14 11:30 world2.L
> -rw-r--r--   1 root     staff       54832 Oct 14 11:30 world2.N
> 
Note the actual file requested (usa.N) doesn't actually exist!

> :
> 
> Any hint appreciated,
> 
I had this sort of problem on a Windows system, and had to add an extra
command into Makefile.win.  [Is there recognised such a thing as
Makefile.mac? I seem to recall there used to be, but it is not mentioned
in the latest R-exts.]

What you need to do is add the line:

	$(CP) ${*}.n ../inst/mapdata/${*}.N     # need this here for Mac

as the second line of the .gon.g: target in maps/src/Makefile.
[note the first character is a tab]

I'll fix this (and the //) in the next version.

Ray Brownrigg



From ripley at stats.ox.ac.uk  Wed Nov  5 21:06:38 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Nov 2003 20:06:38 +0000 (GMT)
Subject: [R] Contributing to the R Extensions documentation
In-Reply-To: <1068061789.26104.82.camel@iron.libaux.ucsf.edu>
Message-ID: <Pine.LNX.4.44.0311052004220.25018-100000@gannet.stats>

A list is just a vector of type VECSXP.
There IS a section called `Handling lists'.

I don't think the gap is in the `Writing R Extensions' document, maybe in 
your reading of it.

On Wed, 5 Nov 2003, Ross Boylan wrote:

> I thought there were some gaps in the R Extensions document; in
> particular, I was left wondering how to create a list.  I think a
> paragraph on it would be useful.
> 
> I would be happy to contribute the paragraph, but I'm not sure if
> there's interest or what the procedure is.  Can anyone advise me?
> 
> Though I was looking at the 1.7.0 version, I just checked 1.8.0 and the
> relevant section seems the same.
> 
> My ulterior motive is to discover if my understanding of lists is
> actually correct :)
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ross at biostat.ucsf.edu  Wed Nov  5 21:31:28 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 05 Nov 2003 12:31:28 -0800
Subject: [R] Contributing to the R Extensions documentation
In-Reply-To: <Pine.LNX.4.44.0311052004220.25018-100000@gannet.stats>
References: <Pine.LNX.4.44.0311052004220.25018-100000@gannet.stats>
Message-ID: <1068064288.26108.100.camel@iron.libaux.ucsf.edu>

On Wed, 2003-11-05 at 12:06, Prof Brian Ripley wrote:
> A list is just a vector of type VECSXP.
> There IS a section called `Handling lists'.
> 
> I don't think the gap is in the `Writing R Extensions' document, maybe in 
> your reading of it.
> 
That section discusses reading lists, not making them.

It also includes no explicit statement that the names of list items are
in the R_NamesSymbol attribute, nor instructions on how to create the
value that goes in that attribute (i.e., it should be a character vector
and its elements made with mkChar()).  (I'm also not sure how deep one
needs to use PROTECT, though that's a more general issue.)

There is no explicit statement that the elements of the list are
arbitrary SEXP's.

I also had the list[i] vs list[[i]] lurking in my mind, wondering how
that mapped to the C level constructs.  That is less central.

I'm not saying the clues aren't there; after all, I did work it out, I
think correctly.  I am saying that certain information would be better
stated explicitly rather than simply being open to inference from an
example.  And I am saying that an explicit example of constructing and
returning a list (with named members) would be useful, since that's a
common scenario.

> On Wed, 5 Nov 2003, Ross Boylan wrote:
> 
> > I thought there were some gaps in the R Extensions document; in
> > particular, I was left wondering how to create a list.  I think a
> > paragraph on it would be useful.
> > 
> > I would be happy to contribute the paragraph, but I'm not sure if
> > there's interest or what the procedure is.  Can anyone advise me?
> > 
> > Though I was looking at the 1.7.0 version, I just checked 1.8.0 and the
> > relevant section seems the same.
> > 
> > My ulterior motive is to discover if my understanding of lists is
> > actually correct :)
> > 
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From maj at stats.waikato.ac.nz  Wed Nov  5 21:45:35 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 06 Nov 2003 09:45:35 +1300
Subject: [R] ETA for 1.8.1 ?
Message-ID: <3FA9616F.1000902@stats.waikato.ac.nz>

When is version 1.8.1 likely to be released?

Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From luke at stat.uiowa.edu  Wed Nov  5 22:01:27 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Wed, 5 Nov 2003 15:01:27 -0600 (CST)
Subject: [R] query on proxy settings for R.
In-Reply-To: <3FA94831.F053DE17@Sun.COM>
Message-ID: <Pine.LNX.4.44.0311051459100.9648-100000@itasca.stat.uiowa.edu>

On Wed, 5 Nov 2003, Dipti Kamdar wrote:

> Hi,
> I have R installed on SuSE.
> I am trying to find out as to where is the proxy information
> stored and how it is stored. 
> I was trying to run the install.package("...")  command on
> the R prompt and it complained that it could not find the URL
> http://cran....
> Thank you,
> Dipti

If you are having proxy-related problems on SuSE this may be related
to the fact that SuSE shell startup scripts on your system may define
the environment variable no_proxy.  This was discussed in a thread back
in July; see for example

	https://stat.ethz.ch/pipermail/r-help/2003-July/035410.html

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From nlpace at remi.med.utah.edu  Wed Nov  5 22:07:08 2003
From: nlpace at remi.med.utah.edu (Nathan Leon Pace, MD, MStat)
Date: Wed, 5 Nov 2003 14:07:08 -0700
Subject: [R] R for various ports of linux
Message-ID: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>

To all:

I currently download the R binaries for Redhat 7.x Linux.

There is considerable turmoil in the vendors of Linux. Redhat 
apparently is changing it's business model to paid versions.

This might motivate my department to use a different vendor of Linux.

Is there anything predictable about which vendors/versions of Linux 
will have R binaries in the future?

Thanks,

Nathan

PS I looked at CRAN and didn't immediately find any info about the 
future.


Nathan Leon Pace, MD, MStat	Work:nlpace at bigpace.med.utah.edu
Department of Anesthesiology	Home:nlpaces at comcast.net
University of Utah			Work:801.581.6393
Salt Lake City, Utah			    Home:801.467.2925
					Fax:801.581.4367										Cell:801.558.3987



From kjetil at entelnet.bo  Wed Nov  5 22:33:25 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Wed, 05 Nov 2003 17:33:25 -0400
Subject: [R] R function help arranged in categorical order ?
In-Reply-To: <16297.5690.142523.625697@arbres1a.fmr.com>
Message-ID: <3FA93465.16972.4EA5C@localhost>

On 5 Nov 2003 at 10:24, David Brahm wrote:

> 
> For a few functional categories there are "general" help pages, and you might
> not easily stumble across them.  Here's a list I came up with recently.  Just
> type e.g. "?Arithmetic" at the R prompt to learn about Arithmetic Operators.
> 
> ?Arithmetic
> ?Comparison
> ?Control
> ?DateTimeClasses
> ?Defunct
> ?Deprecated
> ?Devices
> ?Extract     (same as ?Subscript)
> ?Foreign
> ?Logic
> ?Memory
> ?Paren
> ?Rdconv      (RdUtils page: Rdconv, Rd2dvi, Rd2txt, Sd2Rd)
> ?Special     (beta, gamma, choose, ...)
> ?Startup
> ?Syntax
> ?build       (PkgUtils page: R CMD build, R cmd check)
> ?connections (file, pipe, ...)
> ?pi          (Constants page: LETTERS, letters, month.abb, month.name, pi)
> 

Could this list be put easily visible in ome of the places refered at 
startup, like ?help, demo(), or in the first page of 
help.start()
?

Kjetil Halvorsen

> -- 
>                               -- David Brahm (brahm at alum.mit.edu)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jasont at indigoindustrial.co.nz  Wed Nov  5 23:05:12 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 06 Nov 2003 11:05:12 +1300
Subject: [R] R for various ports of linux
In-Reply-To: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
References: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
Message-ID: <3FA97418.3070704@indigoindustrial.co.nz>

Nathan Leon Pace, MD, MStat wrote:

> To all:
> 
> I currently download the R binaries for Redhat 7.x Linux.
> 
> There is considerable turmoil in the vendors of Linux. Redhat apparently 
> is changing it's business model to paid versions.
> 
> This might motivate my department to use a different vendor of Linux.
> 
> Is there anything predictable about which vendors/versions of Linux will 
> have R binaries in the future?

Short answer: build from source.  You won't regret it.

Long answer:
The "build from source" approach is remarkably painless under any Linux 
distribution I've tried (RH, SuSE, Slackware, et. al.).  It's also 
painless under Solaris.

The days of having to be a programmer to build R from source have been 
over for years.  If you're computer literate enough to use R, you're 
probably over-qualified to build from sources.

Kudos to R-core for their attention to detail in making what's 
complicated "under the hood" quite simple for the end user.

Alternate answer:
If you absolutely must have binaries, there will be binaries as long as 
there are users of your OS with time they wish to commit to building 
them.  This may be where your sysadmin steps in :)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From p.dalgaard at biostat.ku.dk  Wed Nov  5 23:15:55 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Nov 2003 23:15:55 +0100
Subject: [R] ETA for 1.8.1 ?
In-Reply-To: <3FA9616F.1000902@stats.waikato.ac.nz>
References: <3FA9616F.1000902@stats.waikato.ac.nz>
Message-ID: <x2n0ba797o.fsf@biostat.ku.dk>

Murray Jorgensen <maj at stats.waikato.ac.nz> writes:

> When is version 1.8.1 likely to be released?

Soon. I had a preliminary proposition for Nov.14 (internal to R-core),
but then I got this nasty cold.... We do need to give package
maintainers (esp. of recommended packages) fair warning, so we
probably need to delay it for a week or so.

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From bolker at zoo.ufl.edu  Wed Nov  5 23:29:05 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 5 Nov 2003 17:29:05 -0500 (EST)
Subject: [R] R for various ports of linux
In-Reply-To: <3FA97418.3070704@indigoindustrial.co.nz>
Message-ID: <Pine.LNX.4.44.0311051727010.3401-100000@bolker.zoo.ufl.edu>


  I've always built from source and almost never had to do anything beyond 
"tar zxf sources.tgz; ./configure; make; make install" (on various Red Hat 
versions).  On the other hand ... I've been hoping to move in the 
direction of an apt- or rpm-based solution to get a better handle on 
tracking package versions etc. etc. across multiple machines ...  It does 
seem as though the Debian folks (Eddelbuettel [sp]?) are very quick about 
packaging apt versions ...

   Ben

On Thu, 6 Nov 2003, Jason Turner wrote:

> Nathan Leon Pace, MD, MStat wrote:
> 
> > To all:
> > 
> > I currently download the R binaries for Redhat 7.x Linux.
> > 
> > There is considerable turmoil in the vendors of Linux. Redhat apparently 
> > is changing it's business model to paid versions.
> > 
> > This might motivate my department to use a different vendor of Linux.
> > 
> > Is there anything predictable about which vendors/versions of Linux will 
> > have R binaries in the future?
> 
> Short answer: build from source.  You won't regret it.
> 
> Long answer:
> The "build from source" approach is remarkably painless under any Linux 
> distribution I've tried (RH, SuSE, Slackware, et. al.).  It's also 
> painless under Solaris.
> 
> The days of having to be a programmer to build R from source have been 
> over for years.  If you're computer literate enough to use R, you're 
> probably over-qualified to build from sources.
> 
> Kudos to R-core for their attention to detail in making what's 
> complicated "under the hood" quite simple for the end user.
> 
> Alternate answer:
> If you absolutely must have binaries, there will be binaries as long as 
> there are users of your OS with time they wish to commit to building 
> them.  This may be where your sysadmin steps in :)
> 
> Cheers
> 
> Jason
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From MSchwartz at medanalytics.com  Wed Nov  5 23:21:57 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 05 Nov 2003 16:21:57 -0600
Subject: [R] R for various ports of linux
In-Reply-To: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
References: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
Message-ID: <1068070917.13860.466.camel@localhost.localdomain>

On Wed, 2003-11-05 at 15:07, Nathan Leon Pace, MD, MStat wrote:
> To all:
> 
> I currently download the R binaries for Redhat 7.x Linux.
> 
> There is considerable turmoil in the vendors of Linux. Redhat 
> apparently is changing it's business model to paid versions.
> 
> This might motivate my department to use a different vendor of Linux.
> 
> Is there anything predictable about which vendors/versions of Linux 
> will have R binaries in the future?
> 
> Thanks,
> 
> Nathan
> 
> PS I looked at CRAN and didn't immediately find any info about the 
> future.


At the risk of raising the spectre of a heated discussion, you can
always download the source code for R and compile it locally, which is
what I have been doing for some time. 

That approach also avails you of the updated R-Patched versions, as
opposed to waiting for the next formal release binary version for bug
fixes.

There is a considerable amount of turmoil right now in the commercial
Linux arena and much energy is being expended in the debate. Given the
acquisition of SUSE by Novell/Ximian (with a notable investment by IBM)
this week, that has thrown much of the commercial Linux world market
into a frenzy. You can read Slashdot or other forums to gain a sense of
the spectrum of opinions on this deal.

That activity has prompted some to speculate on when Mandrake will be
acquired given their fragile financial state.

Combine this all with RH's change in direction with the Enterprise arm
of products versus Fedora Core 1 (which went to release today), that has
further aggravated the debate regarding the cost of paid support,
community based distros versus commercial, etc. Fedora Core will be RH's
free community based distro moving forward. If you want/need paid
support from RH, then RHEL is your option there.

Needless to say, Debian is very much still there as well.

Each end-user organization will need to assess its own needs and which
distro meets those needs. It is clear that the commercial entities are
looking to find ways to remain financially viable, while still
attempting to gain market share and evolve.  

Time will tell where it all goes. That time interval will more than
likely be measured in years, not weeks or months.

HTH,

Marc Schwartz



From ivankautter at hotmail.com  Wed Nov  5 23:55:52 2003
From: ivankautter at hotmail.com (Ivan Kautter)
Date: Wed, 05 Nov 2003 14:55:52 -0800
Subject: [R] using LSODA in R
Message-ID: <BAY2-F973W3Nz7XKGbo0001d56d@hotmail.com>

Thanks for the response, Ben.

It's not a case that the list isn't coming out correctly.  It's that the 
numbers that are coming out are not the numbers that these equations should 
be producing if I have specified the equations correctly in R code for use 
with LSODA.  So the question is more if I have the code right when the user 
specifies the differential equations for LSODA.


>From: Ben Bolker <bolker at zoo.ufl.edu>
>Reply-To: bolker at zoo.ufl.edu
>To: Ivan Kautter <ivankautter at hotmail.com>
>CC: R help list <r-help at stat.math.ethz.ch>
>Subject: Re: [R] using LSODA in R
>Date: Wed, 5 Nov 2003 08:43:53 -0500 (EST)
>
>
>   Try returning list(c(Rprime,Cprime,Pprime),NULL) -- the first element in
>the returned list should be a numeric *vector* of the derivatives.
>
>   Ben
>
>On Tue, 4 Nov 2003, Ivan Kautter wrote:
>
> > R help list subscribers,
> >
> > I am a new user of R.  I am attempting to use R to explore a set of
> > equations specifying the dynamics of a three trophic level food chain.  
>I
> > have put together this code for the function that is to be evaluted by
> > LSODA.  My equations Rprime, Cprime, and Pprime are meant to describe 
>the
> > actual equation of the derivative.  When I run LSODA, I do not get the
> > output that these equations should be giving.  Can someone tell me if I 
>have
> > set this function up correctly to use with LSODA when the user is 
>specifying
> > the equation of the derivative  or offer some advice for using LSODA in 
>R?
> > An example of how to code for user specified differential equations 
>would be
> > great.
> >
> > function(times,y,p)
> > {
> > Rprime <-
> > (R*(1-R))-((xc*yc*C*R)/(R+R0))-((w*xp*ypr*P*R)/(R02+((1-w)*C)+(w*R)))
> > Cprime <-
> > (-1*(xc*C)*(1-(yc*R)/(R+R0)))-(((1-w)*xp*ypc*P*C)/((w*R)+((1-w)*C)+C0))
> > Pprime <-
> > 
>(-1*P)-(((1-w)*xp*ypc*C*P)/((w*R)+((1-w)*C)+C0))+((w*xp*ypr*P*R)/((w*R)+((1-w)*C)+R02))
> > list(c(Rprime, Cprime, Pprime))
> > }
> >
> > The above is the function yprime which the documentation for the 
>odesolve
> > says that I may specify.
> >
> > Thanks for any help that anyone can provide.
> >
> > Ivan Kautter
> >
> > _________________________________________________________________
> > Compare high-speed Internet plans, starting at $26.95.
> > https://broadband.msn.com (Prices may vary by service area.)
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>--
>620B Bartram Hall                            bolker at zoo.ufl.edu
>Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
>Box 118525                                   (ph)  352-392-5697
>Gainesville, FL 32611-8525                   (fax) 352-392-3704
>

_________________________________________________________________
Compare high-speed Internet plans, starting at $26.95.  
https://broadband.msn.com (Prices may vary by service area.)



From rossini at blindglobe.net  Wed Nov  5 23:55:58 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 05 Nov 2003 14:55:58 -0800
Subject: [R] R for various ports of linux
In-Reply-To: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
	(Nathan Leon Pace's message of "Wed, 5 Nov 2003 14:07:08 -0700")
References: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
Message-ID: <85oevqo269.fsf@blindglobe.net>

"Nathan Leon Pace, MD, MStat" <nlpace at remi.med.utah.edu> writes:

> To all:
>
> I currently download the R binaries for Redhat 7.x Linux.
>
> There is considerable turmoil in the vendors of Linux. Redhat
> apparently is changing it's business model to paid versions.
>
> This might motivate my department to use a different vendor of Linux.
>
> Is there anything predictable about which vendors/versions of Linux
> will have R binaries in the future?

While many people have commented on building from source, I'll state
that's fine, but it gets old after the 10,000th time.   Sure, it's
amusing, and you get a great pleasure jolt from debugging on novel
platforms and configurations, but it's not real work.

One strategy is to find a distribution where the R maintainer is
someone you trust.

I trust Doug and Dirk (and hence Debian).

best,
-tony 

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From bates at stat.wisc.edu  Thu Nov  6 00:26:47 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 05 Nov 2003 17:26:47 -0600
Subject: [R] R for various ports of linux
In-Reply-To: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
References: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
Message-ID: <6rn0baieh4.fsf@bates4.stat.wisc.edu>

"Nathan Leon Pace, MD, MStat" <nlpace at remi.med.utah.edu> writes:

> I currently download the R binaries for Redhat 7.x Linux.
> 
> There is considerable turmoil in the vendors of Linux. Redhat
> apparently is changing it's business model to paid versions.
> 
> 
> This might motivate my department to use a different vendor of Linux.
> 
> Is there anything predictable about which vendors/versions of Linux
> will have R binaries in the future?

Debian, and hence Knoppix, will continue to have R binaries.  

For those who are considering switching Linux distributions I would
strongly recommend looking at Knoppix 3.3
(http://www.knopper.net/knoppix/ although for the next few weeks you
will need to click through to
http://www.knopper.net/knoppix/index-old-en.html ) and Dirk
Eddelbuettel's Quantian (http://dirk.eddelbuettel.com/quantian/) which
is based on Knoppix and contains the binaries of all R and Octave
packages as part of the distribution.  Dirk maintains the Debian
packages of R and Octave packages and usually has binary Debian
packages uploaded within a day of a new R release.  (Well technically
Dirk and I are co-maintainers of the R packages for Debian but in
practice it is about 92% Dirk and 8% Doug doing the maintaining.)

If you have never used Knoppix or Quantian you find it astonishing
when you first try it out.  You download one CD-ROM image, burn it
onto a CD and boot from the CD.  Next thing you know you have a
working system.

Dirk presented a paper on Quantian at DSC-2003.  See

http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Proceedings/Eddelbuettel.pdf



From baron at psych.upenn.edu  Thu Nov  6 01:19:54 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 5 Nov 2003 19:19:54 -0500
Subject: [R] R for various ports of linux
In-Reply-To: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
References: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
Message-ID: <20031106001954.GA11493@mail2.sas.upenn.edu>

>Is there anything predictable about which vendors/versions of Linux 
>will have R binaries in the future?

No.

But, for what it is worth, the RPM for RedHat 9 installs
perfectly on Fedora Severn beta.  This is the closest thing to
Red Hat 10, and I'm going to stick with Fedora unless I learn
that their security announcements are slower than some other
distribution.  In the past, Red Hat has been first almost all the
time to make patches available.  I hope that continues with
Fedora, but we will see.

Jon



From ggrothendieck at myway.com  Thu Nov  6 01:26:16 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed,  5 Nov 2003 19:26:16 -0500 (EST)
Subject: [R] save(iris,file=
Message-ID: <20031106002616.4C8763987@mprdmxin.myway.com>



I have played around with this some more and although I still do
not have a solution for loading an .rda file from the Windows
clipboard that is entirely R, with the help of the
pclip utility found at unxutils.sourceforge.net this seems
to work:

> load(pipe("pclip"))

---
 
Date: Wed, 5 Nov 2003 14:39:00 -0500 (EST) 
From: Gabor Grothendieck <ggrothendieck at myway.com>
To: <ripley at stats.ox.ac.uk>, <ggrothendieck at myway.com> 
Cc: <R-help at stat.math.ethz.ch> 
Subject: Re: [R] save(iris,file= 

I tried it using file and it seems to work for saving:

> data(iris)
> con <- file("clipboard","w")
> save(iris,ascii=T,file=con)
> close(con)
> readLines("clipboard")
... lengthy output follows which seems correct ...

but not for loading:

> con <- file("clipboard","r")
> load(con)
Error in load(con) : loading from connections not compatible with magic number

even though when I try it with real files then it works both ways:

> save(iris,ascii=T,file="myiris.rda")
> rm(iris)
> load("myiris.rda")
> ls()
... iris is back ...

--- 

Date: Wed, 5 Nov 2003 19:01:20 +0000 (GMT) 
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: Gabor Grothendieck <ggrothendieck at myway.com> 
Cc: <R-help at stat.math.ethz.ch> 
Subject: Re: [R] save(iris,file="clipboard",ascii=TRUE) 

As should be evident , you thought wrong (and you are thinking in the
blinkered Windows way, too).

On Windows, file() can take a filename "clipboard" in text mode only.
load() and save() are not using file(), but you could probably use it
explicitly in ASCII mode.

Don't assume your own errors are bugs in other peoples' work: it is 
discourteous.

On Wed, 5 Nov 2003, Gabor Grothendieck wrote:

> 
> 
> Is this a bug? I thought that "clipboard" could always be substituted
> for a filename when dealing with ASCII files.
> 
> > data(iris)
> > save(iris,ascii=TRUE,file="clipboard")
> Error in file(file, "wb") : `mode' for the clipboard must be `r' or `w'
> 
> Also this (where gclip is a utility found at unxutils.sourceforge.net
> that copies its standard input to the clipboard):
> 
> > save(iris,ascii=TRUE,file="myiris.rda")
> > system("cmd /c gclip < myiris.rda")
> > load("clipboard")
> Error in open.connection(con, "rb") : unable to open connection
> In addition: Warning message:
> cannot open compressed file `clipboard'


_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From vograno at sbcglobal.net  Thu Nov  6 02:24:31 2003
From: vograno at sbcglobal.net (Vadim Ogranovich)
Date: Wed, 5 Nov 2003 17:24:31 -0800
Subject: [R] building r-patch
Message-ID: <000101c3a404$bf7c6190$f5fea8c0@VOGRANO>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031105/21d75b01/attachment.pl

From edd at debian.org  Thu Nov  6 03:12:33 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 5 Nov 2003 20:12:33 -0600
Subject: [R] building r-patch
In-Reply-To: <000101c3a404$bf7c6190$f5fea8c0@VOGRANO>
References: <000101c3a404$bf7c6190$f5fea8c0@VOGRANO>
Message-ID: <20031106021233.GA2123@sonny.eddelbuettel.com>


Hi Vadim,

On Wed, Nov 05, 2003 at 05:24:31PM -0800, Vadim Ogranovich wrote:
> I am building r-patch from the sources (rsync-ed today).
[...]
> Other questions are related to building of recommended packages:
> * The src/library/Recommended directory was empty. Is it expected? If
> yes, how to download the entire bundle of recommended packages (I know I

Execute the script

	$ src/tools/recommended-rsync

which fetch them for you. I call that each time I create Debian packages of
pre-releases, or of patch releases (as so far on 10/24 and 11/01).

Cheers, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From jasont at indigoindustrial.co.nz  Thu Nov  6 05:50:17 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 06 Nov 2003 17:50:17 +1300
Subject: [R] building r-patch
In-Reply-To: <000101c3a404$bf7c6190$f5fea8c0@VOGRANO>
References: <000101c3a404$bf7c6190$f5fea8c0@VOGRANO>
Message-ID: <3FA9D309.7070407@indigoindustrial.co.nz>

Vadim Ogranovich wrote:
...
> I am building r-patch from the sources (rsync-ed today).
>  
> make check produced the following message:
>  
> running tests of Internet and socket functions
>   expect some differences
...  assorted error messages, then ...
>  OK
>     
>  
>  
> I noticed that I had to expect some differences so my question is how to
> tell whether it's harmless or not?

The "OK".  If made exited without an error, the regression tests were 
passed.  In this case, the differences between the maintainers' results 
and yours were due to local login and network setup differences.

Hope that helps

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From umeno at students.uiuc.edu  Thu Nov  6 06:33:33 2003
From: umeno at students.uiuc.edu (umeno)
Date: Wed, 5 Nov 2003 23:33:33 -0600
Subject: [R] Number of Days
Message-ID: <3FC6B09D@webmail.uiuc.edu>

Hi everyone,

I have been trying to compute numbers of days between two dates as follows:

> x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
> z <- format(x, "%d%b%Y")
> ex <- c("1jan1961", "15jan1960", "21mar1975", "10jul1981")
> ez <- format(ex, "%d%b%Y")
> ez-z
Error in ez - z : non-numeric argument to binary operator

As you may see, I am getting an error.  Can anyone tell me how I can convert z 
and ez to numeric vectors, so that I can compute days between the 
corresponding dates in these vectors?

thank you
soyoko

______________________________________
Ms. Soyoko Umeno
Graduate Research Assitant for the Illinois-Missouri Biotechnology Alliance (IMBA) at http://www.imba.missouri.edu/
Ph.D. Student at the Department of Agricultural and Consumer Economics
at the University of Illinois at Urbana-Champaign
Office Phone: 217-333-3417 or 217-333-0364
Fax: 217-244-4817
Mailing Address: 1301 W. Gregory Dr. MC710, Urbana, IL 61801



From jarioksa at sun3.oulu.fi  Thu Nov  6 07:13:42 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 06 Nov 2003 08:13:42 +0200
Subject: [R] USA map
In-Reply-To: <200311051917.hA5JH96D024365@tahi.mcs.vuw.ac.nz>
References: <200311051917.hA5JH96D024365@tahi.mcs.vuw.ac.nz>
Message-ID: <1068099221.27790.6.camel@biol102145.oulu.fi>

On Wed, 2003-11-05 at 21:17, Ray Brownrigg wrote:
> > Ivar Herfindal <Ivar.Herfindal at bio.ntnu.no> wrote:
> > 
> > On Wed,  5 Nov 2003 11:28:42 +0100 (MET), Mathieu Ros 
> > <mros at autan.toulouse.inra.fr> wrote:
> > 
> > >>>>>> "k" == kjetil  <kjetil at entelnet.bo> disait:
> > >
> > > <snip>
> > > k> I also tried
> > >
> > > k>> map("worldHires","sweden")
> > > k>> map("worldHires","denmark") # which comes out very small since it
> > > k>                              # includes the Faroe k>                   
> > > # islands properly faraway
> > >
> > > and, just to know, how would you do to plot *only* continental
> > > denmark? The same applies for france, UK, ...
> > >
> > Hello
> > 
> > One simple way of doing it is to specify the xlim and ylim of your map, 
> > e.g. library(maps)
> > map('world', 'Norway', xlim=c(5, 33), ylim=c(55, 75))
> > 
> But the 'best' way is RTFM!
> map("world", "Norway", exact=T)
> 
Actually this not a good way, since then you have to trust CIA and its
naming conventions. All large coastal islands are left out (Lofoten
etc), although for some peculiar reason, Troms? seems to be there.
However, even continental parts of eastern Finmark are excluded (I hope
this does not have political implications). Just compare the following
maps:

map("worldHires","Norway", exact=TRUE, type="n")
map("worldHires","Norway", add=TRUE)
map("worldHires","Norway", add=TRUE, exact=TRUE, col="red")

By the way, where is Estonia? Couln't find it with any strings I could
imagine. Some R core developers have frequented Estonia, so it would be
nice to have that in the map.

cheers, jari oksanen
-- 
Jari Oksanen -- Biologian laitos, Oulun yliopisto, 90014 Oulu
Puh. (08) 553 1526, k?si 040 5136529, fax (08) 553 1061
sposti jari.oksanen at oulu.fi, kotisivu http://cc.oulu.fi/~jarioksa/



From h.wickham at auckland.ac.nz  Thu Nov  6 07:18:28 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Thu, 06 Nov 2003 19:18:28 +1300
Subject: [R] R function help arranged in categorical order ?
In-Reply-To: <Pine.LNX.4.44.0311051547150.1579-100000@gannet.stats>
References: <Pine.LNX.4.44.0311051547150.1579-100000@gannet.stats>
Message-ID: <3FA9E7B4.2050002@auckland.ac.nz>


>Similarly help.search can list by categories, aka keywords.  Perhaps its 
>help page needs to say where the list of standard keywords is.
>
>  
>
But to list all the help pages in a given "category", you need to use 
help.search(keyword="iplot",agrep=FALSE,package="base")
or is there an easier way?

Hadley



From vograno at evafunds.com  Thu Nov  6 07:41:45 2003
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed, 5 Nov 2003 22:41:45 -0800
Subject: [R] building r-patch
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A50C3976@phost015.intermedia.net>

I thought about the "OK". However the MASS and the survival tests
printed "OK" too, though, as far as I could tell, the packages were not
installed at all (well, maybe this was the reason for calling it "OK")

Thank you for the answer. Now I think I can move forward,
Vadim

> -----Original Message-----
> From: Jason Turner [mailto:jasont at indigoindustrial.co.nz] 
> Sent: Wednesday, November 05, 2003 8:50 PM
> To: vograno at yahoo.com
> Cc: R-Help
> Subject: Re: [R] building r-patch
> 
> 
> Vadim Ogranovich wrote:
> ...
> > I am building r-patch from the sources (rsync-ed today).
> >  
> > make check produced the following message:
> >  
> > running tests of Internet and socket functions
> >   expect some differences
> ...  assorted error messages, then ...
> >  OK
> >     
> >  
> >  
> > I noticed that I had to expect some differences so my 
> question is how 
> > to tell whether it's harmless or not?
> 
> The "OK".  If made exited without an error, the regression tests were 
> passed.  In this case, the differences between the 
> maintainers' results 
> and yours were due to local login and network setup differences.
> 
> Hope that helps
> 
> Jason
> -- 
> Indigo Industrial Controls Ltd. 
> http://www.indigoindustrial.co.nz 64-21-343-> 545 
> jasont at indigoindustrial.co.nz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From ripley at stats.ox.ac.uk  Thu Nov  6 08:10:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Nov 2003 07:10:26 +0000 (GMT)
Subject: [R] building r-patch
In-Reply-To: <000101c3a404$bf7c6190$f5fea8c0@VOGRANO>
Message-ID: <Pine.LNX.4.44.0311060707300.26300-100000@gannet.stats>

The first is more or less what you should expect.

On Wed, 5 Nov 2003, Vadim Ogranovich wrote:

> Hi,
>  
> I am building r-patch from the sources (rsync-ed today).
>  
> make check produced the following message:
>  
> running tests of Internet and socket functions
>   expect some differences
> make[3]: Entering directory `/usr/evahome/vograno/R/tests'
> running code in 'internet.R' ... OK
> comparing 'internet.Rout' to './internet.Rout.save' ...18c18
> < Content type `text/plain; charset=iso-8859-1' length 134991 bytes
> ---
> > Content type `text/plain; charset=iso-8859-1' length 124178 bytes
> 22,23c22,23
> < .......... .......... .......... .
> < downloaded 131Kb
> ---
> > .......... .......... .
> > downloaded 121Kb
> 25c25
> < [1] 273
> ---
> > [1] 251
> 60,61d59
> < Error in url(" <http://foo.bar> http://foo.bar", "r") : unable to open
> connection
> < In addition: Warning message: 
> 62a61
> > Error in url(" <http://foo.bar> http://foo.bar", "r") : unable to open
> connection
> 365,370c364
> <  Login: root              Name: root
> < Directory: /root                     Shell: /bin/tcsh
> < Last login Wed Nov  5 13:34 (PST) on pts/1 from
> verdi.irisfinancial.com
> < New mail received Wed Nov  5 04:02 2003 (PST)
> <      Unread since Fri Oct 24 04:02 2003 (PDT )
> < No Plan.
> ---
> > Error in make.socket(host, port) : Socket not established
>  OK
>     
>  
>  
> I noticed that I had to expect some differences so my question is how to
> tell whether it's harmless or not?
>  
>  
> Other questions are related to building of recommended packages:
> * The src/library/Recommended directory was empty. Is it expected? 

No.  You forgot to run tools/rsync-recommended in the sources.

> If
> yes, how to download the entire bundle of recommended packages (I know I
> can get them one by one)? Is install.packaes() the recommended way?
> * make check tried to test MASS and survival (and failed because the
> packages were not there), but it didn't try to test the other
> recommended  packages. Why only these two?

It did not test those packages, it tried to make use of them.  make
check-all would have tested the recommended packages.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Nov  6 08:13:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Nov 2003 07:13:22 +0000 (GMT)
Subject: [R] Number of Days
In-Reply-To: <3FC6B09D@webmail.uiuc.edu>
Message-ID: <Pine.LNX.4.44.0311060711580.26300-100000@gannet.stats>

?strptime
?as.POSIXct
?difftime

On Wed, 5 Nov 2003, umeno wrote:

> Hi everyone,
> 
> I have been trying to compute numbers of days between two dates as follows:
> 
> > x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
> > z <- format(x, "%d%b%Y")
> > ex <- c("1jan1961", "15jan1960", "21mar1975", "10jul1981")
> > ez <- format(ex, "%d%b%Y")
> > ez-z
> Error in ez - z : non-numeric argument to binary operator
> 
> As you may see, I am getting an error.  Can anyone tell me how I can convert z 
> and ez to numeric vectors, so that I can compute days between the 
> corresponding dates in these vectors?
> 
> thank you
> soyoko
> 
> ______________________________________
> Ms. Soyoko Umeno
> Graduate Research Assitant for the Illinois-Missouri Biotechnology Alliance (IMBA) at http://www.imba.missouri.edu/
> Ph.D. Student at the Department of Agricultural and Consumer Economics
> at the University of Illinois at Urbana-Champaign
> Office Phone: 217-333-3417 or 217-333-0364
> Fax: 217-244-4817
> Mailing Address: 1301 W. Gregory Dr. MC710, Urbana, IL 61801
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From psirab at inwind.it  Thu Nov  6 08:32:31 2003
From: psirab at inwind.it (Paolo Sirabella)
Date: Thu, 6 Nov 2003 08:32:31 +0100
Subject: [R] Reading JPG files within R
Message-ID: <002c01c3a438$23b73940$0100000a@freegenius>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031106/37b7d845/attachment.pl

From r.darnell at uq.edu.au  Thu Nov  6 08:41:45 2003
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Thu, 06 Nov 2003 17:41:45 +1000
Subject: [R] help with nomogram function
Message-ID: <65hyvt8m.fsf@uq.edu.au>


Frank Harrell wrote
 
> On Wed, 05 Nov 2003 09:22:34 +1000
> Ross Darnell <r.darnell at uq.edu.au> wrote:
> 
> > I have fitted a logistic regression model
> > 
> > > failed.lr2$call
> > lrm(formula = failed ~ Age + task2 + Age:task2, data = time.long, 
> >     na.action = na.omit)
> 
> Use Age*task2 and omit na.action as na.omit is the default
> 
> > 
> > using the Design package functions and would like to generate a
> > nomogram from this model.
> > 
> > the datadist information is generated and stored in
> > 
> > > ddist
> >                 time.long$Age time.long$task2
> > Low:effect                 45            <NA>
> > Adjust to                  56       both.foam
> > High:effect                68            <NA>
> > Low:prediction             21       both.foam
> > High:prediction            80           right
> > Low                        20       both.foam
> > High                       80           right
> 
> This looks most strange.  You did not include the original code but I
> suspect you had $ in a term.  $ should not appear in column headings
> above.  Design wants you to use data= or attach, and avoid $ in terms.
> 
> 
> > 
> > Values:
> > 
> > time.long$task2 : both.foam left right 
> > > 
> > 
> > The model fitted and then when I try the nomgram function
> > 
> > > nomogram(failed.lr2)
> > Error in value.chk(at, i, NA, -nint, Limval, type.range = "full") : 
> > 	variable Age does not have limits defined by datadist
> > > 
> > 
> > I get an error. The NA values in ddist seem to be the problem but I
> > don't understand the datadist information.
> > 

I tried using the data argument in datadist

> names(my.data)
[1] "subject" "Age"     "failed"  "task"   
> ddist <- datadist(Age,task,data=my.data)
Error in datadist(Age, task, data = my.data) : 
	Object "Age" not found


Strange.

Thanks
Ross Darnell


--



From socrates at mis.tutkie.tut.ac.jp  Thu Nov  6 10:04:55 2003
From: socrates at mis.tutkie.tut.ac.jp (Sokratis Alikhanidi)
Date: Thu, 6 Nov 2003 18:04:55 +0900
Subject: [R] Variable selection.
Message-ID: <14630743968.20031106180455@mis.tutkie.tut.ac.jp>

  Dear colleagues,

Please point me out to a variable selection approach or package in the R environment.
I am particularly interesting in evolutionary/genetic algorithms for optimization of PLS and SVM models.

---
My knowledge is limited by the follows packages:

Package "Subselect" does not seem to be valid, because it handles with the correlation/covariance matrix only.
Therefore, is it applicable to linear models (am I right?).
Can it be used for the non-linear learning approaches? What is its area of application?

Package "gafit" can optimize only continuous parameters in a function, but not the feature selection.
---

I will be glad for any recommendations.

Thank you very much.

Sokratis Alikhanidi.



From maechler at stat.math.ethz.ch  Thu Nov  6 11:12:38 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 6 Nov 2003 11:12:38 +0100
Subject: [R] Contributing to the R Extensions documentation
In-Reply-To: <1068064288.26108.100.camel@iron.libaux.ucsf.edu>
References: <Pine.LNX.4.44.0311052004220.25018-100000@gannet.stats>
	<1068064288.26108.100.camel@iron.libaux.ucsf.edu>
Message-ID: <16298.7830.607498.807137@gargle.gargle.HOWL>

>>>>> "Ross" == Ross Boylan <ross at biostat.ucsf.edu>
>>>>>     on Wed, 05 Nov 2003 12:31:28 -0800 writes:

    Ross> On Wed, 2003-11-05 at 12:06, Prof Brian Ripley wrote:
    >> A list is just a vector of type VECSXP.  There IS a
    >> section called `Handling lists'.
    >> 
    >> I don't think the gap is in the `Writing R Extensions'
    >> document, maybe in your reading of it.
    >> 
    Ross> That section discusses reading lists, not making them.

    Ross> It also includes no explicit statement that the names
    Ross> of list items are in the R_NamesSymbol attribute, nor
    Ross> instructions on how to create the value that goes in
    Ross> that attribute (i.e., it should be a character vector
    Ross> and its elements made with mkChar()).  (I'm also not
    Ross> sure how deep one needs to use PROTECT, though that's
    Ross> a more general issue.)

    Ross> There is no explicit statement that the elements of
    Ross> the list are arbitrary SEXP's.

    Ross> I also had the list[i] vs list[[i]] lurking in my
    Ross> mind, wondering how that mapped to the C level
    Ross> constructs.  That is less central.

    Ross> I'm not saying the clues aren't there; after all, I
    Ross> did work it out, I think correctly.  I am saying that
    Ross> certain information would be better stated explicitly
    Ross> rather than simply being open to inference from an
    Ross> example.  And I am saying that an explicit example of
    Ross> constructing and returning a list (with named members)
    Ross> would be useful, since that's a common scenario.

I tend to agree.
I assume most people will read that manual electronically --- as
opposed to "on paper", because you can search quickly ---
and such a proposed addition would be quite helpful.

Alternatively, and sometimes even more usefully,
one could consider providing these more extended examples as
files (*.c, *.R, Makefile, .. or even better, as an R package
(with a vignette !) which would have an almost purely didactical
aim.   As an R package --- source only, no binaries! --- it had
the advantage of providing "provably" (via R CMD check) working
code.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

    >> On Wed, 5 Nov 2003, Ross Boylan wrote:
    >> 
    >> I thought there were some gaps in the R Extensions
    >> document; in particular, I was left wondering how to
    >> create a list.  I think a paragraph on it would be
    >> useful.
    >> 
    >> I would be happy to contribute the paragraph, but I'm
    >> not sure if there's interest or what the procedure is.
    >> Can anyone advise me?
    >> 
    >> Though I was looking at the 1.7.0 version, I just
    >> checked 1.8.0 and the relevant section seems the same.
    >> 
    >> My ulterior motive is to discover if my understanding
    >> of lists is actually correct :)



From VINCENT.STOLIAROFF at sgam.com  Thu Nov  6 12:04:20 2003
From: VINCENT.STOLIAROFF at sgam.com (STOLIAROFF VINCENT)
Date: Thu, 6 Nov 2003 12:04:20 +0100 
Subject: [R] import data troubles 
Message-ID: <F8F9E8240570AB4E86DC49B64FDCA2C40101BDA0@FR-MAILBOX1.fr.sgam.socgen>

HI R lovers,

I have been facing a petty trouble with datas' import :

I have a plain txt file (see attached file or the copy below) that I cannot
read either with scan or read.table


> scan(file="F:/Alt/HDG/Stoliaroff/Data/test.txt")
Error in scan(file = "F:/Alt/HDG/Stoliaroff/Data/test.txt") : 
        "scan" expected a real, got "??6"

> read.table(file="F:/Alt/HDG/Stoliaroff/Data/test.txt")
    V1
1  ??6
2   \n
3    6
4    4
5    5
6    3
7    3
8   \n
9    6
10   4
11   5
12   3
13   3
14  \n
15   6
16   4
17   5
18   3
19   2
20  \n
21   6
22   4
23   5
24   3
25   2
26  \n
27 



My file is as simple as:

62.5000	47.5048	56.8500	36.4700	32.4500	
62.1500	47.0952	55.0500	35.5600	30.1500	
61.3300	45.2476	53.6500	34.8200	29.4900	
61.6600	46.2286	53.8500	35.2000	30.6400	
62.0000	47.3714	54.4400	35.1100	30.1600	
60.8500	46.7143	52.9900	34.4200	29.3400	
61.0900	46.4381	52.7600	33.9600	29.1000	
	

 <<test.txt>> 		

Does anybody have an idea of the cause of my problem?

Besides, I'd like to know if there is a function for importing datas from
excel file? I cannot find one...

Thanks a lot for any help
Sorry for my poor english and the possible irrelevancy of my questions

Vincent



*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
SG Asset Management et ses filiales declinent toute responsabilite au titre
de ce message s'il a ete altere, deforme ou falsifie.

D?couvrez l'offre et les services de SG Asset Management sur le site
www.sgam.fr 

				********

This message and any attachments (the "message") are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited. 
E-mails are susceptible to alteration.   
Neither SG Asset Management nor any of its subsidiaries or affiliates shall
be liable for the message if altered, changed or falsified. 

*************************************************************************



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: test.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031106/f39ae182/test.txt

From John.Marsland at CommerzbankIB.com  Thu Nov  6 12:04:25 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Thu, 6 Nov 2003 11:04:25 -0000 
Subject: [R] GDB under windows
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA27@xmx8lonib.lonib.commerzbank.com>

Does anybody have some simple instructions to get me going using the GNU
debugger GDB under windows with R? 

The R Extensions manual mentions briefly debugging under unix, but I've seen
seen GDB mention in the Bloodshed Dev C++ IDE so it should be possible to
use it with R?

Regards,

John

[Using R-1.8.0 under Windows NT 4.0] 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From VINCENT.STOLIAROFF at sgam.com  Thu Nov  6 12:15:17 2003
From: VINCENT.STOLIAROFF at sgam.com (STOLIAROFF VINCENT)
Date: Thu, 6 Nov 2003 12:15:17 +0100 
Subject: [R] RE: import data troubles 
Message-ID: <F8F9E8240570AB4E86DC49B64FDCA2C40101BDA1@FR-MAILBOX1.fr.sgam.socgen>

I am sorry for polluting the list.... I have solved my problem: the text
file was written in unicode format.

>  -----Message d'origine-----
> De : 	STOLIAROFF VINCENT  
> Envoy? :	jeudi 6 novembre 2003 12:04
> ? :	'r-help at stat.math.ethz.ch'
> Objet :	import data troubles 
> 
> HI R lovers,
> 
> I have been facing a petty trouble with datas' import :
> 
> I have a plain txt file (see attached file or the copy below) that I
> cannot read either with scan or read.table
> 
> 
> > scan(file="F:/Alt/HDG/Stoliaroff/Data/test.txt")
> Error in scan(file = "F:/Alt/HDG/Stoliaroff/Data/test.txt") : 
>         "scan" expected a real, got "??6"
> 
> > read.table(file="F:/Alt/HDG/Stoliaroff/Data/test.txt")
>     V1
> 1  ??6
> 2   \n
> 3    6
> 4    4
> 5    5
> 6    3
> 7    3
> 8   \n
> 9    6
> 10   4
> 11   5
> 12   3
> 13   3
> 14  \n
> 15   6
> 16   4
> 17   5
> 18   3
> 19   2
> 20  \n
> 21   6
> 22   4
> 23   5
> 24   3
> 25   2
> 26  \n
> 27 
> 
> 
> 
> My file is as simple as:
> 
> 62.5000	47.5048	56.8500	36.4700	32.4500	
> 62.1500	47.0952	55.0500	35.5600	30.1500	
> 61.3300	45.2476	53.6500	34.8200	29.4900	
> 61.6600	46.2286	53.8500	35.2000	30.6400	
> 62.0000	47.3714	54.4400	35.1100	30.1600	
> 60.8500	46.7143	52.9900	34.4200	29.3400	
> 61.0900	46.4381	52.7600	33.9600	29.1000	
> 	
> 
> << Fichier: test.txt>>		
> 
> Does anybody have an idea of the cause of my problem?
> 
> Besides, I'd like to know if there is a function for importing datas from
> excel file? I cannot find one...
> 
> Thanks a lot for any help
> Sorry for my poor english and the possible irrelevancy of my questions
> 
> Vincent
> 
> 
> 
*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
SG Asset Management et ses filiales declinent toute responsabilite au titre
de ce message s'il a ete altere, deforme ou falsifie.

D?couvrez l'offre et les services de SG Asset Management sur le site
www.sgam.fr 

				********

This message and any attachments (the "message") are confide...{{dropped}}



From ripley at stats.ox.ac.uk  Thu Nov  6 12:23:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 6 Nov 2003 11:23:53 +0000 (GMT Standard Time)
Subject: [R] GDB under windows
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA27@xmx8lonib.lonib.commerzbank.com>
Message-ID: <Pine.WNT.4.44.0311061123090.1832-100000@petrel>

It's in the rw-FAQ! That describes this as `fraught' with good reason.

On Thu, 6 Nov 2003, Marsland, John wrote:

> Does anybody have some simple instructions to get me going using the GNU
> debugger GDB under windows with R?
>
> The R Extensions manual mentions briefly debugging under unix, but I've seen
> seen GDB mention in the Bloodshed Dev C++ IDE so it should be possible to
> use it with R?
>
> Regards,
>
> John
>
> [Using R-1.8.0 under Windows NT 4.0]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From plummer at iarc.fr  Thu Nov  6 12:33:14 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: 06 Nov 2003 12:33:14 +0100
Subject: [R] R for various ports of linux
In-Reply-To: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
References: <04453A37-0FD4-11D8-8728-000393B3E9D0@bigpace.med.utah.edu>
Message-ID: <1068118395.1005.56.camel@xena>

On Wed, 2003-11-05 at 22:07, Nathan Leon Pace, MD, MStat wrote:
> To all:
> 
> I currently download the R binaries for Redhat 7.x Linux.
> 
> There is considerable turmoil in the vendors of Linux. Redhat 
> apparently is changing it's business model to paid versions.
> 
> This might motivate my department to use a different vendor of Linux.
> 
> Is there anything predictable about which vendors/versions of Linux 
> will have R binaries in the future?

I hadn't really given it much thought. I suppose I shall switch to
creating RPMS for Fedora, since there won't be a Red Hat Linux 10. Don't
hold your breath for RPMS for the Enterprise Version of Red Hat unless
we (IARC) can negotiate a sweet licensing deal.

I don't think Red Hat are abandoning poor acadamic users. They just
aren't making money out of their boxed set, so they're replacing it with
Fedora.

Martyn



From ajsmit at science.uct.ac.za  Thu Nov  6 12:33:17 2003
From: ajsmit at science.uct.ac.za (AJ Smit)
Date: Thu,  6 Nov 2003 13:33:17 +0200
Subject: [R] Levelplot and NAs
Message-ID: <1068118397.3faa317db8c0b@webmail.uct.ac.za>

Dear all

How does one get a levelplot (lattice library) to plot NAs in a
different colour to that specified in the default colorkey? 

Thanks in advance,
Albertus

-- 
Dr. Albertus J. Smit
Department of Botany
University of Cape Town
PO Box Rondebosch
7700
SOUTH AFRICA

-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From dmurdoch at pair.com  Thu Nov  6 12:40:15 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 06 Nov 2003 06:40:15 -0500
Subject: [R] R function help arranged in categorical order ?
In-Reply-To: <3FA9E7B4.2050002@auckland.ac.nz>
References: <Pine.LNX.4.44.0311051547150.1579-100000@gannet.stats>
	<3FA9E7B4.2050002@auckland.ac.nz>
Message-ID: <rjckqvslb32h8jjs3r1re8q4rusdonkooq@4ax.com>

On Thu, 06 Nov 2003 19:18:28 +1300, you wrote:

>
>>Similarly help.search can list by categories, aka keywords.  Perhaps its 
>>help page needs to say where the list of standard keywords is.
>>
>>  
>>
>But to list all the help pages in a given "category", you need to use 
>help.search(keyword="iplot",agrep=FALSE,package="base")
>or is there an easier way?

Use help.start().  This starts the HTML help system.  Follow the link
to "Search engine and keywords".

This works as long as you have an HTML browser configured.

Duncan Murdoch



From jdn at cs.mu.OZ.AU  Thu Nov  6 13:17:09 2003
From: jdn at cs.mu.OZ.AU (James Noble)
Date: Thu, 6 Nov 2003 23:17:09 +1100 (EST)
Subject: [R] Statistics newbie question
Message-ID: <Pine.NEB.4.21.0311062306310.4884-100000@mulga.cs.mu.OZ.AU>


Hi there,

I am relatively new to R and statistics.

I have large dataset where each sample has about 3000 dimensions, 
and belongs to one of 13 classes. I am wanting to measure the statistical
significance of each dimension with respect to the class, in order to
find what dimensions are likely to be good predictors.

I undertand the standard way to do this is with ANOVA or regression, 
but am not to sure if these methods are the most suitable. 

If this is a good way to approach it how do I code it as  a regression
problem in R.

Thanks for your help.

-James



From feh3k at spamcop.net  Thu Nov  6 13:04:53 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 6 Nov 2003 07:04:53 -0500
Subject: [R] help with nomogram function
In-Reply-To: <65hyvt8m.fsf@uq.edu.au>
References: <65hyvt8m.fsf@uq.edu.au>
Message-ID: <20031106070453.2ebaea7f.feh3k@spamcop.net>

On Thu, 06 Nov 2003 17:41:45 +1000
Ross Darnell <r.darnell at uq.edu.au> wrote:

> 
> Frank Harrell wrote
>  
> > On Wed, 05 Nov 2003 09:22:34 +1000
> > Ross Darnell <r.darnell at uq.edu.au> wrote:
> > 
> > > I have fitted a logistic regression model
> > > 
> > > > failed.lr2$call
> > > lrm(formula = failed ~ Age + task2 + Age:task2, data = time.long, 
> > >     na.action = na.omit)
> > 
> > Use Age*task2 and omit na.action as na.omit is the default
> > 
> > > 
> > > using the Design package functions and would like to generate a
> > > nomogram from this model.
> > > 
> > > the datadist information is generated and stored in
> > > 
> > > > ddist
> > >                 time.long$Age time.long$task2
> > > Low:effect                 45            <NA>
> > > Adjust to                  56       both.foam
> > > High:effect                68            <NA>
> > > Low:prediction             21       both.foam
> > > High:prediction            80           right
> > > Low                        20       both.foam
> > > High                       80           right
> > 
> > This looks most strange.  You did not include the original code but I
> > suspect you had $ in a term.  $ should not appear in column headings
> > above.  Design wants you to use data= or attach, and avoid $ in terms.
> > 
> > 
> > > 
> > > Values:
> > > 
> > > time.long$task2 : both.foam left right 
> > > > 
> > > 
> > > The model fitted and then when I try the nomgram function
> > > 
> > > > nomogram(failed.lr2)
> > > Error in value.chk(at, i, NA, -nint, Limval, type.range = "full") : 
> > > 	variable Age does not have limits defined by datadist
> > > > 
> > > 
> > > I get an error. The NA values in ddist seem to be the problem but I
> > > don't understand the datadist information.
> > > 
> 
> I tried using the data argument in datadist
> 
> > names(my.data)
> [1] "subject" "Age"     "failed"  "task"   
> > ddist <- datadist(Age,task,data=my.data)
> Error in datadist(Age, task, data = my.data) : 
> 	Object "Age" not found
> 

Please read the documentation more carefully.  Either do ddist <-
datadist(my.data) (if the data frame contains the most up to date versions
of the variables) or attach(my.data);ddist <- datadist(Age, task).   -FH

> 
> Strange.
> 
> Thanks
> Ross Darnell
> 
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From deepayan at stat.wisc.edu  Thu Nov  6 14:35:11 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 6 Nov 2003 07:35:11 -0600
Subject: [R] Levelplot and NAs
In-Reply-To: <1068118397.3faa317db8c0b@webmail.uct.ac.za>
References: <1068118397.3faa317db8c0b@webmail.uct.ac.za>
Message-ID: <200311060735.11887.deepayan@stat.wisc.edu>

On Thursday 06 November 2003 05:33, AJ Smit wrote:
> Dear all
>
> How does one get a levelplot (lattice library) to plot NAs in a
> different colour to that specified in the default colorkey?

You can't do it. If you don't need to distinguish NA's and missing points 
(that is (x,y) pairs that are completely absent from the data, as opposed to 
being present with a z-value of NA), you can use panel.fill() to fill the 
background with your 'NA' color. Something like

levelplot(...

          panel = function(...) {
              panel.fill(col = "red")
              panel.levelplot(...)
          })

Otherwise, change NA's to some suitable number before plotting.

Deepayan



From maechler at stat.math.ethz.ch  Thu Nov  6 15:15:19 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 6 Nov 2003 15:15:19 +0100
Subject: [R] R function help arranged in categorical order ?
In-Reply-To: <Pine.LNX.4.44.0311051547150.1579-100000@gannet.stats>
References: <16297.5690.142523.625697@arbres1a.fmr.com>
	<Pine.LNX.4.44.0311051547150.1579-100000@gannet.stats>
Message-ID: <16298.22391.503383.845337@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Wed, 5 Nov 2003 15:51:09 +0000 (GMT) writes:

    BDR> On Wed, 5 Nov 2003, David Brahm wrote:
    >> Neil Osborne <r_stuff_online at hotmail.com> wrote: > Is any
    >> one aware of R help documentation that is aranged in
    >> functional > categories for e.g.: > String manipulation >
    >> File I/O > Dataframe, List manipulation
    >> 
    >> There really oughta be.  Several people replied with ways
    >> to search the help, but that assumes you know the
    >> specific task you want to perform, and the right
    >> "keyword" to describe it.  Beginners often just want to
    >> learn what's available.

    BDR> Well, as described in your quotation you need to know
    BDR> the `functional categories' and help.start's search
    BDR> page does list the known `functional categories' and
    BDR> will list under each one. So there really IS, not
    BDR> `oughta be',

    BDR> Similarly help.search can list by categories, aka
    BDR> keywords.  Perhaps its help page needs to say where the
    BDR> list of standard keywords is.

Good, idea!
such as tell the user to execute
	file.show(file.path(R.home(),"doc", "KEYWORDS"))

{BTW, a problem with KEYWORDS is that "R CMD check" works
 with KEYWORDS.db, and the human readable KEYWORDS needs to be
 kept in sync with *.db manually}.

Martin



From solares at unsl.edu.ar  Thu Nov  6 15:34:47 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 6 Nov 2003 11:34:47 -0300 (ART)
Subject: [R] how to install tkrplot.zip
Message-ID: <52531.170.210.173.216.1068129287.squirrel@inter14.unsl.edu.ar>

Hi, mi question is for how to install tkrplot, i like to load him but i' 
failed (i see "first.lib Failed") because he said  not exist the file 
tkrplot.dll but i download the tkrplot.zip and i unzip him in the file 
c:\R\1071\library\libs\tkrplot.dll (R 1.7.1), what i do to make for the R 
encounter the .dll file? thanks Ruben



From rdsp5 at hotmail.com  Thu Nov  6 15:41:17 2003
From: rdsp5 at hotmail.com (ruben dario solares)
Date: Thu, 06 Nov 2003 14:41:17 +0000
Subject: [R] how to install tkrplot?
Message-ID: <BAY7-F42FmrLbcfmINl00034839@hotmail.com>


   Hello, my question is on as installing tkrplot, i want to charge it
   but appears "first.lib Failed" therefore says that not exist the
   tkrplot.dll and I download the tkrplot.zip and i unzip him and the
   file is  in the path c: \R\1071\library\libs\tkrplot.dll, that should
   do so that find the. dll?  Thanks Ruben
     _________________________________________________________________

   Nuevo MSN Messenger [1]Una forma r?pida y divertida de enviar mensajes

References

   1. http://g.msn.com/8HMAESAR/2737??PS=


From ggrothendieck at myway.com  Thu Nov  6 15:44:10 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu,  6 Nov 2003 09:44:10 -0500 (EST)
Subject: [R] Number of Days
Message-ID: <20031106144410.4650339E3@mprdmxin.myway.com>



ndays <- strptime(ex,format="%d%b%Y") - strptime(x,format="%d%b%Y")

If you need it in a calculation then as.numeric(ndays) might be
useful.

---
 
Date: Wed, 5 Nov 2003 23:33:33 -0600 
From: umeno <umeno at students.uiuc.edu>
To: R-Help  
Subject: [R] Number of Days 

 
 
Hi everyone,

I have been trying to compute numbers of days between two dates as follows:

> x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
> z <- format(x, "%d%b%Y")
> ex <- c("1jan1961", "15jan1960", "21mar1975", "10jul1981")
> ez <- format(ex, "%d%b%Y")
> ez-z
Error in ez - z : non-numeric argument to binary operator

As you may see, I am getting an error. Can anyone tell me how I can convert z 
and ez to numeric vectors, so that I can compute days between the 
corresponding dates in these vectors?

thank you
soyoko

______________________________________
Ms. Soyoko Umeno
Graduate Research Assitant for the Illinois-Missouri Biotechnology Alliance (IMBA) at http://www.imba.missouri.edu/
Ph.D. Student at the Department of Agricultural and Consumer Economics
at the University of Illinois at Urbana-Champaign
Office Phone: 217-333-3417 or 217-333-0364
Fax: 217-244-4817
Mailing Address: 1301 W. Gregory Dr. MC710, Urbana, IL 61801


_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From spe2 at cornell.edu  Thu Nov  6 15:50:55 2003
From: spe2 at cornell.edu (Stephen Ellner)
Date: Thu, 06 Nov 2003 09:50:55 -0500
Subject: [R] Re: using LSODA in R 
Message-ID: <5.2.1.1.2.20031106093554.00abb468@postoffice6.mail.cornell.edu>

I think an additional problem is that the derivatives function 
must be 'told' where to 'look' in y for the values of R, C, and P 
that are used to compute Rprime,Cprime, Pprime - it has no way of
'knowing' that the model's state vector y consists of
the variables (R,C,P). Appended below is an example of code
that works to solve a similar system of equations. Perhaps 
it might be useful to add something like that to the 
?lsoda page?  

> function(times,y,p)
> {
> Rprime <-
> (R*(1-R))-((xc*yc*C*R)/(R+R0))-((w*xp*ypr*P*R)/(R02+((1-w)*C)+(w*R)))
> Cprime <-
> (-1*(xc*C)*(1-(yc*R)/(R+R0)))-(((1-w)*xp*ypc*P*C)/((w*R)+((1-w)*C)+C0))
> Pprime <-
> 
>(-1*P)-(((1-w)*xp*ypc*C*P)/((w*R)+((1-w)*C)+C0))+((w*xp*ypr*P*R)/((w*R)+((1-w)*C)+R02))
>list(c(Rprime, Cprime, Pprime))
>}

require(odesolve);

# Set parameter values
bmaxc=3.3; bmaxb=2.25; Kc=4.3; Kb=15; ni=80;
m=0.05; lambda=0.4; epsilon=0.25; delta=0.95;

f2k=function(t,y,parms){
        dy=rep(0,4); 
        n=y[1]; c=y[2]; r=y[3]; b=y[4];
        fcn=bmaxc*n/(Kc+n);  
        fbc=bmaxb*c/(Kb+c);
        dy[1]=delta*(ni-n)-fcn*c;
        dy[2]=fcn*c-fbc*b/epsilon-delta*c;
        dy[3]=fbc*r-(delta+m+lambda)*r;
        dy[4]=fbc*r-(delta+m)*b;
        list(dy);
}   

y0=c(1,70,.01,.01); times=(0:240)/4; parms=0; 
out=lsoda(y0, times, f2k, parms, rtol=1e-4, atol=1e-4);
matplot(times,cbind(out[,3]/5,out[,5]),type="l",col=c("green","red"), lty=1,
xlab="Time (d)", ylab="Prey (green) and Predators (red)"); 


Stephen P. Ellner (spe2 at cornell.edu)
Department of Ecology and Evolutionary Biology
Corson Hall, Cornell University, Ithaca NY 14853-2701
Phone (607) 254-4221    FAX (607) 255-8088



From ligges at statistik.uni-dortmund.de  Thu Nov  6 16:02:31 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Nov 2003 16:02:31 +0100
Subject: [R] how to install tkrplot?
In-Reply-To: <BAY7-F42FmrLbcfmINl00034839@hotmail.com>
References: <BAY7-F42FmrLbcfmINl00034839@hotmail.com>
Message-ID: <3FAA6287.7050308@statistik.uni-dortmund.de>

ruben dario solares wrote:

>    Hello, my question is on as installing tkrplot, i want to charge it
>    but appears "first.lib Failed" therefore says that not exist the
>    tkrplot.dll and I download the tkrplot.zip and i unzip him and the
>    file is  in the path c: \R\1071\library\libs\tkrplot.dll, that should
>    do so that find the. dll?  Thanks Ruben
>      _________________________________________________________________
> 
>    Nuevo MSN Messenger [1]Una forma r?pida y divertida de enviar mensajes
> 
> References
> 
>    1. http://g.msn.com/8HMAESAR/2737??PS=
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



PLEASE, read the FAQs and manuals before posting questions like this on 
R-help (you are already "famous" among R-help readers for posting such 
questions). It is mentioned in the R for Windows FAQs how packages are 
installed! And PLEASE, don't post questions more than once.

install.packages("tkrplot")
  should do it for you.

BTW: After unzipping the package manually, the DLL should appear in 
(guessed from above) c:\R\1071\library\tkrplot\libs\tkrplot.dll
on your machine.

Uwe Ligges



From cougar3721 at yahoo.com  Thu Nov  6 16:25:55 2003
From: cougar3721 at yahoo.com (L Z)
Date: Thu, 6 Nov 2003 07:25:55 -0800 (PST)
Subject: [R] for help about R--probit
Message-ID: <20031106152555.51774.qmail@web14811.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031106/c15ac9f8/attachment.pl

From jblazi at gmx.de  Thu Nov  6 16:56:34 2003
From: jblazi at gmx.de (JB)
Date: Thu, 06 Nov 2003 16:56:34 +0100
Subject: [R] Absolut newbie questions
Message-ID: <6.0.0.22.2.20031106164520.01bcf0c0@pop.gmx.de>

I teach at a high school and should like to find out, if I can use R for my 
teaching. So I jhave installed it on my XP system and now I should like to 
solve a simple problem:

We have just measured dx and dt (d standing here for \Delta) on an inclined 
plain and received some data thet are in two lists (x_list and t_list). The 
theory says, that dx = a/2*(dt)^2 for a constant a.

I should like to fit the data against the theoretical prediction. This 
should deliver an estimate for a.

Then I should like to graph the data (as bullets) and the predicted 
function into the same graph.

Is this possible? I suspect that the answer is "yes" and that R is an 
overkill for this.

Could somebody tell me how to do these things? (I need only a few lines of 
MuPad or Maple for this; the problem is that I own a MuPad license but the 
school does not.)

TIA,
Janos Blazi



From yun.xu at bristol.ac.uk  Thu Nov  6 17:09:32 2003
From: yun.xu at bristol.ac.uk (Yun Xu)
Date: Thu, 6 Nov 2003 16:09:32 -0000
Subject: [R] How to setup proxy in R for windows?
Message-ID: <01ad01c3a480$5d5b4ea0$622bde89@chm.bris.ac.uk>

Dear All:

I just want to ask how can I setup proxy address in R for win32? I remember
I had read a relative topic in R-help before, but I can't find it anymore.
Anyhelp would be very appreciated!

Yun
School of Chemistry
University of Bristol



From ripley at stats.ox.ac.uk  Thu Nov  6 17:15:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Nov 2003 16:15:51 +0000 (GMT)
Subject: [R] for help about R--probit
In-Reply-To: <20031106152555.51774.qmail@web14811.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311061612470.1460-100000@gannet.stats>

And did you actually look at the fitted values?  I got 22 ones.  For a
substantial part of your x1-x2 space there are no failures.  The warning 
is telling you that the fitted probabilities are so close to one as to be 
unreliable.  The largest is 1-exp-20!

On Thu, 6 Nov 2003, L Z wrote:

> Not real data. It was gererated randomly. The original codes are the following:
>  
> par(mfrow=c(2,1))
> n <- 500
> 
> #########################
> #DATA GENERATING PROCESS#
> #########################
> x1  <- rnorm(n,0,1)
> x2  <- rchisq(n,df=3,ncp=0)-3
> sigma <- 1
> u1   <- rnorm(n,0,sigma)
> ylatent1 <-x1+x2+u1
> y1   <- (ylatent1 >=0)  # create the binary indicator
> #######################
> #THE Probit Estimation#
> #######################
> probit<-glm(y1~x1+x2-1, family=binomial(link=probit))
> bp<-probit$coef[2]/probit$coef[1]
> bp;
> I also tried family=quasibinomial. There seems no error message. But the result is different from what I got from Gauss. For u1 belongs to another distribution (not normal), the difference is even larger. I used the same data for the comparison.
>  
> Thanks a lot!
> 
> Steve Sullivan <ssullivan at qedgroupllc.com> wrote:
> Is this simulated or actual data?
> 
> STS
> 
> Steven Sullivan, Ph.D.
> Senior Associate
> The QED Group, LLC
> 1250 Eye St. NW, Suite 802
> Washington, DC 20005
> ssullivan at qedgroupllc.com
> 202.898.1910.x15 (v)
> 202.898.0887 (f)
> 202.421.8161 (m)
> 
> 
> -----Original Message-----
> From: L Z [mailto:cougar3721 at yahoo.com] 
> Sent: Wednesday, November 05, 2003 12:10 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] for help about R 
> 
> just want to ask the following
> > > question:
> > > > probit<-glm(y1~x1+x2-1,
> > > family=binomial(link=probit))
> > > Warning message:
> > > fitted probabilities numerically 0 or 1 occurred
> in:
> > > glm.fit(x = X, y = Y,
> > > weights = weights, start = start, etastart =
> > > etastart,
> > > why does that happen?
> 
> 
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.pagel at gsf.de  Thu Nov  6 17:13:14 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Thu, 6 Nov 2003 17:13:14 +0100
Subject: [R] Absolut newbie questions
In-Reply-To: <6.0.0.22.2.20031106164520.01bcf0c0@pop.gmx.de>
References: <6.0.0.22.2.20031106164520.01bcf0c0@pop.gmx.de>
Message-ID: <20031106161314.GA4532@porcupine.gsf.de>

	Hi!

> We have just measured dx and dt (d standing here for \Delta) on an inclined 
> plain and received some data thet are in two lists (x_list and t_list). The 
> theory says, that dx = a/2*(dt)^2 for a constant a.
> 
> I should like to fit the data against the theoretical prediction. This 
> should deliver an estimate for a.

You will find everyhing you want to know in the chapter on statistical
models in the manual "Introduction to R". Also look at the online
documentation for lm() and maybe nls().

> Then I should like to graph the data (as bullets) and the predicted 
> function into the same graph.

Have a look at the documentation for plot(), line() and predict(). 

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From ripley at stats.ox.ac.uk  Thu Nov  6 17:17:47 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Nov 2003 16:17:47 +0000 (GMT)
Subject: [R] How to setup proxy in R for windows?
In-Reply-To: <01ad01c3a480$5d5b4ea0$622bde89@chm.bris.ac.uk>
Message-ID: <Pine.LNX.4.44.0311061615570.1460-100000@gannet.stats>

Do read the rw-FAQ and then ?download.file

On Thu, 6 Nov 2003, Yun Xu wrote:

> I just want to ask how can I setup proxy address in R for win32? I remember
> I had read a relative topic in R-help before, but I can't find it anymore.
> Anyhelp would be very appreciated!


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Pascal.Niklaus at unibas.ch  Thu Nov  6 17:22:57 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Thu, 06 Nov 2003 17:22:57 +0100
Subject: [R] Absolut newbie questions
In-Reply-To: <6.0.0.22.2.20031106164520.01bcf0c0@pop.gmx.de>
References: <6.0.0.22.2.20031106164520.01bcf0c0@pop.gmx.de>
Message-ID: <3FAA7561.5030909@unibas.ch>

summary(lm(x ~ I(t^2))), but you should probably read the "Introduction 
to R"

Pascal



From MSchwartz at medanalytics.com  Thu Nov  6 17:30:27 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 06 Nov 2003 10:30:27 -0600
Subject: [R] How to setup proxy in R for windows?
In-Reply-To: <01ad01c3a480$5d5b4ea0$622bde89@chm.bris.ac.uk>
References: <01ad01c3a480$5d5b4ea0$622bde89@chm.bris.ac.uk>
Message-ID: <1068136227.6055.190.camel@localhost.localdomain>

On Thu, 2003-11-06 at 10:09, Yun Xu wrote:
> Dear All:
> 
> I just want to ask how can I setup proxy address in R for win32? I remember
> I had read a relative topic in R-help before, but I can't find it anymore.
> Anyhelp would be very appreciated!
> 
> Yun
> School of Chemistry
> University of Bristol


See R Windows FAQ 2.17 at:

http://cran.r-project.org/bin/windows/rw-FAQ.html

A search of the R Help archives at:

http://maths.newcastle.edu.au/~rking/R/

results in 104 hits using 'windows' and 'proxy' as keywords:

http://www.google.com/u/newcastlemaths?q=windows+proxy&sa=Google+Search

HTH,

Marc Schwartz



From Pascal.Niklaus at unibas.ch  Thu Nov  6 17:48:52 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Thu, 06 Nov 2003 17:48:52 +0100
Subject: [R] Hierarchical glm
Message-ID: <3FAA7B74.9040106@unibas.ch>

Hi all,

I'm not sure how to correctly analyse the following data with glm, and 
hope for some advice from this list, ideally showing how to specify the 
model in R and perform the tests, and also for suggestions of literature.

The data structure is like this:

   - 20 plant populations were investigated (random factor pop), which 
belong to different habitat types (factor ht)
   - Within each plant population, individuals were grouped into 3 size 
classes (factor sz)
   - For each individual, some count data were recorded

The independent variables I'd like to analyse are either poission of 
binomially distributed.

For gaussian data, I would use the following model:

   ht + pop %in% ht + sz + sz:ht + sz : pop %in %ht

ht would basically be tested against pop (because the population is the 
unit of replication for ht), and sz against sz:pop:ht. (the hypotheses 
to test are that ht has an effect, and whether the effect of sz on 
individuals of a population depends on ht)

However, I do not know how to translate this to the deviance analysis 
case. For example, when I fit the whole model, and then drop ht to test 
for the effect of ht, the effect of ht shows up in pop (I understand 
why, but don't know how to do this otherwise). If I compare the null 
model to the model including ht only, do I then commit a pseudoreplication?

Thanks for your help

Pascal



From ggrothendieck at myway.com  Thu Nov  6 18:03:46 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu,  6 Nov 2003 12:03:46 -0500 (EST)
Subject: [R] import data troubles 
Message-ID: <20031106170346.5EC263979@mprdmxin.myway.com>


 --- On Thu 11/06, STOLIAROFF VINCENT < VINCENT.STOLIAROFF at sgam.com > wrote:
> I'd like to know if there is a function for importing datas from 
> excel file? 

There are a number of choices:

- select range in Excel, press ctrl-c and read in the data from the
clipboard using read.table("clipboard",header=T)

- write out the data from Excel into a .csv file and use
read.csv

- use Baird's dataload utility (search Google) and convert the
.xls file to .rda format and then use the R load command.
You can alternately use dataload to convert the xls file
to csv or text and then proceed as above.

- use the RODBC package to directly read the .xls file.

- use the RDCOM package.  Its not in CRAN so search for it.  This
also directly reads the .xls file.




_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From ggrothendieck at myway.com  Thu Nov  6 18:03:49 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu,  6 Nov 2003 12:03:49 -0500 (EST)
Subject: [R] import data troubles 
Message-ID: <20031106170349.3A2233979@mprdmxin.myway.com>


 --- On Thu 11/06, STOLIAROFF VINCENT < VINCENT.STOLIAROFF at sgam.com > wrote:
> I'd like to know if there is a function for importing datas from 
> excel file? 

There are a number of choices:

- select range in Excel, press ctrl-c and read in the data from the
clipboard using read.table("clipboard",header=T)

- write out the data from Excel into a .csv file and use
read.csv

- use Baird's dataload utility (search Google) and convert the
.xls file to .rda format and then use the R load command.
You can alternately use dataload to convert the xls file
to csv or text and then proceed as above.

- use the RODBC package to directly read the .xls file.

- use the RDCOM package.  Its not in CRAN so search for it.  This
also directly reads the .xls file.




_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From r at r.com  Thu Nov  6 18:12:47 2003
From: r at r.com (r@r.com)
Date: Thu, 6 Nov 2003 18:12:47 +0100 (MET)
Subject: [R] Lexical scoping
Message-ID: <200311061712.hA6HClN5012563@uranus.idi.ntnu.no>

Comparing SPlus and R: a lesson in lexical scoping. If you consider to move to S, be aware of the following.

Consider the piece of code:

f <- function(x) {
  g <- function(y) {
    x + y
  }
  g(0)
}

What would be the result of calling f(10)? Try it in SPlus. They are too professional to make their product work well...

r.ar



From jeff.hamann at forestinformatics.com  Thu Nov  6 18:16:52 2003
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Thu, 6 Nov 2003 09:16:52 -0800
Subject: [R] created data doesn't remain when split...
Message-ID: <005b01c3a489$ce753b10$0a00a8c0@rodan>


I've been trying to figure out why the following is happening....

I've got some data I'll load in from a file...

rm(list=ls(all=TRUE))
trees <- read.table( "c:/cruisepak/data.txt", header=T)
trees$ct <- 1

And when I create some temp variable, then split the data to perform further
processing, the additional column doesn't maintain the data correctly....

mtrees <- trees[trees$m == 1,]
ctrees <- trees[trees$m == 0,]

The results are as follows...

> trees
plot tree m sp dbh tht ct
1      1    1 1 DF  44 185 1
3      1    3 0 DF  40 192  1
.....blah, blah, blah......
6      1    6 0 DF  26 156   1
8      1    8 0 DF  26 155   1


but,
>mtrees
    plot tree m sp dbh tht ct
1      1    1 1 DF  44 185     1
2      1    2 1 DF  38 188    NA
17     2    6 1 DF  26 174    NA
26     3    1 1 DF  42 185    NA

and

>ctrees
> ctrees
    plot tree m sp dbh tht  ct
3      1    3 0 DF  40 192    NA
4      1    4 0 DF  33 148    NA
5      1    5 0 DF  43 182    NA

when the value of ct for all the records in all the data.frames should be 1,
not NA.

Why is that? Am I missing a step here? I'm running R 1.7.1 on Win2k.


Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com


---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From Simon.Fear at synequanon.com  Thu Nov  6 18:35:00 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 6 Nov 2003 17:35:00 -0000
Subject: [R] created data doesn't remain when split...
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0E81@synequanon01>

Not having the data, I can't reproduce this, but I would say
that

trees$ct <- 1

is not a robust way to add a column to a data frame; it
relies on data frames being implemented as lists (and is
probably the cause of the error - only guessing though). I
suspect ct repeats ones only on printout, internally it is a
half-dataframe, half-list hybrid.

Do you get the same problem if you use

trees <- data.frame(trees, ct=1)

or even more explicitly

trees <- data.frame(trees, ct=rep(1, length(trees[,1]))

> -----Original Message-----
> From: Jeff D. Hamann [mailto:jeff.hamann at forestinformatics.com]
> Sent: 06 November 2003 17:17
> To: r-help at stat.math.ethz.ch
> Subject: [R] created data doesn't remain when split...
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> 
> I've been trying to figure out why the following is happening....
> 
> I've got some data I'll load in from a file...
> 
> rm(list=ls(all=TRUE))
> trees <- read.table( "c:/cruisepak/data.txt", header=T)
> trees$ct <- 1
> 
> And when I create some temp variable, then split the data to 
> perform further
> processing, the additional column doesn't maintain the data 
> correctly....
> 
> mtrees <- trees[trees$m == 1,]
> ctrees <- trees[trees$m == 0,]
> 
> The results are as follows...
> 
> > trees
> plot tree m sp dbh tht ct
> 1      1    1 1 DF  44 185 1
> 3      1    3 0 DF  40 192  1
> .....blah, blah, blah......
> 6      1    6 0 DF  26 156   1
> 8      1    8 0 DF  26 155   1
> 
> 
> but,
> >mtrees
>     plot tree m sp dbh tht ct
> 1      1    1 1 DF  44 185     1
> 2      1    2 1 DF  38 188    NA
> 17     2    6 1 DF  26 174    NA
> 26     3    1 1 DF  42 185    NA
> 
> and
> 
> >ctrees
> > ctrees
>     plot tree m sp dbh tht  ct
> 3      1    3 0 DF  40 192    NA
> 4      1    4 0 DF  33 148    NA
> 5      1    5 0 DF  43 182    NA
> 
> when the value of ct for all the records in all the 
> data.frames should be 1,
> not NA.
> 
> Why is that? Am I missing a step here? I'm running R 1.7.1 on Win2k.
> 
> 
> Jeff.
> 
> ---
> Jeff D. Hamann
> Forest Informatics, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> (office) 541-754-1428
> (cell) 541-740-5988
> jeff.hamann at forestinformatics.com
> www.forestinformatics.com
> 
> 
> ---
> Jeff D. Hamann
> Forest Informatics, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> (office) 541-754-1428
> (cell) 541-740-5988
> jeff.hamann at forestinformatics.com
> www.forestinformatics.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From dmurdoch at pair.com  Thu Nov  6 18:37:30 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 06 Nov 2003 12:37:30 -0500
Subject: [R] GDB under windows
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA27@xmx8lonib.lonib.commerzbank.com>
References: <8CBAA121CEB4D5118CB200508BB2BBEF0317EA27@xmx8lonib.lonib.commerzbank.com>
Message-ID: <fh1lqvs39akh8t7m9l3hva8onhsvuqn8oq@4ax.com>

On Thu, 6 Nov 2003 11:04:25 -0000 , "Marsland, John"
<John.Marsland at CommerzbankIB.com> wrote :

>Does anybody have some simple instructions to get me going using the GNU
>debugger GDB under windows with R? 
>
>The R Extensions manual mentions briefly debugging under unix, but I've seen
>seen GDB mention in the Bloodshed Dev C++ IDE so it should be possible to
>use it with R?

I've got a few tips beyond those in the FAQ, but haven't had a chance
to write them down anywhere.  If anyone wants to volunteer to write
this up, I think it would be worthwhile putting them in a web page for
future reference.

One tip:  in recent versions of R (but hopefully not in 1.8.1), gdb
always traps on a few memory allocation errors during startup.  This
is irritating but harmless, continuing from that point on will
eventually get R to start.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Thu Nov  6 18:38:38 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Nov 2003 17:38:38 +0000 (GMT)
Subject: [R] created data doesn't remain when split...
In-Reply-To: <005b01c3a489$ce753b10$0a00a8c0@rodan>
Message-ID: <Pine.LNX.4.44.0311061734200.16330-100000@gannet.stats>

On Thu, 6 Nov 2003, Jeff D. Hamann wrote:

> I've been trying to figure out why the following is happening....
> 
> I've got some data I'll load in from a file...
> 
> rm(list=ls(all=TRUE))
> trees <- read.table( "c:/cruisepak/data.txt", header=T)
> trees$ct <- 1

That is incorrect usage: you set the last element to 1, and you used list
indexing on a data frame.  Either use

tree["ct"] <- 1

or, better,  use a value of the correct length.  (As from 1.8.0 using
$ with data frames is supported.)

> And when I create some temp variable, then split the data to perform further
> processing, the additional column doesn't maintain the data correctly....

Actually, it was maintained correctly.

> mtrees <- trees[trees$m == 1,]
> ctrees <- trees[trees$m == 0,]
> 
> The results are as follows...
> 
> > trees
> plot tree m sp dbh tht ct
> 1      1    1 1 DF  44 185 1
> 3      1    3 0 DF  40 192  1
> .....blah, blah, blah......
> 6      1    6 0 DF  26 156   1
> 8      1    8 0 DF  26 155   1

That's a bug that got fixed in 1.8.0.
 
> but,
> >mtrees
>     plot tree m sp dbh tht ct
> 1      1    1 1 DF  44 185     1
> 2      1    2 1 DF  38 188    NA
> 17     2    6 1 DF  26 174    NA
> 26     3    1 1 DF  42 185    NA
> 
> and
> 
> >ctrees
> > ctrees
>     plot tree m sp dbh tht  ct
> 3      1    3 0 DF  40 192    NA
> 4      1    4 0 DF  33 148    NA
> 5      1    5 0 DF  43 182    NA
> 
> when the value of ct for all the records in all the data.frames should be 1,
> not NA.
> 
> Why is that? Am I missing a step here? I'm running R 1.7.1 on Win2k.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Alan.Jackson at shell.com  Thu Nov  6 18:56:19 2003
From: Alan.Jackson at shell.com (Jackson, Alan AK SIEP-EPT-AEN)
Date: Thu, 6 Nov 2003 11:56:19 -0600
Subject: [R] R for various ports of linux
Message-ID: <A3B4E948E728054CAC7A6D9C55EAB6A3479CF2@houic-s-348.americas.shell.com>

Ahh that's the beauty of gentoo Linux and emerge. You get to compile from source, but at the same time it keeps track of what you have done. There is now a Freshmeat project for emerge on other platforms, so others can take advantage of this model if they wish.


Alan Jackson
Staff Geophysicist
Shell International Exploration and Production Inc.
3737 Bellaire Blvd, P O Box 481, Houston, Texas 77001-0481, USA

Tel: +0117132457355 none Other Tel: +011-713-245-7355
Email: Alan.Jackson at shell.com
Internet: http://www.shell.com/eandp-en


-----Original Message-----
From: Ben Bolker [mailto:bolker at zoo.ufl.edu]
Sent: Wednesday, November 05, 2003 4:29 PM
To: Jason Turner
Cc: R-help at stat.math.ethz.ch; Nathan Leon Pace, MD,MStat
Subject: Re: [R] R for various ports of linux



  I've always built from source and almost never had to do anything beyond 
"tar zxf sources.tgz; ./configure; make; make install" (on various Red Hat 
versions).  On the other hand ... I've been hoping to move in the 
direction of an apt- or rpm-based solution to get a better handle on 
tracking package versions etc. etc. across multiple machines ...  It does 
seem as though the Debian folks (Eddelbuettel [sp]?) are very quick about 
packaging apt versions ...

   Ben

On Thu, 6 Nov 2003, Jason Turner wrote:

> Nathan Leon Pace, MD, MStat wrote:
> 
> > To all:
> > 
> > I currently download the R binaries for Redhat 7.x Linux.
> > 
> > There is considerable turmoil in the vendors of Linux. Redhat apparently 
> > is changing it's business model to paid versions.
> > 
> > This might motivate my department to use a different vendor of Linux.
> > 
> > Is there anything predictable about which vendors/versions of Linux will 
> > have R binaries in the future?
> 
> Short answer: build from source.  You won't regret it.
> 
> Long answer:
> The "build from source" approach is remarkably painless under any Linux 
> distribution I've tried (RH, SuSE, Slackware, et. al.).  It's also 
> painless under Solaris.
> 
> The days of having to be a programmer to build R from source have been 
> over for years.  If you're computer literate enough to use R, you're 
> probably over-qualified to build from sources.
> 
> Kudos to R-core for their attention to detail in making what's 
> complicated "under the hood" quite simple for the end user.
> 
> Alternate answer:
> If you absolutely must have binaries, there will be binaries as long as 
> there are users of your OS with time they wish to commit to building 
> them.  This may be where your sysadmin steps in :)
> 
> Cheers
> 
> Jason
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Thu Nov  6 19:04:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Nov 2003 18:04:32 +0000 (GMT)
Subject: [R] GDB under windows
In-Reply-To: <fh1lqvs39akh8t7m9l3hva8onhsvuqn8oq@4ax.com>
Message-ID: <Pine.LNX.4.44.0311061757520.16383-100000@gannet.stats>

On Thu, 6 Nov 2003, Duncan Murdoch wrote:

> On Thu, 6 Nov 2003 11:04:25 -0000 , "Marsland, John"
> <John.Marsland at CommerzbankIB.com> wrote :
> 
> >Does anybody have some simple instructions to get me going using the GNU
> >debugger GDB under windows with R? 
> >
> >The R Extensions manual mentions briefly debugging under unix, but I've seen
> >seen GDB mention in the Bloodshed Dev C++ IDE so it should be possible to
> >use it with R?
> 
> I've got a few tips beyond those in the FAQ, but haven't had a chance
> to write them down anywhere.  If anyone wants to volunteer to write
> this up, I think it would be worthwhile putting them in a web page for
> future reference.
> 
> One tip:  in recent versions of R (but hopefully not in 1.8.1), gdb
> always traps on a few memory allocation errors during startup.  This
> is irritating but harmless, continuing from that point on will
> eventually get R to start.

That is unlikely to be fixed in 1.8.1 but is already fixed in R-devel.  
The changes involved are quite far-reaching.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gregory_r_warnes at groton.pfizer.com  Thu Nov  6 20:16:18 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu, 6 Nov 2003 14:16:18 -0500 
Subject: [R] Contrast
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AA49@groexmb02.pfizer.com>

Or ?contrast in the Design library.

-G

> -----Original Message-----
> From: Simon Blomberg [mailto:Simon.Blomberg at anu.edu.au]
> Sent: Tuesday, November 04, 2003 8:32 PM
> To: Igor Roytberg; R-help at stat.math.ethz.ch
> Subject: RE: [R] Contrast
> 
> 
> see ?fit.contrast in library gregmisc.
> 
> Cheers,
> 
> Simon.
> 
> Simon Blomberg, PhD
> Depression & Anxiety Consumer Research Unit
> Centre for Mental Health Research
> Australian National University
> http://www.anu.edu.au/cmhr/
> Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379
> 
> 
> > -----Original Message-----
> > From: Igor Roytberg [mailto:ir1982 at u.washington.edu]
> > Sent: Wednesday, 5 November 2003 12:04 PM
> > To: R-help at stat.math.ethz.ch
> > Subject: [R] Contrast
> > 
> > 
> > Could anyone please explain how to set up contrasts between 
> > means in R. I want to know if "before I conduct an experiment 
> > and believe the mean for 1 and 2 will be different from means 
> > 3 and 4, Is this true?"  That is what I have to prove or 
> > disprove, I thought that contrasts would be the way to go. 
> > Thanks for the help. 
> > 
> > Igor
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From vograno at sbcglobal.net  Thu Nov  6 20:39:58 2003
From: vograno at sbcglobal.net (Vadim Ogranovich)
Date: Thu, 6 Nov 2003 11:39:58 -0800
Subject: [R] building r-patch
In-Reply-To: <Pine.LNX.4.44.0311060707300.26300-100000@gannet.stats>
Message-ID: <000701c3a49d$c90aba10$c10100c8@VOGRANO>

Thank you for Dirk Eddelbuettel and Prof. Ripley for pointing out to
tools/rsync-recommended. Maybe it is wort mentioning in the R
Administration guide and in the INSTALL file?

Thanks,
Vadim

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Wednesday, November 05, 2003 11:10 PM
> To: vograno at yahoo.com
> Cc: R-Help
> Subject: Re: [R] building r-patch
> 
> 
> The first is more or less what you should expect.
> 
> On Wed, 5 Nov 2003, Vadim Ogranovich wrote:
> 
> > Hi,
> >  
> > I am building r-patch from the sources (rsync-ed today).
> >  
> > make check produced the following message:
> >  
> > running tests of Internet and socket functions
> >   expect some differences
> > make[3]: Entering directory `/usr/evahome/vograno/R/tests' running 
> > code in 'internet.R' ... OK comparing 'internet.Rout' to 
> > './internet.Rout.save' ...18c18 < Content type `text/plain; 
> > charset=iso-8859-1' length 134991 bytes
> > ---
> > > Content type `text/plain; charset=iso-8859-1' length 124178 bytes
> > 22,23c22,23
> > < .......... .......... .......... .
> > < downloaded 131Kb
> > ---
> > > .......... .......... .
> > > downloaded 121Kb
> > 25c25
> > < [1] 273
> > ---
> > > [1] 251
> > 60,61d59
> > < Error in url(" <http://foo.bar> http://foo.bar", "r") : unable to 
> > open connection < In addition: Warning message:
> > 62a61
> > > Error in url(" <http://foo.bar> http://foo.bar", "r") : unable to 
> > > open
> > connection
> > 365,370c364
> > <  Login: root              Name: root
> > < Directory: /root                     Shell: /bin/tcsh
> > < Last login Wed Nov  5 13:34 (PST) on pts/1 from 
> > verdi.irisfinancial.com < New mail received Wed Nov  5 04:02 2003 
> > (PST)
> > <      Unread since Fri Oct 24 04:02 2003 (PDT )
> > < No Plan.
> > ---
> > > Error in make.socket(host, port) : Socket not established
> >  OK
> >     
> >  
> >  
> > I noticed that I had to expect some differences so my 
> question is how 
> > to tell whether it's harmless or not?
> >  
> >  
> > Other questions are related to building of recommended packages:
> > * The src/library/Recommended directory was empty. Is it expected?
> 
> No.  You forgot to run tools/rsync-recommended in the sources.
> 
> > If
> > yes, how to download the entire bundle of recommended 
> packages (I know 
> > I can get them one by one)? Is install.packaes() the 
> recommended way?
> > * make check tried to test MASS and survival (and failed 
> because the 
> > packages were not there), but it didn't try to test the other 
> > recommended  packages. Why only these two?
> 
> It did not test those packages, it tried to make use of them. 
>  make check-all would have tested the recommended packages.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From joehl at gmx.de  Thu Nov  6 20:41:16 2003
From: joehl at gmx.de (Jens =?ISO-8859-1?Q?Oehlschl=E4gel?=)
Date: Thu, 6 Nov 2003 20:41:16 +0100 (MET)
Subject: Summary: [R] How to represent pure linefeeds chr(10) under R for
	Windows
Message-ID: <27454.1068147676@www48.gmx.net>


Thanks to all who have responded.
My concern was to be able to write a csv file that can have line feeds in
string columns chr(10).
Why? Excel allows line feeds chr(10) within cells and line breaks
chr(13)+chr(10) at line ending, 
but the windows version of R automatically replaces \n by \r\n in writing
and \r\n by \n in reading (text mode).

The clues for a solution came from Brian Ripley and Thomas Lumley: we need
to use "binary"  connection mode (will not replace \n by \r\n) and explicit
specification of line ending as "\r\n".
Testing with these gave the following results:

## write.table / read.table: a bit inconsistent: need text connection to
read and binary connection to write
## writeLines / readLines: readLines misses a sep= parameter to properly
read in such data
## writeChar / readChar: OK

Thanks again and
Best regards


Jens Oehlsch?gel



## Details

filename <- "c:/tmp/c2.csv"


## write.table / read.table: a bit inconsistent: need binary connection to
read and text connection to write

data <- data.frame(a='c\nd', b='"???????"')

# writing in text mode replaces \n by \r\n
file <- file(filename, "w")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double")
close(file)

# writing in binary mode does not replace \n, however the real line endings
are also \n instead of \r\n
file <- file(filename, "wb")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double")
close(file)

# using the eol parameter we can create the desired csv format (which can be
read by Excel
file <- file(filename, "wb")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double",
eol="\r\n")
close(file)


# for the read test write a dataset that avoids a reported bug in
read.table()
data <- data.frame(a=c(rep("x", 5), "c\nd"), b=c(rep("y", 5), '"???????"'))
file <- file(filename, "wb")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double",
eol="\r\n")
close(file)

# read astonishingly works on char mode connection
file <- file(filename, "r")
read.csv2(file)
close(file)

# and doesn't work on binary connection
file <- file(filename, "rb")
read.csv2(file)
close(file)



## writeLines / readLines: readLines misses a sep= parameter to properly
read in such data
data <- c('a;b', 'c\nd;"???????"')

# text mode substitutes \n -> \r\n like in write.table
file <- file(filename, "w")
writeLines(data, file, sep="\n")
close(file)

# we can write out the desired one using binary mode and sep="\r\n"
file <- file(filename, "wb")
writeLines(data, file, sep="\r\n")
close(file)

# However, we cannot read this in in binary mode, readLines misses a sep=
parameter
file <- file(filename, "rb")
readLines(file)
close(file)

# text mode replaces as expected
file <- file(filename, "r")
readLines(file)
close(file)



## writeChar / readChar: OK
data <- c('a;b\r\nc\nd;"???????"')

# writing text mode substitutes as expected
file <- file(filename, "w")
writeChar(data, file, eos=NULL)
close(file)

# writing binary mode works
file <- file(filename, "wb")
writeChar(data, file, eos=NULL)
close(file)

# reading binary mode works
file <- file(filename, "rb")
readChar(file, nchar(data))
close(file)

# reading text mode substitutes as expected
file <- file(filename, "r")
readChar(file, nchar(data))
close(file)



--



From paul.louisell at pw.utc.com  Thu Nov  6 20:33:26 2003
From: paul.louisell at pw.utc.com (Louisell, Paul T.)
Date: Thu, 6 Nov 2003 14:33:26 -0500 
Subject: [R] Question about computing offsets automatically
Message-ID: <7DD415E9F609F946BA0851B6D28B24421AF396@pusehe04.eh.pweh.com>

Hi,

I'm using R version 1.8.0 on Windows NT. When fitting a glm with Poisson
random component and a log link, I frequently need to include an offset.
Typically I use xtabs or table to get the counts for the contingency table,
and then I use as.data.frame.table to create a data frame that I can use in
the glm function. I have not found an option that allows me to total the
offset variable to obtain offsets for cells in the contingency table. 

For example, suppose I have the following data frame named Data:

  F1 F2 Off
1  A  C   4
2  A  C   3
3  A  C   2
4  B  C   3
5  A  D   2
6  A  D   4
7  B  D   1

xtabs(~F1+F2, data=Data) produces the contingency table:

   F2
F1  C D
  A 3 2
  B 1 1

And as.data.frame.table(xtabs(~F1+F2, data=Data)) changes the contingency
table to a data frame suitable for use in the glm function:

  F1 F2 Freq
1  A  C    3
2  B  C    1
3  A  D    2
4  B  D    1

What I'm looking for is some option that would add a 4th column to the
output of as.data.frame.table which contains the offsets for each cell in
the contingency table:

  F1 F2 Freq  Off
1  A  C    3    9
2  B  C    1    3
3  A  D    2    6
4  B  D    1    1

Does such an option exist somewhere in R (I wasn't able to find it in the
documentation for the table, xtabs, as.data.frame.table, or glm functions)?
I can obtain the Off column easily enough in a simple loop, but I thought
there might be an option for this somewhere.
	

Paul Louisell
Statistician
(860) 565-5417
louisept at pweh.com



From MSchwartz at medanalytics.com  Thu Nov  6 21:31:49 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 06 Nov 2003 14:31:49 -0600
Subject: [R] Question about computing offsets automatically
In-Reply-To: <7DD415E9F609F946BA0851B6D28B24421AF396@pusehe04.eh.pweh.com>
References: <7DD415E9F609F946BA0851B6D28B24421AF396@pusehe04.eh.pweh.com>
Message-ID: <1068150709.6055.336.camel@localhost.localdomain>

On Thu, 2003-11-06 at 13:33, Louisell, Paul T. wrote:
> Hi,
> 
> I'm using R version 1.8.0 on Windows NT. When fitting a glm with Poisson
> random component and a log link, I frequently need to include an offset.
> Typically I use xtabs or table to get the counts for the contingency table,
> and then I use as.data.frame.table to create a data frame that I can use in
> the glm function. I have not found an option that allows me to total the
> offset variable to obtain offsets for cells in the contingency table. 
> 
> For example, suppose I have the following data frame named Data:
> 
>   F1 F2 Off
> 1  A  C   4
> 2  A  C   3
> 3  A  C   2
> 4  B  C   3
> 5  A  D   2
> 6  A  D   4
> 7  B  D   1
> 
> xtabs(~F1+F2, data=Data) produces the contingency table:
> 
>    F2
> F1  C D
>   A 3 2
>   B 1 1
> 
> And as.data.frame.table(xtabs(~F1+F2, data=Data)) changes the contingency
> table to a data frame suitable for use in the glm function:
> 
>   F1 F2 Freq
> 1  A  C    3
> 2  B  C    1
> 3  A  D    2
> 4  B  D    1
> 
> What I'm looking for is some option that would add a 4th column to the
> output of as.data.frame.table which contains the offsets for each cell in
> the contingency table:
> 
>   F1 F2 Freq  Off
> 1  A  C    3    9
> 2  B  C    1    3
> 3  A  D    2    6
> 4  B  D    1    1
> 
> Does such an option exist somewhere in R (I wasn't able to find it in the
> documentation for the table, xtabs, as.data.frame.table, or glm functions)?
> I can obtain the Off column easily enough in a simple loop, but I thought
> there might be an option for this somewhere.


I don't know of an easy 'option' approach, but you can use aggregate()
to get the sums and then do a cbind() to add the fourth column:

> aggregate(Data$Off, list(F1 = Data$F1, F2 = Data$F2), sum)
  F1  F2 x
1  A   C 9
2  B   C 3
3  A   D 6
4  B   D 1

So:

> df <- as.data.frame.table(xtabs(~F1+F2, data = Data))
> df
  F1  F2 Freq
1  A   C    3
2  B   C    1
3  A   D    2
4  B   D    1

> Off <- aggregate(Data$Off, list(F1 = Data$F1, F2 = Data$F2), sum)$x
> Off
[1] 9 3 6 1

> cbind(df, Off)
  F1  F2 Freq Off
1  A   C    3   9
2  B   C    1   3
3  A   D    2   6
4  B   D    1   1
 

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Thu Nov  6 21:33:04 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu,  6 Nov 2003 15:33:04 -0500 (EST)
Subject: Summary: [R] How to represent pure linefeeds chr(10) under R for
	Windows
Message-ID: <20031106203304.8BF07394F@mprdmxin.myway.com>



Its also possible to avoid these intricacies by not 
using an intermediate text representation, i.e. csv, 
in the first place.  

The following R code uses the free dataload utility 
(Google search for Baird dataload utility) to create 
an .xls file from data frame, x:

   save(x,file="x.rda")
   system("dataload x.rda x.xls/u")

At this point you can read x.xls into Excel.

---
Date: Thu, 6 Nov 2003 20:41:16 +0100 (MET) 
From: Jens =?ISO-8859-1?Q?Oehlschl=E4gel?= <joehl at gmx.de>
To: <r-help at stat.math.ethz.ch> 
Subject: Summary: [R] How to represent pure linefeeds chr(10) under R for Windows 

 
 

Thanks to all who have responded.
My concern was to be able to write a csv file that can have line feeds in
string columns chr(10).
Why? Excel allows line feeds chr(10) within cells and line breaks
chr(13)+chr(10) at line ending, 
but the windows version of R automatically replaces \n by \r\n in writing
and \r\n by \n in reading (text mode).

The clues for a solution came from Brian Ripley and Thomas Lumley: we need
to use "binary" connection mode (will not replace \n by \r\n) and explicit
specification of line ending as "\r\n".
Testing with these gave the following results:

## write.table / read.table: a bit inconsistent: need text connection to
read and binary connection to write
## writeLines / readLines: readLines misses a sep= parameter to properly
read in such data
## writeChar / readChar: OK

Thanks again and
Best regards


Jens Oehlschgel



## Details

filename <- "c:/tmp/c2.csv"


## write.table / read.table: a bit inconsistent: need binary connection to
read and text connection to write

data <- data.frame(a='c\nd', b='""')

# writing in text mode replaces \n by \r\n
file <- file(filename, "w")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double")
close(file)

# writing in binary mode does not replace \n, however the real line endings
are also \n instead of \r\n
file <- file(filename, "wb")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double")
close(file)

# using the eol parameter we can create the desired csv format (which can be
read by Excel
file <- file(filename, "wb")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double",
eol="\r\n")
close(file)


# for the read test write a dataset that avoids a reported bug in
read.table()
data <- data.frame(a=c(rep("x", 5), "c\nd"), b=c(rep("y", 5), '""'))
file <- file(filename, "wb")
write.table(data, row.names=FALSE, file=file, sep=";", qmethod="double",
eol="\r\n")
close(file)

# read astonishingly works on char mode connection
file <- file(filename, "r")
read.csv2(file)
close(file)

# and doesn't work on binary connection
file <- file(filename, "rb")
read.csv2(file)
close(file)



## writeLines / readLines: readLines misses a sep= parameter to properly
read in such data
data <- c('a;b', 'c\nd;""')

# text mode substitutes \n -> \r\n like in write.table
file <- file(filename, "w")
writeLines(data, file, sep="\n")
close(file)

# we can write out the desired one using binary mode and sep="\r\n"
file <- file(filename, "wb")
writeLines(data, file, sep="\r\n")
close(file)

# However, we cannot read this in in binary mode, readLines misses a sep=
parameter
file <- file(filename, "rb")
readLines(file)
close(file)

# text mode replaces as expected
file <- file(filename, "r")
readLines(file)
close(file)



## writeChar / readChar: OK
data <- c('a;b\r\nc\nd;""')

# writing text mode substitutes as expected
file <- file(filename, "w")
writeChar(data, file, eos=NULL)
close(file)

# writing binary mode works
file <- file(filename, "wb")
writeChar(data, file, eos=NULL)
close(file)

# reading binary mode works
file <- file(filename, "rb")
readChar(file, nchar(data))
close(file)

# reading text mode substitutes as expected
file <- file(filename, "r")
readChar(file, nchar(data))
close(file)



_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From jblazi at gmx.de  Thu Nov  6 21:50:41 2003
From: jblazi at gmx.de (JB)
Date: Thu, 06 Nov 2003 21:50:41 +0100
Subject: [R] newbie's additional (probably to some extent OT) questions
Message-ID: <6.0.0.22.2.20031106213701.01bd0548@pop.gmx.de>

(1)
So finally, thank to your help I have this:

  summary(lm(x ~ 0+I(t^2)))

And then I get this result:
=================================================
Call:
lm(formula = x ~ 0 + I(t^2))

Residuals:
        Min         1Q     Median         3Q        Max
-3.332e-02 -9.362e-03  1.169e-05  1.411e-02  3.459e-02

Coefficients:
         Estimate Std. Error t value Pr(>|t|)
I(t^2) 0.0393821  0.0001487   264.8   <2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 0.01945 on 18 degrees of freedom
Multiple R-Squared: 0.9997,     Adjusted R-squared: 0.9997
F-statistic: 7.014e+04 on 1 and 18 DF,  p-value: < 2.2e-16
=================================================

I see in MuPad, that Delta^2 is 0.006813. Now is not the standard error the 
square root of Delta^2? Should I not get 0.069 as standard error?

(2)
When I use the model
summary(lm(x ~ I(t^2)))
I get (of course) another result with a slightly smaller Delta^2. But I do 
not expect such an error as this would mean that there was a systematic 
error in our measurement of the distance and if I understand the result of 
R correctly, the error was 0.04m which is impossible:

==========================================================
Call:
lm(formula = x ~ I(t^2))

Residuals:
        Min         1Q     Median         3Q        Max
-0.0202520 -0.0116533 -0.0006036  0.0036699  0.0432987

Coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept) 0.0427606  0.0161085   2.655   0.0167 *
I(t^2)      0.0379989  0.0005367  70.801   <2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 0.01683 on 17 degrees of freedom
Multiple R-Squared: 0.9966,     Adjusted R-squared: 0.9964
F-statistic:  5013 on 1 and 17 DF,  p-value: < 2.2e-16
=====================================================

What is going on here?
(Sorry but I am only a high school teacher and have not much idea of 
statistics.)

TIA,

JB



From thomas at holm.cn  Thu Nov  6 22:08:26 2003
From: thomas at holm.cn (Thomas Holm)
Date: Thu, 6 Nov 2003 23:08:26 +0200
Subject: [R]Copula in R? 
In-Reply-To: <6.0.0.22.2.20031106213701.01bd0548@pop.gmx.de>
Message-ID: <001501c3a4aa$354c8a30$6600a8c0@acernomdu1aktf>

Is there any function to mesure different copulas in R?
Would appreciate any codes or whatever information you may have. 

Thank you in advance 

Thomas Holm
 

thomas at holm.cn



-----Ursprungligt meddelande-----
Fr?n: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] F?r JB
Skickat: den 6 november 2003 22:51
Till: R-help at stat.math.ethz.ch
?mne: [R] newbie's additional (probably to some extent OT) questions


(1)
So finally, thank to your help I have this:

  summary(lm(x ~ 0+I(t^2)))

And then I get this result:
=================================================
Call:
lm(formula = x ~ 0 + I(t^2))

Residuals:
        Min         1Q     Median         3Q        Max
-3.332e-02 -9.362e-03  1.169e-05  1.411e-02  3.459e-02

Coefficients:
         Estimate Std. Error t value Pr(>|t|)
I(t^2) 0.0393821  0.0001487   264.8   <2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 0.01945 on 18 degrees of freedom
Multiple R-Squared: 0.9997,     Adjusted R-squared: 0.9997
F-statistic: 7.014e+04 on 1 and 18 DF,  p-value: < 2.2e-16
=================================================

I see in MuPad, that Delta^2 is 0.006813. Now is not the standard error
the 
square root of Delta^2? Should I not get 0.069 as standard error?

(2)
When I use the model
summary(lm(x ~ I(t^2)))
I get (of course) another result with a slightly smaller Delta^2. But I
do 
not expect such an error as this would mean that there was a systematic 
error in our measurement of the distance and if I understand the result
of 
R correctly, the error was 0.04m which is impossible:

==========================================================
Call:
lm(formula = x ~ I(t^2))

Residuals:
        Min         1Q     Median         3Q        Max
-0.0202520 -0.0116533 -0.0006036  0.0036699  0.0432987

Coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept) 0.0427606  0.0161085   2.655   0.0167 *
I(t^2)      0.0379989  0.0005367  70.801   <2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 0.01683 on 17 degrees of freedom
Multiple R-Squared: 0.9966,     Adjusted R-squared: 0.9964
F-statistic:  5013 on 1 and 17 DF,  p-value: < 2.2e-16
=====================================================

What is going on here?
(Sorry but I am only a high school teacher and have not much idea of 
statistics.)

TIA,

JB

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
###########################################
This message has been scanned by F-Secure Anti-Virus for Internet Mail.
For more information, connect to http://www.F-Secure.com/



From mmiller3 at iupui.edu  Thu Nov  6 22:37:12 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Thu, 06 Nov 2003 16:37:12 -0500
Subject: [R] newbie's additional (probably to some extent OT) questions
In-Reply-To: <6.0.0.22.2.20031106213701.01bd0548@pop.gmx.de> (jblazi@gmx.de's
	message of "Thu, 06 Nov 2003 21:50:41 +0100")
References: <6.0.0.22.2.20031106213701.01bd0548@pop.gmx.de>
Message-ID: <878ymtdvqv.fsf@lumen.indyrad.iupui.edu>

>>>>> "JB" == JB  <jblazi at gmx.de> writes:

    > (1) So finally, thank to your help I have this:

    >   summary(lm(x ~ 0+I(t^2)))
[...]

Would you post your data set?  It is hard for me to sort out what
is going on without seeing the input.

Regards, Mike



From mathieu.drapeau at bioneq.qc.ca  Fri Nov  7 03:53:08 2003
From: mathieu.drapeau at bioneq.qc.ca (Mathieu Drapeau)
Date: Thu, 06 Nov 2003 21:53:08 -0500
Subject: [R] R input file scanning
Message-ID: <3FAB0914.3080509@bioneq.qc.ca>

Hi,
I would like to know how can I solve my problem...
I want to load some data (surrounded by a tag) that are stored in a file 
that contains also some scrap (header and descriptions) that I want to 
skip. How can I do that?

Thanks,
Mathieu



From apv at capital.net  Thu Nov  6 23:13:56 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 06 Nov 2003 17:13:56 -0500
Subject: [R] RMySQL for Windows
Message-ID: <1068156836.3935.27.camel@redtail.mydomain.home>

Hi,

I have been using RMySQL under linux.  Does anybody know what is
involved in compiling it for Windows?  There is not a binary version
available.

Thanks,
Arend



From jasont at indigoindustrial.co.nz  Thu Nov  6 23:24:23 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 07 Nov 2003 11:24:23 +1300
Subject: [R] R input file scanning
In-Reply-To: <3FAB0914.3080509@bioneq.qc.ca>
References: <3FAB0914.3080509@bioneq.qc.ca>
Message-ID: <3FAACA17.20104@indigoindustrial.co.nz>

Mathieu Drapeau wrote:

> Hi,
> I would like to know how can I solve my problem...
> I want to load some data (surrounded by a tag) that are stored in a file 
> that contains also some scrap (header and descriptions) that I want to 
> skip. How can I do that?
> 

By writing some code to use readLines() or scan().  I'll be more 
specific if you will.  :)

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From rpeng at jhsph.edu  Thu Nov  6 23:31:15 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 06 Nov 2003 17:31:15 -0500
Subject: [R] R input file scanning
In-Reply-To: <3FAB0914.3080509@bioneq.qc.ca>
References: <3FAB0914.3080509@bioneq.qc.ca>
Message-ID: <3FAACBB3.702@jhsph.edu>

You can use readLines() on a file connection to read line by line and 
throw out the header stuff.  Once you get to the point where the data 
start, you can use read.table() (or something similar).

-roger

Mathieu Drapeau wrote:

> Hi,
> I would like to know how can I solve my problem...
> I want to load some data (surrounded by a tag) that are stored in a 
> file that contains also some scrap (header and descriptions) that I 
> want to skip. How can I do that?
>
> Thanks,
> Mathieu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rdeb_question at yahoo.com  Thu Nov  6 23:42:55 2003
From: rdeb_question at yahoo.com (Simon Rex)
Date: Thu, 6 Nov 2003 14:42:55 -0800 (PST)
Subject: [R] some error messages using arm cpu with Debian
Message-ID: <20031106224255.77353.qmail@web21507.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031106/3c6b63b3/attachment.pl

From edd at debian.org  Thu Nov  6 23:53:18 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 6 Nov 2003 16:53:18 -0600
Subject: [R] some error messages using arm cpu with Debian
In-Reply-To: <20031106224255.77353.qmail@web21507.mail.yahoo.com>
References: <20031106224255.77353.qmail@web21507.mail.yahoo.com>
Message-ID: <20031106225318.GA12831@sonny.eddelbuettel.com>

On Thu, Nov 06, 2003 at 02:42:55PM -0800, Simon Rex wrote:
> I have a small handheld pc having ARM process as a CPU. I installed debian and installed R using apt-get command. Everything worked great except for drawing even simple graphs
>  
> x <- 1:10
> plot(x)
>  
> I got error messages
>  
>         1: Nonfinite axis limits [GScale(nan,nan,1, .); log=0] 
>         2: relative range of values = 9.0072e+15 * EPS, is small (axis 1). 
>         3: Nonfinite axis limits [GScale(-inf,inf,2, .); log=0] 
>         4: relative range of values = 9.0072e+15 * EPS, is small (axis 2). 
>    
> I searched R-help Archives hoping answers to this problem and ran into this message
>  
> *****************
> 
> Debian tries to build its packages on a variety of platforms. The arm 
> platform compiled 0.90.1 (the last Debian release before the Debian package 
> required an Atlas library, something we no longer require) failed in 'make 
> check'. The log snippet follows; I traced this to the example(Bessel) code. 
>   
> > matplot(nu, t(outer(xx,nu, besselI)), type = 'l', ylim = c(-50,200), 
> + main = expression(paste("Bessel ",I[nu](x)," for fixed ", x, 
> + ", as ",f(nu))), 
> + xlab = expression(nu)) 
> Error in title(main = main, sub = sub, xlab = xlab, ylab = ylab, ...) : 
>         Metric information not yet available for this device 
>         In addition: Warning messages: 
>         1: Nonfinite axis limits [GScale(nan,nan,1, .); log=0] 
>         2: relative range of values = 9.0072e+15 * EPS, is small (axis 1). 
>         3: Nonfinite axis limits [GScale(-inf,inf,2, .); log=0] 
>         4: relative range of values = 9.0072e+15 * EPS, is small (axis 2). 
>         Execution halted 
> 
> Casual inspection suggests that GScale(nan,nan,1, .) is probably 
> incorrect. Now, src/nmath/bessel* provide the Bessel functions but does this 
> reflect a potential libc bug in IEEE handling? 
> 
> I have also asked on the debian-arm mailing list, but no result so far. I 
> have some access to an arm box and could compile small test cases if that 
> helped. 
> 
> Dirk 
> ****************
> 
> Is there any way I can fix this problem ? I checked Debain FTP sites to find Atlas but there is no Atlas lib for arm. 

Yes, there is no Atlas, and we had a small bug in as much as we depended on
atlas for all arches. That is fixed the most recent versions. Generally,
there are lots of successful builds:

http://buildd.debian.org/build.php?arch=arm&pkg=r-base

However, Peter D looked into this a little, and as I recall, found some FPU
isssues. You should probably get in contact with the Debian arm porters, as
well as r-devel. If you could act as a conduit between arm, R and Debian to
improve this, we would all appreciate this.

Regards, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From bates at stat.wisc.edu  Fri Nov  7 00:06:09 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 06 Nov 2003 17:06:09 -0600
Subject: R.com domain [was: [R] Lexical scoping]
In-Reply-To: <200311061712.hA6HClN5012563@uranus.idi.ntnu.no>
References: <200311061712.hA6HClN5012563@uranus.idi.ntnu.no>
Message-ID: <6rsml1f672.fsf@bates4.stat.wisc.edu>

r at r.com writes:

...


Why are you faking a "From:" address of R at R.com?  There is no such
domain.  Single letter domain names like R.com (and R.net and R.org)
are reserved by the Internet Assigned Numbers Authority (IANA), which
is the reason that our domain is R-project.org and not R.org.

Your message came through a Norwegian university 

Organization Name..........: Norges Teknisk-Naturvitenskapelige Universitet
Organization Number........: 974767880
Post Address...............: H?gskoleringen 1
Postal Code................: N-7491
Postal Area................: Trondheim
Country....................: Norway

after the first hop from nobody at localhost

I am replying to the list because I can't reply to your apparent
address.



From wolski at molgen.mpg.de  Fri Nov  7 00:13:04 2003
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Fri, 7 Nov 2003 00:13:04 +0100 (MET)
Subject: [R] Flury faces.
Message-ID: <Pine.OSF.4.31.0311070012001.25116-100000@harry.molgen.mpg.de>

How to plot if possible flury faces in R?
/Eryk



From wolski at molgen.mpg.de  Fri Nov  7 00:14:41 2003
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Fri, 7 Nov 2003 00:14:41 +0100 (MET)
Subject: [R] Plotting Andrew's curves?
Message-ID: <Pine.OSF.4.31.0311070013260.25116-100000@harry.molgen.mpg.de>

Hi!
Is there a function for plotting Andrew's curves in R?
/Eryk



From tblackw at umich.edu  Fri Nov  7 00:24:23 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 6 Nov 2003 18:24:23 -0500 (EST)
Subject: [R] newbie's additional (probably to some extent OT) questions
In-Reply-To: <6.0.0.22.2.20031106213701.01bd0548@pop.gmx.de>
References: <6.0.0.22.2.20031106213701.01bd0548@pop.gmx.de>
Message-ID: <Pine.SOL.4.58.0311061735040.27133@millipede.gpcc.itd.umich.edu>

JB and Michael  -

I'm coming into this without having reviewed the earlier emails
(if there are any) in this thread.  But I will guess that the
data come from a high school physics experiment on gravitational
acceleration which drops a weight dragging a paper tape through
a buzzer with a piece of carbon paper in it.  This prints periodic
marks on the paper tape.  The data  x  are the distances traveled
at successive time points following time zero.

I think it's DYNAMITE that you're actually doing this data analysis.
It's what I always wanted to do as a high school student, but didn't
have the technical background then to carry out.  In fact ... come to
think of it ... I'm pretty sure I STILL HAVE my high school ticker
tapes folded up among my high school papers somewhere, 35 years
later, still waiting to be properly analyzed !

It makes sense to fit a no-intercept model with no linear term
and only a quadratic term.  The model formula  x ~ 0 + I(t^2)
does this correctly.  (If one wanted to account for friction,
the linear term would come back in.)

Question 1 involves a distinction between the standard deviation
of the residuals and the standard error of an estimate for the
single coefficient in the model.  These are not at all the same
concept.  The coefficient estimate behaves like a sample average,
and has much smaller sampling variation over repeated experiments
than one observation would.  In the no-intercept model, the
standard deviation of the residuals is stated as 0.01945 on 18 df.
In the model WITH an intercept, it is stated as  0.01683 on 17 df.

I don not understand 'MuPad' but I observe an apparent typographical
error in which the second residual standard deviation is reported
instead as  0.006813.  All of these three numbers represent the
residual standard deviation.  Naturally, this is much larger than
the standard error of an estimate:  0.0001487  or  0.0005367.

Question 2 refers to the estimated value for the intercept in a
model with constant and quadratic terms only (no linear term).
The estimated value is  0.043 +- 0.016  (no units are given).
Gosh, I'm not surprised.  The observations and the predictors
are all non-negative.  Linear regression produces an unbiased
estimate, given its assumptions, but when there is uncertainty
in the predictors as well, it is known to be biased downward.
(Think of the "two regression lines".)  If some of that bias
shows up in the intercept, it's no surprise.  If this were a
mission-critical data set, I would certainly plot the residuals
against the fitted values and look for empirical evidence to
judge whether the quadratic-only model is adequate.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 6 Nov 2003, JB wrote:

> (1)
> So finally, thank to your help I have this:
>
>   summary(lm(x ~ 0+I(t^2)))
>
> And then I get this result:
> =================================================
> Call:
> lm(formula = x ~ 0 + I(t^2))
>
> Residuals:
>         Min         1Q     Median         3Q        Max
> -3.332e-02 -9.362e-03  1.169e-05  1.411e-02  3.459e-02
>
> Coefficients:
>          Estimate Std. Error t value Pr(>|t|)
> I(t^2) 0.0393821  0.0001487   264.8   <2e-16 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> Residual standard error: 0.01945 on 18 degrees of freedom
> Multiple R-Squared: 0.9997,     Adjusted R-squared: 0.9997
> F-statistic: 7.014e+04 on 1 and 18 DF,  p-value: < 2.2e-16
> =================================================
>
> I see in MuPad, that Delta^2 is 0.006813. Now is not the standard error the
> square root of Delta^2? Should I not get 0.069 as standard error?
>
> (2)
> When I use the model
> summary(lm(x ~ I(t^2)))
> I get (of course) another result with a slightly smaller Delta^2. But I do
> not expect such an error as this would mean that there was a systematic
> error in our measurement of the distance and if I understand the result of
> R correctly, the error was 0.04m which is impossible:
>
> ==========================================================
> Call:
> lm(formula = x ~ I(t^2))
>
> Residuals:
>         Min         1Q     Median         3Q        Max
> -0.0202520 -0.0116533 -0.0006036  0.0036699  0.0432987
>
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept) 0.0427606  0.0161085   2.655   0.0167 *
> I(t^2)      0.0379989  0.0005367  70.801   <2e-16 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> Residual standard error: 0.01683 on 17 degrees of freedom
> Multiple R-Squared: 0.9966,     Adjusted R-squared: 0.9964
> F-statistic:  5013 on 1 and 17 DF,  p-value: < 2.2e-16
> =====================================================
>
> What is going on here?
> (Sorry but I am only a high school teacher and have not much idea of
> statistics.)
>
> TIA,
>
> JB
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From andy_liaw at merck.com  Fri Nov  7 01:52:50 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 06 Nov 2003 19:52:50 -0500
Subject: [R] R input file scanning
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDE6@usrymx25.merck.com>

If the portion of the file that you want to read is "rectangular" (same
number of fields in all lines and same type of data in each column), you can
use either read.table() or scan() and supply the skip= argument to skip over
the headers you don't want to read in.

HTH,
Andy

> From: Mathieu Drapeau [mailto:mathieu.drapeau at bioneq.qc.ca] 
> 
> Hi,
> I would like to know how can I solve my problem...
> I want to load some data (surrounded by a tag) that are 
> stored in a file 
> that contains also some scrap (header and descriptions) that 
> I want to 
> skip. How can I do that?
> 
> Thanks,
> Mathieu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From andy_liaw at merck.com  Fri Nov  7 02:00:41 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 06 Nov 2003 20:00:41 -0500
Subject: [R] Plotting Andrew's curves?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDE8@usrymx25.merck.com>

Is that the technique for visualizing multivariate data by plotting linear
combinations of sine and cosine curves using the data values as
coefficients?  Seems to be fairly easy to cook up with a few lines of R
code...

Andy

> From: Eryk Wolski [mailto:wolski at molgen.mpg.de] 
> 
> Hi!
> Is there a function for plotting Andrew's curves in R?
> /Eryk



From day at programmer.net  Fri Nov  7 02:53:39 2003
From: day at programmer.net (Ben Day)
Date: Thu, 06 Nov 2003 20:53:39 -0500
Subject: [R] Q. About String indexing
Message-ID: <20031107015342.47100.qmail@mail.com>

Hi all - this is a very basic question: how does one index substrings of a character string, for example get the 2nd through 5th characters of the string "testing", in the R language? Indexing with square brackets seems only to work for vectors, lists, etc., and although I've found plenty of functions for concatenating strings, running substitutions with regexps and the like, I seem to be at a loss when it comes to indexing or selecting substrings.

I'm sure I'm missing something very obvious here, but I ask only after having scoured the basic help manuals.

I am not so subscribed to this list, so if any replies could be sent directly to me.

Thanks very much,
-----Ben
-- 
__________________________________________________________
Sign-up for your own personalized E-mail at Mail.com


Search Smarter - get the new eXact Search Bar for free!
http://www.exactsearchbar.com/



From MSchwartz at medanalytics.com  Fri Nov  7 03:10:34 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 06 Nov 2003 20:10:34 -0600
Subject: [R] Q. About String indexing
In-Reply-To: <20031107015342.47100.qmail@mail.com>
References: <20031107015342.47100.qmail@mail.com>
Message-ID: <1068171034.6055.359.camel@localhost.localdomain>

On Thu, 2003-11-06 at 19:53, Ben Day wrote:
> Hi all - this is a very basic question: how does one index substrings
> of a character string, for example get the 2nd through 5th characters
> of the string "testing", in the R language? Indexing with square
> brackets seems only to work for vectors, lists, etc., and although
> I've found plenty of functions for concatenating strings, running
> substitutions with regexps and the like, I seem to be at a loss when
> it comes to indexing or selecting substrings.
> 
> I'm sure I'm missing something very obvious here, but I ask only after
> having scoured the basic help manuals.
> 
> I am not so subscribed to this list, so if any replies could be sent
> directly to me.
> 
> Thanks very much,
> -----Ben


unlist(strsplit("testing",""))[2:5]
[1] "e" "s" "t" "i"

Use strsplit() to convert the string into a list of characters, where ""
is the separator.

Then use unlist() to convert the list into a vector and index the 2:5
characters.

See ?strsplit and ?unlist

HTH,

Marc Schwartz



From jfox at mcmaster.ca  Fri Nov  7 03:24:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 06 Nov 2003 21:24:02 -0500
Subject: [R] Q. About String indexing
In-Reply-To: <1068171034.6055.359.camel@localhost.localdomain>
References: <20031107015342.47100.qmail@mail.com>
	<20031107015342.47100.qmail@mail.com>
Message-ID: <5.1.0.14.2.20031106212318.01fb28f8@127.0.0.1>

Dear Ben and Mark,

substring and substr are also helpful here.

John

At 08:10 PM 11/6/2003 -0600, Marc Schwartz wrote:
>On Thu, 2003-11-06 at 19:53, Ben Day wrote:
> > Hi all - this is a very basic question: how does one index substrings
> > of a character string, for example get the 2nd through 5th characters
> > of the string "testing", in the R language? Indexing with square
> > brackets seems only to work for vectors, lists, etc., and although
> > I've found plenty of functions for concatenating strings, running
> > substitutions with regexps and the like, I seem to be at a loss when
> > it comes to indexing or selecting substrings.
> >
> > I'm sure I'm missing something very obvious here, but I ask only after
> > having scoured the basic help manuals.
> >
> > I am not so subscribed to this list, so if any replies could be sent
> > directly to me.
> >
> > Thanks very much,
> > -----Ben
>
>
>unlist(strsplit("testing",""))[2:5]
>[1] "e" "s" "t" "i"
>
>Use strsplit() to convert the string into a list of characters, where ""
>is the separator.
>
>Then use unlist() to convert the list into a vector and index the 2:5
>characters.
>
>See ?strsplit and ?unlist
>
>HTH,
>
>Marc Schwartz
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From tangsl8 at hotmail.com  Fri Nov  7 03:58:38 2003
From: tangsl8 at hotmail.com (Sen-Lin Tang)
Date: Fri, 07 Nov 2003 02:58:38 +0000
Subject: [R] XML package
Message-ID: <Sea2-F47nXAjnb7KUyO000216ca@hotmail.com>

Dear Sir/Madam,

I have tried to install biocoductor package. During the installation, there 
was an error message showing, there is no XML package available and 
suggested me to download from the R-project website. Unfortunately I could 
not find it. Could you give me a hand? Thanks a lot.

Cheers,

Sen-Lin



------------------------------------------------
Sen-Lin Tang (Ph.D.)

Postdoctoral Research Fellow
Microbiology Laboratory,
School of Veterinary Science,
The University of Melbourne,
Parkville, Victoria, 3010
Australia

Phone: +61-3-83447368
Email: tangsl8 at hotmail.com



From ripley at stats.ox.ac.uk  Fri Nov  7 04:01:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Nov 2003 03:01:55 +0000 (GMT)
Subject: [R] RMySQL for Windows
In-Reply-To: <1068156836.3935.27.camel@redtail.mydomain.home>
Message-ID: <Pine.LNX.4.44.0311070258590.27789-100000@gannet.stats>

There are instructions in the source code, and from the ReadMe on the 
Windows area of CRAN:

  RMySQL is available at http://stat.bell-labs.com/RS-DBI/download,
  provided by its maintainer, David A. James.

One caveat: binary versions of RMySQL have proved sensitive to the exact 
version of MySQL installed, so it is better to build from the sources on 
your own machine (if you can).

On 6 Nov 2003, Arend P. van der Veen wrote:

> I have been using RMySQL under linux.  Does anybody know what is
> involved in compiling it for Windows?  There is not a binary version
> available.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edd at debian.org  Fri Nov  7 04:07:34 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 6 Nov 2003 21:07:34 -0600
Subject: [R] XML package
In-Reply-To: <Sea2-F47nXAjnb7KUyO000216ca@hotmail.com>
References: <Sea2-F47nXAjnb7KUyO000216ca@hotmail.com>
Message-ID: <20031107030734.GA14931@sonny.eddelbuettel.com>

On Fri, Nov 07, 2003 at 02:58:38AM +0000, Sen-Lin Tang wrote:
> Dear Sir/Madam,
> 
> I have tried to install biocoductor package. During the installation, there 
> was an error message showing, there is no XML package available and 
> suggested me to download from the R-project website. Unfortunately I could 
> not find it. Could you give me a hand? Thanks a lot.

Try this for the source package:

	http://cran.au.r-project.org/src/contrib/XML_0.95-4.tar.gz
	
where I substituted .au. for the .us. location I'd use. Binary packages are
in the sibbling directories. 

If you happen to run Debian, thanks to Rafael's packaging work on this:

	$ apt-get install r-cran-xml
	
Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From MSchwartz at medanalytics.com  Fri Nov  7 04:32:04 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 06 Nov 2003 21:32:04 -0600
Subject: [R] Q. About String indexing
In-Reply-To: <5.1.0.14.2.20031106212318.01fb28f8@127.0.0.1>
References: <20031107015342.47100.qmail@mail.com>
	<20031107015342.47100.qmail@mail.com>
	<5.1.0.14.2.20031106212318.01fb28f8@127.0.0.1>
Message-ID: <1068175924.6055.385.camel@localhost.localdomain>

On Thu, 2003-11-06 at 20:24, John Fox wrote:
> Dear Ben and Mark,
> 
> substring and substr are also helpful here.
> 
> John


Quite true. 

As usual, there is usually more than one way to do things. The above
approach, given the C code, would be faster as the source vector and the
offsets of the substring increase in size.

This would become more influential if you want the resultant characters
as a single substring as opposed to a vector of the characters, which my
initial solution would yield.

> unlist(strsplit("testing", ""))[2:5]
[1] "e" "s" "t" "i"

> substr("testing", 2, 5)
[1] "esti"

Thanks John.

Marc



From jdn at cs.sfu.ca  Fri Nov  7 06:38:29 2003
From: jdn at cs.sfu.ca (Jason Nielsen)
Date: Thu, 06 Nov 2003 21:38:29 -0800 (PST)
Subject: [R] quadprog
Message-ID: <Pine.LNX.4.53.0311062134100.2528@lenny>

Hi all,

I'm trying to get quadprog to give me the Lagrange multipliers.  By taking
a look at the Fortran source it appears they are stored in the working
vector 'work'.  However, this working vector is larger than the number of
possible multipliers so I figure it also contains the slack variable etc.  
My problem is figuring out which values in the work array are the
multipliers so I can modify solve.QP.R to output them for me.  Any info
would be greatly appreciated.

Cheers,
Jason



From jblazi at gmx.de  Fri Nov  7 07:00:36 2003
From: jblazi at gmx.de (JB)
Date: Fri, 07 Nov 2003 07:00:36 +0100
Subject: [R] newbie's additional (probably to some extent OT)
  questions
Message-ID: <6.0.0.22.2.20031107070018.01becea0@pop.gmx.de>

At 07.11.2003 (00:24), Thomas W Blackwell wrote:
>JB and Michael  -
>
>But I will guess that the
>data come from a high school physics experiment on gravitational
>acceleration which drops a weight dragging a paper tape through
>a buzzer with a piece of carbon paper in it.  This prints periodic
>marks on the paper tape.  The data  x  are the distances traveled
>at successive time points following time zero.

No. It is a body (slider?) that is sliding down an inclined plane on an air 
cushion. we can determine the position of the slider pretty exactly (the 
error should be less than 0.01m). The clock starts when we release the body 
and it stops when the body passes a photo cell.

There are two data sets as we experimented with two different angles 
between plane table. The measurement of the angles is probably a bit less 
exact than the measurement of the position.

Here are the two data sets:
The positions are in the dx-list and are the same in both experiments:
dx-list = c( 1.60, 1.55,1.50,...,0.70) (19 values).

The corresponding dt-lists are
dt-list1 = 
c(6.44,6.29,6.1,6.09,6.02,5.87,5.68,5.65,5.52,5.43,5.30,5.20,5.01,4.88,4.74,4.61,4.44,4.36,4.12)

dt-list2 = 
c(3.98,3.86,3.78,3.72,3.65,3.59,3.51,3.45,3.37,3.28,3.22,3.14,3.07,2.96,2.89,2.81,2.74,2.61,2.55)

During the first series of measurements, tha body bumped against a boundary 
that was fixed on the inclined plane. By bumping against this boundray, the 
inclined plane, that has a much bigger mass than the body, was slightly 
pushed and after 15 measurements the position of this boundary changed by 
0.01m:


A------------------------------B---C

Here B should be a fixed position and A should be changed. According to our 
mistake B was changed a bit too. C is a boundary that stops the body from 
leavinf the air cushion (as those sliding bodies are expensive).

Then, when we took the second series of measurements, I "ordered" a pupil 
to stop tha body with his hand before bumping against C. And really, it 
seems to me that the second series is more precise.


>I think it's DYNAMITE that you're actually doing this data analysis.

Why? I always do this, but this year I started to involve a bit more 
statistics. I told about how the method of least squares was an "unbiased 
estimate" and that also some hypothesis testing is done (when I check 
whether the points lie on a parabola). The pupils are 16 to 18 years old. 
They have to draw dx against (dt)^2 as their homework and have to fit in a 
straight line. This is the way we do linear regression.

>It's what I always wanted to do as a high school student, but didn't
>have the technical background then to carry out.  In fact ... come to
>think of it ... I'm pretty sure I STILL HAVE my high school ticker
>tapes folded up among my high school papers somewhere, 35 years
>later, still waiting to be properly analyzed !

 From your explanations which follow this point, I do not understand a 
single word (the termini technici are all unknown to me) but I suspect that 
I pretty much would like to understand them. Sigh. Probably, I should have 
to read some work on statistics



From mn216 at columbia.edu  Fri Nov  7 08:16:44 2003
From: mn216 at columbia.edu (Murad Nayal)
Date: Fri, 07 Nov 2003 02:16:44 -0500
Subject: [R] clustering distributions
Message-ID: <3FAB46DC.C2E41103@columbia.edu>



Hi,

I have a dataset where each case is characterized by a histogram. I
would like to cluster these cases using a sensible distance measure,
possibly relative entropy? Is there a way I can use R facilities to do
this (hclust etc.). I couldn't find an alternative to dist that would
compute something like relative entropies. 

thanks
Murad



From rsoerum80 at hotmail.com  Fri Nov  7 08:53:00 2003
From: rsoerum80 at hotmail.com (=?iso-8859-1?B?UmFnbmhpbGQgU/hydW0=?=)
Date: Fri, 07 Nov 2003 07:53:00 +0000
Subject: [R] opposite function of strsplit() ?
Message-ID: <BAY10-F49PASI3KXjlR000617e3@hotmail.com>

Hi,

I what to solve this problem:

>alfab <- "ABCEDFG"                            #[1] "ABCEDFG"
>chara <- strsplit(alfab, "")                    #[1] "A" "B" "C" "E" "D" 
>"F" "G"
Then I do some changes before I want the character together again, say, 
remove two letters.
Now, "chara" is "A" "B" "E" "D" "G".
Is there any opposite function of strspilt()?

May anybody help me?
Thanks,
*Ragnhild"

_________________________________________________________________
MSN Foto http://www.msn.no/foto Fest dine digitale minner til papir



From ligges at statistik.uni-dortmund.de  Fri Nov  7 09:05:43 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 Nov 2003 09:05:43 +0100
Subject: [R] opposite function of strsplit() ?
In-Reply-To: <BAY10-F49PASI3KXjlR000617e3@hotmail.com>
References: <BAY10-F49PASI3KXjlR000617e3@hotmail.com>
Message-ID: <3FAB5257.2040400@statistik.uni-dortmund.de>

Ragnhild S?rum wrote:
> Hi,
> 
> I what to solve this problem:
> 
>> alfab <- "ABCEDFG"                            #[1] "ABCEDFG"
>> chara <- strsplit(alfab, "")                    #[1] "A" "B" "C" "E" 
>> "D" "F" "G"
> 
> Then I do some changes before I want the character together again, say, 
> remove two letters.
> Now, "chara" is "A" "B" "E" "D" "G".
> Is there any opposite function of strspilt()?
> 
> May anybody help me?

Yes, the help ?strsplit does!
It tells you: "See Also: 'paste' for the reverse".

Uwe Ligges




> Thanks,
> *Ragnhild"
> 
> _________________________________________________________________
> MSN Foto http://www.msn.no/foto Fest dine digitale minner til papir
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Fri Nov  7 09:10:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Nov 2003 08:10:07 +0000 (GMT)
Subject: [R] opposite function of strsplit() ?
In-Reply-To: <BAY10-F49PASI3KXjlR000617e3@hotmail.com>
Message-ID: <Pine.LNX.4.44.0311070809450.31440-100000@gannet.stats>

?paste

On Fri, 7 Nov 2003, Ragnhild S?rum wrote:

> I what to solve this problem:
> 
> >alfab <- "ABCEDFG"                            #[1] "ABCEDFG"
> >chara <- strsplit(alfab, "")                    #[1] "A" "B" "C" "E" "D" 
> >"F" "G"
> Then I do some changes before I want the character together again, say, 
> remove two letters.
> Now, "chara" is "A" "B" "E" "D" "G".
> Is there any opposite function of strspilt()?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rn001 at cebas.csic.es  Fri Nov  7 10:11:54 2003
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Fri, 7 Nov 2003 10:11:54 +0100
Subject: [R] precision in operations
Message-ID: <200311070852.hA78psR19437@natura.cebas.csic.es>

Hi all;
could you remind me what is the function to change the precision of the 
operations done in R? I can't remember nor find it.

Best regards

Javier



From maechler at stat.math.ethz.ch  Fri Nov  7 10:32:44 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 7 Nov 2003 10:32:44 +0100
Subject: Summary: [R] How to represent pure linefeeds chr(10) under R for
	Windows
In-Reply-To: <20031106203304.8BF07394F@mprdmxin.myway.com>
References: <20031106203304.8BF07394F@mprdmxin.myway.com>
Message-ID: <16299.26300.975062.287309@gargle.gargle.HOWL>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at myway.com>
>>>>>     on Thu,  6 Nov 2003 15:33:04 -0500 (EST) writes:

    Gabor> Its also possible to avoid these intricacies by not
    Gabor> using an intermediate text representation, i.e. csv,
    Gabor> in the first place.

    Gabor> The following R code uses the free dataload utility
    Gabor> (Google search for Baird dataload utility) to create
    Gabor> an .xls file from data frame, x:

    Gabor>    save(x,file="x.rda") 
    Gabor>    system("dataload x.rda x.xls/u")

    Gabor> At this point you can read x.xls into Excel.

Note that this has two "problems" IMO, which Jens' R-only
solution does not have:

1) dataload is *not* free software in the sense of the 
   Free Software Foundation  (which has existed for a much
   longer time than MS windows!):
   It's only "free" as in "free beer", not "free" as in "free speech" .
   For more, read the  "Free as in Freedom" main link on http://www.fsf.org/

2) dataload is only available as *binary* on *some* platforms,
   as opposed to R which is available to everyone working with
   it :-)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Pascal.Niklaus at unibas.ch  Fri Nov  7 11:29:02 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Fri, 07 Nov 2003 11:29:02 +0100
Subject: [R] Hierarchical glm - Followup
In-Reply-To: <3FAA7B74.9040106@unibas.ch>
References: <3FAA7B74.9040106@unibas.ch>
Message-ID: <3FAB73EE.7050205@unibas.ch>

Pascal A. Niklaus wrote:

> Hi all,
>
> I'm not sure how to correctly analyse the following data with glm, and 
> hope for some advice from this list, ideally showing how to specify 
> the model in R and perform the tests, and also for suggestions of 
> literature.
>
> The data structure is like this:
>
>   - 20 plant populations were investigated (random factor pop), which 
> belong to different habitat types (factor ht)
>   - Within each plant population, individuals were grouped into 3 size 
> classes (factor sz)
>   - For each individual, some count data were recorded
>
> The dependent variables I'd like to analyse are either poission of 
> binomially distributed.
>
> For gaussian data, I would use the following model:
>
>   ht + pop %in% ht + sz + sz:ht + sz : pop %in %ht
>
> ht would basically be tested against pop (because the population is 
> the unit of replication for ht), and sz against sz:pop:ht. (the 
> hypotheses to test are that ht has an effect, and whether the effect 
> of sz on individuals of a population depends on ht)
>
> However, I do not know how to translate this to the deviance analysis 
> case. For example, when I fit the whole model, and then drop ht to 
> test for the effect of ht, the effect of ht shows up in pop (I 
> understand why, but don't know how to do this otherwise). If I compare 
> the null model to the model including ht only, do I then commit a 
> pseudoreplication?
>
> Thanks for your help
>
> Pascal 


I have seen F-tests being used to compare the mean deviance explained by 
a factor (deviance reduction/df) against the mean deviance explained by 
factor x random-effect... any comments on that approach?

Pascal



From jasont at indigoindustrial.co.nz  Fri Nov  7 11:40:19 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 07 Nov 2003 23:40:19 +1300
Subject: [R] precision in operations
In-Reply-To: <200311070852.hA78psR19437@natura.cebas.csic.es>
References: <200311070852.hA78psR19437@natura.cebas.csic.es>
Message-ID: <3FAB7693.7010908@indigoindustrial.co.nz>

javier garcia - CEBAS wrote:

> Hi all;
> could you remind me what is the function to change the precision of the 
> operations done in R? I can't remember nor find it.
> 

There isn't one.  R does all its calculations with system defined 
double-precision or integers (on most platforms where R is used, these 
are both 32 bits).  See help(is.single)

Are you thinking of format(...,digits=n) ?  This only affects display 
(i.e. printing).

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From stephen at inf.ed.ac.uk  Fri Nov  7 12:28:33 2003
From: stephen at inf.ed.ac.uk (Stephen Eglen)
Date: Fri, 7 Nov 2003 11:28:33 +0000
Subject: [R] Electronic copy of Ihaka and Gentleman (1996)?
Message-ID: <16299.33249.466355.177177@bushmills.inf.ed.ac.uk>

Hi,

The R FAQ suggests that we can cite Ihaka and Gentleman (1996) in
publications.  Does anyone have an electronic copy of this that could
be (legally) made publically available -- my library here doesn't take
this journal (Journal of Computational and Graphical Statistics).
Otherwise, I can order it through interlibrary loan.

Thanks, Stephen



From Simon.Bond at mrc-bsu.cam.ac.uk  Fri Nov  7 12:32:38 2003
From: Simon.Bond at mrc-bsu.cam.ac.uk (Simon.Bond)
Date: Fri, 7 Nov 2003 11:32:38 +0000 (GMT)
Subject: [R] summary.nlme
Message-ID: <Pine.GSO.4.58.0311071117180.4755@bononcini>

Hi,


I'm trying to work out how the nlme function estimates the variances of
the fixed effects parameters, so I tried to look at the code for these
functions: summary.nlme, summary.lme, MEestimate.

> MEestimate
Error: Object "MEestimate" not found
> summary.nlme
Error: Object "summary.nlme" not found
> summary.lme
Error: Object "summary.lme" not found
>


So R says they don't exist, although summary(AnNlmeObject) works fine.


What's going on?


Simon Bond.



From ripley at stats.ox.ac.uk  Fri Nov  7 12:45:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Nov 2003 11:45:49 +0000 (GMT)
Subject: [R] summary.nlme
In-Reply-To: <Pine.GSO.4.58.0311071117180.4755@bononcini>
Message-ID: <Pine.LNX.4.44.0311071142450.32014-100000@gannet.stats>

> What's going on?

Namespaces. See `Writing R Extensions'.

?getS3method
?getAnywhere

will show these to you.

It is probably easier to read the source code for the package, though.

On Fri, 7 Nov 2003, Simon.Bond wrote:

> Hi,
> 
> 
> I'm trying to work out how the nlme function estimates the variances of
> the fixed effects parameters, so I tried to look at the code for these
> functions: summary.nlme, summary.lme, MEestimate.
> 
> > MEestimate
> Error: Object "MEestimate" not found
> > summary.nlme
> Error: Object "summary.nlme" not found
> > summary.lme
> Error: Object "summary.lme" not found
> 
> So R says they don't exist, although summary(AnNlmeObject) works fine.

It does not.  It says they are not found, which is true.

> What's going on?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Fri Nov  7 12:56:29 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 07 Nov 2003 06:56:29 -0500
Subject: Summary: [R] How to represent pure linefeeds chr(10) under R for
	Windows
In-Reply-To: <16299.26300.975062.287309@gargle.gargle.HOWL>
References: <20031106203304.8BF07394F@mprdmxin.myway.com>
	<16299.26300.975062.287309@gargle.gargle.HOWL>
Message-ID: <ur1nqv870sk54inr3jcot5tngb7k8fr7ri@4ax.com>

On Fri, 7 Nov 2003 10:32:44 +0100, Martin Maechler wrote:


>1) dataload is *not* free software in the sense of the 
>   Free Software Foundation  (which has existed for a much
>   longer time than MS windows!):

Actually they're contemporaneous.  MS Windows version 1.0 came out in
1985, the same year the FSF was formed.  The initial announcement of
it was made in 1983, the same year of the initial announcement of the
GNU project.

Coincidence?  I think not.  Has anyone ever seen Bill Gates and
Richard Stallman in the same room at the same time??  :-)

Duncan Murdoch



From ggrothendieck at myway.com  Fri Nov  7 14:04:18 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri,  7 Nov 2003 08:04:18 -0500 (EST)
Subject: Summary: [R] How to represent pure linefeeds chr(10) under R for
	Windows
Message-ID: <20031107130418.DF8B23972@mprdmxin.myway.com>



While I don't disagree with what you say, the purpose of this 
is to interface to Excel which is even less free (you
have to pay for Excel but not for dataload) so 
perhaps the status of the glue used between R and Excel 
is not as important.  

>From an expediency viewpoint, I found that dataload solves
a wide variety of interfacing problems easily, typically 
in a single line of code, using a single tool and consistent 
syntax.  I can translate easily among .rda, .xls, .csv, .txt 
and numerous other formats.  

---
Date: Fri, 7 Nov 2003 10:32:44 +0100 
From: Martin Maechler <maechler at stat.math.ethz.ch>
To: <ggrothendieck at myway.com> 
Cc: <joehl at gmx.de>, <r-help at stat.math.ethz.ch> 
Subject: Re: Summary: [R] How to represent pure linefeeds chr(10) under R for Windows 

 
 
>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at myway.com>
>>>>> on Thu, 6 Nov 2003 15:33:04 -0500 (EST) writes:

Gabor> Its also possible to avoid these intricacies by not
Gabor> using an intermediate text representation, i.e. csv,
Gabor> in the first place.

Gabor> The following R code uses the free dataload utility
Gabor> (Google search for Baird dataload utility) to create
Gabor> an .xls file from data frame, x:

Gabor> save(x,file="x.rda") 
Gabor> system("dataload x.rda x.xls/u")

Gabor> At this point you can read x.xls into Excel.

Note that this has two "problems" IMO, which Jens' R-only
solution does not have:

1) dataload is *not* free software in the sense of the 
Free Software Foundation (which has existed for a much
longer time than MS windows!):
It's only "free" as in "free beer", not "free" as in "free speech" .
For more, read the "Free as in Freedom" main link on http://www.fsf.org/

2) dataload is only available as *binary* on *some* platforms,
as opposed to R which is available to everyone working with
it :-)

Martin Maechler <maechler at stat.math.ethz.ch>     http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum LEO C16     Leonhardstr. 27
ETH (Federal Inst. Technology)     8092 Zurich     SWITZERLAND
phone: x-41-1-632-3408          fax: ...-1228               <><



From laura at env.leeds.ac.uk  Fri Nov  7 14:06:46 2003
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Fri, 7 Nov 2003 13:06:46 +0000 (GMT)
Subject: [R] Non-standard axis plotting
Message-ID: <Pine.LNX.4.44.0311071301590.31007-100000@env-pc-phd13>

I am trying to plot positions on a grid where the x and y axis equate to
longitudinal and latitudinal co-prdinates respectively. As these
co-ordinates are southings and westings, i need the origin of my graph to
contain the two highest values of each co0ordinate, with the values
decreasing in both respects along both axes - I cannot seem to find any
function within r to allow me to do this.

Also, how can i avoid r automatically rescaling my data - my data points
are not evenly clustered and I want the scalings on the x and y axes to be
the same, so that they represent a true picture of the spatial scattering.
R rescales the data to fit the best "square" in each case -
misrepresenting the scaling of my data. I have looked at all the options
within par() and axis() and nothing here appears appropriate.

Thanks in advance..
Laura



From ggrothendieck at myway.com  Fri Nov  7 14:18:28 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri,  7 Nov 2003 08:18:28 -0500 (EST)
Subject: [R] R input file scanning
Message-ID: <20031107131828.9DC293978@mprdmxin.myway.com>



Assuming the start tag contains the word "start" and the end tag
contains the word "end" you could do this:

   lines <- readLines( "input.txt" )    # lines is a vector of lines
   g <- grep( "start|end", lines )   # positions of tags
   lines <- lines[ seq( g[1]+1, g[2]-1 ) ] 
   mydata <- read.table( textConnection(lines), head=TRUE )

If the scrap only appears before and not after the data then you
could shorten this to:

   lines <- readLines( "input.txt" )    # lines is a vector of lines
   g <- grep( "start", lines )   # position of tag
   mydata <- read.table( textConnection(lines), skip=g[1], head=TRUE )
   

--- 
Date: Thu, 06 Nov 2003 21:53:08 -0500 
From: Mathieu Drapeau <mathieu.drapeau at bioneq.qc.ca>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] R input file scanning 

 
 
Hi,
I would like to know how can I solve my problem...
I want to load some data (surrounded by a tag) that are stored in a file 
that contains also some scrap (header and descriptions) that I want to 
skip. How can I do that?

Thanks,
Mathieu



From bates at stat.wisc.edu  Fri Nov  7 14:39:29 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 07 Nov 2003 07:39:29 -0600
Subject: [R] precision in operations
In-Reply-To: <3FAB7693.7010908@indigoindustrial.co.nz>
References: <200311070852.hA78psR19437@natura.cebas.csic.es>
	<3FAB7693.7010908@indigoindustrial.co.nz>
Message-ID: <6rllqse1ri.fsf@bates4.stat.wisc.edu>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> javier garcia - CEBAS wrote:
> 
> > Hi all;
> > could you remind me what is the function to change the precision of
> > the operations done in R? I can't remember nor find it.
> 
> >
> 
> 
> There isn't one.  R does all its calculations with system defined
> double-precision or integers (on most platforms where R is used, these
> are both 32 bits).  See help(is.single)

Usually the double-precision representation is 64 bits in memory and,
for the IA-32 processors (Intel and AMD x86 family), 80 bits in the
floating point registers.

Javier may be looking for

options(digits = nn)

where the default value of nn is 7.
If you want more precision in printed results try setting

options(digits = 12)



From bates at stat.wisc.edu  Fri Nov  7 14:42:16 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 07 Nov 2003 07:42:16 -0600
Subject: [R] summary.nlme
In-Reply-To: <Pine.LNX.4.44.0311071142450.32014-100000@gannet.stats>
References: <Pine.LNX.4.44.0311071142450.32014-100000@gannet.stats>
Message-ID: <6rhe1ge1mv.fsf@bates4.stat.wisc.edu>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> > What's going on?
> 
> Namespaces. See `Writing R Extensions'.
> 
> ?getS3method
> ?getAnywhere
> 
> will show these to you.
> 
> It is probably easier to read the source code for the package, though.

When reading the source code for the nlme package is the "easier"
route I would hate to think of what the harder route is like.  I wrote half
of it and at times I find it hard to read :-)



From MSchwartz at medanalytics.com  Fri Nov  7 14:43:40 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 07 Nov 2003 07:43:40 -0600
Subject: [R] precision in operations
In-Reply-To: <3FAB7693.7010908@indigoindustrial.co.nz>
References: <200311070852.hA78psR19437@natura.cebas.csic.es>
	<3FAB7693.7010908@indigoindustrial.co.nz>
Message-ID: <1068212620.6055.397.camel@localhost.localdomain>

On Fri, 2003-11-07 at 04:40, Jason Turner wrote:
> javier garcia - CEBAS wrote:
> 
> > Hi all;
> > could you remind me what is the function to change the precision of the 
> > operations done in R? I can't remember nor find it.
> > 
> 
> There isn't one.  R does all its calculations with system defined 
> double-precision or integers (on most platforms where R is used, these 
> are both 32 bits).  See help(is.single)
> 
> Are you thinking of format(...,digits=n) ?  This only affects display 
> (i.e. printing).
> 
> Cheers
> 
> Jason


These are also global settings, options("digits") and options("sicpen"),
which influence the formatting of output (but not internal
representation or precision). The latter is new for R 1.8.0.

See ?options for more information.

HTH,

Marc Schwartz



From peter.schlattmann at medizin.fu-berlin.de  Fri Nov  7 14:47:14 2003
From: peter.schlattmann at medizin.fu-berlin.de (Dr. Peter Schlattmann)
Date: Fri, 7 Nov 2003 14:47:14 +0100 (CET)
Subject: [R] xyplot
Message-ID: <33006.160.45.172.237.1068212834.squirrel@www.medizin.fu-berlin.de>

Dear all,

I am trying to use xyplot inside a function


plotme<-function(dataframe)
{
xyplot(x~y|z,data=dataframe)
}

x,y,z are members of the data frame.

When calling  function

library(lattice)
plotme(dataframe)


nothing happens. (R-1.8.0, SuSe Linux 8.1)



What am I doing wrong? Many thanks in advance

Peter



From B.Rowlingson at lancaster.ac.uk  Fri Nov  7 14:54:45 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 07 Nov 2003 13:54:45 +0000
Subject: [R] R humour: Early versions
Message-ID: <3FABA425.8030603@lancaster.ac.uk>

I didn't realise version 1 of the R programming language was quite so old:

http://www.jbum.com/idt/r.html

Does anyone still have hardware that runs it?

http://www.jbum.com/idt/hyperboreans.html

Baz



From christoph.bier at web.de  Fri Nov  7 14:55:35 2003
From: christoph.bier at web.de (Christoph Bier)
Date: Fri, 07 Nov 2003 14:55:35 +0100
Subject: [R] chisq.test error: x and y must have at least 2 levels
Message-ID: <3FABA457.1060908@web.de>

Hi,

I use a little script? to make a chi-square-test on 162 
factors (it makes no difference if I take the numeric variant 
of the factors). At factor nr. 4 is stops with an error:

[1] "v1= V7.KARTM v11= V7.KAR1M"
Error in chisq.test(d1, d2) : x and y must have at least 2 levels

But x and y /have/ two levels ("nein", "ja"):

 > fbhint.spss1$V7.KARTM
  [1] nein nein nein nein nein nein nein nein nein nein nein 
nein nein nein nein
[16] nein nein nein nein nein nein nein nein nein nein nein 
nein nein nein nein
[31] nein nein nein nein nein nein nein nein nein nein nein 
nein nein nein nein
[46] nein nein nein nein
Levels: nein ja

 > fbhint.spss1$V7.KAR1M
  [1] nein nein nein nein nein nein nein nein nein nein nein 
nein nein nein nein
[16] nein <NA> nein nein nein nein nein nein nein nein nein 
nein <NA> nein <NA>
[31] nein nein nein nein nein nein nein nein nein nein nein 
nein <NA> <NA> nein
[46] <NA> nein nein <NA>
Levels: nein ja

Or is there another meaning of 'levels' that doesn't 
correspond to the one returned above?
    Any hints what's going wrong/which mistake(s) I make?

BTW to the german speaking readers: What's the R pendant to or 
translation for "Konfigurationsfrequenzanalyse (KFA)"?

TIA

Best regards,

Christoph

_____________________

? (I got help from a colleague to do this =))

v007.s <- fbhint.spss1[58:219]
v007.1.s <- fbhint.spss1[360:521]
name7.s<-names(v007.s)
name71.s<-names(v007.1.s)
bln<-length(name7.s)
for (i in 1:bln) {
v1<-name7.s[i]
   v11<-name71.s[i]
   print(paste("v1=",v1,"v11=",v11))
   d1<-fb.12.hint[[v1]]
   d2<-fb.12.hint[[v11]]
res<-chisq.test(d1,d2)
print(res)
}


-- 
Christoph Bier, Dipl.Oecotroph., Email: bier at wiz.uni-kassel.de
Universitaet Kassel, FG Oekologische Lebensmittelqualitaet und
Ernaehrungskultur \\ Postfach 12 52 \\ 37202 Witzenhausen
Tel.: +49 (0) 55 42 / 98 -17 21, Fax: -17 13



From MSchwartz at medanalytics.com  Fri Nov  7 15:05:51 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 07 Nov 2003 08:05:51 -0600
Subject: [R] R humour: Early versions
In-Reply-To: <3FABA425.8030603@lancaster.ac.uk>
References: <3FABA425.8030603@lancaster.ac.uk>
Message-ID: <1068213950.6055.419.camel@localhost.localdomain>

On Fri, 2003-11-07 at 07:54, Barry Rowlingson wrote:
> I didn't realise version 1 of the R programming language was quite so old:
> 
> http://www.jbum.com/idt/r.html
> 
> Does anyone still have hardware that runs it?
> 
> http://www.jbum.com/idt/hyperboreans.html
> 
> Baz


I think that you just answered Doug Bates' question about what would be
harder to read than the nlme source code...

Not to mention, that you have located a seminal example of "obfuscated
R".

;-)

Marc



From andy_liaw at merck.com  Fri Nov  7 15:11:17 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 07 Nov 2003 09:11:17 -0500
Subject: [R] xyplot
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDF0@usrymx25.merck.com>

Need to wrap the xyplot() in print(), as in 

print(xyplot(...))

Andy

> From: Dr. Peter Schlattmann 
> 
> Dear all,
> 
> I am trying to use xyplot inside a function
> 
> plotme<-function(dataframe)
> {
> xyplot(x~y|z,data=dataframe)
> }
> 
> x,y,z are members of the data frame.
> 
> When calling  function
> 
> library(lattice)
> plotme(dataframe)
> 
> nothing happens. (R-1.8.0, SuSe Linux 8.1)
> 
> What am I doing wrong? Many thanks in advance
> 
> Peter



From GPetris at uark.edu  Fri Nov  7 15:20:10 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 7 Nov 2003 08:20:10 -0600 (CST)
Subject: [R] Non-standard axis plotting
In-Reply-To: <Pine.LNX.4.44.0311071301590.31007-100000@env-pc-phd13> (message
	from Laura Quinn on Fri, 07 Nov 2003 13:06:46 +0000 (GMT))
References: <Pine.LNX.4.44.0311071301590.31007-100000@env-pc-phd13>
Message-ID: <200311071420.hA7EKAlU011373@definetti.uark.edu>


If you want to preserve the aspect ratio of x and y axis, use asp=1
within the plot function.

To reverse the direction of the x and y axes, if I understand
correctly what you are trying to do, I am not sure. There may be more
efficient ways. What I would do is something along the following
lines:

plot(-x,-y, xast='n', yaxt='n')

and set manually the axis labelling. 

HTH
Giovanni

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]

> Date: Fri, 07 Nov 2003 13:06:46 +0000 (GMT)
> From: Laura Quinn <laura at env.leeds.ac.uk>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> I am trying to plot positions on a grid where the x and y axis equate to
> longitudinal and latitudinal co-prdinates respectively. As these
> co-ordinates are southings and westings, i need the origin of my graph to
> contain the two highest values of each co0ordinate, with the values
> decreasing in both respects along both axes - I cannot seem to find any
> function within r to allow me to do this.
> 
> Also, how can i avoid r automatically rescaling my data - my data points
> are not evenly clustered and I want the scalings on the x and y axes to be
> the same, so that they represent a true picture of the spatial scattering.
> R rescales the data to fit the best "square" in each case -
> misrepresenting the scaling of my data. I have looked at all the options
> within par() and axis() and nothing here appears appropriate.
> 
> Thanks in advance..
> Laura
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From p.dalgaard at biostat.ku.dk  Fri Nov  7 15:26:59 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Nov 2003 15:26:59 +0100
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <3FABA457.1060908@web.de>
References: <3FABA457.1060908@web.de>
Message-ID: <x2r80k9rv0.fsf@biostat.ku.dk>

Christoph Bier <christoph.bier at web.de> writes:

> Hi,
> 
> I use a little script? to make a chi-square-test on 162 factors (it
> makes no difference if I take the numeric variant of the factors). At
> factor nr. 4 is stops with an error:
> 
> [1] "v1= V7.KARTM v11= V7.KAR1M"
> Error in chisq.test(d1, d2) : x and y must have at least 2 levels
> 
> But x and y /have/ two levels ("nein", "ja"):
> 
>  > fbhint.spss1$V7.KARTM
>   [1] nein nein nein nein nein nein nein nein nein nein nein nein nein
> nein nein
> [16] nein nein nein nein nein nein nein nein nein nein nein nein nein
> nein nein
> [31] nein nein nein nein nein nein nein nein nein nein nein nein nein
> nein nein
> [46] nein nein nein nein
> Levels: nein ja
> 
>  > fbhint.spss1$V7.KAR1M
>   [1] nein nein nein nein nein nein nein nein nein nein nein nein nein
> nein nein
> [16] nein <NA> nein nein nein nein nein nein nein nein nein nein <NA>
> nein <NA>
> [31] nein nein nein nein nein nein nein nein nein nein nein nein <NA>
> <NA> nein
> [46] <NA> nein nein <NA>
> Levels: nein ja
> 
> Or is there another meaning of 'levels' that doesn't correspond to the
> one returned above?
>     Any hints what's going wrong/which mistake(s) I make?

Well, the error message might be slightly beside the point, but the
issue would seem to be that there are no "ja"'s inside either vector.
I.e. it first reduces each factor to those levels that are actually
present, then checks whether there are at least two levels.

You can't do a chisquare test on a table that looks like this

      nein   ja
nein    42    0
  ja     0    0

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Fri Nov  7 15:37:17 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Nov 2003 15:37:17 +0100
Subject: [R] R humour: Early versions
In-Reply-To: <1068213950.6055.419.camel@localhost.localdomain>
References: <3FABA425.8030603@lancaster.ac.uk>
	<1068213950.6055.419.camel@localhost.localdomain>
Message-ID: <x2islw9rdu.fsf@biostat.ku.dk>

Marc Schwartz <MSchwartz at medanalytics.com> writes:

> On Fri, 2003-11-07 at 07:54, Barry Rowlingson wrote:
> > I didn't realise version 1 of the R programming language was quite so old:
> > 
> > http://www.jbum.com/idt/r.html
> > 
> > Does anyone still have hardware that runs it?
> > 
> > http://www.jbum.com/idt/hyperboreans.html
> > 
> > Baz
> 
> 
> I think that you just answered Doug Bates' question about what would be
> harder to read than the nlme source code...
> 
> Not to mention, that you have located a seminal example of "obfuscated
> R".

It may be of interest that the R-like rune (raido) has been given the
following semi-magical/representative interpretation:

Raido: (journey). New ventures, new beginnings, as well as the mundane
taking a trip somewhere. It may also point out the right (or best)
path among a selection of alternates. There may well be a sense of
directed change. (http://members.aol.com/JehanaS/futhark/)



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Fri Nov  7 15:32:43 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 07 Nov 2003 08:32:43 -0600
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <3FABA457.1060908@web.de>
References: <3FABA457.1060908@web.de>
Message-ID: <1068215562.6055.465.camel@localhost.localdomain>

On Fri, 2003-11-07 at 07:55, Christoph Bier wrote:
> Hi,
> 
> I use a little script? to make a chi-square-test on 162 
> factors (it makes no difference if I take the numeric variant 
> of the factors). At factor nr. 4 is stops with an error:
> 
> [1] "v1= V7.KARTM v11= V7.KAR1M"
> Error in chisq.test(d1, d2) : x and y must have at least 2 levels
> 
> But x and y /have/ two levels ("nein", "ja"):
> 
>  > fbhint.spss1$V7.KARTM
>   [1] nein nein nein nein nein nein nein nein nein nein nein 
> nein nein nein nein
> [16] nein nein nein nein nein nein nein nein nein nein nein 
> nein nein nein nein
> [31] nein nein nein nein nein nein nein nein nein nein nein 
> nein nein nein nein
> [46] nein nein nein nein
> Levels: nein ja
> 
>  > fbhint.spss1$V7.KAR1M
>   [1] nein nein nein nein nein nein nein nein nein nein nein 
> nein nein nein nein
> [16] nein <NA> nein nein nein nein nein nein nein nein nein 
> nein <NA> nein <NA>
> [31] nein nein nein nein nein nein nein nein nein nein nein 
> nein <NA> <NA> nein
> [46] <NA> nein nein <NA>
> Levels: nein ja
> 
> Or is there another meaning of 'levels' that doesn't 
> correspond to the one returned above?
>     Any hints what's going wrong/which mistake(s) I make?

'levels' indicates how many levels are defined for the factor. However,
it is possible that the actual data present may contain only a subset of
the levels.

In this case, your factors contain defined levels for both "ja" and
"nein", however in the subset of data that you are analyzing, only
"nein" appears (and of course NA in the second, though NA is not defined
as a level).

Hence that particular cross-tabulation of factors contains one level
each, yielding a table with a single cell.

Presumably, your original dataset contains both values prior to
subsetting.

See ?factor and ?levels for more information.

> BTW to the german speaking readers: What's the R pendant to or 
> translation for "Konfigurationsfrequenzanalyse (KFA)"?
> 

I am not a German speaker, however:

Analysis of Configuration Frequencies (CFA)?

There is a package 'cfa' on CRAN.

HTH,

Marc Schwartz



From steve.roberts at man.ac.uk  Fri Nov  7 15:45:08 2003
From: steve.roberts at man.ac.uk (Steve Roberts)
Date: Fri, 7 Nov 2003 14:45:08 +0000
Subject: [R] Bug in cor.test - Spearman
Message-ID: <3FABAFF5.15819.16632BB@localhost>

Greetings.

There seems to be a problem with the P-value computation in the 
cor.test with method="spearman". In R1.8.0  (MS Windows) I 
seem to be getting intermittently nonsense P-values, but the rho's 
are OK. I can get this reproducibly with the toy example attached 
where the first use is OK and subsequent calls with the same data 
give nonsense. (I have also seen the problem without the warning 
about duplicated values.) The toy example behaves correctly under 
1.7.1.

Steve.

---Script---
x<-1:100
y<-rep(c(2,3,4,5),25)
cor.test(x,y,m="p")
cor.test(x,y,m="s")
cor.test(x,y,m="s")
cor.test(x,y,m="k")

---Output--
R : Copyright 2003, The R Development Core Team
Version 1.8.0  (2003-10-08)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> x<-1:100
> y<-rep(c(2,3,4,5),25)
> cor.test(x,y,m="p")

        Pearson's product-moment correlation

data:  x and y 
t = 0.3837, df = 98, p-value = 0.702
alternative hypothesis: true correlation is not equal to 0 
95 percent confidence interval:
 -0.1588952  0.2333745 
sample estimates:
       cor 
0.03873177 

> cor.test(x,y,m="s")

        Spearman's rank correlation rho

data:  x and y 
S = 160195, p-value = 0.7015
alternative hypothesis: true rho is not equal to 0 
sample estimates:
       rho 
0.03873177 

Warning message: 
p-values may be incorrect due to ties in: cor.test.default(x, y, m = 
"s") 
> cor.test(x,y,m="s")

        Spearman's rank correlation rho

data:  x and y 
S = 160195, p-value = < 2.2e-16
alternative hypothesis: true rho is not equal to 0 
sample estimates:
       rho 
0.03873177 

Warning message: 
p-values may be incorrect due to ties in: cor.test.default(x, y, m = 
"s") 
> cor.test(x,y,m="k")

        Kendall's rank correlation tau

data:  x and y 
z = 0.5132, p-value = 0.6078
alternative hypothesis: true tau is not equal to 0 
sample estimates:
       tau 
0.03481553 

> 

  Dr Steve Roberts 
  steve.roberts at man.ac.uk

Senior Lecturer in Medical Statistics,
CMMCH NHS Trust and University of Manchester Biostatistics Group,
0161 275 5192 / 0161 276 5785



From eric.esposito at gazdefrance.com  Fri Nov  7 13:52:23 2003
From: eric.esposito at gazdefrance.com (Eric ESPOSITO)
Date: Fri, 7 Nov 2003 13:52:23 +0100
Subject: [R] SOM function with missig values
Message-ID: <OF5C85389A.A02BF4F3-ON41256DD7.0045D666@notes.edfgdf.fr>

Hi,
I found two sorts of functions to use the SOM algorithm, one in the package
"som" and the other one in the package "class", but none of them deal with
the missing values.
The som function in package "som" gives results with option init="random",
but the value of the code vector has missing values where at least one of
the training vectors has a missing value which is not acceptable to me. I
know SOM algorithm is quite good to handle missing values, does anyone know
if a som function dealing with missing values exists and where I can find
it. I heard about "GeneSOM" package but couldn't find it on the CRAN
website, is it the same as "som" package?
Thanks for any help!

Eric ESPOSITO



From GPetris at uark.edu  Fri Nov  7 16:15:35 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 7 Nov 2003 09:15:35 -0600 (CST)
Subject: [R] Bug in cor.test - Spearman
In-Reply-To: <3FABAFF5.15819.16632BB@localhost> (message from Steve Roberts on
	Fri, 07 Nov 2003 14:45:08 +0000)
References: <3FABAFF5.15819.16632BB@localhost>
Message-ID: <200311071515.hA7FFZSR011506@definetti.uark.edu>


It works fine for me, on a Sun.

> x<-1:100
> y<-rep(c(2,3,4,5),25)
> cor.test(x,y,m="p")

	Pearson's product-moment correlation

data:  x and y 
t = 0.3837, df = 98, p-value = 0.702
alternative hypothesis: true correlation is not equal to 0 
95 percent confidence interval:
 -0.1588952  0.2333745 
sample estimates:
       cor 
0.03873177 

> cor.test(x,y,m="s")

	Spearman's rank correlation rho

data:  x and y 
S = 160195, p-value = 0.7015
alternative hypothesis: true rho is not equal to 0 
sample estimates:
       rho 
0.03873177 

Warning message: 
p-values may be incorrect due to ties in: cor.test.default(x, y, m = "s") 
> cor.test(x,y,m="s")

	Spearman's rank correlation rho

data:  x and y 
S = 160195, p-value = 0.7015
alternative hypothesis: true rho is not equal to 0 
sample estimates:
       rho 
0.03873177 

Warning message: 
p-values may be incorrect due to ties in: cor.test.default(x, y, m = "s") 
> cor.test(x,y,m="k")

	Kendall's rank correlation tau

data:  x and y 
z = 0.5132, p-value = 0.6078
alternative hypothesis: true tau is not equal to 0 
sample estimates:
       tau 
0.03481553 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From MSchwartz at medanalytics.com  Fri Nov  7 16:23:53 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 07 Nov 2003 09:23:53 -0600
Subject: [R] Bug in cor.test - Spearman
In-Reply-To: <3FABAFF5.15819.16632BB@localhost>
References: <3FABAFF5.15819.16632BB@localhost>
Message-ID: <1068218632.6055.506.camel@localhost.localdomain>

On Fri, 2003-11-07 at 08:45, Steve Roberts wrote:
> Greetings.
> 
> There seems to be a problem with the P-value computation in the 
> cor.test with method="spearman". In R1.8.0  (MS Windows) I 
> seem to be getting intermittently nonsense P-values, but the rho's 
> are OK. I can get this reproducibly with the toy example attached 
> where the first use is OK and subsequent calls with the same data 
> give nonsense. (I have also seen the problem without the warning 
> about duplicated values.) The toy example behaves correctly under 
> 1.7.1.
> 

SNIP

This is PR#4718, which appears to be fixed in R 1.8.1:

http://r-bugs.biostat.ku.dk/cgi-bin/R/Analyses-fixed?user=guest;selectid=4718

I don't know that a pre-compiled version of r-patched for Windows is
available.

If not, then the 'rcorr' function in Frank Harrell's Hmisc package my be
a short term solution for you until R 1.8.1 becomes available.

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Fri Nov  7 16:29:53 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 07 Nov 2003 07:29:53 -0800
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <x2r80k9rv0.fsf@biostat.ku.dk>
References: <3FABA457.1060908@web.de> <x2r80k9rv0.fsf@biostat.ku.dk>
Message-ID: <3FABBA71.5090306@pdf.com>

As Peter said, the standard chi-square for a 2x2 table won't work for 
your data.  However, if you tabulate the numbers first and then ask for 
the chi-square, you get a warning, not an error: 

 > contable <- array(c(42, 0,0,0), dim=c(2,2))
 > chisq.test(contable)

        Pearson's Chi-squared test with Yates' continuity correction

data:  contable
X-squared = Inf, df = 1, p-value = < 2.2e-16

Warning message:
Chi-squared approximation may be incorrect in: chisq.test(contable)
 >

##### If you are willing to make stronger assumptions, then you can get 
a finite number for chi-square: 

 > chisq.test(as.vector(contable), p = rep(0.25, 4))

        Chi-squared test for given probabilities

data:  as.vector(contable)
X-squared = 126, df = 3, p-value = < 2.2e-16

##### However, you have to be careful with this, because the following 
did NOT give me what I expected: 

 > chisq.test(contable, p = rep(0.25, 4))

        Pearson's Chi-squared test with Yates' continuity correction

data:  contable
X-squared = Inf, df = 1, p-value = < 2.2e-16

Warning message:
Chi-squared approximation may be incorrect in: chisq.test(contable, p = 
rep(0.25, 4))
 >
      Hope this helps.  spencer graves

Peter Dalgaard wrote:

>Christoph Bier <christoph.bier at web.de> writes:
>
>  
>
>>Hi,
>>
>>I use a little script? to make a chi-square-test on 162 factors (it
>>makes no difference if I take the numeric variant of the factors). At
>>factor nr. 4 is stops with an error:
>>
>>[1] "v1= V7.KARTM v11= V7.KAR1M"
>>Error in chisq.test(d1, d2) : x and y must have at least 2 levels
>>
>>But x and y /have/ two levels ("nein", "ja"):
>>
>> > fbhint.spss1$V7.KARTM
>>  [1] nein nein nein nein nein nein nein nein nein nein nein nein nein
>>nein nein
>>[16] nein nein nein nein nein nein nein nein nein nein nein nein nein
>>nein nein
>>[31] nein nein nein nein nein nein nein nein nein nein nein nein nein
>>nein nein
>>[46] nein nein nein nein
>>Levels: nein ja
>>
>> > fbhint.spss1$V7.KAR1M
>>  [1] nein nein nein nein nein nein nein nein nein nein nein nein nein
>>nein nein
>>[16] nein <NA> nein nein nein nein nein nein nein nein nein nein <NA>
>>nein <NA>
>>[31] nein nein nein nein nein nein nein nein nein nein nein nein <NA>
>><NA> nein
>>[46] <NA> nein nein <NA>
>>Levels: nein ja
>>
>>Or is there another meaning of 'levels' that doesn't correspond to the
>>one returned above?
>>    Any hints what's going wrong/which mistake(s) I make?
>>    
>>
>
>Well, the error message might be slightly beside the point, but the
>issue would seem to be that there are no "ja"'s inside either vector.
>I.e. it first reduces each factor to those levels that are actually
>present, then checks whether there are at least two levels.
>
>You can't do a chisquare test on a table that looks like this
>
>      nein   ja
>nein    42    0
>  ja     0    0
>
>  
>



From christoph.bier at web.de  Fri Nov  7 16:34:28 2003
From: christoph.bier at web.de (Christoph Bier)
Date: Fri, 07 Nov 2003 16:34:28 +0100
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <1068215562.6055.465.camel@localhost.localdomain>
References: <3FABA457.1060908@web.de>
	<1068215562.6055.465.camel@localhost.localdomain>
Message-ID: <3FABBB84.1010709@web.de>

Marc Schwartz wrote:

[answer to my problem]

Thanks!

>>BTW to the german speaking readers: What's the R pendant to or 
>>translation for "Konfigurationsfrequenzanalyse (KFA)"?
>>
> 
> 
> I am not a German speaker, however:
> 
> Analysis of Configuration Frequencies (CFA)?

Sounds reasonable ;-).

> There is a package 'cfa' on CRAN.

Thanks again.

Best regards,

Christoph



From jc at or.psychology.dal.ca  Fri Nov  7 16:38:13 2003
From: jc at or.psychology.dal.ca (John J. Christie)
Date: Fri, 7 Nov 2003 11:38:13 -0400 (AST)
Subject: [R] CircStats bug? (circ.plot)
Message-ID: <Pine.SOL.3.95.1031107112455.6756A-100000@OR.Psychology.Dal.Ca>




I am trying to work through CircStats (R 1.8, CircStats just downloaded
last week).  circ.plot just does not work.  I am plotting about 800 points
and they come out very different (and apparently correct) in rose.diag,
but circ.plot does not work (high angles or low negative angles are not
plotted).


------------------------------------------------------------------

John Christie

"You aren't free because you CAN choose - only if you DO choose."

"All you are is the decisions you make.  If you let circumstances make 
them for you then what you are becomes very easy to estimate."



From SuzieBlatt at netscape.net  Fri Nov  7 16:46:27 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Fri, 07 Nov 2003 10:46:27 -0500
Subject: [R] Barplots
Message-ID: <01AEFF19.26FCF0C6.0D1322AF@netscape.net>

Hello,
Can anyone tell me how to label individual bars on a barplot?  I want to put an "*" or letter ABOVE the bar to denote statistical significance.  Is this possible and how?

Thanks,
Suzanne

__________________________________________________________________
McAfee VirusScan Online from the Netscape Network.
Comprehensive protection for your entire computer. Get your free trial today!
http://channels.netscape.com/ns/computing/mcafee/index.jsp?promo=393397

Get AOL Instant Messenger 5.1 free of charge.  Download Now!



From christoph.bier at web.de  Fri Nov  7 16:48:43 2003
From: christoph.bier at web.de (Christoph Bier)
Date: Fri, 07 Nov 2003 16:48:43 +0100
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <x2r80k9rv0.fsf@biostat.ku.dk>
References: <3FABA457.1060908@web.de> <x2r80k9rv0.fsf@biostat.ku.dk>
Message-ID: <3FABBEDB.9030308@web.de>

Peter Dalgaard wrote:

> Well, the error message might be slightly beside the point, but the
> issue would seem to be that there are no "ja"'s inside either vector.
> I.e. it first reduces each factor to those levels that are actually
> present, then checks whether there are at least two levels.

Thanks for this explanation.

> You can't do a chisquare test on a table that looks like this
> 
>       nein   ja
> nein    42    0
>   ja     0    0
> 

Hm, and now? There is data like this and I need to do a chisquare 
test. Spencer's answer seems to be the solution.
    Is my data that uncommon, that chisq.test hasn't a built-in 
function to avoid this error?

Best regards,

Christoph



From christoph.bier at web.de  Fri Nov  7 16:48:48 2003
From: christoph.bier at web.de (Christoph Bier)
Date: Fri, 07 Nov 2003 16:48:48 +0100
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <3FABBA71.5090306@pdf.com>
References: <3FABA457.1060908@web.de> <x2r80k9rv0.fsf@biostat.ku.dk>
	<3FABBA71.5090306@pdf.com>
Message-ID: <3FABBEE0.7030305@web.de>

Spencer Graves wrote:

> As Peter said, the standard chi-square for a 2x2 table won't work for 
> your data.  However, if you tabulate the numbers first and then ask for 
> the chi-square, you get a warning, not an error:

Thanks for the solution of my problem!

Best regards,

Christoph



From MSchwartz at medanalytics.com  Fri Nov  7 17:01:15 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 07 Nov 2003 10:01:15 -0600
Subject: [R] Barplots
In-Reply-To: <01AEFF19.26FCF0C6.0D1322AF@netscape.net>
References: <01AEFF19.26FCF0C6.0D1322AF@netscape.net>
Message-ID: <1068220875.6055.512.camel@localhost.localdomain>

On Fri, 2003-11-07 at 09:46, Suzanne E. Blatt wrote:
> Hello,
> Can anyone tell me how to label individual bars on a barplot?  I want
> to put an "*" or letter ABOVE the bar to denote statistical
> significance.  Is this possible and how?
> 
> Thanks,
> Suzanne


You might want to take a look at the most recent issue of R News, which
has an article on R's base graphics, that contains an example of an
annotated barplot(). There is also a graphic of the output.

http://cran.r-project.org/doc/Rnews/Rnews_2003-2.pdf

HINT:  barplot() returns the bar midpoints (ie. mp <- barplot(....))

HTH,

Marc Schwartz



From ligges at statistik.uni-dortmund.de  Fri Nov  7 17:16:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 Nov 2003 17:16:39 +0100
Subject: [R] Barplots
In-Reply-To: <01AEFF19.26FCF0C6.0D1322AF@netscape.net>
References: <01AEFF19.26FCF0C6.0D1322AF@netscape.net>
Message-ID: <3FABC567.5000801@statistik.uni-dortmund.de>

Suzanne E. Blatt wrote:

> Hello,
> Can anyone tell me how to label individual bars on a barplot?  I want to put an "*" or letter ABOVE the bar to denote statistical significance.  Is this possible and how?
> 
> Thanks,
> Suzanne

Examples on how to label bars in that way can be found on the help page 
?barplot (well, not above but within the var, which can be adapted), and 
in the R Help Desk article by Marc Schwartz in the recent issue of R 
News, available at:
http://cran.r-project.org/doc/Rnews/

Uwe Ligges



From tlumley at u.washington.edu  Fri Nov  7 17:19:52 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 7 Nov 2003 08:19:52 -0800 (PST)
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <3FABBEDB.9030308@web.de>
References: <3FABA457.1060908@web.de> <x2r80k9rv0.fsf@biostat.ku.dk>
	<3FABBEDB.9030308@web.de>
Message-ID: <Pine.A41.4.58.0311070816380.74030@homer24.u.washington.edu>

On Fri, 7 Nov 2003, Christoph Bier wrote:

> Peter Dalgaard wrote:
>
> > Well, the error message might be slightly beside the point, but the
> > issue would seem to be that there are no "ja"'s inside either vector.
> > I.e. it first reduces each factor to those levels that are actually
> > present, then checks whether there are at least two levels.
>
> Thanks for this explanation.
>
> > You can't do a chisquare test on a table that looks like this
> >
> >       nein   ja
> > nein    42    0
> >   ja     0    0
> >
>
> Hm, and now? There is data like this and I need to do a chisquare
> test. Spencer's answer seems to be the solution.
>     Is my data that uncommon, that chisq.test hasn't a built-in
> function to avoid this error?
>

It's not that your data are uncommon.  Your data contain no information
about whether `ja' answers tend to occur together for the two variables,
because there no `ja' answers.

	-thomas



From p.pagel at gsf.de  Fri Nov  7 17:24:31 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Fri, 7 Nov 2003 17:24:31 +0100
Subject: [R] Barplots
In-Reply-To: <01AEFF19.26FCF0C6.0D1322AF@netscape.net>
References: <01AEFF19.26FCF0C6.0D1322AF@netscape.net>
Message-ID: <20031107162431.GA5059@porcupine.gsf.de>

	Hi!

On Fri, Nov 07, 2003 at 10:46:27AM -0500, Suzanne E. Blatt wrote:
> Can anyone tell me how to label individual bars on a barplot?  I want
> to put an "*" or letter ABOVE the bar to denote statistical
> significance.  Is this possible and how?

You can use text() to put arbitrary strings in your plot. So you only
need to add some offset to your y-values and work out the x-positions:

y <- c(10,12,15,8)
lab <- c('*','**','***','*')
barplot(y, ylim=c(0,20), space=0.5)
x <- (0:3*0.5)+1:4 
text(x, y+1, lab, adj=0.5)

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From umeno at students.uiuc.edu  Fri Nov  7 18:08:08 2003
From: umeno at students.uiuc.edu (umeno)
Date: Fri, 7 Nov 2003 11:08:08 -0600
Subject: [R] Intervals of Tickmarks
Message-ID: <3FAD8BCE@webmail.uiuc.edu>

Hi,

Does anyone know how to control intervals of tickmarks on the plot?

Thank you
Soyoko



From umeno at students.uiuc.edu  Fri Nov  7 18:12:06 2003
From: umeno at students.uiuc.edu (umeno)
Date: Fri, 7 Nov 2003 11:12:06 -0600
Subject: [R] Two Y-axises and One X-axis
Message-ID: <3FAD97CA@webmail.uiuc.edu>

Hi,

I would like to know if anyone knows how to draw a plot with two Y-axises and 
one X-axis? When you have two sets of y values that do not have the same 
scale, but correspond to the same x value, I would like to plot them on one 
graph.

Could you please help me?

Thank you
Soyoko



From petzoldt at rcs.urz.tu-dresden.de  Fri Nov  7 18:48:07 2003
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 07 Nov 2003 18:48:07 +0100
Subject: [R] Re: using LSODA in R
In-Reply-To: <5.2.1.1.2.20031106093554.00abb468@postoffice6.mail.cornell.edu>
References: <5.2.1.1.2.20031106093554.00abb468@postoffice6.mail.cornell.edu>
Message-ID: <3FABDAD7.6070404@rcs.urz.tu-dresden.de>

Stephen Ellner schrieb:

> I think an additional problem is that the derivatives function 
> must be 'told' where to 'look' in y for the values of R, C, and P 
> that are used to compute Rprime,Cprime, Pprime - it has no way of
> 'knowing' that the model's state vector y consists of
> the variables (R,C,P). Appended below is an example of code
> that works to solve a similar system of equations. Perhaps 
> it might be useful to add something like that to the 
> ?lsoda page?  

I think the ?lsoda page is still large enough, but there are some 
preliminary examples on my homepage:

http://www.tu-dresden.de/fghhihb/petzoldt/modlim/src/

e.g. "chemostat.R" or "blasius*.R". Furthermore, I am playing around 
with a small package with a collection of ecological models and I would 
be interested if there are some other people who are interested using R 
as a simulation platform in ecological modelling.


Thomas Petzoldt


-- 
Thomas Petzoldt
Dresden University of Technology
Institute of Hydrobiology          petzoldt at rcs.urz.tu-dresden.de
01062 Dresden

http://www.tu-dresden.de/fghhihb/petzoldt/



From chzieg01 at athena.louisville.edu  Fri Nov  7 18:49:19 2003
From: chzieg01 at athena.louisville.edu (Craig H. Ziegler)
Date: Fri, 7 Nov 2003 12:49:19 -0500 (EST)
Subject: [R] Annoteting graphs using text
Message-ID: <Pine.A41.4.33.0311071222020.71168-100000@athena.louisville.edu>

Dear All,

I am new to R and am trying to learn how to create functions using R.
Below is code which calculates Lin's Concordance Coefficient.  After
I calculate the coefficient I want to create a scatter plot which
annotates the coefficient along with preceding text onto the plot.
The below code doesn't seem to work.  If I use only the object
'lincc' on the text command it works (but doesn't give me the preceding
text) or if I use only "Lin's Concordance Coefficient = " on the text
command it works (but doesn't place on the plot the value for the object
'lincc').  Similarly, I have tried using:
          linc=cat("Lin's Concordance Coefficient = ",lincc)
within the function and then specifying:
                    text(20,60,(linc)

Also, the objects I create inside a "user defined function"
are internal to the function.  Is there anyway/command that
can make them external, i.e., make them exists to perform
tasks on outside the user defined function.

Can anyone offer some advise as to what I am doing wrong?

Thanks,

Craig Ziegler
**************************************************************
# o1 is the x vector
# o2 is the y vector
# I am trying to correlate these vectors to get
# Lin's Concordance Coeffient.  These are just
# test vectors
o1=c(11,9,54,55,50,44,58,5,21,58,41,59,39,34,23)
o2=c(27,15,72,63,65,49,51,8,30,43,40,62,52,49,21)

#title is a specification for the plot title; see 'main = title' in the
#plot function
#hlab is the x axis label; see "xlab = hlab" in the plot function
#vlab is the y axis label; see "ylab = vlab" in the plot function

title="This is a test plot"
vlab="Label for verticle axis"
hlab="Label for horizontal axis"

# Start of the function I call lin

lin = function (x,y)
     {
      lincc =
              (2 * cov(x,y)) /
              (var(x) + (var(y)) +
	      ((mean(x) - mean(y))^2))
               print(lincc)

       agree =
               plot(x,y,xlim=c(0,70),ylim=c(0,70),
	       main = title, xlab = hlab, ylab = vlab )
	       abline(0,1)

               #Below is where I am having trouble as discussed above

               text(20,60,cat("Lin's Concordance Coefficient = ",lincc))
	       print(agree)
       }

#executes the function
lin(o1,o2)



From andy_liaw at merck.com  Fri Nov  7 19:08:02 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 07 Nov 2003 13:08:02 -0500
Subject: [R] Annoteting graphs using text
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDF8@usrymx25.merck.com>

You want to use paste() inside text(), not cat().

Andy

> From: Craig H. Ziegler [mailto:chzieg01 at athena.louisville.edu] 
> 
> Dear All,
> 
> I am new to R and am trying to learn how to create functions 
> using R. Below is code which calculates Lin's Concordance 
> Coefficient.  After I calculate the coefficient I want to 
> create a scatter plot which annotates the coefficient along 
> with preceding text onto the plot. The below code doesn't 
> seem to work.  If I use only the object 'lincc' on the text 
> command it works (but doesn't give me the preceding
> text) or if I use only "Lin's Concordance Coefficient = " on 
> the text command it works (but doesn't place on the plot the 
> value for the object 'lincc').  Similarly, I have tried using:
>           linc=cat("Lin's Concordance Coefficient = ",lincc) 
> within the function and then specifying:
>                     text(20,60,(linc)
> 
> Also, the objects I create inside a "user defined function"
> are internal to the function.  Is there anyway/command that
> can make them external, i.e., make them exists to perform
> tasks on outside the user defined function.
> 
> Can anyone offer some advise as to what I am doing wrong?
> 
> Thanks,
> 
> Craig Ziegler
> **************************************************************
> # o1 is the x vector
> # o2 is the y vector
> # I am trying to correlate these vectors to get
> # Lin's Concordance Coeffient.  These are just
> # test vectors
> o1=c(11,9,54,55,50,44,58,5,21,58,41,59,39,34,23)
> o2=c(27,15,72,63,65,49,51,8,30,43,40,62,52,49,21)
> 
> #title is a specification for the plot title; see 'main = 
> title' in the #plot function #hlab is the x axis label; see 
> "xlab = hlab" in the plot function #vlab is the y axis label; 
> see "ylab = vlab" in the plot function
> 
> title="This is a test plot"
> vlab="Label for verticle axis"
> hlab="Label for horizontal axis"
> 
> # Start of the function I call lin
> 
> lin = function (x,y)
>      {
>       lincc =
>               (2 * cov(x,y)) /
>               (var(x) + (var(y)) +
> 	      ((mean(x) - mean(y))^2))
>                print(lincc)
> 
>        agree =
>                plot(x,y,xlim=c(0,70),ylim=c(0,70),
> 	       main = title, xlab = hlab, ylab = vlab )
> 	       abline(0,1)
> 
>                #Below is where I am having trouble as discussed above
> 
>                text(20,60,cat("Lin's Concordance Coefficient 
> = ",lincc))
> 	       print(agree)
>        }
> 
> #executes the function
> lin(o1,o2)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From macq at llnl.gov  Fri Nov  7 19:20:41 2003
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 7 Nov 2003 10:20:41 -0800
Subject: [R] Annoteting graphs using text
In-Reply-To: <Pine.A41.4.33.0311071222020.71168-100000@athena.louisville.edu>
References: <Pine.A41.4.33.0311071222020.71168-100000@athena.louisville.edu>
Message-ID: <p06002001bbd1926cc5a1@[128.115.153.6]>

Try using paste() instead of cat() in

>                text(20,60,cat("Lin's Concordance Coefficient = ",lincc))

The last expression in your function will be returned as the value of 
the function; that is the best way to get results out of a function 
and available for use outside the function.

-Don

At 12:49 PM -0500 11/7/03, Craig H. Ziegler wrote:
>Dear All,
>
>I am new to R and am trying to learn how to create functions using R.
>Below is code which calculates Lin's Concordance Coefficient.  After
>I calculate the coefficient I want to create a scatter plot which
>annotates the coefficient along with preceding text onto the plot.
>The below code doesn't seem to work.  If I use only the object
>'lincc' on the text command it works (but doesn't give me the preceding
>text) or if I use only "Lin's Concordance Coefficient = " on the text
>command it works (but doesn't place on the plot the value for the object
>'lincc').  Similarly, I have tried using:
>           linc=cat("Lin's Concordance Coefficient = ",lincc)
>within the function and then specifying:
>                     text(20,60,(linc)
>
>Also, the objects I create inside a "user defined function"
>are internal to the function.  Is there anyway/command that
>can make them external, i.e., make them exists to perform
>tasks on outside the user defined function.
>
>Can anyone offer some advise as to what I am doing wrong?
>
>Thanks,
>
>Craig Ziegler
>**************************************************************
># o1 is the x vector
># o2 is the y vector
># I am trying to correlate these vectors to get
># Lin's Concordance Coeffient.  These are just
># test vectors
>o1=c(11,9,54,55,50,44,58,5,21,58,41,59,39,34,23)
>o2=c(27,15,72,63,65,49,51,8,30,43,40,62,52,49,21)
>
>#title is a specification for the plot title; see 'main = title' in the
>#plot function
>#hlab is the x axis label; see "xlab = hlab" in the plot function
>#vlab is the y axis label; see "ylab = vlab" in the plot function
>
>title="This is a test plot"
>vlab="Label for verticle axis"
>hlab="Label for horizontal axis"
>
># Start of the function I call lin
>
>lin = function (x,y)
>      {
>       lincc =
>               (2 * cov(x,y)) /
>               (var(x) + (var(y)) +
>	      ((mean(x) - mean(y))^2))
>                print(lincc)
>
>        agree =
>                plot(x,y,xlim=c(0,70),ylim=c(0,70),
>	       main = title, xlab = hlab, ylab = vlab )
>	       abline(0,1)
>
>                #Below is where I am having trouble as discussed above
>
>                text(20,60,cat("Lin's Concordance Coefficient = ",lincc))
>	       print(agree)
>        }
>
>#executes the function
>lin(o1,o2)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From kwan022 at stat.auckland.ac.nz  Fri Nov  7 19:21:04 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 8 Nov 2003 07:21:04 +1300 (NZDT)
Subject: [R] Two Y-axises and One X-axis
In-Reply-To: <3FAD97CA@webmail.uiuc.edu>
Message-ID: <Pine.LNX.4.44.0311080716480.22718-100000@stat61.stat.auckland.ac.nz>

Hi,

On Fri, 7 Nov 2003, umeno wrote:

> I would like to know if anyone knows how to draw a plot with two Y-axises and 
> one X-axis? When you have two sets of y values that do not have the same 
> scale, but correspond to the same x value, I would like to plot them on one 
> graph.

I think both "Modern Applied Statistics with S" (Venables and Ripley 2002) 
and "Introductory Statistics with R" (Dalgaard 2002) have some example.

Basically one way to do this is to build the plot "piece by piece" (aka by 
first principle, or low-level plotting).  For example, the axis() command 
can be useful:
  axis(1) # x-axis at the bottom
  axis(2) # y-axis on the left
  axis(4) # y-axis on the right


-- 
Cheers,

Kevin

---------------------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From ligges at statistik.uni-dortmund.de  Fri Nov  7 19:22:25 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 Nov 2003 19:22:25 +0100
Subject: [R] Two Y-axises and One X-axis
In-Reply-To: <3FAD97CA@webmail.uiuc.edu>
References: <3FAD97CA@webmail.uiuc.edu>
Message-ID: <3FABE2E1.7010901@statistik.uni-dortmund.de>

umeno wrote:

> Hi,
> 
> I would like to know if anyone knows how to draw a plot with two Y-axises and 
> one X-axis? When you have two sets of y values that do not have the same 
> scale, but correspond to the same x value, I would like to plot them on one 
> graph.
> 
> Could you please help me?

Please look into the help archives before asking! This question has been 
answered several times during the last years.

Example for a short solution:

   plot(1:10)
   par("usr")
# [1]  0.64 10.36  0.64 10.36
# Now resetting y-axis' usr coordinates:
   par(usr=c(par("usr")[1:2], 101, 105))
   points(1:5, 105:101, col="red")
   axis(4)


Uwe Ligges



From umeno at students.uiuc.edu  Fri Nov  7 20:35:30 2003
From: umeno at students.uiuc.edu (umeno)
Date: Fri, 7 Nov 2003 13:35:30 -0600
Subject: [R] y label after axis (4)
Message-ID: <3FAF343E@webmail.uiuc.edu>

Hi,

I am trying to figure out how to lable the second y-axis after the following 
codes:

plot(x, y,
	xlab="time",
	ylab="pay1"
	)
par(new=TRUE)
plot(x,y2,
	ann=FALSE,
	xaxt="n",
	yaxt="n",
	pch=7
	)
axis(4)

Then, I want to label the second y axis "pay2".  I tried "title(ylab="pay2")", 
but it put this lable on the first y-axis.  Does anyone know how to move this 
to the second y-axis?

Thank you
Soyoko

______________________________________
Ms. Soyoko Umeno
Graduate Research Assitant for the Illinois-Missouri Biotechnology Alliance (IMBA) at http://www.imba.missouri.edu/
Ph.D. Student at the Department of Agricultural and Consumer Economics
at the University of Illinois at Urbana-Champaign
Office Phone: 217-333-3417 or 217-333-0364
Fax: 217-244-4817
Mailing Address: 1301 W. Gregory Dr. MC710, Urbana, IL 61801



From William.Simpson at drdc-rddc.gc.ca  Fri Nov  7 15:47:35 2003
From: William.Simpson at drdc-rddc.gc.ca (Bill Simpson)
Date: Fri, 7 Nov 2003 09:47:35 -0500 (EST)
Subject: [R] average of y at each level of x?
Message-ID: <Pine.LNX.4.44.0311070945400.14679-100000@localhost.localdomain>

I have x,y data and would like to compute the average of y at each level 
of x.

> x
 [1] 0.006110 0.007027 0.007027 0.007027 0.008081 0.008081 0.008081 0.008081
 [9] 0.008081 0.008081 0.008081 0.009293 0.009293 0.009293 0.009293 0.009293
[17] 0.009293 0.009293 0.009293 0.010686 0.010686 0.010686 0.010686 0.010686
[25] 0.010686 0.010686 0.010686 0.010686 0.010686 0.012289 0.012289 0.012289
[33] 0.012289 0.012289 0.012289 0.012289 0.012289 0.012289 0.012289 0.012289
[41] 0.012289 0.012289 0.014133 0.014133 0.014133 0.014133 0.016253 0.018691
[49] 0.021494 0.024718 0.028426 0.032690 0.037594 0.043233 0.049718 0.057175
[57] 0.065752 0.075614 0.086957 0.100000

> y
 [1] 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1
[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1

> table(x,y)
          y
x          0  1 
  0.00611   1  0
  0.007027  2  1
  0.008081  3  4
  0.009293  3  5
  0.010686  4  6
  0.012289  1 12
  0.014133  0  4
  0.016253  0  1
  0.018691  0  1
  0.021494  0  1
  0.024718  0  1
  0.028426  0  1
  0.03269   0  1
  0.037594  0  1
  0.043233  0  1
  0.049718  0  1
  0.057175  0  1
  0.065752  0  1
  0.075614  0  1
  0.086957  0  1
  0.1       0  1

I would like to compute p = count1/(count0 +count1). For example, for
x=0.012289, p= 12/(1+12)= 0.923077. Please tell me how to do it. Maybe 
there is a better way to do this without going through table().

Thanks very much for any help.

Bill Simpson



From kwan022 at stat.auckland.ac.nz  Fri Nov  7 20:52:33 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 8 Nov 2003 08:52:33 +1300 (NZDT)
Subject: [R] y label after axis (4)
In-Reply-To: <3FAF343E@webmail.uiuc.edu>
Message-ID: <Pine.LNX.4.44.0311080850190.4465-100000@stat55.stat.auckland.ac.nz>

Hi,

On Fri, 7 Nov 2003, umeno wrote:

> Then, I want to label the second y axis "pay2".  I tried "title(ylab="pay2")", 
> but it put this lable on the first y-axis.  Does anyone know how to move this 
> to the second y-axis?

?mtext will do what you want.

For example, here is a few codes from Venables and Ripley 2002 "Modern 
Applied Statistics with S", Chapter 8.1:
  library(MASS)
  attach(wtloss)
  # alter margin 4; others are default
  oldpar <- par(mar = c(5.1, 4.1, 4.1, 4.1))
  plot(Days, Weight, type = "p", ylab = "Weight (kg)")
  Wt.lbs <- pretty(range(Weight*2.205))
  axis(side = 4, at = Wt.lbs/2.205, lab = Wt.lbs, srt = 90)
  mtext("Weight (lb)", side = 4, line = 3)
  par(oldpar) # restore settings
  detach()

Note that you can also get the above codes from 
$R_HOME/library/MASS/scripts/ch08.R.




-- 
Cheers,

Kevin

---------------------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From andy_liaw at merck.com  Fri Nov  7 20:54:11 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 07 Nov 2003 14:54:11 -0500
Subject: [R] average of y at each level of x?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDF9@usrymx25.merck.com>

Try (untested):

p1 <- tapply(y, x, function(z) mean(z == 0))

HTH,
Andy

> From: Bill Simpson [mailto:William.Simpson at drdc-rddc.gc.ca] 
> 
> I have x,y data and would like to compute the average of y at 
> each level 
> of x.
> 
> > x
>  [1] 0.006110 0.007027 0.007027 0.007027 0.008081 0.008081 
> 0.008081 0.008081  [9] 0.008081 0.008081 0.008081 0.009293 
> 0.009293 0.009293 0.009293 0.009293 [17] 0.009293 0.009293 
> 0.009293 0.010686 0.010686 0.010686 0.010686 0.010686 [25] 
> 0.010686 0.010686 0.010686 0.010686 0.010686 0.012289 
> 0.012289 0.012289 [33] 0.012289 0.012289 0.012289 0.012289 
> 0.012289 0.012289 0.012289 0.012289 [41] 0.012289 0.012289 
> 0.014133 0.014133 0.014133 0.014133 0.016253 0.018691 [49] 
> 0.021494 0.024718 0.028426 0.032690 0.037594 0.043233 
> 0.049718 0.057175 [57] 0.065752 0.075614 0.086957 0.100000
> 
> > y
>  [1] 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 
> 1 1 1 0 1 1 1 1 1 1 [39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> 
> > table(x,y)
>           y
> x          0  1 
>   0.00611   1  0
>   0.007027  2  1
>   0.008081  3  4
>   0.009293  3  5
>   0.010686  4  6
>   0.012289  1 12
>   0.014133  0  4
>   0.016253  0  1
>   0.018691  0  1
>   0.021494  0  1
>   0.024718  0  1
>   0.028426  0  1
>   0.03269   0  1
>   0.037594  0  1
>   0.043233  0  1
>   0.049718  0  1
>   0.057175  0  1
>   0.065752  0  1
>   0.075614  0  1
>   0.086957  0  1
>   0.1       0  1
> 
> I would like to compute p = count1/(count0 +count1). For 
> example, for x=0.012289, p= 12/(1+12)= 0.923077. Please tell 
> me how to do it. Maybe 
> there is a better way to do this without going through table().
> 
> Thanks very much for any help.
> 
> Bill Simpson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From jasont at indigoindustrial.co.nz  Fri Nov  7 20:54:47 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 08 Nov 2003 08:54:47 +1300
Subject: [R] precision in operations
In-Reply-To: <6rllqse1ri.fsf@bates4.stat.wisc.edu>
References: <200311070852.hA78psR19437@natura.cebas.csic.es>	<3FAB7693.7010908@indigoindustrial.co.nz>
	<6rllqse1ri.fsf@bates4.stat.wisc.edu>
Message-ID: <3FABF887.1050802@indigoindustrial.co.nz>

Douglas Bates wrote:

> Jason Turner <jasont at indigoindustrial.co.nz> writes:
...
>>There isn't one.  R does all its calculations with system defined
>>double-precision or integers (on most platforms where R is used, these
>>are both 32 bits).  See help(is.single)
> 
> 
> Usually the double-precision representation is 64 bits in memory and,
> for the IA-32 processors (Intel and AMD x86 family), 80 bits in the
> floating point registers.

Blush.  Of course.

I hate it when I hit "send" without checking if I was thinking when I wrote.

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From SuzieBlatt at netscape.net  Fri Nov  7 21:16:13 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Fri, 07 Nov 2003 15:16:13 -0500
Subject: [R] Barplots
Message-ID: <68DF82F2.67260A2B.0D1322AF@netscape.net>


Hello,

Thanks for the suggestion below.  I did one of my figures and it worked perfectly.  I tried it on my second figure and got double-labelling on the first bar.  I used the same code to create both figures, and the same code to label.  I've attached the code for one of the plots (there were 3/figure) if anyone has a chance to figure out why.

Thanks,
Suzanne


Philipp Pagel <p.pagel at gsf.de> wrote:

>    Hi!
>
>On Fri, Nov 07, 2003 at 10:46:27AM -0500, Suzanne E. Blatt wrote:
>> Can anyone tell me how to label individual bars on a barplot?  I want
>> to put an "*" or letter ABOVE the bar to denote statistical
>> significance.  Is this possible and how?
>
>You can use text() to put arbitrary strings in your plot. So you only
>need to add some offset to your y-values and work out the x-positions:
>
>y <- c(10,12,15,8)
>lab <- c('*','**','***','*')
>barplot(y, ylim=c(0,20), space=0.5)
>x <- (0:3*0.5)+1:4 
>text(x, y+1, lab, adj=0.5)
>
>cu
>    Philipp
>
>-- 
>Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
>Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
>GSF - National Research Center for Environment and Health
>Ingolstaedter Landstrasse 1
>85764 Neuherberg, Germany
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

__________________________________________________________________
McAfee VirusScan Online from the Netscape Network.
Comprehensive protection for your entire computer. Get your free trial today!
http://channels.netscape.com/ns/computing/mcafee/index.jsp?promo=393397

Get AOL Instant Messenger 5.1 free of charge.  Download Now!


From William.Simpson at drdc-rddc.gc.ca  Fri Nov  7 16:25:23 2003
From: William.Simpson at drdc-rddc.gc.ca (Bill Simpson)
Date: Fri, 7 Nov 2003 10:25:23 -0500 (EST)
Subject: [R] average of y at each level of x?
In-Reply-To: <Pine.LNX.4.44.0311070945400.14679-100000@localhost.localdomain>
Message-ID: <Pine.LNX.4.44.0311071024330.14748-100000@localhost.localdomain>

one way that works is:

 sapply(split(y,x), mean)



Bill



From Amer.Siddique at ssa.gov  Fri Nov  7 21:29:46 2003
From: Amer.Siddique at ssa.gov (Siddique, Amer)
Date: Fri, 7 Nov 2003 14:29:46 -0600 
Subject: [R] barplot(names.arg) versus axis(labels)
Message-ID: <F151C5EFCA66314D9FE66CB7199F4AAD5A36A3@sad6cd1.ch.ssa.gov>

Should I be able to use axis() on a barplot?  i have a data.frame, the first
3 values of which are:

> c[1:3,]
    median      mean
A1    56.5  58.50000
A61   73.0  73.00000
A62   63.0  63.00000

> str(c)
`data.frame':   19 obs. of  2 variables:
 $ median: num  56.5 73 63 161 51 55 44.5 22 54 49 ...
 $ mean  : num   58.5  73.0  63.0 161.0  47.5 ...

if I do barplot(median) and then try to label the bars with axis(), I get;

> axis(1,,labels=rownames(c),font=4,cex=1)
Error in axis(side, at, labels, tick, line, pos, outer, font, vfont, lty,  :

        location and label lengths differ, 5 != 19

even though 

barplot(median, names.arg=rownames(c)) works and

> length(rownames(c))
[1] 19

also when I attempt to place the value of the observation
 above the bar it does not space properly across all bars:

text(median,labels=median,pos=3,cex=0.6)

do i need to explicitly state an x-pos for the co-ord argument here?

Thanks,
Amer



From p.pagel at gsf.de  Fri Nov  7 21:57:32 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Fri, 7 Nov 2003 21:57:32 +0100
Subject: [R] Barplots
In-Reply-To: <68DF82F2.67260A2B.0D1322AF@netscape.net>
References: <68DF82F2.67260A2B.0D1322AF@netscape.net>
Message-ID: <20031107205732.GA2498@porcupine.gsf.de>

On Fri, Nov 07, 2003 at 03:16:13PM -0500, Suzanne E. Blatt wrote:
> Thanks for the suggestion below.  I did one of my figures and it
> worked perfectly.  I tried it on my second figure and got
> double-labelling on the first bar.  I used the same code to create
> both figures, and the same code to label.

Well, maybe you should use the x values returned by barplot (your
variable blocks) instead of computing x-positions yourself as I
originally suggested.

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From MSchwartz at medanalytics.com  Fri Nov  7 22:04:38 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 07 Nov 2003 15:04:38 -0600
Subject: [R] barplot(names.arg) versus axis(labels)
In-Reply-To: <F151C5EFCA66314D9FE66CB7199F4AAD5A36A3@sad6cd1.ch.ssa.gov>
References: <F151C5EFCA66314D9FE66CB7199F4AAD5A36A3@sad6cd1.ch.ssa.gov>
Message-ID: <1068239077.6055.576.camel@localhost.localdomain>

On Fri, 2003-11-07 at 14:29, Siddique, Amer wrote:
> Should I be able to use axis() on a barplot?  i have a data.frame, the first
> 3 values of which are:
> 
> > c[1:3,]
>     median      mean
> A1    56.5  58.50000
> A61   73.0  73.00000
> A62   63.0  63.00000
> 
> > str(c)
> `data.frame':   19 obs. of  2 variables:
>  $ median: num  56.5 73 63 161 51 55 44.5 22 54 49 ...
>  $ mean  : num   58.5  73.0  63.0 161.0  47.5 ...
> 
> if I do barplot(median) and then try to label the bars with axis(), I get;
> 
> > axis(1,,labels=rownames(c),font=4,cex=1)
          ^^
You have an error in your call to axis().

You are missing the 'at' argument. As a result, the default values of
'at' are set to axTicks(1), which in this case is returning 5 values.
You have passed 19 values to the 'labels' argument in axis(). Hence the
error message below.

> Error in axis(side, at, labels, tick, line, pos, outer, font, vfont, lty,  :
> 
>         location and label lengths differ, 5 != 19
> 
> even though 
> 
> barplot(median, names.arg=rownames(c)) works and
> 
> > length(rownames(c))
> [1] 19


In the above call to barplot(), you have specified the bar names, which
will be matched within the function to the number of bars, thus it
works.

> also when I attempt to place the value of the observation
>  above the bar it does not space properly across all bars:
> 
> text(median,labels=median,pos=3,cex=0.6)
> 
> do i need to explicitly state an x-pos for the co-ord argument here?

Yes. You get the proper x axis values by calling barplot() in the
following fashion:

mp <- barplot(....)

In this case, barplot() returns the bar midpoints and assigns them to
'mp'.

Once you have that information, you can call text() with the x values
set to 'mp'.

See ?barplot for examples and you may wish to review the most recent R
News, where there is an article on R's base graphics in R Help Desk.

http://cran.r-project.org/doc/Rnews/Rnews_2003-2.pdf

Just beware though....the author of that article has been known indulge
in single malt scotches on Friday afternoons...  ;-)

HTH,

Marc Schwartz



From SuzieBlatt at netscape.net  Fri Nov  7 22:14:11 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Fri, 07 Nov 2003 16:14:11 -0500
Subject: [R] Barplots (THANK YOU!!)
Message-ID: <3C20C961.2F8CC16E.0D1322AF@netscape.net>



Thanks!

That did it!!

Suzanne


Philipp Pagel <p.pagel at gsf.de> wrote:

>On Fri, Nov 07, 2003 at 03:16:13PM -0500, Suzanne E. Blatt wrote:
>> Thanks for the suggestion below.  I did one of my figures and it
>> worked perfectly.  I tried it on my second figure and got
>> double-labelling on the first bar.  I used the same code to create
>> both figures, and the same code to label.
>
>Well, maybe you should use the x values returned by barplot (your
>variable blocks) instead of computing x-positions yourself as I
>originally suggested.
>
>cu
>    Philipp
>
>-- 
>Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
>Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
>GSF - National Research Center for Environment and Health
>Ingolstaedter Landstrasse 1
>85764 Neuherberg, Germany
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

__________________________________________________________________
McAfee VirusScan Online from the Netscape Network.
Comprehensive protection for your entire computer. Get your free trial today!
http://channels.netscape.com/ns/computing/mcafee/index.jsp?promo=393397

Get AOL Instant Messenger 5.1 free of charge.  Download Now!



From thomas at holm.cn  Fri Nov  7 23:48:01 2003
From: thomas at holm.cn (Thomas Holm)
Date: Sat, 8 Nov 2003 00:48:01 +0200
Subject: [R] Copula functions in R? 
Message-ID: <001201c3a581$389292c0$6600a8c0@acernomdu1aktf>

Hello


I am writing to you regarding your interest in Copula/copulae and it?s
usage. I am currently studying Copula for my Master thesis and also
therefore  have a large interest in it. Now I am looking for information
regarding copula as well as Copula and "R". 
Code, information how to calculate or anything would be appreciated!


Since there seem to be little information regarding this matter I would
appreciate if you could inform me where to find or attach any code
available.

Thank you in advance


Thomas Holm
 

thomas at holm.cn



From jizhu at umich.edu  Fri Nov  7 23:50:32 2003
From: jizhu at umich.edu (Ji Zhu)
Date: Fri, 7 Nov 2003 17:50:32 -0500 (EST)
Subject: [R] stack overflow and predict()
Message-ID: <Pine.GSO.4.31.0311071743530.9978-100000@fisher.stat.lsa.umich.edu>


Dear R users,

I'm trying to use rpart() to build a classification tree on a big dataset.
The number of samples is n=100 and the number of variables is p=10000.

At first I stored all the data in a data.frame and got a "stack overflow"
error; then I changed the data into a matrix and the problem disappeared.
Now the trouble is when I try to use the predict() function, since each
newdata is a long list with p=10000 elements, the predict() function
doesn't recognize it and simply returns the fitted values at the training
data (rather than the newdata).

Could anyone give me some suggestion on how to proceed?  Thank you.

Regards,

Ji

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Ji Zhu                          439 West Hall
Assistant Professor             550 East University
Department of Statistics        Ann Arbor, MI 48109
University of Michigan          (734) 936-2577 (O)
jizhu at umich.edu                 (734) 763-4676 (F)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From andy_liaw at merck.com  Sat Nov  8 01:24:25 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 07 Nov 2003 19:24:25 -0500
Subject: [R] stack overflow and predict()
Message-ID: <3A822319EB35174CA3714066D590DCD50205CDFE@usrymx25.merck.com>

Try something like this (suppose x is the matrix of predictors in the
training set, and xtest is the same for the test set):

my.rp <- rpart(y ~ x, ...)
test.pred <- predict(my.rp, newdata=data.frame(x=I(xtest)))

Make sure the name of the variable in the data frame given to newdata
matches the name of the variable in the original formula, in this case `x',
a matrix.

HTH,
Andy


> From: Ji Zhu [mailto:jizhu at umich.edu] 
> 
> Dear R users,
> 
> I'm trying to use rpart() to build a classification tree on a 
> big dataset. The number of samples is n=100 and the number of 
> variables is p=10000.
> 
> At first I stored all the data in a data.frame and got a 
> "stack overflow" error; then I changed the data into a matrix 
> and the problem disappeared. Now the trouble is when I try to 
> use the predict() function, since each newdata is a long list 
> with p=10000 elements, the predict() function doesn't 
> recognize it and simply returns the fitted values at the 
> training data (rather than the newdata).
> 
> Could anyone give me some suggestion on how to proceed?  Thank you.
> 
> Regards,
> 
> Ji
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Ji Zhu                          439 West Hall
> Assistant Professor             550 East University
> Department of Statistics        Ann Arbor, MI 48109
> University of Michigan          (734) 936-2577 (O)
> jizhu at umich.edu                 (734) 763-4676 (F)
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From jmatthews at t-graphic.com  Sat Nov  8 02:19:26 2003
From: jmatthews at t-graphic.com (Jack Matthews)
Date: Fri, 07 Nov 2003 18:19:26 -0700
Subject: [R] [Fwd: Sun Solaris 8 compile problem.]
Message-ID: <3FAC449E.30504@t-graphic.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031107/3b60f977/attachment.pl

From edd at debian.org  Sat Nov  8 02:39:01 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 7 Nov 2003 19:39:01 -0600
Subject: [R] [Fwd: Sun Solaris 8 compile problem.]
In-Reply-To: <3FAC449E.30504@t-graphic.com>
References: <3FAC449E.30504@t-graphic.com>
Message-ID: <20031108013901.GA25244@sonny.eddelbuettel.com>

On Fri, Nov 07, 2003 at 06:19:26PM -0700, Jack Matthews wrote:
> I am new to the list was wondering if anyone can help me find the reason 
> and remedy for compiling R on an ultrasparc 60 solaris 8 with gcc 3.2.2 
> in 64 bit mode? Fails in checking for a fortran library.....

RTFM, in this case the R-admin manual, and I cite from the .texi source:

   @node Solaris, HP-UX, MacOS X, Platform notes
   @subsection Solaris on Sparc
   @cindex Solaris
   [...]
   @command{gcc} 3.2.1 and 3.2.2 generate incorrect code on 32-bit Solaris
   builds with optimization, but versions 3.1, 3.2, 3.2.3  and 3.3 work
   correctly.  At least files @file{src/main/engine.c},
   @file{src/main/graphics.c} and @file{src/modules/devX11.c} are affected.

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From kjetil at entelnet.bo  Sat Nov  8 03:37:11 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Fri, 07 Nov 2003 22:37:11 -0400
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <Pine.A41.4.58.0311070816380.74030@homer24.u.washington.edu>
References: <3FABBEDB.9030308@web.de>
Message-ID: <3FAC1E97.8701.99A30@localhost>

On 7 Nov 2003 at 8:19, Thomas Lumley wrote:

Just to make the point more clear:

> fisher.test( matrix(c(42,0,0,0),2,2))

        Fisher's Exact Test for Count Data

data:  matrix(c(42, 0, 0, 0), 2, 2) 
p-value = 1
alternative hypothesis: true odds ratio is not equal to 1 
95 percent confidence interval:
   0 Inf 
sample estimates:
odds ratio 
         0 

The confidence interval for odds ratio goes from 0 to infinity, 
a rather clear way of saying there is no information.

Kjetil Halvorsen

> On Fri, 7 Nov 2003, Christoph Bier wrote:
> 
> > Peter Dalgaard wrote:
> >
> > > Well, the error message might be slightly beside the point, but the
> > > issue would seem to be that there are no "ja"'s inside either vector.
> > > I.e. it first reduces each factor to those levels that are actually
> > > present, then checks whether there are at least two levels.
> >
> > Thanks for this explanation.
> >
> > > You can't do a chisquare test on a table that looks like this
> > >
> > >       nein   ja
> > > nein    42    0
> > >   ja     0    0
> > >
> >
> > Hm, and now? There is data like this and I need to do a chisquare
> > test. Spencer's answer seems to be the solution.
> >     Is my data that uncommon, that chisq.test hasn't a built-in
> > function to avoid this error?
> >
> 
> It's not that your data are uncommon.  Your data contain no information
> about whether `ja' answers tend to occur together for the two variables,
> because there no `ja' answers.
> 
> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sat Nov  8 04:56:35 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Fri, 07 Nov 2003 23:56:35 -0400
Subject: [R] average of y at each level of x?
In-Reply-To: <Pine.LNX.4.44.0311070945400.14679-100000@localhost.localdomain>
Message-ID: <3FAC3133.23978.524E8E@localhost>

On 7 Nov 2003 at 9:47, Bill Simpson wrote:

Since your y is 0-1 the following works:

tapply(x, y ,mean)

aggregate(x, y, mean)
gives the output in a different format.

Kjetil Halvorsen

> I have x,y data and would like to compute the average of y at each level 
> of x.
> 
> > x
>  [1] 0.006110 0.007027 0.007027 0.007027 0.008081 0.008081 0.008081 0.008081
>  [9] 0.008081 0.008081 0.008081 0.009293 0.009293 0.009293 0.009293 0.009293
> [17] 0.009293 0.009293 0.009293 0.010686 0.010686 0.010686 0.010686 0.010686
> [25] 0.010686 0.010686 0.010686 0.010686 0.010686 0.012289 0.012289 0.012289
> [33] 0.012289 0.012289 0.012289 0.012289 0.012289 0.012289 0.012289 0.012289
> [41] 0.012289 0.012289 0.014133 0.014133 0.014133 0.014133 0.016253 0.018691
> [49] 0.021494 0.024718 0.028426 0.032690 0.037594 0.043233 0.049718 0.057175
> [57] 0.065752 0.075614 0.086957 0.100000
> 
> > y
>  [1] 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1
> [39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> 
> > table(x,y)
>           y
> x          0  1 
>   0.00611   1  0
>   0.007027  2  1
>   0.008081  3  4
>   0.009293  3  5
>   0.010686  4  6
>   0.012289  1 12
>   0.014133  0  4
>   0.016253  0  1
>   0.018691  0  1
>   0.021494  0  1
>   0.024718  0  1
>   0.028426  0  1
>   0.03269   0  1
>   0.037594  0  1
>   0.043233  0  1
>   0.049718  0  1
>   0.057175  0  1
>   0.065752  0  1
>   0.075614  0  1
>   0.086957  0  1
>   0.1       0  1
> 
> I would like to compute p = count1/(count0 +count1). For example, for
> x=0.012289, p= 12/(1+12)= 0.923077. Please tell me how to do it. Maybe 
> there is a better way to do this without going through table().
> 
> Thanks very much for any help.
> 
> Bill Simpson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sat Nov  8 07:09:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Nov 2003 06:09:01 +0000 (GMT)
Subject: [R] stack overflow and predict()
In-Reply-To: <Pine.GSO.4.31.0311071743530.9978-100000@fisher.stat.lsa.umich.edu>
Message-ID: <Pine.LNX.4.44.0311080606290.2188-100000@gannet.stats>

That's not a sensible thing to do.  Supply predict.rpart with a data frame 
that contains just the variables rpart selected.

R does have limits, and attempting to use 10,000 variables is hitting 
them,  But surely any statistician is aware of the dangers of selecting 
from 10000 variables on just 100 observations?

On Fri, 7 Nov 2003, Ji Zhu wrote:

> 
> Dear R users,
> 
> I'm trying to use rpart() to build a classification tree on a big dataset.
> The number of samples is n=100 and the number of variables is p=10000.
> 
> At first I stored all the data in a data.frame and got a "stack overflow"
> error; then I changed the data into a matrix and the problem disappeared.
> Now the trouble is when I try to use the predict() function, since each
> newdata is a long list with p=10000 elements, the predict() function
> doesn't recognize it and simply returns the fitted values at the training
> data (rather than the newdata).
> 
> Could anyone give me some suggestion on how to proceed?  Thank you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Nov  8 07:15:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Nov 2003 06:15:17 +0000 (GMT)
Subject: [R] [Fwd: Sun Solaris 8 compile problem.]
In-Reply-To: <20031108013901.GA25244@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0311080609560.2188-100000@gannet.stats>

Actually not, 3.2.2 works in 64-bit mode (although I would recommend a 
later version of gcc).

The issue seems more basic: the environment does not have a working 
compiler.  A likely reason is the the 64-bit shared libraries are not in 
the LD_LIBRARY_PATH, or not high enough up it.  That Fortran has a shared 
libg2c, normally in /usr/local/lib/sparcv9.

This is not an R problem, and local Solaris expertise should be sought.

FWIW, my `I.USED' script is

markov% cat I.USED
setenv LD_LIBRARY_PATH /usr/local/lib/sparcv9/:${LD_LIBRARY_PATH}
env CONFIG_SITE=$PWD/config.site ~/R/cvs/R-devel/configure --without-tcltk -C


On Fri, 7 Nov 2003, Dirk Eddelbuettel wrote:

> On Fri, Nov 07, 2003 at 06:19:26PM -0700, Jack Matthews wrote:
> > I am new to the list was wondering if anyone can help me find the reason 
> > and remedy for compiling R on an ultrasparc 60 solaris 8 with gcc 3.2.2 
> > in 64 bit mode? Fails in checking for a fortran library.....
> 
> RTFM, in this case the R-admin manual, and I cite from the .texi source:
> 
>    @node Solaris, HP-UX, MacOS X, Platform notes
>    @subsection Solaris on Sparc
>    @cindex Solaris
>    [...]
>    @command{gcc} 3.2.1 and 3.2.2 generate incorrect code on 32-bit Solaris
>    builds with optimization, but versions 3.1, 3.2, 3.2.3  and 3.3 work
>    correctly.  At least files @file{src/main/engine.c},
>    @file{src/main/graphics.c} and @file{src/modules/devX11.c} are affected.
> 
> Hth, Dirk
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kfung95 at yahoo.com  Sat Nov  8 09:46:13 2003
From: kfung95 at yahoo.com (Kaiser Fung)
Date: Sat, 8 Nov 2003 00:46:13 -0800 (PST)
Subject: [R] rpart node size
Message-ID: <20031108084613.7548.qmail@web21101.mail.yahoo.com>


After getting an error, I figured out that there is a
minimum node size for doing classification trees with
rpart.  Surely nodes with too few observations are not
reliable.  However, I have not found any references to
how one might set the min node size.  Knowing this
number will allow me to calculate how much data I need
for the tree to get reliable results (it's expensive
to run experiments).  Any thoughts?

Kais



From christoph.bier at web.de  Sat Nov  8 11:13:27 2003
From: christoph.bier at web.de (Christoph Bier)
Date: Sat, 08 Nov 2003 11:13:27 +0100
Subject: [R] chisq.test error: x and y must have at least 2 levels
In-Reply-To: <3FAC1E97.8701.99A30@localhost>
References: <3FABBEDB.9030308@web.de> <3FAC1E97.8701.99A30@localhost>
Message-ID: <3FACC1C7.3090600@web.de>

kjetil at entelnet.bo wrote:
> On 7 Nov 2003 at 8:19, Thomas Lumley wrote:
> 
> Just to make the point more clear:

[...]

Thanks!

Regards,

Christoph



From shuangge at stat.wisc.edu  Sat Nov  8 15:20:56 2003
From: shuangge at stat.wisc.edu (Shuangge Ma)
Date: Sat, 8 Nov 2003 08:20:56 -0600 (CST)
Subject: [R] about .RData
Message-ID: <Pine.LNX.4.58.0311080818540.1827@istat04.stat.wisc.edu>

Dear Sir/Madam:
I got a question about this .RData.

I wrote a R program and run it with:
nohup R BATCH a.R &
in Unix system.

However, each time it generate a .RData file, which is huge.
I add "remove" to my code, but this .RData is still there.

My question is: how can I avoid this .RData file automatically?

Thanks a lot,

Shuangge Ma
*********************
Department of Statistics		Phone: 608-263-4782(O)
University of Wisconsin--Madison



From pavlicov at stat.ohio-state.edu  Sat Nov  8 15:31:13 2003
From: pavlicov at stat.ohio-state.edu (Martina Pavlicova)
Date: Sat, 8 Nov 2003 09:31:13 -0500 (EST)
Subject: [R] notation for skewness and kurtosis
Message-ID: <Pine.GSO.4.58.0311080929060.8784@spatial.stat.ohio-state.edu>


Hello everybody,

this is a bit off topic, so maybe you can just reply to me personally...

What is the typical notation for 'skewness', 'kurtosis' and maybe 'excess
kurtosis'?

Thank you,

Martina
--------------------------------------------------------------------------
Department of Statistics             Office Phone: (614) 292-1567
1958 Neil Avenue, 304E Cockins Hall  FAX: (614) 292-2096
The Ohio State University            E-mail: pavlicov at stat.ohio-state.edu
Columbus, OH 43210-1247              www.stat.ohio-state.edu/~pavlicov



From ligges at statistik.uni-dortmund.de  Sat Nov  8 15:37:45 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 08 Nov 2003 15:37:45 +0100
Subject: [R] about .RData
In-Reply-To: <Pine.LNX.4.58.0311080818540.1827@istat04.stat.wisc.edu>
References: <Pine.LNX.4.58.0311080818540.1827@istat04.stat.wisc.edu>
Message-ID: <3FACFFB9.7090903@statistik.uni-dortmund.de>

Shuangge Ma wrote:

> Dear Sir/Madam:
> I got a question about this .RData.
> 
> I wrote a R program and run it with:
> nohup R BATCH a.R &
> in Unix system.
> 
> However, each time it generate a .RData file, which is huge.
> I add "remove" to my code, but this .RData is still there.
> 
> My question is: how can I avoid this .RData file automatically?

R BATCH --help

tells you:

"Further arguments starting with a '-' are considered as options as long
as '--' was not encountered, and are passed on to the R process, which
by default is started with '--restore --save --no-readline'."

so what about specifying --no-save as in
nohup R BATCH --no-save a.R &
?

Uwe Ligges



From flom at ndri.org  Sat Nov  8 16:25:01 2003
From: flom at ndri.org (Peter Flom)
Date: Sat, 08 Nov 2003 10:25:01 -0500
Subject: [R] Effects of rounding on regression
Message-ID: <sfacc496.078@MAIL.NDRI.ORG>

Does anyone know of research on the effects of rounding on regression?

e.g., when you ask people "How often have you _______?" you are more
likely to get answers like 100, 200, etc. than 98, 203, etc.

I'm interested in investigating this, but don't want to reinvent the
wheel.

thanks

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From spencer.graves at pdf.com  Sat Nov  8 16:37:46 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 08 Nov 2003 07:37:46 -0800
Subject: [R] Effects of rounding on regression
In-Reply-To: <sfacc496.078@MAIL.NDRI.ORG>
References: <sfacc496.078@MAIL.NDRI.ORG>
Message-ID: <3FAD0DCA.1010705@pdf.com>

Have you considered "?qr" and the references cited therein? 

hope this helps.  spencer graves

Peter Flom wrote:

>Does anyone know of research on the effects of rounding on regression?
>
>e.g., when you ask people "How often have you _______?" you are more
>likely to get answers like 100, 200, etc. than 98, 203, etc.
>
>I'm interested in investigating this, but don't want to reinvent the
>wheel.
>
>thanks
>
>Peter
>
>Peter L. Flom, PhD
>Assistant Director, Statistics and Data Analysis Core
>Center for Drug Use and HIV Research
>National Development and Research Institutes
>71 W. 23rd St
>www.peterflom.com
>New York, NY 10010
>(212) 845-4485 (voice)
>(917) 438-0894 (fax)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From edd at debian.org  Sat Nov  8 16:40:41 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 8 Nov 2003 09:40:41 -0600
Subject: [R] notation for skewness and kurtosis
In-Reply-To: <Pine.GSO.4.58.0311080929060.8784@spatial.stat.ohio-state.edu>
References: <Pine.GSO.4.58.0311080929060.8784@spatial.stat.ohio-state.edu>
Message-ID: <20031108154041.GA32500@sonny.eddelbuettel.com>

On Sat, Nov 08, 2003 at 09:31:13AM -0500, Martina Pavlicova wrote:
> What is the typical notation for 'skewness', 'kurtosis' and maybe 'excess
> kurtosis'?

I don't think there is a standard. One decent book I have handy -- Capmbell,
Lo and MacKinlay, "Econometrics of Financial Markets", Princeton UP, 1997 --
defines them as \hat{S} and \hat{K} on page 17. No symbol for excess
kurtosis, but the usual definition of \hat{K} - 3.

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From shuangge at stat.wisc.edu  Sat Nov  8 16:53:31 2003
From: shuangge at stat.wisc.edu (Shuangge Ma)
Date: Sat, 8 Nov 2003 09:53:31 -0600 (CST)
Subject: [R] about .RData
In-Reply-To: <3FACFFB9.7090903@statistik.uni-dortmund.de>
References: <Pine.LNX.4.58.0311080818540.1827@istat04.stat.wisc.edu>
	<3FACFFB9.7090903@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.58.0311080953140.2101@istat04.stat.wisc.edu>

Thanks.
It seems working.

>
> R BATCH --help
>
> tells you:
>
> "Further arguments starting with a '-' are considered as options as long
> as '--' was not encountered, and are passed on to the R process, which
> by default is started with '--restore --save --no-readline'."
>
> so what about specifying --no-save as in
> nohup R BATCH --no-save a.R &
> ?
>
> Uwe Ligges
>
>
>

Shuangge Ma
*********************
Department of Statistics		Phone: 608-263-4782(O)
University of Wisconsin--Madison



From Timur.Elzhov at jinr.ru  Sat Nov  8 17:32:23 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Sat, 8 Nov 2003 19:32:23 +0300
Subject: [R] Two Y-axises and One X-axis
In-Reply-To: <3FAD97CA@webmail.uiuc.edu>
References: <3FAD97CA@webmail.uiuc.edu>
Message-ID: <20031108163223.GA6733@nf034.jinr.ru>

On Fri, Nov 07, 2003 at 11:12:06AM -0600, umeno wrote:

> I would like to know if anyone knows how to draw a plot with two Y-axises and 
> one X-axis? When you have two sets of y values that do not have the same 
> scale, but correspond to the same x value, I would like to plot them on one 
> graph.
x11()
plot(1:10)
op <- par(new = TRUE)
plot(101:110, axes = FALSE, xlab = "", ylab = "", ylim = c(90, 120))
axis(4)
par(op)

--
WBR,
Timur.



From kjetil at entelnet.bo  Sat Nov  8 17:35:59 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sat, 08 Nov 2003 12:35:59 -0400
Subject: [R] Effects of rounding on regression
In-Reply-To: <sfacc496.078@MAIL.NDRI.ORG>
Message-ID: <3FACE32F.10064.52006E@localhost>

On 8 Nov 2003 at 10:25, Peter Flom wrote:

One reference for this is Seber (1977), "Linear Regression 
Analysis",. page 158, "roundoff errors", and references therein. 
(There is a new edition of this book, 02 (03?), which I haven't seen)

Synopsis: bias in \hat{\beta} does only depen on regressors which 
have roundimg errors, so rounding errors in continuous variables will 
not make bias in estimates for factors.
The usual variance estimate is biased upwards. 

This should also be easy to investigate with simulation.

Kjetil Halvorsen


> Does anyone know of research on the effects of rounding on regression?
> 
> e.g., when you ask people "How often have you _______?" you are more
> likely to get answers like 100, 200, etc. than 98, 203, etc.
> 
> I'm interested in investigating this, but don't want to reinvent the
> wheel.
> 
> thanks
> 
> Peter
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jones at reed.edu  Sat Nov  8 19:05:23 2003
From: jones at reed.edu (Albyn Jones)
Date: Sat, 8 Nov 2003 10:05:23 -0800
Subject: [R] Effects of rounding on regression
In-Reply-To: <3FAD0DCA.1010705@pdf.com>
References: <sfacc496.078@MAIL.NDRI.ORG> <3FAD0DCA.1010705@pdf.com>
Message-ID: <20031108180523.GX14790@sellwood.reed.edu>

On Sat, Nov 08, 2003 at 07:37:46AM -0800, Spencer Graves wrote:
> Have you considered "?qr" and the references cited therein? 
> 
> hope this helps.  spencer graves
> 
> Peter Flom wrote:
> 
> >Does anyone know of research on the effects of rounding on regression?
> >
> >e.g., when you ask people "How often have you _______?" you are more
> >likely to get answers like 100, 200, etc. than 98, 203, etc.
> >
> >I'm interested in investigating this, but don't want to reinvent the
> >wheel.
> >
> >thanks
> >
> >Peter

Are you asking about the propagation of rounding error in the 
computation, or about the statistical effects of measurement error?  

If the latter, and if the errors are in the explanatory variables, 
the keywords are "errors in variables".  One source is the text by 
Wayne Fuller "Measurement error Models" (1978, Wiley), and there is 
considerable literature more recently.

albyn
========================================================================
     "I would rather be exposed to the inconveniences attending too 
      much liberty than to those attending too small a degree of it."
      -Thomas Jefferson
================================================================
http://www.reed.edu/~jones    Albyn Jones	  jones at reed.edu
Reed College, Portland OR 97202             (503)-771-1112 x7418



From jizhu at umich.edu  Sat Nov  8 21:09:09 2003
From: jizhu at umich.edu (Ji Zhu)
Date: Sat, 8 Nov 2003 15:09:09 -0500 (EST)
Subject: [R] stack overflow and predict()
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CDFE@usrymx25.merck.com>
Message-ID: <Pine.GSO.4.31.0311081508030.13825-100000@fisher.stat.lsa.umich.edu>


Hi Andy,

It works perfectly.  Thank you so much!!

Cheers,
Ji

> Try something like this (suppose x is the matrix of predictors in the
> training set, and xtest is the same for the test set):
>
> my.rp <- rpart(y ~ x, ...)
> test.pred <- predict(my.rp, newdata=data.frame(x=I(xtest)))
>
> Make sure the name of the variable in the data frame given to newdata
> matches the name of the variable in the original formula, in this case `x',
> a matrix.
>
> HTH,
> Andy
>
>
> > From: Ji Zhu [mailto:jizhu at umich.edu]
> >
> > Dear R users,
> >
> > I'm trying to use rpart() to build a classification tree on a
> > big dataset. The number of samples is n=100 and the number of
> > variables is p=10000.
> >
> > At first I stored all the data in a data.frame and got a
> > "stack overflow" error; then I changed the data into a matrix
> > and the problem disappeared. Now the trouble is when I try to
> > use the predict() function, since each newdata is a long list
> > with p=10000 elements, the predict() function doesn't
> > recognize it and simply returns the fitted values at the
> > training data (rather than the newdata).
> >
> > Could anyone give me some suggestion on how to proceed?  Thank you.
> >
> > Regards,
> >
> > Ji
> >
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> > Ji Zhu                          439 West Hall
> > Assistant Professor             550 East University
> > Department of Statistics        Ann Arbor, MI 48109
> > University of Michigan          (734) 936-2577 (O)
> > jizhu at umich.edu                 (734) 763-4676 (F)
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
>

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Ji Zhu                          439 West Hall
Assistant Professor             550 East University
Department of Statistics        Ann Arbor, MI 48109
University of Michigan          (734) 936-2577 (O)
jizhu at umich.edu                 (734) 763-4676 (F)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From h.wickham at auckland.ac.nz  Sat Nov  8 22:18:07 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Sun, 09 Nov 2003 10:18:07 +1300
Subject: [R] signalCondition
Message-ID: <3FAD5D8F.10600@auckland.ac.nz>

Does signalCondition() only work within try-catch blocks?

I expected:

testSignal <- function() {
    error <- simpleError("An error!")
    signalCondition(error)
}

to do the same thing as

testStop <- function() {
    error <- simpleError("An error!")
    stop(error)
}

but testSignal returns NULL without throwing an error.  Have I 
misunderstood something?

Thanks,

Hadley



From ramyasundaram2002 at yahoo.com  Sat Nov  8 22:23:56 2003
From: ramyasundaram2002 at yahoo.com (ramya sundaram)
Date: Sat, 8 Nov 2003 13:23:56 -0800 (PST)
Subject: [R] help with hierarchical clustering
Message-ID: <20031108212356.41480.qmail@web13202.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031108/d0253aee/attachment.pl

From h.wickham at auckland.ac.nz  Sat Nov  8 22:29:28 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Sun, 09 Nov 2003 10:29:28 +1300
Subject: [R] Dealing with ...
Message-ID: <3FAD6038.1030902@auckland.ac.nz>

 From within a function, how can I extract the individual arguments that 
make up ...?

I'm sure this has been discussed on here before but ... does not get 
indexed.  Any suggestions as to what I should search for would be 
equally welcome.

Thanks,

Hadley



From ripley at stats.ox.ac.uk  Sat Nov  8 22:39:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Nov 2003 21:39:02 +0000 (GMT)
Subject: [R] help with hierarchical clustering
In-Reply-To: <20031108212356.41480.qmail@web13202.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311082137450.9531-100000@gannet.stats>

Try traceback().

My bet is that the error is in dist(), and you do not have space for the 
distance matrix.  If so you need to reassess what you are doing.

On Sat, 8 Nov 2003, ramya sundaram wrote:

> I have a large excel file with data in it. I converted it to a 'csv' format.
> I imported this dataset to R using the follownig command
> mldata <- read.csv("c:\\temp\\mldata.csv", header=T)
>  
> all the column names and the rows seems to be correct.
>  
> Now that I have this object, I need to perfrom hclust. I used the following 
> hc <- hclust(dist(mldata), method="single") 
>  
> I get the following error
>  
> > hc <- hclust(dist(mldata),"ave")
> Error: cannot allocate vector of size 622668 Kb
> In addition: Warning messages: 
> 1: NAs introduced by coercion 
> 2: Reached total allocation of 479Mb: see help(memory.size) 
> 
> Can anyone please point where I'm going wrong ?
>  
> Thank you,
> Ramya
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From h.wickham at auckland.ac.nz  Sat Nov  8 22:39:50 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Sun, 09 Nov 2003 10:39:50 +1300
Subject: [R] Dealing with ...
In-Reply-To: <3FAD6038.1030902@auckland.ac.nz>
References: <3FAD6038.1030902@auckland.ac.nz>
Message-ID: <3FAD62A6.7060402@auckland.ac.nz>

I found what I was looking for in R-lang:

args <- list(...)
for (a in args)


Hadley



From ripley at stats.ox.ac.uk  Sat Nov  8 22:44:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Nov 2003 21:44:45 +0000 (GMT)
Subject: [R] Dealing with ...
In-Reply-To: <3FAD6038.1030902@auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0311082139160.9531-100000@gannet.stats>

On Sun, 9 Nov 2003, Hadley Wickham wrote:

>  From within a function, how can I extract the individual arguments that 
> make up ...?

dots <- list(...)
names(dots)

is the most common paradigm.  You can also use match.call(expand=TRUE)

> I'm sure this has been discussed on here before but ... does not get 
> indexed.  Any suggestions as to what I should search for would be 
> equally welcome.

Well, that's why there are books about S Programming ... (p.46 gives a 
more sophisticated version).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kjetil at entelnet.bo  Sat Nov  8 22:54:02 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sat, 08 Nov 2003 17:54:02 -0400
Subject: [R] help with hierarchical clustering
In-Reply-To: <20031108212356.41480.qmail@web13202.mail.yahoo.com>
Message-ID: <3FAD2DBA.17739.D7ABE@localhost>

On 8 Nov 2003 at 13:23, ramya sundaram wrote:

The error message should be clear: you don't have sufficient
memory. By more RAM, or see to it that R uses virtual memory.
AFAIK, the way to do this could depend on OS, and you did'nt tell 
which. Read
?Memory

But first think about if this could possible help: in n is the number 
of observations, a dist object have length n(n-1)/2, compute this and 
see if what you try to do make sense!

If not, try
library(cluster)
and look at 
?clara
"clustering large applications"
That will not work with factors, but from your code below it seems 
you doesn't have factors.

Kjetil Halvorsen

> I have a large excel file with data in it. I converted it to a 'csv' format.
> I imported this dataset to R using the follownig command
> mldata <- read.csv("c:\\temp\\mldata.csv", header=T)
>  
> all the column names and the rows seems to be correct.
>  
> Now that I have this object, I need to perfrom hclust. I used the following 
> hc <- hclust(dist(mldata), method="single") 
>  
> I get the following error
>  
> > hc <- hclust(dist(mldata),"ave")
> Error: cannot allocate vector of size 622668 Kb
> In addition: Warning messages: 
> 1: NAs introduced by coercion 
> 2: Reached total allocation of 479Mb: see help(memory.size) 
> 
> Can anyone please point where I'm going wrong ?
>  
> Thank you,
> Ramya
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sat Nov  8 22:54:02 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sat, 08 Nov 2003 17:54:02 -0400
Subject: [R] Dealing with ...
In-Reply-To: <3FAD6038.1030902@auckland.ac.nz>
Message-ID: <3FAD2DBA.12588.D7A51@localhost>

On 9 Nov 2003 at 10:29, Hadley Wickham wrote:

Does the following help?

> test <- function(...) {
+   return( list(...) )
+ }
> test(a=4, b=7, test=17)
$a
[1] 4

$b
[1] 7

$test
[1] 17

Kjetil Halvorsen


>  From within a function, how can I extract the individual arguments that 
> make up ...?
> 
> I'm sure this has been discussed on here before but ... does not get 
> indexed.  Any suggestions as to what I should search for would be 
> equally welcome.
> 
> Thanks,
> 
> Hadley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hodgess at gator.uhd.edu  Sat Nov  8 23:46:28 2003
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Sat, 8 Nov 2003 16:46:28 -0600
Subject: [R] simple compile/Fortran question
Message-ID: <200311082246.hA8MkS210647@gator.dt.uh.edu>

Dear R People:

I was finally able to compile R ffrom source
on a Linux Red Hat 7.2

With R-1.8.0

I would like to test out a simple Fortran subroutine with R.

Here is the output:
[hodgess at gator bin]$ ./R CMD SHLIB -o test1.so test1.f                          

g77 -mieee-fp  -fPIC  -g -O2 -c test1.f -o test1.o                              

gcc -shared -L/usr/local/lib -o test1.so test1.o  -L/usr/local/lib -L/usr/lib/gc

c-lib/i386-redhat-linux/2.96 -L/usr/lib/gcc-lib/i386-redhat-linux/2.96/../../.. 

-lg2c -lm      



[Previously saved workspace restored]                                           

                                                                                

> dyn.load("test1.so")                                                          

> is.loaded(symbol.For("test1.so"))                                             

[1] FALSE                                                                       

> 

What am I doing wrong, please?

I'm sure that it's something simple.

Thanks in advance!
Erin
mailto: hodgess at gator.uhd.edu



From dmurdoch at pair.com  Sun Nov  9 00:48:09 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 08 Nov 2003 18:48:09 -0500
Subject: [R] simple compile/Fortran question
In-Reply-To: <200311082246.hA8MkS210647@gator.dt.uh.edu>
References: <200311082246.hA8MkS210647@gator.dt.uh.edu>
Message-ID: <d20rqvkih56ovo9pal4evfaqcggum029qb@4ax.com>

On Sat, 8 Nov 2003 16:46:28 -0600, you wrote:


>> dyn.load("test1.so")                                                          
>
>> is.loaded(symbol.For("test1.so"))                                             
>
>[1] FALSE                                                                       
>
>> 
>
>What am I doing wrong, please?

In symbol.For, use the name of the Fortran subroutine, not the name of
the DLL.  

Duncan Murdoch



From hodgess at gator.uhd.edu  Sun Nov  9 04:37:51 2003
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Sat, 8 Nov 2003 21:37:51 -0600
Subject: [R] simple compilation
Message-ID: <200311090337.hA93bpF29636@gator.dt.uh.edu>

Thanks to the many people who helped me!

This is what worked:

> dyn.load("test1.so")
> is.loaded(symbol.For("test1"))


Yippee!

Thanks again!

Sincerely,
Erin 
mailto: hodgess at gator.uhd.edu



From peter.malewski at gmx.de  Sun Nov  9 10:56:26 2003
From: peter.malewski at gmx.de (Peter Malewski)
Date: Sun, 9 Nov 2003 10:56:26 +0100
Subject: [R] invisible functions?
Message-ID: <20031109095626.GA7520@localhost>

Hallo,
	I've not worked with R about at least 1/2 year and I wonder
if it is now impossible to read functions like t.test.default within
R?

> methods("t.test")
[1] t.test.default* t.test.formula*

    Non-visible functions are asterisked


and in the NEWS-File I read: 

    o	methods() has a print method which asterisks functions which
	are not user-visible.  methods(class = "foo") now lists
	non-visible functions, and checks that there is a matching generic.

...but perhaps I have to read about the "new classes". Is there a way
to read the hidden functions?

P.Malewski



From nortonsm at verizon.net  Sun Nov  9 13:58:52 2003
From: nortonsm at verizon.net (Scott Norton)
Date: Sun, 9 Nov 2003 07:58:52 -0500
Subject: [R] How to create unique factor from two factors? + Boostrap Q
Message-ID: <000001c3a6c1$3a6f56a0$6501a8c0@scott>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031109/d85faa47/attachment.pl

From ripley at stats.ox.ac.uk  Sun Nov  9 14:29:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 9 Nov 2003 13:29:01 +0000 (GMT)
Subject: [R] How to create unique factor from two factors? + Boostrap Q
In-Reply-To: <000001c3a6c1$3a6f56a0$6501a8c0@scott>
Message-ID: <Pine.LNX.4.44.0311091325530.25496-100000@gannet.stats>

Factor3 <- factor(unclass(Factor1) + nlevels(Factor1)*(unclass(Factor2)-1))

will give you the unique combinations, not labelled as you do but then I 
don't think you need that.

On Sun, 9 Nov 2003, Scott Norton wrote:

> This might be easy but I'm very new to R and this question doesn't seem to
> have any nice keywords that bring up relevant search results when I search
> the CRAN search engine.  Therefore, I'll plead (as I have in the recent
> past) Newbie status.
> 
>  
> 
> I have a data frame with two factors (Factor 1 and 2) which together specify
> another unique level.  I want to create a third factor in the data frame
> that captures this uniqueness.
> 
> For example, say I had dataframe, Df, with Factors, 1 and 2.  I want to
> create Factor 3 and add it to my Df dataframe.
> 
> i.e.
> 
> Df dataframe:                          WANT TO 
> 
> Row#     Factor1          Factor2     CREATE THIS: Factor 3        Data
> 
> 1            1               1                    1                 23
> 
> 2            1               2                    2                 43
> 
> 3            1               2                    2                 19
> 
> 4            1               2                    2                 11
> 
> 5            1               4                    3                 3
> 
> 6            1               4                    3                 13
> 
> 7            3               1                    4                 52
> 
> 8            3               1                    4                 12
> 
> 9            3               1                    4                 9
> 
> 10           3               3                    5                 21
> 
> 11           3               3                    5                 43
> 
> 
> 12           4               1                    6                 32
> 
> 13           4               1                    6                 18
> 
> 14           4               2                    7                 52
> 
> 15           4               2                    7                 21
> 
> 
>  
> 
> and of course, I'm trying to create Factor 3 without loops..
> 
>  
> 
> My end goal here (which I add because maybe I don't need to create Factor 3
> (although I'm still curious)), is to bootstrap "sample" Factor 3. I want to
> repeatedly grab, say, 3 levels of Factor 3, and take the mean of those
> levels (e.g. say in my first bootstrap sample, I grab levels 2,4, and 7 from
> Factor 3, then I want to take the mean of rows, 2,3,4,7,8,9,14,15).  Of
> course, each sample from Factor 3 for my bootstrap will most likely have a
> differing number of rows since my experiment is not balanced.  I'm not sure
> if this is an issue yet when I try to implement the "boot" function in R (I
> haven't gotten to that point yet).  

The boot package will easily do this for you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From elsawy at ysbl.york.ac.uk  Sun Nov  9 15:28:17 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Sun, 09 Nov 2003 14:28:17 +0000
Subject: [R] weird behaviour of eigen()
Message-ID: <3FAE4F01.F966109E@ysbl.york.ac.uk>

I'm using R 1.7.1 under linux redhat
it seems that the eigen values produced by eigen() do not follow 
a consistant order; I mean either ascending or discending

e.g

for one system:
eigenV<-eigen(V)
>                   print(eigenV$values)
 [1] -7.706828e+13 -4.702980e+13 -3.267579e+13 -1.701297e+13
-8.041677e+12
 [6] -5.707311e+12 -5.053941e+12 -4.774652e+12 -4.280423e+12
-3.798905e+12
[11] -3.422172e+12 -3.148595e+12 -2.974540e+12 -2.881025e+12
-2.730044e+12
[16] -2.476652e+12 -2.216184e+12 -1.996965e+12 -1.852241e+12
-1.419131e+12
[21] -1.307872e+12 -1.248930e+12 -1.244060e+12 -1.092555e+12
-1.069742e+12
[26] -1.064907e+12 -1.007863e+12 -9.894342e+11 -9.459110e+11
-8.017146e+11
[31] -5.619008e+11 -5.443052e+11 -3.834215e+11 -7.530864e+10
-2.820257e+10
[36] -1.757125e+10 -5.503488e+09 -2.225226e+09 -1.106936e+09
-1.035204e-05

> -7.706828e+13 > -1.035204e-05
[1] FALSE

for anther system:
eigenV<-eigen(V)
> print(eigenV$values)
 [1] -8.564110e-03 -1.486071e+08 -8.200752e+08 -2.033989e+09
-3.166960e+09
 [6] -9.511769e+09 -1.067173e+10 -1.207226e+10 -3.779904e+10
-6.752452e+10
[11] -1.717127e+11 -1.781890e+11 -1.887900e+11 -2.566200e+11
-2.908604e+11
[16] -4.027630e+11 -4.813731e+11 -5.072795e+11 -7.635460e+11
-8.442470e+11
[21] -8.938820e+11 -9.533737e+11 -1.038059e+12 -1.155368e+12
-1.297694e+12
[26] -1.502400e+12 -1.577757e+12 -1.748035e+12 -1.948777e+12
-2.234958e+12
[31] -2.586261e+12 -2.635164e+12 -2.705431e+12 -2.714573e+12
-3.189646e+12
[36] -3.313364e+12 -3.405791e+12 -4.951881e+12 -5.396912e+12
-5.681758e+12
[41] -5.964839e+12 -6.782151e+12 -7.234084e+12 -7.328940e+12
-7.421814e+12
[46] -8.129555e+12 -8.226702e+12 -9.268597e+12 -1.003589e+13
-1.076822e+13
[51] -1.136816e+13 -1.456318e+13 -1.903689e+13 -3.804764e+13
-6.641937e+13
[56] -1.547690e+14

> -8.564110e-03 > -1.547690e+14
[1] TRUE

what worries me now is that whether the order of the eigen vectors
follow the
corresponding eigen values or not?????
THIS IS OF PRIME IMPORTANCE.

any help is very much appreciated
best regards
Karim



From mpie at yahoo.com  Sun Nov  9 15:31:15 2003
From: mpie at yahoo.com (mpie)
Date: Sun, 9 Nov 2003 06:31:15 -0800 (PST)
Subject: [R] multiple cross-correlation function
Message-ID: <20031109143115.76003.qmail@web12804.mail.yahoo.com>


Hi all,

Please forgive my ignorance, but is there such thing
as a "multiple cross-correlation function", i.e., a
cross-correlation function for more than two time
series. If there is, is it implemented in R? I
couldn't find it.

Thanks,

Mark



From kjetil at entelnet.bo  Sun Nov  9 15:51:57 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sun, 09 Nov 2003 10:51:57 -0400
Subject: [R] How to create unique factor from two factors? + Boostrap Q
In-Reply-To: <Pine.LNX.4.44.0311091325530.25496-100000@gannet.stats>
References: <000001c3a6c1$3a6f56a0$6501a8c0@scott>
Message-ID: <3FAE1C4D.16945.22A320@localhost>

On 9 Nov 2003 at 13:29, Prof Brian Ripley wrote:

> Factor3 <- factor(unclass(Factor1) + nlevels(Factor1)*(unclass(Factor2)-1))
> 

Cannot this be done even easier by calculating the interaction?

> a <- factor(rep(1:3,rep(3,3)))
> b <- factor(rep(1:3,3))
> ab <- a:b
> ab
[1] 1:1 1:2 1:3 2:1 2:2 2:3 3:1 3:2 3:3
Levels: 1:1 1:2 1:3 2:1 2:2 2:3 3:1 3:2 3:3

Kjetil Halvorsen

> will give you the unique combinations, not labelled as you do but then I 
> don't think you need that.
> 
> On Sun, 9 Nov 2003, Scott Norton wrote:
> 
> > This might be easy but I'm very new to R and this question doesn't seem to
> > have any nice keywords that bring up relevant search results when I search
> > the CRAN search engine.  Therefore, I'll plead (as I have in the recent
> > past) Newbie status.
> > 
> >  
> > 
> > I have a data frame with two factors (Factor 1 and 2) which together specify
> > another unique level.  I want to create a third factor in the data frame
> > that captures this uniqueness.
> > 
> > For example, say I had dataframe, Df, with Factors, 1 and 2.  I want to
> > create Factor 3 and add it to my Df dataframe.
> > 
> > i.e.
> > 
> > Df dataframe:                          WANT TO 
> > 
> > Row#     Factor1          Factor2     CREATE THIS: Factor 3        Data
> > 
> > 1            1               1                    1                 23
> > 
> > 2            1               2                    2                 43
> > 
> > 3            1               2                    2                 19
> > 
> > 4            1               2                    2                 11
> > 
> > 5            1               4                    3                 3
> > 
> > 6            1               4                    3                 13
> > 
> > 7            3               1                    4                 52
> > 
> > 8            3               1                    4                 12
> > 
> > 9            3               1                    4                 9
> > 
> > 10           3               3                    5                 21
> > 
> > 11           3               3                    5                 43
> > 
> > 
> > 12           4               1                    6                 32
> > 
> > 13           4               1                    6                 18
> > 
> > 14           4               2                    7                 52
> > 
> > 15           4               2                    7                 21
> > 
> > 
> >  
> > 
> > and of course, I'm trying to create Factor 3 without loops..
> > 
> >  
> > 
> > My end goal here (which I add because maybe I don't need to create Factor 3
> > (although I'm still curious)), is to bootstrap "sample" Factor 3. I want to
> > repeatedly grab, say, 3 levels of Factor 3, and take the mean of those
> > levels (e.g. say in my first bootstrap sample, I grab levels 2,4, and 7 from
> > Factor 3, then I want to take the mean of rows, 2,3,4,7,8,9,14,15).  Of
> > course, each sample from Factor 3 for my bootstrap will most likely have a
> > differing number of rows since my experiment is not balanced.  I'm not sure
> > if this is an issue yet when I try to implement the "boot" function in R (I
> > haven't gotten to that point yet).  
> 
> The boot package will easily do this for you.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun Nov  9 16:14:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 9 Nov 2003 15:14:06 +0000 (GMT)
Subject: [R] How to create unique factor from two factors? + Boostrap Q
In-Reply-To: <3FAE1C4D.16945.22A320@localhost>
Message-ID: <Pine.LNX.4.44.0311091503260.29055-100000@gannet.stats>

Well, it is one of those things

-- it works in R but not in S
-- it appears in the examples for help(":") but is not otherwise mentioned
   on the help page (why?)
-- it does not give a numerical list of combinations, as asked for
-- it does give unused levels, which in this application is disastrous.

so I at least do not find it `easier'.

> a <- factor(letters)[1:6]
> b <- factor(rep(letters[1:3], each=2))
> a:b
[1] a:a b:a c:b d:b e:c f:c
78 Levels: a:a a:b a:c b:a b:b b:c c:a c:b c:c d:a d:b d:c e:a e:b e:c ... 


On Sun, 9 Nov 2003 kjetil at entelnet.bo wrote:

> On 9 Nov 2003 at 13:29, Prof Brian Ripley wrote:
> 
> > Factor3 <- factor(unclass(Factor1) + nlevels(Factor1)*(unclass(Factor2)-1))
> > 
> 
> Cannot this be done even easier by calculating the interaction?
> 
> > a <- factor(rep(1:3,rep(3,3)))

a <- factor(rep(1:3, each=3) is definitely easier!

> > b <- factor(rep(1:3,3))
> > ab <- a:b
> > ab
> [1] 1:1 1:2 1:3 2:1 2:2 2:3 3:1 3:2 3:3
> Levels: 1:1 1:2 1:3 2:1 2:2 2:3 3:1 3:2 3:3
> 
> Kjetil Halvorsen
> 
> > will give you the unique combinations, not labelled as you do but then I 
> > don't think you need that.
> > 
> > On Sun, 9 Nov 2003, Scott Norton wrote:
> > 
> > > This might be easy but I'm very new to R and this question doesn't seem to
> > > have any nice keywords that bring up relevant search results when I search
> > > the CRAN search engine.  Therefore, I'll plead (as I have in the recent
> > > past) Newbie status.
> > > 
> > >  
> > > 
> > > I have a data frame with two factors (Factor 1 and 2) which together specify
> > > another unique level.  I want to create a third factor in the data frame
> > > that captures this uniqueness.
> > > 
> > > For example, say I had dataframe, Df, with Factors, 1 and 2.  I want to
> > > create Factor 3 and add it to my Df dataframe.
> > > 
> > > i.e.
> > > 
> > > Df dataframe:                          WANT TO 
> > > 
> > > Row#     Factor1          Factor2     CREATE THIS: Factor 3        Data
> > > 
> > > 1            1               1                    1                 23
> > > 
> > > 2            1               2                    2                 43
> > > 
> > > 3            1               2                    2                 19
> > > 
> > > 4            1               2                    2                 11
> > > 
> > > 5            1               4                    3                 3
> > > 
> > > 6            1               4                    3                 13
> > > 
> > > 7            3               1                    4                 52
> > > 
> > > 8            3               1                    4                 12
> > > 
> > > 9            3               1                    4                 9
> > > 
> > > 10           3               3                    5                 21
> > > 
> > > 11           3               3                    5                 43
> > > 
> > > 
> > > 12           4               1                    6                 32
> > > 
> > > 13           4               1                    6                 18
> > > 
> > > 14           4               2                    7                 52
> > > 
> > > 15           4               2                    7                 21
> > > 
> > > 
> > >  
> > > 
> > > and of course, I'm trying to create Factor 3 without loops..
> > > 
> > >  
> > > 
> > > My end goal here (which I add because maybe I don't need to create Factor 3
> > > (although I'm still curious)), is to bootstrap "sample" Factor 3. I want to
> > > repeatedly grab, say, 3 levels of Factor 3, and take the mean of those
> > > levels (e.g. say in my first bootstrap sample, I grab levels 2,4, and 7 from
> > > Factor 3, then I want to take the mean of rows, 2,3,4,7,8,9,14,15).  Of
> > > course, each sample from Factor 3 for my bootstrap will most likely have a
> > > differing number of rows since my experiment is not balanced.  I'm not sure
> > > if this is an issue yet when I try to implement the "boot" function in R (I
> > > haven't gotten to that point yet).  
> > 
> > The boot package will easily do this for you.
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Nov  9 16:14:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 9 Nov 2003 15:14:56 +0000 (GMT)
Subject: [R] multiple cross-correlation function
In-Reply-To: <20031109143115.76003.qmail@web12804.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311091514200.29055-100000@gannet.stats>

On Sun, 9 Nov 2003, mpie wrote:

> Please forgive my ignorance, but is there such thing
> as a "multiple cross-correlation function", i.e., a
> cross-correlation function for more than two time
> series. If there is, is it implemented in R? I
> couldn't find it.

?acf


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Sun Nov  9 17:13:37 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 9 Nov 2003 08:13:37 -0800 (PST)
Subject: [R] weird behaviour of eigen()
In-Reply-To: <3FAE4F01.F966109E@ysbl.york.ac.uk>
References: <3FAE4F01.F966109E@ysbl.york.ac.uk>
Message-ID: <Pine.A41.4.58.0311090810450.17834@homer20.u.washington.edu>

On Sun, 9 Nov 2003, Karim Elsawy wrote:

> I'm using R 1.7.1 under linux redhat
> it seems that the eigen values produced by eigen() do not follow
> a consistant order; I mean either ascending or discending

This is strange, since the source code explicitly sorts them. Can you send
an actual example?

	-thomas

> e.g
>
> for one system:
> eigenV<-eigen(V)
> >                   print(eigenV$values)
>  [1] -7.706828e+13 -4.702980e+13 -3.267579e+13 -1.701297e+13
> -8.041677e+12
>  [6] -5.707311e+12 -5.053941e+12 -4.774652e+12 -4.280423e+12
> -3.798905e+12
> [11] -3.422172e+12 -3.148595e+12 -2.974540e+12 -2.881025e+12
> -2.730044e+12
> [16] -2.476652e+12 -2.216184e+12 -1.996965e+12 -1.852241e+12
> -1.419131e+12
> [21] -1.307872e+12 -1.248930e+12 -1.244060e+12 -1.092555e+12
> -1.069742e+12
> [26] -1.064907e+12 -1.007863e+12 -9.894342e+11 -9.459110e+11
> -8.017146e+11
> [31] -5.619008e+11 -5.443052e+11 -3.834215e+11 -7.530864e+10
> -2.820257e+10
> [36] -1.757125e+10 -5.503488e+09 -2.225226e+09 -1.106936e+09
> -1.035204e-05
>
> > -7.706828e+13 > -1.035204e-05
> [1] FALSE
>
> for anther system:
> eigenV<-eigen(V)
> > print(eigenV$values)
>  [1] -8.564110e-03 -1.486071e+08 -8.200752e+08 -2.033989e+09
> -3.166960e+09
>  [6] -9.511769e+09 -1.067173e+10 -1.207226e+10 -3.779904e+10
> -6.752452e+10
> [11] -1.717127e+11 -1.781890e+11 -1.887900e+11 -2.566200e+11
> -2.908604e+11
> [16] -4.027630e+11 -4.813731e+11 -5.072795e+11 -7.635460e+11
> -8.442470e+11
> [21] -8.938820e+11 -9.533737e+11 -1.038059e+12 -1.155368e+12
> -1.297694e+12
> [26] -1.502400e+12 -1.577757e+12 -1.748035e+12 -1.948777e+12
> -2.234958e+12
> [31] -2.586261e+12 -2.635164e+12 -2.705431e+12 -2.714573e+12
> -3.189646e+12
> [36] -3.313364e+12 -3.405791e+12 -4.951881e+12 -5.396912e+12
> -5.681758e+12
> [41] -5.964839e+12 -6.782151e+12 -7.234084e+12 -7.328940e+12
> -7.421814e+12
> [46] -8.129555e+12 -8.226702e+12 -9.268597e+12 -1.003589e+13
> -1.076822e+13
> [51] -1.136816e+13 -1.456318e+13 -1.903689e+13 -3.804764e+13
> -6.641937e+13
> [56] -1.547690e+14
>
> > -8.564110e-03 > -1.547690e+14
> [1] TRUE
>
> what worries me now is that whether the order of the eigen vectors
> follow the
> corresponding eigen values or not?????
> THIS IS OF PRIME IMPORTANCE.
>
> any help is very much appreciated
> best regards
> Karim
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From rajiv.prasad at charter.net  Mon Nov 10 19:02:00 2003
From: rajiv.prasad at charter.net (Rajiv Prasad)
Date: Mon, 10 Nov 2003 10:02:00 -0800
Subject: [R] "configure" options and R CMD INSTALL
Message-ID: <200311091851.hA9Ip29w061334@mxsf08.cluster1.charter.net>

Hi folks:

I am trying to install the package "rimage" in R 1.8.0 on an Alpha Linux box. 
 "R CMD INSTALL rimage_0.5-1.tar.gz" fails with the following:

...
...
checking for stdint.h... yes
checking for unistd.h... yes
checking fftw.h usability... yes
checking fftw.h presence... yes
checking for fftw.h... yes
checking jpeglib.h usability... yes
checking jpeglib.h presence... yes
checking for jpeglib.h... yes
checking for fftwnd_one in -lfftw... no
configure: error: Sorry, can't find fftw library. Please use --with-fftw-lib.
ERROR: configuration failed for package 'rimage'
** Removing '/usr/local/R-1.8.0/lib/R/library/rimage'

I separately compiled and installed fftw-3.0.1.  The problem seems to be that 
I need to provide "--with-fftw-lib" option to the configure script.  How do I 
do this?

> version
         _
platform alphapca56-unknown-linux-gnu
arch     alphapca56
os       linux-gnu
system   alphapca56, linux-gnu
status
major    1
minor    8.0
year     2003
month    10
day      08
language R

Thanks.

Rajiv



From edd at debian.org  Sun Nov  9 20:02:20 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 9 Nov 2003 13:02:20 -0600
Subject: [R] "configure" options and R CMD INSTALL
In-Reply-To: <200311091851.hA9Ip29w061334@mxsf08.cluster1.charter.net>
References: <200311091851.hA9Ip29w061334@mxsf08.cluster1.charter.net>
Message-ID: <20031109190220.GA11886@sonny.eddelbuettel.com>

On Mon, Nov 10, 2003 at 10:02:00AM -0800, Rajiv Prasad wrote:
> I separately compiled and installed fftw-3.0.1.  The problem seems to be that 
> I need to provide "--with-fftw-lib" option to the configure script.  How do I 
> do this?

As options to R CMD INSTALL as per:

edd at homebud:~/chibud/mm/pictures/tmp> R CMD INSTALL --help
Usage: R CMD INSTALL [options] pkgs
[...]
Options:
  -h, --help            print short help message and exit
  -v, --version         print version info and exit
      --configure-args=ARGS 
                        set arguments for the package's configure script
			(if any)
      --configure-vars=VARS 
                        set variables for the configure script (if any)

You may have to use quotes as e.g.

$ R CMD INSTALL --configures-args="--with-fftw-lib=/opt/fftw3" rimage

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From p.murrell at auckland.ac.nz  Sun Nov  9 21:32:42 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 10 Nov 2003 09:32:42 +1300
Subject: [R] Non-standard axis plotting
References: <Pine.LNX.4.44.0311071301590.31007-100000@env-pc-phd13>
Message-ID: <3FAEA46A.1050702@stat.auckland.ac.nz>

Hi


Laura Quinn wrote:
> I am trying to plot positions on a grid where the x and y axis equate to
> longitudinal and latitudinal co-prdinates respectively. As these
> co-ordinates are southings and westings, i need the origin of my graph to
> contain the two highest values of each co0ordinate, with the values
> decreasing in both respects along both axes - I cannot seem to find any
> function within r to allow me to do this.


If you specify the axis limits as (highest, lowest), R should do the 
rest.  For example, ...

	x <- -10:5
	y <- exp(x)
	par(mfrow=c(1,2))
	plot(x, y, type="l")
	plot(x, y, type="l", xlim=c(5, -10), ylim=c(150, 0))

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From p.dalgaard at biostat.ku.dk  Sun Nov  9 22:55:58 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Nov 2003 22:55:58 +0100
Subject: [R] How to create unique factor from two factors? + Boostrap Q
In-Reply-To: <Pine.LNX.4.44.0311091503260.29055-100000@gannet.stats>
References: <Pine.LNX.4.44.0311091503260.29055-100000@gannet.stats>
Message-ID: <x2ptg1tde9.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Well, it is one of those things
> 
> -- it works in R but not in S
> -- it appears in the examples for help(":") but is not otherwise mentioned
>    on the help page (why?)
> -- it does not give a numerical list of combinations, as asked for
> -- it does give unused levels, which in this application is disastrous.
> 
> so I at least do not find it `easier'.
> 
> > a <- factor(letters)[1:6]
> > b <- factor(rep(letters[1:3], each=2))
> > a:b
> [1] a:a b:a c:b d:b e:c f:c
> 78 Levels: a:a a:b a:c b:a b:b b:c c:a c:b c:c d:a d:b d:c e:a e:b e:c ... 

My preference is 

> interaction(a,b,drop=TRUE)
[1] a.a b.a c.b d.b e.c f.c
Levels: a.a b.a c.b d.b e.c f.c

This is in Splus too, is documented, and has the possibility of
excluding unused levels. (I'm fairly sure, btw, that we decided to
standardize the :/. thing, but it seems to have been forgotten). It
doesn't give a numerically labeled result, but did Scott really want
that? (as.integer or levels(x) <- seq(along=levels(x)) will get you
there soon enough).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From thomas at holm.cn  Sun Nov  9 23:26:59 2003
From: thomas at holm.cn (Thomas Holm)
Date: Mon, 10 Nov 2003 00:26:59 +0200
Subject: SV: [R] How to create unique factor from two factors? + Boostrap Q
In-Reply-To: <x2ptg1tde9.fsf@biostat.ku.dk>
Message-ID: <200311092227.hA9MRRS00349@posti.pp.htv.fi>


Well! 

Isn?t that what Copulas is all about. 
Fitting multifactor models into one model
/T

Thomas Holm
S?dra Hesperiagatan 32A9 
00100 Helsingfors

thomas at holm.cn


-----Ursprungligt meddelande-----
Fr?n: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] F?r Peter Dalgaard
Skickat: den 9 november 2003 23:56
Till: Prof Brian Ripley
Kopia: r-help at stat.math.ethz.ch; Scott Norton; kjetil at entelnet.bo
?mne: Re: [R] How to create unique factor from two factors? + Boostrap Q

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Well, it is one of those things
> 
> -- it works in R but not in S
> -- it appears in the examples for help(":") but is not otherwise mentioned
>    on the help page (why?)
> -- it does not give a numerical list of combinations, as asked for
> -- it does give unused levels, which in this application is disastrous.
> 
> so I at least do not find it `easier'.
> 
> > a <- factor(letters)[1:6]
> > b <- factor(rep(letters[1:3], each=2))
> > a:b
> [1] a:a b:a c:b d:b e:c f:c
> 78 Levels: a:a a:b a:c b:a b:b b:c c:a c:b c:c d:a d:b d:c e:a e:b e:c ...


My preference is 

> interaction(a,b,drop=TRUE)
[1] a.a b.a c.b d.b e.c f.c
Levels: a.a b.a c.b d.b e.c f.c

This is in Splus too, is documented, and has the possibility of
excluding unused levels. (I'm fairly sure, btw, that we decided to
standardize the :/. thing, but it seems to have been forgotten). It
doesn't give a numerically labeled result, but did Scott really want
that? (as.integer or levels(x) <- seq(along=levels(x)) will get you
there soon enough).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
###########################################
This message has been scanned by F-Secure Anti-Virus for Internet Mail.
For more information, connect to http://www.F-Secure.com/



From rajiv.prasad at charter.net  Mon Nov 10 01:10:23 2003
From: rajiv.prasad at charter.net (Rajiv Prasad)
Date: Sun, 9 Nov 2003 16:10:23 -0800
Subject: [R] "configure" options and R CMD INSTALL
References: <200311091851.hA9Ip29w061334@mxsf08.cluster1.charter.net>
	<20031109190220.GA11886@sonny.eddelbuettel.com>
Message-ID: <000901c3a71f$0a017bc0$6501a8c0@Jeeves2>

Hi Dirk (and Tomomi):

Thanks for the quick reply.  I tried using
'--configure-args="--with-fftw-lib=/usr/local/fftw-3.0.1"', but it did not
help.  configure still fails at the same place:

...
checking for fftwnd_one in -lfftw... no
configure: error: Sorry, cant find fftw library. Please use --with-fftw-lib.
ERROR: configuration failed for package 'rimage'
** Removing '/usr/local/R-1.8.0/lib/R/library/rimage'

I tried downgrading to fftw-2.1.5, but that was no help either.  The error
message is still the same, at the same place during configuration.

It seems to me that configure is checking for the existance of a function
named "fftwnd_one" in the fftw library, and is not able to find it (2.1.5 as
well as 3.0.1).

Any more ideas?  Thanks.

Rajiv

P.S. I'm also copying this message to the rimage maintainer Tomomi
TAKASHINA.  Maybe he can help.



----- Original Message ----- 
From: "Dirk Eddelbuettel" <edd at debian.org>
To: "Rajiv Prasad" <rajiv.prasad at charter.net>
Cc: "R-Help Mailing List" <r-help at stat.math.ethz.ch>
Sent: Sunday, November 09, 2003 11:02 AM
Subject: Re: [R] "configure" options and R CMD INSTALL


> On Mon, Nov 10, 2003 at 10:02:00AM -0800, Rajiv Prasad wrote:
> > I separately compiled and installed fftw-3.0.1.  The problem seems to be
that
> > I need to provide "--with-fftw-lib" option to the configure script.  How
do I
> > do this?
>
> As options to R CMD INSTALL as per:
>
> edd at homebud:~/chibud/mm/pictures/tmp> R CMD INSTALL --help
> Usage: R CMD INSTALL [options] pkgs
> [...]
> Options:
>   -h, --help            print short help message and exit
>   -v, --version         print version info and exit
>       --configure-args=ARGS
>                         set arguments for the package's configure script
> (if any)
>       --configure-vars=VARS
>                         set variables for the configure script (if any)
>
> You may have to use quotes as e.g.
>
> $ R CMD INSTALL --configures-args="--with-fftw-lib=/opt/fftw3" rimage
>
> Hth, Dirk
>
> -- 
> Those are my principles, and if you don't like them... well, I have
others.
>                                                 -- Groucho Marx



From h.wickham at auckland.ac.nz  Mon Nov 10 01:43:07 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Mon, 10 Nov 2003 13:43:07 +1300
Subject: [R] Subsetting a list of vectors
Message-ID: <3FAEDF1B.3060600@auckland.ac.nz>

Hi,

I'm trying to subset a list which contains variable length vectors.  
What I want to do is extract (eg.) the 3rd item in each vector (with 
length >= 3).  At the moment I'm using sapply(list.of.vectors, 
function(x) {x[3]}).  The problem with this is that sapply returns a 
list of the same length of list.of.vectors so I end up with a whole lot 
of null entries from those vectors that aren't long enough.  I have a 
similar problem if I want to select all the vectors where the 3rd item 
is a specified value.

Does anyone have any better solutions?

Thanks for you help,

Hadley



From spencer.graves at pdf.com  Mon Nov 10 02:08:36 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 09 Nov 2003 17:08:36 -0800
Subject: [R] Subsetting a list of vectors
In-Reply-To: <3FAEDF1B.3060600@auckland.ac.nz>
References: <3FAEDF1B.3060600@auckland.ac.nz>
Message-ID: <3FAEE514.2070101@pdf.com>

When I did it in S-Plus 6.1 and R 1.8.0, I didn't get NULL entries:  I 
got NAs.  There is a difference between NULLs and NAs.  The NAs can be 
deleted using is.na, as follows: 

 > list.of.vectors <- list(a=1, b=1:3)
 > x3 <- sapply(list.of.vectors, function(x)x[3])
 > x3
 a  b
NA  3
 > x3
 a  b
NA  3
 > x3[!is.na(x3)]
b
3
 >
Is this acceptable? 
spencer graves

Hadley Wickham wrote:

> Hi,
>
> I'm trying to subset a list which contains variable length vectors.  
> What I want to do is extract (eg.) the 3rd item in each vector (with 
> length >= 3).  At the moment I'm using sapply(list.of.vectors, 
> function(x) {x[3]}).  The problem with this is that sapply returns a 
> list of the same length of list.of.vectors so I end up with a whole 
> lot of null entries from those vectors that aren't long enough.  I 
> have a similar problem if I want to select all the vectors where the 
> 3rd item is a specified value.
>
> Does anyone have any better solutions?
>
> Thanks for you help,
>
> Hadley
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From t.takashina at computer.org  Mon Nov 10 03:15:59 2003
From: t.takashina at computer.org (Tomomi TAKASHINA)
Date: Mon, 10 Nov 2003 11:15:59 +0900 (JST)
Subject: [R] Re: configure" options and R CMD INSTALL
In-Reply-To: <000901c3a71f$0a017bc0$6501a8c0@Jeeves2>
References: <200311091851.hA9Ip29w061334@mxsf08.cluster1.charter.net>
	<20031109190220.GA11886@sonny.eddelbuettel.com>
	<000901c3a71f$0a017bc0$6501a8c0@Jeeves2>
Message-ID: <16102609.1068430559090.JavaMail.t.takashina@computer.org>

Hi, Rajiv:

At Sun, 9 Nov 2003 16:10:23 -0800, "Rajiv Prasad" wrote:

> I tried downgrading to fftw-2.1.5, but that was no help either.  The error
> message is still the same, at the same place during configuration.
> 
> It seems to me that configure is checking for the existance of a function
> named "fftwnd_one" in the fftw library, and is not able to find it (2.1.5 as
> well as 3.0.1).

I'm sorry that the configure script of currently distributed package 
doesn't check library and header path correctly. I had submitted new 
package to cran by e-mail few weeks ago. But unforunately, the mail 
had returned by some reason. 

I'll send the new pacakge to Rajiv by another e-mail.

rimage can't work with fftw3 right now. It'll be changed someday in 
future. I don't have time to work on the update. Please use fftw2.



===================================
Tomomi TAKASHINA
http://homepage.mac.com/t_takashina



From rajiv.prasad at charter.net  Mon Nov 10 03:38:18 2003
From: rajiv.prasad at charter.net (Rajiv Prasad)
Date: Sun, 9 Nov 2003 18:38:18 -0800
Subject: [R] Re: configure" options and R CMD INSTALL
References: <200311091851.hA9Ip29w061334@mxsf08.cluster1.charter.net>
	<20031109190220.GA11886@sonny.eddelbuettel.com>
	<000901c3a71f$0a017bc0$6501a8c0@Jeeves2>
	<16102609.1068430559090.JavaMail.t.takashina@computer.org>
Message-ID: <001b01c3a733$b5c08690$6501a8c0@Jeeves2>

Hi Tomomi:

I received the other e-mail where you sent rimage_0.5-3.  It installed
without any problems using fftw-2.1.5.  Thanks for the quick response.

Rajiv

----- Original Message ----- 
From: "Tomomi TAKASHINA" <t.takashina at computer.org>
To: "Rajiv Prasad" <rajiv.prasad at charter.net>
Cc: "Dirk Eddelbuettel" <edd at debian.org>; "R-Help Mailing List"
<r-help at stat.math.ethz.ch>; <t.takashina at computer.org>
Sent: Sunday, November 09, 2003 6:15 PM
Subject: Re: configure" options and R CMD INSTALL


> Hi, Rajiv:
>
> At Sun, 9 Nov 2003 16:10:23 -0800, "Rajiv Prasad" wrote:
>
> > I tried downgrading to fftw-2.1.5, but that was no help either.  The
error
> > message is still the same, at the same place during configuration.
> >
> > It seems to me that configure is checking for the existance of a
function
> > named "fftwnd_one" in the fftw library, and is not able to find it
(2.1.5 as
> > well as 3.0.1).
>
> I'm sorry that the configure script of currently distributed package
> doesn't check library and header path correctly. I had submitted new
> package to cran by e-mail few weeks ago. But unforunately, the mail
> had returned by some reason.
>
> I'll send the new pacakge to Rajiv by another e-mail.
>
> rimage can't work with fftw3 right now. It'll be changed someday in
> future. I don't have time to work on the update. Please use fftw2.
>
>
>
> ===================================
> Tomomi TAKASHINA
> http://homepage.mac.com/t_takashina
> ===================================
>
>



From sdutky at terpalum.umd.edu  Mon Nov 10 03:57:02 2003
From: sdutky at terpalum.umd.edu (Steve Dutky)
Date: Sun, 9 Nov 2003 21:57:02 -0500
Subject: [R] Extending function symbols() to handle arbitrary shapes
Message-ID: <002201c3a736$528953b0$64fca8c0@warbunny>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031109/da7cf407/attachment.pl

From ggrothendieck at myway.com  Mon Nov 10 04:00:42 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun,  9 Nov 2003 22:00:42 -0500 (EST)
Subject: [R] Subsetting a list of vectors
Message-ID: <20031110030042.8063039A0@mprdmxin.myway.com>



This has already been answered but I think behind your 
question may have been the thought of whether its 
possible to do it all at once: transformation and selection.

There are languages that do allow this.  For example, Python 
has list comprehensions which are things like this:

   # give me the squares of the even numbers from 1-10, in a list. 
   >>> [ x*x for x in range(1,11) if x%2 == 0]

In R you could do this:

	sapply( 1:10, function(x)x^2 )

but AFAIK you can't incorporate the condition without creating 
a temporary:

	t <- sapply( 1:10, function(x)x^2 )
	z <- t[ t%%2 == 0 ]

(In this simple example we could have used the fact that parity
is invariant under squaring to reduce 1:10 to seq(2,10,2)
and thereby eliminate the selection part but that's not really
the point since that avoids the problem rather than allowing its
expression in the terms we want.)

---
 
Date: Mon, 10 Nov 2003 13:43:07 +1300 
From: Hadley Wickham <h.wickham at auckland.ac.nz>
To: R-Help Mailing List <r-help at stat.math.ethz.ch> 
Subject: [R] Subsetting a list of vectors 

 
 
Hi,

I'm trying to subset a list which contains variable length vectors. 
What I want to do is extract (eg.) the 3rd item in each vector (with 
length >= 3). At the moment I'm using sapply(list.of.vectors, 
function(x) {x[3]}). The problem with this is that sapply returns a 
list of the same length of list.of.vectors so I end up with a whole lot 
of null entries from those vectors that aren't long enough. I have a 
similar problem if I want to select all the vectors where the 3rd item 
is a specified value.

Does anyone have any better solutions?

Thanks for you help,

Hadley



From kjetil at entelnet.bo  Mon Nov 10 04:17:29 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sun, 09 Nov 2003 23:17:29 -0400
Subject: [R] small problem with symbols
Message-ID: <3FAECB09.2703.1D8D029@localhost>

Hola!

The help page 
?symbols
says that the argument fg= 
takes the value of col as its default, but

symbols(0,0,circles=1, col="red")

does not pick up the color. 

Kjetil Halvorsen



From edd at debian.org  Mon Nov 10 04:29:26 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 9 Nov 2003 21:29:26 -0600
Subject: [R] Subsetting a list of vectors
In-Reply-To: <20031110030042.8063039A0@mprdmxin.myway.com>
References: <20031110030042.8063039A0@mprdmxin.myway.com>
Message-ID: <20031110032926.GA15286@sonny.eddelbuettel.com>

On Sun, Nov 09, 2003 at 10:00:42PM -0500, Gabor Grothendieck wrote:
> There are languages that do allow this.  For example, Python 
> has list comprehensions which are things like this:
> 
>    # give me the squares of the even numbers from 1-10, in a list. 
>    >>> [ x*x for x in range(1,11) if x%2 == 0]
> 
> In R you could do this:
> 
> 	sapply( 1:10, function(x)x^2 )
> 
> but AFAIK you can't incorporate the condition without creating 
> a temporary:
> 
> 	t <- sapply( 1:10, function(x)x^2 )
> 	z <- t[ t%%2 == 0 ]

ifelse is your friend:

> sapply( 1:10, function(x) ifelse(x%%2, 0, x)^2 )
[1]   0   4   0  16   0  36   0  64   0 100
 
Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From edd at debian.org  Mon Nov 10 04:47:06 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 9 Nov 2003 21:47:06 -0600
Subject: [R] Subsetting a list of vectors
In-Reply-To: <20031110032926.GA15286@sonny.eddelbuettel.com>
References: <20031110030042.8063039A0@mprdmxin.myway.com>
	<20031110032926.GA15286@sonny.eddelbuettel.com>
Message-ID: <20031110034706.GA15448@sonny.eddelbuettel.com>

On Sun, Nov 09, 2003 at 09:29:26PM -0600, Dirk Eddelbuettel wrote:
> On Sun, Nov 09, 2003 at 10:00:42PM -0500, Gabor Grothendieck wrote:
> > There are languages that do allow this.  For example, Python 
> > has list comprehensions which are things like this:
> > 
> >    # give me the squares of the even numbers from 1-10, in a list. 
> >    >>> [ x*x for x in range(1,11) if x%2 == 0]
> > 
> > In R you could do this:
> > 
> > 	sapply( 1:10, function(x)x^2 )
> > 
> > but AFAIK you can't incorporate the condition without creating 
> > a temporary:
> > 
> > 	t <- sapply( 1:10, function(x)x^2 )
> > 	z <- t[ t%%2 == 0 ]
> 
> ifelse is your friend:
> 
> > sapply( 1:10, function(x) ifelse(x%%2, 0, x)^2 )
> [1]   0   4   0  16   0  36   0  64   0 100

PS: if you want just the set, maybe flagging as NA would do:

> as.numeric(na.omit(sapply( 1:10, function(x) ifelse(x%%2,NA,x)^2 )))
[1]   4  16  36  64 100

but that is indeed still not as clever as the loop-condiional from Python.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From ggrothendieck at myway.com  Mon Nov 10 06:23:17 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 10 Nov 2003 00:23:17 -0500 (EST)
Subject: [R] Subsetting a list of vectors
Message-ID: <20031110052317.67B893984@mprdmxin.myway.com>



Dirk and Ray have provided two very clever solutions which 
perform transformation and selection in one go 
by returning NA and NULL respectively for unwanted elements 
and then eliminating the NAs and NULLs.  

I thought it would be worthwhile to bring them together and 
make some further minor improvements.

Note that for the NULL solution we use the fact that 
if(FALSE)... with no else leg equals NULL.


Problem 1. If v is a list of vectors, get the vector which is the
third element of each vector in v.  Do not include any elements 
for vectors with less than 3 elements.

Here the NA solution is particularly short:

  as.numeric( na.omit( sapply( v, "[", 3 ) ) ) 

but the NULL solution seems closer to the list comprehension idea:

  unlist( sapply( v, function(x) if (length(x)>=3) x[3] ) )


Problem 2. Express this Python program in R:
     # give me the squares of the even numbers from 1-10, in a list. 
     >>> [ x*x for x in range(1,11) if x%2 == 0]


Here the NULL Solution is both short and closer to the Python one:

  unlist( sapply( 1:10, function(x) if (x%%2==0) x^2 ) )

while the NA solution is:

  as.numeric(na.omit(sapply(1:10,function(x)if(x%%2==0)x^2 else NA)))



From mn216 at columbia.edu  Mon Nov 10 06:52:35 2003
From: mn216 at columbia.edu (Murad Nayal)
Date: Mon, 10 Nov 2003 00:52:35 -0500
Subject: [R] kmeans error (bug?)
Message-ID: <3FAF27A3.24D4940@columbia.edu>


Hello,

I have been getting the following intermittent error from kmeans:

>str(cavint.p.r)
 num [1:1967, 1:13] 0.691 0.123 0.388 0.268 0.485 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:1967] "6" "49" "87" "102" ...
  ..$ : chr [1:13] "HYD" "NEG" "POS" "OXY" ...
> set.seed(34)
> kmeans(cavint.p.r,centers=34)
Error: empty cluster: try a better set of initial centers

the seed being equal to the number of centers in this case is just a
coincidence. I've encountered the same error with or without setting the
seed at different numbers of clusters.

there is nothing particularly unusual about cavint.p.r (no NAs, NULLs),
except maybe for the fact that the rows sum to 1.

> sum(is.na(cavint.p.r))
[1] 0
> sum(is.nan(cavint.p.r))
[1] 0
> 

I thought kmeans should select initial centers from the data if not
given explicitly! any idea what might be going wrong?

I am running R 1.7.0

many thanks

Murad



From lecoutre at stat.ucl.ac.be  Mon Nov 10 09:02:49 2003
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Mon, 10 Nov 2003 09:02:49 +0100
Subject: [R] Subsetting a list of vectors
In-Reply-To: <3FAEDF1B.3060600@auckland.ac.nz>
Message-ID: <5.1.1.5.2.20031110085553.017ddeb0@stat4ux.stat.ucl.ac.be>


Hi,

I propose here a solution that relies on names of elements:

# From a list, with any names
ll=list(v1=1:4,v2=1:2,v3=5:7,v4=9:11,v5=1,v6=rnorm(4))
# Make a copy to be able to change names
ll2=ll

names(ll2)=rep("a",lengh(ll2))

# Use unlist, which "autobuilds" names based on
# previous names and indexes in # vectors.
# Extracts 3 elements  when they exists

unlist(ll2)[substring(names(unlist(ll2)),2)=="3"]

Eric

At 13:43 10/11/2003 +1300, Hadley Wickham wrote:
>Hi,
>
>I'm trying to subset a list which contains variable length vectors.
>What I want to do is extract (eg.) the 3rd item in each vector (with 
>length >= 3).  At the moment I'm using sapply(list.of.vectors, function(x) 
>{x[3]}).  The problem with this is that sapply returns a list of the same 
>length of list.of.vectors so I end up with a whole lot of null entries 
>from those vectors that aren't long enough.  I have a similar problem if I 
>want to select all the vectors where the 3rd item is a specified value.
>
>Does anyone have any better solutions?
>
>Thanks for you help,
>
>Hadley



--------------------------------------------------
L'erreur est certes humaine, mais un vrai d?sastre
n?cessite un ou deux ordinateurs. Citation anonyme
--------------------------------------------------
Eric Lecoutre
Informaticien/Statisticien
Institut de Statistique / UCL

TEL (+32)(0)10473050       lecoutre at stat.ucl.ac.be
URL http://www.stat.ucl.ac.be/ISpersonnel/lecoutre



From e.pebesma at geog.uu.nl  Mon Nov 10 09:07:36 2003
From: e.pebesma at geog.uu.nl (Edzer J. Pebesma)
Date: Mon, 10 Nov 2003 09:07:36 +0100
Subject: [R] predict.lm with (logical) NA vector
Message-ID: <3FAF4748.2080208@geog.uu.nl>

I was surprised by the following (R 1.8.0):

R> lm.fit = lm(y~x, data.frame(x=1:10, y=1:10))
R> predict(lm.fit, data.frame(x = rep(NA, 10)))
             1              2              3              4              5
-1.060998e-314 -1.060998e-314 -1.060998e-314 -1.060998e-314 -1.060998e-314
             6              7              8              9             10
  0.000000e+00  1.406440e-269  6.715118e-265  4.940656e-323  1.782528e-265
R> predict(lm.fit, data.frame(x = as.numeric(rep(NA, 10))))
 1  2  3  4  5  6  7  8  9 10
NA NA NA NA NA NA NA NA NA NA

shouldn't the first predict() call return NA's, or else issue an error 
message?
--
Edzer



From ripley at stats.ox.ac.uk  Mon Nov 10 09:19:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 08:19:16 +0000 (GMT)
Subject: [R] kmeans error (bug?)
In-Reply-To: <3FAF27A3.24D4940@columbia.edu>
Message-ID: <Pine.LNX.4.44.0311100812560.21158-100000@gannet.stats>

This is not a bug.  It just means that the algorithm sometimes finds an 
empty cluster, and as you asked for 34 clusters and it had 33 or less it 
stops.

What to do in this situation is currently under discussion, but the advice 
given is good: try another set of initial centres.

Please do read the description of a bug in the R FAQ, and do not misuse 
the term to mean `something I do not understand'.

On Mon, 10 Nov 2003, Murad Nayal wrote:

> I have been getting the following intermittent error from kmeans:
> 
> >str(cavint.p.r)
>  num [1:1967, 1:13] 0.691 0.123 0.388 0.268 0.485 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : chr [1:1967] "6" "49" "87" "102" ...
>   ..$ : chr [1:13] "HYD" "NEG" "POS" "OXY" ...
> > set.seed(34)
> > kmeans(cavint.p.r,centers=34)
> Error: empty cluster: try a better set of initial centers
> 
> the seed being equal to the number of centers in this case is just a
> coincidence. I've encountered the same error with or without setting the
> seed at different numbers of clusters.
> 
> there is nothing particularly unusual about cavint.p.r (no NAs, NULLs),
> except maybe for the fact that the rows sum to 1.
> 
> > sum(is.na(cavint.p.r))
> [1] 0
> > sum(is.nan(cavint.p.r))
> [1] 0
> > 
> 
> I thought kmeans should select initial centers from the data if not
> given explicitly! any idea what might be going wrong?

And what makes you think it did not?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From elsawy at ysbl.york.ac.uk  Mon Nov 10 09:34:07 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Mon, 10 Nov 2003 08:34:07 +0000
Subject: [R] weird behaviour of eigen() (actual example)
References: <3FAE4F01.F966109E@ysbl.york.ac.uk>
	<Pine.A41.4.58.0311090810450.17834@homer20.u.washington.edu>
Message-ID: <3FAF4D7F.F08A998A@ysbl.york.ac.uk>

Hi Thomas,
the matrix V , which produced the anomelous order,is attached as an R
object,

load("V.r")
eigen(V)$values
you'll get the eigen values in reverse order

best regards
Karim

Thomas Lumley wrote:
> 
> On Sun, 9 Nov 2003, Karim Elsawy wrote:
> 
> > I'm using R 1.7.1 under linux redhat
> > it seems that the eigen values produced by eigen() do not follow
> > a consistant order; I mean either ascending or discending
> 
> This is strange, since the source code explicitly sorts them. Can you send
> an actual example?
> 
>         -thomas
> 
> > e.g
> >
> > for one system:
> > eigenV<-eigen(V)
> > >                   print(eigenV$values)
> >  [1] -7.706828e+13 -4.702980e+13 -3.267579e+13 -1.701297e+13
> > -8.041677e+12
> >  [6] -5.707311e+12 -5.053941e+12 -4.774652e+12 -4.280423e+12
> > -3.798905e+12
> > [11] -3.422172e+12 -3.148595e+12 -2.974540e+12 -2.881025e+12
> > -2.730044e+12
> > [16] -2.476652e+12 -2.216184e+12 -1.996965e+12 -1.852241e+12
> > -1.419131e+12
> > [21] -1.307872e+12 -1.248930e+12 -1.244060e+12 -1.092555e+12
> > -1.069742e+12
> > [26] -1.064907e+12 -1.007863e+12 -9.894342e+11 -9.459110e+11
> > -8.017146e+11
> > [31] -5.619008e+11 -5.443052e+11 -3.834215e+11 -7.530864e+10
> > -2.820257e+10
> > [36] -1.757125e+10 -5.503488e+09 -2.225226e+09 -1.106936e+09
> > -1.035204e-05
> >
> > > -7.706828e+13 > -1.035204e-05
> > [1] FALSE
> >
> > for anther system:
> > eigenV<-eigen(V)
> > > print(eigenV$values)
> >  [1] -8.564110e-03 -1.486071e+08 -8.200752e+08 -2.033989e+09
> > -3.166960e+09
> >  [6] -9.511769e+09 -1.067173e+10 -1.207226e+10 -3.779904e+10
> > -6.752452e+10
> > [11] -1.717127e+11 -1.781890e+11 -1.887900e+11 -2.566200e+11
> > -2.908604e+11
> > [16] -4.027630e+11 -4.813731e+11 -5.072795e+11 -7.635460e+11
> > -8.442470e+11
> > [21] -8.938820e+11 -9.533737e+11 -1.038059e+12 -1.155368e+12
> > -1.297694e+12
> > [26] -1.502400e+12 -1.577757e+12 -1.748035e+12 -1.948777e+12
> > -2.234958e+12
> > [31] -2.586261e+12 -2.635164e+12 -2.705431e+12 -2.714573e+12
> > -3.189646e+12
> > [36] -3.313364e+12 -3.405791e+12 -4.951881e+12 -5.396912e+12
> > -5.681758e+12
> > [41] -5.964839e+12 -6.782151e+12 -7.234084e+12 -7.328940e+12
> > -7.421814e+12
> > [46] -8.129555e+12 -8.226702e+12 -9.268597e+12 -1.003589e+13
> > -1.076822e+13
> > [51] -1.136816e+13 -1.456318e+13 -1.903689e+13 -3.804764e+13
> > -6.641937e+13
> > [56] -1.547690e+14
> >
> > > -8.564110e-03 > -1.547690e+14
> > [1] TRUE
> >
> > what worries me now is that whether the order of the eigen vectors
> > follow the
> > corresponding eigen values or not?????
> > THIS IS OF PRIME IMPORTANCE.
> >
> > any help is very much appreciated
> > best regards
> > Karim
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> Thomas Lumley                   Assoc. Professor, Biostatistics
> tlumley at u.washington.edu        University of Washington, Seattle

From ripley at stats.ox.ac.uk  Mon Nov 10 09:44:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 08:44:53 +0000 (GMT)
Subject: [R] predict.lm with (logical) NA vector
In-Reply-To: <3FAF4748.2080208@geog.uu.nl>
Message-ID: <Pine.LNX.4.44.0311100839000.21158-100000@gannet.stats>

On Mon, 10 Nov 2003, Edzer J. Pebesma wrote:

> I was surprised by the following (R 1.8.0):
> 
> R> lm.fit = lm(y~x, data.frame(x=1:10, y=1:10))
> R> predict(lm.fit, data.frame(x = rep(NA, 10)))
>              1              2              3              4              5
> -1.060998e-314 -1.060998e-314 -1.060998e-314 -1.060998e-314 -1.060998e-314
>              6              7              8              9             10
>   0.000000e+00  1.406440e-269  6.715118e-265  4.940656e-323  1.782528e-265
> R> predict(lm.fit, data.frame(x = as.numeric(rep(NA, 10))))
>  1  2  3  4  5  6  7  8  9 10
> NA NA NA NA NA NA NA NA NA NA
> 
> shouldn't the first predict() call return NA's, or else issue an error 
> message?

The prediction methods do not in general check that new variables you give 
are of the correct type: the type used in the fit is not recorded in the 
model object.  In this case a logical column will `work' provided it has 
two values (even with NAs).  We can probably trap this exact case, but 
there will remain a lot of scope for user error.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon Nov 10 09:52:55 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Nov 2003 09:52:55 +0100
Subject: [R] weird behaviour of eigen() (actual example)
In-Reply-To: <3FAF4D7F.F08A998A@ysbl.york.ac.uk>
References: <3FAE4F01.F966109E@ysbl.york.ac.uk>
	<Pine.A41.4.58.0311090810450.17834@homer20.u.washington.edu>
	<3FAF4D7F.F08A998A@ysbl.york.ac.uk>
Message-ID: <16303.20967.301220.979483@gargle.gargle.HOWL>

>>>>> "Karim" == Karim Elsawy <elsawy at ysbl.york.ac.uk>
>>>>>     on Mon, 10 Nov 2003 08:34:07 +0000 writes:

    Karim> Hi Thomas, the matrix V , which produced the
    Karim> anomelous order,is attached as an R object,

and it wasn't :
Most binary attachments are *not* allowed on our mailing lists
(for several reasons I'd rather not discuss on R-help)
and the mailman software silently drops them. 
Either send these only to individuals, give the R code to
generate them, give an URL (ftp://.. or http://.. ) where people
can get it; post the result of  dput(...), or if you must, use plain/text
attachments e.g. from save(..., ascii=TRUE).

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From christoph.lehmann at gmx.ch  Mon Nov 10 10:04:28 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: 10 Nov 2003 10:04:28 +0100
Subject: [R] criterion for variable selection in LDA
Message-ID: <1068455068.1161.19.camel@christophl>

Hi
Since a stepwise procedure for variable selection (as e.g. in SPSS) for
a LDA is not implemented in R and anyway I cannot be sure, that all the
required assumptions for e.g. a procedure using a statistic based on
wilks' lambda, hold (such as normality and variance homogeneity) I would
like to ask you, what you would recommend me:

shall I e.g. define a criterion such as the error-rate stemming from a
leaving-one-out cross-validation and then write my own procedure of
including/removing variables?

or what would be the golden standard for such a case (my "case" is that
I have 2 groups (n1=30, n2=15, number of potential variables: 37, no
equal variance in the two groups))

many thanks

cheers

christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From elsawy at ysbl.york.ac.uk  Mon Nov 10 10:22:34 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Mon, 10 Nov 2003 09:22:34 +0000
Subject: [R] weird behaviour of eigen() (actual example)
References: <3FAE4F01.F966109E@ysbl.york.ac.uk>
	<Pine.A41.4.58.0311090810450.17834@homer20.u.washington.edu>
	<3FAF4D7F.F08A998A@ysbl.york.ac.uk>
	<16303.20967.301220.979483@gargle.gargle.HOWL>
Message-ID: <3FAF58DA.EF5A51F9@ysbl.york.ac.uk>

Hi Thomas, 
the matrix V , which produced the anomelous order,is attached as a text
file,
V<-matrix(scan("V.dat"),ncol=40,byrow=T)
eigen(V)$values

best regards
karim

Martin Maechler wrote:
> 
> >>>>> "Karim" == Karim Elsawy <elsawy at ysbl.york.ac.uk>
> >>>>>     on Mon, 10 Nov 2003 08:34:07 +0000 writes:
> 
>     Karim> Hi Thomas, the matrix V , which produced the
>     Karim> anomelous order,is attached as an R object,
> 
> and it wasn't :
> Most binary attachments are *not* allowed on our mailing lists
> (for several reasons I'd rather not discuss on R-help)
> and the mailman software silently drops them.
> Either send these only to individuals, give the R code to
> generate them, give an URL (ftp://.. or http://.. ) where people
> can get it; post the result of  dput(...), or if you must, use plain/text
> attachments e.g. from save(..., ascii=TRUE).
> 
> Martin Maechler <maechler at stat.math.ethz.ch>    http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
> ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
> phone: x-41-1-632-3408          fax: ...-1228                   <><
-------------- next part --------------
-581140810362.995 0 0 16045978345.0765 0 9495573.10875 3900554371.51 0 0 2.88157401725673e-113 0 61216825505.8433 49181859142.8507 0 5864209.73297746 3.76227977993903e-229 0 0 2428549023.49768 0 299207533573.156 1.20016704027939e-225 140610993190.011 0 0 1.71785720923498e-115 0 0 0 13704342247.4798 0 0 0 0 26010107830.0685 0 0 0 0 0
0 -1255004877865.73 31236501054.631 0 76276970.7467233 1797962289.67698 1.14762042381474e-45 563312968.627084 40443014305.7111 614126334.650567 2.04071904836340e-42 509374152.089907 5.9445365412695 0 81593143.7418469 106230530.551845 0 36998556.4378358 158138758990.610 177249723.581601 0 34599598.7092567 0 110872677.630578 1.04473492303786e-37 1859008910.27622 0 1867144355.99983 25895398.8931615 465494057.119419 2128763500.44649 12415180.6340063 0 1.11753961506099e-38 6540309.49289193 28395505075.6188 138315073.659288 749071092.826726 0 34223150.7242273
0 31236501054.631 -1068332469839.86 0 0 0 0 2766595667.0944 3167124515.68267 0 0 0 0 9.9052613308723e-40 8140252.57208804 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 166591312.238244 5805795552.31068 0 0 0 961964261.039074 0 0 0 0
16045978345.0765 0 0 -9352333617695.03 0 0 1324145033.81920 0 0 0 9688515497.26971 0 0 0 0 0 0 0 250986592.815148 3637902424.11987 29354480900.1705 3.03759528939867e-33 13825830981.2082 0 358977268002.692 0 0 7177854957515.75 0 0 219517.072336381 0 0 8.2023608159934e-225 2525319264.16884 2.01370834706529e-123 13417020982.5027 0 0 0
0 76276970.7467231 0 0 -3805866036519.22 0 0 0 0 167134240379.783 11428256665.8533 680011681423.987 20156956099.1605 343832104113.671 4269548464.47571 13863491531.7605 52879601095.642 1935665895.88937 106020701.878367 3128670409.05590 0 280.226855562593 7478808711.27514 924152866.726997 212884792027.175 298124177.882638 0 0 23993889135.3667 159341108.710488 0 0 0 20435986547.2565 150189032.582340 39406.5417093058 53.9347531010634 8.79132870238602e-45 0 4.5421435860649e-123
9495573.10875002 1797962289.67698 0 0 0 -3783385992.83987 1072306.58990903 2.50562084985639e-114 0 0 9792756.92478245 70513620.5118605 32205695.9522684 6813501086.46266 50052847.9700318 0 42551563.2589913 0 34660901.6211451 0 17331268.4002349 5.63292032881281e-126 36414751094.5568 626096988.219633 186994674.401882 0 0 1.01372387776417e-33 1.12732460757837e-36 0 20134104.2214651 38569497.5213521 3126486905.62096 0 92965249.6303278 0 0 0 0 0
3900554371.51000 1.14762042381477e-45 0 1324145033.81920 0 1072306.58990902 -6963152041.96441 0 9.1905719456918e-37 0 35477388063.3793 8299781573.7853 0 46504967094.4847 0 0 1030306033.39468 0 939544.483521955 2.12391762747207e-37 9288579091.45015 0 4370336058.80982 0 6047826470.88493 3.36809708929696e-39 0 0 0 0 1.30487845994847e-129 0 0 0 0 1660641.57964074 0 2.6224893924501e-114 0 0
0 563312968.627085 2766595667.0944 0 0 2.50562084985642e-114 0 -32634780535438.2 1038114.84922592 1255213505985.45 553260827.851603 4.29718112964314e-33 0 0 0 3800286278.20747 1.83112335671973e-126 458635695.565973 4.67525610439246e-228 8719833833.51867 0 20582198007.9636 0 2575306586.92573 0 23208370.3730724 0 100921615494.636 6556398784.6314 1144637166692.03 54540.2466237763 283054763.162504 3788904285.15697 107800463.088446 202980586.856833 134421261.480229 3146883992.30452 17073809347.6777 0 3136926670.53375
0 40443014305.7111 3167124515.68266 0 0 0 9.19057194569173e-37 1038114.84922592 -615003645546.066 62261129.5381359 158363588.804267 0 0 0 432294490.99367 192790.942334588 0 0 92992701394.1232 927375598.225468 0 103603.243983549 0 210333706.238551 136645454.084926 2339569.00252188 0 5763074.58100738 253767372.802138 0 30834892029.089 104648622.894840 1468969.3181696 89077463.3405707 1071303.25995459 456772000.789515 3043129967.02778 6283387506.61292 0 90215141.5492152
5.11366369426759e-117 108983.337661621 0 0 29659772.4709079 0 0 222751166.399788 11048.9085401451 -4776490813948.69 19066859.7812707 5.96331085453367e-36 0.00371967117354574 0 943822.00788001 3063300.75220452 0 0 0 7024258.27600864 0 16619344.6327106 1635147.19070782 142034.919664943 0 365737.141502887 0 863466949.843415 5298241.81541014 29440237.9573723 581.142746043455 381096.070133784 1771175.78617976 1265645869.17005 808918.331851452 1431624.46537783 4243108.28652016 0 4605684484.07300 4232347.08681659
0 2.04071904836339e-42 0 9688515497.26973 11428256665.8533 9792756.92478244 35477388063.3793 553260827.851604 158363588.804267 107442669329.181 -1222148869136.64 61028446122.4511 10551153203.1965 101538634633.366 25840810342.2967 110176483105.401 0 9666010416.76489 6.16569974682692e-40 0 0 0 0 5200185265.49073 41834350853.6936 1677554556.79059 0 0 1770318.30704894 0 2442722.85802006 8221653729.9079 0 0 12358128728.6305 0 426274285257.928 33487019358.78 0 0
61216825505.8433 509374152.089907 0 0 680011681423.987 70513620.5118604 8299781573.7853 4.29718112964318e-33 0 3.36035426704159e-32 61028446122.4511 -3286468897719.27 224605738114.565 1123064611862.72 21359688442.0109 69329241837.4135 52166511148.066 9554323875.23956 201123896.114144 0 75167491623.0267 375185243433.84 0 4914793117.25448 23731594697.0169 1514258508.77002 0 12801760422.9706 128603336551.440 0 149270185.088101 5177924791.56757 0 0 10976062143.0251 63759482.384529 57293223326.8228 0 0 0
49181859142.8506 5.94453654126949 0 0 20156956099.1606 32205695.9522684 0 0 0 20.9605254613105 10551153203.1965 224605738114.565 -1042314063477.12 0 21050002311.4336 40637104213.9336 18315912475.8398 5672924831.5647 91709552.3086587 0.0819845142507353 0 104067087137.735 0 0 18317839238.5766 142.159189907319 0 9.438247599765e-32 6178625080.13616 0 1236659.57506659 0.0269632208981177 1.25370715331182e-38 0 0 3045908094.44606 0 0 8311046231.32212 0
0 0 3.82406403626994e-40 0 132741170569.43 2630446950.91686 17953889981.6460 0 0 0 39200403505.0745 433574728538.072 0 -76968486682203.6 263749120539.079 0 30034549727.5419 13667753198.1409 0 0 0 0 0 7.0338315310902e-117 0 0 0 1043199725112.05 0 0 0 0 3113187.33099218 0 0 0 0 0 0 0
615343.063600659 8561729.0862864 854172.716235462 0 448012119.612242 5252143.80355718 0 0 45361511.3678189 558078808.47163 2711527064.34306 2241314127.89513 2208818152.98612 71686869740.1851 -73802391075.3489 0.0174055976381191 0 254124872.008514 1880495.18263184 742702231.982785 0 0.00319121616534791 0 218922601.619422 183825164.332134 3877250023.95705 0 86839178.374591 0.0465728663131426 337176075.635053 90651075.9261115 87362945.6428966 0 0 477312.543002229 0 0 0 3140066.42920038 0
3.76227977993867e-229 106230530.551845 0 0 13863491531.7605 0 0 3800286278.20748 192790.942334588 17261846657.0066 110176483105.401 69329241837.4136 40637104213.9336 0 0.165875072159729 -1356468076160.76 0 1721952.43883409 0 51908112007.3789 0 32341678190.6790 0 15330526990.5536 50379997675.6536 4958721311.80261 0 2694979403.70092 1919902665.35861 10863006972.8039 477008.640923032 17172502141.3367 3652840.04505624 193197212.742978 14757594.8375802 1285044.72137781 190602474331.467 2077509477.46312 97209529.1834387 14085143722.3707
0 0 0 0 52879601095.642 42551563.2589912 1030306033.39469 1.83112335671973e-126 0 0 0 52166511148.066 18315912475.8398 77796831115.98 0 0 -2004771602651.64 2647875343.19061 121761090.103541 0 10349140784.0179 0 4860969448.42935 1274864005.58100 47974036837.5128 0 0 0 0 0 1634886.48788492 0 0 0 511215154.824759 0 2676775137.5332 0 0 0
0 144313492.419519 0 0 7550097422.38181 0 0 1788916253.7081 0 0 37702436400.4723 37266801164.5177 22127338834.2067 138089312391.056 9446295239.04617 6716504.48432985 10328082364.7649 -30454167349.1762 0 662141246.423717 0 36493330.2185543 82438103640.542 195199736.103644 27682239216.3800 100931130.094831 0 0 29291.8782211868 273023776.238179 4528028.87411928 3705318.09877405 0.570752410503495 580779671.857504 1894558.42203724 0 3882411847.58992 0 0 0
2428549023.49768 158138758990.610 0 250986592.815148 106020701.878367 34660901.6211451 939544.483521955 4.67525610439226e-228 92992701394.1232 0 6.1656997468268e-40 201123896.114144 91709552.3086587 0 17921089.5598288 0 121761090.103542 0 -796651577826.837 0 310207917.250803 0 0 19194042.1536414 533694645.423169 1253633.38818344 0 736943710.273305 0 333230142.742263 4919776365.3503 4341052.8283389 0 0 4532799137.18741 44560703.5432492 1065333223.55883 0 0 9.25380936529758e-41
0 177249723.581601 0 3637902424.11987 3128670409.05590 0 2.12391762747208e-37 8719833833.51868 927375598.225468 39582032274.3078 0 0 0.0819845142507359 0 7077940607.65435 51908112007.3789 0 169757310.040079 0 -1972211210420.49 0 8081261730.2126 0 18574330141.7274 3345717613.53092 5995674573.6432 0 606962498.247423 2571206661.06557 2357095691.03223 69476060.2733235 588381150109.579 8086290318.21099 493997716.985375 3649601.17521301 2540083064.86277 116782986689.561 0 21961644.0439419 3181728790.06729
299207533573.156 0 0 29354480900.1705 0 17331268.4002349 9288579091.45014 0 0 0 0 75167491623.0267 0 0 0 0 10349140784.0179 0 310207917.250803 0 -1086139332511.2 0 137643049234.655 4.83769844486708e-128 180459143250.591 0 0 3.35296897581186e-115 0 0 0 0 0 0 0 0 0 4985445476.94364 0 0
1.20016704027934e-225 34599598.7092566 0 3.03759528939871e-33 280.226855562592 5.6329203288129e-126 0 20582198007.9636 103603.243983549 93650804082.2768 0 375185243433.84 104067087137.734 0 0.0304122399419994 32341678190.679 0 9356024.27090274 0 8081261730.2126 0 -2765240348614.84 0 2155678271.41795 335035158907.109 695954937.314776 0 14582451304.2414 61857192062.8367 9479313751.91625 2585876.20878627 2411163845.2071 194098458455.66 11927205509.6461 80195353.7720606 13413966.7602381 26842969440.0107 8209193203.42352 527641567.273655 26783509488.4229
140610993190.011 0 0 13825830981.2082 7478808711.27512 36414751094.5568 4370336058.80981 0 0 9214132842.595 0 0 0 0 0 0 4860969448.42934 21135174397.3193 0 0 137643049234.655 0 -1039447445723.35 3.24551239367368e-125 0 0 0 6.22183729447046e-227 0 0 2.81099510617278e-50 0 0 0 23913324523.5523 2.5023806580202e-48 2.3358730567817e-45 1.89520375574151e-32 0 0
0 110872677.630578 0 0 924152866.726995 626096988.219633 0 2575306586.92572 210333706.238551 800373584.419373 5200185265.49073 4914793117.25447 0 1.82193443446464e-116 2086328955.54751 15330526990.5535 1274864005.58100 50044582.3311287 19194042.1536414 18574330141.7275 4.83769844486703e-128 2155678271.41795 3.24551239367363e-125 -1511828193777.11 972169551.250643 241905365126.778 0 179126185.850476 127966275.404140 695407104.424274 2724032.16578171 838745774835.295 2386294626.47383 68993.7021976604 983606.376628664 27231662633.4488 34462218669.2555 229040720.551175 0 2178086836.70260
0 1.04473492303786e-37 0 358977268002.692 212884792027.175 186994674.401882 6047826470.88493 0 136645454.084926 0 41834350853.6936 23731594697.0169 18317839238.5766 0 1751850929.35779 50379997675.6536 47974036837.5128 7097069531.07027 533694645.423171 3345717613.53092 180459143250.591 335035158907.109 0 972169551.250642 -5674120617489.52 316791507.650717 0 0 87658863722.2112 211227861238.890 7183719.45708472 3862986229.71241 3.2302737534583e-36 0 124748671.839113 17680312415.3812 42493567862.3501 0 0 0
1.71785720923487e-115 1859008910.27621 0 0 298124177.882638 0 3.36809708929697e-39 23208370.3730726 2339569.00252188 2060946333.41221 1677554556.79059 1514258508.77002 142.159189907318 0 36950131841.3037 4958721311.80261 0 25876347.7381070 1253633.38818344 5995674573.6432 0 695954937.314776 0 241905365126.778 316791507.650715 -166527317685.027 0 57790788.7256028 245627952.207121 224472412.739313 9891834.49535453 293442890646.056 2602884368.21040 0 317473.876343121 241863580.616224 11121197484.5795 44681450.4013053 19029959.2265715 67395112.120033
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -2730043659433.44 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1867144355.99983 0 7177854957515.75 0 1.01372387776417e-33 0 100921615494.636 5763074.5810074 4865677674927.53 0 12801760422.9706 9.43824759976476e-32 2702142484938.16 827576006.217124 2694979403.70092 0 0 736943710.273305 606962498.247423 3.35296897581188e-115 14582451304.2414 6.22183729447012e-227 179126185.850477 0 57790788.7256028 0 -45752200164505.3 4649477632.23932 15483019563.9593 9925575.25372739 200302515.104305 30300340019.2083 371389482107.290 426275593.044067 24469037824.2220 2231149007.88375 0 16434601627.5678 2225788262.44308
0 25895398.8931614 0 0 23993889135.3666 1.12732460757836e-36 0 6556398784.63141 253767372.802137 29855846737.7165 1770318.30704894 128603336551.440 6178625080.13616 0 0.443838684599901 1919902665.35861 0 7509.74279235315 0 2571206661.06557 0 61857192062.8366 0 127966275.404140 87658863722.2111 245627952.207121 0 4649477632.23932 -2142364806566.79 18058758072.1168 4102194.75067433 143144458.956752 0 333918288.081669 88123170393.3515 13419750.6324606 9375588476.7507 0 0 461392122716.929
13704342247.4798 465494057.119418 0 0 159341108.710488 0 0 1144637166692.03 0 165897152866.96 0 0 0 0 3213282705.90439 10863006972.8039 0 69996820.2879764 333230142.742263 2357095691.03223 0 9479313751.91625 0 695407104.424274 211227861238.890 224472412.739312 0 15483019563.9593 18058758072.1168 -1059689611719.12 22287651.0570508 813501939.078959 0 12639274510.2658 1730791668.05392 6240353147.95506 8840214820.17061 48647384557.1152 560068786.097591 8700721824.4639
0 2128763500.44649 166591312.238244 219517.072336381 0 20134104.2214651 1.30487845994848e-129 54540.2466237762 30834892029.089 3274767.24602197 2442722.85802006 149270185.088101 1236659.57506659 0 863903330.02238 477008.640923032 1634886.48788492 1160879.20153884 4919776365.3503 69476060.2733235 0 2585876.20878626 2.81099510617286e-50 2724032.16578172 7183719.45708473 9891834.49535456 0 9925575.2537274 4102194.75067433 22287651.0570507 -1713919788.74473 5504853.41757242 4205379.98754770 4693271.21698703 12748.5382011552 24016444.2240076 2317020895.90843 0 207450.797045276 61084382.2235465
0 12415180.6340063 5805795552.31068 0 0 38569497.5213522 0 283054763.162504 104648622.894840 2147494632.87371 8221653729.90792 5177924791.56758 0.0269632208981178 0 832567500.059016 17172502141.3368 0 949955.672884014 4341052.82833889 588381150109.579 0 2411163845.2071 0 838745774835.295 3862986229.71241 293442890646.056 0 200302515.104305 143144458.956753 813501939.078961 5504853.41757242 -2156448317330.80 2667646839.07386 163979393.707341 200656304.668042 13550041038.0576 38555350486.5277 4773651018.54541 141768040.519560 1050203170.36745
0 0 0 0 0 3126486905.62096 0 3788904285.15697 1468969.31816960 9980660502.11868 0 0 1.25370715331181e-38 8063916.76315067 0 3652840.04505624 0 0.146327380191572 0 8086290318.21099 0 194098458455.66 0 2386294626.47383 3.23027375345832e-36 2602884368.2104 0 30300340019.2083 0 0 4205379.98754769 2667646839.07386 -2880519751747.53 6749975.34643046 1116712621.35358 121662697.643815 1205908700.19446 0 9.69309420190401e-123 91803719039.1527
0 1.11753961506102e-38 0 8.20236081599332e-225 20435986547.2565 0 0 107800463.088446 89077463.3405705 7131975174153.14 0 0 0 0 0 193197212.742978 0 148898132.162875 0 493997716.985375 0 11927205509.6461 0 68993.7021976602 0 0 0 371389482107.290 333918288.081668 12639274510.2658 4693271.21698704 163979393.707341 6749975.34643044 -5022251434885.47 65285472.2792878 1016506406.04316 1821980159.14527 2.750796498623e-125 20993739940.8739 897010944.040845
26010107830.0685 6540309.49289193 0 2525319264.16884 150189032.582341 92965249.6303277 0 202980586.856833 1071303.25995459 4558293596.34783 12358128728.6305 10976062143.0251 0 0 4548781.03925848 14757594.8375802 511215154.82476 485719.841764716 4532799137.18740 3649601.17521302 0 80195353.7720606 23913324523.5523 983606.376628663 124748671.839113 317473.876343121 0 426275593.044067 88123170393.3515 1730791668.05392 12748.5382011552 200656304.668042 1116712621.35358 65285472.2792878 -37293945503.9952 4785533.03765338 0 328460495.719677 0 64518722911.5803
0 28395505075.6188 961964261.039073 2.01370834706536e-123 39406.541709306 0 1660641.57964073 134421261.480229 456772000.789514 8067272524.24913 0 63759482.384529 3045908094.44606 0 0 1285044.72137781 0 0 44560703.5432492 2540083064.86277 0 13413966.7602381 2.50238065802021e-48 27231662633.4488 17680312415.3811 241863580.616224 0 24469037824.222 13419750.6324606 6240353147.95506 24016444.2240075 13550041038.0575 121662697.643815 1016506406.04316 4785533.03765339 -3798212509690.93 9333968855.399 0 0 12218308.2863277
0 138315073.659288 0 13417020982.5027 53.9347531010634 0 0 3146883992.30452 3043129967.02779 23910118697.3805 426274285257.928 57293223326.8227 0 0 0 190602474331.467 2676775137.5332 995358309.53634 1065333223.55884 116782986689.561 0 26842969440.0107 2.33587305678171e-45 34462218669.2555 42493567862.3501 11121197484.5795 0 2231149007.88375 9375588476.75071 8840214820.1706 2317020895.90843 38555350486.5277 1205908700.19446 1821980159.14526 0 9333968855.399 -3314545049217.43 652094928.055766 0 2600324327.73986
0 9839359017.97298 0 0 1.15477743269150e-43 0 3.44474842244525e-113 224271556578.522 82534897046.0295 0 439865867296.343 0 0 0 0 27288947347.9249 0 0 0 0 65485890968.0621 107831152409.818 2.48942861946281e-31 3008544717.34304 0 586909355.002827 0 0 0 639003542556.372 0 62703883046.3128 0 3.61328512000088e-124 4314464637.00991 0 8565536932.8531 -17010095162939.0 5739010053.88976 37549611898.7957
0 0 0 0 0 0 0 0 0 25953252960032.8 0 0 8311046231.32213 0 29924783.7597515 97209529.1834389 0 0 0 21961644.0439419 0 527641567.273655 0 0 0 19029959.2265715 0 16434601627.5678 0 560068786.097592 207450.797045276 141768040.519560 9.6930942019042e-123 20993739940.8739 0 0 0 436911238.319301 -1282776892267.26 0
0 34223150.7242273 0 0 4.542143586065e-123 0 0 3136926670.53374 90215141.549215 23849478820.9352 0 0 0 0 0 14085143722.3707 0 0 9.25380936529746e-41 3181728790.06729 0 26783509488.4229 0 2178086836.70260 0 67395112.1200331 0 2225788262.44308 461392122716.929 8700721824.46389 61084382.2235464 1050203170.36744 91803719039.1527 897010944.040845 64518722911.5802 12218308.2863277 2600324327.73986 2858654590.08781 0 -668892922298.802

From neteler at itc.it  Mon Nov 10 10:39:12 2003
From: neteler at itc.it (Markus Neteler)
Date: Mon, 10 Nov 2003 10:39:12 +0100
Subject: [R] Rdbi/RdbiPgSQL updates
In-Reply-To: <200311091101.hA9B0DPe005241@hypatia.math.ethz.ch>;
	from bioconductor-request@stat.math.ethz.ch on Sun, Nov 09, 2003
	at 12:01:28PM +0100
References: <200311091101.hA9B0DPe005241@hypatia.math.ethz.ch>
Message-ID: <20031110103912.E8271@itc.it>

To get the Rdbi/RdbiPgSQL 1.0.1 interface from BioConductor
functional, I would like to suggest some fixes.
Find patches and the updated packages here:

 http://mpa.itc.it/markus/tmp/rdbi/

Changes

 Rdbi:
  - fixed load of RdbiPgSQL   (wrong name)
  - fixed dbConnectionInfo()  (typo)

 RdbiPgSQL:
  - fixed table export to PostgreSQL
  - added make.names() to polish column names for R usage

(maybe some of these patches are already in the 
 BioConductor-CVS)

Now the interface seems to work smoothly.

Thanks to Steno Fontanari and Dirk Eddelbuettel for their assistance.

Kind regards

 Markus Neteler

-- 
Markus Neteler     <neteler at itc.it      http://mpa.itc.it
ITC-irst, Istituto per la Ricerca Scientifica e Tecnologica
MPBA - Predictive Models for Biol. & Environ. Data Analysis
Via Sommarive, 18        -       38050 Povo (Trento), Italy



From Luis.Tito-de-Morais at ird.sn  Mon Nov 10 10:50:44 2003
From: Luis.Tito-de-Morais at ird.sn (Tito de Morais Luis)
Date: 10 Nov 2003 09:50:44 +0000
Subject: [R] position of given values labels in coplot
Message-ID: <1068457840.24016.12.camel@rap06.ird.sn>

Hello dear listers,

I can't find a way to align the given values labels when using coplot.

The labels always appear like a stair. Is there a way to modify this ?

I searched the help and archives but was unable to find out.

Any help would be much appreciated,

Tito

-- 
L. Tito de Morais
      UR RAP
   IRD de Dakar
      BP 1386
       Dakar
      S?n?gal

T?l.: + 221 849 33 31
Fax: +221 832 16 75
Courriel: tito at ird.sn



From ripley at stats.ox.ac.uk  Mon Nov 10 11:10:46 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 10:10:46 +0000 (GMT)
Subject: [R] weird behaviour of eigen() (actual example)
In-Reply-To: <3FAF58DA.EF5A51F9@ysbl.york.ac.uk>
Message-ID: <Pine.LNX.4.44.0311101005010.25387-100000@gannet.stats>

That is not a symmetric matrix so the eigenvalues are potentially complex 
and are sorted by modulus.  There's an ambiguity in the description for 
that case.

In all cases the eigenvectors are in the same order as the eigenvalues.

On Mon, 10 Nov 2003, Karim Elsawy wrote:

> Hi Thomas, 
> the matrix V , which produced the anomelous order,is attached as a text
> file,
> V<-matrix(scan("V.dat"),ncol=40,byrow=T)
> eigen(V)$values
> 
> best regards
> karim
> 
> Martin Maechler wrote:
> > 
> > >>>>> "Karim" == Karim Elsawy <elsawy at ysbl.york.ac.uk>
> > >>>>>     on Mon, 10 Nov 2003 08:34:07 +0000 writes:
> > 
> >     Karim> Hi Thomas, the matrix V , which produced the
> >     Karim> anomelous order,is attached as an R object,
> > 
> > and it wasn't :
> > Most binary attachments are *not* allowed on our mailing lists
> > (for several reasons I'd rather not discuss on R-help)
> > and the mailman software silently drops them.
> > Either send these only to individuals, give the R code to
> > generate them, give an URL (ftp://.. or http://.. ) where people
> > can get it; post the result of  dput(...), or if you must, use plain/text
> > attachments e.g. from save(..., ascii=TRUE).
> > 
> > Martin Maechler <maechler at stat.math.ethz.ch>    http://stat.ethz.ch/~maechler/
> > Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
> > ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
> > phone: x-41-1-632-3408          fax: ...-1228                   <><

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon Nov 10 11:40:33 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Nov 2003 11:40:33 +0100
Subject: [R] weird behaviour of eigen() (actual example)
In-Reply-To: <Pine.LNX.4.44.0311101005010.25387-100000@gannet.stats>
References: <Pine.LNX.4.44.0311101005010.25387-100000@gannet.stats>
Message-ID: <x2he1cwlpa.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> That is not a symmetric matrix so the eigenvalues are potentially complex 
> and are sorted by modulus.  There's an ambiguity in the description for 
> that case.

Ah-ha! Thanks, Brian. 

I wonder if we should switch to sorting by absolute value in the real
case too, for consistency, and maybe also to avoid silly mistakes
caused by people expecting that the first/last eigenvalues are the
important ones.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pburns at pburns.seanet.com  Mon Nov 10 11:52:21 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 10 Nov 2003 10:52:21 +0000
Subject: [R] weird behaviour of eigen() (actual example)
References: <Pine.LNX.4.44.0311101005010.25387-100000@gannet.stats>
	<x2he1cwlpa.fsf@biostat.ku.dk>
Message-ID: <3FAF6DE5.4000503@pburns.seanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031110/3e1bbb57/attachment.pl

From kgk at pharm.auth.gr  Mon Nov 10 11:57:40 2003
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Mon, 10 Nov 2003 12:57:40 +0200
Subject: [R] model constant relations
Message-ID: <010c01c3a779$774be5d0$5e05cf9b@lakonia>

Dear list members,

 this is not an R question and forgive me for using the list for irrelevant
questions, but this is the only place I know where I can find some good
statisticians and I need an expert opinion.
There is this power law kinetic model of the form:
M=kt^n
where t is the time, M is the fraction of drug released, k is the rate
constant and n is an exponent related to the mechanism of release.
I fit this equation to 100 different datasets (by linear regression, after
logarithmic transformation) and then I plot n vs k. What I get is a decay
pattern of n as k increases.
QUESTION 1: Is some theoretical reason for this kind of relation. Is it
expected? Is it "normal" that model parameters (intercept and slope in the
linearised form) should be correlated?
QUESTION 2: Is it theoretically sound to compare the magnitude of constants,
k, that correspond to different exponents, n? (k has dimensions of [time]^-n
so we are comparing quantities with different physical interpretation).
Practically speaking, does k=0.2 with an exponent n=0.5 mean that we have
the same release rate as in the case of k=0.2 but with n=1.0?

Thank you very much in advance.

 Kyriakos.



---



From luke.keele at politics-and-international-relations.oxford.ac.uk  Mon Nov 10 12:16:42 2003
From: luke.keele at politics-and-international-relations.oxford.ac.uk (Luke Keele)
Date: Mon, 10 Nov 2003 11:16:42 -0000
Subject: [R] (no subject)
Message-ID: <000001c3a77c$1e80b2c0$903701a3@politics.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031110/c7bc486a/attachment.pl

From gindo.tampubolon at man.ac.uk  Mon Nov 10 12:46:56 2003
From: gindo.tampubolon at man.ac.uk (Gindo Tampubolon)
Date: Mon, 10 Nov 2003 11:46:56 +0000
Subject: [R] Copula functions in R? 
In-Reply-To: <200311081109.hA8B1sQF024055@hypatia.math.ethz.ch>
Message-ID: <E1AJAVT-0004tH-Fz@serenity.mcc.ac.uk>

Dear Thomas,

Try Jim Lindsey's R code: http://alpha.luc.ac.be/~jlindsey/

HTH

> Hello
> 
> 
> I am writing to you regarding your interest in Copula/copulae and it?s
> usage. I am currently studying Copula for my Master thesis and also
> therefore  have a large interest in it. Now I am looking for
> information regarding copula as well as Copula and "R". Code,
> information how to calculate or anything would be appreciated!
> 
> 
> Since there seem to be little information regarding this matter I
> would appreciate if you could inform me where to find or attach any
> code available.
> 
> Thank you in advance
> 
> 
> Thomas Holm
> 


Dr. Gindo Tampubolon
gindo.tampubolon at man.ac.uk
International Data Service - 
Economic and Social Data Services (Funded by ESRC & JISC)
- and -
Department of Sociology
University of Manchester



From ripley at stats.ox.ac.uk  Mon Nov 10 13:44:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 12:44:19 +0000 (GMT)
Subject: [R] (no subject)
In-Reply-To: <000001c3a77c$1e80b2c0$903701a3@politics.ox.ac.uk>
Message-ID: <Pine.LNX.4.44.0311101239050.25794-100000@gannet.stats>

Using split.screen should enable you to go back to earlier plots, with the
coordinate system you used.  I was able to amend the example of
split.screen to identify on the first plot, for example.  As far as I 
recall this works imperfectly with log axes.

On Mon, 10 Nov 2003, Luke Keele wrote:

> I want to use the identify command when I have multiple plots on the
> same page.  

> For example if I use:
> par(mfrows=c(2,1))

(mfrow, I presume)

> and then:
> 
> plot(x1,y1)
> 
> plot(x2,y2)
> 
> I get two plots on the same page, but if I use identify after this plot
> set-up it can't find the data points.  I need someway to reference which
> plot I want to identify as far as I can tell.  If I  just do one plot at
> a time identify works fine.  Is there any other way to just label all
> the data points?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Mon Nov 10 14:08:28 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 10 Nov 2003 05:08:28 -0800
Subject: [R] model constant relations
In-Reply-To: <010c01c3a779$774be5d0$5e05cf9b@lakonia>
References: <010c01c3a779$774be5d0$5e05cf9b@lakonia>
Message-ID: <3FAF8DCC.2090405@pdf.com>

     Have you looked at the correlation of the parameter estimates? 

      In S-Plus, this is automatically produced by summary(lm(...)).  
There is probably a simple, elegant way to get this in R, but I don't 
know it.  Therefore, I produced it as follows: 

 > DF <- data.frame(x=1:12, y=rep(1:6, each=2))
 > fit <- lm(y~x, DF)
 > sumfit <- summary(fit)
 > cov.fit <- sumfit$cov.unscaled
 > seb <- sqrt(diag(cov.fit))
 > cov.fit / outer(seb, seb)
            (Intercept)         x
(Intercept)    1.000000 -0.883176
x             -0.883176  1.000000

I developed this by looking at attributes(fit), then attributes(sumfit), 
etc. 

Is this helpful?
spencer graves

Kyriakos Kachrimanis wrote:

>Dear list members,
>
> this is not an R question and forgive me for using the list for irrelevant
>questions, but this is the only place I know where I can find some good
>statisticians and I need an expert opinion.
>There is this power law kinetic model of the form:
>M=kt^n
>where t is the time, M is the fraction of drug released, k is the rate
>constant and n is an exponent related to the mechanism of release.
>I fit this equation to 100 different datasets (by linear regression, after
>logarithmic transformation) and then I plot n vs k. What I get is a decay
>pattern of n as k increases.
>QUESTION 1: Is some theoretical reason for this kind of relation. Is it
>expected? Is it "normal" that model parameters (intercept and slope in the
>linearised form) should be correlated?
>QUESTION 2: Is it theoretically sound to compare the magnitude of constants,
>k, that correspond to different exponents, n? (k has dimensions of [time]^-n
>so we are comparing quantities with different physical interpretation).
>Practically speaking, does k=0.2 with an exponent n=0.5 mean that we have
>the same release rate as in the case of k=0.2 but with n=1.0?
>
>Thank you very much in advance.
>
> Kyriakos.
>
>
>
>---
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Nov 10 14:15:42 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 10 Nov 2003 14:15:42 +0100 (CET)
Subject: [R] criterion for variable selection in LDA
In-Reply-To: <1068455068.1161.19.camel@christophl>
References: <1068455068.1161.19.camel@christophl>
Message-ID: <Pine.LNX.4.51.0311101407380.2754@artemis.imbe.med.uni-erlangen.de>

On Mon, 10 Nov 2003, Christoph Lehmann wrote:

> Hi
> Since a stepwise procedure for variable selection (as e.g. in SPSS) for
> a LDA is not implemented in R and anyway I cannot be sure, that all the
> required assumptions for e.g. a procedure using a statistic based on
> wilks' lambda, hold (such as normality and variance homogeneity) I would
> like to ask you, what you would recommend me:
>
> shall I e.g. define a criterion such as the error-rate stemming from a
> leaving-one-out cross-validation and then write my own procedure of
> including/removing variables?
>
> or what would be the golden standard for such a case (my "case" is that
> I have 2 groups (n1=30, n2=15, number of potential variables: 37, no
> equal variance in the two groups))
>

Since you suffer a dimensionality problem, you should consider
discriminant analysis methods that can deal with it. If you are forced to
use a linear discriminant analysis, you can reduce the dimensionality by
computing appropriate data-driven linear scores of the inputs. The
idea is described in

@article{multivaria:1998,
   key       = {63},
   author    = {J\"urgen L\"auter and Ekkehard Glimm and Siegfried Kropf},
   title     = {Multivariate Tests Based on Left-Spherically Distributed
                Linear Scores},
   journal   = {The Annals of Statistics},
   pages     = {1972-1988},
   year      = {1998},
   volume    = {26},
   number    = {5},
   note      = {Correction: 1999, Vol. 27, p. 1441}
}

and, focusing on discriminant problems,

@book{stabile-mu:1992,
   key       = {337},
   author    = {J\"urgen L\"auter},
   title     = {Stabile multivariate {V}erfahren: {D}iskriminanzanalyse -
                {Regressionsanalyse} - {F}aktoranalyse},
   year      = {1992},
   publisher = {Akademie Verlag},
   address   = {Berlin}
}

and


@article{new-multiv:1996,
   key       = {66},
   author    = {J\"urgen L\"auter and Ekkehard Glimm and Siegfried Kropf},
   title     = {New Multivariate Tests for Data with an Inherent
                Structure},
   journal   = {Biometrical Journal},
   pages     = {5-23},
   year      = {1996},
   volume    = {38},
   number    = {1}
}

@book{hochdimens:2000,
   key       = {74},
   author    = {Siegfried Kropf},
   title     = {Hochdimensionale multivariate Verfahren in der
                medizinischen Statistik},
   year      = {2000},
   publisher = {Shaker Verlag},
   address   = {Aachen}
}

and the function `slda' (ipred package) implements it. If you are free to
choose the methodology, the packages `randomForest' and `gbm' may help...

Best,

Torsten


> many thanks
>
> cheers
>
> christoph
> --
> Christoph Lehmann <christoph.lehmann at gmx.ch>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ripley at stats.ox.ac.uk  Mon Nov 10 14:25:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 13:25:56 +0000 (GMT)
Subject: [R] model constant relations
In-Reply-To: <3FAF8DCC.2090405@pdf.com>
Message-ID: <Pine.LNX.4.44.0311101324210.25870-100000@gannet.stats>

On Mon, 10 Nov 2003, Spencer Graves wrote:

>      Have you looked at the correlation of the parameter estimates? 
> 
>       In S-Plus, this is automatically produced by summary(lm(...)).  
> There is probably a simple, elegant way to get this in R, but I don't 
> know it.  Therefore, I produced it as follows: 

summary(fit, cor=TRUE) : the default is different between R and S 
(intentionally).

See also ?vcov.

>  > DF <- data.frame(x=1:12, y=rep(1:6, each=2))
>  > fit <- lm(y~x, DF)
>  > sumfit <- summary(fit)
>  > cov.fit <- sumfit$cov.unscaled
>  > seb <- sqrt(diag(cov.fit))
>  > cov.fit / outer(seb, seb)
>             (Intercept)         x
> (Intercept)    1.000000 -0.883176
> x             -0.883176  1.000000
> 
> I developed this by looking at attributes(fit), then attributes(sumfit), 
> etc. 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Nov 10 14:24:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 13:24:00 +0000 (GMT)
Subject: [R] weird behaviour of eigen() (actual example)
In-Reply-To: <3FAF6DE5.4000503@pburns.seanet.com>
Message-ID: <Pine.LNX.4.44.0311101252340.25870-100000@gannet.stats>

I agree with Patrick that we should leave the symmetric case alone,
although I did notice that Splus 6.1 says

   values:  vector of nrow(x) eigenvalues in descending order of modulus.

but does sort the symmetric case by value and not modulus, so the code 
that Pat refers to is presuming the documentation to be wrong ....

The asymmetric case is both back-compatible (EISPACK=T) and compatible
with S, so I think the documentation should be clarified---I am about to
do that.

On Mon, 10 Nov 2003, Patrick Burns wrote:

> I think switching the sort order would probably
> break a fair amount of code, and it wouldn't
> necessarily be obvious that it had been broken.
> For example, I suspect that there is a fair amount
> of code that tests if all eigenvalues are positive by
> just looking at the last one.  
> 
> Anyway, consistency is the hobgoblin of small minds.
> 
> 
> Patrick Burns
> 
> Burns Statistics
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
> Peter Dalgaard wrote:
> 
> >Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> >
> >  
> >
> >>That is not a symmetric matrix so the eigenvalues are potentially complex 
> >>and are sorted by modulus.  There's an ambiguity in the description for 
> >>that case.
> >>    
> >>
> >
> >Ah-ha! Thanks, Brian. 
> >
> >I wonder if we should switch to sorting by absolute value in the real
> >case too, for consistency, and maybe also to avoid silly mistakes
> >caused by people expecting that the first/last eigenvalues are the
> >important ones.
> >
> >  
> >
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From luke at stat.uiowa.edu  Mon Nov 10 15:50:28 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 10 Nov 2003 08:50:28 -0600 (CST)
Subject: [R] signalCondition
In-Reply-To: <3FAD5D8F.10600@auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0311100843590.14925-100000@itasca.stat.uiowa.edu>

On Sun, 9 Nov 2003, Hadley Wickham wrote:

> Does signalCondition() only work within try-catch blocks?
> 
> I expected:
> 
> testSignal <- function() {
>     error <- simpleError("An error!")
>     signalCondition(error)
> }
> 
> to do the same thing as
> 
> testStop <- function() {
>     error <- simpleError("An error!")
>     stop(error)
> }
> 
> but testSignal returns NULL without throwing an error.  Have I 
> misunderstood something?

signalCondition does not throw an error it just runs handlers if any
are available.  If none are available or all the available ones are
calling handlers that return normally, then signalCondition will
return NULL.  Conceptually, signalCondition is a lower level mechainsm
on which stop and warning are built.  stop roughly corresponds to a
call to signalCondition followed by the defaul error handling code.
If a handler established by tryCatch is available, then
signalCondition will transfer control to that handler and the default
code is not reached.

Hope that helps,

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From rodrigo.abt at sii.cl  Mon Nov 10 17:01:41 2003
From: rodrigo.abt at sii.cl (Rodrigo Abt)
Date: Mon, 10 Nov 2003 13:01:41 -0300
Subject: [R] Memory issues..
Message-ID: <000001c3a7a3$ef13b5a0$fc011592@rodrigoabt>

Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. My
sample size is about 2965 and 3 factors:

year (5 levels), ssize (4 levels), condition (2 levels).

When I issue the following command:

>
lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,method
="ML")

I got the following error:

Error in logLik.lmeStructInt(lmeSt, lmePars) :
        Calloc could not allocate (65230 of 8) memory
In addition: Warning message:
Reached total allocation of 120Mb: see help(memory.size)

I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb processor.
My version of R is 1.7.1.

Thanks in advance,

Rodrigo Abt.
Department of Economic and Tributary Studies,
SII, Chile.



From christoph.lange at tuebingen.mpg.de  Mon Nov 10 17:06:17 2003
From: christoph.lange at tuebingen.mpg.de (Christoph Lange)
Date: Mon, 10 Nov 2003 17:06:17 +0100
Subject: [R] Finding the name ob an object
Message-ID: <20031110160615.GA21156@sesame.kyb.local>


Hi, all!

I want to give an object to a function and use the NAME of this object
inside the function to build new objects based on this name.

How do I get the name of an object if I don't pass a string containing
the name but the object itself?

Christoph.

-- 
Christoph Lange
MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|



From rxg218 at psu.edu  Mon Nov 10 17:14:41 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 10 Nov 2003 11:14:41 -0500
Subject: [R] attaching data to any object
Message-ID: <1068480880.5002.1.camel@ra.chem.psu.edu>

Hi,
  is the following possible - in a given session I make a lot of objects
and save when exiting. Usually I note down seperately what each object
is about. Is it possible to attach data to any object which would
essentially be a short note explaining the meaning of it?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
The Heineken Uncertainty Principle:
You can never be sure how many beers you had last night.



From spencer.graves at pdf.com  Mon Nov 10 17:15:45 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 10 Nov 2003 08:15:45 -0800
Subject: [R] model constant relations
In-Reply-To: <Pine.LNX.4.44.0311101324210.25870-100000@gannet.stats>
References: <Pine.LNX.4.44.0311101324210.25870-100000@gannet.stats>
Message-ID: <3FAFB9B0.9020308@pdf.com>

Thanks very much:  I typed "?summary.fit" when I meant to type 
"?summary.lm", which explains why I didn't find the "cor" argument.  
Thanks also for the reference to "?vcov".  I didn't see that in the "see 
also" section for either "lm" or "summary" or "summary.lm".  Might it be 
worth added? 

Thanks again,
spencer graves

Prof Brian Ripley wrote:

>On Mon, 10 Nov 2003, Spencer Graves wrote:
>
>  
>
>>     Have you looked at the correlation of the parameter estimates? 
>>
>>      In S-Plus, this is automatically produced by summary(lm(...)).  
>>There is probably a simple, elegant way to get this in R, but I don't 
>>know it.  Therefore, I produced it as follows: 
>>    
>>
>
>summary(fit, cor=TRUE) : the default is different between R and S 
>(intentionally).
>
>See also ?vcov.
>
>  
>
>> > DF <- data.frame(x=1:12, y=rep(1:6, each=2))
>> > fit <- lm(y~x, DF)
>> > sumfit <- summary(fit)
>> > cov.fit <- sumfit$cov.unscaled
>> > seb <- sqrt(diag(cov.fit))
>> > cov.fit / outer(seb, seb)
>>            (Intercept)         x
>>(Intercept)    1.000000 -0.883176
>>x             -0.883176  1.000000
>>
>>I developed this by looking at attributes(fit), then attributes(sumfit), 
>>etc. 
>>    
>>
>
>  
>



From spencer.graves at pdf.com  Mon Nov 10 17:18:01 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 10 Nov 2003 08:18:01 -0800
Subject: [R] Finding the name ob an object
In-Reply-To: <20031110160615.GA21156@sesame.kyb.local>
References: <20031110160615.GA21156@sesame.kyb.local>
Message-ID: <3FAFBA39.1060308@pdf.com>

 > f <- function(x)deparse(substitute(x))
 > f(pi)
[1] "pi"

answer the question?  spencer graves

Christoph Lange wrote:

>Hi, all!
>
>I want to give an object to a function and use the NAME of this object
>inside the function to build new objects based on this name.
>
>How do I get the name of an object if I don't pass a string containing
>the name but the object itself?
>
>Christoph.
>
>  
>



From Simon.Fear at synequanon.com  Mon Nov 10 17:14:27 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 10 Nov 2003 16:14:27 -0000
Subject: [R] Finding the name ob an object
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572D27558@synequanon01>

You probably want

deparse(substitute(object))

See ?substitute.

> -----Original Message-----
> From: Christoph Lange [mailto:christoph.lange at tuebingen.mpg.de]
> Sent: 10 November 2003 16:06
> To: R Help List
> Subject: [R] Finding the name ob an object
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> 
> Hi, all!
> 
> I want to give an object to a function and use the NAME of this object
> inside the function to build new objects based on this name.
> 
> How do I get the name of an object if I don't pass a string containing
> the name but the object itself?
> 
> Christoph.
> 
> -- 
> Christoph Lange
> MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
> Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From GPetris at uark.edu  Mon Nov 10 17:17:08 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Mon, 10 Nov 2003 10:17:08 -0600 (CST)
Subject: [R] Finding the name ob an object
In-Reply-To: <20031110160615.GA21156@sesame.kyb.local> (message from Christoph
	Lange on Mon, 10 Nov 2003 17:06:17 +0100)
References: <20031110160615.GA21156@sesame.kyb.local>
Message-ID: <200311101617.hAAGH8mb013277@definetti.uark.edu>


Look at the first lines of plot.default for an example of how to
extract the name of an argument.

HTH,
Giovanni

> Date: Mon, 10 Nov 2003 17:06:17 +0100
> From: Christoph Lange <christoph.lange at tuebingen.mpg.de>
> Sender: r-help-bounces at stat.math.ethz.ch
> Mail-followup-to: R Help List <r-help at stat.math.ethz.ch>
> Precedence: list
> User-Agent: Mutt/1.4.1i-nntp
> 
> 
> Hi, all!
> 
> I want to give an object to a function and use the NAME of this object
> inside the function to build new objects based on this name.
> 
> How do I get the name of an object if I don't pass a string containing
> the name but the object itself?
> 
> Christoph.
> 
> -- 
> Christoph Lange
> MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
> Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From rpeng at jhsph.edu  Mon Nov 10 17:21:40 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 10 Nov 2003 11:21:40 -0500
Subject: [R] Memory issues..
In-Reply-To: <000001c3a7a3$ef13b5a0$fc011592@rodrigoabt>
References: <000001c3a7a3$ef13b5a0$fc011592@rodrigoabt>
Message-ID: <3FAFBB14.20509@jhsph.edu>

The error says you don't have enough memory on your computer.   
Unfortunately, the only solution may be to buy more.

-roger

Rodrigo Abt wrote:

>Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. My
>sample size is about 2965 and 3 factors:
>
>year (5 levels), ssize (4 levels), condition (2 levels).
>
>When I issue the following command:
>
>  
>
>lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,method
>="ML")
>
>I got the following error:
>
>Error in logLik.lmeStructInt(lmeSt, lmePars) :
>        Calloc could not allocate (65230 of 8) memory
>In addition: Warning message:
>Reached total allocation of 120Mb: see help(memory.size)
>
>I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb processor.
>My version of R is 1.7.1.
>
>Thanks in advance,
>
>Rodrigo Abt.
>Department of Economic and Tributary Studies,
>SII, Chile.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>



From Simon.Fear at synequanon.com  Mon Nov 10 17:21:48 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 10 Nov 2003 16:21:48 -0000
Subject: [R] attaching data to any object
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572D27559@synequanon01>

See ?comment for a built-in method using S3 class attributes.

> -----Original Message-----
> From: Rajarshi Guha [mailto:rxg218 at psu.edu]
> Sent: 10 November 2003 16:15
> To: R
> Subject: [R] attaching data to any object
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> Hi,
>   is the following possible - in a given session I make a lot 
> of objects
> and save when exiting. Usually I note down seperately what each object
> is about. Is it possible to attach data to any object which would
> essentially be a short note explaining the meaning of it?
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> The Heineken Uncertainty Principle:
> You can never be sure how many beers you had last night.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From ligges at statistik.uni-dortmund.de  Mon Nov 10 17:27:22 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Nov 2003 17:27:22 +0100
Subject: [R] Finding the name ob an object
In-Reply-To: <20031110160615.GA21156@sesame.kyb.local>
References: <20031110160615.GA21156@sesame.kyb.local>
Message-ID: <3FAFBC6A.1030507@statistik.uni-dortmund.de>

Christoph Lange wrote:

> Hi, all!
> 
> I want to give an object to a function and use the NAME of this object
> inside the function to build new objects based on this name.
> 
> How do I get the name of an object if I don't pass a string containing
> the name but the object itself?

  deparse(substitute(x))

Uwe Ligges



From rxg218 at psu.edu  Mon Nov 10 17:28:56 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 10 Nov 2003 11:28:56 -0500
Subject: [R] shuffling a vector
Message-ID: <1068481736.5002.6.camel@ra.chem.psu.edu>

Hi,
  I'me trying to write  a function that will shuffle a vector. At the
moment I'm baically making a vector of randomized indices and then
making  a new vector from the original one using these random indices.

However, is there an alternative (more elegant) method to do this? I
tried help.search('shuffle') but it does'nt return anything relevant.

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------

Q: What is a dyslexic, agnostic, insomniac?
A: Someone who lays awake at night wondering if there really is a dog!



From ligges at statistik.uni-dortmund.de  Mon Nov 10 17:32:23 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Nov 2003 17:32:23 +0100
Subject: [R] attaching data to any object
In-Reply-To: <1068480880.5002.1.camel@ra.chem.psu.edu>
References: <1068480880.5002.1.camel@ra.chem.psu.edu>
Message-ID: <3FAFBD97.2020308@statistik.uni-dortmund.de>

Rajarshi Guha wrote:

> Hi,
>   is the following possible - in a given session I make a lot of objects
> and save when exiting. Usually I note down seperately what each object
> is about. Is it possible to attach data to any object which would
> essentially be a short note explaining the meaning of it?

You can add an attribute as in:

x <- 1:10
attributes(x) <- list(my.note = "This is a test")

but I think it is not really what you are going to do...

Uwe Ligges





> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> The Heineken Uncertainty Principle:
> You can never be sure how many beers you had last night.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Mon Nov 10 17:35:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 16:35:14 +0000 (GMT)
Subject: [R] Memory issues..
In-Reply-To: <000001c3a7a3$ef13b5a0$fc011592@rodrigoabt>
Message-ID: <Pine.LNX.4.44.0311101633060.32693-100000@gannet.stats>

Have you done what the message said?

On Mon, 10 Nov 2003, Rodrigo Abt wrote:

> Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. My
> sample size is about 2965 and 3 factors:
> 
> year (5 levels), ssize (4 levels), condition (2 levels).
> 
> When I issue the following command:
> 
> >
> lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,method
> ="ML")
> 
> I got the following error:
> 
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>         Calloc could not allocate (65230 of 8) memory
> In addition: Warning message:
> Reached total allocation of 120Mb: see help(memory.size)
> 
> I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb processor.
> My version of R is 1.7.1.

You probably need more memory, but you could try following the advice in 
the help page pointed to.  If you increase the memory allocation R will 
continue to run, albeit slowly.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From uli at biochem.dshs-koeln.de  Mon Nov 10 16:31:51 2003
From: uli at biochem.dshs-koeln.de (Ulrich Flenker)
Date: Mon, 10 Nov 2003 16:31:51 +0100 (CET)
Subject: [R] attaching data to any object
In-Reply-To: <1068480880.5002.1.camel@ra.chem.psu.edu>
Message-ID: <Pine.LNX.4.44.0311101622390.6960-100000@FILESERV.biochem.dshs-koeln.de>

On 10 Nov 2003, Rajarshi Guha wrote:

> Hi,
>   is the following possible - in a given session I make a lot of objects
> and save when exiting. Usually I note down seperately what each object
> is about. Is it possible to attach data to any object which would
> essentially be a short note explaining the meaning of it?
> 
> Thanks,
 

Rajarshi,

the following does what you want. I don't know whether its generally a 
good idea to do the documentation of your data this way.

> X <- data.frame(x=1:10,y=1:0)

> X
    y  x
1   1  1
2   2  2
3   3  3
4   4  4
5   5  5
6   6  6
7   7  7
8   8  8
9   9  9 
10 10 10

> attr(X,"note") <- " Rajarshi's dummy data"

> X
    x  y
1   1  1
2   2  2
3   3  3
4   4  4
5   5  5
6   6  6
7   7  7
8   8  8
9   9  9
10 10 10

> attr(X,"note")

[1] " Rajarshi's dummy data"




--
	Uli Flenker

	Institute of Biochemistry
	German Sport University Cologne
	Carl-Diem-Weg 6
	50933 Cologne

	Phone 0049/221/4982-506



From j.fernandez-galvez at reading.ac.uk  Mon Nov 10 17:36:00 2003
From: j.fernandez-galvez at reading.ac.uk (Jesus Fernandez Galvez)
Date: Mon, 10 Nov 2003 16:36:00 -0000
Subject: [R] animated plot 
Message-ID: <E1AJF1E-0004ll-00@vimb2.rdg.ac.uk>

Dear colleagues,

Is there any way of saving an animated plot with R? For instance, any format
that could be read by Microsoft windows media or whatever.

Cheers,

Jesus



From rxg218 at psu.edu  Mon Nov 10 17:39:29 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 10 Nov 2003 11:39:29 -0500
Subject: [R] attaching data to any object
In-Reply-To: <3FAFBD97.2020308@statistik.uni-dortmund.de>
References: <1068480880.5002.1.camel@ra.chem.psu.edu>
	<3FAFBD97.2020308@statistik.uni-dortmund.de>
Message-ID: <1068482369.5002.8.camel@ra.chem.psu.edu>

On Mon, 2003-11-10 at 11:32, Uwe Ligges wrote:
> Rajarshi Guha wrote:
> 
> > Hi,
> >   is the following possible - in a given session I make a lot of objects
> > and save when exiting. Usually I note down seperately what each object
> > is about. Is it possible to attach data to any object which would
> > essentially be a short note explaining the meaning of it?
> 
> You can add an attribute as in:
> 
> x <- 1:10
> attributes(x) <- list(my.note = "This is a test")
> 
> but I think it is not really what you are going to do...

The comment function does what I wanted

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A meeting is an event at which the minutes are kept and the hours are
lost.



From p.dalgaard at biostat.ku.dk  Mon Nov 10 17:50:45 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Nov 2003 17:50:45 +0100
Subject: [R] shuffling a vector
In-Reply-To: <1068481736.5002.6.camel@ra.chem.psu.edu>
References: <1068481736.5002.6.camel@ra.chem.psu.edu>
Message-ID: <x2ad74w4ka.fsf@biostat.ku.dk>

Rajarshi Guha <rxg218 at psu.edu> writes:

> Hi,
>   I'me trying to write  a function that will shuffle a vector. At the
> moment I'm baically making a vector of randomized indices and then
> making  a new vector from the original one using these random indices.
> 
> However, is there an alternative (more elegant) method to do this? I
> tried help.search('shuffle') but it does'nt return anything relevant.

sample(x,length(x))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Mon Nov 10 17:45:55 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Nov 2003 17:45:55 +0100
Subject: [R] shuffling a vector
In-Reply-To: <1068481736.5002.6.camel@ra.chem.psu.edu>
References: <1068481736.5002.6.camel@ra.chem.psu.edu>
Message-ID: <3FAFC0C3.7030202@statistik.uni-dortmund.de>

Rajarshi Guha wrote:

> Hi,
>   I'me trying to write  a function that will shuffle a vector. At the
> moment I'm baically making a vector of randomized indices and then
> making  a new vector from the original one using these random indices.
> 
> However, is there an alternative (more elegant) method to do this? I
> tried help.search('shuffle') but it does'nt return anything relevant.

  sample(x)

Uwe Ligges



From rajarshi at presidency.com  Mon Nov 10 17:46:35 2003
From: rajarshi at presidency.com (Rajarshi Guha)
Date: 10 Nov 2003 11:46:35 -0500
Subject: [R] shuffling a vector
In-Reply-To: <1068481736.5002.6.camel@ra.chem.psu.edu>
References: <1068481736.5002.6.camel@ra.chem.psu.edu>
Message-ID: <1068482794.5002.13.camel@ra.chem.psu.edu>

On Mon, 2003-11-10 at 11:28, Rajarshi Guha wrote:
> Hi,
>   I'me trying to write  a function that will shuffle a vector. At the
> moment I'm baically making a vector of randomized indices and then
> making  a new vector from the original one using these random indices.
> 
> However, is there an alternative (more elegant) method to do this? I
> tried help.search('shuffle') but it does'nt return anything relevant.

Seems I sent of the mail prematurely :-/
sample() allows me to get the randomzied indices

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A mathematician is a device for turning coffee into theorems.
-- P. Erdos



From zeileis at ci.tuwien.ac.at  Mon Nov 10 17:45:28 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Mon, 10 Nov 2003 17:45:28 +0100
Subject: [R] shuffling a vector
In-Reply-To: <1068481736.5002.6.camel@ra.chem.psu.edu>
References: <1068481736.5002.6.camel@ra.chem.psu.edu>
Message-ID: <200311101645.hAAGjSiP013276@thorin.ci.tuwien.ac.at>

On Monday 10 November 2003 17:28, Rajarshi Guha wrote:

> Hi,
>   I'me trying to write  a function that will shuffle a vector. At
> the moment I'm baically making a vector of randomized indices and
> then making  a new vector from the original one using these random
> indices.
>
> However, is there an alternative (more elegant) method to do this? I
> tried help.search('shuffle') but it does'nt return anything
> relevant.

Sampling is a more statistical expression for what you are trying to 
da and I guess something like

R> letters[1:5]
[1] "a" "b" "c" "d" "e"
R> sample(letters[1:5])
[1] "a" "c" "d" "e" "b"

is what you want.
Z


> Thanks,
>
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
>
> Q: What is a dyslexic, agnostic, insomniac?
> A: Someone who lays awake at night wondering if there really is a
> dog!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jmacdon at med.umich.edu  Mon Nov 10 17:47:25 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Mon, 10 Nov 2003 11:47:25 -0500
Subject: [R] shuffling a vector
Message-ID: <sfaf7ae2.089@med-gwia-02a.med.umich.edu>

This is probably what you want.

?sample

HTH,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Rajarshi Guha <rxg218 at psu.edu> 11/10/03 11:28AM >>>
Hi,
  I'me trying to write  a function that will shuffle a vector. At the
moment I'm baically making a vector of randomized indices and then
making  a new vector from the original one using these random indices.

However, is there an alternative (more elegant) method to do this? I
tried help.search('shuffle') but it does'nt return anything relevant.

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------

Q: What is a dyslexic, agnostic, insomniac?
A: Someone who lays awake at night wondering if there really is a dog!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ramasamya at gis.a-star.edu.sg  Mon Nov 10 17:46:02 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Tue, 11 Nov 2003 00:46:02 +0800
Subject: [R] shuffling a vector
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D56076004@BIONIC.biopolis.one-north.com>

help(sample)

	-----Original Message----- 
	From: r-help-bounces at stat.math.ethz.ch on behalf of Rajarshi Guha 
	Sent: Tue 11/11/2003 12:28 AM 
	To: R 
	Cc: 
	Subject: [R] shuffling a vector
	
	

	Hi,
	  I'me trying to write  a function that will shuffle a vector. At the
	moment I'm baically making a vector of randomized indices and then
	making  a new vector from the original one using these random indices.
	
	However, is there an alternative (more elegant) method to do this? I
	tried help.search('shuffle') but it does'nt return anything relevant.
	
	Thanks,
	
	-------------------------------------------------------------------
	Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
	GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
	-------------------------------------------------------------------
	
	Q: What is a dyslexic, agnostic, insomniac?
	A: Someone who lays awake at night wondering if there really is a dog!
	
	______________________________________________
	R-help at stat.math.ethz.ch mailing list
	https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From MSchwartz at medanalytics.com  Mon Nov 10 17:51:42 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 10 Nov 2003 10:51:42 -0600
Subject: [R] shuffling a vector
In-Reply-To: <1068481736.5002.6.camel@ra.chem.psu.edu>
References: <1068481736.5002.6.camel@ra.chem.psu.edu>
Message-ID: <1068483101.12485.4.camel@localhost.localdomain>

On Mon, 2003-11-10 at 10:28, Rajarshi Guha wrote:
> Hi,
>   I'me trying to write  a function that will shuffle a vector. At the
> moment I'm baically making a vector of randomized indices and then
> making  a new vector from the original one using these random indices.
> 
> However, is there an alternative (more elegant) method to do this? I
> tried help.search('shuffle') but it does'nt return anything relevant.
> 
> Thanks,


You might want to look at the permute() function in the 'gregmisc'
package.

Example:

> x <- 1:10
> permute(x)
 [1]  1  3  2  6  5  7 10  8  9  4

HTH,

Marc Schwartz



From GPetris at uark.edu  Mon Nov 10 17:56:24 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Mon, 10 Nov 2003 10:56:24 -0600 (CST)
Subject: [R] shuffling a vector
In-Reply-To: <1068481736.5002.6.camel@ra.chem.psu.edu> (message from Rajarshi
	Guha on Mon, 10 Nov 2003 11:28:56 -0500)
References: <1068481736.5002.6.camel@ra.chem.psu.edu>
Message-ID: <200311101656.hAAGuOhm013403@definetti.uark.edu>


?sample

> Date: Mon, 10 Nov 2003 11:28:56 -0500
> From: Rajarshi Guha <rxg218 at psu.edu>
> Sender: r-help-bounces at stat.math.ethz.ch
> Organization: 
> Precedence: list
> 
> Hi,
>   I'me trying to write  a function that will shuffle a vector. At the
> moment I'm baically making a vector of randomized indices and then
> making  a new vector from the original one using these random indices.
> 
> However, is there an alternative (more elegant) method to do this? I
> tried help.search('shuffle') but it does'nt return anything relevant.
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> 
> Q: What is a dyslexic, agnostic, insomniac?
> A: Someone who lays awake at night wondering if there really is a dog!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From MSchwartz at medanalytics.com  Mon Nov 10 17:57:17 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 10 Nov 2003 10:57:17 -0600
Subject: [R] shuffling a vector
In-Reply-To: <1068483101.12485.4.camel@localhost.localdomain>
References: <1068481736.5002.6.camel@ra.chem.psu.edu>
	<1068483101.12485.4.camel@localhost.localdomain>
Message-ID: <1068483437.12485.10.camel@localhost.localdomain>

On Mon, 2003-11-10 at 10:51, Marc Schwartz wrote:
> On Mon, 2003-11-10 at 10:28, Rajarshi Guha wrote:
> > Hi,
> >   I'me trying to write  a function that will shuffle a vector. At the
> > moment I'm baically making a vector of randomized indices and then
> > making  a new vector from the original one using these random indices.
> > 
> > However, is there an alternative (more elegant) method to do this? I
> > tried help.search('shuffle') but it does'nt return anything relevant.
> > 
> > Thanks,
> 
> 
> You might want to look at the permute() function in the 'gregmisc'
> package.
> 
> Example:
> 
> > x <- 1:10
> > permute(x)
>  [1]  1  3  2  6  5  7 10  8  9  4
> 
> HTH,
> 
> Marc Schwartz


A quick add:

Also the sample() function in the base package:

> sample(x)
 [1]  4 10  5  3  7  2  1  6  9  8

See ?sample for more information. sample() is also more flexible in
terms of options if you want more than just a permutation of the
original vector.

HTH,

Marc



From pjacklam at online.no  Mon Nov 10 18:29:58 2003
From: pjacklam at online.no (Peter J. Acklam)
Date: Mon, 10 Nov 2003 18:29:58 +0100
Subject: [R] shuffling a vector
Message-ID: <3FB1C7B3@epostleser.online.no>

rxg218 at psu.edu wrote:

> I'me trying to write  a function that will shuffle a vector.
> At the moment I'm baically making a vector of randomized indices
> and then making  a new vector from the original one using these
> random indices.

What's your definition of "elegant"?  :-)

Isn't this elegant enough?

   x[order(runif(length(x)))]

Peter

-- 
Peter J. Acklam - pjacklam at online.no - http://home.online.no/~pjacklam



From honggao at lsu.edu  Mon Nov 10 18:34:00 2003
From: honggao at lsu.edu (Honggao Liu)
Date: Mon, 10 Nov 2003 11:34:00 -0600
Subject: [R] make failed
Message-ID: <OF554DBCE9.C27F5AF7-ON86256DDA.005FA974@lsu.edu>





Dear R supports:
I am trying to install R-1.8.0 on an IBM p630 box (AIX 5.1) for a user.
When I try to run make after I run ./configure, I get the following error:
 # make
Target "R" is up to date.
make: 1254-002 Cannot find a rule to create target R from dependencies.
Stop.
make: 1254-004 The error code from the last command is 1.
Stop.

When I use GNU make "gmake", I got the following error:
# gmake
gmake[1]: Entering directory `/mnt/local/R/R-1.8.0/m4'
gmake[1]: Nothing to be done for `R'.
gmake[1]: Leaving directory `/mnt/local/R/R-1.8.0/m4'
gmake[1]: Entering directory `/mnt/local/R/R-1.8.0/tools'
gmake[1]: *** No rule to make target `R'.  Stop.
gmake[1]: Leaving directory `/mnt/local/R/R-1.8.0/tools'
gmake: *** [R] Error 1

Any suggestions and help will be appreciated.

Dr. Honggao Liu
Applications Consultant
High Performance Computing
Office of Computing Services
Louisiana State University
Tel: (225) 578-0235
Fax: (225) 578-6400
E-mail: honggao at lsu.edu



From mn216 at columbia.edu  Mon Nov 10 18:28:22 2003
From: mn216 at columbia.edu (Murad Nayal)
Date: Mon, 10 Nov 2003 12:28:22 -0500
Subject: [R] kmeans error (bug?)
References: <Pine.LNX.4.44.0311100812560.21158-100000@gannet.stats>
Message-ID: <3FAFCAB6.99540F4B@columbia.edu>




Prof Brian Ripley wrote:
> 
> This is not a bug.  It just means that the algorithm sometimes finds an
> empty cluster, and as you asked for 34 clusters and it had 33 or less it
> stops.
> 
> What to do in this situation is currently under discussion, but the advice
> given is good: try another set of initial centres.

I am running kmeans in a loop for a range of possible cluster numbers.
The error terminates the loop. is there a mechanism by which I can
'trap' the error so that I can rerun kmeans with another set of initial
centers and hence allow the loop to run to completion. something like
try {} catch() mechanism of C++ for example. A flag for kmeans that
would have it return say a NULL value rather than an error would also
help in this type of application.


In fact, I wonder if anyone can point me to research, or better still R
functions/package/recipe, that help in choosing the best number of
clusters for the data. What I have tried so far is to do a manova using
the clustering result from kmeans, plot the approximate F statistic
and/or the p-value and look for cluster numbers where a sharp increase
in F or -log(pvalue) occur. what I would like to do but don't know how
is to formally compare successive clustering models. I know you can
compare models using the R function anova. but anova does not seem to
work with mlm models?


> 
> Please do read the description of a bug in the R FAQ, and do not misuse
> the term to mean `something I do not understand'.

This wasn't really a declaration that this behavior is a bug, rather it
was a question of whether it is (hence the question mark). I guess what
I found somewhat confusing is that if kmeans was selecting data points
at random as the initial cluster centers then, at least initially, non
of these clusters would start out empty. It wasn't immediately clear how
could further refinement result in clusters becoming empty.

thanks for the feedback


> 
> On Mon, 10 Nov 2003, Murad Nayal wrote:
> 
> > I have been getting the following intermittent error from kmeans:
> >
> > >str(cavint.p.r)
> >  num [1:1967, 1:13] 0.691 0.123 0.388 0.268 0.485 ...
> >  - attr(*, "dimnames")=List of 2
> >   ..$ : chr [1:1967] "6" "49" "87" "102" ...
> >   ..$ : chr [1:13] "HYD" "NEG" "POS" "OXY" ...
> > > set.seed(34)
> > > kmeans(cavint.p.r,centers=34)
> > Error: empty cluster: try a better set of initial centers
> >
> > the seed being equal to the number of centers in this case is just a
> > coincidence. I've encountered the same error with or without setting the
> > seed at different numbers of clusters.
> >
> > there is nothing particularly unusual about cavint.p.r (no NAs, NULLs),
> > except maybe for the fact that the rows sum to 1.
> >
> > > sum(is.na(cavint.p.r))
> > [1] 0
> > > sum(is.nan(cavint.p.r))
> > [1] 0
> > >
> >
> > I thought kmeans should select initial centers from the data if not
> > given explicitly! any idea what might be going wrong?
> 
> And what makes you think it did not?
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Murad Nayal M.D. Ph.D.
Department of Biochemistry and Molecular Biophysics
College of Physicians and Surgeons of Columbia University
630 West 168th Street. New York, NY 10032
Tel: 212-305-6884	Fax: 212-305-6926



From kjetil at entelnet.bo  Mon Nov 10 19:01:26 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 10 Nov 2003 14:01:26 -0400
Subject: [R] Finding the name ob an object
In-Reply-To: <20031110160615.GA21156@sesame.kyb.local>
Message-ID: <3FAF9A36.30336.210F32@localhost>

On 10 Nov 2003 at 17:06, Christoph Lange wrote:

> test <- function(x){
+      return(substitute(x))}
> a <- 3
> test(a)
a


Kjetil Halvorsen

> 
> Hi, all!
> 
> I want to give an object to a function and use the NAME of this object
> inside the function to build new objects based on this name.
> 
> How do I get the name of an object if I don't pass a string containing
> the name but the object itself?
> 
> Christoph.
> 
> -- 
> Christoph Lange
> MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
> Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Mon Nov 10 19:01:26 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 10 Nov 2003 14:01:26 -0400
Subject: [R] attaching data to any object
In-Reply-To: <1068480880.5002.1.camel@ra.chem.psu.edu>
Message-ID: <3FAF9A36.32186.210EC4@localhost>

On 10 Nov 2003 at 11:14, Rajarshi Guha wrote:

The library Hmisc has a function comment()
doing this.

Kjetil Halvorsen

> Hi,
>   is the following possible - in a given session I make a lot of objects
> and save when exiting. Usually I note down seperately what each object
> is about. Is it possible to attach data to any object which would
> essentially be a short note explaining the meaning of it?
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> The Heineken Uncertainty Principle:
> You can never be sure how many beers you had last night.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Mon Nov 10 18:39:00 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 10 Nov 2003 12:39:00 -0500
Subject: [R] shuffling a vector
In-Reply-To: <1068481736.5002.6.camel@ra.chem.psu.edu>
Message-ID: <5.0.2.1.0.20031110123758.00b1ddd0@127.0.0.1>

Dear Rajarshi,

sample(x) will randomly permute the elements of x.

I hope that this helps,
  John

At 11:28 AM 11/10/2003 -0500, Rajarshi Guha wrote:
>Hi,
>   I'me trying to write  a function that will shuffle a vector. At the
>moment I'm baically making a vector of randomized indices and then
>making  a new vector from the original one using these random indices.
>
>However, is there an alternative (more elegant) method to do this? I
>tried help.search('shuffle') but it does'nt return anything relevant.
>
>Thanks,
>
>-------------------------------------------------------------------
>Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>-------------------------------------------------------------------

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From kjetil at entelnet.bo  Mon Nov 10 19:41:31 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 10 Nov 2003 14:41:31 -0400
Subject: [R] Memory issues..
In-Reply-To: <000001c3a7a3$ef13b5a0$fc011592@rodrigoabt>
Message-ID: <3FAFA39B.1055.139A6E@localhost>

On 10 Nov 2003 at 13:01, Rodrigo Abt wrote:

See?Memory
for how you can get R to use virtual memory.

Kjetil Halvorsen


> Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. My
> sample size is about 2965 and 3 factors:
> 
> year (5 levels), ssize (4 levels), condition (2 levels).
> 
> When I issue the following command:
> 
> >
> lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,method
> ="ML")
> 
> I got the following error:
> 
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>         Calloc could not allocate (65230 of 8) memory
> In addition: Warning message:
> Reached total allocation of 120Mb: see help(memory.size)
> 
> I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb processor.
> My version of R is 1.7.1.
> 
> Thanks in advance,
> 
> Rodrigo Abt.
> Department of Economic and Tributary Studies,
> SII, Chile.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mathieu.drapeau at bioneq.qc.ca  Tue Nov 11 01:05:17 2003
From: mathieu.drapeau at bioneq.qc.ca (Mathieu Drapeau)
Date: Mon, 10 Nov 2003 19:05:17 -0500
Subject: [R] textConnections so slow!
Message-ID: <3FB027BD.7070901@bioneq.qc.ca>

Is it normal that it takes a very long time to generate a connection 
object on a big character vector?

This takes a very long time to process:
lines <- readLines ("myBigFile.txt")
data <- scan(textConnection(lines), sep = "\t")

against this that is pretty short to process:
data <- scan("myBigFile.txt", sep = "\t")

Anyone has any clues how to efficiently do that because I need to use a 
textConnection on a big vector?

Thank you,
Mathieu



From hb at maths.lth.se  Mon Nov 10 20:44:56 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 10 Nov 2003 20:44:56 +0100
Subject: [R] textConnections so slow!
In-Reply-To: <3FB027BD.7070901@bioneq.qc.ca>
Message-ID: <000801c3a7c3$1e926dc0$e502eb82@maths.lth.se>

Hi. I haven't looked at the source code for textConnection(), but I am
confident that the authors have done a good job, which makes me believe
that you're running out of RAM-memory and that you're starting to swap.
>From ?textConnection:

 "An input text connection is opened and the character vector is
  copied at time the connection object is created, and `close'
  destroys the copy."

Thus, in your code

 lines <- readLines("myBigFile.txt")
 data <- scan(textConnection(lines), sep = "\t")

you use approx. 2*object.size(lines) bytes (ignoring object.size(data)).
Try

 lines <- readLines("myBigFile.txt")
 lines <- textConnection(lines)
 gc() # maybe it helps to call the garbage collector here?
 data <- scan(lines, sep = "\t")

which should use approx object.size(lines) bytes. So if you're swapping,
then scan()-ing from a (temporary) file may do better. 

Moreover and more of a general suggestion, when using scan() and
read.table() you can help R to save memory by specifying the 'what' and
'colClasses' arguments, respectively.

Could this be it?

Henrik Bengtsson


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mathieu Drapeau
> Sent: den 11 november 2003 01:05
> To: r-help at stat.math.ethz.ch
> Subject: [R] textConnections so slow!
> 
> 
> Is it normal that it takes a very long time to generate a connection 
> object on a big character vector?
> 
> This takes a very long time to process:
> lines <- readLines ("myBigFile.txt")
> data <- scan(textConnection(lines), sep = "\t")
> 
> against this that is pretty short to process:
> data <- scan("myBigFile.txt", sep = "\t")
> 
> Anyone has any clues how to efficiently do that because I 
> need to use a 
> textConnection on a big vector?
> 
> Thank you,
> Mathieu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> 
>



From ripley at stats.ox.ac.uk  Mon Nov 10 20:45:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Nov 2003 19:45:26 +0000 (GMT)
Subject: [R] textConnections so slow!
In-Reply-To: <3FB027BD.7070901@bioneq.qc.ca>
Message-ID: <Pine.LNX.4.44.0311101943200.709-100000@gannet.stats>

On Mon, 10 Nov 2003, Mathieu Drapeau wrote:

> Is it normal that it takes a very long time to generate a connection 
> object on a big character vector?

Yes.

> This takes a very long time to process:
> lines <- readLines ("myBigFile.txt")
> data <- scan(textConnection(lines), sep = "\t")
> 
> against this that is pretty short to process:
> data <- scan("myBigFile.txt", sep = "\t")
> 
> Anyone has any clues how to efficiently do that because I need to use a 
> textConnection on a big vector?

Why?  There are better ways, even described on the help page!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Mon Nov 10 21:01:35 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 11 Nov 2003 09:01:35 +1300
Subject: [R] kmeans error (bug?)
In-Reply-To: <3FAFCAB6.99540F4B@columbia.edu>
References: <Pine.LNX.4.44.0311100812560.21158-100000@gannet.stats>
	<3FAFCAB6.99540F4B@columbia.edu>
Message-ID: <3FAFEE9F.6020509@indigoindustrial.co.nz>

Murad Nayal wrote:
> I am running kmeans in a loop for a range of possible cluster numbers.
> The error terminates the loop. is there a mechanism by which I can
> 'trap' the error so that I can rerun kmeans with another set of initial
> centers and hence allow the loop to run to completion. something like
> try {} catch() mechanism of C++ for example.

For R version < 1.8.0, ?try
For R version >= 1.8.0, see also ?tryCatch

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From pburns at pburns.seanet.com  Mon Nov 10 21:28:18 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 10 Nov 2003 20:28:18 +0000
Subject: [R] attaching data to any object
References: <1068480880.5002.1.camel@ra.chem.psu.edu>
	<3FAFBD97.2020308@statistik.uni-dortmund.de>
Message-ID: <3FAFF4E2.3010602@pburns.seanet.com>

An alternative that might alleviate Uwe's scepticism:

Many functions such as the modelling functions have
a "call" component or attribute which is the result of

match.call()

within the function.  This makes the resulting object essentially
self-documenting.  I find it easier to write functions with the
returned object including "call" than to _accurately_ document
objects by hand.

In some settings the "call" can cause problems since it is a
language object.  This can be solved by using

deparse(match.call())

in place of the raw match.call call.


Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Uwe Ligges wrote:

> Rajarshi Guha wrote:
>
>> Hi,
>>   is the following possible - in a given session I make a lot of objects
>> and save when exiting. Usually I note down seperately what each object
>> is about. Is it possible to attach data to any object which would
>> essentially be a short note explaining the meaning of it?
>
>
> You can add an attribute as in:
>
> x <- 1:10
> attributes(x) <- list(my.note = "This is a test")
>
> but I think it is not really what you are going to do...
>
> Uwe Ligges
>
>
>
>
>
>> Thanks,
>>
>> -------------------------------------------------------------------
>> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>> -------------------------------------------------------------------
>> The Heineken Uncertainty Principle:
>> You can never be sure how many beers you had last night.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ggrothendieck at myway.com  Mon Nov 10 22:11:39 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 10 Nov 2003 16:11:39 -0500 (EST)
Subject: [R] textConnections so slow!
Message-ID: <20031110211139.D70053960@mprdmxin.myway.com>


 --- On Mon 11/10, Mathieu Drapeau < mathieu.drapeau at bioneq.qc.ca > wrote:
> Is it normal that it takes a very long time to generate a 
> connection object on a big character vector?

If the reason you need a text connection is that you are locating
your data via a tag like this:

   lines <- readLines( "input.txt" )    # lines is a vector of lines
   g <- grep( "start", lines )   # position of tag
   mydata <- read.table( textConnection(lines), skip=g[1], head=TRUE )

then you could simply read your data twice like this:

   lines <- readLines( "input.txt" )    # lines is a vector of lines
   g <- grep( "start", lines )   # position of tag
   mydata <- read.table( "input.txt", skip=g[1], head=TRUE )



From snorton at surromed.com  Tue Nov 11 00:08:04 2003
From: snorton at surromed.com (Scott Norton)
Date: Mon, 10 Nov 2003 15:08:04 -0800
Subject: [R] boot package question: sampling on factor, not row
Message-ID: <9D33C6169B1FDB419767356B8A8FEDB5082CAF@lynx.corp.surromed.com>

Hi all:

      I've been looking at the boot package to "bootstrap" sample my data in a particular way.  I haven't figured out how to set this up using the boot() command and thus have resorted to trying to write my own script (although I'd prefer if I could get boot() to work for this problem!)

The dataset is set up in the following way:

ix(factor)  value
1		5.73
1		6.99
1		0.32
1		4.64
1		8.39
2		8.47
2		1.04
2		0.73
2		0.29
3		6.82
3		8.81
3		1.33
3		9.17
3		9.84
4		8.57
4		5.04
4		7.18
4		4.54
4		4.37
5		7.36
5		4.97
5		2.66

What I would like to do is repeatedly sample the ix (a factor), not the individual rows.  For example, say I wanted to repeatedly sample (at a sample size of 3) the ix value - 
e.g. 1,3,5 then average the "value"s within those factors and then lets say take the median across this each.   
So for a random sample of (1,3,5) that would be: median(c(mean(c(5.73,6.99,0.32,4.64,8.39)), mean(6.82,8.81,1.33,9.17,9.84), mean(7.36,4.97,2.66)))
Then repeat this over combinations of 3 ix factors e.g. (1,2,3), (1,1,4), etc...

Is it possible to subsample a factor using boot() and then use that sample of factors to access rows, rather than directly sample rows?

Thanks!!!
-Scott



From Paul.Sorenson at vision-bio.com  Tue Nov 11 00:10:50 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Tue, 11 Nov 2003 10:10:50 +1100
Subject: [R] relationship between two discrete variables
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C62739C9@ewok.vsl.com.au>

I want to investigate possible relationships between two discrete variables.  I have tried a few things but figured you guys might be able to point me at some purpose built functions.

Our scientists score results of tests which are performed in lets say, 8 positions.  The scores are assigned a value of 1,2,3 or 4.  I want to know if there is a correlation between the test results and the position.  The scientists have a feeling that position 1 does not score as high as the others.

Not all 8 positions are always used, so the frequency of all test results can be substantially biased towards the first position.  Here is an example dataset (not very biased) resulting from table(result, position):

     1  2  3  4  5  6  7  8
  0  3  3  2  2  0  3  3  0
  1 11  4  6  7  7  3  3  5
  2 38 37 32 38 31 21 23 27
  3 51 66 54 66 57 37 58 56
  4  3  1  3  0  1  0  1  1

Because the test results are highly quantized, the boxplots I tried all looked pretty much the same.

The bias means that stacked barplots aren't that useful for visualising the data.  With a bit of data processing I guess I could normalise the total frequencies of each test position.

I also tried a correlation between the two variables.  The answer is non-zero but I am not sure that any relationship between the two variables would be monotonic (BTW cor() give me the correlation coefficient, how do I get the "confidence" of the coefficient?)

Maybe I am overlooking the obvious, like just averaging the scores.

cheers



From kjetil at entelnet.bo  Tue Nov 11 00:22:33 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 10 Nov 2003 19:22:33 -0400
Subject: [R] Reading an upper triangular matrix
Message-ID: <3FAFE579.17667.136ECA@localhost>

Hola!

I have data in the form of a symmetric distance matrix, in the file I 
have recorded only the upper triangular part, with diagonal. The 
matrix is 21x21, and the file have row and col names, and some other 
information. I am trying to read with the following code (I tried 
many variations on it, but all give the same error). The items in the 
data file is delimited by white space. 

(Part of) script to read:

myfile <- file("Paises.dat", open="r")
               # opens a connection which stays open until closed by 
close(myfile)
name <- readLines(con=myfile, n=1)
varnames <- scan( myfile, what=character(0), nlines=1 )
 
stopifnot( length(varnames) == 21 )
Paises <- matrix(0, 21, 21)
colnames(Paises) <- varnames
rownames(Paises) <- varnames
for (i in 1:21) {
    temp <- scan(myfile, what=list("a", rep(0,22-i) ), nlines=1, 
sep="")
    Paises[i, i:21] <- temp[[2]]
  }

I get the following result:

> source("Paises.R", echo=TRUE)

> myfile <- file("Paises.dat", open = "r")

> name <- readLines(con = myfile, n = 1)

> varnames <- scan(myfile, what = character(0), nlines = 1)
Read 21 items

> stopifnot(length(varnames) == 21)

> Paises <- matrix(0, 21, 21)

> colnames(Paises) <- varnames

> rownames(Paises) <- varnames

> for (i in 1:21) {
    temp <- scan(myfile, what = list("a", rep(0, 22 - i)), nlines = 
1, 
        sep = "")
    Paises[i, i:21] <- temp[[2]]
}
Read 11 records
Error in "[<-"(`*tmp*`, i, i:21, value = temp[[2]]) : 
        number of items to replace is not a multiple of replacement 
length
> i
[1] 1
> temp
[[1]]
 [1] "Bolivia" "1"       "2"       "3"       "2"       "4"       "4"  
    
 [8] "6"       "6"       "8"       "8"      

[[2]]
 [1] 0 2 3 2 3 5 5 6 6 7 8

> 

While I am asking only for one character string, multiple items are 
read as strings! What is happening?

Kjetil Halvorsen



From rossini at blindglobe.net  Tue Nov 11 01:46:22 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 10 Nov 2003 16:46:22 -0800
Subject: [R] sample size/power calc packages
Message-ID: <85fzgvenq9.fsf@blindglobe.net>


For various reasons, I spent part of my time today looking at sample
size and power calculation tools (don't ask, don't tell...).  This
seems to be one area that R is incredibly weak in (well, nearly all
stat packages, except perhaps specialized tools and SAS); sure, there
are a number of functions in various packages:

          base, statmod, Hmisc

Have I missed something?  (I would've expected at least one sequential
computation, or non-standard design, but apparently there are none, or
I missed it).  

I'd appreciate hearing about work that I've missed...

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From loraine at loraine.net  Tue Nov 11 02:11:30 2003
From: loraine at loraine.net (Ann Loraine)
Date: Mon, 10 Nov 2003 17:11:30 -0800
Subject: [R] predict.lm with (logical) NA vector
In-Reply-To: <3FAF4748.2080208@geog.uu.nl>
Message-ID: <FB72D51F-13E3-11D8-ADE2-000A959EED5E@loraine.net>

Hello,

How do I tell R not to place a label on an axis when using the "plot" 
command?

Thank you,

Ann Loraine



From spencer.graves at pdf.com  Tue Nov 11 02:20:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 10 Nov 2003 17:20:02 -0800
Subject: [R] plot w/o axes [was: predict.lm with (logical) NA vector]
In-Reply-To: <FB72D51F-13E3-11D8-ADE2-000A959EED5E@loraine.net>
References: <FB72D51F-13E3-11D8-ADE2-000A959EED5E@loraine.net>
Message-ID: <3FB03942.4050908@pdf.com>

e.g.: 

plot(1:2, axes=F)
axis(1)

spencer graves

Ann Loraine wrote:

> Hello,
>
> How do I tell R not to place a label on an axis when using the "plot" 
> command?
>
> Thank you,
>
> Ann Loraine
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Tue Nov 11 03:34:14 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 10 Nov 2003 21:34:14 -0500 (EST)
Subject: [R] plot w/o axes [was: predict.lm with (logical) NA vector]
In-Reply-To: <3FB03942.4050908@pdf.com>
References: <FB72D51F-13E3-11D8-ADE2-000A959EED5E@loraine.net>
	<3FB03942.4050908@pdf.com>
Message-ID: <Pine.SOL.4.58.0311102127480.11597@zektor.gpcc.itd.umich.edu>

Ann  -

Maybe you are looking for
	 	plot( ..., xlab="", ylab="")
followed by	title(xlab="the real x axis label")
	 	title(ylab="the real y axis label", mgp=c(2.5,0.5,0))

This is a construction that I use all, all, all the time.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 10 Nov 2003, Ann Loraine wrote:

> How do I tell R not to place a label on an axis when using the "plot"
> command?



From tblackw at umich.edu  Tue Nov 11 04:43:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 10 Nov 2003 22:43:04 -0500 (EST)
Subject: [R] boot package question: sampling on factor, not row
In-Reply-To: <9D33C6169B1FDB419767356B8A8FEDB5082CAF@lynx.corp.surromed.com>
References: <9D33C6169B1FDB419767356B8A8FEDB5082CAF@lynx.corp.surromed.com>
Message-ID: <Pine.SOL.4.58.0311102137270.11597@zektor.gpcc.itd.umich.edu>

Scott  -

The second argument to  boot(),  called 'statistic', can be
any user-written function you want to cook up, with additional
arguments being passed to it through the '...' mechanism after
all of the named arguments.  (See: `R-intro `Writing your own
functions `The ellipsis argument  for details.)

To carry out your example, I would do something like the following:
(not tested ! use at your own risk.)

my.summary <- function(data, groups, ix, value)
     {	median(aggregate(value, list(ix), mean)[groups[seq(3)]])   }
library("boot")
result <- boot(seq(along=levels(ix)), my.summary, 10000, ix=ix, value=value)

You will note that what  boot()  thinks is the "data" in the
example here is only a vector of sequential integers the same
length as  levels(ix).  This data is ignored in  my.summary()
and the two columns which you show as "ix" and "value" are used
instead.  Furthermore, unless I misunderstand your example, the
mean within each level of "ix" is invariant to which three levels
have been chosen for this particular bootstrap replicate.
Therefore, you could call  aggregate()  only once rather than
10000 times, if you rewrite the function  my.summary()  to use
the result of  aggregate()  rather than call it afresh on every
iteration.

I've given you the reference for the '...' mechanism, because
that reference is almost impossible to find using  help.search().
For the rest of the functions I've used, you're on your own to
look up their help pages.

I *will* comment that I can't see why this particular statistic
is of interest . . . but, I assume you have your own reasons.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 10 Nov 2003, Scott Norton wrote:

> Hi all:
>
> I've been looking at the boot package to "bootstrap" sample
> my data in a particular way.  I haven't figured out how to
> set this up using the boot() command and thus have resorted
> to trying to write my own script (although I'd prefer if I
> could get boot() to work for this problem!)
>
> The dataset is set up in the following way:
>
> ix(factor)  value
> 1		5.73
> 1		6.99
> 1		0.32
> 1		4.64
> 1		8.39
> 2		8.47
> 2		1.04
> 2		0.73
> 2		0.29
> 3		6.82
> 3		8.81
> 3		1.33
> 3		9.17
> 3		9.84
> 4		8.57
> 4		5.04
> 4		7.18
> 4		4.54
> 4		4.37
> 5		7.36
> 5		4.97
> 5		2.66
>
> What I would like to do is repeatedly sample the ix (a factor),
> not the individual rows.  For example, say I wanted to repeatedly
> sample (at a sample size of 3) the ix value - e.g. 1,3,5 - then
> average the "value"s within those factors and then lets say take
> the median across this each.
>
> So for a random sample of (1,3,5) that would be:
>
>    median(c(mean(c(5.73,6.99,0.32,4.64,8.39)),
>             mean(6.82,8.81,1.33,9.17,9.84),
>             mean(7.36,4.97,2.66)))
>
> Then repeat this over combinations of 3 ix factors e.g. (1,2,3),
> (1,1,4), etc...
>
> Is it possible to subsample a factor using boot() and then use
> that sample of factors to access rows, rather than directly sample
> rows?
>
> Thanks!!!
> -Scott
>



From tblackw at umich.edu  Tue Nov 11 04:48:43 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 10 Nov 2003 22:48:43 -0500 (EST)
Subject: [R] relationship between two discrete variables
In-Reply-To: <5E06BFED29594F4C9C5EBE230DE320C62739C9@ewok.vsl.com.au>
References: <5E06BFED29594F4C9C5EBE230DE320C62739C9@ewok.vsl.com.au>
Message-ID: <Pine.SOL.4.58.0311102243170.11597@zektor.gpcc.itd.umich.edu>

Paul  -

This situation seems like an obvious candidate for a log-linear model.
See the book MASS for details.  They're beyond the scope of this list.
Or try  help.search("log-linear").

(and ... can you find a way to break lines when sending your email ?)

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 11 Nov 2003, Paul Sorenson wrote:

> I want to investigate possible relationships between two discrete variables.  I have tried a few things but figured you guys might be able to point me at some purpose built functions.
>
> Our scientists score results of tests which are performed in lets say, 8 positions.  The scores are assigned a value of 1,2,3 or 4.  I want to know if there is a correlation between the test results and the position.  The scientists have a feeling that position 1 does not score as high as the others.
>
> Not all 8 positions are always used, so the frequency of all test results can be substantially biased towards the first position.  Here is an example dataset (not very biased) resulting from table(result, position):
>
>      1  2  3  4  5  6  7  8
>   0  3  3  2  2  0  3  3  0
>   1 11  4  6  7  7  3  3  5
>   2 38 37 32 38 31 21 23 27
>   3 51 66 54 66 57 37 58 56
>   4  3  1  3  0  1  0  1  1
>
> Because the test results are highly quantized, the boxplots I tried all looked pretty much the same.
>
> The bias means that stacked barplots aren't that useful for visualising the data.  With a bit of data processing I guess I could normalise the total frequencies of each test position.
>
> I also tried a correlation between the two variables.  The answer is non-zero but I am not sure that any relationship between the two variables would be monotonic (BTW cor() give me the correlation coefficient, how do I get the "confidence" of the coefficient?)
>
> Maybe I am overlooking the obvious, like just averaging the scores.
>
> cheers
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tblackw at umich.edu  Tue Nov 11 05:11:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 10 Nov 2003 23:11:04 -0500 (EST)
Subject: [R] Reading an upper triangular matrix
In-Reply-To: <3FAFE579.17667.136ECA@localhost>
References: <3FAFE579.17667.136ECA@localhost>
Message-ID: <Pine.SOL.4.58.0311102255020.11597@zektor.gpcc.itd.umich.edu>

Kjetil  -

Frankly, your file would be much, much easier to read
if it didn't have a row name at the beginning of each
line.  Any chance you can edit it to remove those ?

Then, I think you could read in the numeric data with
just one call to scan:

mat  <- matrix(0, 21, 21)
mat[row(mat) >= col(mat)] <- scan("filename", skip=1)
Paises <- t(mat)

(Note that the upper-tri matrix gets transposed, in
effect, when I read it in row-wise.  So I transpose
it back to upper-tri form in assigning it to 'Paises".)
Last, you will need to read in the column names and
assign these to both dimnames of Paises, but it's
clear that you already know how to do that.

Seems to me that you're going through a great deal of
unnecessry gyrations by trying to use a "connection"
rather than just pass the literal filename to  scan().
I've never understood why people do that.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Mon, 10 Nov 2003 kjetil at entelnet.bo wrote:

> Hola!
>
> I have data in the form of a symmetric distance matrix, in the file I
> have recorded only the upper triangular part, with diagonal. The
> matrix is 21x21, and the file have row and col names, and some other
> information. I am trying to read with the following code (I tried
> many variations on it, but all give the same error). The items in the
> data file is delimited by white space.
>
> (Part of) script to read:
>
> myfile <- file("Paises.dat", open="r")
>                # opens a connection which stays open until closed by
> close(myfile)
> name <- readLines(con=myfile, n=1)
> varnames <- scan( myfile, what=character(0), nlines=1 )
>
> stopifnot( length(varnames) == 21 )
> Paises <- matrix(0, 21, 21)
> colnames(Paises) <- varnames
> rownames(Paises) <- varnames
> for (i in 1:21) {
>     temp <- scan(myfile, what=list("a", rep(0,22-i) ), nlines=1,
> sep="")
>     Paises[i, i:21] <- temp[[2]]
>   }
>
> I get the following result:
>
> > source("Paises.R", echo=TRUE)
>
> > myfile <- file("Paises.dat", open = "r")
>
> > name <- readLines(con = myfile, n = 1)
>
> > varnames <- scan(myfile, what = character(0), nlines = 1)
> Read 21 items
>
> > stopifnot(length(varnames) == 21)
>
> > Paises <- matrix(0, 21, 21)
>
> > colnames(Paises) <- varnames
>
> > rownames(Paises) <- varnames
>
> > for (i in 1:21) {
>     temp <- scan(myfile, what = list("a", rep(0, 22 - i)), nlines =
> 1,
>         sep = "")
>     Paises[i, i:21] <- temp[[2]]
> }
> Read 11 records
> Error in "[<-"(`*tmp*`, i, i:21, value = temp[[2]]) :
>         number of items to replace is not a multiple of replacement
> length
> > i
> [1] 1
> > temp
> [[1]]
>  [1] "Bolivia" "1"       "2"       "3"       "2"       "4"       "4"
>
>  [8] "6"       "6"       "8"       "8"
>
> [[2]]
>  [1] 0 2 3 2 3 5 5 6 6 7 8
>
> >
>
> While I am asking only for one character string, multiple items are
> read as strings! What is happening?
>
> Kjetil Halvorsen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From h.wickham at auckland.ac.nz  Tue Nov 11 07:48:17 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Tue, 11 Nov 2003 19:48:17 +1300
Subject: [R] Subsetting a list of vectors
In-Reply-To: <20031110052317.67B893984@mprdmxin.myway.com>
References: <20031110052317.67B893984@mprdmxin.myway.com>
Message-ID: <3FB08631.101@auckland.ac.nz>

Thanks to you all for your helpful solutions.  I particularly like the 
simplicity of Gabor's na.omit( sapply(... ) )  formulation, but you've 
all given me some ideas to think about.

Thanks again,

Hadley



From arv at ono.com  Tue Nov 11 08:15:21 2003
From: arv at ono.com (antonio rodriguez)
Date: Tue, 11 Nov 2003 08:15:21 +0100
Subject: [R] animated plot 
In-Reply-To: <E1AJF1E-0004ll-00@vimb2.rdg.ac.uk>
Message-ID: <IPEFKICOHOECENGJBAGLEEKMCHAA.arv@ono.com>

Hi Jesus,

Don't know if in R this is possible, but on a Linux machine you can do the
following (no very elegant): save your individual images (i.e.: jan, feb,
march, ...)in .jpeg format, then with some image manager package (i.e.
Imagemagic) transfrom to .gif, and, finally, use whirlgif to paste in one
file all your newly created individuals files (jan.gif, feb.gif,...), and
you will get an animated plot.

Saludos!

Antonio Rodriguez

> -----Mensaje original-----
> De: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Jesus Fernandez
> Galvez
> Enviado el: lunes, 10 de noviembre de 2003 17:36
> Para: r-help at stat.math.ethz.ch
> Asunto: [R] animated plot
>
>
> Dear colleagues,
>
> Is there any way of saving an animated plot with R? For instance,
> any format
> that could be read by Microsoft windows media or whatever.
>
> Cheers,
>
> Jesus
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> ---
> Incoming mail is certified Virus Free.
> Checked by AVG anti-virus system (http://www.grisoft.com).
> Version: 6.0.536 / Virus Database: 331 - Release Date: 03/11/2003
>
---



From ripley at stats.ox.ac.uk  Tue Nov 11 08:22:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 07:22:07 +0000 (GMT)
Subject: [R] Reading an upper triangular matrix
In-Reply-To: <3FAFE579.17667.136ECA@localhost>
Message-ID: <Pine.LNX.4.44.0311110717130.22442-100000@gannet.stats>

You supplied "what" as a list of length 2, which is not what you intended.
I presume you read every other item on the first line.

Try list("a", rep(list(0), 22-i))

I would have read the whole of the matrix as a character vector,
removed the items corresponding to the labels, converted to numeric.


On Mon, 10 Nov 2003 kjetil at entelnet.bo wrote:

> Hola!
> 
> I have data in the form of a symmetric distance matrix, in the file I 
> have recorded only the upper triangular part, with diagonal. The 
> matrix is 21x21, and the file have row and col names, and some other 
> information. I am trying to read with the following code (I tried 
> many variations on it, but all give the same error). The items in the 
> data file is delimited by white space. 
> 
> (Part of) script to read:
> 
> myfile <- file("Paises.dat", open="r")
>                # opens a connection which stays open until closed by 
> close(myfile)
> name <- readLines(con=myfile, n=1)
> varnames <- scan( myfile, what=character(0), nlines=1 )
>  
> stopifnot( length(varnames) == 21 )
> Paises <- matrix(0, 21, 21)
> colnames(Paises) <- varnames
> rownames(Paises) <- varnames
> for (i in 1:21) {
>     temp <- scan(myfile, what=list("a", rep(0,22-i) ), nlines=1, 
> sep="")
>     Paises[i, i:21] <- temp[[2]]
>   }
> 
> I get the following result:
> 
> > source("Paises.R", echo=TRUE)
> 
> > myfile <- file("Paises.dat", open = "r")
> 
> > name <- readLines(con = myfile, n = 1)
> 
> > varnames <- scan(myfile, what = character(0), nlines = 1)
> Read 21 items
> 
> > stopifnot(length(varnames) == 21)
> 
> > Paises <- matrix(0, 21, 21)
> 
> > colnames(Paises) <- varnames
> 
> > rownames(Paises) <- varnames
> 
> > for (i in 1:21) {
>     temp <- scan(myfile, what = list("a", rep(0, 22 - i)), nlines = 
> 1, 
>         sep = "")
>     Paises[i, i:21] <- temp[[2]]
> }
> Read 11 records
> Error in "[<-"(`*tmp*`, i, i:21, value = temp[[2]]) : 
>         number of items to replace is not a multiple of replacement 
> length
> > i
> [1] 1
> > temp
> [[1]]
>  [1] "Bolivia" "1"       "2"       "3"       "2"       "4"       "4"  
>     
>  [8] "6"       "6"       "8"       "8"      
> 
> [[2]]
>  [1] 0 2 3 2 3 5 5 6 6 7 8
> 
> > 
> 
> While I am asking only for one character string, multiple items are 
> read as strings! What is happening?
> 
> Kjetil Halvorsen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Nov 11 08:27:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 07:27:10 +0000 (GMT)
Subject: [R] model constant relations
In-Reply-To: <3FAFB9B0.9020308@pdf.com>
Message-ID: <Pine.LNX.4.44.0311110724220.22442-100000@gannet.stats>

On Mon, 10 Nov 2003, Spencer Graves wrote:

> Thanks very much:  I typed "?summary.fit" when I meant to type 
> "?summary.lm", which explains why I didn't find the "cor" argument.  
> Thanks also for the reference to "?vcov".  I didn't see that in the "see 
> also" section for either "lm" or "summary" or "summary.lm".  Might it be 
> worth added? 

It's just one of a whole bunch of generic extractors, which are usually 
not mentioned.  It was lifted from MASS, and is documented there.

> >>      In S-Plus, this is automatically produced by summary(lm(...)).  
> >>There is probably a simple, elegant way to get this in R, but I don't 
> >>know it.  Therefore, I produced it as follows: 
> >
> >summary(fit, cor=TRUE) : the default is different between R and S 
> >(intentionally).
> >
> >See also ?vcov.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Nov 11 08:30:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 07:30:03 +0000 (GMT)
Subject: [R] animated plot 
In-Reply-To: <IPEFKICOHOECENGJBAGLEEKMCHAA.arv@ono.com>
Message-ID: <Pine.LNX.4.44.0311110727290.22442-100000@gannet.stats>

It's better to save in png or bmp than jpeg unless these are image() plots 
(and maybe even then).

There are lots of tools to take a series of bitmapped plots and make an 
animation from them.

A more elegant way is to use a screengrab tool which can grep a video 
clip of an animation running in a R graphics window.

On Tue, 11 Nov 2003, antonio rodriguez wrote:

> Hi Jesus,
> 
> Don't know if in R this is possible, but on a Linux machine you can do the
> following (no very elegant): save your individual images (i.e.: jan, feb,
> march, ...)in .jpeg format, then with some image manager package (i.e.
> Imagemagic) transfrom to .gif, and, finally, use whirlgif to paste in one
> file all your newly created individuals files (jan.gif, feb.gif,...), and
> you will get an animated plot.
> 
> Saludos!
> 
> Antonio Rodriguez
> 
> > -----Mensaje original-----
> > De: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Jesus Fernandez
> > Galvez
> > Enviado el: lunes, 10 de noviembre de 2003 17:36
> > Para: r-help at stat.math.ethz.ch
> > Asunto: [R] animated plot
> >
> >
> > Dear colleagues,
> >
> > Is there any way of saving an animated plot with R? For instance,
> > any format
> > that could be read by Microsoft windows media or whatever.
> >
> > Cheers,
> >
> > Jesus
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > ---
> > Incoming mail is certified Virus Free.
> > Checked by AVG anti-virus system (http://www.grisoft.com).
> > Version: 6.0.536 / Virus Database: 331 - Release Date: 03/11/2003
> >
> ---
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Nov 11 08:33:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 07:33:10 +0000 (GMT)
Subject: [R] Reading an upper triangular matrix
In-Reply-To: <Pine.LNX.4.44.0311110717130.22442-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0311110732010.22442-100000@gannet.stats>

On Tue, 11 Nov 2003, Prof Brian Ripley wrote:

> You supplied "what" as a list of length 2, which is not what you intended.
> I presume you read every other item on the first line.
> 
> Try list("a", rep(list(0), 22-i))

Sorry, that got mangled when my cable modem went down.  I tested

c(list("a"), rep(list(0), 22-i))

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hb at maths.lth.se  Tue Nov 11 09:55:59 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 11 Nov 2003 09:55:59 +0100
Subject: [R] animated plot 
In-Reply-To: <IPEFKICOHOECENGJBAGLEEKMCHAA.arv@ono.com>
Message-ID: <002101c3a831$a4d767f0$3b0040d5@maths.lth.se>

Just a follow up: ImageMagick's command 'convert', which Antonio is
refering to, has also an option (-adjoin) to join gifs into an animated
sequence that can loop etc. ImageMagick exists for Windows too and its
free. With system("convert -adjoin ...") you can do everything from
within R. The it is also easier to edit the order of you images.

BTW: I would write my original images in *.png because *.jpg is
"destructive" (specially if you consider scatter plots etc). ImageMagick
also has 'mogrify', which allows you to convert a batch of images at
once.

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> antonio rodriguez
> Sent: den 11 november 2003 08:15
> To: Jesus Fernandez Galvez; r-help at stat.math.ethz.ch
> Subject: RE: [R] animated plot 
> 
> 
> Hi Jesus,
> 
> Don't know if in R this is possible, but on a Linux machine 
> you can do the following (no very elegant): save your 
> individual images (i.e.: jan, feb, march, ...)in .jpeg 
> format, then with some image manager package (i.e.
> Imagemagic) transfrom to .gif, and, finally, use whirlgif to 
> paste in one file all your newly created individuals files 
> (jan.gif, feb.gif,...), and you will get an animated plot.
> 
> Saludos!
> 
> Antonio Rodriguez
> 
> > -----Mensaje original-----
> > De: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Jesus 
> Fernandez 
> > Galvez Enviado el: lunes, 10 de noviembre de 2003 17:36
> > Para: r-help at stat.math.ethz.ch
> > Asunto: [R] animated plot
> >
> >
> > Dear colleagues,
> >
> > Is there any way of saving an animated plot with R? For 
> instance, any 
> > format that could be read by Microsoft windows media or whatever.
> >
> > Cheers,
> >
> > Jesus
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > ---
> > Incoming mail is certified Virus Free.
> > Checked by AVG anti-virus system (http://www.grisoft.com).
> > Version: 6.0.536 / Virus Database: 331 - Release Date: 03/11/2003
> >
> ---
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> 
>



From Wohlgemuth at mpimp-golm.mpg.de  Tue Nov 11 10:13:22 2003
From: Wohlgemuth at mpimp-golm.mpg.de (Gert Wohlgemuth)
Date: Tue, 11 Nov 2003 10:13:22 +0100
Subject: [R] subscripe
Message-ID: <0F072619A2C4594781FBFF69DA96AA37D6A6C6@MAIL.mpimp-golm.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031111/643234c5/attachment.pl

From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Nov 11 08:49:05 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 11 Nov 2003 08:49:05 +0100 (CET)
Subject: [R] useR! 2004
Message-ID: <Pine.LNX.4.51.0311110847230.2239@artemis.imbe.med.uni-erlangen.de>



We are happy to announce that the first R user conference

  useR! 2004

is scheduled for May 20-22 2004 and will take place at the Vienna
University of Technology.

The conference will focus on
  - giving an overview of the new features of the rapidly evolving R project,
  - providing a platform for R users to discuss and exchange ideas how R can
    be used to do statistical computations, data analysis, visualization and
    exciting applications in various fields.


KEYNOTE LECTURES
A huge amount of exciting features and innovations came up in the last
releases of R. How these features can be used efficiently will be presented in
keynote lectures given by R core team members, addressing hot topics such as
  - grid Graphics
  - Good Programming Practice
  - Dynamic Documents
  - Language Interfaces
  - Packaging and Quality Assurance
  - Datamining and Large Databases

Speakers will include Peter Dalgaard, Kurt Hornik, Fritz Leisch, Paul Murrell
and Brian D. Ripley.

USER-CONTRIBUTED SESSIONS
Oral and poster presentations will be a platform to bring together R users,
contributers, package maintainers and developers in the S spirit that
`users are developers'. People from different fields will show us how they solve
problems with R in fascinating applications. The sessions are organized by
members of the program committee, including Axel Benner, Roger Bivand, Dirk
Eddelbuettel, John Fox, Kurt Hornik, Stefano Iacus, Steffen L. Lauritzen,
Friedrich Leisch, Uwe Ligges and Martin Theus, and will cover topics such as
  - Finance & Econometrics
  - Visualization & Graphics
  - Spatial Statistics
  - Biostatistics
  - Graphical Models
  - and many more.

After the official presentations, Vienna's famous wine and beer pubs, cafes
and restaurants proofed to be a very stimulating environment for fruitful
discussions at previous meetings of the R community like this year's DSC 2003.

We invite all R users to submit abstracts on topics presenting innovations or
exciting applications of R. A web page offering more information on the `useR!'
conference, abstract submission, registration and Vienna is available at

  http://www.ci.tuwien.ac.at/Conferences/useR-2004/

We hope to meet you in Vienna!

For the organizing committee:

Torsten Hothorn, Achim Zeileis and David Meyer.

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From Simon.Fear at synequanon.com  Tue Nov 11 10:44:00 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Tue, 11 Nov 2003 09:44:00 -0000
Subject: [R] relationship between two discrete variables
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0E8C@synequanon01>

Don't use correlation for discrete variables; the 
correlation coefficient does not vary freely between -1 
and 1, it is tightly constrained by the joint probabilities of 
nonzero outcomes in a rather counterintuitive way.  
Please ask me off list if you don't follow this.

While I'm off-topic, following Tom B's comment, the only
way I know to break lines in emails using Explorer is to
actually type returns - is what I always do here and is a
pain in  the ****. If anyone knows how to overcome this
I'd be very grateful. [I don't have a choice about using
Explorer]  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From nioksane at cc.jyu.fi  Tue Nov 11 11:33:26 2003
From: nioksane at cc.jyu.fi (nioksane@cc.jyu.fi)
Date: Tue, 11 Nov 2003 12:33:26 +0200 (EET)
Subject: [R] nlme-problem
Message-ID: <3295.130.234.32.166.1068546806.squirrel@webmail2.cc.jyu.fi>

Hi,
I have a problem with fitting a nonlinear mixed-effects model to my data.
I was able to fit quite simple exponential model but now I?m trying to fit
the following Gompertz model:

> gomp<-nlme(paino~b0+b1*exp(-exp(-b2*(daydeg.scale-b3))), data=group1,
fixed=b0+b1+b2+b3~1, start=c(b0=150, b1=3000, b2=0.6, b3=2500))

I?m getting the following error:

Error in chol((value + t(value))/2) : the leading minor of order 2 is not
positive definite

Could you give me some ideas what might be wrong and how to deal with it?
I know that the data and the syntax should be ok as I have tested it
already with exponential model. The problem seems to be in the model-form.

Many thanks,

Niina Kotamaki
University of Jyvaskyla



From j.fernandez-galvez at reading.ac.uk  Tue Nov 11 11:42:26 2003
From: j.fernandez-galvez at reading.ac.uk (Jesus Fernandez Galvez)
Date: Tue, 11 Nov 2003 10:42:26 -0000
Subject: [R] animated plot 
In-Reply-To: <Pine.LNX.4.44.0311110727290.22442-100000@gannet.stats>
Message-ID: <E1AJVyc-0000cd-00@vimb2.rdg.ac.uk>

Thanks for you comments,

I am visualising 4 months time series at 30 minutes intervals so it is
impossible to create all this set of images (*.png, *.jpg, *.bmp,?). With
R, I can change the speed of visualisation but I think I would need  a
screengrab tool to save the sequence. I manage to save as .pdf and the graph
moves! But the file is huge. Could you please shedding some light on how to
find screengrab tools (name of free software if possible)

Thanks,

Jesus



-------------------
> It's better to save in png or bmp than jpeg unless these are image() plots

> (and maybe even then).
> 
> There are lots of tools to take a series of bitmapped plots and make an 
> animation from them.
> 
> A more elegant way is to use a screengrab tool which can grep a video 
> clip of an animation running in a R graphics window.
> 
> On Tue, 11 Nov 2003, antonio rodriguez wrote:
> 
> > Hi Jesus,
> > 
> > Don't know if in R this is possible, but on a Linux machine you can do
the
> > following (no very elegant): save your individual images (i.e.: jan,
feb,
> > march, ...)in .jpeg format, then with some image manager package (i.e.
> > Imagemagic) transfrom to .gif, and, finally, use whirlgif to paste in
one
> > file all your newly created individuals files (jan.gif, feb.gif,...),
and
> > you will get an animated plot.
> > 
> > Saludos!
> > 
> > Antonio Rodriguez
> > 
> > > -----Mensaje original-----
> > > De: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Jesus Fernandez
> > > Galvez
> > > Enviado el: lunes, 10 de noviembre de 2003 17:36
> > > Para: r-help at stat.math.ethz.ch
> > > Asunto: [R] animated plot
> > >
> > >
> > > Dear colleagues,
> > >
> > > Is there any way of saving an animated plot with R? For instance,
> > > any format
> > > that could be read by Microsoft windows media or whatever.
> > >
> > > Cheers,
> > >
> > > Jesus
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > ---
> > > Incoming mail is certified Virus Free.
> > > Checked by AVG anti-virus system (http://www.grisoft.com).
> > > Version: 6.0.536 / Virus Database: 331 - Release Date: 03/11/2003
> > >
> > ---
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>



From a.shipunov at rbgkew.org.uk  Tue Nov 11 11:49:43 2003
From: a.shipunov at rbgkew.org.uk (Alexey Shipunov)
Date: Tue, 11 Nov 2003 10:49:43 -0000
Subject: [R] A co-occurrence matrix
Message-ID: <3FB0BEC7.3916.45A420F@localhost>

Dear R experts,

I have a matrix (from some sort of 
classification) like this:

      object  group
 [1,] 1       1
 [2,] 2       2
 [3,] 3       1
 [4,] 4       1
 [5,] 5       3

And I need something like this:

      [,1] [,2] [,3] [,4] [,5]
 [1,] 1    0    1    1    0
 [2,] 0    1    0    0    0
 [3,] 1    0    1    1    0
 [4,] 1    0    1    1    0
 [5,] 0    0    0    0    1

where all zeros mean that these objects are not 
in same group, and vice versa.

Is there a relatively simple way to construct co-
uccurence matrices of type shown above?

Any help would be appreciated,


=================================
Dr. Alexey B. Shipunov
Section of Molecular Systematics
Jodrell Laboratory
Royal Botanic Gardens, Kew,
Richmond, Surrey, TW9 3DS, U.K.
e-mail: a.shipunov at rbgkew.org.uk



From ripley at stats.ox.ac.uk  Tue Nov 11 11:53:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 10:53:10 +0000 (GMT)
Subject: [R] animated plot 
In-Reply-To: <E1AJVyc-0000cd-00@vimb2.rdg.ac.uk>
Message-ID: <Pine.LNX.4.44.0311111047450.19776-100000@gannet.stats>

On Tue, 11 Nov 2003, Jesus Fernandez Galvez wrote:

> Thanks for you comments,
> 
> I am visualising 4 months time series at 30 minutes intervals so it is
> impossible to create all this set of images (*.png, *.jpg, *.bmp,???). With

That's about 4300 images, so why is it impossible to save them?  Looks 
like much less than 1Gb in total.  However, is that actually useful?
At 1/sec that will take over an hour to watch the animation: what do you 
hope to see?

> R, I can change the speed of visualisation but I think I would need  a
> screengrab tool to save the sequence. I manage to save as .pdf and the graph
> moves! But the file is huge. Could you please shedding some light on how to
> find screengrab tools (name of free software if possible)

I used Snagit, which is not free (and my movie had 100 frames).  But do
ask your computing questions of your local computing support -- I ask my 
engineering collaborators who do this sort of thing all the time.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Tue Nov 11 12:30:29 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Nov 2003 12:30:29 +0100
Subject: [R] sample size/power calc packages
In-Reply-To: <85fzgvenq9.fsf@blindglobe.net>
References: <85fzgvenq9.fsf@blindglobe.net>
Message-ID: <x2d6bzywfe.fsf@biostat.ku.dk>

rossini at blindglobe.net (A.J. Rossini) writes:

> For various reasons, I spent part of my time today looking at sample
> size and power calculation tools (don't ask, don't tell...).  This
> seems to be one area that R is incredibly weak in (well, nearly all
> stat packages, except perhaps specialized tools and SAS); sure, there
> are a number of functions in various packages:
> 
>           base, statmod, Hmisc
> 
> Have I missed something?  (I would've expected at least one sequential
> computation, or non-standard design, but apparently there are none, or
> I missed it).  
> 
> I'd appreciate hearing about work that I've missed...

Is SAS particularly hot? I've just been explaining to people how to
cheat SAS Analyst into letting the Two-Sample t-Test sample-sizer do
binomial proportions with a fudged SD.

I think Claus Ekstr?m submitted a modification power.t.test for
unequal sample size, but he wasn't sufficiently assertive that it was
actually done right, so it didn't get in.

One thing we really ought to get around to soon is sample sizing for
equivalence studies. And, yes, sequential procedures would be obvious
too.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ekstrom at dina.kvl.dk  Tue Nov 11 13:01:19 2003
From: ekstrom at dina.kvl.dk (Claus =?iso-8859-1?Q?Ekstr=F8m?=)
Date: Tue, 11 Nov 2003 13:01:19 +0100
Subject: [R] sample size/power calc packages
In-Reply-To: <x2d6bzywfe.fsf@biostat.ku.dk>
References: <85fzgvenq9.fsf@blindglobe.net> <x2d6bzywfe.fsf@biostat.ku.dk>
Message-ID: <20031111120119.GA8844@dina.kvl.dk>

Peter Dalgaard writes:

> I think Claus Ekstr?m submitted a modification power.t.test for
> unequal sample size, but he wasn't sufficiently assertive that it was
> actually done right, so it didn't get in.

It does the calculations right but is not implemented in the most elegant way. See

https://www.stat.math.ethz.ch/pipermail/r-devel/2003-September/027458.html

for the code.

Cheers,

Claus

-- 
*****************************************
Claus Thorn Ekstr?m <ekstrom at dina.kvl.dk>
Dept of Mathematics and Physics, KVL
Thorvaldsensvej 40
DK-1871 Frederiksberg C
Denmark
Phone:[+45] 3528 2341
Fax:  [+45] 3528 2350



From jfox at mcmaster.ca  Tue Nov 11 13:39:09 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 11 Nov 2003 07:39:09 -0500
Subject: [R] A co-occurrence matrix
In-Reply-To: <3FB0BEC7.3916.45A420F@localhost>
Message-ID: <5.1.0.14.2.20031111073618.01fb4058@127.0.0.1>

Dear Alexey,

You can use outer(), as follows:

 > group <- c(1, 2, 1, 1, 3)

 > matrix(as.numeric(outer(group, group, "==")), 5, 5)
      [,1] [,2] [,3] [,4] [,5]
[1,]    1    0    1    1    0
[2,]    0    1    0    0    0
[3,]    1    0    1    1    0
[4,]    1    0    1    1    0
[5,]    0    0    0    0    1
 >

If a logical result will do, the expression is even simpler:

 > outer(group, group, "==")
       [,1]  [,2]  [,3]  [,4]  [,5]
[1,]  TRUE FALSE  TRUE  TRUE FALSE
[2,] FALSE  TRUE FALSE FALSE FALSE
[3,]  TRUE FALSE  TRUE  TRUE FALSE
[4,]  TRUE FALSE  TRUE  TRUE FALSE
[5,] FALSE FALSE FALSE FALSE  TRUE

I hope that this helps,
  John

At 10:49 AM 11/11/2003 +0000, Alexey Shipunov wrote:
>Dear R experts,
>
>I have a matrix (from some sort of
>classification) like this:
>
>       object  group
>  [1,] 1       1
>  [2,] 2       2
>  [3,] 3       1
>  [4,] 4       1
>  [5,] 5       3
>
>And I need something like this:
>
>       [,1] [,2] [,3] [,4] [,5]
>  [1,] 1    0    1    1    0
>  [2,] 0    1    0    0    0
>  [3,] 1    0    1    1    0
>  [4,] 1    0    1    1    0
>  [5,] 0    0    0    0    1
>
>where all zeros mean that these objects are not
>in same group, and vice versa.
>
>Is there a relatively simple way to construct co-
>uccurence matrices of type shown above?
>
>Any help would be appreciated,
>

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From andy_liaw at merck.com  Tue Nov 11 13:41:18 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 11 Nov 2003 07:41:18 -0500
Subject: [R] A co-occurrence matrix
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE04@usrymx25.merck.com>

Does the following help?

> group <- c(1, 2, 1, 1, 3)
> outer(group, group, "==")
      [,1]  [,2]  [,3]  [,4]  [,5]
[1,]  TRUE FALSE  TRUE  TRUE FALSE
[2,] FALSE  TRUE FALSE FALSE FALSE
[3,]  TRUE FALSE  TRUE  TRUE FALSE
[4,]  TRUE FALSE  TRUE  TRUE FALSE
[5,] FALSE FALSE FALSE FALSE  TRUE
> outer(group, group, "==") + 0  # Turn it into a numeric matrix.
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    0    1    1    0
[2,]    0    1    0    0    0
[3,]    1    0    1    1    0
[4,]    1    0    1    1    0
[5,]    0    0    0    0    1


Andy

> -----Original Message-----
> From: Alexey Shipunov [mailto:a.shipunov at rbgkew.org.uk] 
> Sent: Tuesday, November 11, 2003 5:50 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] A co-occurrence matrix
> 
> 
> Dear R experts,
> 
> I have a matrix (from some sort of 
> classification) like this:
> 
>       object  group
>  [1,] 1       1
>  [2,] 2       2
>  [3,] 3       1
>  [4,] 4       1
>  [5,] 5       3
> 
> And I need something like this:
> 
>       [,1] [,2] [,3] [,4] [,5]
>  [1,] 1    0    1    1    0
>  [2,] 0    1    0    0    0
>  [3,] 1    0    1    1    0
>  [4,] 1    0    1    1    0
>  [5,] 0    0    0    0    1
> 
> where all zeros mean that these objects are not 
> in same group, and vice versa.
> 
> Is there a relatively simple way to construct co-
> uccurence matrices of type shown above?
> 
> Any help would be appreciated,
> 
> 
> =================================
> Dr. Alexey B. Shipunov
> Section of Molecular Systematics
> Jodrell Laboratory
> Royal Botanic Gardens, Kew,
> Richmond, Surrey, TW9 3DS, U.K.
> e-mail: a.shipunov at rbgkew.org.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From ramasamya at gis.a-star.edu.sg  Tue Nov 11 13:40:55 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Tue, 11 Nov 2003 20:40:55 +0800
Subject: [R] A co-occurrence matrix
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D56076009@BIONIC.biopolis.one-north.com>

You can try the following commands, which I have not tested extensively,
 
m <- data.frame( object=c(1,2,3,4,5), group=c(1,2,1,1,3) )
tab <- table(m)
out <- tab %*% t(tab)

The above is OK if every object belongs to one group only. But if it does not, say as in "m2 <- rbind(m, c(1,3))", the values above 1 can occur on the diagonal indicating the number of membership that object has.

 

-----Original Message----- 
From: r-help-bounces at stat.math.ethz.ch on behalf of Alexey Shipunov 
Sent: Tue 11/11/2003 18:49 
To: R-help at stat.math.ethz.ch 
Cc: 
Subject: [R] A co-occurrence matrix



	Dear R experts,
	
	I have a matrix (from some sort of
	classification) like this:
	
	      object  group
	 [1,] 1       1
	 [2,] 2       2
	 [3,] 3       1
	 [4,] 4       1
	 [5,] 5       3
	
	And I need something like this:
	
	      [,1] [,2] [,3] [,4] [,5]
	 [1,] 1    0    1    1    0
	 [2,] 0    1    0    0    0
	 [3,] 1    0    1    1    0
	 [4,] 1    0    1    1    0
	 [5,] 0    0    0    0    1
	
	where all zeros mean that these objects are not
	in same group, and vice versa.
	
	Is there a relatively simple way to construct co-
	uccurence matrices of type shown above?
	
	Any help would be appreciated,
	
	
	=================================
	Dr. Alexey B. Shipunov
	Section of Molecular Systematics
	Jodrell Laboratory
	Royal Botanic Gardens, Kew,
	Richmond, Surrey, TW9 3DS, U.K.
	e-mail: a.shipunov at rbgkew.org.uk
	
	______________________________________________
	R-help at stat.math.ethz.ch mailing list
	https://www.stat.math.ethz.ch/mailman/listinfo/r-help <https://www.stat.math.ethz.ch/mailman/listinfo/r-help>



From wilks at dial.pipex.com  Tue Nov 11 13:49:13 2003
From: wilks at dial.pipex.com (John Wilkinson)
Date: Tue, 11 Nov 2003 12:49:13 -0000
Subject: [R] Unloading packages
Message-ID: <DMEPLBPHNFFELNGCFKEBGEEACAAA.wilks@dial.pipex.com>

In order to update the packages from Cran, it is first necessary
to unload all packages from the R Console.

Can anyone, please, inform me, how to unload all loaded packages with one
command?

Thanks for any help,

John Wilkinson



From johannes.huesing at medizin.uni-essen.de  Tue Nov 11 13:49:14 2003
From: johannes.huesing at medizin.uni-essen.de (=?iso-8859-1?Q?=22H=FCsing=2C_Johannes=22?=)
Date: Tue, 11 Nov 2003 13:49:14 +0100
Subject: [R] A co-occurrence matrix
Message-ID: <B3A80C9C13928B45B2FCE4C43656363A0194E2FF@mail-srv02.master.medizin.uni-essen.de>

>       [,1] [,2] [,3] [,4] [,5]
>  [1,] 1    0    1    1    0
>  [2,] 0    1    0    0    0
>  [3,] 1    0    1    1    0
>  [4,] 1    0    1    1    0
>  [5,] 0    0    0    0    1
> 
> where all zeros mean that these objects are not 
> in same group, and vice versa.

This is a block diagonal matrix of 1s and 0s 
with rows and cols permuted.

A block diagonal matrix can be set up with:

blockdiag <- function (v) {
  n <- sum(v)
  onezero <- function(k) {
    c(rep(c(rep(1,k), rep(0,n-k)), k), rep(0,k))
  }
  array(unlist(sapply(v, onezero))[1:(n*n)], c(n,n))
}

John's answer just came in; it seems more elegant to me.

Greetings


Johannes



From jfox at mcmaster.ca  Tue Nov 11 13:55:07 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 11 Nov 2003 07:55:07 -0500
Subject: [R] sample size/power calc packages
In-Reply-To: <x2d6bzywfe.fsf@biostat.ku.dk>
References: <85fzgvenq9.fsf@blindglobe.net>
 <85fzgvenq9.fsf@blindglobe.net>
Message-ID: <5.1.0.14.2.20031111074118.0201efb8@127.0.0.1>

Dear Peter,

At 12:30 PM 11/11/2003 +0100, Peter Dalgaard wrote:
>rossini at blindglobe.net (A.J. Rossini) writes:
>
> > For various reasons, I spent part of my time today looking at sample
> > size and power calculation tools (don't ask, don't tell...).  This
> > seems to be one area that R is incredibly weak in (well, nearly all
> > stat packages, except perhaps specialized tools and SAS); sure, there
> > are a number of functions in various packages:
> >
> >           base, statmod, Hmisc
> >
> > Have I missed something?  (I would've expected at least one sequential
> > computation, or non-standard design, but apparently there are none, or
> > I missed it).
> >
> > I'd appreciate hearing about work that I've missed...
>
>Is SAS particularly hot? I've just been explaining to people how to
>cheat SAS Analyst into letting the Two-Sample t-Test sample-sizer do
>binomial proportions with a fudged SD.

There is an extensive set of power-calculation macros in SAS, by Ralph 
O'Brien, at <http://www.bio.ri.ccf.org/power.html>. Apparently SAS Version 
9.1 will have new procs power and glmpower, which will cover most of what 
is in these macros.

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From ripley at stats.ox.ac.uk  Tue Nov 11 13:57:13 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 12:57:13 +0000 (GMT)
Subject: [R] Unloading packages
In-Reply-To: <DMEPLBPHNFFELNGCFKEBGEEACAAA.wilks@dial.pipex.com>
Message-ID: <Pine.LNX.4.44.0311111256150.20080-100000@gannet.stats>

Just don't load them -- start the session with --vanilla.

And that is in the rw-FAQ if you want more details.

On Tue, 11 Nov 2003, John Wilkinson wrote:

> In order to update the packages from Cran, it is first necessary
> to unload all packages from the R Console.

On Windows, since you mention a console?

> Can anyone, please, inform me, how to unload all loaded packages with one
> command?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tblackw at umich.edu  Tue Nov 11 14:46:05 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 11 Nov 2003 08:46:05 -0500 (EST)
Subject: [R] boot package question: sampling on factor, not row
In-Reply-To: <Pine.LNX.4.44.0311110654560.22241-100000@gannet.stats>
References: <Pine.LNX.4.44.0311110654560.22241-100000@gannet.stats>
Message-ID: <Pine.SOL.4.58.0311110839550.25354@mspacman.gpcc.itd.umich.edu>


> On Mon, 10 Nov 2003, Thomas W Blackwell wrote:
>
> > The second argument to  boot(),  called 'statistic', can be
> > any user-written function you want to cook up, with additional
> > arguments being passed to it through the '...' mechanism after
> > all of the named arguments.  (See: `R-intro `Writing your own
> > functions `The ellipsis argument  for details.)
>
> > I've given you the reference for the '...' mechanism, because
> > that reference is almost impossible to find using  help.search().
>
On Tue, 11 Nov 2003, Prof Brian Ripley wrote:

> Right, as help.search `allows for searching the help system'. It does not
> search the manuals, nor the FAQs, so it would be imposible to find things
> not in the help system.
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

Precisely my point, Brian.  The usage and meaning of '...' are
almost impossible to find in the help system.  Could there be a
help page for it ?  Questions about '...' are reasonably frequently
asked on this list.

While we're at it, what could be done so that  help.search("logistic")
returns a reference to  glm()  and  help.search("regression") returns
references to both  lm()  and  glm() ?

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From c.gold at magnet.at  Tue Nov 11 14:47:12 2003
From: c.gold at magnet.at (Christian Gold)
Date: Tue, 11 Nov 2003 14:47:12 +0100
Subject: [R] installing an add-on package
Message-ID: <3FB0E860.64FC4511@magnet.at>

Dear all,

my apologies if I am posting a silly question - but I couldn't find any
helpful information on this elswhere.
In the R FAQ, version 1.8-1, there is a section "5.2 How can add-on
packages be installed?", but it only gives information for Unix users.
How can I install an add-on package under Windows? (Specifically, I have
downloaded the "rmeta" package from CRAN.)

Thanks for your help!

Christian

From ripley at stats.ox.ac.uk  Tue Nov 11 14:55:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 13:55:01 +0000 (GMT)
Subject: [R] boot package question: sampling on factor, not row
In-Reply-To: <Pine.SOL.4.58.0311110839550.25354@mspacman.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0311111353440.22879-100000@gannet.stats>

On Tue, 11 Nov 2003, Thomas W Blackwell wrote:

> 
> > On Mon, 10 Nov 2003, Thomas W Blackwell wrote:
> >
> > > The second argument to  boot(),  called 'statistic', can be
> > > any user-written function you want to cook up, with additional
> > > arguments being passed to it through the '...' mechanism after
> > > all of the named arguments.  (See: `R-intro `Writing your own
> > > functions `The ellipsis argument  for details.)
> >
> > > I've given you the reference for the '...' mechanism, because
> > > that reference is almost impossible to find using  help.search().
> >
> On Tue, 11 Nov 2003, Prof Brian Ripley wrote:
> 
> > Right, as help.search `allows for searching the help system'. It does not
> > search the manuals, nor the FAQs, so it would be imposible to find things
> > not in the help system.
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> Precisely my point, Brian.  The usage and meaning of '...' are
> almost impossible to find in the help system.  Could there be a
> help page for it ?  Questions about '...' are reasonably frequently
> asked on this list.

Not that I've noticed.

Yes, it could be done: you know how to submit contributions?  It's in the 
FAQ I believe.

> While we're at it, what could be done so that  help.search("logistic")
> returns a reference to  glm()  and  help.search("regression") returns
> references to both  lm()  and  glm() ?

Add \concepts ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Tue Nov 11 14:59:47 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 11 Nov 2003 08:59:47 -0500
Subject: [R] installing an add-on package
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE07@usrymx25.merck.com>

You should be reading the R for Windows FAQ (rw-FAQ), which is under the
"Help" menu on Rgui.

Big hint:  Look under the "Packages" menu in Rgui.

Andy

> From: Christian Gold [mailto:c.gold at magnet.at] 
> 
> Dear all,
> 
> my apologies if I am posting a silly question - but I 
> couldn't find any helpful information on this elswhere. In 
> the R FAQ, version 1.8-1, there is a section "5.2 How can 
> add-on packages be installed?", but it only gives information 
> for Unix users. How can I install an add-on package under 
> Windows? (Specifically, I have downloaded the "rmeta" package 
> from CRAN.)
> 
> Thanks for your help!
> 
> Christian
>



From paulojus at est.ufpr.br  Tue Nov 11 15:10:32 2003
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 11 Nov 2003 12:10:32 -0200 (BRST)
Subject: [R] installing an add-on package
In-Reply-To: <3FB0E860.64FC4511@magnet.at>
References: <3FB0E860.64FC4511@magnet.at>
Message-ID: <Pine.LNX.4.56.0311111208400.20498@gauss.est.ufpr.br>

The command:

install.packages() works for whatever platform.
See ?install.packages

If you youse windoes you can go to the top menu and under "Packages"
you will finf "Install packages from CRAN" and "Install from local zip
files"
if you have aready downloaded the package use the second.


On Tue, 11 Nov 2003, Christian Gold wrote:

> Dear all,
>
> my apologies if I am posting a silly question - but I couldn't find any
> helpful information on this elswhere.
> In the R FAQ, version 1.8-1, there is a section "5.2 How can add-on
> packages be installed?", but it only gives information for Unix users.
> How can I install an add-on package under Windows? (Specifically, I have
> downloaded the "rmeta" package from CRAN.)
>
> Thanks for your help!
>
> Christian
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From ripley at stats.ox.ac.uk  Tue Nov 11 15:14:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 14:14:00 +0000 (GMT)
Subject: [R] installing an add-on package
In-Reply-To: <3FB0E860.64FC4511@magnet.at>
Message-ID: <Pine.LNX.4.44.0311111409270.22930-100000@gannet.stats>

You look in the FAQ for R for Windows ....

It's under HTML help, and file rw-FAQ in the top-level directory of the R 
installation.  It's also mentioned in the FAQ you consulted, and linked 
from www.r-project.org (and BTW I think the R 1.6.0 Mac FAQ needs to
be removed from there and replaced by the MacOS X one).

On Tue, 11 Nov 2003, Christian Gold wrote:

> my apologies if I am posting a silly question - but I couldn't find any
> helpful information on this elswhere.
> In the R FAQ, version 1.8-1, there is a section "5.2 How can add-on
> packages be installed?", but it only gives information for Unix users.
> How can I install an add-on package under Windows? (Specifically, I have
> downloaded the "rmeta" package from CRAN.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Tue Nov 11 15:18:34 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Nov 2003 08:18:34 -0600
Subject: [R] nlme-problem
In-Reply-To: <3295.130.234.32.166.1068546806.squirrel@webmail2.cc.jyu.fi>
References: <3295.130.234.32.166.1068546806.squirrel@webmail2.cc.jyu.fi>
Message-ID: <6roevj56px.fsf@bates4.stat.wisc.edu>

<nioksane at cc.jyu.fi> writes:

> I have a problem with fitting a nonlinear mixed-effects model to my data.
> I was able to fit quite simple exponential model but now I'm trying to fit
> the following Gompertz model:
> 
> > gomp<-nlme(paino~b0+b1*exp(-exp(-b2*(daydeg.scale-b3))), data=group1,
> fixed=b0+b1+b2+b3~1, start=c(b0=150, b1=3000, b2=0.6, b3=2500))
> 
> I'm getting the following error:
> 
> Error in chol((value + t(value))/2) : the leading minor of order 2 is not
> positive definite
> 
> Could you give me some ideas what might be wrong and how to deal with it?
> I know that the data and the syntax should be ok as I have tested it
> already with exponential model. The problem seems to be in the model-form.

Try using the optional arguments

 verbose = TRUE, control = list(msVerbose = TRUE)

in your call to nlme so that you can see how the parameter estimates
are being changed.

By the way, there is a self-starting model function SSgompertz that
you could try instead.  I would try to fit an nlsList model first with
that.



From c.gold at magnet.at  Tue Nov 11 15:40:18 2003
From: c.gold at magnet.at (Christian Gold)
Date: Tue, 11 Nov 2003 15:40:18 +0100
Subject: [R] installing an add-on package
References: <3A822319EB35174CA3714066D590DCD50205CE07@usrymx25.merck.com>
Message-ID: <3FB0F4D2.DC47C142@magnet.at>

Dear all,

thanks very much for your quick and helpful response! It tought me again the
old lesson that one should look for simple solutions first, before looking
for more complicated ones...

Thanks

Christian

From bill.shipley at usherbrooke.ca  Tue Nov 11 15:44:32 2003
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Tue, 11 Nov 2003 09:44:32 -0500
Subject: [R] interpreting output of lme
Message-ID: <01e801c3a862$51e0e360$8d1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031111/aceb9def/attachment.pl

From ueb901c at tninet.se  Tue Nov 11 17:33:12 2003
From: ueb901c at tninet.se (Sven Sandin)
Date: Tue, 11 Nov 2003 17:33:12 +0100
Subject: [R] Compilation problem SuSE 9.0
Message-ID: <200311111733.13039.ueb901c@tninet.se>

Hi

I have problem running R (tried 1.8.0 and 1.7.1) under a fresh installed SuSE 
9.0 using default settings: I'm not able to send plots to the monitor. Only 
postscript graphs are produced in external files. When assigning 
options(device='X11') and then plotting I get the message "Error in X11() : 
X11 is not available".

Since this occured using the r-cran binary I tried to compile from source. 
However, the problem was not resolved. I do not have the competence for 
interpreting the output from the configure and make commands. Running the 
 ./configure  (also tried  ./configure --with-x) I read the following line:

checking for X... no

and at the bottom:

R is now configured for i686-pc-linux-gnu

? Source directory: ? ? ? ? ?.
? Installation directory: ? ?/usr/local

? C compiler: ? ? ? ? ? ? ? ?gcc -D__NO_MATH_INLINES -mieee-fp -g -O2
? C++ compiler: ? ? ? ? ? ? ?g++ -mieee-fp -g -O2
? Fortran compiler: ? ? ? ? ?g77 -mieee-fp -g -O2

? Interfaces supported:
? External libraries: ? ? ? ?readline
? Additional capabilities: ? PNG, JPEG, bzip2, PCRE
? Options enabled: ? ? ? ? ? R profiling

? Recommended packages: ? ? ?yes

Thankful for any help on this matter.



From bbeckage at uvm.edu  Tue Nov 11 17:34:10 2003
From: bbeckage at uvm.edu (Brian Beckage)
Date: Tue, 11 Nov 2003 11:34:10 -0500
Subject: [R] Calendar Time Series
Message-ID: <p06002005bbd6bdab4519@[132.198.177.56]>

Hello,

Does R have any facilities for calendar time series?  I'm working 
with a 40 year long, daily time series and I would like to have each 
datum associated with a calendar date.  I searched the R website and 
found several new packages for irregular time series but none for cts.

By the way, I just installed 1.8.0 on Mac OSX and the installation 
was effortless!  I also very much like having the option of using R 
on the Mac with Aqua or X11.  Thanks to all who have contributed to 
the R project!

Thanks for your help,
Brian



From etuka at stams.strath.ac.uk  Tue Nov 11 17:34:30 2003
From: etuka at stams.strath.ac.uk (Etuka Onono)
Date: Tue, 11 Nov 2003 16:34:30 +0000
Subject: [R] Installing and Loading RMySQL on OS X 2.8
Message-ID: <EC7EA657-1464-11D8-B20D-000A959D22C4@stams.strath.ac.uk>

Hello,

I have trouble installing and loading the RMySQL package on OS X 2.8.  
The package seems to install from source fine (using R package manager 
from within the R environment).  I have the following error when I try 
to load the package:

loading package: RMySQL
Error in dyn.load(x, as.logical(local), as.logical(now)) :
	unable to load shared library 
"/Users/etukaonono/Library/RAqua/library/RMySQL/libs/RMySQL.so":
   dlcompat: dyld: 
/Applications/StartR.app/RAqua.app/Contents/MacOS/RAqua Undefined 
symbols:
_getopt_long
Error in library(pkgs[i], character.only = TRUE) :
	.First.lib failed

If I uninstall the package and try running R CMD test RMySQL, I get the 
following error messages.  What should I be looking at to try and 
reolve these issues?

[Etuka-Ononos-Computer:~/desktop] etukaonono% R CMD check RMySQL* 
checking for working latex ... OK
* using log directory '/Users/etukaonono/Desktop/RMySQL.Rcheck'
* checking for file 'RMySQL/DESCRIPTION' ... OK
* checking if this is a source package ... OK

* Installing *source* package 'RMySQL' ...
loading cache ./config.cache
checking how to run the C preprocessor... (cached) cc -E 
-traditional-cpp
checking for mysql_init in -lmysqlclient... (cached) yes
checking for mysql.h... (cached) no
checking for /usr/local/include/mysql/mysql.h... (cached) no
checking for /usr/include/mysql/mysql.h... (cached) yes
creating ./config.status
creating src/Makevars
** libs
make: `RMySQL.so' is up to date.
** R
** inst
** save image
[1] TRUE
[1] "dbObjectId"
[1] "format"
[1] "show"
[1] "print"
[1] "MySQLObject"
[1] "MySQLDriver"
[1] "dbUnloadDriver"
[1] "dbGetInfo"
[1] "dbListConnections"
[1] "summary"
[1] "MySQLConnection"
[1] "dbConnect"
[1] "dbConnect"
[1] "dbConnect"
[1] "dbDisconnect"
[1] "dbSendQuery"
[1] "dbGetQuery"
[1] "dbGetException"
[1] "dbGetInfo"
[1] "dbListResults"
[1] "summary"
[1] "dbListTables"
[1] "dbReadTable"
[1] "dbWriteTable"
[1] "dbExistsTable"
[1] "dbRemoveTable"
[1] "dbListFields"
[1] "dbCommit"
[1] "dbRollback"
[1] "dbCallProc"
[1] "MySQLResult"
[1] "dbClearResult"
[1] "fetch"
[1] "fetch"
[1] "dbGetInfo"
[1] "dbGetStatement"
[1] "dbListFields"
[1] "dbColumnInfo"
[1] "dbGetRowsAffected"
[1] "dbGetRowCount"
[1] "dbHasCompleted"
[1] "dbGetException"
[1] "summary"
[1] "dbDataType"
[1] "make.db.names"
[1] "SQLKeywords"
[1] "isSQLKeyword"
[1] "dbApply"
[1] "dbApply"

** help
  >>> Building/Updating help pages for package 'RMySQL'
      Formats: text html latex example
   MySQL                             text    html    latex   example
   MySQLConnection-class             text    html    latex   example
   MySQLDriver-class                 text    html    latex   example
   MySQLObject-class                 text    html    latex   example
   MySQLResult-class                 text    html    latex   example
   S4R                               text    html    latex
   dbApply                           text    html    latex   example
   dbObjectId-class                  text    html    latex   example
   isIdCurrent                       text    html    latex   example
   mysqlDBApply                      text    html    latex   example
   mysqlSupport                      text    html    latex
   safe.write                        text    html    latex   example
* DONE (RMySQL)

* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking package dependencies ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :
         .First.lib failed
Execution halted
* checking for replacement functions with final arg not named 'value' 
... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :
         .First.lib failed
Execution halted
* checking Rd files ... OK
* checking for missing documentation entries ... ERROR
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc, 
character.only = TRUE, verbose = FALSE) :




Etuka Onono
Statistics and Modelling Science
Strathclyde University


-----------------------------------------------------------
Is The Clydesdale Bank ripping you off too?



From maechler at stat.math.ethz.ch  Tue Nov 11 17:40:12 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 11 Nov 2003 17:40:12 +0100
Subject: [R] A co-occurrence matrix
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE04@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE04@usrymx25.merck.com>
Message-ID: <16305.4332.983336.651095@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Tue, 11 Nov 2003 07:41:18 -0500 writes:

    AndyL> Does the following help?

    > group <- c(1, 2, 1, 1, 3)
    > outer(group, group, "==")
	  [,1]  [,2]  [,3]  [,4]  [,5]
    [1,]  TRUE FALSE  TRUE  TRUE FALSE
    [2,] FALSE  TRUE FALSE FALSE FALSE
    [3,]  TRUE FALSE  TRUE  TRUE FALSE
    [4,]  TRUE FALSE  TRUE  TRUE FALSE
    [5,] FALSE FALSE FALSE FALSE  TRUE
    > outer(group, group, "==") + 0  # Turn it into a numeric matrix.
	 [,1] [,2] [,3] [,4] [,5]
    [1,]    1    0    1    1    0
    [2,]    0    1    0    0    0
    [3,]    1    0    1    1    0
    [4,]    1    0    1    1    0
    [5,]    0    0    0    0    1

very good.  Note that for large matrices, you can save (a factor
2 of) space by using integer instead, i.e.

 > outer(group, group, "==") + 0:0  # Turn it into a *integer* matrix.
                                ==
or (maybe easier to understand):
  
  r <- outer(group, group, "==")
  storage.mode(r) <- "integer"  ## as.integer() drop's the matrix dim()!

For nice visual output, also consider symnum()
{where the ``lower = FALSE'' is not needed anymore in R-patched
 (or R-devel) for several weeks now} :

> symnum(outer(group, group, "=="), lower = FALSE)
              
[1,] | . | | .
[2,] . | . . .
[3,] | . | | .
[4,] | . | | .
[5,] . . . . |
> 

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From rossini at blindglobe.net  Tue Nov 11 17:39:24 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 11 Nov 2003 08:39:24 -0800
Subject: [R] sample size/power calc packages
In-Reply-To: <5.1.0.14.2.20031111074118.0201efb8@127.0.0.1> (John Fox's
	message of "Tue, 11 Nov 2003 07:55:07 -0500")
References: <85fzgvenq9.fsf@blindglobe.net> <85fzgvenq9.fsf@blindglobe.net>
	<5.1.0.14.2.20031111074118.0201efb8@127.0.0.1>
Message-ID: <85he1adflv.fsf@blindglobe.net>

John Fox <jfox at mcmaster.ca> writes:

> There is an extensive set of power-calculation macros in SAS, by Ralph
> O'Brien, at <http://www.bio.ri.ccf.org/power.html>. Apparently SAS
> Version 9.1 will have new procs power and glmpower, which will cover
> most of what is in these macros.

They are quite nice, and what we (well, one of the groups that I work
with) use for power calculations.  

The explicit example was that I needed to design a non-inferiority
trial using a geometric mean (titration-based assay) as the endpoint.

(similarly, we do a good bit of work with selection designs with
continuous and binary endpoints.  I've got some functions, but the
interface is ugly).

It was both easy enough to do (this is R :-) as well as annoying
enough to do, that I spent part of the day trying to see what was out
there.

Yet another thing to add to the list of projects to do.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From rpeng at jhsph.edu  Tue Nov 11 17:46:11 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 11 Nov 2003 11:46:11 -0500
Subject: [R] Compilation problem SuSE 9.0
In-Reply-To: <200311111733.13039.ueb901c@tninet.se>
References: <200311111733.13039.ueb901c@tninet.se>
Message-ID: <3FB11253.1040105@jhsph.edu>

I don't know much about SuSE but you probably don't have the X11 
development libraries installed.  You need those when compiling R from 
source.  I'm not sure why the CRAN binary didn't work though....

-roger

Sven Sandin wrote:
> Hi
> 
> I have problem running R (tried 1.8.0 and 1.7.1) under a fresh installed SuSE 
> 9.0 using default settings: I'm not able to send plots to the monitor. Only 
> postscript graphs are produced in external files. When assigning 
> options(device='X11') and then plotting I get the message "Error in X11() : 
> X11 is not available".
> 
> Since this occured using the r-cran binary I tried to compile from source. 
> However, the problem was not resolved. I do not have the competence for 
> interpreting the output from the configure and make commands. Running the 
>  ./configure  (also tried  ./configure --with-x) I read the following line:
> 
> checking for X... no
> 
> and at the bottom:
> 
> R is now configured for i686-pc-linux-gnu
> 
>   Source directory:          .
>   Installation directory:    /usr/local
> 
>   C compiler:                gcc -D__NO_MATH_INLINES -mieee-fp -g -O2
>   C++ compiler:              g++ -mieee-fp -g -O2
>   Fortran compiler:          g77 -mieee-fp -g -O2
> 
>   Interfaces supported:
>   External libraries:        readline
>   Additional capabilities:   PNG, JPEG, bzip2, PCRE
>   Options enabled:           R profiling
> 
>   Recommended packages:      yes
> 
> Thankful for any help on this matter.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From MSchwartz at medanalytics.com  Tue Nov 11 17:57:27 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 11 Nov 2003 10:57:27 -0600
Subject: [R] Compilation problem SuSE 9.0
In-Reply-To: <200311111733.13039.ueb901c@tninet.se>
References: <200311111733.13039.ueb901c@tninet.se>
Message-ID: <1068569846.4541.276.camel@localhost.localdomain>

On Tue, 2003-11-11 at 10:33, Sven Sandin wrote:
> Hi
> 
> I have problem running R (tried 1.8.0 and 1.7.1) under a fresh installed SuSE 
> 9.0 using default settings: I'm not able to send plots to the monitor. Only 
> postscript graphs are produced in external files. When assigning 
> options(device='X11') and then plotting I get the message "Error in X11() : 
> X11 is not available".
> 
> Since this occured using the r-cran binary I tried to compile from source. 
> However, the problem was not resolved. I do not have the competence for 
> interpreting the output from the configure and make commands. Running the 
>  ./configure  (also tried  ./configure --with-x) I read the following line:
> 
> checking for X... no
> 
> and at the bottom:
> 
> R is now configured for i686-pc-linux-gnu
> 
>   Source directory:          .
>   Installation directory:    /usr/local
> 
>   C compiler:                gcc -D__NO_MATH_INLINES -mieee-fp -g -O2
>   C++ compiler:              g++ -mieee-fp -g -O2
>   Fortran compiler:          g77 -mieee-fp -g -O2
> 
>   Interfaces supported:
>   External libraries:        readline
>   Additional capabilities:   PNG, JPEG, bzip2, PCRE
>   Options enabled:           R profiling
> 
>   Recommended packages:      yes
> 
> Thankful for any help on this matter.


That error usually indicates that you do not have the X development
source code files and headers installed. You would need those in order
to compile R from source.

That typically should not be a problem with the pre-compiled binaries
however.

HTH,

Marc Schwartz



From p.b.pynsent at bham.ac.uk  Tue Nov 11 18:36:34 2003
From: p.b.pynsent at bham.ac.uk (p.b.pynsent)
Date: Tue, 11 Nov 2003 17:36:34 +0000
Subject: [R] animated plot 
In-Reply-To: <E1AJVyc-0000cd-00@vimb2.rdg.ac.uk>
Message-ID: <98677080-146D-11D8-B776-003065F42152@bham.ac.uk>

If you can do your analysis on an Apple then there are two bits of 
software that might be helpful.
1) GraphicsConverter by Lemke Software ($30 shareware but comes free 
with some Macs) will automatically join together many types of image 
files to produce a QuickTime movie. Simply dump the images into to a 
folder getting R to update the name  so the list file order is your 
time order. Then a single command will do the job.
2) iMovie (free) will allow you to drag and drop say .pdfs  files into 
a movie. This programme gives you considerable control over things like 
the duration of each frame and the zoom factor but may be rather time 
consuming for your purpose.

I would probably use both, joining  the files with GraphicsConverter 
and editing the movie with iMovie.

Whatever you do I think you will need a few Gigabytes of disk space 
depending on your image and video resolution/compression.


On Tuesday, November 11, 2003, at 10:42  am, Jesus Fernandez Galvez 
wrote:

> Thanks for you comments,
>
> I am visualising 4 months time series at 30 minutes intervals so it is
> impossible to create all this set of images (*.png, *.jpg, *.bmp,?). 
> With
> R, I can change the speed of visualisation but I think I would need  a
> screengrab tool to save the sequence. I manage to save as .pdf and the 
> graph
> moves! But the file is huge. Could you please shedding some light on 
> how to
> find screengrab tools (name of free software if possible)
>
> Thanks,
>
> Jesus
>
>
>
> -------------------
>> It's better to save in png or bmp than jpeg unless these are image() 
>> plots
>
>> (and maybe even then).
>>
>> There are lots of tools to take a series of bitmapped plots and make 
>> an
>> animation from them.
>>
>> A more elegant way is to use a screengrab tool which can grep a video
>> clip of an animation running in a R graphics window.
>>
>> On Tue, 11 Nov 2003, antonio rodriguez wrote:
>>
>>> Hi Jesus,
>>>
>>> Don't know if in R this is possible, but on a Linux machine you can 
>>> do
> the
>>> following (no very elegant): save your individual images (i.e.: jan,
> feb,
>>> march, ...)in .jpeg format, then with some image manager package 
>>> (i.e.
>>> Imagemagic) transfrom to .gif, and, finally, use whirlgif to paste in
> one
>>> file all your newly created individuals files (jan.gif, feb.gif,...),
> and
>>> you will get an animated plot.
>>>
>>> Saludos!
>>>
>>> Antonio Rodriguez
>>>
>>>> -----Mensaje original-----
>>>> De: r-help-bounces at stat.math.ethz.ch
>>>> [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Jesus 
>>>> Fernandez
>>>> Galvez
>>>> Enviado el: lunes, 10 de noviembre de 2003 17:36
>>>> Para: r-help at stat.math.ethz.ch
>>>> Asunto: [R] animated plot
>>>>
>>>>
>>>> Dear colleagues,
>>>>
>>>> Is there any way of saving an animated plot with R? For instance,
>>>> any format
>>>> that could be read by Microsoft windows media or whatever.
>>>>
>>>> Cheers,
>>>>
>>>> Jesus
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>> ---
>>>> Incoming mail is certified Virus Free.
>>>> Checked by AVG anti-virus system (http://www.grisoft.com).
>>>> Version: 6.0.536 / Virus Database: 331 - Release Date: 03/11/2003
>>>>
>>> ---
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>>>
>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From brahm at alum.mit.edu  Tue Nov 11 18:58:24 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 11 Nov 2003 12:58:24 -0500
Subject: [R] += assignment operator
Message-ID: <16305.9024.588853.424895@arbres1a.fmr.com>

The thread "Finding the name ob an object" gave me an idea about how to write
an assignment operator like C's "+=":

"%+=%" <- function(a, b) {
  as <- deparse(substitute(a))
  bs <- deparse(substitute(b))
  st <- paste(as, "<-", as, "+", bs)
  eval.parent(parse(text=st), 2)
}

R> xx <- matrix(1:9, 3,3)
R> xx[2, which(xx[2, ] < 6)] %+=% 100
R> xx
        [,1] [,2] [,3]
   [1,]    1    4    7
   [2,]  102  105    8
   [3,]    3    6    9

Anyone have any better ideas on building this kind of operator?  It would be
better if the condition [which(...)] were only evaluated once.  Bonus points if
you can make %*=%, %-=%, etc. all in one fell swoop.
-- 
                              -- David Brahm (brahm at alum.mit.edu)



From B.Rowlingson at lancaster.ac.uk  Tue Nov 11 18:58:52 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 11 Nov 2003 17:58:52 +0000
Subject: [R] animated plot
In-Reply-To: <98677080-146D-11D8-B776-003065F42152@bham.ac.uk>
References: <98677080-146D-11D8-B776-003065F42152@bham.ac.uk>
Message-ID: <3FB1235C.2010107@lancaster.ac.uk>

p.b.pynsent wrote:


> I would probably use both, joining  the files with GraphicsConverter and 
> editing the movie with iMovie.
> 
> Whatever you do I think you will need a few Gigabytes of disk space 
> depending on your image and video resolution/compression.


  On a Unix/Linux box you could use im2avi:

http://cpbotha.net/im2avi.html

  It uses avifile to write the movie files, so can use a wide range of 
codecs (file formats):

http://avifile.sourceforge.net/

But one question remains: Is there a movie player with a fine-grain 
fast/slow speed control? For the usual platforms..

I did once generate an MPG from Splus graphics using screen captures and 
mpegencode software on an old Sun Sparcstation.

Baz



From edd at debian.org  Tue Nov 11 19:24:04 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 11 Nov 2003 12:24:04 -0600
Subject: [R] Calendar Time Series
In-Reply-To: <p06002005bbd6bdab4519@[132.198.177.56]>
References: <p06002005bbd6bdab4519@[132.198.177.56]>
Message-ID: <20031111182403.GA1087@sonny.eddelbuettel.com>

On Tue, Nov 11, 2003 at 11:34:10AM -0500, Brian Beckage wrote:
> Does R have any facilities for calendar time series?  I'm working 
> with a 40 year long, daily time series and I would like to have each 
> datum associated with a calendar date.  I searched the R website and 

Did you look at  help(DateTimeClasses)  as well as the corresponding R News
article?

R has excellent facilities to convert human-readable date formats into an
internal representation which can be transformed further using appropriate
cut, seq, round, ... methods, basic comparison, indexing and arithmetic.  

To paraphrase the MasterCard ads: "Having R for this: priceless". 

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From kjetil at entelnet.bo  Tue Nov 11 20:09:20 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Tue, 11 Nov 2003 15:09:20 -0400
Subject: [R] sample size/power calc packages
In-Reply-To: <5.1.0.14.2.20031111074118.0201efb8@127.0.0.1>
References: <x2d6bzywfe.fsf@biostat.ku.dk>
Message-ID: <3FB0FBA0.15279.C22DF@localhost>

On 11 Nov 2003 at 7:55, John Fox wrote:

I have uploaded to CRAN a port of the asypow package for 
S-Plus, but I am not sure if it is visible there yet.

Kjetil Halvorsen

> Dear Peter,
> 
> At 12:30 PM 11/11/2003 +0100, Peter Dalgaard wrote:
> >rossini at blindglobe.net (A.J. Rossini) writes:
> >
> > > For various reasons, I spent part of my time today looking at sample
> > > size and power calculation tools (don't ask, don't tell...).  This
> > > seems to be one area that R is incredibly weak in (well, nearly all
> > > stat packages, except perhaps specialized tools and SAS); sure, there
> > > are a number of functions in various packages:
> > >
> > >           base, statmod, Hmisc
> > >
> > > Have I missed something?  (I would've expected at least one sequential
> > > computation, or non-standard design, but apparently there are none, or
> > > I missed it).
> > >
> > > I'd appreciate hearing about work that I've missed...
> >
> >Is SAS particularly hot? I've just been explaining to people how to
> >cheat SAS Analyst into letting the Two-Sample t-Test sample-sizer do
> >binomial proportions with a fudged SD.
> 
> There is an extensive set of power-calculation macros in SAS, by Ralph 
> O'Brien, at <http://www.bio.ri.ccf.org/power.html>. Apparently SAS Version 
> 9.1 will have new procs power and glmpower, which will cover most of what 
> is in these macros.
> 
> Regards,
>   John
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ryszard.czerminski at pharma.novartis.com  Tue Nov 11 20:28:05 2003
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Tue, 11 Nov 2003 14:28:05 -0500
Subject: [R] symbolic column extraction ?
Message-ID: <OFA0E11F93.3A132A29-ON85256DDB.0069CF5B-85256DDB.006B0751@EU.novartis.net>

I have a data frame (df) with colums x, y and z.
e.g.  df <- data.frame(x = sample(4), y = sample(4), z = sample(4))
I can extract column z by: df$z or df[3]
I can also extract columns x,y by: df[1:2] or by df[-3].

Is it possible to extract x,y columns in a "symbolic" fashion i.e.
by equivalent of df[-z] (which is illegal) ???

Or alternativeley, is there an equivalent of "index" function,
which would return index of the column given name ?



From bill.shipley at usherbrooke.ca  Tue Nov 11 20:38:56 2003
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Tue, 11 Nov 2003 14:38:56 -0500
Subject: [R] help specifying error structure in lme
Message-ID: <025c01c3a88b$725995a0$8d1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031111/f5826a93/attachment.pl

From mandevip at uaslp.mx  Tue Nov 11 20:51:11 2003
From: mandevip at uaslp.mx (Peter B. Mandeville)
Date: Tue, 11 Nov 2003 13:51:11 -0600
Subject: [R] cor
Message-ID: <5.1.0.14.0.20031111134651.023c77e0@uaslp.mx>

Greetings:

It would seem to me that the three arguments "a", "c" and "p" ought to 
produce the same result with a data frame that doesn't have any missing 
data which is not the case. What am I doing wrong or what don't I understand?

 > tmp <- data.frame(vol,con,mot,esp,pri,sec)
 > tmp
     vol con mot esp pri sec
1  1.00 120  90  78  21   1
2  0.50  60  25  80  15   5
3  0.50  50  40  52  46   2
4  1.00 257  60  78  20   2
5  0.50 150  85  85  11   4
6  0.50 113   5  79  18   3
7  0.50 117  60  67  30   3
8  1.00 193  60  74  23   3
9  0.50 139  60  50  46   4
10 0.50 144  70  67  31   2
11 1.00 127  80  47  41  12
12 0.50 200  80  42  40  18
13 0.75 106  40  58  33   9
14 0.50 127  30  61  28  11
15 0.50 200  50  51  45   4
16 1.00 229  80  70  27   3
17 0.75 207  50  62  28  10
18 0.25  63  30  60  35   5
19 1.00  58  80  67  29   4
 > cor(tmp)
             vol         con         mot         esp         pri         sec
vol  1.00000000  0.36263681  0.52616642  0.21163185 -0.21149234 -0.09813069
con  0.36263681  1.00000000  0.34665834  0.02016283 -0.07877831  0.12922310
mot  0.52616642  0.34665834  1.00000000 -0.04678632  0.04038370  0.03675419
esp  0.21163185  0.02016283 -0.04678632  1.00000000 -0.94112303 -0.60128659
pri -0.21149234 -0.07877831  0.04038370 -0.94112303  1.00000000  0.29576002
sec -0.09813069  0.12922310  0.03675419 -0.60128659  0.29576002  1.00000000
 > cor(tmp,use="a")
             vol         con         mot         esp         pri         sec
vol  1.00000000  0.36263681  0.52616642  0.21163185 -0.21149234 -0.09813069
con  0.36263681  1.00000000  0.34665834  0.02016283 -0.07877831  0.12922310
mot  0.52616642  0.34665834  1.00000000 -0.04678632  0.04038370  0.03675419
esp  0.21163185  0.02016283 -0.04678632  1.00000000 -0.94112303 -0.60128659
pri -0.21149234 -0.07877831  0.04038370 -0.94112303  1.00000000  0.29576002
sec -0.09813069  0.12922310  0.03675419 -0.60128659  0.29576002  1.00000000
 > cor(tmp,use="c")
             vol         con         mot         esp         pri         sec
vol  1.00000000  0.36263681  0.52616642  0.21163185 -0.21149234 -0.09813069
con  0.36263681  1.00000000  0.34665834  0.02016283 -0.07877831  0.12922310
mot  0.52616642  0.34665834  1.00000000 -0.04678632  0.04038370  0.03675419
esp  0.21163185  0.02016283 -0.04678632  1.00000000 -0.94112303 -0.60128659
pri -0.21149234 -0.07877831  0.04038370 -0.94112303  1.00000000  0.29576002
sec -0.09813069  0.12922310  0.03675419 -0.60128659  0.29576002  1.00000000
 > cor(tmp,use="p")
           vol         con        mot         esp         pri         sec
vol 1.0000000  0.35898321 0.33585184  0.26418611  0.31817707  0.34311708
con 0.3589832  0.99240991 0.34399506  0.02035910 -0.07698392  0.12891702
mot 0.3358518  0.34399506 0.98480785  0.04365569  0.08719418  0.05687228
esp 0.2641861  0.02035910 0.04365569  0.99985490 -0.85247286 -0.55912698
pri 0.3181771 -0.07698392 0.08719418 -0.85247286  0.98445398  0.30189124
sec 0.3431171  0.12891702 0.05687228 -0.55912698  0.30189124  0.95034447

Thank you very much,

Peter B.



From ripley at stats.ox.ac.uk  Tue Nov 11 21:06:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Nov 2003 20:06:57 +0000 (GMT)
Subject: [R] cor
In-Reply-To: <5.1.0.14.0.20031111134651.023c77e0@uaslp.mx>
Message-ID: <Pine.LNX.4.44.0311112006001.3492-100000@gannet.stats>

What version of R?  From the NEWS file for 1.8.1 alpha:

    o   cor(<matrix>, use = "pairwise") gave wrong result in 1.8.0 (only).
        (PR#4646)

On Tue, 11 Nov 2003, Peter B. Mandeville wrote:

> Greetings:
> 
> It would seem to me that the three arguments "a", "c" and "p" ought to 
> produce the same result with a data frame that doesn't have any missing 
> data which is not the case. What am I doing wrong or what don't I understand?
> 
>  > tmp <- data.frame(vol,con,mot,esp,pri,sec)
>  > tmp
>      vol con mot esp pri sec
> 1  1.00 120  90  78  21   1
> 2  0.50  60  25  80  15   5
> 3  0.50  50  40  52  46   2
> 4  1.00 257  60  78  20   2
> 5  0.50 150  85  85  11   4
> 6  0.50 113   5  79  18   3
> 7  0.50 117  60  67  30   3
> 8  1.00 193  60  74  23   3
> 9  0.50 139  60  50  46   4
> 10 0.50 144  70  67  31   2
> 11 1.00 127  80  47  41  12
> 12 0.50 200  80  42  40  18
> 13 0.75 106  40  58  33   9
> 14 0.50 127  30  61  28  11
> 15 0.50 200  50  51  45   4
> 16 1.00 229  80  70  27   3
> 17 0.75 207  50  62  28  10
> 18 0.25  63  30  60  35   5
> 19 1.00  58  80  67  29   4
>  > cor(tmp)
>              vol         con         mot         esp         pri         sec
> vol  1.00000000  0.36263681  0.52616642  0.21163185 -0.21149234 -0.09813069
> con  0.36263681  1.00000000  0.34665834  0.02016283 -0.07877831  0.12922310
> mot  0.52616642  0.34665834  1.00000000 -0.04678632  0.04038370  0.03675419
> esp  0.21163185  0.02016283 -0.04678632  1.00000000 -0.94112303 -0.60128659
> pri -0.21149234 -0.07877831  0.04038370 -0.94112303  1.00000000  0.29576002
> sec -0.09813069  0.12922310  0.03675419 -0.60128659  0.29576002  1.00000000
>  > cor(tmp,use="a")
>              vol         con         mot         esp         pri         sec
> vol  1.00000000  0.36263681  0.52616642  0.21163185 -0.21149234 -0.09813069
> con  0.36263681  1.00000000  0.34665834  0.02016283 -0.07877831  0.12922310
> mot  0.52616642  0.34665834  1.00000000 -0.04678632  0.04038370  0.03675419
> esp  0.21163185  0.02016283 -0.04678632  1.00000000 -0.94112303 -0.60128659
> pri -0.21149234 -0.07877831  0.04038370 -0.94112303  1.00000000  0.29576002
> sec -0.09813069  0.12922310  0.03675419 -0.60128659  0.29576002  1.00000000
>  > cor(tmp,use="c")
>              vol         con         mot         esp         pri         sec
> vol  1.00000000  0.36263681  0.52616642  0.21163185 -0.21149234 -0.09813069
> con  0.36263681  1.00000000  0.34665834  0.02016283 -0.07877831  0.12922310
> mot  0.52616642  0.34665834  1.00000000 -0.04678632  0.04038370  0.03675419
> esp  0.21163185  0.02016283 -0.04678632  1.00000000 -0.94112303 -0.60128659
> pri -0.21149234 -0.07877831  0.04038370 -0.94112303  1.00000000  0.29576002
> sec -0.09813069  0.12922310  0.03675419 -0.60128659  0.29576002  1.00000000
>  > cor(tmp,use="p")
>            vol         con        mot         esp         pri         sec
> vol 1.0000000  0.35898321 0.33585184  0.26418611  0.31817707  0.34311708
> con 0.3589832  0.99240991 0.34399506  0.02035910 -0.07698392  0.12891702
> mot 0.3358518  0.34399506 0.98480785  0.04365569  0.08719418  0.05687228
> esp 0.2641861  0.02035910 0.04365569  0.99985490 -0.85247286 -0.55912698
> pri 0.3181771 -0.07698392 0.08719418 -0.85247286  0.98445398  0.30189124
> sec 0.3431171  0.12891702 0.05687228 -0.55912698  0.30189124  0.95034447
> 
> Thank you very much,
> 
> Peter B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Tue Nov 11 21:26:23 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 11 Nov 2003 15:26:23 -0500 (EST)
Subject: [R] Calendar Time Series
Message-ID: <20031111202623.84D5639AE@mprdmxin.myway.com>



Using the chron package you could create your time
series like this (assuming it starts at Jan 25, 1999):

   z <- ts(rnorm(25),start=as.numeric(chron("01/25/99")))

and then get back the times like this:

   chron(time(z))

To plot it:

   plot(chron(time(z)),z)

---

Date: Tue, 11 Nov 2003 11:34:10 -0500 
From: Brian Beckage <bbeckage at uvm.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Calendar Time Series 

 
 
Hello,

Does R have any facilities for calendar time series? I'm working 
with a 40 year long, daily time series and I would like to have each 
datum associated with a calendar date. I searched the R website and 
found several new packages for irregular time series but none for cts.

By the way, I just installed 1.8.0 on Mac OSX and the installation 
was effortless! I also very much like having the option of using R 
on the Mac with Aqua or X11. Thanks to all who have contributed to 
the R project!

Thanks for your help,
Brian

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.murrell at auckland.ac.nz  Tue Nov 11 22:02:23 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 12 Nov 2003 10:02:23 +1300
Subject: [R] animated plot
References: <E1AJVyc-0000cd-00@vimb2.rdg.ac.uk>
Message-ID: <3FB14E5F.6070306@stat.auckland.ac.nz>

Hi


Jesus Fernandez Galvez wrote:
> Thanks for you comments,
> 
> I am visualising 4 months time series at 30 minutes intervals so it is
> impossible to create all this set of images (*.png, *.jpg, *.bmp,?). With
> R, I can change the speed of visualisation but I think I would need  a
> screengrab tool to save the sequence. I manage to save as .pdf and the graph
> moves! But the file is huge. Could you please shedding some light on how to
> find screengrab tools (name of free software if possible)


If your animations are only changing the data symbols (or lines) (and if 
SVG is an acceptable format), you could try using my (experimental!) 
gridSVG package (I expect an SVG file would be a lot smaller).

If you can generate a tiny version from some of your data and send me a 
file showing the sort of animation you are doing, I can have a go at 
mocking up an SVG version.

Paul


> -------------------
> 
>>It's better to save in png or bmp than jpeg unless these are image() plots
> 
> 
>>(and maybe even then).
>>
>>There are lots of tools to take a series of bitmapped plots and make an 
>>animation from them.
>>
>>A more elegant way is to use a screengrab tool which can grep a video 
>>clip of an animation running in a R graphics window.
>>
>>On Tue, 11 Nov 2003, antonio rodriguez wrote:
>>
>>
>>>Hi Jesus,
>>>
>>>Don't know if in R this is possible, but on a Linux machine you can do
>>
> the
> 
>>>following (no very elegant): save your individual images (i.e.: jan,
>>
> feb,
> 
>>>march, ...)in .jpeg format, then with some image manager package (i.e.
>>>Imagemagic) transfrom to .gif, and, finally, use whirlgif to paste in
>>
> one
> 
>>>file all your newly created individuals files (jan.gif, feb.gif,...),
>>
> and
> 
>>>you will get an animated plot.
>>>
>>>Saludos!
>>>
>>>Antonio Rodriguez
>>>
>>>
>>>>-----Mensaje original-----
>>>>De: r-help-bounces at stat.math.ethz.ch
>>>>[mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Jesus Fernandez
>>>>Galvez
>>>>Enviado el: lunes, 10 de noviembre de 2003 17:36
>>>>Para: r-help at stat.math.ethz.ch
>>>>Asunto: [R] animated plot
>>>>
>>>>
>>>>Dear colleagues,
>>>>
>>>>Is there any way of saving an animated plot with R? For instance,
>>>>any format
>>>>that could be read by Microsoft windows media or whatever.
>>>>
>>>>Cheers,
>>>>
>>>>Jesus
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>---
>>>>Incoming mail is certified Virus Free.
>>>>Checked by AVG anti-virus system (http://www.grisoft.com).
>>>>Version: 6.0.536 / Virus Database: 331 - Release Date: 03/11/2003
>>>>
>>>
>>>---
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>>>
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From p.dalgaard at biostat.ku.dk  Tue Nov 11 22:42:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Nov 2003 22:42:39 +0100
Subject: [R] += assignment operator
In-Reply-To: <16305.9024.588853.424895@arbres1a.fmr.com>
References: <16305.9024.588853.424895@arbres1a.fmr.com>
Message-ID: <x2llqmtwds.fsf@biostat.ku.dk>

David Brahm <brahm at alum.mit.edu> writes:

> The thread "Finding the name ob an object" gave me an idea about how to write
> an assignment operator like C's "+=":
> 
> "%+=%" <- function(a, b) {
>   as <- deparse(substitute(a))
>   bs <- deparse(substitute(b))
>   st <- paste(as, "<-", as, "+", bs)
>   eval.parent(parse(text=st), 2)
> }
> 
> R> xx <- matrix(1:9, 3,3)
> R> xx[2, which(xx[2, ] < 6)] %+=% 100
> R> xx
>         [,1] [,2] [,3]
>    [1,]    1    4    7
>    [2,]  102  105    8
>    [3,]    3    6    9
> 
> Anyone have any better ideas on building this kind of operator?  It would be
> better if the condition [which(...)] were only evaluated once.  Bonus points if
> you can make %*=%, %-=%, etc. all in one fell swoop.

I don't think either of those are realistically possible at the R
level. Even at the C level, it would probably be a hack, but so is the
way we handle complex assignments (like foo$i[j][[k]] <- fum) already.

However, paste() always looks wrong to me:

"%+=%" <- function(a, b) eval.parent(substitute(a <- a + b))


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From naumov at acsu.buffalo.edu  Tue Nov 11 23:05:16 2003
From: naumov at acsu.buffalo.edu (Aleksey Naumov)
Date: Tue, 11 Nov 2003 17:05:16 -0500
Subject: [R] Test for new page
Message-ID: <200311111705.16216.naumov@acsu.buffalo.edu>

Dear R experts,

I am writing a multi-page PDF file and would like to put a header on each 
page. Is there a way to test a graphic device to see if a new page is started 
(so that I know when to write the header)? 
I could simply count the plots made (each page has the same number of plots), 
but wanted to see if a more general solution is available.

Thank you,

Aleksey

-- 
Aleksey Naumov
GIS Analyst
Center for Health and Social Research
Buffalo State College



From p.murrell at auckland.ac.nz  Tue Nov 11 23:49:10 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 12 Nov 2003 11:49:10 +1300
Subject: [R] Test for new page
References: <200311111705.16216.naumov@acsu.buffalo.edu>
Message-ID: <3FB16766.3040507@stat.auckland.ac.nz>

Hi


Aleksey Naumov wrote:
> Dear R experts,
> 
> I am writing a multi-page PDF file and would like to put a header on each 
> page. Is there a way to test a graphic device to see if a new page is started 
> (so that I know when to write the header)?


Sorry.  Not that I can think of.

Paul


> I could simply count the plots made (each page has the same number of plots), 
> but wanted to see if a more general solution is available.
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From MSchwartz at medanalytics.com  Wed Nov 12 00:08:15 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 11 Nov 2003 17:08:15 -0600
Subject: [R] Test for new page
In-Reply-To: <3FB16766.3040507@stat.auckland.ac.nz>
References: <200311111705.16216.naumov@acsu.buffalo.edu>
	<3FB16766.3040507@stat.auckland.ac.nz>
Message-ID: <1068592095.4541.313.camel@localhost.localdomain>

On Tue, 2003-11-11 at 16:49, Paul Murrell wrote:
> Hi
> 
> 
> Aleksey Naumov wrote:
> > Dear R experts,
> > 
> > I am writing a multi-page PDF file and would like to put a header on each 
> > page. Is there a way to test a graphic device to see if a new page is started 
> > (so that I know when to write the header)?
> 
> 
> Sorry.  Not that I can think of.
> 
> Paul
> 
> 
> > I could simply count the plots made (each page has the same number of plots), 
> > but wanted to see if a more general solution is available.


I was trying to think of a way but could not either.

You may be best served by:

1. Generating your plots as EPS files and then import them into your
favorite page layout/document processing application to format your
pages and associated text. Under Linux you could then print the document
to a PS file and then convert to PDF using ps2pdf. A few more steps, but
greater flexibility.

2. Consider using SWeave, which enables you to combine the power of R's
output and LaTeX together. Here is a link where there is a FAQ and
associated documentation:

http://www.ci.tuwien.ac.at/~leisch/Sweave/

HTH,

Marc Schwartz



From ray at mcs.vuw.ac.nz  Wed Nov 12 00:27:58 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Wed, 12 Nov 2003 12:27:58 +1300 (NZDT)
Subject: [R] Test for new page
Message-ID: <200311112327.hABNRwM6028243@tahi.mcs.vuw.ac.nz>

Marc Schwartz <MSchwartz at medanalytics.com> wrote:
> On Tue, 2003-11-11 at 16:49, Paul Murrell wrote:
> > Hi
> > 
> > 
> > Aleksey Naumov wrote:
> > > Dear R experts,
> > > 
> > > I am writing a multi-page PDF file and would like to put a header on each 
> > > page. Is there a way to test a graphic device to see if a new page is started 
> > > (so that I know when to write the header)?
> > 
> > 
> > Sorry.  Not that I can think of.
> > 
> > Paul
> > 
> > 
> > > I could simply count the plots made (each page has the same number of plots), 
> > > but wanted to see if a more general solution is available.
> 
> 
> I was trying to think of a way but could not either.
> 
It's not clear what you want as the "header", but if it is the same on
each page, then using mtext("Header", outer=TRUE) (after a suitable
par(oma=c(0, 0, 1, 0))), you can just write the header after every plot.

Ray



From tmurph6 at po-box.mcgill.ca  Wed Nov 12 00:28:24 2003
From: tmurph6 at po-box.mcgill.ca (tmurph6@po-box.mcgill.ca)
Date: Tue, 11 Nov 2003 18:28:24 -0500
Subject: [R] HMisc describe -- error with dates
Message-ID: <1068593304.3fb170987ca93@webmail.mcgill.ca>

Hello,

I am trying to use HMisc describe on a data frame. I have specified certain
variables as dates using, for example:

df1$aidsdate       <- dates(aidsdate,format="day.mon.year", origin=c(month = 1,
day = 1, year = 1960))

When I use describe on the dataframe I get this error:

Error in Ops.dates(weights, x) : * not defined for chron objects

Has anyone had this problem? I had used the same method with an older version of
R and HMisc and it worked. 

Should be be formatting date variables differently?

Thank you!

Sincerely,
Tanya Murphy


-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From davidD at qimr.edu.au  Wed Nov 12 00:59:01 2003
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 12 Nov 2003 09:59:01 +1000 (EST)
Subject: [R] Re: R-help Digest, Vol 9, Issue 11
In-Reply-To: <200311111116.hABBBPQ0022236@hypatia.math.ethz.ch>
References: <200311111116.hABBBPQ0022236@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0311120954210.21351@orpheus.qimr.edu.au>

Tony Rossini wrote:
>
> For various reasons, I spent part of my time today looking at sample
> size and power calculation tools (don't ask, don't tell...).  This
> seems to be one area that R is incredibly weak in (well, nearly all
> stat packages, except perhaps specialized tools and SAS); sure, there
> are a number of functions in various packages:
>
>           base, statmod, Hmisc
>
> Have I missed something?  (I would've expected at least one sequential
> computation, or non-standard design, but apparently there are none, or
> I missed it).
>
David Clayton has a couple of little functions on his website, one for
sequential analysis IIRC.  I have some on my website for genetic
association (TDT and case-control) and linkage (variance components)
analysis.


| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From feh3k at spamcop.net  Wed Nov 12 01:32:02 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 11 Nov 2003 19:32:02 -0500
Subject: [R] HMisc describe -- error with dates
In-Reply-To: <1068593304.3fb170987ca93@webmail.mcgill.ca>
References: <1068593304.3fb170987ca93@webmail.mcgill.ca>
Message-ID: <20031111193202.369fcebf.feh3k@spamcop.net>

On Tue, 11 Nov 2003 18:28:24 -0500
tmurph6 at po-box.mcgill.ca wrote:

> Hello,
> 
> I am trying to use HMisc describe on a data frame. I have specified
> certain variables as dates using, for example:
> 
> df1$aidsdate       <- dates(aidsdate,format="day.mon.year",
> origin=c(month = 1, day = 1, year = 1960))
> 
> When I use describe on the dataframe I get this error:
> 
> Error in Ops.dates(weights, x) : * not defined for chron objects
> 
> Has anyone had this problem? I had used the same method with an older
> version of R and HMisc and it worked. 
> 
> Should be be formatting date variables differently?
> 
> Thank you!
> 
> Sincerely,
> Tanya Murphy
> 

In recent versions, describe for R recognizes date/times by one of the
following classes: 'POSIXt','POSIXct','chron'.  If you really need to use
another date format I could be talked into extending the code for that if
you can remind me where dates( ) is found.  -Frank

---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From tmurph6 at po-box.mcgill.ca  Wed Nov 12 02:06:38 2003
From: tmurph6 at po-box.mcgill.ca (tmurph6@po-box.mcgill.ca)
Date: Tue, 11 Nov 2003 20:06:38 -0500
Subject: [R] HMisc describe -- error with dates
In-Reply-To: <20031111193202.369fcebf.feh3k@spamcop.net>
References: <1068593304.3fb170987ca93@webmail.mcgill.ca>
	<20031111193202.369fcebf.feh3k@spamcop.net>
Message-ID: <1068599198.3fb1879ed2dc2@webmail.mcgill.ca>

I am using the chron package. I have no preference for which function I use. I
just want the most reliable format for HMisc functions and general plotting. I
like the ddmonyyy formats (e.g. 11NOV2003). What would you recommend?

Thank you!

Quoting Frank E Harrell Jr <feh3k at spamcop.net>:

> On Tue, 11 Nov 2003 18:28:24 -0500
> tmurph6 at po-box.mcgill.ca wrote:
> 
> > Hello,
> > 
> > I am trying to use HMisc describe on a data frame. I have specified
> > certain variables as dates using, for example:
> > 
> > df1$aidsdate       <- dates(aidsdate,format="day.mon.year",
> > origin=c(month = 1, day = 1, year = 1960))
> > 
> > When I use describe on the dataframe I get this error:
> > 
> > Error in Ops.dates(weights, x) : * not defined for chron objects
> > 
> > Has anyone had this problem? I had used the same method with an older
> > version of R and HMisc and it worked. 
> > 
> > Should be be formatting date variables differently?
> > 
> > Thank you!
> > 
> > Sincerely,
> > Tanya Murphy
> > 
> 
> In recent versions, describe for R recognizes date/times by one of the
> following classes: 'POSIXt','POSIXct','chron'.  If you really need to use
> another date format I could be talked into extending the code for that if
> you can remind me where dates( ) is found.  -Frank
> 
> ---
> Frank E Harrell Jr    Professor and Chair            School of Medicine
>                       Department of Biostatistics    Vanderbilt University
> 




-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From ggrothendieck at myway.com  Wed Nov 12 02:40:50 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 11 Nov 2003 20:40:50 -0500 (EST)
Subject: [R] HMisc describe -- error with dates
Message-ID: <20031112014050.6D7A8394F@mprdmxin.myway.com>



dates is part of chron.  There may be something wrong in 
Hmisc's detection of chron objects.

> chron(1)
[1] 01/02/70

> isChron(chron(1))
FALSE

---
 
Date: Tue, 11 Nov 2003 20:06:38 -0500 
From: <tmurph6 at po-box.mcgill.ca>
To: Frank E Harrell Jr <feh3k at spamcop.net> 
Cc: <r-help at stat.math.ethz.ch> 
Subject: Re: [R] HMisc describe -- error with dates 

 
 
I am using the chron package. I have no preference for which function I use. I
just want the most reliable format for HMisc functions and general plotting. I
like the ddmonyyy formats (e.g. 11NOV2003). What would you recommend?

Thank you!

Quoting Frank E Harrell Jr <feh3k at spamcop.net>:

> On Tue, 11 Nov 2003 18:28:24 -0500
> tmurph6 at po-box.mcgill.ca wrote:
> 
> > Hello,
> > 
> > I am trying to use HMisc describe on a data frame. I have specified
> > certain variables as dates using, for example:
> > 
> > df1$aidsdate <- dates(aidsdate,format="day.mon.year",
> > origin=c(month = 1, day = 1, year = 1960))
> > 
> > When I use describe on the dataframe I get this error:
> > 
> > Error in Ops.dates(weights, x) : * not defined for chron objects
> > 
> > Has anyone had this problem? I had used the same method with an older
> > version of R and HMisc and it worked. 
> > 
> > Should be be formatting date variables differently?
> > 
> > Thank you!
> > 
> > Sincerely,
> > Tanya Murphy
> > 
> 
> In recent versions, describe for R recognizes date/times by one of the
> following classes: 'POSIXt','POSIXct','chron'. If you really need to use
> another date format I could be talked into extending the code for that if
> you can remind me where dates( ) is found. -Frank
> 
> ---
> Frank E Harrell Jr Professor and Chair School of Medicine
> Department of Biostatistics Vanderbilt University
>



From feh3k at spamcop.net  Wed Nov 12 03:25:21 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 11 Nov 2003 21:25:21 -0500
Subject: [R] HMisc describe -- error with dates
In-Reply-To: <20031112014050.6D7A8394F@mprdmxin.myway.com>
References: <20031112014050.6D7A8394F@mprdmxin.myway.com>
Message-ID: <20031111212521.1d6dda5e.feh3k@spamcop.net>

On Tue, 11 Nov 2003 20:40:50 -0500 (EST)
"Gabor Grothendieck" <ggrothendieck at myway.com> wrote:

> 
> 
> dates is part of chron.  There may be something wrong in 
> Hmisc's detection of chron objects.
> 
> > chron(1)
> [1] 01/02/70
> 
> > isChron(chron(1))
> FALSE
> 
> ---
>  
> Date: Tue, 11 Nov 2003 20:06:38 -0500 
> From: <tmurph6 at po-box.mcgill.ca>
> To: Frank E Harrell Jr <feh3k at spamcop.net> 
> Cc: <r-help at stat.math.ethz.ch> 
> Subject: Re: [R] HMisc describe -- error with dates 
> 
>  
>  
> I am using the chron package. I have no preference for which function I
> use. I just want the most reliable format for HMisc functions and
> general plotting. I like the ddmonyyy formats (e.g. 11NOV2003). What
> would you recommend?

I like POSIX but chron should be workable.  The fix for isChron in Hmisc
is:

function(x) {
  cl <- class(x)
  dc <- if(.R.) c('POSIXt','POSIXct','dates','times','chron') else
                c('timeDate','date','dates','times','chron')
  length(cl) && any(cl %in% dc)
}

But describe also runs this command:

  if(isdatetime) notime <- all(format(x.unique,"%H%M%S")=='000000')

and such calls to format for chron objects (which actually calls
format.dates if x.unique is a dates object) do not work.  So a few more
modifications will need to be made in describe to work with chron objects,
when time allows.

Frank

> 
> Thank you!
> 
> Quoting Frank E Harrell Jr <feh3k at spamcop.net>:
> 
> > On Tue, 11 Nov 2003 18:28:24 -0500
> > tmurph6 at po-box.mcgill.ca wrote:
> > 
> > > Hello,
> > > 
> > > I am trying to use HMisc describe on a data frame. I have specified
> > > certain variables as dates using, for example:
> > > 
> > > df1$aidsdate <- dates(aidsdate,format="day.mon.year",
> > > origin=c(month = 1, day = 1, year = 1960))
> > > 
> > > When I use describe on the dataframe I get this error:
> > > 
> > > Error in Ops.dates(weights, x) : * not defined for chron objects
> > > 
> > > Has anyone had this problem? I had used the same method with an
> > > older version of R and HMisc and it worked. 
> > > 
> > > Should be be formatting date variables differently?
> > > 
> > > Thank you!
> > > 
> > > Sincerely,
> > > Tanya Murphy
> > > 
> > 
> > In recent versions, describe for R recognizes date/times by one of the
> > following classes: 'POSIXt','POSIXct','chron'. If you really need to
> > use another date format I could be talked into extending the code for
> > that if you can remind me where dates( ) is found. -Frank
> > 
> > ---
> > Frank E Harrell Jr Professor and Chair School of Medicine
> > Department of Biostatistics Vanderbilt University
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From liuqi at sibs.ac.cn  Wed Nov 12 03:52:15 2003
From: liuqi at sibs.ac.cn (liuqi)
Date: Wed, 12 Nov 2003 10:52:15 +0800
Subject: [R] trouble in setting jpeg a large size
Message-ID: <200311120252.hAC2puPW012555@hypatia.math.ethz.ch>

  I met a trouble in setting jpeg a large size. for example, when i use
jpeg(height=65526), a problem "Error in devga(paste("jpeg:", quality, ":", filename, sep = ""), width,  : 
unable to start device devga In addition: Warning message: Unable to allocate bitmap" occurs.
 if a smaller size is set, no errors occur. 

 I'm using R 1.8.0 on win2k.

 Thank you for your help!

Liu Qi



From jc at or.psychology.dal.ca  Wed Nov 12 04:17:22 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Tue, 11 Nov 2003 23:17:22 -0400
Subject: [R] CircStats reveals underlying R bug?
Message-ID: <BB85974D-14BE-11D8-8327-000A956DE534@or.psychology.dal.ca>

circ.plot in CircStats under R 1.8.0 yields incorrect plots (easily 
compare hist() and rose.diag()).  However, the code in circ.plot has 
not changed.  Has anyone tracked this down yet?



From liuqi at sibs.ac.cn  Wed Nov 12 04:30:24 2003
From: liuqi at sibs.ac.cn (liuqi)
Date: Wed, 12 Nov 2003 11:30:24 +0800
Subject: [R] trouble in setting jpeg a large size
Message-ID: <200311120330.hAC3U4PW027331@hypatia.math.ethz.ch>


I met a trouble in setting jpeg a large size. for example, when i use
jpeg(height=65526), a problem "Error in devga(paste("jpeg:", quality, ":", filename, sep = ""), width,  : 
unable to start device devga In addition: Warning message: Unable to allocate bitmap" occurs.
 if a smaller size is set, no errors occur. 

 I'm using R 1.8.0 on win2k.

 Thank you for your help!

Liu Qi



From heimdal at aracnet.com  Wed Nov 12 05:36:57 2003
From: heimdal at aracnet.com (John)
Date: Tue, 11 Nov 2003 20:36:57 -0800
Subject: [R] Time plot question.
Message-ID: <200311112036.57846.heimdal@aracnet.com>

Hello,

I have parsed out some data from a file containing output from the top 
command. The time stamps are of the form "hh:mm:ss". When the command 

plot( Time, FreeMemory, type = "l", col = "blue", main = "\"swap in use\" 
versus Time", xlab = "Time", ylab = "Swap in Use")

is executed, the plot() function ignores the col and type arguments and plots 
the points in some sort of default manner. Do I need to use strptime() and 
reformat the "Time" coordinates? Where could I find some documentation on 
this, as the R docs that I am aware of do not contain an example of this. Any 
suggestions on this will be greatly appreciated.

Cheers,

John



From ggrothendieck at myway.com  Wed Nov 12 06:12:13 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 Nov 2003 00:12:13 -0500 (EST)
Subject: [R] Time plot question.
Message-ID: <20031112051213.828733969@mprdmxin.myway.com>


Either of these should work:


tt = c( "01:03:30", "18:21:03", "22:29:56", "23:03:20" )
y <- 1:4

require(chron)
plot(chron(times=tt),y)

# or

plot(strptime(tt,format="%H:%M:%S"),y)

--- 
Date: Tue, 11 Nov 2003 20:36:57 -0800 
From: John <heimdal at aracnet.com>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Time plot question. 

 
 
Hello,

I have parsed out some data from a file containing output from the top 
command. The time stamps are of the form "hh:mm:ss". When the command 

plot( Time, FreeMemory, type = "l", col = "blue", main = "\"swap in use\" 
versus Time", xlab = "Time", ylab = "Swap in Use")

is executed, the plot() function ignores the col and type arguments and plots 
the points in some sort of default manner. Do I need to use strptime() and 
reformat the "Time" coordinates? Where could I find some documentation on 
this, as the R docs that I am aware of do not contain an example of this. Any 
suggestions on this will be greatly appreciated.

Cheers,

John

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed Nov 12 06:26:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 05:26:37 +0000 (GMT)
Subject: [R] trouble in setting jpeg a large size
In-Reply-To: <200311120330.hAC3U4PW027331@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0311120506570.10602-100000@gannet.stats>

What exactly do you not understand about this? Almost certainly Windows
refused to create a 480x65526 bitmap, and it looks as if dimensions of
bitmaps are limited to 2^15-1.

The mind boggles as to what you actually wanted to do with such a wierd 
aspect ratio.  For a more normal aspect ratio you will run out of memory:
for example a 10000 pixel square bitmap is 380Mb and you will need at 
least 2 copies.  My 512Mb system failed to create that.

Have you tried bitmap()?

On Wed, 12 Nov 2003, liuqi wrote:

> I met a trouble in setting jpeg a large size. for example, when i use
> jpeg(height=65526), a problem "Error in devga(paste("jpeg:", quality, ":", filename, sep = ""), width,  : 
> unable to start device devga In addition: Warning message: Unable to allocate bitmap" occurs.
>  if a smaller size is set, no errors occur. 
> 
>  I'm using R 1.8.0 on win2k.
> 
>  Thank you for your help!
> 
> Liu Qi

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Wed Nov 12 06:42:35 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 Nov 2003 00:42:35 -0500 (EST)
Subject: [R] Strange behavior of pipes
Message-ID: <20031112054235.DCB6E3970@mprdmxin.myway.com>



In R 1.8.0 on Windows 2000 suppose that \a.awk contains:

BEGIN { print "on stdout"
print "on stderr" > "/dev/stderr"
}

which is a simple awk program that writes "on stdout" to stdout
and "on stderr" to stderr.

Then if I start up R I consistently get the following.  That is,
the first pipe does not return anything.  The second pipe returns
a weird character followed by BOTH the stdout and stderr output.
The third pipe does not return anything and then for subsequent
calls we are back to the weird character followed by BOTH the
stdout and stderr output.

I get similar behavior for other programs that use stdout and 
stderr too -- not just gawk.

It looks like a bug to me but I thought I would ask before 
submitting a report in case anyone has any insight into this.

> readLines(pipe("gawk -f \\a.awk"))
character(0)
> readLines(pipe("gawk -f \\a.awk"))
[1] "on stdout" "on stderr" 
> readLines(pipe("gawk -f \\a.awk"))
character(0)
> readLines(pipe("gawk -f \\a.awk"))
[1] "on stdout" "on stderr" 
> readLines(pipe("gawk -f \\a.awk"))
[1] "Ton stdout" "on stderr" 
> readLines(pipe("gawk -f \\a.awk"))
[1] "on stdout" "on stderr"



From markus.helbig at gmx.net  Wed Nov 12 08:17:10 2003
From: markus.helbig at gmx.net (Markus Helbig)
Date: Wed, 12 Nov 2003 08:17:10 +0100
Subject: [R] Talk with from Java
Message-ID: <200311120817.10321.markus.helbig@gmx.net>

Hi everybody

anybody knows how to talk with R like shown in the Java-Code above?

Perhaps someone can help, or tell me its not possible.

/*
 * Java_R.java
 *
 * Created on November 11, 2003, 5:36 PM
 */
import java.io.*;
/**
 *
 * @author  markus
 */
public class Java_R {

    /** Creates a new instance of Java_R */
    public Java_R() {
    }
    
    /**
     * @param args the command line arguments
     */
    public static void main(String[] args) {
        try {
             Process process = Runtime.getRuntime().exec("R --no-save");
             
             //Process process = Runtime.getRuntime().exec("R --help");

             BufferedReader in = new BufferedReader(new 
InputStreamReader(process.getInputStream()));
             BufferedReader reader = new BufferedReader(new 
java.io.InputStreamReader(System.in));
             BufferedWriter out = new BufferedWriter(new 
OutputStreamWriter(process.getOutputStream()));


             String s=null;
             String c=null;

             while(true) {
                 try {
                    while ((s=in.readLine())!=null) {
                         System.out.println(s); 
                    }
 /* The big problem is: it seems like R doesn't come out of this loop, or if 
its does I get the following error:  java.io.IOException: Broken pipe*/

                    System.out.print("\n>");
                    c = reader.readLine();
                    out.write(c);
                    out.flush();
                 }
                 catch(Exception e) {
                    System.out.println(e.toString());
                    System.out.println("Cause : " + e.getCause());
                    System.out.println("Message : " + e.getMessage());
                 }
             }
        }
        catch (Exception e) {
             System.out.println(e.toString());
             System.out.println("Cause : " + e.getCause());
             System.out.println("Message : " + e.getMessage());
        }
    }

}


Thanks everybody who can help me or tries to !

Markus



From Giles.Heywood at CommerzbankIB.com  Wed Nov 12 08:51:37 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Wed, 12 Nov 2003 07:51:37 -0000
Subject: [R] Calendar Time Series
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF05BF7361@xmx8lonib.lonib.commerzbank.com>

I'm not sure what a calendar time series is, but it may be helpful
to consider it as an irregular time series, depending on what 
analysis or display you are wanting to do.  As you say, there are
packages (including 'its') for this purpose.

- Giles

> -----Original Message-----
> From: Brian Beckage [mailto:bbeckage at uvm.edu]
> Sent: 11 November 2003 16:34
> To: r-help at stat.math.ethz.ch
> Subject: [R] Calendar Time Series
> 
> 
> Hello,
> 
> Does R have any facilities for calendar time series?  I'm working 
> with a 40 year long, daily time series and I would like to have each 
> datum associated with a calendar date.  I searched the R website and 
> found several new packages for irregular time series but none for cts.
> 
> By the way, I just installed 1.8.0 on Mac OSX and the installation 
> was effortless!  I also very much like having the option of using R 
> on the Mac with Aqua or X11.  Thanks to all who have contributed to 
> the R project!
> 
> Thanks for your help,
> Brian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From h.wickham at auckland.ac.nz  Wed Nov 12 09:10:00 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Wed, 12 Nov 2003 21:10:00 +1300
Subject: [R] Talk with from Java
In-Reply-To: <200311120817.10321.markus.helbig@gmx.net>
References: <200311120817.10321.markus.helbig@gmx.net>
Message-ID: <3FB1EAD8.1030306@auckland.ac.nz>

Hi Markus,

My Java is a bit rusty, but I think when reading from an input stream 
like the one you've set up, Java "blocks" if there's no input, waiting 
until there is some to return.  I don't think the stream ends until the 
R process closes.  You should test ready() to see if there is more 
output to be read.

Hope this is helpful,

Hadley



From H.RINNER at tirol.gv.at  Wed Nov 12 10:37:56 2003
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Wed, 12 Nov 2003 10:37:56 +0100
Subject: [R] value of strptime in R 1.8.0
Message-ID: <C4D44AB4CB62D311BA6500041202E886031EE340@xms1.tirol.gv.at>

Dear R-people!

I am using R 1.8.0, under Windows XP.

What I want to do is a date conversion of a character column of a data frame
and assign the result as a new column.

Simple example:
> x <- data.frame(a=c("yesterday","today","tomorrow"), b=I(c("20031111",
"20031112", "20031113")))
# convert x$b from character to date:
> strptime(x$b, format="%Y%m%d")
[1] "2003-11-11" "2003-11-12" "2003-11-13"
# trying to make this a new column in x:
> x$c <- strptime(x$b, format="%Y%m%d")
Error in "$<-.data.frame"(`*tmp*`, "c", value = strptime(x$b, format =
"%Y%m%d")) : 
        replacement has 9 rows, data has 3

I have done this before (in R 1.7.0), and I am pretty sure this has been
working then.
What am I doing wrong here (has something changed concerning the value of
strptime() in R 1.8.0)?

-Heinrich.



From Timur.Elzhov at jinr.ru  Wed Nov 12 10:56:17 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Wed, 12 Nov 2003 12:56:17 +0300
Subject: [R] problem with x11 and PS devices on different machines
Message-ID: <20031112095617.GA10917@nf034.jinr.ru>

Dear R help,

I run R at home and the work, I have Debian Linux on both machines and
the same 'r-base-core' deb packages installed. So I tried to run the
same R script, which plots graph in x11 device and then dump it to eps
file (x11 and eps you'll find attached). On the home machine there are
some stranges in x11 plot as well as in eps file.  On the work machine
all the ok, despite of that I use the _same_ version of binary deb
package. May be any troubles with the font paths? Thank you in advance
for any suggestions!

--
WBR,
Timur


-------------- next part --------------
A non-text attachment was scrubbed...
Name: x11-bad.png
Type: image/png
Size: 6604 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20031112/36c756b5/x11-bad.png
-------------- next part --------------
A non-text attachment was scrubbed...
Name: x11-good.png
Type: image/png
Size: 10612 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20031112/36c756b5/x11-good.png

From ripley at stats.ox.ac.uk  Wed Nov 12 11:00:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 10:00:48 +0000 (GMT)
Subject: [R] value of strptime in R 1.8.0
In-Reply-To: <C4D44AB4CB62D311BA6500041202E886031EE340@xms1.tirol.gv.at>
Message-ID: <Pine.LNX.4.44.0311120957490.24673-100000@gannet.stats>

On Wed, 12 Nov 2003, RINNER Heinrich wrote:

> I am using R 1.8.0, under Windows XP.
> 
> What I want to do is a date conversion of a character column of a data frame
> and assign the result as a new column.
> 
> Simple example:
> > x <- data.frame(a=c("yesterday","today","tomorrow"), b=I(c("20031111",
> "20031112", "20031113")))
> # convert x$b from character to date:
> > strptime(x$b, format="%Y%m%d")
> [1] "2003-11-11" "2003-11-12" "2003-11-13"
> # trying to make this a new column in x:
> > x$c <- strptime(x$b, format="%Y%m%d")
> Error in "$<-.data.frame"(`*tmp*`, "c", value = strptime(x$b, format =
> "%Y%m%d")) : 
>         replacement has 9 rows, data has 3
> 
> I have done this before (in R 1.7.0), and I am pretty sure this has been
> working then.

It was an undetected error then.

> What am I doing wrong here (has something changed concerning the value of
> strptime() in R 1.8.0)?

You need as.POSXIct, just as you always have.  strptime gives a list of 
length 9, and that does not go into a dataframe of 3 rows.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gguigon at pasteur.fr  Wed Nov 12 11:04:39 2003
From: gguigon at pasteur.fr (Ghislaine Guigon)
Date: Wed, 12 Nov 2003 11:04:39 +0100
Subject: [R] marrayTools package
Message-ID: <5.0.2.1.2.20031112103259.00b35308@mail.pasteur.fr>


   Hi,
   I work with R and bioconductor only for 2 months, and I'm trying to
   work with the marrayTools package from Yee Hwa Yang.
   I follow recommandations but R answers me :
   > data <- gpTools()
   [1] 33
   [1] "Reading ./Pf742.gpr"
   Generating ...Error in exty[[i]] : subscript out of bounds
   In addition: Warning messages:
   1: the condition has length > 1 and only the first element will be
   used in: if (dev == "jpeg") {
   2: the condition has length > 1 and only the first element will be
   used in: if (dev == "postscript") {
   Gpr files are in the working directory with gal file and library is
   load.
   thanks for help !

   Ghislaine GUIGON
   Biostatisticienne
   Plateau Technique 2 - Puces ? ADN
   INSTITUT PASTEUR
   25-28 rue du Dr ROUX
   75724 Paris cedex 15
   FRANCE
   tel: (33) (0)1 40 61 86 51
   fax: (33) (0)1 45 68 84 06


From glaziou at pasteur-kh.org  Wed Nov 12 11:26:51 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 12 Nov 2003 17:26:51 +0700
Subject: [R] problem with x11 and PS devices on different machines
In-Reply-To: <20031112095617.GA10917@nf034.jinr.ru>
References: <20031112095617.GA10917@nf034.jinr.ru>
Message-ID: <20031112102650.GN4276@pasteur-kh.org>

Timur Elzhov <Timur.Elzhov at jinr.ru> wrote:
> I run R at home and the work, I have Debian Linux on both machines and
> the same 'r-base-core' deb packages installed. So I tried to run the
> same R script, which plots graph in x11 device and then dump it to eps
> file (x11 and eps you'll find attached). On the home machine there are
> some stranges in x11 plot as well as in eps file.  On the work machine
> all the ok, despite of that I use the _same_ version of binary deb
> package. May be any troubles with the font paths? Thank you in advance
> for any suggestions!



I ran the unix tool 'file' on your two attached files:

x11-good.png: PNG image data, 600 x 420, 8-bit/color RGB,
non-interlaced

x11-bad.png: PNG image data, 449 x 315, 8-bit/color RGB,
non-interlaced

It could be that your X11 Modes differ between both machines,
with a different number of dots per inch. 

Hth,

-- 
Philippe



From p.dalgaard at biostat.ku.dk  Wed Nov 12 12:04:54 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Nov 2003 12:04:54 +0100
Subject: [R] CircStats reveals underlying R bug?
In-Reply-To: <BB85974D-14BE-11D8-8327-000A956DE534@or.psychology.dal.ca>
References: <BB85974D-14BE-11D8-8327-000A956DE534@or.psychology.dal.ca>
Message-ID: <x2u159vodl.fsf@biostat.ku.dk>

John Christie <jc at or.psychology.dal.ca> writes:

> circ.plot in CircStats under R 1.8.0 yields incorrect plots (easily
> compare hist() and rose.diag()).  However, the code in circ.plot has
> not changed.  Has anyone tracked this down yet?

Could you supply a directly runnable example, please?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Timur.Elzhov at jinr.ru  Wed Nov 12 12:20:07 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Wed, 12 Nov 2003 14:20:07 +0300
Subject: [R] problem with x11 and PS devices on different machines
In-Reply-To: <20031112102650.GN4276@pasteur-kh.org>
References: <20031112095617.GA10917@nf034.jinr.ru>
	<20031112102650.GN4276@pasteur-kh.org>
Message-ID: <20031112112007.GA11371@nf034.jinr.ru>

On Wed, Nov 12, 2003 at 05:26:51PM +0700, Philippe Glaziou wrote:

>>  I run R at home and the work, I have Debian Linux on both machines and
>>  the same 'r-base-core' deb packages installed. So I tried to run the
>>  same R script, which plots graph in x11 device and then dump it to eps
>>  file (x11 and eps you'll find attached). On the home machine there are
>>  some stranges in x11 plot as well as in eps file.  On the work machine
>>  all the ok, despite of that I use the _same_ version of binary deb
>>  package. May be any troubles with the font paths? Thank you in advance
>>  for any suggestions!
> x11-good.png: PNG image data, 600 x 420, 8-bit/color RGB,
> non-interlaced
> 
> x11-bad.png: PNG image data, 449 x 315, 8-bit/color RGB,
> non-interlaced
Right, "bad" x11() picture is smaller. These 'png' are simply their
screen shots (made by gimp).

> It could be that your X11 Modes differ between both machines,
> with a different number of dots per inch. 
I use the same resolution, 1024x768 on both machines. Anyway, I do
not think that xserver resolution is important for screenshot size
(in pixels) :)

--
Timur



From jrgonzalez at ico.scs.es  Wed Nov 12 12:22:36 2003
From: jrgonzalez at ico.scs.es (Juan Ramon Gonzalez)
Date: Wed, 12 Nov 2003 12:22:36 +0100
Subject: [R] survrec 1.1-2
Message-ID: <008501c3a90f$46a79fe0$1100a8c0@ico.scs.es>

Dear R-Listers,

We have just updated the version 1.1-2 of  "survrec" package. As you can
remember this package deals with recurrent event data. Previous version
computes survival curves when the interocurrence times are iid or
correlated. The new version allows to calculate asymptotic standard errors
for Pe?a-Straderman-Hollander's and Wang-Chang's estimators (print,
summary,.. are still similar to survival package). We can plot pointwise
confidence intervals using these standard errors using plot function.
Furthermore, we have added a new function called "survdiffr" that computes
the bootstrap distribution for a selected quantile. The result of this
function is an object of class "boot". So, using "boot" package we can
compute the bootstrap confidence intervals using "boot.ci" function.

Best Regards,

Juan R Gonzalez



From s2wagner at hotmail.com  Wed Nov 12 12:24:49 2003
From: s2wagner at hotmail.com (Stefan Wagner)
Date: Wed, 12 Nov 2003 12:24:49 +0100
Subject: [R] (no subject)
Message-ID: <BAY1-DAV70Aedn2AG1U0000d4df@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031112/a9018e58/attachment.pl

From glaziou at pasteur-kh.org  Wed Nov 12 13:14:01 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 12 Nov 2003 19:14:01 +0700
Subject: [R] problem with x11 and PS devices on different machines
In-Reply-To: <20031112112007.GA11371@nf034.jinr.ru>
References: <20031112095617.GA10917@nf034.jinr.ru>
	<20031112102650.GN4276@pasteur-kh.org>
	<20031112112007.GA11371@nf034.jinr.ru>
Message-ID: <20031112121401.GO4276@pasteur-kh.org>

Timur Elzhov <Timur.Elzhov at jinr.ru> wrote:
 > It could be that your X11 Modes differ between both machines,
> > with a different number of dots per inch. 
> I use the same resolution, 1024x768 on both machines. Anyway, I do
> not think that xserver resolution is important for screenshot size
> (in pixels) :)



The width and height of a default R x11 plotting window are both 
7 inches. 

There will be a different number of dots within those 7x7 square
inches if the number of dots per inch is not similar. This could 
be the case even though your two xservers are set at 1024x768.  

Does 'xdpyinfo | grep dots' return the same numbers on both
machines?

-- 
Philippe



From p.pagel at gsf.de  Wed Nov 12 13:17:37 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Wed, 12 Nov 2003 13:17:37 +0100
Subject: [R] (no subject)
In-Reply-To: <BAY1-DAV70Aedn2AG1U0000d4df@hotmail.com>
References: <BAY1-DAV70Aedn2AG1U0000d4df@hotmail.com>
Message-ID: <20031112121736.GA9041@porcupine.gsf.de>


	Hi!

> I got information on the shares of some subgroups over time (summing
> up to 1 in each year). The graph I want to create should display the
> development of the individual shares over time by shading rectangulars
> for each share in a different color.

Maybe I'm missing the point but this sounds like a pretty simple barplot
to me.

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From ryszard.czerminski at pharma.novartis.com  Wed Nov 12 13:50:37 2003
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Wed, 12 Nov 2003 07:50:37 -0500
Subject: [R] column extraction by name ?
Message-ID: <OF7228B439.B5B01817-ON85256DDC.00465683-85256DDC.0046A3CD@EU.novartis.net>

I have a data frame (df) with colums x, y and z.
e.g.  df <- data.frame(x = sample(4), y = sample(4), z = sample(4))
I can extract column z by: df$z or df[3]
I can also extract columns x,y by: df[1:2] or by df[-3].

Is it possible to extract x,y columns in a "symbolic" fashion i.e.
by equivalent of df[-z] (which is illegal) ???

Or alternativeley, is there an equivalent of "index" function,
which would return index of the column given name ?

Ryszard



From jc at or.psychology.dal.ca  Wed Nov 12 14:01:31 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Wed, 12 Nov 2003 09:01:31 -0400
Subject: [R] CircStats reveals underlying R bug?
In-Reply-To: <x2u159vodl.fsf@biostat.ku.dk>
References: <BB85974D-14BE-11D8-8327-000A956DE534@or.psychology.dal.ca>
	<x2u159vodl.fsf@biostat.ku.dk>
Message-ID: <565BCC44-1510-11D8-8327-000A956DE534@or.psychology.dal.ca>


On Nov 12, 2003, at 7:04 AM, Peter Dalgaard wrote:

> John Christie <jc at or.psychology.dal.ca> writes:
>
>> circ.plot in CircStats under R 1.8.0 yields incorrect plots (easily
>> compare hist() and rose.diag()).  However, the code in circ.plot has
>> not changed.  Has anyone tracked this down yet?
>
> Could you supply a directly runnable example, please?

Actually, in making something concise and runnable I found the problem. 
  It is undocumented that circ.plot does not handle negative angles 
while rose.diag does.  I think that should be called a bug in 
circ,plot.  It seems to me the code of these two should be merged 
anyway to avoid future errors.  rose.diag can do a circ.plot type 
diagram (but you always get the rose as well).

So, a simple example is.

x<-rvm(100,1,1)
circ.plot(x, bins=18, stack=T, shrink=2)
rose.diag(x, bins=18, pts=T, shrink=2)
# everything should look OK up until you try comparing the next two 
plots
circ.plot(-x, bins=18, stack=T, shrink=2)
rose.diag(-x, bins=18, pts=T, shrink=2)



From allan_kachelmeier at hotmail.com  Wed Nov 12 14:01:00 2003
From: allan_kachelmeier at hotmail.com (Allan Kachelmeier)
Date: Wed, 12 Nov 2003 15:01:00 +0200
Subject: [R] (no subject)
Message-ID: <BAY1-F1597cWlX0MGOV00006a61@hotmail.com>






From ripley at stats.ox.ac.uk  Wed Nov 12 14:06:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 13:06:39 +0000 (GMT)
Subject: [R] column extraction by name ?
In-Reply-To: <OF7228B439.B5B01817-ON85256DDC.00465683-85256DDC.0046A3CD@EU.novartis.net>
Message-ID: <Pine.LNX.4.44.0311121304371.1115-100000@gannet.stats>

?match
?pmatch

On Wed, 12 Nov 2003 ryszard.czerminski at pharma.novartis.com wrote:

> I have a data frame (df) with colums x, y and z.
> e.g.  df <- data.frame(x = sample(4), y = sample(4), z = sample(4))
> I can extract column z by: df$z or df[3]
> I can also extract columns x,y by: df[1:2] or by df[-3].
> 
> Is it possible to extract x,y columns in a "symbolic" fashion i.e.
> by equivalent of df[-z] (which is illegal) ???

df[-match("z", names(df))]

df[!(names(df) %in% "z")]

etc

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bolker at zoo.ufl.edu  Wed Nov 12 14:28:25 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 12 Nov 2003 08:28:25 -0500 (EST)
Subject: [R] CircStats reveals underlying R bug?
In-Reply-To: <565BCC44-1510-11D8-8327-000A956DE534@or.psychology.dal.ca>
Message-ID: <Pine.LNX.4.44.0311120826060.18206-100000@bolker.zoo.ufl.edu>


  Maybe you should take this up with package maintainers (who may or may 
not be reading R-help) ... this sounds like a design/documentation issue 
rather than a "bug" per se (although the distinction is not always clear).  
To be honest, the underlying R code in CircStats doesn't seem terribly 
sophisticated -- I have hacked it some for my own use (e.g. to allow 
the various von Mises functions (rvm, dvm, etc.) to handle vectors of 
different parameter values).

  Ben

On Wed, 12 Nov 2003, John Christie wrote:

> 
> On Nov 12, 2003, at 7:04 AM, Peter Dalgaard wrote:
> 
> > John Christie <jc at or.psychology.dal.ca> writes:
> >
> >> circ.plot in CircStats under R 1.8.0 yields incorrect plots (easily
> >> compare hist() and rose.diag()).  However, the code in circ.plot has
> >> not changed.  Has anyone tracked this down yet?
> >
> > Could you supply a directly runnable example, please?
> 
> Actually, in making something concise and runnable I found the problem. 
>   It is undocumented that circ.plot does not handle negative angles 
> while rose.diag does.  I think that should be called a bug in 
> circ,plot.  It seems to me the code of these two should be merged 
> anyway to avoid future errors.  rose.diag can do a circ.plot type 
> diagram (but you always get the rose as well).
> 
> So, a simple example is.
> 
> x<-rvm(100,1,1)
> circ.plot(x, bins=18, stack=T, shrink=2)
> rose.diag(x, bins=18, pts=T, shrink=2)
> # everything should look OK up until you try comparing the next two 
> plots
> circ.plot(-x, bins=18, stack=T, shrink=2)
> rose.diag(-x, bins=18, pts=T, shrink=2)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From lecoutre at stat.ucl.ac.be  Wed Nov 12 14:24:49 2003
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Wed, 12 Nov 2003 14:24:49 +0100
Subject: [R] column extraction by name ?
In-Reply-To: <OF7228B439.B5B01817-ON85256DDC.00465683-85256DDC.0046A3CD@
	EU.novartis.net>
Message-ID: <5.1.1.5.2.20031112142326.03b527c0@stat4ux.stat.ucl.ac.be>

At 07:50 12/11/2003 -0500, ryszard.czerminski at pharma.novartis.com wrote:
>I have a data frame (df) with colums x, y and z.
>e.g.  df <- data.frame(x = sample(4), y = sample(4), z = sample(4))
>I can extract column z by: df$z or df[3]
>I can also extract columns x,y by: df[1:2] or by df[-3].
>
>Is it possible to extract x,y columns in a "symbolic" fashion i.e.
>by equivalent of df[-z] (which is illegal) ???
>
>Or alternativeley, is there an equivalent of "index" function,
>which would return index of the column given name ?

colindex=function(dataframe,columname){
         return(which(dimnames(dataframe)[[2]]==columname))
}

 > x=data.frame(diag(3))
 > colindex(x,"X2")
[1] 2


Eric

colindex(x,"X2")


--------------------------------------------------
L'erreur est certes humaine, mais un vrai d?sastre
n?cessite un ou deux ordinateurs. Citation anonyme
--------------------------------------------------
Eric Lecoutre
Informaticien/Statisticien
Institut de Statistique / UCL

TEL (+32)(0)10473050       lecoutre at stat.ucl.ac.be
URL http://www.stat.ucl.ac.be/ISpersonnel/lecoutre



From marlene.mueller at gmx.de  Wed Nov 12 14:22:00 2003
From: marlene.mueller at gmx.de (Marlene Mueller)
Date: Wed, 12 Nov 2003 14:22:00 +0100
Subject: [R] column extraction by name ?
In-Reply-To: <OF7228B439.B5B01817-ON85256DDC.00465683-85256DDC.0046A3CD@EU.novartis.net>
References: <OF7228B439.B5B01817-ON85256DDC.00465683-85256DDC.0046A3CD@EU.novartis.net>
Message-ID: <3FB233F8.8080408@gmx.de>



ryszard.czerminski at pharma.novartis.com wrote:
> I have a data frame (df) with colums x, y and z.
> e.g.  df <- data.frame(x = sample(4), y = sample(4), z = sample(4))
> I can extract column z by: df$z or df[3]
> I can also extract columns x,y by: df[1:2] or by df[-3].
> 
> Is it possible to extract x,y columns in a "symbolic" fashion i.e.
> by equivalent of df[-z] (which is illegal) ???

df[,dimnames(df)[[2]] %in% c("x","y")] or df[,dimnames(df)[[2]] != "z"]
should do this.

Marlene

-- 
PD Dr. Marlene M?ller
Fraunhofer ITWM Kaiserslautern, Abt. Finanzmathematik
mailto:Marlene.Mueller at itwm.fhg.de, Tel/Fax: +49 631 205 4189/4139
http://www.itwm.fhg.de/de/fm__employees__mueller/mueller/



From rsoerum80 at hotmail.com  Wed Nov 12 15:26:12 2003
From: rsoerum80 at hotmail.com (=?iso-8859-1?B?UmFnbmhpbGQgU/hydW0=?=)
Date: Wed, 12 Nov 2003 14:26:12 +0000
Subject: [R] repeat  until function
Message-ID: <BAY10-F59ql2RkeS8Yk0000b0f5@hotmail.com>

Hi,

I'm in this situation:
I what to generate N random numbers(integer) that are different from each 
other.
One suggestion:

tabel <- rep(NULL, N)
for (i in 1:N){
   temp <- as.integer(runif(1,1,max))
   if(temp in tabel) {
       repeat (?) (temp <- as.integer(runif(i,i,max)))
       until (?) ((temp in tabel) ==FALSE)
   }
   else{ tabel[i] <- temp}

I can't use repeat/until - don't exist....
Any suggestions?


Thanks
*Ragnhild*

_________________________________________________________________
MSN Messenger http://www.msn.no/messenger Den korteste veien mellom deg og 
dine venner



From Simon.Fear at synequanon.com  Wed Nov 12 15:25:17 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 12 Nov 2003 14:25:17 -0000
Subject: [R] column extraction by name ?
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0E91@synequanon01>

Uh oh! Time for my occasional reminder post to use subset(), 
as in

subset(df, select = -z)

for this case.


> -----Original Message-----
> From: ryszard.czerminski at pharma.novartis.com
> [mailto:ryszard.czerminski at pharma.novartis.com]
> Sent: 12 November 2003 12:51
> To: R-help list
> Subject: [R] column extraction by name ?
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> I have a data frame (df) with colums x, y and z.
> e.g.  df <- data.frame(x = sample(4), y = sample(4), z = sample(4))
> I can extract column z by: df$z or df[3]
> I can also extract columns x,y by: df[1:2] or by df[-3].
> 
> Is it possible to extract x,y columns in a "symbolic" fashion i.e.
> by equivalent of df[-z] (which is illegal) ???
> 
> Or alternativeley, is there an equivalent of "index" function,
> which would return index of the column given name ?
> 
> Ryszard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From jfri at novozymes.com  Wed Nov 12 15:27:31 2003
From: jfri at novozymes.com (JFRI (Jesper Frickman))
Date: Wed, 12 Nov 2003 09:27:31 -0500
Subject: [R] Memory issues..
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D14FD52@exusfr14.novo.dk>

How much processing takes place before you get to the lme call? Maybe R
has just used up the memory on something else. I think there is a fair
amount of memory leak, as I get similar problems with my program. I use
R 1.8.0. My program goes as follows.

1. Use RODBC to get a data.frame containing assays to analyze (17 assays
are found).
2. Define an AnalyzeAssay(assay, suffix) function to do the following:
	a) Use RODBC to get data.
	b) Store dataset "limsdata" in workspace using the <<- operator
to avoid the following error in qqnorm.lme: Error in eval(expr, envir,
enclos) : Object "limsdata" not found, when I call it with a grouping
formula like: ~ resid(.) | ORDCURV.
	c) Call lme to analyze data.
	d) Produce some diagnostic plots. Record them by setting
record=TRUE on the trellis.device
	e) Save the plots on win.metafile using replayPlot(...)
	f) Save text to a file using sink(...)

3. Call the function for each assay using the code:

# Analyze each assay
for(i in 1:length(assays[,1]))
{
	writeLines(paste("Analyzing ", assays$DILUTION[i], " ",
assays$PROFNO[i], "...", sep=""))
	flush.console()
	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])

	# Clean up memory
	rm(limsdata)
	gc()
}

As you can see, I try to remove the dataset stored in workspace and then
call gc() to clean up my memory as I go.

Nevertheless, when I come to assay 11 out of 17, it stops with a memory
allocation error. I have to quit R, and start again with assay 11, then
it stops again with assay 15 and finally 17. The last assays have much
more data than the first ones, but all assays can be completed as long
as I keep restarting...

Maybe restarting the job can help you getting it done?

Cheers,
Jesper

-----Original Message-----
From: Rodrigo Abt [mailto:rodrigo.abt at sii.cl] 
Sent: Monday, November 10, 2003 11:02 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Memory issues..


Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. My
sample size is about 2965 and 3 factors:

year (5 levels), ssize (4 levels), condition (2 levels).

When I issue the following command:

>
lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,me
thod
="ML")

I got the following error:

Error in logLik.lmeStructInt(lmeSt, lmePars) :
        Calloc could not allocate (65230 of 8) memory
In addition: Warning message:
Reached total allocation of 120Mb: see help(memory.size)

I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb
processor. My version of R is 1.7.1.

Thanks in advance,

Rodrigo Abt.
Department of Economic and Tributary Studies,
SII, Chile.



From bbeckage at uvm.edu  Wed Nov 12 15:26:55 2003
From: bbeckage at uvm.edu (Brian Beckage)
Date: Wed, 12 Nov 2003 09:26:55 -0500
Subject: [R] Summary:  Calendar Time Series
Message-ID: <p06010200bbd7f0ee8d93@[132.198.177.56]>

Thanks to Patrick Burns, Giles Heywood, and Gabor Grothendiec for 
responding to my question.

Gabor suggested something along the lines of
    z <- ts(rnorm(25),start=as.numeric(chron("01/25/99")))
and then get back the times like this:
    chron(time(z))
To plot it:
    plot(chron(time(z)),z)

Patrick and Giles suggested using the its library.  In case anyone is 
interested, the following code created the time series that I needed:

# Creating dates to associate with the time series
dates.p33<-seq.dates(from="10/01/1952", length=dim(stageP33)[1], by="days");
# The next line insures that the dates start in 1952 rather than 2052
dates.p33<-format(as.POSIXct(dates.p33+1), "%m/%d/%Y")

# Combining dates with data
p33.its<-its(x=as.matrix(stageP33),
 
dates=as.POSIXct(x=strptime(as.character(dates.p33),format="%m/%d/%Y")),
              names=dimnames(stageP33)[[2]],format=its.format())

I don't claim that is the best way to do it.  Also note that this 
required the its and chron libraries.

With regards,
Brian



From CMiller at PICR.man.ac.uk  Wed Nov 12 14:21:42 2003
From: CMiller at PICR.man.ac.uk (Crispin Miller)
Date: Wed, 12 Nov 2003 13:21:42 -0000
Subject: [R] Alpha values
Message-ID: <BAA35444B19AD940997ED02A6996AAE0B5C2C8@sanmail.picr.man.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031112/5b0a8fbc/attachment.pl

From rlandis at middlebury.edu  Wed Nov 12 15:39:32 2003
From: rlandis at middlebury.edu (Landis, R Matthew)
Date: Wed, 12 Nov 2003 09:39:32 -0500
Subject: [R] "/" operator in model formula
Message-ID: <0FE98FA04927D411A48300D0B77CF9BB0E7A71C4@tiger.middlebury.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031112/c02afe53/attachment.pl

From RBaskin at ahrq.gov  Wed Nov 12 15:42:30 2003
From: RBaskin at ahrq.gov (RBaskin@ahrq.gov)
Date: Wed, 12 Nov 2003 09:42:30 -0500
Subject: [R] repeat  until function
Message-ID: <3598558AD728D41183350008C7CF291C0F16B9A7@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031112/0307689f/attachment.pl

From jfox at mcmaster.ca  Wed Nov 12 15:47:39 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 12 Nov 2003 09:47:39 -0500
Subject: [R] repeat  until function
In-Reply-To: <BAY10-F59ql2RkeS8Yk0000b0f5@hotmail.com>
Message-ID: <5.1.0.14.2.20031112094528.02006bb0@127.0.0.1>

Dear Ragnhild,

You can break out of a loop (see ?break), but, if I understand correctly 
what you want, why not just use sample(max, N)?

John

At 02:26 PM 11/12/2003 +0000, Ragnhild S?rum wrote:
>Hi,
>
>I'm in this situation:
>I what to generate N random numbers(integer) that are different from each 
>other.
>One suggestion:
>
>tabel <- rep(NULL, N)
>for (i in 1:N){
>   temp <- as.integer(runif(1,1,max))
>   if(temp in tabel) {
>       repeat (?) (temp <- as.integer(runif(i,i,max)))
>       until (?) ((temp in tabel) ==FALSE)
>   }
>   else{ tabel[i] <- temp}
>
>I can't use repeat/until - don't exist....
>Any suggestions?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From bbeckage at uvm.edu  Wed Nov 12 16:05:39 2003
From: bbeckage at uvm.edu (Brian Beckage)
Date: Wed, 12 Nov 2003 10:05:39 -0500
Subject: [R] Chron, as.POSIXct problem
Message-ID: <p06010201bbd7f3cc3994@[132.198.177.56]>

Dear R list,

I noticed the following 'problem' when changing the format of dates 
created with seq.dates() (from the Chron library) using as.POSIXct() 
(R 1.8.0 on OSX 10.2.8):

>  datesTest<-seq.dates(from="10/01/1952", length=3, by="days");
>  datesTest
[1] 10/01/52 10/02/52 10/03/52

# Now changing the format to show year as 1952.

>  datesTest<-format(as.POSIXct(datesTest), "%m/%d/%Y")
>  datesTest
[1] "09/30/1952" "10/01/1952" "10/02/1952"
>

The dates were shifted by one day.  The work around is simple enough, e.g.,

>  datesTest<-format(as.POSIXct(datesTest+1), "%m/%d/%Y")
[1] "10/01/1952" "10/02/1952" "10/03/1952"

but I wonder if this is the intended behavior?

Brian



From p.pagel at gsf.de  Wed Nov 12 16:16:36 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Wed, 12 Nov 2003 16:16:36 +0100
Subject: [R] repeat  until function
In-Reply-To: <BAY10-F59ql2RkeS8Yk0000b0f5@hotmail.com>
References: <BAY10-F59ql2RkeS8Yk0000b0f5@hotmail.com>
Message-ID: <20031112151634.GA9759@porcupine.gsf.de>

> I what to generate N random numbers(integer) that are different from each 
> other.
> One suggestion:
> 
> tabel <- rep(NULL, N)
> for (i in 1:N){
>   temp <- as.integer(runif(1,1,max))
>   if(temp in tabel) {
>       repeat (?) (temp <- as.integer(runif(i,i,max)))
>       until (?) ((temp in tabel) ==FALSE)
>   }
>   else{ tabel[i] <- temp}
> 
> I can't use repeat/until - don't exist....

repeat ... until loops can be rewritten as while loops.


The easiest way is this:

# n unique random numbers between min and max
sample(min:max, n)


But maybe you don't want to generate the array min:max for some reason
(because it is really large?). Then you can do the whole thing yourself:

# another way to the same result
left <- n
tab <- NULL
while (left > 0) {
	new <- as.integer(runif(left, min, max))
	tab <- unique(c(tab, new))
	left <- n - length(tab)	
}

If max-min is really large and n is not much smaller than max-min you
may want to generate more numbers than you actually need so unique()
leaves you with more results and you don't have to iterate so often...

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From tblackw at umich.edu  Wed Nov 12 16:43:21 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 12 Nov 2003 10:43:21 -0500 (EST)
Subject: [R] Memory issues..
In-Reply-To: <D53147E531BFBC4B8853FD134FAEE44D14FD52@exusfr14.novo.dk>
References: <D53147E531BFBC4B8853FD134FAEE44D14FD52@exusfr14.novo.dk>
Message-ID: <Pine.SOL.4.58.0311121019470.18728@zektor.gpcc.itd.umich.edu>

Jesper  -  (off-list)

Jim MacDonald reports seeing different memory-management behavior
between Windows and Linux operating systems on the same, dual boot
machine.  Unfortunately, this is happening at the operating system
level, so the R code cannot do anything about it.  I have cc'ed
Jim on this email, hoping that he will give more details to the
entire list.  What operating systems (and versions of R) do you
think Rodrigo and Jesper are using ?

Specifically for Jesper's  AnalyzeAssay() function:  There is some
manipulation you can do using  formula()  or  as.formula()  that will
assign a local object as the environment in which to find values for
the terms in a formula.  (I've never done this, so I can't give you
an example of working code, only references to the help pages for
"formula" and "environment".  It's often very instructive to literally
type in the sequence of statements given as examples at the bottom
of each help page.)  I think this will allow you to avoid assigning
to the global workspace.

Are you sure that the call to  rm() below is actually removing the
copy of limsdata that's in .GlobalEnv, rather than a local copy ?
I would expect you to have to specify  where=1  in order to get the
behavior you want.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 12 Nov 2003, JFRI (Jesper Frickman) wrote:

> How much processing takes place before you get to the lme call? Maybe R
> has just used up the memory on something else. I think there is a fair
> amount of memory leak, as I get similar problems with my program. I use
> R 1.8.0. My program goes as follows.
>
> 1. Use RODBC to get a data.frame containing assays to analyze (17 assays
> are found).
> 2. Define an AnalyzeAssay(assay, suffix) function to do the following:
> 	a) Use RODBC to get data.
> 	b) Store dataset "limsdata" in workspace using the <<- operator
> to avoid the following error in qqnorm.lme: Error in eval(expr, envir,
> enclos) : Object "limsdata" not found, when I call it with a grouping
> formula like: ~ resid(.) | ORDCURV.
> 	c) Call lme to analyze data.
> 	d) Produce some diagnostic plots. Record them by setting
> record=TRUE on the trellis.device
> 	e) Save the plots on win.metafile using replayPlot(...)
> 	f) Save text to a file using sink(...)
>
> 3. Call the function for each assay using the code:
>
> # Analyze each assay
> for(i in 1:length(assays[,1]))
> {
> 	writeLines(paste("Analyzing ", assays$DILUTION[i], " ",
> assays$PROFNO[i], "...", sep=""))
> 	flush.console()
> 	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])
>
> 	# Clean up memory
> 	rm(limsdata)
> 	gc()
> }
>
> As you can see, I try to remove the dataset stored in workspace and then
> call gc() to clean up my memory as I go.
>
> Nevertheless, when I come to assay 11 out of 17, it stops with a memory
> allocation error. I have to quit R, and start again with assay 11, then
> it stops again with assay 15 and finally 17. The last assays have much
> more data than the first ones, but all assays can be completed as long
> as I keep restarting...
>
> Maybe restarting the job can help you getting it done?
>
> Cheers,
> Jesper
>
> -----Original Message-----
> From: Rodrigo Abt [mailto:rodrigo.abt at sii.cl]
> Sent: Monday, November 10, 2003 11:02 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Memory issues..
>
>
> Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. My
> sample size is about 2965 and 3 factors:
>
> year (5 levels), ssize (4 levels), condition (2 levels).
>
> When I issue the following command:
>
> >
> lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,me
> thod
> ="ML")
>
> I got the following error:
>
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>         Calloc could not allocate (65230 of 8) memory
> In addition: Warning message:
> Reached total allocation of 120Mb: see help(memory.size)
>
> I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb
> processor. My version of R is 1.7.1.
>
> Thanks in advance,
>
> Rodrigo Abt.
> Department of Economic and Tributary Studies,
> SII, Chile.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Wed Nov 12 16:49:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 15:49:54 +0000 (GMT)
Subject: [R] Chron, as.POSIXct problem
In-Reply-To: <p06010201bbd7f3cc3994@[132.198.177.56]>
Message-ID: <Pine.LNX.4.44.0311121546100.4998-100000@gannet.stats>

Does not happen on Solaris or Linux, so looks like a MacOS X problem.

Here is some crosschecks:

> unclass(datesTest)
[1] -6301 -6300 -6299
attr(,"format")
[1] "m/d/y"
attr(,"origin")
month   day  year
    1     1  1970
> unclass(as.POSIXct(datesTest))
[1] -544406400 -544320000 -544233600


On Wed, 12 Nov 2003, Brian Beckage wrote:

> Dear R list,
> 
> I noticed the following 'problem' when changing the format of dates 
> created with seq.dates() (from the Chron library) using as.POSIXct() 
> (R 1.8.0 on OSX 10.2.8):
> 
> >  datesTest<-seq.dates(from="10/01/1952", length=3, by="days");
> >  datesTest
> [1] 10/01/52 10/02/52 10/03/52
> 
> # Now changing the format to show year as 1952.
> 
> >  datesTest<-format(as.POSIXct(datesTest), "%m/%d/%Y")
> >  datesTest
> [1] "09/30/1952" "10/01/1952" "10/02/1952"
> >
> 
> The dates were shifted by one day.  The work around is simple enough, e.g.,
> 
> >  datesTest<-format(as.POSIXct(datesTest+1), "%m/%d/%Y")
> [1] "10/01/1952" "10/02/1952" "10/03/1952"
> 
> but I wonder if this is the intended behavior?
> 
> Brian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfri at novozymes.com  Wed Nov 12 16:50:55 2003
From: jfri at novozymes.com (JFRI (Jesper Frickman))
Date: Wed, 12 Nov 2003 10:50:55 -0500
Subject: [R] Memory issues..
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D154756@exusfr14.novo.dk>

I am using Windows 2000.

Kind regards, 
Jesper Frickmann 
Statistician, Quality Control 
Novozymes North America Inc. 
Tel. +1 919 494 3266
Fax +1 919 494 3460

-----Original Message-----
From: Thomas W Blackwell [mailto:tblackw at umich.edu] 
Sent: Wednesday, November 12, 2003 10:43 AM
To: JFRI (Jesper Frickman)
Cc: rodrigo.abt at sii.cl; jmacdon at umich.edu; r-help at stat.math.ethz.ch
Subject: RE: [R] Memory issues..


Jesper  -  (off-list)

Jim MacDonald reports seeing different memory-management behavior
between Windows and Linux operating systems on the same, dual boot
machine.  Unfortunately, this is happening at the operating system
level, so the R code cannot do anything about it.  I have cc'ed Jim on
this email, hoping that he will give more details to the entire list.
What operating systems (and versions of R) do you think Rodrigo and
Jesper are using ?

Specifically for Jesper's  AnalyzeAssay() function:  There is some
manipulation you can do using  formula()  or  as.formula()  that will
assign a local object as the environment in which to find values for the
terms in a formula.  (I've never done this, so I can't give you an
example of working code, only references to the help pages for "formula"
and "environment".  It's often very instructive to literally type in the
sequence of statements given as examples at the bottom of each help
page.)  I think this will allow you to avoid assigning to the global
workspace.

Are you sure that the call to  rm() below is actually removing the copy
of limsdata that's in .GlobalEnv, rather than a local copy ? I would
expect you to have to specify  where=1  in order to get the behavior you
want.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 12 Nov 2003, JFRI (Jesper Frickman) wrote:

> How much processing takes place before you get to the lme call? Maybe 
> R has just used up the memory on something else. I think there is a 
> fair amount of memory leak, as I get similar problems with my program.

> I use R 1.8.0. My program goes as follows.
>
> 1. Use RODBC to get a data.frame containing assays to analyze (17 
> assays are found). 2. Define an AnalyzeAssay(assay, suffix) function 
> to do the following:
> 	a) Use RODBC to get data.
> 	b) Store dataset "limsdata" in workspace using the <<- operator
to 
> avoid the following error in qqnorm.lme: Error in eval(expr, envir,
> enclos) : Object "limsdata" not found, when I call it with a grouping 
> formula like: ~ resid(.) | ORDCURV.
> 	c) Call lme to analyze data.
> 	d) Produce some diagnostic plots. Record them by setting
record=TRUE 
> on the trellis.device
> 	e) Save the plots on win.metafile using replayPlot(...)
> 	f) Save text to a file using sink(...)
>
> 3. Call the function for each assay using the code:
>
> # Analyze each assay
> for(i in 1:length(assays[,1]))
> {
> 	writeLines(paste("Analyzing ", assays$DILUTION[i], " ", 
> assays$PROFNO[i], "...", sep=""))
> 	flush.console()
> 	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])
>
> 	# Clean up memory
> 	rm(limsdata)
> 	gc()
> }
>
> As you can see, I try to remove the dataset stored in workspace and 
> then call gc() to clean up my memory as I go.
>
> Nevertheless, when I come to assay 11 out of 17, it stops with a 
> memory allocation error. I have to quit R, and start again with assay 
> 11, then it stops again with assay 15 and finally 17. The last assays 
> have much more data than the first ones, but all assays can be 
> completed as long as I keep restarting...
>
> Maybe restarting the job can help you getting it done?
>
> Cheers,
> Jesper
>
> -----Original Message-----
> From: Rodrigo Abt [mailto:rodrigo.abt at sii.cl]
> Sent: Monday, November 10, 2003 11:02 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Memory issues..
>
>
> Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. 
> My sample size is about 2965 and 3 factors:
>
> year (5 levels), ssize (4 levels), condition (2 levels).
>
> When I issue the following command:
>
> >
> lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,
> me
> thod
> ="ML")
>
> I got the following error:
>
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>         Calloc could not allocate (65230 of 8) memory
> In addition: Warning message:
> Reached total allocation of 120Mb: see help(memory.size)
>
> I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb 
> processor. My version of R is 1.7.1.
>
> Thanks in advance,
>
> Rodrigo Abt.
> Department of Economic and Tributary Studies,
> SII, Chile.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Timur.Elzhov at jinr.ru  Wed Nov 12 16:55:15 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Wed, 12 Nov 2003 18:55:15 +0300
Subject: [R] problem with x11 and PS devices on different machines
In-Reply-To: <20031112121401.GO4276@pasteur-kh.org>
References: <20031112095617.GA10917@nf034.jinr.ru>
	<20031112102650.GN4276@pasteur-kh.org>
	<20031112112007.GA11371@nf034.jinr.ru>
	<20031112121401.GO4276@pasteur-kh.org>
Message-ID: <20031112155515.GA15130@nf034.jinr.ru>

On Wed, Nov 12, 2003 at 07:14:01PM +0700, Philippe Glaziou wrote:

> The width and height of a default R x11 plotting window are both 
> 7 inches. 
> 
> There will be a different number of dots within those 7x7 square
> inches if the number of dots per inch is not similar. This could 
> be the case even though your two xservers are set at 1024x768.  
> 
> Does 'xdpyinfo | grep dots' return the same numbers on both
> machines?
I see :)  I am in the office now, but I tried to play with dpi. I used
to think that dpi _is_ resolution / real_monitor_dimensions, and could
not be set in Xserver config. But I found its set in xdm/Xservers, I saw
that x11 R device and ps dump from them are dependent on it.
Thank you!

--
Timur



From ripley at stats.ox.ac.uk  Wed Nov 12 16:54:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 15:54:58 +0000 (GMT)
Subject: [R] Memory issues..
In-Reply-To: <D53147E531BFBC4B8853FD134FAEE44D14FD52@exusfr14.novo.dk>
Message-ID: <Pine.LNX.4.44.0311121551450.4998-100000@gannet.stats>

On Wed, 12 Nov 2003, JFRI (Jesper Frickman) wrote:

> How much processing takes place before you get to the lme call? Maybe R
> has just used up the memory on something else. I think there is a fair
> amount of memory leak, as I get similar problems with my program. I use

Windows, right?  I don't think this is memory leak, but rather
fragmentation.  Hopefully the memory management in R-devel will ease this, 
and you might like to compile that up and try it.

On R 1.8.0 on Windows you have to be able to find a block of contiguous 
memory of the needed size, so fragmentation can kill you.  Try increasing 
--max-memory-size unless you are near 2Gb.

> R 1.8.0. My program goes as follows.
> 
> 1. Use RODBC to get a data.frame containing assays to analyze (17 assays
> are found).
> 2. Define an AnalyzeAssay(assay, suffix) function to do the following:
> 	a) Use RODBC to get data.
> 	b) Store dataset "limsdata" in workspace using the <<- operator
> to avoid the following error in qqnorm.lme: Error in eval(expr, envir,
> enclos) : Object "limsdata" not found, when I call it with a grouping
> formula like: ~ resid(.) | ORDCURV.
> 	c) Call lme to analyze data.
> 	d) Produce some diagnostic plots. Record them by setting
> record=TRUE on the trellis.device
> 	e) Save the plots on win.metafile using replayPlot(...)
> 	f) Save text to a file using sink(...)
> 
> 3. Call the function for each assay using the code:
> 
> # Analyze each assay
> for(i in 1:length(assays[,1]))
> {
> 	writeLines(paste("Analyzing ", assays$DILUTION[i], " ",
> assays$PROFNO[i], "...", sep=""))
> 	flush.console()
> 	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])
> 
> 	# Clean up memory
> 	rm(limsdata)
> 	gc()
> }
> 
> As you can see, I try to remove the dataset stored in workspace and then
> call gc() to clean up my memory as I go.
> 
> Nevertheless, when I come to assay 11 out of 17, it stops with a memory
> allocation error. I have to quit R, and start again with assay 11, then
> it stops again with assay 15 and finally 17. The last assays have much
> more data than the first ones, but all assays can be completed as long
> as I keep restarting...
> 
> Maybe restarting the job can help you getting it done?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Nov 12 17:00:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 16:00:16 +0000 (GMT)
Subject: [R] "/" operator in model formula
In-Reply-To: <0FE98FA04927D411A48300D0B77CF9BB0E7A71C4@tiger.middlebury.edu>
Message-ID: <Pine.LNX.4.44.0311121557260.4998-100000@gannet.stats>

On Wed, 12 Nov 2003, Landis, R Matthew wrote:

> Dear R-help folks,
>  
> Can someone guide me to a source where I can learn more about the / operator
> in model formulae?  I found a reference to it in Venables and Ripley's MASS,
> p. 142, where it says, in reference to ANCOVA:  "Terms of the form a/x,
> where a is a factor, are best thought of as 'separate regression models of
> type 1 + x within the levels of a.'..."

See p.150 for a/b where b is a factor.

> This seems very appropriate to my analysis, where I am doing an ANCOVA of
> tree growth as a function of tree height (ht - continuous) separately for
> three species (spp) and three light levels (lt).  The problem is, I'm not
> exactly sure how to interpret the results of this model specification, and I
> can't find any other references to it despite doing searches in the help
> pages, Google, Jonathon Baron's R site search, and other text books such as
> Dalgaard or Crawley.
>  
> I've fit the model as: growth ~ spp*lt / ht -1, and compared the results to
> growth ~ spp*lt*ht.
>  
> The coefficients are equivalent in both models, producing identical plots of
> predicted values.  but the terms that appear in the summary table differ, as
> do the P-values, and I'm not sure how to interpret them.  In the more
> standard model (growth ~ spp*lt*ht), I am clear on the fact that each level
> of the main effects is compared to the lowest level of that main effect
> (when using contr.treatment).  But the alternative model (growth ~spp*lt /
> ht -1) contains all three levels of the main effect, spp.  

That is caused by the -1.

The difference is between testing and crossing. In a / b the levels 
of b are unrelated for different levels of a, whereas in a*b they are the 
same levels.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ivo.welch at yale.edu  Wed Nov 12 17:05:05 2003
From: ivo.welch at yale.edu (ivo welch)
Date: Wed, 12 Nov 2003 11:05:05 -0500
Subject: [R] postscript: font size in text(x,y,label)?
In-Reply-To: <200311011104.hA1B4SPY016224@hypatia.math.ethz.ch>
References: <200311011104.hA1B4SPY016224@hypatia.math.ethz.ch>
Message-ID: <3FB25A31.3090109@yale.edu>


I would like to just create my (point) labels [created by 
text(x,y,labels)] in smaller font size, especially when I write out to 
eps.  all other point sizes should not change.  is this possible?  help 
appreciated.  regards, /iaw



From ripley at stats.ox.ac.uk  Wed Nov 12 17:03:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 16:03:45 +0000 (GMT)
Subject: [R] Alpha values
In-Reply-To: <BAA35444B19AD940997ED02A6996AAE0B5C2C8@sanmail.picr.man.ac.uk>
Message-ID: <Pine.LNX.4.44.0311121601290.4998-100000@gannet.stats>

Yes, but currently only alpha=0 and alpha=255 are supported by the
available devices that I know of (and I introduced this).

Adding alpha-level support is complicated for the devices people normally
use, although it would be trivial in PDF1.4.

On Wed, 12 Nov 2003, Crispin Miller wrote:

> Does anyone know whether it is possible to construct a colour for
> plotting with an alpha value as well as simply specifying rgb values?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From glaziou at pasteur-kh.org  Wed Nov 12 17:18:09 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 12 Nov 2003 23:18:09 +0700
Subject: [R] Chron, as.POSIXct problem
In-Reply-To: <Pine.LNX.4.44.0311121546100.4998-100000@gannet.stats>
References: <p06010201bbd7f3cc3994@[132.198.177.56]>
	<Pine.LNX.4.44.0311121546100.4998-100000@gannet.stats>
Message-ID: <20031112161809.GB24608@pasteur-kh.org>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> Does not happen on Solaris or Linux, so looks like a MacOS X problem.

It does not happen on my Mac G4 box (R 1.8.0 on MacOSX 10.2.6). 

--Philippe




> Here is some crosschecks:
> 
> > unclass(datesTest)
> [1] -6301 -6300 -6299
> attr(,"format")
> [1] "m/d/y"
> attr(,"origin")
> month   day  year
>     1     1  1970
> > unclass(as.POSIXct(datesTest))
> [1] -544406400 -544320000 -544233600
> 
> 
> On Wed, 12 Nov 2003, Brian Beckage wrote:
> 
> > Dear R list,
> > 
> > I noticed the following 'problem' when changing the format of dates 
> > created with seq.dates() (from the Chron library) using as.POSIXct() 
> > (R 1.8.0 on OSX 10.2.8):
> > 
> > >  datesTest<-seq.dates(from="10/01/1952", length=3, by="days");
> > >  datesTest
> > [1] 10/01/52 10/02/52 10/03/52
> > 
> > # Now changing the format to show year as 1952.
> > 
> > >  datesTest<-format(as.POSIXct(datesTest), "%m/%d/%Y")
> > >  datesTest
> > [1] "09/30/1952" "10/01/1952" "10/02/1952"
> > >
> > 
> > The dates were shifted by one day.  The work around is simple enough, e.g.,
> > 
> > >  datesTest<-format(as.POSIXct(datesTest+1), "%m/%d/%Y")
> > [1] "10/01/1952" "10/02/1952" "10/03/1952"
> > 
> > but I wonder if this is the intended behavior?
> > 
> > Brian
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Philippe



From jfri at novozymes.com  Wed Nov 12 17:29:17 2003
From: jfri at novozymes.com (JFRI (Jesper Frickman))
Date: Wed, 12 Nov 2003 11:29:17 -0500
Subject: [R] Memory issues..
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D14FD53@exusfr14.novo.dk>

I have just tried listing limsdata from the workspace and it is indeed
gone from .GlobalEnv. I also tried passing the environment to the
as.formula function, but it still doesn't work.

Kind regards, 
Jesper Frickmann 
Statistician, Quality Control 
Novozymes North America Inc. 
Tel. +1 919 494 3266
Fax +1 919 494 3460


-----Original Message-----
From: Thomas W Blackwell [mailto:tblackw at umich.edu] 
Sent: Wednesday, November 12, 2003 10:43 AM
To: JFRI (Jesper Frickman)
Cc: rodrigo.abt at sii.cl; jmacdon at umich.edu; r-help at stat.math.ethz.ch
Subject: RE: [R] Memory issues..


Jesper  -  (off-list)

Jim MacDonald reports seeing different memory-management behavior
between Windows and Linux operating systems on the same, dual boot
machine.  Unfortunately, this is happening at the operating system
level, so the R code cannot do anything about it.  I have cc'ed Jim on
this email, hoping that he will give more details to the entire list.
What operating systems (and versions of R) do you think Rodrigo and
Jesper are using ?

Specifically for Jesper's  AnalyzeAssay() function:  There is some
manipulation you can do using  formula()  or  as.formula()  that will
assign a local object as the environment in which to find values for the
terms in a formula.  (I've never done this, so I can't give you an
example of working code, only references to the help pages for "formula"
and "environment".  It's often very instructive to literally type in the
sequence of statements given as examples at the bottom of each help
page.)  I think this will allow you to avoid assigning to the global
workspace.

Are you sure that the call to  rm() below is actually removing the copy
of limsdata that's in .GlobalEnv, rather than a local copy ? I would
expect you to have to specify  where=1  in order to get the behavior you
want.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 12 Nov 2003, JFRI (Jesper Frickman) wrote:

> How much processing takes place before you get to the lme call? Maybe 
> R has just used up the memory on something else. I think there is a 
> fair amount of memory leak, as I get similar problems with my program.

> I use R 1.8.0. My program goes as follows.
>
> 1. Use RODBC to get a data.frame containing assays to analyze (17 
> assays are found). 2. Define an AnalyzeAssay(assay, suffix) function 
> to do the following:
> 	a) Use RODBC to get data.
> 	b) Store dataset "limsdata" in workspace using the <<- operator
to 
> avoid the following error in qqnorm.lme: Error in eval(expr, envir,
> enclos) : Object "limsdata" not found, when I call it with a grouping 
> formula like: ~ resid(.) | ORDCURV.
> 	c) Call lme to analyze data.
> 	d) Produce some diagnostic plots. Record them by setting
record=TRUE 
> on the trellis.device
> 	e) Save the plots on win.metafile using replayPlot(...)
> 	f) Save text to a file using sink(...)
>
> 3. Call the function for each assay using the code:
>
> # Analyze each assay
> for(i in 1:length(assays[,1]))
> {
> 	writeLines(paste("Analyzing ", assays$DILUTION[i], " ", 
> assays$PROFNO[i], "...", sep=""))
> 	flush.console()
> 	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])
>
> 	# Clean up memory
> 	rm(limsdata)
> 	gc()
> }
>
> As you can see, I try to remove the dataset stored in workspace and 
> then call gc() to clean up my memory as I go.
>
> Nevertheless, when I come to assay 11 out of 17, it stops with a 
> memory allocation error. I have to quit R, and start again with assay 
> 11, then it stops again with assay 15 and finally 17. The last assays 
> have much more data than the first ones, but all assays can be 
> completed as long as I keep restarting...
>
> Maybe restarting the job can help you getting it done?
>
> Cheers,
> Jesper
>
> -----Original Message-----
> From: Rodrigo Abt [mailto:rodrigo.abt at sii.cl]
> Sent: Monday, November 10, 2003 11:02 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Memory issues..
>
>
> Hi dear R-listers, I'm trying to fit a 3-level model using lme in R. 
> My sample size is about 2965 and 3 factors:
>
> year (5 levels), ssize (4 levels), condition (2 levels).
>
> When I issue the following command:
>
> >
> lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,
> me
> thod
> ="ML")
>
> I got the following error:
>
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>         Calloc could not allocate (65230 of 8) memory
> In addition: Warning message:
> Reached total allocation of 120Mb: see help(memory.size)
>
> I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb 
> processor. My version of R is 1.7.1.
>
> Thanks in advance,
>
> Rodrigo Abt.
> Department of Economic and Tributary Studies,
> SII, Chile.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Wed Nov 12 17:44:05 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Nov 2003 17:44:05 +0100
Subject: [R] "/" operator in model formula
In-Reply-To: <Pine.LNX.4.44.0311121557260.4998-100000@gannet.stats>
References: <Pine.LNX.4.44.0311121557260.4998-100000@gannet.stats>
Message-ID: <x28ymlv8oa.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> The difference is between testing and crossing. In a / b the levels 
> of b are unrelated for different levels of a, whereas in a*b they are the 
> same levels.

"...nesting and crossing", of course.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Wed Nov 12 17:39:23 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 Nov 2003 11:39:23 -0500 (EST)
Subject: [R] Chron, as.POSIXct problem
Message-ID: <20031112163923.EE20B397A@mprdmxin.myway.com>




You are being hit by a timezone problem.  Its not really shifting 
the days by one.  Its working in the GMT timezone, not yours.

If you can accept a date format that chron supports then this is the 
easiest solution since chron does not support timezones and so can't
give you such problems in the first place.  For example, 
the following stays in chron the whole time:

   format(datesTest, format="m/day/year")
   [1] "Oct/01/1952" "Oct/02/1952" "Oct/03/1952"

If you must convert to POSIXt to take advantage of a format
only supported by POSIXt then use POSIXlt and specify the timezone explictly:

   format(as.POSIXlt(datesTest,tz="GMT"), "%m/%d/%Y")
   [1] "10/01/1952" "10/02/1952" "10/03/1952"

Its because of subtle problems like this that I think that some 
sort of naive (i.e. non-timezone) time such as chron or 
an alternative, should be in the base to encourage wider use.

--- 
Date: Wed, 12 Nov 2003 10:05:39 -0500 
From: Brian Beckage <bbeckage at uvm.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Chron, as.POSIXct problem 

 
 
Dear R list,

I noticed the following 'problem' when changing the format of dates 
created with seq.dates() (from the Chron library) using as.POSIXct() 
(R 1.8.0 on OSX 10.2.8):

> datesTest<-seq.dates(from="10/01/1952", length=3, by="days");
> datesTest
[1] 10/01/52 10/02/52 10/03/52

# Now changing the format to show year as 1952.

> datesTest<-format(as.POSIXct(datesTest), "%m/%d/%Y")
> datesTest
[1] "09/30/1952" "10/01/1952" "10/02/1952"
>

The dates were shifted by one day. The work around is simple enough, e.g.,

> datesTest<-format(as.POSIXct(datesTest+1), "%m/%d/%Y")
[1] "10/01/1952" "10/02/1952" "10/03/1952"

but I wonder if this is the intended behavior?

Brian

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.pagel at gsf.de  Wed Nov 12 17:39:15 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Wed, 12 Nov 2003 17:39:15 +0100
Subject: [R] postscript: font size in text(x,y,label)?
In-Reply-To: <3FB25A31.3090109@yale.edu>
References: <200311011104.hA1B4SPY016224@hypatia.math.ethz.ch>
	<3FB25A31.3090109@yale.edu>
Message-ID: <20031112163914.GA10560@porcupine.gsf.de>

	Hi!
	
> I would like to just create my (point) labels [created by 
> text(x,y,labels)] in smaller font size, especially when I write out to 
> eps.  all other point sizes should not change.  is this possible?  help 

I don't know how to define the point size exactly (since ps=something
does not work in text()) but using the cex option is a workaround:

plot(1:100, (1:100)^2)
text(10,1000, "foo")
text(10,2000, "foo", cex=2)

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From edd at debian.org  Wed Nov 12 17:51:56 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 12 Nov 2003 10:51:56 -0600
Subject: [R] postscript: font size in text(x,y,label)?
In-Reply-To: <3FB25A31.3090109@yale.edu>
References: <200311011104.hA1B4SPY016224@hypatia.math.ethz.ch>
	<3FB25A31.3090109@yale.edu>
Message-ID: <20031112165156.GA11760@sonny.eddelbuettel.com>

On Wed, Nov 12, 2003 at 11:05:05AM -0500, ivo welch wrote:
> 
> I would like to just create my (point) labels [created by 
> text(x,y,labels)] in smaller font size, especially when I write out to 
> eps.  all other point sizes should not change.  is this possible?  help 
> appreciated.  regards, /iaw

You didn't read  help(text),  did you?  Anyway, works as advertised:

plot(1:10)
text(2,2,"small",cex=0.5)
text(4,4,"big",cex=1.5)

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From andy_liaw at merck.com  Wed Nov 12 18:00:06 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 12 Nov 2003 12:00:06 -0500
Subject: [R] repeat  until function
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE18@usrymx25.merck.com>

As others already pointed out, the fast way is to use sample().

What I'd like to add is the following, which I learned from peeking at the C
code underneath sample():  To draw n samples without replacement from 1:N
(N>=n), you only need a loop from 1 to n that used up n random numbers.  The
algorithm is simple, but IMHO very clever:

pop <- 1:N
samp <- rep(NA, n)
soFar <- N
for (i in 1:n) {
    idx <- ceiling(runif(1) * soFar)
    samp[i] <- pop[idx]
    ## swap the soFar-th and idx-th element of pop.
    tmp <- pop[soFar]
    pop[soFar] <- pop[idx]
    pop[idx] <- tmp
    ## decrease the population by 1.
    soFar <- soFar - 1
}

This is obviously not efficient in high-level languages like R, but in terms
of algorithm, it is a lot more efficient than check-and-reject.  IMHO this
should be described in some book, but I have not seen any book describing
it.

Just my $0.02...
Andy

> -----Original Message-----
> From: Ragnhild S?rum [mailto:rsoerum80 at hotmail.com] 
> Sent: Wednesday, November 12, 2003 9:26 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] repeat until function
> 
> 
> Hi,
> 
> I'm in this situation:
> I what to generate N random numbers(integer) that are 
> different from each 
> other.
> One suggestion:
> 
> tabel <- rep(NULL, N)
> for (i in 1:N){
>    temp <- as.integer(runif(1,1,max))
>    if(temp in tabel) {
>        repeat (?) (temp <- as.integer(runif(i,i,max)))
>        until (?) ((temp in tabel) ==FALSE)
>    }
>    else{ tabel[i] <- temp}
> 
> I can't use repeat/until - don't exist....
> Any suggestions?
> 
> 
> Thanks
> *Ragnhild*
> 
> _________________________________________________________________
> MSN Messenger http://www.msn.no/messenger Den korteste veien 
> mellom deg og 
> dine venner
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From apv at capital.net  Wed Nov 12 18:10:41 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 12 Nov 2003 12:10:41 -0500
Subject: [R] RMySQL
Message-ID: <1068657041.614.9.camel@redtail.mydomain.home>

HI,

I have been having trouble installing RMySQL under Redhat Linux 9.0.  I
am using R 1.8.0 and MySQL 4.0.13.  MySQL is install in /opt/mysql.  I
try to install RMySQL using configure-args to specify the path of mysql
but it does not work.  Does any body have any suggestions.

Thanks,
Arend van der Veen


The command that I am using is:

# R CMD INSTALL --configure-args='--with-mysql-dir=/opt/mysql' \
> RMySQL_0.5-2.tar.gz

I get the following response:

* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for mysql_init in -lmysqlclient... no
checking for mysql.h... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for /usr/local/include/mysql/mysql.h... no
checking for /usr/include/mysql/mysql.h... no
checking for /usr/local/mysql/include/mysql/mysql.h... no
checking for /opt/include/mysql/mysql.h... no
checking for /include/mysql/mysql.h... no
 
Configuration error:
  could not find the MySQL installation include and/or library
  directories.  Manually specify the location of the MySQL
  libraries and the header files and re-run R CMD INSTALL.
 
INSTRUCTIONS:
 
1. Define and export the 2 shell variables PKG_CPPFLAGS and
   PKG_LIBS to include the directory for header files (*.h)
   and libraries, for example (using Bourne shell syntax):
 
      export PKG_CPPFLAGS="-I<MySQL-include-dir>"
      export PKG_LIBS="-L<MySQL-lib-dir> -lmysqlclient"
 
   Re-run the R INSTALL command:
 
      R CMD INSTALL RMySQL_<version>.tar.gz
 
2. Alternatively, you may pass the configure arguments
      --with-mysql-dir=<base-dir> (distribution directory)
   or
      --with-mysql-inc=<base-inc> (where MySQL header files reside)
      --with-mysql-lib=<base-lib> (where MySQL libraries reside)
   in the call to R INSTALL --configure-args='...'
 
   R CMD INSTALL --configure-args='--with-mysql-dir=DIR'
RMySQL_<version>.tar.gz
 
ERROR: configuration failed for package 'RMySQL'
** Removing '/opt/r-1.8.0/lib/R/library/RMySQL'



From jun at galton.uchicago.edu  Wed Nov 12 18:41:17 2003
From: jun at galton.uchicago.edu (Mikyoung Jun)
Date: Wed, 12 Nov 2003 11:41:17 -0600 (CST)
Subject: [R] question about matrix
Message-ID: <Pine.LNX.4.44.0311121137540.8049-100000@pelham.uchicago.edu>

Hello,

I have a few questions about matrix in R. 

Can we make a matrix whose elements are list? I would like to save two
different values in each elements of matrix. If there is a package or
something which can deal with complex numbers, that will do it too. Also,
I am wondering whether there is a function to calculate the rank of the
matrix. I found a matrix package, but it doesn't have functions like that.

Thanks a lot in advance!

Mikyoung Jun



From ripley at stats.ox.ac.uk  Wed Nov 12 18:45:09 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 17:45:09 +0000 (GMT)
Subject: [R] repeat  until function
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE18@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0311121739430.5377-100000@gannet.stats>

On Wed, 12 Nov 2003, Liaw, Andy wrote:

> As others already pointed out, the fast way is to use sample().
> 
> What I'd like to add is the following, which I learned from peeking at the C
> code underneath sample():  To draw n samples without replacement from 1:N
> (N>=n), you only need a loop from 1 to n that used up n random numbers.  The
> algorithm is simple, but IMHO very clever:
> 
> pop <- 1:N
> samp <- rep(NA, n)
> soFar <- N
> for (i in 1:n) {
>     idx <- ceiling(runif(1) * soFar)
>     samp[i] <- pop[idx]
>     ## swap the soFar-th and idx-th element of pop.
>     tmp <- pop[soFar]
>     pop[soFar] <- pop[idx]
>     pop[idx] <- tmp
>     ## decrease the population by 1.
>     soFar <- soFar - 1
> }
> 
> This is obviously not efficient in high-level languages like R, but in terms
> of algorithm, it is a lot more efficient than check-and-reject.  IMHO this
> should be described in some book, but I have not seen any book describing
> it.

Ripley (1987) Stochastic Simulation, pp.80-1 for one.  I am pretty sure it
is Knuth's book, although I don't have that to hand.  I attribute it to 
Moses & Oakford (1963).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Wed Nov 12 19:03:36 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Nov 2003 19:03:36 +0100
Subject: [R] repeat  until function
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE18@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE18@usrymx25.merck.com>
Message-ID: <x2znf1tqfb.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> This is obviously not efficient in high-level languages like R, but in terms
> of algorithm, it is a lot more efficient than check-and-reject.  IMHO this
> should be described in some book, but I have not seen any book describing
> it.

I'm pretty sure I have - way back. Can't recall exactly where though.
Either in a CS book or as an exercise in a stats book (proving that it
actually works).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Wed Nov 12 19:03:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2003 18:03:57 +0000 (GMT)
Subject: [R] RMySQL
In-Reply-To: <1068657041.614.9.camel@redtail.mydomain.home>
Message-ID: <Pine.LNX.4.44.0311121800390.5519-100000@gannet.stats>

Do you actually have the MySQL client libraries installed?  They are in a
separate RPM, if you used RPMs, something like
MySQL-client-4.0.16-0.i386.rpm.

On 12 Nov 2003, Arend P. van der Veen wrote:

> I have been having trouble installing RMySQL under Redhat Linux 9.0.  I
> am using R 1.8.0 and MySQL 4.0.13.  MySQL is install in /opt/mysql.  I
> try to install RMySQL using configure-args to specify the path of mysql
> but it does not work.  Does any body have any suggestions.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From heimdal at aracnet.com  Wed Nov 12 19:09:12 2003
From: heimdal at aracnet.com (heimdal@aracnet.com)
Date: Wed, 12 Nov 2003 18:09:12 GMT
Subject: Subject: RE: [R] Time plot question.
Message-ID: <200311121812.hACICWGA018509@obsidian.spiritone.com>

Hello,

Thank you for your reply. I am missing an intermediate step as

> plot( strptime( Time, format = "%H:%M:%S"), FreeMemory)
Error in strptime(Time, format = "%H:%M:%S") :
        invalid `x' argument
> plot( strptime( c(Time), format = "%H:%M:%S"), FreeMemory)
Error in strptime(c(Time), format = "%H:%M:%S") :
        invalid `x' argument

does not work. My "Time" data is part of a data.frame. Do I need to
"as.POSIXlt" this in some way, and if so, how?
I will continue to work on this, and buy a suitable book on R so as not to
plague this excellent news group with such questions. I could generate a
sequence of ISODates similar to my
data, but I would like to use the actual Time coordinates instead. Here is
my "Time" data below:

> Time
  [1] 12:39:26 12:40:22 12:41:19 12:42:15 12:43:11 12:44:08 12:45:04
12:46:00
  [9] 12:46:57 12:47:53 12:48:49 12:49:46 12:50:42 12:51:38 12:52:35
12:53:31
 [17] 12:54:27 12:55:24 12:56:20 12:57:16 12:58:13 12:59:09 13:00:05
13:01:01
 [25] 13:01:58 13:02:54 13:03:50 13:04:47 13:05:43 13:06:39 13:07:36
13:08:32
 [33] 13:09:28 13:10:25 13:11:21 13:12:17 13:13:14 13:14:10 13:15:06
13:16:03
 [41] 13:16:59 13:17:55 13:18:52 13:19:48 13:20:44 13:21:41 13:22:37
13:23:33
 [49] 13:24:30 13:25:26 13:26:22 13:27:19 13:28:15 13:29:11 13:30:07
13:31:04
 [57] 13:32:00 13:32:56 13:33:53 13:34:49 13:35:46 13:36:42 13:37:39
13:38:35
 [65] 13:39:32 13:40:28 13:41:24 13:42:21 13:43:17 13:44:13 13:45:10
13:46:06
 [73] 13:47:02 13:47:59 13:48:55 13:49:51 13:50:48 13:51:44 13:52:40
13:53:37
 [81] 13:54:33 13:55:29 13:56:26 13:57:22 13:58:19 13:59:15 14:00:11
14:01:08
 [89] 14:02:05 14:03:01 14:03:57 14:04:54 14:05:50 14:06:46 14:07:42
14:08:39
 [97] 14:09:35 14:10:31 14:11:28 14:12:24 14:13:20 14:14:17 14:15:13
14:16:09
[105] 14:17:06 14:18:02 14:18:58 14:19:55 14:20:51 14:21:47 14:22:44
14:23:40
[113] 14:24:36 14:25:32 14:26:29 14:27:25 14:28:21 14:29:18 14:30:14
14:31:10
120 Levels: 12:39:26 12:40:22 12:41:19 12:42:15 12:43:11 12:44:08 ...
14:31:10
>

Enjoying a little "R and R",

John



From dmurdoch at pair.com  Wed Nov 12 19:27:27 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 12 Nov 2003 13:27:27 -0500
Subject: [R] repeat  until function
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE18@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE18@usrymx25.merck.com>
Message-ID: <4mu4rvglotuqhrk4f5f1m3bf1slvfv3j4s@4ax.com>

On Wed, 12 Nov 2003 12:00:06 -0500, "Liaw, Andy" <andy_liaw at merck.com>
wrote :


>This is obviously not efficient in high-level languages like R, but in terms
>of algorithm, it is a lot more efficient than check-and-reject.  IMHO this
>should be described in some book, but I have not seen any book describing
>it.

That's a variation on the standard shuffling algorithm, which is
described in Knuth (but is not original to him). What you described
takes time n but uses storage N.  There's also a very similar
variation that takes time N and storage n; this is equivalent to the
McLeod and Bellhouse (1983) sampling algorithm.

Duncan murdoch



From apv at capital.net  Wed Nov 12 19:36:32 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 12 Nov 2003 13:36:32 -0500
Subject: [R] RMySQL & couldn't find function ".valueClassTest"
In-Reply-To: <Pine.LNX.4.44.0311121800390.5519-100000@gannet.stats>
References: <Pine.LNX.4.44.0311121800390.5519-100000@gannet.stats>
Message-ID: <1068662192.614.28.camel@redtail.mydomain.home>

I compile MySQL from source and do have the client libraries installed
(I can run mysql from a terminal)  However, I was able to compile RMySQL
by:

# export PKG_CPPFLAGS="-I/opt/mysql/include"
# export PKG_LIBS="-L/opt/mysql/lib -lmysqlclient"
# R CMD INSTALL RMySQL_0.5-2.tar.gz

Now I am having the problem that was mentioned at 

http://stat.bell-labs.com/RS-DBI/download/index.html

with

> m <- dbDriver("MySQL")
> Error in dbDriver("MySQL") : couldn't find function ".valueClassTest"

One of the solutions was to patch R 1.8.0.  I downloaded R-release.diff.gz but I am not
sure what to do with it.  Does anybody know of any documentation that can
guide me ?

Thanks again,
Arend van der Veen


On Wed, 2003-11-12 at 13:03, Prof Brian Ripley wrote:
> Do you actually have the MySQL client libraries installed?  They are in a
> separate RPM, if you used RPMs, something like
> MySQL-client-4.0.16-0.i386.rpm.
> 
> On 12 Nov 2003, Arend P. van der Veen wrote:
> 
> > I have been having trouble installing RMySQL under Redhat Linux 9.0.  I
> > am using R 1.8.0 and MySQL 4.0.13.  MySQL is install in /opt/mysql.  I
> > try to install RMySQL using configure-args to specify the path of mysql
> > but it does not work.  Does any body have any suggestions.
>



From jc at or.psychology.dal.ca  Wed Nov 12 20:10:19 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Wed, 12 Nov 2003 15:10:19 -0400
Subject: [R] CircStats reveals underlying R bug?
In-Reply-To: <Pine.LNX.4.44.0311120826060.18206-100000@bolker.zoo.ufl.edu>
References: <Pine.LNX.4.44.0311120826060.18206-100000@bolker.zoo.ufl.edu>
Message-ID: <DB60096E-1543-11D8-8327-000A956DE534@or.psychology.dal.ca>


On Nov 12, 2003, at 9:28 AM, Ben Bolker wrote:

>
>   Maybe you should take this up with package maintainers (who may or 
> may
> not be reading R-help) ... this sounds like a design/documentation 
> issue
> rather than a "bug" per se (although the distinction is not always 
> clear).
> To be honest, the underlying R code in CircStats doesn't seem terribly
> sophisticated -- I have hacked it some for my own use (e.g. to allow
> the various von Mises functions (rvm, dvm, etc.) to handle vectors of
> different parameter values).

Thanks, I have done that.  But, I also think it is good to let the list 
know and be forewarned of a potential problem.  If someone had a large 
data set with a small number of negative angles they may have never 
spotted the problem if they relied on circ.plot.



From mcaj at tci.ufal.br  Wed Nov 12 20:34:38 2003
From: mcaj at tci.ufal.br (mcaj@tci.ufal.br)
Date: Wed, 12 Nov 2003 16:34:38 -0300
Subject: [R] Usando Tcltk com o Sistema R
Message-ID: <1068665678.3fb28b4e276c1@webmail.tci.ufal.br>



   Fiz um arquivo em tcltk para ser utilizado no Sistema R, por?m estou 
necessitanto neste arquivo de chamar uma fun??o do R, ent?o saberia me 
informar como chamo uma fun??o do R em um arquivo TclTk?

   Algu?m poderia me d? alguma sugest?o quanto a utilizar a liguagem TclTk 
(com o comando .Tcl("comando TclTk")) ou utilizar o pr?prio pacote Tcltk do 
sistema R? Qual a melhor op??o? Por que?

   Desde j? agrade?o a aten??o de todos.



   Marcos Cerqueira J?nior
       UFAL - Brasil
      

-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From tblackw at umich.edu  Wed Nov 12 20:36:22 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 12 Nov 2003 14:36:22 -0500 (EST)
Subject: [R] question about matrix
In-Reply-To: <Pine.LNX.4.44.0311121137540.8049-100000@pelham.uchicago.edu>
References: <Pine.LNX.4.44.0311121137540.8049-100000@pelham.uchicago.edu>
Message-ID: <Pine.SOL.4.58.0311121408390.24798@zektor.gpcc.itd.umich.edu>

Mikyoung  -

All answers are "yes", but IMHO you are trying to be
too clever with your data structure.  Programming is
*much* easier if you keep things simple.

Specifically:

(1)  The function  matrix()  will happily build you
a matrix of type "list", with each element of the list
occupying one cell in the matrix.  For example,

tma <- matrix(as.list(letters), nrow=13, ncol=2)
is.list(tma)
[1] TRUE
is.matrix(tma)
[1] TRUE
tma[5,2]
[[1]]
[1] "r"

Same effect with

tma <- as.list(letters)
dim(tma) <- c(13,2)

(2)  Complex numbers - see  help("complex").  This
help page even gives an example which constructs a
matrix of complex numbers.

(3)  To find the rank of matrix  x,  qr(x)$rank.
I don't think there is a specific extractor function
for this component, but I could be wrong.

(4)  But, once again, I think you would be better served by
storing your two values of different types either as two
separate matrices, or as two columns in a data frame, with
additional columns of repetitive integers to indicate the
row and column in your conceptual matrix.

See  help("tapply"),  help("aggregate")  for two functions
which can operate on such a data structure, and  help("gl")
help("col"), help("row")  for functions that will generate
the additional columns.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 12 Nov 2003, Mikyoung Jun wrote:

> Hello,
>
> I have a few questions about matrix in R.
>
> Can we make a matrix whose elements are list? I would like to save two
> different values in each elements of matrix. If there is a package or
> something which can deal with complex numbers, that will do it too. Also,
> I am wondering whether there is a function to calculate the rank of the
> matrix. I found a matrix package, but it doesn't have functions like that.
>
> Thanks a lot in advance!
>
> Mikyoung Jun
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mcaj at tci.ufal.br  Wed Nov 12 20:41:21 2003
From: mcaj at tci.ufal.br (mcaj@tci.ufal.br)
Date: Wed, 12 Nov 2003 16:41:21 -0300
Subject: [R] Using tcltk language with R system
Message-ID: <1068666081.3fb28ce11172b@webmail.tci.ufal.br>



Hello, Does anybody know how can i call a R function in a tcltk file? I made 
a tcltk file, but I need call functions in R. i.e: in R I can put .Tcl("tcltk 
statement"). There are a same command to call R in a tcltk file?

  I want to make a R Gui using tcltk language, do you recommend use a tcltk or 
a R pack tcltk and don't use tcltk language?

  Thanks for your attention.


  Marcos Cerqueira J?nior
 Alagoas University - Brazil


-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From MSchwartz at medanalytics.com  Wed Nov 12 20:49:01 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 12 Nov 2003 13:49:01 -0600
Subject: [R] Using tcltk language with R system
In-Reply-To: <1068666081.3fb28ce11172b@webmail.tci.ufal.br>
References: <1068666081.3fb28ce11172b@webmail.tci.ufal.br>
Message-ID: <1068666540.4541.566.camel@localhost.localdomain>

On Wed, 2003-11-12 at 13:41, mcaj at tci.ufal.br wrote:
> Hello, Does anybody know how can i call a R function in a tcltk file? I made 
> a tcltk file, but I need call functions in R. i.e: in R I can put .Tcl("tcltk 
> statement"). There are a same command to call R in a tcltk file?
> 
>   I want to make a R Gui using tcltk language, do you recommend use a tcltk or 
> a R pack tcltk and don't use tcltk language?
> 
>   Thanks for your attention.
> 
> 
>   Marcos Cerqueira J?nior
>  Alagoas University - Brazil


You might want to look at John Fox's RCmdr:

http://socserv.mcmaster.ca/jfox/Misc/Rcmdr/

Which I suspect, does what you are considering, though not to dissuade
you in any way from contributing...  :-)

HTH,

Marc Schwartz



From trond.rafoss at planteforsk.no  Wed Nov 12 20:53:34 2003
From: trond.rafoss at planteforsk.no (Trond Rafoss)
Date: Wed, 12 Nov 2003 20:53:34 +0100
Subject: [R] RMySQL & couldn't find function ".valueClassTest"
Message-ID: <625C3FEB6AEAE14486CAFA82A001C8AD53F751@post.planteforsk.no>

Hi Arend, I had the same problem on RH 9 as you, but the tip on http://stat.bell-labs.com/RS-DBI/download/index.html at the bottom telling:

""""""""""""""""""""""""""""""""""""""""" 
The following are some workarounds: 

append the line 
export(.valueClassTest)

to the file $R_HOME/src/library/methods/NAMESPACE where $R_HOME refers to the directory where you have R 1.8.0 installed. 
""""""""""""""""""""""""""""""""""""""""""

fixed the problem for me, and I can use RMySQL successfully on RedHat 9 !

Regards, Trond Rafoss

-----Original Message-----
From:	Arend P. van der Veen [mailto:apv at capital.net]
Sent:	Wed 11/12/2003 7:36 PM
To:	r-help at stat.math.ethz.ch
Cc:	
Subject:	Re: [R] RMySQL & couldn't find function ".valueClassTest"
I compile MySQL from source and do have the client libraries installed
(I can run mysql from a terminal)  However, I was able to compile RMySQL
by:

# export PKG_CPPFLAGS="-I/opt/mysql/include"
# export PKG_LIBS="-L/opt/mysql/lib -lmysqlclient"
# R CMD INSTALL RMySQL_0.5-2.tar.gz

Now I am having the problem that was mentioned at 

http://stat.bell-labs.com/RS-DBI/download/index.html

with

> m <- dbDriver("MySQL")
> Error in dbDriver("MySQL") : couldn't find function ".valueClassTest"

One of the solutions was to patch R 1.8.0.  I downloaded R-release.diff.gz but I am not
sure what to do with it.  Does anybody know of any documentation that can
guide me ?

Thanks again,
Arend van der Veen


On Wed, 2003-11-12 at 13:03, Prof Brian Ripley wrote:
> Do you actually have the MySQL client libraries installed?  They are in a
> separate RPM, if you used RPMs, something like
> MySQL-client-4.0.16-0.i386.rpm.
> 
> On 12 Nov 2003, Arend P. van der Veen wrote:
> 
> > I have been having trouble installing RMySQL under Redhat Linux 9.0.  I
> > am using R 1.8.0 and MySQL 4.0.13.  MySQL is install in /opt/mysql.  I
> > try to install RMySQL using configure-args to specify the path of mysql
> > but it does not work.  Does any body have any suggestions.
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From a9265 at stud.uni-bayreuth.de  Wed Nov 12 21:21:31 2003
From: a9265 at stud.uni-bayreuth.de (Thomas Stabla)
Date: Wed, 12 Nov 2003 21:21:31 +0100 (MET)
Subject: [R] setValidity and "initialize" method conflict ?
Message-ID: <Pine.GSO.4.21.0311122118090.16351-200000@btr0xe.rz.uni-bayreuth.de>

Hello,

i am using classes and want to force an validity check when an
object is created.

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.1
year     2003
month    06
day      16
language R


Following piece of code works fine, just like I expected it to
----------
> setClass("Foo", representation(woo = "numeric"))
[1] "Foo"
> validFooObject <- function(object) {
+   if(object at woo > 0) return(TRUE)
+   else return("warning: negative value for woo")}
> setValidity("Foo", validFooObject)
[1] "Foo"
> new("Foo", woo = 1) # all is fine
An object of class "Foo"
Slot "woo":
[1] 1

> new("Foo", woo = -1) # ok, negative value
Error in validObject(.Object) : Invalid "Foo" object: warning: negative
value for woo
---------

Now, if i define a initialize method for Foo, things change (R had
been restarted)

---------
> setClass("Foo", representation(woo = "numeric"))
[1] "Foo"
> validFooObject <- function(object) {
+   if(object at woo > 0) return(TRUE)
+   else return("warning: negative value for woo")}
> setValidity("Foo", validFooObject)
[1] "Foo"
> setMethod("initialize", "Foo", function(.Object, woo){
+   .Object at woo = woo
+   .Object})
[1] "initialize"
> new("Foo", woo = 1) # all is fine
An object of class "Foo"
Slot "woo":
[1] 1

> new("Foo", woo = -1) # ! no warning, object created!
An object of class "Foo"
Slot "woo":
[1] -1
---------

How do i force an validity check, when an initalize method has been
set?
Thanks for your help.

Greetings,
Thomas Stabla
-------------- next part --------------
setClass("Foo", representation(woo = "numeric"))
validFooObject <- function(object) { 
  if(object at woo > 0) return(TRUE)
  else return("warning: negative value for woo")} 
setValidity("Foo", validFooObject)
new("Foo", woo = 1) # all is fine
new("Foo", woo = -1) # ok, negative value
###############################################
setClass("Foo", representation(woo = "numeric"))
validFooObject <- function(object) { 
  if(object at woo > 0) return(TRUE)
  else return("warning: negative value for woo")} 
setValidity("Foo", validFooObject)
setMethod("initialize", "Foo", function(.Object, woo){
  .Object at woo = woo
  .Object})
new("Foo", woo = 1) # all is fine
new("Foo", woo = -1) # ! no warning message is produced !

From mlaia at fcav.unesp.br  Wed Nov 12 21:39:08 2003
From: mlaia at fcav.unesp.br (Marcelo Luiz de Laia)
Date: Wed, 12 Nov 2003 18:39:08 -0200
Subject: [R] I receiv an error when try to run a function...
Message-ID: <DFECKFJKEJHHMLJFFEOMKEJDCBAA.mlaia@fcav.unesp.br>

Hi All,

I use R 1.8.0 and Bioconductor packages in Windows 2000 professional.

When I try to run one function, I will receive one dialog box with this
message:

Rgui.exe has generate errors and will be closed by Windows.
You will need to restart the program.
An error log is being created.

I look in for in my system for the "error log", but nothing...

I search in microsoft KB database, but nothing, too.

I do not search in R-help archieves.

Do someone already see this problem?

Thanks

Marcelo Luiz de Laia, M.Sc.
Dep. de Tecnologia, Lab. Bioqu?mica e de Biologia Molecular
Universidade Estadual Paulista - UNESP
Via de Acesso Prof. Paulo Donato Castelane, Km 05
14.884-900 - Jaboticabal, SP, Brazil
PhoneFax: 16 3209-2675/2676/2677 R. 202/208/203 (trab.)
Phone res: 16 3203 2328 - www.lbm.fcav.unesp.br - mlaia at yahoo.com
---



From p.murrell at auckland.ac.nz  Wed Nov 12 21:25:26 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 13 Nov 2003 09:25:26 +1300
Subject: [R] Alpha values
References: <Pine.LNX.4.44.0311121601290.4998-100000@gannet.stats>
Message-ID: <3FB29736.7020706@stat.auckland.ac.nz>

Hi

The only other current possibility I know of is by producing grid 
graphics output in SVG format.  A simple example ...

library(grid)
# Get from http://www.stat.auckland.ac.nz/~paul/
library(gridSVG)
# Important
push.viewport(viewport(gp=gpar(col="black", fill=NA)))
grid.circle(x=0.4, r=0.3, gp=gpar(fill="green", alpha=0.3))
grid.circle(x=0.6, r=0.3, gp=gpar(fill="red", alpha=0.3))
# Important
pop.viewport()
# Produce files test.svg and test.svg.html
# test.svg.html can be viewed by, e.g., Adobe SVG Viewer 3.0 in IE
gridToSVG("test.svg")

Of course, you have to use grid, and gridSVG (which is very 
experimental), and you only get SVG, so it depends on how badly you want 
transparency.

Paul


Prof Brian Ripley wrote:
> Yes, but currently only alpha=0 and alpha=255 are supported by the
> available devices that I know of (and I introduced this).
> 
> Adding alpha-level support is complicated for the devices people normally
> use, although it would be trivial in PDF1.4.
> 
> On Wed, 12 Nov 2003, Crispin Miller wrote:
> 
> 
>>Does anyone know whether it is possible to construct a colour for
>>plotting with an alpha value as well as simply specifying rgb values?
> 
> 


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From bbeckage at uvm.edu  Wed Nov 12 23:09:14 2003
From: bbeckage at uvm.edu (Brian Beckage)
Date: Wed, 12 Nov 2003 17:09:14 -0500
Subject: [R] Chron, as.POSIXct problem
In-Reply-To: <20031112163923.EE20B397A@mprdmxin.myway.com>
References: <20031112163923.EE20B397A@mprdmxin.myway.com>
Message-ID: <p06010204bbd85cb11675@[132.198.177.56]>

Thanks to all who responded to my posting.

At 11:39 AM -0500 11/12/03, Gabor Grothendieck wrote:
>You are being hit by a timezone problem.  Its not really shifting
>the days by one.  Its working in the GMT timezone, not yours.
>
>If you can accept a date format that chron supports then this is the
>easiest solution since chron does not support timezones and so can't
>give you such problems in the first place.  For example,
>the following stays in chron the whole time:
>
>    format(datesTest, format="m/day/year")
>    [1] "Oct/01/1952" "Oct/02/1952" "Oct/03/1952"
>
>If you must convert to POSIXt to take advantage of a format
>only supported by POSIXt then use POSIXlt and specify the timezone explictly:
>
>    format(as.POSIXlt(datesTest,tz="GMT"), "%m/%d/%Y")
>    [1] "10/01/1952" "10/02/1952" "10/03/1952"

This solved the problem using as.POSIXlt().  I guess the tz argument 
doesn't solve the problem using as.POSIXct().  In any case, I'm able 
to use as.POSIXlt() in my current application.

>
>Its because of subtle problems like this that I think that some
>sort of naive (i.e. non-timezone) time such as chron or
>an alternative, should be in the base to encourage wider use.

I agree. Thanks again for your help.

Brian

>
>---
>Date: Wed, 12 Nov 2003 10:05:39 -0500
>From: Brian Beckage <bbeckage at uvm.edu>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] Chron, as.POSIXct problem
>
>
>
>Dear R list,
>
>I noticed the following 'problem' when changing the format of dates
>created with seq.dates() (from the Chron library) using as.POSIXct()
>(R 1.8.0 on OSX 10.2.8):
>
>>  datesTest<-seq.dates(from="10/01/1952", length=3, by="days");
>>  datesTest
>[1] 10/01/52 10/02/52 10/03/52
>
># Now changing the format to show year as 1952.
>
>>  datesTest<-format(as.POSIXct(datesTest), "%m/%d/%Y")
>>  datesTest
>[1] "09/30/1952" "10/01/1952" "10/02/1952"
>>
>
>The dates were shifted by one day. The work around is simple enough, e.g.,
>
>>  datesTest<-format(as.POSIXct(datesTest+1), "%m/%d/%Y")
>[1] "10/01/1952" "10/02/1952" "10/03/1952"
>
>but I wonder if this is the intended behavior?
>
>Brian
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>_______________________________________________
>No banners. No pop-ups. No kidding.
>Introducing My Way - http://www.myway.com



From andrewr at uidaho.edu  Wed Nov 12 23:18:03 2003
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 12 Nov 2003 14:18:03 -0800 (PST)
Subject: [R] lme: estimates and confidence intervals for crossed fixed
	effects
Message-ID: <Pine.GSO.4.51.0311121337280.14582@cyclone.csrv.uidaho.edu>

Hi all,

I'm fitting a mixed-effects model that has two fixed factors and their
interaction.  I'd like to obtain a dataframe of estimates and
standard errors for the estimates for each combination of the levels.

A    B   Yhat  se
a1  b1
a1  b2
a1  b3
a2  b1
a2  b2
a2  b3

etc

I believe that I could use the correlation matrix and the estimated
standard errors, but I wonder if this problem has been solved?

Thanks for any pointers.

Andrew

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From andy_liaw at merck.com  Wed Nov 12 23:31:27 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 12 Nov 2003 17:31:27 -0500
Subject: [R] repeat  until function
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE21@usrymx25.merck.com>

> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> 
> Ripley (1987) Stochastic Simulation, pp.80-1 for one.  I am 
> pretty sure it is Knuth's book, although I don't have that to 
> hand.  I attribute it to 
> Moses & Oakford (1963).

Thanks to Brian, Peter and Duncan for the info.  And I have both Ripley
(1987) and Knuth (1981), just not smart enough to look there...

The shuffling algorithm is described on pp. 139-140 in Knuth's book (vol. 2,
2nd ed.), and in addition to Moses & Oakford, he also referenced R.
Durstenfeld, CACM 7 (1964), 420.

Best,
Andy

 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>



From maj at stats.waikato.ac.nz  Wed Nov 12 23:40:03 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 13 Nov 2003 11:40:03 +1300
Subject: [R] Plotting lm() attributes
Message-ID: <3FB2B6C3.3090100@stats.waikato.ac.nz>

Suppose you fit a linear model

 > model.1 ~ lm(v1 ~ ..., data=myframe)

and v2 is some other column of myframe typically not in the model. You 
will often want to try

 > plot(v2, model.1$residuals)

but this will fail if there are NAs in the response v1 as 
model.1$residuals has length equal to the number of nonmissing values in 
  v1. I suppose

 > plot(v2[!is.na(v1)], model.1$residuals)

does the job, but it seems irritating that model.1$residuals, does not 
have length agreeing with the number of rows in the data frame. It would 
be even more irritating for model.1$fitted.values, where the removed 
elements would often have nonmissing values.

Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From znmeb at aracnet.com  Wed Nov 12 23:45:14 2003
From: znmeb at aracnet.com (M. Edward (Ed) Borasky)
Date: Wed, 12 Nov 2003 14:45:14 -0800 (PST)
Subject: [R] Formatting axis label numbers on plots
Message-ID: <Pine.LNX.4.44.0311121440260.22742-100000@onyx.spiritone.com>

Is there any way to control the format of the axis label numbers on a
plot? More specifically, I have some plots that get axes with label
numbers in exponential format, and I'd like to change that to
non-exponential. Thanks!!


-- 
M. Edward (Ed) Borasky, MS, MNLP, NST, FBG, PGS & PTA

znmeb at borasky-research.net
http://www.borasky-research.net



From sue at xlsolutions-corp.com  Wed Nov 12 23:57:46 2003
From: sue at xlsolutions-corp.com (sue@xlsolutions-corp.com)
Date: Wed, 12 Nov 2003 15:57:46 -0700
Subject: [R] Course***R/Splus Fundamentals and Programming Techniques,
	December 2003 @ 4 locations near you! (Princeton, DC, Boston,
	San Francisco)
Message-ID: <20031112225746.27101.qmail@webmail-2-1.secureserver.net>


   XLSolutions Corporation ([1]www.xlsolutions-corp.com/training.htm) is
   proud
   to announce December 2-day "R/S-plus Fundamentals and Programming
   Techniques".
   ****Washington, DC -----------------> September 11-12
   ****Boston, MA ---------------------> September 11-12
   ****Princeton, NJ ------------------> December 18-19
   ****San Francisco, CA --------------> December 18-19
   Reserve your seat now at the early bird rates! Payment due AFTER the
   class.
   Interested in R/Splus Advanced course? email us.
   Course Description:
   This two-day R/S-plus course focuses on a broad spectrum of topics,
   from reading raw data to a comparison of R and S. We will learn
   the essentials of data manipulation, graphical visualization
   and R/S-plus programming. We will explore statistical data analysis
   tools,
   including graphics with data sets. How to enhance your plots.
   We will perform basic statistics and fit linear regression models.
   Participants are encouraged to bring data for interactive sessions
   With the following outline:
   - An Overview of R: Installation and Demonstration
   - Data Manipulation and Graphics
   - Using Lattice Graphics
   - A Comparison of R and S-Plus
   - How can R Complement SAS?
   - Writing Functions
   - Avoiding Loops
   - Vectorization
   - Statistical Modeling
   - Project Management
   - Techniques for Effective use of R and S
   - Enhancing Plots
   - Using High-level Plotting Functions
   - Building and Distributing Packages (libraries)
   Interested in R/Splus Advanced course? email us.
   Early Bird ends November 30th  ( fee Includes course materials, 90
   days Technical
   Support for R, snacks and continental breakfast!); Email us for group
   discounts.
   Email Sue Turner: [2]sue at xlsolutions-corp.com
   Phone: 206-686-1578 x221
   Visit us: [3]www.xlsolutions-corp.com/training.htm
   Please let us know if you and your colleagues are interested in this
   class
   to take advantage of group discount. Register now to secure your seat!

   Cheers,
   Elvis Miller, PhD
   Manager Training.
   XLSolutions Corporation
   206 686 1578
   [4]www.xlsolutions-corp.com
   [5]elvis at xlsolutions-corp.com

References

   1. http://www.xlsolutions-corp.com/training.htm
   2. mailto:sue at xlsolutions-corp.com
   3. http://www.xlsolutions-corp.com/training.htm
   4. http://www.xlsolutions-corp.com/
   5. mailto:elvis at xlsolutions-corp.com


From tplate at acm.org  Wed Nov 12 23:59:00 2003
From: tplate at acm.org (Tony Plate)
Date: Wed, 12 Nov 2003 15:59:00 -0700
Subject: [R] Plotting lm() attributes
In-Reply-To: <3FB2B6C3.3090100@stats.waikato.ac.nz>
Message-ID: <5.2.1.1.2.20031112155530.03787878@mailhost.blackmesacapital.com>

I believe this is the sort of things that the functions resid() and 
predict(), in conjunction with na.exclude, are designed for.  E.g.:

 > data <- data.frame(x=c(1:5), y=c(1,3,2,NA,4))
 > m <- lm(y~x, data=data, na.action=na.exclude)
 > predict(m)
        1        2        3        4        5
1.400000 2.028571 2.657143       NA 3.914286
 > resid(m)
           1           2           3           4           5
-0.40000000  0.97142857 -0.65714286          NA  0.08571429
 >

Note that NA's are not reintroduced if na.action=na.omit, which is the 
default (unless you have options("na.action") set otherwise).  Also, note 
that this technique produces a NA fitted value where a non-NA one could be 
produced (use predict(m, newdata=data) to get those values.)

hope this helps,

Tony Plate

At Thursday 11:40 AM 11/13/2003 +1300, Murray Jorgensen wrote:
>Suppose you fit a linear model
>
> > model.1 ~ lm(v1 ~ ..., data=myframe)
>
>and v2 is some other column of myframe typically not in the model. You 
>will often want to try
>
> > plot(v2, model.1$residuals)
>
>but this will fail if there are NAs in the response v1 as 
>model.1$residuals has length equal to the number of nonmissing values 
>in  v1. I suppose
>
> > plot(v2[!is.na(v1)], model.1$residuals)
>
>does the job, but it seems irritating that model.1$residuals, does not 
>have length agreeing with the number of rows in the data frame. It would 
>be even more irritating for model.1$fitted.values, where the removed 
>elements would often have nonmissing values.
>
>Murray
>
>--
>Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>Department of Statistics, University of Waikato, Hamilton, New Zealand
>Email: maj at waikato.ac.nz                                Fax 7 838 4155
>Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Tony Plate   tplate at acm.org



From sue at xlsolutions-corp.com  Thu Nov 13 00:00:58 2003
From: sue at xlsolutions-corp.com (sue@xlsolutions-corp.com)
Date: Wed, 12 Nov 2003 16:00:58 -0700
Subject: [R] Course***R/Splus Fundamentals and Programming Techniques,
	December 2003 @ 4 locations near you! (Princeton, DC, Boston,
	San Francisco)   
Message-ID: <20031112230058.27275.qmail@webmail-2-1.secureserver.net>


   XLSolutions Corporation ([1]www.xlsolutions-corp.com/training.htm) is
   proud
   to announce December 2-day "R/S-plus Fundamentals and Programming
   Techniques".
   ****Washington, DC -----------------> December 11-12
   ****Boston, MA ---------------------> December 11-12
   ****Princeton, NJ ------------------> December 18-19
   ****San Francisco, CA --------------> December 18-19
   Reserve your seat now at the early bird rates! Payment due AFTER the
   class.
   Interested in R/Splus Advanced course? email us.
   Course Description:
   This two-day R/S-plus course focuses on a broad spectrum of topics,
   from reading raw data to a comparison of R and S. We will learn
   the essentials of data manipulation, graphical visualization
   and R/S-plus programming. We will explore statistical data analysis
   tools,
   including graphics with data sets. How to enhance your plots.
   We will perform basic statistics and fit linear regression models.
   Participants are encouraged to bring data for interactive sessions
   With the following outline:
   - An Overview of R: Installation and Demonstration
   - Data Manipulation and Graphics
   - Using Lattice Graphics
   - A Comparison of R and S-Plus
   - How can R Complement SAS?
   - Writing Functions
   - Avoiding Loops
   - Vectorization
   - Statistical Modeling
   - Project Management
   - Techniques for Effective use of R and S
   - Enhancing Plots
   - Using High-level Plotting Functions
   - Building and Distributing Packages (libraries)
   Interested in R/Splus Advanced course? email us.
   Early Bird ends November 30th  ( fee Includes course materials, 90
   days Technical
   Support for R, snacks and continental breakfast!); Email us for group
   discounts.
   Email Sue Turner: [2]sue at xlsolutions-corp.com
   Phone: 206-686-1578 x221
   Visit us: [3]www.xlsolutions-corp.com/training.htm
   Please let us know if you and your colleagues are interested in this
   class
   to take advantage of group discount. Register now to secure your seat!

   Cheers,
   Elvis Miller, PhD
   Manager Training.
   XLSolutions Corporation
   206 686 1578
   [4]www.xlsolutions-corp.com
   [5]elvis at xlsolutions-corp.com

References

   1. http://207.68.162.250/cgi-bin/linkrd?_lang=EN&lah=44ad3987d513b8bd2cd75552938f29c9&lat=1068677948&hm___action=http%3a%2f%2fwww%2exlsolutions%2dcorp%2ecom%2ftraining%2ehtm
   2. http://sea1fd.sea1.hotmail.msn.com /cgi-bin/compose?mailto=1&msg=MSG1068677894.65&start=1598889&len=3557&src=&type=x&to=sue%40xlsolutions%2dcorp%2ecom&cc=&bcc=&subject=&body=&curmbox=F000000001&a=dcbbc42ff00f6e1364fa92d526abac37
   3. http://207.68.162.250/cgi-bin/linkrd?_lang=EN&lah=44ad3987d513b8bd2cd75552938f29c9&lat=1068677948&hm___action=http%3a%2f%2fwww%2exlsolutions%2dcorp%2ecom%2ftraining%2ehtm
   4. http://207.68.162.250/cgi-bin/linkrd?_lang=EN&lah=85c9debf73c5b447cbe89d4a85dfb980&lat=1068677948&hm___action=http%3a%2f%2fwww%2exlsolutions%2dcorp%2ecom%2f
   5. http://sea1fd.sea1.hotmail.msn.com/cgi-bin/compose?mailto=1&msg=MSG1068677894.65&start=1598889&len=3557&src=&type=x&to=elvis%40xlsolutions%2dcorp%2ecom&cc=&bcc=&subject=&body=&curmbox=F000000001&a=dcbbc42ff00f6e1364fa92d526abac37


From jmacdon at med.umich.edu  Thu Nov 13 01:19:38 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Wed, 12 Nov 2003 19:19:38 -0500
Subject: [R] Formatting axis label numbers on plots
Message-ID: <sfb287df.039@med-gwia-01a.med.umich.edu>

Look at xaxt and yaxt under ?par, as well as ?axis.

HTH,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623
>>> "M. Edward (Ed) Borasky" <znmeb at aracnet.com> 11/12/03 17:56 PM >>>
Is there any way to control the format of the axis label numbers on a
plot? More specifically, I have some plots that get axes with label
numbers in exponential format, and I'd like to change that to
non-exponential. Thanks!!


-- 
M. Edward (Ed) Borasky, MS, MNLP, NST, FBG, PGS & PTA

znmeb at borasky-research.net
http://www.borasky-research.net

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Thu Nov 13 03:50:10 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 12 Nov 2003 21:50:10 -0500
Subject: [R] Formatting axis label numbers on plots
In-Reply-To: <Pine.LNX.4.44.0311121440260.22742-100000@onyx.spiritone.co
 m>
Message-ID: <5.1.0.14.2.20031112214859.01fcb878@127.0.0.1>

Dear Ed,

Take a look at the scipen option, new (I believe) in R 1.8.0, which can be 
used to suppress scientific notation.

I hope that this helps,
  John

At 02:45 PM 11/12/2003 -0800, M. Edward (Ed) Borasky wrote:
>Is there any way to control the format of the axis label numbers on a
>plot? More specifically, I have some plots that get axes with label
>numbers in exponential format, and I'd like to change that to
>non-exponential. Thanks!!

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From jasont at indigoindustrial.co.nz  Thu Nov 13 04:47:15 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 13 Nov 2003 16:47:15 +1300
Subject: [R] (no subject)
In-Reply-To: <BAY1-DAV70Aedn2AG1U0000d4df@hotmail.com>
References: <BAY1-DAV70Aedn2AG1U0000d4df@hotmail.com>
Message-ID: <3FB2FEC3.1020106@indigoindustrial.co.nz>

Stefan Wagner wrote:

> Hi all,
> 
> I am looking for a clever way to create the following graph using R:
> 
> I got information on the shares of some subgroups over time (summing 
 > up to 1 in each year). The graph I want to create should display the
 > evelopment of the individual shares over time by shading rectangulars
 > for each share in a different color.
> 

?polygon

to start. Also have a look at the code for barplot.

But given that about eight percent of adult males are colour-blind to 
some degree, be careful how you pick your colours, or you'll just 
confuse some of your audience.

http://www.visibone.com/colorblind/ shows how "web-safe" colours look to 
people with colour deficient vision.  Don't bet on everyone who has 
these issues knowing they have it; I know people who discovered they 
were partially colour blind when they were in their fourties.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From ggrothendieck at myway.com  Thu Nov 13 05:37:05 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 Nov 2003 23:37:05 -0500 (EST)
Subject: [R] question about matrix
Message-ID: <20031113043705.6B35A39C4@mprdmxin.myway.com>



You could consider storing your data in 3d array.

If A and B are your matrices of first and second 
numbers, respectively, with both being of the same
shape, then:

   C <- array(c(A,B), dim=c(dim(A),2))

gives you a 3d array.  For example, 

   C[,,1] is A
   C[,,2] is B
   C[2,1,] is the the vector: c(A[2,1],B[2,1])

---
Date: Wed, 12 Nov 2003 11:41:17 -0600 (CST) 
From: Mikyoung Jun <jun at galton.uchicago.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] question about matrix 

 
 
Hello,

I have a few questions about matrix in R. 

Can we make a matrix whose elements are list? I would like to save two
different values in each elements of matrix. If there is a package or
something which can deal with complex numbers, that will do it too. Also,
I am wondering whether there is a function to calculate the rank of the
matrix. I found a matrix package, but it doesn't have functions like that.

Thanks a lot in advance!

Mikyoung Jun

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Paul.Sorenson at vision-bio.com  Thu Nov 13 06:54:00 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Thu, 13 Nov 2003 16:54:00 +1100
Subject: [R] xlims of barplot
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C602C2B682@ewok.vsl.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031113/b5f3072e/attachment.pl

From pauljohn at ku.edu  Thu Nov 13 07:04:58 2003
From: pauljohn at ku.edu (Paul E. Johnson)
Date: Thu, 13 Nov 2003 00:04:58 -0600
Subject: [R] what does this multinom error mean?
Message-ID: <3FB31F0A.8070304@ku.edu>

I have RedHat linux 9 with R 1.8.

I'm estimating models with multinom with a dependent variable that has 3 
different values.  Sometimes the models run fine and I can understand 
the results.

Sometimes when I put in another variable, I see an indication that the 
estimation did work, but then I can't get the summary method to work.  
It's like this:

 > votemn1 <-  multinom(vote~V023022+rep+V023027+ V023131,data=nes2002)
# weights:  18 (10 variable)
initial  value 914.045424
iter  10 value 474.831205
iter  20 value 449.612637
iter  20 value 449.612636
iter  20 value 449.612636
final  value 449.612636
converged

 > summary(votemn1)
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
    invalid variable type

In this model, rep is a dichotomous (0,1) variable indicating if a 
person is a republican or not. If I drop that variable, the model does 
run and the summary method produces estimates & standard errors.

 > votemn2 <-  multinom(vote~V023022+V023027+ V023131,data=nes2002)
# weights:  15 (8 variable)
initial  value 917.341261
iter  10 value 529.137064
final  value 527.178682
converged

 > summary(votemn2)
Call:
multinom(formula = vote ~ V023022 + V023027 + V023131, data = nes2002)

Coefficients:
  (Intercept)    V023022    V023027     V023131
3  -2.2033403  0.9227144 -0.3835378 0.017960208
5  -0.8411559 -0.1853416 -0.2174085 0.005808468

Std. Errors:
  (Intercept)    V023022   V023027    V023131
3   0.5883961 0.07054401 0.0894393 0.05655965
5   1.2438595 0.14582161 0.1963035 0.12453307

Residual Deviance: 1054.357
AIC: 1070.357
...

-- 
Paul E. Johnson                       email: pauljohn at ukans.edu
Dept. of Political Science            http://lark.cc.ukans.edu/~pauljohn
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66045                FAX: (785) 864-5700



From ripley at stats.ox.ac.uk  Thu Nov 13 08:26:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Nov 2003 07:26:40 +0000 (GMT)
Subject: Don't use the names of R functions as variable names (was [R] what
	does this multinom (actually model.frame) error mean?)
In-Reply-To: <3FB31F0A.8070304@ku.edu>
Message-ID: <Pine.LNX.4.44.0311130721210.15687-100000@gannet.stats>

Note that is a *model.frame* error, not a multinom one.

Don't use the names of R functions as variable names!  I am sure that is
in the introductory documentation, and it is certainly stressed in my
books.  Although I cannot be sure it seems very likely (perhaps because of
the scoping induced by namespaces) that your `rep' is being matched to the
function.

On Thu, 13 Nov 2003, Paul E. Johnson wrote:

> I have RedHat linux 9 with R 1.8.
> 
> I'm estimating models with multinom with a dependent variable that has 3 
> different values.  Sometimes the models run fine and I can understand 
> the results.
> 
> Sometimes when I put in another variable, I see an indication that the 
> estimation did work, but then I can't get the summary method to work.  
> It's like this:
> 
>  > votemn1 <-  multinom(vote~V023022+rep+V023027+ V023131,data=nes2002)
> # weights:  18 (10 variable)
> initial  value 914.045424
> iter  10 value 474.831205
> iter  20 value 449.612637
> iter  20 value 449.612636
> iter  20 value 449.612636
> final  value 449.612636
> converged
> 
>  > summary(votemn1)
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>     invalid variable type
> 
> In this model, rep is a dichotomous (0,1) variable indicating if a 
> person is a republican or not. If I drop that variable, the model does 
> run and the summary method produces estimates & standard errors.
> 
>  > votemn2 <-  multinom(vote~V023022+V023027+ V023131,data=nes2002)
> # weights:  15 (8 variable)
> initial  value 917.341261
> iter  10 value 529.137064
> final  value 527.178682
> converged
> 
>  > summary(votemn2)
> Call:
> multinom(formula = vote ~ V023022 + V023027 + V023131, data = nes2002)
> 
> Coefficients:
>   (Intercept)    V023022    V023027     V023131
> 3  -2.2033403  0.9227144 -0.3835378 0.017960208
> 5  -0.8411559 -0.1853416 -0.2174085 0.005808468
> 
> Std. Errors:
>   (Intercept)    V023022   V023027    V023131
> 3   0.5883961 0.07054401 0.0894393 0.05655965
> 5   1.2438595 0.14582161 0.1963035 0.12453307
> 
> Residual Deviance: 1054.357
> AIC: 1070.357
> ...
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Nov 13 08:40:27 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Nov 2003 07:40:27 +0000 (GMT)
Subject: [R] Plotting lm() attributes
In-Reply-To: <5.2.1.1.2.20031112155530.03787878@mailhost.blackmesacapital.com>
Message-ID: <Pine.LNX.4.44.0311130736510.15687-100000@gannet.stats>

On Wed, 12 Nov 2003, Tony Plate wrote:

> I believe this is the sort of things that the functions resid() and 
> predict(), in conjunction with na.exclude, are designed for.  E.g.:
> 
>  > data <- data.frame(x=c(1:5), y=c(1,3,2,NA,4))
>  > m <- lm(y~x, data=data, na.action=na.exclude)
>  > predict(m)
>         1        2        3        4        5
> 1.400000 2.028571 2.657143       NA 3.914286
>  > resid(m)
>            1           2           3           4           5
> -0.40000000  0.97142857 -0.65714286          NA  0.08571429
>  >
> 
> Note that NA's are not reintroduced if na.action=na.omit, which is the 
> default (unless you have options("na.action") set otherwise).  Also, note 
> that this technique produces a NA fitted value where a non-NA one could be 
> produced (use predict(m, newdata=data) to get those values.)

More accurately, where a non-NA prediction could be produced.  There never 
was a fitted value for those cases, so NA is correct.  That predict gives 
what people expect with NA values is a new feature in 1.8.0.

And please, please, folks use the extractor functions and not the
components (NOT attributes) directly.

> 
> hope this helps,
> 
> Tony Plate
> 
> At Thursday 11:40 AM 11/13/2003 +1300, Murray Jorgensen wrote:
> >Suppose you fit a linear model
> >
> > > model.1 ~ lm(v1 ~ ..., data=myframe)
> >
> >and v2 is some other column of myframe typically not in the model. You 
> >will often want to try
> >
> > > plot(v2, model.1$residuals)
> >
> >but this will fail if there are NAs in the response v1 as 
> >model.1$residuals has length equal to the number of nonmissing values 
> >in  v1. I suppose
> >
> > > plot(v2[!is.na(v1)], model.1$residuals)
> >
> >does the job, but it seems irritating that model.1$residuals, does not 
> >have length agreeing with the number of rows in the data frame. It would 
> >be even more irritating for model.1$fitted.values, where the removed 
> >elements would often have nonmissing values.
> >
> >Murray
> >
> >--
> >Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> >Department of Statistics, University of Waikato, Hamilton, New Zealand
> >Email: maj at waikato.ac.nz                                Fax 7 838 4155
> >Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> Tony Plate   tplate at acm.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From arne.gjuvsland at iha.nlh.no  Thu Nov 13 09:59:48 2003
From: arne.gjuvsland at iha.nlh.no (Arne Gjuvsland)
Date: Thu, 13 Nov 2003 09:59:48
Subject: [R] Running R-program as queue jobs
Message-ID: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>

I have a problem with running my R programs as queue jobs. When I try
to submit a batch file to the queue with qsub I get the following error
message:
____________________________________________________________

/home/gjuvslan/kluster/R-1.7.1/bin/R.bin: error while loading shared
libraries: 
libpcre.so.0: cannot load shared object file: No such file or directory
____________________________________________________________

When executed from the command prompt the batch file does its job.

Any ideas?

Arne



From mkondrin at relay.hppi.troitsk.ru  Thu Nov 13 09:54:41 2003
From: mkondrin at relay.hppi.troitsk.ru (mkondrin@relay.hppi.troitsk.ru)
Date: Thu, 13 Nov 2003 11:54:41 +0300
Subject: [R] Using tcltk language with R system
In-Reply-To: <1068666081.3fb28ce11172b@webmail.tci.ufal.br>
References: <1068666081.3fb28ce11172b@webmail.tci.ufal.br>
Message-ID: <20031113085441.GA2077@relay.hppi.troitsk.ru>

On Wed, Nov 12, 2003 at 04:41:21PM -0300, mcaj at tci.ufal.br wrote:
> 
> 
> Hello, Does anybody know how can i call a R function in a tcltk file? I made 
> a tcltk file, but I need call functions in R. i.e: in R I can put .Tcl("tcltk 
> statement"). There are a same command to call R in a tcltk file?
> 
>   I want to make a R Gui using tcltk language, do you recommend use a tcltk or 
> a R pack tcltk and don't use tcltk language?
> 
>   Thanks for your attention.
> 
> 
>   Marcos Cerqueira J?nior
>  Alagoas University - Brazil
> 
> 
> -------------------------------------------------
> This mail sent through IMP: http://horde.org/imp/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

in tcltk file you can use tcl command R_eval ... (... - any valid R statement).



From Giles.Heywood at CommerzbankIB.com  Thu Nov 13 10:10:34 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Thu, 13 Nov 2003 09:10:34 -0000
Subject: Subject: RE: [R] Time plot question.
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF05BF7365@xmx8lonib.lonib.commerzbank.com>

The following is an example of a dataframe containing times, 
plus some numeric data.

foo <- c("12:39:26","12:40:22","12:41:19")
bar <- data.frame(foo,1:3,11:13)

Note that the times are of class 'factor' (their class changes
in this case, as they go into the dataframe).

To convert this dataframe to an 'its', do the following:

library(its)
its.format("%H:%M:%S")
its(x=as.matrix(bar[,2:3]),dates=as.POSIXct(x=strptime(as.character(bar[[1]]
),format=its.format())))

Incidentally, since these types of question come up from
time to time on the R-help ist, I intend to expand the 'its' 
documentation with some more examples and illustrations, in
a 'vignette'.

- Giles

> -----Original Message-----
> From: heimdal at aracnet.com [mailto:heimdal at aracnet.com]
> Sent: 12 November 2003 18:09
> To: ggrothendieck at myway.com
> Cc: r-help at stat.math.ethz.ch
> Subject: Subject: RE: [R] Time plot question.
> 
> 
> Hello,
> 
> Thank you for your reply. I am missing an intermediate step as
> 
> > plot( strptime( Time, format = "%H:%M:%S"), FreeMemory)
> Error in strptime(Time, format = "%H:%M:%S") :
>         invalid `x' argument
> > plot( strptime( c(Time), format = "%H:%M:%S"), FreeMemory)
> Error in strptime(c(Time), format = "%H:%M:%S") :
>         invalid `x' argument
> 
> does not work. My "Time" data is part of a data.frame. Do I need to
> "as.POSIXlt" this in some way, and if so, how?
> I will continue to work on this, and buy a suitable book on R 
> so as not to
> plague this excellent news group with such questions. I could 
> generate a
> sequence of ISODates similar to my
> data, but I would like to use the actual Time coordinates 
> instead. Here is
> my "Time" data below:
> 
> > Time
>   [1] 12:39:26 12:40:22 12:41:19 12:42:15 12:43:11 12:44:08 12:45:04
> 12:46:00
>   [9] 12:46:57 12:47:53 12:48:49 12:49:46 12:50:42 12:51:38 12:52:35
> 12:53:31
>  [17] 12:54:27 12:55:24 12:56:20 12:57:16 12:58:13 12:59:09 13:00:05
> 13:01:01
>  [25] 13:01:58 13:02:54 13:03:50 13:04:47 13:05:43 13:06:39 13:07:36
> 13:08:32
>  [33] 13:09:28 13:10:25 13:11:21 13:12:17 13:13:14 13:14:10 13:15:06
> 13:16:03
>  [41] 13:16:59 13:17:55 13:18:52 13:19:48 13:20:44 13:21:41 13:22:37
> 13:23:33
>  [49] 13:24:30 13:25:26 13:26:22 13:27:19 13:28:15 13:29:11 13:30:07
> 13:31:04
>  [57] 13:32:00 13:32:56 13:33:53 13:34:49 13:35:46 13:36:42 13:37:39
> 13:38:35
>  [65] 13:39:32 13:40:28 13:41:24 13:42:21 13:43:17 13:44:13 13:45:10
> 13:46:06
>  [73] 13:47:02 13:47:59 13:48:55 13:49:51 13:50:48 13:51:44 13:52:40
> 13:53:37
>  [81] 13:54:33 13:55:29 13:56:26 13:57:22 13:58:19 13:59:15 14:00:11
> 14:01:08
>  [89] 14:02:05 14:03:01 14:03:57 14:04:54 14:05:50 14:06:46 14:07:42
> 14:08:39
>  [97] 14:09:35 14:10:31 14:11:28 14:12:24 14:13:20 14:14:17 14:15:13
> 14:16:09
> [105] 14:17:06 14:18:02 14:18:58 14:19:55 14:20:51 14:21:47 14:22:44
> 14:23:40
> [113] 14:24:36 14:25:32 14:26:29 14:27:25 14:28:21 14:29:18 14:30:14
> 14:31:10
> 120 Levels: 12:39:26 12:40:22 12:41:19 12:42:15 12:43:11 12:44:08 ...
> 14:31:10
> >
> 
> Enjoying a little "R and R",
> 
> John
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From p.pagel at gsf.de  Thu Nov 13 10:27:12 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Thu, 13 Nov 2003 10:27:12 +0100
Subject: [R] Running R-program as queue jobs
In-Reply-To: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>
References: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>
Message-ID: <20031113092712.GA2668@porcupine.gsf.de>

	Hi!

On Thu, Nov 13, 2003 at 09:59:48AM +0000, Arne Gjuvsland wrote:
> I have a problem with running my R programs as queue jobs. When I try
> to submit a batch file to the queue with qsub I get the following error
> message:
> ____________________________________________________________
> 
> /home/gjuvslan/kluster/R-1.7.1/bin/R.bin: error while loading shared
> libraries: 
> libpcre.so.0: cannot load shared object file: No such file or directory
> ____________________________________________________________
> 
> When executed from the command prompt the batch file does its job.

Did you run the script on the same machine in both cases? I got burnt a
couple of times with different machines running different versions of
the OS, non-identical versions of shared libraries etc...

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From Simon.Fear at synequanon.com  Thu Nov 13 10:53:17 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 13 Nov 2003 09:53:17 -0000
Subject: [R] xlims of barplot
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0E95@synequanon01>

I'd recommend you read the code for barplot (it's all in R;
just type barplot.default at the prompt) then emulate the
xlim calculation prior to starting your series of plots, calling
each plot with the same xlim.

Reading the base package coding is always VERY instructive.
Takes time, but it's worth it.

> -----Original Message-----
> From: Paul Sorenson [mailto:Paul.Sorenson at vision-bio.com]
> Sent: 13 November 2003 05:54
> To: r-help at stat.math.ethz.ch
> Subject: [R] xlims of barplot
  
> I would like to create a family of barplots with the same xlimits.  Is
> there a way to "read" the xlimits from the first graph so I 
> can apply it to
> the subsequent ones?  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From jasont at indigoindustrial.co.nz  Thu Nov 13 11:45:01 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 13 Nov 2003 23:45:01 +1300
Subject: [R] Running R-program as queue jobs
In-Reply-To: <20031113092712.GA2668@porcupine.gsf.de>
References: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>
	<20031113092712.GA2668@porcupine.gsf.de>
Message-ID: <3FB360AD.7070208@indigoindustrial.co.nz>

Philipp Pagel wrote:
> 	Hi!
> 
> On Thu, Nov 13, 2003 at 09:59:48AM +0000, Arne Gjuvsland wrote:
> 
>>I have a problem with running my R programs as queue jobs. When I try
>>to submit a batch file to the queue with qsub I get the following error
>>message:
>>____________________________________________________________
>>
>>/home/gjuvslan/kluster/R-1.7.1/bin/R.bin: error while loading shared
>>libraries: 
>>libpcre.so.0: cannot load shared object file: No such file or directory
>>____________________________________________________________
>>
>>When executed from the command prompt the batch file does its job.
> 
> 
> Did you run the script on the same machine in both cases? I got burnt a
> couple of times with different machines running different versions of
> the OS, non-identical versions of shared libraries etc...
> 

In addition to Philipp's good sugestion, I've been burnt on the same 
machine, but with the batch job running as a different user.  When 
environment variables are needed, or private libraries need to be 
loaded, things go bad very quickly.

Cheers

Jason

-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From Pascal.Niklaus at unibas.ch  Thu Nov 13 11:54:57 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Thu, 13 Nov 2003 11:54:57 +0100
Subject: [R] postscript device: horizontal=F
In-Reply-To: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>
References: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>
Message-ID: <3FB36301.4020101@unibas.ch>

The postscript device behaves strangely - is this possibly a bug?

case 1)

  postscript("gfx-%d.ps",width=8 , height=5, paper="special", 
horizontal=F, onefile=FALSE);
  <some plots here>
  dev.off()

  The first plot is in "portrait" orientation
  The second and all the following plots are in "landscape" orientation

case 2)

  postscript("gfx-%d.ps",width=8 , height=5, paper="special", 
horizontal=T, onefile=FALSE);
  <some plots here>
  dev.off()

  Now, all plots are in "portrait"...

So it seems that the orientation of the *first* plot is not affected by 
horizontal=T/F.

Pascal



From p.dalgaard at biostat.ku.dk  Thu Nov 13 12:17:36 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Nov 2003 12:17:36 +0100
Subject: [R] Running R-program as queue jobs
In-Reply-To: <3FB360AD.7070208@indigoindustrial.co.nz>
References: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>
	<20031113092712.GA2668@porcupine.gsf.de>
	<3FB360AD.7070208@indigoindustrial.co.nz>
Message-ID: <x2znf0msa7.fsf@biostat.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> Philipp Pagel wrote:
> > 	Hi!
> > On Thu, Nov 13, 2003 at 09:59:48AM +0000, Arne Gjuvsland wrote:
> >
> >>I have a problem with running my R programs as queue jobs. When I try
> >>to submit a batch file to the queue with qsub I get the following error
> >>message:
> >>____________________________________________________________
> >>
> >>/home/gjuvslan/kluster/R-1.7.1/bin/R.bin: error while loading shared
> >> libraries: libpcre.so.0: cannot load shared object file: No such
> >> file or directory
> >>____________________________________________________________
> >>
> >>When executed from the command prompt the batch file does its job.
> > Did you run the script on the same machine in both cases? I got
> > burnt a
> > couple of times with different machines running different versions of
> > the OS, non-identical versions of shared libraries etc...
> >
> 
> In addition to Philipp's good sugestion, I've been burnt on the same
> machine, but with the batch job running as a different user.  When
> environment variables are needed, or private libraries need to be
> loaded, things go bad very quickly.

Also, environment variables may be set differently between interactive
and batch shells. E.g. my crontab file looks like this

CVS_RSH=ssh
35 0 * * *  $HOME/scripts/r-bugs-commit > /dev/null
...

for a reason. In Arne's case, I'd suspect the setting of
LD_LIBRARY_PATH. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From bitwrit at ozemail.com.au  Thu Nov 13 12:31:17 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 13 Nov 2003 22:31:17 +1100
Subject: [R] (no subject)
In-Reply-To: <BAY1-DAV70Aedn2AG1U0000d4df@hotmail.com>
References: <BAY1-DAV70Aedn2AG1U0000d4df@hotmail.com>
Message-ID: <20031113113316.QQFX6319.smta02.mail.ozemail.net@there>

On Wednesday 12 November 2003 10:24 pm, Stefan Wagner wrote:
> Hi all,
>
> I am looking for a clever way to create the following graph using R:
>
> I got information on the shares of some subgroups over time (summing up
> to 1 in each year). The graph I want to create should display the
> development of the individual shares over time by shading rectangulars
> for each share in a different color.
>
> Is there a clever of doing this?
>

I don't know whether this will help, but here is a function that draws a 
rectangle specified by the position arguments with a color gradient 
specified by either endpoints for red, green and blue, or vectors of red, 
green and blue values in either 0-1 or 0-255. The gradient will be a 
linear sequence if only the extremes of the bar are specified, or can be
explicitly specified by passing a vector of x values for horizontal
shading or y values for vertical shading. Useful for doing barplots where 
you would like to illustrate critical areas (e.g. risk levels of a 
concentration - I've included a fake example) in a series of observed 
values. It's a bit messy, as there isn't a lot of error checking, but it 
may be useful.

Jim
-------------- next part --------------
rgb.to.hex<-function(rgb) {
 if(length(rgb) != 3) stop("rgb must be an rgb triplet")
 if(any(rgb < 0) || any(rgb > 255)) stop("all rgb must be between 0 and 255")
 # if it looks like a 0-1 value, get the 0-255 equivalent
 if(all(rgb <= 1)) rgb<-rgb*255 
 hexdigit<-c(0:9,letters[1:6])
 return(paste("#",hexdigit[rgb[1]%/%16+1],hexdigit[rgb[1]%%16+1],
  hexdigit[rgb[2]%/%16+1],hexdigit[rgb[2]%%16+1],
  hexdigit[rgb[3]%/%16+1],hexdigit[rgb[3]%%16+1],
  sep="",collapse=""))
}

gradient.rect<-function(xleft,ybottom,xright,ytop,reds,greens,blues,
 nslices=20,gradient="x") {
 maxncol<-max(c(length(reds),length(greens),length(blues)))
 if(maxncol < 2) stop("Must specify at least two values for one color")
 if(maxncol > 2 || maxncol > nslices) nslices<-maxncol
 if(length(reds) == 2) {
  # assume they are endpoints and calculate linear gradient
  if(reds[1] < 0 || reds[2] > 1) {
   reds[1]<-ifelse(reds[1] < 0,0,reds[1])
   reds[2]<-ifelse(reds[2] > 1,1,reds[2])
  }
  reds<-seq(reds[1],reds[2],length=nslices)
 }
 if(length(greens) == 2) {
  # assume they are endpoints and calculate linear gradient
  if(greens[1] < 0 || greens[2] > 1) {
   greens[1]<-ifelse(greens[1] < 0,0,greens[1])
   greens[2]<-ifelse(greens[2] > 1,1,greens[2])
  }
  greens<-seq(greens[1],greens[2],length=nslices)
 }
 if(length(blues) == 2) {
  # assume they are endpoints and calculate linear gradient
  if(blues[1] < 0 || blues[2] > 1) {
   blues[1]<-ifelse(blues[1] < 0,0,blues[1])
   blues[2]<-ifelse(blues[2] > 1,1,blues[2])
  }
  blues<-seq(blues[1],blues[2],length=nslices)
 }
 colormatrix<-cbind(reds,greens,blues)
 colvec<-apply(colormatrix,1,rgb.to.hex)
 if(gradient == "x") {
  if(length(xleft) == 1) {
   xinc<-(xright-xleft)/(nslices-1)
   xlefts<-seq(xleft,xright-xinc,length=nslices)
   xrights<-xlefts+xinc
  }
  else {
   xlefts<-xleft
   xrights<-xright
  }
  rect(xlefts,ybottom,xrights,ytop,col=colvec,lty=0)
 }
 else {
  if(length(ybottom) == 1) {
   yinc<-(ytop-ybottom)/(nslices-1)
   ybottoms<-seq(ybottom,ytop-yinc,length=nslices)
   ytops<-ybottoms+yinc
  }
  else {
   ybottoms<-ybottom
   ytops<-ytop
  }
  rect(xleft,ybottoms,xright,ytops,col=colvec,lty=0)
 }
}
-------------- next part --------------
arsenic.red<-c(seq(0,1,length=50),rep(1,50))
arsenic.green<-c(seq(1,0,length=50),rep(0,50))
arsenic.blue<-rep(0,100)
dioxin.red<-c(seq(0,1,length=20),rep(1,80))
dioxin.green<-c(seq(1,0,length=20),rep(0,80))
dioxin.blue<-rep(0,100)
plot(0:5,seq(0,100,by=20),axes=F,type="n",main="Cancer risk",xlab="Carcinogen",
 ylab="Concentration (ppb)")
box()
axis(2)
mtext(c("Arsenic","Dioxin"),1,at=c(1.5,3.5))
gradient.rect(1,-5,2,105,arsenic.red,arsenic.green,arsenic.blue,gradient="y")
gradient.rect(3,-5,4,105,dioxin.red,dioxin.green,dioxin.blue,gradient="y")
legend(4.1,50,legend=c("High","Low"),fill=c("red","green"))

From ramakrsn at CS.ColoState.EDU  Thu Nov 13 12:51:36 2003
From: ramakrsn at CS.ColoState.EDU (U.Ramakrishna)
Date: Thu, 13 Nov 2003 04:51:36 -0700 (MST)
Subject: [R] identify function with postscript output?
In-Reply-To: <x2n0dk70xo.fsf@biostat.ku.dk>
References: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>
	<20030904164138.GB22988@sonny.eddelbuettel.com>
	<x2n0dk70xo.fsf@biostat.ku.dk>
Message-ID: <Pine.GSO.4.58.0311130444390.13966@faure.cs.colostate.edu>

Hello,
I want to select some points in a plot using 'identify' function
and also want the identified points to be saved in a
postscript file? Any help in how to do it?

A better question might have been, how do i pipe the screen output
to a postscript file?

Thanks and Regards
Ramakrishna



From ripley at stats.ox.ac.uk  Thu Nov 13 12:56:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Nov 2003 11:56:32 +0000 (GMT)
Subject: [R] Running R-program as queue jobs
In-Reply-To: <x2znf0msa7.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0311131142090.20213-100000@gannet.stats>

On 13 Nov 2003, Peter Dalgaard wrote:

> Jason Turner <jasont at indigoindustrial.co.nz> writes:
> 
> > Philipp Pagel wrote:
> > > 	Hi!
> > > On Thu, Nov 13, 2003 at 09:59:48AM +0000, Arne Gjuvsland wrote:
> > >
> > >>I have a problem with running my R programs as queue jobs. When I try
> > >>to submit a batch file to the queue with qsub I get the following error
> > >>message:
> > >>____________________________________________________________
> > >>
> > >>/home/gjuvslan/kluster/R-1.7.1/bin/R.bin: error while loading shared
> > >> libraries: libpcre.so.0: cannot load shared object file: No such
> > >> file or directory
> > >>____________________________________________________________
> > >>
> > >>When executed from the command prompt the batch file does its job.
> > > Did you run the script on the same machine in both cases? I got
> > > burnt a
> > > couple of times with different machines running different versions of
> > > the OS, non-identical versions of shared libraries etc...
> > >
> > 
> > In addition to Philipp's good sugestion, I've been burnt on the same
> > machine, but with the batch job running as a different user.  When
> > environment variables are needed, or private libraries need to be
> > loaded, things go bad very quickly.
> 
> Also, environment variables may be set differently between interactive
> and batch shells. E.g. my crontab file looks like this
> 
> CVS_RSH=ssh
> 35 0 * * *  $HOME/scripts/r-bugs-commit > /dev/null
> ...
> 
> for a reason. In Arne's case, I'd suspect the setting of
> LD_LIBRARY_PATH. 

(The R script will include in R_LD_LIBRARY_PATH the settings used at
configure time, so we do try to workaround that one.  For example my 
64-bit Solaris build has sparcv9 library paths in.)

As an aside, from the next non-patch release PCRE, BZLIB and ZLIB will be
statically linked into R in a vanilla configuration to help avoid such
problems.  (For some reason my RH8.0 system has a dynamic pcreposix but 
only a static pcre, although the current PCRE default build makes both 
versions of each.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From simon.brown at metoffice.com  Thu Nov 13 13:39:03 2003
From: simon.brown at metoffice.com (Brown, Simon)
Date: Thu, 13 Nov 2003 12:39:03 +0000
Subject: [R] Problem with parser and if/else
Message-ID: <1068727143.22311.9.camel@eld426.desktop.frd.metoffice.com>

Dear r-help people,

could you confirm that this is correct behaviour for R?  I am using RH9.

the code:
x1 <- 1:6
t1 <- 5
if (length(x1) >= t1) {
	cat("in the if \n")
} else {
	cat("in the else\n")
}

runs fine:
> source("test_if_else.R")
in the if
>

but the code:
x1 <- 1:6
t1 <- 5
if (length(x1) >= t1) {
	cat("in the if 2\n")
} 
else {
	cat("in the else\n")
}

fails with the error:
> source("test_if_else2.R")
Error in parse(file, n, text, prompt) : syntax error on line 6
>

Could someone explain this to me please?

Thanks,

Simon.
-- 
Dr. Simon Brown                         Climate extremes research manager
simon.brown at metoffice.com                http://www.hadleycentre.com
Telephone: +44 (0)1392 886879             Fax: +44 (0)870 900 5050
Met Office Hadley Centre, FitzRoy Road, EXETER, EX1 3PB, U.K



From jblazi at gmx.de  Fri Nov  7 06:54:43 2003
From: jblazi at gmx.de (JB)
Date: Fri, 07 Nov 2003 06:54:43 +0100
Subject: [R] newbie's additional (probably to some extent OT)
  questions
In-Reply-To: <Pine.SOL.4.58.0311061735040.27133@millipede.gpcc.itd.umich .edu>
References: <6.0.0.22.2.20031106213701.01bd0548@pop.gmx.de>
	<Pine.SOL.4.58.0311061735040.27133@millipede.gpcc.itd.umich.edu>
Message-ID: <6.0.0.22.2.20031107063347.01bd5988@pop.gmx.de>

At 07.11.2003 (00:24), Thomas W Blackwell wrote:
>JB and Michael  -
>
>But I will guess that the
>data come from a high school physics experiment on gravitational
>acceleration which drops a weight dragging a paper tape through
>a buzzer with a piece of carbon paper in it.  This prints periodic
>marks on the paper tape.  The data  x  are the distances traveled
>at successive time points following time zero.

No. It is a body (slider?) that is sliding down an inclined plane on an air 
cushion. we can determine the position of the slider pretty exactly (the 
error should be less than 0.01m). The clock starts when we release the body 
and it stops when the body passes a photo cell.

There are two data sets as we experimented with two different angles 
between plane table. The measurement of the angles is probably a bit less 
exact than the measurement of the position.

Here are the two data sets:
The positions are in the dx-list and are the same in both experiments:
dx-list = c( 1.60, 1.55,1.50,...,0.70) (19 values).

The corresponding dt-lists are
dt-list1 = 
c(6.44,6.29,6.1,6.09,6.02,5.87,5.68,5.65,5.52,5.43,5.30,5.20,5.01,4.88,4.74,4.61,4.44,4.36,4.12)

dt-list2 = 
c(3.98,3.86,3.78,3.72,3.65,3.59,3.51,3.45,3.37,3.28,3.22,3.14,3.07,2.96,2.89,2.81,2.74,2.61,2.55)

During the first series of measurements, tha body bumped against a boundary 
that was fixed on the inclined plane. By bumping against this boundray, the 
inclined plane, that has a much bigger mass than the body, was slightly 
pushed and after 15 measurements the position of this boundary changed by 
0.01m:


A------------------------------B---C

Here B should be a fixed position and A should be changed. According to our 
mistake B was changed a bit too. C is a boundary that stops the body from 
leavinf the air cushion (as those sliding bodies are expensive).

Then, when we took the second series of measurements, I "ordered" a pupil 
to stop tha body with his hand before bumping against C. And really, it 
seems to me that the second series is more precise.


>I think it's DYNAMITE that you're actually doing this data analysis.

Why? I always do this, but this year I started to involve a bit more 
statistics. I told about how the method of least squares was an "unbiased 
estimate" and that also some hypothesis testing is done (when I check 
whether the points lie on a parabola). The pupils are 16 to 18 years old. 
They have to draw dx against (dt)^2 as their homework and have to fit in a 
straight line. This is the way we do linear regression.

>It's what I always wanted to do as a high school student, but didn't
>have the technical background then to carry out.  In fact ... come to
>think of it ... I'm pretty sure I STILL HAVE my high school ticker
>tapes folded up among my high school papers somewhere, 35 years
>later, still waiting to be properly analyzed !

 From your explanations which follow this point, I do not understand a 
single word (the termini technici are all unknown to me) but I suspect that 
I pretty much would like to understand them. Sigh. Probably, I should have 
to read some work on statistics thoroughly (which I cannot do at the moment).

Thank you for your help, anyway.



From jfri at novozymes.com  Thu Nov 13 14:19:52 2003
From: jfri at novozymes.com (JFRI (Jesper Frickman))
Date: Thu, 13 Nov 2003 08:19:52 -0500
Subject: [R] Running R-program as queue jobs
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D14FD54@exusfr14.novo.dk>

A search on Google shows that libpcre.so.0 is a Perl-compatible regular
expression library. Does R use that, or is it the queue script? Have you
checked /usr/lib for that library? Maybe you need to install the library
or rerun ldconfig. You can get info about shared libraries with the ldd
command.

That was some ideas, but no shrink wrapped solutions!

Hilsen Jesper

-----Original Message-----
From: Arne Gjuvsland [mailto:arne.gjuvsland at iha.nlh.no] 
Sent: Thursday, November 13, 2003 5:00 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Running R-program as queue jobs


I have a problem with running my R programs as queue jobs. When I try to
submit a batch file to the queue with qsub I get the following error
message: ____________________________________________________________

/home/gjuvslan/kluster/R-1.7.1/bin/R.bin: error while loading shared
libraries: 
libpcre.so.0: cannot load shared object file: No such file or directory
____________________________________________________________

When executed from the command prompt the batch file does its job.

Any ideas?

Arne



From arne.gjuvsland at iha.nlh.no  Thu Nov 13 14:23:22 2003
From: arne.gjuvsland at iha.nlh.no (Arne Gjuvsland)
Date: Thu, 13 Nov 2003 14:23:22
Subject: [R] Running R-program as queue jobs - problem solved
In-Reply-To: <Pine.LNX.4.44.0311131142090.20213-100000@gannet.stats>
References: <x2znf0msa7.fsf@biostat.ku.dk>
Message-ID: <3.0.2.16.20031113142322.2137a9f8@iha.nlh.no>

At 11:56 13.11.2003 +0000, Prof Brian Ripley wrote:
>On 13 Nov 2003, Peter Dalgaard wrote:
>
>> Jason Turner <jasont at indigoindustrial.co.nz> writes:
>> 
>> > Philipp Pagel wrote:
>> > > 	Hi!
>> > > On Thu, Nov 13, 2003 at 09:59:48AM +0000, Arne Gjuvsland wrote:
>> > >
>> > >>I have a problem with running my R programs as queue jobs. When I try
>> > >>to submit a batch file to the queue with qsub I get the following error
>> > >>message:
>> > >>____________________________________________________________
>> > >>
>> > >>/home/gjuvslan/kluster/R-1.7.1/bin/R.bin: error while loading shared
>> > >> libraries: libpcre.so.0: cannot load shared object file: No such
>> > >> file or directory
>> > >>____________________________________________________________
>> > >>
>> > >>When executed from the command prompt the batch file does its job.
>> > > Did you run the script on the same machine in both cases? I got
>> > > burnt a
>> > > couple of times with different machines running different versions of
>> > > the OS, non-identical versions of shared libraries etc...
>> > >
>> > 
>> > In addition to Philipp's good sugestion, I've been burnt on the same
>> > machine, but with the batch job running as a different user.  When
>> > environment variables are needed, or private libraries need to be
>> > loaded, things go bad very quickly.
>> 
>> Also, environment variables may be set differently between interactive
>> and batch shells. E.g. my crontab file looks like this
>> 
>> CVS_RSH=ssh
>> 35 0 * * *  $HOME/scripts/r-bugs-commit > /dev/null
>> ...
>> 
>> for a reason. In Arne's case, I'd suspect the setting of
>> LD_LIBRARY_PATH. 
>
>(The R script will include in R_LD_LIBRARY_PATH the settings used at
>configure time, so we do try to workaround that one.  For example my 
>64-bit Solaris build has sparcv9 library paths in.)
>
>As an aside, from the next non-patch release PCRE, BZLIB and ZLIB will be
>statically linked into R in a vanilla configuration to help avoid such
>problems.  (For some reason my RH8.0 system has a dynamic pcreposix but 
>only a static pcre, although the current PCRE default build makes both 
>versions of each.)
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
Thanks for helpful advice, the R_LD_LIBRARY_PATH in the R script did not
contain
the path of the library. Now the script is in the queue, waiting for some
quality CPU-time.

Arne



From bolker at zoo.ufl.edu  Thu Nov 13 14:42:01 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Thu, 13 Nov 2003 08:42:01 -0500 (EST)
Subject: [R] Problem with parser and if/else
In-Reply-To: <1068727143.22311.9.camel@eld426.desktop.frd.metoffice.com>
Message-ID: <Pine.LNX.4.44.0311130821590.19313-100000@bolker.zoo.ufl.edu>

  
  In the second case, R stops when it has a syntactically complete clause:

if (...) {
  ...
}

is complete since an else{} clause is not required.  R evaluates it, then 
moves onto 

else { ... }

which is a syntax error (since it "doesn't have an if {} in front of it, 
since that has already been evaluated)

  One way to see this illustrated is to enter these commands a line at a 
time in interactive mode.

  I don't know exactly where this appears in the documentation, probably 
someone will point to it in another message.

On Thu, 13 Nov 2003, Brown, Simon wrote:

> Dear r-help people,
> 
> could you confirm that this is correct behaviour for R?  I am using RH9.
> 
> the code:
> x1 <- 1:6
> t1 <- 5
> if (length(x1) >= t1) {
> 	cat("in the if \n")
> } else {
> 	cat("in the else\n")
> }
> 
> runs fine:
> > source("test_if_else.R")
> in the if
> >
> 
> but the code:
> x1 <- 1:6
> t1 <- 5
> if (length(x1) >= t1) {
> 	cat("in the if 2\n")
> } 
> else {
> 	cat("in the else\n")
> }
> 
> fails with the error:
> > source("test_if_else2.R")
> Error in parse(file, n, text, prompt) : syntax error on line 6
> >
> 
> Could someone explain this to me please?
> 
> Thanks,
> 
> Simon.
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From Joerg.Schaber at uv.es  Thu Nov 13 14:31:34 2003
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Thu, 13 Nov 2003 14:31:34 +0100
Subject: [R] conf int mixed effects
References: <200311131109.hADB1ZQ3011351@hypatia.math.ethz.ch>
Message-ID: <3FB387B6.1060608@uv.es>

Hi,

I have a linear mixed-effects model object and want to extract the 95% 
confidence intervals for the fixed and random effects, respectively. I 
found the function intervals() for confidence intervals for the fixed 
effects but no corresponding function for the random effects. Does it 
exist or do I have to calculate the confidence intervals for the random 
effects myself?

Greetings,

joerg



From MSchwartz at medanalytics.com  Thu Nov 13 14:49:07 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 13 Nov 2003 07:49:07 -0600
Subject: [R] xlims of barplot
In-Reply-To: <5E06BFED29594F4C9C5EBE230DE320C602C2B682@ewok.vsl.com.au>
References: <5E06BFED29594F4C9C5EBE230DE320C602C2B682@ewok.vsl.com.au>
Message-ID: <1068731347.4550.153.camel@localhost.localdomain>

On Wed, 2003-11-12 at 23:54, Paul Sorenson wrote:
> I would like to create a family of barplots with the same xlimits.  Is
> there a way to "read" the xlimits from the first graph so I can apply it to
> the subsequent ones?
> 
> I have tried just taking the min and max of the x data and the plot doesn't
> show.
> 
> cheers

A point of clarification:

When you say x axis limits, are you referring to the bar heights in a
horizontal barplot or are you referring to the range of the x axis with
vertical bars?  A critical difference.

In the former situation, you can explicitly set the x axis limits using
the 'xlim' argument to include the range of values in your various sets
of data. Thus, you can use:

# Get the maximum x value in the datasets
# Presumes that 'MyData' contains all values
max.x <- max(MyData)

# Now use this format for EACH barplot
barplot(...., horiz = TRUE, xlim = c(0, max.x))

That will result in the x axis being the same in each plot.  You might
want to use something like 'xlim = c(0, max.x * 1.25)', which will give
you some additional space above the bars (ie. for a legend, etc.).

Note that if you use the range of x values (instead of 0 and max) and
set xlim to that min/max pair, you will get a "funny" result. For
example:

barplot(1:5, horiz = TRUE, xlim = c(1, 5))

Since par("xpd") is set to TRUE by default in barplot(), the bases of
the bars will actually appear beyond the left side of the plot region.
You can eliminate that effect by using:

barplot(1:5, horiz = TRUE, xlim = c(1, 5), xpd = FALSE)

However, you will not see a bar for your minimum value.

If you are talking about a vertical barplot, then the x axis range will
be the same for each barplot under the following conditions, without
having to set it:

1. You have the same number of bars in each plot
2. You do not change the values of 'space', 'width' or 'beside' across
the plots.

Also, keep in mind that the bars are NOT centered over integer values on
the respective axis. You can get the bar center positions by using:

mp <- barplot(...)

where 'mp' will contain the bar midpoints, which is useful for
subsequent annotation, etc.

See ?barplot for more help and examples.

HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Thu Nov 13 14:55:24 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 13 Nov 2003 13:55:24 +0000 (GMT Standard Time)
Subject: [R] Problem with parser and if/else
In-Reply-To: <Pine.LNX.4.44.0311130821590.19313-100000@bolker.zoo.ufl.edu>
Message-ID: <Pine.WNT.4.44.0311131351480.3448-100000@gannet.stats.ox.ac.uk>

On Thu, 13 Nov 2003, Ben Bolker wrote:

>
>   In the second case, R stops when it has a syntactically complete clause:
>
> if (...) {
>   ...
> }
>
> is complete since an else{} clause is not required.  R evaluates it, then
> moves onto
>
> else { ... }
>
> which is a syntax error (since it "doesn't have an if {} in front of it,
> since that has already been evaluated)
>
>   One way to see this illustrated is to enter these commands a line at a
> time in interactive mode.
>
>   I don't know exactly where this appears in the documentation, probably
> someone will point to it in another message.

help("if"), for example (the most obvious place to look?)
MASS4, p.58
....


> On Thu, 13 Nov 2003, Brown, Simon wrote:
>
> > Dear r-help people,
> >
> > could you confirm that this is correct behaviour for R?  I am using RH9.
> >
> > the code:
> > x1 <- 1:6
> > t1 <- 5
> > if (length(x1) >= t1) {
> > 	cat("in the if \n")
> > } else {
> > 	cat("in the else\n")
> > }
> >
> > runs fine:
> > > source("test_if_else.R")
> > in the if
> > >
> >
> > but the code:
> > x1 <- 1:6
> > t1 <- 5
> > if (length(x1) >= t1) {
> > 	cat("in the if 2\n")
> > }
> > else {
> > 	cat("in the else\n")
> > }
> >
> > fails with the error:
> > > source("test_if_else2.R")
> > Error in parse(file, n, text, prompt) : syntax error on line 6
> > >
> >
> > Could someone explain this to me please?
> >
> > Thanks,
> >
> > Simon.
> >
>
> --
> 620B Bartram Hall                            bolker at zoo.ufl.edu
> Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Nov 13 15:05:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Nov 2003 15:05:12 +0100
Subject: [R] Problem with parser and if/else
In-Reply-To: <1068727143.22311.9.camel@eld426.desktop.frd.metoffice.com>
References: <1068727143.22311.9.camel@eld426.desktop.frd.metoffice.com>
Message-ID: <x2vfpomkiv.fsf@biostat.ku.dk>

"Brown, Simon" <simon.brown at metoffice.com> writes:

> Dear r-help people,
> 
> could you confirm that this is correct behaviour for R?  I am using RH9.
> 
> the code:
> x1 <- 1:6
> t1 <- 5
> if (length(x1) >= t1) {
> 	cat("in the if \n")
> } else {
> 	cat("in the else\n")
> }
> 
> runs fine:
> > source("test_if_else.R")
> in the if
> >
> 
> but the code:
> x1 <- 1:6
> t1 <- 5
> if (length(x1) >= t1) {
> 	cat("in the if 2\n")
> } 
> else {
> 	cat("in the else\n")
> }
> 
> fails with the error:
> > source("test_if_else2.R")
> Error in parse(file, n, text, prompt) : syntax error on line 6
> >
> 
> Could someone explain this to me please?

Again? This has been hashed over several times before. The basic issue
is whether a statement can be assumed to be syntactically complete at
the end of a line. It is fairly obvious what happens when you type the
same expressions at an interactive prompt:

> x1 <- 1:6
> t1 <- 5
> if (length(x1) >= t1) {
+ cat("in the if 2\n")
+ }
in the if 2
> else {
Error: syntax error
> cat("in the else\n")
in the else
> }
Error: syntax error

Notice that the first right curly brace is seen as terminating the if
construct. Otherwise, R would need to wait and check whether the
*next* line starts with an "else" which would certainly be confusing
in interactive use. So R assumes the expression is finished and
evaluates it. Then it gets an "else" keyword that it doesn't know what
to do with and barfs.

Files that are source()'ed are subject to the same restrictions as
code given as input. This is a fairly useful consistency requirement. 

[Come to think of it, it is not entirely obvious that we couldn't have
"else ..." working like "if (TRUE) ..." or "if (FALSE) ..." depending
on the result of a previous if(). I suppose the issue is how to make
sure that there actually is a matching "if".]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Thu Nov 13 15:08:09 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Nov 2003 15:08:09 +0100
Subject: [R] I receiv an error when try to run a function...
In-Reply-To: <DFECKFJKEJHHMLJFFEOMKEJDCBAA.mlaia@fcav.unesp.br>
References: <DFECKFJKEJHHMLJFFEOMKEJDCBAA.mlaia@fcav.unesp.br>
Message-ID: <3FB39049.8030707@statistik.uni-dortmund.de>

Marcelo Luiz de Laia wrote:

> Hi All,
> 
> I use R 1.8.0 and Bioconductor packages in Windows 2000 professional.
> 
> When I try to run one function, I will receive one dialog box with this
> message:
> 
> Rgui.exe has generate errors and will be closed by Windows.
> You will need to restart the program.
> An error log is being created.
> 
> I look in for in my system for the "error log", but nothing...
> 
> I search in microsoft KB database, but nothing, too.
> 
> I do not search in R-help archieves.
> 
> Do someone already see this problem?

If the crash is reproducible, you should send a bug report to the 
maintainer of the corresponding package that function is in.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Thu Nov 13 15:17:41 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Nov 2003 15:17:41 +0100
Subject: [R] identify function with postscript output?
In-Reply-To: <Pine.GSO.4.58.0311130444390.13966@faure.cs.colostate.edu>
References: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>	<20030904164138.GB22988@sonny.eddelbuettel.com>	<x2n0dk70xo.fsf@biostat.ku.dk>
	<Pine.GSO.4.58.0311130444390.13966@faure.cs.colostate.edu>
Message-ID: <3FB39285.3000304@statistik.uni-dortmund.de>

U.Ramakrishna wrote:

> Hello,
> I want to select some points in a plot using 'identify' function
> and also want the identified points to be saved in a
> postscript file? Any help in how to do it?
> 
> A better question might have been, how do i pipe the screen output
> to a postscript file?
> 
> Thanks and Regards
> Ramakrishna


See ?dev.copy

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Thu Nov 13 15:21:37 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Nov 2003 15:21:37 +0100
Subject: [R] postscript device: horizontal=F
In-Reply-To: <3FB36301.4020101@unibas.ch>
References: <3.0.2.16.20031113095948.2fbf632e@iha.nlh.no>
	<3FB36301.4020101@unibas.ch>
Message-ID: <3FB39371.6000906@statistik.uni-dortmund.de>

Pascal A. Niklaus wrote:

> The postscript device behaves strangely - is this possibly a bug?
> 
> case 1)
> 
>  postscript("gfx-%d.ps",width=8 , height=5, paper="special", 
> horizontal=F, onefile=FALSE);
>  <some plots here>
>  dev.off()
> 
>  The first plot is in "portrait" orientation
>  The second and all the following plots are in "landscape" orientation
> 
> case 2)
> 
>  postscript("gfx-%d.ps",width=8 , height=5, paper="special", 
> horizontal=T, onefile=FALSE);
>  <some plots here>
>  dev.off()
> 
>  Now, all plots are in "portrait"...
> 
> So it seems that the orientation of the *first* plot is not affected by 
> horizontal=T/F.

Works for me (R-1.8.1alpha, WinNT4.0).
Which version of R are you using?

Uwe Ligges



From ggrothendieck at myway.com  Thu Nov 13 15:30:50 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 13 Nov 2003 09:30:50 -0500 (EST)
Subject: [R] Chron, as.POSIXct problem
Message-ID: <20031113143050.BE7603977@mprdmxin.myway.com>


From: Brian Beckage <bbeckage at uvm.edu>
>  
> Thanks to all who responded to my posting.
> 
> At 11:39 AM -0500 11/12/03, Gabor Grothendieck wrote:
> >You are being hit by a timezone problem. Its not really shifting
> >the days by one. Its working in the GMT timezone, not yours.
> >
> >If you can accept a date format that chron supports then this is the
> >easiest solution since chron does not support timezones and so can't
> >give you such problems in the first place. For example,
> >the following stays in chron the whole time:
> >
> > format(datesTest, format="m/day/year")
> > [1] "Oct/01/1952" "Oct/02/1952" "Oct/03/1952"
> >
> >If you must convert to POSIXt to take advantage of a format
> >only supported by POSIXt then use POSIXlt and specify the timezone explictly:
> >
> > format(as.POSIXlt(datesTest,tz="GMT"), "%m/%d/%Y")
> > [1] "10/01/1952" "10/02/1952" "10/03/1952"
> 
> This solved the problem using as.POSIXlt(). I guess the tz argument 
> doesn't solve the problem using as.POSIXct(). In any case, I'm able 
> to use as.POSIXlt() in my current application.

You can use POSIXct but its a bit trickier.  Assuming datesTest is a 
chron vector, as before you can do this.  

  format(as.POSIXct(datesTest), "%m/%d/%Y", tz="GMT") # right

Note that in this case you have to use the tz parameter on format, NOT
on as.POSIXct: 

  format(as.POSIXct(datesTest, tz="GMT"), "%m/%d/%Y") # wrong



From p.dalgaard at biostat.ku.dk  Thu Nov 13 15:40:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Nov 2003 15:40:52 +0100
Subject: [R] identify function with postscript output?
In-Reply-To: <3FB39285.3000304@statistik.uni-dortmund.de>
References: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>
	<20030904164138.GB22988@sonny.eddelbuettel.com>
	<x2n0dk70xo.fsf@biostat.ku.dk>
	<Pine.GSO.4.58.0311130444390.13966@faure.cs.colostate.edu>
	<3FB39285.3000304@statistik.uni-dortmund.de>
Message-ID: <x2r80cmivf.fsf@biostat.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> U.Ramakrishna wrote:
> 
> > Hello,
> > I want to select some points in a plot using 'identify' function
> > and also want the identified points to be saved in a
> > postscript file? Any help in how to do it?
> > A better question might have been, how do i pipe the screen output
> > to a postscript file?
> > Thanks and Regards
> > Ramakrishna
> 
> 
> See ?dev.copy

Specifically dev.copy2eps(). In some applications you want to make
sure that the dimensions of the two devices match (or at least that
height/pointsize and width/pointsize are the same).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Thu Nov 13 15:45:22 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 13 Nov 2003 08:45:22 -0600
Subject: [R] xlims of barplot
In-Reply-To: <1068731347.4550.153.camel@localhost.localdomain>
References: <5E06BFED29594F4C9C5EBE230DE320C602C2B682@ewok.vsl.com.au>
	<1068731347.4550.153.camel@localhost.localdomain>
Message-ID: <1068734721.4550.175.camel@localhost.localdomain>

On Thu, 2003-11-13 at 07:49, Marc Schwartz wrote:

<snip>

> # Now use this format for EACH barplot
> barplot(...., horiz = TRUE, xlim = c(0, max.x))
> 
> That will result in the x axis being the same in each plot.  You might
> want to use something like 'xlim = c(0, max.x * 1.25)', which will give
> you some additional space above the bars (ie. for a legend, etc.).

<snip>


Quick clarification:

The last line in the above paragraph should of course read:

"...additional space *to the right* of the bars..."

when creating a horizontal barplot.

Marc



From sbarbar at uni-goettingen.de  Thu Nov 13 15:59:45 2003
From: sbarbar at uni-goettingen.de (Salvatore Barbaro)
Date: Thu, 13 Nov 2003 15:59:45 +0100
Subject: [R] identify function with postscript output?
In-Reply-To: <x2r80cmivf.fsf@biostat.ku.dk>
References: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>
	<3FB39285.3000304@statistik.uni-dortmund.de>
	<x2r80cmivf.fsf@biostat.ku.dk>
Message-ID: <200311131559.45644.sbarbar@uni-goettingen.de>

dev.copy2eps works fine, but, however, does anybody know how to rotate the 
figure? 
dev.copy2eps(horizontal=F) doesn't work.






On Thursday 13 November 2003 15:40, Peter Dalgaard wrote:
> Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
> > U.Ramakrishna wrote:
> > > Hello,
> > > I want to select some points in a plot using 'identify' function
> > > and also want the identified points to be saved in a
> > > postscript file? Any help in how to do it?
> > > A better question might have been, how do i pipe the screen output
> > > to a postscript file?
> > > Thanks and Regards
> > > Ramakrishna
> >
> > See ?dev.copy
>
> Specifically dev.copy2eps(). In some applications you want to make
> sure that the dimensions of the two devices match (or at least that
> height/pointsize and width/pointsize are the same).

-- 
Salvatore Barbaro
University of Goettingen
Department of Public Economics
Platz der Goettinger Sieben 3
D-37073 Goettingen, Germany
Tel +49 (0)551 3919704
http://www.gwdg.de/~sbarbar



From bates at stat.wisc.edu  Thu Nov 13 16:10:31 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 Nov 2003 09:10:31 -0600
Subject: [R] conf int mixed effects
In-Reply-To: <3FB387B6.1060608@uv.es>
References: <200311131109.hADB1ZQ3011351@hypatia.math.ethz.ch>
	<3FB387B6.1060608@uv.es>
Message-ID: <6rhe18jod4.fsf@bates4.stat.wisc.edu>

Joerg Schaber <Joerg.Schaber at uv.es> writes:

> I have a linear mixed-effects model object and want to extract the 95%
> confidence intervals for the fixed and random effects, respectively. I
> found the function intervals() for confidence intervals for the fixed
> effects but no corresponding function for the random effects. Does it
> exist or do I have to calculate the confidence intervals for the
> random effects myself?

You have to calculate them yourself, partly because it is not clear
what such an interval should be.  Technically, the random effects are
not parameters and defining a "confidence interval" on a random
variable that is part of the model is, at the very least, awkward.



From jblazi at gmx.de  Thu Nov 13 16:31:54 2003
From: jblazi at gmx.de (JB)
Date: Thu, 13 Nov 2003 16:31:54 +0100
Subject: [R] Fitting to strange function
Message-ID: <6.0.0.22.2.20031113163004.01c6d2a8@pop.gmx.de>

I have some data int the variabley y (response variable) and x, and I 
suspect the formula

y = A*x^2 +sqrt(0.08*A)*x.

How can I fit my data to this curve?

TIA,

Janos Blazi



From bolker at zoo.ufl.edu  Thu Nov 13 16:57:35 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Thu, 13 Nov 2003 10:57:35 -0500 (EST)
Subject: [R] Problem with parser and if/else
In-Reply-To: <x2vfpomkiv.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0311131046300.19407-100000@bolker.zoo.ufl.edu>


  With all due respect to BDR and you, I think this behavior is not
obvious to casual/new users (using the R search page with "if else" as the
search string turns up nearly identical queries from 1998, 2001, and
2002).  There's a philosophical issue here, of course, about how much we
need to hold people's hands/fill the help files with details about
behavior that is clearly defined but not obvious to beginners.  (And the
fact that some people don't read help pages anyway ...)

  I don't have the new edition of MASS (shame on me), but looking at both 
p. 93 of MASS 3d ed. and at help("if") in R 1.8.0, I don't see this 
problem clearly highlighted (yes, reading the syntax

if(cond) cons.expr  else  alt.expr

very precisely one could infer that the cons.expr and the alt.expr had to
be "on the same line" syntactically).  There *is* a note in the help page
about forgetting braces.

How much would it hurt to add

Another common mistake is to begin an 'else' clause on a new line; this
causes a syntax error, because R assumes that the preceding 'if' statement 
is finished, and tries to read the 'else' clause as a new statement.  

to the documentation?

On 13 Nov 2003, Peter Dalgaard wrote:

> "Brown, Simon" <simon.brown at metoffice.com> writes:
> 
> > Dear r-help people,
> > 
> > could you confirm that this is correct behaviour for R?  I am using RH9.
> > 
> > the code:
> > x1 <- 1:6
> > t1 <- 5
> > if (length(x1) >= t1) {
> > 	cat("in the if \n")
> > } else {
> > 	cat("in the else\n")
> > }
> > 
> > runs fine:
> > > source("test_if_else.R")
> > in the if
> > >
> > 
> > but the code:
> > x1 <- 1:6
> > t1 <- 5
> > if (length(x1) >= t1) {
> > 	cat("in the if 2\n")
> > } 
> > else {
> > 	cat("in the else\n")
> > }
> > 
> > fails with the error:
> > > source("test_if_else2.R")
> > Error in parse(file, n, text, prompt) : syntax error on line 6
> > >
> > 
> > Could someone explain this to me please?
> 
> Again? This has been hashed over several times before. The basic issue
> is whether a statement can be assumed to be syntactically complete at
> the end of a line. It is fairly obvious what happens when you type the
> same expressions at an interactive prompt:
> 
> > x1 <- 1:6
> > t1 <- 5
> > if (length(x1) >= t1) {
> + cat("in the if 2\n")
> + }
> in the if 2
> > else {
> Error: syntax error
> > cat("in the else\n")
> in the else
> > }
> Error: syntax error
> 
> Notice that the first right curly brace is seen as terminating the if
> construct. Otherwise, R would need to wait and check whether the
> *next* line starts with an "else" which would certainly be confusing
> in interactive use. So R assumes the expression is finished and
> evaluates it. Then it gets an "else" keyword that it doesn't know what
> to do with and barfs.
> 
> Files that are source()'ed are subject to the same restrictions as
> code given as input. This is a fairly useful consistency requirement. 
> 
> [Come to think of it, it is not entirely obvious that we couldn't have
> "else ..." working like "if (TRUE) ..." or "if (FALSE) ..." depending
> on the result of a previous if(). I suppose the issue is how to make
> sure that there actually is a matching "if".]
> 
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From Joerg.Schaber at uv.es  Thu Nov 13 16:49:34 2003
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Thu, 13 Nov 2003 16:49:34 +0100
Subject: [R] conf int mixed effects
References: <200311131109.hADB1ZQ3011351@hypatia.math.ethz.ch>	<3FB387B6.1060608@uv.es>
	<6rhe18jod4.fsf@bates4.stat.wisc.edu>
Message-ID: <3FB3A80E.1040909@uv.es>

  I naively thought when I can give estimates of the random effects I 
should also be able to calculate confidence levels of these estimates 
(that's what statistics is about, isn't it?)
For example, similar to the fixed case, I can calculate a 
variance-covariance matrix (C) for the random effects (e.g. following 
Hemmerle and Hartley,TECHNOMETRICS 15 (4): 819-831 1973) and using the 
t-value for the given confidence level and degrees of freedom (t), I can 
estimate confidence intervals for random effect i (r[i]) as something 
like r[i] +- t*sqrt(C[i][i]).
What does the statistician say?


Douglas Bates wrote:

>Joerg Schaber <Joerg.Schaber at uv.es> writes:
>
>  
>
>>I have a linear mixed-effects model object and want to extract the 95%
>>confidence intervals for the fixed and random effects, respectively. I
>>found the function intervals() for confidence intervals for the fixed
>>effects but no corresponding function for the random effects. Does it
>>exist or do I have to calculate the confidence intervals for the
>>random effects myself?
>>    
>>
>
>You have to calculate them yourself, partly because it is not clear
>what such an interval should be.  Technically, the random effects are
>not parameters and defining a "confidence interval" on a random
>variable that is part of the model is, at the very least, awkward.
>  
>

-- 
----------------------------------------------------------
J?rg Schaber
Instituto Cavanilles de Biodiversidad y Biologia Evolutiva
Universidad de Valencia               Tel.: ++34 96 354 3666
A.C. 22085                            Fax.: ++34 96 354 3670
46071 Valencia, Espa?a                email : jos at uv.es



From jfri at novozymes.com  Thu Nov 13 17:02:57 2003
From: jfri at novozymes.com (JFRI (Jesper Frickman))
Date: Thu, 13 Nov 2003 11:02:57 -0500
Subject: [R] Memory issues..
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D14FD55@exusfr14.novo.dk>

I tried first to increase --min-vsize to 2G (which I assume means as
much of the 512M RAM available on my system as possible). The idea was
to allocate all the heap memory in one huge chunk to avoid
fragmentation. It actually brought the number of assays completed up
from 11 to 13 before it stopped with the usual error. Then I increased
--max-memory-size to 2G, and when I came in this morning it was still
running. However, it would probably take days instead of hours to
complete the last couple of assays! So it is easier to restart a couple
of times...

Do you think that running R on Linux would fix the problem? I use Linux
on my private home PC, and I might get a permission to try it out on the
company network... If I have a good reason to do so!

Cheers,
Jesper

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Wednesday, November 12, 2003 10:55 AM
To: JFRI (Jesper Frickman)
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Memory issues..


On Wed, 12 Nov 2003, JFRI (Jesper Frickman) wrote:

> How much processing takes place before you get to the lme call? Maybe 
> R has just used up the memory on something else. I think there is a 
> fair amount of memory leak, as I get similar problems with my program.

> I use

Windows, right?  I don't think this is memory leak, but rather
fragmentation.  Hopefully the memory management in R-devel will ease
this, 
and you might like to compile that up and try it.

On R 1.8.0 on Windows you have to be able to find a block of contiguous 
memory of the needed size, so fragmentation can kill you.  Try
increasing 
--max-memory-size unless you are near 2Gb.

> R 1.8.0. My program goes as follows.
> 
> 1. Use RODBC to get a data.frame containing assays to analyze (17 
> assays are found). 2. Define an AnalyzeAssay(assay, suffix) function 
> to do the following:
> 	a) Use RODBC to get data.
> 	b) Store dataset "limsdata" in workspace using the <<- operator
to 
> avoid the following error in qqnorm.lme: Error in eval(expr, envir,
> enclos) : Object "limsdata" not found, when I call it with a grouping 
> formula like: ~ resid(.) | ORDCURV.
> 	c) Call lme to analyze data.
> 	d) Produce some diagnostic plots. Record them by setting
record=TRUE 
> on the trellis.device
> 	e) Save the plots on win.metafile using replayPlot(...)
> 	f) Save text to a file using sink(...)
> 
> 3. Call the function for each assay using the code:
> 
> # Analyze each assay
> for(i in 1:length(assays[,1]))
> {
> 	writeLines(paste("Analyzing ", assays$DILUTION[i], " ", 
> assays$PROFNO[i], "...", sep=""))
> 	flush.console()
> 	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])
> 
> 	# Clean up memory
> 	rm(limsdata)
> 	gc()
> }
> 
> As you can see, I try to remove the dataset stored in workspace and 
> then call gc() to clean up my memory as I go.
> 
> Nevertheless, when I come to assay 11 out of 17, it stops with a 
> memory allocation error. I have to quit R, and start again with assay 
> 11, then it stops again with assay 15 and finally 17. The last assays 
> have much more data than the first ones, but all assays can be 
> completed as long as I keep restarting...
> 
> Maybe restarting the job can help you getting it done?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Thu Nov 13 17:09:31 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 Nov 2003 10:09:31 -0600
Subject: [R] conf int mixed effects
In-Reply-To: <3FB3A80E.1040909@uv.es>
References: <200311131109.hADB1ZQ3011351@hypatia.math.ethz.ch>
	<3FB387B6.1060608@uv.es> <6rhe18jod4.fsf@bates4.stat.wisc.edu>
	<3FB3A80E.1040909@uv.es>
Message-ID: <6r1xscjlms.fsf@bates4.stat.wisc.edu>

Joerg Schaber <Joerg.Schaber at uv.es> writes:

> I naively thought when I can give estimates of the random effects I
> should also be able to calculate confidence levels of these estimates
> (that's what statistics is about, isn't it?)

Again, to be technical, the random effects are not parameters.  They
are random variables that are part of the probability model and in
that sense they are not 'estimated' per se.  The quantities that are
often interpreted as 'the estimates of the random effects' are in fact
the best linear unbiased predictors (BLUPs).

There could be ways of assigning intervals that somehow measure the
precision of these predictors but, as I said, it is not easy to define
these in a way that is completely consistent with the theory.  I would
prefer not to do it rather than to do it sloppily and end up in a lot
of controversy.

(I already spend an inordinate amount of my time responding to claims
about the calculation of degrees of freedom in approximations to the
distribution of the fixed-effects estimates.  Note to those who know
the "correct" degrees of freedom that should be used - it's all an
approximation.)

> For example, similar to the fixed case, I can calculate a
> variance-covariance matrix (C) for the random effects (e.g. following
> Hemmerle and Hartley,TECHNOMETRICS 15 (4): 819-831 1973) and using the
> t-value for the given confidence level and degrees of freedom (t), I
> can estimate confidence intervals for random effect i (r[i]) as
> something like r[i] +- t*sqrt(C[i][i]).

I haven't looked at the article (my copies of Technometrics don't go
back to 1973) but it is unlikely that such an article would apply to
all the cases that lme can handle and I suspect that some of the
theoretical niceties have been glossed over.



From mlaia at fcav.unesp.br  Thu Nov 13 17:18:24 2003
From: mlaia at fcav.unesp.br (Marcelo Luiz de Laia)
Date: Thu, 13 Nov 2003 14:18:24 -0200
Subject: [R] I receiv an error when try to run a function...
In-Reply-To: <3FB39049.8030707@statistik.uni-dortmund.de>
Message-ID: <DFECKFJKEJHHMLJFFEOMAEKBCBAA.mlaia@fcav.unesp.br>

Hi All,

Three or four days ago I install in my windows 2000 professional 3 (three)
latest "windows 2000 hotfix".

Now, any function provoke errors and the next message will be prompted.

"Rgui.exe has generate errors and will be closed by Windows.
 You will need to restart the program.
 An error log is being created."

I suppose that this bring up to date in my system is the cause of this
errors.

I re-install R, but the errors continue...

Thanks for any tip

Marcelo

> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: quinta-feira, 13 de novembro de 2003 12:08
> To: mlaia at fcav.unesp.br
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] I receiv an error when try to run a function...
>
>
> Marcelo Luiz de Laia wrote:
>
> > Hi All,
> >
> > I use R 1.8.0 and Bioconductor packages in Windows 2000 professional.
> >
> > When I try to run one function, I will receive one dialog box with this
> > message:
> >
> > Rgui.exe has generate errors and will be closed by Windows.
> > You will need to restart the program.
> > An error log is being created.
> >
> > I look in for in my system for the "error log", but nothing...
> >
> > I search in microsoft KB database, but nothing, too.
> >
> > I do not search in R-help archieves.
> >
> > Do someone already see this problem?
>
> If the crash is reproducible, you should send a bug report to the
> maintainer of the corresponding package that function is in.
---



From ripley at stats.ox.ac.uk  Thu Nov 13 17:12:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Nov 2003 16:12:12 +0000 (GMT)
Subject: [R] Memory issues..
In-Reply-To: <D53147E531BFBC4B8853FD134FAEE44D14FD55@exusfr14.novo.dk>
Message-ID: <Pine.LNX.4.44.0311131609541.1689-100000@gannet.stats>

On Thu, 13 Nov 2003, JFRI (Jesper Frickman) wrote:

> I tried first to increase --min-vsize to 2G (which I assume means as
> much of the 512M RAM available on my system as possible). The idea was
> to allocate all the heap memory in one huge chunk to avoid
> fragmentation. 

But had you actually read the documentation you would know it did not do 
that.  That needs --max-memory-size set.

> It actually brought the number of assays completed up
> from 11 to 13 before it stopped with the usual error. Then I increased
> --max-memory-size to 2G, and when I came in this morning it was still
> running. However, it would probably take days instead of hours to
> complete the last couple of assays! So it is easier to restart a couple
> of times...
> 
> Do you think that running R on Linux would fix the problem? I use Linux
> on my private home PC, and I might get a permission to try it out on the
> company network... If I have a good reason to do so!

We don't know what the problem is, and you haven't AFAICS compiled up 
R-devel and tried that.

> Cheers,
> Jesper
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Wednesday, November 12, 2003 10:55 AM
> To: JFRI (Jesper Frickman)
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Memory issues..
> 
> 
> On Wed, 12 Nov 2003, JFRI (Jesper Frickman) wrote:
> 
> > How much processing takes place before you get to the lme call? Maybe 
> > R has just used up the memory on something else. I think there is a 
> > fair amount of memory leak, as I get similar problems with my program.
> 
> > I use
> 
> Windows, right?  I don't think this is memory leak, but rather
> fragmentation.  Hopefully the memory management in R-devel will ease
> this, 
> and you might like to compile that up and try it.
> 
> On R 1.8.0 on Windows you have to be able to find a block of contiguous 
> memory of the needed size, so fragmentation can kill you.  Try
> increasing 
> --max-memory-size unless you are near 2Gb.
> 
> > R 1.8.0. My program goes as follows.
> > 
> > 1. Use RODBC to get a data.frame containing assays to analyze (17 
> > assays are found). 2. Define an AnalyzeAssay(assay, suffix) function 
> > to do the following:
> > 	a) Use RODBC to get data.
> > 	b) Store dataset "limsdata" in workspace using the <<- operator
> to 
> > avoid the following error in qqnorm.lme: Error in eval(expr, envir,
> > enclos) : Object "limsdata" not found, when I call it with a grouping 
> > formula like: ~ resid(.) | ORDCURV.
> > 	c) Call lme to analyze data.
> > 	d) Produce some diagnostic plots. Record them by setting
> record=TRUE 
> > on the trellis.device
> > 	e) Save the plots on win.metafile using replayPlot(...)
> > 	f) Save text to a file using sink(...)
> > 
> > 3. Call the function for each assay using the code:
> > 
> > # Analyze each assay
> > for(i in 1:length(assays[,1]))
> > {
> > 	writeLines(paste("Analyzing ", assays$DILUTION[i], " ", 
> > assays$PROFNO[i], "...", sep=""))
> > 	flush.console()
> > 	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])
> > 
> > 	# Clean up memory
> > 	rm(limsdata)
> > 	gc()
> > }
> > 
> > As you can see, I try to remove the dataset stored in workspace and 
> > then call gc() to clean up my memory as I go.
> > 
> > Nevertheless, when I come to assay 11 out of 17, it stops with a 
> > memory allocation error. I have to quit R, and start again with assay 
> > 11, then it stops again with assay 15 and finally 17. The last assays 
> > have much more data than the first ones, but all assays can be 
> > completed as long as I keep restarting...
> > 
> > Maybe restarting the job can help you getting it done?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at jhsph.edu  Thu Nov 13 17:17:11 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 13 Nov 2003 11:17:11 -0500
Subject: [R] Fitting to strange function
In-Reply-To: <6.0.0.22.2.20031113163004.01c6d2a8@pop.gmx.de>
References: <6.0.0.22.2.20031113163004.01c6d2a8@pop.gmx.de>
Message-ID: <3FB3AE87.7080308@jhsph.edu>

You could use nls() or optimize().

-roger

JB wrote:
> I have some data int the variabley y (response variable) and x, and I 
> suspect the formula
> 
> y = A*x^2 +sqrt(0.08*A)*x.
> 
> How can I fit my data to this curve?
> 
> TIA,
> 
> Janos Blazi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Joerg.Schaber at uv.es  Thu Nov 13 17:33:16 2003
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Thu, 13 Nov 2003 17:33:16 +0100
Subject: [R] conf int mixed effects
References: <3A822319EB35174CA3714066D590DCD50205CE2B@usrymx25.merck.com>
Message-ID: <3FB3B24C.1050107@uv.es>

OK, I am convinced that CI for random effects might not really be 
meaningful.
By the way, the article I mentioned does indeed only cover the 2-way 
model (one fixed effect, one random effect), I think.

But talking about CI of the variance components. How do I extract those? 
In the summary function something like

<snip>
Random effects:
 Formula: ~1 | s
        (Intercept) Residual
StdDev:    2.633981 8.583093
<snip>

is displayed which are the square roots of the variance components, I 
suppose. However, I did not manage to access them directly (at least the 
intercept part, the residual part is accessible via the 'sigma' 
parameter of the summary function).

greetings,

joerg

Liaw, Andy wrote:

>I'm by no mean expert in this, but... Are you referring to confidence
>intervals for variance components, instead of random effects?
>
>As Prof. Bates said, computing CI on random effects is a bit strange
>philosophically, because random effects are sort of estimates of random
>quantities, unlike fixed effects, which are estimates of some "population
>constants".  The definition of CI is that with certain probability, when the
>data generation and model fitting is repeated infinite number of times, the
>computed CI will "cover" the "true population constant".  There's no "true
>population constant" for random effects, but there is for a variance
>component.
>
>HTH,
>Andy
>
>  
>
>>-----Original Message-----
>>From: Joerg Schaber [mailto:Joerg.Schaber at uv.es] 
>>Sent: Thursday, November 13, 2003 10:50 AM
>>To: Douglas Bates; r-help at stat.math.ethz.ch
>>Subject: Re: [R] conf int mixed effects
>>
>>
>>  I naively thought when I can give estimates of the random effects I 
>>should also be able to calculate confidence levels of these estimates 
>>(that's what statistics is about, isn't it?)
>>For example, similar to the fixed case, I can calculate a 
>>variance-covariance matrix (C) for the random effects (e.g. following 
>>Hemmerle and Hartley,TECHNOMETRICS 15 (4): 819-831 1973) and 
>>using the 
>>t-value for the given confidence level and degrees of freedom 
>>(t), I can 
>>estimate confidence intervals for random effect i (r[i]) as something 
>>like r[i] +- t*sqrt(C[i][i]).
>>What does the statistician say?
>>
>>
>>    
>>



From ripley at stats.ox.ac.uk  Thu Nov 13 17:38:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Nov 2003 16:38:12 +0000 (GMT)
Subject: [R] Problem with parser and if/else
In-Reply-To: <Pine.LNX.4.44.0311131046300.19407-100000@bolker.zoo.ufl.edu>
Message-ID: <Pine.LNX.4.44.0311131634350.1761-100000@gannet.stats>

On Thu, 13 Nov 2003, Ben Bolker wrote:

>   With all due respect to BDR and you, I think this behavior is not
> obvious to casual/new users (using the R search page with "if else" as the
> search string turns up nearly identical queries from 1998, 2001, and
> 2002).  There's a philosophical issue here, of course, about how much we
> need to hold people's hands/fill the help files with details about
> behavior that is clearly defined but not obvious to beginners.  (And the
> fact that some people don't read help pages anyway ...)
> 
>   I don't have the new edition of MASS (shame on me), but looking at both 
> p. 93 of MASS 3d ed. and at help("if") in R 1.8.0, I don't see this 
> problem clearly highlighted (yes, reading the syntax

Well, do take a look at MASS4 p.58 as it is completely different from that 
citation.

  A little care is needed when entering \sfn{if ... else} statements to
  ensure that the input is not syntactically complete before the \sfn{else}
  clause, and braces can help with achieving this.

That is exactly the point.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Nov 13 17:42:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Nov 2003 16:42:37 +0000 (GMT)
Subject: [R] I receiv an error when try to run a function...
In-Reply-To: <DFECKFJKEJHHMLJFFEOMAEKBCBAA.mlaia@fcav.unesp.br>
Message-ID: <Pine.LNX.4.44.0311131640370.1761-100000@gannet.stats>

On Thu, 13 Nov 2003, Marcelo Luiz de Laia wrote:

> Three or four days ago I install in my windows 2000 professional 3 (three)
> latest "windows 2000 hotfix".
> 
> Now, any function provoke errors and the next message will be prompted.
> 
> "Rgui.exe has generate errors and will be closed by Windows.
>  You will need to restart the program.
>  An error log is being created."
> 
> I suppose that this bring up to date in my system is the cause of this
> errors.

You mean you have just installed Microsoft's latest set of bugs?

> I re-install R, but the errors continue...> 
> Thanks for any tip

Uninstall the not-so-hot fix and report to Microsoft.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From g38903040 at ym.edu.tw  Thu Nov 13 18:23:47 2003
From: g38903040 at ym.edu.tw (Shih-Te Yang)
Date: Fri, 14 Nov 2003 01:23:47 +0800
Subject: [R] Problems about Heatmap
Message-ID: <000001c3aa0a$e8d58c90$853b818c@Causality>

Dear all:

Recently, I am using "heatmap" function to perform 2-Dimension hierarchical
clustering for gene expression profile. The number of gene and condition are
6370 and 994 respectively. However, I got the error massage after running
the "heatmap" function. Please see below:

> heatmap(int.dat, col=col.map)
Error in match.fun(FUN) : evaluation is nested too deeply: infinite
recursion?
Error: evaluation is nested too deeply: infinite recursion?

Besides, my computer OS is Mandrake9.1 and R version is 1.8.0.

Would you please tell me how to deal with this problem?
Thank you for the kind reply.

Your truly,
Shih-Te
------------------------------------------------
Shih-Te Yang, Ph.D. student
Bioinformatics Research Center
Institute of Biochemistry
School of Life Science
National Yang-Ming University
Tel:+886-2-28267000*5666
Fax:+886-2-81461062
E-mail:g38903040 at ym.edu.tw
MyWeb: http://binfo.ym.edu.tw/styang/



From ihaka at stat.auckland.ac.nz  Thu Nov 13 18:57:52 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Fri, 14 Nov 2003 06:57:52 +1300
Subject: [R] identify function with postscript output?
In-Reply-To: <Pine.GSO.4.58.0311130444390.13966@faure.cs.colostate.edu>
References: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>
	<20030904164138.GB22988@sonny.eddelbuettel.com>
	<x2n0dk70xo.fsf@biostat.ku.dk>
	<Pine.GSO.4.58.0311130444390.13966@faure.cs.colostate.edu>
Message-ID: <3FB3C620.8040106@stat.auckland.ac.nz>

U.Ramakrishna wrote:
> Hello,
> I want to select some points in a plot using 'identify' function
> and also want the identified points to be saved in a
> postscript file? Any help in how to do it?
> 
> A better question might have been, how do i pipe the screen output
> to a postscript file?

You may want to look at the "pos" argument to "identify" and "text". 
Specifying pos=TRUE as an argument to "identify" makes it add a "pos" 
component to its return value.  This can be passed as an argument "text" 
to place the labels in new plots just as they appear in the on-screen 
version.

E.g.

 > #  Onscreen
 > y = rnorm(10)
 > plot(y)
 > id = identify(y,pos=TRUE)

 > #  Later, for hardcopy
 > postscript()
 > plot(y)
 > text(1:length(y)[id$ind], y[id$ind], labels=id$ind, pos=id$pos)
 > dev.off()

That way you can capture the essential state of your on-screen plot,
but make revisions to the way in which its drawn.


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From nlpace at remi.med.utah.edu  Thu Nov 13 19:18:31 2003
From: nlpace at remi.med.utah.edu (Nathan Leon Pace, MD, MStat)
Date: Thu, 13 Nov 2003 11:18:31 -0700
Subject: [R] Installing packages
Message-ID: <C9274C2F-1605-11D8-B8E6-000393B3E9D0@bigpace.med.utah.edu>

Running under Redhat 7.3 Linux I have installed R Version 1.8.0  
(2003-10-08) from a binary download using the rpm manager.

Using packageStatus(), I am attempted to upgrade several packages.

This is unsuccessful with the following error messages:

* Installing *source* package 'MASS' ...
** libs
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c MASS.c -o MASS.o
gcc: installation problem, cannot exec `cpp0': No such file or directory
make: *** [MASS.o] Error 1
ERROR: compilation failed for package 'MASS'

gcc version 2.96 20000731 (Red Hat Linux 7.3 2.96-113) is installed.

I have checked the R archives and FAQ and admin manual for help.

My knowledge of c compiling is limited.

Any pointers for debugging this problem would be appreciated.

Nathan

Nathan Leon Pace, MD, MStat	Work:nlpace at bigpace.med.utah.edu
Department of Anesthesiology	Home:nlpaces at comcast.net
University of Utah			Work:801.581.6393
Salt Lake City, Utah			    Home:801.467.2925
					Fax:801.581.4367										Cell:801.558.3987



From sreedevi at uab.edu  Thu Nov 13 19:42:30 2003
From: sreedevi at uab.edu (Sreedevi Gopalan)
Date: Thu, 13 Nov 2003 12:42:30 -0600
Subject: [R] comparing k-means and hierarchical clustering
Message-ID: <7C93F21AD56849408985C3478EE83BA6617821@UABEXMB2.ad.uab.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031113/68b8ed7d/attachment.pl

From youngser at jhu.edu  Thu Nov 13 19:52:49 2003
From: youngser at jhu.edu (Youngser Park)
Date: Thu, 13 Nov 2003 13:52:49 -0500
Subject: [R] Help: Strange MDS behavior
Message-ID: <93FBCDAC-160A-11D8-8F4F-000A95A725A0@jhu.edu>

Hi!
I have a dissimilarity matrix X and try to compare it with X' = 
dist(cmdscsale(X,k)).
If I increase k, I should expect that the error (or fit) should 
monotonically decrease, right.

Here is a sample code;

   library(mva)
   set.seed(12345)
   x <- as.matrix(dist(matrix(rnorm(100),ncol=10,byrow=T)))
#  x[1,2]<-x[2,1]<-1000  ## <<--** 1
#  x[5,6]<-x[6,5]<-1000  ## <<--** 2
   fit <- NULL
   for(k in 1:9)
    {
    mds <- cmdscale(x,k,add=T)
    xprime <- as.matrix(dist(mds$points))
    fit[k] <- sum((x-xprime)^2)/sum(x^2)
    }
   plot(fit)

When I run this example, it gives a nice "good" plot. However, with 
those two commented lines added, the plot is opposite, that is, the fit 
is increasing as k grows!

I really don't understand this behavior. The reason why I added those 
two lines is because my real input data is not an Euclidean distance 
matrix, but a dissimilarity matrix calculated from my own metric.

So, does this mean that the matrix X *must* be an Euclidean distance 
matrix in this example?
Thanks in advance.

- Youngser



From jblazi at gmx.de  Thu Nov 13 19:54:15 2003
From: jblazi at gmx.de (JB)
Date: Thu, 13 Nov 2003 19:54:15 +0100
Subject: [R] Fitting to strange function
In-Reply-To: <3FB3AE87.7080308@jhsph.edu>
References: <6.0.0.22.2.20031113163004.01c6d2a8@pop.gmx.de>
	<3FB3AE87.7080308@jhsph.edu>
Message-ID: <6.0.0.22.2.20031113195114.01c93320@pop.gmx.de>

At 13.11.2003 (17:17), Roger D. Peng wrote:
>You could use nls() or optimize().
>
>-roger

Well, thx.
This is very complicated. In Mupad I simply say:

         r:=stats::reg(t_list,x_list,a/2*t^2+sqrt(0.08*a)*t,[t],[a])

and get the (right) answer. How would the same command in R go?

TIA,

jb



From mavaillant at saiinc.qc.ca  Thu Nov 13 20:05:17 2003
From: mavaillant at saiinc.qc.ca (Marc-Antoine Vaillant)
Date: Thu, 13 Nov 2003 14:05:17 -0500
Subject: [R] Program Saving
Message-ID: <A9938C35F8ABAF4C86C4C8753021AC8B0343DC@mtl00.saiinc.qc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031113/b21dd23d/attachment.pl

From w_mccardle at msn.com  Thu Nov 13 20:07:15 2003
From: w_mccardle at msn.com (Wes McCardle)
Date: Thu, 13 Nov 2003 19:07:15 +0000
Subject: [R] (no subject)
Message-ID: <BAY5-F12f9Afw5VmKld000034b5@hotmail.com>

Hello All,
I hope you can help me.  I'm trying to put error bars in a xyplot trellis 
graph (see below).  I know there is a function for this, larrows, but for 
the life of me I can't figure out how to use it.  I've been using the 
default panel function (which is I haven't specified any panel function) and 
this produces the plot that I like.  I've tried defining a panel function 
based on some of the examples in the panel.* functions in lattice, but 
without much success.  I would appreciate any help that anyone can give me 
with this problem.  I can provide the data as an attached e-mail if needed.
Thanks,

xyplot(log10(Females+1)+log10(BG+1)~Trap.Type|Species,trap.agg,allow.multiple=T,type='b',as.table=T,auto.key=T)


Wes McCardle
phone: (301) 504-8328
fax: (301) 504-6580
w_mccardle at msn.com

_________________________________________________________________
Concerned that messages may bounce because your Hotmail account is over 
limit? Get Hotmail Extra Storage! http://join.msn.com/?PAGE=features/es



From kwan022 at stat.auckland.ac.nz  Thu Nov 13 20:14:09 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 14 Nov 2003 08:14:09 +1300 (NZDT)
Subject: [R] Program Saving
In-Reply-To: <A9938C35F8ABAF4C86C4C8753021AC8B0343DC@mtl00.saiinc.qc.ca>
Message-ID: <Pine.LNX.4.44.0311140809540.11123-100000@stat55.stat.auckland.ac.nz>

Hi,

On Thu, 13 Nov 2003, Marc-Antoine Vaillant wrote:

> I have a very simple question. If a want to save a whole program (say more than 5 command lines), how can I proceed without each time using the command history (that allow me to recall previously saved command, but which is to long if you want to recall more than 5 command lines), or without saving to a text file and use copy/paste when I open a new R session (but in fact this doesn't work since when you copy your program to a text file, you copy the "<" or the "+" , and when you paste it back to a new R command sheet, you get syntax error since you now have double "<" (<<) and double "+" (++) at each line.

Please wrap your text to something like 80 character per line...

Copy/paste works very well.  Instead of copying from your R session over 
to a text editor, why don't you do it the other way round?  i.e. type your 
R codes in your favourite editor, THEN copy/paste into R.  That way you 
don't get any syntax error, and you have all your R codes saved into one 
file.

There are several good tools.  (X)Emacs/ESS is one of them (and it's the 
one I prefer).  For beginners there is RWinEdt (a plugin, written by Uwe 
Ligges, for WinEdt).  Both allows direct communication from the editor to 
R....

HTH.

-- 
Cheers,

Kevin

---------------------------------------------------------------
"Try not.  Do, do!  Or do not.  There is no try"
   Jedi Master Yoda

----
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From naumov at acsu.buffalo.edu  Thu Nov 13 20:41:40 2003
From: naumov at acsu.buffalo.edu (Aleksey Naumov)
Date: Thu, 13 Nov 2003 14:41:40 -0500
Subject: [R] Test for new page: thanks
In-Reply-To: <200311112327.hABNRwM6028243@tahi.mcs.vuw.ac.nz>
References: <200311112327.hABNRwM6028243@tahi.mcs.vuw.ac.nz>
Message-ID: <200311131441.40579.naumov@acsu.buffalo.edu>

Thank you Paul, Marc, and Ray for helping. Alas: there seems to be no way to 
test for a new page. In my simple case it is no big problem since I can just 
count the number of plots made on the page so far.

Ray: yes I could probably write the header after every plot, effectively 
writing on top of old header (which in my case has both text and a legend). I 
was just looking for a neater way...

Thank you all!
Aleksey

put the same header on each page

On Tuesday 11 November 2003 06:27 pm, Ray Brownrigg wrote:
> Marc Schwartz <MSchwartz at medanalytics.com> wrote:
> > On Tue, 2003-11-11 at 16:49, Paul Murrell wrote:
> > > Hi
> > >
> > > Aleksey Naumov wrote:
> > > > Dear R experts,
> > > >
> > > > I am writing a multi-page PDF file and would like to put a header on
> > > > each page. Is there a way to test a graphic device to see if a new
> > > > page is started (so that I know when to write the header)?
> > >
> > > Sorry.  Not that I can think of.
> > >
> > > Paul
> > >
> > > > I could simply count the plots made (each page has the same number of
> > > > plots), but wanted to see if a more general solution is available.
> >
> > I was trying to think of a way but could not either.
>
> It's not clear what you want as the "header", but if it is the same on
> each page, then using mtext("Header", outer=TRUE) (after a suitable
> par(oma=c(0, 0, 1, 0))), you can just write the header after every plot.
>
> Ray

-- 
Aleksey Naumov
GIS Analyst
Center for Health and Social Research
Buffalo State College



From tplate at blackmesacapital.com  Thu Nov 13 21:08:08 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 13 Nov 2003 13:08:08 -0700
Subject: [R] Fitting to strange function
In-Reply-To: <6.0.0.22.2.20031113195114.01c93320@pop.gmx.de>
References: <3FB3AE87.7080308@jhsph.edu>
	<6.0.0.22.2.20031113163004.01c6d2a8@pop.gmx.de>
	<3FB3AE87.7080308@jhsph.edu>
Message-ID: <5.2.1.1.2.20031113121852.0408da38@mailhost.blackmesacapital.com>

Is there some reason that the simple & obvious does not work or is in some 
way not adequate?

 > data <- data.frame(x=c(1:5), y=c(1,3,2,NA,4))
 > nls(y ~ A*x^2 +sqrt(0.08*A)*x, data=data, start=list(A=0))
Nonlinear regression model
   model:  y ~ A * x^2 + sqrt(0.08 * A) * x
    data:  data
         A
0.1577584
  residual sum-of-squares:  5.445525
 >

At Thursday 07:54 PM 11/13/2003 +0100, JB wrote:
>At 13.11.2003 (17:17), Roger D. Peng wrote:
>>You could use nls() or optimize().
>>
>>-roger
>
>Well, thx.
>This is very complicated. In Mupad I simply say:
>
>         r:=stats::reg(t_list,x_list,a/2*t^2+sqrt(0.08*a)*t,[t],[a])
>
>and get the (right) answer. How would the same command in R go?
>
>TIA,
>
>jb
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jgentry at jimmy.harvard.edu  Thu Nov 13 21:09:53 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 13 Nov 2003 15:09:53 -0500 (EST)
Subject: [R] install.packages() for a local file
Message-ID: <Pine.SOL.4.20.0311131448280.15253-100000@santiam.dfci.harvard.edu>

Hello ...

I see that on Windows one can specify a filename as the "pkgs" argument
and then set CRAN=NULL when calling install.packages() for a local
file.  Is there a way to do this on unix?  It doesn't appear to be
possible, but perhaps I am missing something here.  

Also, if indeed there is no method to do this on unix, is there a reason
behind it or has it just never been implemented?



From jeff.hamann at forestinformatics.com  Thu Nov 13 21:48:09 2003
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Thu, 13 Nov 2003 12:48:09 -0800
Subject: [R] creating a "report" table from a set of lists
Message-ID: <000b01c3aa27$72e1c130$0a00a8c0@rodan>


I've been trying to figure out how to accomplish the following...

I've got a list (returned from a function) and I would like to "cbind()" the
lists together to create a "cross tab" report or simply bind them together
somehow

the function returns a list that looks like the following:

> all$BM
$species
[1] "BM"
$vbar.nobs
[1] 3
$vbar.sum
[1] 54.05435
$count.nobs
[1] 20
$basal.area
[1] 26
$expf
[1] 5.339182

>

so there are different variable types in the list (meaning I can't use
cbind?) to create a table with more than one column for stringing together
multiple species. I tried to use rbind and got similar results. Tried
unlist, but the values get cast into strings (which would be alright be
simply reporting values, but I would like to maintain the types (for using
digits=xxx arguments). I've used unlist and rbind, then turn the matrix to
obtain,

> t(rpt)
               BM                  DF
species        "BM"                "DF"
vbar.nobs      "3"                 "33"
vbar.pctse     "8.77458627230236"  "2.67841483098916"
count.nobs     "20"                "20"
count.se       "0.254175654140783" "0.630267278307595"
...blah, blah, blah....
count.pctse    "39.1039467908896"  "8.34791097096152"
combined.pctse "40.0763274125113"  "8.76707041068808"
basal.area     "26"                "302"
expf           "5.33918184530697"  "48.4101260565985"
>

which is the desired result, but without the quotes


> print.matrix( t(rpt), quote=F )
               BM                DF
species        BM                DF
vbar.nobs      3                 33
vbar.sum       54.0543454534738  584.712753385096
count.nobs     20                20
count.sum      13                151
...blah, blah, blah....
basal.area     26                302
expf           5.33918184530697  48.4101260565985
volume         100               100

but would still like to be able to control the number of digits that are
printed for the doubles....

Am I even close, or is there more engineering I need to do here?

Thanks,
Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From ramakrsn at CS.ColoState.EDU  Thu Nov 13 21:52:16 2003
From: ramakrsn at CS.ColoState.EDU (U.Ramakrishna)
Date: Thu, 13 Nov 2003 13:52:16 -0700 (MST)
Subject: [R] stop further sourcing of an R file
Message-ID: <Pine.GSO.4.44.0310300216490.18754@faure.cs.colostate.edu>

Hello,
Thanks to people who responded to previous mail!

Is there a way in which we can stop further sourcing
of an R file? i.e., i am sourcing an R file and keep
an equivalent of 'exit' in it and run the code till that point?

Thanks again
Regards
Ramakrishna



From p.dalgaard at biostat.ku.dk  Thu Nov 13 22:02:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Nov 2003 22:02:12 +0100
Subject: [R] install.packages() for a local file
In-Reply-To: <Pine.SOL.4.20.0311131448280.15253-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0311131448280.15253-100000@santiam.dfci.harvard.edu>
Message-ID: <x2vfpornhn.fsf@biostat.ku.dk>

Jeff Gentry <jgentry at jimmy.harvard.edu> writes:

> Hello ...
> 
> I see that on Windows one can specify a filename as the "pkgs" argument
> and then set CRAN=NULL when calling install.packages() for a local
> file.  Is there a way to do this on unix?  It doesn't appear to be
> possible, but perhaps I am missing something here.  
> 
> Also, if indeed there is no method to do this on unix, is there a reason
> behind it or has it just never been implemented?

Unix doesn't (generally) have binary packages, so has to be different.
I suppose the theory is that you might as well just run "R CMD
INSTALL" on the file.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Thu Nov 13 21:59:59 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 13 Nov 2003 12:59:59 -0800
Subject: [R] creating a "report" table from a set of lists
In-Reply-To: <000b01c3aa27$72e1c130$0a00a8c0@rodan>
References: <000b01c3aa27$72e1c130$0a00a8c0@rodan>
Message-ID: <3FB3F0CF.6010209@pdf.com>

Does the following do what you want: 

 > list1 <- list(a=1, b=1:2)
 > list2 <- list(c=1:3, d=1:4)
 > c(list1, list2)
$a
[1] 1

$b
[1] 1 2

$c
[1] 1 2 3

$d
[1] 1 2 3 4

spencer graves

Jeff D. Hamann wrote:

>I've been trying to figure out how to accomplish the following...
>
>I've got a list (returned from a function) and I would like to "cbind()" the
>lists together to create a "cross tab" report or simply bind them together
>somehow
>
>the function returns a list that looks like the following:
>
>  
>
>>all$BM
>>    
>>
>$species
>[1] "BM"
>$vbar.nobs
>[1] 3
>$vbar.sum
>[1] 54.05435
>$count.nobs
>[1] 20
>$basal.area
>[1] 26
>$expf
>[1] 5.339182
>
>  
>
>
>so there are different variable types in the list (meaning I can't use
>cbind?) to create a table with more than one column for stringing together
>multiple species. I tried to use rbind and got similar results. Tried
>unlist, but the values get cast into strings (which would be alright be
>simply reporting values, but I would like to maintain the types (for using
>digits=xxx arguments). I've used unlist and rbind, then turn the matrix to
>obtain,
>
>  
>
>>t(rpt)
>>    
>>
>               BM                  DF
>species        "BM"                "DF"
>vbar.nobs      "3"                 "33"
>vbar.pctse     "8.77458627230236"  "2.67841483098916"
>count.nobs     "20"                "20"
>count.se       "0.254175654140783" "0.630267278307595"
>...blah, blah, blah....
>count.pctse    "39.1039467908896"  "8.34791097096152"
>combined.pctse "40.0763274125113"  "8.76707041068808"
>basal.area     "26"                "302"
>expf           "5.33918184530697"  "48.4101260565985"
>  
>
>
>which is the desired result, but without the quotes
>
>
>  
>
>>print.matrix( t(rpt), quote=F )
>>    
>>
>               BM                DF
>species        BM                DF
>vbar.nobs      3                 33
>vbar.sum       54.0543454534738  584.712753385096
>count.nobs     20                20
>count.sum      13                151
>...blah, blah, blah....
>basal.area     26                302
>expf           5.33918184530697  48.4101260565985
>volume         100               100
>
>but would still like to be able to control the number of digits that are
>printed for the doubles....
>
>Am I even close, or is there more engineering I need to do here?
>
>Thanks,
>Jeff.
>
>---
>Jeff D. Hamann
>Forest Informatics, Inc.
>PO Box 1421
>Corvallis, Oregon USA 97339-1421
>(office) 541-754-1428
>(cell) 541-740-5988
>jeff.hamann at forestinformatics.com
>www.forestinformatics.com
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From jgentry at jimmy.harvard.edu  Thu Nov 13 22:00:34 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 13 Nov 2003 16:00:34 -0500 (EST)
Subject: [R] install.packages() for a local file
In-Reply-To: <x2vfpornhn.fsf@biostat.ku.dk>
Message-ID: <Pine.SOL.4.20.0311131558510.15253-100000@santiam.dfci.harvard.edu>


On 13 Nov 2003, Peter Dalgaard wrote:
> I suppose the theory is that you might as well just run "R CMD
> INSTALL" on the file.

That's what I figured here, but wanted to be sure.  I had found a block of
code of mine where I was basically reinventing the wheel installing local
packages and was wondering why I hadn't just used install.packages() on
the files.  I can at least change the code for the Windows side of things.



From macq at llnl.gov  Thu Nov 13 21:59:29 2003
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 13 Nov 2003 12:59:29 -0800
Subject: [R] install.packages() for a local file
In-Reply-To: <Pine.SOL.4.20.0311131448280.15253-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0311131448280.15253-100000@santiam.dfci.harvard.edu>
Message-ID: <p06002007bbd9a0929927@[128.115.153.6]>

There is a method to install a package from a local file.
 From the unix command line, use
   R INSTALL
possibly using
   R CMD build
first.

See Writing R Extensions at CRAN for more information. Or R --help at 
the unix command line.

I haven't looked for a way using install.packages().

-Don

At 3:09 PM -0500 11/13/03, Jeff Gentry wrote:
>Hello ...
>
>I see that on Windows one can specify a filename as the "pkgs" argument
>and then set CRAN=NULL when calling install.packages() for a local
>file.  Is there a way to do this on unix?  It doesn't appear to be
>possible, but perhaps I am missing something here. 
>
>Also, if indeed there is no method to do this on unix, is there a reason
>behind it or has it just never been implemented?
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From jgentry at jimmy.harvard.edu  Thu Nov 13 22:01:55 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 13 Nov 2003 16:01:55 -0500 (EST)
Subject: [R] install.packages() for a local file
In-Reply-To: <p06002007bbd9a0929927@[128.115.153.6]>
Message-ID: <Pine.SOL.4.20.0311131600580.15253-100000@santiam.dfci.harvard.edu>

> There is a method to install a package from a local file.
>  From the unix command line, use
>    R INSTALL
> possibly using
>    R CMD build
> first.

Right.  

I already do this within the function (I need to install the packages from
inside of R), but was going through trying to find redundant code and
thought this might be a place where I could replace one of my functions
with a call to one of R's functions.



From GPetris at uark.edu  Thu Nov 13 22:03:22 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Thu, 13 Nov 2003 15:03:22 -0600 (CST)
Subject: [R] stop further sourcing of an R file
In-Reply-To: <Pine.GSO.4.44.0310300216490.18754@faure.cs.colostate.edu>
	(ramakrsn@CS.ColoState.EDU)
References: <Pine.GSO.4.44.0310300216490.18754@faure.cs.colostate.edu>
Message-ID: <200311132103.hADL3Mrg017023@definetti.uark.edu>


q()


> Date: Thu, 13 Nov 2003 13:52:16 -0700 (MST)
> From: "U.Ramakrishna" <ramakrsn at CS.ColoState.EDU>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> Hello,
> Thanks to people who responded to previous mail!
> 
> Is there a way in which we can stop further sourcing
> of an R file? i.e., i am sourcing an R file and keep
> an equivalent of 'exit' in it and run the code till that point?
> 
> Thanks again
> Regards
> Ramakrishna
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 


-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From ripley at stats.ox.ac.uk  Thu Nov 13 22:13:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Nov 2003 21:13:19 +0000 (GMT)
Subject: [R] Program Saving
In-Reply-To: <A9938C35F8ABAF4C86C4C8753021AC8B0343DC@mtl00.saiinc.qc.ca>
Message-ID: <Pine.LNX.4.44.0311132110360.14115-100000@gannet.stats>

I think you are looking for savehistory(), or the equivalent on the menus
under GUI systems.

But, R is a program, and although I think you mean a section of R code, I 
do not know exactly what you intend `program'to mean.  If you mean a 
function, see dump().

On Thu, 13 Nov 2003, Marc-Antoine Vaillant wrote:

> I have a very simple question. If a want to save a whole program (say
> more than 5 command lines), how can I proceed without each time using
> the command history (that allow me to recall previously saved command,
> but which is to long if you want to recall more than 5 command lines),
> or without saving to a text file and use copy/paste when I open a new R
> session (but in fact this doesn't work since when you copy your program
> to a text file, you copy the "<" or the "+" , and when you paste it back
> to a new R command sheet, you get syntax error since you now have double
> "<" (<<) and double "+" (++) at each line.
> 
> Do they have something simple like in any other program, that consist of
> saving the command sheet under say Program X. Program X will become a
> simple file that I can reopened any time I want and each time I open it,
> I will have in front of me all the previous saved command, (including
> error, I don't care), in order that I don't have to recall anything when
> the program X is opened.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Paul.Sorenson at vision-bio.com  Thu Nov 13 22:40:38 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Fri, 14 Nov 2003 08:40:38 +1100
Subject: [R] xlims of barplot
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C602C2B688@ewok.vsl.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/bbd3ac4a/attachment.pl

From Paul.Sorenson at vision-bio.com  Thu Nov 13 22:53:55 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Fri, 14 Nov 2003 08:53:55 +1100
Subject: [R] xlims of barplot
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C602C2B689@ewok.vsl.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/ba6f260a/attachment.pl

From umeno at students.uiuc.edu  Thu Nov 13 22:57:40 2003
From: umeno at students.uiuc.edu (umeno)
Date: Thu, 13 Nov 2003 15:57:40 -0600
Subject: [R] Panel Data Analysis
Message-ID: <3FB61240@webmail.uiuc.edu>

Hi,

I have been having hard time trying to find out commands to conduct panel data 
analysis such as random effect, fixed effect, within effect, and specification 
tests for these panel data models.

Could anyone please tell me where I can find commands and examples for panel 
data analysis?

Thank you
Soyoko



From ramakrsn at CS.ColoState.EDU  Thu Nov 13 23:24:05 2003
From: ramakrsn at CS.ColoState.EDU (U.Ramakrishna)
Date: Thu, 13 Nov 2003 15:24:05 -0700 (MST)
Subject: [R] stop further sourcing of an R file
In-Reply-To: <200311132103.hADL3Mrg017023@definetti.uark.edu>
References: <Pine.GSO.4.44.0310300216490.18754@faure.cs.colostate.edu>
	<200311132103.hADL3Mrg017023@definetti.uark.edu>
Message-ID: <Pine.GSO.4.58.0311131521470.17876@faure.cs.colostate.edu>

Thankyou, but i *donot* want the R session to quit.
Someone suggested writing functions with return kept at
the locations.
I wanted to ask if there was another way.

Regards
Ramakrishna

On Thu, 13 Nov 2003, Giovanni Petris wrote:

>
> q()
>
>
> > Date: Thu, 13 Nov 2003 13:52:16 -0700 (MST)
> > From: "U.Ramakrishna" <ramakrsn at CS.ColoState.EDU>
> > Sender: r-help-bounces at stat.math.ethz.ch
> > Precedence: list
> >
> > Hello,
> > Thanks to people who responded to previous mail!
> >
> > Is there a way in which we can stop further sourcing
> > of an R file? i.e., i am sourcing an R file and keep
> > an equivalent of 'exit' in it and run the code till that point?
> >
> > Thanks again
> > Regards
> > Ramakrishna
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
>
>
> --
>
>  __________________________________________________
> [                                                  ]
> [ Giovanni Petris                 GPetris at uark.edu ]
> [ Department of Mathematical Sciences              ]
> [ University of Arkansas - Fayetteville, AR 72701  ]
> [ Ph: (479) 575-6324, 575-8630 (fax)               ]
> [ http://definetti.uark.edu/~gpetris/              ]
> [__________________________________________________]
>
>



From MSchwartz at medanalytics.com  Thu Nov 13 23:43:52 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 13 Nov 2003 16:43:52 -0600
Subject: [R] xlims of barplot
In-Reply-To: <5E06BFED29594F4C9C5EBE230DE320C602C2B689@ewok.vsl.com.au>
References: <5E06BFED29594F4C9C5EBE230DE320C602C2B689@ewok.vsl.com.au>
Message-ID: <1068763432.10114.22.camel@localhost.localdomain>

On Thu, 2003-11-13 at 15:53, Paul Sorenson wrote:

SNIP

> Sorry for being vague, it is the latter case, vertical bars.  The data
> doesn't satisfy condition 1.  The family of 6 plots is datestamped data,
> the first plot showing all defects, then each subsequent plot showing
> defects of each severity level we define.  The min and max of each of the
> subsequent datasets is in general a subset of the full dataset.  I can
> easily plot them but it would be nice to keep the same x limits on each
> graph.  The x data is POSIXct although I suspect that is not relevant.


OK...I think I understand what you are doing.

You want a series of barplots that have "space" for the same number of
vertical bars along the x axis, but there may be gaps in the series for
any given barplot. Presumably, those gaps may be anywhere in the time
series along the x axis.

Hint: barplot() will leave gaps in the bar series where an NA appears in
the vector or in a matrix column of height values.

Thus, if you want all of your barplots to have space for say 12 vertical
bars, even though some may only have 7, you can do something like the
following:

# Let's plot these two vertically arranged for show
# First save pars and then set device to two rows
opar <- par(no.readonly = TRUE)
par(mfrow = c(2, 1))

# Example of complete data barplot()
barplot(1:12)

#Example of partial data
MyData <- c(1, 2, NA, 4, NA, NA, NA, 8, 9, 10, 11, NA)
barplot(MyData)

# restore pars
par(opar)


So, the key is to be sure that the vector or matrix has the same number
of elements or matrix columns in each dataset. For your incomplete
datasets, pad each series with NA's to fill out the missing entries in
the time series.

Does that do what you want?

HTH,

Marc Schwartz



From Scott.Waichler at pnl.gov  Thu Nov 13 23:54:53 2003
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Thu, 13 Nov 2003 14:54:53 -0800
Subject: [R] Can't get Sweave syntax highlighting with Emacs
Message-ID: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2146@pnlmse25.pnl.gov>

I can't get Emacs to automatically do syntax highlighting of 
Sweave files.  I have followed Friedrich's suggestion for code
to insert into my .emacs file.  The complete section from my .emacs
file is given below.  When I load a *.Snw file, font is white until I press
M-x, then the first code and document chunks get highlighted, but not
the rest of the file.  Latex and Noweb menus are active, but not ESS,
and there is no switching of modes as I move the pointer to different
types of chunks.

; -------------------------------------------------------------
; Emacs Speaks Statistics
; mode for R
; -------------------------------------------------------------
(load "/home/waichler/emacs/ess-5.1.19/lisp/ess-site")

; ESS  "emacs speaks statistics" SRW 2-19-01
(autoload 'ess-mode "ess" "ess major mode" t)
(autoload 'ess-noweb-mode "ess" "ess noweb mode" t)
(autoload 'ess-noweb-make-buffer "ess" "open a buffer in R mode" t)
(autoload 'ess-make-buffer "ess" "open a buffer in R mode" t)
(setq auto-mode-alist (append '(("\\.R$" . ess-mode)) auto-mode-alist))
(setq auto-mode-alist (append '(("\\.S$" . ess-mode)) auto-mode-alist))
(setq auto-mode-alist (append '(("\\.sp$" . ess-mode)) auto-mode-alist))
(global-set-key [(f10)] 'ess-make-buffer)    
(add-hook 'ess-mode-hook 'turn-on-font-lock)         

; Sweave mode
(defun Rnw-mode ()
  (require 'ess-noweb)
  (noweb-mode)
  (if (fboundp 'R-mode)
      (setq noweb-default-code-mode 'R-mode)))
(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))
(setq reftex-file-extensions
      '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
(setq TeX-file-extensions
      '("Snw" "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))


Scott

Scott Waichler, Senior Research Scientist
Pacific Northwest National Laboratory
MSIN K9-36
P.O. Box 999
Richland, WA   99352    USA
509-372-4423 (voice)
509-372-6089 (fax)
scott.waichler at pnl.gov
http://hydrology.pnl.gov



From ray at mcs.vuw.ac.nz  Thu Nov 13 23:58:38 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Fri, 14 Nov 2003 11:58:38 +1300 (NZDT)
Subject: [R] stop further sourcing of an R file
Message-ID: <200311132258.hADMwcR3014468@tahi.mcs.vuw.ac.nz>

> Thankyou, but i *donot* want the R session to quit.
> Someone suggested writing functions with return kept at
> the locations.
> I wanted to ask if there was another way.
> 
Just have a single
}
as your last line, and put:
if (FALSE) {

just after where you want to stop.

Ray Brownrigg



From ggrothendieck at myway.com  Fri Nov 14 00:02:32 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 13 Nov 2003 18:02:32 -0500 (EST)
Subject: [R] stop further sourcing of an R file
Message-ID: <20031113230232.00D013950@mprdmxin.myway.com>


This will source lines up but not including the first line with
exit in it:

z <- readLines("myfile.r")
z <- textConnection(z[seq(grep("exit",z)[[1]]-1)])
source(z)
close(z)


--- 
Date: Thu, 13 Nov 2003 13:52:16 -0700 (MST) 
From: U.Ramakrishna <ramakrsn at CS.ColoState.EDU>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] stop further sourcing of an R file 

 
 
Hello,
Thanks to people who responded to previous mail!

Is there a way in which we can stop further sourcing
of an R file? i.e., i am sourcing an R file and keep
an equivalent of 'exit' in it and run the code till that point?

Thanks again
Regards
Ramakrishna



From bates at stat.wisc.edu  Fri Nov 14 00:15:21 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 Nov 2003 17:15:21 -0600
Subject: [R] Panel Data Analysis
In-Reply-To: <3FB61240@webmail.uiuc.edu>
References: <3FB61240@webmail.uiuc.edu>
Message-ID: <6rekwbhncm.fsf@bates4.stat.wisc.edu>

umeno <umeno at students.uiuc.edu> writes:

> I have been having hard time trying to find out commands to conduct
> panel data analysis such as random effect, fixed effect, within
> effect, and specification tests for these panel data models.

> Could anyone please tell me where I can find commands and examples
> for panel data analysis?

lme from the nlme package.  It is described in detail in Pinheiro and
Bates (2000) "Mixed-effects Models in S and S-PLUS".  Jed Frees
<jfrees at bus.wisc.edu> may have examples more specifically oriented to
panel data models.



From feh3k at spamcop.net  Fri Nov 14 01:14:09 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 13 Nov 2003 18:14:09 -0600
Subject: [R] (no subject)
In-Reply-To: <BAY5-F12f9Afw5VmKld000034b5@hotmail.com>
References: <BAY5-F12f9Afw5VmKld000034b5@hotmail.com>
Message-ID: <20031113181409.0851e7f6.feh3k@spamcop.net>

On Thu, 13 Nov 2003 19:07:15 +0000
"Wes McCardle" <w_mccardle at msn.com> wrote:

> Hello All,
> I hope you can help me.  I'm trying to put error bars in a xyplot
> trellis graph (see below).  I know there is a function for this,
> larrows, but for the life of me I can't figure out how to use it.  I've
> been using the default panel function (which is I haven't specified any
> panel function) and this produces the plot that I like.  I've tried
> defining a panel function based on some of the examples in the panel.*
> functions in lattice, but without much success.  I would appreciate any
> help that anyone can give me with this problem.  I can provide the data
> as an attached e-mail if needed. Thanks,
> 
> xyplot(log10(Females+1)+log10(BG+1)~Trap.Type|Species,trap.agg,allow.mu
> ltiple=T,type='b',as.table=T,auto.key=T)
> 
> 
> Wes McCardle
> phone: (301) 504-8328
> fax: (301) 504-6580
> w_mccardle at msn.com
>

The xYplot function in the Hmisc package has some semi-automatic ways of
adding error bars/bands to plots. 
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From MSchwartz at medanalytics.com  Fri Nov 14 00:19:13 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 13 Nov 2003 17:19:13 -0600
Subject: [R] Installing packages
In-Reply-To: <C9274C2F-1605-11D8-B8E6-000393B3E9D0@bigpace.med.utah.edu>
References: <C9274C2F-1605-11D8-B8E6-000393B3E9D0@bigpace.med.utah.edu>
Message-ID: <1068765553.10114.38.camel@localhost.localdomain>

On Thu, 2003-11-13 at 12:18, Nathan Leon Pace, MD, MStat wrote:
> Running under Redhat 7.3 Linux I have installed R Version 1.8.0  
> (2003-10-08) from a binary download using the rpm manager.
> 
> Using packageStatus(), I am attempted to upgrade several packages.
> 
> This is unsuccessful with the following error messages:
> 
> * Installing *source* package 'MASS' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c MASS.c -o MASS.o
> gcc: installation problem, cannot exec `cpp0': No such file or directory
> make: *** [MASS.o] Error 1
> ERROR: compilation failed for package 'MASS'
> 
> gcc version 2.96 20000731 (Red Hat Linux 7.3 2.96-113) is installed.
> 
> I have checked the R archives and FAQ and admin manual for help.
> 
> My knowledge of c compiling is limited.
> 
> Any pointers for debugging this problem would be appreciated.
> 
> Nathan


Not sure if you have received any other replies yet, but it appears that
you may be getting bitten by the infamous Red Hat 7.x gcc 2.96 problem.
Without getting into details, this is a known issue with this version of
gcc that was improperly released by RH.

The "official" note on this issue from gnu.org is here:

http://gcc.gnu.org/gcc-2.96.html

To my knowledge RH released updates to that version, but I believe that
the only "real" fix is to either revert to gcc 2.95.x or upgrade to a
version 3.x series release.

Martyn Plummer, the RH maintainer for R may have more detailed
information on this and I am cc'ing him on this reply.

HTH,

Marc Schwartz



From Ted.Harding at nessie.mcc.ac.uk  Fri Nov 14 00:04:11 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 13 Nov 2003 23:04:11 -0000 (GMT)
Subject: [R] stop further sourcing of an R file
In-Reply-To: <200311132103.hADL3Mrg017023@definetti.uark.edu>
Message-ID: <XFMail.031113230209.Ted.Harding@nessie.mcc.ac.uk>

q() will terminate the entire R session.

I suspect what Ramakrishna wants is to set a break-point
in a source file, so as to just read in part of it, and
then continue in the R session with other things.

Though not what it's intended for, 'break' will do the job.

E.g. if test.R contains

  x<-pi*0.01*(0:200);
  plot(x,sin(x))
  break
  plot(x,cos(x))

then after

  source("test.R")

R will plot the sine curve, but not the cosine curve, exiting
at 'break' with the message

  No loop to break from, jumping to top level

and the R session will still be intact, including any variables
created in the script.

Ted.

On 13-Nov-03 Giovanni Petris wrote:
> 
> q()
> 
> 
>> Date: Thu, 13 Nov 2003 13:52:16 -0700 (MST)
>> From: "U.Ramakrishna" <ramakrsn at CS.ColoState.EDU>
>> Sender: r-help-bounces at stat.math.ethz.ch
>> Precedence: list
>> 
>> Hello,
>> Thanks to people who responded to previous mail!
>> 
>> Is there a way in which we can stop further sourcing
>> of an R file? i.e., i am sourcing an R file and keep
>> an equivalent of 'exit' in it and run the code till that point?



From Paul.Sorenson at vision-bio.com  Fri Nov 14 01:01:43 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Fri, 14 Nov 2003 11:01:43 +1100
Subject: [R] xlims of barplot
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C602C2B68E@ewok.vsl.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/37dd1c8b/attachment.pl

From rossini at blindglobe.net  Fri Nov 14 02:16:11 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 13 Nov 2003 17:16:11 -0800
Subject: [R] Can't get Sweave syntax highlighting with Emacs
In-Reply-To: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2146@pnlmse25.pnl.gov> (Scott
	R. Waichler's message of "Thu, 13 Nov 2003 14:54:53 -0800")
References: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2146@pnlmse25.pnl.gov>
Message-ID: <857k23sqas.fsf@blindglobe.net>




"Waichler, Scott R" <Scott.Waichler at pnl.gov> writes:

> I can't get Emacs to automatically do syntax highlighting of 
> Sweave files.  I have followed Friedrich's suggestion for code
> to insert into my .emacs file.  The complete section from my .emacs
> file is given below.  When I load a *.Snw file, font is white until I press
> M-x, then the first code and document chunks get highlighted, but not
> the rest of the file.  Latex and Noweb menus are active, but not ESS,
> and there is no switching of modes as I move the pointer to different
> types of chunks.

This is a contradiction.  You should at least switch from LaTeX to
fundamental mode within chunks, or Noweb isn't working.

You might try:

M-x noweb-set-code-mode <ret> R-mode <ret>

(where <ret> is the enter or return key).

I've had problems like that before -- and havn't had time to fix them
yet. 

(as always, will be fixed with the new version of ESS, which is only
1+ years delayed).

best,
-tony


> ; -------------------------------------------------------------
> ; Emacs Speaks Statistics
> ; mode for R
> ; -------------------------------------------------------------
> (load "/home/waichler/emacs/ess-5.1.19/lisp/ess-site")
>
> ; ESS  "emacs speaks statistics" SRW 2-19-01
> (autoload 'ess-mode "ess" "ess major mode" t)
> (autoload 'ess-noweb-mode "ess" "ess noweb mode" t)
> (autoload 'ess-noweb-make-buffer "ess" "open a buffer in R mode" t)
> (autoload 'ess-make-buffer "ess" "open a buffer in R mode" t)
> (setq auto-mode-alist (append '(("\\.R$" . ess-mode)) auto-mode-alist))
> (setq auto-mode-alist (append '(("\\.S$" . ess-mode)) auto-mode-alist))
> (setq auto-mode-alist (append '(("\\.sp$" . ess-mode)) auto-mode-alist))
> (global-set-key [(f10)] 'ess-make-buffer)    
> (add-hook 'ess-mode-hook 'turn-on-font-lock)         
>
> ; Sweave mode
> (defun Rnw-mode ()
>   (require 'ess-noweb)
>   (noweb-mode)
>   (if (fboundp 'R-mode)
>       (setq noweb-default-code-mode 'R-mode)))
> (add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
> (add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))
> (setq reftex-file-extensions
>       '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
> (setq TeX-file-extensions
>       '("Snw" "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))
>
>
> Scott
>
> Scott Waichler, Senior Research Scientist
> Pacific Northwest National Laboratory
> MSIN K9-36
> P.O. Box 999
> Richland, WA   99352    USA
> 509-372-4423 (voice)
> 509-372-6089 (fax)
> scott.waichler at pnl.gov
> http://hydrology.pnl.gov
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From kjetil at entelnet.bo  Fri Nov 14 02:20:19 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Thu, 13 Nov 2003 21:20:19 -0400
Subject: [R] Program Saving
In-Reply-To: <Pine.LNX.4.44.0311140809540.11123-100000@stat55.stat.auckland.ac.nz>
References: <A9938C35F8ABAF4C86C4C8753021AC8B0343DC@mtl00.saiinc.qc.ca>
Message-ID: <3FB3F593.1286.184DFB2@localhost>

On 14 Nov 2003 at 8:14, Ko-Kang Kevin Wang wrote:

> Hi,
> 
> On Thu, 13 Nov 2003, Marc-Antoine Vaillant wrote:
> 
> > I have a very simple question. If a want to save a whole program (say more than 5 command lines), how can I proceed without each time using the command history (that allow me to recall previously saved command, but which is to long if you want to recall more than 5 command lines), or without saving to a text file and use copy/paste when I open a new R session (but in fact this doesn't work since when you copy your program to a text file, you copy the "<" or the "+" , and when you paste it back to a new R 
command sheet, you get syntax error since you now have double "<" (<<) and double "+" (++) at each line.
> 
> Please wrap your text to something like 80 character per line...

Or even a little bit less ...

> 
> Copy/paste works very well.  Instead of copying from your R session over 
> to a text editor, why don't you do it the other way round?  i.e. type your 
> R codes in your favourite editor, THEN copy/paste into R.  That way you 
> don't get any syntax error, and you have all your R codes saved into one 
> file.
> 
> There are several good tools.  (X)Emacs/ESS is one of them (and it's the 
> one I prefer).  For beginners there is RWinEdt (a plugin, written by Uwe 
> Ligges, for WinEdt).  Both allows direct communication from the editor to 
> R....

Yes. But sometimes one wants to experiment, then it is usefull to 
have
 options(continue=" ")

Kjetil Halvorsen

> 
> HTH.
> 
> -- 
> Cheers,
> 
> Kevin
> 
> ---------------------------------------------------------------
> "Try not.  Do, do!  Or do not.  There is no try"
>    Jedi Master Yoda
> 
> ----
> Ko-Kang Kevin Wang
> Master of Science (MSc) Student
> SLC Tutor and Lab Demonstrator
> Department of Statistics
> University of Auckland
> New Zealand
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> Ph: 373-7599
>     x88475 (City)
>     x88480 (Tamaki)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From trafton at itd.nrl.navy.mil  Fri Nov 14 03:37:46 2003
From: trafton at itd.nrl.navy.mil (Greg Trafton)
Date: Thu, 13 Nov 2003 21:37:46 -0500
Subject: [R] calculating arc length using R?
In-Reply-To: <1dc6c71dc2a4.1dc2a41dc6c7@ono.com> (arv@ono.com's message of
	"Wed, 19 Mar 2003 08:35:14 +0100")
References: <1dc6c71dc2a4.1dc2a41dc6c7@ono.com>
Message-ID: <m21xsbk745.fsf@resume.itd.nrl.navy.mil>

Hi, All.  I have a function I want to know the plotted length of.  is it
possible to calculate the length of the function (e.g., arc length)?

for example, if I want to know the length of the line of
sin(x) from -pi to pi, how can I do that in R?

thanks!
greg



From MSchwartz at medanalytics.com  Fri Nov 14 04:08:44 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 13 Nov 2003 21:08:44 -0600
Subject: [R] xlims of barplot
In-Reply-To: <5E06BFED29594F4C9C5EBE230DE320C602C2B68E@ewok.vsl.com.au>
References: <5E06BFED29594F4C9C5EBE230DE320C602C2B68E@ewok.vsl.com.au>
Message-ID: <1068779324.10114.180.camel@localhost.localdomain>

On Thu, 2003-11-13 at 18:01, Paul Sorenson wrote:

SNIP

> >OK...I think I understand what you are doing.
> >
> >You want a series of barplots that have "space" for the same number of
> >vertical bars along the x axis, but there may be gaps in the series for
> >any given barplot. Presumably, those gaps may be anywhere in the time
> >series along the x axis.
> 
> Correct and most problematically at the ends.

Actually, in many respects, that makes it a bit easier...  :-)

> >Hint: barplot() will leave gaps in the bar series where an NA appears in
> >the vector or in a matrix column of height values.
> >
> >...
> >
> >So, the key is to be sure that the vector or matrix has the same number
> >of elements or matrix columns in each dataset. For your incomplete
> >datasets, pad each series with NA's to fill out the missing entries in
> >the time series.
> 
> That sounds like a way forward.  I just need to go back to the basics and
> learn how to add "rows" to data.frames.  I am sure it won't be hard, its
> just my personal learning curve with several new data types (factors,
> tables, data.frames vs vectors, lists, arrays which I am more familiar
> with).  For example, yesterday I tried max(myFactor) and it gave me an
> error (something like "must be a vector"), even though to my naive way of
> thinking myFactor clearly had a numeric max.

What was myFactor?  If it was a 'factor', then you cannot use max() on
it.  Use str(myFactor) and see what it says. That will show you the
structure of myFactor.



The key will be to create the actual vector or matrix of bar values that
you will use for the barplots from your data frame. Don't modify the
dataframe, but extract the data you need and work with the subset. 

Once you have that, it becomes relatively easy.

If for example, you have a single vector of 6 values and you need it to
have 3 NA's (gaps) before and 6 NA's (gaps) after, for a total of 15
values:

SixValues <- c(12, 24, 11, 8, 17, 7)
MyData <- c(rep(NA, 3), SixValues, rep(NA, 6))
barplot(MyData)

MyData ends up looking like:

> MyData
 [1] NA NA NA 12 24 11  8 17  7 NA NA NA NA NA NA

See ?rep and ?c for more information on generating repeating sequences
of values and concatenating (joining) vectors.

On the other hand, let's say you have data that requires segmented bars
with 15 bars, three segments each. However, you only have data for 6
bars and need to pad space for 3 bars before and 6 bars after:

SixBars <- matrix(c(4, 2, 6, 12, 8, 4, 
                    3, 5, 3, 2,  5, 1, 
                    5, 4, 8, 3, 2, 2), ncol = 6)

The above generates a matrix of values that looks like:

> SixBars
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    4   12    3    2    5    3
[2,]    2    8    5    5    4    2
[3,]    6    4    3    1    8    2

We end up with 3 rows and 6 columns, which will result in 6 bars, each
with 3 segments. Remember that in barplot(), the columns represent each
bar if 'beside = FALSE' or groups of bars if 'beside = TRUE'.

Now call barplot():

barplot(SixBars)

Now, we need to add the gaps before and after. In essence, we need to
add a 3 x 3 matrix of NA's before and a 3 x 6 matrix of NA's after to
pad the known data:

MyData <- cbind(matrix(rep(NA, 9), ncol = 3), 
                SixBars, 
                matrix(rep(NA, 18), ncol = 6))

MyData looks like:

     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
[1,]   NA   NA   NA    4   12    3    2    5    3    NA    NA    NA
[2,]   NA   NA   NA    2    8    5    5    4    2    NA    NA    NA
[3,]   NA   NA   NA    6    4    3    1    8    2    NA    NA    NA
     [,13] [,14] [,15]
[1,]    NA    NA    NA
[2,]    NA    NA    NA
[3,]    NA    NA    NA


Now call barplot:

barplot(MyData)

See ?cbind for more information on binding columns and rows (rbind).

And...finally, if you need the bars to be grouped:

barplot(MyData, beside = TRUE)


One final example.  We need to take SixBars and add two gaps between the
3rd and 4th bars to make a total of 8:

MyData <- cbind(SixBars[, 1:3], 
                matrix(rep(NA, 6), ncol = 2), 
                SixBars[, 4:6])

> MyData
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    4   12    3   NA   NA    2    5    3
[2,]    2    8    5   NA   NA    5    4    2
[3,]    6    4    3   NA   NA    1    8    2

barplot(MyData)

The construct SixBars[, 1:3] extracts all rows and the 1st through 3rd
columns from SixBars.  See ?Extract for more information.

Be sure to read through the available documentation, especially
Introduction to R, which is available via the Documentation links on the
main R web site. That covers a lot of the data management basics. There
are also some very good user written documents on the Contributed
Documentation link.

HTH,

Marc Schwartz



From P.Lemmens at nici.kun.nl  Fri Nov 14 09:05:57 2003
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Fri, 14 Nov 2003 09:05:57 +0100
Subject: [R] Problem with parser and if/else
In-Reply-To: <x2vfpomkiv.fsf@biostat.ku.dk>
References: <1068727143.22311.9.camel@eld426.desktop.frd.metoffice.com>
	<x2vfpomkiv.fsf@biostat.ku.dk>
Message-ID: <1085015.1068800757@lemmens.socsci.kun.nl>

Dear Peter,

--On donderdag 13 november 2003 15:05 +0100 Peter Dalgaard 
<p.dalgaard at biostat.ku.dk> wrote:

> "Brown, Simon" <simon.brown at metoffice.com> writes:
>
>> Dear r-help people,
>>
>> could you confirm that this is correct behaviour for R?  I am using RH9.
>>
>> the code:
>> x1 <- 1:6
>> t1 <- 5
>> if (length(x1) >= t1) {
>> 	cat("in the if \n")
>> } else {
>> 	cat("in the else\n")
>> }
>>
>> runs fine:
>> > source("test_if_else.R")
>> in the if
>> >
>>
>> but the code:
>> x1 <- 1:6
>> t1 <- 5
>> if (length(x1) >= t1) {
>> 	cat("in the if 2\n")
>> }
>> else {
>> 	cat("in the else\n")
>> }
>>
>> fails with the error:
>> > source("test_if_else2.R")
>> Error in parse(file, n, text, prompt) : syntax error on line 6
>> >
>>
>> Could someone explain this to me please?
>
> Again? This has been hashed over several times before. The basic issue
> is whether a statement can be assumed to be syntactically complete at
> the end of a line. It is fairly obvious what happens when you type the
> same expressions at an interactive prompt:
>
>> x1 <- 1:6
>> t1 <- 5
>> if (length(x1) >= t1) {
> + cat("in the if 2\n")
> + }
> in the if 2
>> else {
> Error: syntax error
>> cat("in the else\n")
> in the else
>> }
> Error: syntax error
>
> Notice that the first right curly brace is seen as terminating the if
> construct. Otherwise, R would need to wait and check whether the
> *next* line starts with an "else" which would certainly be confusing
> in interactive use. So R assumes the expression is finished and
> evaluates it. Then it gets an "else" keyword that it doesn't know what
> to do with and barfs.
>
I'm trying to grasp this: if you're saying (or are you saying) that the 
only way to have if() know that an else will be present is to put it on the 
same line as the closing curly brace of the if() (compound) statement. But 
if I look at some code from, e.g., aov and lm, I see plenty violations of 
that rule.

regards,
Paul


-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From ripley at stats.ox.ac.uk  Fri Nov 14 09:22:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Nov 2003 08:22:05 +0000 (GMT)
Subject: [R] Problem with parser and if/else
In-Reply-To: <1085015.1068800757@lemmens.socsci.kun.nl>
Message-ID: <Pine.LNX.4.44.0311140817080.24473-100000@gannet.stats>

On Fri, 14 Nov 2003, Paul Lemmens wrote:

> I'm trying to grasp this: if you're saying (or are you saying) that the 
> only way to have if() know that an else will be present is to put it on the 
> same line as the closing curly brace of the if() (compound) statement. But 
> if I look at some code from, e.g., aov and lm, I see plenty violations of 
> that rule.

The actual rule is given in my reference (the one that Ben Bolker did not 
bother to look up) earlier in this thread.

You need to ensure that the code is syntactically incomplete when `else'
is encountered.  That will always be true inside a braced expression such 
as the bodies of the functions you quote.  But at top-level, you do need
to write

if(condition) something else something_else

or

if(condition) {
} else {
}

since

if(condition) {
} 
else {
}

fails the test.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Joerg.Schaber at uv.es  Fri Nov 14 10:28:35 2003
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Fri, 14 Nov 2003 10:28:35 +0100
Subject: [R] R CMD check problems
Message-ID: <3FB4A043.4010008@uv.es>

Hi,

I am trying to create a R-package. When I load my R source files using 
source() for debugging reasons everthing works fine and all function 
also do want they are supposed to do. However, when I run 'R CMD check' 
it stop with
* checking R files for syntax errors ... ERROR
Syntax error in file

Is there a way to further investigate where the error is?

greetings,

joerg



From agustin.perez at umh.es  Fri Nov 14 10:37:30 2003
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Fri, 14 Nov 2003 10:37:30 +0100
Subject: [R] packages
Message-ID: <5AFDDD57E2771B409224CD858CC6DE0D02DAB314@mailer-e051.umh.es>

Hello every body, I am new in this list and I am Spanish (excuses for my
English)

I have a lot of versions of R (under windows) and I want to know the mode to
use the packages of these versions without download any more.
It takes me more time because I have all the packages that there are in
CRAN.

Thanks,
Agustin Perez



From ligges at statistik.uni-dortmund.de  Fri Nov 14 10:55:12 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 14 Nov 2003 10:55:12 +0100
Subject: [R] packages
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB314@mailer-e051.umh.es>
References: <5AFDDD57E2771B409224CD858CC6DE0D02DAB314@mailer-e051.umh.es>
Message-ID: <3FB4A680.1040809@statistik.uni-dortmund.de>

Perez Martin, Agustin wrote:

> Hello every body, I am new in this list and I am Spanish (excuses for my
> English)
> 
> I have a lot of versions of R (under windows) and I want to know the mode to
> use the packages of these versions without download any more.
> It takes me more time because I have all the packages that there are in
> CRAN.
> 
> Thanks,
> Agustin Perez

In principle, you can use *some* of the packages that were compiled for 
an old version of R, *but*
a) some other packages need to be recompiled,
b) you might have outdated versions of some packages given you use those 
that have been installed some time ago for an outdated version of R.

Uwe Ligges



From H.RINNER at tirol.gv.at  Fri Nov 14 11:13:26 2003
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Fri, 14 Nov 2003 11:13:26 +0100
Subject: [R] ISOdate() and strptime()
Message-ID: <C4D44AB4CB62D311BA6500041202E886031EE347@xms1.tirol.gv.at>

Dear R-people!

I am using R 1.8.0, under Windows XP.
While using ISOdate() and strptime(), I noticed the following behaviour when
"wrong" arguments (e.g., months>12) are given to these functions:

> ISOdate(year=2003,month=2,day=20) #ok
[1] "2003-02-20 13:00:00 Westeurop?ische Normalzeit"
> ISOdate(year=2003,month=2,day=30) #wrong day, but returns a value
[1] "2003-03-02 13:00:00 Westeurop?ische Normalzeit"
> ISOdate(year=2003,month=2,day=35) #wrong day, and returns NA
[1] NA
> ISOdate(year=2003,month=2,day=40) #wrong day, but returns a value
[1] "2003-02-04 01:12:00 Westeurop?ische Normalzeit"
> ISOdate(year=2003,month=22,day=20) #wrong month, but returns a value
[1] "2003-02-02 21:12:00 Westeurop?ische Normalzeit"

And almost the same with strptime():
> strptime("2003-02-20", format="%Y-%m-%d")
[1] "2003-02-20"
> strptime("2003-02-30", format="%Y-%m-%d")
[1] "2003-03-02"
> strptime("2003-02-35", format="%Y-%m-%d")
[1] NA
> strptime("2003-02-40", format="%Y-%m-%d")
[1] "2003-02-04"
> strptime("2003-22-20", format="%Y-%m-%d")
[1] NA

Is this considered to be a user error ("If you put garbage in, expect to get
garbage out"), or would it be safer to generally return Nas, as in
ISOdate(year=2003,month=2,day=35)?

-Heinrich.



From ripley at stats.ox.ac.uk  Fri Nov 14 12:03:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Nov 2003 11:03:00 +0000 (GMT)
Subject: [R] ISOdate() and strptime()
In-Reply-To: <C4D44AB4CB62D311BA6500041202E886031EE347@xms1.tirol.gv.at>
Message-ID: <Pine.LNX.4.44.0311141102040.24857-100000@gannet.stats>

On Fri, 14 Nov 2003, RINNER Heinrich wrote:

> Dear R-people!
> 
> I am using R 1.8.0, under Windows XP.
> While using ISOdate() and strptime(), I noticed the following behaviour when
> "wrong" arguments (e.g., months>12) are given to these functions:
> 
> > ISOdate(year=2003,month=2,day=20) #ok
> [1] "2003-02-20 13:00:00 Westeurop?ische Normalzeit"
> > ISOdate(year=2003,month=2,day=30) #wrong day, but returns a value
> [1] "2003-03-02 13:00:00 Westeurop?ische Normalzeit"
> > ISOdate(year=2003,month=2,day=35) #wrong day, and returns NA
> [1] NA
> > ISOdate(year=2003,month=2,day=40) #wrong day, but returns a value
> [1] "2003-02-04 01:12:00 Westeurop?ische Normalzeit"
> > ISOdate(year=2003,month=22,day=20) #wrong month, but returns a value
> [1] "2003-02-02 21:12:00 Westeurop?ische Normalzeit"
> 
> And almost the same with strptime():
> > strptime("2003-02-20", format="%Y-%m-%d")
> [1] "2003-02-20"
> > strptime("2003-02-30", format="%Y-%m-%d")
> [1] "2003-03-02"
> > strptime("2003-02-35", format="%Y-%m-%d")
> [1] NA
> > strptime("2003-02-40", format="%Y-%m-%d")
> [1] "2003-02-04"
> > strptime("2003-22-20", format="%Y-%m-%d")
> [1] NA
> 
> Is this considered to be a user error ("If you put garbage in, expect to get
> garbage out"), or would it be safer to generally return Nas, as in
> ISOdate(year=2003,month=2,day=35)?

Expect to get the best guess at what you intended, and expect this to 
depend on your OS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Nov 14 12:11:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Nov 2003 11:11:55 +0000 (GMT)
Subject: [R] packages
In-Reply-To: <3FB4A680.1040809@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0311141107060.24857-100000@gannet.stats>

On Fri, 14 Nov 2003, Uwe Ligges wrote:

> Perez Martin, Agustin wrote:
> 
> > Hello every body, I am new in this list and I am Spanish (excuses for my
> > English)
> > 
> > I have a lot of versions of R (under windows) and I want to know the mode to
> > use the packages of these versions without download any more.
> > It takes me more time because I have all the packages that there are in
> > CRAN.
> > 
> > Thanks,
> > Agustin Perez
> 
> In principle, you can use *some* of the packages that were compiled for 
> an old version of R, *but*
> a) some other packages need to be recompiled,
> b) you might have outdated versions of some packages given you use those 
> that have been installed some time ago for an outdated version of R.

And to add to that, we don't know which are which, as we don't test old 
versions of packages with current versions of R.

I would be really surprised that you needed all the CRAN packages.  But if 
you do, you can just select all the packages in the scrolling list, or do 
something like

> install.packages(CRAN.packages()[,1])

to reinstall them all.  It might be better to download all the zip files 
(I use ftp) and install them as needed  (which is what I do when I know I 
will be using my laptop away from an internet connection).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Fri Nov 14 12:37:50 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Nov 2003 12:37:50 +0100
Subject: [R] Installing packages
In-Reply-To: <1068765553.10114.38.camel@localhost.localdomain>
References: <C9274C2F-1605-11D8-B8E6-000393B3E9D0@bigpace.med.utah.edu>
	<1068765553.10114.38.camel@localhost.localdomain>
Message-ID: <x2d6bvkwoh.fsf@biostat.ku.dk>

Marc Schwartz <MSchwartz at medanalytics.com> writes:

> On Thu, 2003-11-13 at 12:18, Nathan Leon Pace, MD, MStat wrote:
> > Running under Redhat 7.3 Linux I have installed R Version 1.8.0  
> > (2003-10-08) from a binary download using the rpm manager.
> > 
> > Using packageStatus(), I am attempted to upgrade several packages.
> > 
> > This is unsuccessful with the following error messages:
> > 
> > * Installing *source* package 'MASS' ...
> > ** libs
> > gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> > -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c MASS.c -o MASS.o
> > gcc: installation problem, cannot exec `cpp0': No such file or directory
> > make: *** [MASS.o] Error 1
> > ERROR: compilation failed for package 'MASS'
> > 
> > gcc version 2.96 20000731 (Red Hat Linux 7.3 2.96-113) is installed.
> > 
> > I have checked the R archives and FAQ and admin manual for help.
> > 
> > My knowledge of c compiling is limited.
> > 
> > Any pointers for debugging this problem would be appreciated.
> > 
> > Nathan
> 
> 
> Not sure if you have received any other replies yet, but it appears that
> you may be getting bitten by the infamous Red Hat 7.x gcc 2.96 problem.
> Without getting into details, this is a known issue with this version of
> gcc that was improperly released by RH.
> 
> The "official" note on this issue from gnu.org is here:
> 
> http://gcc.gnu.org/gcc-2.96.html
> 
> To my knowledge RH released updates to that version, but I believe that
> the only "real" fix is to either revert to gcc 2.95.x or upgrade to a
> version 3.x series release.
> 
> Martyn Plummer, the RH maintainer for R may have more detailed
> information on this and I am cc'ing him on this reply.

Hmm, the symptoms don't quite usually look like that, and most of them
got fixed in the 2.96-N releases where N was somewhere in the 80's
IIRC. This claims to be an installation error where the preprocessor
cpp0 is not found, so my first try would be to go look for it, i.e. (on
RH8)

$ locate cpp0
/usr/lib/gcc-lib/i386-redhat-linux/3.2/tradcpp0
/usr/lib/gcc-lib/i386-redhat-linux/3.2/cpp0

It seems to live in the cpp package, 

$ rpm -qf /usr/lib/gcc-lib/i386-redhat-linux/3.2/cpp0
cpp-3.2-7

so 

rpm -V cpp

should help you check your installation.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Fri Nov 14 13:36:36 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Nov 2003 13:36:36 +0100
Subject: [R] stop further sourcing of an R file
In-Reply-To: <XFMail.031113230209.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.031113230209.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <x28ymjktyj.fsf@biostat.ku.dk>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> q() will terminate the entire R session.
> 
> I suspect what Ramakrishna wants is to set a break-point
> in a source file, so as to just read in part of it, and
> then continue in the R session with other things.
> 
> Though not what it's intended for, 'break' will do the job.
> 
> E.g. if test.R contains
> 
>   x<-pi*0.01*(0:200);
>   plot(x,sin(x))
>   break
>   plot(x,cos(x))
> 
> then after
> 
>   source("test.R")
> 
> R will plot the sine curve, but not the cosine curve, exiting
> at 'break' with the message
> 
>   No loop to break from, jumping to top level
> 
> and the R session will still be intact, including any variables
> created in the script.

Similarly, stop() could be used, as, I suspect, anything else that
generates a (non-fatal) runtime error:

> source("t.R")
[1] 1
Error in eval.with.vis(expr, envir, enclos) :
        done
> x
[1] 1
> system("cat t.R")
x <- 1;
print(1)
stop("done")
print(2)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From petr.pikal at precheza.cz  Fri Nov 14 13:35:52 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 14 Nov 2003 13:35:52 +0100
Subject: [R] bad performance of a function
Message-ID: <3FB4DA38.4484.394967@localhost>

Dear all

I need to find a length of true sequences in logical vector (see example 1). I found 
a possible solution which is good but if I use it on a larger data set I experience a 
substantial decrease in performance (example 2).

Example 1
set.seed(111)
x <- sample(c(T,F),50, replace=T)
system.time(cetnost <- as.numeric(table(which(x)-cumsum(x[which(x)]))))
[1] 0.00 0.00 0.03   NA   NA
cetnost
[1] 1 3 2 5 1 4 1 1 1 3 1 1 2

Example 2
x<-sample(c(T,F),40321*51, replace=T)
dd<-matrix(x,40321,51)
system.time(cetnost <- lapply(dd,function(x) as.numeric(table(which(x)-
cumsum(x[which(x)])))))
Timing stopped at: 750.63 1 775.6 NA NA 

Please give me any hint how to improve performance or advice a different (but 
more effective) solution.

R 1.8.0, W2000,  512M memory, Pentium4

Thank you in advance.



Petr Pikal
petr.pikal at precheza.cz



From Roger.Bivand at nhh.no  Fri Nov 14 13:52:10 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 14 Nov 2003 13:52:10 +0100 (CET)
Subject: [R] bad performance of a function
In-Reply-To: <3FB4DA38.4484.394967@localhost>
Message-ID: <Pine.LNX.4.44.0311141348060.15094-100000@reclus.nhh.no>

On Fri, 14 Nov 2003, Petr Pikal wrote:

> Dear all
> 
> I need to find a length of true sequences in logical vector (see example 1). I found 
> a possible solution which is good but if I use it on a larger data set I experience a 
> substantial decrease in performance (example 2).
> 
> Example 1
> set.seed(111)
> x <- sample(c(T,F),50, replace=T)
> system.time(cetnost <- as.numeric(table(which(x)-cumsum(x[which(x)]))))
> [1] 0.00 0.00 0.03   NA   NA
> cetnost
> [1] 1 3 2 5 1 4 1 1 1 3 1 1 2

Have you looked at rle()?

> rlex <- rle(x)
> str(rlex)
List of 2
 $ lengths: int [1:27] 2 1 1 3 1 2 2 5 1 1 ...
 $ values : logi [1:27] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE 
FALSE  TRUE FALSE  TRUE ...
 - attr(*, "class")= chr "rle"
> rlex$lengths[rlex$values]
 [1] 1 3 2 5 1 4 1 1 1 3 1 1 2
> cetnost
 [1] 1 3 2 5 1 4 1 1 1 3 1 1 2

rle() is interpreted too, like your solution, so I'm not sure how it will 
scale.

> 
> Example 2
> x<-sample(c(T,F),40321*51, replace=T)
> dd<-matrix(x,40321,51)
> system.time(cetnost <- lapply(dd,function(x) as.numeric(table(which(x)-
> cumsum(x[which(x)])))))
> Timing stopped at: 750.63 1 775.6 NA NA 
> 
> Please give me any hint how to improve performance or advice a different (but 
> more effective) solution.
> 
> R 1.8.0, W2000,  512M memory, Pentium4
> 
> Thank you in advance.
> 
> 
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From d.orme at imperial.ac.uk  Fri Nov 14 14:16:24 2003
From: d.orme at imperial.ac.uk (David Orme)
Date: Fri, 14 Nov 2003 13:16:24 +0000
Subject: [R] Vector indices and minus sign
Message-ID: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>

Hi,

I got caught out by this behaviour in 1.8.0 and I wondered why this 
happens:

I have a list of vectors and was using lapply and grep to remove 
matched elements that occur in only a subset of the elements of the 
list:
	locs <- lapply(locs, function(x){x[- grep("^x", x)]})

The problem is that where the grep finds no matches and hence returns a 
vector of length 0, all the elements of x were removed, rather than 
none. As a toy example:

vect <- 1:10
vect[-5]
index <- 5
vect[-index]
index <- numeric()
vect[-index] # I was expecting this to give all the elements of vect 
rather than an empty vector
vect[index] # does the same thing


Thanks,
David



From p.dalgaard at biostat.ku.dk  Fri Nov 14 14:22:54 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Nov 2003 14:22:54 +0100
Subject: [R] bad performance of a function
In-Reply-To: <Pine.LNX.4.44.0311141348060.15094-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0311141348060.15094-100000@reclus.nhh.no>
Message-ID: <x2u157jd8x.fsf@biostat.ku.dk>

Roger Bivand <Roger.Bivand at nhh.no> writes:

> > rlex$lengths[rlex$values]
>  [1] 1 3 2 5 1 4 1 1 1 3 1 1 2
> > cetnost
>  [1] 1 3 2 5 1 4 1 1 1 3 1 1 2
> 
> rle() is interpreted too, like your solution, so I'm not sure how it will 
> scale.

Not spectacularly better, but I don't think Peter is doing what he
thinks he's doing...

> > 
> > Example 2
> > x<-sample(c(T,F),40321*51, replace=T)
> > dd<-matrix(x,40321,51)
> > system.time(cetnost <- lapply(dd,function(x) as.numeric(table(which(x)-
> > cumsum(x[which(x)])))))
> > Timing stopped at: 750.63 1 775.6 NA NA 

dd is not a list or data frame, so lapply is doing something for each
of the 2 million cells. Was this intended instead:

> system.time(cetnost <- apply(dd,2,function(x) as.numeric(table(which(x)-
+ cumsum(x[which(x)])))))
[1]  8.45  0.10 13.84  0.00  0.00

rle() helps a bit but not orders of magnitude:

> system.time(cetnost <- apply(dd,2,function(x) ((z <- rle(x))$lengths)[z$values]))
[1] 2.88 0.03 5.32 0.00 0.00

(This problem has a memory foot print of more than 200MB, so total
timings vary wildly depending on whether swapping occurs.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Fri Nov 14 14:38:26 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Nov 2003 07:38:26 -0600
Subject: [R] Installing packages
In-Reply-To: <x2d6bvkwoh.fsf@biostat.ku.dk>
References: <C9274C2F-1605-11D8-B8E6-000393B3E9D0@bigpace.med.utah.edu>
	<1068765553.10114.38.camel@localhost.localdomain>
	<x2d6bvkwoh.fsf@biostat.ku.dk>
Message-ID: <1068817105.10114.210.camel@localhost.localdomain>

On Fri, 2003-11-14 at 05:37, Peter Dalgaard wrote:
> Marc Schwartz <MSchwartz at medanalytics.com> writes:
> 
> > On Thu, 2003-11-13 at 12:18, Nathan Leon Pace, MD, MStat wrote:
> > > Running under Redhat 7.3 Linux I have installed R Version 1.8.0  
> > > (2003-10-08) from a binary download using the rpm manager.
> > > 
> > > Using packageStatus(), I am attempted to upgrade several packages.
> > > 
> > > This is unsuccessful with the following error messages:
> > > 
> > > * Installing *source* package 'MASS' ...
> > > ** libs
> > > gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
> > > -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c MASS.c -o MASS.o
> > > gcc: installation problem, cannot exec `cpp0': No such file or directory
> > > make: *** [MASS.o] Error 1
> > > ERROR: compilation failed for package 'MASS'
> > > 
> > > gcc version 2.96 20000731 (Red Hat Linux 7.3 2.96-113) is installed.
> > > 
> > > I have checked the R archives and FAQ and admin manual for help.
> > > 
> > > My knowledge of c compiling is limited.
> > > 
> > > Any pointers for debugging this problem would be appreciated.
> > > 
> > > Nathan
> > 
> > 
> > Not sure if you have received any other replies yet, but it appears that
> > you may be getting bitten by the infamous Red Hat 7.x gcc 2.96 problem.
> > Without getting into details, this is a known issue with this version of
> > gcc that was improperly released by RH.
> > 
> > The "official" note on this issue from gnu.org is here:
> > 
> > http://gcc.gnu.org/gcc-2.96.html
> > 
> > To my knowledge RH released updates to that version, but I believe that
> > the only "real" fix is to either revert to gcc 2.95.x or upgrade to a
> > version 3.x series release.
> > 
> > Martyn Plummer, the RH maintainer for R may have more detailed
> > information on this and I am cc'ing him on this reply.
> 
> Hmm, the symptoms don't quite usually look like that, and most of them
> got fixed in the 2.96-N releases where N was somewhere in the 80's
> IIRC. This claims to be an installation error where the preprocessor
> cpp0 is not found, so my first try would be to go look for it, i.e. (on
> RH8)
> 
> $ locate cpp0
> /usr/lib/gcc-lib/i386-redhat-linux/3.2/tradcpp0
> /usr/lib/gcc-lib/i386-redhat-linux/3.2/cpp0
> 
> It seems to live in the cpp package, 
> 
> $ rpm -qf /usr/lib/gcc-lib/i386-redhat-linux/3.2/cpp0
> cpp-3.2-7
> 
> so 
> 
> rpm -V cpp
> 
> should help you check your installation.


Peter,

Thanks for your comments on this. 

In checking at RH for 2.96 update announcements, I believe this one:

https://rhn.redhat.com/errata/RHBA-2002-200.html

is the most recent, which would suggest that the 2.96-113 series of RPMS
is the latest for that version.

Perhaps the first step toward resolution would be to check the
installation of cpp as you suggest.

If that shows any problems, starting with [re]installing the
cpp-2.96-113.i386.rpm from the above site would make sense and if that
does not work or has errors, then re-installing all 9 RPMS under the RH
7.3/i386 section on that page, would be a next step.

Marc



From p.dalgaard at biostat.ku.dk  Fri Nov 14 14:53:57 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Nov 2003 14:53:57 +0100
Subject: [R] Vector indices and minus sign
In-Reply-To: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>
References: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>
Message-ID: <x2ptfvjbt6.fsf@biostat.ku.dk>

David Orme <d.orme at imperial.ac.uk> writes:

> Hi,
> 
> I got caught out by this behaviour in 1.8.0 and I wondered why this
> happens:
> 
> I have a list of vectors and was using lapply and grep to remove
> matched elements that occur in only a subset of the elements of the
> list:
> 	locs <- lapply(locs, function(x){x[- grep("^x", x)]})
> 
> The problem is that where the grep finds no matches and hence returns
> a vector of length 0, all the elements of x were removed, rather than
> none. As a toy example:
> 
> vect <- 1:10
> vect[-5]
> index <- 5
> vect[-index]
> index <- numeric()
> vect[-index] # I was expecting this to give all the elements of vect
> rather than an empty vector
> vect[index] # does the same thing

...which is the point: -index is just as empty as index and indexing
by an empty vector gives you nothing. Probably the most convenient way
out is

ix <- 1:10
found <- numeric()
vect(!(ix %in% found))

or maybe (I suspect more efficient)

sel <- rep(T,10)
found <- numeric()
sel[found] <- FALSE
x[sel]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tblackw at umich.edu  Fri Nov 14 14:47:37 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 14 Nov 2003 08:47:37 -0500 (EST)
Subject: [R] Vector indices and minus sign
In-Reply-To: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>
References: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>
Message-ID: <Pine.SOL.4.58.0311140841200.6802@rygar.gpcc.itd.umich.edu>

David  -

I had to try your example verbatim before I understood what is
happening.  index <- numeric() creates a vector with no entries.
Therefore the subscript is neither positive or negative, rather
it contains no numeric values, so the return contains no entries
either.  Works the same in R-1.7.1 (which I am still running).

Not sure whether they will be equivalent to what your  grep()
construct is doing, but take a look at  help("unique"),
help(duplicated).  I use those all the time.

-  tom blackwell  -  u michigna medical school  -  ann arbor  -

On Fri, 14 Nov 2003, David Orme wrote:

> Hi,
>
> I got caught out by this behaviour in 1.8.0 and I wondered why this
> happens:
>
> I have a list of vectors and was using lapply and grep to remove
> matched elements that occur in only a subset of the elements of the
> list:
> 	locs <- lapply(locs, function(x){x[- grep("^x", x)]})
>
> The problem is that where the grep finds no matches and hence returns a
> vector of length 0, all the elements of x were removed, rather than
> none. As a toy example:
>
> vect <- 1:10
> vect[-5]
> index <- 5
> vect[-index]
> index <- numeric()
> vect[-index] # I was expecting this to give all the elements of vect
> rather than an empty vector
> vect[index] # does the same thing
>
> Thanks,
> David
>



From p.dalgaard at biostat.ku.dk  Fri Nov 14 14:55:58 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Nov 2003 14:55:58 +0100
Subject: [R] bad performance of a function
In-Reply-To: <x2u157jd8x.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0311141348060.15094-100000@reclus.nhh.no>
	<x2u157jd8x.fsf@biostat.ku.dk>
Message-ID: <x2llqjjbpt.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> Roger Bivand <Roger.Bivand at nhh.no> writes:
> 
> > > rlex$lengths[rlex$values]
> >  [1] 1 3 2 5 1 4 1 1 1 3 1 1 2
> > > cetnost
> >  [1] 1 3 2 5 1 4 1 1 1 3 1 1 2
> > 
> > rle() is interpreted too, like your solution, so I'm not sure how it will 
> > scale.
> 
> Not spectacularly better, but I don't think Peter is doing what he
> thinks he's doing...

Argh. Petr, not Peter....
 
> > > 
> > > Example 2
> > > x<-sample(c(T,F),40321*51, replace=T)
> > > dd<-matrix(x,40321,51)
> > > system.time(cetnost <- lapply(dd,function(x) as.numeric(table(which(x)-
> > > cumsum(x[which(x)])))))
> > > Timing stopped at: 750.63 1 775.6 NA NA 
> 
> dd is not a list or data frame, so lapply is doing something for each
> of the 2 million cells. Was this intended instead:
> 
> > system.time(cetnost <- apply(dd,2,function(x) as.numeric(table(which(x)-
> + cumsum(x[which(x)])))))
> [1]  8.45  0.10 13.84  0.00  0.00
> 
> rle() helps a bit but not orders of magnitude:
> 
> > system.time(cetnost <- apply(dd,2,function(x) ((z <- rle(x))$lengths)[z$values]))
> [1] 2.88 0.03 5.32 0.00 0.00
> 
> (This problem has a memory foot print of more than 200MB, so total
> timings vary wildly depending on whether swapping occurs.)
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From maechler at stat.math.ethz.ch  Fri Nov 14 14:57:31 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 14 Nov 2003 14:57:31 +0100
Subject: Reading R's base code {was [R] xlims of barplot}
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0E95@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572AC0E95@synequanon01>
Message-ID: <16308.57163.176107.319038@gargle.gargle.HOWL>

>>>>> "Simon" == Simon Fear <Simon.Fear at synequanon.com>
>>>>>     on Thu, 13 Nov 2003 09:53:17 -0000 writes:

    Simon> I'd recommend you read the code for barplot (it's all
    Simon> in R; just type barplot.default at the prompt) then
    Simon> emulate the xlim calculation prior to starting your
    Simon> series of plots, calling each plot with the same
    Simon> xlim.

    Simon> Reading the base package coding is always VERY
    Simon> instructive.  Takes time, but it's worth it.

and Paul confirmed this was useful advice.

Just one general remark: Many users know that it is useful to
look at function definitions that way.  Less and less users
however seem to be aware that this is *NOT* the source code in a
strict sense.
One important difference is that the source code *does* have
comments that you'll never see for base package functions if you
just inspect their value.

While there is 
options(keep.source      = TRUE)  ## per default
options(keep.source.pkgs = FALSE) ## per default

these do not influence the base package code.
If you compile R from the source, then the base package source
is in the many     <R_SRC_HOME/src/library/base/R/*.R  files.  
Otherwise, you can still see the source __including__ comments
by inspecting the (about 1 MB large) file

> system.file("R","base")

which has all the definitions concatenated into one file.

For other packages than base, you might
1) consider setting
  > options(keep.source.pkgs = TRUE) 
  in your Rprofile {which will need more memory and time to load packages !!!},
2) or inspect the contents of, e.g.
  > system.file("R", "splines", package = "splines")
  for the splines package.
3) or (as I do) work with the real source in <sourcepackage>/R/*.R.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From vincent.vicaire at libertysurf.fr  Fri Nov 14 15:02:31 2003
From: vincent.vicaire at libertysurf.fr (=?iso-8859-1?Q?vincent.vicaire@libertysurf.fr?=)
Date: Fri, 14 Nov 2003 15:02:31 +0100
Subject: [R] What goodness-of-fit measure for robust regression ?
Message-ID: <HOCHO7$0F31CCB47373E857DA5DE2FC26EA43A7@tiscali.fr>

Hi,


i. After estimating some coefficients using robust regression with rlm() or lqs(), I wonder if there exist some measures of the goodness-of-fit as those for standard linear model(R2)... or evenly if it's a statistics non-sense to look for since I do not find any mention of that in differents chapters on robust and resistant regression or in severals R documentation (Fox, Ripley and Venables)?

ii.If such measure exist for robust regression, how could I implement it in R, and what about their comparability with traditionnal R2 of linear model ?

Best regards
A lot of thank to anyone that could give me some light.

Vincent

********** L'ADSL A 20 EUR/MOIS********** 
Avec Tiscali, l'ADSL est ? 20 EUR/mois. Vous pourrez chercher longtemps avant de trouver moins cher ! 
Pour profiter de cette offre exceptionnelle, cliquez ici : http://register.tiscali.fr/adsl/
Offre soumise ? conditions.



From karlknoblich at yahoo.de  Fri Nov 14 15:07:31 2003
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Fri, 14 Nov 2003 15:07:31 +0100 (CET)
Subject: [R] LOCF - Last Observation Carried Forward
Message-ID: <20031114140731.93361.qmail@web10010.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/aae7933c/attachment.pl

From hodgess at gator.uhd.edu  Fri Nov 14 15:14:39 2003
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Fri, 14 Nov 2003 08:14:39 -0600
Subject: [R] Expressions and Functions
Message-ID: <200311141414.hAEEEdA13872@gator.dt.uh.edu>

Dear R People:

When the D function is used for a symbolic derivative,
an expression is returned, which is fine.

How do you change that expression to a function, please?

I've been experimenting with substitute and deparse, but no success
yet.

This is R 1.8.0 for Windows.

thanks in advance for the help!

Sincerely,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From andy_liaw at merck.com  Fri Nov 14 15:10:56 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 Nov 2003 09:10:56 -0500
Subject: [R] R CMD check problems
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE31@usrymx25.merck.com>

In the directory where you ran the check, you should have a subdirectory
like pkg.Rcheck (substitute "pkg" with the name of your package).  That's
where the package got installed for the purpose of the check.  You could try
to source() the files there and see if you can find the problem.

HTH,
Andy

> From: Joerg Schaber [mailto:Joerg.Schaber at uv.es] 
> Hi,
> 
> I am trying to create a R-package. When I load my R source 
> files using 
> source() for debugging reasons everthing works fine and all function 
> also do want they are supposed to do. However, when I run 'R 
> CMD check' 
> it stop with
> * checking R files for syntax errors ... ERROR
> Syntax error in file
> 
> Is there a way to further investigate where the error is?
> 
> greetings,
> 
> joerg
>



From aurora at ebi.ac.uk  Fri Nov 14 15:22:55 2003
From: aurora at ebi.ac.uk (Aurora Torrente)
Date: Fri, 14 Nov 2003 14:22:55 +0000
Subject: [R] Round error?
Message-ID: <3FB4E53F.7040809@ebi.ac.uk>

Hi all,

I have tried to compute a p-value for a hypergeometric distribution as:

dhyper(x,k,l,n) + phyper(x,k,l,n,lower.tail=FALSE)

and sometimes obtained negative values.  Do you know if it is because a 
round error or am I doing something wrong?

Thanks in advance,

        Aurora



From jmacdon at med.umich.edu  Fri Nov 14 15:28:52 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Fri, 14 Nov 2003 09:28:52 -0500
Subject: [R] Problem with parser and if/else
Message-ID: <sfb4a06e.010@med-gwia-01a.med.umich.edu>

> I'm trying to grasp this: if you're saying (or are you saying) that
the 
> only way to have if() know that an else will be present is to put it
on the 
> same line as the closing curly brace of the if() (compound)
statement. But 
> if I look at some code from, e.g., aov and lm, I see plenty
violations of 
> that rule.

There are no violations to that rule in either lm or aov. It simply
looks that way if you type lm or aov from within R. If you looked at the
functions themselves using an editor, you would see that they all
conform to 

if{
...
}else{
...
}

> regards,
> Paul


Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623



From bates at stat.wisc.edu  Fri Nov 14 15:31:41 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 14 Nov 2003 08:31:41 -0600
Subject: [R] Expressions and Functions
In-Reply-To: <200311141414.hAEEEdA13872@gator.dt.uh.edu>
References: <200311141414.hAEEEdA13872@gator.dt.uh.edu>
Message-ID: <6ru157owc2.fsf@bates4.stat.wisc.edu>

Would it work to use deriv with the optional function.arg argument?

In some ways deriv is just a wrapper around repeated calls to D. (It
does a bit more than that but you could think of it that way.)

Erin Hodgess <hodgess at gator.uhd.edu> writes:

> Dear R People:
> 
> When the D function is used for a symbolic derivative,
> an expression is returned, which is fine.
> 
> How do you change that expression to a function, please?
> 
> I've been experimenting with substitute and deparse, but no success
> yet.
> 
> This is R 1.8.0 for Windows.
> 
> thanks in advance for the help!
> 
> Sincerely,
> Erin Hodgess
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From jmacdon at med.umich.edu  Fri Nov 14 15:45:22 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Fri, 14 Nov 2003 09:45:22 -0500
Subject: [R] Round error?
Message-ID: <sfb4a445.039@med-gwia-01a.med.umich.edu>

You are doing something wrong.The p-value should be calculated using
phyper alone.

HTH,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Aurora Torrente <aurora at ebi.ac.uk> 11/14/03 09:22AM >>>
Hi all,

I have tried to compute a p-value for a hypergeometric distribution
as:

dhyper(x,k,l,n) + phyper(x,k,l,n,lower.tail=FALSE)

and sometimes obtained negative values.  Do you know if it is because a

round error or am I doing something wrong?

Thanks in advance,

        Aurora

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Fri Nov 14 15:46:20 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 Nov 2003 09:46:20 -0500
Subject: [R] Expressions and Functions
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE32@usrymx25.merck.com>

You should be able to use deriv(..., func=TRUE) to get a function returned,
instead of an expression.

If you need to use D, here's a rather clumsy way that seems to work:

> dx2x <- D(expression(x^2), name="x"); dx2x
2 * x
> eval(parse(text=paste("f <- function(x){",
                        paste(deparse(dx2x), collapse=";"), "}")))
> f
function(x){ 2 * x }

HTH,
Andy

> From: Erin Hodgess [mailto:hodgess at gator.uhd.edu] 
> 
> Dear R People:
> 
> When the D function is used for a symbolic derivative,
> an expression is returned, which is fine.
> 
> How do you change that expression to a function, please?
> 
> I've been experimenting with substitute and deparse, but no 
> success yet.
> 
> This is R 1.8.0 for Windows.
> 
> thanks in advance for the help!
> 
> Sincerely,
> Erin Hodgess
> mailto: hodgess at gator.uhd.edu



From Simon.Fear at synequanon.com  Fri Nov 14 15:47:42 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 14 Nov 2003 14:47:42 -0000
Subject: [R] ISOdate() and strptime()
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0E9D@synequanon01>

People who don't like this behaviour (and particularly those
who dislike it as much as I do), should consider as.date() from 
the dates package as an alternative. Gives you a NA if the
specified date is impossible (at least in all the examples given 
earlier).

Is the behaviour of ISOtime() and strptime() determined by ISO
or POSIX standard? Seems not to fit R's "no nannying" policy
at all. Or maybe it's the future: in version 1.9 will I be able to
type glm() and have R take a best guess at the model 
specification I had in mind? 

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]

> Expect to get the best guess at what you intended, and expect this to 
> depend on your OS.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From ggrothendieck at myway.com  Fri Nov 14 15:54:18 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 Nov 2003 09:54:18 -0500 (EST)
Subject: [R] Vector indices and minus sign
Message-ID: <20031114145418.2CC5339AA@mprdmxin.myway.com>


Just append the search string to the end of the target string,
i.e. x <- c(x,"x") so that it always matches something:

> my.list <- list(letters,LETTERS)
> lapply(my.list, function(x){x <- c(x,"x"); x[- grep("^x", x)]})
[[1]]
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q" "r" "s"
[20] "t" "u" "v" "w" "y" "z"

[[2]]
 [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S"
[20] "T" "U" "V" "W" "X" "Y" "Z"


--- 
Date: Fri, 14 Nov 2003 13:16:24 +0000 
From: David Orme <d.orme at imperial.ac.uk>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Vector indices and minus sign 

 
 
Hi,

I got caught out by this behaviour in 1.8.0 and I wondered why this 
happens:

I have a list of vectors and was using lapply and grep to remove 
matched elements that occur in only a subset of the elements of the 
list:
     locs <- lapply(locs, function(x){x[- grep("^x", x)]})

The problem is that where the grep finds no matches and hence returns a 
vector of length 0, all the elements of x were removed, rather than 
none. As a toy example:

vect <- 1:10
vect[-5]
index <- 5
vect[-index]
index <- numeric()
vect[-index] # I was expecting this to give all the elements of vect 
rather than an empty vector
vect[index] # does the same thing


Thanks,
David



From rpeng at jhsph.edu  Fri Nov 14 15:53:27 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 14 Nov 2003 09:53:27 -0500
Subject: [R] Expressions and Functions
In-Reply-To: <200311141414.hAEEEdA13872@gator.dt.uh.edu>
References: <200311141414.hAEEEdA13872@gator.dt.uh.edu>
Message-ID: <3FB4EC67.9090109@jhsph.edu>

I can think of 2 ways:

f <- function(x) { }
body(f) <- D(expression(log(x)), "x")

Or maybe

g <- deriv(expression(log(x)), "x", function.arg = TRUE)
f <- function(x) { attr(g(x), "gradient") }

Or something along those lines.

-roger

Erin Hodgess wrote:
> Dear R People:
> 
> When the D function is used for a symbolic derivative,
> an expression is returned, which is fine.
> 
> How do you change that expression to a function, please?
> 
> I've been experimenting with substitute and deparse, but no success
> yet.
> 
> This is R 1.8.0 for Windows.
> 
> thanks in advance for the help!
> 
> Sincerely,
> Erin Hodgess
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Fri Nov 14 16:04:55 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Nov 2003 16:04:55 +0100
Subject: [R] Round error?
In-Reply-To: <3FB4E53F.7040809@ebi.ac.uk>
References: <3FB4E53F.7040809@ebi.ac.uk>
Message-ID: <x2znezhtyg.fsf@biostat.ku.dk>

Aurora Torrente <aurora at ebi.ac.uk> writes:

> Hi all,
> 
> I have tried to compute a p-value for a hypergeometric distribution as:
> 
> dhyper(x,k,l,n) + phyper(x,k,l,n,lower.tail=FALSE)
> 
> and sometimes obtained negative values.  Do you know if it is because
> a round error or am I doing something wrong?

Could you give us specific x,k,l,n where this happens, please. It
sounds like it shouldn't happen.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Nov 14 16:13:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Nov 2003 15:13:00 +0000 (GMT)
Subject: [R] Expressions and Functions
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE32@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0311141508450.25449-100000@gannet.stats>

On Fri, 14 Nov 2003, Liaw, Andy wrote:

> You should be able to use deriv(..., func=TRUE) to get a function returned,
> instead of an expression.
> 
> If you need to use D, here's a rather clumsy way that seems to work:
> 
> > dx2x <- D(expression(x^2), name="x"); dx2x
> 2 * x
> > eval(parse(text=paste("f <- function(x){",
>                         paste(deparse(dx2x), collapse=";"), "}")))
> > f
> function(x){ 2 * x }

I would have used

f <- function(x) {}
body(f) <- D(expression(x^2), name="x")

> 
> HTH,
> Andy
> 
> > From: Erin Hodgess [mailto:hodgess at gator.uhd.edu] 
> > 
> > Dear R People:
> > 
> > When the D function is used for a symbolic derivative,
> > an expression is returned, which is fine.
> > 
> > How do you change that expression to a function, please?
> > 
> > I've been experimenting with substitute and deparse, but no 
> > success yet.
> > 
> > This is R 1.8.0 for Windows.
> > 
> > thanks in advance for the help!
> > 
> > Sincerely,
> > Erin Hodgess
> > mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Fri Nov 14 16:20:29 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Nov 2003 07:20:29 -0800 (PST)
Subject: [R] ISOdate() and strptime()
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0E9D@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572AC0E9D@synequanon01>
Message-ID: <Pine.A41.4.58.0311140718030.62532@homer06.u.washington.edu>

On Fri, 14 Nov 2003, Simon Fear wrote:
>
> Is the behaviour of ISOtime() and strptime() determined by ISO
> or POSIX standard? Seems not to fit R's "no nannying" policy
> at all. Or maybe it's the future: in version 1.9 will I be able to
> type glm() and have R take a best guess at the model
> specification I had in mind?
>

It's determined by your operating system, so you're complaining to the
wrong people.

R does not have enough information to work out time zones and daylight
saving itself --it has to rely on the OS. as.date doesn't have this
problem because it works only with whole days.


	-thomas



From GPetris at uark.edu  Fri Nov 14 16:14:47 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 14 Nov 2003 09:14:47 -0600 (CST)
Subject: [R] calculating arc length using R?
In-Reply-To: <m21xsbk745.fsf@resume.itd.nrl.navy.mil> (message from Greg
	Trafton on Thu, 13 Nov 2003 21:37:46 -0500)
References: <1dc6c71dc2a4.1dc2a41dc6c7@ono.com>
	<m21xsbk745.fsf@resume.itd.nrl.navy.mil>
Message-ID: <200311141514.hAEFElsU017900@definetti.uark.edu>


It seems you want to integrate a function. Try

?integrate

You can do the math yourself if the function is simple, like sin(x). 
Otherwise I suspect you could combine integrate with `deriv', although
you will slow down the calculations somehow (just a guess).

HTH
Giovanni  

> Date: Thu, 13 Nov 2003 21:37:46 -0500
> From: Greg Trafton <trafton at itd.nrl.navy.mil>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> User-Agent: Gnus/5.1002 (Gnus v5.10.2) Emacs/21.2 (darwin)
> 
> Hi, All.  I have a function I want to know the plotted length of.  is it
> possible to calculate the length of the function (e.g., arc length)?
> 
> for example, if I want to know the length of the line of
> sin(x) from -pi to pi, how can I do that in R?
> 
> thanks!
> greg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From tlumley at u.washington.edu  Fri Nov 14 16:24:28 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Nov 2003 07:24:28 -0800 (PST)
Subject: [R] Problem with parser and if/else
In-Reply-To: <sfb4a06e.010@med-gwia-01a.med.umich.edu>
References: <sfb4a06e.010@med-gwia-01a.med.umich.edu>
Message-ID: <Pine.A41.4.58.0311140721190.62532@homer06.u.washington.edu>

On Fri, 14 Nov 2003, James MacDonald wrote:

>
> There are no violations to that rule in either lm or aov. It simply
> looks that way if you type lm or aov from within R. If you looked at the
> functions themselves using an editor, you would see that they all
> conform to
>
> if{
> ...
> }else{
> ...
> }
>

This turns out not to be the case. Looking for example at
lm() in src/library/base/R/lm.R

    if (is.empty.model(mt)) {
        x <- NULL
        z <- list(coefficients = numeric(0), residuals = y,
                  fitted.values = 0 * y, weights = w, rank = 0,
                  df.residual = length(y))
        if(!is.null(offset)) z$fitted.values <- offset
    }
    else {
        x <- model.matrix(mt, mf, contrasts)
        z <- if(is.null(w)) lm.fit(x, y, offset = offset,
                                   singular.ok=singular.ok, ...)
        else lm.wfit(x, y, w, offset = offset, singular.ok=singular.ok,
...)
    }


The *real* rule is that the } of the if() must not produce a syntactically
complete statement, so else on a separate line is ok inside functions.

I still tend to write } else {, but I'm sure it annoys some people.


	-thomas



From tlumley at u.washington.edu  Fri Nov 14 16:26:00 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Nov 2003 07:26:00 -0800 (PST)
Subject: [R] Vector indices and minus sign
In-Reply-To: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>
References: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>
Message-ID: <Pine.A41.4.58.0311140724390.62532@homer06.u.washington.edu>

On Fri, 14 Nov 2003, David Orme wrote:

> Hi,
>
> I got caught out by this behaviour in 1.8.0 and I wondered why this
> happens:
>

Some anomaly of this sort is unavoidable because R allows positive or
negative numeric indices. It can't distinguish between a vector of no
positive numbers and a vector of no negative numbers.

	-thomas



From pburns at pburns.seanet.com  Fri Nov 14 14:27:49 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 14 Nov 2003 13:27:49 +0000
Subject: [R] Vector indices and minus sign
References: <BF5CFBF8-16A4-11D8-8322-000393DC1748@ic.ac.uk>
Message-ID: <3FB4D855.8050406@pburns.seanet.com>

S Poetry, page 72.

If there is nothing there, then R can't know that
you want the nothing to be negative.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

David Orme wrote:

> Hi,
>
> I got caught out by this behaviour in 1.8.0 and I wondered why this 
> happens:
>
> I have a list of vectors and was using lapply and grep to remove 
> matched elements that occur in only a subset of the elements of the list:
>     locs <- lapply(locs, function(x){x[- grep("^x", x)]})
>
> The problem is that where the grep finds no matches and hence returns 
> a vector of length 0, all the elements of x were removed, rather than 
> none. As a toy example:
>
> vect <- 1:10
> vect[-5]
> index <- 5
> vect[-index]
> index <- numeric()
> vect[-index] # I was expecting this to give all the elements of vect 
> rather than an empty vector
> vect[index] # does the same thing
>
>
> Thanks,
> David
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From bwheeler at echip.com  Fri Nov 14 16:26:13 2003
From: bwheeler at echip.com (Bob Wheeler)
Date: Fri, 14 Nov 2003 10:26:13 -0500
Subject: [R] Round error?
References: <3FB4E53F.7040809@ebi.ac.uk> <x2znezhtyg.fsf@biostat.ku.dk>
Message-ID: <3FB4F415.9080805@echip.com>

You might try pghyper() in the SuppDists package. It should give the 
same values for integer arguments.


Peter Dalgaard wrote:
> Aurora Torrente <aurora at ebi.ac.uk> writes:
> 
> 
>>Hi all,
>>
>>I have tried to compute a p-value for a hypergeometric distribution as:
>>
>>dhyper(x,k,l,n) + phyper(x,k,l,n,lower.tail=FALSE)
>>
>>and sometimes obtained negative values.  Do you know if it is because
>>a round error or am I doing something wrong?
> 
> 
> Could you give us specific x,k,l,n where this happens, please. It
> sounds like it shouldn't happen.
> 


-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From andy_liaw at merck.com  Fri Nov 14 16:52:08 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 Nov 2003 10:52:08 -0500
Subject: [R] What goodness-of-fit measure for robust regression ?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE37@usrymx25.merck.com>

This is at best on the order of a match light...

GOF and robust estimation seem to be answering rather conflicting questions.
GOF asks how well the model fit the data.  Robust methods say not to pay too
much attention to some "bad" data points.  How does one tell GOF which
subset of data to pay less attention to?

One possible question is that, with respect to the data that the robust
estimation procedure treated as "good", how good a fit is the linear model?
I do not know of any work on this.

Andy

> From: vincent.vicaire at libertysurf.fr 
> 
> Hi,
> 
> 
> i. After estimating some coefficients using robust regression 
> with rlm() or lqs(), I wonder if there exist some measures of 
> the goodness-of-fit as those for standard linear model(R2)... 
> or evenly if it's a statistics non-sense to look for since I 
> do not find any mention of that in differents chapters on 
> robust and resistant regression or in severals R 
> documentation (Fox, Ripley and Venables)?
> 
> ii.If such measure exist for robust regression, how could I 
> implement it in R, and what about their comparability with 
> traditionnal R2 of linear model ?
> 
> Best regards
> A lot of thank to anyone that could give me some light.
> 
> Vincent
> 
> ********** L'ADSL A 20 EUR/MOIS********** 
> Avec Tiscali, l'ADSL est ? 20 EUR/mois. Vous pourrez chercher 
> longtemps avant de trouver moins cher ! 
> Pour profiter de cette offre exceptionnelle, cliquez ici : 
http://register.tiscali.fr/adsl/ Offre soumise ? conditions.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From nikko at hailmail.net  Fri Nov 14 16:55:15 2003
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 14 Nov 2003 23:55:15 +0800
Subject: [R] Help wilth lme for repeted measures design
Message-ID: <20031114155515.892A13FCD0@server1.messagingengine.com>

Hi,
I am trying to figure out how to specify the model for a repeated
measures experiment using lme. I have the following structure for the
experiment:
There are 3 sites and at each site there are two depths, so site and
depth are crossed. At each site and depth there are 12 fragments of
Coral, each representing a seperate genotype, so genotype is crossed with
site and depth. On each coral fragment the size of 6 coralites is
measured so coralite is nested in fragment. Now in the model genotype
should be a random effect, and we are trying to measure the effect of
depth and site. So I fit the model
mod1<-lme(Factor1~Islands*Depths+Frags:Depths+Frags:Islands +
          Frags:Depths:Islands,dhfactan,random=~1|Frags/Corallites)

and

anova(mod1)
                     numDF denDF   F-value p-value
(Intercept)              1   289  0.000000  1.0000
Islands                  2   289  2.503565  0.0836
Depths                   1   289 10.022984  0.0017
Islands:Depths           2   289  3.772553  0.0241
Depths:Frags            22   289  7.970114  <.0001
Islands:Frags           22   289  7.806390  <.0001
Islands:Depths:Frags    22   289  6.554670  <.0001

Now I know I have done something wrong here becuase there seem to be far
too many degrees of freedom 
in the denominator. I am not sure if this is due to how I coded the data
frame or how I specified the model.
The data frame looks like

   Corallites Frags Islands Depths    Factor1
1           1     1       1      1  0.9476487
2           2     1       1      1  0.4810762
3           3     1       1      1 -0.2544952
4           4     1       1      1 -0.3711468
5           5     1       1      1 -1.0486175
6           6     1       1      1 -0.9323673
7           1     2       1      1  0.6410660
8           2     2       1      1  0.7590714
9           3     2       1      1  2.3403437
10          4     2       1      1  1.8750632
11          5     2       1      1  0.7945611
12          6     2       1      1  2.0533272

Where Factor1 is the response. Any advice is much appreciated.

Thanks
Nicholas



From smalladi at lexgen.com  Fri Nov 14 17:20:12 2003
From: smalladi at lexgen.com (Malladi, Sukhaswami)
Date: Fri, 14 Nov 2003 10:20:12 -0600
Subject: [R] stop further sourcing of an R file
Message-ID: <80A38867B1DBD511A8C9009027764C8C379EE1@lexchange.lexgen.com>

?stop

swami


*************************************************************************** 
 The contents of this communication are intended only for the addressee and
may contain confidential and/or privileged material. If you are not the
intended recipient, please do not read, copy, use or disclose this
communication and notify the sender.  Opinions, conclusions and other
information in this communication that do not relate to the official
business of my company shall be understood as neither given nor endorsed by
it.



From moracsa1 at zhwin.ch  Fri Nov 14 17:27:28 2003
From: moracsa1 at zhwin.ch (Morach Sascha, moracsa1)
Date: Fri, 14 Nov 2003 17:27:28 +0100
Subject: [R] R and RS232-Interface?
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B902945678@lobster.zhwin.ch>

Hi there

 

Does any one of you know something about R and an implemented RS232-Interface? Are there any packages? Or is it possible to write an extensions or something like that in C/C++ ?

The problem is that i should handle the information from a measuring device via the RS232-Interface (probably you know LabVIEW, which provides this functionality). These informations should then directly be handled by R.

Is this possible?

(I hope I found the right words, I?m swiss, J )

 

thanks

Sascha Morach, diplomastudent, ZHW



From Simon.Fear at synequanon.com  Fri Nov 14 17:28:03 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 14 Nov 2003 16:28:03 -0000
Subject: [R] LOCF - Last Observation Carried Forward
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0E9F@synequanon01>

I use this:

#
# change NAs to preceding values (initial NAs remain NAs)
# e.g.  NA  1 NA  2 NA NA  4 NA  3
# to    NA  1  1  2  2  2  4  4  3
"locf" <- function(x) {
  assign("stored.value", x[1], envir=.GlobalEnv)
  sapply(x, function(x) {
    if(is.na(x))
      stored.value
    else {
      assign("stored.value", x, envir=.GlobalEnv)
      x
    }})
}

That sets up "LOCF" within a vector, or could be applied to the
rows of your data frame:

df[ , <<numeric bits only>>] <- apply(df[ , <<numeric bits only>>], 2, locf)

I've got a feeling there would be a much neater way to code this
than the above (I wrote it first in Splus, hence the funny scoping control).

When  theres only one postbaseline timepoint, I tend to use this instead:

"set.nas.previous" <- function(x,previous) {
  if (is.numeric(x)) 
    x <- ifelse(is.na(x),previous,x)
  x
}

which is used like

df$locf <- set.nas.previous(df$postbaseline, df$baseline)

It's a bit of a dodgy function name really because there is no actual
test that "previous" is really previous.

HTH

Simon

PS use `subset` instead of `[`. Do what I say, not what I do.

> -----Original Message-----
> From: Karl Knoblick [mailto:karlknoblich at yahoo.de]
> Sent: 14 November 2003 14:08
> To: r-help at stat.math.ethz.ch
> Subject: [R] LOCF - Last Observation Carried Forward
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> Hi!
>  
> Is there a possibilty in R to carry out LOCF (Last 
> Observation Carried Forward) analysis or to create a new data 
> frame (array, matrix) with LOCF? Or some helpful functions, packages?
>  
> Karl
> 
> 
> 
> ---------------------------------
> Gesendet von http://mail.yahoo.de
> Schneller als Mail - der neue Yahoo! Messenger.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From andy_liaw at merck.com  Fri Nov 14 17:38:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 Nov 2003 11:38:03 -0500
Subject: [R] Vector indices and minus sign
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE3B@usrymx25.merck.com>

> From: Thomas Lumley [mailto:tlumley at u.washington.edu] 
> 
> On Fri, 14 Nov 2003, David Orme wrote:
> 
> > Hi,
> >
> > I got caught out by this behaviour in 1.8.0 and I wondered why this
> > happens:
> >
> 
> Some anomaly of this sort is unavoidable because R allows 
> positive or negative numeric indices. It can't distinguish 
> between a vector of no positive numbers and a vector of no 
> negative numbers.
> 
> 	-thomas

I guess this can only work if "-" is treated specially in the subset
operators, so that, e.g., x[-"Andy"] would also work.  (This would be nice,
IMHO.)

[A bit OT: I remembered that among the list of bugs fixed in Splus 3.2 for
Windows is -0 == 0 is F...]

Andy



From petr.pikal at precheza.cz  Fri Nov 14 17:42:41 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 14 Nov 2003 17:42:41 +0100
Subject: [R] bad performance of a function
In-Reply-To: <3FB4DA38.4484.394967@localhost>
Message-ID: <3FB51411.7816.11B5EA9@localhost>

Hallo

Thanks to all who responded (Patrick Burns, Roger Bivand and 
especially Peter Dalgaard). Do not know why I used lapply when 
apply made the task as well. My actuall data are in data frame 
(size as in example 2) and with apply rle() is about an order of 
magnitude quicker.

Thanks again

Petr


On 14 Nov 2003 at 13:35, Petr Pikal wrote:

> Dear all
> 
> I need to find a length of true sequences in logical vector (see
> example 1). I found a possible solution which is good but if I use it
> on a larger data set I experience a substantial decrease in
> performance (example 2).
> 
> Example 1
> set.seed(111)
> x <- sample(c(T,F),50, replace=T)
> system.time(cetnost <-
> as.numeric(table(which(x)-cumsum(x[which(x)])))) [1] 0.00 0.00 0.03  
> NA   NA cetnost [1] 1 3 2 5 1 4 1 1 1 3 1 1 2
> 
> Example 2
> x<-sample(c(T,F),40321*51, replace=T)
> dd<-matrix(x,40321,51)
> system.time(cetnost <- lapply(dd,function(x)
> as.numeric(table(which(x)- cumsum(x[which(x)]))))) Timing stopped at:
> 750.63 1 775.6 NA NA 
> 
> Please give me any hint how to improve performance or advice a
> different (but more effective) solution.
> 
> R 1.8.0, W2000,  512M memory, Pentium4
> 
> Thank you in advance.
> 
> 
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Petr Pikal
petr.pikal at precheza.cz



From MSchwartz at medanalytics.com  Fri Nov 14 18:00:01 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Nov 2003 11:00:01 -0600
Subject: [R] LOCF - Last Observation Carried Forward
Message-ID: <1068829200.4347.46.camel@localhost.localdomain>

karlknoblich at yahoo.de wrote:
> Hi!
>  
> Is there a possibilty in R to carry out LOCF (Last Observation Carried
> Forward) analysis or to create a new data frame (array, matrix) with
> LOCF? Or some helpful functions, packages?
>  
> Karl


As I understand the methodology and potential issues regarding the
imputation of data for the missing observations, I have a couple of
thoughts:

1. The missing observation data can be imputed where missing using
standard R data management functions. The complexity or lack of it will
likely depend upon your exact data structure. 

For example, if the missing values are all NA's, you can use
vector/matrix indexing to replace them based upon various conditions. If
the subsetting logic is more complex, you can use the replace()
function, which enables you to specify a complex boolean construct. See
?replace for more information.

If your data (x) is sequenced left to right in a time series vector, you
can identify the position of the last known observation for example:

> x <- c(23, 25, 24, NA, 25, NA, NA)
> max(which(!is.na(x)))
[1] 5

and fill to the right, repeating the last known data:

> LOCF <- max(which(!is.na(x)))
> x[LOCF:length(x)] <- x[LOCF]
> x
[1] 23 25 24 NA 25 25 25

A quick search on Google raises some known issues with the methodology
depending upon the nature of the missing data and what sort of
assumptions you are willing to make or live with. 

For more complex imptation, there are a variety of missing data
imputation functions available for R, for example in Frank Harrell's
Design and Hmisc packages on CRAN.


2. Another alternative to consider, depending upon how much missing data
you are dealing with and its etiology, would be an unbalanced mixed
effects approach using the model functions in package 'nlme'.  I might
defer to others here, but something to consider.

HTH,

Marc Schwartz



From tplate at acm.org  Fri Nov 14 18:20:17 2003
From: tplate at acm.org (Tony Plate)
Date: Fri, 14 Nov 2003 10:20:17 -0700
Subject: [R] LOCF - Last Observation Carried Forward
In-Reply-To: <20031114140731.93361.qmail@web10010.mail.yahoo.com>
Message-ID: <5.2.1.1.2.20031114100304.0408d620@mailhost.blackmesacapital.com>

Here's a function that does the essential computation (written to work in 
both S-plus and R).

This looks like one of those tricky problems that do not vectorize 
easily.  It would be simple to write a C-program to compute this very 
efficiently.  But are there any more efficient solutions than ones like the 
below (that are written without resort to C)?

most.recent <- function(x) {
     # return a vector of indices of the most recent TRUE value
     if (!is.logical(x))
         stop("x must be logical")
     x[is.na(x)] <- FALSE
     # x is a logical vector
     r <- rle(x)
     ends <- cumsum(r$lengths)
     starts <- ends - r$lengths + 1
     spec <- as.list(as.data.frame(rbind(start=starts, len=r$lengths, 
value=as.numeric(r$values), prev.end=c(NA, ends[-length(ends)]))))
     names(spec) <- NULL
     unlist(lapply(spec, function(s) if (s[3]) seq(s[1], len=s[2]) else 
rep(s[4], len=s[2])), use.names=F)
}

 > x <- c(F,T,T,F,F,F,T,F)
 > most.recent(x)
[1] NA  2  3  3  3  3  7  7

And using it to do the fill-forward:

 > x <- c(NA,2,3,NA,4,NA,5,NA,NA,NA,6,7,8,NA)
 > x[most.recent(!is.na(x))]
  [1] NA  2  3  3  4  4  5  5  5  5  6  7  8  8
 >

Some timings:

 > x <- sample(c(T,F),1e4,rep=T)
 > system.time(most.recent(x))
[1] 0.33 0.01 0.47   NA   NA
 > x <- sample(c(T,F),1e5,rep=T)
 > system.time(most.recent(x))
[1] 4.27 0.06 6.44   NA   NA
 > x <- sample(c(T,F),1e6,rep=T)
 > system.time(most.recent(x))
[1] 47.27  0.17 47.97    NA    NA
 >

-- Tony Plate

PS. Actually, I just found a solution that I had lying around that is about 
70 times as fast on random test data like the above.


At Friday 03:07 PM 11/14/2003 +0100, Karl Knoblick wrote:
>Hi!
>
>Is there a possibilty in R to carry out LOCF (Last Observation Carried 
>Forward) analysis or to create a new data frame (array, matrix) with LOCF? 
>Or some helpful functions, packages?
>
>Karl
>
>
>
>---------------------------------
>Gesendet von http://mail.yahoo.de
>Schneller als Mail - der neue Yahoo! Messenger.
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Tony Plate   tplate at acm.org



From ahenningsen at agric-econ.uni-kiel.de  Fri Nov 14 18:23:21 2003
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Fri, 14 Nov 2003 18:23:21 +0100
Subject: [R] assigning rownames
Message-ID: <200311141823.21452.ahenningsen@agric-econ.uni-kiel.de>

Hi!

I have got a variable, say
    myVar <- matrix( 1:6, 3, 2 )
and a variable that contains the name of the variable, say
   myVarName <- "myVar"
Now, I want to assign rownames to the Variable "myVar".
I can do it by 
   rownames( myVar ) <- c( "A", "B", "C" )
but for some reason I want "myVarName" as argument, e.g.
  rownames( ????( myVarName ) )  <- c( "A", "B", "C" )
How can I do this?

Thanks,
Arne

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From TAC at NEI.NIH.GOV  Fri Nov 14 18:26:23 2003
From: TAC at NEI.NIH.GOV (Cox, Terry (NIH/NEI))
Date: Fri, 14 Nov 2003 12:26:23 -0500
Subject: [R] R user group at NIH
Message-ID: <C22C76D2A47CF24DA972C1963DC1A833079970AF@nihexchange1.nih.gov>

I am interested in starting an R User Group at the National Institutes of
Health in Bethesda, Maryland. I would appreciate any comments or
suggestions. I would especially like to hear from any NIHers who might be
interested.

TAC

----------------------------------------------
Terry A. Cox, MD, PhD
Division of Epidemiology and Clinical Research
National Eye Institute 

National Institutes of Health 
31 Center Drive, MSC 2510 
Building 31, Room 6A52 
Bethesda, MD 20892-2510

Phone: 301-496-6583 
FAX:   301-496-2297



From pburns at pburns.seanet.com  Fri Nov 14 18:06:00 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 14 Nov 2003 17:06:00 +0000
Subject: [R] Vector indices and minus sign
References: <3A822319EB35174CA3714066D590DCD50205CE3B@usrymx25.merck.com>
Message-ID: <3FB50B78.5070105@pburns.seanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/482e3cec/attachment.pl

From rvaradha at jhsph.edu  Fri Nov 14 18:42:50 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri, 14 Nov 2003 12:42:50 -0500
Subject: [R] calculating arc length using R?
Message-ID: <5c316d5c6f52.5c6f525c316d@jhsph.edu>

Hi:

If your curve is in a 2-dim plane, then you can use the following 
formula (in Tex notation):

\int_a^b \sqrt{1 + (\frac{df}{dx})^2} dx

So you need to take the derivative of your function first, and then 
compute the integral of (1 + deriv^2) from a to b.

Here is a simple code to find the arclength of the curve: sin(x), 
between -pi and pi.
##########################
arclen <- function(gexp, a, b) {
g <- function(x) { }
body(g) <- D(gexp, "x")
farc <- function(x) sqrt(1 + g(x)^2)
integrate(farc,low=a,upp=b)$val
}

gexp <- expression(sin(x))
arclen(gexp,-pi,pi)
###########################

Best,
Ravi.

----- Original Message -----
From: Greg Trafton <trafton at itd.nrl.navy.mil>
Date: Thursday, November 13, 2003 9:37 pm
Subject: [R] calculating arc length using R?

> Hi, All.  I have a function I want to know the plotted length of.  
> is it
> possible to calculate the length of the function (e.g., arc length)?
> 
> for example, if I want to know the length of the line of
> sin(x) from -pi to pi, how can I do that in R?
> 
> thanks!
> greg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rvaradha at jhsph.edu  Fri Nov 14 18:44:17 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri, 14 Nov 2003 12:44:17 -0500
Subject: [R] calculating arc length using R?
Message-ID: <5c7fb75c5181.5c51815c7fb7@jhsph.edu>

Hi:

If your curve is in a 2-dim plane, then you can use the following 
formula (in Tex notation):

\int_a^b \sqrt{1 + (\frac{df}{dx})^2} dx

So you need to take the derivative of your function first, and then 
compute the integral of sqrt(1 + deriv^2) from a to b.

Here is a simple code to find the arclength of the curve: sin(x), 
between -pi and pi.
##########################
arclen <- function(gexp, a, b) {
g <- function(x) { }
body(g) <- D(gexp, "x")
farc <- function(x) sqrt(1 + g(x)^2)
integrate(farc,low=a,upp=b)$val
}

gexp <- expression(sin(x))
arclen(gexp,-pi,pi)
###########################

Best,
Ravi.



----- Original Message -----
From: Greg Trafton <trafton at itd.nrl.navy.mil>
Date: Thursday, November 13, 2003 9:37 pm
Subject: [R] calculating arc length using R?

> Hi, All.  I have a function I want to know the plotted length of.  
> is it
> possible to calculate the length of the function (e.g., arc length)?
> 
> for example, if I want to know the length of the line of
> sin(x) from -pi to pi, how can I do that in R?
> 
> thanks!
> greg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From JLCAVIGLIA-HARRIS at salisbury.edu  Fri Nov 14 19:01:44 2003
From: JLCAVIGLIA-HARRIS at salisbury.edu (Jill Caviglia-Harris)
Date: Fri, 14 Nov 2003 13:01:44 -0500
Subject: [R] spatial modeling
Message-ID: <sfb4d23a.012@mail2.salisbury.edu>

I am new to R and have a question about spatial econometrics.  I have
noticed that you can easily test for spatial autocorrelation with the
spdep package, but was wondering if any code has been written to correct
for spatial autocorrelation?   Or if there is any literature on this?

Thanks.  -Jill

***************************************************
Jill L. Caviglia-Harris, Ph.D.
Assistant Professor
Economics and Finance Department
Salisbury University
Salisbury, MD 21801-6860
   phone: (410) 548-5591
   fax: (410) 546-6208



From andy_liaw at merck.com  Fri Nov 14 19:05:39 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 Nov 2003 13:05:39 -0500
Subject: [R] Vector indices and minus sign
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE3F@usrymx25.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/42fa2c49/attachment.pl

From tplate at acm.org  Fri Nov 14 19:31:06 2003
From: tplate at acm.org (Tony Plate)
Date: Fri, 14 Nov 2003 11:31:06 -0700
Subject: [R] assigning rownames
In-Reply-To: <200311141823.21452.ahenningsen@agric-econ.uni-kiel.de>
Message-ID: <5.2.1.1.2.20031114113046.04088528@mailhost.blackmesacapital.com>

 > myVar <- matrix( 1:6, 3, 2 )
 > myVar
      [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
 > substitute(rownames(X) <- c("A", "B", "C"), list(X=as.name(myVarName)))
rownames(myVar) <- c("A", "B", "C")
 > eval(substitute(rownames(X) <- c("A", "B", "C"), 
list(X=as.name(myVarName))))
 > myVar
   [,1] [,2]
A    1    4
B    2    5
C    3    6
 >

At Friday 06:23 PM 11/14/2003 +0100, Arne Henningsen wrote:
>Hi!
>
>I have got a variable, say
>     myVar <- matrix( 1:6, 3, 2 )
>and a variable that contains the name of the variable, say
>    myVarName <- "myVar"
>Now, I want to assign rownames to the Variable "myVar".
>I can do it by
>    rownames( myVar ) <- c( "A", "B", "C" )
>but for some reason I want "myVarName" as argument, e.g.
>   rownames( ????( myVarName ) )  <- c( "A", "B", "C" )
>How can I do this?
>
>Thanks,
>Arne
>
>--
>Arne Henningsen
>Department of Agricultural Economics
>University of Kiel
>Olshausenstr. 40
>D-24098 Kiel (Germany)
>Tel: +49-431-880 4445
>Fax: +49-431-880 1397
>ahenningsen at agric-econ.uni-kiel.de
>http://www.uni-kiel.de/agrarpol/ahenningsen/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Tony Plate   tplate at acm.org



From andy_liaw at merck.com  Fri Nov 14 19:40:15 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 Nov 2003 13:40:15 -0500
Subject: [R] assigning rownames
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE40@usrymx25.merck.com>

Try something like this:

> m <- matrix(1:6, 3, 2)
> mName <- "m"
> eval(substitute(rownames(Name) <- LETTERS[1:3],
list(Name=as.name(mName))))
> m
  [,1] [,2]
A    1    4
B    2    5
C    3    6

HTH,
Andy


> -----Original Message-----
> From: Arne Henningsen [mailto:ahenningsen at agric-econ.uni-kiel.de] 
> Sent: Friday, November 14, 2003 12:23 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] assigning rownames
> 
> 
> Hi!
> 
> I have got a variable, say
>     myVar <- matrix( 1:6, 3, 2 )
> and a variable that contains the name of the variable, say
>    myVarName <- "myVar"
> Now, I want to assign rownames to the Variable "myVar".
> I can do it by 
>    rownames( myVar ) <- c( "A", "B", "C" )
> but for some reason I want "myVarName" as argument, e.g.
>   rownames( ????( myVarName ) )  <- c( "A", "B", "C" )
> How can I do this?
> 
> Thanks,
> Arne
> 
> -- 
> Arne Henningsen
> Department of Agricultural Economics
> University of Kiel
> Olshausenstr. 40
> D-24098 Kiel (Germany)
> Tel: +49-431-880 4445
> Fax: +49-431-880 1397
> ahenningsen at agric-econ.uni-kiel.de
> http://www.uni-kiel.de/agrarpol/ahenningsen/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From ryszard.czerminski at pharma.novartis.com  Fri Nov 14 20:05:32 2003
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Fri, 14 Nov 2003 14:05:32 -0500
Subject: [R] index of max value ?
Message-ID: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@EU.novartis.net>

Is there a function in R, which would return index of maximum value
in a vector ?

e.g.

> v <- round(10*rnorm(8))
> v
[1]   6  -3  -6  15   7   9   0 -19
> max(v)
[1] 15

??? index.max(v)
??? 4



From tplate at blackmesacapital.com  Fri Nov 14 20:12:38 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri, 14 Nov 2003 12:12:38 -0700
Subject: [R] Vector indices and minus sign
In-Reply-To: <3FB50B78.5070105@pburns.seanet.com>
References: <3A822319EB35174CA3714066D590DCD50205CE3B@usrymx25.merck.com>
Message-ID: <5.2.1.1.2.20031114120752.041c1fa8@mailhost.blackmesacapital.com>

At Friday 05:06 PM 11/14/2003 +0000, Patrick Burns wrote:


>Liaw, Andy wrote:
> > [material omitted...]
> >
> >I guess this can only work if "-" is treated specially in the subset
> >operators, so that, e.g., x[-"Andy"] would also work.  (This would be nice,
> >IMHO.)
> >
>I agree that  x[-c("Andy", "Pat")] would come in handy at times, but
>x[-numeric(0)] still can not work because the numbers that aren't there
>might be negative and the minus sign is to put them positive.
>
>Pat

Maybe what's needed is a new simple class that wraps vectors that can be 
used as indices, e.g.,

 > x[subomit(c("Andy", "Pat"))] # returns all elements except those named
 > x[subomit(c(1,4,9))]
 > x[subomit(numeric(0))] # returns all elements

This would require appropriate modifications to the code for "[" to detect 
when its indices were of class "subomit".

-- Tony Plate



From ray at mcs.vuw.ac.nz  Fri Nov 14 20:15:53 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Sat, 15 Nov 2003 08:15:53 +1300 (NZDT)
Subject: [R] Problem with parser and if/else
Message-ID: <200311141915.hAEJFr8d020618@tahi.mcs.vuw.ac.nz>

Prof Brian Ripley <ripley at stats.ox.ac.uk>

> On Fri, 14 Nov 2003, Paul Lemmens wrote:
> 
> > I'm trying to grasp this: if you're saying (or are you saying) that the 
> > only way to have if() know that an else will be present is to put it on the 
> > same line as the closing curly brace of the if() (compound) statement. But 
> > if I look at some code from, e.g., aov and lm, I see plenty violations of 
> > that rule.
> 
> The actual rule is given in my reference (the one that Ben Bolker did not 
> bother to look up) earlier in this thread.
> 
> You need to ensure that the code is syntactically incomplete when `else'
> is encountered.  That will always be true inside a braced expression such 
> as the bodies of the functions you quote.  But at top-level, you do need
> to write
> 
> if(condition) something else something_else
> 
> or
> 
> if(condition) {
> } else {
> }
> 
> since
> 
> if(condition) {
> } 
> else {
> }
> 
> fails the test.
> 
BUT, just to make it even clearer, what does succeed interactively is
(what is effectively the same as a function body):

{
if(condition) {
"TRUE"
}
else {
"FALSE"
}
}
because the parser has to find the final closing brace before the
syntactic item is complete.

Ray Brownrigg



From jmacdon at med.umich.edu  Fri Nov 14 20:17:19 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Fri, 14 Nov 2003 14:17:19 -0500
Subject: [R] index of max value ?
Message-ID: <sfb4e3fa.087@med-gwia-01a.med.umich.edu>

which(v==max(v)) should do the trick.

HTH,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> <ryszard.czerminski at pharma.novartis.com> 11/14/03 02:05PM >>>
Is there a function in R, which would return index of maximum value
in a vector ?

e.g.

> v <- round(10*rnorm(8))
> v
[1]   6  -3  -6  15   7   9   0 -19
> max(v)
[1] 15

??? index.max(v)
??? 4

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rpeng at jhsph.edu  Fri Nov 14 20:14:28 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 14 Nov 2003 14:14:28 -0500
Subject: [R] index of max value ?
In-Reply-To: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@EU.novartis.net>
References: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@EU.novartis.net>
Message-ID: <3FB52994.5010604@jhsph.edu>

?which.max

-roger

ryszard.czerminski at pharma.novartis.com wrote:
> Is there a function in R, which would return index of maximum value
> in a vector ?
> 
> e.g.
> 
> 
>>v <- round(10*rnorm(8))
>>v
> 
> [1]   6  -3  -6  15   7   9   0 -19
> 
>>max(v)
> 
> [1] 15
> 
> ??? index.max(v)
> ??? 4
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From hodgess at gator.uhd.edu  Fri Nov 14 20:31:24 2003
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Fri, 14 Nov 2003 13:31:24 -0600
Subject: [R] summary of expression and functions
Message-ID: <200311141931.hAEJVOD10261@gator.dt.uh.edu>


Thank you so much for all of your help!

I went with:

f <- function(x)
body(f) <- D(expression(x^2),"x")

This is SO COOL!

Thanks again,
Erin
mailto: hodgess at gator.uhd.edu



From tlumley at u.washington.edu  Fri Nov 14 20:28:24 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Nov 2003 11:28:24 -0800 (PST)
Subject: [R] index of max value ?
In-Reply-To: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@EU.novartis.net>
References: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@EU.novartis.net>
Message-ID: <Pine.A41.4.58.0311141127470.48800@homer35.u.washington.edu>

On Fri, 14 Nov 2003 ryszard.czerminski at pharma.novartis.com wrote:

> Is there a function in R, which would return index of maximum value
> in a vector ?
>

Yes.  which.max(), which is mentioned in the See Also section in
help(max).


	-thomas



From RBaskin at ahrq.gov  Fri Nov 14 20:28:04 2003
From: RBaskin at ahrq.gov (RBaskin@ahrq.gov)
Date: Fri, 14 Nov 2003 14:28:04 -0500
Subject: [R] index of max value ?
Message-ID: <3598558AD728D41183350008C7CF291C0F16B9BA@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/3cc4ce6d/attachment.pl

From cmoffet at nwrc.ars.usda.gov  Fri Nov 14 20:40:59 2003
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Fri, 14 Nov 2003 12:40:59 -0700
Subject: [R] index of max value ?
In-Reply-To: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@
	EU.novartis.net>
Message-ID: <3.0.6.32.20031114124059.00ff4c10@nwrc.ars.usda.gov>

?which

v <- c(6,  -3,  -6,  15,   7,   9,   0 -19)
v
which(v == max(v))


At 02:05 PM 11/14/2003 -0500, ryszard.czerminski at pharma.novartis.com wrote:
>Is there a function in R, which would return index of maximum value
>in a vector ?
>
>e.g.
>
>> v <- round(10*rnorm(8))
>> v
>[1]   6  -3  -6  15   7   9   0 -19
>> max(v)
>[1] 15
>
>??? index.max(v)
>??? 4
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Rangeland Scientist

USDA-ARS
Northwest Watershed Research Center
800 Park Blvd, Plaza IV, Suite 105
Boise, ID 83712-7716

Voice: (208) 422-0718
FAX:   (208) 334-1502



From spencer.graves at pdf.com  Fri Nov 14 20:56:27 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 14 Nov 2003 11:56:27 -0800
Subject: [R] index of max value ?
In-Reply-To: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@EU.novartis.net>
References: <OFE1A0B9F4.5AC30B85-ON85256DDE.00687F44-85256DDE.0068F729@EU.novartis.net>
Message-ID: <3FB5336B.3010709@pdf.com>

Have you considered: 

 > x <- c(1, 3, 1)
 > which(x==max(x))
[1] 2

Is this what you want?  spencer graves

ryszard.czerminski at pharma.novartis.com wrote:

>Is there a function in R, which would return index of maximum value
>in a vector ?
>
>e.g.
>
>  
>
>>v <- round(10*rnorm(8))
>>v
>>    
>>
>[1]   6  -3  -6  15   7   9   0 -19
>  
>
>>max(v)
>>    
>>
>[1] 15
>
>??? index.max(v)
>??? 4
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From hb at maths.lth.se  Fri Nov 14 21:16:02 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 14 Nov 2003 21:16:02 +0100
Subject: [R] R and RS232-Interface?
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B902945678@lobster.zhwin.ch>
Message-ID: <001301c3aaec$20e35900$930040d5@maths.lth.se>

Hi, I recall I've seen a RS232-interface communication class in Java a
few years ago. I can't remember for what platforms it were written for
(I think it relied on some native code). If you find it, you then might
be able to use the SJava package by Omegahat
(http://www.omegahat.org/RSJava/). A long shot, but it might be better
than nothing.

Cheers

Henrik Bengtsson 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Morach 
> Sascha, moracsa1
> Sent: den 14 november 2003 17:27
> To: r-help at stat.math.ethz.ch
> Subject: [R] R and RS232-Interface?
> 
> 
> Hi there
> 
>  
> 
> Does any one of you know something about R and an implemented 
> RS232-Interface? Are there any packages? Or is it possible to 
> write an extensions or something like that in C/C++ ?
> 
> The problem is that i should handle the information from a 
> measuring device via the RS232-Interface (probably you know 
> LabVIEW, which provides this functionality). These 
> informations should then directly be handled by R.
> 
> Is this possible?
> 
> (I hope I found the right words, I'm swiss, J )
> 
>  
> 
> thanks
> 
> Sascha Morach, diplomastudent, ZHW
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> 
>



From tlumley at u.washington.edu  Fri Nov 14 22:30:07 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Nov 2003 13:30:07 -0800 (PST)
Subject: [R] assigning rownames
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE40@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE40@usrymx25.merck.com>
Message-ID: <Pine.A41.4.58.0311141326310.57128@homer22.u.washington.edu>

On Fri, 14 Nov 2003, Liaw, Andy wrote:

> Try something like this:
>
> > m <- matrix(1:6, 3, 2)
> > mName <- "m"
> > eval(substitute(rownames(Name) <- LETTERS[1:3],
> list(Name=as.name(mName))))

Or in R 1.8.0

   mName<-as.name("m")
   eval(bquote( rownames(.(mName))<-LETTERS[1:3]))


	-thomas



From Roger.Bivand at nhh.no  Fri Nov 14 23:14:21 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 14 Nov 2003 23:14:21 +0100 (CET)
Subject: [R] spatial modeling
In-Reply-To: <sfb4d23a.012@mail2.salisbury.edu>
Message-ID: <Pine.LNX.4.44.0311142259120.15760-100000@reclus.nhh.no>

On Fri, 14 Nov 2003, Jill Caviglia-Harris wrote:

> I am new to R and have a question about spatial econometrics.  I have
> noticed that you can easily test for spatial autocorrelation with the
> spdep package, but was wondering if any code has been written to correct
> for spatial autocorrelation?   Or if there is any literature on this?

There are some comments in Robert Haining's 2003 book "Spatial Data 
Analysis", Cambridge University Press, both for modelling in general 
terms, and for degrees of freedom correction. His bibliography is very 
extensive, and will repay study. There is some code for so-called 
simultaneous autoregressive models in spdep, for those and conditional 
autoregressive models in the S-PLUS Spatial Stats module, and some Matlab 
code at www.spatial-econometrics.com. But I'd think looking through 
Haining's book would be the place to start. Please report back if you find 
some worthwhile ideas, possibly via the R-sig-geo list (access via 
http://sal.agecon.uiuc.edu/csiss/RgeoatSAL.html)

Roger

> 
> Thanks.  -Jill
> 
> ***************************************************
> Jill L. Caviglia-Harris, Ph.D.
> Assistant Professor
> Economics and Finance Department
> Salisbury University
> Salisbury, MD 21801-6860
>    phone: (410) 548-5591
>    fax: (410) 546-6208
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From partha_bagchi at hgsi.com  Fri Nov 14 23:02:02 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Fri, 14 Nov 2003 17:02:02 -0500
Subject: [R] A suggestion regarding multiple replies
Message-ID: <OFA98B0146.0CAEAECD-ON85256DDE.0078C063-85256DDE.0079091A@hgsi.com>

Please don't take this the wrong way. There are a lot of extremely helpful 
people who subscribe to r-help. 

I was wondering if it is time to adopt a strategy a-la Splus help whereby 
people reply to the author and the author summarizes all the replies?

Just a thought and have a good weekend.
Partha



From William.Burrows at ec.gc.ca  Fri Nov 14 23:50:28 2003
From: William.Burrows at ec.gc.ca (William.Burrows@ec.gc.ca)
Date: Fri, 14 Nov 2003 17:50:28 -0500
Subject: [R] this is a test
Message-ID: <DDA8F0C2655CB14DA8C7B84CDC6759A6B58BED@dowexch2.ontario.int.ec.gc.ca>



Dr. William R. Burrows
Meteorological Research Branch / ARMA
Meteorological Service of Canada
4905 Dufferin St.
Downsview, Ontario, M3H 5T4
Canada

 tel:  416-739-4927
fax:  416-739-4221
e-mail: william.burrows at ec.gc.ca



From William.Burrows at ec.gc.ca  Fri Nov 14 23:58:41 2003
From: William.Burrows at ec.gc.ca (William.Burrows@ec.gc.ca)
Date: Fri, 14 Nov 2003 17:58:41 -0500
Subject: [R] installing the next version of R while in an older version
Message-ID: <DDA8F0C2655CB14DA8C7B84CDC6759A6B58BEE@dowexch2.ontario.int.ec.gc.ca>

Hello -
I am a fairly new user of R. I currently have R1.7 installed. I tried to
install the KernSmooth package but a message tells me I need R1.8. Is there
a way to update to R1.8 while in R1.7 in the same manner that I can use
"update.packages", or do I have to install R1.8 in a separate directory and
re-install the many packages I have already installed in R1.7? Thanks in
advance for your help -

Bill

Dr. William R. Burrows
Meteorological Research Branch / ARMA
Meteorological Service of Canada
4905 Dufferin St.
Downsview, Ontario, M3H 5T4
Canada

 tel:  416-739-4927
fax:  416-739-4221
e-mail: william.burrows at ec.gc.ca



From WZocher at t-online.de  Sat Nov 15 00:14:54 2003
From: WZocher at t-online.de (Wolfgang Zocher)
Date: 15 Nov 2003 00:14:54 +0100
Subject: [R] Initial size of graphics window
Message-ID: <m365hmzgnl.fsf@wzocher.dialin.t-online.de>

Hi,

using par() a window is opened which is too large for my monitor. Is there any
chance to change the size of this window? 

Thanks,
Wolfgang



From dgrove at fhcrc.org  Sat Nov 15 00:29:49 2003
From: dgrove at fhcrc.org (Douglas Grove)
Date: Fri, 14 Nov 2003 15:29:49 -0800 (PST)
Subject: [R] A suggestion regarding multiple replies
In-Reply-To: <OFA98B0146.0CAEAECD-ON85256DDE.0078C063-85256DDE.0079091A@hgsi.com>
Message-ID: <Pine.LNX.4.44.0311141527130.22888-100000@echidna.fhcrc.org>

On Fri, 14 Nov 2003 partha_bagchi at hgsi.com wrote:

> I was wondering if it is time to adopt a strategy a-la Splus help whereby 
> people reply to the author and the author summarizes all the replies?


That might be a bit extreme, but it would be nice if people didn't
reply to the list (only to the authors) for very basic questions.

Most of us already know how to e.g. find the position of the 
largest element in a vector.

Doug



From mailinglist2_wegmann at web.de  Sat Nov 15 00:29:48 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Sat, 15 Nov 2003 00:29:48 +0100
Subject: [R] installing the next version of R while in an older version
In-Reply-To: <DDA8F0C2655CB14DA8C7B84CDC6759A6B58BEE@dowexch2.ontario.int.ec.gc.ca>
References: <DDA8F0C2655CB14DA8C7B84CDC6759A6B58BEE@dowexch2.ontario.int.ec.gc.ca>
Message-ID: <200311150029.48642.mailinglist2_wegmann@web.de>

Hello, 

On Friday 14 November 2003 23:58, William.Burrows at ec.gc.ca wrote:
> Hello -
> I am a fairly new user of R. I currently have R1.7 installed. I tried to
> install the KernSmooth package but a message tells me I need R1.8. Is there
> a way to update to R1.8 while in R1.7 in the same manner that I can use
> "update.packages", or do I have to install R1.8 in a separate directory and
> re-install the many packages I have already installed in R1.7? Thanks in
> advance for your help -

which operating system are you using? 

I only can tell it for Linux
you have to install R 1.8.0 the "usual" way, not inside R
your previously installed R packages should be still there after your upgrade. 

I assume it is +/- the same as in windows

cheers Martin


>
> Bill
>
> Dr. William R. Burrows
> Meteorological Research Branch / ARMA
> Meteorological Service of Canada
> 4905 Dufferin St.
> Downsview, Ontario, M3H 5T4
> Canada
>
>  tel:  416-739-4927
> fax:  416-739-4221
> e-mail: william.burrows at ec.gc.ca
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From swsmiley at genetics.utah.edu  Sat Nov 15 01:06:59 2003
From: swsmiley at genetics.utah.edu (Stan Smiley)
Date: Fri, 14 Nov 2003 17:06:59 -0700
Subject: [R] som package tutorial?
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAArZXp6c+HGE6fw3bI7RtXScKAAAAQAAAAQ7PSafw0jE6UQNX4QZ7l6wEAAAAA@genetics.utah.edu>


Is there a tutorial for the som package?
I'm trying to figure out which genes are in each cluster and having no luck.

Oh, and I'm also wondering why the som package isn't in Bioconductor...


Thanks.

Stan Smiley
stan.smiley at genetics.utah.edu
801-585-1527



From spencer.graves at pdf.com  Sat Nov 15 01:16:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 14 Nov 2003 16:16:48 -0800
Subject: [R] A suggestion regarding multiple replies
In-Reply-To: <Pine.LNX.4.44.0311141527130.22888-100000@echidna.fhcrc.org>
References: <Pine.LNX.4.44.0311141527130.22888-100000@echidna.fhcrc.org>
Message-ID: <3FB57070.5010805@pdf.com>

      Replying to all also notifies everyone else that an answer has 
been provided to the questioner.  I believe that replies to the 
originator do not go to the archives, which make it harder for someone 
else with essentially that question to get an answer from "search".  The 
number of multiple responses could be reduced dramatically if this 
listserve did not have such a long delay.  However, I presume the 
primary obstacle to that may be budget constraints at the Swiss Federal 
Institute of Technology in Zurich (ethz.ch).  I'm happy to have the 
service, and I don't have the resources to help upgrade ETHZ's server, 
so I don't complain. 

      Besides I read this list like I read a newspaper:  There is no 
need to read every reply.  People concerned about the volume can 
subscribe to the daily digest. 

      Briefly, I like the system as it is. 

      spencer graves

Douglas Grove wrote:

>On Fri, 14 Nov 2003 partha_bagchi at hgsi.com wrote:
>
>  
>
>>I was wondering if it is time to adopt a strategy a-la Splus help whereby 
>>people reply to the author and the author summarizes all the replies?
>>    
>>
>
>
>That might be a bit extreme, but it would be nice if people didn't
>reply to the list (only to the authors) for very basic questions.
>
>Most of us already know how to e.g. find the position of the 
>largest element in a vector.
>
>Doug
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From Ted.Harding at nessie.mcc.ac.uk  Sat Nov 15 01:30:42 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 15 Nov 2003 00:30:42 -0000 (GMT)
Subject: [R] A suggestion regarding multiple replies
In-Reply-To: <OFA98B0146.0CAEAECD-ON85256DDE.0078C063-85256DDE.0079091A@hgsi.com>
Message-ID: <XFMail.031115003042.Ted.Harding@nessie.mcc.ac.uk>

On 14-Nov-03 partha_bagchi at hgsi.com wrote:
> Please don't take this the wrong way. There are a lot of extremely
> helpful people who subscribe to r-help. 
> 
> I was wondering if it is time to adopt a strategy a-la Splus help
> whereby people reply to the author and the author summarizes all the
> replies?
> 
> Just a thought and have a good weekend.
> Partha

This has its merits, in reducing the load on the list and its readers.

However, personally I like the way questions are bounced around between
people. and answers are devoped "conversationally", as it were, and I
think a lot would be lost if this were not to happen. On the whole,
I welcome the load!

R strikes me as somewhat special amongst languages in that there are
a lot of hidden subtleties, which sometimes are only pointed out by
the few people who are really familiar with them. At present this
happens on-list and usually very promptly, and this timely intervention
puts wrong ideas right before they get too deeply embedded; this
benefit would tend to vanish if a "summarise to the list" policy
were adopted.

Of course there are some cases where a simple answer can be sent directly
to a person asking a simple question, but my experience is that I have
learned a lot about R by watching these dynamic discussions. I hope they
will continue!

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 15-Nov-03                                       Time: 00:30:42
------------------------------ XFMail ------------------------------



From rnews at kernstat.com  Sat Nov 15 01:38:34 2003
From: rnews at kernstat.com (Remington, Richard)
Date: Fri, 14 Nov 2003 17:38:34 -0700
Subject: [R] Initial size of graphics window
In-Reply-To: <m365hmzgnl.fsf@wzocher.dialin.t-online.de>
References: <m365hmzgnl.fsf@wzocher.dialin.t-online.de>
Message-ID: <3FB5758A.7020100@kernstat.com>

Wolfgang Zocher wrote:
> Hi,
> 
> using par() a window is opened which is too large for my monitor. Is there any
> chance to change the size of this window? 
> 
> Thanks,
> Wolfgang
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

par(din=c(?,?))

Alternatively, if you don't need to use par() and are using Microsoft 
Windows, see

?win.graph

Example, 4 x 4 inch window

win.graph(width = 4, height = 4)

-- 

Richard E. Remington III
Statistician
KERN Statistical Services, Inc.
PO Box 1046
Boise, ID 83701
Tel: 208.426.0113
KernStat.com



From ggrothendieck at myway.com  Sat Nov 15 02:40:29 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 Nov 2003 20:40:29 -0500 (EST)
Subject: [R] Subsetting a list of vectors
Message-ID: <20031115014029.BC57C394B@mprdmxin.myway.com>



One idea.  If sapply were to have an rm= parameter then the 
4 solutions below would reduce to:

   sapply( v, "[", 3, rm=NA )
   sapply( v, function(x) if (length(x)>=3) x[3], rm=NULL )

   sapply( 1:10, function(x) if (x%%2==0) x^2, rm=NULL )
   sapply( 1:10, function(x) if(x%%2==0)x^2 else NA, rm=NA )

---
 
Date: Mon, 10 Nov 2003 00:23:17 -0500 (EST) 
From: Gabor Grothendieck <ggrothendieck at myway.com>
To: <edd at debian.org>, <ray at mcs.vuw.ac.nz>, <h.wickham at auckland.ac.nz> 
Cc: <r-help at stat.math.ethz.ch> 
Subject: Re: [R] Subsetting a list of vectors 

 
 


Dirk and Ray have provided two very clever solutions which 
perform transformation and selection in one go 
by returning NA and NULL respectively for unwanted elements 
and then eliminating the NAs and NULLs. 

I thought it would be worthwhile to bring them together and 
make some further minor improvements.

Note that for the NULL solution we use the fact that 
if(FALSE)... with no else leg equals NULL.


Problem 1. If v is a list of vectors, get the vector which is the
third element of each vector in v. Do not include any elements 
for vectors with less than 3 elements.

Here the NA solution is particularly short:

as.numeric( na.omit( sapply( v, "[", 3 ) ) ) 

but the NULL solution seems closer to the list comprehension idea:

unlist( sapply( v, function(x) if (length(x)>=3) x[3] ) )


Problem 2. Express this Python program in R:
# give me the squares of the even numbers from 1-10, in a list. 
>>> [ x*x for x in range(1,11) if x%2 == 0]


Here the NULL Solution is both short and closer to the Python one:

unlist( sapply( 1:10, function(x) if (x%%2==0) x^2 ) )

while the NA solution is:

as.numeric(na.omit(sapply(1:10,function(x)if(x%%2==0)x^2 else NA)))




 --- On Mon 11/10, Gabor Grothendieck < ggrothendieck at myway.com > wrote:
From: Gabor Grothendieck [mailto: ggrothendieck at myway.com]
To: edd at debian.org, ray at mcs.vuw.ac.nz, h.wickham at auckland.ac.nz
     Cc: r-help at stat.math.ethz.ch
Date: Mon, 10 Nov 2003 00:23:17 -0500 (EST)
Subject: Re: [R] Subsetting a list of vectors

<br><br>Dirk and Ray have provided two very clever solutions which <br>perform transformation and selection in one go <br>by returning NA and NULL respectively for unwanted elements <br>and then eliminating the NAs and NULLs.  <br><br>I thought it would be worthwhile to bring them together and <br>make some further minor improvements.<br><br>Note that for the NULL solution we use the fact that <br>if(FALSE)... with no else leg equals NULL.<br><br><br>Problem 1. If v is a list of vectors, get the vector which is the<br>third element of each vector in v.  Do not include any elements <br>for vectors with less than 3 elements.<br><br>Here the NA solution is particularly short:<br><br>  as.numeric( na.omit( sapply( v, "[", 3 ) ) ) <br><br>but the NULL solution seems closer to the list comprehension idea:<br><br>  unlist( sapply( v, function(x) if (length(x)>=3) x[3] ) )<br><br><br>Problem 2. Express this Python program in R:<br>     # give me the squares of the even numbers from 1-10, in a list. <br>     >>> [ x*x for x in range(1,11) if x%2 == 0]<br><br><br>Here the NULL Solution is both short and closer to the Python one:<br><br>  unlist( sapply( 1:10, function(x) if (x%%2==0) x^2 ) )<br><br>while the NA solution is:<br><br>  as.numeric(na.omit(sapply(1:10,function(x)if(x%%2==0)x^2 else NA)))<br><br>______________________________________________<br>R-help at stat.math.ethz.ch mailing list<br>https://www.stat.math.ethz.ch/mailman/listinfo/r-help<br>



From andreas.lackner at wi-wiss.uni-goettingen.de  Sat Nov 15 04:12:50 2003
From: andreas.lackner at wi-wiss.uni-goettingen.de (Andreas Lackner)
Date: Sat, 15 Nov 2003 04:12:50 +0100
Subject: [R] Rescaling character widthof the title 
Message-ID: <000001c3ab26$63b3f1b0$0b01a8c0@wub73>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031115/627b71df/attachment.pl

From ggrothendieck at myway.com  Sat Nov 15 04:21:25 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 Nov 2003 22:21:25 -0500 (EST)
Subject: [R] LOCF - Last Observation Carried Forward
Message-ID: <20031115032125.27A64394A@mprdmxin.myway.com>


From: Tony Plate <tplate at acm.org>:
>
> Here's a function that does the essential computation (written to work in 
> both S-plus and R).
> 
> This looks like one of those tricky problems that do not vectorize 
> easily. It would be simple to write a C-program to compute this very 
> efficiently. But are there any more efficient solutions than ones like the 
> below (that are written without resort to C)?
> 
> most.recent <- function(x) {
> # return a vector of indices of the most recent TRUE value
> if (!is.logical(x))
> stop("x must be logical")
> x[is.na(x)] <- FALSE
> # x is a logical vector
> r <- rle(x)
> ends <- cumsum(r$lengths)
> starts <- ends - r$lengths + 1
> spec <- as.list(as.data.frame(rbind(start=starts, len=r$lengths, 
> value=as.numeric(r$values), prev.end=c(NA, ends[-length(ends)]))))
> names(spec) <- NULL
> unlist(lapply(spec, function(s) if (s[3]) seq(s[1], len=s[2]) else 
> rep(s[4], len=s[2])), use.names=F)
> }
> 
> > x <- c(F,T,T,F,F,F,T,F)
> > most.recent(x)
> [1] NA 2 3 3 3 3 7 7
> 
> And using it to do the fill-forward:
> 
> > x <- c(NA,2,3,NA,4,NA,5,NA,NA,NA,6,7,8,NA)
> > x[most.recent(!is.na(x))]
> [1] NA 2 3 3 4 4 5 5 5 5 6 7 8 8
> >
> 
> Some timings:
> 
> > x <- sample(c(T,F),1e4,rep=T)
> > system.time(most.recent(x))
> [1] 0.33 0.01 0.47 NA NA
> > x <- sample(c(T,F),1e5,rep=T)
> > system.time(most.recent(x))
> [1] 4.27 0.06 6.44 NA NA
> > x <- sample(c(T,F),1e6,rep=T)
> > system.time(most.recent(x))
> [1] 47.27 0.17 47.97 NA NA
> >
> 
> -- Tony Plate
> 
> PS. Actually, I just found a solution that I had lying around that is about 
> 70 times as fast on random test data like the above.

I was waiting for you to post this but didn't see it so I thought 
I would post mine.  This one is 13x as fast and only requires 
a single line of code.  

> set.seed(111)
> x <- sample(c(T,F),10000,rep=T)

> system.time(z1 <- most.recent(x))
[1] 0.92 0.02 1.68   NA   NA

> system.time(z2 <- as.numeric(as.vector(
     cut(seq(x),c(which(x),Inf),lab=which(x),right=F))))
[1] 0.07 0.00 0.12   NA   NA

> all.equal(z1,z2)
[1] TRUE



From ggrothendieck at myway.com  Sat Nov 15 04:34:21 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 Nov 2003 22:34:21 -0500 (EST)
Subject: [R] Rescaling character widthof the title 
Message-ID: <20031115033421.AB2E4394A@mprdmxin.myway.com>



---
 
From: Andreas Lackner <andreas.lackner at wi-wiss.uni-goettingen.de>
> When I export a graphic into a windows metafile, import that file into a
> Word document, the width of the character of my title isnt uniform anymore.

I generally find that this and other details of the plot are 
easier to handle in Word.   After inserting the wmf into Word, just 
right click on it and choose 

   Picture Object | Open 

at which point you are placed in an editor in which each of the 
titles and other objects in your picture are separately 
accessible and can easily be modified using Word's capabilities.



From Mohamed.Abdolell at cancercare.on.ca  Sat Nov 15 04:56:42 2003
From: Mohamed.Abdolell at cancercare.on.ca (Abdolell, Mohamed)
Date: Fri, 14 Nov 2003 22:56:42 -0500
Subject: [R] computing a p-value for a one-way ANOVA given only means and 
	std dev of 5 factor levels
Message-ID: <152C2DB31156D511B2BB00B0D0F0154105FB0203@provexch02.cancercare.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031114/c20ecc3e/attachment.pl

From ripley at stats.ox.ac.uk  Sat Nov 15 05:17:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 Nov 2003 04:17:29 +0000 (GMT)
Subject: [R] Rescaling character widthof the title 
In-Reply-To: <000001c3ab26$63b3f1b0$0b01a8c0@wub73>
Message-ID: <Pine.LNX.4.44.0311150413400.27539-100000@gannet.stats>

On Sat, 15 Nov 2003, Andreas Lackner wrote:

> When I export a graphic into a windows metafile, import that file into a
> Word document, the width of the character of my title isn?t uniform anymore.

`anymore'?  It was not uniform when you plotted on-screen in R:  
Arial/Helvetica is a not a monospaced font.

> The only way I found for solving this problem is to use the courier font,
> but I would like to use a font like (font.main=1). Does anybody know about
> that problem?

Please tell us exactly what you want to do, if possible with a 
reproducible example and screenshots (.png).

Note also that Word is far from perfect at importing WMF files so you
could easily be seeing a Word bug.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From smyth at wehi.edu.au  Sat Nov 15 05:25:39 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sat, 15 Nov 2003 15:25:39 +1100
Subject: [R] cross-classified random factors in lme without blocking
In-Reply-To: <6rbrrx4h9k.fsf@bates4.stat.wisc.edu>
References: <6rbrrx33us.fsf@bates4.stat.wisc.edu>
	<5.2.1.1.1.20031031153622.00acecc8@imaphost.wehi.edu.au>
	<x2r80trbmv.fsf@biostat.ku.dk>
	<6rbrrx33us.fsf@bates4.stat.wisc.edu>
Message-ID: <5.2.1.1.1.20031115151417.00ae7318@imaphost.wehi.edu.au>

Many thanks for help from Peter Dalgaard, Douglas Bates and Bill Venables. 
As a result of their help, here is a working example of using lme to fit an 
additive random effects model. The model here is effectively y~a+b with a 
and b random:

y <- rnorm(12)
a <- gl(4,1,12)
b <- gl(3,4,12)
u <- gl(1,1,12)
library(nlme)
fm <- lme(y~1,random=list(u=pdBlocked(list(pdIdent(~a-1),pdIdent(~b-1)))))
summary(fm)

I still can't see though how to extract the three variance components (for 
a and b and for the residual) from the fitted object 'fm'.

Thanks
Gordon



From ripley at stats.ox.ac.uk  Sat Nov 15 05:26:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 Nov 2003 04:26:05 +0000 (GMT)
Subject: [R] installing the next version of R while in an older version
In-Reply-To: <200311150029.48642.mailinglist2_wegmann@web.de>
Message-ID: <Pine.LNX.4.44.0311150422250.27539-100000@gannet.stats>

On Sat, 15 Nov 2003, Martin Wegmann wrote:

> Hello, 
> 
> On Friday 14 November 2003 23:58, William.Burrows at ec.gc.ca wrote:
> > Hello -
> > I am a fairly new user of R. I currently have R1.7 installed. I tried to
> > install the KernSmooth package but a message tells me I need R1.8. Is there

Your installation of R 1.7.x should have KernSmooth installed! It is a 
recommended package.  The later version available only makes use of the 
new documentation features of R 1.8.x.

> > a way to update to R1.8 while in R1.7 in the same manner that I can use
> > "update.packages", or do I have to install R1.8 in a separate directory and
> > re-install the many packages I have already installed in R1.7? Thanks in
> > advance for your help -
> 
> which operating system are you using? 
> 
> I only can tell it for Linux
> you have to install R 1.8.0 the "usual" way, not inside R
> your previously installed R packages should be still there after your upgrade. 
> 
> I assume it is +/- the same as in windows

Not quite (it will install into a parallel directory) but this is 
covered in the rw-FAQ.

Note that quite a few packages need to be re-installed for 1.8.x (if 
installed under a version before 1.8.0).

Also please note there is no R 1.7 and no R 1.8: try looking more closely.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Sat Nov 15 07:17:02 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 15 Nov 2003 19:17:02 +1300
Subject: [R] ISOdate() and strptime()
In-Reply-To: <Pine.A41.4.58.0311140718030.62532@homer06.u.washington.edu>
References: <6C8A8033ABC1E3468048ABC4F13CE572AC0E9D@synequanon01>
	<Pine.A41.4.58.0311140718030.62532@homer06.u.washington.edu>
Message-ID: <3FB5C4DE.4060902@indigoindustrial.co.nz>

Thomas Lumley wrote:

> On Fri, 14 Nov 2003, Simon Fear wrote:
> 
>>Is the behaviour of ISOtime() and strptime() determined by ISO
>>or POSIX standard? Seems not to fit R's "no nannying" policy
>>at all. 
>>
> 
> 
> It's determined by your operating system, so you're complaining to the
> wrong people.
> 

And since R is written to be portable across multiple OSs, you might get 
an idea how tricky this becomes.  Hence the "iron fist" approach to date 
handling.  Believe me, I've programmed date handling - it's always a 
terrible, nasty, messy business when international locales and different 
operating systems clash.  I'm stunned it's as good as it is, subtle 
traps and all.

Cheers

Jason



From seanpor at acm.org  Sat Nov 15 08:44:28 2003
From: seanpor at acm.org (Sean O'Riordain)
Date: Sat, 15 Nov 2003 07:44:28 +0000
Subject: [R] R and RS232-Interface?
In-Reply-To: <001301c3aaec$20e35900$930040d5@maths.lth.se>
References: <001301c3aaec$20e35900$930040d5@maths.lth.se>
Message-ID: <3FB5D95C.9030309@acm.org>

Hi,

Personally, I would avoid Java for hardware handling - in my experience 
this is tricky and very hardware specific.

Sascha, is this for a Unix type machine or under windows?  If under 
Unix/Linux, it should not be  particularly difficult to send characters 
and receive characters in C through a plain rs-232 port - though I don't 
have any code examples for you.  Just open the relevant /dev/cua0 (or 
whatever it is called on your machine) in character mode and treat it 
like a file.

cheers,
Sean



Henrik Bengtsson wrote:

>Hi, I recall I've seen a RS232-interface communication class in Java a
>few years ago. I can't remember for what platforms it were written for
>(I think it relied on some native code). If you find it, you then might
>be able to use the SJava package by Omegahat
>(http://www.omegahat.org/RSJava/). A long shot, but it might be better
>than nothing.
>
>Cheers
>
>Henrik Bengtsson 
>
>  
>
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Morach 
>>Sascha, moracsa1
>>Sent: den 14 november 2003 17:27
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] R and RS232-Interface?
>>
>>
>>Hi there
>>
>> 
>>
>>Does any one of you know something about R and an implemented 
>>RS232-Interface? Are there any packages? Or is it possible to 
>>write an extensions or something like that in C/C++ ?
>>
>>The problem is that i should handle the information from a 
>>measuring device via the RS232-Interface (probably you know 
>>LabVIEW, which provides this functionality). These 
>>informations should then directly be handled by R.
>>
>>Is this possible?
>>
>>(I hope I found the right words, I'm swiss, J )
>>
>> 
>>
>>thanks
>>
>>Sascha Morach, diplomastudent, ZHW
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list 
>>https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
>>
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>



From skennedy at netway.com  Sat Nov 15 15:02:05 2003
From: skennedy at netway.com (Stephen J. Kennedy)
Date: Sat, 15 Nov 2003 09:02:05 -0500
Subject: [R] r 1.7.1, MacOS 9.2.2, mclust 2.0-2
Message-ID: <a05100308bbdbe06294b4@[216.177.6.32]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031115/da5d7c9a/attachment.pl

From kim.1406 at osu.edu  Sat Nov 15 15:10:18 2003
From: kim.1406 at osu.edu (Kwang Kim)
Date: Sat, 15 Nov 2003 09:10:18 -0500
Subject: [R] Loading file to use with qda()
Message-ID: <BBEOJPCOOEJPILBAAMNMEEAHCAAA.kim.1406@osu.edu>

z <- qda(train, cl)
save(z, file = "qda.dat")
load("qda.dat")
predict(qda.dat, test)$class

I'm trying to save z where z <-qda(train, cl) and load z for later use in predict(z, test)$class.
I think I successfully saved z by save(z, file = "qda.dat") but when I tried to load by load("qda.dat") and
call predict(qda.dat, test)$class, it gives me error 'object qda.dat is not found'.

Does anybody have an idea?



From jeaneid at chass.utoronto.ca  Sat Nov 15 15:26:09 2003
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Sat, 15 Nov 2003 09:26:09 -0500
Subject: [R] recognizing "(" as a character
Message-ID: <Pine.SGI.4.40.0311150915500.9822327-100000@origin.chass.utoronto.ca>

Dear All,
I have been trying to scan data from pdf files and use R to seperate them.
The following will make it clear
I have a line that reads
"Intrepid (D)  15,977 11,956 45,143 39,014"
where what is in the parenthesis is either a "D" for domestic or "I" for
import.
I want to try to strsplit the line according to the full character "(D)"
or "(I)"  but unfortunately R recognizes this as "D", or "I" in the
strsplit command. my question is is there any way that I can tell R that
this "(" is a character.
P.S. even grep() does have the same problem. I know this is not a problem
since "(", ")", "[", etc.. are predefined in R but why is the quotation
marks for strings not doing its job here?

Thanks,
Jean Eid



From ligges at statistik.uni-dortmund.de  Sat Nov 15 15:34:14 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 15 Nov 2003 15:34:14 +0100
Subject: [R] recognizing "(" as a character
In-Reply-To: <Pine.SGI.4.40.0311150915500.9822327-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0311150915500.9822327-100000@origin.chass.utoronto.ca>
Message-ID: <3FB63966.3020307@statistik.uni-dortmund.de>

Jean Eid wrote:

> Dear All,
> I have been trying to scan data from pdf files and use R to seperate them.
> The following will make it clear
> I have a line that reads
> "Intrepid (D)  15,977 11,956 45,143 39,014"
> where what is in the parenthesis is either a "D" for domestic or "I" for
> import.
> I want to try to strsplit the line according to the full character "(D)"
> or "(I)"  but unfortunately R recognizes this as "D", or "I" in the
> strsplit command. my question is is there any way that I can tell R that
> this "(" is a character.
> P.S. even grep() does have the same problem. I know this is not a problem
> since "(", ")", "[", etc.. are predefined in R but why is the quotation
> marks for strings not doing its job here?
> 
> Thanks,
> Jean Eid

These functions do use regular expression. Try e.g.:

strsplit("Intrepid (D)  15,977 11,956 45,143 39,014", "\\(D\\)")

Uwe Ligges



From hb at maths.lth.se  Sat Nov 15 15:37:48 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 15 Nov 2003 15:37:48 +0100
Subject: [R] recognizing "(" as a character
In-Reply-To: <Pine.SGI.4.40.0311150915500.9822327-100000@origin.chass.utoronto.ca>
Message-ID: <001201c3ab86$0b9c35e0$110040d5@maths.lth.se>

You have to escape (="\\") such "special" characters, e.g.

 strsplit("abc(d)(e)", split="\\(")

or put them in brackets (matches sets of characters)

 strsplit("abc(d)(e)", split="[(]")

if you think that is more readable. Similar for gsub(), grep(),
regexpr() and friends.

Henrik Bengtsson


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jean Eid
> Sent: den 15 november 2003 15:26
> To: r-help at stat.math.ethz.ch
> Subject: [R] recognizing "(" as a character
> 
> 
> Dear All,
> I have been trying to scan data from pdf files and use R to 
> seperate them. The following will make it clear I have a line 
> that reads "Intrepid (D)  15,977 11,956 45,143 39,014" where 
> what is in the parenthesis is either a "D" for domestic or 
> "I" for import. I want to try to strsplit the line according 
> to the full character "(D)" or "(I)"  but unfortunately R 
> recognizes this as "D", or "I" in the strsplit command. my 
> question is is there any way that I can tell R that this "(" 
> is a character. P.S. even grep() does have the same problem. 
> I know this is not a problem since "(", ")", "[", etc.. are 
> predefined in R but why is the quotation marks for strings 
> not doing its job here?
> 
> Thanks,
> Jean Eid
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> 
>



From ligges at statistik.uni-dortmund.de  Sat Nov 15 15:42:23 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 15 Nov 2003 15:42:23 +0100
Subject: [R] Loading file to use with qda()
In-Reply-To: <BBEOJPCOOEJPILBAAMNMEEAHCAAA.kim.1406@osu.edu>
References: <BBEOJPCOOEJPILBAAMNMEEAHCAAA.kim.1406@osu.edu>
Message-ID: <3FB63B4F.5080506@statistik.uni-dortmund.de>

Kwang Kim wrote:

> z <- qda(train, cl)
> save(z, file = "qda.dat")
> load("qda.dat")
> predict(qda.dat, test)$class
> 
> I'm trying to save z where z <-qda(train, cl) and load z for later use in predict(z, test)$class.
> I think I successfully saved z by save(z, file = "qda.dat") but when I tried to load by load("qda.dat") and
> call predict(qda.dat, test)$class, it gives me error 'object qda.dat is not found'.
> 
> Does anybody have an idea?

You saved an object called z in a file called qda.dat. After loading the
file qda.dat, the object called z is in your workspace, so you can use:

predict(z, test)$class

Maybe you called z in the former session also qda.dat (like the file),
but you saved only the object called z ...

Uwe Ligges



From lobry at biomserv.univ-lyon1.fr  Sat Nov 15 15:49:29 2003
From: lobry at biomserv.univ-lyon1.fr (Jean lobry)
Date: Sat, 15 Nov 2003 15:49:29 +0100
Subject: [R] correlation and causality examples
In-Reply-To: <200311151115.hAFB7MQ5009261@hypatia.math.ethz.ch>
References: <200311151115.hAFB7MQ5009261@hypatia.math.ethz.ch>
Message-ID: <p05200f24bbdbe089b05a@[81.49.236.148]>

Dear All,

I'am looking for examples showing that correlation does not imply
causality, the targeted audience consists of undergraduate students
(their first year at the university but in the BioMathStat track).
All practicals are under R.

I was able to extract this from R datasets:

### begin
data(sunspots)
data(lynx)
spots <- window(sunspots, freq = 1, start = 1880, end = 1900)
lnx <- window(lynx, start = 1880, end = 1900)
ratio <- max(lnx)/max(spots)
par(mai = rep(1, 4))
plot(lnx, main = "Sun spots intensity\nand lynx population density",
      t = "b", ylab = "")
lines(ratio*spots, col = "red", t = "b")
axis(side = 4, col = "red", col.axis = "red", at = ratio*pretty(spots),
      lab = pretty(spots))
legend(1887, 4500, col = c("red", "black"), c("spots", "lynx"), pch = 21)
### end

Shouldn't I try to publish this in Nature or Science with a title
that goes "Solar activity increase libido in lynx populations" ?
Note the nice shift between the two curves corresponding to the
gestation time!

A brief look at the whole dataset demonstates that this is
definitively wrong:

### begin
spots <- window(sunspots, freq = 1, start = 1821, end = 1934)
ratio <- max(lynx)/max(spots)
plot(lynx, main = "Sun spots intensity\nand lynx population density",
      ylab = "")
lines(ratio*spots, col = "red")
axis(side = 4, col = "red", col.axis = "red", at = ratio*pretty(spots),
     lab = pretty(spots))
legend(1870, 6000, col = c("red", "black"), c("spots", "lynx"), lty = 1)
### end

So, I'am looking for similar examples, any hint would be greatly
appreciated. Basically, I'am looking for correlations between
completely deconnected phenomena so that the overinterpreted
causality relationships look stupid at first glance (and the more
funny the link, the better).

BTW, does someone know where to find the data of this example
of a high correlation between beer drinking in the US and children
mortality in japan (or something like that, I'm unsure, I have
googled around with these keywords but found nothing) ?

All the best, and many thanks to the whole R team for providing
us such a nice tool.

Jean
-- 
Jean R. Lobry            (lobry at biomserv.univ-lyon1.fr)
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - LYON I,
43 Bd 11/11/1918, F-69622 VILLEURBANNE CEDEX, FRANCE
allo  : +33 472 43 12 87     fax    : +33 472 43 13 88
http://pbil.univ-lyon1.fr/members/lobry/



From Mohamed.Abdolell at cancercare.on.ca  Sat Nov 15 16:28:03 2003
From: Mohamed.Abdolell at cancercare.on.ca (Abdolell, Mohamed)
Date: Sat, 15 Nov 2003 10:28:03 -0500
Subject: FW: [R] computing a p-value ...
Message-ID: <152C2DB31156D511B2BB00B0D0F0154105FB020A@provexch02.cancercare.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031115/a2929494/attachment.pl

From edd at debian.org  Sat Nov 15 17:10:00 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 15 Nov 2003 10:10:00 -0600
Subject: [R] correlation and causality examples
In-Reply-To: <p05200f24bbdbe089b05a@[81.49.236.148]>
References: <200311151115.hAFB7MQ5009261@hypatia.math.ethz.ch>
	<p05200f24bbdbe089b05a@[81.49.236.148]>
Message-ID: <20031115161000.GA12830@sonny.eddelbuettel.com>

On Sat, Nov 15, 2003 at 03:49:29PM +0100, Jean lobry wrote:
> BTW, does someone know where to find the data of this example
> of a high correlation between beer drinking in the US and children
> mortality in japan (or something like that, I'm unsure, I have
> googled around with these keywords but found nothing) ?

IIRC someone did a paper a few ago correlating "everything" in a OECD or
World Bank database of macroeconomic variables... and found something like
milk production in Indonesia to be a perfect predictor for subsequent SP500
returns.

The point was, of course, to show the fallacy in such 'data mining'.  I wish
I had the original reference.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From tlumley at u.washington.edu  Sat Nov 15 18:22:01 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 15 Nov 2003 09:22:01 -0800 (PST)
Subject: [R] recognizing "(" as a character
In-Reply-To: <001201c3ab86$0b9c35e0$110040d5@maths.lth.se>
References: <001201c3ab86$0b9c35e0$110040d5@maths.lth.se>
Message-ID: <Pine.A41.4.58.0311150921130.103366@homer40.u.washington.edu>

On Sat, 15 Nov 2003, Henrik Bengtsson wrote:

> You have to escape (="\\") such "special" characters, e.g.
>
>  strsplit("abc(d)(e)", split="\\(")
>
> or put them in brackets (matches sets of characters)
>
>  strsplit("abc(d)(e)", split="[(]")
>
> if you think that is more readable. Similar for gsub(), grep(),
> regexpr() and friends.
>

For all except (unfortunately) strsplit() there is now a fixed=TRUE
argument to make this unnecessary.

	-thomas



From tlumley at u.washington.edu  Sat Nov 15 18:28:53 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 15 Nov 2003 09:28:53 -0800 (PST)
Subject: [R] correlation and causality examples
In-Reply-To: <p05200f24bbdbe089b05a@[81.49.236.148]>
References: <200311151115.hAFB7MQ5009261@hypatia.math.ethz.ch>
	<p05200f24bbdbe089b05a@[81.49.236.148]>
Message-ID: <Pine.A41.4.58.0311150923290.103366@homer40.u.washington.edu>

On Sat, 15 Nov 2003, Jean lobry wrote:

> Dear All,
>
> I'am looking for examples showing that correlation does not imply
> causality, the targeted audience consists of undergraduate students
> (their first year at the university but in the BioMathStat track).
> All practicals are under R.
>

There's a nice example we use (data at
http://courses.washington.edu/b517/datasets/fev.txt
documentation at
http://courses.washington.edu/b517/datasets/fevdoc.txt
)

These are lung function (FEV1) data on children, taken at routine
checkups, and we tell people to do
a t.test comparing smokers and non-smokers.

There is a large and statistically significant difference -- the smokers
have *higher* FEV1, because they are older.

In a statistics course for graduate students in public health there are
always a few people who see the difference and forget to check the
direction...


	-thomas



From skennedy at netway.com  Sat Nov 15 17:48:27 2003
From: skennedy at netway.com (Stephen J. Kennedy)
Date: Sat, 15 Nov 2003 11:48:27 -0500
Subject: [R] r 1.7.1, MacOS 9.2.2, mclust 2.0-2 (Update)
Message-ID: <a0510030abbdc087e30ad@[216.177.6.32]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031115/44a63a02/attachment.pl

From spencer.graves at pdf.com  Sat Nov 15 19:14:21 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 15 Nov 2003 10:14:21 -0800
Subject: [R] cross-classified random factors in lme without blocking
In-Reply-To: <5.2.1.1.1.20031115151417.00ae7318@imaphost.wehi.edu.au>
References: <6rbrrx33us.fsf@bates4.stat.wisc.edu>	<5.2.1.1.1.20031031153622.00acecc8@imaphost.wehi.edu.au>	<x2r80trbmv.fsf@biostat.ku.dk>	<6rbrrx33us.fsf@bates4.stat.wisc.edu>
	<5.2.1.1.1.20031115151417.00ae7318@imaphost.wehi.edu.au>
Message-ID: <3FB66CFD.7040005@pdf.com>

George Box presented a beautiful plot that showed a high correlation 
between stork sightings and the number of human babies born year by year 
for several years in Oldenberg (Germany, I think).  I believe it appears 
early in Box, Hunter and Hunter (1978) Statistics for Experimenters 
(Wiley), but I don't have the book in my hand, so I can't confirm that 
or give a page reference. 

hope this helps.  spencer graves

Gordon Smyth wrote:

> Many thanks for help from Peter Dalgaard, Douglas Bates and Bill 
> Venables. As a result of their help, here is a working example of 
> using lme to fit an additive random effects model. The model here is 
> effectively y~a+b with a and b random:
>
> y <- rnorm(12)
> a <- gl(4,1,12)
> b <- gl(3,4,12)
> u <- gl(1,1,12)
> library(nlme)
> fm <- 
> lme(y~1,random=list(u=pdBlocked(list(pdIdent(~a-1),pdIdent(~b-1)))))
> summary(fm)
>
> I still can't see though how to extract the three variance components 
> (for a and b and for the residual) from the fitted object 'fm'.
>
> Thanks
> Gordon
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sat Nov 15 19:22:46 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 Nov 2003 18:22:46 +0000 (GMT)
Subject: [R] recognizing "(" as a character
In-Reply-To: <Pine.A41.4.58.0311150921130.103366@homer40.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0311151744140.22013-100000@gannet.stats>

On Sat, 15 Nov 2003, Thomas Lumley wrote:

> On Sat, 15 Nov 2003, Henrik Bengtsson wrote:
> 
> > You have to escape (="\\") such "special" characters, e.g.
> >
> >  strsplit("abc(d)(e)", split="\\(")
> >
> > or put them in brackets (matches sets of characters)
> >
> >  strsplit("abc(d)(e)", split="[(]")
> >
> > if you think that is more readable. Similar for gsub(), grep(),
> > regexpr() and friends.
> >
> 
> For all except (unfortunately) strsplit() there is now a fixed=TRUE
> argument to make this unnecessary.

As from 1.8.1 there will be a help page explaining what exactly a regexp
is.  You can use basic regexps here:

> strsplit("abc(d)(e)", split="(", extended=FALSE)
[[1]]
[1] "abc" "d)"  "e)" 

and those brought up on the original pre-POSIX Unix grep may be more
comfortable with that.

But it sounds like people would like a fixed=TRUE option too.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Sat Nov 15 19:29:26 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sat, 15 Nov 2003 12:29:26 -0600
Subject: [R] cross-classified random factors in lme without blocking
In-Reply-To: <5.2.1.1.1.20031115151417.00ae7318@imaphost.wehi.edu.au>
References: <6rbrrx33us.fsf@bates4.stat.wisc.edu>	<5.2.1.1.1.20031031153622.00acecc8@imaphost.wehi.edu.au>	<x2r80trbmv.fsf@biostat.ku.dk>	<6rbrrx33us.fsf@bates4.stat.wisc.edu>
	<5.2.1.1.1.20031115151417.00ae7318@imaphost.wehi.edu.au>
Message-ID: <3FB67086.2090704@pdf.com>



Gordon Smyth wrote:

> Many thanks for help from Peter Dalgaard, Douglas Bates and Bill 
> Venables. As a result of their help, here is a working example of using 
> lme to fit an additive random effects model. The model here is 
> effectively y~a+b with a and b random:
> 
> y <- rnorm(12)
> a <- gl(4,1,12)
> b <- gl(3,4,12)
> u <- gl(1,1,12)
> library(nlme)
> fm <- lme(y~1,random=list(u=pdBlocked(list(pdIdent(~a-1),pdIdent(~b-1)))))
> summary(fm)
> 
> I still can't see though how to extract the three variance components 
> (for a and b and for the residual) from the fitted object 'fm'.
> 
> Thanks
> Gordon
> 

Would this work for you? It still needs some parsing to extract sigma_a 
and sigma_b, but that should be simple.

v <- as.matrix(fm$modelStruct$reStruct$u)
c(sqrt(diag(v)), Residual = 1) * fm$sigma

Regards,
Sundar



From skennedy at netway.com  Sat Nov 15 19:49:05 2003
From: skennedy at netway.com (Stephen J. Kennedy)
Date: Sat, 15 Nov 2003 13:49:05 -0500
Subject: [R] r 1.7.1, MacOS 9.2.2, mclust 2.0-2 (Update), lapackLib
Message-ID: <a05100300bbdc23fc2028@[216.177.6.32]>

I am new to r and mclust.

I have version 1.7.1 of r, precompiled for Classic Mac OS (I am running 9.2.2 on a PowerBook G4).
I downloaded the precompiled version 2.0-2 of mclust for Classic MacOS.

It appears (from the example I was using below) that I need a library called lapackLib.  There does not appear to be a precompiled version at CRAN.  There is a makefile for lapackLib, to use with MPW.  I wondered if a compiled version might exist somewhere else.  I do not have MPW (although I could download this from Apple's site).  It has been a LONG time since I have used this and imagine it will be painful to get back up to speed.

Thanks,

S. Kennedy 

> library(mclust)

Attaching package 'mclust':

	The following object(s) are masked from package:base :

	 density 

>  data(iris)
> irisMatrix <- as.matrix(iris[,1:4])
> irisClass <- iris[,5]
> irisMclust <- Mclust(irisMatrix)
> plot(irisMclust,irisMatrix)

make a plot selection (0 to exit):
 
1:plot: BIC 
2:plot: Pairs 
3:plot: Classification (2-D projection) 
4:plot: Uncertainty (2-D projection) 
5:plot: All 
Selection: 5
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 
Error in eigen(sigma, symmetric = TRUE) : lapack routines cannot be loaded
In addition: Warning message: 
unable to load shared library "Hard Drive:R Stat Package:modules:lapackLib":
  error code -43 creating file spec for library Hard Drive:R Stat Package:modules:lapackLib



From jones at reed.edu  Sat Nov 15 21:02:03 2003
From: jones at reed.edu (Albyn Jones)
Date: Sat, 15 Nov 2003 12:02:03 -0800
Subject: [R] correlation and causality examples
In-Reply-To: <p05200f24bbdbe089b05a@[81.49.236.148]>
References: <200311151115.hAFB7MQ5009261@hypatia.math.ethz.ch>
	<p05200f24bbdbe089b05a@[81.49.236.148]>
Message-ID: <20031115200203.GM22515@sellwood.reed.edu>

On Sat, Nov 15, 2003 at 03:49:29PM +0100, Jean lobry wrote:
> Dear All,
> 
> I'am looking for examples showing that correlation does not imply
> causality, the targeted audience consists of undergraduate students
> (their first year at the university but in the BioMathStat track).
> All practicals are under R.
> 

The dataset below contains data by state, including population in 
thousands, area in square miles, percent urban population, percent 
below poverty line, whether there are gun registration laws or not, 
and the number of homicides. The socioeconomic data are from 1990/91,
from the census bureau as I recall.
 
The gun registration indicator is taken from a USA Today article 
(Tuesday, January 7, 1992, PAGE 5A).  The article reported that
gun registration laws lead to increased numbers of murders 
(homicides), a conclusion reached by comparing the mean number of 
homicides in states with gun registration laws to states without 
registration laws.  

"Guns" <- 
structure(.Data = list(
"pop" = c(4089, 2372, 30380, 3291, 598, 13277, 1135, 2795, 11543, 5996, 
   4860, 9368, 4432, 5158, 6737, 635, 7760, 18058, 10939, 11961, 1004,
   3560, 4953, 17349, 1770, 5018, 570, 3750, 3377, 680, 6623,
   1039, 5610, 2495, 3713, 4252, 1235, 2592, 808, 1593, 1105,
   1548, 1284, 3175, 2922, 703, 6286, 567, 4955, 1801, 460.), 
"area" = c(52.4, 53.2, 163.7, 5.5, 0.1, 65.8, 10.9, 56.3, 57.9, 10.6, 
   12.4, 96.8, 86.9, 69.7, 53.8, 70.7, 8.7, 54.5, 44.8, 46.1, 1.5, 32, 
   42.1, 268.6, 84.9, 71.3, 656.4, 114, 104.1, 2.5, 59.4, 83.6, 36.4, 
   82.3, 40.4, 51.8, 35.4, 48.4, 147, 77.4, 9.4, 121.6, 110.6, 69.9, 
   98.4, 77.1, 42.8, 9.6, 65.5, 24.2, 97.8), 
"urban" = c(60, 54, 93, 79, 100, 85, 89, 61, 85, 84, 81, 70, 71, 53, 
   50, 53, 89, 84, 74, 69, 86, 55, 61, 80, 87, 76, 68, 88, 82,
   73, 63, 57, 65, 69, 52, 68, 45, 47, 53, 66, 51, 73, 88,
   68, 71, 50, 69, 32, 66, 36, 65.), 
"poverty" = c(19, 18.4, 14.2, 5.8, 19.2, 14.1, 10, 10.1, 13.3, 10.2, 
   9.3, 13.9, 12, 13.6, 13.2, 13.5, 9, 14.1, 11.8, 10.8, 8.2, 16.5, 
   16.9, 16.8, 9.8, 26.2, 11.2, 14.2, 12.1, 8.1, 16, 13.7, 14.1, 11.1, 
   17.4, 22, 12.5, 23.8, 15.8, 10.9, 7.1, 20.9, 10.7, 15.8, 11.3, 13.5, 
   10.6, 7.1, 9.2, 17.2, 10.6), 
"gunreg" = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
   1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.), 
"homicides" = c(410, 240, 3710, 170, 489, 1300, 44, 62, 1270, 200, 540, 
   1020, 100, 550, 730, 11, 350, 2550, 760, 740, 38, 350, 470, 2660,
   43, 220, 56, 290, 155, 32, 720, 21, 380, 150, 260, 760,
   23, 370, 29, 43, 32, 160, 135, 220, 120, 9, 550, 24, 240,
   135, 20.)), 
names = c("pop", "area", "urban", "poverty", "gunreg", "homicides"), 
row.names = c("AL", "AR", "CA", "CT", "DC", "FL", "HI", "IA", "IL", "MA", 
   "MD", "MI", "MN", "MO", "NC", "ND", "NJ", "NY", "OH", "PA", "RI", "SC", 
   "TN", "TX", "UT", "WA", "AK", "AZ", "CO", "DE", "GA", "ID", "IN", "KS", 
   "KY", "LA", "ME", "MS", "MT", "NE", "NH", "NM", "NV", "OK", "OR", "SD", 
   "VA", "VT", "WI", "WV", "WY"), class = "data.frame")


========================================================================
     "I would rather be exposed to the inconveniences attending too 
      much liberty than to those attending too small a degree of it."
      -Thomas Jefferson
================================================================
http://www.reed.edu/~jones    Albyn Jones	  jones at reed.edu
Reed College, Portland OR 97202             (503)-771-1112 x7418



From JLCAVIGLIA-HARRIS at salisbury.edu  Sun Nov 16 01:41:29 2003
From: JLCAVIGLIA-HARRIS at salisbury.edu (Jill Caviglia-Harris)
Date: Sat, 15 Nov 2003 19:41:29 -0500
Subject: [R] an object of class lm returned by lm?
Message-ID: <sfb6816c.003@mail2.salisbury.edu>

Can someone tell me what an object of class lm returned by lm means?  I
assumed it mean the regression model - but I'm not sure how to enter
this in.  I have tried 

y~a+b 

but this is not working.  I have also tried saving the regression
results and entering these, but again this is incorrect.  

This language is from the following:

lm.LMtests(model, listw, zero.policy=FALSE, test="LMerr", spChk=NULL)

Arguments
model - an object of class lm returned by lm
listw - a listw object created for example by nb2listw, expected to be
row-standardised (W-style) 


Any help is welcomed.  Thanks.

-Jill

***************************************************
Jill L. Caviglia-Harris, Ph.D.
Assistant Professor
Economics and Finance Department
Salisbury University
Salisbury, MD 21801-6860
   phone: (410) 548-5591
   fax: (410) 546-6208



From dmurdoch at pair.com  Sun Nov 16 02:00:36 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 15 Nov 2003 20:00:36 -0500
Subject: [R] an object of class lm returned by lm?
In-Reply-To: <sfb6816c.003@mail2.salisbury.edu>
References: <sfb6816c.003@mail2.salisbury.edu>
Message-ID: <0uidrv44d2svlad8rvi5jbvjgpplabpir4@4ax.com>

On Sat, 15 Nov 2003 19:41:29 -0500, you wrote:

>Can someone tell me what an object of class lm returned by lm means?  I
>assumed it mean the regression model - but I'm not sure how to enter
>this in.  I have tried 
>
>y~a+b 
>
>but this is not working.  I have also tried saving the regression
>results and entering these, but again this is incorrect.  
>
>This language is from the following:
>
>lm.LMtests(model, listw, zero.policy=FALSE, test="LMerr", spChk=NULL)
>
>Arguments
>model - an object of class lm returned by lm
>listw - a listw object created for example by nb2listw, expected to be
>row-standardised (W-style) 
>
>
>Any help is welcomed.  Thanks.

Most functions in R return objects.  The description of "model" is
referring to the object returned by the lm() function.  For example,

fit <- lm(y~a+b)

Then "fit" would be a suitable value to pass as the model.

Duncan Murdoch



From spencer.graves at pdf.com  Sun Nov 16 02:04:35 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 15 Nov 2003 17:04:35 -0800
Subject: [R] an object of class lm returned by lm?
In-Reply-To: <sfb6816c.003@mail2.salisbury.edu>
References: <sfb6816c.003@mail2.salisbury.edu>
Message-ID: <3FB6CD23.2030708@pdf.com>

      I haven't used "lm.LMtest", but I can make a guess:  Have you 
tried the following: 

         mdl <- lm(y~a+b, data=...)
        lm.LMtests(mdl, ...)

      hope this  helps.  spencer graves

Jill Caviglia-Harris wrote:

>Can someone tell me what an object of class lm returned by lm means?  I
>assumed it mean the regression model - but I'm not sure how to enter
>this in.  I have tried 
>
>y~a+b 
>
>but this is not working.  I have also tried saving the regression
>results and entering these, but again this is incorrect.  
>
>This language is from the following:
>
>lm.LMtests(model, listw, zero.policy=FALSE, test="LMerr", spChk=NULL)
>
>Arguments
>model - an object of class lm returned by lm
>listw - a listw object created for example by nb2listw, expected to be
>row-standardised (W-style) 
>
>
>Any help is welcomed.  Thanks.
>
>-Jill
>
>***************************************************
>Jill L. Caviglia-Harris, Ph.D.
>Assistant Professor
>Economics and Finance Department
>Salisbury University
>Salisbury, MD 21801-6860
>   phone: (410) 548-5591
>   fax: (410) 546-6208
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From JLCAVIGLIA-HARRIS at salisbury.edu  Sun Nov 16 02:04:26 2003
From: JLCAVIGLIA-HARRIS at salisbury.edu (Jill Caviglia-Harris)
Date: Sat, 15 Nov 2003 20:04:26 -0500
Subject: [R] an object of class lm returned by lm?
Message-ID: <sfb686cc.008@mail2.salisbury.edu>

Duncan:

Thanks for your response.  I actually tried this as well.  The error
message I get is "objects of different length" I thought I was chosign
the model incorrectly, perhaps this is something else?

-Jill

***************************************************
Jill L. Caviglia-Harris, Ph.D.
Assistant Professor
Economics and Finance Department
Salisbury University
Salisbury, MD 21801-6860
   phone: (410) 548-5591
   fax: (410) 546-6208
*********************************************************

>>> Duncan Murdoch <dmurdoch at pair.com> 11/15/03 08:00PM >>>
On Sat, 15 Nov 2003 19:41:29 -0500, you wrote:

>Can someone tell me what an object of class lm returned by lm means? 
I
>assumed it mean the regression model - but I'm not sure how to enter
>this in.  I have tried 
>
>y~a+b 
>
>but this is not working.  I have also tried saving the regression
>results and entering these, but again this is incorrect.  
>
>This language is from the following:
>
>lm.LMtests(model, listw, zero.policy=FALSE, test="LMerr", spChk=NULL)
>
>Arguments
>model - an object of class lm returned by lm
>listw - a listw object created for example by nb2listw, expected to
be
>row-standardised (W-style) 
>
>
>Any help is welcomed.  Thanks.

Most functions in R return objects.  The description of "model" is
referring to the object returned by the lm() function.  For example,

fit <- lm(y~a+b)

Then "fit" would be a suitable value to pass as the model.

Duncan Murdoch



From jeff.hamann at forestinformatics.com  Sun Nov 16 02:58:23 2003
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Sat, 15 Nov 2003 17:58:23 -0800
Subject: [R] prevent conversion to factors in aggregate?
Message-ID: <001d01c3abe5$215588a0$0a00a8c0@rodan>

I've been trying to figure out how to prevent a column that is the result of
an aggregate function call so that I can use it in further calculations. For
example, I would like to aggregate the expf for the data.frame by sp
(character) and dbh (double d=rounded to integer) using the command:


> st2 <- aggregate( ntrs$expf, by=list(sp=ntrs$sp,dbh=ntrs$dbh), sum )
> st2$expf <- st2$x / 20
> st2$basal.area <- st2$dbh^2 * st2$expf
Warning message:
"^" not meaningful for factors in: Ops.factor(st2$dbh, 2)
>

attributes(st2$dbh) tell me the class is a factor. I would like to values to
remain AsIs but cannot seem to figure out how to tell aggregate how to do
that, or even handle the operation after the fact by converting or adding an
extra column to the resulting data.frame.

I've tried using I() with no luck

> st2 <- aggregate( ntrs$expf, by=list(sp=ntrs$sp,dbh=I(ntrs$dbh)), sum )

How can/do I "cast" the dbh factor into an integer in the data.frame?

Thanks,
Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From spencer.graves at pdf.com  Sun Nov 16 04:33:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 15 Nov 2003 19:33:38 -0800
Subject: [R] prevent conversion to factors in aggregate?
In-Reply-To: <001d01c3abe5$215588a0$0a00a8c0@rodan>
References: <001d01c3abe5$215588a0$0a00a8c0@rodan>
Message-ID: <3FB6F012.2090608@pdf.com>

I don't know how to prevent aggregate from making factors of everything, 
but the following shows how to cast them back into what you want: 

 > DF1 <- data.frame(a=1:9, b=rep(letters[1:3], 3), d=rep(1:3, each=3))
 >
 > DF. <- aggregate(DF1$a, by=list(b=DF1$b, d=DF1$d), FUN=sum)
 > sapply(DF., class)
        b         d         x
 "factor"  "factor" "integer"
 >
 > DF.$bch <- as.character(DF.$b)
 > DF.$dn <- as.numeric(as.character(DF.$d))
 > sapply(DF., class)
          b           d           x         bch          dn
   "factor"    "factor"   "integer" "character"   "numeric"

How's this?  I just got this same result from S-Plus 6.1 and R 1.8.0. 
spencer graves

Jeff D. Hamann wrote:

>I've been trying to figure out how to prevent a column that is the result of
>an aggregate function call so that I can use it in further calculations. For
>example, I would like to aggregate the expf for the data.frame by sp
>(character) and dbh (double d=rounded to integer) using the command:
>
>
>  
>
>>st2 <- aggregate( ntrs$expf, by=list(sp=ntrs$sp,dbh=ntrs$dbh), sum )
>>st2$expf <- st2$x / 20
>>st2$basal.area <- st2$dbh^2 * st2$expf
>>    
>>
>Warning message:
>"^" not meaningful for factors in: Ops.factor(st2$dbh, 2)
>  
>
>
>attributes(st2$dbh) tell me the class is a factor. I would like to values to
>remain AsIs but cannot seem to figure out how to tell aggregate how to do
>that, or even handle the operation after the fact by converting or adding an
>extra column to the resulting data.frame.
>
>I've tried using I() with no luck
>
>  
>
>>st2 <- aggregate( ntrs$expf, by=list(sp=ntrs$sp,dbh=I(ntrs$dbh)), sum )
>>    
>>
>
>How can/do I "cast" the dbh factor into an integer in the data.frame?
>
>Thanks,
>Jeff.
>
>---
>Jeff D. Hamann
>Forest Informatics, Inc.
>PO Box 1421
>Corvallis, Oregon USA 97339-1421
>(office) 541-754-1428
>(cell) 541-740-5988
>jeff.hamann at forestinformatics.com
>www.forestinformatics.com
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From snail at nycap.rr.com  Sun Nov 16 05:25:12 2003
From: snail at nycap.rr.com (Aaron "Snail:Lewis" Dinkin)
Date: Sat, 15 Nov 2003 23:25:12 -0500
Subject: [R] R-Project:  Graphic/3-D capabilites and information...
Message-ID: <3FB6FC28.7000801@nycap.rr.com>

Greetings, and Salutations to the wonderful people of the R-Project!!!

I have a question:

       There is are images on the Screenshots page of the r-project home ::

        http://www.r-project.org/screenshots/screenshots.html

There are THREE (3) images in particular I am interested in, that also 
pertain to this e-mail:

    http://www.r-project.org/screenshots/icon-persp-surface.jpg
    http://www.r-project.org/screenshots/volcano-image.jpg
    http://www.r-project.org/screenshots/volcano-persp.jpg

The http://www.r-project.org/screenshots/icon-persp-surface.jpg image is 
the one I am interested in the most, however, I would like to have 
information regarding all of them...

Information I would like to have would be:

    How were these images created (step by step with explanations if 
possible)
   
    What utilities, plugins, or data were used to create these images
     
    Tutorials, FAQs, or ANY and ALL information I would need to be able 
to understand how I can create images like these from my data, and how I 
can interpret images like these (what do they mean, how do you read the 
image...), because all graphics are representations of mathematical 
functions (all meaning ALL, even a picture in PhotoShop is a 
mathematical function)...

Many Thanks In Advance to the Kind peoples whom helped me find, and 
understand the information I requested!!!



From snail at nycap.rr.com  Sun Nov 16 06:04:53 2003
From: snail at nycap.rr.com (Aaron "Snail:Lewis" Dinkin)
Date: Sun, 16 Nov 2003 00:04:53 -0500
Subject: [R] Newbie Help:: Honors Chem. Project:: How to use R instead of JMP
 IN and GraphicalAnalysis...
Message-ID: <3FB70575.5070908@nycap.rr.com>

Greetings, and Salutations to the wonderful people of the R-Project!!!

I have a question:
    I use JMP IN and GraphicalAnalysis for my Honors Chem. Projects. I 
would like to be pointed in the right direction: I would like to know 
how to use R to obtain the same data I would if I were to use JMP IN and 
GraphicalAnalysis.

I would need to be able to do the following:

    produce a graphical depiction of :
       Oneway ANOVA
       Standard Deviation (Lines :JMPin)
       Means(Diamonds, Dots :JMPin)
       Data Points
       Standard Error (Bars/Lines :JMPin)
      
I would have to be able to "Fit X by Y" and make the X-axis Proportional

I would need to obtain the following numerical data:
    <Summary of Fit>
    RSquare
    RSquare Adj
    Root Mean Square Error
    Mean of Response
    Observations (or Sum Wgts)
    <Analysis of Variance>
    Source   DF   Sum of Squares   Mean Square   F-Ratio
    Model
    Error
    C-Total
    <Means for Oneway ANOVA>
    Level    Number   Mean    Std-Error
    <Means and Std Deviations>
    Level   Number   Mean   Std-Dev   Std-Err-Mean

I would also need to produce data that would illustrate my precision of 
measurements and my accuracy of measurements... Either Graphically or 
Numerically or both...
My class uses %CV to illustrate precision where %CV= (sd()/mean)*100
But any or all other methods used to calculate precision (and accuracy) 
would be fine too...

<The above was to describe a replacement for JMP IN>

For a replacement for GraphicalAnalysis, I would need the following 
information:

    A graph that would have points depicting the data entered with  a 
"Fit Line"
    a "Curve Fit" that would be set for "Linear" a Linear Equation...
    The "Liner Fit" would be depicted on the graph, the equation of the 
line in y =    mx+b format, the m(slope) of the line, the b(Y-intercept) 
of the line, and the Correlation [coefficient] of the line...
    I would have to be able to annotate the graph with my name, a title 
for the graph, the date, and the equation of the line...
    I would also need to be able to print out the dataset used to create 
the graph...
    also, I would need interpolative functionality: I would need to be 
able to figure out data while having only one known variable (ie.: we 
had to analyze the concentration of a pigment using a Spectrometer we 
had two variables: Concentration and Absorbance, several of the samples 
had "Unknown" concentrations while having known absorbances, we needed 
to find their Concentrations by interpolating the "Linear Fit For: 
Spectrometer Data" which entailed finding the spot where Absorbance 
(foo) hit the line, then we would assign the (bar) value (x axis value 
to y value) to Concentration, the Unknowns are now known!!!

   
    
Many Thanks In Advance to the Kind peoples whom helped me find, and 
understand the information I requested!!!



From dmurdoch at pair.com  Sun Nov 16 12:07:23 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 16 Nov 2003 06:07:23 -0500
Subject: [R] R-Project:  Graphic/3-D capabilites and information...
In-Reply-To: <3FB6FC28.7000801@nycap.rr.com>
References: <3FB6FC28.7000801@nycap.rr.com>
Message-ID: <19mervovfmhrbbtr2hhtugtpagaksakna7@4ax.com>

On Sat, 15 Nov 2003 23:25:12 -0500, you wrote:

>Greetings, and Salutations to the wonderful people of the R-Project!!!
>
>I have a question:
>
>       There is are images on the Screenshots page of the r-project home ::
 ...
>Information I would like to have would be:
>
>    How were these images created (step by step with explanations if 
>possible)
>   
>    What utilities, plugins, or data were used to create these images

They look very similar to the examples produced by example(persp) and
example(image).  No extras needed.  
   
>    Tutorials, FAQs, or ANY and ALL information I would need to be able 
>to understand how I can create images like these from my data, and how I 
>can interpret images like these (what do they mean, how do you read the 
>image...), because all graphics are representations of mathematical 
>functions (all meaning ALL, even a picture in PhotoShop is a 
>mathematical function)...

I don't know of FAQs, but there are lots of books on statistical
graphics, and many of them include sections on visualizing 3D data.
For example, Visualizing Data by Cleveland.

Duncan Murdoch



From Roger.Bivand at nhh.no  Sun Nov 16 12:30:06 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 16 Nov 2003 12:30:06 +0100 (CET)
Subject: [R] an object of class lm returned by lm?
In-Reply-To: <sfb686cc.008@mail2.salisbury.edu>
Message-ID: <Pine.LNX.4.44.0311161225100.26728-100000@reclus.nhh.no>

On Sat, 15 Nov 2003, Jill Caviglia-Harris wrote:

> Duncan:
> 
> Thanks for your response.  I actually tried this as well.  The error
> message I get is "objects of different length" I thought I was chosign
> the model incorrectly, perhaps this is something else?
> 

The error message is caused by a difference in the length of the residual 
vector - see 

> length(rediduals(model))

and the number of spatial units in your spatial weights list object, see

> length(listw$neighbours)

or

> print(listw)

Please contact me off-list if you need more explanation, for example 
giving the output of these lengths.

Roger


> -Jill
> 
> ***************************************************
> Jill L. Caviglia-Harris, Ph.D.
> Assistant Professor
> Economics and Finance Department
> Salisbury University
> Salisbury, MD 21801-6860
>    phone: (410) 548-5591
>    fax: (410) 546-6208
> *********************************************************
> 
> >>> Duncan Murdoch <dmurdoch at pair.com> 11/15/03 08:00PM >>>
> On Sat, 15 Nov 2003 19:41:29 -0500, you wrote:
> 
> >Can someone tell me what an object of class lm returned by lm means? 
> I
> >assumed it mean the regression model - but I'm not sure how to enter
> >this in.  I have tried 
> >
> >y~a+b 
> >
> >but this is not working.  I have also tried saving the regression
> >results and entering these, but again this is incorrect.  
> >
> >This language is from the following:
> >
> >lm.LMtests(model, listw, zero.policy=FALSE, test="LMerr", spChk=NULL)
> >
> >Arguments
> >model - an object of class lm returned by lm
> >listw - a listw object created for example by nb2listw, expected to
> be
> >row-standardised (W-style) 
> >
> >
> >Any help is welcomed.  Thanks.
> 
> Most functions in R return objects.  The description of "model" is
> referring to the object returned by the lm() function.  For example,
> 
> fit <- lm(y~a+b)
> 
> Then "fit" would be a suitable value to pass as the model.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From christophe.saintjean at free.fr  Sun Nov 16 12:53:36 2003
From: christophe.saintjean at free.fr (Saint-Jean Christophe)
Date: Sun, 16 Nov 2003 12:53:36 +0100
Subject: [R] Mixtures of Von-mises distributions
Message-ID: <003a01c3ac38$4c7f40e0$e1de4052@bilbon>

Dear all,
    I would like to fit a von mises mixture to my data using the EM
Algorithm.
    Unfornately, existing packages (including circstats) doesn't provide
such method.
    So, does anybody have written such code ?
Big thanks,
Christophe, (R newbie)



From ripley at stats.ox.ac.uk  Sun Nov 16 13:28:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Nov 2003 12:28:21 +0000 (GMT)
Subject: [R] Mixtures of Von-mises distributions
In-Reply-To: <003a01c3ac38$4c7f40e0$e1de4052@bilbon>
Message-ID: <Pine.LNX.4.44.0311161222020.15453-100000@gannet.stats>

Why do you want to use the EM `algorithm'?

It will be easier to directly maximize the log likelihood, and that is a 
5-mins job in R.

Take a look at the examples in MASS4 ch 16 (and see the books in the FAQ 
or the scripts in the MASS package).

On Sun, 16 Nov 2003, Saint-Jean Christophe wrote:

>     I would like to fit a von mises mixture to my data using the EM
> Algorithm.
>     Unfornately, existing packages (including circstats) doesn't provide
> such method.
>     So, does anybody have written such code ?
> Big thanks,
> Christophe, (R newbie)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From flom at ndri.org  Sun Nov 16 13:52:08 2003
From: flom at ndri.org (Peter Flom)
Date: Sun, 16 Nov 2003 07:52:08 -0500
Subject: [R] A suggestion regarding multiple replies
Message-ID: <sfb72cc9.078@MAIL.NDRI.ORG>

I like the current method.  It allows discussion to flourish, and
prevents (to some extent) the phenonmenon of a single question
generating 50 nearly identical replies (usually when it's a syntax
question which many people know the answer to).

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)


>>> <partha_bagchi at hgsi.com> 11/14/03 5:02 PM >>>
Please don't take this the wrong way. There are a lot of extremely
helpful 
people who subscribe to r-help. 

I was wondering if it is time to adopt a strategy a-la Splus help
whereby 
people reply to the author and the author summarizes all the replies?

Just a thought and have a good weekend.
Partha

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tomhopper at comcast.net  Sun Nov 16 14:26:07 2003
From: tomhopper at comcast.net (Tom Hopper)
Date: Sun, 16 Nov 2003 08:26:07 -0500
Subject: [R] Newbie: Barchart Gray with White Grid?
Message-ID: <6F3ED160-1838-11D8-98BD-00306552AAF4@comcast.net>

Hello,

I'm just getting in to R, been reading manuals (thanks to all who 
provided pointers to good docs!), and messing with different commands. 
I'd appreciate a little help with this exploration, and I hope that my 
question is relatively easy to answer (probably, there's a simple way 
to do what I'm working toward).

R's statistical functions are coming along easily enough, but graphics 
seem to be a little tougher for me, probably because I'm used to 
working in SigmaPlot. As an exercise, I tried to create a gray bar 
chart with white grid overlay, like the one on page 128 of Tufte's 
"Visual Display of Quantitative Information." I  figure this would 
cover a lot of the basic techniques that I'll need for "real" work. I 
got as far as having a gray bar chart (I was working within hist(), 
mostly) with white borders, white (on white background) axes, white 
grid *under* the bars, and both x- and y-axis labels (both the numeric 
or categorical label, and the axis titles...I don't quite remember the 
correct terms in R).

I wasn't able to find a way to display only the gridlines parallel to 
the x-axis, or to overlay that grid on top of the bars, or to turn off 
the numeric labels on the x-axis without touching the y-axis, or to 
show the x-axis as a gray line without showing the y-axis.

Has anyone done this? How?

Thank you,

Tom



From andreas.lackner at wi-wiss.uni-goettingen.de  Sun Nov 16 15:08:55 2003
From: andreas.lackner at wi-wiss.uni-goettingen.de (Andreas Lackner)
Date: Sun, 16 Nov 2003 15:08:55 +0100
Subject: [R] Other fixed-width fonts like courier?
In-Reply-To: <sfb72cc9.078@MAIL.NDRI.ORG>
Message-ID: <000001c3ac4b$2f652bb0$0b01a8c0@wub73>

Hi,

does R have any other fixed width fonts next to courier (font=11)?

Thanks Andreas


-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von Peter Flom
Gesendet: Sonntag, 16. November 2003 13:52
An: partha_bagchi at hgsi.com; r-help at stat.math.ethz.ch
Betreff: Re: [R] A suggestion regarding multiple replies

I like the current method.  It allows discussion to flourish, and
prevents (to some extent) the phenonmenon of a single question
generating 50 nearly identical replies (usually when it's a syntax
question which many people know the answer to).

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)


>>> <partha_bagchi at hgsi.com> 11/14/03 5:02 PM >>>
Please don't take this the wrong way. There are a lot of extremely
helpful 
people who subscribe to r-help. 

I was wondering if it is time to adopt a strategy a-la Splus help
whereby 
people reply to the author and the author summarizes all the replies?

Just a thought and have a good weekend.
Partha

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun Nov 16 15:40:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Nov 2003 14:40:29 +0000 (GMT)
Subject: [R] Other fixed-width fonts like courier?
In-Reply-To: <000001c3ac4b$2f652bb0$0b01a8c0@wub73>
Message-ID: <Pine.LNX.4.44.0311161435280.15781-100000@gannet.stats>

R has no fonts at all.

At a guess you are using Windows, and your OS has many other fonts.
For how to use them in an R graphics device on Windows see the rw-FAQ or
?Rdevga, and in the Rgui console see ?Rconsole and the GUI preferences 
editor.

And what has this to do with Peter Flom's reply to another question?

On Sun, 16 Nov 2003, Andreas Lackner wrote:

> Hi,
> 
> does R have any other fixed width fonts next to courier (font=11)?
> 
> Thanks Andreas
> 
> 
> -----Urspr?ngliche Nachricht-----
> Von: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von Peter Flom
> Gesendet: Sonntag, 16. November 2003 13:52
> An: partha_bagchi at hgsi.com; r-help at stat.math.ethz.ch
> Betreff: Re: [R] A suggestion regarding multiple replies
> 
> I like the current method.  It allows discussion to flourish, and
> prevents (to some extent) the phenonmenon of a single question
> generating 50 nearly identical replies (usually when it's a syntax
> question which many people know the answer to).
> 
> Peter
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> 
> >>> <partha_bagchi at hgsi.com> 11/14/03 5:02 PM >>>
> Please don't take this the wrong way. There are a lot of extremely
> helpful 
> people who subscribe to r-help. 
> 
> I was wondering if it is time to adopt a strategy a-la Splus help
> whereby 
> people reply to the author and the author summarizes all the replies?
> 
> Just a thought and have a good weekend.
> Partha
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Nov 16 15:44:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Nov 2003 14:44:29 +0000 (GMT)
Subject: [R] Newbie: Barchart Gray with White Grid?
In-Reply-To: <6F3ED160-1838-11D8-98BD-00306552AAF4@comcast.net>
Message-ID: <Pine.LNX.4.44.0311161441190.15781-100000@gannet.stats>

On Sun, 16 Nov 2003, Tom Hopper wrote:

> I'm just getting in to R, been reading manuals (thanks to all who 
> provided pointers to good docs!), and messing with different commands. 
> I'd appreciate a little help with this exploration, and I hope that my 
> question is relatively easy to answer (probably, there's a simple way 
> to do what I'm working toward).
> 
> R's statistical functions are coming along easily enough, but graphics 
> seem to be a little tougher for me, probably because I'm used to 
> working in SigmaPlot. As an exercise, I tried to create a gray bar 
> chart with white grid overlay, like the one on page 128 of Tufte's 
> "Visual Display of Quantitative Information." I  figure this would 
> cover a lot of the basic techniques that I'll need for "real" work. I 
> got as far as having a gray bar chart (I was working within hist(), 
> mostly) with white borders, white (on white background) axes, white 
> grid *under* the bars, and both x- and y-axis labels (both the numeric 
> or categorical label, and the axis titles...I don't quite remember the 
> correct terms in R).
> 
> I wasn't able to find a way to display only the gridlines parallel to 
> the x-axis, or to overlay that grid on top of the bars, or to turn off 
> the numeric labels on the x-axis without touching the y-axis, or to 
> show the x-axis as a gray line without showing the y-axis.

?grid (and the hint in the details).

?par and look at xaxt and yaxt.  Then use axis() to add the axes you want.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ramasamya at gis.a-star.edu.sg  Sun Nov 16 15:42:35 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Sun, 16 Nov 2003 22:42:35 +0800
Subject: [R] Newbie: Barchart Gray with White Grid?
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D5607600D@BIONIC.biopolis.one-north.com>

The examples in help(hist) and help(barplot) uses the argument col='gray' etc to set the color of the barplots/histograms. As for grids, the following may help
 
tN <- table(Ni <- rpois(100, lambda=5))
r <- barplot(tN, col="gray", xaxt="n")          # alternatively  hist(Ni, col="gray", freq=T)
abline( h=seq(0,max(tN), by=5), col="white" )

To turn off the numeric labels, use xaxt="n" option in the plot() command. You can try to set the background using the bg="blue". This and more options are documented in par().
 
 
-----Original Message----- 
From: r-help-bounces at stat.math.ethz.ch on behalf of Tom Hopper 
Sent: Sun 11/16/2003 9:26 PM 
To: r-help at stat.math.ethz.ch 
Cc: 
Subject: [R] Newbie: Barchart Gray with White Grid?



	Hello,
	
	I'm just getting in to R, been reading manuals (thanks to all who
	provided pointers to good docs!), and messing with different commands.
	I'd appreciate a little help with this exploration, and I hope that my
	question is relatively easy to answer (probably, there's a simple way
	to do what I'm working toward).
	
	R's statistical functions are coming along easily enough, but graphics
	seem to be a little tougher for me, probably because I'm used to
	working in SigmaPlot. As an exercise, I tried to create a gray bar
	chart with white grid overlay, like the one on page 128 of Tufte's
	"Visual Display of Quantitative Information." I  figure this would
	cover a lot of the basic techniques that I'll need for "real" work. I
	got as far as having a gray bar chart (I was working within hist(),
	mostly) with white borders, white (on white background) axes, white
	grid *under* the bars, and both x- and y-axis labels (both the numeric
	or categorical label, and the axis titles...I don't quite remember the
	correct terms in R).
	
	I wasn't able to find a way to display only the gridlines parallel to
	the x-axis, or to overlay that grid on top of the bars, or to turn off
	the numeric labels on the x-axis without touching the y-axis, or to
	show the x-axis as a gray line without showing the y-axis.
	
	Has anyone done this? How?
	
	Thank you,
	
	Tom
	
	______________________________________________
	R-help at stat.math.ethz.ch mailing list
	https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ramasamya at gis.a-star.edu.sg  Sun Nov 16 16:31:52 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Sun, 16 Nov 2003 23:31:52 +0800
Subject: [R] Newbie Help:: Honors Chem. Project:: How to use R instead of
	JMP IN and GraphicalAnalysis...
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D5607600E@BIONIC.biopolis.one-north.com>

See the "Manual" or "Publications" under http://www.r-project.org/. Books with ref [4] and [9] under publications might be of interest.
 

	-----Original Message----- 
	From: r-help-bounces at stat.math.ethz.ch on behalf of Aaron "Snail:Lewis" Dinkin 
	Sent: Sun 11/16/2003 1:04 PM 
	To: R-help at stat.math.ethz.ch; snail at nycap.rr.com 
	Cc: 
	Subject: [R] Newbie Help:: Honors Chem. Project:: How to use R instead of JMP IN and GraphicalAnalysis...
	
	

	Greetings, and Salutations to the wonderful people of the R-Project!!!
	
	I have a question:
	    I use JMP IN and GraphicalAnalysis for my Honors Chem. Projects. I
	would like to be pointed in the right direction: I would like to know
	how to use R to obtain the same data I would if I were to use JMP IN and
	GraphicalAnalysis.
	
	I would need to be able to do the following:
	
	    produce a graphical depiction of :
	       Oneway ANOVA
	       Standard Deviation (Lines :JMPin)
	       Means(Diamonds, Dots :JMPin)
	       Data Points
	       Standard Error (Bars/Lines :JMPin)
	     
	I would have to be able to "Fit X by Y" and make the X-axis Proportional
	
	I would need to obtain the following numerical data:
	    <Summary of Fit>
	    RSquare
	    RSquare Adj
	    Root Mean Square Error
	    Mean of Response
	    Observations (or Sum Wgts)
	    <Analysis of Variance>
	    Source   DF   Sum of Squares   Mean Square   F-Ratio
	    Model
	    Error
	    C-Total
	    <Means for Oneway ANOVA>
	    Level    Number   Mean    Std-Error
	    <Means and Std Deviations>
	    Level   Number   Mean   Std-Dev   Std-Err-Mean
	
	I would also need to produce data that would illustrate my precision of
	measurements and my accuracy of measurements... Either Graphically or
	Numerically or both...
	My class uses %CV to illustrate precision where %CV= (sd()/mean)*100
	But any or all other methods used to calculate precision (and accuracy)
	would be fine too...
	
	<The above was to describe a replacement for JMP IN>
	
	For a replacement for GraphicalAnalysis, I would need the following
	information:
	
	    A graph that would have points depicting the data entered with  a
	"Fit Line"
	    a "Curve Fit" that would be set for "Linear" a Linear Equation...
	    The "Liner Fit" would be depicted on the graph, the equation of the
	line in y =    mx+b format, the m(slope) of the line, the b(Y-intercept)
	of the line, and the Correlation [coefficient] of the line...
	    I would have to be able to annotate the graph with my name, a title
	for the graph, the date, and the equation of the line...
	    I would also need to be able to print out the dataset used to create
	the graph...
	    also, I would need interpolative functionality: I would need to be
	able to figure out data while having only one known variable (ie.: we
	had to analyze the concentration of a pigment using a Spectrometer we
	had two variables: Concentration and Absorbance, several of the samples
	had "Unknown" concentrations while having known absorbances, we needed
	to find their Concentrations by interpolating the "Linear Fit For:
	Spectrometer Data" which entailed finding the spot where Absorbance
	(foo) hit the line, then we would assign the (bar) value (x axis value
	to y value) to Concentration, the Unknowns are now known!!!
	
	  
	   
	Many Thanks In Advance to the Kind peoples whom helped me find, and
	understand the information I requested!!!
	
	______________________________________________
	R-help at stat.math.ethz.ch mailing list
	https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From sreedevi at uab.edu  Sun Nov 16 16:37:56 2003
From: sreedevi at uab.edu (Sreedevi Gopalan)
Date: Sun, 16 Nov 2003 09:37:56 -0600
Subject: [R] help with EMclust
Message-ID: <7C93F21AD56849408985C3478EE83BA60AB185@UABEXMB2.ad.uab.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031116/db861d23/attachment.pl

From friendly at yorku.ca  Sun Nov 16 17:01:22 2003
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 16 Nov 2003 11:01:22 -0500
Subject: [R] correlation and causality examples
In-Reply-To: <200311161101.hAGB1BPW025462@hypatia.math.ethz.ch>
References: <200311161101.hAGB1BPW025462@hypatia.math.ethz.ch>
Message-ID: <3FB79F52.5060907@yorku.ca>

My favorite example on correlation !-> causation is data from Yule & Kendall
on the relationship between number of licenses for radios and the number
of people classified as 'mental defectives' in England and Wales from 
1924-37

Of course, both were increasing over time, the latter due to increase in 
diagnosis
using this term, the former due to increased availability, accounting 
for the very
high correlation.  I've attached the data as a SAS file.

>
> Subject:
> [R] correlation and causality examples
> From:
> Jean lobry <lobry at biomserv.univ-lyon1.fr>
> Date:
> Sat, 15 Nov 2003 15:49:29 +0100
> To:
> r-help at stat.math.ethz.ch
>
>
> Dear All,
>
> I'am looking for examples showing that correlation does not imply
> causality, the targeted audience consists of undergraduate students
> (their first year at the university but in the BioMathStat track).
> All practicals are under R.



-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From karlknoblich at yahoo.de  Sun Nov 16 17:27:34 2003
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Sun, 16 Nov 2003 17:27:34 +0100 (CET)
Subject: [R] SE of ANOVA (aov) with repeated measures and a bewtween-subject
	factor
Message-ID: <20031116162734.42740.qmail@web10009.mail.yahoo.com>


Hallo!

I have data of the following design: 
NSubj were measured at Baseline (visit 1) and at 3
following time points (visit 2, visit 3, visit 4).
There is or is not a treatment.

Most interesting is the question if there is a
difference in treatment between the results of visit 4
and baseline. (The other time points are also of
interest.) The level of significance is alpha=0.0179
(because of an interim analysis).

My questions:

1) I prefer calculating s model with the differences
to baseline as Y:
Y ~ treat*visit + Error(treat:id)
where treat is the treatment and id is the subject's
id
Other possibilities are:
a) Y0 ~ treat*visit + v1 + Error(treat:id)
where Y0 are the results (visit 2 to visit 4) and v1
is the result of visit 1 as covariate
b) Calculating a t-test with the results of visit 4
and visit 1
What's best?

2) When calculating a model (ANOVA) I have to
calculate the treatment effect (easy with coef(...)).
But how can I get the standard errors, or more exactly
the 98.21% confidence 

intervals? 
- lm() does not work with an Error()-term in the
formula
- using lme(), I can not reproduce results e.g. of an
example of a text book ((Bortz,
Statistik f?r Sozialwissenschaftler, p.412, 3.
Auflage, see at the very end)

Here what I have done (with random data):

  # Random generation of data
  NSubj<-30 # No. of subjects
  set.seed(1234)
  id<-c(1:NSubj) # ID of subjects
  treat<-runif(NSubj, min=0, max=1) > 0.5 # Treatment
  v1<-runif(NSubj, min=0, max=1) # Result visit 1
Baseline)
  v2<-runif(NSubj, min=0, max=1) # Result visit 2
  v3<-runif(NSubj, min=0, max=1) # Result visit 3
  v4<-runif(NSubj, min=0, max=1) # Result visit 4

  # Making the data frame
  Y<-c(v2-v1,v3-v1,v4-v1) # Taking the differences to
baseline (visit 1)
  id<-as.factor(rep(id, 3))
  treat<-as.factor(rep(treat, 3))
  visit<-as.factor(rep(2:4, each=NSubj))
  df<-data.frame(id, treat, visit, Y)

  # Analysis
  df.aov <- aov(Y ~ treat*visit + Error(treat:id),
data=df)
  summary(df.aov)
  coef(df.aov)

How can I get the SE?

Hope somebody can help!

Karl

Example (Bortz, Statistik f?r Sozialwissenschaftler,
p.412, 3. Auflage), two-factorial 

analysis of variance with repeated measurements:

 Subject b1 b2 b3
al 1 56 52 48
al 2 57 54 46
al 3 55 51 51
al 4 58 51 50
al 5 54 53 46
a2 1 54 50 49
a2 2 53 49 48
a2 3 56 48 52
a2 4 52 52 50
a2 5 55 51 46
a3 1 57 49 50
a3 2 55 51 47
a3 3 56 48 51
a3 4 58 50 48
a3 5 58 46 52

The factors are A (a1,a2,a3) and B (b1,b2,b3); 5
subjects. Factor A is
kind of training (creativity) for the subjacts and
factor B is before,
during and after training.

The results of the example:

Source SS df sigma2 F
A 9.9 2 4.95 3.87
Subject in sample 15.4 12 1.28
between subjects 25.3 14
B 370.7 2 185.35 44.03 (**)
AxB 45.6 4 11.4 2.71
BxSubject 101.0 24 4.21
within subjects 517.3 30
Total 542.6 44



From arc at arcriswell.com  Sun Nov 16 18:02:55 2003
From: arc at arcriswell.com (Andrew Criswell)
Date: Mon, 17 Nov 2003 00:02:55 +0700
Subject: [R] correlation and causality examples
References: <200311161101.hAGB1BPW025462@hypatia.math.ethz.ch>
	<3FB79F52.5060907@yorku.ca>
Message-ID: <3FB7ADBF.5010105@arcriswell.com>

Hi all:

And then there's the classic case of higher frequency of cases with 
coronary heart disease in Arizona than NYC.  Does that support the 
hypothesis that cleaner air causes CHD or that those with CHD choose 
Arizona for its cleaner air?

ANDREW



From sundar.dorai-raj at pdf.com  Sun Nov 16 18:07:47 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 16 Nov 2003 11:07:47 -0600
Subject: [R] help with EMclust
In-Reply-To: <7C93F21AD56849408985C3478EE83BA60AB185@UABEXMB2.ad.uab.edu>
References: <7C93F21AD56849408985C3478EE83BA60AB185@UABEXMB2.ad.uab.edu>
Message-ID: <3FB7AEE3.7030405@pdf.com>



Sreedevi Gopalan wrote:
> we have implemented teh following code for determinging the clustering
> model of a dataset.
>  
> bicvals <- EMclust( hdata, 7)
>  sumry1 <- summary(bicvals, hdata,7) # summary object for emclust()
>  print(sumry1)
> 
>  This set of code gives the following output
>  
> classification table:
>  
> 1 2 3 4 5 6 7 
> 1 1 1 4 1 1 1 
>  
> which I think means there is 1 gene in the 1st cluster...1 gene in the
> 2nd cluster , 4 genes in the 4th cluster and so on....But I need to know
> which gene is in which cluster.
>  
> Is there any way to find that out....
>  

Here's an example:

R> data(iris)
R> irisMatrix <- as.matrix(iris[,1:4])
R> irisBic <- EMclust(irisMatrix)
R> irisBest <- summary(irisBic, irisMatrix)
R> names(irisBest)
  [1] "bic"            "options"
  [3] "classification" "uncertainty"
  [5] "n"              "d"
  [7] "G"              "z"
  [9] "mu"             "sigma"
[11] "decomp"         "pro"
[13] "loglik"         "Vinv"
[15] "modelName"
R> irisBest$classification
   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
  [23] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
  [45] 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [67] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [89] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[111] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[133] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
R>

Hope this helps,

Sundar



From spencer.graves at pdf.com  Sun Nov 16 18:21:44 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 16 Nov 2003 09:21:44 -0800
Subject: [R] SE of ANOVA (aov) with repeated measures and a
	bewtween-subject factor
In-Reply-To: <20031116162734.42740.qmail@web10009.mail.yahoo.com>
References: <20031116162734.42740.qmail@web10009.mail.yahoo.com>
Message-ID: <3FB7B228.5060607@pdf.com>

Have you looked at Pinhiero and Bates (2000) Mixed-Effects Models in S 
and S-Plus (Springer)?  Bates and his graduate students, including 
Pinhiero, wrote "lme".  This book has good examples that helped me solve 
problems like this. 

hope this helps.  spencer graves

Karl Knoblick wrote:

>Hallo!
>
>I have data of the following design: 
>NSubj were measured at Baseline (visit 1) and at 3
>following time points (visit 2, visit 3, visit 4).
>There is or is not a treatment.
>
>Most interesting is the question if there is a
>difference in treatment between the results of visit 4
>and baseline. (The other time points are also of
>interest.) The level of significance is alpha=0.0179
>(because of an interim analysis).
>
>My questions:
>
>1) I prefer calculating s model with the differences
>to baseline as Y:
>Y ~ treat*visit + Error(treat:id)
>where treat is the treatment and id is the subject's
>id
>Other possibilities are:
>a) Y0 ~ treat*visit + v1 + Error(treat:id)
>where Y0 are the results (visit 2 to visit 4) and v1
>is the result of visit 1 as covariate
>b) Calculating a t-test with the results of visit 4
>and visit 1
>What's best?
>
>2) When calculating a model (ANOVA) I have to
>calculate the treatment effect (easy with coef(...)).
>But how can I get the standard errors, or more exactly
>the 98.21% confidence 
>
>intervals? 
>- lm() does not work with an Error()-term in the
>formula
>- using lme(), I can not reproduce results e.g. of an
>example of a text book ((Bortz,
>Statistik f?r Sozialwissenschaftler, p.412, 3.
>Auflage, see at the very end)
>
>Here what I have done (with random data):
>
>  # Random generation of data
>  NSubj<-30 # No. of subjects
>  set.seed(1234)
>  id<-c(1:NSubj) # ID of subjects
>  treat<-runif(NSubj, min=0, max=1) > 0.5 # Treatment
>  v1<-runif(NSubj, min=0, max=1) # Result visit 1
>Baseline)
>  v2<-runif(NSubj, min=0, max=1) # Result visit 2
>  v3<-runif(NSubj, min=0, max=1) # Result visit 3
>  v4<-runif(NSubj, min=0, max=1) # Result visit 4
>
>  # Making the data frame
>  Y<-c(v2-v1,v3-v1,v4-v1) # Taking the differences to
>baseline (visit 1)
>  id<-as.factor(rep(id, 3))
>  treat<-as.factor(rep(treat, 3))
>  visit<-as.factor(rep(2:4, each=NSubj))
>  df<-data.frame(id, treat, visit, Y)
>
>  # Analysis
>  df.aov <- aov(Y ~ treat*visit + Error(treat:id),
>data=df)
>  summary(df.aov)
>  coef(df.aov)
>
>How can I get the SE?
>
>Hope somebody can help!
>
>Karl
>
>Example (Bortz, Statistik f?r Sozialwissenschaftler,
>p.412, 3. Auflage), two-factorial 
>
>analysis of variance with repeated measurements:
>
> Subject b1 b2 b3
>al 1 56 52 48
>al 2 57 54 46
>al 3 55 51 51
>al 4 58 51 50
>al 5 54 53 46
>a2 1 54 50 49
>a2 2 53 49 48
>a2 3 56 48 52
>a2 4 52 52 50
>a2 5 55 51 46
>a3 1 57 49 50
>a3 2 55 51 47
>a3 3 56 48 51
>a3 4 58 50 48
>a3 5 58 46 52
>
>The factors are A (a1,a2,a3) and B (b1,b2,b3); 5
>subjects. Factor A is
>kind of training (creativity) for the subjacts and
>factor B is before,
>during and after training.
>
>The results of the example:
>
>Source SS df sigma2 F
>A 9.9 2 4.95 3.87
>Subject in sample 15.4 12 1.28
>between subjects 25.3 14
>B 370.7 2 185.35 44.03 (**)
>AxB 45.6 4 11.4 2.71
>BxSubject 101.0 24 4.21
>within subjects 517.3 30
>Total 542.6 44
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From sundar.dorai-raj at pdf.com  Sun Nov 16 18:32:43 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 16 Nov 2003 11:32:43 -0600
Subject: [R] Other fixed-width fonts like courier?
In-Reply-To: <000001c3ac4b$2f652bb0$0b01a8c0@wub73>
References: <000001c3ac4b$2f652bb0$0b01a8c0@wub73>
Message-ID: <3FB7B4BB.9010204@pdf.com>



Andreas Lackner wrote:

> Hi,
> 
> does R have any other fixed width fonts next to courier (font=11)?
> 
> Thanks Andreas
> 
> 

(Please create a new email message when posting to the list rather than 
replying to a previous message and simply changing the subject line.)

As for your question, take a look at

etc/Rdevga

in the directory where R is installed and take note of the comments in 
that file. Which fonts you can use depends on which fonts are installed 
on your computer.

Hope this helps,

Sundar



From SBroyl at lsuhsc.edu  Sun Nov 16 18:26:54 2003
From: SBroyl at lsuhsc.edu (Broyles, Stephanie)
Date: Sun, 16 Nov 2003 11:26:54 -0600
Subject: [R] na.rm default
Message-ID: <FFBCB2526662D411A17600B0D03D55F00A07BB3A@lsumc-med-exch2.med.lsuhsc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031116/a1f85f26/attachment.pl

From MSchwartz at medanalytics.com  Sun Nov 16 19:16:12 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 16 Nov 2003 12:16:12 -0600
Subject: [R] na.rm default
In-Reply-To: <FFBCB2526662D411A17600B0D03D55F00A07BB3A@lsumc-med-exch2.med.lsuhsc.edu>
References: <FFBCB2526662D411A17600B0D03D55F00A07BB3A@lsumc-med-exch2.med.lsuhsc.edu>
Message-ID: <1069006572.4347.418.camel@localhost.localdomain>

On Sun, 2003-11-16 at 11:26, Broyles, Stephanie wrote:
> Is there a way to set "na.rm=TRUE" as a default, so that this does not have
> to be re-specified for all of the functions requiring this option?
> 
> Thanks in advance,
> Stephanie Broyles
> sbroyl at lsuhsc.edu 


I will stand to be corrected on this, but if you are referring to the
use of "na.rm = TRUE" in functions like mean(), etc. then not likely.

If you look at the code for those functions, they do not check R
options() settings (such as na.action) or other mechanisms that would
allow you to change that behavior globally. The handling of NA's in the
code is entirely dependent upon the setting of the 'na.rm' argument to
the function, which has a default of FALSE.

The code snippet (ie. from mean.default() ) for this is:

if (na.rm)
  x <- x[!is.na(x)]

which occurs prior to the calculation.

That being said, you can always create your own wrapper functions to
those:

MyMean <- function(x)
{
  mean(x, na.rm = TRUE)
}

HTH,

Marc Schwartz



From dieter.menne at menne-biomed.de  Sun Nov 16 19:23:55 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sun, 16 Nov 2003 19:23:55 +0100
Subject: [R] prevent conversion to factors in aggregate?
Message-ID: <JLEPLGAANFCEAEDCAGJNKEMHCGAA.dieter.menne@menne-biomed.de>

Spencer Graves wrote

>>I don't know how to prevent aggregate from making factors of everything,
>>but the following shows how to cast them back into what you want:
....
> DF.$bch <- as.character(DF.$b)
> DF.$dn <- as.numeric(as.character(DF.$d))
> sapply(DF., class)
...

----
help(factor) suggests:

"To ?revert? a factor f to its original numeric values,
as.numeric(levels(f))[f] is recommended and slightly more efficient than
as.numeric(as.character(f)). "

And in package Hmisc there is a function "summarize" that does not touch
non-factors.

Dieter Menne



From andreas.lackner at wi-wiss.uni-goettingen.de  Sun Nov 16 19:42:27 2003
From: andreas.lackner at wi-wiss.uni-goettingen.de (Andreas Lackner)
Date: Sun, 16 Nov 2003 19:42:27 +0100
Subject: [R] Legend position in barplots
Message-ID: <000001c3ac71$652150f0$0b01a8c0@wub73>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031116/92970a66/attachment.pl

From jeff.hamann at forestinformatics.com  Sun Nov 16 19:46:50 2003
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Sun, 16 Nov 2003 10:46:50 -0800
Subject: [R] Re: prevent conversion to factors in aggregate?
References: <JLEPLGAANFCEAEDCAGJNKEMHCGAA.dieter.menne@menne-biomed.de>
Message-ID: <001901c3ac72$0860b2b0$0a00a8c0@rodan>

Ah ha! That's perfect. It would have taken me forever to get that. And I'm
back in business....

Thanks,
Jeff.


----- Original Message ----- 
From: "Dieter Menne" <dieter.menne at menne-biomed.de>
To: <spencer.graves at pdf.com>; <jeff.hamann at forestinformatics.com>; "R-Help"
<r-help at hypatia.math.ethz.ch>
Sent: Sunday, November 16, 2003 10:23 AM
Subject: prevent conversion to factors in aggregate?


> Spencer Graves wrote
>
> >>I don't know how to prevent aggregate from making factors of everything,
> >>but the following shows how to cast them back into what you want:
> ....
> > DF.$bch <- as.character(DF.$b)
> > DF.$dn <- as.numeric(as.character(DF.$d))
> > sapply(DF., class)
> ...
>
> ----
> help(factor) suggests:
>
> "To "revert" a factor f to its original numeric values,
> as.numeric(levels(f))[f] is recommended and slightly more efficient than
> as.numeric(as.character(f)). "
>
> And in package Hmisc there is a function "summarize" that does not touch
> non-factors.
>
> Dieter Menne
>
>



From MSchwartz at medanalytics.com  Sun Nov 16 19:57:57 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 16 Nov 2003 12:57:57 -0600
Subject: [R] Legend position in barplots
In-Reply-To: <000001c3ac71$652150f0$0b01a8c0@wub73>
References: <000001c3ac71$652150f0$0b01a8c0@wub73>
Message-ID: <1069009076.4347.423.camel@localhost.localdomain>

On Sun, 2003-11-16 at 12:42, Andreas Lackner wrote:
> Hello!

> Is there a way to change the position of the legend created in a barplot
> from the right side of the plot to the left side or somewhere else?
> 
> Thanks


Yes...instead of specifying 'legend.text' in barplot, use the legend()
function, which will enable you to specify the coordinates and other
details for the legend.

See ?legend for more information.

HTH,

Marc Schwartz



From bernd.holleczek at gmx.de  Sun Nov 16 20:18:33 2003
From: bernd.holleczek at gmx.de (Bernd Holleczek)
Date: Sun, 16 Nov 2003 20:18:33 +0100 (MET)
Subject: [R] Error when calling a dll procedure
Message-ID: <19817.1069010313@www62.gmx.net>

Dear experts,

I am a beginner in R and try to build dlls (Win XP, MinGW, R 1.7.1).
So far, I have managed to create and to use some dlls with C code which
worked properly.

Now I am stuck with a dll containing C++ code.

I have included some part of the source code (of an implementation of a
function to find all primes below a given numeric value -> its just an exercises
to get familar with R/C++).

>#include <vector>
>
>using namespace std;
>
>extern "C" {
>#include <R.h>
>#include <Rdefines.h>
>}
>
>SEXP getPrimes(SEXP a)
>{ 
>SEXP c;
>
 
//my implementation

>
>return c;
>}

Here is the output (hopefully without any typos) of the process building the
dll:

>Rcmd SHLIB Primes.cc
>making Primes.d from Primes.c
>g++ -IE:\programs\R\rw1071\src\include -Wall -02 -c Primes.cc  -o Primes.o
>ar cr Primes.a *.o
>ranlib Primes.a
>g++ --shared -s -o Primes.dll Primes.def Primes.a
-LE:\programs\R\rw1071\src\gnuwin32 -lg2c -lR


My PROBLEM is now that I can load the dll (no error message), but not access
the function "getPrimes". Here is some output of the R console:

>> dyn.load("E:\\R_work5\\Primes")
>> .Call("getPrimes", 100)
>Error in .Call("getPrimes", 100) : .Call function name not in load table


Has anybody been confronted with the same kind of difficulties?
I'll appreciate suggestions on how to fix the problem.
Thanks.

Regards,

Bernd Holleczek



-- 
Bernd Holleczek <bernd.holleczek at gmx.de>



From duncan at research.bell-labs.com  Sun Nov 16 20:23:52 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Sun, 16 Nov 2003 14:23:52 -0500
Subject: [R] Error when calling a dll procedure
In-Reply-To: <19817.1069010313@www62.gmx.net>;
	from bernd.holleczek@gmx.de on Sun, Nov 16, 2003 at 08:18:33PM
	+0100
References: <19817.1069010313@www62.gmx.net>
Message-ID: <20031116142352.A16627@jessie.research.bell-labs.com>

Hi Bernd.

  When you compile the code with a C++ compiler, it "mangles" the name
getPrimes into something that has type information (to allow other
routines with the same name but different signatures).  You need to
tell the compiler not to do this. And you use extern "C" to declare
it as a regular C symbol that should not be mangled.

  extern "C" {

   SEXP getPrimes(SEXP);
  }


Then recompile and all should be well.

 D.


Bernd Holleczek wrote:
> Dear experts,
> 
> I am a beginner in R and try to build dlls (Win XP, MinGW, R 1.7.1).
> So far, I have managed to create and to use some dlls with C code which
> worked properly.
> 
> Now I am stuck with a dll containing C++ code.
> 
> I have included some part of the source code (of an implementation of a
> function to find all primes below a given numeric value -> its just an exercises
> to get familar with R/C++).
> 
> >#include <vector>
> >
> >using namespace std;
> >
> >extern "C" {
> >#include <R.h>
> >#include <Rdefines.h>
> >}
> >
> >SEXP getPrimes(SEXP a)
> >{ 
> >SEXP c;
> >
>  
> //my implementation
> 
> >
> >return c;
> >}
> 
> Here is the output (hopefully without any typos) of the process building the
> dll:
> 
> >Rcmd SHLIB Primes.cc
> >making Primes.d from Primes.c
> >g++ -IE:\programs\R\rw1071\src\include -Wall -02 -c Primes.cc  -o Primes.o
> >ar cr Primes.a *.o
> >ranlib Primes.a
> >g++ --shared -s -o Primes.dll Primes.def Primes.a
> -LE:\programs\R\rw1071\src\gnuwin32 -lg2c -lR
> 
> 
> My PROBLEM is now that I can load the dll (no error message), but not access
> the function "getPrimes". Here is some output of the R console:
> 
> >> dyn.load("E:\\R_work5\\Primes")
> >> .Call("getPrimes", 100)
> >Error in .Call("getPrimes", 100) : .Call function name not in load table
> 
> 
> Has anybody been confronted with the same kind of difficulties?
> I'll appreciate suggestions on how to fix the problem.
> Thanks.
> 
> Regards,
> 
> Bernd Holleczek
> 
> 
> 
> -- 
> Bernd Holleczek <bernd.holleczek at gmx.de>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From bernd.holleczek at gmx.de  Sun Nov 16 20:26:38 2003
From: bernd.holleczek at gmx.de (Bernd Holleczek)
Date: Sun, 16 Nov 2003 20:26:38 +0100 (MET)
Subject: [R] Error when calling a dll procedure
References: <19817.1069010313@www62.gmx.net>
Message-ID: <26183.1069010798@www55.gmx.net>

Dear experts,

I am a beginner in R and try to build dlls (Win XP, MinGW, R 1.7.1).
So far, I have managed to create and to use some dlls with C code which
worked properly.

Now I am stuck with a dll containing C++ code.

I have included some part of the source code (of an implementation of a
function to find all primes below a given numeric value -> its just an
exercises
to get familar with R/C++).

>#include <vector>
>
>using namespace std;
>
>extern "C" {
>#include <R.h>
>#include <Rdefines.h>
>}
>
>SEXP getPrimes(SEXP a)
>{ 
>SEXP c;
>
 
//my implementation

>
>return c;
>}

Here is the output (hopefully without any typos) of the process building the
dll:

>Rcmd SHLIB Primes.cc
>making Primes.d from Primes.c
>g++ -IE:\programs\R\rw1071\src\include -Wall -02 -c Primes.cc  -o Primes.o
>ar cr Primes.a *.o
>ranlib Primes.a
>g++ --shared -s -o Primes.dll Primes.def Primes.a
-LE:\programs\R\rw1071\src\gnuwin32 -lg2c -lR


My PROBLEM is now that I can load the dll (no error message), but not access
the function "getPrimes". Here is some output of the R console:

>> dyn.load("E:\\R_work5\\Primes")
>> .Call("getPrimes", 100)
>Error in .Call("getPrimes", 100) : .Call function name not in load table


Has anybody been confronted with the same kind of difficulties?
I'll appreciate suggestions on how to fix the problem.
Thanks.

Regards,

Bernd Holleczek

-- 
Bernd Holleczek <bernd.holleczek at gmx.de>



From ripley at stats.ox.ac.uk  Sun Nov 16 20:48:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Nov 2003 19:48:54 +0000 (GMT)
Subject: [R] Error when calling a dll procedure
In-Reply-To: <26183.1069010798@www55.gmx.net>
Message-ID: <Pine.LNX.4.44.0311161942470.16531-100000@gannet.stats>

You seem to have asked that twice in 8 minutes!

See `Writing R Extensions', the section on `Interfacing C++ code'.
Or section 7.5 of the rw-FAQ.  There are worked examples there: please do 
not ignore the R documentation.

On Sun, 16 Nov 2003, Bernd Holleczek wrote:

> I am a beginner in R and try to build dlls (Win XP, MinGW, R 1.7.1).
> So far, I have managed to create and to use some dlls with C code which
> worked properly.
> 
> Now I am stuck with a dll containing C++ code.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.murrell at auckland.ac.nz  Sun Nov 16 21:07:29 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 17 Nov 2003 09:07:29 +1300
Subject: [R] Initial size of graphics window
References: <m365hmzgnl.fsf@wzocher.dialin.t-online.de>
	<3FB5758A.7020100@kernstat.com>
Message-ID: <3FB7D901.3020108@stat.auckland.ac.nz>

Hi


Remington, Richard wrote:
> Wolfgang Zocher wrote:
> 
>> Hi,
>>
>> using par() a window is opened which is too large for my monitor. Is 
>> there any
>> chance to change the size of this window?
>> Thanks,
>> Wolfgang
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> par(din=c(?,?))
> 
> Alternatively, if you don't need to use par() and are using Microsoft 
> Windows, see
> 
> ?win.graph
> 
> Example, 4 x 4 inch window
> 
> win.graph(width = 4, height = 4)


The first time you use a graphics command, R automatically opens a 
graphics device (what sort of device you get is controlled by 
options(device=?)).  This device will open with default size settings. 
If you want to control the size of the device, you need to explicitly 
open the device first and specify the size you want (as in Richard's 
win.graph example).  par("din") can only be used to query the current 
size of a device;  it cannot be used to set/modify the size of a device.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From nirmalg at psu.edu  Sun Nov 16 23:17:29 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Sun, 16 Nov 2003 17:17:29 -0500
Subject: [R] DOE support in R and fac.design
Message-ID: <3FB7F779.9040409@psu.edu>

Hi,

I've searched through the contributed packages and found conf.design 
which supports factorial design generation - is there any way to specify 
the values of the levels in the functions in this library? Currently the 
default for 2 level designs are the levels 0 and 1. Reason I ask is I'd 
like to create a Central Composite design and to do this by appending to 
a factorial design, it would be easiest if the levels of the factorial 
were at -1 and 1... (so I can add levels such as 0, -2 and 2)

This brings me to my second question - is there any support for design 
creation of some of the common designs like the CCD?

And finally - in the help for conf.design, in the "See Also" section, 
there's a fac.design mentioned but I can't seem to find it anywhere.. is 
this function available and what does it do?

I would appreciate it if you could please cc me on the reply.

Thanks,
nirmal



From mn216 at columbia.edu  Sun Nov 16 23:19:29 2003
From: mn216 at columbia.edu (Murad Nayal)
Date: Sun, 16 Nov 2003 17:19:29 -0500
Subject: [R] graphics reset
Message-ID: <3FB7F7F1.60120F23@columbia.edu>



Hello,

Is there a specific command to clear the graphics window. On occasion I
need to construct plots using commands that don't clear the graphics
window (like text, lines and points etc.) -only- and hence need to clear
the graphics completely before hand. 

also, is there a way to restore the graphics parameters to default
values, say in these cases where you forgot to save the original values
and want to restore the graphics to some sane state after a long R
session.

many thanks


-- 
Murad Nayal M.D. Ph.D.
Department of Biochemistry and Molecular Biophysics
College of Physicians and Surgeons of Columbia University
630 West 168th Street. New York, NY 10032
Tel: 212-305-6884	Fax: 212-305-6926



From ripley at stats.ox.ac.uk  Sun Nov 16 23:51:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Nov 2003 22:51:42 +0000 (GMT)
Subject: [R] DOE support in R and fac.design
In-Reply-To: <3FB7F779.9040409@psu.edu>
Message-ID: <Pine.LNX.4.44.0311162245290.16964-100000@gannet.stats>

On Sun, 16 Nov 2003, Nirmal Govind wrote:

> I've searched through the contributed packages and found conf.design 
> which supports factorial design generation - is there any way to specify 
> the values of the levels in the functions in this library? Currently the 
> default for 2 level designs are the levels 0 and 1. Reason I ask is I'd 
> like to create a Central Composite design and to do this by appending to 
> a factorial design, it would be easiest if the levels of the factorial 
> were at -1 and 1... (so I can add levels such as 0, -2 and 2)

It is very easy to change the levels of a factor by levels<-(): see its 
help page.

> This brings me to my second question - is there any support for design 
> creation of some of the common designs like the CCD?

charge-coupled device?  Probably central composite design -- not that I 
know of.

> And finally - in the help for conf.design, in the "See Also" section, 
> there's a fac.design mentioned but I can't seem to find it anywhere.. is 
> this function available and what does it do?

conf.design was ported from S, which does have fac.design.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Mon Nov 17 00:24:56 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 16 Nov 2003 18:24:56 -0500
Subject: [R] graphics reset
In-Reply-To: <3FB7F7F1.60120F23@columbia.edu>
References: <3FB7F7F1.60120F23@columbia.edu>
Message-ID: <li1grvokmu14qp5rifoav9nl1d2k89tlck@4ax.com>

On Sun, 16 Nov 2003 17:19:29 -0500, you wrote:

>
>
>Hello,
>
>Is there a specific command to clear the graphics window. On occasion I
>need to construct plots using commands that don't clear the graphics
>window (like text, lines and points etc.) -only- and hence need to clear
>the graphics completely before hand. 

frame() or plot.new() will move to the next frame.  By default,
there's only one frame, but calls like par(mfrow=c(2,2)) set up more
frames on a single page.

>also, is there a way to restore the graphics parameters to default
>values, say in these cases where you forgot to save the original values
>and want to restore the graphics to some sane state after a long R
>session.

The easiest way is to use dev.off() to close the graphics window and
then start plotting to open a fresh new one, with default settings.

Duncan Murdoch



From nirmalg at psu.edu  Mon Nov 17 00:43:10 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Sun, 16 Nov 2003 18:43:10 -0500
Subject: [R] DOE support in R and fac.design
In-Reply-To: <Pine.LNX.4.44.0311162245290.16964-100000@gannet.stats>
References: <Pine.LNX.4.44.0311162245290.16964-100000@gannet.stats>
Message-ID: <3FB80B8E.6080501@psu.edu>

Thanks for your reply Prof. Ripley.

> It is very easy to change the levels of a factor by levels<-(): see its 
> help page.

Great.. thanks.

> charge-coupled device?  Probably central composite design -- not that I 
> know of.

Yes, I meant central composite design ...

> conf.design was ported from S, which does have fac.design.

I see... it may be helpful if this is mentioned next to fac.design so 
that the user doesn't go searching for it in R...

Thanks,
nirmal



From yuanji at mdanderson.org  Mon Nov 17 02:16:42 2003
From: yuanji at mdanderson.org (yuanji@mdanderson.org)
Date: Sun, 16 Nov 2003 19:16:42 -0600
Subject: [R] gradient option in 'nlm' function
Message-ID: <OFF95D0986.16EE0888-ON86256DE1.000705A6-86256DE1.000705AB@mdacc.tmc.edu>

<FONT face="Default Sans Serif, Verdana, Arial, Helvetica, sans-serif" size=2><DIV>Dear list members,</DIV><DIV>&nbsp;</DIV><DIV>I am trying to use "nlm" function to maximize a mixture likelihood of beta densities. There are five unknown parameters in the likelihood. Since I can get the analytic gradient, I attach the "gradient" attribute in my target likehood function. The code is as the following </DIV><DIV>&nbsp;</DIV><DIV>&nbsp;target &lt;- function(x)</DIV><DIV>&nbsp;{ resp &lt;- ....</DIV><DIV>&nbsp;&nbsp; grad &lt;- rep(0,5) ## I have 5 paramters</DIV><DIV>&nbsp;&nbsp; grad[1] &lt;- ...; grad[2] &lt;- ...; grad[3] &lt;- ...; grad[4] &lt;- ...; grad[5] &lt;- ...</DIV><DIV>&nbsp;&nbsp; attr(resp, "gradient") &lt;- grad</DIV><DIV>&nbsp;&nbsp; resp<BR>&nbsp;}</DIV><DIV>nlm(targ, c(1,2,3,4,5))</DIV><DIV>The R gave me this error message</DIV><DIV>&nbsp;</DIV><DIV>VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV</DIV><DIV>"Error in nlm(targ, c(1,2,3,4,5)) : probable coding error in analytic gradient"</DIV><DIV>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</DIV><DIV>I ran my code for defining gradient separately, and there seemed to be no coding error. I provided other options for nlm() function and it gave me the same error message. I removed the gradient part and let nlm() do the numerical derivative, it ran but the algorithm was not converging. </DIV><DIV>&nbsp;</DIV><DIV>I want to know if nlm can handle multiple parameters problems, and if yes, was there any error in my code? How do I properly provide the gradient for my function? </DIV><DIV>&nbsp;</DIV><DIV>Thanks a lot,</DIV><DIV>&nbsp;</DIV><DIV>&nbsp;</DIV><DIV>Yuan&nbsp;Ji,&nbsp;Ph.D.<BR><BR>############################################<BR>Assistant&nbsp;Professor<BR>Department&nbsp;of&nbsp;Bistatistics<BR>The&nbsp;University&nbsp;of&nbsp;Texas&nbsp;M.D.&nbsp;Anderson&nbsp;Cancer&nbsp;Center<BR>1515&nbsp;Holcombe&nbsp;Blvd.&nbsp;-&nbsp;Unit&nbsp;447<BR>Houston,&nbsp;TX&nbsp;77030-4009<BR>(713)794-4153<BR>############################################<BR></DIV></FONT>

From gopal_a00 at hotmail.com  Mon Nov 17 04:25:14 2003
From: gopal_a00 at hotmail.com (Gopal Annasundaram)
Date: Sun, 16 Nov 2003 19:25:14 -0800
Subject: [R] Newbie question
Message-ID: <BAY99-DAV20Hjon60TM00000b28@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031116/28c6c3c4/attachment.pl

From edd at debian.org  Mon Nov 17 04:41:41 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 16 Nov 2003 21:41:41 -0600
Subject: [R] Newbie question
In-Reply-To: <BAY99-DAV20Hjon60TM00000b28@hotmail.com>
References: <BAY99-DAV20Hjon60TM00000b28@hotmail.com>
Message-ID: <20031117034141.GA28341@sonny.eddelbuettel.com>

On Sun, Nov 16, 2003 at 07:25:14PM -0800, Gopal Annasundaram wrote:
> I'm trying to find a good open source software to do sales forecasting using Holt Winters and Box Jenkins time series algorithm. Somebody pointed me that R is the best open source available for statistical computing. Are there functions to do Holt Winters and Box Jenkins time series prediction in R? If there is none, can some one point me a good GNU/freeware to do the sales forecasting using the above algorithms?

Try "help(library=ts)" once you have a prompt. R does both Holt-Winters and
Arima.  Using ts objects is not entirely trivial, though.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From spencer.graves at pdf.com  Mon Nov 17 04:47:44 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 16 Nov 2003 19:47:44 -0800
Subject: [R] Newbie question
In-Reply-To: <BAY99-DAV20Hjon60TM00000b28@hotmail.com>
References: <BAY99-DAV20Hjon60TM00000b28@hotmail.com>
Message-ID: <3FB844E0.1000409@pdf.com>

R can apparently handle it, according to "www.r-project.org" -> search 
-> "R site search". 

hope this helps.  spencer graves

Gopal Annasundaram wrote:

>I'm trying to find a good open source software to do sales forecasting using Holt Winters and Box Jenkins time series algorithm. Somebody pointed me that R is the best open source available for statistical computing. Are there functions to do Holt Winters and Box Jenkins time series prediction in R? If there is none, can some one point me a good GNU/freeware to do the sales forecasting using the above algorithms?
>
>
>Appreciate your help.
>
>Thanks,
>Gopal
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From ramasamya at gis.a-star.edu.sg  Mon Nov 17 06:24:16 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Mon, 17 Nov 2003 13:24:16 +0800
Subject: [R] A suggestion regarding multiple replies
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D560A00FF@BIONIC.biopolis.one-north.com>

I like the list the way it is and am grateful for all the email I get
everyday. If an alternative is required, perhaps forums (e.g.
http://forums.devshed.com/) could be considered but then everyone has to
make an effort to visit the websites instead of getting the questions
delivered in their mailbox.

--
Adaikalavan Ramasamy 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
Ted.Harding at nessie.mcc.ac.uk
Sent: Saturday, November 15, 2003 8:31 AM
To: partha_bagchi at hgsi.com
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] A suggestion regarding multiple replies


On 14-Nov-03 partha_bagchi at hgsi.com wrote:
> Please don't take this the wrong way. There are a lot of extremely 
> helpful people who subscribe to r-help.
> 
> I was wondering if it is time to adopt a strategy a-la Splus help 
> whereby people reply to the author and the author summarizes all the 
> replies?
> 
> Just a thought and have a good weekend.
> Partha

This has its merits, in reducing the load on the list and its readers.

However, personally I like the way questions are bounced around between
people. and answers are devoped "conversationally", as it were, and I
think a lot would be lost if this were not to happen. On the whole, I
welcome the load!

R strikes me as somewhat special amongst languages in that there are a
lot of hidden subtleties, which sometimes are only pointed out by the
few people who are really familiar with them. At present this happens
on-list and usually very promptly, and this timely intervention puts
wrong ideas right before they get too deeply embedded; this benefit
would tend to vanish if a "summarise to the list" policy were adopted.

Of course there are some cases where a simple answer can be sent
directly to a person asking a simple question, but my experience is that
I have learned a lot about R by watching these dynamic discussions. I
hope they will continue!

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 15-Nov-03                                       Time: 00:30:42
------------------------------ XFMail ------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Tom.Mulholland at health.wa.gov.au  Mon Nov 17 10:04:21 2003
From: Tom.Mulholland at health.wa.gov.au (Mulholland, Tom)
Date: Mon, 17 Nov 2003 17:04:21 +0800
Subject: [R] A suggestion regarding multiple replies
Message-ID: <74E242B6968AA0469B632C5A3EFC1EFD03D56FFC@nt207mesep.corporate.hdwa.health.wa.gov.au>

As with most of the replies so far, I enjoy the way the list works.

A couple of observations however are that it is evident that off list
replies already happen and imho more importantly is the fact that
initially quite straightforward queries can turn into something much
more interesting. I find this type of query to be among the most
helpful. Partly because they tend to deal with issues that I think I
have already got covered. An example of this was the use of asp=1 in a
plot to keep the aspect ratio correct. One might argue that having to go
to plot.default to find this reference rather than in plot was the
problem, but what it did to me was to ensure that I follow through
deeper and deeper into the workings of R. There are times when it is
only after you have found the answer that you realise why the answer had
to be where it was (as with plot.default) and that's when the real
learning begins.

I use the list as a way of exploring different aspects of R (often those
that I have no direct need of at the time.)

________________________________________________
 
Tom Mulholland
Senior Policy Officer
WA Country Health Service
Tel: (08) 9222 4062
 

-----Original Message-----
From: partha_bagchi at hgsi.com [mailto:partha_bagchi at hgsi.com] 
Sent: Saturday, 15 November 2003 6:02 AM
To: r-help at stat.math.ethz.ch
Subject: [R] A suggestion regarding multiple replies


Please don't take this the wrong way. There are a lot of extremely
helpful 
people who subscribe to r-help. 

I was wondering if it is time to adopt a strategy a-la Splus help
whereby 
people reply to the author and the author summarizes all the replies?

Just a thought and have a good weekend.
Partha

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

The contents of this e-mail transmission are confidential an...{{dropped}}



From angel_lul at hotmail.com  Sun Nov 16 22:36:21 2003
From: angel_lul at hotmail.com (Angel)
Date: Sun, 16 Nov 2003 22:36:21 +0100
Subject: [R] ?for
Message-ID: <Law11-OE57gfcssxfJU00004b67@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031116/4652cb1c/attachment.pl

From ripley at stats.ox.ac.uk  Mon Nov 17 10:46:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Nov 2003 09:46:30 +0000 (GMT)
Subject: [R] ?for
In-Reply-To: <Law11-OE57gfcssxfJU00004b67@hotmail.com>
Message-ID: <Pine.LNX.4.44.0311170943140.25420-100000@gannet.stats>

You have typed a syntactically incomplete statement: this is explained in 
?help.

Hint: ?"for" and help("for") work.

On Sun, 16 Nov 2003, Angel wrote:

> I have always been intrigued by why ?for (or ?if,?while,etc) leave R
> wanting for more:
> > ?for
> + 
> I know the help for these is in ?Control, but I sometimes make the
> mistake of typing ?for instead. What is R expecting me to say to finish
> the statement?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From optimisation1.stagiaire at lagardere-active.com  Mon Nov 17 11:23:41 2003
From: optimisation1.stagiaire at lagardere-active.com (optimisation1.stagiaire@lagardere-active.com)
Date: Mon, 17 Nov 2003 11:23:41 +0100
Subject: [R] CLARA
Message-ID: <OF22D08535.79B267A4-ONC1256DE1.0037B132-C1256DE1.00385E1F@e-c-s.fr>






I need informations about the clara routine. The on-line doc say that the
argument stand is a logical, indicating if the measurements in x are
standardized before calculating the dissimilarities. Measurements are
standardized for each variable (column), by subtracting the variable's mean
value and dividing by the variable's mean absolute deviation. If we note
STAND = TRUE, I suppose that the data will not be standardized before
clustering. On the contrary, STAND = FALSE means that the data will be
standardized before clustering.
Each sub-dataset is partitioned into k clusters using the same algorithm as
in pam. But the pam routine argument stand is a logical; if true, the
measurements in x are standardized before calculating the dissimilarities.
Measurements are standardized for each variable (column), by subtracting
the variable's mean value and dividing by the variable's mean absolute
deviation. If x is already a dissimilarity matrix, then this argument will
be ignored. If we note STAND = TRUE, I suppose that the data will be
standardized.

There is a big difference as clara and pam use nearly the same algorithm.

I need to use clara because I have a large dataset. Could help me about the
argument stand ? May I have to standardize my datas with excel before ? If
yes, what I have to write : STAND = ?? ?

Best regards,
Cordialement,

R?gis CHARIGNON
Service Optimisation
Direct Line: +33 (0)1 47 23 21 44
_________________________
Lagard?re Active Publicit?
28, rue Fran?ois 1er,  75008 Paris

 http://www.lagardere-active-pub.com


******************************************************************************************************************************************************************
Attention : le present message et toutes les pieces jointes (le "message") sont confidentiels et etablis a l'attention exclusive du ou des destinataire(s) 
indique(s). Toute autre diffusion ou utilisation non autorisee est interdite. Si vous recevez ce message par erreur, veuillez immediatement en avertir 
l'expediteur par e-mail en retour, detruire le message et vous abstenir de toute reference aux informations qui y figurent afin d'eviter les sanctions 
attachees a la divulgation et a l'utilisation d'informations confidentielles. Les messages electroniques sont susceptibles d'alteration. Lagardere SCA 
et ses filiales declinent toute responsabilite en cas d'alteration ou de falsification du present message.



From HStevens at muohio.edu  Mon Nov 17 11:37:22 2003
From: HStevens at muohio.edu (Hank Stevens)
Date: Mon, 17 Nov 2003 05:37:22 -0500
Subject: [R] Symbolic math?
Message-ID: <5.1.0.14.2.20031117051022.04e246a8@po.muohio.edu>

Hi Folks,
I am using Windows 2000 and was wondering what (Open Source) software R 
users use or might recommend for symbolic computations (aside from the ol' 
noggin, e.g., Maxima, Mathomatic) .
Thanks,
Hank

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology



From p.dalgaard at biostat.ku.dk  Mon Nov 17 11:49:37 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Nov 2003 11:49:37 +0100
Subject: [R] ?for
In-Reply-To: <Pine.LNX.4.44.0311170943140.25420-100000@gannet.stats>
References: <Pine.LNX.4.44.0311170943140.25420-100000@gannet.stats>
Message-ID: <x2n0av8e2m.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> You have typed a syntactically incomplete statement: this is explained in 
> ?help.
> 
> Hint: ?"for" and help("for") work.

Further hint: ? is an operator, syntactically similar to + and -. You
can apply operators to the result of a for loop. Consider for example

x <- 1; - for (i in 1:10) x <- x * i

(? has special semantics, but that is not noticed at parse time).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From alain.guerreau at libertysurf.fr  Mon Nov 17 12:15:23 2003
From: alain.guerreau at libertysurf.fr (guerreau)
Date: Mon, 17 Nov 2003 12:15:23 +0100
Subject: [R] function identify()
Message-ID: <000a01c3acfc$33d44030$371624d5@jetzt0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031117/b1309464/attachment.pl

From ahenningsen at agric-econ.uni-kiel.de  Mon Nov 17 12:37:25 2003
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Mon, 17 Nov 2003 12:37:25 +0100
Subject: [R] Symbolic math?
In-Reply-To: <5.1.0.14.2.20031117051022.04e246a8@po.muohio.edu>
References: <5.1.0.14.2.20031117051022.04e246a8@po.muohio.edu>
Message-ID: <200311171237.25927.ahenningsen@agric-econ.uni-kiel.de>

Hi,

I sometimes use "MuPAD" (www.mupad.com). Unfortunately, it is not Open Source, 
but most versions are free of charge for non-commercial use (see http://
www.sciface.com/personal.shtml). 

Arne

On Monday 17 November 2003 11:37, Hank Stevens wrote:
> Hi Folks,
> I am using Windows 2000 and was wondering what (Open Source) software R
> users use or might recommend for symbolic computations (aside from the ol'
> noggin, e.g., Maxima, Mathomatic) .
> Thanks,
> Hank
>
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/botany/bot/henry.html
> http://www.muohio.edu/ecology
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From maechler at stat.math.ethz.ch  Mon Nov 17 12:45:11 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 17 Nov 2003 12:45:11 +0100
Subject: [R] Initial size of graphics window
In-Reply-To: <3FB7D901.3020108@stat.auckland.ac.nz>
References: <m365hmzgnl.fsf@wzocher.dialin.t-online.de>
	<3FB5758A.7020100@kernstat.com>
	<3FB7D901.3020108@stat.auckland.ac.nz>
Message-ID: <16312.46279.590287.715740@gargle.gargle.HOWL>

>>>>> "Paul" == Paul Murrell <p.murrell at auckland.ac.nz>
>>>>>     on Mon, 17 Nov 2003 09:07:29 +1300 writes:

    Paul> Hi
    Paul> Remington, Richard wrote:
    >> Wolfgang Zocher wrote:
    >> 
    >>> Hi,
    >>> 
    >>> using par() a window is opened which is too large for my monitor. Is 
    >>> there any
    >>> chance to change the size of this window?
    >> 
    >> par(din=c(?,?))
    >> 
    >> Alternatively, if you don't need to use par() and are using Microsoft 
    >> Windows, see
    >> 
    >> ?win.graph
    >> 
    >> Example, 4 x 4 inch window
    >> 
    >> win.graph(width = 4, height = 4)

    Paul> The first time you use a graphics command, R
    Paul> automatically opens a graphics device (what sort of
    Paul> device you get is controlled by options(device=?)).
    Paul> This device will open with default size settings.

Hence, if you really want the default window opened 
{by par() or plot() or ...} to become smaller, 
you could do something like

  myWin <- function() win.graph(width = 4, height = 4)
  options(device = "myWin")

and even put this into an approriate  Rprofile file, see ?Startup.

Martin



From Ulrich.Halekoh at agrsci.dk  Mon Nov 17 13:24:23 2003
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Mon, 17 Nov 2003 13:24:23 +0100
Subject: [R] confint: which method attached?
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC5AE81D@DJFPOST01.djf.agrsci.dk>




the function
confint
uses the profiling method of the function of the package MASS
 
confint.glm

even after the package has been detached!

1: might this be the intenden behavior?

2. How does the function remember its 'MASS' functionality after detaching the package?

R: 1.8.0; Windows 2000



Here is a sample program


> set.seed(7882)
> x<-rep(c(0,1),c(20,20))
> p<-plogis(2+0.1*x)
> y<-cbind(event,50-rbinom(length(p),50,p))
> xf<-factor(x)
> g<-glm(y~xf,family=binomial)
> 
> # conficence intervals according base package:
> print(confint(g))
                 2.5 %    97.5 %
(Intercept) 1.65425534 2.0266122
xf1         0.06324695 0.6282106
> 
> library(MASS)
> print(confint(g))
Waiting for profiling to be done...
                 2.5 %    97.5 %
(Intercept) 1.66398057 2.0247678
xf1         0.07341592 0.6210034
> 
> detach(package:MASS)
> print(search())
[1] ".GlobalEnv"      "package:methods" "package:ctest"   "package:mva"    
[5] "package:modreg"  "package:nls"     "package:ts"      "Autoloads"      
[9] "package:base"   
> print(confint(g))
Waiting for profiling to be done...
                 2.5 %    97.5 %
(Intercept) 1.66398057 2.0247678
xf1         0.07341592 0.6210034


Ulrich Halekoh, PhD
Institute of Agricultural Sciences, Biometry Group
8830 Tjele, Denmark,
ulrich.halekoh at agrsci.dk



From baron at psych.upenn.edu  Mon Nov 17 13:24:35 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 17 Nov 2003 07:24:35 -0500
Subject: [R] Rweb: how to use source()
Message-ID: <20031117122435.GA14694@mail1.sas.upenn.edu>

I cannot discover how to set or find the working directory in
Rweb, so that I can source() a file from the server.  The file I
source() must refer to a data file in its directory.

setwd() does not do anything, and getwd() says that the working
directory is in /var/www/cgi-bin/ (on Linux).

(I have a student who installed R on her own computer and
analyzed half of her data, and then her computer died.  Rweb
could let her finish, if I could just take what she's done so
far, which I have, and put it on my server.)

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron



From ligges at statistik.uni-dortmund.de  Mon Nov 17 13:27:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 17 Nov 2003 13:27:03 +0100 (MET)
Subject: [R] function identify()
In-Reply-To: <000a01c3acfc$33d44030$371624d5@jetzt0>
Message-ID: <Pine.GSO.4.21.0311171308410.27007-100000@amadeus.statistik.uni-dortmund.de>



On Mon, 17 Nov 2003, guerreau wrote:

> How can I control the size of the characters when using the function identify() ?

You cannot and found the bug mentioned in PR#660.

Uwe Ligges


> Many thanks in advance.
> 
> alain GUERREAU    CNRS-Paris
> 
> alain.guerrreau at libertysurf.fr
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Simon.Fear at synequanon.com  Mon Nov 17 13:47:09 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 17 Nov 2003 12:47:09 -0000
Subject: [R] ISOdate() and strptime()
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0EA2@synequanon01>

I think I do understand how difficult dates are. All I'm saying is
that by adopting a "standard" that is OS dependent (and hence, 
almost by definition, OS varying) you make R behave differently 
on different OSs - and that is NOT "making R portable across
multiple OSs".

This is a theoretical whinge. I'm not going to program it !

Please don't let me make too much of this anyway. For one thing,
although it is not guaranteed, it seems that many OSs DO in
fact behave identically. Also, it is only incomplete or erroneous 
dates that might be handled differently - and in most applications, 
one needs to pre-process incomplete date-times in R, rather than 
leave them to any default interpretation (even if that default was 
strictly fixed).

> -----Original Message-----
> From: Jason Turner [mailto:jasont at indigoindustrial.co.nz]
> Sent: 15 November 2003 06:17
> To: Simon Fear
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] ISOdate() and strptime()
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> Thomas Lumley wrote:
> 
> > On Fri, 14 Nov 2003, Simon Fear wrote:
> > 
> >>Is the behaviour of ISOtime() and strptime() determined by ISO
> >>or POSIX standard? Seems not to fit R's "no nannying" policy
> >>at all. 
> >>
> > 
> > 
> > It's determined by your operating system, so you're 
> complaining to the
> > wrong people.
> > 
> 
> And since R is written to be portable across multiple OSs, 
> you might get 
> an idea how tricky this becomes.  Hence the "iron fist" 
> approach to date 
> handling.  Believe me, I've programmed date handling - it's always a 
> terrible, nasty, messy business when international locales 
> and different 
> operating systems clash.  I'm stunned it's as good as it is, subtle 
> traps and all.
> 
> Cheers
> 
> Jason
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From ripley at stats.ox.ac.uk  Mon Nov 17 14:02:33 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 17 Nov 2003 13:02:33 +0000 (GMT Standard Time)
Subject: [R] confint: which method attached?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC5AE81D@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.WNT.4.44.0311171251380.276-100000@gannet.stats.ox.ac.uk>

On Mon, 17 Nov 2003, Ulrich Halekoh wrote:

> the function
> confint
> uses the profiling method of the function of the package MASS
>
> confint.glm
>
> even after the package has been detached!

Why the exclamation mark?  Note profile.glm is not actually in package:MASS
(sic).  Try looking for it:

> getAnywhere("profile.glm")
A single object matching 'profile.glm' was found
It was found in the following places
  registered S3 method for profile from namespace MASS
  namespace:MASS
with value
   ...

> 1: might this be the intenden behavior?

The accurate description is the intended behaviour.

> 2. How does the function remember its 'MASS' functionality after
> detaching the package?

It isn't in the package ....


There is currently no way to remove registered S3 methods like confint.glm
in an R session.  Nor is there likely to be in the near future,


General comment: R has changed quite a lot recently, and older
preconceptions do need to be checked against current information.
The article `Name Space Management for R' in R-news 2003/1 may help
(although it may tell you mor ethan you want to know).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From alessandro.semeria at cramont.it  Mon Nov 17 15:17:58 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Mon, 17 Nov 2003 15:17:58 +0100
Subject: [R] Rweb: how to use source()
Message-ID: <OFE2CEEF86.201AEF38-ONC1256DE1.004BE3AD@tomware.it>


It seem a user-permission problem.
May be some mistake at Rweb configuration
level (look at the RwebConfig file)?
First you have to try R standalone.

A.S.

----------------------------

Alessandro Semeria
Models and Simulations Laboratory
Montecatini Environmental Research Center (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: alessandro.semeria at cramont.it



From marcos_sanches at gallup.com  Mon Nov 17 15:27:47 2003
From: marcos_sanches at gallup.com (Marcos Sanches)
Date: Mon, 17 Nov 2003 12:27:47 -0200
Subject: [R] Generalized linear model
Message-ID: <007101c3ad16$f8c2af20$b454a8c0@gallup.com>


	Hi all!

 I am fitting a Poisson model, using the following command:

> fit2<-glm(canc~id1+year1+time+lnpa,family=poisson)



 where 'id1', 'year1' and 'time' are factors. I defined them with:

> id1<-C(factor(id1), treatment)

 and 'lnpa' is a continuous variable.

The 'summary' function gives me all the effects estimates, that is, for id1,
I end up with estimates for id12, id13 and id14, the id11 is the reference
level. That is fine, but when I try to fit the model without the point 18,
using the command line:

> fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset(dat, order!=18))

The 'summary' function stop to giving me the levels effect, and gives only
one effect for id1, one for year1, one for time and one for lnpa. I want to
have the parameters estimates for each level of each factor, as it was in
the first fit. Also, I noticed the degree of freedom of deviance and the
deviance itself has increased, so I cont't compare both models in terms of
their deviance.

 What should I do to have each factor level effect as I had in the first
case?

 Thanks

Marcos



From shazz1809 at hotmail.com  Mon Nov 17 15:41:41 2003
From: shazz1809 at hotmail.com (sharon carty)
Date: Mon, 17 Nov 2003 16:41:41 +0200
Subject: [R] using R
Message-ID: <BAY2-F24Xajhfpadp3Y0000f1c6@hotmail.com>

Hello

I am using R through emacs for the first time.
I would like to import a table of values from a folder and then apply Rao's 
homogeneity test to one of the columns in the imported table. Can you 
explain to me how i should go about this?

Thank you

sharon

_________________________________________________________________
Swap large files online - just one of Messenger 6.1's fun features! 
http://messenger.msn.co.za/



From H.RINNER at tirol.gv.at  Mon Nov 17 15:45:18 2003
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Mon, 17 Nov 2003 15:45:18 +0100
Subject: [R] ISOdate() and strptime()
Message-ID: <C4D44AB4CB62D311BA6500041202E886031EE349@xms1.tirol.gv.at>

I have followed with interest the discussion on date handling.
I am no expert in these things; all I want to do is convert a character
vector that has been read into R (and which may contain some erroneous
dates) to a "date format", and then do some work with it [e.g., use it in a
plot].
Classes "POSIXlt" and "POSIXct" seem fine to me - for example, they have
very nice and useful "seq" and "plot" methods.

So now I have two more questions:

1. Is it only incomplete or erroneous dates that might be handled
"differently" by ISOdate() or strptime()? Do correct specifications of year,
month and day always give the same results, no matter where or who I am?

2. Can someone point me to a reference that helps me understand why R's (or
the Operating systems?) "best guess at what I intended" turns out to be the
results in the examples I posted in my earlier mail?

Regards,
Heinrich.

> -----Urspr?ngliche Nachricht-----
> Von: RINNER Heinrich [mailto:H.RINNER at tirol.gv.at] 
> Gesendet: Freitag, 14. November 2003 11:13
> An: 'r-help at stat.math.ethz.ch'
> Betreff: [R] ISOdate() and strptime()
> 
> 
> Dear R-people!
> 
> I am using R 1.8.0, under Windows XP.
> While using ISOdate() and strptime(), I noticed the following 
> behaviour when
> "wrong" arguments (e.g., months>12) are given to these functions:
> 
> > ISOdate(year=2003,month=2,day=20) #ok
> [1] "2003-02-20 13:00:00 Westeurop?ische Normalzeit"
> > ISOdate(year=2003,month=2,day=30) #wrong day, but returns a value
> [1] "2003-03-02 13:00:00 Westeurop?ische Normalzeit"
> > ISOdate(year=2003,month=2,day=35) #wrong day, and returns NA
> [1] NA
> > ISOdate(year=2003,month=2,day=40) #wrong day, but returns a value
> [1] "2003-02-04 01:12:00 Westeurop?ische Normalzeit"
> > ISOdate(year=2003,month=22,day=20) #wrong month, but returns a value
> [1] "2003-02-02 21:12:00 Westeurop?ische Normalzeit"
> 
> And almost the same with strptime():
> > strptime("2003-02-20", format="%Y-%m-%d")
> [1] "2003-02-20"
> > strptime("2003-02-30", format="%Y-%m-%d")
> [1] "2003-03-02"
> > strptime("2003-02-35", format="%Y-%m-%d")
> [1] NA
> > strptime("2003-02-40", format="%Y-%m-%d")
> [1] "2003-02-04"
> > strptime("2003-22-20", format="%Y-%m-%d")
> [1] NA
> 
> Is this considered to be a user error ("If you put garbage 
> in, expect to get
> garbage out"), or would it be safer to generally return Nas, as in
> ISOdate(year=2003,month=2,day=35)?
> 
> -Heinrich.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Mon Nov 17 16:01:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Nov 2003 15:01:53 +0000 (GMT)
Subject: [R] Generalized linear model
In-Reply-To: <007101c3ad16$f8c2af20$b454a8c0@gallup.com>
Message-ID: <Pine.LNX.4.44.0311171459140.1461-100000@gannet.stats>

The second fit appeared to use a dataframe and the first did not.  Try

fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset=-18)

On Mon, 17 Nov 2003, Marcos Sanches wrote:

> 
> 	Hi all!
> 
>  I am fitting a Poisson model, using the following command:
> 
> > fit2<-glm(canc~id1+year1+time+lnpa,family=poisson)
> 
> 
> 
>  where 'id1', 'year1' and 'time' are factors. I defined them with:
> 
> > id1<-C(factor(id1), treatment)
> 
>  and 'lnpa' is a continuous variable.
> 
> The 'summary' function gives me all the effects estimates, that is, for id1,
> I end up with estimates for id12, id13 and id14, the id11 is the reference
> level. That is fine, but when I try to fit the model without the point 18,
> using the command line:
> 
> > fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset(dat, order!=18))
> 
> The 'summary' function stop to giving me the levels effect, and gives only
> one effect for id1, one for year1, one for time and one for lnpa. I want to
> have the parameters estimates for each level of each factor, as it was in
> the first fit. Also, I noticed the degree of freedom of deviance and the
> deviance itself has increased, so I cont't compare both models in terms of
> their deviance.
> 
>  What should I do to have each factor level effect as I had in the first
> case?
> 
>  Thanks
> 
> Marcos
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From marcos_sanches at gallup.com  Mon Nov 17 16:24:03 2003
From: marcos_sanches at gallup.com (Marcos Sanches)
Date: Mon, 17 Nov 2003 13:24:03 -0200
Subject: [R] Generalized linear model
In-Reply-To: <Pine.LNX.4.44.0311171459140.1461-100000@gannet.stats>
Message-ID: <008401c3ad1e$d5808660$b454a8c0@gallup.com>

	Ok, it worked!!!

  But what would be the command if I want to eliminate another point? I
mean, two points at the same time.

	Thanks,

Marcos

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Monday, November 17, 2003 1:02 PM
To: Marcos Sanches
Cc: R-Help
Subject: Re: [R] Generalized linear model


The second fit appeared to use a dataframe and the first did not.  Try

fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset=-18)

On Mon, 17 Nov 2003, Marcos Sanches wrote:

>
> 	Hi all!
>
>  I am fitting a Poisson model, using the following command:
>
> > fit2<-glm(canc~id1+year1+time+lnpa,family=poisson)
>
>
>
>  where 'id1', 'year1' and 'time' are factors. I defined them with:
>
> > id1<-C(factor(id1), treatment)
>
>  and 'lnpa' is a continuous variable.
>
> The 'summary' function gives me all the effects estimates, that is, for
id1,
> I end up with estimates for id12, id13 and id14, the id11 is the reference
> level. That is fine, but when I try to fit the model without the point 18,
> using the command line:
>
> > fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset(dat,
order!=18))
>
> The 'summary' function stop to giving me the levels effect, and gives only
> one effect for id1, one for year1, one for time and one for lnpa. I want
to
> have the parameters estimates for each level of each factor, as it was in
> the first fit. Also, I noticed the degree of freedom of deviance and the
> deviance itself has increased, so I cont't compare both models in terms of
> their deviance.
>
>  What should I do to have each factor level effect as I had in the first
> case?
>
>  Thanks
>
> Marcos
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wildscop at yahoo.com  Mon Nov 17 16:27:23 2003
From: wildscop at yahoo.com (Mohammad Ehsanul Karim)
Date: Mon, 17 Nov 2003 21:27:23 +0600
Subject: [R] S Programming
Message-ID: <5.1.0.14.2.20031117212610.009f3280@mail.dhaka.net>

Dear all,


     I am thinking of writing my own functions in s-plus (or in R). I just 
know how to work with S-plus / R built-in functions. Therefore, I'm a 
beginner in S programming.

     I am looking for some on-line documentation that is well written about 
"Programming in S language" where control stuctures / loops / vectorization 
and necessery sequences of S programming are presented in an organized form.

     Any comment / suggestion / idea / web-link / replies will be gladly 
accepted. Thanks for your time.




_______________________
Mohammad Ehsanul Karim <wildscop at yahoo.com>
Institute of Statistical Research and Training
University of Dhaka, Dhaka- 1000, Bangladesh



From ripley at stats.ox.ac.uk  Mon Nov 17 16:47:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Nov 2003 15:47:16 +0000 (GMT)
Subject: [R] Generalized linear model
In-Reply-To: <008401c3ad1e$d5808660$b454a8c0@gallup.com>
Message-ID: <Pine.LNX.4.44.0311171547010.4096-100000@gannet.stats>

On Mon, 17 Nov 2003, Marcos Sanches wrote:

> 	Ok, it worked!!!
> 
>   But what would be the command if I want to eliminate another point? I
> mean, two points at the same time.

subset=-c(18,27)

> 
> 	Thanks,
> 
> Marcos
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Monday, November 17, 2003 1:02 PM
> To: Marcos Sanches
> Cc: R-Help
> Subject: Re: [R] Generalized linear model
> 
> 
> The second fit appeared to use a dataframe and the first did not.  Try
> 
> fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset=-18)
> 
> On Mon, 17 Nov 2003, Marcos Sanches wrote:
> 
> >
> > 	Hi all!
> >
> >  I am fitting a Poisson model, using the following command:
> >
> > > fit2<-glm(canc~id1+year1+time+lnpa,family=poisson)
> >
> >
> >
> >  where 'id1', 'year1' and 'time' are factors. I defined them with:
> >
> > > id1<-C(factor(id1), treatment)
> >
> >  and 'lnpa' is a continuous variable.
> >
> > The 'summary' function gives me all the effects estimates, that is, for
> id1,
> > I end up with estimates for id12, id13 and id14, the id11 is the reference
> > level. That is fine, but when I try to fit the model without the point 18,
> > using the command line:
> >
> > > fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset(dat,
> order!=18))
> >
> > The 'summary' function stop to giving me the levels effect, and gives only
> > one effect for id1, one for year1, one for time and one for lnpa. I want
> to
> > have the parameters estimates for each level of each factor, as it was in
> > the first fit. Also, I noticed the degree of freedom of deviance and the
> > deviance itself has increased, so I cont't compare both models in terms of
> > their deviance.
> >
> >  What should I do to have each factor level effect as I had in the first
> > case?
> >
> >  Thanks
> >
> > Marcos
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From yuanji at mdanderson.org  Mon Nov 17 16:48:56 2003
From: yuanji at mdanderson.org (yuanji@mdanderson.org)
Date: Mon, 17 Nov 2003 09:48:56 -0600
Subject: [R] gradient option in "nlm" function
Message-ID: <OF3BC168C1.6ED266E1-ON86256DE1.00569539-86256DE1.0056FB59@mdacc.tmc.edu>

Dear list members,

I am trying to use "nlm" function to maximize a mixture likelihood of beta
densities. There are five unknown parameters in the likelihood. Since I can
get the analytic gradient, I attach the "gradient" attribute in my target
likehood function. The code is as the following



> target <- function(x)
> { resp <- ....
>  grad <- rep(0,5)                ## I have 5 paramters
>   grad[1] <- ...; grad[2] <- ...; grad[3] <- ...; grad[4] <- ...; grad[5]
<- ...
>   attr(resp, "gradient") <- grad
>   resp
> }
> nlm(targ, c(1,2,3,4,5))



The R gave me this error message


"Error in nlm(targ, c(1,2,3,4,5)) : probable coding error in analytic
gradient"



I ran my code for defining gradient separately, and there seemed to be no
coding error. I provided other options for nlm() function and it gave me
the same error message. I removed the gradient part and let nlm() do the
numerical derivative, it ran but the algorithm was not converging.

I want to know if nlm can handle multiple parameters problems, and if yes,
was there any error in my code? How do I properly provide the gradient for
my function?

Thanks a lot,

Yuan Ji, Ph.D.


Assistant Professor
Department of Bistatistics
The University of Texas M.D. Anderson Cancer Center
1515 Holcombe Blvd. - Unit 447
Houston, TX 77030-4009
(713)794-4153



From alessandro.semeria at cramont.it  Mon Nov 17 16:53:05 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Mon, 17 Nov 2003 16:53:05 +0100
Subject: [R] S Programming
Message-ID: <OFEBF3BBA6.93382447-ONC1256DE1.00572F62@tomware.it>


Look at http://cran.r-project.org/other-docs.html
A.S.

----------------------------

Alessandro Semeria
Models and Simulations Laboratory
Montecatini Environmental Research Center (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: alessandro.semeria at cramont.it



From spencer.graves at pdf.com  Mon Nov 17 16:52:08 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 17 Nov 2003 07:52:08 -0800
Subject: [R] Generalized linear model
In-Reply-To: <008401c3ad1e$d5808660$b454a8c0@gallup.com>
References: <008401c3ad1e$d5808660$b454a8c0@gallup.com>
Message-ID: <3FB8EEA8.9010108@pdf.com>

      From "?glm", I find the following: 

     subset: an optional vector specifying a subset of observations to be
              used in the fitting process.

      Thus, to delete observations 16 and 18, I can use the following: 

fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset=-c(16,18))

hope this helps.  spencer graves

Marcos Sanches wrote:

>	Ok, it worked!!!
>
>  But what would be the command if I want to eliminate another point? I
>mean, two points at the same time.
>
>	Thanks,
>
>Marcos
>
>-----Original Message-----
>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>Sent: Monday, November 17, 2003 1:02 PM
>To: Marcos Sanches
>Cc: R-Help
>Subject: Re: [R] Generalized linear model
>
>
>The second fit appeared to use a dataframe and the first did not.  Try
>
>fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset=-18)
>
>On Mon, 17 Nov 2003, Marcos Sanches wrote:
>
>  
>
>>	Hi all!
>>
>> I am fitting a Poisson model, using the following command:
>>
>>    
>>
>>>fit2<-glm(canc~id1+year1+time+lnpa,family=poisson)
>>>      
>>>
>>
>> where 'id1', 'year1' and 'time' are factors. I defined them with:
>>
>>    
>>
>>>id1<-C(factor(id1), treatment)
>>>      
>>>
>> and 'lnpa' is a continuous variable.
>>
>>The 'summary' function gives me all the effects estimates, that is, for
>>    
>>
>id1,
>  
>
>>I end up with estimates for id12, id13 and id14, the id11 is the reference
>>level. That is fine, but when I try to fit the model without the point 18,
>>using the command line:
>>
>>    
>>
>>>fit2<-glm(canc~id1+year1+time+lnpa,family=poisson, subset(dat,
>>>      
>>>
>order!=18))
>  
>
>>The 'summary' function stop to giving me the levels effect, and gives only
>>one effect for id1, one for year1, one for time and one for lnpa. I want
>>    
>>
>to
>  
>
>>have the parameters estimates for each level of each factor, as it was in
>>the first fit. Also, I noticed the degree of freedom of deviance and the
>>deviance itself has increased, so I cont't compare both models in terms of
>>their deviance.
>>
>> What should I do to have each factor level effect as I had in the first
>>case?
>>
>> Thanks
>>
>>Marcos
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>    
>>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From xavier.fim at eresmas.net  Mon Nov 17 17:14:17 2003
From: xavier.fim at eresmas.net (Xavier =?iso-8859-1?q?Fern=E1ndez=20i=20Mar=EDn?=)
Date: Mon, 17 Nov 2003 17:14:17 +0100
Subject: [R] Accents in R
Message-ID: <200311171714.18182.xavier.fim@eresmas.net>

Hi,

How can I include accents and signs like '?' '?' in the plots generated by R?

I try, but R automatically transforms the name 
ex:
> countries <- c("M?xico", "Espa?a")
> countries
[1] "M\216?xico" "Espa\216?a"
>

I've seen in some Spanish texts about R how is it normal to include labels of 
the plots and other names with accents, but I can't.

I'm using R 1.8.0 in a Mandrake 9.0

Thanks,

Xavier



From tblackw at umich.edu  Mon Nov 17 17:18:25 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 17 Nov 2003 11:18:25 -0500 (EST)
Subject: [R] gradient option in "nlm" function
In-Reply-To: <OF3BC168C1.6ED266E1-ON86256DE1.00569539-86256DE1.0056FB59@mdacc.tmc.edu>
References: <OF3BC168C1.6ED266E1-ON86256DE1.00569539-86256DE1.0056FB59@mdacc.tmc.edu>
Message-ID: <Pine.SOL.4.58.0311171116350.18692@mspacman.gpcc.itd.umich.edu>

On Mon, 17 Nov 2003 yuanji at mdanderson.org wrote:

> Dear list members,
>
> I am trying to use "nlm" function to maximize a mixture likelihood of beta
> densities. There are five unknown parameters in the likelihood. Since I can
> get the analytic gradient, I attach the "gradient" attribute in my target
> likehood function. The code is as the following
>
> > target <- function(x)
> > { resp <- ....
> >  grad <- rep(0,5)                ## I have 5 paramters
> >   grad[1] <- ...; grad[2] <- ...; grad[3] <- ...; grad[4] <- ...; grad[5]
> <- ...
> >   attr(resp, "gradient") <- grad
> >   resp
> > }
> > nlm(targ, c(1,2,3,4,5))

It would probably help if you passed the function  target()  to
nlm(),  rather than passing  targ().

> The R gave me this error message
>
> "Error in nlm(targ, c(1,2,3,4,5)) : probable coding error in analytic
> gradient"
>
> I ran my code for defining gradient separately, and there seemed to be no
> coding error. I provided other options for nlm() function and it gave me
> the same error message. I removed the gradient part and let nlm() do the
> numerical derivative, it ran but the algorithm was not converging.
>
> I want to know if nlm can handle multiple parameters problems, and if yes,
> was there any error in my code? How do I properly provide the gradient for
> my function?
>
> Thanks a lot,
>
> Yuan Ji, Ph.D.
>
> Assistant Professor
> Department of Bistatistics
> The University of Texas M.D. Anderson Cancer Center
> 1515 Holcombe Blvd. - Unit 447
> Houston, TX 77030-4009
> (713)794-4153
>



From sbarbar at uni-goettingen.de  Mon Nov 17 17:22:19 2003
From: sbarbar at uni-goettingen.de (Salvatore Barbaro)
Date: Mon, 17 Nov 2003 17:22:19 +0100
Subject: [R] Accents in R
In-Reply-To: <200311171714.18182.xavier.fim@eresmas.net>
References: <200311171714.18182.xavier.fim@eresmas.net>
Message-ID: <200311171722.19238.sbarbar@uni-goettingen.de>

Cf.  expression()

On Monday 17 November 2003 17:14, Xavier Fern?ndez i Mar?n wrote:
> Hi,
>
> How can I include accents and signs like '?' '?' in the plots generated by
> R?
>
> I try, but R automatically transforms the name
>
> ex:
> > countries <- c("M?xico", "Espa?a")
> > countries
>
> [1] "M\216?xico" "Espa\216?a"
>
>
> I've seen in some Spanish texts about R how is it normal to include labels
> of the plots and other names with accents, but I can't.
>
> I'm using R 1.8.0 in a Mandrake 9.0
>
> Thanks,
>
> Xavier
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Salvatore Barbaro
University of Goettingen
Department of Public Economics
Platz der Goettinger Sieben 3
D-37073 Goettingen, Germany
Tel +49 (0)551 3919704
http://www.gwdg.de/~sbarbar



From yuanji at mdanderson.org  Mon Nov 17 17:24:54 2003
From: yuanji at mdanderson.org (yuanji@mdanderson.org)
Date: Mon, 17 Nov 2003 10:24:54 -0600
Subject: [R] gradient option in "nlm" function
In-Reply-To: <Pine.SOL.4.58.0311171116350.18692@mspacman.gpcc.itd.umich.edu>
Message-ID: <OF6860A36B.E0258C79-ON86256DE1.005A0EB4-86256DE1.005A462C@mdacc.tmc.edu>


Oh, that's a typo. I passed the function target. Seems to me R requires
some kind of specific syntex.
Yuan Ji, Ph.D.

############################################
Assistant Professor
Department of Bistatistics
The University of Texas M.D. Anderson Cancer Center
1515 Holcombe Blvd. - Unit 447
Houston, TX 77030-4009
(713)794-4153
############################################


|---------+------------------------------------------>
|         |                                          |
|         |                                          |
|         |                        Thomas W Blackwell|
|         |                       <tblackw at umich.edu>|
|         |                                          |
|         |                         11/17/03 10:18 AM|
|         |                                          |
|---------+------------------------------------------>
  >-----------------------------------------------------------------------------------------------------|
  |                                                                                                     |
  |                                                                                                     |
  |                                                                                                     |
  |To:                                                                                                  |
  |      yuanji at mdanderson.org                                                                          |
  |cc:                                                                                                  |
  |      r-help at stat.math.ethz.ch                                                                       |
  |Subject:                                                                                             |
  |      Re: [R] gradient option in "nlm" function                                                      |
  |                                                                                                     |
  >-----------------------------------------------------------------------------------------------------|




On Mon, 17 Nov 2003 yuanji at mdanderson.org wrote:

> Dear list members,
>
> I am trying to use "nlm" function to maximize a mixture likelihood of
beta
> densities. There are five unknown parameters in the likelihood. Since I
can
> get the analytic gradient, I attach the "gradient" attribute in my target
> likehood function. The code is as the following
>
> > target <- function(x)
> > { resp <- ....
> >  grad <- rep(0,5)                ## I have 5 paramters
> >   grad[1] <- ...; grad[2] <- ...; grad[3] <- ...; grad[4] <- ...;
grad[5]
> <- ...
> >   attr(resp, "gradient") <- grad
> >   resp
> > }
> > nlm(targ, c(1,2,3,4,5))

It would probably help if you passed the function  target()  to
nlm(),  rather than passing  targ().

> The R gave me this error message
>
> "Error in nlm(targ, c(1,2,3,4,5)) : probable coding error in analytic
> gradient"
>
> I ran my code for defining gradient separately, and there seemed to be no
> coding error. I provided other options for nlm() function and it gave me
> the same error message. I removed the gradient part and let nlm() do the
> numerical derivative, it ran but the algorithm was not converging.
>
> I want to know if nlm can handle multiple parameters problems, and if
yes,
> was there any error in my code? How do I properly provide the gradient
for
> my function?
>
> Thanks a lot,
>
> Yuan Ji, Ph.D.
>
> Assistant Professor
> Department of Bistatistics
> The University of Texas M.D. Anderson Cancer Center
> 1515 Holcombe Blvd. - Unit 447
> Houston, TX 77030-4009
> (713)794-4153
>



From ggrothendieck at myway.com  Mon Nov 17 17:27:22 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 17 Nov 2003 11:27:22 -0500 (EST)
Subject: [R] Symbolic math?
Message-ID: <20031117162722.D102C397F@mprdmxin.myway.com>


Depending on what you want to do

?deriv

in R may be enough.

--- 
Date: Mon, 17 Nov 2003 05:37:22 -0500 
From: Hank Stevens <HStevens at muohio.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Symbolic math? 

 
 
Hi Folks,
I am using Windows 2000 and was wondering what (Open Source) software R 
users use or might recommend for symbolic computations (aside from the ol' 
noggin, e.g., Maxima, Mathomatic) .
Thanks,
Hank

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056



From p.dalgaard at biostat.ku.dk  Mon Nov 17 17:44:26 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Nov 2003 17:44:26 +0100
Subject: [R] Accents in R
In-Reply-To: <200311171714.18182.xavier.fim@eresmas.net>
References: <200311171714.18182.xavier.fim@eresmas.net>
Message-ID: <x2smkn6j2t.fsf@biostat.ku.dk>

Xavier Fern?ndez i Mar?n <xavier.fim at eresmas.net> writes:

> Hi,
> 
> How can I include accents and signs like '?' '?' in the plots generated by R?
> 
> I try, but R automatically transforms the name 
> ex:
> > countries <- c("M?xico", "Espa?a")

> > countries
> [1] "M\216?xico" "Espa\216?a"
> >
> 
> I've seen in some Spanish texts about R how is it normal to include labels of 
> the plots and other names with accents, but I can't.
> 
> I'm using R 1.8.0 in a Mandrake 9.0

You'll need to get rid of UTF-8 encoding, since R doesn't know how to
deal with it. I'm not sure of the details on Mandrake, but I suspect
you need to diddle /etc/sysconfig/i18n or set some environment
variables (among the ones listed by "locale").

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From lenvi10 at yahoo.com  Mon Nov 17 17:40:31 2003
From: lenvi10 at yahoo.com (Len Vir)
Date: Mon, 17 Nov 2003 08:40:31 -0800 (PST)
Subject: [R] Symbolic math?
In-Reply-To: <200311171237.25927.ahenningsen@agric-econ.uni-kiel.de>
Message-ID: <20031117164031.58249.qmail@web14802.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031117/099ab517/attachment.pl

From ggrothendieck at myway.com  Mon Nov 17 17:45:34 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 17 Nov 2003 11:45:34 -0500 (EST)
Subject: [R] Rweb: how to use source()
Message-ID: <20031117164534.60B033976@mprdmxin.myway.com>



For the code, just copy and paste it through the clipboard 
into Rweb.

For the data, you enter the URL in the area where Rweb says 
External Data Entry.  Alternately, you can use the R dput command
on your machine to turn the data into an R statement and then add it 
to the source file, eliminating the need for reading an external 
data file.

---
Date: Mon, 17 Nov 2003 07:24:35 -0500 
From: Jonathan Baron <baron at psych.upenn.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Rweb: how to use source() 

 
 
I cannot discover how to set or find the working directory in
Rweb, so that I can source() a file from the server. The file I
source() must refer to a data file in its directory.

setwd() does not do anything, and getwd() says that the working
directory is in /var/www/cgi-bin/ (on Linux).

(I have a student who installed R on her own computer and
analyzed half of her data, and then her computer died. Rweb
could let her finish, if I could just take what she's done so
far, which I have, and put it on my server.)

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Mon Nov 17 17:48:01 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 17 Nov 2003 08:48:01 -0800
Subject: [R] Accents in R
In-Reply-To: <200311171722.19238.sbarbar@uni-goettingen.de>
References: <200311171714.18182.xavier.fim@eresmas.net>
	<200311171722.19238.sbarbar@uni-goettingen.de>
Message-ID: <3FB8FBC1.4080206@pdf.com>

      I don't know about "expression", but R 1.8.0 under Windows 2000 
gave me the result you desire NOT the problem. 

      Someone else may tell you what is different, but this may help 
narrow your search for a solution. 

      spencer graves

Salvatore Barbaro wrote:

>Cf.  expression()
>
>On Monday 17 November 2003 17:14, Xavier Fern?ndez i Mar?n wrote:
>  
>
>>Hi,
>>
>>How can I include accents and signs like '?' '?' in the plots generated by
>>R?
>>
>>I try, but R automatically transforms the name
>>
>>ex:
>>    
>>
>>>countries <- c("M?xico", "Espa?a")
>>>countries
>>>      
>>>
>>[1] "M\216?xico" "Espa\216?a"
>>
>>
>>I've seen in some Spanish texts about R how is it normal to include labels
>>of the plots and other names with accents, but I can't.
>>
>>I'm using R 1.8.0 in a Mandrake 9.0
>>
>>Thanks,
>>
>>Xavier
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>    
>>
>
>  
>



From tplate at acm.org  Mon Nov 17 17:50:47 2003
From: tplate at acm.org (Tony Plate)
Date: Mon, 17 Nov 2003 09:50:47 -0700
Subject: [R] LOCF - Last Observation Carried Forward
In-Reply-To: <20031115032125.27A64394A@mprdmxin.myway.com>
Message-ID: <5.2.1.1.2.20031117093047.041bc5b8@mailhost.blackmesacapital.com>

Here's a faster version of "most.recent".  It uses "rep()" in a vectorized 
manner.

 > # Gabor Grothendieck's function:
 > most.recent.cut <- function(x)
+     as.numeric(as.vector(cut(seq(x),c(which(x),Inf),lab=which(x),right=F)))
 >
 > # Version that uses which() and vectorized rep()
 > most.recent <- function(x) {
+     # return a vector of indices of the most recent TRUE value
+     if (!is.logical(x))
+         stop("x must be logical")
+     x.pos <- which(x)
+     if (length(x.pos)==0 || x.pos[1] != 1)
+         x.pos <- c(1, x.pos)
+     rep(x.pos, c(diff(x.pos), length(x) - x.pos[length(x.pos)] + 1))
+ }
 >

 > x <- sample(c(T,F),1e7,rep=T)
 > system.time(most.recent.cut(x))
[1] 41.21  0.54 41.98    NA    NA
 > system.time(most.recent(x))
[1] 2.67 0.08 2.78   NA   NA
 >

-- Tony Plate

At Friday 10:21 PM 11/14/2003 -0500, Gabor Grothendieck wrote:

>From: Tony Plate <tplate at acm.org>:
> >
> > Here's a function that does the essential computation (written to work in
> > both S-plus and R).
> >
> > This looks like one of those tricky problems that do not vectorize
> > easily. It would be simple to write a C-program to compute this very
> > efficiently. But are there any more efficient solutions than ones like the
> > below (that are written without resort to C)?
> >
> > most.recent <- function(x) {
> > # return a vector of indices of the most recent TRUE value
> > if (!is.logical(x))
> > stop("x must be logical")
> > x[is.na(x)] <- FALSE
> > # x is a logical vector
> > r <- rle(x)
> > ends <- cumsum(r$lengths)
> > starts <- ends - r$lengths + 1
> > spec <- as.list(as.data.frame(rbind(start=starts, len=r$lengths,
> > value=as.numeric(r$values), prev.end=c(NA, ends[-length(ends)]))))
> > names(spec) <- NULL
> > unlist(lapply(spec, function(s) if (s[3]) seq(s[1], len=s[2]) else
> > rep(s[4], len=s[2])), use.names=F)
> > }
> >
> > > x <- c(F,T,T,F,F,F,T,F)
> > > most.recent(x)
> > [1] NA 2 3 3 3 3 7 7
> >
> > And using it to do the fill-forward:
> >
> > > x <- c(NA,2,3,NA,4,NA,5,NA,NA,NA,6,7,8,NA)
> > > x[most.recent(!is.na(x))]
> > [1] NA 2 3 3 4 4 5 5 5 5 6 7 8 8
> > >
> >
> > Some timings:
> >
> > > x <- sample(c(T,F),1e4,rep=T)
> > > system.time(most.recent(x))
> > [1] 0.33 0.01 0.47 NA NA
> > > x <- sample(c(T,F),1e5,rep=T)
> > > system.time(most.recent(x))
> > [1] 4.27 0.06 6.44 NA NA
> > > x <- sample(c(T,F),1e6,rep=T)
> > > system.time(most.recent(x))
> > [1] 47.27 0.17 47.97 NA NA
> > >
> >
> > -- Tony Plate
> >
> > PS. Actually, I just found a solution that I had lying around that is 
> about
> > 70 times as fast on random test data like the above.
>
>I was waiting for you to post this but didn't see it so I thought
>I would post mine.  This one is 13x as fast and only requires
>a single line of code.
>
> > set.seed(111)
> > x <- sample(c(T,F),10000,rep=T)
>
> > system.time(z1 <- most.recent(x))
>[1] 0.92 0.02 1.68   NA   NA
>
> > system.time(z2 <- as.numeric(as.vector(
>      cut(seq(x),c(which(x),Inf),lab=which(x),right=F))))
>[1] 0.07 0.00 0.12   NA   NA
>
> > all.equal(z1,z2)
>[1] TRUE
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Tony Plate   tplate at acm.org



From Ted.Harding at nessie.mcc.ac.uk  Mon Nov 17 16:08:38 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 17 Nov 2003 15:08:38 -0000 (GMT)
Subject: [R] A suggestion regarding multiple replies
In-Reply-To: <XFMail.031115003042.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.031117150838.Ted.Harding@nessie.mcc.ac.uk>

On 15-Nov-03 Ted Harding wrote:
> However, personally I like the way questions are bounced around between
> people. and answers are devoped "conversationally", as it were, and I
> think a lot would be lost if this were not to happen. On the whole,
> I welcome the load!
> 
> R strikes me as somewhat special amongst languages in that there are
> a lot of hidden subtleties, which sometimes are only pointed out by
> the few people who are really familiar with them. At present this
> happens on-list and usually very promptly, and this timely intervention
> puts wrong ideas right before they get too deeply embedded; this
> benefit would tend to vanish if a "summarise to the list" policy
> were adopted.

And the following (in today's "?for" thread) is a perfect example
of what I mean:
===============================================================
> From: Peter Dalgaard <p.dalgaard at biostat.ku.dk>
> To: Angel <angel_lul at hotmail.com>, r-help at stat.math.ethz.ch
> Subject: Re: [R] ?for
> Date: 17 Nov 2003 11:49:37 +0100
> 
> Further hint: ? is an operator, syntactically similar to + and -.
> You can apply operators to the result of a for loop. Consider for
> example
> 
> x <- 1; - for (i in 1:10) x <- x * i
> 
> (? has special semantics, but that is not noticed at parse time).
===============================================================

This is just the sort of thing I love to see posted to the list,
since it is an eye-opener. In fact, to really see what goes on
I had to rub my eyes as follows:

  - for (i in 1:10) print(i)

and I'm posting it hoping that it will enlighten some other people.

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Nov-03                                       Time: 15:08:38
------------------------------ XFMail ------------------------------



From umalvarez at fata.unam.mx  Mon Nov 17 18:14:58 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Mon, 17 Nov 2003 11:14:58 -0600 (CST)
Subject: [R] Accents in R
In-Reply-To: <200311171722.19238.sbarbar@uni-goettingen.de>
Message-ID: <Pine.LNX.4.44.0311171110320.3103-100000@fata.unam.mx>

Hello!

If you are using a GNOME-Terminal or if you are running R inside Emacs 
just make yourself sure that you change the UTF-8 encoding before starting 
R. 

 



On Mon, 17 Nov 2003, Salvatore Barbaro wrote:

> Cf.  expression()
> 
> On Monday 17 November 2003 17:14, Xavier Fern?ndez i Mar?n wrote:
> > Hi,
> >
> > How can I include accents and signs like '?' '?' in the plots generated by
> > R?
> >
> > I try, but R automatically transforms the name
> >
> > ex:
> > > countries <- c("M?xico", "Espa?a")
> > > countries
> >
> > [1] "M\216?xico" "Espa\216?a"
> >
> >
> > I've seen in some Spanish texts about R how is it normal to include labels
> > of the plots and other names with accents, but I can't.
> >
> > I'm using R 1.8.0 in a Mandrake 9.0
> >
> > Thanks,
> >
> > Xavier
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From kjetil at entelnet.bo  Mon Nov 17 18:31:53 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 17 Nov 2003 13:31:53 -0400
Subject: [R] Accents in R
In-Reply-To: <200311171714.18182.xavier.fim@eresmas.net>
Message-ID: <3FB8CDC9.8300.2F561A@localhost>

On 17 Nov 2003 at 17:14, Xavier Fern?ndez i Mar?n wrote:

On my windows XP machine I get

> help.search("locale")
> ?locales
help() for `locales' is shown in browser
> Sys.getlocale()
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=English_United 
States.1252"
> #Sys.setlocale()
> c("Espa?a", "Nicarag?ense")
[1] "Espa?a"       "Nicarag?ense"
> 

You need to find out which locales you can set in Mandrake. The 
locale shown above
is the default when I start up my R.

Kjetil Halvorsen

> Hi,
> 
> How can I include accents and signs like '?' '?' in the plots
> generated by R?
> 
> I try, but R automatically transforms the name 
> ex:
> > countries <- c("M?xico", "Espa?a")
> > countries
> [1] "M\216?xico" "Espa\216?a"
> >
> 
> I've seen in some Spanish texts about R how is it normal to include
> labels of the plots and other names with accents, but I can't.
> 
> I'm using R 1.8.0 in a Mandrake 9.0
> 
> Thanks,
> 
> Xavier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Mon Nov 17 18:52:08 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Mon, 17 Nov 2003 13:52:08 -0400
Subject: [R] A suggestion regarding multiple replies
In-Reply-To: <XFMail.031117150838.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.031115003042.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3FB8D288.13848.41E080@localhost>

On 17 Nov 2003 at 15:08, Ted Harding wrote:

> On 15-Nov-03 Ted Harding wrote:
> And the following (in today's "?for" thread) is a perfect example of
> what I mean:
> =============================================================== >
> From: Peter Dalgaard <p.dalgaard at biostat.ku.dk> > To: Angel
> <angel_lul at hotmail.com>, r-help at stat.math.ethz.ch > Subject: Re: [R]
> ?for > Date: 17 Nov 2003 11:49:37 +0100 > > Further hint: ? is an
> operator, syntactically similar to + and -. > You can apply operators
> to the result of a for loop. Consider for > example > > x <- 1; - for
> (i in 1:10) x <- x * i > > (? has special semantics, but that is not
> noticed at parse time).
> ===============================================================
> 
> This is just the sort of thing I love to see posted to the list,
> since it is an eye-opener. In fact, to really see what goes on
> I had to rub my eyes as follows:
> 
>   - for (i in 1:10) print(i)
> 
> and I'm posting it hoping that it will enlighten some other people.
> 
> Best wishes to all,
> Ted.
> 
> 

Indeed! look at the following:

> test <- function(x) invisible(x)
> test(9)
> - test(9)
[1] -9
> 


Kjetil Halvorsen

> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> Fax-to-email: +44
> (0)870 167 1972 Date: 17-Nov-03                                  
> Time: 15:08:38 ------------------------------ XFMail
> ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From B.Rowlingson at lancaster.ac.uk  Mon Nov 17 19:01:53 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 17 Nov 2003 18:01:53 +0000
Subject: [R] A suggestion regarding multiple replies
In-Reply-To: <3FB8D288.13848.41E080@localhost>
References: <XFMail.031115003042.Ted.Harding@nessie.mcc.ac.uk>
	<3FB8D288.13848.41E080@localhost>
Message-ID: <3FB90D11.9010403@lancaster.ac.uk>

kjetil at entelnet.bo wrote:

> 
> Indeed! look at the following:
> 
> 
>>test <- function(x) invisible(x)
>>test(9)
>>- test(9)
> 
> [1] -9
> 


or even:

 > +test(9)
[1] 9



From pburns at pburns.seanet.com  Mon Nov 17 19:05:37 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 17 Nov 2003 18:05:37 +0000
Subject: [R] S Programming
References: <5.1.0.14.2.20031117212610.009f3280@mail.dhaka.net>
Message-ID: <3FB90DF1.2080600@pburns.seanet.com>

"well written" and "organized" are matters of opinion,
but S Poetry potentially fulfills your requirements.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Mohammad Ehsanul Karim wrote:

> Dear all,
>
>
>     I am thinking of writing my own functions in s-plus (or in R). I 
> just know how to work with S-plus / R built-in functions. Therefore, 
> I'm a beginner in S programming.
>
>     I am looking for some on-line documentation that is well written 
> about "Programming in S language" where control stuctures / loops / 
> vectorization and necessery sequences of S programming are presented 
> in an organized form.
>
>     Any comment / suggestion / idea / web-link / replies will be 
> gladly accepted. Thanks for your time.
>
>
>
>
> _______________________
> Mohammad Ehsanul Karim <wildscop at yahoo.com>
> Institute of Statistical Research and Training
> University of Dhaka, Dhaka- 1000, Bangladesh
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ripley at stats.ox.ac.uk  Mon Nov 17 19:13:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Nov 2003 18:13:59 +0000 (GMT)
Subject: [R] Accents in R
In-Reply-To: <3FB8CDC9.8300.2F561A@localhost>
Message-ID: <Pine.LNX.4.44.0311171805590.4242-100000@gannet.stats>

Just to make sure people know:

The issue is the use of UTF-8 encoding in some recent Linux distros, as PD
said.  We do plan to support UTF-8 fairly soon.

Try locale -a on your Linux machine.  Mine has (for Spanish in Spain)

es_ES
es_ES.iso88591
es_ES.iso885915 at euro
es_ES.utf8
es_ES.utf8 at euro
es_ES at euro

You need to set LC_CTYPE appropriately, and that is *not* any of those 
containing `utf8'.


On Mon, 17 Nov 2003 kjetil at entelnet.bo wrote:

> On 17 Nov 2003 at 17:14, Xavier Fern?ndez i Mar?n wrote:
> 
> On my windows XP machine I get
> 
> > help.search("locale")
> > ?locales
> help() for `locales' is shown in browser
> > Sys.getlocale()
> [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
> States.1252;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=English_United 
> States.1252"
> > #Sys.setlocale()
> > c("Espa?a", "Nicarag?ense")
> [1] "Espa?a"       "Nicarag?ense"
> > 
> 
> You need to find out which locales you can set in Mandrake. The 
> locale shown above
> is the default when I start up my R.
> 
> Kjetil Halvorsen
> 
> > Hi,
> > 
> > How can I include accents and signs like '?' '?' in the plots
> > generated by R?
> > 
> > I try, but R automatically transforms the name 
> > ex:
> > > countries <- c("M?xico", "Espa?a")
> > > countries
> > [1] "M\216?xico" "Espa\216?a"
> > >
> > 
> > I've seen in some Spanish texts about R how is it normal to include
> > labels of the plots and other names with accents, but I can't.
> > 
> > I'm using R 1.8.0 in a Mandrake 9.0


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From monica.palaseanu-lovejoy at stud.man.ac.uk  Mon Nov 17 19:30:08 2003
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Mon, 17 Nov 2003 18:30:08 -0000
Subject: [R] cumulative distribution functions
Message-ID: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>

hi y'all,

I am wondering if there is any special command, function, 
package, etc to help me doing a cumulative distribution function, 
with y-scale - probability scale.

I tried the help in R and i got the following answers:
cumsum(base)            Cumulative Sums, Products, and Extremes
ecdf(stepfun)           Empirical Cumulative Distribution Function
cpgram(ts)              Plot Cumulative Periodogram

But i could not find either (stepfun) nor (ts) packages to read the 
specific help. Are they discarded? The "cumsum" seems not to do 
what i really was after.

Any help as usual very much appreciated ;-)

Monica



From tblackw at umich.edu  Mon Nov 17 19:36:58 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 17 Nov 2003 13:36:58 -0500 (EST)
Subject: [R] cumulative distribution functions
In-Reply-To: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>
References: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>
Message-ID: <Pine.SOL.4.58.0311171336110.23664@mspacman.gpcc.itd.umich.edu>


Try  help("INSTALL")  (case-sensitive).

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 17 Nov 2003, Monica Palaseanu-Lovejoy wrote:

> hi y'all,
>
> I am wondering if there is any special command, function,
> package, etc to help me doing a cumulative distribution function,
> with y-scale - probability scale.
>
> I tried the help in R and i got the following answers:
> cumsum(base)            Cumulative Sums, Products, and Extremes
> ecdf(stepfun)           Empirical Cumulative Distribution Function
> cpgram(ts)              Plot Cumulative Periodogram
>
> But i could not find either (stepfun) nor (ts) packages to read the
> specific help. Are they discarded? The "cumsum" seems not to do
> what i really was after.
>
> Any help as usual very much appreciated ;-)
>
> Monica
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From monica.palaseanu-lovejoy at stud.man.ac.uk  Mon Nov 17 19:44:55 2003
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Mon, 17 Nov 2003 18:44:55 -0000
Subject: [R] cumulative distribution functions
In-Reply-To: <Pine.SOL.4.58.0311171336110.23664@mspacman.gpcc.itd.umich.edu>
References: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>
Message-ID: <E1ALoMw-000J1K-I8@probity.mcc.ac.uk>

Hi,

the packages i mentioned are not in the list of packages from 
CRAN even if they appear in the help i just mention an email later 
about cumulative distribution functions. they are "stepfun" and "ts". 
Maybe that helps to clarify my question - in the sense that i know 
how to look after packages on CRAN and how to install them.

Thanks,

Monica



From monica.palaseanu-lovejoy at stud.man.ac.uk  Mon Nov 17 19:50:55 2003
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Mon, 17 Nov 2003 18:50:55 -0000
Subject: [R] cumulative distribution functions - solved;-))
In-Reply-To: <16313.5910.743606.486813@gargle.gargle.HOWL>
References: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>
Message-ID: <E1ALoSj-000JOr-J4@probity.mcc.ac.uk>

OK,

I see what i did .... i though stepfun and ts are two packages on 
CRAN - i didn't realized they are libraries already "installed" under 
R .... now i found them .... mea culpa!

Thanks a lot,

Monica



From kwan022 at stat.auckland.ac.nz  Mon Nov 17 19:51:48 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 18 Nov 2003 07:51:48 +1300 (NZDT)
Subject: [R] S Programming
In-Reply-To: <5.1.0.14.2.20031117212610.009f3280@mail.dhaka.net>
Message-ID: <Pine.LNX.4.44.0311180749560.7259-100000@stat61.stat.auckland.ac.nz>

Take a look at my incomplete 
http://www.stat.auckland.ac.nz/~kwan022/pub/R/RBook/ .  I am hoping to 
gradually complete it in the next few weeks.  I also have some notes which 
I used for a R Programming Workshop at 
http://www.stat.auckland.ac.nz/~kwan022/pub/R/Workshop.pdf

I wouldn't call them well-written nor well-organised.  But they can be a 
start ;-D

-- 
Cheers,

Kevin

---------------------------------------------------------------
"Try not.  Do, do!  Or do not.  There is no try"
   Jedi Master Yoda

----
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From maechler at stat.math.ethz.ch  Mon Nov 17 19:58:04 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 17 Nov 2003 19:58:04 +0100
Subject: [R] Re: clara(*, stand=) and pam(*, stand=)
In-Reply-To: <OF22D08535.79B267A4-ONC1256DE1.0037B132-C1256DE1.00385E1F@e-c-s.fr>
References: <OF22D08535.79B267A4-ONC1256DE1.0037B132-C1256DE1.00385E1F@e-c-s.fr>
Message-ID: <16313.6716.316560.866244@gargle.gargle.HOWL>

>>>>> "ReCH" == optimisation1 stagiaire <optimisation1.stagiaire at lagardere-active.com>
>>>>>     on Mon, 17 Nov 2003 11:23:41 +0100 writes:

    ReCH> I need informations about the clara routine. The
    ReCH> on-line doc say that the argument stand is a logical,
    ReCH> indicating if the measurements in x are standardized
    ReCH> before calculating the dissimilarities. Measurements
    ReCH> are standardized for each variable (column), by
    ReCH> subtracting the variable's mean value and dividing by
    ReCH> the variable's mean absolute deviation. If we note
    ReCH> STAND = TRUE, I suppose that the data will not be
    ReCH> standardized before clustering. On the contrary, STAND
    ReCH> = FALSE means that the data will be standardized
    ReCH> before clustering.  Each sub-dataset is partitioned
    ReCH> into k clusters using the same algorithm as in
    ReCH> pam. But the pam routine argument stand is a logical;
    ReCH> if true, the measurements in x are standardized before
    ReCH> calculating the dissimilarities.  Measurements are
    ReCH> standardized for each variable (column), by
    ReCH> subtracting the variable's mean value and dividing by
    ReCH> the variable's mean absolute deviation. If x is
    ReCH> already a dissimilarity matrix, then this argument
    ReCH> will be ignored. If we note STAND = TRUE, I suppose
    ReCH> that the data will be standardized.

    ReCH> There is a big difference as clara and pam use nearly
    ReCH> the same algorithm.

There is no difference between  clara() and pam() concerning the
meaning and handling of the argument `stand'.

This is very quickly seen if you look at the two functiondefinitions
which both have almost the same statement 

        x2 <-
            if (stand) 
               scale(x, scale = apply(x, 2, meanabsdev))
            else x


    ReCH> I need to use clara because I have a large
    ReCH> dataset. Could help me about the argument stand ? May
    ReCH> I have to standardize my datas with excel before ? If
    ReCH> yes, what I have to write : STAND = ?? ?

    ReCH> Best regards,
    ReCH> Cordialement,

    ReCH> R?gis CHARIGNON



From maechler at stat.math.ethz.ch  Mon Nov 17 20:01:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 17 Nov 2003 20:01:27 +0100
Subject: [R] cumulative distribution functions - solved;-))
In-Reply-To: <E1ALoSj-000JOr-J4@probity.mcc.ac.uk>
References: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>
	<E1ALoSj-000JOr-J4@probity.mcc.ac.uk>
Message-ID: <16313.6919.57417.281426@gargle.gargle.HOWL>

>>>>> "Monica" == Monica Palaseanu-Lovejoy <monica.palaseanu-lovejoy at stud.man.ac.uk>
>>>>>     on Mon, 17 Nov 2003 18:50:55 -0000 writes:

    Monica> OK,
    Monica> I see what i did .... i though stepfun and ts are two packages on 
    Monica> CRAN - i didn't realized they are libraries already "installed" under 
    Monica> R .... now i found them .... mea culpa!

indeed! {causing half a dozen e-mails to more than 2000 people ...}

Note that you woldn't have found them with  
help.search(..) if they hadn't been installed in your R setup, i.e.

**>> you NEVER must install anything after having found it by help.search()!

--
Martin



From svolko1 at jhmi.edu  Mon Nov 17 20:01:17 2003
From: svolko1 at jhmi.edu (Sigrid Volko)
Date: Mon, 17 Nov 2003 14:01:17 -0500
Subject: [R] Fwd: License Agreement
Message-ID: <sfb8d4b6.015@cis27.hosts.jhmi.edu>



***********************************************************
Sigrid M. Volko, Ph.D.
Assistant Director
Office of Licensing and Technology Development
Johns Hopkins University 
100 N. Charles Street, 5th Floor
Baltimore, MD 21201
phone: 410-516-4962
fax: 410-516-5113

This e-mail message (including any attachments hereto) is for the sole use of the intended recipient(s) and may contain confidential and privileged information. If the reader of this message is not an intended recipient, you are hereby notified  that any dissemination, distribution or copying of this message (including the attachments hereto) is prohibited. If you have received this message in error, please contact the sender by reply e-mail message and destroy all copies of the original message (including any attachments hereto). Thank you for your cooperation.
-------------- next part --------------
An embedded message was scrubbed...
From: "Sigrid Volko" <svolko1 at jhmi.edu>
Subject: License Agreement
Date: Mon, 17 Nov 2003 13:57:05 -0500
Size: 2053
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031117/255bf5f3/attachment.mht

From dmurdoch at pair.com  Mon Nov 17 20:05:10 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 17 Nov 2003 14:05:10 -0500
Subject: [R] cumulative distribution functions
In-Reply-To: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>
References: <E1ALo8i-000IP0-Gq@probity.mcc.ac.uk>
Message-ID: <or6irvkot6ba5ioc3u2v6ghfnivnkskjnk@4ax.com>

On Mon, 17 Nov 2003 18:30:08 -0000, "Monica Palaseanu-Lovejoy"
<monica.palaseanu-lovejoy at stud.man.ac.uk> wrote :

>hi y'all,
>
>I am wondering if there is any special command, function, 
>package, etc to help me doing a cumulative distribution function, 
>with y-scale - probability scale.
>
>I tried the help in R and i got the following answers:
>cumsum(base)            Cumulative Sums, Products, and Extremes
>ecdf(stepfun)           Empirical Cumulative Distribution Function
>cpgram(ts)              Plot Cumulative Periodogram
>
>But i could not find either (stepfun) nor (ts) packages to read the 
>specific help. Are they discarded? The "cumsum" seems not to do 
>what i really was after.

You need to execute "library(stepfun)" before help for ecdf will work.

In general, the notation is

topic(package)	Description

and you need library(package) to see ?topic.

Duncan Murdoch



From ray at mcs.vuw.ac.nz  Mon Nov 17 21:06:32 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Tue, 18 Nov 2003 09:06:32 +1300 (NZDT)
Subject: [R] ?for
Message-ID: <200311172006.hAHK6Wq2011730@tahi.mcs.vuw.ac.nz>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
> 
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > You have typed a syntactically incomplete statement: this is explained in 
> > ?help.
> > 
> > Hint: ?"for" and help("for") work.
> 
> [Original question added back in:
> On Sun, 16 Nov 2003, Angel wrote:
> 
> > I have always been intrigued by why ?for (or ?if,?while,etc) leave R
> > wanting for more:
> > > ?for
> > +
> > I know the help for these is in ?Control, but I sometimes make the
> > mistake of typing ?for instead. What is R expecting me to say to finish
> > the statement?
> ]
> Further hint: ? is an operator, syntactically similar to + and -. You
> can apply operators to the result of a for loop. Consider for example
> 
> x <- 1; - for (i in 1:10) x <- x * i
> 
> (? has special semantics, but that is not noticed at parse time).
> 
Unfortunately the original question still hasn't been answered
explicitly, not even in ?help.
Try:
> ?for
+ (i in 0) 0
or:
> ?if
+ (T) T
or:
> ?+
+ 0

So you have to provide the rest of a syntactically complete statement.

Just to see if you now understand exactly how ? works, what do you
think:
? paste("help")
will do?

Ray Brownrigg



From ripley at stats.ox.ac.uk  Mon Nov 17 21:27:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Nov 2003 20:27:21 +0000 (GMT)
Subject: [R] ?for
In-Reply-To: <200311172006.hAHK6Wq2011730@tahi.mcs.vuw.ac.nz>
Message-ID: <Pine.LNX.4.44.0311172026240.4841-100000@gannet.stats>

Well ^C or ESC (on Windows GUI) is the answer I would give.

On Tue, 18 Nov 2003, Ray Brownrigg wrote:

> Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
> > 
> > Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> > 
> > > You have typed a syntactically incomplete statement: this is explained in 
> > > ?help.
> > > 
> > > Hint: ?"for" and help("for") work.
> > 
> > [Original question added back in:
> > On Sun, 16 Nov 2003, Angel wrote:
> > 
> > > I have always been intrigued by why ?for (or ?if,?while,etc) leave R
> > > wanting for more:
> > > > ?for
> > > +
> > > I know the help for these is in ?Control, but I sometimes make the
> > > mistake of typing ?for instead. What is R expecting me to say to finish
> > > the statement?
> > ]
> > Further hint: ? is an operator, syntactically similar to + and -. You
> > can apply operators to the result of a for loop. Consider for example
> > 
> > x <- 1; - for (i in 1:10) x <- x * i
> > 
> > (? has special semantics, but that is not noticed at parse time).
> > 
> Unfortunately the original question still hasn't been answered
> explicitly, not even in ?help.
> Try:
> > ?for
> + (i in 0) 0
> or:
> > ?if
> + (T) T
> or:
> > ?+
> + 0
> 
> So you have to provide the rest of a syntactically complete statement.
> 
> Just to see if you now understand exactly how ? works, what do you
> think:
> ? paste("help")
> will do?
> 
> Ray Brownrigg
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Charles.Annis at statisticalengineering.com  Mon Nov 17 21:33:13 2003
From: Charles.Annis at statisticalengineering.com (Charles Annis, P.E.)
Date: Mon, 17 Nov 2003 15:33:13 -0500
Subject: [R] image processing
Message-ID: <01f101c3ad4a$0921c8a0$2802a8c0@DHT0TL11>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031117/a2117ea8/attachment.pl

From kfung95 at yahoo.com  Mon Nov 17 21:33:37 2003
From: kfung95 at yahoo.com (Kaiser Fung)
Date: Mon, 17 Nov 2003 12:33:37 -0800 (PST)
Subject: [R] rpart postscript graphics, Mac OS
Message-ID: <20031117203337.42461.qmail@web21102.mail.yahoo.com>


I am running R on Mac OS X 10.2x.  When I create
postscript graphics of rpart tree objects, a tiny part
of the tree gets trimmed off, even when it has only a
few terminal nodes.  This happens even without fancy
but worse if fancy=T.  (This doesn't happen with
boxplot, scatter plots, etc.)  How do I fix this?

postscript("tree.eps")
plot(davb.tree, u=T)
text(davb.tree, use.n=T, fancy=F)
dev.off()

Thanks
Kais



From MSchwartz at medanalytics.com  Mon Nov 17 21:58:45 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 17 Nov 2003 14:58:45 -0600
Subject: [R] ?for
In-Reply-To: <Pine.LNX.4.44.0311172026240.4841-100000@gannet.stats>
References: <Pine.LNX.4.44.0311172026240.4841-100000@gannet.stats>
Message-ID: <1069102724.4563.124.camel@localhost.localdomain>

On Mon, 2003-11-17 at 14:27, Prof Brian Ripley wrote:
> Well ^C or ESC (on Windows GUI) is the answer I would give.
> 
> On Tue, 18 Nov 2003, Ray Brownrigg wrote:
> 
> > Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
> > > 
> > > Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> > > 
> > > > You have typed a syntactically incomplete statement: this is explained in 
> > > > ?help.
> > > > 
> > > > Hint: ?"for" and help("for") work.
> > > 
> > > [Original question added back in:
> > > On Sun, 16 Nov 2003, Angel wrote:
> > > 
> > > > I have always been intrigued by why ?for (or ?if,?while,etc) leave R
> > > > wanting for more:
> > > > > ?for
> > > > +
> > > > I know the help for these is in ?Control, but I sometimes make the
> > > > mistake of typing ?for instead. What is R expecting me to say to finish
> > > > the statement?
> > > ]
> > > Further hint: ? is an operator, syntactically similar to + and -. You
> > > can apply operators to the result of a for loop. Consider for example
> > > 
> > > x <- 1; - for (i in 1:10) x <- x * i
> > > 
> > > (? has special semantics, but that is not noticed at parse time).
> > > 
> > Unfortunately the original question still hasn't been answered
> > explicitly, not even in ?help.
> > Try:
> > > ?for
> > + (i in 0) 0
> > or:
> > > ?if
> > + (T) T
> > or:
> > > ?+
> > + 0
> > 
> > So you have to provide the rest of a syntactically complete statement.
> > 
> > Just to see if you now understand exactly how ? works, what do you
> > think:
> > ? paste("help")
> > will do?
> > 
> > Ray Brownrigg


R 1.8.1 Beta using gnome-terminal on Fedora Core 1 gives:

> ? paste("help")
help() for paste  is shown in browser /usr/bin/mozilla ...
Use      help( paste , htmlhelp=FALSE)
or       options(htmlhelp = FALSE)
to revert.


However, using ESS with emacs on the same platform gives:

> ? paste("help")

Error in help("paste(", htmlhelp = FALSE) : 
	No documentation for 'paste(' in specified packages and libraries:
  you could try 'help.search("paste(")'


:-)

Marc



From apv at capital.net  Mon Nov 17 22:08:03 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 17 Nov 2003 16:08:03 -0500
Subject: [R] \preformatted and $
Message-ID: <1069103283.21583.15.camel@redtail.mydomain.home>

Hi,

I have been developing a package in R and have been working on
documentation.  I have a \details function that contains the following:

\details{

some text

\preformatted{
[my-section]
user = apv
host = 127.0.0.1
}

}

 When I run R CMD check I get an error while checking the manual.  If I
remove:

\preformatted{
[my-section]
user = apv
host = 127.0.0.1
}

and replace it with 

[my-section]
user = apv
host = 127.0.0.1

the error goes away.

Has anybody had this problem?  

I have also have a problem including a '$' in my documentation.  I
replace them with \$ which made latex happy but then \$ showed up in the
HTML and R help.

Any advice would be appreciated,
Arend van der Veen



From jbusch at ui.urban.org  Mon Nov 17 23:51:22 2003
From: jbusch at ui.urban.org (Busch, Joe)
Date: Mon, 17 Nov 2003 17:51:22 -0500
Subject: [R] Looking for recommendations for optimal memory settings
Message-ID: <4CD371A22A53D411B60F00508B6F39B003ED1A1E@UINT4>

We have a Windows 2000 operating system and I need to configure the
workstations.  What are your recommendations for users with very large data
sets (300Mb)?  The systems are Dell GX240s with 512 Mbs of Ram.  What
command line or environment variables work best?


Sincerely,

Joe Busch
Urban Institute



From merbirk at yahoo.com  Tue Nov 18 00:21:18 2003
From: merbirk at yahoo.com (Merrill Birkner)
Date: Mon, 17 Nov 2003 15:21:18 -0800 (PST)
Subject: [R] reordering numbers in a vector
Message-ID: <20031117232118.8769.qmail@web20010.mail.yahoo.com>

Suppose you initially create a vector a<-c(5,1,3,4). 
You want to sort the vector before performing specific
calculations to the numbers.  You now have the vector
[1,3,4,5].  How can you now revert back to your
initial ordering of [5,1,3,4]? Is there a specific
command or 'sort by' command that one could use?

Thanks again-



From sundar.dorai-raj at pdf.com  Tue Nov 18 00:26:30 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 17 Nov 2003 17:26:30 -0600
Subject: [R] reordering numbers in a vector
In-Reply-To: <20031117232118.8769.qmail@web20010.mail.yahoo.com>
References: <20031117232118.8769.qmail@web20010.mail.yahoo.com>
Message-ID: <3FB95926.8070306@pdf.com>



Merrill Birkner wrote:
> Suppose you initially create a vector a<-c(5,1,3,4). 
> You want to sort the vector before performing specific
> calculations to the numbers.  You now have the vector
> [1,3,4,5].  How can you now revert back to your
> initial ordering of [5,1,3,4]? Is there a specific
> command or 'sort by' command that one could use?
> 
> Thanks again-
> 

I think what you want is ?order.

a <- c(5, 1, 3, 4)
a.ord <- a[order(a)]

HTH,
Sundar



From GPetris at uark.edu  Tue Nov 18 00:36:01 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Mon, 17 Nov 2003 17:36:01 -0600 (CST)
Subject: [R] reordering numbers in a vector
In-Reply-To: <20031117232118.8769.qmail@web20010.mail.yahoo.com> (message from
	Merrill Birkner on Mon, 17 Nov 2003 15:21:18 -0800 (PST))
References: <20031117232118.8769.qmail@web20010.mail.yahoo.com>
Message-ID: <200311172336.hAHNa1K8021249@definetti.uark.edu>


If you need only to sort a vector, then sort() does the job.
To go back to the original vector, the following may work:

> x <- unique(rpois(30,5))
> x
[1] 8 5 3 4 6 9 2 7
> x.sorted <- sort(x)
> x.sorted
[1] 2 3 4 5 6 7 8 9
> x.sorted[order(order(x))]
[1] 8 5 3 4 6 9 2 7


HTH,
Giovanni

> Date: Mon, 17 Nov 2003 15:21:18 -0800 (PST)
> From: Merrill Birkner <merbirk at yahoo.com>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> Suppose you initially create a vector a<-c(5,1,3,4). 
> You want to sort the vector before performing specific
> calculations to the numbers.  You now have the vector
> [1,3,4,5].  How can you now revert back to your
> initial ordering of [5,1,3,4]? Is there a specific
> command or 'sort by' command that one could use?
> 
> Thanks again-
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From rxg218 at psu.edu  Tue Nov 18 01:28:26 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 17 Nov 2003 19:28:26 -0500
Subject: [R] sampling without repetition
Message-ID: <1069115306.25782.9.camel@ra.chem.psu.edu>

Hi,
  I'm trying to write a function that will divide a given range of
numbers into 3 sets using sample(), without repetition. Currently I'm
trying this approach:

r <- 1:10
s1 <- sample(r,size=3)

Next, I want to remove the selected elements from r and sample() from
the remainder.

r <- r[ -(r=s1) ]
s2 <- sample(r,size=3)

When I go to remove the elements contained in s2 from r I get an error:

r <- r[ -(r=s2) ]
Error: subscript out of bounds

I'm not sure why this is happening. I tried replacing the '=' with '=='
but I get another error 

Warning message:
longer object length
        is not a multiple of shorter object length in: r == s1

Essentially what I need is to get the indices into r of the elements of
s1 & s2. I have looked at which but I cant seem to work out how I can
get the indices into r of all the elements of, say, s1.

Does anybody have any suggestions? (Of course if there is a more elegant
way of doing this whole thing I would appreciate any pointers)

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A committee is a life form with six or more legs and no brain.
-- Lazarus Long, "Time Enough For Love"



From tblackw at umich.edu  Tue Nov 18 02:01:31 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 17 Nov 2003 20:01:31 -0500 (EST)
Subject: [R] sampling without repetition
In-Reply-To: <1069115306.25782.9.camel@ra.chem.psu.edu>
References: <1069115306.25782.9.camel@ra.chem.psu.edu>
Message-ID: <Pine.SOL.4.58.0311172000040.284@rygar.gpcc.itd.umich.edu>

Rajarshi  -

Do you want three sets, three disjoint sets, or sets of
size three ?  It's not clear what you are attempting to do.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 17 Nov 2003, Rajarshi Guha wrote:

> Hi,
>   I'm trying to write a function that will divide a given range of
> numbers into 3 sets using sample(), without repetition. Currently I'm
> trying this approach:
>
> r <- 1:10
> s1 <- sample(r,size=3)
>
> Next, I want to remove the selected elements from r and sample() from
> the remainder.
>
> r <- r[ -(r=s1) ]
> s2 <- sample(r,size=3)
>
> When I go to remove the elements contained in s2 from r I get an error:
>
> r <- r[ -(r=s2) ]
> Error: subscript out of bounds
>
> I'm not sure why this is happening. I tried replacing the '=' with '=='
> but I get another error
>
> Warning message:
> longer object length
>         is not a multiple of shorter object length in: r == s1
>
> Essentially what I need is to get the indices into r of the elements of
> s1 & s2. I have looked at which but I cant seem to work out how I can
> get the indices into r of all the elements of, say, s1.
>
> Does anybody have any suggestions? (Of course if there is a more elegant
> way of doing this whole thing I would appreciate any pointers)
>
> Thanks,
>
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------



From rxg218 at psu.edu  Tue Nov 18 02:07:08 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 17 Nov 2003 20:07:08 -0500
Subject: [R] sampling without repetition
In-Reply-To: <Pine.SOL.4.58.0311172000040.284@rygar.gpcc.itd.umich.edu>
References: <1069115306.25782.9.camel@ra.chem.psu.edu>
	<Pine.SOL.4.58.0311172000040.284@rygar.gpcc.itd.umich.edu>
Message-ID: <1069117628.27458.2.camel@ra.chem.psu.edu>

On Mon, 2003-11-17 at 20:01, Thomas W Blackwell wrote:
> Rajarshi  -
> 
> Do you want three sets, three disjoint sets, or sets of
> size three ?  It's not clear what you are attempting to do.

Sorry about that. I wanted to select 3 disjoint sets from a supplied
vector of numbers. My initial example had 

r <- 1:300

but there is no guarantee that r will contain a consecutive sequence of
numbers.

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------

A list is only as strong as its weakest link.
-- Don Knuth



From tblackw at umich.edu  Tue Nov 18 02:13:18 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 17 Nov 2003 20:13:18 -0500 (EST)
Subject: [R] sampling without repetition
In-Reply-To: <1069117628.27458.2.camel@ra.chem.psu.edu>
References: <1069115306.25782.9.camel@ra.chem.psu.edu> 
	<Pine.SOL.4.58.0311172000040.284@rygar.gpcc.itd.umich.edu>
	<1069117628.27458.2.camel@ra.chem.psu.edu>
Message-ID: <Pine.SOL.4.58.0311172006470.284@rygar.gpcc.itd.umich.edu>

Rajarshi  -

To obtain three disjoint subsets, I would do

indic <- sample(seq(3), length(r), TRUE)
s1 <- r[indic == 1]
s2 <- r[indic == 2]
s3 <- r[indic == 3]

Note that the sizes of the three subsets have a
joint multinomial distribution with parameters
prob = c(1/3, 1/3, 1/3)  and  n = length(r).

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 17 Nov 2003, Rajarshi Guha wrote:

> On Mon, 2003-11-17 at 20:01, Thomas W Blackwell wrote:
> > Rajarshi  -
> >
> > Do you want three sets, three disjoint sets, or sets of
> > size three ?  It's not clear what you are attempting to do.
>
> Sorry about that. I wanted to select 3 disjoint sets from a supplied
> vector of numbers. My initial example had
>
> r <- 1:300
>
> but there is no guarantee that r will contain a consecutive sequence of
> numbers.
>
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
>
> A list is only as strong as its weakest link.
> -- Don Knuth
>
>



From tplate at acm.org  Tue Nov 18 02:24:41 2003
From: tplate at acm.org (Tony Plate)
Date: Mon, 17 Nov 2003 18:24:41 -0700
Subject: [R] sampling without repetition
In-Reply-To: <1069115306.25782.9.camel@ra.chem.psu.edu>
Message-ID: <5.2.1.1.2.20031117182324.041d92b0@mailhost.blackmesacapital.com>

 > r <- 1:30
 > # Random allocation to sets
 > tapply(r, sample(1:3,length(r),rep=T), c)
$"1"
  [1]  1  3  8 12 15 16 18 20 21 25 29

$"2"
  [1]  2  5  6  7  9 10 13 14 17 19 22 27 30

$"3"
[1]  4 11 23 24 26 28

 > # Equal size sets (approximately)
 > tapply(r, sample(seq(length(r))%%3), c)
$"0"
  [1]  1  6  9 10 12 15 22 24 28 30

$"1"
  [1]  2  3  4  5  8 17 18 21 23 27

$"2"
  [1]  7 11 13 14 16 19 20 25 26 29

 >

At Monday 07:28 PM 11/17/2003 -0500, you wrote:
>Hi,
>   I'm trying to write a function that will divide a given range of
>numbers into 3 sets using sample(), without repetition. Currently I'm
>trying this approach:
>
>r <- 1:10
>s1 <- sample(r,size=3)
>
>Next, I want to remove the selected elements from r and sample() from
>the remainder.
>
>r <- r[ -(r=s1) ]
>s2 <- sample(r,size=3)
>
>When I go to remove the elements contained in s2 from r I get an error:
>
>r <- r[ -(r=s2) ]
>Error: subscript out of bounds
>
>I'm not sure why this is happening. I tried replacing the '=' with '=='
>but I get another error
>
>Warning message:
>longer object length
>         is not a multiple of shorter object length in: r == s1
>
>Essentially what I need is to get the indices into r of the elements of
>s1 & s2. I have looked at which but I cant seem to work out how I can
>get the indices into r of all the elements of, say, s1.
>
>Does anybody have any suggestions? (Of course if there is a more elegant
>way of doing this whole thing I would appreciate any pointers)
>
>Thanks,
>
>-------------------------------------------------------------------
>Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>-------------------------------------------------------------------
>A committee is a life form with six or more legs and no brain.
>-- Lazarus Long, "Time Enough For Love"
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Tony Plate   tplate at acm.org



From dmurdoch at pair.com  Tue Nov 18 02:31:52 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 17 Nov 2003 20:31:52 -0500
Subject: [R] sampling without repetition
In-Reply-To: <1069117628.27458.2.camel@ra.chem.psu.edu>
References: <1069115306.25782.9.camel@ra.chem.psu.edu>
	<Pine.SOL.4.58.0311172000040.284@rygar.gpcc.itd.umich.edu>
	<1069117628.27458.2.camel@ra.chem.psu.edu>
Message-ID: <letirvkdi58so7ivhnakb9kkm0psh1l9j7@4ax.com>

On 17 Nov 2003 20:07:08 -0500, you wrote:


>Sorry about that. I wanted to select 3 disjoint sets from a supplied
>vector of numbers. My initial example had 
>
>r <- 1:300
>
>but there is no guarantee that r will contain a consecutive sequence of
>numbers.

It's still not clear whether the 3 sets should be of fixed size or
random size, and whether they should cover all of r or just part of
it.  Thomas' solution gave you a random partition.  If you just want 3
non-overlapping samples, each of size n, then do something like:

indices <- sample(1:length(r), size=3*n)
sample1 <- r[indices[1:n]]
sample2 <- r[indices[(n+1):(2*n)]]
sample3 <- r[indices[(2*n+1):(3*n)]]

Duncan Murdoch



From p.murrell at auckland.ac.nz  Tue Nov 18 03:23:30 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 18 Nov 2003 15:23:30 +1300
Subject: [R] rpart postscript graphics, Mac OS
References: <20031117203337.42461.qmail@web21102.mail.yahoo.com>
Message-ID: <3FB982A2.2080408@stat.auckland.ac.nz>

Hi


Kaiser Fung wrote:
> I am running R on Mac OS X 10.2x.  When I create
> postscript graphics of rpart tree objects, a tiny part
> of the tree gets trimmed off, even when it has only a
> few terminal nodes.  This happens even without fancy
> but worse if fancy=T.  (This doesn't happen with
> boxplot, scatter plots, etc.)  How do I fix this?
> 
> postscript("tree.eps")
> plot(davb.tree, u=T)
> text(davb.tree, use.n=T, fancy=F)
> dev.off()


It's hard to see your problem without the actual data to reproduce it. 
Does it help if you precede the plot command with par(xpd=NA)?

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From btp16 at student.canterbury.ac.nz  Tue Nov 18 03:53:33 2003
From: btp16 at student.canterbury.ac.nz (Bridget)
Date: Tue, 18 Nov 2003 15:53:33 +1300
Subject: [R]  arima() in ts
Message-ID: <3FB989AD.3050700@student.canterbury.ac.nz>

I am trying to find a way to obtain the fitted values for a model fit 
using arima() in the ts package.  I came across a suggestion in the 
mailing list archive that these values can be simply calculated as:

model<-arima(t, order = c(1,1,0));
fitted<-t-model$residuals;

But, the help file for arima() in the ts package describes the residuals 
values returned as being "standardized residuals" - I was wondering in 
what way the residuals have been standardized as they do not appear to 
always have a variance close to 1, and whether the standardization 
affects the validity of the above way of calculating the fitted values. 
  If so, is there any easy way to get the fitted values?

Bridget



From rxg218 at psu.edu  Tue Nov 18 04:42:25 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 17 Nov 2003 22:42:25 -0500
Subject: [R] sampling without repetition
In-Reply-To: <letirvkdi58so7ivhnakb9kkm0psh1l9j7@4ax.com>
References: <1069115306.25782.9.camel@ra.chem.psu.edu>
	<Pine.SOL.4.58.0311172000040.284@rygar.gpcc.itd.umich.edu>
	<1069117628.27458.2.camel@ra.chem.psu.edu>
	<letirvkdi58so7ivhnakb9kkm0psh1l9j7@4ax.com>
Message-ID: <1069126940.2817.8.camel@localhost.localdomain>

On Mon, 2003-11-17 at 20:31, Duncan Murdoch wrote:
> On 17 Nov 2003 20:07:08 -0500, you wrote:
> 
> 
> >Sorry about that. I wanted to select 3 disjoint sets from a supplied
> >vector of numbers. My initial example had 
> >
> >r <- 1:300
> >
> >but there is no guarantee that r will contain a consecutive sequence of
> >numbers.
> 
> It's still not clear whether the 3 sets should be of fixed size or
> random size, and whether they should cover all of r or just part of
> it.  Thomas' solution gave you a random partition.  If you just want 3
> non-overlapping samples, each of size n, then do something like:

Sorry for not providing all the details.

The 3 sets can be of any size (which will be specified by the user of
the function) and cover all of r (ie, set1 + set2 + set3 == r)

Thanks to everybody for all the solutions.

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
"I'd love to go out with you, but there are important world issues that
need worrying about."



From Paul.Sorenson at vision-bio.com  Tue Nov 18 04:54:51 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Tue, 18 Nov 2003 14:54:51 +1100
Subject: [R] RE: relationship between two discrete variables
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C602C2B6C2@ewok.vsl.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031118/5d2cf1c4/attachment.pl

From ripley at stats.ox.ac.uk  Tue Nov 18 06:52:13 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 05:52:13 +0000 (GMT)
Subject: [R] Looking for recommendations for optimal memory settings
In-Reply-To: <4CD371A22A53D411B60F00508B6F39B003ED1A1E@UINT4>
Message-ID: <Pine.LNX.4.44.0311180548500.5568-100000@gannet.stats>

On Mon, 17 Nov 2003, Busch, Joe wrote:

> We have a Windows 2000 operating system and I need to configure the
> workstations.  What are your recommendations for users with very large data
> sets (300Mb)?  The systems are Dell GX240s with 512 Mbs of Ram.  What
> command line or environment variables work best?

The default ones.  Just add another 1.5Gb of RAM and then consider
using --max-mem-size, the only setting that will make any real difference.
(The next minor version of R, probably 1.9.0, will make better use of 2Gb 
under Windows than the current one, so you may want to compile up 
pre-releases of that.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Friedrich.Leisch at ci.tuwien.ac.at  Tue Nov 18 09:01:26 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Tue, 18 Nov 2003 09:01:26 +0100
Subject: [R] Fwd: License Agreement
In-Reply-To: <sfb8d4b6.015@cis27.hosts.jhmi.edu>
References: <sfb8d4b6.015@cis27.hosts.jhmi.edu>
Message-ID: <16313.53718.821456.344954@galadriel.ci.tuwien.ac.at>

>>>>> On Mon, 17 Nov 2003 14:01:17 -0500,
>>>>> Sigrid Volko (SV) wrote:


  > Dear Mr. Leisch,

[don't know why you assume that I'm behind r-help ... but anyway ...

  > I was asked by one of our faculty members at Johns Hopkins University to =
  > assist him in licensing a software application that he has developed. This =
  > package is based on R, the statistical software that is distributed as =
  > freeware. In the course of my due diligence analysis, I reviewed the =
  > official R web page which states that R is an official part of the Free =
  > Software Foundation's GNU project. However, it does not explicitly state =
  > under which License Agreement R is made available. Reviewing the GNU =
  > official web page, I assume that R is made available under the GNU General =
  > Public License. I would, however, appreciate if you could confirm that =
  > this information is correct.=20


I think the web page clearly states that R is indeed distributed under
the terms of the GPL ... and if you use R you get a pointer to the GPL
every time you start it.

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From ligges at statistik.uni-dortmund.de  Tue Nov 18 09:01:54 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Nov 2003 09:01:54 +0100 (MET)
Subject: [R] rpart postscript graphics, Mac OS
In-Reply-To: <3FB982A2.2080408@stat.auckland.ac.nz>
Message-ID: <Pine.GSO.4.21.0311180858130.8047-100000@amadeus.statistik.uni-dortmund.de>



On Tue, 18 Nov 2003, Paul Murrell wrote:

> Hi
> 
> 
> Kaiser Fung wrote:
> > I am running R on Mac OS X 10.2x.  When I create
> > postscript graphics of rpart tree objects, a tiny part
> > of the tree gets trimmed off, even when it has only a
> > few terminal nodes.  This happens even without fancy
> > but worse if fancy=T.  (This doesn't happen with
> > boxplot, scatter plots, etc.)  How do I fix this?
> > 
> > postscript("tree.eps")
> > plot(davb.tree, u=T)
> > text(davb.tree, use.n=T, fancy=F)
> > dev.off()
> 
> 
> It's hard to see your problem without the actual data to reproduce it. 
> Does it help if you precede the plot command with par(xpd=NA)?


Well, the "problem" is known (calculating the required space for labeling 
etc. is hard), hence the argument "margin" in plot.rpart().
?plot.rpart tells you:

"margin: an extra percentage of white space to leave around the borders of
the tree. (Long labels sometimes get cut off by the default computation)."  

margin=0.1 is sufficient in most cases.

Uwe Ligges



From maj at stats.waikato.ac.nz  Tue Nov 18 09:09:30 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 18 Nov 2003 21:09:30 +1300
Subject: [R] sampling without repetition
In-Reply-To: <1069126940.2817.8.camel@localhost.localdomain>
References: <letirvkdi58so7ivhnakb9kkm0psh1l9j7@4ax.com>
	<1069115306.25782.9.camel@ra.chem.psu.edu>
	<Pine.SOL.4.58.0311172000040.284@rygar.gpcc.itd.umich.edu>
	<1069117628.27458.2.camel@ra.chem.psu.edu>
	<letirvkdi58so7ivhnakb9kkm0psh1l9j7@4ax.com>
Message-ID: <E1AM0wu-0005Gv-00@newton.math.waikato.ac.nz>

Really you just want a random permutation of r:

> rperm <- sample(r)

Then you can obtain a random partition of r into cells of any desired size
simply by taking appropriately-sized consecutive blocks of rperm.

Murray

At 22:42 17/11/2003 -0500, Rajarshi Guha wrote:

>Sorry for not providing all the details.
>
>The 3 sets can be of any size (which will be specified by the user of
>the function) and cover all of r (ie, set1 + set2 + set3 == r)
>
>Thanks to everybody for all the solutions.
>
>-------------------------------------------------------------------
>Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>-------------------------------------------------------------------
>"I'd love to go out with you, but there are important world issues that
>need worrying about."
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From jwdougherty at mcihispeed.net  Tue Nov 18 09:23:52 2003
From: jwdougherty at mcihispeed.net (John Dougherty)
Date: Tue, 18 Nov 2003 00:23:52 -0800
Subject: [R] Compiling R
Message-ID: <200311180023.52845.jwdougherty@mcihispeed.net>

I have a generally successful compiled R 1.8.0 version installed on a SuSE 9.0 
system.  One frustration however is that the basic keyboard functions of BASH 
have not completely carried through and the up, down, left and right arrow 
keys don't behave as they do on the regular shell command line.  That is no 
command history can be accessed and the cursor cannot be back-spaced over a 
recalled command to edit it.  I expect that I am missing a "--with-" statment 
but I am not certain what it should be.  	Is there any help file that details 
the fine points for compiling R?  INSTALL does not contain the information I 
am interested in.

Thank you,
jwdougherty



From ripley at stats.ox.ac.uk  Tue Nov 18 09:44:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 08:44:53 +0000 (GMT)
Subject: [R] Compiling R
In-Reply-To: <200311180023.52845.jwdougherty@mcihispeed.net>
Message-ID: <Pine.LNX.4.44.0311180841080.19726-100000@gannet.stats>

>From INSTALL:

The main source of information on installation is the `R Installation
and Administration Manual', an HTML copy of which is available as file
`doc/html/R-admin.html'.  Please read that before installing R.  But
if you are impatient, read on but please refer to the manual to
resolve any problems.

Hint: you are missing the readline development RPMs, and that is covered 
in the manual you were asked to read.

On Tue, 18 Nov 2003, John Dougherty wrote:

> I have a generally successful compiled R 1.8.0 version installed on a SuSE 9.0 
> system.  One frustration however is that the basic keyboard functions of BASH 
> have not completely carried through and the up, down, left and right arrow 
> keys don't behave as they do on the regular shell command line.  That is no 
> command history can be accessed and the cursor cannot be back-spaced over a 
> recalled command to edit it.  I expect that I am missing a "--with-" statment 
> but I am not certain what it should be.  	Is there any help file that details 
> the fine points for compiling R?  INSTALL does not contain the information I 
> am interested in.

but it does tell you *exactly* where to look.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue Nov 18 09:45:50 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Nov 2003 09:45:50 +0100 (MET)
Subject: [R] Compiling R
In-Reply-To: <200311180023.52845.jwdougherty@mcihispeed.net>
Message-ID: <Pine.GSO.4.21.0311180945220.8428-100000@amadeus.statistik.uni-dortmund.de>



On Tue, 18 Nov 2003, John Dougherty wrote:

> I have a generally successful compiled R 1.8.0 version installed on a SuSE 9.0 
> system.  One frustration however is that the basic keyboard functions of BASH 
> have not completely carried through and the up, down, left and right arrow 
> keys don't behave as they do on the regular shell command line.  That is no 
> command history can be accessed and the cursor cannot be back-spaced over a 
> recalled command to edit it.  I expect that I am missing a "--with-" statment 
> but I am not certain what it should be.  	Is there any help file that details 
> the fine points for compiling R?  INSTALL does not contain the information I 
> am interested in.
> 
> Thank you,
> jwdougherty
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

See the R Installation and Administration manual, available at CRAN and in
the sources.

Uwe Ligges



From liulei at l.imap.itd.umich.edu  Tue Nov 18 09:50:00 2003
From: liulei at l.imap.itd.umich.edu (Lei Liu)
Date: Tue, 18 Nov 2003 03:50:00 -0500
Subject: [R] mixed model for Splus and R
Message-ID: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031118/5c9a55b2/attachment.pl

From thomas at holm.cn  Tue Nov 18 10:26:35 2003
From: thomas at holm.cn (Thomas Holm)
Date: Tue, 18 Nov 2003 11:26:35 +0200
Subject: [R] Copula calculation in R?
In-Reply-To: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA8HhJkkxNukea7wv0NzTGUsKAAAAQAAAA65L8nh6oJEKmUtAQEgZESwEAAAAA@holm.cn>

Hello

Anyone that now of any function in R that can calculate copulas?
Or if anyone have any code avaible I would be more than interested. 

Thank you in advance

/Thomas



From ligges at statistik.uni-dortmund.de  Tue Nov 18 10:40:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Nov 2003 10:40:06 +0100 (MET)
Subject: [R] \preformatted and $
In-Reply-To: <1069103283.21583.15.camel@redtail.mydomain.home>
Message-ID: <Pine.GSO.4.21.0311181030480.8997-100000@amadeus.statistik.uni-dortmund.de>



On 17 Nov 2003, Arend P. van der Veen wrote:

> Hi,
> 
> I have been developing a package in R and have been working on
> documentation.  I have a \details function that contains the following:
> 
> \details{
> 
> some text
> 
> \preformatted{
> [my-section]
> user = apv
> host = 127.0.0.1
> }
> 
> }
> 
>  When I run R CMD check I get an error while checking the manual.  If I
> remove:
> 
> \preformatted{
> [my-section]
> user = apv
> host = 127.0.0.1
> }
> 
> and replace it with 
> 
> [my-section]
> user = apv
> host = 127.0.0.1
> 
> the error goes away.
> 
> Has anybody had this problem?  

Confirmed. The problem is that there is no newline after
\end{verbatim}
in the produced TeX code, so we get, e.g.:
\end{verbatim}\end{Details}
.

Might be fixed in R-patched (I don't have access right now).


> 
> I have also have a problem including a '$' in my documentation.  I
> replace them with \$ which made latex happy but then \$ showed up in the
> HTML and R help.

Hmmm. All of the following works for me:

\$, \code{$}, and \deqn{\$}{$}


Uwe Ligges



> Any advice would be appreciated,
> Arend van der Veen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jeff.hamann at forestinformatics.com  Tue Nov 18 10:44:25 2003
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Tue, 18 Nov 2003 01:44:25 -0800
Subject: [R] data.frame subset?
Message-ID: <002401c3adb8$8dcf32e0$0a00a8c0@rodan>

Can someone tell me why this is since I can't seem to find an explination in
the docs or FAQ for this.

Since there are no "BM" in the mtrs data.frame, but only in the "parent"
data.frame (trees), I'm assuming the subset data.frame is still associated
with the original. Is that correct and how would I create a completly
separate data.frame since I'll be using by, lapply and such on the subset
data.frame using "sp" which currently causes by to choke...

> mtrs <- trees[trees$m == 1,]
> mtrs
    plot tree sp m dbh tht   bfvol   cfvol
1      1    1 DF 1  44 185 3825.79  622.97
2      1    2 DF 1  38 188 3166.69  504.12
26     3    1 DF 1  42 185 3568.80  578.09
51     5    4 DF 1  30 189 2071.36  348.28
67     7    1 DF 1  33 168 2036.30  342.90
70     7    4 DF 1  45 180 3665.82  621.90
71     7    5 DF 1  30 160 1530.88  274.69
81     9    1 DF 1  44 175 3398.52  576.79
82     9    2 DF 1  68 205 9516.82 1461.21
95    11    1 DF 1  30 170 1775.60  299.54
96    11    2 DF 1  44 197 4249.98  680.64
97    11    3 DF 1  44 187 3914.88  632.42
107   11   13 WH 1  44 175 3398.52  576.79
121   13    2 WF 1  48 205 5241.14  827.57
126   13    7 DF 1  40 182 3188.77  522.43
138   15    2 DF 1  69 182 7852.22 1285.42
143   15    7 DF 1  28 142 1146.77  207.67
159   17    9 DF 1  12  88   99.13   25.43
177   19    7 DF 1  37 162 2309.06  391.48
> attributes( mtrs$sp )
$class
[1] "factor"

$levels
[1] "BM" "DF" "WF" "WH"

>

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From joehl at gmx.de  Tue Nov 18 10:59:47 2003
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Tue, 18 Nov 2003 10:59:47 +0100 (MET)
Subject: [R] How to return a big treelike list from .Call Interface (protect
	stack overflow)
Message-ID: <18200.1069149587@www54.gmx.net>


I try to create a big treelike list structure using the RDefines/RInternal
macros. The tree carries information at each node (attribute list) and at each
leaf (vector). 
My understanding is that for each node I add to the binary tree I have to
call 
  PROTECT(newnode = NEW_LIST(2)); 
and cannot UNPROTECT before I return the whole tree. Same story for node
attributes and leaf vectors. However, this way I easily reach the limit of the
proteckt stack at 10000 (BTW this error is not catched). How can I increase
the protect stack? Is there a better way to create such an R structure? 
Can one do C-side recursive list assignment MyList[[c(1,2,1,2,2,1)]] <<-
NewSEXP without calling the R evaluator?

Thanks for any help
Best regards


Jens Oehlschl?gel

-- 
GMX Weihnachts-Special: Seychellen-Traumreise zu gewinnen!

Rentier entlaufen. Finden Sie Rudolph! Als Belohnung winken tolle
Preise. http://www.gmx.net/de/cgi/specialmail/



From ligges at statistik.uni-dortmund.de  Tue Nov 18 11:01:32 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Nov 2003 11:01:32 +0100 (MET)
Subject: [R] data.frame subset?
In-Reply-To: <002401c3adb8$8dcf32e0$0a00a8c0@rodan>
Message-ID: <Pine.GSO.4.21.0311181100300.9693-100000@amadeus.statistik.uni-dortmund.de>



On Tue, 18 Nov 2003, Jeff D. Hamann wrote:

> Can someone tell me why this is since I can't seem to find an explination in
> the docs or FAQ for this.
> 
> Since there are no "BM" in the mtrs data.frame, but only in the "parent"
> data.frame (trees), I'm assuming the subset data.frame is still associated
> with the original. Is that correct and how would I create a completly
> separate data.frame since I'll be using by, lapply and such on the subset
> data.frame using "sp" which currently causes by to choke...
> 
> > mtrs <- trees[trees$m == 1,]
> > mtrs
>     plot tree sp m dbh tht   bfvol   cfvol
> 1      1    1 DF 1  44 185 3825.79  622.97
> 2      1    2 DF 1  38 188 3166.69  504.12
> 26     3    1 DF 1  42 185 3568.80  578.09
> 51     5    4 DF 1  30 189 2071.36  348.28
> 67     7    1 DF 1  33 168 2036.30  342.90
> 70     7    4 DF 1  45 180 3665.82  621.90
> 71     7    5 DF 1  30 160 1530.88  274.69
> 81     9    1 DF 1  44 175 3398.52  576.79
> 82     9    2 DF 1  68 205 9516.82 1461.21
> 95    11    1 DF 1  30 170 1775.60  299.54
> 96    11    2 DF 1  44 197 4249.98  680.64
> 97    11    3 DF 1  44 187 3914.88  632.42
> 107   11   13 WH 1  44 175 3398.52  576.79
> 121   13    2 WF 1  48 205 5241.14  827.57
> 126   13    7 DF 1  40 182 3188.77  522.43
> 138   15    2 DF 1  69 182 7852.22 1285.42
> 143   15    7 DF 1  28 142 1146.77  207.67
> 159   17    9 DF 1  12  88   99.13   25.43
> 177   19    7 DF 1  37 162 2309.06  391.48
> > attributes( mtrs$sp )
> $class
> [1] "factor"
> 
> $levels
> [1] "BM" "DF" "WF" "WH"
> 


A factor remembers all its levels unless you tell to drop them as in:
 mtrs <- trees[trees$m == 1, , drop = TRUE]

Uwe Ligges



From C.M.P.Pelletier at westminster.ac.uk  Tue Nov 18 11:08:39 2003
From: C.M.P.Pelletier at westminster.ac.uk (Christine Pelletier)
Date: Tue, 18 Nov 2003 10:08:39 -0000
Subject: [R] Is it possible to source a R program in VBA?
Message-ID: <000e01c3adbb$f0842eb0$ca884aa1@boufnitsa>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031118/25216dd1/attachment.pl

From christian.schulz at questico.de  Tue Nov 18 11:17:45 2003
From: christian.schulz at questico.de (Christian Schulz)
Date: Tue, 18 Nov 2003 11:17:45 +0100
Subject: [R] x[x > y]  and more conditions
Message-ID: <JAEELBHBOPKJDMMCNHKMKEGJCBAA.christian.schulz@questico.de>

...and  i'm getting all cases which
are true for above condition and get the information
how many cases match, too. The vector's are in a attached data.frame.

FAKTOR30[FAKTOR30 > 0.234]
...................
[102193] 0.352 0.352 0.288 0.354 0.352 0.358 0.352 0.352 0.311 0.370 0.352
0.336
[102205] 0.352 0.274 0.352 0.405 0.354 0.352 0.352 0.352 0.352 0.352 0.352
0.340
[102217] 0.352 0.352


But if i use more than one "index" term
UMSATZ30[UMSATZ30 > 10] && FAKTOR30[FAKTOR30 = 0.234]

[1] NA

I get  true, false  or NA  and the latter i think this mean there isn't any
case with this condition!?
But, how can i check cases with more than one condition like the single
example, i trial some but getting no success?

Many thanks for help,
christian



From ligges at statistik.uni-dortmund.de  Tue Nov 18 11:28:52 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Nov 2003 11:28:52 +0100 (MET)
Subject: [R] x[x > y]  and more conditions
In-Reply-To: <JAEELBHBOPKJDMMCNHKMKEGJCBAA.christian.schulz@questico.de>
Message-ID: <Pine.GSO.4.21.0311181126340.9693-100000@amadeus.statistik.uni-dortmund.de>



On Tue, 18 Nov 2003, Christian Schulz wrote:

> ...and  i'm getting all cases which
> are true for above condition and get the information
> how many cases match, too. The vector's are in a attached data.frame.
> 
> FAKTOR30[FAKTOR30 > 0.234]
> ...................
> [102193] 0.352 0.352 0.288 0.354 0.352 0.358 0.352 0.352 0.311 0.370 0.352
> 0.336
> [102205] 0.352 0.274 0.352 0.405 0.354 0.352 0.352 0.352 0.352 0.352 0.352
> 0.340
> [102217] 0.352 0.352
> 
> 
> But if i use more than one "index" term
> UMSATZ30[UMSATZ30 > 10] && FAKTOR30[FAKTOR30 = 0.234]
> 
> [1] NA

See ?"&&" which tells you to use "&" instead os "&&" for vectorized
logical operations like this one.

Using "&&" only evaluates the first elements of those logical vectors, so
there seems to be an NA in UMSATZ30[1] or FAKTOR30[1]....

Uwe Ligges

 
> I get  true, false  or NA  and the latter i think this mean there isn't any
> case with this condition!?
> But, how can i check cases with more than one condition like the single
> example, i trial some but getting no success?
> 
> Many thanks for help,
> christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Tue Nov 18 11:39:11 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Nov 2003 11:39:11 +0100
Subject: [R] How to return a big treelike list from .Call Interface
	(protect stack overflow)
In-Reply-To: <18200.1069149587@www54.gmx.net>
References: <18200.1069149587@www54.gmx.net>
Message-ID: <x28yme6jw0.fsf@biostat.ku.dk>

"Jens Oehlschl?gel" <joehl at gmx.de> writes:

> I try to create a big treelike list structure using the RDefines/RInternal
> macros. The tree carries information at each node (attribute list) and at each
> leaf (vector). 
> My understanding is that for each node I add to the binary tree I have to
> call 
>   PROTECT(newnode = NEW_LIST(2)); 
> and cannot UNPROTECT before I return the whole tree. Same story for node
> attributes and leaf vectors. However, this way I easily reach the limit of the
> proteckt stack at 10000 (BTW this error is not catched). How can I increase
> the protect stack? Is there a better way to create such an R structure? 
> Can one do C-side recursive list assignment MyList[[c(1,2,1,2,2,1)]] <<-
> NewSEXP without calling the R evaluator?

Nono, protection is recursive. You can UNPROTECT as soon as a
structure becomes part of a PROTECT'ed structure, or even avoid
protection at all if you assign immediately, e.g.

SET_VECTOR_ELT(oldnode,0, newnode=NEW_LIST(2))

I believe the protect stack overflow situation has improved in 1.8.1.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Joerg.Schaber at uv.es  Tue Nov 18 11:32:58 2003
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Tue, 18 Nov 2003 11:32:58 +0100
Subject: [R] package compilation
Message-ID: <3FB9F55A.9050005@uv.es>

Hi,

I recently wrote a new R package, which I could 'R CMD check' and 'R CMD 
build' nicely on my Intel Linux PC. Loading the new library as a normal 
user on my PC also works nicely.
This packages includes some compiled C-code in a shared library. 
However, before submitting the package to CRAN I wanted to install it 
also under an other platform in order to check if everything works 
 fine. Obviously, in order to install it under another platform I have 
to recompile the shared lib. So I added a /src directory in the library 
containing the C source code and than run a 'R CMD build'. However, 
running 'R CMD INSTALL'  on the resulting tar.gz archive does not 
recompile the source code on the new machine. But installing other 
packages having a /src directory the source code is recompiled.
So what do I have to do that running a 'R CMD install' on my *tar.gz 
file recompiles de source code and creates a platform dependend shared lib?
Thanks,

joerg



From ligges at statistik.uni-dortmund.de  Tue Nov 18 11:52:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Nov 2003 11:52:39 +0100 (MET)
Subject: [R] package compilation
In-Reply-To: <3FB9F55A.9050005@uv.es>
Message-ID: <Pine.GSO.4.21.0311181149550.9693-100000@amadeus.statistik.uni-dortmund.de>



On Tue, 18 Nov 2003, Joerg Schaber wrote:

> Hi,
> 
> I recently wrote a new R package, which I could 'R CMD check' and 'R CMD 
> build' nicely on my Intel Linux PC. Loading the new library as a normal 
> user on my PC also works nicely.
> This packages includes some compiled C-code in a shared library. 
> However, before submitting the package to CRAN I wanted to install it 
> also under an other platform in order to check if everything works 
>  fine. Obviously, in order to install it under another platform I have 
> to recompile the shared lib. So I added a /src directory in the library 
> containing the C source code and than run a 'R CMD build'. However, 
> running 'R CMD INSTALL'  on the resulting tar.gz archive does not 
> recompile the source code on the new machine. But installing other 
> packages having a /src directory the source code is recompiled.
> So what do I have to do that running a 'R CMD install' on my *tar.gz 
> file recompiles de source code and creates a platform dependend shared lib?

You have to remove any binaries from that directory, but R CMD build
should have done it for you. Or does the compilation fails out of other
reasons? It's hard to guess without any more details.

Uwe Ligges



From bernd.weiss at uni-koeln.de  Tue Nov 18 11:56:38 2003
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Tue, 18 Nov 2003 11:56:38 +0100
Subject: [R] Problems installing lattice
Message-ID: <3FBA08F6.25784.5C61E4@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031118/bc295832/attachment.pl

From ripley at stats.ox.ac.uk  Tue Nov 18 12:04:52 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 11:04:52 +0000 (GMT)
Subject: [R] x[x > y]  and more conditions
In-Reply-To: <JAEELBHBOPKJDMMCNHKMKEGJCBAA.christian.schulz@questico.de>
Message-ID: <Pine.LNX.4.44.0311181104320.1270-100000@gannet.stats>

Did you mean == not = ?

On Tue, 18 Nov 2003, Christian Schulz wrote:

> ...and  i'm getting all cases which
> are true for above condition and get the information
> how many cases match, too. The vector's are in a attached data.frame.
> 
> FAKTOR30[FAKTOR30 > 0.234]
> ...................
> [102193] 0.352 0.352 0.288 0.354 0.352 0.358 0.352 0.352 0.311 0.370 0.352
> 0.336
> [102205] 0.352 0.274 0.352 0.405 0.354 0.352 0.352 0.352 0.352 0.352 0.352
> 0.340
> [102217] 0.352 0.352
> 
> 
> But if i use more than one "index" term
> UMSATZ30[UMSATZ30 > 10] && FAKTOR30[FAKTOR30 = 0.234]
> 
> [1] NA
> 
> I get  true, false  or NA  and the latter i think this mean there isn't any
> case with this condition!?
> But, how can i check cases with more than one condition like the single
> example, i trial some but getting no success?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From alessandro.semeria at cramont.it  Tue Nov 18 12:09:42 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Tue, 18 Nov 2003 12:09:42 +0100
Subject: [R] Problems installing lattice
Message-ID: <OF2C28C9D2.53D62EB4-ONC1256DE2.003D1E1D@tomware.it>


Have you installed 'grid' pkg before lattice?
Look at dependencies !

A.S.

----------------------------

Alessandro Semeria
Models and Simulations Laboratory
Montecatini Environmental Research Center (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: alessandro.semeria at cramont.it



From laurent.faisnel at ariase.com  Tue Nov 18 12:06:21 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Tue, 18 Nov 2003 12:06:21 +0100
Subject: [R] readline not found
Message-ID: <3FB9FD2D.5050107@ariase.com>

Hi all,

I just upgraded to R-1.8.0. Everything worked fine but command line 
editing does not work. This clearly indicates that readline has not been 
found in the compilation process.

How could I explicitely indicate where to find it ?

I use a Red Hat 8.0 system. I checked the FAQ which says readline-devel 
is also needed, but I have it already installed. Perhaps should I add 
the configure option --with-readline=path/to/readline ?

 >> rpm -qva | grep readline
readline-4.3-4
readline-devel-4.3-4
readline41-4.1-14

Is there a problem with that readline41 version ?

Thanks in advance,
Laurent



From ripley at stats.ox.ac.uk  Tue Nov 18 12:09:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 11:09:32 +0000 (GMT)
Subject: [R] package compilation
In-Reply-To: <Pine.GSO.4.21.0311181149550.9693-100000@amadeus.statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0311181106250.1270-100000@gannet.stats>

On Tue, 18 Nov 2003, Uwe Ligges wrote:

> 
> 
> On Tue, 18 Nov 2003, Joerg Schaber wrote:
> 
> > I recently wrote a new R package, which I could 'R CMD check' and 'R CMD 
> > build' nicely on my Intel Linux PC. Loading the new library as a normal 
> > user on my PC also works nicely.
> > This packages includes some compiled C-code in a shared library. 
> > However, before submitting the package to CRAN I wanted to install it 
> > also under an other platform in order to check if everything works 
> >  fine. Obviously, in order to install it under another platform I have 
> > to recompile the shared lib. So I added a /src directory in the library 
> > containing the C source code and than run a 'R CMD build'. However, 
> > running 'R CMD INSTALL'  on the resulting tar.gz archive does not 
> > recompile the source code on the new machine. But installing other 
> > packages having a /src directory the source code is recompiled.
> > So what do I have to do that running a 'R CMD install' on my *tar.gz 
> > file recompiles de source code and creates a platform dependend shared lib?
> 
> You have to remove any binaries from that directory, but R CMD build
> should have done it for you. Or does the compilation fails out of other
> reasons? It's hard to guess without any more details.

If you really run R CMD INSTALL foo.tar.gz (note capitals) then foo.tar.gz
is unpacked to a temporary directory and so the .so will be recompiled.

I suspect it find nothing to compile: check carefully what is in the 
foo.tar.gz.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From christian.schulz at questico.de  Tue Nov 18 12:09:24 2003
From: christian.schulz at questico.de (Christian Schulz)
Date: Tue, 18 Nov 2003 12:09:24 +0100
Subject: AW: [R] x[x > y]  and more conditions
In-Reply-To: <Pine.GSO.4.21.0311181126340.9693-100000@amadeus.statistik.uni-dortmund.de>
Message-ID: <JAEELBHBOPKJDMMCNHKMCEGLCBAA.christian.schulz@questico.de>

Thanks for the hint's, and sorry
for my confusing, which come from my
sql activity which need &&  or AND.

regards,christian




-----Ursprungliche Nachricht-----
Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
Gesendet: Dienstag, 18. November 2003 11:29
An: Christian Schulz
Cc: R-Help
Betreff: Re: [R] x[x > y] and more conditions




On Tue, 18 Nov 2003, Christian Schulz wrote:

> ...and  i'm getting all cases which
> are true for above condition and get the information
> how many cases match, too. The vector's are in a attached data.frame.
>
> FAKTOR30[FAKTOR30 > 0.234]
> ...................
> [102193] 0.352 0.352 0.288 0.354 0.352 0.358 0.352 0.352 0.311 0.370 0.352
> 0.336
> [102205] 0.352 0.274 0.352 0.405 0.354 0.352 0.352 0.352 0.352 0.352 0.352
> 0.340
> [102217] 0.352 0.352
>
>
> But if i use more than one "index" term
> UMSATZ30[UMSATZ30 > 10] && FAKTOR30[FAKTOR30 = 0.234]
>
> [1] NA

See ?"&&" which tells you to use "&" instead os "&&" for vectorized
logical operations like this one.

Using "&&" only evaluates the first elements of those logical vectors, so
there seems to be an NA in UMSATZ30[1] or FAKTOR30[1]....

Uwe Ligges


> I get  true, false  or NA  and the latter i think this mean there isn't
any
> case with this condition!?
> But, how can i check cases with more than one condition like the single
> example, i trial some but getting no success?
>
> Many thanks for help,
> christian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Tue Nov 18 12:43:45 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Nov 2003 12:43:45 +0100
Subject: [R] readline not found
In-Reply-To: <3FB9FD2D.5050107@ariase.com>
References: <3FB9FD2D.5050107@ariase.com>
Message-ID: <x2u1516gwe.fsf@biostat.ku.dk>

Laurent Faisnel <laurent.faisnel at ariase.com> writes:

> Hi all,
> 
> I just upgraded to R-1.8.0. Everything worked fine but command line
> editing does not work. This clearly indicates that readline has not
> been found in the compilation process.
> 
> How could I explicitely indicate where to find it ?
> 
> I use a Red Hat 8.0 system. I checked the FAQ which says
> readline-devel is also needed, but I have it already installed.
> Perhaps should I add the configure option
> --with-readline=path/to/readline ?
> 
>  >> rpm -qva | grep readline
> readline-4.3-4
> readline-devel-4.3-4
> readline41-4.1-14
> 
> Is there a problem with that readline41 version ?

It shouldn't get used. This should work cleanly on RH8.0 and does for
me. Best idea I can come up with is to clean up, reconfigure, and
check the out put and configure log for some anomaly in your local
configuration (paths, something hardcoding --without-readline, etc.).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jc at or.psychology.dal.ca  Tue Nov 18 13:13:14 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Tue, 18 Nov 2003 08:13:14 -0400
Subject: [R] installing a local package in RAqua
Message-ID: <95E732BC-19C0-11D8-953E-000A956DE534@or.psychology.dal.ca>

Hi,
	How does one install a package that is local rather than on CRAN?



From karlknoblich at yahoo.de  Tue Nov 18 13:22:10 2003
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Tue, 18 Nov 2003 13:22:10 +0100 (CET)
Subject: [R] aov with Error and lme
Message-ID: <20031118122210.14637.qmail@web10008.mail.yahoo.com>

Hi

I searched in the list and only found questions
without answers e.g.
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/19955.html
: Is there a way to get the same results with lme as
with aov with Error()?

Can anybody reproduce the following results with lme:
id<-c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5)
factA<-c("al","al","al","al","al","al","al","al","al","al","al","al","al","al","al","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3")
factB<-c("B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3")
Y<-c(56,52,48,57,54,46,55,51,51,58,51,50,54,53,46,54,50,49,53,49,48,56,48,52,52,52,50,55,51,46,57,49,50,55,51,47,56,48,51,58,50,48,58,46,52)

df<-data.frame(id, factA, factB, Y)

df$id<-as.factor(df$id)
df.aov <- aov(Y ~ factA*factB + Error(factA:id),
data=df)
summary(df.aov)

Hope, somebody can help!

Karl





__________________________________________________________________

Gesendet von Yahoo! Mail - http://mail.yahoo.de
Logos und Klingelt?ne f?rs Handy bei http://sms.yahoo.de



From ripley at stats.ox.ac.uk  Tue Nov 18 13:39:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 12:39:21 +0000 (GMT)
Subject: [R] aov with Error and lme
In-Reply-To: <20031118122210.14637.qmail@web10008.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311181229290.1547-100000@gannet.stats>

There are worked examples in MASS (at least the last two editions) of
getting `the same results with lme as with aov with Error()'.

Your over-long lines make it difficult to see, but this appears to be very 
similar to examples both in MASS and in Pinheiro & Bates.  Have you 
consulted either?


On Tue, 18 Nov 2003, Karl Knoblick wrote:

> I searched in the list and only found questions
> without answers e.g.
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/19955.html
> : Is there a way to get the same results with lme as
> with aov with Error()?
> 
> Can anybody reproduce the following results with lme:
> id<-c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5)
> factA<-c("al","al","al","al","al","al","al","al","al","al","al","al","al","al","al","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3")
> factB<-c("B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3")
> Y<-c(56,52,48,57,54,46,55,51,51,58,51,50,54,53,46,54,50,49,53,49,48,56,48,52,52,52,50,55,51,46,57,49,50,55,51,47,56,48,51,58,50,48,58,46,52)
> 
> df<-data.frame(id, factA, factB, Y)
> 
> df$id<-as.factor(df$id)
> df.aov <- aov(Y ~ factA*factB + Error(factA:id),
> data=df)
> summary(df.aov)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jc at or.psychology.dal.ca  Tue Nov 18 14:17:19 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Tue, 18 Nov 2003 09:17:19 -0400
Subject: [R] installing a local package in RAqua
In-Reply-To: <1069159664.28976.0.camel@ra.chem.psu.edu>
References: <95E732BC-19C0-11D8-953E-000A956DE534@or.psychology.dal.ca>
	<1069159664.28976.0.camel@ra.chem.psu.edu>
Message-ID: <895EBF97-19C9-11D8-953E-000A956DE534@or.psychology.dal.ca>


RAqua doesn't provide the external command capability.  Unless...

OK, I see, I can call R from the command line by giving the full path 
through the package.

On Nov 18, 2003, at 8:47 AM, a helpful list reader wrote:

> On Tue, 2003-11-18 at 07:13, John Christie wrote:
>> Hi,
>> 	How does one install a package that is local rather than on CRAN?
>
> I have'nt used RAqua but the docs mention R CMD INSTALL packagname



From apv at capital.net  Tue Nov 18 14:25:17 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 18 Nov 2003 08:25:17 -0500
Subject: [R] \preformatted and $
In-Reply-To: <Pine.GSO.4.21.0311181030480.8997-100000@amadeus.statistik.uni-dortmund.de>
References: <Pine.GSO.4.21.0311181030480.8997-100000@amadeus.statistik.uni-dortmund.de>
Message-ID: <1069161917.26274.18.camel@redtail.mydomain.home>

I found my problem with the second item ('$').  As far as the first
problem with \preformatted, I check the tex code that was generated and
found that 

\end{verbatim}\end{Details}

However, if I add some text between the preformatted text and the end of
the detail section it works.  I will use that as a work around.

\details{
some text
\preformatted{
[my-section]
user = apv
host = 127.0.0.1
}
some more text
}

If anybody knows if this bug is corrected in the patch please let me
know.

Thanks,
Arend  

On Tue, 2003-11-18 at 04:40, Uwe Ligges wrote:
> On 17 Nov 2003, Arend P. van der Veen wrote:
> 
> > Hi,
> > 
> > I have been developing a package in R and have been working on
> > documentation.  I have a \details function that contains the following:
> > 
> > \details{
> > 
> > some text
> > 
> > \preformatted{
> > [my-section]
> > user = apv
> > host = 127.0.0.1
> > }
> > 
> > }
> > 
> >  When I run R CMD check I get an error while checking the manual.  If I
> > remove:
> > 
> > \preformatted{
> > [my-section]
> > user = apv
> > host = 127.0.0.1
> > }
> > 
> > and replace it with 
> > 
> > [my-section]
> > user = apv
> > host = 127.0.0.1
> > 
> > the error goes away.
> > 
> > Has anybody had this problem?  
> 
> Confirmed. The problem is that there is no newline after
> \end{verbatim}
> in the produced TeX code, so we get, e.g.:
> \end{verbatim}\end{Details}
> .
> 
> Might be fixed in R-patched (I don't have access right now).
> 
> 
> > 
> > I have also have a problem including a '$' in my documentation.  I
> > replace them with \$ which made latex happy but then \$ showed up in the
> > HTML and R help.
> 
> Hmmm. All of the following works for me:
> 
> \$, \code{$}, and \deqn{\$}{$}
> 
> 
> Uwe Ligges
> 
> 
> 
> > Any advice would be appreciated,
> > Arend van der Veen
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
>



From nielssteenkrogh at hotmail.com  Tue Nov 18 14:45:36 2003
From: nielssteenkrogh at hotmail.com (Niels Steen Krogh)
Date: Tue, 18 Nov 2003 14:45:36 +0100
Subject: [R] howto improve sharpeness of fonts in a jpg-image produced by R ?
Message-ID: <BAY7-F70vY3ieanzFmC00015d9c@hotmail.com>

Hi.
I've done a standard barplotexample using R1-8.0, redhat8, probably using a 
GhostScript-integration.

How can I improve the "sharpness" of the fonts.
See for example the barplot (originally jpg coming from R) which is part of 
this screendump:
http://www.zug.dk/Members/Nielssteenkrogh/1067525916309553166/element_103003161029

I'm not sure where to improve the this. Is it an R-issue or an 
GhostScript-issue or?

/Niels

Cand. Polit.
Niels Steen Krogh
Solsortvej 44
2000 F.

Tlf: 3888 8613

ZiteLab / EmpoweR youR data with R, Zope and SOAP

_________________________________________________________________
F? alle de nye og sjove ikoner med MSN Messenger http://messenger.msn.dk/



From bates at stat.wisc.edu  Tue Nov 18 14:53:24 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 18 Nov 2003 07:53:24 -0600
Subject: [R] Looking for recommendations for optimal memory settings
In-Reply-To: <Pine.LNX.4.44.0311180548500.5568-100000@gannet.stats>
References: <Pine.LNX.4.44.0311180548500.5568-100000@gannet.stats>
Message-ID: <6rvfphbx63.fsf@bates4.stat.wisc.edu>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Mon, 17 Nov 2003, Busch, Joe wrote:
> 
> > We have a Windows 2000 operating system and I need to configure the
> > workstations.  What are your recommendations for users with very large data
> > sets (300Mb)?  The systems are Dell GX240s with 512 Mbs of Ram.  What
> > command line or environment variables work best?
> 
> The default ones.  Just add another 1.5Gb of RAM and then consider
> using --max-mem-size, the only setting that will make any real difference.
> (The next minor version of R, probably 1.9.0, will make better use of 2Gb 
> under Windows than the current one, so you may want to compile up 
> pre-releases of that.)

>From what I can see in looking at a couple of reviews, the GX240 uses
PC133 DIMMs and comes standard with 256 MB.  Depending on the number
of DIMM slots on the motherboard and the capacity of each slot it may
only be able to handle 1GB of memory and even that may mean removing
the 256 MB DIMMs to replace them with 512 MB DIMMs.  The good news is
that doing so is reasonably cheap.  According to www.pricewatch.com PC133
512 MB DIMMs are available for as little as (US)$40 whereas PC133 1 GB
DIMMs are (US)$160 and up.



From ripley at stats.ox.ac.uk  Tue Nov 18 14:57:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 13:57:30 +0000 (GMT)
Subject: [R] \preformatted and $
In-Reply-To: <1069161917.26274.18.camel@redtail.mydomain.home>
Message-ID: <Pine.LNX.4.44.0311181351030.1736-100000@gannet.stats>

On 18 Nov 2003, Arend P. van der Veen wrote:

> I found my problem with the second item ('$').  As far as the first
> problem with \preformatted, I check the tex code that was generated and
> found that 
> 
> \end{verbatim}\end{Details}
> 
> However, if I add some text between the preformatted text and the end of
> the detail section it works.  I will use that as a work around.
> 
> \details{
> some text
> \preformatted{
> [my-section]
> user = apv
> host = 127.0.0.1
> }
> some more text
> }
> 
> If anybody knows if this bug is corrected in the patch please let me
> know.

Not yet, as this is not actually the bug: look what happens when there is 
text at the end of the \details section.

> 
> Thanks,
> Arend  
> 
> On Tue, 2003-11-18 at 04:40, Uwe Ligges wrote:
> > On 17 Nov 2003, Arend P. van der Veen wrote:
> > 
> > > Hi,
> > > 
> > > I have been developing a package in R and have been working on
> > > documentation.  I have a \details function that contains the following:
> > > 
> > > \details{
> > > 
> > > some text
> > > 
> > > \preformatted{
> > > [my-section]
> > > user = apv
> > > host = 127.0.0.1
> > > }
> > > 
> > > }
> > > 
> > >  When I run R CMD check I get an error while checking the manual.  If I
> > > remove:
> > > 
> > > \preformatted{
> > > [my-section]
> > > user = apv
> > > host = 127.0.0.1
> > > }
> > > 
> > > and replace it with 
> > > 
> > > [my-section]
> > > user = apv
> > > host = 127.0.0.1
> > > 
> > > the error goes away.
> > > 
> > > Has anybody had this problem?  
> > 
> > Confirmed. The problem is that there is no newline after
> > \end{verbatim}
> > in the produced TeX code, so we get, e.g.:
> > \end{verbatim}\end{Details}
> > .
> > 
> > Might be fixed in R-patched (I don't have access right now).
> > 
> > 
> > > 
> > > I have also have a problem including a '$' in my documentation.  I
> > > replace them with \$ which made latex happy but then \$ showed up in the
> > > HTML and R help.
> > 
> > Hmmm. All of the following works for me:
> > 
> > \$, \code{$}, and \deqn{\$}{$}
> > 
> > 
> > Uwe Ligges
> > 
> > 
> > 
> > > Any advice would be appreciated,
> > > Arend van der Veen
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Tue Nov 18 15:00:17 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 18 Nov 2003 08:00:17 -0600
Subject: [R] mixed model for Splus and R
In-Reply-To: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
References: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
Message-ID: <6rptfpbwum.fsf@bates4.stat.wisc.edu>

Lei Liu <liulei at l.imap.itd.umich.edu> writes:

> I try to compare the mixed model package "lme" by Splus and R. I used the 
> dataset "Ovary" and the following code assuming AR(1) model for the error term:
> 
> lme(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), data=Ovary, random = 
> pdDiag(~sin(2*pi*Time) ) , correlation=corAR1() )
> 
> But I got different results! And then I used a simpler model:
> 
> lme(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), data=Ovary, random = 
> pdDiag(~sin(2*pi*Time)) )
> 
> This time I got the same output. I wonder the reason for the inconsistence 
> between R and Splus. I attached the results as follows. Can someone tell me 
> how to do it correctly in R? Thanks!
> 
> Lei
> 
> Result from R:
> 
> ******************************************************************
> Linear mixed-effects model fit by REML
>    Data: Ovary
>    Log-restricted-likelihood: -775.2224
>    Fixed: follicles ~ sin(2 * pi * Time) + cos(2 * pi * Time)
>         (Intercept) sin(2 * pi * Time) cos(2 * pi * Time)
>          12.1895808         -2.9473432         -0.8807113
> 
> Random effects:
>   Formula: ~sin(2 * pi * Time) | Mare
>   Structure: Diagonal
>          (Intercept) sin(2 * pi * Time) Residual
> StdDev:    2.807293         0.03630784 3.665217
> 
> Correlation Structure: AR(1)
>   Formula: ~1 | Mare
>   Parameter estimate(s):
>        Phi
> 0.6073908
> Number of Observations: 308
> Number of Groups: 11
> 
> *****************************************************************************************
> 
> Result from Splus:
> 
> *****************************************************************************************
> Linear mixed-effects model fit by REML
>    Data: Ovary
>    Log-restricted-likelihood: -774.724
>    Fixed: follicles ~ sin(2 * pi * Time) + cos(2 * pi * Time)
>   (Intercept) sin(2 * pi * Time) cos(2 * pi * Time)
>      12.18809          -2.985282         -0.8777629
> 
> Random effects:
>   Formula:  ~ sin(2 * pi * Time) | Mare
>   Structure: Diagonal
>          (Intercept) sin(2 * pi * Time) Residual
> StdDev:    2.858478            1.25802 3.507097
> 
> Correlation Structure: AR(1)
>   Formula:  ~ 1 | Mare
>   Parameter estimate(s):
>         Phi
>   0.5722019
> Number of Observations: 308
> Number of Groups: 11
>   ******************************************************************************************

S-PLUS and R use different optimizer code so the results will not be
identical.  You may want to check with intervals() to see how
well-defined the optima are.  Also try setting
control=list(msVerbose=TRUE) in the call to lme to see how the actual
optimization is behaving.

The log-likelihood in complex lme and nlme models can be a difficult
function to optimize.  I am aware that the results from R's optimizer(s)
are not always as good as those from the optimizer used in S-PLUS and
we are working on rectifying that problem.



From karlknoblich at yahoo.de  Tue Nov 18 15:00:28 2003
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Tue, 18 Nov 2003 15:00:28 +0100 (CET)
Subject: [R] aov with Error and lme
In-Reply-To: <Pine.LNX.4.44.0311181229290.1547-100000@gannet.stats>
Message-ID: <20031118140028.63408.qmail@web10006.mail.yahoo.com>

Thanks!

But I could not find it in MASS 2nd edition, also not
a similiar example to mine in Pinheiro Bates. I
thought at least for a balanced and quite simple
design the results should be equal. Is that wrong?

Karl.

 --- Prof Brian Ripley <ripley at stats.ox.ac.uk>
schrieb: > There are worked examples in MASS (at least
the last
> two editions) of
> getting `the same results with lme as with aov with
> Error()'.
> 
> Your over-long lines make it difficult to see, but
> this appears to be very 
> similar to examples both in MASS and in Pinheiro &
> Bates.  Have you 
> consulted either?
> 
> 
> On Tue, 18 Nov 2003, Karl Knoblick wrote:
> 
> > I searched in the list and only found questions
> > without answers e.g.
> >
>
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/19955.html
> > : Is there a way to get the same results with lme
> as
> > with aov with Error()?
> > 
> > Can anybody reproduce the following results with
> lme:
> >
>
id<-c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5)
> >
>
factA<-c("al","al","al","al","al","al","al","al","al","al","al","al","al","al","al","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a2","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3","a3")
> >
>
factB<-c("B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3","B1","B2","B3")
> >
>
Y<-c(56,52,48,57,54,46,55,51,51,58,51,50,54,53,46,54,50,49,53,49,48,56,48,52,52,52,50,55,51,46,57,49,50,55,51,47,56,48,51,58,50,48,58,46,52)
> > 
> > df<-data.frame(id, factA, factB, Y)
> > 
> > df$id<-as.factor(df$id)
> > df.aov <- aov(Y ~ factA*factB + Error(factA:id),
> > data=df)
> > summary(df.aov)
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>  


__________________________________________________________________

Gesendet von Yahoo! Mail - http://mail.yahoo.de
Logos und Klingelt?ne f?rs Handy bei http://sms.yahoo.de



From leguimas at yahoo.com.br  Tue Nov 18 15:04:39 2003
From: leguimas at yahoo.com.br (=?iso-8859-1?q?Leandro=20Guimar=FFffffe3es?=)
Date: Tue, 18 Nov 2003 11:04:39 -0300 (ART)
Subject: [R] Invalid Characters for hclust or dist
Message-ID: <20031118140439.88292.qmail@web60705.mail.yahoo.com>

Hi !!

   How are you ? Fines, I hope.

   Well, I'm using this function:

     hclust(dist(x), "ave);

   Where x is a table with my data.

   So, when I execute this, I was getting this error:

   "NA/NaN/Inf in foreign function call"

   I discovered this error was generated because in my
labels data there was a ' (single quote). I removed
this characters, in all ocorrencies, and the errors
stopped.

   I would want to know if there are others characters
that would generate this some problem...

   Thanks a lot and so sorry for my bad English.

Regards,

Leandro

Yahoo! Mail - 6MB, anti-spam e antiv?rus gratuito. Crie sua conta agora:
http://mail.yahoo.com.br



From ripley at stats.ox.ac.uk  Tue Nov 18 15:11:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 14:11:20 +0000 (GMT)
Subject: [R] howto improve sharpeness of fonts in a jpg-image produced
	by R ?
In-Reply-To: <BAY7-F70vY3ieanzFmC00015d9c@hotmail.com>
Message-ID: <Pine.LNX.4.44.0311181407180.1736-100000@gannet.stats>

There are two ways to make jpgs in R: which did you use?

If you want a sharp image, why are you using a format designed for 
photographic images?

I suspect your viewer: that example seems as sharp as I would expect 
viewed in a high-quality JPEG viewer on my LCD screen.

On Tue, 18 Nov 2003, Niels Steen Krogh wrote:

> Hi.
> I've done a standard barplotexample using R1-8.0, redhat8, probably using a 
> GhostScript-integration.
> 
> How can I improve the "sharpness" of the fonts.
> See for example the barplot (originally jpg coming from R) which is part of 
> this screendump:
> http://www.zug.dk/Members/Nielssteenkrogh/1067525916309553166/element_103003161029
> 
> I'm not sure where to improve the this. Is it an R-issue or an 
> GhostScript-issue or?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Tue Nov 18 15:29:46 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 18 Nov 2003 08:29:46 -0600
Subject: [R] howto improve sharpeness of fonts in a jpg-image produced
	by R ?
In-Reply-To: <BAY7-F70vY3ieanzFmC00015d9c@hotmail.com>
References: <BAY7-F70vY3ieanzFmC00015d9c@hotmail.com>
Message-ID: <1069165785.4563.290.camel@localhost.localdomain>

On Tue, 2003-11-18 at 07:45, Niels Steen Krogh wrote:
> Hi.
> I've done a standard barplotexample using R1-8.0, redhat8, probably using a 
> GhostScript-integration.
> 
> How can I improve the "sharpness" of the fonts.
> See for example the barplot (originally jpg coming from R) which is part of 
> this screendump:
> http://www.zug.dk/Members/Nielssteenkrogh/1067525916309553166/element_103003161029
> 
> I'm not sure where to improve the this. Is it an R-issue or an 
> GhostScript-issue or?
> 
> /Niels


In general for fonts, using bitmapped image formats are not the best way
to go since they cannot result in "smooth" curves.

Depending upon how you plan to actually use the images, PS/EPS/PDF
vector based image formats would yield higher quality images and fonts.

Be aware also that bitmapped images do not resize well, which is another
limitation of that format.

HTH,

Marc Schwartz



From nielssteenkrogh at hotmail.com  Tue Nov 18 16:04:13 2003
From: nielssteenkrogh at hotmail.com (Niels Steen Krogh)
Date: Tue, 18 Nov 2003 16:04:13 +0100
Subject: [R] howto improve sharpeness of fonts in a jpg-image produced by
	R ?
Message-ID: <BAY7-F104knk27XcYVJ0001646b@hotmail.com>

I used an expression like this:

bitmap(file="barplotx.jpg",type="jpeg")
barplot(c(1,2,3),c(3,4,5),main=list("Death Rates in Virginia", font = 1))
dev.off()


My question:  How can I improve the sharpeness of the text "Death Rates in 
Virginia".
Why jpeg: Its part of a web-environment using R through a SOAP-server. I 
also tried png256, jpeggray and others, but the text "Death Rates in 
Virginia" does not change sharpeness.


/Niels





Cand. Polit.
Niels Steen Krogh
Solsortvej 44
2000 F.

Tlf: 3888 8613

ZiteLab / EmpoweR youR data with R, Zope and SOAP




>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: Niels Steen Krogh <nielssteenkrogh at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] howto improve sharpeness of fonts in a jpg-image produced 
>by R ?
>Date: Tue, 18 Nov 2003 14:11:20 +0000 (GMT)
>
>There are two ways to make jpgs in R: which did you use?
>
>If you want a sharp image, why are you using a format designed for
>photographic images?
>
>I suspect your viewer: that example seems as sharp as I would expect
>viewed in a high-quality JPEG viewer on my LCD screen.
>
>On Tue, 18 Nov 2003, Niels Steen Krogh wrote:
>
> > Hi.
> > I've done a standard barplotexample using R1-8.0, redhat8, probably 
>using a
> > GhostScript-integration.
> >
> > How can I improve the "sharpness" of the fonts.
> > See for example the barplot (originally jpg coming from R) which is part 
>of
> > this screendump:
> > 
>http://www.zug.dk/Members/Nielssteenkrogh/1067525916309553166/element_103003161029
> >
> > I'm not sure where to improve the this. Is it an R-issue or an
> > GhostScript-issue or?
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

_________________________________________________________________
F? alle de nye og sjove ikoner med MSN Messenger http://messenger.msn.dk/



From deepayan at stat.wisc.edu  Tue Nov 18 16:07:21 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 18 Nov 2003 09:07:21 -0600
Subject: [R] Problems installing lattice
In-Reply-To: <3FBA08F6.25784.5C61E4@localhost>
References: <3FBA08F6.25784.5C61E4@localhost>
Message-ID: <200311180907.21801.deepayan@stat.wisc.edu>


What version of lattice is this ? (try library(help = lattice)). What happens 
when you type library(grid) ?

Both grid and lattice are recommended packages, so appropriate versions of 
both should have been installed along with R 1.8.1. From your error message 
(which mentions /usr/local/lib/R/site-library), I'm guessing you are using 
Debian. If that's the case, please check if you have r-recommended installed, 
and whether it has the same version as r-base-core. Dirk uploaded the 1.8.1 
beta packages very recently, so they may not have made it to all the mirrors 
when you upgraded.

If this does not work, we need to know how you installed R to make any further 
diagnosis.  

Deepayan

On Tuesday 18 November 2003 04:56, Bernd Weiss wrote:
> Dear all,
>
> I am not able to install the lattice package. After finishing the
> installation, I got the following error massage:
>
> -------------------snip---------------------------
> Delete downloaded files (y/N)? y
>
> Warning message:
> argument `lib' is missing: using /usr/local/lib/R/site-library in:
> install.packages("lattice")
>
> > library(lattice)
>
> Error in loadNamespace(i, c(lib.loc, .libPaths()), keep.source) :
>         There is no package called 'grid'
> Error in library(lattice) : package/namespace load failed
>
> -------------------snap---------------------------
>
> Some weaks ago a similar thread took place on this list [1]. I am using
>
> > version
>
>          _
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status   beta
> major    1
> minor    8.1
> year     2003
> month    11
> day      14
> language R
>
> So, I don't think, that my version of R should be updated.
>
> Any help would be appreciated,
>
> Bernd
>
> [1] http://finzi.psych.upenn.edu/R/Rhelp02a/archive/21118.html



From tlumley at u.washington.edu  Tue Nov 18 16:10:41 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 Nov 2003 07:10:41 -0800 (PST)
Subject: [R] installing a local package in RAqua
In-Reply-To: <895EBF97-19C9-11D8-953E-000A956DE534@or.psychology.dal.ca>
References: <95E732BC-19C0-11D8-953E-000A956DE534@or.psychology.dal.ca>
	<1069159664.28976.0.camel@ra.chem.psu.edu>
	<895EBF97-19C9-11D8-953E-000A956DE534@or.psychology.dal.ca>
Message-ID: <Pine.A41.4.58.0311180709530.17540@homer19.u.washington.edu>

On Tue, 18 Nov 2003, John Christie wrote:

>
> RAqua doesn't provide the external command capability.  Unless...
>

RAqua has a menu item on the packages menu to install a local source
package.

	-thomas

> OK, I see, I can call R from the command line by giving the full path
> through the package.
>
> On Nov 18, 2003, at 8:47 AM, a helpful list reader wrote:
>
> > On Tue, 2003-11-18 at 07:13, John Christie wrote:
> >> Hi,
> >> 	How does one install a package that is local rather than on CRAN?
> >
> > I have'nt used RAqua but the docs mention R CMD INSTALL packagname
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ripley at stats.ox.ac.uk  Tue Nov 18 16:17:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 18 Nov 2003 15:17:01 +0000 (GMT Standard Time)
Subject: [R] howto improve sharpeness of fonts in a jpg-image produced
	by R ?
In-Reply-To: <BAY7-F104knk27XcYVJ0001646b@hotmail.com>
Message-ID: <Pine.WNT.4.44.0311181511200.2584-100000@petrel>

On Tue, 18 Nov 2003, Niels Steen Krogh wrote:

> I used an expression like this:
>
> bitmap(file="barplotx.jpg",type="jpeg")

So that was nothing to do with R, as reading the help page would have told
you.  Your subject line is false: the `jpg-image' was produced by gs and
you should look into fixing your problems with that.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From apv at capital.net  Tue Nov 18 16:29:50 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 18 Nov 2003 10:29:50 -0500
Subject: [R] Histogram
Message-ID: <1069169390.26274.39.camel@redtail.mydomain.home>

Hi,

I have what should be a simple question.  I would like to generate a
histogram of

x <- c("a","b","c","b","c","c")

where the first bar to be labeled 'c' with height 3, second bar to be
labeled 'b' with height 2 and third bar to be labeled 'a' with height 1.

This should be an easy task in R but I think I am missing something?

Thanks,
Arend van der Veen



From bolker at zoo.ufl.edu  Tue Nov 18 16:49:21 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 18 Nov 2003 10:49:21 -0500 (EST)
Subject: [R] Histogram
In-Reply-To: <1069169390.26274.39.camel@redtail.mydomain.home>
Message-ID: <Pine.LNX.4.44.0311181047050.31545-100000@bolker.zoo.ufl.edu>



plot(table(factor(x,levels=c("c","b","a"))))

is at least approximately what you want (the only complicated bit is 
reversing the order of the bars from the default alphabetical order)

substituting barplot() for plot() also works

you may want to use ylab="something" in the plot or barplot command to get 
a more descriptive axis label

On 18 Nov 2003, Arend P. van der Veen wrote:

> Hi,
> 
> I have what should be a simple question.  I would like to generate a
> histogram of
> 
> x <- c("a","b","c","b","c","c")
> 
> where the first bar to be labeled 'c' with height 3, second bar to be
> labeled 'b' with height 2 and third bar to be labeled 'a' with height 1.
> 
> This should be an easy task in R but I think I am missing something?
> 
> Thanks,
> Arend van der Veen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ligges at statistik.uni-dortmund.de  Tue Nov 18 16:37:26 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Nov 2003 16:37:26 +0100 (MET)
Subject: [R] Histogram
In-Reply-To: <1069169390.26274.39.camel@redtail.mydomain.home>
Message-ID: <Pine.GSO.4.21.0311181636580.759-100000@amadeus.statistik.uni-dortmund.de>



On 18 Nov 2003, Arend P. van der Veen wrote:

> Hi,
> 
> I have what should be a simple question.  I would like to generate a
> histogram of
> 
> x <- c("a","b","c","b","c","c")
> 
> where the first bar to be labeled 'c' with height 3, second bar to be
> labeled 'b' with height 2 and third bar to be labeled 'a' with height 1.
> 
> This should be an easy task in R but I think I am missing something?
> 
> Thanks,
> Arend van der Veen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

You don't want a histogram, but a barplot:
barplot(table(x))

Uwe Ligges



From ryota.suzuki at is.titech.ac.jp  Tue Nov 18 16:47:35 2003
From: ryota.suzuki at is.titech.ac.jp (Ryota Suzuki)
Date: Wed, 19 Nov 2003 00:47:35 +0900
Subject: [R] Histogram
References: <1069169390.26274.39.camel@redtail.mydomain.home>
Message-ID: <3FBA3F17.1000604@is.titech.ac.jp>

Arend P. van der Veen wrote:
> Hi,
>
> I have what should be a simple question.  I would like to generate a
> histogram of
>
> x <- c("a","b","c","b","c","c")
>
> where the first bar to be labeled 'c' with height 3, second bar to be
> labeled 'b' with height 2 and third bar to be labeled 'a' with height 1.

Maybe the following would help you:

x <- c("a","b","c","b","c","c")
x.fac <- factor(x)
plot(x.fac)

Best Regards,
Ryota Suzuki

>
> This should be an easy task in R but I think I am missing something?
>
> Thanks,
> Arend van der Veen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Tue Nov 18 16:58:37 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Nov 2003 16:58:37 +0100
Subject: [R] Histogram
In-Reply-To: <1069169390.26274.39.camel@redtail.mydomain.home>
References: <1069169390.26274.39.camel@redtail.mydomain.home>
Message-ID: <x2brr9653m.fsf@biostat.ku.dk>

"Arend P. van der Veen" <apv at capital.net> writes:

> Hi,
> 
> I have what should be a simple question.  I would like to generate a
> histogram of
> 
> x <- c("a","b","c","b","c","c")
> 
> where the first bar to be labeled 'c' with height 3, second bar to be
> labeled 'b' with height 2 and third bar to be labeled 'a' with height 1.
> 
> This should be an easy task in R but I think I am missing something?

That's not a histogram...

barplot(rev(table(x)))

will do it, or - allowing more general level shuffling - 

barplot(table(factor(x,levels=c("c","b","a"))))

or 

barplot(rev(sort(table(x))))

if you want the columns by decreasing frequency.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Tue Nov 18 16:56:33 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 18 Nov 2003 09:56:33 -0600
Subject: [R] howto improve sharpeness of fonts in a jpg-image produced
	by R ?
In-Reply-To: <BAY7-F104knk27XcYVJ0001646b@hotmail.com>
References: <BAY7-F104knk27XcYVJ0001646b@hotmail.com>
Message-ID: <1069170993.4563.330.camel@localhost.localdomain>

On Tue, 2003-11-18 at 09:04, Niels Steen Krogh wrote:
> I used an expression like this:
> 
> bitmap(file="barplotx.jpg",type="jpeg")
> barplot(c(1,2,3),c(3,4,5),main=list("Death Rates in Virginia", font = 1))
> dev.off()
> 
> 
> My question:  How can I improve the sharpeness of the text "Death Rates in 
> Virginia".
> Why jpeg: Its part of a web-environment using R through a SOAP-server. I 
> also tried png256, jpeggray and others, but the text "Death Rates in 
> Virginia" does not change sharpeness.
> 
> 
> /Niels

SNIP

As Prof. Ripley indicated, this is a Ghostscript (GS) issue, where R is
simply providing an interface of sorts to that application.

One option, at the expense of larger file and image size, is to increase
the dpi resolution for the image that GS generates, using the 'res'
argument in bitmap():

bitmap(file = "barplotx300.jpg", type = "jpeg", res = 300)
barplot(c(1, 2, 3), c(3, 4, 5), 
        main = list("Death Rates in Virginia",  font = 1))
dev.off()

You will likely get a better result (and a smaller file size) using a
PNG format file, if you must stay with a bitmapped approach:

bitmap(file = "barplotx300.png", type = "png256", res = 300)
barplot(c(1, 2, 3), c(3, 4, 5), 
        main = list("Death Rates in Virginia",  font = 1))
dev.off()

Keep in mind that PNG uses a lossless compression approach, whereas JPEG
will typically use a lossy compression, which results in a general
degradation of the image quality.

You can play around with the resolution settings until you get something
that is acceptable. The default is 72 which is fine for photographs in
browsers, but not for plots.

Keep in mind that the above will result in larger image dimensions using
the default height and width arguments. The above images will be 1800 x
1800 pixels, so you will need to scale accordingly. Notice however, that
even upon magnification, the fonts are still not as crisp as a vector
format image.

For example, try these and zoom in on the text:

pdf(file = "barplotx.pdf")
barplot(c(1, 2, 3), c(3, 4, 5), 
        main = list("Death Rates in Virginia", font = 1))
dev.off()

or this:

postscript(file = "barplotx.ps")
barplot(c(1, 2, 3), c(3, 4, 5), 
        main = list("Death Rates in Virginia", font = 1))
dev.off()

Both the PDF and PS formats will look even better printed.

HTH,

Marc Schwartz



From dmurdoch at pair.com  Tue Nov 18 17:17:53 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 18 Nov 2003 11:17:53 -0500
Subject: [R] Histogram
In-Reply-To: <1069169390.26274.39.camel@redtail.mydomain.home>
References: <1069169390.26274.39.camel@redtail.mydomain.home>
Message-ID: <8ehkrvkrpevv5mrgajhvsq7l5qd7j3qqm4@4ax.com>

On 18 Nov 2003 10:29:50 -0500, "Arend P. van der Veen"
<apv at capital.net> wrote :

>Hi,
>
>I have what should be a simple question.  I would like to generate a
>histogram of
>
>x <- c("a","b","c","b","c","c")
>
>where the first bar to be labeled 'c' with height 3, second bar to be
>labeled 'b' with height 2 and third bar to be labeled 'a' with height 1.
>
>This should be an easy task in R but I think I am missing something?

Try  barplot(rev(table(x))).

You use table() to calculate frequencies of discrete classes (and
hist() to count frequencies of different bins for continuous
variables), rev() to reverse the order from the natural order, and
barplot() to plot the bars.

Duncan Murdoch



From maechler at stat.math.ethz.ch  Tue Nov 18 17:22:04 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 Nov 2003 17:22:04 +0100
Subject: [R] Copula calculation in R?
Message-ID: <16314.18220.130078.516002@gargle.gargle.HOWL>


Hello
Anyone that now of any function in R that can calculate copulas?
Or if anyone have any code avaible I would be more than interested. 

Thank you in advance

/Thomas

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gregory.lefebvre at univ-rouen.fr  Tue Nov 18 17:55:37 2003
From: gregory.lefebvre at univ-rouen.fr (gregory)
Date: Tue, 18 Nov 2003 17:55:37 +0100
Subject: [R] time series
Message-ID: <3FBA4F09.9070702@univ-rouen.fr>

Hi the list,

I did not find what I was looking for in archives, thus I decide to send 
this mail.

I would like to do a regression on this kind of dataset where s1 et s2 
are values of the same variable:

time   0      15    60    240
s1      A1   B1   C1    D1
s2      A2   B2   C1    D2

I tryed in vain to use the ts package but it seems I am not able to 
create a ts object with my dataframe.


In advance thank a lot

Greg



From maechler at stat.math.ethz.ch  Tue Nov 18 17:51:23 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 Nov 2003 17:51:23 +0100
Subject: [R] Copula calculation in R?
In-Reply-To: <16314.18220.130078.516002@gargle.gargle.HOWL>
References: <16314.18220.130078.516002@gargle.gargle.HOWL>
Message-ID: <16314.19979.711200.162157@gargle.gargle.HOWL>

I'm sorry for my accidental reply

(which was caused by the fact that you were lazy and did 
 reply to an *existing* r-help posting and changed the subject
 instead of writing a new e-mail -- this destroys all threading
 ("sort+indent according to one topic") in the archives and many
 people's mail readers 
)

    >> Hello
    >> Anyone that now of any function in R that can calculate copulas?
    >> Or if anyone have any code avaible I would be more than interested. 

    >> Thank you in advance

    >> /Thomas

Now to the answer:  There is some S-plus code around here at ETH
that I could get.  Please inquire privately if there isn't a
better answer here.

Regards,

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From mn216 at columbia.edu  Tue Nov 18 18:04:09 2003
From: mn216 at columbia.edu (Murad Nayal)
Date: Tue, 18 Nov 2003 12:04:09 -0500
Subject: [R] SVM question
Message-ID: <3FBA5109.E3804D52@columbia.edu>



Hello all,

I am trying to use svm (from the e1071 package) to solve a binary
classification problem. The two classes in my particular data set are
unequally populated. class 'I' (for important) has about 3000 instances
while class "B" (for background) has about 20,000. experimenting with
different classifiers I realized that in cases where such an asymmetry
exists there is a danger in trivially inflating accuracy levels by
biasing the classifier towards the more prevalent class. for example,
using the numbers cited above, if the testing set maintains the same
distribution of classes as the original data set then you can get an
accuracy of about 85% by simply classifying everything as a "B". an
unsatisfactory classifier given the 'importance' of detecting the "I"
class.

which brings me to my question: I am trying to adjust for these issues
by 

- using the class.weights parameter of svm: I couldn't quite get a sense
of how to use this parameter from the svm help page (or the introductory
papers on the libsvm web site). Is this supposed to be a vector of the
priors for the two classes i.e. c(I=.15,B=.85) (which gave me horrible
coverage of the 'I' class). is there any 'correct' or conventional
values to use for this parameter in cases of unequal sample sizes (for
example, the 'complement' of the priors: c(I=0.85,B=0.15) on the grounds
that these values will give the two classes in the dataset equal
weights. or is it simply another tunable parameter. 

- choosing training sets that contain randomly selected but equal
numbers of cases of each class (and testing on the remaining cases. this
is repeated to assess stability of the accuracy and coverage values).
here i get mediocre accuracy but respectable coverage of "I". This is
not strictly an R question, but I thought someone on the list might have
had recent experience with these types of problems and can offer some
comments about such an approach.

many thanks

 
-- 
Murad Nayal M.D. Ph.D.
Department of Biochemistry and Molecular Biophysics
College of Physicians and Surgeons of Columbia University
630 West 168th Street. New York, NY 10032
Tel: 212-305-6884	Fax: 212-305-6926



From Joerg.Schaber at uv.es  Tue Nov 18 18:41:38 2003
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Tue, 18 Nov 2003 18:41:38 +0100
Subject: [R] \samp tag
Message-ID: <3FBA59D2.9050806@uv.es>

Hi

including the  \samp tag in Rd files gives me errors creating the 
tex-documentation.
How can I escape literal sequences in Rd files? \preformatted also does 
not seem to work.

joerg



From mailinglist2_wegmann at web.de  Tue Nov 18 19:07:00 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Tue, 18 Nov 2003 19:07:00 +0100
Subject: [R] adding variable
Message-ID: <200311181907.00945.mailinglist2_wegmann@web.de>

Hello, 

I have count data of animals (here y, y1, y2...) and env. variables (x, x1, 
x2 ,....).

I used a glm 

glm(y~x1+x2+x3....)

glm(y1~x1+x2+x3....)

and now I would like to add the count data of other species to investigate if 
they might have a bigger impact than the env. variables:

#x? are the selected var from the first glm run

glm(y~x?+x?+y1)

glm(y~x?+x?+x?+y2)

....

I wonder if there is a more elegant method to do this than adding (and 
removing) each y by hand. 

thanks in advance, cheers Martin



From laurent.faisnel at ariase.com  Tue Nov 18 19:06:40 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Tue, 18 Nov 2003 19:06:40 +0100
Subject: [R] readline not found
References: <3FB9FD2D.5050107@ariase.com>
	<x2u1516gwe.fsf@biostat.ku.dk>	<3FBA1BD5.7010700@ariase.com>
	<x2llqd674i.fsf@biostat.ku.dk>
Message-ID: <3FBA5FB0.2010502@ariase.com>

The problem is solved.
I cc this mail to John who probably had the same kind of problem.

Peter Dalgaard wrote:
> Laurent Faisnel <laurent.faisnel at ariase.com> writes:
> 

That's the part of the log where you have the debug information (at the 
top) :

> 
>>configure:11773: gcc -o conftest -g -O2  -L/usr/local/lib conftest.c
>>-lreadline  -ldl -lm  >&5
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `tgetnum'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `tgoto'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `tgetflag'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `BC'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `tputs'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `PC'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `tgetent'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `UP'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.2/../../../libreadline.so:
>>undefined reference to `tgetstr'
> 
> 
> Oho... I think those routines are from libncurses,

I'm very impressed by your intuition (or memory). That's exactly where 
the problem was.

> so you might be
> needing
> 
> ncurses-5.2-28

I already had this one installed. Not sufficient.

> ncurses-devel-5.2-28

But not this one. Once it is installed, evrything works fine and I have 
a readline-enabled R version.

> 
> (not sure you really need the last one, but...)
> 

It's really needed.

More info : http://dbforums.com/arch/147/2002/12/608415 (exactly the same)

Peter : Thanks a lot.

John : Hope it's a solution to your problem too.

	
   - Laurent



From ripley at stats.ox.ac.uk  Tue Nov 18 19:32:28 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 18:32:28 +0000 (GMT)
Subject: [R] adding variable
In-Reply-To: <200311181907.00945.mailinglist2_wegmann@web.de>
Message-ID: <Pine.LNX.4.44.0311181830450.1014-100000@gannet.stats>

On Tue, 18 Nov 2003, Martin Wegmann wrote:

> I have count data of animals (here y, y1, y2...) and env. variables (x, x1, 
> x2 ,....).
> 
> I used a glm 
> 
> glm(y~x1+x2+x3....)
> 
> glm(y1~x1+x2+x3....)
> 
> and now I would like to add the count data of other species to investigate if 
> they might have a bigger impact than the env. variables:
> 
> #x? are the selected var from the first glm run
> 
> glm(y~x?+x?+y1)
> 
> glm(y~x?+x?+x?+y2)
> 
> ....
> 
> I wonder if there is a more elegant method to do this than adding (and 
> removing) each y by hand. 

Do you mean each x?  In either case, see ?update.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From William.Simpson at drdc-rddc.gc.ca  Tue Nov 18 14:40:36 2003
From: William.Simpson at drdc-rddc.gc.ca (Bill Simpson)
Date: Tue, 18 Nov 2003 08:40:36 -0500 (EST)
Subject: [R] model formula
Message-ID: <Pine.LNX.4.44.0311180837090.12229-100000@localhost.localdomain>

I have continuous variables x, y, z. The plot of the data looks like this:

y
|                           z=1(o), 2(@), 3(#), 4(*)
|
|*   *  *
|
|
|#   #   #  #
|
|
|@    @    @  @
|
|                     o
|               o
|          o
|     o  
|o
------------------------ x
The correct model appears to be: if z==1, y~x+z; else y~z
(y~z + z:x isn't it)

How can I express this model in lm()? If I can't express it properly in
lm(), what is the best way to fit the model?

Thanks for any help.

Bill Simpson



From ripley at stats.ox.ac.uk  Tue Nov 18 19:45:36 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 18:45:36 +0000 (GMT)
Subject: [R] \samp tag
In-Reply-To: <3FBA59D2.9050806@uv.es>
Message-ID: <Pine.LNX.4.44.0311181825110.968-100000@gannet.stats>

On Tue, 18 Nov 2003, Joerg Schaber wrote:

> including the  \samp tag in Rd files gives me errors creating the 
> tex-documentation.

Examples, please.

> How can I escape literal sequences in Rd files?

See `Writing R Extensions' for what needs escaping and how.

> \preformatted also does 
> not seem to work.

In what sense does \preformatted not seem to work?  An unrelated bug
in latex (sic) processing has been fixed based on earlier correspondence.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tmurph6 at po-box.mcgill.ca  Tue Nov 18 19:47:17 2003
From: tmurph6 at po-box.mcgill.ca (tmurph6@po-box.mcgill.ca)
Date: Tue, 18 Nov 2003 13:47:17 -0500
Subject: [R] HMisc describe -- error with dates
In-Reply-To: <20031111212521.1d6dda5e.feh3k@spamcop.net>
References: <20031112014050.6D7A8394F@mprdmxin.myway.com>
	<20031111212521.1d6dda5e.feh3k@spamcop.net>
Message-ID: <1069181237.3fba69355b44f@webmail.mcgill.ca>

Thank you Gabor and Frank for you replies last week. Unfortunately I still don't
get it (I'm kind of new at this). Just to recap: I'm starting with a Julian
date and want results presented as 11NOV2003, for example (or some other date
format with no time component). 

The HMisc describe function accepts variables that I have now formatted like
this   

>date.ddmmmyy(aidsdate)

whereas it does not like variables formatted like this

>dates(aidsdate,format="day.mon.year", origin=c(month = 1, day = 1, year =
1960))

which is what I was using with an earlier version of Hmisc.

I wasn't able to figure out how to use posix.

The problem now is that, unlike before, the dates are not sorted (at least not
chronologically--maybe like character variables) and I liked seeing the 5
lowest and highest dates in the describe output. 

Sorry for pestering, but it is a testimony to how much I like Hmisc :)

Thanks!

Tanya



Quoting Frank E Harrell Jr <feh3k at spamcop.net>:

> On Tue, 11 Nov 2003 20:40:50 -0500 (EST)
> "Gabor Grothendieck" <ggrothendieck at myway.com> wrote:
> 
> > 
> > 
> > dates is part of chron.  There may be something wrong in 
> > Hmisc's detection of chron objects.
> > 
> > > chron(1)
> > [1] 01/02/70
> > 
> > > isChron(chron(1))
> > FALSE
> > 
> > ---
> >  
> > Date: Tue, 11 Nov 2003 20:06:38 -0500 
> > From: <tmurph6 at po-box.mcgill.ca>
> > To: Frank E Harrell Jr <feh3k at spamcop.net> 
> > Cc: <r-help at stat.math.ethz.ch> 
> > Subject: Re: [R] HMisc describe -- error with dates 
> > 
> >  
> >  
> > I am using the chron package. I have no preference for which function I
> > use. I just want the most reliable format for HMisc functions and
> > general plotting. I like the ddmonyyy formats (e.g. 11NOV2003). What
> > would you recommend?
> 
> I like POSIX but chron should be workable.  The fix for isChron in Hmisc
> is:
> 
> function(x) {
>   cl <- class(x)
>   dc <- if(.R.) c('POSIXt','POSIXct','dates','times','chron') else
>                 c('timeDate','date','dates','times','chron')
>   length(cl) && any(cl %in% dc)
> }
> 
> But describe also runs this command:
> 
>   if(isdatetime) notime <- all(format(x.unique,"%H%M%S")=='000000')
> 
> and such calls to format for chron objects (which actually calls
> format.dates if x.unique is a dates object) do not work.  So a few more
> modifications will need to be made in describe to work with chron objects,
> when time allows.
> 
> Frank
> 
> > 
> > Thank you!
> > 
> > Quoting Frank E Harrell Jr <feh3k at spamcop.net>:
> > 
> > > On Tue, 11 Nov 2003 18:28:24 -0500
> > > tmurph6 at po-box.mcgill.ca wrote:
> > > 
> > > > Hello,
> > > > 
> > > > I am trying to use HMisc describe on a data frame. I have specified
> > > > certain variables as dates using, for example:
> > > > 
> > > > df1$aidsdate <- dates(aidsdate,format="day.mon.year",
> > > > origin=c(month = 1, day = 1, year = 1960))
> > > > 
> > > > When I use describe on the dataframe I get this error:
> > > > 
> > > > Error in Ops.dates(weights, x) : * not defined for chron objects
> > > > 
> > > > Has anyone had this problem? I had used the same method with an
> > > > older version of R and HMisc and it worked. 
> > > > 
> > > > Should be be formatting date variables differently?
> > > > 
> > > > Thank you!
> > > > 
> > > > Sincerely,
> > > > Tanya Murphy
> > > > 
> > > 
> > > In recent versions, describe for R recognizes date/times by one of the
> > > following classes: 'POSIXt','POSIXct','chron'. If you really need to
> > > use another date format I could be talked into extending the code for
> > > that if you can remind me where dates( ) is found. -Frank
> > > 
> > > ---
> > > Frank E Harrell Jr Professor and Chair School of Medicine
> > > Department of Biostatistics Vanderbilt University
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ---
> Frank E Harrell Jr    Professor and Chair            School of Medicine
>                       Department of Biostatistics    Vanderbilt University
> 




-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From p.dalgaard at biostat.ku.dk  Tue Nov 18 20:07:43 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Nov 2003 20:07:43 +0100
Subject: [R] model formula
In-Reply-To: <Pine.LNX.4.44.0311180837090.12229-100000@localhost.localdomain>
References: <Pine.LNX.4.44.0311180837090.12229-100000@localhost.localdomain>
Message-ID: <x23ccl5wcg.fsf@biostat.ku.dk>

Bill Simpson <William.Simpson at drdc-rddc.gc.ca> writes:

> I have continuous variables x, y, z. The plot of the data looks like this:
> 
> y
> |                           z=1(o), 2(@), 3(#), 4(*)
> |
> |*   *  *
> |
> |
> |#   #   #  #
> |
> |
> |@    @    @  @
> |
> |                     o
> |               o
> |          o
> |     o  
> |o
> ------------------------ x
> The correct model appears to be: if z==1, y~x+z; else y~z
> (y~z + z:x isn't it)

Not if z really is continuous...

 
> How can I express this model in lm()? If I can't express it properly in
> lm(), what is the best way to fit the model?


I'd try something like 

x2 <- ifelse(z==1, x, 0)
z2 <- factor(z)

y ~ x2+z2


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jfox at mcmaster.ca  Tue Nov 18 19:57:28 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 18 Nov 2003 13:57:28 -0500
Subject: [R] model formula
In-Reply-To: <Pine.LNX.4.44.0311180837090.12229-100000@localhost.localdo main>
Message-ID: <5.0.2.1.0.20031118135625.00b15268@127.0.0.1>

Dear Bill,

I believe that lm(y ~ z + I((z == 1)*x)) will give you what you want.

I hope that this helps,
  John

At 08:40 AM 11/18/2003 -0500, you wrote:
>I have continuous variables x, y, z. The plot of the data looks like this:
>
>y
>|                           z=1(o), 2(@), 3(#), 4(*)
>|
>|*   *  *
>|
>|
>|#   #   #  #
>|
>|
>|@    @    @  @
>|
>|                     o
>|               o
>|          o
>|     o
>|o
>------------------------ x
>The correct model appears to be: if z==1, y~x+z; else y~z
>(y~z + z:x isn't it)
>
>How can I express this model in lm()? If I can't express it properly in
>lm(), what is the best way to fit the model?

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From William.Simpson at drdc-rddc.gc.ca  Tue Nov 18 16:16:15 2003
From: William.Simpson at drdc-rddc.gc.ca (Bill Simpson)
Date: Tue, 18 Nov 2003 10:16:15 -0500 (EST)
Subject: [R] model formula
In-Reply-To: <5.0.2.1.0.20031118135625.00b15268@127.0.0.1>
Message-ID: <Pine.LNX.4.44.0311181015420.12326-100000@localhost.localdomain>

Thanks very much John & Peter for your help.

Bill



From kjetil at entelnet.bo  Tue Nov 18 21:16:31 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Tue, 18 Nov 2003 16:16:31 -0400
Subject: [R] Copula calculation in R?
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA8HhJkkxNukea7wv0NzTGUsKAAAAQAAAA65L8nh6oJEKmUtAQEgZESwEAAAAA@holm.cn>
References: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
Message-ID: <3FBA45DF.30272.388DB8@localhost>

On 18 Nov 2003 at 11:26, Thomas Holm wrote:

What is copulas?

Kjetil Halvorsen

> Hello
> 
> Anyone that now of any function in R that can calculate copulas?
> Or if anyone have any code avaible I would be more than interested. 
> 
> Thank you in advance
> 
> /Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mailinglist2_wegmann at web.de  Tue Nov 18 21:53:04 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Tue, 18 Nov 2003 21:53:04 +0100
Subject: [R] adding variable
In-Reply-To: <Pine.LNX.4.44.0311181830450.1014-100000@gannet.stats>
References: <Pine.LNX.4.44.0311181830450.1014-100000@gannet.stats>
Message-ID: <200311182153.05274.mailinglist2_wegmann@web.de>

On Tuesday 18 November 2003 19:32, Prof Brian Ripley wrote:
> On Tue, 18 Nov 2003, Martin Wegmann wrote:
> > I have count data of animals (here y, y1, y2...) and env. variables (x,
> > x1, x2 ,....).
> >
> > I used a glm
> >
> > glm(y~x1+x2+x3....)
> >
> > glm(y1~x1+x2+x3....)
> >
> > and now I would like to add the count data of other species to
> > investigate if they might have a bigger impact than the env. variables:
> >
> > #x? are the selected var from the first glm run
> >
> > glm(y~x?+x?+y1)
> >
> > glm(y~x?+x?+x?+y2)
> >
> > ....
> >
> > I wonder if there is a more elegant method to do this than adding (and
> > removing) each y by hand.
>
> Do you mean each x?  In either case, see ?update.

update looks good but with update and with adding the y I have to do it 
manually. 

I thought something like doing 

glm(y~x+x1+x2+....+y?) 

where y? is: grep y1 out of df.y run glm and name it
grep y2 out of df.y run glm .....

until all y's of df.y has been onced included in the model.
every time only one y? has to be included

the included x's have to be kept. I only want to look if one species variables 
has more explanation power than the env. variables.

perhaps this helps to understand what I am looking for:
I think bash scripts are not possible in R but it would look like such a bash 
script for GRASS:

for variable in y1 y2 y3  ....; do

glm(y~x+x1+x2....+$variable)->glm.$variable
; done

#where $variable refers to the name of read in y's.


Martin



From tlumley at u.washington.edu  Tue Nov 18 22:01:36 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 Nov 2003 13:01:36 -0800 (PST)
Subject: [R] Copula calculation in R?
In-Reply-To: <3FBA45DF.30272.388DB8@localhost>
References: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
	<3FBA45DF.30272.388DB8@localhost>
Message-ID: <Pine.A41.4.58.0311181300590.95398@homer05.u.washington.edu>

On Tue, 18 Nov 2003 kjetil at entelnet.bo wrote:

> On 18 Nov 2003 at 11:26, Thomas Holm wrote:
>
> What is copulas?

After you rescale a bivariate distribution to have specified marginal
distributions the copula is what's left.

	-thomas

>
> Kjetil Halvorsen
>
> > Hello
> >
> > Anyone that now of any function in R that can calculate copulas?
> > Or if anyone have any code avaible I would be more than interested.
> >
> > Thank you in advance
> >
> > /Thomas
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ripley at stats.ox.ac.uk  Tue Nov 18 22:14:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 21:14:51 +0000 (GMT)
Subject: [R] adding variable
In-Reply-To: <200311182153.05274.mailinglist2_wegmann@web.de>
Message-ID: <Pine.LNX.4.44.0311182113370.10016-100000@gannet.stats>

Are you looking for something like add1 then?

We do need a much clearer explanation of what you are trying to do to be 
able to help you: and not with y used in two separate senses!

On Tue, 18 Nov 2003, Martin Wegmann wrote:

> On Tuesday 18 November 2003 19:32, Prof Brian Ripley wrote:
> > On Tue, 18 Nov 2003, Martin Wegmann wrote:
> > > I have count data of animals (here y, y1, y2...) and env. variables (x,
> > > x1, x2 ,....).
> > >
> > > I used a glm
> > >
> > > glm(y~x1+x2+x3....)
> > >
> > > glm(y1~x1+x2+x3....)
> > >
> > > and now I would like to add the count data of other species to
> > > investigate if they might have a bigger impact than the env. variables:
> > >
> > > #x? are the selected var from the first glm run
> > >
> > > glm(y~x?+x?+y1)
> > >
> > > glm(y~x?+x?+x?+y2)
> > >
> > > ....
> > >
> > > I wonder if there is a more elegant method to do this than adding (and
> > > removing) each y by hand.
> >
> > Do you mean each x?  In either case, see ?update.
> 
> update looks good but with update and with adding the y I have to do it 
> manually. 
> 
> I thought something like doing 
> 
> glm(y~x+x1+x2+....+y?) 
> 
> where y? is: grep y1 out of df.y run glm and name it
> grep y2 out of df.y run glm .....
> 
> until all y's of df.y has been onced included in the model.
> every time only one y? has to be included
> 
> the included x's have to be kept. I only want to look if one species variables 
> has more explanation power than the env. variables.
> 
> perhaps this helps to understand what I am looking for:
> I think bash scripts are not possible in R but it would look like such a bash 
> script for GRASS:
> 
> for variable in y1 y2 y3  ....; do
> 
> glm(y~x+x1+x2....+$variable)->glm.$variable
> ; done
> 
> #where $variable refers to the name of read in y's.
> 
> 
> Martin
> 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From btp16 at student.canterbury.ac.nz  Tue Nov 18 22:33:57 2003
From: btp16 at student.canterbury.ac.nz (bridget)
Date: Wed, 19 Nov 2003 10:33:57 +1300
Subject: [R] arima models
Message-ID: <3FBA9045.9020803@student.canterbury.ac.nz>

Hi all,

I want to calculate the residuals of an ARIMA fit to a time series using 
the same calculation method as in arima() in the ts package, BUT I want 
to be able to specify fixed values for ALL the parameters in the ARIMA 
model.  The "fixed = ..." argument in the arima() command appears to 
require at least one parameter to be variable.  Does anyone know a way 
around this?  Altering the parameter values using, for example,

model<-arima(t, order = c(1,1,0), seasonal = list(order = c(0,1,1), 
period = 12));
model$coef[1]<-0.75;

doesn't affect the other model values.

Many thanks,
Bridget



From kjetil at entelnet.bo  Tue Nov 18 22:38:16 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Tue, 18 Nov 2003 17:38:16 -0400
Subject: [R] adding variable
In-Reply-To: <200311182153.05274.mailinglist2_wegmann@web.de>
References: <Pine.LNX.4.44.0311181830450.1014-100000@gannet.stats>
Message-ID: <3FBA5908.9843.8364E6@localhost>

On 18 Nov 2003 at 21:53, Martin Wegmann wrote:

You can go by text representation in a loop, using some of the 
following stuff:

> form <- "y ~ x   "
> as.formula(form)
y ~ x
> nchar(form)
[1] 8
> substr(form, 7,8)
[1] "  "
> substr(form, 7,8) <- "+z"
> form
[1] "y ~ x +z"
> as.formula(form)
y ~ x + z
> 

Then you can loop over (part of) names(your.df)

Kjetil Halvorsen

> On Tuesday 18 November 2003 19:32, Prof Brian Ripley wrote:
> > On Tue, 18 Nov 2003, Martin Wegmann wrote:
> > > I have count data of animals (here y, y1, y2...) and env.
> > > variables (x, x1, x2 ,....).
> > >
> > > I used a glm
> > >
> > > glm(y~x1+x2+x3....)
> > >
> > > glm(y1~x1+x2+x3....)
> > >
> > > and now I would like to add the count data of other species to
> > > investigate if they might have a bigger impact than the env.
> > > variables:
> > >
> > > #x? are the selected var from the first glm run
> > >
> > > glm(y~x?+x?+y1)
> > >
> > > glm(y~x?+x?+x?+y2)
> > >
> > > ....
> > >
> > > I wonder if there is a more elegant method to do this than adding
> > > (and removing) each y by hand.
> >
> > Do you mean each x?  In either case, see ?update.
> 
> update looks good but with update and with adding the y I have to do
> it manually. 
> 
> I thought something like doing 
> 
> glm(y~x+x1+x2+....+y?) 
> 
> where y? is: grep y1 out of df.y run glm and name it
> grep y2 out of df.y run glm .....
> 
> until all y's of df.y has been onced included in the model.
> every time only one y? has to be included
> 
> the included x's have to be kept. I only want to look if one species
> variables has more explanation power than the env. variables.
> 
> perhaps this helps to understand what I am looking for:
> I think bash scripts are not possible in R but it would look like such
> a bash script for GRASS:
> 
> for variable in y1 y2 y3  ....; do
> 
> glm(y~x+x1+x2....+$variable)->glm.$variable
> ; done
> 
> #where $variable refers to the name of read in y's.
> 
> 
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mailinglist2_wegmann at web.de  Tue Nov 18 22:51:28 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Tue, 18 Nov 2003 22:51:28 +0100
Subject: [R] adding variable
In-Reply-To: <Pine.LNX.4.44.0311182113370.10016-100000@gannet.stats>
References: <Pine.LNX.4.44.0311182113370.10016-100000@gannet.stats>
Message-ID: <200311182251.28160.mailinglist2_wegmann@web.de>

Ok I try to explain it clearer. 

I am not looking for step() add1() drop1() or similar commands. Nothing to do 
with variable selection.

I have two data frames, on with environmental variables and another one with 
animal data (let's say absence/presence of 10 species)

first I look which env. variables explain the presence of species 1

glm(species1~env.var1+env.var2+.....) -> glm.spec1

step(glm.spec1) -> glm.spec1.step

I get certain env. variables which have the biggest explanatory power.

Now I would like to treat the other absence/presence data of my species like 
env. variables which could influence the presence of species1
I included the env.variable from glm.spec1.step (I call them env.varX+...)

glm(species1~env.varX+......+species2) -> glm.species1.sp2


glm(species1~env.varX+......+species3) -> glm.species1.sp3


and this procedure shall be done for all remaining species.

I am looking for a method to add automatically each species2 up to species10 
and run glm(). 
The first part with the env. variables shall be kept as it is but the last 
variable (speciesX) shall be changed each time. I am looking for something 
like a placeholder and the command greps a different species from the species 
dataframe for each run and add it instead of the place holder.

I hope I explained it better. thanks Martin

On Tuesday 18 November 2003 22:14, Prof Brian Ripley wrote:
> Are you looking for something like add1 then?
>
> We do need a much clearer explanation of what you are trying to do to be
> able to help you: and not with y used in two separate senses!
>
> On Tue, 18 Nov 2003, Martin Wegmann wrote:
> > On Tuesday 18 November 2003 19:32, Prof Brian Ripley wrote:
> > > On Tue, 18 Nov 2003, Martin Wegmann wrote:
> > > > I have count data of animals (here y, y1, y2...) and env. variables
> > > > (x, x1, x2 ,....).
> > > >
> > > > I used a glm
> > > >
> > > > glm(y~x1+x2+x3....)
> > > >
> > > > glm(y1~x1+x2+x3....)
> > > >
> > > > and now I would like to add the count data of other species to
> > > > investigate if they might have a bigger impact than the env.
> > > > variables:
> > > >
> > > > #x? are the selected var from the first glm run
> > > >
> > > > glm(y~x?+x?+y1)
> > > >
> > > > glm(y~x?+x?+x?+y2)
> > > >
> > > > ....
> > > >
> > > > I wonder if there is a more elegant method to do this than adding
> > > > (and removing) each y by hand.
> > >
> > > Do you mean each x?  In either case, see ?update.
> >
> > update looks good but with update and with adding the y I have to do it
> > manually.
> >
> > I thought something like doing
> >
> > glm(y~x+x1+x2+....+y?)
> >
> > where y? is: grep y1 out of df.y run glm and name it
> > grep y2 out of df.y run glm .....
> >
> > until all y's of df.y has been onced included in the model.
> > every time only one y? has to be included
> >
> > the included x's have to be kept. I only want to look if one species
> > variables has more explanation power than the env. variables.
> >
> > perhaps this helps to understand what I am looking for:
> > I think bash scripts are not possible in R but it would look like such a
> > bash script for GRASS:
> >
> > for variable in y1 y2 y3  ....; do
> >
> > glm(y~x+x1+x2....+$variable)->glm.$variable
> > ; done
> >
> > #where $variable refers to the name of read in y's.
> >
> >
> > Martin



From ripley at stats.ox.ac.uk  Tue Nov 18 22:53:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2003 21:53:42 +0000 (GMT)
Subject: [R] adding variable
In-Reply-To: <200311182251.28160.mailinglist2_wegmann@web.de>
Message-ID: <Pine.LNX.4.44.0311182153280.13259-100000@gannet.stats>

On Tue, 18 Nov 2003, Martin Wegmann wrote:

> Ok I try to explain it clearer. 
> 
> I am not looking for step() add1() drop1() or similar commands. Nothing to do 
> with variable selection.
> 
> I have two data frames, on with environmental variables and another one with 
> animal data (let's say absence/presence of 10 species)
> 
> first I look which env. variables explain the presence of species 1
> 
> glm(species1~env.var1+env.var2+.....) -> glm.spec1
> 
> step(glm.spec1) -> glm.spec1.step
> 
> I get certain env. variables which have the biggest explanatory power.
> 
> Now I would like to treat the other absence/presence data of my species like 
> env. variables which could influence the presence of species1
> I included the env.variable from glm.spec1.step (I call them env.varX+...)
> 
> glm(species1~env.varX+......+species2) -> glm.species1.sp2
> 
> 
> glm(species1~env.varX+......+species3) -> glm.species1.sp3
> 
> 
> and this procedure shall be done for all remaining species.
> 
> I am looking for a method to add automatically each species2 up to species10 
> and run glm(). 

That is what add1 does.

> The first part with the env. variables shall be kept as it is but the last 
> variable (speciesX) shall be changed each time. I am looking for something 
> like a placeholder and the command greps a different species from the species 
> dataframe for each run and add it instead of the place holder.
> 
> I hope I explained it better. thanks Martin
> 
> On Tuesday 18 November 2003 22:14, Prof Brian Ripley wrote:
> > Are you looking for something like add1 then?
> >
> > We do need a much clearer explanation of what you are trying to do to be
> > able to help you: and not with y used in two separate senses!
> >
> > On Tue, 18 Nov 2003, Martin Wegmann wrote:
> > > On Tuesday 18 November 2003 19:32, Prof Brian Ripley wrote:
> > > > On Tue, 18 Nov 2003, Martin Wegmann wrote:
> > > > > I have count data of animals (here y, y1, y2...) and env. variables
> > > > > (x, x1, x2 ,....).
> > > > >
> > > > > I used a glm
> > > > >
> > > > > glm(y~x1+x2+x3....)
> > > > >
> > > > > glm(y1~x1+x2+x3....)
> > > > >
> > > > > and now I would like to add the count data of other species to
> > > > > investigate if they might have a bigger impact than the env.
> > > > > variables:
> > > > >
> > > > > #x? are the selected var from the first glm run
> > > > >
> > > > > glm(y~x?+x?+y1)
> > > > >
> > > > > glm(y~x?+x?+x?+y2)
> > > > >
> > > > > ....
> > > > >
> > > > > I wonder if there is a more elegant method to do this than adding
> > > > > (and removing) each y by hand.
> > > >
> > > > Do you mean each x?  In either case, see ?update.
> > >
> > > update looks good but with update and with adding the y I have to do it
> > > manually.
> > >
> > > I thought something like doing
> > >
> > > glm(y~x+x1+x2+....+y?)
> > >
> > > where y? is: grep y1 out of df.y run glm and name it
> > > grep y2 out of df.y run glm .....
> > >
> > > until all y's of df.y has been onced included in the model.
> > > every time only one y? has to be included
> > >
> > > the included x's have to be kept. I only want to look if one species
> > > variables has more explanation power than the env. variables.
> > >
> > > perhaps this helps to understand what I am looking for:
> > > I think bash scripts are not possible in R but it would look like such a
> > > bash script for GRASS:
> > >
> > > for variable in y1 y2 y3  ....; do
> > >
> > > glm(y~x+x1+x2....+$variable)->glm.$variable
> > > ; done
> > >
> > > #where $variable refers to the name of read in y's.
> > >
> > >
> > > Martin
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jean.vidal at freesurf.fr  Tue Nov 18 23:32:05 2003
From: jean.vidal at freesurf.fr (Jean Vidal)
Date: Tue, 18 Nov 2003 23:32:05 +0100
Subject: [R] Question regarding mosaicplot
Message-ID: <6.0.0.22.1.20031118232152.01cec730@pop.freesurf.fr>

I tried this :
 > mosaicplot(stoc ~ q9r + segca,data=tmp2,color=T) : works fine.

And now, this :
 > mosaicplot(stoc ~ q9r + segca, data=tmp2, color=T, main="Big title")
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
         invalid variable type

I'm probably stupid and missed something simple in the manual (and wouldn't 
like to be flamed if insinuating that, may be... a bug ? Oh no !).

It can be done with :
 > mosaicplot(table(tmp2$stoc,tmp2$q9r,tmp2$segca),color=T,main="Big 
title") : works fine.

So, no real trouble for me...

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    8.0
year     2003
month    10
day      08
language R



From feh3k at spamcop.net  Wed Nov 19 00:42:39 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 18 Nov 2003 18:42:39 -0500
Subject: [R] HMisc describe -- error with dates
In-Reply-To: <1069181237.3fba69355b44f@webmail.mcgill.ca>
References: <20031112014050.6D7A8394F@mprdmxin.myway.com>
	<20031111212521.1d6dda5e.feh3k@spamcop.net>
	<1069181237.3fba69355b44f@webmail.mcgill.ca>
Message-ID: <20031118184239.55b06e9f.feh3k@spamcop.net>

On Tue, 18 Nov 2003 13:47:17 -0500
tmurph6 at po-box.mcgill.ca wrote:

> Thank you Gabor and Frank for you replies last week. Unfortunately I
> still don't get it (I'm kind of new at this). Just to recap: I'm
> starting with a Julian date and want results presented as 11NOV2003, for
> example (or some other date format with no time component). 
> 
> The HMisc describe function accepts variables that I have now formatted
> like this   
> 
> >date.ddmmmyy(aidsdate)
> 
> whereas it does not like variables formatted like this
> 
> >dates(aidsdate,format="day.mon.year", origin=c(month = 1, day = 1, year
> >=
> 1960))
> 
> which is what I was using with an earlier version of Hmisc.
> 
> I wasn't able to figure out how to use posix.
> 
> The problem now is that, unlike before, the dates are not sorted (at
> least not chronologically--maybe like character variables) and I liked
> seeing the 5 lowest and highest dates in the describe output. 
> 
> Sorry for pestering, but it is a testimony to how much I like Hmisc :)
> 
> Thanks!
> 
> Tanya
> 
> 
> 

Tanya,

I want to fix this in general.  It's on my todo list for next week. 
-Frank


> Quoting Frank E Harrell Jr <feh3k at spamcop.net>:
> 
> > On Tue, 11 Nov 2003 20:40:50 -0500 (EST)
> > "Gabor Grothendieck" <ggrothendieck at myway.com> wrote:
> > 
> > > 
> > > 
> > > dates is part of chron.  There may be something wrong in 
> > > Hmisc's detection of chron objects.
> > > 
> > > > chron(1)
> > > [1] 01/02/70
> > > 
> > > > isChron(chron(1))
> > > FALSE
> > > 
> > > ---
> > >  
> > > Date: Tue, 11 Nov 2003 20:06:38 -0500 
> > > From: <tmurph6 at po-box.mcgill.ca>
> > > To: Frank E Harrell Jr <feh3k at spamcop.net> 
> > > Cc: <r-help at stat.math.ethz.ch> 
> > > Subject: Re: [R] HMisc describe -- error with dates 
> > > 
> > >  
> > >  
> > > I am using the chron package. I have no preference for which
> > > function I use. I just want the most reliable format for HMisc
> > > functions and general plotting. I like the ddmonyyy formats (e.g.
> > > 11NOV2003). What would you recommend?
> > 
> > I like POSIX but chron should be workable.  The fix for isChron in
> > Hmisc is:
> > 
> > function(x) {
> >   cl <- class(x)
> >   dc <- if(.R.) c('POSIXt','POSIXct','dates','times','chron') else
> >                 c('timeDate','date','dates','times','chron')
> >   length(cl) && any(cl %in% dc)
> > }
> > 
> > But describe also runs this command:
> > 
> >   if(isdatetime) notime <- all(format(x.unique,"%H%M%S")=='000000')
> > 
> > and such calls to format for chron objects (which actually calls
> > format.dates if x.unique is a dates object) do not work.  So a few
> > more modifications will need to be made in describe to work with chron
> > objects, when time allows.
> > 
> > Frank
> > 
> > > 
> > > Thank you!
> > > 
> > > Quoting Frank E Harrell Jr <feh3k at spamcop.net>:
> > > 
> > > > On Tue, 11 Nov 2003 18:28:24 -0500
> > > > tmurph6 at po-box.mcgill.ca wrote:
> > > > 
> > > > > Hello,
> > > > > 
> > > > > I am trying to use HMisc describe on a data frame. I have
> > > > > specified certain variables as dates using, for example:
> > > > > 
> > > > > df1$aidsdate <- dates(aidsdate,format="day.mon.year",
> > > > > origin=c(month = 1, day = 1, year = 1960))
> > > > > 
> > > > > When I use describe on the dataframe I get this error:
> > > > > 
> > > > > Error in Ops.dates(weights, x) : * not defined for chron objects
> > > > > 
> > > > > Has anyone had this problem? I had used the same method with an
> > > > > older version of R and HMisc and it worked. 
> > > > > 
> > > > > Should be be formatting date variables differently?
> > > > > 
> > > > > Thank you!
> > > > > 
> > > > > Sincerely,
> > > > > Tanya Murphy
> > > > > 
> > > > 
> > > > In recent versions, describe for R recognizes date/times by one of
> > > > the following classes: 'POSIXt','POSIXct','chron'. If you really
> > > > need to use another date format I could be talked into extending
> > > > the code for that if you can remind me where dates( ) is found.
> > > > -Frank
> > > > 
> > > > ---
> > > > Frank E Harrell Jr Professor and Chair School of Medicine
> > > > Department of Biostatistics Vanderbilt University
> > > >
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > 
> > ---
> > Frank E Harrell Jr    Professor and Chair            School of
> > Medicine
> >                       Department of Biostatistics    Vanderbilt
> >                       University
> > 
> 
> 
> 
> 
> -------------------------------------------------
> This mail sent through IMP: http://horde.org/imp/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From rxg218 at psu.edu  Wed Nov 19 02:30:30 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 18 Nov 2003 20:30:30 -0500
Subject: [R] converting a numeric vector to a single string
Message-ID: <1069205429.2564.9.camel@localhost.localdomain>

Hi,
  this is probably a very obvious question but I cant see how I can
convert a numeric vector to a single string as opposed to  a character
vector.

Essentially if I have a vector defined as

x <- c(1,2,3.76,4.56)

I would like to generate the string:

"1 2 3.76 4.56"

rather than

"1" "2" "3.76" "4.56"

which is what paste() gives me.

I thought of using a textConnection() but as far as I can see I need to
use something like writeLines which requires a character vector.

Thanks,


-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
All great discoveries are made by mistake.
-- Young



From ggrothendieck at myway.com  Wed Nov 19 02:35:44 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 18 Nov 2003 20:35:44 -0500 (EST)
Subject: [R] HMisc describe -- error with dates
Message-ID: <20031119013544.3CB553958@mprdmxin.myway.com>



Since Frank Harrell indicates that he will likely have addressed
the chron issue in Hmisc by next week you may just want to
wait for that; however, if you need an interim solution for
representing chron dates in such a manner that they sort and
display correctly under the Hmisc describe function then here
are two workarounds.

Assume z is your vector of chron dates.


1. Character variables

Represent them as character variables using a format, such as
yyyy/mm/dd , that sorts correctly under character comparisons:

  chr <- substring( paste(years(z),chron(z),sep="/"), 1, 10 )
  describe(chr)

This will convert chr back to chron:

 chron( paste(substring(chr,6),substring(chr,3,4),sep="/") )


2. Factors

Represent them as factors like this:

  zs <- chron(sort(unique(z)))
  f <- factor(z,lev=zs,lab=zs)
  describe(f)

This will convert f back to chron:

  chron(as.character(f))


---

From: Frank E Harrell Jr <feh3k at spamcop.net>
To: <tmurph6 at po-box.mcgill.ca> 
Cc: <r-help at stat.math.ethz.ch> 
Subject: Re: [R] HMisc describe -- error with dates 

 
 
On Tue, 18 Nov 2003 13:47:17 -0500
tmurph6 at po-box.mcgill.ca wrote:

> Thank you Gabor and Frank for you replies last week. Unfortunately I
> still don't get it (I'm kind of new at this). Just to recap: I'm
> starting with a Julian date and want results presented as 11NOV2003, for
> example (or some other date format with no time component). 
> 
> The HMisc describe function accepts variables that I have now formatted
> like this 
> 
> >date.ddmmmyy(aidsdate)
> 
> whereas it does not like variables formatted like this
> 
> >dates(aidsdate,format="day.mon.year", origin=c(month = 1, day = 1, year
> >=
> 1960))
> 
> which is what I was using with an earlier version of Hmisc.
> 
> I wasn't able to figure out how to use posix.
> 
> The problem now is that, unlike before, the dates are not sorted (at
> least not chronologically--maybe like character variables) and I liked
> seeing the 5 lowest and highest dates in the describe output. 
> 
> Sorry for pestering, but it is a testimony to how much I like Hmisc :)
> 
> Thanks!
> 
> Tanya
> 
> 
> 

Tanya,

I want to fix this in general. It's on my todo list for next week. 
-Frank


> Quoting Frank E Harrell Jr <feh3k at spamcop.net>:
> 
> > On Tue, 11 Nov 2003 20:40:50 -0500 (EST)
> > "Gabor Grothendieck" <ggrothendieck at myway.com> wrote:
> > 
> > > 
> > > 
> > > dates is part of chron. There may be something wrong in 
> > > Hmisc's detection of chron objects.
> > > 
> > > > chron(1)
> > > [1] 01/02/70
> > > 
> > > > isChron(chron(1))
> > > FALSE
> > > 
> > > ---
> > > 
> > > Date: Tue, 11 Nov 2003 20:06:38 -0500 
> > > From: <tmurph6 at po-box.mcgill.ca>
> > > To: Frank E Harrell Jr <feh3k at spamcop.net> 
> > > Cc: <r-help at stat.math.ethz.ch> 
> > > Subject: Re: [R] HMisc describe -- error with dates 
> > > 
> > > 
> > > 
> > > I am using the chron package. I have no preference for which
> > > function I use. I just want the most reliable format for HMisc
> > > functions and general plotting. I like the ddmonyyy formats (e.g.
> > > 11NOV2003). What would you recommend?
> > 
> > I like POSIX but chron should be workable. The fix for isChron in
> > Hmisc is:
> > 
> > function(x) {
> > cl <- class(x)
> > dc <- if(.R.) c('POSIXt','POSIXct','dates','times','chron') else
> > c('timeDate','date','dates','times','chron')
> > length(cl) && any(cl %in% dc)
> > }
> > 
> > But describe also runs this command:
> > 
> > if(isdatetime) notime <- all(format(x.unique,"%H%M%S")=='000000')
> > 
> > and such calls to format for chron objects (which actually calls
> > format.dates if x.unique is a dates object) do not work. So a few
> > more modifications will need to be made in describe to work with chron
> > objects, when time allows.
> > 
> > Frank
> > 
> > > 
> > > Thank you!
> > > 
> > > Quoting Frank E Harrell Jr <feh3k at spamcop.net>:
> > > 
> > > > On Tue, 11 Nov 2003 18:28:24 -0500
> > > > tmurph6 at po-box.mcgill.ca wrote:
> > > > 
> > > > > Hello,
> > > > > 
> > > > > I am trying to use HMisc describe on a data frame. I have
> > > > > specified certain variables as dates using, for example:
> > > > > 
> > > > > df1$aidsdate <- dates(aidsdate,format="day.mon.year",
> > > > > origin=c(month = 1, day = 1, year = 1960))
> > > > > 
> > > > > When I use describe on the dataframe I get this error:
> > > > > 
> > > > > Error in Ops.dates(weights, x) : * not defined for chron objects
> > > > > 
> > > > > Has anyone had this problem? I had used the same method with an
> > > > > older version of R and HMisc and it worked. 
> > > > > 
> > > > > Should be be formatting date variables differently?
> > > > > 
> > > > > Thank you!
> > > > > 
> > > > > Sincerely,
> > > > > Tanya Murphy
> > > > > 
> > > > 
> > > > In recent versions, describe for R recognizes date/times by one of
> > > > the following classes: 'POSIXt','POSIXct','chron'. If you really
> > > > need to use another date format I could be talked into extending
> > > > the code for that if you can remind me where dates( ) is found.
> > > > -Frank
> > > > 
> > > > ---
> > > > Frank E Harrell Jr Professor and Chair School of Medicine
> > > > Department of Biostatistics Vanderbilt University
> > > >
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > 
> > ---
> > Frank E Harrell Jr Professor and Chair School of
> > Medicine
> > Department of Biostatistics Vanderbilt
> > University



From h.wickham at auckland.ac.nz  Wed Nov 19 02:48:32 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Wed, 19 Nov 2003 14:48:32 +1300
Subject: [R] converting a numeric vector to a single string
In-Reply-To: <1069205429.2564.9.camel@localhost.localdomain>
References: <1069205429.2564.9.camel@localhost.localdomain>
Message-ID: <3FBACBF0.4090603@auckland.ac.nz>

Did you read ?paste ?  I think using the collapse argument will give you 
what you want.

Hadley

Rajarshi Guha wrote:

>Hi,
>  this is probably a very obvious question but I cant see how I can
>convert a numeric vector to a single string as opposed to  a character
>vector.
>
>Essentially if I have a vector defined as
>
>x <- c(1,2,3.76,4.56)
>
>I would like to generate the string:
>
>"1 2 3.76 4.56"
>
>rather than
>
>"1" "2" "3.76" "4.56"
>
>which is what paste() gives me.
>
>I thought of using a textConnection() but as far as I can see I need to
>use something like writeLines which requires a character vector.
>
>Thanks,
>
>  
>



From ripley at stats.ox.ac.uk  Wed Nov 19 05:02:34 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 04:02:34 +0000 (GMT)
Subject: [R] Question regarding mosaicplot
In-Reply-To: <6.0.0.22.1.20031118232152.01cec730@pop.freesurf.fr>
Message-ID: <Pine.LNX.4.44.0311190402000.15093-100000@gannet.stats>

It is a bug (which has been seen before).  Just use title to add the main 
title afterwards.

On Tue, 18 Nov 2003, Jean Vidal wrote:

> I tried this :
>  > mosaicplot(stoc ~ q9r + segca,data=tmp2,color=T) : works fine.
> 
> And now, this :
>  > mosaicplot(stoc ~ q9r + segca, data=tmp2, color=T, main="Big title")
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>          invalid variable type
> 
> I'm probably stupid and missed something simple in the manual (and wouldn't 
> like to be flamed if insinuating that, may be... a bug ? Oh no !).
> 
> It can be done with :
>  > mosaicplot(table(tmp2$stoc,tmp2$q9r,tmp2$segca),color=T,main="Big 
> title") : works fine.
> 
> So, no real trouble for me...
> 
>  > version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    8.0
> year     2003
> month    10
> day      08
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Wed Nov 19 09:14:24 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 19 Nov 2003 09:14:24 +0100
Subject: [R] [R-pkgs] 'nor1mix' for 1-dimensional normal mixture
	distributions
Message-ID: <16315.9824.576634.789737@gargle.gargle.HOWL>

I have been authoring a very small R package on CRAN, named 
"normix" which implements an S3 class "norMix" has plot and
print methods;  further, E[X] and Var[X] methods, random number
generation ("r") and density evaluation.
It also provides the 16 "Marron-Wand densities" (known in the (1d)
density estimation business).
Erik J?rgensen has provided "p" and "q" functions -- such that
there's now the full range of "dpqr" functionality.

I have recently *renamed* the package to 'nor1mix' (now on CRAN
where 'normix' has gone). 

Note that *estimation* (i.e. fitting normal mixtures to data) is 
not part of this package, but rather in (the more general framework of)
the package 'mclust'.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From Simon.Fear at synequanon.com  Wed Nov 19 09:57:39 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 19 Nov 2003 08:57:39 -0000
Subject: [R] Copula calculation in R?
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F02106@synequanon01>

For a more detailed answer try the American Statistician:

Title: The joy of copulas: Bivariate distributions with uniform marginals
(Com: 87V41 p248) 
Author(s): Genest, Christian;MacKay, Jock;
Keywords: [Teacher's Corner];Frechet bound;Kendall $\tau$;Singular
distribution function;Kendall tau
Year: 86 Volume: 40 Page(s): 280- 283 J

Any paper with a title like that just has to be worth reading.


> -----Original Message-----
> From: Thomas Lumley [mailto:tlumley at u.washington.edu]
> Sent: 18 November 2003 21:02
> To: kjetil at entelnet.bo
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Copula calculation in R?
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> On Tue, 18 Nov 2003 kjetil at entelnet.bo wrote:
> 
> > On 18 Nov 2003 at 11:26, Thomas Holm wrote:
> >
> > What is copulas?
> 
> After you rescale a bivariate distribution to have specified marginal
> distributions the copula is what's left.
> 
> 	-thomas
> 
> >
> > Kjetil Halvorsen
> >
> > > Hello
> > >
> > > Anyone that now of any function in R that can calculate copulas?
> > > Or if anyone have any code avaible I would be more than 
> interested.
> > >
> > > Thank you in advance
> > >
> > > /Thomas
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From knoblauch at lyon.inserm.fr  Wed Nov 19 10:16:23 2003
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Wed, 19 Nov 2003 10:16:23 +0100
Subject: [R] Copula calculation in R?
Message-ID: <1069233383.3fbb34e72e390@webmail.lyon.inserm.fr>


In Jim Lindsey's repeated package, 

`gausscop'        Multivariate Gaussian Copula with Arbitrary
     Marginals

kk

Quoting Simon Fear <Simon.Fear at synequanon.com>:

> For a more detailed answer try the American Statistician:
> 
> Title: The joy of copulas: Bivariate distributions with uniform marginals
> (Com: 87V41 p248) 
> Author(s): Genest, Christian;MacKay, Jock;
> Keywords: [Teacher's Corner];Frechet bound;Kendall $\tau$;Singular
> distribution function;Kendall tau
> Year: 86 Volume: 40 Page(s): 280- 283 J
> 
> Any paper with a title like that just has to be worth reading.
> 
> 
> > -----Original Message-----
> > From: Thomas Lumley [mailto:tlumley at u.washington.edu]
> > Sent: 18 November 2003 21:02
> > To: kjetil at entelnet.bo
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Copula calculation in R?
> > 
> > 
> > Security Warning: 
> > If you are not sure an attachment is safe to open please contact  
> > Andy on x234. There are 0 attachments with this message. 
> > ________________________________________________________________ 
> >  
> > On Tue, 18 Nov 2003 kjetil at entelnet.bo wrote:
> > 
> > > On 18 Nov 2003 at 11:26, Thomas Holm wrote:
> > >
> > > What is copulas?
> > 
> > After you rescale a bivariate distribution to have specified marginal
> > distributions the copula is what's left.
> > 
> > 	-thomas
> > 
> > >
> > > Kjetil Halvorsen
> > >
> > > > Hello
> > > >
> > > > Anyone that now of any function in R that can calculate copulas?
> > > > Or if anyone have any code avaible I would be more than 
> > interested.
> > > >
> > > > Thank you in advance
> > > >
> > > > /Thomas
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > 
> > Thomas Lumley			Assoc. Professor, Biostatistics
> > tlumley at u.washington.edu	University of Washington, Seattle
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >  
>  
> Simon Fear 
> Senior Statistician 
> Syne qua non Ltd 
> Tel: +44 (0) 1379 644449 
> Fax: +44 (0) 1379 644445 
> email: Simon.Fear at synequanon.com 
> web: http://www.synequanon.com 
>   
> Number of attachments included with this message: 0 
>   
> This message (and any associated files) is confidential and\...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


-- 
Ken Knoblauch
Inserm U371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
Tel: +33 (0)4 72 91 34 77
Fax: +33 (0)4 72 91 34 61
Portable: 06 84 10 64 10
email: knoblauch at lyon.inserm.fr



From kfung95 at yahoo.com  Wed Nov 19 10:20:35 2003
From: kfung95 at yahoo.com (Kaiser Fung)
Date: Wed, 19 Nov 2003 01:20:35 -0800 (PST)
Subject: [R] solution: rpart graphics, Mac
Message-ID: <20031119092035.70898.qmail@web21106.mail.yahoo.com>


Concerning tree graphics being trimmed, I received two
suggestions, both of which worked.

(a) plot(..., margin=0.1)

(b) set par(xpd=NA), then plot

Thanks!



From igual at mat.uji.es  Wed Nov 19 10:32:39 2003
From: igual at mat.uji.es (Fuensanta Saura Igual)
Date: Wed, 19 Nov 2003 10:32:39 +0100
Subject: [R] question
Message-ID: <1069234359.3fbb38b77ea8a@webmail.uji.es>



Does anyone know how I can read from a .txt file the lines that are between
two strings whose location is unknown?

My problem is that I have a .txt file with data separated by a sentence,
for example:

2.22 3.45
1.56 2.31
pattern 1
4.67 7.91
3.34 2.15
5.32 3.88
pattern 2
...

I do not know the number of lines where these separating sentences are located,
because the number of lines in between them can be random. If it was fixed, I 
think I could use "read.table" using the option "skip", but in this case, I do 
not know how I could manage to do that automatically.

Thanks.



From esg at felix.unife.it  Wed Nov 19 10:41:34 2003
From: esg at felix.unife.it (Josef Eschgfaeller)
Date: Wed, 19 Nov 2003 10:41:34 +0100 (CET)
Subject: [R] gmp
Message-ID: <Pine.LNX.4.44.0311191040270.8618-100000@dns.unife.it>


I'm trying to write some GMP functions but am not sure about
how and where to use pointers.
----------------------------------------------------------------------
// alfa.c
# include <R.h>
# include <gmp.h>

void Createinteger (char *A, mpz_t *N)
{mpz_init(*N); mpz_set_str(*N,A,10);}

void Stringofinteger (mpz_t *X, char ** A)
{*A=mpz_get_str(0,10,*X);}

void Square (mpz_t *X, mpz_t *Y)
{mpz_mul(*X,*X,*Y);}
----------------------------------------------------------------------
R-source:

Square = function (x) {u=0; .C('Createinteger',x,u);
  .C('Square',u,u); # (*)
  .C('Stringofinteger',u,a); a}

u=Square('105')
----------------------------------------------------------------------
As output I obtain always 1 2 3, also if omitting (*).
Someone who knows better? Is there already some package for GMP or
similar multiprecision libraries?

Josef Eschgf?ller



From ripley at stats.ox.ac.uk  Wed Nov 19 10:44:27 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 09:44:27 +0000 (GMT)
Subject: [R] question
In-Reply-To: <1069234359.3fbb38b77ea8a@webmail.uji.es>
Message-ID: <Pine.LNX.4.44.0311190942470.13173-100000@gannet.stats>

Read the lines with readLines into a character vector
Remove the lines you don't want
Use read.table on a textConnection to the character vector

If the file were very large, use an anonymous file() connection instead
(but better use OS tools such as grep to clean up the file).

On Wed, 19 Nov 2003, Fuensanta Saura Igual wrote:

> Does anyone know how I can read from a .txt file the lines that are between
> two strings whose location is unknown?
> 
> My problem is that I have a .txt file with data separated by a sentence,
> for example:
> 
> 2.22 3.45
> 1.56 2.31
> pattern 1
> 4.67 7.91
> 3.34 2.15
> 5.32 3.88
> pattern 2
> ...
> 
> I do not know the number of lines where these separating sentences are located,
> because the number of lines in between them can be random. If it was fixed, I 
> think I could use "read.table" using the option "skip", but in this case, I do 
> not know how I could manage to do that automatically.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From alessandro.semeria at cramont.it  Wed Nov 19 10:49:00 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Wed, 19 Nov 2003 10:49:00 +0100
Subject: [R] question
Message-ID: <OF95B6FC0F.DA2128FC-ONC1256DE3.003579AD@tomware.it>


With "scan" and "match" (pattern1,pattern2,..) you should be able to
build a function to perform what do you want.
A.S.

----------------------------

Alessandro Semeria
Models and Simulations Laboratory
Montecatini Environmental Research Center (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: alessandro.semeria at cramont.it



From glaziou at pasteur-kh.org  Wed Nov 19 11:18:59 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 19 Nov 2003 17:18:59 +0700
Subject: [R] question
In-Reply-To: <1069234359.3fbb38b77ea8a@webmail.uji.es>
References: <1069234359.3fbb38b77ea8a@webmail.uji.es>
Message-ID: <20031119101859.GF16984@pasteur-kh.org>

Fuensanta Saura Igual <igual at maFuensanta Saura Igual <igual at mat.uji.es> wrote:
> Does anyone know how I can read from a .txt file the lines that
> are between two strings whose location is unknown?
> 
> My problem is that I have a .txt file with data separated by a
> sentence, for example:
> 
> 2.22 3.45
> 1.56 2.31
> pattern 1
> 4.67 7.91
> 3.34 2.15
> 5.32 3.88
> pattern 2
> ...
> 
> I do not know the number of lines where these separating
> sentences are located, because the number of lines in between
> them can be random. If it was fixed, I think I could use
> "read.table" using the option "skip", but in this case, I do
> not know how I could manage to do that automatically.


This is a job for sed. The following command will delete any line
not starting with a digit from "file.txt" and save the results in
"file2.txt":

cat file.txt | sed -e '/^$\|^[^0-9]/D' > file2.txt

--
Philippe
Institut Pasteur du Cambodge



From JonesW at kssg.com  Wed Nov 19 11:36:34 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Wed, 19 Nov 2003 10:36:34 -0000
Subject: [R] Correction for first order autocorrelation in OLS residuals
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0EC8@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031119/aaeb8116/attachment.pl

From Thomas.Bock at ptb.de  Wed Nov 19 11:52:35 2003
From: Thomas.Bock at ptb.de (Thomas Bock)
Date: Wed, 19 Nov 2003 11:52:35 +0100
Subject: [R] filter() function
Message-ID: <3FBB4B73.7000604@ptb.de>

Dear expeRts,

I have lots of time series vectors and I simply want to remove certain 
frequencies.
My problem is now that I can not find out how to calculate
automatic the filter coeff. for the filter() function which should 
remove this certain frequencies.
Is there an elegant way to do this?

Thanks
Thomas



From ripley at stats.ox.ac.uk  Wed Nov 19 12:06:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 11:06:48 +0000 (GMT)
Subject: [R] Correction for first order autocorrelation in OLS residuals
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB021F0EC8@gimli.middleearth.kssg.com>
Message-ID: <Pine.LNX.4.44.0311191103120.13366-100000@gannet.stats>

Better, arima in ts and gls in nlme can fit such models by exact maximum 
likelihood.

On Wed, 19 Nov 2003, Wayne Jones wrote:

> Hi there fellow R-users, 
> 
> Can anyone tell me if there exits an R package that deals with serial
> correlation in the residuals of an lm model.
> Perhaps, using the Cochrane Orcutt or Praise Wilson methods?
> 
> Thanks, 
> 
> Wayne
> 
> 
> Dr Wayne R. Jones
> Senior Statistician / Research Analyst
> KSS Limited
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
> 
> 
> 
> 
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and m...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From alain.guerreau at libertysurf.fr  Wed Nov 19 12:16:31 2003
From: alain.guerreau at libertysurf.fr (guerreau)
Date: Wed, 19 Nov 2003 12:16:31 +0100
Subject: [R] size of graphics device
Message-ID: <001a01c3ae8e$b41c79e0$ac0b24d5@jetzt0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031119/50bed0ea/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Nov 19 12:29:19 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Nov 2003 12:29:19 +0100
Subject: [R] question
In-Reply-To: <20031119101859.GF16984@pasteur-kh.org>
References: <1069234359.3fbb38b77ea8a@webmail.uji.es>
	<20031119101859.GF16984@pasteur-kh.org>
Message-ID: <x2y8ucbnqo.fsf@biostat.ku.dk>

Philippe Glaziou <glaziou at pasteur-kh.org> writes:

> Fuensanta Saura Igual <igual at maFuensanta Saura Igual <igual at mat.uji.es> wrote:
> > Does anyone know how I can read from a .txt file the lines that
> > are between two strings whose location is unknown?
> > 
> > My problem is that I have a .txt file with data separated by a
> > sentence, for example:
> > 
> > 2.22 3.45
> > 1.56 2.31
> > pattern 1
> > 4.67 7.91
> > 3.34 2.15
> > 5.32 3.88
> > pattern 2
> > ...
> > 
> > I do not know the number of lines where these separating
> > sentences are located, because the number of lines in between
> > them can be random. If it was fixed, I think I could use
> > "read.table" using the option "skip", but in this case, I do
> > not know how I could manage to do that automatically.
> 
> 
> This is a job for sed. The following command will delete any line
> not starting with a digit from "file.txt" and save the results in
> "file2.txt":
> 
> cat file.txt | sed -e '/^$\|^[^0-9]/D' > file2.txt

Er, no, that wasn't the requirement. It's a job for awk or perl, e.g.

#!/usr/bin/perl -n
if (/pattern 1/){
    $copy = 1;
    next;
}
if (/pattern 2/){
    $copy = 0;
}
print if $copy;

or 

awk '/pattern 1/{copy=1;next};/pattern 2/{copy=0};copy==1' < file.txt > file2.txt


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vito.muggeo at giustizia.it  Wed Nov 19 12:29:57 2003
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Wed, 19 Nov 2003 12:29:57 +0100
Subject: R: [R] Correction for first order autocorrelation in OLS residuals
References: <6B5A9304046AD411BD0200508BDFB6CB021F0EC8@gimli.middleearth.kssg.com>
Message-ID: <004101c3ae90$7a54b040$5c13070a@PROCGEN>

The Cochrane Orcutt is probably an outdated approach to deal with
autocorrelation
and it is rather easy to write code.

Why don't you use a direct likelihood-based approach?

For gaussian data see the arima() function in ts package, or the Jim
Lindsey's packages (for instance the gar() function in the repeated package
at
http://alpha.luc.ac.be/~lucp0753/rcode.html

Also for GLM you can have a look at the Thomas Lumley's weave package that
implements different standard error estimators
http://faculty.washington.edu/tlumley/weave.html

hope this helps you,
best,
vito

----- Original Message -----
From: Wayne Jones <JonesW at kssg.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, November 19, 2003 11:36 AM
Subject: [R] Correction for first order autocorrelation in OLS residuals


> Hi there fellow R-users,
>
> Can anyone tell me if there exits an R package that deals with serial
> correlation in the residuals of an lm model.
> Perhaps, using the Cochrane Orcutt or Praise Wilson methods?
>
> Thanks,
>
> Wayne
>
>
> Dr Wayne R. Jones
> Senior Statistician / Research Analyst
> KSS Limited
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
>
>
>
>
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS
England
> Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040 Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com http://www.kssg.com
>
>
> The information in this Internet email is confidential and m...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From alising at dymaxium.com  Wed Nov 19 13:04:03 2003
From: alising at dymaxium.com (Allen Lising)
Date: Wed, 19 Nov 2003 07:04:03 -0500
Subject: [R] technical questions> connecting to a front end
Message-ID: <000001c3ae95$39ed50c0$7a01a8c0@dymaxium.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031119/13fbfa5f/attachment.pl

From glaziou at pasteur-kh.org  Wed Nov 19 13:20:56 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 19 Nov 2003 19:20:56 +0700
Subject: [R] question
In-Reply-To: <x2y8ucbnqo.fsf@biostat.ku.dk>
References: <1069234359.3fbb38b77ea8a@webmail.uji.es>
	<20031119101859.GF16984@pasteur-kh.org>
	<x2y8ucbnqo.fsf@biostat.ku.dk>
Message-ID: <20031119122055.GA16232@pasteur-kh.org>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> > > My problem is that I have a .txt file with data separated by a
> > > sentence, for example:
> > > 
> > > 2.22 3.45
> > > 1.56 2.31
> > > pattern 1
> > > 4.67 7.91
> > > 3.34 2.15
> > > 5.32 3.88
> > > pattern 2
> > > ...
> > > 
> > > I do not know the number of lines where these separating
> > > sentences are located, because the number of lines in between
> > > them can be random. If it was fixed, I think I could use
> > > "read.table" using the option "skip", but in this case, I do
> > > not know how I could manage to do that automatically.
> > 
> > 
> > This is a job for sed. The following command will delete any line
> > not starting with a digit from "file.txt" and save the results in
> > "file2.txt":
> > 
> > cat file.txt | sed -e '/^$\|^[^0-9]/D' > file2.txt
> 
> Er, no, that wasn't the requirement. It's a job for awk or perl, e.g.
> 
> #!/usr/bin/perl -n
> if (/pattern 1/){
>     $copy = 1;
>     next;
> }
> if (/pattern 2/){
>     $copy = 0;
> }
> print if $copy;
> 
> or 
> 
> awk '/pattern 1/{copy=1;next};/pattern 2/{copy=0};copy==1' < file.txt > file2.txt


Peter, I cannot see your point. sed can get rid of any pattern in
a text file. Fuensanta's example seemed to show that the
sentences (pattern 1, 2,...) were on separate lines from lines
containing data, thus my approach. Another one closer to your awk
example would use:

sed -e '/pattern 1\|pattern 2\|pattern xyz//g' <file.txt>file2.txt

Or is this just a perl versus sed versus awk troll?

-- 
Philippe



From glaziou at pasteur-kh.org  Wed Nov 19 13:30:52 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 19 Nov 2003 19:30:52 +0700
Subject: [R] question
In-Reply-To: <20031119122055.GA16232@pasteur-kh.org>
References: <1069234359.3fbb38b77ea8a@webmail.uji.es>
	<20031119101859.GF16984@pasteur-kh.org>
	<x2y8ucbnqo.fsf@biostat.ku.dk>
	<20031119122055.GA16232@pasteur-kh.org>
Message-ID: <20031119123052.GC16232@pasteur-kh.org>

Philippe Glaziou <glaziou at pasteur-kh.org> wrote:
> Peter, I cannot see your point. sed can get rid of any pattern in
> a text file. Fuensanta's example seemed to show that the
> sentences (pattern 1, 2,...) were on separate lines from lines
> containing data, thus my approach. Another one closer to your awk
> example would use:
> 
> sed -e '/pattern 1\|pattern 2\|pattern xyz//g' <file.txt>file2.txt


I meant sed -e 's/pattern...
                ^
		
Sorry for the additional noise.

-- 
Philippe



From nirmalg at psu.edu  Wed Nov 19 13:36:27 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Wed, 19 Nov 2003 07:36:27 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
Message-ID: <3FBB63CB.4030106@psu.edu>

Hi,

I ran a small data set from a factorial experiment through R, Minitab 
and JMP... the result from R is significantly different from what 
Minitab or JMP give... The data set is at the following link:

http://www.personal.psu.edu/nug107/Uploads/2x3_16repsANOVA.txt

The first 5 columns are the factors and the next three are responses.
In particular, for the response beta11MSE, two of the significant 
effects in the Minitab (and JMP) ANOVA table are not significant in R... 
  What may be the cause for such a difference? I used the lm function in 
R to do the model fitting and fit a model with main effects and 2-way 
interactions in the 5 factors. The design that generated this data was a 
32-run 2^5 full factorial.

Thanks,
nirmal



From nielssteenkrogh at hotmail.com  Wed Nov 19 13:50:01 2003
From: nielssteenkrogh at hotmail.com (Niels Steen Krogh)
Date: Wed, 19 Nov 2003 13:50:01 +0100
Subject: [R] howto improve sharpeness of fonts in a jpg-image producedby R
	?
Message-ID: <BAY7-F20ymQ1WE9ql2R00002bec@hotmail.com>

My original question had the subject of making jpg-image files with the 
bitmap-function.

Firstly I was told, that the problem was in my ghostscript-installation 
which is called by the bitmap-function - not in R itself.

I got a lot of good suggestions (also off-list) about what problems in my 
ghostscript-installation might give some low-quality font-sharpeness in my 
jpg-grafics produced by bitmap.   I tried options like (res=150, 
point=15....) - and substituted jpeg with png -  but wasn't able to find out 
why ghostscript selects the bad fonts (or what might be the problem) when 
producing a png/jpg-image through the bitmap-function. I was actually able 
to produce nice-looking png's doing the steps:
1. Using bitmap to produce a pdf-file
2. invoking ghostscript from my bash-shell and converting the pdf-file 
produced by the bitmap-function into a png-image.   ( gs -sDEVICE=png256 
-r150 -dBATCH -sOutputFile=barplotx_normal.png         
/usr/share/ghostscript/7.05/examples/barplotx_normal.pdf)

In the end the best suggestion was to try another approach using the 
png-function in R instead of the bitmap-function.

/Niels

R1.8.0
Linux redhat 9
GhostScript version 7.05

Cand. Polit.
Niels Steen Krogh
Solsortvej 44
2000 F.

Tlf: 3888 8613

ZiteLab / EmpoweR youR data with R, Zope and SOAP



From heiko.schaefer at swissrisk.com  Wed Nov 19 14:58:24 2003
From: heiko.schaefer at swissrisk.com (Heiko Schaefer)
Date: Wed, 19 Nov 2003 14:58:24 +0100
Subject: [R] ISOdate returns incorrect date?
Message-ID: <002c01c3aea5$341ba650$b600000a@HEIKO>


Dear all,

I have found the following (for me) incomprehensible behaviour of
ISOdate (POSIXct):
> ISOdate(1900,6,16)
[1] "1900-06-15 14:00:00 Westeurop?ische Sommerzeit"
> ISOdate(1950,6,16)
[1] "1950-06-16 14:00:00 Westeurop?ische Sommerzeit"

Note that in the first case I get the 15th of June back, not the 16th as
I would have expected!
This happened under R-1.7.1 on both windows and linux.

I would greatly appreciate your comments,

Heiko



From jfox at mcmaster.ca  Wed Nov 19 15:03:24 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 19 Nov 2003 09:03:24 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <3FBB63CB.4030106@psu.edu>
Message-ID: <5.1.0.14.2.20031119085414.01fd9440@127.0.0.1>

Dear Nirmal,

At 07:36 AM 11/19/2003 -0500, Nirmal Govind wrote:

>I ran a small data set from a factorial experiment through R, Minitab and 
>JMP... the result from R is significantly different from what Minitab or 
>JMP give... The data set is at the following link:
>
>http://www.personal.psu.edu/nug107/Uploads/2x3_16repsANOVA.txt
>
>The first 5 columns are the factors and the next three are responses.
>In particular, for the response beta11MSE, two of the significant effects 
>in the Minitab (and JMP) ANOVA table are not significant in R...  What may 
>be the cause for such a difference? I used the lm function in R to do the 
>model fitting and fit a model with main effects and 2-way interactions in 
>the 5 factors. The design that generated this data was a 32-run 2^5 full 
>factorial.

 From your description, it's not possible to tell what you did or exactly 
what happened -- either in R or in Minitab (and JMP).

Moreover, bcause the design is orthogonal and the factors are dichotomous, 
it's very difficult to get the analysis wrong, at least in R. I believe 
that you should get correct sums of squares even if you don't treat the 
factors as factors, regardless of contrast coding, and even if you use 
"sequential" SSs, as calculated by the anova function (all of which could 
get you in trouble more generally).

Here are the results that I get from R and SAS (I don't have Minitab or JMP):

 > anova(lm(beta11MSE ~ (Cycles + Replns + VarZ + NormB + NormG)^2))
Analysis of Variance Table

Response: beta11MSE
               Df  Sum Sq Mean Sq F value    Pr(>F)
Cycles         1 0.00102 0.00102  0.1602  0.694250
Replns         1 0.18457 0.18457 28.9170 6.164e-05 ***
VarZ           1 0.26800 0.26800 41.9879 7.597e-06 ***
NormB          1 0.00491 0.00491  0.7689  0.393527
NormG          1 0.33606 0.33606 52.6497 1.921e-06 ***
Cycles:Replns  1 0.00004 0.00004  0.0059  0.939751
Cycles:VarZ    1 0.00131 0.00131  0.2060  0.656054
Cycles:NormB   1 0.00008 0.00008  0.0131  0.910348
Cycles:NormG   1 0.00088 0.00088  0.1377  0.715457
Replns:VarZ    1 0.07781 0.07781 12.1897  0.003018 **
Replns:NormB   1 0.00360 0.00360  0.5636  0.463697
Replns:NormG   1 0.08693 0.08693 13.6199  0.001982 **
VarZ:NormB     1 0.00351 0.00351  0.5498  0.469155
VarZ:NormG     1 0.08990 0.08990 14.0843  0.001737 **
NormB:NormG    1 0.00268 0.00268  0.4206  0.525839
Residuals     16 0.10213 0.00638


proc glm;
   class Cycles Replns VarZ NormB NormG;
   model beta11MSE = Cycles|Replns Cycles|VarZ Cycles|NormB Cycles|NormG
   Replns|VarZ Replns|NormB Replns|NormG VarZ|NormB VarZ|NormG NormB|NormG;
   run;

       Source                      DF       Type I SS     Mean Square    F 
Value    Pr > F

       Cycles                       1      0.00102265      0.00102265 
0.16    0.6942
       Replns                       1      0.18457369      0.18457369 
28.92    <.0001
       Cycles*Replns                1      0.00003763      0.00003763 
0.01    0.9398
       VarZ                         1      0.26800351      0.26800351 
41.99    <.0001
       Cycles*VarZ                  1      0.00131456      0.00131456 
0.21    0.6561
       NormB                        1      0.00490793      0.00490793 
0.77    0.3935
       Cycles*NormB                 1      0.00008353      0.00008353 
0.01    0.9103
       NormG                        1      0.33605652      0.33605652 
52.65    <.0001
       Cycles*NormG                 1      0.00087885      0.00087885 
0.14    0.7155
       Replns*VarZ                  1      0.07780526      0.07780526 
12.19    0.0030
       Replns*NormB                 1      0.00359764      0.00359764 
0.56    0.4637
       Replns*NormG                 1      0.08693408      0.08693408 
13.62    0.0020
       VarZ*NormB                   1      0.00350913      0.00350913 
0.55    0.4692
       VarZ*NormG                   1      0.08989860      0.08989860 
14.08    0.0017
       NormB*NormG                  1      0.00268461      0.00268461 
0.42    0.5258


       Source                      DF     Type III SS     Mean Square    F 
Value    Pr > F

       Cycles                       1      0.00102265      0.00102265 
0.16    0.6942
       Replns                       1      0.18457369      0.18457369 
28.92    <.0001
       Cycles*Replns                1      0.00003763      0.00003763 
0.01    0.9398
       VarZ                         1      0.26800351      0.26800351 
41.99    <.0001

       . . .


So, what's the problem?

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From luca at stat.unipg.it  Wed Nov 19 15:09:51 2003
From: luca at stat.unipg.it (Luca Scrucca)
Date: Wed, 19 Nov 2003 15:09:51 +0100 (MET)
Subject: [R] Installing RXlisp
Message-ID: <Pine.SOL.4.50.0311191504070.9158-100000@pearson.stat.unipg.it>

Dear R users,

I was trying to install the package RXLisp by Duncan Temple Lang on a MDK
9.1 Linux machine running R 1.8.0 installed from a RPM.
Unfortunately I had a problem loading the shared library into R. Since
I'm a Linux newbie I was not able to solve the problem. Maybe some of
you can help me.

First of all I downloaded the source archive for Xlisp-Stat and
for the RXlisp package. Then, as root, and from /root/ diretory I type the
following commands:

> tar zxvf xlispstat-3-52-18.tar.gz
> tar xzvf RXLisp_0.3-1.tar.gz
> cd RXLisp/xlisp/
> export XLISP_SRC_DIR=/root/xlispstat-3-52-18
> ./install

The compilation was OK, and the file /root/xlispstat-3-52-18/libxlisp.so
was created. Then

> cd
> R CMD INSTALL --configure-args='--with-build-xlisp-dll' RXLisp

OK this as well, except for a warning on a .Rd file.

> cp xlispstat-3-52-18/libxlisp.so /usr/lib
> /sbin/ldconfig
> R
-------------------------------------------------------------------------
...
R> library(RXLisp)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/usr/lib/R/library/RXLisp/libs/RXLisp.so":
  libRXLispConverters.so: cannot open shared object file: No such file or
directory
Error in library(RXLisp) : .First.lib failed
R> system("ls /usr/lib/R/library/RXLisp/libs/RXLisp.so")
/usr/lib/R/library/RXLisp/libs/RXLisp.so
R> system("ls -l /usr/lib/R/library/RXLisp/libs/RXLisp.so")
-rwxr-xr-x    1 root     root        52784 Oct 28 15:50
/usr/lib/R/library/RXLisp/libs/RXLisp.so
-------------------------------------------------------------------------

I'm a bit confused; the file /usr/lib/R/library/RXLisp/libs/RXLisp.so does
exist, but it seems it can't be loaded. Maybe, the problem is not there.

Do you have any clue of what's going on and how can I fix the problem ?

I hope to be able to install the RXLisp package, I loved the dynamic
graphics capabilities of Xlisp-Stat and it would be very nice to have them
available within R.

Thank you very much for your help.

Luca


+-----------------------------------------------------------------------+
| Dr. Luca Scrucca                                                      |
| Dipartimento di Scienze Statistiche      tel. +39 - 075 - 5855278     |
| Universit degli Studi di Perugia        fax. +39 - 075 - 5855950     |
| Via Pascoli - C.P. 1315 Succ. 1                                       |
| 06100 PERUGIA  (ITALY)                                                |
|                                                                       |
| E-mail:   luca at stat.unipg.it                                          |
| Web page: http://www.stat.unipg.it/luca                               |
+-----------------------------------------------------------------------+



From nirmalg at psu.edu  Wed Nov 19 15:12:28 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Wed, 19 Nov 2003 09:12:28 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <5.1.0.14.2.20031119085414.01fd9440@127.0.0.1>
References: <5.1.0.14.2.20031119085414.01fd9440@127.0.0.1>
Message-ID: <3FBB7A4C.20402@psu.edu>

Thank you very much John and Sundar for your quick responses.

>  From your description, it's not possible to tell what you did or 
> exactly what happened -- either in R or in Minitab (and JMP).

John: in R, I fit the model using lm exactly as you did.. however, for 
the ANOVA table, I used summary(lm) and also tried aov(lm) but not 
anova(lm) ... and it looks like therein lies the problem.. the output of 
these differ.

What's the difference between aov, summary and anova? And when should 
one use one as opposed to the other? It's hard to tell from the help for 
these functions...

Thanks,
nirmal



From s.henderson at ucl.ac.uk  Wed Nov 19 15:47:49 2003
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Wed, 19 Nov 2003 14:47:49 -0000
Subject: [R] X11/ graphics problem
Message-ID: <E7CF6BC2744CBE41AE4E87635C7C893C1C662D@exc.wibr.ucl.ac.uk>

Hello

I'm moving from using R 1.8 for Windows to using Linux (Redhat version 9)
and I cannot get any graphics. However everything else maths, models
equations is fine-- and much quicker. I built from the source file following
the commands in the install manual.

>plot(1:10, 1:10)

does nothing! So clearly I have a problem with X Windows.

> capabilities()
    jpeg      png    tcltk      X11    GNOME     libz http/ftp  sockets
   FALSE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE     TRUE
  libxml     fifo   cledit  IEEE754    bzip2     PCRE
    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE

I'm guessing from manuals etc that X11 is the problem. I've tried starting R
with

R --gui='X11'

but to no avail!

I've also had a look at the requirements under R/bin/linux/redhat/9/i386--
but I'm having some trouble mapping these to the gui installation names,
though Xfree86 which I presume contains libX11.so.6 is installed. This
document also mentions preference for 'gnorpm'. Whats that?

Has anyone else had this problem? have an idea what is likely missing? or
how to reconfigure R?


**********************************************************************
This email and any files transmitted with it are confidentia...{{dropped}}



From jfox at mcmaster.ca  Wed Nov 19 15:57:40 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 19 Nov 2003 09:57:40 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <3FBB7A4C.20402@psu.edu>
References: <5.1.0.14.2.20031119085414.01fd9440@127.0.0.1>
	<5.1.0.14.2.20031119085414.01fd9440@127.0.0.1>
Message-ID: <5.1.0.14.2.20031119095000.01fc92f0@127.0.0.1>

Dear Nirmal,

At 09:12 AM 11/19/2003 -0500, Nirmal Govind wrote:
>Thank you very much John and Sundar for your quick responses.
>
>>  From your description, it's not possible to tell what you did or 
>> exactly what happened -- either in R or in Minitab (and JMP).
>
>John: in R, I fit the model using lm exactly as you did.. however, for the 
>ANOVA table, I used summary(lm) and also tried aov(lm) but not anova(lm) 
>... and it looks like therein lies the problem.. the output of these differ.
>
>What's the difference between aov, summary and anova? And when should one 
>use one as opposed to the other? It's hard to tell from the help for these 
>functions...

Briefly, as ?aov mentions, aov() calls lm() -- the difference is in the 
results produced by generic functions like summary(), print(), etc. For 
example, summary.lm() produces a table of coefficients, std. errors, etc., 
while summary.aov() produces an ANOVA table. One would not normally call 
aov() with a linear-model object as an argument (though this works). 
Applied to a linear-model object, summary() produces coefficients, etc. (as 
mentioned), while anova() produces a (sequential) ANOVA table. This seems 
apparent to me from the output.

More generally, it probably makes sense to read introductory material about 
R -- such as the introductory manual that comes with the software or one of 
several books (some freely available on the Internet) that describe its use 
(see under documentation at <http://www.r-project.org/>).

John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From duncan at research.bell-labs.com  Wed Nov 19 16:05:03 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Wed, 19 Nov 2003 10:05:03 -0500
Subject: [R] Installing RXlisp
In-Reply-To: <Pine.SOL.4.50.0311191504070.9158-100000@pearson.stat.unipg.it>;
	from luca@stat.unipg.it on Wed, Nov 19, 2003 at 03:09:51PM +0100
References: <Pine.SOL.4.50.0311191504070.9158-100000@pearson.stat.unipg.it>
Message-ID: <20031119100503.B19739@jessie.research.bell-labs.com>


You probably need to set the LD_LIBRARY_PATH environment
variable to include

   /usr/lib/R/library/RXLisp/libs

before you start R so that it can find the libRXLispConverters.so
file.  I assume that is in that directory. If not,
use the  --clean flag for R CMD INSTALL, i.e.

   R CMD INSTALL --clean --configure-args='--with-build-xlisp-dll' RXLisp


I haven't looked at this package for a while, so let me know if there
are other problems.

   D.





Luca Scrucca wrote:
> Dear R users,
> 
> I was trying to install the package RXLisp by Duncan Temple Lang on a MDK
> 9.1 Linux machine running R 1.8.0 installed from a RPM.
> Unfortunately I had a problem loading the shared library into R. Since
> I'm a Linux newbie I was not able to solve the problem. Maybe some of
> you can help me.
> 
> First of all I downloaded the source archive for Xlisp-Stat and
> for the RXlisp package. Then, as root, and from /root/ diretory I type the
> following commands:
> 
> > tar zxvf xlispstat-3-52-18.tar.gz
> > tar xzvf RXLisp_0.3-1.tar.gz
> > cd RXLisp/xlisp/
> > export XLISP_SRC_DIR=/root/xlispstat-3-52-18
> > ./install
> 
> The compilation was OK, and the file /root/xlispstat-3-52-18/libxlisp.so
> was created. Then
> 
> > cd
> > R CMD INSTALL --configure-args='--with-build-xlisp-dll' RXLisp
> 
> OK this as well, except for a warning on a .Rd file.
> 
> > cp xlispstat-3-52-18/libxlisp.so /usr/lib
> > /sbin/ldconfig
> > R
> -------------------------------------------------------------------------
> ...
> R> library(RXLisp)
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library
> "/usr/lib/R/library/RXLisp/libs/RXLisp.so":
>   libRXLispConverters.so: cannot open shared object file: No such file or
> directory
> Error in library(RXLisp) : .First.lib failed
> R> system("ls /usr/lib/R/library/RXLisp/libs/RXLisp.so")
> /usr/lib/R/library/RXLisp/libs/RXLisp.so
> R> system("ls -l /usr/lib/R/library/RXLisp/libs/RXLisp.so")
> -rwxr-xr-x    1 root     root        52784 Oct 28 15:50
> /usr/lib/R/library/RXLisp/libs/RXLisp.so
> -------------------------------------------------------------------------
> 
> I'm a bit confused; the file /usr/lib/R/library/RXLisp/libs/RXLisp.so does
> exist, but it seems it can't be loaded. Maybe, the problem is not there.
> 
> Do you have any clue of what's going on and how can I fix the problem ?
> 
> I hope to be able to install the RXLisp package, I loved the dynamic
> graphics capabilities of Xlisp-Stat and it would be very nice to have them
> available within R.
> 
> Thank you very much for your help.
> 
> Luca
> 
> 
> +-----------------------------------------------------------------------+
> | Dr. Luca Scrucca                                                      |
> | Dipartimento di Scienze Statistiche      tel. +39 - 075 - 5855278     |
> | Universit? degli Studi di Perugia        fax. +39 - 075 - 5855950     |
> | Via Pascoli - C.P. 1315 Succ. 1                                       |
> | 06100 PERUGIA  (ITALY)                                                |
> |                                                                       |
> | E-mail:   luca at stat.unipg.it                                          |
> | Web page: http://www.stat.unipg.it/luca                               |
> +-----------------------------------------------------------------------+
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From ripley at stats.ox.ac.uk  Wed Nov 19 16:13:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 15:13:57 +0000 (GMT)
Subject: [R] X11/ graphics problem
In-Reply-To: <E7CF6BC2744CBE41AE4E87635C7C893C1C662D@exc.wibr.ucl.ac.uk>
Message-ID: <Pine.LNX.4.44.0311191508460.14385-100000@gannet.stats>

Did you build from sources or install an RPM?

If the former, you probably do not have the X11 development files
installed.  Something like XFree86-devel-4.2.0-72 (from RH8.0).  (My guess
is that you do have XFree86-libs.)

rm config.cache and reconfigure and rebuild after installation.

On Wed, 19 Nov 2003, Stephen Henderson wrote:

> Hello
> 
> I'm moving from using R 1.8 for Windows to using Linux (Redhat version 9)
> and I cannot get any graphics. However everything else maths, models
> equations is fine-- and much quicker. I built from the source file following
> the commands in the install manual.
> 
> >plot(1:10, 1:10)
> 
> does nothing! So clearly I have a problem with X Windows.

It plots on Rplots.ps, not nothing.

> > capabilities()
>     jpeg      png    tcltk      X11    GNOME     libz http/ftp  sockets
>    FALSE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE     TRUE
>   libxml     fifo   cledit  IEEE754    bzip2     PCRE
>     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
> 
> I'm guessing from manuals etc that X11 is the problem. I've tried starting R
> with
> 
> R --gui='X11'
> 
> but to no avail!
> 
> I've also had a look at the requirements under R/bin/linux/redhat/9/i386--
> but I'm having some trouble mapping these to the gui installation names,
> though Xfree86 which I presume contains libX11.so.6 is installed. This
> document also mentions preference for 'gnorpm'. Whats that?
> 
> Has anyone else had this problem? have an idea what is likely missing? or
> how to reconfigure R?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Wed Nov 19 16:17:26 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 09:17:26 -0600
Subject: [R] X11/ graphics problem
In-Reply-To: <E7CF6BC2744CBE41AE4E87635C7C893C1C662D@exc.wibr.ucl.ac.uk>
References: <E7CF6BC2744CBE41AE4E87635C7C893C1C662D@exc.wibr.ucl.ac.uk>
Message-ID: <1069255045.4563.384.camel@localhost.localdomain>

On Wed, 2003-11-19 at 08:47, Stephen Henderson wrote:
> Hello
> 
> I'm moving from using R 1.8 for Windows to using Linux (Redhat version 9)
> and I cannot get any graphics. However everything else maths, models
> equations is fine-- and much quicker. I built from the source file following
> the commands in the install manual.
> 
> >plot(1:10, 1:10)
> 
> does nothing! So clearly I have a problem with X Windows.
> 
> > capabilities()
>     jpeg      png    tcltk      X11    GNOME     libz http/ftp  sockets
>    FALSE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE     TRUE
>   libxml     fifo   cledit  IEEE754    bzip2     PCRE
>     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
> 
> I'm guessing from manuals etc that X11 is the problem. I've tried starting R
> with
> 
> R --gui='X11'
> 
> but to no avail!
> 
> I've also had a look at the requirements under R/bin/linux/redhat/9/i386--
> but I'm having some trouble mapping these to the gui installation names,
> though Xfree86 which I presume contains libX11.so.6 is installed. This
> document also mentions preference for 'gnorpm'. Whats that?
> 
> Has anyone else had this problem? have an idea what is likely missing? or
> how to reconfigure R?


This seems to be rapidly becoming a FAQ of late.  :-)

The problem is that when you compile R from source code as opposed to
using the pre-compiled binaries that Martyn has kindly provided, you
must have the development libraries for the associated functionality
installed on your system.

In this case the requisite RPM will be XFree86-devel-VERSION.NUMBER.
Presumably, when you installed RH9, you likely did not install all of
the development tools.

If you do:

rpm -q XFree86-devel

from a terminal console, it will likely indicate that it is not
installed.

Lacking this, you cannot compile functionality for the X11() device (the
screen plotting device) into R. Thus, it is not shown when you use the
capabilities() function.

If you have your RH 9 CD's or DVD, you can go to the Add/Remove
Applications menu program and run that (as root) to add the X
development libraries, which should be listed under X Software
Development.

Notice also that you are missing jpeg and png functionality as well. If
you are going to be compiling from source code, you should install all
of the development related tools from the RH CDs/DVD.

Once you install the additional development related RPMS, you should be
good to go.

The 'gnorpm' program is the RH GUI program for installing RPMS as
opposed to doing it from the command line. There have been notable
problems using that GUI and most? folks do not use it.

HTH,

Marc Schwartz



From rab at nauticom.net  Wed Nov 19 16:26:34 2003
From: rab at nauticom.net (Rick Bilonick)
Date: Wed, 19 Nov 2003 10:26:34 -0500
Subject: [R] X11/ graphics problem
In-Reply-To: <E7CF6BC2744CBE41AE4E87635C7C893C1C662D@exc.wibr.ucl.ac.uk>
References: <E7CF6BC2744CBE41AE4E87635C7C893C1C662D@exc.wibr.ucl.ac.uk>
Message-ID: <3FBB8BAA.7090605@nauticom.net>

Stephen Henderson wrote:

>Hello
>
>I'm moving from using R 1.8 for Windows to using Linux (Redhat version 9)
>and I cannot get any graphics. However everything else maths, models
>equations is fine-- and much quicker. I built from the source file following
>the commands in the install manual.
>
>  
>
>

>
>I've also had a look at the requirements under R/bin/linux/redhat/9/i386--
>but I'm having some trouble mapping these to the gui installation names,
>though Xfree86 which I presume contains libX11.so.6 is installed. This
>document also mentions preference for 'gnorpm'. Whats that?
>
>Has anyone else had this problem? have an idea what is likely missing? or
>how to reconfigure R?
>
>  
>
I have R 1.8 installed on 3 different systems running RH 9 using the 
precompiled binaries. R makes plots on all of them. One of the systems 
is a laptop (Toshiba Satellite 2535cds). For some reason on this system 
there is a readline problem and I have to use:

 > R --no-readline

in order to run R but the graphics work fine. Before running 1.8 on this 
machine, I had compiled 1.7.1 (it took many many hours). R would run BUT 
I still had to use the --no-readline option AND the "x11" function would 
not work. (As a work around, I just used "pdf" and used the "system" 
function with gv to view the plots.) Since then I've installed 1.8 using 
the precompiled rpm available from the CRAN mirrors and it works except 
for the readline problem.

Maybe if you install the rpm your graphics will work. If not, "pdf" 
should work. (I'm assuming you have XFree86's Xwindows running.)

BTW, gnorpm is a graphical frontend to rpm. Although to install the one 
rpm for R 1.8, all you need is to do as root:

 > rpm -i R-1.8.0-1.i386.rpm

or

 > rpm -U R-1.8.0-1.i386.rpm

if upgrading from an earlier version of R. I always like to do:

 > rpm -U --test R-1.8.0-1.i386.rpm

first, just to see if there are any problems before actually upgrading. 
I'm not sure why anyone would go through the trouble and time needed for 
compiling when the appropriate rpm is readily available.

Rick B.



From ririzarr at jhsph.edu  Wed Nov 19 16:29:53 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Wed, 19 Nov 2003 10:29:53 -0500 (EST)
Subject: [R] X11/ graphics problem
In-Reply-To: <1069255045.4563.384.camel@localhost.localdomain>
Message-ID: <Pine.GSO.4.10.10311191024430.5834-100000@athena.biostat.jhsph.edu>

fyi, the default RH9 installation from Dell (and probably other vendors)
does not include the developmental tools. Furthermore, the default in the
RH 9.0 installation CD is not to include the developmental tools.
so, i think you are right in saying that this will become a FAQ.


On Wed, 19 Nov 2003, Marc Schwartz wrote:

> On Wed, 2003-11-19 at 08:47, Stephen Henderson wrote:
> > Hello
> > 
> > I'm moving from using R 1.8 for Windows to using Linux (Redhat version 9)
> > and I cannot get any graphics. However everything else maths, models
> > equations is fine-- and much quicker. I built from the source file following
> > the commands in the install manual.
> > 
> > >plot(1:10, 1:10)
> > 
> > does nothing! So clearly I have a problem with X Windows.
> > 
> > > capabilities()
> >     jpeg      png    tcltk      X11    GNOME     libz http/ftp  sockets
> >    FALSE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE     TRUE
> >   libxml     fifo   cledit  IEEE754    bzip2     PCRE
> >     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
> > 
> > I'm guessing from manuals etc that X11 is the problem. I've tried starting R
> > with
> > 
> > R --gui='X11'
> > 
> > but to no avail!
> > 
> > I've also had a look at the requirements under R/bin/linux/redhat/9/i386--
> > but I'm having some trouble mapping these to the gui installation names,
> > though Xfree86 which I presume contains libX11.so.6 is installed. This
> > document also mentions preference for 'gnorpm'. Whats that?
> > 
> > Has anyone else had this problem? have an idea what is likely missing? or
> > how to reconfigure R?
> 
> 
> This seems to be rapidly becoming a FAQ of late.  :-)
> 
> The problem is that when you compile R from source code as opposed to
> using the pre-compiled binaries that Martyn has kindly provided, you
> must have the development libraries for the associated functionality
> installed on your system.
> 
> In this case the requisite RPM will be XFree86-devel-VERSION.NUMBER.
> Presumably, when you installed RH9, you likely did not install all of
> the development tools.
> 
> If you do:
> 
> rpm -q XFree86-devel
> 
> from a terminal console, it will likely indicate that it is not
> installed.
> 
> Lacking this, you cannot compile functionality for the X11() device (the
> screen plotting device) into R. Thus, it is not shown when you use the
> capabilities() function.
> 
> If you have your RH 9 CD's or DVD, you can go to the Add/Remove
> Applications menu program and run that (as root) to add the X
> development libraries, which should be listed under X Software
> Development.
> 
> Notice also that you are missing jpeg and png functionality as well. If
> you are going to be compiling from source code, you should install all
> of the development related tools from the RH CDs/DVD.
> 
> Once you install the additional development related RPMS, you should be
> good to go.
> 
> The 'gnorpm' program is the RH GUI program for installing RPMS as
> opposed to doing it from the command line. There have been notable
> problems using that GUI and most? folks do not use it.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Wed Nov 19 16:48:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Nov 2003 16:48:39 +0100
Subject: [R] question
In-Reply-To: <20031119122055.GA16232@pasteur-kh.org>
References: <1069234359.3fbb38b77ea8a@webmail.uji.es>
	<20031119101859.GF16984@pasteur-kh.org> <x2y8ucbnqo.fsf@biostat.ku.dk>
	<20031119122055.GA16232@pasteur-kh.org>
Message-ID: <x2k75wbbqg.fsf@biostat.ku.dk>

Philippe Glaziou <glaziou at pasteur-kh.org> writes:

> > Er, no, that wasn't the requirement. It's a job for awk or perl, e.g.
> > 
> > #!/usr/bin/perl -n
> > if (/pattern 1/){
> >     $copy = 1;
> >     next;
> > }
> > if (/pattern 2/){
> >     $copy = 0;
> > }
> > print if $copy;
> > 
> > or 
> > 
> > awk '/pattern 1/{copy=1;next};/pattern 2/{copy=0};copy==1' < file.txt > file2.txt
> 
> 
> Peter, I cannot see your point. sed can get rid of any pattern in
> a text file. Fuensanta's example seemed to show that the
> sentences (pattern 1, 2,...) were on separate lines from lines
> containing data, thus my approach. Another one closer to your awk
> example would use:
> 
> sed -e '/pattern 1\|pattern 2\|pattern xyz//g' <file.txt>file2.txt
> 
> Or is this just a perl versus sed versus awk troll?

Data was

2.22 3.45
1.56 2.31
pattern 1
4.67 7.91
3.34 2.15
5.32 3.88
pattern 2

blueberry:~/> sed -e 's/pattern 1\|pattern 2\|pattern xyz//g' < tst.txt
2.22 3.45
1.56 2.31

4.67 7.91
3.34 2.15
5.32 3.88

blueberry:~/> awk '/pattern 1/{copy=1;next};/pattern 2/{copy=0};copy==1' < tst.txt
4.67 7.91
3.34 2.15
5.32 3.88
blueberry:~/> perl -ne 'if(/pattern 1/){$copy=1;next;} if(/pattern 2/){$copy=0;}print if $copy' < tst.txt
4.67 7.91
3.34 2.15
5.32 3.88
blueberry:~/>



The original message started:

"Does anyone know how I can read from a .txt file the lines that are between
two strings whose location is unknown?"


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Wed Nov 19 16:45:05 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 19 Nov 2003 10:45:05 -0500 (EST)
Subject: [R] question (and a suggestion)
Message-ID: <20031119154505.603653967@mprdmxin.myway.com>



This question repeatedly comes up, e.g. see

https://www.stat.math.ethz.ch/pipermail/r-help/2003-November/040184.html
https://www.stat.math.ethz.ch/pipermail/r-help/2003-November/040348.html

from less than two weeks ago.  

One thing that occurred to me is that the answer could be simplified
if skip= could take a 2-vector argument such that:

read.table("x.dat", skip=grep("start|end",readLines("x.dat")), head=T)

reads in the data.  We already have nrows= but it deals with logical
lines whereas skip= deals with physical lines making it harder to 
handle, particularly when blank lines are thrown away.

An even more powerful facility would be to allow the elements of
the 2-vector to be either as above or regular expressions.  In
the latter case, one could simply write:

  read.table("x.dat", skip=c("start","end"), head=T)

which has the added benefit of not reading the data twice.  Of
course, there are numerous other possibilities for embedding data 
in a text file that this does not handle but, based on the postings 
to the list, this does seem to be the common one not already 
easily handled by read.table.

---
Date: Wed, 19 Nov 2003 10:32:39 +0100 
From: Fuensanta Saura Igual <igual at mat.uji.es>
To: <R-help at stat.math.ethz.ch> 
Subject: [R] question 

 
 


Does anyone know how I can read from a .txt file the lines that are between
two strings whose location is unknown?

My problem is that I have a .txt file with data separated by a sentence,
for example:

2.22 3.45
1.56 2.31
pattern 1
4.67 7.91
3.34 2.15
5.32 3.88
pattern 2
...

I do not know the number of lines where these separating sentences are located,
because the number of lines in between them can be random. If it was fixed, I 
think I could use "read.table" using the option "skip", but in this case, I do 
not know how I could manage to do that automatically.

Thanks.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jc at or.psychology.dal.ca  Wed Nov 19 16:51:37 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Wed, 19 Nov 2003 11:51:37 -0400
Subject: [R] repeated measure in GLM
Message-ID: <42110C1F-1AA8-11D8-953E-000A956DE534@or.psychology.dal.ca>


	I was recently asked to perform a GLM analysis (the person comes from 
the JMP world) on a repeated measures design.  I have found some things 
using aov but I cannot find anything with glm.  In fact, multiple 
regressions in general with repeated measures seems to be poorly 
covered in documentation.  I remember SPSS has separate commands to 
handle them.
	I have within variables SOA and ec and a between factor subjrt.  The 
independent variable was RT.  The ec factor cannot be construed as 
parameteric whereas SOA can.



From duncan at research.bell-labs.com  Wed Nov 19 16:54:34 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Wed, 19 Nov 2003 10:54:34 -0500
Subject: [R] size of graphics device
In-Reply-To: <001a01c3ae8e$b41c79e0$ac0b24d5@jetzt0>;
	from alain.guerreau@libertysurf.fr on Wed, Nov 19, 2003 at
	12:16:31PM +0100
References: <001a01c3ae8e$b41c79e0$ac0b24d5@jetzt0>
Message-ID: <20031119105434.G19739@jessie.research.bell-labs.com>

FWIW, there is a way to have one or more scrolled graphics devices
using the RGtk (www.omegahat.org/RGtk) and gtkDevice (from CRAN)
packages.  This currently works only on Unix/Linux.

The following code creates a window with a graphics device inside a
scrolled window inside a top-level Gtk window.



library(RGtk)
library(gtkDevice)

win = gtkWindow(show = FALSE)

sw = gtkScrolledWindow()

scrolledDevice <- gtkDrawingArea()
scrolledDevice$SetUsize(5000, 5000)  # pixels

sw$AddWithViewport(scrolledDevice)

win$Add(sw)
win$SetUsize(800, 700)   # pixels
win$Show()

asGtkDevice(scrolledDevice)  # (from gtkDevice)


Now you are ready to plot.

plot(rnorm(10000))


 D.



guerreau wrote:
> Dear all,
> 
> In many cases, I need a plotting region much bigger than the screen (e.g. for maps or for graphs with many labels).
> 
> A. MS-Windows
> if I try
> windows(width=25, height=25, rescale="fixed")
> it seems to be OK (a screen with scrollbars, exactly what I need)
> 
> but if I try then
> plot(faithful$eruptions, faithful$waiting)
> 
> I receive 
> 
> Error in plot.new() : Outer margins too large (fig.region too small)
> 
> B. Linux
> I try
> X11(width=25, height=25)
> (and the same)
> 
> No  Error message, but no scrollbars !!
> 
> 
> Is there a solution ?
> 
> with many thanks in advance
> 
> Alain Guerreau   directeur de recherche au CNRS  Paris
> alain.guerreau at libertysurf.fr
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From ggrothendieck at myway.com  Wed Nov 19 17:06:29 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 19 Nov 2003 11:06:29 -0500 (EST)
Subject: [R] ISOdate returns incorrect date?
Message-ID: <20031119160629.0D5CC3985@mprdmxin.myway.com>



ISOdate works, by default, in the GMT timezone. Try:

ISOdate(1900,6,16,tz="")
ISOdate(1950,6,16,tz="")

If you don't need timezones and don't want to worry about them
you can alternately use the chron library for your dates and 
times.

---
Date: Wed, 19 Nov 2003 14:58:24 +0100 
From: Heiko Schaefer <heiko.schaefer at swissrisk.com>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] ISOdate returns incorrect date? 

 
 

Dear all,

I have found the following (for me) incomprehensible behaviour of
ISOdate (POSIXct):
> ISOdate(1900,6,16)
[1] "1900-06-15 14:00:00 Westeuropische Sommerzeit"
> ISOdate(1950,6,16)
[1] "1950-06-16 14:00:00 Westeuropische Sommerzeit"

Note that in the first case I get the 15th of June back, not the 16th as
I would have expected!
This happened under R-1.7.1 on both windows and linux.

I would greatly appreciate your comments,

Heiko

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From MSchwartz at medanalytics.com  Wed Nov 19 17:09:02 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 10:09:02 -0600
Subject: [R] X11/ graphics problem
In-Reply-To: <Pine.GSO.4.10.10311191024430.5834-100000@athena.biostat.jhsph.edu>
References: <Pine.GSO.4.10.10311191024430.5834-100000@athena.biostat.jhsph.edu>
Message-ID: <1069258142.4563.412.camel@localhost.localdomain>

On Wed, 2003-11-19 at 09:29, Rafael A. Irizarry wrote:
> fyi, the default RH9 installation from Dell (and probably other vendors)
> does not include the developmental tools. Furthermore, the default in the
> RH 9.0 installation CD is not to include the developmental tools.
> so, i think you are right in saying that this will become a FAQ.

SNIP

I'm not sure what Dell is providing these days as it seems to be all
over the place with respect to Linux. I have a Dell laptop myself
(i8200), running a self-configured dual-boot of WinXP Pro and Fedora
Core 1 (essentially what was to be RH 10). I am only using WinXP at this
point to run an accounting application that I require. Otherwise, I am
under Linux 99% of the time.

The defacto RH9 (and RH 8.0) installation process via Anaconda has some
preconfigured options (ie. Workstation, etc.) that have predefined sets
of components that get installed based upon certain generic assumptions
for different user types.

In the case of the development options for a more advanced user, one
generally needs to run the Custom installation option, which affords you
the opportunity to select from a wide list of packages. 

There is also the "Install Everything" checkbox option, which is what I
typically run as the custom option menu does not actually install
everything, even if all the individual submenu checkboxes are checked.

As long as you have the CDs or DVD (the DVD was included in the retail
boxed sets), you can go back and install the missing development
components as required.

A decent version specific book on RH Linux would be helpful to
understand the differences in the installation procedures and options.

HTH,

Marc Schwartz



From tlumley at u.washington.edu  Wed Nov 19 17:10:17 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 19 Nov 2003 08:10:17 -0800 (PST)
Subject: [R] repeated measure in GLM
In-Reply-To: <42110C1F-1AA8-11D8-953E-000A956DE534@or.psychology.dal.ca>
References: <42110C1F-1AA8-11D8-953E-000A956DE534@or.psychology.dal.ca>
Message-ID: <Pine.A41.4.58.0311190808220.59784@homer07.u.washington.edu>

On Wed, 19 Nov 2003, John Christie wrote:

>
> 	I was recently asked to perform a GLM analysis (the person comes from
> the JMP world) on a repeated measures design.  I have found some things
> using aov but I cannot find anything with glm.  In fact, multiple
> regressions in general with repeated measures seems to be poorly
> covered in documentation.  I remember SPSS has separate commands to
> handle them.
> 	I have within variables SOA and ec and a between factor subjrt.  The
> independent variable was RT.  The ec factor cannot be construed as
> parameteric whereas SOA can.
>

If the person comes from the JMP world, GLM doesn't translate as glm().
You probably want either aov() or lme() [in the nlme package], depending
on how complicated the analysis is.

	-thomas


Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From spencer.graves at pdf.com  Wed Nov 19 17:14:47 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 19 Nov 2003 08:14:47 -0800
Subject: [R] repeated measure in GLM
In-Reply-To: <42110C1F-1AA8-11D8-953E-000A956DE534@or.psychology.dal.ca>
References: <42110C1F-1AA8-11D8-953E-000A956DE534@or.psychology.dal.ca>
Message-ID: <3FBB96F7.1050105@pdf.com>

      Have you checked the following: 

      www.r-project.org -> search -> "R site search"? 

      In particular, have you considered "lme" in package "nlme"?  
Probably the best documentation on this is Pinhiero and Bates (2000) 
Mixed-Effects Models in S and S-Plus (Springer). 

hope this helps.  spencer graves

John Christie wrote:

>
>     I was recently asked to perform a GLM analysis (the person comes 
> from the JMP world) on a repeated measures design.  I have found some 
> things using aov but I cannot find anything with glm.  In fact, 
> multiple regressions in general with repeated measures seems to be 
> poorly covered in documentation.  I remember SPSS has separate 
> commands to handle them.
>     I have within variables SOA and ec and a between factor subjrt.  
> The independent variable was RT.  The ec factor cannot be construed as 
> parameteric whereas SOA can.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Simon.Fear at synequanon.com  Wed Nov 19 17:17:00 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 19 Nov 2003 16:17:00 -0000
Subject: [R] ISOdate returns incorrect date?
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572D275AC@synequanon01>

Well, I live only a few seconds away from GMT and I also get

> ISOdate(1900,6,16,tz="")
[1] "1900-06-15 12:00:00 GMT Daylight Time"

15th, not 16th.

Was 1900 a strange leap year? I certainly haven't tested
thoroughly but note this:

> ISOdate(1900,2,16,tz="")
[1] "1900-02-16 12:00:00 GMT Standard Time"
# 16th OK in February
> ISOdate(1900,3,16,tz="")
[1] "1900-03-15 12:00:00 GMT Standard Time"
# wrong for March

Using today's release of rw181beta (up to date or what?) 
on Win 98 (oh well).

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> Sent: 19 November 2003 16:06
> To: heiko.schaefer at swissrisk.com; r-help at stat.math.ethz.ch
> Subject: RE: [R] ISOdate returns incorrect date?
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> 
> 
> ISOdate works, by default, in the GMT timezone. Try:
> 
> ISOdate(1900,6,16,tz="")
> ISOdate(1950,6,16,tz="")
> 
> If you don't need timezones and don't want to worry about them
> you can alternately use the chron library for your dates and 
> times.
> 
> ---
> Date: Wed, 19 Nov 2003 14:58:24 +0100 
> From: Heiko Schaefer <heiko.schaefer at swissrisk.com>
> To: <r-help at stat.math.ethz.ch> 
> Subject: [R] ISOdate returns incorrect date? 
> 
>  
>  
> 
> Dear all,
> 
> I have found the following (for me) incomprehensible behaviour of
> ISOdate (POSIXct):
> > ISOdate(1900,6,16)
> [1] "1900-06-15 14:00:00 Westeuropdische Sommerzeit"
> > ISOdate(1950,6,16)
> [1] "1950-06-16 14:00:00 Westeuropdische Sommerzeit"
> 
> Note that in the first case I get the 15th of June back, not 
> the 16th as
> I would have expected!
> This happened under R-1.7.1 on both windows and linux.
> 
> I would greatly appreciate your comments,
> 
> Heiko
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From heiko.schaefer at swissrisk.com  Wed Nov 19 17:20:56 2003
From: heiko.schaefer at swissrisk.com (Heiko Schaefer)
Date: Wed, 19 Nov 2003 17:20:56 +0100
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <20031119160629.0D5CC3985@mprdmxin.myway.com>
Message-ID: <002d01c3aeb9$22c5b170$b600000a@HEIKO>


Does this really work for you? I still get:
> ISOdate(1900,6,16)
[1] "1900-06-15 14:00:00 Westeurop?ische Sommerzeit"
> ISOdate(1900,6,16,tz="")
[1] "1900-06-15 12:00:00 Westeurop?ische Sommerzeit"

Obviously the time son influences the time, but it can
Not possibly account for the difference of a full day?!

Still puzzled...

Heiko


-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at myway.com] 
Sent: Mittwoch, 19. November 2003 17:06
To: heiko.schaefer at swissrisk.com; r-help at stat.math.ethz.ch
Subject: RE: [R] ISOdate returns incorrect date?





ISOdate works, by default, in the GMT timezone. Try:



ISOdate(1900,6,16,tz="")

ISOdate(1950,6,16,tz="")



If you don't need timezones and don't want to worry about them

you can alternately use the chron library for your dates and 

times.



---

Date: Wed, 19 Nov 2003 14:58:24 +0100 

From: Heiko Schaefer <heiko.schaefer at swissrisk.com>

To: <r-help at stat.math.ethz.ch> 

Subject: [R] ISOdate returns incorrect date? 



 

 



Dear all,



I have found the following (for me) incomprehensible behaviour of

ISOdate (POSIXct):

> ISOdate(1900,6,16)

[1] "1900-06-15 14:00:00 Westeurop?ische Sommerzeit"

> ISOdate(1950,6,16)

[1] "1950-06-16 14:00:00 Westeurop?ische Sommerzeit"



Note that in the first case I get the 15th of June back, not the 16th as

I would have expected!

This happened under R-1.7.1 on both windows and linux.



I would greatly appreciate your comments,



Heiko



______________________________________________

R-help at stat.math.ethz.ch mailing list

https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From heiko.schaefer at swissrisk.com  Wed Nov 19 17:27:19 2003
From: heiko.schaefer at swissrisk.com (Heiko Schaefer)
Date: Wed, 19 Nov 2003 17:27:19 +0100
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572D275AC@synequanon01>
Message-ID: <002e01c3aeba$00fce670$b600000a@HEIKO>


It starts on the 1st of March 1900 to go wrong .... I feel better now
that somebody
Else these the same effect ;-)

-----Original Message-----
From: Simon Fear [mailto:Simon.Fear at synequanon.com] 
Sent: Mittwoch, 19. November 2003 17:17
To: ggrothendieck at myway.com; heiko.schaefer at swissrisk.com;
r-help at stat.math.ethz.ch
Subject: RE: [R] ISOdate returns incorrect date?


Well, I live only a few seconds away from GMT and I also get

> ISOdate(1900,6,16,tz="")
[1] "1900-06-15 12:00:00 GMT Daylight Time"

15th, not 16th.

Was 1900 a strange leap year? I certainly haven't tested thoroughly but
note this:

> ISOdate(1900,2,16,tz="")
[1] "1900-02-16 12:00:00 GMT Standard Time"
# 16th OK in February
> ISOdate(1900,3,16,tz="")
[1] "1900-03-15 12:00:00 GMT Standard Time"
# wrong for March

Using today's release of rw181beta (up to date or what?) 
on Win 98 (oh well).

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> Sent: 19 November 2003 16:06
> To: heiko.schaefer at swissrisk.com; r-help at stat.math.ethz.ch
> Subject: RE: [R] ISOdate returns incorrect date?
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> 
> 
> ISOdate works, by default, in the GMT timezone. Try:
> 
> ISOdate(1900,6,16,tz="")
> ISOdate(1950,6,16,tz="")
> 
> If you don't need timezones and don't want to worry about them you can

> alternately use the chron library for your dates and times.
> 
> ---
> Date: Wed, 19 Nov 2003 14:58:24 +0100
> From: Heiko Schaefer <heiko.schaefer at swissrisk.com>
> To: <r-help at stat.math.ethz.ch> 
> Subject: [R] ISOdate returns incorrect date? 
> 
>  
>  
> 
> Dear all,
> 
> I have found the following (for me) incomprehensible behaviour of 
> ISOdate (POSIXct):
> > ISOdate(1900,6,16)
> [1] "1900-06-15 14:00:00 Westeuropdische Sommerzeit"
> > ISOdate(1950,6,16)
> [1] "1950-06-16 14:00:00 Westeuropdische Sommerzeit"
> 
> Note that in the first case I get the 15th of June back, not
> the 16th as
> I would have expected!
> This happened under R-1.7.1 on both windows and linux.
> 
> I would greatly appreciate your comments,
> 
> Heiko
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Nov 19 17:33:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 16:33:51 +0000 (GMT)
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <002d01c3aeb9$22c5b170$b600000a@HEIKO>
Message-ID: <Pine.LNX.4.44.0311191629150.14832-100000@gannet.stats>

Well, one clue is that date is before the modern era, and most OSes only
go back to 1902.  Some only go back to 1970!  I suspect the OS does not
know that 1900 was not a leap year.

On Wed, 19 Nov 2003, Heiko Schaefer wrote:

> 
> Does this really work for you? I still get:
> > ISOdate(1900,6,16)
> [1] "1900-06-15 14:00:00 Westeurop?ische Sommerzeit"
> > ISOdate(1900,6,16,tz="")
> [1] "1900-06-15 12:00:00 Westeurop?ische Sommerzeit"
> 
> Obviously the time son influences the time, but it can
> Not possibly account for the difference of a full day?!
> 
> Still puzzled...
> 
> Heiko


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Wed Nov 19 17:45:33 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Nov 2003 17:45:33 +0100
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <002d01c3aeb9$22c5b170$b600000a@HEIKO>
References: <002d01c3aeb9$22c5b170$b600000a@HEIKO>
Message-ID: <x2ekw4b93m.fsf@biostat.ku.dk>

"Heiko Schaefer" <heiko.schaefer at swissrisk.com> writes:

> Does this really work for you? I still get:
> > ISOdate(1900,6,16)
> [1] "1900-06-15 14:00:00 Westeurop?ische Sommerzeit"
> > ISOdate(1900,6,16,tz="")
> [1] "1900-06-15 12:00:00 Westeurop?ische Sommerzeit"
> 
> Obviously the time son influences the time, but it can
> Not possibly account for the difference of a full day?!
> 
> Still puzzled...

Yes, something is strange for me too (RedHat 8):

> ISOdate(1900,3,1)
[1] "1900-03-01 13:00:00 CET"
> ISOdate(1900,3,2)
[1] "1900-03-01 13:00:00 CET"

Apparently, the one-day shift affects all dates after March 2, 1900,
and in no other year. One easily gets the suspicion that the fact that
1900 was *not* a leap year has something to do with it. However,
strptime() which this calls indirectly is only as good as its OS-level
counterpart, I believe. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From heiko.schaefer at swissrisk.com  Wed Nov 19 17:48:00 2003
From: heiko.schaefer at swissrisk.com (Heiko Schaefer)
Date: Wed, 19 Nov 2003 17:48:00 +0100
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <x2ekw4b93m.fsf@biostat.ku.dk>
Message-ID: <002f01c3aebc$eadb2160$b600000a@HEIKO>


You are on the right track. I suppose that linux and windows use 32 bit
For time_t and we go back beyond a valid date. Try this code:

#include <stdio.h>
#include <time.h>

int main() {
  struct tm a;
  time_t b;
  strptime("1900-03-15 12:00:00","%Y-%m-%d %H:%M:%S",&a);
  printf("%s\n",asctime(&a));
  // now go via time_t
  b = mktime(&a);
  printf("%s\n",ctime(&b));
}

And if we go via time_t we get unix epoch 0 back. Somehow R manages
To be less wrong then the OS, but still wrong....

Heiko

-----Original Message-----
From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
Sent: Mittwoch, 19. November 2003 17:46
To: heiko.schaefer at swissrisk.com
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] ISOdate returns incorrect date?


"Heiko Schaefer" <heiko.schaefer at swissrisk.com> writes:

> Does this really work for you? I still get:
> > ISOdate(1900,6,16)
> [1] "1900-06-15 14:00:00 Westeurop?ische Sommerzeit"
> > ISOdate(1900,6,16,tz="")
> [1] "1900-06-15 12:00:00 Westeurop?ische Sommerzeit"
> 
> Obviously the time son influences the time, but it can
> Not possibly account for the difference of a full day?!
> 
> Still puzzled...

Yes, something is strange for me too (RedHat 8):

> ISOdate(1900,3,1)
[1] "1900-03-01 13:00:00 CET"
> ISOdate(1900,3,2)
[1] "1900-03-01 13:00:00 CET"

Apparently, the one-day shift affects all dates after March 2, 1900, and
in no other year. One easily gets the suspicion that the fact that 1900
was *not* a leap year has something to do with it. However,
strptime() which this calls indirectly is only as good as its OS-level
counterpart, I believe. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Wed Nov 19 17:52:36 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 10:52:36 -0600
Subject: [R] X11/ graphics problem
In-Reply-To: <3FBB8BAA.7090605@nauticom.net>
References: <E7CF6BC2744CBE41AE4E87635C7C893C1C662D@exc.wibr.ucl.ac.uk>
	<3FBB8BAA.7090605@nauticom.net>
Message-ID: <1069260756.4563.453.camel@localhost.localdomain>

On Wed, 2003-11-19 at 09:26, Rick Bilonick wrote:

SNIP

> >
> I have R 1.8 installed on 3 different systems running RH 9 using the 
> precompiled binaries. R makes plots on all of them. One of the systems 
> is a laptop (Toshiba Satellite 2535cds). For some reason on this system 
> there is a readline problem and I have to use:
> 
>  > R --no-readline
> 
> in order to run R but the graphics work fine. Before running 1.8 on this 
> machine, I had compiled 1.7.1 (it took many many hours). R would run BUT 
> I still had to use the --no-readline option AND the "x11" function would 
> not work. (As a work around, I just used "pdf" and used the "system" 
> function with gv to view the plots.) Since then I've installed 1.8 using 
> the precompiled rpm available from the CRAN mirrors and it works except 
> for the readline problem.


Please review R FAQ 7.22:

"7.22 How can I get command line editing to work?"

AND the following ReadMe provided by Martyn:

http://cran.r-project.org/bin/linux/redhat/9/i386/ReadMe


HTH,

Marc Schwartz
(Having a sense of Deja Vu...  ;-)



From ggrothendieck at myway.com  Wed Nov 19 18:01:06 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 19 Nov 2003 12:01:06 -0500 (EST)
Subject: [R] ISOdate returns incorrect date?
Message-ID: <20031119170106.29C0C39AA@mprdmxin.myway.com>



One other point that supports your hypothesis is that Excel 2000
on Windows 2000 has a problem in 1900 too.  Enter a date into a 
cell and then enter =60 and it gives the date as Feb 29, 1900 even
though 1900 is not a leap year.   

Windows Excel uses 1900 as the origin for time but when 
Microsoft later created the Mac version of Excel they changed 
the origin to 1904 -- presumably they had realized 
their error by that time.  Excel 2000 allows you to change the default
origin from 1900 to 1904 which allows Windows Excel to properly
read Mac spreadsheets.  See the following for more info on this
and how to set the origin in Excel:

http://support.microsoft.com/default.aspx?scid=http://support.microsoft.com:80/support/kb/articles/q180/1/62.asp&NoWebContent=1


--- 
Date: Wed, 19 Nov 2003 16:33:51 +0000 (GMT) 
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: Heiko Schaefer <heiko.schaefer at swissrisk.com> 
Cc: <r-help at stat.math.ethz.ch> 
Subject: RE: [R] ISOdate returns incorrect date? 

 
 
Well, one clue is that date is before the modern era, and most OSes only
go back to 1902. Some only go back to 1970! I suspect the OS does not
know that 1900 was not a leap year.

On Wed, 19 Nov 2003, Heiko Schaefer wrote:

> 
> Does this really work for you? I still get:
> > ISOdate(1900,6,16)
> [1] "1900-06-15 14:00:00 Westeuropische Sommerzeit"
> > ISOdate(1900,6,16,tz="")
> [1] "1900-06-15 12:00:00 Westeuropische Sommerzeit"
> 
> Obviously the time son influences the time, but it can
> Not possibly account for the difference of a full day?!
> 
> Still puzzled...
> 
> Heiko


-- 
Brian D. Ripley, ripley at stats.ox.ac.uk
Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
University of Oxford, Tel: +44 1865 272861 (self)
1 South Parks Road, +44 1865 272866 (PA)
Oxford OX1 3TG, UK Fax: +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed Nov 19 18:03:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 17:03:17 +0000 (GMT)
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <Pine.LNX.4.44.0311191629150.14832-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0311191700380.14951-100000@gannet.stats>

For the record, ISOdate *is* giving the right answer, a POSIXct object.

The problem is in printing, where there was a simple coding bug: is_year 
was applied to the POSIX `year' which is year-1900.

It's always worth distinguishing between the actual value and its printed 
representation.


On Wed, 19 Nov 2003, Prof Brian Ripley wrote:

> Well, one clue is that date is before the modern era, and most OSes only
> go back to 1902.  Some only go back to 1970!  I suspect the OS does not
> know that 1900 was not a leap year.
> 
> On Wed, 19 Nov 2003, Heiko Schaefer wrote:
> 
> > 
> > Does this really work for you? I still get:
> > > ISOdate(1900,6,16)
> > [1] "1900-06-15 14:00:00 Westeurop?ische Sommerzeit"
> > > ISOdate(1900,6,16,tz="")
> > [1] "1900-06-15 12:00:00 Westeurop?ische Sommerzeit"
> > 
> > Obviously the time son influences the time, but it can
> > Not possibly account for the difference of a full day?!
> > 
> > Still puzzled...
> > 
> > Heiko
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From johannes.ludsteck at wiwi.uni-regensburg.de  Wed Nov 19 18:08:46 2003
From: johannes.ludsteck at wiwi.uni-regensburg.de (Johannes Ludsteck)
Date: Wed, 19 Nov 2003 18:08:46 +0100
Subject: [R] nls (nlrq) boxcox
Message-ID: <3FBBB1AE.18960.6C638D@localhost>

Dear r-help members
I am a newby to R and would like to estimate a simple boxcox 
model, e.g.
 (y^t - 1)/t ~ b0 + b1 * x1 + b2 * x2
unfortunately, R returns with an error message when I try to 
perform this with the call
nls( (y^t - 1)/t ~ b0 + b1 * x1 + b2 * x2, start = 
c(t=1,b0=1,b1=0,b2=0), data = mydataframe)

The error message is  Object "t" not found

Apparently R seems not to accept parameters on the left hand
side of a regression model. I know that the do-it-yourself
strategy is not necessary, since the package box-cox is 
available. Unfortunately, I want the use the box-cox 
transformation in a quantile regression, i.e. I have to replace 
nls by nlrq in the call above.

Any suggestions?

Thanks and best regards,
	Johannes Ludsteck
<><><><><><><><><><><><>
Johannes Ludsteck
Economics Department
University of Regensburg
Universitaetsstrasse 31
93053 Regensburg
Phone +49/0941/943-2741



From paradis at isem.univ-montp2.fr  Wed Nov 19 18:50:33 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Wed, 19 Nov 2003 18:50:33 +0100
Subject: [R] Compiling R 1.8.x under Solaris 9
Message-ID: <4.2.0.58.20031119183845.00b3ff00@isem.isem.univ-montp2.fr>

Dear all,

I am trying to compile R-1.8.0 and R-1.8.1-beta (as 19-11-2003) under 
Solaris 9 using the Sun compilers. './configure' fails; the last lines of 
the display are:


checking whether we can compute C Make dependencies... yes, using cc -M
checking whether cc supports -c -o FILE.lo... yes
checking how to get verbose linking output from f77... -v
checking for Fortran 77 libraries...  -L/usr/local/lib -R/opt/SUNWspro/lib 
-L/opt/SUNWspro/lib -L/opt/SUNWspro/WS6/lib
  -L/usr/ccs/lib -L/usr/lib -lF77 -lM77 -lsunmath -lm -lcx
checking for dummy main to link with Fortran 77 libraries... none
checking for Fortran 77 name-mangling scheme... lower case, underscore, no 
extra underscore
checking whether f77 appends underscores to external names... yes
checking whether mixed C/Fortran code can be run... configure: WARNING: 
cannot run mixed C/Fortan code
configure: error: Maybe check LDFLAGS for paths to Fortran libraries?


I have tried to set LDFLAGS to different values but with no success. I have 
looked in the archives but found no solution. Is there a problem with the 
Solaris compilers? (Others seem to have rather used GCC under Solaris 9.) 
Any help will be appreciated.

Emmanuel Paradis



From dbeyer at u.washington.edu  Wed Nov 19 19:20:16 2003
From: dbeyer at u.washington.edu (Dick Beyer)
Date: Wed, 19 Nov 2003 10:20:16 -0800 (PST)
Subject: [R] Windows R 1.8.0 hangs when Mem Usage >1.8GB
In-Reply-To: <200311191104.hAJB2uPd029703@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.43.0311191020160.27299@hymn11.u.washington.edu>

I have a loop that increases the size of an object after each iteration.  When the Windows Task Manager shows "Mem Usage" about 1.8GB, the Rgui.exe process no longer responds.

I use:

"C:\Program Files\R\rw1080\bin\Rgui.exe" --max-mem-size=4000M --min-vsize=10M --max-vsize=3000M --min-nsize=500k --max-nsize=1000M

I have a dual Xeon 2.8GHz processor box with 4GB of memory and "R version 1.8.0, 2003-10-08".

Any suggestions or ideas would be greatly appreciated.

Thanks,
Dick
*******************************************************************************
Richard P. Beyer, Ph.D.	University of Washington
Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
			Seattle, WA 98105-6099



From ripley at stats.ox.ac.uk  Wed Nov 19 19:22:38 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 18:22:38 +0000 (GMT)
Subject: [R] Compiling R 1.8.x under Solaris 9
In-Reply-To: <4.2.0.58.20031119183845.00b3ff00@isem.isem.univ-montp2.fr>
Message-ID: <Pine.LNX.4.44.0311191816530.15372-100000@gannet.stats>

On Wed, 19 Nov 2003, Emmanuel Paradis wrote:

> Dear all,
> 
> I am trying to compile R-1.8.0 and R-1.8.1-beta (as 19-11-2003) under 
> Solaris 9 using the Sun compilers. './configure' fails; the last lines of 
> the display are:
> 
> 
> checking whether we can compute C Make dependencies... yes, using cc -M
> checking whether cc supports -c -o FILE.lo... yes
> checking how to get verbose linking output from f77... -v
> checking for Fortran 77 libraries...  -L/usr/local/lib -R/opt/SUNWspro/lib 
> -L/opt/SUNWspro/lib -L/opt/SUNWspro/WS6/lib
>   -L/usr/ccs/lib -L/usr/lib -lF77 -lM77 -lsunmath -lm -lcx
> checking for dummy main to link with Fortran 77 libraries... none
> checking for Fortran 77 name-mangling scheme... lower case, underscore, no 
> extra underscore
> checking whether f77 appends underscores to external names... yes
> checking whether mixed C/Fortran code can be run... configure: WARNING: 
> cannot run mixed C/Fortan code
> configure: error: Maybe check LDFLAGS for paths to Fortran libraries?
> 
> 
> I have tried to set LDFLAGS to different values but with no success. I have 
> looked in the archives but found no solution. Is there a problem with the 
> Solaris compilers? (Others seem to have rather used GCC under Solaris 9.) 
> Any help will be appreciated.

This does work, and is covered in the R-admin manual.  Surely you did 
check there, so your comments surprise me.

First, look at config.log for any hints.
Second, check you can actually compile and run a simple Fortran program.

My guess is that your SunPro Fortran installation is incomplete, something 
we have seen a couple of times.  It is possible that you need to use
f95 to interwork with SunPro cc, and you do to use libsunperf, for 
example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Wed Nov 19 19:45:45 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 19 Nov 2003 13:45:45 -0500 (EST)
Subject: [R] ISOdate returns incorrect date?
Message-ID: <20031119184545.5959339D6@mprdmxin.myway.com>



Based on the discussion so far, the 1950 issue is due to the 
timezone and Prof. Riley has established that the 1900 issue
is a coding error in printing dates (but not in ISOdate, itself, 
or in the representation of POSIXct dates).

I assume that the 1900 was found by just playing around but if your
data actually does go that far back then note that neither of 
the above two issues will affect you if you use chron:

> require(chron)
> chron( paste(3,16,c(1900,1950),sep="/"), out.format="year-m-d")
[1] 1900-Mar-16 1950-Mar-16




--- 
Date: Wed, 19 Nov 2003 17:27:19 +0100 
From: Heiko Schaefer <heiko.schaefer at swissrisk.com>
To: <r-help at stat.math.ethz.ch> 
Subject: RE: [R] ISOdate returns incorrect date? 

 
 

It starts on the 1st of March 1900 to go wrong .... I feel better now
that somebody
Else these the same effect ;-)

-----Original Message-----
From: Simon Fear [mailto:Simon.Fear at synequanon.com] 
Sent: Mittwoch, 19. November 2003 17:17
To: ggrothendieck at myway.com; heiko.schaefer at swissrisk.com;
r-help at stat.math.ethz.ch
Subject: RE: [R] ISOdate returns incorrect date?


Well, I live only a few seconds away from GMT and I also get

> ISOdate(1900,6,16,tz="")
[1] "1900-06-15 12:00:00 GMT Daylight Time"

15th, not 16th.

Was 1900 a strange leap year? I certainly haven't tested thoroughly but
note this:

> ISOdate(1900,2,16,tz="")
[1] "1900-02-16 12:00:00 GMT Standard Time"
# 16th OK in February
> ISOdate(1900,3,16,tz="")
[1] "1900-03-15 12:00:00 GMT Standard Time"
# wrong for March

Using today's release of rw181beta (up to date or what?) 
on Win 98 (oh well).

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> Sent: 19 November 2003 16:06
> To: heiko.schaefer at swissrisk.com; r-help at stat.math.ethz.ch
> Subject: RE: [R] ISOdate returns incorrect date?
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
> 
> 
> 
> ISOdate works, by default, in the GMT timezone. Try:
> 
> ISOdate(1900,6,16,tz="")
> ISOdate(1950,6,16,tz="")
> 
> If you don't need timezones and don't want to worry about them you can

> alternately use the chron library for your dates and times.
> 
> ---
> Date: Wed, 19 Nov 2003 14:58:24 +0100
> From: Heiko Schaefer <heiko.schaefer at swissrisk.com>
> To: <r-help at stat.math.ethz.ch> 
> Subject: [R] ISOdate returns incorrect date? 
> 
> 
> 
> 
> Dear all,
> 
> I have found the following (for me) incomprehensible behaviour of 
> ISOdate (POSIXct):
> > ISOdate(1900,6,16)
> [1] "1900-06-15 14:00:00 Westeuropdische Sommerzeit"
> > ISOdate(1950,6,16)
> [1] "1950-06-16 14:00:00 Westeuropdische Sommerzeit"
> 
> Note that in the first case I get the 15th of June back, not
> the 16th as
> I would have expected!
> This happened under R-1.7.1 on both windows and linux.
> 
> I would greatly appreciate your comments,
> 
> Heiko
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 

Number of attachments included with this message: 0 

This message (and any associated files) is confidential and\...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Nov 19 19:51:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 18:51:42 +0000 (GMT)
Subject: [R] Windows R 1.8.0 hangs when Mem Usage >1.8GB
In-Reply-To: <Pine.LNX.4.43.0311191020160.27299@hymn11.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0311191849240.15425-100000@gannet.stats>

Could you compile up and try R-devel (see the FAQ)?  It probably will cope
with more than 2Gb, and I've run it up to 2.5Gb.

Note that an effective limit of 1.7Gb is mentioned in the rw-FAW.

On Wed, 19 Nov 2003, Dick Beyer wrote:

> I have a loop that increases the size of an object after each iteration.  
> When the Windows Task Manager shows "Mem Usage" about 1.8GB, the
> Rgui.exe process no longer responds.
> 
> I use:
> 
> "C:\Program Files\R\rw1080\bin\Rgui.exe" --max-mem-size=4000M
> --min-vsize=10M --max-vsize=3000M --min-nsize=500k --max-nsize=1000M
> 
> I have a dual Xeon 2.8GHz processor box with 4GB of memory and "R
> version 1.8.0, 2003-10-08".
> 
> Any suggestions or ideas would be greatly appreciated.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Wed Nov 19 20:01:09 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 13:01:09 -0600
Subject: [R] OT Sorta: Strouhal Numbers,
	Unladen Swallows and Monthy Python....
Message-ID: <1069268469.4563.493.camel@localhost.localdomain>

Greetings all,

Every now and then, as we engage in serious discourse, it seems
appropriate to throw something into the mix that might digress and
brighten the day.

So, what is a Strouhal Number?

"For an animal or insect in flight, the Strouhal number is determined by
the frequency (f) of wing strokes, multiplied by the amplitude (A) of
the wing, divided by the animal?s forward speed (U) through the air.

The Strouhal number is equal to f A/U"


Jonathan Corum (a graphic designer), has put forth an article on the
graphic representation of birds in flight using Strouhal numbers
(http://www.style.org/strouhalflight/). This is based upon some recently
published research in Nature:

Graham K. Taylor, Robert L. Nudds, Adrian L. R. Thomas
Flying and swimming animals cruise at a Strouhal number tuned for high
power efficiency
Nature 425, 707?711 (October 16, 2003)
http://www.nature.com/cgi-taf/DynaPage.taf?file=/nature/journal/v425/n6959/abs/nature02000_fs.html



Perhaps more importantly, Corum has attempted to address an "age old"
question raised in the famously funny film "Monty Python and the Holy
Grail". The question:

"What is the airspeed velocity of an unladen swallow?"

Hence, the article:

Estimating the Airspeed Velocity of an Unladen Swallow
http://www.style.org/unladenswallow/

For those who are Monty Python fans, enjoy...  :-)

Best regards,

Marc Schwartz

Sir Bedevere: How do know so much about swallows? 
King Arthur: Well, you have to know these things when you're a king, you
know.



From ripley at stats.ox.ac.uk  Wed Nov 19 20:23:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 19:23:16 +0000 (GMT)
Subject: [R] as.double( factor(something) )??
In-Reply-To: <20031119201255.61eea454.rjvbertin@despammed.com>
Message-ID: <Pine.LNX.4.44.0311191922030.15521-100000@gannet.stats>

It's in the FAQ, Q7.12.

On Wed, 19 Nov 2003, RenE J.V. Bertin wrote:

> After converting a numeric variable into a factor, is there a way to convert it back to the original values? as.double() doesn't do that correctly, for evident reasons (I guess) and as shown below.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Wed Nov 19 20:23:59 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 19 Nov 2003 14:23:59 -0500
Subject: [R] Windows R 1.8.0 hangs when Mem Usage >1.8GB
In-Reply-To: <Pine.LNX.4.43.0311191020160.27299@hymn11.u.washington.edu>
References: <200311191104.hAJB2uPd029703@hypatia.math.ethz.ch>
	<Pine.LNX.4.43.0311191020160.27299@hymn11.u.washington.edu>
Message-ID: <5egnrvgjnuj1e3tbhbp3mf0k03stkhd4dj@4ax.com>

On Wed, 19 Nov 2003 10:20:16 -0800 (PST), Dick Beyer
<dbeyer at u.washington.edu> wrote :

>I have a loop that increases the size of an object after each iteration.  When the Windows Task Manager shows "Mem Usage" about 1.8GB, the Rgui.exe process no longer responds.
>
>I use:
>
>"C:\Program Files\R\rw1080\bin\Rgui.exe" --max-mem-size=4000M --min-vsize=10M --max-vsize=3000M --min-nsize=500k --max-nsize=1000M
>
>I have a dual Xeon 2.8GHz processor box with 4GB of memory and "R version 1.8.0, 2003-10-08".
>
>Any suggestions or ideas would be greatly appreciated.

Normally the maximum memory allowed for any process in Windows is 2
GB.  It's possible to raise that to 3 GB but R 1.8 doesn't know how,
so that's an absolute upper limit.  Version 1.9 may be able to go up
to 3 GB, but beyond that you'll probably need a 64 bit processor:  as
far as I know all the 32 bit OS's limit each process to 2 or 3 GB,
because they reserve 1 or 2 GB for themselves.

I don't know why you're hitting the ceiling at 1.8 GB, but it may be
that there's unreported overhead.  I also don't know why it's not
failing gracefully.  

My only suggestion is to say "Don't do that".

Duncan Murdoch



From spencer.graves at pdf.com  Wed Nov 19 20:28:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 19 Nov 2003 11:28:02 -0800
Subject: [R] as.double( factor(something) )??
In-Reply-To: <20031119201255.61eea454.rjvbertin@despammed.com>
References: <20031119201255.61eea454.rjvbertin@despammed.com>
Message-ID: <3FBBC442.8080106@pdf.com>

      Have you considered the following: 

      > f <- factor(1:2)
      > as.numeric(as.character(f))
      [1] 1 2

      See Venables and Ripley (2000) S Programming (Springer, p. 15). 

      Is this what you want?  spencer graves

RenE J.V. Bertin wrote:

>Hello,
>
>After converting a numeric variable into a factor, is there a way to convert it back to the original values? as.double() doesn't do that correctly, for evident reasons (I guess) and as shown below.
>
>Thanks,
>RenE Bertin
>
>  
>
>>dd<-c( rep(0,10), rep(1,10) )
>>dd
>>    
>>
> [1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1
>  
>
>>as.double(dd)
>>    
>>
> [1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1
>  
>
>>dd<-factor(dd)
>>dd
>>    
>>
> [1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1
>Levels: 0 1
>  
>
>>as.double(dd)
>>    
>>
> [1] 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2
>  
>
>>dd<-c( rep(1,10), rep(0,10) )
>>as.double(dd)
>>    
>>
> [1] 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
>  
>
>>dd<-factor(dd)
>>dd
>>    
>>
> [1] 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
>Levels: 0 1
>  
>
>>as.double(dd)
>>    
>>
> [1] 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
>  
>
>>as.double(ordered(dd))
>>    
>>
> [1] 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
>  
>
>>dd<-c( rep(1,10), rep(0,10), rep(-2,10) )
>>dd
>>    
>>
> [1]  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2
>  
>
>>as.double(dd)
>>    
>>
> [1]  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2
>  
>
>>dd<-factor(dd)
>>dd
>>    
>>
> [1] 1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  -2 -2 -2 -2 -2 -2 -2 -2 -2 -2
>Levels: -2 0 1
>  
>
>>as.double(dd)
>>    
>>
> [1] 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From hi_ono2001 at ybb.ne.jp  Wed Nov 19 20:27:35 2003
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Thu, 20 Nov 2003 04:27:35 +0900
Subject: [R] R interface for Swarm, available?
Message-ID: <000e01c3aed3$2fcb2200$818001db@webgis>

Hello.

 Is there R interface for Swarm or other MAS(Multi Agent System) tools
available?

 Thanks.



From spencer.graves at pdf.com  Wed Nov 19 20:42:52 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 19 Nov 2003 11:42:52 -0800
Subject: [R] Windows R 1.8.0 hangs when Mem Usage >1.8GB
In-Reply-To: <5egnrvgjnuj1e3tbhbp3mf0k03stkhd4dj@4ax.com>
References: <200311191104.hAJB2uPd029703@hypatia.math.ethz.ch>	<Pine.LNX.4.43.0311191020160.27299@hymn11.u.washington.edu>
	<5egnrvgjnuj1e3tbhbp3mf0k03stkhd4dj@4ax.com>
Message-ID: <3FBBC7BC.6060802@pdf.com>

      S-Plus has a similar "feature".  I once had a simulation that ran 
for months.  I programmed the simulator to store intermediate results 
using "synchronize" and issue progress reports from which I could tell 
how fast it was running.  Every day or two, I would kill S-Plus and 
restart from the last "synchronize".  I don't know the equivalent in R. 

      Is it feasible to compute in advance how big the object will 
ultimately be and then break it up into appropriately sized chunks and 
do those separately? 

      hope this helps.  spencer graves

Duncan Murdoch wrote:

>On Wed, 19 Nov 2003 10:20:16 -0800 (PST), Dick Beyer
><dbeyer at u.washington.edu> wrote :
>
>  
>
>>I have a loop that increases the size of an object after each iteration.  When the Windows Task Manager shows "Mem Usage" about 1.8GB, the Rgui.exe process no longer responds.
>>
>>I use:
>>
>>"C:\Program Files\R\rw1080\bin\Rgui.exe" --max-mem-size=4000M --min-vsize=10M --max-vsize=3000M --min-nsize=500k --max-nsize=1000M
>>
>>I have a dual Xeon 2.8GHz processor box with 4GB of memory and "R version 1.8.0, 2003-10-08".
>>
>>Any suggestions or ideas would be greatly appreciated.
>>    
>>
>
>Normally the maximum memory allowed for any process in Windows is 2
>GB.  It's possible to raise that to 3 GB but R 1.8 doesn't know how,
>so that's an absolute upper limit.  Version 1.9 may be able to go up
>to 3 GB, but beyond that you'll probably need a 64 bit processor:  as
>far as I know all the 32 bit OS's limit each process to 2 or 3 GB,
>because they reserve 1 or 2 GB for themselves.
>
>I don't know why you're hitting the ceiling at 1.8 GB, but it may be
>that there's unreported overhead.  I also don't know why it's not
>failing gracefully.  
>
>My only suggestion is to say "Don't do that".
>
>Duncan Murdoch
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From vince.forgetta at staff.mcgill.ca  Wed Nov 19 20:59:54 2003
From: vince.forgetta at staff.mcgill.ca (Vince Forgetta)
Date: Wed, 19 Nov 2003 14:59:54 -0500
Subject: [R] maximum width for pdf device
Message-ID: <3FBBCBBA.4090607@staff.mcgill.ca>

Hi all,

What is (or how to I change) the maximum width of a pdf image. I am 
trying to make a pdf image:

pdf(file="out.pdf",width=200,height=20)

and I can't get the image to be more that 200 inches wide i.e. I get an 
empty out.pdf . Is there a solution around this.

Thanks.

Vince

-- 
+-----------------------------------------------------------+
|  Vincenzo Forgetta                                        |
|  Computational Biology                                    |
|  McGill University and Genome Quebec Innovation Centre    |
|  740 Dr. Penfield Avenue                                  |
|  Room 7211                                                |
|  Montreal, Quebec Canada, H3A 1A4                         |
|  Tel: 514-398-3311 00476                                  |
|  Email: vince.forgetta at staff.mcgill.ca                    |
+-----------------------------------------------------------+



From mcneney at cs.sfu.ca  Wed Nov 19 21:05:35 2003
From: mcneney at cs.sfu.ca (Brad Mcneney)
Date: Wed, 19 Nov 2003 15:05:35 -0500 (EST)
Subject: [R] multinom question
Message-ID: <Pine.OSF.4.21.0311191458400.277256-100000@smahlt.math.sfu.ca>

I'd like to fit a multinomial log-linear model for 4 categories of the
form

log[(P(D=i | X)/P(D=0 | X)] = alpha_i + X beta_i ;  i=1,2,3

but with beta_1 constrained to zero. Is there a way to impose such a
constraint in the multinom function?

Brad
-------------------------------------------------------------------------
Brad McNeney                               email: mcneney at stat.sfu.ca
Dept. of Statistics and Actuarial Sci.     web: www.stat.sfu.ca/~mcneney/
Simon Fraser University                    phone: 604.291.4815
8888 University Drive                      fax: 604.291.4368
Burnaby, British Columbia
Canada V5A 1S6



From tlumley at u.washington.edu  Wed Nov 19 21:40:50 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 19 Nov 2003 12:40:50 -0800 (PST)
Subject: [R] as.double( factor(something) )??
In-Reply-To: <3FBBC442.8080106@pdf.com>
References: <20031119201255.61eea454.rjvbertin@despammed.com>
	<3FBBC442.8080106@pdf.com>
Message-ID: <Pine.A41.4.58.0311191240050.49944@homer38.u.washington.edu>

On Wed, 19 Nov 2003, Spencer Graves wrote:

>       Have you considered the following:
>
>       > f <- factor(1:2)
>       > as.numeric(as.character(f))
>       [1] 1 2
>
>       See Venables and Ripley (2000) S Programming (Springer, p. 15).

Or see the FAQ, which makes the same point.

	-thomas



From ripley at stats.ox.ac.uk  Wed Nov 19 22:21:13 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Nov 2003 21:21:13 +0000 (GMT)
Subject: [R] maximum width for pdf device
In-Reply-To: <3FBBCBBA.4090607@staff.mcgill.ca>
Message-ID: <Pine.LNX.4.44.0311192114590.19219-100000@gannet.stats>


On Wed, 19 Nov 2003, Vince Forgetta wrote:

> What is (or how to I change) the maximum width of a pdf image. I am 
> trying to make a pdf image:
> 
> pdf(file="out.pdf",width=200,height=20)
> 
> and I can't get the image to be more that 200 inches wide i.e. I get an 
> empty out.pdf . Is there a solution around this.

There is no such limit, and I don't get an empty file.  Are you _sure_ the
limit is not in your own software, that is in e.g. acrobat?  It seems
acrobat does have a 200" width limit, but other viewers do work.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chzieg01 at athena.louisville.edu  Wed Nov 19 22:45:31 2003
From: chzieg01 at athena.louisville.edu (chzieg01)
Date: Wed, 19 Nov 2003 16:45:31 -0500
Subject: [R] Specifying arguements in user defined functions
Message-ID: <3FBC5034@webmail.louisville.edu>

Dear R subscribees,

First, I am new to R and I apologize if the question is naive.  I am trying to 
find out where arguments specifications
can be found.   For example, the code below (at the very bottom of
this email) contains the argument 'digits' in the function 'lin' which 
printout my output to the 3rd decimal place.  Somebody showed me the 
'digits' argument, but did not show me where to go to find other available 
arguments that can be used in functions. (I have emailed this person
but receive an email saying he is out of the office)

To elaborate further, if you look at some of my
code you can see where I specify in the cov(x,y,use="pairwise.complete.obs")
or var(x,use="pairwise.complete.obs"), etc.  Now for the arguments in the
'lin' function I would like to specify:

  lin <- function (x,y, digits=3, use="all.obs")

or something equivalent that will delete the case if I have NA in either
the x or y variable/vector.  (I get the 'use=all.obs' by just typing
'cov' at the R prompt and looking at the function body. I have tried various 
combination of the 'use=all.obs' along with what looks to be necessary code 
related to it such as "'na.method <- pmatch(use, c("all.obs", "complete.obs", 
"pairwise.complete.obs"))'
and .Internal(cov(x, y, na.method)")

My question is where did the 'use=all.obs' argument come from.  Is this 
basically a function/object/argument(???) that I, a R user, have access to or 
did the originator of this function create an object which is compiled within 
the cor/cov/var functions, etc? If so, how do I know what function arguments 
are available to me or which I have to create. If there are arguments 
available to me where do I find them?

I hope this makes sense and appreciate any help you can give me in sending
me on the right path to understand this.

Thanks,

Craig Ziegler

******************************************************************************
lin <- function (x,y, digits=3) # How did the person who knew about
                                # the digits argument know about
                                # this argument other than through
                                # experience
       {
       lincc <-
            (2 * cov(x,y,use="pairwise.complete.obs")) /
            (var(x,use="pairwise.complete.obs") +
            (var(y,use="pairwise.complete.obs"))+
       	  ((mean(x,na.rm=TRUE) - mean(y,na.rm=TRUE))^2))
  	 print(lincc)
         etc...

        }



From MSchwartz at medanalytics.com  Wed Nov 19 23:04:47 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 16:04:47 -0600
Subject: [R] maximum width for pdf device
In-Reply-To: <Pine.LNX.4.44.0311192114590.19219-100000@gannet.stats>
References: <Pine.LNX.4.44.0311192114590.19219-100000@gannet.stats>
Message-ID: <1069279487.4563.500.camel@localhost.localdomain>

On Wed, 2003-11-19 at 15:21, Prof Brian Ripley wrote:
> On Wed, 19 Nov 2003, Vince Forgetta wrote:
> 
> > What is (or how to I change) the maximum width of a pdf image. I am 
> > trying to make a pdf image:
> > 
> > pdf(file="out.pdf",width=200,height=20)
> > 
> > and I can't get the image to be more that 200 inches wide i.e. I get
> an 
> > empty out.pdf . Is there a solution around this.
> 
> There is no such limit, and I don't get an empty file.  Are you _sure_
> the
> limit is not in your own software, that is in e.g. acrobat?  It seems
> acrobat does have a 200" width limit, but other viewers do work.


One quick follow up thought.

Are you remembering to call dev.off() after your plot?  If you don't,
depending upon the nature of your plot, the pdf file will be empty since
the graphic content will not be flushed to the file until the device is
closed.

Try this:

pdf(file="out.pdf", width = 200, height = 20)
barplot(1:10)
dev.off()

and then look at the file.

I can view that file just fine with Acrobat 5 under Fedora Core 1 as
well as the other pdf viewers.

HTH,

Marc Schwartz



From vince.forgetta at staff.mcgill.ca  Wed Nov 19 23:13:10 2003
From: vince.forgetta at staff.mcgill.ca (Vince Forgetta)
Date: Wed, 19 Nov 2003 17:13:10 -0500
Subject: [R] maximum width for pdf device
In-Reply-To: <1069279487.4563.500.camel@localhost.localdomain>
References: <Pine.LNX.4.44.0311192114590.19219-100000@gannet.stats>
	<1069279487.4563.500.camel@localhost.localdomain>
Message-ID: <3FBBEAF6.3090904@staff.mcgill.ca>

I used dev.off(). I am certain that the problem is associated with 
acrobat reader. Seeing that my collaborators use primarily acrobat 
reader it looks like I'm stuck with this limit. Thanks for the help.


Vince

Marc Schwartz wrote:

>On Wed, 2003-11-19 at 15:21, Prof Brian Ripley wrote:
>  
>
>>On Wed, 19 Nov 2003, Vince Forgetta wrote:
>>
>>    
>>
>>>What is (or how to I change) the maximum width of a pdf image. I am 
>>>trying to make a pdf image:
>>>
>>>pdf(file="out.pdf",width=200,height=20)
>>>
>>>and I can't get the image to be more that 200 inches wide i.e. I get
>>>      
>>>
>>an 
>>    
>>
>>>empty out.pdf . Is there a solution around this.
>>>      
>>>
>>There is no such limit, and I don't get an empty file.  Are you _sure_
>>the
>>limit is not in your own software, that is in e.g. acrobat?  It seems
>>acrobat does have a 200" width limit, but other viewers do work.
>>    
>>
>
>
>One quick follow up thought.
>
>Are you remembering to call dev.off() after your plot?  If you don't,
>depending upon the nature of your plot, the pdf file will be empty since
>the graphic content will not be flushed to the file until the device is
>closed.
>
>Try this:
>
>pdf(file="out.pdf", width = 200, height = 20)
>barplot(1:10)
>dev.off()
>
>and then look at the file.
>
>I can view that file just fine with Acrobat 5 under Fedora Core 1 as
>well as the other pdf viewers.
>
>HTH,
>
>Marc Schwartz
>
>
>
>  
>


-- 
+-----------------------------------------------------------+
|  Vincenzo Forgetta                                        |
|  Computational Biology                                    |
|  McGill University and Genome Quebec Innovation Centre    |
|  740 Dr. Penfield Avenue                                  |
|  Room 7211                                                |
|  Montreal, Quebec Canada, H3A 1A4                         |
|  Tel: 514-398-3311 00476                                  |
|  Email: vince.forgetta at staff.mcgill.ca                    |
+-----------------------------------------------------------+



From p.connolly at hortresearch.co.nz  Wed Nov 19 23:21:56 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 20 Nov 2003 11:21:56 +1300
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <x2ekw4b93m.fsf@biostat.ku.dk>
References: <002d01c3aeb9$22c5b170$b600000a@HEIKO>
	<x2ekw4b93m.fsf@biostat.ku.dk>
Message-ID: <20031119222156.GZ8384@hortresearch.co.nz>

On Wed, 19-Nov-2003 at 05:45PM +0100, Peter Dalgaard wrote:


|> Yes, something is strange for me too (RedHat 8):
|> 
|> > ISOdate(1900,3,1)
|> [1] "1900-03-01 13:00:00 CET"
|> > ISOdate(1900,3,2)
|> [1] "1900-03-01 13:00:00 CET"
|> 
|> Apparently, the one-day shift affects all dates after March 2, 1900,
|> and in no other year. One easily gets the suspicion that the fact that
|> 1900 was *not* a leap year has something to do with it. However,
|> strptime() which this calls indirectly is only as good as its OS-level
|> counterpart, I believe. 

Using RedHat 7.3, the OS seems to know about leap years

$ cal 2 1900
    February 1900
Su Mo Tu We Th Fr Sa 
             1  2  3
 4  5  6  7  8  9 10
11 12 13 14 15 16 17
18 19 20 21 22 23 24
25 26 27 28


Yet, as Peter says, it gets dates after ISOdate(1900,3,1) wrong for
that year (assuming there really was daylight saving then).

> ISOdate(1900,2,28)
[1] "1900-03-01 01:00:00 NZDT"
> ISOdate(1900,3,1)
[1] "1900-03-02 01:00:00 NZDT"
> ISOdate(1900,3,2)
[1] "1900-03-02 01:00:00 NZDT"
> ISOdate(1900,3,3)
[1] "1900-03-03 01:00:00 NZDT"

but all of the next year is correct.

What cal uses at shell level in the OS evidently isn't the same as
what is being used to print ISOdate output.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From jc at or.psychology.dal.ca  Wed Nov 19 23:34:13 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Wed, 19 Nov 2003 18:34:13 -0400
Subject: [R] anova(mylme, type = ??)
Message-ID: <8064164E-1AE0-11D8-953E-000A956DE534@or.psychology.dal.ca>

OK, I found pretty much everything I needed in the short term on lme.  
However, I cannot find anything on the "type" flag in the anova 
command.  When is it used and what for?  In the examples I have found 
type="marginal" is usually entered for lme models with fixed effects.

This is one of the few items that I have done an entire R site search 
for without anything but other examples of this question - unanswered.

It is odd that there is no documentation for a value you can pass to 
one of the commands.



From bates at stat.wisc.edu  Wed Nov 19 23:47:58 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 19 Nov 2003 16:47:58 -0600
Subject: [R] anova(mylme, type = ??)
In-Reply-To: <8064164E-1AE0-11D8-953E-000A956DE534@or.psychology.dal.ca>
References: <8064164E-1AE0-11D8-953E-000A956DE534@or.psychology.dal.ca>
Message-ID: <6rad6sj7q9.fsf@bates4.stat.wisc.edu>

John Christie <jc at or.psychology.dal.ca> writes:

> OK, I found pretty much everything I needed in the short term on lme.
> However, I cannot find anything on the "type" flag in the anova
> command.  When is it used and what for?  In the examples I have found
> type="marginal" is usually entered for lme models with fixed effects.
> 
> 
> This is one of the few items that I have done an entire R site search
> for without anything but other examples of this question - unanswered.
> 
> 
> It is odd that there is no documentation for a value you can pass to
> one of the commands.

Umm - there is documentation for type.  Check

?anova.lme



From MSchwartz at medanalytics.com  Wed Nov 19 23:54:18 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 16:54:18 -0600
Subject: [R] anova(mylme, type = ??)
In-Reply-To: <8064164E-1AE0-11D8-953E-000A956DE534@or.psychology.dal.ca>
References: <8064164E-1AE0-11D8-953E-000A956DE534@or.psychology.dal.ca>
Message-ID: <1069282458.4563.514.camel@localhost.localdomain>

On Wed, 2003-11-19 at 16:34, John Christie wrote:
> OK, I found pretty much everything I needed in the short term on lme.  
> However, I cannot find anything on the "type" flag in the anova 
> command.  When is it used and what for?  In the examples I have found 
> type="marginal" is usually entered for lme models with fixed effects.
> 
> This is one of the few items that I have done an entire R site search 
> for without anything but other examples of this question - unanswered.
> 
> It is odd that there is no documentation for a value you can pass to 
> one of the commands.


Try:

?anova.lme

presuming that you have already done library(nlme).

Keep in mind that anova() is a "high level" function that has several
methods based upon the nature of the object passed to it. To see what
methods are available use:

methods(anova)

If you do that prior to library(nlme), you get:

> methods(anova)
[1] anova.glm     anova.glmlist anova.lm      anova.loess*
[5] anova.loglm*  anova.mlm     anova.negbin* anova.nls*

    Non-visible functions are asterisked


If you do it after library(nlme), you get:

> methods(anova)
 [1] anova.glm     anova.glmlist anova.gls*    anova.lm
 [5] anova.lme     anova.lme1*   anova.loess*  anova.loglm*
 [9] anova.mlm     anova.negbin* anova.nls*
 
    Non-visible functions are asterisked


The above reflects the additional anova methods provided in the nlme
package.

In your case, you are passing an nlme model object to anova, hence the
anova.nlme method is used. The details for the arguments will be listed
in the method specific help.

HTH,

Marc Schwartz



From MSchwartz at medanalytics.com  Wed Nov 19 23:59:58 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 16:59:58 -0600
Subject: [R] anova(mylme, type = ??)
In-Reply-To: <1069282458.4563.514.camel@localhost.localdomain>
References: <8064164E-1AE0-11D8-953E-000A956DE534@or.psychology.dal.ca>
	<1069282458.4563.514.camel@localhost.localdomain>
Message-ID: <1069282798.4563.517.camel@localhost.localdomain>

On Wed, 2003-11-19 at 16:54, Marc Schwartz wrote:

> In your case, you are passing an nlme model object to anova, hence the
> anova.nlme method is used. The details for the arguments will be listed
> in the method specific help.


Quick correction, in both cases above it should be 'lme' not 'nlme'.

Too fast on the send key...sorry.

Marc



From p.connolly at hortresearch.co.nz  Thu Nov 20 00:21:46 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 20 Nov 2003 12:21:46 +1300
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <Pine.LNX.4.44.0311191700380.14951-100000@gannet.stats>
References: <Pine.LNX.4.44.0311191629150.14832-100000@gannet.stats>
	<Pine.LNX.4.44.0311191700380.14951-100000@gannet.stats>
Message-ID: <20031119232146.GA8384@hortresearch.co.nz>

On Wed, 19-Nov-2003 at 05:03PM +0000, Prof Brian Ripley wrote:

|> For the record, ISOdate *is* giving the right answer, a POSIXct object.
|> 
|> The problem is in printing, where there was a simple coding bug: is_year 
|> was applied to the POSIX `year' which is year-1900.

I can't see why it doesn't effect dates before 2nd March.



-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From p.dalgaard at biostat.ku.dk  Thu Nov 20 01:45:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Nov 2003 01:45:52 +0100
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <20031119232146.GA8384@hortresearch.co.nz>
References: <Pine.LNX.4.44.0311191629150.14832-100000@gannet.stats>
	<Pine.LNX.4.44.0311191700380.14951-100000@gannet.stats>
	<20031119232146.GA8384@hortresearch.co.nz>
Message-ID: <x2brr7j29r.fsf@biostat.ku.dk>

Patrick Connolly <p.connolly at hortresearch.co.nz> writes:

> On Wed, 19-Nov-2003 at 05:03PM +0000, Prof Brian Ripley wrote:
> 
> |> For the record, ISOdate *is* giving the right answer, a POSIXct object.
> |> 
> |> The problem is in printing, where there was a simple coding bug: is_year 
> |> was applied to the POSIX `year' which is year-1900.
> 
> I can't see why it doesn't effect dates before 2nd March.

Well, it's an open source program....

2nd March is day 60 and the code works out month and day by
subtracting monts as long as the result is positive. If the code
thinks that there are 29 days in February, then 2nd March becomes the
1st, etc.

The thing that puzzles me is that the old code didn't also claim that
there was a Feb 29 in 1900, and that there wasn't a corresponding issue
with the year 2000 being a leap year by the %%400 rule. But there
wasn't and there still isn't...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From glaziou at pasteur-kh.org  Thu Nov 20 01:44:52 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Thu, 20 Nov 2003 07:44:52 +0700
Subject: [R] question
In-Reply-To: <x2k75wbbqg.fsf@biostat.ku.dk>
References: <1069234359.3fbb38b77ea8a@webmail.uji.es>
	<20031119101859.GF16984@pasteur-kh.org>
	<x2y8ucbnqo.fsf@biostat.ku.dk>
	<20031119122055.GA16232@pasteur-kh.org>
	<x2k75wbbqg.fsf@biostat.ku.dk>
Message-ID: <20031120004452.GD16232@pasteur-kh.org>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> blueberry:~/> sed -e 's/pattern 1\|pattern 2\|pattern xyz//g' < tst.txt
> 2.22 3.45
> 1.56 2.31
> 
> 4.67 7.91
> 3.34 2.15
> 5.32 3.88
> 
> blueberry:~/> awk '/pattern 1/{copy=1;next};/pattern 2/{copy=0};copy==1' < tst.txt
> 4.67 7.91
> 3.34 2.15
> 5.32 3.88
> blueberry:~/> perl -ne 'if(/pattern 1/){$copy=1;next;} if(/pattern 2/){$copy=0;}print if $copy' < tst.txt
> 4.67 7.91
> 3.34 2.15
> 5.32 3.88




I see and here is my (corrected) sed solution:

cunegonde:~/tmp> cat test
2.22 3.45
1.56 2.31
pattern 1
4.67 7.91
3.34 2.15
5.32 3.88
pattern 2

cunegonde:~/tmp> sed -e '/pattern 1\|pattern 2/D' <test
2.22 3.45
1.56 2.31
4.67 7.91
3.34 2.15
5.32 3.88

-- 
Philippe



From glaziou at pasteur-kh.org  Thu Nov 20 02:11:38 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Thu, 20 Nov 2003 08:11:38 +0700
Subject: [R] question
In-Reply-To: <20031120004452.GD16232@pasteur-kh.org>
References: <1069234359.3fbb38b77ea8a@webmail.uji.es>
	<20031119101859.GF16984@pasteur-kh.org>
	<x2y8ucbnqo.fsf@biostat.ku.dk>
	<20031119122055.GA16232@pasteur-kh.org>
	<x2k75wbbqg.fsf@biostat.ku.dk>
	<20031120004452.GD16232@pasteur-kh.org>
Message-ID: <20031120011138.GG16232@pasteur-kh.org>

Philippe Glaziou <glaziou at pasteur-kh.org> wrote:
> I see and here is my (corrected) sed solution:
> 
> cunegonde:~/tmp> cat test
> 2.22 3.45
> 1.56 2.31
> pattern 1
> 4.67 7.91
> 3.34 2.15
> 5.32 3.88
> pattern 2
> 
> cunegonde:~/tmp> sed -e '/pattern 1\|pattern 2/D' <test
> 2.22 3.45
> 1.56 2.31
> 4.67 7.91
> 3.34 2.15
> 5.32 3.88


Ray Brownrigg rightly pointed out my mistake: we want the lines
between the patterns not just to remove the patterns. I pulled
the trigger too fast.

cunegonde:~/tmp> sed -e '/pattern 1/,/pattern 2/!D;/pattern 1\|pattern 2/D' <test
4.67 7.91
3.34 2.15
5.32 3.88


I feel embarrassed now. 

-- 
Philippe



From krcabrer at epm.net.co  Thu Nov 20 03:27:26 2003
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Wed, 19 Nov 2003 21:27:26 -0500
Subject: [R] file not found?
Message-ID: <3FBC268E.3040804@epm.net.co>

Hi R maintainers:

when I use
 update.packages()

And I try to update the package "maps"

maps :
 Version 2.0-9 in D:/rw1080/library
 Version 2.0-10 on CRAN
Update (y/N)?  y

The following message appears:

trying URL 
`http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
Error in download.file(url, destfile, method, mode = "wb") :
        cannot open URL 
`http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
In addition: Warning message:
cannot open: HTTP status was `404 Not Found'

All the rest of packages work fine.

I use R 1.8.0 on W2K platform.

Thank you for your help

Kenneth

-- 
Kenneth Roy Cabrera Torres
Celular +57 (315) 405 9339



From tblackw at umich.edu  Thu Nov 20 03:22:42 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 19 Nov 2003 21:22:42 -0500 (EST)
Subject: [R] file not found?
In-Reply-To: <3FBC268E.3040804@epm.net.co>
References: <3FBC268E.3040804@epm.net.co>
Message-ID: <Pine.SOL.4.58.0311192118450.21550@zektor.gpcc.itd.umich.edu>

Kenneth  -

I recall a message on the [r-pkgs] list from Ray Brownrigg
on November 1 this year that may be relevant.  At that time
he was announcing the availability of  maps_2.0-8.zip  and
some other packages.

Therefore,  2.0-10 must be *very* recent and might still be
going through the CRAN propagation process.  (I don't know
anything about whther it is or not.)  I would wait a couple
of days and try again, if I were you.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 19 Nov 2003, Kenneth Cabrera wrote:

> Hi R maintainers:
>
> when I use
>  update.packages()
>
> And I try to update the package "maps"
>
> maps :
>  Version 2.0-9 in D:/rw1080/library
>  Version 2.0-10 on CRAN
> Update (y/N)?  y
>
> The following message appears:
>
> trying URL
> `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> Error in download.file(url, destfile, method, mode = "wb") :
>         cannot open URL
> `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> In addition: Warning message:
> cannot open: HTTP status was `404 Not Found'
>
> All the rest of packages work fine.
>
> I use R 1.8.0 on W2K platform.
>
> Thank you for your help
>
> Kenneth
>
> --
> Kenneth Roy Cabrera Torres
> Celular +57 (315) 405 9339
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From MSchwartz at medanalytics.com  Thu Nov 20 03:27:54 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Nov 2003 20:27:54 -0600
Subject: [R] file not found?
In-Reply-To: <3FBC268E.3040804@epm.net.co>
References: <3FBC268E.3040804@epm.net.co>
Message-ID: <1069295274.4563.40.camel@localhost.localdomain>

On Wed, 2003-11-19 at 20:27, Kenneth Cabrera wrote:
> Hi R maintainers:
> 
> when I use
>  update.packages()
> 
> And I try to update the package "maps"
> 
> maps :
>  Version 2.0-9 in D:/rw1080/library
>  Version 2.0-10 on CRAN
> Update (y/N)?  y
> 
> The following message appears:
> 
> trying URL 
> `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> Error in download.file(url, destfile, method, mode = "wb") :
>         cannot open URL 
> `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> In addition: Warning message:
> cannot open: HTTP status was `404 Not Found'
> 
> All the rest of packages work fine.
> 
> I use R 1.8.0 on W2K platform.
> 
> Thank you for your help
> 
> Kenneth


You might want to read through:

http://cran.r-project.org/bin/windows/contrib/1.8/

Version 2.0-10 was just posted to CRAN on 2003-11-13. It is possible
that the process to generate the Windows zip file has not yet completed
or there is a problem with the package not passing Rcmd check.

Hence the R 1.8.0 Windows version of the file is not yet on the site,
which is why you are getting the error. 

The new version is on CRAN for R 1.7.x dated 14-Nov-2003, thus it may be
that there is an issue with the package under 1.8.0. that requires
resolution by the package maintainer.

HTH,

Marc Schwartz



From Duncan.Mackay at flinders.edu.au  Thu Nov 20 03:34:52 2003
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Thu, 20 Nov 2003 13:04:52 +1030
Subject: [R] Hidden Rhistory files
Message-ID: <000001c3af0e$e0488d80$92e66081@duncanlt>

Hi all,
I've ecountered a problem in the last few days with my .Rhistory file
not being able to be updated when I quit an R session because its file
attributes under Windows have been set as "Hidden". Recently, I put the
following line in my global Rprofile file:-

history(max.show=Inf)

so that I automatically open the entire history file for a project when
I begin a session, but I don't see why that would cause a problem.

This problem has arisen several times in the last few days while working
on different Rdata files in different folders. When I manually uncheck
the "hidden" attribute of my Rhistory file, the problem goes away. But
why did the files get that attribute in the first place? Is this
something that R itself may have done? I'm running R Version 1.8.0
(2003-10-08) under WinXP.
Cheers, Duncan


*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html



From ray at mcs.vuw.ac.nz  Thu Nov 20 03:42:39 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 20 Nov 2003 15:42:39 +1300 (NZDT)
Subject: [R] file not found?
Message-ID: <200311200242.hAK2gdhW027928@tahi.mcs.vuw.ac.nz>

Thomas W Blackwell <tblackw at umich.edu> wrote:

> I recall a message on the [r-pkgs] list from Ray Brownrigg
> on November 1 this year that may be relevant.  At that time
> he was announcing the availability of  maps_2.0-8.zip  and
> some other packages.
> 
> Therefore,  2.0-10 must be *very* recent and might still be
> going through the CRAN propagation process.  (I don't know
> anything about whther it is or not.)  I would wait a couple
> of days and try again, if I were you.
> 
Well, actually, 2.0-10 in source form is on CRAN since last week, but
for some reason only in the 1.7/ directory in the Windows area.  I just
this morning noticed this and sent a message to the Windows CRAN
maintainer.

In the meantime, 2.0-11 has been uploaded, probably to appear in a few
days (no noticeable changes).

Ray Brownrigg



From dbeyer at u.washington.edu  Thu Nov 20 04:21:27 2003
From: dbeyer at u.washington.edu (Dick Beyer)
Date: Wed, 19 Nov 2003 19:21:27 -0800 (PST)
Subject: [R] Windows R 1.8.0 hangs when Mem Usage >1.8GB
In-Reply-To: <Pine.LNX.4.44.0311191849240.15425-100000@gannet.stats>
Message-ID: <Pine.LNX.4.43.0311191921270.25980@hymn01.u.washington.edu>

Thanks to all those with helpful suggestions about my hitting the upper memory limit.  I do appreciate the help.

Thanks,
Dick
*******************************************************************************
Richard P. Beyer, Ph.D.	University of Washington
Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
			Seattle, WA 98105-6099
*******************************************************************************










On Wed, 19 Nov 2003, Prof Brian Ripley wrote:

> Could you compile up and try R-devel (see the FAQ)?  It probably will cope
> with more than 2Gb, and I've run it up to 2.5Gb.
> 
> Note that an effective limit of 1.7Gb is mentioned in the rw-FAW.
> 
> On Wed, 19 Nov 2003, Dick Beyer wrote:
> 
> > I have a loop that increases the size of an object after each iteration.  
> > When the Windows Task Manager shows "Mem Usage" about 1.8GB, the
> > Rgui.exe process no longer responds.
> > 
> > I use:
> > 
> > "C:\Program Files\R\rw1080\bin\Rgui.exe" --max-mem-size=4000M
> > --min-vsize=10M --max-vsize=3000M --min-nsize=500k --max-nsize=1000M
> > 
> > I have a dual Xeon 2.8GHz processor box with 4GB of memory and "R
> > version 1.8.0, 2003-10-08".
> > 
> > Any suggestions or ideas would be greatly appreciated.
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>



From ggrothendieck at myway.com  Thu Nov 20 04:44:53 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 19 Nov 2003 22:44:53 -0500 (EST)
Subject: [R] Specifying arguements in user defined functions
Message-ID: <20031120034453.5EF6939BC@mprdmxin.myway.com>



The list of arguments to a function and the default values,
if any, are given in online help:

?cov

You can also display the arguments and their defaults like this:

args(cov)

If you write your own function then there are no predefined
arguments.  If you chose to use digits as an argument its up
to you but neither it nor any other argument has any meaning
other than what you give to it in the body of your function.

To write your own functions, read the chapter on writing 
your own functions in Introduction to R, available at:

  http://www.r-project.org > Manuals > Introduction to R 

--- 
Date: Wed, 19 Nov 2003 16:45:31 -0500 
From: chzieg01 <chzieg01 at athena.louisville.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Specifying arguements in user defined functions 

 
 
Dear R subscribees,

First, I am new to R and I apologize if the question is naive. I am trying to 
find out where arguments specifications
can be found. For example, the code below (at the very bottom of
this email) contains the argument 'digits' in the function 'lin' which 
printout my output to the 3rd decimal place. Somebody showed me the 
'digits' argument, but did not show me where to go to find other available 
arguments that can be used in functions. (I have emailed this person
but receive an email saying he is out of the office)

To elaborate further, if you look at some of my
code you can see where I specify in the cov(x,y,use="pairwise.complete.obs")
or var(x,use="pairwise.complete.obs"), etc. Now for the arguments in the
'lin' function I would like to specify:

lin <- function (x,y, digits=3, use="all.obs")

or something equivalent that will delete the case if I have NA in either
the x or y variable/vector. (I get the 'use=all.obs' by just typing
'cov' at the R prompt and looking at the function body. I have tried various 
combination of the 'use=all.obs' along with what looks to be necessary code 
related to it such as "'na.method <- pmatch(use, c("all.obs", "complete.obs", 
"pairwise.complete.obs"))'
and .Internal(cov(x, y, na.method)")

My question is where did the 'use=all.obs' argument come from. Is this 
basically a function/object/argument(???) that I, a R user, have access to or 
did the originator of this function create an object which is compiled within 
the cor/cov/var functions, etc? If so, how do I know what function arguments 
are available to me or which I have to create. If there are arguments 
available to me where do I find them?

I hope this makes sense and appreciate any help you can give me in sending
me on the right path to understand this.

Thanks,

Craig Ziegler

******************************************************************************
lin <- function (x,y, digits=3) # How did the person who knew about
# the digits argument know about
# this argument other than through
# experience
{
lincc <-
(2 * cov(x,y,use="pairwise.complete.obs")) /
(var(x,use="pairwise.complete.obs") +
(var(y,use="pairwise.complete.obs"))+
      ((mean(x,na.rm=TRUE) - mean(y,na.rm=TRUE))^2))
      print(lincc)
etc...

}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From nirmalg at psu.edu  Thu Nov 20 05:49:27 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Wed, 19 Nov 2003 23:49:27 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <5.1.0.14.2.20031119095000.01fc92f0@127.0.0.1>
References: <5.1.0.14.2.20031119085414.01fd9440@127.0.0.1>
	<5.1.0.14.2.20031119085414.01fd9440@127.0.0.1>
	<5.1.0.14.2.20031119095000.01fc92f0@127.0.0.1>
Message-ID: <3FBC47D7.4000807@psu.edu>

Thanks for your reply John.

> this works). Applied to a linear-model object, summary() produces 
> coefficients, etc. (as mentioned), while anova() produces a (sequential) 
> ANOVA table. This seems apparent to me from the output.

What I'm having trouble with is understanding the difference between 
aov() and lm() [since it seems like if I do a summary() after fitting 
using aov(), the output is the same as doing anova() after an lm()]. 
Now, the outputs from aov() and lm() are different - the siginificant 
effects are different. I think this may have to do with how these 
functions treat the data - i.e.  whether the function considers the data 
as being in coded or uncoded units. Is this correct? From what I could 
tell, aov() will code the data automatically and then present the ANOVA 
table whereas lm() does not code the data. This pretty much explains 
everything so far..

There's one problem though - how do I get the coefficients that are 
calculated from the data after they are coded by aov()? The problem here 
is that my factor levels are 0 and 1 instead of the usual -1 and 1... 
if I run coefficients() after a aov() fit or an lm() fit, I get the same 
coefficients... these coeffs. don't seem right (I compared with the 
coefficients from Minitab and JMP -both give coefficients after coding 
the data into a -1, 1 form).. I could of course modify my data and 
change all the 0 levels to -1 but is there a way in R to get 
coefficients that correspond to coded data?

> More generally, it probably makes sense to read introductory material 
> about R -- such as the introductory manual that comes with the software 

Yes, I have read some of these (and maybe I should read more :-))... 
thanks for the pointer.. on the same note, is there any reference that 
talks about how lm() and aov() treat data - coded vs. uncoded etc...

Thanks a lot for the help.. it is greatly appreciated!
nirmal



From rajiv.prasad at charter.net  Thu Nov 20 06:08:28 2003
From: rajiv.prasad at charter.net (Rajiv Prasad)
Date: Wed, 19 Nov 2003 21:08:28 -0800
Subject: [R] maps package for Windows
Message-ID: <005101c3af24$5bf2d430$6401a8c0@Jeeves2>

Hi folks:

maps seems not to be available for download from
http://cran.us.r-project.org/bin/windows/contrib/1.8/.  The status page
(http://cran.us.r-project.org/bin/windows/contrib/1.8/Status dated Nov 16,
2003) says though that it is "OK".  Any idea when it may be available?

Thanks.

Rajiv



From hi_ono2001 at ybb.ne.jp  Thu Nov 20 06:28:40 2003
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Thu, 20 Nov 2003 14:28:40 +0900
Subject: [R] maps package for Windows
References: <005101c3af24$5bf2d430$6401a8c0@Jeeves2>
Message-ID: <003f01c3af27$280a87f0$818001db@webgis>

Hi.

 I could download maps package via "Install Package(s) From CRAN" on RGui.

> maps seems not to be available for download from
> http://cran.us.r-project.org/bin/windows/contrib/1.8/.  The status page
> (http://cran.us.r-project.org/bin/windows/contrib/1.8/Status dated Nov 16,
> 2003) says though that it is "OK".  Any idea when it may be available?
>



From rajiv.prasad at charter.net  Thu Nov 20 07:17:59 2003
From: rajiv.prasad at charter.net (Rajiv Prasad)
Date: Wed, 19 Nov 2003 22:17:59 -0800
Subject: [R] maps package for Windows
References: <005101c3af24$5bf2d430$6401a8c0@Jeeves2>
	<003f01c3af27$280a87f0$818001db@webgis>
Message-ID: <005901c3af2e$0c273b80$6401a8c0@Jeeves2>

Umm... no, does not work for me yet:

> local({a <- CRAN.packages()
+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)})
trying URL `http://cran.r-project.org/bin/windows/contrib/1.8/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 13514 bytes
opened URL
downloaded 13Kb

trying URL
`http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
Error in download.file(url, destfile, method, mode = "wb") :
        cannot open URL
`http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
In addition: Warning message:
cannot open: HTTP status was `404 Not Found'
>

Is it just an issue of the file not haveing reached all mirrors yet?

Thanks.

Rajiv


----- Original Message ----- 
From: "Hisaji Ono" <hi_ono2001 at ybb.ne.jp>
To: "Rajiv Prasad" <rajiv.prasad at charter.net>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, November 19, 2003 9:28 PM
Subject: Re: [R] maps package for Windows


> Hi.
>
>  I could download maps package via "Install Package(s) From CRAN" on RGui.
>
> > maps seems not to be available for download from
> > http://cran.us.r-project.org/bin/windows/contrib/1.8/.  The status page
> > (http://cran.us.r-project.org/bin/windows/contrib/1.8/Status dated Nov
16,
> > 2003) says though that it is "OK".  Any idea when it may be available?
> >
>



From ripley at stats.ox.ac.uk  Thu Nov 20 07:58:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 06:58:31 +0000 (GMT)
Subject: [R] ISOdate returns incorrect date?
In-Reply-To: <x2brr7j29r.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0311200656590.19899-100000@gannet.stats>

On 20 Nov 2003, Peter Dalgaard wrote:

> Patrick Connolly <p.connolly at hortresearch.co.nz> writes:
> 
> > On Wed, 19-Nov-2003 at 05:03PM +0000, Prof Brian Ripley wrote:
> > 
> > |> For the record, ISOdate *is* giving the right answer, a POSIXct object.
> > |> 
> > |> The problem is in printing, where there was a simple coding bug: is_year 
> > |> was applied to the POSIX `year' which is year-1900.
> > 
> > I can't see why it doesn't effect dates before 2nd March.
> 
> Well, it's an open source program....
> 
> 2nd March is day 60 and the code works out month and day by
> subtracting monts as long as the result is positive. If the code
> thinks that there are 29 days in February, then 2nd March becomes the
> 1st, etc.
> 
> The thing that puzzles me is that the old code didn't also claim that
> there was a Feb 29 in 1900, and that there wasn't a corresponding issue
> with the year 2000 being a leap year by the %%400 rule. But there
> wasn't and there still isn't...

2000 is in the range your OS knows about: it only affected dates out of 
range of the OS's knowledge where some substitute code was used.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From forkusam at yahoo.com  Thu Nov 20 08:11:27 2003
From: forkusam at yahoo.com (forkusam)
Date: Wed, 19 Nov 2003 23:11:27 -0800 (PST)
Subject: [R] read.table(..)..Help?
Message-ID: <20031120071127.25215.qmail@web10503.mail.yahoo.com>

 Hallo,
 can someone please help me.
 I have a proplem reading a file with more that one
rows.
e.g I used the function:
p<-read.table(file="FILENAME ", header=TRUE,sep=";")
and later used the data.Frame() function. 
It functions when the file has only a row of
variables.
When I insert the second row I get an error message.
 How do I do this

=====
=====================
Sylvie B. Forkusam
Eppelheimer Str.52/A2-5-2
69115 Heidelberg, Germany
Tel: (0049)-06221/346913
Mobile: 0179-6816276
=======================

__________________________________

Free Pop-Up Blocker - Get it now



From kwan022 at stat.auckland.ac.nz  Thu Nov 20 08:28:01 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 20 Nov 2003 20:28:01 +1300 (NZDT)
Subject: [R] read.table(..)..Help?
In-Reply-To: <20031120071127.25215.qmail@web10503.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311202026110.15899-100000@stat55.stat.auckland.ac.nz>

On Wed, 19 Nov 2003, forkusam wrote:

>  Hallo,
>  can someone please help me.
>  I have a proplem reading a file with more that one
> rows.
> e.g I used the function:
> p<-read.table(file="FILENAME ", header=TRUE,sep=";")
> and later used the data.Frame() function. 
> It functions when the file has only a row of
> variables.
> When I insert the second row I get an error message.
>  How do I do this

1) Have you read through the documentations?

2) Are you sure each field is separated by a semi-colon ";"?

3) Exactly what the error messages are?  It is kind of difficult to 
diagnose your problem without knowing the error messages!

-- 
Cheers,

Kevin

---------------------------------------------------------------
"Try not.  Do, do!  Or do not.  There is no try"
   Jedi Master Yoda

----
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From ripley at stats.ox.ac.uk  Thu Nov 20 08:31:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 07:31:49 +0000 (GMT)
Subject: [R] Hidden Rhistory files
In-Reply-To: <000001c3af0e$e0488d80$92e66081@duncanlt>
Message-ID: <Pine.LNX.4.44.0311200727310.19899-100000@gannet.stats>

It's nothing to do with R: there is no code looking at file attributes in R.

Perhaps you have set your OS to mark .* files as hidden somehow?
It does not happen for me or any of our users on XP.

On Thu, 20 Nov 2003, Duncan Mackay wrote:

> I've ecountered a problem in the last few days with my .Rhistory file
> not being able to be updated when I quit an R session because its file
> attributes under Windows have been set as "Hidden". Recently, I put the
> following line in my global Rprofile file:-
> 
> history(max.show=Inf)
> 
> so that I automatically open the entire history file for a project when
> I begin a session, but I don't see why that would cause a problem.
> 
> This problem has arisen several times in the last few days while working
> on different Rdata files in different folders. When I manually uncheck
> the "hidden" attribute of my Rhistory file, the problem goes away. But
> why did the files get that attribute in the first place? Is this
> something that R itself may have done? I'm running R Version 1.8.0
> (2003-10-08) under WinXP.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Nov 20 08:41:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 07:41:02 +0000 (GMT)
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <3FBC47D7.4000807@psu.edu>
Message-ID: <Pine.LNX.4.44.0311200734160.19899-100000@gannet.stats>

On Wed, 19 Nov 2003, Nirmal Govind wrote:

> Thanks for your reply John.
> 
> > this works). Applied to a linear-model object, summary() produces 
> > coefficients, etc. (as mentioned), while anova() produces a (sequential) 
> > ANOVA table. This seems apparent to me from the output.
> 
> What I'm having trouble with is understanding the difference between 
> aov() and lm() [since it seems like if I do a summary() after fitting 
> using aov(), the output is the same as doing anova() after an lm()]. 
> Now, the outputs from aov() and lm() are different - the siginificant 
> effects are different. I think this may have to do with how these 
> functions treat the data - i.e.  whether the function considers the data 
> as being in coded or uncoded units. Is this correct? From what I could 
> tell, aov() will code the data automatically and then present the ANOVA 
> table whereas lm() does not code the data. This pretty much explains 
> everything so far..

And all of that is explained in the reference on the aov help page.
Please do stop speculating and start reading.

> There's one problem though - how do I get the coefficients that are 
> calculated from the data after they are coded by aov()? The problem here 
> is that my factor levels are 0 and 1 instead of the usual -1 and 1... 
> if I run coefficients() after a aov() fit or an lm() fit, I get the same 
> coefficients... these coeffs. don't seem right (I compared with the 
> coefficients from Minitab and JMP -both give coefficients after coding 
> the data into a -1, 1 form).. I could of course modify my data and 
> change all the 0 levels to -1 but is there a way in R to get 
> coefficients that correspond to coded data?

AoV has nothing to do with coefficients.  There is dummy.coef to get
uncoded coefficients, and there is options(contrasts=) to set the coding.

> > More generally, it probably makes sense to read introductory material 
> > about R -- such as the introductory manual that comes with the software 
> 
> Yes, I have read some of these (and maybe I should read more :-))... 
> thanks for the pointer.. on the same note, is there any reference that 
> talks about how lm() and aov() treat data - coded vs. uncoded etc...

Yes, you should read a lot more.  Chapter 6 of Venables & Ripley (2002) 
and chapter 5 of Chambers & Hastie (1991) would be a good start.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Nov 20 08:42:47 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Nov 2003 08:42:47 +0100
Subject: [R] file not found?
In-Reply-To: <200311200242.hAK2gdhW027928@tahi.mcs.vuw.ac.nz>
References: <200311200242.hAK2gdhW027928@tahi.mcs.vuw.ac.nz>
Message-ID: <3FBC7077.9020200@statistik.uni-dortmund.de>

Ray Brownrigg wrote:
> Thomas W Blackwell <tblackw at umich.edu> wrote:
> 
> 
>>I recall a message on the [r-pkgs] list from Ray Brownrigg
>>on November 1 this year that may be relevant.  At that time
>>he was announcing the availability of  maps_2.0-8.zip  and
>>some other packages.
>>
>>Therefore,  2.0-10 must be *very* recent and might still be
>>going through the CRAN propagation process.  (I don't know
>>anything about whther it is or not.)  I would wait a couple
>>of days and try again, if I were you.
>>
> 
> Well, actually, 2.0-10 in source form is on CRAN since last week, but
> for some reason only in the 1.7/ directory in the Windows area.  I just
> this morning noticed this and sent a message to the Windows CRAN
> maintainer.
> 
> In the meantime, 2.0-11 has been uploaded, probably to appear in a few
> days (no noticeable changes).
> 
> Ray Brownrigg

For some (unknown) reason, the automated upload of maps_2.0-10.zip 
failed (it's in the PACKAGES list, though). I'll upload it manually 
today, so it will appear on CRAN master tomorrow.

Uwe Ligges



From WeiQiang.Li at seagate.com  Thu Nov 20 08:42:02 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Thu, 20 Nov 2003 15:42:02 +0800
Subject: [R] How to handle multiple thread using (D)COM server
Message-ID: <OF9D73BD77.33055762-ON48256DE4.00289E68-48256DE4.002A5CC2@notes.seagate.com>

Hi ALL,
      I am trying to produce ASP web reports using (D)COM server. The
problem I am facing is (D)COM server cannot allow users accessing to R
project concurrently, it need one by one to execute ASP.    Same thing
happened in VB application. I can not run two VB apps at same time.
      Does anyone know whether it is (D)COM server limitation or
configuration issue at my (D)COM server? Thanks in advance!

Best Regards,
WeiQiang Li



From ligges at statistik.uni-dortmund.de  Thu Nov 20 08:43:25 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Nov 2003 08:43:25 +0100
Subject: [R] maps package for Windows
In-Reply-To: <005901c3af2e$0c273b80$6401a8c0@Jeeves2>
References: <005101c3af24$5bf2d430$6401a8c0@Jeeves2>	<003f01c3af27$280a87f0$818001db@webgis>
	<005901c3af2e$0c273b80$6401a8c0@Jeeves2>
Message-ID: <3FBC709D.7010102@statistik.uni-dortmund.de>

Rajiv Prasad wrote:

> Umm... no, does not work for me yet:
> 
> 
>>local({a <- CRAN.packages()
> 
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)})
> trying URL `http://cran.r-project.org/bin/windows/contrib/1.8/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 13514 bytes
> opened URL
> downloaded 13Kb
> 
> trying URL
> `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> Error in download.file(url, destfile, method, mode = "wb") :
>         cannot open URL
> `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> In addition: Warning message:
> cannot open: HTTP status was `404 Not Found'
> 
> 
> Is it just an issue of the file not haveing reached all mirrors yet?
> 
> Thanks.
> 
> Rajiv


For some (unknown) reason, the automated upload of maps_2.0-10.zip 
failed (it's in the PACKAGES list, though). I'll upload it manually 
today, so it will appear on CRAN master tomorrow.

Uwe Ligges



From laurent.marzec at ed.univ-lille1.fr  Thu Nov 20 09:12:26 2003
From: laurent.marzec at ed.univ-lille1.fr (Laurent Marzec)
Date: Thu, 20 Nov 2003 09:12:26 +0100
Subject: [R] netCDF, ncdf library
Message-ID: <6.0.0.22.2.20031120085902.01c11480@pop.etudiant.univ-lille1.fr>


   Dear all,
   I would like to use data in .netcdf format and for those I have to use
   the netCDF or ncdf packages.
   Problem : these packages don't seem to work :
   "Error in testRversion(descfields) : This package has not been
   installed properly
    See the Note in ?library" (with netCDF package)
   Does anybody have the same problems with these packages ?
   Is there any other packages existing to convert netcdf format ?
   Version: 1.8.0
   OS: Windows XP
   with many thanks in advance

   ???????????????????????   A4?   Laurent Marzec (Phd)
   Universit? des Sciences & Technologies de Lille
   D?partement Station Marine
   UMR CNRS 8013 ELICO
   28 avenue Foch, B.P. 80, F-62930 WIMEREUX
   Map info: 50?46'10'' N - 1?37'01'' E
   T?l : + 33 (0)3.21.99.29.05, Fax : + 33 (0)3.21.99.29.01
   e-mail : Laurent.Marzec at ed.univ-lille1.fr
   Site perso: [1]http://home.nordnet.fr/~laurent.marzec
   

References

   1. 3D"http://home.nordnet.fr/~laurent.marzec"

From nirmalg at psu.edu  Thu Nov 20 09:20:53 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Thu, 20 Nov 2003 03:20:53 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <Pine.LNX.4.44.0311200734160.19899-100000@gannet.stats>
References: <Pine.LNX.4.44.0311200734160.19899-100000@gannet.stats>
Message-ID: <3FBC7965.2090704@psu.edu>

Thanks for your reply, Prof. Ripley.

> And all of that is explained in the reference on the aov help page.
> Please do stop speculating and start reading.

Well, the reason for speculation was cos I couldn't find any details on 
that help page... thanks for letting me know that the reference explains 
this...

> AoV has nothing to do with coefficients.  There is dummy.coef to get
> uncoded coefficients, and there is options(contrasts=) to set the coding.

Ok, I will try these...

> Yes, you should read a lot more.  Chapter 6 of Venables & Ripley (2002) 
> and chapter 5 of Chambers & Hastie (1991) would be a good start.

Oh, I most definitely should! :-) .. I guess I was hoping that such 
details would be included in the help page for the function or mentioned 
in some R introduction or tutorial or so on the Documentation page.. 
looks like that's not the case so I'll get a hold of the books above...

Thanks,
nirmal



From kwan022 at stat.auckland.ac.nz  Thu Nov 20 09:55:32 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 20 Nov 2003 21:55:32 +1300 (NZDT)
Subject: [R] read.table(..)..Help?
In-Reply-To: <20031120084823.40188.qmail@web10503.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311202154480.15899-100000@stat55.stat.auckland.ac.nz>

On Thu, 20 Nov 2003, forkusam wrote:

> Hi;
> Thanks for the quick reply. I am presently not sittinh infront of my computer so I can't tell you the exact error message but.
> 
>     I have read through the documentation and have found nothing of help.
>    Yes. the columns are separated by semicolons
>    My problem is: I do not know the command / or parameter I need to read the rows and  process the stored information one after the other.

read.table() should know how to read each rows, can you provide an subset 
of your data? 

-- 
Cheers,

Kevin

---------------------------------------------------------------
"Try not.  Do, do!  Or do not.  There is no try"
   Jedi Master Yoda

----
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From Simon.Fear at synequanon.com  Thu Nov 20 10:04:52 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 20 Nov 2003 09:04:52 -0000
Subject: [R] ISOdate returns incorrect date?
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F0210D@synequanon01>

I've been using the following little `helper` function:

tea <- function() {
 shell("C:\\program files\\kettle\\tea.exe /2sugars", wait=FALSE)
}

I was thinking of submitting it to CRAN until I discovered that
when I ran it on my laptop on holiday in Italy, it made coffee!
I reluctantly decided not to submit it, given that relying on the 
OS, and particularly its timezone settings, obviously wasn't 
robust enough for a cross-platform implementation.  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From ligges at statistik.uni-dortmund.de  Thu Nov 20 10:09:44 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Nov 2003 10:09:44 +0100
Subject: [R] netCDF, ncdf library
In-Reply-To: <6.0.0.22.2.20031120085902.01c11480@pop.etudiant.univ-lille1.fr>
References: <6.0.0.22.2.20031120085902.01c11480@pop.etudiant.univ-lille1.fr>
Message-ID: <3FBC84D8.9020606@statistik.uni-dortmund.de>

Laurent Marzec wrote:

>    Dear all,
>    I would like to use data in .netcdf format and for those I have to use
>    the netCDF or ncdf packages.
>    Problem : these packages don't seem to work :
>    "Error in testRversion(descfields) : This package has not been
>    installed properly
>     See the Note in ?library" (with netCDF package)
>    Does anybody have the same problems with these packages ?
>    Is there any other packages existing to convert netcdf format ?
>    Version: 1.8.0
>    OS: Windows XP
>    with many thanks in advance
> 

I guess you have installed the *source* package without compiling it. 
Either compile it youself or get the binary.

For Windows binaries 
http://cran.r-project.org/bin/windows/contrib/1.8/@ReadMe tells you:

"The packages
   XML, ncdf, netCDF, and xgobi
do not build out of the box. Nevertheless these are available at
   http://www.stats.ox.ac.uk/pub/RWin
kindly provided by Professor Brian D. Ripley."

Uwe Ligges



From ripley at stats.ox.ac.uk  Thu Nov 20 10:09:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 09:09:12 +0000 (GMT)
Subject: [R] netCDF, ncdf library
In-Reply-To: <6.0.0.22.2.20031120085902.01c11480@pop.etudiant.univ-lille1.fr>
Message-ID: <Pine.LNX.4.44.0311200907040.20319-100000@gannet.stats>

Where did you get these from?  You need to compile them from source or get 
versions from my site (not CRAN): the latter work for me.

On Thu, 20 Nov 2003, Laurent Marzec wrote:

>    I would like to use data in .netcdf format and for those I have to use
>    the netCDF or ncdf packages.
>    Problem : these packages don't seem to work :
>    "Error in testRversion(descfields) : This package has not been
>    installed properly

So, you didn't install them properly.  Please rectify your errors.

>     See the Note in ?library" (with netCDF package)
>    Does anybody have the same problems with these packages ?
>    Is there any other packages existing to convert netcdf format ?
>    Version: 1.8.0
>    OS: Windows XP
>    with many thanks in advance


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.pagel at gsf.de  Thu Nov 20 09:27:43 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Thu, 20 Nov 2003 09:27:43 +0100
Subject: [R] read.table(..)..Help?
In-Reply-To: <20031120071127.25215.qmail@web10503.mail.yahoo.com>
References: <20031120071127.25215.qmail@web10503.mail.yahoo.com>
Message-ID: <20031120082743.GA2361@porcupine.gsf.de>

On Wed, Nov 19, 2003 at 11:11:27PM -0800, forkusam wrote:

> p<-read.table(file="FILENAME ", header=TRUE,sep=";")
> and later used the data.Frame() function.
> It functions when the file has only a row of
> variables.

It is not at all clear to me what you are doing and what is going wrong.
Please provide a (short) example of what exactly you do, what error
messages and warnings you get and what your input file looks like. 

BTW: read.table returns a data frame so I'm not sure what
you mean by using data.frame() later on. 

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From Pascal.Niklaus at unibas.ch  Thu Nov 20 13:26:23 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Thu, 20 Nov 2003 13:26:23 +0100
Subject: [R] Find value in vector (or matrix)
Message-ID: <3FBCB2EF.9080201@unibas.ch>

Hi all,

Is there a function to check if a particular value is contained in a 
vector? I've looked at grep in the hope that I could use a Perl-like 
syntax, but obviously it's different...

I'd like to do something like:

    y <- c("a","b","c")
    if("a" in y)
    {
          # "a" is not in y
    }

Also, is there a way to generate character sequences similar to numeric 
sequences, e.g. something like "A":"J" ? I remember having seen a 
command doing this somewhere, but can't find it anymore

Thanks

Pascal



From ripley at stats.ox.ac.uk  Thu Nov 20 13:41:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 12:41:15 +0000 (GMT)
Subject: [R] Find value in vector (or matrix)
In-Reply-To: <3FBCB2EF.9080201@unibas.ch>
Message-ID: <Pine.LNX.4.44.0311201239260.20745-100000@gannet.stats>

On Thu, 20 Nov 2003, Pascal A. Niklaus wrote:

> Is there a function to check if a particular value is contained in a 
> vector? I've looked at grep in the hope that I could use a Perl-like 
> syntax, but obviously it's different...
> 
> I'd like to do something like:
> 
>     y <- c("a","b","c")
>     if("a" in y)

"a" %in" y,

which disguises a call to match(), so look at match.

length(grep("a", y)) > 0 should work too.

>     {
>           # "a" is not in y
>     }
> 
> Also, is there a way to generate character sequences similar to numeric 
> sequences, e.g. something like "A":"J" ? I remember having seen a 
> command doing this somewhere, but can't find it anymore

LETTERS[1:10] will do this.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Thu Nov 20 13:44:05 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 20 Nov 2003 06:44:05 -0600
Subject: [R] Find value in vector (or matrix)
In-Reply-To: <3FBCB2EF.9080201@unibas.ch>
References: <3FBCB2EF.9080201@unibas.ch>
Message-ID: <3FBCB715.4040002@pdf.com>



Pascal A. Niklaus wrote:
> Hi all,
> 
> Is there a function to check if a particular value is contained in a 
> vector? I've looked at grep in the hope that I could use a Perl-like 
> syntax, but obviously it's different...
> 
> I'd like to do something like:
> 
>    y <- c("a","b","c")
>    if("a" in y)
>    {
>          # "a" is not in y
>    }
> 
> Also, is there a way to generate character sequences similar to numeric 
> sequences, e.g. something like "A":"J" ? I remember having seen a 
> command doing this somewhere, but can't find it anymore
> 
> Thanks
> 
> Pascal

You almost have it: Try "%in%" instead.

if("a" %in% y) { }

or

if(any(c("a", "b") %in% y)) { }

See help("%in%").

For question 2, see ?letters or ?LETTERS.

-sundar



From B.Rowlingson at lancaster.ac.uk  Thu Nov 20 13:50:10 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 20 Nov 2003 12:50:10 +0000
Subject: [R] Find value in vector (or matrix)
In-Reply-To: <3FBCB2EF.9080201@unibas.ch>
References: <3FBCB2EF.9080201@unibas.ch>
Message-ID: <3FBCB882.4010507@lancaster.ac.uk>

Pascal A. Niklaus wrote:

>    y <- c("a","b","c")
>    if("a" in y)
>    {
>          # "a" is not in y
>    }

  You are 98% of the way there. The missing two percent is this:

  if("a" %in% y) {
...
}

  you could also use the 'any' function:

  if(any(y=="a")){
...
  }


> Also, is there a way to generate character sequences similar to numeric 
> sequences, e.g. something like "A":"J" ? I remember having seen a 
> command doing this somewhere, but can't find it anymore

  R defines two vectors, "letters" and "LETTERS" which have the 26 lower 
and upper-case letters of the English alphabet. Subset from them to get 
what you want.

Baz



From p.pagel at gsf.de  Thu Nov 20 13:46:59 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Thu, 20 Nov 2003 13:46:59 +0100
Subject: [R] Find value in vector (or matrix)
In-Reply-To: <3FBCB2EF.9080201@unibas.ch>
References: <3FBCB2EF.9080201@unibas.ch>
Message-ID: <20031120124658.GA4760@porcupine.gsf.de>

On Thu, Nov 20, 2003 at 01:26:23PM +0100, Pascal A. Niklaus wrote:
> Is there a function to check if a particular value is contained in a 
> vector?

> myvec <- c('foo','bar','duh','bonk')
> 'bonk' %in% myvec
[1] TRUE
> 'asdf' %in% myvec
[1] FALSE

> Also, is there a way to generate character sequences similar to numeric 
> sequences, e.g. something like "A":"J" ?

> LETTERS[1:5]
[1] "A" "B" "C" "D" "E"

> letters[c(8,9,12,23)]
[1] "h" "i" "l" "w"

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From p.dalgaard at biostat.ku.dk  Thu Nov 20 14:47:49 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Nov 2003 14:47:49 +0100
Subject: [R] Find value in vector (or matrix)
In-Reply-To: <3FBCB2EF.9080201@unibas.ch>
References: <3FBCB2EF.9080201@unibas.ch>
Message-ID: <x24qwzqhh6.fsf@biostat.ku.dk>

"Pascal A. Niklaus" <Pascal.Niklaus at unibas.ch> writes:

> Hi all,
> 
> Is there a function to check if a particular value is contained in a
> vector? I've looked at grep in the hope that I could use a Perl-like
> syntax, but obviously it's different...
> 
> I'd like to do something like:
> 
>     y <- c("a","b","c")
>     if("a" in y)
>     {
>           # "a" is not in y
>     }

"a" %in% y

> Also, is there a way to generate character sequences similar to
> numeric sequences, e.g. something like "A":"J" ? I remember having
> seen a command doing this somewhere, but can't find it anymore

LETTERS[1:10] 

is probably the closest. You do need to look up that "J" is the 10th
letter or resort to things like

LETTERS[which(LETTERS>="A"&LETTERS<="J")]

or

LETTERS[which(LETTERS=="A"):which(LETTERS=="J")]


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Pascal.Niklaus at unibas.ch  Thu Nov 20 14:43:48 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Thu, 20 Nov 2003 14:43:48 +0100
Subject: [R] Increment element of vector and efficiency
Message-ID: <3FBCC514.6050409@unibas.ch>

Hi all,

Thanks for the incredibly quick help with the "%in%"...

There's a second question, though: I'd like to increment an element of a 
vector if a certain event occurs, e.g.

    count[event] <- count[event] + 1;         # works, but...

Is this efficient? I wonder whether R needs to subset the count vector 
on both sides of the assignment operator (i.e., twice), or whether 
there's a shortcut like "++" in C, e.g. "count[i]++" or similar?

Pascal



From apv at capital.net  Thu Nov 20 14:50:00 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 20 Nov 2003 08:50:00 -0500
Subject: [R] RMySQL for Windows
Message-ID: <1069336200.3473.35.camel@redtail.mydomain.home>

Hi all,

I have been reviewing previous messages about installing RMySQL under
windows.  My configuration is WinXP, MySQL 4.0.14-max-debug and R
1.8.0.  I have been able install RMySQL.  However, I do have a question:

When I type

>library(RMySQL)

I get the following:

    Warning message: 
    DLL attempted to change FPU control word from 8001f to 9001f 

Based on previous messages I have concluded that this should not cause
me problems.

Is this correct ?

Thanks for all your help,
Arend



From jfox at mcmaster.ca  Thu Nov 20 14:53:42 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 20 Nov 2003 08:53:42 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <3FBC7965.2090704@psu.edu>
References: <Pine.LNX.4.44.0311200734160.19899-100000@gannet.stats>
	<Pine.LNX.4.44.0311200734160.19899-100000@gannet.stats>
Message-ID: <5.1.0.14.2.20031120085040.01fdf078@127.0.0.1>

Dear Nirmal,

At 03:20 AM 11/20/2003 -0500, Nirmal Govind wrote:
>Thanks for your reply, Prof. Ripley.
>
>>And all of that is explained in the reference on the aov help page.
>>Please do stop speculating and start reading.
>
>Well, the reason for speculation was cos I couldn't find any details on 
>that help page... thanks for letting me know that the reference explains 
>this...
>
>>AoV has nothing to do with coefficients.  There is dummy.coef to get
>>uncoded coefficients, and there is options(contrasts=) to set the coding.
>
>Ok, I will try these...
>
>>Yes, you should read a lot more.  Chapter 6 of Venables & Ripley (2002) 
>>and chapter 5 of Chambers & Hastie (1991) would be a good start.
>
>Oh, I most definitely should! :-) .. I guess I was hoping that such 
>details would be included in the help page for the function or mentioned 
>in some R introduction or tutorial or so on the Documentation page.. looks 
>like that's not the case so I'll get a hold of the books above...

Actually, there's a decent basic explanation of these matters in Sec. 11 of 
the manual An Introduction to R, which comes with R. As Prof. Ripley points 
out, you'll find more detailed treatments in books.

Regards,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From rpeng at jhsph.edu  Thu Nov 20 14:56:38 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 20 Nov 2003 08:56:38 -0500
Subject: [R] Increment element of vector and efficiency
In-Reply-To: <3FBCC514.6050409@unibas.ch>
References: <3FBCC514.6050409@unibas.ch>
Message-ID: <3FBCC816.2080603@jhsph.edu>

I think that's about as efficient as you can get.  I'm not sure of the 
underlying details.  There was some discussion recently of having the 
equivalent of a "+=" operator but currently R has no such thing.

-roger

Pascal A. Niklaus wrote:
> Hi all,
> 
> Thanks for the incredibly quick help with the "%in%"...
> 
> There's a second question, though: I'd like to increment an element of a 
> vector if a certain event occurs, e.g.
> 
>    count[event] <- count[event] + 1;         # works, but...
> 
> Is this efficient? I wonder whether R needs to subset the count vector 
> on both sides of the assignment operator (i.e., twice), or whether 
> there's a shortcut like "++" in C, e.g. "count[i]++" or similar?
> 
> Pascal
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From johannes.ludsteck at wiwi.uni-regensburg.de  Thu Nov 20 15:02:24 2003
From: johannes.ludsteck at wiwi.uni-regensburg.de (Johannes Ludsteck)
Date: Thu, 20 Nov 2003 15:02:24 +0100
Subject: [R] nls, nlrq, and box-cox transformation
Message-ID: <3FBCD77D.21682.13ECE8D@localhost>

Dear r-help members
I posted this message already yesterday, but don't know whether it
reached you since I joined the group only yesterday.
I would like to estimate the boxcox transformed model
 (y^t - 1)/t ~ b0 + b1 * x.
Unfortunately, R returns with an error message when I try to 
perform this with the call
nls( I((y^t - 1)/t) ~ I(b0 + b1*x),
	start = c(t=1,b0=0,b1=0), data = mydataframe)

The error message is:  Object "t" not found

Apparently R seems not to accept parameters on the left hand
side of a regression model. I know that my do-it-yourself
strategy is not necessary, since the package box-cox is 
available. Unfortunately, I want the use the box-cox 
transformation in a quantile regression, i.e. I have to replace 
nls by nlrq in the call above.

Any suggestions?

Thanks and best regards,
	Johannes Ludsteck
<><><><><><><><><><><><><><><><><><>
Johannes Ludsteck
Institut fuer Volkswirtschaftslehre
Lehrstuhl Prof. Dr. Moeller
Universitaet Regensburg
Universitaetsstrasse 31
93053 Regensburg
Tel +49/0941/943-2741



From apv at capital.net  Thu Nov 20 15:08:12 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 20 Nov 2003 09:08:12 -0500
Subject: [R] Compile Packages under Windows and CHM
Message-ID: <1069337292.3473.66.camel@redtail.mydomain.home>

Hi,

I have been developing a small package.  It install under RedHat Linux
9.0 without a problem.  However, I have a small problem under Windows
XP.  I am using R-1.8.0 on both systems and HTML Help Workshop
4.74.8702.0 on Windows XP.  I created the package under Linux.

When I try to install the package created under Linux in Windows XP
using

c:\rtest> rcmd install rtest

I get the following error:

########

      Formats: chm
hhc: not found
cp: cannot stat `C:/R-Packages/rtest/chm/rtest.chm': No such file or
directory
make[1]: *** [chm-rtest] Error 1
make: *** [pkg-rtest] Error 2
*** Installation of rtest failed ***

########

A file with a hhc extension is usually the contents file.  However, the
HTML help project that is automatically created uses toc as the
extension of the content file.  If I load the project file using HTML
Help Workshop I am able to compile it and create a HTML Help File.

Has anybody else had this problem.

Thanks,
Arend van der Veen



From MSchwartz at medanalytics.com  Thu Nov 20 15:10:38 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 20 Nov 2003 08:10:38 -0600
Subject: [R] Increment element of vector and efficiency
In-Reply-To: <3FBCC514.6050409@unibas.ch>
References: <3FBCC514.6050409@unibas.ch>
Message-ID: <1069337437.5636.47.camel@localhost.localdomain>

On Thu, 2003-11-20 at 07:43, Pascal A. Niklaus wrote:
> Hi all,
> 
> Thanks for the incredibly quick help with the "%in%"...
> 
> There's a second question, though: I'd like to increment an element of a 
> vector if a certain event occurs, e.g.
> 
>     count[event] <- count[event] + 1;         # works, but...
> 
> Is this efficient? I wonder whether R needs to subset the count vector 
> on both sides of the assignment operator (i.e., twice), or whether 
> there's a shortcut like "++" in C, e.g. "count[i]++" or similar?
> 
> Pascal


There is no increment operator in R. However, it would not be difficult
to create a function to increment a value:

increment <- function(x)
{
  eval.parent(substitute(x <- x + 1))
}

> x <- c(2, 5, 3, 8)
> increment(x[3])
> x
[1] 2 5 4 8
> increment(x[3])
> x
[1] 2 5 5 8
> increment(x[3])
> x
[1] 2 5 6 8

>From a practical standpoint however, it does not save any time of
course:

> system.time(increment(x[3]))
[1] 0 0 0 0 0
> system.time(x[3] <- x[3] + 1)
[1] 0 0 0 0 0


HTH,

Marc Schwartz



From roger at ysidro.econ.uiuc.edu  Thu Nov 20 15:26:29 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 20 Nov 2003 08:26:29 -0600 (CST)
Subject: [R] Re: nlrq problem
In-Reply-To: <3FBC9C56.13231.57B581@localhost>
Message-ID: <Pine.SOL.4.30.0311200823320.13122-100000@ysidro.econ.uiuc.edu>

Johannes,

You can minimize an model expression by just putting the ~ on the left
and everything else on the righthand side, but I don't think that this
is really what you want.  In the NLS expression this would ignore the
jacobian of the transformation from errors to response, and in nlrq
there is the same problem, however you can adjust for the jacobian
by rescaling by the geometric mean of the response.  I hope that this
helps.

Roger


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Thu, 20 Nov 2003, Johannes Ludsteck wrote:

> Dear Mr. Koenker,
> sorry for bothering you. I have a probably trivial problem with
> your nlrq procedure.
>
> I would like to estimate the simple box-cox tranformed model
>
>  nlrq(I(y^t-1)/t) ~ I(a+b*x), data=df, start = c(t=1,a=0,b=0))
>
> R returns with the error message
>   Error in unique(c("AsIs", oldClass(x))) : Object "t" not found
>
> Is nlrq not able to handle transformations of the left hand side
> variable or have I maked a mistake?
>
> Thanks for every help and best regards,
> 	Johannes Ludsteck
> <><><><><><><><><><><><>
> Johannes Ludsteck
> Economics Department
> University of Regensburg
> Universitaetsstrasse 31
> 93053 Regensburg
> Phone +49/0941/943-2741
>
>



From phgrosjean at sciviews.org  Thu Nov 20 15:24:19 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 20 Nov 2003 15:24:19 +0100
Subject: [R] nls, nlrq, and box-cox transformation
In-Reply-To: <3FBCD77D.21682.13ECE8D@localhost>
Message-ID: <MABBLJDICACNFOLGIHJOCECADPAA.phgrosjean@sciviews.org>

>Dear r-help members
>I posted this message already yesterday, but don't know whether it
>reached you since I joined the group only yesterday.
>I would like to estimate the boxcox transformed model
> (y^t - 1)/t ~ b0 + b1 * x.
>Unfortunately, R returns with an error message when I try to
>perform this with the call
>nls( I((y^t - 1)/t) ~ I(b0 + b1*x),
>	start = c(t=1,b0=0,b1=0), data = mydataframe)

>The error message is:  Object "t" not found

>Apparently R seems not to accept parameters on the left hand
>side of a regression model. I know that my do-it-yourself
>strategy is not necessary, since the package box-cox is
>available. Unfortunately, I want the use the box-cox
>transformation in a quantile regression, i.e. I have to replace
>nls by nlrq in the call above.

>Any suggestions?

>Thanks and best regards,
>	Johannes Ludsteck

You suggest the solution yourself: transform the equation to have all
parameters at the right, thus:

y ~ ((b0 + b1 * x) * t + 1) ^ 1/t

(double check if this is correct)

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       Numerical Ecology Laboratory
 ) ) ) ) )      Mons-Hainaut University
( ( ( ( (       8, Av. du Champ de Mars, 7000 Mons
 ) ) ) ) )      Belgium
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From Wolfgang_Lederer at mckinsey.com  Thu Nov 20 15:26:29 2003
From: Wolfgang_Lederer at mckinsey.com (Wolfgang_Lederer@mckinsey.com)
Date: Thu, 20 Nov 2003 15:26:29 +0100
Subject: [R] How to adjust the Intercept correctly when using ols() and
	validate().
Message-ID: <OFEFDE2F05.E19E5AD2-ONC1256DE4.004CE689@notes.mckinsey.com>

                        
                        
                        
                        
                        


Dear R-Help-List,

i am using the ols() function to fit a model and use the validate()
function to obtain the shrinking constant for the slope. But how can i get
the correct shrinking constant for the Intercept? If i use the provided
constant to adjust the intercept, i get a serious Bias.

the code i use looks like this:

f  <- ols(formula , data = data, y=T, x=T)
fv <- validate(f)
ShrinkingGamma <- fv["Slope","index.corrected"]
f$coefficients[2:(length(f$coefficients)-1)] <-
f$coefficients[2:(length(f$coefficients)-1)] * ShrinkingGamma
f$coefficients[1] <- (1-ShrinkingGamma) * mean(data[,1]) +
f$coefficients[1] * (ShrinkingGamma)
predict(f, newdata = data)


Thanks for your help

Wolfgang

+---------------------------------------------------------+
This message may contain confidential and/or privileged
information.  If you are not the addressee or authorized to
receive this for the addressee, you must not use, copy,
disclose or take any action based on this message or any
information herein.  If you have received this message in
error, please advise the sender immediately by reply e-mail
and delete this message.  Thank you for your cooperation.
+---------------------------------------------------------+



From ligges at statistik.uni-dortmund.de  Thu Nov 20 15:38:20 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Nov 2003 15:38:20 +0100
Subject: [R] Compile Packages under Windows and CHM
In-Reply-To: <1069337292.3473.66.camel@redtail.mydomain.home>
References: <1069337292.3473.66.camel@redtail.mydomain.home>
Message-ID: <3FBCD1DC.9040307@statistik.uni-dortmund.de>

Arend P. van der Veen wrote:

> Hi,
> 
> I have been developing a small package.  It install under RedHat Linux
> 9.0 without a problem.  However, I have a small problem under Windows
> XP.  I am using R-1.8.0 on both systems and HTML Help Workshop
> 4.74.8702.0 on Windows XP.  I created the package under Linux.
> 
> When I try to install the package created under Linux in Windows XP
> using
>

Most easy solution is to copy hhc.exe (from HTML Help Workshop) in your 
Windows directory (it must be in your path, at least).
Also, have you edited the MkRules so that it points to the right 
location of the HTML Help Workshop?

Uwe Ligges


> c:\rtest> rcmd install rtest
> 
> I get the following error:
> 
> ########
> 
>       Formats: chm
> hhc: not found
> cp: cannot stat `C:/R-Packages/rtest/chm/rtest.chm': No such file or
> directory
> make[1]: *** [chm-rtest] Error 1
> make: *** [pkg-rtest] Error 2
> *** Installation of rtest failed ***
> 
> ########
> 
> A file with a hhc extension is usually the contents file.  However, the
> HTML help project that is automatically created uses toc as the
> extension of the content file.  If I load the project file using HTML
> Help Workshop I am able to compile it and create a HTML Help File.
> 
> Has anybody else had this problem.
> 
> Thanks,
> Arend van der Veen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From apv at capital.net  Thu Nov 20 15:55:03 2003
From: apv at capital.net (Arend P. van der Veen)
Date: 20 Nov 2003 09:55:03 -0500
Subject: [R] Compile Packages under Windows and CHM
In-Reply-To: <3FBCD1DC.9040307@statistik.uni-dortmund.de>
References: <1069337292.3473.66.camel@redtail.mydomain.home>
	<3FBCD1DC.9040307@statistik.uni-dortmund.de>
Message-ID: <1069340102.3473.72.camel@redtail.mydomain.home>

Adding hhc.exe to my path did the trick.  I saw hhc and assumed that was
associated with the contents file and not the HTML Help Workshop.

Thanks again,
Arend van der Veen

On Thu, 2003-11-20 at 09:38, Uwe Ligges wrote:
> Arend P. van der Veen wrote:
> 
> > Hi,
> > 
> > I have been developing a small package.  It install under RedHat Linux
> > 9.0 without a problem.  However, I have a small problem under Windows
> > XP.  I am using R-1.8.0 on both systems and HTML Help Workshop
> > 4.74.8702.0 on Windows XP.  I created the package under Linux.
> > 
> > When I try to install the package created under Linux in Windows XP
> > using
> >
> 
> Most easy solution is to copy hhc.exe (from HTML Help Workshop) in your 
> Windows directory (it must be in your path, at least).
> Also, have you edited the MkRules so that it points to the right 
> location of the HTML Help Workshop?
> 
> Uwe Ligges
> 
> 
> > c:\rtest> rcmd install rtest
> > 
> > I get the following error:
> > 
> > ########
> > 
> >       Formats: chm
> > hhc: not found
> > cp: cannot stat `C:/R-Packages/rtest/chm/rtest.chm': No such file or
> > directory
> > make[1]: *** [chm-rtest] Error 1
> > make: *** [pkg-rtest] Error 2
> > *** Installation of rtest failed ***
> > 
> > ########
> > 
> > A file with a hhc extension is usually the contents file.  However, the
> > HTML help project that is automatically created uses toc as the
> > extension of the content file.  If I load the project file using HTML
> > Help Workshop I am able to compile it and create a HTML Help File.
> > 
> > Has anybody else had this problem.
> > 
> > Thanks,
> > Arend van der Veen
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From ripley at stats.ox.ac.uk  Thu Nov 20 15:56:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 14:56:22 +0000 (GMT)
Subject: [R] nls, nlrq, and box-cox transformation
In-Reply-To: <MABBLJDICACNFOLGIHJOCECADPAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0311201437490.21062-100000@gannet.stats>

On Thu, 20 Nov 2003, Philippe Grosjean wrote:

> >Dear r-help members
> >I posted this message already yesterday, but don't know whether it
> >reached you since I joined the group only yesterday.
> >I would like to estimate the boxcox transformed model
> > (y^t - 1)/t ~ b0 + b1 * x.
> >Unfortunately, R returns with an error message when I try to
> >perform this with the call
> >nls( I((y^t - 1)/t) ~ I(b0 + b1*x),
> >	start = c(t=1,b0=0,b1=0), data = mydataframe)
> 
> >The error message is:  Object "t" not found
> 
> >Apparently R seems not to accept parameters on the left hand
> >side of a regression model. I know that my do-it-yourself
> >strategy is not necessary, since the package box-cox is
> >available. Unfortunately, I want the use the box-cox
> >transformation in a quantile regression, i.e. I have to replace
> >nls by nlrq in the call above.
> 
> >Any suggestions?
> 
> >Thanks and best regards,
> >	Johannes Ludsteck
> 
> You suggest the solution yourself: transform the equation to have all
> parameters at the right, thus:
> 
> y ~ ((b0 + b1 * x) * t + 1) ^ 1/t
> 
> (double check if this is correct)

But for nls that changes the fitting criterion from least-squares to
something completely different.

For the original problem, this is not the correct Box-Cox transformation,
as the normalizer has been omitted.  I am unaware of `package box-cox'
(and that is not a valid package name AFAIK), but function boxcox in MASS
computes the correct likelihood.

Now nlrq uses a different criterion and Philippe's suggestion may work
there.  I can't tell quickly: the help page does not say what the
criterion is.  But if those are the same, then I suspect the criterion is 
uninteresting as a way to choose t, since two of the three aims of
Box-Cox are to stabilize the distribution of lhs - rhs.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Thu Nov 20 16:33:40 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 20 Nov 2003 10:33:40 -0500
Subject: [R] RMySQL for Windows
In-Reply-To: <1069336200.3473.35.camel@redtail.mydomain.home>
References: <1069336200.3473.35.camel@redtail.mydomain.home>
Message-ID: <9llprvcpgv54ebhjht4h8hh4nhku7i2mid@4ax.com>

On 20 Nov 2003 08:50:00 -0500, "Arend P. van der Veen"
<apv at capital.net> wrote :

>Hi all,
>
>I have been reviewing previous messages about installing RMySQL under
>windows.  My configuration is WinXP, MySQL 4.0.14-max-debug and R
>1.8.0.  I have been able install RMySQL.  However, I do have a question:
>
>When I type
>
>>library(RMySQL)
>
>I get the following:
>
>    Warning message: 
>    DLL attempted to change FPU control word from 8001f to 9001f 
>
>Based on previous messages I have concluded that this should not cause
>me problems.
>
>Is this correct ?

It's hard to answer that.  These are the issues:

A DLL loaded by the RMySQL package has altered the floating point
precision, to reduce it from 64 bit precision to 53 bits.  R saw that,
and responded by changing it back.  

If the DLL leaves it alone in the future, this won't cause any
problems for R.  This is likely the case, but it's not guaranteed:
some libraries will change it again.  R won't check again, so this
means that future calculations in R will not be carried out in the
environment under which they were designed and tested, and are likely
to be less accurate.

It could conceivably cause problems for the DLL, but this seems pretty
unlikely.  If some routine in the DLL relied on a certain amount of
rounding error, it might not function under the increased precision.
I doubt if RMySQL does a lot of floating point computation, so this
isn't something I'd worry about.

So I'd conclude that this probably won't cause you problems, but it
might.

Duncan Murdoch



From hdoran at nasdc.org  Thu Nov 20 16:37:09 2003
From: hdoran at nasdc.org (Harold Doran)
Date: Thu, 20 Nov 2003 10:37:09 -0500
Subject: [R] conf int mixed effects
Message-ID: <66578BFC0BA55348B5907A0F798EE9307A2BC7@ernesto.NASDC.ORG>

I am very curious about this. If a particular growth model is specified to reflect repeated observations on individual i in unit j, such as:

y_{tij} = [B_{00} + B_{01}*(TIME)]+[u_{00}+u_{01}*(TIME)+ e_{tij}]

where Bs are the fixed effects and the u's are the random effects.

The growth of individual i is then computed as:

B_{01} + u_{01}

Is it appropriate to compute a confidence interval around this growth rate? I so, how might this be accomplished? Based on Doug's comments below, it would seem that only a CI can be formulated for the fixed portion of the model.

I would appreciate any clarification.

HCD


------
Harold C. Doran
Director of Research and Evaluation
New American Schools
675 N. Washington Street, Suite 220
Alexandria, Virginia 22314
703.647.1628
 
 
 


-----Original Message-----
From: Douglas Bates [mailto:bates at stat.wisc.edu]
Sent: Thursday, November 13, 2003 10:11 AM
To: Joerg Schaber
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] conf int mixed effects


Joerg Schaber <Joerg.Schaber at uv.es> writes:

> I have a linear mixed-effects model object and want to extract the 95%
> confidence intervals for the fixed and random effects, respectively. I
> found the function intervals() for confidence intervals for the fixed
> effects but no corresponding function for the random effects. Does it
> exist or do I have to calculate the confidence intervals for the
> random effects myself?

You have to calculate them yourself, partly because it is not clear
what such an interval should be.  Technically, the random effects are
not parameters and defining a "confidence interval" on a random
variable that is part of the model is, at the very least, awkward.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dmurdoch at pair.com  Thu Nov 20 16:39:20 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 20 Nov 2003 10:39:20 -0500
Subject: [R] Increment element of vector and efficiency
In-Reply-To: <1069337437.5636.47.camel@localhost.localdomain>
References: <3FBCC514.6050409@unibas.ch>
	<1069337437.5636.47.camel@localhost.localdomain>
Message-ID: <qrnprvgrr1blc0n54rl7a064fatmnpamog@4ax.com>

On Thu, 20 Nov 2003 08:10:38 -0600, Marc Schwartz
<MSchwartz at medanalytics.com> wrote :

>There is no increment operator in R. However, it would not be difficult
>to create a function to increment a value:
>
>increment <- function(x)
>{
>  eval.parent(substitute(x <- x + 1))
>}
>
>> x <- c(2, 5, 3, 8)
>> increment(x[3])
>> x
>[1] 2 5 4 8
>> increment(x[3])
>> x
>[1] 2 5 5 8
>> increment(x[3])
>> x
>[1] 2 5 6 8
>
>>From a practical standpoint however, it does not save any time of
>course:
>
>> system.time(increment(x[3]))
>[1] 0 0 0 0 0
>> system.time(x[3] <- x[3] + 1)
>[1] 0 0 0 0 0

If you put these in a big loop, you'll find the second is faster:
both do the indexing twice, but the second also has an extra couple of
function calls.

> system.time(for (i in 1:10000) increment(x[3]))
[1]   NA   NA 1.44   NA   NA
> system.time(for (i in 1:10000) x[3] <- x[3]+1)
[1]   NA   NA 0.52   NA   NA

Duncan Murdoch



From MSchwartz at medanalytics.com  Thu Nov 20 17:08:56 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 20 Nov 2003 10:08:56 -0600
Subject: [R] Increment element of vector and efficiency
In-Reply-To: <qrnprvgrr1blc0n54rl7a064fatmnpamog@4ax.com>
References: <3FBCC514.6050409@unibas.ch>
	<1069337437.5636.47.camel@localhost.localdomain>
	<qrnprvgrr1blc0n54rl7a064fatmnpamog@4ax.com>
Message-ID: <1069344535.5636.114.camel@localhost.localdomain>

On Thu, 2003-11-20 at 09:39, Duncan Murdoch wrote:
> On Thu, 20 Nov 2003 08:10:38 -0600, Marc Schwartz
> <MSchwartz at medanalytics.com> wrote :
> 
> >There is no increment operator in R. However, it would not be difficult
> >to create a function to increment a value:
> >
> >increment <- function(x)
> >{
> >  eval.parent(substitute(x <- x + 1))
> >}
> >
> >> x <- c(2, 5, 3, 8)
> >> increment(x[3])
> >> x
> >[1] 2 5 4 8
> >> increment(x[3])
> >> x
> >[1] 2 5 5 8
> >> increment(x[3])
> >> x
> >[1] 2 5 6 8
> >
> >>From a practical standpoint however, it does not save any time of
> >course:
> >
> >> system.time(increment(x[3]))
> >[1] 0 0 0 0 0
> >> system.time(x[3] <- x[3] + 1)
> >[1] 0 0 0 0 0
> 
> If you put these in a big loop, you'll find the second is faster:
> both do the indexing twice, but the second also has an extra couple of
> function calls.
> 
> > system.time(for (i in 1:10000) increment(x[3]))
> [1]   NA   NA 1.44   NA   NA
> > system.time(for (i in 1:10000) x[3] <- x[3]+1)
> [1]   NA   NA 0.52   NA   NA
> 
> Duncan Murdoch


Good point Duncan. The function call approach does introduce some
overhead.

It has been a while (years) since I have done any serious C coding, but
if my 45 year old memory is not failing me, my recollection is that the
advantage of the C increment operators (besides the fact that C is
compiled and R is interpreted), is that they compiled "one to one" with
machine level integer addition instructions, which made them faster and
more efficient. On the x86 family I believe it was INC.

Of course, the end result is also likely to be dependent upon compiler
optimization options as well.

Thanks,

Marc



From ozric at web.de  Wed Nov 19 17:35:54 2003
From: ozric at web.de (Christian Schulz)
Date: Wed, 19 Nov 2003 17:35:54 +0100
Subject: [R] RMySQL_5.2 SuSE9.0
Message-ID: <008101c3aebb$4b255100$9307ebd9@xxlarwv7waunej>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031119/3049d37b/attachment.pl

From roger at ysidro.econ.uiuc.edu  Thu Nov 20 17:51:17 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 20 Nov 2003 10:51:17 -0600 (CST)
Subject: [R] nls, nlrq, and box-cox transformation
In-Reply-To: <Pine.LNX.4.44.0311201437490.21062-100000@gannet.stats>
Message-ID: <Pine.SOL.4.30.0311201027120.13122-100000@ysidro.econ.uiuc.edu>





On Thu, 20 Nov 2003, Prof Brian Ripley wrote:

>
> Now nlrq uses a different criterion and Philippe's suggestion may work
> there.  I can't tell quickly: the help page does not say what the
> criterion is.  But if those are the same, then I suspect the criterion is
> uninteresting as a way to choose t, since two of the three aims of
> Box-Cox are to stabilize the distribution of lhs - rhs.

One of the advantages of the quantile regression fitting criterion in
this circumstance is that it is only _trying_ to accomplish one objective
instead of three, i.e. to deal with the nonlinearity.  One still needs,
as in the Gaussian case to worry about the Jacobian of the transformation
from u -> y, but this can be fixed by the usual rescaling of the response
by its geometric mean as in e.g. Atkinson, Plots, Transformations, and
Regression, p 86-7.

url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From yukangtu at hotmail.com  Thu Nov 20 18:12:41 2003
From: yukangtu at hotmail.com (Tu Yu-Kang)
Date: Thu, 20 Nov 2003 17:12:41 +0000
Subject: [R] p value in MANOVA
Message-ID: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>

Dear R users,

Can anyone tell me how to get the p value out of the output from 
summary.manova?

I tried all the methods I can think of, but failed.

Many thanks

Yu-Kang

_________________________________________________________________
Y MSN Mobile AGbzWo MSN Hotmail 
http://msn.com.tw/msnmobile



From marlene.mueller at gmx.de  Thu Nov 20 18:35:29 2003
From: marlene.mueller at gmx.de (Marlene Mueller)
Date: Thu, 20 Nov 2003 18:35:29 +0100
Subject: [R] RMySQL_5.2 SuSE9.0
In-Reply-To: <008101c3aebb$4b255100$9307ebd9@xxlarwv7waunej>
References: <008101c3aebb$4b255100$9307ebd9@xxlarwv7waunej>
Message-ID: <3FBCFB61.6020705@gmx.de>


My guess is that gcc cannot find libz, which most
likely means that you do not have installed the
development version of it. Search for libz or zlib
in yast2.

Hope that helps, Marlene



Christian Schulz wrote:
> Hi,
> i try to install, but getting no success.
> What this mean cannot find -lz , any necessary 
> lib left in my SuSE Installation?
> 
> Many thanks, Christian
> 
> 
> linux:/usr/lib/R/bin # R CMD  INSTALL RMySQL_0.5-2.tar.gz
> * Installing *source* package 'RMySQL' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> checking for mysql_init in -lmysqlclient... yes
> checking for mysql.h... no
> checking for /usr/local/include/mysql/mysql.h... no
> checking for /usr/include/mysql/mysql.h... yes
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars
> ** libs
> gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC   -c RS-DBI.c -o RS-DBI.o
> gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC   -c RS-MySQL.c -o RS-MySQL.o
> gcc -shared -L/usr/local/lib -o RMySQL.so RS-DBI.o RS-MySQL.o -lmysqlclient -lz -L/usr/lib/R/bin -lR
> /usr/lib/gcc-lib/i586-suse-linux/3.3.1/../../../../i586-suse-linux/bin/ld: cannot find -lz
> collect2: ld returned 1 exit status
> make: *** [RMySQL.so] Error 1
> ERROR: compilation failed for package 'RMySQL'
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
PD Dr. Marlene M?ller
Fraunhofer ITWM Kaiserslautern, Abt. Finanzmathematik
mailto:Marlene.Mueller at itwm.fhg.de, Tel/Fax: +49 631 205 4189/4139
http://www.itwm.fhg.de/de/fm__employees__mueller/mueller/



From krcabrer at unalmed.edu.co  Thu Nov 20 19:06:39 2003
From: krcabrer at unalmed.edu.co (Kenneth Cabrera)
Date: Thu, 20 Nov 2003 13:06:39 -0500
Subject: [R] ts format for daily time serie
Message-ID: <opryx69dwjfaouaq@200.24.8.4>

Hi R-users:

How can I format a daily time serie with ts function
so the plot of the time shows the date right
(dd/mm/yy) or yy.xxxx ?

Excerp of the database:

           FECHA     TRM
1    01/01/2000 1873.77
2    02/01/2000 1873.77
3    03/01/2000 1873.77
4    04/01/2000 1874.35
5    05/01/2000 1895.97
.
.
.
1397 10/11/2003 2843.82
1398 11/11/2003 2840.41
1399 12/11/2003 2840.41
1400 13/11/2003 2845.69
1401 14/11/2003 2850.24
1402 18/11/2003 2842.53
1403 19/11/2003 2831.97
1404 20/11/2003 2826.60


Thank you for your help.

--



From zeileis at ci.tuwien.ac.at  Thu Nov 20 19:15:33 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 20 Nov 2003 19:15:33 +0100
Subject: [R] ts format for daily time serie
In-Reply-To: <opryx69dwjfaouaq@200.24.8.4>
References: <opryx69dwjfaouaq@200.24.8.4>
Message-ID: <200311201815.hAKIFXpJ007381@thorin.ci.tuwien.ac.at>

On Thursday 20 November 2003 19:06, Kenneth Cabrera wrote:

> Hi R-users:
>
> How can I format a daily time serie with ts function
> so the plot of the time shows the date right
> (dd/mm/yy) or yy.xxxx ?

ts() only allows regulary spaced time series. Try the package its or 
the irts() function in package tseries for irregularly spaced time 
series.

hth,
Z

> Excerp of the database:
>
>            FECHA     TRM
> 1    01/01/2000 1873.77
> 2    02/01/2000 1873.77
> 3    03/01/2000 1873.77
> 4    04/01/2000 1874.35
> 5    05/01/2000 1895.97
> .
> .
> .
> 1397 10/11/2003 2843.82
> 1398 11/11/2003 2840.41
> 1399 12/11/2003 2840.41
> 1400 13/11/2003 2845.69
> 1401 14/11/2003 2850.24
> 1402 18/11/2003 2842.53
> 1403 19/11/2003 2831.97
> 1404 20/11/2003 2826.60
>
>
> Thank you for your help.



From MSchwartz at medanalytics.com  Thu Nov 20 19:19:54 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 20 Nov 2003 12:19:54 -0600
Subject: [R] p value in MANOVA
In-Reply-To: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>
References: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>
Message-ID: <1069352393.5636.205.camel@localhost.localdomain>

On Thu, 2003-11-20 at 11:12, Tu Yu-Kang wrote:
> Dear R users,
> 
> Can anyone tell me how to get the p value out of the output from 
> summary.manova?
> 
> I tried all the methods I can think of, but failed.
> 
> Many thanks
> 
> Yu-Kang


Using the example in ?summary.manova:

## Example on producing plastic film from Krzanowski (1998, p. 381)
tear <- c(6.5, 6.2, 5.8, 6.5, 6.5, 6.9, 7.2, 6.9, 6.1, 6.3,
          6.7, 6.6, 7.2, 7.1, 6.8, 7.1, 7.0, 7.2, 7.5, 7.6)
gloss <- c(9.5, 9.9, 9.6, 9.6, 9.2, 9.1, 10.0, 9.9, 9.5, 9.4,
           9.1, 9.3, 8.3, 8.4, 8.5, 9.2, 8.8, 9.7, 10.1, 9.2)
opacity <- c(4.4, 6.4, 3.0, 4.1, 0.8, 5.7, 2.0, 3.9, 1.9, 5.7,
             2.8, 4.1, 3.8, 1.6, 3.4, 8.4, 5.2, 6.9, 2.7, 1.9)
Y <- cbind(tear, gloss, opacity)
rate <- factor(gl(2,10), labels=c("Low", "High"))
additive <- factor(gl(2, 5, len=20), labels=c("Low", "High"))
fit <- manova(Y ~ rate * additive)

summary(fit) results in:

> summary(fit)
              Df Pillai approx F num Df den Df   Pr(>F)   
rate           1 0.6181   7.5543      3     14 0.003034 **
additive       1 0.4770   4.2556      3     14 0.024745 * 
rate:additive  1 0.2229   1.3385      3     14 0.301782   
Residuals     16                                          
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 


To get just the p values, you would use:

> summary(fit)$stats[1:3, "Pr(>F)"]
         rate      additive rate:additive 
  0.003034045   0.024745281   0.301781645 

and if you just want just the numbers as a vector:

> as.numeric(summary(fit)$stats[1:3, "Pr(>F)"])
[1] 0.003034045 0.024745281 0.301781645



To gain some insight into how to get to the above, ?summary.manova tells
you that the values returned by the method are in a list with one
component being 'stats'. Alternatively, you can use:

str(summary(fit))

which will give you the details of the internal structure of the list
object returned by summary.manova(). See ?str for more information.

The output of the above includes the following:

...
 $ stats      : num [1:4, 1:6]  1.000  1.000  1.000 16.000  0.618 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:4] "rate" "additive" "rate:additive" "Residuals"
  .. ..$ : chr [1:6] "Df" "Pillai" "approx F" "num Df" ...
...

This tells you that summary(fit)$stats is a 4 x 6 matrix in this
example.

Then to get the complete list of dimnames for 'stats' use:

> dimnames(summary(fit)$stats) 
[[1]]
[1] "rate"          "additive"      "rate:additive" "Residuals"    

[[2]]
[1] "Df"       "Pillai"   "approx F" "num Df"   "den Df"   "Pr(>F)"  


So to get the p values, you want the first three rows (in this case) and
the "Pr(>F)" column, hence:

summary(fit)$stats[1:3, "Pr(>F)"]

HTH,

Marc Schwartz



From forkusam at yahoo.com  Thu Nov 20 19:21:49 2003
From: forkusam at yahoo.com (forkusam)
Date: Thu, 20 Nov 2003 10:21:49 -0800 (PST)
Subject: [R] reading data rows
Message-ID: <20031120182149.55302.qmail@web10501.mail.yahoo.com>

 I have problems reading a file with more than one row
to carry out mathematical calculations 

I have a a file  of the form 
mu1	mu2	alpha	beta	Wsigma sigmaA  b  r 
25	15	.05	.05	22	 3	  .3	.5
30	20	.1	.2	22	.3	  .3	.5

 I intend to read one row , carry out the calculations
and then the next row with which I intend to do the
same calculations.
I do the following.
p<-read.table(file="eingabe.csv", header=TRUE,sep=";")
	
data.frame(as.numeric(mu1<-p$mu1),as.numeric(mu2<-p$mu2),
		  
as.numeric(alpha<-p$alpha),as.numeric(beta<-p$beta),
		  
as.numeric(Wsigma<-p$Wsigma),as.numeric(sigmaA<-p$sigmaA),as.numeric(b<-p$b),as.numeric(r<-p$r))

I intend to  use the variables stored in the the data
frame for my caculations. but each time I try I get
the  followingerror message.

Error in uniroot(function(n) eval(p.body) - power,
c(2, 1e+07)) : 
        invalid function value in 'zeroin'
In addition: Warning message: 
the condition has length > 1 and only the first
element will be used in: if (f(lower, ...) * f(upper,
...) >= 0) stop("f() values at end points not of
opposite sign")

...which I do not get when I use just one row.

Thanks
sylvie


=====
=====================
Sylvie B. Forkusam
Eppelheimer Str.52/A2-5-2
69115 Heidelberg, Germany
Tel: (0049)-06221/346913
Mobile: 0179-6816276
=======================

__________________________________

Free Pop-Up Blocker - Get it now



From ripley at stats.ox.ac.uk  Thu Nov 20 19:35:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 18:35:10 +0000 (GMT)
Subject: [R] p value in MANOVA
In-Reply-To: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>
Message-ID: <Pine.LNX.4.44.0311201831090.21598-100000@gannet.stats>

Hint: print.summary.manova manages it.  Try

example(summary.manova)
summary(fit, test="Wilks")$stats[,"Pr(>F)"]


On Thu, 20 Nov 2003, Tu Yu-Kang wrote:

> Can anyone tell me how to get the p value out of the output from 
> summary.manova?
> 
> I tried all the methods I can think of, but failed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Nov 20 19:38:11 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 18:38:11 +0000 (GMT)
Subject: [R] ts format for daily time serie
In-Reply-To: <opryx69dwjfaouaq@200.24.8.4>
Message-ID: <Pine.LNX.4.44.0311201835210.21598-100000@gannet.stats>

It's probably best to handle this an an x-y plot (?plot.POSIXct) or as an
irregular time series (see package its on CRAN).

The ts function is designed for time series that you want to do 
time-series analysis on.

On Thu, 20 Nov 2003, Kenneth Cabrera wrote:

> Hi R-users:
> 
> How can I format a daily time serie with ts function
> so the plot of the time shows the date right
> (dd/mm/yy) or yy.xxxx ?
> 
> Excerp of the database:
> 
>            FECHA     TRM
> 1    01/01/2000 1873.77
> 2    02/01/2000 1873.77
> 3    03/01/2000 1873.77
> 4    04/01/2000 1874.35
> 5    05/01/2000 1895.97
> .
> .
> .
> 1397 10/11/2003 2843.82
> 1398 11/11/2003 2840.41
> 1399 12/11/2003 2840.41
> 1400 13/11/2003 2845.69
> 1401 14/11/2003 2850.24
> 1402 18/11/2003 2842.53
> 1403 19/11/2003 2831.97
> 1404 20/11/2003 2826.60


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From krcabrer at unalmed.edu.co  Thu Nov 20 19:53:45 2003
From: krcabrer at unalmed.edu.co (Kenneth Cabrera)
Date: Thu, 20 Nov 2003 13:53:45 -0500
Subject: [R] ts format for daily time serie
In-Reply-To: <Pine.LNX.4.44.0311201835210.21598-100000@gannet.stats>
References: <Pine.LNX.4.44.0311201835210.21598-100000@gannet.stats>
Message-ID: <opryx9fvuffaouaq@200.24.8.4>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> It's probably best to handle this an an x-y plot (?plot.POSIXct) or as an
> irregular time series (see package its on CRAN).

A daily time serie is not a regulary spaced time serie?
>
> The ts function is designed for time series that you want to do
> time-series analysis on.

That is what I want, make time-series analysis, but at the same
time I want to plot it directly.

Achim Zeileis <zeileis at ci.tuwien.ac.at> wrote:
> ts() only allows regulary spaced time series. Try the package its or the 
> irts() function in package tseries for irregularly spaced time series.

> hth,
> Z

A daily time serie is not a regulary spaced time serie?



>> Excerp of the database:
>>
>>            FECHA     TRM
>> 1    01/01/2000 1873.77
>> 2    02/01/2000 1873.77
>> 3    03/01/2000 1873.77
>> 4    04/01/2000 1874.35
>> 5    05/01/2000 1895.97
>> .
>> .
>> .
>> 1397 10/11/2003 2843.82
>> 1398 11/11/2003 2840.41
>> 1399 12/11/2003 2840.41
>> 1400 13/11/2003 2845.69
>> 1401 14/11/2003 2850.24
>> 1402 18/11/2003 2842.53
>> 1403 19/11/2003 2831.97
>> 1404 20/11/2003 2826.60



From Roger.Bivand at nhh.no  Thu Nov 20 19:51:32 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 20 Nov 2003 19:51:32 +0100 (CET)
Subject: [R] Reading JPG files within R
In-Reply-To: <002c01c3a438$23b73940$0100000a@freegenius>
Message-ID: <Pine.LNX.4.44.0311201945120.580-100000@reclus.nhh.no>

On Thu, 6 Nov 2003, Paolo Sirabella wrote:

> Dear R-listers,
> I am an enthusiastic new to R and have the following simple (. I hope .)
> problem:
> I am searching a function that allows to import jpg files as matrices (n
> x m x 3) i.e. n_pixels x m_pixels x 3_colors.
> I have seen the pixmap library, but it seems able only to read BMP
> pictures (and not all them .).

I don't think your question was answered straight away, and maybe you have 
found a solution yourself. Typically, you can convert your JPG to the 
format handled by the pixmap package, PPM, in a graphics utility such as 
ImageMagick on Windows or Unix/Linux, and then use pixmap, which gives you 
an array in its pixmapRGB form.

> Can someone give me some suggestions ? 
> Thank you in advance.
>  
> =========================================
> Paolo Sirabella
> University of Rome "La Sapienza" - Rome - Italy
> Dept. of Human Physiology and Pharmacology
> Biophysiscs Group
> =========================================
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From zeileis at ci.tuwien.ac.at  Thu Nov 20 20:02:11 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 20 Nov 2003 20:02:11 +0100
Subject: [R] ts format for daily time serie
In-Reply-To: <opryx9fvuffaouaq@200.24.8.4>
References: <Pine.LNX.4.44.0311201835210.21598-100000@gannet.stats>
	<opryx9fvuffaouaq@200.24.8.4>
Message-ID: <200311201902.hAKJ2Bjb007716@thorin.ci.tuwien.ac.at>

On Thursday 20 November 2003 19:53, Kenneth Cabrera wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > It's probably best to handle this an an x-y plot (?plot.POSIXct)
> > or as an irregular time series (see package its on CRAN).
>
> A daily time serie is not a regulary spaced time serie?
>
> > The ts function is designed for time series that you want to do
> > time-series analysis on.
>
> That is what I want, make time-series analysis, but at the same
> time I want to plot it directly.
>
> Achim Zeileis <zeileis at ci.tuwien.ac.at> wrote:
> > ts() only allows regulary spaced time series. Try the package its
> > or the irts() function in package tseries for irregularly spaced
> > time series.
> >
> > hth,
> > Z
>
> A daily time serie is not a regulary spaced time serie?

Not if it has gaps like in the excerpt of your data given below. 
Furthermore the frequency is not exactly 365.
Z

> >> Excerp of the database:
> >>
> >>            FECHA     TRM
> >> 1    01/01/2000 1873.77
> >> 2    02/01/2000 1873.77
> >> 3    03/01/2000 1873.77
> >> 4    04/01/2000 1874.35
> >> 5    05/01/2000 1895.97
> >> .
> >> .
> >> .
> >> 1397 10/11/2003 2843.82
> >> 1398 11/11/2003 2840.41
> >> 1399 12/11/2003 2840.41
> >> 1400 13/11/2003 2845.69
> >> 1401 14/11/2003 2850.24
> >> 1402 18/11/2003 2842.53
> >> 1403 19/11/2003 2831.97
> >> 1404 20/11/2003 2826.60
>
> Using M2, Opera's revolutionary e-mail client:
> http://www.opera.com/m2/



From kwan022 at stat.auckland.ac.nz  Thu Nov 20 20:08:25 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 21 Nov 2003 08:08:25 +1300 (NZDT)
Subject: [R] reading data rows
In-Reply-To: <20031120182149.55302.qmail@web10501.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0311210805450.25123-100000@stat61.stat.auckland.ac.nz>

Hi,

On Thu, 20 Nov 2003, forkusam wrote:

> to carry out mathematical calculations 
> 
> I have a a file  of the form 
> mu1	mu2	alpha	beta	Wsigma sigmaA  b  r 
> 25	15	.05	.05	22	 3	  .3	.5
> 30	20	.1	.2	22	.3	  .3	.5
> 
>  I intend to read one row , carry out the calculations
> and then the next row with which I intend to do the
> same calculations.
> I do the following.
> p<-read.table(file="eingabe.csv", header=TRUE,sep=";")
> 	
> data.frame(as.numeric(mu1<-p$mu1),as.numeric(mu2<-p$mu2),
> 		  
> as.numeric(alpha<-p$alpha),as.numeric(beta<-p$beta),
> 		  
> as.numeric(Wsigma<-p$Wsigma),as.numeric(sigmaA<-p$sigmaA),as.numeric(b<-p$b),as.numeric(r<-p$r))

Is there any particular reason why you want to do this data.frame() line?  
To me it seems redundant.  Each column is already in numeric/vector form,  
I believe.

> Error in uniroot(function(n) eval(p.body) - power,
> c(2, 1e+07)) : 
>         invalid function value in 'zeroin'
> In addition: Warning message: 
> the condition has length > 1 and only the first
> element will be used in: if (f(lower, ...) * f(upper,
> ...) >= 0) stop("f() values at end points not of
> opposite sign")

What kind of mathematical calculations were you trying to do when you got 
this error message?  As discussed off-list last night, since you want to 
operate on each row using the same operation, have you tried using 
apply()?

-- 
Cheers,

Kevin

---------------------------------------------------------------
"Try not.  Do, do!  Or do not.  There is no try"
   Jedi Master Yoda

----
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From rvaradha at jhsph.edu  Thu Nov 20 20:28:21 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Thu, 20 Nov 2003 14:28:21 -0500
Subject: [R] TISEAN and nonlinear time series
Message-ID: <ae8dc2ae8f0b.ae8f0bae8dc2@jhsph.edu>

Hi:

Has anyone linked TISEAN, which is a nonlinear time series analysis 
package developed by Schreiber et al., with R?  If not, are there 
similar tools based on the phase-space representation of an observed 
time series?

thanks,
Ravi.



From anthony_staines at hotmail.com  Thu Nov 20 20:37:43 2003
From: anthony_staines at hotmail.com (anthony staines)
Date: Thu, 20 Nov 2003 19:37:43 +0000
Subject: [R] Problem with Trellis graphics in nlme
Message-ID: <Law11-F56tWdWhkeLZs0001874c@hotmail.com>

Hi,
I would be grateful for help with a problem which is irritating me.
I am quite sure that I am doing something stupid, but I can't see what it 
is.

I am running R 1.7 on Windows 2000. The graphics device is the PC screen.

The graphics from the nlme demonstration in Bates an Pinheiro's manual work 
just as advertised. The CO2 data and the Orthodont data dsiplay 
beautifully.(plot(Orthodont, outer=true, key=false)  However. when I try to 
analyse a data set of my own, of about 2,770 measurements on 293 women the 
graphics go very peculiar. The graphics in the example from the manual fill 
most of the vertical extent of the graphics device. My graphics are correct 
horizontally, but are confined to about one-fifth of the vertical extent of 
the graphics device. As a result they look odd, and are almost usless for 
analysis. They do seem, however, to be the correct graphics (In this case 
maternal weight against gestational age for two groups of women).

I have read the manual for the lattice commands, and the nlme command, and 
indeed for the plain plot command, but failed to get any ideas. Roughly, I 
need to tell lattice to use the full vertical extent of the display device. 
If it helps, I can e-mail the offending images to you individually on 
request.

Anthony Staines,
Public Health,
UCD



From spencer.graves at pdf.com  Thu Nov 20 20:43:57 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 20 Nov 2003 11:43:57 -0800
Subject: [R] Problem with Trellis graphics in nlme
In-Reply-To: <Law11-F56tWdWhkeLZs0001874c@hotmail.com>
References: <Law11-F56tWdWhkeLZs0001874c@hotmail.com>
Message-ID: <3FBD197D.1050602@pdf.com>

I see you mentioned the Bates and Pinhiero manual, but I didn't see 
Bates and Pinhiero (2000) Mixed-Effects Models in S and S-Plus 
(Springer).  Have you also looked at this? 

hope this helps.  spencer graves

anthony staines wrote:

> Hi,
> I would be grateful for help with a problem which is irritating me.
> I am quite sure that I am doing something stupid, but I can't see what 
> it is.
>
> I am running R 1.7 on Windows 2000. The graphics device is the PC screen.
>
> The graphics from the nlme demonstration in Bates an Pinheiro's manual 
> work just as advertised. The CO2 data and the Orthodont data dsiplay 
> beautifully.(plot(Orthodont, outer=true, key=false)  However. when I 
> try to analyse a data set of my own, of about 2,770 measurements on 
> 293 women the graphics go very peculiar. The graphics in the example 
> from the manual fill most of the vertical extent of the graphics 
> device. My graphics are correct horizontally, but are confined to 
> about one-fifth of the vertical extent of the graphics device. As a 
> result they look odd, and are almost usless for analysis. They do 
> seem, however, to be the correct graphics (In this case maternal 
> weight against gestational age for two groups of women).
>
> I have read the manual for the lattice commands, and the nlme command, 
> and indeed for the plain plot command, but failed to get any ideas. 
> Roughly, I need to tell lattice to use the full vertical extent of the 
> display device. If it helps, I can e-mail the offending images to you 
> individually on request.
>
> Anthony Staines,
> Public Health,
> UCD
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.pagel at gsf.de  Thu Nov 20 20:47:31 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Thu, 20 Nov 2003 20:47:31 +0100
Subject: [R] reading data rows
In-Reply-To: <20031120182149.55302.qmail@web10501.mail.yahoo.com>
References: <20031120182149.55302.qmail@web10501.mail.yahoo.com>
Message-ID: <20031120194731.GA2160@porcupine.gsf.de>


On Thu, Nov 20, 2003 at 10:21:49AM -0800, forkusam wrote:
>  I have problems reading a file with more than one row
> to carry out mathematical calculations 
> 
> I have a a file  of the form 
> mu1	mu2	alpha	beta	Wsigma sigmaA  b  r 
> 25	15	.05	.05	22	 3	  .3	.5
> 30	20	.1	.2	22	.3	  .3	.5
> 
>  I intend to read one row , carry out the calculations
> and then the next row with which I intend to do the
> same calculations.

Although you can read the file line by line I guess you actually want to
read the whole table and then perform your calculations on the resulting
data frame.

> I do the following.
> p<-read.table(file="eingabe.csv", header=TRUE,sep=";")

Your file is not separated by ';'! From what you show above I guess it's
tab-separated - or maybe by variying numbers of spaces. Assuming tabs
this will read the entire file:

p <- read.table('eingabe.csv', header=T, sep='\t')


> data.frame(as.numeric(mu1<-p$mu1),as.numeric(mu2<-p$mu2),
> as.numeric(alpha<-p$alpha),as.numeric(beta<-p$beta),
> as.numeric(Wsigma<-p$Wsigma),as.numeric(sigmaA<-p$sigmaA),as.numeric(b<-p$b),as.numeric(r<-p$r))

I'm totally confused about this. First, p is already a data frame.
Second, the columns are already of type numeric or int after correctly
reading the file - so as.numeric is not needed here. You should
probably read 'An Introduction to R', especially the section on lists
and data frames and the one about reading data from files.

> I intend to use the variables stored in the the data
> frame for my caculations. but each time I try I get
> the  followingerror message.
> 
> Error in uniroot(function(n) eval(p.body) - power,
> c(2, 1e+07)) : 
>         invalid function value in 'zeroin'
> In addition: Warning message: 
> the condition has length > 1 and only the first
> element will be used in: if (f(lower, ...) * f(upper,
> ...) >= 0) stop("f() values at end points not of
> opposite sign")
> 
> ...which I do not get when I use just one row.

Since you didn't say what calculation you were attempting I can't even
guess, what is going on. Maybe you can tell us what the goal of all this
is and what commands you were using ...

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From Natalia.BAHAMONDE at lss.supelec.fr  Thu Nov 20 20:28:51 2003
From: Natalia.BAHAMONDE at lss.supelec.fr (Natalia BAHAMONDE)
Date: Thu, 20 Nov 2003 20:28:51 +0100
Subject: [R] acf with NA?
Message-ID: <1069356531.3fbd15f374656@courrier.lss.supelec.fr>

Hello

I?m a PhD student and I?m working with covariance function.

I?m interested to know how R to work the acf function with missing values.
I like to know what is exactly the estimation process in this case and where I 
can to find the function .C(?acf?).

Thanks, Natalia Bahamonde




-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From ripley at stats.ox.ac.uk  Thu Nov 20 21:41:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2003 20:41:42 +0000 (GMT)
Subject: [R] acf with NA?
In-Reply-To: <1069356531.3fbd15f374656@courrier.lss.supelec.fr>
Message-ID: <Pine.LNX.4.44.0311202041040.25612-100000@gannet.stats>

It's in the source code, and that is on the same server you got  R from.

On Thu, 20 Nov 2003, Natalia BAHAMONDE wrote:

> I?m a PhD student and I?m working with covariance function.
> 
> I?m interested to know how R to work the acf function with missing values.
> I like to know what is exactly the estimation process in this case and where I 
> can to find the function .C(?acf?).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ercan971 at aol.com  Thu Nov 20 21:50:59 2003
From: Ercan971 at aol.com (Ercan971@aol.com)
Date: Thu, 20 Nov 2003 15:50:59 EST
Subject: [R] Fracpoly
Message-ID: <ad.365cbc04.2cee8333@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031120/b90f3b67/attachment.pl

From Ercan971 at aol.com  Thu Nov 20 22:11:49 2003
From: Ercan971 at aol.com (Ercan971@aol.com)
Date: Thu, 20 Nov 2003 16:11:49 EST
Subject: [R] Fractional polynomials
Message-ID: <1ac.1d343117.2cee8815@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031120/d59e17df/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Nov 20 22:34:41 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Nov 2003 22:34:41 +0100
Subject: [R] Fracpoly
References: <ad.365cbc04.2cee8333@aol.com>
Message-ID: <3FBD3371.D904765D@statistik.uni-dortmund.de>



Ercan971 at aol.com wrote:
> 
> How can I find the Fracpoly-Package?
> Thanks!!

I don't know of any "fracpoly" package in R. There is a set of S(-PLUS)
functions called "fracpoly" on Statlib, though.

Uwe Ligges



From Paul.Sorenson at vision-bio.com  Thu Nov 20 22:37:58 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Fri, 21 Nov 2003 08:37:58 +1100
Subject: [R] model tutorial
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C602C2B6F0@ewok.vsl.com.au>

The help and man pages of R discuss the model syntax eg a ~ b.  They kind of just appear as if everyone knows why - I must be a bit of a mug.

Are there any tutorial style documents around on this topic?

cheers



From ligges at statistik.uni-dortmund.de  Thu Nov 20 22:43:45 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Nov 2003 22:43:45 +0100
Subject: [R] TISEAN and nonlinear time series
References: <ae8dc2ae8f0b.ae8f0bae8dc2@jhsph.edu>
Message-ID: <3FBD3591.3250E70@statistik.uni-dortmund.de>



Ravi Varadhan wrote:
> 
> Hi:
> 
> Has anyone linked TISEAN, which is a nonlinear time series analysis
> package developed by Schreiber et al., with R?  If not, are there
> similar tools based on the phase-space representation of an observed
> time series?
> 
> thanks,
> Ravi.
> 

AFAIK, TISEAN consists of a couple of executables. I don't think anybody
has really linked it to R.

But from R it's pretty easy to write data appropriatly to a file and
call TISEAN via a shell() command (at least one of my colleagues did so
...).

Uwe Ligges



From andy_liaw at merck.com  Thu Nov 20 22:45:58 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 20 Nov 2003 16:45:58 -0500
Subject: [R] Fracpoly
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE6A@usrymx25.merck.com>

> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> 
> Ercan971 at aol.com wrote:
> > 
> > How can I find the Fracpoly-Package?
> > Thanks!!
> 
> I don't know of any "fracpoly" package in R. There is a set 
> of S(-PLUS) functions called "fracpoly" on Statlib, though.

There used to be.  I believe I posted a link to R-help the last time someone
asked.

Andy
 
> Uwe Ligges



From andy_liaw at merck.com  Thu Nov 20 22:56:12 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 20 Nov 2003 16:56:12 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE6B@usrymx25.merck.com>

> From: Nirmal Govind [mailto:nirmalg at psu.edu] 
> 
> Thanks for your reply, Prof. Ripley.
> 
> > And all of that is explained in the reference on the aov help page. 
> > Please do stop speculating and start reading.
> 
> Well, the reason for speculation was cos I couldn't find any 
> details on 
> that help page... thanks for letting me know that the 
> reference explains 
> this...
> 
> > AoV has nothing to do with coefficients.  There is 
> dummy.coef to get 
> > uncoded coefficients, and there is options(contrasts=) to set the 
> > coding.
> 
> Ok, I will try these...
> 
> > Yes, you should read a lot more.  Chapter 6 of Venables & Ripley 
> > (2002)
> > and chapter 5 of Chambers & Hastie (1991) would be a good start.
> 
> Oh, I most definitely should! :-) .. I guess I was hoping that such 
> details would be included in the help page for the function 
> or mentioned 
> in some R introduction or tutorial or so on the Documentation page.. 
> looks like that's not the case so I'll get a hold of the 
> books above...
> 
> Thanks,
> nirmal

It's unreasonable to expect stat software documentation to also serve as
textbooks or reference books.  What you have not learned in a course can not
be made up just by reading help pages.  That's not the purpose of help
pages.

Andy



From zeileis at ci.tuwien.ac.at  Thu Nov 20 22:55:07 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 20 Nov 2003 22:55:07 +0100
Subject: [R] Fracpoly
In-Reply-To: <3FBD3371.D904765D@statistik.uni-dortmund.de>
References: <ad.365cbc04.2cee8333@aol.com>
	<3FBD3371.D904765D@statistik.uni-dortmund.de>
Message-ID: <200311202155.hAKLt7mw011078@thorin.ci.tuwien.ac.at>

On Thursday 20 November 2003 22:34, Uwe Ligges wrote:

> Ercan971 at aol.com wrote:
> > How can I find the Fracpoly-Package?
> > Thanks!!
>
> I don't know of any "fracpoly" package in R. There is a set of
> S(-PLUS) functions called "fracpoly" on Statlib, though.

I don't know of a "fracpoly" package either, but entering "fracpoly R" 
in google guides you to Gareth Ambler's homepage who seems to provide 
some R functions for fractional polynomial models.
Z

  http://www.homepages.ucl.ac.uk/~ucakgam/r/

> Uwe Ligges
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Thu Nov 20 23:02:33 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 20 Nov 2003 17:02:33 -0500 (EST)
Subject: [R] Problem with Trellis graphics in nlme
In-Reply-To: <Law11-F56tWdWhkeLZs0001874c@hotmail.com>
References: <Law11-F56tWdWhkeLZs0001874c@hotmail.com>
Message-ID: <Pine.SOL.4.58.0311201655100.10362@tetris.gpcc.itd.umich.edu>

Anthony  -

It seems just possible that the difficulty may have nothing to do
with  nlme() or any other data analysis.  The graph you describe
could result if one of the y-values was five time as large as any
of the others.  This could result from an error in reading the
data input file, a missing decimal point somewhere, etc.

In order to diagnose this, do  range(data$y)  (assuming that you
are plotting a data frame named "data" with a column named "y"),
then do

data[ data$y == max(data$y), ]

to look at just the offending row(s).

Another possibility is that somehow you are setting "ylim" in the
plotting command, but I assume you've excluded that one already.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 20 Nov 2003, anthony staines wrote:

> Hi,
> I would be grateful for help with a problem which is irritating me.
> I am quite sure that I am doing something stupid, but I can't see what it
> is.
>
> I am running R 1.7 on Windows 2000. The graphics device is the PC screen.
>
> The graphics from the nlme demonstration in Bates an Pinheiro's manual work
> just as advertised. The CO2 data and the Orthodont data dsiplay
> beautifully.(plot(Orthodont, outer=true, key=false)  However. when I try to
> analyse a data set of my own, of about 2,770 measurements on 293 women the
> graphics go very peculiar. The graphics in the example from the manual fill
> most of the vertical extent of the graphics device. My graphics are correct
> horizontally, but are confined to about one-fifth of the vertical extent of
> the graphics device. As a result they look odd, and are almost usless for
> analysis. They do seem, however, to be the correct graphics (In this case
> maternal weight against gestational age for two groups of women).
>
> I have read the manual for the lattice commands, and the nlme command, and
> indeed for the plain plot command, but failed to get any ideas. Roughly, I
> need to tell lattice to use the full vertical extent of the display device.
> If it helps, I can e-mail the offending images to you individually on
> request.
>
> Anthony Staines,
> Public Health,
> UCD
>



From henric.nilsson at statisticon.se  Thu Nov 20 23:15:52 2003
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Thu, 20 Nov 2003 23:15:52 +0100
Subject: [R] Fracpoly
In-Reply-To: <ad.365cbc04.2cee8333@aol.com>
References: <ad.365cbc04.2cee8333@aol.com>
Message-ID: <6.0.0.22.0.20031120230701.04815488@10.0.10.66>

At 21:50 2003-11-20, you wrote:

>How can I find the Fracpoly-Package?

I'm not aware of a Fracpoly-Package. But Gareth Ambler has written a 
collection of functions that can be downloaded from 
http://www.homepages.ucl.ac.uk/~ucakgam/r/index.htm

//Henric



From nirmalg at psu.edu  Thu Nov 20 23:29:17 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Thu, 20 Nov 2003 17:29:17 -0500
Subject: [R] Difference in ANOVA results - R vs. JMP/Minitab
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE6B@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE6B@usrymx25.merck.com>
Message-ID: <3FBD403D.6000407@psu.edu>

> textbooks or reference books.  What you have not learned in a course can not
> be made up just by reading help pages.  That's not the purpose of help
> pages.
> 

Very true.. in this specific case, however, the objective was to figure 
out how to reconcile the differences between two software packages and 
it's more a question of how something is done in R (it's quite obvious 
how it's done in Minitab)... so the books on R or S I presume will 
explain this...

nirmal



From p.dalgaard at biostat.ku.dk  Thu Nov 20 23:43:21 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Nov 2003 23:43:21 +0100
Subject: [R] Fracpoly
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE6A@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE6A@usrymx25.merck.com>
Message-ID: <x2ekw2y83a.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> > From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> > 
> > Ercan971 at aol.com wrote:
> > > 
> > > How can I find the Fracpoly-Package?
> > > Thanks!!
> > 
> > I don't know of any "fracpoly" package in R. There is a set 
> > of S(-PLUS) functions called "fracpoly" on Statlib, though.
> 
> There used to be.  I believe I posted a link to R-help the last time someone
> asked.

On Gareth Ambler's (I suppose you have to become a statistician with a
name like that!) pages:

http://www.homepages.ucl.ac.uk/~ucakgam/r/index.htm 

The S-PLUS version has a non-commercial clause but that seems to be
absent from the R version.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From soofi at cs.ucla.edu  Thu Nov 20 23:38:35 2003
From: soofi at cs.ucla.edu (Amir Soofi)
Date: Thu, 20 Nov 2003 14:38:35 -0800
Subject: [R] incorporating R into C
Message-ID: <1a8d01c3afb7$0a1721f0$05182e04@asus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031120/c9392332/attachment.pl

From kjetil at entelnet.bo  Fri Nov 21 01:12:35 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Thu, 20 Nov 2003 20:12:35 -0400
Subject: [R] nls, nlrq, and box-cox transformation
In-Reply-To: <MABBLJDICACNFOLGIHJOCECADPAA.phgrosjean@sciviews.org>
References: <3FBCD77D.21682.13ECE8D@localhost>
Message-ID: <3FBD2033.15757.63977B@localhost>

On 20 Nov 2003 at 15:24, Philippe Grosjean wrote:

> >Dear r-help members
> >I posted this message already yesterday, but don't know whether it
> >reached you since I joined the group only yesterday. I would like to
> >estimate the boxcox transformed model
> > (y^t - 1)/t ~ b0 + b1 * x.
> >Unfortunately, R returns with an error message when I try to
> >perform this with the call
> >nls( I((y^t - 1)/t) ~ I(b0 + b1*x),
> >	start = c(t=1,b0=0,b1=0), data = mydataframe)
> 
> >The error message is:  Object "t" not found
> 
> >Apparently R seems not to accept parameters on the left hand
> >side of a regression model. I know that my do-it-yourself
> >strategy is not necessary, since the package box-cox is
> >available. Unfortunately, I want the use the box-cox
> >transformation in a quantile regression, i.e. I have to replace
> >nls by nlrq in the call above.
> 
> >Any suggestions?
> 
> >Thanks and best regards,
> >	Johannes Ludsteck
> 
> You suggest the solution yourself: transform the equation to have all
> parameters at the right, thus:
> 
> y ~ ((b0 + b1 * x) * t + 1) ^ 1/t
> 

Bit this is still not correct, since the transformation changes 
the scale of the variance, and lesat squares will not be correct. 
There is needed a factor (the jacobian) to compensate for this,

Kjetil Halvorsen

> (double check if this is correct)
> 
> Best,
> 
> Philippe Grosjean
> 
> ...........]<(({?<...............<?}))><..............................
> .
>  ) ) ) ) )
> ( ( ( ( (       Dr. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (       Numerical Ecology Laboratory
>  ) ) ) ) )      Mons-Hainaut University
> ( ( ( ( (       8, Av. du Champ de Mars, 7000 Mons
>  ) ) ) ) )      Belgium
> ( ( ( ( (
>  ) ) ) ) )      e-mail: phgrosjean at sciviews.org
> ( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
>  ) ) ) ) )
> ......................................................................
> .
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From angel_lul at hotmail.com  Mon Nov 17 22:19:12 2003
From: angel_lul at hotmail.com (Angel)
Date: Mon, 17 Nov 2003 22:19:12 +0100
Subject: [R] ?for
References: <Pine.LNX.4.44.0311172026240.4841-100000@gannet.stats>
	<1069102724.4563.124.camel@localhost.localdomain>
Message-ID: <Law11-OE62rBHxvZ9aZ00000276@hotmail.com>

I thought I was getting to grips with it, until last reply from Prof Brian
Ripley's. At least in my Windows and Linux boxes
? paste("help")
opens the help for help (!?)
(But Marc is right, when you use emacs (in my Debian) instead of the shell
it gives the error he says, anybody knows why?)
For what I think I've learned, when you call ? it first evaluates the topic
and then asks for help on the result, i.e. if you put a function after ? it
will call help on the return value of that function, if it is a for or other
type of flow control it will ask for help for each of the loop results. Is
this the explicit reply to my original answer??
Thanks,
Angel
----- Original Message -----
From: "Marc Schwartz" <MSchwartz at MedAnalytics.com>
To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
Cc: "Ray Brownrigg" <ray at mcs.vuw.ac.nz>; <r-help at stat.math.ethz.ch>;
<angel_lul at hotmail.com>; <p.dalgaard at biostat.ku.dk>
Sent: Monday, November 17, 2003 9:58 PM
Subject: Re: [R] ?for


> On Mon, 2003-11-17 at 14:27, Prof Brian Ripley wrote:
> > Well ^C or ESC (on Windows GUI) is the answer I would give.
> >
> > On Tue, 18 Nov 2003, Ray Brownrigg wrote:
> >
> > > Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
> > > >
> > > > Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> > > >
> > > > > You have typed a syntactically incomplete statement: this is
explained in
> > > > > ?help.
> > > > >
> > > > > Hint: ?"for" and help("for") work.
> > > >
> > > > [Original question added back in:
> > > > On Sun, 16 Nov 2003, Angel wrote:
> > > >
> > > > > I have always been intrigued by why ?for (or ?if,?while,etc) leave
R
> > > > > wanting for more:
> > > > > > ?for
> > > > > +
> > > > > I know the help for these is in ?Control, but I sometimes make the
> > > > > mistake of typing ?for instead. What is R expecting me to say to
finish
> > > > > the statement?
> > > > ]
> > > > Further hint: ? is an operator, syntactically similar to + and -.
You
> > > > can apply operators to the result of a for loop. Consider for
example
> > > >
> > > > x <- 1; - for (i in 1:10) x <- x * i
> > > >
> > > > (? has special semantics, but that is not noticed at parse time).
> > > >
> > > Unfortunately the original question still hasn't been answered
> > > explicitly, not even in ?help.
> > > Try:
> > > > ?for
> > > + (i in 0) 0
> > > or:
> > > > ?if
> > > + (T) T
> > > or:
> > > > ?+
> > > + 0
> > >
> > > So you have to provide the rest of a syntactically complete statement.
> > >
> > > Just to see if you now understand exactly how ? works, what do you
> > > think:
> > > ? paste("help")
> > > will do?
> > >
> > > Ray Brownrigg
>
>
> R 1.8.1 Beta using gnome-terminal on Fedora Core 1 gives:
>
> > ? paste("help")
> help() for paste  is shown in browser /usr/bin/mozilla ...
> Use      help( paste , htmlhelp=FALSE)
> or       options(htmlhelp = FALSE)
> to revert.
>
>
> However, using ESS with emacs on the same platform gives:
>
> > ? paste("help")
>
> Error in help("paste(", htmlhelp = FALSE) :
> No documentation for 'paste(' in specified packages and libraries:
>   you could try 'help.search("paste(")'
>
>
> :-)
>
> Marc
>
>
>
>



From rossini at blindglobe.net  Fri Nov 21 03:04:10 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 20 Nov 2003 18:04:10 -0800
Subject: [R] ?for
In-Reply-To: <Law11-OE62rBHxvZ9aZ00000276@hotmail.com> (Angel's message of
	"Mon, 17 Nov 2003 22:19:12 +0100")
References: <Pine.LNX.4.44.0311172026240.4841-100000@gannet.stats>
	<1069102724.4563.124.camel@localhost.localdomain>
	<Law11-OE62rBHxvZ9aZ00000276@hotmail.com>
Message-ID: <85u14yxysl.fsf@blindglobe.net>

"Angel" <angel_lul at hotmail.com> writes:

> I thought I was getting to grips with it, until last reply from Prof Brian
> Ripley's. At least in my Windows and Linux boxes
> ? paste("help")
> opens the help for help (!?)
> (But Marc is right, when you use emacs (in my Debian) instead of the shell
> it gives the error he says, anybody knows why?)

Yes.  Emacs/ESS takes stuff of the form ?name  and calls help("name")
on it.

This is a feature, not a bug.

best,
-tony

> For what I think I've learned, when you call ? it first evaluates the topic
> and then asks for help on the result, i.e. if you put a function after ? it
> will call help on the return value of that function, if it is a for or other
> type of flow control it will ask for help for each of the loop results. Is
> this the explicit reply to my original answer??
> Thanks,
> Angel
> ----- Original Message -----
> From: "Marc Schwartz" <MSchwartz at MedAnalytics.com>
> To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> Cc: "Ray Brownrigg" <ray at mcs.vuw.ac.nz>; <r-help at stat.math.ethz.ch>;
> <angel_lul at hotmail.com>; <p.dalgaard at biostat.ku.dk>
> Sent: Monday, November 17, 2003 9:58 PM
> Subject: Re: [R] ?for
>
>
>> On Mon, 2003-11-17 at 14:27, Prof Brian Ripley wrote:
>> > Well ^C or ESC (on Windows GUI) is the answer I would give.
>> >
>> > On Tue, 18 Nov 2003, Ray Brownrigg wrote:
>> >
>> > > Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
>> > > >
>> > > > Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>> > > >
>> > > > > You have typed a syntactically incomplete statement: this is
> explained in
>> > > > > ?help.
>> > > > >
>> > > > > Hint: ?"for" and help("for") work.
>> > > >
>> > > > [Original question added back in:
>> > > > On Sun, 16 Nov 2003, Angel wrote:
>> > > >
>> > > > > I have always been intrigued by why ?for (or ?if,?while,etc) leave
> R
>> > > > > wanting for more:
>> > > > > > ?for
>> > > > > +
>> > > > > I know the help for these is in ?Control, but I sometimes make the
>> > > > > mistake of typing ?for instead. What is R expecting me to say to
> finish
>> > > > > the statement?
>> > > > ]
>> > > > Further hint: ? is an operator, syntactically similar to + and -.
> You
>> > > > can apply operators to the result of a for loop. Consider for
> example
>> > > >
>> > > > x <- 1; - for (i in 1:10) x <- x * i
>> > > >
>> > > > (? has special semantics, but that is not noticed at parse time).
>> > > >
>> > > Unfortunately the original question still hasn't been answered
>> > > explicitly, not even in ?help.
>> > > Try:
>> > > > ?for
>> > > + (i in 0) 0
>> > > or:
>> > > > ?if
>> > > + (T) T
>> > > or:
>> > > > ?+
>> > > + 0
>> > >
>> > > So you have to provide the rest of a syntactically complete statement.
>> > >
>> > > Just to see if you now understand exactly how ? works, what do you
>> > > think:
>> > > ? paste("help")
>> > > will do?
>> > >
>> > > Ray Brownrigg
>>
>>
>> R 1.8.1 Beta using gnome-terminal on Fedora Core 1 gives:
>>
>> > ? paste("help")
>> help() for paste  is shown in browser /usr/bin/mozilla ...
>> Use      help( paste , htmlhelp=FALSE)
>> or       options(htmlhelp = FALSE)
>> to revert.
>>
>>
>> However, using ESS with emacs on the same platform gives:
>>
>> > ? paste("help")
>>
>> Error in help("paste(", htmlhelp = FALSE) :
>> No documentation for 'paste(' in specified packages and libraries:
>>   you could try 'help.search("paste(")'
>>
>>
>> :-)
>>
>> Marc
>>
>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From ray at mcs.vuw.ac.nz  Fri Nov 21 03:42:44 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Fri, 21 Nov 2003 15:42:44 +1300 (NZDT)
Subject: [R] ?for
Message-ID: <200311210242.hAL2gi9U004997@tahi.mcs.vuw.ac.nz>

> I thought I was getting to grips with it, until last reply from Prof Brian
> Ripley's. At least in my Windows and Linux boxes

Actually it was my reply that suggested ?paste("help")

> ? paste("help")
> opens the help for help (!?)

Not on my systems! [Solaris, NetBSD, Windows 98].  I believe it should
open the help for paste().

The point is that it requires a syntactically correct statement after
the ? so that the command parses correctly (with ? as a unary
operator), but the result is to provide the help for the first
syntactic element of the parsed expression, *without* evaluating the expression.

Ray Brownrigg



From WeiQiang.Li at seagate.com  Fri Nov 21 04:00:16 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Fri, 21 Nov 2003 11:00:16 +0800
Subject: [R] Who can provide me RWeb installation
Message-ID: <OF6C7EFE2C.D1535C07-ON48256DE5.0010353B-48256DE5.001090FD@notes.seagate.com>

Hi,
      RWeb web site is down past couple days, I am insterested in this
project and want to try it for my projects. Deos anyone have this
installation and user guide? Thanks!

Best  Regards,
WeiQiang Li



From WeiQiang.Li at seagate.com  Fri Nov 21 04:18:37 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Fri, 21 Nov 2003 11:18:37 +0800
Subject: [R] Who can provide me RWeb installation
Message-ID: <OFF2161040.53967B0F-ON48256DE5.0011D627-48256DE5.00123EEA@notes.seagate.com>

Hi Tom,
      Thanks for your quick reply.
      What I am trying is to access RWeb which is a R project under "R GUI"
and the address is shown as below:
            http://gauss.math.montana.edu/Rweb/Rweb.general.html
            http://gauss.math.montana.edu/Rweb/Resources.html

Thanks & Regards,
WeiQiang Li

----- Forwarded by WeiQiang Li/Seagate on 2003-11-21 11:15 -----
                                                                                                                                            
                      "Mulholland, Tom"                                                                                                     
                      <Tom.Mulholland at health        To:       <WeiQiang.Li at seagate.com>                                                     
                      .wa.gov.au>                   cc:                                                                                     
                      No Phone Info                 Subject:  RE: [R] Who can provide me RWeb installation                                  
                      Available                                                                                                             
                                                                                                                                            
                      2003-11-21 11:12                                                                                                      
                                                                                                                                            




I've just tried the site and it's there, but these are the mirrors

The Comprehensive R Archive Network is available at the following URLs,
please choose a location close to you:

Australia
http://cran.au.r-project.org  PlanetMirror
http://mirror.aarnet.edu.au/pub/CRAN  AARNet (accessible only from
Australia and New Zealand)

Austria
http://cran.at.r-project.org TU Wien

Brasil
http://cran.br.r-project.org Universidade Federal do Paran?
http://www.termix.ufv.br/CRAN Federal University of Vi?osa
http://lmq.esalq.usp.br/CRAN University of Sao Paulo, Piracicaba

Canada
http://probability.ca/cran/ University of Toronto

Denmark
http://cran.dk.r-project.org  SunSITE

France
http://mirrors.toulouse.inra.fr/R  INRA, Toulouse

Hungary
http://cran.hu.r-project.org Semmelweis University

Japan
ftp://ftp.u-aizu.ac.jp/pub/lang/R/CRAN/  University of Aizu

South Africa
http://cran.za.r-project.org  Rhodes University

Spain
http://cran.es.r-project.org  Spanish National Research Network, Madrid

Switzerland
http://cran.ch.r-project.org  ETH Z?rich

United Kingdom
http://cran.uk.r-project.org  University of Bristol
http://www.sourcekeg.co.uk/cran/  Sourcekeg

United States of America
http://cran.us.r-project.org  University of Wisconsin, Madison, WI
http://cran.stat.ucla.edu/  University of California, Los Angeles, CA
http://www.bioconductor.org/CRAN/  Dana Farber Cancer Institute, Boston, MA

http://cran.get-software.com  Get-Software.com, Augusta, ME
http://www.ibiblio.org/pub/languages/R/CRAN/  University of North Carolina,
Chapel Hill, NC
http://lib.stat.cmu.edu/R/CRAN/  Statlib, Carnegie Mellon University,
Pittsburgh, PA
http://cran.mirrors.pair.com/  Pair Networks, Pittsburgh, PA
http://www.binarycode.org/cran  BinaryCode.org, Austin, TX
http://mirrors.mix5.com/CRAN/  Mix5.com, Houston, TX

Many of these sites can also be accessed using FTP. In addition, several
StatLib mirrors around the world provide a complete CRAN mirror. Please let
us know if you want your server being added to the list of mirrors.

The CRAN master site at TU Wien, Austria, can be found at the URLs

http://cran.r-project.org
ftp://cran.r-project.org/pub/R/
rsync: cran.r-project.org::CRAN

Ciao, Tom

_________________________________________________

Tom Mulholland
Senior Policy Officer
WA Country Health Service
Tel: (08) 9222 4062

The contents of this e-mail transmission are confidential an...{{dropped}}



From rxg218 at psu.edu  Fri Nov 21 04:23:27 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 20 Nov 2003 22:23:27 -0500
Subject: [R] speeding up a pairwise correlation calculation
Message-ID: <1069385007.4193.4.camel@ra.chem.psu.edu>

Hi,
  I have a data.frame with 294 columns and 211 rows. I am calculating
correlations between all pairs of columns (excluding column 1) and based
on these correlation values I delete one column from any pair that shows
a R^2 greater than a cuttoff value. (Rather than directly delete the
column all I do is store the column number, and do the deletion later)

The code I am using is:

    ndesc <- length(names(data));
    for (i in 2:(ndesc-1)) {
        for (j in (i+1):ndesc) {

            if (i %in% drop || j %in% drop) next;
            
            r2 <- cor(data[,i],data[,j]);
            r2 <- r2*r2;

            if (r2 >= r2cut) {
                rnd <- abs(rnorm(1));
                if (rnd < 0.5) { drop <- c(drop,i); }
                else { drop <- c(drop,j); }
            }
        }
    }

drop is a vector that contains columns numbers that can be skipped
data is the data.frame

For the data.frame mentioned above (279 columns, 211 rows) the
calculation takes more than 7 minutes (after which I Ctrl-C'ed the
calculation). The machine is a 1GHz Duron with 1GB RAM

The output of version is:

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.1
year     2003
month    06
day      16
language R

I'm not too sure why it takes *so* long (I had done a similar
calculation in Python using list operations and it took forever), but is
there any trick that could be used to make this run faster or is this
type of runtime to be expected?

Thanks,
-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A red sign on the door of a physics professor: 
'If this sign is blue, you're going too fast.'



From spencer.graves at pdf.com  Fri Nov 21 04:55:33 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 20 Nov 2003 19:55:33 -0800
Subject: [R] speeding up a pairwise correlation calculation
In-Reply-To: <1069385007.4193.4.camel@ra.chem.psu.edu>
References: <1069385007.4193.4.camel@ra.chem.psu.edu>
Message-ID: <3FBD8CB5.9040403@pdf.com>

      Have you tried computing the correlation matrix using "cor" and 
then selecting variables to retain or drop from the resulting 
correlation matrix?  R uses vectorized arithmetic for operations like 
"cor".  By comparison, "for" loops are quite inefficient, requiring 
extra overhead for memory management and validity checking. 

      Alternatively, have you considered vectorizing the inner loop, 
something like the following: 

      ndesc <- dim(data)[2]
      Keep <- rep(TRUE, ndesc)
      for(i in 2:(ndesc-1)){
            if(any(K.i <- Keep[(i+1):ndesc])){          
                  cor.i <- cor(data[,i], data[,((i+1):ndesc)[K.i]])
                  ...<your selection criteria applied to Keep>  

      }

      Obviously, I haven't tested this specific code, but I hope it is 
adequate to illustrate the technique.  It might even be faster than 
either of the other options discussed. 

      hope this helps.  spencer graves

Rajarshi Guha wrote:

>Hi,
>  I have a data.frame with 294 columns and 211 rows. I am calculating
>correlations between all pairs of columns (excluding column 1) and based
>on these correlation values I delete one column from any pair that shows
>a R^2 greater than a cuttoff value. (Rather than directly delete the
>column all I do is store the column number, and do the deletion later)
>
>The code I am using is:
>
>    ndesc <- length(names(data));
>    for (i in 2:(ndesc-1)) {
>        for (j in (i+1):ndesc) {
>
>            if (i %in% drop || j %in% drop) next;
>            
>            r2 <- cor(data[,i],data[,j]);
>            r2 <- r2*r2;
>
>            if (r2 >= r2cut) {
>                rnd <- abs(rnorm(1));
>                if (rnd < 0.5) { drop <- c(drop,i); }
>                else { drop <- c(drop,j); }
>            }
>        }
>    }
>
>drop is a vector that contains columns numbers that can be skipped
>data is the data.frame
>
>For the data.frame mentioned above (279 columns, 211 rows) the
>calculation takes more than 7 minutes (after which I Ctrl-C'ed the
>calculation). The machine is a 1GHz Duron with 1GB RAM
>
>The output of version is:
>
>platform i686-pc-linux-gnu
>arch     i686
>os       linux-gnu
>system   i686, linux-gnu
>status
>major    1
>minor    7.1
>year     2003
>month    06
>day      16
>language R
>
>I'm not too sure why it takes *so* long (I had done a similar
>calculation in Python using list operations and it took forever), but is
>there any trick that could be used to make this run faster or is this
>type of runtime to be expected?
>
>Thanks,
>-------------------------------------------------------------------
>Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>-------------------------------------------------------------------
>A red sign on the door of a physics professor: 
>'If this sign is blue, you're going too fast.'
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From lkazembe at chanco.unima.mw  Fri Nov 21 05:51:01 2003
From: lkazembe at chanco.unima.mw (Lawrence Kazembe)
Date: Fri, 21 Nov 2003 06:51:01 +0200
Subject: [R] software for Log Gaussian Cox processes and Short-Noise G Cox
 processes
In-Reply-To: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>
References: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>
Message-ID: <200311210651010880.000C373B@216.252.252.194>

Is there an R package to implement the above spatial point processes.



Lawrence Kazembe

 
Lawrence Kazembe
Chancellor College
Mathematical Sciences Dept.
PO Box 280, Zomba
MALAWI.

Tel: +265 1 526 391(O)/ 1 527 850 (H)
Fax:+265 1 526 391
e-mail: lkazembe at chanco.unima.mw



From lkazembe at chanco.unima.mw  Fri Nov 21 05:56:12 2003
From: lkazembe at chanco.unima.mw (Lawrence Kazembe)
Date: Fri, 21 Nov 2003 06:56:12 +0200
Subject: [R] software for Log Gaussian Cox processes and Short-Noise G Cox
 processes
In-Reply-To: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>
References: <Law15-F74TIq8L7rW7c0002309b@hotmail.com>
Message-ID: <200311210656120537.0010F4BB@216.252.252.194>

Is there an R package to implement the above spatial point processes.



Lawrence Kazembe

 
Lawrence Kazembe
Chancellor College
Mathematical Sciences Dept.
PO Box 280, Zomba
MALAWI.

Tel: +265 1 526 391(O)/ 1 527 850 (H)
Fax:+265 1 526 391
e-mail: lkazembe at chanco.unima.mw



From rxg218 at psu.edu  Fri Nov 21 06:38:19 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 21 Nov 2003 00:38:19 -0500
Subject: [R] using a logical vector as a mask?
Message-ID: <1069393098.2382.1.camel@localhost.localdomain>

Hi,
  say I have a vector:

v <- c(1,2,3,NA,5,6,NA,7)

And I would like to set the elements that are NA to, say, 0

I can use is.na() to get a logical vector:

ind <- is.na(v)

Is there a way in which I can use this logical vector to set the NA
elements in v to 0?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
All great ideas are controversial, or have been at one time.



From ramasamya at gis.a-star.edu.sg  Fri Nov 21 06:54:35 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Fri, 21 Nov 2003 13:54:35 +0800
Subject: [R] speeding up a pairwise correlation calculation
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D56076023@BIONIC.biopolis.one-north.com>

You probably want to use runif() instead of rnorm() for equal
probability of selecting between i,j

Your algorithm is of order n^2 [ 294 choose 2, 293 choose 2, ... ], so
it should not be too slow. But two for() loops are inefficient in R.
Something like this should be fairly fast in C.

What is you aim in trying to do this ? Your algorithm is similar to
hclust() - which has nice graphical support - but it merges two nearest
neighbour to find another centroid instead of removing one of the
neigbours. By removing columns early in stage you are losing
information. 

The alternative would be to use hclust(), select a
similarity/dissimilarity cutoff to create groups. Then from each group
you can either choose the average profile or randomly select one column
to represent the group.

--
Adaikalavan Ramasamy 


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rajarshi Guha
Sent: Friday, November 21, 2003 11:23 AM
To: R
Subject: [R] speeding up a pairwise correlation calculation


Hi,
  I have a data.frame with 294 columns and 211 rows. I am calculating
correlations between all pairs of columns (excluding column 1) and based
on these correlation values I delete one column from any pair that shows
a R^2 greater than a cuttoff value. (Rather than directly delete the
column all I do is store the column number, and do the deletion later)

The code I am using is:

    ndesc <- length(names(data));
    for (i in 2:(ndesc-1)) {
        for (j in (i+1):ndesc) {

            if (i %in% drop || j %in% drop) next;
            
            r2 <- cor(data[,i],data[,j]);
            r2 <- r2*r2;

            if (r2 >= r2cut) {
                rnd <- abs(rnorm(1));
                if (rnd < 0.5) { drop <- c(drop,i); }
                else { drop <- c(drop,j); }
            }
        }
    }

drop is a vector that contains columns numbers that can be skipped data
is the data.frame

For the data.frame mentioned above (279 columns, 211 rows) the
calculation takes more than 7 minutes (after which I Ctrl-C'ed the
calculation). The machine is a 1GHz Duron with 1GB RAM

The output of version is:

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.1
year     2003
month    06
day      16
language R

I'm not too sure why it takes *so* long (I had done a similar
calculation in Python using list operations and it took forever), but is
there any trick that could be used to make this run faster or is this
type of runtime to be expected?

Thanks,
-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A red sign on the door of a physics professor: 
'If this sign is blue, you're going too fast.'

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Wanzare at HCJP.com  Fri Nov 21 07:06:33 2003
From: Wanzare at HCJP.com (Manoj - Hachibushu Capital)
Date: Fri, 21 Nov 2003 15:06:33 +0900
Subject: [R] using a logical vector as a mask?
Message-ID: <1CBA12F2D414914989C723D196B287DC04050C@jp-svr-ex1.HCJP.COM>

v[is.na(v)]=0

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rajarshi Guha
Sent: Friday, November 21, 2003 2:38 PM
To: R
Subject: [R] using a logical vector as a mask?

Hi,
  say I have a vector:

v <- c(1,2,3,NA,5,6,NA,7)

And I would like to set the elements that are NA to, say, 0

I can use is.na() to get a logical vector:

ind <- is.na(v)

Is there a way in which I can use this logical vector to set the NA
elements in v to 0?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
All great ideas are controversial, or have been at one time.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From baron at psych.upenn.edu  Fri Nov 21 07:11:02 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 21 Nov 2003 01:11:02 -0500
Subject: [R] Who can provide me RWeb installation
In-Reply-To: <OF6C7EFE2C.D1535C07-ON48256DE5.0010353B-48256DE5.001090FD@notes.seagate.com>
References: <OF6C7EFE2C.D1535C07-ON48256DE5.0010353B-48256DE5.001090FD@notes.seagate.com>
Message-ID: <20031121061102.GA167@mail1.sas.upenn.edu>

On 11/21/03 11:00, WeiQiang.Li at seagate.com wrote:
>Hi,
>      RWeb web site is down past couple days, I am insterested in this
>project and want to try it for my projects. Deos anyone have this
>installation and user guide? Thanks!

I've put it in
http://finzi.psych.upenn.edu/~baron/Rweb1.03.tar.gz

This version has a small error.  In 
Rweb.JavaScript.html, and I think in a couple of other files,
there are lines like this:
<IMG SRC="RwebLogo.GIF ALT="Great Rweb Logo">
which should be
<IMG SRC="RwebLogo.GIF" ALT="Great Rweb Logo">
Maybe some browsers will deal with this error, but Mozilla
won't, and the image doesn't show up.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From ripley at stats.ox.ac.uk  Fri Nov 21 07:44:28 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Nov 2003 06:44:28 +0000 (GMT)
Subject: [R] model tutorial
In-Reply-To: <5E06BFED29594F4C9C5EBE230DE320C602C2B6F0@ewok.vsl.com.au>
Message-ID: <Pine.LNX.4.44.0311210643180.2949-100000@gannet.stats>

On Fri, 21 Nov 2003, Paul Sorenson wrote:

> The help and man pages of R discuss the model syntax eg a ~ b.  They
> kind of just appear as if everyone knows why - I must be a bit of a mug.
> 
> Are there any tutorial style documents around on this topic?

`An Introdction to R', which ships with R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From WeiQiang.Li at seagate.com  Fri Nov 21 07:51:20 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Fri, 21 Nov 2003 14:51:20 +0800
Subject: [R] Who can provide me RWeb installation
In-Reply-To: <20031121061102.GA167@mail1.sas.upenn.edu>
Message-ID: <OF86A196B5.4F5B434F-ON48256DE5.0025593D-48256DE5.0025B8E3@notes.seagate.com>


Hi Jonathan,

      Thank you, I got it. I am trying now.

Regards,
WeiQiang Li



                                                                                                                                       
                      Jonathan Baron                                                                                                   
                      <baron at psych.upen        To:       WeiQiang.Li at seagate.com                                                       
                      n.edu>                   cc:       r-help at stat.math.ethz.ch                                                      
                      No Phone Info            Subject:  Re: [R] Who can provide me RWeb installation                                  
                      Available                                                                                                        
                                                                                                                                       
                      2003-11-21 14:11                                                                                                 
                                                                                                                                       




On 11/21/03 11:00, WeiQiang.Li at seagate.com wrote:
>Hi,
>      RWeb web site is down past couple days, I am insterested in this
>project and want to try it for my projects. Deos anyone have this
>installation and user guide? Thanks!

I've put it in
http://finzi.psych.upenn.edu/~baron/Rweb1.03.tar.gz

This version has a small error.  In
Rweb.JavaScript.html, and I think in a couple of other files,
there are lines like this:
<IMG SRC="RwebLogo.GIF ALT="Great Rweb Logo">
which should be
<IMG SRC="RwebLogo.GIF" ALT="Great Rweb Logo">
Maybe some browsers will deal with this error, but Mozilla
won't, and the image doesn't show up.

Jon
--
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From p.pagel at gsf.de  Fri Nov 21 07:50:33 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Fri, 21 Nov 2003 07:50:33 +0100
Subject: [R] incorporating R into C
In-Reply-To: <1a8d01c3afb7$0a1721f0$05182e04@asus>
References: <1a8d01c3afb7$0a1721f0$05182e04@asus>
Message-ID: <20031121065033.GB1326@porcupine.gsf.de>

On Thu, Nov 20, 2003 at 02:38:35PM -0800, Amir Soofi wrote:
> I've become somewhat decent with R over the last month, and I feel
> confident that nothing online can help me with this question,

http://cran.r-project.org/doc/manuals/R-exts.pdf

is this online enough?

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From phgrosjean at sciviews.org  Fri Nov 21 08:36:32 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 21 Nov 2003 08:36:32 +0100
Subject: [R] nls, nlrq, and box-cox transformation
In-Reply-To: <3FBD2033.15757.63977B@localhost>
Message-ID: <MABBLJDICACNFOLGIHJOAECMDPAA.phgrosjean@sciviews.org>

>> You suggest the solution yourself: transform the equation to have all
>> parameters at the right, thus:
>>
>> y ~ ((b0 + b1 * x) * t + 1) ^ 1/t
>>

>Bit this is still not correct, since the transformation changes
>the scale of the variance, and lesat squares will not be correct.
>There is needed a factor (the jacobian) to compensate for this,

>Kjetil Halvorsen

OK, sorry you are correct: one would need also to calculate residuals as
(y - ymodel)^2*t instead of (y - ymodel)^2 in the case of nls. This effects
also nlrq, although in a somewhat reduced manner.

Best,

Philippe Grosjean



From rajiv.prasad at charter.net  Fri Nov 21 08:45:35 2003
From: rajiv.prasad at charter.net (Rajiv Prasad)
Date: Thu, 20 Nov 2003 23:45:35 -0800
Subject: [R] maps package for Windows
References: <005101c3af24$5bf2d430$6401a8c0@Jeeves2>	<003f01c3af27$280a87f0$818001db@webgis>
	<005901c3af2e$0c273b80$6401a8c0@Jeeves2>
	<3FBC709D.7010102@statistik.uni-dortmund.de>
Message-ID: <002701c3b003$73cd7120$6401a8c0@Jeeves2>

Thanks, Uwe.  I successfully installed maps_2.0-10.

But now I have another problem.  mapdata_2.0-8.zip in the contrib directory
seems to be an invalid zip archive.  I downloaded it using IE, but WinZip
complains about its validity.  If I try to "Install from CRAN" in RGui, I
get the following:

> local({a <- CRAN.packages()
+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)})
trying URL `http://cran.r-project.org/bin/windows/contrib/1.8/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 13514 bytes
opened URL
downloaded 13Kb

trying URL
`http://cran.r-project.org/bin/windows/contrib/1.8/mapdata_2.0-8.zip'
Content type `application/zip' length 3153920 bytes
opened URL
downloaded 3080Kb

Error in file(file, "r") : unable to open connection
In addition: Warning messages:
1: error 1 in extracting from zip file
2: cannot open file `mapdata/DESCRIPTION'
>

Thanks for all your help, and the wonderful efforts of the whole R team.
I'm trying now to set up the build tools on my Windows laptop, so I can use
the sources directly, and not have to bother you more.  I have some
questions regarding setting up build tools on Windows.  I'll start a new
thread for it.

Thanks again.

Rajiv



----- Original Message ----- 
From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
To: "Rajiv Prasad" <rajiv.prasad at charter.net>
Cc: "Hisaji Ono" <hi_ono2001 at ybb.ne.jp>; <r-help at stat.math.ethz.ch>
Sent: Wednesday, November 19, 2003 11:43 PM
Subject: Re: [R] maps package for Windows


> Rajiv Prasad wrote:
>
> > Umm... no, does not work for me yet:
> >
> >
> >>local({a <- CRAN.packages()
> >
> > + install.packages(select.list(a[,1],,TRUE), .libPaths()[1],
available=a)})
> > trying URL `http://cran.r-project.org/bin/windows/contrib/1.8/PACKAGES'
> > Content type `text/plain; charset=iso-8859-1' length 13514 bytes
> > opened URL
> > downloaded 13Kb
> >
> > trying URL
> > `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> > Error in download.file(url, destfile, method, mode = "wb") :
> >         cannot open URL
> > `http://cran.r-project.org/bin/windows/contrib/1.8/maps_2.0-10.zip'
> > In addition: Warning message:
> > cannot open: HTTP status was `404 Not Found'
> >
> >
> > Is it just an issue of the file not haveing reached all mirrors yet?
> >
> > Thanks.
> >
> > Rajiv
>
>
> For some (unknown) reason, the automated upload of maps_2.0-10.zip
> failed (it's in the PACKAGES list, though). I'll upload it manually
> today, so it will appear on CRAN master tomorrow.
>
> Uwe Ligges
>
>



From soofi at cs.ucla.edu  Fri Nov 21 08:43:32 2003
From: soofi at cs.ucla.edu (Amir Soofi)
Date: Thu, 20 Nov 2003 23:43:32 -0800
Subject: [R] Answered: incorporating R into C
Message-ID: <1bbf01c3b003$2ac91ec0$05182e04@asus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031120/d2840bcc/attachment.pl

From angel_lul at hotmail.com  Thu Nov 20 21:37:49 2003
From: angel_lul at hotmail.com (Angel)
Date: Thu, 20 Nov 2003 21:37:49 +0100
Subject: [R] ?for
References: <200311210242.hAL2gi9U004997@tahi.mcs.vuw.ac.nz>
Message-ID: <LAW11-OE22rdFOSPUPe00000593@hotmail.com>

Windows 98 with R 1.7.1: ? paste("help") opens help for help in my machine.
In my linux debian with R 1.8.1 beta it opens the help for paste.
I am even more puzzled now!, is this system dependent or R-version
dependent?
----- Original Message -----
From: "Ray Brownrigg" <ray at mcs.vuw.ac.nz>
To: <angel_lul at hotmail.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Friday, November 21, 2003 3:42 AM
Subject: Re: [R] ?for


> > I thought I was getting to grips with it, until last reply from Prof
Brian
> > Ripley's. At least in my Windows and Linux boxes
>
> Actually it was my reply that suggested ?paste("help")
>
> > ? paste("help")
> > opens the help for help (!?)
>
> Not on my systems! [Solaris, NetBSD, Windows 98].  I believe it should
> open the help for paste().
>
> The point is that it requires a syntactically correct statement after
> the ? so that the command parses correctly (with ? as a unary
> operator), but the result is to provide the help for the first
> syntactic element of the parsed expression, *without* evaluating the
expression.
>
> Ray Brownrigg
>



From angel_lul at hotmail.com  Thu Nov 20 22:27:05 2003
From: angel_lul at hotmail.com (Angel)
Date: Thu, 20 Nov 2003 22:27:05 +0100
Subject: [R] best editor for .R files
Message-ID: <Sea2-DAV15zxDPHprp500000eae@hotmail.com>


Which is the best editor for .R files?

I currently use kate on my linux as it has R highlighting and allows me to
split the window into two: in one I edit the .R file and in the other I have
a shell so I run R and can easily  copy and paste the code. There are some
features that I don't like and I am having a look on some alternatives.
I've heard wonders of emacs with ess but I am a little bit frightened of the
steep learning curve.

What do the R experts use or would recommend using?
Both linux and/or windows alternatives are welcomed.
I guess it would much depend on the particular needs/preferences of each
user but I would like to know which are the most commonly used editors.
Thanks,
Angel



From christian.schulz at questico.de  Fri Nov 21 10:36:33 2003
From: christian.schulz at questico.de (Christian Schulz)
Date: Fri, 21 Nov 2003 10:36:33 +0100
Subject: AW: [R] best editor for .R files
In-Reply-To: <Sea2-DAV15zxDPHprp500000eae@hotmail.com>
Message-ID: <JAEELBHBOPKJDMMCNHKMOEINCBAA.christian.schulz@questico.de>

That's a good question, i was really satisifed with R-Winedt for Windows,
and this was one reason for me avoid a migration to linux. But one day
i decide to start the mmigration process from win2linux and now using
EmacsSpeaksStatistics what's really cool, but you need a bit of practice
takes getting used to!

http://stat.ethz.ch/ESS/

christian




-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]Im Auftrag von Angel
Gesendet: Donnerstag, 20. November 2003 22:27
An: r-help at stat.math.ethz.ch
Betreff: [R] best editor for .R files



Which is the best editor for .R files?

I currently use kate on my linux as it has R highlighting and allows me to
split the window into two: in one I edit the .R file and in the other I have
a shell so I run R and can easily  copy and paste the code. There are some
features that I don't like and I am having a look on some alternatives.
I've heard wonders of emacs with ess but I am a little bit frightened of the
steep learning curve.

What do the R experts use or would recommend using?
Both linux and/or windows alternatives are welcomed.
I guess it would much depend on the particular needs/preferences of each
user but I would like to know which are the most commonly used editors.
Thanks,
Angel

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From phgrosjean at sciviews.org  Fri Nov 21 10:43:21 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 21 Nov 2003 10:43:21 +0100
Subject: [R] best editor for .R files
In-Reply-To: <Sea2-DAV15zxDPHprp500000eae@hotmail.com>
Message-ID: <MABBLJDICACNFOLGIHJOAECODPAA.phgrosjean@sciviews.org>

You will find a list of several possible editors for R in:
http://www.r-project.org/GUI/projects/editors.html (and for related aspects,
look at http://www.r-project.org/GUI). The best way is to try several, and
decide in function of your own feeling and needs.
Best,

Philippe Grosjean


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Angel
Sent: Thursday, 20 November, 2003 22:27
To: r-help at stat.math.ethz.ch
Subject: [R] best editor for .R files



Which is the best editor for .R files?

I currently use kate on my linux as it has R highlighting and allows me to
split the window into two: in one I edit the .R file and in the other I have
a shell so I run R and can easily  copy and paste the code. There are some
features that I don't like and I am having a look on some alternatives.
I've heard wonders of emacs with ess but I am a little bit frightened of the
steep learning curve.

What do the R experts use or would recommend using?
Both linux and/or windows alternatives are welcomed.
I guess it would much depend on the particular needs/preferences of each
user but I would like to know which are the most commonly used editors.
Thanks,
Angel

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From uth at zhwin.ch  Fri Nov 21 10:58:16 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Fri, 21 Nov 2003 10:58:16 +0100
Subject: AW: [R] best editor for .R files
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F1AB8D4@langouste.zhwin.ch>


Hi

The best is definitively (X)Emacs (my opinion).

For Windows have a look at (GNU Emacs):
http://www.math.auc.dk/~dethlef/Tips/introduction.html

And for XEmacs with Cygwin (XEmacs, Latex, ..., for Ess simple save (require 'ess-site) in your init.el):
http://home.imf.au.dk/hellmund/indhold.html

For native Xemacs for Windows:
www.xemacs.org

Xemacs is easy to install, use and configure (more easy than the GNU-Version).


Under Linux both comes with the most distributions (I use both under SuSE 8.2).


HTH

Thomas



-----Urspr?ngliche Nachricht-----
Von: Angel [mailto:angel_lul at hotmail.com] 
Gesendet: Donnerstag, 20. November 2003 22:27
An: r-help at stat.math.ethz.ch
Betreff: [R] best editor for .R files



Which is the best editor for .R files?

I currently use kate on my linux as it has R highlighting and allows me to split the window into two: in one I edit the .R file and in the other I have a shell so I run R and can easily  copy and paste the code. There are some features that I don't like and I am having a look on some alternatives. I've heard wonders of emacs with ess but I am a little bit frightened of the steep learning curve.

What do the R experts use or would recommend using?
Both linux and/or windows alternatives are welcomed.
I guess it would much depend on the particular needs/preferences of each user but I would like to know which are the most commonly used editors. Thanks, Angel

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Gerrit.Eichner at math.uni-giessen.de  Fri Nov 21 11:26:25 2003
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 21 Nov 2003 11:26:25 +0100 (CET)
Subject: [R] Problem with Trellis graphics in nlme
In-Reply-To: <Law11-F56tWdWhkeLZs0001874c@hotmail.com>
References: <Law11-F56tWdWhkeLZs0001874c@hotmail.com>
Message-ID: <Pine.A41.4.56.0311211123390.25500@e1.hrz.uni-giessen.de>

On Thu, 20 Nov 2003, anthony staines wrote:

> ... My graphics are correct horizontally, but are confined to about
> one-fifth of the vertical extent of the graphics device. As a result
> they look odd, and are almost usless for analysis. They do seem,
> however, to be the correct graphics ...
> Roughly, I need to tell lattice to use the full vertical extent of the
> display device.  If it helps, I can e-mail the offending images to you
> individually on request.

Have a looked at the argument "aspect" of plot.nfnGroupedData().
Maybe this is what could help you.

 Regards  --  Gerrit

 -------------------------------------------------------------------------
  Dr. Gerrit Eichner                        Mathematical Institute of the
  gerrit.eichner at math.uni-giessen.de        Justus-Liebig-Univ. Giessen
  Tel: +49-(0)641-99-32104	      Arndtstr. 2, 35392 Giessen, Germany
  Fax: +49-(0)641-99-32029	http://www.math.uni-giessen.de/Stochastik
 -------------------------------------------------------------------------



From eve.corda at oncfs.gouv.fr  Fri Nov 21 11:50:01 2003
From: eve.corda at oncfs.gouv.fr (Eve Corda)
Date: Fri, 21 Nov 2003 11:50:01 +0100
Subject: [R]: BIC for gls models
Message-ID: <006701c3b01d$371a3370$7a03a8c0@DER6>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031121/4bb5f4f2/attachment.pl

From elio.mineo at dssm.unipa.it  Fri Nov 21 10:34:05 2003
From: elio.mineo at dssm.unipa.it (Elio Mineo)
Date: Fri, 21 Nov 2003 10:34:05 +0100
Subject: [R] Package for Mandrake 8.2
Message-ID: <3FBDDC0D.4070303@dssm.unipa.it>

Dear all,
a (non official) Mandrake 8.2 package for R 1.8.0 can be downloaded from

http://dssm.unipa.it/mandrake/8.2/

The author of this package is Alfredo Pontillo. If you have any problem with this package, please send me a message.
With best regards,
Elio Mineo

-- 
--------------------------------------------------------------------------
Elio Mineo
Dipartimento di Scienze Statistiche e Matematiche "Silvio Vianelli"
Universit? degli Studi di Palermo
Viale delle Scienze
90128 Palermo
URL: http://dssm.unipa.it/elio



From kjetil at entelnet.bo  Fri Nov 21 12:59:14 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Fri, 21 Nov 2003 07:59:14 -0400
Subject: [R] using a logical vector as a mask?
In-Reply-To: <1069393098.2382.1.camel@localhost.localdomain>
Message-ID: <3FBDC5D2.8826.266086@localhost>

On 21 Nov 2003 at 0:38, Rajarshi Guha wrote:

> v <- c(1,2,3,NA,5,6,NA,7)
> ind <- is.na(v)
> ind
[1] FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE
> v[ind] <- 0
> v
[1] 1 2 3 0 5 6 0 7

Kjetil Halvorsen

> Hi,
>   say I have a vector:
> 
> v <- c(1,2,3,NA,5,6,NA,7)
> 
> And I would like to set the elements that are NA to, say, 0
> 
> I can use is.na() to get a logical vector:
> 
> ind <- is.na(v)
> 
> Is there a way in which I can use this logical vector to set the NA
> elements in v to 0?
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net> GPG Fingerprint:
> 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> All great ideas are controversial, or have been at one time.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dmurdoch at pair.com  Fri Nov 21 13:08:22 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 21 Nov 2003 07:08:22 -0500
Subject: [R] ?for
In-Reply-To: <LAW11-OE22rdFOSPUPe00000593@hotmail.com>
References: <200311210242.hAL2gi9U004997@tahi.mcs.vuw.ac.nz>
	<LAW11-OE22rdFOSPUPe00000593@hotmail.com>
Message-ID: <gjvrrv8pl8udm9nsigji41iako1chqvooo@4ax.com>

On Thu, 20 Nov 2003 21:37:49 +0100, you wrote:

>Windows 98 with R 1.7.1: ? paste("help") opens help for help in my machine.
>In my linux debian with R 1.8.1 beta it opens the help for paste.
>I am even more puzzled now!, is this system dependent or R-version
>dependent?

Version dependent. This was an intentional change, to allow you to
find the help for an S4 method separately from the generic.  It's
documented in ?help.

Duncan Murdoch



From bates at stat.wisc.edu  Fri Nov 21 13:38:34 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 21 Nov 2003 06:38:34 -0600
Subject: [R]: BIC for gls models
In-Reply-To: <006701c3b01d$371a3370$7a03a8c0@DER6>
References: <006701c3b01d$371a3370$7a03a8c0@DER6>
Message-ID: <6r65hdq4l1.fsf@bates4.stat.wisc.edu>

"Eve Corda" <eve.corda at oncfs.gouv.fr> writes:

> I would like to know how the BIC criterion is calculated for models estimated using gls( ) function. I read in Pinheiro & Bates (2000) p84 that 
> BIC = -2logL + npar*log(N) (for the ML method), or
> BIC = -2logLR + npar*log(N-p) (for the REML method)
> but when I use any of these formulae I don't obtain the result given by R. 

> library(nlme)
Loading required package: lattice 
> getS3method("BIC", "gls")
function (object, ...) 
{
    if ((rt <- nargs()) > 1) {
        object <- list(object, ...)
        val <- lapply(object, logLik)
        val <- as.data.frame(t(sapply(val, function(el) c(attr(el, 
            "df"), BIC(el)))))
        names(val) <- c("df", "BIC")
        row.names(val) <- as.character(match.call()[-1])
        val
    }
    else {
        BIC(logLik(object))
    }
}
<environment: namespace:nlme>



From p.dalgaard at biostat.ku.dk  Fri Nov 21 13:45:53 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Nov 2003 13:45:53 +0100
Subject: [R] R-1.8.1 is released 
Message-ID: <x2oev5x532.fsf@biostat.ku.dk>

I've rolled up R-1.8.1.tgz a short while ago. This is a patch version
mostly fixing a number of issues in 1.8.0, some of which were quite
serious. As usual, a few new features have crept in as well. (See below
for details.)

You can get it from

http://cran.us.r-project.org/src/base/R-1.8.1.tgz

or wait for it to be mirrored at a CRAN site nearer to you. Binaries
for various platforms will appear in due course.
 
There is also a version split for floppies.

These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

cd81fdeaf22f93dfc28979e8132722ec  R-1.8.1.tgz
5690ed4e1f453115551122facb4b34b0  R-1.8.1.tgz-split.aa
cd2fd749085c1e63fce22e3e09f70cdb  R-1.8.1.tgz-split.ab
ab0b08746d1f5bd56a736a8b1f5bfee6  R-1.8.1.tgz-split.ac
41332e09272598bfb64c25ac84274404  R-1.8.1.tgz-split.ad
51d3f4e376efdee4ae069b135f909621  R-1.8.1.tgz-split.ae
c50f27fdf41c44c71c5b4f285a2dd98f  R-1.8.1.tgz-split.af
2eb71e8a54e41b3e30e3e40f35151aa0  R-1.8.1.tgz-split.ag

On behalf of the R Core Team,

        Peter Dalgaard


Here's the relevant part of the NEWS file


		CHANGES IN R VERSION 1.8.1


NEW FEATURES

    o	There is now a "Complex" S3 group generic (a side-effect of
	fixing up the corresponding S4 group generic).

    o	help("regex") now gives a description of the regular expressions
	used in R.

    o	The startup message now shows the R Foundation as copyright
	holder, and includes the R ISBN number and a pointer to the new
	citation() function.

    o	The solve() function now uses the `tol' argument for all
	non-complex cases.  The default tolerance for LINPACK is 1e-7,
	as before.  For LAPACK it currently is .Machine$double.eps but
	may be changed in later versions of R.

    o	help.search() now defaults to agrep = FALSE when keyword= is
	specified, since no one wants fuzzy matching of categories.

    o	Function texi2dvi() in package tools can be used to compile
	latex files from within R.

    o	Objects with formal S4 classes saved in pre-1.8 versions and
	loaded into the current version have incompatible class
	attributes (no package information).  A new function,
	fixPre1.8() in package methods, will fix the class attributes.
	See the help for this function.

    o	heatmap() allows Rowv/Colv = NA, suppressing the corresponding
	dendrogram.

    o   An "antifeature": Tcl 8.0 is now officially unsupported. In 1.8.0
	it just didn't work. This very old version lacks several features
        that are needed for the new version of the tcltk package. R will
	still build the tcltk package against Tcl 8.0 but the resulting
	package will not load.


BUG FIXES

    o	symnum(x) now behaves as documented when length(x) == 0 and uses
	lower.triangular = FALSE for logical arrays.

    o	c() now has a method for "noquote" objects and hence works as
	expected.

    o	split(1:10, c(1,2)) no longer gives a spurious warning.

    o	The "Complex" S4 group generic now works.

    o	abbreviate() doesn't get into infinite loops on input that differs
	only by leading/trailing space

    o	Added check for user interrupt in Rvprintf to allow printing to be
	interrupted.

    o	Fixed bug that would cause segfault on protect stack overflow.

    o	crossprod() on matrices with zero extents would return an
	uninitialized matrix (rather than one filled with zeros).

    o	DF[[i,j]] for a data frame used row j and col i, not as intended
	row i and col j.

    o	Even more user errors in recursive indexing of lists are now
	caught.	 (PR#4486)

    o	cor(<matrix>, use = "pairwise") gave wrong result in 1.8.0 (only).
	(PR#4646)

    o	merge.data.frame() could give incorrect names when one of the
	arguments had only one column.	(PR#4299)

    o	Subsetting a one-dimensional array dropped dimensions even when
	they were not of length one.  (Related to PR#4110)

    o	The plot() method for `ecdf' objects, plot.ecdf(), now allows to
	set a `ylab' argument (different from the default).

    o	cor.test(*, method="spearman") gave wrong results `randomly'
	(because of a wrong type passed to C; PR#4718).

    o	dist() objects with NA's didn't print these, now do. (PR#4866).

    o	regexpr(fixed = TRUE) returned 0-based indices.

    o	df[, length_1_index] <- value did not recycle short rhs. (PR#4820)

    o	median() no longer `works' for odd-length factor variables.

    o	packageStatus() is more robust to failing to contact a
	repository, and contacts the correct paths in the repositories
	under Windows.

    o	.setOldIs (methods) contained a typo stopping POSIXct objects (etc)
	being included in formal classes.

    o	terms() sometimes removed offset() terms incorrectly, since it
	counted by variables and not terms.  Its "offset" attribute
	was incorrectly documented as referring to terms not
	variables. (Related to PR#4941)

    o	buildVignettes() and pkgVignettes() in package tools are now
	documented.  The call to texi2dvi is wrapped in the new
	function texi2dvi() which also works on Windows.

    o   hclust() was sometimes not finding the correct inter-cluster
	distances with non-monotone methods.  (PR#4195)

    o   plot.hclust() now tolerates mode changes on dumped objects. (PR#4361)

    o   prompt() no longer insists files are in the current directory.
	(PR#4978)

    o   filter() did not use init in reverse order as documented. (PR#5017)

    o	contrasts<-() and model.matrix() now have sanity checks that
	factors having at least 2 levels (or one level and a contrast
	matrix): model.matrix() gave nonsensical results for 0-level
	factors.

    o   writeChar() could segfault if more characters were requested
	than exist. (PR#5090)

    o	round() and signif() dropped attributes with 0-length inputs,
	only. (PR#4710)

    o	The default graphics device in the GNOME interface was gtk,
	which is no longer in the base package. It is now X11.

    o	The print button on the toolbar of the GNOME graphics device
	did not work.

    o	The example code on the man page for TkWidgetcmds had not been
	updated after the change that made tkget (et al.) return
	tclObj objects, so the "Submit" button didn't work.

    o	Rd conversion to latex did not add a new line before
	\end{Section} for the section environments, which caused
	problems if the last thing in a section was \preformatted{}
	(and potentially elsewhere).

    o	Under some circumstances mosaicplot() failed if main was
	supplied as it was passed on to model.frame.default().

    o	Conversion to POSIXlt (including printing) of POSIXct dates
	before 1902 and after 2038 computed which were leap years from
	(year-1900) so got some xx00 years wrong.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From partha_bagchi at hgsi.com  Fri Nov 21 13:40:15 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Fri, 21 Nov 2003 07:40:15 -0500
Subject: [R] best editor for .R files
Message-ID: <OFB9360104.D5E0D9C9-ON85256DE5.00454F29-85256DE5.00459A2B@hgsi.com>

On the Windows platform, I use SourceEdit which also has R syntax 
highlighting (and much more) (http://www.brixoft.com/). However, as an 
organization, we do have plans to look at the IDE Eclipse 
(http://www.eclipse.org/ )

Partha





"Angel" <angel_lul at hotmail.com>
Sent by: r-help-bounces at stat.math.ethz.ch
11/20/2003 04:27 PM

 
        To:     <r-help at stat.math.ethz.ch>
        cc: 
        Subject:        [R] best editor for .R files



Which is the best editor for .R files?

I currently use kate on my linux as it has R highlighting and allows me to
split the window into two: in one I edit the .R file and in the other I 
have
a shell so I run R and can easily  copy and paste the code. There are some
features that I don't like and I am having a look on some alternatives.
I've heard wonders of emacs with ess but I am a little bit frightened of 
the
steep learning curve.

What do the R experts use or would recommend using?
Both linux and/or windows alternatives are welcomed.
I guess it would much depend on the particular needs/preferences of each
user but I would like to know which are the most commonly used editors.
Thanks,
Angel

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From Pascal.Niklaus at unibas.ch  Fri Nov 21 14:01:38 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Fri, 21 Nov 2003 14:01:38 +0100
Subject: [R] plot map of areas
Message-ID: <3FBE0CB2.7080604@unibas.ch>

Hi all,

Given a number of points (x,y) in a plane, I'd like to plot a map of 
polygons, so that

    1) each polygon contains exactly one point
    2) the polygon defines the area for which this specific point is 
closer than any other point.

It's a bit like a map of areas "influenced" by that point, and it's 
obviously a matter of intersecting the perpendicular bisectors between 
adjacent points.

I believe this type of map has a name, but I can't remember how it's 
called.

Is there a function somewhere in a R package that may do this?

Thanks for your help

Pascal



From JonesW at kssg.com  Fri Nov 21 13:55:51 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Fri, 21 Nov 2003 12:55:51 -0000
Subject: [R] gls with serial correlation 
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0ECF@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031121/b64a7db2/attachment.pl

From bernd.weiss at uni-koeln.de  Fri Nov 21 14:08:14 2003
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Fri, 21 Nov 2003 14:08:14 +0100
Subject: [R] event history analysis and multiple origin and destination
	states
Message-ID: <3FBE1C4E.12921.11FCE58@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031121/f0b47ad2/attachment.pl

From mailinglist2_wegmann at web.de  Fri Nov 21 14:17:00 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Fri, 21 Nov 2003 14:17:00 +0100
Subject: [R] cross-validation with count-data
Message-ID: <200311211417.00739.mailinglist2_wegmann@web.de>

Hello, 

possibly it is a stupid question but after few hours of trying and searching, 
perhaps I used the wrong key words, I decided to post it. 

I have the output of a glm() of count data (poisson).
I would like to get the prediction error (cross-validation).

cv.glm() does not work with poisson error family data. Or I have to transform 
the output error pred. in some way. 

are there method especially for glm() with different error families to receive 
the model goodness / the model badness?

thanks in advance, Martin



From jc at or.psychology.dal.ca  Fri Nov 21 14:22:37 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Fri, 21 Nov 2003 09:22:37 -0400
Subject: [R] what does this mean in R-1.8.1 release notes?
Message-ID: <C68950B1-1C25-11D8-9D74-000A956DE534@or.psychology.dal.ca>

what does this mean in R-1.8.1 release notes?

     o	median() no longer `works' for odd-length factor variables.



From p.dalgaard at biostat.ku.dk  Fri Nov 21 14:30:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Nov 2003 14:30:13 +0100
Subject: [R] plot map of areas
In-Reply-To: <3FBE0CB2.7080604@unibas.ch>
References: <3FBE0CB2.7080604@unibas.ch>
Message-ID: <x2k75tx316.fsf@biostat.ku.dk>

"Pascal A. Niklaus" <Pascal.Niklaus at unibas.ch> writes:

> Hi all,
> 
> Given a number of points (x,y) in a plane, I'd like to plot a map of
> polygons, so that
> 
>     1) each polygon contains exactly one point
>     2) the polygon defines the area for which this specific point is
> closer than any other point.
> 
> It's a bit like a map of areas "influenced" by that point, and it's
> obviously a matter of intersecting the perpendicular bisectors between
> adjacent points.
> 
> I believe this type of map has a name, but I can't remember how it's
> called.

Voronoi Tesselation, unless my memory is failing me (again...)
 
> Is there a function somewhere in a R package that may do this?

package deldir will do VTs.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Roger.Bivand at nhh.no  Fri Nov 21 14:20:31 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 21 Nov 2003 14:20:31 +0100 (CET)
Subject: [R] plot map of areas
In-Reply-To: <3FBE0CB2.7080604@unibas.ch>
Message-ID: <Pine.LNX.4.44.0311211414360.1575-100000@reclus.nhh.no>

On Fri, 21 Nov 2003, Pascal A. Niklaus wrote:

> Hi all,
> 
> Given a number of points (x,y) in a plane, I'd like to plot a map of 
> polygons, so that
> 
>     1) each polygon contains exactly one point
>     2) the polygon defines the area for which this specific point is 
> closer than any other point.
> 
> It's a bit like a map of areas "influenced" by that point, and it's 
> obviously a matter of intersecting the perpendicular bisectors between 
> adjacent points.
> 
> I believe this type of map has a name, but I can't remember how it's 
> called.
> 
> Is there a function somewhere in a R package that may do this?

Try this:

> library(tripack)
> coords <- cbind(runif(100), runif(100))
> plot(coords, pch=19, col="blue")
> plot(voronoi.mosaic(coords[,1], coords[,2], duplicate = "remove"), 
+   add=TRUE)
> 

A Voronoi diagram? There are quite a lot of relevant functions in the 
tripack package. 

> 
> Thanks for your help
> 
> Pascal
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From john_hendrickx at yahoo.com  Fri Nov 21 14:25:31 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Fri, 21 Nov 2003 05:25:31 -0800 (PST)
Subject: [R] best editor for .R files
In-Reply-To: <OFB9360104.D5E0D9C9-ON85256DE5.00454F29-85256DE5.00459A2B@hgsi.com>
Message-ID: <20031121132531.50478.qmail@web14201.mail.yahoo.com>

An extensive review of text editors for different platforms is at
http://fmwww.bc.edu/repec/bocode/t/textEditors.html
It's geared to Stata users but contains relevant information for R
users as well.

Personally, I use TextPad for Windows. It has syntax highlighting,
regular expression search and replace, selection of rectangular
blocks  of text. You can run programs from within TextPad and if the
output file has been opened it's automatically updated if you submit
the syntax again, a very useful feature I found.

Good luck,
John Hendrickx

--- partha_bagchi at hgsi.com wrote:
> On the Windows platform, I use SourceEdit which also has R syntax 
> highlighting (and much more) (http://www.brixoft.com/). However, as
> an 
> organization, we do have plans to look at the IDE Eclipse 
> (http://www.eclipse.org/ )
> 
> Partha
> 
> 
> 
> 
> 
> "Angel" <angel_lul at hotmail.com>
> Sent by: r-help-bounces at stat.math.ethz.ch
> 11/20/2003 04:27 PM
> 
>  
>         To:     <r-help at stat.math.ethz.ch>
>         cc: 
>         Subject:        [R] best editor for .R files
> 
> 
> 
> Which is the best editor for .R files?
> 
> I currently use kate on my linux as it has R highlighting and
> allows me to
> split the window into two: in one I edit the .R file and in the
> other I 
> have
> a shell so I run R and can easily  copy and paste the code. There
> are some
> features that I don't like and I am having a look on some
> alternatives.
> I've heard wonders of emacs with ess but I am a little bit
> frightened of 
> the
> steep learning curve.
> 
> What do the R experts use or would recommend using?
> Both linux and/or windows alternatives are welcomed.
> I guess it would much depend on the particular needs/preferences of
> each
> user but I would like to know which are the most commonly used
> editors.
> Thanks,
> Angel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> --
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


__________________________________

Free Pop-Up Blocker - Get it now



From Simon.Fear at synequanon.com  Fri Nov 21 14:31:28 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 21 Nov 2003 13:31:28 -0000
Subject: [R] what does this mean in R-1.8.1 release notes?
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F02116@synequanon01>

median() has never worked for even-length factors but
the error message was rather unclear (complained about
sum not working for factors). But it did give an "answer"
of sorts for odd-length factors.

Now it doesn't work for either, which is a Good Thing, since
there is no obvious extension of the idea of numeric median
to factors. If you insist you can use

median(as.numeric(myfactor))

but you should think very carefully what this
actually means. Perhaps it has some kind of meaning
for ordered factors, but mostly you'd be better off looking
at a table().


> -----Original Message-----
> From: John Christie [mailto:jc at or.psychology.dal.ca]
> Sent: 21 November 2003 13:23
> To: R-help at stat.math.ethz.ch
> Subject: [R] what does this mean in R-1.8.1 release notes?
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> what does this mean in R-1.8.1 release notes?
> 
>      o	median() no longer `works' for odd-length 
> factor variables.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From p.dalgaard at biostat.ku.dk  Fri Nov 21 14:46:49 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Nov 2003 14:46:49 +0100
Subject: [R] what does this mean in R-1.8.1 release notes?
In-Reply-To: <C68950B1-1C25-11D8-9D74-000A956DE534@or.psychology.dal.ca>
References: <C68950B1-1C25-11D8-9D74-000A956DE534@or.psychology.dal.ca>
Message-ID: <x2fzghx29i.fsf@biostat.ku.dk>

John Christie <jc at or.psychology.dal.ca> writes:

> what does this mean in R-1.8.1 release notes?
> 
>      o	median() no longer `works' for odd-length factor variables.

The median has always been undefined for factors, but nevertheless
median() gave an answer. If the length was even, it would fail since
it needed to average non-numeric values. This confused some and the
answer you got for in the odd-length case was meaningless anyway
(what's the median of three pears, four apples, and two bananas?). So
now we check.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Fri Nov 21 14:52:17 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 21 Nov 2003 08:52:17 -0500
Subject: [R] what does this mean in R-1.8.1 release notes?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE70@usrymx25.merck.com>

> From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
> 
> John Christie <jc at or.psychology.dal.ca> writes:
> 
> > what does this mean in R-1.8.1 release notes?
> > 
> >      o	median() no longer `works' for odd-length 
> factor variables.
> 
> The median has always been undefined for factors, but nevertheless
> median() gave an answer. If the length was even, it would 
> fail since it needed to average non-numeric values. This 
> confused some and the answer you got for in the odd-length 
> case was meaningless anyway (what's the median of three 
> pears, four apples, and two bananas?). So now we check.

Why not just give an error if median is given an unordered factor?

Andy
 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From p.dalgaard at biostat.ku.dk  Fri Nov 21 15:08:09 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Nov 2003 15:08:09 +0100
Subject: [R] what does this mean in R-1.8.1 release notes?
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE70@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE70@usrymx25.merck.com>
Message-ID: <x2brr5x19y.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> > From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
> > 
> > John Christie <jc at or.psychology.dal.ca> writes:
> > 
> > > what does this mean in R-1.8.1 release notes?
> > > 
> > >      o	median() no longer `works' for odd-length 
> > factor variables.
> > 
> > The median has always been undefined for factors, but nevertheless
> > median() gave an answer. If the length was even, it would 
> > fail since it needed to average non-numeric values. This 
> > confused some and the answer you got for in the odd-length 
> > case was meaningless anyway (what's the median of three 
> > pears, four apples, and two bananas?). So now we check.
> 
> Why not just give an error if median is given an unordered factor?

That's what we do and didn't:

    if (is.factor(x) || mode(x) != "numeric")
        stop("need numeric data")

(also for ordered factors; it is not clear what to do if the median
sits between two levels in that case either.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From kan_liu2 at yahoo.co.uk  Fri Nov 21 15:05:24 2003
From: kan_liu2 at yahoo.co.uk (=?iso-8859-1?q?kan=20liu?=)
Date: Fri, 21 Nov 2003 14:05:24 +0000 (GMT)
Subject: [R] read SAS format file from R
Message-ID: <20031121140524.67372.qmail@web86110.mail.ukl.yahoo.com>

Hi,

Can you please piont me how to read SAS format file
from R (is it possible?)?

Kan


________________________________________________________________________
Want to chat instantly with your online friends?  Get the FREE Yahoo!
Messenger http://mail.messenger.yahoo.co.uk



From andy_liaw at merck.com  Fri Nov 21 15:26:11 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 21 Nov 2003 09:26:11 -0500
Subject: [R] speeding up a pairwise correlation calculation
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE71@usrymx25.merck.com>

My guess is that the objective is to delete correlated variables before
doing some sort of modeling...

This is what I would do (untested):

rcut <- sqrt(r2cut)
cormat <- cor(data[, 2:ncol(data)])
## get the position of entries larger than the cutoff
bad.idx <- which(abs(cormat) > rcut, arr.ind=TRUE)
## get the indices of the lower triangular part.
bad.idx <- bad.idx[bad.idx[,1] < bad.idx[,2]] 
## randomly pick one or the other:
drop.idx <- ifelse(runif(nrow(bad.idx)) > .5,
                   bad.idx[,1], bad.idx[,2])

HTH,
Andy

> From: Adaikalavan RAMASAMY [mailto:ramasamya at gis.a-star.edu.sg] 
> 
> You probably want to use runif() instead of rnorm() for equal 
> probability of selecting between i,j
> 
> Your algorithm is of order n^2 [ 294 choose 2, 293 choose 2, 
> ... ], so it should not be too slow. But two for() loops are 
> inefficient in R. Something like this should be fairly fast in C.
> 
> What is you aim in trying to do this ? Your algorithm is similar to
> hclust() - which has nice graphical support - but it merges 
> two nearest neighbour to find another centroid instead of 
> removing one of the neigbours. By removing columns early in 
> stage you are losing information. 
> 
> The alternative would be to use hclust(), select a 
> similarity/dissimilarity cutoff to create groups. Then from 
> each group you can either choose the average profile or 
> randomly select one column to represent the group.
> 
> --
> Adaikalavan Ramasamy 
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rajarshi Guha
> Sent: Friday, November 21, 2003 11:23 AM
> To: R
> Subject: [R] speeding up a pairwise correlation calculation
> 
> 
> Hi,
>   I have a data.frame with 294 columns and 211 rows. I am 
> calculating correlations between all pairs of columns 
> (excluding column 1) and based on these correlation values I 
> delete one column from any pair that shows a R^2 greater than 
> a cuttoff value. (Rather than directly delete the column all 
> I do is store the column number, and do the deletion later)
> 
> The code I am using is:
> 
>     ndesc <- length(names(data));
>     for (i in 2:(ndesc-1)) {
>         for (j in (i+1):ndesc) {
> 
>             if (i %in% drop || j %in% drop) next;
>             
>             r2 <- cor(data[,i],data[,j]);
>             r2 <- r2*r2;
> 
>             if (r2 >= r2cut) {
>                 rnd <- abs(rnorm(1));
>                 if (rnd < 0.5) { drop <- c(drop,i); }
>                 else { drop <- c(drop,j); }
>             }
>         }
>     }
> 
> drop is a vector that contains columns numbers that can be 
> skipped data is the data.frame
> 
> For the data.frame mentioned above (279 columns, 211 rows) 
> the calculation takes more than 7 minutes (after which I 
> Ctrl-C'ed the calculation). The machine is a 1GHz Duron with 1GB RAM
> 
> The output of version is:
> 
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    7.1
> year     2003
> month    06
> day      16
> language R
> 
> I'm not too sure why it takes *so* long (I had done a similar 
> calculation in Python using list operations and it took 
> forever), but is there any trick that could be used to make 
> this run faster or is this type of runtime to be expected?
> 
> Thanks,
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> A red sign on the door of a physics professor: 
> 'If this sign is blue, you're going too fast.'
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
> 
> ______________________________________________
> 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From p.dalgaard at biostat.ku.dk  Fri Nov 21 15:35:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Nov 2003 15:35:39 +0100
Subject: [R] read SAS format file from R
In-Reply-To: <20031121140524.67372.qmail@web86110.mail.ukl.yahoo.com>
References: <20031121140524.67372.qmail@web86110.mail.ukl.yahoo.com>
Message-ID: <x27k1tx004.fsf@biostat.ku.dk>

kan liu <kan_liu2 at yahoo.co.uk> writes:

> Hi,
> 
> Can you please piont me how to read SAS format file
> from R (is it possible?)?

Only export libraries, see the foreign package. Not even SAS itself
has been able to read its own dataset formats across platforms... (at
least until recently. New stuff in SAS v.9.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From busscher at wiz.uni-kassel.de  Fri Nov 21 16:00:24 2003
From: busscher at wiz.uni-kassel.de (Nicolaas Busscher)
Date: Fri, 21 Nov 2003 16:00:24 +0100
Subject: [R] kruskal wallis for manova?
Message-ID: <20031121160024.4aab648e.busscher@wiz.uni-kassel.de>

Hello,
Is there like the kruskal wallis test in relation to ANOVA (no
restrictions on normallity and variance homogenity) something (in R)
for MANOVA?
thanks 

-- 
Dr.Nicolaas Busscher Universit?t GH Kassel
Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713



From wolski at molgen.mpg.de  Fri Nov 21 16:03:13 2003
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 21 Nov 2003 16:03:13 +0100
Subject: [R] method names conflict.
Message-ID: <200311211603130174.00C48541@harry.molgen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031121/65ca8ded/attachment.pl

From tblackw at umich.edu  Fri Nov 21 16:05:56 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 21 Nov 2003 10:05:56 -0500 (EST)
Subject: [R] kruskal wallis for manova?
In-Reply-To: <20031121160024.4aab648e.busscher@wiz.uni-kassel.de>
References: <20031121160024.4aab648e.busscher@wiz.uni-kassel.de>
Message-ID: <Pine.SOL.4.58.0311211003080.16965@rygar.gpcc.itd.umich.edu>

Nicolaas  -

help.search("kruskal")  returns:

kruskal.test(ctest)      Kruskal-Wallis Rank Sum Test

This means that the function is  kruskal.test()  in the
ctest package.  In order to run it, you must do
library("ctest")  first.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 21 Nov 2003, Nicolaas Busscher wrote:

> Hello,
> Is there like the kruskal wallis test in relation to ANOVA (no
> restrictions on normallity and variance homogenity) something (in R)
> for MANOVA?
> thanks
>
> --
> Dr.Nicolaas Busscher Universit?t GH Kassel
> Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
> Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rpeng at jhsph.edu  Fri Nov 21 16:13:47 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 21 Nov 2003 10:13:47 -0500
Subject: [R] method names conflict.
In-Reply-To: <200311211603130174.00C48541@harry.molgen.mpg.de>
References: <200311211603130174.00C48541@harry.molgen.mpg.de>
Message-ID: <3FBE2BAB.6020206@jhsph.edu>

If you are using S4 classes/methods you can just do

setGeneric("union")

and that converts union() into an S4 generic function.  Then you can use 
setMethod() to create a union() method for your own objects.  I think 
the original union() in the base package because the default method.

-roger

Wolski wrote:
> Hi!
> 
> I would like to give my objects functions like "subset", "union", et cetera and name it also in this way.
> But this functions names are already used in the base package and they are not generic.
> I am right in that if they would be generic then i still can use the neat names with my objects?
> I have the impression that there are more and more packages are going to be developed. How this is going to be handled in future?
> 
> Eryk.
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics
> Ihnestrasse 73 14195 Berlin          'v'
> tel: 0049-30-84131285               /   \
> mail: wolski at molgen.mpg.de        ---W-W----
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jfri at novozymes.com  Fri Nov 21 16:25:12 2003
From: jfri at novozymes.com (JFRI (Jesper Frickmann))
Date: Fri, 21 Nov 2003 10:25:12 -0500
Subject: [R] Memory issues..
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D15478B@exusfr14.novo.dk>

I just tried out the 1.8.1 beta build, and it works! It ran through all
17 assays without a any problems on Windows 2000.

Thanks to the R development team, they did a great job!

Kind regards, 
Jesper Frickmann 
Statistician, Quality Control 
Novozymes North America Inc. 
Tel. +1 919 494 3266
Fax +1 919 494 3460


-----Original Message-----
From: James MacDonald [mailto:jmacdon at med.umich.edu] 
Sent: Wednesday, November 12, 2003 1:09 PM
To: JFRI (Jesper Frickman); rodrigo.abt at sii.cl; tblackw at umich.edu
Cc: jmacdon at umich.edu
Subject: RE: [R] Memory issues..


There was a discussion about memory allocation on the R-devel list this
summer, and apparently somebody has done something about it in R-1.8.1
(according to BDR's earlier post). If you can compile yourself on
windows, you could check it out yourself.

Original post http://maths.newcastle.edu.au/~rking/R/devel/03b/0432.html
BDR's  reply http://maths.newcastle.edu.au/~rking/R/devel/03b/0433.html

BDR's recent comment
"Hopefully the memory management in R-devel will ease this, 
and you might like to compile that up and try it."

HTH,

Jim





James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Rodrigo Abt <rodrigo.abt at sii.cl> 11/12/03 12:08PM >>>
I started R with --max-mem-size=300M and it "seems" to work better (at
least it doesn't hang up my machine), but I don't have any results yet.

P.S.: Are there any differences in memory management from 1.7.x to 1.8.0
?

Greetings,
Rodrigo Abt B.,
Statistical Analyst,
Department of Economic and Tributary Studies,
Studies Subdivision,
SII, Chile.

-----Mensaje original-----
De: Thomas W Blackwell [mailto:tblackw at umich.edu] 
Enviado el: Miercoles, 12 de Noviembre de 2003 12:43
Para: JFRI (Jesper Frickman)
CC: rodrigo.abt at sii.cl; jmacdon at umich.edu; r-help at stat.math.ethz.ch 
Asunto: RE: [R] Memory issues..


Jesper  -  (off-list)

Jim MacDonald reports seeing different memory-management behavior
between Windows and Linux operating systems on the same, dual boot
machine.  Unfortunately, this is happening at the operating system
level, so the R code cannot do anything about it.  I have cc'ed Jim on
this email, hoping that he will give more details to the entire list.
What operating systems (and versions of R) do you think Rodrigo and
Jesper are using ?

Specifically for Jesper's  AnalyzeAssay() function:  There is some
manipulation you can do using  formula()  or  as.formula()  that will
assign a local object as the environment in which to find values for the
terms in a formula.  (I've never done this, so I can't give you an
example of working code, only references to the help pages for "formula"
and "environment".  It's often very instructive to literally type in the
sequence of statements given as examples at the bottom of each help
page.)  I think this will allow you to avoid assigning to the global
workspace.

Are you sure that the call to  rm() below is actually removing the copy
of limsdata that's in .GlobalEnv, rather than a local copy ? I would
expect you to have to specify  where=1  in order to get the behavior you
want.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 12 Nov 2003, JFRI (Jesper Frickman) wrote:

> How much processing takes place before you get to the lme call? Maybe
R
> has just used up the memory on something else. I think there is a
fair
> amount of memory leak, as I get similar problems with my program. I
use
> R 1.8.0. My program goes as follows.
>
> 1. Use RODBC to get a data.frame containing assays to analyze (17
assays
> are found).
> 2. Define an AnalyzeAssay(assay, suffix) function to do the
following:
> 	a) Use RODBC to get data.
> 	b) Store dataset "limsdata" in workspace using the <<- operator
to 
> avoid the following error in qqnorm.lme: Error in eval(expr,
envir,
> enclos) : Object "limsdata" not found, when I call it with a
grouping
> formula like: ~ resid(.) | ORDCURV.
> 	c) Call lme to analyze data.
> 	d) Produce some diagnostic plots. Record them by setting
record=TRUE 
> on the trellis.device
> 	e) Save the plots on win.metafile using replayPlot(...)
> 	f) Save text to a file using sink(...)
>
> 3. Call the function for each assay using the code:
>
> # Analyze each assay
> for(i in 1:length(assays[,1]))
> {
> 	writeLines(paste("Analyzing ", assays$DILUTION[i], " ", 
> assays$PROFNO[i], "...", sep=""))
> 	flush.console()
> 	AnalyzeAssay(assays$DILUTION[i], assays$PROFNO[i])
>
> 	# Clean up memory
> 	rm(limsdata)
> 	gc()
> }
>
> As you can see, I try to remove the dataset stored in workspace and
then
> call gc() to clean up my memory as I go.
>
> Nevertheless, when I come to assay 11 out of 17, it stops with a
memory
> allocation error. I have to quit R, and start again with assay 11,
then
> it stops again with assay 15 and finally 17. The last assays have
much
> more data than the first ones, but all assays can be completed as
long
> as I keep restarting...
>
> Maybe restarting the job can help you getting it done?
>
> Cheers,
> Jesper
>
> -----Original Message-----
> From: Rodrigo Abt [mailto:rodrigo.abt at sii.cl]
> Sent: Monday, November 10, 2003 11:02 AM
> To: r-help at stat.math.ethz.ch 
> Subject: [R] Memory issues..
>
>
> Hi dear R-listers, I'm trying to fit a 3-level model using lme in R.
My
> sample size is about 2965 and 3 factors:
>
> year (5 levels), ssize (4 levels), condition (2 levels).
>
> When I issue the following command:
>
> >
>
lme(var~year*ssize*condition,random=~ssize+condition|subject,data=smp,me
> thod
> ="ML")
>
> I got the following error:
>
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>         Calloc could not allocate (65230 of 8) memory
> In addition: Warning message:
> Reached total allocation of 120Mb: see help(memory.size)
>
> I'm currently using a Win2000 machine with 128Mb RAM and a 1.2 Gb 
> processor. My version of R is 1.7.1.
>
> Thanks in advance,
>
> Rodrigo Abt.
> Department of Economic and Tributary Studies,
> SII, Chile.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tblackw at umich.edu  Fri Nov 21 16:29:05 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 21 Nov 2003 10:29:05 -0500 (EST)
Subject: [R] kruskal wallis for manova?
In-Reply-To: <Pine.SOL.4.58.0311211003080.16965@rygar.gpcc.itd.umich.edu>
References: <20031121160024.4aab648e.busscher@wiz.uni-kassel.de>
	<Pine.SOL.4.58.0311211003080.16965@rygar.gpcc.itd.umich.edu>
Message-ID: <Pine.SOL.4.58.0311211021200.16965@rygar.gpcc.itd.umich.edu>

Nicolaas  -

I think I was too quick and didn't answer the question
you asked.

No, I do not know of a multivariate equivalent to the
(univariate) Kruskal Wallis Rank Sum test, . . .  and
it's not clear to me that there is a unique way to define
the ranks for multivariate data in the first place.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 21 Nov 2003, Thomas W Blackwell wrote:

> Nicolaas  -
>
> help.search("kruskal")  returns:
>
> kruskal.test(ctest)      Kruskal-Wallis Rank Sum Test
>
> This means that the function is  kruskal.test()  in the
> ctest package.  In order to run it, you must do
> library("ctest")  first.
>
> HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
> On Fri, 21 Nov 2003, Nicolaas Busscher wrote:
>
> > Hello,
> > Is there like the kruskal wallis test in relation to ANOVA (no
> > restrictions on normallity and variance homogenity) something (in R)
> > for MANOVA?
> > thanks
> >
> > --
> > Dr.Nicolaas Busscher Universit?t GH Kassel
> > Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
> > Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713



From Simon.Fear at synequanon.com  Fri Nov 21 16:30:32 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 21 Nov 2003 15:30:32 -0000
Subject: [R] method names conflict.
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F02117@synequanon01>

There is nothing to stop you using these names, you just need
to be aware that you would be hiding the base definitions. Though
these could always be accessed using the double colon operator,
e.g.  base::subset, you might indeed get very unexpected results
if some function called subset() expecting the default but found 
yours instead.

I rather like the behaviour of S-Plus here - it warns you when you
are masking something. But in R we are all grown-ups and expected
to fend for ourselves. 

I frequently type a name at a blank prompt to check whether it 
already exists before assigning to it (there are much more beautiful 
ways, but this is quickest).

I wouldn't worry overmuch about the explosion in the number of
packages and their multiple use of same names. There is seldom 
a need to load more than a couple of packages at any one time.
Besides, package writers tend to use peculiar names for internal
functions precisely to reduce the potential problem.

> -----Original Message-----
> From: Wolski [mailto:wolski at molgen.mpg.de]
> Sent: 21 November 2003 15:03
> To: R-help at stat.math.ethz.ch
> Subject: [R] method names conflict.
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> Hi!
> 
> I would like to give my objects functions like "subset", 
> "union", et cetera and name it also in this way.
> But this functions names are already used in the base package 
> and they are not generic.
> I am right in that if they would be generic then i still can 
> use the neat names with my objects?
> I have the impression that there are more and more packages 
> are going to be developed. How this is going to be handled in future?
> 
> Eryk.
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. 
> Vertebrate Genomics
> Ihnestrasse 73 14195 Berlin          'v'
> tel: 0049-30-84131285               /   \
> mail: wolski at molgen.mpg.de        ---W-W----
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From B.Rowlingson at lancaster.ac.uk  Fri Nov 21 16:33:17 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 21 Nov 2003 15:33:17 +0000
Subject: [R] Memory issues..
In-Reply-To: <D53147E531BFBC4B8853FD134FAEE44D15478B@exusfr14.novo.dk>
References: <D53147E531BFBC4B8853FD134FAEE44D15478B@exusfr14.novo.dk>
Message-ID: <3FBE303D.1060908@lancaster.ac.uk>

JFRI (Jesper Frickmann) wrote:
> I just tried out the 1.8.1 beta build, and it works! It ran through all
> 17 assays without a any problems on Windows 2000.
> 
> Thanks to the R development team, they did a great job!
> 

  As I always say at the end of a busking session, "Please, please dont 
applaud - just throw money":

http://www.r-project.org/foundation/donations.html

  I'm sure the R development team will be grateful (I'm not part of the 
R dev team, I'm just making a plug for them, and reminding myself I 
ought to get round to joining the Foundation).

Baz



From clists at perrin.socsci.unc.edu  Fri Nov 21 16:57:39 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 21 Nov 2003 10:57:39 -0500 (EST)
Subject: [R] glmmPQL, log-likelihoods issue
Message-ID: <Pine.LNX.4.53.0311211055060.19128@perrin.socsci.unc.edu>

Greetings-

a reviewer for a paper of mine noted an anomaly in some models I ran using
glmmPQL (from the MASS package).  Specifically, the models are three-level
hierarchical probit models estimated using PQL under R.  The anomaly is
that the log-likelihoods decrease (or, alternatively -2logLik increases)
as variables are added to the null model. This is unusual, and I'm trying
to figure out how to interpret it.  I've found some indication (e.g., at
http://www.ssicentral.com/hlm/hlm00150.htm) that PQL estimation doesn't
produce meaningful log-likelihoods, but I'm suspicious of that claim. Any
comments or advice would be helpful.

Thanks.

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From manuel.martin at ifrance.com  Fri Nov 21 17:08:05 2003
From: manuel.martin at ifrance.com (manuel martin)
Date: Fri, 21 Nov 2003 17:08:05 +0100
Subject: [R] VIP and pls
Message-ID: <3FBE3865.2040206@ifrance.com>

Hi everyone,
does anyone know a way to calculate VIP (Variable Importance in the 
Projection) from R pls.pcr package procedures?
Thanks, 

-- 
Manuel Martin
23 rue des g?tines
75020 Paris   tel: 0143664965 



_____________________________________________________________________
Envie de discuter en "live" avec vos amis ? T?l?charger MSN Messenger
http://www.ifrance.com/_reloc/m la 1?re messagerie instantan?e de France



From f.sanchezcabo at tugraz.at  Fri Nov 21 17:25:23 2003
From: f.sanchezcabo at tugraz.at (Fatima Sanchez Cabo)
Date: Fri, 21 Nov 2003 17:25:23 +0100
Subject: [R] output files in a different directory
In-Reply-To: <3FBE3865.2040206@ifrance.com>
Message-ID: <005e01c3b04c$107daa60$6200020a@genome.tugraz.at>

Hi!

Is it possible in R to write the output files in a different directory
than the working directory?

Thanks in advance,

Fatima

--------------------------------------------------------
Fatima Sanchez-Cabo
 
Institute of Biomedical Engineering
Graz Technical University
Krengasse 37
8010 Graz / Austria
 
Department of Biomolecular Sciences
UMIST
P.O. Box 88
Manchester M60 1QD/UK



From ripley at stats.ox.ac.uk  Fri Nov 21 17:39:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Nov 2003 16:39:21 +0000 (GMT)
Subject: [R] glmmPQL, log-likelihoods issue
In-Reply-To: <Pine.LNX.4.53.0311211055060.19128@perrin.socsci.unc.edu>
Message-ID: <Pine.LNX.4.44.0311211637200.6383-100000@gannet.stats>

glmmPQL does not fit by maximum likelihood, and what is being quoted is 
not a likelihood for the original problem.

On Fri, 21 Nov 2003, Andrew Perrin wrote:

> Greetings-
> 
> a reviewer for a paper of mine noted an anomaly in some models I ran using
> glmmPQL (from the MASS package).  Specifically, the models are three-level
> hierarchical probit models estimated using PQL under R.  The anomaly is
> that the log-likelihoods decrease (or, alternatively -2logLik increases)
> as variables are added to the null model. This is unusual, and I'm trying
> to figure out how to interpret it.  I've found some indication (e.g., at
> http://www.ssicentral.com/hlm/hlm00150.htm) that PQL estimation doesn't
> produce meaningful log-likelihoods, but I'm suspicious of that claim. Any
> comments or advice would be helpful.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kmw at mail.rockefeller.edu  Fri Nov 21 17:37:25 2003
From: kmw at mail.rockefeller.edu (Knut M. Wittkowski)
Date: Fri, 21 Nov 2003 11:37:25 -0500
Subject: [R] kruskal wallis for manova?
In-Reply-To: <Pine.SOL.4.58.0311211021200.16965@rygar.gpcc.itd.umich.edu
 >
References: <Pine.SOL.4.58.0311211003080.16965@rygar.gpcc.itd.umich.edu>
	<20031121160024.4aab648e.busscher@wiz.uni-kassel.de>
	<Pine.SOL.4.58.0311211003080.16965@rygar.gpcc.itd.umich.edu>
Message-ID: <5.1.0.14.0.20031121110717.03e77228@imap.rockefeller.edu>

Nicolaas:

All linear rank tests, including the Kruskal-Wallis test, can be applied to 
multivariate data, provided that all the variables have the same 
orientation as an underlying unmeasurable (latent) factor. You score the 
multivariate observations first and then treat them as described in Hajek 
and Sidak (1967) for linear rank tests in general, using the R package 
exactRankTests.

Of course, you wouldn't want to use a (parametric) scoring mechanism, such 
as average z-scores, with a non-parametric test. A unique non-parametric 
scoring system was based on the marginal likelihood principle (Wittkowski 
1992, JASA 75:258). With u-statistics (Wittkowski, in press, Statistics in 
Medicine) one obtains a very good approximation to these unique scores, 
which is computationally more efficient (n^2 vs n!).

Please feel free to contact me for reprints and details.

Knut
(Ex-G?ttinger)

At 10:29 2003-11-21 -0500, Thomas W Blackwell wrote:
>Nicolaas  -
>
>I do not know of a multivariate equivalent to the
>(univariate) Kruskal Wallis Rank Sum test, . . .  and
>it's not clear to me that there is a unique way to define
>the ranks for multivariate data in the first place.
>
>-  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
> > On Fri, 21 Nov 2003, Nicolaas Busscher wrote:
> >
> > > Hello,
> > > Is there like the kruskal wallis test in relation to ANOVA (no
> > > restrictions on normallity and variance homogenity) something (in R)
> > > for MANOVA?
> > > thanks
> > > --
> > > Dr. Nicolaas Busscher Universit?t GH Kassel
> > > Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
> > > Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713


Knut M. Wittkowski, PhD,DSc
------------------------------------------
The Rockefeller University, GCRC
Experimental Design and Biostatistics
1230 York Ave #121B, Box 322, NY,NY 10021
+1(212)327-7175, +1(212)327-8450 (Fax)
kmw at rockefeller.edu
http://www.rucares.org/clinicalresearch/dept/biometry/



From Subramanian_Karthikeyan at hc-sc.gc.ca  Fri Nov 21 17:59:53 2003
From: Subramanian_Karthikeyan at hc-sc.gc.ca (Subramanian Karthikeyan)
Date: Fri, 21 Nov 2003 11:59:53 -0500
Subject: [R] hidden node names in a dendrogram plot
Message-ID: <OF5FFA06B3.ED894D37-ON85256DE5.005D0440@hc-sc.gc.ca>

HI All:

When I plot a cluster (from hclust(...)) or a dendrogram
(as.dendrogram(hclust(....)), the node names are partly cut off at the
bottom of the plot.
Is there any way of resizing my cluster plot so that we can see them all?

Thanks in advance.

Karthi.



From clists at perrin.socsci.unc.edu  Fri Nov 21 18:18:39 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 21 Nov 2003 12:18:39 -0500 (EST)
Subject: [R] glmmPQL, log-likelihoods issue
In-Reply-To: <Pine.LNX.4.44.0311211637200.6383-100000@gannet.stats>
References: <Pine.LNX.4.44.0311211637200.6383-100000@gannet.stats>
Message-ID: <Pine.LNX.4.53.0311211217290.19128@perrin.socsci.unc.edu>

Sorry for my ignorance, but could you explain a little further?  I'm
guessing from your response that this makes the log-likelihood that is
quoted by glmmPQL a poor measure of model fit. Are there are statistics
that would be better for reporting model fit?

thanks.

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Fri, 21 Nov 2003, Prof Brian Ripley wrote:

> glmmPQL does not fit by maximum likelihood, and what is being quoted is
> not a likelihood for the original problem.
>
> On Fri, 21 Nov 2003, Andrew Perrin wrote:
>
> > Greetings-
> >
> > a reviewer for a paper of mine noted an anomaly in some models I ran using
> > glmmPQL (from the MASS package).  Specifically, the models are three-level
> > hierarchical probit models estimated using PQL under R.  The anomaly is
> > that the log-likelihoods decrease (or, alternatively -2logLik increases)
> > as variables are added to the null model. This is unusual, and I'm trying
> > to figure out how to interpret it.  I've found some indication (e.g., at
> > http://www.ssicentral.com/hlm/hlm00150.htm) that PQL estimation doesn't
> > produce meaningful log-likelihoods, but I'm suspicious of that claim. Any
> > comments or advice would be helpful.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From bates at stat.wisc.edu  Fri Nov 21 18:40:34 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 21 Nov 2003 11:40:34 -0600
Subject: [R] glmmPQL, log-likelihoods issue
In-Reply-To: <Pine.LNX.4.53.0311211217290.19128@perrin.socsci.unc.edu>
References: <Pine.LNX.4.44.0311211637200.6383-100000@gannet.stats>
	<Pine.LNX.4.53.0311211217290.19128@perrin.socsci.unc.edu>
Message-ID: <6risldwrfx.fsf@bates4.stat.wisc.edu>

Andrew Perrin <clists at perrin.socsci.unc.edu> writes:

> Sorry for my ignorance, but could you explain a little further?  I'm
> guessing from your response that this makes the log-likelihood that is
> quoted by glmmPQL a poor measure of model fit. Are there are statistics
> that would be better for reporting model fit?

You could try GLMM from the lme4 package instead.  It has two methods
of fitting the model - PQL and Laplace.  The parameter estimates from
PQL should be similar to those from glmmPQL (it's essentially the same
algorithm) but the log-likelihood reported by GLMM is that evaluated by the
Laplacian approximation.

If you choose method="Laplace" then GLMM does the PQL fit followed by
further iterations to optimize the (second-order) Laplacian
approximation to the log-likelihood.  This takes longer to fit but
should be more accurate. The log-likelihood from this fit should be
greater than that from the PQL fit for the same model.  These
log-likelihood can be compared between models.



From maechler at stat.math.ethz.ch  Fri Nov 21 19:10:44 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Nov 2003 19:10:44 +0100
Subject: [R] hidden node names in a dendrogram plot
In-Reply-To: <OF5FFA06B3.ED894D37-ON85256DE5.005D0440@hc-sc.gc.ca>
References: <OF5FFA06B3.ED894D37-ON85256DE5.005D0440@hc-sc.gc.ca>
Message-ID: <16318.21796.852460.468134@gargle.gargle.HOWL>

>>>>> "Karthi" == Subramanian Karthikeyan <Subramanian_Karthikeyan at hc-sc.gc.ca>
>>>>>     on Fri, 21 Nov 2003 11:59:53 -0500 writes:

    Karthi> HI All:
    Karthi> When I plot a cluster (from hclust(...)) or a dendrogram
    Karthi> (as.dendrogram(hclust(....)), the node names are partly cut off at the
    Karthi> bottom of the plot.

    Karthi> Is there any way of resizing my cluster plot so that
    Karthi> we can see them all?

Yes, if you increase the corresponding margin (1-st or 4-th),
see ?par , e.g.,

data(USArrests)
dhc <- as.dendrogram(hc <- hclust(dist(USArrests), "ave"))
par(mar=c(3,2,2,6))
plot(dhc, horiz=TRUE)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From clists at perrin.socsci.unc.edu  Fri Nov 21 19:29:47 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 21 Nov 2003 13:29:47 -0500 (EST)
Subject: [R] glmmPQL, log-likelihoods issue
In-Reply-To: <6risldwrfx.fsf@bates4.stat.wisc.edu>
References: <Pine.LNX.4.44.0311211637200.6383-100000@gannet.stats>
	<Pine.LNX.4.53.0311211217290.19128@perrin.socsci.unc.edu>
	<6risldwrfx.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.LNX.4.53.0311211328570.19128@perrin.socsci.unc.edu>

On Fri, 21 Nov 2003, Douglas Bates wrote:

> Andrew Perrin <clists at perrin.socsci.unc.edu> writes:
>
> > Sorry for my ignorance, but could you explain a little further?  I'm
> > guessing from your response that this makes the log-likelihood that is
> > quoted by glmmPQL a poor measure of model fit. Are there are statistics
> > that would be better for reporting model fit?
>
> You could try GLMM from the lme4 package instead.  It has two methods
> ...


Does this mean anything to you?:


> morality.full.pql4<-GLMM(formula =  r.logic.morality ~ realage +
minority + female +
+ education + income + scenario + grouptype, random = ~1 |
+ groupid/participantid,
+ family = binomial(link = probit),
+ data = fgdata.df[coded.logic, ],
+ na.action = na.omit,
+ niter = 50,
+ method='PQL')
Error in lmeLevel(random[[i]], groups[[i]], reStructColumns[[i]], if
(self at useWeighted) self at weighted else self at original) :
        No direct or inherited method for function "lmeLevel" for this
call


----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From ggrothendieck at myway.com  Fri Nov 21 19:41:04 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 21 Nov 2003 13:41:04 -0500 (EST)
Subject: [R] read SAS format file from R
Message-ID: <20031121184104.2722F39A7@mprdmxin.myway.com>


kan_liu2 wrote:
> Can you please piont me how to read SAS format file from R (is 
> it possible?)?

There was a thread on this last month.  Check out the replies to:

http://maths.newcastle.edu.au/~rking/R/help/03b/5450.html



From jfri at novozymes.com  Fri Nov 21 19:44:09 2003
From: jfri at novozymes.com (JFRI (Jesper Frickmann))
Date: Fri, 21 Nov 2003 13:44:09 -0500
Subject: [R] output files in a different directory
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D15478D@exusfr14.novo.dk>

Yes it is. Example from my program:

workdir <- "S:\\Stat\\C03202\\R-output\\"
...
sink(file=paste(workdir, assayname, "-1.txt", sep=""))
...
win.metafile(filename = paste(workdir, assayname, "-2%02d.wmf", sep=""))

You get the idea!

Kind regards, 
Jesper Frickmann 
Statistician, Quality Control 
Novozymes North America Inc. 
Tel. +1 919 494 3266
Fax +1 919 494 3460


-----Original Message-----
From: Fatima Sanchez Cabo [mailto:f.sanchezcabo at tugraz.at] 
Sent: Friday, November 21, 2003 11:25 AM
To: r-help at stat.math.ethz.ch
Subject: [R] output files in a different directory


Hi!

Is it possible in R to write the output files in a different directory
than the working directory?

Thanks in advance,

Fatima

--------------------------------------------------------
Fatima Sanchez-Cabo
 
Institute of Biomedical Engineering
Graz Technical University
Krengasse 37
8010 Graz / Austria
 
Department of Biomolecular Sciences
UMIST
P.O. Box 88
Manchester M60 1QD/UK

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From susanms at stat.washington.edu  Fri Nov 21 20:16:43 2003
From: susanms at stat.washington.edu (Susan Shortreed)
Date: Fri, 21 Nov 2003 11:16:43 -0800 (PST)
Subject: [R] R memory allocation error - Unix
Message-ID: <Pine.OSF.4.58.0311201120550.124792@lisbon1.stat.washington.edu>



I am using ESS on a unix system for my analysis.  My R environment
contains a 90118 by 94 dataframe.  I am trying to calculate the mean of a
column in this data frame and I am getting the following error:

Error: can not allocate a vector of size 704 Kb

I have tried
options(memory=1000000000000000000)
and this does not help.

when I call gc() this is what is returned
> gc()
           used (Mb) gc trigger  (Mb)
Ncells  1178845 31.5    2564037  68.5
Vcells 11666683 89.1   38686231 295.2

I tried calling mem.limits(nsize=1000000000000).  Any value for vsize
gives an NA error, and when I recall gc() the limit for Vcells is NA.
There is more than enough memory available on the Unix machine, when I
call top I am using 0.0% of the memory and the other handful of users are
using about 10% all together.  I have increased my  user memory limit
and that still did not help (I found an email in R-help archives
suggesting this).  It seems to me that 704Kb is a rather small size to
give an error and it appears to be available on the system.

Any suggestions?

Thank you,
Susan



From p.dalgaard at biostat.ku.dk  Fri Nov 21 20:33:40 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Nov 2003 20:33:40 +0100
Subject: [R] output files in a different directory
In-Reply-To: <D53147E531BFBC4B8853FD134FAEE44D15478D@exusfr14.novo.dk>
References: <D53147E531BFBC4B8853FD134FAEE44D15478D@exusfr14.novo.dk>
Message-ID: <x2u14xv7mz.fsf@biostat.ku.dk>

"JFRI (Jesper Frickmann)" <jfri at novozymes.com> writes:

> Yes it is. Example from my program:
> 
> workdir <- "S:\\Stat\\C03202\\R-output\\"
> ...
> sink(file=paste(workdir, assayname, "-1.txt", sep=""))
> ...
> win.metafile(filename = paste(workdir, assayname, "-2%02d.wmf", sep=""))
> 
> You get the idea!

Also check out file.path() and setwd().

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Fri Nov 21 20:27:40 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 21 Nov 2003 14:27:40 -0500
Subject: [R] R memory allocation error - Unix
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE76@usrymx25.merck.com>

> From: Susan Shortreed [mailto:susanms at stat.washington.edu] 
> 
> I am using ESS on a unix system for my analysis.  My R 
> environment contains a 90118 by 94 dataframe.  I am trying to 
> calculate the mean of a column in this data frame and I am 
> getting the following error:
> 
> Error: can not allocate a vector of size 704 Kb
> 
> I have tried
> options(memory=1000000000000000000)
> and this does not help.
> 
> when I call gc() this is what is returned
> > gc()
>            used (Mb) gc trigger  (Mb)
> Ncells  1178845 31.5    2564037  68.5
> Vcells 11666683 89.1   38686231 295.2
> 
> I tried calling mem.limits(nsize=1000000000000).  Any value 
> for vsize gives an NA error, and when I recall gc() the limit 
> for Vcells is NA. There is more than enough memory available 
> on the Unix machine, when I call top I am using 0.0% of the 
> memory and the other handful of users are using about 10% all 
> together.  I have increased my  user memory limit and that 
> still did not help (I found an email in R-help archives 
> suggesting this).  It seems to me that 704Kb is a rather 
> small size to give an error and it appears to be available on 
> the system.
> 
> Any suggestions?

What exactly is this "unix" system?  This could be important, because I was
recently made aware of a problem on AIX 5, where R was compiled as 32-bit.
By default the R process will only have access to 256 MB of RAM, even though
ulimit -a reports unlimited and the machines has GBs of RAM.  I had to set
an evironment variable before starting R to get it to use up two 4GB of
memory.

This may not be your problem, but you do need to provide more details about
your system.

Andy

 
> Thank you,
> Susan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From itayf at fhcrc.org  Fri Nov 21 21:01:23 2003
From: itayf at fhcrc.org (Itay Furman)
Date: Fri, 21 Nov 2003 12:01:23 -0800 (PST)
Subject: [R] best editor for .R files
In-Reply-To: <Sea2-DAV15zxDPHprp500000eae@hotmail.com>
Message-ID: <Pine.LNX.4.44.0311211152580.13971-100000@cezanne.fhcrc.org>


Xemacs learning curve may not be as steep as you think. In any case the gains 
are certainly high because most of the short-cuts that you will learn,
especially for navigation and editting, will apply in some way-or-another to 
most of the modes that emacs will operate in: document editing, source code 
editing, file systemoperations, mail and www, help browsing, etc

	I hope it is encouraging,
	Itay

--


On Thu, 20 Nov 2003, Angel wrote:

> 
> Which is the best editor for .R files?
> 
> I currently use kate on my linux as it has R highlighting and allows me to
> split the window into two: in one I edit the .R file and in the other I have
> a shell so I run R and can easily  copy and paste the code. There are some
> features that I don't like and I am having a look on some alternatives.
> I've heard wonders of emacs with ess but I am a little bit frightened of the
> steep learning curve.
> 
> What do the R experts use or would recommend using?
> Both linux and/or windows alternatives are welcomed.
> I guess it would much depend on the particular needs/preferences of each
> user but I would like to know which are the most commonly used editors.
> Thanks,
> Angel
> 
> 
>



From flyfish72 at fastmail.fm  Sat Nov 22 00:41:34 2003
From: flyfish72 at fastmail.fm (flyfish72@fastmail.fm)
Date: Fri, 21 Nov 2003 18:41:34 -0500
Subject: [R] C++ streams in shared library in cause R to hang? (linux)
Message-ID: <20031121234134.43877424B6@server1.messagingengine.com>

Hello,

I'm using dyn.load() to load in a shared library compiled for R on linux.
 The code does quite a bit (DB accesses, C-style file reads/writes) with
no trouble, but hangs when it reaches code that uses C++ streams,
specifically operator>>() and operator<<().  From the debugger output
(below) it seems like it could be __flockfile() related (maybe a deadlock
of some sort?).

Has anyone encountered anything like this before?  Or anything obvious
jump to mind for anyone?

Thank you!
Annie Bibble


Debugger output:
#0  0x40112aa5 in __sigsuspend (set=0xbfffec10)
    at ../sysdeps/unix/sysv/linux/sigsuspend.c:45
#1  0x40f63079 in __pthread_wait_for_restart_signal (self=0x40f6bd60)
    at pthread.c:967
#2  0x40f64d39 in __pthread_alt_lock (lock=0x9203448, self=0x0) at
restart.h:34
#3  0x40f61c16 in __pthread_mutex_lock (mutex=0x9203438) at mutex.c:120
#4  0x40f63e12 in __flockfile (stream=0xbfffefa4) at lockfile.c:39
#5  0x40e35ba8 in read_int () from /usr/lib/libstdc++-libc6.2-2.so.3
#6  0x40e35f58 in istream::operator>> () from
/usr/lib/libstdc++-libc6.2-2.so.3
#7  0x4093f2e2 in myFunc () at myfunc.cc:347
...



From yzhou at sdsc.edu  Sat Nov 22 00:57:35 2003
From: yzhou at sdsc.edu (Yi-Xiong Zhou)
Date: Fri, 21 Nov 2003 15:57:35 -0800
Subject: [R] How to read .bmp files into R? read.pnm throws error
Message-ID: <DOEGLCMDLJCLMLNMGPMIKEIFCAAA.yzhou@sdsc.edu>

Hi,

Is there a way to read .bmp files into R? I have tried read.pnm from pixmap
package. It returned

Error in pm.readmagicnumber(con) : Not a PNM format file

Anyother ways to load bitmap images?

Yi-Xiong



From Simon.Blomberg at anu.edu.au  Sat Nov 22 01:11:16 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Sat, 22 Nov 2003 11:11:16 +1100
Subject: [R] summary.manova and rank deficiency
Message-ID: <7A3A13F416B40842BD2C1753E044B359B13488@CASEVS02.cas.anu.edu.au>

Hi all,

I have received the following error from summary.manova:

Error in summary.manova(manova.test, test = "Pillai") : 
	residuals have rank 36 < 64

The data is simulated data for 64 variables. The design is a 2*2 factorial with 10 replicates per treatment. Looking at the code for summary.manova,  the error involves a problem with qr(). Does anyone have a suggestion as to how to deal with this error? The analysis works fine when there are only 32 variables.

Thanks,

Simon.

Simon Blomberg, PhD
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379



From dmurdoch at pair.com  Sat Nov 22 01:37:25 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 21 Nov 2003 19:37:25 -0500
Subject: [R] How to read .bmp files into R? read.pnm throws error
In-Reply-To: <DOEGLCMDLJCLMLNMGPMIKEIFCAAA.yzhou@sdsc.edu>
References: <DOEGLCMDLJCLMLNMGPMIKEIFCAAA.yzhou@sdsc.edu>
Message-ID: <t6btrvcqecj5jsakbkpmneucegosfet4i3@4ax.com>

On Fri, 21 Nov 2003 15:57:35 -0800, you wrote:

>Hi,
>
>Is there a way to read .bmp files into R? I have tried read.pnm from pixmap
>package. It returned
>
>Error in pm.readmagicnumber(con) : Not a PNM format file
>
>Anyother ways to load bitmap images?

.bmp format is fairly simple, and is well documented (e.g. see
www.wotsit.org).  It wouldn't be hard to write a reader using
connections.

The only difficulty is that several pixel formats are available.
However, if you have control of the creation of the files, you can
choose 24 bit BMPs, which are the simplest to read.

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Sat Nov 22 02:33:38 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Nov 2003 02:33:38 +0100
Subject: [R] summary.manova and rank deficiency
In-Reply-To: <7A3A13F416B40842BD2C1753E044B359B13488@CASEVS02.cas.anu.edu.au>
References: <7A3A13F416B40842BD2C1753E044B359B13488@CASEVS02.cas.anu.edu.au>
Message-ID: <x2llq9uqz1.fsf@biostat.ku.dk>

"Simon Blomberg" <Simon.Blomberg at anu.edu.au> writes:

> Hi all,
> 
> I have received the following error from summary.manova:
> 
> Error in summary.manova(manova.test, test = "Pillai") : 
> 	residuals have rank 36 < 64
> 
> The data is simulated data for 64 variables. The design is a 2*2
> factorial with 10 replicates per treatment. Looking at the code for
> summary.manova, the error involves a problem with qr(). Does anyone
> have a suggestion as to how to deal with this error? The analysis
> works fine when there are only 32 variables.

So were you expecting "residuals have rank 36 < 32" in that case?? 

Some multivariate tests require that you can obtain a full rank
estimate of the covariance matrix, which requires the residual degrees
of freedom to be less than the number of response variables. Not sure
whether there is a meaningful way to proceed if that is not the case -
I suspect you'll get negative DF for the F tests and similar
awkwardness.  

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sat Nov 22 05:23:33 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Nov 2003 04:23:33 +0000 (GMT)
Subject: [R] How to read .bmp files into R? read.pnm throws error
In-Reply-To: <t6btrvcqecj5jsakbkpmneucegosfet4i3@4ax.com>
Message-ID: <Pine.LNX.4.44.0311220412420.1316-100000@gannet.stats>

On Fri, 21 Nov 2003, Duncan Murdoch wrote:

> On Fri, 21 Nov 2003 15:57:35 -0800, you wrote:
> >
> >Is there a way to read .bmp files into R? I have tried read.pnm from pixmap
> >package. It returned
> >
> >Error in pm.readmagicnumber(con) : Not a PNM format file
> >
> >Anyother ways to load bitmap images?
> 
> .bmp format is fairly simple, and is well documented (e.g. see
> www.wotsit.org).  It wouldn't be hard to write a reader using
> connections.
> 
> The only difficulty is that several pixel formats are available.
> However, if you have control of the creation of the files, you can
> choose 24 bit BMPs, which are the simplest to read.

Even easier is to convert .bmp to .pnm by an external utility. For
example, `convert' from the ImageMagick suite (www.imagemagick.org) can do
this.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jago at mclink.it  Sat Nov 22 09:49:43 2003
From: jago at mclink.it (Stefano Iacus)
Date: Sat, 22 Nov 2003 09:49:43 +0100
Subject: [R] RAqua 1.8.1 binaries available on CRAN
Message-ID: <D10DF528-1CC8-11D8-B6A8-003065CC4CB8@mclink.it>

New binaries for RAqua 1.8.1 are now available on CRAN (main site) and 
will be propagated soon over the network.


Stefano



From Ted.Harding at nessie.mcc.ac.uk  Sat Nov 22 09:40:10 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 22 Nov 2003 08:40:10 -0000 (GMT)
Subject: [R] lm with ordered factors
Message-ID: <XFMail.031122084010.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

No doubt a question with a well-known answer, but I'm unfortunately
not managing to find it readily ... !

I have a quantitative variable Y and a 4-level ordered factor A
(with very unequal numbers at the different levels, by the way).

The command

  lm(Y ~ A)

returns (amongst other stuff) an intercept, and coefficients
A.L, A.Q and A.C for the Linear, Quadratic and Cubic effects.

I'm trying to verify how R computes A.L, A.Q and A.C (equivalently,
and preferably, what are the definitions of these that correspond
to how R computes them). I haven't touched whatever R's default
settings may be for this operation.

Can some kind soul enlighten me?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 22-Nov-03                                       Time: 08:40:10
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Sat Nov 22 10:51:34 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Nov 2003 09:51:34 +0000 (GMT)
Subject: [R] lm with ordered factors
In-Reply-To: <XFMail.031122084010.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0311220947560.24464-100000@gannet.stats>

On Sat, 22 Nov 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> Hi Folks,
> 
> No doubt a question with a well-known answer, but I'm unfortunately
> not managing to find it readily ... !
> 
> I have a quantitative variable Y and a 4-level ordered factor A
> (with very unequal numbers at the different levels, by the way).
> 
> The command
> 
>   lm(Y ~ A)
> 
> returns (amongst other stuff) an intercept, and coefficients
> A.L, A.Q and A.C for the Linear, Quadratic and Cubic effects.
> 
> I'm trying to verify how R computes A.L, A.Q and A.C (equivalently,
> and preferably, what are the definitions of these that correspond
> to how R computes them). I haven't touched whatever R's default
> settings may be for this operation.
> 
> Can some kind soul enlighten me?

?contr.poly, as the default contrasts set by options("contrasts") specify
that for ordered factors. For more details, including how R uses
contrasts, see Chapter 6 of MASS (any edition).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ted.Harding at nessie.mcc.ac.uk  Sat Nov 22 11:35:23 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 22 Nov 2003 10:35:23 -0000 (GMT)
Subject: [R] lm with ordered factors
In-Reply-To: <XFMail.031122084010.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.031122103523.Ted.Harding@nessie.mcc.ac.uk>

On 22-Nov-03 Ted Harding wrote:
> [...]
> I have a quantitative variable Y and a 4-level ordered factor A
> (with very unequal numbers at the different levels, by the way).
> 
> The command
> 
>   lm(Y ~ A)
> 
> returns (amongst other stuff) an intercept, and coefficients
> A.L, A.Q and A.C for the Linear, Quadratic and Cubic effects.
> 
> I'm trying to verify how R computes A.L, A.Q and A.C [...]

Thanks to Brian Ripley ('"contr.poly" and see MASS Ch 6'),
and Berwin Turlach (private response).

In particular, Berwin's revelation

  fm <- lm(Y ~ A)
  model.matrix(fm)

shows me exactly what is going on!

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 22-Nov-03                                       Time: 10:35:23
------------------------------ XFMail ------------------------------



From klot at gsf.de  Sat Nov 22 13:25:28 2003
From: klot at gsf.de (Stephanie Klot)
Date: Sat, 22 Nov 2003 13:25:28 +0100
Subject: [R]: how to plot smooth function estimate from gam (mgcv package) in
	other program
Message-ID: <MCBBJOBEBLEIJHNBAPNICEECCAAA.klot@gsf.de>

Hi all,

I would like to export the smooth function estimate I got from gam to plot
it in another graphics software. In S-plus I use the function preplot() for
that, but it seems not to work in R.
Has somebody an idea how to solve that?

Thanks
Stephanie

********************************
Stephanie von Klot
Institut f?r Epidemiologie
GSF - Forschungszentrum
f?r Umwelt und Gesundheit
Ingolst?dter Landstr. 1
85764 Neuherberg
Germany



From hi_ono2001 at ybb.ne.jp  Sat Nov 22 14:04:34 2003
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Sat, 22 Nov 2003 22:04:34 +0900
Subject: [R] About implementing triangulation function in gpclib
Message-ID: <001601c3b0f9$2d28cde0$818001db@webgis>

Hello.

 I've used triangulation function of 'original' gpc to generate vrml files
from ESRI Shapefiles.

 In CRAN, tripack can do triangulation, but gpclib's triangulation can only
create within polygons.

 Do you have any plan to implement this triangulation function into gpclib.

 Regards.



From dmurdoch at pair.com  Sat Nov 22 15:07:12 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 22 Nov 2003 09:07:12 -0500
Subject: [R] R-1.8.1 is released 
In-Reply-To: <x2oev5x532.fsf@biostat.ku.dk>
References: <x2oev5x532.fsf@biostat.ku.dk>
Message-ID: <84rurv0ltq4kcl6hse170od1sgkhn7fpr6@4ax.com>

On 21 Nov 2003 13:45:53 +0100, you wrote:

>I've rolled up R-1.8.1.tgz a short while ago. This is a patch version
>mostly fixing a number of issues in 1.8.0, some of which were quite
>serious. As usual, a few new features have crept in as well. (See below
>for details.)
>
>You can get it from
>
>http://cran.us.r-project.org/src/base/R-1.8.1.tgz

The Windows build of 1.8.1 is now on CRAN and the mirrors.  Get it at

<http://cran.us.r-project.org/bin/windows/base>.

See the CHANGES file in that directory for Windows-specific news.


Duncan Murdoch

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From apiszcz at solarrain.com  Sat Nov 22 17:57:32 2003
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sat, 22 Nov 2003 11:57:32 -0500 (EST)
Subject: [R] 1.8.1 behavior change?
Message-ID: <Pine.LNX.4.55.0311221154310.6457@l1>


In <R 1.8.1 the following fragment worked properly, now (1.8.1)
it creates the following warning/error:

Any advice appreciated.


  stt <- data.frame()
  # load all datasets into a dataframe
  for (ds in 1:n) {
    stt[ds] <- as.matrix(read.table(fileList[ds]))
  }


--

>   stt <- data.frame()
>   # load all datasets into a dataframe
>   for (ds in 1:n) {
+     stt[ds] <- as.matrix(read.table(fileList[ds]))
+   }
Error in "[<-.data.frame"(`*tmp*`, ds, value =
as.matrix(read.table(fileList[ds]))) :
        replacement has 358 rows, data has 0
>



From takeshi.takama at transport-studies.oxford.ac.uk  Sat Nov 22 19:17:53 2003
From: takeshi.takama at transport-studies.oxford.ac.uk (Takeshi Takama)
Date: Sat, 22 Nov 2003 18:17:53 -0000
Subject: R crashes with package SJava; was [R] Memory leakage?
Message-ID: <002101c3b124$f22dc250$063301a3@tsu.ox.ac.uk>

Dear All,

<<OS and software>>
    R-1.81
    j2sdk1.4.0_03
    SJava_0.66-1
    Windows NT4.01


I try to run R from Java with SJava and I seem to have the same problem as
discussed before in this mail list a few month ago:
https://www.stat.math.ethz.ch/pipermail/r-help/2003-May/031960.html
https://www.stat.math.ethz.ch/pipermail/r-help/2003-May/031962.html
https://www.stat.math.ethz.ch/pipermail/r-help/2003-May/031963.html
https://www.stat.math.ethz.ch/pipermail/r-help/2003-May/031965.html
https://www.stat.math.ethz.ch/pipermail/r-help/2003-May/031969.html
https://www.stat.math.ethz.ch/pipermail/r-help/2003-May/032048.html

I think I set up JAVA_HOME property, i.e. JAVA_HOME="D:\j2sdk1.4.0_03\jre"
So, I can see that these sentences work from R.
    library(SJava)
     .JavaInit()
     .Java("java.lang.System", "getProperty", "java.class.path")
     names(.Java("java.lang.System", "getProperties"))

However, when I try to run an example which uses a call-back process from
Java to R, such as "ttest.R" http://www.omegahat.org/RSJava/examples/ttest.R
R crushes when I press the "submit" button. However, the RGui.exe is still
running as a process but not application. This problem is exactly the same
as the one discussed in the links above.  Also, I have not succeeded to call
R from Java, either.  So, simply there is a problem of call-back from Java
to R.

The discussion a few months ago looks suddenly ended, so I could not get the
answer for this problem, or I might have missed searching the archive since
I am very new to this mail list.  I am trying to solve this problem for more
than a week and have no one using R around me. So, it would be grateful if
anyone can give me any hint to solve this problem.
Thank you

Best regards,
Tak

P.S. Please tell me if I need to set else environment variables other than
JAVA_HOME.
The output I get after I type ".javaConfig" is below:

> .javaConfig
$classPath
[1] "D:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/Environment.jar"
[2] "D:/PROGRA~1/R/rw1081/library/SJava/org/.."
[3] "D:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/antlr.jar"
[4] "D:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/jas.jar"
[5] "D:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/jhall.jar"

$properties
                                                                 EmbeddedInR
                                                                      "true"
                                                       InterfaceManagerClass
             "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager"
                                                   ForeignReferenceBaseClass
                                     "org/omegahat/R/Java/RForeignReference"
                                                               java.compiler
                                                                      "NONE"
                                                                  OMEGA_HOME
                           "D:/PROGRA~1/R/rw1081/library/SJava/org/omegahat"
                                                          OmegahatSearchPath
".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/Environment.jar"
                                                           java.library.path
                                   "D:/PROGRA~1/R/rw1081/library/SJava/libs"

$libraryPath
[1] "D:/PROGRA~1/R/rw1081/library/SJava/libs"


================
Takeshi Takama
University of Oxford
Transport Studies Unit
St. Catherine's College
     Oxford Kobe scholar
phone ++44 (01865) 2 74709
fax   ++44 (01865) 515194
takeshi.takma at tsu.ox.ac.uk



From ripley at stats.ox.ac.uk  Sat Nov 22 19:41:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Nov 2003 18:41:55 +0000 (GMT)
Subject: [R] 1.8.1 behavior change?
In-Reply-To: <Pine.LNX.4.55.0311221154310.6457@l1>
Message-ID: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>

On Sat, 22 Nov 2003, Al Piszcz wrote:

> In <R 1.8.1 the following fragment worked properly, now (1.8.1)

I take it you mean R < 1.8.1?  In trying to reproduce something
like this

stt <- data.frame()
stt[1] <- as.matrix(data.frame(foo=1:10, bar=letters[1:10]))

in 1.8.0 I got

> stt
[1] V1
<0 rows> (or 0-length row.names)

so is that what `worked properly' means?  (It is also what S+6.1 does, but
I am pretty sure it is not what anyone wanted.  Note the number of 
columns is wrong, too.)

In 1.7.1 it gave a similar error to 1.8.1.

So as far as I can see (given you did not supply a test example) 1.8.1 is
just more helpful by pointing out your user error.  The rule is that the
existing columns should be replicated an exact number of times when
extending a data frame: and that includes the row names so applies even if
there are no other columns.

I hope each of your input files except the last have just one column (in 
which case your code is very clunky) as otherwise you are asking for 
columns to be overwritten.  I would advise you to use cbind for this, 
or dimension the data frame correctly in the first place and replace 
sections at a time.

> it creates the following warning/error:
> 
> Any advice appreciated.

Supply reproducible examples, as the FAQ asks.  I have no idea why you
have given the same code twice here, BTW, so I remove the first copy.


> >   stt <- data.frame()
> >   # load all datasets into a dataframe
> >   for (ds in 1:n) {
> +     stt[ds] <- as.matrix(read.table(fileList[ds]))
> +   }
> Error in "[<-.data.frame"(`*tmp*`, ds, value =
> as.matrix(read.table(fileList[ds]))) :
>         replacement has 358 rows, data has 0

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Sat Nov 22 19:45:23 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 22 Nov 2003 13:45:23 -0500
Subject: [R] 1.8.1 behavior change?
In-Reply-To: <Pine.LNX.4.55.0311221154310.6457@l1>
References: <Pine.LNX.4.55.0311221154310.6457@l1>
Message-ID: <79bvrv0vr9np4m2v7a0r5eb6uijbph8h2a@4ax.com>

On Sat, 22 Nov 2003 11:57:32 -0500 (EST), you wrote:

>
>In <R 1.8.1 the following fragment worked properly, now (1.8.1)
>it creates the following warning/error:
>
>Any advice appreciated.
>
>
>  stt <- data.frame()
>  # load all datasets into a dataframe
>  for (ds in 1:n) {
>    stt[ds] <- as.matrix(read.table(fileList[ds]))
>  }

I don't know what you are trying to do here. I can't run this code in
1.7.1 because so much is missing, but I get errors with simple
approximations like this:

> stt <- data.frame()
> stt[1] <- as.matrix(data.frame(a=1:5,b=1:5))
Error in "names<-.default"(*tmp*, value = new.cols) : 
        names attribute must be the same length as the vector
In addition: Warning message: 
Replacement length not a multiple of the elements to replace in
matrix(...) 

This is not surprising:  stt[1] is a data.frame with no rows or
columns

Could you please give a reproducible example that fails in 1.8.1, but
runs in a recent earlier version?

Duncan Murdoch



From korponai at georgikon.hu  Sat Nov 22 19:50:36 2003
From: korponai at georgikon.hu (Korponai =?iso-8859-2?q?J=E1nos?=)
Date: Sat, 22 Nov 2003 19:50:36 +0100
Subject: [R] Warning: X11 protocol error: BadWindow (invalid Window
	parameter)
Message-ID: <200311221950.36723.korponai@georgikon.hu>

Hi all,
I've got this using Rcmdr package only.
R-cmdr> scatterplot.matrix(~PC1+PC2+PC3+PC4 | Species, 
reg.line=FALSE, smooth=FALSE, span=0.5, diagonal= 'density', 
by.groups=TRUE, data=iris)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)
Warning: X11 protocol error: BadWindow (invalid Window parameter)

What's this? The plot is shown.

Thanks

> version
         _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status   Under development (unstable)
major    1
minor    8.0
year     2003
month    09
day      06
language R

-- 
Dr. Janos Korponai
West-Transdanubian District Water Authority, Dept. Kis-Balaton
H-8360 Keszthely, Csik F. str. 1, Hungary
e-mail: korponai.janos at nyuduvizig.hu



From gopal_a00 at hotmail.com  Sat Nov 22 20:50:40 2003
From: gopal_a00 at hotmail.com (Gopal Annasundaram)
Date: Sat, 22 Nov 2003 11:50:40 -0800
Subject: [R] arima {ts}
Message-ID: <BAY99-DAV13iu3fQtYd00000525@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031122/f1466f83/attachment.pl

From ripley at stats.ox.ac.uk  Sat Nov 22 20:55:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Nov 2003 19:55:30 +0000 (GMT)
Subject: [R] ISOdate() and strptime()
In-Reply-To: <Pine.LNX.4.44.0311141102040.24857-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0311221932390.353-100000@gannet.stats>

Confirmation that this *is* an OS-specific problem: A professional 
implementation of the POSIX standard (Solaris) gets all of these correct.

Your so-called OS lacks any implementation of strptime, so we borrowed one 
from glibc.  Unfortunately, that is buggy, even to the extent that

unclass(strptime("2003-22-20", format="%Y-%m-%d"))
unclass(strptime("2003 22 20", format="%Y %m %d"))

give different answers!  (And RH8.0 gives the same answers as the 
substitute code used on R for Windows.)

I believe Simon Fear owes the R-developers a public apology for his (not
properly referenced in the archives) reply to this thread.

BDR

On Fri, 14 Nov 2003, Prof Brian Ripley wrote:

> On Fri, 14 Nov 2003, RINNER Heinrich wrote:
> 
> > Dear R-people!
> > 
> > I am using R 1.8.0, under Windows XP.
> > While using ISOdate() and strptime(), I noticed the following behaviour when
> > "wrong" arguments (e.g., months>12) are given to these functions:
> > 
> > > ISOdate(year=2003,month=2,day=20) #ok
> > [1] "2003-02-20 13:00:00 Westeurop?ische Normalzeit"
> > > ISOdate(year=2003,month=2,day=30) #wrong day, but returns a value
> > [1] "2003-03-02 13:00:00 Westeurop?ische Normalzeit"
> > > ISOdate(year=2003,month=2,day=35) #wrong day, and returns NA
> > [1] NA
> > > ISOdate(year=2003,month=2,day=40) #wrong day, but returns a value
> > [1] "2003-02-04 01:12:00 Westeurop?ische Normalzeit"
> > > ISOdate(year=2003,month=22,day=20) #wrong month, but returns a value
> > [1] "2003-02-02 21:12:00 Westeurop?ische Normalzeit"
> > 
> > And almost the same with strptime():
> > > strptime("2003-02-20", format="%Y-%m-%d")
> > [1] "2003-02-20"
> > > strptime("2003-02-30", format="%Y-%m-%d")
> > [1] "2003-03-02"
> > > strptime("2003-02-35", format="%Y-%m-%d")
> > [1] NA
> > > strptime("2003-02-40", format="%Y-%m-%d")
> > [1] "2003-02-04"
> > > strptime("2003-22-20", format="%Y-%m-%d")
> > [1] NA
> > 
> > Is this considered to be a user error ("If you put garbage in, expect to get
> > garbage out"), or would it be safer to generally return Nas, as in
> > ISOdate(year=2003,month=2,day=35)?
> 
> Expect to get the best guess at what you intended, and expect this to 
> depend on your OS.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From apiszcz at solarrain.com  Sat Nov 22 21:14:31 2003
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sat, 22 Nov 2003 15:14:31 -0500 (EST)
Subject: [R] 1.8.1 behavior change?
In-Reply-To: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>
References: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>
Message-ID: <Pine.LNX.4.55.0311221506300.6460@l1>


I would like to have one handle or reference to
'n' matrices. The matrices vary in size.
All data is floating point.
The input files have 21 columns and a varying
number of rows.

I am open to any data structure that will
support this.








On Sat, 22 Nov 2003, Prof Brian Ripley wrote:

> Date: Sat, 22 Nov 2003 18:41:55 +0000 (GMT)
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: Al Piszcz <apiszcz at solarrain.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] 1.8.1 behavior change?
>
> On Sat, 22 Nov 2003, Al Piszcz wrote:
>
> > In <R 1.8.1 the following fragment worked properly, now (1.8.1)
>
> I take it you mean R < 1.8.1?  In trying to reproduce something
> like this
>
> stt <- data.frame()
> stt[1] <- as.matrix(data.frame(foo=1:10, bar=letters[1:10]))
>
> in 1.8.0 I got
>
> > stt
> [1] V1
> <0 rows> (or 0-length row.names)
>
> so is that what `worked properly' means?  (It is also what S+6.1 does, but
> I am pretty sure it is not what anyone wanted.  Note the number of
> columns is wrong, too.)
>
> In 1.7.1 it gave a similar error to 1.8.1.
>
> So as far as I can see (given you did not supply a test example) 1.8.1 is
> just more helpful by pointing out your user error.  The rule is that the
> existing columns should be replicated an exact number of times when
> extending a data frame: and that includes the row names so applies even if
> there are no other columns.
>
> I hope each of your input files except the last have just one column (in
> which case your code is very clunky) as otherwise you are asking for
> columns to be overwritten.  I would advise you to use cbind for this,
> or dimension the data frame correctly in the first place and replace
> sections at a time.
>
> > it creates the following warning/error:
> >
> > Any advice appreciated.
>
> Supply reproducible examples, as the FAQ asks.  I have no idea why you
> have given the same code twice here, BTW, so I remove the first copy.
>
>
> > >   stt <- data.frame()
> > >   # load all datasets into a dataframe
> > >   for (ds in 1:n) {
> > +     stt[ds] <- as.matrix(read.table(fileList[ds]))
> > +   }
> > Error in "[<-.data.frame"(`*tmp*`, ds, value =
> > as.matrix(read.table(fileList[ds]))) :
> >         replacement has 358 rows, data has 0
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From apiszcz at solarrain.com  Sat Nov 22 21:36:19 2003
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sat, 22 Nov 2003 15:36:19 -0500 (EST)
Subject: [R] 1.8.1 behavior change? W EXAMPLE
In-Reply-To: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>
References: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>
Message-ID: <Pine.LNX.4.55.0311221534280.6915@l1>



Here is a working example with R 1.8.0, followed by the
test files, and finally the R 1.8.1 error messages.


**** [1] R 1.8.0 WORKING EXAMPLE

R

R : Copyright 2003, The R Development Core Team
Version 1.8.0  (2003-10-08)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> stt <- data.frame()
> stt[1]<-as.matrix(read.table("a"))
> stt[2]<-as.matrix(read.table("b"))
> stt[3]<-as.matrix(read.table("c"))
> stt[1]
[1] V1
<0 rows> (or 0-length row.names)
> stt[,1]
  V1 V2 V3
1  1  2  3
2  4  5  6
3  7  8  9
> stt[,2]
  V1 V2 V3
1 10 11 12
2 13 14 15
3 16 17 18
> stt[,3]
  V1 V2 V3
1 19 20 21
2 22 23 24
3 25 26 27
>



**** [2] FILES
::::::::::::::
a
::::::::::::::
1 2 3
4 5 6
7 8 9
::::::::::::::
b
::::::::::::::
10 11 12
13 14 15
16 17 18
::::::::::::::
c
::::::::::::::
19 20 21
22 23 24
25 26 27




**** [3] R 1.8.1 Error
$ R

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> stt <- data.frame()
> stt[1]<-as.matrix(read.table("a"))
Error in "[<-.data.frame"(`*tmp*`, 1, value = as.matrix(read.table("a")))
:
        replacement has 3 rows, data has 0
apiszcz at l1:/x/t_16 $ R

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> stt <- data.frame()
> stt[1]<-as.matrix(read.table("a"))
Error in "[<-.data.frame"(`*tmp*`, 1, value = as.matrix(read.table("a")))
:
        replacement has 3 rows, data has 0





On Sat, 22 Nov 2003, Prof Brian Ripley wrote:

> Date: Sat, 22 Nov 2003 18:41:55 +0000 (GMT)
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: Al Piszcz <apiszcz at solarrain.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] 1.8.1 behavior change?
>
> On Sat, 22 Nov 2003, Al Piszcz wrote:
>
> > In <R 1.8.1 the following fragment worked properly, now (1.8.1)
>
> I take it you mean R < 1.8.1?  In trying to reproduce something
> like this
>
> stt <- data.frame()
> stt[1] <- as.matrix(data.frame(foo=1:10, bar=letters[1:10]))
>
> in 1.8.0 I got
>
> > stt
> [1] V1
> <0 rows> (or 0-length row.names)
>
> so is that what `worked properly' means?  (It is also what S+6.1 does, but
> I am pretty sure it is not what anyone wanted.  Note the number of
> columns is wrong, too.)
>
> In 1.7.1 it gave a similar error to 1.8.1.
>
> So as far as I can see (given you did not supply a test example) 1.8.1 is
> just more helpful by pointing out your user error.  The rule is that the
> existing columns should be replicated an exact number of times when
> extending a data frame: and that includes the row names so applies even if
> there are no other columns.
>
> I hope each of your input files except the last have just one column (in
> which case your code is very clunky) as otherwise you are asking for
> columns to be overwritten.  I would advise you to use cbind for this,
> or dimension the data frame correctly in the first place and replace
> sections at a time.
>
> > it creates the following warning/error:
> >
> > Any advice appreciated.
>
> Supply reproducible examples, as the FAQ asks.  I have no idea why you
> have given the same code twice here, BTW, so I remove the first copy.
>
>
> > >   stt <- data.frame()
> > >   # load all datasets into a dataframe
> > >   for (ds in 1:n) {
> > +     stt[ds] <- as.matrix(read.table(fileList[ds]))
> > +   }
> > Error in "[<-.data.frame"(`*tmp*`, ds, value =
> > as.matrix(read.table(fileList[ds]))) :
> >         replacement has 358 rows, data has 0
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From christoff_pale at yahoo.com  Sat Nov 22 22:37:03 2003
From: christoff_pale at yahoo.com (christoff pale)
Date: Sat, 22 Nov 2003 13:37:03 -0800 (PST)
Subject: [R] plotting and overlay
Message-ID: <20031122213703.95298.qmail@web40812.mail.yahoo.com>

Hi,
I am use to matlab and when I want to 
overlay multiple plots on the same graphics devise
I type in "hold on" and when I am done I type in
"hold off"

Does R have an equivalent feature?
can someone give me an example where they plotted
2 functions on top of each other? thanks



From spencer.graves at pdf.com  Sat Nov 22 22:54:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 22 Nov 2003 13:54:34 -0800
Subject: [R] plotting and overlay
In-Reply-To: <20031122213703.95298.qmail@web40812.mail.yahoo.com>
References: <20031122213703.95298.qmail@web40812.mail.yahoo.com>
Message-ID: <3FBFDB1A.7040004@pdf.com>

Start the plot using "plot", add lines and points using "lines" and 
"points", as described in the examples with "?plot". 

hope this helps.  spencer graves

christoff pale wrote:

>Hi,
>I am use to matlab and when I want to 
>overlay multiple plots on the same graphics devise
>I type in "hold on" and when I am done I type in
>"hold off"
>
>Does R have an equivalent feature?
>can someone give me an example where they plotted
>2 functions on top of each other? thanks
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From apiszcz at solarrain.com  Sat Nov 22 23:07:49 2003
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sat, 22 Nov 2003 17:07:49 -0500 (EST)
Subject: [R] 1.8.1 behavior change?
In-Reply-To: <3FBFD464.2060605@pburns.seanet.com>
References: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>
	<Pine.LNX.4.55.0311221506300.6460@l1>
	<3FBFD464.2060605@pburns.seanet.com>
Message-ID: <Pine.LNX.4.55.0311221707070.7046@l1>

Thank you very much!

This method works with R 1.8.0 and R 1.8.1



R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> stt <- vector("list", 4)
> stt[[1]]<-as.matrix(read.table("a"))
> stt[[2]]<-as.matrix(read.table("b"))
> stt[[3]]<-as.matrix(read.table("c"))
> stt[[4]]<-as.matrix(read.table("d"))
> stt.allmat <- do.call("rbind", stt)
> stt
[[1]]
  V1 V2 V3
1  1  2  3
2  4  5  6
3  7  8  9

[[2]]
  V1 V2 V3
1 10 11 12
2 13 14 15
3 16 17 18

[[3]]
  V1 V2 V3
1 19 20 21
2 22 23 24
3 25 26 27

[[4]]
  V1 V2 V3
1 28 29 30
2 31 32 33
3 34 35 36
4 37 38 39

> stt[[4]]
  V1 V2 V3
1 28 29 30
2 31 32 33
3 34 35 36
4 37 38 39






On Sat, 22 Nov 2003, Patrick
Burns wrote:

> Date: Sat, 22 Nov 2003 21:25:56 +0000
> From: Patrick Burns <pburns at pburns.seanet.com>
> To: Al Piszcz <apiszcz at solarrain.com>
> Subject: Re: [R] 1.8.1 behavior change?
>
> I would suggest a list that is n long, or alternatively rbind
> the matrices together (assuming that the columns all have
> the same meaning and are in the same order).
>
> stt <- vector("list", n)
> for(i in 1:n) stt[[i]] <- as.matrix(read.table(... ))
>
> stt.allmat <- do.call("rbind", stt)
>
> Patrick Burns
>
> Burns Statistics
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> Al Piszcz wrote:
>
> >I would like to have one handle or reference to
> >'n' matrices. The matrices vary in size.
> >All data is floating point.
> >The input files have 21 columns and a varying
> >number of rows.
> >
> >I am open to any data structure that will
> >support this.
> >
> >
> >
> >
> >
> >
> >
> >
> >On Sat, 22 Nov 2003, Prof Brian Ripley wrote:
> >
> >
> >
> >>Date: Sat, 22 Nov 2003 18:41:55 +0000 (GMT)
> >>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> >>To: Al Piszcz <apiszcz at solarrain.com>
> >>Cc: r-help at stat.math.ethz.ch
> >>Subject: Re: [R] 1.8.1 behavior change?
> >>
> >>On Sat, 22 Nov 2003, Al Piszcz wrote:
> >>
> >>
> >>
> >>>In <R 1.8.1 the following fragment worked properly, now (1.8.1)
> >>>
> >>>
> >>I take it you mean R < 1.8.1?  In trying to reproduce something
> >>like this
> >>
> >>stt <- data.frame()
> >>stt[1] <- as.matrix(data.frame(foo=1:10, bar=letters[1:10]))
> >>
> >>in 1.8.0 I got
> >>
> >>
> >>
> >>>stt
> >>>
> >>>
> >>[1] V1
> >><0 rows> (or 0-length row.names)
> >>
> >>so is that what `worked properly' means?  (It is also what S+6.1 does, but
> >>I am pretty sure it is not what anyone wanted.  Note the number of
> >>columns is wrong, too.)
> >>
> >>In 1.7.1 it gave a similar error to 1.8.1.
> >>
> >>So as far as I can see (given you did not supply a test example) 1.8.1 is
> >>just more helpful by pointing out your user error.  The rule is that the
> >>existing columns should be replicated an exact number of times when
> >>extending a data frame: and that includes the row names so applies even if
> >>there are no other columns.
> >>
> >>I hope each of your input files except the last have just one column (in
> >>which case your code is very clunky) as otherwise you are asking for
> >>columns to be overwritten.  I would advise you to use cbind for this,
> >>or dimension the data frame correctly in the first place and replace
> >>sections at a time.
> >>
> >>
> >>
> >>>it creates the following warning/error:
> >>>
> >>>Any advice appreciated.
> >>>
> >>>
> >>Supply reproducible examples, as the FAQ asks.  I have no idea why you
> >>have given the same code twice here, BTW, so I remove the first copy.
> >>
> >>
> >>
> >>
> >>>>  stt <- data.frame()
> >>>>  # load all datasets into a dataframe
> >>>>  for (ds in 1:n) {
> >>>>
> >>>>
> >>>+     stt[ds] <- as.matrix(read.table(fileList[ds]))
> >>>+   }
> >>>Error in "[<-.data.frame"(`*tmp*`, ds, value =
> >>>as.matrix(read.table(fileList[ds]))) :
> >>>        replacement has 358 rows, data has 0
> >>>
> >>>
> >>--
> >>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>1 South Parks Road,                     +44 1865 272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> >>
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> >
> >
>
>



From dmurdoch at pair.com  Sat Nov 22 23:10:39 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 22 Nov 2003 17:10:39 -0500
Subject: [R] 1.8.1 behavior change?
In-Reply-To: <Pine.LNX.4.55.0311221506300.6460@l1>
References: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>
	<Pine.LNX.4.55.0311221506300.6460@l1>
Message-ID: <onkvrvg723s0qcmfntn41oseqaic3t4iq7@4ax.com>

On Sat, 22 Nov 2003 15:14:31 -0500 (EST), you wrote:

>
>I would like to have one handle or reference to
>'n' matrices. The matrices vary in size.
>All data is floating point.
>The input files have 21 columns and a varying
>number of rows.
>
>I am open to any data structure that will
>support this.

Why not store them in a list, e.g.

> stt <- list()
> for (i in 1:3) stt[[i]] <- matrix(i, i, i)
> 
> stt
[[1]]
     [,1]
[1,]    1

[[2]]
     [,1] [,2]
[1,]    2    2
[2,]    2    2

[[3]]
     [,1] [,2] [,3]
[1,]    3    3    3
[2,]    3    3    3
[3,]    3    3    3

There are no restrictions on the shapes of the matrices that can be
stored this way.  You access matrix i entry (j,k) as stt[[i]][j,k].

Duncan Murdoch



From dmurdoch at pair.com  Sat Nov 22 23:13:54 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 22 Nov 2003 17:13:54 -0500
Subject: [R] plotting and overlay
In-Reply-To: <3FBFDB1A.7040004@pdf.com>
References: <20031122213703.95298.qmail@web40812.mail.yahoo.com>
	<3FBFDB1A.7040004@pdf.com>
Message-ID: <donvrv4th3ppfck0b09qps0a6nne8oit7o@4ax.com>

On Sat, 22 Nov 2003 13:54:34 -0800, Spencer Graves
<spencer.graves at pdf.com> wrote:

>Start the plot using "plot", add lines and points using "lines" and 
>"points", as described in the examples with "?plot". 

That's how you do plots that you construct yourself; you can get a lot
of the higher level functions (e.g. hist) to do this using the
argument "add=TRUE".

Duncan Murdoch



From apiszcz at solarrain.com  Sat Nov 22 23:19:45 2003
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sat, 22 Nov 2003 17:19:45 -0500 (EST)
Subject: [R] 1.8.1 behavior change?
In-Reply-To: <onkvrvg723s0qcmfntn41oseqaic3t4iq7@4ax.com>
References: <Pine.LNX.4.44.0311221818550.32532-100000@gannet.stats>
	<Pine.LNX.4.55.0311221506300.6460@l1>
	<onkvrvg723s0qcmfntn41oseqaic3t4iq7@4ax.com>
Message-ID: <Pine.LNX.4.55.0311221719000.7325@l1>



That is what the last suggestion was and
it works, see previous message from me. Thx again.
I'm changing my code to use this method now.


On Sat, 22 Nov 2003,
Duncan Murdoch wrote:

> Date: Sat, 22 Nov 2003 17:10:39 -0500
> From: Duncan Murdoch <dmurdoch at pair.com>
> To: Al Piszcz <apiszcz at solarrain.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] 1.8.1 behavior change?
>
> On Sat, 22 Nov 2003 15:14:31 -0500 (EST), you wrote:
>
> >
> >I would like to have one handle or reference to
> >'n' matrices. The matrices vary in size.
> >All data is floating point.
> >The input files have 21 columns and a varying
> >number of rows.
> >
> >I am open to any data structure that will
> >support this.
>
> Why not store them in a list, e.g.
>
> > stt <- list()
> > for (i in 1:3) stt[[i]] <- matrix(i, i, i)
> >
> > stt
> [[1]]
>      [,1]
> [1,]    1
>
> [[2]]
>      [,1] [,2]
> [1,]    2    2
> [2,]    2    2
>
> [[3]]
>      [,1] [,2] [,3]
> [1,]    3    3    3
> [2,]    3    3    3
> [3,]    3    3    3
>
> There are no restrictions on the shapes of the matrices that can be
> stored this way.  You access matrix i entry (j,k) as stt[[i]][j,k].
>
> Duncan Murdoch
>



From kjetil at entelnet.bo  Sat Nov 22 23:25:26 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sat, 22 Nov 2003 18:25:26 -0400
Subject: [R] plotting and overlay
In-Reply-To: <20031122213703.95298.qmail@web40812.mail.yahoo.com>
Message-ID: <3FBFAA16.20163.12C3BBD@localhost>

On 22 Nov 2003 at 13:37, christoff pale wrote:

In R many graphics functions take an argument add, and there are some
functions (points, lines) which add data to an existing graph. 

Some examples:

plot( dnorm, from=-3, to=3 )
plot( function(x) dt(x, 2), from=-3, to=3, col="red2", add=TRUE)

x <- rnorm(20)
y <- rnorm(20)
plot(x,t, type="n")
points(x,y, col="skyblue")

Kjetil Halvorsen

> Hi,
> I am use to matlab and when I want to 
> overlay multiple plots on the same graphics devise
> I type in "hold on" and when I am done I type in
> "hold off"
> 
> Does R have an equivalent feature?
> can someone give me an example where they plotted
> 2 functions on top of each other? thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From wang at galton.uchicago.edu  Sun Nov 23 01:12:03 2003
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sat, 22 Nov 2003 18:12:03 -0600 (CST)
Subject: [R] where to get the "leaps" package
In-Reply-To: <200311221102.hAMB2BPf008199@hypatia.math.ethz.ch>
Message-ID: <Pine.GSO.4.05.10311221806080.17830-100000@aitken.uchicago.edu>

Dear all
I am supposed to use Mallow's Cp creterion to select a model which require
a "leaps" package. the version right now I am using is R
1.7.1(os:windows), the "leaps" package is not included. please let me know
how and where
can I get this package and add it to the current version, any caution on
adding this package is highly appreciated.
thank you 

best



From kjetil at entelnet.bo  Sun Nov 23 01:49:21 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sat, 22 Nov 2003 20:49:21 -0400
Subject: [R] where to get the "leaps" package
In-Reply-To: <Pine.GSO.4.05.10311221806080.17830-100000@aitken.uchicago.edu>
References: <200311221102.hAMB2BPf008199@hypatia.math.ethz.ch>
Message-ID: <3FBFCBD1.28634.8A1C7@localhost>

On 22 Nov 2003 at 18:12, Yong Wang wrote:

You should find it on CRAN, the Comprehensive R Archival
Network. Search google for CRAN. 
or if you are on windows, go to menu Packages --- install packages 
from CRAN.

Kjetil Halvorsen

> Dear all
> I am supposed to use Mallow's Cp creterion to select a model which
> require a "leaps" package. the version right now I am using is R
> 1.7.1(os:windows), the "leaps" package is not included. please let me
> know how and where can I get this package and add it to the current
> version, any caution on adding this package is highly appreciated.
> thank you 
> 
> best
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sun Nov 23 03:20:26 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sat, 22 Nov 2003 22:20:26 -0400
Subject: [R] options(width= ) in rw1081
Message-ID: <3FBFE12A.24242.5C080F@localhost>

Hola!

I just downloaded and installed the factory-fresh
rw1081. Windows XP. 

In my Rprofile file in the \etc subdirectory I put
(among others)


options(continue=" ")
options(width=65)
options(scipen=5)
options(show.signif.stars=FALSE)

R is honoring all of this on startup, exept 
the width=65 option, which does'nt have any effect. I tried
other values for width also (70, 90) , none honored. R keeps
the system default of 80. 

Kjetil Halvorsen



From andy_liaw at merck.com  Sun Nov 23 04:05:02 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 22 Nov 2003 22:05:02 -0500
Subject: [R] where to get the "leaps" package
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE7F@usrymx25.merck.com>

Once you start up Rgui, click on the menu "Packages" -> "Install packages
from CRAN", and then select "leaps" from the list and click OK.

Andy

> From: r-help-bounces at stat.math.ethz.ch 
> 
> Dear all
> I am supposed to use Mallow's Cp creterion to select a model 
> which require a "leaps" package. the version right now I am 
> using is R 1.7.1(os:windows), the "leaps" package is not 
> included. please let me know how and where can I get this 
> package and add it to the current version, any caution on 
> adding this package is highly appreciated. thank you 
> 
> best



From ripley at stats.ox.ac.uk  Sun Nov 23 07:18:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Nov 2003 06:18:42 +0000 (GMT)
Subject: [R] options(width= ) in rw1081
In-Reply-To: <3FBFE12A.24242.5C080F@localhost>
Message-ID: <Pine.LNX.4.44.0311230607330.12353-100000@gannet.stats>

On Sat, 22 Nov 2003 kjetil at entelnet.bo wrote:

> I just downloaded and installed the factory-fresh
> rw1081. Windows XP. 
> 
> In my Rprofile file in the \etc subdirectory I put
> (among others)
> 
> 
> options(continue=" ")
> options(width=65)
> options(scipen=5)
> options(show.signif.stars=FALSE)
> 
> R is honoring all of this on startup, exept 
> the width=65 option, which does'nt have any effect. I tried
> other values for width also (70, 90) , none honored. R keeps
> the system default of 80. 

Is this in Rgui?  Then it actually keeps to the width of the console on
startup.  From etc/Rconsole

# should options(width=) be set to the console width?
setwidthonresize = yes

So please check that you have set that to your wishes (I guess you have
not).  Unless you resize the console, setting options(width=65) in the
console itself will work.

None of this applies to Rterm.

NB: this *is* in the rw-FAQ, Q4.2.  In case it is not clear to you,
opening the console is a resizing of it, from width and height 0.

NBB: the behaviour is unchanged since rw0641!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Nov 23 07:22:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Nov 2003 06:22:39 +0000 (GMT)
Subject: [R] plotting and overlay
In-Reply-To: <donvrv4th3ppfck0b09qps0a6nne8oit7o@4ax.com>
Message-ID: <Pine.LNX.4.44.0311230619480.12353-100000@gannet.stats>

On Sat, 22 Nov 2003, Duncan Murdoch wrote:

> On Sat, 22 Nov 2003 13:54:34 -0800, Spencer Graves
> <spencer.graves at pdf.com> wrote:
> 
> >Start the plot using "plot", add lines and points using "lines" and 
> >"points", as described in the examples with "?plot". 
> 
> That's how you do plots that you construct yourself; you can get a lot
> of the higher level functions (e.g. hist) to do this using the
> argument "add=TRUE".

And if you really want to overlay plots, there is par(new=TRUE).  (This 
will replot the axes etc, so the second plot may perhaps need axes=FALSE 
or xaxt="n", yaxt="n" in its call.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From smyth at wehi.edu.au  Sun Nov 23 07:34:04 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sun, 23 Nov 2003 17:34:04 +1100
Subject: [R] cross-classified random factors in lme without
	blocking - success
In-Reply-To: <3FB67086.2090704@pdf.com>
References: <6rbrrx33us.fsf@bates4.stat.wisc.edu>
	<5.2.1.1.1.20031031153622.00acecc8@imaphost.wehi.edu.au>
	<x2r80trbmv.fsf@biostat.ku.dk>
	<6rbrrx33us.fsf@bates4.stat.wisc.edu>
	<5.2.1.1.1.20031115151417.00ae7318@imaphost.wehi.edu.au>
	<3FB67086.2090704@pdf.com>
Message-ID: <6.0.1.1.1.20031123172910.02962c08@imaphost.wehi.edu.au>

Sundar's advice seems to do the trick. Here is a small simulation of a 
cross-classified random model with extraction of the fitted variance 
components from lme:

 > library(nlme)
 > set.seed(18112003)
 > na <- 20
 > nb <- 20
 > sigma.a <- 2
 > sigma.b <- 3
 > sigma.res <- 1
 > mu <- 0.5
 > n <- na*nb
 > a <- gl(na,1,n)
 > b <- gl(nb,na,n)
 > u <- gl(1,1,n)
 > ya <- rnorm(na,mean=0,sd=sigma.a)
 > yb <- rnorm(nb,mean=0,sd=sigma.b)
 > y <- model.matrix(~a-1) %*% ya + model.matrix(~b-1) %*% yb + 
rnorm(n,mean=mu,sd=sigma.res)
 > fm <- lme(y~1,random=list(u=pdBlocked(list(pdIdent(~a-1),pdIdent(~b-1)))))
 > v <- sqrt(diag(as.matrix(fm$modelStruct$reStruct$u))[c(1,na+1)])
 > v <- fm$sigma * c(v, 1)
 > names(v) <- c("Sigma.a","Sigma.b","Sigma.res")
 > print(v)
   Sigma.a   Sigma.b Sigma.res
  2.450700  3.650427  1.046689

Gordon

At 05:29 AM 16/11/2003, Sundar Dorai-Raj wrote:
>Gordon Smyth wrote:
>
>>Many thanks for help from Peter Dalgaard, Douglas Bates and Bill 
>>Venables. As a result of their help, here is a working example of using 
>>lme to fit an additive random effects model. The model here is 
>>effectively y~a+b with a and b random:
>>y <- rnorm(12)
>>a <- gl(4,1,12)
>>b <- gl(3,4,12)
>>u <- gl(1,1,12)
>>library(nlme)
>>fm <- lme(y~1,random=list(u=pdBlocked(list(pdIdent(~a-1),pdIdent(~b-1)))))
>>summary(fm)
>>I still can't see though how to extract the three variance components 
>>(for a and b and for the residual) from the fitted object 'fm'.
>>Thanks
>>Gordon
>
>Would this work for you? It still needs some parsing to extract sigma_a 
>and sigma_b, but that should be simple.
>
>v <- as.matrix(fm$modelStruct$reStruct$u)
>c(sqrt(diag(v)), Residual = 1) * fm$sigma
>
>Regards,
>Sundar



From spencer.graves at pdf.com  Sun Nov 23 10:58:15 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 23 Nov 2003 01:58:15 -0800
Subject: [R] where to get the "leaps" package
In-Reply-To: <3FBFCBD1.28634.8A1C7@localhost>
References: <200311221102.hAMB2BPf008199@hypatia.math.ethz.ch>
	<3FBFCBD1.28634.8A1C7@localhost>
Message-ID: <3FC084B7.9090404@pdf.com>

      Amazingly perhaps, asking Google for "r" will also take you 
directly to "www.r-project.org", at least today. 

spencer graves

kjetil at entelnet.bo wrote:

>On 22 Nov 2003 at 18:12, Yong Wang wrote:
>
>You should find it on CRAN, the Comprehensive R Archival
>Network. Search google for CRAN. 
>or if you are on windows, go to menu Packages --- install packages 
>from CRAN.
>
>Kjetil Halvorsen
>
>  
>
>>Dear all
>>I am supposed to use Mallow's Cp creterion to select a model which
>>require a "leaps" package. the version right now I am using is R
>>1.7.1(os:windows), the "leaps" package is not included. please let me
>>know how and where can I get this package and add it to the current
>>version, any caution on adding this package is highly appreciated.
>>thank you 
>>
>>best
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From roedhammer_florian at hotmail.com  Sun Nov 23 12:38:05 2003
From: roedhammer_florian at hotmail.com (Florian Roedhammer)
Date: Sun, 23 Nov 2003 11:38:05 +0000
Subject: [R] R comparison
Message-ID: <BAY9-F17KbiYMRBvt010000740b@hotmail.com>


   Hi,


   My name is Florian R?dhammer and I am a student of the UMIT in
   Innsbruck.

   For a presentation I should compare differnet programming languages- R
   is one of them.



   I would need information concerning the features of R such as
   static/dynamic typing, method overlapping, object oriontation,

   
   My question is whether you know  any site where such features are
   discussed on or if you could help me directly.

   
   Yours Florian R?dhammer
     _________________________________________________________________

   Hotmail  -  Absolut kostenfrei! Der weltweit gr??te E-Mail-Anbieter im
   Netz: [1]Hier klicken 

References

   1. http://g.msn.com/8HMBDEAT/2731??PS=


From viola_rossini at yahoo.it  Sun Nov 23 16:48:05 2003
From: viola_rossini at yahoo.it (=?iso-8859-1?q?Viola=20Rossini?=)
Date: Sun, 23 Nov 2003 16:48:05 +0100 (CET)
Subject: [R] Distribution transformations
Message-ID: <20031123154805.17646.qmail@web25210.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031123/0ad11608/attachment.pl

From rolf at math.unb.ca  Sun Nov 23 17:03:40 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 23 Nov 2003 12:03:40 -0400 (AST)
Subject: [R] Distribution transformations
Message-ID: <200311231603.hANG3eb6023747@erdos.math.unb.ca>


You wrote:

> Dear R-Users,
> 
> I have a question that bothers me in the last few days. It is
> supposed to be easy but I can't come up with a solution.  Are there
> any functions in R dealing with transforming empirical and parametric
> distributions? I have two data sets of observed variables that I want
> to transform to Frechet and Uniform distribution.  I would appreciate
> if someone could inform me about R-functions for this purpose or
> enligthen me how to do it by myself.
> 
> Thank you very much in advance,
> Viola Rossini

Is this a homework question?

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ivo.welch at yale.edu  Sun Nov 23 17:04:36 2003
From: ivo.welch at yale.edu (ivo welch)
Date: Sun, 23 Nov 2003 11:04:36 -0500
Subject: [R] readline problem under src-compiled R 1.8.x under Mandrake 9.2
Message-ID: <3FC0DA94.6070703@yale.edu>


R compiles very easily  under Mandrake 9.2, with one exception:  readline 
seems not to work.  for some odd reason, in the configure script, 
rl_callback_read_char is set to no, so the R configure script does not use 
readline (I think this means it refuses to link readline into the executable, 
but I am not sure.)  Now, MD 9.2 uses libreadline 4-4.3-7mdk (yes, it is 
installed), rather than earlier readline versions.

Has anyone else encountered or solved this problem?

sincerely,  /iaw



From spencer.graves at pdf.com  Sun Nov 23 17:26:58 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 23 Nov 2003 08:26:58 -0800
Subject: [R] Distribution transformations
In-Reply-To: <20031123154805.17646.qmail@web25210.mail.ukl.yahoo.com>
References: <20031123154805.17646.qmail@web25210.mail.ukl.yahoo.com>
Message-ID: <3FC0DFD2.8000209@pdf.com>

      For the uniform distribution, have you considered something like 
"(((1:n)-0.5)/n))[order(x)]"?  For the Frechet distribution, a "search" 
-> "R site search" from "www.r-project.org" exposed something that 
should help.  The information you need seems to be there. 

      hope this helps.  spencer graves

Viola Rossini wrote:

>Dear R-Users,
>I have a question that bothers me in the last few days. It is supposed to be easy but I can't come up with a solution. 
>Are there any functions in R dealing with transforming empirical and parametric distributions? I have two data sets of observed variables that I want to transform to Frechet and Uniform distribution. 
>I would appreciate if someone could inform me about R-functions for this purpose or enligthen me how to do it by myself.
>Thank you very much in advance,
>Viola Rossini
>
>
>
>
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From MSchwartz at medanalytics.com  Sun Nov 23 17:35:07 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 23 Nov 2003 10:35:07 -0600
Subject: [R] readline problem under src-compiled R 1.8.x under Mandrake 9.2
In-Reply-To: <3FC0DA94.6070703@yale.edu>
References: <3FC0DA94.6070703@yale.edu>
Message-ID: <1069605307.25196.7.camel@localhost.localdomain>

On Sun, 2003-11-23 at 10:04, ivo welch wrote:
> R compiles very easily  under Mandrake 9.2, with one exception:  readline 
> seems not to work.  for some odd reason, in the configure script, 
> rl_callback_read_char is set to no, so the R configure script does not use 
> readline (I think this means it refuses to link readline into the executable, 
> but I am not sure.)  Now, MD 9.2 uses libreadline 4-4.3-7mdk (yes, it is 
> installed), rather than earlier readline versions.
> 
> Has anyone else encountered or solved this problem?
> 
> sincerely,  /iaw


Do you have readline-devel installed?  If you are compiling from source,
you also need the 'devel' versions of the packages installed to provide
the header files, etc.

>From a console command line use:

rpm -q readline-devel

If it returns:

package readline-devel is not installed

That is likely your problem.

HTH,

Marc Schwartz



From ivo.welch at yale.edu  Sun Nov 23 17:48:42 2003
From: ivo.welch at yale.edu (ivo welch)
Date: Sun, 23 Nov 2003 11:48:42 -0500
Subject: [R] readline problem under src-compiled R 1.8.x under Mandrake 9.2
In-Reply-To: <1069605307.25196.7.camel@localhost.localdomain>
References: <3FC0DA94.6070703@yale.edu>
	<1069605307.25196.7.camel@localhost.localdomain>
Message-ID: <3FC0E4EA.4020609@yale.edu>


thanks, marc+brian.  it was indeed not installed.  i was under the mistaken 
impression that readline was just a linkto library.  the compile now works great.

suggestion:  if libreadline is installed and libreadline-devel is not 
installed, please print a warning/suggestion message during the ./configure. 
(i wonder whether there are other similar libraries for which I should have 
installed the devel version, too.)

I did search R documentation for "readline" failures via google for a while, 
but failed to find this particular reference.  Yep, I did not fully read the 
docs from start to end again (its been a while), so mea culpa.  still, adding 
the warning at ./configure time is a good idea.  apologies for taking 
everyone's time.  and thanks for the help.  now I will try to research how to 
build a binary for md 9.2 for others (to make up!)

regards,

/iaw



From MSchwartz at medanalytics.com  Sun Nov 23 18:04:39 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 23 Nov 2003 11:04:39 -0600
Subject: [R] readline problem under src-compiled R 1.8.x under Mandrake 9.2
In-Reply-To: <3FC0E4EA.4020609@yale.edu>
References: <3FC0DA94.6070703@yale.edu>
	<1069605307.25196.7.camel@localhost.localdomain>
	<3FC0E4EA.4020609@yale.edu>
Message-ID: <1069607078.25196.14.camel@localhost.localdomain>

On Sun, 2003-11-23 at 10:48, ivo welch wrote:
> thanks, marc+brian.  it was indeed not installed.  i was under the mistaken 
> impression that readline was just a linkto library.  the compile now works great.
> 
> suggestion:  if libreadline is installed and libreadline-devel is not 
> installed, please print a warning/suggestion message during the ./configure. 
> (i wonder whether there are other similar libraries for which I should have 
> installed the devel version, too.)
> 
> I did search R documentation for "readline" failures via google for a while, 
> but failed to find this particular reference.  Yep, I did not fully read the 
> docs from start to end again (its been a while), so mea culpa.  still, adding 
> the warning at ./configure time is a good idea.  apologies for taking 
> everyone's time.  and thanks for the help.  now I will try to research how to 
> build a binary for md 9.2 for others (to make up!)
> 
> regards,
> 
> /iaw


Actually, there is a message in the output of ./configure:

R is now configured for i686-pc-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc -D__NO_MATH_INLINES -mieee-fp -g -O2
  C++ compiler:              g++ -mieee-fp -g -O2
  Fortran compiler:          g77 -mieee-fp -g -O2

  Interfaces supported:      X11, tcltk
  External libraries:        readline, BLAS(generic)
  Additional capabilities:   PNG, JPEG, bzip2, PCRE
  Options enabled:           R profiling

  Recommended packages:      yes


Note that in the above, the line "External libraries" indicates what
will be supported, which in my case, shows readline.

In addition, you can use capabilities() once in the R console to see
what has been included:

> capabilities()
    jpeg      png    tcltk      X11    GNOME     libz http/ftp  sockets
    TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE     TRUE
  libxml     fifo   cledit  IEEE754    bzip2     PCRE
    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE

In the above case, 'cledit' shows TRUE, which is the indication that
command line editing is supported.

On your final thought, you might want to review the following:

http://cran.r-project.org/bin/linux/mandrake/Mandrake-Readme.txt

HTH,

Marc Schwartz



From Pascal.Niklaus at unibas.ch  Sun Nov 23 18:22:11 2003
From: Pascal.Niklaus at unibas.ch (Pascal.Niklaus@unibas.ch)
Date: Sun, 23 Nov 2003 18:22:11 +0100
Subject: [R] coplot row separatot line
Message-ID: <1069608131.3fc0ecc32afb1@webmail.unibas.ch>


Hi all,

I could not find a way to add the dashed horizontal separator line to the top
panel of a coplot (the one indicating which panel belongs to which range of the
given variable a in  y~x | a).

This line should separate the ranges plotted in a row of panels in the panel
matrix below (hmmm, hope this is reasonably clear). I like it because it
enhances readability.

I'll try a sketch:

> coplot(y~x | a)

           given: a
+------------------------------+
|                         6666 | 
|                    55555     |
|                4444          |
+ - - - - - - - - - - - - - - -+   <== this line
|             333              |
|       22222                  |
| 11111                        |
+------------------------------+

+--------+ +--------+ +--------+ 
|  4     | |  5     | |   6    |
|        | |        | |        |
+--------+ +--------+ +--------+ 

+--------+ +--------+ +--------+
|  1     | |   2    | |   3    |
|        | |        | |        | 
+--------+ +--------+ +--------+ 

I've seen this line in some coplots, but am not sure whether this was S-Plus or R.

Thanks for any hint

Pascal


-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From tord.snall at ebc.uu.se  Sun Nov 23 18:30:27 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Sun, 23 Nov 2003 18:30:27 +0100
Subject: [R] remove 0 rows from a data frame
Message-ID: <3.0.6.32.20031123183027.00ce1cb8@mail.anst.uu.se>

Dear all,

As part of a larger function, I am randomly removing rows from a data
frame. The number of removed rows is determmined by a Poisson distribution
with a low mean. Sometimes, the random number is 0, and that's when the
problem starts:

My data frame:
> temp
    occ        x        y dbh  age
801   0 2977.196 3090.225   6 36.0
802   0 2951.892 3083.769   8 40.6
803   0 2919.111 3075.557   8 40.6
804   0 2914.123 3072.700   9 42.9
805   0 2925.353 3074.675   8 40.6

How many rows (nft) shall be removed?
> nft<- rpois(1, 2)
> nft
[1] 2

Ok remove 2 rows:
 
> temp2<- temp[-sample(nrow(temp), nft), ]
> temp2
    occ        x        y dbh  age
801   0 2977.196 3090.225   6 36.0
803   0 2919.111 3075.557   8 40.6
805   0 2925.353 3074.675   8 40.6

No problem.

 
However, sometimes rpois(1, 2) lead to nft=0, and in that case I do not want 

> temp2<- temp[-sample(nrow(temp), 0), ]
> temp2
[1] occ x   y   dbh age
<0 rows> (or 0-length row.names)
> 

Instead I want
> temp2<- temp
> temp2
    occ        x        y dbh  age
801   0 2977.196 3090.225   6 36.0
802   0 2951.892 3083.769   8 40.6
803   0 2919.111 3075.557   8 40.6
804   0 2914.123 3072.700   9 42.9
805   0 2925.353 3074.675   8 40.6


Could someone help whith that?


Thanks in advance!


Sincerely,
Tord



-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From jasont at indigoindustrial.co.nz  Sun Nov 23 18:34:11 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 24 Nov 2003 06:34:11 +1300
Subject: [R] remove 0 rows from a data frame
In-Reply-To: <3.0.6.32.20031123183027.00ce1cb8@mail.anst.uu.se>
References: <3.0.6.32.20031123183027.00ce1cb8@mail.anst.uu.se>
Message-ID: <3FC0EF93.4000500@indigoindustrial.co.nz>

Tord Snall wrote:

> Dear all,
> 
> As part of a larger function, I am randomly removing rows from a data
> frame. The number of removed rows is determmined by a Poisson distribution
> with a low mean. Sometimes, the random number is 0, and that's when the
> problem starts:
...
> However, sometimes rpois(1, 2) lead to nft=0, and in that case I do not want 
> 
> 
>>temp2<- temp[-sample(nrow(temp), 0), ]
>>temp2
> 
> [1] occ x   y   dbh age
> <0 rows> (or 0-length row.names)

This is a language feature, not a bug.  The easiest way around it is to 
catch the case where it's an issue.  Something like

if(nft==0) {
	rows <- 1:nrow(temp)
} else {
	rows <- -1 * sample(1:nrow(temp),nft)
}
temp2 <- temp[rows,]

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From MSchwartz at medanalytics.com  Sun Nov 23 18:40:55 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 23 Nov 2003 11:40:55 -0600
Subject: [R] remove 0 rows from a data frame
In-Reply-To: <3.0.6.32.20031123183027.00ce1cb8@mail.anst.uu.se>
References: <3.0.6.32.20031123183027.00ce1cb8@mail.anst.uu.se>
Message-ID: <1069609254.25196.23.camel@localhost.localdomain>

On Sun, 2003-11-23 at 11:30, Tord Snall wrote:
> Dear all,
> 
> As part of a larger function, I am randomly removing rows from a data
> frame. The number of removed rows is determmined by a Poisson distribution
> with a low mean. Sometimes, the random number is 0, and that's when the
> problem starts:
> 
> My data frame:
> > temp
>     occ        x        y dbh  age
> 801   0 2977.196 3090.225   6 36.0
> 802   0 2951.892 3083.769   8 40.6
> 803   0 2919.111 3075.557   8 40.6
> 804   0 2914.123 3072.700   9 42.9
> 805   0 2925.353 3074.675   8 40.6
> 
> How many rows (nft) shall be removed?
> > nft<- rpois(1, 2)
> > nft
> [1] 2
> 
> Ok remove 2 rows:
>  
> > temp2<- temp[-sample(nrow(temp), nft), ]
> > temp2
>     occ        x        y dbh  age
> 801   0 2977.196 3090.225   6 36.0
> 803   0 2919.111 3075.557   8 40.6
> 805   0 2925.353 3074.675   8 40.6
> 
> No problem.
> 
>  
> However, sometimes rpois(1, 2) lead to nft=0, and in that case I do not want 
> 
> > temp2<- temp[-sample(nrow(temp), 0), ]
> > temp2
> [1] occ x   y   dbh age
> <0 rows> (or 0-length row.names)
> > 
> 
> Instead I want
> > temp2<- temp
> > temp2
>     occ        x        y dbh  age
> 801   0 2977.196 3090.225   6 36.0
> 802   0 2951.892 3083.769   8 40.6
> 803   0 2919.111 3075.557   8 40.6
> 804   0 2914.123 3072.700   9 42.9
> 805   0 2925.353 3074.675   8 40.6
> 
> 
> Could someone help whith that?
> 
> 
> Thanks in advance!
> 
> 
> Sincerely,
> Tord


Without seeing your entire function, this particular approach may or may
not fit, but how about:

nft <- rpois(1, 2)
ifelse(nft > 0, temp2 <- temp[-sample(nrow(temp), nft), ], 
       temp2 <- temp)

Essentially, this checks the value of the test:

nft > 0

If TRUE, then remove the rows, else copy the entire df.

See ?ifelse for more information.

HTH,

Marc Schwartz



From jasont at indigoindustrial.co.nz  Sun Nov 23 17:56:02 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 24 Nov 2003 05:56:02 +1300
Subject: [R] Stangle - dropping re-used code chunks
Message-ID: <3FC0E6A2.7000506@indigoindustrial.co.nz>

My question is:  is there a way for Rtangle() to *not* print re-used 
code chunks?  It'd be easy enough to brew up a perl script to do just 
this, but if methods exist already, I'd rather use them.  My reading of 
the help pages and FAQs has missed something, if it's there.

Background:
I have course notes on R, written using Sweave.  I want to provide the R 
code separately so the course attendees don't have to re-type everthing 
in the manual.

In this manual, I typically show a command, then re-use the chunk to 
produce a plot.  Something like this:

%% first, show how the plot is done...
<<ex.ts.acf.mottle,echo=TRUE,fig=FALSE>>=
par(mfrow=c(2,2))
mottle.acf <- acf(mottle.t[,1], lag.max=45)
mottle.pacf <- pacf(mottle.t[,1], lag.max=45)
mottle.acf <- acf(mottle.t[,1], lag.max=45, ci.type="ma")
mottle.pacf <- pacf(mottle.t[,1], lag.max=45, ci.type="ma")

@

%% then plot it.

\begin{figure}[tbh]
   \centering
<<echo=FALSE,fig=TRUE>>=
<<ex.ts.acf.mottle>>
@
   \caption{Autocorrelation plot of the \Data{mottle} dataset.}
   \label{fig:ex.ts.acf.mottle}
\end{figure}
%% example ends

Stangle will (correctly) print the <<ex.ts.acf.mottle>> chunk twice, 
since it is called twice; once to create it, and once to re-use it.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From spencer.graves at pdf.com  Sun Nov 23 18:50:52 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 23 Nov 2003 09:50:52 -0800
Subject: [R] remove 0 rows from a data frame
In-Reply-To: <3.0.6.32.20031123183027.00ce1cb8@mail.anst.uu.se>
References: <3.0.6.32.20031123183027.00ce1cb8@mail.anst.uu.se>
Message-ID: <3FC0F37C.8000709@pdf.com>

Have you considered the complement, e.g.: 

N <- 4
DF <- data.frame(a=1:N, b=1:N)
DF[-1,]
#nft <- rpois(1,2)
nft <- 0
DF[sample(N, N-nft),]

hope this helps.  spencer graves

Tord Snall wrote:

>Dear all,
>
>As part of a larger function, I am randomly removing rows from a data
>frame. The number of removed rows is determmined by a Poisson distribution
>with a low mean. Sometimes, the random number is 0, and that's when the
>problem starts:
>
>My data frame:
>  
>
>>temp
>>    
>>
>    occ        x        y dbh  age
>801   0 2977.196 3090.225   6 36.0
>802   0 2951.892 3083.769   8 40.6
>803   0 2919.111 3075.557   8 40.6
>804   0 2914.123 3072.700   9 42.9
>805   0 2925.353 3074.675   8 40.6
>
>How many rows (nft) shall be removed?
>  
>
>>nft<- rpois(1, 2)
>>nft
>>    
>>
>[1] 2
>
>Ok remove 2 rows:
> 
>  
>
>>temp2<- temp[-sample(nrow(temp), nft), ]
>>temp2
>>    
>>
>    occ        x        y dbh  age
>801   0 2977.196 3090.225   6 36.0
>803   0 2919.111 3075.557   8 40.6
>805   0 2925.353 3074.675   8 40.6
>
>No problem.
>
> 
>However, sometimes rpois(1, 2) lead to nft=0, and in that case I do not want 
>
>  
>
>>temp2<- temp[-sample(nrow(temp), 0), ]
>>temp2
>>    
>>
>[1] occ x   y   dbh age
><0 rows> (or 0-length row.names)
>  
>
>
>Instead I want
>  
>
>>temp2<- temp
>>temp2
>>    
>>
>    occ        x        y dbh  age
>801   0 2977.196 3090.225   6 36.0
>802   0 2951.892 3083.769   8 40.6
>803   0 2919.111 3075.557   8 40.6
>804   0 2914.123 3072.700   9 42.9
>805   0 2925.353 3074.675   8 40.6
>
>
>Could someone help whith that?
>
>
>Thanks in advance!
>
>
>Sincerely,
>Tord
>
>
>
>-----------------------------------------------------------------------
>Tord Sn?ll
>Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
>Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
>Villav?gen 14			
>SE-752 36 Uppsala, Sweden
>Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
>Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
>Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
>E-mail: Tord.Snall at ebc.uu.se
>Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From ggrothendieck at myway.com  Sun Nov 23 18:56:31 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 23 Nov 2003 12:56:31 -0500 (EST)
Subject: [R] remove 0 rows from a data frame
Message-ID: <20031123175631.740523A23@mprdmxin.myway.com>



Append a dummy row which is always deleted:

nft <- 0
n <- nrow( temp )
temp0 <- rbind( temp, temp[n,] )
temp0[ -c( sample( n, nft ), n+1 ) , ]

--- 
Date: Sun, 23 Nov 2003 18:30:27 +0100 
From: Tord Snall <tord.snall at ebc.uu.se>
To: <r-help at r-project.org> 
Subject: [R] remove 0 rows from a data frame 

 
 
Dear all,

As part of a larger function, I am randomly removing rows from a data
frame. The number of removed rows is determmined by a Poisson distribution
with a low mean. Sometimes, the random number is 0, and that's when the
problem starts:

My data frame:
> temp
occ x y dbh age
801 0 2977.196 3090.225 6 36.0
802 0 2951.892 3083.769 8 40.6
803 0 2919.111 3075.557 8 40.6
804 0 2914.123 3072.700 9 42.9
805 0 2925.353 3074.675 8 40.6

How many rows (nft) shall be removed?
> nft<- rpois(1, 2)
> nft
[1] 2

Ok remove 2 rows:

> temp2<- temp[-sample(nrow(temp), nft), ]
> temp2
occ x y dbh age
801 0 2977.196 3090.225 6 36.0
803 0 2919.111 3075.557 8 40.6
805 0 2925.353 3074.675 8 40.6

No problem.


However, sometimes rpois(1, 2) lead to nft=0, and in that case I do not want 

> temp2<- temp[-sample(nrow(temp), 0), ]
> temp2
[1] occ x y dbh age
<0 rows> (or 0-length row.names)
> 

Instead I want
> temp2<- temp
> temp2
occ x y dbh age
801 0 2977.196 3090.225 6 36.0
802 0 2951.892 3083.769 8 40.6
803 0 2919.111 3075.557 8 40.6
804 0 2914.123 3072.700 9 42.9
805 0 2925.353 3074.675 8 40.6


Could someone help whith that?


Thanks in advance!


Sincerely,
Tord



-----------------------------------------------------------------------
Tord Snll
Avd. f vxtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villavgen 14               
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From viola_rossini at yahoo.it  Sun Nov 23 19:35:58 2003
From: viola_rossini at yahoo.it (=?iso-8859-1?q?Viola=20Rossini?=)
Date: Sun, 23 Nov 2003 19:35:58 +0100 (CET)
Subject: [R] Distribution transformations
In-Reply-To: <200311231603.hANG3eb6023747@erdos.math.unb.ca>
Message-ID: <20031123183558.29051.qmail@web25203.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031123/c8f815ac/attachment.pl

From kjetil at entelnet.bo  Sun Nov 23 19:54:24 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Sun, 23 Nov 2003 14:54:24 -0400
Subject: [R] Distribution transformations
In-Reply-To: <20031123183558.29051.qmail@web25203.mail.ukl.yahoo.com>
References: <200311231603.hANG3eb6023747@erdos.math.unb.ca>
Message-ID: <3FC0CA20.12481.284851@localhost>

On 23 Nov 2003 at 19:35, Viola Rossini wrote:

The frechet dirtribution is in the evd (extreme value dist) package 
on CRAN. 

The basic preinciple is that if U is uniform (0,1) anf F
is a cumulative distrubution function, then
F^{-1}(U) is distributed as F. 

Kjetil Halvorsen

> I am still not getting it. 
> I am trying to understand multivariate distributions and copulas. In
> the beginning of each article it is said that the observed data must
> be transformed to uniform or frechet distribution by means of
> probability integral transform. Apparently this is something easy and
> trivial and a standard procedure in introductory statistics. Well, I
> have some books in statistics of different degrees of complexity but
> unfortunately I cannot find the answer there. All examples are only
> about how to generate a random sample with desired (always
> exponential) distribution. Now, I have two variables X and Y and I
> want to transform them to Frechet or uniform. I was just thinking, if
> this is so simple and trivial as all stat books say, then, it must
> exist a simple function for it in R. 
> 
> 
> P.s. @Rolf, I would like to have it as a homework but I am afraid I am
> too old for a school.
> 
> Rolf Turner <rolf at math.unb.ca> wrote:
> You wrote:
> 
> > Dear R-Users,
> > 
> > I have a question that bothers me in the last few days. It is
> > supposed to be easy but I can't come up with a solution. Are there
> > any functions in R dealing with transforming empirical and
> > parametric distributions? I have two data sets of observed variables
> > that I want to transform to Frechet and Uniform distribution. I
> > would appreciate if someone could inform me about R-functions for
> > this purpose or enligthen me how to do it by myself.
> > 
> > Thank you very much in advance,
> > Viola Rossini
> 
> Is this a homework question?
> 
> cheers,
> 
> Rolf Turner
> rolf at math.unb.ca
> 
> 
> 
> ---------------------------------
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Sun Nov 23 20:53:41 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Nov 2003 20:53:41 +0100
Subject: [R] Distribution transformations
In-Reply-To: <3FC0CA20.12481.284851@localhost>
References: <200311231603.hANG3eb6023747@erdos.math.unb.ca>
	<3FC0CA20.12481.284851@localhost>
Message-ID: <x24qwuvp2y.fsf@biostat.ku.dk>

kjetil at entelnet.bo writes:

> On 23 Nov 2003 at 19:35, Viola Rossini wrote:
> 
> The frechet dirtribution is in the evd (extreme value dist) package 
> on CRAN. 
> 
> The basic preinciple is that if U is uniform (0,1) anf F
> is a cumulative distrubution function, then
> F^{-1}(U) is distributed as F. 

[Slightly unfortunate double use of "F" there] 

...and conversely if X has distribution D with continuous cumulative
distribution function F, then F(X) will have a uniform distribution. I
suspect this was the clue that Viola was missing. This requires that
you know F, though. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.murrell at auckland.ac.nz  Sun Nov 23 20:48:19 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 24 Nov 2003 08:48:19 +1300
Subject: [R] R Home Page Graphic Competition
Message-ID: <3FC10F03.1050608@stat.auckland.ac.nz>

R Home Page Graphic Competition
===============================

We're looking for a snazzy graphic for the home page of the R Project.

Please send us your favourite R image and the best (as chosen by R-core) 
will be used on the web site.  The author of the winning image will also 
receive *free registration* for the useR! 2004 conference 
(http://www.ci.tuwien.ac.at/Conferences/useR-2004/)

The original image should be produced using R.  Images which have been 
"jazzed up" using a graphics program such as gimp will also be 
considered (but may suffer an "impurity" penalty in the judging).

Please send images and source code (and data) used to produce them, to 
paul at stat.auckland.ac.nz

The competition will last until January 31st 2004, or until we die 
waiting, whichever happens first.

R-core reserves the right to decide that the R user base is just as 
devoid of artistic talent as R-core itself;  we only promise to make use 
of zero or more of the submitted images on the web site.

The R-core development team.



From p.murrell at auckland.ac.nz  Sun Nov 23 21:41:26 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 24 Nov 2003 09:41:26 +1300
Subject: [R] coplot row separatot line
References: <1069608131.3fc0ecc32afb1@webmail.unibas.ch>
Message-ID: <3FC11B76.90005@stat.auckland.ac.nz>

Hi

I think the only way you can do this is by modifying the coplot code.
See the part that starts ...

     if (show.given[1]) {

Paul


Pascal.Niklaus at unibas.ch wrote:
> Hi all,
> 
> I could not find a way to add the dashed horizontal separator line to the top
> panel of a coplot (the one indicating which panel belongs to which range of the
> given variable a in  y~x | a).
> 
> This line should separate the ranges plotted in a row of panels in the panel
> matrix below (hmmm, hope this is reasonably clear). I like it because it
> enhances readability.
> 
> I'll try a sketch:
> 
> 
>>coplot(y~x | a)
> 
> 
>            given: a
> +------------------------------+
> |                         6666 | 
> |                    55555     |
> |                4444          |
> + - - - - - - - - - - - - - - -+   <== this line
> |             333              |
> |       22222                  |
> | 11111                        |
> +------------------------------+
> 
> +--------+ +--------+ +--------+ 
> |  4     | |  5     | |   6    |
> |        | |        | |        |
> +--------+ +--------+ +--------+ 
> 
> +--------+ +--------+ +--------+
> |  1     | |   2    | |   3    |
> |        | |        | |        | 
> +--------+ +--------+ +--------+ 
> 
> I've seen this line in some coplots, but am not sure whether this was S-Plus or R.
> 
> Thanks for any hint
> 
> Pascal
> 
> 
> -------------------------------------------------
> This mail sent through IMP: http://horde.org/imp/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From dkelly at alum.mit.edu  Sun Nov 23 21:52:51 2003
From: dkelly at alum.mit.edu (David Kelly)
Date: Sun, 23 Nov 2003 12:52:51 -0800
Subject: [R] dvips function gives "Documents not found" error
Message-ID: <3FC11E23.3090701@alum.mit.edu>

I'm new to R, and using version 1.8.0 on Windows XP, under emacs/ess. 
I'm trying to test some simple output flow using functions in the Hmisc 
package and hit an error that may be a more general problem than just my 
specific situation.

If I issue the command
latex(describe(mtcars), file = ??)
I get what looks like good TeX code output to the console.

However, if I issue the command
dvips(latex(describe(mtcars)),file="friday.ps")

I get the following error:
Error in system(cmd, intern = intern, wait = wait | intern, 
show.output.on.console = wait,  :
C:/Documents not found

and I don't find any postscript output file.

I'm guessing the "C:/Documents" reference is actually a problem with 
something dealing with paths with embedded spaces and that it's failing 
to deal with a path like C:/Documents and Settings/....

What I've been unable to figure out is what file reference it's 
hiccuping on, so that I can hopefully find a workaround.  I tried 
several things without any change in behavior:
- insuring that the working directory for R didn't have any spaces in 
the pathname.
- changing my TEMP and TMP environment variables to paths without any 
spaces.
- in the possibility that some piece of software (emacs, R, LaTex) was 
looking for the TMPDIR environment variable, tried setting that to a 
path without any spaces.

Any ideas, suggestions for further experiments, or solutions would be 
welcome!  A copy of any reply to my email address (as well as just 
posting to the list) would be appreciated.

Thank you -
David Kelly



From Paul.Sorenson at vision-bio.com  Sun Nov 23 23:05:23 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Mon, 24 Nov 2003 09:05:23 +1100
Subject: [R] RE: best editor for .R files
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C62739E0@ewok.vsl.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031124/08751a54/attachment.pl

From Simon.Blomberg at anu.edu.au  Sun Nov 23 23:09:17 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Mon, 24 Nov 2003 09:09:17 +1100
Subject: [R] summary.manova and rank deficiency
Message-ID: <7A3A13F416B40842BD2C1753E044B359012281B1@CASEVS02.cas.anu.edu.au>

Hi all,

I have received the following error from summary.manova:

Error in summary.manova(manova.test, test = "Pillai") : 
	residuals have rank 36 < 64

The data is simulated data for 64 variables. The design is a 2*2 factorial with 10 replicates per treatment. Looking at the code for summary.manova,  the error involves a problem with qr(). Does anyone have a suggestion as to how to deal with this error? The analysis works fine when there are only 32 variables.

Thanks,

Simon.

Simon Blomberg, PhD
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379



From WZocher at t-online.de  Sun Nov 16 23:18:02 2003
From: WZocher at t-online.de (Wolfgang Zocher)
Date: 16 Nov 2003 23:18:02 +0100
Subject: [R] Initial size of graphics window
In-Reply-To: <3FB7D901.3020108@stat.auckland.ac.nz>
References: <m365hmzgnl.fsf@wzocher.dialin.t-online.de>
	<3FB5758A.7020100@kernstat.com> <3FB7D901.3020108@stat.auckland.ac.nz>
Message-ID: <m3k760lzz9.fsf@wzocher.dialin.t-online.de>

Paul Murrell <p.murrell at auckland.ac.nz> writes:

> Remington, Richard wrote:
> > Wolfgang Zocher wrote:
> >> [...] Is there any
> >> chance to change the size of this window?

> > ?win.graph
> > Example, 4 x 4 inch window
> > win.graph(width = 4, height = 4)> 

> The first time you use a graphics command, R automatically opens a graphics
> device (what sort of device you get is controlled by options(device=?)).  This
> device will open with default size settings. If you want to control the size
> of the device, you need to explicitly open the device first and specify the
> size you want (as in Richard's win.graph example).  par("din") can only be
> used to query the current size of a device;  it cannot be used to set/modify
> the size of a device.

Thanks to both of you (Richard and Paul),

Wolfgang



From Simon.Blomberg at anu.edu.au  Mon Nov 24 00:22:07 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Mon, 24 Nov 2003 10:22:07 +1100
Subject: [R] summary.manova and rank deficiency
Message-ID: <7A3A13F416B40842BD2C1753E044B359B13489@CASEVS02.cas.anu.edu.au>

Sorry for reposting. I didn't receive any of the replies to my original message (must be an email problem at my end). I will read the responses in the archive.

Thanks!

Simon.

Simon Blomberg, PhD
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


> -----Original Message-----
> From: Simon Blomberg 
> Sent: Monday, 24 November 2003 9:09 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] summary.manova and rank deficiency
> 
> 
> Hi all,
> 
> I have received the following error from summary.manova:
> 
> Error in summary.manova(manova.test, test = "Pillai") : 
> 	residuals have rank 36 < 64
> 
> The data is simulated data for 64 variables. The design is a 
> 2*2 factorial with 10 replicates per treatment. Looking at 
> the code for summary.manova,  the error involves a problem 
> with qr(). Does anyone have a suggestion as to how to deal 
> with this error? The analysis works fine when there are only 
> 32 variables.
> 
> Thanks,
> 
> Simon.
> 
> Simon Blomberg, PhD
> Depression & Anxiety Consumer Research Unit
> Centre for Mental Health Research
> Australian National University
> http://www.anu.edu.au/cmhr/
> Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From cpwww at comcast.net  Mon Nov 24 05:56:56 2003
From: cpwww at comcast.net (Coburn Watson)
Date: Sun, 23 Nov 2003 20:56:56 -0800
Subject: [R] ROracle issue with shared library and RMySQL
Message-ID: <200311232056.56777.cpwww@comcast.net>

Hello,

Someone posted this same issue back in May 2003 and hasn't yet resolved the 
situation.  I hope someone can provide some additional light.

After starting R I attempt to load the ROracle library and receive the 
following message:

> library(ROracle)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library 
"/usr/local/lib/R/library/ROracle/libs/ROracle.so":
  /usr/local/lib/R/library/ROracle/libs/ROracle.so: undefined symbol: sqlca
Error in library(ROracle) : .First.lib failed

My configuration:
Gentoo 1.4 - kernel 2.4.20
Oracle 9.2.0.4 (upgraded 9.2.0.2)

I compiled ROracle with the necessary Oracle libraries in the path.  My 
LD_LIBRARY_PATH is set to:

/u01/app/oracle/product/9.2.0/lib:/u01/app/oracle/product/9.2.0/precomp/public
:/u01/app/oracle/product/9.2.0/sqlplus/public:/u01/app/oracle/product/9.2.0/precomp/lib

My other oracle applications run fine as far as I can tell. I can also compile 
and execute the Oracle sample12 which does an include of sqlca.h and uses 
dynamic SQL (under the same envrionment conditions).  Is there a way to dump 
the environment which R executes under? Maybe something is getting dropped.

Any help is appreciated.

Coburn Watson
cpwww at comcast.net



From ripley at stats.ox.ac.uk  Mon Nov 24 09:22:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Nov 2003 08:22:45 +0000 (GMT)
Subject: [R] ROracle issue with shared library and RMySQL
In-Reply-To: <200311232056.56777.cpwww@comcast.net>
Message-ID: <Pine.LNX.4.44.0311240818320.21744-100000@gannet.stats>

R CMD ldd /usr/local/lib/R/library/ROracle/libs/ROracle.so

should help.  (Assuming this is Linux, a piece of information I am 
guessing from the kernel number.  What or who is `Gentoo'?)  You are 
looking for either unsatisfied dependencies or a lack of expected Oracle 
dependencies.


On Sun, 23 Nov 2003, Coburn Watson wrote:

> Hello,
> 
> Someone posted this same issue back in May 2003 and hasn't yet resolved the 
> situation.  I hope someone can provide some additional light.
> 
> After starting R I attempt to load the ROracle library and receive the 
> following message:
> 
> > library(ROracle)
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library 
> "/usr/local/lib/R/library/ROracle/libs/ROracle.so":
>   /usr/local/lib/R/library/ROracle/libs/ROracle.so: undefined symbol: sqlca
> Error in library(ROracle) : .First.lib failed
> 
> My configuration:
> Gentoo 1.4 - kernel 2.4.20
> Oracle 9.2.0.4 (upgraded 9.2.0.2)
> 
> I compiled ROracle with the necessary Oracle libraries in the path.  My 
> LD_LIBRARY_PATH is set to:
> 
> /u01/app/oracle/product/9.2.0/lib:/u01/app/oracle/product/9.2.0/precomp/public
> :/u01/app/oracle/product/9.2.0/sqlplus/public:/u01/app/oracle/product/9.2.0/precomp/lib
> 
> My other oracle applications run fine as far as I can tell. I can also compile 
> and execute the Oracle sample12 which does an include of sqlca.h and uses 
> dynamic SQL (under the same envrionment conditions).  Is there a way to dump 
> the environment which R executes under? Maybe something is getting dropped.
> 
> Any help is appreciated.
> 
> Coburn Watson
> cpwww at comcast.net
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Nov 24 09:23:43 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 24 Nov 2003 09:23:43 +0100 (CET)
Subject: [R] kruskal wallis for manova?
In-Reply-To: <20031121160024.4aab648e.busscher@wiz.uni-kassel.de>
References: <20031121160024.4aab648e.busscher@wiz.uni-kassel.de>
Message-ID: <Pine.LNX.4.51.0311240921370.29182@artemis.imbe.med.uni-erlangen.de>


> Hello,
> Is there like the kruskal wallis test in relation to ANOVA (no
> restrictions on normallity and variance homogenity) something (in R)
> for MANOVA?

You may know Fortunato Pesarin's book

@book{multivaria:2001,
   key       = {386},
   author    = {Fortunato Pesarin},
   title     = {Multivariate Permutation Tests:
                With Applications to Biostatistics},
   year      = {2001},
   publisher = {John Wiley \& Sons},
   address   = {Chichester}
}

which addresses those problems. There is some S-Code on the authors
web-page which may be point to start.

Best,

Torsten


> thanks
>
> --
> Dr.Nicolaas Busscher Universit?t GH Kassel
> Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
> Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From VINCENT.STOLIAROFF at sgam.com  Mon Nov 24 10:49:06 2003
From: VINCENT.STOLIAROFF at sgam.com (STOLIAROFF VINCENT)
Date: Mon, 24 Nov 2003 10:49:06 +0100
Subject: [R] link between arima and arma fit
Message-ID: <F8F9E8240570AB4E86DC49B64FDCA2C40101BDD3@FR-MAILBOX1.fr.sgam.socgen>

Hi dear sirs,
I am wondering why the fit of the time serie x with an arima and the fit of
diff(x) with an arma (same coeff p & d) differ one from another
here are the output of R:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
> modelarma<-arma(diff(x),c(7,5))
> modelarma
Call:
arma(x = diff(x), order = c(7, 5))
Coefficient(s):
ar1 ar2 ar3 ar4 ar5 ar6 ar7 ma1 ma2 
0.06078 -0.44774 0.41881 0.47624 0.01406 0.06565 -0.06167 -0.01294 0.31313 
ma3 ma4 ma5 intercept 
-0.49027 -0.55461 -0.11520 -0.10692 
> modelarima<-arima(x,c(7,1,5))
> modelarima
Call:
arima(x = x, order = c(7, 1, 5))
Coefficients:
ar1 ar2 ar3 ar4 ar5 ar6 ar7 ma1 ma2 ma3 ma4
0.1244 -0.1149 -0.2283 0.5209 0.4135 -0.0072 0.0263 -0.087 0.0038 0.1868
-0.5477
s.e. NaN NaN 0.0696 0.1554 NaN NaN NaN NaN NaN 0.1079 0.1369
ma5
-0.5179
s.e. NaN
sigma^2 estimated as 149417: log likelihood = -129578.0, aic = 259181.9
Warning message: 
NaNs produced in: sqrt(diag(x$var.coef)) 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
What method between the two should be considered the best one?
Thanks for your help
Vincent



*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
SG Asset Management et ses filiales declinent toute responsabilite au titre
de ce message s'il a ete altere, deforme ou falsifie.

D?couvrez l'offre et les services de SG Asset Management sur le site
www.sgam.fr 

				********

This message and any attachments (the "message") are confide...{{dropped}}



From VINCENT.STOLIAROFF at sgam.com  Mon Nov 24 10:51:11 2003
From: VINCENT.STOLIAROFF at sgam.com (STOLIAROFF VINCENT)
Date: Mon, 24 Nov 2003 10:51:11 +0100
Subject: [R] merging variable and character
Message-ID: <F8F9E8240570AB4E86DC49B64FDCA2C40101BDD4@FR-MAILBOX1.fr.sgam.socgen>

Hi R lovers!  I'd like to know the trick to get a plot with a title
associating variable and text  
I'd like to plot something like  
for (i in 1:10) plot(x[,i],ylab="Serie" & i)  
to get  Serie 1  Serie 2  so on and so forth...  of course it doesn't work.

If somebody could give me an idea, it would be very nice  
thank you very much and long life to R  
Vincent	




*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
SG Asset Management et ses filiales declinent toute responsabilite au titre
de ce message s'il a ete altere, deforme ou falsifie.

D?couvrez l'offre et les services de SG Asset Management sur le site
www.sgam.fr 

				********

This message and any attachments (the "message") are confide...{{dropped}}



From dominique.couturier at unine.ch  Mon Nov 24 11:09:11 2003
From: dominique.couturier at unine.ch (Dominique Couturier)
Date: Mon, 24 Nov 2003 11:09:11 +0100
Subject: [R] mle in the gamma model
Message-ID: <400B6CDE-1E66-11D8-B9D2-0003931DD6AE@unine.ch>

Dear [R]-list,

I'm looking for a classic equivalent of the wle.gamma function (library 
wle) that estimate robustly the shape and the scale parameters of gamma 
data.
I have a vector of iid gamma rv :
 >data=rgamma(100,shape=10,scale=3)
and a vector of their weights:
 >weights=c(rep(.5/70,70),rep(.25/20,20),rep(.25/10,10))
and want to estimate the scale and shape of the gamma distribution.
Does such a function exists?

thanks,
DLC



From Ivar.Herfindal at bio.ntnu.no  Mon Nov 24 11:18:07 2003
From: Ivar.Herfindal at bio.ntnu.no (Ivar Herfindal)
Date: Mon, 24 Nov 2003 11:18:07 +0100
Subject: [R] merging variable and character
In-Reply-To: <F8F9E8240570AB4E86DC49B64FDCA2C40101BDD4@FR-MAILBOX1.fr.sgam.socgen>
References: <F8F9E8240570AB4E86DC49B64FDCA2C40101BDD4@FR-MAILBOX1.fr.sgam.socgen>
Message-ID: <opry4z8hw6ndboo6@mail.bio.ntnu.no>

Hello

Try ?paste

plot(x[,i],ylab=paste("Serie", i))

Ivar Herfindal

On Mon, 24 Nov 2003 10:51:11 +0100, STOLIAROFF VINCENT 
<VINCENT.STOLIAROFF at sgam.com> wrote:

> Hi R lovers!  I'd like to know the trick to get a plot with a title
> associating variable and text  I'd like to plot something like  for (i in 
> 1:10) plot(x[,i],ylab="Serie" & i)  to get  Serie 1  Serie 2  so on and 
> so forth...  of course it doesn't work.
>
> If somebody could give me an idea, it would be very nice  thank you very 
> much and long life to R  Vincent	
>
>
>
>
> *************************************************************************
> Ce message et toutes les pieces jointes (ci-apres le "message") sont
> confidentiels et etablis a l'intention exclusive de ses destinataires.
> Toute utilisation ou diffusion non autorisee est interdite. Tout message 
> electronique est susceptible d'alteration. SG Asset Management et ses 
> filiales declinent toute responsabilite au titre
> de ce message s'il a ete altere, deforme ou falsifie.
>
> D?couvrez l'offre et les services de SG Asset Management sur le site
> www.sgam.fr
>
> 				********
>
> This message and any attachments (the "message") are 
> confide...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From vito.muggeo at giustizia.it  Mon Nov 24 11:25:11 2003
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Mon, 24 Nov 2003 11:25:11 +0100
Subject: R: [R] merging variable and character
References: <F8F9E8240570AB4E86DC49B64FDCA2C40101BDD4@FR-MAILBOX1.fr.sgam.socgen>
Message-ID: <004e01c3b275$41ad4ca0$5c13070a@PROCGEN>

See ?paste

plot(x[,i], ylab=paste("series",i,sep=" "))

does what you want.

I think it should be a good idea to read (at least) some of several official
manuals, contributed doc, books on R.

best,
vito


----- Original Message -----
From: STOLIAROFF VINCENT <VINCENT.STOLIAROFF at sgam.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, November 24, 2003 10:51 AM
Subject: [R] merging variable and character


Hi R lovers!  I'd like to know the trick to get a plot with a title
associating variable and text
I'd like to plot something like
for (i in 1:10) plot(x[,i],ylab="Serie" & i)
to get  Serie 1  Serie 2  so on and so forth...  of course it doesn't work.

If somebody could give me an idea, it would be very nice
thank you very much and long life to R
Vincent




*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration.
SG Asset Management et ses filiales declinent toute responsabilite au titre
de ce message s'il a ete altere, deforme ou falsifie.

D?couvrez l'offre et les services de SG Asset Management sur le site
www.sgam.fr

********

This message and any attachments (the "message") are confide...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Mon Nov 24 11:51:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Nov 2003 10:51:56 +0000 (GMT)
Subject: [R] mle in the gamma model
In-Reply-To: <400B6CDE-1E66-11D8-B9D2-0003931DD6AE@unine.ch>
Message-ID: <Pine.LNX.4.44.0311241050580.22141-100000@gannet.stats>

library(MASS)
?fitdistr

You can also use survreg (survival) and glm (with some help from functions 
in MASS for the shape).

On Mon, 24 Nov 2003, Dominique Couturier wrote:

> I'm looking for a classic equivalent of the wle.gamma function (library 
> wle) that estimate robustly the shape and the scale parameters of gamma 
> data.
> I have a vector of iid gamma rv :
>  >data=rgamma(100,shape=10,scale=3)
> and a vector of their weights:
>  >weights=c(rep(.5/70,70),rep(.25/20,20),rep(.25/10,10))
> and want to estimate the scale and shape of the gamma distribution.
> Does such a function exists?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Nov 24 11:53:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Nov 2003 10:53:48 +0000 (GMT)
Subject: [R] dvips function gives "Documents not found" error
In-Reply-To: <3FC11E23.3090701@alum.mit.edu>
Message-ID: <Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>

This is a question about Hmisc, I believe, although you certainly did not 
mention it.  Looking at the source code I see

    sys(paste("cd", tempdir(), sc, optionsCmds("latex"), tmp))

do my guess is that it is writing .dvi files in tempdir().
If you look up help on tempdir() you will see how to avoid this,

Moral: don't guess, and don't make your readers guess either.

And to Frank Harrell as author of Hmisc: spaces are valid in file names 
even on Unix/Linux, so it would be nice if this could be corrected.

On Sun, 23 Nov 2003, David Kelly wrote:

> I'm new to R, and using version 1.8.0 on Windows XP, under emacs/ess. 
> I'm trying to test some simple output flow using functions in the Hmisc 
> package and hit an error that may be a more general problem than just my 
> specific situation.
> 
> If I issue the command
> latex(describe(mtcars), file = ??)
> I get what looks like good TeX code output to the console.
> 
> However, if I issue the command
> dvips(latex(describe(mtcars)),file="friday.ps")
> 
> I get the following error:
> Error in system(cmd, intern = intern, wait = wait | intern, 
> show.output.on.console = wait,  :
> C:/Documents not found
> 
> and I don't find any postscript output file.
> 
> I'm guessing the "C:/Documents" reference is actually a problem with 
> something dealing with paths with embedded spaces and that it's failing 
> to deal with a path like C:/Documents and Settings/....
> 
> What I've been unable to figure out is what file reference it's 
> hiccuping on, so that I can hopefully find a workaround.  I tried 
> several things without any change in behavior:
> - insuring that the working directory for R didn't have any spaces in 
> the pathname.
> - changing my TEMP and TMP environment variables to paths without any 
> spaces.
> - in the possibility that some piece of software (emacs, R, LaTex) was 
> looking for the TMPDIR environment variable, tried setting that to a 
> path without any spaces.
> 
> Any ideas, suggestions for further experiments, or solutions would be 
> welcome!  A copy of any reply to my email address (as well as just 
> posting to the list) would be appreciated.
> 
> Thank you -
> David Kelly
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon Nov 24 11:58:54 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 24 Nov 2003 11:58:54 +0100
Subject: [R] median() for ordered factor {was "what does this mean .."}
In-Reply-To: <x2brr5x19y.fsf@biostat.ku.dk>
References: <3A822319EB35174CA3714066D590DCD50205CE70@usrymx25.merck.com>
	<x2brr5x19y.fsf@biostat.ku.dk>
Message-ID: <16321.58478.779181.250176@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>     on 21 Nov 2003 15:08:09 +0100 writes:

    PD> "Liaw, Andy" <andy_liaw at merck.com> writes:
    >> > From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]
    >> > 
    >> > John Christie <jc at or.psychology.dal.ca> writes:
    >> > 
    >> > > what does this mean in R-1.8.1 release notes?
    >> > > 
    >> > > o median() no longer `works' for odd-length > factor
    >> variables.
    >> > 
    >> > The median has always been undefined for factors, but
    >> nevertheless > median() gave an answer. If the length was
    >> even, it would > fail since it needed to average
    >> non-numeric values. This > confused some and the answer
    >> you got for in the odd-length > case was meaningless
    >> anyway (what's the median of three > pears, four apples,
    >> and two bananas?). So now we check.
    >> 
    >> Why not just give an error if median is given an
    >> unordered factor?

    PD> That's what we do and didn't:

    PD>     if (is.factor(x) || mode(x) != "numeric") 
    PD>            stop("need numeric data")

    PD> (also for ordered factors; it is not clear what to do if
    PD> the median sits between two levels in that case either.)

Actually, our  mad() function has  arguments  low & high 
(for partial S-plus compatibility) to ask for the 
lo-median or hi-median respectively.  These only differ from the
median in the case of even  n := length(x), and
for ox := sort(x)  give  ox[ n/2 ] or ox[n/2 + 1] respectively.

Hence, for ordered factors, the lo- and hi-median would be well
defined, and I have in the past considered propagating the 'low'
and 'high' arguments from mad() to median().

Martin



From mailinglist2_wegmann at web.de  Mon Nov 24 13:59:44 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Mon, 24 Nov 2003 13:59:44 +0100
Subject: [R] statistical prediction for glm()
Message-ID: <200311241359.44976.mailinglist2_wegmann@web.de>

hello, 

I apologize that I poste this question again but I did not receive any replies 
on this topic and would like to know if the mail has been read over or if 
there is no method of statistical prediction computation for poisson errors 
in glm(). 

I am looking for a way to compute the model prediciton error of a glm() with 
poisson error family.
cv.glm() does not work. (it prompts values around 90.00)

A " not there isn't such a method" would be fine as well.

Thanks in advance, Martin



From Par.Wiklund at ap1.se  Mon Nov 24 15:32:24 2003
From: Par.Wiklund at ap1.se (=?iso-8859-1?Q?=22Wiklund=2C_P=E4r=22?=)
Date: Mon, 24 Nov 2003 15:32:24 +0100
Subject: [R] Warning calling par
Message-ID: <FF7BA726C256BE40865428CF15E0B42E75AC45@apex01.ap1.se>

Hi. I have a function that works well under R 1.7.1 But under 1.8.0 and 1.8.1 I get:Warning message: 
calling par(new=) with no plot

And it doesnt plot

The function is:
mplotmeth1<-function(data1,data2,alpha,nr){
	psfile<-paste("Meth1_",nr[1],"-",nr[length(nr)],".ps",sep="")
	postscript(psfile)
	close.screen(all=T)
	par(mex=0.73,cex=0.8)
	split.screen(c(2,2))
	tq<-sort(runif(length(data1)))
	message<-rep("no message",4)
	for (i in 1:length(nr)){
		diffmethod<-paste("du.",nr[i],sep="")
		title<-paste("Family",nr[i])
		alphavalue<-paste("a=",round(alpha[i],digits=3),sep="")
		screen(i)
		data3<-sort(eval(call(diffmethod,data1,data2,alpha[i])))
		diffdata<-data3[!is.na(data3)]
		if(length(data3)>length(diffdata)){
			message[i]<-paste("Family ",nr[i],"contains NA!")
		}
		tq<-((1:length(diffdata))/(length(diffdata)+1))
		plot(diffdata,tq,xlab="C1[F(x),G(y)]",ylab="U(0,1)",type="l")
		mtext(title,line=0.7,cex=1.2)
		legend(0.5,0.3,alphavalue)
		abline(0,1)
	}
	dev.off()
	message
}

Best regards

P. Wiklund



From Arnaud_Amsellem at ssga.com  Mon Nov 24 16:19:10 2003
From: Arnaud_Amsellem at ssga.com (Arnaud_Amsellem@ssga.com)
Date: Mon, 24 Nov 2003 15:19:10 +0000
Subject: [R] Bollinger Bands
Message-ID: <OF9430EB6F.8804B9AE-ON80256DE8.0053ED55-80256DE8.00545AF6@statestr.com>

Is there a way to create Bollinger Bands without having to loop on the
observations of a time serie?

Any help appreciated

Thanks



From MSchwartz at medanalytics.com  Mon Nov 24 16:29:18 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 24 Nov 2003 09:29:18 -0600
Subject: [R] Bollinger Bands
In-Reply-To: <OF9430EB6F.8804B9AE-ON80256DE8.0053ED55-80256DE8.00545AF6@statestr.com>
References: <OF9430EB6F.8804B9AE-ON80256DE8.0053ED55-80256DE8.00545AF6@statestr.com>
Message-ID: <1069687758.4844.50.camel@localhost.localdomain>

On Mon, 2003-11-24 at 09:19, Arnaud_Amsellem at ssga.com wrote:
> Is there a way to create Bollinger Bands without having to loop on the
> observations of a time serie?
> 
> Any help appreciated
> 
> Thanks


Have you considered matlines() or matplot()?

Each will generate a plot or add lines to an existing plot based upon
matrices of values.

See the examples in ?matlines or ?matplot to get a feel for what they
can do.

HTH,

Marc Schwartz



From jiafucang at hotmail.com  Mon Nov 24 16:31:20 2003
From: jiafucang at hotmail.com (Fucang Jia)
Date: Mon, 24 Nov 2003 23:31:20 +0800
Subject: [R] Questions on Random Forest
Message-ID: <Law11-F77iQovlQJT7m0000bb56@hotmail.com>

Hi, everyone,

I am a newbie on R. Now I want to do image pixel classification by random 
forest. But I has not a clear understanding on random forest. Here is some 
question:

As for an image, for example its size is 512x512 and has only one variable 
-- gray level. The histogram of the image looks like mixture Gaussian Model, 
say Gauss distribution (u1,sigma1), (u2,sigma2),(u3,sigma3). And a image 
classified by K-means or EM algorithm, so the class label image is also 
512x512 and has 0, 1, 2 value.

I read the binary image data as follows:

datafile <- file("bone.img","rb")
img <- readBin(datafile,size=2,what="integer",n=512*512,signed=FALSE)
img <- as.matrix(img)
close(datafile)

labelfile <- file(label.img","rb")
label <- readBin(labelfile,size=2,what="integer",n=512*512,signed=FALSE)
label <- as.matrix(label)
close(labelfile)

img_and_label <- c(img,label)  // binds the image data and class label
img_and_label <- as.matrix(img_and_label)
img_and_label <- array(img_and_label, dim=c(262144,2))


Random Forest need a class label like "Species" in the  iris. I do not know 
how
to set a class label like "Species" to the img.  So I run the command as 
follows:

set.seed(166)
rf <- randomForest(img_and_label[,2],data=image_and_label,importance=TRUE,
proximity=TRUE)

which outputs:

Error in if (n == 0) stop("data (x) has 0 rows") :
        argument is of length zero

Could anyone tell what is wrong and how can do the RF?

Secondly, if there is an new image , say img3 (dimension is 512x512,too), 
how can I
use the former result to classifify the new image?

Thirdly, whether or not random forest be used well if there is only one 
variable, say pixel
gray level, or three variables, such as red, green, blue color component to 
an true color
image?

Thank you very much!

Best,

Fucang

========================================
Fucang Jia, Ph.D student
Institute of Computing Technology, Chinese Academy of Sciences
Post.Box 2704
Beijing, 100080
P.R.China
E-mail:fcjia at ict.ac.cn



From feh3k at spamcop.net  Mon Nov 24 14:12:28 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Mon, 24 Nov 2003 08:12:28 -0500
Subject: [R] dvips function gives "Documents not found" error
In-Reply-To: <Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>
References: <3FC11E23.3090701@alum.mit.edu>
	<Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>
Message-ID: <20031124081228.2cd671c1.feh3k@spamcop.net>

On Mon, 24 Nov 2003 10:53:48 +0000 (GMT)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> This is a question about Hmisc, I believe, although you certainly did
> not mention it.  Looking at the source code I see
> 
>     sys(paste("cd", tempdir(), sc, optionsCmds("latex"), tmp))
> 
> do my guess is that it is writing .dvi files in tempdir().
> If you look up help on tempdir() you will see how to avoid this,
> 
> Moral: don't guess, and don't make your readers guess either.
> 
> And to Frank Harrell as author of Hmisc: spaces are valid in file names 
> even on Unix/Linux, so it would be nice if this could be corrected.

I've resisted this until now.  The fix appears to be to surround tempdir()
and tmp by dQuote( ). This will be in the next release.  I'm assuming that
superfluous quotes never hurt.   -Frank
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From spencer.graves at pdf.com  Mon Nov 24 16:53:49 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 24 Nov 2003 07:53:49 -0800
Subject: [R] statistical prediction for glm()
In-Reply-To: <200311241359.44976.mailinglist2_wegmann@web.de>
References: <200311241359.44976.mailinglist2_wegmann@web.de>
Message-ID: <3FC2298D.7010609@pdf.com>

      The help page for "predict" says it is a generic function.  Then 
command 'methods("predict")' reveals a function called "predict.glm", 
which has its own help page.  Does that provide what you want? 

      Also, I didn't find your earlier post in "www.r-project.org" -> 
"search" -> "R site search".  I found 15 hits for "martin wegmann 
prediction glm", but none that looked like your question below;  perhaps 
someone else can explain why I didn't find your earlier post.  I also 
found 25 hits for "statistical prediction for glm".  Have you looked at 
those?  One or more of them might help you.

hope this helps.  spencer graves

Martin Wegmann wrote:

>hello, 
>
>I apologize that I poste this question again but I did not receive any replies 
>on this topic and would like to know if the mail has been read over or if 
>there is no method of statistical prediction computation for poisson errors 
>in glm(). 
>
>I am looking for a way to compute the model prediciton error of a glm() with 
>poisson error family.
>cv.glm() does not work. (it prompts values around 90.00)
>
>A " not there isn't such a method" would be fine as well.
>
>Thanks in advance, Martin
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From tblackw at umich.edu  Mon Nov 24 16:57:22 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 24 Nov 2003 10:57:22 -0500 (EST)
Subject: [R] statistical prediction for glm()
In-Reply-To: <200311241359.44976.mailinglist2_wegmann@web.de>
References: <200311241359.44976.mailinglist2_wegmann@web.de>
Message-ID: <Pine.SOL.4.58.0311240827200.17843@zektor.gpcc.itd.umich.edu>

Martin  -

I can't figure out what question you are asking.
Does either  predict.glm()  in the base package or
cv.glm()  in the boot package do what you want ?

The theory for all of this is given in the references
listed in the help pages for  "glm"  and  "cv.glm".

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 24 Nov 2003, Martin Wegmann wrote:

> hello,
>
> I apologize that I poste this question again but I did not receive any replies
> on this topic and would like to know if the mail has been read over or if
> there is no method of statistical prediction computation for poisson errors
> in glm().
>
> I am looking for a way to compute the model prediciton error of a glm() with
> poisson error family.
> cv.glm() does not work. (it prompts values around 90.00)
>
> A " not there isn't such a method" would be fine as well.
>
> Thanks in advance, Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tblackw at umich.edu  Mon Nov 24 17:11:31 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 24 Nov 2003 11:11:31 -0500 (EST)
Subject: [R] statistical prediction for glm()
In-Reply-To: <200311211417.00739.mailinglist2_wegmann@web.de>
References: <200311211417.00739.mailinglist2_wegmann@web.de>
Message-ID: <Pine.SOL.4.58.0311241107590.17843@zektor.gpcc.itd.umich.edu>

Martin  -

Do you want a goodness of fit measure for a Poisson glm ?

I would start py plotting the residuals and doing an
analysis of deviance on nested models.  See McCullagh and
Nelder, as well as more recent references.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 21 Nov 2003, Martin Wegmann wrote:

> Hello,
>
> possibly it is a stupid question but after few hours of trying and searching,
> perhaps I used the wrong key words, I decided to post it.
>
> I have the output of a glm() of count data (poisson).
> I would like to get the prediction error (cross-validation).
>
> cv.glm() does not work with poisson error family data. Or I have to transform
> the output error pred. in some way.
>
> are there method especially for glm() with different error families to receive
> the model goodness / the model badness?
>
> thanks in advance, Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ggrothendieck at myway.com  Mon Nov 24 17:28:35 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 24 Nov 2003 11:28:35 -0500 (EST)
Subject: [R] Bollinger Bands
Message-ID: <20031124162835.2626B39AC@mprdmxin.myway.com>


I assume you are looking to apply some function, f, over the
last k points of your time series for each point in the 
series (except for the first k-1 points).

Let z be a vector that represents your time series.  Then 
the j-th column of 

  zl <- matrix(c(z,NA),length(z),k)[-seq(k-1),]   # ignore warning

is z lagged by j-1.  Now apply f to the rows:

  apply(zl,1,f)

--- 
Date: Mon, 24 Nov 2003 15:19:10 +0000 
From: <Arnaud_Amsellem at ssga.com>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] Bollinger Bands 

 
 
Is there a way to create Bollinger Bands without having to loop on the
observations of a time serie?

Any help appreciated

Thanks



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Mon Nov 24 17:47:53 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Mon, 24 Nov 2003 17:47:53 +0100
Subject: [R] Model checking for glms
Message-ID: <488C02265C6AD611BF200002A542182F03F2A854@irnts22.ifp.fr>

Hello,

I would like to have some advises concerning checking glms quality for
prediction. I've a glm with Gamma family and link=log, and I would like to
compute a Press statistic to check the predictivity of my model. Since my
link function is not "identity", I wonder which "Hat" matrix I should take
... Is the expression of this matrix unchanged (ie equal to
sqrt(W)%*%X%*%solve(t(X)%*%W%*%X)%*%t(X)%*%sqrt(W)) even if my link is equal
to log. Should I make a development of log ???

Thanks in advance for your help,

Regards

Isabelle Zabalza-Mezghani



From mailinglist2_wegmann at web.de  Mon Nov 24 19:02:39 2003
From: mailinglist2_wegmann at web.de (Martin Wegmann)
Date: Mon, 24 Nov 2003 19:02:39 +0100
Subject: goodness of fit for poisson glm - was:Re: [R] statistical prediction
	for glm()
In-Reply-To: <Pine.SOL.4.58.0311241107590.17843@zektor.gpcc.itd.umich.edu>
References: <200311211417.00739.mailinglist2_wegmann@web.de>
	<Pine.SOL.4.58.0311241107590.17843@zektor.gpcc.itd.umich.edu>
Message-ID: <200311241902.39679.mailinglist2_wegmann@web.de>

I have to apologize, my subject was misleading or wrong. 

thanks for pointing me to the correct name/description. 

A goodness of fit measure for a Poisson GLM is what I am looking for.

I am looking for a method similar to cv.glm(),to receive the estimate of 
prediction error.

I will have a look at the references given below, thanks for them. 

Martin

On Monday 24 November 2003 17:11, Thomas W Blackwell wrote:
> Martin  -
>
> Do you want a goodness of fit measure for a Poisson glm ?
>
> I would start py plotting the residuals and doing an
> analysis of deviance on nested models.  See McCullagh and
> Nelder, as well as more recent references.
>
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
> On Fri, 21 Nov 2003, Martin Wegmann wrote:
> > Hello,
> >
> > possibly it is a stupid question but after few hours of trying and
> > searching, perhaps I used the wrong key words, I decided to post it.
> >
> > I have the output of a glm() of count data (poisson).
> > I would like to get the prediction error (cross-validation).
> >
> > cv.glm() does not work with poisson error family data. Or I have to
> > transform the output error pred. in some way.
> >
> > are there method especially for glm() with different error families to
> > receive the model goodness / the model badness?
> >
> > thanks in advance, Martin
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dkelly at alum.mit.edu  Mon Nov 24 20:09:17 2003
From: dkelly at alum.mit.edu (David Kelly)
Date: Mon, 24 Nov 2003 11:09:17 -0800
Subject: [R] dvips function gives "Documents not found" error
References: <3FC11E23.3090701@alum.mit.edu>	<Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>
	<20031124081228.2cd671c1.feh3k@spamcop.net>
Message-ID: <3FC2575D.9040100@alum.mit.edu>

Thanks to you both for your suggestions, and great to hear from the 
author himself!

I may be thick, but I'm still having the problem. I did look at help for 
tempdir(), but tempdir() just *returns* the directory that's used; it 
doesn't allow me to change it.  As a slightly different tack, I tried 
using tempfile("dsk","\\kellytest")
but I still got the same error.

 From looking at the source code line mentioned below, I wouldn't expect 
the tempfile() call that I tried to make a difference anyway.

So: Is there someway I can change the value of tempdir() so I can 
influence Hmisc?  Also, in the source line quoted below, what is "tmp" 
and do I have some way to change that to give it a path without spaces?

I'm looking for a workaround here to allow to do some further 
testing/prototyping, not a permanent fix.

Thanks again --
David Kelly
--------------
On Mon, 24 Nov 2003 10:53:48 +0000 (GMT)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

 > This is a question about Hmisc, I believe, although you certainly did
 > not mention it.  Looking at the source code I see
 >
 >     sys(paste("cd", tempdir(), sc, optionsCmds("latex"), tmp))
 >
 > do my guess is that it is writing .dvi files in tempdir().
 > If you look up help on tempdir() you will see how to avoid this,
 >
 > Moral: don't guess, and don't make your readers guess either.
 >
 > And to Frank Harrell as author of Hmisc: spaces are valid in file names
 > even on Unix/Linux, so it would be nice if this could be corrected.


I've resisted this until now.  The fix appears to be to surround tempdir()
and tmp by dQuote( ). This will be in the next release.  I'm assuming that
superfluous quotes never hurt.   -Frank
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                       Department of Biostatistics    Vanderbilt University



From flyfish72 at fastmail.fm  Mon Nov 24 20:17:26 2003
From: flyfish72 at fastmail.fm (flyfish72@fastmail.fm)
Date: Mon, 24 Nov 2003 14:17:26 -0500
Subject: [R] Is R multi-threaded?
Message-ID: <20031124191726.9F62A3FF78@server1.messagingengine.com>

Hi,

I couldn't find a good answer for this anywhere in the docs, and I've
looked through the code for 1.8.0;  could someone who knows please
confirm that R (for unix) is *not* currently multi-threaded?

(I'm having trouble dynamically loading a C++ shared lib, and I want to
make sure it's not thread-related)

Thanks,
Annie



From ltorgo at liacc.up.pt  Mon Nov 24 20:45:56 2003
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Mon, 24 Nov 2003 19:45:56 +0000
Subject: [R] RMySQL valid field names
Message-ID: <200311241945.56603.ltorgo@liacc.up.pt>

I'm having some problems with valid field names when using RMySQL to interface 
R (version 1.7.0, under RedHat9.0), to MySQL (4.1.0-alpha). I think I've 
spotted the problem and a solution (which is working for me), but I wanted to 
share this with you as I may be missing something.
(Note: I'm aware that this is an old R version, but I've checked the code of 
the lastest version of the RMySQL package at CRAN, and my comments still 
apply).

I have a data frame which has among others three columns with names 
('DateTime', 'Open' and 'Close'). When I use dbWriteTable to dump the data 
frame into a MySQL database everything works fine except the names of these 
three columns which are slightly different (e.g. 'DateTime_9'). 

This only occurs with these 3 columns because their names are reserved words 
of MySQL. The change of names is occurring in the function mysqlWriteTable, 
namely in the call:
...
names(field.types) <- make.db.names(con,names(field.types),allow.keywords=F)
...
If I change the parameter allow.keywords into T, everything works fine for me. 
Given that MySQL allows all characters to be part of field names (section 
6.1.2 of MySQL reference manual), I do not understand what is the reason for 
calling make.db.names with this value of parameter allow.keywords.

In resume, my question is: Is there any reason for this that I am missing, or 
the change I've done is pretty safe and could possibly be done in future 
versions of the package?

Thank you for any help.
Luis

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From ripley at stats.ox.ac.uk  Mon Nov 24 21:16:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Nov 2003 20:16:42 +0000 (GMT)
Subject: [R] Is R multi-threaded?
In-Reply-To: <20031124191726.9F62A3FF78@server1.messagingengine.com>
Message-ID: <Pine.LNX.4.44.0311242015260.22426-100000@gannet.stats>

R for Unix is not of itself multi-threaded, but it can call libraries 
which are (notably a multi-threaded BLAS).

R for Windows is multi-threaded.

On Mon, 24 Nov 2003 flyfish72 at fastmail.fm wrote:

> I couldn't find a good answer for this anywhere in the docs, and I've
> looked through the code for 1.8.0;  could someone who knows please
> confirm that R (for unix) is *not* currently multi-threaded?
> 
> (I'm having trouble dynamically loading a C++ shared lib, and I want to
> make sure it's not thread-related)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Nov 24 21:33:09 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Nov 2003 20:33:09 +0000 (GMT)
Subject: [R] Warning calling par
In-Reply-To: <FF7BA726C256BE40865428CF15E0B42E75AC45@apex01.ap1.se>
Message-ID: <Pine.LNX.4.44.0311242027500.22426-100000@gannet.stats>

On Mon, 24 Nov 2003, "Wiklund, P?r" wrote:

> Hi. I have a function that works well under R 1.7.1 But under 1.8.0 and 1.8.1 I get:Warning message: 
> calling par(new=) with no plot
> 
> And it doesnt plot

And your point is?  Your code was incorrect, and now your error is
detected.  Why are you calling close.screen:

     'close.screen' removes the specified screen definition(s).

when you have not specified any?

Such code produced invalid output on e.g. postscript() and pdf() devices
in the past, and the error is now trapped.


> The function is:
> mplotmeth1<-function(data1,data2,alpha,nr){
> 	psfile<-paste("Meth1_",nr[1],"-",nr[length(nr)],".ps",sep="")
> 	postscript(psfile)
> 	close.screen(all=T)

[...]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Nancy.Lo at noaa.gov  Mon Nov 24 22:22:04 2003
From: Nancy.Lo at noaa.gov (Nancy Lo)
Date: Mon, 24 Nov 2003 13:22:04 -0800
Subject: [R] How to get the parameters of  nls(...) for later use
Message-ID: <3FC2767C.28EA5A60@noaa.gov>

Hi all,

I need to use the parameter estimates of nls() for further analysis. I
know how to do in S+, e.g. nls(...)$parameters. In R, the
attributes(nls(...)) does not have parameters, how would one get the
parameter values out of nls()?
Thanks in advance.

Nancy



From p.connolly at hortresearch.co.nz  Mon Nov 24 22:23:46 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 25 Nov 2003 10:23:46 +1300
Subject: [R] 1.8.1 and subsetting dataframes
Message-ID: <20031124212346.GB26966@hortresearch.co.nz>

I've encountered something that didn't arise using earlier versions of
R (Linux).

A dataframe is created and new columns added to it by doing
calculations using apply with various functions on some of the
original columns.  It's somewhat too involved to give a toy example
that's reproducible.  However, the resulting phenemonon can be
characterised by the following:

Browse[1]> dim(mod.df)
[1] 409   5
Browse[1]> object.size(mod.df)
[1] 31520
Browse[1]> is.array(mod.df)
[1] FALSE
Browse[1]> mod.df[1:5,]
Error in as.data.frame.default(x[[i]], optional = TRUE) : 
	can't coerce array into a data.frame

The whole dataframe would display correctly, so I figured it couldn't
have much wrong with it.  So I tried this:


Browse[1]>     write.table(mod.df, "mod.tmp", quote = F, sep = "\t", row.names = F)
Browse[1]>     mod.df <- read.table("mod.tmp", T, sep = "\t")
Browse[1]> is.array(mod.df)
[1] FALSE
Browse[1]> object.size(mod.df)
[1] 16164
Browse[1]> mod.df[1:5,]
        Site System Cultivar  Type CFU
1 Canterbury    ifp braeburn fruit 388
2 Canterbury    ifp braeburn fruit 920
3 Canterbury    ifp braeburn fruit 868
4 Canterbury    ifp braeburn fruit 328
5 Canterbury    ifp braeburn fruit 656


The size of the object using R-1.8.0 (which had no subsetting
problems) was

Browse[1]> object.size(mod.df)
[1] 21160


I suspect it could have something to do with some of the changes
mentioned in this part of the NEWS file:

    o	Subscripting for data.frames has been rationalized:

But I'm not smart enough to see what in those dozen or so would have a
bearing on this case.  I don't think the drop argument comes into what
I've done.

If that's not sufficient to give anyone a hint what could be
happening, I'll have another attempt to get a toy version.


Thanks.

PS: Is there a more elegant way using a text connection instead or
creating a temporary file in my work around?

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From p.dalgaard at biostat.ku.dk  Mon Nov 24 22:57:16 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Nov 2003 22:57:16 +0100
Subject: [R] How to get the parameters of  nls(...) for later use
In-Reply-To: <3FC2767C.28EA5A60@noaa.gov>
References: <3FC2767C.28EA5A60@noaa.gov>
Message-ID: <x2ekvxtooz.fsf@biostat.ku.dk>

"Nancy Lo" <Nancy.Lo at noaa.gov> writes:

> Hi all,
> 
> I need to use the parameter estimates of nls() for further analysis. I
> know how to do in S+, e.g. nls(...)$parameters. In R, the
> attributes(nls(...)) does not have parameters, how would one get the
> parameter values out of nls()?
> Thanks in advance.

Same way as you really ought to do it in S-PLUS:

library(nls)
example(nls)

coef(Pur.wt)

or, if you insist on using the internals:  Pur.wt$m$getPars()


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon Nov 24 22:59:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Nov 2003 21:59:05 +0000 (GMT)
Subject: [R] 1.8.1 and subsetting dataframes
In-Reply-To: <20031124212346.GB26966@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.44.0311242156050.26100-100000@gannet.stats>

The changes you point to were between 1.7.1 and 1.8.0, not between 1.8.0 
and 1.8.1.

1.7.1 was quite capable of producing invalid data frames from erroneous 
usages.

I think we really do need to see a reproducible example.

On Tue, 25 Nov 2003, Patrick Connolly wrote:

> I've encountered something that didn't arise using earlier versions of
> R (Linux).
> 
> A dataframe is created and new columns added to it by doing
> calculations using apply with various functions on some of the
> original columns.  It's somewhat too involved to give a toy example
> that's reproducible.  However, the resulting phenemonon can be
> characterised by the following:
> 
> Browse[1]> dim(mod.df)
> [1] 409   5
> Browse[1]> object.size(mod.df)
> [1] 31520
> Browse[1]> is.array(mod.df)
> [1] FALSE
> Browse[1]> mod.df[1:5,]
> Error in as.data.frame.default(x[[i]], optional = TRUE) : 
> 	can't coerce array into a data.frame
> 
> The whole dataframe would display correctly, so I figured it couldn't
> have much wrong with it.  So I tried this:
> 
> 
> Browse[1]>     write.table(mod.df, "mod.tmp", quote = F, sep = "\t", row.names = F)
> Browse[1]>     mod.df <- read.table("mod.tmp", T, sep = "\t")
> Browse[1]> is.array(mod.df)
> [1] FALSE
> Browse[1]> object.size(mod.df)
> [1] 16164
> Browse[1]> mod.df[1:5,]
>         Site System Cultivar  Type CFU
> 1 Canterbury    ifp braeburn fruit 388
> 2 Canterbury    ifp braeburn fruit 920
> 3 Canterbury    ifp braeburn fruit 868
> 4 Canterbury    ifp braeburn fruit 328
> 5 Canterbury    ifp braeburn fruit 656
> 
> 
> The size of the object using R-1.8.0 (which had no subsetting
> problems) was
> 
> Browse[1]> object.size(mod.df)
> [1] 21160
> 
> 
> I suspect it could have something to do with some of the changes
> mentioned in this part of the NEWS file:
> 
>     o	Subscripting for data.frames has been rationalized:
> 
> But I'm not smart enough to see what in those dozen or so would have a
> bearing on this case.  I don't think the drop argument comes into what
> I've done.
> 
> If that's not sufficient to give anyone a hint what could be
> happening, I'll have another attempt to get a toy version.
> 
> 
> Thanks.
> 
> PS: Is there a more elegant way using a text connection instead or
> creating a temporary file in my work around?

Yes!  Use an anonymous file connection opened for rw.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Mon Nov 24 23:06:12 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 24 Nov 2003 16:06:12 -0600
Subject: [R] How to get the parameters of  nls(...) for later use
In-Reply-To: <3FC2767C.28EA5A60@noaa.gov>
References: <3FC2767C.28EA5A60@noaa.gov>
Message-ID: <6r8ym5whez.fsf@bates4.stat.wisc.edu>

"Nancy Lo" <Nancy.Lo at noaa.gov> writes:

> I need to use the parameter estimates of nls() for further analysis. I
> know how to do in S+, e.g. nls(...)$parameters. In R, the
> attributes(nls(...)) does not have parameters, how would one get the
> parameter values out of nls()?

In both R and S-PLUS the use of the extractor function coef() is the
preferred way to obtain the parameter estimates from a fitted nls
model.  Try

 coef(nls(...))



From p.dalgaard at biostat.ku.dk  Mon Nov 24 23:36:32 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Nov 2003 23:36:32 +0100
Subject: [R] 1.8.1 and subsetting dataframes
In-Reply-To: <20031124212346.GB26966@hortresearch.co.nz>
References: <20031124212346.GB26966@hortresearch.co.nz>
Message-ID: <x2ad6ltmvj.fsf@biostat.ku.dk>

Patrick Connolly <p.connolly at hortresearch.co.nz> writes:

> I've encountered something that didn't arise using earlier versions of
> R (Linux).
> 
> A dataframe is created and new columns added to it by doing
> calculations using apply with various functions on some of the
> original columns.  It's somewhat too involved to give a toy example
> that's reproducible.  

You can try harder, though. See below.

> However, the resulting phenemonon can be
> characterised by the following:
> 
> Browse[1]> dim(mod.df)
> [1] 409   5
> Browse[1]> object.size(mod.df)
> [1] 31520
> Browse[1]> is.array(mod.df)
> [1] FALSE
> Browse[1]> mod.df[1:5,]
> Error in as.data.frame.default(x[[i]], optional = TRUE) : 
> 	can't coerce array into a data.frame

Looks like one of the columns of mod.df is not what is should have
been. So what does str(mod.df) say?. Also, just before the subsetting,
try setting debug(as.data.frame.default) and see what its argument is
in the case that fails.
 
> The whole dataframe would display correctly, so I figured it couldn't
> have much wrong with it.  

My bet is that it does...

> I suspect it could have something to do with some of the changes
> mentioned in this part of the NEWS file:
> 
>     o	Subscripting for data.frames has been rationalized:
> 
> But I'm not smart enough to see what in those dozen or so would have a
> bearing on this case.  I don't think the drop argument comes into what
> I've done.

Note that this was changed already in 1.8.0, which you say have no
problems... 

My guess is that the code is not quite smart enough yet, e.g.

> x <-data.frame(a=0:9,b=2:11)
> x$b <- array(1:10,10)
> x
Error in as.data.frame.default(x[[i]], optional = TRUE) :
        can't coerce array into a data.frame

but it's not like that has worked before (certainly not in 1.7.1
anyway). One difference is that indexing used to clean up this kind of
corrupted data frame, but now it gives you a data frame which is
corrupted in the same way:

1.8.0 (x as above):

> z <- x[1:5,]
> z
  a b
1 0 1
2 1 2
3 2 3
4 3 4
5 4 5
> x
Error in as.data.frame.default(x[[i]], optional = TRUE) :
        can't coerce array into a data.frame

1.8.1:

> z <- x[1:5,]
> z
Error in as.data.frame.default(x[[i]], optional = TRUE) :
        can't coerce array into a data.frame


> If that's not sufficient to give anyone a hint what could be
> happening, I'll have another attempt to get a toy version.
> 
> 
> Thanks.
> 
> PS: Is there a more elegant way using a text connection instead or
> creating a temporary file in my work around?

Not really. Shouldn't have to do it though. You probably want to put
an as.vector around those apply() calls instead.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.connolly at hortresearch.co.nz  Mon Nov 24 23:51:48 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 25 Nov 2003 11:51:48 +1300
Subject: [R] 1.8.1 and subsetting dataframes
In-Reply-To: <x2ad6ltmvj.fsf@biostat.ku.dk>
References: <20031124212346.GB26966@hortresearch.co.nz>
	<x2ad6ltmvj.fsf@biostat.ku.dk>
Message-ID: <20031124225148.GC26966@hortresearch.co.nz>

On Mon, 24-Nov-2003 at 11:36PM +0100, Peter Dalgaard wrote:

|> Patrick Connolly <p.connolly at hortresearch.co.nz> writes:
|> 
|> > I've encountered something that didn't arise using earlier versions of
|> > R (Linux).
|> > 
|> > A dataframe is created and new columns added to it by doing
|> > calculations using apply with various functions on some of the
|> > original columns.  It's somewhat too involved to give a toy example
|> > that's reproducible.  
|> 
|> You can try harder, though. See below.


|> > PS: Is there a more elegant way using a text connection instead or
|> > creating a temporary file in my work around?
|> 
|> Not really. Shouldn't have to do it though. You probably want to put
|> an as.vector around those apply() calls instead.

What brilliant insight!  That's exactly what it needed.  Thanks for
the other suggestions, but they weren't necessary.

Things are *not* rotten in the state of Denmark.  

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From mendigo at netcabo.pt  Mon Nov 24 23:58:39 2003
From: mendigo at netcabo.pt (Miguel Martins Palhoto Nobre Rodrigues)
Date: Mon, 24 Nov 2003 22:58:39 -0000
Subject: [R] Variance Ratios
Message-ID: <006f01c3b2de$80d2fa60$e9a716d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031124/184806db/attachment.pl

From dj at research.bell-labs.com  Tue Nov 25 00:29:26 2003
From: dj at research.bell-labs.com (David James)
Date: Mon, 24 Nov 2003 18:29:26 -0500
Subject: [R] Re: [RMySQL] unable to establish connection since R-1.8.0
	upgrade
In-Reply-To: <3FC2281F.3080205@ariase.com>;
	from laurent.faisnel@ariase.com on Mon, Nov 24, 2003 at
	04:47:43PM +0100
References: <3FC2281F.3080205@ariase.com>
Message-ID: <20031124182926.A11269@jessie.research.bell-labs.com>

Hi Laurent,

The issue is a very simple one to correct --- you only need to
re-install RMySQL with the R version you're currently using.

The issue is that the internal representation of objects in the
methods package changed in 1.8.0, and thus packages that use S4
classes and methods and save their images (like RMySQL) and were
installed prior to 1.8.0 need to be re-installed to be used with
newer R versions.

Hope this helps,

--
David

Laurent Faisnel wrote:
> Hi David,
> 
> I have problems with RMySQL since I have upgraded to R-1.8.0 (now I have 
> R-1.8.1). I have been using this package for quite a long time (don't 
> konw if you remember, you helped me out with a function lean.exec which 
> runs queries much faster than the standard dbGetQuery), without trouble, 
> but there seems to be something incompatible with R >= R-1.8.0.
> 
> The error comes up when I try to establish a connection :
> 
>  > library(DBI)
>  > library(RMySQL)
>  > dbConnect("MySQL")
> Error in initialize(value, ...) : Invalid names for slots of class 
> MySQLDriver: Id
> 
> This is the error I have after having added to the NAMESPACE file of the 
> "methods" package the line :
> 				export(.valueClassTest)
> 
> following John Chambers' piece of advice (see 
> http://maths.newcastle.edu.au/~rking/R/devel/03b/0861.html).
> 
> Before adding that line I had the same problem Fernando mentionned (see 
> previous link).
> 
> My settings are :
> 
> Red Hat Linux 8.0
> R-1.8.1
> RMySQL-0.5.2
> 
> I don't have a sufficient knowledge of the way R is programmed to fix 
> the problem by myself. What's your opinion about that ? Should RMySQL be 
> updated ? Are you working on that ? In the previous debate you seemed to 
> believe the problem lies in R (>= 1.8.0), and not in RMySQL. I'm 
> enclined to think you may be right, since I had a few difficulties with 
> R >= 1.8.0 (new library to be added for X11, eg).
> 
> If you think this can be useful to others you can cc your answer to R-devel.
> 
> Thanks in advance for any help,
> Best regards,
> Laurent



From Duncan.Mackay at flinders.edu.au  Tue Nov 25 00:54:34 2003
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Tue, 25 Nov 2003 10:24:34 +1030
Subject: [R] kruskal wallis for manova?
In-Reply-To: <Pine.LNX.4.51.0311240921370.29182@artemis.imbe.med.uni-erlangen.de>
Message-ID: <LKEKIOMKIBNKJOPKIKOOAEMADKAA.Duncan.Mackay@flinders.edu.au>

Hi,
you may also be interested in Marti Anderson's NPMANOVA program, described
at http://www.stat.auckland.ac.nz/~mja/Programs.htm

Cheers, Duncan

*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Torsten Hothorn
Sent: Monday, 24 November 2003 6:54 PM
To: Nicolaas Busscher
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] kruskal wallis for manova?



> Hello,
> Is there like the kruskal wallis test in relation to ANOVA (no
> restrictions on normallity and variance homogenity) something (in R)
> for MANOVA?

You may know Fortunato Pesarin's book

@book{multivaria:2001,
   key       = {386},
   author    = {Fortunato Pesarin},
   title     = {Multivariate Permutation Tests:
                With Applications to Biostatistics},
   year      = {2001},
   publisher = {John Wiley \& Sons},
   address   = {Chichester}
}

which addresses those problems. There is some S-Code on the authors
web-page which may be point to start.

Best,

Torsten


> thanks
>
> --
> Dr.Nicolaas Busscher Universit?t GH Kassel
> Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
> Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dmurdoch at pair.com  Tue Nov 25 00:57:14 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 24 Nov 2003 18:57:14 -0500
Subject: [R] dvips function gives "Documents not found" error
In-Reply-To: <3FC2575D.9040100@alum.mit.edu>
References: <3FC11E23.3090701@alum.mit.edu>	<Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>
	<20031124081228.2cd671c1.feh3k@spamcop.net>
	<3FC2575D.9040100@alum.mit.edu>
Message-ID: <1u55svod3mcllfp7vrees3c7a0cp9eherj@4ax.com>

On Mon, 24 Nov 2003 11:09:17 -0800, David Kelly <dkelly at alum.mit.edu>
wrote:


>So: Is there someway I can change the value of tempdir() so I can 
>influence Hmisc?  

Not after R has started, but if you set the TMP or TEMP environment
variable to the name of an existing directory, that will be used as
the base of temp directories.  You can do this on the R command line,
e.g. set the Target field in the R shortcut to 

C:\R\rw1081\bin\Rgui.exe TMP=c:/junk

More on this is in ?tempdir and ?Startup.

Duncan Murdoch



From Jason.L.Higbee at stls.frb.org  Tue Nov 25 02:55:28 2003
From: Jason.L.Higbee at stls.frb.org (Jason.L.Higbee@stls.frb.org)
Date: Mon, 24 Nov 2003 19:55:28 -0600
Subject: [R] Time series indexing/subsetting
Message-ID: <20031125015529.9DEE4857BC@p3fed1.frb.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031124/a4175d0e/attachment.pl

From jasont at indigoindustrial.co.nz  Tue Nov 25 03:55:11 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 25 Nov 2003 15:55:11 +1300
Subject: [R] Time series indexing/subsetting
In-Reply-To: <20031125015529.9DEE4857BC@p3fed1.frb.org>
References: <20031125015529.9DEE4857BC@p3fed1.frb.org>
Message-ID: <3FC2C48F.4070600@indigoindustrial.co.nz>

Jason.L.Higbee at stls.frb.org wrote:

> R-listers:
> 
> I may be asking too much from R, but is there a way to use time indexing 
> on a time series object.  For instance:
> 
> 
>>tsobject <- ts(1:12, start =1999, freq = 4)
>>tsobject
> 
>      Qtr1 Qtr2 Qtr3 Qtr4
> 1999    1    2    3    4
> 2000    5    6    7    8
> 2001    9   10   11   12
> 
>>tsobject[1999,Qtr4]
> 

Qtr4 isn't a part of the tsobject.  It's produced by the print method 
for ts objects in general.

I believe you want "window"  Something like...

 > window(tsobject, start=c(1999,4), deltat =1)
Time Series:
Start = 1999.8
End = 2001.8
Frequency = 1
[1]  4  8 12

Cheers

Jason

-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From aves at ci.uc.pt  Tue Nov 25 04:33:02 2003
From: aves at ci.uc.pt (Ricardo Lopes)
Date: Tue, 25 Nov 2003 03:33:02 -0000
Subject: [R] Y axis scale in plot.gam
Message-ID: <3FC2CD6E.2070.74A86D@localhost>


Hi,

Is there any way to change the y axis range of values in a plot.gam()? I 
need that two different GAM plots to be of the same scale.

Also, it is possible to change the labels?

I tried with "ylab" and "ylim" and did not work


Thanks in advance


Ricardo Lopes

Ricardo Lopes

.............................................

Instituto do Mar
Departamento de Zoologia
Universidade de Coimbra

Tel: +351 239 834729 (305)
Fax: +351 239823603
Telem?vel: +351 965078884

.............................................



From Giles.Heywood at CommerzbankIB.com  Tue Nov 25 08:58:00 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 25 Nov 2003 07:58:00 -0000
Subject: [R] Bollinger Bands
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF05BF7386@xmx8lonib.lonib.commerzbank.com>

You might wish to have a look at the 'its' package for irregular 
time-series on CRAN.  If your prices are in an its called price, 
then the following will get you on your way.  Since it is not efficient 
either in storage or computation, I offer it because it might be 
convenient for display, further processing, etc.

library(its)
...
tmp <- lagdistIts(diff(log(price)),1,20)
rollvol <- its(as.matrix(sqrt(apply(tmp,1,var,na.rm=TRUE))))

- Giles

> -----Original Message-----
> From: Arnaud_Amsellem at ssga.com [mailto:Arnaud_Amsellem at ssga.com]
> Sent: 24 November 2003 15:19
> To: r-help at stat.math.ethz.ch
> Subject: [R] Bollinger Bands
> 
> 
> Is there a way to create Bollinger Bands without having to loop on the
> observations of a time serie?
> 
> Any help appreciated
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From eia018 at comp.lancs.ac.uk  Tue Nov 25 10:09:06 2003
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Tue, 25 Nov 2003 09:09:06 +0000 (GMT)
Subject: [R] Parameter estimation in nls
Message-ID: <Pine.GSO.4.21.0311250903090.1533-100000@austin>

I am trying to fit a rank-frequency distribution with 3 unknowns (a, b
and k) to a set of data.

This is my data set:

y <- c(37047647,27083970,23944887,22536157,20133224,
20088720,18774883,18415648,17103717,13580739,12350767,
8682289,7496355,7248810,7022120,6396495,6262477,6005496,
5065887,4594147,2853307,2745322,454572,448397,275136,268771)

and this is the fit I'm trying to do:

nlsfit <- nls(y ~ a * x^k * b^x, start=list(a=5,k=1,b=3))

(It's a Yule distribution.)

However, I keep getting:

"Error in nls(y ~ a * x^k * b^x, start = list(a = 5, k = 1, b = 3)) : 
singular gradient"

I guess this has something to do with the parameter start values.

I was wondering, is there a fully automated way of estimating parameters
which doesn't need start values close to the final estimates?  I know
other programs do it, so is it possible in R?

Thanks,
Andrew Wilson



From simon at stats.gla.ac.uk  Tue Nov 25 10:11:23 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Tue, 25 Nov 2003 09:11:23 +0000 (GMT)
Subject: [R] Y axis scale in plot.gam
In-Reply-To: <3FC2CD6E.2070.74A86D@localhost>
References: <3FC2CD6E.2070.74A86D@localhost>
Message-ID: <Pine.SOL.4.58.0311250907040.15639@moon.stats.gla.ac.uk>

> Is there any way to change the y axis range of values in a plot.gam()? I
> need that two different GAM plots to be of the same scale.

- Sorry, I don't think there is a simple way of doing it, except by
editing plot.gam to fix `ylim' by hand.... It's an obvious thing to want
to do and I'll fix it for the next release.

> Also, it is possible to change the labels?

- The easiest thing to do is to use the `select' argument to plot 1 panel
at a time, with ann=FALSE (see ?par) to supress annotation. Then use the
`title' function to add x and y labels.

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From p.dalgaard at biostat.ku.dk  Tue Nov 25 10:59:47 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Nov 2003 10:59:47 +0100
Subject: [R] Parameter estimation in nls
In-Reply-To: <Pine.GSO.4.21.0311250903090.1533-100000@austin>
References: <Pine.GSO.4.21.0311250903090.1533-100000@austin>
Message-ID: <x2wu9osr8s.fsf@biostat.ku.dk>

Dr Andrew Wilson <eia018 at comp.lancs.ac.uk> writes:

> I am trying to fit a rank-frequency distribution with 3 unknowns (a, b
> and k) to a set of data.
> 
> This is my data set:
> 
> y <- c(37047647,27083970,23944887,22536157,20133224,
> 20088720,18774883,18415648,17103717,13580739,12350767,
> 8682289,7496355,7248810,7022120,6396495,6262477,6005496,
> 5065887,4594147,2853307,2745322,454572,448397,275136,268771)
> 
> and this is the fit I'm trying to do:
> 
> nlsfit <- nls(y ~ a * x^k * b^x, start=list(a=5,k=1,b=3))
> 
> (It's a Yule distribution.)
> 
> However, I keep getting:
> 
> "Error in nls(y ~ a * x^k * b^x, start = list(a = 5, k = 1, b = 3)) : 
> singular gradient"
> 
> I guess this has something to do with the parameter start values.
> 
> I was wondering, is there a fully automated way of estimating parameters
> which doesn't need start values close to the final estimates?  I know
> other programs do it, so is it possible in R?

You don't seem to have an x anywhere. Are you making the (apparently
not uncommon) mistake of trying to use a program for fitting nonlinear
relations by least squares to fit a probability density? If so, look
for fitdistr() instead.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From eia018 at comp.lancs.ac.uk  Tue Nov 25 10:56:36 2003
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Tue, 25 Nov 2003 09:56:36 +0000 (GMT)
Subject: [R] Parameter estimation in nls - ERRATUM
In-Reply-To: <x2wu9osr8s.fsf@biostat.ku.dk>
Message-ID: <Pine.GSO.4.21.0311250954100.1713-100000@austin>

Martin Maechler has pointed out to me that I omitted to include my values
for x when circulating my query.  They are a simple rank list from 1 to
26:

x <- 1:26

Thanks,
Andrew



From H.RINNER at tirol.gv.at  Tue Nov 25 11:05:53 2003
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Tue, 25 Nov 2003 11:05:53 +0100
Subject: AW: [R] ISOdate() and strptime()
Message-ID: <C4D44AB4CB62D311BA6500041202E886031EE352@xms1.tirol.gv.at>

Thanks for this clarification.

I have learned in the meantime that it is necessary to be very careful when
using all these POSIX things.
As another example, here is something that made me scratch my head just
yesterday:

When I create a sequence of days that happens to start before and ends in
daylight savings time, I seem to lose a day:

> seq(from = strptime("20030329", format="%Y%m%d"), to= strptime("20030402",
format="%Y%m%d"), by="DSTday")
[1] "2003-03-29 Westeurop?ische Normalzeit" "2003-03-30 Westeurop?ische
Normalzeit"
[3] "2003-03-31 Westeurop?ische Sommerzeit" "2003-04-01 Westeurop?ische
Sommerzeit"
> seq(from = strptime("20030329", format="%Y%m%d"), to= strptime("20030402",
format="%Y%m%d"), by="day")
[1] "2003-03-29 00:00:00 Westeurop?ische Normalzeit" "2003-03-30 00:00:00
Westeurop?ische Normalzeit"
[3] "2003-03-31 01:00:00 Westeurop?ische Sommerzeit" "2003-04-01 01:00:00
Westeurop?ische Sommerzeit"

Again, my expectations might be wrong here, and there will be good reasons
why I get this result (my OS again?).

But considering all these subtle issues I have encountered so far,
personally I can understand why some people suggested that it may be easier
to use the chron or date package (especially if you are a beginner, have no
prior experience with all these things, and don't want to worry about time
zones, DST, or the pitfalls of your OS).
At least it was useful for me to cross-check the results I obtained with
POSIX with the results using chron.

The POSIX classes are a great thing, but as they are much more powerful,
they are also more complex and have more things to watch out for and more
"traps" to fall in (for me at least ;-)).

-Heinrich.

> -----Urspr?ngliche Nachricht-----
> Von: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Gesendet: Samstag, 22. November 2003 20:56
> An: RINNER Heinrich
> Cc: r-help at stat.math.ethz.ch; Simon.Fear at synequanon.com
> Betreff: Re: [R] ISOdate() and strptime()
> 
> 
> Confirmation that this *is* an OS-specific problem: A professional 
> implementation of the POSIX standard (Solaris) gets all of 
> these correct.
> 
> Your so-called OS lacks any implementation of strptime, so we 
> borrowed one 
> from glibc.  Unfortunately, that is buggy, even to the extent that
> 
> unclass(strptime("2003-22-20", format="%Y-%m-%d"))
> unclass(strptime("2003 22 20", format="%Y %m %d"))
> 
> give different answers!  (And RH8.0 gives the same answers as the 
> substitute code used on R for Windows.)
> 
> I believe Simon Fear owes the R-developers a public apology 
> for his (not
> properly referenced in the archives) reply to this thread.
> 
> BDR
> 
> On Fri, 14 Nov 2003, Prof Brian Ripley wrote:
> 
> > On Fri, 14 Nov 2003, RINNER Heinrich wrote:
> > 
> > > Dear R-people!
> > > 
> > > I am using R 1.8.0, under Windows XP.
> > > While using ISOdate() and strptime(), I noticed the 
> following behaviour when
> > > "wrong" arguments (e.g., months>12) are given to these functions:
> > > 
> > > > ISOdate(year=2003,month=2,day=20) #ok
> > > [1] "2003-02-20 13:00:00 Westeurop?ische Normalzeit"
> > > > ISOdate(year=2003,month=2,day=30) #wrong day, but 
> returns a value
> > > [1] "2003-03-02 13:00:00 Westeurop?ische Normalzeit"
> > > > ISOdate(year=2003,month=2,day=35) #wrong day, and returns NA
> > > [1] NA
> > > > ISOdate(year=2003,month=2,day=40) #wrong day, but 
> returns a value
> > > [1] "2003-02-04 01:12:00 Westeurop?ische Normalzeit"
> > > > ISOdate(year=2003,month=22,day=20) #wrong month, but 
> returns a value
> > > [1] "2003-02-02 21:12:00 Westeurop?ische Normalzeit"
> > > 
> > > And almost the same with strptime():
> > > > strptime("2003-02-20", format="%Y-%m-%d")
> > > [1] "2003-02-20"
> > > > strptime("2003-02-30", format="%Y-%m-%d")
> > > [1] "2003-03-02"
> > > > strptime("2003-02-35", format="%Y-%m-%d")
> > > [1] NA
> > > > strptime("2003-02-40", format="%Y-%m-%d")
> > > [1] "2003-02-04"
> > > > strptime("2003-22-20", format="%Y-%m-%d")
> > > [1] NA
> > > 
> > > Is this considered to be a user error ("If you put 
> garbage in, expect to get
> > > garbage out"), or would it be safer to generally return Nas, as in
> > > ISOdate(year=2003,month=2,day=35)?
> > 
> > Expect to get the best guess at what you intended, and 
> expect this to 
> > depend on your OS.
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From Pascal.Niklaus at unibas.ch  Tue Nov 25 11:20:37 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Tue, 25 Nov 2003 11:20:37 +0100
Subject: [R] randomly permuting rows or col's of a matrix
Message-ID: <3FC32CF5.50205@unibas.ch>

Is there an shortcut (compared to "manually" swap row vectors) for the 
random permutation of rows of a matrix?

"sample" does not act on the element row vectors as a whole.

Thanks

Pascal



From christian.schulz at questico.de  Tue Nov 25 11:29:04 2003
From: christian.schulz at questico.de (Christian Schulz)
Date: Tue, 25 Nov 2003 11:29:04 +0100
Subject: [R] 1.8.1. RMySQL Win2K Writing-Table Problem?
Message-ID: <JAEELBHBOPKJDMMCNHKMOEKGCBAA.christian.schulz@questico.de>

Hi,

i getting following error and don't know doing
something wrong.

>mysqlWriteTable(con,"model1",model1,overwrite=T)
Error in "[.data.frame"(value, from:to, drop = FALSE) :
        undefined columns selected
In addition: Warning message:
drop argument will be ignored in: "[.data.frame"(value, from:to, drop =
FALSE)

Exactly the same code, database and data
works with 1.7.1 very nice!

Many thanks,
Christian



From B.Rowlingson at lancaster.ac.uk  Tue Nov 25 11:38:03 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 25 Nov 2003 10:38:03 +0000
Subject: [R] randomly permuting rows or col's of a matrix
In-Reply-To: <3FC32CF5.50205@unibas.ch>
References: <3FC32CF5.50205@unibas.ch>
Message-ID: <3FC3310B.9060807@lancaster.ac.uk>

Pascal A. Niklaus wrote:
> Is there an shortcut (compared to "manually" swap row vectors) for the 
> random permutation of rows of a matrix?
> 
> "sample" does not act on the element row vectors as a whole.
> 

  True, but sample(nrow(foo)) gives you a permutation of 1:nrow(foo) 
that you can subscript with:

  foo[sample(nrow(foo)),]

or

  foo[,sample(ncol(foo))]


Baz



From christian.schulz at questico.de  Tue Nov 25 11:36:38 2003
From: christian.schulz at questico.de (Christian Schulz)
Date: Tue, 25 Nov 2003 11:36:38 +0100
Subject: [R] RandomForest &  memory demand
Message-ID: <JAEELBHBOPKJDMMCNHKMKEKHCBAA.christian.schulz@questico.de>

Hi,

is it correct that i need  ~ 2GB RAM that it's
possible to work with the default setting 
ntree=500 and a data.frame with 100.000 rows 
and max. 10 columns for training and testing?

P.S.
It's possible calculate approximate the
memory demand for different settings with RF?

Many thanks & regards,
Christian



From rksh at soc.soton.ac.uk  Tue Nov 25 12:09:47 2003
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 25 Nov 2003 11:09:47 +0000
Subject: [R] Lambert's W function
Message-ID: <a0600201dbbe8de9dec6e@[139.166.242.29]>

Hello List

does anyone have an R function for the Lambert W function?  I need 
complex arguments.

[the Lamert W function W(z) satisfies

W(z)*exp(W(z)) = z

but I could'nt even figure out how to use uniroot() for complex z]





-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Nov 25 12:25:51 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 25 Nov 2003 12:25:51 +0100 (CET)
Subject: [R] RandomForest &  memory demand
In-Reply-To: <JAEELBHBOPKJDMMCNHKMKEKHCBAA.christian.schulz@questico.de>
References: <JAEELBHBOPKJDMMCNHKMKEKHCBAA.christian.schulz@questico.de>
Message-ID: <Pine.LNX.4.51.0311251220370.3344@artemis.imbe.med.uni-erlangen.de>


> Hi,
>
> is it correct that i need  ~ 2GB RAM that it's
> possible to work with the default setting
> ntree=500 and a data.frame with 100.000 rows
> and max. 10 columns for training and testing?
>

no. You may parallelize the computations: perform 5 runs of RF with `ntree
= 100' (or less) and save the resulting RF-objects into files.

For prediction, calculate the prediction of each of the 5 objects and
aggregate them. This requires some simple lines of code but will help to
circumvent RAM restrictions.

Best,

Torsten

> P.S.
> It's possible calculate approximate the
> memory demand for different settings with RF?
>
> Many thanks & regards,
> Christian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From tluediger at gmx.de  Tue Nov 25 13:10:03 2003
From: tluediger at gmx.de (=?iso-8859-1?Q?Tobias_L=FCdiger?=)
Date: Tue, 25 Nov 2003 13:10:03 +0100
Subject: [R] Coxian-Distribution
Message-ID: <009601c3b34d$0ef07840$0b2fa8c0@Arbeitsgruppe>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031125/cbac87e1/attachment.pl

From v.demart at libero.it  Tue Nov 25 13:38:46 2003
From: v.demart at libero.it (v.demart@libero.it)
Date: Tue, 25 Nov 2003 13:38:46 +0100
Subject: [R] Something broken with update?
Message-ID: <HOWR4M$E175318879CAAD97C03DEE559BF1B7AC@libero.it>

Updating my 1.8.0 R installation (>update.packages() ) I obtain the following
(SORRY FOR THE LENGTH OF THE LOG BUT IT HELPS!!!):

................
downloaded 135Kb

KernSmooth :
 Version 2.22-11 in /usr/lib/R/library 
 Version 2.22-12 on CRAN
Update (y/N)?  y
mgcv :
 Version 0.9-3.1 in /usr/lib/R/library 
 Version 0.9-6 on CRAN
Update (y/N)?  y
trying URL `http://cran.r-project.org/src/contrib/KernSmooth_2.22-12.tar.gz'
Content type `application/x-tar' length 24752 bytes
opened URL
.......... .......... ....
downloaded 24Kb

trying URL `http://cran.r-project.org/src/contrib/mgcv_0.9-6.tar.gz'
Content type `application/x-tar' length 181022 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... ......
downloaded 176Kb

* Installing *source* package 'KernSmooth' ...
** libs
g77 -mieee-fp  -fPIC  -g -O2 -c blkest.f -o blkest.o
g77 -mieee-fp  -fPIC  -g -O2 -c cp.f -o cp.o
g77 -mieee-fp  -fPIC  -g -O2 -c dgedi.f -o dgedi.o
g77 -mieee-fp  -fPIC  -g -O2 -c dgefa.f -o dgefa.o
g77 -mieee-fp  -fPIC  -g -O2 -c dgesl.f -o dgesl.o
g77 -mieee-fp  -fPIC  -g -O2 -c linbin2D.f -o linbin2D.o
g77 -mieee-fp  -fPIC  -g -O2 -c linbin.f -o linbin.o
g77 -mieee-fp  -fPIC  -g -O2 -c locpoly.f -o locpoly.o
g77 -mieee-fp  -fPIC  -g -O2 -c rlbin.f -o rlbin.o
g77 -mieee-fp  -fPIC  -g -O2 -c sdiag.f -o sdiag.o
g77 -mieee-fp  -fPIC  -g -O2 -c sstdiag.f -o sstdiag.o
gcc -shared  -o KernSmooth.so blkest.o cp.o dgedi.o dgefa.o dgesl.o linbin2D.o
linbin.o locpoly.o rlbin.o sdiag.o sstdiag.o -lf77blas -latlas
-L/usr/lib/gcc-lib/i486-linux/3.3.2 -L/usr/lib/gcc-lib/i486-linux/3.3.2/../../..
-lfrtbegin -lg2c-pic -lm -lgcc_s -L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lf77blas
collect2: ld returned 1 exit status
make: *** [KernSmooth.so] Error 1
ERROR: compilation failed for package 'KernSmooth'
** Removing '/usr/lib/R/library/KernSmooth'
** Restoring previous '/usr/lib/R/library/KernSmooth'
* Installing *source* package 'mgcv' ...
** libs
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c gcv.c
-o gcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
magic.c -o magic.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c mat.c
-o mat.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
matrix.c -o matrix.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
mgcv.c -o mgcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c qp.c
-o qp.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
tprs.c -o tprs.o
gcc -shared  -o mgcv.so gcv.o magic.o mat.o matrix.o mgcv.o qp.o tprs.o
-L/usr/lib/R/bin -lRlapack -lf77blas -latlas -L/usr/lib/gcc-lib/i486-linux/3.3.2
-L/usr/lib/gcc-lib/i486-linux/3.3.2/../../.. -lfrtbegin -lg2c-pic -lm -lgcc_s 
-L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lf77blas
collect2: ld returned 1 exit status
make: *** [mgcv.so] Error 1
ERROR: compilation failed for package 'mgcv'
** Removing '/usr/lib/R/library/mgcv'
** Restoring previous '/usr/lib/R/library/mgcv'

Delete downloaded files (y/N)? y

Warning messages: 
1: Installation of package KernSmooth had non-zero exit status in:
install.packages(update[, "Package"], instlib, contriburl = contriburl,  
2: Installation of package mgcv had non-zero exit status in:
install.packages(update[, "Package"], instlib, contriburl = contriburl,  
-----------------------------------------------------------------

What's going wrong with these two packages?

Please help

Ciao
Vittorio



From Roger.Bivand at nhh.no  Tue Nov 25 14:01:13 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 25 Nov 2003 14:01:13 +0100 (CET)
Subject: [R] Something broken with update?
In-Reply-To: <HOWR4M$E175318879CAAD97C03DEE559BF1B7AC@libero.it>
Message-ID: <Pine.LNX.4.44.0311251357390.15725-100000@reclus.nhh.no>

On Tue, 25 Nov 2003, v.demart at libero.it wrote:

I think you need to tell is specifically which platform you are using 
(output of version), and whether you installed R from source or a binary 
distribution. Most likely you are on a Unix or Linux platform, and 
installed a binary distribution, but are now updating *source* recommended 
packages. 


> Updating my 1.8.0 R installation (>update.packages() ) I obtain the following
> (SORRY FOR THE LENGTH OF THE LOG BUT IT HELPS!!!):
> 
> ................
> downloaded 135Kb
> 
> KernSmooth :
>  Version 2.22-11 in /usr/lib/R/library 
>  Version 2.22-12 on CRAN
> Update (y/N)?  y
> mgcv :
>  Version 0.9-3.1 in /usr/lib/R/library 
>  Version 0.9-6 on CRAN
> Update (y/N)?  y
> trying URL `http://cran.r-project.org/src/contrib/KernSmooth_2.22-12.tar.gz'
> Content type `application/x-tar' length 24752 bytes
> opened URL
> .......... .......... ....
> downloaded 24Kb
> 
> trying URL `http://cran.r-project.org/src/contrib/mgcv_0.9-6.tar.gz'
> Content type `application/x-tar' length 181022 bytes
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... ......
> downloaded 176Kb
> 
> * Installing *source* package 'KernSmooth' ...
> ** libs
> g77 -mieee-fp  -fPIC  -g -O2 -c blkest.f -o blkest.o
> g77 -mieee-fp  -fPIC  -g -O2 -c cp.f -o cp.o
> g77 -mieee-fp  -fPIC  -g -O2 -c dgedi.f -o dgedi.o
> g77 -mieee-fp  -fPIC  -g -O2 -c dgefa.f -o dgefa.o
> g77 -mieee-fp  -fPIC  -g -O2 -c dgesl.f -o dgesl.o
> g77 -mieee-fp  -fPIC  -g -O2 -c linbin2D.f -o linbin2D.o
> g77 -mieee-fp  -fPIC  -g -O2 -c linbin.f -o linbin.o
> g77 -mieee-fp  -fPIC  -g -O2 -c locpoly.f -o locpoly.o
> g77 -mieee-fp  -fPIC  -g -O2 -c rlbin.f -o rlbin.o
> g77 -mieee-fp  -fPIC  -g -O2 -c sdiag.f -o sdiag.o
> g77 -mieee-fp  -fPIC  -g -O2 -c sstdiag.f -o sstdiag.o
> gcc -shared  -o KernSmooth.so blkest.o cp.o dgedi.o dgefa.o dgesl.o linbin2D.o
> linbin.o locpoly.o rlbin.o sdiag.o sstdiag.o -lf77blas -latlas
> -L/usr/lib/gcc-lib/i486-linux/3.3.2 -L/usr/lib/gcc-lib/i486-linux/3.3.2/../../..
> -lfrtbegin -lg2c-pic -lm -lgcc_s -L/usr/lib/R/bin -lR
> /usr/bin/ld: cannot find -lf77blas
> collect2: ld returned 1 exit status
> make: *** [KernSmooth.so] Error 1
> ERROR: compilation failed for package 'KernSmooth'
> ** Removing '/usr/lib/R/library/KernSmooth'
> ** Restoring previous '/usr/lib/R/library/KernSmooth'
> * Installing *source* package 'mgcv' ...
> ** libs
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c gcv.c
> -o gcv.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
> magic.c -o magic.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c mat.c
> -o mat.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
> matrix.c -o matrix.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
> mgcv.c -o mgcv.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c qp.c
> -o qp.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c
> tprs.c -o tprs.o
> gcc -shared  -o mgcv.so gcv.o magic.o mat.o matrix.o mgcv.o qp.o tprs.o
> -L/usr/lib/R/bin -lRlapack -lf77blas -latlas -L/usr/lib/gcc-lib/i486-linux/3.3.2
> -L/usr/lib/gcc-lib/i486-linux/3.3.2/../../.. -lfrtbegin -lg2c-pic -lm -lgcc_s 
> -L/usr/lib/R/bin -lR
> /usr/bin/ld: cannot find -lf77blas
> collect2: ld returned 1 exit status
> make: *** [mgcv.so] Error 1
> ERROR: compilation failed for package 'mgcv'
> ** Removing '/usr/lib/R/library/mgcv'
> ** Restoring previous '/usr/lib/R/library/mgcv'
> 
> Delete downloaded files (y/N)? y
> 
> Warning messages: 
> 1: Installation of package KernSmooth had non-zero exit status in:
> install.packages(update[, "Package"], instlib, contriburl = contriburl,  
> 2: Installation of package mgcv had non-zero exit status in:
> install.packages(update[, "Package"], instlib, contriburl = contriburl,  
> -----------------------------------------------------------------
> 
> What's going wrong with these two packages?
> 
> Please help
> 
> Ciao
> Vittorio
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From michael.watson at bbsrc.ac.uk  Tue Nov 25 14:54:46 2003
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Tue, 25 Nov 2003 13:54:46 -0000
Subject: [R] Persistent state of R
Message-ID: <20B7EB075F2D4542AFFAF813E98ACD9302822442@cl-exsrv1.irad.bbsrc.ac.uk>

Hi

I am using R as a back-end to some CGI scripts, written in Perl.  My platform is Suse Linux 8.2, Apache 1.3.7.  So the CGI script takes some form parameters, opens a pipe to an R process, loads up some Bioconductor libraries, executes some R commands and takes the ouput and creates a web page.  It is all very neat and works well.

I am trying to make my cgi scripts quicker and it turns out that the bottle-neck is the loading of the libraries into R - for example loading up marrayPlots into R takes 10-20 seconds, which although not long, is long enough for users to imagine it is not working and start clicking reload....

So I just wondered if anyone had a neat solution whereby I could somehow have the required libraries permanently loaded into R - perhaps I need a persistent R process with the libraries in memory that I can pipe commands to?  Is this possible?

Thanks
Mick



From andy_liaw at merck.com  Tue Nov 25 14:56:28 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 25 Nov 2003 08:56:28 -0500
Subject: [R] RandomForest &  memory demand
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE8C@usrymx25.merck.com>

> From: Christian Schulz
> 
> Hi,
> 
> is it correct that i need  ~ 2GB RAM that it's
> possible to work with the default setting 
> ntree=500 and a data.frame with 100.000 rows 
> and max. 10 columns for training and testing?

If you have the test set, and don't need the forest for predicting other
data, you can give both training data and test data to randomForest() at the
same time (if that fits in memory).  This way there will only be one tree
kept in memory.  E.g., you would do something like:

my.result <- randomForest(x, y, xtest)

Then my.result$test will contain a list of results on the test set.  If you
also give ytest, there will be a bit more output.

If you follow Torsten's suggestion, you can use the combine() function to
merge the five forests into one.
 
> P.S.
> It's possible calculate approximate the
> memory demand for different settings with RF?

The current implementation of the code requires (assuming classification, no
test data, and proximity=FALSE) approximately:

At R level:
- One copy of the training data.
- 6*(2n+1)*ntree integers for storing the forest.

At C level (dynamically allocated):
- (2n + 37)*nclass + 9*n + p*(2+nclass) doubles.
- 5 + (3*p + 22)*n + 5*(p + nclass) integers.

(nclass is the number of classes, n the number of cases in training data, p
the number of variables.)

HTH,
Andy
 
> Many thanks & regards,
> Christian



From wantia at ifi.unizh.ch  Tue Nov 25 15:03:49 2003
From: wantia at ifi.unizh.ch (Jan Wantia)
Date: 25 Nov 2003 15:03:49 +0100
Subject: [R] plot mean + S.E. over time
Message-ID: <3FC36145.704@ifi.unizh.ch>

Hi, there!

I finally became a disciple of 'R', after having lost years of my life 
handling data with a popular, rather wide-spread spreadsheet-software.

Now I want to plot the results of many runs of my simulation over time, 
so that the means +/- Standard error are on the y-axis, and time on the 
x-axis.

I have tried 'boxplot', with timesteps as the grouping variable, but did 
not manage to replace quartils by S.E.
Then, with 'plot' I do not know how to handle the data of 100 runs for a 
given time to produce the mean and S.E.

Are there any suggestions? Any help would be appreciated!

Cheers, Jan

-- 

______________________________________________________

Jan Wantia
Dept. of Information Technology, University of Z?rich
Andreasstr. 15
CH 8050 Z?rich
Switzerland

Tel.:     +41 (0) 1 635 4315
Fax:     +41 (0) 1 635 45 07
email: wantia at ifi.unizh.ch



From andy_liaw at merck.com  Fri Nov 21 14:18:09 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 21 Nov 2003 08:18:09 -0500
Subject: [R] plot map of areas
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE6F@usrymx25.merck.com>

Is the contributed package `deldir' on CRAN what you're looking for?

HTH,
andy

> From: Pascal A. Niklaus [mailto:Pascal.Niklaus at unibas.ch] 
> Hi all,
> 
> Given a number of points (x,y) in a plane, I'd like to plot a map of 
> polygons, so that
> 
>     1) each polygon contains exactly one point
>     2) the polygon defines the area for which this specific point is 
> closer than any other point.
> 
> It's a bit like a map of areas "influenced" by that point, and it's 
> obviously a matter of intersecting the perpendicular 
> bisectors between 
> adjacent points.
> 
> I believe this type of map has a name, but I can't remember how it's 
> called.
> 
> Is there a function somewhere in a R package that may do this?
> 
> Thanks for your help
> 
> Pascal



From roger at ysidro.econ.uiuc.edu  Tue Nov 25 15:33:42 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Tue, 25 Nov 2003 08:33:42 -0600 (CST)
Subject: [R] plot map of areas
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE6F@usrymx25.merck.com>
Message-ID: <Pine.SOL.4.30.0311250833120.20121-100000@ysidro.econ.uiuc.edu>

or tripack perhaps...


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Fri, 21 Nov 2003, Liaw, Andy wrote:

> Is the contributed package `deldir' on CRAN what you're looking for?
>
> HTH,
> andy
>
> > From: Pascal A. Niklaus [mailto:Pascal.Niklaus at unibas.ch]
> > Hi all,
> >
> > Given a number of points (x,y) in a plane, I'd like to plot a map of
> > polygons, so that
> >
> >     1) each polygon contains exactly one point
> >     2) the polygon defines the area for which this specific point is
> > closer than any other point.
> >
> > It's a bit like a map of areas "influenced" by that point, and it's
> > obviously a matter of intersecting the perpendicular
> > bisectors between
> > adjacent points.
> >
> > I believe this type of map has a name, but I can't remember how it's
> > called.
> >
> > Is there a function somewhere in a R package that may do this?
> >
> > Thanks for your help
> >
> > Pascal
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From dj at research.bell-labs.com  Tue Nov 25 15:30:12 2003
From: dj at research.bell-labs.com (David James)
Date: Tue, 25 Nov 2003 09:30:12 -0500
Subject: [R] RMySQL valid field names
In-Reply-To: <200311241945.56603.ltorgo@liacc.up.pt>;
	from ltorgo@liacc.up.pt on Mon, Nov 24, 2003 at 07:45:56PM +0000
References: <200311241945.56603.ltorgo@liacc.up.pt>
Message-ID: <20031125093011.B729@jessie.research.bell-labs.com>

Luis,

Thanks for your thoughtful comments.  Indeed you've uncovered
a bug/problem in that there's no way for users to control the
"allow.keywords=" argument in calls to dbWriteTable() -- this
needs to be fixed.  Regarding the default value for allow.keywords,
I'm not sure it is wise to set it to TRUE by default (despite the 
fact that MySQL does not explicitly prohibit keywords as column names)
since problems can arise when MySQL runs in ANSI mode (see section
6.1.7 in the manual).  Perhaps the default value should depend
on whether MySQL is running in ANSI mode or not, I'll check whether
that's easy to determine from R at runtime.

Again, thanks for reporting the problem.

--
David

Luis Torgo wrote:
> I'm having some problems with valid field names when using RMySQL to interface 
> R (version 1.7.0, under RedHat9.0), to MySQL (4.1.0-alpha). I think I've 
> spotted the problem and a solution (which is working for me), but I wanted to 
> share this with you as I may be missing something.
> (Note: I'm aware that this is an old R version, but I've checked the code of 
> the lastest version of the RMySQL package at CRAN, and my comments still 
> apply).
> 
> I have a data frame which has among others three columns with names 
> ('DateTime', 'Open' and 'Close'). When I use dbWriteTable to dump the data 
> frame into a MySQL database everything works fine except the names of these 
> three columns which are slightly different (e.g. 'DateTime_9'). 
> 
> This only occurs with these 3 columns because their names are reserved words 
> of MySQL. The change of names is occurring in the function mysqlWriteTable, 
> namely in the call:
> ...
> names(field.types) <- make.db.names(con,names(field.types),allow.keywords=F)
> ...
> If I change the parameter allow.keywords into T, everything works fine for me. 
> Given that MySQL allows all characters to be part of field names (section 
> 6.1.2 of MySQL reference manual), I do not understand what is the reason for 
> calling make.db.names with this value of parameter allow.keywords.
> 
> In resume, my question is: Is there any reason for this that I am missing, or 
> the change I've done is pretty safe and could possibly be done in future 
> versions of the package?
> 
> Thank you for any help.
> Luis
> 
> -- 
> Luis Torgo
>     FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
>     Machine Learning Group           Fax   : (+351) 22 600 36 54
>     R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
>     4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636



From dj at research.bell-labs.com  Tue Nov 25 15:39:20 2003
From: dj at research.bell-labs.com (David James)
Date: Tue, 25 Nov 2003 09:39:20 -0500
Subject: [R] 1.8.1. RMySQL Win2K Writing-Table Problem?
In-Reply-To: <JAEELBHBOPKJDMMCNHKMOEKGCBAA.christian.schulz@questico.de>;
	from christian.schulz@questico.de on Tue, Nov 25, 2003 at
	11:29:04AM +0100
References: <JAEELBHBOPKJDMMCNHKMOEKGCBAA.christian.schulz@questico.de>
Message-ID: <20031125093920.C729@jessie.research.bell-labs.com>

Hi,

I think this is caused by changes to subscripting for data.frames 
made in 1.8.0 (grep "Subscripting" in the 1.8.0 NEWS file).  
I'll fix this in an RMySQL update I'm currently working on
(and soon to be available).

Regards,
--
David

Christian Schulz wrote:
> Hi,
> 
> i getting following error and don't know doing
> something wrong.
> 
> >mysqlWriteTable(con,"model1",model1,overwrite=T)
> Error in "[.data.frame"(value, from:to, drop = FALSE) :
>         undefined columns selected
> In addition: Warning message:
> drop argument will be ignored in: "[.data.frame"(value, from:to, drop =
> FALSE)
> 
> Exactly the same code, database and data
> works with 1.7.1 very nice!
> 
> Many thanks,
> Christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636



From Pascal.Niklaus at unibas.ch  Tue Nov 25 16:10:56 2003
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Tue, 25 Nov 2003 16:10:56 +0100
Subject: [R] R recursion depth and stack size
Message-ID: <3FC37100.6060000@unibas.ch>

Hi all,

I am playing around with latin squares, and wrote a recursive function 
that searches for valid combinations.
Apart from the fact that there are very many, I run into troubles 
beginning with size 10x10 because the recursion depth becomes too large 
(max of 10x9-1=89 in this case).

Why is this a problem? Isn't there enough space allocated to the stack? 
Can this be increased? The memory demand shouldn't be terrible, with 
only minimal local variables (only set and the function params r,c,t - s 
is local to a block called only once when a solution is found). Even if 
variables aren't stored efficiently, a recursion depth of 100 shouldn't 
consume more than a couple of kilobytes.

Is this a fundamental misunderstanding of the way R works?

Pascal

BTW: Is there a way to pass variables "by reference" in function calls?

------

The function stripped-down to the essential looks like this:

latin.square <- function(t = 4)
{
    latinCheck <- function(r,c,t)
    {
        set <- setdiff(LETTERS[1:t],c(m[r,],m[,c]));
        for(i in set)
        {
            m[r,c] <<- i;
            if(c<t)
            {
                latinCheck(r,c+1,t);
            }
            else
            {
                if(r<t)
                {
                    latinCheck(r+1,1,t);
                }
                else # found a solution
                {
                    s <- paste(m[1,],collapse="",sep="");;
                    for(i in 2:t)
                    {
                        s <- paste(c(s,"-",m[i,]),collapse="",sep="");
                    }
                    cat(s,"\n");
                }
            }
        }
        m[r,c] <<- NA;
    }

    latinSolutions <<- character(0);
    fullset <<- LETTERS[1:t];

    m <<- matrix(nrow=t,ncol=t);
    m[1,] <<- LETTERS[1:t];
    latinCheck(2,1,t)
}

l



From andy_liaw at merck.com  Thu Nov 20 00:10:22 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 19 Nov 2003 18:10:22 -0500
Subject: [R] Windows R 1.8.0 hangs when Mem Usage >1.8GB
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE61@usrymx25.merck.com>

With a custom compiled kernel, I've run R processes that used more than 5GB
of RAM on a Linux box with 8GB RAM and dual Xeons.  So it seems to work on
32-bit Linux with big memory kernel.

Andy


> From: Duncan Murdoch [mailto:dmurdoch at pair.com] 
[snip] 
> Normally the maximum memory allowed for any process in 
> Windows is 2 GB.  It's possible to raise that to 3 GB but R 
> 1.8 doesn't know how, so that's an absolute upper limit.  
> Version 1.9 may be able to go up to 3 GB, but beyond that 
> you'll probably need a 64 bit processor:  as far as I know 
> all the 32 bit OS's limit each process to 2 or 3 GB, because 
> they reserve 1 or 2 GB for themselves.
>
[snip]
 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From paradis at isem.univ-montp2.fr  Tue Nov 25 16:33:25 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Tue, 25 Nov 2003 16:33:25 +0100
Subject: [R] plot mean + S.E. over time
In-Reply-To: <3FC36145.704@ifi.unizh.ch>
Message-ID: <4.2.0.58.20031125163142.00365ca8@isem.isem.univ-montp2.fr>

See the function plotCI() in package gregmisc on CRAN.

EP

At 15:03 25/11/2003 +0100, vous avez ?crit:
>Hi, there!
>
>I finally became a disciple of 'R', after having lost years of my life 
>handling data with a popular, rather wide-spread spreadsheet-software.
>
>Now I want to plot the results of many runs of my simulation over time, so 
>that the means +/- Standard error are on the y-axis, and time on the x-axis.
>
>I have tried 'boxplot', with timesteps as the grouping variable, but did 
>not manage to replace quartils by S.E.
>Then, with 'plot' I do not know how to handle the data of 100 runs for a 
>given time to produce the mean and S.E.
>
>Are there any suggestions? Any help would be appreciated!
>
>Cheers, Jan
>
>--
>
>______________________________________________________
>
>Jan Wantia
>Dept. of Information Technology, University of Z?rich
>Andreasstr. 15
>CH 8050 Z?rich
>Switzerland
>
>Tel.:     +41 (0) 1 635 4315
>Fax:     +41 (0) 1 635 45 07
>email: wantia at ifi.unizh.ch
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gregory_r_warnes at groton.pfizer.com  Tue Nov 25 16:35:47 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue, 25 Nov 2003 10:35:47 -0500
Subject: [R] Persistent state of R
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AB4F@groexmb02.pfizer.com>


Starting up R and loading libraries can be very time consuming.  For my
RSOAP system (http://www.analytics.washington.edu/Zope/projects/RSOAP/)  I
took the step of pre-starting the R process, including the loading of some
libraries, and then handing work of to the pre-started process.  You should
be able to use RSOAP from perl, and it would be a simple change to have it
add the bioconductor packages to the pre-loaded set.

Alternatively, I suppose that one could force R to dump core and then start
it from the core image...

-G

-----Original Message-----
From: michael watson (IAH-C)
To: 'r-help at stat.math.ethz.ch'
Sent: 11/25/03 8:54 AM
Subject: [R] Persistent state of R

Hi

I am using R as a back-end to some CGI scripts, written in Perl.  My
platform is Suse Linux 8.2, Apache 1.3.7.  So the CGI script takes some
form parameters, opens a pipe to an R process, loads up some
Bioconductor libraries, executes some R commands and takes the ouput and
creates a web page.  It is all very neat and works well.

I am trying to make my cgi scripts quicker and it turns out that the
bottle-neck is the loading of the libraries into R - for example loading
up marrayPlots into R takes 10-20 seconds, which although not long, is
long enough for users to imagine it is not working and start clicking
reload....

So I just wondered if anyone had a neat solution whereby I could somehow
have the required libraries permanently loaded into R - perhaps I need a
persistent R process with the libraries in memory that I can pipe
commands to?  Is this possible?

Thanks
Mick

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From spencer.graves at pdf.com  Tue Nov 25 16:43:32 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 25 Nov 2003 07:43:32 -0800
Subject: [R] Parameter estimation in nls
In-Reply-To: <Pine.GSO.4.21.0311250903090.1533-100000@austin>
References: <Pine.GSO.4.21.0311250903090.1533-100000@austin>
Message-ID: <3FC378A4.3060307@pdf.com>

      Since x <- 1:26 and your y's are all positive, your model, 
ignoring the error term, is mathematically isomorphic to the following: 

 > x <- 1:26
 > (fit <- lm(y~x+log(x)))

Call:
lm(formula = y ~ x + log(x))

Coefficients:
(Intercept)            x       log(x) 
   35802074      -371008     -8222922 

      With reasonable starting values, I would expect "a" to converge to 
roughly exp(35802074), "k" to (-8222922), and "b" to exp(-371008).  With 
values of these magnitudes for "a" and "b", the "nls" optimization is 
highly ill conditioned. 

      What do these numbers represent?  By using "nls" you are assuming 
implicitly the following: 

      y = a*x^k*b^x + e, where the e's are independent normal errors 
with mean 0 and constant variance. 

      Meanwhile, the linear model I fit above assumes a different noise 
model: 

      log(y) = log(a) + k*log(x) + x*log(b) + e, where these e's are 
also independent normal, mean 0, constant variance. 

      If you have no preference for one noise model over the other, I 
suggest you use the linear model I estimated, declare victory and worry 
about something else.  If you insist on estimating the multiplicative 
model, you should start by dividing y by some number like 1e6 or 1e7 and 
consider reparameterizing the problem if that is not adequate.  Have you 
consulted a good book on nonlinear regression?  The two references cited 
in "?nls" are both excellent: 

       Bates, D.M. and Watts, D.G. (1988) _Nonlinear Regression Analysis
     and Its Applications_, Wiley

     Bates, D. M. and Chambers, J. M. (1992) _Nonlinear models._
     Chapter 10 of _Statistical Models in S_ eds J. M. Chambers and T.
     J. Hastie, Wadsworth & Brooks/Cole.

hope this helps.  spencer graves

Dr Andrew Wilson wrote:

>I am trying to fit a rank-frequency distribution with 3 unknowns (a, b
>and k) to a set of data.
>
>This is my data set:
>
>y <- c(37047647,27083970,23944887,22536157,20133224,
>20088720,18774883,18415648,17103717,13580739,12350767,
>8682289,7496355,7248810,7022120,6396495,6262477,6005496,
>5065887,4594147,2853307,2745322,454572,448397,275136,268771)
>
>and this is the fit I'm trying to do:
>
>nlsfit <- nls(y ~ a * x^k * b^x, start=list(a=5,k=1,b=3))
>
>(It's a Yule distribution.)
>
>However, I keep getting:
>
>"Error in nls(y ~ a * x^k * b^x, start = list(a = 5, k = 1, b = 3)) : 
>singular gradient"
>
>I guess this has something to do with the parameter start values.
>
>I was wondering, is there a fully automated way of estimating parameters
>which doesn't need start values close to the final estimates?  I know
>other programs do it, so is it possible in R?
>
>Thanks,
>Andrew Wilson
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From ahenningsen at agric-econ.uni-kiel.de  Tue Nov 25 16:57:04 2003
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Tue, 25 Nov 2003 16:57:04 +0100
Subject: [R] best editor for .R files
In-Reply-To: <Sea2-DAV15zxDPHprp500000eae@hotmail.com>
References: <Sea2-DAV15zxDPHprp500000eae@hotmail.com>
Message-ID: <200311251657.04406.ahenningsen@agric-econ.uni-kiel.de>

Hi Angel and * !

I also use kate and in my opinion it is very convenient. I don't know which 
features you don't like, but if you mean some syntax highlighting "features", 
you might try my R syntax highlighting (XML) file for kate. It is based on 
Egon Willighagen's one and contains a few bug fixes and several extensions. 
You can download it from my homepage (http://www.uni-kiel.de/agrarpol/
ahenningsen/, the link is at the bottom of the page). 
This new file is NOT thoroughly tested so far. After testing it for some time, 
I will send it to CRAN and to kate.kde.org as an update of Egon's file, since 
Egon stopped maintaining it. 

Best wishes,
Arne


On Thursday 20 November 2003 22:27, Angel wrote:
> Which is the best editor for .R files?
>
> I currently use kate on my linux as it has R highlighting and allows me to
> split the window into two: in one I edit the .R file and in the other I
> have a shell so I run R and can easily  copy and paste the code. There are
> some features that I don't like and I am having a look on some
> alternatives. I've heard wonders of emacs with ess but I am a little bit
> frightened of the steep learning curve.
>
> What do the R experts use or would recommend using?
> Both linux and/or windows alternatives are welcomed.
> I guess it would much depend on the particular needs/preferences of each
> user but I would like to know which are the most commonly used editors.
> Thanks,
> Angel
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From spencer.graves at pdf.com  Tue Nov 25 17:10:25 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 25 Nov 2003 08:10:25 -0800
Subject: [R] Parameter estimation in nls
In-Reply-To: <Pine.GSO.4.21.0311250903090.1533-100000@austin>
References: <Pine.GSO.4.21.0311250903090.1533-100000@austin>
Message-ID: <3FC37EF1.8080206@pdf.com>

	  If the numbers are letter frequencies, I would suggest Poisson 
regression using "glm"  the default link is logarithms, and that should 
work quite well for you.

	  hope this helps.  spencer graves

###################################
Very many thanks for your help.


 >> What do these numbers represent?


They are letter frequencies arranged in rank order.  (A very big sample
that I got off the web for testing, but my own data - rank frequencies of
various linguistic entities, including letter frequencies - are likely to
be similar.)

Basically, I am testing the goodness of fit of three or four equations:

- the one I posted (Yule's equation)
- Zipf's equation (y = a * b^x, if I remember rightly, but the paper's at
home, so I may be wrong...)
- a parameter-free equation

Regards,
Andrew Wilson

####################################
      Since x <- 1:26 and your y's are all positive, your model,
ignoring the error term, is mathematically isomorphic to the following:

> x <- 1:26
> (fit <- lm(y~x+log(x)))

Call:
lm(formula = y ~ x + log(x))

Coefficients:
(Intercept)            x       log(x)
   35802074      -371008     -8222922

      With reasonable starting values, I would expect "a" to converge to
roughly exp(35802074), "k" to (-8222922), and "b" to exp(-371008).  With
values of these magnitudes for "a" and "b", the "nls" optimization is
highly ill conditioned.

      What do these numbers represent?  By using "nls" you are assuming
implicitly the following:

      y = a*x^k*b^x + e, where the e's are independent normal errors
with mean 0 and constant variance.

      Meanwhile, the linear model I fit above assumes a different noise
model:

      log(y) = log(a) + k*log(x) + x*log(b) + e, where these e's are
also independent normal, mean 0, constant variance.

      If you have no preference for one noise model over the other, I
suggest you use the linear model I estimated, declare victory and worry
about something else.  If you insist on estimating the multiplicative
model, you should start by dividing y by some number like 1e6 or 1e7 and
consider reparameterizing the problem if that is not adequate.  Have you
consulted a good book on nonlinear regression?  The two references cited
in "?nls" are both excellent:

       Bates, D.M. and Watts, D.G. (1988) _Nonlinear Regression Analysis
     and Its Applications_, Wiley

     Bates, D. M. and Chambers, J. M. (1992) _Nonlinear models._
     Chapter 10 of _Statistical Models in S_ eds J. M. Chambers and T.
     J. Hastie, Wadsworth & Brooks/Cole.

hope this helps.  spencer graves

Dr Andrew Wilson wrote:

>I am trying to fit a rank-frequency distribution with 3 unknowns (a, b
>and k) to a set of data.
>
>This is my data set:
>
>y <- c(37047647,27083970,23944887,22536157,20133224,
>20088720,18774883,18415648,17103717,13580739,12350767,
>8682289,7496355,7248810,7022120,6396495,6262477,6005496,
>5065887,4594147,2853307,2745322,454572,448397,275136,268771)
>
>and this is the fit I'm trying to do:
>
>nlsfit <- nls(y ~ a * x^k * b^x, start=list(a=5,k=1,b=3))
>
>(It's a Yule distribution.)
>
>However, I keep getting:
>
>"Error in nls(y ~ a * x^k * b^x, start = list(a = 5, k = 1, b = 3)) : 
>singular gradient"
>
>I guess this has something to do with the parameter start values.
>
>I was wondering, is there a fully automated way of estimating parameters
>which doesn't need start values close to the final estimates?  I know
>other programs do it, so is it possible in R?
>
>Thanks,
>Andrew Wilson
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From ripley at stats.ox.ac.uk  Tue Nov 25 17:09:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Nov 2003 16:09:39 +0000 (GMT)
Subject: [R] R recursion depth and stack size
In-Reply-To: <3FC37100.6060000@unibas.ch>
Message-ID: <Pine.LNX.4.44.0311251558140.6668-100000@gannet.stats>

Perhaps you could take the trouble to read the error message, which is

   Error in inherits(x, "factor") : evaluation is nested too deeply: 
   infinite recursion?

The evaluation depth is controlled by options(expressions=).  Increasing
it allows your code to run, albeit very slowly.

On Tue, 25 Nov 2003, Pascal A. Niklaus wrote:

> Hi all,
> 
> I am playing around with latin squares, and wrote a recursive function 
> that searches for valid combinations.
> Apart from the fact that there are very many, I run into troubles 
> beginning with size 10x10 because the recursion depth becomes too large 
> (max of 10x9-1=89 in this case).
> 
> Why is this a problem? Isn't there enough space allocated to the stack? 

It is space for expressions.  This is a safety check to avoid infinite
recursion overrunning the C-level stack and crashing R (and thereby losing
all the current work).  There is no portable way to check the C stack size
and usage that we know of.

> Can this be increased? The memory demand shouldn't be terrible, with 
> only minimal local variables (only set and the function params r,c,t - s 
> is local to a block called only once when a solution is found). Even if 
> variables aren't stored efficiently, a recursion depth of 100 shouldn't 
> consume more than a couple of kilobytes.

Why `shouldn't' it?  Have you any idea of the storage requirements of R 
objects?

> Is this a fundamental misunderstanding of the way R works?

It is a misreading of a simple message, for sure.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bill.shipley at usherbrooke.ca  Tue Nov 25 17:10:08 2003
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Tue, 25 Nov 2003 11:10:08 -0500
Subject: [R] using pdMAT in the lme function?
Message-ID: <006e01c3b36e$9897de50$8d1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031125/2ba7775d/attachment.pl

From maechler at stat.math.ethz.ch  Tue Nov 25 17:16:24 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Nov 2003 17:16:24 +0100
Subject: [R] R recursion depth and stack size
In-Reply-To: <3FC37100.6060000@unibas.ch>
References: <3FC37100.6060000@unibas.ch>
Message-ID: <16323.32856.524524.363214@gargle.gargle.HOWL>

>>>>> "Pascal" == Pascal A Niklaus <Pascal.Niklaus at unibas.ch>
>>>>>     on Tue, 25 Nov 2003 16:10:56 +0100 writes:

    Pascal> Hi all, I am playing around with latin squares, and
    Pascal> wrote a recursive function that searches for valid
    Pascal> combinations.  Apart from the fact that there are
    Pascal> very many, I run into troubles beginning with size
    Pascal> 10x10 because the recursion depth becomes too large
    Pascal> (max of 10x9-1=89 in this case).

    Pascal> Why is this a problem? Isn't there enough space
    Pascal> allocated to the stack?  Can this be increased? The
    Pascal> memory demand shouldn't be terrible, with only
    Pascal> minimal local variables (only set and the function
    Pascal> params r,c,t - s is local to a block called only
    Pascal> once when a solution is found). Even if variables
    Pascal> aren't stored efficiently, a recursion depth of 100
    Pascal> shouldn't consume more than a couple of kilobytes.

    Pascal> Is this a fundamental misunderstanding of the way R
    Pascal> works?

a slight one, at least: The recursion depth is limited by
options(expressions = ...), i.e.  getOption("expressions")  which
is 500 by default.

We've had similar problem when drawing a somewhat large dendrogram
(of less than 10000 end nodes still).

I think we should consider increasing the *default* maximal
recursion depth (from 500 to a few thousands) and
even think about increasing the maximally allowed value for
'expressions' (which is 100000).

Martin



From Timur.Elzhov at jinr.ru  Tue Nov 25 17:17:41 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue, 25 Nov 2003 19:17:41 +0300
Subject: [R] R comparison
In-Reply-To: <BAY9-F17KbiYMRBvt010000740b@hotmail.com>
References: <BAY9-F17KbiYMRBvt010000740b@hotmail.com>
Message-ID: <20031125161741.GA1503@nf034.jinr.ru>

On Sun, Nov 23, 2003 at 11:38:05AM +0000, Florian Roedhammer wrote:

>    I would need information concerning the features of R such as
>    static/dynamic typing, method overlapping, object oriontation,
>    
>    My question is whether you know  any site where such features are
>    discussed on or if you could help me directly.
Have you had a look at http://cran.r-project.org/doc/manuals/R-lang.pdf ?

--
WBR,
Timur



From feh3k at spamcop.net  Tue Nov 25 15:27:46 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 25 Nov 2003 09:27:46 -0500
Subject: [R] plot mean + S.E. over time
In-Reply-To: <3FC36145.704@ifi.unizh.ch>
References: <3FC36145.704@ifi.unizh.ch>
Message-ID: <20031125092746.0b818f6a.feh3k@spamcop.net>

On 25 Nov 2003 15:03:49 +0100
"Jan Wantia" <wantia at ifi.unizh.ch> wrote:

> Hi, there!
> 
> I finally became a disciple of 'R', after having lost years of my life 
> handling data with a popular, rather wide-spread spreadsheet-software.
> 
> Now I want to plot the results of many runs of my simulation over time, 
> so that the means +/- Standard error are on the y-axis, and time on the 
> x-axis.
> 
> I have tried 'boxplot', with timesteps as the grouping variable, but did
> 
> not manage to replace quartils by S.E.
> Then, with 'plot' I do not know how to handle the data of 100 runs for a
> 
> given time to produce the mean and S.E.
> 
> Are there any suggestions? Any help would be appreciated!
> 
> Cheers, Jan
> 
> -- 
> 
> ______________________________________________________
> 
> Jan Wantia
> Dept. of Information Technology, University of Z?rich
> Andreasstr. 15
> CH 8050 Z?rich
> Switzerland
> 

You might look at the xYplot function in the Hmisc package.
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From apjaworski at mmm.com  Tue Nov 25 17:39:21 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue, 25 Nov 2003 10:39:21 -0600
Subject: [R] Parameter estimation in nls
Message-ID: <OF3EE0A00A.5CEE6BD5-ON86256DE9.00578E0E-86256DE9.005B7EAB@mmm.com>


Your starting values for the parameters are no even in the general
ballpark.  Here is what I got for the final fit:

Parameters:
    Estimate Std. Error t value Pr(>|t|)
a  3.806e+07  1.732e+06  21.971   <2e-16 ***
k -3.391e-02  6.903e-02  -0.491    0.628
b  9.000e-01  1.240e-02  72.612   <2e-16 ***

As you can see only b has the same order of magnitude as your starting b
and a is different by 7 orders!

In general, an nls procedure needs starting values that are "close".  The
same is true for any general nonlinear optimization algorithm.  Only in
special circumstances a nonlinear algorithm will converge from any starting
point - one I know of is the convexity of the objective function.

I do not think there is any nls program that will find starting values
automatically for an arbitrary nonlinear model.  It is possible for
specific models, but is very much model dependent.  Your model, for
example, can be easily linearized by taking logs of both sides, i.e.

mm <- lm(log(y) ~ x + I(log(x)))

Then doing

aa <- exp(coef(mm)[1])
bb <- exp(coef(mm)[2])
kk <- coef(mm)[3]
mm1 <- nls(y ~ a * x^k * b^x, start=list(a=aa,k=kk,b=bb))

results in convergence with no problems in 7 iterations.

Hope this helps,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           Dr Andrew Wilson     |
|         |           <eia018 at comp.lancs.ac|
|         |           .uk>                 |
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           11/25/2003 03:09     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       r-help at stat.math.ethz.ch                                                                                     |
  |      cc:                                                                                                                    |
  |      Subject:  [R] Parameter estimation in nls                                                                              |
  >-----------------------------------------------------------------------------------------------------------------------------|




I am trying to fit a rank-frequency distribution with 3 unknowns (a, b
and k) to a set of data.

This is my data set:

y <- c(37047647,27083970,23944887,22536157,20133224,
20088720,18774883,18415648,17103717,13580739,12350767,
8682289,7496355,7248810,7022120,6396495,6262477,6005496,
5065887,4594147,2853307,2745322,454572,448397,275136,268771)

and this is the fit I'm trying to do:

nlsfit <- nls(y ~ a * x^k * b^x, start=list(a=5,k=1,b=3))

(It's a Yule distribution.)

However, I keep getting:

"Error in nls(y ~ a * x^k * b^x, start = list(a = 5, k = 1, b = 3)) :
singular gradient"

I guess this has something to do with the parameter start values.

I was wondering, is there a fully automated way of estimating parameters
which doesn't need start values close to the final estimates?  I know
other programs do it, so is it possible in R?

Thanks,
Andrew Wilson

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From luke at stat.uiowa.edu  Tue Nov 25 18:00:36 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 25 Nov 2003 11:00:36 -0600 (CST)
Subject: [R] Persistent state of R
In-Reply-To: <20B7EB075F2D4542AFFAF813E98ACD9302822442@cl-exsrv1.irad.bbsrc.ac.uk>
Message-ID: <Pine.LNX.4.44.0311251032490.20728-100000@itasca.stat.uiowa.edu>

On Tue, 25 Nov 2003, michael watson (IAH-C) wrote:

> Hi
> 
> I am using R as a back-end to some CGI scripts, written in Perl.  My platform is Suse Linux 8.2, Apache 1.3.7.  So the CGI script takes some form parameters, opens a pipe to an R process, loads up some Bioconductor libraries, executes some R commands and takes the ouput and creates a web page.  It is all very neat and works well.
> 
> I am trying to make my cgi scripts quicker and it turns out that the bottle-neck is the loading of the libraries into R - for example loading up marrayPlots into R takes 10-20 seconds, which although not long, is long enough for users to imagine it is not working and start clicking reload....
> 
> So I just wondered if anyone had a neat solution whereby I could somehow have the required libraries permanently loaded into R - perhaps I need a persistent R process with the libraries in memory that I can pipe commands to?  Is this possible?
> 
> Thanks
> Mick

One option we have been experimenting with is to process the contents
of packages into a simple data base and then use "lazy loading".  This
means that loading a package will load only a small amount of
information, basically the names of the variables defined.  The actual
values are only loaded from the data base on demand.  An experimental
package that implements this is available at

	http://www.stat.uiowa.edu/~luke/R/serialize/lazyload.tar.gz

I believe `make check-all' passes with all base and recommended
packages set up for lazy loading.  Lazy laoding has not been tested
much with packages using S4 methods or with anything in Bioconductor
as far as I know.  So this may or may not do anything useful for you.

[WARNING: Since this messes with the installed packages in your R
system you should only experiment with it in an R installation you can
afford to mess up.]

The README file from the package is attached below.

Best,

luke

------------------------------------(README)-----------------------------------
This package provides tools to set up packages for lazy loading from a
data base.  If you want to try this out, here are the steps:

1) Install the current version of package lazyload from
http://www.stat.uiowa.edu/~luke/R/serialize/.

2) To make base use lazy loading, start R with something like

	env R_DEFAULT_PACKAGES=NULL R

to make sure no packages are loaded.  Then do

	source(file.path(.find.package("lazyload"),"makebasedb.R"))
	library(lazyload)
	makeLazyLoading("base")

Make sure to do the source first, then the library call.

3) To make package foo use lazy loading use makeLazyLoading("foo").
You can make all base packages use lazy loading with

for (p in rev(installed.packages(priority="base")[,"Package"])) {
    cat(paste("converting", p, "..."))
    makeLazyLoading(p)
    cat("done\n")
}

The rev() is a quick and dirty way to get stepfun done before modreg,
since modreg imports from stepfun.


-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From bates at stat.wisc.edu  Tue Nov 25 18:16:58 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 25 Nov 2003 11:16:58 -0600
Subject: [R] using pdMAT in the lme function?
In-Reply-To: <006e01c3b36e$9897de50$8d1ad284@BIO041>
References: <006e01c3b36e$9897de50$8d1ad284@BIO041>
Message-ID: <6rsmkc9xmd.fsf@bates4.stat.wisc.edu>

"Bill Shipley" <bill.shipley at usherbrooke.ca> writes:

> Hello.  I want to specify a diagonal structure for the covariance matrix
> of random effects in the lme() function.
> 
> Here is the call before I specify a diagonal structure:
> > fit2<-lme(Ln.rgr~I(Ln.nar-log(0.0011)),data=meta.analysis,
> 
> + random=~1+I(Ln.nar-log(0.0011)|STUDY.CODE,na.action=na.omit)
> 
>  
> 
> and this works fine.  Now, I want to fix the covariance between the
> between-groups slopes and intercepts to zero.  I try do do this using
> the pdDiag command as follows, but it does not work:
> 
>  
> 
> > fit2<-lme(Ln.rgr~I(Ln.nar-log(0.0011)),data=meta.analysis,
> 
> +
> random=pdDiag(diag(2),~1+I(Ln.nar-log(0.0011))|STUDY.CODE),na.action=na.
> omit)

Try random=list(STUDY.CODE=pdDiag(~1+I(Ln.nar-log(0.0011))))



From matthew_wiener at merck.com  Mon Nov 24 17:10:42 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Mon, 24 Nov 2003 11:10:42 -0500
Subject: [R] Questions on Random Forest
Message-ID: <AEBD81486231A343B1813FE62D3352250369A66B@usrymx15.merck.com>

It looks like image_and_label has only 2 columns, so when you take
img_and_label[,2] you have a vector left.  Even if that weren't the case,
you're going to need to pass in both the gray scale points and labels,
presumably in a data frame.  You've created a character matrix below, so
you're just passing in a character vector of labels.

You'll probably want something like 
rf <- randomForest(label~image,data=image_and_label,importance=TRUE,
proximity=TRUE),

assuming that image_and_label is a data frame with elements image and label.


For the second question, see the documentation for the predict method for
random forests; for the third, the answer is yes, random forests can be used
with multiple variables.

There is an introduction to the random forests package in volume 2, issue 3
of the R newsletter (available in the documentation section of cran).

Hope this helps,

Matt Wiener

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fucang Jia
Sent: Monday, November 24, 2003 10:31 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Questions on Random Forest


Hi, everyone,

I am a newbie on R. Now I want to do image pixel classification by random 
forest. But I has not a clear understanding on random forest. Here is some 
question:

As for an image, for example its size is 512x512 and has only one variable 
-- gray level. The histogram of the image looks like mixture Gaussian Model,

say Gauss distribution (u1,sigma1), (u2,sigma2),(u3,sigma3). And a image 
classified by K-means or EM algorithm, so the class label image is also 
512x512 and has 0, 1, 2 value.

I read the binary image data as follows:

datafile <- file("bone.img","rb")
img <- readBin(datafile,size=2,what="integer",n=512*512,signed=FALSE)
img <- as.matrix(img)
close(datafile)

labelfile <- file(label.img","rb")
label <- readBin(labelfile,size=2,what="integer",n=512*512,signed=FALSE)
label <- as.matrix(label)
close(labelfile)

img_and_label <- c(img,label)  // binds the image data and class label
img_and_label <- as.matrix(img_and_label)
img_and_label <- array(img_and_label, dim=c(262144,2))


Random Forest need a class label like "Species" in the  iris. I do not know 
how
to set a class label like "Species" to the img.  So I run the command as 
follows:

set.seed(166)
rf <- randomForest(img_and_label[,2],data=image_and_label,importance=TRUE,
proximity=TRUE)

which outputs:

Error in if (n == 0) stop("data (x) has 0 rows") :
        argument is of length zero

Could anyone tell what is wrong and how can do the RF?

Secondly, if there is an new image , say img3 (dimension is 512x512,too), 
how can I
use the former result to classifify the new image?

Thirdly, whether or not random forest be used well if there is only one 
variable, say pixel
gray level, or three variables, such as red, green, blue color component to 
an true color
image?

Thank you very much!

Best,

Fucang

========================================
Fucang Jia, Ph.D student
Institute of Computing Technology, Chinese Academy of Sciences
Post.Box 2704
Beijing, 100080
P.R.China
E-mail:fcjia at ict.ac.cn

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Mon Nov 24 17:34:14 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 24 Nov 2003 11:34:14 -0500
Subject: [R] Questions on Random Forest
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE88@usrymx25.merck.com>

It's not clear to me what you want to do, but if I understand your problem
somewhat, I don't see how randomForest would be relevant.

Sounds like you are doing the following:

o  Read in a 512x512 image with pixel intensities.
o  You somehow fit a 3-component normal mixture model to the intensity data,
and have labels for which component the pixels belong to.
o  You want to be able to "fit" (or "predict") other images to the
3-component mixture model you have; i.e., create the "label" data given an
image.

If that's about right, I don't see why you would need some learning
algorithm such as randomForest.  You should be able to compute the
likelihood that a pixel belong to each of the 3 components in the mixture
model, based on the fitted parameters of that model.  The simplest I can
think of, ignoring the mixing proportions, is to simply compute the absolute
Z scores of a pixel with respect to the three components: z1 =
abs((x-u1)/sigma1), z2 = abs((x-u2)/sigma2), z2 = abs((x-u3)/sigma3), and
assign the pixel to the component with the largest absolute z-score.

HTH,
Andy

> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fucang Jia
> 
> Hi, everyone,
> 
> I am a newbie on R. Now I want to do image pixel 
> classification by random 
> forest. But I has not a clear understanding on random forest. 
> Here is some 
> question:
> 
> As for an image, for example its size is 512x512 and has only 
> one variable 
> -- gray level. The histogram of the image looks like mixture 
> Gaussian Model, 
> say Gauss distribution (u1,sigma1), (u2,sigma2),(u3,sigma3). 
> And a image 
> classified by K-means or EM algorithm, so the class label 
> image is also 
> 512x512 and has 0, 1, 2 value.
> 
> I read the binary image data as follows:
> 
> datafile <- file("bone.img","rb")
> img <- readBin(datafile,size=2,what="integer",n=512*512,signed=FALSE)
> img <- as.matrix(img)
> close(datafile)
> 
> labelfile <- file(label.img","rb")
> label <- 
> readBin(labelfile,size=2,what="integer",n=512*512,signed=FALSE)
> label <- as.matrix(label)
> close(labelfile)
> 
> img_and_label <- c(img,label)  // binds the image data and class label
> img_and_label <- as.matrix(img_and_label)
> img_and_label <- array(img_and_label, dim=c(262144,2))
> 
> 
> Random Forest need a class label like "Species" in the  iris. 
> I do not know 
> how
> to set a class label like "Species" to the img.  So I run the 
> command as 
> follows:
> 
> set.seed(166)
> rf <- 
> randomForest(img_and_label[,2],data=image_and_label,importance=TRUE,
> proximity=TRUE)
> 
> which outputs:
> 
> Error in if (n == 0) stop("data (x) has 0 rows") :
>         argument is of length zero
> 
> Could anyone tell what is wrong and how can do the RF?
> 
> Secondly, if there is an new image , say img3 (dimension is 
> 512x512,too), 
> how can I
> use the former result to classifify the new image?
> 
> Thirdly, whether or not random forest be used well if there 
> is only one 
> variable, say pixel
> gray level, or three variables, such as red, green, blue 
> color component to 
> an true color
> image?
> 
> Thank you very much!
> 
> Best,
> 
> Fucang
> 
> ========================================
> Fucang Jia, Ph.D student
> Institute of Computing Technology, Chinese Academy of Sciences
> Post.Box 2704
> Beijing, 100080
> P.R.China
> E-mail:fcjia at ict.ac.cn
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ryszard.czerminski at pharma.novartis.com  Tue Nov 25 19:34:28 2003
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Tue, 25 Nov 2003 13:34:28 -0500
Subject: [R] plotting to postscript: how to control line width ?
Message-ID: <OF2E115A9B.F41A8866-ON85256DE9.006347A0-85256DE9.00662082@EU.novartis.net>

How to control line width ?

if I do:

> postscript("IC50-density.eps", width = 4.0, height = 3.0, horizontal = 
FALSE, onefile = FALSE, paper = "special", title = "IC50 distribution")
> plot(d$x, d$y, xlab = "-log10(IC50)", ylab = "density")
> lines(d$x, d$y, lwd = 0.1)
> dev.off()

but whatever value I give for ldw parameter (e.g. 0.1 or 10) I am getting 
the same line width ?!



From andy_liaw at merck.com  Tue Nov 25 20:05:30 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 25 Nov 2003 14:05:30 -0500
Subject: [R] Windows R 1.8.0 hangs when Mem Usage >1.8GB
Message-ID: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>

Sorry.  I need to retract my claim.  There seems to be a 3G limit, even
though the OS could handle nearly 8G.  (I can have two simultaneous R
processes each using near 3G.)

On another note, on our dual Opteron box R (compiled as 64-bit) could easily
use nearly all the 16G in that box (that's one of the reason for having that
box).

Cheers,
Andy

> From: Paul Gilbert [mailto:pgilbert at bank-banque-canada.ca] 
> 
> Liaw, Andy wrote:
> > With a custom compiled kernel, I've run R processes that 
> used more than 5GB
> > of RAM on a Linux box with 8GB RAM and dual Xeons.  So it 
> seems to work on
> > 32-bit Linux with big memory kernel.
> > 
> > Andy
> 
> I'm curious about this. I believe the address space limit of a 32-bit 
> processor is 4G, and I thought Xeons were 32-bit processors. 
> How can a 
> single process exceed the address space?
> 
> Thanks,
> Paul Gilbert
> > 
> > 
> > 
> >>From: Duncan Murdoch [mailto:dmurdoch at pair.com] 
> > 
> > [snip] 
> > 
> >>Normally the maximum memory allowed for any process in 
> >>Windows is 2 GB.  It's possible to raise that to 3 GB but R 
> >>1.8 doesn't know how, so that's an absolute upper limit.  
> >>Version 1.9 may be able to go up to 3 GB, but beyond that 
> >>you'll probably need a 64 bit processor:  as far as I know 
> >>all the 32 bit OS's limit each process to 2 or 3 GB, because 
> >>they reserve 1 or 2 GB for themselves.
> >>
> > 
> > [snip]
> >  
> > 
> >>Duncan Murdoch
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list 
> >>https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
>



From ryszard.czerminski at pharma.novartis.com  Tue Nov 25 20:42:50 2003
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Tue, 25 Nov 2003 14:42:50 -0500
Subject: [R] plotting to postscript: how to control line width ?
Message-ID: <OFF0CD2458.E86770D7-ON85256DE9.006BE6B4-85256DE9.006C62FC@EU.novartis.net>

When I use
plot(..., type = "line")  then ldw parameter makes a difference...

Because of large number of points overlapping I simply han an impression
before that I am getting thick line...

R





Ryszard Czerminski/PH/Novartis at PH
Sent by: r-help-bounces at stat.math.ethz.ch
11/25/2003 01:34 PM

 
        To:     r-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] plotting to postscript: how to control line width ?


How to control line width ?

if I do:

> postscript("IC50-density.eps", width = 4.0, height = 3.0, horizontal = 
FALSE, onefile = FALSE, paper = "special", title = "IC50 distribution")
> plot(d$x, d$y, xlab = "-log10(IC50)", ylab = "density")
> lines(d$x, d$y, lwd = 0.1)
> dev.off()

but whatever value I give for ldw parameter (e.g. 0.1 or 10) I am getting 
the same line width ?!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From cstrato at aon.at  Wed Nov 26 22:27:17 2003
From: cstrato at aon.at (cstrato)
Date: Wed, 26 Nov 2003 22:27:17 +0100
Subject: [R] Raqua.dmg on MacOS X Panther?
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>
Message-ID: <3FC51AB5.6020806@aon.at>

Dear MacR users

During the weekend I did a clean install of MacOSX 10.3.1, of Apples X11,
of Apples development tools, and of the basic Fink 0.6.2 package.

Now I have just downloaded Raqua.dmg from CRAN and installed the
RAqua, libreadline and tcltk packages.
Sorrowly, double-clicking on StartR has no effect, and starting R from the
command line does not find R, even if I start R from /usr/local/bin.

Does the Raqua binary work with Panther?
(Why do I need to install tcltk, when it comes installed with Panther?)

Thank you in advance
Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._



From andy_liaw at merck.com  Tue Nov 25 22:18:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 25 Nov 2003 16:18:03 -0500
Subject: 64-bit R on Opteron [was Re: [R] Windows R 1.8.0 hangs when
	M	em Usage >1.8GB]
Message-ID: <3A822319EB35174CA3714066D590DCD50205CEA0@usrymx25.merck.com>

> From: Douglas Bates [mailto:bates at bates4.stat.wisc.edu]
> 
> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> > Sorry.  I need to retract my claim.  There seems to be a 3G 
> limit, even
> > though the OS could handle nearly 8G.  (I can have two 
> simultaneous R
> > processes each using near 3G.)
> > 
> > On another note, on our dual Opteron box R (compiled as 
> 64-bit) could easily
> > use nearly all the 16G in that box (that's one of the 
> reason for having that
> > box).
> 
> Does "could" mean you have verified that it did or is this a
> theoretical statement?  I.e., have you compiled and tested R on your
> dual Opteron?

Given my questionable memory of things, this question is very fair.
Here's the evidence:

> x <- matrix(0, 5e5, 5e5)
> x2 <- matrix(0, 5e5, 5e5)
> gc()
             used    (Mb) gc trigger    (Mb)
Ncells     413379    22.1     741108    39.6
Vcells 1783900405 13610.1 1784288128 13613.1

Best,
Andy



From cstrato at aon.at  Wed Nov 26 22:38:37 2003
From: cstrato at aon.at (cstrato)
Date: Wed, 26 Nov 2003 22:38:37 +0100
Subject: [R] Re: Raqua.dmg on MacOS X Panther? - works fine now
In-Reply-To: <3FC51AB5.6020806@aon.at>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>
	<3FC51AB5.6020806@aon.at>
Message-ID: <3FC51D5D.4060702@aon.at>

Dear MacR users

Sorry for the earlier mail, now everything works really great.
For some reason I could not start R immediately after installation,
I had to log out first and then login again, then R did start from
a really great R Console.

Best regards
Christian

cstrato wrote:

> Dear MacR users
>
> During the weekend I did a clean install of MacOSX 10.3.1, of Apples X11,
> of Apples development tools, and of the basic Fink 0.6.2 package.
>
> Now I have just downloaded Raqua.dmg from CRAN and installed the
> RAqua, libreadline and tcltk packages.
> Sorrowly, double-clicking on StartR has no effect, and starting R from 
> the
> command line does not find R, even if I start R from /usr/local/bin.
>
> Does the Raqua binary work with Panther?
> (Why do I need to install tcltk, when it comes installed with Panther?)
>
> Thank you in advance
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
>
>



From mail at joeconway.com  Tue Nov 25 23:38:08 2003
From: mail at joeconway.com (Joe Conway)
Date: Tue, 25 Nov 2003 14:38:08 -0800
Subject: [R] Persistent state of R
In-Reply-To: <20B7EB075F2D4542AFFAF813E98ACD9302822442@cl-exsrv1.irad.bbsrc.ac.uk>
References: <20B7EB075F2D4542AFFAF813E98ACD9302822442@cl-exsrv1.irad.bbsrc.ac.uk>
Message-ID: <3FC3D9D0.5030104@joeconway.com>

michael watson (IAH-C) wrote:
> I am trying to make my cgi scripts quicker and it turns out that the
> bottle-neck is the loading of the libraries into R - for example
> loading up marrayPlots into R takes 10-20 seconds, which although not
> long, is long enough for users to imagine it is not working and start
> clicking reload....
> 
> So I just wondered if anyone had a neat solution whereby I could
> somehow have the required libraries permanently loaded into R -
> perhaps I need a persistent R process with the libraries in memory
> that I can pipe commands to?  Is this possible?

If you are processing data already stored in a database, you could use 
Postgres and PL/R. See:
   http://www.joeconway.com/

Use Postgres 7.4 and preload PL/R for the best performance -- i.e put 
the following line in $PGDATA/postgresql.conf
     preload_libraries = '$libdir/plr:plr_init'

HTH,

Joe



From heron at stanford.edu  Wed Nov 26 00:09:37 2003
From: heron at stanford.edu (Christian Reilly)
Date: Tue, 25 Nov 2003 15:09:37 -0800 (PST)
Subject: [R] problem plotting curve through data
Message-ID: <Pine.GSO.4.44.0311251454470.5651-100000@elaine21.Stanford.EDU>


I'm having trouble plotting a curve (basically a dose-response
function) through a set of data.

I have created a dataframe (df) of Stimulus Intensities (xstim) and
Normalized Responses (yresp), and I've used nls() to calculate a nonlinear
regression, like so:


--------------------
> f <- yresp ~ xstim^n / (xstim^n + B^n)
> starts <- list(n=.6,  B=11)
> myfit <- nls(formula=f, data=df, start = starts)
>myfit

Nonlinear regression model
  model:  yresp ~ xstim^n/(xstim^n + B^n)
   data:  df
        n         B
0.8476233 5.7943791
 residual sum-of-squares:  0.03913122
>
-----------

Which seems great, but I'd like to be able to plot this curve through my
data to see how the fit looks.

when I try:

------------
> plot(f,data=df)
Error in terms.formula(formula, data = data) :
	invalid power in formula
----------

or

----------
> n <- 0.87
> B <- 5.7
> plot(f,data=df)
Error in terms.formula(formula, data = data) :
	invalid power in formula
------------

If anyone can give me any tips on this "Error in terms.formula" message,
or how functions are plotted over data, I'd be much obliged. I've only
been at about a R, some no explanations or suggestions are too simplistic.
Even an example of a plot of a logistic growth function of the form

R = S^n / ( S^n + S50^n)

where R is response, S is stimulus intensity and S50 is the intensity that
produces a 50% response

would be tremendously helpful



Cheers,

and many thanks,

Christian

-----------------------------------------------------------------------
Christian Reilly			http://www.stanford.edu/~heron
Hopkins Marine Station
Pacific Grove, CA 93950
heron at stanford.edu



From mathieu.drapeau at bioneq.qc.ca  Wed Nov 26 00:11:01 2003
From: mathieu.drapeau at bioneq.qc.ca (Mathieu Drapeau)
Date: Tue, 25 Nov 2003 18:11:01 -0500
Subject: [R] hist plot and custom "band" width
Message-ID: <3FC3E185.3000800@bioneq.qc.ca>

Hi,
I have some difficulties to figure how to set a range to my histogram bands.
I have values that are [0,500000] and they appear once in my list. How 
can I do a histogram that include all the values between a range of 
10000 together? [0,10000],[10001,20000],[200001,30000], ...

Thanks,
Mathieu



From MZodet at ahrq.gov  Wed Nov 26 00:28:16 2003
From: MZodet at ahrq.gov (MZodet@ahrq.gov)
Date: Tue, 25 Nov 2003 18:28:16 -0500
Subject: [R] weighted mean
Message-ID: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031125/dc8c42fd/attachment.pl

From jasont at indigoindustrial.co.nz  Wed Nov 26 00:37:29 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 26 Nov 2003 12:37:29 +1300
Subject: [R] hist plot and custom "band" width
In-Reply-To: <3FC3E185.3000800@bioneq.qc.ca>
References: <3FC3E185.3000800@bioneq.qc.ca>
Message-ID: <3FC3E7B9.4040702@indigoindustrial.co.nz>

Mathieu Drapeau wrote:

> Hi,
> I have some difficulties to figure how to set a range to my histogram 
> bands.
> I have values that are [0,500000] and they appear once in my list. How 
> can I do a histogram that include all the values between a range of 
> 10000 together? [0,10000],[10001,20000],[200001,30000], ...

?hist
see the "breaks" argument.

Cheers

Jason

-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From Duncan.Mackay at flinders.edu.au  Wed Nov 26 00:42:26 2003
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 26 Nov 2003 10:12:26 +1030
Subject: [R] plot mean + S.E. over time
In-Reply-To: <3FC36145.704@ifi.unizh.ch>
Message-ID: <LKEKIOMKIBNKJOPKIKOOCEMKDKAA.Duncan.Mackay@flinders.edu.au>

check out "plotCI" and "plotmeans" in the gregmisc library.
Duncan

*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Jan Wantia
Sent: Wednesday, 26 November 2003 12:34 AM
To: r-help at stat.math.ethz.ch
Subject: [R] plot mean + S.E. over time


Hi, there!

I finally became a disciple of 'R', after having lost years of my life
handling data with a popular, rather wide-spread spreadsheet-software.

Now I want to plot the results of many runs of my simulation over time,
so that the means +/- Standard error are on the y-axis, and time on the
x-axis.

I have tried 'boxplot', with timesteps as the grouping variable, but did
not manage to replace quartils by S.E.
Then, with 'plot' I do not know how to handle the data of 100 runs for a
given time to produce the mean and S.E.

Are there any suggestions? Any help would be appreciated!

Cheers, Jan

--

______________________________________________________

Jan Wantia
Dept. of Information Technology, University of Z?rich
Andreasstr. 15
CH 8050 Z?rich
Switzerland

Tel.:     +41 (0) 1 635 4315
Fax:     +41 (0) 1 635 45 07
email: wantia at ifi.unizh.ch

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bates at stat.wisc.edu  Wed Nov 26 00:39:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 25 Nov 2003 17:39:02 -0600
Subject: [R] problem plotting curve through data
In-Reply-To: <Pine.GSO.4.44.0311251454470.5651-100000@elaine21.Stanford.EDU>
References: <Pine.GSO.4.44.0311251454470.5651-100000@elaine21.Stanford.EDU>
Message-ID: <6rad6k6msp.fsf@bates4.stat.wisc.edu>

Christian Reilly <heron at stanford.edu> writes:

> I'm having trouble plotting a curve (basically a dose-response
> function) through a set of data.
> 
> I have created a dataframe (df) of Stimulus Intensities (xstim) and
> Normalized Responses (yresp), and I've used nls() to calculate a nonlinear
> regression, like so:
> 
> 
> --------------------
> > f <- yresp ~ xstim^n / (xstim^n + B^n)
> > starts <- list(n=.6,  B=11)
> > myfit <- nls(formula=f, data=df, start = starts)
> >myfit
> 
> Nonlinear regression model
>   model:  yresp ~ xstim^n/(xstim^n + B^n)
>    data:  df
>         n         B
> 0.8476233 5.7943791
>  residual sum-of-squares:  0.03913122
> >
> -----------
> 
> Which seems great, but I'd like to be able to plot this curve through my
> data to see how the fit looks.
> 
> when I try:
> 
> ------------
> > plot(f,data=df)
> Error in terms.formula(formula, data = data) :
> 	invalid power in formula
> ----------
> 
> or
> 
> ----------
> > n <- 0.87
> > B <- 5.7
> > plot(f,data=df)
> Error in terms.formula(formula, data = data) :
> 	invalid power in formula
> ------------

Use predict.nls to get the fitted response curve.  See
?predict.nls
and especially the example, which you can run with
example(predict.nls)



From jasont at indigoindustrial.co.nz  Wed Nov 26 00:39:42 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 26 Nov 2003 12:39:42 +1300
Subject: [R] weighted mean
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>
References: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>
Message-ID: <3FC3E83E.8000302@indigoindustrial.co.nz>

MZodet at ahrq.gov wrote:

> How do I go about generating a WEIGHTED mean (and standard error) of a
> variable (e.g., expenditures) for each level of a categorical variable
> (e.g., geographic region)?  I'm looking for something comparable to PROC
> MEANS in SAS with both a class and weight statement.

That's two questions.
1) to apply a weighted mean to a vector, see ?weighted.mean

2) to apply a function to data grouped by categorical variable, you 
probably need "by" or "tapply".  See the help pages and examples for both.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From s195404 at student.uq.edu.au  Wed Nov 26 01:09:46 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Wed, 26 Nov 2003 00:09:46 +0000
Subject: [R] weighted mean
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>
References: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>
Message-ID: <1069805386.3fc3ef4a071c2@my.uq.edu.au>

Dear Marc,

For the weighted mean, one possible solution is as follows
and will hopefully give you the general idea:

tmp <- data.frame(x=sample(1:5, 100, replace=TRUE), 
                  y=sample(1:100, 100, replace=TRUE),
                  w=runif(100))
lapply(split(tmp[, 2:3], tmp[, "x"]),
   function(x) { weighted.mean(x=x$y, w=x$w)})


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia


Quoting MZodet at ahrq.gov:

> How do I go about generating a WEIGHTED mean (and
> standard error) of a
> variable (e.g., expenditures) for each level of a
> categorical variable
> (e.g., geographic region)?  I'm looking for something
> comparable to PROC
> MEANS in SAS with both a class and weight statement.
> 
>  
> 
> Thanks.
> 
>  
> 
> Marc
> 
>  
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From kwan022 at stat.auckland.ac.nz  Wed Nov 26 01:23:45 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 26 Nov 2003 13:23:45 +1300 (NZDT)
Subject: [R] strptime Usage
Message-ID: <Pine.LNX.4.44.0311261318120.15890-100000@stat55.stat.auckland.ac.nz>

Hi,

I have a column in a dataframe in the form of:
> as.vector(SLDATX[1:20])
 [1] "1/6/1986"  "1/17/1986" "2/2/1986"  "2/4/1986"  "2/4/1986"
 [6] "2/21/1986" "3/6/1986"  "3/25/1986" "4/6/1986"  "4/10/1986"
[11] "4/23/1986" "4/30/1986" "5/8/1986"  "5/29/1986" "6/15/1986"
[16] "6/18/1986" "6/23/1986" "6/29/1986" "7/16/1986" "7/25/1986"

I'd like to convert it into either yyyy-mm or yyyy/mm form, e.g. 1986-06 
or 1986/06, and I've been suggsted to use the strptime() function.  

However when I look at the documentation of it and tried something like:
> strptime(as.vector(SLDATX)[1:20], "%y/%m")
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA

I got a bunch of NA's.  I also tried:
> strptime(as.vector(SLDATX)[1:20], "%y/%m/%d")
 [1] "2001-06-19" NA           "2002-02-19" "2002-04-19" "2002-04-19"
 [6] NA           "2003-06-19" NA           "2004-06-19" "2004-10-19"
[11] NA           NA           "2005-08-19" NA           NA
[16] NA           NA           NA           NA           NA

It is totally messed up.

I'd really appreciate if anyone can point out where I did wrong *_*!

Many thanks in advance.


-- 
Cheers,

Kevin

---------------------------------------------------------------
"Try not.  Do, do!  Or do not.  There is no try"
   Jedi Master Yoda

----
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From jasont at indigoindustrial.co.nz  Wed Nov 26 01:36:24 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 26 Nov 2003 13:36:24 +1300
Subject: [R] strptime Usage
In-Reply-To: <Pine.LNX.4.44.0311261318120.15890-100000@stat55.stat.auckland.ac.nz>
References: <Pine.LNX.4.44.0311261318120.15890-100000@stat55.stat.auckland.ac.nz>
Message-ID: <3FC3F588.901@indigoindustrial.co.nz>

Ko-Kang Kevin Wang wrote:

> Hi,
> 
> I have a column in a dataframe in the form of:
> 
>>as.vector(SLDATX[1:20])
> 
>  [1] "1/6/1986"  "1/17/1986" "2/2/1986"  "2/4/1986"  "2/4/1986"
>  [6] "2/21/1986" "3/6/1986"  "3/25/1986" "4/6/1986"  "4/10/1986"
> [11] "4/23/1986" "4/30/1986" "5/8/1986"  "5/29/1986" "6/15/1986"
> [16] "6/18/1986" "6/23/1986" "6/29/1986" "7/16/1986" "7/25/1986"
> 
...

First, you have to make this character vector into a time object.
You want something like:

times <- strptime(as.vector(SLDATX[1:20]),"%d/%m/%Y")

so R knows what format you're using for dates.

 From there, format(times,"%Y/%m") will work.

Subtle trap - strptime produces a list of 9 vectors; "times" will always 
have length 9.  If you want to include this into a data frame, you'll 
need to convert to a  POSIX time type:

as.POSIXct(times)

to get the right length.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From soofi at cs.ucla.edu  Wed Nov 26 02:32:12 2003
From: soofi at cs.ucla.edu (Amir Soofi)
Date: Tue, 25 Nov 2003 17:32:12 -0800
Subject: [R] nlm
Message-ID: <088701c3b3bd$1f31bcd0$05182e04@asus>

Can I use nlm through the R API from C?

It's an internal, so I believe it's not supported yet.

If not, any suggestions on a workaround.



From david.baird at agresearch.co.nz  Wed Nov 26 02:36:03 2003
From: david.baird at agresearch.co.nz (Baird, David)
Date: Wed, 26 Nov 2003 14:36:03 +1300
Subject: [R] Update to DataLoad on VSN website
Message-ID: <26F42F6AA462B74AB58BC34342A09A7C109040@lime.agresearch.co.nz>

I would like to announce that my DataLoad utility which can be found at:
http://www.vsn-intl.com/genstat/downloads/datald.htm 
has been updated to support R data.frames. DataLoad reads a
large variety of data formats (listed on the web page) and
can convert these to ASCII or XDR data.frames. Only the Windows
and Linux versions are up to date due to the fact that I no longer
has access to a Unix system (the Sparc/Motif version included
in the zip file does not have all the latest features). I'm
currently working with Stefano Iacus on developing a Mac OSX
version. This is not open source software, due to the fact that 
its development has been paid for by the GenStat user community, 
and VSN, the distributor of GenStat, would like to maintain its 
rights to the source. In the spirit of co-operation VSN have 
allowed me to distribute the compiled executable, and those R users
who are not against free gifts are welcome to download it.
I hope this is of use to the R community.

I would like to thank Gabor Grothendieck for many helpful suggestions
that are likely to make the utility more flexible and useful.

I am open to anyone who has troubles or bugs in converting particular
files in one of the supported formats emailing me to work out a
solution. 

Best wishes,
David
_________________________________________________________
Dr David Baird, Biometrician  EMail:  David.Baird at AgResearch.CO.NZ
Mail: AgResearch, PO Box 60, Gerald St, Lincoln, NEW ZEALAND
Phone: +64 3 983 3975   Fax: +64 3 983 3946
=======================================================================
Attention: The information contained in this message and/or ...{{dropped}}



From soofi at cs.ucla.edu  Wed Nov 26 02:37:21 2003
From: soofi at cs.ucla.edu (Amir Soofi)
Date: Tue, 25 Nov 2003 17:37:21 -0800
Subject: [R] Visual Studio 6, GetRNGstate() causes crash
Message-ID: <08a501c3b3bd$d7271740$05182e04@asus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031125/7d5df16d/attachment.pl

From j.byrne at mackillop.acu.edu.au  Wed Nov 26 04:38:54 2003
From: j.byrne at mackillop.acu.edu.au (john byrne)
Date: Wed, 26 Nov 2003 14:38:54 +1100
Subject: [R] Syntax error from the following command running on Win XP: Rcmd
	BATCH a:test.r
Message-ID: <OF3CD10F94.464D7B6C-ONCA256DEA.001370F2-CA256DEA.00140AE2@mackillop.acu.edu.au>





What is the correct syntax for running a batch program (test.r) from the a:
drive. I have tried no quotes, single and double quotes around a:test.r to
no avail.

Thanks in anticipation.

John Byrne.



From Toby.Patterson at csiro.au  Wed Nov 26 05:25:28 2003
From: Toby.Patterson at csiro.au (Toby.Patterson@csiro.au)
Date: Wed, 26 Nov 2003 15:25:28 +1100
Subject: [R] Calculating great circle distances
Message-ID: <C4178DC99E08604EA5E2BDB989F09380242042@extas2-hba.tas.csiro.au>

Hi, 
Has anyone got any R code (or are there any packages) that calculates
the great circle distance between two geographical (lat, lon) positions?


Cheers 

Toby Patterson 
Pelagic Ecosystems Research Group
CSIRO Marine Research 
Email: Toby.Patterson at csiro.au



From Duncan.Mackay at flinders.edu.au  Wed Nov 26 06:31:18 2003
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 26 Nov 2003 16:01:18 +1030
Subject: [R] Calculating great circle distances
In-Reply-To: <C4178DC99E08604EA5E2BDB989F09380242042@extas2-hba.tas.csiro.au>
Message-ID: <LKEKIOMKIBNKJOPKIKOOIEMNDKAA.Duncan.Mackay@flinders.edu.au>

Have you seen "Online calculations & Downloadable spreadsheets to perform
Geodetic Calculations."
at http://www.ga.gov.au/nmd/geodesy/datums/calcs.jsp ?
Duncan

*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of
Toby.Patterson at csiro.au
Sent: Wednesday, 26 November 2003 2:55 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Calculating great circle distances


Hi,
Has anyone got any R code (or are there any packages) that calculates
the great circle distance between two geographical (lat, lon) positions?


Cheers

Toby Patterson
Pelagic Ecosystems Research Group
CSIRO Marine Research
Email: Toby.Patterson at csiro.au

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ggrothendieck at myway.com  Wed Nov 26 06:34:11 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 26 Nov 2003 00:34:11 -0500 (EST)
Subject: [R] strptime Usage
Message-ID: <20031126053411.B27DF39C2@mprdmxin.myway.com>



strptime takes a character input and produces a POSIXlt output so
the format you specify to strptime is the format of the input, 
not the output:

   format( strptime("10/22/1986", "%m/%d/%Y"), "%Y-%m" )

---
Date: Wed, 26 Nov 2003 13:23:45 +1300 (NZDT) 
From: Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz>
To: R Help <r-help at stat.math.ethz.ch> 
Subject: [R] strptime Usage 

 
 
Hi,

I have a column in a dataframe in the form of:
> as.vector(SLDATX[1:20])
[1] "1/6/1986" "1/17/1986" "2/2/1986" "2/4/1986" "2/4/1986"
[6] "2/21/1986" "3/6/1986" "3/25/1986" "4/6/1986" "4/10/1986"
[11] "4/23/1986" "4/30/1986" "5/8/1986" "5/29/1986" "6/15/1986"
[16] "6/18/1986" "6/23/1986" "6/29/1986" "7/16/1986" "7/25/1986"

I'd like to convert it into either yyyy-mm or yyyy/mm form, e.g. 1986-06 
or 1986/06, and I've been suggsted to use the strptime() function. 

However when I look at the documentation of it and tried something like:
> strptime(as.vector(SLDATX)[1:20], "%y/%m")
[1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA

I got a bunch of NA's. I also tried:
> strptime(as.vector(SLDATX)[1:20], "%y/%m/%d")
[1] "2001-06-19" NA "2002-02-19" "2002-04-19" "2002-04-19"
[6] NA "2003-06-19" NA "2004-06-19" "2004-10-19"
[11] NA NA "2005-08-19" NA NA
[16] NA NA NA NA NA

It is totally messed up.

I'd really appreciate if anyone can point out where I did wrong *_*!

Many thanks in advance.


-- 
Cheers,

Kevin

---------------------------------------------------------------
"Try not. Do, do! Or do not. There is no try"
Jedi Master Yoda

----
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
x88475 (City)
x88480 (Tamaki)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Roger.Bivand at nhh.no  Wed Nov 26 08:27:53 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 26 Nov 2003 08:27:53 +0100 (CET)
Subject: [R] Calculating great circle distances
In-Reply-To: <C4178DC99E08604EA5E2BDB989F09380242042@extas2-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.44.0311260820510.17265-100000@reclus.nhh.no>

On Wed, 26 Nov 2003 Toby.Patterson at csiro.au wrote:

> Hi, 
> Has anyone got any R code (or are there any packages) that calculates
> the great circle distance between two geographical (lat, lon) positions?
> 

Yes, there is R code in fields, function rdist.earth() taking vectors as
arguments for one solution, alternatively there is a C function in spdep:

void gcdist(double *lon1, double *lon2, double *lat1, double *lat2, 
		double *dist)

which needs to be put in a loop, but is specifically WGS84, and is based 
on the implementation at:

http://home.att.net/~srschmitt/greatcircle.html

There may be other code too.

Roger

> 
> Cheers 
> 
> Toby Patterson 
> Pelagic Ecosystems Research Group
> CSIRO Marine Research 
> Email: Toby.Patterson at csiro.au
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ligges at statistik.uni-dortmund.de  Wed Nov 26 08:45:30 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 26 Nov 2003 08:45:30 +0100
Subject: [R] Syntax error from the following command running on Win XP:
	Rcmd	BATCH a:test.r
In-Reply-To: <OF3CD10F94.464D7B6C-ONCA256DEA.001370F2-CA256DEA.00140AE2@mackillop.acu.edu.au>
References: <OF3CD10F94.464D7B6C-ONCA256DEA.001370F2-CA256DEA.00140AE2@mackillop.acu.edu.au>
Message-ID: <3FC45A1A.4050203@statistik.uni-dortmund.de>

john byrne wrote:

> 
> 
> 
> What is the correct syntax for running a batch program (test.r) from the a:
> drive. I have tried no quotes, single and double quotes around a:test.r to
> no avail.

Learn how to specify paths in Windows:
Rcmd BATCH a:\test.R

BTW: If a: is a flopp drive, I'd highly recommend to copy files to a 
hard disk before working with them ...

Uwe Ligges


> Thanks in anticipation.
> 
> John Byrne.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed Nov 26 09:00:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Nov 2003 08:00:29 +0000 (GMT)
Subject: [R] nlm
In-Reply-To: <088701c3b3bd$1f31bcd0$05182e04@asus>
Message-ID: <Pine.LNX.4.44.0311260759080.10587-100000@gannet.stats>

Look in Writing R Extensions for what is in the R API.

Hint: the internals of optim() are.

On Tue, 25 Nov 2003, Amir Soofi wrote:

> Can I use nlm through the R API from C?
> 
> It's an internal, so I believe it's not supported yet.
> 
> If not, any suggestions on a workaround.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From markus.jantti at iki.fi  Wed Nov 26 09:55:16 2003
From: markus.jantti at iki.fi (Markus =?ISO-8859-1?Q?J=E4ntti?=)
Date: Wed, 26 Nov 2003 10:55:16 +0200
Subject: [R] weighted mean
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>
References: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>
Message-ID: <1069836916.22488.10.camel@maynard>

On Wed, 2003-11-26 at 01:28, MZodet at ahrq.gov wrote:
> How do I go about generating a WEIGHTED mean (and standard error) of a
> variable (e.g., expenditures) for each level of a categorical variable
> (e.g., geographic region)?  I'm looking for something comparable to PROC
> MEANS in SAS with both a class and weight statement.
> 

I asked this question a few years ago and this is the anwer I got works:

see 
http://www.r-project.org/nocvs/mail/r-help/1999/2160.html

tapply(seq(along=wage), list(Educc,Year), 
       function(i, x=wage, w=weight)  weighted.mean(x[i], w[i]))

(wage and weight are the variable of interest and weight, while Educc
and Year are the factors)

Regards,

Markus
>  
> 
> Thanks.
> 
>  
> 
> Marc
> 
>  
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
-- 
Markus J?ntti <markus.jantti at iki.fi>
Abo Akademi University



From p.b.pynsent at bham.ac.uk  Wed Nov 26 10:53:17 2003
From: p.b.pynsent at bham.ac.uk (p.b.pynsent)
Date: Wed, 26 Nov 2003 09:53:17 +0000
Subject: [R] pdf files, change in content
Message-ID: <5BD24216-1FF6-11D8-B3EF-003065F42152@bham.ac.uk>

There seems to be something different about pdf files generated under 
RAqua (1.8.1).
I am losing text.
I am not sure when things changed but, on Carbon 1.7, when files were  
'drag and dropped'  onto another application they worked fine. Now the 
text is lost but the graphics are intact. However the text is there 
when viewed with Acrobat.
On the other hand, if I output to an eps file and then use the 
Perl/ghostscript function eps2pdf,  the pdf file generated works as I 
would expect.

****************
platform powerpc-apple-darwin6.8
arch     powerpc
os       darwin6.8
system   powerpc, darwin6.8
status
major    1
minor    8.1
year     2003
month    11
day      21
language R

Mac OS 10.2.8
*****************

The programme I have used as a test is:

oldpar <- par(no.readonly=TRUE)
postscript("test.eps", onefile=TRUE, bg = "white",
	family= "Times", paper = "A4", horizontal = TRUE)
par(omi=c(0.5,0.5,0.5,0.5))
plot(1:10,type = "p")
text (5, 5, labels = "Hello world", cex = 1.5)
par(oldpar)
dev.off()
#
oldpar <- par(no.readonly=TRUE)
par(omi=c(0.5,0.5,0.5,0.5)
pdf("test.pdf",width = 27/2.54, height = 18.4/2.54, bg = "white", 
onefile = TRUE,family = "Times")
plot(1:10,type = "p")
text (5, 5, labels = "Hello world", cex = 1.5)
par(oldpar)
dev.off()


I should be most grateful for any suggestions for a remedy.

Paul



From commercial at s-boehringer.de  Wed Nov 26 11:25:03 2003
From: commercial at s-boehringer.de (Stefan =?ISO-8859-1?Q?B=F6hringer?=)
Date: 26 Nov 2003 11:25:03 +0100
Subject: [R] Lambert's W function
In-Reply-To: <a0600201dbbe8de9dec6e@[139.166.242.29]>
References: <a0600201dbbe8de9dec6e@[139.166.242.29]>
Message-ID: <1069842303.8561.13.camel@hgX>


On Tue, 2003-11-25 at 12:09, Robin Hankin wrote:
> Hello List
> 
> does anyone have an R function for the Lambert W function?  I need 
> complex arguments.
> 
> [the Lamert W function W(z) satisfies
> 
> W(z)*exp(W(z)) = z
> 
> but I could'nt even figure out how to use uniroot() for complex z]
> 
> 

There are several 'branches' of W(z) for complex arguments, since the
inverse of f(z) = z * exp(z) does not exist. Therefore you have to
constrain root-finding methods appropriately.

Here is an implementation for real valued arguments, if that is of any
help to you:

WE1 <- function(x) {
	if (1) {
	o <- optim(c(1),
		# optimize squared difference of z and log(t) + t
		function(t) { (x - (log(t[1]) + t[1]))**2 },
		# the gradient of the above function
		#function(t) { 2(log(t[1]) + t[1] - x)(1/t[1] - 1) },
		method="L-BFGS-B", lower=exp(-70),
			control = list(lmm=40, maxit=10000, factr=1e9));
	} else {
	o <- optim(c(1),
		# optimize squared difference of z and log(t) + t
		function(t) { (x - (log(t[1]) + t[1]))**2 },
		method="BFGS");
	}
	o$par
}

W2 <- function(x) {
	eps <- 10^-5;	# precision

	if (x == 0) {
		wnew <- 0
	} else {
		# initial guess
		wold <- if (x < 2.5) {
			(x + 4/3*x^2)/(1 + 7/3*x + 5/6*x^2)
		} else {
			log(x)
		};
		if (x < 0) print("error");
			lx <- log(x);
		wnew <- 2 * wold;
		if (x != Inf) {
			while (abs( (wnew - wold)/wold ) > eps) {
				wold <- wnew
				zn <- lx - wold - log(wold);
				y <- 2*(1 + wold)*((1 + wold) + 2/3*zn) - zn;
				wnew <- wold*(1 + (zn * y)/((1 + wold)*(y - zn)));
			}
		} else {
			wnew <- Inf;
		}
	}
	wnew
}
WE <- function(z) {
	if ( z < -1 ) { W2(exp(z)) }
	else { WE1(z) };
}
W <- function(z) { WE(log(z)) }


Stefan



From dmurdoch at pair.com  Wed Nov 26 12:55:25 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 26 Nov 2003 06:55:25 -0500
Subject: [R] Syntax error from the following command running on Win XP:
	Rcmd BATCH a:test.r
In-Reply-To: <OF3CD10F94.464D7B6C-ONCA256DEA.001370F2-CA256DEA.00140AE2@mackillop.acu.edu.au>
References: <OF3CD10F94.464D7B6C-ONCA256DEA.001370F2-CA256DEA.00140AE2@mackillop.acu.edu.au>
Message-ID: <7o49sv4srn91ifeb1oc214evj4ptbvrpp4@4ax.com>

On Wed, 26 Nov 2003 14:38:54 +1100, you wrote:


>What is the correct syntax for running a batch program (test.r) from the a:
>drive. I have tried no quotes, single and double quotes around a:test.r to
>no avail.
>

(I'd put the full question in the message; I almost asked what syntax
you had used, because I didn't notice it at first in the subject
line.)

You used 

Rcmd BATCH a:test.r

and I can't see anything wrong with that syntax.  What error message
are you seeing?  Do you have write permission on a:?

Duncan Murdoch



From M.Torrance at staffs.ac.uk  Wed Nov 26 13:31:02 2003
From: M.Torrance at staffs.ac.uk (TORRANCE Mark)
Date: Wed, 26 Nov 2003 12:31:02 -0000
Subject: [R] Interations to convergence with eigen()
Message-ID: <AF4ED2CCDF03F748A188D3D4B5B47F5240A836@crwnmail2.staff.staffs.ac.uk>

Hello,

 

Is there any way I can get R to tell me the number of iterations it went
through when calculating eigenvalues? 

 

(My apologies if this question displays excessive ignorance of R and/or
how eigenvalues are calculated. If so, maybe someone could quietly take
me to one side ...) 

 

Mark Torrance

The information in this email is confidential and is intende...{{dropped}}



From Nicolas.Stransky at curie.fr  Wed Nov 26 13:47:09 2003
From: Nicolas.Stransky at curie.fr (Nicolas STRANSKY)
Date: Wed, 26 Nov 2003 13:47:09 +0100
Subject: [R] Spearman correlation and missing observations
Message-ID: <3FC4A0CD.9020702@curie.fr>

Hi,

I am using R 1.8.1 on WinXP. I encounter a problem when trying to
compute a Spearman correlation under certain conditions (at least I
think there is a problem, but maybe this is the normal behavior).

> X<-array(0,c(20,2))
>
> X[,1]<-c(runif(10),rep(NA,10))
> X[,2]<-c(runif(10),rep(NA,10))
>
> Y<-X[1:10,]
>
> cor(Y,method="s",use="complete.obs")
          [,1]      [,2]
[1,] 1.0000000 0.3939394
[2,] 0.3939394 1.0000000
> cor(X,method="s",use="complete.obs")
         [,1]     [,2]
[1,] 1.000000 0.924812
[2,] 0.924812 1.000000


The problem is that I do not get the same results whenever there are
NA's is the dataset or not. Perhaps I misunderstand the use of
"complete.obs" and "pairwise.complete.obs" for dealing with missing data
; if so, please tell me how I could manage to have se same result at the
end.

On the other hand, the same type of commands with a Pearson correlation
gives exactly the same result for X and Y :

> cor(Y,method="p",use="complete.obs")
          [,1]      [,2]
[1,] 1.0000000 0.3109109
[2,] 0.3109109 1.0000000
> cor(X,method="p",use="complete.obs")
          [,1]      [,2]
[1,] 1.0000000 0.3109109
[2,] 0.3109109 1.0000000

Thank's for your help
-- 
Nicolas STRANSKY
Institut Curie  - UMR 144 du CNRS
26, rue d'Ulm - 75248 Paris Cedex 05
tel : 01.42.34.63.40 / fax : 01.42.34.63.49



From p.dalgaard at biostat.ku.dk  Wed Nov 26 14:26:57 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Nov 2003 14:26:57 +0100
Subject: [R] weighted mean
In-Reply-To: <3FC3E83E.8000302@indigoindustrial.co.nz>
References: <3598558AD728D41183350008C7CF291C0A5CD488@exchange1.ahrq.gov>
	<3FC3E83E.8000302@indigoindustrial.co.nz>
Message-ID: <x265h72rby.fsf@biostat.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> MZodet at ahrq.gov wrote:
> 
> > How do I go about generating a WEIGHTED mean (and standard error) of a
> > variable (e.g., expenditures) for each level of a categorical variable
> > (e.g., geographic region)?  I'm looking for something comparable to PROC
> > MEANS in SAS with both a class and weight statement.
> 
> That's two questions.
> 1) to apply a weighted mean to a vector, see ?weighted.mean
 
> 2) to apply a function to data grouped by categorical variable, you
> probably need "by" or "tapply".  See the help pages and examples for
> both.

Three actually. Noone seems to have answered how to get the SD, and
that's a little more tricky.  

The simplest (well, the quickest) way to get the weighted SD is to do
a weighted regression analysis with just an intercept term:

x <- c(3,4,5); w <- c(2,5,7) # just for testing
summary(lm(x~1,weight=w))$sigma

# this is the weighted sum of squares on N-1 DF

wss <- sum((x-m)^2*w)
sqrt(wss/2)


Notice however that SAS also does frequency weighting where
(x=2.7,w=5) means that there are five observations of 2.7. 

In that case, the brute-force approach is 


sd(rep(x,w))

# which is the same as

sqrt(wss/13) # sum(w)-1 DF

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Wed Nov 26 15:04:10 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Nov 2003 15:04:10 +0100
Subject: [R] Spearman correlation and missing observations
In-Reply-To: <3FC4A0CD.9020702@curie.fr>
References: <3FC4A0CD.9020702@curie.fr>
Message-ID: <x21xrv2plx.fsf@biostat.ku.dk>

Nicolas STRANSKY <Nicolas.Stransky at curie.fr> writes:

> Hi,
> 
> I am using R 1.8.1 on WinXP. I encounter a problem when trying to
> compute a Spearman correlation under certain conditions (at least I
> think there is a problem, but maybe this is the normal behavior).
> 
> > X<-array(0,c(20,2))
> >
> > X[,1]<-c(runif(10),rep(NA,10))
> > X[,2]<-c(runif(10),rep(NA,10))
> >
> > Y<-X[1:10,]
> >
> > cor(Y,method="s",use="complete.obs")
>           [,1]      [,2]
> [1,] 1.0000000 0.3939394
> [2,] 0.3939394 1.0000000
> > cor(X,method="s",use="complete.obs")
>          [,1]     [,2]
> [1,] 1.000000 0.924812
> [2,] 0.924812 1.000000
> 
> 
> The problem is that I do not get the same results whenever there are
> NA's is the dataset or not. Perhaps I misunderstand the use of
> "complete.obs" and "pairwise.complete.obs" for dealing with missing data
> ; if so, please tell me how I could manage to have se same result at the
> end.
> 
> On the other hand, the same type of commands with a Pearson correlation
> gives exactly the same result for X and Y :
> 
> > cor(Y,method="p",use="complete.obs")
>           [,1]      [,2]
> [1,] 1.0000000 0.3109109
> [2,] 0.3109109 1.0000000
> > cor(X,method="p",use="complete.obs")
>           [,1]      [,2]
> [1,] 1.0000000 0.3109109
> [2,] 0.3109109 1.0000000
> 
> Thank's for your help

Oh, d*mn....

The problem is that 

> rank(c(runif(10),rep(NA,10)))
 [1]  4  8  6  5  9 10  2  3  7  1 11 12 13 14 15 16 17 18 19 20

and we want 

> rank(c(runif(10),rep(NA,10)),na.last="keep")
 [1]  6  2  9  5  8  3  7  1 10  4 NA NA NA NA NA NA NA NA NA NA

so inside cor, we need to add na.last="keep" in two places:

    if (method != "pearson") {
        Rank <- function(u) if (is.matrix(u))
            apply(u, 2, rank, na.last="keep")
        else rank(u, na.last="keep")
        x <- Rank(x)
        if (!is.null(y))
            y <- Rank(y)
    }


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From apiszcz at solarrain.com  Wed Nov 26 15:15:10 2003
From: apiszcz at solarrain.com (Al Piszcz)
Date: Wed, 26 Nov 2003 09:15:10 -0500 (EST)
Subject: [R] plotCI : Disabling X axis labels ?
Message-ID: <Pine.LNX.4.55.0311260910020.16574@l1>


I have my own set of labels for the X axis and typically
apply them to other plot modes using:
axis(1,at=1:n,labels=xLabels)

Where n is the number of character strings in xLabels

Is there a parameter to disable plotCI from creating its
default labels for the X axis?



From reinhard at meinberlikomm.de  Wed Nov 26 15:16:14 2003
From: reinhard at meinberlikomm.de (Reinhard Sy)
Date: Wed, 26 Nov 2003 15:16:14 +0100
Subject: [R] creating graphs in BATCH mode
Message-ID: <200311261511.38845.reinhard@meinberlikomm.de>

Hi 
 a short question is there a way to generate jpeg's etc. in BATCH mode ? The 
following example does not work in BATCH:

I have a file called Rgraph.in:
*rsy at puffin*[15:11][~][57]> cat Rgraph.in 
jpeg("/tmp/my.jpg")
hist(runif(10000))
dev.off()

*rsy at puffin*[15:11][~][58]> 

*rsy at puffin*[15:09][~][55]> R BATCH Rgraph.in OUT
4.120u 0.160s 0:05.17 82.7%     0+0k 0+0io 2208pf+0w
*rsy at puffin*[15:09][~][56]> cat OUT

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]


> invisible(options(echo = TRUE))
> jpeg("/tmp/my.jpg")
Error in jpeg("/tmp/my.jpg") : R_X11 module cannot be loaded
In addition: Warning message: 
X11 module is not available under this GUI 
Execution halted
*rsy at puffin*[15:09][~][57]>



From rpeng at jhsph.edu  Wed Nov 26 15:31:06 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 26 Nov 2003 09:31:06 -0500
Subject: [R] creating graphs in BATCH mode
In-Reply-To: <200311261511.38845.reinhard@meinberlikomm.de>
References: <200311261511.38845.reinhard@meinberlikomm.de>
Message-ID: <3FC4B92A.2010204@jhsph.edu>

Try using bitmap() instead.

-roger

Reinhard Sy wrote:
> Hi 
>  a short question is there a way to generate jpeg's etc. in BATCH mode ? The 
> following example does not work in BATCH:
> 
> I have a file called Rgraph.in:
> *rsy at puffin*[15:11][~][57]> cat Rgraph.in 
> jpeg("/tmp/my.jpg")
> hist(runif(10000))
> dev.off()
> 
> *rsy at puffin*[15:11][~][58]> 
> 
> *rsy at puffin*[15:09][~][55]> R BATCH Rgraph.in OUT
> 4.120u 0.160s 0:05.17 82.7%     0+0k 0+0io 2208pf+0w
> *rsy at puffin*[15:09][~][56]> cat OUT
> 
> R : Copyright 2003, The R Foundation for Statistical Computing
> Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
> 
> [Previously saved workspace restored]
> 
> 
> 
>>invisible(options(echo = TRUE))
>>jpeg("/tmp/my.jpg")
> 
> Error in jpeg("/tmp/my.jpg") : R_X11 module cannot be loaded
> In addition: Warning message: 
> X11 module is not available under this GUI 
> Execution halted
> *rsy at puffin*[15:09][~][57]>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From bolker at zoo.ufl.edu  Wed Nov 26 15:52:44 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 26 Nov 2003 09:52:44 -0500 (EST)
Subject: [R] Lambert's W function
In-Reply-To: <200311261103.hAQB3mCf013863@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0311260949560.14710-100000@bolker.zoo.ufl.edu>


  This implementation, originally written by Nici Schraudolph, allows you
to choose which branch you want.  I've checked the answers for complex
arguments, non-systematically, against Mathematica's ProductLog function.

  Ben Bolker

lambertW = function(z,b=0,maxiter=10,eps=.Machine$double.eps,
  min.imag=1e-9) {
  if (any(round(Re(b)) != b))
    stop("branch number for W must be an integer")
  if (!is.complex(z) && any(z<0)) z=as.complex(z)
  ## series expansion about -1/e
  ##
  ## p = (1 - 2*abs(b)).*sqrt(2*e*z + 2);
  ## w = (11/72)*p;
  ## w = (w - 1/3).*p;
  ## w = (w + 1).*p - 1
  ##
  ## first-order version suffices:
  ##
  w = (1 - 2*abs(b))*sqrt(2*exp(1)*z + 2) - 1
  ## asymptotic expansion at 0 and Inf
  ##
  v = log(z + as.numeric(z==0 & b==0)) + 2*pi*b*1i;
  v = v - log(v + as.numeric(v==0))
  ## choose strategy for initial guess
  ##
  c = abs(z + exp(-1));
  c = (c > 1.45 - 1.1*abs(b));
  c = c | (b*Im(z) > 0) | (!Im(z) & (b == 1))
  w = (1 - c)*w + c*v
  ## Halley iteration
  ##
  for (n in 1:maxiter) {
    p = exp(w)
    t = w*p - z
    f = (w != -1)
    t = f*t/(p*(w + f) - 0.5*(w + 2.0)*t/(w + f))
    w = w - t
    if (abs(Re(t)) < (2.48*eps)*(1.0 + abs(Re(w)))
        && abs(Im(t)) < (2.48*eps)*(1.0 + abs(Im(w))))
      break
  }
  if (n==maxiter) warning(paste("iteration limit (",maxiter,
        ") reached, result of W may be inaccurate",sep=""))
  if (all(Im(w)<min.imag)) w = as.numeric(w)
  return(w)
}

---------

\name{lambertW}
\alias{lambertW}
\title{Lambert W function}
\description{
  Computes the Lambert W function, giving efficient solutions to the equation x*exp(x)==x
}
\usage{
lambertW(z, b = 0, maxiter = 10, eps = .Machine$double.eps, min.imag = 1e-09)
}
\arguments{
  \item{z}{(complex) vector of values for which to compute the function}
  \item{b}{(integer) vector of branches: b=0 specifies the principal
    branch, 0 and -1 are the ones that can take non-complex values}
  \item{maxiter}{maximum numbers of iterations for convergence}
  \item{eps}{convergence tolerance}
  \item{min.imag}{maximum magnitude of imaginary part to chop when
    returning solutions}
}
\details{
Compute the Lambert W function of z.  This function satisfies
W(z)*exp(W(z)) = z, and can thus be used to express solutions
of transcendental equations involving exponentials or logarithms.
The Lambert W function is also available in 
Mathematica (as the ProductLog function), and in Maple.
}
\value{
  Complex or real vector of solutions.
}
\references{Corless, Gonnet, Hare, Jeffrey, and Knuth (1996), "On the Lambert
W Function", Advances in Computational Mathematics 5(4):329-359}
\author{Nici Schraudolph <schraudo at inf.ethz.ch> (original
  version (c) 1998), Ben Bolker (R translation)
  }
\note{
This implementation should return values within 2.5*eps of its
counterpart in Maple V, release 3 or later.  Please report any
discrepancies to the author or translator.
}
\examples{
curve(lambertW(x),from=0,to=10)
pvec = seq(-1,1,length=40)
m = outer(pvec,pvec,function(x,y)Re(lambertW(x+y*1i)))
persp(pvec,pvec,m,
      theta=290,shade=0.5,zlab="lambertW")
num1 = uniroot(function(x) {x*exp(x)-1},lower=0,upper=1,tol=1e-9)
abs(lambertW(1)-num1$root)<1e-9
}
\keyword{math}

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From flyfish72 at fastmail.fm  Wed Nov 26 15:57:37 2003
From: flyfish72 at fastmail.fm (Annie Bibble)
Date: Wed, 26 Nov 2003 09:57:37 -0500
Subject: [R] iostream (was: is R multi-threaded?)
In-Reply-To: <Pine.LNX.4.44.0311242015260.22426-100000@gannet.stats>
References: <Pine.LNX.4.44.0311242015260.22426-100000@gannet.stats>
Message-ID: <3FC4BF61.9080902@fastmail.fm>

In the "Writing extensions for R" document, there is a part that reads:

"Using C++ iostreams, as in this example, is best avoided.  There is no 
guarantee that the output will appear in the R console..."

Does R do anything that would potentially cause a stream:: method in a 
dynamically-loaded library to get stuck waiting for a mutex?  Or is this 
just a warning about potential formatting issues?

(on linux)

Thank you!
Annie



From apiszcz at solarrain.com  Wed Nov 26 15:58:18 2003
From: apiszcz at solarrain.com (Al Piszcz)
Date: Wed, 26 Nov 2003 09:58:18 -0500 (EST)
Subject: [R] (a solution for) plotCI : Disabling X axis labels ?
Message-ID: <Pine.LNX.4.55.0311260956480.17217@l1>




This work around is sufficient:

par(xaxt="n")
plotCI(....)
par(xaxt="s")
axis(1,at=1:8,labels=xLabels)



---------- Forwarded message ----------
Date: Wed, 26 Nov 2003 09:15:10 -0500 (EST)
From: Al Piszcz <apiszcz at solarrain.com>
To: r-help at stat.math.ethz.ch
Subject: plotCI : Disabling X axis labels ?


I have my own set of labels for the X axis and typically
apply them to other plot modes using:
axis(1,at=1:n,labels=xLabels)

Where n is the number of character strings in xLabels

Is there a parameter to disable plotCI from creating its
default labels for the X axis?



From mendigo at netcabo.pt  Wed Nov 26 16:03:45 2003
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Wed, 26 Nov 2003 15:03:45 -0000
Subject: [R] Correlation test in time series
Message-ID: <004801c3b42e$7d9f6800$e9a716d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031126/a0ab27fa/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Nov 26 17:05:00 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Nov 2003 17:05:00 +0100
Subject: [R] iostream (was: is R multi-threaded?)
In-Reply-To: <3FC4BF61.9080902@fastmail.fm>
References: <Pine.LNX.4.44.0311242015260.22426-100000@gannet.stats>
	<3FC4BF61.9080902@fastmail.fm>
Message-ID: <x2smkb15g3.fsf@biostat.ku.dk>

Annie Bibble <flyfish72 at fastmail.fm> writes:

> In the "Writing extensions for R" document, there is a part that reads:
> 
> "Using C++ iostreams, as in this example, is best avoided.  There is
> no guarantee that the output will appear in the R console..."
> 
> Does R do anything that would potentially cause a stream:: method in a
> dynamically-loaded library to get stuck waiting for a mutex?  Or is
> this just a warning about potential formatting issues?
> 
> (on linux)

Printing in R generally goes through Rprintf or REprintf, these may be
redefined to send output into (e.g.) a GUI widget. Iostreams bypass
this mechanism and print to the originating terminal or into
/dev/null, which is likely not what you want.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From antoniamarija at net.hr  Wed Nov 26 17:06:08 2003
From: antoniamarija at net.hr (Antonia Drugica)
Date: Wed, 26 Nov 2003 17:06:08 +0100
Subject: [R] FDA and ICH Compliance of R
Message-ID: <3fc4cf70.4583.0@net.hr>

Does anybody know if R is FDA or ICH (or EMEA...) compliant? AFAIK S-Plus
is but that means nothing...

--
Trebate bolji pristup internetu?
Nazovite IskonInternet na 0800 1000 ili pogledajte
http://www.iskon.biz/individualni/usluge/dialup/



From mendigo at netcabo.pt  Wed Nov 26 17:17:17 2003
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Wed, 26 Nov 2003 16:17:17 -0000
Subject: [R] Correlation test in time series
References: <B3A80C9C13928B45B2FCE4C43656363A0194E32F@mail-srv02.master.medizin.uni-essen.de>
Message-ID: <006101c3b438$c3506520$e9a716d5@galactic>

Thanks for you help,

And how to test covariance = zero in time series ,
cov(r_t, r_t-1)=0
and r_t  are homoscedastik and dependent ?

 Thanks



From tlumley at u.washington.edu  Wed Nov 26 17:24:12 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 26 Nov 2003 08:24:12 -0800 (PST)
Subject: [R] FDA and ICH Compliance of R
In-Reply-To: <3fc4cf70.4583.0@net.hr>
References: <3fc4cf70.4583.0@net.hr>
Message-ID: <Pine.A41.4.58.0311260810400.21424@homer13.u.washington.edu>

On Wed, 26 Nov 2003, Antonia Drugica wrote:

> Does anybody know if R is FDA or ICH (or EMEA...) compliant? AFAIK S-Plus
> is but that means nothing...

Actually, "FDA compliant" means nothing. The FDA does not certify
statistical software and responsibility for validation is left entirely up
to the user.

Insightful Co, the S-PLUS vendors provide some tools to help you with
validation and some information on validation that pharmaceutical
companies have done.

The only validation tools provided with R are the tests used by the
developers.  These show which aspects of R have been tested and might
help other people develop tests to examine specific areas more carefully.


	-thomas



From Bernhard.Pfaff at drkw.com  Wed Nov 26 17:35:52 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Wed, 26 Nov 2003 17:35:52 +0100
Subject: [R] Correlation test in time series
Message-ID: <18D602BD42B7E24EB810D6454A58DB9004730721@ibfftce505.is.de.dresdnerkb.com>

> Thanks for you help,
> 
> And how to test covariance = zero in time series ,
> cov(r_t, r_t-1)=0
> and r_t  are homoscedastik and dependent ?

How about:

?acf
?pacf

in package 'ts'

HTH,
Bernhard

> 
>  Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


--------------------------------------------------------------------------------
The information contained herein is confidential and is intended solely for the
addressee. Access by any other party is unauthorised without the express 
written permission of the sender. If you are not the intended recipient, please 
contact the sender either via the company switchboard on +44 (0)20 7623 8000, or
via e-mail return. If you have received this e-mail in error or wish to read our
e-mail disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From rossini at blindglobe.net  Wed Nov 26 17:39:44 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 26 Nov 2003 08:39:44 -0800
Subject: [R] FDA and ICH Compliance of R
In-Reply-To: <3fc4cf70.4583.0@net.hr> (Antonia Drugica's message of "Wed, 26
	Nov 2003 17:06:08 +0100")
References: <3fc4cf70.4583.0@net.hr>
Message-ID: <85r7zvjd7z.fsf@blindglobe.net>

"Antonia Drugica" <antoniamarija at net.hr> writes:

> Does anybody know if R is FDA or ICH (or EMEA...) compliant? AFAIK S-Plus
> is but that means nothing...

As Thomas pointed out, that does mean nothing -- there was a group of
folks discussing what might be done to help, earlier this year, but
then everyone got busy...

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From andreas.palmen at sh.se  Wed Nov 26 17:42:48 2003
From: andreas.palmen at sh.se (=?ISO-8859-1?Q?Andreas_Palm=E9n?=)
Date: Wed, 26 Nov 2003 17:42:48 +0100
Subject: [R] connect RAqua 1.8.1 with external editor (alphaX)
Message-ID: <91C9828C-202F-11D8-B9FB-000A95890E50@sh.se>

Hi

This might be a trivial question or as well put forward in the wrong 
forum, but I try anyways. I'm new to R and have installed the latest 
mac version for osx. I would like R to communicate with an external 
editor e.g. alphaX, or maybe more precisely the other way around. This 
doesn't work at present, I can't open or switch to R from alphaX. Does 
anyone have some advice to me how to solve this problem or any 
suggestions what other forum to address this matter?

-Andreas



From ivo.welch at yale.edu  Wed Nov 26 17:43:15 2003
From: ivo.welch at yale.edu (ivo welch)
Date: Wed, 26 Nov 2003 11:43:15 -0500
Subject: [R] lines(lowess()) trouble
Message-ID: <3FC4D823.9060005@yale.edu>


hi:    apologies for taking up everyone's time.  my problem is probably 
documented somewhere, but I again cannot find it.  (which reminds me: I cannot 
find a search engine that allows me to search the archives of this very useful 
mailing list.)

* it seems that lines(lowess()) fails to plot certain line segments.  (and, 
what does it do at the x-min and x-max of a data set?)  Rather than speculate 
what causes it, I am including a short R snippet and a short data set that 
demonstrates it.  is this a bug or a feature?

* it would be nice if lowess was a little better documented.  I have easy 
access to Becker-Chambers-Wilks, but not to JASA and AS.  I wish "?lowess" 
would tell me a little more about the method.

thanks in advance.

regards, /iaw

-------- test.R
test <- read.table(file="test.txt", sep="\t", header=T);
plot( test$x, test$y, log="xy");
lines( lowess( test$x, test$y, f=0.5 ) );

-------- test.txt
x	y
5584440	5000
2300100	1
37320	3977
92500	1
38440	1
70000	1
161282	151759
963000	7453
200000	5000
162000	1
29100	1200
20000	1
7921000	8112906
100000	1
426500	1
200000	1
450000	1
1900000	1
220001	2000
109901	13463
16300	6965



From elio.mineo at dssm.unipa.it  Wed Nov 26 17:44:29 2003
From: elio.mineo at dssm.unipa.it (Elio Mineo)
Date: Wed, 26 Nov 2003 17:44:29 +0100
Subject: [R] R 1.8.1 for Mandrake 8.2
Message-ID: <3FC4D86D.3080103@dssm.unipa.it>

Dear All,
as the R package for the Mandrake Linux distribution, version 8.2, is 
not supported anymore, a (non official) package for R 1.8.1 for this 
distribution can be downloaded from

http://dssm.unipa.it/mandrake/8.2/

The author of this package is Alfredo Pontillo. If you have any problem 
with this package, please send me a message.
With best regards,
Elio Mineo

-- 
--------------------------------------------------------------------------
Elio Mineo
Dipartimento di Scienze Statistiche e Matematiche "Silvio Vianelli"
Universit? degli Studi di Palermo
Viale delle Scienze
90128 Palermo
URL: http://dssm.unipa.it/elio



From rksh at soc.soton.ac.uk  Wed Nov 26 17:40:51 2003
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 26 Nov 2003 16:40:51 +0000
Subject: [R] [R-pkgs] new R package: magic squares
Message-ID: <a06002024bbea865e3f74@[139.166.242.29]>

Dear List

I have just placed a new R package on CRAN that includes many tools 
for creating and
investigating magic squares and hypercubes.

Any comments, suggestions, etc very welcome.  I am particularly interested in
coding up additional algorithms for magic squares, and also in improving the
existing methods.


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From ahmlatif at yahoo.com  Wed Nov 26 18:07:36 2003
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Wed, 26 Nov 2003 09:07:36 -0800 (PST)
Subject: [R] lines(lowess()) trouble
In-Reply-To: <3FC4D823.9060005@yale.edu>
Message-ID: <20031126170736.13757.qmail@web41201.mail.yahoo.com>

Try this...

plot(log(test$x), log(test$y))
lines(lowess(log(test$x), log(test$y)))

your lowess was using different observations than you
plotted.

Mahbub.
--- ivo welch <ivo.welch at yale.edu> wrote:
> 
> hi:    apologies for taking up everyone's time.  my
> problem is probably 
> documented somewhere, but I again cannot find it. 
> (which reminds me: I cannot 
> find a search engine that allows me to search the
> archives of this very useful 
> mailing list.)
> 
> * it seems that lines(lowess()) fails to plot
> certain line segments.  (and, 
> what does it do at the x-min and x-max of a data
> set?)  Rather than speculate 
> what causes it, I am including a short R snippet and
> a short data set that 
> demonstrates it.  is this a bug or a feature?
> 
> * it would be nice if lowess was a little better
> documented.  I have easy 
> access to Becker-Chambers-Wilks, but not to JASA and
> AS.  I wish "?lowess" 
> would tell me a little more about the method.
> 
> thanks in advance.
> 
> regards, /iaw
> 
> -------- test.R
> test <- read.table(file="test.txt", sep="\t",
> header=T);
> plot( test$x, test$y, log="xy");
> lines( lowess( test$x, test$y, f=0.5 ) );
> 
> -------- test.txt
> x	y
> 5584440	5000
> 2300100	1
> 37320	3977
> 92500	1
> 38440	1
> 70000	1
> 161282	151759
> 963000	7453
> 200000	5000
> 162000	1
> 29100	1200
> 20000	1
> 7921000	8112906
> 100000	1
> 426500	1
> 200000	1
> 450000	1
> 1900000	1
> 220001	2000
> 109901	13463
> 16300	6965
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From lockwood at rand.org  Wed Nov 26 18:26:45 2003
From: lockwood at rand.org (J.R. Lockwood)
Date: Wed, 26 Nov 2003 12:26:45 -0500 (EST)
Subject: [R] R 1.8.1 on SUSE 9.0
Message-ID: <Pine.LNX.4.33.0311261220150.12917-100000@penguin.rand.org>

Hello,

I recently did a full install of SUSE 9.0 and want to get R up and
running.  An attempted install of R-base-1.8.1-1.i586.rpm resulted in:

####
error: Failed dependencies:
        libg2c.so.0 is needed by R-base-1.8.1-1
####

And a ./configure in the source directory of R-1.8.1 failed with

####
configure: error: Neither an F77 compiler nor f2c found
####

I guess SUSE 9.0 does not come with the required fortran
libraries/compilers.  Can someone point me in the direction of
packages I need to install to get R running (either by installing the
binaries or compiling from source)?  Thanks to all.

J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org
http://www.rand.org/methodology/stat/members/lockwood/



From jfri at novozymes.com  Wed Nov 26 18:37:31 2003
From: jfri at novozymes.com (JFRI (Jesper Frickmann))
Date: Wed, 26 Nov 2003 12:37:31 -0500
Subject: [R] R 1.8.1 on SUSE 9.0
Message-ID: <D53147E531BFBC4B8853FD134FAEE44D1547A8@exusfr014.novo.dk>

If you go to http://www.rpmfind.net/ and search for libg2c.so.0, it
finds
http://speakeasy.rpmfind.net//linux/RPM/mandrake/9.1/i586/Mandrake/RPMS/
libf2c0-3.2.2-3mdk.i586.html

BR Jesper

-----Original Message-----
From: J.R. Lockwood [mailto:lockwood at rand.org] 
Sent: Wednesday, November 26, 2003 12:27 PM
To: r-help at stat.math.ethz.ch
Subject: [R] R 1.8.1 on SUSE 9.0


Hello,

I recently did a full install of SUSE 9.0 and want to get R up and
running.  An attempted install of R-base-1.8.1-1.i586.rpm resulted in:

####
error: Failed dependencies:
        libg2c.so.0 is needed by R-base-1.8.1-1
####

And a ./configure in the source directory of R-1.8.1 failed with

####
configure: error: Neither an F77 compiler nor f2c found
####

I guess SUSE 9.0 does not come with the required fortran
libraries/compilers.  Can someone point me in the direction of packages
I need to install to get R running (either by installing the binaries or
compiling from source)?  Thanks to all.

J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org http://www.rand.org/methodology/stat/members/lockwood/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ahenningsen at agric-econ.uni-kiel.de  Wed Nov 26 18:49:02 2003
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Wed, 26 Nov 2003 18:49:02 +0100
Subject: [R] R 1.8.1 on SUSE 9.0
In-Reply-To: <Pine.LNX.4.33.0311261220150.12917-100000@penguin.rand.org>
References: <Pine.LNX.4.33.0311261220150.12917-100000@penguin.rand.org>
Message-ID: <200311261849.02919.ahenningsen@agric-econ.uni-kiel.de>

Hi,

you have to install a Fortran compiler. 
It is available on the DVD/CD as package "gcc-g77".

Best wishes,
Arne

On Wednesday 26 November 2003 18:26, J.R. Lockwood wrote:
> Hello,
>
> I recently did a full install of SUSE 9.0 and want to get R up and
> running.  An attempted install of R-base-1.8.1-1.i586.rpm resulted in:
>
> ####
> error: Failed dependencies:
>         libg2c.so.0 is needed by R-base-1.8.1-1
> ####
>
> And a ./configure in the source directory of R-1.8.1 failed with
>
> ####
> configure: error: Neither an F77 compiler nor f2c found
> ####
>
> I guess SUSE 9.0 does not come with the required fortran
> libraries/compilers.  Can someone point me in the direction of
> packages I need to install to get R running (either by installing the
> binaries or compiling from source)?  Thanks to all.
>
> J.R. Lockwood
> 412-683-2300 x4941
> lockwood at rand.org
> http://www.rand.org/methodology/stat/members/lockwood/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From ivo.welch at yale.edu  Wed Nov 26 18:54:39 2003
From: ivo.welch at yale.edu (ivo welch)
Date: Wed, 26 Nov 2003 12:54:39 -0500
Subject: [R] re: lines(lowess())
Message-ID: <3FC4E8DF.8020200@yale.edu>


beginner's mistake on my part.  the fitted turned out to have negative values 
in it, so the logplot failed.  apologies.

it still would be nice to have more docs on lowess, but this has nothing to do 
with my question.

regards, /iaw



From fml at sanger.ac.uk  Wed Nov 26 19:12:39 2003
From: fml at sanger.ac.uk (Fergus Lippi)
Date: Wed, 26 Nov 2003 18:12:39 -0000
Subject: [R] cumulative relative frequency curve(ogive) 
Message-ID: <131DF14ECE564A4D8F35376FD3465172018996F3@EXCHSRV1.internal.sanger.ac.uk>

Hi, 

I have a set of experiments showing a bimodal behaviour and would like
to draw a cumulative relative frequency curve(ogive).

I would also like to read off my lower limit a the 2.5% point and the
upper at 97.5%  in oredr to have a 5% sig level.

Does anyone know if there is a function around that can perform either
of these operations.

I also know that the stepfun library has got the ecdf function which
probably only needs a few modifications to make the ogive(?)

Thank you in advance,

Fergus



From spencer.graves at pdf.com  Wed Nov 26 19:30:15 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 Nov 2003 10:30:15 -0800
Subject: [R] re: lines(lowess())
In-Reply-To: <3FC4E8DF.8020200@yale.edu>
References: <3FC4E8DF.8020200@yale.edu>
Message-ID: <3FC4F137.9030606@pdf.com>

      Did you try Google?  For me just now, Google produced "about 
9,800" hits, the first 10 of which seemed to be relevant;  I didn't look 
beyond that.  Lowess (sometimes called "loess") is a relatively old 
technique and has been documented in many places.  Many books on 
"exploratory data analysis" discuss it. 

      hope this helps.  spencer graves

ivo welch wrote:

>
> beginner's mistake on my part.  the fitted turned out to have negative 
> values in it, so the logplot failed.  apologies.
>
> it still would be nice to have more docs on lowess, but this has 
> nothing to do with my question.
>
> regards, /iaw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jasont at indigoindustrial.co.nz  Wed Nov 26 19:29:21 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 27 Nov 2003 07:29:21 +1300
Subject: [R] creating graphs in BATCH mode
In-Reply-To: <200311261511.38845.reinhard@meinberlikomm.de>
References: <200311261511.38845.reinhard@meinberlikomm.de>
Message-ID: <3FC4F101.7040508@indigoindustrial.co.nz>

Reinhard Sy wrote:

> Hi 
>  a short question is there a way to generate jpeg's etc. in BATCH mode ? The 
> following example does not work in BATCH:
...
> Error in jpeg("/tmp/my.jpg") : R_X11 module cannot be loaded
> In addition: Warning message: 
> X11 module is not available under this GUI 
> Execution halted
> *rsy at puffin*[15:09][~][57]>

Under Unix and Unix-like systems, R needs a running X server to produce 
JPEGs.  You needn't start the X-server; check out XVFB - X Virtual Frame 
Buffer - which sets up a virtual X server, but with no display.  You may 
already have this installed:  "man Xvfb" will tell you.

http://www.visualmining.com/support/server/XvfbonUnix.html

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From washington.santos at posgrad.ufla.br  Wed Nov 26 19:25:02 2003
From: washington.santos at posgrad.ufla.br (Washington Santos Da Silva)
Date: Wed, 26 Nov 2003 15:25:02 -0300
Subject: [R] lsmeans
Message-ID: <20031126181830.M49046@posgrad.ufla.br>

Dear list,

Is there a function (or an equivalent way) in R resembling the lsmeans 
command in SAS? The objective is to get the (adjusted) means for design 
models. Thanks in advance.

Regards,

Washington Santos da Silva.



From jfox at mcmaster.ca  Wed Nov 26 20:17:43 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 26 Nov 2003 14:17:43 -0500
Subject: [R] lsmeans
In-Reply-To: <20031126181830.M49046@posgrad.ufla.br>
Message-ID: <5.0.2.1.0.20031126141447.00b1ea00@127.0.0.1>

Dear Washington,

Take a look at the effects package, which will compute adjusted means (and 
more general adjusted "effects"). There's an article describing the package 
in the Journal of Statistical Software, at 
<http://www.jstatsoft.org/v08/i15/effect-displays-revised.pdf>.

I hope that this helps,
  John

At 03:25 PM 11/26/2003 -0300, Washington Santos Da Silva wrote:
>Dear list,
>
>Is there a function (or an equivalent way) in R resembling the lsmeans
>command in SAS? The objective is to get the (adjusted) means for design
>models. Thanks in advance.

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From washington.santos at posgrad.ufla.br  Wed Nov 26 19:53:34 2003
From: washington.santos at posgrad.ufla.br (Washington Santos Da Silva)
Date: Wed, 26 Nov 2003 15:53:34 -0300
Subject: [R] lsmeans
Message-ID: <20031126185217.M35367@posgrad.ufla.br>

Thank you very much (John Fox and Andy Liaw) for your help.

Regards,

Washington Santos da Silva



From roger at ysidro.econ.uiuc.edu  Wed Nov 26 20:44:45 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed, 26 Nov 2003 13:44:45 -0600 (CST)
Subject: [R] excluding libraries at configure
Message-ID: <Pine.SOL.4.30.0311261336340.24078-100000@ysidro.econ.uiuc.edu>

I'm trying build R-1.8.1 on a apple g4 that I've just upgraded
to panther.  Configure quits with complaints about  "linking
to Fortran libraries from C fails".  Based on some comparisons
with a fresh g5 install that worked...I conjecture that this
is due to the fact that /sw/lib on the g4 contains lots of stuff from
the prior jaguar installation, and ./configure wants to include
-L/sw/lib.

So my question is this:  is there way to tell configure politely
to not look in /sw/lib?  Or is there another suggestion entirely?

url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From p.dalgaard at biostat.ku.dk  Wed Nov 26 21:35:25 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Nov 2003 21:35:25 +0100
Subject: [R] re: lines(lowess())
In-Reply-To: <3FC4F137.9030606@pdf.com>
References: <3FC4E8DF.8020200@yale.edu> <3FC4F137.9030606@pdf.com>
Message-ID: <x28ym26f76.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

>       Did you try Google?  For me just now, Google produced "about
> 9,800" hits, the first 10 of which seemed to be relevant;  I didn't
> look beyond that.  Lowess (sometimes called "loess") is a relatively
> old technique and has been documented in many places.  Many books on
> "exploratory data analysis" discuss it.     hope this helps.  spencer
> graves

Incidentally, "lowess" is a misunderstanding. "Loess" is a
transcription of Hungarian "L?ss" (with o-diaeresis or possibly the
Hungarian accent that is like a double grave accent). I.e. it's a one
syllable word where the vowel got transcribed as an oe ligature as in
"hors d'oeuvre". However people who didn't know pronounced it lo-ess,
and... 

The thing itself is a kind of silt that gets carried by the wind,
forming a sediment layer which smooths the underlying rock surface.
Primary example is the Great Hungarian Plains (puszta), but there are
also Loess Hills in Iowa.

Undoubtedly, some guy from .hu will correct me Real Soon Now...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Wed Nov 26 21:49:42 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 Nov 2003 12:49:42 -0800
Subject: [R] re: lines(lowess())
In-Reply-To: <x28ym26f76.fsf@biostat.ku.dk>
References: <3FC4E8DF.8020200@yale.edu> <3FC4F137.9030606@pdf.com>
	<x28ym26f76.fsf@biostat.ku.dk>
Message-ID: <3FC511E6.8050607@pdf.com>

Dear Peter: 

      English is almost certainly one of the supreme bastard languages 
on the face of the earth.  The ancient Celtic (or whatever it was) was 
contaminated by Latin roughly 2,000 years ago and then by the 
Anglo-Saxon invasion from Schleswig-Holstein and Saxony, just south of 
modern Denmark, beginning in the fifth century AD, and then by the 
Norman conquest in 1066, following which the King's English was French.  
The Norman conquest was led by William the Conqueror, Guillaume le 
Batard, as the French say.  I am close to 3/4 British plus 1/4 German.  
A Danish friend ensures me he knows the source of my flaming red hair 
(what's left of it.)  There is strength in diversity (or at least that's 
what I tell myself). 

      Best Wishes,
      Spencer Graves

Peter Dalgaard wrote:

>Spencer Graves <spencer.graves at pdf.com> writes:
>
>  
>
>>      Did you try Google?  For me just now, Google produced "about
>>9,800" hits, the first 10 of which seemed to be relevant;  I didn't
>>look beyond that.  Lowess (sometimes called "loess") is a relatively
>>old technique and has been documented in many places.  Many books on
>>"exploratory data analysis" discuss it.     hope this helps.  spencer
>>graves
>>    
>>
>
>Incidentally, "lowess" is a misunderstanding. "Loess" is a
>transcription of Hungarian "L?ss" (with o-diaeresis or possibly the
>Hungarian accent that is like a double grave accent). I.e. it's a one
>syllable word where the vowel got transcribed as an oe ligature as in
>"hors d'oeuvre". However people who didn't know pronounced it lo-ess,
>and... 
>
>The thing itself is a kind of silt that gets carried by the wind,
>forming a sediment layer which smooths the underlying rock surface.
>Primary example is the Great Hungarian Plains (puszta), but there are
>also Loess Hills in Iowa.
>
>Undoubtedly, some guy from .hu will correct me Real Soon Now...
>
>  
>



From solares at unsl.edu.ar  Wed Nov 26 23:08:50 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Wed, 26 Nov 2003 19:08:50 -0300 (ART)
Subject: [R] multiple peaks in data frame
Message-ID: <46589.170.210.173.216.1069884530.squirrel@wiki.unsl.edu.ar>

Hello, it wanted to know how I can extract of a dates frame the values 
peaks according to an interval that I
establish.  For example if dates are: 
1 23
 2 4
 3 56
 4 7
 5 99
 6 33
 extract the date i wanted to divide into intervals of 2 an
d to take alone the numbers 23, 56 and 99 of those 3 intervals.  Thanks 
Ruben



From cortuno at sma.df.gob.mx  Wed Nov 26 23:49:44 2003
From: cortuno at sma.df.gob.mx (=?iso-8859-1?Q?Cristina_Ortu=F1o_Mojica?=)
Date: Wed, 26 Nov 2003 16:49:44 -0600
Subject: [R] multiple peaks in data frame
In-Reply-To: <46589.170.210.173.216.1069884530.squirrel@wiki.unsl.edu.ar>
Message-ID: <DPEPJLBCAOJJFKMHNFDJAENNCEAA.cortuno@sma.df.gob.mx>

Maybe, i can help (even when i'm not expert in R neither in english, just a
beginner)

But i use SPlus more then R, so i'm not sure if it works in R

example:

>dta<-c(23,4,56,7,99,33)
>interv<-2
>steps<-seq(1,length(dta),interv)
> dta[steps]
[1] 23 56 99


Regards

Cristina Ortu?o Mojica
Air Quality Monitoring Network in
Mexico City metropolitan area
Ministery of Environmental, Mexico City
Tel. (+52) 55-52099903 xt. 6225
Fax. (+52) 55-55111460
Jalapa #15, 2nd floor Col Roma
C.P. 06700 Mexico D. F.
Our Internet URL: http://www.sma.df.gob.mx/


-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]En nombre de
solares at unsl.edu.ar
Enviado el: Mi?rcoles, 26 de Noviembre de 2003 16:09
Para: R-help at stat.math.ethz.ch
Asunto: [R] multiple peaks in data frame


Hello, it wanted to know how I can extract of a dates frame the values
peaks according to an interval that I
establish.  For example if dates are:
1 23
 2 4
 3 56
 4 7
 5 99
 6 33
 extract the date i wanted to divide into intervals of 2 an
d to take alone the numbers 23, 56 and 99 of those 3 intervals.  Thanks
Ruben

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ggrothendieck at myway.com  Thu Nov 27 00:00:40 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 26 Nov 2003 18:00:40 -0500 (EST)
Subject: [R] multiple peaks in data frame
Message-ID: <20031126230040.019443992@mprdmxin.myway.com>


Not entirely sure what you need.  

This gives data greater than a certain level:

z <- c(23,4,56,7,99)
z[z>20]
or
z[z>=median(z)]

This extracts points that are larger than the ones on either 
side:

zz <- c(-Inf,z,-Inf)
z[diff(sign(diff(zz)))<0]

---

Date: Wed, 26 Nov 2003 19:08:50 -0300 (ART) 
From: <solares at unsl.edu.ar>
To: <R-help at stat.math.ethz.ch> 
Subject: [R] multiple peaks in data frame 

 
 
Hello, it wanted to know how I can extract of a dates frame the values 
peaks according to an interval that I
establish. For example if dates are: 
1 23
2 4
3 56
4 7
5 99
6 33
extract the date i wanted to divide into intervals of 2 an
d to take alone the numbers 23, 56 and 99 of those 3 intervals. Thanks 
Ruben



From Mark.Wilkinson at stjude.org  Thu Nov 27 00:30:15 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Wed, 26 Nov 2003 17:30:15 -0600
Subject: [R] multiple peaks in data frame
Message-ID: <F2235647AC878D438F09255C39842FBC1DD257@SJMEMXMB03.stjude.sjcrh.local>

I don't quite understand your English, but I'll take a stab at answering your question.  If by "date" you mean "data" and by "peaks" "maxima," then

df <- data.frame(V1=c(23, 4, 56, 7, 99, 33))
interval <- 2
if (nrow(df) %% interval == 0) 
tapply(df$V1, rep(1:(nrow(df) / interval), each=interval), max)

might be what you need.


Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent those of St. Jude Children's Research Hospital.


 -----Original Message-----
From: 	solares at unsl.edu.ar [mailto:solares at unsl.edu.ar] 
Sent:	Wednesday, November 26, 2003 4:09 PM
To:	R-help at stat.math.ethz.ch
Subject:	[R] multiple peaks in data frame

Hello, it wanted to know how I can extract of a dates frame the values 
peaks according to an interval that I
establish.  For example if dates are: 
1 23
 2 4
 3 56
 4 7
 5 99
 6 33
 extract the date i wanted to divide into intervals of 2 an
d to take alone the numbers 23, 56 and 99 of those 3 intervals.  Thanks 
Ruben

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ggrothendieck at myway.com  Thu Nov 27 01:22:01 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 26 Nov 2003 19:22:01 -0500 (EST)
Subject: [R] multiple peaks in data frame
Message-ID: <20031127002201.0329F39B4@mprdmxin.myway.com>


Here is a minor simplification of the last statement:

df <- data.frame(V1=c(23, 4, 56, 7, 99, 33))
interval <- 2
if (nrow(df) %% interval == 0) 
     apply(matrix(df$V1,interval),2,max)

---
Date: Wed, 26 Nov 2003 17:30:15 -0600 
From: Wilkinson, Mark <Mark.Wilkinson at stjude.org>
To: <solares at unsl.edu.ar>, <R-help at stat.math.ethz.ch> 
Subject: RE: [R] multiple peaks in data frame 

 
 
I don't quite understand your English, but I'll take a stab at answering your question. If by "date" you mean "data" and by "peaks" "maxima," then

df <- data.frame(V1=c(23, 4, 56, 7, 99, 33))
interval <- 2
if (nrow(df) %% interval == 0) 
tapply(df$V1, rep(1:(nrow(df) / interval), each=interval), max)

might be what you need.


Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent those of St. Jude Children's Research Hospital.


-----Original Message-----
From:      solares at unsl.edu.ar [mailto:solares at unsl.edu.ar] 
Sent:     Wednesday, November 26, 2003 4:09 PM
To:     R-help at stat.math.ethz.ch
Subject:     [R] multiple peaks in data frame

Hello, it wanted to know how I can extract of a dates frame the values 
peaks according to an interval that I
establish. For example if dates are: 
1 23
2 4
3 56
4 7
5 99
6 33
extract the date i wanted to divide into intervals of 2 an
d to take alone the numbers 23, 56 and 99 of those 3 intervals. Thanks 
Ruben



From tlumley at u.washington.edu  Thu Nov 27 02:04:29 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 26 Nov 2003 17:04:29 -0800 (PST)
Subject: [R] excluding libraries at configure
In-Reply-To: <Pine.SOL.4.30.0311261336340.24078-100000@ysidro.econ.uiuc.edu>
References: <Pine.SOL.4.30.0311261336340.24078-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.A41.4.58.0311261701590.41664@homer19.u.washington.edu>

On Wed, 26 Nov 2003, Roger Koenker wrote:

> I'm trying build R-1.8.1 on a apple g4 that I've just upgraded
> to panther.  Configure quits with complaints about  "linking
> to Fortran libraries from C fails".  Based on some comparisons
> with a fresh g5 install that worked...I conjecture that this
> is due to the fact that /sw/lib on the g4 contains lots of stuff from
> the prior jaguar installation, and ./configure wants to include
> -L/sw/lib.

This doesn't answer your question but might solve your problem: this
symptom occurs for a number of people who have installed teTeX using the
i-installer distribution.  One of the optional packages is `wmf + iconv
support" which installs an incompatible version of libiconv in
/usr/local/lib.  Removing this works for us.

	-thomas



From roger at ysidro.econ.uiuc.edu  Thu Nov 27 02:58:13 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed, 26 Nov 2003 19:58:13 -0600 (CST)
Subject: [R] excluding libraries at configure
In-Reply-To: <Pine.A41.4.58.0311261701590.41664@homer19.u.washington.edu>
Message-ID: <Pine.SOL.4.30.0311261952560.24706-100000@ysidro.econ.uiuc.edu>


Thanks Thomas...but it was simpler that this...as Don MacQueen suggested
it was just a matter of renaming /sw and then reconfiguring...


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Wed, 26 Nov 2003, Thomas Lumley wrote:

> On Wed, 26 Nov 2003, Roger Koenker wrote:
>
> > I'm trying build R-1.8.1 on an apple g4 that I've just upgraded
> > to panther.  Configure quits with complaints about  "linking
> > to Fortran libraries from C fails".  Based on some comparisons
> > with a fresh g5 install that worked...I conjecture that this
> > is due to the fact that /sw/lib on the g4 contains lots of stuff from
> > the prior jaguar installation, and ./configure wants to include
> > -L/sw/lib.
>
> This doesn't answer your question but might solve your problem: this
> symptom occurs for a number of people who have installed teTeX using the
> i-installer distribution.  One of the optional packages is `wmf + iconv
> support" which installs an incompatible version of libiconv in
> /usr/local/lib.  Removing this works for us.
>
> 	-thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jwdougherty at mcihispeed.net  Thu Nov 27 03:11:50 2003
From: jwdougherty at mcihispeed.net (John Dougherty)
Date: Wed, 26 Nov 2003 18:11:50 -0800
Subject: [R] R 1.8.1 on SUSE 9.0
In-Reply-To: <Pine.LNX.4.33.0311261220150.12917-100000@penguin.rand.org>
References: <Pine.LNX.4.33.0311261220150.12917-100000@penguin.rand.org>
Message-ID: <200311261811.51008.jwdougherty@mcihispeed.net>

I have 1.8.1 running on SuSE 9.0 as I write.  I use the "Professional" 
release, which comes with most development packages, certainly all the ones 
needed to compile R-1.8.1.  If you do not have the "Professional" version, 
you will have to acquire the full collection.  You can use YaST to check what 
is available.  Bring up the YaST window and highlight "Software," then in the 
right hand window "Install and Remove Software."  When the window comes up, 
click on the "filter" box and use the search facility.  I would point out 
though that I have R-1.8.1 running as I write and YaST search tells me that 
the librbary you listed is not present on my system either.  What OS are you 
running?

John

On Wednesday 26 November 2003 09:26, J.R. Lockwood wrote:
> Hello,
>
> I recently did a full install of SUSE 9.0 and want to get R up and
> running.  An attempted install of R-base-1.8.1-1.i586.rpm resulted in:
>
> ####
> error: Failed dependencies:
>         libg2c.so.0 is needed by R-base-1.8.1-1
> ####
>
> And a ./configure in the source directory of R-1.8.1 failed with
>
> ####
> configure: error: Neither an F77 compiler nor f2c found
> ####
>
> I guess SUSE 9.0 does not come with the required fortran
> libraries/compilers.  Can someone point me in the direction of
> packages I need to install to get R running (either by installing the
> binaries or compiling from source)?  Thanks to all.
>
> J.R. Lockwood
> 412-683-2300 x4941
> lockwood at rand.org
> http://www.rand.org/methodology/stat/members/lockwood/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dmurdoch at pair.com  Thu Nov 27 05:33:25 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 26 Nov 2003 23:33:25 -0500
Subject: [R] Syntax error from the following command running on Win XP:
	Rcmd BATCH a:test.r
In-Reply-To: <3FC45A1A.4050203@statistik.uni-dortmund.de>
References: <OF3CD10F94.464D7B6C-ONCA256DEA.001370F2-CA256DEA.00140AE2@mackillop.acu.edu.au>
	<3FC45A1A.4050203@statistik.uni-dortmund.de>
Message-ID: <hfvasvkejm22tngei15n5ve71l275rev47@4ax.com>

On Wed, 26 Nov 2003 08:45:30 +0100, Uwe Ligges
<ligges at statistik.uni-dortmund.de> wrote:

>Learn how to specify paths in Windows:
>Rcmd BATCH a:\test.R

Both a:test.R and a:\test.R are valid paths in Windows, and they may
mean different things.  The first looks in the current directory on
A:, the second looks in the root of A:.

>BTW: If a: is a flopp drive, I'd highly recommend to copy files to a 
>hard disk before working with them ...

That's good advice.

Duncan Murdoch



From rxg218 at psu.edu  Thu Nov 27 06:24:01 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: 27 Nov 2003 00:24:01 -0500
Subject: [R] sorting a list structure based on one of its components
Message-ID: <1069910641.2829.3.camel@localhost.localdomain>

Hi,
  is the following possible?

I have a list of vectors which may be numeric or character. Is there any
way I can sort all the vectors based on a certain numeric vector?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
I saw Elvis. He sat between me and Bigfoot on the UFO.



From ggrothendieck at myway.com  Thu Nov 27 06:44:01 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 27 Nov 2003 00:44:01 -0500 (EST)
Subject: [R] sorting a list structure based on one of its components
Message-ID: <20031127054401.694303984@mprdmxin.myway.com>


Assuming you want to order the components of my.list according
to the order of the third one:

lapply( my.list, function(x) x[order(my.list[[3]])] )



 --- On Thu 11/27, Rajarshi Guha < rxg218 at psu.edu > wrote:
From: Rajarshi Guha <rxg218 at psu.edu>
To: R <r-help at stat.math.ethz.ch> 
Subject: [R] sorting a list structure based on one of its components 

 
 
Hi,
is the following possible?

I have a list of vectors which may be numeric or character. Is there any
way I can sort all the vectors based on a certain numeric vector?

Thanks,



From antoniamarija at net.hr  Thu Nov 27 07:48:02 2003
From: antoniamarija at net.hr (Antonia Drugica)
Date: Thu, 27 Nov 2003 07:48:02 +0100
Subject: [R] FDA and ICH Compliance of R
Message-ID: <3fc59e22.1512.0@net.hr>

I'm quite new to this medical stuff. But my associates told me that we are
not free in choice of Statistical Software because the FDA has high
standards concerning this topic. But if they would prefer a specific
package (like SAS) that could mean, that this package vendourer could lay
back and hold it's hand open for licence money.

Is there any part of the ICH document referring to software packages? I
really would use R for some tasks but therefor I need arguments...




>"Antonia Drugica" <antoniamarija at net.hr> writes:
>
>> Does anybody know if R is FDA or ICH (or EMEA...) compliant? AFAIK
S-Plus
>> is but that means nothing...
>
>As Thomas pointed out, that does mean nothing -- there was a group of
>folks discussing what might be done to help, earlier this year, but
>then everyone got busy...
>
>best,
>-tony
>
>-- 
>rossini at u.washington.edu            http://www.analytics.washington.edu/ 
>Biomedical and Health Informatics   University of Washington
>Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
>UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
>FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
>
>CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

--
Trebate bolji pristup internetu?
Nazovite IskonInternet na 0800 1000 ili pogledajte
http://www.iskon.biz/individualni/usluge/dialup/



From kuenzli at stat.math.ethz.ch  Thu Nov 27 08:27:11 2003
From: kuenzli at stat.math.ethz.ch (Christina Kuenzli)
Date: Thu, 27 Nov 2003 08:27:11 +0100
Subject: [R] Workshop on Statistics in Functional Genomics 2004
Message-ID: <16325.42831.499483.52813@gargle.gargle.HOWL>

Apologies in advance if you receive multiple copies of this email.

This is to announce and invite your participation in a workshop on
Statistics in Functional Genomics, to be held from 27 June - 2 July
2004 at Ascona in the Italian-speaking part of Switzerland.
The purpose of the workshop is to bring together participants
from statistics, computational sciences, bioinformatics and
biology, and aim to encourage interaction among them.

Confirmed invited speakers include: Philip Brown (Kent),
Sandrine Dudoit (Berkeley), Robert Gentleman (Harvard),
Othmar Pfannes (GeneData), Sylvia Richardson (Imperial College),
Terry Speed (Berkeley), Martin Vingron (Max Planck Institute),
Anja Wille (ETH Zurich).  Other acceptances are pending.
Contributed presentations will also be welcome.

More details and pre-registration instructions are available at
http://www.stat.math.ethz.ch/talks/Ascona_04

Peter B?hlmann
Anthony Davison
Darlene Goldstein



Eidgenoessische Technische Hochschule Zuerich
Swiss Federal Institute of Technology  Zurich
________________________________________________________
Christina Kuenzli            <kuenzli at stat.math.ethz.ch>
Seminar fuer Statistik      
Leonhardstr. 27,  LEO D11          phone: +41 1 632 3438         
ETH Zentrum,                       fax  : +41 1 632 1228 
CH-8092 Zurich, Switzerland        http://stat.ethz.ch/



From mendigo at netcabo.pt  Thu Nov 27 11:11:39 2003
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Thu, 27 Nov 2003 10:11:39 -0000
Subject: [R] would like to know how to simulated a GARCH(1,2) 
Message-ID: <001e01c3b4ce$de353f00$e9a716d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031127/91c97d48/attachment.pl

From Joerg.Rieckermann at eawag.ch  Thu Nov 27 11:34:35 2003
From: Joerg.Rieckermann at eawag.ch (Rieckermann Joerg)
Date: Thu, 27 Nov 2003 11:34:35 +0100
Subject: [R] multiple peaks in data frame
Message-ID: <79EACAE180E2CD48A096E486F53334AB2FA95F@hathor.eawag.wroot.emp-eaw.ch>

Hello!

why not try the R site search for "peaks":
http://finzi.psych.upenn.edu/search.html


which gives you (among other things):
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/7593.html

Hope this helps,
J.


Joerg Rieckermann
Environmental Engineering
Swiss Federal Institute for Environmental Science and Technology (EAWAG)



> -----Original Message-----
> From: solares at unsl.edu.ar [mailto:solares at unsl.edu.ar] 
> Sent: Mittwoch, 26. November 2003 23:09
> To: R-help at stat.math.ethz.ch
> Subject: [R] multiple peaks in data frame
> 
> 
> Hello, it wanted to know how I can extract of a dates frame 
> the values 
> peaks according to an interval that I
> establish.  For example if dates are: 
> 1 23
>  2 4
>  3 56
>  4 7
>  5 99
>  6 33
>  extract the date i wanted to divide into intervals of 2 an
> d to take alone the numbers 23, 56 and 99 of those 3 
> intervals.  Thanks 
> Ruben
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From pburns at pburns.seanet.com  Thu Nov 27 12:19:46 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 27 Nov 2003 11:19:46 +0000
Subject: [R] would like to know how to simulated a GARCH(1,2)
References: <001e01c3b4ce$de353f00$e9a716d5@galactic>
Message-ID: <3FC5DDD2.3090502@pburns.seanet.com>

Prelude for those not in the know:

GARCH models the variance of a times series
conditional on past information (often only the
series itself).  It is a reasonably good model of
the variance of the returns of market-priced
assets, which display big jumps upwards in
variance followed by gradual decays.

Rob Engle is just about to receive the Nobel Prize
in Economics for originating the model (without
the "G" for generalized).

The Answer:

You need to create a vector of conditional variances,
traditionally called "h".  So at the start you will have an
extra line:

h <- double(n)

in the for loop you will have:

h[i] <- a[1]+a[2]*x[i-1]^2+a[3]*x[i-2]^2 + b[1] * h[i-1]
x[i] <- e[i] * sqrt(h[i])

This leaves just one (I think) detail:

What is the initial value of h? This will depend on what you
are doing.  If you are simulating into the future, then you
want to use the (conditional) variance for the present.
Other choices can be the observed unconditional variance
and a random selection from the estimated conditional
variances that are observed.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

M. M. Palhoto N. Rodrigues wrote:

>Follow the example in tseries, we can simulated a GARCH(0,2),  
>n <- 1100
>a <- c(0.1, 0.5, 0.2)  # ARCH(2) coefficients
>e <- rnorm(n)  
>x <- double(n)
>x[1:2] <- rnorm(2, sd = sqrt(a[1]/(1.0-a[2]-a[3]))) 
>for(i in 3:n)  # Generate ARCH(2) process
>{
>  x[i] <- e[i]*sqrt(a[1]+a[2]*x[i-1]^2+a[3]*x[i-2]^2)
>}
>x <- ts(x[101:1100])
>and x is a GARCH(0,2).
>But, I would like to know how to simulated a GARCH(1,2) ?
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>



From spencer.graves at pdf.com  Thu Nov 27 12:24:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Nov 2003 03:24:02 -0800
Subject: [R] FDA and ICH Compliance of R
In-Reply-To: <3fc59e22.1512.0@net.hr>
References: <3fc59e22.1512.0@net.hr>
Message-ID: <3FC5DED2.7020005@pdf.com>

      Have you tried "www.r-project.org" -> search -> "R site search"?  
This issue has been discussed in the past.  With luck, you may find 
something there that might help. 

      hope this helps.  spencer graves

Antonia Drugica wrote:

>I'm quite new to this medical stuff. But my associates told me that we are
>not free in choice of Statistical Software because the FDA has high
>standards concerning this topic. But if they would prefer a specific
>package (like SAS) that could mean, that this package vendourer could lay
>back and hold it's hand open for licence money.
>
>Is there any part of the ICH document referring to software packages? I
>really would use R for some tasks but therefor I need arguments...
>
>
>
>
>  
>
>>"Antonia Drugica" <antoniamarija at net.hr> writes:
>>
>>    
>>
>>>Does anybody know if R is FDA or ICH (or EMEA...) compliant? AFAIK
>>>      
>>>
>S-Plus
>  
>
>>>is but that means nothing...
>>>      
>>>
>>As Thomas pointed out, that does mean nothing -- there was a group of
>>folks discussing what might be done to help, earlier this year, but
>>then everyone got busy...
>>
>>best,
>>-tony
>>
>>-- 
>>rossini at u.washington.edu            http://www.analytics.washington.edu/ 
>>Biomedical and Health Informatics   University of Washington
>>Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
>>UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
>>FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
>>
>>CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>    
>>
>
>--
>Trebate bolji pristup internetu?
>Nazovite IskonInternet na 0800 1000 ili pogledajte
>http://www.iskon.biz/individualni/usluge/dialup/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From stecalza at tiscali.it  Thu Nov 27 13:11:48 2003
From: stecalza at tiscali.it (Stefano Calza)
Date: Thu, 27 Nov 2003 13:11:48 +0100
Subject: [R] OT: apt-get and R in Debian
In-Reply-To: <6rptfpbwum.fsf@bates4.stat.wisc.edu>
References: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
	<6rptfpbwum.fsf@bates4.stat.wisc.edu>
Message-ID: <20031127121148.GA2530@med.unibs.it>

Hi everybody,

Sorry for the OffTopic, but I always have a problem using apt-get to 
update my debian siystem and R. 
Anytime it updates the packages (right now I installed a self-compiled 
version of 1.8.1), even if they are exactly the same. Anybody can help 
me?

TIA,
Stefano



From a.trapletti at bluewin.ch  Thu Nov 27 13:32:26 2003
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Thu, 27 Nov 2003 13:32:26 +0100
Subject: [R] Correlation test in time series
Message-ID: <3FC5EEDA.1010906@bluewin.ch>

>
>
>>> Thanks for you help,
>>> 
>>> And how to test covariance = zero in time series ,
>>> cov(r_t, r_t-1)=0
>>> and r_t  are homoscedastik and dependent ?
>>    
>>
>
>How about:
>
>?acf
>?pacf
>
>in package 'ts'
>  
>
Box.test from package 'ts'

best
Adrian

-- 
Dr. Adrian Trapletti
Trapletti Statistical Computing
Wildsbergstrasse 31, 8610 Uster
Switzerland
Phone & Fax : +41 (0) 1 994 5631
Mobile : +41 (0) 76 370 5631
Email : mailto:a.trapletti at bluewin.ch
WWW : http://trapletti.homelinux.com



From R.A.Sanderson at newcastle.ac.uk  Thu Nov 27 13:48:39 2003
From: R.A.Sanderson at newcastle.ac.uk (Roy Sanderson)
Date: Thu, 27 Nov 2003 12:48:39 +0000
Subject: [R] lagsarlm - using mixed explanatory variables (spdep package)
Message-ID: <3.0.3.32.20031127124839.00b01100@popin.ncl.ac.uk>

Hello

I'm very new to R (which is excellent), so apologies if this has already
been raised.  In the spdep package, I'm trying to undertake an
autoregressive mixed model using the lagsarlm function.  This is working
fine, but there does not appear to be a method of including an explanatory
variable without it automatically being included as a lagged term.  I'm
after something along the lines of

y = rho.W.y + x1 + x2 + lag(x2)

but am only able to output

y = rho.W.y + x1 + x2 + lag(x1) + lag(x2)

Is there any way around this issue?

Many thanks
Roy

----------------------------------------------------------------------------
Roy Sanderson
Centre for Life Sciences Modelling
Porter Building
University of Newcastle
Newcastle upon Tyne
NE1 7RU
United Kingdom

Tel: +44 191 222 7789

r.a.sanderson at newcastle.ac.uk
http://www.ncl.ac.uk/clsm



From p.dalgaard at biostat.ku.dk  Thu Nov 27 13:58:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Nov 2003 13:58:02 +0100
Subject: [R] Blocked Mail Notification
In-Reply-To: <200311271207.hARC7cg07275@scr.siemens.com>
References: <200311271207.hARC7cg07275@scr.siemens.com>
Message-ID: <x24qwq55ph.fsf@biostat.ku.dk>

sysadmin at scr.siemens.com writes:

> ************* eManager Notification **************
> 
> Recipient, Content filter has detected a sensitive e-mail.
> 
> Source mailbox: "r-help-bounces at stat.math.ethz.ch"
> Destination mailbox(es): "r-help at stat.math.ethz.ch"
> 
> ******************* End of message *******************
> 
> Received: from 129.73.8.34 by postoffice.scr.siemens.com (InterScan E-Mail VirusWall NT); Thu, 27 Nov 2003 06:12:27 -0500
> Received: from idmz1.scr.siemens.com ([129.73.8.9])
> 	by scr.siemens.com (8.11.7/8.11.7) with ESMTP id hARBCMg06444
> 	for <ralfk at imail.scr.siemens.com>; Thu, 27 Nov 2003 06:12:22 -0500 (EST)
> X-SCR-Return-Path:  <r-help-bounces at stat.math.ethz.ch>   (as seen by idmz1.scr.siemens.com) 
> Received: from hypatia.math.ethz.ch (hypatia.ethz.ch [129.132.58.23])
> 	by idmz1.scr.siemens.com (8.12.10/8.12.10) with ESMTP id hARBCTmN022366
> 	for <ralfk at scr.siemens.com>; Thu, 27 Nov 2003 06:12:30 -0500 (EST)
> Received: from hypatia.math.ethz.ch (hypatia [129.132.58.23])
> 	by hypatia.math.ethz.ch (8.12.10/8.12.10) with ESMTP id hARB53Cw016647;
> 	Thu, 27 Nov 2003 12:09:26 +0100 (MET)
> Date: Thu, 27 Nov 2003 12:09:26 +0100 (MET)
> Message-Id: <200311271109.hARB53Cw016647 at hypatia.math.ethz.ch>
> From: r-help-request at stat.math.ethz.ch
> Subject: R-help Digest, Vol 9, Issue 27
> To: r-help at stat.math.ethz.ch
> Reply-To: r-help at stat.math.ethz.ch
> MIME-Version: 1.0

[.... and proceeds to spew the entire digest message into r-help!]

Will someone please tell these guys how to configure their MTA
correctly (errors should *never* go to the Reply-To field), and/or
unsubscribe mr. ralfk at scr.siemens.com?

Grrr....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From a.trapletti at bluewin.ch  Thu Nov 27 13:56:08 2003
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Thu, 27 Nov 2003 13:56:08 +0100
Subject: [R] would like to know how to simulated a GARCH(1,2)
Message-ID: <3FC5F468.9070301@bluewin.ch>

>
>
>Follow the example in tseries, we can simulated a GARCH(0,2),  
>n <- 1100
>a <- c(0.1, 0.5, 0.2)  # ARCH(2) coefficients
>e <- rnorm(n)  
>x <- double(n)
>x[1:2] <- rnorm(2, sd = sqrt(a[1]/(1.0-a[2]-a[3]))) 
>for(i in 3:n)  # Generate ARCH(2) process
>{
>  x[i] <- e[i]*sqrt(a[1]+a[2]*x[i-1]^2+a[3]*x[i-2]^2)
>}
>x <- ts(x[101:1100])
>and x is a GARCH(0,2).
>But, I would like to know how to simulated a GARCH(1,2) ?
>
>  
>
GARCH(1,1) something like

n <- 1100
a <- c(0.1, 0.2, 0.7)

e <- rnorm(n) 
x <- double(n)
v <- double(n)

v[1] <- a[1]/(1.0-a[2]-a[3])
x[1] <- rnorm(1, sd = sqrt(v[1]))

for(i in 2:n) {
    v[i] <- a[1]+a[2]*x[i-1]^2+a[3]*v[i-1]
    x[i] <- e[i]*sqrt(v[i])
}

x <- ts(x[101:1100])
x.garch <- garch(x, order = c(1,1))
summary(x.garch)

and accordingly the GARCH(1,2)

best
Adrian

-- 
Dr. Adrian Trapletti
Trapletti Statistical Computing
Wildsbergstrasse 31, 8610 Uster
Switzerland
Phone & Fax : +41 (0) 1 994 5631
Mobile : +41 (0) 76 370 5631
Email : mailto:a.trapletti at bluewin.ch
WWW : http://trapletti.homelinux.com



From uth at zhwin.ch  Thu Nov 27 14:26:57 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Thu, 27 Nov 2003 14:26:57 +0100
Subject: [R] stl and NA
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F1AB8DD@langouste.zhwin.ch>


Hi,

I try to figure out what the stl-function exactly do.
I was reading the paper by Cleveland et al. (1990) and tested some features of stl (the ability to decompose time series with missing values and the robustness feature).

I tried the following:
> data(co2)
> co2.na <- co2
> is.na(co2.na[c(50, 100)]) <- TRUE
> plot(stl(co2.na, s.window = 12, na.action = na.exclude))

With the error message:
"Error in stl(co2.na, s.window = 12, na.action = na.exclude) : 
	series is not periodic or has less than two periods"

The following works fine:
> plot(stl(co2, s.window = 12))

I had then a short look in the code of stl. Is it true that the argument na.action must be a generic function, one of ?na.fail?

The help of stl:
"na.action   action on missing values."   (Mmmh, not really helpful)

The other functions na.omit and na.pass do not what I was expecting?!
> plot(stl(co2.na, s.window = 12, na.action = na.omit))
Error in na.omit.ts(as.ts(x)) : time series contains internal NAs


Is this feature correctly implemented? 
I do not found a bug report http://r-bugs.biostat.ku.dk/cgi-bin/R... So I assume that I'm missing something.  


How can I handle NAs in stl() correctly?


Thanks for any hints and comments

Thomas



From edd at debian.org  Thu Nov 27 15:03:29 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 27 Nov 2003 08:03:29 -0600
Subject: [R] OT: apt-get and R in Debian
In-Reply-To: <20031127121148.GA2530@med.unibs.it>
References: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
	<6rptfpbwum.fsf@bates4.stat.wisc.edu>
	<20031127121148.GA2530@med.unibs.it>
Message-ID: <20031127140329.GA6626@sonny.eddelbuettel.com>

On Thu, Nov 27, 2003 at 01:11:48PM +0100, Stefano Calza wrote:
> Sorry for the OffTopic, but I always have a problem using apt-get to 
> update my debian siystem and R. 
> Anytime it updates the packages (right now I installed a self-compiled 
> version of 1.8.1), even if they are exactly the same. Anybody can help 
> me?

We probably need more info to help you.  

I presume you have CRAN and Debian testing in /etc/apt/sources.list?  Did
you try to use the apt configuration to give preference to one archive over
another, or exclude one, or ...  See some of the available apt documents,
e.g. from the apt-howto package, should help. Also, 'apt-cache policy
r-base-core' will tell how apt sees and ranks the archives you have set up.

The easiest will probably be to simply exclude, say, CRAN.  

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From tlumley at u.washington.edu  Thu Nov 27 15:07:00 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 27 Nov 2003 06:07:00 -0800 (PST)
Subject: [R] FDA and ICH Compliance of R
In-Reply-To: <3fc59e22.1512.0@net.hr>
References: <3fc59e22.1512.0@net.hr>
Message-ID: <Pine.A41.4.58.0311270606080.28918@homer18.u.washington.edu>

On Thu, 27 Nov 2003, Antonia Drugica wrote:

> I'm quite new to this medical stuff. But my associates told me that we are
> not free in choice of Statistical Software because the FDA has high
> standards concerning this topic. But if they would prefer a specific
> package (like SAS) that could mean, that this package vendourer could lay
> back and hold it's hand open for licence money.
>
> Is there any part of the ICH document referring to software packages? I
> really would use R for some tasks but therefor I need arguments...

As far as I can see, ICH has not said anything useful about software (the
most relevant things are about data management).

	-thomas



From feh3k at spamcop.net  Thu Nov 27 15:04:38 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 27 Nov 2003 09:04:38 -0500
Subject: [R] FDA and ICH Compliance of R
In-Reply-To: <3fc59e22.1512.0@net.hr>
References: <3fc59e22.1512.0@net.hr>
Message-ID: <20031127090438.48d09ddf.feh3k@spamcop.net>

On Thu, 27 Nov 2003 07:48:02 +0100
"Antonia Drugica" <antoniamarija at net.hr> wrote:

> I'm quite new to this medical stuff. But my associates told me that we
> are not free in choice of Statistical Software because the FDA has high
> standards concerning this topic. But if they would prefer a specific
> package (like SAS) that could mean, that this package vendourer could
> lay back and hold it's hand open for licence money.

Your associates are completely wrong.  It is only sponsors that choose not
to be free in their choice, due in my humble opinion mainly to the fact
that SAS has been in use since 1966 and that "no one has ever been
criticized by the FDA for using SAS."  FDA even receives submissions based
on Excel and we all know about the accuracy of Excel's statistical
calculations.  High standards need to be held by statisticians doing the
analyses.  Related to such standards open source systems such as R have
many advantages, and the reproducible reporting capabilities of R using
its Sweave package have major impacts on accuracy of reporting.

I along with colleagues at another institution are working on an open
source R package for clinical trial analysis and reporting that should be
mature in about a year.  I am currently using the package in two
pharmaceutical industry-sponsored randomized clinical trials to report to
data monitoring committees.  I'm also working on a document addressing
validation of statistical calculations.  Let me know if you'd like a copy
of the current version of that document.

> 
> Is there any part of the ICH document referring to software packages? I
> really would use R for some tasks but therefor I need arguments...

Don't know of anything in ICH.

In view of the fact that large pharma companies have to pay more than $10M
per year in SAS licenses and have to hire armies of non-intellectually
challenged SAS programmers to do the work of significantly fewer
programmers that use modern statistical computing tools like R and S-Plus,
it is surprising that SAS is still the most commonly used tool in the
clinical side of drug development.  I quit using SAS in 1991 because my
productivity jumped at least 20% within one month of using S-Plus.
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From pato_mardeajo at tvc5sa.com.ar  Thu Nov 27 15:19:30 2003
From: pato_mardeajo at tvc5sa.com.ar (Patricia)
Date: Thu, 27 Nov 2003 11:19:30 -0300
Subject: [R] help me!
Message-ID: <000601c3b4f1$7bcc2400$9b0f2fc8@tvc5>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031127/d8d1fcd4/attachment.pl

From stecalza at tiscali.it  Thu Nov 27 15:44:38 2003
From: stecalza at tiscali.it (Stefano Calza)
Date: Thu, 27 Nov 2003 15:44:38 +0100
Subject: [R] OT: apt-get and R in Debian
In-Reply-To: <6rad6hc30h.fsf@bates4.stat.wisc.edu>
References: <5.1.0.14.1.20031118034019.024c6e90@l.imap.itd.umich.edu>
	<6rptfpbwum.fsf@bates4.stat.wisc.edu>
	<20031127121148.GA2530@med.unibs.it>
	<6rad6hc30h.fsf@bates4.stat.wisc.edu>
Message-ID: <20031127144438.GB541@med.unibs.it>

> Can you give us more details, please?  Which version of Debian
> (stable, testing or unstable) are you running and what are the
> relevant parts of your /etc/apt/sources.list file?  (Just send us the
> whole file if you are not sure what parts are relevant.)

Ok. Find attach my source.list + the output from apt-cache show 
r-base-core + apt-cache policy r-base-core.
I use Debian/testing version + some unstable package.

> 
> To others on the cc: list:  May I suggest that we ask Martin to create
> an email list with a name like r-debian for Debian-specific questions
> about R installation?

Yes, it would be a great idea!

Thanks,
Ste

> 
> -- 
> Douglas Bates                            bates at stat.wisc.edu
> Statistics Department                    608/262-2598
> University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/

-- 
Stefano Calza,
Sezione di Statistica Medica
Dip. di Scienze Biomediche e Biotecnologie
Universit? degli Studi di Brescia - Italy
Viale Europa, 11 25123 Brescia
email: calza at med.unibs.it
Telefono/Phone: +390303717532
Fax: +390303701157
-------------- next part --------------
deb http://ftp.it.debian.org/debian/ stable main non-free contrib
deb-src http://ftp.it.debian.org/debian/ stable main non-free contrib
deb http://non-us.debian.org/debian-non-US stable/non-US main contrib non-free
deb-src http://non-us.debian.org/debian-non-US stable/non-US main contrib non-free

deb http://ftp.it.debian.org/debian/ testing main non-free contrib
deb http://ftp.it.debian.org/debian-non-US testing/non-US main contrib non-free
deb-src http://ftp.it.debian.org/debian testing main contrib non-free
deb-src http://ftp.it.debian.org/debian-non-US testing/non-US main contrib non-free

deb http://ftp.it.debian.org/debian/ unstable main non-free contrib
deb http://ftp.it.debian.org/debian-non-US unstable/non-US main contrib non-free
deb-src http://ftp.it.debian.org/debian unstable main contrib non-free
deb-src http://ftp.it.debian.org/debian-non-US unstable/non-US main contrib non-free

# R

#deb http://cran.at.r-project.org/bin/linux/debian stable main
#deb http://cran.at.r-project.org/bin/linux/debian testing main
#deb http://cran.at.r-project.org/bin/linux/debian unstable main

deb http://security.debian.org/ stable/updates main contrib non-free


## Java Environment

#deb http://mirrors.publicshout.org/java-linux/debian testing main non-free
#deb http://mirrors.publicshout.org/java-linux/debian unstable main non-free

## Bioconductor

deb http://lab.analytics.washington.edu/debian-local ./
-------------- next part --------------
Package: r-base-core
Priority: optional
Section: math
Installed-Size: 23916
Maintainer: Dirk Eddelbuettel <edd at debian.org>
Architecture: i386
Source: r-base
Version: 1.8.0.cvs.20031114-1
Replaces: r-base (<= 1.4.1-1)
Depends: perl, zlib-bin, libbz2-1.0, libc6 (>= 2.3.2.ds1-4), libg2c0 (>= 1:3.3.2-1), libgcc1 (>= 1:3.3.2-1), libjpeg62, libncurses5 (>= 5.3.20030510-1), libpcre3 (>= 4.0), libpng10-0 (>= 1.0.15-4), libreadline4 (>= 4.3-1), tcl8.4 (>= 8.4.2), tk8.4 (>= 8.4.2), xlibs (>> 4.1.0), zlib1g (>= 1:1.1.4)
Recommends: r-recommended, r-base-dev
Suggests: libpaperg, ess, r-doc-info | r-doc-pdf | r-doc-html
Filename: pool/main/r/r-base/r-base-core_1.8.0.cvs.20031114-1_i386.deb
Size: 5939210
MD5sum: 8cc59556c1385f4ec50b84f69380c691
Description: GNU R core of statistical computing language and environment
 R is `GNU S' - A language and environment for statistical computing
 and graphics. R is similar to the award-winning S system, which was
 developed at Bell Laboratories by John Chambers et al. It provides a
 wide variety of statistical and graphical techniques (linear and
 nonlinear modelling, statistical tests, time series analysis,
 classification, clustering, ...).
 .
 R is designed as a true computer language with control-flow
 constructions for iteration and alternation, and it allows users to
 add additional functionality by defining new functions. For
 computationally intensive tasks, C, C++ and Fortran code can be
 linked and called at run time.
 .
 S is the statistician's Matlab and R is to S what Octave is to Matlab.
 .
 This package provides the core GNU R system from which only the optional
 documentation packages r-base-html, r-base-latex, r-doc-html, r-doc-pdf
 and r-doc-info have been split off to somewhat reduce the size of this
 package.

Package: r-base-core
Status: install ok installed
Priority: optional
Section: math
Installed-Size: 23912
Maintainer: Dirk Eddelbuettel <edd at debian.org>
Source: r-base
Version: 1.8.0.cvs.20031114-1
Replaces: r-base (<= 1.4.1-1)
Depends: perl, zlib-bin, libbz2-1.0, libc6 (>= 2.3.2.ds1-4), libg2c0 (>= 1:3.3.2-1), libgcc1 (>= 1:3.3.2-1), libjpeg62, libncurses5 (>= 5.3.20030510-1), libpcre3 (>= 4.0), libpng12-0 (>= 1.2.5.0-4), libreadline4 (>= 4.3-1), tcl8.4 (>= 8.4.2), tk8.4 (>= 8.4.2), xlibs (>> 4.1.0), zlib1g (>= 1:1.1.4)
Recommends: r-recommended, r-base-dev
Suggests: libpaperg, ess, r-doc-info | r-doc-pdf | r-doc-html
Conffiles:
 /etc/R/Makeconf c819eaeb69d4f1514795e3a9eb7e2c9c
 /etc/R/Renviron 8ca0b400f24f00d60a2bacdcbb03db85
Description: GNU R core of statistical computing language and environment
 R is `GNU S' - A language and environment for statistical computing
 and graphics. R is similar to the award-winning S system, which was
 developed at Bell Laboratories by John Chambers et al. It provides a
 wide variety of statistical and graphical techniques (linear and
 nonlinear modelling, statistical tests, time series analysis,
 classification, clustering, ...).
 .
 R is designed as a true computer language with control-flow
 constructions for iteration and alternation, and it allows users to
 add additional functionality by defining new functions. For
 computationally intensive tasks, C, C++ and Fortran code can be
 linked and called at run time.
 .
 S is the statistician's Matlab and R is to S what Octave is to Matlab.
 .
 This package provides the core GNU R system from which only the optional
 documentation packages r-base-html, r-base-latex, r-doc-html, r-doc-pdf
 and r-doc-info have been split off to somewhat reduce the size of this
 package.

Package: r-base-core
Priority: optional
Section: math
Installed-Size: 21944
Maintainer: Dirk Eddelbuettel <edd at debian.org>
Architecture: i386
Source: r-base
Version: 1.7.1-1
Replaces: r-base (<= 1.4.1-1)
Depends: perl, zlib-bin, atlas2-base | atlas2, libbz2-1.0, libc6 (>= 2.3.1-1), libg2c0 (>= 1:3.3-0pre9), libgcc1 (>= 1:3.3-0pre9), libjpeg62, libncurses5 (>= 5.3.20030510-1), libpcre3, libpng10-0 (>= 1.0.15-4), libreadline4 (>= 4.3-1), tcl8.4 (>= 8.4.2), tk8.4 (>= 8.4.2), xlibs (>> 4.1.0), zlib1g (>= 1:1.1.4)
Recommends: r-recommended, r-base-dev
Suggests: libpaperg, ess, r-doc-info | r-doc-pdf | r-doc-html
Filename: pool/main/r/r-base/r-base-core_1.7.1-1_i386.deb
Size: 5415844
MD5sum: c620e3533140e802038d0c0adce740a5
Description: GNU R core of statistical computing language and environment
 R is `GNU S' - A language and environment for statistical computing
 and graphics. R is similar to the award-winning S system, which was
 developed at Bell Laboratories by John Chambers et al. It provides a
 wide variety of statistical and graphical techniques (linear and
 nonlinear modelling, statistical tests, time series analysis,
 classification, clustering, ...).
 .
 R is designed as a true computer language with control-flow
 constructions for iteration and alternation, and it allows users to
 add additional functionality by defining new functions. For
 computationally intensive tasks, C, C++ and Fortran code can be
 linked and called at run time.
 .
 S is the statistician's Matlab and R is to S what Octave is to Matlab.
 .
 This package provides the core GNU R system from which only the optional
 documentation packages r-base-html, r-base-latex, r-doc-html, r-doc-pdf
 and r-doc-info have been split off to somewhat reduce the size of this
 package.

Package: r-base-core
Priority: optional
Section: math
Installed-Size: 19884
Maintainer: Dirk Eddelbuettel <edd at debian.org>
Architecture: i386
Source: r-base
Version: 1.5.1-0woody1
Replaces: r-base (<= 1.4.1-1)
Depends: perl, zlib-bin, atlas2-base | blas | blas2, libc6 (>= 2.2.4-4), libjpeg62, libncurses5 (>= 5.2.20020112a-1), libpng2(>=1.0.12), libreadline4 (>= 4.2a-4), tcl8.3 (>= 8.3.0), tk8.3 (>= 8.3.0), xlibs (>> 4.1.0), zlib1g (>= 1:1.1.4)
Recommends: r-recommended, r-base-dev
Filename: pool/main/r/r-base/r-base-core_1.5.1-0woody1_i386.deb
Size: 4697006
MD5sum: ccfd24d8fc00c30c7965854b10516d63
Description: GNU R core of statistical computing language and environment
 R is `GNU S' - A language and environment for statistical computing
 and graphics. R is similar to the award-winning S system, which was
 developed at Bell Laboratories by John Chambers et al. It provides a
 wide variety of statistical and graphical techniques (linear and
 nonlinear modelling, statistical tests, time series analysis,
 classification, clustering, ...).
 .
 R is designed as a true computer language with control-flow
 constructions for iteration and alternation, and it allows users to
 add additional functionality by defining new functions. For
 computationally intensive tasks, C, C++ and Fortran code can be
 linked and called at run time.
 .
 S is the statistician's Matlab and R is to S what Octave is to Matlab.
 .
 This package provides the core GNU R system from which only the optional
 documentation packages r-base-html, r-base-latex, r-doc-html, r-doc-pdf
 and r-doc-info have been split off to somewhat reduce the size of this
 package.

-------------- next part --------------
r-base-core:
  Installato: 1.8.0.cvs.20031114-1
  Candidato: 1.8.0.cvs.20031114-1
  Tabella Versione:
     1.8.0.cvs.20031114-1 0
        500 http://ftp.it.debian.org unstable/main Packages
 *** 1.8.0.cvs.20031114-1 0
        100 /var/lib/dpkg/status
     1.7.1-1 0
        990 http://ftp.it.debian.org testing/main Packages
     1.5.1-0woody1 0
        500 http://ftp.it.debian.org stable/main Packages

From ggrothendieck at myway.com  Thu Nov 27 15:59:57 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 27 Nov 2003 09:59:57 -0500 (EST)
Subject: [R] FDA and ICH Compliance of R
Message-ID: <20031127145957.8BA883965@mprdmxin.myway.com>


From: Frank E Harrell Jr <feh3k at spamcop.net>
> per year in SAS licenses and have to hire armies of non-intellectually
> challenged SAS programmers to do the work of significantly fewer
> programmers that use modern statistical computing tools like R and S-Plus,
> it is surprising that SAS is still the most commonly used tool in the
> clinical side of drug development. I quit using SAS in 1991 because my
> productivity jumped at least 20% within one month of using S-Plus.

I have not used SAS for even longer than you but to
give SAS its due:

- its pretty easy to produce all the info you need for a
  complete analysis with a few SAS commands.  It would be
  possible to create analogous R commands but as it stands
  you have to keep going back and forth with R rather than
  just get it all out at once like you can with SAS.

- SAS has more functionality in missing values.  You
  can have different types of SAS missing values but in R you
  can have only one type of missing value.

- the BY phrase in SAS is incredibly powerful and handy.  You
  can get the same effect in R but I think that specific
  functionality is easier with SAS.

Obviously R is incredibly powerful and functional and I really
am out of touch with the SAS world but I thought I would make
whatever case I could.  I am willing to be corrected by those 
more in the know with SAS if this wrong.



From aurelie.defferrard at bayercropscience.com  Thu Nov 27 16:10:51 2003
From: aurelie.defferrard at bayercropscience.com (aurelie.defferrard@bayercropscience.com)
Date: Thu, 27 Nov 2003 16:10:51 +0100
Subject: [R] problems with R graph.
Message-ID: <OFAFC1D969.6A95B843-ONC1256DEB.004DB978-C1256DEB.00536414@bayer.de>






Hello,

I have some problems to generate graph with R...

I am working on two different platform :

- Compaq Alpha Server (Unix True 64 5.1) + R 1.6
- Sparc Server (Sun Solaris 8) + R 1.6

I use different functions like the bitmap function, the legend function and the
barplot function.
The graph are made by the same script on the both platform.

I obtain nice graph on the compaq server but the graph  which is generate on the
sun server has some problems...
I don't understand why the result is not the same because we use the same
library on each platform.
Please look at these images to see what I mean.

(See attached file: histogramme_bad.bmp)(See attached file:
histogramme_good.bmp)

thank you for your help.

Aurelie.

From ripley at stats.ox.ac.uk  Thu Nov 27 16:59:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Nov 2003 15:59:05 +0000 (GMT)
Subject: [R] problems with R graph.
In-Reply-To: <OFAFC1D969.6A95B843-ONC1256DEB.004DB978-C1256DEB.00536414@bayer.de>
Message-ID: <Pine.LNX.4.44.0311271554360.4831-100000@gannet.stats>

If indeed you used the bitmap() function, please read its help page.
The differences are very likely due to the installations of ghostscript
and nothing to do with R.

There never was an `R 1.6', but the current version of R is 1.8.1, so it 
looks as if an update is well overdue.

On Thu, 27 Nov 2003 aurelie.defferrard at bayercropscience.com wrote:

> I have some problems to generate graph with R...
> 
> I am working on two different platform :
> 
> - Compaq Alpha Server (Unix True 64 5.1) + R 1.6
> - Sparc Server (Sun Solaris 8) + R 1.6
> 
> I use different functions like the bitmap function, the legend function and the
> barplot function.
> The graph are made by the same script on the both platform.
> 
> I obtain nice graph on the compaq server but the graph  which is generate on the
> sun server has some problems...
> I don't understand why the result is not the same because we use the same
> library on each platform.
> Please look at these images to see what I mean.
> 
> (See attached file: histogramme_bad.bmp)(See attached file:
> histogramme_good.bmp)

You cannot send binary attachments to R-help, so we can't see anything 
here.  In any case, .bmp is a strange choice for use on Unix systems: png 
would be much better for your readers here (but you would have to put them 
on a web site).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Arne.Muller at aventis.com  Thu Nov 27 17:04:35 2003
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Thu, 27 Nov 2003 17:04:35 +0100
Subject: [R] significance in difference of proportions
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>

Hello,

I'm looking for some guidance with the following problem:

I've 2 samples A (111 items) and B (10 items) drawn from the same unknown
population. Witihn A I find 9 "positives" and in B 0 positives. I'd like to
know if the 2 samples A and B are different, ie is there a way to find out
whether the number of "positives" is significantly different in A and B?

I'm currently using prop.test, but unfortunately some of my data contains
less than 5 items in a group (like in the example above), and the test
statistics may not hold:

> prop.test(c(9,0), c(111,10))

        2-sample test for equality of proportions with continuity correction

data:  c(9, 0) out of c(111, 10) 
X-squared = 0.0941, df = 1, p-value = 0.759
alternative hypothesis: two.sided 
95 percent confidence interval:
 -0.02420252  0.18636468 
sample estimates:
    prop 1     prop 2 
0.08108108 0.00000000 

Warning message: 
Chi-squared approximation may be incorrect in: prop.test(c(9, 0), c(111, 10))


Do you have suggestions for an alternative test?
	
	many thanks for your help,
	+kind regards,

	Arne



From lockwood at rand.org  Thu Nov 27 17:09:31 2003
From: lockwood at rand.org (J.R. Lockwood)
Date: Thu, 27 Nov 2003 11:09:31 -0500 (EST)
Subject: [R] R 1.8.1 on SUSE 9.0
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CEAC@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.33.0311271107280.20100-100000@penguin.rand.org>

> 
> I think the problem is that "by default" g77 is not installed.  However you
> should still be able to find the rpm on the CDROM.
> 
> HTH,
> Andy

Thanks to all for your replies.  Indeed the package gcc-g77 was on the
install disk, and I was able to install the R rpm with no problems.


J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org
http://www.rand.org/methodology/stat/members/lockwood/



From jc at or.psychology.dal.ca  Thu Nov 27 15:02:27 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Thu, 27 Nov 2003 10:02:27 -0400
Subject: [R] lme v. aov?
Message-ID: <555B5D8C-20E2-11D8-A7E6-000A956DE534@or.psychology.dal.ca>


I am trying to understand better an analysis mean RT in various 
conditions in a within subjects design with the overall mean RT / 
subject as one of the factors.  LME seems to be the right way to do 
this. using something like m<- lme(rt~ a *b *subjectRT, random= 
~1|subject) and then anova(m,type = "marginal").  My understanding is 
that lme is an easy interface for dummy coding variables and doing a 
multiple regression (and that could be wrong).  But, what is aov doing 
in this instance? MANOVA?  I also haven't been able to find anything 
really useful on what to properly assign to  "random" in the lme 
formula.  For repeated measures the use above is always in the 
examples.



From spencer.graves at pdf.com  Thu Nov 27 17:30:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Nov 2003 08:30:22 -0800
Subject: [R] help me!
In-Reply-To: <000601c3b4f1$7bcc2400$9b0f2fc8@tvc5>
References: <000601c3b4f1$7bcc2400$9b0f2fc8@tvc5>
Message-ID: <3FC6269E.90804@pdf.com>

      English may have greater variation between regional dialects than 
does Spanish,  The Scots roll their r's, and I suspect it is more like 
the Spanish rolls (perro) than taps (pero), though I have not had enough 
contact with the Scots to judge.  The English r may be closer to the r 
in Portuguese, French, and German than Spanish but does not close the 
throat.  Try making an r like you do but without letting your tongue hit 
the roof of your mouth. 

      hope this helps. 
      Que esto pueda ayudarle!
       spencer graves

Patricia wrote:

>Would you help me to answer this question, please?
> 
>
> 
>
>/r/ is one of the most difficult English sounds to acquire and imitate. Describe in what ways it is different from our Spanish rolls (perro) and taps (pero).  How does the pronunciation of this sound vary according to the context? Find at least three examples of linking r and intrusive r and transcribe into phonetics. When do we use them? Why are they used? 
>
>I`ll waiting for your answer.
>Thanks
>Patricia
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From spencer.graves at pdf.com  Thu Nov 27 17:54:05 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Nov 2003 08:54:05 -0800
Subject: [R] lme v. aov?
In-Reply-To: <555B5D8C-20E2-11D8-A7E6-000A956DE534@or.psychology.dal.ca>
References: <555B5D8C-20E2-11D8-A7E6-000A956DE534@or.psychology.dal.ca>
Message-ID: <3FC62C2D.4000504@pdf.com>

      Do you want to make inference about the specific subjects in your 
study?  If yes, the subjects are a fixed effect.  If instead you want to 
make inference about the societal processes that will generate the 
subjects you will get in the future, that is a random effect.  The 
function "lme" handles both fixed and random effects, as does 
"varcomp".  The functions "aov" and "lm" are restricted to fixed effects 
only.  You can use dummy coding for "lm" and "aov" as well. 

      The the distinction between "fixed" and "random" effects seems to 
me to be the same as what Deming called the difference between 
"enumerative" and "analytic" studies:  With a fixed effect / enumerative 
study, the objective is to determine the disposition of the sampling 
frame.  For example, Deming managed a survey of food distribution in 
Japan in 1946 or so, right after World War II.  The purpose was to 
determine where to deliver food the next day, etc., to keep people from 
dying of starvation.  That was an enumerative study.  If the purpose had 
been to advance economic theories for use not only in Japan or in 
1946-47, that is an analytic study. 

      Do you have the book Pinhiero and Bates (2000) Mixed-Effects 
Models in S and S-Plus (Springer)?  If you have more than one use for 
analyzing data on human subjects, I suggest you get and study this book 
if you haven't already.  Doug Bates and several of his graduate students 
have developed "lme".  I am not current in the absolute latest 
literature in that area of statistics, but Bates seems to me to be among 
the leaders in that area and specifically in statistical computing for 
that kind of problem. 

      hope this helps.  spencer graves

John Christie wrote:

>
> I am trying to understand better an analysis mean RT in various 
> conditions in a within subjects design with the overall mean RT / 
> subject as one of the factors.  LME seems to be the right way to do 
> this. using something like m<- lme(rt~ a *b *subjectRT, random= 
> ~1|subject) and then anova(m,type = "marginal").  My understanding is 
> that lme is an easy interface for dummy coding variables and doing a 
> multiple regression (and that could be wrong).  But, what is aov doing 
> in this instance? MANOVA?  I also haven't been able to find anything 
> really useful on what to properly assign to  "random" in the lme 
> formula.  For repeated measures the use above is always in the examples.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Roger.Bivand at nhh.no  Thu Nov 27 18:03:42 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 27 Nov 2003 18:03:42 +0100 (CET)
Subject: [R] lagsarlm - using mixed explanatory variables (spdep package)
In-Reply-To: <3.0.3.32.20031127124839.00b01100@popin.ncl.ac.uk>
Message-ID: <Pine.LNX.4.44.0311271753550.18984-100000@reclus.nhh.no>

On Thu, 27 Nov 2003, Roy Sanderson wrote:

> Hello

Usually it is easier to send package questions directly to the package 
maintainer, because they may not interest the whole list.

> 
> I'm very new to R (which is excellent), so apologies if this has already
> been raised.  In the spdep package, I'm trying to undertake an
> autoregressive mixed model using the lagsarlm function.  This is working
> fine, but there does not appear to be a method of including an explanatory
> variable without it automatically being included as a lagged term.  I'm
> after something along the lines of
> 
> y = rho.W.y + x1 + x2 + lag(x2)
> 
> but am only able to output
> 
> y = rho.W.y + x1 + x2 + lag(x1) + lag(x2)
> 

Using the old Columbus data set in the spdep package:

> data(oldcol)
> lagsarlm(CRIME ~ INC + HOVAL, data = COL.OLD, nb2listw(COL.nb))
> lagsarlm(CRIME ~ INC + HOVAL, data = COL.OLD, nb2listw(COL.nb), 
+ type="mixed")

give the standard lag and mixed model types, but you need to use
type="lag" and include the spatially lagged x variable(s) manually:

> WINC <- lag.listw(nb2listw(COL.nb), COL.OLD$INC)
> lagsarlm(CRIME ~ INC + HOVAL + WINC, data = COL.OLD, nb2listw(COL.nb))

Hope this helps,

Roger


> Is there any way around this issue?
> 
> Many thanks
> Roy
> 
> ----------------------------------------------------------------------------
> Roy Sanderson
> Centre for Life Sciences Modelling
> Porter Building
> University of Newcastle
> Newcastle upon Tyne
> NE1 7RU
> United Kingdom
> 
> Tel: +44 191 222 7789
> 
> r.a.sanderson at newcastle.ac.uk
> http://www.ncl.ac.uk/clsm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From baron at psych.upenn.edu  Thu Nov 27 18:09:04 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 27 Nov 2003 12:09:04 -0500
Subject: [R] significance in difference of proportions
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>
Message-ID: <20031127170904.GA5562@mail1.sas.upenn.edu>

On 11/27/03 17:04, Arne.Muller at aventis.com wrote:
>Hello,
>
>I'm looking for some guidance with the following problem:
>
>I've 2 samples A (111 items) and B (10 items) drawn from the same unknown
>population. Witihn A I find 9 "positives" and in B 0 positives. I'd like to
>know if the 2 samples A and B are different, ie is there a way to find out
>whether the number of "positives" is significantly different in A and B?
>
>I'm currently using prop.test, but unfortunately some of my data contains
>less than 5 items in a group (like in the example above), and the test
>statistics may not hold:

fisher.test in the ctest package, which loads automatically.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Nov 27 18:18:06 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 27 Nov 2003 18:18:06 +0100 (CET)
Subject: [R] significance in difference of proportions
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>
Message-ID: <Pine.LNX.4.51.0311271814110.32011@artemis.imbe.med.uni-erlangen.de>


> Hello,
>
> I'm looking for some guidance with the following problem:
>
> I've 2 samples A (111 items) and B (10 items) drawn from the same unknown
> population. Witihn A I find 9 "positives" and in B 0 positives. I'd like to
> know if the 2 samples A and B are different, ie is there a way to find out
> whether the number of "positives" is significantly different in A and B?
>
> I'm currently using prop.test, but unfortunately some of my data contains
> less than 5 items in a group (like in the example above), and the test
> statistics may not hold:

The statistic is fine, the approximation to its null distribution may be
questionable :-)



>
> > prop.test(c(9,0), c(111,10))
>
>         2-sample test for equality of proportions with continuity correction
>
> data:  c(9, 0) out of c(111, 10)
> X-squared = 0.0941, df = 1, p-value = 0.759
> alternative hypothesis: two.sided
> 95 percent confidence interval:
>  -0.02420252  0.18636468
> sample estimates:
>     prop 1     prop 2
> 0.08108108 0.00000000
>
> Warning message:
> Chi-squared approximation may be incorrect in: prop.test(c(9, 0), c(111, 10))
>
>
> Do you have suggestions for an alternative test?
>

you may consider a permutation test for two independent samples:

R> library(exactRankTests)
R> x = c(rep(1, 9), rep(0, 102))
R> y = rep(0, 10)
R> mean(x)
[1] 0.08108108
R> mean(y)
[1] 0
R> perm.test(y, x, exact = TRUE)

        2-sample Permutation Test

data:  y and x
T = 0, p-value = 0.6092
alternative hypothesis: true mu is not equal to 0

Best,

Torsten


> 	many thanks for your help,
> 	+kind regards,
>
> 	Arne
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From Ted.Harding at nessie.mcc.ac.uk  Thu Nov 27 18:43:00 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 27 Nov 2003 17:43:00 -0000 (GMT)
Subject: [R] significance in difference of proportions
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>
Message-ID: <XFMail.031127174300.Ted.Harding@nessie.mcc.ac.uk>

On 27-Nov-03 Arne.Muller at aventis.com wrote:
> I've 2 samples A (111 items) and B (10 items) drawn from the same
> unknown population. Witihn A I find 9 "positives" and in B 0
> positives. I'd like to know if the 2 samples A and B are different,
> ie is there a way to find out whether the number of "positives" is
> significantly different in A and B?

Pretty obviously not, just from looking at the numbers:

9 out of 111 -> p = P(positive) approx = 1/10

P(0 out of 10 when p = 1/10) is not unlikely (in fact = 0.35).

However, a Fisher exact test will give you a respectable P-value:

> library(ctest)
> ?fisher.test
> fisher.test(matrix(c(102,9,10,0),nrow=2))
  [...]
  p-value = 1
  alternative hypothesis: true odds ratio is not equal to 1 
  95 percent confidence interval:
   0.000000 6.088391 
> fisher.test(matrix(c(102,9,9,1),nrow=2))
  p-value = 0.5926
> fisher.test(matrix(c(102,9,8,2),nrow=2))
  p-value = 0.2257
> fisher.test(matrix(c(102,9,7,3),nrow=2))
  p-value = 0.0605
> fisher.test(matrix(c(102,9,6,4),nrow=2))
  p-value = 0.01202

So there's a 95% CI (0,6.1) for the odds ratio which, for
identical probabilities of "+", is 1.0 hence well within the CI.
And, keeping the numbers for the larger sample fixed for
simplicity, you have to go quite a way with the smaller one to get
a result significant at 5%:

(102,9):(7,3) -> P = 0.06
(102,9):(6,4) -> P = 0.01

and, to have 80% power (0.8 probability of this event), the
probability of "+" in the second sample would have to be as
high as 0.41.

Conclusion: your second sample size is quite inadequate except
to detect rather large differences between the true proportions
in the two cases!

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 27-Nov-03                                       Time: 17:43:00
------------------------------ XFMail ------------------------------



From spencer.graves at pdf.com  Thu Nov 27 18:51:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Nov 2003 09:51:34 -0800
Subject: [R] significance in difference of proportions:  What problem
	are you solving? 
In-Reply-To: <Pine.LNX.4.51.0311271814110.32011@artemis.imbe.med.uni-erlangen.de>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>
	<Pine.LNX.4.51.0311271814110.32011@artemis.imbe.med.uni-erlangen.de>
Message-ID: <3FC639A6.2030404@pdf.com>

Hi, Torsten: 

      Thanks for the reference to library(exactRankTests).  That seems 
like a reasonable alternative to "prop.test" with small samples. 

      However, aren't "exact tests" and the related bootstrap 
methodology what Deming called "enumerative techniques", more relating 
to describing a fixed finite population than "enumerative techniques" 
for describing more general processes that will likely generate similar 
samples in the future?  Don't "exact tests" and bootstraps answer 
different ("enumerative") questions from those posed by standard 
("analytic") parametric procedures?  (I know that the chi-square 
distribution is only an approximation to the distribution of the 
contingency table chi-square;  however, that is a different issue from 
the question of enumerative vs. analytic studies.) 

      Thanks again for this and your many other interesting 
contributions to r-help. 
      Spencer Graves    

Torsten Hothorn wrote:

>>Hello,
>>
>>I'm looking for some guidance with the following problem:
>>
>>I've 2 samples A (111 items) and B (10 items) drawn from the same unknown
>>population. Witihn A I find 9 "positives" and in B 0 positives. I'd like to
>>know if the 2 samples A and B are different, ie is there a way to find out
>>whether the number of "positives" is significantly different in A and B?
>>
>>I'm currently using prop.test, but unfortunately some of my data contains
>>less than 5 items in a group (like in the example above), and the test
>>statistics may not hold:
>>    
>>
>
>The statistic is fine, the approximation to its null distribution may be
>questionable :-)
>
>
>
>  
>
>>>prop.test(c(9,0), c(111,10))
>>>      
>>>
>>        2-sample test for equality of proportions with continuity correction
>>
>>data:  c(9, 0) out of c(111, 10)
>>X-squared = 0.0941, df = 1, p-value = 0.759
>>alternative hypothesis: two.sided
>>95 percent confidence interval:
>> -0.02420252  0.18636468
>>sample estimates:
>>    prop 1     prop 2
>>0.08108108 0.00000000
>>
>>Warning message:
>>Chi-squared approximation may be incorrect in: prop.test(c(9, 0), c(111, 10))
>>
>>
>>Do you have suggestions for an alternative test?
>>
>>    
>>
>
>you may consider a permutation test for two independent samples:
>
>R> library(exactRankTests)
>R> x = c(rep(1, 9), rep(0, 102))
>R> y = rep(0, 10)
>R> mean(x)
>[1] 0.08108108
>R> mean(y)
>[1] 0
>R> perm.test(y, x, exact = TRUE)
>
>        2-sample Permutation Test
>
>data:  y and x
>T = 0, p-value = 0.6092
>alternative hypothesis: true mu is not equal to 0
>
>Best,
>
>Torsten
>
>
>  
>
>>	many thanks for your help,
>>	+kind regards,
>>
>>	Arne
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From olinares at med.umich.edu  Thu Nov 27 18:49:15 2003
From: olinares at med.umich.edu (Oscar Linares)
Date: Thu, 27 Nov 2003 12:49:15 -0500
Subject: [R] MASS fitdistr()
Message-ID: <sfc5f2dc.076@med-gwia-01a.med.umich.edu>

Dear R experts,

I am trying to use the R MASS library fitdistr() to fit the following
list:

k21stsList<-c(0.76697,0.57642,0.75938,0.82616,0.93706,0.77377,0.58923,0.37157,0.60796,1.00070,0.97529,0.62858,0.63504,0.68697,0.61714,0.75227,1.16390,0.66702,0.83578)

as follows,

library(MASS)
fitdistr(k21stsList, "normal")

But, I get

Error in fitdistr(k21stsList, "normal") : 'start' must be a named list

What am I doing wrong (probably alot!)

Thanks,

Oscar



From dkelly at alum.mit.edu  Thu Nov 27 19:04:51 2003
From: dkelly at alum.mit.edu (David Kelly)
Date: Thu, 27 Nov 2003 10:04:51 -0800
Subject: [R] dvips function gives "Documents not found" error
References: <3FC11E23.3090701@alum.mit.edu>	<Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>
	<20031124081228.2cd671c1.feh3k@spamcop.net>
Message-ID: <3FC63CC3.4080600@alum.mit.edu>

This is primarily an FYI to the Hmisc author, though any brilliant 
suggestions from him or anyone else are always welcome.  Re this problem 
reported earlier in this thread:

   getting an error from Hmisc when trying
   dvips(latex(describe(mtcars)),file="/kellytest/kelly.ps")
   that says
   Error in system(cmd, intern = intern, wait = wait | intern,
   show.output.on.console = wait,  :
	C:/Documents not found
   which appears to be a path-parsing problem of "Documents and Settings"

The problem is still present. I've tried every suggestion that was sent 
to me. Most recently, I created a .Renviron which said
TMP=c:/kellytest/rtemp
and I then ran R (from within emacs/ess).

I verified that TMP had been set correctly as follows:
 > tempdir()
[1] "c:/kellytest/rtemp\\Rtmp5417"

but I still got the C:/Documents not found error.

P.S. I found that a TeX file was created when the command was executed, 
but I could find no evidence of a dvi or ps file.

-- David Kelly



From ripley at stats.ox.ac.uk  Thu Nov 27 19:22:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Nov 2003 18:22:39 +0000 (GMT)
Subject: [R] MASS fitdistr()
In-Reply-To: <sfc5f2dc.076@med-gwia-01a.med.umich.edu>
Message-ID: <Pine.LNX.4.44.0311271818170.27181-100000@gannet.stats>

On Thu, 27 Nov 2003, Oscar Linares wrote:

> Dear R experts,
> 
> I am trying to use the R MASS library fitdistr() to fit the following
> list:

Well, that is not a list!

> k21stsList<-c(0.76697,0.57642,0.75938,0.82616,0.93706,0.77377,0.58923,0.37157,0.60796,1.00070,0.97529,0.62858,0.63504,0.68697,0.61714,0.75227,1.16390,0.66702,0.83578)
> 
> as follows,
> 
> library(MASS)
> fitdistr(k21stsList, "normal")
> 
> But, I get
> 
> Error in fitdistr(k21stsList, "normal") : 'start' must be a named list

You omitted the `start' argument, and "normal" is not in the list 
specified in the Details section.

> What am I doing wrong (probably alot!)

It always helps to read through the whole help page rather than guessing.

Given that the MLEs for a normal are known explicitly, why are you doing 
this?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jc at or.psychology.dal.ca  Thu Nov 27 19:46:22 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Thu, 27 Nov 2003 14:46:22 -0400
Subject: [R] lme v. aov?
In-Reply-To: <3FC62C2D.4000504@pdf.com>
References: <555B5D8C-20E2-11D8-A7E6-000A956DE534@or.psychology.dal.ca>
	<3FC62C2D.4000504@pdf.com>
Message-ID: <FEED7364-2109-11D8-A7E6-000A956DE534@or.psychology.dal.ca>


Its not so much that I wasn't getting the difference between fixed and 
random effects.  Although, I do like the way you put the comment below. 
  For my purposes subject is a random effect.  It was more on correct 
notation in lme with repeated measures designs (my a and b are repeated 
while the mean subjectRT is between).  And, on whether the way aov 
treats repeated measures might best be called a MANOVA method.

On Nov 27, 2003, at 12:54 PM, Spencer Graves wrote:

>      Do you want to make inference about the specific subjects in your 
> study?  If yes, the subjects are a fixed effect.  If instead you want 
> to make inference about the societal processes that will generate the 
> subjects you will get in the future, that is a random effect.  The 
> function "lme" handles both fixed and random effects, as does 
> "varcomp".  The functions "aov" and "lm" are restricted to fixed 
> effects only.  You can use dummy coding for "lm" and "aov" as well.
>      The the distinction between "fixed" and "random" effects seems to 
> me to be the same as what Deming called the difference between 
> "enumerative" and "analytic" studies:  With a fixed effect / 
> enumerative study, the objective is to determine the disposition of 
> the sampling frame.  For example, Deming managed a survey of food 
> distribution in Japan in 1946 or so, right after World War II.  The 
> purpose was to determine where to deliver food the next day, etc., to 
> keep people from dying of starvation.  That was an enumerative study.  
> If the purpose had been to advance economic theories for use not only 
> in Japan or in 1946-47, that is an analytic study.
>      Do you have the book Pinhiero and Bates (2000) Mixed-Effects 
> Models in S and S-Plus (Springer)?  If you have more than one use for 
> analyzing data on human subjects, I suggest you get and study this 
> book if you haven't already.  Doug Bates and several of his graduate 
> students have developed "lme".  I am not current in the absolute 
> latest literature in that area of statistics, but Bates seems to me to 
> be among the leaders in that area and specifically in statistical 
> computing for that kind of problem.
>      hope this helps.  spencer graves
>
> John Christie wrote:
>
>>
>> I am trying to understand better an analysis mean RT in various 
>> conditions in a within subjects design with the overall mean RT / 
>> subject as one of the factors.  LME seems to be the right way to do 
>> this. using something like m<- lme(rt~ a *b *subjectRT, random= 
>> ~1|subject) and then anova(m,type = "marginal").  My understanding is 
>> that lme is an easy interface for dummy coding variables and doing a 
>> multiple regression (and that could be wrong).  But, what is aov 
>> doing in this instance? MANOVA?  I also haven't been able to find 
>> anything really useful on what to properly assign to  "random" in the 
>> lme formula.  For repeated measures the use above is always in the 
>> examples.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>



From ripley at stats.ox.ac.uk  Thu Nov 27 19:53:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Nov 2003 18:53:40 +0000 (GMT)
Subject: [R] lme v. aov?
In-Reply-To: <3FC62C2D.4000504@pdf.com>
Message-ID: <Pine.LNX.4.44.0311271847480.27234-100000@gannet.stats>

On Thu, 27 Nov 2003, Spencer Graves wrote:

>       Do you want to make inference about the specific subjects in your 
> study?  If yes, the subjects are a fixed effect.  If instead you want to 
> make inference about the societal processes that will generate the 
> subjects you will get in the future, that is a random effect.  The 
> function "lme" handles both fixed and random effects, as does 
> "varcomp".  The functions "aov" and "lm" are restricted to fixed effects 
> only.  You can use dummy coding for "lm" and "aov" as well. 

Have you considered Modern Applied Statistics with S (2002) by 
Venables and Ripley?  That has a very helpful chapter 10 which shows 
examples of doing random-effects and mixed-effects studies using aov()
and should help set straight some of your misconceptions.  

A lot of classical analyses of variance are for random effects and this 
used to be taught in all the basic statistic courses.  It is still in some 
of the better introductory books.  And all multistratum aov fits (think 
`Error() term') are mixed (since there is an overall mean which is a fixed 
effect).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From statho3 at web.de  Thu Nov 27 20:11:36 2003
From: statho3 at web.de (Thomas Stabla)
Date: Thu, 27 Nov 2003 20:11:36 +0100 (CET)
Subject: [R] tcltk - tkcreate question
Message-ID: <Pine.LNX.4.44.0311271953450.1422-100000@spock.vulcan>

Hello,

i'm trying to translate following tcltk source code, which I found in
newsgroup comp.lang.tcl, written by Tom Wilkason, into R Code.

proc scrolled_Canvas {base} {
   frame $base.fm -borderwidth 2 -relief sunken

   canvas $base.fm.cv -yscrollcommand "$base.fm.cv_vertscrollbar set"
   scrollbar $base.fm.cv_vertscrollbar -orient vertical \
   -command  "$base.fm.cv yview"
   pack $base.fm.cv -side left -fill both -expand true
   pack $base.fm.cv_vertscrollbar -side right -fill y
   pack $base.fm -side top -fill both -expand true

   set hull [frame $base.fm.cv.hull -borderwidth 2 -relief ridge]

   set wid [winfo width $base.fm]
   $base.fm.cv create window 0 0 -anchor nw -window $hull -width 10 -height 500 -tag window
   bind $base.fm.cv <Configure> "ResizeCanvas %W %w %h"
   return $hull
}


I have successfully translated the code until the line

   $base.fm.cv create window 0 0 -anchor nw -window $hull -width 10 -height 500 -tag window

which i don't fully understand because i started with tcltk just this
week.

I tried to translate this line using the R function tkcreate, but i didn't
get very far.

Thanks for your help.


Greetings,
Thomas Stabla



From p.dalgaard at biostat.ku.dk  Thu Nov 27 20:42:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Nov 2003 20:42:39 +0100
Subject: [R] tcltk - tkcreate question
In-Reply-To: <Pine.LNX.4.44.0311271953450.1422-100000@spock.vulcan>
References: <Pine.LNX.4.44.0311271953450.1422-100000@spock.vulcan>
Message-ID: <x2fzg94mz4.fsf@biostat.ku.dk>

Thomas Stabla <statho3 at web.de> writes:

> 
> I have successfully translated the code until the line
> 
>    $base.fm.cv create window 0 0 -anchor nw -window $hull -width 10 -height 500 -tag window
> 
> which i don't fully understand because i started with tcltk just this
> week.
> 
> I tried to translate this line using the R function tkcreate, but i didn't
> get very far.

I assume you got the canvas ($base.fm.cv) stored in a variable,
"cv", say, and "hull" similarly. Then my first guess would be  

tkcreate(cv, "window", 0, 0, anchor="nw", window=hull, width=10,
         height=5, tag= "window")


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From statho3 at web.de  Thu Nov 27 20:48:43 2003
From: statho3 at web.de (Thomas Stabla)
Date: Thu, 27 Nov 2003 20:48:43 +0100 (CET)
Subject: [R] tcltk - tkcreate question
In-Reply-To: <x2fzg94mz4.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0311272047010.1958-100000@spock.vulcan>

On 27 Nov 2003, Peter Dalgaard wrote:

> Thomas Stabla <statho3 at web.de> writes:
>
> >
> > I have successfully translated the code until the line
> >
> >    $base.fm.cv create window 0 0 -anchor nw -window $hull -width 10 -height 500 -tag window
> >
> > which i don't fully understand because i started with tcltk just this
> > week.
> >
> > I tried to translate this line using the R function tkcreate, but i didn't
> > get very far.
>
> I assume you got the canvas ($base.fm.cv) stored in a variable,
> "cv", say, and "hull" similarly. Then my first guess would be
>
> tkcreate(cv, "window", 0, 0, anchor="nw", window=hull, width=10,
>          height=5, tag= "window")
>

Works fine, thank you for your fast help.

Best regards,
Thomas Stabla



From xma at arcturusag.com  Fri Nov 28 00:01:36 2003
From: xma at arcturusag.com (Xiao-Jun Ma)
Date: Thu, 27 Nov 2003 15:01:36 -0800
Subject: [R] Getting rid of loops?
Message-ID: <BBAF0DEC119BD41193C100B0D0788DFE3FCF4C@GENOME>

I wrote a function to calculate cosine distances between rows of a matrix.
It uses two loops and is slow. Any suggestions to speed this up? Thanks in
advance.


theta.dist <- function(x){

  res <- matrix(NA, nrow(x), nrow(x))

  for (i in 1:nrow(x)){
    for(j in 1:nrow(x)){
      if (i > j)
        res[i, j] <- res[j, i]
      else {
        v1 <- x[i,]
        v2 <- x[j,]
        good <- !is.na(v1) & !is.na(v2)
        v1 <- v1[good]
        v2 <- v2[good]
        theta <- acos(v1%*%v2 / sqrt(v1%*%v1 * v2%*%v2 )) / pi * 180
        res[i,j] <- theta
      }
    }
  }
  as.dist(res)
}



From bruno at speech.kth.se  Fri Nov 28 00:52:49 2003
From: bruno at speech.kth.se (Bruno Giordano)
Date: Fri, 28 Nov 2003 00:52:49 +0100
Subject: [R] cclust - cindex - binary data
Message-ID: <002001c3b541$90a5c2f0$ba43ed82@brungio>

Hi,
I'm trying to debug a function I wrote to calculate the cindex for a
hierarchical tree.
For this it is useful to compare my calculations with those in output from
the clustindex function, in the cclust library.
There's no way, however, to have the cindex value for a given output of the
cclust function, as a NA value is always returned.
This happens almost surely because the cindex in clustIndex is calculated
only for binary data, but, in turn, I can't find a way to specify either
with the cclust function or with the clustIndex function, that an eventual
input data set is binary.

Thanks a lot
    Bruno



From feh3k at spamcop.net  Fri Nov 28 00:54:36 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 27 Nov 2003 18:54:36 -0500
Subject: [R] dvips function gives "Documents not found" error
In-Reply-To: <3FC63CC3.4080600@alum.mit.edu>
References: <3FC11E23.3090701@alum.mit.edu>
	<Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>
	<20031124081228.2cd671c1.feh3k@spamcop.net>
	<3FC63CC3.4080600@alum.mit.edu>
Message-ID: <20031127185436.0684ada3.feh3k@spamcop.net>

On Thu, 27 Nov 2003 10:04:51 -0800
David Kelly <dkelly at alum.mit.edu> wrote:

> This is primarily an FYI to the Hmisc author, though any brilliant 
> suggestions from him or anyone else are always welcome.  Re this problem
> 
> reported earlier in this thread:
> 
>    getting an error from Hmisc when trying
>    dvips(latex(describe(mtcars)),file="/kellytest/kelly.ps")
>    that says
>    Error in system(cmd, intern = intern, wait = wait | intern,
>    show.output.on.console = wait,  :
> 	C:/Documents not found
>    which appears to be a path-parsing problem of "Documents and
>    Settings"
> 
> The problem is still present. I've tried every suggestion that was sent 
> to me. Most recently, I created a .Renviron which said
> TMP=c:/kellytest/rtemp
> and I then ran R (from within emacs/ess).
> 
> I verified that TMP had been set correctly as follows:
>  > tempdir()
> [1] "c:/kellytest/rtemp\\Rtmp5417"
> 
> but I still got the C:/Documents not found error.
> 
> P.S. I found that a TeX file was created when the command was executed, 
> but I could find no evidence of a dvi or ps file.
> 
> -- David Kelly
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Did you make the changes I suggested (surrounding two items by dQuote( ))?

Have you tried Linux?  :)

---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From Paul.Sorenson at vision-bio.com  Fri Nov 28 01:03:52 2003
From: Paul.Sorenson at vision-bio.com (Paul Sorenson)
Date: Fri, 28 Nov 2003 11:03:52 +1100
Subject: [R] Re: FDA and ICH Compliance of R
Message-ID: <5E06BFED29594F4C9C5EBE230DE320C62739E9@ewok.vsl.com.au>

> "Antonia Drugica" <antoniamarija at net.hr> writes:
> 
> > Does anybody know if R is FDA or ICH (or EMEA...) 
> compliant? AFAIK S-Plus
> > is but that means nothing...
> 
> As Thomas pointed out, that does mean nothing -- there was a group of
> folks discussing what might be done to help, earlier this year, but
> then everyone got busy...

FDA has a guidance document for off-the-shelf software:

http://www.fda.gov/cdrh/ode/guidance/585.html

Note that if focuses on OTS used in medical devices.  However you
should read it.  The document:

http://www.fda.gov/cdrh/comp/guidance/938.html

Has a section on applicability of the software guidance (which
encompasses stuff outside the instrument itself.  Since I am no
lawyer, I can't say whether R falls within this scope.

It is fair to say however that the FDA consider safety and
effectiveness very important.  If the effectiveness that you claim is
based on statistics provided by software, or you rely in software for
determining safe levels (eg of a drug) then I would say (as a layman)
it is largely irrelevant whether the vendor claims some sort of "FDA
badge" because that does not prevent someone from writing dodgy
scripts.

So what you can do (other than soliciting mail list opinions)
includes: 
	o Think.  What are the implications for end users, patients
etc.  Would you take a pill based on your own stats?  
	o Read what the FDA have to say.  
	o Evaluate the risk and safety implications of the
statistics you use.  
	o Manage the risk.  Eg can you indepently confirm
the key results?  
	o Your scripts are software - the FDA requires
evidence of a credible process in the life cycle of software, whether
they be spreadsheets, real time control systems or whatever.

OTS software that is "validated" does not remove responsibility for
reducing risk to acceptable levels.

HTH

paul



From feh3k at spamcop.net  Fri Nov 28 01:11:06 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 27 Nov 2003 19:11:06 -0500
Subject: [R] FDA and ICH Compliance of R
In-Reply-To: <20031127145957.8BA883965@mprdmxin.myway.com>
References: <20031127145957.8BA883965@mprdmxin.myway.com>
Message-ID: <20031127191106.3a2c866f.feh3k@spamcop.net>

On Thu, 27 Nov 2003 09:59:57 -0500 (EST)
"Gabor Grothendieck" <ggrothendieck at myway.com> wrote:

> 
> From: Frank E Harrell Jr <feh3k at spamcop.net>
> > per year in SAS licenses and have to hire armies of non-intellectually
> > challenged SAS programmers to do the work of significantly fewer
> > programmers that use modern statistical computing tools like R and
> > S-Plus, it is surprising that SAS is still the most commonly used tool
> > in the clinical side of drug development. I quit using SAS in 1991
> > because my productivity jumped at least 20% within one month of using
> > S-Plus.
> 
> I have not used SAS for even longer than you but to
> give SAS its due:
> 
> - its pretty easy to produce all the info you need for a
>   complete analysis with a few SAS commands.  It would be
>   possible to create analogous R commands but as it stands
>   you have to keep going back and forth with R rather than
>   just get it all out at once like you can with SAS.

Thanks for your note Gabor.  It depends on what you mean by "complete
analysis".  SAS often would give me things I didn't need but was and is
short on modern methods.  But to address the needs I think you are getting
at, this is the reason I developed the Hmisc package (especially
summary.formula).

> 
> - SAS has more functionality in missing values.  You
>   can have different types of SAS missing values but in R you
>   can have only one type of missing value.

Several points here.  First, I always liked the 27 levels of missing that
SAS supported, but I've never seen a pharmaceutical company actually use
more than the standard missing (.).  Second, you can easily implement them
in R and S-Plus anyway; the sas.get function in Hmisc imports all SAS
special missing values and lets you work with them (e.g.,
is.special.miss(x, 'B')) while treating all of them as NA in standard
calculations.  In S you can add your own attributes on the fly (as long as
you don't use the new class mechanism) so you can do things much more
generally than with SAS.  For example, I can add 'comment' attributes and
attributes documenting file names containing the image of the case report
form page containing the variable, etc.  When you get to missing value
imputation, S has more methods available than SAS.

> 
> - the BY phrase in SAS is incredibly powerful and handy.  You
>   can get the same effect in R but I think that specific
>   functionality is easier with SAS.

Again I'll have to respectfully disagree.  BY in SAS is very good for
within-procedure repetition of analyses, but not between procedure.  And
if you need any SAS PROC IML code to do customized matrix programming, you
lose the ability to do by-processing.  In S you can put any number of
things within a loop, with an easier-to-use mechanism for collecting the
results.

> 
> Obviously R is incredibly powerful and functional and I really
> am out of touch with the SAS world but I thought I would make
> whatever case I could.  I am willing to be corrected by those 
> more in the know with SAS if this wrong.

My view is that SAS is best at handling massive databases when you need
standard (i.e., older) methods run, and SAS is very good at getting
P-values in mixed effects models.  Other than that, S is better in almost
every way.  Over the years I've developed documents demonstrating how to
do data manipulation in S (yes, S is superior to SAS for this task) and
how to make semi-advanced statistical reports and fairly complex tables. 
Granted, the learning curve for S is not shallow but the payoff is great
in terms of productivity, beauty of output (when coupling S with LaTeX)
and availability of modern applied statistical methods.

---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From dkelly at alum.mit.edu  Fri Nov 28 01:21:04 2003
From: dkelly at alum.mit.edu (David Kelly)
Date: Thu, 27 Nov 2003 16:21:04 -0800
Subject: [R] dvips function gives "Documents not found" error
References: <3FC11E23.3090701@alum.mit.edu>	<Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>	<20031124081228.2cd671c1.feh3k@spamcop.net>	<3FC63CC3.4080600@alum.mit.edu>
	<20031127185436.0684ada3.feh3k@spamcop.net>
Message-ID: <3FC694F0.5080805@alum.mit.edu>

Frank Harrell wrote:

 > Did you make the changes I suggested (surrounding two items by
 > dQuote())?
 >
 > Have you tried Linux?
------------
No, I didn't make those changes because I've just been working with a 
binary distribution. I may go ahead and pull down sources and try; I was 
trying to avoid that.

I wish I were working with Linux, but I'm doing this work for someone 
with many installed PCs that want to use R, and they're all running 
Win2K and that isn't going to change.

Thanks for the reply -
David Kelly



From edd at debian.org  Fri Nov 28 04:11:42 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 27 Nov 2003 21:11:42 -0600
Subject: [R] dvips function gives "Documents not found" error
In-Reply-To: <3FC694F0.5080805@alum.mit.edu>
References: <3FC11E23.3090701@alum.mit.edu>
	<Pine.LNX.4.44.0311241012230.22048-100000@gannet.stats>
	<20031124081228.2cd671c1.feh3k@spamcop.net>
	<3FC63CC3.4080600@alum.mit.edu>
	<20031127185436.0684ada3.feh3k@spamcop.net>
	<3FC694F0.5080805@alum.mit.edu>
Message-ID: <20031128031142.GA12847@sonny.eddelbuettel.com>

On Thu, Nov 27, 2003 at 04:21:04PM -0800, David Kelly wrote:
> Frank Harrell wrote:
> 
> > Did you make the changes I suggested (surrounding two items by
> > dQuote())?
> >
> > Have you tried Linux?
> ------------
> No, I didn't make those changes because I've just been working with a 
> binary distribution. I may go ahead and pull down sources and try; I was 

But that's the beauty of it -- even in Windoze, the $R_HOME/library/$FOO/R/
directory for a package $FOO contains simple text code which you can edit.

If you know how to read and write S source code, I may take you only about
one minute to locate the file, and insert the suggested dQuote().

> trying to avoid that.
> 
> I wish I were working with Linux, but I'm doing this work for someone 
> with many installed PCs that want to use R, and they're all running 
> Win2K and that isn't going to change.

If you organise your work environment wel, operating systems matter less and
less. R, Perl, Python, ... are pretty much completely cross-platform (unless
you insist on using OS-specific features). 

Dirk


-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From lenvi10 at yahoo.com  Fri Nov 28 07:13:12 2003
From: lenvi10 at yahoo.com (Len Vir)
Date: Thu, 27 Nov 2003 22:13:12 -0800 (PST)
Subject: [R] (no subject)
Message-ID: <20031128061312.95832.qmail@web14802.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031127/1c0c2d68/attachment.pl

From WeiQiang.Li at seagate.com  Fri Nov 28 07:55:28 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Fri, 28 Nov 2003 14:55:28 +0800
Subject: [R] (no subject)
Message-ID: <OF28F1C783.CC409EF8-ON48256DEC.0025F712-48256DEC.00261B6C@notes.seagate.com>

Hi Philippe,

      I am facing a problem that R-(D)COM cannot support multiple threads
when I am using this ActiveX component to produce statistical graphics on
IIS web server environment. Do you have any idea whether this is R (D)COM
limitation or something I made the mis-configuration?

       Your help is very important to us and will be very appreciated

Best Regards,
WeiQiang Li



From ripley at stats.ox.ac.uk  Fri Nov 28 08:18:46 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Nov 2003 07:18:46 +0000 (GMT)
Subject: [R] dvips function gives "Documents not found" error
In-Reply-To: <20031128031142.GA12847@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0311280710050.28551-100000@gannet.stats>

On Thu, 27 Nov 2003, Dirk Eddelbuettel wrote:

> On Thu, Nov 27, 2003 at 04:21:04PM -0800, David Kelly wrote:
> > Frank Harrell wrote:
> > 
> > > Did you make the changes I suggested (surrounding two items by
> > > dQuote())?
> > >
> > > Have you tried Linux?
> > ------------
> > No, I didn't make those changes because I've just been working with a 
> > binary distribution. I may go ahead and pull down sources and try; I was 
> 
> But that's the beauty of it -- even in Windoze, the $R_HOME/library/$FOO/R/
> directory for a package $FOO contains simple text code which you can edit.
> 
> If you know how to read and write S source code, I may take you only about
> one minute to locate the file, and insert the suggested dQuote().
> 
> > trying to avoid that.
> > 
> > I wish I were working with Linux, but I'm doing this work for someone 
> > with many installed PCs that want to use R, and they're all running 
> > Win2K and that isn't going to change.
> 
> If you organise your work environment wel, operating systems matter less and
> less. R, Perl, Python, ... are pretty much completely cross-platform (unless
> you insist on using OS-specific features). 

Well, it is sort of the latter.  Almost all current OSes allow spaces in 
paths, but only Windows users seem to make use of them.  Which is why 
early on I suggested that it would be good if Frank could ensure they are 
allowed in Hmisc.   However (and I don't know if this is the issue here)
there is the concept of `quoting hell' and quoting is certainly not even
cross-sh-clones on Unix-alike.  And since Dirk mentions Perl, the system() 
call in Perl does not even work the same on Windows 98 and 2000/XP, 
something R has always managed.

I will try over the weekend to track down exactly where the problem lies,
but only because it may help us to be offer some general guidelines.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From antoniamarija at net.hr  Fri Nov 28 08:37:37 2003
From: antoniamarija at net.hr (Antonia Drugica)
Date: Fri, 28 Nov 2003 08:37:37 +0100
Subject: [R] FDA and ICH Compliance of R
Message-ID: <3fc6fb41.5cef.0@net.hr>

Concerning the debate about SAS vs. S/R I think that a multiple approach
has to be taken. As far as I observed it many Pharmas are going to use more
than one Spftwarepackage. We all now that S SAS SPSS and so on have their
advantages and disatvantages. I think a modern statistician has to know at
least three or four softwarepackages so that he can decide which problem
can be solved by which software.


>On Thu, 27 Nov 2003 07:48:02 +0100
>"Antonia Drugica" <antoniamarija at net.hr> wrote:
>
>> I'm quite new to this medical stuff. But my associates told me that we
>> are not free in choice of Statistical Software because the FDA has high
>> standards concerning this topic. But if they would prefer a specific
>> package (like SAS) that could mean, that this package vendourer could
>> lay back and hold it's hand open for licence money.
>
>Your associates are completely wrong.  It is only sponsors that choose not
>to be free in their choice, due in my humble opinion mainly to the fact
>that SAS has been in use since 1966 and that "no one has ever been
>criticized by the FDA for using SAS."  FDA even receives submissions based
>on Excel and we all know about the accuracy of Excel's statistical
>calculations.  High standards need to be held by statisticians doing the
>analyses.  Related to such standards open source systems such as R have
>many advantages, and the reproducible reporting capabilities of R using
>its Sweave package have major impacts on accuracy of reporting.
>
>I along with colleagues at another institution are working on an open
>source R package for clinical trial analysis and reporting that should be
>mature in about a year.  I am currently using the package in two
>pharmaceutical industry-sponsored randomized clinical trials to report to
>data monitoring committees.  I'm also working on a document addressing
>validation of statistical calculations.  Let me know if you'd like a copy
>of the current version of that document.
>
>> 
>> Is there any part of the ICH document referring to software packages? I
>> really would use R for some tasks but therefor I need arguments...
>
>Don't know of anything in ICH.
>
>In view of the fact that large pharma companies have to pay more than $10M
>per year in SAS licenses and have to hire armies of non-intellectually
>challenged SAS programmers to do the work of significantly fewer
>programmers that use modern statistical computing tools like R and S-Plus,
>it is surprising that SAS is still the most commonly used tool in the
>clinical side of drug development.  I quit using SAS in 1991 because my
>productivity jumped at least 20% within one month of using S-Plus.
>---
>Frank E Harrell Jr    Professor and Chair            School of Medicine
>                      Department of Biostatistics    Vanderbilt University
>

--
Trebate bolji pristup internetu?
Nazovite IskonInternet na 0800 1000 ili pogledajte
http://www.iskon.biz/individualni/usluge/dialup/



From ripley at stats.ox.ac.uk  Fri Nov 28 09:17:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Nov 2003 08:17:39 +0000 (GMT)
Subject: [R] FDA and ICH Compliance of R
In-Reply-To: <3fc6fb41.5cef.0@net.hr>
Message-ID: <Pine.LNX.4.44.0311280753490.28677-100000@gannet.stats>

On Fri, 28 Nov 2003, Antonia Drugica wrote:

> Concerning the debate about SAS vs. S/R I think that a multiple approach
> has to be taken. As far as I observed it many Pharmas are going to use more
> than one Spftwarepackage. We all now that S SAS SPSS and so on have their
> advantages and disatvantages. I think a modern statistician has to know at
> least three or four softwarepackages so that he can decide which problem
> can be solved by which software.

Really?  I think very few people `know' even one in any depth, and the
phrase `jack of all trades and master of none' springs to mind.  A decade
or so ago we switched the vast majority of our teaching to one (S-PLUS) to
try to ensure that during their year our Master's students achieved a
reasonable mastery of some tool, and we no longer cover SAS nor SPSS.
(And given that my wife provides help in all three and sometimes Stata as 
part of her job, I hear a lot about disadvantages.)  Even our social 
scientists have recently requested a move from SPSS to R for their 
practical classes.

Whereas there are whole swathes of modern statistics that would be very
hard to cover in SAS or SPSS (some of it in our first undergraduate
practical course, which is now using R), I doubt that the advantages of
SAS and SPSS are known to `all' the readers of this list, so perhaps you
could enlighten us (including me)?  And, importantly, please use a
signature wth your real name and affiliation so we know your credentials.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From luca.paglieri at polimi.it  Fri Nov 28 10:32:47 2003
From: luca.paglieri at polimi.it (Luca Paglieri)
Date: Fri, 28 Nov 2003 10:32:47 +0100
Subject: [R] tcltk extension: documentation?
Message-ID: <20031128103247.S13779@tharros.mate.polimi.it>

Hi all,
	i'm searching for a tutorial on the tcltk extension to R. I've 
looked at the pages linked to the R web site, and found the examples 
extremely useful, but I'd like something more.
Does anyone know about other documents regarding this subject?

Thank you very much

ciao
luca



From maechler at stat.math.ethz.ch  Fri Nov 28 11:58:20 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 28 Nov 2003 11:58:20 +0100
Subject: [R] problems with R graph.
In-Reply-To: <Pine.LNX.4.44.0311271554360.4831-100000@gannet.stats>
References: <OFAFC1D969.6A95B843-ONC1256DEB.004DB978-C1256DEB.00536414@bayer.de>
	<Pine.LNX.4.44.0311271554360.4831-100000@gannet.stats>
Message-ID: <16327.10828.132305.276554@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Thu, 27 Nov 2003 15:59:05 +0000 (GMT) writes:

    BDR> You cannot send binary attachments to R-help, so we
    BDR> can't see anything here.  In any case, .bmp is a
    BDR> strange choice for use on Unix systems: png would be
    BDR> much better for your readers here (but you would have
    BDR> to put them on a web site).

Actually no:  
	 I've been explicitely allowing  image/png  for a
	 longer while now.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From bruno.giordano at unipd.it  Fri Nov 28 12:10:24 2003
From: bruno.giordano at unipd.it (bruno.giordano@unipd.it)
Date: Fri, 28 Nov 2003 12:10:24 +0100 (MET)
Subject: [R] cclust - cindex - binary data
Message-ID: <1070017824.3fc72d20eaba8@webmail.unipd.it>

Hi,
I'm trying to debug a function I wrote to calculate the cindex for a
hierarchical tree.
For this it is useful to compare my calculations with those in output from
the clustindex function, in the cclust library.
There's no way, however, to have the cindex value for a given output of the
cclust function, as a NA value is always returned.
This happens almost surely because the cindex in clustIndex is calculated
only for binary data, but, in turn, I can't find a way to specify either
with the cclust function or with the clustIndex function, that an eventual
input data set is binary.

Thanks a lot
    Bruno

~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Bruno L. Giordano - Ph. D. student
Dipartimento di Psicologia Generale
Via Venezia 8 - 35131 Padova, Italy

currently hosted by

KTH - Royal Institute of Technology 
TMH - Department of Speech, Music and Hearing 
Drottning Kristinas v. 31
SE-100 44 Stockholm, Sweden

-------------------------------------------------
This mail sent through IMP: webmail.unipd.it



From Siegfried.Macho at unifr.ch  Fri Nov 28 23:02:10 2003
From: Siegfried.Macho at unifr.ch (Siegfried.Macho)
Date: Fri, 28 Nov 2003 14:02:10 -0800
Subject: [R] problem with nls()
Message-ID: <5.1.0.14.0.20031128135432.02750120@MAIL.UNIFR.CH>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031128/09814fe1/attachment.pl

From allan at stats.uct.ac.za  Fri Nov 28 14:01:56 2003
From: allan at stats.uct.ac.za (allan clark)
Date: Fri, 28 Nov 2003 15:01:56 +0200
Subject: [R] GLM FITTED VALUES TABLE
Message-ID: <3FC74744.6802A72D@stats.uct.ac.za>


   Hi all

   I have the following generalized linear problem.

   In a study of allergic responses, patients arriving at a clinic in
   Groote Schuur hospital were tested for sensitivity to a number of
   substances. Three of these were moulds: Cladosporium (C), Alternaria
   (F) and Aspergillius (T). Their level of sensitivity was measured on
   the Rast Scale as: 0: not allergic   1: mildly allergic   2 or more:
   allergic

   The data is supplied below. The analysis is fairly straight forward
   and I understand how R solves the problem. I've supplied a copy of the
   code in order to perform the analysis.

   My question is: HOW DOES ONE CONVERT THE OUTPUT (FITTED VALUES)
   SUPPLIED BY R AND DISPLAY THEM IN A CONTINGENCY TABLE?

   allergy<-read.table("c:/a.dat",header=T)
   attach(allergy)
   allergy.fit.main.2int<-glm(y~ .^2,family=poisson, data=allergy)
   fitted(allergy.fit.main.2int)

   The fitted values are:
           1          2          3          4          5
   6          7          8
   666.198041  25.858478  14.943481  60.568127   5.350317   5.081557
   28.233832   3.791205
            9         10         11         12         13
   14         15         16
    10.974962  32.170233   7.068334   1.761433  14.077680   7.039304
   2.883016   7.752087
           17         18         19         20         21
   22         23         24
     5.892362   7.355551  35.631726  14.073188  14.295086   7.354193
   6.610380  11.035427
           25         26         27
     9.014081  12.316433  62.669487

   The data for those interested is as follows:

   > allergy
         t    f    c   y
   1  none none none 671
   2  none none  one  23
   3  none none  two  13
   4  none  one none  60
   5  none  one  one   8
   6  none  one  two   3
   7  none  two none  24
   8  none  two  one   4
   9  none  two  two  15
   10  one none none  31
   11  one none  one   9
   12  one none  two   1
   13  one  one none  14
   14  one  one  one   6
   15  one  one  two   4
   16  one  two none   9
   17  one  two  one   5
   18  one  two  two   7
   19  two none none  32
   20  two none  one  15
   21  two none  two  17
   22  two  one none   8
   23  two  one  one   5
   24  two  one  two  12
   25  two  two none  12
   26  two  two  one  13
   27  two  two  two  59

   Regards
   Allan


From ripley at stats.ox.ac.uk  Fri Nov 28 14:18:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Nov 2003 13:18:08 +0000 (GMT)
Subject: [R] problem with nls()
In-Reply-To: <5.1.0.14.0.20031128135432.02750120@MAIL.UNIFR.CH>
Message-ID: <Pine.LNX.4.44.0311281313480.1110-100000@gannet.stats>

On Fri, 28 Nov 2003, Siegfried.Macho wrote:

> I wanted to use the nls() module to solve a Problem from Sen & Srivastava 
> (1990, p.209). Here is the (basic) code used to perform the estimation:
> 
> library(SenSrivastava)
> library(nls)
> data(E9.8)
> 
> # Use Linear Least Square for estimating start values
> lm.obj <- lm(R.1 ~ I.1 + S.1, data = E9.8)

Those are not the column names in E9.8!

> nls1.obj <- nls(R.1 ~ b.0 + b.1*(I.1^a.1-1)/a.1 + b.2*(S.1^a.2-1)/a.2,
>                          data = E9.8,
>                          start = list(b.0 = coef(lm.obj)[1], b.1 = 
> coef(lm.obj)[2], b.2 = coef(lm.obj)[3],                       a.1 = 1, a.2 = 1)
>                     )
> 
> unfortunately, I receive the following message from nls(): "Error in 
> object[[i]] : object is not subsettable"
> 
> Why do I get this message, what does it mean, and how can I avoid it ?
> Note 1: Enclosing expressions by using the function I() does not help either.
> Note 2: To avoid confusion I have changed the names I, R, S to I.1, R.1, S.1.

Perhaps that is your problem, as without changing the names this works for 
me in R 1.8.1.

If you still have a problem using the actual names and R 1.8.1, please
try using R's debugging facilities to find the problem on your computer.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nolwenn.lemeur at nantes.inserm.fr  Fri Nov 28 14:45:57 2003
From: nolwenn.lemeur at nantes.inserm.fr (Nolwenn Le Meur)
Date: Fri, 28 Nov 2003 14:45:57 +0100
Subject: [R] mark axis
Message-ID: <LMEBLNBEKKODLAONNGJMOEGECCAA.nolwenn.lemeur@nantes.inserm.fr>

Maybe a stupid question:
    In a plot, which parameter(s) ables to visualize the axis  like in a
coplot
    where the axis is also visible in the plot background ?
    Thanks
    Nolwenn

********************************************
Nolwenn Le Meur
INSERM U533
Facult? de m?decine
1, rue Gaston Veil
44035 Nantes Cedex 1
France

Tel: (+33)-2-40-41-29-86 (office)
     (+33)-2-40-41-28-44 (secretary)
Fax: (+33)-2-40-41-29-50
mail: nolwenn.lemeur at nantes.inserm.fr



From stievie at utanet.at  Fri Nov 28 15:44:02 2003
From: stievie at utanet.at (Stefan Ascher)
Date: Fri, 28 Nov 2003 15:44:02 +0100
Subject: [R] [ANN] For those of you that uses syn Text Editor to edit .R
	files
Message-ID: <3FC75F32.8010908@utanet.at>

Hi,

sorry to bother you, and that this is probably not the right list :-),
but I read that some of you might use syn as Editor
for .R files. I've released an unofficial Version of the syn Text Editor
with improved support for R (I'm the initial developer of this program,
btw.). syn is a Windows 32 Program (Win9x, NT4, 2000), but maybe it runs
also inside Wine, I didn't try it.

Improved means:
- More commands to send source in the Editor to a running Process (e.g.
R), like: * Send Selection, * Send Word under Caret, * Send Line, * Send
Line and jump to next line, * Send all to Cursor, * Send from Cursor to
next Breakpoint
- A Version of Ctags with R Parser and enhanced BibTeX Parser. Note:
Ctags is released under the GPL.
- Support for Sweave files, a combination of LaTeX and S code (BUT syn
isn't a good editor for editing LaTeX file, due to the lack of automatic
linebreak, and a very rudimentary LaTeX Highlighter)
- Highlights about 3300 R Functions of the base Package. To add or
remove functions edit config\rfuncs.txt
- A program to start syn and load a document and wait until this
document has been closed. So you can use syn as Editor for
edit(something). To do so send the line
options(editor='$[Exe-Dir-FwdSlash]/syncli.exe') at start of R.
- Breakpoint Marker Type, to use with Send from Cursor to Breakpoint.
Toggle Breakpoints click on the Gutter.

Homepage: http://web.utanet.at/ascherst/syn.html
Direct download: http://web.utanet.at/ascherst/synsetup-2.2.0.62.exe (~5 MB)
Official Homepage (without the improved R features):
http://syn.sourceforge.net/

syn is Open Source released under the MPL 1.1.

For further questions or something else contact me at
stievie[at]utanet[dot]at. Please send Bugreports for this Version
directly to me, not to the SF project.

BTW. I use R for my Diploma thesis (I study psychology), so it could be
that I'll ask
some questions in the near future (after I read the docs, of course).
But at the moment everything works just fine :-). Thanks for this
wonderful product!

P.S. The Documentation for syn is included in the Setup, but is not
completely up to date, sorry.

Best wishes
-- 
stefan



From edd at debian.org  Fri Nov 28 16:25:40 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 28 Nov 2003 09:25:40 -0600
Subject: [R] tcltk extension: documentation?
In-Reply-To: <20031128103247.S13779@tharros.mate.polimi.it>
References: <20031128103247.S13779@tharros.mate.polimi.it>
Message-ID: <20031128152540.GB17445@sonny.eddelbuettel.com>


Luca,

On Fri, Nov 28, 2003 at 10:32:47AM +0100, Luca Paglieri wrote:
> Hi all,
> 	i'm searching for a tutorial on the tcltk extension to R. I've 
> looked at the pages linked to the R web site, and found the examples 
> extremely useful, but I'd like something more.
> Does anyone know about other documents regarding this subject?

Couple of points:

i)   There are two R News articles you should read.  Not all of their examples
     work "as is", but it will give a rather nice introduction that should help
     you understand the framework. The second article also explained what 
     changed in the R / tcltk interaction, and why. 
    
ii)  Read and try to modify the examples and the demos in the tcltk package
     itself. 

iii) Look at James Wettenhall's excellent 'cookbook' website at
     http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/

iv)  Read / search the mailing list archives. Various people have posted
     snippets in response to questions.  

v)   Look at some of the other 'public' code using tcltk. By the far the most
     extensive example is Rcmd by John Fox.
     
vi)  Lastly, use some other *tk documentation.  I find the 2nd edition of the
     Perl/Tk book by O'Reilly quite helpful for an overview of what is 
     available, as well as short examples.
     
Hope this helps,  Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From MSchwartz at medanalytics.com  Fri Nov 28 16:27:18 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 28 Nov 2003 09:27:18 -0600
Subject: [R] mark axis
In-Reply-To: <LMEBLNBEKKODLAONNGJMOEGECCAA.nolwenn.lemeur@nantes.inserm.fr>
References: <LMEBLNBEKKODLAONNGJMOEGECCAA.nolwenn.lemeur@nantes.inserm.fr>
Message-ID: <1070033238.2577.17.camel@localhost.localdomain>

On Fri, 2003-11-28 at 07:45, Nolwenn Le Meur wrote:
> Maybe a stupid question:
>     In a plot, which parameter(s) ables to visualize the axis  like in a
> coplot
>     where the axis is also visible in the plot background ?
>     Thanks
>     Nolwenn
> 


There are two approaches:

1. Use par("tck") in the axis() command to extend the tick marks through
the plot region. The values for 'tck' are 0 to 1, representing the
proportion of the plot region that the tick marks will extend in to. For
example:

axis(1, tck = 1)
axis(2, tck = 1)


2. Use grid(), which will do the same thing with a single function. This
is actually the way that coplot() does it. It has a default color of
'lightgray' to de-emphasize the grid. It uses a 'dotted' line by
default, so if you want a solid line like coplot(), change the 'lty'
argument.

See ?axis, ?par (for 'tck') and ?grid for more information.

HTH,

Marc Schwartz



From edd at debian.org  Fri Nov 28 16:31:20 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 28 Nov 2003 09:31:20 -0600
Subject: [R] tcltk extension: documentation?
In-Reply-To: <20031128152540.GB17445@sonny.eddelbuettel.com>
References: <20031128103247.S13779@tharros.mate.polimi.it>
	<20031128152540.GB17445@sonny.eddelbuettel.com>
Message-ID: <20031128153120.GC17445@sonny.eddelbuettel.com>

On Fri, Nov 28, 2003 at 09:25:40AM -0600, Dirk Eddelbuettel wrote:
> 
> Luca,
> 
> On Fri, Nov 28, 2003 at 10:32:47AM +0100, Luca Paglieri wrote:
> > Hi all,
> > 	i'm searching for a tutorial on the tcltk extension to R. I've 
> > looked at the pages linked to the R web site, and found the examples 
> > extremely useful, but I'd like something more.
> > Does anyone know about other documents regarding this subject?
> 
> Couple of points:
> 
> i)   There are two R News articles you should read.  Not all of their examples
>      work "as is", but it will give a rather nice introduction that should help
>      you understand the framework. The second article also explained what 
>      changed in the R / tcltk interaction, and why. 

PS 1:  Sorry, I meant not all examples from the first article work as is.
       IIRC they will for the second one.
     
> ii)  Read and try to modify the examples and the demos in the tcltk package
>      itself. 
> 
> iii) Look at James Wettenhall's excellent 'cookbook' website at
>      http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/
>
> iv)  Read / search the mailing list archives. Various people have posted
>      snippets in response to questions.  

PS 2:  I forgot to mention the r-sig-gui mailing list which cover tcltk often.

> v)   Look at some of the other 'public' code using tcltk. By the far the most
>      extensive example is Rcmd by John Fox.

PS 3:  Sorry -- that should be Rcmdr.

> vi)  Lastly, use some other *tk documentation.  I find the 2nd edition of the
>      Perl/Tk book by O'Reilly quite helpful for an overview of what is 
>      available, as well as short examples.
>      
> Hope this helps,  Dirk

Dirk


-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From spencer.graves at pdf.com  Fri Nov 28 17:52:24 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 Nov 2003 08:52:24 -0800
Subject: [R] lme v. aov?
In-Reply-To: <555B5D8C-20E2-11D8-A7E6-000A956DE534@or.psychology.dal.ca>
References: <555B5D8C-20E2-11D8-A7E6-000A956DE534@or.psychology.dal.ca>
Message-ID: <3FC77D48.4020401@pdf.com>

       Please excuse:  You and these other sources are correct: 
"varcomp" does not exist in R.  I prefer R but am forced to use S-Plus, 
because I work in an organization with many S-Plus users and only 2 R 
users, and I forgot that point in my reply.

       My experience suggests that in S-Plus "varcomp" may run faster 
than "lme" and may sometimes be easier to use.  However, there are many 
things that are easy to get from "lme" and quite difficult to get from 
"varcomp".  Moreover, "lme" is under active development, while "varcomp" 
is not. I think the R developers made the right choice:  If "lme" can do 
everything that "varcomp" can do plus more, it is a waste of time to 
create a function called "varcomp".  Users concerned about speed can buy 
a faster computer or modify the source code to get what they want faster.

       Thanks for the question, and excuse me for sending you on a 
search for something that doesn't exist.
       Spencer Graves

Peter B. Mandeville wrote:

 > According to MASS fourth edition pages 279 to 286, the functions 
varcomp and raov are only found in SPLUS. I tried help for varcomp after 
load the libraries MASS and nlme without success. Help search didn't 
find them either. MASS and the Cox book on variance components state 
that the variance components can be gotten from lme.
 >
 > Where is the varcomp funtion found in R?
 >
 > Thank you very much,
 >
 > Peter B.
 >
 > At 08:54 a.m. 27/11/03 -0800, you wrote:
 >
      Do you want to make inference about the specific subjects in your
study?  If yes, the subjects are a fixed effect.  If instead you want to
make inference about the societal processes that will generate the
subjects you will get in the future, that is a random effect.  The
function "lme" handles both fixed and random effects, as does
"varcomp".  The functions "aov" and "lm" are restricted to fixed effects
only.  You can use dummy coding for "lm" and "aov" as well.

      The the distinction between "fixed" and "random" effects seems to
me to be the same as what Deming called the difference between
"enumerative" and "analytic" studies:  With a fixed effect / enumerative
study, the objective is to determine the disposition of the sampling
frame.  For example, Deming managed a survey of food distribution in
Japan in 1946 or so, right after World War II.  The purpose was to
determine where to deliver food the next day, etc., to keep people from
dying of starvation.  That was an enumerative study.  If the purpose had
been to advance economic theories for use not only in Japan or in
1946-47, that is an analytic study.

      Do you have the book Pinhiero and Bates (2000) Mixed-Effects
Models in S and S-Plus (Springer)?  If you have more than one use for
analyzing data on human subjects, I suggest you get and study this book
if you haven't already.  Doug Bates and several of his graduate students
have developed "lme".  I am not current in the absolute latest
literature in that area of statistics, but Bates seems to me to be among
the leaders in that area and specifically in statistical computing for
that kind of problem.

      hope this helps.  spencer graves

John Christie wrote:

>
> I am trying to understand better an analysis mean RT in various 
> conditions in a within subjects design with the overall mean RT / 
> subject as one of the factors.  LME seems to be the right way to do 
> this. using something like m<- lme(rt~ a *b *subjectRT, random= 
> ~1|subject) and then anova(m,type = "marginal").  My understanding is 
> that lme is an easy interface for dummy coding variables and doing a 
> multiple regression (and that could be wrong).  But, what is aov doing 
> in this instance? MANOVA?  I also haven't been able to find anything 
> really useful on what to properly assign to  "random" in the lme 
> formula.  For repeated measures the use above is always in the examples.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Fri Nov 28 17:59:54 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 Nov 2003 08:59:54 -0800
Subject: [R] GLM FITTED VALUES TABLE
In-Reply-To: <3FC74744.6802A72D@stats.uct.ac.za>
References: <3FC74744.6802A72D@stats.uct.ac.za>
Message-ID: <3FC77F0A.5020702@pdf.com>

      Did you try something like the following: 

      allergy$fitted <- fitted(allergy.fit.main.2int)

      The documentation "?fitted.glm" says "Value:  Fitted values 
extracted from the object 'x'."  I didn't try this with your data.  
However, from this documentation and previous experience similar 
situations, it would appear that this command would give you the fitted 
values as a column of your original data.frame. 

      hope this helps.  spencer graves

allan clark wrote:

>   Hi all
>
>   I have the following generalized linear problem.
>
>   In a study of allergic responses, patients arriving at a clinic in
>   Groote Schuur hospital were tested for sensitivity to a number of
>   substances. Three of these were moulds: Cladosporium (C), Alternaria
>   (F) and Aspergillius (T). Their level of sensitivity was measured on
>   the Rast Scale as: 0: not allergic   1: mildly allergic   2 or more:
>   allergic
>
>   The data is supplied below. The analysis is fairly straight forward
>   and I understand how R solves the problem. I've supplied a copy of the
>   code in order to perform the analysis.
>
>   My question is: HOW DOES ONE CONVERT THE OUTPUT (FITTED VALUES)
>   SUPPLIED BY R AND DISPLAY THEM IN A CONTINGENCY TABLE?
>
>   allergy<-read.table("c:/a.dat",header=T)
>   attach(allergy)
>   allergy.fit.main.2int<-glm(y~ .^2,family=poisson, data=allergy)
>   fitted(allergy.fit.main.2int)
>
>   The fitted values are:
>           1          2          3          4          5
>   6          7          8
>   666.198041  25.858478  14.943481  60.568127   5.350317   5.081557
>   28.233832   3.791205
>            9         10         11         12         13
>   14         15         16
>    10.974962  32.170233   7.068334   1.761433  14.077680   7.039304
>   2.883016   7.752087
>           17         18         19         20         21
>   22         23         24
>     5.892362   7.355551  35.631726  14.073188  14.295086   7.354193
>   6.610380  11.035427
>           25         26         27
>     9.014081  12.316433  62.669487
>
>   The data for those interested is as follows:
>
>   > allergy
>         t    f    c   y
>   1  none none none 671
>   2  none none  one  23
>   3  none none  two  13
>   4  none  one none  60
>   5  none  one  one   8
>   6  none  one  two   3
>   7  none  two none  24
>   8  none  two  one   4
>   9  none  two  two  15
>   10  one none none  31
>   11  one none  one   9
>   12  one none  two   1
>   13  one  one none  14
>   14  one  one  one   6
>   15  one  one  two   4
>   16  one  two none   9
>   17  one  two  one   5
>   18  one  two  two   7
>   19  two none none  32
>   20  two none  one  15
>   21  two none  two  17
>   22  two  one none   8
>   23  two  one  one   5
>   24  two  one  two  12
>   25  two  two none  12
>   26  two  two  one  13
>   27  two  two  two  59
>
>   Regards
>   Allan
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From p.dalgaard at biostat.ku.dk  Fri Nov 28 18:09:31 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Nov 2003 18:09:31 +0100
Subject: [R] tcltk extension: documentation?
In-Reply-To: <20031128153120.GC17445@sonny.eddelbuettel.com>
References: <20031128103247.S13779@tharros.mate.polimi.it>
	<20031128152540.GB17445@sonny.eddelbuettel.com>
	<20031128153120.GC17445@sonny.eddelbuettel.com>
Message-ID: <x23cc84dys.fsf@biostat.ku.dk>

Dirk Eddelbuettel <edd at debian.org> writes:

> On Fri, Nov 28, 2003 at 09:25:40AM -0600, Dirk Eddelbuettel wrote:
> > 
> > Luca,
> > 
> > On Fri, Nov 28, 2003 at 10:32:47AM +0100, Luca Paglieri wrote:
> > > Hi all,
> > > 	i'm searching for a tutorial on the tcltk extension to R. I've 
> > > looked at the pages linked to the R web site, and found the examples 
> > > extremely useful, but I'd like something more.
> > > Does anyone know about other documents regarding this subject?
> > 
> > Couple of points:
> > 
> > i)   There are two R News articles you should read.  Not all of their examples
> >      work "as is", but it will give a rather nice introduction that should help
> >      you understand the framework. The second article also explained what 
> >      changed in the R / tcltk interaction, and why. 
> 
> PS 1:  Sorry, I meant not all examples from the first article work as is.
>        IIRC they will for the second one.

I think so, although a couple of things have changed since. The second
article also explains why the examples in the first one stopped
working. 
     
> > ii)  Read and try to modify the examples and the demos in the tcltk package
> >      itself. 
> > 
> > iii) Look at James Wettenhall's excellent 'cookbook' website at
> >      http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/

Yup. Be suspicious of any calls to paste() though. AFAIR, there used
to be a lot more of those which James has cleaned up since, but there
are still a few left. E.g. (from the page about menus),

copyText <- function()
.Tcl(paste("event","generate",.Tcl.args(.Tk.ID(txt),"<<Copy>>")))

I think that wants to be

copyText <- function() tkcmd("event", "generate", txt, "<<Copy>>")

[Untested, however...]
 
> > vi)  Lastly, use some other *tk documentation.  I find the 2nd edition of the
> >      Perl/Tk book by O'Reilly quite helpful for an overview of what is 
> >      available, as well as short examples.

My favourite here is Brent Welch's book. Not cheap (by computer
standards -- compared to stats books it is a steal!), but very
comprehensive. Most importantly it is one of those books which by some
sort of magic can answer your questions without actually putting it in
writing anywhere: For instance, I went looking for a recipe of how to
bind a keystroke event to an image and couldn't find one; however, I
did see sufficiently many references to "Keyboard focus" that it
dawned on me that images are put in labels and labels just don't get
keyboard focus (at least not without further ado)....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From busscher at wiz.uni-kassel.de  Fri Nov 28 18:51:06 2003
From: busscher at wiz.uni-kassel.de (Nicolaas Busscher)
Date: Fri, 28 Nov 2003 18:51:06 +0100
Subject: [R] box m-test in R?
Message-ID: <20031128185106.2bea10f0.busscher@wiz.uni-kassel.de>

Hi all,
Is there in R a so called box m-test for testing the equality of the
cov. matrix for checking on homoscedasticity? If not (i havent found
it) is there a workaround for this ? thanks


-- 
Dr.Nicolaas Busscher Universit?t GH Kassel
Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713



From ggrothendieck at myway.com  Fri Nov 28 22:27:06 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 28 Nov 2003 16:27:06 -0500 (EST)
Subject: [R] Discovering methods
Message-ID: <20031128212706.CA125396B@mprdmxin.myway.com>



How would I discover that + is a method for POSIXct? Applying
methods() to POSIXt and POSIXct does not reveal it.

> methods(class="POSIXt")
 [1] as.character.POSIXt cut.POSIXt          diff.POSIXt        
 [4] hist.POSIXt         julian.POSIXt       months.POSIXt      
 [7] quarters.POSIXt     seq.POSIXt          str.POSIXt         
[10] weekdays.POSIXt 
   
> methods(class="POSIXct")
 [1] [.POSIXct             [[.POSIXct            [<-.POSIXct          
 [4] all.equal.POSIXct     as.data.frame.POSIXct c.POSIXct            
 [7] format.POSIXct        mean.POSIXct          plot.POSIXct         
[10] print.POSIXct         rep.POSIXct           summary.POSIXct  

Applying methods() to "+" does give it but, in general, this 
would not be a feasible way to discover it since it would be
tantamount to trying everything possible:

> methods("+")
[1] +.POSIXt

Is there some other way?



From wdmccoy at geo.umass.edu  Sat Nov 29 00:25:34 2003
From: wdmccoy at geo.umass.edu (William D. McCoy)
Date: Fri, 28 Nov 2003 18:25:34 -0500 (EST)
Subject: [R] compile problem with gzfile
Message-ID: <200311282325.SAA18211@aeolus.geo.umass.edu>

I just finished compiling today's r-patched (R 1.8.1 patched) on my
old Sparc 20 using gcc 3.3 along with Sun's f77.

As it was compiling, I noticed an error regarding gzfile.  The compile 
process left the methods directory and continued on.  Obviously, there 
was a problem, but I don't have the original error message from the
compiler.  After installing R, I get the following error message when
I start R:

Error in open.connection(con, "rb") : unable to open connection
In addition: Warning message: 
cannot open compressed file
`/usr/local/lib/R/library/methods/R/all.rda'

A check for the file 'all.rda' showed that it does not exist.  I do
have gzip installed and I have libz.so.1.1.4 in /usr/local/lib.  I
realize this isn't much to go on, but does anyone have an idea what
might be wrong?  Has anyone had a similar error?

-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA  01003



From kjetil at entelnet.bo  Sat Nov 29 04:17:45 2003
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Fri, 28 Nov 2003 23:17:45 -0400
Subject: [R] Discovering methods
In-Reply-To: <20031128212706.CA125396B@mprdmxin.myway.com>
Message-ID: <3FC7D799.20371.44BD4A@localhost>

On 28 Nov 2003 at 16:27, Gabor Grothendieck wrote:



How would I discover that + is a method for POSIXct? Applying
methods() to POSIXt and POSIXct does not reveal it.

Reading
?POSIXct
will tell you.

Kjetil Halvorsen

> methods(class="POSIXt")
 [1] as.character.POSIXt cut.POSIXt          diff.POSIXt        
 [4] hist.POSIXt         julian.POSIXt       months.POSIXt      
 [7] quarters.POSIXt     seq.POSIXt          str.POSIXt         
[10] weekdays.POSIXt 

> methods(class="POSIXct")
 [1] [.POSIXct             [[.POSIXct            [<-.POSIXct         
 [4] all.equal.POSIXct     as.data.frame.POSIXct c.POSIXct           
 [7] format.POSIXct        mean.POSIXct          plot.POSIXct         

[10] print.POSIXct         rep.POSIXct           summary.POSIXct  

Applying methods() to "+" does give it but, in general, this 
would not be a feasible way to discover it since it would be
tantamount to trying everything possible:

> methods("+")
[1] +.POSIXt

Is there some other way?

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Sat Nov 29 04:19:27 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 28 Nov 2003 22:19:27 -0500
Subject: [R] performance gap between R 1.7.1 and 1.8.0
Message-ID: <3A822319EB35174CA3714066D590DCD50205CEBB@usrymx25.merck.com>

Dear R-help,

A colleague of mine was running some code on two of our boxes, and noticed a
rather large difference in running time.  We've so far isolated the problem
to the difference between R 1.7.1 and 1.8.0, but not more than that.  The
exact same code took 933.5 seconds in 1.7.1, and 3594.4 seconds in 1.8.1, on
the same box.

Basically, the code calls boot() to bootstrap fitting mixture models by
calling flexmix() (in the flexmix package) with intercept-only models.
The code needs to be strip down further, but I thought some of you might be
able to tell what's wrong from the info we have so far:

I ran R profiling on the code, under both R 1.7.1 and 1.8.1 (but the
performance gap is there in 1.8.0 already).  Sorted by "self" part of the
output, the top 10 lines are:

R 1.7.1
   %       self        %       total
 self     seconds    total    seconds    name
 10.75    100.36     10.75    100.36     ".Fortran"
  8.71     81.32     34.27    319.88     "lm.wfit"
  5.43     50.66     81.19    757.88     "FLXfit"
  4.30     40.16      4.30     40.16     "^"
  4.26     39.80      4.26     39.80     "=="
  4.15     38.74      4.99     46.62     "names"
  3.90     36.38     20.57    191.98     "initialize"
  3.51     32.80      5.37     50.14     "dnorm"
  2.29     21.34      4.94     46.14     "hclass"
  1.83     17.10      5.85     54.64     "inherits"

R 1.8.1:
   %       self        %       total
 self     seconds    total    seconds    name
  6.24    224.26     11.69    420.32     "paste"
  5.93    213.04     13.21    474.76     "read.dcf"
  4.37    157.24      5.17    185.92     "names"
  4.18    150.42      5.53    198.66     "exists"
  3.71    133.52     14.66    527.00     "lapply"
  3.15    113.16      4.43    159.32     "names<-"
  2.98    107.26      2.98    107.26     ".Fortran"
  2.57     92.46      5.75    206.82     "seq"
  2.54     91.42      3.18    114.14     "seq.default"
  2.37     85.24      8.93    320.96     "lm.wfit"

The ".Fortran" call took about the same amount of time, as does "lm.wfit",
so that's a bit comforting.  (The code also fits the same model using
mclust, and that's probably where the .Fortran call is from.)  What puzzled
me are:

-  Several functions took much longer in 1.8.1; e.g., 
          1.7.1  1.8.1 
  "paste"    28    224
  "names"    38    157
  "names<-"  15    113
  "exists"    4    150

-  The presence of "read.dcf" in 1.8.1.  Where could this be from?

Any clues as to why we're seeing this?

Best,
Andy

Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw at merck.com        732-594-0820



From ggrothendieck at myway.com  Sat Nov 29 05:05:59 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 28 Nov 2003 23:05:59 -0500 (EST)
Subject: [R] Discovering methods
Message-ID: <20031129040559.499A83962@mprdmxin.myway.com>



Sure, but why are some methods found using methods("POSIXct")
while other methods not found?

It would be nice to have some reliable documentation-independent 
way to discover all the methods for a class.

---
Date: Fri, 28 Nov 2003 23:17:45 -0400 
From: <kjetil at entelnet.bo>
To: <R-help at stat.math.ethz.ch>, <ggrothendieck at myway.com> 
Subject: Re: [R] Discovering methods 

 
 
On 28 Nov 2003 at 16:27, Gabor Grothendieck wrote:



How would I discover that + is a method for POSIXct? Applying
methods() to POSIXt and POSIXct does not reveal it.

Reading
?POSIXct
will tell you.

Kjetil Halvorsen

> methods(class="POSIXt")
[1] as.character.POSIXt cut.POSIXt diff.POSIXt 
[4] hist.POSIXt julian.POSIXt months.POSIXt 
[7] quarters.POSIXt seq.POSIXt str.POSIXt 
[10] weekdays.POSIXt 

> methods(class="POSIXct")
[1] [.POSIXct [[.POSIXct [<-.POSIXct 
[4] all.equal.POSIXct as.data.frame.POSIXct c.POSIXct 
[7] format.POSIXct mean.POSIXct plot.POSIXct 

[10] print.POSIXct rep.POSIXct summary.POSIXct 

Applying methods() to "+" does give it but, in general, this 
would not be a feasible way to discover it since it would be
tantamount to trying everything possible:

> methods("+")
[1] +.POSIXt

Is there some other way?



From Torsten.Hothorn at rzmail.uni-erlangen.de  Fri Nov 28 09:09:34 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Fri, 28 Nov 2003 09:09:34 +0100 (CET)
Subject: [R] significance in difference of proportions: What problemareyou
	solving? 
In-Reply-To: <3FC639A6.2030404@pdf.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE410B56@crbsmxsusr04.pharma.aventis.com>
	<Pine.LNX.4.51.0311271814110.32011@artemis.imbe.med.uni-erlangen.de>
	<3FC639A6.2030404@pdf.com>
Message-ID: <Pine.LNX.4.51.0311280856080.23047@artemis.imbe.med.uni-erlangen.de>


On Thu, 27 Nov 2003, Spencer Graves wrote:

> Hi, Torsten:
>
>       Thanks for the reference to library(exactRankTests).  That seems
> like a reasonable alternative to "prop.test" with small samples.
>
>       However, aren't "exact tests" and the related bootstrap
> methodology what Deming called "enumerative techniques", more relating
> to describing a fixed finite population than "enumerative techniques"
> for describing more general processes that will likely generate similar
> samples in the future?  Don't "exact tests" and bootstraps answer
> different ("enumerative") questions from those posed by standard
> ("analytic") parametric procedures?  (I know that the chi-square
> distribution is only an approximation to the distribution of the
> contingency table chi-square;  however, that is a different issue from
> the question of enumerative vs. analytic studies.)
>

yes, thats my understanding too. The "enumerative techniques" as
you call it condition on the data actually observed and determine
the null distribution of the associated test statistic from the data. In
contrast, unconditional procedures require some assumptions to the
underlying data generating process from which the null distribution is
derived. The appropriate choice depends of the kind of experiment
under test: In a randomized trial we would like to see all possible
outcomes of the trial caused by "rerandomization" and the enumerative
techniques are natural here. When we draw many samples from predefined
populations, men and women, say, "rerandomization" of gender is of course
not that easy and we may assume something about the data generating
process :-)

Best,

Torsten



From Bill.Venables at csiro.au  Sat Nov 29 08:11:29 2003
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sat, 29 Nov 2003 17:11:29 +1000
Subject: [R] GLM FITTED VALUES TABLE
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9276579@roper-cv.qld.cmis.csiro.au>

Converting a collection of factors and a vector into an array is a general
problem for which there is no general tool available (but it would be easy
to write and curiously the S-PLUS function as.data.frame.array  does the
inverse operation).  Let me think about it...

In your case, however, the operation is easy, because you can exploit the
regular layout of the data.

not <- c("none", "one", "two")
dm <- rep(3,3)
dn <- list(c = not, f = not, t = not)
Otable <- array(allergy$y, dim=dm, dimnames = dn)
Etable <- array(fitted(allergy.fit.main.2int), dim = dm, dimnames = dn)
Etable

You just need to remember that the dimensions come out as c-rows, f-colums,
t-layers.  If you want them in some other order the tool to use is aperm( ),
but I'll leave that interesting story for you to sort out.

Bill Venables.



: -----Original Message-----
: From: allan clark [mailto:allan at stats.uct.ac.za] 
: Sent: Friday, 28 November 2003 11:02 PM
: To: r-help at stat.math.ethz.ch
: Subject: [R] GLM FITTED VALUES TABLE
: 
: 
: 
:    Hi all
: 
:    I have the following generalized linear problem.
: 
:    In a study of allergic responses, patients arriving at a clinic in
:    Groote Schuur hospital were tested for sensitivity to a number of
:    substances. Three of these were moulds: Cladosporium (C), 
: Alternaria
:    (F) and Aspergillius (T). Their level of sensitivity was 
: measured on
:    the Rast Scale as: 0: not allergic   1: mildly allergic   
: 2 or more:
:    allergic
: 
:    The data is supplied below. The analysis is fairly straight forward
:    and I understand how R solves the problem. I've supplied a 
: copy of the
:    code in order to perform the analysis.
: 
:    My question is: HOW DOES ONE CONVERT THE OUTPUT (FITTED VALUES)
:    SUPPLIED BY R AND DISPLAY THEM IN A CONTINGENCY TABLE?
: 
:    allergy<-read.table("c:/a.dat",header=T)
:    attach(allergy)
:    allergy.fit.main.2int<-glm(y~ .^2,family=poisson, data=allergy)
:    
: 
:    The fitted values are:
:            1          2          3          4          5
:    6          7          8
:    666.198041  25.858478  14.943481  60.568127   5.350317   5.081557
:    28.233832   3.791205
:             9         10         11         12         13
:    14         15         16
:     10.974962  32.170233   7.068334   1.761433  14.077680   7.039304
:    2.883016   7.752087
:            17         18         19         20         21
:    22         23         24
:      5.892362   7.355551  35.631726  14.073188  14.295086   7.354193
:    6.610380  11.035427
:            25         26         27
:      9.014081  12.316433  62.669487
: 
:    The data for those interested is as follows:
: 
:    > allergy
:          t    f    c   y
:    1  none none none 671
:    2  none none  one  23
:    3  none none  two  13
:    4  none  one none  60
:    5  none  one  one   8
:    6  none  one  two   3
:    7  none  two none  24
:    8  none  two  one   4
:    9  none  two  two  15
:    10  one none none  31
:    11  one none  one   9
:    12  one none  two   1
:    13  one  one none  14
:    14  one  one  one   6
:    15  one  one  two   4
:    16  one  two none   9
:    17  one  two  one   5
:    18  one  two  two   7
:    19  two none none  32
:    20  two none  one  15
:    21  two none  two  17
:    22  two  one none   8
:    23  two  one  one   5
:    24  two  one  two  12
:    25  two  two none  12
:    26  two  two  one  13
:    27  two  two  two  59
: 
:    Regards
:    Allan
: ______________________________________________
: R-help at stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
:



From ripley at stats.ox.ac.uk  Sat Nov 29 09:38:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Nov 2003 08:38:18 +0000 (GMT)
Subject: [R] GLM FITTED VALUES TABLE
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A9276579@roper-cv.qld.cmis.csiro.au>
Message-ID: <Pine.LNX.4.44.0311290830140.2576-100000@gannet.stats>

On Sat, 29 Nov 2003 Bill.Venables at csiro.au wrote:

> Converting a collection of factors and a vector into an array is a general
> problem for which there is no general tool available (but it would be easy

It's called xtabs() in R:

allergy$fitted <- fitted(allergy.fit.main.2int)
xtabs(fitted ~ t + f + c, data=allergy)

and you permute the dimensions by reordering the factors.

Note that the roughly analogous crosstabs in S-PLUS will not do this, but
xtabs generates a call to table() which could be used directly.

In this case there were no repeated (and no missing) combinations of 
factors: if there has been just predict the model at all combinations and 
apply xtabs/table to the predictions.

> to write and curiously the S-PLUS function as.data.frame.array  does the
> inverse operation).  Let me think about it...
> 
> In your case, however, the operation is easy, because you can exploit the
> regular layout of the data.
> 
> not <- c("none", "one", "two")
> dm <- rep(3,3)
> dn <- list(c = not, f = not, t = not)
> Otable <- array(allergy$y, dim=dm, dimnames = dn)
> Etable <- array(fitted(allergy.fit.main.2int), dim = dm, dimnames = dn)
> Etable
> 
> You just need to remember that the dimensions come out as c-rows, f-colums,
> t-layers.  If you want them in some other order the tool to use is aperm( ),
> but I'll leave that interesting story for you to sort out.
> 
> Bill Venables.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Pascal.Niklaus at unibas.ch  Sat Nov 29 11:37:47 2003
From: Pascal.Niklaus at unibas.ch (Pascal.Niklaus@unibas.ch)
Date: Sat, 29 Nov 2003 11:37:47 +0100
Subject: [R] Indexing ANOVA table
Message-ID: <1070102267.3fc876fba6a2a@webmail.unibas.ch>

Hi all,

I'd like to extract a value from an ANOVA table, but experience the following
problem:

### This works:

> s.pseudo <- summary(aov(m ~ block + mix*graz,data=split1))
> s.pseudo
            Df  Sum Sq Mean Sq F value  Pr(>F)
block        2 1114.66  557.33  4.4296 0.04192 *
mix          1    6.14    6.14  0.0488 0.82956
graz         2    1.45    0.72  0.0057 0.99427
mix:graz     2    3.82    1.91  0.0152 0.98495
Residuals   10 1258.19  125.82
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> s.pseudo[[1]]["mix ","Pr(>F)"]
[1] 0.8295556

### But this doesn't -- why?

> s.split <-  summary(aov(m ~ block + mix*graz + Error(Plot),data=split1))
> s.split

Error: Plot
          Df  Sum Sq Mean Sq F value Pr(>F)
block      2 1114.66  557.33  0.8994 0.5265
mix        1    6.14    6.14  0.0099 0.9298
Residuals  2 1239.37  619.68

Error: Within
          Df  Sum Sq Mean Sq F value Pr(>F)
graz       2  1.4464  0.7232  0.3073 0.7437
mix:graz   2  3.8206  1.9103  0.8117 0.4776
Residuals  8 18.8278  2.3535
> s.split[["Error: Plot"]]  ## extracting first list element works
          Df  Sum Sq Mean Sq F value Pr(>F)
block      2 1114.66  557.33  0.8994 0.5265
mix        1    6.14    6.14  0.0099 0.9298
Residuals  2 1239.37  619.68
> s.split[["Error: Plot"]]["mix ","Pr(>F)"]  ### <== FAILS
Error in s.split[["Error: Plot"]]["mix ", "Pr(>F)"] :
        incorrect number of dimensions

So where is the difference between the two?

Thanks for any hint

Pascal




-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From Ted.Harding at nessie.mcc.ac.uk  Sat Nov 29 11:09:18 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 29 Nov 2003 10:09:18 -0000 (GMT)
Subject: [R] significance in difference of proportions: What problema
In-Reply-To: <Pine.LNX.4.51.0311280856080.23047@artemis.imbe.med.uni-erlangen.de>
Message-ID: <XFMail.031129100918.Ted.Harding@nessie.mcc.ac.uk>

On 28-Nov-03 Torsten Hothorn wrote:
> yes, thats my understanding too. The "enumerative techniques" as
> you call it condition on the data actually observed and determine
> the null distribution of the associated test statistic from the data.
> In contrast, unconditional procedures require some assumptions to the
> underlying data generating process from which the null distribution is
> derived. The appropriate choice depends of the kind of experiment
> under test: In a randomized trial we would like to see all possible
> outcomes of the trial caused by "rerandomization" and the enumerative
> techniques are natural here. When we draw many samples from predefined
> populations, men and women, say, "rerandomization" of gender is of
> course not that easy and we may assume something about the data
> generating process :-)

Nice example, but it depends on how you look at it!

Suppose you have samples of n1 Men and n2 Women and record, for instance,
whether or not each is suffering from a cold (r1 and r2 respectively).
Do M & W differ in their risk of catching cold?

NH: No difference; implies that the R = (r1+r2) colds have selected
a random subset of the N=(n1+n2) individuals as victims; implies
that the n1 Men out of N are a random subset of the R+(N-R)
Colds/NonColds. So you then have a hypergeometric distribution and are
back with an "exact" test. But are we "assuming somthing about the
data generating process" here?

(Of course, in the background lurks the Ogre of Exchangeability,
in that the probability of catching cold may vary from person to
person, whether Man or Woman, but nothing in the information
plus NH suggests any reason to distinguish any arrangement of the
N people from any other; equivalent to a re-randomisation of
gender ... ??).

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 29-Nov-03                                       Time: 10:09:18
------------------------------ XFMail ------------------------------



From p.dalgaard at biostat.ku.dk  Sat Nov 29 12:32:41 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Nov 2003 12:32:41 +0100
Subject: [R] Indexing ANOVA table
In-Reply-To: <1070102267.3fc876fba6a2a@webmail.unibas.ch>
References: <1070102267.3fc876fba6a2a@webmail.unibas.ch>
Message-ID: <x2u14n2yw6.fsf@biostat.ku.dk>

Pascal.Niklaus at unibas.ch writes:

> Hi all,
> 
> I'd like to extract a value from an ANOVA table, but experience the following
> problem:
> 
> ### This works:
> 
> > s.pseudo <- summary(aov(m ~ block + mix*graz,data=split1))
> > s.pseudo
>             Df  Sum Sq Mean Sq F value  Pr(>F)
> block        2 1114.66  557.33  4.4296 0.04192 *
> mix          1    6.14    6.14  0.0488 0.82956
> graz         2    1.45    0.72  0.0057 0.99427
> mix:graz     2    3.82    1.91  0.0152 0.98495
> Residuals   10 1258.19  125.82
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> > s.pseudo[[1]]["mix ","Pr(>F)"]
> [1] 0.8295556
> 
> ### But this doesn't -- why?
> 
> > s.split <-  summary(aov(m ~ block + mix*graz + Error(Plot),data=split1))
> > s.split
> 
> Error: Plot
>           Df  Sum Sq Mean Sq F value Pr(>F)
> block      2 1114.66  557.33  0.8994 0.5265
> mix        1    6.14    6.14  0.0099 0.9298
> Residuals  2 1239.37  619.68
> 
> Error: Within
>           Df  Sum Sq Mean Sq F value Pr(>F)
> graz       2  1.4464  0.7232  0.3073 0.7437
> mix:graz   2  3.8206  1.9103  0.8117 0.4776
> Residuals  8 18.8278  2.3535
> > s.split[["Error: Plot"]]  ## extracting first list element works
>           Df  Sum Sq Mean Sq F value Pr(>F)
> block      2 1114.66  557.33  0.8994 0.5265
> mix        1    6.14    6.14  0.0099 0.9298
> Residuals  2 1239.37  619.68
> > s.split[["Error: Plot"]]["mix ","Pr(>F)"]  ### <== FAILS
> Error in s.split[["Error: Plot"]]["mix ", "Pr(>F)"] :
>         incorrect number of dimensions
> 
> So where is the difference between the two?
> 
> Thanks for any hint

There's an extra list level:

> example(aov)
...
> str(summary(npk.aovE)[["Error: Within"]])
List of 1
 $ :Classes anova  and `data.frame':    7 obs. of  5 variables:
  ..$ Df     : num [1:7] 1 1 1 1 1 1 12
  ..$ Sum Sq : num [1:7] 189.3   8.4  95.2  21.3  33.1 ...
  ..$ Mean Sq: num [1:7] 189.3   8.4  95.2  21.3  33.1 ...
  ..$ F value: num [1:7] 12.259  0.544  6.166  1.378  2.146 ...
  ..$ Pr(>F) : num [1:7] 0.00437 0.47490 0.02880 0.26317 0.16865 ...
 - attr(*, "class")= chr [1:2] "summary.aov" "listof"
> summary(npk.aovE)[["Error: Within"]][[1]]["N:P","Pr(>F)"]
[1] 0.2631653

As to *why* there's this extra level, you have to ask the author...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sat Nov 29 12:57:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Nov 2003 11:57:37 +0000 (GMT)
Subject: [R] Indexing ANOVA table
In-Reply-To: <1070102267.3fc876fba6a2a@webmail.unibas.ch>
Message-ID: <Pine.LNX.4.44.0311291154460.13346-100000@gannet.stats>

On Sat, 29 Nov 2003 Pascal.Niklaus at unibas.ch wrote:

> Hi all,
> 
> I'd like to extract a value from an ANOVA table, but experience the following
> problem:
> 
> ### This works:
> 
> > s.pseudo <- summary(aov(m ~ block + mix*graz,data=split1))
> > s.pseudo
>             Df  Sum Sq Mean Sq F value  Pr(>F)
> block        2 1114.66  557.33  4.4296 0.04192 *
> mix          1    6.14    6.14  0.0488 0.82956
> graz         2    1.45    0.72  0.0057 0.99427
> mix:graz     2    3.82    1.91  0.0152 0.98495
> Residuals   10 1258.19  125.82
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> > s.pseudo[[1]]["mix ","Pr(>F)"]
> [1] 0.8295556
> 
> ### But this doesn't -- why?

Why should it?

> > s.split <-  summary(aov(m ~ block + mix*graz + Error(Plot),data=split1))
> > s.split
> 
> Error: Plot
>           Df  Sum Sq Mean Sq F value Pr(>F)
> block      2 1114.66  557.33  0.8994 0.5265
> mix        1    6.14    6.14  0.0099 0.9298
> Residuals  2 1239.37  619.68
> 
> Error: Within
>           Df  Sum Sq Mean Sq F value Pr(>F)
> graz       2  1.4464  0.7232  0.3073 0.7437
> mix:graz   2  3.8206  1.9103  0.8117 0.4776
> Residuals  8 18.8278  2.3535
> > s.split[["Error: Plot"]]  ## extracting first list element works
>           Df  Sum Sq Mean Sq F value Pr(>F)
> block      2 1114.66  557.33  0.8994 0.5265
> mix        1    6.14    6.14  0.0099 0.9298
> Residuals  2 1239.37  619.68
> > s.split[["Error: Plot"]]["mix ","Pr(>F)"]  ### <== FAILS
> Error in s.split[["Error: Plot"]]["mix ", "Pr(>F)"] :
>         incorrect number of dimensions

You should have written

s.split[["Error: Plot"]][[1]]["mix ","Pr(>F)"]

> So where is the difference between the two?

One is an "aov" object, the other an "aovlist" object.  Take a closer look 
at print.summary.aov, for example.

More generally, learn how to look at R objects instead of assuming you
know what you are doing: unclass(s.split[["Error: Plot"]]) would have been
informative.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Sat Nov 29 12:58:38 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 29 Nov 2003 12:58:38 +0100
Subject: [R] performance gap between R 1.7.1 and 1.8.0
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CEBB@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CEBB@usrymx25.merck.com>
Message-ID: <16328.35310.3183.532529@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Fri, 28 Nov 2003 22:19:27 -0500 writes:

    AndyL> Dear R-help, A colleague of mine was running some
    AndyL> code on two of our boxes, and noticed a rather large
    AndyL> difference in running time.  We've so far isolated
    AndyL> the problem to the difference between R 1.7.1 and
    AndyL> 1.8.0, but not more than that.  The exact same code
    AndyL> took 933.5 seconds in 1.7.1, and 3594.4 seconds in
    AndyL> 1.8.1, on the same box.

I understand your concern.  I do believe that it must be some
peculiarity of your (or the non-standard packages you used
code).

Some wild guessing: 
Looking at your profiling table, and seeing  read.dcf()  makes
me think about library() -- which does call read.dcf() only when
called on a package that's not yet attached --- and the
bioconductor extra package management -- which for me makes only
the first time (!) attachment of bioconductor packages
relatively slow.  
I still have no idea how this could influence bootstrapping,
unless you detach() and attach() packages many times.
In any case, it might depend on the exact list (and order!?) of
packages present in search() when calling your code.

A very first step of diagnosis might be to activate
  trace(read.dcf)
  trace(library)
  options(verbose = TRUE)

A step further might be to patch read.dcf such that it prints
info 
       if(getOption("verbose")) { <<print what I am trying to read>> }

Martin



From tura at centroin.com.br  Sat Nov 29 14:39:19 2003
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sat, 29 Nov 2003 11:39:19 -0200
Subject: [R] MASS fitdistr()
Message-ID: <6.0.0.22.2.20031129113915.02b00bb0@pop.centroin.com.br>

At 15:49 27-11-2003, you wrote:
>Dear R experts,
>
>I am trying to use the R MASS library fitdistr() to fit the following
>list:
>
>k21stsList<-c(0.76697,0.57642,0.75938,0.82616,0.93706,0.77377,0.58923,0.37157,0.60796,1.00070,0.97529,0.62858,0.63504,0.68697,0.61714,0.75227,1.16390,0.66702,0.83578)
>
>as follows,
>
>library(MASS)
>fitdistr(k21stsList, "normal")
>
>But, I get
>
>Error in fitdistr(k21stsList, "normal") : 'start' must be a named list

Hi

You don?t put the start list, something like this

fitdistr(k21stsList, "normal",list(mean = 0.5 sd = 0.1))

      mean          sd    
  0.74584591   0.17908744 
 (0.04108548) (0.02904255)




Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil



From tblackw at umich.edu  Sat Nov 29 17:25:31 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sat, 29 Nov 2003 11:25:31 -0500 (EST)
Subject: [R] compile problem with gzfile
In-Reply-To: <200311282325.SAA18211@aeolus.geo.umass.edu>
References: <200311282325.SAA18211@aeolus.geo.umass.edu>
Message-ID: <Pine.SOL.4.58.0311291103291.26128@robotron.gpcc.itd.umich.edu>

William  -

I don't have an answer for you, just some stream of
consciousness rambling about how I would go about
diagnosing this, if it were my problem.

In my installation directory (of R-1.7.1 on linux) there
is a file  config.log  which contains all of the configure
script's queries and replies.  Yes, there is a difference
between configuring and compiling, but that file might be
one place to start looking for where the problem begins.
For me, 'grep gzfile config.log' returns no matching lines.
However, 'grep methods config.log' returns three lines
which say

config.status:884: creating src/library/methods/DESCRIPTION
config.status:884: creating src/library/methods/Makefile
config.status:884: creating src/library/methods/src/Makefile

Seems odd that the 'methods' package would be the only one
which fails to unpack.  Perhaps the problem is more general,
and, likely, more elementary.

Ah.  When you downloaded the source files, did you set 'binary'
in ftp or equivalent ?

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 28 Nov 2003, William D. McCoy wrote:

> I just finished compiling today's r-patched (R 1.8.1 patched) on my
> old Sparc 20 using gcc 3.3 along with Sun's f77.
>
> As it was compiling, I noticed an error regarding gzfile.  The compile
> process left the methods directory and continued on.  Obviously, there
> was a problem, but I don't have the original error message from the
> compiler.  After installing R, I get the following error message when
> I start R:
>
> Error in open.connection(con, "rb") : unable to open connection
> In addition: Warning message:
> cannot open compressed file
> `/usr/local/lib/R/library/methods/R/all.rda'
>
> A check for the file 'all.rda' showed that it does not exist.  I do
> have gzip installed and I have libz.so.1.1.4 in /usr/local/lib.  I
> realize this isn't much to go on, but does anyone have an idea what
> might be wrong?  Has anyone had a similar error?
>
> --
> William D. McCoy
> Geosciences
> University of Massachusetts
> Amherst, MA  01003
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From celso.barros at lady-margaret-hall.oxford.ac.uk  Sat Nov 29 17:52:02 2003
From: celso.barros at lady-margaret-hall.oxford.ac.uk (Celso Barros)
Date: Sat, 29 Nov 2003 16:52:02 +0000 (GMT)
Subject: [R] problems with xlab
Message-ID: <E1AQ8KA-0002Gi-00@wing3.herald.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031129/0a892d4f/attachment.pl

From ripley at stats.ox.ac.uk  Sat Nov 29 18:03:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Nov 2003 17:03:30 +0000 (GMT)
Subject: [R] compile problem with gzfile
In-Reply-To: <Pine.SOL.4.58.0311291103291.26128@robotron.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0311291658560.14026-100000@gannet.stats>

Try compiling after configure --without-zlib (available in a less 
obselete system than 1.7.1).  This skips your system's zlib (which is 
apparently fragile) and compiles that in the R sources.

On Sat, 29 Nov 2003, Thomas W Blackwell wrote:

> William  -
> 
> I don't have an answer for you, just some stream of
> consciousness rambling about how I would go about
> diagnosing this, if it were my problem.
> 
> In my installation directory (of R-1.7.1 on linux) there
> is a file  config.log  which contains all of the configure
> script's queries and replies.  Yes, there is a difference
> between configuring and compiling, but that file might be
> one place to start looking for where the problem begins.
> For me, 'grep gzfile config.log' returns no matching lines.

Nor should it: it is lib/zlib that is being invoked, and gzfile() is an R 
function.

> However, 'grep methods config.log' returns three lines
> which say
> 
> config.status:884: creating src/library/methods/DESCRIPTION
> config.status:884: creating src/library/methods/Makefile
> config.status:884: creating src/library/methods/src/Makefile
> 
> Seems odd that the 'methods' package would be the only one
> which fails to unpack.  

Not at all.  That is the only package that is installed as a compressed 
saved image rather than as a text source file.

> Perhaps the problem is more general,
> and, likely, more elementary.
> 
> Ah.  When you downloaded the source files, did you set 'binary'
> in ftp or equivalent ?
> 
> HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Fri, 28 Nov 2003, William D. McCoy wrote:
> 
> > I just finished compiling today's r-patched (R 1.8.1 patched) on my
> > old Sparc 20 using gcc 3.3 along with Sun's f77.
> >
> > As it was compiling, I noticed an error regarding gzfile.  The compile
> > process left the methods directory and continued on.  Obviously, there
> > was a problem, but I don't have the original error message from the
> > compiler.  After installing R, I get the following error message when
> > I start R:
> >
> > Error in open.connection(con, "rb") : unable to open connection
> > In addition: Warning message:
> > cannot open compressed file
> > `/usr/local/lib/R/library/methods/R/all.rda'
> >
> > A check for the file 'all.rda' showed that it does not exist.  I do
> > have gzip installed and I have libz.so.1.1.4 in /usr/local/lib.  I
> > realize this isn't much to go on, but does anyone have an idea what
> > might be wrong?  Has anyone had a similar error?
> >
> > --
> > William D. McCoy
> > Geosciences
> > University of Massachusetts
> > Amherst, MA  01003
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Sat Nov 29 18:30:33 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 29 Nov 2003 12:30:33 -0500
Subject: [R] problems with xlab
In-Reply-To: <E1AQ8KA-0002Gi-00@wing3.herald.ox.ac.uk>
Message-ID: <5.1.0.14.2.20031129122611.01fe2b68@127.0.0.1>

Dear Celso,

At 04:52 PM 11/29/2003 +0000, Celso Barros wrote:


>Dear R-list members,
>
>I'm using the 'effects' package to plot a graph with fixed values. For 
>some reason, I cannot change the label for the 'x' axis using 'xlab=""'. 
>The usual commands work for the y axis and for the main title. My last 
>attempt used the following syntax:
>
>model.effects<-(all.effects(model.1))
>plot (model.effects, main="Figure 1",xlab="Year",ylab="Change")
>
>The resulting graph has the default label for the x axis instead of 
>'Year'. The main title and the label for 'y' are as expected.
>
>Anyone knows what may be happening?

I'm afraid that you've found a bug in plot.effect(): I omitted specifying 
the xlab argument to xyplot() in one of the six cases that plot.effect() 
distinguishes. The fix is simple, and I'll shortly upload a new version of 
the package with it, but in the meantime, I'll send you (privately) the 
fixed version of plot.effect().

I apologize for the problem,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From wdmccoy at geo.umass.edu  Sat Nov 29 22:10:05 2003
From: wdmccoy at geo.umass.edu (William D. McCoy)
Date: Sat, 29 Nov 2003 16:10:05 -0500 (EST)
Subject: [R] compile problem with gzfile
In-Reply-To: <Pine.LNX.4.44.0311291658560.14026-100000@gannet.stats>
References: <Pine.SOL.4.58.0311291103291.26128@robotron.gpcc.itd.umich.edu>
	<Pine.LNX.4.44.0311291658560.14026-100000@gannet.stats>
Message-ID: <200311292110.QAA04630@aeolus.geo.umass.edu>

Thanks to Brian Ripley and Thomas Blackwell for responses concerning
my problem.  I am following Brian's suggestion and recompiling after
configuring with --without-zlib.  The compile takes a couple of hours
on the old Sparc 20, but the process has passed the point where it
failed before and has successfully completed compiliation of the
methods package.  So it looks like it will be alright.

Prof Brian Ripley writes:
 > Try compiling after configure --without-zlib (available in a less 
 > obselete system than 1.7.1).  This skips your system's zlib (which is 
 > apparently fragile) and compiles that in the R sources.
 > 
 > On Sat, 29 Nov 2003, Thomas W Blackwell wrote:
 > 
 > > William  -
 > > 
 > > I don't have an answer for you, just some stream of
 > > consciousness rambling about how I would go about
 > > diagnosing this, if it were my problem.
 > > 
 > > In my installation directory (of R-1.7.1 on linux) there
 > > is a file  config.log  which contains all of the configure
 > > script's queries and replies.  Yes, there is a difference
 > > between configuring and compiling, but that file might be
 > > one place to start looking for where the problem begins.
 > > For me, 'grep gzfile config.log' returns no matching lines.
 > 
 > Nor should it: it is lib/zlib that is being invoked, and gzfile() is an R 
 > function.
 > 
 > > However, 'grep methods config.log' returns three lines
 > > which say
 > > 
 > > config.status:884: creating src/library/methods/DESCRIPTION
 > > config.status:884: creating src/library/methods/Makefile
 > > config.status:884: creating src/library/methods/src/Makefile
 > > 
 > > Seems odd that the 'methods' package would be the only one
 > > which fails to unpack.  
 > 
 > Not at all.  That is the only package that is installed as a compressed 
 > saved image rather than as a text source file.
 > 
 > > Perhaps the problem is more general,
 > > and, likely, more elementary.
 > > 
 > > Ah.  When you downloaded the source files, did you set 'binary'
 > > in ftp or equivalent ?
 > > 
 > > HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
 > > 
 > > On Fri, 28 Nov 2003, William D. McCoy wrote:
 > > 
 > > > I just finished compiling today's r-patched (R 1.8.1 patched) on my
 > > > old Sparc 20 using gcc 3.3 along with Sun's f77.
 > > >
 > > > As it was compiling, I noticed an error regarding gzfile.  The compile
 > > > process left the methods directory and continued on.  Obviously, there
 > > > was a problem, but I don't have the original error message from the
 > > > compiler.  After installing R, I get the following error message when
 > > > I start R:
 > > >
 > > > Error in open.connection(con, "rb") : unable to open connection
 > > > In addition: Warning message:
 > > > cannot open compressed file
 > > > `/usr/local/lib/R/library/methods/R/all.rda'
 > > >
 > > > A check for the file 'all.rda' showed that it does not exist.  I do
 > > > have gzip installed and I have libz.so.1.1.4 in /usr/local/lib.  I
 > > > realize this isn't much to go on, but does anyone have an idea what
 > > > might be wrong?  Has anyone had a similar error?
 > > >
 > > > --
 > > > William D. McCoy
 > > > Geosciences
 > > > University of Massachusetts
 > > > Amherst, MA  01003
 > > >
 > > > ______________________________________________
 > > > R-help at stat.math.ethz.ch mailing list
 > > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 > > >
 > > 
 > > ______________________________________________
 > > R-help at stat.math.ethz.ch mailing list
 > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 > > 
 > > 
 > 
 > -- 
 > Brian D. Ripley,                  ripley at stats.ox.ac.uk
 > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
 > University of Oxford,             Tel:  +44 1865 272861 (self)
 > 1 South Parks Road,                     +44 1865 272866 (PA)
 > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 > 

-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA  01003



From szank at web.de  Sat Nov 29 22:56:40 2003
From: szank at web.de (Sebastian Zank)
Date: Sat, 29 Nov 2003 22:56:40 +0100
Subject: [R] Classic Levene Test of variances
Message-ID: <000b01c3b6c3$ac6f2930$7193fea9@zankt28ydsx7go>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20031129/1172acf7/attachment.pl

From p.dalgaard at biostat.ku.dk  Sat Nov 29 23:46:47 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Nov 2003 23:46:47 +0100
Subject: [R] Classic Levene Test of variances
In-Reply-To: <000b01c3b6c3$ac6f2930$7193fea9@zankt28ydsx7go>
References: <000b01c3b6c3$ac6f2930$7193fea9@zankt28ydsx7go>
Message-ID: <x2ptfa3i94.fsf@biostat.ku.dk>

"Sebastian Zank" <szank at web.de> writes:

> Hello,
> 
> I am searching for the classic Levene test of variances in R but I don't find the function. Is there any command or do I have to programm the test by myself? Does anybody know? Help would be fine because R is very new to me.

There's one inside the Rcmdr package.

http://cran.r-project.org/src/contrib/PACKAGES.html#Rcmdr

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Sun Nov 30 05:42:05 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 29 Nov 2003 23:42:05 -0500 (EST)
Subject: [R] tcltk problem with <Button-2>
Message-ID: <20031130044205.076D4394F@mprdmxin.myway.com>



The following R code works as expected:

require( tcltk )
tt <- tktoplevel()

# create a button labelled A that changes to B when pressed
pressed <- function() tkconfigure( tt.but, text="B" )
tt.but <- tkbutton( tt, text="A", command=pressed )
tkpack(tt.but)

# if Control-Button-1 pressed change button label to C
e <- expression( tkconfigure( tt.but, text="C" ), break )
tkbind(tt.but, "<Control-Button-1>", e )

But if I simply replace Control-Button-1 with Button-2 in the tkbind
command, i.e. the last line, then nothing happens when I press 
Button-2 (which I assume is the right mouse button).

I also tried removing the break and using a function instead of an
expression but it also does not respond, i.e. I tried replacing
the last line with:

tkbind(tt.but, "<Button-2>", function() tkconfigure( tt.but, text="C" ) ) 

I am using Windows 2000 and R 1.8.1 and am pasting the script 
into Rterm to make sure that the Rgui does not interfere with it.



From h.wickham at auckland.ac.nz  Sun Nov 30 10:20:03 2003
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Sun, 30 Nov 2003 22:20:03 +1300
Subject: [R] with for objects
Message-ID: <3FC9B643.6050700@auckland.ac.nz>

Is there a form of with (or an equivalent function) that can be applied 
to objects?

I'd like to be able to write something like (drawing from bioconductor + 
trellis as an example)
xyplot(maA ~ maM | maPrintTip, object = swirl[,1]) which would be 
interpreted as xyplot(swirl[,1]@maA ~ swirl[,1]@maM | 
swirl[,1]@maPrintTip) (or even better, match functions not slots eg. as 
xyplot(maA(swirl[,1]) ~ maM(swirl[,1]) | maPrintTip(swirl[,1])))

If there isn't, can any one offer any tips on writing such a function.  
I presume I'd have to deparse the formula, match the text with the 
slots/methods of the function, create the appropriate call objects and 
then call them?

Thanks for you help,

Hadley



From tencpa at yahoo.it  Sun Nov 30 10:47:59 2003
From: tencpa at yahoo.it (Paolo Tenconi)
Date: Sun, 30 Nov 2003 10:47:59 +0100
Subject: [R] Escape optimization
Message-ID: <oprzf2t91n0rxtxe@smtp.mail.yahoo.it>

Hello,
I'm using optim and I'd like to know if there is a way to escape the 
optimization process at a given time (for example by pressing some sequence 
on the keyboard) while retaining the optimization results achieved.
I found this very useful using the Aptech GAUSS optimization module.
Thanks
Paolo



From ripley at stats.ox.ac.uk  Sun Nov 30 11:27:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 30 Nov 2003 10:27:50 +0000 (GMT)
Subject: [R] Escape optimization
In-Reply-To: <oprzf2t91n0rxtxe@smtp.mail.yahoo.it>
Message-ID: <Pine.LNX.4.44.0311301025300.31440-100000@gannet.stats>

No, the status of the optimization is only in C code until the finish.

Whyever would a partially run optimization be useful?  You can arrange for 
your optimizand to record the latest set of parameters if you wish, and 
then just interrupt R in the usual way.  Or you can set a limit on the 
number of iterations.

On Sun, 30 Nov 2003, Paolo Tenconi wrote:

> I'm using optim and I'd like to know if there is a way to escape the 
> optimization process at a given time (for example by pressing some sequence 
> on the keyboard) while retaining the optimization results achieved.
> I found this very useful using the Aptech GAUSS optimization module.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sun Nov 30 12:20:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Nov 2003 12:20:39 +0100
Subject: [R] tcltk problem with <Button-2>
In-Reply-To: <20031130044205.076D4394F@mprdmxin.myway.com>
References: <20031130044205.076D4394F@mprdmxin.myway.com>
Message-ID: <x2ad6e2jco.fsf@biostat.ku.dk>

"Gabor Grothendieck" <ggrothendieck at myway.com> writes:

> But if I simply replace Control-Button-1 with Button-2 in the tkbind
> command, i.e. the last line, then nothing happens when I press 
> Button-2 (which I assume is the right mouse button).

It's the middle button (Tk was designed for three-button mice). The
right button is Button-3.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From busscher at wiz.uni-kassel.de  Sun Nov 30 21:03:15 2003
From: busscher at wiz.uni-kassel.de (Nicolaas Busscher)
Date: Sun, 30 Nov 2003 21:03:15 +0100
Subject: [R] box m-test in R , 2nd
Message-ID: <20031130210315.15305c55.busscher@wiz.uni-kassel.de>

Hi all,
For the box m-test i found a matlab script for the box m-test. i
converted it to R and it seems to run so far with the testdata from
the author. I am not a statistician, so for me it would be helpfull if
somebody can supply me with data and the output, so i can check it
further. when i have the permission from the author (i asked him this
morning by E-mail) i will share it, if there are people who wants to
test and use it.

thanks
Nicolaas Busscher
 
-- 
Dr.Nicolaas Busscher Universit?t GH Kassel
Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Sun Nov 30 22:10:52 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 30 Nov 2003 13:10:52 -0800 (PST)
Subject: [R] Discovering methods
In-Reply-To: <20031129040559.499A83962@mprdmxin.myway.com>
References: <20031129040559.499A83962@mprdmxin.myway.com>
Message-ID: <Pine.A41.4.58.0311301308110.142760@homer01.u.washington.edu>

On Fri, 28 Nov 2003, Gabor Grothendieck wrote:

>
>
> Sure, but why are some methods found using methods("POSIXct")
> while other methods not found?
>
> It would be nice to have some reliable documentation-independent
> way to discover all the methods for a class.

Indeed it would, but that requires registration of methods using either
the S4 approach or the functions for handling S3 methods in namespaces.

Without this, it is simply not possible to decide, for example, whether
t.test.formula is a method for t() or for t.test() or a separate function.


	-thomas



