From c.kong at pmci.unimelb.edu.au  Tue Feb 29 04:29:05 2000
From: c.kong at pmci.unimelb.edu.au (Kong, Chuang Fong)
Date: Tue, 29 Feb 2000 14:29:05 +1100
Subject: [R] RE: r-excel interface code
Message-ID: <B29D3ABE5A8CD311869C0080C8E7EAD43A840F@raid.pmci.unimelb.edu.au>

Dear Erich,
do you have them for windows NT? thanks.

Best regards,
Chuang Fong Kong, Ph D
Head, Microarrays
Peter MacCallum Cancer Institute - Research
St. Andrew's Place, East Melbourne
Victoria 3002, Australia
Tel: 61 3 9656-1796 or 1138
Fax: 61 3 9656-1411
e-mail: c.kong at pmci.unimelb.edu.au



-----Original Message-----
From: Erich Neuwirth [mailto:erich.neuwirth at univie.ac.at]
Sent: Friday, February 25, 2000 11:26 PM
To: r-announce at stat.math.ethz.ch
Subject: r-excel interface code



some of you might be interested.

i just uploaded the first release of my 
r-excel interface package to CRAN.

it is in
contributed extensions
nonstandard extensions

erich neuwirth

--
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-announce mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000229/d833b173/attachment.html

From edd at debian.org  Tue Feb 29 05:43:10 2000
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 28 Feb 2000 23:43:10 -0500 (EST)
Subject: [R] RE: r-excel interface code
In-Reply-To: <B29D3ABE5A8CD311869C0080C8E7EAD43A840F@raid.pmci.unimelb.edu.au>
References: <B29D3ABE5A8CD311869C0080C8E7EAD43A840F@raid.pmci.unimelb.edu.au>
Message-ID: <14523.20005.686416.453958@sonny.eddelbuettel.com>


  Chuang Fong>  Dear Erich, do you have them for windows NT? thanks.

Yes, it works under NT. You also need the DCOM server from the same
subdirectory of 'non-standard contributions'.

-- 
According to the latest figures, 43% of all statistics are totally worthless.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Tue Feb 29 08:21:48 2000
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Tue, 29 Feb 2000 08:21:48 +0100
Subject: [R] mapping of colornames into hsv: half way done
Message-ID: <000401bf8285$a4e6beb0$a9021aac@joelschlaegel>



Ok,
now we have the mapping of color names to color codes (see below) and
conversion to rgb (something like Ben Bolker's function), but how to convert
rgb to hsv?

Thanks to Brian Ripley, Peter Dalgaard and Ben Bolker
Details below


Regards


Jens




  etc/colors.big maps 455 names to rgb in S syntax
  etc/rgb.txt maps 657 names to rgb in C syntax, but unlike colors() it has
mixed upper and lower case

The C source has the information twice
  rgb.c maps 657 names to rgb (mixed upper and lower case)
  graphics.c maps 657 names tp colorstrings (lower case only)

internal name2col() and R colors() accesses those in graphics.c


Here is the color representations from graphics.c in R code

.ColorDataBase <-  matrix(c(
    "white",		"#FFFFFF",
    "aliceblue",	"#F0F8FF",
    "antiquewhite",	"#FAEBD7",
    "antiquewhite1",	"#FFEFDB",
    "antiquewhite2",	"#EEDFCC",
    "antiquewhite3",	"#CDC0B0",
    "antiquewhite4",	"#8B8378",
    "aquamarine",	"#7FFFD4",
    "aquamarine1",	"#7FFFD4",
    "aquamarine2",	"#76EEC6",
    "aquamarine3",	"#66CDAA",
    "aquamarine4",	"#458B74",
    "azure",		"#F0FFFF",
    "azure1",		"#F0FFFF",
    "azure2",		"#E0EEEE",
    "azure3",		"#C1CDCD",
    "azure4",		"#838B8B",
    "beige",		"#F5F5DC",
    "bisque",		"#FFE4C4",
    "bisque1",		"#FFE4C4",
    "bisque2",		"#EED5B7",
    "bisque3",		"#CDB79E",
    "bisque4",		"#8B7D6B",
    "black",		"#000000",
    "blanchedalmond",	"#FFEBCD",
    "blue",		"#0000FF",
    "blue1",		"#0000FF",
    "blue2",		"#0000EE",
    "blue3",		"#0000CD",
    "blue4",		"#00008B",
    "blueviolet",	"#8A2BE2",
    "brown",		"#A52A2A",
    "brown1",		"#FF4040",
    "brown2",		"#EE3B3B",
    "brown3",		"#CD3333",
    "brown4",		"#8B2323",
    "burlywood",	"#DEB887",
    "burlywood1",	"#FFD39B",
    "burlywood2",	"#EEC591",
    "burlywood3",	"#CDAA7D",
    "burlywood4",	"#8B7355",
    "cadetblue",	"#5F9EA0",
    "cadetblue1",	"#98F5FF",
    "cadetblue2",	"#8EE5EE",
    "cadetblue3",	"#7AC5CD",
    "cadetblue4",	"#53868B",
    "chartreuse",	"#7FFF00",
    "chartreuse1",	"#7FFF00",
    "chartreuse2",	"#76EE00",
    "chartreuse3",	"#66CD00",
    "chartreuse4",	"#458B00",
    "chocolate",	"#D2691E",
    "chocolate1",	"#FF7F24",
    "chocolate2",	"#EE7621",
    "chocolate3",	"#CD661D",
    "chocolate4",	"#8B4513",
    "coral",		"#FF7F50",
    "coral1",		"#FF7256",
    "coral2",		"#EE6A50",
    "coral3",		"#CD5B45",
    "coral4",		"#8B3E2F",
    "cornflowerblue",	"#6495ED",
    "cornsilk",	"#FFF8DC",
    "cornsilk1",	"#FFF8DC",
    "cornsilk2",	"#EEE8CD",
    "cornsilk3",	"#CDC8B1",
    "cornsilk4",	"#8B8878",
    "cyan",		"#00FFFF",
    "cyan1",		"#00FFFF",
    "cyan2",		"#00EEEE",
    "cyan3",		"#00CDCD",
    "cyan4",		"#008B8B",
    "darkblue",	"#00008B",
    "darkcyan",	"#008B8B",
    "darkgoldenrod",	"#B8860B",
    "darkgoldenrod1",	"#FFB90F",
    "darkgoldenrod2",	"#EEAD0E",
    "darkgoldenrod3",	"#CD950C",
    "darkgoldenrod4",	"#8B6508",
    "darkgray",	"#A9A9A9",
    "darkgreen",	"#006400",
    "darkgrey",	"#A9A9A9",
    "darkkhaki",	"#BDB76B",
    "darkmagenta",	"#8B008B",
    "darkolivegreen",	"#556B2F",
    "darkolivegreen1",	"#CAFF70",
    "darkolivegreen2",	"#BCEE68",
    "darkolivegreen3",	"#A2CD5A",
    "darkolivegreen4",	"#6E8B3D",
    "darkorange",	"#FF8C00",
    "darkorange1",	"#FF7F00",
    "darkorange2",	"#EE7600",
    "darkorange3",	"#CD6600",
    "darkorange4",	"#8B4500",
    "darkorchid",	"#9932CC",
    "darkorchid1",	"#BF3EFF",
    "darkorchid2",	"#B23AEE",
    "darkorchid3",	"#9A32CD",
    "darkorchid4",	"#68228B",
    "darkred",		"#8B0000",
    "darksalmon",	"#E9967A",
    "darkseagreen",	"#8FBC8F",
    "darkseagreen1",	"#C1FFC1",
    "darkseagreen2",	"#B4EEB4",
    "darkseagreen3",	"#9BCD9B",
    "darkseagreen4",	"#698B69",
    "darkslateblue",	"#483D8B",
    "darkslategray",	"#2F4F4F",
    "darkslategray1",	"#97FFFF",
    "darkslategray2",	"#8DEEEE",
    "darkslategray3",	"#79CDCD",
    "darkslategray4",	"#528B8B",
    "darkslategrey",	"#2F4F4F",
    "darkturquoise",	"#00CED1",
    "darkviolet",	"#9400D3",
    "deeppink",	"#FF1493",
    "deeppink1",	"#FF1493",
    "deeppink2",	"#EE1289",
    "deeppink3",	"#CD1076",
    "deeppink4",	"#8B0A50",
    "deepskyblue",	"#00BFFF",
    "deepskyblue1",	"#00BFFF",
    "deepskyblue2",	"#00B2EE",
    "deepskyblue3",	"#009ACD",
    "deepskyblue4",	"#00688B",
    "dimgray",		"#696969",
    "dimgrey",		"#696969",
    "dodgerblue",	"#1E90FF",
    "dodgerblue1",	"#1E90FF",
    "dodgerblue2",	"#1C86EE",
    "dodgerblue3",	"#1874CD",
    "dodgerblue4",	"#104E8B",
    "firebrick",	"#B22222",
    "firebrick1",	"#FF3030",
    "firebrick2",	"#EE2C2C",
    "firebrick3",	"#CD2626",
    "firebrick4",	"#8B1A1A",
    "floralwhite",	"#FFFAF0",
    "forestgreen",	"#228B22",
    "gainsboro",	"#DCDCDC",
    "ghostwhite",	"#F8F8FF",
    "gold",		"#FFD700",
    "gold1",		"#FFD700",
    "gold2",		"#EEC900",
    "gold3",		"#CDAD00",
    "gold4",		"#8B7500",
    "goldenrod",	"#DAA520",
    "goldenrod1",	"#FFC125",
    "goldenrod2",	"#EEB422",
    "goldenrod3",	"#CD9B1D",
    "goldenrod4",	"#8B6914",
    "gray",		"#BEBEBE",
    "gray0",		"#000000",
    "gray1",		"#030303",
    "gray2",		"#050505",
    "gray3",		"#080808",
    "gray4",		"#0A0A0A",
    "gray5",		"#0D0D0D",
    "gray6",		"#0F0F0F",
    "gray7",		"#121212",
    "gray8",		"#141414",
    "gray9",		"#171717",
    "gray10",		"#1A1A1A",
    "gray11",		"#1C1C1C",
    "gray12",		"#1F1F1F",
    "gray13",		"#212121",
    "gray14",		"#242424",
    "gray15",		"#262626",
    "gray16",		"#292929",
    "gray17",		"#2B2B2B",
    "gray18",		"#2E2E2E",
    "gray19",		"#303030",
    "gray20",		"#333333",
    "gray21",		"#363636",
    "gray22",		"#383838",
    "gray23",		"#3B3B3B",
    "gray24",		"#3D3D3D",
    "gray25",		"#404040",
    "gray26",		"#424242",
    "gray27",		"#454545",
    "gray28",		"#474747",
    "gray29",		"#4A4A4A",
    "gray30",		"#4D4D4D",
    "gray31",		"#4F4F4F",
    "gray32",		"#525252",
    "gray33",		"#545454",
    "gray34",		"#575757",
    "gray35",		"#595959",
    "gray36",		"#5C5C5C",
    "gray37",		"#5E5E5E",
    "gray38",		"#616161",
    "gray39",		"#636363",
    "gray40",		"#666666",
    "gray41",		"#696969",
    "gray42",		"#6B6B6B",
    "gray43",		"#6E6E6E",
    "gray44",		"#707070",
    "gray45",		"#737373",
    "gray46",		"#757575",
    "gray47",		"#787878",
    "gray48",		"#7A7A7A",
    "gray49",		"#7D7D7D",
    "gray50",		"#7F7F7F",
    "gray51",		"#828282",
    "gray52",		"#858585",
    "gray53",		"#878787",
    "gray54",		"#8A8A8A",
    "gray55",		"#8C8C8C",
    "gray56",		"#8F8F8F",
    "gray57",		"#919191",
    "gray58",		"#949494",
    "gray59",		"#969696",
    "gray60",		"#999999",
    "gray61",		"#9C9C9C",
    "gray62",		"#9E9E9E",
    "gray63",		"#A1A1A1",
    "gray64",		"#A3A3A3",
    "gray65",		"#A6A6A6",
    "gray66",		"#A8A8A8",
    "gray67",		"#ABABAB",
    "gray68",		"#ADADAD",
    "gray69",		"#B0B0B0",
    "gray70",		"#B3B3B3",
    "gray71",		"#B5B5B5",
    "gray72",		"#B8B8B8",
    "gray73",		"#BABABA",
    "gray74",		"#BDBDBD",
    "gray75",		"#BFBFBF",
    "gray76",		"#C2C2C2",
    "gray77",		"#C4C4C4",
    "gray78",		"#C7C7C7",
    "gray79",		"#C9C9C9",
    "gray80",		"#CCCCCC",
    "gray81",		"#CFCFCF",
    "gray82",		"#D1D1D1",
    "gray83",		"#D4D4D4",
    "gray84",		"#D6D6D6",
    "gray85",		"#D9D9D9",
    "gray86",		"#DBDBDB",
    "gray87",		"#DEDEDE",
    "gray88",		"#E0E0E0",
    "gray89",		"#E3E3E3",
    "gray90",		"#E5E5E5",
    "gray91",		"#E8E8E8",
    "gray92",		"#EBEBEB",
    "gray93",		"#EDEDED",
    "gray94",		"#F0F0F0",
    "gray95",		"#F2F2F2",
    "gray96",		"#F5F5F5",
    "gray97",		"#F7F7F7",
    "gray98",		"#FAFAFA",
    "gray99",		"#FCFCFC",
    "gray100",		"#FFFFFF",
    "green",		"#00FF00",
    "green1",		"#00FF00",
    "green2",		"#00EE00",
    "green3",		"#00CD00",
    "green4",		"#008B00",
    "greenyellow",	"#ADFF2F",
    "grey",		"#BEBEBE",
    "grey0",		"#000000",
    "grey1",		"#030303",
    "grey2",		"#050505",
    "grey3",		"#080808",
    "grey4",		"#0A0A0A",
    "grey5",		"#0D0D0D",
    "grey6",		"#0F0F0F",
    "grey7",		"#121212",
    "grey8",		"#141414",
    "grey9",		"#171717",
    "grey10",		"#1A1A1A",
    "grey11",		"#1C1C1C",
    "grey12",		"#1F1F1F",
    "grey13",		"#212121",
    "grey14",		"#242424",
    "grey15",		"#262626",
    "grey16",		"#292929",
    "grey17",		"#2B2B2B",
    "grey18",		"#2E2E2E",
    "grey19",		"#303030",
    "grey20",		"#333333",
    "grey21",		"#363636",
    "grey22",		"#383838",
    "grey23",		"#3B3B3B",
    "grey24",		"#3D3D3D",
    "grey25",		"#404040",
    "grey26",		"#424242",
    "grey27",		"#454545",
    "grey28",		"#474747",
    "grey29",		"#4A4A4A",
    "grey30",		"#4D4D4D",
    "grey31",		"#4F4F4F",
    "grey32",		"#525252",
    "grey33",		"#545454",
    "grey34",		"#575757",
    "grey35",		"#595959",
    "grey36",		"#5C5C5C",
    "grey37",		"#5E5E5E",
    "grey38",		"#616161",
    "grey39",		"#636363",
    "grey40",		"#666666",
    "grey41",		"#696969",
    "grey42",		"#6B6B6B",
    "grey43",		"#6E6E6E",
    "grey44",		"#707070",
    "grey45",		"#737373",
    "grey46",		"#757575",
    "grey47",		"#787878",
    "grey48",		"#7A7A7A",
    "grey49",		"#7D7D7D",
    "grey50",		"#7F7F7F",
    "grey51",		"#828282",
    "grey52",		"#858585",
    "grey53",		"#878787",
    "grey54",		"#8A8A8A",
    "grey55",		"#8C8C8C",
    "grey56",		"#8F8F8F",
    "grey57",		"#919191",
    "grey58",		"#949494",
    "grey59",		"#969696",
    "grey60",		"#999999",
    "grey61",		"#9C9C9C",
    "grey62",		"#9E9E9E",
    "grey63",		"#A1A1A1",
    "grey64",		"#A3A3A3",
    "grey65",		"#A6A6A6",
    "grey66",		"#A8A8A8",
    "grey67",		"#ABABAB",
    "grey68",		"#ADADAD",
    "grey69",		"#B0B0B0",
    "grey70",		"#B3B3B3",
    "grey71",		"#B5B5B5",
    "grey72",		"#B8B8B8",
    "grey73",		"#BABABA",
    "grey74",		"#BDBDBD",
    "grey75",		"#BFBFBF",
    "grey76",		"#C2C2C2",
    "grey77",		"#C4C4C4",
    "grey78",		"#C7C7C7",
    "grey79",		"#C9C9C9",
    "grey80",		"#CCCCCC",
    "grey81",		"#CFCFCF",
    "grey82",		"#D1D1D1",
    "grey83",		"#D4D4D4",
    "grey84",		"#D6D6D6",
    "grey85",		"#D9D9D9",
    "grey86",		"#DBDBDB",
    "grey87",		"#DEDEDE",
    "grey88",		"#E0E0E0",
    "grey89",		"#E3E3E3",
    "grey90",		"#E5E5E5",
    "grey91",		"#E8E8E8",
    "grey92",		"#EBEBEB",
    "grey93",		"#EDEDED",
    "grey94",		"#F0F0F0",
    "grey95",		"#F2F2F2",
    "grey96",		"#F5F5F5",
    "grey97",		"#F7F7F7",
    "grey98",		"#FAFAFA",
    "grey99",		"#FCFCFC",
    "grey100",		"#FFFFFF",
    "honeydew",	"#F0FFF0",
    "honeydew1",	"#F0FFF0",
    "honeydew2",	"#E0EEE0",
    "honeydew3",	"#C1CDC1",
    "honeydew4",	"#838B83",
    "hotpink",		"#FF69B4",
    "hotpink1",	"#FF6EB4",
    "hotpink2",	"#EE6AA7",
    "hotpink3",	"#CD6090",
    "hotpink4",	"#8B3A62",
    "indianred",	"#CD5C5C",
    "indianred1",	"#FF6A6A",
    "indianred2",	"#EE6363",
    "indianred3",	"#CD5555",
    "indianred4",	"#8B3A3A",
    "ivory",		"#FFFFF0",
    "ivory1",		"#FFFFF0",
    "ivory2",		"#EEEEE0",
    "ivory3",		"#CDCDC1",
    "ivory4",		"#8B8B83",
    "khaki",		"#F0E68C",
    "khaki1",		"#FFF68F",
    "khaki2",		"#EEE685",
    "khaki3",		"#CDC673",
    "khaki4",		"#8B864E",
    "lavender",	"#E6E6FA",
    "lavenderblush",	"#FFF0F5",
    "lavenderblush1",	"#FFF0F5",
    "lavenderblush2",	"#EEE0E5",
    "lavenderblush3",	"#CDC1C5",
    "lavenderblush4",	"#8B8386",
    "lawngreen",	"#7CFC00",
    "lemonchiffon",	"#FFFACD",
    "lemonchiffon1",	"#FFFACD",
    "lemonchiffon2",	"#EEE9BF",
    "lemonchiffon3",	"#CDC9A5",
    "lemonchiffon4",	"#8B8970",
    "lightblue",	"#ADD8E6",
    "lightblue1",	"#BFEFFF",
    "lightblue2",	"#B2DFEE",
    "lightblue3",	"#9AC0CD",
    "lightblue4",	"#68838B",
    "lightcoral",	"#F08080",
    "lightcyan",	"#E0FFFF",
    "lightcyan1",	"#E0FFFF",
    "lightcyan2",	"#D1EEEE",
    "lightcyan3",	"#B4CDCD",
    "lightcyan4",	"#7A8B8B",
    "lightgoldenrod",	"#EEDD82",
    "lightgoldenrod1",	"#FFEC8B",
    "lightgoldenrod2",	"#EEDC82",
    "lightgoldenrod3",	"#CDBE70",
    "lightgoldenrod4",	"#8B814C",
    "lightgoldenrodyellow","#FAFAD2",
    "lightgray",	"#D3D3D3",
    "lightgreen",	"#90EE90",
    "lightgrey",	"#D3D3D3",
    "lightpink",	"#FFB6C1",
    "lightpink1",	"#FFAEB9",
    "lightpink2",	"#EEA2AD",
    "lightpink3",	"#CD8C95",
    "lightpink4",	"#8B5F65",
    "lightsalmon",	"#FFA07A",
    "lightsalmon1",	"#FFA07A",
    "lightsalmon2",	"#EE9572",
    "lightsalmon3",	"#CD8162",
    "lightsalmon4",	"#8B5742",
    "lightseagreen",	"#20B2AA",
    "lightskyblue",	"#87CEFA",
    "lightskyblue1",	"#B0E2FF",
    "lightskyblue2",	"#A4D3EE",
    "lightskyblue3",	"#8DB6CD",
    "lightskyblue4",	"#607B8B",
    "lightslateblue",	"#8470FF",
    "lightslategray",	"#778899",
    "lightslategrey",	"#778899",
    "lightsteelblue",	"#B0C4DE",
    "lightsteelblue1",	"#CAE1FF",
    "lightsteelblue2",	"#BCD2EE",
    "lightsteelblue3",	"#A2B5CD",
    "lightsteelblue4",	"#6E7B8B",
    "lightyellow",	"#FFFFE0",
    "lightyellow1",	"#FFFFE0",
    "lightyellow2",	"#EEEED1",
    "lightyellow3",	"#CDCDB4",
    "lightyellow4",	"#8B8B7A",
    "limegreen",	"#32CD32",
    "linen",		"#FAF0E6",
    "magenta",		"#FF00FF",
    "magenta1",	"#FF00FF",
    "magenta2",	"#EE00EE",
    "magenta3",	"#CD00CD",
    "magenta4",	"#8B008B",
    "maroon",		"#B03060",
    "maroon1",		"#FF34B3",
    "maroon2",		"#EE30A7",
    "maroon3",		"#CD2990",
    "maroon4",		"#8B1C62",
    "mediumaquamarine","#66CDAA",
    "mediumblue",	"#0000CD",
    "mediumorchid",	"#BA55D3",
    "mediumorchid1",	"#E066FF",
    "mediumorchid2",	"#D15FEE",
    "mediumorchid3",	"#B452CD",
    "mediumorchid4",	"#7A378B",
    "mediumpurple",	"#9370DB",
    "mediumpurple1",	"#AB82FF",
    "mediumpurple2",	"#9F79EE",
    "mediumpurple3",	"#8968CD",
    "mediumpurple4",	"#5D478B",
    "mediumseagreen",	"#3CB371",
    "mediumslateblue",	"#7B68EE",
    "mediumspringgreen","#00FA9A",
    "mediumturquoise",	"#48D1CC",
    "mediumvioletred",	"#C71585",
    "midnightblue",	"#191970",
    "mintcream",	"#F5FFFA",
    "mistyrose",	"#FFE4E1",
    "mistyrose1",	"#FFE4E1",
    "mistyrose2",	"#EED5D2",
    "mistyrose3",	"#CDB7B5",
    "mistyrose4",	"#8B7D7B",
    "moccasin",	"#FFE4B5",
    "navajowhite",	"#FFDEAD",
    "navajowhite1",	"#FFDEAD",
    "navajowhite2",	"#EECFA1",
    "navajowhite3",	"#CDB38B",
    "navajowhite4",	"#8B795E",
    "navy",		"#000080",
    "navyblue",	"#000080",
    "oldlace",		"#FDF5E6",
    "olivedrab",	"#6B8E23",
    "olivedrab1",	"#C0FF3E",
    "olivedrab2",	"#B3EE3A",
    "olivedrab3",	"#9ACD32",
    "olivedrab4",	"#698B22",
    "orange",		"#FFA500",
    "orange1",		"#FFA500",
    "orange2",		"#EE9A00",
    "orange3",		"#CD8500",
    "orange4",		"#8B5A00",
    "orangered",	"#FF4500",
    "orangered1",	"#FF4500",
    "orangered2",	"#EE4000",
    "orangered3",	"#CD3700",
    "orangered4",	"#8B2500",
    "orchid",		"#DA70D6",
    "orchid1",		"#FF83FA",
    "orchid2",		"#EE7AE9",
    "orchid3",		"#CD69C9",
    "orchid4",		"#8B4789",
    "palegoldenrod",	"#EEE8AA",
    "palegreen",	"#98FB98",
    "palegreen1",	"#9AFF9A",
    "palegreen2",	"#90EE90",
    "palegreen3",	"#7CCD7C",
    "palegreen4",	"#548B54",
    "paleturquoise",	"#AFEEEE",
    "paleturquoise1",	"#BBFFFF",
    "paleturquoise2",	"#AEEEEE",
    "paleturquoise3",	"#96CDCD",
    "paleturquoise4",	"#668B8B",
    "palevioletred",	"#DB7093",
    "palevioletred1",	"#FF82AB",
    "palevioletred2",	"#EE799F",
    "palevioletred3",	"#CD6889",
    "palevioletred4",	"#8B475D",
    "papayawhip",	"#FFEFD5",
    "peachpuff",	"#FFDAB9",
    "peachpuff1",	"#FFDAB9",
    "peachpuff2",	"#EECBAD",
    "peachpuff3",	"#CDAF95",
    "peachpuff4",	"#8B7765",
    "peru",		"#CD853F",
    "pink",		"#FFC0CB",
    "pink1",		"#FFB5C5",
    "pink2",		"#EEA9B8",
    "pink3",		"#CD919E",
    "pink4",		"#8B636C",
    "plum",		"#DDA0DD",
    "plum1",		"#FFBBFF",
    "plum2",		"#EEAEEE",
    "plum3",		"#CD96CD",
    "plum4",		"#8B668B",
    "powderblue",	"#B0E0E6",
    "purple",		"#A020F0",
    "purple1",		"#9B30FF",
    "purple2",		"#912CEE",
    "purple3",		"#7D26CD",
    "purple4",		"#551A8B",
    "red",		"#FF0000",
    "red1",		"#FF0000",
    "red2",		"#EE0000",
    "red3",		"#CD0000",
    "red4",		"#8B0000",
    "rosybrown",	"#BC8F8F",
    "rosybrown1",	"#FFC1C1",
    "rosybrown2",	"#EEB4B4",
    "rosybrown3",	"#CD9B9B",
    "rosybrown4",	"#8B6969",
    "royalblue",	"#4169E1",
    "royalblue1",	"#4876FF",
    "royalblue2",	"#436EEE",
    "royalblue3",	"#3A5FCD",
    "royalblue4",	"#27408B",
    "saddlebrown",	"#8B4513",
    "salmon",		"#FA8072",
    "salmon1",		"#FF8C69",
    "salmon2",		"#EE8262",
    "salmon3",		"#CD7054",
    "salmon4",		"#8B4C39",
    "sandybrown",	"#F4A460",
    "seagreen",	"#2E8B57",
    "seagreen1",	"#54FF9F",
    "seagreen2",	"#4EEE94",
    "seagreen3",	"#43CD80",
    "seagreen4",	"#2E8B57",
    "seashell",	"#FFF5EE",
    "seashell1",	"#FFF5EE",
    "seashell2",	"#EEE5DE",
    "seashell3",	"#CDC5BF",
    "seashell4",	"#8B8682",
    "sienna",		"#A0522D",
    "sienna1",		"#FF8247",
    "sienna2",		"#EE7942",
    "sienna3",		"#CD6839",
    "sienna4",		"#8B4726",
    "skyblue",		"#87CEEB",
    "skyblue1",	"#87CEFF",
    "skyblue2",	"#7EC0EE",
    "skyblue3",	"#6CA6CD",
    "skyblue4",	"#4A708B",
    "slateblue",	"#6A5ACD",
    "slateblue1",	"#836FFF",
    "slateblue2",	"#7A67EE",
    "slateblue3",	"#6959CD",
    "slateblue4",	"#473C8B",
    "slategray",	"#708090",
    "slategray1",	"#C6E2FF",
    "slategray2",	"#B9D3EE",
    "slategray3",	"#9FB6CD",
    "slategray4",	"#6C7B8B",
    "slategrey",	"#708090",
    "snow",		"#FFFAFA",
    "snow1",		"#FFFAFA",
    "snow2",		"#EEE9E9",
    "snow3",		"#CDC9C9",
    "snow4",		"#8B8989",
    "springgreen",	"#00FF7F",
    "springgreen1",	"#00FF7F",
    "springgreen2",	"#00EE76",
    "springgreen3",	"#00CD66",
    "springgreen4",	"#008B45",
    "steelblue",	"#4682B4",
    "steelblue1",	"#63B8FF",
    "steelblue2",	"#5CACEE",
    "steelblue3",	"#4F94CD",
    "steelblue4",	"#36648B",
    "tan",		"#D2B48C",
    "tan1",		"#FFA54F",
    "tan2",		"#EE9A49",
    "tan3",		"#CD853F",
    "tan4",		"#8B5A2B",
    "thistle",		"#D8BFD8",
    "thistle1",	"#FFE1FF",
    "thistle2",	"#EED2EE",
    "thistle3",	"#CDB5CD",
    "thistle4",	"#8B7B8B",
    "tomato",		"#FF6347",
    "tomato1",		"#FF6347",
    "tomato2",		"#EE5C42",
    "tomato3",		"#CD4F39",
    "tomato4",		"#8B3626",
    "turquoise",	"#40E0D0",
    "turquoise1",	"#00F5FF",
    "turquoise2",	"#00E5EE",
    "turquoise3",	"#00C5CD",
    "turquoise4",	"#00868B",
    "violet",		"#EE82EE",
    "violetred",	"#D02090",
    "violetred1",	"#FF3E96",
    "violetred2",	"#EE3A8C",
    "violetred3",	"#CD3278",
    "violetred4",	"#8B2252",
    "wheat",		"#F5DEB3",
    "wheat1",		"#FFE7BA",
    "wheat2",		"#EED8AE",
    "wheat3",		"#CDBA96",
    "wheat4",		"#8B7E66",
    "whitesmoke",	"#F5F5F5",
    "yellow",		"#FFFF00",
    "yellow1",		"#FFFF00",
    "yellow2",		"#EEEE00",
    "yellow3",		"#CDCD00",
    "yellow4",		"#8B8B00",
    "yellowgreen",	"#9ACD32"
    )
, ncol=2, byrow=T)

and a quick retrieval function

name2col <- function(name){
  i <- match(name, .ColorDataBase[, 1])
  .ColorDataBase[i, 2]
}


# Ben Bolker's function
# not vectorized yet
color.to.rgb <- function(color) {
#  given color as hexadecimal, return RGB values
  hexvec <- c(0:9,"A","B","C","D","E","F")
  rgb <- numeric(3)
  names(rgb) <- c("red","blue","green")
  for (i in (0:2)) {
    h1 <- which(hexvec==substr(color,i*2+2,i*2+2))-1
    h2 <- which(hexvec==substr(color,i*2+3,i*2+3))-1
    rgb[i+1] <- h1*16+h2
  }
  rgb
}




On the long run, using the internal name2col is probably preferable over
duplicating the representation.




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From William.Venables at cmis.CSIRO.AU  Tue Feb 29 12:44:49 2000
From: William.Venables at cmis.CSIRO.AU (Bill Venables)
Date: Tue, 29 Feb 2000 21:44:49 +1000 (EST)
Subject: [R] Congratulations on the release of 1.0.0
Message-ID: <200002291144.VAA07019@acland.qld.cmis.CSIRO.AU>

I see Peter has just announced the release of 1.0.0, on time,
even here in Australia, in accordance with a timetable privately
announced about 6 months ago.  At that time it seemed optimistic
to put it mildly.

I am not a member of the core team, but as an ordinary user of R
with a more privileged inside view than most I'd like to offer
my personal congratulations and thanks.

This is the first major release, and a triumph for the skill,
perseverence and dedication of the core team that works so
quietly but so productively.  (I see there was just a little more
fanfare than usual this time but I suspect few will notice.)  The
statistical computing community owes you a tremendous debt of
gratitude.  My hope is that this release will lead to many
authors and teachers adopting R as a standard computational
vehicle of great elegance and power, free and here to stay.

Well done, Ross, Robert, Kurt, Peter, Doug, Martin, Brian and
whoever else I may have missed.  In fact very well done.

Bill Venables.
--
Bill Venables,      Statistician,     CMIS Environmetrics Project
CSIRO Marine Labs, PO Box 120, Cleveland, Qld,  AUSTRALIA.   4163
Tel: +61 7 3826 7251           Email: Bill.Venables at cmis.csiro.au    
Fax: +61 7 3826 7304      http://www.cmis.csiro.au/bill.venables/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cestluk at polyu.edu.hk  Tue Feb 29 13:15:55 2000
From: cestluk at polyu.edu.hk (LUK ShunTim)
Date: Tue, 29 Feb 2000 20:15:55 +0800
Subject: [R] Re: R-1.0.0 is released
References: <x23dqc5obk.fsf@blueberry.kubism.ku.dk>
Message-ID: <38BBB87B.BC70190A@polyu.edu.hk>

Peter Dalgaard BSA wrote:

[snipped]

> 
> Since this is a major release, we've made a formal release
> statement this time. Below is an excerpt; full text is available at
> 
> http://developer.r-project.org/R-release-1.0.0.txt
> 
> "The release of a current major version indicates that we believe that
> R has reached a level of stability and maturity that makes it suitable
> for production use. Also, the release of 1.0.0 marks that the base
> language and the API for extension writers will remain stable for the
> foreseeable future. In addition we have taken the opportunity to tie
> up as many loose ends as we could."
> 
>         For the R Core Team,

Yes, to waste a little band width which I think is deserved at this
point in time, 

Three cheers for all the team!. 

I've not only had a good (which is becoming better) piece of software
but also learnt a lot of statistics from the team and of course from all
who posted to this list.

A heartfelt thanks,
ST
--
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Tue Feb 29 13:34:18 2000
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Tue, 29 Feb 2000 13:34:18 +0100
Subject: [R] standing ovations
Message-ID: <000201bf82b1$4c5def30$a9021aac@joelschlaegel>



I think this is a moment to lean back from daily business, details or
whatsoever and appreciate the impressive achievment of Ross, Robert and the
R-core team. Incredible!

They created an impressive and extremely useful software, for teaching,
research and more. Besides these direct practical benefits, I think this
project is more: it gives an outstanding example of international
cooperation and it gives access to everyone, including the not-so-rich
countries, to tools essential to perform empirical research as they need it.

Thank you very much
and best wishes
for whatever your post-1.0 plans are

--
Dr. Jens Oehlschl?gel-Akiyoshi
(private mail, standard disclaimer)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steuer at statistik.uni-dortmund.de  Tue Feb 29 14:41:48 2000
From: steuer at statistik.uni-dortmund.de (Dipl.-Stat. Detlef Steuer)
Date: Tue, 29 Feb 2000 14:41:48 +0100 (CET)
Subject: [R] R-1.0.0 one question:
In-Reply-To: <000201bf82b1$4c5def30$a9021aac@joelschlaegel>
Message-ID: <XFMail.20000229144148.steuer@statistik.uni-dortmund.de>


Release 1.0.0

(silence)

Wow! Thank you!

When I started using R-0.49 in our department the question always was:
"What software? Never heard of ... "

Even in the previous pre-1.0.0 week that sounded like:
"Do we still need the other licences ..."

Thanks to the Core-Team! Incredible work!

-----

If I am allowed to ask just one question today:

How do you fit 48 hours of coding in an ordinary day? 
Any hints will be appreciated ...

:-) 

-----

All the best,
Detlef Steuer

-- 

Detlef Steuer Universitaet Dortmund                             ///////
LS Computergestuetzte Statistik                          U N I D O ///  
steuer at statistik.uni-dortmund.de                        ______///////  
Tel: ++49 +231 755 4353 Fax: ++49 +231 755 4387         \_\_\_\/////
                                                         \_\_\_\///
                                                          \_\_\_\/

*** Use what talents you possess: the woods would be very silent ***
*** if no birds sang there except those that sang best.          ***
*** Henry Van Dyke                                               ***
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rnassar at duke.edu  Tue Feb 29 14:48:06 2000
From: rnassar at duke.edu (Rashid Nassar)
Date: Tue, 29 Feb 2000 08:48:06 -0500 (EST)
Subject: [R] Re: R-1.0.0 is released
In-Reply-To: <38BBB87B.BC70190A@polyu.edu.hk>
Message-ID: <Pine.SOL.3.91.1000229084549.15508B-100000@bio3.acpub.duke.edu>

ST,

May I humbly add my voice to yours?  WHAT AN ACCOMPLISHMENT!

Rashid


On Tue, 29 Feb 2000, LUK ShunTim wrote:

> Yes, to waste a little band width which I think is deserved at this
> point in time, 
> 
> Three cheers for all the team!. 
> 
> I've not only had a good (which is becoming better) piece of software
> but also learnt a lot of statistics from the team and of course from all
> who posted to this list.
> 
> A heartfelt thanks,
> ST
> --
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Tue Feb 29 12:25:18 2000
From: ernesto at ipimar.pt (=?iso-8859-1?Q?Jos=E9?= Ernesto Jardim)
Date: Tue, 29 Feb 2000 11:25:18 +0000
Subject: [R] Re: R-1.0.0 is released
References: <x23dqc5obk.fsf@blueberry.kubism.ku.dk>
Message-ID: <38BBAC9D.25D6FEE1@ipimar.pt>

Congratulations !!

You're making an excellent work.

R is one of the best programs I know and you're work is amazing.

Best regards and thanks for your dedication to R

ernesto


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From j.logsdon at lancaster.ac.uk  Tue Feb 29 15:18:25 2000
From: j.logsdon at lancaster.ac.uk (John Logsdon)
Date: Tue, 29 Feb 2000 14:18:25 +0000 (GMT)
Subject: [R] More standing ovations and off-topic stuff ...
In-Reply-To: <000201bf82b1$4c5def30$a9021aac@joelschlaegel>
Message-ID: <Pine.LNX.4.10.10002291407380.28188-100000@mercury.quantex>

As a very humble R user can I append my harmonica to the current round of
congratulations and thanks to all the R people who have produced 1.0.0 on
time and on target.

If a plea is in order, could you all award yourselves a long break now so
that we lower folk may catch up!  Such a vacation would be more than
well deserved.

The pace of change is such that I am still running 0.90.1 on one machine
and 0.63.3 on another on the basis that if it ain't broke don't fix it!  
I guess there are other ordinary mortals around as well and people using R
in a teaching environment etc that will appreciate a quiet life.

The skiing is pretty good in Austria at the moment - my son has just
returned - there is a lovely big old coffee place just down the road from
TUWien and I am sure NZ is blissfully beautiful this autumn.  Meanwhile it
is raining in Manchester.  Perhaps a virtual R-holiday with webcams and a
beer in all hands.  

Thanks again

John

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Tue Feb 29 16:46:22 2000
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Tue, 29 Feb 2000 09:46:22 -0600
Subject: [R] Congrats!
Message-ID: <200002291546.AA16335@uhddx01.dt.uh.edu>

R Rocks!

Great job, y'all!

Erin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Tue Feb 29 17:04:25 2000
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 29 Feb 2000 11:04:25 -0500 (EST)
Subject: [R] R-1.0.0
Message-ID: <Pine.LNX.4.10.10002291056210.2939-100000@bolker.zoo.ufl.edu>


  I want to add my two cents of congratulation to the R core team.

  I also want to encourage everyone who uses R to be an active, not a
passive user -- the fastest way R will get better is if the folks who use
it submit bug reports, suggestions, R code for their particular fields,
documentation, even patches and code fixes.  R is big and complicated
enough now that we can't leave testing to the core team.

  Of course, many "bugs" are misunderstandings about the way R
works--it's always worth reading the documentation, or asking around if
there are experts in your vicinity--but there are also lots of real bugs
out there waiting to be found and fixed.  When you ask about something on
R-help, it also goes into the archives where it can be found in the future
by people with the same question.

  The best "thank you" for R (OK, with the possible exception of
beer/pizza/money) is help with improving it.

-- 
Ben Bolker                                  bolker at zoo.ufl.edu
Zoology Department, University of Florida   http://www.zoo.ufl.edu/bolker
318 Carr Hall/Box 118525                    tel: (352) 392-5697
Gainesville, FL 32611-8525                  fax: (352) 392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Feb 29 17:12:22 2000
From: gb at stat.umu.se (gb@stat.umu.se)
Date: Tue, 29 Feb 2000 17:12:22 +0100 (CET)
Subject: [R] ms and congratulations!
In-Reply-To: <6r4sat5ljr.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.LNX.4.10.10002291706090.31186-100000@pc16.stat.umu.se>

On 28 Feb 2000, Douglas Bates wrote:

> Douglas Bates <bates at stat.wisc.edu> writes:
> 
> > Assuming that the quadratic form evaluates to a scalar, try
> > 
> > opt.func <- function(alf, beta) 
> >   t(Y-(X[,1] * alf + X[,2] * bet)^delta) %*% covariance.matrix.inverse %*%
> >             (Y-(X[,1] * alf + X[,2] * bet)^delta)
> > 
> > nlm(opt.func, c(alf = 5, bet = 0.5))
> > 
> > or
> > 
> > optim(c(alf = 5, bet = 0.5), opt.func)
> 
> Those are wrong.  The function being optimized has to be a function of
> a single argument.  If alf and bet are both scalars you can combine
> them into a vector and use
> 
> opt.func <- function(arg) 
>   t(Y-(X[,1] * arg[1] + X[,2] * arg[2])^delta) %*% covariance.matrix.inverse %*%
>             (Y-(X[,1] * arg[1] + X[,2] * arg[2])^delta)

Doug, thank you for the help. Of course it works perfectly!
And of course my thanks go to the whole  R  team on a day
like today! 

G?ran
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krastev at fas.harvard.edu  Tue Feb 29 17:56:49 2000
From: krastev at fas.harvard.edu (Krassimir Krastev)
Date: Tue, 29 Feb 2000 11:56:49 -0500
Subject: No subject
Message-ID: <MNBBLKFOOKIIOFHMMMFEEEIECAAA.krastev@fas.harvard.edu>

Does anyone know of any comprehensive literature (like a book, collection of
articles, etc.) that walk thorugh example of ARIMA modeling with the ts
package of R? Genarlly if you've just started to learn the R-language and
are all week long with ARIMA, what is a fast-pace source that you would
recommend (to a beginner) ?

Thank you,
Krasi

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gromero at chass.utoronto.ca  Tue Feb 29 17:55:48 2000
From: gromero at chass.utoronto.ca (Giovanni Eduardo Romero)
Date: Tue, 29 Feb 2000 11:55:48 -0500
Subject: [R] BRAVO!!
In-Reply-To: <Pine.LNX.4.10.10002291407380.28188-100000@mercury.quantex>
Message-ID: <Pine.SGI.4.10.10002291152310.2079299-100000@origin.chass.utoronto.ca>

Thank you to the Core team and all contributors for the outstanding work,
dedication and help. 
Congratulations!!



Giovanni E. Romero
Department of Economics
University of Toronto

http://www.chass.utoronto.ca/~gromero
e-mail:giovanni at canada.com



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 29 18:13:57 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Feb 2000 17:13:57 +0000 (GMT)
Subject: [R] Re: arima in ts.
Message-ID: <200002291713.RAA29954@toucan.stats.ox.ac.uk>


> From: "Krassimir Krastev" <krastev at fas.harvard.edu>
> To: "R-help" <r-help at stat.math.ethz.ch>
> Date: Tue, 29 Feb 2000 11:56:49 -0500
> X-Priority: 3 (Normal)
> X-MSMail-Priority: Normal
> Importance: Normal
> X-MimeOLE: Produced By Microsoft MimeOLE V5.00.2919.6600
> 
> Does anyone know of any comprehensive literature (like a book, collection of
> articles, etc.) that walk thorugh example of ARIMA modeling with the ts
> package of R? Genarlly if you've just started to learn the R-language and
> are all week long with ARIMA, what is a fast-pace source that you would
> recommend (to a beginner) ?

1) arima0 is explicitly a provisional function: it will be replaced
   shortly.
   
2) Venables & Ripley third edition (1999) (see the CRAN doc page) has
   many worked examples in S-PLUS, and the script ch13.R distributed
   with the MASS package (in the VR bundle) has the changes need to use this 
   with R.

As far as I know there is no other source, nor for a provisional function
would I expect one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossetti at markov.stat.unipg.it  Tue Feb 29 17:03:51 2000
From: rossetti at markov.stat.unipg.it (Andrea Rossetti)
Date: Tue, 29 Feb 2000 17:03:51 +0100 (MET)
Subject: [R] isoMDS error message!!!
Message-ID: <Pine.GSO.4.05.10002291701220.4374-100000@markov.stat.unipg.it>

Hi to all,

I do this

> valumod<-read.table("valu-medie.txt",header=T)
> library(mass)
> library(mva)
> valumod.x <- as.matrix(valumod)
> valumod.dist<-dist(valumod.x)
> valumod.mds <- isoMDS(valumod.dist)
Error in isoMDS(valumod.dist) : zero or negative distance between objects 2 and 4
>

Where is the error?

Andrea Rossetti.

PS I've attached the dataset.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laniel at cmu.edu  Tue Feb 29 19:08:35 2000
From: laniel at cmu.edu (Stephen R. Laniel)
Date: Tue, 29 Feb 2000 13:08:35 -0500 (EST)
Subject: [R] Re: your mail
In-Reply-To: <MNBBLKFOOKIIOFHMMMFEEEIECAAA.krastev@fas.harvard.edu>
Message-ID: <Pine.SOL.3.96L.1000229130745.8727A-100000@unix7.andrew.cmu.edu>

On Tue, 29 Feb 2000, Krassimir Krastev wrote:

> Does anyone know of any comprehensive literature (like a book, collection of
> articles, etc.) that walk thorugh example of ARIMA modeling with the ts
> package of R? Genarlly if you've just started to learn the R-language and
> are all week long with ARIMA, what is a fast-pace source that you would
> recommend (to a beginner) ?

You might want to try the Venables & Ripley book (Modern Applied
Statistics with S-PLUS; I believe the latest edition is the 3rd).  It has
a good section on time-series analysis.

--Steve

Stephen R. Laniel            |  "Farewell Angelina
Carnegie Mellon University   |   The sky is erupting
laniel at cmu.edu               |   I must go where it's quiet."
www.stat.cmu.edu/~laniel/    |   --Bob Dylan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 29 19:11:18 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Feb 2000 18:11:18 +0000 (GMT)
Subject: Reading the documentation (was [R] isoMDS error message!!!)
Message-ID: <200002291811.SAA00277@toucan.stats.ox.ac.uk>

> Date: Tue, 29 Feb 2000 17:03:51 +0100 (MET)
> From: Andrea Rossetti <rossetti at markov.stat.unipg.it>

[Mail to your address is undeliverable!!!]

> I do this
> 
> > valumod<-read.table("valu-medie.txt",header=T)
> > library(mass)
> > library(mva)
> > valumod.x <- as.matrix(valumod)
> > valumod.dist<-dist(valumod.x)
> > valumod.mds <- isoMDS(valumod.dist)
> Error in isoMDS(valumod.dist) : zero or negative distance between objects 2 
and 4

It means that rows 2 and 4 of valumod.x are identical.

> Where is the error?

isoMDS is from package MASS, and there is an example of this, the reason
for it and the workaround on page 334 of the book MASS!!!  When people
produce code to support a book, the book is part of the documentation.
However, the help page is quite explicit:

       d: distance structure of the form returned by `dist', or a full,
          symmetric matrix.  Data are assumed to be dissimilarities or
          relative distances, but must be positive except for
          self-distance. 

It does help to read the documentation!!!

> PS I've attached the dataset.

No sign of it.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter at esb.ucp.pt  Tue Feb 29 19:48:05 2000
From: peter at esb.ucp.pt (Peter Ho)
Date: Tue, 29 Feb 2000 18:48:05 +0000
Subject: [R] se.contrasts.
Message-ID: <38BC1460.51FE2357@esb.ucp.pt>

Dear R users,

Firstly, I would like to congratulate the R core team in bringing out R
1.0.0 and all who have helped in developing it.
I have been having problems with using se.contrasts and would be pleased
if someone help.

I have been doing a repeated measures ANOVA using aov using a split plot
design for a single variable, color. The aov results were as follows:

> summary(aov(CD2~cont + Error(cont:rpl)+times+cont:times, color))

Error: cont:rpl
                  Df         Sum Sq         Mean Sq         F
value         Pr(>F)
cont             6         8.6214          1.4369
6.8651            0.2841
Residuals      1         0.2093          0.2093

Error: Within
                   Df         Sum Sq         Mean Sq         F
value        Pr(>F)
times           7         53.133               7.590
1053.32         4.886e-10 ***
cont:times    42        86.030               2.048
284.24         2.149e-08 ***
Residuals       7          0.050               0.007
---
Signif. codes:  0  `***'  0.001  `**'  0.01  `*'  0.05  `.'  0.1  ` '  1

I then used model.tables to get the effects and standard errors , which
gave me this:

> model.tables(cd.aov2, "effects", se=T)
Standard error information not returned as design is unbalanced.
Standard errors can be obtained through se.contrast.
........... followed by the table of effects

However, whatever I do I cannot calculate se.contrast.

In the above test the factor cont has 7 levels (1,2,3,4,5,6,7,7) , rpl
is the replication, and times has 8 levels.
I want to test if there is a significant difference between the
following:

(1) if there is a difference between cont (1,2,3) between times (6,7,8)
(2) if there is a difference between cont (4,5,6) between times (6,7,8)

essentially these are the main contrast I am interested in, as a
treatment is applied between times 6 and 7 at 3 levels within
cont(1,2,3) and cont(4,5,6).
Interaction effects between cont with times can be seem by plotting
effects, but I suppose this isn't enough to show significant
differences, isn't it?

I would be grateful if someone could suggests how I might calculate the
contrasts using se.contrasts.
As there are also different contrasts.ie. helmert,treatments, etc. This
confuses me even more.

Also I mentioned in the beginning of the text that I did the ANOVA for a
single variable.  I infact measured 13 variables and wanted do
originally try a repeated measures MANOVA, but did not know how to do
this. Any suggestions here would also be grateful. Cons and Pros of
univariate and multivariate approach.
I have looked at  the growth and rmutil, which the author J Lindsey
suggested could be used, but as I had no experience using them, again I
did not know what to do. Has anyone tried this approach?

Thanks


Peter


-----------------------------
Peter Ho
Escola Superior de Biotecnologia
Universidade Cat?lica Portuguesa
Rua Dr. Ant?nio Bernardino de Almeida
Porto 4200-072
Portugal

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetil.kjernsmo at astro.uio.no  Tue Feb 29 20:13:05 2000
From: kjetil.kjernsmo at astro.uio.no (Kjetil Kjernsmo)
Date: Tue, 29 Feb 2000 20:13:05 +0100 (MET)
Subject: [R] Reading data from file made by C fwrite
Message-ID: <Pine.OSF.4.05.10002291921540.15162-100000@rasalgethi.uio.no>

Hello!

First, I must also congratulate the R core team with their accomplishment!
I have gotten to like R a lot, and I have recommended it for inclusion in
an "Astronomy for Linux"-distribution which is in use by many professional
astronomers and observatories. 

I'm currently working on importing data from files created by a C program
(that I have not written myself, I have the source code, but I don't know
if the author wants to publish it yet). 

I really don't know much about C, but I can understand that the program
writes to a file using 
fwrite(MAP,sizeof(float),MAP_i*MAP_j,f)
where MAP most probably is a pointer to a two-dimensional array of single
precision floats. This is what I want to read into a matrix in R.

When I look at the files written by this program, it is clear that they
are not on a simple form, less says it is a binary file. However, it
appears to be kind of common, as I have seen other packages (such as IDL)
reading files like this without much ado... :-) So, can I read the data of
these files into R? (If not, I may sit down and try to hack it up myself,
some hints would be greatly appreciated).

BTW, something unrelated, if anybody has a couple of examples of
generating random numbers from distribution functions with a couple of
jumps, they would like to share, I'd be happy (I'm an astronomer with very
little training in statistics, so I'm uncertain whether I've got my code 
right (while it returns the expected results, I have a bad feeling)).

Best,

Kjetil
-- 
Kjetil Kjernsmo
Graduate astronomy-student                    Problems worthy of attack
University of Oslo, Norway            Prove their worth by hitting back
E-mail: kjetikj at astro.uio.no                                - Piet Hein
Homepage <URL:http://www.astro.uio.no/~kjetikj/>
Webmaster at skepsis.no 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brian at trichodon.afsc.noaa.gov  Tue Feb 29 20:15:47 2000
From: brian at trichodon.afsc.noaa.gov (Brian O'Gorman)
Date: Tue, 29 Feb 2000 10:15:47 -0900
Subject: [R] R-1.0.0 make error
Message-ID: <38BC1AE3.CF3E309D@trichodon.afsc.noaa.gov>

I'm getting this error when I try to make after my configure, any
solutions? Thanks in advance...


make[2]: Entering directory `/export/trichodon2/R/R-1.0.0/demos/dynload'

/usr/local/bin/make zero.so
make[3]: Entering directory `/export/trichodon2/R/R-1.0.0/demos/dynload'

/export/trichodon2/R/R-0.99.0a/bin/SHLIB:
/export/trichodon2/R/R-0.99.0a/bin/SHLIB: cannot open
make[3]: *** [zero.so] Error 1
make[3]: Leaving directory `/export/trichodon2/R/R-1.0.0/demos/dynload'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/export/trichodon2/R/R-1.0.0/demos/dynload'
make[1]: *** [R] Error 2
make[1]: Leaving directory `/export/trichodon2/R/R-1.0.0/demos'
make: *** [R] Error 1

-------------- next part --------------
A non-text attachment was scrubbed...
Name: brian.vcf
Type: text/x-vcard
Size: 211 bytes
Desc: Card for Brian O'Gorman
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000229/80f27a83/brian.vcf

From p.dalgaard at biostat.ku.dk  Tue Feb 29 20:27:02 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Feb 2000 20:27:02 +0100
Subject: [R] R-1.0.0 make error
In-Reply-To: "Brian O'Gorman"'s message of "Tue, 29 Feb 2000 10:15:47 -0900"
References: <38BC1AE3.CF3E309D@trichodon.afsc.noaa.gov>
Message-ID: <x21z5v7qt5.fsf@blueberry.kubism.ku.dk>

"Brian O'Gorman" <brian at trichodon.afsc.noaa.gov> writes:

> This is a multi-part message in MIME format.
> --------------431C580A200A8B87AB538006
> Content-Type: text/plain; charset=us-ascii
> Content-Transfer-Encoding: 7bit
> 
> I'm getting this error when I try to make after my configure, any
> solutions? Thanks in advance...
> 
> 
> make[2]: Entering directory `/export/trichodon2/R/R-1.0.0/demos/dynload'
> 
> /usr/local/bin/make zero.so
> make[3]: Entering directory `/export/trichodon2/R/R-1.0.0/demos/dynload'
> 
> /export/trichodon2/R/R-0.99.0a/bin/SHLIB:
> /export/trichodon2/R/R-0.99.0a/bin/SHLIB: cannot open
> make[3]: *** [zero.so] Error 1
> make[3]: Leaving directory `/export/trichodon2/R/R-1.0.0/demos/dynload'
> make[2]: *** [R] Error 2
> make[2]: Leaving directory `/export/trichodon2/R/R-1.0.0/demos/dynload'
> make[1]: *** [R] Error 2
> make[1]: Leaving directory `/export/trichodon2/R/R-1.0.0/demos'
> make: *** [R] Error 1

Um, why would it go looking in R-0.99.0a/bin ??

I wager a guess: You somehow didn't start with a clean slate. Either
you unpacked 1.0.0 on top of 0.99.0a and renamed directories, or you
had things like config.cache hanging around from a previous build

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 29 20:46:14 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 29 Feb 2000 19:46:14 +0000 (GMT Standard Time)
Subject: [R] Reading data from file made by C fwrite
In-Reply-To: <Pine.OSF.4.05.10002291921540.15162-100000@rasalgethi.uio.no>
Message-ID: <Pine.WNT.4.05.10002291936590.317-100000@tern.stats>

On Tue, 29 Feb 2000, Kjetil Kjernsmo wrote:

> I'm currently working on importing data from files created by a C program
> (that I have not written myself, I have the source code, but I don't know
> if the author wants to publish it yet). 
> 
> I really don't know much about C, but I can understand that the program
> writes to a file using 
> fwrite(MAP,sizeof(float),MAP_i*MAP_j,f)
> where MAP most probably is a pointer to a two-dimensional array of single
> precision floats. This is what I want to read into a matrix in R.

Just link a bit of C in to read the format with fread. You will need to do
this anyway: R does not use the float type.

Here's a bit of code we use for similar purposes. This reads 64x64 slices
of 16 bit values from fMRI machine files.

/* Read a slice from a .img file */
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include "R.h"

void readimg(unsigned int *ans, int *nslice, char **name)
{
  int fd, i;
  unsigned int t1, t2;
  char *p, buf[64*64*2];
  long nread;
  
  fd = open(name[0], O_RDONLY);
  if(fd < 0) {
    PROBLEM "can't open file" RECOVER(NULL_ENTRY);
  }
  lseek(fd, 2*64*64*(*nslice), SEEK_SET);
  
  nread = read(fd, buf, 64 * 64*2);
  p = buf;
  for(i = 0; i < 64*64; i++) {
    t1 = (*p++)&0xFF;
    t2 = (*p++)&0xFF;
    *ans++ = 256 * t1 + t2;
  }
  close(fd);
}

called by

getslice <- function (nslice, name = "MRI.img") 
.C("readimg", ans = integer(64 * 64), as.integer(nslice), name)$ans


> When I look at the files written by this program, it is clear that they
> are not on a simple form, less says it is a binary file. However, it
> appears to be kind of common, as I have seen other packages (such as IDL)
> reading files like this without much ado... :-) So, can I read the data of
> these files into R? (If not, I may sit down and try to hack it up myself,
> some hints would be greatly appreciated).

Um. However do they know what it is (float, double, integer,
dimensions)....  Yes, they read it, often incorrectly!

Alternatively, netpbm has lots of filters to dump such formats to ASCII.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Tue Feb 29 20:46:21 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Tue, 29 Feb 2000 11:46:21 -0800 (PST)
Subject: [R] Reading data from file made by C fwrite
In-Reply-To: <Pine.OSF.4.05.10002291921540.15162-100000@rasalgethi.uio.no>
Message-ID: <Pine.GSO.4.21.0002291136050.5673-100000@mail.biostat.washington.edu>

On Tue, 29 Feb 2000, Kjetil Kjernsmo wrote:

> 
> I'm currently working on importing data from files created by a C program
> (that I have not written myself, I have the source code, but I don't know
> if the author wants to publish it yet). 
> 
> I really don't know much about C, but I can understand that the program
> writes to a file using 
> fwrite(MAP,sizeof(float),MAP_i*MAP_j,f)
> where MAP most probably is a pointer to a two-dimensional array of single
> precision floats. This is what I want to read into a matrix in R.
> 

We don't currently have any support for this in R. It's not that hard to
do, but it doesn't generalise that well to eg multiple variables.

What you want to do is to write a C function that accepts a filename and
a pointer to a vector of doubles. It should open the file, read each
float, cast it to double, and put it in the vector of doubles, then close
the file.
	
	void readTheFile(char **filename, double *workspace)

Calling this function from R would read the numbers into the supplied
vector, and you could then fix up the dimensions in R (I'm assuming you
know the size of the file here)

	a<-.C("readTheFile",filename,numeric(size.of.file))
	m<-a[[2]]
	dim(m)<-c(100,200) #for example


The manual on writing R Extensions should help.


	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Tue Feb  1 08:55:27 2000
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Tue, 1 Feb 2000 08:55:27 +0100 (MET)
Subject: [R] glm
In-Reply-To: <002201bf6bfc$849ee640$3a96ce84@math.mcgill.ca> from "Keith Worsley" at Jan 31, 2000 10:04:48 AM
Message-ID: <200002010755.IAA31047@alpha.luc.ac.be>

> 4. I don't think AIC is stricly correct. My understanding of AIC is that
> it is the log likelihood maximised over all the parameters, including
> the dispersion parameter. Now the problem is that the mle of the
> dispersion parameter for the gamma family (and the exponential family in
> general) is really awkward - I think it has to be found by interative
> methods, using the derivative of the gamma function - I see from a print
> of Gamma that you are using dev/n, but I don't think this is the mle....

Yes you are right. I chose this only as a reasonable approximation for the
gamma and inverse Gaussian distributions. If you want the exact AIC,
you can get it from the gnlr function in my gnlm library.
  Jim
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb  1 09:40:44 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 1 Feb 2000 08:40:44 +0000 (GMT)
Subject: [R] glm
In-Reply-To: <200002010755.IAA31047@alpha.luc.ac.be>
Message-ID: <Pine.GSO.4.05.10002010831520.20787-100000@auk.stats>

On Tue, 1 Feb 2000, Jim Lindsey wrote:

> > 4. I don't think AIC is stricly correct. My understanding of AIC is that
> > it is the log likelihood maximised over all the parameters, including
> > the dispersion parameter. Now the problem is that the mle of the
> > dispersion parameter for the gamma family (and the exponential family in
> > general) is really awkward - I think it has to be found by interative
> > methods, using the derivative of the gamma function - I see from a print
> > of Gamma that you are using dev/n, but I don't think this is the mle....
> 
> Yes you are right. I chose this only as a reasonable approximation for the
> gamma and inverse Gaussian distributions. If you want the exact AIC,
> you can get it from the gnlr function in my gnlm library.

Another way to get the MLE of the dispersion parameter from the glm output
is to use the function gamma.shape.glm (by Bill Venables) in the MASS
package.  Its help says

Details:

     A glm fit for a Gamma family correctly calculates the maximum
     likelihood estimate of the mean parameters but provides only a
     crude estimate of the dispersion parameter.  This function takes
     the results of the glm fit and solves the maximum likelihood
     equation for the reciprocal of the dispersion parameter, which is
     usually called the shape (or exponent) parameter.

and yes it is optimized over an expression using the digamma and trigamma
functions, but the code is about 30 lines only including all the warnings
and housekeeping. (Such things show the power of S over GLIM: it would be
`really awkward' in GLIM.)

Note, though, that McCullagh and Nelder argue hard against the MLE of
dispersion in the gamma family.

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From marcus.eger at physik.uni-marburg.de  Tue Feb  1 12:01:20 2000
From: marcus.eger at physik.uni-marburg.de (Marcus Eger)
Date: Tue, 01 Feb 2000 12:01:20 +0100
Subject: [R] R: possibility for sth. like parameter passing by reference?
Message-ID: <3896BD00.6A46D678@physik.uni-marburg.de>

Hello,
is there a possibility to pass parameters to a
function without copying them into the new environment?
In my case I have huge data structures which I would not
like to be copied - or handled globally.
Thanks
M. Eger

-- 

+-------------------------------------------------------
| E-Mail: marcus.eger at physik.uni-marburg.de
+-------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zj at expert.cc.purdue.edu  Tue Feb  1 14:37:11 2000
From: zj at expert.cc.purdue.edu (zj@expert.cc.purdue.edu)
Date: Tue, 01 Feb 2000 08:37:11 -0500
Subject: [R] plotting spectrum of time series etc
Message-ID: <3896E187.BE3C5061@expert.cc.purdue.edu>

Hi, everyone, I tried to use "spectrum()" or "spec.pgram()" to get a
periodogram of a time series but they didn't work.
Even the examples given in the help file didn't work (all with the same
error message, below). And the 'ts'ibrary was
loaded with "library(ts)" or "library("ts"). I also tried
library(tseries) but got the same problem. Could anyone please
give me some help with this?

> spectrum(seriesa)
Error in plot.spec(spg.out, ...) : binary operator applied to invalid
types.

Also, I'm running R under windows 95, and I can't seem to set the line
length of the display right. So sometimes I got an error message that's
too long and I can't read it in full. I tried options(width=??) or
.Options$width=??, they changed the values, but had no effect on the
display.

Thanks a lot!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: zj.vcf
Type: text/x-vcard
Size: 216 bytes
Desc: Card for 
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000201/152536f2/zj.vcf

From ben at zoo.ufl.edu  Tue Feb  1 16:18:22 2000
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 1 Feb 2000 10:18:22 -0500 (EST)
Subject: [R] plotting spectrum of time series etc
In-Reply-To: <3896E187.BE3C5061@expert.cc.purdue.edu>
Message-ID: <Pine.LNX.4.10.10002011014340.2268-100000@bolker.zoo.ufl.edu>


library(ts)
x <- runif(256)
spectrum(x)

works for me, as do the examples in the help file.
  What is "seriesa"?  Can you give us a slightly more complete snippet of
code that produces the problem? spectrum() might not work when applied to
data frames -- have you tried spectrum(as.vector(seriesa))?

On Tue, 1 Feb 2000 zj at expert.cc.purdue.edu wrote:

> Hi, everyone, I tried to use "spectrum()" or "spec.pgram()" to get a
> periodogram of a time series but they didn't work.
> Even the examples given in the help file didn't work (all with the same
> error message, below). And the 'ts'ibrary was
> loaded with "library(ts)" or "library("ts"). I also tried
> library(tseries) but got the same problem. Could anyone please
> give me some help with this?
> 
> > spectrum(seriesa)
> Error in plot.spec(spg.out, ...) : binary operator applied to invalid
> types.
> 

-- 
Ben Bolker                                  bolker at zoo.ufl.edu
Zoology Department, University of Florida   http://www.zoo.ufl.edu/bolker
318 Carr Hall/Box 118525                    tel: (352) 392-5697
Gainesville, FL 32611-8525                  fax: (352) 392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Tue Feb  1 17:29:59 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Tue, 1 Feb 2000 16:29:59 +0000 (GMT)
Subject: [R] R: possibility for sth. like parameter passing by reference?
In-Reply-To: <3896BD00.6A46D678@physik.uni-marburg.de>
Message-ID: <Pine.LNX.4.10.10002011621410.10622-100000@gimel.biostat.washington.edu>

On Tue, 1 Feb 2000, Marcus Eger wrote:

> Hello,
> is there a possibility to pass parameters to a
> function without copying them into the new environment?
> In my case I have huge data structures which I would not
> like to be copied - or handled globally.

In general objects are copied only when they are modified. The underlying
code basically does call by reference until you change the object.  There
isn't a simple way to modify without copying, if that's what you mean.

For example, if I define x to be a really big matrix and then
R>  g<-function(x) mean(x)+1
R> f<-function(x) mean(x+1)
R> g(w)
[1] 0.9992614
R> f(w)
Error: heap memory (6144 Kb) exhausted [needed 1562 Kb more]

The first function doesn't copy x, the second does.



	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb  1 17:33:22 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 1 Feb 2000 16:33:22 +0000 (GMT)
Subject: [R] plotting spectrum of time series etc
In-Reply-To: <Pine.LNX.4.10.10002011014340.2268-100000@bolker.zoo.ufl.edu>
Message-ID: <Pine.GSO.4.05.10002011619280.23624-100000@auk.stats>

> On Tue, 1 Feb 2000 zj at expert.cc.purdue.edu wrote:
> 
> > Hi, everyone, I tried to use "spectrum()" or "spec.pgram()" to get a
> > periodogram of a time series but they didn't work.
> > Even the examples given in the help file didn't work (all with the same
> > error message, below).

Then by definition you have a broken version of R. (R has been installed
properly if it passes `make check', and that includes running all the
examples in all the packages.) 

One possibility is that you have broken it by re-defining some system
functions in your user workspace: look at ?conflicts and/or try starting R
with --vanilla and running example(spectrum), as the first command.

Another is that you really do have a broken installation, so if you
compiled it yourself do run make check.

To go further you need to run traceback() to locate the error, and debug on
the function giving the error (plot.spec, apparently) to find out exactly
where the error is and what the variable values are.  If you can report
that to us and the version of R you are using we may be able to help more.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Feb  1 18:35:07 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 Feb 2000 18:35:07 +0100
Subject: [R] R: possibility for sth. like parameter passing by reference?
In-Reply-To: Thomas Lumley's message of "Tue, 1 Feb 2000 16:29:59 +0000 (GMT)"
References: <Pine.LNX.4.10.10002011621410.10622-100000@gimel.biostat.washington.edu>
Message-ID: <x2ln54hlmc.fsf@blueberry.kubism.ku.dk>

Thomas Lumley <thomas at biostat.washington.edu> writes:

> On Tue, 1 Feb 2000, Marcus Eger wrote:
> 
> > Hello,
> > is there a possibility to pass parameters to a
> > function without copying them into the new environment?
...
> For example, if I define x to be a really big matrix and then
> R>  g<-function(x) mean(x)+1
> R> f<-function(x) mean(x+1)
> R> g(w)
> [1] 0.9992614
> R> f(w)
> Error: heap memory (6144 Kb) exhausted [needed 1562 Kb more]
> 
> The first function doesn't copy x, the second does.

Interesting... I would have expected that both functions would copy x
when the argument is evaluated, but the 2nd one create an additional
object the same size as x to hold the intermediate value of x+1.

I thought that the copying would be avoided altogether by using

h<-function(x)eval.parent(substitute(mean(x)+1))

but that seems to take as much space as g(), which seems to indicate
that the object is linked rather than copied in such cases.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ihaka at stat.auckland.ac.nz  Tue Feb  1 20:28:29 2000
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Wed, 2 Feb 2000 08:28:29 +1300 (NZDT)
Subject: [R] R: possibility for sth. like parameter passing by reference?
Message-ID: <200002011928.IAA17362@stat1.stat.auckland.ac.nz>

	From owner-r-help at stat.math.ethz.ch Wed Feb  2 06:36:50 2000
	To: Thomas Lumley <thomas at biostat.washington.edu>
	Cc: Marcus Eger <marcus.eger at physik.uni-marburg.de>,
	        "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
	Subject: Re: [R] R: possibility for sth. like parameter passing by reference?
	From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
	Date: 01 Feb 2000 18:35:07 +0100
	Mime-Version: 1.0
	Content-Transfer-Encoding: 7bit

	Thomas Lumley <thomas at biostat.washington.edu> writes:

	> On Tue, 1 Feb 2000, Marcus Eger wrote:
	> 
	> > Hello,
	> > is there a possibility to pass parameters to a
	> > function without copying them into the new environment?
	...
	> For example, if I define x to be a really big matrix and then
	> R>  g<-function(x) mean(x)+1
	> R> f<-function(x) mean(x+1)
	> R> g(w)
	> [1] 0.9992614
	> R> f(w)
	> Error: heap memory (6144 Kb) exhausted [needed 1562 Kb more]
	> 
	> The first function doesn't copy x, the second does.

	Interesting... I would have expected that both functions would copy x
	when the argument is evaluated, but the 2nd one create an additional
	object the same size as x to hold the intermediate value of x+1.

We put quite a bit of work into making this happen.  I would describe the
semantics as "copy on modify (if necessary)".  Copying is done only when
objects are modified.  The (if necessary) part means that if we can prove
that the modification cannot change any non-local variables then we just go
ahead and modify without copying.

For example, log(x+1) creates a copy when "x+1" is evaluated, but no
additional copy is made when log() is evaluated -- the result is written
back into the same bit of memory that x+1 was sitting in.  This is ok
because there is no name bound to the value of "x+1".

Caveats:

1. This is how it used to be -- the present state may differ :-).

2. I now a firm believer in call-by-reference semantics.

	Ross
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cstrato at EUnet.at  Tue Feb  1 21:26:10 2000
From: cstrato at EUnet.at (cstrato@EUnet.at)
Date: Tue, 01 Feb 2000 21:26:10 +0100
Subject: [R] hdf5
Message-ID: <3897415C.349864D1@EUnet.at>

Dear R-user group

I am currently running R-0.90.1-1 for LinuxPPC on my PowerBook. Few days
ago
I have seen at CRAN that a new R-package exists, namely
R-base-with-hdf5-0.90.1-2.
Sorrowly, I could not find any explanation, what the difference to the
other package is.

I have downloaded the "Introduction to HDF5 Release 1.2" from
hdf.ncsa.uiuc.edu/HDF5.
It seems that HDF5 is a data format, wich overcomes some file size and
storage problems.

However, what is the advantage with respect to R?
Does this result in an improved memory model for R (or do I get
something wrong)?
Is it worth using this new version?

I have to work with very large tables (about 300,000 rows) so any
improvement in the
memory model of R would probably be an advantage.

Thank you in advance for your help.
Christian Stratowa, Ph.D.
Vienna

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mcw at ln.nimh.nih.gov  Wed Feb  2 03:43:20 2000
From: mcw at ln.nimh.nih.gov (Matthew Wiener)
Date: Tue, 1 Feb 2000 21:43:20 -0500 (EST)
Subject: [R] (not) compiling fortran -- dynamic loading problem
Message-ID: <Pine.SGI.3.96.1000201213651.27226A-100000@ln.nimh.nih.gov>

Hi, everyone.  This may be properly a fortran question rather than an R
question.

I'm trying to add a few print statements to otherwise working fortran code
in one of the libraries so I can see what's going on in the code.  I have
no problem doing so on an SGI machine, but under LinuxPPC I've run into a
problem.  The code compiles and creates a shared object (.so), but when I
issue the "library" command to load the new (printing) version, I get the
following error: 

undefined symbol: do_lio

I assume this must be some fortran i/o function, and perhaps I'm missing a
library.  But I've never seen this symbol before, and I can't find it in
the info pages for g77 (or on the LinuxPPC mailing lists).  Does anyone
have any idea where I can find this library on LinuxPPC?

(Or do I have the wrong idea about what the problem is?)

Thanks,

Matt Wiener






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From e980153 at leonard.anu.edu.au  Wed Feb  2 05:26:35 2000
From: e980153 at leonard.anu.edu.au (John Maindonald)
Date: Wed, 02 Feb 2000 15:26:35 +1100
Subject: [R] Outer margin (oma) settings for pairs()
Message-ID: <3.0.1.32.20000202152635.0069bbac@anu.edu.au>

I propose the following small changes to pairs.default.
The point is to allow control of the outer margin settings,
so that there is for example room for legends.

[Note also the issue re the setting of par()$usr on exit]

----------------------------------------------------------------
(1) Replace
function (x, labels, panel = points, main = NULL, font.main =
par("font.main"), 
    cex.main = par("cex.main"), ...) 

with:

function (x, labels, panel = points, main = NULL, font.main =
par("font.main"), 
    cex.main = par("cex.main"), oma=NULL, ...) 
(i. e. add the named parameter oma)

----------------------------------------------------------------
(2) Replace lines 16-19, i. e.

 oma <- c(4, 4, 4, 4)
    if (!is.null(main)) 
        oma[3] <- 6
    opar <- par(mfrow = c(nc, nc), mar = rep(0.5, 4), oma = oma)

with the following:

if(is.null(oma)){
    oma <- c(4, 4, 4, 4)
    if (!is.null(main)) 
        oma[3] <- 6}
    opar <- par(mfrow = c(nc, nc), mar = rep(0.5, 4), oma = oma)

----------------------------------------------------------------

A related issue has to do with the user co-ordinates [par()$usr]
that are left in place after exiting from pairs().  The user
co-ordinates seem to be determined by the range for the 
variable whose name appears in the bottom panel on the right, 
i. e. the final variable in the data frame.  They apply however
to the whole plot region.  The on.exit(par(opar)) resets other
parameters, but not par()$usr, which remain at the setting
used for the final panel.  One can of course interrogate
par()$usr for purposes of placing a legend, but it would
surely make more sense to reset par()$usr to c(0,1,0,1)?
[Note also that for using legend() to put legends in the margins,
one needs par(xpd=T).]

John Maindonald
john.maindonald at anu.edu.au

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From e980153 at leonard.anu.edu.au  Wed Feb  2 05:27:58 2000
From: e980153 at leonard.anu.edu.au (John Maindonald)
Date: Wed, 02 Feb 2000 15:27:58 +1100
Subject: [R] Side be side legend items?
Message-ID: <3.0.1.32.20000202152758.0069df38@anu.edu.au>

Am I right in thinking that legend() inevitably places the
successive items ine under the other, that it there is
at present no provision (short of multiple calls to
legend()) to place them side by side in multiple columns?

John Maindonald
john.maindonald at anu.edu.au

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From e980153 at leonard.anu.edu.au  Wed Feb  2 05:30:39 2000
From: e980153 at leonard.anu.edu.au (John Maindonald)
Date: Wed, 02 Feb 2000 15:30:39 +1100
Subject: [R] Plotting expressions
Message-ID: <3.0.1.32.20000202153039.0069df38@anu.edu.au>

Is there any way to move to a new line, when
using expression() within a text etc. command?

John Maindonald
john.maindonald at anu.edu.au
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Feb  2 08:49:50 2000
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 2 Feb 2000 08:49:50 +0100 (MET)
Subject: [R] glm
In-Reply-To: <Pine.GSO.4.05.10002010831520.20787-100000@auk.stats> from "Prof Brian D Ripley" at Feb 01, 2000 08:40:44 AM
Message-ID: <200002020749.IAA00019@alpha.luc.ac.be>


> 
> On Tue, 1 Feb 2000, Jim Lindsey wrote:
> 
> > > 4. I don't think AIC is stricly correct. My understanding of AIC is that
> > > it is the log likelihood maximised over all the parameters, including
> > > the dispersion parameter. Now the problem is that the mle of the
> > > dispersion parameter for the gamma family (and the exponential family in
> > > general) is really awkward - I think it has to be found by interative
> > > methods, using the derivative of the gamma function - I see from a print
> > > of Gamma that you are using dev/n, but I don't think this is the mle....
> > 
> > Yes you are right. I chose this only as a reasonable approximation for the
> > gamma and inverse Gaussian distributions. If you want the exact AIC,
> > you can get it from the gnlr function in my gnlm library.
> 
> Another way to get the MLE of the dispersion parameter from the glm output
> is to use the function gamma.shape.glm (by Bill Venables) in the MASS
> package.  Its help says
> 
> Details:
> 
>      A glm fit for a Gamma family correctly calculates the maximum
>      likelihood estimate of the mean parameters but provides only a
>      crude estimate of the dispersion parameter.  This function takes
>      the results of the glm fit and solves the maximum likelihood
>      equation for the reciprocal of the dispersion parameter, which is
>      usually called the shape (or exponent) parameter.
> 
> and yes it is optimized over an expression using the digamma and trigamma
> functions, but the code is about 30 lines only including all the warnings
> and housekeeping. (Such things show the power of S over GLIM: it would be
> `really awkward' in GLIM.)
> 
> Note, though, that McCullagh and Nelder argue hard against the MLE of
> dispersion in the gamma family.

That argument can be made when a precision interval is required for
the dispersion parameter (conditional or REML estimate). I do not
believe that it can be made for substituting the estimate into the
likelihood or AIC for comparing different models which is the case in
question here. Jim

> 
> Brian
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  2 08:49:06 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 2 Feb 2000 07:49:06 +0000 (GMT)
Subject: [R] (not) compiling fortran -- dynamic loading problem
In-Reply-To: <Pine.SGI.3.96.1000201213651.27226A-100000@ln.nimh.nih.gov>
Message-ID: <Pine.GSO.4.05.10002020738521.26986-100000@auk.stats>

On Tue, 1 Feb 2000, Matthew Wiener wrote:

> Hi, everyone.  This may be properly a fortran question rather than an R
> question.
> 
> I'm trying to add a few print statements to otherwise working fortran code
> in one of the libraries so I can see what's going on in the code.  I have
> no problem doing so on an SGI machine, but under LinuxPPC I've run into a
> problem.  The code compiles and creates a shared object (.so), but when I
> issue the "library" command to load the new (printing) version, I get the
> following error: 
> 
> undefined symbol: do_lio

It's in libg2c.a, in module libg2c.a[dolio.o], on gcc 2.95.2. I just ran
nm over the g77 libraries.

> I assume this must be some fortran i/o function, and perhaps I'm missing a
> library.  But I've never seen this symbol before, and I can't find it in
> the info pages for g77 (or on the LinuxPPC mailing lists).  Does anyone
> have any idea where I can find this library on LinuxPPC?
> 
> (Or do I have the wrong idea about what the problem is?)

You may need to adjust FLIBS. On my gcc/g77 build (Solaris), I have

FLIBS = -L/usr/local/lib   -L/usr/ccs/lib -L/usr/lib
-L/ext/gcc-2.95.2/lib/gcc-lib/sparc-sun-solaris2.6/2.95.2 -L/usr/ccs/bin -L/usr/ccs/lib
-L/ext/gcc-2.95.2/lib -lg2c -lm

so libg2c does get searched.


However, mixing C and Fortran I/O from R is not a good idea. That's why we
have subroutines dblepr, intpr and realpr for seeing what's going on in the
code. They are documented in the Writing R Extensions manual in the
development version, and I can quote a bit (please ignore the texinfo
markup):

In theory Fortran @code{write} and @code{print} statements can be used,
but its output may not interleave well with that of C, and will be
invisible on GUI interfaces.  They are best avoided.

Three subroutines are provided to ease the output of information from
Fortran code.  
@example
subroutine dblepr(label, nchar, data, ndata)
subroutine realpr(label, nchar, data, ndata)
subroutine intpr (label, nchar, data, ndata)
@end example

@noindent
Here @code{label} is a character label of up to 255 characters,
@code{nchar} is its length (which can be @code{-1} if the whole label is
to be used), and @code{data} is an array of length at least @code{ndata}
of the appropriate type (@code{double precision}, @code{real} and
@code{integer} respectively).  These routines print the label on one
line and then print @code{data} as if it were an @R{} vector on
subsequent line(s).  They work with @code{ndata = 0} and so can be used
to print a label alone.

The actual subroutines have been in R for a year or so, but the
documentation is new (like for many things in R).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  2 08:55:41 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 2 Feb 2000 07:55:41 +0000 (GMT)
Subject: [R] glm
In-Reply-To: <200002020749.IAA00019@alpha.luc.ac.be>
Message-ID: <Pine.GSO.4.05.10002020750230.26986-100000@auk.stats>

On Wed, 2 Feb 2000, Jim Lindsey wrote:

[> > Quoting me]
> > Note, though, that McCullagh and Nelder argue hard against the MLE of
> > dispersion in the gamma family.
> 
> That argument can be made when a precision interval is required for
> the dispersion parameter (conditional or REML estimate). I do not
> believe that it can be made for substituting the estimate into the
> likelihood or AIC for comparing different models which is the case in
> question here. Jim

Right, It was meant to be an aside as to why MLE estimation of the
dispersion might not be the default in R (or S). I don't think R's glm
should be quoting AICs (but then I have problems with understanding how one
compares two models on the basis of a measure whose derivation requires
each model to be true: there are extensions to AIC, like NIC and p_eff,
that avoid this).

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  2 09:07:43 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 2 Feb 2000 08:07:43 +0000 (GMT)
Subject: [R] Re: Outer margin (oma) settings for pairs()
In-Reply-To: <3.0.1.32.20000202152635.0069bbac@anu.edu.au>
Message-ID: <Pine.GSO.4.05.10002020757140.26986-100000@auk.stats>

On Wed, 2 Feb 2000, John Maindonald wrote:

> I propose the following small changes to pairs.default.
> The point is to allow control of the outer margin settings,
> so that there is for example room for legends.

John:

We've just hit feature freeze for 0.99.0 (due Feb 7, at least
in source form).  As this seems minor, I have put it in
(plus a comment on the help page).

Brian

> 
> [Note also the issue re the setting of par()$usr on exit]
> 
> ----------------------------------------------------------------
> (1) Replace
> function (x, labels, panel = points, main = NULL, font.main =
> par("font.main"), 
>     cex.main = par("cex.main"), ...) 
> 
> with:
> 
> function (x, labels, panel = points, main = NULL, font.main =
> par("font.main"), 
>     cex.main = par("cex.main"), oma=NULL, ...) 
> (i. e. add the named parameter oma)
> 
> ----------------------------------------------------------------
> (2) Replace lines 16-19, i. e.
> 
>  oma <- c(4, 4, 4, 4)
>     if (!is.null(main)) 
>         oma[3] <- 6
>     opar <- par(mfrow = c(nc, nc), mar = rep(0.5, 4), oma = oma)
> 
> with the following:
> 
> if(is.null(oma)){
>     oma <- c(4, 4, 4, 4)
>     if (!is.null(main)) 
>         oma[3] <- 6}
>     opar <- par(mfrow = c(nc, nc), mar = rep(0.5, 4), oma = oma)
> 
> ----------------------------------------------------------------
> 
> A related issue has to do with the user co-ordinates [par()$usr]
> that are left in place after exiting from pairs().  The user
> co-ordinates seem to be determined by the range for the 
> variable whose name appears in the bottom panel on the right, 
> i. e. the final variable in the data frame.  They apply however
> to the whole plot region.  The on.exit(par(opar)) resets other
> parameters, but not par()$usr, which remain at the setting
> used for the final panel.  One can of course interrogate
> par()$usr for purposes of placing a legend, but it would
> surely make more sense to reset par()$usr to c(0,1,0,1)?
> [Note also that for using legend() to put legends in the margins,
> one needs par(xpd=T).]

I think this is consistent with all multi-plot layouts. You should
only use the usr coordinates for the current plot, in that case the last
one drawn.  It would seem strange for pairs.default to be an exception
(and c(0,1,0,1) is not a user coordinate system for anything, as far as I
can see).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Wed Feb  2 09:32:37 2000
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed, 02 Feb 2000 09:32:37 +0100 (CET)
Subject: [R] hdf5
In-Reply-To: <3897415C.349864D1@EUnet.at>
Message-ID: <XFMail.000202093237.plummer@iarc.fr>

The only difference between the "R-base" and "R-base-with-hdf5" RPMs is
that the latter can read and write files in HDF5 format (This capability
is determined at compile time, which is why we need to distribute two
binary versions).  If you don't need to read and write HDF5 files, just
use the "R-base" RPM.

Martyn

On 01-Feb-00 cstrato at EUnet.at wrote:
> Dear R-user group
> 
> I am currently running R-0.90.1-1 for LinuxPPC on my PowerBook. Few days
> ago
> I have seen at CRAN that a new R-package exists, namely
> R-base-with-hdf5-0.90.1-2.
> Sorrowly, I could not find any explanation, what the difference to the
> other package is.
> 
> I have downloaded the "Introduction to HDF5 Release 1.2" from
> hdf.ncsa.uiuc.edu/HDF5.
> It seems that HDF5 is a data format, wich overcomes some file size and
> storage problems.
> 
> However, what is the advantage with respect to R?
> Does this result in an improved memory model for R (or do I get
> something wrong)?
> Is it worth using this new version?
> 
> I have to work with very large tables (about 300,000 rows) so any
> improvement in the
> memory model of R would probably be an advantage.
> 
> Thank you in advance for your help.
> Christian Stratowa, Ph.D.
> Vienna
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb  2 09:52:29 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Feb 2000 09:52:29 +0100
Subject: [R] Side be side legend items?
In-Reply-To: John Maindonald's message of "Wed, 02 Feb 2000 15:27:58 +1100"
References: <3.0.1.32.20000202152758.0069df38@anu.edu.au>
Message-ID: <x2snzc56lu.fsf@blueberry.kubism.ku.dk>

John Maindonald <e980153 at leonard.anu.edu.au> writes:

> Am I right in thinking that legend() inevitably places the
> successive items ine under the other, that it there is
> at present no provision (short of multiple calls to
> legend()) to place them side by side in multiple columns?

Yes... However, it may be possible to modify legend() if you add an
"nrows" parameter and redo the coordinate calculations. It looks like
more than an afternoons work, though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb  2 09:54:55 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Feb 2000 09:54:55 +0100
Subject: [R] Plotting expressions
In-Reply-To: John Maindonald's message of "Wed, 02 Feb 2000 15:30:39 +1100"
References: <3.0.1.32.20000202153039.0069df38@anu.edu.au>
Message-ID: <x2puug56hs.fsf@blueberry.kubism.ku.dk>

John Maindonald <e980153 at leonard.anu.edu.au> writes:

> Is there any way to move to a new line, when
> using expression() within a text etc. command?

text(1,0.5,expression(atop("x","yy")))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From loferre at univ-tlse2.fr  Wed Feb  2 11:18:07 2000
From: loferre at univ-tlse2.fr (Louis FERRE)
Date: Wed, 2 Feb 2000 11:18:07 +0100 (MET)
Subject: No subject
Message-ID: <200002021018.LAA27257@mail.univ-tlse2.fr>

I am using the rw0901 version of R and I fail in reading large files.
Actually, I really dont know how to extend the memory. Does somebody knows?
Louis FERRE
D?partement de Math?matiques et Informatique
Equipe GRIMM                  |Laboratoire de Stat et Proba
Universit? Toulouse Mirail    |Universit? Paul Sabatier
5, all?es Antonio Machado     |Ade:lferre at cict.fr
31058 Toulouse Cedex          |
Tel:05/61/50/46/11            |
Adel:loferre at univ-tlse2.fr    |http://www-sv.cict.fr/lsp/Ferre/index.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From michael.preminger at jbi.hioslo.no  Wed Feb  2 11:26:02 2000
From: michael.preminger at jbi.hioslo.no (Michael Preminger)
Date: Wed, 02 Feb 2000 10:26:02 +0000
Subject: [R] Factor Analysis?
Message-ID: <38980639.93647316@jbi.hioslo.no>

Hello.
I have been browsing the R- manual and not seen any direct
implementation of Factor analysis.
Is there anyone out there who has run Factor Analysis with R?

Thanks

Michael

--
Michael Preminger

Forsker / Research Scientist
Avdeling for journalistikk,
bibliotek- og informasjonsfag /
Faculty of Journalism, Library and
Information Science
H?gskolen i Oslo / Oslo College

http://www.hioslo.no/~michaelp

Pilestredet 52, N-0167 Oslo
Voice: +47-22452778
Fax:   +47-22452605
E-mail: michael.preminger at jbi.hioslo.no


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bitwrit at ozemail.com.au  Wed Feb  2 13:26:35 2000
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Wed, 02 Feb 2000 23:26:35 +1100
Subject: [R] Large data sets and aggregation
Message-ID: <3898227B.25544D38@ozemail.com.au>

I've noticed quite a few messages relating to large data sets bedeviling
R users, and having just had to program my way through one that actually
caused a "Bus error" when I tried to read it in, I'd like to ask two
questions.

1) Are there any facilities for aggregation of data in R?
( I admit that this will not do much for the large data set problem
immediately)

2) Is there any interest out there for a C-based roll-your-own
aggregation program?

I've had to reduce over 150,000 records to just under 3000 for a
multi-record per case data file, and I might be able to generalize the
code enough to make it useful for others.

Jim

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  2 13:25:53 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Feb 2000 12:25:53 +0000 (GMT)
Subject: [R] Factor Analysis?
Message-ID: <200002021225.MAA27402@toucan.stats.ox.ac.uk>

> Date: Wed, 02 Feb 2000 10:26:02 +0000
> From: Michael Preminger <michael.preminger at jbi.hioslo.no>

> I have been browsing the R- manual and not seen any direct
> implementation of Factor analysis.

True, AFAIK, in the strict sense.  However, quite a few books
call factor analysis what statisticians call principal components
analysis, and that is there, in standard package mva.

> Is there anyone out there who has run Factor Analysis with R?

I have an experimental implementation, but it depends on features in the
development version, due out as 0.99.0 next week. However, people
seem to expect things such as varimax rotations to go with factor
analysis, and I have not yet thought about that.

My feeling is that there are plenty of packages that do factor analysis,
and not much demand for it in R.  Anyone want to write a factor analysis
package for R?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolters at ikp.uni-bonn.de  Wed Feb  2 16:28:40 2000
From: wolters at ikp.uni-bonn.de (Maria Wolters)
Date: Wed, 02 Feb 2000 16:28:40 +0100
Subject: [R] Factor Analysis?
References: <200002021225.MAA27402@toucan.stats.ox.ac.uk>
Message-ID: <38984D28.6F4B1C4E@ikp.uni-bonn.de>

Brian Ripley wrote:

> My feeling is that there are plenty of packages that do factor analysis,
> and not much demand for it in R.  Anyone want to write a factor analysis
> package for R?

Well, IM very HO, the problem is that factor analysis is frequently used in the social
sciences, and social science people tend to prefer more GUI-orineted
packages such as SPSS or Systat. Therefore, demands have been low.
I believe that if R is to be a true alternative to mainstream stats 
packages, it should include this functionality. While we're at it,
a package dedicated to the analysis of survey results would also be great.
(I'm sure that R already contains most of the required functionality, but 
having it in a separate package would greatly speed up finding it. And no,
I don't have access to Matlab or Mathematica. And yes, most mainstream stats
books for the social sciences do cover only PCA as a factor analysis method.)

Judging from the contributions to the list, R seems to be quite popular in the 
statistics / applied statistics (biostatistics) community. I think
it's time for other communities to join in the effort and contribute packages.
Sociology, psychology, media studies, anyone? Linguistics? 
(will the physicist in the back row please stop laughing ... ;)

Since I'm a shoddy programmer myself, and have no prior experience with S
or S-Plus, I'm probably not the right person to write new packages. But I
would definitely be interested in collaborating on writing them, and sharing 
any of the truly embarrassing code I've come up with so far. Michael,
would you be interested in joining in? 

Maria Wolters
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Wed Feb  2 15:48:05 2000
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Wed, 2 Feb 2000 15:48:05 +0100
Subject: [R] Factor Analysis?
In-Reply-To: <200002021225.MAA27402@toucan.stats.ox.ac.uk>
Message-ID: <000b01bf6d8c$83d95290$a9021aac@joelschlaegel>



I know it is easy to wish features and difficult to implement them, thus I
hope it is ok to make the following remark (I can't offer to implement
factor analysis):

As R is an integrating statistics environment, I wish factor analysis (with
rotations) would be available within R on the long run, just BECAUSE it is a
kind of standard, which is in plenty of other packages.

>My feeling is that there are plenty of packages that do factor analysis,
>and not much demand for it in R.  Anyone want to write a factor analysis
>package for R?


Jens

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb  2 16:09:01 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Feb 2000 16:09:01 +0100
Subject: [R] Factor Analysis?
In-Reply-To: Maria Wolters's message of "Wed, 02 Feb 2000 16:28:40 +0100"
References: <200002021225.MAA27402@toucan.stats.ox.ac.uk> <38984D28.6F4B1C4E@ikp.uni-bonn.de>
Message-ID: <x2ya934p6a.fsf@blueberry.kubism.ku.dk>

Maria Wolters <wolters at ikp.uni-bonn.de> writes:

> Brian Ripley wrote:
> 
> > My feeling is that there are plenty of packages that do factor analysis,
> > and not much demand for it in R.  Anyone want to write a factor analysis
> > package for R?
> 
> Well, IM very HO, the problem is that factor analysis is frequently used in the social
> sciences, and social science people tend to prefer more GUI-orineted
> packages such as SPSS or Systat. Therefore, demands have been low.
> I believe that if R is to be a true alternative to mainstream stats 
> packages, it should include this functionality. 

Erm, while there is a certain truth to what you're saying, in that
factor analysis is often used by people who find anything non-GUI too
difficult, I don't think that is a valid cause for further supporting
that state of affairs... Such users will have no grasp of what a
factor analysis means and will likely overinterpret the results. 

There are good reasons to support factor analysis and other variants
of "structural equations modelling" and there are also good reasons to
make R more accessible to people with simple statistical needs, but
oversimplifying complicated models is a real danger. (And I have
several scary stories of the "I just filled in the forms the way it
seemed to be intended" variety, mostly with SPSS users.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s-luppescu at uchicago.edu  Wed Feb  2 16:18:29 2000
From: s-luppescu at uchicago.edu (Stuart Luppescu)
Date: Wed, 02 Feb 2000 09:18:29 -0600 (CST)
Subject: [R] Factor Analysis?
In-Reply-To: <200002021225.MAA27402@toucan.stats.ox.ac.uk>
Message-ID: <XFMail.000202091829.s-luppescu@uchicago.edu>

On 02-Feb-00 Prof Brian Ripley wrote:
> My feeling is that there are plenty of packages that do factor analysis,
> and not much demand for it in R.  Anyone want to write a factor analysis
> package for R?

You know what they say about factor analysis: it's what the data get into when
theory goes on vacation (or ``on holiday,'' for those of the British
persuasion).
______________________________________________________________________
Stuart Luppescu         -=-=-  University of Chicago
$(B:MJ8$HCRF`H~$NIc(B        -=-=-  s-luppescu at uchicago.edu
http://www.consortium-chicago.org/people/sl/sl.html
ICQ #21172047  AIM: psycho7070
Adam and Eve had many advantages, but the principal one was, that they escaped
teething.
                -- Mark Twain, "Pudd'nhead Wilson's Calendar"
>> Sent on 02-Feb-00 at 09:16:39 with xfmail
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolters at ikp.uni-bonn.de  Wed Feb  2 17:25:56 2000
From: wolters at ikp.uni-bonn.de (Maria Wolters)
Date: Wed, 02 Feb 2000 17:25:56 +0100
Subject: [R] Factor Analysis?
References: <200002021225.MAA27402@toucan.stats.ox.ac.uk> <38984D28.6F4B1C4E@ikp.uni-bonn.de> <x2ya934p6a.fsf@blueberry.kubism.ku.dk>
Message-ID: <38985A94.EB3D5433@ikp.uni-bonn.de>

Peter,

> Erm, while there is a certain truth to what you're saying, in that
> factor analysis is often used by people who find anything non-GUI too
> difficult, I don't think that is a valid cause for further supporting
> that state of affairs... Such users will have no grasp of what a
> factor analysis means and will likely overinterpret the results.
this is a valid point. My argument wasn't "let's make R more accessible",
it was "let's include this functionality" - in the hope that some 
stats-literate practicioners in these fields will be able to make good
use of it. 

I actually think it's an advantage of R that it discourages the innocent 
click'n'play approach fostered by GUI-based systems. In fact, using R
has shown me (personally) how statistically illiterate I still am, and 
made me much more aware of many use and misuse issues. 

Maria
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  2 16:44:19 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Feb 2000 15:44:19 +0000 (GMT)
Subject: [R] Factor Analysis?
Message-ID: <200002021544.PAA14447@toucan.stats.ox.ac.uk>

> Date: Wed, 02 Feb 2000 16:28:40 +0100
> From: Maria Wolters <wolters at ikp.uni-bonn.de>
> 
> Brian Ripley wrote:
> 
> > My feeling is that there are plenty of packages that do factor analysis,
> > and not much demand for it in R.  Anyone want to write a factor analysis
> > package for R?
> 
> Well, IM very HO, the problem is that factor analysis is frequently used in 
the social
> sciences, and social science people tend to prefer more GUI-orineted
> packages such as SPSS or Systat. Therefore, demands have been low.
> I believe that if R is to be a true alternative to mainstream stats 
> packages, it should include this functionality. 

That may not be our aim.  (By the way, there is an `alternative' to
SPSS out there, called PSPP at last count (it did have another name,
I think).)  Things get into R because we (the R community and especially
R core) want them for teaching, research, intellectual curiosity, ...
or even because we feel that other people need/want them.  I would like
to see factor analysis in R, but it comes below time series and a
usable Windows version in what I have wanted.

> While we're at it,
> a package dedicated to the analysis of survey results would also be great.
> (I'm sure that R already contains most of the required functionality, but 
> having it in a separate package would greatly speed up finding it. And no,
> I don't have access to Matlab or Mathematica. And yes, most mainstream stats
> books for the social sciences do cover only PCA as a factor analysis method.)
> 
> Judging from the contributions to the list, R seems to be quite popular in the 
> statistics / applied statistics (biostatistics) community. I think
> it's time for other communities to join in the effort and contribute packages.
> Sociology, psychology, media studies, anyone? Linguistics? 
> (will the physicist in the back row please stop laughing ... ;)

I went to a research conference in linguistics and music to talk
about pattern recognition a year or so ago....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at biostat.washington.edu  Wed Feb  2 18:11:22 2000
From: rossini at biostat.washington.edu (A.J. Rossini)
Date: 02 Feb 2000 09:11:22 -0800
Subject: [R] Factor Analysis?
In-Reply-To: Prof Brian Ripley's message of "Wed, 2 Feb 2000 15:44:19 +0000 (GMT)"
References: <200002021544.PAA14447@toucan.stats.ox.ac.uk>
Message-ID: <877lgn5y2t.fsf@alpha.cfas.washington.edu>



    >> Date: Wed, 02 Feb 2000 16:28:40 +0100 From: Maria Wolters

    >> Judging from the contributions to the list, R seems to be quite
    >> popular in the statistics / applied statistics (biostatistics)
    >> community. I think it's time for other communities to join in
    >> the effort and contribute packages.  Sociology, psychology,
    >> media studies, anyone? Linguistics? (will the physicist in the
    >> back row please stop laughing ... ;)

Sure, some of us are working on detailing how to use R for Social
Network Analysis, among other things (as well as implementing some of
the "less traditional" methods found there...).

Of course, we know that all fields come under the heading
"biostatistics" or "applications of biostatistics", so your first
sentence covers most fields of endeavor...

best,
-tony

-- 
A.J. Rossini		       Research Assistant Professor of Biostatistics 
Biostatistics/Univ. of Washington  (Th)	Box 357232   206-543-1044 (3286=fax)
Center for AIDS Research/HMC/UW	  (M/F)	Box 359931   206-731-3647 (3693=fax)
VTN/SCHARP/FHCRC		 (Tu/W)	Box 358080   206-667-7025 (4812=fax)
rossini@(biostat.washington.edu|u.washington.edu|hivnet.fhcrc.org)
http://www.biostat.washington.edu/~rossini

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lorenmc at socrates.berkeley.edu  Wed Feb  2 18:12:34 2000
From: lorenmc at socrates.berkeley.edu (Loren M. McCarter)
Date: Wed, 02 Feb 2000 09:12:34 -0800 (PST)
Subject: [R] Factor Analysis?
In-Reply-To: <38984D28.6F4B1C4E@ikp.uni-bonn.de>
References: <200002021225.MAA27402@toucan.stats.ox.ac.uk>
	<38984D28.6F4B1C4E@ikp.uni-bonn.de>
Message-ID: <20000202091234P.lorenmc@socrates.berkeley.edu>


> Brian Ripley wrote:
> 
ripley> My feeling is that there are plenty of packages that do factor analysis,
ripley> and not much demand for it in R.  Anyone want to write a factor analysis
ripley> package for R?
ripley> 

I'm simultaneously working on my dissertation and also putting
together a collection of variations on principal components analysis
(pca) techniques into an R library. Unfortunately, I don't think that
I will have a complete R library until at least a few months as it has
to take a back seat to writing and graduating from school. Unless
someone else has taken the initiative by then, I will plan to begin
adding factor analysis to the library. And yes, the rotation (e.g.,
varimax) would be a necessary option for most factor analysts and yes,
it would take me some time to figure out how to write those rotation
functions.

I personnally use pca more than factor analysis because pca allows the
output of vectors containing "observed" component scores for each
individual, which is useful for my work. Factor analysis requires more
assumptions about the data and does not allow, theoretically, the
output of vectors containing the "observed" individual component
scores. Of course, factor analysis also has many advantages over pca
if assumptions are met and observed component scores are not
necessary.

Maria Wolters <wolters at ikp.uni-bonn.de> wrote:
wolters> Well, IM very HO, the problem is that factor analysis is frequently used in the social
wolters> sciences, and social science people tend to prefer more GUI-orineted
wolters> packages such as SPSS or Systat....

I'm a graduate student in behavioral neuroscience, which is officially
in psychology and thus I have some experience with this. Though there
is certainly variation among psychologists (many do use S-Plus and
many work with large complex datasets), you are correct that the
majority of psychologists do seem to use and prefer the GUI,
point-and-click interfaces (ala SPSS). The datasets of many
psychologists have a small n with many variables, and do not require
much computer programming to perform manipulations (e.g., little need
to use UNIX, perl, python etc. to manipulate matrices).

Among the statistically and computationally-sophisticated
psychologists, many are experts in techniques such as Structural
Equation Modeling (SEM), which can be described as a factor-analytic
approach to path analysis. Interestingly, the SEM software market has
been dominated by specialized statistical packages, not the
mainstream, one-size-fits-all, statistical packages. For example, most
psychologists do NOT use the SEM procedures bundled with SAS (i.e.,
PROC CALIS) but instead prefer LISREL, AMOS, EQS, MPlus and the like
(I believe that SPSS owns LISREL however). Many of these packages
allow the user to draw path diagrams in a GUI dialog box and then
apply SEM statistical tests to the drawing, which is quite useful for
testing path theories. There is a "freely downloadable" (though I do
not think that it is open-source) SEM package called Mx, by Michael
Neale (see http://views.vcu.edu/mx/; runs on Linux [also my FreeBSD
2.2.8 Linux emulation] and Windows).

I agree that an SEM library (including factor analysis functions)
would be a nice addition to R, but maybe it would be more reasonable
to create an R interface to Mx, which is already a full-blown SEM
package (of course this may be a stupid idea on my part, especially
since obtaining the Mx open-source may not be an option).

Loren

----------------------------------------
Loren McCarter
Graduate Student, Behavioral Neuroscience
UC Berkeley
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Feb  2 18:33:22 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 02 Feb 2000 11:33:22 -0600
Subject: [R] Large data sets and aggregation
In-Reply-To: Jim Lemon's message of "Wed, 02 Feb 2000 23:26:35 +1100"
References: <3898227B.25544D38@ozemail.com.au>
Message-ID: <6rzotjcxwd.fsf@franz.stat.wisc.edu>

One of the many items on my "To Do" list is writing a short primer on
using relational databases with R.  I am currently working with some
data that consists of hundreds of thousands of records on thousands of
variables.  Needless to say, we don't load that directly into R.

We have written several scripts in python to crack the original data
files (SAS packed data sets) and install the data into a relational
database.  The relational database system we use is MySQL
(www.mysql.com).  It provides powerful facilities for manipulating
data and performing operations like aggregation.  We have been
impressed with MySQL.  PostgreSQL is another possibility.  Timothy
Keitt has written an PostgreSQL interface package for R.

David James at Bell Labs has drafted an API for relational database
interfaces from S or R.  He also wrote an implementation of an
interface to MySQL for S, which Saikat DebRoy has modified for R.  I
understand that the RMySQL package should be uploaded to CRAN "real
soon".

This interface allows us to do all the large scale data manipulation
in MySQL then extract pieces for modeling within R.  There are many
advantages to this approach including speed, data persistence,
simultaneous access to the data by several users, etc.  The main
disadvantage is the need to learn yet another language (SQL) to do the
manipulations.  I have found Paul Dubois's book "MySQL" to be a very
good way to learn MySQL.  The first chapter alone is worth the cost of
the book.

I should warn the list that I am famous for never getting to many of
the items on the ToDo list so you should not hold your breath waiting
for the primer.

Jim Lemon <bitwrit at ozemail.com.au> writes:

> I've noticed quite a few messages relating to large data sets bedeviling
> R users, and having just had to program my way through one that actually
> caused a "Bus error" when I tried to read it in, I'd like to ask two
> questions.
> 
> 1) Are there any facilities for aggregation of data in R?
> ( I admit that this will not do much for the large data set problem
> immediately)
> 
> 2) Is there any interest out there for a C-based roll-your-own
> aggregation program?
> 
> I've had to reduce over 150,000 records to just under 3000 for a
> multi-record per case data file, and I might be able to generalize the
> code enough to make it useful for others.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From loparic at student.fsa.ucl.ac.be  Wed Feb  2 23:44:51 2000
From: loparic at student.fsa.ucl.ac.be (Adriane Leal)
Date: Wed, 2 Feb 2000 23:44:51 +0100 (CET)
Subject: No subject
Message-ID: <Pine.LNX.3.96.1000202233557.222B-100000@18-11.campusnet.ucl.ac.be>

Dear fellows,
 
I'd like to perform a box-cox transformation to a data set and also plot
lambda versus L(lambda) using R. Does anybody knows how can I do such a
thing? 

Greetings to all,

Adriane

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From loparic at student.fsa.ucl.ac.be  Thu Feb  3 00:21:02 2000
From: loparic at student.fsa.ucl.ac.be (Adriane Leal)
Date: Thu, 3 Feb 2000 00:21:02 +0100 (CET)
Subject: [R] Deleting a component with a known probability
Message-ID: <Pine.LNX.3.96.1000203001441.292A-100000@18-11.campusnet.ucl.ac.be>

Here I'm again!

Imagine you have a bivariate normal sample (n=500) , with mean
vector=(0,0)T and Covariance matrix (1,.9,.9,1). How could I construct an
incomplete sample by deleting the second component Yi1 with probability:

Pi= (e**2Yi1)/(1+e**2Yi1) ?

best regards,

Adriane

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From eschmid at php.net  Wed Feb  2 19:29:17 2000
From: eschmid at php.net (Egon Schmid)
Date: Wed, 02 Feb 2000 19:29:17 +0100
Subject: [R] Large data sets and aggregation
References: <3898227B.25544D38@ozemail.com.au> <6rzotjcxwd.fsf@franz.stat.wisc.edu>
Message-ID: <3898777D.C53FD83@php.net>

Douglas Bates wrote:

> This interface allows us to do all the large scale data manipulation
> in MySQL then extract pieces for modeling within R.  There are many
> advantages to this approach including speed, data persistence,
> simultaneous access to the data by several users, etc.  The main
> disadvantage is the need to learn yet another language (SQL) to do the
> manipulations.  I have found Paul Dubois's book "MySQL" to be a very
> good way to learn MySQL.  The first chapter alone is worth the cost of
> the book.

I know, the book by Paul DuBois is the best book I have read about
MySQL. But why don't you use PHP?

-Egon

-- 
Gr?ninger Stra?e 6 ? D-70599 Stuttgart
Fon +49 711 45 37 21 ? http://www.php.net/
http://www.php.net/manual/ ? http://www.php.net/books.php3
Concert Band: http://www.uni-hohenheim.de/~windband/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  2 19:39:52 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 2 Feb 2000 18:39:52 +0000 (GMT)
Subject: [R] Re: your mail
In-Reply-To: <Pine.LNX.3.96.1000202233557.222B-100000@18-11.campusnet.ucl.ac.be>
Message-ID: <Pine.GSO.4.05.10002021839080.12091-100000@auk.stats>

On Wed, 2 Feb 2000, Adriane Leal wrote:

> I'd like to perform a box-cox transformation to a data set and also plot
> lambda versus L(lambda) using R. Does anybody knows how can I do such a
> thing? 

Use boxcox in package MASS, at least for a linear model.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From loparic at student.fsa.ucl.ac.be  Thu Feb  3 00:46:54 2000
From: loparic at student.fsa.ucl.ac.be (Adriane Leal)
Date: Thu, 3 Feb 2000 00:46:54 +0100 (CET)
Subject: [R] Correction-Deleting a component with a known probability 
Message-ID: <Pine.LNX.3.96.1000203004409.226B-100000@18-11.campusnet.ucl.ac.be>

Sorry. Correction: by deleting the second component Yi2... 

______________________________________________________________________
Imagine you have a bivariate normal sample (n=500) , with mean
vector=(0,0)T and Covariance matrix (1,.9,.9,1). How could I construct an
incomplete sample by deleting the second component Yi1 with probability:

Pi= (e**2Yi1)/(1+e**2Yi1) ?

best regards,

Adriane



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From loparic at student.fsa.ucl.ac.be  Thu Feb  3 00:48:16 2000
From: loparic at student.fsa.ucl.ac.be (Adriane Leal)
Date: Thu, 3 Feb 2000 00:48:16 +0100 (CET)
Subject: [R] Re: your mail
In-Reply-To: <Pine.GSO.4.05.10002021839080.12091-100000@auk.stats>
Message-ID: <Pine.LNX.3.96.1000203004718.226D-100000@18-11.campusnet.ucl.ac.be>

Thanks very much for the information. I'll try right now.

greetings, Adriane

On Wed, 2 Feb 2000, Prof Brian D Ripley wrote:

> On Wed, 2 Feb 2000, Adriane Leal wrote:
> 
> > I'd like to perform a box-cox transformation to a data set and also plot
> > lambda versus L(lambda) using R. Does anybody knows how can I do such a
> > thing? 
> 
> Use boxcox in package MASS, at least for a linear model.
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lorenmc at socrates.berkeley.edu  Wed Feb  2 21:00:06 2000
From: lorenmc at socrates.berkeley.edu (Loren M. McCarter)
Date: Wed, 02 Feb 2000 12:00:06 -0800 (PST)
Subject: [R] Summary: Archetypal Analysis in R
Message-ID: <20000202120006T.lorenmc@socrates.berkeley.edu>

I previously asked a question about performing archetypal analyis in
R. In addition to the responses I received from r-help, the author
sent me some S code to peform the analysis. With the author's
permission, I ported the S code to R using two excellent sets of
instructions:

(1) From the FAQ - 5.5 How can I create an R package?
(2) Thomas Lumley's instructions on porting S to R - 
    http://www.biostat.washington.edu/~thomas/Rlib.html

The author of this code is Adele Cutler (adele at math.usu.edu,
http://www.math.usu.edu/~adele). With the author's permission, I've
made this port available at:

http://socrates.berkeley.edu/~lorenmc/R/

Since this is not a full-blown library and hasn't been completely
tested with R, I don't think it is ready to be submitted as an R
library (it only has one function!), but feel free to download it if
you want to check it out or need it to perform some analyses. To the R
core team members, this is my first contribution so please to let me
if I have gone about this process incorrectly. Thanks.

Loren

--------------------------------------------------
Loren McCarter
Graduate Student, Behavioral Neuroscience
UC Berkeley
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MattP2 at prodigy.net  Wed Feb  2 22:05:43 2000
From: MattP2 at prodigy.net (Matt Pocernich)
Date: Wed, 2 Feb 2000 14:05:43 -0700
Subject: [R] Placing a varialbe within a text statement.
Message-ID: <00bb01bf6dc1$45649a80$21f8fed1@dog>

I have a simple question.

On a plot, I would like to place text containing a calculated value.  What is the format?

For example.

I would like the following text to appear on a plot.

The average temperature is 23.1 degrees.

I'm guessing the command is 
text( x, y, "The average temperature is " %variable name% "degrees")

Thanks,
Matt Pocernich
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000202/b943cd4c/attachment.html

From thomas at biostat.washington.edu  Wed Feb  2 22:14:41 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Wed, 2 Feb 2000 21:14:41 +0000 (GMT)
Subject: [R] Placing a varialbe within a text statement.
In-Reply-To: <00bb01bf6dc1$45649a80$21f8fed1@dog>
Message-ID: <Pine.LNX.4.10.10002022113040.11658-100000@gimel.biostat.washington.edu>

On Wed, 2 Feb 2000, Matt Pocernich wrote:

> I have a simple question.
> 
> On a plot, I would like to place text containing a calculated value.  What is the format?
> 
> For example.
> 
> I would like the following text to appear on a plot.
> 
> The average temperature is 23.1 degrees.
> 
> I'm guessing the command is 
> text( x, y, "The average temperature is " %variable name% "degrees")
> 
You're guessing incorrectly.  Try

	text(x,y,paste("The average temperature is ", variable, "degrees"))

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Mike.McCoy at arbitron.com  Wed Feb  2 23:43:56 2000
From: Mike.McCoy at arbitron.com (McCoy, Mike)
Date: Wed, 2 Feb 2000 17:43:56 -0500 
Subject: [R] "R"
Message-ID: <411EA40BC162D211B92B0008C7B1D2B301D571CA@arbmdex.arbitron.com>


  Help!  I was surfing the net looking for documentation on the relationship
between the power exponential family distribution and the internal
correlation of sets of exponential data, when I ran into one of your 'R'
pages.  I'm hoping to develop a radio listening pattern model based on a
generalized gamma distribution, beginning with raw Weibull listening
durations.  This package, 'R', sounds invaluable, but I cannot seem to
locate directions on how to get it!  Please help.

Also, is there documentation across the rich spread of distributions offered
that suggest when one distribution may be preferred over another?  For
instance, I find plentiful references in academic texts to normal-gamma
distributions (sets of normal distributions, themselves distributed such
that their precisions (inverted variances) are gamma distributed.)  These
have nice properties in Bayesian conjugate families, but I've never heard of
any situation where such a distribution is applicable?  So, I'd love to have
this 'R' with some quickie manual of helpful application hints -- caveat
emptor, I know, but I'd still like some idea of how these may come into play
in the real world.

Thanks for whatever you can tell me.  I'm very excited about the utility
this package may have for my media research work!

Sincerely,

		Mike McCoy    (mike.mccoy at arbitron.com)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From john.maindonald at anu.edu.au  Thu Feb  3 00:01:46 2000
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 3 Feb 2000 10:01:46 +1100 (EST)
Subject: [R] Factor Analysis?
Message-ID: <200002022301.KAA16223@leonard.anu.edu.au>

Peter Dalgaard wrote:

> Erm, while there is a certain truth to what you're saying, in that
> factor analysis is often used by people who find anything non-GUI too
> difficult, I don't think that is a valid cause for further supporting
> that state of affairs... Such users will have no grasp of what a
> factor analysis means and will likely overinterpret the results. 
> 
> There are good reasons to support factor analysis and other variants
> of "structural equations modelling" and there are also good reasons to
> make R more accessible to people with simple statistical needs, but
> oversimplifying complicated models is a real danger. (And I have
> several scary stories of the "I just filled in the forms the way it
> seemed to be intended" variety, mostly with SPSS users.)

One could easily get the impression that these sorts of use are almost
the only ways in which factor analysis that goes beyond principal
components kinds of uses, and structural equation modelling, are used.
It is very hard to find examples of the use of these techniques where
there is some genuine and plausible attempt at model validation.  It
is also very hard to devise and implement good diagnostic statistics
and plots.  Such concerns are well articulated in David Freedman's
paper (with extensive following discussion) "As Others See Us; A Case
Study in Path Analysis", in J. Educ. Statistics 12: 101-223

I'd very much like to learn of published examples of the use of
these methods which do address these concerns.  If these can be
found, they would be good references to include when and if these
techniques are implemented.

One reason for the current popularity of qualitative research methods
in the social sciences may be a disaffection with the way that these
methodologies are used to provide results whose meaning and
interpretation make sense only to high priests of these arts.  There's
a good deal of unease about much of the way these methdologies are
used in the social sciences, but those who are uneasy rarely have the
technical skills needed to go beyond unease to articulate criticism.

(By the way, I think qualitative research has a pretty important role.
I do not want to leave the impression that I see qualititative and
quantitative approaches as alternatives, though this is the way they
are presented in much of the literature.  What is needed and has long
been needed is an effective marriage of quantitative approaches with
well-conducted qualitative research.)


John Maindonald               email : john.maindonald at anu.edu.au        
Statistical Consulting Unit,  phone : (6249)3998        
c/o CMA, SMS,                 fax   : (6249)5549  
John Dedman Mathematical Sciences Building
Australian National University
Canberra ACT 0200
Australia
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stewart at scitec.auckland.ac.nz  Thu Feb  3 01:11:07 2000
From: stewart at scitec.auckland.ac.nz (Wayne Stewart)
Date: Thu, 03 Feb 2000 13:11:07 +1300
Subject: [R] sas.get
Message-ID: <3898C79B.CCDF9FF8@scitec.auckland.ac.nz>

Is there an "R" equivalent of the Splus "sas.get"?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: stewart.vcf
Type: text/x-vcard
Size: 220 bytes
Desc: Card for Wayne Stewart
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000203/b520fc32/stewart.vcf

From mhart at terrigal.net.au  Thu Feb  3 01:49:14 2000
From: mhart at terrigal.net.au (Michael Hart)
Date: Thu, 3 Feb 2000 11:49:14 +1100
Subject: [R] Factor Analysis?
Message-ID: <059201bf6de0$7f32c9c0$08c3fea9@maincomputer>

-----Original Message-----
From: John Maindonald <john.maindonald at anu.edu.au>
To: p.dalgaard at biostat.ku.dk <p.dalgaard at biostat.ku.dk>;
wolters at ikp.uni-bonn.de <wolters at ikp.uni-bonn.de>
Cc: r-help at stat.math.ethz.ch <r-help at stat.math.ethz.ch>
Date: Thursday, February 03, 2000 11:08 AM
Subject: Re: [R] Factor Analysis?


>One reason for the current popularity of qualitative research methods
>in the social sciences may be a disaffection with the way that these
>methodologies are used to provide results whose meaning and
>interpretation make sense only to high priests of these arts.  There's
>a good deal of unease about much of the way these methdologies are
>used in the social sciences, but those who are uneasy rarely have the
>technical skills needed to go beyond unease to articulate criticism.


Hi John,

Whilst this is off the topic of this list it does deserve a response.

I hate to be somewhat cynical but I think the current popularity for
qualitative research, particularly in social sciences and psychology, stems
largely from the fact that the funding bodies require a desired result and
are using "research" to "prove" their point.

The research method, in many cases, must be manipulated to produce the
desired result.  Qualitative research allows this on many levels:

1.  It allows selective usage of data.
2.  It allows selective interpretation of data.
3.  It allows selective reporting of data.

Whilst I think qualitive research is a necessary precurser to quantitative
work I believe it has been put to malevolent use in some areas of social
science and psychology.

I refute your point above and have seen in the past some fairly
sophisticated statistics developed by these groups some of which has been
adopted by more mainstream medical sience.

I know that in Australia over the last few years I can think of a number of
scientificly flawed "research" projects which cost the taxpayer millions and
only done to enhance the funding body (i.e particular social interest
groups) profile and ability to get more money as well as secure "scientific
proof" of their philosophy.  If you would like to discuss the particular
projects (one of which the ABS was contracted to do) I would be pleased to
do so off list.

Michael Hart
MIXSTATICS
Ph  +61 2 4325 4859
Fax +61 2 4324 9660

>(By the way, I think qualitative research has a pretty important role.
>I do not want to leave the impression that I see qualititative and
>quantitative approaches as alternatives, though this is the way they
>are presented in much of the literature.  What is needed and has long
>been needed is an effective marriage of quantitative approaches with
>well-conducted qualitative research.)
>
>
>John Maindonald               email : john.maindonald at anu.edu.au
>Statistical Consulting Unit,  phone : (6249)3998
>c/o CMA, SMS,                 fax   : (6249)5549
>John Dedman Mathematical Sciences Building
>Australian National University
>Canberra ACT 0200
>Australia


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nbentley at trophia.com  Thu Feb  3 06:59:38 2000
From: nbentley at trophia.com (Nokome Bentley)
Date: Thu, 3 Feb 2000 18:59:38 +1300
Subject: [R] map() and C++ interface
Message-ID: <000001bf6e0b$db1befc0$5bfd6dcb@jasus>

Hi,

I am just beginning to use R for Windows and have two (perhaps naive)
questions:

1.  I am wanting to produce maps of the New Zealand coastline using R.   I
am aware of the map function in S-plus and was wondering if anyone had
ported it to R yet.  I could use the 'world' database for the data source
but since it is very large I was also wondering if anyone had fine scale
long and lat data for the NZ coatline.

2.  I am doing simulations using a C++ and am looking for a way to easily
transfer outputs to R.  Text files are an obvious way but it would be neat
to output all my simulation C++ objects into a single .RData file and then
to analyse and plot them from there.  Is there a way of doing that? Should I
consult the R source code?  Or would it be easier to create an R package
from within my C++ code.

Thanks,

Nokome Bentley

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Zdenek.Skala at incoma.cz  Thu Feb  3 09:00:55 2000
From: Zdenek.Skala at incoma.cz (Zdenek Skala)
Date: Thu, 3 Feb 2000 09:00:55 +0100
Subject: [R] Factor Analysis?
In-Reply-To: <38985A94.EB3D5433@ikp.uni-bonn.de>
Message-ID: <200002030758.IAA32138@benes.incoma.cz>

Maria Wolters wrote:
> I actually think it's an advantage of R that it discourages the innocent
> click'n'play approach fostered by GUI-based systems. In fact, using R has
> shown me (personally) how statistically illiterate I still am, and made me
> much more aware of many use and misuse issues. 

Agree completely. I am a "simple user" of R, so unfortunately 
unable to write new library and feel, of course, that it is harder to 
write one than to require it... I would only argue in favor of factor 
analysis in general, not to exclude it principally from the future R 
development: (1) it is, in my opinion, not only for social sciences - 
in "biostatistics" (and especially morphometrics) I feel high 
potential for use of factor analysis; (2) at the same time, life 
scientists are often using S(plus)/R - so the audience is prepared; 
(3) my understanding of factor analysis is that it does not differ 
from PCA primarily by rotation but by searching for structure within 
a (partial) correlation matrix, not within a covariance matrix. As 
such it *is*, in my opinion, intellectually attractive and not only 
useful for practitioners.
Best
Zdenek Skala
++++++++++++++++++++++
] Zdenek Skala
] e-mail:
] Zdenek.Skala at incoma.cz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steuer at statistik.uni-dortmund.de  Thu Feb  3 10:07:51 2000
From: steuer at statistik.uni-dortmund.de (Dipl.-Stat. Detlef Steuer)
Date: Thu, 03 Feb 2000 10:07:51 +0100 (CET)
Subject: [R] Large data sets and aggregation
In-Reply-To: <6rzotjcxwd.fsf@franz.stat.wisc.edu>
Message-ID: <XFMail.20000203100751.steuer@statistik.uni-dortmund.de>

Hello!
Nice to read these news.

> 
> David James at Bell Labs has drafted an API for relational database
> interfaces from S or R.  He also wrote an implementation of an
> interface to MySQL for S, which Saikat DebRoy has modified for R.  I
> understand that the RMySQL package should be uploaded to CRAN "real
> soon".

As I am working on a RMySQL package myself (I need it to inerface a relatively
small project which uses MySQL), are
there any adresses to contact Saikat DebRoy or to download alpha/beta Versions
of his code? 
If the work is already done, I will stop  working on it _now_ :-)

Detlef


> 
> -- 
> Douglas Bates                            bates at stat.wisc.edu
> Statistics Department                    608/262-2598
> University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

-- 

Detlef Steuer Universitaet Dortmund                             ///////
LS Computergestuetzte Statistik                          U N I D O ///  
steuer at statistik.uni-dortmund.de                        ______///////  
Tel: ++49 +231 755 4353 Fax: ++49 +231 755 4387         \_\_\_\/////
                                                         \_\_\_\///
                                                          \_\_\_\/

*** Use what talents you possess: the woods would be very silent ***
*** if no birds sang there except those that sang best.          ***
*** Henry Van Dyke                                               ***
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb  3 10:09:22 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 3 Feb 2000 09:09:22 +0000 (GMT)
Subject: [R] map() and C++ interface
In-Reply-To: <000001bf6e0b$db1befc0$5bfd6dcb@jasus>
Message-ID: <Pine.GSO.4.05.10002030902441.15467-100000@auk.stats>

On Thu, 3 Feb 2000, Nokome Bentley wrote:

> I am just beginning to use R for Windows and have two (perhaps naive)
> questions:
> 
[Q1 on maps left for others]

> 2.  I am doing simulations using a C++ and am looking for a way to easily
> transfer outputs to R.  Text files are an obvious way but it would be neat
> to output all my simulation C++ objects into a single .RData file and then
> to analyse and plot them from there.  Is there a way of doing that? Should I
> consult the R source code?  Or would it be easier to create an R package
> from within my C++ code.

You could borrow the R save code, but as you don't have R objects to start
with that would be tricky.  One idea you might like to try is to use hdf5.
As of the next release (next week), there is an hdf5 package available for
the Windows version of R, and Windows libraries are on the HDF5 site. Then
you can use hdf5load to load in all the objects you wrote of a single hdf5
file.

Another idea (which maybe is what you last para meant) is to dynamically
load your C++ into R. Then you can write return or write R objects form
your C++ code (but you will need to understand a lot of the `Writing R
Extensions' manual to do that).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Thu Feb  3 10:13:23 2000
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Thu, 3 Feb 2000 10:13:23 +0100 (MET)
Subject: [R] Re: your mail
Message-ID: <200002030913.KAA25484@alpha.luc.ac.be>

> On Wed, 2 Feb 2000, Adriane Leal wrote:
> 
> > I'd like to perform a box-cox transformation to a data set and also plot
> > lambda versus L(lambda) using R. Does anybody knows how can I do such a
> > thing? 

gnlr3 in my gnlm library does both linear and nonlinear models with
Box-Cox transformation. However, it is somewhat nonstandard as it
renormalizes to obtain a true density whereas the standard
transformation creates a function that is not a density because of the
constraint that only positive values can be transformed but the normal
distribution is on the whole real line. Jim
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From albmun at est-econ.uc3m.es  Thu Feb  3 13:32:07 2000
From: albmun at est-econ.uc3m.es (Alberto =?iso-8859-1?Q?Mu=F1oz?=)
Date: Thu, 03 Feb 2000 13:32:07 +0100
Subject: [R] How to include TeX formulae in R plots?
Message-ID: <38997547.E0CB0B88@est-econ.uc3m.es>

Hi, all

Does anybody know if it is possible to include TeX-style formulae
in R plots? The aim is to export such plots to LaTeX documents
using the postscript() device.

Many  thanks in advance,


Alberto Munoz


---------------------------------------------------------------------
Alberto Munoz                       Phone: +34-91- 624 95 79
Dpto. de Estadistica y Econometria  Fax:   +34-91- 624 98 49
c/Madrid 126, 28903 Getafe          e-mail: albmun at est-econ.uc3m.es
Universidad Carlos III de Madrid
---------------------------------------------------------------------



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Feb  3 14:21:56 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Feb 2000 07:21:56 -0600
Subject: [R] Large data sets and aggregation
In-Reply-To: "Dipl.-Stat. Detlef Steuer"'s message of "Thu, 03 Feb 2000 10:07:51 +0100 (CET)"
References: <XFMail.20000203100751.steuer@statistik.uni-dortmund.de>
Message-ID: <6rln52l8uj.fsf@franz.stat.wisc.edu>

"Dipl.-Stat. Detlef Steuer" <steuer at statistik.uni-dortmund.de> writes:

> Hello!
> Nice to read these news.
> 
> > =
> 
> > David James at Bell Labs has drafted an API for relational database
> > interfaces from S or R.  He also wrote an implementation of an
> > interface to MySQL for S, which Saikat DebRoy has modified for R.  I
> > understand that the RMySQL package should be uploaded to CRAN "real
> > soon".
> 
> As I am working on a RMySQL package myself (I need it to inerface a relativ=
> ely
> small project which uses MySQL), are
> there any adresses to contact Saikat DebRoy or to download alpha/beta Versi=
> ons
> of his code? =
> 
> If the work is already done, I will stop  working on it _now_ :-)

Saikat DebRoy <saikat at stat.wisc.edu>
David James <dj at research.bell-labs.com>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Feb  3 14:33:52 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Feb 2000 07:33:52 -0600
Subject: [R] sas.get
In-Reply-To: Wayne Stewart's message of "Thu, 03 Feb 2000 13:11:07 +1300"
References: <3898C79B.CCDF9FF8@scitec.auckland.ac.nz>
Message-ID: <6rhffql8an.fsf@franz.stat.wisc.edu>

Wayne Stewart <stewart at scitec.auckland.ac.nz> writes:

> Is there an "R" equivalent of the Splus "sas.get"?

There is a package called `foreign' in the Devel section of the
contributed packages at CRAN.  It can only be expected to compile
under R-0.99.0, which is scheduled for release next Monday.

The foreign package allows reading of SAS data sets in the XPORT
format.  The XPORT format is standardized across machine architectures
and documented (sort-of).  It has been adopted by the Food and Drug
Administration (FDA) of the United States government as their `vendor
neutral' data format.  (I like the idea that `vendor neutral' means
`whatever SAS Institute says'.)

I don't know of any packages to read the general SAS data formats.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Feb  3 15:02:49 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Feb 2000 15:02:49 +0100
Subject: [R] sas.get
In-Reply-To: Douglas Bates's message of "03 Feb 2000 07:33:52 -0600"
References: <3898C79B.CCDF9FF8@scitec.auckland.ac.nz> <6rhffql8an.fsf@franz.stat.wisc.edu>
Message-ID: <x23draqt86.fsf@blueberry.kubism.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> Wayne Stewart <stewart at scitec.auckland.ac.nz> writes:
> 
> > Is there an "R" equivalent of the Splus "sas.get"?

> The foreign package allows reading of SAS data sets in the XPORT
> format.  The XPORT format is standardized across machine architectures
...
> I don't know of any packages to read the general SAS data formats.

...but sas.get also requires that you have a version of SAS around, so
you're not significantly worse off with R. In fact, you're better off
if you have an XPORT file but no SAS!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Feb  3 16:00:14 2000
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 03 Feb 2000 10:00:14 -0500
Subject: [R] Factor Analysis?
In-Reply-To: <200002022301.KAA16223@leonard.anu.edu.au>
Message-ID: <3.0.5.32.20000203100014.00a39100@mcmail.cis.mcmaster.ca>

Dear John,

At 10:01 AM 2/3/2000 +1100, you wrote:
>One could easily get the impression that these sorts of use are almost
>the only ways in which factor analysis that goes beyond principal
>components kinds of uses, and structural equation modelling, are used.
>It is very hard to find examples of the use of these techniques where
>there is some genuine and plausible attempt at model validation.  It
>is also very hard to devise and implement good diagnostic statistics
>and plots.  Such concerns are well articulated in David Freedman's
>paper (with extensive following discussion) "As Others See Us; A Case
>Study in Path Analysis", in J. Educ. Statistics 12: 101-223

I think that Freedman's point is more general, and extends, for example, to regression analysis, even supported by good diagnostics -- he argues generally against drawing causal conclusions from nonexperimental data. Although many of his points are well taken, I find his argument extreme.

>I'd very much like to learn of published examples of the use of
>these methods which do address these concerns.  If these can be
>found, they would be good references to include when and if these
>techniques are implemented.
>

I don't generally think of myself as an advocate of either factor analysis or of structural-equation models, but I recognize that the better practitioners of these methods pay some attention to the descriptive adequacy of their models. Take a look, for example, at Bollen, Structural Equations With Latent Variables (Wiley, 1989) and Bollen and Long, eds., Testing Structural Equation Models (Sage, 1993).

John


|----------------------------------------------------|
| John Fox                          jfox at McMaster.ca |
| Department of Sociology        McMaster University |
|----------------------------------------------------|
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krupa at alpha.sggw.waw.pl  Thu Feb  3 15:58:03 2000
From: krupa at alpha.sggw.waw.pl (Jan Krupa)
Date: Thu, 3 Feb 2000 15:58:03 +0100 (EET)
Subject: [R] How to include TeX formulae in R plots?
In-Reply-To: <38997547.E0CB0B88@est-econ.uc3m.es>
Message-ID: <Pine.LNX.3.96.1000203155440.665A-100000@mel220.sggw.waw.pl>



On Thu, 3 Feb 2000, Alberto [iso-8859-1] Mu?oz wrote:

> Hi, all
> 
> Does anybody know if it is possible to include TeX-style formulae
> in R plots? The aim is to export such plots to LaTeX documents
> using the postscript() device.

You can use different way:
First export plot for R as an (e)ps file and than use
LaTeX psfrag package to add text and formulae. 

Jan
> 
> Many  thanks in advance,
> 
> 
> Alberto Munoz
> 
> 
> ---------------------------------------------------------------------
> Alberto Munoz                       Phone: +34-91- 624 95 79
> Dpto. de Estadistica y Econometria  Fax:   +34-91- 624 98 49
> c/Madrid 126, 28903 Getafe          e-mail: albmun at est-econ.uc3m.es
> Universidad Carlos III de Madrid
> ---------------------------------------------------------------------
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Thu Feb  3 16:31:21 2000
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Thu, 3 Feb 2000 16:31:21 +0100
Subject: [R] sas.get
In-Reply-To: <x23draqt86.fsf@blueberry.kubism.ku.dk>
Message-ID: <001001bf6e5b$b9716940$a9021aac@joelschlaegel>


>...but sas.get also requires that you have a version of SAS around, so
>you're not significantly worse off with R. In fact, you're better off
>if you have an XPORT file but no SAS!

I wasn't aware of that. That's indeed more than just an advantage: Congrats!


Jens

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Feb  3 16:56:18 2000
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 03 Feb 2000 10:56:18 -0500
Subject: [R] questions about image()
Message-ID: <51F9C42DA15CD311BD220008C707D8197A04DB@usrymx10.merck.com>

Hi all,

I have a few questions on color image in R (I'm using 0.90.1 on NT4).

1.  How do I get a color key on the plot?
2.  What I'd like to have is 0=white, 1=red, -1=blue (or any other color),
and numbers in between represented by different shade (e.g., 0.1 would be
light pink, -0.1 would be light blue, etc.).  Is this possible?

Thanks for any help any of you can provide.

Regards,

Andy Liaw
Merck Biometrics Research
Phone: (732) 594-0820
Fax: (732) 594-1565
mailto:andy_liaw at merck.com

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Thu Feb  3 17:30:44 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Thu, 3 Feb 2000 16:30:44 +0000 (GMT)
Subject: [R] How to include TeX formulae in R plots?
In-Reply-To: <38997547.E0CB0B88@est-econ.uc3m.es>
Message-ID: <Pine.LNX.4.10.10002031621190.13886-100000@gimel.biostat.washington.edu>

On Thu, 3 Feb 2000, Alberto [iso-8859-1] Muoz wrote:

> Hi, all
> 
> Does anybody know if it is possible to include TeX-style formulae
> in R plots? The aim is to export such plots to LaTeX documents
> using the postscript() device.
> 

R has a facility for printing expressions as text, which results in quite
a lot of TeX-style functionality.  It's not quite as pretty as TeX, and
it probably won't be using the same fonts as your LaTeX document, but it
is quite easy to use.

There are examples of how to do this in help(text) and help(legend).
There used to be a description in doc/plotmath.tex,but it seems to have
moved.


	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Thu Feb  3 18:56:04 2000
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Thu, 3 Feb 2000 18:56:04 +0100
Subject: [R] How to include TeX formulae in R plots?
In-Reply-To: <Pine.LNX.4.10.10002031621190.13886-100000@gimel.biostat.washington.edu>
Message-ID: <001401bf6e6f$f152e4b0$a9021aac@joelschlaegel>



>There are examples of how to do this in help(text) and help(legend).
>There used to be a description in doc/plotmath.tex,but it seems to have
>moved.

I think some description is now in the Extension Writer's Manual

   doc/manual/R-exts.pdf

Regards


Jens
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From franco at sciences.sdsu.edu  Thu Feb  3 20:00:57 2000
From: franco at sciences.sdsu.edu (Franco Biondi)
Date: Thu, 3 Feb 2000 11:00:57 -0800 (PST)
Subject: [R] Evolutionary spectrum
Message-ID: <200002031900.LAA29926@sciences.sdsu.edu>

Greetings,

I am a new user of R for Windows, and I'd like to ask about any R or S-Plus
routine that can compute the evolutionary spectrum of a time series. 
Any help or pointers are greatly appreciated.
Apologies in advance if this has already been mentioned on the list.

	Regards,
	Franco
------------------------------------------------------------------------
      Franco Biondi

      Biology Department
      Mailcode 4614
      San Diego State University
      San Diego, CA 92182-4614
          E-MAIL: franco at sciences.sdsu.edu
------------------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kurt.Hornik at ci.tuwien.ac.at  Thu Feb  3 20:29:46 2000
From: Kurt.Hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Thu, 3 Feb 2000 20:29:46 +0100 (CET)
Subject: [R] How to include TeX formulae in R plots?
In-Reply-To: <001401bf6e6f$f152e4b0$a9021aac@joelschlaegel>
References: <Pine.LNX.4.10.10002031621190.13886-100000@gimel.biostat.washington.edu>
	<001401bf6e6f$f152e4b0$a9021aac@joelschlaegel>
Message-ID: <14489.55082.217918.887106@aragorn.ci.tuwien.ac.at>

>>>>> =?iso-8859-1?Q?Jens Oehlschl=E4gel-Akiyoshi?= writes:

>> There are examples of how to do this in help(text) and help(legend).
>> There used to be a description in doc/plotmath.tex,but it seems to have
>> moved.

> I think some description is now in the Extension Writer's Manual

>    doc/manual/R-exts.pdf

I'd recommend to wait for Monday when version 0.99.0 is released.  You
can then use ?plotmath to obtained the information ...

-k
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ray.Brownrigg at mcs.vuw.ac.nz  Thu Feb  3 21:24:07 2000
From: Ray.Brownrigg at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Fri, 4 Feb 2000 09:24:07 +1300 (NZDT)
Subject: [R] map() and C++ interface
Message-ID: <200002032024.JAA24673@aqua.mcs.vuw.ac.nz>

For the record, this was my reply to Nokome. The package contains all
the standard Becker & Wilks US databases (usa, county, state), as well
as world, world2 (0 to 360 degrees instead of -180 to 180), nz and
rivers. It also has a world cities database and a few other enhancements
(map.axes, map.scale), but does not do the projections that the S[-Plus]
version does.  This latter, coupled with the fact that the database
format varies with platform, is the reason that I have not submitted it
to CRAN.  [I understand also that Ross Ihaka is working on a rewrite.]

> 1.  I am wanting to produce maps of the New Zealand coastline using R.  I
> am aware of the map function in S-plus and was wondering if anyone had
> ported it to R yet.  I could use the 'world' database for the data source
> but since it is very large I was also wondering if anyone had fine scale
> long and lat data for the NZ coatline.
>
I can help you here.  Go to ftp://ftp.mcs.vuw.ac.nz/pub/statistics/map/
where there is an R package maps_0.1-2_intel.tar.gz (25MB).  This
includes both high- and medium-resolution NZ map databases.  To install,
just type:
R INSTALL maps_0.1-2_intel.tar.gz
(as long as you have R-0.65.1 or better, you do not even need to unpack
the file).

By the way, I am assuming you are using Linux on Intel for R (you don't
actually say).  There is a SPARC version also, but otherwise you may be
stuck for a suitable database format.
 
Ray Brownrigg
Statistical Computing Manager
School of Mathematical and Computing Sciences
Victoria University of Wellington
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paul at stat.auckland.ac.nz  Thu Feb  3 22:17:03 2000
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 4 Feb 2000 10:17:03 +1300
Subject: [R] questions about image()
References: <51F9C42DA15CD311BD220008C707D8197A04DB@usrymx10.merck.com>
Message-ID: <00bb01bf6e8c$0450bc60$175dd882@stat.auckland.ac.nz>

hi


> 1.  How do I get a color key on the plot?


its possible, but you'll have to do it by hand.  take a look at
filled.contour() and see if that does the sort of key you are after.  If so,
look at the filled.contour() code (e.g., by typing "filled.contour<return>")
for an example of how to produce such a key using the layout() and rect()
functions.

if you want a quick, dirty fix, you can piggy-back on the filled.contour()
code.  for example:

data(volcano)
filled.contour(volcano, color = terrain.colors,
                     plot.axes={ image(volcano, add=T,
col=terrain.colors(21));
                                       axis(1); axis(2); })

but you would have to be careful to coordinate the colours used by
filled.contour() and the colours used by image(), and this is not a
long-term solution, and figuring out how it works may be just as much work
as writing your own function :)


> 2.  What I'd like to have is 0=white, 1=red, -1=blue (or any other color),
> and numbers in between represented by different shade (e.g., 0.1 would be
> light pink, -0.1 would be light blue, etc.).  Is this possible?


you can specify an arbitrary range of colours using the rgb() function.  for
example, try

plot(1:10)
points(1:10, col=rgb(10:1/10, rep(0,10), 1:10/10))

or

data(volcano)
image(volcano, col=rgb(10:1/10, rep(0,10), 1:10/10))

hope that is of some help

paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gfeeney at hawaii.edu  Wed Feb  2 21:47:32 2000
From: gfeeney at hawaii.edu (Griffith Feeney)
Date: Wed, 02 Feb 2000 10:47:32 -1000
Subject: [R] "Use a command like x <- vi() to recover"
Message-ID: <3.0.5.32.20000202104732.00871d80@pop-server.hawaii.edu>

Subject command doesn't work with rw0901 running on win95 (of course) so,
after looking at the vi and emacs code, I put

textpad <- function(name = NULL, file = ""){
edit(name, file, editor = "g:\\textpad\\txtpad32.exe")
}

Now

x <- textpad()

brings up the botched code in the textpad editor, as expected, but when I
try to save changes I get an "Access to D:\s3vvkogv was denied" message
from the editor. The only way I've found to recover is to restart R, and
the changes in the edited function are lost. This is a nuisance, to say the
least. Can anyone tell me a better way to handle this?

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ralf.herold at gmx.net  Thu Feb  3 23:17:57 2000
From: ralf.herold at gmx.net (R. Herold)
Date: Thu, 3 Feb 2000 23:17:57 +0100
Subject: [R] Merge?
Message-ID: <000501bf6e95$4271cd00$0100007f@knmnote.charite.de>

I see that feature freeze for a better than ever R has been announced. May I
ask if there will be or could be "merge" function for data frames? I believe
it would be very nice if this were "centrally" implemented (with regard to
my humble steps to writing such a function and the related error and other
precautions). I know from VR2R.pdf (courtesy Profs. Venables and Ripley)
that the "Functions crosstabs [...], by and merge [...] do not exist in R.",
but perhaps someone can suggest such a merge function, just as a "by"
function was suggested by Peter Dalgaard on 31. January?

Thank You, Ralf Herold

# Charite Campus Virchow-Klinikum
# Medizinische Fakultaet der Humboldt-Universitaet
# Augustenburger Platz 1, D-13353 Berlin
# ralf.herold at charite.de  pgp welcome

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Feb  3 23:33:32 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Feb 2000 23:33:32 +0100
Subject: [R] "Use a command like x <- vi() to recover"
In-Reply-To: Griffith Feeney's message of "Wed, 02 Feb 2000 10:47:32 -1000"
References: <3.0.5.32.20000202104732.00871d80@pop-server.hawaii.edu>
Message-ID: <x2ematykzn.fsf@blueberry.kubism.ku.dk>

Griffith Feeney <gfeeney at hawaii.edu> writes:

> Subject command doesn't work with rw0901 running on win95 (of course) so,
> after looking at the vi and emacs code, I put
> 
> textpad <- function(name = NULL, file = ""){
> edit(name, file, editor = "g:\\textpad\\txtpad32.exe")
> }
> 
> Now
> 
> x <- textpad()

Um, yes, that error message would be better as "use a command like x
<- edit()", especially in the upcoming R where edit() will call up
getOption("editor"). And in windows that would give you the Notepad
(for better or worse...).

> brings up the botched code in the textpad editor, as expected, but when I
> try to save changes I get an "Access to D:\s3vvkogv was denied" message
> from the editor. The only way I've found to recover is to restart R, and
> the changes in the edited function are lost. This is a nuisance, to say the
> least. Can anyone tell me a better way to handle this?

I've seen similar effects with W9x processes apparently fighting over
a file in ways that wouldn't happen on Unix. Looks like textpad
says that R is holding the file open. (I believe it was editing the
Rprofile with R running that turned out to be taboo for me at some
point). 

A fairly obvious workaround is to save the edited file to another name
and then source that into R (or x <- edit(file="c:\\whatever").

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From William.Venables at cmis.CSIRO.AU  Fri Feb  4 00:13:05 2000
From: William.Venables at cmis.CSIRO.AU (Bill Venables)
Date: Fri, 04 Feb 2000 09:13:05 +1000
Subject: [R] Re: your mail 
In-Reply-To: Your message of "Thu, 03 Feb 2000 10:13:23 +0100."
             <200002030913.KAA25484@alpha.luc.ac.be> 
Message-ID: <200002032313.KAA29968@snowy.nsw.cmis.CSIRO.AU>

OK, this is not R, but my curiosity has got the better of me.

> > On Wed, 2 Feb 2000, Adriane Leal wrote:
> > 
> > > I'd like to perform a box-cox transformation to a data set and also plot
> > > lambda versus L(lambda) using R. Does anybody knows how can I do such a
> > > thing? 
> 
> gnlr3 in my gnlm library does both linear and nonlinear models with
> Box-Cox transformation. 

I'm really curious to know why you would want to do a box-cox
transformation model on top of a non-linear model.

It seems to me linear models are often used as a local,
investigative tool and the box-cox transformation is really an
extension of this aspect of linear models to look for a scale of
measurement where some sort of simplicity of structure is
apparent, like homogeneity of variance, additivity and so on.

By contrast I regard non-linear models as appropriate where the
investigative phase is well and truly over.  I would never fit a
non-linear model unless I had some pretty clear idea that it was
going to be appropriate, preferably with a solid theory behind
it, beginning with the scale of measurement.  If you need to hunt
around for a scale of measurement in which your non-linear model
looks reasonable, I become very skeptical about whether there was
any solid basis for a specific non-linear model in the first 
place.

I must admit, though, I have seen papers on fitting box-cox
transformed non-linear models before (at least in tech report
form) so am I missing something?  Does anyone have a good example
of where a box-cox transformed non-linear model is clearly an
appropriate thing to use?

> However, it is somewhat nonstandard as it
> renormalizes to obtain a true density whereas the standard
> transformation creates a function that is not a density because of the
> constraint that only positive values can be transformed but the normal
> distribution is on the whole real line. Jim

Again, under my contention that box-cox transformed models are
largely investigative tools, I wonder if this refinement is going
to pay off very much.

Brian Ripley wrote the first version of our box-cox and I did
some fiddling with it to make it a bit slicker.  At the time I
thought about this kind of extension but decided against any on
the grounds (a) that I could not see much use for them and (b)
they could send the wrong message to users.  I have to say I
still think so.

-- 
Bill Venables,      Statistician,     CMIS Environmetrics Project
CSIRO Marine Labs, PO Box 120, Cleveland, Qld,  AUSTRALIA.   4163
Tel: +61 7 3826 7251           Email: Bill.Venables at cmis.csiro.au    
Fax: +61 7 3826 7304      http://www.cmis.csiro.au/bill.venables/



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From john.maindonald at anu.edu.au  Fri Feb  4 01:33:37 2000
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 4 Feb 2000 11:33:37 +1100 (EST)
Subject: [R] Factor Analysis?
Message-ID: <200002040033.LAA22325@leonard.anu.edu.au>

John Fox wrote

> Dear John,

> At 10:01 AM 2/3/2000 +1100, you wrote:

> >One could easily get the impression that these sorts of use are
> >almost the only ways in which factor analysis that goes beyond
> >principal components kinds of uses, and structural equation
> >modelling, are used.  It is very hard to find examples of the use
> >of these techniques where there is some genuine and plausible
> >attempt at model validation.  It is also very hard to devise and
> >implement good diagnostic statistics and plots.  Such concerns are
> >well articulated in David Freedman's paper (with extensive
> >following discussion) "As Others See Us; A Case Study in Path
> >Analysis", in J. Educ. Statistics 12: 101-223

> I think that Freedman's point is more general, and extends, for
  example, to regression analysis, even supported by good diagnostics
  -- he argues generally against drawing causal conclusions from
  nonexperimental data. Although many of his points are well taken, I
  find his argument extreme.

Thanks for that comment.

The arrow surely goes in the other direction.  The points which
Freedman makes on regression in his "Statistical Analysis and Shoe
Leather" paper (Sociological Methodology 1991, pp. 291-358) apply also
to Path Analysis, Structural Equation Modelling, etc.  There are
however additional points to be made, which have to do with the near
impossibility of checking empirically the hidden relationships that
are assumed.  

Freedman does sometimes get extreme.  I do not think it is fair to say
that he rules out the drawing of causal conclusions from
non-experimental data.  Rather I understand his argument to be that
the data on its own, however analysed, are not enough.  There is
extensive contextual information which, as he illustrates from John
Snow's work on the spread of cholera in the mid-19th C in London, has
to come together with the data.  In Path Analysis, Structural Equation
Modelling etc., one has to be very sure of the contextual information
(what are are paths?  what direction do they go?) for the analytic
results to have any credence.  This is in a context where the
statistical assumptions, on variables that are mostly hidden, readily
get out of hand.

> >I'd very much like to learn of published examples of the use of
> >these methods which do address these concerns.  If these can be
> >found, they would be good references to include when and if these
> >techniques are implemented.

> I don't generally think of myself as an advocate of either factor
  analysis or of structural-equation models, but I recognize that the
  better practitioners of these methods pay some attention to the
  descriptive adequacy of their models. Take a look, for example, at
  Bollen, Structural Equations With Latent Variables (Wiley, 1989) and
  Bollen and Long, eds., Testing Structural Equation Models (Sage,
  1993).

> John
> 
> 
> |----------------------------------------------------|
> | John Fox                          jfox at McMaster.ca |
> | Department of Sociology        McMaster University |
> |----------------------------------------------------|
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-

I guess if this discussion is to continue, it might be well for it to
continue off-list.  It is well for list members to be aware that there
are issues here to consider.  One service that R may perform is to bring
together communities of statisticians and statistical users which have
become too largely separate.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb  4 09:09:38 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 4 Feb 2000 08:09:38 +0000 (GMT)
Subject: [R] Merge?
In-Reply-To: <000501bf6e95$4271cd00$0100007f@knmnote.charite.de>
Message-ID: <Pine.GSO.4.05.10002040803420.10301-100000@auk.stats>

On Thu, 3 Feb 2000, R. Herold wrote:

> I see that feature freeze for a better than ever R has been announced. May I
> ask if there will be or could be "merge" function for data frames? I believe

Not for 0.99.0 due on Monday.

> it would be very nice if this were "centrally" implemented (with regard to
> my humble steps to writing such a function and the related error and other
> precautions). I know from VR2R.pdf (courtesy Profs. Venables and Ripley)
> that the "Functions crosstabs [...], by and merge [...] do not exist in R.",
> but perhaps someone can suggest such a merge function, just as a "by"
> function was suggested by Peter Dalgaard on 31. January?

VR2R.* was frozen last August and will not be updated (it complements an
obselete edition). VR3R.* is kept up to date.

Yes, versions of `by' and `merge' would be a good idea. We now have
`ftable' that does some of the crosstabs functionality.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jonathan.Yuen at evp.slu.se  Fri Feb  4 09:20:22 2000
From: Jonathan.Yuen at evp.slu.se (Jonathan.Yuen@evp.slu.se)
Date: Fri, 4 Feb 2000 09:20:22 +0100 (MET)
Subject: [R] sas data sets
In-Reply-To: <6rhffql8an.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.A41.4.05.10002040915080.13036-100000@kilauea.evp.slu.se>

On 3 Feb 2000, Douglas Bates wrote:

> I don't know of any packages to read the general SAS data formats.

SAS can't even do this itself!!  There are a number of different
'internal' data formats for SAS (I currently use Wintel, AIX, and DEC) and
they aren't compatible with each other.  One of the main uses of the
export files (I use proc cport/cimport) is to move the data from one SAS
environment to another.

I do have a vague memory of things that could at least read the wintel
data sets...

I haven't had a chance to try, but how does R do cross platform?

Jonathan

Jonathan Yuen, Professor in Plant Pathology     phone: 46 18 672369
Dept. of Ecology and Crop Production Sciences   fax:   46 18 672890
Swedish University of Agricultural Sciences     http://www.tvs.slu.se
Box 7043                                        email replies to
S 750 07 Uppsala, SWEDEN                        Jonathan.Yuen at evp.slu.se 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yudi at stat.ucc.ie  Fri Feb  4 12:27:25 2000
From: yudi at stat.ucc.ie (yudi@stat.ucc.ie)
Date: Fri, 04 Feb 2000 11:27:25 +0000
Subject: [R] filled tesselation
Message-ID: <01JLIAVNGOG20024GX@CCSERV.UCC.IE>


The wonderful filled.contour() function gives me some
hope that somebody (Ross?) has some advice for this 
problem: how can I fill the Dirichlet tesselation with 
possibly different colours  (determined by the value
on the node)?

-Yudi-

------------------------------
Yudi Pawitan: yudi at stat.ucc.ie
Department of Statistics, UCC
Cork, Ireland
Ph : 353-21-902 906
Fax: 353-21-271 040
------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Fri Feb  4 12:30:42 2000
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Fri, 4 Feb 2000 12:30:42 +0100 (MET)
Subject: [R] Re: your mail
In-Reply-To: <200002032313.KAA29968@snowy.nsw.cmis.CSIRO.AU> from "Bill Venables" at Feb 04, 2000 09:13:05 AM
Message-ID: <200002041130.MAA23962@alpha.luc.ac.be>


> 
> OK, this is not R, but my curiosity has got the better of me.
> 
> > > On Wed, 2 Feb 2000, Adriane Leal wrote:
> > > 
> > > > I'd like to perform a box-cox transformation to a data set and also plot
> > > > lambda versus L(lambda) using R. Does anybody knows how can I do such a
> > > > thing? 
> > 
> > gnlr3 in my gnlm library does both linear and nonlinear models with
> > Box-Cox transformation. 
> 
> I'm really curious to know why you would want to do a box-cox
> transformation model on top of a non-linear model.

The Weibull distribution is a Box-Cox transform of an exponential
distribution and no one complains that it isn't a useful distribution.
Viewed as a distinct three-parameter distribution (when renormalized
as I do), Box-Coxed normal is as useful as the generalized gamma,
etc. For example, it allows one to distinguish parametrically between
normal and log normal. So I thought it was worth including and doing
correctly.

> 
> It seems to me linear models are often used as a local,
> investigative tool and the box-cox transformation is really an
> extension of this aspect of linear models to look for a scale of
> measurement where some sort of simplicity of structure is
> apparent, like homogeneity of variance, additivity and so on.
> 
> By contrast I regard non-linear models as appropriate where the
> investigative phase is well and truly over.  I would never fit a
> non-linear model unless I had some pretty clear idea that it was
> going to be appropriate, preferably with a solid theory behind
> it, beginning with the scale of measurement.  If you need to hunt
> around for a scale of measurement in which your non-linear model
> looks reasonable, I become very skeptical about whether there was
> any solid basis for a specific non-linear model in the first 
> place.

I am afraid that is not the way it works in PK. Kineticists want to
compare different compartment models. They would never dream of
investigating with linear models. My experience is the same in other
areas where nonlinear mechanistic models are used.

This is no more or less a question of scale of measurement than it is
for the Weibull.

> 
> I must admit, though, I have seen papers on fitting box-cox
> transformed non-linear models before (at least in tech report
> form) so am I missing something?  Does anyone have a good example
> of where a box-cox transformed non-linear model is clearly an
> appropriate thing to use?

Except in chemistry (bioassays), I have no direct experience anywhere
where normal distributions (previously transformed to normality or
not) are appropriate. So I don't have any examples. My personal
private opinion is that the Box-Cox transformation is a thing of the
1960s and should be quickly and quietly forgotten.

> 
> > However, it is somewhat nonstandard as it
> > renormalizes to obtain a true density whereas the standard
> > transformation creates a function that is not a density because of the
> > constraint that only positive values can be transformed but the normal
> > distribution is on the whole real line. Jim
> 
> Again, under my contention that box-cox transformed models are
> largely investigative tools, I wonder if this refinement is going
> to pay off very much.

It certainly makes a difference to the resulting transformation in the
cases I have tried. Jim

> 
> Brian Ripley wrote the first version of our box-cox and I did
> some fiddling with it to make it a bit slicker.  At the time I
> thought about this kind of extension but decided against any on
> the grounds (a) that I could not see much use for them and (b)
> they could send the wrong message to users.  I have to say I
> still think so.
> 
> -- 
> Bill Venables,      Statistician,     CMIS Environmetrics Project
> CSIRO Marine Labs, PO Box 120, Cleveland, Qld,  AUSTRALIA.   4163
> Tel: +61 7 3826 7251           Email: Bill.Venables at cmis.csiro.au    
> Fax: +61 7 3826 7304      http://www.cmis.csiro.au/bill.venables/
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bond at graylab.ac.uk  Fri Feb  4 15:05:35 2000
From: bond at graylab.ac.uk (Simon  Bond)
Date: Fri, 04 Feb 2000 14:05:35 +0000
Subject: [R] font size for pairs()
Message-ID: <3.0.6.32.20000204140535.007c0b70@graylab.ac.uk>

Dear R-Help,

I'm having some trouble with the font size in the pairs() function. It
seems to be impossible to alter the font size for the variable labels that
run down the diagonal. I've tried all the cex.??? parameters to no avail.

I'm using R0.65.0 on windowsNT. If the simple answer is to upgrade to the
latest version of R, then please accept my humble apologies for troubling you.


Simon Bond.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Feb  4 15:52:07 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Feb 2000 08:52:07 -0600
Subject: Cross-platform saves [was Re: [R] sas data sets]
In-Reply-To: Jonathan.Yuen@evp.slu.se's message of "Fri, 4 Feb 2000 09:20:22 +0100 (MET)"
References: <Pine.A41.4.05.10002040915080.13036-100000@kilauea.evp.slu.se>
Message-ID: <6raelh2f6w.fsf@franz.stat.wisc.edu>

Jonathan.Yuen at evp.slu.se writes:

> On 3 Feb 2000, Douglas Bates wrote:
> 
> > I don't know of any packages to read the general SAS data formats.
> 
> SAS can't even do this itself!!  There are a number of different
> 'internal' data formats for SAS (I currently use Wintel, AIX, and DEC) and
> they aren't compatible with each other.  One of the main uses of the
> export files (I use proc cport/cimport) is to move the data from one SAS
> environment to another.
> 
> I do have a vague memory of things that could at least read the wintel
> data sets...
> 
> I haven't had a chance to try, but how does R do cross platform?

There is an R ASCII save format that can be used to transport R
objects across architectures.  See
 help(save)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb  4 16:10:38 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 4 Feb 2000 15:10:38 +0000 (GMT)
Subject: [R] font size for pairs()
In-Reply-To: <3.0.6.32.20000204140535.007c0b70@graylab.ac.uk>
Message-ID: <Pine.GSO.4.05.10002041503220.1032-100000@auk.stats>

On Fri, 4 Feb 2000, Simon  Bond wrote:

> Dear R-Help,
> 
> I'm having some trouble with the font size in the pairs() function. It
> seems to be impossible to alter the font size for the variable labels that
> run down the diagonal. I've tried all the cex.??? parameters to no avail.

I think you just need to modify the function pairs.default to something
like

function (x, labels, panel = points, main = NULL, font.main =
par("font.main"), 
    cex.main = par("cex.main"), cex.labels= par("cex"), ...) 
....
            text(mean(par("usr")[1:2]), mean(par("usr")[3:4]), 
                labels[i], cex=cex.labels)
....

I see S-PLUS computes the cex from the number if plots, and I suspect
we should consider a better default. pairs(USJudgeRatings[, 1:3])
looks pretty silly.

> I'm using R0.65.0 on windowsNT. If the simple answer is to upgrade to the
> latest version of R, then please accept my humble apologies for troubling you.

Well, all the font sizes have been altered since then, but with 0.99.0
imminent you might want to wait for that before upgrading.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Feb  4 16:38:55 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 04 Feb 2000 16:38:55 +0100
Subject: [R] font size for pairs()
In-Reply-To: Prof Brian D Ripley's message of "Fri, 4 Feb 2000 15:10:38 +0000 (GMT)"
References: <Pine.GSO.4.05.10002041503220.1032-100000@auk.stats>
Message-ID: <x2zoth6kq8.fsf@blueberry.kubism.ku.dk>

Prof Brian D Ripley <ripley at stats.ox.ac.uk> writes:

> I see S-PLUS computes the cex from the number if plots, and I suspect
> we should consider a better default. pairs(USJudgeRatings[, 1:3])
> looks pretty silly.

Boldfacing the labels would likely look neat too. Perhaps use largest
font size that allow all labels to fit inside box (or 90% of it)? 

Post 0.99 stuff though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb  4 16:52:14 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 4 Feb 2000 15:52:14 +0000 (GMT Standard Time)
Subject: Cross-platform saves [was Re: [R] sas data sets]
In-Reply-To: <6raelh2f6w.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.WNT.4.05.10002041546310.97-100000@tern.stats>

On 4 Feb 2000, Douglas Bates wrote:

> Jonathan.Yuen at evp.slu.se writes:
> 
> > I haven't had a chance to try, but how does R do cross platform?
> 
> There is an R ASCII save format that can be used to transport R
> objects across architectures.  See
>  help(save)

However, on almost all platforms (even Windows), R uses xdr for its binary
saves, and so is platform-independent.  It certainly works across Windows,
i686-linux and sparc-solaris, and they cover both endian conventions.

(SAS predates xdr and indeed common floating point formats, maybe
floating-point formats, period.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pete at seul.org  Fri Feb  4 17:30:39 2000
From: pete at seul.org (Pete St. Onge)
Date: Fri, 04 Feb 2000 11:30:39 -0500
Subject: [R] MA / RMA / Type II regression?
Message-ID: <389AFEAF.EDEB0039@seul.org>

For starters, let me say again how impressive R is, and how all of the
effort that has gone into R shines through clearly. It is an amazing
program, and I am frequently pleasantly surprised to find out how powerful
and capable R is. Finding the interface to xgobi is the latest pleasant
surprise.

Are there functions in R for Major Axis and Reduced Major Axis regression? I
have OBS-RESID graphs of two of my regressions showing a linear increasing
trend, indicating the inappropriate use of Type I regression; I upgraded to
R 0.90.1 and after looking through the help pages, didn't see anything that
seemed what I needed. LQS didn't quite seem what I was looking for.

Any pointers are greatly appreciated.

Thanks,

Pete

-- 
Pete St. Onge - McGill U.  Limnology - Fun with Ropes & Buckets
pete at seul.org                  http://wwp.mirabilis.com/4322052
---------------------------------------------------------------
SEUL - Linux for All!                       http://www.seul.org
Programming For Science Page        http://www.trentu.ca/~erpds
  1 9   A p r i l   1 9 9 9  -  V I N D I C A T I O N   D A Y

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Feb  4 17:50:11 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 04 Feb 2000 17:50:11 +0100
Subject: [R] MA / RMA / Type II regression?
In-Reply-To: "Pete St. Onge"'s message of "Fri, 04 Feb 2000 11:30:39 -0500"
References: <389AFEAF.EDEB0039@seul.org>
Message-ID: <x2u2jo7vzw.fsf@blueberry.kubism.ku.dk>

"Pete St. Onge" <pete at seul.org> writes:

> Are there functions in R for Major Axis and Reduced Major Axis regression? I
> have OBS-RESID graphs of two of my regressions showing a linear increasing
> trend, indicating the inappropriate use of Type I regression; I upgraded to
> R 0.90.1 and after looking through the help pages, didn't see anything that
> seemed what I needed. LQS didn't quite seem what I was looking for.

(What is MA/RMA regression? I don't know them, not by that name
anyway.) I hope you plotted FIT vs. residuals there and not really OBS
vs. resid. The latter are well-known to generate apparent linear
relations when none is in fact present, especially when the original
relation is weak, as in.

x<-rnorm(20)
y<-0.01*x + rnorm(20)
plot(y ,residuals(lm(y~x)))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pete at seul.org  Fri Feb  4 18:30:44 2000
From: pete at seul.org (Pete St. Onge)
Date: Fri, 04 Feb 2000 12:30:44 -0500
Subject: [R] MA / RMA / Type II regression?
References: <389AFEAF.EDEB0039@seul.org> <x2u2jo7vzw.fsf@blueberry.kubism.ku.dk>
Message-ID: <389B0CC4.DFA74BA2@seul.org>

> (What is MA/RMA regression? I don't know them, not by that name
> anyway.)
     Major Axis and Reduced Major Axis are the terms, and Geometric Mean
(GM) regression is also sometimes used, if I remember correctly. My
understanding in the latter is that it minimizes the squares of both the
horizontal and vertical distances from the regression line, and thus do not
impart any particular 'accuracy' to the predictor variable. If I'm not
completely wrong, the slope of the GM regression of Y on X should be the
inverse of the GM regression of X on Y.

This regression technique seems to be seldom used in the ecological
literature, even though there seems to be frequently error in the predictor
variable (eg. roundoff and measurement error in watershed size estimates
based on map data, etc). I've yet to see it in the mainstream stats
packages, and only know of the technique through two papers, both from the
same author. The primary paper is:

Ricker, W.E. 1973. Linear regressions in fishery research. Journal of the
Fisheries Research Board of Canada. 30:409-434.

MA is not so much a regression, according to this paper, but rather the
major axis of the corellation ellipse (assuming equal scales in the X and Y
axes).

> I hope you plotted FIT vs. residuals there and not really OBS
> vs. resid. The latter are well-known to generate apparent linear
> relations when none is in fact present, especially when the original
> relation is weak, as in.
> 
> x<-rnorm(20)
> y<-0.01*x + rnorm(20)
> plot(y ,residuals(lm(y~x)))

Actually, I did in fact plot the fitted data versus the residuals as well,
and see no pattern in the residuals. There is considerable scatter, so the
relationships are weak (but significant nonetheless). However, the same
trend in the OBS-RESID graphs is seen in three data series (nutrient export
as a function of catchment size, in three treatments), hence my concern
about type I vs type II regression.

Like I said, I've yet to see these technique in any statistics package, and
was wondering if this already existed within R. If it doesn't yet, then I
should be easily able to calculate it using these formulas and other R
functions, or at worse hacking the lm function to do the GM univariate
regression (I don't see any details / suggestions for the use of 
GM regression on multivariate data). One this would be done, I wonder if it
should be possible to use anova to compare two different GM lines.

To this end, any ideas or suggestions are appreciated.

Thanks,

Pete

-- 
Pete St. Onge - McGill U.  Limnology - Fun with Ropes & Buckets
pete at seul.org                  http://wwp.mirabilis.com/4322052
---------------------------------------------------------------
SEUL - Linux for All!                       http://www.seul.org
Programming For Science Page        http://www.trentu.ca/~erpds
  1 9   A p r i l   1 9 9 9  -  V I N D I C A T I O N   D A Y
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb  4 19:31:06 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 4 Feb 2000 18:31:06 +0000 (GMT)
Subject: [R] MA / RMA / Type II regression?
In-Reply-To: <389B0CC4.DFA74BA2@seul.org>
Message-ID: <Pine.GSO.4.05.10002041826370.1547-100000@auk.stats>

On Fri, 4 Feb 2000, Pete St. Onge wrote:

> > (What is MA/RMA regression? I don't know them, not by that name
> > anyway.)
>      Major Axis and Reduced Major Axis are the terms, and Geometric Mean
> (GM) regression is also sometimes used, if I remember correctly. My
> understanding in the latter is that it minimizes the squares of both the
> horizontal and vertical distances from the regression line, and thus do not
> impart any particular 'accuracy' to the predictor variable. If I'm not
> completely wrong, the slope of the GM regression of Y on X should be the
> inverse of the GM regression of X on Y.

Well, it assumes equal accuracies of x and y.  The sum of squares
of horizontal and vertical distances i just Euclidean distance^2 to the 
projection on to the line, so this is just PCA. Use  princomp and
take the first principal component.

> This regression technique seems to be seldom used in the ecological
> literature, even though there seems to be frequently error in the predictor
> variable (eg. roundoff and measurement error in watershed size estimates
> based on map data, etc). I've yet to see it in the mainstream stats
> packages, and only know of the technique through two papers, both from the
> same author. The primary paper is:
> 
> Ricker, W.E. 1973. Linear regressions in fishery research. Journal of the
> Fisheries Research Board of Canada. 30:409-434.
> 
> MA is not so much a regression, according to this paper, but rather the
> major axis of the corellation ellipse (assuming equal scales in the X and Y
> axes).

More accurately the covariance ellipse.

There are lots of related things under names like functional relationships
and structural relationships, so this is almost certainly in Fuller's
of Seber's or Sprent's books.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From denis at mail.cor.epa.gov  Fri Feb  4 23:38:29 2000
From: denis at mail.cor.epa.gov (Denis White)
Date: Fri, 4 Feb 2000 14:38:29 -0800 (PST)
Subject: [R] terminating plot
Message-ID: <Pine.SUN.3.91.1000204143357.15511F-100000@okapi.cor.epa.gov>

This script (in Version 0.90.1 [Solaris]):

  postscript (file="test.eps",onefile=F)
  par (mfrow=c(3,1))
  plot (1:10,rep(1,10))
  plot (1:10,rep(1,10))
  plot (1:10,rep(1,10))
  frame()

does not terminate the plot.  Rather it gives the message:

  Warning message: 
  multiple pages used in postscript() with onefile=FALSE 

and the plot is only complete after quitting R.

Is there some other way to complete a plot?

thanks
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Feb  4 23:52:37 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 04 Feb 2000 23:52:37 +0100
Subject: [R] terminating plot
In-Reply-To: Denis White's message of "Fri, 4 Feb 2000 14:38:29 -0800 (PST)"
References: <Pine.SUN.3.91.1000204143357.15511F-100000@okapi.cor.epa.gov>
Message-ID: <x2bt5wtway.fsf@blueberry.kubism.ku.dk>

Denis White <denis at mercury.cor.epa.gov> writes:

> This script (in Version 0.90.1 [Solaris]):
> 
>   postscript (file="test.eps",onefile=F)
>   par (mfrow=c(3,1))
>   plot (1:10,rep(1,10))
>   plot (1:10,rep(1,10))
>   plot (1:10,rep(1,10))
>   frame()
> 
> does not terminate the plot.  Rather it gives the message:
> 
>   Warning message: 
>   multiple pages used in postscript() with onefile=FALSE 
> 
> and the plot is only complete after quitting R.
> 
> Is there some other way to complete a plot?

dev.off() will flush the output buffer and close the file. Don't use
frame() since that tells you to start a new page, and with onefile=F
you cannot have that.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fredrik.lundgren at norrkoping.mail.telia.com  Sat Feb  5 00:19:22 2000
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Sat, 5 Feb 2000 00:19:22 +0100
Subject: [R] Import files?
Message-ID: <000201bf6f66$7d8552a0$8bc643c3@oemcomputer>

Hello,
How can SPSS files be imported?
Fredrik Lundgren
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000205/8cae3890/attachment.html

From mlamias at isr.umich.edu  Sat Feb  5 02:28:07 2000
From: mlamias at isr.umich.edu (Mark Lamias)
Date: Fri, 4 Feb 2000 20:28:07 -0500 
Subject: [R] Import files?
Message-ID: <5D28BEE5CAE8D1119F5700A0C9B4268E02E5D115@isr.umich.edu>

>Hello,
>How can SPSS files be imported?
>Fredrik Lundgren
 
If you are working with only a few SPSS datasets, I think the easiest thing
to do is to save the SPSS dataset as a tab-delimited (.dat) file, and then
read in the tab-delimited dataset using the usual read.table command.

Mark J. Lamias
Department of Statistics
Department of Political Science
Survey Methodology Program/Survey Research Center 
Institute for Social Research - University of Michigan 
426 Thompson Street, Room 315 
Ann Arbor, Michigan 48104-2321 
(734) 647-5381 

 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chong at stat.purdue.edu  Sat Feb  5 03:32:25 2000
From: chong at stat.purdue.edu (Chong Gu)
Date: Fri, 4 Feb 2000 21:32:25 -0500
Subject: [R] terminating plot
In-Reply-To: <Pine.SUN.3.91.1000204143357.15511F-100000@okapi.cor.epa.gov>
	(message from Denis White on Fri, 4 Feb 2000 14:38:29 -0800 (PST))
Message-ID: <200002050232.VAA71226@mean.stat.purdue.edu>

   Date: Fri, 4 Feb 2000 14:38:29 -0800 (PST)
   From: Denis White <denis at mercury.cor.epa.gov>
   MIME-Version: 1.0
   Content-Type: TEXT/PLAIN; charset=US-ASCII
   Sender: owner-r-help at stat.math.ethz.ch
   Precedence: bulk

   This script (in Version 0.90.1 [Solaris]):

     postscript (file="test.eps",onefile=F)
     par (mfrow=c(3,1))
     plot (1:10,rep(1,10))
     plot (1:10,rep(1,10))
     plot (1:10,rep(1,10))
     frame()

   does not terminate the plot.  Rather it gives the message:

     Warning message: 
     multiple pages used in postscript() with onefile=FALSE 

   and the plot is only complete after quitting R.

   Is there some other way to complete a plot?

   thanks
   -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
   r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
   Send "info", "help", or "[un]subscribe"
   (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
   _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


dev.off()
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bitwrit at ozemail.com.au  Sat Feb  5 11:29:42 2000
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sat, 05 Feb 2000 21:29:42 +1100
Subject: [R] Import files?
Message-ID: <389BFB96.BB7E9122@ozemail.com.au>

Mark's suggestion

>If you are working with only a few SPSS datasets, I think the easiest
thing
>to do is to save the SPSS dataset as a tab-delimited (.dat) file, and
then
>read in the tab-delimited dataset using the usual read.table command.

is the one I use, but make sure that you get rid of unwanted spaces in
the
file (using 'tr' or similar), or you often get factors instead of
numeric
variables out the other end.

Jim

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Sat Feb  5 14:39:49 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 05 Feb 2000 07:39:49 -0600
Subject: [R] Import files?
In-Reply-To: Mark Lamias's message of "Fri, 4 Feb 2000 20:28:07 -0500"
References: <5D28BEE5CAE8D1119F5700A0C9B4268E02E5D115@isr.umich.edu>
Message-ID: <6r3dr7kbtm.fsf@franz.stat.wisc.edu>

Mark Lamias <mlamias at isr.umich.edu> writes:

> >Hello,
> >How can SPSS files be imported?
> >Fredrik Lundgren
>  
> If you are working with only a few SPSS datasets, I think the easiest thing
> to do is to save the SPSS dataset as a tab-delimited (.dat) file, and then
> read in the tab-delimited dataset using the usual read.table command.

One of the SPSS save formats is described in the documentation for
PSPP, a freely-available SPSS clone (see http://pspp.stat.wisc.edu/).
GPL'd code to parse that format is included in PSPP.  It seems that it
would not be overly difficult to modify that code for the `foreign'
package but I can't guarantee when I will have time to work on doing
so.  If someone who has a more pressing need wanted to contribute
modifications of that code for R, I would be delighted.  For details
on R internal structures see the document Writing R Extensions,
included in the doc/manual directory of R-0.99.0 as R-exts.texi from
which can be produced PDF, info or dvi formats.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From h0444idm at rz.hu-berlin.de  Sat Feb  5 15:30:25 2000
From: h0444idm at rz.hu-berlin.de (Tino Reinhardt)
Date: Sat, 5 Feb 2000 15:30:25 +0100 (MET)
Subject: [R] command-line editing
Message-ID: <200002051430.PAA03700@amor.rz.hu-berlin.de>

hello,
I've had compiled Version 0.90.1  (December 15, 1999) on an i586
running GNU/Linux (RedHat 5.2-patched with 6.* pieces) last night.
Everything seems to work fine but it's impossible to use command-line
editing (on the linuxconsole, xterm, rxvt). It just looks like

> a <- 1
> ^[[A^[[A^[[A
after pressing arrow-up, left or right

On the console i've got	$ echo $TERM linux-lat
an in X			$ echo $TERM	xterm

Did I forgot something whilst compiling? More info needed?
Thanks for any help. Tino
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Sat Feb  5 21:37:50 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Sat, 5 Feb 2000 20:37:50 +0000 (GMT)
Subject: [R] command-line editing
In-Reply-To: <200002051430.PAA03700@amor.rz.hu-berlin.de>
Message-ID: <Pine.LNX.4.10.10002052028460.8839-100000@gimel.biostat.washington.edu>

On Sat, 5 Feb 2000, Tino Reinhardt wrote:

> hello,
> I've had compiled Version 0.90.1  (December 15, 1999) on an i586
> running GNU/Linux (RedHat 5.2-patched with 6.* pieces) last night.
> Everything seems to work fine but it's impossible to use command-line
> editing (on the linuxconsole, xterm, rxvt). It just looks like
> 
> > a <- 1
> > ^[[A^[[A^[[A
> after pressing arrow-up, left or right
> 
> On the console i've got	$ echo $TERM linux-lat
> an in X			$ echo $TERM	xterm
> 
> Did I forgot something whilst compiling? More info needed?


You probably don't have GNU readline or its header files installed.

If you have the library (libreadline.so) then look
in config.cache for the lines
 ac_cv_header_readline_history_h=${ac_cv_header_readline_history_h=yes}
 ac_cv_header_readline_readline_h=${ac_cv_header_readline_readline_h=yes}
or
 ac_cv_header_readline_history_h=${ac_cv_header_readline_history_h=no}
 ac_cv_header_readline_readline_h=${ac_cv_header_readline_readline_h=no}

If you have the =no version then ./configure couldn't find the headers, so
you probably need to install them. They should be on the Red Hat
distribution.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Feb  6 00:26:20 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Feb 2000 00:26:20 +0100
Subject: [R] command-line editing
In-Reply-To: Thomas Lumley's message of "Sat, 5 Feb 2000 20:37:50 +0000 (GMT)"
References: <Pine.LNX.4.10.10002052028460.8839-100000@gimel.biostat.washington.edu>
Message-ID: <x2og9vut7n.fsf@blueberry.kubism.ku.dk>

Thomas Lumley <thomas at biostat.washington.edu> writes:

> On Sat, 5 Feb 2000, Tino Reinhardt wrote:
> 
> > hello,
> > I've had compiled Version 0.90.1  (December 15, 1999) on an i586
> > running GNU/Linux (RedHat 5.2-patched with 6.* pieces) last night.
> > Everything seems to work fine but it's impossible to use command-line
> > editing (on the linuxconsole, xterm, rxvt). It just looks like
> > 
> > > a <- 1
> > > ^[[A^[[A^[[A
> > after pressing arrow-up, left or right
....
> You probably don't have GNU readline or its header files installed.
> 
> If you have the library (libreadline.so) then look
> in config.cache for the lines
>  ac_cv_header_readline_history_h=${ac_cv_header_readline_history_h=yes}
>  ac_cv_header_readline_readline_h=${ac_cv_header_readline_readline_h=yes}
> or
>  ac_cv_header_readline_history_h=${ac_cv_header_readline_history_h=no}
>  ac_cv_header_readline_readline_h=${ac_cv_header_readline_readline_h=no}
> 
> If you have the =no version then ./configure couldn't find the headers, so
> you probably need to install them. They should be on the Red Hat
> distribution.

Somewhere in the back of my mind sits a recollection that there's a
version problem, that we require a newer readline than shipped in
RH5.2. In redhat 6.1 we have 2.2.1 and that works but I suspect 2.0
will not do the callback method we use in the console handler.

Also note that you need the readline-devel package as well as the
library itself.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From seniorr at aracnet.com  Sun Feb  6 09:36:28 2000
From: seniorr at aracnet.com (Russell Senior)
Date: 06 Feb 2000 00:36:28 -0800
Subject: [R] Factor Analysis?
In-Reply-To: Prof Brian Ripley's message of "Wed, 2 Feb 2000 15:44:19 +0000 (GMT)"
References: <200002021544.PAA14447@toucan.stats.ox.ac.uk>
Message-ID: <86g0v6g22b.fsf@coulee.tdb.com>

>>>>> "BR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

BR> [...] (By the way, there is an `alternative' to SPSS out there,
BR> called PSPP at last count (it did have another name, I think).)
BR> [...]

I believe it was called `Fiasco' at some point.


-- 
Russell Senior         ``The two chiefs turned to each other.        
seniorr at aracnet.com      Bellison uncorked a flood of horrible       
                         profanity, which, translated meant, `This is
                         extremely unusual.' ''                      
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From niels.waller at vanderbilt.edu  Mon Feb  7 12:01:08 2000
From: niels.waller at vanderbilt.edu (Niels Waller)
Date: Mon, 7 Feb 2000 11:01:08 -0000
Subject: [R] RE: R-0.99.0 is released
In-Reply-To: <x2n1pdb287.fsf@blueberry.kubism.ku.dk>
Message-ID: <NDBBLLOPOEMNNHONCHBFCEOFCBAA.niels.waller@vanderbilt.edu>

Does anyone know when the new Windows NT binary files will be released for
the new version of R?

0=================================================0
Dr. Niels G. Waller
Director of Quantitative Methods Program: Measurement & Program Evaluation
Department of Psychology and Human Development
Box 512 Peabody College
Vanderbilt University
Nashville TN 37203
email:  niels.waller at vanderbilt.edu
fax:    615 343-9494
http://peabody.vanderbilt.edu/depts/psych_and_hd/faculty/wallern/
0=================================================0


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Feb  7 18:32:25 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Feb 2000 17:32:25 +0000 (GMT)
Subject: [R] Re: R-0.99.0 is released
Message-ID: <200002071732.RAA11971@toucan.stats.ox.ac.uk>

>From the NEWS for 0.99.0:

> 	Many packages will need to be re-installed for use with this
> 	release.

My testing at the the weekend showed that amongst the CRAN packages:

    VR
    chron
    foreign (in Devel)
    integrate
    nlme
    stataread
    survival5
    tree
    tseries

need to be re-compiled.

gee does not need to be recompiled, but you need the version 4.13-3 now
on CRAN if you want to re-compile.

locfit will need a new version.

However, as the processing of the help files has been substantially
improved, you may well wish to remove and re-install all the packages.


It is expected that that packages installed under 0.99.0 will continue
to work with 1.0.0, but that 1.0.0 will impose more stringent conditions
to compile packages.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MattP2 at prodigy.net  Mon Feb  7 19:17:57 2000
From: MattP2 at prodigy.net (Matt Pocernich)
Date: Mon, 7 Feb 2000 11:17:57 -0700
Subject: No subject
Message-ID: <004401bf7197$a9fe9f20$f7f8fed1@dog>

How do I change the dimensions and proportions of my graphics device?  

I've used the fin parameter to change the shape of the figure region, but the files are still square.

I'm using the windows version R 0.90.0.

Thanks,

Matt
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000207/392b519c/attachment.html

From ripley at stats.ox.ac.uk  Mon Feb  7 20:11:27 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 7 Feb 2000 19:11:27 +0000 (GMT Standard Time)
Subject: [R] Re: How do I change the dimensions and proportions of my graphics
 device?
In-Reply-To: <004401bf7197$a9fe9f20$f7f8fed1@dog>
Message-ID: <Pine.WNT.4.05.10002071906350.213-100000@tern.stats>

On Mon, 7 Feb 2000, Matt Pocernich wrote:

> How do I change the dimensions and proportions of my graphics device?  

Which device? The on-screen one, or a printer one or ...?

> I've used the fin parameter to change the shape of the figure region, 
> but the files are still square.
> 
> I'm using the windows version R 0.90.0.

Open a device with a given width and height, e.g.

windows(width=8, height=6)

However, I don't see what that has to do with files: if you are copying to
a file that should respect the dimensions given,

Under most circumstances you can just resize the graphics window if you
want another shape.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From faheem at email.unc.edu  Mon Feb  7 23:41:53 2000
From: faheem at email.unc.edu (Faheem Mitha)
Date: Mon, 7 Feb 2000 17:41:53 -0500 (EST)
Subject: [R] multicomp
Message-ID: <Pine.LNX.4.21.0002071735350.500-100000@Chrestomanci.home.earth>

Dear R people,

I have heard rumors of a function called (I believe) multicomp in S+ for
doing multiple comparisons for linear models. It doesn't seem to be in the
version of R I am using, 0.90.0. Is there something equivalent to this in
R, or does it simply not exist?

I see there is are more recent versions of R. For my platform, SuSE Linux,
the most recent rpm available appears to be 0.90.1-2. Does the update
effect people like myself doing basic things with linear models?

                                 Sincerely, Faheem Mitha.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb  8 00:07:23 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 7 Feb 2000 23:07:23 +0000 (GMT)
Subject: [R] multicomp
In-Reply-To: <Pine.LNX.4.21.0002071735350.500-100000@Chrestomanci.home.earth>
Message-ID: <Pine.GSO.4.05.10002072301100.23938-100000@auk.stats>

On Mon, 7 Feb 2000, Faheem Mitha wrote:

> Dear R people,
> 
> I have heard rumors of a function called (I believe) multicomp in S+ for
> doing multiple comparisons for linear models. It doesn't seem to be in the
> version of R I am using, 0.90.0. Is there something equivalent to this in
> R, or does it simply not exist?

Yes, S-PLUS (but not S) has had a function called multicomp for a couple of
years. However, R is `not unlike' S version 3, not S-PLUS 4.x or 5.x.  The
latest version of R, 0.99.0, has some capability for multiple comparisons,
but nothing as comprehensive as multicomp().

> I see there is are more recent versions of R. For my platform, SuSE Linux,
> the most recent rpm available appears to be 0.90.1-2. Does the update
> effect people like myself doing basic things with linear models?

Well, _lots_ of bugs get fixed on each release, but as the only more
recent version was released earlier today, you might expect an RPM
fairly soon but not today.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From novo at uiuc.edu  Mon Feb  7 23:44:21 2000
From: novo at uiuc.edu (Alvaro A. Novo)
Date: Mon, 7 Feb 2000 16:44:21 -0600
Subject: [R] Re: R-0.99.0 is released
In-Reply-To: <x2n1pdb287.fsf@blueberry.kubism.ku.dk>
References: <x2n1pdb287.fsf@blueberry.kubism.ku.dk>
Message-ID: <0002071749110Q.00336@friedman>

On Mon, 07 Feb 2000, Peter Dalgaard BSA writes:
> NEW FEATURES
> 
>     o	The ``Introduction to R'' manual, in doc/manual.
> 	The ``Writing R Extensions'' manual is much enhanced for
> 	this release.

anovo at friedman manual > ls /usr/local/lib/R/doc/manual
Rd.sty

Where's the manual? I understood it has being included in R-0.99.0.tgz, or, am I
supposed to install the package Rnotes_1.1-1.tar.gz? I believe this goes into
RHOME/library/Rnotes, not RHOME/doc/manual.

Thank you very much for your attention,

Alvaro Novo
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From novo at uiuc.edu  Tue Feb  8 01:09:57 2000
From: novo at uiuc.edu (Alvaro A. Novo)
Date: Mon, 7 Feb 2000 18:09:57 -0600
Subject: [R] Re: R-0.99.0 is released
In-Reply-To: <0002071749110Q.00336@friedman>
References: <x2n1pdb287.fsf@blueberry.kubism.ku.dk> <0002071749110Q.00336@friedman>
Message-ID: <0002071811340R.00336@friedman>

On Mon, 07 Feb 2000, Alvaro A. Novo wrote:
> anovo at friedman manual > ls /usr/local/lib/R/doc/manual
> Rd.sty
> 
> Where's the manual? I understood it has being included in R-0.99.0.tgz, or, am I
> supposed to install the package Rnotes_1.1-1.tar.gz? I believe this goes into
> RHOME/library/Rnotes, not RHOME/doc/manual.

Just remembered Rnotes is not it; it's the dataset for Venables & Ripley "Modern
Applied Stats w/ S-PLUS"...

Alvaro
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Feb  8 01:13:54 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Feb 2000 01:13:54 +0100
Subject: [R] Re: R-0.99.0 is released
In-Reply-To: "Alvaro A. Novo"'s message of "Mon, 7 Feb 2000 16:44:21 -0600"
References: <x2n1pdb287.fsf@blueberry.kubism.ku.dk> <0002071749110Q.00336@friedman>
Message-ID: <x2zotcim9p.fsf@blueberry.kubism.ku.dk>

"Alvaro A. Novo" <novo at uiuc.edu> writes:

> Where's the manual? I understood it has being included in R-0.99.0.tgz, or, am I
> supposed to install the package Rnotes_1.1-1.tar.gz? I believe this goes into
> RHOME/library/Rnotes, not RHOME/doc/manual.

Barring packaging problems, try "make pdf" and R-Intro.pdf should
appear in doc/manual in your build directory. "make install-pdf" will
copy it to RHOME as well. (And similarly "make dvi" gets you a
LaTeX'ed version if you don't have Acrobat Reader around).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From novo at uiuc.edu  Tue Feb  8 01:25:31 2000
From: novo at uiuc.edu (Alvaro A. Novo)
Date: Mon, 7 Feb 2000 18:25:31 -0600
Subject: [R] Re: R-0.99.0 is released
In-Reply-To: <x2zotcim9p.fsf@blueberry.kubism.ku.dk>
References: <x2n1pdb287.fsf@blueberry.kubism.ku.dk> <0002071749110Q.00336@friedman> <x2zotcim9p.fsf@blueberry.kubism.ku.dk>
Message-ID: <0002071838080T.00336@friedman>

On Mon, 07 Feb 2000, Peter Dalgaard BSA writes:
> Barring packaging problems, try "make pdf" and R-Intro.pdf should
> appear in doc/manual in your build directory. "make install-pdf" will
> copy it to RHOME as well. (And similarly "make dvi" gets you a
> LaTeX'ed version if you don't have Acrobat Reader around).
 
That did... I was looking at an (quite) old print out of INSTALL. Thanks.

As a curiosity, your answer arrived before I even saw my question
posted. I have noticed this behavior for quite some time now, is this normal?

Thank you very much,

Alvaro
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mahmud101 at hotmail.com  Tue Feb  8 01:52:14 2000
From: mahmud101 at hotmail.com (MMahmud)
Date: Fri, 7 Feb 2000 19:52:14 -0500
Subject: [R] Survival Analysis
Message-ID: <20000208005216.96306.qmail@hotmail.com>

Hi!

I am using R with almost all the features(packages) but couldn't use SURVIVAL ANALYSIS (survival5) part which i laready downloaded/unzipped.

Please let me know what should i do to work on this package.

My system is 
Pentium III, 450 MHZ, 64MB RAM, 512K cache, 8.4 GB Hard disk
OS: Windows 98 plus


Sincerely

M Mahmud
Grad. student
Dept. of MAth. & Stat
Concordia University
Canada.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gfeeney at hawaii.edu  Tue Feb  8 03:17:10 2000
From: gfeeney at hawaii.edu (Griffith Feeney)
Date: Mon, 07 Feb 2000 16:17:10 -1000
Subject: [R] increasing scrollback lines/rw0901
Message-ID: <3.0.5.32.20000207161710.0089faf0@pop-server.hawaii.edu>

I'd like to increase the number of lines available via the vertical
scrolling bar when running RGui.exe under win95. Would think this is set in
options() or /etc/Rconsole, but haven't been able to figure out how. Note
that it's output I'm concerened with viewing, not the command history. Can
anyone help? Thanks!
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hansel at hansel.moorhead.msus.edu  Tue Feb  8 03:25:42 2000
From: hansel at hansel.moorhead.msus.edu (hansel@hansel.moorhead.msus.edu)
Date: Mon, 7 Feb 2000 21:25:42 -0500 (EST)
Subject: [R] Alpha Linux compile failure with 0.99
In-Reply-To: <3.0.5.32.20000207161710.0089faf0@pop-server.hawaii.edu>
Message-ID: <Pine.LNX.4.10.10002072117180.25554-100000@hansel.moorhead.msus.edu>

On an alpha-linux (RH 6.0) and a second (RH 6.1), compiling fails in
printutils.c, line 424 (if (!arg)) { ....) with the fatal error message
that arg is neither an array nor a pointer. arg is declared in the
function parameter list as type va_list. If this is va_list ass defined in
glib.h (/usr/include/glib.h), it is indeed a pointer (or an array of
pointers?). (I did not try to back track through all the includes.)

Other details available upon request.

The same source compiled cleanly on an RH 6.1.

Mark Hansel
PO Box 41
Moorhead State University
Moorhead, MN 56563
ph: 218-236-2039 fax: 218-236-2593
email: hansel at mnstate.edu
web: http://wwwcj.moorhead.msus.edu


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From starab at nus.edu.sg  Tue Feb  8 06:10:44 2000
From: starab at nus.edu.sg (Rich Bud)
Date: Tue, 8 Feb 2000 13:10:44 +0800 (SGT)
Subject: [R] 0.99.0 --with-f77 configure problem
Message-ID: <Pine.GSO.4.21.0002081229050.25465-100000@tu.stat.nus.edu.sg>

Installing 0.99.0 with Dec UNIX 4.0f, if I use the native fortran compiler
(--with-f77) configure fails with:

  checking for Fortran libraries...  -lUfor -lfor -lFutil -lm -lots -lm
  checking whether Fortran libraries work correctly... no

In case anyone else runs into this, the quick fix is to change line 2071
of configure from
  ${CC} ${LDFLAGS} -o conftest conftest.o ${FLIBS} \
to
  ${FC} ${LDFLAGS} -o conftest conftest.o ${FLIBS} \

(Or just change line 2076 to set r_cv_prog_f77_flibs_ok=yes, if you're 
 sure your fortran setup is correct...)

		Rich
=======
For those who actually want to know why...

The error in config.log is that 'main' is unresolved. The problem is that 
the test program is specified as follows in configure:

2069  echo "      END" > conftest.f
2070  ${FC} -c ${FFLAGS} conftest.f 1>&5 2>&5
2071  ${CC} ${LDFLAGS} -o conftest conftest.o ${FLIBS} \

That is, the C compiler is used instead of the fortran compiler for the 
linking stage. This seems wrong to me, although it probably works for g77
because of the way gcc and g77 are linked.

In 0.90.1 this step was done as just ${FC} -o conftest conftest.f, which 
works. So does the fix above, to use the fortran compiler for both stages 
of the compile...


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb  8 08:14:31 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 8 Feb 2000 07:14:31 +0000 (GMT)
Subject: [R] increasing scrollback lines/rw0901
In-Reply-To: <3.0.5.32.20000207161710.0089faf0@pop-server.hawaii.edu>
Message-ID: <Pine.GSO.4.05.10002080707390.25187-100000@auk.stats>

On Mon, 7 Feb 2000, Griffith Feeney wrote:

> I'd like to increase the number of lines available via the vertical
> scrolling bar when running RGui.exe under win95. Would think this is set in
> options() or /etc/Rconsole, but haven't been able to figure out how. Note
> that it's output I'm concerened with viewing, not the command history. Can
> anyone help? Thanks!

It's compiled in. You need to re-compile with an increased setting of
DIMLBUF (and perhaps MLBUF) in console.c.  (Almost all scrolling terminals
do have a fixed maximum history buffer, often much less than that one.)

I am not sure why you would want to to this though: you can avoid the limit
entirely by running Rterm.exe, or saving excessively long output to a file
with sink().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gautier at lionbioscience.com  Tue Feb  8 10:17:02 2000
From: gautier at lionbioscience.com (Laurent Gautier)
Date: Tue, 8 Feb 2000 10:17:02 +0100
Subject: [R] MA / RMA / Type II regression?
References: <Pine.GSO.4.05.10002041826370.1547-100000@auk.stats>
Message-ID: <389FDEBA.D0834F06@lion-ag.de>

Prof Brian D Ripley wrote:

> > MA is not so much a regression, according to this paper, but rather the
> > major axis of the corellation ellipse (assuming equal scales in the X and Y
> > axes).
>
> More accurately the covariance ellipse.
>
> There are lots of related things under names like functional relationships
> and structural relationships, so this is almost certainly in Fuller's

>
> of Seber's or Sprent's books.
>

All this teased my curiosity. I looked for possible references corresponding to
these names and ended up with the following books.
Since I only have the references but no further description, could tell me if they
are the books you thought about, and eventually give short comments about them (so
I can have valuable indication on which one I should go first) ?

Analytic Geometry
by Gordon Fuller, Dalton Tarwater (Contributor)
7th edition (February 1993)
Addison-Wesley Pub Co; ISBN: 0201134845

Multivariate Observations
by G. A. F. Seber
1 edition (April 30, 1984)
John Wiley & Sons; ISBN: 047188104X

Data Driven Statistical Methods (Chapman & Hall Texts in Statistical Science
Series)
by Sprent
Hardcover 1 Ed edition (March 1998)
CRC Press; ISBN: 041279540X



Thanking you in advance,





Laurent Gautier




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb  8 10:27:11 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 8 Feb 2000 09:27:11 +0000 (GMT)
Subject: [R] MA / RMA / Type II regression?
In-Reply-To: <389FDEBA.D0834F06@lion-ag.de>
Message-ID: <Pine.GSO.4.05.10002080920210.11901-100000@auk.stats>

On Tue, 8 Feb 2000, Laurent Gautier wrote:

> Prof Brian D Ripley wrote:
> 
> > > MA is not so much a regression, according to this paper, but rather the
> > > major axis of the corellation ellipse (assuming equal scales in the X and Y
> > > axes).
> >
> > More accurately the covariance ellipse.
> >
> > There are lots of related things under names like functional relationships
> > and structural relationships, so this is almost certainly in Fuller's
> 
> >
> > of Seber's or Sprent's books.
> >
> 
> All this teased my curiosity. I looked for possible references corresponding to
> these names and ended up with the following books.
> Since I only have the references but no further description, could tell me if they
> are the books you thought about, and eventually give short comments about them (so
> I can have valuable indication on which one I should go first) ?
> 

W. Fuller Measurement Error Models. Wiley 1987.
The most comprehensive.

> Multivariate Observations
> by G. A. F. Seber
> 1 edition (April 30, 1984)
> John Wiley & Sons; ISBN: 047188104X

The linear models one:

Seber, G.A.F. Linear Regression Analysis Wiley 1977

> Data Driven Statistical Methods (Chapman & Hall Texts in Statistical Science
> Series)
> by Sprent
> Hardcover 1 Ed edition (March 1998)
> CRC Press; ISBN: 041279540X

There is a much earlier one, I think

Sprent, P. Models in Regression and Related Topics. Methuen, 1969.

It is 15 years since I worked on this, but looking up the terms I mentioned
should get you to the details in those books.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From BXC at novo.dk  Tue Feb  8 10:50:49 2000
From: BXC at novo.dk (BXC (Bendix Carstensen))
Date: Tue, 8 Feb 2000 10:50:49 +0100 
Subject: [R] Windows metafile
Message-ID: <D5A7D734C9C5D211B9E30008C78923020609E650@exdkba03.novo.dk>

Running

R : Copyright 1999, The R Development Core Team
Version 0.90.1  (December 15, 1999)

on NT 4.0 gives me problems with:

win.metafile(file="./x.emf")
x <- 1:100/7
plot(x,cos(x),type="n")
lines(x,sin(x))
abline(v=0:15,h=-2:2/2,col=gray(0.8))

Only labels and titles on axes are in the file.
No axes or lines of any kind. (I look at the file by 
inserting it in Word, which is what I need for
my client). Variations over the theme by using
type="l" or "p", does not change anything.

Am I missing a point? Or is this a known bug?

Bendix Carstensen
                      \\\|///
                     \\ - - /
                     (  @ @ )  
+------------------o00o-(_)-o00o-------------------------+
| Bendix Carstensen                 tel: +45 44 43 87 38 |
| Senior Statistician               SDC: +45 44 43 90 42 |
| Steno Diabetes Center             fax: +45 44 43 73 13 |
| Niels Steensens Vej 2              e-mail: bxc at novo.dk |
| DK - 2820 Gentofte       http://www.biostat.ku.dk/~bxc |
| Denmark                   Ooooo                        |
+------------------ooooO----(   )------------------------+
                   (   )     ) /
                    \ (     (_/
                     \_)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb  8 11:03:44 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Feb 2000 10:03:44 +0000 (GMT)
Subject: [R] Alpha Linux compile failure with 0.99
Message-ID: <200002081003.KAA21187@toucan.stats.ox.ac.uk>

> From: hansel at hansel.moorhead.msus.edu
> Date: Mon, 7 Feb 2000 21:25:42 -0500 (EST)
> 
> On an alpha-linux (RH 6.0) and a second (RH 6.1), compiling fails in
> printutils.c, line 424 (if (!arg)) { ....) with the fatal error message
> that arg is neither an array nor a pointer. arg is declared in the
> function parameter list as type va_list. If this is va_list ass defined in
> glib.h (/usr/include/glib.h), it is indeed a pointer (or an array of
> pointers?). (I did not try to back track through all the includes.)


Thank you for the report, and apologies for the inconvenience.

The fix I have come up with is to replace !arg by 0, so that branch is
never entered.  It looks as if this may be needed on PPC platforms too.

On some platforms, va_list may be a struct, it appears.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossetti at markov.stat.unipg.it  Tue Feb  8 11:29:18 2000
From: rossetti at markov.stat.unipg.it (Andrea Rossetti)
Date: Tue, 8 Feb 2000 11:29:18 +0100 (MET)
Subject: [R] Windows metafile
In-Reply-To: <D5A7D734C9C5D211B9E30008C78923020609E650@exdkba03.novo.dk>
Message-ID: <Pine.GSO.4.05.10002081126060.16190-100000@markov.stat.unipg.it>



On Tue, 8 Feb 2000, BXC (Bendix Carstensen) wrote:

> Date: Tue, 8 Feb 2000 10:50:49 +0100 
> From: "BXC (Bendix Carstensen)" <BXC at novo.dk>
> To: r-help at stat.math.ethz.ch
> Subject: [R] Windows metafile
> 
> Running
> 
> R : Copyright 1999, The R Development Core Team
> Version 0.90.1  (December 15, 1999)
> 
> on NT 4.0 gives me problems with:
> 
> win.metafile(file="./x.emf")
> x <- 1:100/7
> plot(x,cos(x),type="n")
> lines(x,sin(x))
> abline(v=0:15,h=-2:2/2,col=gray(0.8))


I do it on a Pentium running Windows 95 OSR2, but it seems to work fine!!!


> 
> Only labels and titles on axes are in the file.
> No axes or lines of any kind. (I look at the file by 
> inserting it in Word, which is what I need for
> my client). Variations over the theme by using
> type="l" or "p", does not change anything.
> 
> Am I missing a point? Or is this a known bug?
> 
> Bendix Carstensen
>                       \\\|///
>                      \\ - - /
>                      (  @ @ )  
> +------------------o00o-(_)-o00o-------------------------+
> | Bendix Carstensen                 tel: +45 44 43 87 38 |
> | Senior Statistician               SDC: +45 44 43 90 42 |
> | Steno Diabetes Center             fax: +45 44 43 73 13 |
> | Niels Steensens Vej 2              e-mail: bxc at novo.dk |
> | DK - 2820 Gentofte       http://www.biostat.ku.dk/~bxc |
> | Denmark                   Ooooo                        |
> +------------------ooooO----(   )------------------------+
>                    (   )     ) /
>                     \ (     (_/
>                      \_)
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Adrian.Trapletti at wu-wien.ac.at  Tue Feb  8 12:55:06 2000
From: Adrian.Trapletti at wu-wien.ac.at (Adrian Trapletti)
Date: Tue, 08 Feb 2000 11:55:06 +0000
Subject: [R] Re: [Rd] installing online help (PR#423)
References: <200002081129.MAA18950@pubhealth.ku.dk>
Message-ID: <38A0041A.C18D38A5@wu-wien.ac.at>

jlindsey at alpha.luc.ac.be wrote:

> When I attempt to install the online help for R.99 on Intel RH5.2, I
> get the following message
>
> Substitution loop at /usr/local/src/R/etc/Rdconvlib.pl line 1589, <rdfile> chunk 171
>
> and it stops after a few files. Each time I rerun it, it gets a bit
> further and gives a different number at the end. I commented out the
> line 1589 and it works.

I had exactly the same problem, also under RH5.2. I upgraded to perl version 5.005_03
and now it works. Seems to be a problem with the RH5.2 version of perl?

Adrian

--
Adrian Trapletti, Vienna University  of  Economics  and Business Ad-
ministration, Operations Research, Augasse 2-6, 1090 Vienna, Austria
Phone: ++43-(0)1-31336-4561    Email: adrian.trapletti at wu-wien.ac.at
Fax: ++43-(0)1-31336-708     WWW: http://quor/adrian/html/index.html



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phurd at uts.cc.utexas.edu  Tue Feb  8 23:54:36 2000
From: phurd at uts.cc.utexas.edu (Pete Hurd)
Date: Tue, 8 Feb 2000 16:54:36 -0600 (CST)
Subject: [R] Ancova in R?
Message-ID: <Pine.OSF.4.21.0002081603340.18360-100000@moe.cc.utexas.edu>

How to Ancova in R?

I know this has got to be an FAQ, because I see it asked in the lists, but
I haven't seen an answer to it.

I see the R-sm has the ancova thing happening, but I kind of doubt that
what I'm trying to do is "smoothing"...

-- 
Pete Hurd
phurd at uts.cc.utexas.edu
http://www.zo.utexas.edu/research/phurd
Section of Integrative Biology, University of Texas, Austin TX 78712 USA


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brian.o'gorman at noaa.gov  Tue Feb  8 00:11:31 2000
From: brian.o'gorman at noaa.gov (brian.o'gorman@noaa.gov)
Date: Mon, 07 Feb 2000 15:11:31 -0800
Subject: [R] demo(nlm) error under R 0.99.0 
Message-ID: <0002089500.AA950052245@smtpgate.akctr.noaa.gov>

I can't seem to get the demo(nlm) to run under  R version 0.99.0
Anyone know a solution?


> fgh <- function(x) {
    gr <- function(x1, x2) {
        c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1), 200 * (x2 -
            x1 * x1))
    }
    h <- function(x1, x2) {
        a11 <- 2 - 400 * (x2 - x1 * x1) + 800 * x1 * x1
        a21 <- -400 *  .... [TRUNCATED]

> nlm(fgh, c(-1.2, 1), hessian = TRUE)
Segmentation fault (core dumped)


-------------- next part --------------
begin:vcard 
n:O'Gorman;Joseph 
x-mozilla-html:FALSE
org:NOAA NMFS AFSC RACE
adr:;;;;;;
version:2.1
email;internet:brian.o'gorman at noaa.gov
title:Computer Specialist
x-mozilla-cpt:;0
fn:Joseph O'Gorman
end:vcard

From p.dalgaard at biostat.ku.dk  Wed Feb  9 00:38:18 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Feb 2000 00:38:18 +0100
Subject: [R] demo(nlm) error under R 0.99.0
In-Reply-To: brian.o'gorman@noaa.gov's message of "Mon, 07 Feb 2000 15:11:31 -0800"
References: <0002089500.AA950052245@smtpgate.akctr.noaa.gov>
Message-ID: <x2ln4vs1sl.fsf@blueberry.kubism.ku.dk>

brian.o'gorman at noaa.gov writes:

> --simple boundary
> Content-Type: text/plain; charset=US-ASCII
> Content-Transfer-Encoding: 7bit
> Content-Description: "cc:Mail Note Part"
> 
> I can't seem to get the demo(nlm) to run under  R version 0.99.0
> Anyone know a solution?
> 
> 
> > fgh <- function(x) {
>     gr <- function(x1, x2) {
>         c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1), 200 * (x2 -
>             x1 * x1))
>     }
>     h <- function(x1, x2) {
>         a11 <- 2 - 400 * (x2 - x1 * x1) + 800 * x1 * x1
>         a21 <- -400 *  .... [TRUNCATED]
> 
> > nlm(fgh, c(-1.2, 1), hessian = TRUE)
> Segmentation fault (core dumped)

A nasty little bug in uncmin.c: in line 1820, change i++ to j++ !

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brian.o'gorman at noaa.gov  Wed Feb  9 00:12:50 2000
From: brian.o'gorman at noaa.gov (brian.o'gorman@noaa.gov)
Date: Tue, 08 Feb 2000 15:12:50 -0800
Subject: [R] demo(dyn.load) error in R 0.99.0 
Message-ID: <0002089500.AA950055233@dogbert.akctr.noaa.gov>

I noticed this error in my demo from previous versions as well as
R 0.99.0. Is there a way around this one also? Thanks in advance...


> demo(dyn.load)


        demo(dyn.load)
        ---- ~~~~~~~~

Type  <Return>   to start :

> dyn.load(file.path(R.home(), "demos", "dynload", paste("zero",
    .Platform$dynlib.ext, sep = "")))
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/usr/local/lib/R/demos/dynload/zero.so":
  ld.so.1: /usr/local/lib/R/bin/R.X11: fatal:
/usr/local/lib/R/demos/dynload/zero.so: open failed: No such file or
directory
>


-------------- next part --------------
begin:vcard 
n:O'Gorman;Joseph 
x-mozilla-html:FALSE
org:NOAA NMFS AFSC RACE
adr:;;;;;;
version:2.1
email;internet:brian.o'gorman at noaa.gov
title:Computer Specialist
x-mozilla-cpt:;0
fn:Joseph O'Gorman
end:vcard


From novo at uiuc.edu  Wed Feb  9 01:47:01 2000
From: novo at uiuc.edu (Alvaro A. Novo)
Date: Tue, 8 Feb 2000 18:47:01 -0600
Subject: [R] demo(dyn.load) error in R 0.99.0
In-Reply-To: <0002089500.AA950055233@dogbert.akctr.noaa.gov>
References: <0002089500.AA950055233@dogbert.akctr.noaa.gov>
Message-ID: <0002081849521H.00336@friedman>

On Tue, 08 Feb 2000, brian.o'gorman at noaa.gov wrote:
> 
> I noticed this error in my demo from previous versions as well as
> R 0.99.0. Is there a way around this one also? Thanks in advance...

zero.c in RHOME/demos/dynload is not compiled. su and do "make," it solves the
problem... but this should have been done at installation time, I guess.

Alvaro
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bxf4 at psu.edu  Wed Feb  9 07:15:39 2000
From: bxf4 at psu.edu (bxf4@psu.edu)
Date: Tue, 8 Feb 2000 22:15:39 -0800
Subject: [R] error during no-segfault.R
Message-ID: <20000209061539.GPHM6572.mail.rdc2.pa.home.com@c119756-b>

Hello,

I am trying to install R0.99 on my PC running Solairis 7.  Here is
some text from my shell when I ran 'make check':

running `primitive-funs.R'
comparing `primitive-funs.Rout' to `./primitive-funs.Rout.save' ... OK
running `mode-methods.R'
comparing `mode-methods.Rout' to `./mode-methods.Rout.save' ... OK
running `simple-true.R'
comparing `simple-true.Rout' to `./simple-true.Rout.save' ... OK
LC_ALL=C ../bin/R --vanilla < make-isas-tests.R > /dev/null
running `isas-tests.R'
comparing `isas-tests.Rout' to `./isas-tests.Rout.save' ... OK
running sloppy specific tests
running `print-tests.R'
comparing `print-tests.Rout' to `./print-tests.Rout.save' ... OK
LC_ALL=C ../bin/R --vanilla < make-no-segfault.R > /dev/null
running `no-segfault.R'
sh: syntax error at line 1: `;' unexpected

After spending a long time looking at the makefile and learning a bit
about how they work, I noticed that there is no no-segfault.Rout.save
in the tar distribution.  Should there be?

{bxf4} c119756-b: tar tf ~/tmp/R-0.99.0.tar | grep Rout\.save
R-0.99.0/tests/arith-true.Rout.save
R-0.99.0/tests/arith.Rout.save
R-0.99.0/tests/d-p-q-r-tests.Rout.save
R-0.99.0/tests/eval-etc.Rout.save
R-0.99.0/tests/is-things.Rout.save
R-0.99.0/tests/isas-tests.Rout.save
R-0.99.0/tests/lm-tests.Rout.save
R-0.99.0/tests/mode-methods.Rout.save
R-0.99.0/tests/primitive-funs.Rout.save
R-0.99.0/tests/print-tests.Rout.save
R-0.99.0/tests/simple-true.Rout.save

Thanks for your time and I hope I didn't miss an announcement about
this already.

Brian Flaherty


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  9 08:11:27 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 9 Feb 2000 07:11:27 +0000 (GMT)
Subject: [R] Ancova in R?
In-Reply-To: <Pine.OSF.4.21.0002081603340.18360-100000@moe.cc.utexas.edu>
Message-ID: <Pine.GSO.4.05.10002090701300.20671-100000@auk.stats>

On Tue, 8 Feb 2000, Pete Hurd wrote:

> How to Ancova in R?
> 
> I know this has got to be an FAQ, because I see it asked in the lists, but
> I haven't seen an answer to it.

That's what the aov() function does, if I understand you correctly, and it
is itself a wrapper for calls to lm.  ancova normally means just the
analysis of variance for some simple regression models.  The S language has
an elegant formula notation for regression models rather than a whole set
of special-purpose procedures.

> I see the R-sm has the ancova thing happening, but I kind of doubt that
> what I'm trying to do is "smoothing"...

And what is R-sm? An obscure reference to the sm package on CRAN,
perhaps?   There is a function sm.ancova in that package, and that compares
a set of nonparametric regression curves.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  9 08:18:24 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 9 Feb 2000 07:18:24 +0000 (GMT)
Subject: [R] demo(dyn.load) error in R 0.99.0
In-Reply-To: <0002081849521H.00336@friedman>
Message-ID: <Pine.GSO.4.05.10002090715530.20671-100000@auk.stats>

On Tue, 8 Feb 2000, Alvaro A. Novo wrote:

> On Tue, 08 Feb 2000, brian.o'gorman at noaa.gov wrote:
> > 
> > I noticed this error in my demo from previous versions as well as
> > R 0.99.0. Is there a way around this one also? Thanks in advance...
> 
> zero.c in RHOME/demos/dynload is not compiled. su and do "make," it solves the
> problem... but this should have been done at installation time, I guess.

It has not been intended to be done at installation time. The purpose of
the demo is not to run it (that's trivial) but to demonstrate how to build
it.  One idea we have had is to change the demo to display the code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hiebsra at hotmail.com  Wed Feb  9 08:29:59 2000
From: hiebsra at hotmail.com (HoiNam)
Date: Wed, 9 Feb 2000 15:29:59 +0800
Subject: [R] About function 'gnls'
Message-ID: <20000209073113.74227.qmail@hotmail.com>

Dear all,

  I'm currently using R v0.90.0 with packages "nlme" on Windows 98 Second Edition. I have an enquiry on using the generalised least squares function 'gnls'.

  My data set "lx.sea" contains some seasonal GDP with some independent variables. I want to fit a nonlinear least square using restricted maximum likelihood estimation. There exists a AR(4) correlation structure (only the 4th AR) in the error term. So I enter the following commands:

> gnls(ldgdp~+pc2+pc3+pc4+pc5+pc7+t,data=lx.sea,correlation=corARMA(p=4,q=0))

It results not only the 4th AR but also the first 3 order AR in the equation. So how can I fit my model with only the 4th AR?? Are there any other function in R allow me to do that??

Thanks for the help and look forward to your reply.

Yours,

Vincent
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000209/33a76974/attachment.html

From ripley at stats.ox.ac.uk  Wed Feb  9 09:05:35 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 9 Feb 2000 08:05:35 +0000 (GMT)
Subject: [R] error during no-segfault.R
In-Reply-To: <20000209061539.GPHM6572.mail.rdc2.pa.home.com@c119756-b>
Message-ID: <Pine.GSO.4.05.10002090800300.20748-100000@auk.stats>

On Tue, 8 Feb 2000 bxf4 at psu.edu wrote:

> Hello,
> 
> I am trying to install R0.99 on my PC running Solairis 7.  Here is
> some text from my shell when I ran 'make check':
> 
> running `primitive-funs.R'
> comparing `primitive-funs.Rout' to `./primitive-funs.Rout.save' ... OK
> running `mode-methods.R'
> comparing `mode-methods.Rout' to `./mode-methods.Rout.save' ... OK
> running `simple-true.R'
> comparing `simple-true.Rout' to `./simple-true.Rout.save' ... OK
> LC_ALL=C ../bin/R --vanilla < make-isas-tests.R > /dev/null
> running `isas-tests.R'
> comparing `isas-tests.Rout' to `./isas-tests.Rout.save' ... OK
> running sloppy specific tests
> running `print-tests.R'
> comparing `print-tests.Rout' to `./print-tests.Rout.save' ... OK
> LC_ALL=C ../bin/R --vanilla < make-no-segfault.R > /dev/null
> running `no-segfault.R'
> sh: syntax error at line 1: `;' unexpected

That's not actually an error, rather a warning that when no-segfault.R
tests something silly the shell objects. It is normal on machines with
real sh (rather than bash), and as it resulted from a change made on the
day of release it was not corrected.

> After spending a long time looking at the makefile and learning a bit
> about how they work, I noticed that there is no no-segfault.Rout.save
> in the tar distribution.  Should there be?

No. The idea is that the tests run, not that they give the same error
messages everywhere.

> Thanks for your time and I hope I didn't miss an announcement about
> this already.

I don't think so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Feb  9 09:33:25 2000
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 9 Feb 2000 09:33:25 +0100 (CET)
Subject: [R] demo(nlm) error under R 0.99.0
In-Reply-To: <x2ln4vs1sl.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.10.10002090921120.11106-100000@pc16.stat.umu.se>

On 9 Feb 2000, Peter Dalgaard BSA wrote:

> A nasty little bug in uncmin.c: in line 1820, change i++ to j++ !

Peter, in my version of uncmin.c, line 1820 contains  ++i, not i++
Should it be changed to j++ or ++j? 

Or, wait; are j++ and ++j equivalent in this context? 
(This turned out to be a question for C-help rather than R-help, I guess.)

G?ran 
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Feb  9 10:02:48 2000
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 9 Feb 2000 10:02:48 +0100 (CET)
Subject: [R] demo(nlm) error under R 0.99.0
In-Reply-To: <Pine.LNX.4.10.10002090921120.11106-100000@pc16.stat.umu.se>
Message-ID: <Pine.LNX.4.10.10002091001150.12709-100000@pc16.stat.umu.se>

On Wed, 9 Feb 2000, G?ran Brostr?m wrote:

> On 9 Feb 2000, Peter Dalgaard BSA wrote:
> 
> > A nasty little bug in uncmin.c: in line 1820, change i++ to j++ !
> 
> Peter, in my version of uncmin.c, line 1820 contains  ++i, not i++
> Should it be changed to j++ or ++j? 
> 
> Or, wait; are j++ and ++j equivalent in this context? 
> (This turned out to be a question for C-help rather than R-help, I guess.)

I reply to my own question: The answer is yes!

G?ran
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb  9 10:00:38 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Feb 2000 10:00:38 +0100
Subject: [R] demo(nlm) error under R 0.99.0
In-Reply-To: G?ran Brostr?m's message of "Wed, 9 Feb 2000 09:33:25 +0100 (CET)"
References: <Pine.LNX.4.10.10002090921120.11106-100000@pc16.stat.umu.se>
Message-ID: <x2ln4uoimh.fsf@blueberry.kubism.ku.dk>

G?ran Brostr?m <gb at stat.umu.se> writes:

> On 9 Feb 2000, Peter Dalgaard BSA wrote:
> 
> > A nasty little bug in uncmin.c: in line 1820, change i++ to j++ !
> 
> Peter, in my version of uncmin.c, line 1820 contains  ++i, not i++
> Should it be changed to j++ or ++j? 
> 
> Or, wait; are j++ and ++j equivalent in this context? 
> (This turned out to be a question for C-help rather than R-help, I guess.)

They're the same when you don't use the value of the operation (and I
always write them the other way round...).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Feb  9 14:48:14 2000
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 9 Feb 2000 14:48:14 +0100 (MET)
Subject: [R] Re: R-0.99.0 bugfixes available
In-Reply-To: <x2bt5qo8lz.fsf@blueberry.kubism.ku.dk> from "Peter Dalgaard BSA" at Feb 09, 2000 01:36:56 PM
Message-ID: <200002091348.OAA03193@alpha.luc.ac.be>

I am not sure who to ask about this:
Is my example with strsplit going to continue giving the same answer,
that is "" "" instead of character(0) as it did in .90.1 and previous
so that I leave the "bugfix" in my libraries that I put in yesterday?
  Jim
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb  9 15:09:09 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Feb 2000 15:09:09 +0100
Subject: [R] Re: R-0.99.0 bugfixes available
In-Reply-To: Jim Lindsey's message of "Wed, 9 Feb 2000 14:48:14 +0100 (MET)"
References: <200002091348.OAA03193@alpha.luc.ac.be>
Message-ID: <x266vyo4ca.fsf@blueberry.kubism.ku.dk>

Jim Lindsey <jlindsey at alpha.luc.ac.be> writes:

> I am not sure who to ask about this:
> Is my example with strsplit going to continue giving the same answer,
> that is "" "" instead of character(0) as it did in .90.1 and previous
> so that I leave the "bugfix" in my libraries that I put in yesterday?
>   Jim

Yes.

> strsplit("",";")
[[1]]
character(0)

> strsplit(";",";")
[[1]]
[1] ""

> strsplit(";;",";")
[[1]]
[1] "" ""

and the same thing with spaces, of course.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pete at seul.org  Wed Feb  9 16:11:20 2000
From: pete at seul.org (Pete St. Onge)
Date: Wed, 09 Feb 2000 10:11:20 -0500
Subject: Comparing Type 2 regressions Was: [R] Ancova in R?
References: <Pine.GSO.4.05.10002090701300.20671-100000@auk.stats>
Message-ID: <38A18398.35F8C79A@seul.org>

For starters, thanks to everyone who responsded to my previous request for
help about Type 2 regression. 

> > I see the R-sm has the ancova thing happening, but I kind of doubt that
> > what I'm trying to do is "smoothing"...
> 
> And what is R-sm? An obscure reference to the sm package on CRAN,
> perhaps?   There is a function sm.ancova in that package, and that
> compares a set of nonparametric regression curves.

To follow this up with the other thread, is there a way to compare two or
more lines based on Type 2 regression techniques (or lines based on the 1st
principal component) to see if they are significantly different from each
other with respect to their slopes and intercepts?

This is not a subject that I've seen dealt with in any of the stats books
that I've read, and pointers to other references that do would be
appreciated.

Many thanks,


-- 
Pete St. Onge
pete at seul.org

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb  9 17:12:18 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Feb 2000 16:12:18 +0000 (GMT)
Subject: [R] Comparing Type 2 regressions
Message-ID: <200002091612.QAA02798@toucan.stats.ox.ac.uk>


> Date: Wed, 09 Feb 2000 10:11:20 -0500
> From: "Pete St. Onge" <pete at seul.org>
> Subject: Comparing Type 2 regressions Was: [R] Ancova in R?
> 
> For starters, thanks to everyone who responsded to my previous request for
> help about Type 2 regression. 
> 
> > > I see the R-sm has the ancova thing happening, but I kind of doubt that
> > > what I'm trying to do is "smoothing"...
> > 
> > And what is R-sm? An obscure reference to the sm package on CRAN,
> > perhaps?   There is a function sm.ancova in that package, and that
> > compares a set of nonparametric regression curves.
> 
> To follow this up with the other thread, is there a way to compare two or
> more lines based on Type 2 regression techniques (or lines based on the 1st
> principal component) to see if they are significantly different from each
> other with respect to their slopes and intercepts?

Well, that has nothing to do with sm.ancova, and it is quoting me without
due credit!

> This is not a subject that I've seen dealt with in any of the stats books
> that I've read, and pointers to other references that do would be
> appreciated.

Once again. W.A. Fuller (1977), Measurement Error Models, has the
appropriate theory.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Wed Feb  9 17:29:45 2000
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed, 09 Feb 2000 17:29:45 +0100 (CET)
Subject: [R] Ancova in R?
In-Reply-To: <Pine.GSO.4.05.10002090701300.20671-100000@auk.stats>
Message-ID: <XFMail.000209172945.plummer@iarc.fr>

On 09-Feb-00 Prof Brian D Ripley wrote:
> On Tue, 8 Feb 2000, Pete Hurd wrote:
> 
>> I see the R-sm has the ancova thing happening, but I kind of doubt that
>> what I'm trying to do is "smoothing"...
> 
> And what is R-sm? An obscure reference to the sm package on CRAN,
> perhaps?   

CRAN packages are renamed when binary RPM packages are made from them by
adding the prefix "R-", so sm becomes R-sm for example.  This may be what
Peter is referring to.  Of course the correct name for the package is
"sm".

Martyn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kouts96 at med.mcgill.ca  Wed Feb  9 23:05:59 2000
From: kouts96 at med.mcgill.ca (Tom Koutsavlis)
Date: Wed, 09 Feb 2000 22:05:59 +0000
Subject: No subject
Message-ID: <001601bf7349$d96d77a0$41b5a8c6@akouts>

I have the Windows 95 version of R.
How do I increase the memory of the vsize and nsize??
Can you please give me exact codes that I should enter.
When I enter the codes from the help manual ... they don't work. I believe they are for the Unix system only.
 
Any help would be very much appreciated.
 
Sincerely,
 
Dr. Athanasios Tom Koutsavlis
Montreal Public Health Department
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000209/c5176b81/attachment.html

From kouts96 at med.mcgill.ca  Wed Feb  9 23:06:19 2000
From: kouts96 at med.mcgill.ca (Tom Koutsavlis)
Date: Wed, 09 Feb 2000 22:06:19 +0000
Subject: No subject
Message-ID: <001f01bf7349$e5362140$41b5a8c6@akouts>

I have the Windows 95 version of R.
How do I increase the memory of the vsize and nsize??
Can you please give me exact codes that I should enter.
When I enter the codes from the help manual ... they don't work. I believe they are for the Unix system only.
 
Any help would be very much appreciated.
 
Sincerely,
 
Dr. Athanasios Tom Koutsavlis
Montreal Public Health Department
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000209/6ae4feac/attachment.html

From ripley at stats.ox.ac.uk  Thu Feb 10 08:13:22 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 10 Feb 2000 07:13:22 +0000 (GMT)
Subject: [R] Re: your mail
In-Reply-To: <001f01bf7349$e5362140$41b5a8c6@akouts>
Message-ID: <Pine.GSO.4.05.10002100710110.19295-100000@auk.stats>

On Wed, 9 Feb 2000, Tom Koutsavlis wrote:

> I have the Windows 95 version of R.
> How do I increase the memory of the vsize and nsize??
> Can you please give me exact codes that I should enter.
> When I enter the codes from the help manual ... they don't work. I believe they are for the Unix system only.

What is in the help is correct, but you may be confused as to where to
enter them. (The help has been expnaded for R 0.99.0.) 
There are worked examples in the R for Windows FAQ, which comes
with the distribution. The exact codes depend on the version of R
(there is no `Windows 95 version', but there are numbers like 0.90.1),
so please look in distribution you have.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paradis at isem.univ-montp2.fr  Thu Feb 10 09:29:11 2000
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Thu, 10 Feb 2000 09:29:11 +0100
Subject: [R] Re: your mail about Memory on Windows95
Message-ID: <3.0.32.20000210092911.008f8ec0@162.38.183.200>

A non-text attachment was scrubbed...
Name: not available
Type: text/enriched
Size: 1580 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000210/0b902104/attachment.bin

From J.Harold at uea.ac.uk  Thu Feb 10 10:52:39 2000
From: J.Harold at uea.ac.uk (J.Harold@uea.ac.uk)
Date: Thu, 10 Feb 2000 09:52:39 +0000
Subject: [R] compiling R in alpha digital unix 4.0E
Message-ID: <E12IqH9-0006Rt-00@cpca7.uea.ac.uk>

I am trying to compile R on an alpha running digital unix 4.0E.

I have used the R-0.99.0a source code, and run the following, 

 ./configure --prefix=/hpc/readonly/code/bin.alpha/R

and get this error 

checking for Fortran libraries...  -lUfor -lfor -lFutil -lm -lots -lm
checking whether Fortran libraries work correctly... no
configure: warning: Fortran libraries do not work correctly
configure: error: Maybe your Fortran installation is incomplete


I have no problems with fortran for anything else.

Any help greatly appreciated.

Julie

I enclose the output from my compiling effort.

# ./configure --prefix=/hpc/readonly/code/bin.alpha/R
loading cache ./config.cache
checking host system type... alpha-dec-osf4.0
loading site script ./config.site
loading build specific script ./config.site
checking for mawk... no
checking for gawk... gawk
checking for a BSD compatible install... /usr/bin/installbsd -c
checking whether ln -s works... yes
checking for ranlib... ranlib
checking for bison... bison -y
checking for ar... ar
checking whether echo can suppress newlines... yes
checking for nroff... /usr/bin/nroff
checking for tbl... /usr/bin/tbl
checking for perl... /usr/bin/perl
checking whether perl version is at least 5... yes
checking for dvips... false
checking for latex... false
checking for makeindex... false
checking for pdflatex... false
checking for makeinfo... no
configure: warning: you cannot build info versions of the R manuals
checking for unzip... /sw1/bin/unzip
checking for zip... no
checking for gcc... gcc
checking whether the C compiler (gcc  ) works... yes
checking whether the C compiler (gcc  ) is a cross-compiler... no
checking whether we are using GNU C... yes
checking whether gcc accepts -g... yes
checking how to run the C preprocessor... gcc -E
checking whether gcc needs -traditional... no
checking whether gcc accepts -M for generating dependencies... yes
checking for g77... no
checking for f77... /usr/bin/f77
checking for Fortran libraries...  -lUfor -lfor -lFutil -lm -lots -lm
checking whether Fortran libraries work correctly... no
configure: warning: Fortran libraries do not work correctly
configure: error: Maybe your Fortran installation is incomplete






----------------------------------------------------------------------

                       Dr Julie Harold, ITCS, 
             University of East Anglia, Norwich, NR4 7TJ
          phone 592385  email  j.harold at uea.ac.uk
               http://www.uea.ac.uk/~e288/index.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.Harold at uea.ac.uk  Thu Feb 10 10:56:26 2000
From: J.Harold at uea.ac.uk (J.Harold@uea.ac.uk)
Date: Thu, 10 Feb 2000 09:56:26 +0000
Subject: [R] compiling R on alpha 4.0E
Message-ID: <E12IqKo-0005mB-00@cpca7.uea.ac.uk>

I have tried compiling R on a dec alpha running digital unix 4.0E

configure works ok - giving 
 is now configured for alpha-dec-osf4.0

  Source directory:         .
  Installation directory:   /hpc/readonly/code/bin.alpha/R
  C compiler:               gcc  -ieee_with_inexact -g -O2
  FORTRAN compiler:         f77  
  Gnome support:            no

make runs ok   (make version gnu make-3.78.1)

make check gives this error

>make[5]: Leaving directory `/hpc/readonly/code/bin.alpha/R-0.90.1/src/library'
running code in base-Ex.R ...
../../bin/R --vanilla < base-Ex.R > base-Ex.Rout
/bin/sh: 280 Floating exception
make[4]: *** [base-Ex.Rout] Error 136
make[4]: Leaving directory `/hpc/readonly/code/bin.alpha/R-0.90.1/tests/Examples'
make[3]: *** [test-Examples] Error 2
make[3]: Leaving directory `/hpc/readonly/code/bin.alpha/R-0.90.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/hpc/readonly/code/bin.alpha/R-0.90.1/tests'
make[1]: *** [test-All] Error 2
make[1]: Leaving directory `/hpc/readonly/code/bin.alpha/R-0.90.1/tests'
make: *** [test-All] Error 2


what do I need to do to overcome this ?

Julie

----------------------------------------------------------------------

                       Dr Julie Harold, ITCS, 
             University of East Anglia, Norwich, NR4 7TJ
          phone 592385  email  j.harold at uea.ac.uk
               http://www.uea.ac.uk/~e288/index.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yudi at stat.ucc.ie  Thu Feb 10 11:22:23 2000
From: yudi at stat.ucc.ie (yudi@stat.ucc.ie)
Date: Thu, 10 Feb 2000 10:22:23 +0000
Subject: [R] Re: your mail about Memory on Windows95
Message-ID: <01JLQMEJ26W2000T2Q@CCSERV.UCC.IE>

>I use WinNT. You have to "launch" R from a DOS-shell window; you 1st
>change to the directory where you have RGui.exe, then type :
> Rgui --vsize 15M --nsize 1000k
>
>and R opens with increased memore size. It works here with my NT box, and
>will probably do with Win95 (though I think that the DOS-shells are not
>strictly similar in both OSs but this may not be a problem).

You don't have to launch R from the DOS-window.
Simply click on the icon. 

You should create a shortcut icon for Rgui (click the
right mouse button, say from Explorer), move it to 
somewhere sensible. Then,
click the right mouse button on the shortcut icon,
and go to Properties, then Shortcut section, that's
where the command line is  (look for Target), where 
you can add the vsize and nsize option.

-Yudi-

------------------------------
Yudi Pawitan: yudi at stat.ucc.ie
Department of Statistics, UCC
Cork, Ireland
Ph : 353-21-902 906
Fax: 353-21-271 040
------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cstrato at EUnet.at  Thu Feb 10 12:23:51 2000
From: cstrato at EUnet.at (cstrato@EUnet.at)
Date: Thu, 10 Feb 2000 12:23:51 +0100
Subject: [R] list to matrix
Message-ID: <38A29FC6.F8DCC805@EUnet.at>

Dear R-users

This seems to be a trivial problem but at the moment I don?t know how to
solve it.

I have a list with 7000 matrices, every matrix has 2 columns but
different row-sizes.
Now I want to combine all lists into one matrix with 2 columns. I would
have to write:

ma <- rbind(list[[1]],list[[2]], and so on) (this works fine for lists
with few matrices)

Since it is not possible to write:
          ma <- rbind(list[[1:7000]]) or
          ma <- rbind(list[[1]]:list[[7000]])
maybe someone could tell me how to do it?

Thank you in advance for your help for this stupid question.

Best regards
Christian Stratowa, Ph.D. Vienna

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Feb 10 12:31:51 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Feb 2000 12:31:51 +0100
Subject: [R] list to matrix
In-Reply-To: cstrato@EUnet.at's message of "Thu, 10 Feb 2000 12:23:51 +0100"
References: <38A29FC6.F8DCC805@EUnet.at>
Message-ID: <x27lgdqons.fsf@blueberry.kubism.ku.dk>

cstrato at EUnet.at writes:

> I have a list with 7000 matrices, every matrix has 2 columns but
> different row-sizes.
> Now I want to combine all lists into one matrix with 2 columns. I would
> have to write:
> 
> ma <- rbind(list[[1]],list[[2]], and so on) (this works fine for lists
> with few matrices)
> 
> Since it is not possible to write:
>           ma <- rbind(list[[1:7000]]) or
>           ma <- rbind(list[[1]]:list[[7000]])
> maybe someone could tell me how to do it?

do.call("rbind", list)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ferster at stat.math.ethz.ch  Thu Feb 10 12:54:44 2000
From: ferster at stat.math.ethz.ch (Monika Ferster)
Date: Thu, 10 Feb 2000 12:54:44 +0100 (MET)
Subject: [R] random effects in analysis of variance
Message-ID: <200002101154.MAA01237@sophie.math.ethz.ch>

I have a data.frame paint (below-mentioned). In SPlus I used the command 

raov( MOISTURE ~ BATCH / PROBE )

(you could do raov( MOISTURE ~ BATCH +  PROBE%in%BATCH) as well)

so that the factors are taken as random. In R this function raov doesn't
exist. How can I calculate the same? Maybe with lme, but how? 

str(paint)
----------
`data.frame':	60 obs. of  5 variables:
 $ BATCH   : Factor w/ 15 levels "1","2","3","4",..: 1 1 1 1 2 2 2 2 3 3 ...
 $ SAMPLE  : num  1 1 2 2 3 3 4 4 5 5 ...
 $ REP     : num  1 2 1 2 1 2 1 2 1 2 ...
 $ MOISTURE: num  40 39 30 30 26 28 25 26 29 28 ...
 $ PROBE   : Factor w/ 2 levels "1","2": 1 1 2 2 1 1 2 2 1 1 ...

dput(paint)
-----------
structure(list(BATCH = structure(c(1, 1, 1, 1, 2, 2, 2, 2, 3, 
3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 
8, 8, 9, 9, 9, 9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 
12, 13, 13, 13, 13, 14, 14, 14, 14, 15, 15, 15, 15), .Label = c("1", 
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", 
"14", "15"), class = "factor"), SAMPLE = c(1, 1, 2, 2, 3, 3, 
4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 
13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 
21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 
29, 30, 30), REP = c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 2, 1, 2), MOISTURE = c(40, 39, 30, 30, 26, 28, 25, 26, 29, 
28, 14, 15, 30, 31, 24, 24, 19, 20, 17, 17, 33, 32, 26, 24, 23, 
24, 32, 33, 34, 34, 29, 29, 27, 27, 31, 31, 13, 16, 27, 24, 25, 
23, 25, 27, 29, 29, 31, 32, 19, 20, 29, 30, 23, 24, 25, 25, 39, 
37, 26, 28), PROBE = structure(c(1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 
2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 
2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 
1, 1, 2, 2, 1, 1, 2, 2), .Label = c("1", "2"), class = "factor")), .Names = c("BATCH", 
"SAMPLE", "REP", "MOISTURE", "PROBE"), row.names = c("1", "2", 
"3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", 
"15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", 
"26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", 
"37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", 
"48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", 
"59", "60"), class = "data.frame")
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Feb 10 13:12:20 2000
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 10 Feb 2000 13:12:20 +0100 (MET)
Subject: [R] random effects in analysis of variance
In-Reply-To: <200002101154.MAA01237@sophie.math.ethz.ch>
References: <200002101154.MAA01237@sophie.math.ethz.ch>
Message-ID: <14498.43812.319373.229634@lynne.ethz.ch>

>>>>> "Monika" == Monika Ferster <ferster at stat.math.ethz.ch> writes:

    Monika> I have a data.frame paint (below-mentioned). In SPlus I used
    Monika> the command raov( MOISTURE ~ BATCH / PROBE )

    Monika> (you could do raov( MOISTURE ~ BATCH + PROBE%in%BATCH) as well)

    Monika> so that the factors are taken as random. In R this function
    Monika> raov doesn't exist. How can I calculate the same? Maybe with
    Monika> lme, but how?

	    .....

sehr gut!
Ich hoffe, wir bekommen ntzliche Antworten..

Martin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lgygax at access.unizh.ch  Thu Feb 10 13:34:10 2000
From: lgygax at access.unizh.ch (Lorenz Gygax)
Date: Thu, 10 Feb 2000 13:34:10 +0100 (MET)
Subject: [R] interpreting evecs in pca (mulitv)
Message-ID: <Pine.LNX.3.96.1000210133352.580F-100000@iamgygax.unizh.ch>


Dear R specialists and users,

can you help me with the interpretation of the $evecs in the result of a
pca from the library multiv? (I must ashamedly admit that this is still R
V 0.64.1 and multiv V 1.0-1)

I did a default pca which is supposed to normalise the variables before
rotating them. Now, I was trying to find out, whether the $evecs are the
loadings for the unstandardised or standardised variables. Thus, I tried
to calculate the linear combinations using the $evecs and either the
original variables or the standardised variables but neither seems to
result in the values that can be found in $rproj.

Do I miss something?

Many thanks and regards, Lorenz
-- 
                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Lorenz Gygax             LGygax at amath.unizh.ch;       room: 36-L-40
                         Department of Applied Mathematics
                         University of Zuerich-Irchel
                         Winterthurerstr. 190; CH-8057 Zurich
                         voice: 41-1-635-58-52  fax: 41-1-635-57-05
                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 10 13:45:32 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 10 Feb 2000 12:45:32 +0000 (GMT)
Subject: [R] random effects in analysis of variance
In-Reply-To: <200002101154.MAA01237@sophie.math.ethz.ch>
Message-ID: <Pine.GSO.4.05.10002101237210.19996-100000@auk.stats>

On Thu, 10 Feb 2000, Monika Ferster wrote:

> I have a data.frame paint (below-mentioned). In SPlus I used the command 
> 
> raov( MOISTURE ~ BATCH / PROBE )
> 
> (you could do raov( MOISTURE ~ BATCH +  PROBE%in%BATCH) as well)
> 
> so that the factors are taken as random. In R this function raov doesn't
> exist. How can I calculate the same? Maybe with lme, but how? 

Easier, in both S and R

> summary(aov( MOISTURE ~ BATCH + Error(BATCH / PROBE) , data=paint))
Error: BATCH 
      Df Sum of Sq  Mean Sq 
BATCH 14  1210.933 86.49524

Error: PROBE %in% BATCH 
          Df Sum of Sq  Mean Sq F Value Pr(F) 
Residuals 15    869.75 57.98333              

Error: Within 
          Df Sum of Sq   Mean Sq F Value Pr(F) 
Residuals 30      27.5 0.9166667              

but just so you know how,

fit <- lme(MOISTURE ~ 1, random = ~1 | BATCH / PROBE, data=paint)

is the fit you want, and print or summary will let you pick off the
estimates you might need.

There is a worked example almost exactly like this in V&R3.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 10 12:51:34 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 10 Feb 2000 11:51:34 +0000 (GMT)
Subject: [R] list to matrix
In-Reply-To: <38A29FC6.F8DCC805@EUnet.at>
Message-ID: <Pine.GSO.4.05.10002101144010.15498-100000@auk.stats>

On Thu, 10 Feb 2000 cstrato at EUnet.at wrote:

> Dear R-users
> 
> This seems to be a trivial problem but at the moment I dont know how to
> solve it.
> 
> I have a list with 7000 matrices, every matrix has 2 columns but
> different row-sizes.
> Now I want to combine all lists into one matrix with 2 columns. I would
> have to write:
> 
> ma <- rbind(list[[1]],list[[2]], and so on) (this works fine for lists
> with few matrices)
> 
> Since it is not possible to write:
>           ma <- rbind(list[[1:7000]]) or
>           ma <- rbind(list[[1]]:list[[7000]])
> maybe someone could tell me how to do it?

You could use do.call("rbind", list), but for efficiency, something like

nr <- sapply(list, NROWS)  # to get a vector of the numbers of rows.
cs <- cumsum(nr)
st <- c(0, nr[-length(nr)]) + 1
res <- matrix(, sum(nr), 2)
for(i in seq(along=nr)) res[st[i]:en[i],] <- list[[i]]

Beware: untested code.

Or, a lot sneakier but probably a lot quicker than either

row1 <- lapply(list, function(x) x[, 1])
row2 <- lapply(list, function(x) x[, 2])
matrix(c(unlist(row1), unlist(row2)),,2)



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cstrato at EUnet.at  Thu Feb 10 15:42:33 2000
From: cstrato at EUnet.at (cstrato@EUnet.at)
Date: Thu, 10 Feb 2000 15:42:33 +0100
Subject: [R] list to matrix
References: <Pine.GSO.4.05.10002101144010.15498-100000@auk.stats>
Message-ID: <38A2CE58.99497BC6@EUnet.at>

Thank you both,  Dr. Dalgaard and Prof. Ripley, for the prompt response.

I have tested all solutions with a list of 500 matrices, all solutions are
about equally fast.

The untested code from Prof. Ripley works as follows:

nr <- sapply(list, nrow)
cs <- cumsum(nr)
st <- c(0, cs[-length(cs)]) + 1
res <- matrix(, sum(nr), 2)
for(i in seq(along=nr)) res[st[i]:cs[i],] <- list[[i]]

Thank you once again
Christian  Stratowa


Prof Brian D Ripley wrote:

> On Thu, 10 Feb 2000 cstrato at EUnet.at wrote:
>
> > Dear R-users
> >
> > This seems to be a trivial problem but at the moment I don?t know how to
> > solve it.
> >
> > I have a list with 7000 matrices, every matrix has 2 columns but
> > different row-sizes.
> > Now I want to combine all lists into one matrix with 2 columns. I would
> > have to write:
> >
> > ma <- rbind(list[[1]],list[[2]], and so on) (this works fine for lists
> > with few matrices)
> >
> > Since it is not possible to write:
> >           ma <- rbind(list[[1:7000]]) or
> >           ma <- rbind(list[[1]]:list[[7000]])
> > maybe someone could tell me how to do it?
>
> You could use do.call("rbind", list), but for efficiency, something like
>
> nr <- sapply(list, NROWS)  # to get a vector of the numbers of rows.
> cs <- cumsum(nr)
> st <- c(0, nr[-length(nr)]) + 1
> res <- matrix(, sum(nr), 2)
> for(i in seq(along=nr)) res[st[i]:en[i],] <- list[[i]]
>
> Beware: untested code.
>
> Or, a lot sneakier but probably a lot quicker than either
>
> row1 <- lapply(list, function(x) x[, 1])
> row2 <- lapply(list, function(x) x[, 2])
> matrix(c(unlist(row1), unlist(row2)),,2)
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Feb 10 21:28:49 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 10 Feb 2000 14:28:49 -0600
Subject: [R] creating a grid of function values
Message-ID: <6rln4sls3i.fsf@franz.stat.wisc.edu>

I want to create a grid of function values for use in `contour' or
`persp'.  The function is the log-likelihood for the gamma.  The
sample is stored as vector of length 20 called `Survival'.

A single evaluation of the log-likelihood at, say, scale = 9 and shape
= 10 would be obtained by
 sum(dgamma(Survival, scale = 9, shape = 10, log = TRUE))
(This may work only 0.99.0, I'm not sure.)

I would like to evaluate such a function on a grid of scale and shape
values.  I don't think I can use `outer' because of the way the
evaluation of the dgamma function would vectorize.  Although I could
write the calculation for the grid in `for' loops, I have a nagging
suspicion that there is a cleaner way that I have forgotten.

Can anyone remind me of a slick way of generating the grid?

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 10 23:00:13 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 10 Feb 2000 22:00:13 +0000 (GMT)
Subject: [R] creating a grid of function values
In-Reply-To: <6rln4sls3i.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.GSO.4.05.10002102138420.26006-100000@auk.stats>

On 10 Feb 2000, Douglas Bates wrote:

> I want to create a grid of function values for use in `contour' or
> `persp'.  The function is the log-likelihood for the gamma.  The
> sample is stored as vector of length 20 called `Survival'.
> 
> A single evaluation of the log-likelihood at, say, scale = 9 and shape
> = 10 would be obtained by
>  sum(dgamma(Survival, scale = 9, shape = 10, log = TRUE))
> (This may work only 0.99.0, I'm not sure.)
> 
> I would like to evaluate such a function on a grid of scale and shape
> values.  I don't think I can use `outer' because of the way the
> evaluation of the dgamma function would vectorize.  Although I could

It should vectorize correctly if we use three dimensions. Let's see:

Survival <- rgamma(20, 5, 5)

res <- do.call("dgamma", expand.grid(x=Survival, scale=8:12, 
shape=7:12, log=1))
# avoid conversion of logicals to factor here.

dim(res) <- c(length(Survival), 5, 6)

> apply(res, c(2,3), sum)
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]
[1,] -121.0935 -141.6717 -164.9205 -190.5250 -218.2367 -247.8546
[2,] -131.1431 -154.0770 -179.6815 -207.6417 -237.7090 -269.6826
[3,] -140.7416 -165.7827 -193.4944 -223.5618 -255.7364 -289.8171
[4,] -149.8698 -176.8171 -206.4350 -238.4086 -272.4894 -308.4764
[5,] -158.5387 -187.2262 -218.5844 -252.2982 -288.1192 -325.8464


Actually, I would use

sc <- 8:12; sh <- 7:12
args <- expand.grid(scale=sc, shape=sh)

matrix(apply(args, 1, function(x) sum(dgamma(Survival, scale=x[1],
shape=x[2], log=T))), length(sc), dimnames=list(scale=sc, shape=sh))

     shape
scale         7         8         9        10        11        12
   8  -121.0935 -141.6717 -164.9205 -190.5250 -218.2367 -247.8546
   9  -131.1431 -154.0770 -179.6815 -207.6417 -237.7090 -269.6826
   10 -140.7416 -165.7827 -193.4944 -223.5618 -255.7364 -289.8171
   11 -149.8698 -176.8171 -206.4350 -238.4086 -272.4894 -308.4764
   12 -158.5387 -187.2262 -218.5844 -252.2982 -288.1192 -325.8464

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chong at stat.purdue.edu  Thu Feb 10 23:47:30 2000
From: chong at stat.purdue.edu (Chong Gu)
Date: Thu, 10 Feb 2000 17:47:30 -0500
Subject: [R] creating a grid of function values
In-Reply-To: <6rln4sls3i.fsf@franz.stat.wisc.edu> (message from Douglas Bates
	on 10 Feb 2000 14:28:49 -0600)
Message-ID: <200002102247.RAA141230@odds.stat.purdue.edu>


   From: Douglas Bates <bates at stat.wisc.edu>
   Date: 10 Feb 2000 14:28:49 -0600
   Lines: 21
   X-Mailer: Gnus v5.5/Emacs 20.3
   Sender: owner-r-help at stat.math.ethz.ch
   Precedence: bulk

   I want to create a grid of function values for use in `contour' or
   `persp'.  The function is the log-likelihood for the gamma.  The
   sample is stored as vector of length 20 called `Survival'.

   A single evaluation of the log-likelihood at, say, scale = 9 and shape
   = 10 would be obtained by
    sum(dgamma(Survival, scale = 9, shape = 10, log = TRUE))
   (This may work only 0.99.0, I'm not sure.)

   I would like to evaluate such a function on a grid of scale and shape
   values.  I don't think I can use `outer' because of the way the
   evaluation of the dgamma function would vectorize.  Although I could
   write the calculation for the grid in `for' loops, I have a nagging
   suspicion that there is a cleaner way that I have forgotten.

   Can anyone remind me of a slick way of generating the grid?

   -- 
   Douglas Bates                            bates at stat.wisc.edu
   Statistics Department                    608/262-2598
   University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
   -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
   r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
   Send "info", "help", or "[un]subscribe"
   (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
   _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


Doug,

I don't quite understand what you meant about outer.  The first thing
I would try is

    dgamma.grid<-function(x,y,z) sum(dgamma(z,scale=x,shape=y,log=TRUE))
    outer(xgrid,ygrid,dgamma.grid,Survival)

Chong
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jimrc at gauss.math.montana.edu  Thu Feb 10 23:57:13 2000
From: jimrc at gauss.math.montana.edu (Jim Robison-Cox)
Date: Thu, 10 Feb 2000 15:57:13 -0700 (MST)
Subject: [R] creating a grid of function values
In-Reply-To: <6rln4sls3i.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.GSO.4.02.10002101530320.20339-100000@gauss.math.montana.edu>

On 10 Feb 2000, Douglas Bates wrote:

> I want to create a grid of function values for use in `contour' or
> `persp'.  The function is the log-likelihood for the gamma.  The
> sample is stored as vector of length 20 called `Survival'.
> 
> A single evaluation of the log-likelihood at, say, scale = 9 and shape
> = 10 would be obtained by
>  sum(dgamma(Survival, scale = 9, shape = 10, log = TRUE))
> (This may work only 0.99.0, I'm not sure.)
> 
> I would like to evaluate such a function on a grid of scale and shape
> values.  I don't think I can use `outer' because of the way the
> evaluation of the dgamma function would vectorize.  Although I could
> write the calculation for the grid in `for' loops, I have a nagging
> suspicion that there is a cleaner way that I have forgotten.
> 
> Can anyone remind me of a slick way of generating the grid?
> 

Here's one way which avoids looping by using apply.

gridS <- expand.grid(scales, shapes)
survLilel <- function(ss) sum(dgamma(Survival,ss[1],ss[2]))
Likel <- apply(gridS,1,survLilel)

Regards,
Jim
 

Jim Robison-Cox               ____________    
Department of Math Sciences  |            |       phone: (406)994-5340
2-214 Wilson Hall             \   BZN, MT |       FAX:   (406)994-1789
Montana State University       |  *_______|
Bozeman, MT 59717-2400          \_|      e-mail: jimrc at math.montana.edu 




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lamkel at yahoo.com  Fri Feb 11 04:04:19 2000
From: lamkel at yahoo.com (Kelvin Lam)
Date: Thu, 10 Feb 2000 19:04:19 -0800 (PST)
Subject: [R] Help Help!
Message-ID: <20000211030419.10090.qmail@web1504.mail.yahoo.com>

Hello!  I have two questions.

First of all, I have a problem dealing with acf
(Autocovariance function) and need help.  First I
defined a time series, x, which is a vector created by
x <- ts(rnorm(200)).  So I plugged the series directly
into the acf function, acf(x) and an error message
popped up as:

Error in .C("acf", as.double(x), as.integer(sampleT),
as.integer(nser),  : C/Fortran function name not in
load table

I downloaded R to my PC and am thinking if it's
anything to do with the operating system.  Please help
me out!

The second question is about arima simulation.  I have
an AR and MA process and need to simulate 200
observations from these two models.  Don't know how to
do.

Thank you for the help!  You can send me a mail at
lamkel at yahoo.com.  

Regards,
Kelvin Lam

__________________________________________________
Do You Yahoo!?
Talk to your friends online with Yahoo! Messenger.
http://im.yahoo.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lamkel at yahoo.com  Fri Feb 11 04:06:43 2000
From: lamkel at yahoo.com (Kelvin Lam)
Date: Thu, 10 Feb 2000 19:06:43 -0800 (PST)
Subject: [R] Help Help 2
Message-ID: <20000211030643.10830.qmail@web1505.mail.yahoo.com>

Please pardon me if you see this message twice.  The
mail server has a bit problem.

*****************************************************

Hello!  I have two questions.

First of all, I have a problem dealing with acf
(Autocovariance function) and need help.  First I
defined a time series, x, which is a vector created by
x <- ts(rnorm(200)).  So I plugged the series directly
into the acf function, acf(x) and an error message
popped up as:

Error in .C("acf", as.double(x), as.integer(sampleT),
as.integer(nser),  : C/Fortran function name not in
load table

I downloaded R to my PC and am thinking if it's
anything to do with the operating system.  Please help
me out!

The second question is about arima simulation.  I have
an AR and MA process and need to simulate 200
observations from these two models.  Don't know how to
do.

Thank you for the help!  You can send me a mail at
lamkel at yahoo.com.  

Regards,
Kelvin Lam

__________________________________________________
Do You Yahoo!?
Talk to your friends online with Yahoo! Messenger.
http://im.yahoo.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb 11 08:01:44 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 11 Feb 2000 07:01:44 +0000 (GMT)
Subject: [R] Help Help!
In-Reply-To: <20000211030419.10090.qmail@web1504.mail.yahoo.com>
Message-ID: <Pine.GSO.4.05.10002110655290.7534-100000@auk.stats>

On Thu, 10 Feb 2000, Kelvin Lam wrote:

> Hello!  I have two questions.
> 
> First of all, I have a problem dealing with acf
> (Autocovariance function) and need help.  First I
> defined a time series, x, which is a vector created by
> x <- ts(rnorm(200)).  So I plugged the series directly
> into the acf function, acf(x) and an error message
> popped up as:
> 
> Error in .C("acf", as.double(x), as.integer(sampleT),
> as.integer(nser),  : C/Fortran function name not in
> load table
> 
> I downloaded R to my PC and am thinking if it's
> anything to do with the operating system.  Please help
> me out!

Look at ?bug.report to find out how to send a bug report with the 
information we need, like the version of R in use.

Let me check one thing. You did do library(ts) and got no
error messages? Your example does work in a proper install of 
rw0901 (if you have Windows on your PC, that is).

> The second question is about arima simulation.  I have
> an AR and MA process and need to simulate 200
> observations from these two models.  Don't know how to
> do.

Look at the example in ?filter in library(ts). That will
almost certainly not work if acf does not, though.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rhurlin at gwdg.de  Fri Feb 11 08:07:48 2000
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Fri, 11 Feb 2000 08:07:48 +0100
Subject: [R] Re: Install problems with RPgSQL
References: <38972CE1.D433532A@nceas.ucsb.edu>
Message-ID: <38A3B544.B03718B2@gwdg.de>

"Timothy H. Keitt" wrote:
> 
> If you have had problems with the latest configure script in RPgSQL,
> please try the version attached to this message.  Let me know if you
> have any problems.  Thanks.
> 
> Tim
> 

Sorry about my pausing in looking for a solution to install on a
FreeBSD-3.4 machine. PostgreSQL-6.5.3 is located at /usr/local/pgsql
with libraries in /usr/local/pgsql/lib and headers in
/usr/local/pgsql/include. This seems to be standard location on FreeBSD
machines (?).

I was confused on how to install your package the right way, because the
gcc did not found lpq on his place. 

Here my solution. It has two steps and works fine with your newest
version RPgSQL_0.5-1.tar.gz.


First I have to set two variables:

    setenv PG_LIB_DIR     /usr/local/pgsql/lib
    setenv PG_INCLUDE_DIR /usr/local/pgsql/include


Second I have to patch the configure script at line 577:

RPgSQL/configure

    576    if test $PG_LIB_DIR; then
    577       PKG_LIBS="$PKG_LIBS -L$PG_LIB_DIR -lpq"
                                  ^^^^^^^^^^^^^
    578       PKG_LDFLAGS="-L${PG_LIB_DIR}"
    579    else

Do you think it's possible to integrate these two changes in your
autoconfiguration?


Thanks,

Rainer
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From holzer at stat.math.ethz.ch  Fri Feb 11 08:16:17 2000
From: holzer at stat.math.ethz.ch (Peter Holzer)
Date: Fri, 11 Feb 2000 08:16:17 +0100 (MET)
Subject: [R] Creating efficiently a subset of a matrix
Message-ID: <14499.46913.287876.530790@sara.ethz.ch>

Dear R-helpers

I have the following problem: given a  m x n matrix A, I want to have just a
m x k submatrix B, with B[i,] = A[i, offset[i] + 1:k], e.g. from

> offset <- c(0, 0, 1)
> a <- matrix(1:9, 3)
> a
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9

the submatrix b

1 4
2 5
6 9

I can do this with a for loop or with sapply

> b <- sapply(seq(offset), function(x) a[x,offset[x]+1:2])
## result is transposed

However, comparing the two possibilities on a 10000 x 100 matrix and a
submatrix of 10000 x 50 it turned out (using system.time) that the for loop
was faster (about 20%).

Is there a more efficient way to achieve the desired result?

Thanks, Peter

-- 
____________________________________________________________

Peter Holzer                      phone: + 41 1 632 46 34
Seminar fuer Statistik, LEO C14   fax:   + 41 1 632 12 28
(Leonhardstr. 27)                  <holzer at stat.math.ethz.ch>
ETH (Federal Inst. Technology)
8092 Zurich                       http://www.stat.math.ethz.ch/~holzer/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb 11 09:07:10 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 11 Feb 2000 08:07:10 +0000 (GMT)
Subject: [R] Creating efficiently a subset of a matrix
In-Reply-To: <14499.46913.287876.530790@sara.ethz.ch>
Message-ID: <Pine.GSO.4.05.10002110755140.12096-100000@auk.stats>

On Fri, 11 Feb 2000, Peter Holzer wrote:

> I have the following problem: given a  m x n matrix A, I want to have just a
> m x k submatrix B, with B[i,] = A[i, offset[i] + 1:k], e.g. from
> 
> > offset <- c(0, 0, 1)
> > a <- matrix(1:9, 3)
> > a
>      [,1] [,2] [,3]
> [1,]    1    4    7
> [2,]    2    5    8
> [3,]    3    6    9
> 
> the submatrix b
> 
> 1 4
> 2 5
> 6 9
> 
> I can do this with a for loop or with sapply
> 
> > b <- sapply(seq(offset), function(x) a[x,offset[x]+1:2])
> ## result is transposed
> 
> However, comparing the two possibilities on a 10000 x 100 matrix and a
> submatrix of 10000 x 50 it turned out (using system.time) that the for loop
> was faster (about 20%).

Unless you used R-0.99.0, sapply _is_ a for loop.

> Is there a more efficient way to achieve the desired result?

Yes, matrix indexing (at least in theory).  You want the following elements
of `a':

1 1
2 1
3 2
1 2
1 2
2 3

and you can use that matrix as an index. As in

ind <- cbind(seq(nrow(a)), as.vector(outer(offset, seq(k), "+")))
matrix(a[ind],,k)
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    6    9

Now, your matrices are pretty large, and however I was doing it I would
do this in chunks of rows at a time.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jwilliams at commerce.otago.ac.nz  Sun Feb 13 04:32:18 2000
From: jwilliams at commerce.otago.ac.nz (John Williams)
Date: Sun, 13 Feb 2000 16:32:18 +1300
Subject: [R] Post Hoc Tests in ANOVA
References: <20000211114734.20126@hal.stat.unipd.it>
Message-ID: <38A625C2.369A7751@commerce.otago.ac.nz>

I am trying to produce post hoc tests for ANOVA in R, specifically
Tukey's HSD and Scheffes LSD.  

I suppose I could programme them myself, but I am a fan of Larry Wall's
statement that one of the greatest virtues of a programmer is laziness.
Also, K&R's oft-repeated statement of the UNIX philosphy: build on the
work of others (UNIX System V Programmer's Guide, p. 3) is a driving
force behind my sloth.

Does anyone know of a library containing routines such as these?

TIA

John
-------------- next part --------------
A non-text attachment was scrubbed...
Name: jwilliams.vcf
Type: text/x-vcard
Size: 215 bytes
Desc: Card for John Williams
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000213/d39e38bd/jwilliams.vcf

From kjetil.kjernsmo at astro.uio.no  Sun Feb 13 13:09:59 2000
From: kjetil.kjernsmo at astro.uio.no (Kjetil Kjernsmo)
Date: Sun, 13 Feb 2000 13:09:59 +0100 (MET)
Subject: [R] Underflow warnings?
Message-ID: <Pine.OSF.4.05.10002131258530.9925-100000@rukbat.uio.no>

Dear all,

I'm a bit concerned about underflow problems. Such problems typically
occur when two almost equal numbers are subtracted. I was wondering if R
has any mechanisms for warning users about potential problems, or if any
policy has been developed? 

To check, I just did:
> 1.0000000000000001 - 1
[1] 0
> 1.000000000000001 - 1
[1] 1.110223e-15
> 1.00000000000001 - 1
[1] 9.992007e-15

I guess many users are unaware of the potential problems caused by
underflow (i.e. garbage becoming significant), so perhaps R should issue
a warning?

Best,

Kjetil
-- 
Kjetil Kjernsmo
Graduate astronomy-student                    Problems worthy of attack
University of Oslo, Norway            Prove their worth by hitting back
E-mail: kjetikj at astro.uio.no                                - Piet Hein
Homepage <URL:http://www.astro.uio.no/~kjetikj/>
Webmaster at skepsis.no 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Sun Feb 13 18:58:53 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Sun, 13 Feb 2000 17:58:53 +0000 (GMT)
Subject: [R] Underflow warnings?
In-Reply-To: <Pine.OSF.4.05.10002131258530.9925-100000@rukbat.uio.no>
Message-ID: <Pine.LNX.4.10.10002131747380.13423-100000@gimel.biostat.washington.edu>

On Sun, 13 Feb 2000, Kjetil Kjernsmo wrote:

> Dear all,
> 
> I'm a bit concerned about underflow problems. Such problems typically
> occur when two almost equal numbers are subtracted. I was wondering if R
> has any mechanisms for warning users about potential problems, or if any
> policy has been developed? 
> 
> To check, I just did:
> > 1.0000000000000001 - 1
> [1] 0
> > 1.000000000000001 - 1
> [1] 1.110223e-15
> > 1.00000000000001 - 1
> [1] 9.992007e-15
> 
> I guess many users are unaware of the potential problems caused by
> underflow (i.e. garbage becoming significant), so perhaps R should issue
> a warning?

Checking for loss of precision would be a) hard, b) slow, c) probably
unreliable. We do provide the Machine() function that returns information
about the level of precision being used. 

In your first example, you would find that 1.0000000000000001 is equal to
1 up to machine precision

R> 1.0000000000000001
  [1] 1
 
The reason that testing is hard and unreliable is that there is very
little absolute loss of precision in the arithmetic operations. There can
be enormous relative loss of precision, but that depends critically on how
big the correct final answer is.

Eg 
	exp(1.0000000000000001-1)
or
	2+(1.0000000000000001-1)
have essentially full precision.

A bigger issue, which we _have_ been working on, is getting closer to full 
precision for the probability and quantile functions. 


	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rosm at ufrima.imag.fr  Mon Feb 14 09:53:54 2000
From: rosm at ufrima.imag.fr (ros mathieu)
Date: Mon, 14 Feb 2000 09:53:54 +0100
Subject: [R] par(fig) problem
Message-ID: <38A7C2A1.72D0C3A1@ufrima.imag.fr>

hello R-users,
I'd like to plot four graphics on the same page but with different
sizes. I've tried to use :

par(fig=c(0,0.5,0,0.6))
plot(fig1)
par(fig=c(0.5,1,0,0.6))
plot(fig2)
etc...

but when a figure is plotted, it erase the previous.
I've tried to pass 'new=T' to plot function but it's not possible.
What can I do ? is it a  bug ?
I've already reported this a 2 or 3 month ago but I can't find out the
answers I get.

    Mathieu

I run R 0.99-0 on a linux mandrake 7.0

--
----------------------------------------------------------------------
Mathieu Ros - 13 rue b?vi?re - 38000 GRENOBLE - 04 76 491 370
http://mathieu.ros.free.fr/
DESS ing?nierie math?matique (biostatistiques)
Universite Joseph Fourier, Grenoble
----------------------------------------------------------------------
l'exp?rience est le nom que chacun donne a ses erreurs. Wilde



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From manuel.castejon at dim.unirioja.es  Mon Feb 14 10:18:29 2000
From: manuel.castejon at dim.unirioja.es (Manuel Castejon Limas)
Date: Mon, 14 Feb 2000 10:18:29 +0100
Subject: [R] Error in the inverse of a diagonal matrix?
Message-ID: <001001bf76cc$74b729b0$b1eb92c1@unirioja.es>

I?m new to R so maybe this issue has been asked before and I still could not read the complete set of past messages sent to the list.
I found a weird behabiour that I will explain with a simple example. Lets consider the following block of commands:

> x <- diag(c(1,4,10))
> x
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    4    0
[3,]    0    0   10

> invx <- x^-1
> invx
     [,1] [,2] [,3]
[1,]    1  Inf  Inf
[2,]  Inf 0.25  Inf
[3,]  Inf  Inf  0.1

I would really appreciate if the result would have been
     [,1] [,2] [,3]
[1,]  1    0    0
[2,]  0  0.25  0
[3,]  0    0  0.1

most of all because
> x %*% invx
     [,1] [,2] [,3]
[1,]  NaN  NaN  NaN
[2,]  NaN  NaN  NaN
[3,]  NaN  NaN  NaN

does not really satisfies me :-)

I?m using version 0.90.1.

Is this what it was meant to be?
Is this a known bug?
Am I doing something wrong?
Anybody knows a workaround (for a general matrix, not for a diagonal one)?

I would really appreciate your help and support.
Thanks in advance.


------------------------------------------------------------------------------------------------------------------------------------------------------
                          Manuel Castejon Limas.
                     Manuel.Castejon at dim.unirioja.es 
Departamento de Ingenieria Mecanica.   | Mechanical Engineering Department.
Area de Proyectos de Ingenieria.       | Project Management Area.
Universidad de La Rioja.               | University of La Rioja.
Espa?a.                                | Spain.
------------------------------------------------------------------------------------------------------------------------------------------------------

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000214/f7312c35/attachment.html

From manuel.castejon at dim.unirioja.es  Mon Feb 14 10:25:45 2000
From: manuel.castejon at dim.unirioja.es (Manuel Castejon Limas)
Date: Mon, 14 Feb 2000 10:25:45 +0100
Subject: [R] Error in the qchisq with ncp parameter
Message-ID: <001d01bf76cd$79175a10$b1eb92c1@unirioja.es>

I?m new to R (using version 0.90.1.) and this list so maybe this issue has been asked before and I still could not read the complete set of past messages sent to the list.
Here is a simple example.

> qchisq(0.99,5,ncp=0.4)
Error in qnchisq(p, df, ncp) : unimplemented real function

even when the help(qchisq) specifies that I could use the ncp parameter.


Is this a known bug?
Am I doing something wrong?
Anybody knows a workaround (for a general matrix, not for a diagonal one)?

I would really appreciate your help and support.
Thanks in advance.


------------------------------------------------------------------------------------------------------------------------------------------------------
                          Manuel Castejon Limas.
                    Manuel.Castejon at dim.unirioja.es 
Departamento de Ingenieria Mecanica.   | Mechanical Engineering Department.
Area de Proyectos de Ingenieria.       | Project Management Area.
Universidad de La Rioja.               | University of La Rioja.
Espa?a.                                | Spain.
------------------------------------------------------------------------------------------------------------------------------------------------------

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000214/7321076f/attachment.html

From gb at stat.umu.se  Mon Feb 14 10:35:21 2000
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 14 Feb 2000 10:35:21 +0100 (CET)
Subject: [R] Error in the inverse of a diagonal matrix?
In-Reply-To: <001001bf76cc$74b729b0$b1eb92c1@unirioja.es>
Message-ID: <Pine.LNX.4.10.10002141033230.29219-100000@pc16.stat.umu.se>

On Mon, 14 Feb 2000, Manuel Castejon Limas wrote:

> I?m new to R so maybe this issue has been asked before and I still could not read the complete set of past messages sent to the list.
> I found a weird behabiour that I will explain with a simple example. Lets consider the following block of commands:
> 
> > x <- diag(c(1,4,10))
> > x
>      [,1] [,2] [,3]
> [1,]    1    0    0
> [2,]    0    4    0
> [3,]    0    0   10
> 
> > invx <- x^-1
> > invx
>      [,1] [,2] [,3]
> [1,]    1  Inf  Inf
> [2,]  Inf 0.25  Inf
> [3,]  Inf  Inf  0.1
> 
> I would really appreciate if the result would have been
>      [,1] [,2] [,3]
> [1,]  1    0    0
> [2,]  0  0.25  0
> [3,]  0    0  0.1
> 
> most of all because
> > x %*% invx
>      [,1] [,2] [,3]
> [1,]  NaN  NaN  NaN
> [2,]  NaN  NaN  NaN
> [3,]  NaN  NaN  NaN
> 
> does not really satisfies me :-)
> 
> I?m using version 0.90.1.
> 
> Is this what it was meant to be?
> Is this a known bug?
> Am I doing something wrong?
> Anybody knows a workaround (for a general matrix, not for a diagonal one)?
> 
> I would really appreciate your help and support.
> Thanks in advance.
> 
> 
> -------------------------------------------------------------------------------------------------------------------------------------------------------
>                           Manuel Castejon Limas.
>                      Manuel.Castejon at dim.unirioja.es 
> Departamento de Ingenieria Mecanica.   | Mechanical Engineering Department.
> Area de Proyectos de Ingenieria.       | Project Management Area.
> Universidad de La Rioja.               | University of La Rioja.
> Espa?a.                                | Spain.
> -------------------------------------------------------------------------------------------------------------------------------------------------------

You should use  solve(x) instead of x^-1, which inverts element-wise.

G?ran
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Mon Feb 14 10:59:36 2000
From: plummer at iarc.fr (Martyn Plummer)
Date: Mon, 14 Feb 2000 10:59:36 +0100 (CET)
Subject: [R] Error in the inverse of a diagonal matrix?
In-Reply-To: <001001bf76cc$74b729b0$b1eb92c1@unirioja.es>
Message-ID: <XFMail.000214105936.plummer@iarc.fr>

Arithmetic operations act element-wise on matrices, which is why you
get 1/0 = Inf (NB the "*" operator also acts element-wise, which is why
you need to use the operator "%*%" for matrix multiplication).

To invert a square matrix use the solve() function. If you know that the
matrix is diagonal then it is more efficient to use

diag(1/(diag(x))

Martyn

On 14-Feb-00 Manuel Castejon Limas wrote:
> Im new to R so maybe this issue has been asked before and I still could not
> read the complete set of past messages sent to the list.
> I found a weird behabiour that I will explain with a simple example. Lets
> consider the following block of commands:
> 
>> x <- diag(c(1,4,10))
>> x
>      [,1] [,2] [,3]
> [1,]    1    0    0
> [2,]    0    4    0
> [3,]    0    0   10
> 
>> invx <- x^-1
>> invx
>      [,1] [,2] [,3]
> [1,]    1  Inf  Inf
> [2,]  Inf 0.25  Inf
> [3,]  Inf  Inf  0.1
> 
> I would really appreciate if the result would have been
>      [,1] [,2] [,3]
> [1,]  1    0    0
> [2,]  0  0.25  0
> [3,]  0    0  0.1
> 
> most of all because
>> x %*% invx
>      [,1] [,2] [,3]
> [1,]  NaN  NaN  NaN
> [2,]  NaN  NaN  NaN
> [3,]  NaN  NaN  NaN
> 
> does not really satisfies me :-)
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetil.kjernsmo at astro.uio.no  Mon Feb 14 11:53:02 2000
From: kjetil.kjernsmo at astro.uio.no (Kjetil Kjernsmo)
Date: Mon, 14 Feb 2000 11:53:02 +0100 (MET)
Subject: [R] creating a grid of function values
In-Reply-To: <Pine.GSO.4.05.10002102138420.26006-100000@auk.stats>
Message-ID: <Pine.OSF.4.05.10002141151070.9925-100000@rukbat.uio.no>

On Thu, 10 Feb 2000, Prof Brian D Ripley wrote:

>On 10 Feb 2000, Douglas Bates wrote:
>
>> I want to create a grid of function values for use in `contour' or
>> `persp'.  The function is the log-likelihood for the gamma.  The
>> sample is stored as vector of length 20 called `Survival'.

I'm curious, how would one do this in n dimensions?

Best,

Kjetil
-- 
Kjetil Kjernsmo
Graduate astronomy-student                    Problems worthy of attack
University of Oslo, Norway            Prove their worth by hitting back
E-mail: kjetikj at astro.uio.no                                - Piet Hein
Homepage <URL:http://www.astro.uio.no/~kjetikj/>
Webmaster at skepsis.no 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Feb 14 14:10:40 2000
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 14 Feb 2000 08:10:40 -0500
Subject: [R] par(fig) problem
In-Reply-To: <38A7C2A1.72D0C3A1@ufrima.imag.fr>
Message-ID: <3.0.5.32.20000214081040.00a26bf0@mcmail.cis.mcmaster.ca>

At 09:53 AM 2/14/2000 +0100, ros mathieu wrote:
>I'd like to plot four graphics on the same page but with different
>sizes. I've tried to use :
>
>par(fig=c(0,0.5,0,0.6))
>plot(fig1)
>par(fig=c(0.5,1,0,0.6))
>plot(fig2)
>etc...
>
>but when a figure is plotted, it erase the previous.
>I've tried to pass 'new=T' to plot function but it's not possible.
>What can I do ? is it a  bug ?
>I've already reported this a 2 or 3 month ago but I can't find out the
>answers I get.
>


Dear Mathieu,

See the documentation (in par) for mfcol and mfrow, which allow you to plot an array of figures, respectively by columns and rows. For example
	par(mfrow=c(3,2))
will direct subsequent plots to a 3 x 2 array, filled by rows.

I hope that this helps,
John




|----------------------------------------------------|
| John Fox                          jfox at McMaster.ca |
| Department of Sociology        McMaster University |
|----------------------------------------------------|
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Feb 14 14:34:34 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Feb 2000 14:34:34 +0100
Subject: [R] par(fig) problem
In-Reply-To: John Fox's message of "Mon, 14 Feb 2000 08:10:40 -0500"
References: <3.0.5.32.20000214081040.00a26bf0@mcmail.cis.mcmaster.ca>
Message-ID: <x2ya8newlx.fsf@blueberry.kubism.ku.dk>

John Fox <jfox at mcmaster.ca> writes:

> At 09:53 AM 2/14/2000 +0100, ros mathieu wrote:
> >I'd like to plot four graphics on the same page but with different
> >sizes. I've tried to use :
...
> 
> See the documentation (in par) for mfcol and mfrow, which allow you to plot an array of figures, respectively by columns and rows. For example
> 	par(mfrow=c(3,2))
> will direct subsequent plots to a 3 x 2 array, filled by rows.
> 
> I hope that this helps,

Um, John, I think you missed the "with different sizes" bit there...

Ros: If you really want to overplot, you can use par(new=T) between plots,
but try layout() instead.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rosm at ufrima.imag.fr  Mon Feb 14 15:40:16 2000
From: rosm at ufrima.imag.fr (ros mathieu)
Date: Mon, 14 Feb 2000 15:40:16 +0100
Subject: [R] summary : par(fig)
Message-ID: <38A813CF.85532DBF@ufrima.imag.fr>

many thanks to P. Dalgaard, J. Fox, J. Lemon, JE. Paradis and J. Polzehl
for their quick replies.
The original posting is at the end of this summary.
I've not well explained myself but I don't wanted to use par(mfrow) or
par(mfcol) because I wanted to plot very different graphics and this
solution doesn't match my needs.

E. Paradis and P. Dalgaard made me discover a new (for me!) function :
layout() which may do the job (I'm exploring the possibilities).

But I finally chose the P. Dalgaard' s solution of setting par(new=T)
between each plot say:
par(fig=c(0,0.5,0,0.6))
plot(fig1)
par(fig=c(0.5,1,0,0.6),new=T)
plot(fig2)
etc.

thanks very much,
    Mathieu

----------------------------------------------------------------------
Mathieu Ros - 13 rue b?vi?re - 38000 GRENOBLE - 04 76 491 370
http://mathieu.ros.free.fr/
DESS ing?nierie math?matique (biostatistiques)
Universite Joseph Fourier, Grenoble
----------------------------------------------------------------------
l'exp?rience est le nom que chacun donne a ses erreurs. Wilde


-- original posting : --

hello R-users,

I'd like to plot four graphics on the same page but with different

sizes. I've tried to use :

par(fig=c(0,0.5,0,0.6))

plot(fig1)

par(fig=c(0.5,1,0,0.6))

plot(fig2)

etc...

but when a figure is plotted, it erase the previous.

I've tried to pass 'new=T' to plot function but it's not possible.

What can I do ? is it a  bug ?

I've already reported this a 2 or 3 month ago but I can't find out the

answers I get.

    Mathieu

I run R 0.99-0 on a linux mandrake 7.0


-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000214/4643ea39/attachment.html

From j.logsdon at lancaster.ac.uk  Mon Feb 14 16:49:03 2000
From: j.logsdon at lancaster.ac.uk (John Logsdon)
Date: Mon, 14 Feb 2000 15:49:03 +0000 (GMT)
Subject: Distribution and quantile precision (was [R] Underflow warnings?)
In-Reply-To: <Pine.LNX.4.10.10002131747380.13423-100000@gimel.biostat.washington.edu>
Message-ID: <Pine.LNX.4.10.10002141542040.28563-100000@mercury.quantex>



On Sun, 13 Feb 2000, Thomas Lumley wrote:

> 
> A bigger issue, which we _have_ been working on, is getting closer to full 
> precision for the probability and quantile functions. 
> 

Ah - will this include functions for the logs of densities and quantiles?
I recently fell flat on my nose when, in the middle of a very long (in
time) calculation I was suddenly calculating log(dnorm) where the variance
was reducing (as it should) without thinking too much ('cos it was easier
to swap distributions).  This meant that the (x-xbar)/sigma was increasing
to the point where it all blew up.  Mea culpa I know.

I recoded it appropriately and it worked fine.  Kept the chips burning all
Christmas though.

So for those of use that regularly use maximum likelihood, it would be
nice to have log(pdist), log(1-pdist) and log(ddist) where dist is as you
like it - norm to start with.

\J

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Mon Feb 14 17:33:04 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Mon, 14 Feb 2000 16:33:04 +0000 (GMT)
Subject: Distribution and quantile precision (was [R] Underflow warnings?)
In-Reply-To: <Pine.LNX.4.10.10002141542040.28563-100000@mercury.quantex>
Message-ID: <Pine.LNX.4.10.10002141629470.26488-100000@gimel.biostat.washington.edu>

On Mon, 14 Feb 2000, John Logsdon wrote:
> 
> On Sun, 13 Feb 2000, Thomas Lumley wrote:
> 
> > 
> > A bigger issue, which we _have_ been working on, is getting closer to full 
> > precision for the probability and quantile functions. 
> >  
> Ah - will this include functions for the logs of densities and quantiles?


Yes: eg from the pre1.0.0 help page for pchisq()

Usage:

     dchisq(x, df, ncp=0, log = FALSE)
     pchisq(q, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
     qchisq(p, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
     rchisq(n, df)


so we at least have syntax for log densities and log probabilities and
for lower as well as upper tail probabilities. I don't know if all the
underlying functions have been updated or only some of them.

	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Mon Feb 14 18:03:16 2000
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Mon, 14 Feb 2000 18:03:16 +0100 (MET)
Subject: Distribution and quantile precision (was [R] Underflow warnings?)
In-Reply-To: <Pine.LNX.4.10.10002141629470.26488-100000@gimel.biostat.washington.edu> from "Thomas Lumley" at Feb 14, 2000 04:33:04 PM
Message-ID: <200002141703.SAA07807@alpha.luc.ac.be>


> 
> On Mon, 14 Feb 2000, John Logsdon wrote:
> > 
> > On Sun, 13 Feb 2000, Thomas Lumley wrote:
> > 
> > > 
> > > A bigger issue, which we _have_ been working on, is getting closer to full 
> > > precision for the probability and quantile functions. 
> > >  
> > Ah - will this include functions for the logs of densities and quantiles?
> 
> 
> Yes: eg from the pre1.0.0 help page for pchisq()
> 
> Usage:
> 
>      dchisq(x, df, ncp=0, log = FALSE)
>      pchisq(q, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
>      qchisq(p, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
>      rchisq(n, df)
> 
> 
> so we at least have syntax for log densities and log probabilities and
> for lower as well as upper tail probabilities. I don't know if all the
> underlying functions have been updated or only some of them.

Unless errors have crept in, everything is working. Jim


> 
> 	-thomas
> 
> Thomas Lumley
> Assistant Professor, Biostatistics
> University of Washington, Seattle
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Feb 14 18:28:01 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 14 Feb 2000 17:28:01 +0000 (GMT)
Subject: Distribution and quantile precision (was [R] Underflow warnings?)
In-Reply-To: <Pine.LNX.4.10.10002141629470.26488-100000@gimel.biostat.washington.edu>
Message-ID: <Pine.GSO.4.05.10002141724200.1178-100000@auk.stats>

On Mon, 14 Feb 2000, Thomas Lumley wrote:

> On Mon, 14 Feb 2000, John Logsdon wrote:
> > 
> > On Sun, 13 Feb 2000, Thomas Lumley wrote:
> > 
> > > 
> > > A bigger issue, which we _have_ been working on, is getting closer to full 
> > > precision for the probability and quantile functions. 
> > >  
> > Ah - will this include functions for the logs of densities and quantiles?
> 
> 
> Yes: eg from the pre1.0.0 help page for pchisq()
> 
> Usage:
> 
>      dchisq(x, df, ncp=0, log = FALSE)
>      pchisq(q, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
>      qchisq(p, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
>      rchisq(n, df)
> 
> 
> so we at least have syntax for log densities and log probabilities and
> for lower as well as upper tail probabilities. I don't know if all the
> underlying functions have been updated or only some of them.

They are all in 0.99.0, although not necessarily in the final (most
accurate) form. (There were some changes very close to 0.99.0's release,
and I don't recall if all the tweaks made it.) From 0.99.0's NEWS

    o	All the DPQ {probability density quantile} functions have new
	arguments, "lower_tail = TRUE" and "log{_p} = FALSE".  This allows
	more precise results when values would be close to 0 or 1.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rab at nauticom.net  Mon Feb 14 21:36:32 2000
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon, 14 Feb 2000 20:36:32 +0000
Subject: [R] Dates in R
References: <38A29FC6.F8DCC805@EUnet.at> <x27lgdqons.fsf@blueberry.kubism.ku.dk>
Message-ID: <38A86750.B45ED40D@nauticom.net>

Hi,

My dates are printing as 01/01/100 instead of 01/01/2000. I can't find a way to
get mm/dd/yyyy type format. I've installed both chron and date.


Rick Bilonick

--
Statistical Consulting for Business & Industry
mailto:rab at nauticom.net
efax:  508 445 5821
voice: 412 831 4509


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paul at stat.auckland.ac.nz  Mon Feb 14 21:00:49 2000
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 15 Feb 2000 09:00:49 +1300
Subject: [R] par(fig) problem
References: <38A7C2A1.72D0C3A1@ufrima.imag.fr>
Message-ID: <008701bf7726$304b0a30$175dd882@stat.auckland.ac.nz>

hi


> I'd like to plot four graphics on the same page but with different
> sizes. I've tried to use :
> 
> par(fig=c(0,0.5,0,0.6))
> plot(fig1)
> par(fig=c(0.5,1,0,0.6))
> plot(fig2)
> etc...


in case it helps ...

    layout(rbind(c(0, 0), c(1, 2)), heights=c(4, 6))

will do the arrangement described above and ...

    layout.show(2) 

will show what the arrangement looks like.

paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Mon Feb 14 20:53:27 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Mon, 14 Feb 2000 19:53:27 +0000 (GMT)
Subject: [R] Dates in R
In-Reply-To: <38A86750.B45ED40D@nauticom.net>
Message-ID: <Pine.LNX.4.10.10002141947250.26488-100000@gimel.biostat.washington.edu>

On Mon, 14 Feb 2000, Richard A. Bilonick wrote:

> Hi,
> 
> My dates are printing as 01/01/100 instead of 01/01/2000. I can't find a way to
> get mm/dd/yyyy type format. I've installed both chron and date.
> 

This shouldn't happen with date unless you actually specify the date as
100CE rather than 2000CE.

I get
R> d1<-as.date("14 Feb 2000")
R> d2<-as.date("2/14/2000")
R> d3<-mdy.date(2,14,2000)
R> d1
[1] 14Feb2000
R> d2
[1] 14Feb2000
R> d3
[1] 14Feb2000
R> date.mmddyy(d1)
[1] "2/14/2000"
R> date.mmddyy(d2)
[1] "2/14/2000"
R> date.mmddyy(d3)
[1] "2/14/2000"
R> date.mmddyyyy(d1)
[1] "2/14/2000"

In fact, as the default is to treat two-digit years as being in the 20th
century you even get
R> as.date("31Dec99")+1
[1] 1Jan2000


I don't know about chron, though.


	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at epm.net.co  Mon Feb 14 22:43:57 2000
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Mon, 14 Feb 2000 16:43:57 -0500
Subject: [R]:  Noncentral F distribution 
References: <Pine.LNX.4.10.10002131747380.13423-100000@gimel.biostat.washington.edu>
Message-ID: <38A8771C.6FB7C2CF@epm.net.co>

Dear all,

How can I calculate the Noncentral F distribution?
I need to calculate the probability of the error type II or the Power of some
experiment design.

Thank you very much for you help.

Kenneth Cabrera
Universidad Nacional de Colombia, Sede Medell?n.
ICNE
Instituto de Ciencias Naturales y Ecolog?a
Medellin, Antioquia.
Colombia, S.A.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Feb 14 22:53:54 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 14 Feb 2000 21:53:54 +0000 (GMT)
Subject: [R] Merge?
In-Reply-To: <Pine.GSO.4.05.10002040803420.10301-100000@auk.stats>
Message-ID: <Pine.GSO.4.05.10002142152170.23080-100000@auk.stats>

On Fri, 4 Feb 2000, Prof Brian D Ripley wrote:

> On Thu, 3 Feb 2000, R. Herold wrote:
> 
> > I see that feature freeze for a better than ever R has been announced. May I
> > ask if there will be or could be "merge" function for data frames? I believe
> 
> Not for 0.99.0 due on Monday.
> 
> > it would be very nice if this were "centrally" implemented (with regard to
> > my humble steps to writing such a function and the related error and other
> > precautions). I know from VR2R.pdf (courtesy Profs. Venables and Ripley)
> > that the "Functions crosstabs [...], by and merge [...] do not exist in R.",
> > but perhaps someone can suggest such a merge function, just as a "by"
> > function was suggested by Peter Dalgaard on 31. January?
> 
> VR2R.* was frozen last August and will not be updated (it complements an
> obselete edition). VR3R.* is kept up to date.
> 
> Yes, versions of `by' and `merge' would be a good idea. We now have
> `ftable' that does some of the crosstabs functionality.

R 1.0.0 (due on 2000/2/29) will have `by' and `merge', and the development
version will have them by tomorrow.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Mon Feb 14 22:58:19 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 14 Feb 2000 15:58:19 -0600
Subject: [R]:  Noncentral F distribution
In-Reply-To: Kenneth Cabrera's message of "Mon, 14 Feb 2000 16:43:57 -0500"
References: <Pine.LNX.4.10.10002131747380.13423-100000@gimel.biostat.washington.edu> <38A8771C.6FB7C2CF@epm.net.co>
Message-ID: <6rya8n5tvo.fsf@franz.stat.wisc.edu>

Kenneth Cabrera <krcabrer at epm.net.co> writes:

> How can I calculate the Noncentral F distribution?
> I need to calculate the probability of the error type II or the Power of some
> experiment design.

In 0.99.0 the pf function takes an argument ncp, which is the
noncentrality parameter.

FDist                  package:base                  R Documentation

The F Distribution

Description:

     Density, distribution function, quantile function and random
     generation for the F distribution with `df1' and `df2' degrees of
     freedom (and optional non-centrality parameter `ncp').

Usage:

     df(x, df1, df2, log = FALSE)
     pf(q, df1, df2, ncp=0, lower.tail = TRUE, log.p = FALSE)
     qf(p, df1, df2,        lower.tail = TRUE, log.p = FALSE)
     rf(n, df1, df2)

Arguments:

    x, q: vector of quantiles.

       p: vector of probabilities.

       n: number of observations to generate.

df1, df2: degrees of freedom.

     ncp: non-centrality parameter.

log, log.p: logical; if TRUE, probabilities p are given as log(p).

lower.tail: logical; if TRUE (default), probabilities are P[X <= x],
          otherwise, P[X > x].
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kelley at Phys.Ocean.Dal.CA  Mon Feb 14 23:01:30 2000
From: kelley at Phys.Ocean.Dal.CA (Dan E. Kelley)
Date: Mon, 14 Feb 2000 18:01:30 -0400 (AST)
Subject: [R] a nls(~...) question for R-0.90.1 (redhat-linux)
Message-ID: <Pine.LNX.4.10.10002141801130.15719-300000@Intrusion.Phys.Ocean.Dal.Ca>

Please excuse a question from somebody who is new to R.

I'm using R version 0.90.1 (from an RPM package for redhat-linux)
and am running into difficulties with code that looks like:

	nls(~ relative.error(..., x, y),data,start=list(...))

I've taken this code, which attempts to do a nonlinear curve-fit with
weighted deviations, from section 10.3 of the book 'Statistical models
in S' by Chambers and Hastings.

Attached are 'test.ess' (my program file) and 'test.dat' (a data
file).  The files are very short (24 lines and 5 lines, respectively),
and I'm hoping that somebody on this list would be willing to have a
look and see why I get an error (as I've indicated in the first few
comment-lines of the 'test.ess' file).

Maybe my question is even more basic.  Does R support
	library(nls)
	nls(~ ...)
or only the
	library(nls)
	nls(y ~ ...)
form?  If only the latter, how may I specify weights for the data?

I send thanks in advance for any help that folks can give me on this
basic problem.

Dan E. Kelley                   internet:   mailto:Dan.Kelley at Dal.CA
Oceanography Department         phone:                 (902)494-1694
Dalhousie University            fax:                   (902)494-2885
Halifax, NS, CANADA, B3H 4J1    http://www.phys.ocean.dal.ca/~kelley
-------------- next part --------------
# Demonstrate problem using nls(), yielding the error:
#
# Error in relerr(A, B, x, y) : Object "A" not found
#
#
# QUESTION: any advice as to how I can make this work?
#
# PS: For reference, I'm trying to copy what's in section 10.3 
# of Chambers and Hastie's 'Statistical models in S', and my
# platform is redhat-linux version 6.1, with R version 0.98.1-1.

library(nls)
mydata <- read.table("test.dat", header=TRUE, col.names=list("x","y"))
attach(mydata)

relerr <- function(A, B, z, observed) {
	pred <- A + B * x
	(pred - observed) / sqrt(observed)
}

nls.test <- nls(~ relerr(A, B, x, y), 
	mydata,
	start = list(A = 9, B = 2))
summary(nls.test)
-------------- next part --------------
x	y
1	11
2	21
3	31
4	41

From rossini at biostat.washington.edu  Mon Feb 14 23:52:09 2000
From: rossini at biostat.washington.edu (A.J. Rossini)
Date: 14 Feb 2000 14:52:09 -0800
Subject: [R] FAQ and Answer: How to convert factors back to integers
Message-ID: <87k8k78kiu.fsf@alpha.cfas.washington.edu>



(thanks to thomas for assistance; I'm posting this for archival
reasons).

Question:

My silly dataset looks like "00223423", "00234234", ... 
and when I read it in, I get a factor which looks like and
integer.  How do I convert it back?

(i.e. I've got something like:
> hivplasma
 [1] 00050400 00219000 00136000 00000906 00142000 00002150 00000400 00001880
 [9] 00000200 00000400 00115000 00000924 00051500 00000216 00007670 00000200
[17] 00538000 00001720 00000738 00000400 00759000 00023900 00002166 00000200
[25] 00000200 00185000 00002160 00003056 00002770 00002040 00000200 00000200
[33] 00000582 00054898 00003312 00002010 00010365 00000966 00000465 00000200
[41] 00000400 00480731 00000931 00790349 00033402 00000200 00000200 00000400
[49] 00760993 00000649 00000511 01611560 00009509 00001181 00000400 00053308
[57] 00000939 00001229 00006537 00000400 00000400 00141695 00001471 00000490
[65] 00004674 00001095 00000872 00002461 00000400 00000400 00144266 00394994
[73] 00550144 00015851 00000400 00000000
Levels:  00000000 00000200 00000216 00000400 00000465 00000490 00000511 00000582 00000649 00000738 00000872 00000906 00000924 00000931 00000939 00000966 00001095 00001181 00001229 00001471 00001720 00001880 00002010 00002040 00002150 00002160 00002166 00002461 00002770 00003056 00003312 00004674 00006537 00007670 00009509 00010365 00015851 00023900 00033402 00050400 00051500 00053308 00054898 00115000 00136000 00141695 00142000 00144266 00185000 00219000 00394994 00480731 00538000 00550144 00759000 00760993 00790349 01611560 
> 
)

Answer:

hivplasma.integer.NOT.FACTOR <- 
	as.numeric(levels(hivplasma))[codes(hivplasma)]

best,
-tony

-- 
A.J. Rossini		       Research Assistant Professor of Biostatistics 
Biostatistics/Univ. of Washington  (Th)	Box 357232   206-543-1044 (3286=fax)
Center for AIDS Research/HMC/UW	  (M/F)	Box 359931   206-731-3647 (3693=fax)
VTN/SCHARP/FHCRC		 (Tu/W)	Box 358080   206-667-7025 (4812=fax)
rossini@(biostat.washington.edu|u.washington.edu|hivnet.fhcrc.org)
http://www.biostat.washington.edu/~rossini

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Feb 15 00:12:45 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Feb 2000 00:12:45 +0100
Subject: [R] FAQ and Answer: How to convert factors back to integers
In-Reply-To: rossini@biostat.washington.edu's message of "14 Feb 2000 14:52:09 -0800"
References: <87k8k78kiu.fsf@alpha.cfas.washington.edu>
Message-ID: <x2g0uvv0nm.fsf@blueberry.kubism.ku.dk>

rossini at biostat.washington.edu (A.J. Rossini) writes:


> 	as.numeric(levels(hivplasma))[codes(hivplasma)]
                                      ^^^^^

Whoops. Make that as.integer(), codes() has some Splus-compatible
breakage built into it:

> f<-factor(1:10)
> f
 [1] 1  2  3  4  5  6  7  8  9  10
Levels:  1 2 3 4 5 6 7 8 9 10 
> as.numeric(levels(f))[codes(f)]
 [1]  1  3  4  5  6  7  8  9 10  2

It happens because 10 sorts between 1 and 2, alphabetically. Yes, it
is silly... 

If you're not badly squeezed for space, as.numeric(as.character(f))
works too, and is easier to remember.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Feb 15 00:26:08 2000
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 15 Feb 2000 00:26:08 +0100 (CET)
Subject: [R] nls question
In-Reply-To: <Pine.LNX.4.10.10002141033230.29219-100000@pc16.stat.umu.se>
Message-ID: <Pine.LNX.4.10.10002150009190.8023-100000@pc16.stat.umu.se>

I have two functions, tids1 and tids2:

tids1 <- function(W, w)
  {
    nls(W ~ w %*% beta,
        data = parent.frame(0),
        start = list(beta = rep(0, ncol(w)) ) )
}
    
tids2 <- function(W, w)
{
  X.1 <- w[, 1]
  X.2 <- w[, 2]
  
  nls(W ~ X.1 * beta1 + X.2 * beta2,
      data = parent.frame(0),
      start = list(beta1 = 0, beta2 = 0))
}

I want something like tids1, but only tids2 works:

> tids1(Y, X)
Error in qr.qty(QR, resid) : qr and y must have the same number of rows

> tids2(Y, X)
Nonlinear regression model
  model:  W ~ X.1 * beta1 + X.2 * beta2 
   data:  parent.frame 0 
   beta1    beta2 
1.200331 1.027278 
 residual sum-of-squares:  5.358129 

Q: How do I write a _general_ tids2?
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Tue Feb 15 00:46:21 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 14 Feb 2000 17:46:21 -0600
Subject: [R] nls question
In-Reply-To: G?ran Brostr?m's message of "Tue, 15 Feb 2000 00:26:08 +0100 (CET)"
References: <Pine.LNX.4.10.10002150009190.8023-100000@pc16.stat.umu.se>
Message-ID: <6ritzr5ovm.fsf@franz.stat.wisc.edu>

=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?= <gb at stat.umu.se> writes:

> I have two functions, tids1 and tids2:
> 
> tids1 <- function(W, w)
>   {
>     nls(W ~ w %*% beta,
>         data = parent.frame(0),
>         start = list(beta = rep(0, ncol(w)) ) )
> }
>     
> tids2 <- function(W, w)
> {
>   X.1 <- w[, 1]
>   X.2 <- w[, 2]
>   
>   nls(W ~ X.1 * beta1 + X.2 * beta2,
>       data = parent.frame(0),
>       start = list(beta1 = 0, beta2 = 0))
> }
> 
> I want something like tids1, but only tids2 works:
> 
> > tids1(Y, X)
> Error in qr.qty(QR, resid) : qr and y must have the same number of rows
> 
> > tids2(Y, X)
> Nonlinear regression model
>   model:  W ~ X.1 * beta1 + X.2 * beta2 
>    data:  parent.frame 0 
>    beta1    beta2 
> 1.200331 1.027278 
>  residual sum-of-squares:  5.358129 
> 
> Q: How do I write a _general_ tids2?

The nls function has an argument "algorithm" which can be set to
"plinear" for partially linear models.  This will fits exactly this
kind of model, assuming that the matrix w itself depends on some
parameters (if it doesn't you have a linear regression model and no
need to use nls).

Look at
 example(nls)
to see how that argument is used.


 nls> fm2DNase1 <- nls(density ~ 1/(1 + exp((xmid - log(conc))/scal)), 
     data = DNase1, start = list(xmid = 0, scal = 1), alg = "plinear", 
     trace = TRUE)
 0.7139315 : 0.000000 1.000000 1.453853 
 0.1445295 : 1.640243 1.390186 2.461754 
 0.008302151 : 1.620899 1.054228 2.478388 
 0.004794192 : 1.485226 1.043709 2.347334 
 0.004789569 : 1.483130 1.041468 2.345218 
 0.004789569 : 1.483090 1.041455 2.345180 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From datamanagement at email.com  Tue Feb 15 01:11:09 2000
From: datamanagement at email.com (a s)
Date: Mon, 14 Feb 2000 19:11:09 -0500 (EST)
Subject: [R] Help with for
Message-ID: <384540157.950573469170.JavaMail.root@web03_mc.mail.com>

I haven't been able to solve two issues, really appreciate any help.

Q1. Why this one goes like that? (could it be a bug?):

What I want:
> J_c(1,2,3)
> MA_NA
> MA[1]_min(J[1:2])
> MA[2]_min(J[2:3])
> MA
[1] 1 2

Good, so now lets do it a little more faster (since the real vectors have
over 15000 obs):

> for (i in 1:2) MA[i]_min(J[i:i+1])
> MA
[1] 2 3

It does the same with any function instead of min.

Q2. The former type of job works better with sapply (or the like), but when
FUN returns a vector, I haven't been able to get a matrix instead of a list
(simplify=TRUE, does not make any difference). Any way to avoid converting
list into matrix after sapply??

Thank you very much,

Alex Ahgarin
Data Management Dpt.
IDS
Washington, US

-----------------------------------------------
FREE! The World's Best Email Address @email.com
Reserve your name now at http://www.email.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Tue Feb 15 01:25:49 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Mon, 14 Feb 2000 16:25:49 -0800 (PST)
Subject: [R] Help with for
In-Reply-To: <384540157.950573469170.JavaMail.root@web03_mc.mail.com>
Message-ID: <Pine.GSO.4.21.0002141623290.18686-100000@mail.biostat.washington.edu>

On Mon, 14 Feb 2000, a s wrote:

> I haven't been able to solve two issues, really appreciate any help.
> 
> Q1. Why this one goes like that? (could it be a bug?):
> 
> What I want:
> > J_c(1,2,3)
> > MA_NA
> > MA[1]_min(J[1:2])
> > MA[2]_min(J[2:3])
> > MA
> [1] 1 2
> 
> Good, so now lets do it a little more faster (since the real vectors have
> over 15000 obs):
> 
> > for (i in 1:2) MA[i]_min(J[i:i+1])
> > MA
> [1] 2 3
> 
> It does the same with any function instead of min.

The problem is that i:i+1 should be i:(i+1)
eg
R> i<-10
R> i:i+1
[1] 11
R> i:(i+1)
[1] 10 11

i:i+1  means (i:i)+1, which reduces to i+1


> 
> Q2. The former type of job works better with sapply (or the like), but when
> FUN returns a vector, I haven't been able to get a matrix instead of a list
> (simplify=TRUE, does not make any difference). Any way to avoid converting
> list into matrix after sapply??

I don't know what you mean.  The examples for sapply() include such an
example, and it works.
R> x <- list(a = 1:10, beta = exp(-3:3), logic = c(T,F,F,T))
R> sapply(x, quantile)
         a        beta logic
0%    1.00  0.04978707   0.0
25%   3.25  0.25160736   0.0
50%   5.50  1.00000000   0.5
75%   7.75  5.05366896   1.0
100% 10.00 20.08553692   1.0

	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 15 08:13:42 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 15 Feb 2000 07:13:42 +0000 (GMT)
Subject: [R] FAQ and Answer: How to convert factors back to integers
In-Reply-To: <87k8k78kiu.fsf@alpha.cfas.washington.edu>
Message-ID: <Pine.GSO.4.05.10002150711280.23811-100000@auk.stats>

On 14 Feb 2000, A.J. Rossini wrote:

> 
> 
> (thanks to thomas for assistance; I'm posting this for archival
> reasons).
> 
> Question:
> 
> My silly dataset looks like "00223423", "00234234", ... 
> and when I read it in, I get a factor which looks like and
> integer.  How do I convert it back?
> 
> (i.e. I've got something like:
> > hivplasma
>  [1] 00050400 00219000 00136000 00000906 00142000 00002150 00000400 00001880
>  [9] 00000200 00000400 00115000 00000924 00051500 00000216 00007670 00000200
> [17] 00538000 00001720 00000738 00000400 00759000 00023900 00002166 00000200
> [25] 00000200 00185000 00002160 00003056 00002770 00002040 00000200 00000200
> [33] 00000582 00054898 00003312 00002010 00010365 00000966 00000465 00000200
> [41] 00000400 00480731 00000931 00790349 00033402 00000200 00000200 00000400
> [49] 00760993 00000649 00000511 01611560 00009509 00001181 00000400 00053308
> [57] 00000939 00001229 00006537 00000400 00000400 00141695 00001471 00000490
> [65] 00004674 00001095 00000872 00002461 00000400 00000400 00144266 00394994
> [73] 00550144 00015851 00000400 00000000
> Levels:  00000000 00000200 00000216 00000400 00000465 00000490 00000511 00000582 00000649 00000738 00000872 00000906 00000924 00000931 00000939 00000966 00001095 00001181 00001229 00001471 00001720 00001880 00002010 00002040 00002150 00002160 00002166 00002461 00002770 00003056 00003312 00004674 00006537 00007670 00009509 00010365 00015851 00023900 00033402 00050400 00051500 00053308 00054898 00115000 00136000 00141695 00142000 00144266 00185000 00219000 00394994 00480731 00538000 00550144 00759000 00760993 00790349 01611560 
> > 
> )
> 
> Answer:
> 
> hivplasma.integer.NOT.FACTOR <- 
> 	as.numeric(levels(hivplasma))[codes(hivplasma)]

No, please do not do that in general. The answer is

as.numeric(as.character(hivplasma))

as your answer depends on the levels being in alphabetical order (which
they happen to be). Replace codes by as.numeric if you want to do that sort
of thing: `codes' does not give the numeric codes, it re-codes. See its
help page for a warning!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Tue Feb 15 13:06:35 2000
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Tue, 15 Feb 2000 12:06:35 +0000 (GMT)
Subject: [R] dev.list() not a list?
Message-ID: <Pine.LNX.4.10.10002151203060.9040-100000@localhost.localdomain>

Isn't dev.list() a list? I am using R-0.99a

> dev.list()
NULL
> is.list(dev.list())
[1] FALSE
> is.null(dev.list())
[1] TRUE
Fine.


> x11()
> dev.list()
X11 
  2 
> is.null(dev.list())
[1] FALSE
> is.list(dev.list())
[1] FALSE
What is it then, if not a list? Is this a bug?


My basic problem: I want my function to do
x11(height=6, width=6, pointsize=20)
if no x11 window is open yet (if dev.list() is NULL)

Thanks for any help.

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 15 13:04:18 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 15 Feb 2000 12:04:18 +0000 (GMT)
Subject: [R] dev.list() not a list?
In-Reply-To: <Pine.LNX.4.10.10002151203060.9040-100000@localhost.localdomain>
Message-ID: <Pine.GSO.4.05.10002151153310.13395-100000@auk.stats>

On Tue, 15 Feb 2000, Bill Simpson wrote:

> Isn't dev.list() a list? I am using R-0.99a

It is a `list', but not an object of mode "list".

> > dev.list()
> NULL
> > is.list(dev.list())
> [1] FALSE
> > is.null(dev.list())
> [1] TRUE
> Fine.
> 
> 
> > x11()
> > dev.list()
> X11 
>   2 
> > is.null(dev.list())
> [1] FALSE
> > is.list(dev.list())
> [1] FALSE
> What is it then, if not a list? Is this a bug?

A named vector. No. .Devices is an R list, though.

(Someone has been copying S-PLUS here, hence the name dev.list.)

> My basic problem: I want my function to do
> x11(height=6, width=6, pointsize=20)
> if no x11 window is open yet (if dev.list() is NULL)

Well, those are different. Either test if is.null(dev.list()), or
if names(dev.cur()) != "X11".

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Tue Feb 15 15:37:29 2000
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Tue, 15 Feb 2000 14:37:29 +0000 (GMT)
Subject: [R] par: mar and mgp dead?
Message-ID: <Pine.LNX.4.10.10002151417440.9348-100000@localhost.localdomain>

I just installed 99.0a, and I can't set mar and mgp:

> par(mar(2,2,.1,.1))
Error in par(mar(2, 2, .1, .1)) : couldn't find function "mar"

I had the same happen with mgp.
Are these bugs or a problem in my installation (everything else seems
OK)?

Is R core going to kill mar and mgp? If so, how should I fix the
huge margins and huge space between axis title and axis? Try this to see
what I mean:

 x11(width=6, height=6,pointsize=21)
 x<-seq(1,10)
 y<-x+rnorm(10)
 plot(x,y)
dev.print(horizontal=FALSE,width=6,height=6,pointsize=21, file="junk.ps")

(Maybe this looks OK to you, but to me a huge fraction of the figure is
wasted space that should be devoted to the actual plot)

pointsize is acting like cex, scaling up the margins and axis title
spacing.

Bill Simpson

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Feb 15 14:50:59 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Feb 2000 14:50:59 +0100
Subject: [R] par: mar and mgp dead?
In-Reply-To: Bill Simpson's message of "Tue, 15 Feb 2000 14:37:29 +0000 (GMT)"
References: <Pine.LNX.4.10.10002151417440.9348-100000@localhost.localdomain>
Message-ID: <x21z6emv5o.fsf@blueberry.kubism.ku.dk>

Bill Simpson <wsi at gcal.ac.uk> writes:

> I just installed 99.0a, and I can't set mar and mgp:
> 
> > par(mar(2,2,.1,.1))
> Error in par(mar(2, 2, .1, .1)) : couldn't find function "mar"

try mar=c(2,2,.1,.1)

> I had the same happen with mgp.

I'll believe that

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Feb 15 17:19:42 2000
From: gb at stat.umu.se (gb@stat.umu.se)
Date: Tue, 15 Feb 2000 17:19:42 +0100 (CET)
Subject: [R] nls question continued
In-Reply-To: <6ritzr5ovm.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.LNX.4.10.10002151558320.9072-100000@pc16.stat.umu.se>

Douglas,

Thank you for the prompt answer. However, I still have
difficulties, see below. 

On 14 Feb 2000, Douglas Bates wrote:

> gb at stat.umu.se writes:
> 
> > I have two functions, tids1 and tids2:
> > 
> > tids1 <- function(W, w)
> >   {
> >     nls(W ~ w %*% beta,
> >         data = parent.frame(0),
> >         start = list(beta = rep(0, ncol(w)) ) )
> > }
> >     
> > tids2 <- function(W, w)
> > {
> >   X.1 <- w[, 1]
> >   X.2 <- w[, 2]
> >   
> >   nls(W ~ X.1 * beta1 + X.2 * beta2,
> >       data = parent.frame(0),
> >       start = list(beta1 = 0, beta2 = 0))
> > }
> > 
> > I want something like tids1, but only tids2 works:
> > 
> > > tids1(Y, X)
> > Error in qr.qty(QR, resid) : qr and y must have the same number of rows
> > 
> > > tids2(Y, X)
> > Nonlinear regression model
> >   model:  W ~ X.1 * beta1 + X.2 * beta2 
> >    data:  parent.frame 0 
> >    beta1    beta2 
> > 1.200331 1.027278 
> >  residual sum-of-squares:  5.358129 
> > 
> > Q: How do I write a _general_ tids2?
> 
> The nls function has an argument "algorithm" which can be set to
> "plinear" for partially linear models.  This will fits exactly this
> kind of model, assuming that the matrix w itself depends on some
> parameters (if it doesn't you have a linear regression model and no
> need to use nls).
> 
> Look at
>  example(nls)
> to see how that argument is used.
> 
> 
>  nls> fm2DNase1 <- nls(density ~ 1/(1 + exp((xmid - log(conc))/scal)), 
>      data = DNase1, start = list(xmid = 0, scal = 1), alg = "plinear", 
>      trace = TRUE)
>  0.7139315 : 0.000000 1.000000 1.453853 
>  0.1445295 : 1.640243 1.390186 2.461754 
>  0.008302151 : 1.620899 1.054228 2.478388 
>  0.004794192 : 1.485226 1.043709 2.347334 
>  0.004789569 : 1.483130 1.041468 2.345218 
>  0.004789569 : 1.483090 1.041455 2.345180 

This works alright, but what if you want to use 'data = DNase' instead,
and include DNase$Run as a factor in the model, for instance linearly?

This is close to my _real_ problem, where the model is something like

y ~ (x.1 * beta1 + x.2 * beta2)^delta + X %*% Alpha

where  X  is a matrix created from indicators of the levels of a 
factor. 'delta' is a known constant, beta1 and beta2 are scalar
parameters, and Alpha is vector of parameters.

Could this be done? 

G?ran
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Tue Feb 15 18:20:05 2000
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Tue, 15 Feb 2000 17:20:05 +0000 (GMT)
Subject: [R] par: mar and mgp dead?
In-Reply-To: <x21z6emv5o.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.10.10002151718340.9501-100000@localhost.localdomain>

Sorry for bothering the list with that stupid error! Thanks for the help.

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clive at research.bell-labs.com  Tue Feb 15 19:28:53 2000
From: clive at research.bell-labs.com (Clive Loader)
Date: Tue, 15 Feb 2000 13:28:53 -0500 (EST)
Subject: [R] locfit for R 0.99.0
Message-ID: <200002151828.NAA24011@jessie.research.bell-labs.com>

I've updated the locfit library, with R 0.99.0 compatability and other
changes. The new version is propagating through CRAN, or available
from my webpage, http://cm.bell-labs.com/stat/project/locfit.


Also with regard to distribution accuracy, these might be of interest -
http://cm.bell-labs.com/stat/clive/dbinom.ps  (document)
http://cm.bell-labs.com/stat/clive/dbinom.c   (c source code).
It's using a saddle point method for dbinom() and dpois() which
is much more accurate than the current R (and S-Plus) implementations
for large n (no R interface yet, but that should be easy).

Regards,
Clive.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mai at ms.uky.edu  Tue Feb 15 20:22:41 2000
From: mai at ms.uky.edu (Mai Zhou)
Date: Tue, 15 Feb 2000 14:22:41 -0500 (EST)
Subject: [R] binary representation of an integer?
Message-ID: <200002151922.OAA28003@t3.mscf.uky.edu>

Is there a function or other ways in R that can find the 
binary representation of an integer?
(or list all those representations for integers 0:63, for example)
OR do I have to built such a table?

i.e.   something like  binary(3)= 11
                       binary(4)= 100  etc.

Thanks.

Mai Zhou
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Tue Feb 15 20:42:58 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Tue, 15 Feb 2000 11:42:58 -0800 (PST)
Subject: [R] binary representation of an integer?
In-Reply-To: <200002151922.OAA28003@t3.mscf.uky.edu>
Message-ID: <Pine.GSO.4.21.0002151136410.3968-100000@mail.biostat.washington.edu>

On Tue, 15 Feb 2000, Mai Zhou wrote:

> Is there a function or other ways in R that can find the 
> binary representation of an integer?
> (or list all those representations for integers 0:63, for example)
> OR do I have to built such a table?
> 
> i.e.   something like  binary(3)= 11
>                        binary(4)= 100  etc.
> 

Here's a function that works for integers up to 2^10-1, so that the value
can be returned as an integer (if you have a 64bit machine you may be able
to use a larger value of 10)

binary<-function(i) {
a<-2^(0:9)
b<-2*a
sapply(i,function(x) sum(10^(0:9)[(x %% b)>=a]))
}


And this one works up to 2^32-1 but returns a string with leading zeros

binarys<-function(i) {
a<-2^(31:0)
b<-2*a
sapply(i,function(x) paste(as.integer((x %% b)>=a),collapse=""))
}

Either could be improved, but it's probably not worth much effort.

	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rab at nauticom.net  Tue Feb 15 22:09:04 2000
From: rab at nauticom.net (Richard A. Bilonick)
Date: Tue, 15 Feb 2000 21:09:04 +0000
Subject: [R] Problem with Dates 
References: <200002151828.NAA24011@jessie.research.bell-labs.com>
Message-ID: <38A9C070.A884FC16@nauticom.net>

Hi,

My dates are printing as 01/01/100 instead of 01/01/2000. I can't find a way to
get mm/dd/yyyy type format. I've tried using out.format="mm/dd/yyyy" but it writes
out the month name (and that is all). I've installed both chron and date. The
version of R is 0.65.1.

Rick Bilonick

--
Statistical Consulting for Business & Industry
mailto:rab at nauticom.net
efax:  508 445 5821
voice: 412 831 4509


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Feb 15 21:16:22 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Feb 2000 21:16:22 +0100
Subject: [R] binary representation of an integer?
In-Reply-To: Thomas Lumley's message of "Tue, 15 Feb 2000 11:42:58 -0800 (PST)"
References: <Pine.GSO.4.21.0002151136410.3968-100000@mail.biostat.washington.edu>
Message-ID: <x2snyudxwp.fsf@blueberry.kubism.ku.dk>

Thomas Lumley <thomas at biostat.washington.edu> writes:

> And this one works up to 2^32-1 but returns a string with leading zeros
> 
> binarys<-function(i) {
> a<-2^(31:0)
> b<-2*a
> sapply(i,function(x) paste(as.integer((x %% b)>=a),collapse=""))
> }
> 
> Either could be improved, but it's probably not worth much effort.

And there's also:

bb<-function(i) if (i) paste(bb(i %/% 2), i %% 2, sep="") else ""

which works for all integer 0 < i < 2^54 on IEEE machines. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jallen at students.cas.unt.edu  Wed Feb 16 01:05:52 2000
From: jallen at students.cas.unt.edu (Joel Allen)
Date: Tue, 15 Feb 2000 18:05:52 -0600
Subject: [R] chron and mysql
Message-ID: <38A9E9DF.55866CAD@students.cas.unt.edu>

R 0.90.1
chron 2.2-2
MySQL 3.22.30

Attempts to create a chron object fail when using date and time data
from a mysql database.   It appears that chron does not like 4 digit
years.  Is this the problem?

my data look like:

> c.time[1:10,]
         Date     Time
1  2000-02-14 10:15:02
2  2000-02-14 10:17:03
3  2000-02-14 10:18:03
4  2000-02-14 10:19:03
5  2000-02-14 10:20:04
6  2000-02-14 10:21:04
7  2000-02-14 10:22:04
8  2000-02-14 10:23:05
9  2000-02-14 10:24:05
10 2000-02-14 10:26:06

the chron command looks like:

>
time.stamp<-chron(as.character(c.time[,"Date"]),c.time[,"Time"],format=c("y/m/d","h:m:s"))

Error in convert.dates(dates., format = format[[1]], origin = origin.) :
format y/m/d may be incorrect
In addition: Warning messages:
1: 1796 entries set to NA due to wrong number of fields in:
unpaste(dates., sep = fmt$sep, fnames = fmt$periods, nfields = 3)
2: NAs introduced by coercion
3: NAs introduced by coercion
4: NAs introduced by coercion

Thanks,

Joel Allen
Institute of Applied Sciences
University of North Texas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Brian.O'Gorman at noaa.gov  Wed Feb 16 00:43:12 2000
From: Brian.O'Gorman at noaa.gov (Brian.O'Gorman@noaa.gov)
Date: Tue, 15 Feb 2000 15:43:12 -0800
Subject: [R] R installation 
Message-ID: <0002159506.AA950661851@dogbert.akctr.noaa.gov>

I've decided to install in R in a directory other than /usr/local, but
I'm having difficulty in setting the correct paths, i.e. PATH or path.
I've set my R_HOME, and sure enough there's a bin and lib directory
there but R just won't execute (something like GUI 'X11' is not
supported. However when R is installed in /usr/local then everything is
OK...Any help or comments appreciated...

-------------- next part --------------
begin:vcard 
n:O'Gorman;Brian
tel;fax:(907) 481-1701
tel;work:(907) 481-1716
x-mozilla-html:FALSE
org:National Marine Fisheries Service;Alaska Fisheries Science Center 
version:2.1
email;internet:brian.o'gorman at noaa.gov
adr;quoted-printable:;;Resource Assessment and Conservation Engineering Division=0D=0AShellfish Assessment Program=0D=0A301 Research Court;Kodiak;Alaska;99615;USA
fn:Brian O'Gorman
end:vcard


From Ray.Brownrigg at mcs.vuw.ac.nz  Wed Feb 16 05:57:30 2000
From: Ray.Brownrigg at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Wed, 16 Feb 2000 17:57:30 +1300 (NZDT)
Subject: [R] R installation
Message-ID: <200002160457.RAA18732@aqua.mcs.vuw.ac.nz>

> I've decided to install in R in a directory other than /usr/local, but
> I'm having difficulty in setting the correct paths, i.e. PATH or path.
> I've set my R_HOME, and sure enough there's a bin and lib directory
> there but R just won't execute (something like GUI 'X11' is not
> supported. However when R is installed in /usr/local then everything is
> OK...Any help or comments appreciated...
> 
Try:
sh -x `which R`
That will display the shell commands as they are executed by the
script. This may give you a clue as to what is happening.  In
particular, it tells you where it is looking for the file
$R_HOME/bin/R.X11 (which is what it is complaining about).

Hope this helps,
Ray Brownrigg <ray at mcs.vuw.ac.nz>	http://www.mcs.vuw.ac.nz/~ray
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb 16 10:41:55 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 16 Feb 2000 10:41:55 +0100
Subject: [R] R installation
In-Reply-To: Brian.O'Gorman@noaa.gov's message of "Tue, 15 Feb 2000 15:43:12 -0800"
References: <0002159506.AA950661851@dogbert.akctr.noaa.gov>
Message-ID: <x2snyt4h7g.fsf@blueberry.kubism.ku.dk>

Brian.O'Gorman at noaa.gov writes:

> --simple boundary
> Content-Type: text/plain; charset=ISO-8859-1
> Content-Transfer-Encoding: 7bit
> Content-Description: "cc:Mail Note Part"
> 
> I've decided to install in R in a directory other than /usr/local, but
> I'm having difficulty in setting the correct paths, i.e. PATH or path.
> I've set my R_HOME, and sure enough there's a bin and lib directory
> there but R just won't execute (something like GUI 'X11' is not
> supported. However when R is installed in /usr/local then everything is
> OK...Any help or comments appreciated...

The official way is to use --prefix=/path/to/mydir on the configure
command before building, but you should be able to get away with
altering the relevant line in the startup script (bin/R) which sets
R_HOME. 

(The error message is admittedly cryptic and comes from checking
whether $R_HOME/R.X11 is there. 1.0.0 will have a direct check for the
existence of $R_HOME first.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MattP2 at prodigy.net  Wed Feb 16 20:30:50 2000
From: MattP2 at prodigy.net (Matt Pocernich)
Date: Wed, 16 Feb 2000 12:30:50 -0700
Subject: [R] Format of the tick label in a histogram
Message-ID: <001601bf78b4$561004c0$bef8fed1@dog>

I am producing a series of histograms and would like to control the format of the tick labels.

I tried using the exp=1 option, but apparently this can't be set in a higher level plot function.

I've unsuccessfully tried to modify the hist command.

Any suggestions?

Thanks

Matt Pocernich

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000216/e9165757/attachment.html

From Brian.O'Gorman at noaa.gov  Wed Feb 16 23:31:15 2000
From: Brian.O'Gorman at noaa.gov (Brian.O'Gorman@noaa.gov)
Date: Wed, 16 Feb 2000 14:31:15 -0800
Subject: [R] R installation 
Message-ID: <0002169507.AA950743929@dogbert.akctr.noaa.gov>

To get R-0.99.0a to execute in a directory other than /usr/local, I've
had to do the following
setenv R_HOME /export/trichodon2/R/R-0.99.0a   
./configure --prefix=/export/trichodon2/R/R-0.99.0a
make
make install
make check
add to the path $R_HOME/bin, eg. in my .cshrc

/export/trichodon2/R/R-0.99.0a is where I gunzip and tar the
R-0.99.0a.tar.gz on my Solaris 2.7 Unix machine.

Peter Dalgaard BSA wrote:
> 
> Brian.O'Gorman at noaa.gov writes:
> 
> > --simple boundary
> > Content-Type: text/plain; charset=ISO-8859-1
> > Content-Transfer-Encoding: 7bit
> > Content-Description: "cc:Mail Note Part"
> >
> > I've decided to install in R in a directory other than /usr/local, but
> > I'm having difficulty in setting the correct paths, i.e. PATH or path.
> > I've set my R_HOME, and sure enough there's a bin and lib directory
> > there but R just won't execute (something like GUI 'X11' is not
> > supported. However when R is installed in /usr/local then everything is
> > OK...Any help or comments appreciated...
> 
> The official way is to use --prefix=/path/to/mydir on the configure
> command before building, but you should be able to get away with
> altering the relevant line in the startup script (bin/R) which sets
> R_HOME.
> 
> (The error message is admittedly cryptic and comes from checking
> whether $R_HOME/R.X11 is there. 1.0.0 will have a direct check for the
> existence of $R_HOME first.)
> 
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-------------- next part --------------
begin:vcard 
n:O'Gorman;Brian
tel;fax:(907) 481-1701
tel;work:(907) 481-1716
x-mozilla-html:FALSE
org:National Marine Fisheries Service;Alaska Fisheries Science Center 
version:2.1
email;internet:brian.o'gorman at noaa.gov
adr;quoted-printable:;;Resource Assessment and Conservation Engineering Division=0D=0AShellfish Assessment Program=0D=0A301 Research Court;Kodiak;Alaska;99615;USA
fn:Brian O'Gorman
end:vcard


From ripley at stats.ox.ac.uk  Thu Feb 17 00:29:58 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 16 Feb 2000 23:29:58 +0000 (GMT)
Subject: [R] Windows metafile
In-Reply-To: <D5A7D734C9C5D211B9E30008C78923020609E650@exdkba03.novo.dk>
Message-ID: <Pine.GSO.4.05.10002162318250.3017-100000@auk.stats>

On Tue, 8 Feb 2000, BXC (Bendix Carstensen) wrote:

> Running
> 
> R : Copyright 1999, The R Development Core Team
> Version 0.90.1  (December 15, 1999)
> 
> on NT 4.0 gives me problems with:
> 
> win.metafile(file="./x.emf")
> x <- 1:100/7
> plot(x,cos(x),type="n")
> lines(x,sin(x))
> abline(v=0:15,h=-2:2/2,col=gray(0.8))
> 
> Only labels and titles on axes are in the file.
> No axes or lines of any kind. (I look at the file by 
> inserting it in Word, which is what I need for
> my client). Variations over the theme by using
> type="l" or "p", does not change anything.

Yes, I get that with Word 2000 on NT4, but the problem appears to be in
Word's preview, and definitely the lines are in the file.

1) The Word document prints with all the lines, and looks correct.
2) If you preview in Word and magnify, you can see all the lines.

Interestingly

3) If I copy to the clipboard as a metafile and paste into Word, I
do see the lines, but if I copy the graphics device to a file I do not.

Also

4) I have seen this with metafiles from S-PLUS 4.5 to Word 97, and 3) also
held true there

I suspect that the anti-aliasing built into the NT4 display engine is
losing narrow lines completely (it does a poor job of small fonts), and if
you do what you did, you will get a much larger nominal page and hence
relatively narrower lines than copying a graphics device to the clipboard.

I might try setting width and height on the win.metafile device to
something much closer to the size you want to include at. (I haven't
do so, though.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paul at stat.auckland.ac.nz  Thu Feb 17 04:25:44 2000
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 17 Feb 2000 16:25:44 +1300
Subject: [R] Format of the tick label in a histogram
References: <001601bf78b4$561004c0$bef8fed1@dog>
Message-ID: <00db01bf78f6$ad147430$175dd882@stat.auckland.ac.nz>

hi


> I am producing a series of histograms and would like to control the format
of the tick
> labels.
>
> I tried using the exp=1 option, but apparently this can't be set in a
higher level plot
> function.
>
> I've unsuccessfully tried to modify the hist command.
>
> Any suggestions?


um ... you're trying to use a graphics parameter that exists in S-Plus, but
not in R ? :)

you might be able to do some of what you want by a combination of plot(...
axes=F),
axis(... at= ... labels= ...) or mtext(), and format() and/or formatC()

paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 17 08:24:52 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 17 Feb 2000 07:24:52 +0000 (GMT)
Subject: [R] R installation 
In-Reply-To: <0002169507.AA950743929@dogbert.akctr.noaa.gov>
Message-ID: <Pine.GSO.4.05.10002170711480.3481-100000@auk.stats>

On Wed, 16 Feb 2000 Brian.O'Gorman at noaa.gov wrote:

> To get R-0.99.0a to execute in a directory other than /usr/local, I've
> had to do the following
> setenv R_HOME /export/trichodon2/R/R-0.99.0a   
> ./configure --prefix=/export/trichodon2/R/R-0.99.0a
> make
> make install
> make check
> add to the path $R_HOME/bin, eg. in my .cshrc
> 
> /export/trichodon2/R/R-0.99.0a is where I gunzip and tar the
> R-0.99.0a.tar.gz on my Solaris 2.7 Unix machine.

All I do to run R from the directory tree in which I unpacked is to
link /export/trichodon2/R/R-0.99.0a/bin/R to somewhere in my path. That is,
I do not set R_HOME and I do not `make install'.  Setting R_HOME will
just cause confusion if there is more than one copy of R around: the 
`R' scripts sets it as required. As an example:

./configure
make
ln -s /export/trichodon2/R/R-0.99.0a/bin/R ~/bin
[optionally, make clean]

You only need to `install' to move the operational parts of the built
sources somewhere else. To install a stable version for public use, I use,
e.g.

./configure --prefix=/packages/R/0.99.0a
make
make install
ln -s /packages/R/0.99.0a/bin/R /usr/local/bin

and then remove the directory in which I unpacked.

In each case `rehash' (I use tcsh/csh) and `R' runs R.

> 
> Peter Dalgaard BSA wrote:
> > 
> > Brian.O'Gorman at noaa.gov writes:
> > 
> > > --simple boundary
> > > Content-Type: text/plain; charset=ISO-8859-1
> > > Content-Transfer-Encoding: 7bit
> > > Content-Description: "cc:Mail Note Part"
> > >
> > > I've decided to install in R in a directory other than /usr/local, but
> > > I'm having difficulty in setting the correct paths, i.e. PATH or path.
> > > I've set my R_HOME, and sure enough there's a bin and lib directory
> > > there but R just won't execute (something like GUI 'X11' is not
> > > supported. However when R is installed in /usr/local then everything is
> > > OK...Any help or comments appreciated...
> > 
> > The official way is to use --prefix=/path/to/mydir on the configure
> > command before building, but you should be able to get away with
> > altering the relevant line in the startup script (bin/R) which sets
> > R_HOME.
> > 
> > (The error message is admittedly cryptic and comes from checking
> > whether $R_HOME/R.X11 is there. 1.0.0 will have a direct check for the
> > existence of $R_HOME first.)
> > 
> > --
> >    O__  ---- Peter Dalgaard             Blegdamsvej 3
> >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
> >  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chong at stat.purdue.edu  Thu Feb 17 19:12:10 2000
From: chong at stat.purdue.edu (Chong Gu)
Date: Thu, 17 Feb 2000 13:12:10 -0500
Subject: [R] se from predict.glm
Message-ID: <200002171812.NAA176036@odds.stat.purdue.edu>


I am not sure whether it is a design decision or just an oversight.

When I ask for the standard errors of the predictions with

  predict(budwm.lgt,se=TRUE)

where budwm.lgt is a logistic fit of the budworm data in MASS, I got

  Error in match.arg(type) : ARG should be one of response, terms

If one is to construct a CI for the fitted binomial probability,
wouldn't it be more natural to do it on the link scale before
transforming to the probability scale?

Of course, knowing a bit about what's going on inside glm, I could use
predict.lm to get what I want, but I am curious why se is not made
available for the link prediction in predict.glm.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 17 19:36:54 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 Feb 2000 18:36:54 +0000 (GMT)
Subject: [R] se from predict.glm
In-Reply-To: <200002171812.NAA176036@odds.stat.purdue.edu>
Message-ID: <Pine.GSO.4.05.10002171833040.15482-100000@toucan.stats>

On Thu, 17 Feb 2000, Chong Gu wrote:

> 
> I am not sure whether it is a design decision or just an oversight.
> 
> When I ask for the standard errors of the predictions with
> 
>   predict(budwm.lgt,se=TRUE)
> 
> where budwm.lgt is a logistic fit of the budworm data in MASS, I got
> 
>   Error in match.arg(type) : ARG should be one of response, terms
> 
> If one is to construct a CI for the fitted binomial probability,
> wouldn't it be more natural to do it on the link scale before
> transforming to the probability scale?

Yes, that's what we (V&R) do normally.

> Of course, knowing a bit about what's going on inside glm, I could use
> predict.lm to get what I want, but I am curious why se is not made
> available for the link prediction in predict.glm.

It is, and this works in 0.99.0. You are hitting a bug in an earlier
version of R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Feb 17 19:50:29 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Feb 2000 19:50:29 +0100
Subject: [R] se from predict.glm
In-Reply-To: Chong Gu's message of "Thu, 17 Feb 2000 13:12:10 -0500"
References: <200002171812.NAA176036@odds.stat.purdue.edu>
Message-ID: <x21z6bu0i2.fsf@blueberry.kubism.ku.dk>

Chong Gu <chong at stat.purdue.edu> writes:

> Of course, knowing a bit about what's going on inside glm, I could use
> predict.lm to get what I want, but I am curious why se is not made
> available for the link prediction in predict.glm.

This was fixed recently (in 0.99.0). It happened because the type=
argument got passed on to predict.lm which doesn't know about
type=link. Newer versions of predict.glm has this kind of stuff
internally:

	pred <- predict.lm(object, newdata, se.fit, scale = residual.scale,
                           type=ifelse(type=="link", "response",
                           type),
                           terms=terms)
        fit <- pred$fit
        se.fit <- pred$se.fit
        switch(type,
               response = {
                   fit <- family(object)$linkinv(fit)
                   se.fit <- se.fit * abs(family(object)$mu.eta(fit))
               },
               link =, terms=)



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Thu Feb 17 22:51:16 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Thu, 17 Feb 2000 13:51:16 -0800 (PST)
Subject: [R] se from predict.glm
In-Reply-To: <200002171812.NAA176036@odds.stat.purdue.edu>
Message-ID: <Pine.GSO.4.21.0002171350200.11882-100000@mail.biostat.washington.edu>

On Thu, 17 Feb 2000, Chong Gu wrote:

> 
> I am not sure whether it is a design decision or just an oversight.
> 
> When I ask for the standard errors of the predictions with
> 
>   predict(budwm.lgt,se=TRUE)
> 
> where budwm.lgt is a logistic fit of the budworm data in MASS, I got
> 
>   Error in match.arg(type) : ARG should be one of response, terms
> 
> If one is to construct a CI for the fitted binomial probability,
> wouldn't it be more natural to do it on the link scale before
> transforming to the probability scale?
> 
> Of course, knowing a bit about what's going on inside glm, I could use
> predict.lm to get what I want, but I am curious why se is not made
> available for the link prediction in predict.glm.

It's a bug. It's been fixed.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From badel at bach.urbb.jussieu.fr  Fri Feb 18 16:22:53 2000
From: badel at bach.urbb.jussieu.fr (Anne Badel-Chagnon)
Date: Fri, 18 Feb 2000 16:22:53 +0100
Subject: [R] : multiple discriminant analysis
Message-ID: <38AD63CD.6E67DD5A@urbb.jussieu.fr>

I am looking for a "multiple discriminant analysis" function
It seems to be called DISCR in Splus, but I can't find it in R, and
R-packages.
Thank for your help


--
Anne BADEL-CHAGNON     Email:badel at urbb.jussieu.fr
Equipe de Bioinformatique Mol?culaire, Universite Paris 7
Tour 53, 1er etage, case 7113       Tel : 01.44.27.77.14
75251 Paris cedex 05                Fax : 01.43.26.38.30


-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000218/35c6ac9c/attachment.html

From ripley at stats.ox.ac.uk  Fri Feb 18 16:50:16 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 Feb 2000 15:50:16 +0000 (GMT)
Subject: [R] : multiple discriminant analysis
Message-ID: <200002181550.PAA13017@toucan.stats.ox.ac.uk>

> Date: Fri, 18 Feb 2000 16:22:53 +0100
> From: Anne Badel-Chagnon <badel at bach.urbb.jussieu.fr>
> 
> I am looking for a "multiple discriminant analysis" function
> It seems to be called DISCR in Splus, but I can't find it in R, and
> R-packages.
> Thank for your help

That is not in R, but lda in library MASS (part of the VR suite)
is much friendlier, I think, and does what you are looking for.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mcw at ln.nimh.nih.gov  Fri Feb 18 20:32:54 2000
From: mcw at ln.nimh.nih.gov (Matthew Wiener)
Date: Fri, 18 Feb 2000 14:32:54 -0500 (EST)
Subject: [R] splitstr problem
Message-ID: <Pine.SGI.3.96.1000218142841.24687A-100000@ln.nimh.nih.gov>

Hi, all.

Using the patched version of R-0.99.0, I cannot reproduce the following
example from the strsplit  documentation:

(Example)
unlist(strsplit("a.b.c", "."))  
## [1] "" "" "" "" "" 
## Note that `split' is a regexp!  
## If you really want to split on `.', use
unlist(strsplit("a.b.c", "\."))
## [1] "a" "b" "c"


The first one gets the stated result, but the second gets me the same
result as the first.

Is there some way to do what's intended?

Thanks,
		Matt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mcw at ln.nimh.nih.gov  Fri Feb 18 22:25:34 2000
From: mcw at ln.nimh.nih.gov (Matthew Wiener)
Date: Fri, 18 Feb 2000 16:25:34 -0500 (EST)
Subject: [R] splitstr problem solved
In-Reply-To: <20000219101949.B18928@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.SGI.3.96.1000218162411.25871C-100000@ln.nimh.nih.gov>

Hi.  Robert Gentleman's solution works.  Thanks.

This seems to be a documentation bug; I will submit a separate report to
the bug list for completeness.

Matt


On Sat, 19 Feb 2000, Robert Gentleman wrote:

> On Fri, Feb 18, 2000 at 02:32:54PM -0500, Matthew Wiener wrote:
> > Hi, all.
> > 
> > Using the patched version of R-0.99.0, I cannot reproduce the following
> > example from the strsplit  documentation:
> > 
> > (Example)
> > unlist(strsplit("a.b.c", "."))  
> > ## [1] "" "" "" "" "" 
> > ## Note that `split' is a regexp!  
> > ## If you really want to split on `.', use
> > unlist(strsplit("a.b.c", "\."))
> > ## [1] "a" "b" "c"
> 
>   I don't have a copy of 0.99 but I think you want
>     unlist(strsplit("a.b.c", "\\."))
>                               ^^
> > 
> > 
> > The first one gets the stated result, but the second gets me the same
> > result as the first.
> > 
> > Is there some way to do what's intended?
> > 
> > Thanks,
> > 		Matt
> > 
> > 
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> -- 
> +-------------------------------------------------------------------------+
> | Robert Gentleman              phone : (64-9) 3737-599 ext 3946          | 
> | Senior Lecturer               fax :   (64-9) 3737-018                   |
> | Department of Statistics                                                |
> | University of Auckland	email : rgentlem at stat.auckland.ac.nz      |
> +-------------------------------------------------------------------------+
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Feb 18 22:40:16 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Feb 2000 22:40:16 +0100
Subject: [R] splitstr problem
In-Reply-To: Matthew Wiener's message of "Fri, 18 Feb 2000 14:32:54 -0500 (EST)"
References: <Pine.SGI.3.96.1000218142841.24687A-100000@ln.nimh.nih.gov>
Message-ID: <x2itzmp4u7.fsf@blueberry.kubism.ku.dk>

Matthew Wiener <mcw at ln.nimh.nih.gov> writes:


> unlist(strsplit("a.b.c", "\."))
> ## [1] "a" "b" "c"
<doesn't work>

> Is there some way to do what's intended?

More backslashes ("\." is the same as "."):

unlist(strsplit("a.b.c", "\\."))

(and to get that in formatted docs, the source needs to say

unlist(strsplit("a.b.c", "\\\\."))

which it didn't)

It's fixed in the snapshots already.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb 18 23:17:00 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 18 Feb 2000 22:17:00 +0000 (GMT)
Subject: [R] splitstr problem
In-Reply-To: <x2itzmp4u7.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.GSO.4.05.10002182216020.11040-100000@auk.stats>

On 18 Feb 2000, Peter Dalgaard BSA wrote:

> Matthew Wiener <mcw at ln.nimh.nih.gov> writes:
> 
> 
> > unlist(strsplit("a.b.c", "\."))
> > ## [1] "a" "b" "c"
> <doesn't work>
> 
> > Is there some way to do what's intended?
> 
> More backslashes ("\." is the same as "."):
> 
> unlist(strsplit("a.b.c", "\\."))
> 
> (and to get that in formatted docs, the source needs to say
> 
> unlist(strsplit("a.b.c", "\\\\."))
> 
> which it didn't)

(And even if it had it would have come out wrong in latex, at least).

> It's fixed in the snapshots already.

As is the formatting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From christian.hoffmann at wsl.ch  Mon Feb 21 09:24:21 2000
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Mon, 21 Feb 2000 09:24:21 +0100
Subject: [R] splitstr problem
Message-ID: <3.0.5.32.20000221092421.009bf5e0@mail.wsl.ch>

Hi all,

In my  "\R-0.65.1/src/library/base/man/"   I can only find "strsplit.Rd" giving the help to strsplit, but no "strsplit"  itself.

Can anybody tell me how to retrieve "strsplit" itself? (as R/S-Plus program)

Ciao,
--Christian
Christian W. Hoffmann
Mathematics and Statistical Computing
Landscape Modeling and Web Applications
Swiss Federal Institute for Forest, Snow and Landscape Research
CH-8903 Birmensdorf, Switzerland
phone: ++41-1-739 22 77    fax  : ++41-1-737 40 80 or  ++41-1-739 2215  e-mail: Hoffmann at WSL.CH

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Mon Feb 21 11:15:47 2000
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Mon, 21 Feb 2000 10:15:47 +0000 (GMT)
Subject: [R] read.table and factor
Message-ID: <Pine.LNX.4.10.10002211011390.14081-100000@localhost.localdomain>

I have a data file like this:

std     cf      hit     miss    fa      cr
920     980     40      15      14      31
950     1010    24      23      23      30
1190    1250    26      21      27      26
1010    1070    33      10      28      29
1040    1100    35      10      11      44

I use read.table to read it in. My problem is that read.table makes std
and cf into factors. I want them just to be ordinary numeric variables.

as.numeric(d$std) doesn't work properly (as the docs warn), and same goes
for codes(d$std)

How can I either tell read.table to leave the first two cols as numeric
(not factors) or convert them from factors into the proper numeric values?

Thanks very much for any help.

Bill Simpson

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Feb 21 10:41:39 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Feb 2000 10:41:39 +0100
Subject: [R] read.table and factor
In-Reply-To: Bill Simpson's message of "Mon, 21 Feb 2000 10:15:47 +0000 (GMT)"
References: <Pine.LNX.4.10.10002211011390.14081-100000@localhost.localdomain>
Message-ID: <x2ya8eki3w.fsf@blueberry.kubism.ku.dk>

Bill Simpson <wsi at gcal.ac.uk> writes:

> I have a data file like this:
> 
> std     cf      hit     miss    fa      cr
> 920     980     40      15      14      31
> 950     1010    24      23      23      30
> 1190    1250    26      21      27      26
> 1010    1070    33      10      28      29
> 1040    1100    35      10      11      44
> 
> I use read.table to read it in. My problem is that read.table makes std
> and cf into factors. I want them just to be ordinary numeric variables.
> 
> as.numeric(d$std) doesn't work properly (as the docs warn), and same goes
> for codes(d$std)

as.numeric(as.character()) should do it

> How can I either tell read.table to leave the first two cols as numeric
> (not factors) or convert them from factors into the proper numeric values?

If they're not read as numeric, then they must contain non-numeric
elements. Either fix the typo (!) or set na.strings in the call to
read.table. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Mon Feb 21 12:01:27 2000
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Mon, 21 Feb 2000 11:01:27 +0000 (GMT)
Subject: [R] read.table and factor
In-Reply-To: <x2ya8eki3w.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.10.10002211056550.14081-200000@localhost.localdomain>

Thanks very much Peter

> as.numeric(as.character()) should do it
yes, this works, thanks.
> 
> > How can I either tell read.table to leave the first two cols as numeric
> > (not factors) or convert them from factors into the proper numeric values?
> 
> If they're not read as numeric, then they must contain non-numeric
> elements. Either fix the typo (!) or set na.strings in the call to
> read.table. 

No, so far as I can tell neither std nor cf contain non-numeric elements.
This problem arises with every data file I read (the files are created by
a C program). I attach a file--std and cf are numeric, yet read.table

d<-read.table("~/papers/letter/data/ws60.dat",header=TRUE)

makes d$std and d$cf factors.

Bill
-------------- next part --------------
std	cf	hit	miss	fa	cr
920	980	40	15	14	31
950	1010	24	23	23	30
1190	1250	26	21	27	26
1010	1070	33	10	28	29
1040	1100	35	10	11	44
1070	1130	40	17	13	30
890	950	44	14	13	29
830	890	34	13	11	42
1160	1220	30	17	14	39
1130	1190	32	19	20	29
860	920	37	8	17	38
800	860	34	14	11	41
980	1040	33	14	15	38
1100	1160	32	11	16	41
860	920	45	9	10	36
1040	1100	26	14	19	41
1130	1190	41	12	13	34
950	1010	31	18	22	29
890	950	36	12	9	43
1160	1220	20	24	14	42
800	860	33	14	10	43
1100	1160	29	18	7	46
1010	1070	39	10	14	37
1070	1130	40	9	15	36
830	890	47	9	5	39
980	1040	40	7	18	35
1190	1250	28	18	18	36
920	980	49	2	14	35
830	890	39	1	6	54
1040	1100	36	19	6	39
980	1040	34	9	15	42
1100	1160	36	13	14	37
860	920	47	10	15	28
800	860	41	12	6	41
1010	1070	30	10	10	50
1190	1250	26	12	18	44
950	1010	33	9	25	33
1130	1190	34	13	11	42
1160	1220	40	15	17	28
920	980	42	10	15	33
890	950	41	14	7	38
1070	1130	39	13	12	36

From ripley at stats.ox.ac.uk  Mon Feb 21 11:02:23 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 21 Feb 2000 10:02:23 +0000 (GMT)
Subject: [R] read.table and factor
In-Reply-To: <Pine.LNX.4.10.10002211011390.14081-100000@localhost.localdomain>
Message-ID: <Pine.GSO.4.05.10002210955560.19487-100000@auk.stats>

On Mon, 21 Feb 2000, Bill Simpson wrote:

> I have a data file like this:
> 
> std     cf      hit     miss    fa      cr
> 920     980     40      15      14      31
> 950     1010    24      23      23      30
> 1190    1250    26      21      27      26
> 1010    1070    33      10      28      29
> 1040    1100    35      10      11      44
> 
> I use read.table to read it in. My problem is that read.table makes std
> and cf into factors. I want them just to be ordinary numeric variables.
> 
> as.numeric(d$std) doesn't work properly (as the docs warn), and same goes
> for codes(d$std)

as.numeric(as.character(foo)), or if you really want to save space and 
have lots of repeated values

as.numeric(levels(foo))[as.numeric(foo)]

> How can I either tell read.table to leave the first two cols as numeric
> (not factors) or convert them from factors into the proper numeric values?

Well, in the example you give it does leave them as numeric if use
header=T. (You did do so, didn't you?)

> test <- read.table("test.dat", header=T)
> test
   std   cf hit miss fa cr
1  920  980  40   15 14 31
2  950 1010  24   23 23 30
3 1190 1250  26   21 27 26
4 1010 1070  33   10 28 29
5 1040 1100  35   10 11 44
> is.factor(test$std)
[1] FALSE

Maybe there is something else in the column that is not numeric. The
solution is to ensure that the column can be coerced to numeric without
errors.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Mon Feb 21 12:16:05 2000
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Mon, 21 Feb 2000 11:16:05 +0000 (GMT)
Subject: [R] read.table and factor
In-Reply-To: <Pine.GSO.4.05.10002210955560.19487-100000@auk.stats>
Message-ID: <Pine.LNX.4.10.10002211110550.14276-100000@localhost.localdomain>

> as.numeric(as.character(foo)), or if you really want to save space and 
> have lots of repeated values
> 
> as.numeric(levels(foo))[as.numeric(foo)]
> 
> > How can I either tell read.table to leave the first two cols as numeric
> > (not factors) or convert them from factors into the proper numeric values?

I found the source of the problem--it was not read.table!
After reading in the data frame I do:
d<-aggregate(d[,-(1:2)], by=list(std=d$std, cf=d$cf), sum)
*This* makes std and cf into factors.

Anyway I have a good solution: as.numeric(as.character(foo))
[It might be better to find a way to collapse the data without using
aggregate().]

Thanks very much for the help Brian.

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Feb 21 11:20:01 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Feb 2000 11:20:01 +0100
Subject: [R] read.table and factor
In-Reply-To: Bill Simpson's message of "Mon, 21 Feb 2000 11:01:27 +0000 (GMT)"
References: <Pine.LNX.4.10.10002211056550.14081-200000@localhost.localdomain>
Message-ID: <x2snymkgby.fsf@blueberry.kubism.ku.dk>

Bill Simpson <wsi at gcal.ac.uk> writes:

> No, so far as I can tell neither std nor cf contain non-numeric elements.
> This problem arises with every data file I read (the files are created by
> a C program). I attach a file--std and cf are numeric, yet read.table
> 
> d<-read.table("~/papers/letter/data/ws60.dat",header=TRUE)
> 
> makes d$std and d$cf factors.


?????!!!...:

> summary(read.table('/tmp/billS.txt', header=T))
      std             cf            hit             miss            fa       
 Min.   : 800   Min.   : 860   Min.   :20.00   Min.   : 1.0   Min.   : 5.00  
 1st Qu.: 890   1st Qu.: 950   1st Qu.:32.00   1st Qu.:10.0   1st Qu.:11.00  
 Median : 995   Median :1055   Median :35.50   Median :13.0   Median :14.00  
 Mean   : 995   Mean   :1055   Mean   :35.62   Mean   :12.9   Mean   :14.24  
 3rd Qu.:1100   3rd Qu.:1160   3rd Qu.:40.00   3rd Qu.:15.0   3rd Qu.:17.00  
 Max.   :1190   Max.   :1250   Max.   :49.00   Max.   :24.0   Max.   :28.00  
       cr       
 Min.   :26.00  
 1st Qu.:33.00  
 Median :37.50  
 Mean   :37.24  
 3rd Qu.:41.75  
 Max.   :54.00  


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Mon Feb 21 19:54:24 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Mon, 21 Feb 2000 10:54:24 -0800 (PST)
Subject: [R] splitstr problem
In-Reply-To: <3.0.5.32.20000221092421.009bf5e0@mail.wsl.ch>
Message-ID: <Pine.GSO.4.21.0002211044530.25558-100000@mail.biostat.washington.edu>

On Mon, 21 Feb 2000, Christian Hoffmann wrote:

> Hi all,
> 
> In my  "\R-0.65.1/src/library/base/man/"   I can only find "strsplit.Rd" giving the help to strsplit, but no "strsplit"  itself.
> 
> Can anybody tell me how to retrieve "strsplit" itself? (as R/S-Plus program)

Well, if you type the name of any function it will list itself
   > strsplit
   function (x, split)
   .Internal(strsplit(as.character(x), as.character(split)))

and you will see that this isn't very helpful.  The function is written in
C and is part of the internal compiled code.

Now, to find the C code you need to look somewhere in the subdirectories
of src/, probably in src/main. This means that you need the source, not
just a compiled version.

You can look in src/main/names.c to see what the C function is called

On Unix this is done with grep
  % cd src/main
  % fgrep strsplit names.c
   {"strsplit",    do_strsplit,    1,      11,     2,      PP_FUNCALL},
on Windows you can probably use 'Find file'

and you find that it is called do_strsplit, which is the usual naming
convention.

Now a similar search for do_strsplit shows that it is declared in
character.c, and looking in character.c reveals the function.

	-thomas


Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rdiazuri at students.wisc.edu  Mon Feb 21 20:17:12 2000
From: rdiazuri at students.wisc.edu (Ramon Diaz-Uriarte)
Date: Mon, 21 Feb 2000 20:17:12 +0100
Subject: [R] incompatibilities between 0.90 and 0.99?
Message-ID: <00022120311400.00531@ligarto>

Maybe this is dumb, but I seem to be having problems reading a file saved in R
v. 0.99 into  R 0.90.1 (in a different machine).  

I did 

>save(test1, file="test1.RData")

then I tried to read that data file in R 0.90.1:

>load("test1.RData")
Error in load("test1.RData") : restore file corrupted -- no data loaded

More info:
- both machines are running Linux; 
- things work the other way around (i.e., use save in 0.90.1 and load in 0.99); 
- things do not improve if I save as ascii;
- I get the problem even with a simple vector;
- (Things work, though, if I save the data frame with write.table, and then
use read.table).


What am I doing wrong?

Thanks,
Ramon

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at epm.net.co  Tue Feb 22 05:57:15 2000
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Mon, 21 Feb 2000 23:57:15 -0500
Subject: [R] Help with the Shapiro Wilk normality test
References: <00022120311400.00531@ligarto>
Message-ID: <38B2172B.49365FB8@epm.net.co>

Hello:

I want to ask about the accuracy of the Shapiro-Wilk's test.

I use this short program in SAS
____________________________________________________________________________
data test1;
 input x @@;
 cards;
 1.00 1.70 2.13 2.13 2.03 2.50 2.00 2.87 2.40 2.20 1.47 1.70 1.70 1.50 1.80
 1.03 0.63 0.60 1.87 1.13 1.10 1.27 0.83 0.67 1.73 2.23 2.50 1.60 1.97 2.17
 2.10 0.90 0.80 2.23 0.10 0.43 0.83 0.10 0.40 0.60 1.67 1.13 1.53 1.47 0.67
 0.50 1.03 1.33 1.73 1.27 0.90 1.70 2.17 0.70 0.90 0.70 1.07 0.23 0.57 0.90
 0.67 1.30 1.03 0.33 0.70 1.47 1.53 1.07 0.60 0.40 0.27 1.53 1.43 2.13 0.87
 1.13
 ;
run;
proc univariate data=test1 normal;
run;
_____________________________________________________________________________

And I obtain the following result for the Shapiro-Wilk's test

 W:Normal   0.960439  Pr<W  0.0602

When I use the same data in R, with the following statement:

___________________________________________________________________________________

test1<-c(1.00,1.70,2.13,2.13,2.03,2.50,2.00,2.87,2.40,2.20,1.47,1.70,1.70,1.50,1.80,

 1.03,0.63,0.60,1.87,1.13,1.10,1.27,0.83,0.67,1.73,2.23,2.50,1.60,1.97,2.17,
 2.10,0.90,0.80,2.23,0.10,0.43,0.83,0.10,0.40,0.60,1.67,1.13,1.53,1.47,0.67,
 0.50,1.03,1.33,1.73,1.27,0.90,1.70,2.17,0.70,0.90,0.70,1.07,0.23,0.57,0.90,
 0.67,1.30,1.03,0.33,0.70,1.47,1.53,1.07,0.60,0.40,0.27,1.53,1.43,2.13,0.87,
 1.13)
shapiro.test(test1)
____________________________________________________________________________________

I obtain the following answer:

       Shapiro-Wilk normality test

data:  test1
W = 0.9733, p-value = 0.1083

The rest of the statistics are the same, mean, median, sd, etc.
But I don't understand the difference in the Shapiro-Wilk's test of
normality.

Thank you very much for your help.

Kenneth Cabrera
Universidad Nacional de Colombia, Sede Medellin
Facultad de Ciencias
ICNE
Instituto de Ciencias Naturales y Ecologia
krcabrer at epm.net.co


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 22 08:22:46 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 22 Feb 2000 07:22:46 +0000 (GMT)
Subject: [R] incompatibilities between 0.90 and 0.99?
In-Reply-To: <00022120311400.00531@ligarto>
Message-ID: <Pine.GSO.4.05.10002220718320.7453-100000@auk.stats>

On Mon, 21 Feb 2000, Ramon Diaz-Uriarte wrote:

> Maybe this is dumb, but I seem to be having problems reading a file saved in R
> v. 0.99 into  R 0.90.1 (in a different machine).  
> 
> I did 
> 
> >save(test1, file="test1.RData")
> 
> then I tried to read that data file in R 0.90.1:
> 
> >load("test1.RData")
> Error in load("test1.RData") : restore file corrupted -- no data loaded
> 
> More info:
> - both machines are running Linux; 
> - things work the other way around (i.e., use save in 0.90.1 and load in 0.99); 
> - things do not improve if I save as ascii;
> - I get the problem even with a simple vector;
> - (Things work, though, if I save the data frame with write.table, and then
> use read.table).

Look at the NEWS, which says, right at the top,

    o   The format for save/load has been changed. Workspaces and
        objects saved in earlier versions can be loaded into this
        version, but not conversely. Use save() or save.image() with
        argument oldstyle=TRUE to save in the old format if you need to.

The new format is unknown to the older versions.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.malewski at tu-bs.de  Tue Feb 22 09:18:05 2000
From: p.malewski at tu-bs.de (Peter Malewski)
Date: Tue, 22 Feb 2000 09:18:05 +0100 (CET)
Subject: [R] incompatibilities between 0.90 and 0.99?
In-Reply-To: <00022120311400.00531@ligarto>
Message-ID: <Pine.LNX.4.21.0002220916480.829-100000@Uranus.Levi>

On Mon, 21 Feb 2000, Ramon Diaz-Uriarte wrote:

> Maybe this is dumb, but I seem to be having problems reading a file saved in R
> v. 0.99 into  R 0.90.1 (in a different machine).  

As the file "NEWS" says: 

    o	The format for save/load has been changed. Workspaces and
	objects saved in earlier versions can be loaded into this
	version, but not conversely. Use save() or save.image() with
	argument oldstyle=TRUE to save in the old format if you need to.


peter


**I'd never join any club that would have the likes of me as a member.GM**
P.Malewski				Tel.: 0531 500965
Maschplatz 8				mailto: Peter.Malewski at gmx.de
************************38114 Braunschweig********************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Tue Feb 22 11:46:30 2000
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Tue, 22 Feb 2000 11:46:30 +0100
Subject: [R] Inverse prediction with R?
Message-ID: <B4D82796.2132%pflugshaupt@geobot.umnw.ethz.ch>

Hello,

after some searching in the mailing list archives, R-Help and S-Plus-Help, I
dare asking the question here: How can I do inverse prediction from a lm
model with R?
What I want to achieve is this: predict term values for given new response
values. If I've got a model

t.m<-lm(y?x)

I would type something like

inverse.predict(t.m, newdata=data.frame(y=1:10))

which would give me new corresponding x values. If it returned confidence
intervals as well, I'd be in heaven :-)

All I have found is "terms prediction" in the predict.lm routine, which does
not seem to heed the "newdata=" argument and returns predicted values for
the locations that the model was built from. There seems to be no way to get
confidence intervals for those predictions, either. Moreover, the returned
values are  centered and scaled somehow that I don't understand. The help
file was a bit too terse for me.

Can I use the predict.lm function for my problem, or would I have to
implement the real thing myself? I've got a formula (from Zar,
Biostatistical Analysis), but it would take me some time and work.

Thanks (and I hope I made myself clear)

Kaspar

-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From B.Rowlingson at lancaster.ac.uk  Tue Feb 22 12:17:48 2000
From: B.Rowlingson at lancaster.ac.uk (Baz)
Date: Tue, 22 Feb 2000 11:17:48 +0000
Subject: [R] "Maps in R"
Message-ID: <38B2705C.AFAFD8C6@lancs.ac.uk>


 I've just spent a couple of idle weekends getting a version of the
S-plus 'maps' library working under R.

 For those unfamiliar with the maps library, it lets you map a 
geographical region, split into areas, and optionally colour-fill
those areas according to some variable. For example:

R> library(maps)
R> map("state",c("california","nevada","washington"))

 draws a line map of those three states.

R> map("uk",fill=T,color=pop.colour)

 draws a map of the uk with counties coloured by the pop.colour
vector.

 The system also supports map projections. You can do this:

R> map("state",proj="merc")

 to draw the map on a mercator projection. I have used the USGS
PROJ4.2 projection library, and so there are many projections
and options available. I've also added a Great Britain Ordnance
Survey grid projection to PROJ4.2, for use with maps of this
area.

 You can also do inverse projections - plot a map with a projection,
get locations with locator(), and then inverse-project them to get
back to lat-long coordinates.

 That's all the good news. The bad news is that there's a few problems
here and there, mainly related to lines that cross the +180/-180
boundary
and to certain projections - an azimuthal projection (i.e. as you would
see the earth from space) of the world map doesn't do hidden-line 
removal of the far side, it just crashes!

 So I'm looking for interested parties to have a play with the code.
Preferably people with some experience of the S/Splus maps library, or
anyone with a geographical interest. It may even be worth starting from
scratch again and building an R-GIS package from the ground up...

 Email me with your interest.

Barry Rowlingson
Maths and Stats
Lancaster University
Lancaster, UK
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jniesch at gwdg.de  Tue Feb 22 13:03:35 2000
From: jniesch at gwdg.de (jens)
Date: Tue, 22 Feb 2000 13:03:35 +0100
Subject: [R] R-0.65 installation on UNIX
Message-ID: <3.0.2.32.20000222130335.0068b118@popper.gwdg.de>

I have trouble to install R on  Sparc Sun Solaris 2.6.
make returns the error message:
Undefined symbol 		first referenced in file
d_lg10				../appl/libappl.a(uncmin.o)
d_sign				../appl/libappl.a(dpoco.o

Anybody can help me out?

	Jens
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 22 13:25:20 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Feb 2000 12:25:20 +0000 (GMT)
Subject: [R] R-0.65 installation on UNIX
Message-ID: <200002221225.MAA17326@toucan.stats.ox.ac.uk>

> Date: Tue, 22 Feb 2000 13:03:35 +0100
> From: jens <jniesch at gwdg.de>
> 
> I have trouble to install R on  Sparc Sun Solaris 2.6.
> make returns the error message:
> Undefined symbol 		first referenced in file
> d_lg10				../appl/libappl.a(uncmin.o)
> d_sign				../appl/libappl.a(dpoco.o
> 
> Anybody can help me out?

Try installing the current version, 0.99.0, which does a better
job of finding the right libraries. If that fails come back to us
with a listing of Makeconf in the top-level build directory,
and details of the compilers you used.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Tue Feb 22 13:28:41 2000
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Tue, 22 Feb 2000 13:28:41 +0100
Subject: Follow-up: [R] Inverse prediction with R?
In-Reply-To: <C125688D.0042544D.00@osla28smtp.hda.hydro.com>
Message-ID: <B4D83F88.2136%pflugshaupt@geobot.umnw.ethz.ch>

(message from 22.2.2000 13:04 Uhr):

> 
> 
> Why don't you inverse the modelling instead:
> 
> t.m.i <- lm((x~y)
> 

Jan,

thanks for the tip, but it's not just the same. The coefficients come out
differently, since the squared y residuals are minimized. Orthogonal
regression would be symmetric, but least squares is not, I'm afraid. And,
what's more, I have to state my model that way since the x values I have got
are fixed. 

Perhaps I have to explain where my problem comes from: I want to measure the
age of trees. I cannot cut them and I can take core samples only from the
bigger ones. What I can measure is the number of bud rings and branchings,
which is proportional to the age, although the measurement is rather
inaccurate. So, I 'd like to model that number based on the core samples
I've got (N?40), which are accurate, and the inversely "predict core
samples" for the rest of my trees (N?300).

Maybe there is another way to do what I intend, but at the moment I've no
clue. I'm grateful for any hint.

 

Kaspar


-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 22 14:02:45 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Feb 2000 13:02:45 +0000 (GMT)
Subject: Follow-up: [R] Inverse prediction with R?
Message-ID: <200002221302.NAA26600@toucan.stats.ox.ac.uk>

> Date: Tue, 22 Feb 2000 13:28:41 +0100
> Subject: Follow-up: [R] Inverse prediction with R?
> 
> (message from 22.2.2000 13:04 Uhr):
> 
> > 
> > 
> > Why don't you inverse the modelling instead:
> > 
> > t.m.i <- lm((x~y)
> > 
> 
> Jan,
> 
> thanks for the tip, but it's not just the same. The coefficients come out
> differently, since the squared y residuals are minimized. Orthogonal
> regression would be symmetric, but least squares is not, I'm afraid. And,
> what's more, I have to state my model that way since the x values I have got
> are fixed. 
> 
> Perhaps I have to explain where my problem comes from: I want to measure the
> age of trees. I cannot cut them and I can take core samples only from the
> bigger ones. What I can measure is the number of bud rings and branchings,
> which is proportional to the age, although the measurement is rather
> inaccurate. So, I 'd like to model that number based on the core samples
> I've got (N?40), which are accurate, and the inversely "predict core
> samples" for the rest of my trees (N?300).
> 
> Maybe there is another way to do what I intend, but at the moment I've no
> clue. I'm grateful for any hint.


So, you only have one x? Then this is a calibration problem, and the
terms you mentioned before are not relevant.

Assuming that the trees are a random sample x, is not fixed but (y,x)
are random pairs, and inverse regression is the right way to solve
the problenm. E.g. P.J. Brown (1993), `Measurement, Regression and
Calibration', OUP, page 22.  If somehow you managed to choose the
trees to have specific x's, then there would be better ways.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Tue Feb 22 15:18:19 2000
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Tue, 22 Feb 2000 14:18:19 +0000 (GMT)
Subject: Follow-up: [R] Inverse prediction with R?
In-Reply-To: <B4D83F88.2136%pflugshaupt@geobot.umnw.ethz.ch>
Message-ID: <Pine.LNX.4.10.10002221411140.15714-100000@localhost.localdomain>

You fit
y = a+b*x

Then you get the inverse regression estimate

x = (y-a)/b

I don't see what is hard about that.

As for the confidence interval for x, try bootstrapping:
- randomly sample your (x,y) data
- do the y = a+b*x fit
- get the estimate x = (y-a)/b
- use the bootstrapped x distribution to get your CI

Or use the formulas you saw in a book.

I don't see this as a hard programming project. (I am no ace R programmer
myself)

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Tue Feb 22 15:08:54 2000
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue, 22 Feb 2000 15:08:54 +0100 (CET)
Subject: Follow-up: [R] Inverse prediction with R?
In-Reply-To: <Pine.LNX.4.10.10002221411140.15714-100000@localhost.localdomain>
Message-ID: <XFMail.000222150854.plummer@iarc.fr>

My $0.02.

If y ~ a + b * (x - xbar) where xbar is the mean of the observed x values,
then a 95% confidence region for x given a new value of y may be obtained
by solving the inequality

abs (y - ahat - bhat * (x - xbar)) / 
   sqrt (Var(ahat) + (x - xbar)^2 * Var(bhat)) <= 1.96

where ahat, bhat are your estimates of a and b.  If b is significantly
different from 0 at the 5% level then this is a (usually rather skew)
interval, otherwise it may be the whole real line or two intervals.

As Brian says, this is the calibration problem. Most of the literature on
it comes from technometrics, whic isn't my field.  I found the following
review useful when I looked into this some years ago.

Osborne, C. Statistical Calibration: A Review, Intenational Statistical
Review, 51, 309-336, 1991.

Martyn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Feb 22 15:12:56 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Feb 2000 14:12:56 +0000 (GMT)
Subject: Follow-up: [R] Inverse prediction with R?
Message-ID: <200002221412.OAA10135@toucan.stats.ox.ac.uk>

> Date: Tue, 22 Feb 2000 14:18:19 +0000 (GMT)
> From: Bill Simpson <wsi at gcal.ac.uk>
> 
> You fit
> y = a+b*x
> 
> Then you get the inverse regression estimate
> 
> x = (y-a)/b
> 
> I don't see what is hard about that.
> 
> As for the confidence interval for x, try bootstrapping:
> - randomly sample your (x,y) data
> - do the y = a+b*x fit
> - get the estimate x = (y-a)/b
> - use the bootstrapped x distribution to get your CI

But that is not the right bootstrap if the sample x's were fixed,
as we were told (although I find it hard to believe), and if that
is the right bootstrap, it is the wrong inverse prediction procedure.
In most regression problems you need to bootstrap the residuals.

That CI only takes into account the uncertainty in the fitted curve,
not in that the future y, which will surely dominate.  Strictly
speaking, one wants a prediciton interval.

> Or use the formulas you saw in a book.

Yes, reading a good book on this is highly recommended. There are lots
of subtleties that provide puzzles for cognescenti of inference procedures.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From l.chikhi at qmw.ac.uk  Tue Feb 22 15:23:40 2000
From: l.chikhi at qmw.ac.uk (Lounes Chikhi)
Date: Tue, 22 Feb 2000 14:23:40 +0000
Subject: [R] Some problems with R and/or locfit
Message-ID: <38B29BEC.E5DE1D0B@qmw.ac.uk>

Hello,
Here is a problem I have had trying to install locfit, the package for
R.
I have already contacted Clive Loader who thinks the problem has more to
do with R than locfit, so here is the point :

The version of R I am currently running is R-base-0.90 that I installed
using the R-base-0.90.1-1.i386.rpm package.
I dowloaded the locfit package available at the CRAN site and ran : R
INSTALL locfit_1.00.tar.gz.
During the installation I receive the following message :


Installing package `locfit' ...
 libs
gcc -I/usr/lib/R/include -I/usr/lib/R/include/R_ext   -mieee-fp  -fPIC
-O2 -m486 -fno-strength-reduce -g -c S_enter.c -o S_enter.o
S_enter.c: In function `basis': S_enter.c:39: warning: passing arg 3 of
`call_R' from incompatible pointer type
gcc -I/usr/lib/R/include -I/usr/lib/R/include/R_ext   -mieee-fp  -fPIC
-O2 -m486 -fno-strength-reduce -g -c adap.c -o adap.o
gcc -I/usr/lib/R/include -I/usr/lib/R/include/R_ext   -mieee-fp  -fPIC
-O2 -m486 -fno-strength-reduce -g -c band.c -o band.o
...
IT SEEMS THUS TO WORK FINE UNTIL  :
...
gcc -I/usr/lib/R/include -I/usr/lib/R/include/R_ext   -mieee-fp  -fPIC
-O2 -m486 -fno-strength-reduce -g -c weight.c -o weight.o
gcc -shared  -o /usr/lib/R/library/locfit/libs/locfit.so S_enter.o
adap.o band.o density.o family.o fitted.o frend.o kappa0.o kdtree.o
lfstr.o linalg.o locfit.o math.o minmax.o nbhd.o odint.o pcomp.o
preplot.o random.o scbmax.o simul.o startlf.o vari.o wdiag.o weight.o
-L/usr/lib/gcc-lib/i386-redhat-linux/egcs-2.91.66
-L/usr/i386-redhat-linux/lib -lg2c -lm
/usr/bin/ld: cannot open -lg2c: No such file or directory  <------ HERE
IS WHERE IT REALLY SEEMS TO HAVE PROBLEMS
collect2: ld returned 1 exit status
make: *** [/usr/lib/R/library/locfit/libs/locfit.so] Error 1
 R
 data
 help
 >>> Building/Updating help pages for package `locfit'
    Formats: text html latex example
  aic                               text    html    latex
  aicplot                           text    html    latex   example
 ....
THE REST IS FINE

I have tried to change my R version by upgrading to R-base-0.99 by using
the R-base-0.99.0-4.i386.rpm. But this just does not seem to change
anything !

Since I am very far from being a computer expert, I would be happy to
understand why it just does not work. And even more happy to have it
work.
It looks like all this is caused by the absence of some libraries.
But what should I do then ? I could not find anything called lg2c or g2c

anywhere in the redHat site. Perhaps didn't I look enough ?
Thank you very much in advance for your help.
I am sorry to bother whoever may read this but I spent a whole day
trying different things before contacting this list.


Lounes Chikhi
Queen Mary and Westfield College
London,
UK

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Feb 22 15:39:34 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 22 Feb 2000 15:39:34 +0100
Subject: [R] Some problems with R and/or locfit
In-Reply-To: Lounes Chikhi's message of "Tue, 22 Feb 2000 14:23:40 +0000"
References: <38B29BEC.E5DE1D0B@qmw.ac.uk>
Message-ID: <x21z65nvx5.fsf@blueberry.kubism.ku.dk>

Lounes Chikhi <l.chikhi at qmw.ac.uk> writes:

> -L/usr/i386-redhat-linux/lib -lg2c -lm
> /usr/bin/ld: cannot open -lg2c: No such file or directory  <------ HERE
> IS WHERE IT REALLY SEEMS TO HAVE PROBLEMS
...
> Since I am very far from being a computer expert, I would be happy to
> understand why it just does not work. And even more happy to have it
> work.
> It looks like all this is caused by the absence of some libraries.
> But what should I do then ? I could not find anything called lg2c or g2c
> 
> anywhere in the redHat site. Perhaps didn't I look enough ?

They come with the Fortran compiler, egcs-g77-1.1.2-24 on this RH6.1
system to be precise.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Tue Feb 22 16:02:30 2000
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Tue, 22 Feb 2000 16:02:30 +0100
Subject: [R] Another (last?) follow-up: Inverse Prediction with R
Message-ID: <B4D86395.2142%pflugshaupt@geobot.umnw.ethz.ch>

Hello,

after I've read a few answers from the list, I realised that I stated my
problem incorrectly: my x values are not _fixed_, as I wrote (I did not set
them). They just have no errors to them, but, apart from that, are random.

I think I shall be reading up on calibration next. Many thanks for the
references!

Kaspar

-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Tue Feb 22 16:08:12 2000
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue, 22 Feb 2000 16:08:12 +0100 (CET)
Subject: [R] Some problems with R and/or locfit
In-Reply-To: <38B29BEC.E5DE1D0B@qmw.ac.uk>
Message-ID: <XFMail.000222160812.plummer@iarc.fr>

It's not a problem with R or locfit, but with your build environment
which does not match the one used to make the R RPM.

Either install the egcs-g77 package, which provides libg2c
Or     Edit /usr/lib/R/etc/Makeconf and remove the -g2c flag from FLIBS

I recommend the former.
Martyn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rdiazuri at students.wisc.edu  Tue Feb 22 09:04:10 2000
From: rdiazuri at students.wisc.edu (Ramon Diaz-Uriarte)
Date: Tue, 22 Feb 2000 09:04:10 +0100
Subject: [R] incompatibilities between 0.90 and 0.99?
In-Reply-To: <Pine.GSO.4.05.10002220718320.7453-100000@auk.stats>
References: <Pine.GSO.4.05.10002220718320.7453-100000@auk.stats>
Message-ID: <00022209082803.00594@ligarto>

Thank you very much to B. Ripley, P. Malewski and M. Wiener; they all pointed
out to NEWS (reproduced below). I should have read that first. Sorry
for the dumb question.

Ramon

On Tue, 22 Feb 2000, you wrote:
> On Mon, 21 Feb 2000, Ramon Diaz-Uriarte wrote:
> 
> > Maybe this is dumb, but I seem to be having problems reading a file saved in R
> > v. 0.99 into  R 0.90.1 (in a different machine).  
> > 
> > I did 
> > 
> > >save(test1, file="test1.RData")
> > 
> > then I tried to read that data file in R 0.90.1:
> > 
> > >load("test1.RData")
> > Error in load("test1.RData") : restore file corrupted -- no data loaded
> > 
> > More info:
> > - both machines are running Linux; 
> > - things work the other way around (i.e., use save in 0.90.1 and load in 0.99); 
> > - things do not improve if I save as ascii;
> > - I get the problem even with a simple vector;
> > - (Things work, though, if I save the data frame with write.table, and then
> > use read.table).
> 
>     o   The format for save/load has been changed. Workspaces and
>         objects saved in earlier versions can be loaded into this
>         version, but not conversely. Use save() or save.image() with
>         argument oldstyle=TRUE to save in the old format if you need to.
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jniesch at gwdg.de  Tue Feb 22 16:35:15 2000
From: jniesch at gwdg.de (jens)
Date: Tue, 22 Feb 2000 16:35:15 +0100
Subject: [R] R-0.99 installation on UNIX/got it
Message-ID: <3.0.2.32.20000222163515.0068cd24@popper.gwdg.de>

I installed the FORTRAN compiler g77 version 0.5.23 and used it instead of
f2c and had no problems to get R-0.99.0 to run.
	Jens
> Date: Tue, 22 Feb 2000 13:03:35 +0100
> From: jens <jniesch at gwdg.de>
> 
> I have trouble to install R on  Sparc Sun Solaris 2.6.
> make returns the error message:
> Undefined symbol 		first referenced in file
> d_lg10				../appl/libappl.a(uncmin.o)
> d_sign				../appl/libappl.a(dpoco.o
> 
> Anybody can help me out?

Try installing the current version, 0.99.0, which does a better
job of finding the right libraries. If that fails come back to us
with a listing of Makeconf in the top-level build directory,
and details of the compilers you used.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kelley at Phys.Ocean.Dal.CA  Tue Feb 22 16:50:19 2000
From: kelley at Phys.Ocean.Dal.CA (Dan E. Kelley)
Date: Tue, 22 Feb 2000 11:50:19 -0400 (AST)
Subject: [R] 'function name not in load table' (nlme)
In-Reply-To: <200002221302.NAA26600@toucan.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.10.10002221146260.30055-100000@Intrusion.Phys.Ocean.Dal.Ca>

When I try to run 'gnls' from the nlme library, I get the error: 

	fb.result <- gnls(0 ~ err2(sigma0, F, z, rho),
	                 start=list(sigma0=46,F=7000))
	Error in .C("fit_gnls", thetaNLS = as.double(spar),
	as.integer(unlist(Dims)),  : 
	C/Fortran function name not in load table

I'd be very grateful for any advice as to how I should proceed.  Thanks!

PS: I'm using R-base-0.99.0-4 (redhat-6.1 linux) with nlme_3.1-3.tar.gz.

Dan E. Kelley                   internet:   mailto:Dan.Kelley at Dal.CA
Oceanography Department         phone:                 (902)494-1694
Dalhousie University            fax:                   (902)494-2885
Halifax, NS, CANADA, B3H 4J1    http://www.phys.ocean.dal.ca/~kelley

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From camann at babylon.cnrs.humboldt.edu  Tue Feb 22 05:21:00 2000
From: camann at babylon.cnrs.humboldt.edu (Michael Camann)
Date: Mon, 21 Feb 2000 20:21:00 -0800
Subject: [R] identify() output doesn't print
Message-ID: <200002220421.UAA01323@babylon.cnrs.humboldt.edu>

Hope this isn't a faq, but....

I'm using R 0.99 for Windows under Win98.  When I label points in a scatterplot 
with identify(), the labels appear as expected on the graphics device, but do 
not print when I select the printer icon.  The scatter plot itself prints just 
fine-- only the output from identfy() is missing.  Can anyone offer any hints?

--Mike C.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Michael A. Camann                                    mac24 at axe.humboldt.edu
Assistant Professor of Zoology                         Voice: 707-826-3676
Dept. of Biological Sciences                                Fax: 707-826-3201
Humboldt State University
Arcata, CA 95521-8299

                 http://www.humboldt.edu/~mac24/camann.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From york at noaa.gov  Wed Feb 23 01:18:12 2000
From: york at noaa.gov (Anne York)
Date: Tue, 22 Feb 2000 16:18:12 -0800 (PST)
Subject: [R] Files unavailable on CRAN
Message-ID: <Pine.GSO.4.05.10002221614400.3174-100000@ofis450a.akctr.noaa.gov>

I've been trying to download from CRAN the floppy versions of the R source
files:

R-release-1.tar.gz, R-release-2.tar.gz 

I tried the servers in Seattle, Madison,  and the Vienna
Technical University. In each case, the file(s) were unavailable.  

Anne
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at epm.net.co  Wed Feb 23 01:21:49 2000
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Tue, 22 Feb 2000 19:21:49 -0500
Subject: [R] Thank you!
References: <Pine.GSO.4.05.10002220812550.15948-100000@ofis450a.akctr.noaa.gov>
Message-ID: <38B3281C.C1CC7F80@epm.net.co>

Thank you very much for your help, your fuction runs on R without
any change, and the results are the same that your obtain with Splus,
but there still a small difference.

In SAS
W=0.960439

With your shapiro.wilk.test
W=0.9606107

But the p-values are almost the same.

Thank you very much for your help.

> Here is a function for the Shapiro-wilk test that I obtained from StatLib.
> Using this function in Splus, with  your sample, it gives the same values
> as the SAS routine. I'll copy it into R later today and see what happens.
>
> Cheers,
>
> Anne
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Anne E. York
> National Marine Mammal Laboratory
> Seattle WA 98115-0070  USA
> e-mail: anne.york at noaa.gov
> Voice: +1 206-526-4039
> Fax: +1 206-526-6615
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
> Shapiro.Wilk.test(test1)
> $W:
> [1] 0.9606107
>
> $n:
> [1] 76
>
> $p:
> [1] 0.06176898
>
> +++++++++++++++++++++++++++++++++++++++++++
> "Shapiro.Wilk.test" <- function(x)
> {
> #
> #This function is an S version of the procedure described by
> # J. P. Royston (1982) in "An Extension of Shapiro and Wilk's W Test
> # for Normality to Large Samples" from Applied Statistics, 31 no.2
> #  pp. 115-124.
> #
>         n <- length(x)
>         index <- 1:n
>         m <- qnorm((index - 0.375)/(n + 0.25))
>         y <- sort(x)
>         mu <- mean(y)
>         SSq <- sum((y - mu)^2)
>         astar <- 2 * m
>         ends <- c(1, n)
>         astar.p <- astar[ - ends]
>         if(n <= 20)
>                 m <- n - 1
>         else m <- n
>         if(m < 20)
>                 aa <- gamma(0.5 * (m + 1))/(sqrt(2) * gamma(0.5 * m + 1))
>         else {
>                 f1 <- (6 * m + 7)/(6 * m + 13)
>                 f2 <- exp(1)/(m + 2)
>                 f3 <- (m + 1)/(m + 2)
>                 f3 <- f3^(m - 2)
>                 aa <- f1 * sqrt(f2 * f3)
>         }
>         astar.1 <- (aa * sum(astar.p^2))/(1 - 2 * aa)
>         astar.1 <- sqrt(astar.1)
>         astar[1] <-  - astar.1
>         astar[n] <- astar.1
>         A <- astar/sqrt(sum(astar^2))
>         W <- (sum(A * y)^2)/SSq
>         if(n <= 20) {
>                 u <- log(n) - 3
>                 lambda <- 0.118898 + 0.133414 * u + 0.327907 * u^2
>                 logmu <- -0.37542 - 0.492145 * u - 1.124332 * u^2 -
> 0.199422 *
>                         u^3
>                 logsigma <- -3.15805 + 0.729399 * u + 3.01855 * u^2 +
> 1.558776
> *
>                         u^3
>         }
>         if(n > 20) {
>                 u <- log(n) - 5
>                 lambda <- 0.480385 + 0.318828 * u - 0.0241665 * u^3 +
>                         0.00879701 * u^4 + 0.002989646 * u^5
>                 logmu <- -1.91487 - 1.37888 * u - 0.04183209 * u^2 +
> 0.1066339
> *
>                         u^3 - 0.03513666 * u^4 - 0.01504614 * u^5
>                 logsigma <- -3.73538 - 1.015807 * u - 0.331885 * u^2 +
>                         0.1773538 * u^3 - 0.01638782 * u^4 - 0.03215018 *
> u^5 +
>
>                         0.003852646 * u^6
>         }
>         mu <- exp(logmu)
>         sigma <- exp(logsigma)
>         y <- (1 - W)^lambda
>         z <- (y - mu)/sigma
>         p <- 1 - pnorm(z)
>         if(n < 7) {
>                 warning("n is too small for this program to correctly
> estimate
> p\n"
>                         )
>                 p <- NA
>         }
>         if(n > 2000) {
>                 warning("n is too large for this program to correctly
> estimate
> p\n"
>                         )
>                 p <- NA
>         }
>         out <- list(W = W, n = n, p = p)
>         out
> }
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
> On Mon, 21 Feb 2000, Kenneth Cabrera wrote:
>
> >Hello:
> >
> >I want to ask about the accuracy of the Shapiro-Wilk's test.
> >
> >I use this short program in SAS
> >____________________________________________________________________________
> >data test1;
> > input x @@;
> > cards;
> > 1.00 1.70 2.13 2.13 2.03 2.50 2.00 2.87 2.40 2.20 1.47 1.70 1.70 1.50 1.80
> > 1.03 0.63 0.60 1.87 1.13 1.10 1.27 0.83 0.67 1.73 2.23 2.50 1.60 1.97 2.17
> > 2.10 0.90 0.80 2.23 0.10 0.43 0.83 0.10 0.40 0.60 1.67 1.13 1.53 1.47 0.67
> > 0.50 1.03 1.33 1.73 1.27 0.90 1.70 2.17 0.70 0.90 0.70 1.07 0.23 0.57 0.90
> > 0.67 1.30 1.03 0.33 0.70 1.47 1.53 1.07 0.60 0.40 0.27 1.53 1.43 2.13 0.87
> > 1.13
> > ;
> >run;
> >proc univariate data=test1 normal;
> >run;
> >_____________________________________________________________________________
> >
> >And I obtain the following result for the Shapiro-Wilk's test
> >
> > W:Normal   0.960439  Pr<W  0.0602
> >
> >When I use the same data in R, with the following statement:
> >
> >___________________________________________________________________________________
> >
> >test1<-c(1.00,1.70,2.13,2.13,2.03,2.50,2.00,2.87,2.40,2.20,1.47,1.70,1.70,1.50,1.80,
> >
> > 1.03,0.63,0.60,1.87,1.13,1.10,1.27,0.83,0.67,1.73,2.23,2.50,1.60,1.97,2.17,
> > 2.10,0.90,0.80,2.23,0.10,0.43,0.83,0.10,0.40,0.60,1.67,1.13,1.53,1.47,0.67,
> > 0.50,1.03,1.33,1.73,1.27,0.90,1.70,2.17,0.70,0.90,0.70,1.07,0.23,0.57,0.90,
> > 0.67,1.30,1.03,0.33,0.70,1.47,1.53,1.07,0.60,0.40,0.27,1.53,1.43,2.13,0.87,
> > 1.13)
> >shapiro.test(test1)
> >____________________________________________________________________________________
> >
> >I obtain the following answer:
> >
> >       Shapiro-Wilk normality test
> >
> >data:  test1
> >W = 0.9733, p-value = 0.1083
> >
> >The rest of the statistics are the same, mean, median, sd, etc.
> >But I don't understand the difference in the Shapiro-Wilk's test of
> >normality.
> >
> >Thank you very much for your help.
> >
> >Kenneth Cabrera
> >Universidad Nacional de Colombia, Sede Medellin
> >Facultad de Ciencias
> >ICNE
> >Instituto de Ciencias Naturales y Ecologia
> >krcabrer at epm.net.co
> >
> >
> >-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> >r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >Send "info", "help", or "[un]subscribe"
> >(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Wed Feb 23 01:49:49 2000
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Tue, 22 Feb 2000 16:49:49 -0800 (PST)
Subject: [R] Files unavailable on CRAN
In-Reply-To: <Pine.GSO.4.05.10002221614400.3174-100000@ofis450a.akctr.noaa.gov>
Message-ID: <Pine.GSO.4.21.0002221645540.11812-100000@mail.biostat.washington.edu>

On Tue, 22 Feb 2000, Anne York wrote:

> I've been trying to download from CRAN the floppy versions of the R source
> files:
> 
> R-release-1.tar.gz, R-release-2.tar.gz 


The URL is wrong for these files

Try 
   www.r-project.org/src/devel/floppies/R-release-1.tar.gz
(ie /floppies/ instead of /floppy/)
and similarly for -2

> I tried the servers in Seattle, Madison,  and the Vienna
> Technical University. In each case, the file(s) were unavailable.  

There hasn't been a server in Seattle for a long time. The other two
should work.

	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle


> 
> Anne
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Anne E. York
> National Marine Mammal Laboratory
> Seattle WA 98115-0070  USA
> e-mail: anne.york at noaa.gov
> Voice: +1 206-526-4039
> Fax: +1 206-526-6615
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laniel at cmu.edu  Wed Feb 23 02:36:54 2000
From: laniel at cmu.edu (Stephen R. Laniel)
Date: Tue, 22 Feb 2000 20:36:54 -0500
Subject: [R] Large datasets under R
Message-ID: <2064042444.951251814@GROATS184.PPP.ANDREW.CMU.EDU>

Hello,

I recall reading a thread months ago on this mailing list about handling
very datasets under R, but I can't seem to find it.  This has become
particularly important recently, because I've been playing with a dataset
containing information about every fatal car accident in the U.S. since
1975; in total, the relevant files are about 120 megs.  I'd like to load
all of these into R at once and do some longitudinal analyses.  R seems to
choke on tables above a few megabytes.  From what I can tell, these are
memory management issues; the user must allocate memory using command-line
switches.

I'm using R 0.90 under Windows NT 4.0.  Have things improved in more recent
versions?  Are they expected to improve soon?  In the meantime, what can we
do to make large-dataset analysis more convenient?

Thanks,
Steve

Stephen R. Laniel            |  "Farewell Angelina
Carnegie Mellon University   |   The sky is erupting
laniel at cmu.edu               |   I must go where it's quiet."
www.stat.cmu.edu/~laniel/    |   --Bob Dylan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arnholt at math.appstate.edu  Wed Feb 23 03:08:47 2000
From: arnholt at math.appstate.edu (Alan T. Arnholt)
Date: Tue, 22 Feb 2000 21:08:47 -0500 (EST)
Subject: [R] Lack of Fit test
In-Reply-To: <Pine.GSO.4.05.10002221614400.3174-100000@ofis450a.akctr.noaa.gov>
Message-ID: <SIMEON.10002222147.A@arnholtat.math.appstate.edu>

Does anyone know of a "Lack of Fit" program for 
regression or have any thoughts on how one might work with 
"lm" to create such code?  Many thanks in advance.

Alan   

----------------------
Alan T. Arnholt
Associate Professor
Department of Mathematical Sciences
Appalachian State University
Boone, NC 28608

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paul at stat.auckland.ac.nz  Wed Feb 23 03:52:24 2000
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 23 Feb 2000 15:52:24 +1300
Subject: [R] identify() output doesn't print
References: <200002220421.UAA01323@babylon.cnrs.humboldt.edu>
Message-ID: <00e801bf7da9$0356abe0$175dd882@stat.auckland.ac.nz>

hi


> I'm using R 0.99 for Windows under Win98.  When I label points in a
scatterplot
> with identify(), the labels appear as expected on the graphics device, but
do
> not print when I select the printer icon.  The scatter plot itself prints
just
> fine-- only the output from identfy() is missing.  Can anyone offer any
hints?


its a bug.
there is now a fix which will appear in 1.0.0 (early next week)
thanks for drawing our attention to it :)

if you can't wait, you can probably do what you want with something like ...

x <- 1:10
y <- 1:10
plot(x, y)
temp <- identify(x, y, pos=TRUE)
text(x[temp$ind], y[temp$ind], temp$ind, pos=temp$pos)

paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From William.Venables at cmis.CSIRO.AU  Wed Feb 23 03:48:49 2000
From: William.Venables at cmis.CSIRO.AU (Bill Venables)
Date: Wed, 23 Feb 2000 12:48:49 +1000
Subject: [R] Lack of Fit test 
In-Reply-To: Your message of "Tue, 22 Feb 2000 21:08:47 EST."
             <SIMEON.10002222147.A@arnholtat.math.appstate.edu> 
Message-ID: <200002230248.NAA02775@snowy.nsw.cmis.CSIRO.AU>

Alan T. Arnholt asks:

> Does anyone know of a "Lack of Fit" program for regression or
> have any thoughts on how one might work with "lm" to create
> such code?  Many thanks in advance.

There is no canonical way of doing this.  This is primarily why
people use regression diagnostics.

Most standard tests for lack of fit, such as chi-squared tests,
amount to testing the current model within some global model that
contains all realistic models as special cases.  With regression
models that information has to be used to estimate the variance,
and indeed if you knew sigma^2 beforehand you could use the RSS
for a chi-squared test of lack of fit, but mostly you do not know
sigma^2 beforehand.

The same idea can be used to produce a special purpose test for
lack of fit, even if it must lack the global aspect of standard
chi-squared test.  What you do is dream up a larger model that
contains the model you are considering as a special case but has
enough flexibility to cater for any of the kinds of lack of fit
you think might be worth checking for.  The larger model still
has to have enough residual degrees of freedom, though, to allow
you to estimate sigma^2 in a fairly stable manner (you might even
consider doing it robustly).  Then test the chosen model within
the outer model in the standard way.

Of course this demands that you have enough knowledge of the
situation to choose the outer model satisfactorily.  It makes it
impossible to write code to do it automatically, but if you know
what you are doing the procedure is simple with the software you
have.  As with so many things in statistics, it is not a matter
of good software so much as of having a good understanding of the
problem in hand.

Bill Venables.
-- 
Bill Venables,      Statistician,     CMIS Environmetrics Project
CSIRO Marine Labs, PO Box 120, Cleveland, Qld,  AUSTRALIA.   4163
Tel: +61 7 3826 7251           Email: Bill.Venables at cmis.csiro.au    
Fax: +61 7 3826 7304      http://www.cmis.csiro.au/bill.venables/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb 23 09:27:00 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 23 Feb 2000 08:27:00 +0000 (GMT)
Subject: [R] Large datasets under R
In-Reply-To: <2064042444.951251814@GROATS184.PPP.ANDREW.CMU.EDU>
Message-ID: <Pine.GSO.4.05.10002230822560.4666-100000@auk.stats>

On Tue, 22 Feb 2000, Stephen R. Laniel wrote:

> Hello,
> 
> I recall reading a thread months ago on this mailing list about handling
> very datasets under R, but I can't seem to find it.  This has become
> particularly important recently, because I've been playing with a dataset
> containing information about every fatal car accident in the U.S. since
> 1975; in total, the relevant files are about 120 megs.  I'd like to load
> all of these into R at once and do some longitudinal analyses.  R seems to
> choke on tables above a few megabytes.  From what I can tell, these are
> memory management issues; the user must allocate memory using command-line
> switches.

Yes, ?Memory will tell you how.

> I'm using R 0.90 under Windows NT 4.0.  Have things improved in more recent
> versions?  Are they expected to improve soon?  

No, not for that size of dataset.  The current garbage collector is too
slow: this might change fairly soon.

> In the meantime, what can we
> do to make large-dataset analysis more convenient?

The idea is to use interfaces to databases to pull over just the bits of
the dataset which are needed, including doing the analyses in chunks. There
are several database interfaces around, and plans to pull them into a
common


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Wed Feb 23 09:31:29 2000
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich Leisch)
Date: Wed, 23 Feb 2000 09:31:29 +0100 (CET)
Subject: [R] Files unavailable on CRAN
In-Reply-To: <Pine.GSO.4.21.0002221645540.11812-100000@mail.biostat.washington.edu>
References: <Pine.GSO.4.05.10002221614400.3174-100000@ofis450a.akctr.noaa.gov>
	<Pine.GSO.4.21.0002221645540.11812-100000@mail.biostat.washington.edu>
Message-ID: <14515.39650.11509.834265@galadriel.ci.tuwien.ac.at>

>>>>> On Tue, 22 Feb 2000 16:49:49 -0800 (PST),
>>>>> Thomas Lumley (TL) wrote:

TL> On Tue, 22 Feb 2000, Anne York wrote:
>> I've been trying to download from CRAN the floppy versions of the R source
>> files:
>> 
>> R-release-1.tar.gz, R-release-2.tar.gz 


TL> The URL is wrong for these files

TL> Try 
TL>    www.r-project.org/src/devel/floppies/R-release-1.tar.gz
TL> (ie /floppies/ instead of /floppy/)
TL> and similarly for -2


Fixed on CRAN now, thanks a lot for pointing this out!

Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich  Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
     PGP public key http://www.ci.tuwien.ac.at/~leisch/pgp.key
-------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ihaka at stat.auckland.ac.nz  Wed Feb 23 09:50:29 2000
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Wed, 23 Feb 2000 21:50:29 +1300
Subject: [R] Large datasets under R
In-Reply-To: <Pine.GSO.4.05.10002230822560.4666-100000@auk.stats>; from Prof Brian D Ripley on Wed, Feb 23, 2000 at 08:27:00AM +0000
References: <2064042444.951251814@GROATS184.PPP.ANDREW.CMU.EDU> <Pine.GSO.4.05.10002230822560.4666-100000@auk.stats>
Message-ID: <20000223215029.A14593@stat1.stat.auckland.ac.nz>

On Wed, Feb 23, 2000 at 08:27:00AM +0000, Prof Brian D Ripley wrote:
> On Tue, 22 Feb 2000, Stephen R. Laniel wrote:
> 
> > Hello,
> > 
> > I recall reading a thread months ago on this mailing list about handling
> > very datasets under R, but I can't seem to find it.  This has become
> > particularly important recently, because I've been playing with a dataset
> > containing information about every fatal car accident in the U.S. since
> > 1975; in total, the relevant files are about 120 megs.  I'd like to load
> > all of these into R at once and do some longitudinal analyses.  R seems to
> > choke on tables above a few megabytes.  From what I can tell, these are
> > memory management issues; the user must allocate memory using command-line
> > switches.
> 
> Yes, ?Memory will tell you how.
> 
> > I'm using R 0.90 under Windows NT 4.0.  Have things improved in more recent
> > versions?  Are they expected to improve soon?  
> 
> No, not for that size of dataset.  The current garbage collector is too
> slow: this might change fairly soon.

Just to add some details.  The easy (== feasible) approach here is to
store all system objects using "malloc" when they are assigned,
rather than putting them into the space examined by the collector.
This means that the collector will only inspect the user's data and
hopefully this will spead things up a lot.

In addition, Robert has plans to support demand loading of objects
from external files using exception handling.  This means that only
the objects being used need reside in memory.  This is very much like
the S approach.

Mucking about with memory management is quite likely to break a ton
of stuff, so it won't happen until we get a bit more stability
(i.e. post 1.0).

	Ross
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kurt.Hornik at ci.tuwien.ac.at  Wed Feb 23 09:58:43 2000
From: Kurt.Hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Wed, 23 Feb 2000 09:58:43 +0100 (CET)
Subject: [R] Help with the Shapiro Wilk normality test
In-Reply-To: <38B2172B.49365FB8@epm.net.co>
References: <00022120311400.00531@ligarto>
	<38B2172B.49365FB8@epm.net.co>
Message-ID: <14515.41283.81139.974192@aragorn.ci.tuwien.ac.at>

>>>>> Kenneth Cabrera writes:

> Hello:
> I want to ask about the accuracy of the Shapiro-Wilk's test.

> I use this short program in SAS
> ____________________________________________________________________________
> data test1;
>  input x @@;
>  cards;
>  1.00 1.70 2.13 2.13 2.03 2.50 2.00 2.87 2.40 2.20 1.47 1.70 1.70 1.50 1.80
>  1.03 0.63 0.60 1.87 1.13 1.10 1.27 0.83 0.67 1.73 2.23 2.50 1.60 1.97 2.17
>  2.10 0.90 0.80 2.23 0.10 0.43 0.83 0.10 0.40 0.60 1.67 1.13 1.53 1.47 0.67
>  0.50 1.03 1.33 1.73 1.27 0.90 1.70 2.17 0.70 0.90 0.70 1.07 0.23 0.57 0.90
>  0.67 1.30 1.03 0.33 0.70 1.47 1.53 1.07 0.60 0.40 0.27 1.53 1.43 2.13 0.87
>  1.13
>  ;
> run;
> proc univariate data=test1 normal;
> run;
> _____________________________________________________________________________

> And I obtain the following result for the Shapiro-Wilk's test

>  W:Normal   0.960439  Pr<W  0.0602

> When I use the same data in R, with the following statement:

> ___________________________________________________________________________________

> test1<-c(1.00,1.70,2.13,2.13,2.03,2.50,2.00,2.87,2.40,2.20,1.47,1.70,1.70,1.50,1.80,

>  1.03,0.63,0.60,1.87,1.13,1.10,1.27,0.83,0.67,1.73,2.23,2.50,1.60,1.97,2.17,
>  2.10,0.90,0.80,2.23,0.10,0.43,0.83,0.10,0.40,0.60,1.67,1.13,1.53,1.47,0.67,
>  0.50,1.03,1.33,1.73,1.27,0.90,1.70,2.17,0.70,0.90,0.70,1.07,0.23,0.57,0.90,
>  0.67,1.30,1.03,0.33,0.70,1.47,1.53,1.07,0.60,0.40,0.27,1.53,1.43,2.13,0.87,
>  1.13)
> shapiro.test(test1)
> ____________________________________________________________________________________

> I obtain the following answer:

>        Shapiro-Wilk normality test

> data:  test1
> W = 0.9733, p-value = 0.1083

> The rest of the statistics are the same, mean, median, sd, etc.
> But I don't understand the difference in the Shapiro-Wilk's test of
> normality.

> Thank you very much for your help.

> Kenneth Cabrera
> Universidad Nacional de Colombia, Sede Medellin
> Facultad de Ciencias
> ICNE
> Instituto de Ciencias Naturales y Ecologia
> krcabrer at epm.net.co

I think I was contacted and taught about this some time ago.  If I
recall it correctly, I was told that R's version (which is based on AS
R94) is correct whereas SAS's (apparently based on AS 181) is not.

>From the apstat index:

         R94 --> calculates Shapiro-Wilk normality test and P-value for sample
            sizes 3 <= n <= 5000 .  Handles censored or uncensored data.
            Corrects AS 181, which was found to be inaccurate for n > 50.

Hope this helps.

-k
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From use at eio.uva.es  Wed Feb 23 12:29:43 2000
From: use at eio.uva.es (=?iso-8859-1?Q?Eusebio_Arenal_Guti=E9rrez?=)
Date: Wed, 23 Feb 2000 12:29:43 +0100
Subject: [R] Console font size
Message-ID: <000101bf7df1$48a42310$6458589d@palent.etsiiaa.uva.es>

It is posible to change the console font size? What in the funtion needed?

Tanks in advance

Eusebio

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Joerg.Kindermann at gmd.de  Wed Feb 23 11:49:40 2000
From: Joerg.Kindermann at gmd.de (Joerg Kindermann)
Date: Wed, 23 Feb 2000 11:49:40 +0100 (MET)
Subject: [R] Version 0.90.1 bug report on matrix indexing
Message-ID: <200002231049.LAA08418@alderney.gmd.de>


Hi ,

R Version 0.90.1 on Solaris2.5 and Suse Linux 6.[1,3] crashes some time
after a matrix row or column has been addressed via an incorrect
row/colname:


R : Copyright 1999, The R Development Core Team
Version 0.90.1  (December 15, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type    "?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type    "?contributors" for a list.

Type    "demo()" for some demos, "help()" for on-line help, or
        "help.start()" for a HTML browser interface to help.
Type    "q()" to quit R.


Attaching Package "package:genproc":


        The following object(s) are masked from package:base :

         date unix 

> bla_matrix(1:24,nc=6)
> dimnames(bla) _ list(1:4,1:6)
> bla
  1 2  3  4  5  6
1 1 5  9 13 17 21
2 2 6 10 14 18 22
3 3 7 11 15 19 23
4 4 8 12 16 20 24
> bla["a",]_.6
> bla
  1   2    3    4    5    6
1 1 0.6  0.6  0.6  0.6  0.6
2 2 6.0 10.0 14.0 18.0 22.0
3 3 7.0 11.0 15.0 19.0 23.0
4 4 8.0 12.0 16.0 20.0 24.0
> gc()
Bus error

--  Dr. Joerg Kindermann             GMD - AiS
            German National Research Center for Information Technology
                Schloss Birlinghoven, D-53754 St. Augustin, Germany
                   phone: +49 02241 142437 fax: +49 02241 142342
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Wed Feb 23 11:52:50 2000
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich Leisch)
Date: Wed, 23 Feb 2000 11:52:50 +0100 (CET)
Subject: [R] Console font size
In-Reply-To: <000101bf7df1$48a42310$6458589d@palent.etsiiaa.uva.es>
References: <000101bf7df1$48a42310$6458589d@palent.etsiiaa.uva.es>
Message-ID: <14515.48130.988994.356720@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 23 Feb 2000 12:29:43 +0100,
>>>>> =?iso-8859-1?Q?Eusebio Arenal Guti=E9rrez?= (=AG) wrote:

=AG> It is posible to change the console font size? What in the funtion needed?
=AG> Tanks in advance

It would be a LOT easier to help you out if you gave at least some
minimal information regarding which platform you are using. On my
Linux box running R in Emacs I change the font using using
SHIFT+(LEFT MOUSE BUTTON) ... but that won't be of any help, e.g., on
windows ...

-- 
-------------------------------------------------------------------
                        Friedrich  Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
     PGP public key http://www.ci.tuwien.ac.at/~leisch/pgp.key
-------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb 23 12:19:04 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Feb 2000 12:19:04 +0100
Subject: [R] Version 0.90.1 bug report on matrix indexing
In-Reply-To: Joerg Kindermann's message of "Wed, 23 Feb 2000 11:49:40 +0100 (MET)"
References: <200002231049.LAA08418@alderney.gmd.de>
Message-ID: <x266vg88uv.fsf@blueberry.kubism.ku.dk>

Joerg Kindermann <Joerg.Kindermann at gmd.de> writes:

> 
> > bla_matrix(1:24,nc=6)
> > dimnames(bla) _ list(1:4,1:6)
> > bla
>   1 2  3  4  5  6
> 1 1 5  9 13 17 21
> 2 2 6 10 14 18 22
> 3 3 7 11 15 19 23
> 4 4 8 12 16 20 24
> > bla["a",]_.6
> > bla
>   1   2    3    4    5    6
> 1 1 0.6  0.6  0.6  0.6  0.6
> 2 2 6.0 10.0 14.0 18.0 22.0
> 3 3 7.0 11.0 15.0 19.0 23.0
> 4 4 8.0 12.0 16.0 20.0 24.0
> > gc()
> Bus error

Still present in (yesterdays) 1.0.0pre. Thanks for the report.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kurt.Hornik at ci.tuwien.ac.at  Wed Feb 23 12:32:17 2000
From: Kurt.Hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Wed, 23 Feb 2000 12:32:17 +0100 (CET)
Subject: [R] Problem with Dates 
In-Reply-To: <38A9C070.A884FC16@nauticom.net>
References: <200002151828.NAA24011@jessie.research.bell-labs.com>
	<38A9C070.A884FC16@nauticom.net>
Message-ID: <14515.50497.296467.512371@aragorn.ci.tuwien.ac.at>

>>>>> Richard A Bilonick writes:

> Hi,

> My dates are printing as 01/01/100 instead of 01/01/2000. I can't find
> a way to get mm/dd/yyyy type format. I've tried using
> out.format="mm/dd/yyyy" but it writes out the month name (and that is
> all). I've installed both chron and date. The version of R is 0.65.1.

Chron does not support mm/dd/yyyy etc formats.  I am planning to add
improved full-year formatting capabilities to chron eventually, but this
may take some time.  Meanwhile, you can always use

	out.format = "mon day year"

(which will use spaces as separators), or try writing your own format.

One quick hack for output formatting:

mdY <- function(x) {
    out <- month.day.year(x)
    paste(formatC(out$m, width = 2, flag = "0"),
          formatC(out$d, width = 2, flag = "0"),
          out$y,
          sep = "/")
}

R> x <- chron(15000, out.format = mdY)
R> x
[1] 01/26/2011

-k
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From use at eio.uva.es  Wed Feb 23 13:25:42 2000
From: use at eio.uva.es (=?iso-8859-1?Q?Eusebio_Arenal_Guti=E9rrez?=)
Date: Wed, 23 Feb 2000 13:25:42 +0100
Subject: [R] Console font size
Message-ID: <000101bf7df9$1ae7a2a0$6458589d@palent.etsiiaa.uva.es>

Friedrich Leisch point me out that in my first message I forgot the R
version: R 0.99.0 for Windows 9x-NT

It is posible to change the console font size? What is the funtion needed?

Tanks in advance

Eusebio


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kurt.Hornik at ci.tuwien.ac.at  Wed Feb 23 12:46:53 2000
From: Kurt.Hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Wed, 23 Feb 2000 12:46:53 +0100 (CET)
Subject: [R] chron and mysql
In-Reply-To: <38A9E9DF.55866CAD@students.cas.unt.edu>
References: <38A9E9DF.55866CAD@students.cas.unt.edu>
Message-ID: <14515.51373.664751.999917@aragorn.ci.tuwien.ac.at>

>>>>> Joel Allen writes:

> R 0.90.1
> chron 2.2-2
> MySQL 3.22.30

> Attempts to create a chron object fail when using date and time data
> from a mysql database.   It appears that chron does not like 4 digit
> years.  Is this the problem?

Yes, and no.  The current design of chron is meant to use `y' as a
2-digit only year qualifier.  Version 2.2-2 has added code which will
make this work across 2000 as well.

To ready that in, you can easily write your own code.  E.g.,

infmt <- function(str) {
    x <- strsplit(str, "-")
    i <- seq(from = 0, length = length(x), by = 3)
    x <- as.integer(unlist(x))
    julian(y = x[i+1], m = x[i+2], d = x[i+3])
}

R> chron(infmt(c("2000-03-12", "1999-12-22")))
[1] 03/12/00 12/22/99

-k

> my data look like:

>> c.time[1:10,]
>          Date     Time
> 1  2000-02-14 10:15:02
> 2  2000-02-14 10:17:03
> 3  2000-02-14 10:18:03
> 4  2000-02-14 10:19:03
> 5  2000-02-14 10:20:04
> 6  2000-02-14 10:21:04
> 7  2000-02-14 10:22:04
> 8  2000-02-14 10:23:05
> 9  2000-02-14 10:24:05
> 10 2000-02-14 10:26:06

> the chron command looks like:

>> 
> time.stamp<-chron(as.character(c.time[,"Date"]),c.time[,"Time"],format=c("y/m/d","h:m:s"))

> Error in convert.dates(dates., format = format[[1]], origin = origin.) :
> format y/m/d may be incorrect
> In addition: Warning messages:
> 1: 1796 entries set to NA due to wrong number of fields in:
> unpaste(dates., sep = fmt$sep, fnames = fmt$periods, nfields = 3)
> 2: NAs introduced by coercion
> 3: NAs introduced by coercion
> 4: NAs introduced by coercion

> Thanks,

> Joel Allen
> Institute of Applied Sciences
> University of North Texas

> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb 23 14:46:40 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Feb 2000 13:46:40 +0000 (GMT)
Subject: [R] Console font size
Message-ID: <200002231346.NAA06463@toucan.stats.ox.ac.uk>


> From: "Eusebio Arenal Guti?rrez" <use at eio.uva.es>
> To: "R help" <r-help at stat.math.ethz.ch>
> Subject: [R] Console font size
> Date: Wed, 23 Feb 2000 13:25:42 +0100
> X-Priority: 3
> X-MSMail-Priority: Normal
> X-MimeOLE: Produced By Microsoft MimeOLE V4.72.3612.1700
> 
> Friedrich Leisch point me out that in my first message I forgot the R
> version: R 0.99.0 for Windows 9x-NT
> 
> It is posible to change the console font size? What is the funtion needed?

Look in the file Rconsole (the default place is rw0990\etc\Rconsole,
but you can have a personal copy).  That contains:

   ## Font.
   # Please use only fixed width font.
   # If font=FixedFont the system fixed font is used; in this case
   # points and style are ignored. If font begins with "TT ", only 
   # True Type fonts are searched for.
   font = TT Courier New
   points = 10
   style = normal # Style can be normal, bold, italic

and you need to alter `points' and re-start the R console.

One day we may have a configuration editor (it is on the TODO list)
but for now you need to edit this file.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Feb 23 14:45:38 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Feb 2000 14:45:38 +0100
Subject: [R] Version 0.90.1 bug report on matrix indexing
In-Reply-To: Peter Dalgaard BSA's message of "23 Feb 2000 12:19:04 +0100"
References: <200002231049.LAA08418@alderney.gmd.de> <x266vg88uv.fsf@blueberry.kubism.ku.dk>
Message-ID: <x2wvnw6ni5.fsf@blueberry.kubism.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> > > bla["a",]_.6
> > > bla
> >   1   2    3    4    5    6
> > 1 1 0.6  0.6  0.6  0.6  0.6
> > 2 2 6.0 10.0 14.0 18.0 22.0
> > 3 3 7.0 11.0 15.0 19.0 23.0
> > 4 4 8.0 12.0 16.0 20.0 24.0
> > > gc()
> > Bus error
> 
> Still present in (yesterdays) 1.0.0pre. Thanks for the report.

Squashed!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arnholt at math.appstate.edu  Wed Feb 23 15:40:21 2000
From: arnholt at math.appstate.edu (Alan T. Arnholt)
Date: Wed, 23 Feb 2000 09:40:21 -0500 (EST)
Subject: [R] Lack of Fit test
In-Reply-To: <200002230248.NAA02775@snowy.nsw.cmis.CSIRO.AU>
Message-ID: <SIMEON.10002230921.C@speedy.math.appstate.edu>


I guess my question was not adequately stated when I sent it to the list.  I was
inquiring to see if anyone had written code to perform a lack of fit test in the 
special case when you have replicate predictors.  If your predictors contain 
replicates (repeated x values with one predictor or repeated combinations of x 
values with multiple predictors), you can easily calculate a pure error test for 
lack of fit. The error term will be partitioned into pure error (error within replicates)
, and a lack of fit error and the F-test can be used to test if you have chosen an 
adequate regression model.  See Neter, Kutener, Nachtsheim, and Wasserman fourth edition
page 115, or Draper and Smith.  Bill Venables wrote "...It makes it
impossible to write code to do it automatically, but if you know
what you are doing, the procedure is simple with the software you
have.  As with so many things in statistics, it is not a matter
of good software so much as of having a good understanding of the
problem in hand."  I guess I am not sure what "if you know what you are doing the
procedure is simple..." means since I clearly know what I am doing in reference to 
the statistical procedure.  Where I need help is not with the statistics, but rather 
with automating the procedure in R.  


On Wed, 23 Feb 2000 12:48:49 +1000 Bill Venables 
<William.Venables at cmis.CSIRO.AU> wrote:

> Alan T. Arnholt asks:
> 
> > Does anyone know of a "Lack of Fit" program for regression or
> > have any thoughts on how one might work with "lm" to create
> > such code?  Many thanks in advance.
> 
> There is no canonical way of doing this.  This is primarily why
> people use regression diagnostics.
> 
> Most standard tests for lack of fit, such as chi-squared tests,
> amount to testing the current model within some global model that
> contains all realistic models as special cases.  With regression
> models that information has to be used to estimate the variance,
> and indeed if you knew sigma^2 beforehand you could use the RSS
> for a chi-squared test of lack of fit, but mostly you do not know
> sigma^2 beforehand.
> 
> The same idea can be used to produce a special purpose test for
> lack of fit, even if it must lack the global aspect of standard
> chi-squared test.  What you do is dream up a larger model that
> contains the model you are considering as a special case but has
> enough flexibility to cater for any of the kinds of lack of fit
> you think might be worth checking for.  The larger model still
> has to have enough residual degrees of freedom, though, to allow
> you to estimate sigma^2 in a fairly stable manner (you might even
> consider doing it robustly).  Then test the chosen model within
> the outer model in the standard way.
> 
> Of course this demands that you have enough knowledge of the
> situation to choose the outer model satisfactorily.  It makes it
> impossible to write code to do it automatically, but if you know

> what you are doing the procedure is simple with the software you
> have.  As with so many things in statistics, it is not a matter
> of good software so much as of having a good understanding of the
> problem in hand.
> 
> Bill Venables.
> -- 
> Bill Venables,      Statistician,     CMIS Environmetrics Project
> CSIRO Marine Labs, PO Box 120, Cleveland, Qld,  AUSTRALIA.   4163
> Tel: +61 7 3826 7251           Email: Bill.Venables at cmis.csiro.au    
> Fax: +61 7 3826 7304      http://www.cmis.csiro.au/bill.venables/
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

___________________________________
Alan T. Arnholt
Associate Professor
Dept. of Mathematical Sciences
Appalachian State University
Boone, NC  28608
http://www.mathsci.appstate.edu/~arnholt/
Office phone: (828) 262 - 2863
Office fax  : (828) 265 - 8617

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Feb 23 16:05:44 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Feb 2000 15:05:44 +0000 (GMT)
Subject: [R] Lack of Fit test
Message-ID: <200002231505.PAA12211@toucan.stats.ox.ac.uk>


> From: "Alan T. Arnholt" <arnholt at math.appstate.edu>
> To: Bill Venables <William.Venables at cmis.CSIRO.AU>
> Cc: r-help at stat.math.ethz.ch, arnholt at math.appstate.edu
> Subject: Re: [R] Lack of Fit test
> Date: Wed, 23 Feb 2000 09:40:21 -0500 (EST)
> X-Authentication: none
> 
> 
> I guess my question was not adequately stated when I sent it to the list.  I 
was
> inquiring to see if anyone had written code to perform a lack of fit test in 
the 
> special case when you have replicate predictors.  If your predictors contain 
> replicates (repeated x values with one predictor or repeated combinations of x 
> values with multiple predictors), you can easily calculate a pure error test 
for 
> lack of fit. The error term will be partitioned into pure error (error within 
replicates)
> , and a lack of fit error and the F-test can be used to test if you have 
chosen an 
> adequate regression model.  See Neter, Kutener, Nachtsheim, and Wasserman 
fourth edition
> page 115, or Draper and Smith.  Bill Venables wrote "...It makes it
> impossible to write code to do it automatically, but if you know
> what you are doing, the procedure is simple with the software you
> have.  As with so many things in statistics, it is not a matter
> of good software so much as of having a good understanding of the
> problem in hand."  I guess I am not sure what "if you know what you are doing 
the
> procedure is simple..." means since I clearly know what I am doing in 
reference to 
> the statistical procedure.  Where I need help is not with the statistics, but 
rather 
> with automating the procedure in R.  

That's easy. Suppose your data frame x has some column, say, ID, which
identifies the various cases, and you fitted  

fit1 <- lm(y ~ rhs, data=df)

Now do 

fit2 <- lm(y ~ factor(ID), data=df)
anova(fit1, fit2, test="F")

e.g.

set.seed(123)
df <- data.frame(x = rnorm(10), ID=1:10)[rep(1:10, 1+rpois(10, 3)), ]
df$y <- 3*df$x+rnorm(nrow(df))
fit1 <- lm(y ~ x, data=df)
fit2 <- lm(y ~ factor(ID), data=df)
anova(fit1, fit2, test="F")

  Res.Df Res.Sum Sq Df Sum Sq F value Pr(>F)
1     23     26.101                         
2     15     15.222  8 10.878  1.3399 0.2975

Despite Bill's sound comments, there is an R package lmtest on CRAN,
which is full of tests for linear models.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ray.Brownrigg at mcs.vuw.ac.nz  Wed Feb 23 21:28:16 2000
From: Ray.Brownrigg at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 24 Feb 2000 09:28:16 +1300 (NZDT)
Subject: [R] Large datasets under R
Message-ID: <200002232028.JAA05149@aqua.mcs.vuw.ac.nz>

> From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
> 
> In addition, Robert has plans to support demand loading of objects
> from external files using exception handling.  This means that only
> the objects being used need reside in memory.  This is very much like
> the S approach.
> 
If anyone wants an interim solution, I have something like this working
already (0.65.1 through 0.99.0). It uses delay(), and works well (and
transparently), except when you run out of memory when loading a
dataset, then it turns to custard (but if you're out of memory, you need
to restart anyway).

Contact me if you need more information.

Hope this helps,
Ray Brownrigg <ray at mcs.vuw.ac.nz>	http://www.mcs.vuw.ac.nz/~ray
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From William.Venables at cmis.CSIRO.AU  Thu Feb 24 00:01:02 2000
From: William.Venables at cmis.CSIRO.AU (Bill Venables)
Date: Thu, 24 Feb 2000 09:01:02 +1000
Subject: [R] Lack of Fit test 
In-Reply-To: Your message of "Wed, 23 Feb 2000 09:40:21 EST."
             <SIMEON.10002230921.C@speedy.math.appstate.edu> 
Message-ID: <200002232301.KAA16551@snowy.nsw.cmis.CSIRO.AU>

Alan T. Arnholt writes:

> I guess my question was not adequately stated when I sent it to
> the list.  I was inquiring to see if anyone had written code to
> perform a lack of fit test in the special case when you have
> replicate predictors.  If your predictors contain replicates
> (repeated x values with one predictor or repeated combinations
> of x values with multiple predictors), you can easily calculate
> a pure error test for lack of fit.  The error term will be
> partitioned into pure error (error within replicates), and a
> lack of fit error and the F-test can be used to test if you
> have chosen an adequate regression model.  See Neter, Kutener,
> Nachtsheim, and Wasserman fourth edition page 115, or Draper
> and Smith.

This is precisely a special case of what I was saying.  You fit a
larger model that contains the given model as a special case and
test one within the other.  In this case the larger model is
pretty obvious (a single classification model with the repeated
combinations defining the classes) but even here some care is
necessary if the degrees of freedom available for estimating
sigma^2 is too few.

Moreover no special software is needed.  Suppose you have only
one predictor with repeated values, say x, and you are testing a
simple linear regression model.  Then you can do the test using

inner.mod <- lm(y ~ x, dat)
outer.mod <- lm(y ~ factor(x), dat)
anova(inner.mod, outer.mod)

Test for lack of fit done.  If you have several predictors
defining the repeated combinations all you need do is paste them
together, for example, and make a factor from that.

> Bill Venables wrote "...It makes it impossible to write code to
> do it automatically, but if you know what you are doing, the
> procedure is simple with the software you have.  As with so
> many things in statistics, it is not a matter of good software
> so much as of having a good understanding of the problem in
> hand."  I guess I am not sure what "if you know what you are
> doing the procedure is simple..." means since I clearly know
> what I am doing in reference to the statistical procedure.
> Where I need help is not with the statistics, but rather with
> automating the procedure in R.

You are testing "Lack of fit" by testing one linear model within
another and that procedure is pretty well automated within R
already (see above).  What the textbooks don't always tell you is
that that is all you are doing when you test for lack of fit, so
it can look like a special procedure that needs some new software
to perform.  It isn't.

What I was also referring to was the fact that the textbook test
for lack of fit is not always appropriate, even in this special
situation of repeated combinations of predictors.  If you have
too few degrees of freedom left over for estimating sigma^2
within repeated combinations you may need to make do with a
smaller outer model.  From a statistical point of view, unless
you are in a very special context that is not a decision you can
afford to delegate to an automatic procedure.  You need a good
understanding of the problem in hand to make it sensibly.

-- 
Bill Venables,      Statistician,     CMIS Environmetrics Project
CSIRO Marine Labs, PO Box 120, Cleveland, Qld,  AUSTRALIA.   4163
Tel: +61 7 3826 7251           Email: Bill.Venables at cmis.csiro.au    
Fax: +61 7 3826 7304      http://www.cmis.csiro.au/bill.venables/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From John.Strumila at corpmail.telstra.com.au  Thu Feb 24 04:29:27 2000
From: John.Strumila at corpmail.telstra.com.au (Strumila, John)
Date: Thu, 24 Feb 2000 14:29:27 +1100
Subject: [R] queueing problems
Message-ID: <61411576E951D211AF330008C7245DD90433626C@ntmsg0005.corpmail.telstra.com.au>

howdy R friends,

I'm new but I used to play with S+ a long time ago.  Can someone please help
me with how to approach this?

I have some response time data I want to 'correlate' with other data.  I
believe queueing is involved so I need to prove somehow (F test?) that
response ~ exponential(...)

How do I go about this?  I cant find exponential in 'nlm' or other
functions.

thanks,
John Strumila
john.strumila at corpmail.telstra.com.au



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Feb 24 11:25:35 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Feb 2000 11:25:35 +0100
Subject: [R] Lack of Fit test
In-Reply-To: Bill Venables's message of "Thu, 24 Feb 2000 09:01:02 +1000"
References: <200002232301.KAA16551@snowy.nsw.cmis.CSIRO.AU>
Message-ID: <x2wvnusxr4.fsf@blueberry.kubism.ku.dk>

Bill Venables <William.Venables at cmis.CSIRO.AU> writes:

> Moreover no special software is needed.  Suppose you have only
> one predictor with repeated values, say x, and you are testing a
> simple linear regression model.  Then you can do the test using
> 
> inner.mod <- lm(y ~ x, dat)
> outer.mod <- lm(y ~ factor(x), dat)
> anova(inner.mod, outer.mod)

Or, anova(lm(y~x+factor(x),data)) and the F-test is in the row for
factor(x). Has the advantage of making *d?mn* sure that you are
actually comparing nested models... Or, in the case with few
replications of each x, perhaps consider models like 

  y~x+cut(x,cutpoints)

(although some might prefer (say) a spline curve alternative instead)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossetti at markov.stat.unipg.it  Thu Feb 24 12:30:11 2000
From: rossetti at markov.stat.unipg.it (Andrea Rossetti)
Date: Thu, 24 Feb 2000 12:30:11 +0100 (MET)
Subject: [R] Correspondence ananlysis
Message-ID: <Pine.GSO.4.05.10002241224060.28409-100000@markov.stat.unipg.it>

Hi to all,
how can I perform a multiple correspondence analysys with a block
contingence matrix?
What's the proper package that must I load into R?

Andrea Rossetti.

PS Excuse me if my question is stupid and for my bad english!!!

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 24 13:35:15 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 24 Feb 2000 12:35:15 +0000 (GMT)
Subject: [R] Correspondence ananlysis
In-Reply-To: <Pine.GSO.4.05.10002241224060.28409-100000@markov.stat.unipg.it>
Message-ID: <Pine.GSO.4.05.10002241234270.2414-100000@auk.stats>

On Thu, 24 Feb 2000, Andrea Rossetti wrote:

> Hi to all,
> how can I perform a multiple correspondence analysys with a block
> contingence matrix?

Yes.

> What's the proper package that must I load into R?

Library MASS. You will need the Venables & Ripley MASS3 on-line complements
to follow how to use it.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clelancm at UMDNJ.EDU  Thu Feb 24 13:51:52 2000
From: clelancm at UMDNJ.EDU (Chuck Cleland)
Date: Thu, 24 Feb 2000 07:51:52 -0500
Subject: [R] landscape plots
Message-ID: <38B52968.F3FEA875@umdnj.edu>

Is there a set of R expressions that has the same effect as the
following set of S-Plus 2000 expressions:

graphsheet(format="printer", orientation="landscape")
par(mfrow=c(2,2))
plot(x1, y1)
plot(x2, y2)
plot(x3, y3)
plot(x4, y4)
dev.off()    # one page of landscape plots sent to printer

I am having trouble with formulating the equivalent of the first line of
the above in R.  I want a page of plots that is landscape and makes
optimal use of a 8.5 by 11 inch piece of paper.  I am using R 0.99.0 on
Windows 98 SE and S-Plus 2000 on the same machine.   

thanks,

Chuck

----------------------------------------------
Chuck Cleland
Institute for the Study of Child Development
UMDNJ-Robert Wood Johnson Medical School
97 Paterson Street
New Brunswick, NJ 08903
phone: (732) 235-7699
  fax: (732) 235-6189
http://www2.umdnj.edu/iscdweb/
----------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 24 14:28:23 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 24 Feb 2000 13:28:23 +0000 (GMT)
Subject: [R] landscape plots
In-Reply-To: <38B52968.F3FEA875@umdnj.edu>
Message-ID: <Pine.GSO.4.05.10002241321220.13847-100000@auk.stats>

On Thu, 24 Feb 2000, Chuck Cleland wrote:

> Is there a set of R expressions that has the same effect as the
> following set of S-Plus 2000 expressions:
> 
> graphsheet(format="printer", orientation="landscape")
> par(mfrow=c(2,2))
> plot(x1, y1)
> plot(x2, y2)
> plot(x3, y3)
> plot(x4, y4)
> dev.off()    # one page of landscape plots sent to printer
> 
> I am having trouble with formulating the equivalent of the first line of
> the above in R.  I want a page of plots that is landscape and makes
> optimal use of a 8.5 by 11 inch piece of paper.  I am using R 0.99.0 on
> Windows 98 SE and S-Plus 2000 on the same machine.   

There is no direct way to do that, that I know of. You ought to be able to
use win.metafile with width=11, height=8.5 and print the result in
landscape, or win.print(width=11, height=8.5) and select landscape from the
printer selection box (if you get one: I did when I tried).

Exactly what happens is rather OS and printer-driver specific: I was using
a networked PostScript printer (Adobe driver) on NT4.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kelley at Phys.Ocean.Dal.CA  Thu Feb 24 15:20:05 2000
From: kelley at Phys.Ocean.Dal.CA (Dan E. Kelley)
Date: Thu, 24 Feb 2000 10:20:05 -0400 (AST)
Subject: [R] queueing problems
In-Reply-To: <61411576E951D211AF330008C7245DD90433626C@ntmsg0005.corpmail.telstra.com.au>
Message-ID: <Pine.LNX.4.10.10002241019100.5621-100000@Intrusion.Phys.Ocean.Dal.Ca>

I have a similar task, and I've figured out that 'nls' is the thing you
want.  There is also 'nlme' but I can't make (the latest version --
3.1-3.tar) it work with my R version (0.99.0).

EX:
        library(nls)
        ... get data
        model.fit <- nls(y ~ exp(x))
        plot(model.fit)
or something like that.



On Thu, 24 Feb 2000, Strumila, John wrote:

> howdy R friends,
> 
> I'm new but I used to play with S+ a long time ago.  Can someone please help
> me with how to approach this?
> 
> I have some response time data I want to 'correlate' with other data.  I
> believe queueing is involved so I need to prove somehow (F test?) that
> response ~ exponential(...)
> 
> How do I go about this?  I cant find exponential in 'nlm' or other
> functions.
> 
> thanks,
> John Strumila
> john.strumila at corpmail.telstra.com.au
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

Dan E. Kelley                   internet:   mailto:Dan.Kelley at Dal.CA
Oceanography Department         phone:                 (902)494-1694
Dalhousie University            fax:                   (902)494-2885
Halifax, NS, CANADA, B3H 4J1    http://www.phys.ocean.dal.ca/~kelley

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mac at foodsci.unibo.it  Thu Feb 24 16:46:59 2000
From: mac at foodsci.unibo.it (Mauro Andrea Cremonini)
Date: Thu, 24 Feb 2000 16:46:59 +0100 (MET)
Subject: [R] canonical variates
Message-ID: <Pine.LNX.4.10.10002241640130.15606-100000@carbon.foodsci.unibo.it>

Dear all, I am a new R user so forgive my perhaps naive question.

I am looking for a R canonical variates routine, which as far as I
understand it is not contained in the mva multivariate package.
Anybody has already written this routine? And where can I find it?
Thank you all very much.

Mauro


-------------------------------------------
Mauro Andrea Cremonini, Ph.D.
Food Science and Technology Laboratory
University of Bologna
Via Ravennate 1020 - 47023 - Cesena - Italy
Phone: +39.0547.636106
FAX:   +39.0547.382348
e-mail: mac at foodsci.unibo.it
-------------------------------------------



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossetti at markov.stat.unipg.it  Thu Feb 24 16:03:45 2000
From: rossetti at markov.stat.unipg.it (Andrea Rossetti)
Date: Thu, 24 Feb 2000 16:03:45 +0100 (MET)
Subject: [R] Correspondence ananlysis
In-Reply-To: <Pine.GSO.4.05.10002241234270.2414-100000@auk.stats>
Message-ID: <Pine.GSO.4.05.10002241601510.28951-100000@markov.stat.unipg.it>



On Thu, 24 Feb 2000, Prof Brian D Ripley wrote:

> Date: Thu, 24 Feb 2000 12:35:15 +0000 (GMT)
> From: Prof Brian D Ripley <ripley at stats.ox.ac.uk>
> To: Andrea Rossetti <rossetti at markov.stat.unipg.it>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Correspondence ananlysis
> 
> On Thu, 24 Feb 2000, Andrea Rossetti wrote:
> 
> > Hi to all,
> > how can I perform a multiple correspondence analysys with a block
> > contingence matrix?
> 
> Yes.
> 
> > What's the proper package that must I load into R?
> 
> Library MASS. You will need the Venables & Ripley MASS3 on-line complements
> to follow how to use it.

Is it available for the Windows 32 version of R?

Andrea.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 24 17:10:04 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Feb 2000 16:10:04 +0000 (GMT)
Subject: [R] Correspondence ananlysis
Message-ID: <200002241610.QAA01368@toucan.stats.ox.ac.uk>

> From: Andrea Rossetti <rossetti at markov.stat.unipg.it>
> To: Prof Brian D Ripley <ripley at stats.ox.ac.uk>
> 
> 
> 
> On Thu, 24 Feb 2000, Prof Brian D Ripley wrote:
> 
> > 
> > On Thu, 24 Feb 2000, Andrea Rossetti wrote:
> > 
> > > Hi to all,
> > > how can I perform a multiple correspondence analysys with a block
> > > contingence matrix?
> > 
> > Yes.
> > 
> > > What's the proper package that must I load into R?
> > 
> > Library MASS. You will need the Venables & Ripley MASS3 on-line complements
> > to follow how to use it.
> 
> Is it available for the Windows 32 version of R?

Yes, on CRAN, part of the VR bundle

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From venkat at biost.mskcc.org  Thu Feb 24 18:14:48 2000
From: venkat at biost.mskcc.org (E. S. Venkatraman)
Date: Thu, 24 Feb 2000 12:14:48 -0500
Subject: [R] Ordinal Regression
Message-ID: <38B56708.EAB3DF1D@biost.mskcc.org>

Hi:

Is there any function in R to fit ordinal regression models (linear 
and non-linear) described by Peter McCullagh.

    Regression Models for Ordinal Data, JRSS-B, 1980, 42:109-142

Thanks,
Venkat
-----------------------------------------------------------------------
E. S. Venkatraman, Ph.D.     Phone: (212) 639-8520  Fax: (212) 717-3137
Assistant Attending Member     Memorial Sloan-Kettering Cancer Center
-----------------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 24 18:28:23 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Feb 2000 17:28:23 +0000 (GMT)
Subject: [R] canonical variates
Message-ID: <200002241728.RAA01662@toucan.stats.ox.ac.uk>


> Date: Thu, 24 Feb 2000 16:46:59 +0100 (MET)
> From: Mauro Andrea Cremonini <mac at foodsci.unibo.it>
> 
> Dear all, I am a new R user so forgive my perhaps naive question.
> 
> I am looking for a R canonical variates routine, which as far as I
> understand it is not contained in the mva multivariate package.
> Anybody has already written this routine? And where can I find it?

Not that I know of, but it is fairly simple. Suppose you have data matrices
A and B on the same observations. Then

cancor <- function(A, B) 
{
   Ap <- prcomp(scale(A, T, F), retx=T)
   Apc <- Ap$x %*% diag(1/Ap$sdev)
   Bp <- prcomp(scale(B, T, F), retx=T)
   Bpc <- Bp$x %*% diag(1/Bp$sdev)
   Sigma <- crossprod(Apc, Bpc)/(nrow(A) - 1)
   s <- svd(Sigma, ncol(A), ncol(B))
   return(list(cor=s$d, canvar.x=Apc %*% s$u, canvar.y=Bpc %*% s$v))
}
should do the trick. The canonical variates are zero-mean, unit-variance
(unlike S-PLUS).

I have only done some simple checks, but this seems to agree with
S-PLUS up to the different normalizations.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jimrc at gauss.math.montana.edu  Thu Feb 24 19:17:52 2000
From: jimrc at gauss.math.montana.edu (Jim Robison-Cox)
Date: Thu, 24 Feb 2000 11:17:52 -0700 (MST)
Subject: [R] lg2c
Message-ID: <Pine.GSO.4.02.10002241114310.21994-100000@gauss.math.montana.edu>

Dear Rhelp folks,

   I think I read this in recent Rhelp, but I can't find it in the
archive.  I need to know how to get lg2c in order to build the nlme
package.
  I'm trying to install nlme_3.1-2.tar.gz on a Linux machine (6.1 Redhat)
under R Version 0.99.0  (February 7, 2000).

  Thanks,
Jim

Jim Robison-Cox               ____________    
Department of Math Sciences  |            |       phone: (406)994-5340
2-214 Wilson Hall             \   BZN, MT |       FAX:   (406)994-1789
Montana State University       |  *_______|
Bozeman, MT 59717-2400          \_|      e-mail: jimrc at math.montana.edu 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Feb 24 19:42:55 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 24 Feb 2000 18:42:55 +0000 (GMT)
Subject: [R] lg2c
In-Reply-To: <Pine.GSO.4.02.10002241114310.21994-100000@gauss.math.montana.edu>
Message-ID: <Pine.GSO.4.05.10002241841390.18911-100000@auk.stats>

On Thu, 24 Feb 2000, Jim Robison-Cox wrote:

>    I think I read this in recent Rhelp, but I can't find it in the
> archive.  I need to know how to get lg2c in order to build the nlme
> package.
>   I'm trying to install nlme_3.1-2.tar.gz on a Linux machine (6.1 Redhat)
> under R Version 0.99.0  (February 7, 2000).

Install egcs-g77 (preferably) or remove -lg2c from the FLIBS in
etc/Makeconf.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kelley at Phys.Ocean.Dal.CA  Thu Feb 24 20:43:11 2000
From: kelley at Phys.Ocean.Dal.CA (Dan E. Kelley)
Date: Thu, 24 Feb 2000 15:43:11 -0400 (AST)
Subject: [R] (-1 as index) OR (envelope for QQ)
Message-ID: <Pine.LNX.4.10.10002241525110.6438-103000@Intrusion.Phys.Ocean.Dal.Ca>

I'm new to R (and to S) and am wondering about code from pages 72 and
83 of MASS (Venables+Ripley, 3rd edition), to draw an envelope on a QQ
plot.  Copying from the book, I've got:

  #... code whose gist is "a.fit <-  nls(..."
  num.points <- length(resid(a.fit))
  qqnorm(residuals(a.fit))     # illustrate data-model residuals
  qqline(residuals(a.fit))
  samp <- cbind(residuals(a.fit), matrix(rnorm(num.points*19),num.points,19))
  samp <- apply(scale(samp), 2, sort)
  rs <- samp[,1] 
  xs <- qqnorm(rs, plot=FALSE)$x
  env <- t(apply(samp[,-1], 1, range))  ###########################3
  xyul <- par("usr")
  smidge <- min(diff(c(xyul[1], xs, xyul[2])))/2
  segments(xs-smidge,env[,1], xs+smidge, env[,1])
  segments(xs-smidge,env[,2], xs+smidge, env[,2])

where I've marked a confusing line with ########.  From what I gather
(from section 2.1, or page 5, of "R complements to MASS" by VR),
indexing is different in R than in S.  It's not clear to me whether
this R-to-S difference is giving me problems.  I'm such a newbie that
I'm not entirely sure what the 'samp[,-1]' is supposed to be doing.
(Confession: I'm such a newbie that I've spent much of the day typing
"?apply" and then "?par" etc, working through the program to try to
figure it out!)

In any case, my worry is visible in the QQ plot attached.  Why do I
have get so few "ledges" from the segments() calls?  It's not clear to
me how the scale of the data-model deviations come into this problem.

Q: should I first be standardizing the residuals from the data-model
comparison?  I would have guessed that something in this 'QQ envelope'
would be doing that.  

I'm guessing any replies will fit into one of three categories ...

1) You idiot!  QQ plots are supposed to have standardized residuals of
   the data-model misfit.  Do that and the QQ envelop is ok.

2) Don't copy S stuff into R code.  The S code "samp[,-1]" from VR
   should be written "..." for use in R.

3) Don't be so rude as to ask such questions (with length attachments,
   no less) on a group like this.  Give us a break!

... but I'm hoping that the mode won't be in the final category!

Many thanks in advance.

Dan E. Kelley                   internet:   mailto:Dan.Kelley at Dal.CA
Oceanography Department         phone:                 (902)494-1694
Dalhousie University            fax:                   (902)494-2885
Halifax, NS, CANADA, B3H 4J1    http://www.phys.ocean.dal.ca/~kelley
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.ps.gz
Type: application/octet-stream
Size: 2860 bytes
Desc: 
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000224/7d190b34/Rplots.ps.obj
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fit.R.gz
Type: application/octet-stream
Size: 1657 bytes
Desc: 
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000224/7d190b34/fit.R.obj
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fbox.dat.gz
Type: application/octet-stream
Size: 380 bytes
Desc: 
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20000224/7d190b34/fbox.dat.obj

From ripley at stats.ox.ac.uk  Thu Feb 24 21:14:24 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 24 Feb 2000 20:14:24 +0000 (GMT)
Subject: [R] (-1 as index) OR (envelope for QQ)
In-Reply-To: <Pine.LNX.4.10.10002241525110.6438-103000@Intrusion.Phys.Ocean.Dal.Ca>
Message-ID: <Pine.GSO.4.05.10002242006230.23418-100000@auk.stats>

On Thu, 24 Feb 2000, Dan E. Kelley wrote:

> I'm new to R (and to S) and am wondering about code from pages 72 and
> 83 of MASS (Venables+Ripley, 3rd edition), to draw an envelope on a QQ
> plot.  Copying from the book, I've got:
> 
>   #... code whose gist is "a.fit <-  nls(..."
>   num.points <- length(resid(a.fit))
>   qqnorm(residuals(a.fit))     # illustrate data-model residuals
>   qqline(residuals(a.fit))
>   samp <- cbind(residuals(a.fit), matrix(rnorm(num.points*19),num.points,19))
>   samp <- apply(scale(samp), 2, sort)
>   rs <- samp[,1] 
>   xs <- qqnorm(rs, plot=FALSE)$x
>   env <- t(apply(samp[,-1], 1, range))  ###########################3
>   xyul <- par("usr")
>   smidge <- min(diff(c(xyul[1], xs, xyul[2])))/2
>   segments(xs-smidge,env[,1], xs+smidge, env[,1])
>   segments(xs-smidge,env[,2], xs+smidge, env[,2])
> 
> where I've marked a confusing line with ########.  From what I gather
> (from section 2.1, or page 5, of "R complements to MASS" by VR),
> indexing is different in R than in S.  It's not clear to me whether
> this R-to-S difference is giving me problems.  I'm such a newbie that
> I'm not entirely sure what the 'samp[,-1]' is supposed to be doing.
> (Confession: I'm such a newbie that I've spent much of the day typing
> "?apply" and then "?par" etc, working through the program to try to
> figure it out!)

You can look in the R scripts (in the MASS package in the VR bundle) to see
fully tested R versions of the code.  That works, although you left out a
line (starting matplot).

samp[, -1] drops the first column (pp.39-40), so the marked line applies
range to the remaining columns.

That code applies to a variable, not residuals, which may or may not
matter depending on your model complexity.

> In any case, my worry is visible in the QQ plot attached.  Why do I
> have get so few "ledges" from the segments() calls?  It's not clear to
> me how the scale of the data-model deviations come into this problem.
> 
> Q: should I first be standardizing the residuals from the data-model
> comparison?  I would have guessed that something in this 'QQ envelope'
> would be doing that.  

Yes, the `scale' function is already normalizing for you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Feb 24 21:17:39 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Feb 2000 21:17:39 +0100
Subject: [R] (-1 as index) OR (envelope for QQ)
In-Reply-To: "Dan E. Kelley"'s message of "Thu, 24 Feb 2000 15:43:11 -0400 (AST)"
References: <Pine.LNX.4.10.10002241525110.6438-103000@Intrusion.Phys.Ocean.Dal.Ca>
Message-ID: <x2k8junyn0.fsf@blueberry.kubism.ku.dk>

"Dan E. Kelley" <kelley at Phys.Ocean.Dal.CA> writes:

> Content-Type: TEXT/PLAIN; charset=US-ASCII
> 
> I'm new to R (and to S) and am wondering about code from pages 72 and
> 83 of MASS (Venables+Ripley, 3rd edition), to draw an envelope on a QQ
> plot.  Copying from the book, I've got:
> 
>   #... code whose gist is "a.fit <-  nls(..."
>   num.points <- length(resid(a.fit))
>   qqnorm(residuals(a.fit))     # illustrate data-model residuals
>   qqline(residuals(a.fit))
>   samp <- cbind(residuals(a.fit), matrix(rnorm(num.points*19),num.points,19))
>   samp <- apply(scale(samp), 2, sort)
>   rs <- samp[,1] 
>   xs <- qqnorm(rs, plot=FALSE)$x
>   env <- t(apply(samp[,-1], 1, range))  ###########################3
>   xyul <- par("usr")
>   smidge <- min(diff(c(xyul[1], xs, xyul[2])))/2
>   segments(xs-smidge,env[,1], xs+smidge, env[,1])
>   segments(xs-smidge,env[,2], xs+smidge, env[,2])
> 
....
> 1) You idiot!  QQ plots are supposed to have standardized residuals of
>    the data-model misfit.  Do that and the QQ envelop is ok.
> 
> 2) Don't copy S stuff into R code.  The S code "samp[,-1]" from VR
>    should be written "..." for use in R.
> 
> 3) Don't be so rude as to ask such questions (with length attachments,
>    no less) on a group like this.  Give us a break!
> 
> ... but I'm hoping that the mode won't be in the final category!


Well, 2) is *not* the answer... Try removing the plot=F from the 2nd
qqnorm and I think you'll see the light. Notice the scale on the y
axis. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.malewski at tu-bs.de  Thu Feb 24 21:45:33 2000
From: p.malewski at tu-bs.de (Peter Malewski)
Date: Thu, 24 Feb 2000 21:45:33 +0100 (CET)
Subject: [R] Ordinal Regression
In-Reply-To: <38B56708.EAB3DF1D@biost.mskcc.org>
Message-ID: <Pine.LNX.4.21.0002242140430.1415-100000@Uranus.Levi>

On Thu, 24 Feb 2000, E. S. Venkatraman wrote:

> Hi:
> 
> Is there any function in R to fit ordinal regression models (linear 
> and non-linear) described by Peter McCullagh.
> 
>     Regression Models for Ordinal Data, JRSS-B, 1980, 42:109-142

I dont't know this article, but...

polr {MASS}                                  R Documentation
   Proportional Odds Logistic Regression

described in detail, of course, in VR3

Peter


**I'd never join any club that would have the likes of me as a member.GM**
P.Malewski				Tel.: 0531 500965
Maschplatz 8				mailto: Peter.Malewski at gmx.de
************************38114 Braunschweig********************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tring at mail1.stofanet.dk  Thu Feb 24 23:08:00 2000
From: tring at mail1.stofanet.dk (Troels Ring)
Date: Thu, 24 Feb 2000 23:08:00 +0100
Subject: Sv: [R] Ordinal Regression
Message-ID: <002301bf7f13$a1124ae0$2c4fa8c0@tring.stofanet.dk>

Patrick Lindsey has made available a library devoted to ordinal models available at:

http://www.luc.ac.be/~plindsey/publications.html


Best wishes

Troels Ring

-----Oprindelig meddelelse-----
Fra: Peter Malewski <p.malewski at tu-bs.de>
Til: E. S. Venkatraman <venkat at biost.mskcc.org>
Cc: r-help at stat.math.ethz.ch <r-help at stat.math.ethz.ch>
Dato: 24. februar 2000 22:48
Emne: Re: [R] Ordinal Regression


>On Thu, 24 Feb 2000, E. S. Venkatraman wrote:
>
>> Hi:
>> 
>> Is there any function in R to fit ordinal regression models (linear 
>> and non-linear) described by Peter McCullagh.
>> 
>>     Regression Models for Ordinal Data, JRSS-B, 1980, 42:109-142
>
>I dont't know this article, but...
>
>polr {MASS}                                  R Documentation
>   Proportional Odds Logistic Regression
>
>described in detail, of course, in VR3
>
>Peter
>
>
>**I'd never join any club that would have the likes of me as a member.GM**
>P.Malewski Tel.: 0531 500965
>Maschplatz 8 mailto: Peter.Malewski at gmx.de
>************************38114 Braunschweig********************************
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Fri Feb 25 03:41:42 2000
From: jyan at stat.wisc.edu (Jun Yan)
Date: Thu, 24 Feb 2000 20:41:42 -0600 (CST)
Subject: [R] model selection using step
In-Reply-To: <200002241728.RAA01662@toucan.stats.ox.ac.uk>
Message-ID: <Pine.LNX.3.96L.1000224203358.2013B-100000@istat10.stat.wisc.edu>

I am trying to do a model selection using function step. There are 21
independent variables. I first started from a model with all variables,
the step function does not go anywhere, returning the full model to me. 

Q1. Does this have to do with missing values?
Q2. I refit the model after removing all rows including missing values,
but the result still does not change. What am I missing here?

body.m <- lm(BI.PPrem ~ ., data=insure[,c(1, 19:39)])
na <- as.numeric(attr(attr(body.m$model, "na.action"), "names"))
body.m <- lm(BI.PPrem ~ ., data=insure[-na,c(1, 19:39)])
body.step <- step(body.m, scope=list(upper = ~., lower= ~1))


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From c.kong at pmci.unimelb.edu.au  Fri Feb 25 06:35:47 2000
From: c.kong at pmci.unimelb.edu.au (Kong, Chuang Fong)
Date: Fri, 25 Feb 2000 16:35:47 +1100
Subject: [R] problem with read.table
Message-ID: <B29D3ABE5A8CD311869C0080C8E7EAD43A8192@raid.pmci.unimelb.edu.au>



> Hi,
> I recently downloaded R on window and running Rgui on NT. I have never use
> R before and trying to learn R by following An introduction to R. 
> I generated a table of 900x5 in excel and saved as tab delimited txt file.
> I then do read.table but I keeping getting the following message
> > data <- read.table("ML4mm25.txt", header=T, sep=" ")
> Error in count.fields(file, sep, quote, skip) : 
>   can't open file ML4mm25.txt
> and when I try to count.fields, again there is error message. I was able
> to use the same command to read the file into S-plus with no problem, can
> you tell me what is wrong? also, what is the value for quote?
> Thanks.
> Chuang Fong Kong, Ph D
> Head, Microarrays
> Peter MacCallum Cancer Institute - Research
> St. Andrew's Place, East Melbourne
> Victoria 3002, Australia
> Tel: 61 3 9656-1796 or 1138
> Fax: 61 3 9656-1411
> e-mail: c.kong at pmci.unimelb.edu.au
> 
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000225/9984299f/attachment.html

From tring at mail1.stofanet.dk  Fri Feb 25 08:44:12 2000
From: tring at mail1.stofanet.dk (Troels Ring)
Date: Fri, 25 Feb 2000 08:44:12 +0100
Subject: Sv: Sv: [R] Ordinal Regression
Message-ID: <000c01bf7f64$1f691220$2c4fa8c0@tring.stofanet.dk>

Dear Peter.

I guess you know that Jim Lindseys code include nordr and ordglm in library gnlm - I attach the htmls which do various linear and nonlinear ordinal regressions - exemplified with just the data mentioned, McCullagh (1980) JRSS B42, 109-142. I had it work very fine. 

-----Oprindelig meddelelse-----
Fra: Peter Malewski <p.malewski at tu-bs.de>
Til: Troels Ring <tring at mail1.stofanet.dk>
Dato: 25. februar 2000 07:35
Emne: Re: Sv: [R] Ordinal Regression


>On Thu, 24 Feb 2000, Troels Ring wrote:
>
>> Patrick Lindsey has made available a library devoted to ordinal models available at:
>> 
>> http://www.luc.ac.be/~plindsey/publications.html
>
>Yes thanks for your hint . I've already looked at his html-page, but never
>tested one of his libraries...  
>
>best wishes
>Peter
>
>> 
>> 
>> Best wishes
>> 
>> Troels Ring
>> 
>> -----Oprindelig meddelelse-----
>> Fra: Peter Malewski <p.malewski at tu-bs.de>
>> Til: E. S. Venkatraman <venkat at biost.mskcc.org>
>> Cc: r-help at stat.math.ethz.ch <r-help at stat.math.ethz.ch>
>> Dato: 24. februar 2000 22:48
>> Emne: Re: [R] Ordinal Regression
>> 
>> 
>> >On Thu, 24 Feb 2000, E. S. Venkatraman wrote:
>> >
>> >> Hi:
>> >> 
>> >> Is there any function in R to fit ordinal regression models (linear 
>> >> and non-linear) described by Peter McCullagh.
>> >> 
>> >>     Regression Models for Ordinal Data, JRSS-B, 1980, 42:109-142
>> >
>> >I dont't know this article, but...
>> >
>> >polr {MASS}                                  R Documentation
>> >   Proportional Odds Logistic Regression
>> >
>> >described in detail, of course, in VR3
>> >
>> >Peter
>> >
>> >
>> >**I'd never join any club that would have the likes of me as a member.GM**
>> >P.Malewski Tel.: 0531 500965
>> >Maschplatz 8 mailto: Peter.Malewski at gmx.de
>> >************************38114 Braunschweig********************************
>> >
>> >-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>> >r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> >Send "info", "help", or "[un]subscribe"
>> >(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>> >
>> 
>
>
>**I'd never join any club that would have the likes of me as a member.GM**
>P.Malewski Tel.: 0531 500965
>Maschplatz 8 mailto: Peter.Malewski at gmx.de
>************************38114 Braunschweig********************************
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000225/8230029e/nordr.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000225/8230029e/ordglm.html

From ripley at stats.ox.ac.uk  Fri Feb 25 08:38:40 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 25 Feb 2000 07:38:40 +0000 (GMT)
Subject: [R] problem with read.table
In-Reply-To: <B29D3ABE5A8CD311869C0080C8E7EAD43A8192@raid.pmci.unimelb.edu.au>
Message-ID: <Pine.GSO.4.05.10002250733020.24142-100000@auk.stats>

On Fri, 25 Feb 2000, Kong, Chuang Fong wrote:

> > I recently downloaded R on window and running Rgui on NT. I have never use
> > R before and trying to learn R by following An introduction to R. 
> > I generated a table of 900x5 in excel and saved as tab delimited txt file.
> > I then do read.table but I keeping getting the following message
> > > data <- read.table("ML4mm25.txt", header=T, sep=" ")

If it is tab-delimited, you want sep = "\t" there, in both R and S-PLUS.

> > Error in count.fields(file, sep, quote, skip) : 
> >   can't open file ML4mm25.txt
> > and when I try to count.fields, again there is error message. I was able
> > to use the same command to read the file into S-plus with no problem, can
> > you tell me what is wrong? also, what is the value for quote?

See the help page for read.table. The idea is to that "A label with spaces"
will get read as one field, not four.

I hope that helps. If you need further help, we would need to see the file,
as there are too many possibilities to guess from. (One is that
Excel tends to leave off trailing fields if they are missing.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Fri Feb 25 08:49:32 2000
From: gb at stat.umu.se (gb@stat.umu.se)
Date: Fri, 25 Feb 2000 08:49:32 +0100 (CET)
Subject: [R] problem with read.table
In-Reply-To: <B29D3ABE5A8CD311869C0080C8E7EAD43A8192@raid.pmci.unimelb.edu.au>
Message-ID: <Pine.LNX.4.10.10002250845320.25072-100000@pc16.stat.umu.se>

On Fri, 25 Feb 2000, Kong, Chuang Fong wrote:

> 
> 
> > Hi,
> > I recently downloaded R on window and running Rgui on NT. I have never use
> > R before and trying to learn R by following An introduction to R. 
> > I generated a table of 900x5 in excel and saved as tab delimited txt file.
> > I then do read.table but I keeping getting the following message
> > > data <- read.table("ML4mm25.txt", header=T, sep=" ")
> > Error in count.fields(file, sep, quote, skip) : 
> >   can't open file ML4mm25.txt
> > and when I try to count.fields, again there is error message. I was able
> > to use the same command to read the file into S-plus with no problem, can
> > you tell me what is wrong? also, what is the value for quote?
> > Thanks.
> > Chuang Fong Kong, Ph D
> > Head, Microarrays
> > Peter MacCallum Cancer Institute - Research
> > St. Andrew's Place, East Melbourne
> > Victoria 3002, Australia
> > Tel: 61 3 9656-1796 or 1138
> > Fax: 61 3 9656-1411
> > e-mail: c.kong at pmci.unimelb.edu.au

Well, I think you can take for granted that  R doesn't find your
file ...

Is your file in the default directory? Try changing directory to
the place where your file is. You can do that somewhere in the menus.

You should normally not use count.fields.

G?ran
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Feb 25 09:17:46 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 25 Feb 2000 08:17:46 +0000 (GMT)
Subject: [R] model selection using step
In-Reply-To: <Pine.LNX.3.96L.1000224203358.2013B-100000@istat10.stat.wisc.edu>
Message-ID: <Pine.GSO.4.05.10002250800350.24142-100000@auk.stats>

On Thu, 24 Feb 2000, Jun Yan wrote:

> I am trying to do a model selection using function step. There are 21
> independent variables. I first started from a model with all variables,
> the step function does not go anywhere, returning the full model to me. 
> 
> Q1. Does this have to do with missing values?

Probably. As R uses na.action=na.omit by default it compares
incomparable models all too easily.

(This needs sorting out: ?m says na.omit is the default and ?glm says
na.fail is the default, but it does seem to be na.omit for both.
And anova.lm merrily compares models on different numbers of observations.)

> Q2. I refit the model after removing all rows including missing values,
> but the result still does not change. What am I missing here?

Try using the trace option. It is probably the case that dropping a single
variable does not lead to a better fit as assessed by AIC. That could be
genuine, or it could be a problem with non-comparable datasets or it could
be a bug.

> body.m <- lm(BI.PPrem ~ ., data=insure[,c(1, 19:39)])
> na <- as.numeric(attr(attr(body.m$model, "na.action"), "names"))

(Is that correct? It depends on the row names being numeric ....)

> body.m <- lm(BI.PPrem ~ ., data=insure[-na,c(1, 19:39)])
> body.step <- step(body.m, scope=list(upper = ~., lower= ~1))

You would do better to use na.omit and something like

thisdf <- na.omit(insure[,c(1, 19:39)])
body.m <- lm(BI.PPrem ~ ., data=thisdf, na.action=na.fail)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Fri Feb 25 11:34:46 2000
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Fri, 25 Feb 2000 11:34:46 +0100
Subject: [R] partial correlation coefficients in R?
Message-ID: <B4DC1956.21AC%pflugshaupt@geobot.umnw.ethz.ch>

Hello,

after thorough searching of the R help files as well as S+-help, I'm coming
to the list: Is there a possibility to compute partial correlation
coefficients between multiple variables (correlation between two paired
samples with the "effects of all other  variables partialled out")? All I
seem to find are the standard Pearson correlation coefficients (with cor())
and no clue as to how to convert them into partial ones. One of my books
states that"this is a computionally intensive problem and computer help is
most welcome" :-), but fails to give an algorithm. Can anyone help? Maybe
this feature already exists somewhere?

Cheers

Kaspar


-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From D.J.Lucy at Bradford.ac.uk  Fri Feb 25 12:58:07 2000
From: D.J.Lucy at Bradford.ac.uk (Dave Lucy)
Date: Fri, 25 Feb 2000 11:58:07 +0000 (GMT)
Subject: [R] partial correlation coefficients in R?
In-Reply-To: <B4DC1956.21AC%pflugshaupt@geobot.umnw.ethz.ch>
Message-ID: <Pine.GSO.3.96.1000225115336.15076D-100000@kite.cen.brad.ac.uk>

Kaspar,

> to the list: Is there a possibility to compute partial correlation
> coefficients between multiple variables (correlation between two paired

I use this for partialing the three variable case, if you find any which
will handle more varibles let me know:

# pcor - partial correlation routine invoked by tspcor and the like
# calculates the partial correlation coefficient between v1 and v2
# controlling for v3 - returns that value

pcor <- function(v1, v2, v3)
	{
	c12 <- cor(v1, v2)
	c23 <- cor(v2, v3)
	c13 <- cor(v1, v3)

	partial <- (c12-(c13*c23))/(sqrt(1-(c13^2)) * sqrt(1-(c23^2)))

	return(partial)
	}





********************************************************************
Dr. David Lucy
Department of Archaeological Sciences
University of Bradford
Bradford
West Yorkshire
BD7 1DP
UK

tel. +44 01274 233556
fax. +44 01274 235190
********************************************************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Fri Feb 25 14:35:31 2000
From: plummer at iarc.fr (Martyn Plummer)
Date: Fri, 25 Feb 2000 14:35:31 +0100 (CET)
Subject: [R] partial correlation coefficients in R?
In-Reply-To: <Pine.GSO.3.96.1000225115336.15076D-100000@kite.cen.brad.ac.uk>
Message-ID: <XFMail.000225143531.plummer@iarc.fr>

On 25-Feb-00 Dave Lucy wrote:
> Kaspar,
> 
>> to the list: Is there a possibility to compute partial correlation
>> coefficients between multiple variables (correlation between two paired
> 
> I use this for partialing the three variable case, if you find any which
> will handle more varibles let me know:
> 
># pcor - partial correlation routine invoked by tspcor and the like
># calculates the partial correlation coefficient between v1 and v2
># controlling for v3 - returns that value
> 
> pcor <- function(v1, v2, v3)
>       {
>       c12 <- cor(v1, v2)
>       c23 <- cor(v2, v3)
>       c13 <- cor(v1, v3)
> 
>       partial <- (c12-(c13*c23))/(sqrt(1-(c13^2)) * sqrt(1-(c23^2)))
> 
>       return(partial)
>       }

In general you invert the variance-covariance matrix and then rescale it
so the diagonal is one.  The off-diagonal elements are the negative
partial correlation coefficients given all other variables.

pcor2 <- function(x){
        conc <- solve(var(x))
        resid.sd <- 1/sqrt(diag(conc))
        pcc <- - sweep(sweep(conc, 1, resid.sd, "*"), 2, resid.sd, "*")
        return(pcc)
}

pcor2(cbind(x1,x2,x3))


J. Whittaker's book "Graphical models in applied multivariate statistics"
is a good reference for the theory behind this.

Martyn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From olivier.martin at cea.fr  Fri Feb 25 14:54:16 2000
From: olivier.martin at cea.fr (Olivier MARTIN)
Date: Fri, 25 Feb 2000 14:54:16 +0100
Subject: [R] kohonen
Message-ID: <38B68988.AB398447@cea.fr>

hi all,

i would like to apply the kohonen 's algorithm (SOM). Somebody knows if
there is an available script ?

thanks

--

------- Olivier MARTIN --------
_______________________________
_______________________________
CEA
17, rues des martyrs
LETI/DSYS/SCSI
Bur 225
olivier.martin at cea.fr
04 76 88 47 61 (bur.)
04 76 88 57 87 (fax.)
----------------------
06 08 67 93 42 (pers.)
_______________________________
_______________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Fri Feb 25 15:48:56 2000
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 25 Feb 2000 09:48:56 -0500
Subject: [R] partial correlation coefficients in R?
In-Reply-To: <B4DC1956.21AC%pflugshaupt@geobot.umnw.ethz.ch>
Message-ID: <3.0.5.32.20000225094856.00a3a6e0@mcmail.cis.mcmaster.ca>

At 11:34 AM 2/25/2000 +0100, you wrote:

>after thorough searching of the R help files as well as S+-help, I'm coming
>to the list: Is there a possibility to compute partial correlation
>coefficients between multiple variables (correlation between two paired
>samples with the "effects of all other  variables partialled out")? All I
>seem to find are the standard Pearson correlation coefficients (with cor())
>and no clue as to how to convert them into partial ones. One of my books
>states that"this is a computionally intensive problem and computer help is
>most welcome" :-), but fails to give an algorithm. Can anyone help? Maybe
>this feature already exists somewhere?
>

Dear Kaspar,

Actually, this is quite straightforward. Suppose that R is the correlation matrix among the variables. Then,

	Rinv<-solve(R)
	D<-diag(1/sqrt(diag(Rinv)))
	P<- -D %*% Rinv %*% D

The off-diagonal elements of P are then the partial correlations between each pair of variables "partialed" for the others. (Why one would want to do this is another question.)

I hope that this helps,
 John



|----------------------------------------------------|
| John Fox                          jfox at McMaster.ca |
| Department of Sociology        McMaster University |
|----------------------------------------------------|
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolbers at stat.math.ethz.ch  Fri Feb 25 15:53:06 2000
From: wolbers at stat.math.ethz.ch (Marcel Wolbers)
Date: Fri, 25 Feb 2000 15:53:06 +0100 (MET)
Subject: [R] partial correlation coefficients in R?
In-Reply-To: <Pine.GSO.3.96.1000225115336.15076D-100000@kite.cen.brad.ac.uk>
References: <B4DC1956.21AC%pflugshaupt@geobot.umnw.ethz.ch>
	<Pine.GSO.3.96.1000225115336.15076D-100000@kite.cen.brad.ac.uk>
Message-ID: <14518.38738.26682.130328@gargle.gargle.HOWL>

Hi Kaspar,

> to the list: Is there a possibility to compute partial correlation
> coefficients between multiple variables 

pcor2 works also generrally (not only for 3 vars):

#pcor from David Lucy (only for 3 vars)
pcor <- function(v1, v2, v3)
	{
	c12 <- cor(v1, v2)
	c23 <- cor(v2, v3)
	c13 <- cor(v1, v3)

	partial <- (c12-(c13*c23))/(sqrt(1-(c13^2)) * sqrt(1-(c23^2)))

	return(partial)
	}

#pcor2
pcor2 <- function(x1,x2){
  #canonical correlation matrix of x1 given x2
  S1.2 <- cov(x1)-cov(x1,x2)%*%solve(cov(x2))%*%cov(x2,x1)
    #partial covariance of x1 given x2
  D1.2.Inv <- diag(1/sqrt(diag(S1.2)))
  partial <- D1.2.Inv%*%S1.2%*%D1.2.Inv #partial correlations
  return(partial)
}

v1 <- rnorm(10)
v2 <- rnorm(10)
v3 <- rnorm(10)
pcor(v1,v2,v3)
> [1] 0.08953366
pcor2(cbind(v1,v2),v3)
>   
             [,1]       [,2]
  [1,] 1.00000000 0.08953366
  [2,] 0.08953366 1.00000000

Best wishes
Marcel

-------------------------------------------------------------------------------
Marcel Wolbers, LEO C14, Seminar for Statistics, ETH Zurich
CH-8092 Zurich, Switzerland; phone: +41 1 632 2252	
http://stat.ethz.ch/~wolbers/
-------------------------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From D.J.Lucy at Bradford.ac.uk  Fri Feb 25 16:08:30 2000
From: D.J.Lucy at Bradford.ac.uk (Dave Lucy)
Date: Fri, 25 Feb 2000 15:08:30 +0000 (GMT)
Subject: [R] partial correlation coefficients in R?
In-Reply-To: <XFMail.000225143531.plummer@iarc.fr>
Message-ID: <Pine.GSO.3.96.1000225150632.15076L-100000@kite.cen.brad.ac.uk>

On Fri, 25 Feb 2000, Martyn Plummer wrote:

> In general you invert the variance-covariance matrix and then rescale it
> so the diagonal is one.  The off-diagonal elements are the negative
> partial correlation coefficients given all other variables.

Martyn,

Thanks - quite a bit cleverer than mine - I'll pour over it when I need
to do some more partial correlations.

Dave.





********************************************************************
Dr. David Lucy
Department of Archaeological Sciences
University of Bradford
Bradford
West Yorkshire
BD7 1DP
UK

tel. +44 01274 233556
fax. +44 01274 235190
********************************************************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.M.E.Altham at statslab.cam.ac.uk  Fri Feb 25 16:34:04 2000
From: P.M.E.Altham at statslab.cam.ac.uk (Pat Altham)
Date: Fri, 25 Feb 2000 15:34:04 +0000
Subject: [R] partial correlation coefficients in R?
Message-ID: <E12OMkm-0006JZ-00@whist.statslab.cam.ac.uk>

Worksheet 3 of my
`Other worksheets for S-Plus: a miscellany'
gives an example of this
(computing partial correlations from the inverse of the covariance matrix)
see
http://www.statslab.cam.ac.uk/~pat

 Pat Altham
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Fri Feb 25 17:01:21 2000
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Fri, 25 Feb 2000 17:01:21 +0100
Subject: [R] Summary: Partial correlation coefficients in R. Thanks everybody!
Message-ID: <B4DC65E0.21C1%pflugshaupt@geobot.umnw.ethz.ch>

Hello all,

here's a collection of answers I got on my question concerning partial
correlation coefficients:

Some people gave a simple formula for the three-variable-case, as did Dave
Lucy:

pcor <- function(v1, v2, v3)
    {
    c12 <- cor(v1, v2)
    c23 <- cor(v2, v3)
    c13 <- cor(v1, v3)

    partial <- (c12-(c13*c23))/(sqrt(1-(c13^2)) * sqrt(1-(c23^2)))

    return(partial)
}

The general algorithm was given by John Logsdon, among others:

The partial correlation coefficients are the negative
scaled off-diagonal inverse variance.  So compute the variance-covariance
matrix, invert, scale to the diagonal and negate and you have it.

And an implementation by Martyn Plummer (here, too, I received several):

pcor2 <- function(x){
        conc <- solve(var(x))
        resid.sd <- 1/sqrt(diag(conc))
        pcc <- - sweep(sweep(conc, 1, resid.sd, "*"), 2, resid.sd, "*")
        return(pcc)
}

This is the version I'm using now, together with a test for significance of
each coefficient (H0: coeff=0):

f.parcor <-
function (x, test = F, p = 0.05)
{
    nvar <- ncol(x)
    ndata <- nrow(x)
    conc <- solve(cor(x))
    resid.sd <- 1/sqrt(diag(conc))
    pcc <- -sweep(sweep(conc, 1, resid.sd, "*"), 2, resid.sd,
        "*")
    colnames(pcc) <- rownames(pcc) <- colnames(x)
    if (test) {
        t.df <- ndata - nvar
        t <- pcc/sqrt((1 - pcc^2)/t.df)
        pcc <- list(coefs = pcc, significant = t > qt(1 - (p/2),
            df = t.df))
    }
    return(pcc)
}

Thanks to everybody for your help!

Kaspar

-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lina.lundgren at norrkoping.mail.telia.com  Sat Feb 26 15:20:52 2000
From: lina.lundgren at norrkoping.mail.telia.com (Lina Lundgren)
Date: Sat, 26 Feb 2000 15:20:52 +0100
Subject: [R] Problem with 'link.html.help()'
Message-ID: <000701bf8064$b1d25620$36c743c3@oemcomputer>

Hello,

I just recently installed R 0.99 and use Windows 98.
It appears as if  
link.html.help()

locks the system. But somehow the information on 'Mass' is there but not about 'survival5'. Both these libraries are

installed and functions OK.

Any help available?



Fredrik Lundgren

Norrk?ping

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20000226/cadcfd6d/attachment.html

From ripley at stats.ox.ac.uk  Sat Feb 26 18:07:41 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 26 Feb 2000 17:07:41 +0000 (GMT)
Subject: [R] Problem with 'link.html.help()'
In-Reply-To: <000701bf8064$b1d25620$36c743c3@oemcomputer>
Message-ID: <Pine.GSO.4.05.10002261658550.27578-100000@auk.stats>

On Sat, 26 Feb 2000, Lina Lundgren wrote:

> Hello,
> 
> I just recently installed R 0.99 and use Windows 98.
> It appears as if  
> link.html.help()
> 
> locks the system. But somehow the information on 'Mass' is there but 
> not about 'survival5'.

Does it give a prompt 1: on the console?: Just hit return.  This happens if
some package you have installed lacks a TITLE file. None of those I have on
the contrib area on CRAN are deficient, but I have met this recently. (The
imminent rw1000 will check such things much more carefully as a result.)

[Note to package distributors: do run the R CMD build checks, as that will
tell you if files are missing.]

Alternatively, follow the advice in the rw-FAQ about using `make indices'
as being the preferred way to do this.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lina.lundgren at norrkoping.mail.telia.com  Sat Feb 26 19:23:10 2000
From: lina.lundgren at norrkoping.mail.telia.com (Lina Lundgren)
Date: Sat, 26 Feb 2000 19:23:10 +0100
Subject: VB: [R] Problem with 'link.html.help()'
Message-ID: <000e01bf8086$89e7b520$dac643c3@oemcomputer>

To Brian Ripley,
Thanks!
Yes indeed, It functions if you hit return at the prompt 1:
but this had to be done for five times!
Later five packages were found named NA with the description NA NA but all the rest of the 'libraries'
are there in proper order with names and descriptions.

Thanks to Brian Ripley

Fredrik Lundgren

-----Ursprungligt meddelande-----
Fr?n: Prof Brian D Ripley <ripley at stats.ox.ac.uk>
Till: Lina Lundgren <lina.lundgren at norrkoping.mail.telia.com>
Kopia: r-help at stat.math.ethz.ch <r-help at stat.math.ethz.ch>
Datum: den 26 februari 2000 18:09
?mne: Re: [R] Problem with 'link.html.help()'


>On Sat, 26 Feb 2000, Lina Lundgren wrote:
>
>> Hello,
>> 
>> I just recently installed R 0.99 and use Windows 98.
>> It appears as if  
>> link.html.help()
>> 
>> locks the system. But somehow the information on 'Mass' is there but 
>> not about 'survival5'.
>
>Does it give a prompt 1: on the console?: Just hit return.  This happens if
>some package you have installed lacks a TITLE file. None of those I have on
>the contrib area on CRAN are deficient, but I have met this recently. (The
>imminent rw1000 will check such things much more carefully as a result.)
>
>[Note to package distributors: do run the R CMD build checks, as that will
>tell you if files are missing.]
>
>Alternatively, follow the advice in the rw-FAQ about using `make indices'
>as being the preferred way to do this.
>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272860 (secr)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From faheem at email.unc.edu  Sun Feb 27 06:38:11 2000
From: faheem at email.unc.edu (Faheem Mitha)
Date: Sun, 27 Feb 2000 00:38:11 -0500 (EST)
Subject: [R] multiple comparisons
In-Reply-To: <x2zotcim9p.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.21.0002270009240.503-100000@Chrestomanci.home.earth>

Dear R people,

I was wanting `canned' routines to do the following in a complete two way
linear model (I think in R/S+ this is of the form y ~ a*b where a and b
are the factors.) 

a) 95% simultaneous confidence intervals for interaction contrasts of the
form \tau_{ik} - \tau{il} - \tau{jkl + \tau{jll (I think this is all
interaction contrasts) using the Scheffe and Bonferroni methods.

b) 95% simultaneous confidence intervals for all pairwise main effect
contrasts of each factor separately using the Sheffe/Bonferroni/Tukey
methods.

I can't see a way to do this in R. If there is one, please let me know. I
also have access to S+, though I try to use R if possible because I have
it on my home computer. (Also, it is free software :-) ). I know there is
a function in S+ called multicomp, but the only documentation I have
available it that which I get when I type ?multicomp, which I find
somewhat cryptic. I don't know if multicomp can handle the situations
about, but if it can, would someone be kind enough to tell me what the
correct syntax for them? Also, it there somewhere where I can find more
detailed information about multicomp?

By the way, there doesn't seem to be a newsgroup for S+. Does anyone know
of a mailing list? I did a web search for multicomp just now, and someone
had asked a question about multicomp (apparently, without getting a reply)
on a mailing list called s-news at wubios.wustl.edu. What is this?

Please excuse the somewhat off-topic stuff about S+.

                                   Sincerely, Faheem Mitha.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From faheem at email.unc.edu  Sun Feb 27 06:53:15 2000
From: faheem at email.unc.edu (Faheem Mitha)
Date: Sun, 27 Feb 2000 00:53:15 -0500 (EST)
Subject: No subject
In-Reply-To: <Pine.LNX.4.21.0002270009240.503-100000@Chrestomanci.home.earth>
Message-ID: <Pine.LNX.4.21.0002270038360.503-100000@Chrestomanci.home.earth>

Dear R people,

Here is a little script. There is a problem with the function plot.factor,
which is puzzling. I wrote a very similar code for a one-way model and it
worked fine. With the code below, I get the mysterious error message 

Error in barplot.default(table(x), axisnames = axisnames, ...) : `height'
must be a vector or a matrix
 
I was told the problem was likely connected to the fact that I had not
coerced my factors to be factor objects, but I did so and it still
doesn't work. I have not included the file hkepd.dat from which the data
is read. I think that it is possible the error will be visible from the
code below. If not, I can certainly send out the data file if anybody
wants to use it. I would be grateful if anyone would tell me how to
correct the fault.

The linear model below is of the form hosp ~ s*pollut. `hosp' is hospital
admissions data, `s' is the season to which the data belongs, and `pollut'
is the level of so2 pollution.

                               Sincerely, Faheem Mitha.

*****************************************************************************

hk.df <- read.table("hkepd.dat",header=T, row.names=NULL)

attach(hk.df)
                       
# making a function `season' to convert season data (months. years, into
# season factors (spring, summer, autumn, winter).

season <- function(m,d)
{

if ( m == 1 || m == 2 || ( m == 12 && d >= 21) || (m == 3 && d <= 20 ) )
     return("wi")

else if
      ( m == 4 || m == 5 || ( m == 3 && d >= 21) ||(m == 6 && d <= 20 ) )
     return("sp")

else if
      ( m == 7 || m == 8 || ( m == 6 && d >= 21) ||(m == 9 && d <= 20 ))
     return("su")

else if 
      ( m == 10 || m == 11 || ( m == 9 && d >= 21) || (m == 12 && d <= 20 ) )
     return("au")

else
    return("error")  

}

#making season factor vector

s <- 1:length(month)
for(i in 1:length(month))
 s[i] <- season(month[i],day[i])

# reading columns of the data frame to vectors

hosp <- Total
so <- so2

#stuff to make pollut factor vector

pollut <- rep("high",length(so))
pollut[so <= 21.62] <- "med"
pollut[so <= 14.23] <- "low"

# coercing season and pollut vectors to be factors.

sf <- factor(s)
pollutf <- factor(pollut)

# making data frame to do the two way model

poll.df  <- data.frame(hosp,s,pollut)
attach(poll.df)

pollf.df  <- data.frame(hosp,sf,pollutf)
attach(pollf.df)

# trying to get plot.factor to do its stuff. Fails with error message
# quoted above.

postscript("poll.anova1.ps",width=5.5, height = 5, horizontal=F, pointsize=8)
par(mfrow=c(2,2),mar=c(5,3,3,1)+0.1)
plot.factor(pollf.df)
dev.off()

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Feb 27 12:51:14 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 27 Feb 2000 12:51:14 +0100
Subject: [R] Re: none
In-Reply-To: Faheem Mitha's message of "Sun, 27 Feb 2000 00:53:15 -0500 (EST)"
References: <Pine.LNX.4.21.0002270038360.503-100000@Chrestomanci.home.earth>
Message-ID: <x2n1om7tjh.fsf@blueberry.kubism.ku.dk>

Faheem Mitha <faheem at email.unc.edu> writes:


> Error in barplot.default(table(x), axisnames = axisnames, ...) : `height'
> must be a vector or a matrix

...
> pollf.df  <- data.frame(hosp,sf,pollutf)
> attach(pollf.df)
> 
> # trying to get plot.factor to do its stuff. Fails with error message
> # quoted above.
> 
> postscript("poll.anova1.ps",width=5.5, height = 5, horizontal=F, pointsize=8)
> par(mfrow=c(2,2),mar=c(5,3,3,1)+0.1)
> plot.factor(pollf.df)
> dev.off()

Well, plot.factor() is a method for the generic function plot() when
the argument is a factor, passing it anything but a factor is asking
for trouble.

What will happen is that it will do table(pollf.df) and try to barplot
that, but table() on a data frame with three variables is a three way
array and barplot() only knows what to do with 1-D or 2-D structures,
hence the error.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jniesch at gwdg.de  Tue Feb 22 14:38:18 2000
From: jniesch at gwdg.de (jens)
Date: Tue, 22 Feb 2000 14:38:18 +0100
Subject: [R] R-0.99 installation on UNIX
Message-ID: <3.0.2.32.20000222143818.00692534@popper.gwdg.de>

	      {message bounced because it has "$$$" in it.
	       manually approved by list maintainer -- MM}

> Date: Tue, 22 Feb 2000 13:03:35 +0100
> From: jens <jniesch at gwdg.de>
>
> I have trouble to install R on  Sparc Sun Solaris 2.6.
> make returns the error message:
> Undefined symbol 		first referenced in file
> d_lg10				../appl/libappl.a(uncmin.o)
> d_sign				../appl/libappl.a(dpoco.o
>
> Anybody can help me out?

Try installing the current version, 0.99.0, which does a better
job of finding the right libraries. If that fails come back to us
with a listing of Makeconf in the top-level build directory,
and details of the compilers you used.

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

I tried the R-0.99.0 version and got the following for make

Undefined symbol 		first referenced in file
i_len				xxxpr.o
d_sign				../appl/libappl.a(dpoco.o)

The compilers used are
C: gcc version 2.81
FORTRAN: f2c (from the gnu download packet f2c-1993_04_28_tar.gz)

The Makeconf reads:

PACKAGE = R
VERSION = 0.99.0

AR = ar
AWK = gawk
BLAS = blas.o
CC =
gcc
CFLAGS = -g -O2
CPICFLAGS = -fPIC
CPPFLAGS =
DEFS =
-DHAVE_CONFIG_H
DLLFLAGS =
DVIPS = false
FC =
FFLAGS =
FLIBS =

FPICFLAGS = -PIC
F2C = f2c
F2CFLAGS =
GNOMEUI_LIBS =
GNOME_LIBDIR =

GNOME_INCLUDEDIR =
INSTALL = $(top_srcdir)/tools/install-sh
-c
INSTALL_DATA = ${INSTALL} -m 644
INSTALL_PROGRAM =
${INSTALL}
INSTALL_DIR = ${INSTALL} -d
LATEX = false
LDCMD = gcc
LDFLAGS =

LIBGLADE_CFLAGS =
LIBGLADE_LIBS =
LIBS = -lz -ldl -ltermcap -lm
LN_S =
ln -s
MAKEINDEX = /usr/local/bin/makeindex
MKINSTALLDIRS =
$(top_srcdir)/tools/mkinstalldirs
R_PKGS = base ctest eda lqs modreg mva
nls splines stepfun ts
R_XTRA_CFLAGS =
R_XTRA_CPPFLAGS = -I. -I../include
-I$(top_srcdir)/src/include -I$(top_srcdir)/src/include/R_ext
R_XTRA_FFLAGS
=
R_XTRA_LIBS =
RANLIB = ranlib
SHELL = /bin/sh
SHLIBEXT = so
SHLIBLD =
gcc
SHLIBLDFLAGS = -G
TAR = tar
X_CFLAGS =  -I/usr/openwin/include
X_LIBS =
 -L/usr/openwin/lib -R/usr/openwin/lib -lX11
X_PRE_LIBS =  -lSM
-lICE
X_EXTRA_LIBS = -lsocket  -lnsl
YACC = bison -y

ALL_CFLAGS =
$(R_XTRA_CFLAGS) $(CFLAGS)
ALL_CPPFLAGS = $(R_XTRA_CPPFLAGS) $(CPPFLAGS)
$(DEFS)
ALL_FFLAGS = $(R_XTRA_FFLAGS) $(FFLAGS)

.SUFFIXES:
.SUFFIXES: .c
.f .d .o


.c.d:
	@echo "making $@ from $<"
	@$(CC) -M $(ALL_CPPFLAGS) $< >
$@
.c.o:
	$(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) -c $< -o $@

.f.o:
	$(F2C)
$(F2CFLAGS) < $< > $*.c
	$(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) -c $*.c -o $@

@rm -f $*.c

prefix = /usr/users/jniesch/iwas
exec_prefix =
${prefix}
bindir = ${exec_prefix}/bin
datadir = ${prefix}/share
libdir =
${exec_prefix}/lib
mandir = ${prefix}/man

rhome = ${exec_prefix}/lib/R


	Jens



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Mon Feb 28 11:30:23 2000
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Mon, 28 Feb 2000 11:30:23 +0100
Subject: [R] mapping of colornames into hsv?
Message-ID: <000501bf81d6$d2d40d00$a9021aac@joelschlaegel>



I couldn't find this in online help or the archives:
Is there any R function or object giving the mapping of the colornames as
given by colors() into the hsv() model?

Regards


--
Dr. Jens Oehlschl?gel-Akiyoshi
MD FACTORY GmbH
Bayerstrasse 21

80335 M?nchen

Tel.: 089 545 28-27
Fax.: 089 545 28-10
http://www.mdfactory.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Feb 28 12:22:45 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Feb 2000 12:22:45 +0100
Subject: [R] mapping of colornames into hsv?
In-Reply-To: "Jens Oehlschl?gel-Akiyoshi"'s message of "Mon, 28 Feb 2000 11:30:23 +0100"
References: <000501bf81d6$d2d40d00$a9021aac@joelschlaegel>
Message-ID: <x2og917ere.fsf@blueberry.kubism.ku.dk>

"Jens Oehlschl?gel-Akiyoshi" <jens.oehlschlaegel-akiyoshi at mdfactory.de> writes:

> I couldn't find this in online help or the archives:
> Is there any R function or object giving the mapping of the colornames as
> given by colors() into the hsv() model?

It isn't there. You might be able to cook something up which calls the
internal name2col() C function which returns the RGB color code for a
string name. 

[And as I was experimenting with this I tried palette(colors()) and
got a segfault...]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Feb 28 12:58:36 2000
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Feb 2000 11:58:36 +0000 (GMT)
Subject: [R] mapping of colornames into hsv?
Message-ID: <200002281158.LAA22209@toucan.stats.ox.ac.uk>


> To: <jens.oehlschlaegel-akiyoshi at mdfactory.de>
> Date: 28 Feb 2000 12:22:45 +0100
> 
> "Jens Oehlschl?gel-Akiyoshi" <jens.oehlschlaegel-akiyoshi at mdfactory.de> 
writes:
> 
> > I couldn't find this in online help or the archives:
> > Is there any R function or object giving the mapping of the colornames as
> > given by colors() into the hsv() model?
> 
> It isn't there. You might be able to cook something up which calls the
> internal name2col() C function which returns the RGB color code for a
> string name. 
> 
> [And as I was experimenting with this I tried palette(colors()) and
> got a segfault...]

I _think_  etc/colors.big is the R code that does the job, but whether
it is the same is unsure.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Feb 28 14:36:22 2000
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 28 Feb 2000 08:36:22 -0500
Subject: [R] Rinst.exe question
Message-ID: <51F9C42DA15CD311BD220008C707D8197A0522@usrymx10.merck.com>

Hi all,

I'm using R0.99a on WinNT4.  I downloaded a bunch of packages and tried
using Rinst.exe to install them.  For whatever reason, Rinst.exe does not
find all the packages I downloaded.  I put all files in the same temp
directory, but Rinst only finds some of them.  I have no problem installing
the rest with WinZip, but if Rinst works it would be much easier (don't have
to run WinZip 20+ times).

Anyone have any idea?

Regards,
Andy Liaw
Merck Biometrics Research
Phone: (732) 594-0820
Fax: (732) 594-1565
mailto:andy_liaw at merck.com

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Feb 28 14:53:52 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Feb 2000 14:53:52 +0100
Subject: [R] Rinst.exe question
In-Reply-To: "Liaw, Andy"'s message of "Mon, 28 Feb 2000 08:36:22 -0500"
References: <51F9C42DA15CD311BD220008C707D8197A0522@usrymx10.merck.com>
Message-ID: <x2ln4577rj.fsf@blueberry.kubism.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Hi all,
> 
> I'm using R0.99a on WinNT4.  I downloaded a bunch of packages and tried
> using Rinst.exe to install them.  For whatever reason, Rinst.exe does not
> find all the packages I downloaded.  I put all files in the same temp
> directory, but Rinst only finds some of them.  I have no problem installing
> the rest with WinZip, but if Rinst works it would be much easier (don't have
> to run WinZip 20+ times).
> 
> Anyone have any idea?

Silly question #1, but it has to be asked: The installer window is
scrollable, isn't it?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Feb 28 14:58:37 2000
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 28 Feb 2000 08:58:37 -0500
Subject: [R] Rinst.exe question
Message-ID: <51F9C42DA15CD311BD220008C707D8197A0523@usrymx10.merck.com>

Sure the window scrolls, but it does *not* list all packages I have in the
same directory.  (It's flat out obvious because I downloaded just about all
the packages in the contrib section, yet it only lists about 4 or 5 of
them.)  I've checked this several times.  Same thing on a Win98 machine.

Andy Liaw
Merck Biometrics Research
Phone: (732) 594-0820
Fax: (732) 594-1565
mailto:andy_liaw at merck.com


> ----------
> From: 	Peter Dalgaard BSA[SMTP:p.dalgaard at biostat.ku.dk]
> Sent: 	Monday, February 28, 2000 8:53 AM
> To: 	Liaw, Andy
> Cc: 	'r-help'
> Subject: 	Re: [R] Rinst.exe question
> 
> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> > Hi all,
> > 
> > I'm using R0.99a on WinNT4.  I downloaded a bunch of packages and tried
> > using Rinst.exe to install them.  For whatever reason, Rinst.exe does
> not
> > find all the packages I downloaded.  I put all files in the same temp
> > directory, but Rinst only finds some of them.  I have no problem
> installing
> > the rest with WinZip, but if Rinst works it would be much easier (don't
> have
> > to run WinZip 20+ times).
> > 
> > Anyone have any idea?
> 
> Silly question #1, but it has to be asked: The installer window is
> scrollable, isn't it?
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Feb 28 16:01:08 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Feb 2000 16:01:08 +0100
Subject: [R] Rinst.exe question
In-Reply-To: "Liaw, Andy"'s message of "Mon, 28 Feb 2000 08:58:37 -0500"
References: <51F9C42DA15CD311BD220008C707D8197A0523@usrymx10.merck.com>
Message-ID: <x2g0ud74nf.fsf@blueberry.kubism.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Sure the window scrolls, but it does *not* list all packages I have in the
> same directory.  (It's flat out obvious because I downloaded just about all
> the packages in the contrib section, yet it only lists about 4 or 5 of
> them.)  I've checked this several times.  Same thing on a Win98 machine.

Doesn't happen here, I just tried with all 50+ of 'em on a W98. They
all have the proper .zip suffix and downloaded OK? (but how else could
winzip work with them?) The source directory is correct too?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Feb 28 16:21:44 2000
From: gb at stat.umu.se (gb@stat.umu.se)
Date: Mon, 28 Feb 2000 16:21:44 +0100 (CET)
Subject: [R] ms?
In-Reply-To: <200002281158.LAA22209@toucan.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.10.10002281607540.29695-100000@pc16.stat.umu.se>


Is the Splus (4.0) function  ms  (or something equivalent)
available in some  R  package? I am trying to get an Splus
program to work with R. The piece of  Splus  code is

ms.fit<-ms(~t(Y-(X[,1] * alf + X[,2] * bet)^delta)%*%
           covariance.matrix.inverse%*%
           (Y-(X[,1] * alf + X[,2] * bet)^delta),
           sys.parent(0) , list(alf=5,bet=0.5), trace = F)

G?ran
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Mon Feb 28 16:40:08 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 28 Feb 2000 09:40:08 -0600
Subject: [R] ms?
In-Reply-To: gb@stat.umu.se's message of "Mon, 28 Feb 2000 16:21:44 +0100 (CET)"
References: <Pine.LNX.4.10.10002281607540.29695-100000@pc16.stat.umu.se>
Message-ID: <6r90055o9z.fsf@franz.stat.wisc.edu>

gb at stat.umu.se writes:

> Is the Splus (4.0) function  ms  (or something equivalent)
> available in some  R  package? I am trying to get an Splus
> program to work with R. The piece of  Splus  code is
> 
> ms.fit<-ms(~t(Y-(X[,1] * alf + X[,2] * bet)^delta)%*%
>            covariance.matrix.inverse%*%
>            (Y-(X[,1] * alf + X[,2] * bet)^delta),
>            sys.parent(0) , list(alf=5,bet=0.5), trace = F)

There are several different optimizers available in R now but none of
them are exactly the same as the ms optimizer in S.  The nlm
optimizer has been available for a long time.  Recently Brian Ripley
added a variety of optimizers in the optim function.  Try
 ?optim
and
 ?nlm
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Feb 28 17:12:41 2000
From: gb at stat.umu.se (gb@stat.umu.se)
Date: Mon, 28 Feb 2000 17:12:41 +0100 (CET)
Subject: [R] ms?
In-Reply-To: <6r90055o9z.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.LNX.4.10.10002281707370.29776-100000@pc16.stat.umu.se>

On 28 Feb 2000, Douglas Bates wrote:

> gb at stat.umu.se writes:
> 
> > Is the Splus (4.0) function  ms  (or something equivalent)
> > available in some  R  package? I am trying to get an Splus
> > program to work with R. The piece of  Splus  code is
> > 
> > ms.fit<-ms(~t(Y-(X[,1] * alf + X[,2] * bet)^delta)%*%
> >            covariance.matrix.inverse%*%
> >            (Y-(X[,1] * alf + X[,2] * bet)^delta),
> >            sys.parent(0) , list(alf=5,bet=0.5), trace = F)
> 
> There are several different optimizers available in R now but none of
> them are exactly the same as the ms optimizer in S.  The nlm
> optimizer has been available for a long time.  Recently Brian Ripley
> added a variety of optimizers in the optim function.  Try
>  ?optim
> and
>  ?nlm
> 

Thanks for the answer; I just hoped for the _very_ simple 
solution. Guess I have to write a function to minimize.

G?ran
----------------------------------------------------------
 G?ran Brostr?m                      tel: +46 90 786-5223
 Department of Statistics            fax: +46 90 786-6614
 Ume? University                                         
 SE-90187 Ume?, Sweden              email: gb at stat.umu.se
                                                        
 http://www.stat.umu.se/egna/gb    ftp://capa.stat.umu.se
----------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Mon Feb 28 17:26:05 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 28 Feb 2000 10:26:05 -0600
Subject: [R] ms?
In-Reply-To: gb@stat.umu.se's message of "Mon, 28 Feb 2000 17:12:41 +0100 (CET)"
References: <Pine.LNX.4.10.10002281707370.29776-100000@pc16.stat.umu.se>
Message-ID: <6r7lfp5m5e.fsf@franz.stat.wisc.edu>

gb at stat.umu.se writes:

> On 28 Feb 2000, Douglas Bates wrote:
> 
> > gb at stat.umu.se writes:
> > 
> > > Is the Splus (4.0) function  ms  (or something equivalent)
> > > available in some  R  package? I am trying to get an Splus
> > > program to work with R. The piece of  Splus  code is
> > > 
> > > ms.fit<-ms(~t(Y-(X[,1] * alf + X[,2] * bet)^delta)%*%
> > >            covariance.matrix.inverse%*%
> > >            (Y-(X[,1] * alf + X[,2] * bet)^delta),
> > >            sys.parent(0) , list(alf=5,bet=0.5), trace = F)
> > 
> > There are several different optimizers available in R now but none of
> > them are exactly the same as the ms optimizer in S.  The nlm
> > optimizer has been available for a long time.  Recently Brian Ripley
> > added a variety of optimizers in the optim function.  Try
> >  ?optim
> > and
> >  ?nlm
> > 
> 
> Thanks for the answer; I just hoped for the _very_ simple 
> solution. Guess I have to write a function to minimize.

Assuming that the quadratic form evaluates to a scalar, try

opt.func <- function(alf, beta) 
  t(Y-(X[,1] * alf + X[,2] * bet)^delta) %*% covariance.matrix.inverse %*%
            (Y-(X[,1] * alf + X[,2] * bet)^delta)

nlm(opt.func, c(alf = 5, bet = 0.5))

or

optim(c(alf = 5, bet = 0.5), opt.func)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Mon Feb 28 17:39:04 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 28 Feb 2000 10:39:04 -0600
Subject: [R] ms?
In-Reply-To: Douglas Bates's message of "28 Feb 2000 10:26:05 -0600"
References: <Pine.LNX.4.10.10002281707370.29776-100000@pc16.stat.umu.se> <6r7lfp5m5e.fsf@franz.stat.wisc.edu>
Message-ID: <6r4sat5ljr.fsf@franz.stat.wisc.edu>

Douglas Bates <bates at stat.wisc.edu> writes:

> Assuming that the quadratic form evaluates to a scalar, try
> 
> opt.func <- function(alf, beta) 
>   t(Y-(X[,1] * alf + X[,2] * bet)^delta) %*% covariance.matrix.inverse %*%
>             (Y-(X[,1] * alf + X[,2] * bet)^delta)
> 
> nlm(opt.func, c(alf = 5, bet = 0.5))
> 
> or
> 
> optim(c(alf = 5, bet = 0.5), opt.func)

Those are wrong.  The function being optimized has to be a function of
a single argument.  If alf and bet are both scalars you can combine
them into a vector and use

opt.func <- function(arg) 
  t(Y-(X[,1] * arg[1] + X[,2] * arg[2])^delta) %*% covariance.matrix.inverse %*%
            (Y-(X[,1] * arg[1] + X[,2] * arg[2])^delta)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Feb 28 10:25:35 2000
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 28 Feb 2000 09:25:35 +0000 (GMT)
Subject: [R] R-0.99 installation on UNIX
In-Reply-To: <3.0.2.32.20000222143818.00692534@popper.gwdg.de>
Message-ID: <Pine.GSO.4.05.10002280913580.11182-100000@auk.stats>

On Tue, 22 Feb 2000, jens wrote:

> > Date: Tue, 22 Feb 2000 13:03:35 +0100
> > From: jens <jniesch at gwdg.de>
> >
> > I have trouble to install R on  Sparc Sun Solaris 2.6.
> > make returns the error message:
> > Undefined symbol 		first referenced in file
> > d_lg10				../appl/libappl.a(uncmin.o)
> > d_sign				../appl/libappl.a(dpoco.o
> >
> > Anybody can help me out?
>
> Try installing the current version, 0.99.0, which does a better
> job of finding the right libraries. If that fails come back to us
> with a listing of Makeconf in the top-level build directory,
> and details of the compilers you used.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> I tried the R-0.99.0 version and got the following for make
>
> Undefined symbol 		first referenced in file
> i_len				xxxpr.o
> d_sign				../appl/libappl.a(dpoco.o)
>
> The compilers used are
> C: gcc version 2.81
> FORTRAN: f2c (from the gnu download packet f2c-1993_04_28_tar.gz)

That is really ancient!  I suggest you install gcc-2.95.2, including g77,
if you do not have the Sun compilers.  You will find life much easier with
a real Fortran compiler.

> The Makeconf reads:
>
> PACKAGE = R
> VERSION = 0.99.0
>
> AR = ar
> AWK = gawk
> BLAS = blas.o
> CC =
> gcc
> CFLAGS = -g -O2
> CPICFLAGS = -fPIC
> CPPFLAGS =
> DEFS =
> -DHAVE_CONFIG_H
> DLLFLAGS =
> DVIPS = false
> FC =
> FFLAGS =
> FLIBS =

That's wrong. You need -lf2c there, and possibly -L/path/to/it.  I would
have expected -lm too, but you have that in LIBS, I see, which may well
suffice.  Try setting FLIBS in config.site, or just alter Makeconf and see
if the compilation succeeds (and you will need to alter it in etc/Makeconf
too).

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juergen.bock at Roche.COM  Mon Feb 28 20:55:18 2000
From: juergen.bock at Roche.COM (Juergen Bock)
Date: Mon, 28 Feb 2000 20:55:18 +0100 (MET)
Subject: [R] foreign package
Message-ID: <14522.53926.762742.374884@lynne.ethz.ch>

       {Note the DATE !  this message bounced ...
        because it was sent to R-announce which was definitely the wrong list
	anyway.    MM - your list maintainer }

Dear R-Team

I have installed R version 0.990 and the foreign package under Windows NT..

Whilst lookup.xport() works as it should, read.xport() crashes reporting an
"access error" as well for larger datasets as also for small datasets. I
have tried the same on a single user machine (Intel Celeron 460, 256
MB). It crashes with the same error. On computer I have also installed R
version 0.90 under SuSE Linux. read.xport crashes reporting an R
sementation error.
Do you know a solution?

With many thanks in advance
Juergen Bock
juergen.bock at roche.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Mon Feb 28 21:17:39 2000
From: bates at stat.wisc.edu (Douglas Bates)
Date: 28 Feb 2000 14:17:39 -0600
Subject: [R] foreign package
In-Reply-To: Juergen Bock's message of "Mon, 28 Feb 2000 20:55:18 +0100 (MET)"
References: <14522.53926.762742.374884@lynne.ethz.ch>
Message-ID: <6rputh3wv0.fsf@franz.stat.wisc.edu>

Juergen Bock <juergen.bock at Roche.COM> writes:

> Dear R-Team
> 
> I have installed R version 0.990 and the foreign package under Windows NT..
> 
> Whilst lookup.xport() works as it should, read.xport() crashes reporting an
> "access error" as well for larger datasets as also for small datasets. I
> have tried the same on a single user machine (Intel Celeron 460, 256
> MB). It crashes with the same error. On computer I have also installed R
> version 0.90 under SuSE Linux. read.xport crashes reporting an R
> sementation error.
> Do you know a solution?

Is it possible that you could make available a sample SAS XPORT data
set that exhibits this behavior?  If so, please contact me privately
to arrange the transfer.

Saikat DebRoy and I were the people who wrote the foreign package but
neither of us has a whole lot of experience with SAS and we don't have
many sample data sets on which to test this package.

The problem is probably that the count of the rows in the data set is
too large by one.  Can you check the value from lookup.xport() and
compare it to the number of rows that should be in the data set?

The algorithm for determining the end of a data set in this format is
not well defined and apparently does not correspond to their
documentation.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From RLS at pincock.com  Mon Feb 28 22:00:59 2000
From: RLS at pincock.com (Robert L. Sandefur)
Date: Mon, 28 Feb 2000 13:00:59 -0800
Subject: [R] sub in boxplot doesn't do subtiles
Message-ID: <s8ba719c.026@hc4>

R list-

Under Windows 2000 and r 99:

I wanted a subtitle in boxplot and tried:

> boxplot((AU[ROCK==2 & AU>-1]+0.1~iz),log="y",main="Boxplot of AU by 25 M elevations",sub="aa")

And I got:

Error in sort(x) : only vectors can be sorted
In addition: Warning messages: 
1: is.na() applied to non-(list or vector) in: is.na(x) 
2: is.na() applied to non-(list or vector) in: is.na(x) 
3: is.na() applied to non-(list or vector) in: is.na(x) 
4: is.na() applied to non-(list or vector) in: is.na(x) 
> boxplot((AU[ROCK==2 & AU>-1]+0.1~iz),log="y",main="Boxplot of AU by 25 M elevations")
> title(sub="aa")

Gives a subtitle. 

Could someone point me to the documentation of sub in Boxplot (I did actually try help(boxplot))

Thanx

bob sandefur

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Feb 28 22:19:42 2000
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Feb 2000 22:19:42 +0100
Subject: [R] sub in boxplot doesn't do subtiles
In-Reply-To: "Robert L. Sandefur"'s message of "Mon, 28 Feb 2000 13:00:59 -0800"
References: <s8ba719c.026@hc4>
Message-ID: <x2d7phgh3l.fsf@blueberry.kubism.ku.dk>

"Robert L. Sandefur" <RLS at pincock.com> writes:

> I wanted a subtitle in boxplot and tried:
> 
> > boxplot((AU[ROCK==2 & AU>-1]+0.1~iz),log="y",main="Boxplot of AU by 25 M elevations",sub="aa")

Exercise in matching rules: sub= matches *subset* in the definition of
boxplot.formula 

One way out is to use the format

boxplot(x~y,subset=,sub="qwerty") 

another is to change the definition of boxplot.formula() so that the
'...' goes immediately after the formula argument, which will force
all argument matches to be exact and non-positional.

There's a deep code freeze on 1.0.0, so it cannot be fixed now, but
it might go into 1.0.1.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


