From bgunter@4567 @end|ng |rom gm@||@com  Sun Jun  1 00:08:32 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 31 May 2025 15:08:32 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
Message-ID: <CAGxFJbRVvxYtVgYdV20v6WWdKVznJSMWLYpcpnrTcOm_HJHOBw@mail.gmail.com>

If this is a real problem and not homework, can you tell us the
context? It is not at all clear (to me) what you mean by "simulate",
i.e. what your target distribution is, which may depend on/be defined
by the context.

Bert

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."


On Sat, May 31, 2025 at 11:52?AM Brian Smith <briansmith199312 at gmail.com> wrote:
>
> Hi,
>
> Let say I have a range [0, 100]
>
> Now I need to simulate 1000 10 mid-points within the range with
> accuracy upto second decimal number.
>
> Let say, one simulated set is
>
> X1, X2, ..., X10
>
> Ofcourrse
>
> X1 < X2 < ... <X10
>
> I have one more constraint that the difference between any 2
> consecutive mid-points shall be at-least 5.00.
>
> I wonder if there is any Statistical theory available to support this
> kind of simulation.
>
> Alternately, is there any way in R to implement this?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrg @end|ng |rom |oe@|@u@  Sun Jun  1 00:43:30 2025
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Sat, 31 May 2025 22:43:30 +0000
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAGxFJbRVvxYtVgYdV20v6WWdKVznJSMWLYpcpnrTcOm_HJHOBw@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CAGxFJbRVvxYtVgYdV20v6WWdKVznJSMWLYpcpnrTcOm_HJHOBw@mail.gmail.com>
Message-ID: <FE93t9pXxzBpMFMKdRtIhqY3gIx7eBYczmY3S_p1MCMbsbvSdU9dp4zkIEOZOL3lDW0Fh4S76jW5P3kbUv85XM_cTFpsTE2K8lEdNMBf_uU=@loesl.us>

I'll second Bert's comments, also assuming this is not homework.  In addition:

Your use of "mid-point" is not a standard one (in my world), nor perhaps is that of "simulate".

Let me attempt to re-state your problem:  You wish to choose 10-tuples of integers 0 <= k <= 100 satisfying

1) 0 <= k_i <= 100 for i = 1:10;
   and
2) k_(i+1) - k_(i) >= 5 for i = 1:9.

Finally, you'd like 1000 of those 10-tuples.
[Here, "k_(i)" is the usual notation for order statistics.]

Is that the task?

If so, are there are other requirements on the k_i ?

The word "simulate" suggests the k_i are supposed to be realizations of random variables.  If so, what sort of distributional assumptions did you have in mind?


---JRG



On Saturday, May 31st, 2025 at 6:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 
> 
> If this is a real problem and not homework, can you tell us the
> context? It is not at all clear (to me) what you mean by "simulate",
> i.e. what your target distribution is, which may depend on/be defined
> by the context.
> 
> Bert
> 
> "An educated person is one who can entertain new ideas, entertain
> others, and entertain herself."
> 
> 
> On Sat, May 31, 2025 at 11:52?AM Brian Smith briansmith199312 at gmail.com wrote:
> 
> > Hi,
> > 
> > Let say I have a range [0, 100]
> > 
> > Now I need to simulate 1000 10 mid-points within the range with
> > accuracy upto second decimal number.
> > 
> > Let say, one simulated set is
> > 
> > X1, X2, ..., X10
> > 
> > Ofcourrse
> > 
> > X1 < X2 < ... <X10
> > 
> > I have one more constraint that the difference between any 2
> > consecutive mid-points shall be at-least 5.00.
> > 
> > I wonder if there is any Statistical theory available to support this
> > kind of simulation.
> > 
> > Alternately, is there any way in R to implement this?
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jun  1 01:44:36 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 31 May 2025 16:44:36 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <FE93t9pXxzBpMFMKdRtIhqY3gIx7eBYczmY3S_p1MCMbsbvSdU9dp4zkIEOZOL3lDW0Fh4S76jW5P3kbUv85XM_cTFpsTE2K8lEdNMBf_uU=@loesl.us>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CAGxFJbRVvxYtVgYdV20v6WWdKVznJSMWLYpcpnrTcOm_HJHOBw@mail.gmail.com>
 <FE93t9pXxzBpMFMKdRtIhqY3gIx7eBYczmY3S_p1MCMbsbvSdU9dp4zkIEOZOL3lDW0Fh4S76jW5P3kbUv85XM_cTFpsTE2K8lEdNMBf_uU=@loesl.us>
Message-ID: <CAGxFJbTSicAPqZ9EE72rx+7WgaxAOvMr0f29o9e4xfXctLUxdA@mail.gmail.com>

JRG:

I don't think your specification is correct -- perhaps just a thinko. I
think a 10-tuple of "reals" (scare quotes because of computer precision)
with your specifications is what is wanted.

Bert

"An educated person is one who can entertain new ideas, entertain others,
and entertain herself."



On Sat, May 31, 2025 at 3:43?PM JRG <jrg at loesl.us> wrote:

> I'll second Bert's comments, also assuming this is not homework.  In
> addition:
>
> Your use of "mid-point" is not a standard one (in my world), nor perhaps
> is that of "simulate".
>
> Let me attempt to re-state your problem:  You wish to choose 10-tuples of
> integers 0 <= k <= 100 satisfying
>
> 1) 0 <= k_i <= 100 for i = 1:10;
>    and
> 2) k_(i+1) - k_(i) >= 5 for i = 1:9.
>
> Finally, you'd like 1000 of those 10-tuples.
> [Here, "k_(i)" is the usual notation for order statistics.]
>
> Is that the task?
>
> If so, are there are other requirements on the k_i ?
>
> The word "simulate" suggests the k_i are supposed to be realizations of
> random variables.  If so, what sort of distributional assumptions did you
> have in mind?
>
>
> ---JRG
>
>
>
> On Saturday, May 31st, 2025 at 6:09 PM, Bert Gunter <
> bgunter.4567 at gmail.com> wrote:
>
> >
> >
> > If this is a real problem and not homework, can you tell us the
> > context? It is not at all clear (to me) what you mean by "simulate",
> > i.e. what your target distribution is, which may depend on/be defined
> > by the context.
> >
> > Bert
> >
> > "An educated person is one who can entertain new ideas, entertain
> > others, and entertain herself."
> >
> >
> > On Sat, May 31, 2025 at 11:52?AM Brian Smith briansmith199312 at gmail.com
> wrote:
> >
> > > Hi,
> > >
> > > Let say I have a range [0, 100]
> > >
> > > Now I need to simulate 1000 10 mid-points within the range with
> > > accuracy upto second decimal number.
> > >
> > > Let say, one simulated set is
> > >
> > > X1, X2, ..., X10
> > >
> > > Ofcourrse
> > >
> > > X1 < X2 < ... <X10
> > >
> > > I have one more constraint that the difference between any 2
> > > consecutive mid-points shall be at-least 5.00.
> > >
> > > I wonder if there is any Statistical theory available to support this
> > > kind of simulation.
> > >
> > > Alternately, is there any way in R to implement this?
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrg @end|ng |rom |oe@|@u@  Sun Jun  1 03:01:42 2025
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Sun, 01 Jun 2025 01:01:42 +0000
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAGxFJbTSicAPqZ9EE72rx+7WgaxAOvMr0f29o9e4xfXctLUxdA@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CAGxFJbRVvxYtVgYdV20v6WWdKVznJSMWLYpcpnrTcOm_HJHOBw@mail.gmail.com>
 <FE93t9pXxzBpMFMKdRtIhqY3gIx7eBYczmY3S_p1MCMbsbvSdU9dp4zkIEOZOL3lDW0Fh4S76jW5P3kbUv85XM_cTFpsTE2K8lEdNMBf_uU=@loesl.us>
 <CAGxFJbTSicAPqZ9EE72rx+7WgaxAOvMr0f29o9e4xfXctLUxdA@mail.gmail.com>
Message-ID: <FP6Rkh2M9oI16rlxqZPmhK-OcNVzGvk2izj9-EPVlHdeduiLp3FrPVWOH4HwWHuaBinBrQUnnPyhVcfd7fSkuox7bm_SKPGQUXUWuYqKpAk=@loesl.us>

On Saturday, May 31st, 2025 at 7:44 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> JRG:
>
> I don't think your specification is correct -- perhaps just a thinko. I think a 10-tuple of "reals" (scare quotes because of computer precision) with your specifications is what is wanted.
>
> Bert
>
> "An educated person is one who can entertain new ideas, entertain others, and entertain herself."

Well, I had started with 10-tuples of reals. Forcing integer elements was a feeble attempt to deal with this aspect of the original post:

". . . with accuracy up to second decimal number".

But as this seems to be homework, radio silence ensues.

---JRG

> On Sat, May 31, 2025 at 3:43?PM JRG <jrg at loesl.us> wrote:
>
>> I'll second Bert's comments, also assuming this is not homework. In addition:
>>
>> Your use of "mid-point" is not a standard one (in my world), nor perhaps is that of "simulate".
>>
>> Let me attempt to re-state your problem: You wish to choose 10-tuples of integers 0 <= k <= 100 satisfying
>>
>> 1) 0 <= k_i <= 100 for i = 1:10;
>> and
>> 2) k_(i+1) - k_(i) >= 5 for i = 1:9.
>>
>> Finally, you'd like 1000 of those 10-tuples.
>> [Here, "k_(i)" is the usual notation for order statistics.]
>>
>> Is that the task?
>>
>> If so, are there are other requirements on the k_i ?
>>
>> The word "simulate" suggests the k_i are supposed to be realizations of random variables. If so, what sort of distributional assumptions did you have in mind?
>>
>> ---JRG
>>
>> On Saturday, May 31st, 2025 at 6:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>>>
>>>
>>> If this is a real problem and not homework, can you tell us the
>>> context? It is not at all clear (to me) what you mean by "simulate",
>>> i.e. what your target distribution is, which may depend on/be defined
>>> by the context.
>>>
>>> Bert
>>>
>>> "An educated person is one who can entertain new ideas, entertain
>>> others, and entertain herself."
>>>
>>>
>>> On Sat, May 31, 2025 at 11:52?AM Brian Smith briansmith199312 at gmail.com wrote:
>>>
>>> > Hi,
>>> >
>>> > Let say I have a range [0, 100]
>>> >
>>> > Now I need to simulate 1000 10 mid-points within the range with
>>> > accuracy upto second decimal number.
>>> >
>>> > Let say, one simulated set is
>>> >
>>> > X1, X2, ..., X10
>>> >
>>> > Ofcourrse
>>> >
>>> > X1 < X2 < ... <X10
>>> >
>>> > I have one more constraint that the difference between any 2
>>> > consecutive mid-points shall be at-least 5.00.
>>> >
>>> > I wonder if there is any Statistical theory available to support this
>>> > kind of simulation.
>>> >
>>> > Alternately, is there any way in R to implement this?
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From kev|n @end|ng |rom zembower@org  Sun Jun  1 22:01:20 2025
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Sun, 1 Jun 2025 20:01:20 +0000
Subject: [R] Repository of Examples and Problems from Lock5 textbook
References: <72e01a363b34fa3269daf0b16f789dd9bbe3fbc2.camel@zembower.org>
Message-ID: <010001972d159cf3-5dde9417-a822-46c9-89ea-46f49c914dc7-000000@email.amazonses.com>

I've completed my Basic Statistics course, and am pleased overall with
the experience. In addition to earning a grade of 105.82% (smart-ass
comment from wife: "How is that even statistically possible?"), I feel
as if I have a comprehensive understanding of not only the procedures
and formulas of basic statistics, but also know where the theory and
numbers come from.

One contribution to my knowledge of the material was the fact that I
tried to work all the problems and homework in the course in R, even
though the course itself never mentioned it or used it. It was still
helpful to me to be able to translate the examples and problems from
the textbook into R, and strengthened both my knowledge of statistics
and R.

Instead of just storing my work away, I've created a GihHub repository
of the work that I did that was directly related to the textbook I
used, _Statistics: Unlocking the Power of Data_ by Lock, Lock, Lock,
Lock and Lock, third edition. I created an Rmarkdown file for each
chapter's examples and the problems at the end of each chapter. I also
processed each .Rmd file into a PDF file. 

I've uploaded these to
https://github.com/kzembower/Lock5ProblemsExamples_R. They're available
for any use anyone would like to make of them. I also created some 1-2
sheet quick references of things I found helpful.

I'm pretty certain that these do not represent the best R coding, and
may even have some significant flaws. I checked the final answers
against those given in the book for almost all the problems.

Let me know if you think this repository could be improved in any way.
Thank you to all the folks who helped me better understand statistics
and how to compute them with R.

-Kevin


From r@oknz @end|ng |rom gm@||@com  Tue Jun  3 03:21:52 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 3 Jun 2025 13:21:52 +1200
Subject: [R] Looking for a function or a set of steps
In-Reply-To: <008a01dbd0a6$d64f4770$82edd650$@gmail.com>
References: <CABaFrRawDYfLYpsRb4vOtQc3tUL7Mc16SBKROxx7snOPeH20Hg@mail.gmail.com>
 <623B76F6-3881-4C25-8DE9-614A865EE657@tiscali.co.uk>
 <008a01dbd0a6$d64f4770$82edd650$@gmail.com>
Message-ID: <CABcYAd+R20_eA+oB==irkH=XmFkCp0ZpGkbwpMdc7mTNP+qZjw@mail.gmail.com>

I've replying to Avi Gross because there is useful information here for the
original poster.
A Fortran compiler is explicitly allowed to transform arithmetic
expressions as if computer
arithmetic obeyed the usual mathematical laws, which it doesn't.  R is not
Fortran.
There are two questions about a built-in function like "+" or "-".
(1) Is it VECTORISED?  That is, is it applied to corresponding elements of
vector arguments.
All the usual arithmetic operations, including comparison, and functions
like "exp" adn
"cos" are vectorised.
(2) is it GENERIC?  That is, can the operation performed vary with the
dynamic type of
one or more arguments?  Again, all the usual arithmetic operations &c are
generic.

The issue here is that because "+" and "-" and unary "-" are generic,
-x + 1 and 1 - x might or might NOT be equivalent, so the R engine is NOT
allowed to
optimise them.  (And this is without worrying about the oddities of IEEE
arithmetic.
The numbers here are all integers, BUT R DOES NOT KNOW THAT until run time.)

By actual measurement, it is clear that
-x + 1 involves *two* operations, a negation and an addition, while
1 - x involves *one* operation, a subtraction.
TWO new vectors are allocated and filled in in the first case,
ONE in the second.

For this particular problem, both versions are too fast for it to matter.
A programmer should, as a rule, write the code SIMPLY and CLEARLY, a metric
that -x + 1 fails.  When the code is working, it it is too slow, it's time
to start measuring and rewriting.  But at the beginning, make it obvious.

On those grounds, 1-x is still a bit tricky.
If there are two values A and B, swapping them can be done by (A+B)-x.
But it doesn't work with three (unless the third is NA, which 1-x leaves
unchanged).
It certainly deserves a comment:
  foobar <- 1 - foobar  # Turn 0 into 1 and vice versa.

Keywords: VECTORISED, GENERIC, and KISS.


On Fri, 30 May 2025 at 2:35?AM, <avi.e.gross at gmail.com> wrote:

> Mike,
>
> There is in a mathematical sense, no difference between:
>
> 1 - x
>
> and
>
> -x + 1
>
> But for code that is compiled or interpreted, I suspect various strategies
> may make one be acted on a bit differently. Does the hardware for addition
> work differently than for subtraction? Does it implement -x by getting x
> and then in another operation flipping bits to negate it? Or, in some
> cases, if it is recognized you are dealing with very small numbers limited
> to 0 and 1, as can happen if you use a Boolean data type, then operations
> can be avoided entirely or done on single bytes or bits rather than
> full-blown integers and so on.
>
> My previous point was that the solution written as
>
> y<- (-1*x)+1
>
> was a tad too bulky and would have been simpler if there was no use of
> parentheses and no multiplication. Internally -1*x may take more operations
> than -x while your solution may take even less.
>
> Boolean solutions can be more compact as in
>
>  Y <- !X
>
> And, they remove some ambiguities in that many languages allow truth
> values such that 5 is also true and thus the formula fails if it sees a 5
> and changes it to another TRUE value like 4. When there is no reason not
> to, using a Boolean data type is often best for some uses.
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Mike Day via
> R-help
> Sent: Thursday, May 29, 2025 3:45 AM
> To: R help Mailing list <r-help at r-project.org>
> Subject: Re: [R] Looking for a function or a set of steps
>
> What's wrong with
>    1-x
> ?
>
> Sent from my iPad
>
> > On 28 May 2025, at 21:41, Avi Gross <avi.e.gross at gmail.com> wrote:
> >
> > ?Paul,
> >
> > Perhaps slightly better and more concise is
> >
> > y <- -x + 1
> >
> > Why multiply? Of course it may be optimized in some cases.
> >
> >> On Tue, May 27, 2025, 3:36?AM Paul Zachos <paz at acase.org> wrote:
> >>
> >> Wow! Amazing stuff.
> >> It will take me a while to digest all that you have offered here.
> >>
> >> I came up with a simple solution myself:
> >> y<- (-1*x)+1
> >>
> >> Thank you
> >> _________________
> >> Paul Zachos, PhD
> >> Director, Research and Evaluation
> >> Association for the Cooperative Advancement of Science and Education
> >> (ACASE)
> >> 110 Spring Street  Saratoga Springs, NY 12866  |
> >> paz at acase.org  |  www.acase.org
> >>
> >>
> >>
> >>
> >>>> On May 19, 2025, at 3:08?AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >>>
> >>> ?s 18:40 de 18/05/2025, paul zachos via R-help escreveu:
> >>>> Dear R Community
> >>>> I am an R beginner
> >>>> I have a vector of ?1?s and ?0?s
> >>>> x
> >>>> [1] 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0
> >>>> [28] 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1
> >>>> [55] 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
> >>>> [82] 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1
> >>>> I would like to generate a new vector  in which the ?1?s in x become
> >> ?0?s and the ?0?s in x become ?1?s.
> >>>> How should I go about this?
> >>>> Thank you,
> >>>> paz
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>> Hello,
> >>>
> >>> A simple way is to treat x as logical and negate its values. Then
> coerce
> >> to integer.
> >>>
> >>>
> >>> x <- c(0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
> >>> 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L,
> >>> 1L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
> >>> 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L,
> >>> 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L,
> >>> 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
> >>> 1L)
> >>>
> >>>
> >>> as.integer(!x)
> >>> #>  [1] 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0
> >> 1 0 0 1 1 1
> >>> #> [39] 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1
> >> 1 0 1 1 0 0
> >>> #> [77] 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0
> >>>
> >>>
> >>> Also, the recommended way of posting data is with ?dput:
> >>>
> >>>
> >>> dput(x)
> >>> #> c(0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
> >>> #> 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L,
> >>> #> 1L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
> >>> #> 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L,
> >>> #> 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L,
> >>> #> 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
> >>> #> 1L)
> >>>
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>>
> >>> --
> >>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >> presen?a de v?rus.
> >>> www.avg.com
> >>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From br|@n@m|th199312 @end|ng |rom gm@||@com  Tue Jun  3 08:59:44 2025
From: br|@n@m|th199312 @end|ng |rom gm@||@com (Brian Smith)
Date: Tue, 3 Jun 2025 12:29:44 +0530
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <FP6Rkh2M9oI16rlxqZPmhK-OcNVzGvk2izj9-EPVlHdeduiLp3FrPVWOH4HwWHuaBinBrQUnnPyhVcfd7fSkuox7bm_SKPGQUXUWuYqKpAk=@loesl.us>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CAGxFJbRVvxYtVgYdV20v6WWdKVznJSMWLYpcpnrTcOm_HJHOBw@mail.gmail.com>
 <FE93t9pXxzBpMFMKdRtIhqY3gIx7eBYczmY3S_p1MCMbsbvSdU9dp4zkIEOZOL3lDW0Fh4S76jW5P3kbUv85XM_cTFpsTE2K8lEdNMBf_uU=@loesl.us>
 <CAGxFJbTSicAPqZ9EE72rx+7WgaxAOvMr0f29o9e4xfXctLUxdA@mail.gmail.com>
 <FP6Rkh2M9oI16rlxqZPmhK-OcNVzGvk2izj9-EPVlHdeduiLp3FrPVWOH4HwWHuaBinBrQUnnPyhVcfd7fSkuox7bm_SKPGQUXUWuYqKpAk=@loesl.us>
Message-ID: <CAHUBDY96ADJH=JMCcNL_Q+7oPCFhLqS5ZP31i=5Z3S7Q5uH6ww@mail.gmail.com>

Hi JRG,

It is not a homwork, but a practical problem. I was unsure about the
theritical framework to generate such sequence.

I introduced the condition that accuracy up to second decimal number,
so that we would get a finite number of possible values. Otherwise I
thought there could be infinite possibilities. Let me know your
opinion if there is any other way to impose finiteness in the possible
numbers of ways to generate such sequence.

Thanks and regards,

On Sun, 1 Jun 2025 at 06:31, JRG <jrg at loesl.us> wrote:
>
>
>
> On Saturday, May 31st, 2025 at 7:44 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> JRG:
>
> I don't think your specification is correct -- perhaps just a thinko. I think a 10-tuple of "reals" (scare quotes because of computer precision) with your specifications is what is wanted.
>
> Bert
>
> "An educated person is one who can entertain new ideas, entertain others, and entertain herself."
>
>
> Well, I had started with 10-tuples of reals.  Forcing integer elements was a feeble attempt to deal with this aspect of the original post:
>
>          ". . .  with accuracy up to second decimal number".
>
> But as this seems to be homework, radio silence ensues.
>
>
> ---JRG
>
>
>
> On Sat, May 31, 2025 at 3:43?PM JRG <jrg at loesl.us> wrote:
>>
>> I'll second Bert's comments, also assuming this is not homework. In addition:
>>
>> Your use of "mid-point" is not a standard one (in my world), nor perhaps is that of "simulate".
>>
>> Let me attempt to re-state your problem: You wish to choose 10-tuples of integers 0 <= k <= 100 satisfying
>>
>> 1) 0 <= k_i <= 100 for i = 1:10;
>> and
>> 2) k_(i+1) - k_(i) >= 5 for i = 1:9.
>>
>> Finally, you'd like 1000 of those 10-tuples.
>> [Here, "k_(i)" is the usual notation for order statistics.]
>>
>> Is that the task?
>>
>> If so, are there are other requirements on the k_i ?
>>
>> The word "simulate" suggests the k_i are supposed to be realizations of random variables. If so, what sort of distributional assumptions did you have in mind?
>>
>>
>> ---JRG
>>
>>
>>
>> On Saturday, May 31st, 2025 at 6:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> >
>> >
>> > If this is a real problem and not homework, can you tell us the
>> > context? It is not at all clear (to me) what you mean by "simulate",
>> > i.e. what your target distribution is, which may depend on/be defined
>> > by the context.
>> >
>> > Bert
>> >
>> > "An educated person is one who can entertain new ideas, entertain
>> > others, and entertain herself."
>> >
>> >
>> > On Sat, May 31, 2025 at 11:52?AM Brian Smith briansmith199312 at gmail.com wrote:
>> >
>> > > Hi,
>> > >
>> > > Let say I have a range [0, 100]
>> > >
>> > > Now I need to simulate 1000 10 mid-points within the range with
>> > > accuracy upto second decimal number.
>> > >
>> > > Let say, one simulated set is
>> > >
>> > > X1, X2, ..., X10
>> > >
>> > > Ofcourrse
>> > >
>> > > X1 < X2 < ... <X10
>> > >
>> > > I have one more constraint that the difference between any 2
>> > > consecutive mid-points shall be at-least 5.00.
>> > >
>> > > I wonder if there is any Statistical theory available to support this
>> > > kind of simulation.
>> > >
>> > > Alternately, is there any way in R to implement this?
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From br|@n@m|th199312 @end|ng |rom gm@||@com  Tue Jun  3 09:21:11 2025
From: br|@n@m|th199312 @end|ng |rom gm@||@com (Brian Smith)
Date: Tue, 3 Jun 2025 12:51:11 +0530
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
Message-ID: <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>

Hi Richard,

Thanks for your insight.

As I mentioned in one of my earlier emails to the group, I imposed a
constraint of accuracy up to two decimal places in order to obtain a
finite set of possible values. For instance, if I were to round values
to zero decimal places, the number of unique sequences that could be
generated would be strictly finite and quite limited. Therefore, I
chose a precision of two decimal places to allow for a larger but
still finite number of possibilities.


Now, my question is: how can this accuracy constraint be imposed effectively?

Is the only practical method to generate samples, round each to two
decimal places, and then check for duplicates to ensure uniqueness? If
so, I?m concerned this might be inefficient, as many samples could be
discarded, making the process time-consuming.

Is there a better or more efficient way to directly enforce this
constraint while generating the values?

________________________________

Additionally, could you please elaborate on your suggestion regarding
imposing minimum gap constraints by subtracting and then adding back
certain gaps?


For example, based on your earlier guidance, one possible sequence I
obtained is:


10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
68.62261, 92.49899, 98.29308


Now, I?d like to post-process this sequence to enforce a minimum
difference constraint of, say, 5 units between values (including both
lower and upper bounds).

What would be the appropriate way to modify the sequence to impose
this kind of constraint?


Many thanks for your time and insight.

On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
>
> PS I forgot about the weird gaps requirement.
> What you do is subtract the gaps off and then add them back.  I hope that is clear.
>
> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com> wrote:
>>
>> Hi,
>>
>> Let say I have a range [0, 100]
>>
>> Now I need to simulate 1000 10 mid-points within the range with
>> accuracy upto second decimal number.
>>
>> Let say, one simulated set is
>>
>> X1, X2, ..., X10
>>
>> Ofcourrse
>>
>> X1 < X2 < ... <X10
>>
>> I have one more constraint that the difference between any 2
>> consecutive mid-points shall be at-least 5.00.
>>
>> I wonder if there is any Statistical theory available to support this
>> kind of simulation.
>>
>> Alternately, is there any way in R to implement this?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Tue Jun  3 23:15:28 2025
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 3 Jun 2025 23:15:28 +0200
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
Message-ID: <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>

Can't you just generate 10 values in (0,55), sort them, generate the distances, add 5 and cumulate? 

> x <- sort(runif(10,0,55))
> d <- diff(x)+5
> cumsum(c(x[1],d))
 [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
 [8] 75.74085 81.28533 98.30792


> On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com> wrote:
> 
> Hi Richard,
> 
> Thanks for your insight.
> 
> As I mentioned in one of my earlier emails to the group, I imposed a
> constraint of accuracy up to two decimal places in order to obtain a
> finite set of possible values. For instance, if I were to round values
> to zero decimal places, the number of unique sequences that could be
> generated would be strictly finite and quite limited. Therefore, I
> chose a precision of two decimal places to allow for a larger but
> still finite number of possibilities.
> 
> 
> Now, my question is: how can this accuracy constraint be imposed effectively?
> 
> Is the only practical method to generate samples, round each to two
> decimal places, and then check for duplicates to ensure uniqueness? If
> so, I?m concerned this might be inefficient, as many samples could be
> discarded, making the process time-consuming.
> 
> Is there a better or more efficient way to directly enforce this
> constraint while generating the values?
> 
> ________________________________
> 
> Additionally, could you please elaborate on your suggestion regarding
> imposing minimum gap constraints by subtracting and then adding back
> certain gaps?
> 
> 
> For example, based on your earlier guidance, one possible sequence I
> obtained is:
> 
> 
> 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
> 68.62261, 92.49899, 98.29308
> 
> 
> Now, I?d like to post-process this sequence to enforce a minimum
> difference constraint of, say, 5 units between values (including both
> lower and upper bounds).
> 
> What would be the appropriate way to modify the sequence to impose
> this kind of constraint?
> 
> 
> Many thanks for your time and insight.
> 
> On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
>> 
>> PS I forgot about the weird gaps requirement.
>> What you do is subtract the gaps off and then add them back.  I hope that is clear.
>> 
>> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com> wrote:
>>> 
>>> Hi,
>>> 
>>> Let say I have a range [0, 100]
>>> 
>>> Now I need to simulate 1000 10 mid-points within the range with
>>> accuracy upto second decimal number.
>>> 
>>> Let say, one simulated set is
>>> 
>>> X1, X2, ..., X10
>>> 
>>> Ofcourrse
>>> 
>>> X1 < X2 < ... <X10
>>> 
>>> I have one more constraint that the difference between any 2
>>> consecutive mid-points shall be at-least 5.00.
>>> 
>>> I wonder if there is any Statistical theory available to support this
>>> kind of simulation.
>>> 
>>> Alternately, is there any way in R to implement this?
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  4 13:43:39 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 4 Jun 2025 04:43:39 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
Message-ID: <CAGxFJbRL3G+qQAVKcObmiQS7fvnVhYDZF5CAbX_i1GwCe1tLCg@mail.gmail.com>

Is Peter's solution different then:

diffs <- cumsum(runif(9, 5, 100/9))
x <-runif(1,0,100-diffs[9])
c(x, x+diffs)

I ask because:
1. If yes, this is why more context is needed;
2. If no, the above avoids a sort.

Cheers,
Bert




On Tue, Jun 3, 2025 at 2:15?PM peter dalgaard <pdalgd at gmail.com> wrote:

> Can't you just generate 10 values in (0,55), sort them, generate the
> distances, add 5 and cumulate?
>
> > x <- sort(runif(10,0,55))
> > d <- diff(x)+5
> > cumsum(c(x[1],d))
>  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
>  [8] 75.74085 81.28533 98.30792
>
>
> > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com> wrote:
> >
> > Hi Richard,
> >
> > Thanks for your insight.
> >
> > As I mentioned in one of my earlier emails to the group, I imposed a
> > constraint of accuracy up to two decimal places in order to obtain a
> > finite set of possible values. For instance, if I were to round values
> > to zero decimal places, the number of unique sequences that could be
> > generated would be strictly finite and quite limited. Therefore, I
> > chose a precision of two decimal places to allow for a larger but
> > still finite number of possibilities.
> >
> >
> > Now, my question is: how can this accuracy constraint be imposed
> effectively?
> >
> > Is the only practical method to generate samples, round each to two
> > decimal places, and then check for duplicates to ensure uniqueness? If
> > so, I?m concerned this might be inefficient, as many samples could be
> > discarded, making the process time-consuming.
> >
> > Is there a better or more efficient way to directly enforce this
> > constraint while generating the values?
> >
> > ________________________________
> >
> > Additionally, could you please elaborate on your suggestion regarding
> > imposing minimum gap constraints by subtracting and then adding back
> > certain gaps?
> >
> >
> > For example, based on your earlier guidance, one possible sequence I
> > obtained is:
> >
> >
> > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
> > 68.62261, 92.49899, 98.29308
> >
> >
> > Now, I?d like to post-process this sequence to enforce a minimum
> > difference constraint of, say, 5 units between values (including both
> > lower and upper bounds).
> >
> > What would be the appropriate way to modify the sequence to impose
> > this kind of constraint?
> >
> >
> > Many thanks for your time and insight.
> >
> > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
> >>
> >> PS I forgot about the weird gaps requirement.
> >> What you do is subtract the gaps off and then add them back.  I hope
> that is clear.
> >>
> >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com>
> wrote:
> >>>
> >>> Hi,
> >>>
> >>> Let say I have a range [0, 100]
> >>>
> >>> Now I need to simulate 1000 10 mid-points within the range with
> >>> accuracy upto second decimal number.
> >>>
> >>> Let say, one simulated set is
> >>>
> >>> X1, X2, ..., X10
> >>>
> >>> Ofcourrse
> >>>
> >>> X1 < X2 < ... <X10
> >>>
> >>> I have one more constraint that the difference between any 2
> >>> consecutive mid-points shall be at-least 5.00.
> >>>
> >>> I wonder if there is any Statistical theory available to support this
> >>> kind of simulation.
> >>>
> >>> Alternately, is there any way in R to implement this?
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000
> Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From br|@n@m|th199312 @end|ng |rom gm@||@com  Wed Jun  4 14:23:34 2025
From: br|@n@m|th199312 @end|ng |rom gm@||@com (Brian Smith)
Date: Wed, 4 Jun 2025 17:53:34 +0530
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAGxFJbRL3G+qQAVKcObmiQS7fvnVhYDZF5CAbX_i1GwCe1tLCg@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAGxFJbRL3G+qQAVKcObmiQS7fvnVhYDZF5CAbX_i1GwCe1tLCg@mail.gmail.com>
Message-ID: <CAHUBDY_mFWAQx++boT4h56pWo0X7+uxx2f4Z89==8Jx8G3zZKw@mail.gmail.com>

Hi,

I dont see from the solution pov they are different.

One followup Q though, how can I extend this to draw only integer
mid-point between 0-100 while maintaining minimum difference as 5?

Also, are all generated points are equally likely?

Thanks for your time and suggestions.

Thanks and regards,

On Wed, 4 Jun 2025 at 17:13, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Is Peter's solution different then:
>
> diffs <- cumsum(runif(9, 5, 100/9))
> x <-runif(1,0,100-diffs[9])
> c(x, x+diffs)
>
> I ask because:
> 1. If yes, this is why more context is needed;
> 2. If no, the above avoids a sort.
>
> Cheers,
> Bert
>
>
>
>
> On Tue, Jun 3, 2025 at 2:15?PM peter dalgaard <pdalgd at gmail.com> wrote:
>>
>> Can't you just generate 10 values in (0,55), sort them, generate the distances, add 5 and cumulate?
>>
>> > x <- sort(runif(10,0,55))
>> > d <- diff(x)+5
>> > cumsum(c(x[1],d))
>>  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
>>  [8] 75.74085 81.28533 98.30792
>>
>>
>> > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com> wrote:
>> >
>> > Hi Richard,
>> >
>> > Thanks for your insight.
>> >
>> > As I mentioned in one of my earlier emails to the group, I imposed a
>> > constraint of accuracy up to two decimal places in order to obtain a
>> > finite set of possible values. For instance, if I were to round values
>> > to zero decimal places, the number of unique sequences that could be
>> > generated would be strictly finite and quite limited. Therefore, I
>> > chose a precision of two decimal places to allow for a larger but
>> > still finite number of possibilities.
>> >
>> >
>> > Now, my question is: how can this accuracy constraint be imposed effectively?
>> >
>> > Is the only practical method to generate samples, round each to two
>> > decimal places, and then check for duplicates to ensure uniqueness? If
>> > so, I?m concerned this might be inefficient, as many samples could be
>> > discarded, making the process time-consuming.
>> >
>> > Is there a better or more efficient way to directly enforce this
>> > constraint while generating the values?
>> >
>> > ________________________________
>> >
>> > Additionally, could you please elaborate on your suggestion regarding
>> > imposing minimum gap constraints by subtracting and then adding back
>> > certain gaps?
>> >
>> >
>> > For example, based on your earlier guidance, one possible sequence I
>> > obtained is:
>> >
>> >
>> > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
>> > 68.62261, 92.49899, 98.29308
>> >
>> >
>> > Now, I?d like to post-process this sequence to enforce a minimum
>> > difference constraint of, say, 5 units between values (including both
>> > lower and upper bounds).
>> >
>> > What would be the appropriate way to modify the sequence to impose
>> > this kind of constraint?
>> >
>> >
>> > Many thanks for your time and insight.
>> >
>> > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
>> >>
>> >> PS I forgot about the weird gaps requirement.
>> >> What you do is subtract the gaps off and then add them back.  I hope that is clear.
>> >>
>> >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com> wrote:
>> >>>
>> >>> Hi,
>> >>>
>> >>> Let say I have a range [0, 100]
>> >>>
>> >>> Now I need to simulate 1000 10 mid-points within the range with
>> >>> accuracy upto second decimal number.
>> >>>
>> >>> Let say, one simulated set is
>> >>>
>> >>> X1, X2, ..., X10
>> >>>
>> >>> Ofcourrse
>> >>>
>> >>> X1 < X2 < ... <X10
>> >>>
>> >>> I have one more constraint that the difference between any 2
>> >>> consecutive mid-points shall be at-least 5.00.
>> >>>
>> >>> I wonder if there is any Statistical theory available to support this
>> >>> kind of simulation.
>> >>>
>> >>> Alternately, is there any way in R to implement this?
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From br|@n@m|th199312 @end|ng |rom gm@||@com  Wed Jun  4 14:24:51 2025
From: br|@n@m|th199312 @end|ng |rom gm@||@com (Brian Smith)
Date: Wed, 4 Jun 2025 17:54:51 +0530
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
Message-ID: <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>

Hi Peter,

Could you please help me to understand what is the basis of choosing
55 in runif(10,0,55))?

Thank you!

On Wed, 4 Jun 2025 at 02:45, peter dalgaard <pdalgd at gmail.com> wrote:
>
> Can't you just generate 10 values in (0,55), sort them, generate the distances, add 5 and cumulate?
>
> > x <- sort(runif(10,0,55))
> > d <- diff(x)+5
> > cumsum(c(x[1],d))
>  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
>  [8] 75.74085 81.28533 98.30792
>
>
> > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com> wrote:
> >
> > Hi Richard,
> >
> > Thanks for your insight.
> >
> > As I mentioned in one of my earlier emails to the group, I imposed a
> > constraint of accuracy up to two decimal places in order to obtain a
> > finite set of possible values. For instance, if I were to round values
> > to zero decimal places, the number of unique sequences that could be
> > generated would be strictly finite and quite limited. Therefore, I
> > chose a precision of two decimal places to allow for a larger but
> > still finite number of possibilities.
> >
> >
> > Now, my question is: how can this accuracy constraint be imposed effectively?
> >
> > Is the only practical method to generate samples, round each to two
> > decimal places, and then check for duplicates to ensure uniqueness? If
> > so, I?m concerned this might be inefficient, as many samples could be
> > discarded, making the process time-consuming.
> >
> > Is there a better or more efficient way to directly enforce this
> > constraint while generating the values?
> >
> > ________________________________
> >
> > Additionally, could you please elaborate on your suggestion regarding
> > imposing minimum gap constraints by subtracting and then adding back
> > certain gaps?
> >
> >
> > For example, based on your earlier guidance, one possible sequence I
> > obtained is:
> >
> >
> > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
> > 68.62261, 92.49899, 98.29308
> >
> >
> > Now, I?d like to post-process this sequence to enforce a minimum
> > difference constraint of, say, 5 units between values (including both
> > lower and upper bounds).
> >
> > What would be the appropriate way to modify the sequence to impose
> > this kind of constraint?
> >
> >
> > Many thanks for your time and insight.
> >
> > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
> >>
> >> PS I forgot about the weird gaps requirement.
> >> What you do is subtract the gaps off and then add them back.  I hope that is clear.
> >>
> >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com> wrote:
> >>>
> >>> Hi,
> >>>
> >>> Let say I have a range [0, 100]
> >>>
> >>> Now I need to simulate 1000 10 mid-points within the range with
> >>> accuracy upto second decimal number.
> >>>
> >>> Let say, one simulated set is
> >>>
> >>> X1, X2, ..., X10
> >>>
> >>> Ofcourrse
> >>>
> >>> X1 < X2 < ... <X10
> >>>
> >>> I have one more constraint that the difference between any 2
> >>> consecutive mid-points shall be at-least 5.00.
> >>>
> >>> I wonder if there is any Statistical theory available to support this
> >>> kind of simulation.
> >>>
> >>> Alternately, is there any way in R to implement this?
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>


From br|@n@m|th199312 @end|ng |rom gm@||@com  Wed Jun  4 14:56:26 2025
From: br|@n@m|th199312 @end|ng |rom gm@||@com (Brian Smith)
Date: Wed, 4 Jun 2025 18:26:26 +0530
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>
Message-ID: <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>

Okay, I think I found the reason. This is due to accumulation of nine
5s in the cumsum. Thanks again for the elegant solution.

But I wonder, if the solution is simple then what is the significance
of the Research paper by Bentley and Saxe naming ?Generating sorted
lists of random numbers? which Richard mentioned?

On Wed, 4 Jun 2025 at 17:54, Brian Smith <briansmith199312 at gmail.com> wrote:
>
> Hi Peter,
>
> Could you please help me to understand what is the basis of choosing
> 55 in runif(10,0,55))?
>
> Thank you!
>
> On Wed, 4 Jun 2025 at 02:45, peter dalgaard <pdalgd at gmail.com> wrote:
> >
> > Can't you just generate 10 values in (0,55), sort them, generate the distances, add 5 and cumulate?
> >
> > > x <- sort(runif(10,0,55))
> > > d <- diff(x)+5
> > > cumsum(c(x[1],d))
> >  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
> >  [8] 75.74085 81.28533 98.30792
> >
> >
> > > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com> wrote:
> > >
> > > Hi Richard,
> > >
> > > Thanks for your insight.
> > >
> > > As I mentioned in one of my earlier emails to the group, I imposed a
> > > constraint of accuracy up to two decimal places in order to obtain a
> > > finite set of possible values. For instance, if I were to round values
> > > to zero decimal places, the number of unique sequences that could be
> > > generated would be strictly finite and quite limited. Therefore, I
> > > chose a precision of two decimal places to allow for a larger but
> > > still finite number of possibilities.
> > >
> > >
> > > Now, my question is: how can this accuracy constraint be imposed effectively?
> > >
> > > Is the only practical method to generate samples, round each to two
> > > decimal places, and then check for duplicates to ensure uniqueness? If
> > > so, I?m concerned this might be inefficient, as many samples could be
> > > discarded, making the process time-consuming.
> > >
> > > Is there a better or more efficient way to directly enforce this
> > > constraint while generating the values?
> > >
> > > ________________________________
> > >
> > > Additionally, could you please elaborate on your suggestion regarding
> > > imposing minimum gap constraints by subtracting and then adding back
> > > certain gaps?
> > >
> > >
> > > For example, based on your earlier guidance, one possible sequence I
> > > obtained is:
> > >
> > >
> > > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
> > > 68.62261, 92.49899, 98.29308
> > >
> > >
> > > Now, I?d like to post-process this sequence to enforce a minimum
> > > difference constraint of, say, 5 units between values (including both
> > > lower and upper bounds).
> > >
> > > What would be the appropriate way to modify the sequence to impose
> > > this kind of constraint?
> > >
> > >
> > > Many thanks for your time and insight.
> > >
> > > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
> > >>
> > >> PS I forgot about the weird gaps requirement.
> > >> What you do is subtract the gaps off and then add them back.  I hope that is clear.
> > >>
> > >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com> wrote:
> > >>>
> > >>> Hi,
> > >>>
> > >>> Let say I have a range [0, 100]
> > >>>
> > >>> Now I need to simulate 1000 10 mid-points within the range with
> > >>> accuracy upto second decimal number.
> > >>>
> > >>> Let say, one simulated set is
> > >>>
> > >>> X1, X2, ..., X10
> > >>>
> > >>> Ofcourrse
> > >>>
> > >>> X1 < X2 < ... <X10
> > >>>
> > >>> I have one more constraint that the difference between any 2
> > >>> consecutive mid-points shall be at-least 5.00.
> > >>>
> > >>> I wonder if there is any Statistical theory available to support this
> > >>> kind of simulation.
> > >>>
> > >>> Alternately, is there any way in R to implement this?
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >


From @ggp@@erge| @end|ng |rom gm@||@com  Wed Jun  4 15:02:59 2025
From: @ggp@@erge| @end|ng |rom gm@||@com (Sergei Ko)
Date: Wed, 4 Jun 2025 14:02:59 +0100
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>
 <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>
Message-ID: <CAK2fHGdfJtH0RYH6ww3B4uP4L2j4TesyqLCHH7_VAx7Hagkpaw@mail.gmail.com>

Hi!
It's possible I'm wrong. But for me it looks like:
n_sample <- 3000000
v <- round(runif(n_sample, 0, 100), 2)
m <- matrix(v, ncol = 10)
m_s <- t(apply(m, 1, sort))
m_d <- t(apply(m_s, 1, diff))
m_5 <- m_d>=5
f <- rowSums(m_5) == 9
sum(f)
res <- m_s[f, ]
Regards,
Sergiy

On Wed, Jun 4, 2025 at 1:56?PM Brian Smith <briansmith199312 at gmail.com>
wrote:

> Okay, I think I found the reason. This is due to accumulation of nine
> 5s in the cumsum. Thanks again for the elegant solution.
>
> But I wonder, if the solution is simple then what is the significance
> of the Research paper by Bentley and Saxe naming ?Generating sorted
> lists of random numbers? which Richard mentioned?
>
> On Wed, 4 Jun 2025 at 17:54, Brian Smith <briansmith199312 at gmail.com>
> wrote:
> >
> > Hi Peter,
> >
> > Could you please help me to understand what is the basis of choosing
> > 55 in runif(10,0,55))?
> >
> > Thank you!
> >
> > On Wed, 4 Jun 2025 at 02:45, peter dalgaard <pdalgd at gmail.com> wrote:
> > >
> > > Can't you just generate 10 values in (0,55), sort them, generate the
> distances, add 5 and cumulate?
> > >
> > > > x <- sort(runif(10,0,55))
> > > > d <- diff(x)+5
> > > > cumsum(c(x[1],d))
> > >  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
> > >  [8] 75.74085 81.28533 98.30792
> > >
> > >
> > > > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com>
> wrote:
> > > >
> > > > Hi Richard,
> > > >
> > > > Thanks for your insight.
> > > >
> > > > As I mentioned in one of my earlier emails to the group, I imposed a
> > > > constraint of accuracy up to two decimal places in order to obtain a
> > > > finite set of possible values. For instance, if I were to round
> values
> > > > to zero decimal places, the number of unique sequences that could be
> > > > generated would be strictly finite and quite limited. Therefore, I
> > > > chose a precision of two decimal places to allow for a larger but
> > > > still finite number of possibilities.
> > > >
> > > >
> > > > Now, my question is: how can this accuracy constraint be imposed
> effectively?
> > > >
> > > > Is the only practical method to generate samples, round each to two
> > > > decimal places, and then check for duplicates to ensure uniqueness?
> If
> > > > so, I?m concerned this might be inefficient, as many samples could be
> > > > discarded, making the process time-consuming.
> > > >
> > > > Is there a better or more efficient way to directly enforce this
> > > > constraint while generating the values?
> > > >
> > > > ________________________________
> > > >
> > > > Additionally, could you please elaborate on your suggestion regarding
> > > > imposing minimum gap constraints by subtracting and then adding back
> > > > certain gaps?
> > > >
> > > >
> > > > For example, based on your earlier guidance, one possible sequence I
> > > > obtained is:
> > > >
> > > >
> > > > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
> > > > 68.62261, 92.49899, 98.29308
> > > >
> > > >
> > > > Now, I?d like to post-process this sequence to enforce a minimum
> > > > difference constraint of, say, 5 units between values (including both
> > > > lower and upper bounds).
> > > >
> > > > What would be the appropriate way to modify the sequence to impose
> > > > this kind of constraint?
> > > >
> > > >
> > > > Many thanks for your time and insight.
> > > >
> > > > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com>
> wrote:
> > > >>
> > > >> PS I forgot about the weird gaps requirement.
> > > >> What you do is subtract the gaps off and then add them back.  I
> hope that is clear.
> > > >>
> > > >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <
> briansmith199312 at gmail.com> wrote:
> > > >>>
> > > >>> Hi,
> > > >>>
> > > >>> Let say I have a range [0, 100]
> > > >>>
> > > >>> Now I need to simulate 1000 10 mid-points within the range with
> > > >>> accuracy upto second decimal number.
> > > >>>
> > > >>> Let say, one simulated set is
> > > >>>
> > > >>> X1, X2, ..., X10
> > > >>>
> > > >>> Ofcourrse
> > > >>>
> > > >>> X1 < X2 < ... <X10
> > > >>>
> > > >>> I have one more constraint that the difference between any 2
> > > >>> consecutive mid-points shall be at-least 5.00.
> > > >>>
> > > >>> I wonder if there is any Statistical theory available to support
> this
> > > >>> kind of simulation.
> > > >>>
> > > >>> Alternately, is there any way in R to implement this?
> > > >>>
> > > >>> ______________________________________________
> > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Peter Dalgaard, Professor,
> > > Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3,
> 2000 Frederiksberg, Denmark
> > > Phone: (+45)38153501
> > > Office: A 4.23
> > > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  4 15:38:34 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 4 Jun 2025 06:38:34 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAGxFJbRL3G+qQAVKcObmiQS7fvnVhYDZF5CAbX_i1GwCe1tLCg@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAGxFJbRL3G+qQAVKcObmiQS7fvnVhYDZF5CAbX_i1GwCe1tLCg@mail.gmail.com>
Message-ID: <CAGxFJbTTXxvStEV_b1_axXaAuQzxBYJUVcQV2ruvSFn-zPMKkw@mail.gmail.com>

To answer my own question, yes they are different.

Peter's code can generate the solution 1 20 26 32 38 44 50 56 62 68. Mine
cannot.

So, again, context?

-- Bert

On Wed, Jun 4, 2025 at 4:43?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Is Peter's solution different then:
>
> diffs <- cumsum(runif(9, 5, 100/9))
> x <-runif(1,0,100-diffs[9])
> c(x, x+diffs)
>
> I ask because:
> 1. If yes, this is why more context is needed;
> 2. If no, the above avoids a sort.
>
> Cheers,
> Bert
>
>
>
>
> On Tue, Jun 3, 2025 at 2:15?PM peter dalgaard <pdalgd at gmail.com> wrote:
>
>> Can't you just generate 10 values in (0,55), sort them, generate the
>> distances, add 5 and cumulate?
>>
>> > x <- sort(runif(10,0,55))
>> > d <- diff(x)+5
>> > cumsum(c(x[1],d))
>>  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
>>  [8] 75.74085 81.28533 98.30792
>>
>>
>> > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com>
>> wrote:
>> >
>> > Hi Richard,
>> >
>> > Thanks for your insight.
>> >
>> > As I mentioned in one of my earlier emails to the group, I imposed a
>> > constraint of accuracy up to two decimal places in order to obtain a
>> > finite set of possible values. For instance, if I were to round values
>> > to zero decimal places, the number of unique sequences that could be
>> > generated would be strictly finite and quite limited. Therefore, I
>> > chose a precision of two decimal places to allow for a larger but
>> > still finite number of possibilities.
>> >
>> >
>> > Now, my question is: how can this accuracy constraint be imposed
>> effectively?
>> >
>> > Is the only practical method to generate samples, round each to two
>> > decimal places, and then check for duplicates to ensure uniqueness? If
>> > so, I?m concerned this might be inefficient, as many samples could be
>> > discarded, making the process time-consuming.
>> >
>> > Is there a better or more efficient way to directly enforce this
>> > constraint while generating the values?
>> >
>> > ________________________________
>> >
>> > Additionally, could you please elaborate on your suggestion regarding
>> > imposing minimum gap constraints by subtracting and then adding back
>> > certain gaps?
>> >
>> >
>> > For example, based on your earlier guidance, one possible sequence I
>> > obtained is:
>> >
>> >
>> > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
>> > 68.62261, 92.49899, 98.29308
>> >
>> >
>> > Now, I?d like to post-process this sequence to enforce a minimum
>> > difference constraint of, say, 5 units between values (including both
>> > lower and upper bounds).
>> >
>> > What would be the appropriate way to modify the sequence to impose
>> > this kind of constraint?
>> >
>> >
>> > Many thanks for your time and insight.
>> >
>> > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
>> >>
>> >> PS I forgot about the weird gaps requirement.
>> >> What you do is subtract the gaps off and then add them back.  I hope
>> that is clear.
>> >>
>> >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com>
>> wrote:
>> >>>
>> >>> Hi,
>> >>>
>> >>> Let say I have a range [0, 100]
>> >>>
>> >>> Now I need to simulate 1000 10 mid-points within the range with
>> >>> accuracy upto second decimal number.
>> >>>
>> >>> Let say, one simulated set is
>> >>>
>> >>> X1, X2, ..., X10
>> >>>
>> >>> Ofcourrse
>> >>>
>> >>> X1 < X2 < ... <X10
>> >>>
>> >>> I have one more constraint that the difference between any 2
>> >>> consecutive mid-points shall be at-least 5.00.
>> >>>
>> >>> I wonder if there is any Statistical theory available to support this
>> >>> kind of simulation.
>> >>>
>> >>> Alternately, is there any way in R to implement this?
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000
>> Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  4 16:03:34 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 4 Jun 2025 07:03:34 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAHUBDY_mFWAQx++boT4h56pWo0X7+uxx2f4Z89==8Jx8G3zZKw@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAGxFJbRL3G+qQAVKcObmiQS7fvnVhYDZF5CAbX_i1GwCe1tLCg@mail.gmail.com>
 <CAHUBDY_mFWAQx++boT4h56pWo0X7+uxx2f4Z89==8Jx8G3zZKw@mail.gmail.com>
Message-ID: <CAGxFJbRPGsgo4a1pdR2CdVyDqSHj8-Ckuc5Xv=vbbL3dobqSLQ@mail.gmail.com>

In Peter's solution, just sample without replacement from integers instead
of generating random uniforms. See ?sample.

-- Bert


On Wed, Jun 4, 2025 at 5:23?AM Brian Smith <briansmith199312 at gmail.com>
wrote:

> Hi,
>
> I dont see from the solution pov they are different.
>
> One followup Q though, how can I extend this to draw only integer
> mid-point between 0-100 while maintaining minimum difference as 5?
>
> Also, are all generated points are equally likely?
>
> Thanks for your time and suggestions.
>
> Thanks and regards,
>
> On Wed, 4 Jun 2025 at 17:13, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Is Peter's solution different then:
> >
> > diffs <- cumsum(runif(9, 5, 100/9))
> > x <-runif(1,0,100-diffs[9])
> > c(x, x+diffs)
> >
> > I ask because:
> > 1. If yes, this is why more context is needed;
> > 2. If no, the above avoids a sort.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> > On Tue, Jun 3, 2025 at 2:15?PM peter dalgaard <pdalgd at gmail.com> wrote:
> >>
> >> Can't you just generate 10 values in (0,55), sort them, generate the
> distances, add 5 and cumulate?
> >>
> >> > x <- sort(runif(10,0,55))
> >> > d <- diff(x)+5
> >> > cumsum(c(x[1],d))
> >>  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
> >>  [8] 75.74085 81.28533 98.30792
> >>
> >>
> >> > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com>
> wrote:
> >> >
> >> > Hi Richard,
> >> >
> >> > Thanks for your insight.
> >> >
> >> > As I mentioned in one of my earlier emails to the group, I imposed a
> >> > constraint of accuracy up to two decimal places in order to obtain a
> >> > finite set of possible values. For instance, if I were to round values
> >> > to zero decimal places, the number of unique sequences that could be
> >> > generated would be strictly finite and quite limited. Therefore, I
> >> > chose a precision of two decimal places to allow for a larger but
> >> > still finite number of possibilities.
> >> >
> >> >
> >> > Now, my question is: how can this accuracy constraint be imposed
> effectively?
> >> >
> >> > Is the only practical method to generate samples, round each to two
> >> > decimal places, and then check for duplicates to ensure uniqueness? If
> >> > so, I?m concerned this might be inefficient, as many samples could be
> >> > discarded, making the process time-consuming.
> >> >
> >> > Is there a better or more efficient way to directly enforce this
> >> > constraint while generating the values?
> >> >
> >> > ________________________________
> >> >
> >> > Additionally, could you please elaborate on your suggestion regarding
> >> > imposing minimum gap constraints by subtracting and then adding back
> >> > certain gaps?
> >> >
> >> >
> >> > For example, based on your earlier guidance, one possible sequence I
> >> > obtained is:
> >> >
> >> >
> >> > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
> >> > 68.62261, 92.49899, 98.29308
> >> >
> >> >
> >> > Now, I?d like to post-process this sequence to enforce a minimum
> >> > difference constraint of, say, 5 units between values (including both
> >> > lower and upper bounds).
> >> >
> >> > What would be the appropriate way to modify the sequence to impose
> >> > this kind of constraint?
> >> >
> >> >
> >> > Many thanks for your time and insight.
> >> >
> >> > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com>
> wrote:
> >> >>
> >> >> PS I forgot about the weird gaps requirement.
> >> >> What you do is subtract the gaps off and then add them back.  I hope
> that is clear.
> >> >>
> >> >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <
> briansmith199312 at gmail.com> wrote:
> >> >>>
> >> >>> Hi,
> >> >>>
> >> >>> Let say I have a range [0, 100]
> >> >>>
> >> >>> Now I need to simulate 1000 10 mid-points within the range with
> >> >>> accuracy upto second decimal number.
> >> >>>
> >> >>> Let say, one simulated set is
> >> >>>
> >> >>> X1, X2, ..., X10
> >> >>>
> >> >>> Ofcourrse
> >> >>>
> >> >>> X1 < X2 < ... <X10
> >> >>>
> >> >>> I have one more constraint that the difference between any 2
> >> >>> consecutive mid-points shall be at-least 5.00.
> >> >>>
> >> >>> I wonder if there is any Statistical theory available to support
> this
> >> >>> kind of simulation.
> >> >>>
> >> >>> Alternately, is there any way in R to implement this?
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> >> >>> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Peter Dalgaard, Professor,
> >> Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000
> Frederiksberg, Denmark
> >> Phone: (+45)38153501
> >> Office: A 4.23
> >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Thu Jun  5 08:04:24 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 5 Jun 2025 18:04:24 +1200
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>
 <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>
Message-ID: <CABcYAdJmmAfA33en+PVwKraxOmuhUr89cHjxGgAsbvAfayN2vw@mail.gmail.com>

The Bentley and Saxe paper answers the questions
(1) How can I draw a sample of n numbers in the range 0..1 such that
the numbers are returned in increasing order WITHOUT sorting and so
that all such sequences are equally likely in LINEAR time.  That's the
code I showed in R.
(2) How can I do this in a single pass?
(3) How can I return the elements one at a time, generating each one
on demand (O(1) space).

The cumsum(runif(n))/n trick gets a sequence in linear time but the
distribution is different.
The sort(runif(n)) trick gets a sequence in O(n.log n) time but the
distribution is different again.

The "use an upper bound of 100 - (n+1)*5" and then "add back
cumsum(rep(5,n)) at the end" (or equivalent) trick ensures the gaps
are right but does nothing about the distribution..

By the way, since you want numbers with 2 decimal places for some
reason I don't understand,
perhaps the simplest trick of all is

   n <- 10 # how many numbers you want
   L <- 0 # lower bound of the range
   U <- 100 # upper bound of the range
   G <- 5 # gap size
   V <- U - G*(n+1) # reduced upper bound
   x <- sort(sample((L*100):(V*100), size = n)) + cumsum(rep(G, times=n))/100

I hope this is clear.



On Thu, 5 Jun 2025 at 00:56, Brian Smith <briansmith199312 at gmail.com> wrote:
>
> Okay, I think I found the reason. This is due to accumulation of nine
> 5s in the cumsum. Thanks again for the elegant solution.
>
> But I wonder, if the solution is simple then what is the significance
> of the Research paper by Bentley and Saxe naming ?Generating sorted
> lists of random numbers? which Richard mentioned?
>
> On Wed, 4 Jun 2025 at 17:54, Brian Smith <briansmith199312 at gmail.com> wrote:
> >
> > Hi Peter,
> >
> > Could you please help me to understand what is the basis of choosing
> > 55 in runif(10,0,55))?
> >
> > Thank you!
> >
> > On Wed, 4 Jun 2025 at 02:45, peter dalgaard <pdalgd at gmail.com> wrote:
> > >
> > > Can't you just generate 10 values in (0,55), sort them, generate the distances, add 5 and cumulate?
> > >
> > > > x <- sort(runif(10,0,55))
> > > > d <- diff(x)+5
> > > > cumsum(c(x[1],d))
> > >  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
> > >  [8] 75.74085 81.28533 98.30792
> > >
> > >
> > > > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com> wrote:
> > > >
> > > > Hi Richard,
> > > >
> > > > Thanks for your insight.
> > > >
> > > > As I mentioned in one of my earlier emails to the group, I imposed a
> > > > constraint of accuracy up to two decimal places in order to obtain a
> > > > finite set of possible values. For instance, if I were to round values
> > > > to zero decimal places, the number of unique sequences that could be
> > > > generated would be strictly finite and quite limited. Therefore, I
> > > > chose a precision of two decimal places to allow for a larger but
> > > > still finite number of possibilities.
> > > >
> > > >
> > > > Now, my question is: how can this accuracy constraint be imposed effectively?
> > > >
> > > > Is the only practical method to generate samples, round each to two
> > > > decimal places, and then check for duplicates to ensure uniqueness? If
> > > > so, I?m concerned this might be inefficient, as many samples could be
> > > > discarded, making the process time-consuming.
> > > >
> > > > Is there a better or more efficient way to directly enforce this
> > > > constraint while generating the values?
> > > >
> > > > ________________________________
> > > >
> > > > Additionally, could you please elaborate on your suggestion regarding
> > > > imposing minimum gap constraints by subtracting and then adding back
> > > > certain gaps?
> > > >
> > > >
> > > > For example, based on your earlier guidance, one possible sequence I
> > > > obtained is:
> > > >
> > > >
> > > > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623, 63.40264,
> > > > 68.62261, 92.49899, 98.29308
> > > >
> > > >
> > > > Now, I?d like to post-process this sequence to enforce a minimum
> > > > difference constraint of, say, 5 units between values (including both
> > > > lower and upper bounds).
> > > >
> > > > What would be the appropriate way to modify the sequence to impose
> > > > this kind of constraint?
> > > >
> > > >
> > > > Many thanks for your time and insight.
> > > >
> > > > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com> wrote:
> > > >>
> > > >> PS I forgot about the weird gaps requirement.
> > > >> What you do is subtract the gaps off and then add them back.  I hope that is clear.
> > > >>
> > > >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <briansmith199312 at gmail.com> wrote:
> > > >>>
> > > >>> Hi,
> > > >>>
> > > >>> Let say I have a range [0, 100]
> > > >>>
> > > >>> Now I need to simulate 1000 10 mid-points within the range with
> > > >>> accuracy upto second decimal number.
> > > >>>
> > > >>> Let say, one simulated set is
> > > >>>
> > > >>> X1, X2, ..., X10
> > > >>>
> > > >>> Ofcourrse
> > > >>>
> > > >>> X1 < X2 < ... <X10
> > > >>>
> > > >>> I have one more constraint that the difference between any 2
> > > >>> consecutive mid-points shall be at-least 5.00.
> > > >>>
> > > >>> I wonder if there is any Statistical theory available to support this
> > > >>> kind of simulation.
> > > >>>
> > > >>> Alternately, is there any way in R to implement this?
> > > >>>
> > > >>> ______________________________________________
> > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Peter Dalgaard, Professor,
> > > Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, Denmark
> > > Phone: (+45)38153501
> > > Office: A 4.23
> > > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> > >


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun  5 14:19:08 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Jun 2025 05:19:08 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CABcYAdJmmAfA33en+PVwKraxOmuhUr89cHjxGgAsbvAfayN2vw@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>
 <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>
 <CABcYAdJmmAfA33en+PVwKraxOmuhUr89cHjxGgAsbvAfayN2vw@mail.gmail.com>
Message-ID: <CAGxFJbT3K4N19VQhukVZ02kwn04kae3NDDJ=vJzEQRXs9Rze=g@mail.gmail.com>

Richard:

"The "use an upper bound of 100 - (n+1)*5" and then "add back
cumsum(rep(5,n)) at the end" (or equivalent) trick ensures the gaps
are right but does nothing about the distribution.."

If I understand you correctly, I think the above is wrong. Here is a
one-line version of Peter's code for the original problem:

sort(runif(10, 0, 55)) + seq.int(0, 45, 5)

AFAICS this is a bijection between the order statistics of runif(10, 0, 55)
and those of runif(10, 0, 100) with diffs >5. Please correct if I am wrong
or I have misunderstood.

Your other remarks about space and time complexity are correct, of course.

Cheers,
Bert




On Wed, Jun 4, 2025 at 11:04?PM Richard O'Keefe <raoknz at gmail.com> wrote:

> The Bentley and Saxe paper answers the questions
> (1) How can I draw a sample of n numbers in the range 0..1 such that
> the numbers are returned in increasing order WITHOUT sorting and so
> that all such sequences are equally likely in LINEAR time.  That's the
> code I showed in R.
> (2) How can I do this in a single pass?
> (3) How can I return the elements one at a time, generating each one
> on demand (O(1) space).
>
> The cumsum(runif(n))/n trick gets a sequence in linear time but the
> distribution is different.
> The sort(runif(n)) trick gets a sequence in O(n.log n) time but the
> distribution is different again.
>
> The "use an upper bound of 100 - (n+1)*5" and then "add back
> cumsum(rep(5,n)) at the end" (or equivalent) trick ensures the gaps
> are right but does nothing about the distribution..
>
> By the way, since you want numbers with 2 decimal places for some
> reason I don't understand,
> perhaps the simplest trick of all is
>
>    n <- 10 # how many numbers you want
>    L <- 0 # lower bound of the range
>    U <- 100 # upper bound of the range
>    G <- 5 # gap size
>    V <- U - G*(n+1) # reduced upper bound
>    x <- sort(sample((L*100):(V*100), size = n)) + cumsum(rep(G,
> times=n))/100
>
> I hope this is clear.
>
>
>
> On Thu, 5 Jun 2025 at 00:56, Brian Smith <briansmith199312 at gmail.com>
> wrote:
> >
> > Okay, I think I found the reason. This is due to accumulation of nine
> > 5s in the cumsum. Thanks again for the elegant solution.
> >
> > But I wonder, if the solution is simple then what is the significance
> > of the Research paper by Bentley and Saxe naming ?Generating sorted
> > lists of random numbers? which Richard mentioned?
> >
> > On Wed, 4 Jun 2025 at 17:54, Brian Smith <briansmith199312 at gmail.com>
> wrote:
> > >
> > > Hi Peter,
> > >
> > > Could you please help me to understand what is the basis of choosing
> > > 55 in runif(10,0,55))?
> > >
> > > Thank you!
> > >
> > > On Wed, 4 Jun 2025 at 02:45, peter dalgaard <pdalgd at gmail.com> wrote:
> > > >
> > > > Can't you just generate 10 values in (0,55), sort them, generate the
> distances, add 5 and cumulate?
> > > >
> > > > > x <- sort(runif(10,0,55))
> > > > > d <- diff(x)+5
> > > > > cumsum(c(x[1],d))
> > > >  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
> > > >  [8] 75.74085 81.28533 98.30792
> > > >
> > > >
> > > > > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com>
> wrote:
> > > > >
> > > > > Hi Richard,
> > > > >
> > > > > Thanks for your insight.
> > > > >
> > > > > As I mentioned in one of my earlier emails to the group, I imposed
> a
> > > > > constraint of accuracy up to two decimal places in order to obtain
> a
> > > > > finite set of possible values. For instance, if I were to round
> values
> > > > > to zero decimal places, the number of unique sequences that could
> be
> > > > > generated would be strictly finite and quite limited. Therefore, I
> > > > > chose a precision of two decimal places to allow for a larger but
> > > > > still finite number of possibilities.
> > > > >
> > > > >
> > > > > Now, my question is: how can this accuracy constraint be imposed
> effectively?
> > > > >
> > > > > Is the only practical method to generate samples, round each to two
> > > > > decimal places, and then check for duplicates to ensure
> uniqueness? If
> > > > > so, I?m concerned this might be inefficient, as many samples could
> be
> > > > > discarded, making the process time-consuming.
> > > > >
> > > > > Is there a better or more efficient way to directly enforce this
> > > > > constraint while generating the values?
> > > > >
> > > > > ________________________________
> > > > >
> > > > > Additionally, could you please elaborate on your suggestion
> regarding
> > > > > imposing minimum gap constraints by subtracting and then adding
> back
> > > > > certain gaps?
> > > > >
> > > > >
> > > > > For example, based on your earlier guidance, one possible sequence
> I
> > > > > obtained is:
> > > > >
> > > > >
> > > > > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623,
> 63.40264,
> > > > > 68.62261, 92.49899, 98.29308
> > > > >
> > > > >
> > > > > Now, I?d like to post-process this sequence to enforce a minimum
> > > > > difference constraint of, say, 5 units between values (including
> both
> > > > > lower and upper bounds).
> > > > >
> > > > > What would be the appropriate way to modify the sequence to impose
> > > > > this kind of constraint?
> > > > >
> > > > >
> > > > > Many thanks for your time and insight.
> > > > >
> > > > > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com>
> wrote:
> > > > >>
> > > > >> PS I forgot about the weird gaps requirement.
> > > > >> What you do is subtract the gaps off and then add them back.  I
> hope that is clear.
> > > > >>
> > > > >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <
> briansmith199312 at gmail.com> wrote:
> > > > >>>
> > > > >>> Hi,
> > > > >>>
> > > > >>> Let say I have a range [0, 100]
> > > > >>>
> > > > >>> Now I need to simulate 1000 10 mid-points within the range with
> > > > >>> accuracy upto second decimal number.
> > > > >>>
> > > > >>> Let say, one simulated set is
> > > > >>>
> > > > >>> X1, X2, ..., X10
> > > > >>>
> > > > >>> Ofcourrse
> > > > >>>
> > > > >>> X1 < X2 < ... <X10
> > > > >>>
> > > > >>> I have one more constraint that the difference between any 2
> > > > >>> consecutive mid-points shall be at-least 5.00.
> > > > >>>
> > > > >>> I wonder if there is any Statistical theory available to support
> this
> > > > >>> kind of simulation.
> > > > >>>
> > > > >>> Alternately, is there any way in R to implement this?
> > > > >>>
> > > > >>> ______________________________________________
> > > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >>> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > > > >>> and provide commented, minimal, self-contained, reproducible
> code.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > --
> > > > Peter Dalgaard, Professor,
> > > > Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3,
> 2000 Frederiksberg, Denmark
> > > > Phone: (+45)38153501
> > > > Office: A 4.23
> > > > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> > > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  6 07:09:01 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Jun 2025 22:09:01 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAGxFJbT3K4N19VQhukVZ02kwn04kae3NDDJ=vJzEQRXs9Rze=g@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>
 <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>
 <CABcYAdJmmAfA33en+PVwKraxOmuhUr89cHjxGgAsbvAfayN2vw@mail.gmail.com>
 <CAGxFJbT3K4N19VQhukVZ02kwn04kae3NDDJ=vJzEQRXs9Rze=g@mail.gmail.com>
Message-ID: <CAGxFJbST+tgDDLTk+swjGxgi1MNfF91bLVGabNU6C-GHCbDpHw@mail.gmail.com>

... and here is a a simple 2-liner without a sort that I think is linear in
time and space (but please correct if this is wrong):

x <- cumsum(runif(10))
x/x[10] * runif(1, 0, 55) + seq.int(0, 45,5)

Question: Does this give the same distribution as Peter's method using the
order statistics?  I believe yes, but someone more statistically competent
than me needs to verify or correct this.

Cheers,
Bert




On Thu, Jun 5, 2025 at 5:19?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

>
> Richard:
>
> "The "use an upper bound of 100 - (n+1)*5" and then "add back
> cumsum(rep(5,n)) at the end" (or equivalent) trick ensures the gaps
> are right but does nothing about the distribution.."
>
> If I understand you correctly, I think the above is wrong. Here is a
> one-line version of Peter's code for the original problem:
>
> sort(runif(10, 0, 55)) + seq.int(0, 45, 5)
>
> AFAICS this is a bijection between the order statistics of runif(10, 0,
> 55) and those of runif(10, 0, 100) with diffs >5. Please correct if I am
> wrong or I have misunderstood.
>
> Your other remarks about space and time complexity are correct, of course.
>
> Cheers,
> Bert
>
>
>
>
> On Wed, Jun 4, 2025 at 11:04?PM Richard O'Keefe <raoknz at gmail.com> wrote:
>
>> The Bentley and Saxe paper answers the questions
>> (1) How can I draw a sample of n numbers in the range 0..1 such that
>> the numbers are returned in increasing order WITHOUT sorting and so
>> that all such sequences are equally likely in LINEAR time.  That's the
>> code I showed in R.
>> (2) How can I do this in a single pass?
>> (3) How can I return the elements one at a time, generating each one
>> on demand (O(1) space).
>>
>> The cumsum(runif(n))/n trick gets a sequence in linear time but the
>> distribution is different.
>> The sort(runif(n)) trick gets a sequence in O(n.log n) time but the
>> distribution is different again.
>>
>> The "use an upper bound of 100 - (n+1)*5" and then "add back
>> cumsum(rep(5,n)) at the end" (or equivalent) trick ensures the gaps
>> are right but does nothing about the distribution..
>>
>> By the way, since you want numbers with 2 decimal places for some
>> reason I don't understand,
>> perhaps the simplest trick of all is
>>
>>    n <- 10 # how many numbers you want
>>    L <- 0 # lower bound of the range
>>    U <- 100 # upper bound of the range
>>    G <- 5 # gap size
>>    V <- U - G*(n+1) # reduced upper bound
>>    x <- sort(sample((L*100):(V*100), size = n)) + cumsum(rep(G,
>> times=n))/100
>>
>> I hope this is clear.
>>
>>
>>
>> On Thu, 5 Jun 2025 at 00:56, Brian Smith <briansmith199312 at gmail.com>
>> wrote:
>> >
>> > Okay, I think I found the reason. This is due to accumulation of nine
>> > 5s in the cumsum. Thanks again for the elegant solution.
>> >
>> > But I wonder, if the solution is simple then what is the significance
>> > of the Research paper by Bentley and Saxe naming ?Generating sorted
>> > lists of random numbers? which Richard mentioned?
>> >
>> > On Wed, 4 Jun 2025 at 17:54, Brian Smith <briansmith199312 at gmail.com>
>> wrote:
>> > >
>> > > Hi Peter,
>> > >
>> > > Could you please help me to understand what is the basis of choosing
>> > > 55 in runif(10,0,55))?
>> > >
>> > > Thank you!
>> > >
>> > > On Wed, 4 Jun 2025 at 02:45, peter dalgaard <pdalgd at gmail.com> wrote:
>> > > >
>> > > > Can't you just generate 10 values in (0,55), sort them, generate
>> the distances, add 5 and cumulate?
>> > > >
>> > > > > x <- sort(runif(10,0,55))
>> > > > > d <- diff(x)+5
>> > > > > cumsum(c(x[1],d))
>> > > >  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
>> > > >  [8] 75.74085 81.28533 98.30792
>> > > >
>> > > >
>> > > > > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com>
>> wrote:
>> > > > >
>> > > > > Hi Richard,
>> > > > >
>> > > > > Thanks for your insight.
>> > > > >
>> > > > > As I mentioned in one of my earlier emails to the group, I
>> imposed a
>> > > > > constraint of accuracy up to two decimal places in order to
>> obtain a
>> > > > > finite set of possible values. For instance, if I were to round
>> values
>> > > > > to zero decimal places, the number of unique sequences that could
>> be
>> > > > > generated would be strictly finite and quite limited. Therefore, I
>> > > > > chose a precision of two decimal places to allow for a larger but
>> > > > > still finite number of possibilities.
>> > > > >
>> > > > >
>> > > > > Now, my question is: how can this accuracy constraint be imposed
>> effectively?
>> > > > >
>> > > > > Is the only practical method to generate samples, round each to
>> two
>> > > > > decimal places, and then check for duplicates to ensure
>> uniqueness? If
>> > > > > so, I?m concerned this might be inefficient, as many samples
>> could be
>> > > > > discarded, making the process time-consuming.
>> > > > >
>> > > > > Is there a better or more efficient way to directly enforce this
>> > > > > constraint while generating the values?
>> > > > >
>> > > > > ________________________________
>> > > > >
>> > > > > Additionally, could you please elaborate on your suggestion
>> regarding
>> > > > > imposing minimum gap constraints by subtracting and then adding
>> back
>> > > > > certain gaps?
>> > > > >
>> > > > >
>> > > > > For example, based on your earlier guidance, one possible
>> sequence I
>> > > > > obtained is:
>> > > > >
>> > > > >
>> > > > > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623,
>> 63.40264,
>> > > > > 68.62261, 92.49899, 98.29308
>> > > > >
>> > > > >
>> > > > > Now, I?d like to post-process this sequence to enforce a minimum
>> > > > > difference constraint of, say, 5 units between values (including
>> both
>> > > > > lower and upper bounds).
>> > > > >
>> > > > > What would be the appropriate way to modify the sequence to impose
>> > > > > this kind of constraint?
>> > > > >
>> > > > >
>> > > > > Many thanks for your time and insight.
>> > > > >
>> > > > > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com>
>> wrote:
>> > > > >>
>> > > > >> PS I forgot about the weird gaps requirement.
>> > > > >> What you do is subtract the gaps off and then add them back.  I
>> hope that is clear.
>> > > > >>
>> > > > >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <
>> briansmith199312 at gmail.com> wrote:
>> > > > >>>
>> > > > >>> Hi,
>> > > > >>>
>> > > > >>> Let say I have a range [0, 100]
>> > > > >>>
>> > > > >>> Now I need to simulate 1000 10 mid-points within the range with
>> > > > >>> accuracy upto second decimal number.
>> > > > >>>
>> > > > >>> Let say, one simulated set is
>> > > > >>>
>> > > > >>> X1, X2, ..., X10
>> > > > >>>
>> > > > >>> Ofcourrse
>> > > > >>>
>> > > > >>> X1 < X2 < ... <X10
>> > > > >>>
>> > > > >>> I have one more constraint that the difference between any 2
>> > > > >>> consecutive mid-points shall be at-least 5.00.
>> > > > >>>
>> > > > >>> I wonder if there is any Statistical theory available to
>> support this
>> > > > >>> kind of simulation.
>> > > > >>>
>> > > > >>> Alternately, is there any way in R to implement this?
>> > > > >>>
>> > > > >>> ______________________________________________
>> > > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > >>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> > > > >>> and provide commented, minimal, self-contained, reproducible
>> code.
>> > > > >
>> > > > > ______________________________________________
>> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > > PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> > > > > and provide commented, minimal, self-contained, reproducible code.
>> > > >
>> > > > --
>> > > > Peter Dalgaard, Professor,
>> > > > Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3,
>> 2000 Frederiksberg, Denmark
>> > > > Phone: (+45)38153501
>> > > > Office: A 4.23
>> > > > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> > > >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  6 14:25:41 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 6 Jun 2025 05:25:41 -0700
Subject: [R] Simulating mid-points from a defined range
In-Reply-To: <CAGxFJbST+tgDDLTk+swjGxgi1MNfF91bLVGabNU6C-GHCbDpHw@mail.gmail.com>
References: <CAHUBDY_GYN_g5GGPLL3vuLbxrqWfodsxcaw6Q=t7--7Rh+UXTA@mail.gmail.com>
 <CABcYAd+uLC_WMrPa5mQdGouBOg2ej+cS845cXQzDzB78pbkqrg@mail.gmail.com>
 <CAHUBDY-ib=M_pVb-tVFE-r0bG6bfmx7FE_N2zzj7KDOJonnNjA@mail.gmail.com>
 <F2EA2B9B-3238-4F5D-AEDE-ADE76E3A5A54@gmail.com>
 <CAHUBDY-kRjreddiKSW7_PJqC+0+kb1eN1fW_kc3nj8iLmKq7SQ@mail.gmail.com>
 <CAHUBDY9nJhWtvj6H_YdKD9Zaxb8RFPSpDU+5EEbdnRy4cjQ3WQ@mail.gmail.com>
 <CABcYAdJmmAfA33en+PVwKraxOmuhUr89cHjxGgAsbvAfayN2vw@mail.gmail.com>
 <CAGxFJbT3K4N19VQhukVZ02kwn04kae3NDDJ=vJzEQRXs9Rze=g@mail.gmail.com>
 <CAGxFJbST+tgDDLTk+swjGxgi1MNfF91bLVGabNU6C-GHCbDpHw@mail.gmail.com>
Message-ID: <CAGxFJbSZvN2kWfxug6yEW_9Tz4XOuL5WKJ=8TVbxV-6rpfuE8w@mail.gmail.com>

Richard O'Keefe pointed out that I was wrong; the distributions are in fact
different.

One (now!) "obvious" reason why is that for the order statistics, the
distribution of the max is clearly skewed. For my cumsum method, the max is
clearly uniform (on [0,55] for the specific example).

Context matters!

Cheers,
Bert







On Thu, Jun 5, 2025 at 10:09?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... and here is a a simple 2-liner without a sort that I think is linear
> in time and space (but please correct if this is wrong):
>
> x <- cumsum(runif(10))
> x/x[10] * runif(1, 0, 55) + seq.int(0, 45,5)
>
> Question: Does this give the same distribution as Peter's method using the
> order statistics?  I believe yes, but someone more statistically competent
> than me needs to verify or correct this.
>
> Cheers,
> Bert
>
>
>
>
> On Thu, Jun 5, 2025 at 5:19?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>>
>> Richard:
>>
>> "The "use an upper bound of 100 - (n+1)*5" and then "add back
>> cumsum(rep(5,n)) at the end" (or equivalent) trick ensures the gaps
>> are right but does nothing about the distribution.."
>>
>> If I understand you correctly, I think the above is wrong. Here is a
>> one-line version of Peter's code for the original problem:
>>
>> sort(runif(10, 0, 55)) + seq.int(0, 45, 5)
>>
>> AFAICS this is a bijection between the order statistics of runif(10, 0,
>> 55) and those of runif(10, 0, 100) with diffs >5. Please correct if I am
>> wrong or I have misunderstood.
>>
>> Your other remarks about space and time complexity are correct, of course.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> On Wed, Jun 4, 2025 at 11:04?PM Richard O'Keefe <raoknz at gmail.com> wrote:
>>
>>> The Bentley and Saxe paper answers the questions
>>> (1) How can I draw a sample of n numbers in the range 0..1 such that
>>> the numbers are returned in increasing order WITHOUT sorting and so
>>> that all such sequences are equally likely in LINEAR time.  That's the
>>> code I showed in R.
>>> (2) How can I do this in a single pass?
>>> (3) How can I return the elements one at a time, generating each one
>>> on demand (O(1) space).
>>>
>>> The cumsum(runif(n))/n trick gets a sequence in linear time but the
>>> distribution is different.
>>> The sort(runif(n)) trick gets a sequence in O(n.log n) time but the
>>> distribution is different again.
>>>
>>> The "use an upper bound of 100 - (n+1)*5" and then "add back
>>> cumsum(rep(5,n)) at the end" (or equivalent) trick ensures the gaps
>>> are right but does nothing about the distribution..
>>>
>>> By the way, since you want numbers with 2 decimal places for some
>>> reason I don't understand,
>>> perhaps the simplest trick of all is
>>>
>>>    n <- 10 # how many numbers you want
>>>    L <- 0 # lower bound of the range
>>>    U <- 100 # upper bound of the range
>>>    G <- 5 # gap size
>>>    V <- U - G*(n+1) # reduced upper bound
>>>    x <- sort(sample((L*100):(V*100), size = n)) + cumsum(rep(G,
>>> times=n))/100
>>>
>>> I hope this is clear.
>>>
>>>
>>>
>>> On Thu, 5 Jun 2025 at 00:56, Brian Smith <briansmith199312 at gmail.com>
>>> wrote:
>>> >
>>> > Okay, I think I found the reason. This is due to accumulation of nine
>>> > 5s in the cumsum. Thanks again for the elegant solution.
>>> >
>>> > But I wonder, if the solution is simple then what is the significance
>>> > of the Research paper by Bentley and Saxe naming ?Generating sorted
>>> > lists of random numbers? which Richard mentioned?
>>> >
>>> > On Wed, 4 Jun 2025 at 17:54, Brian Smith <briansmith199312 at gmail.com>
>>> wrote:
>>> > >
>>> > > Hi Peter,
>>> > >
>>> > > Could you please help me to understand what is the basis of choosing
>>> > > 55 in runif(10,0,55))?
>>> > >
>>> > > Thank you!
>>> > >
>>> > > On Wed, 4 Jun 2025 at 02:45, peter dalgaard <pdalgd at gmail.com>
>>> wrote:
>>> > > >
>>> > > > Can't you just generate 10 values in (0,55), sort them, generate
>>> the distances, add 5 and cumulate?
>>> > > >
>>> > > > > x <- sort(runif(10,0,55))
>>> > > > > d <- diff(x)+5
>>> > > > > cumsum(c(x[1],d))
>>> > > >  [1] 12.27815 21.21060 26.37856 36.03812 41.97237 57.02945 67.86113
>>> > > >  [8] 75.74085 81.28533 98.30792
>>> > > >
>>> > > >
>>> > > > > On 3 Jun 2025, at 09.21, Brian Smith <briansmith199312 at gmail.com>
>>> wrote:
>>> > > > >
>>> > > > > Hi Richard,
>>> > > > >
>>> > > > > Thanks for your insight.
>>> > > > >
>>> > > > > As I mentioned in one of my earlier emails to the group, I
>>> imposed a
>>> > > > > constraint of accuracy up to two decimal places in order to
>>> obtain a
>>> > > > > finite set of possible values. For instance, if I were to round
>>> values
>>> > > > > to zero decimal places, the number of unique sequences that
>>> could be
>>> > > > > generated would be strictly finite and quite limited. Therefore,
>>> I
>>> > > > > chose a precision of two decimal places to allow for a larger but
>>> > > > > still finite number of possibilities.
>>> > > > >
>>> > > > >
>>> > > > > Now, my question is: how can this accuracy constraint be imposed
>>> effectively?
>>> > > > >
>>> > > > > Is the only practical method to generate samples, round each to
>>> two
>>> > > > > decimal places, and then check for duplicates to ensure
>>> uniqueness? If
>>> > > > > so, I?m concerned this might be inefficient, as many samples
>>> could be
>>> > > > > discarded, making the process time-consuming.
>>> > > > >
>>> > > > > Is there a better or more efficient way to directly enforce this
>>> > > > > constraint while generating the values?
>>> > > > >
>>> > > > > ________________________________
>>> > > > >
>>> > > > > Additionally, could you please elaborate on your suggestion
>>> regarding
>>> > > > > imposing minimum gap constraints by subtracting and then adding
>>> back
>>> > > > > certain gaps?
>>> > > > >
>>> > > > >
>>> > > > > For example, based on your earlier guidance, one possible
>>> sequence I
>>> > > > > obtained is:
>>> > > > >
>>> > > > >
>>> > > > > 10.07181, 14.49839, 14.74435, 18.75167, 42.70361, 55.79623,
>>> 63.40264,
>>> > > > > 68.62261, 92.49899, 98.29308
>>> > > > >
>>> > > > >
>>> > > > > Now, I?d like to post-process this sequence to enforce a minimum
>>> > > > > difference constraint of, say, 5 units between values (including
>>> both
>>> > > > > lower and upper bounds).
>>> > > > >
>>> > > > > What would be the appropriate way to modify the sequence to
>>> impose
>>> > > > > this kind of constraint?
>>> > > > >
>>> > > > >
>>> > > > > Many thanks for your time and insight.
>>> > > > >
>>> > > > > On Tue, 3 Jun 2025 at 10:42, Richard O'Keefe <raoknz at gmail.com>
>>> wrote:
>>> > > > >>
>>> > > > >> PS I forgot about the weird gaps requirement.
>>> > > > >> What you do is subtract the gaps off and then add them back.  I
>>> hope that is clear.
>>> > > > >>
>>> > > > >> On Sun, 1 Jun 2025 at 6:52?AM, Brian Smith <
>>> briansmith199312 at gmail.com> wrote:
>>> > > > >>>
>>> > > > >>> Hi,
>>> > > > >>>
>>> > > > >>> Let say I have a range [0, 100]
>>> > > > >>>
>>> > > > >>> Now I need to simulate 1000 10 mid-points within the range with
>>> > > > >>> accuracy upto second decimal number.
>>> > > > >>>
>>> > > > >>> Let say, one simulated set is
>>> > > > >>>
>>> > > > >>> X1, X2, ..., X10
>>> > > > >>>
>>> > > > >>> Ofcourrse
>>> > > > >>>
>>> > > > >>> X1 < X2 < ... <X10
>>> > > > >>>
>>> > > > >>> I have one more constraint that the difference between any 2
>>> > > > >>> consecutive mid-points shall be at-least 5.00.
>>> > > > >>>
>>> > > > >>> I wonder if there is any Statistical theory available to
>>> support this
>>> > > > >>> kind of simulation.
>>> > > > >>>
>>> > > > >>> Alternately, is there any way in R to implement this?
>>> > > > >>>
>>> > > > >>> ______________________________________________
>>> > > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > > >>> PLEASE do read the posting guide
>>> https://www.R-project.org/posting-guide.html
>>> > > > >>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>> > > > >
>>> > > > > ______________________________________________
>>> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > > > PLEASE do read the posting guide
>>> https://www.R-project.org/posting-guide.html
>>> > > > > and provide commented, minimal, self-contained, reproducible
>>> code.
>>> > > >
>>> > > > --
>>> > > > Peter Dalgaard, Professor,
>>> > > > Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3,
>>> 2000 Frederiksberg, Denmark
>>> > > > Phone: (+45)38153501
>>> > > > Office: A 4.23
>>> > > > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> > > >
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Jun  8 08:21:32 2025
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 8 Jun 2025 08:21:32 +0200
Subject: [R] How to stratify data with multiple group simultaneously with R
 ggplot2?
Message-ID: <CAMk+s2TxQjH-VF5R4x67-ax6dAW4jQxkgJfta6ebMhHewxDrkQ@mail.gmail.com>

I would like to plot multivariate data with ggplot2. I have multiple
groups that I need to account for: I have the `x` and `y` values, but
the data must be stratified also by `w` and `z`. I can group by either
`w` or `z`, but how can I group for both simultaneously?
In essence, in the example below, the legend should have two columns
(A and B) and five rows (which are already there since the data is
stratified by w). There should be 10 colors.
How can I do that?
Thank you

>>>>>>
```
df = data.frame(x = c(rep(1,5), rep(2,5), rep(3,5), rep(4,5)),
                                w = rep(letters[1:5],4),
                                z = c(rep(LETTERS[1],10), rep(LETTERS[2],10)),
                                y = rnorm(20),
                                stringsAsFactors = FALSE)
library(ggplot2)
ggplot(df, aes(x=x, y=y, colour=w, group=w)) +
  geom_line(linewidth=2) +
  ggtitle("A+B")
ggplot(df[df$z=="A",], aes(x=x, y=y, colour=w, group=w)) +
  geom_line(linewidth=2) +
  ggtitle("A")
ggplot(df[df$z=="B",], aes(x=x, y=y, colour=w, group=w)) +
  geom_line(linewidth=2) +
  ggtitle("B")
```


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jun  8 09:07:00 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 08 Jun 2025 00:07:00 -0700
Subject: [R] 
 How to stratify data with multiple group simultaneously with R
 ggplot2?
In-Reply-To: <CAMk+s2TxQjH-VF5R4x67-ax6dAW4jQxkgJfta6ebMhHewxDrkQ@mail.gmail.com>
References: <CAMk+s2TxQjH-VF5R4x67-ax6dAW4jQxkgJfta6ebMhHewxDrkQ@mail.gmail.com>
Message-ID: <301DA1D8-E474-4DF8-9C18-54E48E6282AB@dcn.davis.ca.us>

You can use group=interaction(w,z)... but in my experience that gets confusing for the poor person trying to make sense of the plot. It is better to use color=w, linetype=z or use facets for one of the grouping variables.

On June 7, 2025 11:21:32 PM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>I would like to plot multivariate data with ggplot2. I have multiple
>groups that I need to account for: I have the `x` and `y` values, but
>the data must be stratified also by `w` and `z`. I can group by either
>`w` or `z`, but how can I group for both simultaneously?
>In essence, in the example below, the legend should have two columns
>(A and B) and five rows (which are already there since the data is
>stratified by w). There should be 10 colors.
>How can I do that?
>Thank you
>
>>>>>>>
>```
>df = data.frame(x = c(rep(1,5), rep(2,5), rep(3,5), rep(4,5)),
>                                w = rep(letters[1:5],4),
>                                z = c(rep(LETTERS[1],10), rep(LETTERS[2],10)),
>                                y = rnorm(20),
>                                stringsAsFactors = FALSE)
>library(ggplot2)
>ggplot(df, aes(x=x, y=y, colour=w, group=w)) +
>  geom_line(linewidth=2) +
>  ggtitle("A+B")
>ggplot(df[df$z=="A",], aes(x=x, y=y, colour=w, group=w)) +
>  geom_line(linewidth=2) +
>  ggtitle("A")
>ggplot(df[df$z=="B",], aes(x=x, y=y, colour=w, group=w)) +
>  geom_line(linewidth=2) +
>  ggtitle("B")
>```
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jun  8 18:03:31 2025
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Jun 2025 17:03:31 +0100
Subject: [R] 
 How to stratify data with multiple group simultaneously with R
 ggplot2?
In-Reply-To: <CAMk+s2TxQjH-VF5R4x67-ax6dAW4jQxkgJfta6ebMhHewxDrkQ@mail.gmail.com>
References: <CAMk+s2TxQjH-VF5R4x67-ax6dAW4jQxkgJfta6ebMhHewxDrkQ@mail.gmail.com>
Message-ID: <f07f5f89-2f3a-45e8-8d42-095122ab5db8@sapo.pt>

?s 07:21 de 08/06/2025, Luigi Marongiu escreveu:
> I would like to plot multivariate data with ggplot2. I have multiple
> groups that I need to account for: I have the `x` and `y` values, but
> the data must be stratified also by `w` and `z`. I can group by either
> `w` or `z`, but how can I group for both simultaneously?
> In essence, in the example below, the legend should have two columns
> (A and B) and five rows (which are already there since the data is
> stratified by w). There should be 10 colors.
> How can I do that?
> Thank you
> 
>>>>>>>
> ```
> df = data.frame(x = c(rep(1,5), rep(2,5), rep(3,5), rep(4,5)),
>                                  w = rep(letters[1:5],4),
>                                  z = c(rep(LETTERS[1],10), rep(LETTERS[2],10)),
>                                  y = rnorm(20),
>                                  stringsAsFactors = FALSE)
> library(ggplot2)
> ggplot(df, aes(x=x, y=y, colour=w, group=w)) +
>    geom_line(linewidth=2) +
>    ggtitle("A+B")
> ggplot(df[df$z=="A",], aes(x=x, y=y, colour=w, group=w)) +
>    geom_line(linewidth=2) +
>    ggtitle("A")
> ggplot(df[df$z=="B",], aes(x=x, y=y, colour=w, group=w)) +
>    geom_line(linewidth=2) +
>    ggtitle("B")
> ```
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

You can use the 4th variable to define facets. Like this?


ggplot(df, aes(x=x, y=y, colour=w)) +
   geom_line(linewidth=2) +
   facet_wrap(~ z, scales = "free_x") +
   ggtitle("A+B")


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Jun 13 08:41:13 2025
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 13 Jun 2025 08:41:13 +0200
Subject: [R] 
 How to stratify data with multiple group simultaneously with R
 ggplot2?
In-Reply-To: <f07f5f89-2f3a-45e8-8d42-095122ab5db8@sapo.pt>
References: <CAMk+s2TxQjH-VF5R4x67-ax6dAW4jQxkgJfta6ebMhHewxDrkQ@mail.gmail.com>
 <f07f5f89-2f3a-45e8-8d42-095122ab5db8@sapo.pt>
Message-ID: <CAMk+s2Sr41U3cnsMRNZcGjt=Xn2kgzJEqywDA+M4WGghFGBD4g@mail.gmail.com>

Thank you, facets are good but I was looking for something that could
merge everything in a single plot. I found that I could create an
additional column, say M (merge), that accommodates two parameters
into one, for instance, `a + A`, `a + B` etc. By grouping for M, I can
kind of stratify the data...

On Sun, Jun 8, 2025 at 6:03?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> ?s 07:21 de 08/06/2025, Luigi Marongiu escreveu:
> > I would like to plot multivariate data with ggplot2. I have multiple
> > groups that I need to account for: I have the `x` and `y` values, but
> > the data must be stratified also by `w` and `z`. I can group by either
> > `w` or `z`, but how can I group for both simultaneously?
> > In essence, in the example below, the legend should have two columns
> > (A and B) and five rows (which are already there since the data is
> > stratified by w). There should be 10 colors.
> > How can I do that?
> > Thank you
> >
> >>>>>>>
> > ```
> > df = data.frame(x = c(rep(1,5), rep(2,5), rep(3,5), rep(4,5)),
> >                                  w = rep(letters[1:5],4),
> >                                  z = c(rep(LETTERS[1],10), rep(LETTERS[2],10)),
> >                                  y = rnorm(20),
> >                                  stringsAsFactors = FALSE)
> > library(ggplot2)
> > ggplot(df, aes(x=x, y=y, colour=w, group=w)) +
> >    geom_line(linewidth=2) +
> >    ggtitle("A+B")
> > ggplot(df[df$z=="A",], aes(x=x, y=y, colour=w, group=w)) +
> >    geom_line(linewidth=2) +
> >    ggtitle("A")
> > ggplot(df[df$z=="B",], aes(x=x, y=y, colour=w, group=w)) +
> >    geom_line(linewidth=2) +
> >    ggtitle("B")
> > ```
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> You can use the 4th variable to define facets. Like this?
>
>
> ggplot(df, aes(x=x, y=y, colour=w)) +
>    geom_line(linewidth=2) +
>    facet_wrap(~ z, scales = "free_x") +
>    ggtitle("A+B")
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> www.avg.com



-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun 13 13:14:18 2025
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 13 Jun 2025 12:14:18 +0100
Subject: [R] 
 How to stratify data with multiple group simultaneously with R
 ggplot2?
In-Reply-To: <CAMk+s2Sr41U3cnsMRNZcGjt=Xn2kgzJEqywDA+M4WGghFGBD4g@mail.gmail.com>
References: <CAMk+s2TxQjH-VF5R4x67-ax6dAW4jQxkgJfta6ebMhHewxDrkQ@mail.gmail.com>
 <f07f5f89-2f3a-45e8-8d42-095122ab5db8@sapo.pt>
 <CAMk+s2Sr41U3cnsMRNZcGjt=Xn2kgzJEqywDA+M4WGghFGBD4g@mail.gmail.com>
Message-ID: <bf2dd59a-e5fd-44f8-865b-dcacf022d258@sapo.pt>

?s 07:41 de 13/06/2025, Luigi Marongiu escreveu:
> Thank you, facets are good but I was looking for something that could
> merge everything in a single plot. I found that I could create an
> additional column, say M (merge), that accommodates two parameters
> into one, for instance, `a + A`, `a + B` etc. By grouping for M, I can
> kind of stratify the data...
> 
> On Sun, Jun 8, 2025 at 6:03?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> ?s 07:21 de 08/06/2025, Luigi Marongiu escreveu:
>>> I would like to plot multivariate data with ggplot2. I have multiple
>>> groups that I need to account for: I have the `x` and `y` values, but
>>> the data must be stratified also by `w` and `z`. I can group by either
>>> `w` or `z`, but how can I group for both simultaneously?
>>> In essence, in the example below, the legend should have two columns
>>> (A and B) and five rows (which are already there since the data is
>>> stratified by w). There should be 10 colors.
>>> How can I do that?
>>> Thank you
>>>
>>>>>>>>>
>>> ```
>>> df = data.frame(x = c(rep(1,5), rep(2,5), rep(3,5), rep(4,5)),
>>>                                   w = rep(letters[1:5],4),
>>>                                   z = c(rep(LETTERS[1],10), rep(LETTERS[2],10)),
>>>                                   y = rnorm(20),
>>>                                   stringsAsFactors = FALSE)
>>> library(ggplot2)
>>> ggplot(df, aes(x=x, y=y, colour=w, group=w)) +
>>>     geom_line(linewidth=2) +
>>>     ggtitle("A+B")
>>> ggplot(df[df$z=="A",], aes(x=x, y=y, colour=w, group=w)) +
>>>     geom_line(linewidth=2) +
>>>     ggtitle("A")
>>> ggplot(df[df$z=="B",], aes(x=x, y=y, colour=w, group=w)) +
>>>     geom_line(linewidth=2) +
>>>     ggtitle("B")
>>> ```
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> You can use the 4th variable to define facets. Like this?
>>
>>
>> ggplot(df, aes(x=x, y=y, colour=w)) +
>>     geom_line(linewidth=2) +
>>     facet_wrap(~ z, scales = "free_x") +
>>     ggtitle("A+B")
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
>> www.avg.com
> 
> 
> 
Hello,

Any of Jeff's two suggestions seems to work well.
(I prefer the first one.)



library(ggplot2)
library(dplyr)

ggplot(df, aes(x = x, y = y, colour = w, linetype = z)) +
   geom_line(linewidth = 2) +
   ggtitle("A+B")

df %>%
   mutate(M = interaction(w, z)) %>% # arrange(M) %>% print()
   ggplot(aes(x=x, y=y, colour=w, group = M)) +
   geom_line(linewidth=2) +
   ggtitle("A+B")



Hope this helps,

Rui Barradas


From r-@nnounce @end|ng |rom r-project@org  Fri Jun 13 10:06:55 2025
From: r-@nnounce @end|ng |rom r-project@org (Peter Dalgaard via R-announce)
Date: Fri, 13 Jun 2025 08:06:55 +0000
Subject: [R] [Rd] R 4.5.1 is released
Message-ID: <9466D537-EBE3-4347-B8BF-42FDE61A7479@cbs.dk>

The build system rolled up R-4.5.1.tar.gz and .xz (codename ?Great Square Root") this morning.

This is a patch release with a handful of minor changes and mixups.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.5.1.tar.gz
https://cran.r-project.org/src/base/R-4/R-4.5.1.tar.xz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course. 


For the R Core Team,

Peter Dalgaard


These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = 07651d43d483521300ca8d68fc797522
MD5 (build-dist.log) = 5d3ce1a527ec387f0a1ffb34fd2dcb32
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 509204af252e96df0f9c5232667136a9
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = d335f3e8664e05352e4ff5a43bfd0468
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = f8466e418dec6b958b4ce484a13f9a9d
MD5 (NEWS.2) = 05e4a57b645e651ba13019c3cf5c495f
MD5 (NEWS.3) = 082abfc2fdc36912075e78b92fb2941e
MD5 (R-latest.tar.gz) = e22eee30af90ec66eb179b66d122ffd9
MD5 (R-latest.tar.xz) = 9d027d75905654421dbaa7b3953e9760
MD5 (README) = e8e5ee38544d34409177cd479025fe66
MD5 (RESOURCES) = 94ab0226460af048446af1041a23771b
MD5 (THANKS) = 61d146aa6a2cf5999295b2fb340991c1
MD5 (VERSION-INFO.dcf) = a072111b90e7db672871542523a2793c
MD5 (R-4/R-4.5.1.tar.gz) = e22eee30af90ec66eb179b66d122ffd9
MD5 (R-4/R-4.5.1.tar.xz) = 9d027d75905654421dbaa7b3953e9760

b87c4dfcb4300f8af91009e2473f2ee5747e9e199df353c90146cba2aee8f444  AUTHORS
a1c0f18bc5f7a4e234aeb2877e62b477c478fb066ad217a70b302c3b8be9114f  build-dist.log
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
5f9f622d2febc0bfbe5381599f2fba7dcfae3b372d48988ee30f474e86290ffa  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
c4392d9d2f3d3951dc4b4db9323dc9889bfa1ef064bd8a6b3a00f28f510a3469  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
602f3a40ef759c7b2a6c485a33dc674af34249644ac5fb53b21283d4e12e808d  NEWS.1
7babb6d82a4479b2c3803f7dbfaab63125b0f0d1b6bb40b1389d3af65eaf83aa  NEWS.2
eb473efd365822e7ae64eb0f86028ea019815fdd273fe7daa9c6fe5e28fd2737  NEWS.3
b42a7921400386645b10105b91c68728787db5c4c83c9f6c30acdce632e1bb70  R-latest.tar.gz
3c29f587f438588160cc8a82a2b3fcc0abff392f731d930b4eaa7f85fa022a32  R-latest.tar.xz
f5aa875c23185cbfc3a50739d7295b0caba2cf0e38ba082850be338cc9541154  README
fa76f82f7e3664afa4394623afedbc696a2ee90925be65ca57fc9e4b399f3ed6  RESOURCES
1d5064c86b6813865a033763f43212064c0a67ef05f5af13b13c4feb08264a33  THANKS
817ce098a213836d8664201f3eb46fa7969626526c2b31da4297340e0c115524  VERSION-INFO.dcf
b42a7921400386645b10105b91c68728787db5c4c83c9f6c30acdce632e1bb70  R-4/R-4.5.1.tar.gz
3c29f587f438588160cc8a82a2b3fcc0abff392f731d930b4eaa7f85fa022a32  R-4/R-4.5.1.tar.xz

This is the relevant part of the NEWS file

CHANGES IN R 4.5.1:

  NEW FEATURES:

    ? The internal method of unzip() now follows unzip 6.00 in how it
      handles extracted file paths which contain "../".  With thanks to
      Ivan Krylov.

  INSTALLATION:

    ? Standalone nmath can be built with early-2025 versions of
      clang-based compilers such as LLVM clang 20, Apple clang 17 and
      Intel icx 2025.0.

    ? Tcl/Tk 9 can be used to build package tcltk: this has become the
      default in some Linux distributions.  *N.B.* several third-party
      packages currently require Tcl/Tk 8 or even 8.6 without declaring
      so.

  BUG FIXES:

    ? Java detection in javareconf could not detect libjvm.* in the
      zero variant of the JDK (PR#18884).  All valid variants as of JDK
      24u are now supported.

    ? factanal(.., rotation=*) now correctly updates rotmat, fixing
      PR#18886.

    ? dnbinom(<large>, <muchlarger>, ..) now is 0 correctly, instead of
      NaN or Inf sometimes.

    ? dbinom(<large>, n=Inf, ..) is 0 now correctly, instead of NaN
      which also fixes many dnbinom() cases, notably those mentioned in
      PR#16727 comment #5.

    ? Fixing C level ?binomial deviance? bd0() for extreme arguments
      (preventing under-/overflow) solves more PR#16727 cases and also
      prevents some full accuracy loss in such cases for dbinom(),
      dnbinom(), and via dbinom_raw() potentially dgeom(), dhyper(),
      dbeta(), and df().

    ? signif(1.**e308, digits) no longer truncates unnecessarily (but
      still to prevent overflow to Inf), fixing PR#18889.

    ? prettyNum(*, zero.print={>=1-char}, replace.zero=TRUE) now works
      as documented, thanks to Marttila Mikko and Ivan Krylov's
      messages on R-devel.

    ? pbeta(x, a,b, ..) for very large a,b no longer returns NaN but
      the correct values (0 or 1, or their logs for log.p = TRUE).
      This improves Mathlib's C level bratio() and hence also
      pnbinom(), etc..

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

From @m@||@|nve@tor @end|ng |rom @o|@com  Fri Jun 13 13:49:37 2025
From: @m@||@|nve@tor @end|ng |rom @o|@com (Small Investor)
Date: Fri, 13 Jun 2025 11:49:37 +0000 (UTC)
Subject: [R] Some general comments
References: <429529464.317437.1749815377473.ref@mail.yahoo.com>
Message-ID: <429529464.317437.1749815377473@mail.yahoo.com>

Dear R community,
I have been using R for over 15 years. I want to raise an issue which has been haunting me for some time now: It feels as if R is falling apart. I try to justify this feeling by providing three discussion points:
1. Version compatibility issues seem to be on the rise. Very often, you get the message that package x was built on R version y (and thus, won't work in your version of R). When you update to the latest version of R, you realize that not all packages are available for that version. It seems that for each version, only a (non-predictable) subset of packages is available.
2. The overhead of installing new packages seems to be on the rise. It seems that the packages depend on more and more other packages. The more packages you have in the 'foundations' of package x, the more likely it is that one of these causes an error and the whole stack fails. Installing used to be easy back in the day: You got a 20 lines' output. Now you get endless prints. I may be mistaken but some packages seem to require admin rights on your computer which you don't often have on your work PC.
3. R seems to be developing into different dialects. You have dplyr and tidyr, some people prefer data frames, some prefer tibbles. Some people use pipes, some use traditional syntax. Some prefer object-oriented programs, some prefer procedural scripts. If you put in a job announcement that somebody has to know R, it doesn't mean the same thing for different people.
If you compare the use experience of R in 2025 to that of Matlab, the difference is striking: Matlab is concise and clear, R is more and more about endless prints. Of course, Matlab is a commerical product, but R used to be the same way. I don't know if many other people feel the same way, but I think I am shifting away from R.
yours best,a data analyst dude

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun 13 21:17:29 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 13 Jun 2025 15:17:29 -0400
Subject: [R] Some general comments
In-Reply-To: <429529464.317437.1749815377473@mail.yahoo.com>
References: <429529464.317437.1749815377473.ref@mail.yahoo.com>
 <429529464.317437.1749815377473@mail.yahoo.com>
Message-ID: <A77EE3A4-2D52-4FF9-B276-FE0BCB6270A9@dcn.davis.ca.us>

Would you prefer that R be static?

If you don't like the dependency hell of certain packages, then perhaps those packages are not appropriate for you. You always have the option to create your own packages... and in nearly all cases the licenses of contributed packages allow you to re-formulate their code into your own packages.

Do be clear... contributed packages are not "R". R Core bears no responsibility for the decisions made by package developers in making progress on those packages. 

I am curious what you are drifting _toward_... Python has had some dramatic changes in syntax over time... so much so that using Python without a version-pinned virtual environment is hardly possible. You have support for that approach in R also. I suspect that any open scripting tool will have similar problems... if one tool doesn't have that problem now, it will later.

On June 13, 2025 7:49:37 AM EDT, Small Investor via R-help <r-help at r-project.org> wrote:
>Dear R community,
>I have been using R for over 15 years. I want to raise an issue which has been haunting me for some time now: It feels as if R is falling apart. I try to justify this feeling by providing three discussion points:
>1. Version compatibility issues seem to be on the rise. Very often, you get the message that package x was built on R version y (and thus, won't work in your version of R). When you update to the latest version of R, you realize that not all packages are available for that version. It seems that for each version, only a (non-predictable) subset of packages is available.
>2. The overhead of installing new packages seems to be on the rise. It seems that the packages depend on more and more other packages. The more packages you have in the 'foundations' of package x, the more likely it is that one of these causes an error and the whole stack fails. Installing used to be easy back in the day: You got a 20 lines' output. Now you get endless prints. I may be mistaken but some packages seem to require admin rights on your computer which you don't often have on your work PC.
>3. R seems to be developing into different dialects. You have dplyr and tidyr, some people prefer data frames, some prefer tibbles. Some people use pipes, some use traditional syntax. Some prefer object-oriented programs, some prefer procedural scripts. If you put in a job announcement that somebody has to know R, it doesn't mean the same thing for different people.
>If you compare the use experience of R in 2025 to that of Matlab, the difference is striking: Matlab is concise and clear, R is more and more about endless prints. Of course, Matlab is a commerical product, but R used to be the same way. I don't know if many other people feel the same way, but I think I am shifting away from R.
>yours best,a data analyst dude
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @vi@e@gross m@iii@g oii gm@ii@com  Fri Jun 13 23:24:38 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Fri, 13 Jun 2025 17:24:38 -0400
Subject: [R] Some general comments
In-Reply-To: <429529464.317437.1749815377473@mail.yahoo.com>
References: <429529464.317437.1749815377473.ref@mail.yahoo.com>
 <429529464.317437.1749815377473@mail.yahoo.com>
Message-ID: <012401dbdca9$9198b710$b4ca2530$@gmail.com>

I would add to what Jeff replied. Many and perhaps most or even all
languages that have room for evolution, including Python, can end up getting
more and more complex with multiple ways to do things but it generally is
possible to write many useful programs in the core language.

I often wonder what would happen if someone took a language that was decades
old, and examined a recent version and used the results to create a new
streamlined language in which many choices are simply removed and some newer
ones are used instead. Consider the endless number of ways you can now do
formatted printing in python including various versions of strings. In R,
some of the ideas have been made available in the glue package in the
tidyverse which many people do not know about and others use instead of much
of what is available in basic R. 

I think having choices is great for programmers but as noted, makes it
harder when hiring people to see if they fit. But, IMNSHO, any programmer
you hire that is not able to rapidly get on board and read manual pages or
sections of books showing how to use features, may not be the best hire. I
know I have been hired in situations where my experience was of different
operating systems, programming languages and editors/environments and
switching was not hard because I had a flexible background. Over years, we
kept shifting and I kept up while some others who knew ONE THING were often
struggling.

The reality is that R was written so long ago that it would rapidly have
been less and less attractive to some programmers if it stood still. Some of
the concerns mentioned are reasonable and some have solutions such as taking
a snapshot of what versions of things you allow to be used that form a
stable environment and then not updating anything. A new machine would
download just the copies needed, as long as the version remained archived.

But is R as bad as Python which split in ways that made many 2.x programs
incompatible with 3.x and yet some people continue to use the old version,
which is a bit souped up to emulate, rather than changing the code to be
compatible? Nobody forces you to use dplyr and frankly, it has similar
issues as the tidyverse once built has been changed often enough so my older
programs often tell me functionality has been, or will soon be, made
obsolete and the newer stuff may be much more powerful and yet a pain to use
for simple things as they allow ever more abstractions. 

I will say that it may happen to R too and a new language named P may be
offered alongside R that will become more difficult within a year. 

But had this happened, R would not have things like a built-in pipe that
some find useful or even essential.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Small Investor via
R-help
Sent: Friday, June 13, 2025 7:50 AM
To: r-help at r-project.org
Subject: [R] Some general comments

Dear R community,
I have been using R for over 15 years. I want to raise an issue which has
been haunting me for some time now: It feels as if R is falling apart. I try
to justify this feeling by providing three discussion points:
1. Version compatibility issues seem to be on the rise. Very often, you get
the message that package x was built on R version y (and thus, won't work in
your version of R). When you update to the latest version of R, you realize
that not all packages are available for that version. It seems that for each
version, only a (non-predictable) subset of packages is available.
2. The overhead of installing new packages seems to be on the rise. It seems
that the packages depend on more and more other packages. The more packages
you have in the 'foundations' of package x, the more likely it is that one
of these causes an error and the whole stack fails. Installing used to be
easy back in the day: You got a 20 lines' output. Now you get endless
prints. I may be mistaken but some packages seem to require admin rights on
your computer which you don't often have on your work PC.
3. R seems to be developing into different dialects. You have dplyr and
tidyr, some people prefer data frames, some prefer tibbles. Some people use
pipes, some use traditional syntax. Some prefer object-oriented programs,
some prefer procedural scripts. If you put in a job announcement that
somebody has to know R, it doesn't mean the same thing for different people.
If you compare the use experience of R in 2025 to that of Matlab, the
difference is striking: Matlab is concise and clear, R is more and more
about endless prints. Of course, Matlab is a commerical product, but R used
to be the same way. I don't know if many other people feel the same way, but
I think I am shifting away from R.
yours best,a data analyst dude

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


